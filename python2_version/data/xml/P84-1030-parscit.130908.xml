<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000351">
<note confidence="0.9431825">
FROBLEE LOCALIZATION STRATEGIES
EQE FRAGMAT/CS FROCESSING IN NATURAL-LANGUAGE FRONT INDS*
</note>
<author confidence="0.376692">
Lance A. Ramshaw &amp; Ralph M. Weischedel
</author>
<affiliation confidence="0.699984666666667">
Department of Computer and Information Sciences
University of Delaware
Newark, Delaware 19716 USA
</affiliation>
<sectionHeader confidence="0.820472" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999844071428572">
Problem localization is the identification of
the most significant failures in the AND-OR tree
resulting from an unsuccessful attempt to achieve a
goal, for instance, in planning, backward-chaining
inference, or top-down parsing. We examine heuris-
tics and strategies for problem localization in the
context of using a planner to check for pragmatic
failures in natural language input to computer sys-
tems, such as a cooperative natural language
interface to Unix&amp;quot;. Our heuristics call for
selecting the most hopeful branch at ORs, but the
most problematic one at ANDs. Surprise scores and
special-purpose rules are the main strategies sug-
gested to determine this.
</bodyText>
<sectionHeader confidence="0.863919" genericHeader="method">
I PRAGMATIC OVERSHOOT AND PROBLEM LOCALIZATION
</sectionHeader>
<bodyText confidence="0.999910478260869">
Even if the syntactic and semantic content of
a request is correct, 30 that a natural language
front end can derive a coherent representation of
its meaning, its pragmatic content or the structure
of the underlying system may make any direct
response to the request impossible or misleading.
According to Sondheimer and Weischedel (Sondheimer,
1980), an input exhibits pragmatic overshoot if the
representation of its meaning is beyond the capa-
bilities of the underlying system. Kaplan (1979),
Mays (1980a), and Carberry (1984) have each worked
on strategies for dealing with particular classes
of such pragmatic failures. This paper addresses
the problem of identifying the most significant
reason that a plan to achieve a user goal cannot be
carried out.
The approach to pragmatic failure taken in
this paper is to use a planner to verify the
presumptions in a request. The presumptions behind
a request become the subgoals of a plan to fulfill
the request. Using Mays&apos; (1980a) example, the
query &amp;quot;Which faculty members take courses?&amp;quot; is here
handled as an instance of an IDENTIFY-SET-MEMBERS
</bodyText>
<listItem confidence="0.986251">
â€¢ This material is based upon work supported by
the National Science Foundation under grants
IST-8009673 and IST-8311400.
</listItem>
<bodyText confidence="0.99673365625">
of Unix is a trademark of Bell Laboratories.
goal, and the pragmatics of the query are checked
by looking for a plan to achieve that goal. Deter-
mining both that faculty members and courses do
exist and that faculty members can take courses are
subgoals within that plan. A presuppositional
failure is noted if the planner is unable to com-
plete a plan for the goal.
Furthermore, information for recovery process-
ing or explanatory responses can be derived
directly from the failed plan by identifying what-
ever blocked goal in the planning tree of subgoals
is most significant. Thus, in the example above,
if the planner failed because it was unable to show
that faculty can take courses, the helpful response
would be to explain this presumption failure. We
concentrate here on identifying the significant
blocks rather than on generating natural language
responses.
The examples in this paper will be drawn from
a planning system intended to function as the prag-
matic overshoot component of a cooperative natural
language interface to the Unix operating system.
We chose Unix, much as Wilensky (1982) did for his
Unix Consultant, as a familiar domain that was
still complex enough to require interesting plan-
ning. In this system, the pragmatics of a user
request are tested by building a tree of plan
structures whose leaves are elementary facts avail-
able to the operating system. For instance, the
following planning tree is built in response to the
request to print a file:
</bodyText>
<sectionHeader confidence="0.9818172" genericHeader="method">
(PRINT-FILE ?user ?file ?device)
&amp; (IS-TEXT-FILE ?file)
&amp; (UP-AND-RUNNING ?device)
&amp; (READ-PERM ?user ?file)
1 (WORLD-READ-PERM-BIT-SET ?file)
</sectionHeader>
<bodyText confidence="0.516648">
I (READ-PERM-USER ?user ?file)
</bodyText>
<sectionHeader confidence="0.969855625" genericHeader="method">
&amp; (IS-CWNER ?user ?file)
&amp; (USER-READ-PERM-BIT-SET ?file).
I (READ-PERM-GRCOP ?user ?file)
&amp; (SAME-GRCOP ?user ?file)
&amp; (GRCOP-READ-PERM-BIT-SET ?file)
I (READ-PERM-SUPER-USER ?user)
&amp; (AUTHORIZED-SUPER-USER ?user)
&amp; (SUPER-USER-PASSWORD-GIVEN ?user)
</sectionHeader>
<bodyText confidence="0.9798465">
(The children of AND nodes are preceded by =per-
sands, and OR children by vertical bars. Initial
question marks precede plan variables.) If a single
node in this planning tree fails, say (IS-TEXT-FILE
?file), that information can be used in explaining
the failure to the user.
</bodyText>
<page confidence="0.99828">
139
</page>
<bodyText confidence="0.99763925">
The failure of certain nodes could also
trigger recovery processing, as in the following
example, where the failure of (UP-AND-RUNNING
?device) triggers the suggestion of an alternative
device:
User: Please send the file to the laser printer.
System: The laser printer is down.
Is the line printer satisfactory?
This planning scheme offers a way of recognizing
and responding to such temporarily unfulfillable
requests as well as to other pragmatic failures
from requests unfulfillable in context, which is an
important, though largely untouched, problem.
A difficulty arises, however, when more than
one of the planning tree precondition nodes fail.
Even in a tree that was entirely made up of AND
nodes, multiple failures would require either a
list of responses, or else same way of choosing
which of the failures is most meaningful to report.
In a plan tree containing OR nodes, where there are
often many alternative ways that have all failed of
achieving particular goals, it becomes even more
important that the system be able to identify which
of the failures is most significant. This process
of identifying the significant failures is called
&amp;quot;problem localization&amp;quot;, and this paper describes
heuristics and strategies that can be used for
problem localization in failed planning trees.
</bodyText>
<sectionHeader confidence="0.991923" genericHeader="method">
II HEURISTICS FOR PROBLEM LOCALIZATION
</sectionHeader>
<bodyText confidence="0.999960534883721">
The basic heuristics for problem localization
can be derived by considering how a human expert
would respond to someone who was pursuing an impos-
sible goal. Not finding any successful plan, the
expert tries to explain the block by showing that
every plan must fail. Thus, if more than one
branch of an AND node in a plan fails, the most
significant one to be reported is the one that the
user is least likely to be able to change, since it
makes the strongest case. (The planner must check
all the branches of an AND node, even after one
fails, to know which is most significant to
report.) For instance, if all three of the children
of PRINT-FILE in our example fail, (IS-TEXT-FILE
?file) is the one that should be reported, since it
is least likely that the user can affect that node.
If the READ-PERM failure were reported first, the
user would waste time changing the read permission
of a non-text file. Unix&apos;s actual behavior, which
reports the first problem that it happens to dis-
cover in trying to execute the command, is often
frustrating for exactly that reason. This heuris-
tic of reporting the most serious failure at an AND
node is closely related to ABSTRIP&apos;s use of &amp;quot;criti-
cality&amp;quot; numbers to divide a planner into levels of
abstraction, so that the most critical features are
dealt with first (Sacerdoti, 1974). ,
The situation is different at OR nodes, where
only a single child has to succeed. Here the most
serious failure can safely be ignored, as long as
some other branch can be repaired. Thus the most
significant branch at an OR node should be the one
the user is most likely to be able to affect. In
our example, READ-PERM-USER should usually be
reported rather than READ-PERM-SUPER-USER, if both
have failed, since most users have more hope of
changing the former than the latter. There is a
duality here between the AND and OR node heuristics
that is like the duality in the minimax evaluation
of a move in a game tree, where one picks the best
score at nodes where the choice is one&apos;s own, and
the worst score at nodes where the opponent gets to
choose.
</bodyText>
<sectionHeader confidence="0.982737" genericHeader="method">
III STRATEGIES FOR PROBLEM LOCALIZATION
</sectionHeader>
<bodyText confidence="0.969310375">
Identification of the most significant failure
requires the addition to the planner of knowledge
about significance to be used in problem localiza-
tion. Many mechanisms are possible, ranging from
fixed, pre-set ordering of the children of nodes up
through complex knowledge-based mechanisms that
include knowledge about the user&apos;s probable goals.
In this paper, we suggest a combination of statist-
ical &amp;quot;surprise scores&amp;quot; and special-purpose rules.
8, Statistical Ranking gang Surnrise Scores
This strategy relies on statistics that the
system keeps dynamically on the number of times
that each branch of each plan has succeeded or
failed. These are used to define a success ratio
for each branch. For example, the PRINT-FILE plan
might be annotated as follows:
</bodyText>
<sectionHeader confidence="0.890549" genericHeader="method">
SUCCESSES FAILURES RATIO
(PRINT-FILE ?user ?file ?device)
</sectionHeader>
<bodyText confidence="0.955747">
&amp; (IS-TEXT-FILE ?file) 235 3 0.99
&amp; (UP-AND-RUNNING ?device) 185 53 0.78
&amp; (READ-PERM ?user ?file) 228 10 0.96
From these ratios, we derive surprise scores
to provide some measure of how usual or unusual it
is for a particular node to have succeeded or
failed in the context of the goal giving rise to
the node. The surprise score of a successful node
is defined as 1.0 minus the success ratio, so that
the success of a node like IS-TEXT-FILE, that
almost always succeeds, is less surprising than the
success of UP-AND-RUNNING. Failed nodes get nega-
tive surprise scores, with the absolute value of
the score again reflecting the amount of surprise.
The surprise score of a failed node is set to the
negative of the success ratio, so that the failure
of IS-TEXT-FILE would be more surprising than that
of UP-AND-RUNNING, and that would be reflected by a
more strongly negative score.
Here is an example of our PRINT-FILE plan
instantiated for an unlucky user who has failed on
all but two preconditions, with surprise scores
added:
</bodyText>
<page confidence="0.986053">
140
</page>
<table confidence="0.9813244375">
SURPRISE
SUCCESS/FAILURE SCORE
(PRINT-FILE Ann Filel laser)
&amp; (IS-TEXT-FILE Filel) F -.99
&amp; (UP-AND-RUNNING laser) F -.78
&amp; (READ-PERM Ann Filet) F -.96
I (WORLD-READ-PERM-BIT-SET Filel) F -.02
1 (READ-PENN-USER Ann Filel) F -.87
&amp; (IS-CWNER Ann Filel) F -.87
&amp; (USER-READ-PERM-BIT-SET Filet) S +.01
1 (READ-PERM-GROUP Ann Filel) F -.55
&amp; (SAME-GROUP Ann Filel) S +.05
&amp; (GROUP-READ-PERM-BIT-SET File1) F -.58
1 (READ-PERM-SUPER-USER Ann) F -.02
&amp; (AUTHORIZED-SUPER-USER Ann) F -.03
&amp; (SUPER-USER-PASSWORD-GIVEN Ann) F -.02
</table>
<bodyText confidence="0.999914370967742">
Note that the success of USER-READ-PERM-BIT-SET is
not very surprising, since that node almost always
succeeds; the failure of a node like READ-PERM-
SUPER-USER, which seldom succeeds, is much less
surprising than the failure of UP-AND-RUNNING.
We suggest keeping statistics and deriving
surprise scores because we believe that they pro-
vide a useful if imperfect handle on judging the
significance of failed nodes. Regarding OR nodes,
strongly negative surprise scores identify branches
that in the past experience of the system have usu-
ally succeeded, and these are the beat guesses to
be likely to succeed again. Thus READ-PERM-USER,
the child of READ-PERM with the most strongly nega-
tive score, turns out to be the most likely to be
tractable. The negative surprise scores at a
failed OR node give a profile of the typical suc-
cess ratios; to select the nodes that are generally
most likely to succeed, we pick the most surprising
failures, those with the most strongly negative
surprise scores.
At AND nodes, on the other hand, the goal is
to identify the branch that is most critical, that
is, least likely to succeed. Surprisingly, we find
that the most critical branch tends in this case
also to be the most surprising failure. In our
example, IS-TEXT-FILE, which the user can do noth-
ing about, is the most surprising failure under
PRINT-FILE, READ-PERM is next most surprising, and
UP-AND-RUNNING, for which simply waiting often
works, comes last. Therefore at AND nodes, like at
OR nodes, we will report the child with the most
negative surprise score; at AND nodes, this tends
to identify the most critical failures, while at OR
nodes, it tends to select the most hopeful. Note
that the combined effect of the AND and OR stra-
tegies is to choose from among all the failed nodes
those that were statistically most likely to
succeed.
The main advantage of the statistical surprise
score strategy is its low cost, both to design and
execute. Another nice feature is the self-
adjusting character of the surprise scores, based
as they are on success statistics that the system
updates on an ongoing basis. For example, the
likelihood of GROUP-READ-PERM being reported would
depend on how often that feature was used at a par-
ticular site. The main difficulty is that surprise
scores are only a rough guide to the actual signi-
ficance of a failed node. The true significance of
a failure in the context of a particular command
may depend on world knowledge that is beyond the
grasp of the planning system (e.g., the laser
printer is down for days this time rather than
hours), or even on a part of the planning context
itself that is not reflected in the statistical
averages (e.g., READ-PERM-SUPER-USER is much more
likely to succeed when READ-PERM is called as part
of a system dump command than when it is called as
part of PRINT-FILE). To get a more accurate grasp
on the significance of particular failures, more
knowledge-intensive strategies must be employed.
</bodyText>
<subsectionHeader confidence="0.441607">
E. Special-Purpose Problem Localization Rules
</subsectionHeader>
<bodyText confidence="0.999914857142857">
As a mechanism for adding extra knowledge, we
propose supplementing the surprise scores with
condition-action rules attached to particular nodes
in the planning tree. The conditions in these
rules can test the success or failure of other
nodes in the tree or determine the higher-level
planning context, while the actions alter the prob-
lem localization result by changing the surprise
scores attached to the nodes.
The special-purpose rules which we have found
useful so far add information about the criticality
of particular nodes. Consider the following plan-
ning tree, which is somewhat more successful than
the previous one:
</bodyText>
<equation confidence="0.9203339375">
SURPRISE
SUCCESS/FAILURE SCORE
(PRINT-FILE Ann File2 laser)
&amp; (IS-TEXT-FILE File2) S +.01
&amp; (UP-AND-RUNNING laser) S +.22
&amp; (READ-PERM Ann File2) F -.96
I (WORLD-READ-PERM-BIT-SET File2) F -.02
I (READ-PERM-USER Ann File2) F -.87
&amp; (IS-CWNER Ann File2) F -.87
&amp; (USER-READ-PERM-BIT-SET File2) S +.01
I (READ-PERM-GROUP Ann File2) F -.55
&amp; (SAME-GROUP Ann File2) S +.05
&amp; (GROUP-READ-PERM-BIT-SET File2) F -.58
I (READ-PERM-SUPER-USER Ann) F -.02
&amp; (AUTHORIZED-SUPER-USER Ann) S +.97
&amp; (SUPER-USER-PASSWORD-GIVEN Ann) F -.02
</equation>
<bodyText confidence="0.999540090909091">
Relying on surprise scores alone, the most signifi-
cant child of READ-PERM would be READ-PERM-USER,
since its score is most strongly negative. How-
ever, since IS-CWNER has failed, a node which most
users are powerless to change, it is clearly not
helpful to choose READ-PERM-USER as the path to
report. This is an example of the general rule that
if we know that one child of an AND node is criti-
cal, we should include a rule to suppress that AND
node whenever that child fails. Thus we attach the
following rule to READ-PERM-USER:
</bodyText>
<sectionHeader confidence="0.9870305" genericHeader="method">
IF (FAILED-CHILD (IS-CWNEEI ?user ?file))
THEN (SUPPRESS-SCORE 0.8)
</sectionHeader>
<bodyText confidence="0.9973725">
In our current formulation, the numeric argument to
SUPPRESS-SCORE gives the factor (i.e., percentage)
</bodyText>
<page confidence="0.9966">
141
</page>
<bodyText confidence="0.998132">
by which the score should be reduced. The -rule&apos;s
affect is to change READ-PERM-USER&apos;s score to -.17,
which prevents it from being selected.
With READ-PERM-USER suppressed, the surprise
scores would then select READ-PERM-GROUP, which is
a reasonable choice, but probably not the best one.
While the failure of IS-CWNER makes us less
interested in READ-PERM-USER, the very surprising
success of AUTHORIZED-SUPER-USER should draw the
system&apos;s attention to the READ-PERM-SUPER-USER
branch. We can arrange for this by attaching to
READ-PERM-SUPER-USER a rule that states:
</bodyText>
<sectionHeader confidence="0.998845666666667" genericHeader="method">
IF (SUCCESSFUL-CHILD
(AUTHORIZED-SUPER-USER ?user))
THEN (ENHANCE-SCORE 0.8)
</sectionHeader>
<bodyText confidence="0.9999263125">
This rule would change READ-PERM-SUPER-USER&apos;s score
from -.02 to -.79, and thus cause it to be the
branch of READ-PERM selected for reporting.
While our current rules are all in these two
forms, either suppressing or enhancing a parent&apos;s
score on the basis of a critical child&apos;s failure or
success, the mechanism of special-purpose rules
could be expanded to handle more complex forms of
deduction. For example, it might be useful to add
rules that calculate a criticality score for each
node, working upward from preassigned scores
assigned to the leaves. If the rules could access
information about the state of the system, they
could also use that in judging criticality, so that
an UP-AND-RUNNING failure would be more critical if
the device was expected to be down for a long time.
</bodyText>
<subsectionHeader confidence="0.557898">
D. Pith= problem Localization strategies
</subsectionHeader>
<bodyText confidence="0.989723755555556">
While our system depends on surprise scores
and rules, an entire range of strategies is possi-
ble. The simplest strategy would be to hand-code
the problem localization into the plans themselves
by the ordering of the branches. At AND nodes, the
children that are more critical would be listed
first, while at OR nodes, the less critical, more
hopeful, children would come first. In such a
blocked tree, the first failed child could be
selected below each node. A form of this hand-
coded strategy is in force in any planner that
stops exploring an AND node when a single child
blocks; that effectively selects the first child
tested as the significant failure in every case,
since the others are not even explored. Rand-
coding is an alternative to surprise scores for
providing an initial comparative ranking of the
children at each node, but it also would need sup-
plementing with a strategy that can take account of
unusual situations, such as our special-purpose
rules.
It might be possible to improve the perfor-
mance of a surprise score system without adding the
complexity of special-purpose rules by using a for-
mula that allows the surprising success or failure
of a child to increase or decrease the chances of
its parent being reported. While such a formula
could perhaps do much of the work now done by
special-purpose rules, it seems a harder approach
to control, and one more likely to be sensitive to
inaccuracies in the surprise scores themselves.
D. Proper Lover a Detail
One final question concerns identifying the
proper level of detail for helpful responses. The
strategies discussed so far have all focused on
choosing which of multiple blocked children to
report, so that they identify a path from the root
to a leaf. Yet the leaves of the planning tree may
well be too detailed to represent helpful
responses. A selection strategy could report the
node containing the appropriate level of detail for
a given user. Modeling the expertise of a user and
using that to select an appropriate description of
the problem are significant problems in natural
language generation which we have not addressed.
</bodyText>
<sectionHeader confidence="0.997542" genericHeader="method">
IV RELATED APPLICATION AREAS
</sectionHeader>
<bodyText confidence="0.999983833333333">
While developed here in the context of a prag-
matics planner, strategies for problem localization
could have wide applicability. For instance, the
MYCIN -like &amp;quot;How?&amp;quot; and &amp;quot;Why?&amp;quot; questions (Shortliffe,
1976) used in the explanation components of many
expert systems already use either the already-built
successful proof tree or the portion currently
being explored as a source of explanations. Swar-
tout (1983) adds extra knowledge that allows the
system to justify its answers in the user&apos;s terms,
but the user must still direct the exploration. An
effective problem localization facility would allow
the system to answer the question &amp;quot;Why not?&amp;quot;; that
is, the user could ask why a certain goal was not
substantiated, and the system would reply by iden-
tifying the surprising nodes that are likely to be
the significant causes of tae failure. Such &amp;quot;Why
not?&amp;quot; questions could be useful not only in expla-
nation but also in debugging.
In the same way, since the execution of a PRO-
LCG program can be seen as the exploration of and
AND-OR tree, effective problem localization tech-
niques could be useful in debugging the failed
trees that result from incorrect logic programs.
Another example is recovery processing in
top-down parsing, such as using augmented transi-
tion networks (Woods, 1970). When an ATN fails to
parse a sentence, the blocked parse tree is quite
similar to a blocked planning tree. Weischedel
(1983) suggests an approach to understanding ill-
formed input that makes use of meta-rules to relax
some of the constraints on ATN arcs that blocked
the original parse. Recovery processing in that
model requires searching the blocked parse tree for
nodes to which meta-rules can be applied. A prob-
lem localization strategy could be used to sort the
</bodyText>
<page confidence="0.993775">
142
</page>
<bodyText confidence="0.9950675">
list of blocked nodes, so that the most likely can-
didates would be tested first. The statistics of
success ratios here would describe likely paths
through the grammar. Nodes that exhibit surprising
failure would be prime candidates for meta-rule
processing.
VII REFERENCES
Carberry, M. Sandra. &amp;quot;Understanding Pragmatically
Ill-Formed Input.&amp;quot; proceedings gf Ina Interne-
tiOnal Conference nn Computational lAnnulnlinn,
1984.
Before problem localization can be applied in
these related areas, further work needs to be done
to see how many of the heuristics and strategies
that apply to problem localization in the planning
context can be carried over. The larger and more
complex trees of an ATN or PROLCG program may well
require developnent of further strategies. How-
ever, the nature of the problem is such that even
an imperfect result is likely to be useful.
</bodyText>
<sectionHeader confidence="0.999155" genericHeader="method">
V IMPLEMENTATION DESCRIPTION
</sectionHeader>
<bodyText confidence="0.99914825">
The examples in this paper are taken frcm an
Interlisp implementation of a planner which does
pragmatics checklng for a limited set of Unix-
domain requests. The problem localization com-
ponent uses a combination of surprise scores and
special purpose rules, as described. The statis-
tics were derived by running the planner on a test
set of commands in a simulated Unix environment.
</bodyText>
<sectionHeader confidence="0.998924" genericHeader="method">
VI CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.998621833333333">
In planning-based pragmatics processing, prob-
lem localization addresses the largely untouched
problem of providing helpful responses to requests
unfulfillable in context. Problem localization in
the planning context requires identifying the most
hopeful and tractable choice at OR nodes, but the
most critical and problematic one at AND nodes.
Statistical surprise scores provide a cheap but
effective base strategy for problem localization,
and condition-action rules are an appropriate
mechanism for adding further sophistication.
Further work should address (1) applying
recovery strategies to the localized problem, if
any recovery is appropriate; (2) investigating
other applications, such as expert systems,
backward-chaining inference, and top-down parsing;
and (3) exploring natural language generation to
report a block at an appropriate level of detail.
</bodyText>
<reference confidence="0.970692756756757">
Kaplan, Samuel J. C000erative Nesnonsea Prom a
Portable Natural Lanauage Data Same Query System.
PhD. Dissertation, Computer and Information Sci-
ence Dept., University of Pennsylvania, 1979.
Mays, Eric. &amp;quot;Correcting Misconceptions About Data
Base Structure.&amp;quot; Proceedings sat the Conference 2L
tta Daaaglan Society fgr Dzsgutatiggal Studies
Intelligence. Victoria, British Columbia,
Canada, May 1980, 123-128.
Mays, Eric. *Failures in Natural Language Systems:
Applications to Data Base Query Systems.&amp;quot;
Prsandigusa szt the Flrat Annual National Confer-
ence nn Artificial Intelligence (UJ.-8Q). Stan-
ford, California, August 1980, 327-330.
Sacerdoti, E. D. &apos;Planning in a Hierarchy of
Abstraction Spaces.&amp;quot; Artificial Intelligence 5.
(1974), 115-135.
Shortliffe, E. H. Computer 5ase4 Medical Consulta-
tions: =IL (North-Holland, 1976).
Sondbeimer, N. and R. M. Weischedel. &amp;quot;A Rule-Based
Approach to Ill-Formed Input.&amp;quot; proceeding the
ath International Conference ga Computational
Linguistic&amp;quot;, 1980.
Swartout, William R. &amp;quot;XPLAIN: A System for Creat-
ing and Explaining Expert Consulting Programs.&apos;
Artificial Iatelligence U(1903), 285-325.
Weischedel, Ralph M. and Norman K. Sondbeimer.
&amp;quot;Meta-Rules as a Basis for Processing Ill-Formed
Input.&apos; American journal Computational
Li=WI= 9. (1983) , to appear.
Wilensky, Robert. &apos;Talking to UNIX in English: An
Overview of 13C.&apos; proftedingm a =ft 1.92. Nationa
Conference 0,,t Artificial Intelligence (AAAI-82),
103-106.
Woods, William A. *Transition Network Grammars
for Natural Language Analysis.&apos; rawawagatuala a
Ihft AO 13. (Oct. 1970), 591-606.
</reference>
<page confidence="0.999116">
143
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.982232">FROBLEE LOCALIZATION STRATEGIES FROCESSINGIN FRONT INDS*</title>
<author confidence="0.999939">Lance A Ramshaw</author>
<author confidence="0.999939">Ralph M Weischedel</author>
<affiliation confidence="0.9999035">Department of Computer and Information Sciences University of Delaware</affiliation>
<address confidence="0.994752">Newark, Delaware 19716 USA</address>
<abstract confidence="0.983429065727699">Problem localization is the identification of the most significant failures in the AND-OR tree resulting from an unsuccessful attempt to achieve a goal, for instance, in planning, backward-chaining inference, or top-down parsing. We examine heuristics and strategies for problem localization in the of using a planner to check in natural language input to computer sysas a cooperative natural language interface to Unix&amp;quot;. Our heuristics call for selecting the most hopeful branch at ORs, but the most problematic one at ANDs. Surprise scores and special-purpose rules are the main strategies suggested to determine this. I PRAGMATIC OVERSHOOT AND PROBLEM LOCALIZATION Even if the syntactic and semantic content of request is correct, a natural language front end can derive a coherent representation of its meaning, its pragmatic content or the structure of the underlying system may make any direct response to the request impossible or misleading. According to Sondheimer and Weischedel (Sondheimer, an input exhibits overshootif the representation of its meaning is beyond the capabilities of the underlying system. Kaplan (1979), Mays (1980a), and Carberry (1984) have each worked on strategies for dealing with particular classes of such pragmatic failures. This paper addresses the problem of identifying the most significant reason that a plan to achieve a user goal cannot be carried out. The approach to pragmatic failure taken in this paper is to use a planner to verify the presumptions in a request. The presumptions behind a request become the subgoals of a plan to fulfill request. (1980a) example, the query &amp;quot;Which faculty members take courses?&amp;quot; is here handled as an instance of an IDENTIFY-SET-MEMBERS â€¢ This material is based upon work supported by the National Science Foundation under grants IST-8009673 and IST-8311400. is a trademark of Bell Laboratories. goal, and the pragmatics of the query are checked by looking for a plan to achieve that goal. Determining both that faculty members and courses do exist and that faculty members can take courses are subgoals within that plan. A presuppositional failure is noted if the planner is unable to complete a plan for the goal. Furthermore, information for recovery processing or explanatory responses can be derived directly from the failed plan by identifying whatever blocked goal in the planning tree of subgoals is most significant. Thus, in the example above, if the planner failed because it was unable to show that faculty can take courses, the helpful response would be to explain this presumption failure. We concentrate here on identifying the significant blocks rather than on generating natural language responses. The examples in this paper will be drawn from a planning system intended to function as the pragmatic overshoot component of a cooperative natural interface to the system. chose Unix, much as Wilensky (1982) did Unix Consultant, as a familiar domain that was complex enough to require interesting planning. In this system, the pragmatics of a user request are tested by building a tree of plan structures whose leaves are elementary facts available to the operating system. For instance, the following planning tree is built in response to the request to print a file: (PRINT-FILE ?user ?file ?device) &amp; (IS-TEXT-FILE ?file) &amp; (UP-AND-RUNNING ?device) &amp; (READ-PERM ?user ?file) ?file) ?user ?file) &amp; (IS-CWNER ?user ?file) (USER-READ-PERM-BIT-SET ?user ?file) &amp; (SAME-GRCOP ?user ?file) &amp; (GRCOP-READ-PERM-BIT-SET ?file) ?user) &amp; (AUTHORIZED-SUPER-USER ?user) &amp; (SUPER-USER-PASSWORD-GIVEN ?user) (The children of AND nodes are preceded by =persands, and OR children by vertical bars. Initial question marks precede plan variables.) If a single node in this planning tree fails, say (IS-TEXT-FILE ?file), that information can be used in explaining the failure to the user. 139 The failure of certain nodes could also trigger recovery processing, as in the following example, where the failure of (UP-AND-RUNNING ?device) triggers the suggestion of an alternative device: User: Please send the file to the laser printer. System: The laser printer is down. Is the line printer satisfactory? This planning scheme offers a way of recognizing and responding to such temporarily unfulfillable requests as well as to other pragmatic failures from requests unfulfillable in context, which is an important, though largely untouched, problem. A difficulty arises, however, when more than one of the planning tree precondition nodes fail. Even in a tree that was entirely made up of AND nodes, multiple failures would require either a list of responses, or else same way of choosing which of the failures is most meaningful to report. In a plan tree containing OR nodes, where there are often many alternative ways that have all failed of achieving particular goals, it becomes even more important that the system be able to identify which of the failures is most significant. This process of identifying the significant failures is called &amp;quot;problem localization&amp;quot;, and this paper describes heuristics and strategies that can be used for problem localization in failed planning trees. II HEURISTICS FOR PROBLEM LOCALIZATION The basic heuristics for problem localization can be derived by considering how a human expert respond to someone who was pursuing an impossible goal. Not finding any successful plan, the expert tries to explain the block by showing that every plan must fail. Thus, if more than one branch of an AND node in a plan fails, the most significant one to be reported is the one that the user is least likely to be able to change, since it makes the strongest case. (The planner must check all the branches of an AND node, even after one fails, to know which is most significant to report.) For instance, if all three of the children of PRINT-FILE in our example fail, (IS-TEXT-FILE ?file) is the one that should be reported, since it is least likely that the user can affect that node. If the READ-PERM failure were reported first, the user would waste time changing the read permission of a non-text file. Unix&apos;s actual behavior, which reports the first problem that it happens to discover in trying to execute the command, is often frustrating for exactly that reason. This heuristic of reporting the most serious failure at an AND node is closely related to ABSTRIP&apos;s use of &amp;quot;criticality&amp;quot; numbers to divide a planner into levels of abstraction, so that the most critical features are dealt with first (Sacerdoti, 1974). , The situation is different at OR nodes, where only a single child has to succeed. Here the most serious failure can safely be ignored, as long as some other branch can be repaired. Thus the most significant branch at an OR node should be the one the user is most likely to be able to affect. In our example, READ-PERM-USER should usually be reported rather than READ-PERM-SUPER-USER, if both have failed, since most users have more hope of changing the former than the latter. There is a duality here between the AND and OR node heuristics that is like the duality in the minimax evaluation of a move in a game tree, where one picks the best score at nodes where the choice is one&apos;s own, and the worst score at nodes where the opponent gets to choose. III STRATEGIES FOR PROBLEM LOCALIZATION Identification of the most significant failure requires the addition to the planner of knowledge significance to be used in problem localization. Many mechanisms are possible, ranging from fixed, pre-set ordering of the children of nodes up through complex knowledge-based mechanisms that include knowledge about the user&apos;s probable goals. In this paper, we suggest a combination of statistical &amp;quot;surprise scores&amp;quot; and special-purpose rules. StatisticalRanking gang Scores This strategy relies on statistics that the system keeps dynamically on the number of times that each branch of each plan has succeeded or failed. These are used to define a success ratio for each branch. For example, the PRINT-FILE plan might be annotated as follows: SUCCESSES FAILURES RATIO (PRINT-FILE ?user ?file ?device) &amp; (IS-TEXT-FILE ?file) 235 3 0.99 &amp; (UP-AND-RUNNING ?device) 185 53 0.78 &amp; (READ-PERM ?user ?file) 228 10 0.96 From these ratios, we derive surprise scores to provide some measure of how usual or unusual it is for a particular node to have succeeded or failed in the context of the goal giving rise to the node. The surprise score of a successful node is defined as 1.0 minus the success ratio, so that the success of a node like IS-TEXT-FILE, that almost always succeeds, is less surprising than the success of UP-AND-RUNNING. Failed nodes get negative surprise scores, with the absolute value of the score again reflecting the amount of surprise. The surprise score of a failed node is set to the negative of the success ratio, so that the failure IS-TEXT-FILE would surprising than that of UP-AND-RUNNING, and that would be reflected by a more strongly negative score. Here is an example of our PRINT-FILE plan instantiated for an unlucky user who has failed on all but two preconditions, with surprise scores added: 140 SURPRISE SUCCESS/FAILURE SCORE (PRINT-FILE Ann Filel laser)</abstract>
<note confidence="0.983252307692308">amp; (IS-TEXT-FILE Filel) F -.99 &amp; (UP-AND-RUNNING laser) F -.78 &amp; (READ-PERM Ann Filet) F -.96 I (WORLD-READ-PERM-BIT-SET Filel) F -.02 1 (READ-PENN-USER Ann Filel) F -.87 &amp; (IS-CWNER Ann Filel) F -.87 &amp; (USER-READ-PERM-BIT-SET Filet) S +.01 1 (READ-PERM-GROUP Ann Filel) F -.55 &amp; (SAME-GROUP Ann Filel) S +.05 &amp; (GROUP-READ-PERM-BIT-SET File1) F -.58 1 (READ-PERM-SUPER-USER Ann) F -.02 &amp; (AUTHORIZED-SUPER-USER Ann) F -.03 &amp; (SUPER-USER-PASSWORD-GIVEN Ann) F -.02</note>
<abstract confidence="0.978850632911393">Note that the success of USER-READ-PERM-BIT-SET is not very surprising, since that node almost always the failure of a node READ-PERM- SUPER-USER, which seldom succeeds, is much less surprising than the failure of UP-AND-RUNNING. We suggest keeping statistics and deriving surprise scores because we believe that they provide a useful if imperfect handle on judging the significance of failed nodes. Regarding OR nodes, strongly negative surprise scores identify branches that in the past experience of the system have usually succeeded, and these are the beat guesses to be likely to succeed again. Thus READ-PERM-USER, the child of READ-PERM with the most strongly negative score, turns out to be the most likely to be tractable. The negative surprise scores at a failed OR node give a profile of the typical success ratios; to select the nodes that are generally most likely to succeed, we pick the most surprising failures, those with the most strongly negative surprise scores. At AND nodes, on the other hand, the goal is to identify the branch that is most critical, that is, least likely to succeed. Surprisingly, we find that the most critical branch tends in this case also to be the most surprising failure. In our example, IS-TEXT-FILE, which the user can do nothing about, is the most surprising failure under PRINT-FILE, READ-PERM is next most surprising, and UP-AND-RUNNING, for which simply waiting often works, comes last. Therefore at AND nodes, like at OR nodes, we will report the child with the most negative surprise score; at AND nodes, this tends to identify the most critical failures, while at OR nodes, it tends to select the most hopeful. Note that the combined effect of the AND and OR strategies is to choose from among all the failed nodes those that were statistically most likely to succeed. The main advantage of the statistical surprise score strategy is its low cost, both to design and execute. Another nice feature is the selfadjusting character of the surprise scores, based as they are on success statistics that the system updates on an ongoing basis. For example, the likelihood of GROUP-READ-PERM being reported would depend on how often that feature was used at a parsite. The main difficulty is that scores are only a rough guide to the actual significance of a failed node. The true significance of a failure in the context of a particular command may depend on world knowledge that is beyond the grasp of the planning system (e.g., the laser printer is down for days this time rather than hours), or even on a part of the planning context itself that is not reflected in the statistical averages (e.g., READ-PERM-SUPER-USER is much more likely to succeed when READ-PERM is called as part of a system dump command than when it is called as part of PRINT-FILE). To get a more accurate grasp on the significance of particular failures, more knowledge-intensive strategies must be employed. Problem Localization Rules As a mechanism for adding extra knowledge, we propose supplementing the surprise scores with condition-action rules attached to particular nodes the planning tree. The conditions these rules can test the success or failure of other nodes in the tree or determine the higher-level planning context, while the actions alter the problem localization result by changing the surprise scores attached to the nodes. The special-purpose rules which we have found useful so far add information about the criticality of particular nodes. Consider the following planning tree, which is somewhat more successful than the previous one: SURPRISE SUCCESS/FAILURE SCORE</abstract>
<note confidence="0.983354642857143">(PRINT-FILE Ann File2 laser) &amp; (IS-TEXT-FILE File2) S +.01 &amp; (UP-AND-RUNNING laser) S +.22 &amp; (READ-PERM Ann File2) F -.96 I (WORLD-READ-PERM-BIT-SET File2) F -.02 Ann File2) F -.87 &amp; (IS-CWNER Ann File2) F -.87 &amp; (USER-READ-PERM-BIT-SET File2) S +.01 I (READ-PERM-GROUP Ann File2) F -.55 &amp; (SAME-GROUP Ann File2) S +.05 &amp; (GROUP-READ-PERM-BIT-SET File2) F -.58 I (READ-PERM-SUPER-USER Ann) F -.02 &amp; (AUTHORIZED-SUPER-USER Ann) S +.97 &amp; (SUPER-USER-PASSWORD-GIVEN Ann) F -.02</note>
<abstract confidence="0.977563089385475">Relying on surprise scores alone, the most significant child of READ-PERM would be READ-PERM-USER, since its score is most strongly negative. However, since IS-CWNER has failed, a node which most users are powerless to change, it is clearly not helpful to choose READ-PERM-USER as the path to report. This is an example of the general rule that if we know that one child of an AND node is critical, we should include a rule to suppress that AND node whenever that child fails. Thus we attach the following rule to READ-PERM-USER: IF (FAILED-CHILD (IS-CWNEEI ?user ?file)) THEN (SUPPRESS-SCORE 0.8) In our current formulation, the numeric argument to SUPPRESS-SCORE gives the factor (i.e., percentage) 141 which the score should be reduced. The affect is to change READ-PERM-USER&apos;s score to -.17, prevents it selected. With READ-PERM-USER suppressed, the surprise scores would then select READ-PERM-GROUP, which is a reasonable choice, but probably not the best one. While the failure of IS-CWNER makes us less interested in READ-PERM-USER, the very surprising success of AUTHORIZED-SUPER-USER should draw the system&apos;s attention to the READ-PERM-SUPER-USER branch. We can arrange for this by attaching to READ-PERM-SUPER-USER a rule that states: IF (SUCCESSFUL-CHILD (AUTHORIZED-SUPER-USER ?user)) THEN (ENHANCE-SCORE 0.8) This rule would change READ-PERM-SUPER-USER&apos;s score -.02 to thus cause it to be the branch of READ-PERM selected for reporting. While our current rules are all in these two forms, either suppressing or enhancing a parent&apos;s score on the basis of a critical child&apos;s failure or success, the mechanism of special-purpose rules could be expanded to handle more complex forms of deduction. For example, it might be useful to add rules that calculate a criticality score for each node, working upward from preassigned scores assigned to the leaves. If the rules could access information about the state of the system, they could also use that in judging criticality, so that an UP-AND-RUNNING failure would be more critical if the device was expected to be down for a long time. Pith= problemLocalization strategies While our system depends on surprise scores and rules, an entire range of strategies is possible. The simplest strategy would be to hand-code the problem localization into the plans themselves by the ordering of the branches. At AND nodes, the children that are more critical would be listed first, while at OR nodes, the less critical, more hopeful, children would come first. In such a blocked tree, the first failed child could be below each node. A form of coded strategy is in force in any planner that stops exploring an AND node when a single child blocks; that effectively selects the first child tested as the significant failure in every case, the others are not even explored. coding is an alternative to surprise scores for providing an initial comparative ranking of the children at each node, but it also would need supplementing with a strategy that can take account of unusual situations, such as our special-purpose rules. It might be possible to improve the performance of a surprise score system without adding the complexity of special-purpose rules by using a formula that allows the surprising success or failure of a child to increase or decrease the chances of its parent being reported. While such a formula could perhaps do much of the work now done by special-purpose rules, it seems a harder approach to control, and one more likely to be sensitive to inaccuracies in the surprise scores themselves. ProperLover a final question identifying the proper level of detail for helpful responses. The strategies discussed so far have all focused on choosing which of multiple blocked children to report, so that they identify a path from the root to a leaf. Yet the leaves of the planning tree may well be too detailed to represent helpful responses. A selection strategy could report the containing the appropriate level of detail a given user. Modeling the expertise of a user and using that to select an appropriate description of the problem are significant problems in natural language generation which we have not addressed. IV RELATED APPLICATION AREAS While developed here in the context of a pragmatics planner, strategies for problem localization could have wide applicability. For instance, the MYCIN -like &amp;quot;How?&amp;quot; and &amp;quot;Why?&amp;quot; questions (Shortliffe, 1976) used in the explanation components of many expert systems already use either the already-built successful proof tree or the portion currently being explored as a source of explanations. Swartout (1983) adds extra knowledge that allows the system to justify its answers in the user&apos;s terms, but the user must still direct the exploration. An effective problem localization facility would allow the system to answer the question &amp;quot;Why not?&amp;quot;; that is, the user could ask why a certain goal was not substantiated, and the system would reply by identifying the surprising nodes that are likely to be significant causes of tae failure. Such not?&amp;quot; questions could be useful not only in explabut also in In the same way, since the execution of a PRO- LCG program can be seen as the exploration of and AND-OR tree, effective problem localization techniques could be useful in debugging the failed trees that result from incorrect logic programs. Another example is recovery processing in top-down parsing, such as using augmented transition networks (Woods, 1970). When an ATN fails to parse a sentence, the blocked parse tree is quite similar to a blocked planning tree. Weischedel (1983) suggests an approach to understanding illformed input that makes use of meta-rules to relax some of the constraints on ATN arcs that blocked the original parse. Recovery processing in that model requires searching the blocked parse tree for nodes to which meta-rules can be applied. A problem localization strategy could be used to sort the 142 list of blocked nodes, so that the most likely candidates would be tested first. The statistics of success ratios here would describe likely paths through the grammar. Nodes that exhibit surprising failure would be prime candidates for meta-rule processing. VII REFERENCES Carberry, M. Sandra. &amp;quot;Understanding Pragmatically Input.&amp;quot; proceedingsgf Interne- Conferencenn ComputationallAnnulnlinn, 1984. Before problem localization can be applied in these related areas, further work needs to be done to see how many of the heuristics and strategies that apply to problem localization in the planning context can be carried over. The larger and more complex trees of an ATN or PROLCG program may well developnent of further strategies. ever, the nature of the problem is such that even an imperfect result is likely to be useful. V IMPLEMENTATION DESCRIPTION The examples in this paper are taken frcm an Interlisp implementation of a planner which does checklng for a limited set of Unixrequests. The problem localization ponent uses a combination of surprise scores and special purpose rules, as described. The statistics were derived by running the planner on a test set of commands in a simulated Unix environment. VI CONCLUSIONS In planning-based pragmatics processing, problem localization addresses the largely untouched problem of providing helpful responses to requests unfulfillable in context. Problem localization in the planning context requires identifying the most hopeful and tractable choice at OR nodes, but the most critical and problematic one at AND nodes. Statistical surprise scores provide a cheap but effective base strategy for problem localization, and condition-action rules are an appropriate mechanism for adding further sophistication. Further work should address (1) applying recovery strategies to the localized problem, if any recovery is appropriate; (2) investigating other applications, such as expert systems, backward-chaining inference, and top-down parsing; and (3) exploring natural language generation to report a block at an appropriate level of detail.</abstract>
<author confidence="0.836047">Samuel J Nesnonsea Proma</author>
<note confidence="0.286043333333333">Natural LanauageData Query System. PhD. Dissertation, Computer and Information Science Dept., University of Pennsylvania, 1979.</note>
<title confidence="0.349734">Mays, Eric. &amp;quot;Correcting Misconceptions About Data Structure.&amp;quot; Proceedingssat the Conference2L</title>
<author confidence="0.363224">Daaaglan Societyfgr Dzsgutatiggal</author>
<affiliation confidence="0.952734">Intelligence.Victoria, British Columbia,</affiliation>
<address confidence="0.6453965">Canada, May 1980, 123-128. Mays, Eric. *Failures in Natural Language Systems:</address>
<note confidence="0.940173333333334">Applications to Data Base Query Systems.&amp;quot; szt theFlrat Annual National Conferencenn Intelligence(UJ.-8Q). Stanford, California, August 1980, 327-330. Sacerdoti, E. D. &apos;Planning in a Hierarchy of Spaces.&amp;quot; Intelligence5. (1974), 115-135. E. H. 5ase4 Medical Consultations:=IL (North-Holland, 1976). Sondbeimer, N. and R. M. Weischedel. &amp;quot;A Rule-Based to Ill-Formed Input.&amp;quot; the Conferencega Linguistic&amp;quot;,1980. Swartout, William R. &amp;quot;XPLAIN: A System for Creating and Explaining Expert Consulting Programs.&apos; IatelligenceU(1903), Weischedel, Ralph M. and Norman K. Sondbeimer. as a Processing Ill-Formed American Computational 9. (1983) , to Wilensky, Robert. &apos;Talking to UNIX in English: An of 13C.&apos; proftedingma 1.92. Conference0,,t Intelligence(AAAI-82), 103-106.</note>
<title confidence="0.948283">Woods, William A. *Transition Network Grammars Natural Language Analysis.&apos;</title>
<note confidence="0.420296">AO 13. 1970), 143</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Samuel J Kaplan</author>
</authors>
<title>C000erative Nesnonsea Prom a Portable Natural Lanauage Data Same Query System.</title>
<date>1979</date>
<tech>PhD. Dissertation,</tech>
<institution>Computer and Information Science Dept., University of Pennsylvania,</institution>
<contexts>
<context position="1438" citStr="Kaplan (1979)" startWordPosition="214" endWordPosition="215">pecial-purpose rules are the main strategies suggested to determine this. I PRAGMATIC OVERSHOOT AND PROBLEM LOCALIZATION Even if the syntactic and semantic content of a request is correct, 30 that a natural language front end can derive a coherent representation of its meaning, its pragmatic content or the structure of the underlying system may make any direct response to the request impossible or misleading. According to Sondheimer and Weischedel (Sondheimer, 1980), an input exhibits pragmatic overshoot if the representation of its meaning is beyond the capabilities of the underlying system. Kaplan (1979), Mays (1980a), and Carberry (1984) have each worked on strategies for dealing with particular classes of such pragmatic failures. This paper addresses the problem of identifying the most significant reason that a plan to achieve a user goal cannot be carried out. The approach to pragmatic failure taken in this paper is to use a planner to verify the presumptions in a request. The presumptions behind a request become the subgoals of a plan to fulfill the request. Using Mays&apos; (1980a) example, the query &amp;quot;Which faculty members take courses?&amp;quot; is here handled as an instance of an IDENTIFY-SET-MEMBE</context>
</contexts>
<marker>Kaplan, 1979</marker>
<rawString>Kaplan, Samuel J. C000erative Nesnonsea Prom a Portable Natural Lanauage Data Same Query System. PhD. Dissertation, Computer and Information Science Dept., University of Pennsylvania, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Mays</author>
</authors>
<title>Correcting Misconceptions About Data Base Structure.&amp;quot;</title>
<date>1980</date>
<booktitle>Proceedings sat the Conference 2L tta Daaaglan Society fgr Dzsgutatiggal Studies Intelligence.</booktitle>
<pages>123--128</pages>
<location>Victoria, British Columbia, Canada,</location>
<contexts>
<context position="1450" citStr="Mays (1980" startWordPosition="216" endWordPosition="217">rules are the main strategies suggested to determine this. I PRAGMATIC OVERSHOOT AND PROBLEM LOCALIZATION Even if the syntactic and semantic content of a request is correct, 30 that a natural language front end can derive a coherent representation of its meaning, its pragmatic content or the structure of the underlying system may make any direct response to the request impossible or misleading. According to Sondheimer and Weischedel (Sondheimer, 1980), an input exhibits pragmatic overshoot if the representation of its meaning is beyond the capabilities of the underlying system. Kaplan (1979), Mays (1980a), and Carberry (1984) have each worked on strategies for dealing with particular classes of such pragmatic failures. This paper addresses the problem of identifying the most significant reason that a plan to achieve a user goal cannot be carried out. The approach to pragmatic failure taken in this paper is to use a planner to verify the presumptions in a request. The presumptions behind a request become the subgoals of a plan to fulfill the request. Using Mays&apos; (1980a) example, the query &amp;quot;Which faculty members take courses?&amp;quot; is here handled as an instance of an IDENTIFY-SET-MEMBERS â€¢ This ma</context>
</contexts>
<marker>Mays, 1980</marker>
<rawString>Mays, Eric. &amp;quot;Correcting Misconceptions About Data Base Structure.&amp;quot; Proceedings sat the Conference 2L tta Daaaglan Society fgr Dzsgutatiggal Studies Intelligence. Victoria, British Columbia, Canada, May 1980, 123-128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Mays</author>
</authors>
<title>Failures in Natural Language Systems: Applications to Data Base Query Systems.&amp;quot;</title>
<date>1980</date>
<booktitle>Prsandigusa szt the Flrat Annual National Conference nn Artificial Intelligence (UJ.-8Q).</booktitle>
<pages>327--330</pages>
<location>Stanford, California,</location>
<contexts>
<context position="1450" citStr="Mays (1980" startWordPosition="216" endWordPosition="217">rules are the main strategies suggested to determine this. I PRAGMATIC OVERSHOOT AND PROBLEM LOCALIZATION Even if the syntactic and semantic content of a request is correct, 30 that a natural language front end can derive a coherent representation of its meaning, its pragmatic content or the structure of the underlying system may make any direct response to the request impossible or misleading. According to Sondheimer and Weischedel (Sondheimer, 1980), an input exhibits pragmatic overshoot if the representation of its meaning is beyond the capabilities of the underlying system. Kaplan (1979), Mays (1980a), and Carberry (1984) have each worked on strategies for dealing with particular classes of such pragmatic failures. This paper addresses the problem of identifying the most significant reason that a plan to achieve a user goal cannot be carried out. The approach to pragmatic failure taken in this paper is to use a planner to verify the presumptions in a request. The presumptions behind a request become the subgoals of a plan to fulfill the request. Using Mays&apos; (1980a) example, the query &amp;quot;Which faculty members take courses?&amp;quot; is here handled as an instance of an IDENTIFY-SET-MEMBERS â€¢ This ma</context>
</contexts>
<marker>Mays, 1980</marker>
<rawString>Mays, Eric. *Failures in Natural Language Systems: Applications to Data Base Query Systems.&amp;quot; Prsandigusa szt the Flrat Annual National Conference nn Artificial Intelligence (UJ.-8Q). Stanford, California, August 1980, 327-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E D Sacerdoti</author>
</authors>
<title>Planning in a Hierarchy of Abstraction Spaces.&amp;quot;</title>
<date>1974</date>
<journal>Artificial Intelligence</journal>
<volume>5</volume>
<pages>115--135</pages>
<contexts>
<context position="6999" citStr="Sacerdoti, 1974" startWordPosition="1115" endWordPosition="1116">should be reported, since it is least likely that the user can affect that node. If the READ-PERM failure were reported first, the user would waste time changing the read permission of a non-text file. Unix&apos;s actual behavior, which reports the first problem that it happens to discover in trying to execute the command, is often frustrating for exactly that reason. This heuristic of reporting the most serious failure at an AND node is closely related to ABSTRIP&apos;s use of &amp;quot;criticality&amp;quot; numbers to divide a planner into levels of abstraction, so that the most critical features are dealt with first (Sacerdoti, 1974). , The situation is different at OR nodes, where only a single child has to succeed. Here the most serious failure can safely be ignored, as long as some other branch can be repaired. Thus the most significant branch at an OR node should be the one the user is most likely to be able to affect. In our example, READ-PERM-USER should usually be reported rather than READ-PERM-SUPER-USER, if both have failed, since most users have more hope of changing the former than the latter. There is a duality here between the AND and OR node heuristics that is like the duality in the minimax evaluation of a </context>
</contexts>
<marker>Sacerdoti, 1974</marker>
<rawString>Sacerdoti, E. D. &apos;Planning in a Hierarchy of Abstraction Spaces.&amp;quot; Artificial Intelligence 5. (1974), 115-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Shortliffe</author>
</authors>
<date>1976</date>
<booktitle>Computer 5ase4 Medical Consultations: =IL (North-Holland,</booktitle>
<contexts>
<context position="18859" citStr="Shortliffe, 1976" startWordPosition="3057" endWordPosition="3058">. Yet the leaves of the planning tree may well be too detailed to represent helpful responses. A selection strategy could report the node containing the appropriate level of detail for a given user. Modeling the expertise of a user and using that to select an appropriate description of the problem are significant problems in natural language generation which we have not addressed. IV RELATED APPLICATION AREAS While developed here in the context of a pragmatics planner, strategies for problem localization could have wide applicability. For instance, the MYCIN -like &amp;quot;How?&amp;quot; and &amp;quot;Why?&amp;quot; questions (Shortliffe, 1976) used in the explanation components of many expert systems already use either the already-built successful proof tree or the portion currently being explored as a source of explanations. Swartout (1983) adds extra knowledge that allows the system to justify its answers in the user&apos;s terms, but the user must still direct the exploration. An effective problem localization facility would allow the system to answer the question &amp;quot;Why not?&amp;quot;; that is, the user could ask why a certain goal was not substantiated, and the system would reply by identifying the surprising nodes that are likely to be the s</context>
</contexts>
<marker>Shortliffe, 1976</marker>
<rawString>Shortliffe, E. H. Computer 5ase4 Medical Consultations: =IL (North-Holland, 1976).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Sondbeimer</author>
<author>R M Weischedel</author>
</authors>
<title>A Rule-Based Approach to Ill-Formed Input.&amp;quot; proceeding the ath International Conference ga Computational Linguistic&amp;quot;,</title>
<date>1980</date>
<marker>Sondbeimer, Weischedel, 1980</marker>
<rawString>Sondbeimer, N. and R. M. Weischedel. &amp;quot;A Rule-Based Approach to Ill-Formed Input.&amp;quot; proceeding the ath International Conference ga Computational Linguistic&amp;quot;, 1980.</rawString>
</citation>
<citation valid="false">
<authors>
<author>William R Swartout</author>
</authors>
<title>XPLAIN: A System for Creating and Explaining Expert Consulting Programs.&apos;</title>
<journal>Artificial Iatelligence</journal>
<volume>1903</volume>
<pages>285--325</pages>
<marker>Swartout, </marker>
<rawString>Swartout, William R. &amp;quot;XPLAIN: A System for Creating and Explaining Expert Consulting Programs.&apos; Artificial Iatelligence U(1903), 285-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph M Weischedel</author>
<author>Norman K Sondbeimer</author>
</authors>
<title>Meta-Rules as a Basis for Processing Ill-Formed Input.&apos;</title>
<date>1983</date>
<journal>American journal Computational Li=WI=</journal>
<volume>9</volume>
<note>to appear.</note>
<marker>Weischedel, Sondbeimer, 1983</marker>
<rawString>Weischedel, Ralph M. and Norman K. Sondbeimer. &amp;quot;Meta-Rules as a Basis for Processing Ill-Formed Input.&apos; American journal Computational Li=WI= 9. (1983) , to appear.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Robert Wilensky</author>
</authors>
<title>Talking to UNIX in English: An Overview of 13C.&apos; proftedingm a =ft 1.92.</title>
<booktitle>Nationa Conference 0,,t Artificial Intelligence (AAAI-82),</booktitle>
<pages>103--106</pages>
<marker>Wilensky, </marker>
<rawString>Wilensky, Robert. &apos;Talking to UNIX in English: An Overview of 13C.&apos; proftedingm a =ft 1.92. Nationa Conference 0,,t Artificial Intelligence (AAAI-82), 103-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Woods</author>
</authors>
<title>Transition Network Grammars for Natural Language Analysis.&apos; rawawagatuala a Ihft AO 13.</title>
<date>1970</date>
<pages>591--606</pages>
<contexts>
<context position="19938" citStr="Woods, 1970" startWordPosition="3235" endWordPosition="3236"> why a certain goal was not substantiated, and the system would reply by identifying the surprising nodes that are likely to be the significant causes of tae failure. Such &amp;quot;Why not?&amp;quot; questions could be useful not only in explanation but also in debugging. In the same way, since the execution of a PROLCG program can be seen as the exploration of and AND-OR tree, effective problem localization techniques could be useful in debugging the failed trees that result from incorrect logic programs. Another example is recovery processing in top-down parsing, such as using augmented transition networks (Woods, 1970). When an ATN fails to parse a sentence, the blocked parse tree is quite similar to a blocked planning tree. Weischedel (1983) suggests an approach to understanding illformed input that makes use of meta-rules to relax some of the constraints on ATN arcs that blocked the original parse. Recovery processing in that model requires searching the blocked parse tree for nodes to which meta-rules can be applied. A problem localization strategy could be used to sort the 142 list of blocked nodes, so that the most likely candidates would be tested first. The statistics of success ratios here would des</context>
</contexts>
<marker>Woods, 1970</marker>
<rawString>Woods, William A. *Transition Network Grammars for Natural Language Analysis.&apos; rawawagatuala a Ihft AO 13. (Oct. 1970), 591-606.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>