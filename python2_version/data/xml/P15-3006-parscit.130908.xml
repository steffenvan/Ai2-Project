<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026351">
<title confidence="0.984577">
Evaluation Dataset and System for Japanese Lexical Simplification
</title>
<author confidence="0.997495">
Tomoyuki Kajiwara
</author>
<affiliation confidence="0.979751666666667">
Department of Electrical Engineering
Nagaoka University of Technology
Nagaoka City, Niigata, Japan
</affiliation>
<email confidence="0.995369">
kajiwara@jnlp.org
</email>
<sectionHeader confidence="0.997347" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999927272727273">
We have constructed two research re-
sources of Japanese lexical simplification.
One is a simplification system that sup-
ports reading comprehension of a wide
range of readers, including children and
language learners. The other is a dataset
for evaluation that enables open discus-
sions with other systems. Both the sys-
tem and the dataset are made available
providing the first such resources for the
Japanese language.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999484363636364">
Lexical simplification is a technique that substi-
tutes a complex word or phrase in a sentence with
a simpler synonym. This technique supports the
reading comprehension of a wide range of read-
ers, including children (Belder and Moens, 2010;
Kajiwara et al., 2013) and language learners (Eom
et al., 2012; Moku et al., 2012).
The recent years have seen a great activity in
this field of inquiry, especially for English: At the
SemEval-2012 workshop, many systems were par-
ticipating in the English lexical simplification task
(Specia et al., 2012), for which also an evalua-
tion dataset was constructed. Other resources for
statistical learning of simplified rules were built,
drawing on the Simple English Wikipedia (Zhu et
al., 2010; Horn et al., 2014), e.g. several paral-
lel corpora aligning standard and simple English
(Zhu et al., 2010; Kauchak, 2013)1,2 and eval-
uation datasets (Specia et al., 2012; Belder and
Moens, 2012)3,4.
On the other hand, there have been no published
resources on Japanese lexical simplification so far.
</bodyText>
<footnote confidence="0.99994625">
1http://www.cs.pomona.edu/˜dkauchak/simplification/
2https://www.ukp.tu-darmstadt.de/data/
3http://www.cs.york.ac.uk/semeval-2012/task1/
4http://people.cs.kuleuven.be/˜jan.debelder/lseval.zip
</footnote>
<author confidence="0.822469">
Kazuhide Yamamoto
</author>
<affiliation confidence="0.990517333333333">
Department of Electrical Engineering
Nagaoka University of Technology
Nagaoka City, Niigata, Japan
</affiliation>
<email confidence="0.973783">
yamamoto@jnlp.org
</email>
<bodyText confidence="0.964190333333333">
Such resources had to be created and made pub-
lic, for the sake of readers in need of reading as-
sistance, as well as to accelerate the research on
this topic. Therefore, we have constructed and
published a Japanese lexical simplification system
(SNOW S3) and a dataset for evaluation of the sys-
tem (SNOW E4). These resources are available at
the following URL:
http://www.jnlp.org/SNOW
</bodyText>
<sectionHeader confidence="0.997257" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999713333333333">
Two datasets for evaluation of English lexical
simplification have been published. Both were
constructed by transforming a lexical substitution
dataset, which was constructed in an English lex-
ical substitution task of SemEval-2007 workshop
(McCarthy and Navigli, 2007).
</bodyText>
<subsectionHeader confidence="0.937995">
2.1 McCarthy Substitution Dataset
</subsectionHeader>
<bodyText confidence="0.990610190476191">
The English lexical substitution task of SemEval-
2007 requires that the system finds words or
phrases that one can substitute for the given target
word in the given content. These target words are
content words, and their details are shown in Table
1. These contexts are selected from the English In-
ternet Corpus, which is a balanced and web-based
corpus of English (Sharoff, 2006). This dataset
consists of 2,010 sentences, 201 target words each
with 10 sentences as contexts. Five annotators
who are native English speakers proposed at most
three appropriate substitutions for each of the tar-
get words within their contexts. When an appro-
priate paraphrasable word did not occur, the anno-
tator propose paraphrasable phrases.
An example from this dataset is provided be-
low. As a paraphrase of the adjective “bright”
in this context, three annotators proposed “intelli-
gent”, another three annotators proposed “clever”,
and one annotator proposed “smart”.
Context: During the siege, G. Robertson had ap-
</bodyText>
<page confidence="0.993892">
35
</page>
<note confidence="0.934978">
Proceedings of the ACL-IJCNLP 2015 Student Research Workshop, pages 35–40,
Beijing, China, July 28, 2015. c�2015 Association for Computational Linguistics
</note>
<table confidence="0.99965875">
Dataset Sentence Noun(%) Verb(%) Adjective(%) Adverb(%)
McCarthy / Specia 2,010 580 (28.9) 520 (25.9) 560 (27.9) 350 (17.4)
De Belder 430 100 (23.3) 60 (14.0) 160 (37.2) 110 (25.6)
Ours (SNOW E4) 2,330 630 (27.0) 720 (30.9) 500 (21.5) 480 (20.6)
</table>
<tableCaption confidence="0.999904">
Table 1: Size of the dataset
</tableCaption>
<bodyText confidence="0.98421325">
pointed Shuja-ul-Mulk, who was a bright boy
only 12 years old and the youngest surviving
son of Aman-ul-Mulk, as the ruler of Chitral.
Gold-Standard: intelligent 3; clever 3; smart 1;
</bodyText>
<subsectionHeader confidence="0.998629">
2.2 Specia Simplification Dataset
</subsectionHeader>
<bodyText confidence="0.999984148148148">
The English lexical simplification task of
SemEval-2012 requires that the system ranks the
target word and its several paraphrases according
to how simple they are in the context. Simple
means that the word is easy to understand for
many people, including children and non-natives.
This dataset was annotated by fluent but non-
native English speakers (college freshmen). The
Trial dataset used four annotators, and the Test
dataset used five annotators. These annotators
ranked target words and their several paraphrases
according to how simple they were in contexts
from the lexical substitution dataset described in
Section 2.1. Next, the ranks received from each
annotator were integrated into the dataset. Finally,
the gold-standard annotations were generated by
averaging the annotations from all annotators.
An example from this dataset is provided below.
When the following ranking was obtained from
four annotators in a context, the ranks of “clear”
were 1, 2, 1, 4, and the average rank was 2. Sim-
ilarly, the average rank of each word calculated.
Thus, the rank of “light” is 3.25, that of “bright” is
2.5, that of “luminous” is 4, and that of “well-lit”
is 3.25. The final integrated ranking is obtained
by rearranging the average ranks of these words in
the ascending order, as shown below.
</bodyText>
<listItem confidence="0.986536">
1: {clear}{light}{bright}{luminous}{well-lit}
2: {well-lit}{clear}{light}{bright}{luminous}
3: {clear}{bright}{light}{luminous}{well-lit}
4: {bright}{well-lit}{luminous}{clear}{light}
Gold: {clear}{bright}{light,well-lit}{luminous}
</listItem>
<subsectionHeader confidence="0.999703">
2.3 De Belder Simplification Dataset
</subsectionHeader>
<bodyText confidence="0.999975111111111">
De Belder and Moens (2012) also created a simpli-
fication dataset. They deleted enough simple tar-
get words included in the Basic English combined
word list5 from the lexical substitution dataset de-
scribed in the Section 2.1 at first. As a result
of deleting, the number of target words narrowed
down from 201 to 43. Five annotators ranked these
43 target words and their several paraphrases ac-
cording to how simple they were in the context.
These annotators were recruited using the Ama-
zon Mechanical Turk6. De Belder and Moens re-
quested annotators who were located in the U.S.
and had completed at least 95% of their previous
assignments correctly.
In the end, the rank from each annotator was in-
tegrated into the dataset. In this dataset, the noisy
channel model was used in order to take account
of the rank and reliability of each annotator.
</bodyText>
<sectionHeader confidence="0.7951" genericHeader="method">
3 Constructing Japanese Lexical
Substitution Dataset
</sectionHeader>
<bodyText confidence="0.99999">
We have constructed a dataset for evaluation of
Japanese lexical simplification. First, a Japanese
lexical substitution dataset was constructed using
the same method as McCarthy and Navigli (2007).
</bodyText>
<subsectionHeader confidence="0.999812">
3.1 Selecting Target Words
</subsectionHeader>
<bodyText confidence="0.999989666666667">
We define target words as the list of content
words (nouns, verbs, adjectives, and adverbs) that
are common to two Japanese word dictionaries
(IPADIC-2.7.07 and JUMANDIC-7.08) in order to
select the standard target words at first. Next, the
following words were deleted from these words.
</bodyText>
<listItem confidence="0.999975">
• Words that are already simple enough
• Words that have no substitutions
• Words that are a part of a compound word
• Words that are a part of an idiomatic phrase
• Low frequency words
</listItem>
<bodyText confidence="0.99606775">
We define simple words as words in Basic Vo-
cabulary to Learn (Kai and Matsukawa, 2002),
which is a receptive vocabulary for elementary
school students. Words that are not registered
</bodyText>
<footnote confidence="0.9992938">
5http://simple.wikipedia.org/wiki/Wikipedia:
Basic English combined wordlist
6https://www.mturk.com
7http://sourceforge.jp/projects/ipadic/releases/24435/
8http://nlp.ist.i.kyoto-u.ac.jp/index.php?JUMAN
</footnote>
<page confidence="0.965968">
36
</page>
<equation confidence="0.9963348">
P1\P2
EP1,P22P P1[P2 (1)
IPI
Ej(ranki(wj) — ranki)(rankave(wj) — rankave) (2)
qEj(ranki(wj) — ranki)2 Ej(rankave(wj) — rankave)2
</equation>
<bodyText confidence="0.999914">
in SNOW D2 (Yamamoto and Yoshikura, 2013)
are defined as words that have no substitutions.
Low frequency words are defined as words that
occurred less than 10 times over the 15 years in
Japanese newspapers9.
In the end, 250 words (nouns and verbs 75 each,
adjectives and adverbs 50 each) were chosen as a
target words at random.
</bodyText>
<subsectionHeader confidence="0.999902">
3.2 Providing Paraphrases
</subsectionHeader>
<bodyText confidence="0.999955416666667">
An annotator provided several paraphrases for
each target word in 10 contexts. These contexts
were randomly selected from newspaper article.
When providing a paraphrase, an annotator could
refer to a dictionary but was not supposed to ask
the other annotators for an opinion. When an an-
notator could not think of a paraphrase, they were
permitted to supply no entry.
Five annotators for every fifty sentences were
recruited using crowdsourcing service10. On av-
erage, each of these annotators contributed 5.38
paraphrases.
</bodyText>
<subsectionHeader confidence="0.997066">
3.3 Merging All Annotations
</subsectionHeader>
<bodyText confidence="0.999997777777778">
Each annotator’s result was evaluated, and all the
results were merged into one dataset. Five new
annotators for every fifty sentences were recruited
through the crowdsourcing service. We adopted
the paraphrases that more than three annotators
rated appropriate by answering the question, “Is
this paraphrase appropriate?” in the affirmative.
When an annotator rated a paraphrase as inappro-
priate, they were shown the following two criteria.
</bodyText>
<listItem confidence="0.983356166666667">
1. A paraphrase is inappropriate if the sentence
becomes unnatural as a result of the substi-
tution of this paraphrase for the target word.
2. A paraphrase is inappropriate if the meaning of
the sentence changes as a result of the substi-
tution of this paraphrase for the target word.
</listItem>
<bodyText confidence="0.749414">
An average of 4.50 lexical paraphrases were ac-
cepted. However, 170 sentences (17 target words)
that all paraphrases have been evaluated to be in-
appropriate were discarded.
</bodyText>
<footnote confidence="0.998605">
9http://www.nikkeibookvideo.com/kijidb/
10http://www.lancers.jp
</footnote>
<bodyText confidence="0.9990635">
Since we have sets of paraphrases for each tar-
get word and annotator, pairwise agreement was
calculated between each pair of sets (p1, p2 E P)
from each possible pairing (P) according to the
Equation (1), following previous research (Mc-
Carthy and Navigli, 2007). Inter-annotator agree-
ment is 66.4%.
An English translation of an example from the
dataset is provided below. As a paraphrase of
the noun “appeal” in this context, one annotator
proposed “advocate”, another annotator proposed
“exert”, and three annotators proposed “promote”.
Context: You can appeal for proud batting power.
Gold-Standard: advocate 1; promote 3; exert 1;
</bodyText>
<sectionHeader confidence="0.992857" genericHeader="method">
4 Transforming into Lexical
Simplification Dataset
</sectionHeader>
<subsectionHeader confidence="0.999382">
4.1 Ranking Paraphrases
</subsectionHeader>
<bodyText confidence="0.99995985">
These target words and their several paraphrases
were ranked according to how simple they were
in the context from the dataset that we built (as
discussed in Section 3) in order to transform it into
a dataset for evaluation of lexical simplification.
The same annotators as those mentioned in section
3.3 worked on this task.
Finally, the total number of annotators is 500.
Some 250 annotators provided paraphrases, others
evaluated and ranked these paraphrases.
Inter-annotator agreement was calculated by
Spearman’s rank correlation coefficient, follow-
ing previous research (Belder and Moens, 2012).
Spearman’s rank correlation coefficient is defined
as in the Equation (2), where ranki is the average
rank of the words given by annotator i. To extend
this equation to one annotator versus other anno-
tators, we define the rank assigned by the rankave
to be the average of the ranks given by the other
annotators. This agreement is 33.2%11.
</bodyText>
<subsectionHeader confidence="0.983226">
4.2 Merging All Rankings
</subsectionHeader>
<bodyText confidence="0.998461">
All annotators’ work results were merged into one
dataset. The rank of each word was decided based
</bodyText>
<footnote confidence="0.928642333333333">
11While this score is apparently low, the highly subjec-
tive nature of the annotation task must be taken into account
(Specia et al., 2012).
</footnote>
<page confidence="0.996124">
37
</page>
<listItem confidence="0.6081446">
all % noun % verb % adj % adv %
1. # context pairs 10,485 - 2,835 - 3,240 - 2,250 - 2,160 -
2. # 1. with same list 1,593 15 789 28 348 11 168 7 288 13
3. # 2. with different rankings 948 60 344 44 262 75 129 77 213 74
4. # 3. with different top word 463 49 214 62 130 50 51 40 68 32
</listItem>
<tableCaption confidence="0.993522">
Table 2: Context dependency ratio
</tableCaption>
<bodyText confidence="0.999953052631579">
on the average of the rank from each annota-
tor, following the previous research (Specia et al.,
2012). The same rank is assigned to words that
have the same average. In this study, the same
annotator performed both the evaluation of para-
phrases and their ranking. Therefore, any word
that an annotator judged as an inappropriate para-
phrase was not ranked. The minimum rank is as-
signed to these words that were not ranked at the
time of the calculation of the average rank.
An English translation of an example from the
dataset is provided below. When the following
ranking was obtained from five annotators in a
context, the ranks of “appeal” were 1, 2, 4, 2, 2,
and the average rank was 2.2. Similarly, the aver-
age rank of “promote” is 2.2, that of “advocate”
is 2.6, and that of “exert” is 3. The final inte-
grated ranking is obtained by rearranging the av-
erage ranks of these words in the ascending order.
</bodyText>
<listItem confidence="0.9781345">
1: {appeal}{promote}{advocate}{exert}
2: {advocate}{appeal}{promote}{exert}
3: {promote}{exert}{advocate} #appeal
4: {exert}{appeal}{advocate}{promote}
5: {promote}{appeal}{advocate} #exert
Gold: {appeal, promote}{advocate}{exert}
</listItem>
<subsectionHeader confidence="0.995467">
4.3 Properties of the dataset
</subsectionHeader>
<bodyText confidence="0.999727125">
In 1,616 (69.4%) of the sentences, a target word
can be replaced by one or more simpler words. In
420 (18.0%) of the cases, there is also one or more
words that are equally complex. In 1,945 (83.5%)
of the cases, there are words that are more com-
plex. The average number of substitutions is 5.50.
The average number of levels of difficulty is 4.94.
Table 2 shows how the relative simplicity of the
target words and their paraphrases is context de-
pendent. Only 15.2% of all context-pairs which
share the target word have the same list of para-
phrases. This shows that the meaning of many tar-
get words changed slightly in different contexts.
In addition, 59.5% of combinations with the same
list of paraphrases have different ranks of diffi-
culty. This shows that the difficulty of a word
</bodyText>
<figureCaption confidence="0.994294">
Figure 1: Outline of lexical simplification system
</figureCaption>
<bodyText confidence="0.95738">
also changes slightly in different contexts. Among
these, 48.8% is even different in the simplest word.
</bodyText>
<sectionHeader confidence="0.900552" genericHeader="method">
5 Constructing Japanese Lexical
Simplification System
</sectionHeader>
<bodyText confidence="0.999987428571429">
We have also constructed a lexical simplification
system using four typical mechanisms of lexical
simplification (Shardlow, 2014) shown in Figure1.
We expect the standard system to be used as a
baseline of Japanese lexical simplification. We
also expect that the system can support the read-
ing comprehension of a wide range of readers.
</bodyText>
<subsectionHeader confidence="0.998491">
5.1 Identification of Complex Words
</subsectionHeader>
<bodyText confidence="0.999988307692308">
An input sentence is first analyzed by the Japanese
morphological analyzers MeCab-0.993 (Kudo et
al., 2004)12 and IPADIC-2.7.0, and content words
that are not included in the list of simple words
are extracted as complex words. These complex
words are not part of a compound word or an id-
iomatic phrase.
In this study, simple words are defined as
the Basic Vocabulary to Learn; compound words
are defined as the lists of entries from Japanese
Wikipedia13 and the Compound Verb Lexicon14;
finally, idiomatic phrases are defined as the list of
Japanese idiomatic phrases made by Sato (2007).
</bodyText>
<subsectionHeader confidence="0.999825">
5.2 Substitution Generation
</subsectionHeader>
<bodyText confidence="0.9959442">
Several paraphrases are enumerated as candidates
of a simple word for each complex word. These
lexical paraphrases were selected from several
Japanese lexical paraphrasing databases such as
SNOW D2 (Yamamoto and Yoshikura, 2013),
</bodyText>
<footnote confidence="0.999913">
12https://code.google.com/p/mecab/
13http://dumps.wikimedia.org/jawiki/
14http://vvlexicon.ninjal.ac.jp/
</footnote>
<page confidence="0.995955">
38
</page>
<table confidence="0.959565">
Precision Recall F-measure
0.89 0.08 0.15
</table>
<tableCaption confidence="0.904432">
Table 3: Performance of the system
</tableCaption>
<table confidence="0.9888545">
Noun Verb Adjective Adverb
62 65 3 0
</table>
<tableCaption confidence="0.998729">
Table 4: POS of the simplified target words
</tableCaption>
<bodyText confidence="0.927397">
Japanese WordNet Synonyms Database15, Verb
Entailment Database16, and Case Base for Basic
Semantic Relations16, following previous research
(Kajiwara and Yamamoto, 2014).
</bodyText>
<subsectionHeader confidence="0.998939">
5.3 Word Sense Disambiguation
</subsectionHeader>
<bodyText confidence="0.999985428571428">
If, given the context of the sentence, the list of
suggested paraphrases for a complex word con-
tains words that are improper in this context, these
improper paraphrases are removed from the list.
An input sentence receives a predicate-argument
structure analysis using the Japanese predicate-
argument structure analyzer SynCha-0.3 (Iida and
Poesio, 2011)17, and the predicate (verb or adjec-
tive), the arguments (nouns) and grammatical rela-
tions (case makers such as “ga (subject)”, “o (ob-
ject)”, “ni (indirect object)”) are extracted as a set
of the form {predicate, relation, argument}.
Either the predicate or one of the arguments is
identified as a complex word. A list is of candidate
substitutions is generated for that word, followed
by a list of sets of the form {predicate, relation,
argument}, where the candidate substitutions are
used instead of the complex word (so there will be
as many of these sets as there are candidate sub-
stitutions). These new sets are checked against the
Kyoto University Case Frame18. If the set is found
there, the candidate substitution counts as a legiti-
mate substitution; if the set is not found, the candi-
date substitution is not counted as a legitimate sub-
stitution. Kyoto University Case Frame is the list
of predicate and argument pairs that have a case
relationship, and it is built automatically (Kawa-
hara and Kurohashi, 2006) from Web texts.
</bodyText>
<subsectionHeader confidence="0.998769">
5.4 Synonym Ranking
</subsectionHeader>
<bodyText confidence="0.999930857142857">
All candidate words are given a degree of diffi-
culty. The simplest word is used to replace the
complex word in the input sentence, and the out-
put sentence is generated.
In this study, Lexical Properties of Japanese
(Amano and Kondo, 2000) is used for determin-
ing the degree of difficulty.
</bodyText>
<footnote confidence="0.999887">
15http://nlpwww.nict.go.jp/wn-ja/jpn/downloads.html
16https://alaginrc.nict.go.jp/resources/nict-resource/
17http://www.cl.cs.titech.ac.jp/ ryu-i/syncha/
18http://www.gsk.or.jp/catalog/gsk2008-b/
</footnote>
<subsectionHeader confidence="0.93527">
5.5 Evaluation of the System by the Dataset
</subsectionHeader>
<bodyText confidence="0.999947739130435">
The performance of the lexical simplification sys-
tem that was discussed in this section is estimated
using the evaluation dataset that was constructed
as discussed in Section 4. The performance of the
system is shown in Table 3. In 146 sentences,
the system converted a target word into another
word; in 130 sentences, that output word was sim-
pler than the target word defined by the evaluation
dataset appropriately. In addition, the system con-
verted 652 words in total, but only 146 words of
these were the target words.
The details as to the parts of speech of the target
words that got simplified appropriately are shown
in Table 4. The system simplifies only the pred-
icates and arguments extracted by the predicate-
argument structure analysis. However, adverbs are
not simplified since they are included in neither
predicates nor arguments. In addition, an adjective
may become a predicate, but it may also become
part of a noun phrase by modifying a noun. The
system simplifies only predicate adjectives.
An English translation of an example of several
system outputs is provided below.
</bodyText>
<listItem confidence="0.9895725">
• It is {distributed –&gt; dealt} to a {caller –&gt;
visitor} from foreign countries.
• {Principal –&gt; President} Takagi of the bank
presented an idea.
</listItem>
<sectionHeader confidence="0.99764" genericHeader="method">
6 Final Remarks
</sectionHeader>
<bodyText confidence="0.999837785714286">
We built a Japanese lexical simplification system
and a dataset for evaluation of Japanese lexical
simplification. Subsequently, we have published
these resources on the Web.
The system can support the reading comprehen-
sion of a wide range of readers, including children
and language learners. Since we have developed a
standard system, we expect the system to be used
as a baseline system of lexical simplification.
Furthermore, the dataset enables us to figure out
system performance. This solves the problems of
cost and reproducibility associated with the con-
ventional manual evaluation and accelerates re-
search on this topic.
</bodyText>
<page confidence="0.999124">
39
</page>
<sectionHeader confidence="0.996096" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999472163043478">
Shigeaki Amano and Kimihisa Kondo. 2000. On the
ntt psycholinguistic databases ”lexical properties of
japanese”. Journal of the Phonetic Society of Japan,
4(2):44–50.
Jan De Belder and Marie-Francine Moens. 2010. Text
simplification for children. In Proceedings of the SI-
GIR Workshop on Accessible Search Systems, pages
19–26.
Jan De Belder and Marie-Francine Moens. 2012. A
dataset for the evaluation of lexical simplification.
In Proceedings of the 13th International Conference
on Computational Linguistics and Intelligent Text
Processing (CICLing-2012), pages 426–437.
Soojeong Eom, Markus Dickinson, and Rebecca
Sachs. 2012. Sense-specific lexical information for
reading assistance. In Proceedings of the Seventh
Workshop on Building Educational Applications Us-
ing NLP, pages 316–325.
Colby Horn, Cathryn Manduca, and David Kauchak.
2014. Learning a lexical simplifier using wikipedia.
In Proceedings of the 52th Annual Meeting of the
Associatioin for Computational Linguistics, pages
458–463.
Ryu Iida and Massimo Poesio. 2011. A cross-lingual
ilp solution to zero anaphora resolution. The 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 804–813.
Mutsuro Kai and Toshihiro Matsukawa. 2002. Method
of Vocabulary Teaching: Vocabulary Table version.
Mitsumura Tosho Publishing Co., Ltd.
Tomoyuki Kajiwara and Kazuhide Yamamoto. 2014.
Qualitative evaluation of available japanese re-
sources for lexical paraphrasing. IEICE Technical
Report, NLC2014-37, 114(366):43–48.
Tomoyuki Kajiwara, Hiroshi Matsumoto, and
Kazuhide Yamamoto. 2013. Selecting proper
lexical paraphrase for children. In Proceedings of
the 25th Conference on Computational Linguistics
and Speech Processing, pages 59–73.
David Kauchak. 2013. Improving text simplification
language modeling using unsimplified text data. In
Proceedings of the 51th Annual Meeting of the Asso-
ciatioin for Computational Linguistics, pages 1537–
1546.
Daisuke Kawahara and Sadao Kurohashi. 2006. A
fully-lexicalized probabilistic model for japanese
syntactic and case structure analysis. In Proceedings
of the Human Language Technology Conference of
the North American Chapter of the Association for
Computational Linguistics, pages 176–183.
Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.
2004. Applying conditional random fields to
japanese morphological analysis. Proceedings of
the Conference on Empirical Methods in Natural
Language Processing, pages 230–237.
Diana McCarthy and Roberto Navigli. 2007. Semeval-
2007 task10: English lexical substitution task. In
Proceedings of the 4th International Workshop on
Semantic Evaluations (SemEval-2007), pages 48–
53.
Manami Moku, Kazuhide Yamamoto, and Ai Makabi.
2012. Automatic easy japanese translation for infor-
mation accessibility of foreigners. In Proceedings of
the Workshop on Speech and Language Processing
Tools in Education, pages 85–90.
Satoshi Sato. 2007. Compilation of a comparative list
of basic japanese idioms from five sources. The Spe-
cial Interest Group Technical Reports of IPSJ, 2007-
NL-178, pages 1–6.
Matthew Shardlow. 2014. A survey of automated text
simplification. International Journal of Advanced
Computer Science and Applications, Special Issue
on Natural Language Processing, pages 58–70.
Serge Sharoff. 2006. Open-source corpora: Using the
net to fish for linguistic data. International Journal
of Corpus Linguistics, 11(4), pages 435–462.
Lucia Specia, Sujay Kumar Jauhar, and Rada Mihalcea.
2012. Semeval-2012 task 1: English lexical sim-
plification. In Proceedings of the 6th International
Workshop on Semantic Evaluation (SemEval-2012),
pages 347–355.
Kazuhide Yamamoto and Kotaro Yoshikura. 2013.
Manual construction of lexical paraphrase dictio-
nary of japanese verbs, adjectives, and adverbs. In
Proceedings of 19th Annual Meeting of Association
for Natural Language Processing, pages 276–279.
Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.
2010. A monolingual tree-based translation model
for sentence simplification. In Proceedings of the
23rd International Conference on Computational
Linguistics, pages 1353–1361.
</reference>
<page confidence="0.998632">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.463451">
<title confidence="0.999947">Evaluation Dataset and System for Japanese Lexical Simplification</title>
<author confidence="0.977213">Tomoyuki</author>
<affiliation confidence="0.841591333333333">Department of Electrical Nagaoka University of Nagaoka City, Niigata,</affiliation>
<email confidence="0.99809">kajiwara@jnlp.org</email>
<abstract confidence="0.991968833333333">We have constructed two research resources of Japanese lexical simplification. One is a simplification system that supports reading comprehension of a wide range of readers, including children and language learners. The other is a dataset for evaluation that enables open discussions with other systems. Both the system and the dataset are made available providing the first such resources for the Japanese language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shigeaki Amano</author>
<author>Kimihisa Kondo</author>
</authors>
<title>On the ntt psycholinguistic databases ”lexical properties of japanese”.</title>
<date>2000</date>
<journal>Journal of the Phonetic Society of Japan,</journal>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="17638" citStr="Amano and Kondo, 2000" startWordPosition="2733" endWordPosition="2736">he set is found there, the candidate substitution counts as a legitimate substitution; if the set is not found, the candidate substitution is not counted as a legitimate substitution. Kyoto University Case Frame is the list of predicate and argument pairs that have a case relationship, and it is built automatically (Kawahara and Kurohashi, 2006) from Web texts. 5.4 Synonym Ranking All candidate words are given a degree of difficulty. The simplest word is used to replace the complex word in the input sentence, and the output sentence is generated. In this study, Lexical Properties of Japanese (Amano and Kondo, 2000) is used for determining the degree of difficulty. 15http://nlpwww.nict.go.jp/wn-ja/jpn/downloads.html 16https://alaginrc.nict.go.jp/resources/nict-resource/ 17http://www.cl.cs.titech.ac.jp/ ryu-i/syncha/ 18http://www.gsk.or.jp/catalog/gsk2008-b/ 5.5 Evaluation of the System by the Dataset The performance of the lexical simplification system that was discussed in this section is estimated using the evaluation dataset that was constructed as discussed in Section 4. The performance of the system is shown in Table 3. In 146 sentences, the system converted a target word into another word; in 130 s</context>
</contexts>
<marker>Amano, Kondo, 2000</marker>
<rawString>Shigeaki Amano and Kimihisa Kondo. 2000. On the ntt psycholinguistic databases ”lexical properties of japanese”. Journal of the Phonetic Society of Japan, 4(2):44–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan De Belder</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Text simplification for children.</title>
<date>2010</date>
<booktitle>In Proceedings of the SIGIR Workshop on Accessible Search Systems,</booktitle>
<pages>pages</pages>
<marker>De Belder, Moens, 2010</marker>
<rawString>Jan De Belder and Marie-Francine Moens. 2010. Text simplification for children. In Proceedings of the SIGIR Workshop on Accessible Search Systems, pages 19–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan De Belder</author>
<author>Marie-Francine Moens</author>
</authors>
<title>A dataset for the evaluation of lexical simplification.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics and Intelligent Text Processing (CICLing-2012),</booktitle>
<pages>426--437</pages>
<marker>De Belder, Moens, 2012</marker>
<rawString>Jan De Belder and Marie-Francine Moens. 2012. A dataset for the evaluation of lexical simplification. In Proceedings of the 13th International Conference on Computational Linguistics and Intelligent Text Processing (CICLing-2012), pages 426–437.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soojeong Eom</author>
<author>Markus Dickinson</author>
<author>Rebecca Sachs</author>
</authors>
<title>Sense-specific lexical information for reading assistance.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Building Educational Applications Using NLP,</booktitle>
<pages>316--325</pages>
<contexts>
<context position="944" citStr="Eom et al., 2012" startWordPosition="138" endWordPosition="141">ports reading comprehension of a wide range of readers, including children and language learners. The other is a dataset for evaluation that enables open discussions with other systems. Both the system and the dataset are made available providing the first such resources for the Japanese language. 1 Introduction Lexical simplification is a technique that substitutes a complex word or phrase in a sentence with a simpler synonym. This technique supports the reading comprehension of a wide range of readers, including children (Belder and Moens, 2010; Kajiwara et al., 2013) and language learners (Eom et al., 2012; Moku et al., 2012). The recent years have seen a great activity in this field of inquiry, especially for English: At the SemEval-2012 workshop, many systems were participating in the English lexical simplification task (Specia et al., 2012), for which also an evaluation dataset was constructed. Other resources for statistical learning of simplified rules were built, drawing on the Simple English Wikipedia (Zhu et al., 2010; Horn et al., 2014), e.g. several parallel corpora aligning standard and simple English (Zhu et al., 2010; Kauchak, 2013)1,2 and evaluation datasets (Specia et al., 2012; </context>
</contexts>
<marker>Eom, Dickinson, Sachs, 2012</marker>
<rawString>Soojeong Eom, Markus Dickinson, and Rebecca Sachs. 2012. Sense-specific lexical information for reading assistance. In Proceedings of the Seventh Workshop on Building Educational Applications Using NLP, pages 316–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colby Horn</author>
<author>Cathryn Manduca</author>
<author>David Kauchak</author>
</authors>
<title>Learning a lexical simplifier using wikipedia.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52th Annual Meeting of the Associatioin for Computational Linguistics,</booktitle>
<pages>458--463</pages>
<contexts>
<context position="1392" citStr="Horn et al., 2014" startWordPosition="210" endWordPosition="213"> supports the reading comprehension of a wide range of readers, including children (Belder and Moens, 2010; Kajiwara et al., 2013) and language learners (Eom et al., 2012; Moku et al., 2012). The recent years have seen a great activity in this field of inquiry, especially for English: At the SemEval-2012 workshop, many systems were participating in the English lexical simplification task (Specia et al., 2012), for which also an evaluation dataset was constructed. Other resources for statistical learning of simplified rules were built, drawing on the Simple English Wikipedia (Zhu et al., 2010; Horn et al., 2014), e.g. several parallel corpora aligning standard and simple English (Zhu et al., 2010; Kauchak, 2013)1,2 and evaluation datasets (Specia et al., 2012; Belder and Moens, 2012)3,4. On the other hand, there have been no published resources on Japanese lexical simplification so far. 1http://www.cs.pomona.edu/˜dkauchak/simplification/ 2https://www.ukp.tu-darmstadt.de/data/ 3http://www.cs.york.ac.uk/semeval-2012/task1/ 4http://people.cs.kuleuven.be/˜jan.debelder/lseval.zip Kazuhide Yamamoto Department of Electrical Engineering Nagaoka University of Technology Nagaoka City, Niigata, Japan yamamoto@j</context>
</contexts>
<marker>Horn, Manduca, Kauchak, 2014</marker>
<rawString>Colby Horn, Cathryn Manduca, and David Kauchak. 2014. Learning a lexical simplifier using wikipedia. In Proceedings of the 52th Annual Meeting of the Associatioin for Computational Linguistics, pages 458–463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Massimo Poesio</author>
</authors>
<title>A cross-lingual ilp solution to zero anaphora resolution. The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</title>
<date>2011</date>
<pages>804--813</pages>
<contexts>
<context position="16343" citStr="Iida and Poesio, 2011" startWordPosition="2514" endWordPosition="2517">ective Adverb 62 65 3 0 Table 4: POS of the simplified target words Japanese WordNet Synonyms Database15, Verb Entailment Database16, and Case Base for Basic Semantic Relations16, following previous research (Kajiwara and Yamamoto, 2014). 5.3 Word Sense Disambiguation If, given the context of the sentence, the list of suggested paraphrases for a complex word contains words that are improper in this context, these improper paraphrases are removed from the list. An input sentence receives a predicate-argument structure analysis using the Japanese predicateargument structure analyzer SynCha-0.3 (Iida and Poesio, 2011)17, and the predicate (verb or adjective), the arguments (nouns) and grammatical relations (case makers such as “ga (subject)”, “o (object)”, “ni (indirect object)”) are extracted as a set of the form {predicate, relation, argument}. Either the predicate or one of the arguments is identified as a complex word. A list is of candidate substitutions is generated for that word, followed by a list of sets of the form {predicate, relation, argument}, where the candidate substitutions are used instead of the complex word (so there will be as many of these sets as there are candidate substitutions). T</context>
</contexts>
<marker>Iida, Poesio, 2011</marker>
<rawString>Ryu Iida and Massimo Poesio. 2011. A cross-lingual ilp solution to zero anaphora resolution. The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 804–813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mutsuro Kai</author>
<author>Toshihiro Matsukawa</author>
</authors>
<title>Method of Vocabulary Teaching: Vocabulary Table version. Mitsumura Tosho</title>
<date>2002</date>
<publisher>Publishing Co., Ltd.</publisher>
<contexts>
<context position="7608" citStr="Kai and Matsukawa, 2002" startWordPosition="1148" endWordPosition="1151">thod as McCarthy and Navigli (2007). 3.1 Selecting Target Words We define target words as the list of content words (nouns, verbs, adjectives, and adverbs) that are common to two Japanese word dictionaries (IPADIC-2.7.07 and JUMANDIC-7.08) in order to select the standard target words at first. Next, the following words were deleted from these words. • Words that are already simple enough • Words that have no substitutions • Words that are a part of a compound word • Words that are a part of an idiomatic phrase • Low frequency words We define simple words as words in Basic Vocabulary to Learn (Kai and Matsukawa, 2002), which is a receptive vocabulary for elementary school students. Words that are not registered 5http://simple.wikipedia.org/wiki/Wikipedia: Basic English combined wordlist 6https://www.mturk.com 7http://sourceforge.jp/projects/ipadic/releases/24435/ 8http://nlp.ist.i.kyoto-u.ac.jp/index.php?JUMAN 36 P1\P2 EP1,P22P P1[P2 (1) IPI Ej(ranki(wj) — ranki)(rankave(wj) — rankave) (2) qEj(ranki(wj) — ranki)2 Ej(rankave(wj) — rankave)2 in SNOW D2 (Yamamoto and Yoshikura, 2013) are defined as words that have no substitutions. Low frequency words are defined as words that occurred less than 10 times over</context>
</contexts>
<marker>Kai, Matsukawa, 2002</marker>
<rawString>Mutsuro Kai and Toshihiro Matsukawa. 2002. Method of Vocabulary Teaching: Vocabulary Table version. Mitsumura Tosho Publishing Co., Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoyuki Kajiwara</author>
<author>Kazuhide Yamamoto</author>
</authors>
<title>Qualitative evaluation of available japanese resources for lexical paraphrasing.</title>
<date>2014</date>
<tech>IEICE Technical Report, NLC2014-37, 114(366):43–48.</tech>
<contexts>
<context position="15958" citStr="Kajiwara and Yamamoto, 2014" startWordPosition="2457" endWordPosition="2460"> candidates of a simple word for each complex word. These lexical paraphrases were selected from several Japanese lexical paraphrasing databases such as SNOW D2 (Yamamoto and Yoshikura, 2013), 12https://code.google.com/p/mecab/ 13http://dumps.wikimedia.org/jawiki/ 14http://vvlexicon.ninjal.ac.jp/ 38 Precision Recall F-measure 0.89 0.08 0.15 Table 3: Performance of the system Noun Verb Adjective Adverb 62 65 3 0 Table 4: POS of the simplified target words Japanese WordNet Synonyms Database15, Verb Entailment Database16, and Case Base for Basic Semantic Relations16, following previous research (Kajiwara and Yamamoto, 2014). 5.3 Word Sense Disambiguation If, given the context of the sentence, the list of suggested paraphrases for a complex word contains words that are improper in this context, these improper paraphrases are removed from the list. An input sentence receives a predicate-argument structure analysis using the Japanese predicateargument structure analyzer SynCha-0.3 (Iida and Poesio, 2011)17, and the predicate (verb or adjective), the arguments (nouns) and grammatical relations (case makers such as “ga (subject)”, “o (object)”, “ni (indirect object)”) are extracted as a set of the form {predicate, re</context>
</contexts>
<marker>Kajiwara, Yamamoto, 2014</marker>
<rawString>Tomoyuki Kajiwara and Kazuhide Yamamoto. 2014. Qualitative evaluation of available japanese resources for lexical paraphrasing. IEICE Technical Report, NLC2014-37, 114(366):43–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoyuki Kajiwara</author>
<author>Hiroshi Matsumoto</author>
<author>Kazuhide Yamamoto</author>
</authors>
<title>Selecting proper lexical paraphrase for children.</title>
<date>2013</date>
<booktitle>In Proceedings of the 25th Conference on Computational Linguistics and Speech Processing,</booktitle>
<pages>59--73</pages>
<contexts>
<context position="904" citStr="Kajiwara et al., 2013" startWordPosition="131" endWordPosition="134">ation. One is a simplification system that supports reading comprehension of a wide range of readers, including children and language learners. The other is a dataset for evaluation that enables open discussions with other systems. Both the system and the dataset are made available providing the first such resources for the Japanese language. 1 Introduction Lexical simplification is a technique that substitutes a complex word or phrase in a sentence with a simpler synonym. This technique supports the reading comprehension of a wide range of readers, including children (Belder and Moens, 2010; Kajiwara et al., 2013) and language learners (Eom et al., 2012; Moku et al., 2012). The recent years have seen a great activity in this field of inquiry, especially for English: At the SemEval-2012 workshop, many systems were participating in the English lexical simplification task (Specia et al., 2012), for which also an evaluation dataset was constructed. Other resources for statistical learning of simplified rules were built, drawing on the Simple English Wikipedia (Zhu et al., 2010; Horn et al., 2014), e.g. several parallel corpora aligning standard and simple English (Zhu et al., 2010; Kauchak, 2013)1,2 and ev</context>
</contexts>
<marker>Kajiwara, Matsumoto, Yamamoto, 2013</marker>
<rawString>Tomoyuki Kajiwara, Hiroshi Matsumoto, and Kazuhide Yamamoto. 2013. Selecting proper lexical paraphrase for children. In Proceedings of the 25th Conference on Computational Linguistics and Speech Processing, pages 59–73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kauchak</author>
</authors>
<title>Improving text simplification language modeling using unsimplified text data.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51th Annual Meeting of the Associatioin for Computational Linguistics,</booktitle>
<pages>1537--1546</pages>
<contexts>
<context position="1494" citStr="Kauchak, 2013" startWordPosition="228" endWordPosition="229">; Kajiwara et al., 2013) and language learners (Eom et al., 2012; Moku et al., 2012). The recent years have seen a great activity in this field of inquiry, especially for English: At the SemEval-2012 workshop, many systems were participating in the English lexical simplification task (Specia et al., 2012), for which also an evaluation dataset was constructed. Other resources for statistical learning of simplified rules were built, drawing on the Simple English Wikipedia (Zhu et al., 2010; Horn et al., 2014), e.g. several parallel corpora aligning standard and simple English (Zhu et al., 2010; Kauchak, 2013)1,2 and evaluation datasets (Specia et al., 2012; Belder and Moens, 2012)3,4. On the other hand, there have been no published resources on Japanese lexical simplification so far. 1http://www.cs.pomona.edu/˜dkauchak/simplification/ 2https://www.ukp.tu-darmstadt.de/data/ 3http://www.cs.york.ac.uk/semeval-2012/task1/ 4http://people.cs.kuleuven.be/˜jan.debelder/lseval.zip Kazuhide Yamamoto Department of Electrical Engineering Nagaoka University of Technology Nagaoka City, Niigata, Japan yamamoto@jnlp.org Such resources had to be created and made public, for the sake of readers in need of reading a</context>
</contexts>
<marker>Kauchak, 2013</marker>
<rawString>David Kauchak. 2013. Improving text simplification language modeling using unsimplified text data. In Proceedings of the 51th Annual Meeting of the Associatioin for Computational Linguistics, pages 1537– 1546.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>A fully-lexicalized probabilistic model for japanese syntactic and case structure analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>176--183</pages>
<contexts>
<context position="17363" citStr="Kawahara and Kurohashi, 2006" startWordPosition="2684" endWordPosition="2688">list of sets of the form {predicate, relation, argument}, where the candidate substitutions are used instead of the complex word (so there will be as many of these sets as there are candidate substitutions). These new sets are checked against the Kyoto University Case Frame18. If the set is found there, the candidate substitution counts as a legitimate substitution; if the set is not found, the candidate substitution is not counted as a legitimate substitution. Kyoto University Case Frame is the list of predicate and argument pairs that have a case relationship, and it is built automatically (Kawahara and Kurohashi, 2006) from Web texts. 5.4 Synonym Ranking All candidate words are given a degree of difficulty. The simplest word is used to replace the complex word in the input sentence, and the output sentence is generated. In this study, Lexical Properties of Japanese (Amano and Kondo, 2000) is used for determining the degree of difficulty. 15http://nlpwww.nict.go.jp/wn-ja/jpn/downloads.html 16https://alaginrc.nict.go.jp/resources/nict-resource/ 17http://www.cl.cs.titech.ac.jp/ ryu-i/syncha/ 18http://www.gsk.or.jp/catalog/gsk2008-b/ 5.5 Evaluation of the System by the Dataset The performance of the lexical sim</context>
</contexts>
<marker>Kawahara, Kurohashi, 2006</marker>
<rawString>Daisuke Kawahara and Sadao Kurohashi. 2006. A fully-lexicalized probabilistic model for japanese syntactic and case structure analysis. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pages 176–183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Kaoru Yamamoto</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Applying conditional random fields to japanese morphological analysis.</title>
<date>2004</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>230--237</pages>
<contexts>
<context position="14782" citStr="Kudo et al., 2004" startWordPosition="2287" endWordPosition="2290">ly in different contexts. Among these, 48.8% is even different in the simplest word. 5 Constructing Japanese Lexical Simplification System We have also constructed a lexical simplification system using four typical mechanisms of lexical simplification (Shardlow, 2014) shown in Figure1. We expect the standard system to be used as a baseline of Japanese lexical simplification. We also expect that the system can support the reading comprehension of a wide range of readers. 5.1 Identification of Complex Words An input sentence is first analyzed by the Japanese morphological analyzers MeCab-0.993 (Kudo et al., 2004)12 and IPADIC-2.7.0, and content words that are not included in the list of simple words are extracted as complex words. These complex words are not part of a compound word or an idiomatic phrase. In this study, simple words are defined as the Basic Vocabulary to Learn; compound words are defined as the lists of entries from Japanese Wikipedia13 and the Compound Verb Lexicon14; finally, idiomatic phrases are defined as the list of Japanese idiomatic phrases made by Sato (2007). 5.2 Substitution Generation Several paraphrases are enumerated as candidates of a simple word for each complex word. </context>
</contexts>
<marker>Kudo, Yamamoto, Matsumoto, 2004</marker>
<rawString>Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto. 2004. Applying conditional random fields to japanese morphological analysis. Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 230–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<title>Semeval2007 task10: English lexical substitution task.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>48--53</pages>
<contexts>
<context position="2669" citStr="McCarthy and Navigli, 2007" startWordPosition="377" endWordPosition="380">public, for the sake of readers in need of reading assistance, as well as to accelerate the research on this topic. Therefore, we have constructed and published a Japanese lexical simplification system (SNOW S3) and a dataset for evaluation of the system (SNOW E4). These resources are available at the following URL: http://www.jnlp.org/SNOW 2 Previous Work Two datasets for evaluation of English lexical simplification have been published. Both were constructed by transforming a lexical substitution dataset, which was constructed in an English lexical substitution task of SemEval-2007 workshop (McCarthy and Navigli, 2007). 2.1 McCarthy Substitution Dataset The English lexical substitution task of SemEval2007 requires that the system finds words or phrases that one can substitute for the given target word in the given content. These target words are content words, and their details are shown in Table 1. These contexts are selected from the English Internet Corpus, which is a balanced and web-based corpus of English (Sharoff, 2006). This dataset consists of 2,010 sentences, 201 target words each with 10 sentences as contexts. Five annotators who are native English speakers proposed at most three appropriate subs</context>
<context position="7019" citStr="McCarthy and Navigli (2007)" startWordPosition="1046" endWordPosition="1049">ited using the Amazon Mechanical Turk6. De Belder and Moens requested annotators who were located in the U.S. and had completed at least 95% of their previous assignments correctly. In the end, the rank from each annotator was integrated into the dataset. In this dataset, the noisy channel model was used in order to take account of the rank and reliability of each annotator. 3 Constructing Japanese Lexical Substitution Dataset We have constructed a dataset for evaluation of Japanese lexical simplification. First, a Japanese lexical substitution dataset was constructed using the same method as McCarthy and Navigli (2007). 3.1 Selecting Target Words We define target words as the list of content words (nouns, verbs, adjectives, and adverbs) that are common to two Japanese word dictionaries (IPADIC-2.7.07 and JUMANDIC-7.08) in order to select the standard target words at first. Next, the following words were deleted from these words. • Words that are already simple enough • Words that have no substitutions • Words that are a part of a compound word • Words that are a part of an idiomatic phrase • Low frequency words We define simple words as words in Basic Vocabulary to Learn (Kai and Matsukawa, 2002), which is </context>
<context position="10166" citStr="McCarthy and Navigli, 2007" startWordPosition="1521" endWordPosition="1525">e is inappropriate if the meaning of the sentence changes as a result of the substitution of this paraphrase for the target word. An average of 4.50 lexical paraphrases were accepted. However, 170 sentences (17 target words) that all paraphrases have been evaluated to be inappropriate were discarded. 9http://www.nikkeibookvideo.com/kijidb/ 10http://www.lancers.jp Since we have sets of paraphrases for each target word and annotator, pairwise agreement was calculated between each pair of sets (p1, p2 E P) from each possible pairing (P) according to the Equation (1), following previous research (McCarthy and Navigli, 2007). Inter-annotator agreement is 66.4%. An English translation of an example from the dataset is provided below. As a paraphrase of the noun “appeal” in this context, one annotator proposed “advocate”, another annotator proposed “exert”, and three annotators proposed “promote”. Context: You can appeal for proud batting power. Gold-Standard: advocate 1; promote 3; exert 1; 4 Transforming into Lexical Simplification Dataset 4.1 Ranking Paraphrases These target words and their several paraphrases were ranked according to how simple they were in the context from the dataset that we built (as discuss</context>
</contexts>
<marker>McCarthy, Navigli, 2007</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2007. Semeval2007 task10: English lexical substitution task. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 48– 53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manami Moku</author>
<author>Kazuhide Yamamoto</author>
<author>Ai Makabi</author>
</authors>
<title>Automatic easy japanese translation for information accessibility of foreigners.</title>
<date>2012</date>
<booktitle>In Proceedings of the Workshop on Speech and Language Processing Tools in Education,</booktitle>
<pages>85--90</pages>
<contexts>
<context position="964" citStr="Moku et al., 2012" startWordPosition="142" endWordPosition="145">rehension of a wide range of readers, including children and language learners. The other is a dataset for evaluation that enables open discussions with other systems. Both the system and the dataset are made available providing the first such resources for the Japanese language. 1 Introduction Lexical simplification is a technique that substitutes a complex word or phrase in a sentence with a simpler synonym. This technique supports the reading comprehension of a wide range of readers, including children (Belder and Moens, 2010; Kajiwara et al., 2013) and language learners (Eom et al., 2012; Moku et al., 2012). The recent years have seen a great activity in this field of inquiry, especially for English: At the SemEval-2012 workshop, many systems were participating in the English lexical simplification task (Specia et al., 2012), for which also an evaluation dataset was constructed. Other resources for statistical learning of simplified rules were built, drawing on the Simple English Wikipedia (Zhu et al., 2010; Horn et al., 2014), e.g. several parallel corpora aligning standard and simple English (Zhu et al., 2010; Kauchak, 2013)1,2 and evaluation datasets (Specia et al., 2012; Belder and Moens, 20</context>
</contexts>
<marker>Moku, Yamamoto, Makabi, 2012</marker>
<rawString>Manami Moku, Kazuhide Yamamoto, and Ai Makabi. 2012. Automatic easy japanese translation for information accessibility of foreigners. In Proceedings of the Workshop on Speech and Language Processing Tools in Education, pages 85–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sato</author>
</authors>
<title>Compilation of a comparative list of basic japanese idioms from five sources. The Special Interest Group Technical Reports of IPSJ,</title>
<date>2007</date>
<pages>1--6</pages>
<contexts>
<context position="15263" citStr="Sato (2007)" startWordPosition="2370" endWordPosition="2371">ation of Complex Words An input sentence is first analyzed by the Japanese morphological analyzers MeCab-0.993 (Kudo et al., 2004)12 and IPADIC-2.7.0, and content words that are not included in the list of simple words are extracted as complex words. These complex words are not part of a compound word or an idiomatic phrase. In this study, simple words are defined as the Basic Vocabulary to Learn; compound words are defined as the lists of entries from Japanese Wikipedia13 and the Compound Verb Lexicon14; finally, idiomatic phrases are defined as the list of Japanese idiomatic phrases made by Sato (2007). 5.2 Substitution Generation Several paraphrases are enumerated as candidates of a simple word for each complex word. These lexical paraphrases were selected from several Japanese lexical paraphrasing databases such as SNOW D2 (Yamamoto and Yoshikura, 2013), 12https://code.google.com/p/mecab/ 13http://dumps.wikimedia.org/jawiki/ 14http://vvlexicon.ninjal.ac.jp/ 38 Precision Recall F-measure 0.89 0.08 0.15 Table 3: Performance of the system Noun Verb Adjective Adverb 62 65 3 0 Table 4: POS of the simplified target words Japanese WordNet Synonyms Database15, Verb Entailment Database16, and Case</context>
</contexts>
<marker>Sato, 2007</marker>
<rawString>Satoshi Sato. 2007. Compilation of a comparative list of basic japanese idioms from five sources. The Special Interest Group Technical Reports of IPSJ, 2007-NL-178, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Shardlow</author>
</authors>
<title>A survey of automated text simplification.</title>
<date>2014</date>
<journal>International Journal of Advanced Computer Science and Applications, Special Issue on Natural Language Processing,</journal>
<pages>58--70</pages>
<contexts>
<context position="14432" citStr="Shardlow, 2014" startWordPosition="2232" endWordPosition="2233">t word have the same list of paraphrases. This shows that the meaning of many target words changed slightly in different contexts. In addition, 59.5% of combinations with the same list of paraphrases have different ranks of difficulty. This shows that the difficulty of a word Figure 1: Outline of lexical simplification system also changes slightly in different contexts. Among these, 48.8% is even different in the simplest word. 5 Constructing Japanese Lexical Simplification System We have also constructed a lexical simplification system using four typical mechanisms of lexical simplification (Shardlow, 2014) shown in Figure1. We expect the standard system to be used as a baseline of Japanese lexical simplification. We also expect that the system can support the reading comprehension of a wide range of readers. 5.1 Identification of Complex Words An input sentence is first analyzed by the Japanese morphological analyzers MeCab-0.993 (Kudo et al., 2004)12 and IPADIC-2.7.0, and content words that are not included in the list of simple words are extracted as complex words. These complex words are not part of a compound word or an idiomatic phrase. In this study, simple words are defined as the Basic </context>
</contexts>
<marker>Shardlow, 2014</marker>
<rawString>Matthew Shardlow. 2014. A survey of automated text simplification. International Journal of Advanced Computer Science and Applications, Special Issue on Natural Language Processing, pages 58–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Serge Sharoff</author>
</authors>
<title>Open-source corpora: Using the net to fish for linguistic data.</title>
<date>2006</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>11</volume>
<issue>4</issue>
<pages>435--462</pages>
<contexts>
<context position="3085" citStr="Sharoff, 2006" startWordPosition="447" endWordPosition="448">n published. Both were constructed by transforming a lexical substitution dataset, which was constructed in an English lexical substitution task of SemEval-2007 workshop (McCarthy and Navigli, 2007). 2.1 McCarthy Substitution Dataset The English lexical substitution task of SemEval2007 requires that the system finds words or phrases that one can substitute for the given target word in the given content. These target words are content words, and their details are shown in Table 1. These contexts are selected from the English Internet Corpus, which is a balanced and web-based corpus of English (Sharoff, 2006). This dataset consists of 2,010 sentences, 201 target words each with 10 sentences as contexts. Five annotators who are native English speakers proposed at most three appropriate substitutions for each of the target words within their contexts. When an appropriate paraphrasable word did not occur, the annotator propose paraphrasable phrases. An example from this dataset is provided below. As a paraphrase of the adjective “bright” in this context, three annotators proposed “intelligent”, another three annotators proposed “clever”, and one annotator proposed “smart”. Context: During the siege, </context>
</contexts>
<marker>Sharoff, 2006</marker>
<rawString>Serge Sharoff. 2006. Open-source corpora: Using the net to fish for linguistic data. International Journal of Corpus Linguistics, 11(4), pages 435–462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucia Specia</author>
<author>Sujay Kumar Jauhar</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semeval-2012 task 1: English lexical simplification.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval-2012),</booktitle>
<pages>347--355</pages>
<contexts>
<context position="1186" citStr="Specia et al., 2012" startWordPosition="177" endWordPosition="180">roviding the first such resources for the Japanese language. 1 Introduction Lexical simplification is a technique that substitutes a complex word or phrase in a sentence with a simpler synonym. This technique supports the reading comprehension of a wide range of readers, including children (Belder and Moens, 2010; Kajiwara et al., 2013) and language learners (Eom et al., 2012; Moku et al., 2012). The recent years have seen a great activity in this field of inquiry, especially for English: At the SemEval-2012 workshop, many systems were participating in the English lexical simplification task (Specia et al., 2012), for which also an evaluation dataset was constructed. Other resources for statistical learning of simplified rules were built, drawing on the Simple English Wikipedia (Zhu et al., 2010; Horn et al., 2014), e.g. several parallel corpora aligning standard and simple English (Zhu et al., 2010; Kauchak, 2013)1,2 and evaluation datasets (Specia et al., 2012; Belder and Moens, 2012)3,4. On the other hand, there have been no published resources on Japanese lexical simplification so far. 1http://www.cs.pomona.edu/˜dkauchak/simplification/ 2https://www.ukp.tu-darmstadt.de/data/ 3http://www.cs.york.ac</context>
<context position="11818" citStr="Specia et al., 2012" startWordPosition="1781" endWordPosition="1784">and Moens, 2012). Spearman’s rank correlation coefficient is defined as in the Equation (2), where ranki is the average rank of the words given by annotator i. To extend this equation to one annotator versus other annotators, we define the rank assigned by the rankave to be the average of the ranks given by the other annotators. This agreement is 33.2%11. 4.2 Merging All Rankings All annotators’ work results were merged into one dataset. The rank of each word was decided based 11While this score is apparently low, the highly subjective nature of the annotation task must be taken into account (Specia et al., 2012). 37 all % noun % verb % adj % adv % 1. # context pairs 10,485 - 2,835 - 3,240 - 2,250 - 2,160 - 2. # 1. with same list 1,593 15 789 28 348 11 168 7 288 13 3. # 2. with different rankings 948 60 344 44 262 75 129 77 213 74 4. # 3. with different top word 463 49 214 62 130 50 51 40 68 32 Table 2: Context dependency ratio on the average of the rank from each annotator, following the previous research (Specia et al., 2012). The same rank is assigned to words that have the same average. In this study, the same annotator performed both the evaluation of paraphrases and their ranking. Therefore, any</context>
</contexts>
<marker>Specia, Jauhar, Mihalcea, 2012</marker>
<rawString>Lucia Specia, Sujay Kumar Jauhar, and Rada Mihalcea. 2012. Semeval-2012 task 1: English lexical simplification. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval-2012), pages 347–355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazuhide Yamamoto</author>
<author>Kotaro Yoshikura</author>
</authors>
<title>Manual construction of lexical paraphrase dictionary of japanese verbs, adjectives, and adverbs.</title>
<date>2013</date>
<booktitle>In Proceedings of 19th Annual Meeting of Association for Natural Language Processing,</booktitle>
<pages>276--279</pages>
<contexts>
<context position="8080" citStr="Yamamoto and Yoshikura, 2013" startWordPosition="1195" endWordPosition="1198">d • Words that are a part of an idiomatic phrase • Low frequency words We define simple words as words in Basic Vocabulary to Learn (Kai and Matsukawa, 2002), which is a receptive vocabulary for elementary school students. Words that are not registered 5http://simple.wikipedia.org/wiki/Wikipedia: Basic English combined wordlist 6https://www.mturk.com 7http://sourceforge.jp/projects/ipadic/releases/24435/ 8http://nlp.ist.i.kyoto-u.ac.jp/index.php?JUMAN 36 P1\P2 EP1,P22P P1[P2 (1) IPI Ej(ranki(wj) — ranki)(rankave(wj) — rankave) (2) qEj(ranki(wj) — ranki)2 Ej(rankave(wj) — rankave)2 in SNOW D2 (Yamamoto and Yoshikura, 2013) are defined as words that have no substitutions. Low frequency words are defined as words that occurred less than 10 times over the 15 years in Japanese newspapers9. In the end, 250 words (nouns and verbs 75 each, adjectives and adverbs 50 each) were chosen as a target words at random. 3.2 Providing Paraphrases An annotator provided several paraphrases for each target word in 10 contexts. These contexts were randomly selected from newspaper article. When providing a paraphrase, an annotator could refer to a dictionary but was not supposed to ask the other annotators for an opinion. When an an</context>
<context position="15521" citStr="Yamamoto and Yoshikura, 2013" startWordPosition="2404" endWordPosition="2407">lex words. These complex words are not part of a compound word or an idiomatic phrase. In this study, simple words are defined as the Basic Vocabulary to Learn; compound words are defined as the lists of entries from Japanese Wikipedia13 and the Compound Verb Lexicon14; finally, idiomatic phrases are defined as the list of Japanese idiomatic phrases made by Sato (2007). 5.2 Substitution Generation Several paraphrases are enumerated as candidates of a simple word for each complex word. These lexical paraphrases were selected from several Japanese lexical paraphrasing databases such as SNOW D2 (Yamamoto and Yoshikura, 2013), 12https://code.google.com/p/mecab/ 13http://dumps.wikimedia.org/jawiki/ 14http://vvlexicon.ninjal.ac.jp/ 38 Precision Recall F-measure 0.89 0.08 0.15 Table 3: Performance of the system Noun Verb Adjective Adverb 62 65 3 0 Table 4: POS of the simplified target words Japanese WordNet Synonyms Database15, Verb Entailment Database16, and Case Base for Basic Semantic Relations16, following previous research (Kajiwara and Yamamoto, 2014). 5.3 Word Sense Disambiguation If, given the context of the sentence, the list of suggested paraphrases for a complex word contains words that are improper in thi</context>
</contexts>
<marker>Yamamoto, Yoshikura, 2013</marker>
<rawString>Kazuhide Yamamoto and Kotaro Yoshikura. 2013. Manual construction of lexical paraphrase dictionary of japanese verbs, adjectives, and adverbs. In Proceedings of 19th Annual Meeting of Association for Natural Language Processing, pages 276–279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhemin Zhu</author>
<author>Delphine Bernhard</author>
<author>Iryna Gurevych</author>
</authors>
<title>A monolingual tree-based translation model for sentence simplification.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>1353--1361</pages>
<contexts>
<context position="1372" citStr="Zhu et al., 2010" startWordPosition="206" endWordPosition="209">ym. This technique supports the reading comprehension of a wide range of readers, including children (Belder and Moens, 2010; Kajiwara et al., 2013) and language learners (Eom et al., 2012; Moku et al., 2012). The recent years have seen a great activity in this field of inquiry, especially for English: At the SemEval-2012 workshop, many systems were participating in the English lexical simplification task (Specia et al., 2012), for which also an evaluation dataset was constructed. Other resources for statistical learning of simplified rules were built, drawing on the Simple English Wikipedia (Zhu et al., 2010; Horn et al., 2014), e.g. several parallel corpora aligning standard and simple English (Zhu et al., 2010; Kauchak, 2013)1,2 and evaluation datasets (Specia et al., 2012; Belder and Moens, 2012)3,4. On the other hand, there have been no published resources on Japanese lexical simplification so far. 1http://www.cs.pomona.edu/˜dkauchak/simplification/ 2https://www.ukp.tu-darmstadt.de/data/ 3http://www.cs.york.ac.uk/semeval-2012/task1/ 4http://people.cs.kuleuven.be/˜jan.debelder/lseval.zip Kazuhide Yamamoto Department of Electrical Engineering Nagaoka University of Technology Nagaoka City, Niiga</context>
</contexts>
<marker>Zhu, Bernhard, Gurevych, 2010</marker>
<rawString>Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych. 2010. A monolingual tree-based translation model for sentence simplification. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 1353–1361.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>