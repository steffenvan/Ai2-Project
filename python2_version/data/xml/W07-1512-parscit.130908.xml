<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9982265">
Computing translation units and quantifying parallelism
in parallel dependency treebanks
</title>
<author confidence="0.956804">
Matthias Buch-Kromann
</author>
<affiliation confidence="0.947474">
ISV Computational Linguistics Group
Copenhagen Business School
</affiliation>
<email confidence="0.996831">
mbk.isv@cbs.dk
</email>
<sectionHeader confidence="0.995612" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997287642857143">
The linguistic quality of a parallel tree-
bank depends crucially on the parallelism
between the source and target language an-
notations. We propose a linguistic notion
of translation units and a quantitative mea-
sure of parallelism for parallel dependency
treebanks, and demonstrate how the pro-
posed translation units and parallelism mea-
sure can be used to compute transfer rules,
spot annotation errors, and compare differ-
ent annotation schemes with respect to each
other. The proposal is evaluated on the
100,000 word Copenhagen Danish-English
Dependency Treebank.
</bodyText>
<sectionHeader confidence="0.998997" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970764705882">
Parallel treebanks are increasingly seen as a valuable
resource for many different tasks, including machine
translation, word alignment, translation studies and
contrastive linguistics (ˇCmejrek et al., 2004; Cyrus,
2006; Hansen-Schirra et al., 2006). However, the
usefulness of a parallel treebank for these purposes
is directly correlated with the degree of syntactic
parallelism in the treebank. Some non-parallelism
is inevitable because two languages always differ
with respect to their syntactic structure. But non-
parallelism can also be the result of differences in
the linguistic analyses of the source text and target
text, eg, with respect to whether noun phrases are
headed by nouns or determiners, whether conjunc-
tions are headed by the first conjunct or the coordi-
nator, whether prepositions are analyzed as heads or
adjuncts in prepositional phrases, etc.
</bodyText>
<page confidence="0.989663">
69
</page>
<bodyText confidence="0.867734320754717">
In this paper, we focus on parallel dependency
treebanks that consist of source texts and trans-
lations annotated with dependency analyses and
word-alignments. These requirements are directly
satisfied by the analytical layer of the Prague
Czech-English Dependency Treebank (ˇCmejrek et
al., 2004) and by the dependency layer of the
Copenhagen Danish-English Dependency Treebank
(Buch-Kromann et al., 2007). The requirements are
also indirectly satisifed by parallel treebanks with a
constituent layer and a word alignment, eg (Han et
al., 2002; Cyrus, 2006; Hansen-Schirra et al., 2006;
Samuelsson and Volk, 2006), since it is possible
to transform constituent structures into dependency
structures — a procedure used in the CoNLL shared
tasks in 2006 and 2007 (Buchholz and Marsi, 2006).
Finally, it is worth pointing out that the requirements
are also met by any corpus equipped with two dif-
ferent dependency annotations since a text is always
trivially word-aligned with itself. The methods pro-
posed in the paper therefore apply to a wide range
of parallel treebanks, as well as to comparing two
monolingual treebank annotations with each other.
The paper is structured as follows. In section 2,
we define our notions of word alignments and de-
pendencies. In section 3, we define our notion of
translation units and state an algorithm for comput-
ing the translation units in a parallel dependency
treebank. Finally, in sections 4, 5 and 6, we demon-
strate how translation units can be used to compute
transfer rules, quantify parallelism, spot annotation
errors, and compare monolingual and bilingual an-
notation schemes with respect to each other.
Proceedings of the Linguistic Annotation Workshop, pages 69–76,
Prague, June 2007. c�2007 Association for Computational Linguistics
Complement roles Adjunct roles
aobj adjectival object appa parenthetical apposition
avobj adverbial object appr restrictive apposition
conj conjunct of coordinator coord coordination
dobj direct object list unanalyzed sequence
expl expletive subject mod modifier
iobj indirect object modo dobj-oriented modifier
lobj locative-directional obj. modp parenthetical modifier
nobj nominal object modr restrictive modifier
numa additive numeral mods subject-oriented mod.
numm multiplicative numeral name additional proper name
part verbal particle namef additional first name
pobj prepositional object namel additional last name
possd possessed in genitives pnct punctuation modifier
pred subject/object predicate rel relative clause
qobj quotation object title title of person
subj subject xpl explification (colon)
vobj verbal object
</bodyText>
<figureCaption confidence="0.998317">
Figure 1: The main dependency roles in the dependency framework Discontinuous Grammar.
</figureCaption>
<sectionHeader confidence="0.612014" genericHeader="introduction">
2 Word alignments and dependencies
</sectionHeader>
<bodyText confidence="0.999260391304348">
In our linguistic analyses, we will assume that a
word alignment W HW&apos; encodes a translational cor-
respondence between the word clusters W and W&apos; in
the source text and target text, ie, the word align-
ment expresses the human intuition that the subset
W of words in the source text corresponds roughly
in meaning or function to the subset W&apos; of words in
the target text. The translations may contain addi-
tions or deletions, ie, W and W&apos; may be empty.
We also assume that a dependency edge g r�d
encodes a complement or adjunct relation between a
word g (the governor) and a complement or adjunct
phrase headed by the word d (the dependent), where
the edge label r specifies the complement or adjunct
dependency role.1 As an illustration of how comple-
ment and adjunct relations can be encoded by means
of dependency roles, the most important dependency
roles used in the dependency framework Discontin-
uous Grammar (Buch-Kromann, 2006) are shown in
Figure 1. Finally, we will assume that the depen-
dencies form a tree (or a forest). The tree may be
non-projective, ie, it may contain crossing branches
(technically, a dependency g r��d is projective if
</bodyText>
<footnote confidence="0.903333444444444">
1Following standard dependency theoretic assumptions, we
will assume the following differences between complement and
adjunct relations: (a) complements are lexically licensed by
their governor, whereas adjuncts license their adjunct governor;
(b) in the functor-argument structure, complements act as ar-
guments of their governor, whereas adjuncts act as modifiers
of their governor; (c) a governor can have several adjuncts with
the same adjunct role, whereas no two complements of the same
governor can have the same complement role.
</footnote>
<figureCaption confidence="0.984944666666667">
Figure 2: Parallel dependency treebank analysis
with word alignment and two monolingual depen-
dency analyses.
</figureCaption>
<bodyText confidence="0.998337733333333">
and only if g is a transitive governor of all the words
between g and d).
Figure 2 shows an example of this kind of analy-
sis, based on the annotation conventions used in Dis-
continuous Grammar and the associated Copenha-
gen Danish-English Dependency Treebank (Buch-
Kromann et al., 2007). In the example, word align-
ments are indicated by lines connecting Danish word
clusters with English word clusters, and dependen-
cies are indicated by means of arrows that point
from the governor to the dependent, with the de-
pendency role written at the arrow tip. For ex-
ample, the Danish word cluster “koncentrere sig”
(“concentrate self”) has been aligned with the En-
glish word “concentrate”, and the English phrase
</bodyText>
<figure confidence="0.9885485">
subj mod vobj dobj pobj nobj
X has to concentrate only on Y
subj dobj vobj mod pobj nobj
X
X
skal
must
kun
only
koncentrere
concentrate
sig
self
om
about
Y
Y
C
</figure>
<page confidence="0.990851">
70
</page>
<bodyText confidence="0.99248268">
headed by “on” is analyzed as a prepositional ob-
ject of the verb “concentrate.” In the Danish de-
pendency analysis, the dependency between the ad-
verbial “kun” (“only”) and its prepositional gover-
nor “om” (“about”) is non-projective because “om”
does not dominate the words “koncentrere” (“con-
centrate”) and “selv” (“self”).
Dependency analyses differ from phrase-structure
analyses in that phrases are a derived notion: in a de-
pendency tree, each word has a derived phrase that
consists of all the words that can be reached from the
word by following the arrows. For example, the En-
glish word “concentrate” heads the phrase “concen-
trate only on Y,” and the Danish word “om” heads
the discontinuous phrase “kun ... om Y.”
If a parallel dependency analysis is well-formed,
in a sense to be made clear in the following sec-
tion, each alignment edge corresponds to what we
will call a translation unit. Intuitively, given an
aligment edge W ↔W0, we can create the cor-
responding translation unit by taking the source
and target subtrees headed by the words in W
and W0, deleting all parallel adjuncts of W ↔W0,
and replacing all remaining parallel dependents
of W ↔W0 with variables x1,...,xn and x01,...,x0n.
The resulting translation unit will be denoted by
T(x1,...,xn)↔T0(x01,...,x0n), where T and T0 de-
note the source and target dependency trees in the
translation unit. For convenience, we will some-
times use vector notation and write T(x)↔T0(x0)
instead of T(x1,...,xn)↔T0(x01,...,x0n). Dependen-
cies are usually defined as relations between words,
but by an abuse of terminology, we will say that a
word d is a dependent of an alignment edge W ↔W0
provided d is a dependent of some word in W ∪W0
and d is not itself contained in W ∪W0.
Figure 3 shows the six translation units that can
be derived from the parallel dependency analysis in
Figure 2, by means of the procedure outlined above.
Each translation unit can be interpreted as a bidi-
rectional translation rules: eg, the second translation
unit in Figure 3 can be interpreted as a translation
rule stating that a Danish dependency tree with ter-
minals “x1 skal x2” can be translated into an English
dependency tree with terminals “x01 has to x02” where
the English phrases x01,x02 are translations of the Dan-
ish phrases x1,x2, and vice versa.
In the following section, we will go deeper into
subj vobj dobj pobj nobj
subj dobj vobj pobj nobj
</bodyText>
<figureCaption confidence="0.9710655">
Figure 3: The six translation units derived from the
parallel dependency analysis in Figure 2.
</figureCaption>
<bodyText confidence="0.998661285714286">
the definition and interpretation of these rules. In
particular, unlike the essentially context-free trans-
lation rules used in frameworks such as (Quirk et
al., 2005; Ding, 2006; Chiang, 2007), we will not
assume that the words in the translation rules are or-
dered, and that the translation rules can only be used
in a way that leads to projective dependency trees.
</bodyText>
<sectionHeader confidence="0.7028845" genericHeader="method">
3 Translation units within a simple
dependency-based translation model
</sectionHeader>
<bodyText confidence="0.999986833333333">
In many parallel treebanks, word alignments and
syntactic annotations are created independently of
each other, and there is therefore no guarantee that
the word or phrase alignments coincide with any
meaningful notion of translation units. To rectify
this problem, we need to define a notion of trans-
lation units that links the word alignments and the
source and target dependency analysis in a meaning-
ful way, and we need to specify a procedure for con-
structing a meaningful set of word alignments from
the actual treebank annotation.
Statistical machine translation models often em-
body an explicit notion of translation units. How-
ever, many of these models are not applicable to
parallel treebanks because they assume translation
units where either the source text, the target text
or both are represented as word sequences without
any syntactic structure (Galley et al., 2004; Marcu
et al., 2006; Koehn et al., 2003). Other SMT models
assume translation units where the source and tar-
get language annotation is based on either context-
free grammar (Yamada and Knight, 2001; Chiang,
2007) or context-free dependency grammar (Quirk
et al., 2005; Ding, 2006). However, since non-
</bodyText>
<figure confidence="0.985944625">
X x1’ has to x2’ concentrate x1’ only on x1’ Y
X
X
x1
x1
skal
must
x2
x2
koncentrere
concentrate
sig
self
x1
x1
kun
only
om
about
x1
x1
Y
Y
C
</figure>
<page confidence="0.9909">
71
</page>
<bodyText confidence="0.998614714285714">
projectivity is not directly compatible with context-
free grammar, and parallel dependency treebanks
tend to encode non-projective dependencies directly,
the context-free SMT models are not directly appli-
cable to parallel dependency treebanks in general.
But the context-free SMT models are an important
inspiration for the simple dependency-based trans-
lation model and notion of translation units that we
will present below.
In our translation model, we will for simplicity as-
sume that both the source dependency analysis and
the target dependency analysis are unordered trees,
ie, dependency transfer and word ordering are mod-
elled as two separate processes. In this paper, we
only look at the dependency transfer and ignore the
word ordering, as well as the probabilistic modelling
of the rules for transfer and word ordering. There are
three kinds of translation rules in the model:
A. Complement rules have the form T(x)↔T0(x0)
where T(x) is a source dependency tree with vari-
ables x = (x1,...,xn), T0(x0) is a target dependency
tree with variables x0 = (x01,...,x0n), the words in T
are aligned to the words in T0, and the variables xk,x0k
denote parallel source and target subtrees. The rule
states that a source tree T(x) can be transferred into
a target tree T0(x0) by transferring the source sub-
trees in x into the target subtrees in x0.
B. Adjunct rules have the form (x ←a T(y))↔
(x0 a0←−T0(y0)) where T(y) is a source dependency
tree, T0(y0) is a target dependency tree, and x,x0 are
variables that denote parallel adjunct subtrees with
adjunct roles a,a0, respectively. The rule states that
given a translation unit T(y)↔T(y0), an a-adjunct
of any word in T can be translated into an a0-adjunct
of any word in T0.2
</bodyText>
<listItem confidence="0.84186575">
C. Addition/deletion rules have the form T(y)↔
(x0a0←−T0(y0)) and (xa←−T(y))↔T0(y0) where x,x0
are variables that denote adjunct subtrees, and a,a0
are adjunct relations. The addition rule states that
an adjunct subtree x0 can be introduced into the tar-
get tree T0 in a translation unit T(y)↔T(y0) without
any corresponding adjunct in the source tree T. Sim-
ilarly, the deletion rule states that the adjunct subtree
</listItem>
<footnote confidence="0.735424333333333">
2In the form stated here, adjunct rules obviously overgener-
ate because they do not place any restrictions on the words in T0
that the target adjunct can attach to. In a full-fledged translation
model, the adjunct rules must be augmented with a probabilistic
model that can keep track of these restrictions.
subj dobj vobj mod pobj nobj
</footnote>
<figureCaption confidence="0.9547815">
Figure 4: Parallel dependency analysis that is in-
compatible with our translation model.
</figureCaption>
<bodyText confidence="0.997887">
x in the source tree T does not have to correspond to
any adjunct in the target tree T0.3
The translation model places severe restrictions
on the parallel dependency annotations. For exam-
ple, the annotation in Figure 4 is incompatible with
our proposed translation model with respect to the
adjunct “only’, since “only” attaches to the verb
“skal/must” in the Danish analysis, but attaches to
the preposition “on” in the English analysis — ie, it
does not satisfy a requirement that follows implicitly
from the adjunct rule: that corresponding source and
target adjunct governors must belong to the same
translation unit. In our example, there are two ways
of rectifying the problem: we can (a) correct the de-
pendency analysis as shown in Figure 2, or (b) cor-
rect the word alignment as shown in Figure 5.
It can be shown that our translation model trans-
lates into the following four requirements on paral-
lel analyses — ie, the requirements are necessary
and sufficient for ensuring that the linguistic anno-
tations are compatible with our translation model.
In the following, two words are said to be coaligned
if they belong to the same alignment edge. A de-
pendency edge d r←−g is called internal if d and g
are coaligned, and external otherwise. A word w is
called singular if it fails to be coaligned with at least
one word in the other language.
</bodyText>
<tableCaption confidence="0.7928575">
Requirement I. The internal dependencies within
a translation unit must form two connected trees. Ie,
3As with adjunct rules, addition/deletion rules obviously
overgenerate, and must be augmented with probabilistic mod-
els that keep track of the precise characteristics of the adjunct
subtrees that are added to or deleted from the parallel analyses.
</tableCaption>
<figure confidence="0.980823526315789">
subj mod vobj dobj pobj nobj
X has to concentrate only on Y
X
X
skal
must
kun
only
koncentrere
concentrate
sig
self
om
about
Y
Y
C
72
subj dobj vobj mod pobj nobj
</figure>
<figureCaption confidence="0.988295666666667">
Figure 5: Making the analysis from Figure 4 com-
patible with our translation model by changing the
alignment edges.
</figureCaption>
<bodyText confidence="0.988846466666667">
in an alignment W ↔W0, the internal dependencies
within W must form a connected source tree, and
similarly for W0.
Requirement II. The external dependencies be-
tween translation units must form an acyclic graph.
Ie, in an alignment W ↔W0, no word w ∈ W can be
coaligned with an external transitive dependent of
any word in W0, and vice versa.
Requirement III. Parallel external governors must
be aligned to each other. Ie, if two nodes n,n0 are
coaligned with external governor edges nr←−g and
n0 ←r0 g0, then g and g0 must be coaligned.
Requirement IV. The graph contains no singular
external complements. If the source word c is a com-
plement of governor g and c is not coaligned to any
target word, then c and g must be coaligned to each
other; and similarly for target complements.
A graph that satisfies all four requirements is said
to be well-formed with respect to our translation
model. It can be shown that we can always trans-
form an ill-formed graph G into a well-formed graph
G0 by merging alignment edges; G0 is then called a
reduction of G, and a reduction with a minimal num-
ber of mergings is called a minimal reduction of G.
In a well-formed graph, we will refer to an align-
ment edge and its associated source and target de-
pendency tree as a translation unit.
It can be shown that minimal reductions can be
computed by means of the algorithm shown in Fig-
ure 6.4 The body of the for-loop in Figure 6 ensures
</bodyText>
<footnote confidence="0.9438395">
4In the algorithm, G is viewed as a directed graph that con-
tains the source and target dependencies, and alignment edges
</footnote>
<figure confidence="0.560894875">
procedure minimal-reduction(graph G)
merge each alignment edge in G with itself
(ie, ensure int. connectedness &amp; ext. acyclicity)
for each W ↔W0 in bottom-up order do
merge W ↔W0 with all of its external
singular complements
merge all external governors of W ↔W0
return the modified graph G
</figure>
<figureCaption confidence="0.678196333333333">
Figure 6: Algorithm for computing the minimal re-
duction of a graph G.
Requirements III (coaligned external governors) and
IV (no singular complements), and the merging op-
eration is designed so that it ensures Requirements I
(internal connectedness) and II (acyclicity).5
</figureCaption>
<bodyText confidence="0.999536875">
The ill-formed analysis in Figure 4 has the mini-
mal reduction shown in Figure 2, whereas the anal-
yses in Figure 2 and 5 are well-formed, ie, they are
their own minimal reductions. In the remainder of
the paper, we will describe how minimal reductions
and translation units can be used for extracting trans-
ferrules, detecting annotation errors, and comparing
different annotation schemes with each other.
</bodyText>
<sectionHeader confidence="0.6845595" genericHeader="method">
4 Extracting transfer rules and
quantifying parallelism
</sectionHeader>
<bodyText confidence="0.753776866666667">
The complement, adjunct, and addition/deletion
rules in our simple dependency transfer model can
be read off directly from the minimal reductions.
Figure 7 shows the three complement rules induced
from Figure 4 via the minimal reduction in Figure
5. Figure 8 (repeated from Figure 3) shows the six
complement rules induced from the alternative anal-
ysis in Figure 2.
We have tested the extraction procedure on a
large scale by applying it to the 100,000 word
Copenhagen Danish-English Dependency Treebank
(Buch-Kromann et al., 2007). Figure 9 shows the
percentage of translation units with size at least n
W ↔W0 are viewed as short-hands for the set of all bidirectional
edges that link two distinct nodes in W ∪W0.
</bodyText>
<footnote confidence="0.735299">
5The merging operation performs three steps: (a) replace
two alignment edges W1 ↔W01 and W2 ↔W0 2 with their union
W ↔W0 where W = W1 ∪W2 and W0 = W0 1 ∪W02; (b) merge
W ↔W0 with the smallest set of nodes that turns W and W0 into
connected dependency trees; (c) merge W ↔W0 with all nodes
on cycles that involve at least one node from W ↔W0.
</footnote>
<figure confidence="0.95171535">
subj mod vobj dobj pobj nobj
X has to concentrate only on Y
X
X
skal
must
kun
only
koncentrere
concentrate
sig
self
om
about
Y
Y
C
73
subj vobj dobj pobj nobj
subj dobj vobj pobj nobj
</figure>
<figureCaption confidence="0.999999">
Figure 8: The six complement rules induced from
the minimal reduction in Figure 2 (repeated from
Figure 3).
</figureCaption>
<figure confidence="0.691035052631579">
normal scale logarithmic scale
(solid line) (dotted line)
100% 100%
90% 10%
80%
70%
60%
50%
40%
30%
20%
10%
0%
percent 1%
tunits with 0.1%
size ≥ n 0.01%
0.001%
2 10 20 30 40 50
translation unit size n
</figure>
<figureCaption confidence="0.9419725">
Figure 9: The percentage of translation units in the
Copenhagen Danish-English Dependency Treebank
with size at least n, plotted on normal and logarith-
mic scales.
</figureCaption>
<bodyText confidence="0.962149979591837">
in the parallel treebank, where the size of a transla-
tion unit is measured as the number of nodes in the
associated complement transfer rule. The extracted
transfer rules are useful for many purposes, includ-
ing machine translation, lexicography, contrastive
To the human annotator who must check the word-
aligned dependency analyses in a parallel depen-
dency treebank, the analyses in Figure 2 and Fig-
ure 4 look almost identical. However, from the in-
duced translation units and the associated comple-
ment rules shown above, it would have been im-
mediately obvious to the annotator that the analy-
sis in Figure 2 is significantly better than the analy-
sis in Figure 4. This suggests that we can increase
the quality of the human annotation in parallel tree-
bank projects by designing annotation tools that con-
tinuously compute the induced translation units and
present them visibly to the human annotator.
From a linguistic point of view, it can be expected
that errors in the dependency annotation will often
� show up as non-parallelism that results in a large
induced translation unit. So in a parallel depen-
dency treebank, we can identify the most egregious
examples of non-parallelism errors automatically by
computing the induced translation units, and sorting
them with respect to their size; the largest translation
units will then have a high probability of being the
result of annotation errors.
To confirm our linguistic expectation that large
translation units are often caused by annotation er-
rors, we have selected a sample of 75 translation
units from the Copenhagen Danish-English Depen-
dency Treebank, distributed more or less uniformly
with respect to translation unit size in order to ensure
that all translation unit sizes are sampled evenly. We
have then hand-checked each translation unit care-
fully in order to determine whether the translation
unit contains any annotation errors or not, giving us
a data set of the form (C,N) where N is the size
of the translation unit and C indicates whether the
translation unit is correct (C = 1) or not (C = 0).
Figure 10 shows our maximum likelihood estimate
of the conditional probability P(C = 1|N = n) that
a translation unit with size n is correct.6 From the
6In order to estimate the conditional probability p(n) =
P(C = 1|S = n) that a translation unit with size n is correct, we
have fitted p(n) to the parametric family p(n) = eo by means
of conditional maximum likelihood estimation with conditional
likelihood L = ∏75
</bodyText>
<page confidence="0.382483">
+=1 p(n+)&apos;+(1− p(n+))1−&apos;+. The resulting esti-
</page>
<figure confidence="0.99484847368421">
subj vobj dobj pobj nobj
X
X
x1
x1
skal
must
koncentrere
concentrate
sig
self
om
about
x2
x2
Y
Y
X x1’ has to concentrate on x2’ Y
subj dobj vobj pobj nobj
</figure>
<figureCaption confidence="0.9999985">
Figure 7: The three complement rules induced from
Figure 4 via the minimal reduction in Figure 5.
</figureCaption>
<figure confidence="0.98571824137931">
I
X x1’ has to x2’ concentrate x1’ only on x1’ Y
X
X
x1
x1
skal
must
x2
x2
koncentrere
concentrate
sig
self
x1
x1
kun
only
om
about
x1
x1
Y
Y
linguistics, and translation studies, but describing
these applications is outside the scope of this paper.
5 Spotting annotation errors
74
translation unit size n
</figure>
<figureCaption confidence="0.985514666666667">
Figure 10: The estimated percentage of translation
units with size n that are correct, plotted on normal
and logarithmic scales.
</figureCaption>
<bodyText confidence="0.999895833333333">
graph, we see that the correctness rate decreases
quickly with n. For example, only 55% of all trans-
lation units with size 10 are correct, and only 13% of
all translation units with size 20 are correct. Thus,
the statistics confirm that large translation units are
often caused by annotation errors in the treebank,
so focusing the effort on large translation units can
make the postediting more cost-efficient. This also
suggests that when developing algorithms for auto-
matic annotation of parallel dependency treebanks,
the algorithms can improve their accuracy by penal-
izing large translation units.
</bodyText>
<sectionHeader confidence="0.978239" genericHeader="method">
6 Comparing annotation schemes
</sectionHeader>
<bodyText confidence="0.987293521739131">
Translation units can also be used to compare dif-
ferent annotation schemes. This is relevant in par-
allel treebank projects where there are several pos-
sible annotation schemes for one of the languages
— eg, because there is more than one treebank or
rule-based parser for that language. In this situa-
tion, we have the freedom of choosing the anno-
tation schemes for the source and target languages
so that they maximize the parallelism between the
source and target language annotations. To make an
informed choice, we can create a small pilot parallel
treebank for each annotation scheme, and compare
mates are &amp; = 0.99 and �ˆ = 1.77 with confidence value 0.87, ie,
if a data set D with the same translation unit sizes is generated
ˆ�
randomly from the distribution ˆp(n) = ˆ�n, then the conditional
likelihood of D will be larger than the likelihood of our observed
data set in 87% of the cases. This means that a two-sided test
does not reject that the data are generated from the estimated
distribution ˆp(n).
the treebank annotations qualitatively by looking at
their induced translation units, and quantitatively by
looking at their average translation unit size. The
best choice of annotation schemes is then the com-
bination that leads to the smallest and most sensible
translation units.
Since texts are always trivially word-aligned with
themselves, the same procedure applies to monolin-
gual corpora where we want to compare two differ-
ent dependency annotations with each other. In this
setup, structural differences between the two mono-
lingual annotation schemes will show up as large
translation units. While these structural differences
between annotation schemes could have been re-
vealed by careful manual inspection, the automatic
computation of translation units speeds up the pro-
cess of identifying the differences. The method also
suggests that the conversion from one annotation
scheme to another can be viewed as a machine trans-
lation problem — that is, if we can create a machine
translation algorithm that learns to translate from
one language to another on the basis of a parallel
dependency treebank, then this algorithm can also
be used to convert from one dependency annotation
scheme to another, given a training corpus that has
been annotated with both annotation schemes.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999685625">
In this paper, we have addressed the problem that
the linguistic annotations in parallel treebanks often
fail to correspond to meaningful translation units,
because of internal incompatibilities between the de-
pendency analyses and the word alignment. We have
defined a meaningful notion of translation units and
provided an algorithm for computing these transla-
tion units from any parallel dependency treebank.
Finally, we have sketched how our notion of trans-
lation units can be used to aid the creation of par-
allel dependency treebanks by using the translation
units as a visual aid for the human annotator, by us-
ing translation unit sizes to identify likely annota-
tion errors, and by allowing a quantitative and qual-
itative comparison of different annotation schemes,
both for parallel and monolingual treebanks.
</bodyText>
<figure confidence="0.99369824">
normal scale
(solid line)
logarithmic scale
(dotted line)
2 10 20 30 40 50
100%
90%
80%
70%
est. percent
correct tunits
with size = n
30%
20%
10%
0%
100%
10%
1%
0.1%
0.01%
0.001%
60%
50%
40%
</figure>
<page confidence="0.989625">
75
</page>
<sectionHeader confidence="0.997594" genericHeader="acknowledgments">
8 Acknowledgments
</sectionHeader>
<bodyText confidence="0.99994825">
The work was supported by two grants from
the Danish Research Council for the Humanities.
Thanks to the anonymous reviewers for their help-
ful comments.
</bodyText>
<sectionHeader confidence="0.999174" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999686322580645">
Matthias Buch-Kromann, J¨urgen Wedekind, and Jakob
Elming. 2007. The Copenhagen Danish-English De-
pendency Treebank. http://www.id.cbs.dk/∼mbk/ddt-
en.
Matthias Buch-Kromann. 2006. Discontinuous
Grammar. A dependency-based model of human
parsing and language learning. Dr.ling.merc.
dissertation, Copenhagen Business School.
http://www.id.cbs.dk/∼mbk/thesis.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on Multilingual Dependency Parsing. In
Proc. CoNLL-2006.
A. Cahill, M. Burke, R. O’Donovan, J. van Genabith, and
A. Way. 2004. Long-distance dependency resolution
in automatically acquired wide-coverage PCFG-based
LFG approximations. In Proc. of ACL-2004.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2).
Martin ˇCmejrek, Jan Cuˇr´ın, Jiˇr´ı Havelka, Jan Hajiˇc, and
Vladislav Kuboˇn. 2004. Prague Czech-English De-
pendency Treebank. Syntactically annotated resources
for machine translation. In Proc. LREC-2004.
Lea Cyrus. 2006. Building a resource for studying trans-
lation shifts. In Proc. LREC-2006.
Yuan Ding and Martha Palmer. 2005. Machine transla-
tion using Probabilistic Synchronous Dependency In-
sertion Grammars. In Proc. ACL-2005.
Yuan Ding. 2006. Machine translation using Prob-
abilistic Synchronous Dependency Insertion Gram-
mars. Ph.D. thesis, Univ. of Pennsylvania.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What’s in a translation rule? In Proc.
HLT/NAACL-2004.
Chung-hye Han, Na-Rae Han, Eon-Suk Ko, and Martha
Palmer. 2002. Development and evaluation of a Ko-
rean treebank and its application to NLP. In Proc.
LREC-2002.
Silvia Hansen-Schirra, Stella Neumann, and Mihaela
Vela. 2006. Multi-dimensional annotation and align-
ment in an English-German translation corpus. In
Proc. NLPXML-2006.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
HLT/NAACL-2003.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and
Kevin Knight. 2006. SPMT: Statistical machine trans-
lation with syntactified target language phrases. In
Proc. EMNLP-2006.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal SMT. In Proc. ACL-2005.
Yvonne Samuelsson and Martin Volk. 2006. Phrase
alignment in parallel treebanks. In Proc. TLT-2006.
K. Uchimoto, Y. Zhang, K. Sudo, M. Murata, S. Sekine,
and H. Isahara. 2004. Multilingual aligned parallel
treebank corpus reflecting contextual information and
its applications. In Proc. MLR-2004.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Proc. ACL-2001.
</reference>
<page confidence="0.991622">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.362511">
<title confidence="0.999101">Computing translation units and quantifying in parallel dependency treebanks</title>
<author confidence="0.993286">Matthias</author>
<affiliation confidence="0.992367">ISV Computational Linguistics Copenhagen Business</affiliation>
<email confidence="0.957023">mbk.isv@cbs.dk</email>
<abstract confidence="0.972008357142857">The linguistic quality of a parallel treebank depends crucially on the parallelism between the source and target language annotations. We propose a linguistic notion of translation units and a quantitative measure of parallelism for parallel dependency treebanks, and demonstrate how the proposed translation units and parallelism measure can be used to compute transfer rules, spot annotation errors, and compare different annotation schemes with respect to each other. The proposal is evaluated on the 100,000 word Copenhagen Danish-English</abstract>
<intro confidence="0.488281">Dependency Treebank.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Matthias Buch-Kromann</author>
<author>J¨urgen Wedekind</author>
<author>Jakob Elming</author>
</authors>
<title>The Copenhagen Danish-English Dependency Treebank.</title>
<date>2007</date>
<note>http://www.id.cbs.dk/∼mbk/ddten.</note>
<contexts>
<context position="2055" citStr="Buch-Kromann et al., 2007" startWordPosition="291" endWordPosition="294"> whether noun phrases are headed by nouns or determiners, whether conjunctions are headed by the first conjunct or the coordinator, whether prepositions are analyzed as heads or adjuncts in prepositional phrases, etc. 69 In this paper, we focus on parallel dependency treebanks that consist of source texts and translations annotated with dependency analyses and word-alignments. These requirements are directly satisfied by the analytical layer of the Prague Czech-English Dependency Treebank (ˇCmejrek et al., 2004) and by the dependency layer of the Copenhagen Danish-English Dependency Treebank (Buch-Kromann et al., 2007). The requirements are also indirectly satisifed by parallel treebanks with a constituent layer and a word alignment, eg (Han et al., 2002; Cyrus, 2006; Hansen-Schirra et al., 2006; Samuelsson and Volk, 2006), since it is possible to transform constituent structures into dependency structures — a procedure used in the CoNLL shared tasks in 2006 and 2007 (Buchholz and Marsi, 2006). Finally, it is worth pointing out that the requirements are also met by any corpus equipped with two different dependency annotations since a text is always trivially word-aligned with itself. The methods proposed in</context>
<context position="18930" citStr="Buch-Kromann et al., 2007" startWordPosition="3075" endWordPosition="3078">nt annotation schemes with each other. 4 Extracting transfer rules and quantifying parallelism The complement, adjunct, and addition/deletion rules in our simple dependency transfer model can be read off directly from the minimal reductions. Figure 7 shows the three complement rules induced from Figure 4 via the minimal reduction in Figure 5. Figure 8 (repeated from Figure 3) shows the six complement rules induced from the alternative analysis in Figure 2. We have tested the extraction procedure on a large scale by applying it to the 100,000 word Copenhagen Danish-English Dependency Treebank (Buch-Kromann et al., 2007). Figure 9 shows the percentage of translation units with size at least n W ↔W0 are viewed as short-hands for the set of all bidirectional edges that link two distinct nodes in W ∪W0. 5The merging operation performs three steps: (a) replace two alignment edges W1 ↔W01 and W2 ↔W0 2 with their union W ↔W0 where W = W1 ∪W2 and W0 = W0 1 ∪W02; (b) merge W ↔W0 with the smallest set of nodes that turns W and W0 into connected dependency trees; (c) merge W ↔W0 with all nodes on cycles that involve at least one node from W ↔W0. subj mod vobj dobj pobj nobj X has to concentrate only on Y X X skal must </context>
</contexts>
<marker>Buch-Kromann, Wedekind, Elming, 2007</marker>
<rawString>Matthias Buch-Kromann, J¨urgen Wedekind, and Jakob Elming. 2007. The Copenhagen Danish-English Dependency Treebank. http://www.id.cbs.dk/∼mbk/ddten.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Buch-Kromann</author>
</authors>
<title>Discontinuous Grammar. A dependency-based model of human parsing and language learning.</title>
<date>2006</date>
<institution>Copenhagen Business School.</institution>
<note>Dr.ling.merc. dissertation,</note>
<contexts>
<context position="5314" citStr="Buch-Kromann, 2006" startWordPosition="794" endWordPosition="795">r function to the subset W&apos; of words in the target text. The translations may contain additions or deletions, ie, W and W&apos; may be empty. We also assume that a dependency edge g r�d encodes a complement or adjunct relation between a word g (the governor) and a complement or adjunct phrase headed by the word d (the dependent), where the edge label r specifies the complement or adjunct dependency role.1 As an illustration of how complement and adjunct relations can be encoded by means of dependency roles, the most important dependency roles used in the dependency framework Discontinuous Grammar (Buch-Kromann, 2006) are shown in Figure 1. Finally, we will assume that the dependencies form a tree (or a forest). The tree may be non-projective, ie, it may contain crossing branches (technically, a dependency g r��d is projective if 1Following standard dependency theoretic assumptions, we will assume the following differences between complement and adjunct relations: (a) complements are lexically licensed by their governor, whereas adjuncts license their adjunct governor; (b) in the functor-argument structure, complements act as arguments of their governor, whereas adjuncts act as modifiers of their governor;</context>
</contexts>
<marker>Buch-Kromann, 2006</marker>
<rawString>Matthias Buch-Kromann. 2006. Discontinuous Grammar. A dependency-based model of human parsing and language learning. Dr.ling.merc. dissertation, Copenhagen Business School. http://www.id.cbs.dk/∼mbk/thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on Multilingual Dependency Parsing. In</title>
<date>2006</date>
<booktitle>Proc. CoNLL-2006.</booktitle>
<contexts>
<context position="2437" citStr="Buchholz and Marsi, 2006" startWordPosition="351" endWordPosition="354">se requirements are directly satisfied by the analytical layer of the Prague Czech-English Dependency Treebank (ˇCmejrek et al., 2004) and by the dependency layer of the Copenhagen Danish-English Dependency Treebank (Buch-Kromann et al., 2007). The requirements are also indirectly satisifed by parallel treebanks with a constituent layer and a word alignment, eg (Han et al., 2002; Cyrus, 2006; Hansen-Schirra et al., 2006; Samuelsson and Volk, 2006), since it is possible to transform constituent structures into dependency structures — a procedure used in the CoNLL shared tasks in 2006 and 2007 (Buchholz and Marsi, 2006). Finally, it is worth pointing out that the requirements are also met by any corpus equipped with two different dependency annotations since a text is always trivially word-aligned with itself. The methods proposed in the paper therefore apply to a wide range of parallel treebanks, as well as to comparing two monolingual treebank annotations with each other. The paper is structured as follows. In section 2, we define our notions of word alignments and dependencies. In section 3, we define our notion of translation units and state an algorithm for computing the translation units in a parallel </context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on Multilingual Dependency Parsing. In Proc. CoNLL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Cahill</author>
<author>M Burke</author>
<author>R O’Donovan</author>
<author>J van Genabith</author>
<author>A Way</author>
</authors>
<title>Long-distance dependency resolution in automatically acquired wide-coverage PCFG-based LFG approximations.</title>
<date>2004</date>
<booktitle>In Proc. of ACL-2004.</booktitle>
<marker>Cahill, Burke, O’Donovan, van Genabith, Way, 2004</marker>
<rawString>A. Cahill, M. Burke, R. O’Donovan, J. van Genabith, and A. Way. 2004. Long-distance dependency resolution in automatically acquired wide-coverage PCFG-based LFG approximations. In Proc. of ACL-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="9724" citStr="Chiang, 2007" startWordPosition="1528" endWordPosition="1529">nish dependency tree with terminals “x1 skal x2” can be translated into an English dependency tree with terminals “x01 has to x02” where the English phrases x01,x02 are translations of the Danish phrases x1,x2, and vice versa. In the following section, we will go deeper into subj vobj dobj pobj nobj subj dobj vobj pobj nobj Figure 3: The six translation units derived from the parallel dependency analysis in Figure 2. the definition and interpretation of these rules. In particular, unlike the essentially context-free translation rules used in frameworks such as (Quirk et al., 2005; Ding, 2006; Chiang, 2007), we will not assume that the words in the translation rules are ordered, and that the translation rules can only be used in a way that leads to projective dependency trees. 3 Translation units within a simple dependency-based translation model In many parallel treebanks, word alignments and syntactic annotations are created independently of each other, and there is therefore no guarantee that the word or phrase alignments coincide with any meaningful notion of translation units. To rectify this problem, we need to define a notion of translation units that links the word alignments and the sou</context>
<context position="11058" citStr="Chiang, 2007" startWordPosition="1744" endWordPosition="1745">set of word alignments from the actual treebank annotation. Statistical machine translation models often embody an explicit notion of translation units. However, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (Galley et al., 2004; Marcu et al., 2006; Koehn et al., 2003). Other SMT models assume translation units where the source and target language annotation is based on either contextfree grammar (Yamada and Knight, 2001; Chiang, 2007) or context-free dependency grammar (Quirk et al., 2005; Ding, 2006). However, since nonX x1’ has to x2’ concentrate x1’ only on x1’ Y X X x1 x1 skal must x2 x2 koncentrere concentrate sig self x1 x1 kun only om about x1 x1 Y Y C 71 projectivity is not directly compatible with contextfree grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly, the context-free SMT models are not directly applicable to parallel dependency treebanks in general. But the context-free SMT models are an important inspiration for the simple dependency-based translation model an</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin ˇCmejrek</author>
<author>Jan Cuˇr´ın</author>
<author>Jiˇr´ı Havelka</author>
<author>Jan Hajiˇc</author>
<author>Vladislav Kuboˇn</author>
</authors>
<title>Prague Czech-English Dependency Treebank. Syntactically annotated resources for machine translation. In</title>
<date>2004</date>
<booktitle>Proc. LREC-2004.</booktitle>
<marker>ˇCmejrek, Cuˇr´ın, Havelka, Hajiˇc, Kuboˇn, 2004</marker>
<rawString>Martin ˇCmejrek, Jan Cuˇr´ın, Jiˇr´ı Havelka, Jan Hajiˇc, and Vladislav Kuboˇn. 2004. Prague Czech-English Dependency Treebank. Syntactically annotated resources for machine translation. In Proc. LREC-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lea Cyrus</author>
</authors>
<title>Building a resource for studying translation shifts.</title>
<date>2006</date>
<booktitle>In Proc. LREC-2006.</booktitle>
<contexts>
<context position="997" citStr="Cyrus, 2006" startWordPosition="135" endWordPosition="136">nd a quantitative measure of parallelism for parallel dependency treebanks, and demonstrate how the proposed translation units and parallelism measure can be used to compute transfer rules, spot annotation errors, and compare different annotation schemes with respect to each other. The proposal is evaluated on the 100,000 word Copenhagen Danish-English Dependency Treebank. 1 Introduction Parallel treebanks are increasingly seen as a valuable resource for many different tasks, including machine translation, word alignment, translation studies and contrastive linguistics (ˇCmejrek et al., 2004; Cyrus, 2006; Hansen-Schirra et al., 2006). However, the usefulness of a parallel treebank for these purposes is directly correlated with the degree of syntactic parallelism in the treebank. Some non-parallelism is inevitable because two languages always differ with respect to their syntactic structure. But nonparallelism can also be the result of differences in the linguistic analyses of the source text and target text, eg, with respect to whether noun phrases are headed by nouns or determiners, whether conjunctions are headed by the first conjunct or the coordinator, whether prepositions are analyzed as</context>
</contexts>
<marker>Cyrus, 2006</marker>
<rawString>Lea Cyrus. 2006. Building a resource for studying translation shifts. In Proc. LREC-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Ding</author>
<author>Martha Palmer</author>
</authors>
<title>Machine translation using Probabilistic Synchronous Dependency Insertion Grammars. In</title>
<date>2005</date>
<booktitle>Proc. ACL-2005.</booktitle>
<marker>Ding, Palmer, 2005</marker>
<rawString>Yuan Ding and Martha Palmer. 2005. Machine translation using Probabilistic Synchronous Dependency Insertion Grammars. In Proc. ACL-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Ding</author>
</authors>
<title>Machine translation using Probabilistic Synchronous Dependency Insertion Grammars.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>Univ. of Pennsylvania.</institution>
<contexts>
<context position="9709" citStr="Ding, 2006" startWordPosition="1526" endWordPosition="1527">ng that a Danish dependency tree with terminals “x1 skal x2” can be translated into an English dependency tree with terminals “x01 has to x02” where the English phrases x01,x02 are translations of the Danish phrases x1,x2, and vice versa. In the following section, we will go deeper into subj vobj dobj pobj nobj subj dobj vobj pobj nobj Figure 3: The six translation units derived from the parallel dependency analysis in Figure 2. the definition and interpretation of these rules. In particular, unlike the essentially context-free translation rules used in frameworks such as (Quirk et al., 2005; Ding, 2006; Chiang, 2007), we will not assume that the words in the translation rules are ordered, and that the translation rules can only be used in a way that leads to projective dependency trees. 3 Translation units within a simple dependency-based translation model In many parallel treebanks, word alignments and syntactic annotations are created independently of each other, and there is therefore no guarantee that the word or phrase alignments coincide with any meaningful notion of translation units. To rectify this problem, we need to define a notion of translation units that links the word alignme</context>
<context position="11126" citStr="Ding, 2006" startWordPosition="1754" endWordPosition="1755">l machine translation models often embody an explicit notion of translation units. However, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (Galley et al., 2004; Marcu et al., 2006; Koehn et al., 2003). Other SMT models assume translation units where the source and target language annotation is based on either contextfree grammar (Yamada and Knight, 2001; Chiang, 2007) or context-free dependency grammar (Quirk et al., 2005; Ding, 2006). However, since nonX x1’ has to x2’ concentrate x1’ only on x1’ Y X X x1 x1 skal must x2 x2 koncentrere concentrate sig self x1 x1 kun only om about x1 x1 Y Y C 71 projectivity is not directly compatible with contextfree grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly, the context-free SMT models are not directly applicable to parallel dependency treebanks in general. But the context-free SMT models are an important inspiration for the simple dependency-based translation model and notion of translation units that we will present below. In our tra</context>
</contexts>
<marker>Ding, 2006</marker>
<rawString>Yuan Ding. 2006. Machine translation using Probabilistic Synchronous Dependency Insertion Grammars. Ph.D. thesis, Univ. of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule? In</title>
<date>2004</date>
<booktitle>Proc. HLT/NAACL-2004.</booktitle>
<contexts>
<context position="10847" citStr="Galley et al., 2004" startWordPosition="1707" endWordPosition="1710">blem, we need to define a notion of translation units that links the word alignments and the source and target dependency analysis in a meaningful way, and we need to specify a procedure for constructing a meaningful set of word alignments from the actual treebank annotation. Statistical machine translation models often embody an explicit notion of translation units. However, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (Galley et al., 2004; Marcu et al., 2006; Koehn et al., 2003). Other SMT models assume translation units where the source and target language annotation is based on either contextfree grammar (Yamada and Knight, 2001; Chiang, 2007) or context-free dependency grammar (Quirk et al., 2005; Ding, 2006). However, since nonX x1’ has to x2’ concentrate x1’ only on x1’ Y X X x1 x1 skal must x2 x2 koncentrere concentrate sig self x1 x1 kun only om about x1 x1 Y Y C 71 projectivity is not directly compatible with contextfree grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly, the</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In Proc. HLT/NAACL-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chung-hye Han</author>
<author>Na-Rae Han</author>
<author>Eon-Suk Ko</author>
<author>Martha Palmer</author>
</authors>
<title>Development and evaluation of a Korean treebank and its application to NLP. In</title>
<date>2002</date>
<booktitle>Proc. LREC-2002.</booktitle>
<contexts>
<context position="2193" citStr="Han et al., 2002" startWordPosition="313" endWordPosition="316">ions are analyzed as heads or adjuncts in prepositional phrases, etc. 69 In this paper, we focus on parallel dependency treebanks that consist of source texts and translations annotated with dependency analyses and word-alignments. These requirements are directly satisfied by the analytical layer of the Prague Czech-English Dependency Treebank (ˇCmejrek et al., 2004) and by the dependency layer of the Copenhagen Danish-English Dependency Treebank (Buch-Kromann et al., 2007). The requirements are also indirectly satisifed by parallel treebanks with a constituent layer and a word alignment, eg (Han et al., 2002; Cyrus, 2006; Hansen-Schirra et al., 2006; Samuelsson and Volk, 2006), since it is possible to transform constituent structures into dependency structures — a procedure used in the CoNLL shared tasks in 2006 and 2007 (Buchholz and Marsi, 2006). Finally, it is worth pointing out that the requirements are also met by any corpus equipped with two different dependency annotations since a text is always trivially word-aligned with itself. The methods proposed in the paper therefore apply to a wide range of parallel treebanks, as well as to comparing two monolingual treebank annotations with each o</context>
</contexts>
<marker>Han, Han, Ko, Palmer, 2002</marker>
<rawString>Chung-hye Han, Na-Rae Han, Eon-Suk Ko, and Martha Palmer. 2002. Development and evaluation of a Korean treebank and its application to NLP. In Proc. LREC-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silvia Hansen-Schirra</author>
<author>Stella Neumann</author>
<author>Mihaela Vela</author>
</authors>
<title>Multi-dimensional annotation and alignment in an English-German translation corpus.</title>
<date>2006</date>
<booktitle>In Proc. NLPXML-2006.</booktitle>
<contexts>
<context position="1027" citStr="Hansen-Schirra et al., 2006" startWordPosition="137" endWordPosition="140">tive measure of parallelism for parallel dependency treebanks, and demonstrate how the proposed translation units and parallelism measure can be used to compute transfer rules, spot annotation errors, and compare different annotation schemes with respect to each other. The proposal is evaluated on the 100,000 word Copenhagen Danish-English Dependency Treebank. 1 Introduction Parallel treebanks are increasingly seen as a valuable resource for many different tasks, including machine translation, word alignment, translation studies and contrastive linguistics (ˇCmejrek et al., 2004; Cyrus, 2006; Hansen-Schirra et al., 2006). However, the usefulness of a parallel treebank for these purposes is directly correlated with the degree of syntactic parallelism in the treebank. Some non-parallelism is inevitable because two languages always differ with respect to their syntactic structure. But nonparallelism can also be the result of differences in the linguistic analyses of the source text and target text, eg, with respect to whether noun phrases are headed by nouns or determiners, whether conjunctions are headed by the first conjunct or the coordinator, whether prepositions are analyzed as heads or adjuncts in preposit</context>
</contexts>
<marker>Hansen-Schirra, Neumann, Vela, 2006</marker>
<rawString>Silvia Hansen-Schirra, Stella Neumann, and Mihaela Vela. 2006. Multi-dimensional annotation and alignment in an English-German translation corpus. In Proc. NLPXML-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proc. HLT/NAACL-2003.</booktitle>
<contexts>
<context position="10888" citStr="Koehn et al., 2003" startWordPosition="1715" endWordPosition="1718">lation units that links the word alignments and the source and target dependency analysis in a meaningful way, and we need to specify a procedure for constructing a meaningful set of word alignments from the actual treebank annotation. Statistical machine translation models often embody an explicit notion of translation units. However, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (Galley et al., 2004; Marcu et al., 2006; Koehn et al., 2003). Other SMT models assume translation units where the source and target language annotation is based on either contextfree grammar (Yamada and Knight, 2001; Chiang, 2007) or context-free dependency grammar (Quirk et al., 2005; Ding, 2006). However, since nonX x1’ has to x2’ concentrate x1’ only on x1’ Y X X x1 x1 skal must x2 x2 koncentrere concentrate sig self x1 x1 kun only om about x1 x1 Y Y C 71 projectivity is not directly compatible with contextfree grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly, the context-free SMT models are not directly</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proc. HLT/NAACL-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Wei Wang</author>
<author>Abdessamad Echihabi</author>
<author>Kevin Knight</author>
</authors>
<title>SPMT: Statistical machine translation with syntactified target language phrases.</title>
<date>2006</date>
<booktitle>In Proc. EMNLP-2006.</booktitle>
<contexts>
<context position="10867" citStr="Marcu et al., 2006" startWordPosition="1711" endWordPosition="1714">ne a notion of translation units that links the word alignments and the source and target dependency analysis in a meaningful way, and we need to specify a procedure for constructing a meaningful set of word alignments from the actual treebank annotation. Statistical machine translation models often embody an explicit notion of translation units. However, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (Galley et al., 2004; Marcu et al., 2006; Koehn et al., 2003). Other SMT models assume translation units where the source and target language annotation is based on either contextfree grammar (Yamada and Knight, 2001; Chiang, 2007) or context-free dependency grammar (Quirk et al., 2005; Ding, 2006). However, since nonX x1’ has to x2’ concentrate x1’ only on x1’ Y X X x1 x1 skal must x2 x2 koncentrere concentrate sig self x1 x1 kun only om about x1 x1 Y Y C 71 projectivity is not directly compatible with contextfree grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly, the context-free SMT mo</context>
</contexts>
<marker>Marcu, Wang, Echihabi, Knight, 2006</marker>
<rawString>Daniel Marcu, Wei Wang, Abdessamad Echihabi, and Kevin Knight. 2006. SPMT: Statistical machine translation with syntactified target language phrases. In Proc. EMNLP-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
<author>Colin Cherry</author>
</authors>
<title>Dependency treelet translation: Syntactically informed phrasal SMT.</title>
<date>2005</date>
<booktitle>In Proc. ACL-2005.</booktitle>
<contexts>
<context position="9697" citStr="Quirk et al., 2005" startWordPosition="1522" endWordPosition="1525">anslation rule stating that a Danish dependency tree with terminals “x1 skal x2” can be translated into an English dependency tree with terminals “x01 has to x02” where the English phrases x01,x02 are translations of the Danish phrases x1,x2, and vice versa. In the following section, we will go deeper into subj vobj dobj pobj nobj subj dobj vobj pobj nobj Figure 3: The six translation units derived from the parallel dependency analysis in Figure 2. the definition and interpretation of these rules. In particular, unlike the essentially context-free translation rules used in frameworks such as (Quirk et al., 2005; Ding, 2006; Chiang, 2007), we will not assume that the words in the translation rules are ordered, and that the translation rules can only be used in a way that leads to projective dependency trees. 3 Translation units within a simple dependency-based translation model In many parallel treebanks, word alignments and syntactic annotations are created independently of each other, and there is therefore no guarantee that the word or phrase alignments coincide with any meaningful notion of translation units. To rectify this problem, we need to define a notion of translation units that links the </context>
<context position="11113" citStr="Quirk et al., 2005" startWordPosition="1750" endWordPosition="1753">notation. Statistical machine translation models often embody an explicit notion of translation units. However, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (Galley et al., 2004; Marcu et al., 2006; Koehn et al., 2003). Other SMT models assume translation units where the source and target language annotation is based on either contextfree grammar (Yamada and Knight, 2001; Chiang, 2007) or context-free dependency grammar (Quirk et al., 2005; Ding, 2006). However, since nonX x1’ has to x2’ concentrate x1’ only on x1’ Y X X x1 x1 skal must x2 x2 koncentrere concentrate sig self x1 x1 kun only om about x1 x1 Y Y C 71 projectivity is not directly compatible with contextfree grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly, the context-free SMT models are not directly applicable to parallel dependency treebanks in general. But the context-free SMT models are an important inspiration for the simple dependency-based translation model and notion of translation units that we will present belo</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Chris Quirk, Arul Menezes, and Colin Cherry. 2005. Dependency treelet translation: Syntactically informed phrasal SMT. In Proc. ACL-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yvonne Samuelsson</author>
<author>Martin Volk</author>
</authors>
<title>Phrase alignment in parallel treebanks.</title>
<date>2006</date>
<booktitle>In Proc. TLT-2006.</booktitle>
<contexts>
<context position="2263" citStr="Samuelsson and Volk, 2006" startWordPosition="323" endWordPosition="326">ses, etc. 69 In this paper, we focus on parallel dependency treebanks that consist of source texts and translations annotated with dependency analyses and word-alignments. These requirements are directly satisfied by the analytical layer of the Prague Czech-English Dependency Treebank (ˇCmejrek et al., 2004) and by the dependency layer of the Copenhagen Danish-English Dependency Treebank (Buch-Kromann et al., 2007). The requirements are also indirectly satisifed by parallel treebanks with a constituent layer and a word alignment, eg (Han et al., 2002; Cyrus, 2006; Hansen-Schirra et al., 2006; Samuelsson and Volk, 2006), since it is possible to transform constituent structures into dependency structures — a procedure used in the CoNLL shared tasks in 2006 and 2007 (Buchholz and Marsi, 2006). Finally, it is worth pointing out that the requirements are also met by any corpus equipped with two different dependency annotations since a text is always trivially word-aligned with itself. The methods proposed in the paper therefore apply to a wide range of parallel treebanks, as well as to comparing two monolingual treebank annotations with each other. The paper is structured as follows. In section 2, we define our </context>
</contexts>
<marker>Samuelsson, Volk, 2006</marker>
<rawString>Yvonne Samuelsson and Martin Volk. 2006. Phrase alignment in parallel treebanks. In Proc. TLT-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Uchimoto</author>
<author>Y Zhang</author>
<author>K Sudo</author>
<author>M Murata</author>
<author>S Sekine</author>
<author>H Isahara</author>
</authors>
<title>Multilingual aligned parallel treebank corpus reflecting contextual information and its applications. In</title>
<date>2004</date>
<booktitle>Proc. MLR-2004.</booktitle>
<marker>Uchimoto, Zhang, Sudo, Murata, Sekine, Isahara, 2004</marker>
<rawString>K. Uchimoto, Y. Zhang, K. Sudo, M. Murata, S. Sekine, and H. Isahara. 2004. Multilingual aligned parallel treebank corpus reflecting contextual information and its applications. In Proc. MLR-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proc. ACL-2001.</booktitle>
<contexts>
<context position="11043" citStr="Yamada and Knight, 2001" startWordPosition="1740" endWordPosition="1743">onstructing a meaningful set of word alignments from the actual treebank annotation. Statistical machine translation models often embody an explicit notion of translation units. However, many of these models are not applicable to parallel treebanks because they assume translation units where either the source text, the target text or both are represented as word sequences without any syntactic structure (Galley et al., 2004; Marcu et al., 2006; Koehn et al., 2003). Other SMT models assume translation units where the source and target language annotation is based on either contextfree grammar (Yamada and Knight, 2001; Chiang, 2007) or context-free dependency grammar (Quirk et al., 2005; Ding, 2006). However, since nonX x1’ has to x2’ concentrate x1’ only on x1’ Y X X x1 x1 skal must x2 x2 koncentrere concentrate sig self x1 x1 kun only om about x1 x1 Y Y C 71 projectivity is not directly compatible with contextfree grammar, and parallel dependency treebanks tend to encode non-projective dependencies directly, the context-free SMT models are not directly applicable to parallel dependency treebanks in general. But the context-free SMT models are an important inspiration for the simple dependency-based trans</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntax-based statistical translation model. In Proc. ACL-2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>