<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001100">
<title confidence="0.93733">
Be Appropriate and Funny: Automatic Entity Morph Encoding
</title>
<author confidence="0.996608">
Boliang Zhang1, Hongzhao Huang1, Xiaoman Pan1, Heng Ji1, Kevin Knight2
Zhen Wen3, Yizhou Sun4, Jiawei Han5, Bulent Yener1
</author>
<affiliation confidence="0.9466324">
1Computer Science Department, Rensselaer Polytechnic Institute
2Information Sciences Institute, University of Southern California
3IBM T. J. Watson Research Center
4College of Computer and Information Science, Northeastern University
5Computer Science Department, Univerisity of Illinois at Urbana-Champaign
</affiliation>
<email confidence="0.9716235">
1{zhangb8,huangh9,panx2,jih,yener}@rpi.edu, 2knight@isi.edu
3zhenwen@us.ibm.com, 4yzsun@ccs.neu.edu, 5hanj@illinois.edu
</email>
<sectionHeader confidence="0.99379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999851153846154">
Internet users are keen on creating differ-
ent kinds of morphs to avoid censorship,
express strong sentiment or humor. For
example, in Chinese social media, users
often use the entity morph “方4k面 (In-
stant Noodles)” to refer to “周永康 (Zhou
Yongkang)” because it shares one char-
acter “康 (Kang)” with the well-known
brand of instant noodles “康师44 (Master
Kang)”. We developed a wide variety of
novel approaches to automatically encode
proper and interesting morphs, which can
effectively pass decoding tests 1.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996151083333333">
One of the most innovative linguistic forms in so-
cial media is Information Morph (Huang et al.,
2013). Morph is a special case of alias to hide the
original objects (e.g., sensitive entities and events)
for different purposes, including avoiding censor-
ship (Bamman et al., 2012; Chen et al., 2013),
expressing strong sentiment, emotion or sarcasm,
and making descriptions more vivid. Morphs are
widely used in Chinese social media. Here is an
example morphs: “由于X*的事情,方4k面与
天线摊牌. (Because of Gua Dad’s issue, Instant
Noodles faces down with Antenna.)”, where
</bodyText>
<listItem confidence="0.985817833333333">
• “X* (Gua Dad)” refers to “4熙来 (Bo Xilai)”
because it shares one character “X (Gua)” with
“4XX (Bo Guagua)” who is the son of “4熙
来 (Bo Xilai)”;
• “方4k面 (Instant Noodles)” refers to “周 AY-
(Zhou
</listItem>
<bodyText confidence="0.964247">
K(Zhou Yongkang)” because it shares one char-
acter “康 (kang)” with the well-known instant
noodles brand “康师44 (Master Kang)”;
</bodyText>
<footnote confidence="0.988301">
1The morphing data set is available for research purposes:
http://nlp.cs.rpi.edu/data/morphencoding.tar.gz
</footnote>
<listItem confidence="0.9731165">
• “天线 (Antenna)” refers to “温家宝 (Wen Ji-
abao)” because it shares one character “宝
(baby)” with the famous children’s television
series “天线宝宝 (Teletubbies)”;
</listItem>
<bodyText confidence="0.999640555555556">
In contrast with covert or subliminal chan-
nels studied extensively in cryptography and se-
curity, Morphing provides confidentiality against
a weaker adversary which has to make a real time
or near real time decision whether or not to block
a morph within a time interval t. It will take longer
than the duration t for a morph decoder to decide
which encoding method is used and exactly how it
is used; otherwise adversary can create a codebook
and decode the morphs with a simple look up.
We note that there are other distinct characteristics
of morphs that make them different from crypto-
graphic constructs: (1) Morphing can be consid-
ered as a way of using natural language to com-
municate confidential information without encryp-
tion. Most morphs are encoded based on seman-
tic meaning and background knowledge instead
of lexical changes, so they are closer to Jargon.
</bodyText>
<listItem confidence="0.963541923076923">
(2) There can be multiple morphs for an entity.
(3) The Shannon’s Maxim “the enemy knows the
system” does not always hold. There is no com-
mon code-book or secret key between the sender
and the receiver of a morph. (4) Social networks
play an important role in creating morphs. One
main purpose of encoding morphs is to dissemi-
nate them widely so they can become part of the
new Internet language. Therefore morphs should
be interesting, fun, intuitive and easy to remem-
ber. (5) Morphs rapidly evolve over time, as some
morphs are discovered and blocked by censorship
and newly created morphs emerge.
</listItem>
<bodyText confidence="0.99502325">
We propose a brand new and challenging re-
search problem - can we automatically encode
morphs for any given entity to help users commu-
nicate in an appropriate and fun way?
</bodyText>
<page confidence="0.977585">
706
</page>
<bodyText confidence="0.549079">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 706–711,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.995788" genericHeader="introduction">
2 Approaches
</sectionHeader>
<subsectionHeader confidence="0.99985">
2.1 Motivation from Human Approaches
</subsectionHeader>
<bodyText confidence="0.999974777777778">
Let’s start from taking a close look at human’s
intentions and general methods to create morphs
from a social cognitive perspective. In Table 1
and Table 2, we summarize 548 randomly selected
morphs into different categories. In this paper we
automate the first seven human approaches, with-
out investigating the most challenging Method 8,
which requires deep mining of rich background
and tracking all events involving the entities.
</bodyText>
<subsectionHeader confidence="0.999846">
2.2 M1: Phonetic Substitution
</subsectionHeader>
<bodyText confidence="0.99997064">
Given an entity name e, we obtain its pho-
netic transcription pinyin(e). Similarly, for each
unique term t extracted from Tsinghua Weibo
dataset (Zhang et al., 2013) with one billion
tweets from 1.8 million users from 8/28/2012 to
9/29/2012, we obtain pinyin(t). According to the
Chinese phonetic transcription articulation man-
ner 2, the pairs (b, p), (d,t), (g,k), (z,c), (zh,ch),
(j,q), (sh,r), (x,h), (l,n), (c,ch), (s,sh) and (z,zh)
are mutually transformable.
If a part of pinyin(e) and pinyin(t) are identi-
cal or their initials are transformable, we substi-
tute the part of e with t to form a new morph.
For example, we can substitute the characters of
“比尔 盖茨 (Bill Gates) [Bi Er Gai Ci]” with
“鼻耳 (Nose and ear) [Bi Er]” and “盖子 (Lid)
[Gai Zi]” to form new morph “鼻耳 盖子 (Nose
and ear Lid) [Bi Er Gai Zi]”. We rank the candi-
dates based on the following two criteria: (1) If the
morph includes more negative words (based on a
gazetteer including 11,729 negative words derived
from HowNet (Dong and Dong, 1999), it’s more
humorous (Valitutti et al., 2013). (2) If the morph
includes rarer terms with low frequency, it is more
interesting (Petrovic and Matthews, 2013).
</bodyText>
<subsectionHeader confidence="0.99991">
2.3 M2: Spelling Decomposition
</subsectionHeader>
<bodyText confidence="0.9999687">
Chinese characters are ideograms, hieroglyphs
and mostly picture-based. It allows us to natu-
rally construct a virtually infinite range of combi-
nations from a finite set of basic units - radicals (Li
and Zhou, 2007). Some of these radicals them-
selves are also characters. For a given entity name
e = c1...cn, if any character ck can be decomposed
into two radicalsc1 k and c2k which are both char-
acters or can be converted into characters based
on their pictograms (e.g., the radical “艹” can be
</bodyText>
<subsectionHeader confidence="0.452312">
2http://en.wikipedia.org/wiki/Pinyin#Initials and finals
</subsectionHeader>
<bodyText confidence="0.999273818181818">
converted into“草” (grass) ), we create a morph by
replacing ck with c1kc2k in e. Here we use a charac-
ter to radical mapping table that includes 191 rad-
icals (59 of them are characters) and 1328 com-
mon characters. For example, we create a morph
“人*罗 (Person Dumb Luo)” for “保罗 (Paul)”
by decomposing “保 (Pau-)” into “人 (Person)”
and “* (Dull)”. A natural alternative is to com-
posing two chracter radicals in an entity name to
form a morph. However, very few Chinese names
include two characters with single radicals.
</bodyText>
<subsectionHeader confidence="0.999403">
2.4 M3: Nickname Generation
</subsectionHeader>
<bodyText confidence="0.99999325">
We propose a simple method to create morphs by
duplicating the last character of an entity’s first
name. For example, we create a morph “幂幂
(Mimi)” to refer to “杨 幂 (Yang Mi)”.
</bodyText>
<subsectionHeader confidence="0.998547">
2.5 M4: Translation and Transliteration
</subsectionHeader>
<bodyText confidence="0.999928818181818">
Given an entity e, we search its English translation
EN(e) based on 94,015 name translation pairs (Ji
et al., 2009). Then, if any name component in
EN(e) is a common English word, we search for
its Chinese translation based on a 94,966 word
translation pairs (Zens and Ney, 2004), and use the
Chinese translation to replace the corresponding
characters in e. For example, we create a morph
“拉里 鸟儿 (Larry bird)” for “拉里 伯 (Larry
Bird)” by replacing the last name “伯 (Bird)”
with its Chinese translation “鸟儿 (bird)”.
</bodyText>
<subsectionHeader confidence="0.99889">
2.6 M5: Semantic Interpretation
</subsectionHeader>
<bodyText confidence="0.999950818181818">
For each character ck in the first name of a given
entity name e, we search its semantic interpreta-
tion sentence from the Xinhua Chinese character
dictionary including 20,894 entries 3. If a word
in the sentence contains ck, we append the word
with the last name of e to form a new morph. Sim-
ilarly to M1, we prefer positive, negative or rare
words. For example, we create a morph “薄 MAz
(Bo Mess)” for “薄熙Az (Bo Xi Lai)” because the
semantic interpretation sentence for “Az (Lai)” in-
cludes a negative word “MAz (Mess)”.
</bodyText>
<subsectionHeader confidence="0.993811">
2.7 M6: Historical Figure Mapping
</subsectionHeader>
<bodyText confidence="0.999966857142857">
We collect a set of 38 famous historical figures
including politicians, emperors, poets, generals,
ministers and scholars from a website. For a given
entity name e, we rank these candidates by ap-
plying the resolution approach as described in our
previous work (Huang et al., 2013) to measure the
similarity between an entity and a historic figure
</bodyText>
<footnote confidence="0.953171">
3http://xh.5156edu.com/
</footnote>
<page confidence="0.983354">
707
</page>
<table confidence="0.999588625">
Category Frequency Examples
Distribution
Entity Morph Comment
(1) Avoid censorship 6.56% 4熙* (Bo Xi- B-+ 记 (B Secre- “B” is the first letter of “Bo” and “Secretary” is
lai) tary) the entity’s title.
(2) Express strong 15.77% -E勇平 (Wang 奇 迹 哥 (Miracle Sarcasm on the entity’s public speech: “It’s a mir-
sentiment, sarcasm, Yongping) Brother) acle that the girl survived (from the 2011 train col-
emotion lision)”.
(3) Be humorous or 25.91% fi幂 (Yang Mi) 嫩牛3zTj (Tender The entity’s face shape looks like the shape of fa-
make descriptions Beef Pentagon) mous KFC food “Tender Beef Pentagon”.
more vivid
Mixture 25.32% 卡 扎 菲 疯鸭J-_校 (Crazy Sarcasm on Colonel Gaddafi’s violence.
(Gaddafi) Duck Colonel)
Others 23.44% 蒋 11- 石 (Chi- 花生米 (Peanut) Joseph Stilwell, a US general in China during
ang Kai-shek) World War II, called Chiang Kai-shek “花生米
(Peanut)” in his diary because of his stubbornness.
</table>
<tableCaption confidence="0.990065">
Table 1: Morph Examples Categorized based on Human Intentions
</tableCaption>
<table confidence="0.999869416666667">
No. Category Frequency Example
Distribution
Entity Morph Comment
M1 Phonetic Sub- 12.77% 萨 科 齐 傻客Z (Silly Po- The entity’s phonetic transcript “Sa Ke Qi” is
stitution (Sarkozy) lite) similar to the morph’s “Sha Ke Qi”.
M2 Spelling De- 0.73% AA 锦 涛 (Hu *A (Old Moon) The entity’s last name is decomposed into the
composition Jintao) morph “*A (Old Moon)”?
M3 Nickname Gen- 12.41% i=*P, (Jiang 老i= (Old Jiang) The morph is a conventional name for old people
eration Zemin) with last name “Jiang”.
M4 Translation &amp; 3.28% 布Tf (Bush) 树8 (shrub) The morph is the Chinese translation of “bush”.
Transliteration
M5 Semantic Inter- 20.26% 金qA (Kim 金太阳 (Kim Sun) The character “q” in the entity name means “太
pretation Il Sung) 阳 (Sun)”.
M6 Historical Fig- 3.83% 4 熙 * (Bo 平 西 -E (Conquer The entity shares characteristics and political ex-
ure Mapping Xilai) West King) periences similar to the morph.
M7 Characteristics 20.62% 金qA (Kim 金胖+ (Kim Fat) “胖 + (Fat)” describes “金 q A (Kim Il
Modeling Il Sung) Sung)”’s appearance.
M8 Reputation and 26.09% 奥 巴 A 观 海 (Staring at Barack Obama received a calligraphy “观海 听
public perception (Obama) the sea) 涛 (Staring at sea and listening to surf)” as a
present when he visited China.
A 景涛 (Ma 咆 哮 � �L (Roar In the films Ma Jingtao starred, he always used
Jingtao) Bishop) exaggerated roaring to express various emotions.
A 英 ;L (Ma A * 统 (Ma Se- The morph derives from Ma Yingjiu’s political
Yingjiu) cession) position on cross-strait relations.
</table>
<tableCaption confidence="0.997561">
Table 2: Morph Examples Categorized based on Human Generation Methods
</tableCaption>
<bodyText confidence="0.9997165">
based on their semantic contexts. For example,
this approach generates a morph “太祖 (the First
Emperor)” for “毛*A, (Mao Zedong)” who is the
first chairman of P. R. China and “n祖 (the Sec-
ond Emperor )” for “邓小平 (Deng Xiaoping )”
who succeeded Mao.
</bodyText>
<subsectionHeader confidence="0.984687">
2.8 M7: Characteristics Modeling
</subsectionHeader>
<bodyText confidence="0.998125222222222">
Finally, we propose a novel approach to auto-
matically generate an entity’s characteristics using
Google word2vec model (Mikolov et al., 2013).
To make the vocabulary model as general as pos-
sible, we use all of the following large corpora
that we have access to: Tsinghua Weibo dataset,
Chinese Gigaword fifth edition 4 which includes
10 million news documents, TAC-KBP 2009-2013
Source Corpora (McNamee and Dang, 2009; Ji et
</bodyText>
<footnote confidence="0.734193">
4http://catalog.ldc.upenn.edu/LDC2011T13
</footnote>
<bodyText confidence="0.99662125">
al., 2010; Ji et al., 2011; Ji and Grishman, 2011)
which include 3 million news and web documents,
and DARPA BOLT program’s discussion forum
corpora with 300k threads. Given an entity e, we
compute the semantic relationship between e and
each word from these corpora. We then rank the
words by: (1) cosine similarity, (2) the same cri-
teria as in section 2.6. Finally we append the top
ranking word to the entity’s last name to obtain
a new morph. Using this method, we are able
to generate many vivid morphs such as “姚 奇才
(Yao Wizard)” for “姚 明 (Yao Ming)”.
</bodyText>
<sectionHeader confidence="0.999729" genericHeader="background">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.938469">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.9996285">
We collected 1,553,347 tweets from Chinese Sina
Weibo from May 1 to June 30, 2013. We extracted
</bodyText>
<page confidence="0.989112">
708
</page>
<bodyText confidence="0.888852333333333">
187 human created morphs based on M1-M7 for
55 person entities. Our approach generated 382
new morphs in total.
</bodyText>
<subsectionHeader confidence="0.999385">
3.2 Human Evaluation
</subsectionHeader>
<bodyText confidence="0.999718">
We randomly asked 9 Chinese native speakers
who regularly access Chinese social media and are
not involved in this work to conduct evaluation in-
dependently. We designed the following three cri-
teria based on Table 1:
</bodyText>
<listItem confidence="0.993717857142857">
• Perceivability: Who does this morph refer to?
(i) Pretty sure, (ii) Not sure, and (iii) No clues.
• Funniness: How interesting is the morph? (i)
Funny, (ii) Somewhat funny, and (iii) Not funny.
• Appropriateness: Does the morph describe the
target entity appropriately? (i) Make sense, (ii)
Make a little sense, and (iii) Make no sense.
</listItem>
<bodyText confidence="0.998269725806452">
The three choices of each criteria account for
100% (i), 50% (ii) and 0% (iii) satisfaction rate,
respectively. If the assessor correctly predicts the
target entity with the Perceivability measure, (s)he
is asked to continue to answer the Funniness and
Appropriateness questions; otherwise the Funni-
ness and Appropriateness scores are 0. The hu-
man evaluation results are shown in Table 4. The
Fleiss’s kappa coefficient among all the human as-
sessors is 0.147 indicating slight agreement.
From Table 4 we can see that overall the sys-
tem achieves 66% of the human performance
with comparable stability as human. In partic-
ular, Method 4 based on translation and translit-
eration generates much more perceivable morphs
than human because the system may search in a
larger vocabulary. Interestingly, similar encour-
aging results - system outperforms human - have
been observed by previous back-transliteration
work (Knight and Graehl, 1998).
It’s also interesting to see that human assessors
can only comprehend 76% of the human generated
morphs because of the following reasons: (1) the
morph is newly generated or it does not describe
the characteristics of the target entity well; and (2)
the target entity itself is not well known to human
assessors who do not keep close track of news top-
ics. In fact only 64 human generated morphs and
72 system generated morphs are perceivable by all
human assessors.
For Method 2, the human created morphs are
assessed as much more and funny than the sys-
tem generated ones because human creators use
this approach only if: (1). the radicals still reflect
the meaning of the character (e.g., “愁 (worry)”
is decomposed into two radicals “心秋 (heart au-
tumn)” instead of three “禾k心” (grain fire heart)
because people tend to feel sad when the leaves
fall in the autumn), (2). the morph reflects some
characteristics of the entity (e.g., “&gt;L*A, (Jiang
Zemin)” has a morph “zK工*A, (Water Engi-
neer Zemin)” because he gave many instructions
on water conservancy construction); or (3). The
morph becomes very vivid and funny (e.g., the
morph “*子AA鸟 (Muji Yue Yue Bird)” for
“*鹏” is assessed as very funny because “*
子(Muji)” looks like a Japanese name, “AA(Yue
Yue)” can also refer to a famous chubby woman,
and “鸟人 (bird man)” is a bad word referring to
bad people); or (4). The morph expresses strong
sentiment or sarcasm; or (5) The morph is the
name of another entity (e.g., the morph “古A(Gu
Yue)” for “AA锦涛(Hu Jintao)” is also the name
of a famous actor who often acts as Mao Zedong).
The automatic approach didn’t explore these intel-
ligent constraints and thus produced more boring
morph. Moreover, sometimes human creators fur-
ther exploit traditional Chinese characters, gener-
alize or modify the decomposition results.
Table 3 presents some good (with average score
above 80%) and bad (with average score below
20%) examples.
</bodyText>
<table confidence="0.968900384615385">
Good Examples
Entity Morph Method
* 拉 登 (Osama bin 笨拉o (The silly turn- M1
Laden) ing off light)
蒋介石 (Chiang Kai- 草将介石 (Grass Gen- M2
shek) eral Jie Shi)
比尔盖1 (Bill Gates) 票子盖1 (Bill Gates) M4
Bad Examples
Entity Morph Method
科比 (Kobe) S膊 (Arm) M1
梅 德韦 A 夫 梅德I (Mei Virtue) M5
(Medvedev)
AL书豪 (Jeremy Lin) 老子 (Lao Tze) M6
</table>
<tableCaption confidence="0.999845">
Table 3: System Generated Morph Examples
</tableCaption>
<bodyText confidence="0.999740285714286">
To understand whether users would adopt sys-
tem generated morphs for their social media com-
munication, we also ask the assessors to recite
the morphs that they remember after the survey.
Among all the morphs that they remember cor-
rectly, 20.4% are system generated morphs, which
is encouraging.
</bodyText>
<subsectionHeader confidence="0.999016">
3.3 Automatic Evaluation
</subsectionHeader>
<bodyText confidence="0.986543">
Another important goal of morph encoding is to
avoid censorship and freely communicate about
</bodyText>
<page confidence="0.995445">
709
</page>
<table confidence="0.991010625">
M1 M2 M3 M4 M5 M6 M7 Overall
Human System Human System Human System Human System Human System Human System Human System Human System
# of morphs 17 124 4 21 10 54 9 28 64 87 9 18 74 50 187 382
Perceivability 75 76 95 86 94 81 61 71 87 59 66 5 77 34 76 67
Funniness 78 49 92 43 44 41 70 47 70 35 74 28 79 44 76 46
Appropriateness 71 51 89 59 81 43 75 49 76 36 78 18 82 38 79 43
Average 75 59 92 57 73 55 69 56 78 43 73 17 79 39 77 52
Standard Deviation 12.29 21.81 7.32 11.89 13.2 9.2 17.13 20.3 18.83 17.54 10.01 21.23 15.18 15.99 15.99 18.14
</table>
<tableCaption confidence="0.706498">
Table 4: Human Evaluation Satisfaction Rate (%)
certain entities. To evaluate how well the new
morphs can pass censorship, we simulate the cen-
</tableCaption>
<figure confidence="0.905224375">
hs
sorship using an automatic morph decoder con-
685898
169
sisted of a morph candidate identification system
1742 4571
based on Support Vector Machines incorporating
264 11539
</figure>
<bodyText confidence="0.588255">
anomaly analysis and our morph resolution sys-
</bodyText>
<equation confidence="0.780940142857143">
2262 2666
98 811
tem (Huang et al., 2013). We use each system gen-
17052 12784
erated morph to replace its corresponding human-
47812 1E+05
257 329
</equation>
<bodyText confidence="0.986753363636364">
created morphs in Weibo tweets and obtain a new
“morphed” dataset. The morph decoder is then
2568 8984 214.3 2969 1742 451 26
applied to it. We define discovery rate as the per-
centage of morphs identified by the decoder, and
the ranking accuracy Acc@k to evaluate the reso-
lution performance. We conduct this decoding ex-
periment on 247 system generated and 151 human
generated perceivable morphs with perceivability
scores &gt; 70% from human evaluation.
Figure 1 shows that in general the decoder
achieves lower discovery rate on system gener-
ated morphs than human generated ones, because
the identification component in the decoder was
trained based on human morph related features.
This result is promising because it demonstrates
that the system generated morphs contain new and
unique characteristics which are unknown to the
decoder. In contrast, from Figure 2 we can see
that system generated morphs can be more easily
resolved into the right target entities than human
generated ones which are more implicit.
</bodyText>
<figureCaption confidence="0.997919">
Figure 1: Discovery Rate (%)
</figureCaption>
<sectionHeader confidence="0.999477" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.952965666666667">
Some recent work attempted to map between Chi-
nese formal words and informal words (Xia et al.,
2005; Xia and Wong, 2006; Xia et al., 2006; Li
</bodyText>
<figureCaption confidence="0.810325">
Figure 2: Resolution Acc@K Accuracy (%)
and Yarowsky, 2008; Wang et al., 2013; Wang and
766 1 1
</figureCaption>
<bodyText confidence="0.999167333333333">
Kan, 2013). We incorporated the pronunciation,
lexical and semantic similarity measurements pro-
posed in these approaches. Some of our basic se-
lection criteria are also similar to the constraints
used in previous work on generating humors (Val-
itutti et al., 2013; Petrovic and Matthews, 2013).
</bodyText>
<sectionHeader confidence="0.998044" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999978">
This paper proposed a new problem of encoding
entity morphs and developed a wide variety of
novel automatic approaches. In the future we will
focus on improving the language-independent ap-
proaches based on historical figure mapping and
culture and reputation modeling. In addition, we
plan to extend our approaches to other types of in-
formation including sensitive events, satires and
metaphors so that we can generate fable stories.
We are also interested in tracking morphs over
time to study the evolution of Internet language.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999918307692308">
This work was supported by U.S. ARL No.
W911NF-09-2-0053, DARPA No. FA8750-13-
2-0041 and No. W911NF-12-C-0028, ARO
No. W911NF-13-1-0193, NSF IIS-0953149,
CNS-0931975, IIS-1017362, IIS-1320617, IIS-
1354329, IBM, Google, DTRA, DHS and RPI.
The views and conclusions in this document are
those of the authors and should not be inter-
preted as representing the official policies, either
expressed or implied, of the U.S. Government.
The U.S. Government is authorized to reproduce
and distribute reprints for Government purposes
notwithstanding any copyright notation here on.
</bodyText>
<figure confidence="0.995559125">
100
80
60
40
20
0
M1 M2 M3 M4 M5 M6 M7 ALL
Human created morph System generated morph
</figure>
<page confidence="0.976897">
710
</page>
<sectionHeader confidence="0.966347" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.989811947916666">
David Bamman, Brendan O’Connor, and Noah A.
Smith. 2012. Censorship and deletion practices in
Chinese social media. First Monday, 17(3).
Le Chen, Chi Zhang, and Christo Wilson. 2013.
Tweeting under pressure: analyzing trending topics
and evolving word choice on sina weibo. In Pro-
ceedings of the first ACM conference on Online so-
cial networks, pages 89–100.
Zhendong Dong and Qiang Dong. 1999. Hownet. In
http://www.keenage.com.
Hongzhao Huang, Zhen Wen, Dian Yu, Heng Ji,
Yizhou Sun, Jiawei Han, and He Li. 2013. Resolv-
ing entity morphs in censored data. In Proceedings
of the 51st Annual Meeting of the Association for
Computational Linguistics (ACL2013).
Heng Ji and Ralph Grishman. 2011. Knowledge base
population: Successful approaches and challenges.
In Proceedings of the Association for Computational
Linguistics (ACL2011).
Heng Ji, Ralph Grishman, Dayne Freitag, Matthias
Blume, John Wang, Shahram Khadivi, Richard
Zens, and Hermann Ney. 2009. Name extraction
and translation for distillation. Handbook of Natu-
ral Language Processing and Machine Translation:
DARPA Global Autonomous Language Exploitation.
Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2010. Overview of the tac 2010
knowledge base population track. In Text Analysis
Conference (TAC) 2010.
Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011.
Overview of the tac 2011 knowledge base popula-
tion track. In Proc. Text Analysis Conference (TAC)
2011.
Kevin Knight and Jonathan Graehl. 1998. Machine
transliteration. Computational Linguistics, 24(4).
Zhifei Li and David Yarowsky. 2008. Mining and
modeling relations between formal and informal chi-
nese phrases from web corpora. In Proceedings
of Conference on Empirical Methods in Natural
Language Processing (EMNLP2008), pages 1031–
1040.
Jianyu Li and Jie Zhou. 2007. Chinese character struc-
ture analysis based on complex networks. Phys-
ica A: Statistical Mechanics and its Applications,
380:629–638.
Paul McNamee and Hoa Trang Dang. 2009.
Overview of the tac 2009 knowledge base popula-
tion track. In Proceedings of Text Analysis Confer-
ence (TAC2009).
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their composition-
ality. In C.J.C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K.Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
26, pages 3111–3119.
Sasa Petrovic and David Matthews. 2013. Unsuper-
vised joke generation from big data. In Proceed-
ings of the Association for Computational Linguis-
tics (ACL2013).
Alessandro Valitutti, Hannu Toivonen, Antoine
Doucet, and Jukka M. Toivanen. 2013. ”let every-
thing turn well in your wife”: Generation of adult
humor using lexical constraints. In Proceedings
of the Association for Computational Linguistics
(ACL2013).
Aobo Wang and Min-Yen Kan. 2013. Mining informal
language from chinese microtext: Joint word recog-
nition and segmentation. In Proceedings of the As-
sociation for Computational Linguistics (ACL2013).
Aobo Wang, Min-Yen Kan, Daniel Andrade, Takashi
Onishi, and Kai Ishikawa. 2013. Chinese informal
word normalization: an experimental study. In Pro-
ceedings of International Joint Conference on Natu-
ral Language Processing (IJCNLP2013).
Yunqing Xia and Kam-Fai Wong. 2006. Anomaly de-
tecting within dynamic chinese chat text. In Proc.
Workshop On New Text Wikis And Blogs And Other
Dynamic Text Sources.
Yunqing Xia, Kam-Fai Wong, and Wei Gao. 2005. Nil
is not nothing: Recognition of chinese network in-
formal language expressions. In 4th SIGHAN Work-
shop on Chinese Language Processing at IJCNLP,
volume 5.
Yunqing Xia, Kam-Fai Wong, and Wenjie Li. 2006.
A phonetic-based approach to chinese chat text nor-
malization. In Proceedings of COLING-ACL2006,
pages 993–1000.
Richard Zens and Hermann Ney. 2004. Improvements
in phrase-based statistical machine translation. In
Proceedings of HLT-NAACL2004.
Jing Zhang, Biao Liu, Jie Tang, Ting Chen, and Juanzi
Li. 2013. Social influence locality for modeling
retweeting behaviors. In Proceedings of the 23rd
International Joint Conference on Artificial Intelli-
gence (IJCAI’13), pages 2761–2767.
</reference>
<page confidence="0.997938">
711
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.117620">
<title confidence="0.999794">Be Appropriate and Funny: Automatic Entity Morph Encoding</title>
<author confidence="0.8415245">Hongzhao Xiaoman Heng Kevin Yizhou Jiawei Bulent</author>
<affiliation confidence="0.718774">Science Department, Rensselaer Polytechnic Sciences Institute, University of Southern</affiliation>
<author confidence="0.865039">T J Watson Research</author>
<affiliation confidence="0.5152965">of Computer and Information Science, Northeastern Science Department, Univerisity of Illinois at</affiliation>
<abstract confidence="0.980417357142857">Internet users are keen on creating differkinds of avoid censorship, express strong sentiment or humor. For example, in Chinese social media, users use the entity morph (Into refer to because it shares one charwith the well-known of instant noodles We developed a wide variety of novel approaches to automatically encode proper and interesting morphs, which can pass decoding tests</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Bamman</author>
<author>Brendan O’Connor</author>
<author>Noah A Smith</author>
</authors>
<title>Censorship and deletion practices in Chinese social media.</title>
<date>2012</date>
<journal>First Monday,</journal>
<volume>17</volume>
<issue>3</issue>
<marker>Bamman, O’Connor, Smith, 2012</marker>
<rawString>David Bamman, Brendan O’Connor, and Noah A. Smith. 2012. Censorship and deletion practices in Chinese social media. First Monday, 17(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chi Zhang Le Chen</author>
<author>Christo Wilson</author>
</authors>
<title>Tweeting under pressure: analyzing trending topics and evolving word choice on sina weibo.</title>
<date>2013</date>
<booktitle>In Proceedings of the first ACM conference on Online social networks,</booktitle>
<pages>89--100</pages>
<marker>Le Chen, Wilson, 2013</marker>
<rawString>Le Chen, Chi Zhang, and Christo Wilson. 2013. Tweeting under pressure: analyzing trending topics and evolving word choice on sina weibo. In Proceedings of the first ACM conference on Online social networks, pages 89–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhendong Dong</author>
<author>Qiang Dong</author>
</authors>
<date>1999</date>
<note>Hownet. In http://www.keenage.com.</note>
<contexts>
<context position="5657" citStr="Dong and Dong, 1999" startWordPosition="890" endWordPosition="893">r), (x,h), (l,n), (c,ch), (s,sh) and (z,zh) are mutually transformable. If a part of pinyin(e) and pinyin(t) are identical or their initials are transformable, we substitute the part of e with t to form a new morph. For example, we can substitute the characters of “比尔 盖茨 (Bill Gates) [Bi Er Gai Ci]” with “鼻耳 (Nose and ear) [Bi Er]” and “盖子 (Lid) [Gai Zi]” to form new morph “鼻耳 盖子 (Nose and ear Lid) [Bi Er Gai Zi]”. We rank the candidates based on the following two criteria: (1) If the morph includes more negative words (based on a gazetteer including 11,729 negative words derived from HowNet (Dong and Dong, 1999), it’s more humorous (Valitutti et al., 2013). (2) If the morph includes rarer terms with low frequency, it is more interesting (Petrovic and Matthews, 2013). 2.3 M2: Spelling Decomposition Chinese characters are ideograms, hieroglyphs and mostly picture-based. It allows us to naturally construct a virtually infinite range of combinations from a finite set of basic units - radicals (Li and Zhou, 2007). Some of these radicals themselves are also characters. For a given entity name e = c1...cn, if any character ck can be decomposed into two radicalsc1 k and c2k which are both characters or can b</context>
</contexts>
<marker>Dong, Dong, 1999</marker>
<rawString>Zhendong Dong and Qiang Dong. 1999. Hownet. In http://www.keenage.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongzhao Huang</author>
<author>Zhen Wen</author>
<author>Dian Yu</author>
<author>Heng Ji</author>
<author>Yizhou Sun</author>
<author>Jiawei Han</author>
<author>He Li</author>
</authors>
<title>Resolving entity morphs in censored data.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL2013).</booktitle>
<contexts>
<context position="1239" citStr="Huang et al., 2013" startWordPosition="164" endWordPosition="167">ernet users are keen on creating different kinds of morphs to avoid censorship, express strong sentiment or humor. For example, in Chinese social media, users often use the entity morph “方4k面 (Instant Noodles)” to refer to “周永康 (Zhou Yongkang)” because it shares one character “康 (Kang)” with the well-known brand of instant noodles “康师44 (Master Kang)”. We developed a wide variety of novel approaches to automatically encode proper and interesting morphs, which can effectively pass decoding tests 1. 1 Introduction One of the most innovative linguistic forms in social media is Information Morph (Huang et al., 2013). Morph is a special case of alias to hide the original objects (e.g., sensitive entities and events) for different purposes, including avoiding censorship (Bamman et al., 2012; Chen et al., 2013), expressing strong sentiment, emotion or sarcasm, and making descriptions more vivid. Morphs are widely used in Chinese social media. Here is an example morphs: “由于X*的事情,方4k面与 天线摊牌. (Because of Gua Dad’s issue, Instant Noodles faces down with Antenna.)”, where • “X* (Gua Dad)” refers to “4熙来 (Bo Xilai)” because it shares one character “X (Gua)” with “4XX (Bo Guagua)” who is the son of “4熙 来 (Bo Xilai</context>
<context position="8541" citStr="Huang et al., 2013" startWordPosition="1381" endWordPosition="1384">ains ck, we append the word with the last name of e to form a new morph. Similarly to M1, we prefer positive, negative or rare words. For example, we create a morph “薄 MAz (Bo Mess)” for “薄熙Az (Bo Xi Lai)” because the semantic interpretation sentence for “Az (Lai)” includes a negative word “MAz (Mess)”. 2.7 M6: Historical Figure Mapping We collect a set of 38 famous historical figures including politicians, emperors, poets, generals, ministers and scholars from a website. For a given entity name e, we rank these candidates by applying the resolution approach as described in our previous work (Huang et al., 2013) to measure the similarity between an entity and a historic figure 3http://xh.5156edu.com/ 707 Category Frequency Examples Distribution Entity Morph Comment (1) Avoid censorship 6.56% 4熙* (Bo Xi- B-+ 记 (B Secre- “B” is the first letter of “Bo” and “Secretary” is lai) tary) the entity’s title. (2) Express strong 15.77% -E勇平 (Wang 奇 迹 哥 (Miracle Sarcasm on the entity’s public speech: “It’s a mirsentiment, sarcasm, Yongping) Brother) acle that the girl survived (from the 2011 train colemotion lision)”. (3) Be humorous or 25.91% fi幂 (Yang Mi) 嫩牛3zTj (Tender The entity’s face shape looks like the s</context>
<context position="17835" citStr="Huang et al., 2013" startWordPosition="2980" endWordPosition="2983">s 71 51 89 59 81 43 75 49 76 36 78 18 82 38 79 43 Average 75 59 92 57 73 55 69 56 78 43 73 17 79 39 77 52 Standard Deviation 12.29 21.81 7.32 11.89 13.2 9.2 17.13 20.3 18.83 17.54 10.01 21.23 15.18 15.99 15.99 18.14 Table 4: Human Evaluation Satisfaction Rate (%) certain entities. To evaluate how well the new morphs can pass censorship, we simulate the cenhs sorship using an automatic morph decoder con685898 169 sisted of a morph candidate identification system 1742 4571 based on Support Vector Machines incorporating 264 11539 anomaly analysis and our morph resolution sys2262 2666 98 811 tem (Huang et al., 2013). We use each system gen17052 12784 erated morph to replace its corresponding human47812 1E+05 257 329 created morphs in Weibo tweets and obtain a new “morphed” dataset. The morph decoder is then 2568 8984 214.3 2969 1742 451 26 applied to it. We define discovery rate as the percentage of morphs identified by the decoder, and the ranking accuracy Acc@k to evaluate the resolution performance. We conduct this decoding experiment on 247 system generated and 151 human generated perceivable morphs with perceivability scores &gt; 70% from human evaluation. Figure 1 shows that in general the decoder ach</context>
</contexts>
<marker>Huang, Wen, Yu, Ji, Sun, Han, Li, 2013</marker>
<rawString>Hongzhao Huang, Zhen Wen, Dian Yu, Heng Ji, Yizhou Sun, Jiawei Han, and He Li. 2013. Resolving entity morphs in censored data. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Knowledge base population: Successful approaches and challenges.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL2011).</booktitle>
<contexts>
<context position="11934" citStr="Ji and Grishman, 2011" startWordPosition="1949" endWordPosition="1952">“n祖 (the Second Emperor )” for “邓小平 (Deng Xiaoping )” who succeeded Mao. 2.8 M7: Characteristics Modeling Finally, we propose a novel approach to automatically generate an entity’s characteristics using Google word2vec model (Mikolov et al., 2013). To make the vocabulary model as general as possible, we use all of the following large corpora that we have access to: Tsinghua Weibo dataset, Chinese Gigaword fifth edition 4 which includes 10 million news documents, TAC-KBP 2009-2013 Source Corpora (McNamee and Dang, 2009; Ji et 4http://catalog.ldc.upenn.edu/LDC2011T13 al., 2010; Ji et al., 2011; Ji and Grishman, 2011) which include 3 million news and web documents, and DARPA BOLT program’s discussion forum corpora with 300k threads. Given an entity e, we compute the semantic relationship between e and each word from these corpora. We then rank the words by: (1) cosine similarity, (2) the same criteria as in section 2.6. Finally we append the top ranking word to the entity’s last name to obtain a new morph. Using this method, we are able to generate many vivid morphs such as “姚 奇才 (Yao Wizard)” for “姚 明 (Yao Ming)”. 3 Experiments 3.1 Data We collected 1,553,347 tweets from Chinese Sina Weibo from May 1 to J</context>
</contexts>
<marker>Ji, Grishman, 2011</marker>
<rawString>Heng Ji and Ralph Grishman. 2011. Knowledge base population: Successful approaches and challenges. In Proceedings of the Association for Computational Linguistics (ACL2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Dayne Freitag</author>
<author>Matthias Blume</author>
<author>John Wang</author>
<author>Shahram Khadivi</author>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Name extraction and translation for distillation. Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation.</title>
<date>2009</date>
<contexts>
<context position="7274" citStr="Ji et al., 2009" startWordPosition="1162" endWordPosition="1165">b Luo)” for “保罗 (Paul)” by decomposing “保 (Pau-)” into “人 (Person)” and “* (Dull)”. A natural alternative is to composing two chracter radicals in an entity name to form a morph. However, very few Chinese names include two characters with single radicals. 2.4 M3: Nickname Generation We propose a simple method to create morphs by duplicating the last character of an entity’s first name. For example, we create a morph “幂幂 (Mimi)” to refer to “杨 幂 (Yang Mi)”. 2.5 M4: Translation and Transliteration Given an entity e, we search its English translation EN(e) based on 94,015 name translation pairs (Ji et al., 2009). Then, if any name component in EN(e) is a common English word, we search for its Chinese translation based on a 94,966 word translation pairs (Zens and Ney, 2004), and use the Chinese translation to replace the corresponding characters in e. For example, we create a morph “拉里 鸟儿 (Larry bird)” for “拉里 伯 (Larry Bird)” by replacing the last name “伯 (Bird)” with its Chinese translation “鸟儿 (bird)”. 2.6 M5: Semantic Interpretation For each character ck in the first name of a given entity name e, we search its semantic interpretation sentence from the Xinhua Chinese character dictionary including </context>
</contexts>
<marker>Ji, Grishman, Freitag, Blume, Wang, Khadivi, Zens, Ney, 2009</marker>
<rawString>Heng Ji, Ralph Grishman, Dayne Freitag, Matthias Blume, John Wang, Shahram Khadivi, Richard Zens, and Hermann Ney. 2009. Name extraction and translation for distillation. Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
<author>Kira Griffitt</author>
<author>Joe Ellis</author>
</authors>
<title>Overview of the tac 2010 knowledge base population track.</title>
<date>2010</date>
<booktitle>In Text Analysis Conference (TAC)</booktitle>
<marker>Ji, Grishman, Dang, Griffitt, Ellis, 2010</marker>
<rawString>Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Griffitt, and Joe Ellis. 2010. Overview of the tac 2010 knowledge base population track. In Text Analysis Conference (TAC) 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of the tac 2011 knowledge base population track.</title>
<date>2011</date>
<booktitle>In Proc. Text Analysis Conference (TAC)</booktitle>
<contexts>
<context position="11910" citStr="Ji et al., 2011" startWordPosition="1945" endWordPosition="1948"> P. R. China and “n祖 (the Second Emperor )” for “邓小平 (Deng Xiaoping )” who succeeded Mao. 2.8 M7: Characteristics Modeling Finally, we propose a novel approach to automatically generate an entity’s characteristics using Google word2vec model (Mikolov et al., 2013). To make the vocabulary model as general as possible, we use all of the following large corpora that we have access to: Tsinghua Weibo dataset, Chinese Gigaword fifth edition 4 which includes 10 million news documents, TAC-KBP 2009-2013 Source Corpora (McNamee and Dang, 2009; Ji et 4http://catalog.ldc.upenn.edu/LDC2011T13 al., 2010; Ji et al., 2011; Ji and Grishman, 2011) which include 3 million news and web documents, and DARPA BOLT program’s discussion forum corpora with 300k threads. Given an entity e, we compute the semantic relationship between e and each word from these corpora. We then rank the words by: (1) cosine similarity, (2) the same criteria as in section 2.6. Finally we append the top ranking word to the entity’s last name to obtain a new morph. Using this method, we are able to generate many vivid morphs such as “姚 奇才 (Yao Wizard)” for “姚 明 (Yao Ming)”. 3 Experiments 3.1 Data We collected 1,553,347 tweets from Chinese Si</context>
</contexts>
<marker>Ji, Grishman, Dang, 2011</marker>
<rawString>Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011. Overview of the tac 2011 knowledge base population track. In Proc. Text Analysis Conference (TAC) 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="14186" citStr="Knight and Graehl, 1998" startWordPosition="2324" endWordPosition="2327">ppropriateness scores are 0. The human evaluation results are shown in Table 4. The Fleiss’s kappa coefficient among all the human assessors is 0.147 indicating slight agreement. From Table 4 we can see that overall the system achieves 66% of the human performance with comparable stability as human. In particular, Method 4 based on translation and transliteration generates much more perceivable morphs than human because the system may search in a larger vocabulary. Interestingly, similar encouraging results - system outperforms human - have been observed by previous back-transliteration work (Knight and Graehl, 1998). It’s also interesting to see that human assessors can only comprehend 76% of the human generated morphs because of the following reasons: (1) the morph is newly generated or it does not describe the characteristics of the target entity well; and (2) the target entity itself is not well known to human assessors who do not keep close track of news topics. In fact only 64 human generated morphs and 72 system generated morphs are perceivable by all human assessors. For Method 2, the human created morphs are assessed as much more and funny than the system generated ones because human creators use</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhifei Li</author>
<author>David Yarowsky</author>
</authors>
<title>Mining and modeling relations between formal and informal chinese phrases from web corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP2008),</booktitle>
<pages>1031--1040</pages>
<marker>Li, Yarowsky, 2008</marker>
<rawString>Zhifei Li and David Yarowsky. 2008. Mining and modeling relations between formal and informal chinese phrases from web corpora. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP2008), pages 1031– 1040.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianyu Li</author>
<author>Jie Zhou</author>
</authors>
<title>Chinese character structure analysis based on complex networks. Physica A: Statistical Mechanics and its Applications,</title>
<date>2007</date>
<pages>380--629</pages>
<contexts>
<context position="6061" citStr="Li and Zhou, 2007" startWordPosition="954" endWordPosition="957">Er Gai Zi]”. We rank the candidates based on the following two criteria: (1) If the morph includes more negative words (based on a gazetteer including 11,729 negative words derived from HowNet (Dong and Dong, 1999), it’s more humorous (Valitutti et al., 2013). (2) If the morph includes rarer terms with low frequency, it is more interesting (Petrovic and Matthews, 2013). 2.3 M2: Spelling Decomposition Chinese characters are ideograms, hieroglyphs and mostly picture-based. It allows us to naturally construct a virtually infinite range of combinations from a finite set of basic units - radicals (Li and Zhou, 2007). Some of these radicals themselves are also characters. For a given entity name e = c1...cn, if any character ck can be decomposed into two radicalsc1 k and c2k which are both characters or can be converted into characters based on their pictograms (e.g., the radical “艹” can be 2http://en.wikipedia.org/wiki/Pinyin#Initials and finals converted into“草” (grass) ), we create a morph by replacing ck with c1kc2k in e. Here we use a character to radical mapping table that includes 191 radicals (59 of them are characters) and 1328 common characters. For example, we create a morph “人*罗 (Person Dumb L</context>
</contexts>
<marker>Li, Zhou, 2007</marker>
<rawString>Jianyu Li and Jie Zhou. 2007. Chinese character structure analysis based on complex networks. Physica A: Statistical Mechanics and its Applications, 380:629–638.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of the tac 2009 knowledge base population track.</title>
<date>2009</date>
<booktitle>In Proceedings of Text Analysis Conference (TAC2009).</booktitle>
<contexts>
<context position="11835" citStr="McNamee and Dang, 2009" startWordPosition="1936" endWordPosition="1939">orph “太祖 (the First Emperor)” for “毛*A, (Mao Zedong)” who is the first chairman of P. R. China and “n祖 (the Second Emperor )” for “邓小平 (Deng Xiaoping )” who succeeded Mao. 2.8 M7: Characteristics Modeling Finally, we propose a novel approach to automatically generate an entity’s characteristics using Google word2vec model (Mikolov et al., 2013). To make the vocabulary model as general as possible, we use all of the following large corpora that we have access to: Tsinghua Weibo dataset, Chinese Gigaword fifth edition 4 which includes 10 million news documents, TAC-KBP 2009-2013 Source Corpora (McNamee and Dang, 2009; Ji et 4http://catalog.ldc.upenn.edu/LDC2011T13 al., 2010; Ji et al., 2011; Ji and Grishman, 2011) which include 3 million news and web documents, and DARPA BOLT program’s discussion forum corpora with 300k threads. Given an entity e, we compute the semantic relationship between e and each word from these corpora. We then rank the words by: (1) cosine similarity, (2) the same criteria as in section 2.6. Finally we append the top ranking word to the entity’s last name to obtain a new morph. Using this method, we are able to generate many vivid morphs such as “姚 奇才 (Yao Wizard)” for “姚 明 (Yao M</context>
</contexts>
<marker>McNamee, Dang, 2009</marker>
<rawString>Paul McNamee and Hoa Trang Dang. 2009. Overview of the tac 2009 knowledge base population track. In Proceedings of Text Analysis Conference (TAC2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>Advances in Neural Information Processing Systems 26,</booktitle>
<pages>3111--3119</pages>
<editor>In C.J.C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors,</editor>
<contexts>
<context position="11559" citStr="Mikolov et al., 2013" startWordPosition="1891" endWordPosition="1894">ions. A 英 ;L (Ma A * 统 (Ma Se- The morph derives from Ma Yingjiu’s political Yingjiu) cession) position on cross-strait relations. Table 2: Morph Examples Categorized based on Human Generation Methods based on their semantic contexts. For example, this approach generates a morph “太祖 (the First Emperor)” for “毛*A, (Mao Zedong)” who is the first chairman of P. R. China and “n祖 (the Second Emperor )” for “邓小平 (Deng Xiaoping )” who succeeded Mao. 2.8 M7: Characteristics Modeling Finally, we propose a novel approach to automatically generate an entity’s characteristics using Google word2vec model (Mikolov et al., 2013). To make the vocabulary model as general as possible, we use all of the following large corpora that we have access to: Tsinghua Weibo dataset, Chinese Gigaword fifth edition 4 which includes 10 million news documents, TAC-KBP 2009-2013 Source Corpora (McNamee and Dang, 2009; Ji et 4http://catalog.ldc.upenn.edu/LDC2011T13 al., 2010; Ji et al., 2011; Ji and Grishman, 2011) which include 3 million news and web documents, and DARPA BOLT program’s discussion forum corpora with 300k threads. Given an entity e, we compute the semantic relationship between e and each word from these corpora. We then</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In C.J.C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sasa Petrovic</author>
<author>David Matthews</author>
</authors>
<title>Unsupervised joke generation from big data.</title>
<date>2013</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL2013).</booktitle>
<contexts>
<context position="5814" citStr="Petrovic and Matthews, 2013" startWordPosition="915" endWordPosition="918">sformable, we substitute the part of e with t to form a new morph. For example, we can substitute the characters of “比尔 盖茨 (Bill Gates) [Bi Er Gai Ci]” with “鼻耳 (Nose and ear) [Bi Er]” and “盖子 (Lid) [Gai Zi]” to form new morph “鼻耳 盖子 (Nose and ear Lid) [Bi Er Gai Zi]”. We rank the candidates based on the following two criteria: (1) If the morph includes more negative words (based on a gazetteer including 11,729 negative words derived from HowNet (Dong and Dong, 1999), it’s more humorous (Valitutti et al., 2013). (2) If the morph includes rarer terms with low frequency, it is more interesting (Petrovic and Matthews, 2013). 2.3 M2: Spelling Decomposition Chinese characters are ideograms, hieroglyphs and mostly picture-based. It allows us to naturally construct a virtually infinite range of combinations from a finite set of basic units - radicals (Li and Zhou, 2007). Some of these radicals themselves are also characters. For a given entity name e = c1...cn, if any character ck can be decomposed into two radicalsc1 k and c2k which are both characters or can be converted into characters based on their pictograms (e.g., the radical “艹” can be 2http://en.wikipedia.org/wiki/Pinyin#Initials and finals converted into“草</context>
<context position="19524" citStr="Petrovic and Matthews, 2013" startWordPosition="3260" endWordPosition="3263">ies than human generated ones which are more implicit. Figure 1: Discovery Rate (%) 4 Related Work Some recent work attempted to map between Chinese formal words and informal words (Xia et al., 2005; Xia and Wong, 2006; Xia et al., 2006; Li Figure 2: Resolution Acc@K Accuracy (%) and Yarowsky, 2008; Wang et al., 2013; Wang and 766 1 1 Kan, 2013). We incorporated the pronunciation, lexical and semantic similarity measurements proposed in these approaches. Some of our basic selection criteria are also similar to the constraints used in previous work on generating humors (Valitutti et al., 2013; Petrovic and Matthews, 2013). 5 Conclusions and Future Work This paper proposed a new problem of encoding entity morphs and developed a wide variety of novel automatic approaches. In the future we will focus on improving the language-independent approaches based on historical figure mapping and culture and reputation modeling. In addition, we plan to extend our approaches to other types of information including sensitive events, satires and metaphors so that we can generate fable stories. We are also interested in tracking morphs over time to study the evolution of Internet language. Acknowledgments This work was support</context>
</contexts>
<marker>Petrovic, Matthews, 2013</marker>
<rawString>Sasa Petrovic and David Matthews. 2013. Unsupervised joke generation from big data. In Proceedings of the Association for Computational Linguistics (ACL2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Valitutti</author>
<author>Hannu Toivonen</author>
<author>Antoine Doucet</author>
<author>Jukka M Toivanen</author>
</authors>
<title>let everything turn well in your wife”: Generation of adult humor using lexical constraints.</title>
<date>2013</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL2013).</booktitle>
<contexts>
<context position="5702" citStr="Valitutti et al., 2013" startWordPosition="897" endWordPosition="900">) are mutually transformable. If a part of pinyin(e) and pinyin(t) are identical or their initials are transformable, we substitute the part of e with t to form a new morph. For example, we can substitute the characters of “比尔 盖茨 (Bill Gates) [Bi Er Gai Ci]” with “鼻耳 (Nose and ear) [Bi Er]” and “盖子 (Lid) [Gai Zi]” to form new morph “鼻耳 盖子 (Nose and ear Lid) [Bi Er Gai Zi]”. We rank the candidates based on the following two criteria: (1) If the morph includes more negative words (based on a gazetteer including 11,729 negative words derived from HowNet (Dong and Dong, 1999), it’s more humorous (Valitutti et al., 2013). (2) If the morph includes rarer terms with low frequency, it is more interesting (Petrovic and Matthews, 2013). 2.3 M2: Spelling Decomposition Chinese characters are ideograms, hieroglyphs and mostly picture-based. It allows us to naturally construct a virtually infinite range of combinations from a finite set of basic units - radicals (Li and Zhou, 2007). Some of these radicals themselves are also characters. For a given entity name e = c1...cn, if any character ck can be decomposed into two radicalsc1 k and c2k which are both characters or can be converted into characters based on their pi</context>
<context position="19494" citStr="Valitutti et al., 2013" startWordPosition="3255" endWordPosition="3259">o the right target entities than human generated ones which are more implicit. Figure 1: Discovery Rate (%) 4 Related Work Some recent work attempted to map between Chinese formal words and informal words (Xia et al., 2005; Xia and Wong, 2006; Xia et al., 2006; Li Figure 2: Resolution Acc@K Accuracy (%) and Yarowsky, 2008; Wang et al., 2013; Wang and 766 1 1 Kan, 2013). We incorporated the pronunciation, lexical and semantic similarity measurements proposed in these approaches. Some of our basic selection criteria are also similar to the constraints used in previous work on generating humors (Valitutti et al., 2013; Petrovic and Matthews, 2013). 5 Conclusions and Future Work This paper proposed a new problem of encoding entity morphs and developed a wide variety of novel automatic approaches. In the future we will focus on improving the language-independent approaches based on historical figure mapping and culture and reputation modeling. In addition, we plan to extend our approaches to other types of information including sensitive events, satires and metaphors so that we can generate fable stories. We are also interested in tracking morphs over time to study the evolution of Internet language. Acknowl</context>
</contexts>
<marker>Valitutti, Toivonen, Doucet, Toivanen, 2013</marker>
<rawString>Alessandro Valitutti, Hannu Toivonen, Antoine Doucet, and Jukka M. Toivanen. 2013. ”let everything turn well in your wife”: Generation of adult humor using lexical constraints. In Proceedings of the Association for Computational Linguistics (ACL2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aobo Wang</author>
<author>Min-Yen Kan</author>
</authors>
<title>Mining informal language from chinese microtext: Joint word recognition and segmentation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL2013).</booktitle>
<marker>Wang, Kan, 2013</marker>
<rawString>Aobo Wang and Min-Yen Kan. 2013. Mining informal language from chinese microtext: Joint word recognition and segmentation. In Proceedings of the Association for Computational Linguistics (ACL2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aobo Wang</author>
<author>Min-Yen Kan</author>
<author>Daniel Andrade</author>
<author>Takashi Onishi</author>
<author>Kai Ishikawa</author>
</authors>
<title>Chinese informal word normalization: an experimental study.</title>
<date>2013</date>
<booktitle>In Proceedings of International Joint Conference on Natural Language Processing (IJCNLP2013).</booktitle>
<contexts>
<context position="19214" citStr="Wang et al., 2013" startWordPosition="3210" endWordPosition="3213">rph related features. This result is promising because it demonstrates that the system generated morphs contain new and unique characteristics which are unknown to the decoder. In contrast, from Figure 2 we can see that system generated morphs can be more easily resolved into the right target entities than human generated ones which are more implicit. Figure 1: Discovery Rate (%) 4 Related Work Some recent work attempted to map between Chinese formal words and informal words (Xia et al., 2005; Xia and Wong, 2006; Xia et al., 2006; Li Figure 2: Resolution Acc@K Accuracy (%) and Yarowsky, 2008; Wang et al., 2013; Wang and 766 1 1 Kan, 2013). We incorporated the pronunciation, lexical and semantic similarity measurements proposed in these approaches. Some of our basic selection criteria are also similar to the constraints used in previous work on generating humors (Valitutti et al., 2013; Petrovic and Matthews, 2013). 5 Conclusions and Future Work This paper proposed a new problem of encoding entity morphs and developed a wide variety of novel automatic approaches. In the future we will focus on improving the language-independent approaches based on historical figure mapping and culture and reputation</context>
</contexts>
<marker>Wang, Kan, Andrade, Onishi, Ishikawa, 2013</marker>
<rawString>Aobo Wang, Min-Yen Kan, Daniel Andrade, Takashi Onishi, and Kai Ishikawa. 2013. Chinese informal word normalization: an experimental study. In Proceedings of International Joint Conference on Natural Language Processing (IJCNLP2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunqing Xia</author>
<author>Kam-Fai Wong</author>
</authors>
<title>Anomaly detecting within dynamic chinese chat text.</title>
<date>2006</date>
<booktitle>In Proc. Workshop On New Text Wikis And Blogs And Other Dynamic Text Sources.</booktitle>
<contexts>
<context position="19114" citStr="Xia and Wong, 2006" startWordPosition="3192" endWordPosition="3195">man generated ones, because the identification component in the decoder was trained based on human morph related features. This result is promising because it demonstrates that the system generated morphs contain new and unique characteristics which are unknown to the decoder. In contrast, from Figure 2 we can see that system generated morphs can be more easily resolved into the right target entities than human generated ones which are more implicit. Figure 1: Discovery Rate (%) 4 Related Work Some recent work attempted to map between Chinese formal words and informal words (Xia et al., 2005; Xia and Wong, 2006; Xia et al., 2006; Li Figure 2: Resolution Acc@K Accuracy (%) and Yarowsky, 2008; Wang et al., 2013; Wang and 766 1 1 Kan, 2013). We incorporated the pronunciation, lexical and semantic similarity measurements proposed in these approaches. Some of our basic selection criteria are also similar to the constraints used in previous work on generating humors (Valitutti et al., 2013; Petrovic and Matthews, 2013). 5 Conclusions and Future Work This paper proposed a new problem of encoding entity morphs and developed a wide variety of novel automatic approaches. In the future we will focus on improvi</context>
</contexts>
<marker>Xia, Wong, 2006</marker>
<rawString>Yunqing Xia and Kam-Fai Wong. 2006. Anomaly detecting within dynamic chinese chat text. In Proc. Workshop On New Text Wikis And Blogs And Other Dynamic Text Sources.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunqing Xia</author>
<author>Kam-Fai Wong</author>
<author>Wei Gao</author>
</authors>
<title>Nil is not nothing: Recognition of chinese network informal language expressions.</title>
<date>2005</date>
<booktitle>In 4th SIGHAN Workshop on Chinese Language Processing at IJCNLP,</booktitle>
<volume>5</volume>
<contexts>
<context position="19094" citStr="Xia et al., 2005" startWordPosition="3188" endWordPosition="3191">ted morphs than human generated ones, because the identification component in the decoder was trained based on human morph related features. This result is promising because it demonstrates that the system generated morphs contain new and unique characteristics which are unknown to the decoder. In contrast, from Figure 2 we can see that system generated morphs can be more easily resolved into the right target entities than human generated ones which are more implicit. Figure 1: Discovery Rate (%) 4 Related Work Some recent work attempted to map between Chinese formal words and informal words (Xia et al., 2005; Xia and Wong, 2006; Xia et al., 2006; Li Figure 2: Resolution Acc@K Accuracy (%) and Yarowsky, 2008; Wang et al., 2013; Wang and 766 1 1 Kan, 2013). We incorporated the pronunciation, lexical and semantic similarity measurements proposed in these approaches. Some of our basic selection criteria are also similar to the constraints used in previous work on generating humors (Valitutti et al., 2013; Petrovic and Matthews, 2013). 5 Conclusions and Future Work This paper proposed a new problem of encoding entity morphs and developed a wide variety of novel automatic approaches. In the future we w</context>
</contexts>
<marker>Xia, Wong, Gao, 2005</marker>
<rawString>Yunqing Xia, Kam-Fai Wong, and Wei Gao. 2005. Nil is not nothing: Recognition of chinese network informal language expressions. In 4th SIGHAN Workshop on Chinese Language Processing at IJCNLP, volume 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunqing Xia</author>
<author>Kam-Fai Wong</author>
<author>Wenjie Li</author>
</authors>
<title>A phonetic-based approach to chinese chat text normalization.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL2006,</booktitle>
<pages>993--1000</pages>
<contexts>
<context position="19132" citStr="Xia et al., 2006" startWordPosition="3196" endWordPosition="3199">because the identification component in the decoder was trained based on human morph related features. This result is promising because it demonstrates that the system generated morphs contain new and unique characteristics which are unknown to the decoder. In contrast, from Figure 2 we can see that system generated morphs can be more easily resolved into the right target entities than human generated ones which are more implicit. Figure 1: Discovery Rate (%) 4 Related Work Some recent work attempted to map between Chinese formal words and informal words (Xia et al., 2005; Xia and Wong, 2006; Xia et al., 2006; Li Figure 2: Resolution Acc@K Accuracy (%) and Yarowsky, 2008; Wang et al., 2013; Wang and 766 1 1 Kan, 2013). We incorporated the pronunciation, lexical and semantic similarity measurements proposed in these approaches. Some of our basic selection criteria are also similar to the constraints used in previous work on generating humors (Valitutti et al., 2013; Petrovic and Matthews, 2013). 5 Conclusions and Future Work This paper proposed a new problem of encoding entity morphs and developed a wide variety of novel automatic approaches. In the future we will focus on improving the language-in</context>
</contexts>
<marker>Xia, Wong, Li, 2006</marker>
<rawString>Yunqing Xia, Kam-Fai Wong, and Wenjie Li. 2006. A phonetic-based approach to chinese chat text normalization. In Proceedings of COLING-ACL2006, pages 993–1000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Improvements in phrase-based statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL2004.</booktitle>
<contexts>
<context position="7438" citStr="Zens and Ney, 2004" startWordPosition="1191" endWordPosition="1194"> to form a morph. However, very few Chinese names include two characters with single radicals. 2.4 M3: Nickname Generation We propose a simple method to create morphs by duplicating the last character of an entity’s first name. For example, we create a morph “幂幂 (Mimi)” to refer to “杨 幂 (Yang Mi)”. 2.5 M4: Translation and Transliteration Given an entity e, we search its English translation EN(e) based on 94,015 name translation pairs (Ji et al., 2009). Then, if any name component in EN(e) is a common English word, we search for its Chinese translation based on a 94,966 word translation pairs (Zens and Ney, 2004), and use the Chinese translation to replace the corresponding characters in e. For example, we create a morph “拉里 鸟儿 (Larry bird)” for “拉里 伯 (Larry Bird)” by replacing the last name “伯 (Bird)” with its Chinese translation “鸟儿 (bird)”. 2.6 M5: Semantic Interpretation For each character ck in the first name of a given entity name e, we search its semantic interpretation sentence from the Xinhua Chinese character dictionary including 20,894 entries 3. If a word in the sentence contains ck, we append the word with the last name of e to form a new morph. Similarly to M1, we prefer positive, negati</context>
</contexts>
<marker>Zens, Ney, 2004</marker>
<rawString>Richard Zens and Hermann Ney. 2004. Improvements in phrase-based statistical machine translation. In Proceedings of HLT-NAACL2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Zhang</author>
<author>Biao Liu</author>
<author>Jie Tang</author>
<author>Ting Chen</author>
<author>Juanzi Li</author>
</authors>
<title>Social influence locality for modeling retweeting behaviors.</title>
<date>2013</date>
<booktitle>In Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI’13),</booktitle>
<pages>2761--2767</pages>
<contexts>
<context position="4809" citStr="Zhang et al., 2013" startWordPosition="741" endWordPosition="744">art from taking a close look at human’s intentions and general methods to create morphs from a social cognitive perspective. In Table 1 and Table 2, we summarize 548 randomly selected morphs into different categories. In this paper we automate the first seven human approaches, without investigating the most challenging Method 8, which requires deep mining of rich background and tracking all events involving the entities. 2.2 M1: Phonetic Substitution Given an entity name e, we obtain its phonetic transcription pinyin(e). Similarly, for each unique term t extracted from Tsinghua Weibo dataset (Zhang et al., 2013) with one billion tweets from 1.8 million users from 8/28/2012 to 9/29/2012, we obtain pinyin(t). According to the Chinese phonetic transcription articulation manner 2, the pairs (b, p), (d,t), (g,k), (z,c), (zh,ch), (j,q), (sh,r), (x,h), (l,n), (c,ch), (s,sh) and (z,zh) are mutually transformable. If a part of pinyin(e) and pinyin(t) are identical or their initials are transformable, we substitute the part of e with t to form a new morph. For example, we can substitute the characters of “比尔 盖茨 (Bill Gates) [Bi Er Gai Ci]” with “鼻耳 (Nose and ear) [Bi Er]” and “盖子 (Lid) [Gai Zi]” to form new mo</context>
</contexts>
<marker>Zhang, Liu, Tang, Chen, Li, 2013</marker>
<rawString>Jing Zhang, Biao Liu, Jie Tang, Ting Chen, and Juanzi Li. 2013. Social influence locality for modeling retweeting behaviors. In Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI’13), pages 2761–2767.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>