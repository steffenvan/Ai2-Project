<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.9359885">
GIST-IT: Summarizing Email Using Linguistic Knowledge and Machine
Learning
</title>
<author confidence="0.690063">
Evelyne Tzoukermann Smaranda Muresan Judith L. Klavans
</author>
<affiliation confidence="0.509873">
Bell Labs, Lucent Columbia University Columbia University
</affiliation>
<address confidence="0.83107125">
Technologies 500 W 120th Street Center for Research on
700 Mountain Avenue New York, NY, 10027, USA Information Access
Murray Hill, NJ, 07974, USA smara@cs.columbia.edu 535 W 114th Street
evelyne@lucent.com New York, NY, 10027, USA
</address>
<email confidence="0.995613">
klavans@cs.columbia.edu
</email>
<sectionHeader confidence="0.986855" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999755866666667">
We present a system for the automatic
extraction of salient information from
email messages, thus providing the gist of
their meaning. Dealing with email raises
several challenges that we address in this
paper: heterogeneous data in terms of
length and topic. Our method combines
shallow linguistic processing with
machine learning to extract phrasal units
that are representative of email content.
The GIST-IT application is fully
implemented and embedded in an active
mailbox platform. Evaluation was
performed over three machine learning
paradigms.
</bodyText>
<sectionHeader confidence="0.792588" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.99990226923077">
The volume of email messages is huge and
growing. A qualitative and quantitative study of
email overload [Whittaker and Sidner (1996)]
shows that people receive a large number of
email messages each day (~ 49) and that 21% of
their inboxes (about 334 messages) are long
messages (over 10 Kbytes). Therefore
summarization techniques adequate for real-
world applications are of great interest and need
[Berger and Mittal (2000), McKeown and Radev
(1995), Kupiec et al (1995), McKeown et al
(1999), Hovy (2000)].
In this paper we present GIST-IT, an
automatic email message summarizer that will
convey to the user the gist of the document
through topic phrase extraction, by combining
linguistic and machine learning techniques.
Email messages and web documents raise
several challenges to automatic text
processing, and the summarization task
addresses most of them: they are free-style
text, not always syntactically or
grammatically well-formed, domain and
genre independent, of variable length and on
multiple topics. Furthermore, due to the lack
of well-formed syntactic and grammatical
structures, the granularity of document
extracts presents another level of complexity.
In our work, we address the extraction
problem at phrase-level [Ueda et al (2000),
Wacholder et al (2000)], identifying salient
information that is spread across multiple
sentences and paragraphs.
Our novel approach first extracts simple
noun phrases as candidate units for
representing document meaning and then
uses machine learning algorithms to select
the most prominent ones. This combined
method allows us to generate an informative,
generic, “at-a-glance” summary.
In this paper, we show: (a) the efficiency
of the linguistic approach for phrase
extraction in comparing results with and
without filtering techniques, (b) the
usefulness of vector representation in
determining proper features to identify
contentful information, (c) the benefit of
using a new measure of TF*IDF for the noun
phrase and its constituents, (d) the power of
machine learning systems in evaluating
several classifiers in order to select the one
performing the best for this task.
</bodyText>
<sectionHeader confidence="0.992119" genericHeader="method">
1 Related work
</sectionHeader>
<bodyText confidence="0.999890189655173">
Traditionally a document summary is seen as a
small, coherent prose that renders to the user the
important meaning of the text. In this framework
most of the research has focused on extractive
summaries at sentence level. However, as
discussed in [Boguraev and Kennedy (1999)],
the meaning of ‘summary’ should be adjusted
depending on the information management task
for which it is used. Key phrases, for example,
can be seen as semantic metadata that
summarize and characterize documents [Witten
et al (1999), Turney (1999)]. These approaches
select a set of candidate phrases (sequence of
one, two or three consecutive stemmed, non-stop
words) and then apply machine learning
techniques to classify them as key phrases or
not. But dealing only with n-grams does not
always provide good output in terms of a
summary (see discussion in Section 5.4).
Wacholder (1998) proposes a linguistically-
motivated method for the representation of the
document aboutness: ‘head clustering’. A list of
simple noun phrases is first extracted, clustered
by head and then ranked by the frequency of the
head. Klavans et al (2000) report on the
evaluation of ‘usefulness’ of head clustering in
the context of browsing applications, in terms of
quality and coverage.
Other researchers have used noun-phrases
quite successfully for information retrieval task
[Strzalkowski et al (1999), Sparck-Jones
(1999)]. Strzalkowski et al (1999) uses head +
modifier pairs as part of a larger system
which constitutes the “stream model” that is
used for information retrieval. They treat the
head-modifier relationship as an ”ordered
relation between otherwise equal elements”,
emphasizing that for some tasks, the syntactic
head of the NP is not necessarily a semantic
head, and the modifier is not either
necessarily a semantic modifier and that the
opposite is often true. Using a machine
learning approach, we proved this hypothesis
for the task of gisting.
Berger and Mittal (2000) present a
summarization system named OCELOT,
based on probabilistic models, which
provides the gist of web documents. Like
email messages, web documents are also very
heterogeneous and their unstructured nature
pose equal difficulties.
In this paper, we propose a novel
technique for summarization that combines
the linguistic approach of extracting simple
noun phrases as possible candidates for
document extracts, and the use of machine
learning algorithms to automatically select
the most salient ones.
</bodyText>
<sectionHeader confidence="0.529733" genericHeader="method">
2 System architecture
</sectionHeader>
<bodyText confidence="0.9938472">
The input to GIST-IT is a single email
message. The architecture, presented in
Figure 1 consists of four distinct functional
components. The first module is an email
preprocessor developed for Text-To-Speech
</bodyText>
<figure confidence="0.968848">
message
email
NP Extraction and Filtering Unit
Tokenization
E - Mail Prep
Simple NP
Extraction
NP filtering
ML Unit
Feature
selection
Feature
selection
Classification
Model
NP
classification
gist of email presentation
message
</figure>
<figureCaption confidence="0.999889">
Figure 1 System Architecture
</figureCaption>
<bodyText confidence="0.99980765">
applications. The second component is a shallow
text processing unit, which is actually a pipeline
of modules for extraction and filtering of simple
NP candidates. The third functional component
is a machine learning unit, which consists of a
feature selection module and a text classifier.
This module uses a training set and a testing set
that were devided from our email corpus. In
order to test the performance of GIST-IT on the
task of summarization, we use a heterogeneous
collection of email messages in genre, length,
and topic. We represent each email as a set of
NP feature vectors. We used 2,500 NPs
extracted from 51 email messages as a training
set and 324 NPs from 8 messages for testing.
Each NP was manually tagged for saliency by
one of the authors and we are planning to add
more judges in the future. The final module
deals with presentation of the gisted email
message.
</bodyText>
<subsectionHeader confidence="0.999592">
2.1 The Email Preprocessor
</subsectionHeader>
<bodyText confidence="0.9999698">
This module uses finite-state transducer
technology in order to identify message content.
Information at the top of the message related to
“From/To/Date&amp;quot; as well as the signature block
are separated from the message content.
</bodyText>
<subsectionHeader confidence="0.999896">
2.2 Candidate Simple Noun Phrase Extraction and
Filtering Unit
</subsectionHeader>
<bodyText confidence="0.9999954">
This module performs shallow text processing
for extraction and filtering of simple NP
candidates, consisting of a pipeline of three
modules: text tokenization, NP extraction, and
NP filtering. Since the tool was created to
preprocess email for speech output, some of the
text tokenization suitable for speech is not
accurate for text processing and some
modifications needed to be implemented (e.g.
email preprocessor splits acronyms like DLI2
into DLI 2). The noun phrase extraction module
uses Brill&apos;s POS tagger [Brill (1992)]and a base
NP chunker [Ramshaw and Marcus (1995)].
After analyzing some of these errors, we
augmented the tagger lexicon from our training
data and we added lexical and contextual rules
to deal mainly with incorrect tagging of gerund
endings. In order to improve the accuracy of
classifiers we perform linguistic filtering, as
discussed in detail in Section 3.1.2.
</bodyText>
<subsectionHeader confidence="0.999783">
2.3 Machine Learning Unit
</subsectionHeader>
<bodyText confidence="0.999978071428571">
The first component of the ML unit is the
feature selection module to compute NP
vectors. In the training phase, a model for
identifying salient simple NPs is created.
The training data consist of a list of feature
vectors already classified as salient/non-
salient by the user. Thus we rely on user-
relevance judgments to train the ML unit. In
the extraction phase this unit will classify
relevant NPs using the model generated
during training. We applied three machine
learning paradigms (decision trees, rule
induction algorithms, and decision forest)
evaluating three different classifiers.
</bodyText>
<subsectionHeader confidence="0.998945">
2.4 Presentation
</subsectionHeader>
<bodyText confidence="0.999982277777778">
The presentation of the message gist is a
complex user interface issue with its
independent set of problems. Depending on
the application and its use, one can think of
different presentation techniques. The gist of
the message could be the set of NPs or the set
of sentences in which these NPs occur so that
the added context would make it more
understandable to the user. We do not address
in this work the disfluency that could occur in
listing a set of extracted sentences, since the
aim is to deliver to the user the very content
of the message even in a raw fashion. GIST-
IT is to be used in an application where the
output is synthesized speech. The focus of
this paper is on extracting content with GIST-
IT, although presentation is a topic for future
research.
</bodyText>
<subsectionHeader confidence="0.758045">
3 Combining Linguistic Knowledge and
Machine Learning for Email Gisting
</subsectionHeader>
<bodyText confidence="0.999975172413793">
We combine symbolic machine learning and
linguistic processing in order to extract the
salient phrases of a document. Out of the
large syntactic constituents of a sentence, e.g.
noun phrases, verb phrases, and prepositional
phrases, we assume that noun phrases (NPs)
carry the most contentful information about
the document, even if sometimes the verbs
are important too, as reported in the work by
[Klavans and Kan (1998)]. The problem is
that no matter the size of a document, the
number of informative noun phrases is very
small comparing with the number of all noun
phrases, making selection a necessity. Indeed, in
the context of gisting, generating and presenting
the list of all noun phrases, even with adequate
linguistic filtering, may be overwhelming. Thus,
we define the extraction of important noun
phrases as a classification task, applying
machine learning techniques to determine which
features associated with the candidate NPs
classify them as salient vs. non-salient. We
represent the document -- in this case an email
message -- as a set of candidate NPs, each of
them associated with a feature vector used in the
classification model. We use a number of
linguistic methods both in the extraction and in
the filtering of candidate noun phrases, and in
the selection of the features.
</bodyText>
<subsectionHeader confidence="0.990219">
3.1 Candidate NPs
</subsectionHeader>
<bodyText confidence="0.9997124">
Noun phrases were extracted using Ramshaw
and Marcus&apos;s base NP chunker [Ramshaw and
Marcus (1995)]. The base NP is either a simple
NP as defined by Wacholder (1998) or a
conjunction of two simple NPs. Since the
feature vectors used in the classifier scheme are
simple NPs we used different heuristics to
automatically split the conjoined NPs (CNP)
into simple ones (SNP), properly assigning the
premodifiers. Table 1 presents such an example:
</bodyText>
<table confidence="0.983281">
CNP: physics/NN and/CC biology/NN skilled/JJ
researchers/NNS
SNP1: physics/NN skilled/JJ researchers/NNS
SNP2: biology/NN skilled/JJ researchers/NNS
</table>
<tableCaption confidence="0.6362555">
Table 1 Splitting Complex NPs into Simple NPs
3.1.2 Filtering simple NPs
</tableCaption>
<bodyText confidence="0.9105994">
Since not all simple noun phrases are equally
important to reflect the document meaning, we
use well-defined linguistic properties to extract
only those NPs (or parts of NPs) that have a
greater chance to render the salient information.
By introducing this level of linguistic filtering
before applying the learning scheme, we
improve the accuracy of the classifiers, thus
obtaining better results (see discussion in
sections 4.1.3 and 5.3). We performed four
filtering steps:
1. Inflectional morphological processing.
English nouns have only two kinds of inflection:
an affix that marks plural and an affix that
marks possessive.
</bodyText>
<listItem confidence="0.987891441176471">
2. Removing unimportant modifiers. In this
second step we remove the determiners that
accompany the nouns and also the auxiliary
words most and more that form the
periphrastic forms of comparative and
superlative adjectives modifying the nouns.
3. Remove common words. We used a list of
571 common words used in IR systems in
order to further filter the list of candidate
NPs. Thus, words like even, following, every,
are eliminated from the noun phrase
structure. (i.e. “even more detailed
information” and “detailed information” will
also be grouped together).
4. Remove ‘empty’ nouns. Words like lot,
group, set, bunch are considered ‘empty’
nouns in the sense that they have no
contribution to the noun phrase meaning. For
example the meaning of the noun phrases like
“group of students”, “lots of students” or
“bunch of students” is given by the noun
“students”. In order not to bias the extraction
of empty nouns we used three different data
collections: Brown corpus, Wall Street
Journal, and a set of 4000 email messages
(most of which were collected during a
conference organization). Our algorithm was
a simple one: we extracted all the nouns that
appear in front of the preposition “of” and
then sorted them by frequency of appearance
in all three corpora and used a threshold to
select the final list. We generated a set of 141
empty nouns that we used in this forth step of
filtering process.
</listItem>
<subsectionHeader confidence="0.99975">
3.2 Feature Selection
</subsectionHeader>
<bodyText confidence="0.998239090909091">
We select a set of nine features that fall into
three categories: linguistic, statistical
(frequency-based) and positional. These
features capture information about the
relative importance of NPs to the document
meaning.
Several studies rely on linguistic intuition
that the head of the noun phrase makes a
greater contribution to the semantics of the
nominal group than the modifiers. For some
NLP tasks, the head is not necessarily the
most important item of the noun phrase. In
analyzing email messages from the
perspective of finding salient NPs, we claim
that the constituents of the NP have often as
much semantic content as the head. This
opinion is also supported in the work of
[Strzalkowski et al (1999)]. In many cases, the
meaning of the NP is given equally by
modifier(s) -- usually nominal modifiers(s) --
and head. Consider the following list of simple
NPs selected as candidates:
</bodyText>
<listItem confidence="0.98877925">
(1) “conference workshop announcement”
(2) “international conference”
(3) “workshop description”
(4) “conference deadline”
</listItem>
<bodyText confidence="0.999965181818182">
In the case of noun phrase (1) the importance of
the noun phrase is found in the two noun
modifiers: conference and workshop as much
as in the head announcement. We test this
empirical observation by introducing as a
separate feature in the feature vector, a new
TF*IDF measure that counts for both the
modifiers and the head of the noun phrase, thus
seeing the NP as a sequence of equally weighted
elements. For the example above the new
feature will be:
</bodyText>
<equation confidence="0.880172">
TF*IDFconference + TF*IDFworkshop + TF*IDFannouncement
</equation>
<bodyText confidence="0.999965521739131">
We divided the set of features into three
groups: one associated with the head of the noun
phrase, one associated with the whole NP and
one that represents the new TF*IDF measure
discussed above. Since we want to use this
technique on other types of documents, all
features are independent of the text type or
genre. For example, in the initial selection of
our attributes we introduced as separate features
the presence or the absence of NPs in the subject
line of the email and in the headline of the body.
Kilander (1996) pointed out that users estimate
that “subject lines can be useful, but also
devastating if their importance is overly
emphasized”. Based on this study and also on
our goal to provide a method that is domain and
genre independent we decided not to consider
the subject line and the headlines as separate
features, but rather as weights included in the
TF*IDF measures as presented below. Another
motivation for this decision is that in email
processing the correct identification of headlines
is not always clear.
</bodyText>
<subsubsectionHeader confidence="0.983899">
3.2.1 Features associated with the Head
</subsubsectionHeader>
<bodyText confidence="0.9998955">
We choose two features to characterize the head
of the noun phrases:
head_tfidf – the TF*IDF measure of the
head of the candidate NP.
head_focc - The first occurrence of the head
in text (the numbers of words that precede the
head divided by the total number of words in
the document).
</bodyText>
<subsubsectionHeader confidence="0.622113">
3.2.2 Features associated with the whole
NP
</subsubsectionHeader>
<bodyText confidence="0.999588653846154">
We select six features that we consider
relevant in association with the whole NP:
np_tfidf – the TF*IDF measure associated
with the whole NP.
np_focc - The first occurrence of the noun
phrase in the document.
np_length_words - Noun phrase length
measured in number of words, normalized by
dividing it with the total numbers of words in
the candidate NPs list.
np_length_chars - Noun phrase length
measured in number of characters,
normalized by dividing it with the total
numbers of characters in the candidate NPs
list.
sent_pos - Position of the noun phrase in
sentence: the number of words that precede
the noun phrase, divided by the sentence
length. For noun phrases in the subject line
and headlines (which are usually short and
will be affected by this measure), we consider
the maximum length of sentence in document
as the normalization factor.
par_pos - Position of noun phrase in
paragraph, same as sent_pos, but at the
paragraph level.
</bodyText>
<subsubsectionHeader confidence="0.656741">
3.2.3 Feature that considers all constituents
</subsubsectionHeader>
<bodyText confidence="0.91313435">
of the NP equally weighted
m_htfidf - the new TF*IDF measure that
take into consideration the importance of the
modifiers.
In computing the TF*IDF measures
(head_tfidf, np_tfidf, m_tfidf), weights wi,
were assigned to account for the presence in
the subject line and/or headline.
wi1 – if the head appears both in the subject
line and headline;
wi2 – if the head appears only in the subject
line;
wi3 – if the head appears only in headlines
where wi1
These weights were manually chosen after
a set of experiments, but we plan to use either
&gt; wi2
&gt; wi3.
a regression method or explore with genetic
algorithms to automatically learn them.
</bodyText>
<subsectionHeader confidence="0.9992">
3.3 Three Paradigms of Supervised Machine
Learning
</subsectionHeader>
<bodyText confidence="0.99998746875">
Symbolic machine learning is used in
conjunction with many NLP applications
(syntactic and semantic parsing, POS tagging,
text categorization, word sense disambiguation).
In this paper we compare three symbolic
learning techniques applied to the task of salient
NP extraction: decision tree, rule induction
learning and decision forests.
We tested the performance of an axis-parallel
decision tree, C4.5 [Quinlan (1993)]; a rule
learning system RIPPER [Cohen (1995)] and a
decision forest classifier (DFC) [Ho (1998)].
RIPPER allows the user to specify the loss ratio,
which indicates the ratio of the cost of a false
positive to the cost of a false negative, thus
allowing the trade off between precision and
recall. This is crucial for our analysis since we
deal with sparse data set (in a document the
number of salient NPs is much smaller than the
number of irrelevant NPs). Finally we tried to
prove that a combination of classifiers might
improve accuracy, increasing both precision and
recall. The Decision Forest Classifier (DFC)
uses an algorithm for systematically
constructing decision trees by pseudo-randomly
selecting subsets of components of feature
vectors. It implements different splitting
functions. In the setting of our evaluation we
tested the information gain ratio (similar to the
one used by Quinlan in C4.5). An augmented
feature vector (pairwise sums, differences, and
products of features) was used for this classifier.
</bodyText>
<sectionHeader confidence="0.922389" genericHeader="evaluation">
4 Evaluation and Experimental Results
</sectionHeader>
<bodyText confidence="0.999984125">
Since there are many different summaries for
each document, evaluating summaries is a
difficult problem. Extracting the salient noun
phrases is the first key step in the summarization
method that we adopt in this paper. Thus, we
focus on evaluating the performance of GIST-IT
on this task, using three classification schemes
and two different feature settings.
</bodyText>
<subsectionHeader confidence="0.999335">
4.1 Evaluation Scheme
</subsectionHeader>
<bodyText confidence="0.987877">
There are several questions that we address in
this paper:
</bodyText>
<subsubsectionHeader confidence="0.847676">
4.1.1 What features or combination of
</subsubsectionHeader>
<bodyText confidence="0.971920333333333">
features are important in determining the
degree of salience of an NP?
Following our assumption that each
constituent of the noun phrase is equally
meaningful, we evaluate the impact of adding
m_hyfidf (see section 3.2.3), as an additional
feature in the feature vector. This is shown in
Table 2 in the different feature vectors fv1
and fv2.
</bodyText>
<tableCaption confidence="0.7478215">
fv1- head_focc head_tfidf np_focc np_tfidf
np_length_words np_length_chars par_pos sent_pos
fv2 - head_focc head_tfidf m_htfidf np_focc np_tfidf
np_length_words np_length_chars par_pos sent_pos
Table 2 Two feature settings to evaluate the
impact of m_htfidf
</tableCaption>
<subsubsectionHeader confidence="0.868199">
4.1.2 What classification scheme is more
</subsubsectionHeader>
<bodyText confidence="0.971227125">
adequate to our task?
We evaluate the performance of three
different classifiers in the task of extracting
salient noun phrases. As measures of
performance we use precision (p) and recall
(r). The evaluation was performed according
to what degree the output of the classifiers
corresponds to the user judgments.
</bodyText>
<table confidence="0.997667">
Feature C4.5 Ripper DFC
vectors
p r p r p r
fv1 73.3 78.6 83.6 71.4 80.3 83.5
fv2 70 88.9 85.7 78.8 85.7 87.9
</table>
<tableCaption confidence="0.9503715">
Table 3 Evaluation of two feature vectors using
three classifiers
</tableCaption>
<bodyText confidence="0.995759">
Table 3 shows our results that answer
these two questions. The table rows represent
the two feature vectors we are comparing,
and the columns correspond to the three
classifiers chosen for the evaluation.
</bodyText>
<subsubsectionHeader confidence="0.736175">
4.1.3 Is linguistic filtering an important step
</subsubsectionHeader>
<bodyText confidence="0.929452">
in extracting salient NPs?
In the third evaluation we analyse the impact
of linguistic filtering on the classifier’s
performance. It turns out that results show
major improvements, from 69.2% to 85.7%
for precision of fv2, and from 56.25% to
87.9% for recall of fv2. For detailed results,
see [Muresan et al, (2001)].
4.1.4 After the filtering and classification, are
noun phrases good candidates for representing
the gist of an email message?
In order to answer this question, we compare
the output of GIST-IT on one email with the
results of KEA system [Witten et al (1999)] that
uses a &apos;bag-of-words&apos; approach to key phrase
extraction (see Table 4).
</bodyText>
<figure confidence="0.9876065">
module Perl module wordne
sort of batch interface
WordNet data &apos;wn&apos; command line program
accesses simple easy perl interface
the WordNet included man page
lots of WordNet wordnet
WordNet perl wordnet.pm module
QueryData wordnet system
wn wordnet package
perl module query perl module
extracting command line
use this module wordnet relation
extracting lots wordnet data
WordNet system free software
www.cogsci.princeton.e querydata
du
</figure>
<tableCaption confidence="0.783401">
Table 4 KEA (left) vs GIST-IT output (right)
5 Discussion of results
</tableCaption>
<bodyText confidence="0.999982428571428">
The results shown indicate that best system
performance reached 87.9% recall and 85.7%
precision. Although these results are very high,
judging NP relevance is a complex and highly
variable task. In the future, we will extend the
gold standard with more judges, more data, and
thus a more precise standard for measurement.
</bodyText>
<subsectionHeader confidence="0.999136">
5.1 The right selection of features
</subsectionHeader>
<bodyText confidence="0.9999864">
Feature selection has a decisive impact on
overall performance. As seen in Table 2, fv2 has
m_htfidf as an additional feature, and its
performance shown in Table 3 is superior to fv1;
the DFC classifier shows an increase both in
precision and recall. These results support the
original hypothesis that in the context of gisting,
the syntactic head of the noun phrase is not
always the semantic head, and modifiers can
also have an important role.
</bodyText>
<subsectionHeader confidence="0.998488">
5.2 Different classification models
</subsectionHeader>
<bodyText confidence="0.999965666666667">
The effectiveness of different classification
schemes in the context of our task is discussed
here. As shown in Table 3, C4.5 performs well
especially in terms of recall. RIPPER, as
discussed in [Cohen (1995)], is more appropriate
for noisy and sparse data collection than
C4.5, showing an improvement in precision.
Finally, DFC which is a combination of
classifiers, shows improved performance.
The classifier was run with an augumented
feature vector that included pairwise sums,
differences and products of the features.
</bodyText>
<subsectionHeader confidence="0.999872">
5.3 Impact of linguistic knowledge
</subsectionHeader>
<bodyText confidence="0.999994333333333">
As shown in previous section, DFC
performed best in our task, so we chose only
this classifier to present the impact of
linguistic knowledge. Linguistic filtering
improved precision and recall, having an
important role especially on fv2, where the
new feature m_tfidf was used. This is
explained by the fact that the filtering
presented in section 3.1.2 removed the noise
introduced by unimportant modifiers,
common and empty nouns, thus giving this
new feature a larger impact.
</bodyText>
<subsectionHeader confidence="0.993096">
5.4 Noun phrases are better than n-grams
</subsectionHeader>
<bodyText confidence="0.9999894">
Presenting the gist of an email message by
phrase extraction addresses one obvious
question: can any phrasal extract represent
the content of a document, or must a well
defined linguistic phrasal structure be used?
To answer this question we compare the
results of our system that extract
linguistically principled phrasal units, with
KEA output, that extracts bigrams and
trigrams as key phrases [Witten et al (1999)].
Table 4 shows the results of the KEA system.
Due to the n-gram approach, KEA output
contains phrases like sort of batch, extracting
lots, wn, and even urls that are unlikely to
represent the gist of a document.
</bodyText>
<subsectionHeader confidence="0.569734">
Conclusion and future work
</subsectionHeader>
<bodyText confidence="0.9998431">
In this paper we presented a novel technique
for document gisting suitable for domain and
genre independent collections such as email
messages. The method extracts simple noun
phrases using linguistic techniques and then
use machine learning to classify them as
salient for the document content. We
evaluated the system in different
experimental settings using three
classification models. In analyzing the
structure of NPs, we demonstrated that the
modifiers of a noun phrase can be
semantically as important as the head for the
task of gisting. GIST-IT is fully implemented,
evaluated, and embedded in an application,
which allows user to access a set of information
including email, finances, etc.
We plan to extend our work by taking
advantage of structured email, by classifying
messages into folders, and then by applying
information extraction techniques. Since NPs
and machine learning techniques are domain and
genre independent, we plan to test GIST-IT on
different data collections (e.g. web pages), and
for other knowledge management tasks, such as
document indexing or query refinement.
Additionally, we plan to test the significance of
the output for the user, i.e. whether the system
provide informative content and adequate gist of
the message.
</bodyText>
<sectionHeader confidence="0.996763" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998848">
Berger, A.L and Mittal, V.O (2000). OCELOT:A system for
summarizing web pages. In Proceedings of the 23rd
Annual International ACM SIGIR, Athens, Greece, pp
144-151.
Brill, E. (1992). A Simple Rule-based Part of Speech
Tagger. In Proceedings of the Third Conference on
ANLP. Trento, Italy; 1992
Boguraev, B. and Kennedy, C. (1999). Salience-based
content characterisation of text documents. In I. Mani
and T. Maybury, M., editors, Advances in Automatic
Text Summarization, pp 99-111. The MIT Press.
Cohen, W. (1995). Fast Effective Rule Induction. Machine-
Learning: Proceedings of the Twelfth International
Conference.
Ho, T.K (1998). The random subspace method for
constructing decision forests. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 20(8).
Hovy, E.H (2000). Automated Text Summarization. In R.
Mitkov, editor, Oxford University Handbook of
Computational Linguistics. Oxford Univ. Press.
Kilander, F. (1996). Properties of electronic texts for
classification purposes as suggested by users.
Klavans, J.L., Wacholder, N. and Evans, D.K. (2000)
Evaluation of computational linguistic techniques for
identifying significant topics for browsing applications.
In Proceedings (LREC-2000), Athens. Greece.
Klavans, J.L. and Kan, M-Y. (1998).Role of verbs in
document analysis. In proceedings of COLING/ACL 98.
Kupiec, J., Pedersen, J. and Chen, F. (1995). A trainable
document summarizer. In Proceedings of the 18th
Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval, pp
68-73, Seattle, WA.
McKeown, K.R, Klavans, J.L, Hatzivassiloglou, V.,
Barzilay, R. and Eskin, E. (1999). Towards
multidocument summarization by reformulation:
Progress and prospects. In Proceedings of AAAI&apos;99.
McKeown, K.R and Radev, D.R (1995). Generating
summaries of multiple news articles. In Proceedings
of the 18th Annual International ACM SIGIR
Conference on Research and Development in
Information Retrieval, pp 74-82, Seattle, WA.
Muresan, S., Tzoukermann, E. and Klavans, J.L.
(2001). Email Summarization Using Linguistic and
Machine Learning Techniques. In Proceedings of
CoNLL 2001 ACL Workshop, Toulouse, France.
Murthy, S.K., Kasif, S., Salzberg, S. and Beigel, R.
(1993). OC1: Randomized Induction of Oblique
Decision Trees. Proceedings of the Eleventh National
Conference on Artificial Intelligence, pp. 322--327,
Washington, D.C.
Quinlan, J.R (1993). C4.5: Program for Machine
Learning. Morgan Kaufmann.
Ramshaw, L.A. and Marcus, M.P. (1995). Text
Chunking Using Transformation-Based Learning. In
Proceedings of Third ACL Workshop on Very Large
Corpora, MIT.
Sparck-Jones, K. (1999). What Is The Role of NLP in
Text Retrieval. In T. Strzalkowski, editor, Natural
Language Information Retrieval. Kluwer, Boston,
MA.
Strzalkowski, T., Lin, F., Wang, J., and Perez-Carballo,
J. (1999). Evaluating natural language processing
techniques for information retrieval. In T.
Strzalkowski, editor, Natural Language Information
Retrieval. Kluwer, Boston, MA.
Turney, P.D. (2000). Learning algorithms for
keyphrase exraction. Information Retrieval, 2(4): pp
303-336.
Ueda, Y., Oka M., Koyama T. and Miyauchi T (2000).
Toward the &amp;quot;at-a-glance&amp;quot; summary: Phrase-
representation summarization method. In
Proceedings of COLING 2000.
Wacholder, N. (1998). Simplex NPS sorted by head: a
method for identifying significant topics within a
document, In Proceedings of the COLING-ACL
Workshop on the Computational Treatment of
Nominals.
Whittaker, S. and Sidner, C. Email overload: Exploring
personal information management of email. In
Proceedings of CHI’96. p. 276-283. NY:ACM Press
Witten, I.H, Paynter, G.W., Frank E., Gutwin C. and
Nevill-Manning, C.G (1999). KEA: Practical
automatic keyphrase extraction. In Proceedings of
DL&apos;99, pp 254-256.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.630350">
<title confidence="0.9962815">GIST-IT: Summarizing Email Using Linguistic Knowledge and Machine Learning</title>
<address confidence="0.989816">Evelyne Tzoukermann Bell Labs, Lucent Technologies Smaranda Muresan Columbia University W Street Judith L. Klavans Columbia University Center for Research on Information Access W Street New York, NY, 10027, USA</address>
<email confidence="0.8381045">700MountainAvenueMurrayHill,NJ,07974,USANewYork,NY,10027,USAsmara@cs.columbia.eduklavans@cs.columbia.eduevelyne@lucent.com</email>
<abstract confidence="0.99595125">We present a system for the automatic extraction of salient information from email messages, thus providing the gist of their meaning. Dealing with email raises several challenges that we address in this paper: heterogeneous data in terms of length and topic. Our method combines shallow linguistic processing with machine learning to extract phrasal units that are representative of email content. The GIST-IT application is fully implemented and embedded in an active mailbox platform. Evaluation performed over three machine learning paradigms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>V O Mittal</author>
</authors>
<title>OCELOT:A system for summarizing web pages.</title>
<date>2000</date>
<booktitle>In Proceedings of the 23rd Annual International ACM SIGIR,</booktitle>
<pages>144--151</pages>
<location>Athens, Greece,</location>
<contexts>
<context position="1442" citStr="Berger and Mittal (2000)" startWordPosition="206" endWordPosition="209"> representative of email content. The GIST-IT application is fully implemented and embedded in an active mailbox platform. Evaluation was performed over three machine learning paradigms. Introduction The volume of email messages is huge and growing. A qualitative and quantitative study of email overload [Whittaker and Sidner (1996)] shows that people receive a large number of email messages each day (~ 49) and that 21% of their inboxes (about 334 messages) are long messages (over 10 Kbytes). Therefore summarization techniques adequate for realworld applications are of great interest and need [Berger and Mittal (2000), McKeown and Radev (1995), Kupiec et al (1995), McKeown et al (1999), Hovy (2000)]. In this paper we present GIST-IT, an automatic email message summarizer that will convey to the user the gist of the document through topic phrase extraction, by combining linguistic and machine learning techniques. Email messages and web documents raise several challenges to automatic text processing, and the summarization task addresses most of them: they are free-style text, not always syntactically or grammatically well-formed, domain and genre independent, of variable length and on multiple topics. Furthe</context>
<context position="5128" citStr="Berger and Mittal (2000)" startWordPosition="770" endWordPosition="773">al task [Strzalkowski et al (1999), Sparck-Jones (1999)]. Strzalkowski et al (1999) uses head + modifier pairs as part of a larger system which constitutes the “stream model” that is used for information retrieval. They treat the head-modifier relationship as an ”ordered relation between otherwise equal elements”, emphasizing that for some tasks, the syntactic head of the NP is not necessarily a semantic head, and the modifier is not either necessarily a semantic modifier and that the opposite is often true. Using a machine learning approach, we proved this hypothesis for the task of gisting. Berger and Mittal (2000) present a summarization system named OCELOT, based on probabilistic models, which provides the gist of web documents. Like email messages, web documents are also very heterogeneous and their unstructured nature pose equal difficulties. In this paper, we propose a novel technique for summarization that combines the linguistic approach of extracting simple noun phrases as possible candidates for document extracts, and the use of machine learning algorithms to automatically select the most salient ones. 2 System architecture The input to GIST-IT is a single email message. The architecture, prese</context>
</contexts>
<marker>Berger, Mittal, 2000</marker>
<rawString>Berger, A.L and Mittal, V.O (2000). OCELOT:A system for summarizing web pages. In Proceedings of the 23rd Annual International ACM SIGIR, Athens, Greece, pp 144-151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A Simple Rule-based Part of Speech Tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the Third Conference on ANLP.</booktitle>
<location>Trento, Italy;</location>
<contexts>
<context position="7854" citStr="Brill (1992)" startWordPosition="1197" endWordPosition="1198">he message content. 2.2 Candidate Simple Noun Phrase Extraction and Filtering Unit This module performs shallow text processing for extraction and filtering of simple NP candidates, consisting of a pipeline of three modules: text tokenization, NP extraction, and NP filtering. Since the tool was created to preprocess email for speech output, some of the text tokenization suitable for speech is not accurate for text processing and some modifications needed to be implemented (e.g. email preprocessor splits acronyms like DLI2 into DLI 2). The noun phrase extraction module uses Brill&apos;s POS tagger [Brill (1992)]and a base NP chunker [Ramshaw and Marcus (1995)]. After analyzing some of these errors, we augmented the tagger lexicon from our training data and we added lexical and contextual rules to deal mainly with incorrect tagging of gerund endings. In order to improve the accuracy of classifiers we perform linguistic filtering, as discussed in detail in Section 3.1.2. 2.3 Machine Learning Unit The first component of the ML unit is the feature selection module to compute NP vectors. In the training phase, a model for identifying salient simple NPs is created. The training data consist of a list of f</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Brill, E. (1992). A Simple Rule-based Part of Speech Tagger. In Proceedings of the Third Conference on ANLP. Trento, Italy; 1992</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Boguraev</author>
<author>C Kennedy</author>
</authors>
<title>Salience-based content characterisation of text documents.</title>
<date>1999</date>
<booktitle>Advances in Automatic Text Summarization,</booktitle>
<pages>99--111</pages>
<editor>In I. Mani and T. Maybury, M., editors,</editor>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="3447" citStr="Boguraev and Kennedy (1999)" startWordPosition="508" endWordPosition="511"> the usefulness of vector representation in determining proper features to identify contentful information, (c) the benefit of using a new measure of TF*IDF for the noun phrase and its constituents, (d) the power of machine learning systems in evaluating several classifiers in order to select the one performing the best for this task. 1 Related work Traditionally a document summary is seen as a small, coherent prose that renders to the user the important meaning of the text. In this framework most of the research has focused on extractive summaries at sentence level. However, as discussed in [Boguraev and Kennedy (1999)], the meaning of ‘summary’ should be adjusted depending on the information management task for which it is used. Key phrases, for example, can be seen as semantic metadata that summarize and characterize documents [Witten et al (1999), Turney (1999)]. These approaches select a set of candidate phrases (sequence of one, two or three consecutive stemmed, non-stop words) and then apply machine learning techniques to classify them as key phrases or not. But dealing only with n-grams does not always provide good output in terms of a summary (see discussion in Section 5.4). Wacholder (1998) propose</context>
</contexts>
<marker>Boguraev, Kennedy, 1999</marker>
<rawString>Boguraev, B. and Kennedy, C. (1999). Salience-based content characterisation of text documents. In I. Mani and T. Maybury, M., editors, Advances in Automatic Text Summarization, pp 99-111. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Cohen</author>
</authors>
<title>Fast Effective Rule Induction.</title>
<date>1995</date>
<booktitle>MachineLearning: Proceedings of the Twelfth International Conference.</booktitle>
<contexts>
<context position="18824" citStr="Cohen (1995)" startWordPosition="2986" endWordPosition="2987"> wi2 &gt; wi3. a regression method or explore with genetic algorithms to automatically learn them. 3.3 Three Paradigms of Supervised Machine Learning Symbolic machine learning is used in conjunction with many NLP applications (syntactic and semantic parsing, POS tagging, text categorization, word sense disambiguation). In this paper we compare three symbolic learning techniques applied to the task of salient NP extraction: decision tree, rule induction learning and decision forests. We tested the performance of an axis-parallel decision tree, C4.5 [Quinlan (1993)]; a rule learning system RIPPER [Cohen (1995)] and a decision forest classifier (DFC) [Ho (1998)]. RIPPER allows the user to specify the loss ratio, which indicates the ratio of the cost of a false positive to the cost of a false negative, thus allowing the trade off between precision and recall. This is crucial for our analysis since we deal with sparse data set (in a document the number of salient NPs is much smaller than the number of irrelevant NPs). Finally we tried to prove that a combination of classifiers might improve accuracy, increasing both precision and recall. The Decision Forest Classifier (DFC) uses an algorithm for syste</context>
<context position="23914" citStr="Cohen (1995)" startWordPosition="3794" endWordPosition="3795">e 2, fv2 has m_htfidf as an additional feature, and its performance shown in Table 3 is superior to fv1; the DFC classifier shows an increase both in precision and recall. These results support the original hypothesis that in the context of gisting, the syntactic head of the noun phrase is not always the semantic head, and modifiers can also have an important role. 5.2 Different classification models The effectiveness of different classification schemes in the context of our task is discussed here. As shown in Table 3, C4.5 performs well especially in terms of recall. RIPPER, as discussed in [Cohen (1995)], is more appropriate for noisy and sparse data collection than C4.5, showing an improvement in precision. Finally, DFC which is a combination of classifiers, shows improved performance. The classifier was run with an augumented feature vector that included pairwise sums, differences and products of the features. 5.3 Impact of linguistic knowledge As shown in previous section, DFC performed best in our task, so we chose only this classifier to present the impact of linguistic knowledge. Linguistic filtering improved precision and recall, having an important role especially on fv2, where the n</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>Cohen, W. (1995). Fast Effective Rule Induction. MachineLearning: Proceedings of the Twelfth International Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Ho</author>
</authors>
<title>The random subspace method for constructing decision forests.</title>
<date>1998</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>20</volume>
<issue>8</issue>
<contexts>
<context position="18875" citStr="Ho (1998)" startWordPosition="2994" endWordPosition="2995">c algorithms to automatically learn them. 3.3 Three Paradigms of Supervised Machine Learning Symbolic machine learning is used in conjunction with many NLP applications (syntactic and semantic parsing, POS tagging, text categorization, word sense disambiguation). In this paper we compare three symbolic learning techniques applied to the task of salient NP extraction: decision tree, rule induction learning and decision forests. We tested the performance of an axis-parallel decision tree, C4.5 [Quinlan (1993)]; a rule learning system RIPPER [Cohen (1995)] and a decision forest classifier (DFC) [Ho (1998)]. RIPPER allows the user to specify the loss ratio, which indicates the ratio of the cost of a false positive to the cost of a false negative, thus allowing the trade off between precision and recall. This is crucial for our analysis since we deal with sparse data set (in a document the number of salient NPs is much smaller than the number of irrelevant NPs). Finally we tried to prove that a combination of classifiers might improve accuracy, increasing both precision and recall. The Decision Forest Classifier (DFC) uses an algorithm for systematically constructing decision trees by pseudo-ran</context>
</contexts>
<marker>Ho, 1998</marker>
<rawString>Ho, T.K (1998). The random subspace method for constructing decision forests. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(8).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Automated Text Summarization. In</title>
<date>2000</date>
<booktitle>Oxford University Handbook of Computational Linguistics. Oxford</booktitle>
<editor>R. Mitkov, editor,</editor>
<publisher>Univ. Press.</publisher>
<contexts>
<context position="1524" citStr="Hovy (2000)" startWordPosition="222" endWordPosition="223">an active mailbox platform. Evaluation was performed over three machine learning paradigms. Introduction The volume of email messages is huge and growing. A qualitative and quantitative study of email overload [Whittaker and Sidner (1996)] shows that people receive a large number of email messages each day (~ 49) and that 21% of their inboxes (about 334 messages) are long messages (over 10 Kbytes). Therefore summarization techniques adequate for realworld applications are of great interest and need [Berger and Mittal (2000), McKeown and Radev (1995), Kupiec et al (1995), McKeown et al (1999), Hovy (2000)]. In this paper we present GIST-IT, an automatic email message summarizer that will convey to the user the gist of the document through topic phrase extraction, by combining linguistic and machine learning techniques. Email messages and web documents raise several challenges to automatic text processing, and the summarization task addresses most of them: they are free-style text, not always syntactically or grammatically well-formed, domain and genre independent, of variable length and on multiple topics. Furthermore, due to the lack of well-formed syntactic and grammatical structures, the gr</context>
</contexts>
<marker>Hovy, 2000</marker>
<rawString>Hovy, E.H (2000). Automated Text Summarization. In R. Mitkov, editor, Oxford University Handbook of Computational Linguistics. Oxford Univ. Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Kilander</author>
</authors>
<title>Properties of electronic texts for classification purposes as suggested by users.</title>
<date>1996</date>
<contexts>
<context position="15792" citStr="Kilander (1996)" startWordPosition="2490" endWordPosition="2491">mple above the new feature will be: TF*IDFconference + TF*IDFworkshop + TF*IDFannouncement We divided the set of features into three groups: one associated with the head of the noun phrase, one associated with the whole NP and one that represents the new TF*IDF measure discussed above. Since we want to use this technique on other types of documents, all features are independent of the text type or genre. For example, in the initial selection of our attributes we introduced as separate features the presence or the absence of NPs in the subject line of the email and in the headline of the body. Kilander (1996) pointed out that users estimate that “subject lines can be useful, but also devastating if their importance is overly emphasized”. Based on this study and also on our goal to provide a method that is domain and genre independent we decided not to consider the subject line and the headlines as separate features, but rather as weights included in the TF*IDF measures as presented below. Another motivation for this decision is that in email processing the correct identification of headlines is not always clear. 3.2.1 Features associated with the Head We choose two features to characterize the hea</context>
</contexts>
<marker>Kilander, 1996</marker>
<rawString>Kilander, F. (1996). Properties of electronic texts for classification purposes as suggested by users.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Klavans</author>
<author>N Wacholder</author>
<author>D K Evans</author>
</authors>
<title>Evaluation of computational linguistic techniques for identifying significant topics for browsing applications.</title>
<date>2000</date>
<booktitle>In Proceedings (LREC-2000),</booktitle>
<location>Athens. Greece.</location>
<contexts>
<context position="4285" citStr="Klavans et al (2000)" startWordPosition="641" endWordPosition="644">tten et al (1999), Turney (1999)]. These approaches select a set of candidate phrases (sequence of one, two or three consecutive stemmed, non-stop words) and then apply machine learning techniques to classify them as key phrases or not. But dealing only with n-grams does not always provide good output in terms of a summary (see discussion in Section 5.4). Wacholder (1998) proposes a linguisticallymotivated method for the representation of the document aboutness: ‘head clustering’. A list of simple noun phrases is first extracted, clustered by head and then ranked by the frequency of the head. Klavans et al (2000) report on the evaluation of ‘usefulness’ of head clustering in the context of browsing applications, in terms of quality and coverage. Other researchers have used noun-phrases quite successfully for information retrieval task [Strzalkowski et al (1999), Sparck-Jones (1999)]. Strzalkowski et al (1999) uses head + modifier pairs as part of a larger system which constitutes the “stream model” that is used for information retrieval. They treat the head-modifier relationship as an ”ordered relation between otherwise equal elements”, emphasizing that for some tasks, the syntactic head of the NP is </context>
</contexts>
<marker>Klavans, Wacholder, Evans, 2000</marker>
<rawString>Klavans, J.L., Wacholder, N. and Evans, D.K. (2000) Evaluation of computational linguistic techniques for identifying significant topics for browsing applications. In Proceedings (LREC-2000), Athens. Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Klavans</author>
<author>M-Y Kan</author>
</authors>
<title>of verbs in document analysis.</title>
<date>1998</date>
<booktitle>In proceedings of COLING/ACL 98.</booktitle>
<contexts>
<context position="10116" citStr="Klavans and Kan (1998)" startWordPosition="1569" endWordPosition="1572">zed speech. The focus of this paper is on extracting content with GISTIT, although presentation is a topic for future research. 3 Combining Linguistic Knowledge and Machine Learning for Email Gisting We combine symbolic machine learning and linguistic processing in order to extract the salient phrases of a document. Out of the large syntactic constituents of a sentence, e.g. noun phrases, verb phrases, and prepositional phrases, we assume that noun phrases (NPs) carry the most contentful information about the document, even if sometimes the verbs are important too, as reported in the work by [Klavans and Kan (1998)]. The problem is that no matter the size of a document, the number of informative noun phrases is very small comparing with the number of all noun phrases, making selection a necessity. Indeed, in the context of gisting, generating and presenting the list of all noun phrases, even with adequate linguistic filtering, may be overwhelming. Thus, we define the extraction of important noun phrases as a classification task, applying machine learning techniques to determine which features associated with the candidate NPs classify them as salient vs. non-salient. We represent the document -- in this</context>
</contexts>
<marker>Klavans, Kan, 1998</marker>
<rawString>Klavans, J.L. and Kan, M-Y. (1998).Role of verbs in document analysis. In proceedings of COLING/ACL 98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kupiec</author>
<author>J Pedersen</author>
<author>F Chen</author>
</authors>
<title>A trainable document summarizer.</title>
<date>1995</date>
<booktitle>In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>68--73</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="1489" citStr="Kupiec et al (1995)" startWordPosition="214" endWordPosition="217">ation is fully implemented and embedded in an active mailbox platform. Evaluation was performed over three machine learning paradigms. Introduction The volume of email messages is huge and growing. A qualitative and quantitative study of email overload [Whittaker and Sidner (1996)] shows that people receive a large number of email messages each day (~ 49) and that 21% of their inboxes (about 334 messages) are long messages (over 10 Kbytes). Therefore summarization techniques adequate for realworld applications are of great interest and need [Berger and Mittal (2000), McKeown and Radev (1995), Kupiec et al (1995), McKeown et al (1999), Hovy (2000)]. In this paper we present GIST-IT, an automatic email message summarizer that will convey to the user the gist of the document through topic phrase extraction, by combining linguistic and machine learning techniques. Email messages and web documents raise several challenges to automatic text processing, and the summarization task addresses most of them: they are free-style text, not always syntactically or grammatically well-formed, domain and genre independent, of variable length and on multiple topics. Furthermore, due to the lack of well-formed syntactic</context>
</contexts>
<marker>Kupiec, Pedersen, Chen, 1995</marker>
<rawString>Kupiec, J., Pedersen, J. and Chen, F. (1995). A trainable document summarizer. In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp 68-73, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R McKeown</author>
<author>J L Klavans</author>
<author>V Hatzivassiloglou</author>
<author>R Barzilay</author>
<author>E Eskin</author>
</authors>
<title>Towards multidocument summarization by reformulation: Progress and prospects.</title>
<date>1999</date>
<booktitle>In Proceedings of AAAI&apos;99.</booktitle>
<contexts>
<context position="1511" citStr="McKeown et al (1999)" startWordPosition="218" endWordPosition="221">ented and embedded in an active mailbox platform. Evaluation was performed over three machine learning paradigms. Introduction The volume of email messages is huge and growing. A qualitative and quantitative study of email overload [Whittaker and Sidner (1996)] shows that people receive a large number of email messages each day (~ 49) and that 21% of their inboxes (about 334 messages) are long messages (over 10 Kbytes). Therefore summarization techniques adequate for realworld applications are of great interest and need [Berger and Mittal (2000), McKeown and Radev (1995), Kupiec et al (1995), McKeown et al (1999), Hovy (2000)]. In this paper we present GIST-IT, an automatic email message summarizer that will convey to the user the gist of the document through topic phrase extraction, by combining linguistic and machine learning techniques. Email messages and web documents raise several challenges to automatic text processing, and the summarization task addresses most of them: they are free-style text, not always syntactically or grammatically well-formed, domain and genre independent, of variable length and on multiple topics. Furthermore, due to the lack of well-formed syntactic and grammatical struc</context>
</contexts>
<marker>McKeown, Klavans, Hatzivassiloglou, Barzilay, Eskin, 1999</marker>
<rawString>McKeown, K.R, Klavans, J.L, Hatzivassiloglou, V., Barzilay, R. and Eskin, E. (1999). Towards multidocument summarization by reformulation: Progress and prospects. In Proceedings of AAAI&apos;99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R McKeown</author>
<author>D R Radev</author>
</authors>
<title>Generating summaries of multiple news articles.</title>
<date>1995</date>
<booktitle>In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>74--82</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="1468" citStr="McKeown and Radev (1995)" startWordPosition="210" endWordPosition="213">ontent. The GIST-IT application is fully implemented and embedded in an active mailbox platform. Evaluation was performed over three machine learning paradigms. Introduction The volume of email messages is huge and growing. A qualitative and quantitative study of email overload [Whittaker and Sidner (1996)] shows that people receive a large number of email messages each day (~ 49) and that 21% of their inboxes (about 334 messages) are long messages (over 10 Kbytes). Therefore summarization techniques adequate for realworld applications are of great interest and need [Berger and Mittal (2000), McKeown and Radev (1995), Kupiec et al (1995), McKeown et al (1999), Hovy (2000)]. In this paper we present GIST-IT, an automatic email message summarizer that will convey to the user the gist of the document through topic phrase extraction, by combining linguistic and machine learning techniques. Email messages and web documents raise several challenges to automatic text processing, and the summarization task addresses most of them: they are free-style text, not always syntactically or grammatically well-formed, domain and genre independent, of variable length and on multiple topics. Furthermore, due to the lack of </context>
</contexts>
<marker>McKeown, Radev, 1995</marker>
<rawString>McKeown, K.R and Radev, D.R (1995). Generating summaries of multiple news articles. In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pp 74-82, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Muresan</author>
<author>E Tzoukermann</author>
<author>J L Klavans</author>
</authors>
<title>Email Summarization Using Linguistic and Machine Learning Techniques.</title>
<date>2001</date>
<booktitle>In Proceedings of CoNLL 2001 ACL Workshop,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="22022" citStr="Muresan et al, (2001)" startWordPosition="3490" endWordPosition="3493">ation of two feature vectors using three classifiers Table 3 shows our results that answer these two questions. The table rows represent the two feature vectors we are comparing, and the columns correspond to the three classifiers chosen for the evaluation. 4.1.3 Is linguistic filtering an important step in extracting salient NPs? In the third evaluation we analyse the impact of linguistic filtering on the classifier’s performance. It turns out that results show major improvements, from 69.2% to 85.7% for precision of fv2, and from 56.25% to 87.9% for recall of fv2. For detailed results, see [Muresan et al, (2001)]. 4.1.4 After the filtering and classification, are noun phrases good candidates for representing the gist of an email message? In order to answer this question, we compare the output of GIST-IT on one email with the results of KEA system [Witten et al (1999)] that uses a &apos;bag-of-words&apos; approach to key phrase extraction (see Table 4). module Perl module wordne sort of batch interface WordNet data &apos;wn&apos; command line program accesses simple easy perl interface the WordNet included man page lots of WordNet wordnet WordNet perl wordnet.pm module QueryData wordnet system wn wordnet package perl mod</context>
</contexts>
<marker>Muresan, Tzoukermann, Klavans, 2001</marker>
<rawString>Muresan, S., Tzoukermann, E. and Klavans, J.L. (2001). Email Summarization Using Linguistic and Machine Learning Techniques. In Proceedings of CoNLL 2001 ACL Workshop, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S K Murthy</author>
<author>S Kasif</author>
<author>S Salzberg</author>
<author>R Beigel</author>
</authors>
<title>OC1: Randomized Induction of Oblique Decision Trees.</title>
<date>1993</date>
<booktitle>Proceedings of the Eleventh National Conference on Artificial Intelligence,</booktitle>
<pages>322--327</pages>
<location>Washington, D.C.</location>
<marker>Murthy, Kasif, Salzberg, Beigel, 1993</marker>
<rawString>Murthy, S.K., Kasif, S., Salzberg, S. and Beigel, R. (1993). OC1: Randomized Induction of Oblique Decision Trees. Proceedings of the Eleventh National Conference on Artificial Intelligence, pp. 322--327, Washington, D.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>C4.5: Program for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="18778" citStr="Quinlan (1993)" startWordPosition="2979" endWordPosition="2980"> set of experiments, but we plan to use either &gt; wi2 &gt; wi3. a regression method or explore with genetic algorithms to automatically learn them. 3.3 Three Paradigms of Supervised Machine Learning Symbolic machine learning is used in conjunction with many NLP applications (syntactic and semantic parsing, POS tagging, text categorization, word sense disambiguation). In this paper we compare three symbolic learning techniques applied to the task of salient NP extraction: decision tree, rule induction learning and decision forests. We tested the performance of an axis-parallel decision tree, C4.5 [Quinlan (1993)]; a rule learning system RIPPER [Cohen (1995)] and a decision forest classifier (DFC) [Ho (1998)]. RIPPER allows the user to specify the loss ratio, which indicates the ratio of the cost of a false positive to the cost of a false negative, thus allowing the trade off between precision and recall. This is crucial for our analysis since we deal with sparse data set (in a document the number of salient NPs is much smaller than the number of irrelevant NPs). Finally we tried to prove that a combination of classifiers might improve accuracy, increasing both precision and recall. The Decision Fores</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Quinlan, J.R (1993). C4.5: Program for Machine Learning. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M P Marcus</author>
</authors>
<title>Text Chunking Using Transformation-Based Learning.</title>
<date>1995</date>
<booktitle>In Proceedings of Third ACL Workshop on Very Large Corpora, MIT.</booktitle>
<contexts>
<context position="7903" citStr="Ramshaw and Marcus (1995)" startWordPosition="1203" endWordPosition="1206">mple Noun Phrase Extraction and Filtering Unit This module performs shallow text processing for extraction and filtering of simple NP candidates, consisting of a pipeline of three modules: text tokenization, NP extraction, and NP filtering. Since the tool was created to preprocess email for speech output, some of the text tokenization suitable for speech is not accurate for text processing and some modifications needed to be implemented (e.g. email preprocessor splits acronyms like DLI2 into DLI 2). The noun phrase extraction module uses Brill&apos;s POS tagger [Brill (1992)]and a base NP chunker [Ramshaw and Marcus (1995)]. After analyzing some of these errors, we augmented the tagger lexicon from our training data and we added lexical and contextual rules to deal mainly with incorrect tagging of gerund endings. In order to improve the accuracy of classifiers we perform linguistic filtering, as discussed in detail in Section 3.1.2. 2.3 Machine Learning Unit The first component of the ML unit is the feature selection module to compute NP vectors. In the training phase, a model for identifying salient simple NPs is created. The training data consist of a list of feature vectors already classified as salient/nons</context>
<context position="11111" citStr="Ramshaw and Marcus (1995)" startWordPosition="1731" endWordPosition="1734"> of important noun phrases as a classification task, applying machine learning techniques to determine which features associated with the candidate NPs classify them as salient vs. non-salient. We represent the document -- in this case an email message -- as a set of candidate NPs, each of them associated with a feature vector used in the classification model. We use a number of linguistic methods both in the extraction and in the filtering of candidate noun phrases, and in the selection of the features. 3.1 Candidate NPs Noun phrases were extracted using Ramshaw and Marcus&apos;s base NP chunker [Ramshaw and Marcus (1995)]. The base NP is either a simple NP as defined by Wacholder (1998) or a conjunction of two simple NPs. Since the feature vectors used in the classifier scheme are simple NPs we used different heuristics to automatically split the conjoined NPs (CNP) into simple ones (SNP), properly assigning the premodifiers. Table 1 presents such an example: CNP: physics/NN and/CC biology/NN skilled/JJ researchers/NNS SNP1: physics/NN skilled/JJ researchers/NNS SNP2: biology/NN skilled/JJ researchers/NNS Table 1 Splitting Complex NPs into Simple NPs 3.1.2 Filtering simple NPs Since not all simple noun phrase</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Ramshaw, L.A. and Marcus, M.P. (1995). Text Chunking Using Transformation-Based Learning. In Proceedings of Third ACL Workshop on Very Large Corpora, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sparck-Jones</author>
</authors>
<title>What Is The Role of NLP in Text Retrieval.</title>
<date>1999</date>
<booktitle>Natural Language Information Retrieval.</booktitle>
<editor>In T. Strzalkowski, editor,</editor>
<publisher>Kluwer,</publisher>
<location>Boston, MA.</location>
<contexts>
<context position="4559" citStr="Sparck-Jones (1999)" startWordPosition="681" endWordPosition="682"> always provide good output in terms of a summary (see discussion in Section 5.4). Wacholder (1998) proposes a linguisticallymotivated method for the representation of the document aboutness: ‘head clustering’. A list of simple noun phrases is first extracted, clustered by head and then ranked by the frequency of the head. Klavans et al (2000) report on the evaluation of ‘usefulness’ of head clustering in the context of browsing applications, in terms of quality and coverage. Other researchers have used noun-phrases quite successfully for information retrieval task [Strzalkowski et al (1999), Sparck-Jones (1999)]. Strzalkowski et al (1999) uses head + modifier pairs as part of a larger system which constitutes the “stream model” that is used for information retrieval. They treat the head-modifier relationship as an ”ordered relation between otherwise equal elements”, emphasizing that for some tasks, the syntactic head of the NP is not necessarily a semantic head, and the modifier is not either necessarily a semantic modifier and that the opposite is often true. Using a machine learning approach, we proved this hypothesis for the task of gisting. Berger and Mittal (2000) present a summarization system</context>
</contexts>
<marker>Sparck-Jones, 1999</marker>
<rawString>Sparck-Jones, K. (1999). What Is The Role of NLP in Text Retrieval. In T. Strzalkowski, editor, Natural Language Information Retrieval. Kluwer, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Strzalkowski</author>
<author>F Lin</author>
<author>J Wang</author>
<author>J Perez-Carballo</author>
</authors>
<title>Evaluating natural language processing techniques for information retrieval.</title>
<date>1999</date>
<booktitle>Natural Language Information Retrieval.</booktitle>
<editor>In T. Strzalkowski, editor,</editor>
<publisher>Kluwer,</publisher>
<location>Boston, MA.</location>
<contexts>
<context position="4538" citStr="Strzalkowski et al (1999)" startWordPosition="677" endWordPosition="680"> only with n-grams does not always provide good output in terms of a summary (see discussion in Section 5.4). Wacholder (1998) proposes a linguisticallymotivated method for the representation of the document aboutness: ‘head clustering’. A list of simple noun phrases is first extracted, clustered by head and then ranked by the frequency of the head. Klavans et al (2000) report on the evaluation of ‘usefulness’ of head clustering in the context of browsing applications, in terms of quality and coverage. Other researchers have used noun-phrases quite successfully for information retrieval task [Strzalkowski et al (1999), Sparck-Jones (1999)]. Strzalkowski et al (1999) uses head + modifier pairs as part of a larger system which constitutes the “stream model” that is used for information retrieval. They treat the head-modifier relationship as an ”ordered relation between otherwise equal elements”, emphasizing that for some tasks, the syntactic head of the NP is not necessarily a semantic head, and the modifier is not either necessarily a semantic modifier and that the opposite is often true. Using a machine learning approach, we proved this hypothesis for the task of gisting. Berger and Mittal (2000) present a</context>
<context position="14451" citStr="Strzalkowski et al (1999)" startWordPosition="2265" endWordPosition="2268">l (frequency-based) and positional. These features capture information about the relative importance of NPs to the document meaning. Several studies rely on linguistic intuition that the head of the noun phrase makes a greater contribution to the semantics of the nominal group than the modifiers. For some NLP tasks, the head is not necessarily the most important item of the noun phrase. In analyzing email messages from the perspective of finding salient NPs, we claim that the constituents of the NP have often as much semantic content as the head. This opinion is also supported in the work of [Strzalkowski et al (1999)]. In many cases, the meaning of the NP is given equally by modifier(s) -- usually nominal modifiers(s) -- and head. Consider the following list of simple NPs selected as candidates: (1) “conference workshop announcement” (2) “international conference” (3) “workshop description” (4) “conference deadline” In the case of noun phrase (1) the importance of the noun phrase is found in the two noun modifiers: conference and workshop as much as in the head announcement. We test this empirical observation by introducing as a separate feature in the feature vector, a new TF*IDF measure that counts for </context>
</contexts>
<marker>Strzalkowski, Lin, Wang, Perez-Carballo, 1999</marker>
<rawString>Strzalkowski, T., Lin, F., Wang, J., and Perez-Carballo, J. (1999). Evaluating natural language processing techniques for information retrieval. In T. Strzalkowski, editor, Natural Language Information Retrieval. Kluwer, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Learning algorithms for keyphrase exraction.</title>
<date>2000</date>
<journal>Information Retrieval,</journal>
<volume>2</volume>
<issue>4</issue>
<pages>303--336</pages>
<marker>Turney, 2000</marker>
<rawString>Turney, P.D. (2000). Learning algorithms for keyphrase exraction. Information Retrieval, 2(4): pp 303-336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ueda</author>
<author>M Oka</author>
<author>T Koyama</author>
<author>T Miyauchi</author>
</authors>
<title>Toward the &amp;quot;at-a-glance&amp;quot; summary: Phraserepresentation summarization method.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="2274" citStr="Ueda et al (2000)" startWordPosition="329" endWordPosition="332">ugh topic phrase extraction, by combining linguistic and machine learning techniques. Email messages and web documents raise several challenges to automatic text processing, and the summarization task addresses most of them: they are free-style text, not always syntactically or grammatically well-formed, domain and genre independent, of variable length and on multiple topics. Furthermore, due to the lack of well-formed syntactic and grammatical structures, the granularity of document extracts presents another level of complexity. In our work, we address the extraction problem at phrase-level [Ueda et al (2000), Wacholder et al (2000)], identifying salient information that is spread across multiple sentences and paragraphs. Our novel approach first extracts simple noun phrases as candidate units for representing document meaning and then uses machine learning algorithms to select the most prominent ones. This combined method allows us to generate an informative, generic, “at-a-glance” summary. In this paper, we show: (a) the efficiency of the linguistic approach for phrase extraction in comparing results with and without filtering techniques, (b) the usefulness of vector representation in determinin</context>
</contexts>
<marker>Ueda, Oka, Koyama, Miyauchi, 2000</marker>
<rawString>Ueda, Y., Oka M., Koyama T. and Miyauchi T (2000). Toward the &amp;quot;at-a-glance&amp;quot; summary: Phraserepresentation summarization method. In Proceedings of COLING 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Wacholder</author>
</authors>
<title>Simplex NPS sorted by head: a method for identifying significant topics within a document,</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING-ACL Workshop on the Computational Treatment of Nominals.</booktitle>
<contexts>
<context position="4039" citStr="Wacholder (1998)" startWordPosition="604" endWordPosition="605">uraev and Kennedy (1999)], the meaning of ‘summary’ should be adjusted depending on the information management task for which it is used. Key phrases, for example, can be seen as semantic metadata that summarize and characterize documents [Witten et al (1999), Turney (1999)]. These approaches select a set of candidate phrases (sequence of one, two or three consecutive stemmed, non-stop words) and then apply machine learning techniques to classify them as key phrases or not. But dealing only with n-grams does not always provide good output in terms of a summary (see discussion in Section 5.4). Wacholder (1998) proposes a linguisticallymotivated method for the representation of the document aboutness: ‘head clustering’. A list of simple noun phrases is first extracted, clustered by head and then ranked by the frequency of the head. Klavans et al (2000) report on the evaluation of ‘usefulness’ of head clustering in the context of browsing applications, in terms of quality and coverage. Other researchers have used noun-phrases quite successfully for information retrieval task [Strzalkowski et al (1999), Sparck-Jones (1999)]. Strzalkowski et al (1999) uses head + modifier pairs as part of a larger syst</context>
<context position="11178" citStr="Wacholder (1998)" startWordPosition="1746" endWordPosition="1747">ng techniques to determine which features associated with the candidate NPs classify them as salient vs. non-salient. We represent the document -- in this case an email message -- as a set of candidate NPs, each of them associated with a feature vector used in the classification model. We use a number of linguistic methods both in the extraction and in the filtering of candidate noun phrases, and in the selection of the features. 3.1 Candidate NPs Noun phrases were extracted using Ramshaw and Marcus&apos;s base NP chunker [Ramshaw and Marcus (1995)]. The base NP is either a simple NP as defined by Wacholder (1998) or a conjunction of two simple NPs. Since the feature vectors used in the classifier scheme are simple NPs we used different heuristics to automatically split the conjoined NPs (CNP) into simple ones (SNP), properly assigning the premodifiers. Table 1 presents such an example: CNP: physics/NN and/CC biology/NN skilled/JJ researchers/NNS SNP1: physics/NN skilled/JJ researchers/NNS SNP2: biology/NN skilled/JJ researchers/NNS Table 1 Splitting Complex NPs into Simple NPs 3.1.2 Filtering simple NPs Since not all simple noun phrases are equally important to reflect the document meaning, we use wel</context>
</contexts>
<marker>Wacholder, 1998</marker>
<rawString>Wacholder, N. (1998). Simplex NPS sorted by head: a method for identifying significant topics within a document, In Proceedings of the COLING-ACL Workshop on the Computational Treatment of Nominals.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Whittaker</author>
<author>C Sidner</author>
</authors>
<title>Email overload: Exploring personal information management of email.</title>
<booktitle>In Proceedings of CHI’96.</booktitle>
<pages>276--283</pages>
<publisher>NY:ACM Press</publisher>
<marker>Whittaker, Sidner, </marker>
<rawString>Whittaker, S. and Sidner, C. Email overload: Exploring personal information management of email. In Proceedings of CHI’96. p. 276-283. NY:ACM Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>G W Paynter</author>
<author>E Frank</author>
<author>C Gutwin</author>
<author>C G Nevill-Manning</author>
</authors>
<title>KEA: Practical automatic keyphrase extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of DL&apos;99,</booktitle>
<pages>254--256</pages>
<contexts>
<context position="3682" citStr="Witten et al (1999)" startWordPosition="545" endWordPosition="548"> evaluating several classifiers in order to select the one performing the best for this task. 1 Related work Traditionally a document summary is seen as a small, coherent prose that renders to the user the important meaning of the text. In this framework most of the research has focused on extractive summaries at sentence level. However, as discussed in [Boguraev and Kennedy (1999)], the meaning of ‘summary’ should be adjusted depending on the information management task for which it is used. Key phrases, for example, can be seen as semantic metadata that summarize and characterize documents [Witten et al (1999), Turney (1999)]. These approaches select a set of candidate phrases (sequence of one, two or three consecutive stemmed, non-stop words) and then apply machine learning techniques to classify them as key phrases or not. But dealing only with n-grams does not always provide good output in terms of a summary (see discussion in Section 5.4). Wacholder (1998) proposes a linguisticallymotivated method for the representation of the document aboutness: ‘head clustering’. A list of simple noun phrases is first extracted, clustered by head and then ranked by the frequency of the head. Klavans et al (20</context>
<context position="22282" citStr="Witten et al (1999)" startWordPosition="3534" endWordPosition="3537">3 Is linguistic filtering an important step in extracting salient NPs? In the third evaluation we analyse the impact of linguistic filtering on the classifier’s performance. It turns out that results show major improvements, from 69.2% to 85.7% for precision of fv2, and from 56.25% to 87.9% for recall of fv2. For detailed results, see [Muresan et al, (2001)]. 4.1.4 After the filtering and classification, are noun phrases good candidates for representing the gist of an email message? In order to answer this question, we compare the output of GIST-IT on one email with the results of KEA system [Witten et al (1999)] that uses a &apos;bag-of-words&apos; approach to key phrase extraction (see Table 4). module Perl module wordne sort of batch interface WordNet data &apos;wn&apos; command line program accesses simple easy perl interface the WordNet included man page lots of WordNet wordnet WordNet perl wordnet.pm module QueryData wordnet system wn wordnet package perl module query perl module extracting command line use this module wordnet relation extracting lots wordnet data WordNet system free software www.cogsci.princeton.e querydata du Table 4 KEA (left) vs GIST-IT output (right) 5 Discussion of results The results shown </context>
<context position="25202" citStr="Witten et al (1999)" startWordPosition="3992" endWordPosition="3995">iltering presented in section 3.1.2 removed the noise introduced by unimportant modifiers, common and empty nouns, thus giving this new feature a larger impact. 5.4 Noun phrases are better than n-grams Presenting the gist of an email message by phrase extraction addresses one obvious question: can any phrasal extract represent the content of a document, or must a well defined linguistic phrasal structure be used? To answer this question we compare the results of our system that extract linguistically principled phrasal units, with KEA output, that extracts bigrams and trigrams as key phrases [Witten et al (1999)]. Table 4 shows the results of the KEA system. Due to the n-gram approach, KEA output contains phrases like sort of batch, extracting lots, wn, and even urls that are unlikely to represent the gist of a document. Conclusion and future work In this paper we presented a novel technique for document gisting suitable for domain and genre independent collections such as email messages. The method extracts simple noun phrases using linguistic techniques and then use machine learning to classify them as salient for the document content. We evaluated the system in different experimental settings usin</context>
</contexts>
<marker>Witten, Paynter, Frank, Gutwin, Nevill-Manning, 1999</marker>
<rawString>Witten, I.H, Paynter, G.W., Frank E., Gutwin C. and Nevill-Manning, C.G (1999). KEA: Practical automatic keyphrase extraction. In Proceedings of DL&apos;99, pp 254-256.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>