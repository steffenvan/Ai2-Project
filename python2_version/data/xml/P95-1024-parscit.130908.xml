<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000061">
<title confidence="0.993497">
Extraposition via Complex Domain Formation*
</title>
<author confidence="0.97338">
Andreas Kathol and Carl Pollard
</author>
<affiliation confidence="0.94732">
Dept. of Linguistics
</affiliation>
<author confidence="0.510939">
, 1712 Neil Ave.
</author>
<affiliation confidence="0.81212">
Ohio State University
</affiliation>
<address confidence="0.930108">
Columbus, OH 43210, USA
</address>
<email confidence="0.982631">
{kathol,pollard}Oling.ohio-state.edu
</email>
<sectionHeader confidence="0.996978" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999988727272727">
We propose a novel approach to extraposi-
tion in German within an alternative con-
ception of syntax in which syntactic struc-
ture and linear order are mediated not via
encodings of hierarchical relations but in-
stead via order domains. At the heart of
our proposal is a new kind of domain for-
mation which affords analyses of extrapo-
sition constructions that are linguistically
more adequate than those previously sug-
gested in the literature.
</bodyText>
<sectionHeader confidence="0.9484785" genericHeader="keywords">
1 Linearization without phrase
structure
</sectionHeader>
<bodyText confidence="0.980030034482759">
Recent years have seen proposals for the elimina-
tion of the phrase structure component in syntax in
favor of levels of representation encompassing possi-
bly nonconcatenative modes of serialization (Dowty,
In press; Reape, 1993; Reape, 1994; Pollard et al.,
1993). Instead of deriving the string representation
from the yield of the tree encoding the syntactic
structure of that sentence (as, for instance in GPSG,
LFG, and—as far as the relationship between S-
structure and PF, discounting operations at PF, is
concerned—GB), these proposals suggest deriving
the sentential string via a recursive process that op-
erates directly on encodings of the constituent order
of the subconstituents of the sentence. In Reape&apos;s
proposal, which constitutes an extension of HPSG
(Pollard and Sag, 1994), this information is con-
tained in &amp;quot;(Word) Order Domains&amp;quot;. On the other
hand, the way that the surface representation is put
together, i.e. the categories that have contributed
to the ultimate string and the grammatical depen-
dency relations (head-argument, head-adjunct, etc.)
holding among them, will be called the &amp;quot;composi-
tion structure&amp;quot; of that sentence, represented below
by means of unordered trees.
*Thanks to Bob Kasper for helpful discussions and
suggestions.
As an example, consider how a German V1 sen-
tence, e.g. a question or conditional clause, is derived
in such a system.&apos;
</bodyText>
<listItem confidence="0.8078375">
(1) Las Karl das Buch
read Karl the book
</listItem>
<bodyText confidence="0.946622684210526">
E.g.: &apos;Did Karl read the book?&apos;
The representation in Figure 1 involves a number
of order domains along the head projection of the
clause ([1]-[3]). Each time two categories are com-
bined, a new domain is formed from the domains
of the daughters of that node, given as a list value
for the feature DOM. While the nodes in the deriva-
tion correspond to signs in the HPSG sort hierarchy
(Pollard and Sag, 1994), the elements in the order
domains, which we will refer to as domain objects,
will minimally contain categorial and phonological
information (the latter given in italics within angled
brackets). The value of the DOM attribute thus con-
sists of a list of domain objects. Ordering is achieved
via linear precedence (LP) statements.
In Reape&apos;s approach, there are in essence two ways
in which a sign&apos;s DOM value can be integrated into
that of its mother. When combining with its ver-
bal head, a nominal argument such as das Buch in
Figure 1 in general gives rise to a single domain ele-
ment, which is &amp;quot;opaque&amp;quot; in the sense that adjacency
relations holding within it cannot be disturbed by
subsequent intervention of other domain objects. In
contrast, some constituents contribute the contents
of their order domains wholesale into the mother&apos;s
domain. Thus, in Figure 1, both elements of the VP
([2]) domain become part of the higher clausal ([1])
domain. As a result, order domains allow elements
that are not sisters in composition structure to be
linearly ordered with respect to each other, contrary
&apos;In Kathol and Pollard (1995), we argue for dispens-
ing with binary-valued features such as INV(ERTED) or
EXTRA(POSED) in favor of a multi-valued single feature
TOPO(LOGY) which imposes a partition on the set of do-
main elements of a clause according to membership in
Topological Fields (see also Kathol (In progress)). Since
nothing in the present proposal hinges on this detail, we
keep with the more common binary features.
</bodyText>
<page confidence="0.995456">
174
</page>
<figure confidence="0.9993705">
S V[SUBCAT
IVH-INV]
[1] [DO M (1 (las) r (Karl) r (das Buch)1 \]
LNp[Nomi LNp[Acci
[41 [NDPOLN°(Orarl)D1 [2] [VP = V SUBCAT (NP[NOMD]
DOM ( kV/NV] 1 [ iVpa[sit cBcuick) )
[NP[ACC]
DOM ([(das)], [(Buck)])]
[V[SUBCAT (NP[NOM1, NP[ACC])]
[3] D 0 M l[a+S N V
</figure>
<figureCaption confidence="0.999998">
Figure 1: Derivation of V1 clause using order domains
</figureCaption>
<bodyText confidence="0.999583">
to ordinary HPSG, but in the spirit of &amp;quot;liberation&amp;quot;
metarules (Zwicky, 1986).
With Reape we assume that one crucial mecha-
nism in the second type of order domain formation is
the shuffle relation (Reape&apos;s sequence union), which
holds of n lists L1, Ln, if Ln consists of
the elements of the first n-1 lists interleaved in such a
way that the relative order among the original mem-
bers of L1 through Ln_1, respectively, is preserved in
L. As a consequence, any precedence (but not ad-
jacency) relations holding of domain elements in one
domain are also required to hold of those elements
in all other order domains that they are members
of, which amounts to a monotonicity constraint on
deriving linear order. Hence, if [1] in Figure 1 were
to be expanded in the subsequent derivation into
a larger domain (for instance by the addition of a
sentential adverb), the relative order of subject and
object in that domain could not be reversed within
the new domain.
The data structure proposed for domains in
Reape (1993) is that of a list of objects of type sign.
However, it has been argued (Pollard et al., 1993)
that signs contain more information than is desirable
for elements of a domain. Thus, a sign encodes its
internal composition structure via its DAUGHTERS
attribute, while its linear composition is available as
the value of DOM. Yet, there are no known LP con-
straints in any language that make reference to these
types of information. We therefore propose an im-
poverished data structure for elements of order do-
mains which only consists of categorial and seman-
tic information (viz, the value of SYNSEM (Pollard
and Sag, 1994)) and a phonological representation.
This means that whenever a constituent is added to
a domain as a single element, its information con-
tent will be condensed to categorial and phonolog-
ical information.2 The latter is constrained to be
the concatenation of the PHONOLOGY values of the
domain elements in the corresponding sign&apos;s order
</bodyText>
<footnote confidence="0.9835325">
2For expository convenience, semantic information is
systematically ignored in this paper.
</footnote>
<bodyText confidence="0.808612">
domain. We will refer to the relation between a sign
</bodyText>
<listItem confidence="0.692096">
S and its representation as a single domain object
O as the compaction, given informally in (2):3
(2) comp action(13,0
</listItem>
<equation confidence="0.8793215">
dorri-obj
A 0: [ SYNSEM
</equation>
<bodyText confidence="0.996822">
To express this more formally, let us now define an
auxiliary relation, joinF, which holds of two lists
L1 and L2 only if L2 is the concatenation of val-
ues for the feature F of the elements in L1 in the
same order:4
</bodyText>
<equation confidence="0.7757488">
(3) joinF(0,0
A 0)
V (consUF ([3]1 MED
A joinFli
A append( 13,E) )
</equation>
<bodyText confidence="0.990837">
This allows as to define compaction more precisely
as in (4):
</bodyText>
<figure confidence="0.84924925">
(4) compaction( =
A:[sign
SYNSEM
DOM
[dom-obj
SYNSEM
PHON
A joinpHoN(
</figure>
<bodyText confidence="0.671065166666667">
3Here, &amp;quot;o&amp;quot; is a convenient functional notation for the
append relation.
&apos;Here cons is the relational analogue of the LISP
function cons; i.e. cons holds among some element E
and two lists L1 and L2 only if the insertion of E at the
beginning of L1 yields L2.
</bodyText>
<figure confidence="0.99209475">
[sign
: SYNSEM
a
DOM ([PHON ,...,[PHONEI)
131
PHON o o
175
[VP = V [SUBCAT (NP]
DOM
F (das Buch)1 \]
NP [ACC]
0
v[-I-INv]
(las)
[
NP [ACC]
DOM ([(das)],[(Buch)])]
A compaction(0,13
DOM
a
[V [SUBCAT (NP, NP)]
([(las)
[+siNv]
A shuffle(0), 0, ED
</figure>
<figureCaption confidence="0.999786">
Figure 2: Domain formation using compaction and shuffle
</figureCaption>
<bodyText confidence="0.999881833333333">
Given compaction and the earlier shuffle relation,
the construction of the intermediate VP domain can
be thought of as involving an instance of the Head-
Complement Schema (Pollard and Sag, 1994), aug-
mented with the relevant relational constraints on
domain formation, as shown in Figure 2.
</bodyText>
<sectionHeader confidence="0.963506" genericHeader="method">
2 Extraposition via Order Domains
</sectionHeader>
<bodyText confidence="0.999909857142857">
Order domains provide a natural framework for or-
der variation and discontinuous constituency. One of
the areas in which this approach has found a natural
application is extraposition of various kinds of con-
stituents. Reape (1994) proposes the binary-valued
feature EXTRA to order an extraposed VP last in the
domain of the clause, using the LP statement in (5):
</bodyText>
<listItem confidence="0.937333">
(5) [—EXTRA] -‹ [+EXTRA]
</listItem>
<bodyText confidence="0.970575041666667">
Similarly, Nerbonne (1994) uses this feature to
account for instance for extrapositions of relative
clauses from NPs such as (6); the composition struc-
ture proposed by Nerbonne for (6) is given in Fig-
ure 3.
(6) einen Hund fiittern [der Hunger hat]
a dog feed that hunger has
&apos;feed a dog that is hungry&apos;
The structure in Figure 3 also illustrates the fea-
ture UNIONED, which Reape and Nerbonne assume
to play a role in domain formation process. Thus, a
constituent marked [UNIONED +1 requires that the
contents of its domain be shuffled into the domain
of a higher constituent that it becomes part of (i.e.
it is domain-unioned). For instance, in Figure 3, the
[UNIONED +1 specification on the higher NP occa-
sions the VP domain to comprise not only the verb,
but also both domain objects of the NP. Conversely,
a [UNIONED ---] marking in Reape&apos;s and Nerbonne&apos;s
system effects the insertion of a single domain ob-
ject, corresponding to the constituent thus specified.
Therefore, in Figure 3, the internal structure of the
relative clause domain becomes opaque once it be-
comes part of the higher NP domain.
</bodyText>
<sectionHeader confidence="0.962085" genericHeader="method">
3 Shortcomings of Nerbonne&apos;s
analysis
</sectionHeader>
<bodyText confidence="0.999818666666667">
One problematic aspect of Nerbonne&apos;s proposal con-
cerns the fact that on his account, the extraposabil-
ity of relative clauses is directly linked to the Head-
Adjunct Schema that inter alia licenses the combi-
nation of nominals with relative clauses. However,
whether a clause can be extraposed is independent
of its adjunct/complement status within the NP.
Thus, (7) illustrates the extraposition of a comple-
ment clause (Keller, 1994):
</bodyText>
<listItem confidence="0.720497666666667">
(7) Planck hat die Entdeckung gemacht
Planck has the discovery made
[daf3 Licht Teilchennatur hat].
that light particle.nature has
&apos;Planck made the discovery
that light has a particle nature.&apos;
</listItem>
<bodyText confidence="0.921016653846154">
The same also holds for other kinds of extraposable
constituents, such as VPs and PPs. On Nerbonne&apos;s
analysis, the extraposability of complements has to
be encoded separately in the schema that licenses
head-complement structures. This misses the gen-
eralization that extraposability of some element is
tied directly to the final occurrence within the con-
stituent it is dislocated from.&apos; Therefore, extrapos-
ability should be tied to the linear properties of the
constituent in question, not to its grammatical func-
tion.
A different kind of problem arises in the case of ex-
tractions from prepositional phrases, as for instance
in (8):
(8) an einen Hund denken [der Hunger hat]
of a dog think that hunger has
&apos;think of a dog that is hungry&apos;
On the one hand, there has to be a domain object for
an einen Hund in the clausal domain because this
Note that final occurrence is a necessary, but
not sufficient condition. As is noted for instance in
Keller (1994), NP complements (e.g. postnominal geni-
tives) cannot be extraposed out of NPs despite their final
occurrence. We attribute this fact to a general constraint
against extraposed NPs in clauses, except for adverbial
accusative NPs denoting time intervals.
</bodyText>
<page confidence="0.965392">
176
</page>
<table confidence="0.86041">
[VP (einen Hund)1 r(ftittern)-1 [(der Hunger hat)1
[NP
DOM j j j
[NUPNIONED + 1 [DvOM ([ (fittern)])1
DOM ({ (einen Hund) [(der Hunger hat)i)
NP &apos; {REL-S
[REL-SNED
[NP U
EXTRA +
DOM ([ (einen)1, [(Hund)])
[(der)1 [(Hunger)] 1(hat)1\
DOM(REL IN .&apos; IV j /1
</table>
<figureCaption confidence="0.8695185">
io
Figure 3: Extraposition of relative clause in Nerbonne 1994
</figureCaption>
<bodyText confidence="0.999947235294118">
element is subject to the same variations in linear
order as PPs in general. On the other hand, the
attachment site of the preposition will have to be
higher than the relative clause because clearly, the
relative clause modifies the nominal, but not the PP.
As a potential solution one may propose to have
the preposition directly be &amp;quot;integrated&amp;quot; (phonologi-
cally and in terms of SYNSEM information) into the
NP domain object corresponding to einen Hund.
However, this would violate an implicit assumption
made in order domain-based approaches to lineariza-
tion to the effect that domain objects are inalterable.
Hence, the only legitimate operations involve adding
elements to an order domain or compacting that do-
main to form a new domain object, but crucially, op-
erations that nonmonotonically change existing do-
main objects within a domain are prohibited.
</bodyText>
<sectionHeader confidence="0.99181" genericHeader="method">
4 Partial compaction
</sectionHeader>
<bodyText confidence="0.99999046">
In this section, we present an alternative to Ner-
bonne&apos;s analysis based on an extension of the pos-
sibilities for domain formation. In particular, we
propose that besides total compaction and domain
union, there is a third possibility, which we will call
partial compaction. In fact, as will become clear be-
low, total compaction and partial compatcion are
not distinct possibilities; rather, the former is a sub-
case of the latter.
Intuitively, partial compaction allows designated
domain objects to be &amp;quot;liberated&amp;quot; into a higher do-
main, while the remaining elements of the source
domain are compacted into a single domain object.
To see how this improves the analysis of extraposi-
tion, consider the alternative analysis for the exam-
ple in (6), given in Figure 4.
As shown in Figure 4, we assume that the or-
der domain within NPs (or PPs) is essentially flat,
and moreover, that domain objects for NP-internal
prenominal constituents are prepended to the do-
main of the nominal projection so that the linear
string is isomorphic to the yield of the usual right-
branching analysis trees for NPs. Adjuncts and
complements, on the other hand, follow the nomi-
nal head by virtue of their [+ExTRA] specification,
which also renders them extraposable. If the NP
combines with a verbal head, it may be partially
compacted. In that case, the relative clause&apos;s do-
main object (I)) is inserted into the domain of the
VP together with the domain object consisting of
the same SYNSEM value as the original NP and that
NP&apos;s phonology minus the phonology of the relative
clause ([11). By virtue of its [EXTRA +1 marking, the
domain object of the relative clause is now ordered
last in the higher VP domain, while the remnant NP
is ordered along the same lines as NPs in general.
One important aspect to note is that on this ap-
proach, the inalterability condition on domain ob-
jects is not violated. Thus, the domain object of
the relative clause (11I) in the NP domain is token-
identical to the one in the VP domain. Moreover,
the integrity of the remaining NP&apos;s domain object
is not affected as—unlike in Nerbonne&apos;s analysis—
there is no corresponding domain object in the do-
main of the NP before the latter is licensed as the
complement of the verb fittern.
In order to allow for the possibility of partially
compacting a domain by replacing the compaction
relation of (4) by the p-compaction relation, which
is defined as follows:
</bodyText>
<page confidence="0.967602">
177
</page>
<figure confidence="0.999412692307692">
{VP
DOM
[(einen Hund)] rittern)]
[(der Hunger hat)1) I
REL-S
EXTRA -I-
(
NP &apos; V
[NP [ hat)1)1 [V (ppittern)])]
M (der Hunger DOM
[ (einen)1, [(Hula)] REL-S
DO EXTRA +
a
[DET [(der Hunger hat)1)1
DOM Weinen)1) DOM ( { (Hund)N , REL-S
EXTRA ±
A p-compaction(0
A shuffle((, (1=1),
{NDOM ([(Hund)])]
,(B)
13
[REL-S
EXTRA -I-
DOM
( {BEL NP IV
(der)1 [(Hunger)1 1(hat)1\
</figure>
<figureCaption confidence="0.998597">
Figure 4: Extraposition via partial compaction
</figureCaption>
<figure confidence="0.9646564">
[dom-obj
A 0 SYNSEM
PHON
A shuffle( a
A joinpHoN( 13
</figure>
<bodyText confidence="0.987611285714286">
Intuitively, the p-compaction relation holds of a sign
S (la domain object 0 (Ji, and a list of domain
objects L ( 3 only if 0 is the compaction of S with
L being a ist of domain objects &amp;quot;liberated&amp;quot; from
the S&apos;s order domain. This relation is invoked for
instance by the schema combining a head (H) with
a complement (C):
</bodyText>
<equation confidence="0.7576635">
(10) [M:] [Dom u]
{HEAD verb]]\
A (0: 0 V El: SYNSEM
SUBCAT
</equation>
<bodyText confidence="0.983139235294118">
The third constraint associated with the Head-
Complement Schema ensures that only those ele-
ments that are marked as [EXTRA -I-1) within the
smaller constituent can be passed into the higher do-
main, while the last one prevents extraposition out
of clauses (cf. Ross&apos; Right Roof Constraint (Ross,
1967)).
This approach is superior to Nerbonne&apos;s, as the
extraposability of an item is correlated only with
its linear properties (right-peripheral occurrence in
a domain via [EXTRA -H), but not with its sta-
tus as adjunct or complement. Our approach also
makes the correct prediction that extraposition is
only possible if the extraposed element is already
final in the extraposition source.6 In this sense, ex-
traposition is subject to a monotonicity condition to
the effect that the element in question has to occur
in the same linear relationship in the smaller and
the larger domains, viz. right-peripherally (modulo
other extraposed constituents). This aspect clearly
favors our approach over alternative proposals that
treat extraposition in terms of a NONLOCAL depen-
dency (Keller, 1994). In approaches of that kind,
there is nothing, for example, to block extraposition
of prenominal elements.
Our approach allows an obvious extension to the
case of extraposition from PPs which are prob-
lematic for Nerbonne&apos;s analysis. Prepositions are
prepended to the domain of NPs in the same way
61t should be pointed out that we do not make the as-
sumption, often made in transformational grammar, that
cases in which a complement (of a verb) can only occur
extraposed necessitates the existence of an underlying
non-extraposed structure that is never overtly realized.
</bodyText>
<figure confidence="0.990500086956522">
(9) p-compaction( CD a&apos;
[sign
SYNSEM
DOM
a
a
[H:] [Dom ] [C:]
A p-compaction(
A shuffle((, a
A U list ( SYNSEM [EXTRA +] I)
178
[VP [(einem Hund der Hunger hat)] { Vittern) )
DOM NP v
[NP
DOM (einen)
(Hund) , REL-S
(der Hunger hat)]) EXTRA +
K[ftittern)1)]
B
[V
DOM
A p-compaction(a B 0)
A shuffie((1) , ,
</figure>
<figureCaption confidence="0.999956">
Figure 5: Total compaction as a special case of compaction
</figureCaption>
<bodyText confidence="0.989924730769231">
that determiners are to N domains.
Along similar lines, note that extrapositions from
topicalized constituents, noted by Nerbonne as a
challenge for his proposal, do not pose a problem
for our account.
(11) Eine Dame ist an der Tiir
a lady is at the door
[die Sie sprechen
who you speak wants
&apos;A lady is at the door
who wants to talk to you.&apos;
If we assume, following Kathol (In progress), that
topicalized constituents are part of the same clausal
domain as the rest of the sentence,&apos; then an ex-
traposed domain object, inherited via partial com-
paction from the topic, will automatically have to
occur clause-finally, just as in the case of extraposi-
tion from regular complements.
So far, we have only considered the case in which
the extraposed constituent is inherited by the higher
order domain. However, the definition of the p-
compaction relation in (12) also holds in the case
where the list of liberated domain objects is empty,
which amounts to the total compaction of the sign
in question. As a result, we can regard total com-
paction as a special case of the p-compaction relation
in general. This means that as an alternative lin-
earization of (6), we can also have the extraposition-
less analysis in Figure 5.
Therefore, there is no longer a need for the
UNIONED feature for extraposition. This means that
we can have a stronger theory as constraints on ex-
traposability will be result of general conditions on
the syntactic licensing schema (e.g. the Right Roof
Constraint in (10)). But this means that whether or
not something can be extraposed has been rendered
exempt from lexical variation in principle—unlike in
Reape&apos;s system where extraposability is a matter of
lexical selection.
71.e. the initial placement of a preverbal constituent in
a verb-second clause is a consequence of LP constraints
within a flat clausal order domain.
Moreover, while Reape employs this feature for
the linearization of nonfinite complementation, it
can be shown that the Argument Composition
approach of Hinrichs &amp; Nakazawa (Hinrichs and
Nakazawa, 1994), among many others, is linguisti-
cally superior (Kathol, In progress). As a result, we
can dispense with the UNIONED feature altogether
and instead derive linearization conditions from gen-
eral principles of syntactic combination that are not
subject to lexical variation.
</bodyText>
<sectionHeader confidence="0.998779" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999855">
We have argued for an approach to extraposition
from smaller constituents that pays specific atten-
tion to the linear properties of the extraposition
source.8 To this end, we have proposed a more fine-
grained typology of ways in which an order domain
can be formed from smaller constituents. Crucially,
we use relational constraints to define the interde-
pendencies; hence our approach fits squarely into the
paradigm in which grammars are viewed as sets of
relational dependencies that has been advocated for
instance in Dorre et al. (1992). Since the relational
perspective also lies at the heart of computational
formalisms such as CUF (DOrre and Eisele, 1991),
the ideas presented here are expected to carry over
into practical systems rather straightforwardly. We
leave this task for future work.
</bodyText>
<sectionHeader confidence="0.999165" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9718417">
Jochen Dorre and Andreas Eisele. 1991. A Compre-
hensive Unification-Based Grammar Formalism.
DYANA Deliverable R3.1.B, ESPRIT Basic Ac-
tion BR3175.
Jochen Dorre, Andreas Eisele, and Roland Seif-
fert. 1992. Grammars as Relational Dependen-
cies. AIMS Report 7, Institut fiir maschinelle
Sprachverarbeitung, Stuttgart.
&apos;For similar ideas regarding English, see
Stucky (1987).
</reference>
<page confidence="0.987763">
179
</page>
<reference confidence="0.999775596153846">
David Dowty. In press. Towards a Minimalist The-
ory of Syntactic Structure. In Horck and Sijtsma,
editors, Discontinuous Constituency. Mouton de
Gruyter.
Erhard Hinrichs and Tsuneko Nakazawa. 1994.
Linearizing finite AUX in German verbal com-
plexes. In John Nerbonne, Klaus Netter, and Carl
Pollard, editors, German in Head-Driven Phrase
Structure Grammar, pages 11-38. Stanford: CSLI
Publications.
Andreas Kathol and Carl Pollard. 1995. On the
Left Periphery of German Subordinate Clauses.
In West Coast Conference on Formal Linguistics,
volume 14, Stanford University. CSLI Publica-
tions/SLA.
Andreas Kathol. In progress. Linearization-Based
German Syntax. Ph.D. thesis, Ohio State Univer-
sity.
Frank Keller. 1994. Extraposition in HPSG. un-
publ. ms., IBM Germany, Scientific Center Hei-
delberg.
John Nerbonne. 1994. Partial verb phrases and spu-
rious ambiguities. In John Nerbonne, Klaus Net-
ter, and Carl Pollard, editors, German in Head-
Driven Phrase Structure Grammar, pages 109-
150. Stanford: CSLI Publications.
Carl J. Pollard and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. CSLI Publications
and University of Chicago Press.
Carl Pollard, Robert Levine, and Robert Kasper.
1993. Studies in Constituent Ordering: Toward
a Theory of Linearization in Head-Driven Phrase
Structure Grammar. Grant Proposal to the Na-
tional Science Foundation, Ohio State University.
Mike Reape. 1993. A Formal Theory of Word Or-
der: A Case Study in West Germanic. Ph.D. the-
sis, University of Edinburgh.
Mike Reape. 1994. Domain Union and Word Or-
der Variation in German. In John Nerbonne,
Klaus Netter, and Carl Pollard, editors, German
in Head-Driven Phrase Structure Grammar, pages
151-198. Stanford: CSLI Publications.
John Ross. 1967. Constraints on Variables in Syn-
tax. Ph.D. thesis, MIT.
Susan Stucky. 1987. Configurational Variation
in English: A Study of Extraposition and Re-
lated Matters. In Discontinuous Constituency,
volume 20 of Syntax and Semantics, pages 377-
404. Academic Press, New York.
Arnold Zwicky. 1986. Concatenation and libera-
tion. In Papers from the 22nd Regional Meeting,
Chicago Linguistic Society, pages 65-74.
</reference>
<page confidence="0.997744">
180
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.992024">Extraposition via Complex Domain Formation*</title>
<author confidence="0.980813">Kathol Pollard</author>
<affiliation confidence="0.994501">Dept. of Linguistics</affiliation>
<address confidence="0.73687">1712 Neil Ave.</address>
<affiliation confidence="0.999953">Ohio State University</affiliation>
<address confidence="0.999992">Columbus, OH 43210, USA</address>
<email confidence="0.999791">katholOling.ohio-state.edu</email>
<email confidence="0.999791">pollardOling.ohio-state.edu</email>
<abstract confidence="0.940086258382644">We propose a novel approach to extraposition in German within an alternative conception of syntax in which syntactic structure and linear order are mediated not via encodings of hierarchical relations but instead via order domains. At the heart of our proposal is a new kind of domain formation which affords analyses of extraposition constructions that are linguistically more adequate than those previously suggested in the literature. 1 Linearization without phrase structure Recent years have seen proposals for the elimination of the phrase structure component in syntax in favor of levels of representation encompassing possibly nonconcatenative modes of serialization (Dowty, In press; Reape, 1993; Reape, 1994; Pollard et al., 1993). Instead of deriving the string representation from the yield of the tree encoding the syntactic structure of that sentence (as, for instance in GPSG, LFG, and—as far as the relationship between Sstructure and PF, discounting operations at PF, is concerned—GB), these proposals suggest deriving the sentential string via a recursive process that operates directly on encodings of the constituent order of the subconstituents of the sentence. In Reape&apos;s proposal, which constitutes an extension of HPSG (Pollard and Sag, 1994), this information is contained in &amp;quot;(Word) Order Domains&amp;quot;. On the other hand, the way that the surface representation is put together, i.e. the categories that have contributed to the ultimate string and the grammatical dependency relations (head-argument, head-adjunct, etc.) holding among them, will be called the &amp;quot;composition structure&amp;quot; of that sentence, represented below by means of unordered trees. *Thanks to Bob Kasper for helpful discussions and suggestions. As an example, consider how a German V1 sentence, e.g. a question or conditional clause, is derived in such a system.&apos; (1) Las Karl das Buch read Karl the book E.g.: &apos;Did Karl read the book?&apos; The representation in Figure 1 involves a number of order domains along the head projection of the clause ([1]-[3]). Each time two categories are combined, a new domain is formed from the domains of the daughters of that node, given as a list value the feature the nodes in the derivacorrespond to the HPSG sort hierarchy (Pollard and Sag, 1994), the elements in the order which we will refer to as objects, will minimally contain categorial and phonological information (the latter given in italics within angled The value of the thus consists of a list of domain objects. Ordering is achieved via linear precedence (LP) statements. In Reape&apos;s approach, there are in essence two ways which a sign&apos;s can be integrated into that of its mother. When combining with its verhead, a nominal argument such as Buch 1 in general gives rise to single element, which is &amp;quot;opaque&amp;quot; in the sense that adjacency relations holding within it cannot be disturbed by subsequent intervention of other domain objects. In contrast, some constituents contribute the contents of their order domains wholesale into the mother&apos;s domain. Thus, in Figure 1, both elements of the VP ([2]) domain become part of the higher clausal ([1]) domain. As a result, order domains allow elements that are not sisters in composition structure to be linearly ordered with respect to each other, contrary &apos;In Kathol and Pollard (1995), we argue for dispenswith binary-valued features such as favor of a multi-valued single feature imposes a partition on the set of domain elements of a clause according to membership in Fields (see also Kathol (In progress)). nothing in the present proposal hinges on this detail, we keep with the more common binary features. 174 S V[SUBCAT IVH-INV] [DO M r(Karl) r(das Buch)1 \] LNp[Nomi LNp[Acci = V SUBCAT (NP[NOMD] ( 1 [ ) [(Buck)])] [V[SUBCAT (NP[NOM1, NP[ACC])] 0 M N V Figure 1: Derivation of V1 clause using order domains to ordinary HPSG, but in the spirit of &amp;quot;liberation&amp;quot; metarules (Zwicky, 1986). With Reape we assume that one crucial mechanism in the second type of order domain formation is (Reape&apos;s union), of n lists L1, consists of the elements of the first n-1 lists interleaved in such a way that the relative order among the original memof through respectively, is preserved in a consequence, any precedence (but not adjacency) relations holding of domain elements in one domain are also required to hold of those elements in all other order domains that they are members of, which amounts to a monotonicity constraint on linear order. Hence, if [1] in Figure to be expanded in the subsequent derivation into a larger domain (for instance by the addition of a sentential adverb), the relative order of subject and object in that domain could not be reversed within the new domain. The data structure proposed for domains in (1993) is that of a list of objects of type However, it has been argued (Pollard et al., 1993) that signs contain more information than is desirable for elements of a domain. Thus, a sign encodes its composition structure via its attribute, while its linear composition is available as value of there are no known LP constraints in any language that make reference to these types of information. We therefore propose an impoverished data structure for elements of order domains which only consists of categorial and semaninformation (viz, the value of and Sag, 1994)) and a phonological representation. This means that whenever a constituent is added to a domain as a single element, its information content will be condensed to categorial and phonolog- The latter is constrained to be concatenation of the of the domain elements in the corresponding sign&apos;s order expository convenience, semantic information is systematically ignored in this paper. domain. We will refer to the relation between a sign S and its representation as a single domain object as the informally in (2) comp action(13,0 dorri-obj A 0: [ SYNSEM To express this more formally, let us now define an relation, holds of two lists and if the concatenation of valfor the feature the elements in in the (3) A 0) (consUF ([3]1 13,E) ) allows as to define as in (4): compaction( SYNSEM DOM SYNSEM PHON &amp;quot;o&amp;quot; is a convenient functional notation for the append relation. the relational analogue of the LISP cons; i.e. among some element two lists L1 and if the insertion of the of L1 yields [sign : SYNSEM a DOM ([PHON ,...,[PHONEI) 131 PHON o o 175 = V [SUBCAT (NP] DOM Buch)1 \] NP [ACC] 0 v[-I-INv] (las) [ NP [ACC] A compaction(0,13 DOM a [SUBCAT (NP, NP)] shuffle(0), 2: Domain formation using the earlier the construction of the intermediate VP domain can be thought of as involving an instance of the Head- Complement Schema (Pollard and Sag, 1994), augmented with the relevant relational constraints on domain formation, as shown in Figure 2. 2 Extraposition via Order Domains Order domains provide a natural framework for order variation and discontinuous constituency. One of the areas in which this approach has found a natural application is extraposition of various kinds of constituents. Reape (1994) proposes the binary-valued order an extraposed VP last in the domain of the clause, using the LP statement in (5): [—EXTRA] [+EXTRA] Similarly, Nerbonne (1994) uses this feature to account for instance for extrapositions of relative clauses from NPs such as (6); the composition structure proposed by Nerbonne for (6) is given in Figure 3. (6) einen Hund fiittern [der Hunger hat] a dog feed that hunger has &apos;feed a dog that is hungry&apos; The structure in Figure 3 also illustrates the fea- Reape and Nerbonne assume to play a role in domain formation process. Thus, a marked +1 that the contents of its domain be shuffled into the domain of a higher constituent that it becomes part of (i.e. is instance, in Figure 3, the +1 on the higher NP occasions the VP domain to comprise not only the verb, but also both domain objects of the NP. Conversely, ---] in Reape&apos;s and Nerbonne&apos;s system effects the insertion of a single domain object, corresponding to the constituent thus specified. Therefore, in Figure 3, the internal structure of the relative clause domain becomes opaque once it becomes part of the higher NP domain. 3 Shortcomings of Nerbonne&apos;s analysis One problematic aspect of Nerbonne&apos;s proposal concerns the fact that on his account, the extraposability of relative clauses is directly linked to the Head- Adjunct Schema that inter alia licenses the combination of nominals with relative clauses. However, whether a clause can be extraposed is independent of its adjunct/complement status within the NP. Thus, (7) illustrates the extraposition of a complement clause (Keller, 1994): (7) Planck hat die Entdeckung gemacht Planck has the discovery made [daf3 Licht Teilchennatur hat]. that light particle.nature has &apos;Planck made the discovery that light has a particle nature.&apos; same also holds for other kinds of constituents, such as VPs and PPs. On Nerbonne&apos;s analysis, the extraposability of complements has to be encoded separately in the schema that licenses head-complement structures. This misses the generalization that extraposability of some element is tied directly to the final occurrence within the constituent it is dislocated from.&apos; Therefore, extraposshould be tied to the of the constituent in question, not to its grammatical function. A different kind of problem arises in the case of extractions from prepositional phrases, as for instance in (8): (8) an einen Hund denken [der Hunger hat] of a dog think that hunger has &apos;think of a dog that is hungry&apos; On the one hand, there has to be a domain object for Hund the clausal domain because this Note that final occurrence is a necessary, but not sufficient condition. As is noted for instance in Keller (1994), NP complements (e.g. postnominal genitives) cannot be extraposed out of NPs despite their final occurrence. We attribute this fact to a general constraint against extraposed NPs in clauses, except for adverbial accusative NPs denoting time intervals. 176 [VP (einen Hund)1 [NP hat)1 DOM j j j + 1 ([ DOM Hund) NP [(der Hunger hat)i) &apos; {REL-S U EXTRA + ([ [(Hund)]) IN .&apos; IV /1 io Figure 3: Extraposition of relative clause in Nerbonne 1994 element is subject to the same variations in linear order as PPs in general. On the other hand, the attachment site of the preposition will have to be higher than the relative clause because clearly, the clause modifies the nominal, but PP. As a potential solution one may propose to have the preposition directly be &amp;quot;integrated&amp;quot; (phonologiand in terms of into the domain object corresponding to Hund. However, this would violate an implicit assumption made in order domain-based approaches to linearization to the effect that domain objects are inalterable. Hence, the only legitimate operations involve adding elements to an order domain or compacting that domain to form a new domain object, but crucially, operations that nonmonotonically change existing domain objects within a domain are prohibited. 4 Partial compaction In this section, we present an alternative to Nerbonne&apos;s analysis based on an extension of the possibilities for domain formation. In particular, we propose that besides total compaction and domain union, there is a third possibility, which we will call compaction. fact, as will become clear below, total compaction and partial compatcion are not distinct possibilities; rather, the former is a subcase of the latter. Intuitively, partial compaction allows designated domain objects to be &amp;quot;liberated&amp;quot; into a higher domain, while the remaining elements of the source domain are compacted into a single domain object. To see how this improves the analysis of extraposition, consider the alternative analysis for the example in (6), given in Figure 4. As shown in Figure 4, we assume that the order domain within NPs (or PPs) is essentially flat, and moreover, that domain objects for NP-internal prenominal constituents are prepended to the domain of the nominal projection so that the linear string is isomorphic to the yield of the usual rightbranching analysis trees for NPs. Adjuncts and complements, on the other hand, follow the nomihead by virtue of their which also renders them extraposable. If the NP combines with a verbal head, it may be partially compacted. In that case, the relative clause&apos;s domain object (I)) is inserted into the domain of the VP together with the domain object consisting of same as the original NP and that NP&apos;s phonology minus the phonology of the relative ([11). By virtue of its +1 the domain object of the relative clause is now ordered last in the higher VP domain, while the remnant NP is ordered along the same lines as NPs in general. One important aspect to note is that on this approach, the inalterability condition on domain objects is not violated. Thus, the domain object of the relative clause (11I) in the NP domain is tokenidentical to the one in the VP domain. Moreover, the integrity of the remaining NP&apos;s domain object is not affected as—unlike in Nerbonne&apos;s analysis— there is no corresponding domain object in the domain of the NP before the latter is licensed as the of the verb In order to allow for the possibility of partially a domain by replacing the of (4) by the which is defined as follows: 177 {VP DOM [(einen Hund)] rittern)] Hunger hat)1) REL-S -I- ( NP &apos; V [NP [ (ppittern)])] M (der Hunger DOM [(Hula)] REL-S EXTRA + DO a [DET [(der Hunger hat)1)1 ( { REL-S EXTRA ± (1=1), ,(B) 13 [REL-S -I- DOM {BEL NP Figure 4: Extraposition via partial compaction [dom-obj 0 SYNSEM PHON joinpHoN( the holds of a sign (la object (Ji, a list of domain ( 3 if is compaction of a ist of domain objects &amp;quot;liberated&amp;quot; from the S&apos;s order domain. This relation is invoked for instance by the schema combining a head (H) with a complement (C): [M:] [Dom (0: 0 V SUBCAT The third constraint associated with the Head- Schema ensures that only those elethat are marked as -I-1) the smaller constituent can be passed into the higher domain, while the last one prevents extraposition out of clauses (cf. Ross&apos; Right Roof Constraint (Ross, 1967)). This approach is superior to Nerbonne&apos;s, as the extraposability of an item is correlated only with its linear properties (right-peripheral occurrence in domain via -H), not with its status as adjunct or complement. Our approach also makes the correct prediction that extraposition is only possible if the extraposed element is already in the extraposition In this sense, extraposition is subject to a monotonicity condition to the effect that the element in question has to occur in the same linear relationship in the smaller and the larger domains, viz. right-peripherally (modulo other extraposed constituents). This aspect clearly favors our approach over alternative proposals that extraposition in terms of a dependency (Keller, 1994). In approaches of that kind, there is nothing, for example, to block extraposition of prenominal elements. Our approach allows an obvious extension to the case of extraposition from PPs which are problematic for Nerbonne&apos;s analysis. Prepositions are prepended to the domain of NPs in the same way should be pointed out that we do the assumption, often made in transformational grammar, that cases in which a complement (of a verb) can only occur extraposed necessitates the existence of an underlying non-extraposed structure that is never overtly realized. p-compaction( a&apos; [sign SYNSEM DOM a a [H:] [Dom ] [C:] U [EXTRA +] I) 178 [VP DOM Hund NP Hunger hat)] { ) v [NP (Hund), Hunger hat)]) + K[ftittern)1)] B [V DOM B0) A shuffie((1) , , Figure 5: Total compaction as a special case of compaction that determiners are to N domains. Along similar lines, note that extrapositions from topicalized constituents, noted by Nerbonne as a challenge for his proposal, do not pose a problem for our account. (11) Eine Dame ist an der Tiir a lady is at the door [die Sie sprechen who you speak wants &apos;A lady is at the door who wants to talk to you.&apos; If we assume, following Kathol (In progress), that topicalized constituents are part of the same clausal domain as the rest of the sentence,&apos; then an extraposed domain object, inherited via partial compaction from the topic, will automatically have to occur clause-finally, just as in the case of extraposition from regular complements. So far, we have only considered the case in which the extraposed constituent is inherited by the higher domain. However, the definition of the pin (12) also holds in the case where the list of liberated domain objects is empty, which amounts to the total compaction of the sign in question. As a result, we can regard total comas case of the in general. This means that as an alternative linearization of (6), we can also have the extrapositionless analysis in Figure 5. Therefore, there is no longer a need for the for extraposition. This means that we can have a stronger theory as constraints on extraposability will be result of general conditions on the syntactic licensing schema (e.g. the Right Roof Constraint in (10)). But this means that whether or not something can be extraposed has been rendered exempt from lexical variation in principle—unlike in Reape&apos;s system where extraposability is a matter of lexical selection. the initial placement of a preverbal constituent in a verb-second clause is a consequence of LP constraints a order domain. Moreover, while Reape employs this feature for the linearization of nonfinite complementation, it can be shown that the Argument Composition approach of Hinrichs &amp; Nakazawa (Hinrichs and Nakazawa, 1994), among many others, is linguistically superior (Kathol, In progress). As a result, we dispense with the altogether and instead derive linearization conditions from general principles of syntactic combination that are not subject to lexical variation. 5 Conclusion We have argued for an approach to extraposition from smaller constituents that pays specific attention to the linear properties of the extraposition To this end, we have proposed a more finegrained typology of ways in which an order domain can be formed from smaller constituents. Crucially, we use relational constraints to define the interdependencies; hence our approach fits squarely into the paradigm in which grammars are viewed as sets of relational dependencies that has been advocated for instance in Dorre et al. (1992). Since the relational perspective also lies at the heart of computational formalisms such as CUF (DOrre and Eisele, 1991), the ideas presented here are expected to carry over into practical systems rather straightforwardly. We leave this task for future work.</abstract>
<note confidence="0.9752195">References Jochen Dorre and Andreas Eisele. 1991. A Comprehensive Unification-Based Grammar Formalism. DYANA Deliverable R3.1.B, ESPRIT Basic Action BR3175. Jochen Dorre, Andreas Eisele, and Roland Seiffert. 1992. Grammars as Relational Dependencies. AIMS Report 7, Institut fiir maschinelle Sprachverarbeitung, Stuttgart. &apos;For similar ideas regarding English, see Stucky (1987). 179</note>
<author confidence="0.901379">In press Towards a Minimalist The-</author>
<affiliation confidence="0.852968">ory of Syntactic Structure. In Horck and Sijtsma,</affiliation>
<address confidence="0.651598">Constituency. de</address>
<note confidence="0.847264714285714">Gruyter. Erhard Hinrichs and Tsuneko Nakazawa. 1994. Linearizing finite AUX in German verbal complexes. In John Nerbonne, Klaus Netter, and Carl editors, in Head-Driven Phrase Grammar, 11-38. Stanford: CSLI Publications. Andreas Kathol and Carl Pollard. 1995. On the Left Periphery of German Subordinate Clauses. Coast Conference on Formal Linguistics, volume 14, Stanford University. CSLI Publications/SLA. Kathol. In progress. Syntax. thesis, Ohio State University. Frank Keller. 1994. Extraposition in HPSG. unpubl. ms., IBM Germany, Scientific Center Heidelberg. John Nerbonne. 1994. Partial verb phrases and spurious ambiguities. In John Nerbonne, Klaus Netand Carl Pollard, editors, in Head- Phrase Structure pages 109- 150. Stanford: CSLI Publications. J. Pollard and Ivan A. Sag. 1994. Structure Grammar. Publications and University of Chicago Press. Carl Pollard, Robert Levine, and Robert Kasper. 1993. Studies in Constituent Ordering: Toward</note>
<title confidence="0.466138">a Theory of Linearization in Head-Driven Phrase</title>
<author confidence="0.828272">Grant Proposal to the Na-</author>
<affiliation confidence="0.969479">tional Science Foundation, Ohio State University.</affiliation>
<author confidence="0.431812">Formal Theory of Word Or-</author>
<affiliation confidence="0.843127">A Case Study in West Germanic. thesis, University of Edinburgh.</affiliation>
<author confidence="0.908914">Domain Union</author>
<author confidence="0.908914">Word Order Variation in German In John Nerbonne</author>
<email confidence="0.607538">Netter,andCarlPollard,editors,</email>
<affiliation confidence="0.861651">Head-Driven Phrase Structure Grammar,</affiliation>
<address confidence="0.881055">151-198. Stanford: CSLI Publications.</address>
<note confidence="0.900301">Ross. 1967. on Variables in Synthesis, MIT. Susan Stucky. 1987. Configurational Variation in English: A Study of Extraposition and Re- Matters. In Constituency, 20 of and Semantics, 377- 404. Academic Press, New York. Arnold Zwicky. 1986. Concatenation and libera- In from the 22nd Regional Meeting, Linguistic Society, 65-74. 180</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jochen Dorre</author>
<author>Andreas Eisele</author>
</authors>
<title>A Comprehensive Unification-Based Grammar Formalism.</title>
<date>1991</date>
<booktitle>DYANA Deliverable R3.1.B, ESPRIT Basic Action BR3175.</booktitle>
<marker>Dorre, Eisele, 1991</marker>
<rawString>Jochen Dorre and Andreas Eisele. 1991. A Comprehensive Unification-Based Grammar Formalism. DYANA Deliverable R3.1.B, ESPRIT Basic Action BR3175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jochen Dorre</author>
<author>Andreas Eisele</author>
<author>Roland Seiffert</author>
</authors>
<title>Grammars as Relational Dependencies. AIMS Report 7, Institut fiir maschinelle Sprachverarbeitung,</title>
<date>1992</date>
<location>Stuttgart.</location>
<marker>Dorre, Eisele, Seiffert, 1992</marker>
<rawString>Jochen Dorre, Andreas Eisele, and Roland Seiffert. 1992. Grammars as Relational Dependencies. AIMS Report 7, Institut fiir maschinelle Sprachverarbeitung, Stuttgart.</rawString>
</citation>
<citation valid="true">
<title>For similar ideas regarding English,</title>
<date>1987</date>
<location>see Stucky</location>
<marker>1987</marker>
<rawString>&apos;For similar ideas regarding English, see Stucky (1987).</rawString>
</citation>
<citation valid="false">
<authors>
<author>David Dowty</author>
</authors>
<title>In press. Towards a Minimalist Theory of Syntactic Structure.</title>
<booktitle>In Horck and Sijtsma, editors, Discontinuous Constituency. Mouton de Gruyter.</booktitle>
<marker>Dowty, </marker>
<rawString>David Dowty. In press. Towards a Minimalist Theory of Syntactic Structure. In Horck and Sijtsma, editors, Discontinuous Constituency. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erhard Hinrichs</author>
<author>Tsuneko Nakazawa</author>
</authors>
<title>Linearizing finite AUX in German verbal complexes. In</title>
<date>1994</date>
<booktitle>German in Head-Driven Phrase Structure Grammar,</booktitle>
<pages>11--38</pages>
<editor>John Nerbonne, Klaus Netter, and Carl Pollard, editors,</editor>
<publisher>CSLI Publications.</publisher>
<location>Stanford:</location>
<contexts>
<context position="19781" citStr="Hinrichs and Nakazawa, 1994" startWordPosition="3318" endWordPosition="3321">e syntactic licensing schema (e.g. the Right Roof Constraint in (10)). But this means that whether or not something can be extraposed has been rendered exempt from lexical variation in principle—unlike in Reape&apos;s system where extraposability is a matter of lexical selection. 71.e. the initial placement of a preverbal constituent in a verb-second clause is a consequence of LP constraints within a flat clausal order domain. Moreover, while Reape employs this feature for the linearization of nonfinite complementation, it can be shown that the Argument Composition approach of Hinrichs &amp; Nakazawa (Hinrichs and Nakazawa, 1994), among many others, is linguistically superior (Kathol, In progress). As a result, we can dispense with the UNIONED feature altogether and instead derive linearization conditions from general principles of syntactic combination that are not subject to lexical variation. 5 Conclusion We have argued for an approach to extraposition from smaller constituents that pays specific attention to the linear properties of the extraposition source.8 To this end, we have proposed a more finegrained typology of ways in which an order domain can be formed from smaller constituents. Crucially, we use relatio</context>
</contexts>
<marker>Hinrichs, Nakazawa, 1994</marker>
<rawString>Erhard Hinrichs and Tsuneko Nakazawa. 1994. Linearizing finite AUX in German verbal complexes. In John Nerbonne, Klaus Netter, and Carl Pollard, editors, German in Head-Driven Phrase Structure Grammar, pages 11-38. Stanford: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Kathol</author>
<author>Carl Pollard</author>
</authors>
<title>On the Left Periphery of German Subordinate Clauses.</title>
<date>1995</date>
<booktitle>In West Coast Conference on Formal Linguistics,</booktitle>
<volume>14</volume>
<institution>Stanford University. CSLI Publications/SLA.</institution>
<contexts>
<context position="3634" citStr="Kathol and Pollard (1995)" startWordPosition="584" endWordPosition="587">ment such as das Buch in Figure 1 in general gives rise to a single domain element, which is &amp;quot;opaque&amp;quot; in the sense that adjacency relations holding within it cannot be disturbed by subsequent intervention of other domain objects. In contrast, some constituents contribute the contents of their order domains wholesale into the mother&apos;s domain. Thus, in Figure 1, both elements of the VP ([2]) domain become part of the higher clausal ([1]) domain. As a result, order domains allow elements that are not sisters in composition structure to be linearly ordered with respect to each other, contrary &apos;In Kathol and Pollard (1995), we argue for dispensing with binary-valued features such as INV(ERTED) or EXTRA(POSED) in favor of a multi-valued single feature TOPO(LOGY) which imposes a partition on the set of domain elements of a clause according to membership in Topological Fields (see also Kathol (In progress)). Since nothing in the present proposal hinges on this detail, we keep with the more common binary features. 174 S V[SUBCAT IVH-INV] [1] [DO M (1 (las) r (Karl) r (das Buch)1 \] LNp[Nomi LNp[Acci [41 [NDPOLN°(Orarl)D1 [2] [VP = V SUBCAT (NP[NOMD] DOM ( kV/NV] 1 [ iVpa[sit cBcuick) ) [NP[ACC] DOM ([(das)], [(Buck</context>
</contexts>
<marker>Kathol, Pollard, 1995</marker>
<rawString>Andreas Kathol and Carl Pollard. 1995. On the Left Periphery of German Subordinate Clauses. In West Coast Conference on Formal Linguistics, volume 14, Stanford University. CSLI Publications/SLA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Andreas Kathol</author>
</authors>
<title>In progress. Linearization-Based German Syntax.</title>
<tech>Ph.D. thesis,</tech>
<institution>Ohio State University.</institution>
<marker>Kathol, </marker>
<rawString>Andreas Kathol. In progress. Linearization-Based German Syntax. Ph.D. thesis, Ohio State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Keller</author>
</authors>
<date>1994</date>
<booktitle>Extraposition in HPSG. unpubl. ms., IBM Germany, Scientific</booktitle>
<location>Center Heidelberg.</location>
<contexts>
<context position="9852" citStr="Keller, 1994" startWordPosition="1645" endWordPosition="1646">ified. Therefore, in Figure 3, the internal structure of the relative clause domain becomes opaque once it becomes part of the higher NP domain. 3 Shortcomings of Nerbonne&apos;s analysis One problematic aspect of Nerbonne&apos;s proposal concerns the fact that on his account, the extraposability of relative clauses is directly linked to the HeadAdjunct Schema that inter alia licenses the combination of nominals with relative clauses. However, whether a clause can be extraposed is independent of its adjunct/complement status within the NP. Thus, (7) illustrates the extraposition of a complement clause (Keller, 1994): (7) Planck hat die Entdeckung gemacht Planck has the discovery made [daf3 Licht Teilchennatur hat]. that light particle.nature has &apos;Planck made the discovery that light has a particle nature.&apos; The same also holds for other kinds of extraposable constituents, such as VPs and PPs. On Nerbonne&apos;s analysis, the extraposability of complements has to be encoded separately in the schema that licenses head-complement structures. This misses the generalization that extraposability of some element is tied directly to the final occurrence within the constituent it is dislocated from.&apos; Therefore, extrapo</context>
<context position="16797" citStr="Keller, 1994" startWordPosition="2814" endWordPosition="2815">RA -H), but not with its status as adjunct or complement. Our approach also makes the correct prediction that extraposition is only possible if the extraposed element is already final in the extraposition source.6 In this sense, extraposition is subject to a monotonicity condition to the effect that the element in question has to occur in the same linear relationship in the smaller and the larger domains, viz. right-peripherally (modulo other extraposed constituents). This aspect clearly favors our approach over alternative proposals that treat extraposition in terms of a NONLOCAL dependency (Keller, 1994). In approaches of that kind, there is nothing, for example, to block extraposition of prenominal elements. Our approach allows an obvious extension to the case of extraposition from PPs which are problematic for Nerbonne&apos;s analysis. Prepositions are prepended to the domain of NPs in the same way 61t should be pointed out that we do not make the assumption, often made in transformational grammar, that cases in which a complement (of a verb) can only occur extraposed necessitates the existence of an underlying non-extraposed structure that is never overtly realized. (9) p-compaction( CD a&apos; [sig</context>
</contexts>
<marker>Keller, 1994</marker>
<rawString>Frank Keller. 1994. Extraposition in HPSG. unpubl. ms., IBM Germany, Scientific Center Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Nerbonne</author>
</authors>
<title>Partial verb phrases and spurious ambiguities. In</title>
<date>1994</date>
<booktitle>German in HeadDriven Phrase Structure Grammar,</booktitle>
<pages>109--150</pages>
<editor>John Nerbonne, Klaus Netter, and Carl Pollard, editors,</editor>
<publisher>CSLI Publications.</publisher>
<location>Stanford:</location>
<contexts>
<context position="8308" citStr="Nerbonne (1994)" startWordPosition="1385" endWordPosition="1386">volving an instance of the HeadComplement Schema (Pollard and Sag, 1994), augmented with the relevant relational constraints on domain formation, as shown in Figure 2. 2 Extraposition via Order Domains Order domains provide a natural framework for order variation and discontinuous constituency. One of the areas in which this approach has found a natural application is extraposition of various kinds of constituents. Reape (1994) proposes the binary-valued feature EXTRA to order an extraposed VP last in the domain of the clause, using the LP statement in (5): (5) [—EXTRA] -‹ [+EXTRA] Similarly, Nerbonne (1994) uses this feature to account for instance for extrapositions of relative clauses from NPs such as (6); the composition structure proposed by Nerbonne for (6) is given in Figure 3. (6) einen Hund fiittern [der Hunger hat] a dog feed that hunger has &apos;feed a dog that is hungry&apos; The structure in Figure 3 also illustrates the feature UNIONED, which Reape and Nerbonne assume to play a role in domain formation process. Thus, a constituent marked [UNIONED +1 requires that the contents of its domain be shuffled into the domain of a higher constituent that it becomes part of (i.e. it is domain-unioned)</context>
<context position="11575" citStr="Nerbonne 1994" startWordPosition="1930" endWordPosition="1931"> is noted for instance in Keller (1994), NP complements (e.g. postnominal genitives) cannot be extraposed out of NPs despite their final occurrence. We attribute this fact to a general constraint against extraposed NPs in clauses, except for adverbial accusative NPs denoting time intervals. 176 [VP (einen Hund)1 r(ftittern)-1 [(der Hunger hat)1 [NP DOM j j j [NUPNIONED + 1 [DvOM ([ (fittern)])1 DOM ({ (einen Hund) [(der Hunger hat)i) NP &apos; {REL-S [REL-SNED [NP U EXTRA + DOM ([ (einen)1, [(Hund)]) [(der)1 [(Hunger)] 1(hat)1\ DOM(REL IN .&apos; IV j /1 io Figure 3: Extraposition of relative clause in Nerbonne 1994 element is subject to the same variations in linear order as PPs in general. On the other hand, the attachment site of the preposition will have to be higher than the relative clause because clearly, the relative clause modifies the nominal, but not the PP. As a potential solution one may propose to have the preposition directly be &amp;quot;integrated&amp;quot; (phonologically and in terms of SYNSEM information) into the NP domain object corresponding to einen Hund. However, this would violate an implicit assumption made in order domain-based approaches to linearization to the effect that domain objects are i</context>
</contexts>
<marker>Nerbonne, 1994</marker>
<rawString>John Nerbonne. 1994. Partial verb phrases and spurious ambiguities. In John Nerbonne, Klaus Netter, and Carl Pollard, editors, German in HeadDriven Phrase Structure Grammar, pages 109-150. Stanford: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl J Pollard</author>
<author>Ivan A Sag</author>
</authors>
<date>1994</date>
<booktitle>Head-Driven Phrase Structure Grammar. CSLI Publications and University of</booktitle>
<publisher>Chicago Press.</publisher>
<contexts>
<context position="1472" citStr="Pollard and Sag, 1994" startWordPosition="221" endWordPosition="224">enative modes of serialization (Dowty, In press; Reape, 1993; Reape, 1994; Pollard et al., 1993). Instead of deriving the string representation from the yield of the tree encoding the syntactic structure of that sentence (as, for instance in GPSG, LFG, and—as far as the relationship between Sstructure and PF, discounting operations at PF, is concerned—GB), these proposals suggest deriving the sentential string via a recursive process that operates directly on encodings of the constituent order of the subconstituents of the sentence. In Reape&apos;s proposal, which constitutes an extension of HPSG (Pollard and Sag, 1994), this information is contained in &amp;quot;(Word) Order Domains&amp;quot;. On the other hand, the way that the surface representation is put together, i.e. the categories that have contributed to the ultimate string and the grammatical dependency relations (head-argument, head-adjunct, etc.) holding among them, will be called the &amp;quot;composition structure&amp;quot; of that sentence, represented below by means of unordered trees. *Thanks to Bob Kasper for helpful discussions and suggestions. As an example, consider how a German V1 sentence, e.g. a question or conditional clause, is derived in such a system.&apos; (1) Las Karl </context>
<context position="5975" citStr="Pollard and Sag, 1994" startWordPosition="986" endWordPosition="989">93) is that of a list of objects of type sign. However, it has been argued (Pollard et al., 1993) that signs contain more information than is desirable for elements of a domain. Thus, a sign encodes its internal composition structure via its DAUGHTERS attribute, while its linear composition is available as the value of DOM. Yet, there are no known LP constraints in any language that make reference to these types of information. We therefore propose an impoverished data structure for elements of order domains which only consists of categorial and semantic information (viz, the value of SYNSEM (Pollard and Sag, 1994)) and a phonological representation. This means that whenever a constituent is added to a domain as a single element, its information content will be condensed to categorial and phonological information.2 The latter is constrained to be the concatenation of the PHONOLOGY values of the domain elements in the corresponding sign&apos;s order 2For expository convenience, semantic information is systematically ignored in this paper. domain. We will refer to the relation between a sign S and its representation as a single domain object O as the compaction, given informally in (2):3 (2) comp action(13,0 d</context>
<context position="7765" citStr="Pollard and Sag, 1994" startWordPosition="1297" endWordPosition="1300"> cons; i.e. cons holds among some element E and two lists L1 and L2 only if the insertion of E at the beginning of L1 yields L2. [sign : SYNSEM a DOM ([PHON ,...,[PHONEI) 131 PHON o o 175 [VP = V [SUBCAT (NP] DOM F (das Buch)1 \] NP [ACC] 0 v[-I-INv] (las) [ NP [ACC] DOM ([(das)],[(Buch)])] A compaction(0,13 DOM a [V [SUBCAT (NP, NP)] ([(las) [+siNv] A shuffle(0), 0, ED Figure 2: Domain formation using compaction and shuffle Given compaction and the earlier shuffle relation, the construction of the intermediate VP domain can be thought of as involving an instance of the HeadComplement Schema (Pollard and Sag, 1994), augmented with the relevant relational constraints on domain formation, as shown in Figure 2. 2 Extraposition via Order Domains Order domains provide a natural framework for order variation and discontinuous constituency. One of the areas in which this approach has found a natural application is extraposition of various kinds of constituents. Reape (1994) proposes the binary-valued feature EXTRA to order an extraposed VP last in the domain of the clause, using the LP statement in (5): (5) [—EXTRA] -‹ [+EXTRA] Similarly, Nerbonne (1994) uses this feature to account for instance for extraposit</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl J. Pollard and Ivan A. Sag. 1994. Head-Driven Phrase Structure Grammar. CSLI Publications and University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Robert Levine</author>
<author>Robert Kasper</author>
</authors>
<title>Studies in Constituent Ordering: Toward a Theory of Linearization</title>
<date>1993</date>
<booktitle>in Head-Driven Phrase Structure Grammar. Grant Proposal to the</booktitle>
<institution>National Science Foundation, Ohio State University.</institution>
<contexts>
<context position="946" citStr="Pollard et al., 1993" startWordPosition="140" endWordPosition="143">ructure and linear order are mediated not via encodings of hierarchical relations but instead via order domains. At the heart of our proposal is a new kind of domain formation which affords analyses of extraposition constructions that are linguistically more adequate than those previously suggested in the literature. 1 Linearization without phrase structure Recent years have seen proposals for the elimination of the phrase structure component in syntax in favor of levels of representation encompassing possibly nonconcatenative modes of serialization (Dowty, In press; Reape, 1993; Reape, 1994; Pollard et al., 1993). Instead of deriving the string representation from the yield of the tree encoding the syntactic structure of that sentence (as, for instance in GPSG, LFG, and—as far as the relationship between Sstructure and PF, discounting operations at PF, is concerned—GB), these proposals suggest deriving the sentential string via a recursive process that operates directly on encodings of the constituent order of the subconstituents of the sentence. In Reape&apos;s proposal, which constitutes an extension of HPSG (Pollard and Sag, 1994), this information is contained in &amp;quot;(Word) Order Domains&amp;quot;. On the other ha</context>
<context position="5450" citStr="Pollard et al., 1993" startWordPosition="899" endWordPosition="902">y) relations holding of domain elements in one domain are also required to hold of those elements in all other order domains that they are members of, which amounts to a monotonicity constraint on deriving linear order. Hence, if [1] in Figure 1 were to be expanded in the subsequent derivation into a larger domain (for instance by the addition of a sentential adverb), the relative order of subject and object in that domain could not be reversed within the new domain. The data structure proposed for domains in Reape (1993) is that of a list of objects of type sign. However, it has been argued (Pollard et al., 1993) that signs contain more information than is desirable for elements of a domain. Thus, a sign encodes its internal composition structure via its DAUGHTERS attribute, while its linear composition is available as the value of DOM. Yet, there are no known LP constraints in any language that make reference to these types of information. We therefore propose an impoverished data structure for elements of order domains which only consists of categorial and semantic information (viz, the value of SYNSEM (Pollard and Sag, 1994)) and a phonological representation. This means that whenever a constituent</context>
</contexts>
<marker>Pollard, Levine, Kasper, 1993</marker>
<rawString>Carl Pollard, Robert Levine, and Robert Kasper. 1993. Studies in Constituent Ordering: Toward a Theory of Linearization in Head-Driven Phrase Structure Grammar. Grant Proposal to the National Science Foundation, Ohio State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Reape</author>
</authors>
<title>A Formal Theory of Word Order: A Case Study in West Germanic.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="910" citStr="Reape, 1993" startWordPosition="136" endWordPosition="137">ntax in which syntactic structure and linear order are mediated not via encodings of hierarchical relations but instead via order domains. At the heart of our proposal is a new kind of domain formation which affords analyses of extraposition constructions that are linguistically more adequate than those previously suggested in the literature. 1 Linearization without phrase structure Recent years have seen proposals for the elimination of the phrase structure component in syntax in favor of levels of representation encompassing possibly nonconcatenative modes of serialization (Dowty, In press; Reape, 1993; Reape, 1994; Pollard et al., 1993). Instead of deriving the string representation from the yield of the tree encoding the syntactic structure of that sentence (as, for instance in GPSG, LFG, and—as far as the relationship between Sstructure and PF, discounting operations at PF, is concerned—GB), these proposals suggest deriving the sentential string via a recursive process that operates directly on encodings of the constituent order of the subconstituents of the sentence. In Reape&apos;s proposal, which constitutes an extension of HPSG (Pollard and Sag, 1994), this information is contained in &amp;quot;(W</context>
<context position="5356" citStr="Reape (1993)" startWordPosition="882" endWordPosition="883">, respectively, is preserved in L. As a consequence, any precedence (but not adjacency) relations holding of domain elements in one domain are also required to hold of those elements in all other order domains that they are members of, which amounts to a monotonicity constraint on deriving linear order. Hence, if [1] in Figure 1 were to be expanded in the subsequent derivation into a larger domain (for instance by the addition of a sentential adverb), the relative order of subject and object in that domain could not be reversed within the new domain. The data structure proposed for domains in Reape (1993) is that of a list of objects of type sign. However, it has been argued (Pollard et al., 1993) that signs contain more information than is desirable for elements of a domain. Thus, a sign encodes its internal composition structure via its DAUGHTERS attribute, while its linear composition is available as the value of DOM. Yet, there are no known LP constraints in any language that make reference to these types of information. We therefore propose an impoverished data structure for elements of order domains which only consists of categorial and semantic information (viz, the value of SYNSEM (Pol</context>
</contexts>
<marker>Reape, 1993</marker>
<rawString>Mike Reape. 1993. A Formal Theory of Word Order: A Case Study in West Germanic. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Reape</author>
</authors>
<title>Domain Union and Word Order Variation in German. In</title>
<date>1994</date>
<booktitle>German in Head-Driven Phrase Structure Grammar,</booktitle>
<pages>151--198</pages>
<editor>John Nerbonne, Klaus Netter, and Carl Pollard, editors,</editor>
<publisher>CSLI Publications.</publisher>
<location>Stanford:</location>
<contexts>
<context position="923" citStr="Reape, 1994" startWordPosition="138" endWordPosition="139"> syntactic structure and linear order are mediated not via encodings of hierarchical relations but instead via order domains. At the heart of our proposal is a new kind of domain formation which affords analyses of extraposition constructions that are linguistically more adequate than those previously suggested in the literature. 1 Linearization without phrase structure Recent years have seen proposals for the elimination of the phrase structure component in syntax in favor of levels of representation encompassing possibly nonconcatenative modes of serialization (Dowty, In press; Reape, 1993; Reape, 1994; Pollard et al., 1993). Instead of deriving the string representation from the yield of the tree encoding the syntactic structure of that sentence (as, for instance in GPSG, LFG, and—as far as the relationship between Sstructure and PF, discounting operations at PF, is concerned—GB), these proposals suggest deriving the sentential string via a recursive process that operates directly on encodings of the constituent order of the subconstituents of the sentence. In Reape&apos;s proposal, which constitutes an extension of HPSG (Pollard and Sag, 1994), this information is contained in &amp;quot;(Word) Order Do</context>
<context position="8124" citStr="Reape (1994)" startWordPosition="1355" endWordPosition="1356"> ED Figure 2: Domain formation using compaction and shuffle Given compaction and the earlier shuffle relation, the construction of the intermediate VP domain can be thought of as involving an instance of the HeadComplement Schema (Pollard and Sag, 1994), augmented with the relevant relational constraints on domain formation, as shown in Figure 2. 2 Extraposition via Order Domains Order domains provide a natural framework for order variation and discontinuous constituency. One of the areas in which this approach has found a natural application is extraposition of various kinds of constituents. Reape (1994) proposes the binary-valued feature EXTRA to order an extraposed VP last in the domain of the clause, using the LP statement in (5): (5) [—EXTRA] -‹ [+EXTRA] Similarly, Nerbonne (1994) uses this feature to account for instance for extrapositions of relative clauses from NPs such as (6); the composition structure proposed by Nerbonne for (6) is given in Figure 3. (6) einen Hund fiittern [der Hunger hat] a dog feed that hunger has &apos;feed a dog that is hungry&apos; The structure in Figure 3 also illustrates the feature UNIONED, which Reape and Nerbonne assume to play a role in domain formation process.</context>
</contexts>
<marker>Reape, 1994</marker>
<rawString>Mike Reape. 1994. Domain Union and Word Order Variation in German. In John Nerbonne, Klaus Netter, and Carl Pollard, editors, German in Head-Driven Phrase Structure Grammar, pages 151-198. Stanford: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Ross</author>
</authors>
<date>1967</date>
<booktitle>Constraints on Variables in Syntax. Ph.D. thesis, MIT.</booktitle>
<contexts>
<context position="16011" citStr="Ross, 1967" startWordPosition="2693" endWordPosition="2694">ject 0 (Ji, and a list of domain objects L ( 3 only if 0 is the compaction of S with L being a ist of domain objects &amp;quot;liberated&amp;quot; from the S&apos;s order domain. This relation is invoked for instance by the schema combining a head (H) with a complement (C): (10) [M:] [Dom u] {HEAD verb]]\ A (0: 0 V El: SYNSEM SUBCAT The third constraint associated with the HeadComplement Schema ensures that only those elements that are marked as [EXTRA -I-1) within the smaller constituent can be passed into the higher domain, while the last one prevents extraposition out of clauses (cf. Ross&apos; Right Roof Constraint (Ross, 1967)). This approach is superior to Nerbonne&apos;s, as the extraposability of an item is correlated only with its linear properties (right-peripheral occurrence in a domain via [EXTRA -H), but not with its status as adjunct or complement. Our approach also makes the correct prediction that extraposition is only possible if the extraposed element is already final in the extraposition source.6 In this sense, extraposition is subject to a monotonicity condition to the effect that the element in question has to occur in the same linear relationship in the smaller and the larger domains, viz. right-periphe</context>
</contexts>
<marker>Ross, 1967</marker>
<rawString>John Ross. 1967. Constraints on Variables in Syntax. Ph.D. thesis, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Stucky</author>
</authors>
<title>Configurational Variation in English: A Study of Extraposition and Related Matters.</title>
<date>1987</date>
<booktitle>In Discontinuous Constituency,</booktitle>
<volume>20</volume>
<pages>377--404</pages>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<marker>Stucky, 1987</marker>
<rawString>Susan Stucky. 1987. Configurational Variation in English: A Study of Extraposition and Related Matters. In Discontinuous Constituency, volume 20 of Syntax and Semantics, pages 377-404. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arnold Zwicky</author>
</authors>
<title>Concatenation and liberation.</title>
<date>1986</date>
<booktitle>In Papers from the 22nd Regional Meeting, Chicago Linguistic Society,</booktitle>
<pages>65--74</pages>
<contexts>
<context position="4419" citStr="Zwicky, 1986" startWordPosition="718" endWordPosition="719">he set of domain elements of a clause according to membership in Topological Fields (see also Kathol (In progress)). Since nothing in the present proposal hinges on this detail, we keep with the more common binary features. 174 S V[SUBCAT IVH-INV] [1] [DO M (1 (las) r (Karl) r (das Buch)1 \] LNp[Nomi LNp[Acci [41 [NDPOLN°(Orarl)D1 [2] [VP = V SUBCAT (NP[NOMD] DOM ( kV/NV] 1 [ iVpa[sit cBcuick) ) [NP[ACC] DOM ([(das)], [(Buck)])] [V[SUBCAT (NP[NOM1, NP[ACC])] [3] D 0 M l[a+S N V Figure 1: Derivation of V1 clause using order domains to ordinary HPSG, but in the spirit of &amp;quot;liberation&amp;quot; metarules (Zwicky, 1986). With Reape we assume that one crucial mechanism in the second type of order domain formation is the shuffle relation (Reape&apos;s sequence union), which holds of n lists L1, Ln, if Ln consists of the elements of the first n-1 lists interleaved in such a way that the relative order among the original members of L1 through Ln_1, respectively, is preserved in L. As a consequence, any precedence (but not adjacency) relations holding of domain elements in one domain are also required to hold of those elements in all other order domains that they are members of, which amounts to a monotonicity constra</context>
</contexts>
<marker>Zwicky, 1986</marker>
<rawString>Arnold Zwicky. 1986. Concatenation and liberation. In Papers from the 22nd Regional Meeting, Chicago Linguistic Society, pages 65-74.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>