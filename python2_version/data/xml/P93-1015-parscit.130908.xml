<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000060">
<title confidence="0.996677">
Parsing Free Word Order Languages in the
Paninian Framework
</title>
<author confidence="0.8843385">
Akshar Bharati
Rajeev Sangal
</author>
<affiliation confidence="0.905791666666667">
Department of Computer Science and Engineering
Indian Institute of Technology Kanpur
Kanpur 208016 India
</affiliation>
<email confidence="0.990051">
Internet: sangal@iitk.ernet.in
</email>
<sectionHeader confidence="0.99836" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999983730769231">
There is a need to develop a suitable computational
grammar formalism for free word order languages
for two reasons: First, a suitably designed formal-
ism is likely to be more efficient. Second, such a
formalism is also likely to be linguistically more ele-
gant and satisfying. In this paper, we describe such
a formalism, called the Paninian framework, that
has been successfully applied to Indian languages.
This paper shows that the Paninian framework
applied to modern Indian languages gives an elegant
account of the relation between surface form (vib-
hakti) and semantic (karaka) roles. The mapping
is elegant and compact. The same basic account
also explains active-passives and complex sentences.
This suggests that the solution is not just adhoc but
has a deeper underlying unity.
A constraint based parser is described for the
framework. The constraints problem reduces to bi-
partite graph matching problem because of the na-
ture of constraints. Efficient solutions are known
for these problems.
It is interesting to observe that such a parser (de-
signed for free word order languages) compares well
in asymptotic time complexity with the parser for
context free grammars (CFCs) which are basically
designed for positional languages.
</bodyText>
<sectionHeader confidence="0.999629" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999905916666667">
A majority of human languages including Indian
and other languages have relatively free word or-
der. In free word order languages, order of words
contains only secondary information such as em-
phasis etc. Primary information relating to &apos;gross&apos;
meaning (e.g., one that includes semantic relation-
ships) is contained elsewhere. Most existing compu-
tational grammars are based on context free gram-
mars which are basically positional grammars. It
is important to develop a suitable computational
grammar formalism for free word order languages
for two reasons:
</bodyText>
<listItem confidence="0.866087166666667">
1. A suitably designed formalism will be more ef-
ficient because it will be able to make use of
primary sources of information directly.
2. Such a formalism is also likely to be linguisti-
cally more elegant and satisfying. Since it will
be able to relate to primary sources of informa-
</listItem>
<bodyText confidence="0.996850892857143">
tion, the grammar is likely to be more econom-
ical and easier to write.
In this paper, we describe such a formalism, called
the Paninian framework, that has been successfully
applied to Indian languages. 1 It uses the notion
of karaka relations between verbs and nouns in a
sentence. The notion of karaka relations is cen-
tral to the Paninian model. The karaka relations
are syntactico-semantic (or semantico-syntactic) re-
lations between the verbals and other related con-
stituents in a sentence. They by themselves do
not give the semantics. Instead they specify re-
lations which mediate between vibhakti of nom-
inals and verb forms on one hand and semantic
relations on the other (Kiparsky, 1982) (Cardona
(1976), (1988)). See Fig. 1. Two of the impor-
tant karakas are karta karaka and karma karaka.
Frequently, the karta karaka maps to agent theta
role, and the karma to theme or goal theta role.
Here we will not argue for the linguistic significance
of karaka relations and differences with theta rela-
tions, as that has been done elsewhere (Bharati et
al. (1990) and (1992)). In summary, karta karaka
is that participant in the action that is most inde-
pendent. At times, it turns out to be the agent.
But that need not be so. Thus, &apos;boy&apos; and &apos;key&apos; are
respectively the karta karakas in the following sen-
tences
</bodyText>
<footnote confidence="0.9932985">
1The Paninian framework was originally designed more
than two millennia ago for writing a grammar of Sanskrit;
it has been adapted by us to deal with modern Indian
languages.
</footnote>
<page confidence="0.998727">
105
</page>
<bodyText confidence="0.608276">
semantic level (what the speaker
has in mind)
karaka level
vibhakti level
</bodyText>
<figureCaption confidence="0.9387375">
surface level (uttered sentence)
Fig. 1: Levels in the Paninian model
</figureCaption>
<bodyText confidence="0.979708382352941">
The boy opened the lock.
The key opened the lock.
Note that in the first sentence, the karta (boy) maps
to agent theta role, while in the second, karta (key)
maps to instrument theta role.
As part of this framework, a mapping is specified
between karaka relations and vibhakti (which covers
collectively case endings, post-positional markers,
etc.). This mapping between karakas and vibhakti
depends on the verb and its tense aspect modality
(TAM) label. The mapping is represented by two
structures: default karaka charts and karaka chart
transformations. The default karaka chart for a verb
or a class of verbs gives the mapping for the TAM la-
bel tA_hE called basic. It specifies the vibhakti per-
mitted for the applicable karaka relations for a verb
when the verb has the basic TAM label. This basic
TAM label roughly corresponds to present indefinite
tense and is purely syntactic in nature. For other
TAM labels there are karaka chart transformation
rules. Thus, for a given verb with some TAM la-
bel, appropriate karaka chart can be obtained using
its basic karaka chart and the transformation rule
depending on its TAM label. 2
In Hindi for instance, the basic TAM label is
tA_hE (which roughly stands for the present indef-
inite). The default karaka chart for three of the
karakas is given in Fig. 2. This explains the vibhak-
tis in sentences A.1 to A.2. In A.1 and A.2, &apos;Ram&apos;
is karta and &apos;Mohan&apos; is karma, because of their vib-
hakti markers 0 and ko, respectively. 3 (Note that
&apos;rAma&apos; is followed by 0 or empty postposition, and
&apos;mohana&apos; by &apos;ko&apos; postposition.)
A.1 rAma mohana ko pItatA hE.
</bodyText>
<footnote confidence="0.7639945">
2The transformation rules are a device to represent the
karaka charts more compactly. However, as is obvious, they
affect the karaka charts and not the parse structure. There-
fore, they are different from transformational grammars.
Formally, these rules can be eliminated by having separate
karaka charts for each TAM label. But one would miss the
liguistic generalization of relating the karaka charts based on
TAM labels in a systematic manner.
3In the present examples karta and karma turn out to be
agent and theme, respectively.
</footnote>
<table confidence="0.95902075">
KARAKA VIBHAKTI PRESENCE
Karta cb mandatory
Karma ko or 0 mandatory
Karana se or optional
dvArA
Fig. 2: A default karaka Chart
TAM LABEL TRANSFORMED
VIBHAKTI FOR KARTA
yA ne
nA_padA ko
yA_gayA se or dvArA (and karta is
optional)
</table>
<figureCaption confidence="0.919466">
Fig. 3: Transformation rules
</figureCaption>
<bodyText confidence="0.909237">
Ram Mohan -ko beats is
(Ram beats Mohan.)
A.2 mohana ko rAma pItatA hE.
Mohan -ko Ram beats is
(Ram beats Mohan.)
Fig. 3 gives some transformation rules for the
default mapping for Hindi. It explains the vibhakti
in sentences B.1 to B.4, where Ram is the karta but
has different vibhaktis, 0, ne, ko, se, respectively.
In each of the sentences, if we transform the karaka
chart of Fig.2 by the transformation rules of Fig.3,
we get the desired vibhakti for the karta Ram.
B.1 rAma Pala ko KAtA hE.
Ram fruit -ko eats is
(Ram eats the fruit.)
B.2 rAma ne Pala KAyA.
Ram -ne fruit ate
(Ram ate the fruit.)
B.3 rAma ko Pala KAnA padA.
Ram -ko fruit eat had to
(Ram had to eat the fruit.)
B.4 rAma se Pala nahI KAyA gayA
Ram -se fruit not eat could
(Ram could not eat the fruit.)
In general, the transformations affect not only
the vibhakti of karta but also that of other karakas.
They also &apos;delete&apos; karaka roles at times, that is, the
&apos;deleted&apos; karaka roles must not occur in the sen-
tence.
The Paninian framework is similar to the broad
class of case based grammars. What distinguishes
the Paninian framework is the use of karaka re-
lations rather than theta roles, and the neat de-
pendence of the karaka vibhakti mapping on TAMs
</bodyText>
<page confidence="0.991782">
106
</page>
<bodyText confidence="0.9996215">
and the transformation rules, in case of Indian lan-
guages. The same principle also solves the problem
of karaka assignment for complex sentences (Dis-
cussed later in Sec. 3.)
</bodyText>
<sectionHeader confidence="0.791845" genericHeader="method">
2 Constraint Based Parsing
</sectionHeader>
<bodyText confidence="0.999744571428572">
The Paninian theory outlined above can be used
for building a parser. First stage of the parser takes
care of morphology. For each word in the input
sentence, a dictionary or a lexicon is looked up, and
associated grammatical information is retrieved. In
the next stage local word grouping takes place, in
which based on local information certain words are
grouped together yielding noun groups and verb
groups. These are the word groups at the vibhakti
level (i.e., typically each word group is a noun or
verb with its vibhakti, TAM label, etc.). These in-
volve grouping post-positional markers with nouns,
auxiliaries with main verbs etc. Rules for local word
grouping are given by finite state machines. Finally,
the karaka relations among the elements are identi-
fied in the last stage called the core parser.
Morphological analyzer and local word grouper
have been described elsewhere (Bharati et al., 1991).
Here we discuss the core parser. Given the local
word groups in a sentence, the task of the core
parser is two-fold:
</bodyText>
<listItem confidence="0.999161">
1. To identify karaka relations among word
groups, and
2. To identify senses of words.
</listItem>
<bodyText confidence="0.999840916666667">
The first task requires karaka charts and transfor-
mation rules. The second task requires lakshan
charts for nouns and verbs (explained at the end
of the section).
A data structure corresponding to karaka chart
stores information about karaka-vibhakti mapping
including optionality of karakas. Initially, the de-
fault karaka chart is loaded into it for a given verb
group in the sentence. Transformations are per-
formed based on the TAM label. There is a sep-
arate data structure for the karaka chart for each
verb group in the sentence being processed. Each
row is called a karaka resiriction in a karaka chart.
For a given sentence after the word groups have
been formed, karaka charts for the verb groups
are created and each of the noun groups is tested
against the karaka restrictions in each karaka chart.
When testing a noun group against a karaka re-
striction of a verb group, vibhakti information is
checked, and if found satisfactory, the noun group
becomes a candidate for the karaka of the verb
group.
The above can be shown in the form of a con-
straint graph. Nodes of the graph are the word
</bodyText>
<figureCaption confidence="0.991022">
Fig. 4: Constraint graph
</figureCaption>
<bodyText confidence="0.986686214285714">
groups and there is an arc labeled by a karaka from
a verb group to a noun group, if the noun group
satisfies the karaka restriction in the karaka chart
of the verb group. (There is an arc from one verb
group to another, if the karaka chart of the former
shows that it takes a sentential or verbal karaka.)
The verb groups are called demand groups as they
make demands about their karakas, and the noun
groups are called source groups because they sat-
isfy demands.
As an example, consider a sentence containing the
verb KA (eat):
baccA hATa se kelA KAtA hE.
child hand -se banana eats
(The child eats the banana with his hand.)
Its word groups are marked and KA (eat) has the
same karaka chart as in Fig. 2. Its constraint graph
is shown in Fig. 4.
A parse is a sub-graph of the constraint graph
satisfying the following conditions:
1. For each of the mandatory karakas in a karaka
chart for each demand group, there should be
exactly one out-going edge from the demand
group labeled by the karaka.
2. For each of the optional karakas in a karaka
chart for each demand group, there should be
at most one outgoing edge from the demand
group labeled by the karaka.
</bodyText>
<listItem confidence="0.737798">
3. There should be exactly one incoming arc into
each source group.
</listItem>
<bodyText confidence="0.998891111111111">
If several sub-graphs of a constraint graph satisfy
the above conditions, it means that there are multi-
ple parses and the sentence is ambiguous. If no sub-
graph satisfies the above constraints, the sentence
does not have a parse, and is probably ill-formed.
There are similarities with dependency grammars
here because such constraint graphs are also pro-
duced by dependency grammars (Covington, 1990)
(Kashket, 1986).
</bodyText>
<figure confidence="0.76291875">
baccA hATa se
karta
kelA KAtA hE
karma
</figure>
<page confidence="0.982329">
107
</page>
<bodyText confidence="0.99997198">
It differs from them in two ways. First, the
Paninian framework uses the linguistic insight re-
garding karaka relations to identify relations be-
tween constituents in a sentence. Second, the con-
straints are sufficiently restricted that they reduce
to well known bipartite graph matching problems
for which efficient solutions are known. We discuss
the latter aspect next.
If karaka charts contain only mandatory karakas,
the constraint solver can be reduced to finding a
matching in a bipartite graph. Here is what
needs to be done for a given sentence. (Perraju,
1992). For every source word group create a node
belonging to a set U; for every karaka in the karaka
chart of every verb group, create a node belonging
to set V; and for every edge in the constraint graph,
create an edge in E from a node in V to a node in
U as follows: if there is an edge labeled in karaka
k in the constraint graph from a demand node d
to a source node s, create an edge in E in the bi-
partite graph from the node corresponding to (d,
k) in V to the node corresponding to s in U. The
original problem of finding a solution parse in the
constraint graph now reduces to finding a complete
matching in the bipartite graph {U,V,E} that covers
all the nodes in U and V. 5 It has several known effi-
cient algorithms. The time complexity of augment-
ing path algorithm is 0 (min (II UI).1ED which
in the worst case is 0(n3) where n is the number
of word groups in the sentence being parsed. (See
Papadimitrou et al. (1982), Ahuja et al. (1993).)
The fastest known algorithm has asymptotic com-
plexity of 0 (11711/2 . lEl) and is based on max flow
problem (Hoperoft and Karp (1973)).
If we permit optional karakas, the problem still
has an efficient solution. It now reduces to finding
a matching which has the maximal weight in the
weighted matching problem. To perform the reduc-
tion, we need to form a weighted bipartite graph.
We first form a bipartite graph exactly as before.
Next the edges are weighted by assigning a weight
of 1 if the edge is from a node in V representing
a mandatory karaka and 0 if optional karaka. The
problem now is to find the largest maximal match-
ing (or assignment) that has the maximum weight
(called the maximum bipartite matching problem or
assignment problem). The resulting matching rep-
resents a valid parse if the matching covers all nodes
in U and covers those nodes in V that are for manda-
tory karakas. (The maximal weight condition en-
</bodyText>
<footnote confidence="0.687545333333333">
4 We are indebted to Sonmath Biswas for suggesting the
connection.
&apos;A matching in a bipartite graph {U,V,E}is a subgraph
with a subset of E such that no two edges are adjacent. A
complete matching is also a largest maximal matching (Deo,
1979).
</footnote>
<bodyText confidence="0.999891512820513">
sures that all edges from nodes in V representing
mandatory karakas are selected first, if possible.)
This problem has a known solution by the Hun-
garian method of time complexity 0(n3) arithmetic
operations (Kuhn, 1955).
Note that in the above theory we have made
the following assumptions: (a) Each word group
is uniquely identifiable before the core parser ex-
ecutes, (b) Each demand word has only one karaka
chart, and (c) There are no ambiguities between
source word and demand word. Empirical data for
Indian languages shows that, conditions (a) and (b)
hold. Condition (c), however, does not always hold
for certain Indian languages, as shown by a cor-
pus. Even though there are many exceptions for
this condition, they still produce only a small num-
ber of such ambiguities or clashes. Therefore, for
each possible demand group and source group clash,
a new constraint graph can be produced and solved,
leaving the polynomial time complexity unchanged.
The core parser also disambiguates word senses.
This requires the preparation of lakshan charts (or
discrimination nets) for nouns and verbs. A lak-
shan chart for a verb allows us to identify the sense
of the verb in a sentence given its parse. Lakshan
charts make use of the karakas of the verb in the
sentence, for determining the verb sense. Similarly
for the nouns. It should be noted (without discus-
sion) that (a) disambiguation of senses is done only
after karaka assignment is over, and (b) only those
senses are disambiguated which are necessary for
translation
The key point here is that since sense disambigua-
tion is done separately after the karaka assignment
is over it leads to an efficient system. If this were not
done the parsing problem would be NP-complete
(as shown by Barton et al. (1987) if agreement and
sense ambiguity interact, they make the problem
NP-complete).
</bodyText>
<sectionHeader confidence="0.8824805" genericHeader="method">
3 Active-Passives and Com-
plex Sentences
</sectionHeader>
<bodyText confidence="0.999960769230769">
This theory captures the linguistic intuition that in
free word order languages, vibhakti (case endings or
post-positions etc.) plays a key role in determining
karaka roles. To show that the above, though neat,
is not just an adhoc mechanism that explains the
isolated phenomena of semantic roles mapping to
vibhaktis, we discuss two other phenomena: active-
passive and control.
No separate theory is needed to explain active-
passives. Active and passive turn out to be special
cases of certain TAM labels, namely those used to
mark active and passive. Again consider for exam-
ple in Hindi.
</bodyText>
<page confidence="0.998121">
108
</page>
<bodyText confidence="0.987573557692308">
F.1 rAma mohana ko pItatA hE. (active)
Ram Mohan -ko beat pres.
(Ram beats Mohan.)
F.2 rAma dvArA mohana ko pItA gayA.(passv.)
Ram by Mohan -ko beaten was
(Mohan was beaten by Ram.)
Verb in F.2 has TAM label as yA_gayA. Conse-
quently, the vibhakti `dvArA&apos; for karta (Ram) fol-
lows from the transformation already given earlier
in Fig. 3.
A major support for the theory comes from com-
plex sentences, that is, sentences containing more
than one verb group. We first introduce the prob-
lem and then describe how the theory provides an
answer. Consider the Hindi sentences G.1, G.2 and
G.3.
In G.1, Ram is the karta of both the verbs: KA
(eat) and bulA (call). However, it occurs only once.
The problem is to identify which verb will control
its vibhakti. In G.2, karta Ram and the karma
Pala (fruit) both are shared by the two verbs kAta
(cut) and KA (eat). In G.3, the karta `usa&apos; (he) is
shared between the two verbs, and `cAkU&apos; (knife)
the karma karaka of &apos;le&apos; (take) is the karana (instru-
mental) karaka of &apos;kAta&apos; (cut).
G.1 rAma Pala KAkara mohana ko bulAtA hE.
Ram fruit having-eaten Mohan -ko calls
(Having eaten fruit, Ram calls Mohan.)
G.2 rAma ne Pala kAtakara KAyA.
Ram ne fruit having-cut ate
(Ram ate having cut the fruit.)
G.3 Pala kAtane ke liye usane cAkU liyA.
fruit to-cut for he-ne knife took
(To cut fruit, he took a knife.)
The observation that the matrix verb, i.e., main
verb rather than the intermediate verb controls the
vibhakti of the shared nominal is true in the above
sentences, as explained below. The theory we will
outline to elaborate on this theme will have two
parts. The first part gives the karaka to vibhakti
mapping as usual, the second part identifies shared
karakas.
The first part is in terms of the karaka vibhakti
mapping described earlier. Because the interme-
diate verbs have their own TAM labels, they are
handled by exactly the same mechanism. For ex-
ample, kara is the TAM label 6 of the intermedi-
ate verb groups in G.1 and G.2 (KA (eat) in G.1
and kAta (cut) in G.2), and nA is the TAM label
&apos;kara&apos; TAM label roughly means &apos;having completed the
activity&apos;. But note that TAM labels are purely syntactic,
hence the meaning is not required by the system.
</bodyText>
<footnote confidence="0.700309">
7 This is the verbal noun.
</footnote>
<note confidence="0.642404444444444">
TAM LABEL TRANSFORMATION
kara Karta must
not be present. Karma is
optional.
nA Karta and karma are op-
tional.
tA_huA Karta must
not be present. Karma is
optional.
</note>
<figureCaption confidence="0.983003">
Fig. 5: More transformation rules
</figureCaption>
<bodyText confidence="0.9999283">
of the intermediate verb (kAta (cut)) in G.3. As
usual, these TAM labels have transformation rules
that operate and modify the default karaka chart.
In particular, the transformation rules for the two
TAM labels (kara and nA) are given in Fig. 5. The
transformation rule with kara in Fig. 5 says that
karta of the verb with TAM label kara must not be
present in the sentence and the karma is optionally
present.
By these rules, the intermediate verb KA (eat) in
G.1 and kAta (cut) in G.2 do not have (indepen-
dent) karta karaka present in the sentence. Ram is
the karta of the main verb. Pala (fruit) is the karma
of the intermediate verb (KA) in G.1 but not in G.2
(kAta). In the latter, Pala is the karma of the main
verb. All these are accommodated by the above
transformation rule for `kara&apos;. The tree structures
produced are shown in Fig. 6 (ignore dotted lines
for now) where a child node of a parent expresses a
karaka relation or a verb-verb relation.
In the second part, there are rules for obtaining
the shared karakas. Karta of the intermediate verb
KA in G.1 can be obtained by a sharing rule of the
kind given by Si.
Rule Si: Karta of a verb with TAM label `kara&apos; is
the same as the karta of the verb it modifies 8.
The sharing rule(s) are applied after the tentative
karaka assignment (using karaka to vibhakti map-
ping) is over. The shared karakas are shown by
dotted lines in Fig. 6.
</bodyText>
<sectionHeader confidence="0.990385" genericHeader="conclusions">
4 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.6232725">
In summary, this paper makes several contributions:
• It shows that the Paninian framework applied
to modern Indian languages gives an elegant
account of the relation between vibhakti and
karaka roles. The mapping is elegant and com-
pact.
</bodyText>
<footnote confidence="0.9860885">
8The modified verb in the present sentences is the main
verb.
</footnote>
<page confidence="0.994285">
109
</page>
<figure confidence="0.997236076923077">
bulA (call)
karma precede
mohana KA (eat)
karta karma
rAma Pala
(fruit)
KA (eat)
karta karma precede
rAma Pala kAta (cut)
(fruit)
karta ...karma
rAma Pala
le (take)
</figure>
<listItem confidence="0.579038">
• The same basic account also explains active-
passives and complex sentences in these lan-
guages. This suggest that the solution is not
just adhoc but has a deeper underlying unity.
• It shows how a constraint based parser can be
</listItem>
<bodyText confidence="0.985724592592593">
built using the framework. The constraints
problem reduces to bipartite graph matching
problem because of the nature of constraints.
Efficient solutions are known for these prob-
lems.
It is interesting to observe that such a parser
(designed for free word order languages) com-
pares well in asymptotic time complexity with
the parser for context free grammars (CFGs)
which are basically designed for positional lan-
guages.
A parser for Indian languages based on the
Paninian theory is operational as part of a machine
translation system.
As part of our future work, we plan to apply this
framework to other free word order languages (i.e.,
other than the Indian languages). This theory can
also be attempted on positional languages such as
English. What is needed is the concept of general-
ized vibhakti in which position of a word gets inco-
porated in vibhakti. Thus, for a pure free word or-
der language, the generalized vibhakti contains pre-
or post-positional markers, whereas for a pure posi-
tional language it contains position information of a
word (group). Clearly, for most natural languages,
generalized vibhakti would contain information per-
taining to both markers and position.
</bodyText>
<figure confidence="0.895423833333333">
purpose
kAta (cut)
karta karma .karana
\Y
aha Pala cAkU
(he) (fruit) (knife)
</figure>
<figureCaption confidence="0.987197">
Fig. 6: Modifier-modified relations for sentences
G.1, G.2 and G.3,respectively. (Shared karakas
shown by dotted lines.)
</figureCaption>
<sectionHeader confidence="0.979478" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999395846153846">
Vineet Chaitanya is the principal source of ideas
in this paper, who really should be a co-author.
We gratefully acknowledge the help received from
K.V. Ramakrishnamacharyulu of Rashtriya San-
skrit Sansthan, Tirupati in development of the the-
ory. For complexity results, we acknowledge the
contributions of B. Perraju, Somnath Biswas and
Ravindra K. Ahuja.
Support for this and related work comes from the
following agencies of Government of India: Ministry
of Human Resource Development, Department of
Electronics, and Department of Science and Tech-
nology.
</bodyText>
<sectionHeader confidence="0.999585" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9905605">
Ahuja, R.K., Thomas L. Magnanti, and James
B. Orlin, Network Flows: Theory, Algorithms
</reference>
<figure confidence="0.80715625">
karta karma
vaha cAkU
(he) (knife) .
1 1 0
</figure>
<reference confidence="0.999214314814815">
and Applications, Prentice-Hall, 1993 (forth-
coming).
Barton, G. Edward, Robert C. Berwick, and Eric
S. Ristad, Computational Complexity and Nat-
ural Language, MIT Press, Cambridge, MA,
1987.
Bharati, Akshar, Vineet Chaitanya, and Rajeev
Sangal, A Computational Grammar for Indian
Languages Processing, Journal of Indian Lin-
guistics, IL-51. (Also available as TRCS-90-96,
Dept. of CSE, HT Kanpur, 1990.)
Bharati, Akshar, Vineet Chaitanya, and Rajeev
Sangal, Local Word Grouping and Its Rel-
evance to Indian Languages, in Frontiers in
Knowledge Based Computing (KBCS90), V.P.
Bhatkar and K.M. Rege (eds.), Narosa Publish-
ing House, New Delhi, 1991, pp. 277-296.
Bharati, Akshar, Vineet Chaitanya, and Rajeev
Sangal, LFG, GB, and Paninian Frameworks:
An NLP Viewpoint, Part of NLP tutorial for
CPAL-2: UNESCO 2nd Regional Workshop on
Computer Processing of Asian Languages, 12-
16 March 1992, I.I.T. Kanpur. (Also available
as TRCS-92-140, Dept. of CSE, HT Kanpur.)
Cardona, George, Panini: A Survey of Research,
Mouton, Hague-Paris, 1976.
Cardona, George, Panini: His Work and Its Tra-
dition (Vol. 1: Background and Introduction),
Motilal Banarsidas, Delhi, 1988.
Covington, Michael A., Parsing Discontinuous
Constituents in Dependency Grammar (Tech-
nical Correspondence), Computational Lin-
guistics, 16,4 (Dec. 1990), p.234.
Deo, Narsingh, Graph Theory, Prentice-Hall, 1974.
Hoperoft, J.E. and R.M. Karp, &amp;quot;A n.5/2 Algorithm
for Maximum Matching in Bipartite Graphs,&amp;quot;
J. SIAM Comp. 2 (1973), pp.225-231.
Kashket, Michael B., Parsing a free-word-order
language: Warlpiri, Proc. of 24th Annual
Meeting of ACL, pp. 60-66.
Kiparsky, P., Some Theoretical Problems in
Panini&apos;s Grammar, Bhandarkar Oriental Re-
search Institute, Poona, India, 1982.
Kuhn, H.W. &amp;quot;The Hungarian Method for the As-
signment Problem&amp;quot;, Naval Research Logistics
Quarterly, 2 (1955), pp.83-97.
Papadimitrou, Christos H., and K. Steiglitz, Com-
binatorial Optimization, Prentice-Hall, Engle-
wood Cliffs, 1982.
Perraju, Bendapudi V.S., Algorithmic Aspects
of Natural Language Parsing using Paninian
Framework, M.Tech. thesis, Dept. of Com-
puter Science and Engineering, I.I.T. Kanpur,
Dec. 1992.
</reference>
<page confidence="0.998799">
111
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.482548">
<title confidence="0.9694585">Parsing Free Word Order Languages in the Paninian Framework</title>
<author confidence="0.859843">Akshar Bharati Rajeev Sangal</author>
<affiliation confidence="0.9913885">Department of Computer Science and Engineering Indian Institute of Technology Kanpur</affiliation>
<address confidence="0.985262">Kanpur 208016 India</address>
<email confidence="0.798603">Internet:sangal@iitk.ernet.in</email>
<abstract confidence="0.997234444444445">There is a need to develop a suitable computational grammar formalism for free word order languages for two reasons: First, a suitably designed formalism is likely to be more efficient. Second, such a formalism is also likely to be linguistically more elegant and satisfying. In this paper, we describe such a formalism, called the Paninian framework, that has been successfully applied to Indian languages. This paper shows that the Paninian framework applied to modern Indian languages gives an elegant account of the relation between surface form (vibhakti) and semantic (karaka) roles. The mapping is elegant and compact. The same basic account also explains active-passives and complex sentences. This suggests that the solution is not just adhoc but has a deeper underlying unity. A constraint based parser is described for the framework. The constraints problem reduces to bipartite graph matching problem because of the nature of constraints. Efficient solutions are known for these problems. It is interesting to observe that such a parser (designed for free word order languages) compares well in asymptotic time complexity with the parser for context free grammars (CFCs) which are basically designed for positional languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R K Ahuja</author>
<author>Thomas L Magnanti</author>
<author>James B Orlin</author>
</authors>
<title>Network Flows: Theory, Algorithms and Applications, Prentice-Hall,</title>
<date>1993</date>
<contexts>
<context position="13218" citStr="Ahuja et al. (1993)" startWordPosition="2265" endWordPosition="2268">h from a demand node d to a source node s, create an edge in E in the bipartite graph from the node corresponding to (d, k) in V to the node corresponding to s in U. The original problem of finding a solution parse in the constraint graph now reduces to finding a complete matching in the bipartite graph {U,V,E} that covers all the nodes in U and V. 5 It has several known efficient algorithms. The time complexity of augmenting path algorithm is 0 (min (II UI).1ED which in the worst case is 0(n3) where n is the number of word groups in the sentence being parsed. (See Papadimitrou et al. (1982), Ahuja et al. (1993).) The fastest known algorithm has asymptotic complexity of 0 (11711/2 . lEl) and is based on max flow problem (Hoperoft and Karp (1973)). If we permit optional karakas, the problem still has an efficient solution. It now reduces to finding a matching which has the maximal weight in the weighted matching problem. To perform the reduction, we need to form a weighted bipartite graph. We first form a bipartite graph exactly as before. Next the edges are weighted by assigning a weight of 1 if the edge is from a node in V representing a mandatory karaka and 0 if optional karaka. The problem now is </context>
</contexts>
<marker>Ahuja, Magnanti, Orlin, 1993</marker>
<rawString>Ahuja, R.K., Thomas L. Magnanti, and James B. Orlin, Network Flows: Theory, Algorithms and Applications, Prentice-Hall, 1993 (forthcoming).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Edward Barton</author>
<author>Robert C Berwick</author>
<author>Eric S Ristad</author>
</authors>
<date>1987</date>
<booktitle>Computational Complexity and Natural Language,</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="16157" citStr="Barton et al. (1987)" startWordPosition="2769" endWordPosition="2772">ify the sense of the verb in a sentence given its parse. Lakshan charts make use of the karakas of the verb in the sentence, for determining the verb sense. Similarly for the nouns. It should be noted (without discussion) that (a) disambiguation of senses is done only after karaka assignment is over, and (b) only those senses are disambiguated which are necessary for translation The key point here is that since sense disambiguation is done separately after the karaka assignment is over it leads to an efficient system. If this were not done the parsing problem would be NP-complete (as shown by Barton et al. (1987) if agreement and sense ambiguity interact, they make the problem NP-complete). 3 Active-Passives and Complex Sentences This theory captures the linguistic intuition that in free word order languages, vibhakti (case endings or post-positions etc.) plays a key role in determining karaka roles. To show that the above, though neat, is not just an adhoc mechanism that explains the isolated phenomena of semantic roles mapping to vibhaktis, we discuss two other phenomena: activepassive and control. No separate theory is needed to explain activepassives. Active and passive turn out to be special case</context>
</contexts>
<marker>Barton, Berwick, Ristad, 1987</marker>
<rawString>Barton, G. Edward, Robert C. Berwick, and Eric S. Ristad, Computational Complexity and Natural Language, MIT Press, Cambridge, MA, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akshar Bharati</author>
<author>Vineet Chaitanya</author>
<author>Rajeev Sangal</author>
</authors>
<title>A Computational Grammar for Indian Languages Processing,</title>
<date>1990</date>
<journal>Journal of Indian Linguistics,</journal>
<volume>51</volume>
<note>Also available as TRCS-90-96, Dept. of CSE, HT Kanpur,</note>
<contexts>
<context position="3384" citStr="Bharati et al. (1990)" startWordPosition="537" endWordPosition="540">verbals and other related constituents in a sentence. They by themselves do not give the semantics. Instead they specify relations which mediate between vibhakti of nominals and verb forms on one hand and semantic relations on the other (Kiparsky, 1982) (Cardona (1976), (1988)). See Fig. 1. Two of the important karakas are karta karaka and karma karaka. Frequently, the karta karaka maps to agent theta role, and the karma to theme or goal theta role. Here we will not argue for the linguistic significance of karaka relations and differences with theta relations, as that has been done elsewhere (Bharati et al. (1990) and (1992)). In summary, karta karaka is that participant in the action that is most independent. At times, it turns out to be the agent. But that need not be so. Thus, &apos;boy&apos; and &apos;key&apos; are respectively the karta karakas in the following sentences 1The Paninian framework was originally designed more than two millennia ago for writing a grammar of Sanskrit; it has been adapted by us to deal with modern Indian languages. 105 semantic level (what the speaker has in mind) karaka level vibhakti level surface level (uttered sentence) Fig. 1: Levels in the Paninian model The boy opened the lock. The </context>
</contexts>
<marker>Bharati, Chaitanya, Sangal, 1990</marker>
<rawString>Bharati, Akshar, Vineet Chaitanya, and Rajeev Sangal, A Computational Grammar for Indian Languages Processing, Journal of Indian Linguistics, IL-51. (Also available as TRCS-90-96, Dept. of CSE, HT Kanpur, 1990.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akshar Bharati</author>
</authors>
<title>Vineet Chaitanya, and Rajeev Sangal, Local Word Grouping and Its Relevance to Indian Languages,</title>
<date>1991</date>
<booktitle>in Frontiers in Knowledge Based Computing</booktitle>
<pages>277--296</pages>
<editor>(KBCS90), V.P. Bhatkar and K.M. Rege (eds.),</editor>
<publisher>Narosa Publishing House,</publisher>
<location>New Delhi,</location>
<marker>Bharati, 1991</marker>
<rawString>Bharati, Akshar, Vineet Chaitanya, and Rajeev Sangal, Local Word Grouping and Its Relevance to Indian Languages, in Frontiers in Knowledge Based Computing (KBCS90), V.P. Bhatkar and K.M. Rege (eds.), Narosa Publishing House, New Delhi, 1991, pp. 277-296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akshar Bharati</author>
<author>Vineet Chaitanya</author>
<author>Rajeev Sangal</author>
<author>GB LFG</author>
<author>Paninian</author>
</authors>
<title>Frameworks: An NLP Viewpoint, Part of NLP tutorial for CPAL-2:</title>
<date>1992</date>
<journal>HT Kanpur.</journal>
<booktitle>UNESCO 2nd Regional Workshop on Computer Processing of Asian Languages,</booktitle>
<pages>12--16</pages>
<marker>Bharati, Chaitanya, Sangal, LFG, Paninian, 1992</marker>
<rawString>Bharati, Akshar, Vineet Chaitanya, and Rajeev Sangal, LFG, GB, and Paninian Frameworks: An NLP Viewpoint, Part of NLP tutorial for CPAL-2: UNESCO 2nd Regional Workshop on Computer Processing of Asian Languages, 12-16 March 1992, I.I.T. Kanpur. (Also available as TRCS-92-140, Dept. of CSE, HT Kanpur.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Cardona</author>
</authors>
<title>Panini: A Survey of Research,</title>
<date>1976</date>
<location>Mouton, Hague-Paris,</location>
<contexts>
<context position="3032" citStr="Cardona (1976)" startWordPosition="477" endWordPosition="478">be such a formalism, called the Paninian framework, that has been successfully applied to Indian languages. 1 It uses the notion of karaka relations between verbs and nouns in a sentence. The notion of karaka relations is central to the Paninian model. The karaka relations are syntactico-semantic (or semantico-syntactic) relations between the verbals and other related constituents in a sentence. They by themselves do not give the semantics. Instead they specify relations which mediate between vibhakti of nominals and verb forms on one hand and semantic relations on the other (Kiparsky, 1982) (Cardona (1976), (1988)). See Fig. 1. Two of the important karakas are karta karaka and karma karaka. Frequently, the karta karaka maps to agent theta role, and the karma to theme or goal theta role. Here we will not argue for the linguistic significance of karaka relations and differences with theta relations, as that has been done elsewhere (Bharati et al. (1990) and (1992)). In summary, karta karaka is that participant in the action that is most independent. At times, it turns out to be the agent. But that need not be so. Thus, &apos;boy&apos; and &apos;key&apos; are respectively the karta karakas in the following sentences </context>
</contexts>
<marker>Cardona, 1976</marker>
<rawString>Cardona, George, Panini: A Survey of Research, Mouton, Hague-Paris, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Cardona</author>
</authors>
<title>Panini: His Work and Its Tradition (Vol. 1: Background and Introduction), Motilal Banarsidas,</title>
<date>1988</date>
<location>Delhi,</location>
<marker>Cardona, 1988</marker>
<rawString>Cardona, George, Panini: His Work and Its Tradition (Vol. 1: Background and Introduction), Motilal Banarsidas, Delhi, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>Parsing Discontinuous Constituents in Dependency Grammar (Technical Correspondence),</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<pages>234</pages>
<location>Deo, Narsingh, Graph Theory, Prentice-Hall,</location>
<contexts>
<context position="11643" citStr="Covington, 1990" startWordPosition="1976" endWordPosition="1977">the optional karakas in a karaka chart for each demand group, there should be at most one outgoing edge from the demand group labeled by the karaka. 3. There should be exactly one incoming arc into each source group. If several sub-graphs of a constraint graph satisfy the above conditions, it means that there are multiple parses and the sentence is ambiguous. If no subgraph satisfies the above constraints, the sentence does not have a parse, and is probably ill-formed. There are similarities with dependency grammars here because such constraint graphs are also produced by dependency grammars (Covington, 1990) (Kashket, 1986). baccA hATa se karta kelA KAtA hE karma 107 It differs from them in two ways. First, the Paninian framework uses the linguistic insight regarding karaka relations to identify relations between constituents in a sentence. Second, the constraints are sufficiently restricted that they reduce to well known bipartite graph matching problems for which efficient solutions are known. We discuss the latter aspect next. If karaka charts contain only mandatory karakas, the constraint solver can be reduced to finding a matching in a bipartite graph. Here is what needs to be done for a giv</context>
</contexts>
<marker>Covington, 1990</marker>
<rawString>Covington, Michael A., Parsing Discontinuous Constituents in Dependency Grammar (Technical Correspondence), Computational Linguistics, 16,4 (Dec. 1990), p.234. Deo, Narsingh, Graph Theory, Prentice-Hall, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Hoperoft</author>
<author>R M Karp</author>
</authors>
<title>A n.5/2 Algorithm for Maximum Matching in Bipartite Graphs,&amp;quot;</title>
<date>1973</date>
<journal>J. SIAM Comp.</journal>
<volume>2</volume>
<pages>225--231</pages>
<contexts>
<context position="13354" citStr="Hoperoft and Karp (1973)" startWordPosition="2289" endWordPosition="2292"> the node corresponding to s in U. The original problem of finding a solution parse in the constraint graph now reduces to finding a complete matching in the bipartite graph {U,V,E} that covers all the nodes in U and V. 5 It has several known efficient algorithms. The time complexity of augmenting path algorithm is 0 (min (II UI).1ED which in the worst case is 0(n3) where n is the number of word groups in the sentence being parsed. (See Papadimitrou et al. (1982), Ahuja et al. (1993).) The fastest known algorithm has asymptotic complexity of 0 (11711/2 . lEl) and is based on max flow problem (Hoperoft and Karp (1973)). If we permit optional karakas, the problem still has an efficient solution. It now reduces to finding a matching which has the maximal weight in the weighted matching problem. To perform the reduction, we need to form a weighted bipartite graph. We first form a bipartite graph exactly as before. Next the edges are weighted by assigning a weight of 1 if the edge is from a node in V representing a mandatory karaka and 0 if optional karaka. The problem now is to find the largest maximal matching (or assignment) that has the maximum weight (called the maximum bipartite matching problem or assig</context>
</contexts>
<marker>Hoperoft, Karp, 1973</marker>
<rawString>Hoperoft, J.E. and R.M. Karp, &amp;quot;A n.5/2 Algorithm for Maximum Matching in Bipartite Graphs,&amp;quot; J. SIAM Comp. 2 (1973), pp.225-231.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael B Kashket</author>
</authors>
<title>Parsing a free-word-order language: Warlpiri,</title>
<booktitle>Proc. of 24th Annual Meeting of ACL,</booktitle>
<pages>60--66</pages>
<marker>Kashket, </marker>
<rawString>Kashket, Michael B., Parsing a free-word-order language: Warlpiri, Proc. of 24th Annual Meeting of ACL, pp. 60-66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kiparsky</author>
</authors>
<title>Some Theoretical Problems in Panini&apos;s Grammar,</title>
<date>1982</date>
<institution>Bhandarkar Oriental Research Institute,</institution>
<location>Poona, India,</location>
<contexts>
<context position="3016" citStr="Kiparsky, 1982" startWordPosition="475" endWordPosition="476"> paper, we describe such a formalism, called the Paninian framework, that has been successfully applied to Indian languages. 1 It uses the notion of karaka relations between verbs and nouns in a sentence. The notion of karaka relations is central to the Paninian model. The karaka relations are syntactico-semantic (or semantico-syntactic) relations between the verbals and other related constituents in a sentence. They by themselves do not give the semantics. Instead they specify relations which mediate between vibhakti of nominals and verb forms on one hand and semantic relations on the other (Kiparsky, 1982) (Cardona (1976), (1988)). See Fig. 1. Two of the important karakas are karta karaka and karma karaka. Frequently, the karta karaka maps to agent theta role, and the karma to theme or goal theta role. Here we will not argue for the linguistic significance of karaka relations and differences with theta relations, as that has been done elsewhere (Bharati et al. (1990) and (1992)). In summary, karta karaka is that participant in the action that is most independent. At times, it turns out to be the agent. But that need not be so. Thus, &apos;boy&apos; and &apos;key&apos; are respectively the karta karakas in the foll</context>
</contexts>
<marker>Kiparsky, 1982</marker>
<rawString>Kiparsky, P., Some Theoretical Problems in Panini&apos;s Grammar, Bhandarkar Oriental Research Institute, Poona, India, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H W Kuhn</author>
</authors>
<title>The Hungarian Method for the Assignment Problem&amp;quot;,</title>
<date>1955</date>
<journal>Naval Research Logistics Quarterly,</journal>
<volume>2</volume>
<pages>83--97</pages>
<contexts>
<context position="14612" citStr="Kuhn, 1955" startWordPosition="2509" endWordPosition="2510">ts a valid parse if the matching covers all nodes in U and covers those nodes in V that are for mandatory karakas. (The maximal weight condition en4 We are indebted to Sonmath Biswas for suggesting the connection. &apos;A matching in a bipartite graph {U,V,E}is a subgraph with a subset of E such that no two edges are adjacent. A complete matching is also a largest maximal matching (Deo, 1979). sures that all edges from nodes in V representing mandatory karakas are selected first, if possible.) This problem has a known solution by the Hungarian method of time complexity 0(n3) arithmetic operations (Kuhn, 1955). Note that in the above theory we have made the following assumptions: (a) Each word group is uniquely identifiable before the core parser executes, (b) Each demand word has only one karaka chart, and (c) There are no ambiguities between source word and demand word. Empirical data for Indian languages shows that, conditions (a) and (b) hold. Condition (c), however, does not always hold for certain Indian languages, as shown by a corpus. Even though there are many exceptions for this condition, they still produce only a small number of such ambiguities or clashes. Therefore, for each possible </context>
</contexts>
<marker>Kuhn, 1955</marker>
<rawString>Kuhn, H.W. &amp;quot;The Hungarian Method for the Assignment Problem&amp;quot;, Naval Research Logistics Quarterly, 2 (1955), pp.83-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christos H Papadimitrou</author>
<author>K Steiglitz</author>
</authors>
<title>Combinatorial Optimization, Prentice-Hall,</title>
<date>1982</date>
<location>Englewood Cliffs,</location>
<marker>Papadimitrou, Steiglitz, 1982</marker>
<rawString>Papadimitrou, Christos H., and K. Steiglitz, Combinatorial Optimization, Prentice-Hall, Englewood Cliffs, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bendapudi V S Perraju</author>
</authors>
<title>Algorithmic Aspects of Natural Language Parsing using Paninian Framework,</title>
<date>1992</date>
<tech>M.Tech. thesis,</tech>
<institution>Dept. of Computer Science</institution>
<contexts>
<context position="12271" citStr="Perraju, 1992" startWordPosition="2078" endWordPosition="2079">6). baccA hATa se karta kelA KAtA hE karma 107 It differs from them in two ways. First, the Paninian framework uses the linguistic insight regarding karaka relations to identify relations between constituents in a sentence. Second, the constraints are sufficiently restricted that they reduce to well known bipartite graph matching problems for which efficient solutions are known. We discuss the latter aspect next. If karaka charts contain only mandatory karakas, the constraint solver can be reduced to finding a matching in a bipartite graph. Here is what needs to be done for a given sentence. (Perraju, 1992). For every source word group create a node belonging to a set U; for every karaka in the karaka chart of every verb group, create a node belonging to set V; and for every edge in the constraint graph, create an edge in E from a node in V to a node in U as follows: if there is an edge labeled in karaka k in the constraint graph from a demand node d to a source node s, create an edge in E in the bipartite graph from the node corresponding to (d, k) in V to the node corresponding to s in U. The original problem of finding a solution parse in the constraint graph now reduces to finding a complete</context>
</contexts>
<marker>Perraju, 1992</marker>
<rawString>Perraju, Bendapudi V.S., Algorithmic Aspects of Natural Language Parsing using Paninian Framework, M.Tech. thesis, Dept. of Computer Science and Engineering, I.I.T. Kanpur, Dec. 1992.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>