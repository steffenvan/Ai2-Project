<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.970654">
Token and Type Constraints for Cross-Lingual Part-of-Speech Tagging
</title>
<author confidence="0.997877">
Oscar T¨ackstr¨om°†* Dipanjan Das$ Slav Petrov$ Ryan McDonald$ Joakim Nivre†*
</author>
<affiliation confidence="0.887645666666667">
° Swedish Institute of Computer Science
† Department of Linguistics and Philology, Uppsala University
$ Google Research, New York
</affiliation>
<email confidence="0.984225333333333">
oscar@sics.se
{dipanjand|slav|ryanmcd}@google.com
joakim.nivre@lingfil.uu.se
</email>
<sectionHeader confidence="0.998523" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999970227272727">
We consider the construction of part-of-speech
taggers for resource-poor languages. Recently,
manually constructed tag dictionaries from
Wiktionary and dictionaries projected via bitext
have been used as type constraints to overcome
the scarcity of annotated data in this setting.
In this paper, we show that additional token
constraints can be projected from a resource-
rich source language to a resource-poor target
language via word-aligned bitext. We present
several models to this end; in particular a par-
tially observed conditional random field model,
where coupled token and type constraints pro-
vide a partial signal for training. Averaged
across eight previously studied Indo-European
languages, our model achieves a 25% relative
error reduction over the prior state of the art.
We further present successful results on seven
additional languages from different families,
empirically demonstrating the applicability of
coupled token and type constraints across a
diverse set of languages.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995304044444444">
Supervised part-of-speech (POS) taggers are avail-
able for more than twenty languages and achieve ac-
curacies of around 95% on in-domain data (Petrov et
al., 2012). Thanks to their efficiency and robustness,
supervised taggers are routinely employed in many
natural language processing applications, such as syn-
tactic and semantic parsing, named-entity recognition
and machine translation. Unfortunately, the resources
required to train supervised taggers are expensive to
create and unlikely to exist for the majority of written
∗ Work primarily carried out while at Google Research.
languages. The necessity of building NLP tools for
these resource-poor languages has been part of the
motivation for research on unsupervised learning of
POS taggers (Christodoulopoulos et al., 2010).
In this paper, we instead take a weakly supervised
approach towards this problem. Recently, learning
POS taggers with type-level tag dictionary constraints
has gained popularity. Tag dictionaries, noisily pro-
jected via word-aligned bitext, have bridged the gap
between purely unsupervised and fully supervised
taggers, resulting in an average accuracy of over 83%
on a benchmark of eight Indo-European languages
(Das and Petrov, 2011). Li et al. (2012) further im-
proved upon this result by employing Wiktionary1 as
a tag dictionary source, resulting in the hitherto best
published result of almost 85% on the same setup.
Although the aforementioned weakly supervised
approaches have resulted in significant improvements
over fully unsupervised approaches, they have not
exploited the benefits of token-level cross-lingual
projection methods, which are possible with word-
aligned bitext between a target language of interest
and a resource-rich source language, such as English.
This is the setting we consider in this paper (§2).
While prior work has successfully considered both
token- and type-level projection across word-aligned
bitext for estimating the model parameters of genera-
tive tagging models (Yarowsky and Ngai, 2001; Xi
and Hwa, 2005, inter alia), a key observation under-
lying the present work is that token- and type-level
information offer different and complementary sig-
nals. On the one hand, high confidence token-level
projections offer precise constraints on a tag in a
particular context. On the other hand, manually cre-
</bodyText>
<footnote confidence="0.979768">
1http://www.wiktionary.org/.
</footnote>
<page confidence="0.719426">
1
</page>
<bodyText confidence="0.967478181818182">
Transactions of the Association for Computational Linguistics, 1 (2013) 1–12. Action Editor: Sharon Goldwater.
Submitted 11/2012; Revised 1/2013; Published 3/2013. c�2013 Association for Computational Linguistics.
ated type-level dictionaries can have broad coverage
and do not suffer from word-alignment errors; they
can therefore be used to filter systematic as well as
random noise in token-level projections.
In order to reap these potential benefits, we pro-
pose a partially observed conditional random field
(CRF) model (Lafferty et al., 2001) that couples to-
ken and type constraints in order to guide learning
(§3). In essence, the model is given the freedom to
push probability mass towards hypotheses consistent
with both types of information. This approach is flex-
ible: we can use either noisy projected or manually
constructed dictionaries to generate type constraints;
furthermore, we can incorporate arbitrary features
over the input. In addition to standard (contextual)
lexical features and transition features, we observe
that adding features from a monolingual word cluster-
ing (Uszkoreit and Brants, 2008) can significantly im-
prove accuracy. While most of these features can also
be used in a generative feature-based hidden Markov
model (HMM) (Berg-Kirkpatrick et al., 2010), we
achieve the best accuracy with a globally normalized
discriminative CRF model.
To evaluate our approach, we present extensive
results on standard publicly available datasets for 15
languages: the eight Indo-European languages pre-
viously studied in this context by Das and Petrov
(2011) and Li et al. (2012), and seven additional lan-
guages from different families, for which no compa-
rable study exists. In §4 we compare various features,
constraints and model types. Our best model uses
type constraints derived from Wiktionary, together
with token constraints derived from high-confidence
word alignments. When averaged across the eight
languages studied by Das and Petrov (2011) and Li
et al. (2012), we achieve an accuracy of 88.8%. This
is a 25% relative error reduction over the previous
state of the art. Averaged across all 15 languages,
our model obtains an accuracy of 84.5% compared to
78.5% obtained by a strong generative baseline. Fi-
nally, we provide an in depth analysis of the relative
contributions of the two types of constraints in §5.
</bodyText>
<sectionHeader confidence="0.668884" genericHeader="method">
2 Coupling Token and Type Constraints
</sectionHeader>
<bodyText confidence="0.9998996875">
Type-level information has been amply used in
weakly supervised POS induction, either via pure
manually crafted tag dictionaries (Smith and Eisner,
2005; Ravi and Knight, 2009; Garrette and Baldridge,
2012), noisily projected tag dictionaries (Das and
Petrov, 2011) or through crowdsourced lexica, such
as Wiktionary (Li et al., 2012). At the other end
of the spectrum, there have been efforts that project
token-level information across word-aligned bitext
(Yarowsky and Ngai, 2001; Xi and Hwa, 2005). How-
ever, systems that combine both sources of informa-
tion in a single model have yet to be fully explored.
The following three subsections outline our overall
approach for coupling these two types of information
to build robust POS taggers that do not require any
direct supervision in the target language.
</bodyText>
<subsectionHeader confidence="0.9739">
2.1 Token Constraints
</subsectionHeader>
<bodyText confidence="0.999918380952381">
For the majority of resource-poor languages, there
is at least some bitext with a resource-rich source
language; for simplicity, we choose English as our
source language in all experiments. It is then nat-
ural to consider using a supervised part-of-speech
tagger to predict part-of-speech tags for the English
side of the bitext. These predicted tags can subse-
quently be projected to the target side via automatic
word alignments. This approach was pioneered by
Yarowsky and Ngai (2001), who used the resulting
partial target annotation to estimate the parameters
of an HMM. However, due to the automatic nature
of the word alignments and the POS tags, there will
be significant noise in the projected tags. To conquer
this noise, they used very aggressive smoothing tech-
niques when training the HMM. Fossum and Abney
(2005) used similar token-level projections, but in-
stead combined projections from multiple source lan-
guages to filter out random projection noise as well
as the systematic noise arising from different source
language annotations and syntactic divergences.
</bodyText>
<subsectionHeader confidence="0.998491">
2.2 Type Constraints
</subsectionHeader>
<bodyText confidence="0.9999795">
It is well known that given a tag dictionary, even if
it is incomplete, it is possible to learn accurate POS
taggers (Smith and Eisner, 2005; Goldberg et al.,
2008; Ravi and Knight, 2009; Naseem et al., 2009).
While widely differing in the specific model struc-
ture and learning objective, all of these approaches
achieve excellent results. Unfortunately, they rely
on tag dictionaries extracted directly from the un-
derlying treebank data. Such dictionaries provide in
depth coverage of the test domain and also list all
</bodyText>
<page confidence="0.993332">
2
</page>
<figure confidence="0.7296835">
Jordbruksprodukterna mdste vara rena och fdr inte innehdlla ndgra tillsatser �
NOUN VERB VERB ADJ CONJ VERB ADV VERB DET NOUN P
</figure>
<figureCaption confidence="0.9845532">
Figure 1: Lattice representation of the inference search space y(x) for an authentic sentence in Swedish (“The farming
products must be pure and must not contain any additives”), after pruning with Wiktionary type constraints. The
correct parts of speech are listed underneath each word. Bold nodes show projected token constraints ˜y. Underlined
text indicates incorrect tags. The coupled constraints lattice y(x, ˜y) consists of the bold nodes together with nodes for
words that are lacking token constraints; in this case, the coupled constraints lattice thus defines exactly one valid path.
</figureCaption>
<figure confidence="0.995224230769231">
Start
ADP
ADJ VERB
X
NOUN
NOUN
VERB
VERB
ADJ
CONJ VERB
NOUN
ADV VERB PRON NOUN P
StoP
</figure>
<bodyText confidence="0.997008652173913">
inflected forms – both of which are difficult to obtain
and unrealistic to expect for resource-poor languages.
In contrast, Das and Petrov (2011) automatically
create type-level tag dictionaries by aggregating over
projected token-level information extracted from bi-
text. To handle the noise in these automatic dictionar-
ies, they use label propagation on a similarity graph
to smooth (and also expand) the label distributions.
While their approach produces good results and is
applicable to resource-poor languages, it requires a
complex multi-stage training procedure including the
construction of a large distributional similarity graph.
Recently, Li et al. (2012) presented a simple and
viable alternative: crowdsourced dictionaries from
Wiktionary. While noisy and sparse in nature, Wik-
tionary dictionaries are available for 170 languages.2
Furthermore, their quality and coverage is growing
continuously (Li et al., 2012). By incorporating type
constraints from Wiktionary into the feature-based
HMM of Berg-Kirkpatrick et al. (2010), Li et al. were
able to obtain the best published results in this setting,
surpassing the results of Das and Petrov (2011) on
eight Indo-European languages.
</bodyText>
<subsectionHeader confidence="0.998989">
2.3 Coupled Constraints
</subsectionHeader>
<bodyText confidence="0.9996632">
Rather than relying exclusively on either token or
type constraints, we propose to complement the one
with the other during training. For each sentence in
our training set, a partially constrained lattice of tag
sequences is constructed as follows:
</bodyText>
<footnote confidence="0.9531225">
2http://meta.wikimedia.org/wiki/
Wiktionary — October 2012.
</footnote>
<listItem confidence="0.948596583333333">
1. For each token whose type is not in the tag dic-
tionary, we allow the entire tag set.
2. For each token whose type is in the tag dictio-
nary, we prune all tags not licensed by the dictio-
nary and mark the token as dictionary-pruned.
3. For each token that has a tag projected via a
high-confidence bidirectional word alignment:
if the projected tag is still present in the lattice,
then we prune every tag but the projected tag for
that token; if the projected tag is not present in
the lattice, which can only happen for dictionary-
pruned tokens, then we ignore the projected tag.
</listItem>
<bodyText confidence="0.999442947368421">
Figure 1 provides a running example. The lattice
shows tags permitted after constraining the words
to tags licensed by the dictionary (up until Step 2
from above). There is only a single token “Jordbruk-
sprodukterna” (“the farming products”) not in the
dictionary; in this case the lattice permits the full
set of tags. With token-level projections (Step 3;
nodes with bold border in Figure 1), the lattice can
be further pruned. In most cases, the projected tag
is both correct and is in the dictionary-pruned lattice.
We thus successfully disambiguate such tokens and
shrink the search space substantially.
There are two cases we highlight in order to show
where our model can break. First, for the token
“Jordbruksprodukterna”, the erroneously projected
tag ADJ will eliminate all other tags from the lattice,
including the correct tag NOUN. Second, the token
“n˚agra” (“any”) has a single dictionary entry PRON
and is missing the correct tag DET. In the case where
</bodyText>
<page confidence="0.992437">
3
</page>
<subsectionHeader confidence="0.445839">
Percent of tokens covered
</subsectionHeader>
<bodyText confidence="0.999263311111111">
DET is the projected tag, we will not add it to the
lattice and simply ignore it. This is because we hy-
pothesize that the tag dictionary can be trusted more
than the tags projected via noisy word alignments. As
we will see in §4, taking the union of tags performs
worse, which supports this hypothesis.
For generative models, such as HMMs (§3.1), we
need to define only one lattice. For our best gen-
erative model this is the coupled token- and type-
constrained lattice.3 At prediction time, in both the
discriminative and the generative cases, we find the
most likely label sequence using Viterbi decoding.
For discriminative models, such as CRFs (§3.2),
we need to define two lattices: one that the model
moves probability mass towards and another one
defining the overall search space (or partition func-
tion). In traditional supervised learning without a
dictionary, the former is a trivial lattice containing
the gold standard tag sequence and the latter is the
set of all possible tag sequences spanning the tokens.
With our best model, we will move mass towards the
coupled token- and type-constrained lattice, such that
the model can freely distribute mass across all paths
consistent with these constraints. The lattice defining
the partition function will be the full set of possible
tag sequences when no dictionary is used; when a
dictionary is used it will consist of all dictionary-
pruned tag sequences (sans Step 3 above; the full set
of possibilities shown in Figure 1 for our running
example).
Figures 2 and 3 provide statistics regarding the
supervision coverage and remaining ambiguity. Fig-
ure 2 shows that more than two thirds of all tokens in
our training data are in Wiktionary. However, there is
considerable variation between languages: Spanish
has the highest coverage with over 90%, while Turk-
ish, an agglutinative language with a vast number
of word forms, has less than 50% coverage. Fig-
ure 3 shows that there is substantial uncertainty left
after pruning with Wiktionary, since tokens are rarely
fully disambiguated: 1.3 tags per token are allowed
on average for types in Wiktionary.
Figure 2 further shows that high-confidence align-
ments are available for about half of the tokens for
most languages (Japanese is a notable exception with
</bodyText>
<footnote confidence="0.783863">
3Other training methods exist as well, for example, con-
trastive estimation (Smith and Eisner, 2005).
</footnote>
<figureCaption confidence="0.858393625">
avg bg cs da de el es fr it ja nl pt sl sv tr zh
Figure 2: Wiktionary and projection dictionary coverage.
Shown is the percentage of tokens in the target side of the
bitext that are covered by Wiktionary, that have a projected
tag, and that have a projected tag after intersecting the two.
avg bg cs da de el es fr it ja nl pt sl sv tr zh
Figure 3: Average number of licensed tags per token on
the target side of the bitext, for types in Wiktionary.
</figureCaption>
<bodyText confidence="0.999946571428571">
less than 30% of the tokens covered). Intersecting the
Wiktionary tags and the projected tags (Step 2 and 3
above) filters out some of the potentially erroneous
tags, but preserves the majority of the projected tags;
the remaining, presumably more accurate projected
tags cover almost half of all tokens, greatly reducing
the search space that the learner needs to explore.
</bodyText>
<sectionHeader confidence="0.844294" genericHeader="method">
3 Models with Coupled Constraints
</sectionHeader>
<bodyText confidence="0.9997937">
We now formally present how we couple token and
type constraints and how we use these coupled con-
straints to train probabilistic tagging models. Let
x = (x1x2 ... x|x|) E X denote a sentence, where
each token xi E V is an instance of a word type from
the vocabulary V and let y = (y1y2 ... y1x) E Y de-
note a tag sequence, where yi E T is the tag assigned
to token xi and T denotes the set of all possible part-
of-speech tags. We denote the lattice of all admissible
tag sequences for the sentence x by Y(x). This is the
</bodyText>
<figure confidence="0.996048333333333">
Token
coverage
Projected
Projected+Filtered
100
75
50
25
0
Wiktionary
Number of tags per token
0.5
0.0
1.5
1.0
</figure>
<page confidence="0.965378">
4
</page>
<bodyText confidence="0.996041761904762">
inference search space in which the tagger operates.
As we shall see, it is crucial to constrain the size of
this lattice in order to simplify learning when only
incomplete supervision is available.
A tag dictionary maps a word type xj ∈ V to
a set of admissible tags T (xj) ⊆ T. For word
types not in the dictionary we allow the full set of
tags T (while possible, in this paper we do not at-
tempt to distinguish closed-class versus open-class
words). When provided with a tag dictionary, the
lattice of admissible tag sequences for a sentence x
is Y(x) = T (x1) × T (x2) × ... × T (x|x|). When
no tag dictionary is available, we simply have the full
lattice Y(x) = T |x|.
Let y˜ = (˜y1˜y2 ... ˜y|x|) be the projected tags for
the sentence x. Note that {˜yi} = ∅ for tokens without
a projected tag. Next, we define a piecewise operator
_ that couples y˜ and Y(x) with respect to every
sentence index, which results in a token- and type-
constrained lattice. The operator behaves as follows,
coherent with the high level description in §2.3:
</bodyText>
<equation confidence="0.99022325">
�
{˜yi} if ˜yi ∈ T (xi)
T� (xi, ˜yi) = ˜yi _ T (xi) =
T (xi) otherwise.
</equation>
<bodyText confidence="0.98791">
We denote the token- and type-constrained lattice as
</bodyText>
<equation confidence="0.99714">
� � � �
Y(x, ˜y) = T(x1, ˜y1)× T(x2, ˜y2)×...× T(x|x|,˜y|x|).
</equation>
<bodyText confidence="0.999953666666667">
Note that when token-level projections are not used,
the dictionary-pruned lattice and the lattice with cou-
pled constraints are identical, that is Y(x, ˜y) = Y(x).
</bodyText>
<subsectionHeader confidence="0.999678">
3.1 HMMs with Coupled Constraints
</subsectionHeader>
<bodyText confidence="0.999636">
A first-order hidden Markov model (HMM) specifies
the joint distribution of a sentence x ∈ X and a
</bodyText>
<equation confidence="0.97000025">
tag-sequence y ∈ Y(x) as:
pβ(yi  |yi−1)
� olY .
transition
</equation>
<bodyText confidence="0.975848545454545">
We follow the recent trend of using a log-linear
parametrization of the emission and the transition
distributions, instead of a multinomial parametriza-
tion (Chen, 2003). This allows model parameters β
to be shared across categorical events, which has
been shown to give superior performance (Berg-
Kirkpatrick et al., 2010). The categorical emission
and transition events are represented by feature vec-
tors φ(xi, yi) and φ(yi, yi−1). Each element of the
parameter vector β corresponds to a particular fea-
ture; the component log-linear distributions are:
</bodyText>
<equation confidence="0.954881833333333">
pβ(xi |yi) = � i, yi)) ,
x� iEV exp (β�φ(x,
and
exp (βTφ(yi, yi−1))
pβ(yi  |yi−1) = � i, yi−1)) .
y� iET exp (β�φ(y,
</equation>
<bodyText confidence="0.999822166666667">
In maximum-likelihood estimation of the parameters,
we seek to maximize the likelihood of the observed
parts of the data. For this we need the joint marginal
distribution pβ(x,�Y(x, ˜y)) of a sentence x, and its
coupled constraints lattice Y(x, ˜y), which is obtained
by marginalizing over all consistent outputs:
</bodyText>
<equation confidence="0.992822">
pβ(x, �Y(x, ˜y)) = � pβ(x, y) .
yE�Y(x,˜y)
</equation>
<bodyText confidence="0.974679">
If there are no projections and no tag dictionary, then
Y(x, ˜y) = T |x|, and thus pβ(x, Y(x, ˜y)) = pβ(x),
which reduces to fully unsupervised learning. The
`2-regularized marginal joint log-likelihood of the
constrained training data D = {(x(i), ˜y(i))}ni=1 is:
</bodyText>
<equation confidence="0.97833325">
n
L(β; D) = log pβ(x(i), Y(x(i), ˜y(i)))−γ kβk22 .
i=1
(1)
</equation>
<bodyText confidence="0.998408133333333">
We follow Berg-Kirkpatrick et al. (2010) and take a
direct gradient approach for optimizing Eq. 1 with
L-BFGS (Liu and Nocedal, 1989). We set γ = 1 and
run 100 iterations of L-BFGS. One could also em-
ploy the Expectation-Maximization (EM) algorithm
(Dempster et al., 1977) to optimize this objective, al-
though the relative merits of EM versus direct gradi-
ent training for these models is still a topic of debate
(Berg-Kirkpatrick et al., 2010; Li et al., 2012).4 Note
that since the marginal likelihood is non-concave, we
are only guaranteed to find a local maximum of Eq. 1.
After estimating the model parameters β, the tag-
sequence y* ∈ Y(x) for a sentence x ∈ X is pre-
dicted by choosing the one with maximal joint prob-
ability:
</bodyText>
<equation confidence="0.9549845">
y* ← arg max pβ(x, y) .
yEY(x)
</equation>
<footnote confidence="0.987328">
4We trained the HMM with EM as well, but achieved better
results with direct gradient training and hence omit those results.
</footnote>
<table confidence="0.91245225">
pβ(x, y) = � |x |pβ(xi  |yi)
i=1 � I..&apos; ol
emission
exp (βTφ(xi, yi))
</table>
<page confidence="0.823831">
5
</page>
<subsectionHeader confidence="0.823109">
3.2 CRFs with Coupled Constraints
</subsectionHeader>
<bodyText confidence="0.989325">
Whereas an HMM models the joint probability of
the input x E X and output y E Y(x), using locally
normalized component distributions, a conditional
random field (CRF) instead models the probability of
the output conditioned on the input as a globally nor-
malized log-linear distribution (Lafferty et al., 2001):
</bodyText>
<equation confidence="0.973638">
exp (θTq&apos;(x,y))
pθ(y  |x) = Ey,EY(x) exp (θTq&apos;(x, y&apos;)) ,
</equation>
<bodyText confidence="0.999415">
where θ is a parameter vector. As for the HMM,
Y(x) is not necessarily the full space of possible
tag-sequences; specifically, for us, it is the dictionary-
pruned lattice without the token constraints.
With a first-order Markov assumption, the feature
function factors as:
</bodyText>
<equation confidence="0.998911">
q&apos;(x, y) = � |x |φ(x, yi, yi−1) .
i=1
</equation>
<bodyText confidence="0.9994955">
This model is more powerful than the HMM in that
it can use richer feature definitions, such as joint in-
put/transition features and features over a wider input
context. We model a marginal conditional probabil-
ity, given by the total probability of all tag sequences
consistent with the lattice �Y(x, ˜y):
</bodyText>
<equation confidence="0.992551333333333">
pθ( � pθ(y  |x) .
Y(x, ˜y)  |x) =
yE�Y(x,˜y)
</equation>
<bodyText confidence="0.99880875">
The parameters of this constrained CRF are estimated
by maximizing the `2-regularized marginal condi-
tional log-likelihood of the constrained data (Riezler
et al., 2002):
</bodyText>
<equation confidence="0.9933905">
L(θ; D) = n log pθ( y(x(i), ˜y(i))  |x(i)) − γ11θ1122 .
i=1
</equation>
<bodyText confidence="0.979047714285714">
(2)
As with Eq. 1, we maximize Eq. 2 with 100 itera-
tions of L-BFGS and set γ = 1. In contrast to the
HMM, after estimating the model parameters θ, the
tag-sequence y* E Y(x) for a sentence x E X is
chosen as the sequence with the maximal conditional
probability:
</bodyText>
<equation confidence="0.6433655">
y* +- arg max pθ(y  |x) .
yEY(x)
</equation>
<sectionHeader confidence="0.993049" genericHeader="method">
4 Empirical Study
</sectionHeader>
<bodyText confidence="0.999939142857143">
We now present a detailed empirical study of the mod-
els proposed in the previous sections. In addition to
comparing with the state of the art in Das and Petrov
(2011) and Li et al. (2012), we present models with
several combinations of token and type constraints,
additional features incorporating word clusters. Both
generative and discriminative models are explored.
</bodyText>
<subsectionHeader confidence="0.968736">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999967382352941">
Before delving into the experimental details, we
present our setup and datasets.
Languages. We evaluate on eight target languages
used in previous work (Das and Petrov, 2011; Li et
al., 2012) and on seven additional languages (see Ta-
ble 1). While the former eight languages all belong to
the Indo-European family, we broaden the coverage
to language families more distant from the source
language (for example, Chinese, Japanese and Turk-
ish). We use the treebanks from the CoNLL shared
tasks on dependency parsing (Buchholz and Marsi,
2006; Nivre et al., 2007) for evaluation.5 The two-
letter abbreviations from the ISO 639-1 standard are
used when referring to these languages in tables and
figures.
Tagset. In all cases, we map the language-specific
POS tags to universal POS tags using the mapping
of Petrov et al. (2012).6 Since we use indirect super-
vision via projected tags or Wiktionary, the model
states induced by all models correspond directly to
POS tags, enabling us to compute tagging accuracy
without a greedy 1-to-1 or many-to-1 mapping.
Bitext. For all experiments, we use English as the
source language. Depending on availability, there
are between 1M and 5M parallel sentences for each
language. The majority of the parallel data is gath-
ered automatically from the web using the method
of Uszkoreit et al. (2010). We further include data
from Europarl (Koehn, 2005) and from the UN par-
allel corpus (UN, 2006), for languages covered by
these corpora. The English side of the bitext is
POS tagged with a standard supervised CRF tagger,
trained on the Penn Treebank (Marcus et al., 1993),
with tags mapped to universal tags. The parallel sen-
</bodyText>
<footnote confidence="0.993052333333333">
5For French we use the treebank of Abeill´e et al. (2003).
6We use version 1.03 of the mappings available at http:
//code.google.com/p/universal-pos-tags/.
</footnote>
<page confidence="0.999017">
6
</page>
<bodyText confidence="0.99997775862069">
tences are word aligned with the aligner of DeNero
and Macherey (2011). Intersected high-confidence
alignments (confidence &gt;0.95) are extracted and ag-
gregated into projected type-level dictionaries. For
purely practical reasons, the training data with token-
level projections is created by randomly sampling
target-side sentences with a total of 500K tokens.
Wiktionary. We use a snapshot of the Wiktionary
word definitions, and follow the heuristics of Li et
al. (2012) for creating the Wiktionary dictionary by
mapping the Wiktionary tags to universal POS tags.7
Features. For all models, we use only an identity
feature for tag-pair transitions. We use five features
that couple the current tag and the observed word
(analogous to the emission in an HMM): word iden-
tity, suffixes of up to length 3, and three indicator
features that fire when the word starts with a capital
letter, contains a hyphen or contains a digit. These are
the same features as those used by Das and Petrov
(2011). Finally, for some models we add a word
cluster feature that couples the current tag and the
word cluster identity of the word. These (monolin-
gual) word clusters are induced with the exchange
algorithm (Uszkoreit and Brants, 2008). We set the
number of clusters to 256 across all languages, as this
has previously been shown to produce robust results
for similar tasks (Turian et al., 2010; T¨ackstr¨om et
al., 2012). The clusters for each language are learned
on a large monolingual newswire corpus.
</bodyText>
<subsectionHeader confidence="0.998973">
4.2 Models with Type Constraints
</subsectionHeader>
<bodyText confidence="0.999887928571429">
To examine the sole effect of type constraints, we
experiment with the HMM, drawing constraints from
three different dictionaries. Table 1 compares the per-
formance of our models with the best results of Das
and Petrov (2011, D&amp;P) and Li et al. (2012, LG&amp;T).
As in previous work, training is done exclusively on
the training portion of each treebank, stripped of any
manual linguistic annotation.
We first use all of our parallel data to generate
projected tag dictionaries: the English POS tags are
projected across word alignments and aggregated to
tag distributions for each word type. As in Das and
Petrov (2011), the distributions are then filtered with
a threshold of 0.2 to remove noisy tags and to create
</bodyText>
<footnote confidence="0.983031333333333">
7The definitions were downloaded on August 31, 2012 from
http://toolserver.org/˜enwikt/definitions/.
This snapshot is more recent than that used by Li et al.
</footnote>
<table confidence="0.999766761904762">
Lang. Prior work HMM with type constraints
D&amp;P LG&amp;T YHMM proj. YHMM YHMM
wik. union YHMM
union +C
bg – – 84.2 68.1 87.2 87.9
cs – – 75.4 70.2 75.4 79.2
da 83.2 83.3 87.7 82.0 78.4 89.5
de 82.8 85.8 86.6 85.1 80.0 88.3
el 82.5 79.2 83.3 83.8 86.0 83.2
es 84.2 86.4 83.9 83.7 88.3 87.3
fr – – 88.4 75.7 75.6 86.6
it 86.8 86.5 89.0 85.4 89.9 90.6
ja – – 45.2 76.9 74.4 73.7
nl 79.5 86.3 81.7 79.1 83.8 82.7
pt 87.9 84.5 86.7 79.0 83.8 90.4
sl – – 78.7 64.8 82.8 83.4
sv 80.5 86.1 80.6 85.9 85.9 86.7
tr – – 66.2 44.1 65.1 65.7
zh – – 59.2 73.9 63.2 73.0
avg (8) 83.4 84.8 84.9 83.0 84.5 87.3
avg – – 78.5 75.9 80.0 83.2
</table>
<tableCaption confidence="0.8150905">
Table 1: Tagging accuracies for type-constrained HMM
models. D&amp;P is the “With LP” model in Table 2 of
Das and Petrov (2011), while LG&amp;T is the “SHMM-ME”
model in Table 2 of Li et al. (2012). YHMM
</tableCaption>
<figure confidence="0.829157666666667">
proj. , YHMM
wik. and
YHMM
</figure>
<figureCaption confidence="0.9563456">
union are HMMs trained solely with type constraints
derived from the projected dictionary, Wiktionary and
the union of these dictionaries, respectively. YHMM
union +C is
equivalent to YHMM
</figureCaption>
<bodyText confidence="0.878746409090909">
union with additional cluster features. All
models are trained on the treebank of each language,
stripped of gold labels. Results are averaged over the
8 languages from Das and Petrov (2011), denoted avg (8),
as well as over the full set of 15 languages, denoted avg.
an unweighted tag dictionary. We call this model
YHMM; its average accuracy of 84.9% on the eight
proj.
languages is higher than the 83.4% of D&amp;P and on
par with LG&amp;T (84.8%).8 Our next model (YHMM
wik. )
simply draws type constraints from Wiktionary. It
slightly underperforms LG&amp;T (83.0%), presumably
because they used a second-order HMM. As a simple
extension to these two models, we take the union
of the projected dictionary and Wiktionary to con-
strain an HMM, which we name YHMM
union . This model
performs a little worse on the eight Indo-European
languages (84.5), but gives an improvement over the
projected dictionary when evaluated across all 15
languages (80.0% vs. 78.5%).
</bodyText>
<footnote confidence="0.986135">
8Our model corresponds to the weaker, “No LP” projection
of Das and Petrov (2011). We found that label propagation was
only beneficial when small amounts of bitext were available.
</footnote>
<page confidence="0.999355">
7
</page>
<table confidence="0.99990392">
Lang. YHMM Token constraints HMM with coupled constraints CRF with coupled constraints
union +C+L
˜yHMM+C+L ˜yCRF+C+L �YHMM
wik. +C+L �YHMM
union +C+L �YCRF proj. +C+L �YCRF
proj. +C+L �YHMM
wik. +C+L �YCRF
union+C+L
bg 87.7 77.9 84.1 84.5 83.9 86.7 86.0 87.8 85.4
cs 78.3 65.4 74.9 74.8 81.1 76.9 74.7 80.3** 75.0
da 87.3 80.9 85.1 87.2 85.6 88.1 85.5 88.2* 86.0
de 87.7 81.4 83.3 85.0 89.3 86.7 84.4 90.5** 85.5
el 85.9 81.1 77.8 80.1 87.0 83.9 79.6 89.5** 79.7
es 89.1** 84.1 85.5 83.7 85.9 88.0 85.7 87.1 86.0
fr 88.4** 83.5 84.7 85.9 86.4 87.4 84.9 87.2 85.6
it 89.6 85.2 88.5 88.7 87.6 89.8 88.3 89.3 89.4
ja 72.8 47.6 54.2 43.2 76.1 70.5 44.9 81.0** 68.0
nl 83.1 78.4 82.4 82.3 84.2 83.2 83.1 85.9** 83.2
pt 89.1 84.7 87.0 86.6 88.7 88.0 87.9 91.0** 88.3
sl 82.4 69.8 78.2 78.5 81.8 80.1 79.7 82.3 80.0
sv 86.1 80.1 84.2 82.3 87.9 86.9 84.4 88.9** 85.5
tr 62.4 58.1 64.5 64.6 61.8 64.8 65.0 64.1** 65.2
zh 72.6 52.7 39.5 56.0 74.1 73.3 59.7 74.4** 73.4
avg (8) 87.2 82.0 84.2 84.5 87.0 86.8 84.9 88.8 85.4
avg 82.8 74.1 76.9 77.6 82.8 82.3 78.2 84.5 81.1
</table>
<tableCaption confidence="0.881971666666667">
Table 2: Tagging accuracies for models with token constraints and coupled token and type constraints. All models use
cluster features (... +C) and are trained on large training sets each containing 500k tokens with (partial) token-level
projections (... +L). The best type-constrained model, trained on the larger datasets, YHMM
</tableCaption>
<bodyText confidence="0.872807896551724">
union +C+L, is included for
comparison. The remaining columns correspond to HMM and CRF models trained only with token constraints (˜y ...)
and with coupled token and type constraints (Y ...). The latter are trained using the projected dictionary (·proj.),
Wiktionary (·wik.) and the union of these dictionaries (·union), respectively. The search spaces of the models trained with
coupled constraints (Y ...) are each pruned with the respective tag dictionary used to derive the coupled constraints.
The observed difference between �YCRF
wik. +C+L and YHMM
union +C+L is statistically significant at p &lt; 0.01 (**) and p &lt; 0.015
(*) according to a paired bootstrap test (Efron and Tibshirani, 1993). Significance was not assessed for avg or avg (8).
We next add monolingual cluster features to
the model with the union dictionary. This model,
YHMM+C, significantly outperforms all other type-
union
constrained models, demonstrating the utility of
word-cluster features.9 For further exploration, we
train the same model on the datasets containing 500K
tokens sampled from the target side of the parallel
data (YHMM
union +C+L); this is done to explore the effects
of large data during training. We find that training
on these datasets result in an average accuracy of
87.2% which is comparable to the 87.3% reported
for YHMM
union +C in Table 1. This shows that the different
source domain and amount of training data does not
influence the performance of the HMM significantly.
Finally, we train CRF models where we treat type
constraints as a partially observed lattice and use the
full unpruned lattice for computing the partition func-
</bodyText>
<footnote confidence="0.5318155">
9These are monolingual clusters. Bilingual clusters as intro-
duced in T¨ackstr¨om et al. (2012) might bring additional benefits.
</footnote>
<bodyText confidence="0.9999334">
tion (§3.2). Due to space considerations, the results
of these experiments are not shown in table 1. We ob-
serve similar trends in these results, but on average,
accuracies are much lower compared to the type-
constrained HMM models; the CRF model with the
union dictionary along with cluster features achieves
an average accuracy of 79.3% when trained on same
data. This result is not unsurprising. First, the CRF’s
search space is fully unconstrained. Second, the dic-
tionary only provides a weak set of observation con-
straints, which do not provide sufficient information
to successfully train a discriminative model. How-
ever, as we will observe next, coupling the dictionary
constraints with token-level information solves this
problem.
</bodyText>
<subsectionHeader confidence="0.999982">
4.3 Models with Token and Type Constraints
</subsectionHeader>
<bodyText confidence="0.999313">
We now proceed to add token-level information,
focusing in particular on coupled token and type
</bodyText>
<page confidence="0.995265">
8
</page>
<bodyText confidence="0.987218549019608">
constraints. Since it is not possible to generate
projected token constraints for our monolingual
treebanks, we train all models in this subsection
on the 500K-tokens datasets sampled from the bi-
text. As a baseline, we first train HMM and CRF
models that use only projected token constraints
(˜yHMM+C+L and ˜yCRF+C+L). As shown in Table 2,
these models underperform the best type-level model
(YHMM
union +C+L),10 which confirms that projected to-
ken constraints are not reliable on their own. This
is in line with similar projection models previously
examined by Das and Petrov (2011).
We then study models with coupled token and type
constraints. These models use the same three dictio-
naries as used in §4.2, but additionally couple the
derived type constraints with projected token con-
straints; see the caption of Table 2 for a list of these
models. Note that since we only allow projected tags
that are licensed by the dictionary (Step 3 of the trans-
fer, §2.3), the actual token constraints used in these
models vary with the different dictionaries.
From Table 2, we see that coupled constraints are
superior to token constraints, when used both with
the HMM and the CRF. However, for the HMM, cou-
pled constraints do not provide any benefit over type
constraints alone, in particular when the projected
dictionary or the union dictionary is used to derive the
coupled constraints ( _YHMM
proj. +C+L and _YHMM
union +C+L).
We hypothesize that this is because these dictionar-
ies (in particular the former) have the same bias as
the token-level tag projections, so that the dictionary
is unable to correct the systematic errors in the pro-
jections (see §2.1). Since the token constraints are
stronger than the type constraints in the coupled mod-
els, this bias may have a substantial impact. With
the Wiktionary dictionary, the difference between the
type-constrained and the coupled-constrained HMM
is negligible: YHMM
union +C+L and �M+C+L both av-
y
erage at an accuracy of 82.8%.
The CRF model, on the other hand, is able to take
advantage of the complementary information in the
coupled constraints, provided that the dictionary is
able to filter out the systematic token-level errors.
With a dictionary derived from _Wiktionary and pro-
jected token-level constraints, YCRF
wik. +C+L performs
</bodyText>
<footnote confidence="0.972543">
10To make the comparison fair vis-a-vis potential divergences
in training domains, we compare to the best type-constrained
model trained on the same 500K tokens training sets.
</footnote>
<note confidence="0.457894">
Number of tags listed in Wiktionary
</note>
<figure confidence="0.807331857142857">
100
Tagging accuracy 75
50
25
0
0 1 10 100 0 1 10 100 0 1 10 100 0 1 10 100
Number of token−level projections
</figure>
<figureCaption confidence="0.942826571428571">
Figure 4: Relative influence of token and type constraints
on tagging accuracy in the _YCRF wik.+C+L model. Word types
are categorized according to a) their number of Wiktionary
tags (0,1,2 or 3+ tags, with 0 representing no Wiktionary
entry; top-axis) and b) the number of times they are token-
constrained in the training set (divided into buckets of
0, 1-9, 10-99 and 100+ occurrences; x-axis). The boxes
</figureCaption>
<bodyText confidence="0.8034803">
summarize the accuracy distributions across languages
for each word type category as defined by a) and b). The
horizontal line in each box marks the median accuracy,
the top and bottom mark the first and third quantile, re-
spectively, while the whiskers mark the minimum and
maximum values of the accuracy distribution.
better than all the remaining models, with an average
accuracy of 88.8% across the eight Indo-European
languages available to D&amp;P and LG&amp;T. Averaged
over all 15 languages, its accuracy is 84.5%.
</bodyText>
<sectionHeader confidence="0.998202" genericHeader="method">
5 Further Analysis
</sectionHeader>
<bodyText confidence="0.9999628">
In this section we provide a detailed analysis of the
impact of token versus type constraints and we study
the pruning and filtering mistakes resulting from in-
complete Wiktionary entries in detail. This analysis
is based on the training portion of each treebank.
</bodyText>
<subsectionHeader confidence="0.994948">
5.1 Influence of Token and Type Constraints
</subsectionHeader>
<bodyText confidence="0.999726888888889">
The empirical success of the model trained with cou-
pled token and type constraints confirms that these
constraints indeed provide complementary signals.
Figure 4 provides a more detailed view of the rela-
tive benefits of each type of constraint. We observe
several interesting trends.
First, word types that occur with more token con-
straints during training are generally tagged more
accurately, regardless of whether these types occur
</bodyText>
<figure confidence="0.997583418604651">
0
1
2
3
9
97.5
Pruning accuracy
95.0
92.5
90.0
0 50 100 150 200 250
Number of corrected Wiktionary entries
0 25 50 75 100
Proportion of pruning errors
100.0
avg
da
de
bg
cs
es
sv
ja
pt
el
nl
sl
fr
tr
it
PRON
NOUN
DET
ADP
PRT
ADV
NUM
CONJ
ADJ
VERB
X
zh
.
</figure>
<figureCaption confidence="0.986252285714286">
Figure 5: Average pruning accuracy (line) across lan-
guages (dots) as a function of the number of hypotheti-
cally corrected Wiktionary entries for the k most frequent
word types. For example, position 100 on the x-axis cor-
responds to manually correcting the entries for the 100
most frequent types, while position 0 corresponds to ex-
perimental conditions.
</figureCaption>
<bodyText confidence="0.999333222222222">
in Wiktionary. The most common scenario is for a
word type to have exactly one tag in Wiktionary and
to occur with this projected tag over 100 times in
the training set (facet 1, rightmost box). These com-
mon word types are typically tagged very accurately
across all languages.
Second, the word types that are ambiguous accord-
ing to Wiktionary (facets 2 and 3) are predominantly
frequent ones. The accuracy is typically lower for
these words compared to the unambiguous words.
However, as the number of projected token con-
straints is increased from zero to 100+ observations,
the ambiguous words are effectively disambiguated
by the token constraints. This shows the advantage
of intersecting token and type constraints.
Finally, projection generally helps for words that
are not in Wiktionary, although the accuracy for these
words never reach the accuracy of the words with
only one tag in Wiktionary. Interestingly, words that
occur with a projected tag constraint less than 100
times are tagged more accurately for types not in the
dictionary compared to ambiguous word types with
the same number of projected constraints. A possible
explanation for this is that the ambiguous words are
inherently more difficult to predict and that most of
the words that are not in Wiktionary are less common
words that tend to also be less ambiguous.
</bodyText>
<figureCaption confidence="0.9734215">
Figure 6: Prevalence of pruning mistakes per POS tag,
when pruning the inference search space with Wiktionary.
</figureCaption>
<subsectionHeader confidence="0.994647">
5.2 Wiktionary Pruning Mistakes
</subsectionHeader>
<bodyText confidence="0.999902516129032">
The error analysis by Li et al. (2012) showed that the
tags licensed by Wiktionary are often valid. When
using Wiktionary to prune the search space of our
constrained models and to filter token-level projec-
tions, it is also important that correct tags are not
mistakenly pruned because they are missing from
Wiktionary. While the accuracy of filtering is more
difficult to study, due to the lack of a gold standard
tagging of the bitext, Figure 5 (position 0 on the x-
axis) shows that search space pruning errors are not
a major issue for most languages; on average the
pruning accuracy is almost 95%. However, for some
languages such as Chinese and Czech the correct tag
is pruned from the search space for nearly 10% of all
tokens. When using Wiktionary as a pruner, the upper
bound on accuracy for these languages is therefore
only around 90%. However, Figure 5 also shows that
with some manual effort we might be able to remedy
many of these errors. For example, by adding miss-
ing valid tags to the 250 most common word types in
the worst language, the minimum pruning accuracy
would rise above 95% from below 90%. If the same
was to be done for all of the studied languages, the
mean pruning accuracy would reach over 97%.
Figure 6 breaks down pruning errors resulting from
incorrect or incomplete Wiktionary entries across
the correct POS tags. From this we observe that,
for many languages, the pruning errors are highly
skewed towards specific tags. For example, for Czech
over 80% of the pruning errors are caused by mistak-
enly pruned pronouns.
</bodyText>
<page confidence="0.998043">
10
</page>
<sectionHeader confidence="0.999672" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999986823529412">
We considered the problem of constructing multilin-
gual POS taggers for resource-poor languages. To
this end, we explored a number of different models
that combine token constraints with type constraints
from different sources. The best results were ob-
tained with a partially observed CRF model that ef-
fectively integrates these complementary constraints.
In an extensive empirical study, we showed that this
approach substantially improves on the state of the
art in this context. Our best model significantly out-
performed the second-best model on 10 out of 15
evaluated languages, when trained on identical data
sets, with an insignificant difference on 3 languages.
Compared to the prior state of the art (Li et al., 2012),
we observed a relative reduction in error by 25%,
averaged over the eight languages common to our
studies.
</bodyText>
<sectionHeader confidence="0.999074" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999573">
We thank Alexander Rush for help with the hyper-
graph framework that was used to implement our
models and Klaus Macherey for help with the bi-
text extraction. This work benefited from many dis-
cussions with Yoav Goldberg, Keith Hall, Kuzman
Ganchev and Hao Zhang. We also thank the editor
and the three anonymous reviewers for their valuable
feedback. The first author is grateful for the financial
support from the Swedish National Graduate School
of Language Technology (GSLT).
</bodyText>
<sectionHeader confidence="0.99955" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999911871428572">
Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Toussenel.
2003. Building a Treebank for French. In A. Abeill´e,
editor, Treebanks: Building and Using Parsed Corpora,
chapter 10. Kluwer.
Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cˆot´e, John
DeNero, and Dan Klein. 2010. Painless unsupervised
learning with features. In Proceedings of NAACL-HLT.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of CoNLL.
Stanley F Chen. 2003. Conditional and joint models for
grapheme-to-phoneme conversion. In Proceedings of
Eurospeech.
Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsupervised
POS induction: How far have we come? In Proceed-
ings of EMNLP.
Dipanjan Das and Slav Petrov. 2011. Unsupervised part-
of-speech tagging with bilingual graph-based projec-
tions. In Proceedings of ACL-HLT.
Arthur P. Dempster, Nan M. Laird, and Donald B. Rubin.
1977. Maximum likelihood from incomplete data via
the EM algorithm. Journal of the Royal Statistical
Society, Series B, 39.
John DeNero and Klaus Macherey. 2011. Model-based
aligner combination using dual decomposition. In Pro-
ceedings of ACL-HLT.
Brad Efron and Robert J. Tibshirani. 1993. An Introduc-
tion to the Bootstrap. Chapman &amp; Hall, New York, NY,
USA.
Victoria Fossum and Steven Abney. 2005. Automatically
inducing a part-of-speech tagger by projecting from
multiple source languages across aligned corpora. In
Proceedings of IJCNLP.
Dan Garrette and Jason Baldridge. 2012. Type-supervised
hidden markov models for part-of-speech tagging with
incomplete tag dictionaries. In Proceedings of EMNLP-
CoNLL.
Yoav Goldberg, Meni Adler, and Michael Elhadad. 2008.
EM can find pretty good HMM POS-taggers (when
given a good start). In Proceedings of ACL-HLT.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT Summit.
John D. Lafferty, Andrew McCallum, and Fernando C. N.
Pereira. 2001. Conditional random fields: Probabilistic
models for segmenting and labeling sequence data. In
Proceedings of ICML.
Shen Li, Jo˜ao Grac¸a, and Ben Taskar. 2012. Wiki-ly
supervised part-of-speech tagging. In Proceedings of
EMNLP-CoNLL.
Dong C. Liu and Jorge Nocedal. 1989. On the limited
memory BFGS method for large scale optimization.
Mathematical Programming, 45.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beat-
rice Santorini. 1993. Building a large annotated corpus
of English: the Penn treebank. Computational Linguis-
tics, 19(2).
Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, and
Regina Barzilay. 2009. Multilingual part-of-speech
tagging: Two unsupervised approaches. JAIR, 36.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDon-
ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007. The CoNLL 2007 shared task on dependency
parsing. In Proceedings of EMNLP-CoNLL.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceedings of
LREC.
Sujith Ravi and Kevin Knight. 2009. Minimized models
for unsupervised part-of-speech tagging. In Proceed-
ings of ACL-IJCNLP.
</reference>
<page confidence="0.989826">
11
</page>
<reference confidence="0.999431533333333">
Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard
Crouch, John T. Maxwell, III, and Mark Johnson. 2002.
Parsing the wall street journal using a lexical-functional
grammar and discriminative estimation techniques. In
Proceedings of ACL.
Noah Smith and Jason Eisner. 2005. Contrastive estima-
tion: Training log-linear models on unlabeled data. In
Proceedings of ACL.
Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit.
2012. Cross-lingual word clusters for direct transfer of
linguistic structure. In Proceedings of NAACL-HLT.
Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
2010. Word representations: A simple and general
method for semi-supervised learning. In Proceedings
of ACL.
UN. 2006. ODS UN parallel corpus.
Jakob Uszkoreit and Thorsten Brants. 2008. Distributed
word clustering for large scale class-based language
modeling in machine translation. In Proceedings of
ACL-HLT.
Jakob Uszkoreit, Jay Ponte, Ashok Popat, and Moshe
Dubiner. 2010. Large scale parallel document mining
for machine translation. In Proceedings of COLING.
Chenhai Xi and Rebecca Hwa. 2005. A backoff model
for bootstrapping resources for non-English languages.
In Proceedings of HLT-EMNLP.
David Yarowsky and Grace Ngai. 2001. Inducing mul-
tilingual POS taggers and NP bracketers via robust
projection across aligned corpora. In Proceedings of
NAACL.
</reference>
<page confidence="0.998427">
12
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.453599">
<title confidence="0.998094">Token and Type Constraints for Cross-Lingual Part-of-Speech Tagging</title>
<author confidence="0.800406">Dipanjan</author>
<affiliation confidence="0.999036">Institute of Computer Science</affiliation>
<address confidence="0.840748">of Linguistics and Philology, Uppsala Research, New York</address>
<email confidence="0.897384">oscar@sics.sejoakim.nivre@lingfil.uu.se</email>
<abstract confidence="0.999821695652174">We consider the construction of part-of-speech taggers for resource-poor languages. Recently, manually constructed tag dictionaries from Wiktionary and dictionaries projected via bitext been used as constraints overcome the scarcity of annotated data in this setting. this paper, we show that additional be projected from a resourcerich source language to a resource-poor target language via word-aligned bitext. We present several models to this end; in particular a partially observed conditional random field model, where coupled token and type constraints provide a partial signal for training. Averaged across eight previously studied Indo-European languages, our model achieves a 25% relative error reduction over the prior state of the art. We further present successful results on seven additional languages from different families, empirically demonstrating the applicability of coupled token and type constraints across a diverse set of languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Lionel Cl´ement</author>
<author>Franc¸ois Toussenel</author>
</authors>
<title>Building a Treebank for French. In</title>
<date>2003</date>
<booktitle>Treebanks: Building and Using Parsed Corpora, chapter 10.</booktitle>
<editor>A. Abeill´e, editor,</editor>
<publisher>Kluwer.</publisher>
<marker>Abeill´e, Cl´ement, Toussenel, 2003</marker>
<rawString>Anne Abeill´e, Lionel Cl´ement, and Franc¸ois Toussenel. 2003. Building a Treebank for French. In A. Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, chapter 10. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Alexandre Bouchard-Cˆot´e</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL-HLT.</booktitle>
<marker>Berg-Kirkpatrick, Bouchard-Cˆot´e, DeNero, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cˆot´e, John DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Proceedings of NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<contexts>
<context position="22750" citStr="Buchholz and Marsi, 2006" startWordPosition="3692" endWordPosition="3695">ters. Both generative and discriminative models are explored. 4.1 Experimental Setup Before delving into the experimental details, we present our setup and datasets. Languages. We evaluate on eight target languages used in previous work (Das and Petrov, 2011; Li et al., 2012) and on seven additional languages (see Table 1). While the former eight languages all belong to the Indo-European family, we broaden the coverage to language families more distant from the source language (for example, Chinese, Japanese and Turkish). We use the treebanks from the CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) for evaluation.5 The twoletter abbreviations from the ISO 639-1 standard are used when referring to these languages in tables and figures. Tagset. In all cases, we map the language-specific POS tags to universal POS tags using the mapping of Petrov et al. (2012).6 Since we use indirect supervision via projected tags or Wiktionary, the model states induced by all models correspond directly to POS tags, enabling us to compute tagging accuracy without a greedy 1-to-1 or many-to-1 mapping. Bitext. For all experiments, we use English as the source language. Depending on availa</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
</authors>
<title>Conditional and joint models for grapheme-to-phoneme conversion.</title>
<date>2003</date>
<booktitle>In Proceedings of Eurospeech.</booktitle>
<contexts>
<context position="18083" citStr="Chen, 2003" startWordPosition="2894" endWordPosition="2895">pe-constrained lattice as � � � � Y(x, ˜y) = T(x1, ˜y1)× T(x2, ˜y2)×...× T(x|x|,˜y|x|). Note that when token-level projections are not used, the dictionary-pruned lattice and the lattice with coupled constraints are identical, that is Y(x, ˜y) = Y(x). 3.1 HMMs with Coupled Constraints A first-order hidden Markov model (HMM) specifies the joint distribution of a sentence x ∈ X and a tag-sequence y ∈ Y(x) as: pβ(yi |yi−1) � olY . transition We follow the recent trend of using a log-linear parametrization of the emission and the transition distributions, instead of a multinomial parametrization (Chen, 2003). This allows model parameters β to be shared across categorical events, which has been shown to give superior performance (BergKirkpatrick et al., 2010). The categorical emission and transition events are represented by feature vectors φ(xi, yi) and φ(yi, yi−1). Each element of the parameter vector β corresponds to a particular feature; the component log-linear distributions are: pβ(xi |yi) = � i, yi)) , x� iEV exp (β�φ(x, and exp (βTφ(yi, yi−1)) pβ(yi |yi−1) = � i, yi−1)) . y� iET exp (β�φ(y, In maximum-likelihood estimation of the parameters, we seek to maximize the likelihood of the observ</context>
</contexts>
<marker>Chen, 2003</marker>
<rawString>Stanley F Chen. 2003. Conditional and joint models for grapheme-to-phoneme conversion. In Proceedings of Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christos Christodoulopoulos</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Two decades of unsupervised POS induction: How far have we come?</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="2155" citStr="Christodoulopoulos et al., 2010" startWordPosition="297" endWordPosition="300"> al., 2012). Thanks to their efficiency and robustness, supervised taggers are routinely employed in many natural language processing applications, such as syntactic and semantic parsing, named-entity recognition and machine translation. Unfortunately, the resources required to train supervised taggers are expensive to create and unlikely to exist for the majority of written ∗ Work primarily carried out while at Google Research. languages. The necessity of building NLP tools for these resource-poor languages has been part of the motivation for research on unsupervised learning of POS taggers (Christodoulopoulos et al., 2010). In this paper, we instead take a weakly supervised approach towards this problem. Recently, learning POS taggers with type-level tag dictionary constraints has gained popularity. Tag dictionaries, noisily projected via word-aligned bitext, have bridged the gap between purely unsupervised and fully supervised taggers, resulting in an average accuracy of over 83% on a benchmark of eight Indo-European languages (Das and Petrov, 2011). Li et al. (2012) further improved upon this result by employing Wiktionary1 as a tag dictionary source, resulting in the hitherto best published result of almost </context>
</contexts>
<marker>Christodoulopoulos, Goldwater, Steedman, 2010</marker>
<rawString>Christos Christodoulopoulos, Sharon Goldwater, and Mark Steedman. 2010. Two decades of unsupervised POS induction: How far have we come? In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised partof-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="2591" citStr="Das and Petrov, 2011" startWordPosition="360" endWordPosition="363"> necessity of building NLP tools for these resource-poor languages has been part of the motivation for research on unsupervised learning of POS taggers (Christodoulopoulos et al., 2010). In this paper, we instead take a weakly supervised approach towards this problem. Recently, learning POS taggers with type-level tag dictionary constraints has gained popularity. Tag dictionaries, noisily projected via word-aligned bitext, have bridged the gap between purely unsupervised and fully supervised taggers, resulting in an average accuracy of over 83% on a benchmark of eight Indo-European languages (Das and Petrov, 2011). Li et al. (2012) further improved upon this result by employing Wiktionary1 as a tag dictionary source, resulting in the hitherto best published result of almost 85% on the same setup. Although the aforementioned weakly supervised approaches have resulted in significant improvements over fully unsupervised approaches, they have not exploited the benefits of token-level cross-lingual projection methods, which are possible with wordaligned bitext between a target language of interest and a resource-rich source language, such as English. This is the setting we consider in this paper (§2). While</context>
<context position="5309" citStr="Das and Petrov (2011)" startWordPosition="761" endWordPosition="764">o standard (contextual) lexical features and transition features, we observe that adding features from a monolingual word clustering (Uszkoreit and Brants, 2008) can significantly improve accuracy. While most of these features can also be used in a generative feature-based hidden Markov model (HMM) (Berg-Kirkpatrick et al., 2010), we achieve the best accuracy with a globally normalized discriminative CRF model. To evaluate our approach, we present extensive results on standard publicly available datasets for 15 languages: the eight Indo-European languages previously studied in this context by Das and Petrov (2011) and Li et al. (2012), and seven additional languages from different families, for which no comparable study exists. In §4 we compare various features, constraints and model types. Our best model uses type constraints derived from Wiktionary, together with token constraints derived from high-confidence word alignments. When averaged across the eight languages studied by Das and Petrov (2011) and Li et al. (2012), we achieve an accuracy of 88.8%. This is a 25% relative error reduction over the previous state of the art. Averaged across all 15 languages, our model obtains an accuracy of 84.5% co</context>
<context position="9518" citStr="Das and Petrov (2011)" startWordPosition="1433" endWordPosition="1436">ary type constraints. The correct parts of speech are listed underneath each word. Bold nodes show projected token constraints ˜y. Underlined text indicates incorrect tags. The coupled constraints lattice y(x, ˜y) consists of the bold nodes together with nodes for words that are lacking token constraints; in this case, the coupled constraints lattice thus defines exactly one valid path. Start ADP ADJ VERB X NOUN NOUN VERB VERB ADJ CONJ VERB NOUN ADV VERB PRON NOUN P StoP inflected forms – both of which are difficult to obtain and unrealistic to expect for resource-poor languages. In contrast, Das and Petrov (2011) automatically create type-level tag dictionaries by aggregating over projected token-level information extracted from bitext. To handle the noise in these automatic dictionaries, they use label propagation on a similarity graph to smooth (and also expand) the label distributions. While their approach produces good results and is applicable to resource-poor languages, it requires a complex multi-stage training procedure including the construction of a large distributional similarity graph. Recently, Li et al. (2012) presented a simple and viable alternative: crowdsourced dictionaries from Wikt</context>
<context position="21985" citStr="Das and Petrov (2011)" startWordPosition="3574" endWordPosition="3577">arginal conditional log-likelihood of the constrained data (Riezler et al., 2002): L(θ; D) = n log pθ( y(x(i), ˜y(i)) |x(i)) − γ11θ1122 . i=1 (2) As with Eq. 1, we maximize Eq. 2 with 100 iterations of L-BFGS and set γ = 1. In contrast to the HMM, after estimating the model parameters θ, the tag-sequence y* E Y(x) for a sentence x E X is chosen as the sequence with the maximal conditional probability: y* +- arg max pθ(y |x) . yEY(x) 4 Empirical Study We now present a detailed empirical study of the models proposed in the previous sections. In addition to comparing with the state of the art in Das and Petrov (2011) and Li et al. (2012), we present models with several combinations of token and type constraints, additional features incorporating word clusters. Both generative and discriminative models are explored. 4.1 Experimental Setup Before delving into the experimental details, we present our setup and datasets. Languages. We evaluate on eight target languages used in previous work (Das and Petrov, 2011; Li et al., 2012) and on seven additional languages (see Table 1). While the former eight languages all belong to the Indo-European family, we broaden the coverage to language families more distant fr</context>
<context position="25013" citStr="Das and Petrov (2011)" startWordPosition="4060" endWordPosition="4063">. We use a snapshot of the Wiktionary word definitions, and follow the heuristics of Li et al. (2012) for creating the Wiktionary dictionary by mapping the Wiktionary tags to universal POS tags.7 Features. For all models, we use only an identity feature for tag-pair transitions. We use five features that couple the current tag and the observed word (analogous to the emission in an HMM): word identity, suffixes of up to length 3, and three indicator features that fire when the word starts with a capital letter, contains a hyphen or contains a digit. These are the same features as those used by Das and Petrov (2011). Finally, for some models we add a word cluster feature that couples the current tag and the word cluster identity of the word. These (monolingual) word clusters are induced with the exchange algorithm (Uszkoreit and Brants, 2008). We set the number of clusters to 256 across all languages, as this has previously been shown to produce robust results for similar tasks (Turian et al., 2010; T¨ackstr¨om et al., 2012). The clusters for each language are learned on a large monolingual newswire corpus. 4.2 Models with Type Constraints To examine the sole effect of type constraints, we experiment wit</context>
<context position="27158" citStr="Das and Petrov (2011)" startWordPosition="4449" endWordPosition="4452"> 87.9 cs – – 75.4 70.2 75.4 79.2 da 83.2 83.3 87.7 82.0 78.4 89.5 de 82.8 85.8 86.6 85.1 80.0 88.3 el 82.5 79.2 83.3 83.8 86.0 83.2 es 84.2 86.4 83.9 83.7 88.3 87.3 fr – – 88.4 75.7 75.6 86.6 it 86.8 86.5 89.0 85.4 89.9 90.6 ja – – 45.2 76.9 74.4 73.7 nl 79.5 86.3 81.7 79.1 83.8 82.7 pt 87.9 84.5 86.7 79.0 83.8 90.4 sl – – 78.7 64.8 82.8 83.4 sv 80.5 86.1 80.6 85.9 85.9 86.7 tr – – 66.2 44.1 65.1 65.7 zh – – 59.2 73.9 63.2 73.0 avg (8) 83.4 84.8 84.9 83.0 84.5 87.3 avg – – 78.5 75.9 80.0 83.2 Table 1: Tagging accuracies for type-constrained HMM models. D&amp;P is the “With LP” model in Table 2 of Das and Petrov (2011), while LG&amp;T is the “SHMM-ME” model in Table 2 of Li et al. (2012). YHMM proj. , YHMM wik. and YHMM union are HMMs trained solely with type constraints derived from the projected dictionary, Wiktionary and the union of these dictionaries, respectively. YHMM union +C is equivalent to YHMM union with additional cluster features. All models are trained on the treebank of each language, stripped of gold labels. Results are averaged over the 8 languages from Das and Petrov (2011), denoted avg (8), as well as over the full set of 15 languages, denoted avg. an unweighted tag dictionary. We call this </context>
<context position="28482" citStr="Das and Petrov (2011)" startWordPosition="4672" endWordPosition="4675">and on par with LG&amp;T (84.8%).8 Our next model (YHMM wik. ) simply draws type constraints from Wiktionary. It slightly underperforms LG&amp;T (83.0%), presumably because they used a second-order HMM. As a simple extension to these two models, we take the union of the projected dictionary and Wiktionary to constrain an HMM, which we name YHMM union . This model performs a little worse on the eight Indo-European languages (84.5), but gives an improvement over the projected dictionary when evaluated across all 15 languages (80.0% vs. 78.5%). 8Our model corresponds to the weaker, “No LP” projection of Das and Petrov (2011). We found that label propagation was only beneficial when small amounts of bitext were available. 7 Lang. YHMM Token constraints HMM with coupled constraints CRF with coupled constraints union +C+L ˜yHMM+C+L ˜yCRF+C+L �YHMM wik. +C+L �YHMM union +C+L �YCRF proj. +C+L �YCRF proj. +C+L �YHMM wik. +C+L �YCRF union+C+L bg 87.7 77.9 84.1 84.5 83.9 86.7 86.0 87.8 85.4 cs 78.3 65.4 74.9 74.8 81.1 76.9 74.7 80.3** 75.0 da 87.3 80.9 85.1 87.2 85.6 88.1 85.5 88.2* 86.0 de 87.7 81.4 83.3 85.0 89.3 86.7 84.4 90.5** 85.5 el 85.9 81.1 77.8 80.1 87.0 83.9 79.6 89.5** 79.7 es 89.1** 84.1 85.5 83.7 85.9 88.0 </context>
<context position="33199" citStr="Das and Petrov (2011)" startWordPosition="5453" endWordPosition="5456">articular on coupled token and type 8 constraints. Since it is not possible to generate projected token constraints for our monolingual treebanks, we train all models in this subsection on the 500K-tokens datasets sampled from the bitext. As a baseline, we first train HMM and CRF models that use only projected token constraints (˜yHMM+C+L and ˜yCRF+C+L). As shown in Table 2, these models underperform the best type-level model (YHMM union +C+L),10 which confirms that projected token constraints are not reliable on their own. This is in line with similar projection models previously examined by Das and Petrov (2011). We then study models with coupled token and type constraints. These models use the same three dictionaries as used in §4.2, but additionally couple the derived type constraints with projected token constraints; see the caption of Table 2 for a list of these models. Note that since we only allow projected tags that are licensed by the dictionary (Step 3 of the transfer, §2.3), the actual token constraints used in these models vary with the different dictionaries. From Table 2, we see that coupled constraints are superior to token constraints, when used both with the HMM and the CRF. However, </context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised partof-speech tagging with bilingual graph-based projections. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur P Dempster</author>
<author>Nan M Laird</author>
<author>Donald B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society, Series B,</journal>
<volume>39</volume>
<contexts>
<context position="19534" citStr="Dempster et al., 1977" startWordPosition="3136" endWordPosition="3139">) = � pβ(x, y) . yE�Y(x,˜y) If there are no projections and no tag dictionary, then Y(x, ˜y) = T |x|, and thus pβ(x, Y(x, ˜y)) = pβ(x), which reduces to fully unsupervised learning. The `2-regularized marginal joint log-likelihood of the constrained training data D = {(x(i), ˜y(i))}ni=1 is: n L(β; D) = log pβ(x(i), Y(x(i), ˜y(i)))−γ kβk22 . i=1 (1) We follow Berg-Kirkpatrick et al. (2010) and take a direct gradient approach for optimizing Eq. 1 with L-BFGS (Liu and Nocedal, 1989). We set γ = 1 and run 100 iterations of L-BFGS. One could also employ the Expectation-Maximization (EM) algorithm (Dempster et al., 1977) to optimize this objective, although the relative merits of EM versus direct gradient training for these models is still a topic of debate (Berg-Kirkpatrick et al., 2010; Li et al., 2012).4 Note that since the marginal likelihood is non-concave, we are only guaranteed to find a local maximum of Eq. 1. After estimating the model parameters β, the tagsequence y* ∈ Y(x) for a sentence x ∈ X is predicted by choosing the one with maximal joint probability: y* ← arg max pβ(x, y) . yEY(x) 4We trained the HMM with EM as well, but achieved better results with direct gradient training and hence omit th</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Arthur P. Dempster, Nan M. Laird, and Donald B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B, 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Klaus Macherey</author>
</authors>
<title>Model-based aligner combination using dual decomposition.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="24094" citStr="DeNero and Macherey (2011)" startWordPosition="3913" endWordPosition="3916">d automatically from the web using the method of Uszkoreit et al. (2010). We further include data from Europarl (Koehn, 2005) and from the UN parallel corpus (UN, 2006), for languages covered by these corpora. The English side of the bitext is POS tagged with a standard supervised CRF tagger, trained on the Penn Treebank (Marcus et al., 1993), with tags mapped to universal tags. The parallel sen5For French we use the treebank of Abeill´e et al. (2003). 6We use version 1.03 of the mappings available at http: //code.google.com/p/universal-pos-tags/. 6 tences are word aligned with the aligner of DeNero and Macherey (2011). Intersected high-confidence alignments (confidence &gt;0.95) are extracted and aggregated into projected type-level dictionaries. For purely practical reasons, the training data with tokenlevel projections is created by randomly sampling target-side sentences with a total of 500K tokens. Wiktionary. We use a snapshot of the Wiktionary word definitions, and follow the heuristics of Li et al. (2012) for creating the Wiktionary dictionary by mapping the Wiktionary tags to universal POS tags.7 Features. For all models, we use only an identity feature for tag-pair transitions. We use five features t</context>
</contexts>
<marker>DeNero, Macherey, 2011</marker>
<rawString>John DeNero and Klaus Macherey. 2011. Model-based aligner combination using dual decomposition. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brad Efron</author>
<author>Robert J Tibshirani</author>
</authors>
<title>An Introduction to the Bootstrap.</title>
<date>1993</date>
<publisher>Chapman &amp; Hall,</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="30671" citStr="Efron and Tibshirani, 1993" startWordPosition="5051" endWordPosition="5054">nd to HMM and CRF models trained only with token constraints (˜y ...) and with coupled token and type constraints (Y ...). The latter are trained using the projected dictionary (·proj.), Wiktionary (·wik.) and the union of these dictionaries (·union), respectively. The search spaces of the models trained with coupled constraints (Y ...) are each pruned with the respective tag dictionary used to derive the coupled constraints. The observed difference between �YCRF wik. +C+L and YHMM union +C+L is statistically significant at p &lt; 0.01 (**) and p &lt; 0.015 (*) according to a paired bootstrap test (Efron and Tibshirani, 1993). Significance was not assessed for avg or avg (8). We next add monolingual cluster features to the model with the union dictionary. This model, YHMM+C, significantly outperforms all other typeunion constrained models, demonstrating the utility of word-cluster features.9 For further exploration, we train the same model on the datasets containing 500K tokens sampled from the target side of the parallel data (YHMM union +C+L); this is done to explore the effects of large data during training. We find that training on these datasets result in an average accuracy of 87.2% which is comparable to th</context>
</contexts>
<marker>Efron, Tibshirani, 1993</marker>
<rawString>Brad Efron and Robert J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman &amp; Hall, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria Fossum</author>
<author>Steven Abney</author>
</authors>
<title>Automatically inducing a part-of-speech tagger by projecting from multiple source languages across aligned corpora. In</title>
<date>2005</date>
<booktitle>Proceedings of IJCNLP.</booktitle>
<contexts>
<context position="7770" citStr="Fossum and Abney (2005)" startWordPosition="1155" endWordPosition="1158"> natural to consider using a supervised part-of-speech tagger to predict part-of-speech tags for the English side of the bitext. These predicted tags can subsequently be projected to the target side via automatic word alignments. This approach was pioneered by Yarowsky and Ngai (2001), who used the resulting partial target annotation to estimate the parameters of an HMM. However, due to the automatic nature of the word alignments and the POS tags, there will be significant noise in the projected tags. To conquer this noise, they used very aggressive smoothing techniques when training the HMM. Fossum and Abney (2005) used similar token-level projections, but instead combined projections from multiple source languages to filter out random projection noise as well as the systematic noise arising from different source language annotations and syntactic divergences. 2.2 Type Constraints It is well known that given a tag dictionary, even if it is incomplete, it is possible to learn accurate POS taggers (Smith and Eisner, 2005; Goldberg et al., 2008; Ravi and Knight, 2009; Naseem et al., 2009). While widely differing in the specific model structure and learning objective, all of these approaches achieve excelle</context>
</contexts>
<marker>Fossum, Abney, 2005</marker>
<rawString>Victoria Fossum and Steven Abney. 2005. Automatically inducing a part-of-speech tagger by projecting from multiple source languages across aligned corpora. In Proceedings of IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Garrette</author>
<author>Jason Baldridge</author>
</authors>
<title>Type-supervised hidden markov models for part-of-speech tagging with incomplete tag dictionaries.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLPCoNLL.</booktitle>
<contexts>
<context position="6321" citStr="Garrette and Baldridge, 2012" startWordPosition="923" endWordPosition="926">trov (2011) and Li et al. (2012), we achieve an accuracy of 88.8%. This is a 25% relative error reduction over the previous state of the art. Averaged across all 15 languages, our model obtains an accuracy of 84.5% compared to 78.5% obtained by a strong generative baseline. Finally, we provide an in depth analysis of the relative contributions of the two types of constraints in §5. 2 Coupling Token and Type Constraints Type-level information has been amply used in weakly supervised POS induction, either via pure manually crafted tag dictionaries (Smith and Eisner, 2005; Ravi and Knight, 2009; Garrette and Baldridge, 2012), noisily projected tag dictionaries (Das and Petrov, 2011) or through crowdsourced lexica, such as Wiktionary (Li et al., 2012). At the other end of the spectrum, there have been efforts that project token-level information across word-aligned bitext (Yarowsky and Ngai, 2001; Xi and Hwa, 2005). However, systems that combine both sources of information in a single model have yet to be fully explored. The following three subsections outline our overall approach for coupling these two types of information to build robust POS taggers that do not require any direct supervision in the target langua</context>
</contexts>
<marker>Garrette, Baldridge, 2012</marker>
<rawString>Dan Garrette and Jason Baldridge. 2012. Type-supervised hidden markov models for part-of-speech tagging with incomplete tag dictionaries. In Proceedings of EMNLPCoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Meni Adler</author>
<author>Michael Elhadad</author>
</authors>
<title>EM can find pretty good HMM POS-taggers (when given a good start).</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="8205" citStr="Goldberg et al., 2008" startWordPosition="1223" endWordPosition="1226"> the POS tags, there will be significant noise in the projected tags. To conquer this noise, they used very aggressive smoothing techniques when training the HMM. Fossum and Abney (2005) used similar token-level projections, but instead combined projections from multiple source languages to filter out random projection noise as well as the systematic noise arising from different source language annotations and syntactic divergences. 2.2 Type Constraints It is well known that given a tag dictionary, even if it is incomplete, it is possible to learn accurate POS taggers (Smith and Eisner, 2005; Goldberg et al., 2008; Ravi and Knight, 2009; Naseem et al., 2009). While widely differing in the specific model structure and learning objective, all of these approaches achieve excellent results. Unfortunately, they rely on tag dictionaries extracted directly from the underlying treebank data. Such dictionaries provide in depth coverage of the test domain and also list all 2 Jordbruksprodukterna mdste vara rena och fdr inte innehdlla ndgra tillsatser � NOUN VERB VERB ADJ CONJ VERB ADV VERB DET NOUN P Figure 1: Lattice representation of the inference search space y(x) for an authentic sentence in Swedish (“The fa</context>
</contexts>
<marker>Goldberg, Adler, Elhadad, 2008</marker>
<rawString>Yoav Goldberg, Meni Adler, and Michael Elhadad. 2008. EM can find pretty good HMM POS-taggers (when given a good start). In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit.</booktitle>
<contexts>
<context position="23593" citStr="Koehn, 2005" startWordPosition="3832" endWordPosition="3833">al POS tags using the mapping of Petrov et al. (2012).6 Since we use indirect supervision via projected tags or Wiktionary, the model states induced by all models correspond directly to POS tags, enabling us to compute tagging accuracy without a greedy 1-to-1 or many-to-1 mapping. Bitext. For all experiments, we use English as the source language. Depending on availability, there are between 1M and 5M parallel sentences for each language. The majority of the parallel data is gathered automatically from the web using the method of Uszkoreit et al. (2010). We further include data from Europarl (Koehn, 2005) and from the UN parallel corpus (UN, 2006), for languages covered by these corpora. The English side of the bitext is POS tagged with a standard supervised CRF tagger, trained on the Penn Treebank (Marcus et al., 1993), with tags mapped to universal tags. The parallel sen5For French we use the treebank of Abeill´e et al. (2003). 6We use version 1.03 of the mappings available at http: //code.google.com/p/universal-pos-tags/. 6 tences are word aligned with the aligner of DeNero and Macherey (2011). Intersected high-confidence alignments (confidence &gt;0.95) are extracted and aggregated into proje</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of ICML.</booktitle>
<contexts>
<context position="4276" citStr="Lafferty et al., 2001" startWordPosition="606" endWordPosition="609">ar context. On the other hand, manually cre1http://www.wiktionary.org/. 1 Transactions of the Association for Computational Linguistics, 1 (2013) 1–12. Action Editor: Sharon Goldwater. Submitted 11/2012; Revised 1/2013; Published 3/2013. c�2013 Association for Computational Linguistics. ated type-level dictionaries can have broad coverage and do not suffer from word-alignment errors; they can therefore be used to filter systematic as well as random noise in token-level projections. In order to reap these potential benefits, we propose a partially observed conditional random field (CRF) model (Lafferty et al., 2001) that couples token and type constraints in order to guide learning (§3). In essence, the model is given the freedom to push probability mass towards hypotheses consistent with both types of information. This approach is flexible: we can use either noisy projected or manually constructed dictionaries to generate type constraints; furthermore, we can incorporate arbitrary features over the input. In addition to standard (contextual) lexical features and transition features, we observe that adding features from a monolingual word clustering (Uszkoreit and Brants, 2008) can significantly improve </context>
<context position="20561" citStr="Lafferty et al., 2001" startWordPosition="3319" endWordPosition="3322">by choosing the one with maximal joint probability: y* ← arg max pβ(x, y) . yEY(x) 4We trained the HMM with EM as well, but achieved better results with direct gradient training and hence omit those results. pβ(x, y) = � |x |pβ(xi |yi) i=1 � I..&apos; ol emission exp (βTφ(xi, yi)) 5 3.2 CRFs with Coupled Constraints Whereas an HMM models the joint probability of the input x E X and output y E Y(x), using locally normalized component distributions, a conditional random field (CRF) instead models the probability of the output conditioned on the input as a globally normalized log-linear distribution (Lafferty et al., 2001): exp (θTq&apos;(x,y)) pθ(y |x) = Ey,EY(x) exp (θTq&apos;(x, y&apos;)) , where θ is a parameter vector. As for the HMM, Y(x) is not necessarily the full space of possible tag-sequences; specifically, for us, it is the dictionarypruned lattice without the token constraints. With a first-order Markov assumption, the feature function factors as: q&apos;(x, y) = � |x |φ(x, yi, yi−1) . i=1 This model is more powerful than the HMM in that it can use richer feature definitions, such as joint input/transition features and features over a wider input context. We model a marginal conditional probability, given by the total</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shen Li</author>
<author>Jo˜ao Grac¸a</author>
<author>Ben Taskar</author>
</authors>
<title>Wiki-ly supervised part-of-speech tagging.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL.</booktitle>
<marker>Li, Grac¸a, Taskar, 2012</marker>
<rawString>Shen Li, Jo˜ao Grac¸a, and Ben Taskar. 2012. Wiki-ly supervised part-of-speech tagging. In Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong C Liu</author>
<author>Jorge Nocedal</author>
</authors>
<title>On the limited memory BFGS method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical Programming,</booktitle>
<volume>45</volume>
<contexts>
<context position="19396" citStr="Liu and Nocedal, 1989" startWordPosition="3112" endWordPosition="3115"> sentence x, and its coupled constraints lattice Y(x, ˜y), which is obtained by marginalizing over all consistent outputs: pβ(x, �Y(x, ˜y)) = � pβ(x, y) . yE�Y(x,˜y) If there are no projections and no tag dictionary, then Y(x, ˜y) = T |x|, and thus pβ(x, Y(x, ˜y)) = pβ(x), which reduces to fully unsupervised learning. The `2-regularized marginal joint log-likelihood of the constrained training data D = {(x(i), ˜y(i))}ni=1 is: n L(β; D) = log pβ(x(i), Y(x(i), ˜y(i)))−γ kβk22 . i=1 (1) We follow Berg-Kirkpatrick et al. (2010) and take a direct gradient approach for optimizing Eq. 1 with L-BFGS (Liu and Nocedal, 1989). We set γ = 1 and run 100 iterations of L-BFGS. One could also employ the Expectation-Maximization (EM) algorithm (Dempster et al., 1977) to optimize this objective, although the relative merits of EM versus direct gradient training for these models is still a topic of debate (Berg-Kirkpatrick et al., 2010; Li et al., 2012).4 Note that since the marginal likelihood is non-concave, we are only guaranteed to find a local maximum of Eq. 1. After estimating the model parameters β, the tagsequence y* ∈ Y(x) for a sentence x ∈ X is predicted by choosing the one with maximal joint probability: y* ← </context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Dong C. Liu and Jorge Nocedal. 1989. On the limited memory BFGS method for large scale optimization. Mathematical Programming, 45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of English: the Penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="23812" citStr="Marcus et al., 1993" startWordPosition="3869" endWordPosition="3872">compute tagging accuracy without a greedy 1-to-1 or many-to-1 mapping. Bitext. For all experiments, we use English as the source language. Depending on availability, there are between 1M and 5M parallel sentences for each language. The majority of the parallel data is gathered automatically from the web using the method of Uszkoreit et al. (2010). We further include data from Europarl (Koehn, 2005) and from the UN parallel corpus (UN, 2006), for languages covered by these corpora. The English side of the bitext is POS tagged with a standard supervised CRF tagger, trained on the Penn Treebank (Marcus et al., 1993), with tags mapped to universal tags. The parallel sen5For French we use the treebank of Abeill´e et al. (2003). 6We use version 1.03 of the mappings available at http: //code.google.com/p/universal-pos-tags/. 6 tences are word aligned with the aligner of DeNero and Macherey (2011). Intersected high-confidence alignments (confidence &gt;0.95) are extracted and aggregated into projected type-level dictionaries. For purely practical reasons, the training data with tokenlevel projections is created by randomly sampling target-side sentences with a total of 500K tokens. Wiktionary. We use a snapshot </context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: the Penn treebank. Computational Linguistics, 19(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Benjamin Snyder</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Multilingual part-of-speech tagging: Two unsupervised approaches.</title>
<date>2009</date>
<journal>JAIR,</journal>
<volume>36</volume>
<contexts>
<context position="8250" citStr="Naseem et al., 2009" startWordPosition="1231" endWordPosition="1234"> in the projected tags. To conquer this noise, they used very aggressive smoothing techniques when training the HMM. Fossum and Abney (2005) used similar token-level projections, but instead combined projections from multiple source languages to filter out random projection noise as well as the systematic noise arising from different source language annotations and syntactic divergences. 2.2 Type Constraints It is well known that given a tag dictionary, even if it is incomplete, it is possible to learn accurate POS taggers (Smith and Eisner, 2005; Goldberg et al., 2008; Ravi and Knight, 2009; Naseem et al., 2009). While widely differing in the specific model structure and learning objective, all of these approaches achieve excellent results. Unfortunately, they rely on tag dictionaries extracted directly from the underlying treebank data. Such dictionaries provide in depth coverage of the test domain and also list all 2 Jordbruksprodukterna mdste vara rena och fdr inte innehdlla ndgra tillsatser � NOUN VERB VERB ADJ CONJ VERB ADV VERB DET NOUN P Figure 1: Lattice representation of the inference search space y(x) for an authentic sentence in Swedish (“The farming products must be pure and must not cont</context>
</contexts>
<marker>Naseem, Snyder, Eisenstein, Barzilay, 2009</marker>
<rawString>Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, and Regina Barzilay. 2009. Multilingual part-of-speech tagging: Two unsupervised approaches. JAIR, 36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proceedings of EMNLP-CoNLL.</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="1534" citStr="Petrov et al., 2012" startWordPosition="209" endWordPosition="212">del, where coupled token and type constraints provide a partial signal for training. Averaged across eight previously studied Indo-European languages, our model achieves a 25% relative error reduction over the prior state of the art. We further present successful results on seven additional languages from different families, empirically demonstrating the applicability of coupled token and type constraints across a diverse set of languages. 1 Introduction Supervised part-of-speech (POS) taggers are available for more than twenty languages and achieve accuracies of around 95% on in-domain data (Petrov et al., 2012). Thanks to their efficiency and robustness, supervised taggers are routinely employed in many natural language processing applications, such as syntactic and semantic parsing, named-entity recognition and machine translation. Unfortunately, the resources required to train supervised taggers are expensive to create and unlikely to exist for the majority of written ∗ Work primarily carried out while at Google Research. languages. The necessity of building NLP tools for these resource-poor languages has been part of the motivation for research on unsupervised learning of POS taggers (Christodoul</context>
<context position="23034" citStr="Petrov et al. (2012)" startWordPosition="3740" endWordPosition="3743">n additional languages (see Table 1). While the former eight languages all belong to the Indo-European family, we broaden the coverage to language families more distant from the source language (for example, Chinese, Japanese and Turkish). We use the treebanks from the CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) for evaluation.5 The twoletter abbreviations from the ISO 639-1 standard are used when referring to these languages in tables and figures. Tagset. In all cases, we map the language-specific POS tags to universal POS tags using the mapping of Petrov et al. (2012).6 Since we use indirect supervision via projected tags or Wiktionary, the model states induced by all models correspond directly to POS tags, enabling us to compute tagging accuracy without a greedy 1-to-1 or many-to-1 mapping. Bitext. For all experiments, we use English as the source language. Depending on availability, there are between 1M and 5M parallel sentences for each language. The majority of the parallel data is gathered automatically from the web using the method of Uszkoreit et al. (2010). We further include data from Europarl (Koehn, 2005) and from the UN parallel corpus (UN, 200</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Minimized models for unsupervised part-of-speech tagging.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP.</booktitle>
<contexts>
<context position="6290" citStr="Ravi and Knight, 2009" startWordPosition="919" endWordPosition="922">s studied by Das and Petrov (2011) and Li et al. (2012), we achieve an accuracy of 88.8%. This is a 25% relative error reduction over the previous state of the art. Averaged across all 15 languages, our model obtains an accuracy of 84.5% compared to 78.5% obtained by a strong generative baseline. Finally, we provide an in depth analysis of the relative contributions of the two types of constraints in §5. 2 Coupling Token and Type Constraints Type-level information has been amply used in weakly supervised POS induction, either via pure manually crafted tag dictionaries (Smith and Eisner, 2005; Ravi and Knight, 2009; Garrette and Baldridge, 2012), noisily projected tag dictionaries (Das and Petrov, 2011) or through crowdsourced lexica, such as Wiktionary (Li et al., 2012). At the other end of the spectrum, there have been efforts that project token-level information across word-aligned bitext (Yarowsky and Ngai, 2001; Xi and Hwa, 2005). However, systems that combine both sources of information in a single model have yet to be fully explored. The following three subsections outline our overall approach for coupling these two types of information to build robust POS taggers that do not require any direct s</context>
<context position="8228" citStr="Ravi and Knight, 2009" startWordPosition="1227" endWordPosition="1230">ll be significant noise in the projected tags. To conquer this noise, they used very aggressive smoothing techniques when training the HMM. Fossum and Abney (2005) used similar token-level projections, but instead combined projections from multiple source languages to filter out random projection noise as well as the systematic noise arising from different source language annotations and syntactic divergences. 2.2 Type Constraints It is well known that given a tag dictionary, even if it is incomplete, it is possible to learn accurate POS taggers (Smith and Eisner, 2005; Goldberg et al., 2008; Ravi and Knight, 2009; Naseem et al., 2009). While widely differing in the specific model structure and learning objective, all of these approaches achieve excellent results. Unfortunately, they rely on tag dictionaries extracted directly from the underlying treebank data. Such dictionaries provide in depth coverage of the test domain and also list all 2 Jordbruksprodukterna mdste vara rena och fdr inte innehdlla ndgra tillsatser � NOUN VERB VERB ADJ CONJ VERB ADV VERB DET NOUN P Figure 1: Lattice representation of the inference search space y(x) for an authentic sentence in Swedish (“The farming products must be </context>
</contexts>
<marker>Ravi, Knight, 2009</marker>
<rawString>Sujith Ravi and Kevin Knight. 2009. Minimized models for unsupervised part-of-speech tagging. In Proceedings of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy H King</author>
<author>Ronald M Kaplan</author>
<author>Richard Crouch</author>
<author>John T Maxwell</author>
<author>Mark Johnson</author>
</authors>
<title>Parsing the wall street journal using a lexical-functional grammar and discriminative estimation techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="21445" citStr="Riezler et al., 2002" startWordPosition="3467" endWordPosition="3470"> a first-order Markov assumption, the feature function factors as: q&apos;(x, y) = � |x |φ(x, yi, yi−1) . i=1 This model is more powerful than the HMM in that it can use richer feature definitions, such as joint input/transition features and features over a wider input context. We model a marginal conditional probability, given by the total probability of all tag sequences consistent with the lattice �Y(x, ˜y): pθ( � pθ(y |x) . Y(x, ˜y) |x) = yE�Y(x,˜y) The parameters of this constrained CRF are estimated by maximizing the `2-regularized marginal conditional log-likelihood of the constrained data (Riezler et al., 2002): L(θ; D) = n log pθ( y(x(i), ˜y(i)) |x(i)) − γ11θ1122 . i=1 (2) As with Eq. 1, we maximize Eq. 2 with 100 iterations of L-BFGS and set γ = 1. In contrast to the HMM, after estimating the model parameters θ, the tag-sequence y* E Y(x) for a sentence x E X is chosen as the sequence with the maximal conditional probability: y* +- arg max pθ(y |x) . yEY(x) 4 Empirical Study We now present a detailed empirical study of the models proposed in the previous sections. In addition to comparing with the state of the art in Das and Petrov (2011) and Li et al. (2012), we present models with several combin</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard Crouch, John T. Maxwell, III, and Mark Johnson. 2002. Parsing the wall street journal using a lexical-functional grammar and discriminative estimation techniques. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="6267" citStr="Smith and Eisner, 2005" startWordPosition="915" endWordPosition="918">cross the eight languages studied by Das and Petrov (2011) and Li et al. (2012), we achieve an accuracy of 88.8%. This is a 25% relative error reduction over the previous state of the art. Averaged across all 15 languages, our model obtains an accuracy of 84.5% compared to 78.5% obtained by a strong generative baseline. Finally, we provide an in depth analysis of the relative contributions of the two types of constraints in §5. 2 Coupling Token and Type Constraints Type-level information has been amply used in weakly supervised POS induction, either via pure manually crafted tag dictionaries (Smith and Eisner, 2005; Ravi and Knight, 2009; Garrette and Baldridge, 2012), noisily projected tag dictionaries (Das and Petrov, 2011) or through crowdsourced lexica, such as Wiktionary (Li et al., 2012). At the other end of the spectrum, there have been efforts that project token-level information across word-aligned bitext (Yarowsky and Ngai, 2001; Xi and Hwa, 2005). However, systems that combine both sources of information in a single model have yet to be fully explored. The following three subsections outline our overall approach for coupling these two types of information to build robust POS taggers that do n</context>
<context position="8182" citStr="Smith and Eisner, 2005" startWordPosition="1219" endWordPosition="1222"> the word alignments and the POS tags, there will be significant noise in the projected tags. To conquer this noise, they used very aggressive smoothing techniques when training the HMM. Fossum and Abney (2005) used similar token-level projections, but instead combined projections from multiple source languages to filter out random projection noise as well as the systematic noise arising from different source language annotations and syntactic divergences. 2.2 Type Constraints It is well known that given a tag dictionary, even if it is incomplete, it is possible to learn accurate POS taggers (Smith and Eisner, 2005; Goldberg et al., 2008; Ravi and Knight, 2009; Naseem et al., 2009). While widely differing in the specific model structure and learning objective, all of these approaches achieve excellent results. Unfortunately, they rely on tag dictionaries extracted directly from the underlying treebank data. Such dictionaries provide in depth coverage of the test domain and also list all 2 Jordbruksprodukterna mdste vara rena och fdr inte innehdlla ndgra tillsatser � NOUN VERB VERB ADJ CONJ VERB ADV VERB DET NOUN P Figure 1: Lattice representation of the inference search space y(x) for an authentic sente</context>
<context position="14842" citStr="Smith and Eisner, 2005" startWordPosition="2291" endWordPosition="2294">tween languages: Spanish has the highest coverage with over 90%, while Turkish, an agglutinative language with a vast number of word forms, has less than 50% coverage. Figure 3 shows that there is substantial uncertainty left after pruning with Wiktionary, since tokens are rarely fully disambiguated: 1.3 tags per token are allowed on average for types in Wiktionary. Figure 2 further shows that high-confidence alignments are available for about half of the tokens for most languages (Japanese is a notable exception with 3Other training methods exist as well, for example, contrastive estimation (Smith and Eisner, 2005). avg bg cs da de el es fr it ja nl pt sl sv tr zh Figure 2: Wiktionary and projection dictionary coverage. Shown is the percentage of tokens in the target side of the bitext that are covered by Wiktionary, that have a projected tag, and that have a projected tag after intersecting the two. avg bg cs da de el es fr it ja nl pt sl sv tr zh Figure 3: Average number of licensed tags per token on the target side of the bitext, for types in Wiktionary. less than 30% of the tokens covered). Intersecting the Wiktionary tags and the projected tags (Step 2 and 3 above) filters out some of the potential</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>Noah Smith and Jason Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Cross-lingual word clusters for direct transfer of linguistic structure.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACL-HLT.</booktitle>
<marker>T¨ackstr¨om, McDonald, Uszkoreit, 2012</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit. 2012. Cross-lingual word clusters for direct transfer of linguistic structure. In Proceedings of NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev-Arie Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: A simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="25403" citStr="Turian et al., 2010" startWordPosition="4126" endWordPosition="4129">rd identity, suffixes of up to length 3, and three indicator features that fire when the word starts with a capital letter, contains a hyphen or contains a digit. These are the same features as those used by Das and Petrov (2011). Finally, for some models we add a word cluster feature that couples the current tag and the word cluster identity of the word. These (monolingual) word clusters are induced with the exchange algorithm (Uszkoreit and Brants, 2008). We set the number of clusters to 256 across all languages, as this has previously been shown to produce robust results for similar tasks (Turian et al., 2010; T¨ackstr¨om et al., 2012). The clusters for each language are learned on a large monolingual newswire corpus. 4.2 Models with Type Constraints To examine the sole effect of type constraints, we experiment with the HMM, drawing constraints from three different dictionaries. Table 1 compares the performance of our models with the best results of Das and Petrov (2011, D&amp;P) and Li et al. (2012, LG&amp;T). As in previous work, training is done exclusively on the training portion of each treebank, stripped of any manual linguistic annotation. We first use all of our parallel data to generate projected</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio. 2010. Word representations: A simple and general method for semi-supervised learning. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>UN</author>
</authors>
<date>2006</date>
<note>ODS UN parallel corpus.</note>
<contexts>
<context position="23636" citStr="UN, 2006" startWordPosition="3841" endWordPosition="3842"> (2012).6 Since we use indirect supervision via projected tags or Wiktionary, the model states induced by all models correspond directly to POS tags, enabling us to compute tagging accuracy without a greedy 1-to-1 or many-to-1 mapping. Bitext. For all experiments, we use English as the source language. Depending on availability, there are between 1M and 5M parallel sentences for each language. The majority of the parallel data is gathered automatically from the web using the method of Uszkoreit et al. (2010). We further include data from Europarl (Koehn, 2005) and from the UN parallel corpus (UN, 2006), for languages covered by these corpora. The English side of the bitext is POS tagged with a standard supervised CRF tagger, trained on the Penn Treebank (Marcus et al., 1993), with tags mapped to universal tags. The parallel sen5For French we use the treebank of Abeill´e et al. (2003). 6We use version 1.03 of the mappings available at http: //code.google.com/p/universal-pos-tags/. 6 tences are word aligned with the aligner of DeNero and Macherey (2011). Intersected high-confidence alignments (confidence &gt;0.95) are extracted and aggregated into projected type-level dictionaries. For purely pr</context>
</contexts>
<marker>UN, 2006</marker>
<rawString>UN. 2006. ODS UN parallel corpus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Uszkoreit</author>
<author>Thorsten Brants</author>
</authors>
<title>Distributed word clustering for large scale class-based language modeling in machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="4849" citStr="Uszkoreit and Brants, 2008" startWordPosition="692" endWordPosition="695">ional random field (CRF) model (Lafferty et al., 2001) that couples token and type constraints in order to guide learning (§3). In essence, the model is given the freedom to push probability mass towards hypotheses consistent with both types of information. This approach is flexible: we can use either noisy projected or manually constructed dictionaries to generate type constraints; furthermore, we can incorporate arbitrary features over the input. In addition to standard (contextual) lexical features and transition features, we observe that adding features from a monolingual word clustering (Uszkoreit and Brants, 2008) can significantly improve accuracy. While most of these features can also be used in a generative feature-based hidden Markov model (HMM) (Berg-Kirkpatrick et al., 2010), we achieve the best accuracy with a globally normalized discriminative CRF model. To evaluate our approach, we present extensive results on standard publicly available datasets for 15 languages: the eight Indo-European languages previously studied in this context by Das and Petrov (2011) and Li et al. (2012), and seven additional languages from different families, for which no comparable study exists. In §4 we compare variou</context>
<context position="25244" citStr="Uszkoreit and Brants, 2008" startWordPosition="4098" endWordPosition="4101">use only an identity feature for tag-pair transitions. We use five features that couple the current tag and the observed word (analogous to the emission in an HMM): word identity, suffixes of up to length 3, and three indicator features that fire when the word starts with a capital letter, contains a hyphen or contains a digit. These are the same features as those used by Das and Petrov (2011). Finally, for some models we add a word cluster feature that couples the current tag and the word cluster identity of the word. These (monolingual) word clusters are induced with the exchange algorithm (Uszkoreit and Brants, 2008). We set the number of clusters to 256 across all languages, as this has previously been shown to produce robust results for similar tasks (Turian et al., 2010; T¨ackstr¨om et al., 2012). The clusters for each language are learned on a large monolingual newswire corpus. 4.2 Models with Type Constraints To examine the sole effect of type constraints, we experiment with the HMM, drawing constraints from three different dictionaries. Table 1 compares the performance of our models with the best results of Das and Petrov (2011, D&amp;P) and Li et al. (2012, LG&amp;T). As in previous work, training is done </context>
</contexts>
<marker>Uszkoreit, Brants, 2008</marker>
<rawString>Jakob Uszkoreit and Thorsten Brants. 2008. Distributed word clustering for large scale class-based language modeling in machine translation. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Uszkoreit</author>
<author>Jay Ponte</author>
<author>Ashok Popat</author>
<author>Moshe Dubiner</author>
</authors>
<title>Large scale parallel document mining for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="23540" citStr="Uszkoreit et al. (2010)" startWordPosition="3822" endWordPosition="3825">. In all cases, we map the language-specific POS tags to universal POS tags using the mapping of Petrov et al. (2012).6 Since we use indirect supervision via projected tags or Wiktionary, the model states induced by all models correspond directly to POS tags, enabling us to compute tagging accuracy without a greedy 1-to-1 or many-to-1 mapping. Bitext. For all experiments, we use English as the source language. Depending on availability, there are between 1M and 5M parallel sentences for each language. The majority of the parallel data is gathered automatically from the web using the method of Uszkoreit et al. (2010). We further include data from Europarl (Koehn, 2005) and from the UN parallel corpus (UN, 2006), for languages covered by these corpora. The English side of the bitext is POS tagged with a standard supervised CRF tagger, trained on the Penn Treebank (Marcus et al., 1993), with tags mapped to universal tags. The parallel sen5For French we use the treebank of Abeill´e et al. (2003). 6We use version 1.03 of the mappings available at http: //code.google.com/p/universal-pos-tags/. 6 tences are word aligned with the aligner of DeNero and Macherey (2011). Intersected high-confidence alignments (conf</context>
</contexts>
<marker>Uszkoreit, Ponte, Popat, Dubiner, 2010</marker>
<rawString>Jakob Uszkoreit, Jay Ponte, Ashok Popat, and Moshe Dubiner. 2010. Large scale parallel document mining for machine translation. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhai Xi</author>
<author>Rebecca Hwa</author>
</authors>
<title>A backoff model for bootstrapping resources for non-English languages.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP.</booktitle>
<contexts>
<context position="3403" citStr="Xi and Hwa, 2005" startWordPosition="481" endWordPosition="484">the aforementioned weakly supervised approaches have resulted in significant improvements over fully unsupervised approaches, they have not exploited the benefits of token-level cross-lingual projection methods, which are possible with wordaligned bitext between a target language of interest and a resource-rich source language, such as English. This is the setting we consider in this paper (§2). While prior work has successfully considered both token- and type-level projection across word-aligned bitext for estimating the model parameters of generative tagging models (Yarowsky and Ngai, 2001; Xi and Hwa, 2005, inter alia), a key observation underlying the present work is that token- and type-level information offer different and complementary signals. On the one hand, high confidence token-level projections offer precise constraints on a tag in a particular context. On the other hand, manually cre1http://www.wiktionary.org/. 1 Transactions of the Association for Computational Linguistics, 1 (2013) 1–12. Action Editor: Sharon Goldwater. Submitted 11/2012; Revised 1/2013; Published 3/2013. c�2013 Association for Computational Linguistics. ated type-level dictionaries can have broad coverage and do n</context>
<context position="6616" citStr="Xi and Hwa, 2005" startWordPosition="968" endWordPosition="971">analysis of the relative contributions of the two types of constraints in §5. 2 Coupling Token and Type Constraints Type-level information has been amply used in weakly supervised POS induction, either via pure manually crafted tag dictionaries (Smith and Eisner, 2005; Ravi and Knight, 2009; Garrette and Baldridge, 2012), noisily projected tag dictionaries (Das and Petrov, 2011) or through crowdsourced lexica, such as Wiktionary (Li et al., 2012). At the other end of the spectrum, there have been efforts that project token-level information across word-aligned bitext (Yarowsky and Ngai, 2001; Xi and Hwa, 2005). However, systems that combine both sources of information in a single model have yet to be fully explored. The following three subsections outline our overall approach for coupling these two types of information to build robust POS taggers that do not require any direct supervision in the target language. 2.1 Token Constraints For the majority of resource-poor languages, there is at least some bitext with a resource-rich source language; for simplicity, we choose English as our source language in all experiments. It is then natural to consider using a supervised part-of-speech tagger to pred</context>
</contexts>
<marker>Xi, Hwa, 2005</marker>
<rawString>Chenhai Xi and Rebecca Hwa. 2005. A backoff model for bootstrapping resources for non-English languages. In Proceedings of HLT-EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Proceedings of NAACL.</booktitle>
<contexts>
<context position="3385" citStr="Yarowsky and Ngai, 2001" startWordPosition="477" endWordPosition="480">the same setup. Although the aforementioned weakly supervised approaches have resulted in significant improvements over fully unsupervised approaches, they have not exploited the benefits of token-level cross-lingual projection methods, which are possible with wordaligned bitext between a target language of interest and a resource-rich source language, such as English. This is the setting we consider in this paper (§2). While prior work has successfully considered both token- and type-level projection across word-aligned bitext for estimating the model parameters of generative tagging models (Yarowsky and Ngai, 2001; Xi and Hwa, 2005, inter alia), a key observation underlying the present work is that token- and type-level information offer different and complementary signals. On the one hand, high confidence token-level projections offer precise constraints on a tag in a particular context. On the other hand, manually cre1http://www.wiktionary.org/. 1 Transactions of the Association for Computational Linguistics, 1 (2013) 1–12. Action Editor: Sharon Goldwater. Submitted 11/2012; Revised 1/2013; Published 3/2013. c�2013 Association for Computational Linguistics. ated type-level dictionaries can have broad</context>
<context position="6597" citStr="Yarowsky and Ngai, 2001" startWordPosition="964" endWordPosition="967">, we provide an in depth analysis of the relative contributions of the two types of constraints in §5. 2 Coupling Token and Type Constraints Type-level information has been amply used in weakly supervised POS induction, either via pure manually crafted tag dictionaries (Smith and Eisner, 2005; Ravi and Knight, 2009; Garrette and Baldridge, 2012), noisily projected tag dictionaries (Das and Petrov, 2011) or through crowdsourced lexica, such as Wiktionary (Li et al., 2012). At the other end of the spectrum, there have been efforts that project token-level information across word-aligned bitext (Yarowsky and Ngai, 2001; Xi and Hwa, 2005). However, systems that combine both sources of information in a single model have yet to be fully explored. The following three subsections outline our overall approach for coupling these two types of information to build robust POS taggers that do not require any direct supervision in the target language. 2.1 Token Constraints For the majority of resource-poor languages, there is at least some bitext with a resource-rich source language; for simplicity, we choose English as our source language in all experiments. It is then natural to consider using a supervised part-of-sp</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>David Yarowsky and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proceedings of NAACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>