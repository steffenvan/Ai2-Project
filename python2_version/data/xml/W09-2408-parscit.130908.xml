<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002328">
<title confidence="0.885746">
Meeting TempEval-2: Shallow Approach for Temporal Tagger
</title>
<author confidence="0.86787">
Oleksandr Kolomiyets
</author>
<affiliation confidence="0.908085">
Katholieke Universiteit Leuven
Department of Computer Science
</affiliation>
<address confidence="0.412737">
Celestijnenlaan 200A, Heverlee, Belgium
</address>
<email confidence="0.583316">
oleksandr.kolomiyets
@cs.kuleuven.be
</email>
<author confidence="0.730928">
Marie-Francine Moens
</author>
<affiliation confidence="0.8826915">
Katholieke Universiteit Leuven
Department of Computer Science
</affiliation>
<address confidence="0.629585">
Celestijnenlaan 200A, Heverlee, Belgium
</address>
<email confidence="0.988885">
sien.moens@cs.kuleuven.be
</email>
<sectionHeader confidence="0.998548" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9979455">
Temporal expressions are one of the important
structures in natural language. In order to un-
derstand text, temporal expressions have to be
identified and normalized by providing ISO-
based values. In this paper we present a shal-
low approach for automatic recognition of
temporal expressions based on a supervised
machine learning approach trained on an an-
notated corpus for temporal information,
namely TimeBank. Our experiments demon-
strate a performance level comparable to a
rule-based implementation and achieve the
scores of 0.872, 0.836 and 0.852 for precision,
recall and F1-measure for the detection task
respectively, and 0.866, 0.796, 0.828 when an
exact match is required.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999589384615385">
The task of recognizing temporal expressions
(sometimes also referred as time expressions or
simply TIMEX) was first introduced in the Mes-
sage Understanding Conference (MUC) in 1995.
Temporal expressions were treated as a part of the
Named Entity Recognition (NER) task, in which
capitalized tokens in text were labeled with one of
the predefined semantic labels, such as Date, Time,
Person, Organization, Location, Percentage, and
Money. As the types of temporal entities identified
in this way were too restricted and provided little
further information, the Automated Content Ex-
traction (ACE) launched a competition campaign
</bodyText>
<page confidence="0.976368">
52
</page>
<bodyText confidence="0.999352205882353">
for Temporal Expression Recognition and Norma-
lization (TERN 2004). The tasks were to identify
temporal expressions in free text and normalize
them providing an ISO-based date-time value. Lat-
er evaluations of ACE in 2005, 2006 and 2007 un-
fortunately did not set new challenges for temporal
expression recognition and thus the participation
interest in this particular task decreased.
TempEval-2 is a successor of TempEval-2007
and will take place in 2010. The new evaluation
initiative sets new challenges for temporal text
analysis. While TempEval-2007 was solely fo-
cused on recognition of temporal links, the
TempEval-2 tasks aim at an all-around temporal
processing with separate evaluations for recogni-
tion of temporal expressions and events, for the
estimation of temporal relations between events
and times in the same sentence, between events
and document creation time, between two events in
consecutive sentences and between two events,
where one of them syntactically dominates the oth-
er (Pustejovsky et al., 2009). These evaluations
became possible with a new freely available corpus
with annotated temporal information, TimeBank
(Pustejovsky et al., 2003a), and an annotation
schema, called TimeML (Pustejovsky et al.,
2003b).
For us all the tasks of TempEval-2 seem to be
interesting. In this paper we make the first step
towards a comprehensive temporal analysis and
address the problem of temporal expression recog-
nition as it is set in TempEval-2. Despite a number
of previous implementations mainly done in the
context of the ACE TERN competition, very few,
</bodyText>
<note confidence="0.6697695">
Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 52–57,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999403133333333">
and exclusively rule-based methods were reported
for temporal taggers on TimeBank developed by
using the TimeML annotation scheme. As a main
result of the deep analysis of relevant work (Sec-
tion 2), we decided to employ a machine learning
approach for constituent-based classifications with
generic syntactic and lexical features.
The remainder of the paper is organized as fol-
lows: in Section 2 we provide the details of rele-
vant work done in this field along with corpora and
annotations schemes used; Section 3 describes the
approach; experimental setup, results and error
analysis are provided in Section 4. Finally, Section
5 gives an outlook for further improvements and
research.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9997646">
For better understanding of the performance levels
provided in the paper we first describe evaluation
metrics defined for the temporal expression recog-
nition task and then the methods and datasets used
in previous research.
</bodyText>
<subsectionHeader confidence="0.975411">
2.1 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.999771233333333">
With the start of the ACE TERN competition in
2004, two major evaluation conditions were pro-
posed: Recognition+Normalization (full task) and
Recognition only (TERN, 2004).
Detection (Recognition): Detection is a prelimi-
nary task towards the full TERN task, in which
temporally relevant expressions have to be found.
The scoring is very generous and implies a minim-
al overlap in the extent of the reference and the
system output tags. As long as there is at least one
overlapping character, the tags will be aligned.
Any alignment of the system output tags are scored
as a correct detection.
Sloopy span: Spans usually refer to strict match of
both boundaries (the extent) of a temporal expres-
sion (see Exact Match). “Sloopy” admits recog-
nized temporal expressions as long as their right
boundary is the same as in the corresponding
TimeBank’s extents (Boguraev and Ando, 2005).
The motivation was to assess the correctness of
temporal expressions recognized in TimeBank,
which was reported as inconsistent with respect to
some left boundary items, such as determiners and
pre-determiners.
Exact Match (Bracketing or Extent Recogni-
tion): Exact match measures the ability to correct-
ly identify the extent of the TIMEX. The extent of
the reference and the system output tags must
match exactly the system output tag to be scored as
correct.
</bodyText>
<subsectionHeader confidence="0.994593">
2.2 Datasets
</subsectionHeader>
<bodyText confidence="0.972866225">
To date, there are two annotated corpora used for
temporal evaluations, the ACE TERN corpus and
TimeBank (Pustejovsky et al., 2003a). In this sec-
tion we provide a brief description of the temporal
corpora and annotation standards, which can sub-
stantially influence recognition results.
Most of the implementations referred as the
state-of-the-art were developed in the scope of the
ACE TERN 2004. For evaluations, a training cor-
pus of 862 documents with about 306 thousand
words was provided. Each document represents a
news article formatted in XML, in which TIMEX2
tags denote temporal expressions. The total num-
ber of temporal expressions for training is 8047
TIMEX2 tags with an average of 10.5 per docu-
ment. The test set comprises 192 documents with
1828 TIMEX2 tags (Ferro, 2004).
The annotation of temporal expressions in the
ACE corpus was done with respect to the TIDES
annotation guidelines (Ferro et al., 2003). The
TIDES standard specifies so-called markable ex-
pressions, whose syntactic head must be an appro-
priate lexical trigger, e.g. “minute”, “afternoon”,
“Monday”, “8:00”, “future” etc. When tagged, the
full extent of the tag must correspond to one of the
grammatical categories: nouns (NN, NNP), noun
phrases (NP), adjectives (JJ), adjective phrases
(ADJP), adverbs (RB) and adverb phrases
(ADVP). According to this, all pre- and postmo-
difiers as well as dependent clauses are also in-
cluded to the TIMEX2 extent, e.g. “five days after
he came back”, “nearly four decades of expe-
rience”. Such a broad extent for annotations is of
course necessary for correct normalization, but on
the other hand, introduces difficulties for exact
match. Another important characteristic of the
TIDES standard are the nested temporal expres-
sions as for example:
&lt;TIMEX2&gt;The&lt;TIMEX2 VAL = &amp;quot;1994&amp;quot;&gt;1994
&lt;/TIMEX2&gt; baseball season &lt;/TIMEX2&gt;
</bodyText>
<page confidence="0.995619">
53
</page>
<bodyText confidence="0.999459842105263">
The most recent annotation language for tem-
poral expressions, TimeML (Pustejovsky et al.,
2003b), with an underlying corpus TimeBank
(Pustejovsky et al., 2003a), opens up new possibili-
ties for processing temporal information in text.
Besides the specification for temporal expressions,
i.e. TIMEX3, which is to a large extent inherited
from TIDES, TimeML provides a means to capture
temporal semantics by annotations with suitably
defined attributes for fine-grained specification of
analytical detail (Boguraev et al., 2007). The anno-
tation schema establishes new entity and relation
marking tags along with numerous attributes for
them. This advancement influenced the extent for
event-based temporal expression, in which depen-
dent clauses are no longer included into TIMEX3
tags. The TimeBank corpus includes 186 docu-
ments with 68.5 thousand words and 1423
TIMEX3 tags.
</bodyText>
<subsectionHeader confidence="0.822875">
2.3 Approaches for temporal processing
</subsectionHeader>
<bodyText confidence="0.996545393442623">
As for any recognition problem, there are two ma-
jor ways to solve it. Historically, rule-based sys-
tems were first implemented. Such systems are
characterized by a great human effort in data anal-
ysis and rule writing. With a high precision such
systems can be successfully employed for recogni-
tion of temporal expressions, whereas the recall
reflects the effort put into the rule development. By
contrast, machine learning methods require an an-
notated training set, and with a decent feature de-
sign and a minimal human effort can provide
comparable or even better results than rule-based
implementations. As the temporal expression rec-
ognition is not only about to detect them but also to
provide an exact match, machine learning ap-
proaches can be divided into token-by-token classi-
fication following B(egin)-I(nside)-O(utside)
encoding and binary constituent-based classifica-
tion, in which an entire chunk-phrase is under con-
sideration to be classified as a temporal expression
or not. In this case, exact segmentation is the re-
sponsibility of the chunker or the parser used.
Rule-based systems: One of the first well-known
implementations of temporal taggers was presented
in (Many and Wilson, 2000). The approach relies
on a set of hand-crafted and machine-discovered
rules, which are based upon shallow lexical fea-
tures. On average the system achieved a value of
83.2% for F1-measure against hand-annotated da-
ta. The dataset used comprised a set of 22 New
York Times articles and 199 transcripts of Voice of
America taken from the TDT2 collection (Graff et
al., 1999). It should be noted that the reported per-
formance was provided in terms of an exact match.
Another example of rule-based temporal taggers is
Chronos described in (Negri and Marseglia, 2004),
which achieved the highest scores (F1-measure) in
the TERN 2004 of 0.926 and 0.878 for recognition
and exact match.
Recognition of temporal expressions using
TimeBank as an annotated corpus, is reported in
(Boguraev and Ando, 2005) based on a cascaded
finite-state grammar (500 stages and 16000 transi-
tions). A complex approach achieved an F1-
measure value of 0.817 for exact match and 0.896
for detecting “sloopy” spans. Another known im-
plementation for TimeBank is an adaptation of
(Mani and Wilson, 2000) from TIMEX2 to
TIMEX3 with no reported performance level.
Machine learning recognition systems: Success-
ful machine learning TIMEX recognition systems
are described in (Ahn et al., 2005; Hacioglu et al.,
2005; Poveda et al., 2007). Proposed approaches
made use of a token-by-token classification for
temporal expressions represented by B-I-O encod-
ing with a set of lexical and syntactic features, e.g.,
token itself, part-of-speech tag, label in the chunk
phrase and the same features for each token in the
context window. The performance levels are pre-
sented in Table 1. All the results were obtained on
the ACE TERN dataset.
</bodyText>
<table confidence="0.995285714285714">
Approach F1 (detection) F1
(exact match)
Ahn et al., 2005 0.914 0.798
Hacioglu et al., 0.935 0.878
2005
Poveda et al., 0.986 0.757
2007
</table>
<tableCaption confidence="0.999947">
Table 1. Performance of Machine Learning Ap-
</tableCaption>
<subsectionHeader confidence="0.807438">
proaches with B-I-O Encoding
</subsectionHeader>
<bodyText confidence="0.9998215">
Constituent-based classification approach for
temporal expression recognition was presented in
(Ahn et al., 2007). By comparing to the previous
work (Ahn et al., 2005) on the same ACE TERN
dataset, the method demonstrates a slight decrease
in detection with F1-measure of 0.844 and a nearly
equivalent F1-measure value for exact match of
0.787.
</bodyText>
<page confidence="0.996586">
54
</page>
<bodyText confidence="0.841444">
forms categorization of constituent-phrases ex-
tracted from the input.
4 Experiments, Results and Error Analy-
sis
The major characteristic of machine learning
approaches was a simple system design with a mi-
nimal human effort. Machine-learning based rec-
ognition systems have proven to have a
comparable recognition performance level to state-
of-the-art rule-based detectors.
</bodyText>
<sectionHeader confidence="0.997363" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999267538461539">
The approach we describe in this section employs a
machine-learning technique and more specifically
a binary constituent based classification. In this
case the entire phrase is under consideration to be
labeled as a TIMEX or not. We restrict the classifi-
cation for the following phrase types and grammat-
ical categories: NN, NNP, CD, NP, JJ, ADJP, RB,
ADVP and PP. In order to make it possible, for
each sentence we parse the initial input line with a
Maximum Entropy parser (Ratnaparkhi, 1998) and
extract all phrase candidates with respect the types
defined above. Each phrase candidate is examined
against the manual annotations for temporal ex-
pressions found in the sentence. Those phrases,
which correspond to the temporal expressions in
the sentence are taken as positive examples, while
the rest are considered as negative ones. Only one
sub-tree from a parse is marked as positive for a
distinct TIMEX at once. After that, for each can-
didate we produce a feature vector, which includes
the following features: head phrase, head word,
part-of-speech for head word, character type and
character type pattern for head word as well as for
the entire phrase. Character type and character type
pattern1 features are implemented following Ahn et
al. (2005). The patterns are defined by using the
symbols X, x and 9. X and x are used for character
type as well as for character type patterns for
representing capital and lower-case letters for a
token. 9 is used for representing numeric tokens.
Once the character types are computed, the corres-
ponding character patterns are produced. A pattern
consists of the same symbols as character types,
and contains no sequential redundant occurrences
of the same symbol. For example, the constituent
“January 30th” has character type “Xxxxxxx
99xx” and pattern “X(x) (9)(x)”.
On this basis, we employ a classifier that im-
plements a Maximum Entropy model2 and per-
</bodyText>
<footnote confidence="0.991007">
1 In literature such patterns are also known as shorttypes.
2 http://maxent.sourceforge.net/
</footnote>
<bodyText confidence="0.99995688372093">
After processing the TimeBank corpus of 183
documents we had 2612 parsed sentences with
1224 temporal expressions in them. 2612 sentences
resulted in 49656 phrase candidates. We separated
the data in order to perform 10-fold cross valida-
tion, train the classifier and test it on an unseen
dataset. The evaluations were conducted with re-
spect to the TERN 2004 evaluation plan (TERN,
2004) and described in Section 2.1.
After running experiments the classifier demon-
strated the performance in detection of TIMEX3
tags with a minimal overlap of one character with
precision, recall and F1-measure at 0.872, 0.836
and 0.852 respectively. Since the candidate phrases
provided by the parser do not always exactly align
annotated temporal expressions, the results for the
exact match experiments are constrained by an es-
timated upper-bound recall of 0.919. The experi-
ments on exact match demonstrated a small decline
of performance level and received scores of 0.866,
0.796 and 0.828 for precision, recall and F1-
measure respectively.
Putting the received figures in context, we can
say that with a very few shallow features and a
standard machine learning algorithm the recogniz-
er of temporal expressions performed at a compa-
rable operational level to the rule-based approach
of (Boguraev and Ando, 2005) and outperformed it
in exact match. A comparative performance sum-
mary is presented in Table 2.
Sometimes it is very hard even for humans to
identify the use of obvious temporal triggers in a
specific context. As a result, many occurrences of
such triggers remained unannotated for which
TIMEX3 identification could not be properly car-
ried out. Apart of obvious incorrect parses, in-
exact alignment between temporal expressions and
candidate phrases was caused by annotations that
occurred at the middle of a phrase, for example
“eight-years-long”, “overnight”, “yesterday’s”. In
total there are 99 TIMEX3 tags (or 8.1%) misa-
ligned with the parser output, which resulted in 53
(or 4.3%) undetected TIMEX3s.
</bodyText>
<page confidence="0.994872">
55
</page>
<table confidence="0.9997021">
P R F1
Detection
Our approach 0.872 0.836 0.852
Sloopy Span
(Boguraev and 0.852 0.952 0.896
Ando, 2005)
Exact Match
Our approach 0.866 0.796 0.828
(Boguraev and 0.776 0.861 0.817
Ando, 2005)
</table>
<tableCaption confidence="0.999755">
Table 2. Comparative Performance Summary
</tableCaption>
<bodyText confidence="0.98128625">
Definite and indefinite articles are unsystemati-
cally left out or included into TIMEX3 extent,
which may introduce an additional bias in classifi-
cation.
</bodyText>
<sectionHeader confidence="0.99145" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.998378978723405">
In this paper we presented a machine learning
approach for detecting temporal expression using a
recent annotated corpus for temporal information,
TimeBank. Employing shallow syntactic and lexi-
cal features, the performance level of the method
achieved comparable results to a rule-based ap-
proach of Boguraev and Ando (2005) and for the
exact match task even outperforms it. Although a
direct comparison with other state-of-the-art sys-
tems is not possible, due to different evaluation
corpora, annotation standards and size in particu-
lar, our experiments disclose a very important cha-
racteristic. While the recognition systems in the
TERN 2004 reported a substantial drop of F1-
measure between detection and exact match results
(6.5 – 11.6%), our phrase-based detector demon-
strates a light decrease in F1-measure (2.4%), whe-
reas the precision declines only by 0.6%. This
important finding leads us to the conclusion that
most of TIMEX3s in TimeBank can be detected at
a phrase-based level with a reasonably high per-
formance.
Despite a good recognition performance level
there is, of course, room for improvement. Many
implementations in the TERN 2004 employ a set
of apparent temporal tokens as one of the features.
In our implementation, the classifier has difficul-
ties with very simple temporal expressions such as
“now”, “future”, “current”, “currently”, “recent”,
“recently”. A direct employment of vocabularies
with temporal tokens may substantially increase
the F1-measure of the method, however, it yet has
to be proven. As reported in (Ahn et al., 2007) a
precise recognition of temporal expressions is a
prerequisite for accurate normalization.
With our detector and a future normalizer we
are able make the first step towards solving the
TempEval-2 tasks, which introduce new challenges
in temporal information processing: identification
of events, identification of temporal expressions
and identification of temporal relations (Puste-
jovsky et al., 2009). Our future work will be fo-
cused on improving current results by a new
feature design, finalizing the normalization task
and identification of temporal relations. All these
components will result in a solid system infrastruc-
ture for all-around temporal analysis.
</bodyText>
<sectionHeader confidence="0.997477" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996813">
This work has been partly funded by the Flemish
government (through IWT) and by Space Applica-
tions Services NV as part of the ITEA2 project
LINDO (ITEA2-06011).
</bodyText>
<sectionHeader confidence="0.998144" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996443833333333">
Ahn, D., Adafre, S. F., and de Rijke, M. 2005. Extract-
ing Temporal Information from Open Domain Text:
A Comparative Exploration. Digital Information
Management, 3(1):14-20, 2005.
Ahn, D., van Rantwijk, J., and de Rijke, M. 2007. A
Cascaded Machine Learning Approach to Interpret-
ing Temporal Expressions. In Proceedings NAACL-
HLT 2007.
Boguraev, B., and Ando, R. K. 2005. TimeBank-Driven
TimeML Analysis. In Annotating, Extracting and
Reasoning about Time and Events. Dagstuhl Seminar
Proceedings. Dagstuhl, Germany
Boguraev, B., Pustejovsky, J., Ando, R., and Verhagen,
M. 2007. TimeBank Evolution as a Community Re-
source for TimeML Parsing. Language Resource and
Evaluation, 41(1): 91–115.
Ferro, L., Gerber, L., Mani, I., Sundheim, B., and Wil-
son, G. 2003. TIDES 2003 Standard for the Annota-
tion of Temporal Expressions. Sept. 2003.
timex2.mitre.org.
Ferro, L. 2004. TERN Evaluation Task Overview and
Corpus,
&lt;http://fofoca.mitre.org/tern_2004/ferro1_TERN200
4_task_corpus.pdf&gt; (accessed: 5.03.2009)
</reference>
<page confidence="0.966312">
56
</page>
<reference confidence="0.99898097826087">
Graff, D., Cieri, C., Strassel, S., and Martey, N. 1999.
The TDT-2 Text and Speech Corpus. In Proceedings
of DARPA Broadcast News Workshop, pp. 57-60.
Hacioglu, K., Chen, Y., and Douglas, B. 2005. Auto-
matic Time Expression Labeling for English and
Chinese Text. In Proceedings of CICLing-2005, pp.
348-359; Springer-Verlag, Lecture Notes in Comput-
er Science, vol. 3406.
Mani, I. and Wilson, G. 2000. Robust Temporal
Processing of News. In Proceedings of the 38th An-
nual Meeting on Association for Computational Lin-
guistics (Hong Kong, October 03 - 06, 2000). Annual
Meeting of the ACL. Association for Computational
Linguistics, Morristown, NJ, pp. 69-76.
Negri, M. and Marseglia, L. 2004. Recognition and
Normalization of Time Expressions: ITC-irst at
TERN 2004. Technical Report, ITC-irst, Trento.
Poveda, J., Surdeanu, M., and Turmo, J. 2007. A Com-
parison of Statistical and Rule-Induction Learners for
Automatic Tagging of Time Expressions in English.
In Proceedings of the International Symposium on
Temporal Representation and Reasoning, pp. 141-
149.
Pustejovsky, J., Hanks, P., Saurí, R., See, A., Day, D.,
Ferro, L., Gaizauskas, R., Lazo, M., Setzer, A., and
Sundheim, B. 2003a. The TimeBank Corpus. In Pro-
ceedings of Corpus Linguistics 2003, pp. 647-656.
Pustejovsky, J., Castaño, J., Ingria, R., Saurí, R., Gai-
zauskas, R., Setzer, A., and Katz, G. 2003b. Time-
ML: Robust Specification of Event and Temporal
Expressions in Text. In Proceedings of IWCS-5, Fifth
International Workshop on Computational Seman-
tics.
Pustejovsky, J., Verhagen, M., Nianwen, X., Gai-
zauskas, R., Hepple, M., Schilder, F., Katz, G., Saurí,
R., Saquete, E., Caselli, T., Calzolari, N., Lee, K.,
and Im, S. 2009. TempEval2: Evaluating Events,
Time Expressions and Temporal Relations.
&lt;http://www.timeml.org/tempeval2/tempeval2-
proposal.pdf&gt; (accessed: 5.03.2009)
Ratnaparkhi, A. 1999. Learning to Parse Natural Lan-
guage with Maximum Entropy Models. Machine
Learning, 34(1): 151-175.
TERN 2004 Evaluation Plan, 2004,
&lt;http://fofoca.mitre.org/tern_2004/tern_evalplan-
2004.29apr04.pdf&gt; (accessed: 5.03.2009)
</reference>
<page confidence="0.999127">
57
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.255387">
<title confidence="0.929212">Meeting TempEval-2: Shallow Approach for Temporal Tagger Oleksandr</title>
<author confidence="0.825979">Katholieke Universiteit</author>
<affiliation confidence="0.995982">Department of Computer</affiliation>
<address confidence="0.953004">Celestijnenlaan 200A, Heverlee,</address>
<email confidence="0.964949">@cs.kuleuven.be</email>
<title confidence="0.41967">Marie-Francine</title>
<author confidence="0.677338">Katholieke Universiteit</author>
<affiliation confidence="0.996222">Department of Computer</affiliation>
<address confidence="0.956448">Celestijnenlaan 200A, Heverlee,</address>
<email confidence="0.987608">sien.moens@cs.kuleuven.be</email>
<abstract confidence="0.998445352941176">Temporal expressions are one of the important structures in natural language. In order to understand text, temporal expressions have to be identified and normalized by providing ISObased values. In this paper we present a shallow approach for automatic recognition of temporal expressions based on a supervised machine learning approach trained on an annotated corpus for temporal information, namely TimeBank. Our experiments demonstrate a performance level comparable to a rule-based implementation and achieve the scores of 0.872, 0.836 and 0.852 for precision, recall and F1-measure for the detection task respectively, and 0.866, 0.796, 0.828 when an exact match is required.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Ahn</author>
<author>S F Adafre</author>
<author>M de Rijke</author>
</authors>
<title>Extracting Temporal Information from Open Domain Text: A Comparative Exploration.</title>
<date>2005</date>
<journal>Digital Information Management,</journal>
<pages>3--1</pages>
<marker>Ahn, Adafre, de Rijke, 2005</marker>
<rawString>Ahn, D., Adafre, S. F., and de Rijke, M. 2005. Extracting Temporal Information from Open Domain Text: A Comparative Exploration. Digital Information Management, 3(1):14-20, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ahn</author>
<author>J van Rantwijk</author>
<author>M de Rijke</author>
</authors>
<title>A Cascaded Machine Learning Approach to Interpreting Temporal Expressions.</title>
<date>2007</date>
<booktitle>In Proceedings NAACLHLT</booktitle>
<marker>Ahn, van Rantwijk, de Rijke, 2007</marker>
<rawString>Ahn, D., van Rantwijk, J., and de Rijke, M. 2007. A Cascaded Machine Learning Approach to Interpreting Temporal Expressions. In Proceedings NAACLHLT 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Boguraev</author>
<author>R K Ando</author>
</authors>
<title>TimeBank-Driven TimeML Analysis. In Annotating, Extracting and Reasoning about Time and Events. Dagstuhl Seminar Proceedings.</title>
<date>2005</date>
<location>Dagstuhl, Germany</location>
<contexts>
<context position="5299" citStr="Boguraev and Ando, 2005" startWordPosition="791" endWordPosition="794">ask, in which temporally relevant expressions have to be found. The scoring is very generous and implies a minimal overlap in the extent of the reference and the system output tags. As long as there is at least one overlapping character, the tags will be aligned. Any alignment of the system output tags are scored as a correct detection. Sloopy span: Spans usually refer to strict match of both boundaries (the extent) of a temporal expression (see Exact Match). “Sloopy” admits recognized temporal expressions as long as their right boundary is the same as in the corresponding TimeBank’s extents (Boguraev and Ando, 2005). The motivation was to assess the correctness of temporal expressions recognized in TimeBank, which was reported as inconsistent with respect to some left boundary items, such as determiners and pre-determiners. Exact Match (Bracketing or Extent Recognition): Exact match measures the ability to correctly identify the extent of the TIMEX. The extent of the reference and the system output tags must match exactly the system output tag to be scored as correct. 2.2 Datasets To date, there are two annotated corpora used for temporal evaluations, the ACE TERN corpus and TimeBank (Pustejovsky et al.,</context>
<context position="10519" citStr="Boguraev and Ando, 2005" startWordPosition="1605" endWordPosition="1608">2% for F1-measure against hand-annotated data. The dataset used comprised a set of 22 New York Times articles and 199 transcripts of Voice of America taken from the TDT2 collection (Graff et al., 1999). It should be noted that the reported performance was provided in terms of an exact match. Another example of rule-based temporal taggers is Chronos described in (Negri and Marseglia, 2004), which achieved the highest scores (F1-measure) in the TERN 2004 of 0.926 and 0.878 for recognition and exact match. Recognition of temporal expressions using TimeBank as an annotated corpus, is reported in (Boguraev and Ando, 2005) based on a cascaded finite-state grammar (500 stages and 16000 transitions). A complex approach achieved an F1- measure value of 0.817 for exact match and 0.896 for detecting “sloopy” spans. Another known implementation for TimeBank is an adaptation of (Mani and Wilson, 2000) from TIMEX2 to TIMEX3 with no reported performance level. Machine learning recognition systems: Successful machine learning TIMEX recognition systems are described in (Ahn et al., 2005; Hacioglu et al., 2005; Poveda et al., 2007). Proposed approaches made use of a token-by-token classification for temporal expressions re</context>
<context position="15657" citStr="Boguraev and Ando, 2005" startWordPosition="2421" endWordPosition="2424">he parser do not always exactly align annotated temporal expressions, the results for the exact match experiments are constrained by an estimated upper-bound recall of 0.919. The experiments on exact match demonstrated a small decline of performance level and received scores of 0.866, 0.796 and 0.828 for precision, recall and F1- measure respectively. Putting the received figures in context, we can say that with a very few shallow features and a standard machine learning algorithm the recognizer of temporal expressions performed at a comparable operational level to the rule-based approach of (Boguraev and Ando, 2005) and outperformed it in exact match. A comparative performance summary is presented in Table 2. Sometimes it is very hard even for humans to identify the use of obvious temporal triggers in a specific context. As a result, many occurrences of such triggers remained unannotated for which TIMEX3 identification could not be properly carried out. Apart of obvious incorrect parses, inexact alignment between temporal expressions and candidate phrases was caused by annotations that occurred at the middle of a phrase, for example “eight-years-long”, “overnight”, “yesterday’s”. In total there are 99 TI</context>
<context position="17103" citStr="Boguraev and Ando (2005)" startWordPosition="2646" endWordPosition="2649">ch Our approach 0.866 0.796 0.828 (Boguraev and 0.776 0.861 0.817 Ando, 2005) Table 2. Comparative Performance Summary Definite and indefinite articles are unsystematically left out or included into TIMEX3 extent, which may introduce an additional bias in classification. 5 Conclusion and Future Work In this paper we presented a machine learning approach for detecting temporal expression using a recent annotated corpus for temporal information, TimeBank. Employing shallow syntactic and lexical features, the performance level of the method achieved comparable results to a rule-based approach of Boguraev and Ando (2005) and for the exact match task even outperforms it. Although a direct comparison with other state-of-the-art systems is not possible, due to different evaluation corpora, annotation standards and size in particular, our experiments disclose a very important characteristic. While the recognition systems in the TERN 2004 reported a substantial drop of F1- measure between detection and exact match results (6.5 – 11.6%), our phrase-based detector demonstrates a light decrease in F1-measure (2.4%), whereas the precision declines only by 0.6%. This important finding leads us to the conclusion that mo</context>
</contexts>
<marker>Boguraev, Ando, 2005</marker>
<rawString>Boguraev, B., and Ando, R. K. 2005. TimeBank-Driven TimeML Analysis. In Annotating, Extracting and Reasoning about Time and Events. Dagstuhl Seminar Proceedings. Dagstuhl, Germany</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Boguraev</author>
<author>J Pustejovsky</author>
<author>R Ando</author>
<author>M Verhagen</author>
</authors>
<title>TimeBank Evolution as a Community Resource for TimeML Parsing. Language Resource and Evaluation,</title>
<date>2007</date>
<volume>41</volume>
<issue>1</issue>
<pages>91--115</pages>
<contexts>
<context position="8139" citStr="Boguraev et al., 2007" startWordPosition="1230" endWordPosition="1233">ions as for example: &lt;TIMEX2&gt;The&lt;TIMEX2 VAL = &amp;quot;1994&amp;quot;&gt;1994 &lt;/TIMEX2&gt; baseball season &lt;/TIMEX2&gt; 53 The most recent annotation language for temporal expressions, TimeML (Pustejovsky et al., 2003b), with an underlying corpus TimeBank (Pustejovsky et al., 2003a), opens up new possibilities for processing temporal information in text. Besides the specification for temporal expressions, i.e. TIMEX3, which is to a large extent inherited from TIDES, TimeML provides a means to capture temporal semantics by annotations with suitably defined attributes for fine-grained specification of analytical detail (Boguraev et al., 2007). The annotation schema establishes new entity and relation marking tags along with numerous attributes for them. This advancement influenced the extent for event-based temporal expression, in which dependent clauses are no longer included into TIMEX3 tags. The TimeBank corpus includes 186 documents with 68.5 thousand words and 1423 TIMEX3 tags. 2.3 Approaches for temporal processing As for any recognition problem, there are two major ways to solve it. Historically, rule-based systems were first implemented. Such systems are characterized by a great human effort in data analysis and rule writi</context>
</contexts>
<marker>Boguraev, Pustejovsky, Ando, Verhagen, 2007</marker>
<rawString>Boguraev, B., Pustejovsky, J., Ando, R., and Verhagen, M. 2007. TimeBank Evolution as a Community Resource for TimeML Parsing. Language Resource and Evaluation, 41(1): 91–115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ferro</author>
<author>L Gerber</author>
<author>I Mani</author>
<author>B Sundheim</author>
<author>G Wilson</author>
</authors>
<title>Standard for the Annotation of Temporal Expressions.</title>
<date>2003</date>
<tech>TIDES</tech>
<pages>2</pages>
<contexts>
<context position="6695" citStr="Ferro et al., 2003" startWordPosition="1015" endWordPosition="1018">ementations referred as the state-of-the-art were developed in the scope of the ACE TERN 2004. For evaluations, a training corpus of 862 documents with about 306 thousand words was provided. Each document represents a news article formatted in XML, in which TIMEX2 tags denote temporal expressions. The total number of temporal expressions for training is 8047 TIMEX2 tags with an average of 10.5 per document. The test set comprises 192 documents with 1828 TIMEX2 tags (Ferro, 2004). The annotation of temporal expressions in the ACE corpus was done with respect to the TIDES annotation guidelines (Ferro et al., 2003). The TIDES standard specifies so-called markable expressions, whose syntactic head must be an appropriate lexical trigger, e.g. “minute”, “afternoon”, “Monday”, “8:00”, “future” etc. When tagged, the full extent of the tag must correspond to one of the grammatical categories: nouns (NN, NNP), noun phrases (NP), adjectives (JJ), adjective phrases (ADJP), adverbs (RB) and adverb phrases (ADVP). According to this, all pre- and postmodifiers as well as dependent clauses are also included to the TIMEX2 extent, e.g. “five days after he came back”, “nearly four decades of experience”. Such a broad e</context>
</contexts>
<marker>Ferro, Gerber, Mani, Sundheim, Wilson, 2003</marker>
<rawString>Ferro, L., Gerber, L., Mani, I., Sundheim, B., and Wilson, G. 2003. TIDES 2003 Standard for the Annotation of Temporal Expressions. Sept. 2003. timex2.mitre.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ferro</author>
</authors>
<title>TERN Evaluation Task Overview and Corpus, 4_task_corpus.pdf&gt; (accessed:</title>
<date>2004</date>
<pages>5--03</pages>
<contexts>
<context position="6559" citStr="Ferro, 2004" startWordPosition="995" endWordPosition="996">ription of the temporal corpora and annotation standards, which can substantially influence recognition results. Most of the implementations referred as the state-of-the-art were developed in the scope of the ACE TERN 2004. For evaluations, a training corpus of 862 documents with about 306 thousand words was provided. Each document represents a news article formatted in XML, in which TIMEX2 tags denote temporal expressions. The total number of temporal expressions for training is 8047 TIMEX2 tags with an average of 10.5 per document. The test set comprises 192 documents with 1828 TIMEX2 tags (Ferro, 2004). The annotation of temporal expressions in the ACE corpus was done with respect to the TIDES annotation guidelines (Ferro et al., 2003). The TIDES standard specifies so-called markable expressions, whose syntactic head must be an appropriate lexical trigger, e.g. “minute”, “afternoon”, “Monday”, “8:00”, “future” etc. When tagged, the full extent of the tag must correspond to one of the grammatical categories: nouns (NN, NNP), noun phrases (NP), adjectives (JJ), adjective phrases (ADJP), adverbs (RB) and adverb phrases (ADVP). According to this, all pre- and postmodifiers as well as dependent </context>
</contexts>
<marker>Ferro, 2004</marker>
<rawString>Ferro, L. 2004. TERN Evaluation Task Overview and Corpus, 4_task_corpus.pdf&gt; (accessed: 5.03.2009)</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Graff</author>
<author>C Cieri</author>
<author>S Strassel</author>
<author>N Martey</author>
</authors>
<title>The TDT-2 Text and Speech Corpus.</title>
<date>1999</date>
<booktitle>In Proceedings of DARPA Broadcast News Workshop,</booktitle>
<pages>57--60</pages>
<contexts>
<context position="10096" citStr="Graff et al., 1999" startWordPosition="1538" endWordPosition="1541">d as a temporal expression or not. In this case, exact segmentation is the responsibility of the chunker or the parser used. Rule-based systems: One of the first well-known implementations of temporal taggers was presented in (Many and Wilson, 2000). The approach relies on a set of hand-crafted and machine-discovered rules, which are based upon shallow lexical features. On average the system achieved a value of 83.2% for F1-measure against hand-annotated data. The dataset used comprised a set of 22 New York Times articles and 199 transcripts of Voice of America taken from the TDT2 collection (Graff et al., 1999). It should be noted that the reported performance was provided in terms of an exact match. Another example of rule-based temporal taggers is Chronos described in (Negri and Marseglia, 2004), which achieved the highest scores (F1-measure) in the TERN 2004 of 0.926 and 0.878 for recognition and exact match. Recognition of temporal expressions using TimeBank as an annotated corpus, is reported in (Boguraev and Ando, 2005) based on a cascaded finite-state grammar (500 stages and 16000 transitions). A complex approach achieved an F1- measure value of 0.817 for exact match and 0.896 for detecting “</context>
</contexts>
<marker>Graff, Cieri, Strassel, Martey, 1999</marker>
<rawString>Graff, D., Cieri, C., Strassel, S., and Martey, N. 1999. The TDT-2 Text and Speech Corpus. In Proceedings of DARPA Broadcast News Workshop, pp. 57-60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hacioglu</author>
<author>Y Chen</author>
<author>B Douglas</author>
</authors>
<title>Automatic Time Expression Labeling for English and Chinese Text.</title>
<date>2005</date>
<journal>Lecture Notes in Computer Science,</journal>
<booktitle>In Proceedings of CICLing-2005,</booktitle>
<volume>vol.</volume>
<pages>348--359</pages>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="11004" citStr="Hacioglu et al., 2005" startWordPosition="1681" endWordPosition="1684">ion and exact match. Recognition of temporal expressions using TimeBank as an annotated corpus, is reported in (Boguraev and Ando, 2005) based on a cascaded finite-state grammar (500 stages and 16000 transitions). A complex approach achieved an F1- measure value of 0.817 for exact match and 0.896 for detecting “sloopy” spans. Another known implementation for TimeBank is an adaptation of (Mani and Wilson, 2000) from TIMEX2 to TIMEX3 with no reported performance level. Machine learning recognition systems: Successful machine learning TIMEX recognition systems are described in (Ahn et al., 2005; Hacioglu et al., 2005; Poveda et al., 2007). Proposed approaches made use of a token-by-token classification for temporal expressions represented by B-I-O encoding with a set of lexical and syntactic features, e.g., token itself, part-of-speech tag, label in the chunk phrase and the same features for each token in the context window. The performance levels are presented in Table 1. All the results were obtained on the ACE TERN dataset. Approach F1 (detection) F1 (exact match) Ahn et al., 2005 0.914 0.798 Hacioglu et al., 0.935 0.878 2005 Poveda et al., 0.986 0.757 2007 Table 1. Performance of Machine Learning Appr</context>
</contexts>
<marker>Hacioglu, Chen, Douglas, 2005</marker>
<rawString>Hacioglu, K., Chen, Y., and Douglas, B. 2005. Automatic Time Expression Labeling for English and Chinese Text. In Proceedings of CICLing-2005, pp. 348-359; Springer-Verlag, Lecture Notes in Computer Science, vol. 3406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>G Wilson</author>
</authors>
<title>Robust Temporal Processing of News.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics (Hong Kong, October 03 - 06,</booktitle>
<pages>69--76</pages>
<location>Morristown, NJ,</location>
<contexts>
<context position="10796" citStr="Mani and Wilson, 2000" startWordPosition="1650" endWordPosition="1653"> exact match. Another example of rule-based temporal taggers is Chronos described in (Negri and Marseglia, 2004), which achieved the highest scores (F1-measure) in the TERN 2004 of 0.926 and 0.878 for recognition and exact match. Recognition of temporal expressions using TimeBank as an annotated corpus, is reported in (Boguraev and Ando, 2005) based on a cascaded finite-state grammar (500 stages and 16000 transitions). A complex approach achieved an F1- measure value of 0.817 for exact match and 0.896 for detecting “sloopy” spans. Another known implementation for TimeBank is an adaptation of (Mani and Wilson, 2000) from TIMEX2 to TIMEX3 with no reported performance level. Machine learning recognition systems: Successful machine learning TIMEX recognition systems are described in (Ahn et al., 2005; Hacioglu et al., 2005; Poveda et al., 2007). Proposed approaches made use of a token-by-token classification for temporal expressions represented by B-I-O encoding with a set of lexical and syntactic features, e.g., token itself, part-of-speech tag, label in the chunk phrase and the same features for each token in the context window. The performance levels are presented in Table 1. All the results were obtaine</context>
</contexts>
<marker>Mani, Wilson, 2000</marker>
<rawString>Mani, I. and Wilson, G. 2000. Robust Temporal Processing of News. In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics (Hong Kong, October 03 - 06, 2000). Annual Meeting of the ACL. Association for Computational Linguistics, Morristown, NJ, pp. 69-76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>L Marseglia</author>
</authors>
<title>Recognition and Normalization of Time Expressions: ITC-irst at TERN</title>
<date>2004</date>
<tech>Technical Report, ITC-irst,</tech>
<location>Trento.</location>
<contexts>
<context position="10286" citStr="Negri and Marseglia, 2004" startWordPosition="1569" endWordPosition="1572">tions of temporal taggers was presented in (Many and Wilson, 2000). The approach relies on a set of hand-crafted and machine-discovered rules, which are based upon shallow lexical features. On average the system achieved a value of 83.2% for F1-measure against hand-annotated data. The dataset used comprised a set of 22 New York Times articles and 199 transcripts of Voice of America taken from the TDT2 collection (Graff et al., 1999). It should be noted that the reported performance was provided in terms of an exact match. Another example of rule-based temporal taggers is Chronos described in (Negri and Marseglia, 2004), which achieved the highest scores (F1-measure) in the TERN 2004 of 0.926 and 0.878 for recognition and exact match. Recognition of temporal expressions using TimeBank as an annotated corpus, is reported in (Boguraev and Ando, 2005) based on a cascaded finite-state grammar (500 stages and 16000 transitions). A complex approach achieved an F1- measure value of 0.817 for exact match and 0.896 for detecting “sloopy” spans. Another known implementation for TimeBank is an adaptation of (Mani and Wilson, 2000) from TIMEX2 to TIMEX3 with no reported performance level. Machine learning recognition sy</context>
</contexts>
<marker>Negri, Marseglia, 2004</marker>
<rawString>Negri, M. and Marseglia, L. 2004. Recognition and Normalization of Time Expressions: ITC-irst at TERN 2004. Technical Report, ITC-irst, Trento.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Poveda</author>
<author>M Surdeanu</author>
<author>J Turmo</author>
</authors>
<title>A Comparison of Statistical and Rule-Induction Learners for Automatic Tagging of Time Expressions in English.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Symposium on Temporal Representation and Reasoning,</booktitle>
<pages>141--149</pages>
<contexts>
<context position="11026" citStr="Poveda et al., 2007" startWordPosition="1685" endWordPosition="1688">cognition of temporal expressions using TimeBank as an annotated corpus, is reported in (Boguraev and Ando, 2005) based on a cascaded finite-state grammar (500 stages and 16000 transitions). A complex approach achieved an F1- measure value of 0.817 for exact match and 0.896 for detecting “sloopy” spans. Another known implementation for TimeBank is an adaptation of (Mani and Wilson, 2000) from TIMEX2 to TIMEX3 with no reported performance level. Machine learning recognition systems: Successful machine learning TIMEX recognition systems are described in (Ahn et al., 2005; Hacioglu et al., 2005; Poveda et al., 2007). Proposed approaches made use of a token-by-token classification for temporal expressions represented by B-I-O encoding with a set of lexical and syntactic features, e.g., token itself, part-of-speech tag, label in the chunk phrase and the same features for each token in the context window. The performance levels are presented in Table 1. All the results were obtained on the ACE TERN dataset. Approach F1 (detection) F1 (exact match) Ahn et al., 2005 0.914 0.798 Hacioglu et al., 0.935 0.878 2005 Poveda et al., 0.986 0.757 2007 Table 1. Performance of Machine Learning Approaches with B-I-O Enco</context>
</contexts>
<marker>Poveda, Surdeanu, Turmo, 2007</marker>
<rawString>Poveda, J., Surdeanu, M., and Turmo, J. 2007. A Comparison of Statistical and Rule-Induction Learners for Automatic Tagging of Time Expressions in English. In Proceedings of the International Symposium on Temporal Representation and Reasoning, pp. 141-149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>P Hanks</author>
<author>R Saurí</author>
<author>A See</author>
<author>D Day</author>
<author>L Ferro</author>
<author>R Gaizauskas</author>
<author>M Lazo</author>
<author>A Setzer</author>
<author>B Sundheim</author>
</authors>
<title>The TimeBank Corpus.</title>
<date>2003</date>
<booktitle>In Proceedings of Corpus Linguistics</booktitle>
<pages>647--656</pages>
<contexts>
<context position="2867" citStr="Pustejovsky et al., 2003" startWordPosition="408" endWordPosition="411">mpEval-2007 was solely focused on recognition of temporal links, the TempEval-2 tasks aim at an all-around temporal processing with separate evaluations for recognition of temporal expressions and events, for the estimation of temporal relations between events and times in the same sentence, between events and document creation time, between two events in consecutive sentences and between two events, where one of them syntactically dominates the other (Pustejovsky et al., 2009). These evaluations became possible with a new freely available corpus with annotated temporal information, TimeBank (Pustejovsky et al., 2003a), and an annotation schema, called TimeML (Pustejovsky et al., 2003b). For us all the tasks of TempEval-2 seem to be interesting. In this paper we make the first step towards a comprehensive temporal analysis and address the problem of temporal expression recognition as it is set in TempEval-2. Despite a number of previous implementations mainly done in the context of the ACE TERN competition, very few, Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 52–57, Boulder, Colorado, June 2009. c�2009 Association for Computational Lingu</context>
<context position="5904" citStr="Pustejovsky et al., 2003" startWordPosition="887" endWordPosition="890">aev and Ando, 2005). The motivation was to assess the correctness of temporal expressions recognized in TimeBank, which was reported as inconsistent with respect to some left boundary items, such as determiners and pre-determiners. Exact Match (Bracketing or Extent Recognition): Exact match measures the ability to correctly identify the extent of the TIMEX. The extent of the reference and the system output tags must match exactly the system output tag to be scored as correct. 2.2 Datasets To date, there are two annotated corpora used for temporal evaluations, the ACE TERN corpus and TimeBank (Pustejovsky et al., 2003a). In this section we provide a brief description of the temporal corpora and annotation standards, which can substantially influence recognition results. Most of the implementations referred as the state-of-the-art were developed in the scope of the ACE TERN 2004. For evaluations, a training corpus of 862 documents with about 306 thousand words was provided. Each document represents a news article formatted in XML, in which TIMEX2 tags denote temporal expressions. The total number of temporal expressions for training is 8047 TIMEX2 tags with an average of 10.5 per document. The test set comp</context>
<context position="7708" citStr="Pustejovsky et al., 2003" startWordPosition="1169" endWordPosition="1172">(ADVP). According to this, all pre- and postmodifiers as well as dependent clauses are also included to the TIMEX2 extent, e.g. “five days after he came back”, “nearly four decades of experience”. Such a broad extent for annotations is of course necessary for correct normalization, but on the other hand, introduces difficulties for exact match. Another important characteristic of the TIDES standard are the nested temporal expressions as for example: &lt;TIMEX2&gt;The&lt;TIMEX2 VAL = &amp;quot;1994&amp;quot;&gt;1994 &lt;/TIMEX2&gt; baseball season &lt;/TIMEX2&gt; 53 The most recent annotation language for temporal expressions, TimeML (Pustejovsky et al., 2003b), with an underlying corpus TimeBank (Pustejovsky et al., 2003a), opens up new possibilities for processing temporal information in text. Besides the specification for temporal expressions, i.e. TIMEX3, which is to a large extent inherited from TIDES, TimeML provides a means to capture temporal semantics by annotations with suitably defined attributes for fine-grained specification of analytical detail (Boguraev et al., 2007). The annotation schema establishes new entity and relation marking tags along with numerous attributes for them. This advancement influenced the extent for event-based </context>
</contexts>
<marker>Pustejovsky, Hanks, Saurí, See, Day, Ferro, Gaizauskas, Lazo, Setzer, Sundheim, 2003</marker>
<rawString>Pustejovsky, J., Hanks, P., Saurí, R., See, A., Day, D., Ferro, L., Gaizauskas, R., Lazo, M., Setzer, A., and Sundheim, B. 2003a. The TimeBank Corpus. In Proceedings of Corpus Linguistics 2003, pp. 647-656.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>J Castaño</author>
<author>R Ingria</author>
<author>R Saurí</author>
<author>R Gaizauskas</author>
<author>A Setzer</author>
<author>G Katz</author>
</authors>
<title>TimeML: Robust Specification of Event and Temporal Expressions in Text.</title>
<date>2003</date>
<booktitle>In Proceedings of IWCS-5, Fifth International Workshop on Computational Semantics.</booktitle>
<contexts>
<context position="2867" citStr="Pustejovsky et al., 2003" startWordPosition="408" endWordPosition="411">mpEval-2007 was solely focused on recognition of temporal links, the TempEval-2 tasks aim at an all-around temporal processing with separate evaluations for recognition of temporal expressions and events, for the estimation of temporal relations between events and times in the same sentence, between events and document creation time, between two events in consecutive sentences and between two events, where one of them syntactically dominates the other (Pustejovsky et al., 2009). These evaluations became possible with a new freely available corpus with annotated temporal information, TimeBank (Pustejovsky et al., 2003a), and an annotation schema, called TimeML (Pustejovsky et al., 2003b). For us all the tasks of TempEval-2 seem to be interesting. In this paper we make the first step towards a comprehensive temporal analysis and address the problem of temporal expression recognition as it is set in TempEval-2. Despite a number of previous implementations mainly done in the context of the ACE TERN competition, very few, Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 52–57, Boulder, Colorado, June 2009. c�2009 Association for Computational Lingu</context>
<context position="5904" citStr="Pustejovsky et al., 2003" startWordPosition="887" endWordPosition="890">aev and Ando, 2005). The motivation was to assess the correctness of temporal expressions recognized in TimeBank, which was reported as inconsistent with respect to some left boundary items, such as determiners and pre-determiners. Exact Match (Bracketing or Extent Recognition): Exact match measures the ability to correctly identify the extent of the TIMEX. The extent of the reference and the system output tags must match exactly the system output tag to be scored as correct. 2.2 Datasets To date, there are two annotated corpora used for temporal evaluations, the ACE TERN corpus and TimeBank (Pustejovsky et al., 2003a). In this section we provide a brief description of the temporal corpora and annotation standards, which can substantially influence recognition results. Most of the implementations referred as the state-of-the-art were developed in the scope of the ACE TERN 2004. For evaluations, a training corpus of 862 documents with about 306 thousand words was provided. Each document represents a news article formatted in XML, in which TIMEX2 tags denote temporal expressions. The total number of temporal expressions for training is 8047 TIMEX2 tags with an average of 10.5 per document. The test set comp</context>
<context position="7708" citStr="Pustejovsky et al., 2003" startWordPosition="1169" endWordPosition="1172">(ADVP). According to this, all pre- and postmodifiers as well as dependent clauses are also included to the TIMEX2 extent, e.g. “five days after he came back”, “nearly four decades of experience”. Such a broad extent for annotations is of course necessary for correct normalization, but on the other hand, introduces difficulties for exact match. Another important characteristic of the TIDES standard are the nested temporal expressions as for example: &lt;TIMEX2&gt;The&lt;TIMEX2 VAL = &amp;quot;1994&amp;quot;&gt;1994 &lt;/TIMEX2&gt; baseball season &lt;/TIMEX2&gt; 53 The most recent annotation language for temporal expressions, TimeML (Pustejovsky et al., 2003b), with an underlying corpus TimeBank (Pustejovsky et al., 2003a), opens up new possibilities for processing temporal information in text. Besides the specification for temporal expressions, i.e. TIMEX3, which is to a large extent inherited from TIDES, TimeML provides a means to capture temporal semantics by annotations with suitably defined attributes for fine-grained specification of analytical detail (Boguraev et al., 2007). The annotation schema establishes new entity and relation marking tags along with numerous attributes for them. This advancement influenced the extent for event-based </context>
</contexts>
<marker>Pustejovsky, Castaño, Ingria, Saurí, Gaizauskas, Setzer, Katz, 2003</marker>
<rawString>Pustejovsky, J., Castaño, J., Ingria, R., Saurí, R., Gaizauskas, R., Setzer, A., and Katz, G. 2003b. TimeML: Robust Specification of Event and Temporal Expressions in Text. In Proceedings of IWCS-5, Fifth International Workshop on Computational Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>M Verhagen</author>
<author>X Nianwen</author>
<author>R Gaizauskas</author>
<author>M Hepple</author>
<author>F Schilder</author>
<author>G Katz</author>
<author>R Saurí</author>
<author>E Saquete</author>
<author>T Caselli</author>
<author>N Calzolari</author>
<author>K Lee</author>
<author>S Im</author>
</authors>
<title>TempEval2: Evaluating Events, Time Expressions and Temporal Relations.</title>
<date>2009</date>
<tech>accessed:</tech>
<pages>5--03</pages>
<contexts>
<context position="2725" citStr="Pustejovsky et al., 2009" startWordPosition="389" endWordPosition="392"> successor of TempEval-2007 and will take place in 2010. The new evaluation initiative sets new challenges for temporal text analysis. While TempEval-2007 was solely focused on recognition of temporal links, the TempEval-2 tasks aim at an all-around temporal processing with separate evaluations for recognition of temporal expressions and events, for the estimation of temporal relations between events and times in the same sentence, between events and document creation time, between two events in consecutive sentences and between two events, where one of them syntactically dominates the other (Pustejovsky et al., 2009). These evaluations became possible with a new freely available corpus with annotated temporal information, TimeBank (Pustejovsky et al., 2003a), and an annotation schema, called TimeML (Pustejovsky et al., 2003b). For us all the tasks of TempEval-2 seem to be interesting. In this paper we make the first step towards a comprehensive temporal analysis and address the problem of temporal expression recognition as it is set in TempEval-2. Despite a number of previous implementations mainly done in the context of the ACE TERN competition, very few, Proceedings of the NAACL HLT Workshop on Semantic</context>
</contexts>
<marker>Pustejovsky, Verhagen, Nianwen, Gaizauskas, Hepple, Schilder, Katz, Saurí, Saquete, Caselli, Calzolari, Lee, Im, 2009</marker>
<rawString>Pustejovsky, J., Verhagen, M., Nianwen, X., Gaizauskas, R., Hepple, M., Schilder, F., Katz, G., Saurí, R., Saquete, E., Caselli, T., Calzolari, N., Lee, K., and Im, S. 2009. TempEval2: Evaluating Events, Time Expressions and Temporal Relations. &lt;http://www.timeml.org/tempeval2/tempeval2-proposal.pdf&gt; (accessed: 5.03.2009)</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>Learning to Parse Natural Language with Maximum Entropy Models.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>34</volume>
<issue>1</issue>
<pages>151--175</pages>
<marker>Ratnaparkhi, 1999</marker>
<rawString>Ratnaparkhi, A. 1999. Learning to Parse Natural Language with Maximum Entropy Models. Machine Learning, 34(1): 151-175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TERN</author>
</authors>
<title>Evaluation Plan,</title>
<date>2004</date>
<pages>5--03</pages>
<contexts>
<context position="1767" citStr="TERN 2004" startWordPosition="245" endWordPosition="246">ons or simply TIMEX) was first introduced in the Message Understanding Conference (MUC) in 1995. Temporal expressions were treated as a part of the Named Entity Recognition (NER) task, in which capitalized tokens in text were labeled with one of the predefined semantic labels, such as Date, Time, Person, Organization, Location, Percentage, and Money. As the types of temporal entities identified in this way were too restricted and provided little further information, the Automated Content Extraction (ACE) launched a competition campaign 52 for Temporal Expression Recognition and Normalization (TERN 2004). The tasks were to identify temporal expressions in free text and normalize them providing an ISO-based date-time value. Later evaluations of ACE in 2005, 2006 and 2007 unfortunately did not set new challenges for temporal expression recognition and thus the participation interest in this particular task decreased. TempEval-2 is a successor of TempEval-2007 and will take place in 2010. The new evaluation initiative sets new challenges for temporal text analysis. While TempEval-2007 was solely focused on recognition of temporal links, the TempEval-2 tasks aim at an all-around temporal processi</context>
<context position="4593" citStr="TERN, 2004" startWordPosition="675" endWordPosition="676">ion 3 describes the approach; experimental setup, results and error analysis are provided in Section 4. Finally, Section 5 gives an outlook for further improvements and research. 2 Related Work For better understanding of the performance levels provided in the paper we first describe evaluation metrics defined for the temporal expression recognition task and then the methods and datasets used in previous research. 2.1 Evaluation metrics With the start of the ACE TERN competition in 2004, two major evaluation conditions were proposed: Recognition+Normalization (full task) and Recognition only (TERN, 2004). Detection (Recognition): Detection is a preliminary task towards the full TERN task, in which temporally relevant expressions have to be found. The scoring is very generous and implies a minimal overlap in the extent of the reference and the system output tags. As long as there is at least one overlapping character, the tags will be aligned. Any alignment of the system output tags are scored as a correct detection. Sloopy span: Spans usually refer to strict match of both boundaries (the extent) of a temporal expression (see Exact Match). “Sloopy” admits recognized temporal expressions as lon</context>
<context position="6169" citStr="TERN 2004" startWordPosition="930" endWordPosition="931">Exact match measures the ability to correctly identify the extent of the TIMEX. The extent of the reference and the system output tags must match exactly the system output tag to be scored as correct. 2.2 Datasets To date, there are two annotated corpora used for temporal evaluations, the ACE TERN corpus and TimeBank (Pustejovsky et al., 2003a). In this section we provide a brief description of the temporal corpora and annotation standards, which can substantially influence recognition results. Most of the implementations referred as the state-of-the-art were developed in the scope of the ACE TERN 2004. For evaluations, a training corpus of 862 documents with about 306 thousand words was provided. Each document represents a news article formatted in XML, in which TIMEX2 tags denote temporal expressions. The total number of temporal expressions for training is 8047 TIMEX2 tags with an average of 10.5 per document. The test set comprises 192 documents with 1828 TIMEX2 tags (Ferro, 2004). The annotation of temporal expressions in the ACE corpus was done with respect to the TIDES annotation guidelines (Ferro et al., 2003). The TIDES standard specifies so-called markable expressions, whose synta</context>
<context position="10351" citStr="TERN 2004" startWordPosition="1581" endWordPosition="1582">elies on a set of hand-crafted and machine-discovered rules, which are based upon shallow lexical features. On average the system achieved a value of 83.2% for F1-measure against hand-annotated data. The dataset used comprised a set of 22 New York Times articles and 199 transcripts of Voice of America taken from the TDT2 collection (Graff et al., 1999). It should be noted that the reported performance was provided in terms of an exact match. Another example of rule-based temporal taggers is Chronos described in (Negri and Marseglia, 2004), which achieved the highest scores (F1-measure) in the TERN 2004 of 0.926 and 0.878 for recognition and exact match. Recognition of temporal expressions using TimeBank as an annotated corpus, is reported in (Boguraev and Ando, 2005) based on a cascaded finite-state grammar (500 stages and 16000 transitions). A complex approach achieved an F1- measure value of 0.817 for exact match and 0.896 for detecting “sloopy” spans. Another known implementation for TimeBank is an adaptation of (Mani and Wilson, 2000) from TIMEX2 to TIMEX3 with no reported performance level. Machine learning recognition systems: Successful machine learning TIMEX recognition systems are </context>
<context position="14716" citStr="TERN 2004" startWordPosition="2277" endWordPosition="2278">uary 30th” has character type “Xxxxxxx 99xx” and pattern “X(x) (9)(x)”. On this basis, we employ a classifier that implements a Maximum Entropy model2 and per1 In literature such patterns are also known as shorttypes. 2 http://maxent.sourceforge.net/ After processing the TimeBank corpus of 183 documents we had 2612 parsed sentences with 1224 temporal expressions in them. 2612 sentences resulted in 49656 phrase candidates. We separated the data in order to perform 10-fold cross validation, train the classifier and test it on an unseen dataset. The evaluations were conducted with respect to the TERN 2004 evaluation plan (TERN, 2004) and described in Section 2.1. After running experiments the classifier demonstrated the performance in detection of TIMEX3 tags with a minimal overlap of one character with precision, recall and F1-measure at 0.872, 0.836 and 0.852 respectively. Since the candidate phrases provided by the parser do not always exactly align annotated temporal expressions, the results for the exact match experiments are constrained by an estimated upper-bound recall of 0.919. The experiments on exact match demonstrated a small decline of performance level and received scores of 0.86</context>
<context position="17422" citStr="TERN 2004" startWordPosition="2697" endWordPosition="2698">ine learning approach for detecting temporal expression using a recent annotated corpus for temporal information, TimeBank. Employing shallow syntactic and lexical features, the performance level of the method achieved comparable results to a rule-based approach of Boguraev and Ando (2005) and for the exact match task even outperforms it. Although a direct comparison with other state-of-the-art systems is not possible, due to different evaluation corpora, annotation standards and size in particular, our experiments disclose a very important characteristic. While the recognition systems in the TERN 2004 reported a substantial drop of F1- measure between detection and exact match results (6.5 – 11.6%), our phrase-based detector demonstrates a light decrease in F1-measure (2.4%), whereas the precision declines only by 0.6%. This important finding leads us to the conclusion that most of TIMEX3s in TimeBank can be detected at a phrase-based level with a reasonably high performance. Despite a good recognition performance level there is, of course, room for improvement. Many implementations in the TERN 2004 employ a set of apparent temporal tokens as one of the features. In our implementation, the</context>
</contexts>
<marker>TERN, 2004</marker>
<rawString>TERN 2004 Evaluation Plan, 2004, &lt;http://fofoca.mitre.org/tern_2004/tern_evalplan2004.29apr04.pdf&gt; (accessed: 5.03.2009)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>