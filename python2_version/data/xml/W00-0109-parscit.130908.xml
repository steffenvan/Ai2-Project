<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000020">
<title confidence="0.935307">
Partially Saturated Referents
as a Source of Complexity in Semantic Interpretation
</title>
<author confidence="0.933953">
David D. McDonald
</author>
<affiliation confidence="0.959837">
Department of Computer Science, Brandeis University
</affiliation>
<email confidence="0.901097">
davidrnedonald@alum.mitedu
</email>
<bodyText confidence="0.999852">
A significant factor in the complexity of the compressed, complex prose style used by
journalists in short, targeted commercial reports (Who&apos;s News, joint ventures, earnings reports,
etc.) is the fact that many of the phrases are semantically incomplete, i.e. their interpretation is
dependent on information in other parts of the sentence or the in discourse context. We propose
that the complexity that such partially saturated referents contribute to the overall process of
semantic interpretation can be characterized by two factors we will call displacement and
unpacking. This complexity source can be quantified by counting the distance, in nodes, between
each phrase that has a locally incomplete interpretation and the phrase(s) that supply the terms
that complete them.
In this paper we will define this phenomenon and illustrate its impact on interpretation by
examining short texts excerpted from the Tipster corpus and other online sources.
</bodyText>
<sectionHeader confidence="0.981075" genericHeader="method">
1. The Problem
</sectionHeader>
<bodyText confidence="0.966141264150943">
The goal of this paper is to precisely
characterize the intuitive observation that the
A sentences below are more complex than
their B counterparts. (Examplela. is from
article 231 of the Tipster joint venture corpus;
2a is from article 2279.) The B examples were
corn-posed by the author. The task is
information extraction, where the goal is to
determine the amount that each partner in the
joint venture is contributing to the venture&apos;s
total capital-ization.
la. It will be capitalized at 130 million ringgit,
which the three companies will equally
shoulder.
lb The three companies will shoulder equal
amounts of the venture&apos;s capitalization of
130 million ringgit.
2a. ... the joint firm, capitalized at one billion
yen, will be 60 pct owned by P.T. Astra
International, Inc., and 40 pct by Daihatsu.
2b. P.T. Astra will own 60 pct of the joint
firm&apos;s capitalization of one billion yen and
Daihatsu will own 40 pct.
We are trying to quantify an aspect of the
semantic interpretation processâ€”the process
by which the lexical and syntactic elements of
a text are mapped to a collection of typed,
structured objects with respect to some model
(broadly speaking, a collection of individuals
and relations over them).
We presume (a) that interpretations are
formed compositionally following the paths
provided by the syntax; (b) that they come into
existence incrementally phrase by phrase,
object by object as the parser moves left to
right through the text. This implies that most
relations will initially be only partially satur-
ated. And (c) that the mapping from lexico-
syntactic objects to semantic objects is a
matter of recognizing function-argument
patterns that are indicated structurally or
morphologically and ultimately driven by
information provided by the lexical sources of
the predicates,
Given this background, the question is what
makes the A sentences more complex than the
B sentences even though both convey
essentially the same information.&apos; The answer,
Information, albeit of a different kind, is also
conveyed by ordering, choice of cohesive
devices, or even just following the stylistic
conventions of the genre (which the B
sentences do not). Quantifying the impact of
</bodyText>
<page confidence="0.997293">
51
</page>
<bodyText confidence="0.997382795918367">
as we see it, lies in the nature of the path that
that terms must take through the text&apos;s phrase
structure as they are composed to form
relations: the farther the distance the greater
the complexity.
Compositional complexity, as we propose
to call this phenomenon, is a problem that
arises because speakers establish their
relationship with their audience by producing
texts (in the formal sense) rather than a
jumbled salad of independent phrases. To this
end, speakers have at their disposal a large
battery of linguistic devices that give texts
their cohesion by omitting information that
their audience must now infer, thereby
inducing the audience&apos;s attention (Halliday &amp;
Hasan 1976).
One of these devices is the use of phrases
whose interpretations are locally incomplete:
partially saturated. To understand such
phrases, the audience (natural language under-
standing system) must search through the
context and identify the terms that are needed
to fully populate (saturate) the model-level
relations these phrases denote.
We call this aspect of the semantic
interpretation process &apos;compositional&apos; com-
plexity because we assume that the bulk of the
organization on the context that is searched is
provided by the text&apos;s syntactic structure, and
that the interpretation process overall is
organized compositionally as a walk over the
phrase structure the syntax defines (for us a
bottom up and left to right traversal in lock-
step with the parser as it establishes phrasal
boundaries).
These assumptions suggest that a text will
be harder to understand the greater the
separation between the partially-saturated
relations and their missing terms (i.e. the
process of its interpretation will require more
effort in terms of larger working state, using a
richer type system, deploying a more complex
this information structure, however, is beyond
our present abilities.
control structure, inviting a greater chance of
error, etc.). As a first approximation we will
measure this complexity by counting the
number of intervening syntactic nodes.
</bodyText>
<sectionHeader confidence="0.823886" genericHeader="method">
2. An Example
</sectionHeader>
<bodyText confidence="0.977820375">
We will explore this notion of
compositional complexity by first looking in
some detail at the structure and interpretation
of example la, &amp;quot;It [the joint venture] will be
capitalized at 130 million ringgit, which the
three companies will equally shoulder&amp;quot;, which
we take to have the following syntactic
stmcture.2
The first clause, &amp;quot;it will be capitalized at
130 million ringgit&amp;quot;, illustrates the simplest
case of compositional complexity, where terms
are adjacent to their targets. We assume that
2 We are agnostic about what the &apos;true&apos; choice of
labelings and other theory-governed particulars
should be; what is important is the overall
shape of the tree.
</bodyText>
<figure confidence="0.985142333333333">
it
PP
vg
will be
NP
130 mil. ringgit
which
NP
the three
&apos;VP
vg/
Vvg
equal(Nv
shoulder
will
</figure>
<page confidence="0.995821">
52
</page>
<bodyText confidence="0.9997962">
the word capitalize in the sense used here3
denotes a function of two arguments, where tD&amp;quot;
is restricted to (can only be bound to) objects
of type joint venture and $ to objects of type
amount of money.
</bodyText>
<subsectionHeader confidence="0.396575">
J,$ capitalization(J, $)
</subsectionHeader>
<bodyText confidence="0.999841611111111">
In this base case the two needed terms are not
separated by any intermediary syntactic nodes
and we say that the text has a compositional
complexity of zero.
The result of binding these two terms is the
instantiation of the fully saturated relation (i)
below. What is shown is an expression but it
intended just as a gloss of a typed structured
object. Here and the examples to follow we
will abbreviate freely in the interests of space,
e.g. jv indicates the object that represents the
joint venture, 130-million-ringget the object
rep-resenting the instance of that amount of
money that is being invested in the venture,
and so on. We have given expression (i) a
label, Cap-i, to emphasize its status as an
object and to provide a simple means of
indicating references to it in other relations.
</bodyText>
<equation confidence="0.4332505">
(i) Cap-1: capitalization(J, 130-
million-ringgit)
</equation>
<bodyText confidence="0.949865963636364">
Adopting an operational perspective, we
can identify two different aspects of
compositional complexity: displacement and
unpacking. Displacement is simply the separ-
ation between a term and its binding site given
their relative depths in the tree.
The need for unpacking follows from our
assumption that a text is interpreted
incrementally, with relations (or partial rela-
tions) forming as soon as possible in the
parser&apos;s progress through the text. We also
assume that the individual elements of the text
become unavailable at that moment except
with respect to their configuration within the
relation they have become part of.
3 This is the sense of capitalize where it does not
have an agent; cf. &amp;quot;Oracle lost $3.9 billion in
market capitalization&amp;quot; [Wired 8.03, pg. 272].
In our experience this is a valuable
property. Consider the partially saturated rela-
tion below that is the denotation of the relative
clause of la at the point when the downstairs S
has been parsed (&amp;quot;which the three companies
will equally shoulder&amp;quot;). We assume for present
purposes that shoulder denotes a model-level
category we can gloss as contributes-to-capita-
lization, The objects representing the three
companies are glossed as just Cl, C2, C3.
(ii) X amount . contributes-to-
capitalization( collection(C1, C2,
C3), amount)
The agent of this relation is plain enough
(those three particular companies), but what
about the &apos;amount&apos; that they contribute?
Syntactically, the relative clause is of
course open in its direct object, which the
parser will associate with the np 130 million
ringgit. But how is this syntactic open variable
mirrored semantically? When thought of as a
contri-bution to capitalization, the denotation
of 130 million ringgit is not simply an amount
of money in Indonesian currency, which would
be meaningless. The np&apos;s denotation should
instead provide a link though which we can
determine that the money constitutes the fund-
ing of some particular venture. This can be
reflected in the restriction we place on the
amount variable.
This is where unpacking comes in. We have
the option to view (i) as a composite object
with a first class object representing each of its
variable bindings in its own right, as in (iii)
which is the unreduced binding of the amount
of money to the amount variable of the object
we named cap-i. in (i).
</bodyText>
<listItem confidence="0.824756666666667">
(iii) 7*mt-1:
(0, amount . Cap-1)
130-million-ringgit)
</listItem>
<bodyText confidence="0.640163166666667">
Under this view we can unpack cap-i into
its constituent elements and make this binding
object accessible to be bound to amount,
giving us:
(iv) contributes-to-capitalization(
collection(C1, C2, C3), Ant-1)
</bodyText>
<page confidence="0.995875">
53
</page>
<sectionHeader confidence="0.830784" genericHeader="method">
3. Measurements
</sectionHeader>
<bodyText confidence="0.989235388888889">
Now that we have illustrated the character
of the complexity involved, what kind of
numbers should be put to this so that we can
compare different text quantitatively? With no
literature to guide us here we should start with
a simple calculus. We will add one &apos;point&apos; for
each node that intervenes between the partial
relation and each term that it is missing, and
one for each variable binding that must be
unpacked from an already formed relation.
Under this analysis, the displacement of the
&apos;amount&apos; term contributes two points for the
two nodes that intervene between the location
of the verb and the relative pronoun.4 We add
another point for unpacking given that the
amount of money per se does not fit the
restrictions we imposed on the AMT of a
contributes-to-capitalization and we need to
unpack the denotation of the upper clause to
get at the binding we need. This gives us a
total of three points of compositional
complexity for saturating the relation created
by shoulder,
What other kinds of costs have we ignored
so far? One definite cost is establishing what
category (function, predicate) shoulder actual-
ly denotes since unless that is known the type
constraints on its variable bindings will be
untenably vague. (Consider that in this domain
it will be quite common to see the phrase to
shoulder debt.)
Another, possibly debatable, cost is whether
to distribute the denotation of the &amp;quot;the three
companies&amp;quot; across the capitalization to create
three individual relations. Just like one could
elect to ignore the fact that a multi-term
relation can be seen as a set of individual
variable bindings until one of those bindings is
4 We assume the parser carries the denotation of
the relativized rip down to the spec posi-tion;
doing that certainly permits an easier analysis
of the relative clause since it allows it to take on
the surface pattern of, e.g., topicalization.
needed to do work in another part of the text&apos;s
interpretation, the distribution of this
conjunction could remain a latent option until
it was needed to make explicit some other
semantic relation.
We do need to distribute the companies
conjunction in example la because of the other
relation-generating lexical head that we have
yet to consider: equally. (Recall that the text of
1 a is &amp;quot;It will be capitalized at 130 million
ringgit, which the three companies will equally
shoulder&amp;quot;) In isolation (before being specia-
lized to the situation of joint venture capital-
ization, another cost), equal denotes a com-
pletely unsaturated relation:
X collection( partition (measurable-
stuff)) . equal ( elements-of (
collection partition
(measurable-stuff))))
Admittedly this choice of semantics may
already be biased to the joint ventures
problem, but it&apos;s thrust is to say that there must
be some stuff that has been partitioned into
some indeterminate number of portions; in
aggregate these portions form a collection; and
that all of these portions are in some respect
equal
Here equal is predicated of whatever the
shoulder clause denotes so the process of
forming its interpretation must meet and
follow the process of forming that clause&apos;s
interpretation as it percolates up the headline
of the relative clause and into the main clause.
Equal is open in something of type
collection where that collection is a partition of
something. The first collection to be seen mov-
ing up the headline at a remove of two nodes
(the main verb and the vp) is the conjunction
of companies. Because (a) equal is predicating
the equality of some aspect of each of the
elements of the collection and (b) the
companies per se do not have textually
obvious things that might be partitioned, we
can make sense of this only by distributing not
just the companies but the companies qua their
participation in the contribution-to-capitaliza-
tion relation.
</bodyText>
<page confidence="0.997845">
54
</page>
<figureCaption confidence="0.91244694">
This gives us the three latent contribution- Contrast la, with its complexity of six, with
to-capitalization relations (at only the cost of lb, which has a compositional complexity of
the distribution construction, which is zero (though the rather severe departure of this
probably cheap). As part of that distribution artificially constructed sentence from the
construction we must also partition the amount normal stylistic patterning must have a cost to
of the contribution (object (iii)) into three human readers).
parts. This entails unpacking those relations to lb The three companies will shoulder equal
expose their amount bindings. The equals amounts of the venture&apos;s capitalization of
relation then boils to down to a predication5 130 million ringgit.
over those three binding objects, viz. lb garners this minimal cost by placing
(v) Contrib-1: contributes-to-capital- each contributing term right next the partial
ization (C1, Cap-1, Amt-2) relation that provides its binding site, notably
(vi) Contrib-2: contributes-to-capi- pushing the capitalization clause of la down to
talization (C2, Cap-1, Amt-3) the rightmost and lowest position in the sen-
(vii)Contrib-3: contributes-to-cap- tence&apos;s phrase structure.
italization (C3, Cap-1, 7mt-4) Example two presents a challenge to a
(viii) Ant-2: X amount . contributes- standard compositional model of interpretation
to-capitalization (C1, Cap-1, that assumes that the denotation of the syn-
amount) tactic head provides the basis for interpreting
(ix) Amt-3: X amount . contribute9- the head&apos;s syntactic arguments.
to-capitalization (C2, Cap-1, 2a. ... the joint firm, capitalized at one billion
amount) yen, will be 60 pet owned by P.T. Astra
(x) Ant-4: X amount . contributes-to- international, Inc., and 40 pct by Daihatsu.
capitalization (C3, Cap-1, amount) The syntactic head of the conjunct &amp;quot;40 pct
(xi) equal (Amt-2, Amt-3, Amt-4) by Daihatsu&amp;quot; has to be the percentage, yet
In terms of our computational complexity there is no way to fashion a plausible rule of
metric, the interpretation of the equally interpretation that binds a company to a
modifier has contributed two points for the percentage. Instead, both terms must be passed
displacement between it and the conjunction of up through the conjunction node to the
companies and then (modulo the distribution ownership clause (1 count) and then unpack
cost) one point for unpacking the relation the the interpretation of that clause to extract the
companies are participating it to isolate the capitalization value and the joint venture (2
amount binding(s). counts, one for each term). Given that the
This gives example la a total compositional capitalization of the joint venture was given in
complexity of 6: its three relation sources, an appositive off the subject, the ownership
capitalized, shoulder, and equally contributing clause itself required two extra counts for its
zero, three, and three counts respectively; four construction, one to unpack the capitalization
of the counts reflecting the distance that dis- and a second for the displacement of the first
placed elements from their binding sites, and parent company (P.T. Astra) away from the
two reflecting the effort to dip into, or verb in its agentive by-phrase (though that
&apos;unpack&apos;, already created relations in order to count is debatable since the grammar might
select or reify one of the elements within them. explicitly subcategorize for it).
Complexity of this kind is ubiquitous in
business reporting. Consider this excerpt from
5 The amounts of money that the companies are
contributing is given abstractly rather than
calculated out since that appears to be the
preferred level at which it should be represented
for reasoning in this domain
55
</figureCaption>
<bodyText confidence="0.9792205">
the beginning of a quarterly earnings report
(PRNewsWire 1/21/00 5:21 p.m.):
</bodyText>
<listItem confidence="0.8568345">
3. Gensym Corp. &lt; descriptive appositives&gt;
today reported that revenues for its fourth
</listItem>
<bodyText confidence="0.987821722222222">
quarter ended December 31, 1999 were $9.1
million, . . . The net loss for the fourth
quarter of 1999 was. â€ž
The sentence that reports the loss does not
say what company lost the moneyâ€”to do so
would be unnecessarily redundant and reduce
the text&apos;s cohesion. Yet the increased tightness
of the text leaves us with an partially saturated
relation as the immediate referent of that
sentence, open in its company variable, which
must be actively filled in from context.
Moreover this example is somewhat unusual in
that it provides a syntax-supported explicit
indicator of whose fourth quarter reporting
period it is in the first of the two sentences;
usually it would be stated &apos;for the fourth qua-
rter. . .&amp;quot; and the reporting-period object would
also have been left with an unbound variable.
</bodyText>
<sectionHeader confidence="0.931724" genericHeader="method">
4. Modeling
</sectionHeader>
<bodyText confidence="0.999930529411765">
Up to this point we have deliberately not
discussed the question of how one would
actually derive these compositional complexity
counts automatically. We have instead
provided a prose description of the process for
a very few examples and many questions of
just what constitutes a displacement or how
one might know that a relation reached in the
traversal should be unpacked remain
unanswered.
The glib answer is that you fire up your
natural language understanding system, add
some reporting facilities to it, and apply it to
the texts in question. Today at least that
procedure is unlikely to work since texts of the
sort we have been discussing are largely
beyond the state of the art for information
extraction engines without some deliberate,
do-main-specific engineering.
A more germane answer would look to
some resource of hand-annotated texts and
then provide suitable definitions for displace-
ment and unpacking that, given some
debugging, could then be applied
automatically even if there was not system that
could as yet replace the knowledge of the
human annotator.
But this answer too is not available to us
simply because such resources do not yet exist.
Besides the obvious fact that efforts at
providing semantic annotations of corpora are
only just now getting underway, an additional
problem is that the study of the semantic
phenomenon that is the focus of this paper,
unsaturated, model-level relations, is uncom-
mon in the field and for good reason.
An examination of the full text of the
articles in, e.g., the Tipster Joint Ventures
corpus will show that full phrases (maximal
projections) that are unsaturated at the moment
they are delimited by the parser and then given
a semantic interpretation are unusual. A casual
examination of the text in this section did not
turn any up. In the full text from which
example la was taken (which appears at the
end of this paper) turns up only two more
instances (reductions around the word sales). It
is also worth noting that the original Tipster
effort elected to drop attempts to extract
capitalization information, as, indeed, these are
among the more linguistically complex
constructions in the corpus.
Partially saturated relations abound in
financial texts such as quarterly earnings
reports or stock market reports. Our own
interest in this phenomena stems from our
recent focus on such texts as well as the utility
of the perspective shifts this kind of semantic
object provides for work in the tactics of
natural language generation (i.e.
microplanning).
Without further, collective study of this
class of semantic constructions any annotation
effort would have a considerable startup cost
as it arrived at candidate representations for its
annotators to use as well as a subjective cost in
convincing the rest of the community that they
had made reasonable, practical choices that
</bodyText>
<page confidence="0.988582">
56
</page>
<bodyText confidence="0.999936">
other project could adapt to their own
purposes.
Barring a well-financed project to supply a
suitably annotated corpus, we think that the
proper way to proceed towards the goal of a
suitable formalization is along the lines of the
original, glib answer to this problem, namely
to build a parser and interpretation system that
operates at a sufficient level of generalization
that it would require only a minimal effort to
provide the lexicon and conceptual model
needed to examine texts in a given domain.
We have been personally engaged in such a
project over the last few years, albeit at a very
slow pace given the constraints we are
working under, and have made a fair amount
of progress, some of which is described in
McDonald (in press).
</bodyText>
<sectionHeader confidence="0.997484" genericHeader="method">
5. Final Observations
</sectionHeader>
<bodyText confidence="0.999631291666667">
That texts with partially saturated relations
are more complex to process is, we think,
undeniable. It also seems to us a simple matter
of examination to conclude that the cost is
proportional to the factors we have identified:
the distance by which relation elements have
been displaced from each other and the cost of
unpacking already completed relations to find
needed terms that those relations have already
in some sense consumed. On the other hand,
that this cost is measured in integer values
based on simple phrase node counts is entirely
debatable. As other aspects of the semantic
interpretation process are quantified this
component of the total measure will at least
need to be combined with some proportion-
ality constant to make all the numbers com-
parable.
More interesting is the fact that some node
transitions will certainly be different from
others in their practical implementation and
this should probably be factored into the cost
calculation. Consider this sentence from article
1271 of the Tipster joint venture corpus.
</bodyText>
<construct confidence="0.521006">
4. Inoda Cement Co., . . , said Tuesday its U.S.
subsidiary has formed an equally owned
cement joint venture . . . with Lone Star
Industries Inc. .
</construct>
<bodyText confidence="0.999992142857143">
The process that completes the &apos;equal
ownership&apos; relation will have to reach up
through three nodes to get to the first of the
two owner companies. But it will certainly be
different (more elaborate) to pass this partial
relation through a node that is itself creating a
relation (the vp headed by form) as compared
with passing it through report verbs like said
or raising verbs like expects to that add
relatively little information.
What the composition cost comes to in
practice is, of course, a matter of the
architecture of the parser and semantic
interpretation engine that is being deployed.
For some it may be a matter of adding
additional mapping patterns that recognize the
specific local configurations that denote
partially saturated relations Cthe &lt;ordinal&gt;
quarter&apos;) and having heuristics for searching
the discourse context for their missing
elements.
Systems with rich descriptive resources for
lexicalized grammars such as TAGs could
define specific auxiliary trees for relational
heads that can appear in non-standard locations
(e.g. equally) and tie them into map-ping rules
that might try to do the work over the
derivation trees that these parsers produce. The
conjunction problem presented by example
two would be amenable to a syntactic
treatment in a categorial grammar, though the
range of semantic types that can be combined
in this arbitrary way might make that quite
difficult in general.
Finally, we must say that for us this whole
idea of viewing the local interpretation of the
interior phrases of a sentence as partially
saturated relations and viewing their
completion as a matter of passing these partial
interpretations through the tree is the result of
many years of research and development on a
system where such relations are first class
</bodyText>
<page confidence="0.993494">
57
</page>
<bodyText confidence="0.999989714285714">
objects with the same ontological status as
conventional individuals. In our system (see
McDonald in press) the goal is to keep the
syntactic processing simple and to move the
Onus of the interpretation effort onto to the
semantic level by having more than one
referent move up the headline as the phrase
structure is created. The partially saturated
relations are given an active role in seeking the
arguments that they need. This introduces a
bias into our observations in this paper and
could, possibly, be creating a mountain where
systems with quite different architectures
might only see a molehill.
</bodyText>
<sectionHeader confidence="0.996222" genericHeader="method">
References:
</sectionHeader>
<reference confidence="0.751864222222222">
Halliday, Michael A. K., and Ruciaiya Hasan
(1976) Cohesion in English, Longman, London.
McDonald, David D. (in press) &amp;quot;Issues in the
Representation of Real Texts: The Design of
Krisp&amp;quot;, in Iwanska and Shapiro (eds.) Natural
Language Processing and Knowledge
Representation: Language for Knowledge and
Knowledge for Language, AAAI Press, pgs 71-
104.
Appendix: The complete text of example la
&lt;doc&gt;
&lt;docno&gt; 0231 &lt;/docno&gt;
&lt;DD&gt; August 9, 1990, Thursday &lt;/DD&gt;
&lt;SO&gt; Copyright 0 1990 Jiji Press Ltd.;
&lt;/SO&gt;
&lt;TXT&gt;
Mazda Motor Corp. and Sanyo Electric
Co. of Japan and Ford Motor Co. of the United
</reference>
<bodyText confidence="0.997540625">
States have agreed to set up a joint venture by
the end of this year to produce car audio
equipment in Malaysia, they said Thursday.
The new company, whose name is not decided
yet, will produce radios, stereos, compact disc
players and tuners used for cars. It will be
capitalized at 130 million ringgit, which the
three companies will equally shoulder. The
three plan to construct a 21,000-square-meter
plant in the Prai Industrial Estate of Penang.
The joint venture with a startup workforce of
500 will kick off production by June 1992,
with sales expected to reach some 10 billion
Yen. By the mid-1990s, it will increase the
number of employees to 2,000 and sales to 30
billion Yen. Output at the Malaysian company
will be supplied to the three companies. Mazda
will use the products for its cars to produced in
and after the second half of next year, while
Ford will mount them on its cars for sales in
the Far East. Sanyo plans to sell Malaysian -
made products in Japan and other countries.
&lt;/TXT&gt;
&lt;/doe&gt;
</bodyText>
<page confidence="0.998086">
58
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.016225">
<title confidence="0.9979975">Partially Saturated as a Source of Complexity in Semantic Interpretation</title>
<author confidence="0.99999">David D McDonald</author>
<affiliation confidence="0.992874">Department of Computer Science, Brandeis</affiliation>
<email confidence="0.955871">davidrnedonald@alum.mitedu</email>
<abstract confidence="0.990446057728121">A significant factor in the complexity of the compressed, complex prose style used by journalists in short, targeted commercial reports (Who&apos;s News, joint ventures, earnings reports, etc.) is the fact that many of the phrases are semantically incomplete, i.e. their interpretation is dependent on information in other parts of the sentence or the in discourse context. We propose that the complexity that such partially saturated referents contribute to the overall process of semantic interpretation can be characterized by two factors we will call displacement and unpacking. This complexity source can be quantified by counting the distance, in nodes, between each phrase that has a locally incomplete interpretation and the phrase(s) that supply the terms that complete them. In this paper we will define this phenomenon and illustrate its impact on interpretation by examining short texts excerpted from the Tipster corpus and other online sources. 1. The Problem The goal of this paper is to precisely characterize the intuitive observation that the A sentences below are more complex than their B counterparts. (Examplela. is from article 231 of the Tipster joint venture corpus; from article 2279.) The B examples were by The task is information extraction, where the goal is to determine the amount that each partner in the joint venture is contributing to the venture&apos;s total capital-ization. la. It will be capitalized at 130 million ringgit, which the three companies will equally shoulder. lb The three companies will shoulder equal amounts of the venture&apos;s capitalization of 130 million ringgit. 2a. ... the joint firm, capitalized at one billion yen, will be 60 pct owned by P.T. Astra International, Inc., and 40 pct by Daihatsu. 2b. P.T. Astra will own 60 pct of the joint firm&apos;s capitalization of one billion yen and Daihatsu will own 40 pct. We are trying to quantify an aspect of the semantic interpretation processâ€”the process by which the lexical and syntactic elements of a text are mapped to a collection of typed, structured objects with respect to some model (broadly speaking, a collection of individuals and relations over them). We presume (a) that interpretations are formed compositionally following the paths provided by the syntax; (b) that they come into existence incrementally phrase by phrase, object by object as the parser moves left to right through the text. This implies that most relations will initially be only partially saturated. And (c) that the mapping from lexicosyntactic objects to semantic objects is a matter of recognizing function-argument patterns that are indicated structurally or morphologically and ultimately driven by information provided by the lexical sources of the predicates, Given this background, the question is what makes the A sentences more complex than the B sentences even though both convey essentially the same information.&apos; The answer, albeit of a different kind, is conveyed by ordering, choice of cohesive or even following the stylistic of genre (which sentences do not). Quantifying the impact of 51 as we see it, lies in the nature of the path that that terms must take through the text&apos;s phrase structure as they are composed to form relations: the farther the distance the greater the complexity. Compositional complexity, as we propose to call this phenomenon, is a problem that arises because speakers establish their relationship with their audience by producing texts (in the formal sense) rather than a jumbled salad of independent phrases. To this end, speakers have at their disposal a large battery of linguistic devices that give texts their cohesion by omitting information that their audience must now infer, thereby inducing the audience&apos;s attention (Halliday &amp; Hasan 1976). One of these devices is the use of phrases whose interpretations are locally incomplete: partially saturated. To understand such phrases, the audience (natural language understanding system) must search through the context and identify the terms that are needed to fully populate (saturate) the model-level relations these phrases denote. We call this aspect of the semantic interpretation process &apos;compositional&apos; complexity because we assume that the bulk of the on the context that is provided by the text&apos;s syntactic structure, and that the interpretation process overall is organized compositionally as a walk over the phrase structure the syntax defines (for us a bottom up and left to right traversal in lockstep with the parser as it establishes phrasal boundaries). These assumptions suggest that a text will be harder to understand the greater the separation between the partially-saturated relations and their missing terms (i.e. the process of its interpretation will require more effort in terms of larger working state, using a richer type system, deploying a more complex information structure, however, is our present abilities. control structure, inviting a greater chance of error, etc.). As a first approximation we will measure this complexity by counting the of nodes. 2. An Example We will explore this notion of compositional complexity by first looking in some detail at the structure and interpretation example la, [the joint venture] will be capitalized at 130 million ringgit, which the companies will equally shoulder&amp;quot;, take to the following first clause, will be capitalized at million ringgit&amp;quot;, the simplest case of compositional complexity, where terms are adjacent to their targets. We assume that 2We are about what the &apos;true&apos; choice of labelings and other theory-governed particulars should be; what is important is the overall the tree. it PP vg will be NP 130 mil. ringgit which NP the three &apos;VP shoulder will 52 word the sense used denotes a function of two arguments, where tD&amp;quot; is restricted to (can only be bound to) objects of type joint venture and $ to objects of type amount of money. capitalization(J, In this base case the two needed terms are not separated by any intermediary syntactic nodes and we say that the text has a compositional complexity of zero. The result of binding these two terms is the instantiation of the fully saturated relation (i) below. What is shown is an expression but it intended just as a gloss of a typed structured object. Here and the examples to follow we will abbreviate freely in the interests of space, e.g. jv indicates the object that represents the venture, 130-million-ringget rep-resenting the instance of that amount of money that is being invested in the venture, and so on. We have given expression (i) a label, Cap-i, to emphasize its status as an object and to provide a simple means of indicating references to it in other relations. (i) Cap-1: capitalization(J, 130million-ringgit) Adopting an operational perspective, we can identify two different aspects of compositional complexity: displacement and simply the separation between a term and its binding site given their relative depths in the tree. The need for unpacking follows from our assumption that a text is interpreted incrementally, with relations (or partial relations) forming as soon as possible in the parser&apos;s progress through the text. We also assume that the individual elements of the text become unavailable at that moment except with respect to their configuration within the relation they have become part of. 3This is the sense of it does an agent; cf. lost $3.9 billion capitalization&amp;quot; 8.03, pg. 272]. In our experience this is a valuable property. Consider the partially saturated relation below that is the denotation of the relative clause of la at the point when the downstairs S been parsed the three companies equally shoulder&amp;quot;). assume for present that a model-level category we can gloss as contributes-to-capita- The objects representing three companies are glossed as just Cl, C2, C3. X . contributes-tocapitalization( collection(C1, C2, C3), amount) The agent of this relation is plain enough (those three particular companies), but what about the &apos;amount&apos; that they contribute? the relative clause is course open in its direct object, which the will associate the np how this syntactic open variable mirrored semantically? When thought of as a contri-bution to capitalization, the denotation million ringgit not simply an amount of money in Indonesian currency, which would be meaningless. The np&apos;s denotation should provide a link though we can that the money constitutes funding of some particular venture. This can be reflected in the restriction we place on the where in. We have option (i) as a composite object with a first class object representing each of its bindings in its own right, as which is the unreduced binding of the amount of money to the amount variable of the object cap-i. (i). (iii) 7*mt-1: . Cap-1) 130-million-ringgit) Under this view we can unpack cap-i into its constituent elements and make this binding accessible to be bound to giving us: (iv) collection(C1, C2, C3), Ant-1) 53 3. Measurements Now that we have illustrated the character of the complexity involved, what kind of numbers should be put to this so that we can compare different text quantitatively? With no to guide we should start with a simple calculus. We will add one &apos;point&apos; for each node that intervenes between the partial relation and each term that it is missing, and one for each variable binding that must be unpacked from an already formed relation. Under this analysis, the displacement of the &apos;amount&apos; term contributes two points for the two nodes that intervene between the location the verb and the relative We add another point for unpacking given that the amount of money per se does not fit the restrictions we imposed on the AMT of a contributes-to-capitalization and we need to unpack the denotation of the upper clause to get at the binding we need. This gives us a total of three points of compositional complexity for saturating the relation created What other kinds of costs have we ignored so far? One definite cost is establishing what (function, predicate) actually denotes since unless that is known the type constraints on its variable bindings will be untenably vague. (Consider that in this domain will be quite common to see the phrase shoulder debt.) Another, possibly debatable, cost is whether distribute the denotation of the three the capitalization to create three individual relations. Just like one could elect to ignore the fact that a multi-term relation can be seen as a set of individual variable bindings until one of those bindings is 4We assume parser carries the denotation of the relativized rip down to the spec posi-tion; doing that certainly permits an easier analysis of the relative clause since it allows it to take on the surface pattern of, e.g., topicalization. needed to do work in another part of the text&apos;s interpretation, the distribution of this conjunction could remain a latent option until it was needed to make explicit some other semantic relation. We do need to distribute the companies conjunction in example la because of the other relation-generating lexical head that we have to consider: that the text of a is will be capitalized at 130 million ringgit, which the three companies will equally isolation (before being specialized to the situation of joint venture capitalanother cost), a completely unsaturated relation: X collection( partition (measurablestuff)) . equal ( elements-of ( collection (measurable-stuff)))) Admittedly this choice of semantics may already be biased to the joint ventures it&apos;s thrust is say there must stuff that has been into number of portions; in aggregate these portions form a collection; and of these portions are in some equal predicated of whatever the denotes the of forming its interpretation must meet and follow the process of forming that clause&apos;s interpretation as it percolates up the headline of the relative clause and into the main clause. Equal is open in something of type collection where that collection is a partition of something. The first collection to be seen movup the headline at a remove of two main verb the vp) is the conjunction of companies. Because (a) equal is predicating the equality of some aspect of each of the elements of the collection and (b) the companies per se do not have textually obvious things that might be partitioned, we can make sense of this only by distributing not just the companies but the companies qua their participation in the contribution-to-capitalization relation. 54 This gives us the three latent contribution-to-capitalization relations (at only the cost of the distribution construction, which is probably cheap). As part of that distribution construction we must also partition the amount of the contribution (object (iii)) into three parts. This entails unpacking those relations to their The equals then boils to down to a Contrast la, with its complexity of six, with lb, which has a compositional complexity of zero (though the rather severe departure of this artificially constructed sentence from the normal stylistic patterning must have a cost to human readers). over those three binding objects, viz. lb The three companies will shoulder equal amounts of the venture&apos;s capitalization of 130 million ringgit. (v) Contrib-1: contributes-to-capital-ization (C1, Cap-1, Amt-2) lb garners this minimal cost by placing each contributing term right next the partial relation that provides its binding site, notably pushing the capitalization clause of la down to the rightmost and lowest position in the sen-tence&apos;s phrase structure. Contrib-2: talization (C2, Cap-1, Amt-3) Example two presents a challenge to a standard compositional model of interpretation that assumes that the denotation of the syn-tactic head provides the basis for interpreting the head&apos;s syntactic arguments. contributes-to-cap- 2a. ... the joint firm, capitalized at one billion yen, will be 60 pet owned by P.T. Astra international, Inc., and 40 pct by Daihatsu. italization (C3, Cap-1, 7mt-4) syntactic head of the conjunct Daihatsu&amp;quot; to be the percentage, yet there is no way to fashion a plausible rule of interpretation that binds a company to a Instead, terms must be passed through the conjunction node to ownership clause (1 count) and then unpack the interpretation of that clause to extract the capitalization value and the joint venture (2 one for each term). that the capitalization of the joint venture was given in an appositive off the subject, the ownership clause itself required two extra counts for its construction, one to unpack the capitalization and a second for the displacement of the first parent company (P.T. Astra) away from the verb in its agentive by-phrase (though that count is debatable since the grammar might explicitly subcategorize for it). (viii) Ant-2: X amount . contributes-to-capitalization (C1, Cap-1, amount) Complexity of this kind is ubiquitous in business reporting. Consider this excerpt from Amt-3: X amount . contribute9to-capitalization (C2, amount) (x) Ant-4: X amount . contributes-to-capitalization (C3, Cap-1, amount) (xi) equal (Amt-2, Amt-3, Amt-4) In terms of our computational complexity the interpretation of the modifier has contributed two points for the displacement between it and the conjunction of companies and then (modulo the distribution cost) one point for unpacking the relation the are participating it to isolate amount binding(s). gives example compositional complexity of 6: its three relation sources, capitalized, shoulder, and equally contributing zero, three, and three counts respectively; four of the counts reflecting the distance that dis-placed elements from their binding sites, and two reflecting the effort to dip into, or &apos;unpack&apos;, already created relations in order to select or reify one of the elements within them. 5The amounts money the companies are contributing is given abstractly rather than calculated out since that appears to be the preferred level at which it should be represented for reasoning in this domain 55 the beginning of a quarterly earnings report (PRNewsWire 1/21/00 5:21 p.m.): 3. Gensym Corp. &lt; descriptive appositives&gt; today reported that revenues for its fourth quarter ended December 31, 1999 were $9.1 . . . The net loss for quarter of 1999 was. â€ž The sentence that reports the loss does not say what company lost the moneyâ€”to do so would be unnecessarily redundant and reduce the text&apos;s cohesion. Yet the increased tightness of the text leaves us with an partially saturated relation as the immediate referent of that sentence, open in its company variable, which must be actively filled in from context. Moreover this example is somewhat unusual in that it provides a syntax-supported explicit indicator of whose fourth quarter reporting period it is in the first of the two sentences; it would be stated the fourth qua- . .&amp;quot; the reporting-period object would also have been left with an unbound variable. 4. Modeling Up to this point we have deliberately not discussed the question of how one would actually derive these compositional complexity counts automatically. We have instead provided a prose description of the process for a very few examples and many questions of just what constitutes a displacement or how one might know that a relation reached in the traversal should be unpacked remain unanswered. The glib answer is that you fire up your natural language understanding system, add some reporting facilities to it, and apply it to the texts in question. Today at least that procedure is unlikely to work since texts of the sort we have been discussing are largely beyond the state of the art for information extraction engines without some deliberate, do-main-specific engineering. A more germane answer would look to some resource of hand-annotated texts and then provide suitable definitions for displacement and unpacking that, given some debugging, could then be applied automatically even if there was not system that could as yet replace the knowledge of the human annotator. But this answer too is not available to us simply because such resources do not yet exist. Besides the obvious fact that efforts at providing semantic annotations of corpora are only just now getting underway, an additional problem is that the study of the semantic phenomenon that is the focus of this paper, unsaturated, model-level relations, is uncommon in the field and for good reason. An examination of the full text of the articles in, e.g., the Tipster Joint Ventures corpus will show that full phrases (maximal projections) that are unsaturated at the moment they are delimited by the parser and then given a semantic interpretation are unusual. A casual examination of the text in this section did not turn any up. In the full text from which example la was taken (which appears at the end of this paper) turns up only two more (reductions around the word also worth that original Tipster effort elected to drop attempts to extract capitalization information, as, indeed, these are among the more linguistically complex constructions in the corpus. Partially saturated relations abound in financial texts such as quarterly earnings reports or stock market reports. Our own interest in this phenomena stems from our recent focus on such texts as well as the utility of the perspective shifts this kind of semantic object provides for work in the tactics of natural language generation microplanning). Without further, collective study of this class of semantic constructions any annotation effort would have a considerable startup cost as it arrived at candidate representations for its annotators to use as well as a subjective cost in convincing the rest of the community that they had made reasonable, practical choices that 56 other project could adapt to their own purposes. Barring a well-financed project to supply a suitably annotated corpus, we think that the proper way to proceed towards the goal of a suitable formalization is along the lines of the original, glib answer to this problem, namely to build a parser and interpretation system that operates at a sufficient level of generalization that it would require only a minimal effort to provide the lexicon and conceptual model needed to examine texts in a given domain. We have been personally engaged in such a project over the last few years, albeit at a very slow pace given the constraints we are working under, and have made a fair amount of progress, some of which is described in McDonald (in press). 5. Final Observations That texts with partially saturated relations are more complex to process is, we think, undeniable. It also seems to us a simple matter of examination to conclude that the cost is proportional to the factors we have identified: the distance by which relation elements have been displaced from each other and the cost of unpacking already completed relations to find needed terms that those relations have already in some sense consumed. On the other hand, that this cost is measured in integer values based on simple phrase node counts is entirely debatable. As other aspects of the semantic interpretation process are quantified this component of the total measure will at least need to be combined with some proportionality constant to make all the numbers comparable. More interesting is the fact that some node transitions will certainly be different from others in their practical implementation and this should probably be factored into the cost calculation. Consider this sentence from article 1271 of the Tipster joint venture corpus. 4. Inoda Cement Co., . . , said Tuesday its U.S. subsidiary has formed an equally owned cement joint venture . . . with Lone Star Industries Inc. . The process that completes the &apos;equal ownership&apos; relation will have to reach up through three nodes to get to the first of the two owner companies. But it will certainly be different (more elaborate) to pass this partial relation through a node that is itself creating a (the vp headed by compared passing it through report verbs raising verbs like to add relatively little information. What the composition cost comes to in practice is, of course, a matter of the architecture of the parser and semantic interpretation engine that is being deployed. some it may be matter adding additional mapping patterns that recognize the specific local configurations that denote partially saturated relations Cthe &lt;ordinal&gt; quarter&apos;) and having heuristics for searching the discourse context for their missing elements. Systems with rich descriptive resources for lexicalized grammars such as TAGs could define specific auxiliary trees for relational heads that can appear in non-standard locations tie them into map-ping rules that might try to do the work over the derivation trees that these parsers produce. The conjunction problem presented by example two would be amenable to a syntactic treatment in a categorial grammar, though the range of semantic types that can be combined in this arbitrary way might make that quite difficult in general. Finally, we must say that for us this whole idea of viewing the local interpretation of the interior phrases of a sentence as partially saturated relations and viewing their completion as a matter of passing these partial interpretations through the tree is the result of many years of research and development on a where relations first class 57 objects with the same ontological status as conventional individuals. In our system (see McDonald in press) the goal is to keep the syntactic processing simple and to move the the interpretation effort onto to the semantic level by having more than one referent move up the headline as the phrase structure is created. The partially saturated relations are given an active role in seeking the arguments that they need. This introduces a bias into our observations in this paper and could, possibly, be creating a mountain where systems with quite different architectures might only see a molehill.</abstract>
<note confidence="0.828146">References: Halliday, Michael A. K., and Ruciaiya Hasan in English, London. McDonald, David D. (in press) &amp;quot;Issues in the Representation of Real Texts: The Design of Krisp&amp;quot;, in Iwanska and Shapiro (eds.) Natural Language Processing and Knowledge Representation: Language for Knowledge and Knowledge for Language, AAAI Press, pgs 71-</note>
<abstract confidence="0.910295352941177">104. Appendix: The complete text of example la &lt;doc&gt; &lt;/docno&gt; &lt;DD&gt; August 9, 1990, Thursday &lt;/DD&gt; &lt;SO&gt; Copyright 0 1990 Jiji Press Ltd.; &lt;/SO&gt; &lt;TXT&gt; Mazda Motor Corp. and Sanyo Electric Co. of Japan and Ford Motor Co. of the United States have agreed to set up a joint venture by the end of this year to produce car audio equipment in Malaysia, they said Thursday. The new company, whose name is not decided yet, will produce radios, stereos, compact disc and tuners used for cars. will be at 130 million which the companies will shoulder. three plan to construct a 21,000-square-meter plant in the Prai Industrial Estate of Penang. The joint venture with a startup workforce of 500 will kick off production by June 1992, with sales expected to reach some 10 billion Yen. By the mid-1990s, it will increase the number of employees to 2,000 and sales to 30 billion Yen. Output at the Malaysian company will be supplied to the three companies. Mazda will use the products for its cars to produced in and after the second half of next year, while Ford will mount them on its cars for sales in the Far East. Sanyo plans to sell Malaysian made products in Japan and other countries. &lt;/TXT&gt; &lt;/doe&gt;</abstract>
<intro confidence="0.773883">58</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael A K Halliday</author>
<author>Ruciaiya Hasan</author>
</authors>
<title>Cohesion in English,</title>
<date>1976</date>
<location>Longman, London.</location>
<contexts>
<context position="4034" citStr="Halliday &amp; Hasan 1976" startWordPosition="626" endWordPosition="629">take through the text&apos;s phrase structure as they are composed to form relations: the farther the distance the greater the complexity. Compositional complexity, as we propose to call this phenomenon, is a problem that arises because speakers establish their relationship with their audience by producing texts (in the formal sense) rather than a jumbled salad of independent phrases. To this end, speakers have at their disposal a large battery of linguistic devices that give texts their cohesion by omitting information that their audience must now infer, thereby inducing the audience&apos;s attention (Halliday &amp; Hasan 1976). One of these devices is the use of phrases whose interpretations are locally incomplete: partially saturated. To understand such phrases, the audience (natural language understanding system) must search through the context and identify the terms that are needed to fully populate (saturate) the model-level relations these phrases denote. We call this aspect of the semantic interpretation process &apos;compositional&apos; complexity because we assume that the bulk of the organization on the context that is searched is provided by the text&apos;s syntactic structure, and that the interpretation process overal</context>
</contexts>
<marker>Halliday, Hasan, 1976</marker>
<rawString>Halliday, Michael A. K., and Ruciaiya Hasan (1976) Cohesion in English, Longman, London.</rawString>
</citation>
<citation valid="false">
<authors>
<author>David D McDonald</author>
</authors>
<title>(in press) &amp;quot;Issues in the Representation of Real Texts: The Design of Krisp&amp;quot;,</title>
<booktitle>in Iwanska and Shapiro (eds.) Natural Language Processing and Knowledge Representation: Language for Knowledge and Knowledge for Language,</booktitle>
<pages>71--104</pages>
<publisher>AAAI Press,</publisher>
<marker>McDonald, </marker>
<rawString>McDonald, David D. (in press) &amp;quot;Issues in the Representation of Real Texts: The Design of Krisp&amp;quot;, in Iwanska and Shapiro (eds.) Natural Language Processing and Knowledge Representation: Language for Knowledge and Knowledge for Language, AAAI Press, pgs 71-104.</rawString>
</citation>
<citation valid="true">
<title>Appendix: The complete text of example la 0231</title>
<date>1990</date>
<journal>Thursday Copyright</journal>
<volume>0</volume>
<publisher>Jiji Press Ltd.;</publisher>
<marker>1990</marker>
<rawString>Appendix: The complete text of example la &lt;doc&gt; &lt;docno&gt; 0231 &lt;/docno&gt; &lt;DD&gt; August 9, 1990, Thursday &lt;/DD&gt; &lt;SO&gt; Copyright 0 1990 Jiji Press Ltd.; &lt;/SO&gt;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mazda Motor Corp</author>
</authors>
<title>and Sanyo Electric Co. of Japan and Ford Motor Co.</title>
<note>of the United</note>
<marker>Corp, </marker>
<rawString>&lt;TXT&gt; Mazda Motor Corp. and Sanyo Electric Co. of Japan and Ford Motor Co. of the United</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>