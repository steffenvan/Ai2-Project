<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000026">
<title confidence="0.941526">
Dependency Tree Based Sentence Compression
</title>
<note confidence="0.5556402">
Katja Filippova and Michael Strube
EML Research gGmbH
SchloB-Wolfsbrunnenweg 33
69118 Heidelberg, Germany
http://www.eml-research.de/nlp
</note>
<sectionHeader confidence="0.954732" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999481">
We present a novel unsupervised method for
sentence compression which relies on a de-
pendency tree representation and shortens sen-
tences by removing subtrees. An automatic
evaluation shows that our method obtains re-
sult comparable or superior to the state of the
art. We demonstrate that the choice of the
parser affects the performance of the system.
We also apply the method to German and re-
port the results of an evaluation with humans.
</bodyText>
<sectionHeader confidence="0.995169" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999943818181819">
Within the field of text-to-text generation, the sen-
tence compression task can be defined as follows:
given a sentence 5, consisting of words w1w2...wn,
what is a subset of the words of 5, such that it
is grammatical and preserves essential information
from 5? There are many applications which would
benefit from a robust compression system, such as
subtitle generation, compression for mobile devices
with a limited screen size, or news digests. Given
that to date most text and speech summarization
systems are extractive, sentence compression tech-
niques are a common way to deal with redundancy
in their output.
In recent years, a number of approaches to sen-
tence compression have been developed (Jing, 2001;
Knight &amp; Marcu, 2002; Gagnon &amp; Da Sylva, 2005;
Turner &amp; Charniak, 2005; Clarke &amp; Lapata, 2008,
inter alia). Many explicitly rely on a language
model, usually a trigram model, to produce gram-
matical output (Knight &amp; Marcu, 2002; Hori &amp; Fu-
rui, 2004; Turner &amp; Charniak, 2005; Galley &amp; McK-
eown, 2007). Testing the grammaticality of the out-
put with a language model is justified when work-
ing with a language with rigid word order like En-
glish, and all but one approach mentioned have
been applied to English data. However, compress-
ing sentences in languages with less rigid word or-
der needs a deeper analysis to test grammaticality.
And even for languages with rigid word order the
trigram model ignores the structure of the sentence
and therefore may significantly distort the meaning
of the source sentence. Approaches going beyond
the word level either require a comprehensive lexi-
con (Jing, 2001), or manually devised rules (Gagnon
&amp; Da Sylva, 2005; Clarke &amp; Lapata, 2008) to de-
termine prunable constituents. A lexicon is not al-
ways available, whereas the hand-crafted rules may
not cover all cases and are too general to be univer-
sally applicable (e.g. PPs can be pruned).
In this paper we present a novel unsupervised ap-
proach to sentence compression which is motivated
by the belief that the grammaticality of the output
can be better ensured by compressing trees. In par-
ticular, given a dependency tree, we want to prune
subtrees which are neither obligatory syntactic argu-
ments, nor contribute important information to the
content of the sentence. A tree pruning approach
does not generate new dependencies and is unlikely
to produce a compression with a totally different
meaning. Our approach is unsupervised and adapt-
able to other languages, the main requirement be-
ing that there are a dependency parser and a corpus
available for the languages. We test our approach
on English and German data sets and obtain results
comparable or superior to the state of the art.
</bodyText>
<page confidence="0.87161">
25
</page>
<sectionHeader confidence="0.999208" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999414065217392">
Many existing compression systems use a noisy-
channel approach and rely on a language model
to test the grammaticality of the output (Knight &amp;
Marcu, 2002; Turner &amp; Charniak, 2005; Galley &amp;
McKeown, 2007). Other ways to ensure gram-
maticality and to decide whether a constituent is
obligatory or may be pruned are to utilize a sub-
categorization lexicon (Jing, 2001), or to define a
set of generally prunable constituents. Gagnon &amp;
Da Sylva (2005) prune dependency trees by remov-
ing prepositional complements of the verb, subordi-
nate clauses and noun appositions. Apparently, this
does not guarantee grammaticality in all cases. It
may also eliminate important information from the
tree.
Most approaches are supervised and require train-
ing data to learn which words or constituents can
be dropped from a sentence (Riezler et al., 2003;
McDonald, 2006). However, it is difficult to obtain
training data. Still, there are few unsupervised meth-
ods. For example, Hori &amp; Furui (2004) introduce
a scoring function which relies on such informa-
tion sources as word significance score and language
model. A compression of a given length which
maximizes the scoring function is then found with
dynamic programming. Clarke &amp; Lapata (2008)
present another unsupervised approach. They for-
mulate the task as an optimization problem and solve
it with integer linear programming. Two scores con-
tribute to their objective function – a trigram lan-
guage model score and a word significance score.
Additionally, the grammaticality of the output is en-
sured by a handful of linguistic constraints, stating
e.g. which arguments should be preserved.
In this paper we suggest an alternative to the pop-
ular language model basis for compression systems
– a method which compresses dependency trees and
not strings of words. We will argue that our formu-
lation has the following advantages: firstly, the ap-
proach is unsupervised, the only requirement being
that there is a sufficiently large corpus and a depen-
dency parser available. Secondly, it requires neither
a subcategorization lexicon nor hand-crafted rules to
decide which arguments are obligatory. Thirdly, it
finds a globally optimal compression by taking syn-
tax and word importance into account.
</bodyText>
<sectionHeader confidence="0.988143" genericHeader="method">
3 Dependency Based Compression
</sectionHeader>
<bodyText confidence="0.999759875">
Our method compresses sentences in that it removes
dependency edges from the dependency tree of a
sentence. The aim is to preserve dependencies
which are either required for the output to be gram-
matical or have an important word as the dependent.
The algorithm proceeds in three steps: tree transfor-
mation (Section 3.1), tree compression (Section 3.2)
and tree linearization (Section 3.3).
</bodyText>
<subsectionHeader confidence="0.99828">
3.1 Tree Transformation
</subsectionHeader>
<bodyText confidence="0.987039">
Before a dependency tree is compressed, i.e. be-
fore some of the dependencies are removed, the tree
is modified. We will demonstrate the effect of the
transformations with the sentence below:
</bodyText>
<equation confidence="0.528724">
(1) He said that he lived in Paris and Berlin
</equation>
<bodyText confidence="0.997804222222222">
The first transformation (ROOT) inserts an explicit
rootnode (Fig. 1(a)). The result of the second trans-
formation (VERB) is that every inflected verb in the
tree gets an edge originating from the rootnode (Fig.
1(b)). All edges outgoing from the rootnode bear the
s label. Apart from that we remove auxiliary edges
and memorize such grammatical properties as voice,
tense or negation for verbs.
The purpose of the remaining transformations is
to make relations between open-class words more
explicit. We want to decide on pruning an edge
judging from two considerations: (i) how important
for the head this argument is; (ii) how informative
the dependent word is. As an example, consider a
source sentence given in (2). Here, we want to de-
cide whether one prepositional phrase (or both) can
be pruned without making the resulting sentence un-
grammatical.
</bodyText>
<listItem confidence="0.787199">
(2) After some time, he moved to London.
</listItem>
<bodyText confidence="0.9999045">
It would not be very helpful to check whether an ar-
gument attached with the label pp is obligatory for
the verb move. Looking at a particular preposition
(after vs. to) would be more enlightening. This
motivates the PREP transformation which removes
prepositional nodes and places them as labels on the
edge from their head to the respective noun (Fig.
1(c)). We also decompose a chain of conjoined ele-
ments (CONJ) and attach each of them to the head of
the first element in the chain with the label the first
</bodyText>
<figure confidence="0.989445108108108">
26
root
s
root
s s
say
say
live
he
he
in
he
live
he
in
Paris Paris
and Berlin and Berlin
(a) The source tree after ROOT. (b) After VERB
he
in
root
s
s
say
he
in
Paris
live
he
root
s
s
say
live
in
and Berlin he Paris Berlin
(c) After PREP (d) After CONJ
</figure>
<figureCaption confidence="0.999975">
Figure 1: The dependency structure of He said that he lived in Paris and Berlin after the transformations
</figureCaption>
<bodyText confidence="0.9999096">
element attaches to its head with (Fig. 1(d)). This
way we can retain any of the conjoined elements
in the compression and do not have to preserve the
whole sequence of them if we are interested in only
one. This last transformation is not applied to verbs.
</bodyText>
<subsectionHeader confidence="0.998965">
3.2 Tree Compression
</subsectionHeader>
<bodyText confidence="0.9999945">
We formulate the compression task as an optimiza-
tion problem which we solve using integer linear
programming1. Given a transformed dependency
tree (a graph if new edges have been added), we de-
cide which dependency edges to remove. For each
directed dependency edge from head h to word w we
thus introduce a binary variable xlh,w where l stands
for the edge’s label:
</bodyText>
<equation confidence="0.86351625">
�
l _ 1 if the dependency is preserved
xh,w (1)
0 otherwise
</equation>
<bodyText confidence="0.961831333333333">
The goal is to find a subtree which gets the highest
score of the objective function (2) to which both the
1In our implementation we use lp solve (http://
sourceforge.net/projects/lpsolve).
probability of dependencies (P(l|h)) and the impor-
tance of dependent words (I(w)) contribute:
</bodyText>
<equation confidence="0.9828">
f(X) _ xlh,w · P(l|h) · I(w) (2)
x
</equation>
<bodyText confidence="0.999959666666667">
Intuitively, the conditional probabilities prevent us
from removing obligatory dependencies from the
tree. For example, P(subj|work) is higher than
P(with|work), and therefore the subject will be
preserved whereas the prepositional label and thus
the whole PP can be pruned. This way we do
not have to create an additional constraint for every
obligatory argument (e.g. subject or direct object).
Neither do we require a subcategorization lexicon to
look up which arguments are obligatory for a cer-
tain verb. Verb arguments are preserved because the
dependency edges, with which they are attached to
the head, get high scores. Table 1 presents the prob-
abilities of a number of labels given that the head
is study. Table 2 presents the probabilities for their
German counterparts.
Note that if we would not apply the PREP trans-
formation we would not be able to distinguish be-
</bodyText>
<page confidence="0.928004">
27
</page>
<tableCaption confidence="0.9968045">
Table 1: Probabilities of subj, d(irect)obj, in, at, after,
with, to given the verb study
Table 2: Probabilities of subj, obja(ccusative), in, at, af-
ter, with, to given the verb studieren
</tableCaption>
<bodyText confidence="0.999797583333333">
tween different prepositions and could only calcu-
late P(pp|studieren) which would not be very in-
formative. The probabilities for English are lower
than those for German because we calculate the con-
ditional probabilities given word lemma. In English,
the part of speech information cannot be induced
from the lemma and thus the set of possible labels
of a node is on average larger than in German.
There are many ways in which word importance,
I(w) can be defined. Here, we use the formula intro-
duced by Clarke &amp; Lapata (2008) which is a modifi-
cation of the significance score of Hori et al. (2003):
</bodyText>
<equation confidence="0.973271">
l FA
I(wi) = N · fi log (3)
Fi
</equation>
<bodyText confidence="0.998600666666667">
wi is the topic word (either noun or verb), fi is the
frequency of wi in the document, Fi is the frequency
of wi in the corpus, and FA is the sum of frequencies
of all topic words in the corpus. l is the number of
clause nodes above w and N is the maximum level
of embedding of the sentence w belongs to.
The objective function is subject to constraints of
two kinds. The constraints of the first kind are stuc-
tural and ensure that the preserved dependencies re-
sult in a tree. (4) ensures that each word has one
head at most. (5) ensures connectivity in the tree.
(6) restricts the size of the resulting tree to α words.
</bodyText>
<equation confidence="0.9120225">
∀w ∈ W, 1: xlh,w ≤ 1 (4)
h,l
</equation>
<bodyText confidence="0.999503208333333">
α is a function of the length of the source sentence
in open-class words. The function is not linear since
the degree of compression increases with the length
of the sentence. The compression rate of human-
generated sentences is about 70% (Clarke &amp; Lapata,
2008)2. To approximate this value, we set the pro-
portion of deleted words to be 20% for short sen-
tences (5-9 non-stop words), this value increases up
to 50% for long sentences (30+ words).
The constraints of the second type ensure the syn-
tactic validity of the output tree and explicitly state
which edges should be preserved. These constraints
can be general as well as conditional. The former
ensure that an edge is preserved if its source node
is retained in the output. Conditional syntactic con-
straints state that an edge has to be preserved if (and
only if) a certain other edge is preserved. We have
only one syntactic constraint which states that a sub-
ordinate conjunction (sc) should be preserved if and
only if the clause it belongs to functions as a sub-
ordinate clause (sub) in the output. If it is taken as
the main clause, the conjunction should be dropped.
In terms of edges, this can be formulated as follows
(7):
</bodyText>
<equation confidence="0.848499">
∀xscw,u, xsub
h,w − xscw,u = 0 (7)
</equation>
<bodyText confidence="0.999673142857143">
Due to the constraint (4), the compressed subtree
is always rooted in the node added as a result of the
first transformation. A compression of a sentence to
an embedded clause is not possible unless one pre-
serves the structure above the embedded clause. Of-
ten, however, main clauses are less important than an
embedded clause. For example, given the sentence
He said they have to be held in Beirut it is the em-
bedded clause which is informative and to which the
source sentence should be compressed. The purpose
of the VERB modification is to amend exactly this
problem. Having an edge from the rootnode to ev-
ery inflected verb allows us to compress the source
sentence to any clause.
</bodyText>
<subsectionHeader confidence="0.788515">
3.3 Tree Linearization
</subsectionHeader>
<table confidence="0.758637">
subj dobj in at after with to
0.16 0.13 0.05 0.04 0.01 0.01 0.01
subj obja in an nach mit zu
0.88 0.74 0.44 0.42 0.09 0.02 0.01
</table>
<figure confidence="0.887415090909091">
1:
∀w ∈ W,
h,l
1: xlh,w ≤ α (6)
x
2
1:
1
l
xh w −
|W |u,l
</figure>
<equation confidence="0.664595">
xlw,u ≥ 0 (5)
</equation>
<bodyText confidence="0.957735227272727">
A very simple but reasonable linearization technique
is to present the words of a compressed sentence in
the order they are found in the source sentence. This
method has been applied before and this is how we
Higher rates correspond to longer compressions.
28
linearize the trees obtained for the English data. Un-
fortunately, this method cannot be directly applied to
German because of the constraints on word order in
this language. One of the rules of German grammar
states that in the main clause the inflected part of the
verb occupies the second position, the first position
being occupied by exactly one constituent. There-
fore, if the sentence initial position in a source sen-
tence is occupied by a constituent which got pruned
off as a result of compression, the verb becomes
the first element of the sentence which results in an
undesirable output. There are linearization meth-
ods developed for German which find an optimal
word order for a sentence (Ringger et al., 2004;
Filippova &amp; Strube, 2007). We use our recent
method to linearize compressed trees.
</bodyText>
<sectionHeader confidence="0.961208" genericHeader="method">
4 Corpora and Annotation
</sectionHeader>
<bodyText confidence="0.999923434782609">
We apply our method to sentences from two corpora
in English and German. These are presented below.
English Compression Corpus: The English data
we use is a document-based compression cor-
pus from the British National Corpus and
American News Text Corpus which consists of
82 news stories3. We parsed the corpus with
RASP (Briscoe et al., 2006) and with the Stan-
ford PCFG parser (Klein &amp; Manning, 2003).
The output of the former is a set of dependency
relations whereas the latter provides an option
for converting the output into dependency for-
mat (de Marneffe et al., 2006) which we use.
T¨uBa-D/Z: The German corpus we use is a col-
lection of 1,000 newspaper articles (Telljohann
et al., 2003)4. Sentence boundaries, morphol-
ogy, dependency structure and anaphoric rela-
tions are manually annotated in this corpus.
RASP has been used by Clarke &amp; Lapata (2008)
whose state of the art results we compare with ours.
We use not only RASP but also the Stanford parser
for several reasons. Apart from being accurate, the
latter has an elaborated set of dependency relations
</bodyText>
<footnote confidence="0.92151325">
3The corpus is available from http://homepages.
inf.ed.ac.uk/s0460084/data.
4The corpus is available from http://www.sfs.
uni-tuebingen.de/en_tuebadz.shtml.
</footnote>
<bodyText confidence="0.999791578947368">
(48 vs. 15 of RASP) which is not overly large (com-
pared with the 106 grammatical relations of the Link
Parser). This is important for our system which
relies on syntactic information when making prun-
ing decisions. A comparison between the Stanford
parser and two dependency parsers, MiniPar and
Link Parser, showed a decent performance of the for-
mer (de Marneffe et al., 2006). It is also of interest to
see to what extent the choice of the parser influences
the results.
Apart from the corpora listed above, we use the
Tipster corpus to calculate conditional probabilities
of syntactic labels given head lemmas as well as
word significance scores. The significance score
is calculated from the total number of 128 mil-
lion nouns and verbs. Conditional probabilities are
calculated from a much smaller portion of Tipster
(about 6 million tokens). The latter number is com-
parable to the size of the data set we use to com-
pute the probabilities for German. There, we use
a corpus of about 4,000 articles from the German
Wikipedia to calculate conditional probabilities and
significance scores. The corpus is parsed with the
highly accurate CDG parser (Foth &amp; Menzel, 2006)
and has the same dependency format as T¨uBa-D/Z
(Versley, 2005).
Although all corpora are annotated with depen-
dency relations, there are considerable differences
between the annotation of the English and German
data sets. The phrase to dependency structure con-
version done by the Stanford parser makes the se-
mantic head of the constituent its syntactic head. For
example, in the sentence He is right it is the adjec-
tive right which is the root of the tree. Unlike that,
sentences from the German corpora always have a
verb as the root. To unify the formats, we write a set
of rules to make the verb the root of the tree in all
cases.
</bodyText>
<sectionHeader confidence="0.990961" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999974">
We evaluate the results automatically as well as with
human subjects. To assess the performance of the
method on the English data, we calculate the F-
measure on grammatical relations. Following Rie-
zler et al. (2003), we calculate average precision and
recall as the amount of grammatical relations shared
between the output of our system and the gold stan-
</bodyText>
<page confidence="0.830849">
29
</page>
<bodyText confidence="0.988888454545455">
dard variant divided over the total number of rela-
tions in the output and in the human-generated com-
pression respectively. According to Clarke &amp; Lapata
(2006), this measure reliably correlates with human
judgements. The results of our evaluation as well as
the state of the art results reported by Clarke &amp; Lap-
ata (2008) (LM+SIG+CONSTR), whose system uses
language model scoring (LM), word significance
score (SIG), and linguistic constraints (CONSTR),
are presented in Table 3. The F-measure reported
by Clarke &amp; Lapata (2008) is calculated with RASP
which their system builds upon. For our system we
present the results obtained on the data parsed with
RASP as well as with the Stanford parser (SP). In
both cases the F-measure is found with RASP in or-
der to allow for a fair comparison between the three
systems. We recalculate the compression rate for the
gold standard ignoring punctuation. On the whole
corpus the compression rate turns out to be slightly
higher than that reported by Clarke &amp; Lapata (2008)
(70.3%).
F-measure compr.rate
</bodyText>
<tableCaption confidence="0.994531">
Table 3: Average results on the English corpus
</tableCaption>
<bodyText confidence="0.998461823529412">
As there are no human-generated compressions
for German data, we evaluate the performance of the
method in terms of grammaticality and importance
by means of an experiment with native speakers. In
the experiment, humans are presented with a source
sentence and its compression which they are asked
to evaluate on two five-point scales. Higher grades
are given to better sentences. Importance represents
the amount of relevant information from the source
sentence retained in the compression. Since our
method does not generate punctuation, the judges
are asked to ignore errors due to missing commas.
Five participants took part in the experiment and
each rated the total of 25 sentences originating from
a randomly chosen newspaper article. Their ratings
as well as the ratings reported by Clarke &amp; Lapata
(2008) on English corpus are presented in Table 4.
</bodyText>
<figure confidence="0.459758">
grammar importance
LM+SIG+CONSTR
DEP-BASED (DE)
</figure>
<tableCaption confidence="0.994323">
Table 4: Average results for the German data
</tableCaption>
<sectionHeader confidence="0.99186" genericHeader="evaluation">
6 Discussion
</sectionHeader>
<bodyText confidence="0.9999602">
The results on the English data are comparable with
or superior to the state of the art. These were ob-
tained with a single linguistic constraint (7) and
without any elaborated resources which makes our
system adaptable to other languages. This suggests
that tree compression is a better basis for sentence
compression systems than language model-oriented
word deletion.
In order to explain why the choice of parser sig-
nificantly influences the performance of the method,
we calculate the precision P defined as the number
of dependencies shared by a human-generated com-
pression (dep,) and the source sentence (dep,) di-
vided over the total number of dependencies found
in the compression:
</bodyText>
<equation confidence="0.9517025">
P = |depc n deps |(8)
|depc|
</equation>
<bodyText confidence="0.986721">
The intuition is that if a parser does not reach high
precision on gold standard sentences, i.e. if it does
not assign similar dependency structures to a source
sentence and its compression, then it is hopeless
to expect it to produce good compression with our
dependency-based method. However, the precision
does not have to be as high as 100% because of,
e.g., changes within a chain of conjoined elements
or appositions. The precision of the two parsers cal-
culated over the compression corpus is presented in
</bodyText>
<tableCaption confidence="0.745687">
Table 5.
</tableCaption>
<table confidence="0.933611">
RASP Stanford parser
precision 79.6% 84.3%
</table>
<tableCaption confidence="0.999707">
Table 5: Precision of the parsers
</tableCaption>
<bodyText confidence="0.999186666666667">
The precision of the Stanford parser is about 5%
higher than that of RASP. In our opinion, this partly
explains why the use of the Stanford parser increases
the F-measure by 9 points. Another possible reason
for this improvement is that the Stanford parser iden-
tifies three times more dependency relations than
</bodyText>
<figure confidence="0.971980454545454">
GOLD
- 72.1%
LM+SIG+CONSTR
40.5 72.0%
DEP-BASED (RASP)
DEP-BASED (SP)
40.7 49.6%
49.3 69.3%
3.76 3.53
3.62 3.21
30
</figure>
<bodyText confidence="0.998966409090909">
RASP and thus allows for finer distinctions between
the arguments of different types.
Another point concerns the compression rates.
The compressions generated with RASP are consid-
erably shorter than those generated with the Stanford
parser. This is mainly due to the fact that the struc-
ture output by RASP is not necessarily a tree or a
connected graph. In such cases only the first subtree
of the sentence is taken as input and compressed.
The results on the German set are not conclu-
sive since the number of human judges is relatively
small. Still, these preliminary results are compara-
ble to those reported for English and thus give us
some evidence that the method can be adapted to
languages other than English. Interestingly, the im-
portance score depends on the grammaticality of the
sentence. A grammatical sentence can convey unim-
portant information but it was never the case that an
ungrammatical sentence got a high rating on the im-
portance scale. Some of the human judges told us
that they had difficulties assigning the importance
score to ungrammatical sentences.
</bodyText>
<sectionHeader confidence="0.998729" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999981636363636">
We presented a new compression method which
compresses dependency trees and does not rely on a
language model to test grammaticality. The method
is unsupervised and can be easily adapted to lan-
guages other than English. It does not require a
subcategorization lexicon or elaborated hand-crafted
rules to decide which arguments can be pruned and
finds a globally optimal compression taking syn-
tax and word importance into account. We demon-
strated that the performance of the system depends
on the parser and suggested a way to estimate how
well a parser is suited for the compression task. The
results indicate that the dependency-based approach
is an alternative to the language model-based one
which is worth pursuing.
Acknowledgements: This work has been funded
by the Klaus Tschira Foundation, Heidelberg, Ger-
many. The first author has been supported by a KTF
grant (09.009.2004). We would like to thank Yan-
nick Versley who helped us convert T¨uBa-D/Z in the
CDG format and Elke Teich and the three anony-
mous reviewers for their useful comments.
</bodyText>
<sectionHeader confidence="0.989584" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999171142857142">
Briscoe, Edward, John Carroll &amp; Rebecca Watson
(2006). The second release of the RASP sys-
tem. In Proceedings of the COLING-ACL In-
teractive Presentation Session, Sydney, Australia,
2006, pp. 77–80.
Clarke, James &amp; Mirella Lapata (2006). Models for
sentence compression: A comparison across do-
mains, training requirements and evaluation mea-
sures. In Proceedings of the 21st International
Conference on Computational Linguistics and
44th Annual Meeting of the Association for Com-
putational Linguistics, Sydney, Australia, 17–21
July 2006, pp. 377–385.
Clarke, James &amp; Mirella Lapata (2008). Global in-
ference for sentence compression: An integer lin-
ear programming approach. Journal of Artificial
Intelligence Research, 31:399–429.
de Marneffe, Marie-Catherine, Bill MacCartney &amp;
Christopher D. Manning (2006). Generating
typed dependency parses from phrase structure
parses. In Proceedings of the 5th International
Conference on Language Resources and Evalua-
tion, Genoa, Italy, 22–28 May 2006, pp. 449–454.
Filippova, Katja &amp; Michael Strube (2007). Generat-
ing constituent order in German clauses. In Pro-
ceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics, Prague,
Czech Republic, 23–30 June 2007, pp. 320–327.
Foth, Kilian &amp; Wolfgang Menzel (2006). Hybrid
parsing: Using probabilistic models as predictors
for a symbolic parser. In Proceedings of the 21st
International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, Sydney, Aus-
tralia, 17–21 July 2006, pp. 321–327.
Gagnon, Michel &amp; Lyne Da Sylva (2005). Text
summarization by sentence extraction and syn-
tactic pruning. In Proceedings of Computational
Linguistics in the North East, Gatineau, Qu´ebec,
Canada, 26 August 2005.
Galley, Michel &amp; Kathleen R. McKeown (2007).
Lexicalized Markov grammars for sentence com-
</reference>
<page confidence="0.913502">
31
</page>
<reference confidence="0.999592523809524">
pression. In Proceedings of Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Compu-
tational Linguistics, Rochester, N.Y., 22–27 April
2007, pp. 180–187.
Hori, Chiori &amp; Sadaoki Furui (2004). Speech sum-
marization: An approach through word extraction
and a method for evaluation. IEEE Transactions
on Information and Systems, E87-D(1):15–25.
Hori, Chiori, Sadaoki Furui, Rob Malkin, Hua Yu
&amp; Alex Waibel (2003). A statistical approach to
automatic speech summarization. EURASIPJour-
nal on Applied Signal Processing, 2:128–139.
Jing, Hongyan (2001). Cut-and-Paste Text Summa-
rization, (Ph.D. thesis). Computer Science De-
partment, Columbia University, New York, N.Y.
Klein, Dan &amp; Christopher D. Manning (2003). Ac-
curate unlexicalized parsing. In Proceedings of
the 41st Annual Meeting of the Association for
Computational Linguistics, Sapporo, Japan, 7–12
July 2003, pp. 423–430.
Knight, Kevin &amp; Daniel Marcu (2002). Summariza-
tion beyond sentence extraction: A probabilistic
approach to sentence compression. Artificial In-
telligence, 139(1):91–107.
McDonald, Ryan (2006). Discriminative sentence
compression with soft syntactic evidence. In
Proceedings of the 11th Conference of the Eu-
ropean Chapter of the Association for Computa-
tional Linguistics, Trento, Italy, 3–7 April 2006,
pp. 297–304.
Riezler, Stefan, Tracy H. King, Richard Crouch &amp;
Annie Zaenen (2003). Statistical sentence con-
densation using ambiguity packing and stochastic
disambiguation methods for Lexical-Functional
Grammar. In Proceedings of the Human Lan-
guage Technology Conference of the North Amer-
ican Chapter of the Association for Computa-
tional Linguistics, Edmonton, Alberta, Canada,
27 May –1 June 2003, pp. 118–125.
Ringger, Eric, Michael Gamon, Robert C. Moore,
David Rojas, Martine Smets &amp; Simon Corston-
Oliver (2004). Linguistically informed statisti-
cal models of constituent structure for ordering
in sentence realization. In Proceedings of the
20th International Conference on Computational
Linguistics, Geneva, Switzerland, 23–27 August
2004, pp. 673–679.
Telljohann, Heike, Erhard W. Hinrichs &amp; Sandra
K¨ubler (2003). Stylebook for the T¨ubingen tree-
bank of written German (T¨uBa-D/Z). Technical
Report: Seminar f¨ur Sprachwissenschaft, Univer-
sit¨at T¨ubingen, T¨ubingen, Germany.
Turner, Jenine &amp; Eugene Charniak (2005). Su-
pervised and unsupervised learning for sentence
compression. In Proceedings of the 43rd An-
nual Meeting of the Association for Computa-
tional Linguistics, Ann Arbor, Mich., 25–30 June
2005, pp. 290–297.
Versley, Yannick (2005). Parser evaluation across
text types. In Proceedings of the 4th Workshop
on Treebanks and Linguistic Theories, Barcelona,
Spain, 9-10 December 2005.
</reference>
<page confidence="0.944662">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.525638">
<title confidence="0.990398">Dependency Tree Based Sentence Compression</title>
<author confidence="0.829756">Filippova</author>
<affiliation confidence="0.82684">EML Research SchloB-Wolfsbrunnenweg</affiliation>
<address confidence="0.998814">69118 Heidelberg, Germany</address>
<web confidence="0.905906">http://www.eml-research.de/nlp</web>
<abstract confidence="0.998493">We present a novel unsupervised method for sentence compression which relies on a dependency tree representation and shortens sentences by removing subtrees. An automatic evaluation shows that our method obtains result comparable or superior to the state of the art. We demonstrate that the choice of the parser affects the performance of the system. We also apply the method to German and report the results of an evaluation with humans.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Edward Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING-ACL Interactive Presentation Session,</booktitle>
<pages>77--80</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="14947" citStr="Briscoe et al., 2006" startWordPosition="2551" endWordPosition="2554">tence which results in an undesirable output. There are linearization methods developed for German which find an optimal word order for a sentence (Ringger et al., 2004; Filippova &amp; Strube, 2007). We use our recent method to linearize compressed trees. 4 Corpora and Annotation We apply our method to sentences from two corpora in English and German. These are presented below. English Compression Corpus: The English data we use is a document-based compression corpus from the British National Corpus and American News Text Corpus which consists of 82 news stories3. We parsed the corpus with RASP (Briscoe et al., 2006) and with the Stanford PCFG parser (Klein &amp; Manning, 2003). The output of the former is a set of dependency relations whereas the latter provides an option for converting the output into dependency format (de Marneffe et al., 2006) which we use. T¨uBa-D/Z: The German corpus we use is a collection of 1,000 newspaper articles (Telljohann et al., 2003)4. Sentence boundaries, morphology, dependency structure and anaphoric relations are manually annotated in this corpus. RASP has been used by Clarke &amp; Lapata (2008) whose state of the art results we compare with ours. We use not only RASP but also t</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Briscoe, Edward, John Carroll &amp; Rebecca Watson (2006). The second release of the RASP system. In Proceedings of the COLING-ACL Interactive Presentation Session, Sydney, Australia, 2006, pp. 77–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Models for sentence compression: A comparison across domains, training requirements and evaluation measures.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>377--385</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="18160" citStr="Clarke &amp; Lapata (2006)" startWordPosition="3085" endWordPosition="3088">nify the formats, we write a set of rules to make the verb the root of the tree in all cases. 5 Evaluation We evaluate the results automatically as well as with human subjects. To assess the performance of the method on the English data, we calculate the Fmeasure on grammatical relations. Following Riezler et al. (2003), we calculate average precision and recall as the amount of grammatical relations shared between the output of our system and the gold stan29 dard variant divided over the total number of relations in the output and in the human-generated compression respectively. According to Clarke &amp; Lapata (2006), this measure reliably correlates with human judgements. The results of our evaluation as well as the state of the art results reported by Clarke &amp; Lapata (2008) (LM+SIG+CONSTR), whose system uses language model scoring (LM), word significance score (SIG), and linguistic constraints (CONSTR), are presented in Table 3. The F-measure reported by Clarke &amp; Lapata (2008) is calculated with RASP which their system builds upon. For our system we present the results obtained on the data parsed with RASP as well as with the Stanford parser (SP). In both cases the F-measure is found with RASP in order </context>
</contexts>
<marker>Clarke, Lapata, 2006</marker>
<rawString>Clarke, James &amp; Mirella Lapata (2006). Models for sentence compression: A comparison across domains, training requirements and evaluation measures. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Sydney, Australia, 17–21 July 2006, pp. 377–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>31--399</pages>
<contexts>
<context position="1449" citStr="Clarke &amp; Lapata, 2008" startWordPosition="224" endWordPosition="227"> 5, such that it is grammatical and preserves essential information from 5? There are many applications which would benefit from a robust compression system, such as subtitle generation, compression for mobile devices with a limited screen size, or news digests. Given that to date most text and speech summarization systems are extractive, sentence compression techniques are a common way to deal with redundancy in their output. In recent years, a number of approaches to sentence compression have been developed (Jing, 2001; Knight &amp; Marcu, 2002; Gagnon &amp; Da Sylva, 2005; Turner &amp; Charniak, 2005; Clarke &amp; Lapata, 2008, inter alia). Many explicitly rely on a language model, usually a trigram model, to produce grammatical output (Knight &amp; Marcu, 2002; Hori &amp; Furui, 2004; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Testing the grammaticality of the output with a language model is justified when working with a language with rigid word order like English, and all but one approach mentioned have been applied to English data. However, compressing sentences in languages with less rigid word order needs a deeper analysis to test grammaticality. And even for languages with rigid word order the trigram model ig</context>
<context position="4571" citStr="Clarke &amp; Lapata (2008)" startWordPosition="740" endWordPosition="743">aticality in all cases. It may also eliminate important information from the tree. Most approaches are supervised and require training data to learn which words or constituents can be dropped from a sentence (Riezler et al., 2003; McDonald, 2006). However, it is difficult to obtain training data. Still, there are few unsupervised methods. For example, Hori &amp; Furui (2004) introduce a scoring function which relies on such information sources as word significance score and language model. A compression of a given length which maximizes the scoring function is then found with dynamic programming. Clarke &amp; Lapata (2008) present another unsupervised approach. They formulate the task as an optimization problem and solve it with integer linear programming. Two scores contribute to their objective function – a trigram language model score and a word significance score. Additionally, the grammaticality of the output is ensured by a handful of linguistic constraints, stating e.g. which arguments should be preserved. In this paper we suggest an alternative to the popular language model basis for compression systems – a method which compresses dependency trees and not strings of words. We will argue that our formula</context>
<context position="10632" citStr="Clarke &amp; Lapata (2008)" startWordPosition="1764" endWordPosition="1767">able 2: Probabilities of subj, obja(ccusative), in, at, after, with, to given the verb studieren tween different prepositions and could only calculate P(pp|studieren) which would not be very informative. The probabilities for English are lower than those for German because we calculate the conditional probabilities given word lemma. In English, the part of speech information cannot be induced from the lemma and thus the set of possible labels of a node is on average larger than in German. There are many ways in which word importance, I(w) can be defined. Here, we use the formula introduced by Clarke &amp; Lapata (2008) which is a modification of the significance score of Hori et al. (2003): l FA I(wi) = N · fi log (3) Fi wi is the topic word (either noun or verb), fi is the frequency of wi in the document, Fi is the frequency of wi in the corpus, and FA is the sum of frequencies of all topic words in the corpus. l is the number of clause nodes above w and N is the maximum level of embedding of the sentence w belongs to. The objective function is subject to constraints of two kinds. The constraints of the first kind are stuctural and ensure that the preserved dependencies result in a tree. (4) ensures that e</context>
<context position="15462" citStr="Clarke &amp; Lapata (2008)" startWordPosition="2638" endWordPosition="2641"> News Text Corpus which consists of 82 news stories3. We parsed the corpus with RASP (Briscoe et al., 2006) and with the Stanford PCFG parser (Klein &amp; Manning, 2003). The output of the former is a set of dependency relations whereas the latter provides an option for converting the output into dependency format (de Marneffe et al., 2006) which we use. T¨uBa-D/Z: The German corpus we use is a collection of 1,000 newspaper articles (Telljohann et al., 2003)4. Sentence boundaries, morphology, dependency structure and anaphoric relations are manually annotated in this corpus. RASP has been used by Clarke &amp; Lapata (2008) whose state of the art results we compare with ours. We use not only RASP but also the Stanford parser for several reasons. Apart from being accurate, the latter has an elaborated set of dependency relations 3The corpus is available from http://homepages. inf.ed.ac.uk/s0460084/data. 4The corpus is available from http://www.sfs. uni-tuebingen.de/en_tuebadz.shtml. (48 vs. 15 of RASP) which is not overly large (compared with the 106 grammatical relations of the Link Parser). This is important for our system which relies on syntactic information when making pruning decisions. A comparison between</context>
<context position="18322" citStr="Clarke &amp; Lapata (2008)" startWordPosition="3112" endWordPosition="3116">uman subjects. To assess the performance of the method on the English data, we calculate the Fmeasure on grammatical relations. Following Riezler et al. (2003), we calculate average precision and recall as the amount of grammatical relations shared between the output of our system and the gold stan29 dard variant divided over the total number of relations in the output and in the human-generated compression respectively. According to Clarke &amp; Lapata (2006), this measure reliably correlates with human judgements. The results of our evaluation as well as the state of the art results reported by Clarke &amp; Lapata (2008) (LM+SIG+CONSTR), whose system uses language model scoring (LM), word significance score (SIG), and linguistic constraints (CONSTR), are presented in Table 3. The F-measure reported by Clarke &amp; Lapata (2008) is calculated with RASP which their system builds upon. For our system we present the results obtained on the data parsed with RASP as well as with the Stanford parser (SP). In both cases the F-measure is found with RASP in order to allow for a fair comparison between the three systems. We recalculate the compression rate for the gold standard ignoring punctuation. On the whole corpus the </context>
<context position="19906" citStr="Clarke &amp; Lapata (2008)" startWordPosition="3366" endWordPosition="3369">s. In the experiment, humans are presented with a source sentence and its compression which they are asked to evaluate on two five-point scales. Higher grades are given to better sentences. Importance represents the amount of relevant information from the source sentence retained in the compression. Since our method does not generate punctuation, the judges are asked to ignore errors due to missing commas. Five participants took part in the experiment and each rated the total of 25 sentences originating from a randomly chosen newspaper article. Their ratings as well as the ratings reported by Clarke &amp; Lapata (2008) on English corpus are presented in Table 4. grammar importance LM+SIG+CONSTR DEP-BASED (DE) Table 4: Average results for the German data 6 Discussion The results on the English data are comparable with or superior to the state of the art. These were obtained with a single linguistic constraint (7) and without any elaborated resources which makes our system adaptable to other languages. This suggests that tree compression is a better basis for sentence compression systems than language model-oriented word deletion. In order to explain why the choice of parser significantly influences the perfo</context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>Clarke, James &amp; Mirella Lapata (2008). Global inference for sentence compression: An integer linear programming approach. Journal of Artificial Intelligence Research, 31:399–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation,</booktitle>
<pages>449--454</pages>
<location>Genoa, Italy,</location>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>de Marneffe, Marie-Catherine, Bill MacCartney &amp; Christopher D. Manning (2006). Generating typed dependency parses from phrase structure parses. In Proceedings of the 5th International Conference on Language Resources and Evaluation, Genoa, Italy, 22–28 May 2006, pp. 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Filippova</author>
<author>Michael Strube</author>
</authors>
<title>Generating constituent order in German clauses.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>320--327</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="14521" citStr="Filippova &amp; Strube, 2007" startWordPosition="2481" endWordPosition="2484">e of the constraints on word order in this language. One of the rules of German grammar states that in the main clause the inflected part of the verb occupies the second position, the first position being occupied by exactly one constituent. Therefore, if the sentence initial position in a source sentence is occupied by a constituent which got pruned off as a result of compression, the verb becomes the first element of the sentence which results in an undesirable output. There are linearization methods developed for German which find an optimal word order for a sentence (Ringger et al., 2004; Filippova &amp; Strube, 2007). We use our recent method to linearize compressed trees. 4 Corpora and Annotation We apply our method to sentences from two corpora in English and German. These are presented below. English Compression Corpus: The English data we use is a document-based compression corpus from the British National Corpus and American News Text Corpus which consists of 82 news stories3. We parsed the corpus with RASP (Briscoe et al., 2006) and with the Stanford PCFG parser (Klein &amp; Manning, 2003). The output of the former is a set of dependency relations whereas the latter provides an option for converting the</context>
</contexts>
<marker>Filippova, Strube, 2007</marker>
<rawString>Filippova, Katja &amp; Michael Strube (2007). Generating constituent order in German clauses. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Prague, Czech Republic, 23–30 June 2007, pp. 320–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian Foth</author>
<author>Wolfgang Menzel</author>
</authors>
<title>Hybrid parsing: Using probabilistic models as predictors for a symbolic parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>321--327</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="16997" citStr="Foth &amp; Menzel, 2006" startWordPosition="2884" endWordPosition="2887">onditional probabilities of syntactic labels given head lemmas as well as word significance scores. The significance score is calculated from the total number of 128 million nouns and verbs. Conditional probabilities are calculated from a much smaller portion of Tipster (about 6 million tokens). The latter number is comparable to the size of the data set we use to compute the probabilities for German. There, we use a corpus of about 4,000 articles from the German Wikipedia to calculate conditional probabilities and significance scores. The corpus is parsed with the highly accurate CDG parser (Foth &amp; Menzel, 2006) and has the same dependency format as T¨uBa-D/Z (Versley, 2005). Although all corpora are annotated with dependency relations, there are considerable differences between the annotation of the English and German data sets. The phrase to dependency structure conversion done by the Stanford parser makes the semantic head of the constituent its syntactic head. For example, in the sentence He is right it is the adjective right which is the root of the tree. Unlike that, sentences from the German corpora always have a verb as the root. To unify the formats, we write a set of rules to make the verb </context>
</contexts>
<marker>Foth, Menzel, 2006</marker>
<rawString>Foth, Kilian &amp; Wolfgang Menzel (2006). Hybrid parsing: Using probabilistic models as predictors for a symbolic parser. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Sydney, Australia, 17–21 July 2006, pp. 321–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Gagnon</author>
<author>Lyne Da Sylva</author>
</authors>
<title>Text summarization by sentence extraction and syntactic pruning.</title>
<date>2005</date>
<booktitle>In Proceedings of Computational Linguistics in the North East,</booktitle>
<location>Gatineau, Qu´ebec,</location>
<marker>Gagnon, Sylva, 2005</marker>
<rawString>Gagnon, Michel &amp; Lyne Da Sylva (2005). Text summarization by sentence extraction and syntactic pruning. In Proceedings of Computational Linguistics in the North East, Gatineau, Qu´ebec, Canada, 26 August 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Lexicalized Markov grammars for sentence compression.</title>
<date>2007</date>
<booktitle>In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>180--187</pages>
<location>Rochester, N.Y.,</location>
<contexts>
<context position="1652" citStr="Galley &amp; McKeown, 2007" startWordPosition="259" endWordPosition="263">r mobile devices with a limited screen size, or news digests. Given that to date most text and speech summarization systems are extractive, sentence compression techniques are a common way to deal with redundancy in their output. In recent years, a number of approaches to sentence compression have been developed (Jing, 2001; Knight &amp; Marcu, 2002; Gagnon &amp; Da Sylva, 2005; Turner &amp; Charniak, 2005; Clarke &amp; Lapata, 2008, inter alia). Many explicitly rely on a language model, usually a trigram model, to produce grammatical output (Knight &amp; Marcu, 2002; Hori &amp; Furui, 2004; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Testing the grammaticality of the output with a language model is justified when working with a language with rigid word order like English, and all but one approach mentioned have been applied to English data. However, compressing sentences in languages with less rigid word order needs a deeper analysis to test grammaticality. And even for languages with rigid word order the trigram model ignores the structure of the sentence and therefore may significantly distort the meaning of the source sentence. Approaches going beyond the word level either require a comprehensive lexicon (Jing, 2001),</context>
<context position="3550" citStr="Galley &amp; McKeown, 2007" startWordPosition="577" endWordPosition="580">oach does not generate new dependencies and is unlikely to produce a compression with a totally different meaning. Our approach is unsupervised and adaptable to other languages, the main requirement being that there are a dependency parser and a corpus available for the languages. We test our approach on English and German data sets and obtain results comparable or superior to the state of the art. 25 2 Related Work Many existing compression systems use a noisychannel approach and rely on a language model to test the grammaticality of the output (Knight &amp; Marcu, 2002; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Other ways to ensure grammaticality and to decide whether a constituent is obligatory or may be pruned are to utilize a subcategorization lexicon (Jing, 2001), or to define a set of generally prunable constituents. Gagnon &amp; Da Sylva (2005) prune dependency trees by removing prepositional complements of the verb, subordinate clauses and noun appositions. Apparently, this does not guarantee grammaticality in all cases. It may also eliminate important information from the tree. Most approaches are supervised and require training data to learn which words or constituents can be dropped from a se</context>
</contexts>
<marker>Galley, McKeown, 2007</marker>
<rawString>Galley, Michel &amp; Kathleen R. McKeown (2007). Lexicalized Markov grammars for sentence compression. In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics, Rochester, N.Y., 22–27 April 2007, pp. 180–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chiori Hori</author>
<author>Sadaoki Furui</author>
</authors>
<title>Speech summarization: An approach through word extraction and a method for evaluation.</title>
<date>2004</date>
<journal>IEEE Transactions on Information and Systems,</journal>
<pages>87--1</pages>
<contexts>
<context position="1602" citStr="Hori &amp; Furui, 2004" startWordPosition="250" endWordPosition="254">, such as subtitle generation, compression for mobile devices with a limited screen size, or news digests. Given that to date most text and speech summarization systems are extractive, sentence compression techniques are a common way to deal with redundancy in their output. In recent years, a number of approaches to sentence compression have been developed (Jing, 2001; Knight &amp; Marcu, 2002; Gagnon &amp; Da Sylva, 2005; Turner &amp; Charniak, 2005; Clarke &amp; Lapata, 2008, inter alia). Many explicitly rely on a language model, usually a trigram model, to produce grammatical output (Knight &amp; Marcu, 2002; Hori &amp; Furui, 2004; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Testing the grammaticality of the output with a language model is justified when working with a language with rigid word order like English, and all but one approach mentioned have been applied to English data. However, compressing sentences in languages with less rigid word order needs a deeper analysis to test grammaticality. And even for languages with rigid word order the trigram model ignores the structure of the sentence and therefore may significantly distort the meaning of the source sentence. Approaches going beyond the word level ei</context>
<context position="4322" citStr="Hori &amp; Furui (2004)" startWordPosition="701" endWordPosition="704">, 2001), or to define a set of generally prunable constituents. Gagnon &amp; Da Sylva (2005) prune dependency trees by removing prepositional complements of the verb, subordinate clauses and noun appositions. Apparently, this does not guarantee grammaticality in all cases. It may also eliminate important information from the tree. Most approaches are supervised and require training data to learn which words or constituents can be dropped from a sentence (Riezler et al., 2003; McDonald, 2006). However, it is difficult to obtain training data. Still, there are few unsupervised methods. For example, Hori &amp; Furui (2004) introduce a scoring function which relies on such information sources as word significance score and language model. A compression of a given length which maximizes the scoring function is then found with dynamic programming. Clarke &amp; Lapata (2008) present another unsupervised approach. They formulate the task as an optimization problem and solve it with integer linear programming. Two scores contribute to their objective function – a trigram language model score and a word significance score. Additionally, the grammaticality of the output is ensured by a handful of linguistic constraints, st</context>
</contexts>
<marker>Hori, Furui, 2004</marker>
<rawString>Hori, Chiori &amp; Sadaoki Furui (2004). Speech summarization: An approach through word extraction and a method for evaluation. IEEE Transactions on Information and Systems, E87-D(1):15–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chiori Hori</author>
<author>Sadaoki Furui</author>
<author>Rob Malkin</author>
</authors>
<title>Hua Yu &amp; Alex Waibel</title>
<date>2003</date>
<booktitle>EURASIPJournal on Applied Signal Processing,</booktitle>
<pages>2--128</pages>
<contexts>
<context position="10704" citStr="Hori et al. (2003)" startWordPosition="1778" endWordPosition="1781">n the verb studieren tween different prepositions and could only calculate P(pp|studieren) which would not be very informative. The probabilities for English are lower than those for German because we calculate the conditional probabilities given word lemma. In English, the part of speech information cannot be induced from the lemma and thus the set of possible labels of a node is on average larger than in German. There are many ways in which word importance, I(w) can be defined. Here, we use the formula introduced by Clarke &amp; Lapata (2008) which is a modification of the significance score of Hori et al. (2003): l FA I(wi) = N · fi log (3) Fi wi is the topic word (either noun or verb), fi is the frequency of wi in the document, Fi is the frequency of wi in the corpus, and FA is the sum of frequencies of all topic words in the corpus. l is the number of clause nodes above w and N is the maximum level of embedding of the sentence w belongs to. The objective function is subject to constraints of two kinds. The constraints of the first kind are stuctural and ensure that the preserved dependencies result in a tree. (4) ensures that each word has one head at most. (5) ensures connectivity in the tree. (6)</context>
</contexts>
<marker>Hori, Furui, Malkin, 2003</marker>
<rawString>Hori, Chiori, Sadaoki Furui, Rob Malkin, Hua Yu &amp; Alex Waibel (2003). A statistical approach to automatic speech summarization. EURASIPJournal on Applied Signal Processing, 2:128–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongyan Jing</author>
</authors>
<title>Cut-and-Paste Text Summarization,</title>
<date>2001</date>
<tech>(Ph.D. thesis).</tech>
<institution>Computer Science Department, Columbia University,</institution>
<location>New York, N.Y.</location>
<contexts>
<context position="1354" citStr="Jing, 2001" startWordPosition="209" endWordPosition="210"> given a sentence 5, consisting of words w1w2...wn, what is a subset of the words of 5, such that it is grammatical and preserves essential information from 5? There are many applications which would benefit from a robust compression system, such as subtitle generation, compression for mobile devices with a limited screen size, or news digests. Given that to date most text and speech summarization systems are extractive, sentence compression techniques are a common way to deal with redundancy in their output. In recent years, a number of approaches to sentence compression have been developed (Jing, 2001; Knight &amp; Marcu, 2002; Gagnon &amp; Da Sylva, 2005; Turner &amp; Charniak, 2005; Clarke &amp; Lapata, 2008, inter alia). Many explicitly rely on a language model, usually a trigram model, to produce grammatical output (Knight &amp; Marcu, 2002; Hori &amp; Furui, 2004; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Testing the grammaticality of the output with a language model is justified when working with a language with rigid word order like English, and all but one approach mentioned have been applied to English data. However, compressing sentences in languages with less rigid word order needs a deeper ana</context>
<context position="3710" citStr="Jing, 2001" startWordPosition="606" endWordPosition="607">ages, the main requirement being that there are a dependency parser and a corpus available for the languages. We test our approach on English and German data sets and obtain results comparable or superior to the state of the art. 25 2 Related Work Many existing compression systems use a noisychannel approach and rely on a language model to test the grammaticality of the output (Knight &amp; Marcu, 2002; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Other ways to ensure grammaticality and to decide whether a constituent is obligatory or may be pruned are to utilize a subcategorization lexicon (Jing, 2001), or to define a set of generally prunable constituents. Gagnon &amp; Da Sylva (2005) prune dependency trees by removing prepositional complements of the verb, subordinate clauses and noun appositions. Apparently, this does not guarantee grammaticality in all cases. It may also eliminate important information from the tree. Most approaches are supervised and require training data to learn which words or constituents can be dropped from a sentence (Riezler et al., 2003; McDonald, 2006). However, it is difficult to obtain training data. Still, there are few unsupervised methods. For example, Hori &amp; </context>
</contexts>
<marker>Jing, 2001</marker>
<rawString>Jing, Hongyan (2001). Cut-and-Paste Text Summarization, (Ph.D. thesis). Computer Science Department, Columbia University, New York, N.Y.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<location>Sapporo,</location>
<contexts>
<context position="15005" citStr="Klein &amp; Manning, 2003" startWordPosition="2562" endWordPosition="2565">inearization methods developed for German which find an optimal word order for a sentence (Ringger et al., 2004; Filippova &amp; Strube, 2007). We use our recent method to linearize compressed trees. 4 Corpora and Annotation We apply our method to sentences from two corpora in English and German. These are presented below. English Compression Corpus: The English data we use is a document-based compression corpus from the British National Corpus and American News Text Corpus which consists of 82 news stories3. We parsed the corpus with RASP (Briscoe et al., 2006) and with the Stanford PCFG parser (Klein &amp; Manning, 2003). The output of the former is a set of dependency relations whereas the latter provides an option for converting the output into dependency format (de Marneffe et al., 2006) which we use. T¨uBa-D/Z: The German corpus we use is a collection of 1,000 newspaper articles (Telljohann et al., 2003)4. Sentence boundaries, morphology, dependency structure and anaphoric relations are manually annotated in this corpus. RASP has been used by Clarke &amp; Lapata (2008) whose state of the art results we compare with ours. We use not only RASP but also the Stanford parser for several reasons. Apart from being a</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, Dan &amp; Christopher D. Manning (2003). Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, Sapporo, Japan, 7–12 July 2003, pp. 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Summarization beyond sentence extraction: A probabilistic approach to sentence compression.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<volume>139</volume>
<issue>1</issue>
<contexts>
<context position="1376" citStr="Knight &amp; Marcu, 2002" startWordPosition="211" endWordPosition="214">tence 5, consisting of words w1w2...wn, what is a subset of the words of 5, such that it is grammatical and preserves essential information from 5? There are many applications which would benefit from a robust compression system, such as subtitle generation, compression for mobile devices with a limited screen size, or news digests. Given that to date most text and speech summarization systems are extractive, sentence compression techniques are a common way to deal with redundancy in their output. In recent years, a number of approaches to sentence compression have been developed (Jing, 2001; Knight &amp; Marcu, 2002; Gagnon &amp; Da Sylva, 2005; Turner &amp; Charniak, 2005; Clarke &amp; Lapata, 2008, inter alia). Many explicitly rely on a language model, usually a trigram model, to produce grammatical output (Knight &amp; Marcu, 2002; Hori &amp; Furui, 2004; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Testing the grammaticality of the output with a language model is justified when working with a language with rigid word order like English, and all but one approach mentioned have been applied to English data. However, compressing sentences in languages with less rigid word order needs a deeper analysis to test grammati</context>
<context position="3500" citStr="Knight &amp; Marcu, 2002" startWordPosition="569" endWordPosition="572">he content of the sentence. A tree pruning approach does not generate new dependencies and is unlikely to produce a compression with a totally different meaning. Our approach is unsupervised and adaptable to other languages, the main requirement being that there are a dependency parser and a corpus available for the languages. We test our approach on English and German data sets and obtain results comparable or superior to the state of the art. 25 2 Related Work Many existing compression systems use a noisychannel approach and rely on a language model to test the grammaticality of the output (Knight &amp; Marcu, 2002; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Other ways to ensure grammaticality and to decide whether a constituent is obligatory or may be pruned are to utilize a subcategorization lexicon (Jing, 2001), or to define a set of generally prunable constituents. Gagnon &amp; Da Sylva (2005) prune dependency trees by removing prepositional complements of the verb, subordinate clauses and noun appositions. Apparently, this does not guarantee grammaticality in all cases. It may also eliminate important information from the tree. Most approaches are supervised and require training data to learn wh</context>
</contexts>
<marker>Knight, Marcu, 2002</marker>
<rawString>Knight, Kevin &amp; Daniel Marcu (2002). Summarization beyond sentence extraction: A probabilistic approach to sentence compression. Artificial Intelligence, 139(1):91–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>Discriminative sentence compression with soft syntactic evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>297--304</pages>
<location>Trento,</location>
<contexts>
<context position="4195" citStr="McDonald, 2006" startWordPosition="682" endWordPosition="683">icality and to decide whether a constituent is obligatory or may be pruned are to utilize a subcategorization lexicon (Jing, 2001), or to define a set of generally prunable constituents. Gagnon &amp; Da Sylva (2005) prune dependency trees by removing prepositional complements of the verb, subordinate clauses and noun appositions. Apparently, this does not guarantee grammaticality in all cases. It may also eliminate important information from the tree. Most approaches are supervised and require training data to learn which words or constituents can be dropped from a sentence (Riezler et al., 2003; McDonald, 2006). However, it is difficult to obtain training data. Still, there are few unsupervised methods. For example, Hori &amp; Furui (2004) introduce a scoring function which relies on such information sources as word significance score and language model. A compression of a given length which maximizes the scoring function is then found with dynamic programming. Clarke &amp; Lapata (2008) present another unsupervised approach. They formulate the task as an optimization problem and solve it with integer linear programming. Two scores contribute to their objective function – a trigram language model score and </context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>McDonald, Ryan (2006). Discriminative sentence compression with soft syntactic evidence. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, Trento, Italy, 3–7 April 2006, pp. 297–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy H King</author>
<author>Richard Crouch</author>
<author>Annie Zaenen</author>
</authors>
<title>Statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for Lexical-Functional Grammar.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>118--125</pages>
<location>Edmonton, Alberta,</location>
<contexts>
<context position="4178" citStr="Riezler et al., 2003" startWordPosition="678" endWordPosition="681">ways to ensure grammaticality and to decide whether a constituent is obligatory or may be pruned are to utilize a subcategorization lexicon (Jing, 2001), or to define a set of generally prunable constituents. Gagnon &amp; Da Sylva (2005) prune dependency trees by removing prepositional complements of the verb, subordinate clauses and noun appositions. Apparently, this does not guarantee grammaticality in all cases. It may also eliminate important information from the tree. Most approaches are supervised and require training data to learn which words or constituents can be dropped from a sentence (Riezler et al., 2003; McDonald, 2006). However, it is difficult to obtain training data. Still, there are few unsupervised methods. For example, Hori &amp; Furui (2004) introduce a scoring function which relies on such information sources as word significance score and language model. A compression of a given length which maximizes the scoring function is then found with dynamic programming. Clarke &amp; Lapata (2008) present another unsupervised approach. They formulate the task as an optimization problem and solve it with integer linear programming. Two scores contribute to their objective function – a trigram language</context>
<context position="17859" citStr="Riezler et al. (2003)" startWordPosition="3034" endWordPosition="3038">ndency structure conversion done by the Stanford parser makes the semantic head of the constituent its syntactic head. For example, in the sentence He is right it is the adjective right which is the root of the tree. Unlike that, sentences from the German corpora always have a verb as the root. To unify the formats, we write a set of rules to make the verb the root of the tree in all cases. 5 Evaluation We evaluate the results automatically as well as with human subjects. To assess the performance of the method on the English data, we calculate the Fmeasure on grammatical relations. Following Riezler et al. (2003), we calculate average precision and recall as the amount of grammatical relations shared between the output of our system and the gold stan29 dard variant divided over the total number of relations in the output and in the human-generated compression respectively. According to Clarke &amp; Lapata (2006), this measure reliably correlates with human judgements. The results of our evaluation as well as the state of the art results reported by Clarke &amp; Lapata (2008) (LM+SIG+CONSTR), whose system uses language model scoring (LM), word significance score (SIG), and linguistic constraints (CONSTR), are </context>
</contexts>
<marker>Riezler, King, Crouch, Zaenen, 2003</marker>
<rawString>Riezler, Stefan, Tracy H. King, Richard Crouch &amp; Annie Zaenen (2003). Statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for Lexical-Functional Grammar. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, Edmonton, Alberta, Canada, 27 May –1 June 2003, pp. 118–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Ringger</author>
<author>Michael Gamon</author>
<author>Robert C Moore</author>
<author>David Rojas</author>
</authors>
<title>Martine Smets &amp; Simon CorstonOliver</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>673--679</pages>
<location>Geneva,</location>
<contexts>
<context position="14494" citStr="Ringger et al., 2004" startWordPosition="2477" endWordPosition="2480">plied to German because of the constraints on word order in this language. One of the rules of German grammar states that in the main clause the inflected part of the verb occupies the second position, the first position being occupied by exactly one constituent. Therefore, if the sentence initial position in a source sentence is occupied by a constituent which got pruned off as a result of compression, the verb becomes the first element of the sentence which results in an undesirable output. There are linearization methods developed for German which find an optimal word order for a sentence (Ringger et al., 2004; Filippova &amp; Strube, 2007). We use our recent method to linearize compressed trees. 4 Corpora and Annotation We apply our method to sentences from two corpora in English and German. These are presented below. English Compression Corpus: The English data we use is a document-based compression corpus from the British National Corpus and American News Text Corpus which consists of 82 news stories3. We parsed the corpus with RASP (Briscoe et al., 2006) and with the Stanford PCFG parser (Klein &amp; Manning, 2003). The output of the former is a set of dependency relations whereas the latter provides a</context>
</contexts>
<marker>Ringger, Gamon, Moore, Rojas, 2004</marker>
<rawString>Ringger, Eric, Michael Gamon, Robert C. Moore, David Rojas, Martine Smets &amp; Simon CorstonOliver (2004). Linguistically informed statistical models of constituent structure for ordering in sentence realization. In Proceedings of the 20th International Conference on Computational Linguistics, Geneva, Switzerland, 23–27 August 2004, pp. 673–679.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Telljohann</author>
<author>Erhard W Hinrichs</author>
<author>Sandra K¨ubler</author>
</authors>
<title>Stylebook for the T¨ubingen treebank of written German (T¨uBa-D/Z). Technical Report: Seminar f¨ur Sprachwissenschaft, Universit¨at T¨ubingen,</title>
<date>2003</date>
<location>T¨ubingen, Germany.</location>
<marker>Telljohann, Hinrichs, K¨ubler, 2003</marker>
<rawString>Telljohann, Heike, Erhard W. Hinrichs &amp; Sandra K¨ubler (2003). Stylebook for the T¨ubingen treebank of written German (T¨uBa-D/Z). Technical Report: Seminar f¨ur Sprachwissenschaft, Universit¨at T¨ubingen, T¨ubingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenine Turner</author>
<author>Eugene Charniak</author>
</authors>
<title>Supervised and unsupervised learning for sentence compression.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>290--297</pages>
<location>Ann Arbor, Mich.,</location>
<contexts>
<context position="1426" citStr="Turner &amp; Charniak, 2005" startWordPosition="220" endWordPosition="223"> a subset of the words of 5, such that it is grammatical and preserves essential information from 5? There are many applications which would benefit from a robust compression system, such as subtitle generation, compression for mobile devices with a limited screen size, or news digests. Given that to date most text and speech summarization systems are extractive, sentence compression techniques are a common way to deal with redundancy in their output. In recent years, a number of approaches to sentence compression have been developed (Jing, 2001; Knight &amp; Marcu, 2002; Gagnon &amp; Da Sylva, 2005; Turner &amp; Charniak, 2005; Clarke &amp; Lapata, 2008, inter alia). Many explicitly rely on a language model, usually a trigram model, to produce grammatical output (Knight &amp; Marcu, 2002; Hori &amp; Furui, 2004; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Testing the grammaticality of the output with a language model is justified when working with a language with rigid word order like English, and all but one approach mentioned have been applied to English data. However, compressing sentences in languages with less rigid word order needs a deeper analysis to test grammaticality. And even for languages with rigid word ord</context>
<context position="3525" citStr="Turner &amp; Charniak, 2005" startWordPosition="573" endWordPosition="576">ence. A tree pruning approach does not generate new dependencies and is unlikely to produce a compression with a totally different meaning. Our approach is unsupervised and adaptable to other languages, the main requirement being that there are a dependency parser and a corpus available for the languages. We test our approach on English and German data sets and obtain results comparable or superior to the state of the art. 25 2 Related Work Many existing compression systems use a noisychannel approach and rely on a language model to test the grammaticality of the output (Knight &amp; Marcu, 2002; Turner &amp; Charniak, 2005; Galley &amp; McKeown, 2007). Other ways to ensure grammaticality and to decide whether a constituent is obligatory or may be pruned are to utilize a subcategorization lexicon (Jing, 2001), or to define a set of generally prunable constituents. Gagnon &amp; Da Sylva (2005) prune dependency trees by removing prepositional complements of the verb, subordinate clauses and noun appositions. Apparently, this does not guarantee grammaticality in all cases. It may also eliminate important information from the tree. Most approaches are supervised and require training data to learn which words or constituents</context>
</contexts>
<marker>Turner, Charniak, 2005</marker>
<rawString>Turner, Jenine &amp; Eugene Charniak (2005). Supervised and unsupervised learning for sentence compression. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, Ann Arbor, Mich., 25–30 June 2005, pp. 290–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
</authors>
<title>Parser evaluation across text types.</title>
<date>2005</date>
<booktitle>In Proceedings of the 4th Workshop on Treebanks and Linguistic Theories,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="17061" citStr="Versley, 2005" startWordPosition="2896" endWordPosition="2897"> as word significance scores. The significance score is calculated from the total number of 128 million nouns and verbs. Conditional probabilities are calculated from a much smaller portion of Tipster (about 6 million tokens). The latter number is comparable to the size of the data set we use to compute the probabilities for German. There, we use a corpus of about 4,000 articles from the German Wikipedia to calculate conditional probabilities and significance scores. The corpus is parsed with the highly accurate CDG parser (Foth &amp; Menzel, 2006) and has the same dependency format as T¨uBa-D/Z (Versley, 2005). Although all corpora are annotated with dependency relations, there are considerable differences between the annotation of the English and German data sets. The phrase to dependency structure conversion done by the Stanford parser makes the semantic head of the constituent its syntactic head. For example, in the sentence He is right it is the adjective right which is the root of the tree. Unlike that, sentences from the German corpora always have a verb as the root. To unify the formats, we write a set of rules to make the verb the root of the tree in all cases. 5 Evaluation We evaluate the </context>
</contexts>
<marker>Versley, 2005</marker>
<rawString>Versley, Yannick (2005). Parser evaluation across text types. In Proceedings of the 4th Workshop on Treebanks and Linguistic Theories, Barcelona, Spain, 9-10 December 2005.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>