<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.076169">
<title confidence="0.9811475">
RelAgent: Entity Detection and Normalization for Diseases in
Clinical Records: a Linguistically Driven Approach
</title>
<author confidence="0.981643">
Sv Ramanan
</author>
<affiliation confidence="0.895907666666667">
RelAgent Tech Pvt Ltd
Adyar, Chennai
India
</affiliation>
<email confidence="0.996648">
ramanan@relagent.com
</email>
<sectionHeader confidence="0.979979" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999914193548387">
We refined the performance of Co-
coa/Peaberry, a linguistically moti-
vated system, on extracting disease en-
tities from clinical notes in the train-
ing and development sets for Task 7.
Entities were identified in noun chunks
by use of dictionaries, and events (‘The
left atrium is dilated’) through our own
parser and predicate-argument struc-
tures. We also developed a mod-
ule to map the extracted entities to
the SNOMED subset of UMLS. The
module is based on direct matching
against UMLS entries through regu-
lar expressions derived from a small
set of morphological transformations,
along with priority rules when multi-
ple UMLS entries were matched. The
performance on training and develop-
ment sets was 81.0% and 83.3% respec-
tively (Task A), and the UMLS match-
ing scores were respectively 75.3% and
78.2% (Task B). However, the perfor-
mance against the test set was low
by comparison, 72.0% for Task A and
63.9% for Task B, even while the pure
UMLS mapping score was reasonably
high (relaxed score in Task B = 91.2%).
We speculate that our moderate perfor-
mance on the test set derives primarily
from chunking/parsing errors.
</bodyText>
<sectionHeader confidence="0.997735" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999785">
The increasing use of electronic health records,
both for satisfying mandatory requirements as
</bodyText>
<footnote confidence="0.8885454">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and
proceedings footer are added by the organisers. Licence
details: http://creativecommons.org/licenses/by/
4.0/
</footnote>
<author confidence="0.410125">
Senthil Nathan
</author>
<affiliation confidence="0.432516666666667">
RelAgent Tech Pvt Ltd
Adyar, Chennai
India
</affiliation>
<email confidence="0.936988">
senthil@relagent.com
</email>
<bodyText confidence="0.999915414634146">
well as for administrative reasons, has cre-
ated a need for systems to automatically tag
and normalize disease/sign/symptom men-
tions. Statistically significant correlations
extracted from automated analysis of large
databases of clinical records are felt to be use-
ful in detecting phenotype-genotype correla-
tions (reviewed in Kohane (2011)), phenotype-
phenotype correlations (Roque et al., 2011) as
well as in continuous monitoring of events such
as adverse reactions and even early detection
of outbreaks of epidemics/infectious diseases
(Botsis et al., 2013; Collier, 2012). In this
context, Task 7 of SemEval 2014, which is
a continuation of the ShARe/CLEF eHealth
2013 task (Pradhan et al., 2013), provides a
testbed to evaluate systems that automatically
tag and normalize mentions of diseases, signs
and symptoms in clinical records, which in-
clude discharge summaries and echo, radiology
and ECG reports.
Our system consists of (i) Cocoa, a chunk-
based entity tagger and (ii) Peaberry, a parser,
followed by a module for predicate-argument
structure. We have tested the system in a va-
riety of tasks, such as detecting and normal-
izing mentions of chemicals, proteins/genes,
diseases and action terms in the BioCreative
13 Chemdner and CTD tasks (Ramanan and
Senthil Nathan, 2013a; Ramanan and Senthil
Nathan, 2013b), as well as in detecting cel-
lular and pathological events in the BioNLP
cancer genetics task (Ramanan and Senthil
Nathan, 2013c); we also participated in the
eHealth 2013 task (Ramanan et al., 2013d).
Throughout, we have retained a common core
platform for simultaneous detection of a mul-
tiplicity of entity types as well as for chunk-
ing and parsing; we restrict task-specific op-
timization primarily to post-processing mod-
ules. While this strategy may not be optimal
</bodyText>
<page confidence="0.978734">
477
</page>
<note confidence="0.7306155">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 477–481,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999982305555556">
for any individual task, we feel that it is neces-
sary for multi-document spanning tasks such
as literature-based discovery (Swanson, 1988),
where connections are established across a va-
riety of scales, e.g. from molecular events
to patho-physiological phenotypes. Moreover,
these linkages need to be made across a mul-
tiplicity of documents from various sources,
which encompass a linguistic range from com-
plex syntactical utterances in biomedical pub-
lications to free-form phrase-centered clinical
notes.
We refined performance against the pro-
vided training and development sets, with
reasonable performance in Task A (relaxed
f = 0.94, strict f = 0.81 − 0.83, strict recall
0.80 − 0.82). A module to match text from
gold-annotated exact spans to UMLS codes
also achieved reasonable performance for Task
B (relaxed accuracy = 0.94−96). However, the
results against from the test set were quite low
for Task A, (relaxed f = 0.87, strict f = 0.72,
strict recall = 0.70) as well as for Task B
(strict f = 0.64). Comparatively, the module
for UMLS normalization fared better (relaxed
f = 0.91 in Task B). We speculate that the
test set contains entities that are rare in the
training/development sets which were chun-
ked incorrectly, and also that the parse errors
in the test set arose from syntactic structures
missing in the training sets. It is possible that
a post-processing statistical module trained on
a combination of gold annotations as well as
linguistic output may be needed for improv-
ing the performance of our system on clinical
notes.
</bodyText>
<sectionHeader confidence="0.632828" genericHeader="method">
2 System description
</sectionHeader>
<bodyText confidence="0.999967453125">
The basic structure of the entity-tagging
system is unchanged from that used in
Share/CLEF eHealth 13 (Pradhan et al.,
2013) and BioNLP-ST 13. In summary, the
system comprises of a sentence splitter, fol-
lowed by a TBL-based POS tagger and chun-
ker, entity tagging at the single-token level,
a module to handle multi-word entities, a
noun phrase coordination module, a depen-
dency parser (Ramanan and Senthil Nathan,
2013c), and finally a semantic module to tag
disease-related events.
The generic system has dictionaries and
morphological rules for detecting diseases and
body parts. However, there are many exten-
sions needed for clinical notes, which (i) make
extensive use of common words and phrases
for describing symptoms, which requires word
sense disambiguation, (ii) use unusual phrases
for signs and symptoms and (iii) are full of
undefined acronyms. We isolated such special-
ization to disease-related entities within noun
phrases in clinical documents inside a subrou-
tine in the multi-word tagger module. These
were identified by a frequency-based analysis
of words and phrases in the training and de-
velopment corpora. Thus, a few ambiguous
words and phrases such as ’crackles’, ’com-
plaints’, ’mass effect’ and ’focal consolidation’
were tagged as disease markers regardless of
context. Generally, however, even common
clinical words such as ‘redness’ and ‘swelling’
were tagged only in the presence of neighbor-
ing context words. The appearance of major
body parts such as ‘Abdomen’, ‘Neck, ‘Ex-
tremities’ at the beginning of a line followed
by a colon or a hyphen was taken as a dis-
course reference marker for the rest of the line
to tag acronyms such as ‘NT/ND’ and dan-
gling adjectives such as ‘soft’ and ‘warm’. Very
common acronyms (≈ 100) both for anatomi-
cal parts (‘LUQ’) and diseases (‘DMII’) were
also tagged inside the specialized subroutine,
as were common abbreviations (‘regurg’ for re-
gurgitation) and words with common spelling
errors. Finally, some event/process words
which we found to almost always represent
clinical conditions in the training text were
tagged as disease markers. Examples are ‘as-
piration’, agitation’ and ‘confusion’.
We also extended our generic event pro-
cessing module with a task-specific routine
to take into account descriptions of (mostly)
signs/symptoms specific to clinical documents.
These fall into several categories: (i) abnor-
mal changes in body parts or organ systems,
such as ‘The left atrium was moderately en-
larged’, ‘Nose is bloody’ and ’redistribution of
pulmonary blood flow’ (ii) symptoms such as
’The patient was unable to walk’, ’His speech
was slurred’, ’He had difficulty breathing’ and
’alteration of consciousness’ (iii) changes in pa-
rameters marked by phrases/clauses such as
’elevation of troponin’, ‘QR interval was pro-
</bodyText>
<page confidence="0.995254">
478
</page>
<bodyText confidence="0.999968060975611">
longed’ and ’decreased blood sugar’. Certain
environmental conditions such as ‘exposure to
asbestos’ were also handled. Finally, events
with a default animate theme were tagged
regardless of their actual arguments to han-
dle sentences/phrases where our syntax mod-
ule failed to extract the correct theme or the
theme is to be inferred from the discourse; the
≈ 40 words in this set included verbs such
as ‘vomit’, ‘shivering’, ‘lethargic’, ‘violent’ and
‘somnolent’.
The above treatment served to demar-
cate spans for diseases that overlap with
the gold annotations. The system merges
words/phrases denoting a body part with ad-
joining words that denote diseases, and also
merges words denoting severity into the dis-
ease span, since our system design strategy
was to generate the longest contiguous span
that can refer to a disease. However, the pri-
mary score in the shared task are with re-
spect to exact matches with the gold anno-
tations. We therefore wrote a small post-
processing module to omit words in an approx-
imate match that refer to severity (‘acute’) as
well as to excise phrases dealing with intra-
organ parts or their location (such as ‘lobes’
or ‘left/right’) - such words/phrases are usu-
ally omitted from the UMLS descriptions of
diseases to which the gold annotations hew
closely. Also, we noticed that certain words
such as ‘wounds’ and ’lesions’ do not embed
an anatomical entity within their description
in the gold annotations. Yet another point is
that, while parameters are marked up as in-
dicative of a symptom only when they take on
abnormal values (‘elevated LDL’), the direc-
tion of change is almost always omitted from
the gold annotations. Descriptors of the pa-
tient (‘He’) are also excised. Altogether, we
constructed about 40 rules to trim the approx-
imate span into one more conformant to the
exact form in the gold annotations.
Task B requires mapping diseases phrases
into the SNOMED subset of UMLS as spec-
ified in the task description. We proceeded
on the assumption that the exact (gold)
entity spans were constructed by annota-
tors to closely map into the UMLS descrip-
tions. Accordingly, we used the text as
defined by the gold spans and attempted
to map them directly into the UMLS def-
initions after some preprocessing steps that
constructed a regular expression: (a) com-
mon spelling errors were corrected (b) body
part and disease acronyms were expanded
(c) common variants were added as alter-
nates i.e. ‘tumou?rs?’ were expanded into
‘(tumou?r|neoplasm|carcinoma)s?’ (d) adjec-
tival and nominal variants were added e.g.
both ‘atrium’ and ‘atrial’ were converted into
‘(atri)(al?|um)’, and more generally, adjec-
tival endings were generalized, for example,
the ending ‘ic’ was converted into ‘(i[ac]|ism)’.
(e) singular and plural forms were converted
into choices e.g. ‘artery’ was rendered as
‘arter(y|ies)’.
Altogether, we have ≈ 120 rules for vari-
ant morphological forms, covering adjectives,
nouns and number. The resulting regular ex-
pression was directly matched (using ‘grep’)
against UMLS text entries. Generally, sev-
eral matches were found. Matches against the
defining entry (the first one) were prioritized,
otherwise the entry with the largest CUID was
taken. Finally, we noted that some UMLS
CUID’s were preferred to others; for exam-
ple, ‘C0007115 - Malignant neoplasm of thy-
roid’ is preferred to ‘C0549473 - Thyroid car-
cinoma’. The preferred choices were inferred
from gold annotation frequencies, and corre-
spond to ≈ 100 remapping rules.
</bodyText>
<sectionHeader confidence="0.997493" genericHeader="evaluation">
3 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999962">
With a few minor changes to the system used
in the Share/CLEF 2013, we obtained a re-
laxed f-measure in Task A of 0.88 in the
training and development sets. Thereafter
we alternately refined performance in Task A
against the provided training set using the
development set as a testbed, or vice versa.
As described in the last section, these re-
finements took the form of adding context-
sensitive rules for disease-related words and
phrases in order of their frequencies in the
training/development sets. While we could
thereby improve performance against both
training and development sets (relaxed f =
0.94), we noticed that improvements in the
performance against the training set did not
correlate with better performance against the
development set and vice versa, probably im-
</bodyText>
<page confidence="0.998281">
479
</page>
<bodyText confidence="0.999979690476191">
plying that 6% or more of the entities are
unique to each set, or that we were unable to
catch similarities. A similar orthogonal situa-
tion resulted in our attempt to improve perfor-
mance against exact matches on the training
and development sets, strict f = 0.81 − 0.83,
strict recall 0.80 − 0.82. The observation of
orthogonal entity sets in different datasets for
about 6% of entities is seemingly validated in
the test set, where the results showed a re-
laxed f = 0.87, which is quite close to the
baseline performance (0.88 in the Share/CLEF
2013 task); the highest scoring system had re-
laxed f = 0.91 by comparison. We speculate
that our insistence on contextual clues for en-
tity tagging is another cause for low relaxed
performance on the test set.
Performance of the system for exact
matches on the test set (strict f = 0.72)
suffered greatly in comparison to the train-
ing/development sets. This could be partly
ascribed to the 7% lower performance on the
relaxed f-score (i.e. we missed many entities
altogether) from 0.94 in training/development
sets to 0.87 in the test set. Even account-
ing for this, there is an additional perfor-
mance drop of about 3−4% in exact match on
the test set compared to training/development
sets. One implication is that that our rule-
base method for pruning approximate matches
to exact spans is probably sub-optimal, and
should be supplemented or replaced by a sta-
tistical algorithm. As noted earlier, gold anno-
tations are probably made by annotators with
respect to UMLS definitions, and have some
degree of arbitrariness associated with them
depending on the granularity of the UMLS def-
inition e.g. in the choice of whether to remove
or retain a body location in the gold span.
Given the size of the UMLS definition set, a
statistical approach is probably likely to do
better than a rule-based system in the task of
reducing approximate matches to exact spans.
The poor performance in Task A (strict
recall = 0.70) directly impinges on our low
‘strict’ score in Task B (= 0.64); this score is
simply a product of the strict recall in Task A
and the accuracy of mapping to UMLS, where
the latter score is given by the Task B ‘relaxed’
score (= 0.91). An interesting feature is the
mapping accuracy for our system on the test
set suffered a relatively small drop when com-
pared to the mapping accuracies on the train-
ing and development sets, which were 0.94 and
0.96 respectively. We interpret this reasonably
high figure for the mapping score (the best
among the top 10+ teams in Task B) as vali-
dation of our hypothesis that gold annotations
are made with respect to UMLS definitions,
which also strengthens the case (made above)
for the need to incorporate a (semi-)statistical
approach for pruning overlap matches to exact
matches in our system.
Clinical documents are terse and full of
phrasal observations and incomplete sen-
tences, often with missing punctuation. We
have adapted a linguistically based system
to detect disease-related entities and events
with moderate performance; our observation
on the training/development sets is that most
errors arise from parsing/ chunking errors
on grammatically incomplete phrases. The
second task, namely mapping disease-related
entities/events to SNOMED/UMLS, requires
tagged entity spans to correspond closely to
UMLS definitions; system performance in this
regard can probably be usefully supplemented
by statistical approaches. Given proper entity
spans, a small set of morphological transfor-
mations gives high performance in mapping
to UMLS ID’s. We speculate that a chunk-
annotated corpus of clinical records may help
in improving performance for linguistically de-
rived systems.
</bodyText>
<sectionHeader confidence="0.998819" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99965875">
Isaac S. Kohane. 2011. Using electronic health
records to drive discovery in disease genomics.
Nat Rev Genet. 2011 Jun;12(6):417-28.
Francisco S. Roque, Peter B. Jensen, Henri-
ette Schmock, Marlene Dalgaard, Massimo An-
dreatta, Thomas Hansen, Karen Soeby, Soren
Bredkjor, Anders Juul, Thomas Werge, Lars J.
Jensen and Soren Brunak. 2011. Using elec-
tronic patient records to discover disease corre-
lations and stratify patient cohorts. PLoS Comp.
Bio. 7(8):e1002141.
Sv Ramanan and Senthil Nathan. 2013. Perfor-
mance of a multi-class biomedical tagger on the
BioCreative IV CTD task. Proceedings of the
Fourth BioCreative Challenge Evaluation Work-
shop vol. 1. Bethesda, MD.
</reference>
<page confidence="0.976118">
480
</page>
<reference confidence="0.999144828571429">
Sv Ramanan and Senthil Nathan. 2013. Adapt-
ing Cocoa a multi-class entity detector for the
CHEMDNER task of BioCreative IV. Proceed-
ings of the Fourth BioCreative Challenge Eval-
uation Workshop vol. 2. Bethesda, MD.
Sv Ramanan and Senthil Nathan. 2013. Perfor-
mance and limitations of the linguistically moti-
vated Cocoa/Peaberry system in a broad biomed-
ical domain. Proceedings of Workshop. BioNLP
Shared Task 2013. ACL. Sofia.
Sv Ramanan, Shereen Broido and Senthil Nathan.
2013. Performance of a multi-class biomedi-
cal tagger on clinical records. Proceedings of
ShARe/CLEF eHealth Evaluation Labs.
Don R. Swanson. 1988. Migraine and Magnesium:
Eleven Neglected Connections. Persp. Bio. Med.
31(4), 526-557.
Sameer Pradhan, Noemie Elhadad, Brett R.
South, David Martinez, Lee Christensen, Amy
Vogel, Hanna Suominen, Wendy W. Chapman
and Guergana Savova. 2013. Online Work-
ing Notes of the CLEF 2013 Evaluation Labs
and Workshop. Proceedings of ShARe/CLEF
eHealth Evaluation Labs, 23-26 September, Va-
lencia, Spain
Taxiarchis Botsis , Michael D. Nguyen , Emily
J. Woo, Marianthi Markatou and Robert Ball.
2011. Text mining for the Vaccine Adverse
Event Reporting System: medical text classifica-
tion using informative feature selection. J Am
Med Inform Assoc. 2011 Sep-Oct;18(5):631-8
Nigel Collier. 2012. Uncovering text mining: A
survey of current work on web-based epidemic
intelligence. Glob Public Health. Aug 2012;
7(7): 731-749.
</reference>
<page confidence="0.998705">
481
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.373552">
<title confidence="0.971185">RelAgent: Entity Detection and Normalization for Diseases Clinical Records: a Linguistically Driven Approach</title>
<author confidence="0.773571">Sv</author>
<affiliation confidence="0.740877">RelAgent Tech Pvt Adyar,</affiliation>
<email confidence="0.999914">ramanan@relagent.com</email>
<abstract confidence="0.9995781875">We refined the performance of Cocoa/Peaberry, a linguistically motivated system, on extracting disease entities from clinical notes in the training and development sets for Task 7. Entities were identified in noun chunks by use of dictionaries, and events (‘The left atrium is dilated’) through our own parser and predicate-argument structures. We also developed a module to map the extracted entities to the SNOMED subset of UMLS. The module is based on direct matching against UMLS entries through regular expressions derived from a small set of morphological transformations, along with priority rules when multiple UMLS entries were matched. The performance on training and development sets was 81.0% and 83.3% respectively (Task A), and the UMLS matching scores were respectively 75.3% and 78.2% (Task B). However, the performance against the test set was low by comparison, 72.0% for Task A and 63.9% for Task B, even while the pure UMLS mapping score was reasonably high (relaxed score in Task B = 91.2%). We speculate that our moderate performance on the test set derives primarily from chunking/parsing errors.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Isaac S Kohane</author>
</authors>
<title>Using electronic health records to drive discovery in disease genomics. Nat Rev Genet.</title>
<date>2011</date>
<pages>12--6</pages>
<contexts>
<context position="2056" citStr="Kohane (2011)" startWordPosition="311" endWordPosition="312">nsed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/ 4.0/ Senthil Nathan RelAgent Tech Pvt Ltd Adyar, Chennai India senthil@relagent.com well as for administrative reasons, has created a need for systems to automatically tag and normalize disease/sign/symptom mentions. Statistically significant correlations extracted from automated analysis of large databases of clinical records are felt to be useful in detecting phenotype-genotype correlations (reviewed in Kohane (2011)), phenotypephenotype correlations (Roque et al., 2011) as well as in continuous monitoring of events such as adverse reactions and even early detection of outbreaks of epidemics/infectious diseases (Botsis et al., 2013; Collier, 2012). In this context, Task 7 of SemEval 2014, which is a continuation of the ShARe/CLEF eHealth 2013 task (Pradhan et al., 2013), provides a testbed to evaluate systems that automatically tag and normalize mentions of diseases, signs and symptoms in clinical records, which include discharge summaries and echo, radiology and ECG reports. Our system consists of (i) Co</context>
</contexts>
<marker>Kohane, 2011</marker>
<rawString>Isaac S. Kohane. 2011. Using electronic health records to drive discovery in disease genomics. Nat Rev Genet. 2011 Jun;12(6):417-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco S Roque</author>
<author>Peter B Jensen</author>
<author>Henriette Schmock</author>
<author>Marlene Dalgaard</author>
<author>Massimo Andreatta</author>
<author>Thomas Hansen</author>
<author>Karen Soeby</author>
<author>Soren Bredkjor</author>
<author>Anders Juul</author>
<author>Thomas Werge</author>
<author>Lars J Jensen</author>
<author>Soren Brunak</author>
</authors>
<title>Using electronic patient records to discover disease correlations and stratify patient cohorts.</title>
<date>2011</date>
<journal>PLoS Comp. Bio.</journal>
<volume>7</volume>
<issue>8</issue>
<contexts>
<context position="2111" citStr="Roque et al., 2011" startWordPosition="316" endWordPosition="319">ernational Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/ 4.0/ Senthil Nathan RelAgent Tech Pvt Ltd Adyar, Chennai India senthil@relagent.com well as for administrative reasons, has created a need for systems to automatically tag and normalize disease/sign/symptom mentions. Statistically significant correlations extracted from automated analysis of large databases of clinical records are felt to be useful in detecting phenotype-genotype correlations (reviewed in Kohane (2011)), phenotypephenotype correlations (Roque et al., 2011) as well as in continuous monitoring of events such as adverse reactions and even early detection of outbreaks of epidemics/infectious diseases (Botsis et al., 2013; Collier, 2012). In this context, Task 7 of SemEval 2014, which is a continuation of the ShARe/CLEF eHealth 2013 task (Pradhan et al., 2013), provides a testbed to evaluate systems that automatically tag and normalize mentions of diseases, signs and symptoms in clinical records, which include discharge summaries and echo, radiology and ECG reports. Our system consists of (i) Cocoa, a chunkbased entity tagger and (ii) Peaberry, a pa</context>
</contexts>
<marker>Roque, Jensen, Schmock, Dalgaard, Andreatta, Hansen, Soeby, Bredkjor, Juul, Werge, Jensen, Brunak, 2011</marker>
<rawString>Francisco S. Roque, Peter B. Jensen, Henriette Schmock, Marlene Dalgaard, Massimo Andreatta, Thomas Hansen, Karen Soeby, Soren Bredkjor, Anders Juul, Thomas Werge, Lars J. Jensen and Soren Brunak. 2011. Using electronic patient records to discover disease correlations and stratify patient cohorts. PLoS Comp. Bio. 7(8):e1002141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sv Ramanan</author>
<author>Senthil Nathan</author>
</authors>
<title>Performance of a multi-class biomedical tagger on the BioCreative IV CTD task.</title>
<date>2013</date>
<booktitle>Proceedings of the Fourth BioCreative Challenge Evaluation Workshop</booktitle>
<volume>1</volume>
<location>Bethesda, MD.</location>
<marker>Ramanan, Nathan, 2013</marker>
<rawString>Sv Ramanan and Senthil Nathan. 2013. Performance of a multi-class biomedical tagger on the BioCreative IV CTD task. Proceedings of the Fourth BioCreative Challenge Evaluation Workshop vol. 1. Bethesda, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sv Ramanan</author>
<author>Senthil Nathan</author>
</authors>
<title>Adapting Cocoa a multi-class entity detector for the CHEMDNER task of BioCreative IV.</title>
<date>2013</date>
<booktitle>Proceedings of the Fourth BioCreative Challenge Evaluation Workshop</booktitle>
<volume>2</volume>
<location>Bethesda, MD.</location>
<marker>Ramanan, Nathan, 2013</marker>
<rawString>Sv Ramanan and Senthil Nathan. 2013. Adapting Cocoa a multi-class entity detector for the CHEMDNER task of BioCreative IV. Proceedings of the Fourth BioCreative Challenge Evaluation Workshop vol. 2. Bethesda, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sv Ramanan</author>
<author>Senthil Nathan</author>
</authors>
<title>Performance and limitations of the linguistically motivated Cocoa/Peaberry system in a broad biomedical domain.</title>
<date>2013</date>
<booktitle>Proceedings of Workshop. BioNLP Shared Task</booktitle>
<publisher>ACL. Sofia.</publisher>
<marker>Ramanan, Nathan, 2013</marker>
<rawString>Sv Ramanan and Senthil Nathan. 2013. Performance and limitations of the linguistically motivated Cocoa/Peaberry system in a broad biomedical domain. Proceedings of Workshop. BioNLP Shared Task 2013. ACL. Sofia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sv Ramanan</author>
<author>Shereen Broido</author>
<author>Senthil Nathan</author>
</authors>
<title>Performance of a multi-class biomedical tagger on clinical records.</title>
<date>2013</date>
<booktitle>Proceedings of ShARe/CLEF eHealth Evaluation Labs.</booktitle>
<contexts>
<context position="3233" citStr="Ramanan et al., 2013" startWordPosition="495" endWordPosition="498"> ECG reports. Our system consists of (i) Cocoa, a chunkbased entity tagger and (ii) Peaberry, a parser, followed by a module for predicate-argument structure. We have tested the system in a variety of tasks, such as detecting and normalizing mentions of chemicals, proteins/genes, diseases and action terms in the BioCreative 13 Chemdner and CTD tasks (Ramanan and Senthil Nathan, 2013a; Ramanan and Senthil Nathan, 2013b), as well as in detecting cellular and pathological events in the BioNLP cancer genetics task (Ramanan and Senthil Nathan, 2013c); we also participated in the eHealth 2013 task (Ramanan et al., 2013d). Throughout, we have retained a common core platform for simultaneous detection of a multiplicity of entity types as well as for chunking and parsing; we restrict task-specific optimization primarily to post-processing modules. While this strategy may not be optimal 477 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 477–481, Dublin, Ireland, August 23-24, 2014. for any individual task, we feel that it is necessary for multi-document spanning tasks such as literature-based discovery (Swanson, 1988), where connections are established across a variet</context>
</contexts>
<marker>Ramanan, Broido, Nathan, 2013</marker>
<rawString>Sv Ramanan, Shereen Broido and Senthil Nathan. 2013. Performance of a multi-class biomedical tagger on clinical records. Proceedings of ShARe/CLEF eHealth Evaluation Labs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don R Swanson</author>
</authors>
<title>Migraine and Magnesium: Eleven Neglected Connections.</title>
<date>1988</date>
<journal>Persp. Bio. Med.</journal>
<volume>31</volume>
<issue>4</issue>
<pages>526--557</pages>
<contexts>
<context position="3782" citStr="Swanson, 1988" startWordPosition="580" endWordPosition="581"> also participated in the eHealth 2013 task (Ramanan et al., 2013d). Throughout, we have retained a common core platform for simultaneous detection of a multiplicity of entity types as well as for chunking and parsing; we restrict task-specific optimization primarily to post-processing modules. While this strategy may not be optimal 477 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 477–481, Dublin, Ireland, August 23-24, 2014. for any individual task, we feel that it is necessary for multi-document spanning tasks such as literature-based discovery (Swanson, 1988), where connections are established across a variety of scales, e.g. from molecular events to patho-physiological phenotypes. Moreover, these linkages need to be made across a multiplicity of documents from various sources, which encompass a linguistic range from complex syntactical utterances in biomedical publications to free-form phrase-centered clinical notes. We refined performance against the provided training and development sets, with reasonable performance in Task A (relaxed f = 0.94, strict f = 0.81 − 0.83, strict recall 0.80 − 0.82). A module to match text from gold-annotated exact </context>
</contexts>
<marker>Swanson, 1988</marker>
<rawString>Don R. Swanson. 1988. Migraine and Magnesium: Eleven Neglected Connections. Persp. Bio. Med. 31(4), 526-557.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Noemie Elhadad</author>
<author>Brett R South</author>
<author>David Martinez</author>
<author>Lee Christensen</author>
<author>Amy Vogel</author>
<author>Hanna Suominen</author>
<author>Wendy W Chapman</author>
<author>Guergana Savova</author>
</authors>
<date>2013</date>
<booktitle>Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop. Proceedings of ShARe/CLEF eHealth Evaluation Labs,</booktitle>
<pages>23--26</pages>
<location>Valencia, Spain</location>
<contexts>
<context position="2416" citStr="Pradhan et al., 2013" startWordPosition="365" endWordPosition="368">ically tag and normalize disease/sign/symptom mentions. Statistically significant correlations extracted from automated analysis of large databases of clinical records are felt to be useful in detecting phenotype-genotype correlations (reviewed in Kohane (2011)), phenotypephenotype correlations (Roque et al., 2011) as well as in continuous monitoring of events such as adverse reactions and even early detection of outbreaks of epidemics/infectious diseases (Botsis et al., 2013; Collier, 2012). In this context, Task 7 of SemEval 2014, which is a continuation of the ShARe/CLEF eHealth 2013 task (Pradhan et al., 2013), provides a testbed to evaluate systems that automatically tag and normalize mentions of diseases, signs and symptoms in clinical records, which include discharge summaries and echo, radiology and ECG reports. Our system consists of (i) Cocoa, a chunkbased entity tagger and (ii) Peaberry, a parser, followed by a module for predicate-argument structure. We have tested the system in a variety of tasks, such as detecting and normalizing mentions of chemicals, proteins/genes, diseases and action terms in the BioCreative 13 Chemdner and CTD tasks (Ramanan and Senthil Nathan, 2013a; Ramanan and Sen</context>
<context position="5335" citStr="Pradhan et al., 2013" startWordPosition="832" endWordPosition="835"> (relaxed f = 0.91 in Task B). We speculate that the test set contains entities that are rare in the training/development sets which were chunked incorrectly, and also that the parse errors in the test set arose from syntactic structures missing in the training sets. It is possible that a post-processing statistical module trained on a combination of gold annotations as well as linguistic output may be needed for improving the performance of our system on clinical notes. 2 System description The basic structure of the entity-tagging system is unchanged from that used in Share/CLEF eHealth 13 (Pradhan et al., 2013) and BioNLP-ST 13. In summary, the system comprises of a sentence splitter, followed by a TBL-based POS tagger and chunker, entity tagging at the single-token level, a module to handle multi-word entities, a noun phrase coordination module, a dependency parser (Ramanan and Senthil Nathan, 2013c), and finally a semantic module to tag disease-related events. The generic system has dictionaries and morphological rules for detecting diseases and body parts. However, there are many extensions needed for clinical notes, which (i) make extensive use of common words and phrases for describing symptoms</context>
</contexts>
<marker>Pradhan, Elhadad, South, Martinez, Christensen, Vogel, Suominen, Chapman, Savova, 2013</marker>
<rawString>Sameer Pradhan, Noemie Elhadad, Brett R. South, David Martinez, Lee Christensen, Amy Vogel, Hanna Suominen, Wendy W. Chapman and Guergana Savova. 2013. Online Working Notes of the CLEF 2013 Evaluation Labs and Workshop. Proceedings of ShARe/CLEF eHealth Evaluation Labs, 23-26 September, Valencia, Spain</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily J Woo</author>
<author>Marianthi Markatou</author>
<author>Robert Ball</author>
</authors>
<title>Text mining for the Vaccine Adverse Event Reporting System: medical text classification using informative feature selection. J Am Med Inform Assoc.</title>
<date>2011</date>
<pages>18--5</pages>
<marker>Woo, Markatou, Ball, 2011</marker>
<rawString>Taxiarchis Botsis , Michael D. Nguyen , Emily J. Woo, Marianthi Markatou and Robert Ball. 2011. Text mining for the Vaccine Adverse Event Reporting System: medical text classification using informative feature selection. J Am Med Inform Assoc. 2011 Sep-Oct;18(5):631-8</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nigel Collier</author>
</authors>
<title>Uncovering text mining: A survey of current work on web-based epidemic intelligence. Glob Public Health.</title>
<date>2012</date>
<volume>7</volume>
<issue>7</issue>
<pages>731--749</pages>
<contexts>
<context position="2291" citStr="Collier, 2012" startWordPosition="345" endWordPosition="346">dyar, Chennai India senthil@relagent.com well as for administrative reasons, has created a need for systems to automatically tag and normalize disease/sign/symptom mentions. Statistically significant correlations extracted from automated analysis of large databases of clinical records are felt to be useful in detecting phenotype-genotype correlations (reviewed in Kohane (2011)), phenotypephenotype correlations (Roque et al., 2011) as well as in continuous monitoring of events such as adverse reactions and even early detection of outbreaks of epidemics/infectious diseases (Botsis et al., 2013; Collier, 2012). In this context, Task 7 of SemEval 2014, which is a continuation of the ShARe/CLEF eHealth 2013 task (Pradhan et al., 2013), provides a testbed to evaluate systems that automatically tag and normalize mentions of diseases, signs and symptoms in clinical records, which include discharge summaries and echo, radiology and ECG reports. Our system consists of (i) Cocoa, a chunkbased entity tagger and (ii) Peaberry, a parser, followed by a module for predicate-argument structure. We have tested the system in a variety of tasks, such as detecting and normalizing mentions of chemicals, proteins/gene</context>
</contexts>
<marker>Collier, 2012</marker>
<rawString>Nigel Collier. 2012. Uncovering text mining: A survey of current work on web-based epidemic intelligence. Glob Public Health. Aug 2012; 7(7): 731-749.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>