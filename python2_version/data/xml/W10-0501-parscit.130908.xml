<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007068">
<title confidence="0.9921405">
The “Nays” Have It: Exploring Effects of Sentiment in Collaborative
Knowledge Sharing
</title>
<author confidence="0.989027">
Ablimit Aji , Eugene Agichtein
</author>
<affiliation confidence="0.987331">
Mathematics &amp; Computer Science Department
Emory University
</affiliation>
<email confidence="0.999364">
{aaji,eugene}@mathcs.emory.edu
</email>
<sectionHeader confidence="0.997691" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.98902">
In this paper we study what effects sentiment
have on the temporal dynamics of user inter-
action and content generation in a knowledge
sharing setting. We try to identify how senti-
ment influences interaction dynamics in terms
of answer arrival, user ratings arrival, commu-
nity agreement and content popularity. Our
study suggests that “Negativity Bias” triggers
more community attention and consequently
more content contribution. Our findings pro-
vide insight into how users interact in online
knowledge sharing communities, and helpful
for improving existing systems.
</bodyText>
<sectionHeader confidence="0.999373" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997485818181818">
Recently, Collaborative Knowledge Sharing sites( or
CQA sites), such as Naver and Yahoo! Answers
have exploded in popularity. Already, for many in-
formation needs, these sites are becoming valuable
alternatives to search engines. Previous studies iden-
tified visibility as an important factor for content
popularity and developed models in static settings.
However, when users post social media content, they
might either explicitly or implicitly express their
personal attitudes or sentiment. The following ex-
ample illustrates a question with negative sentiment.
</bodyText>
<listItem confidence="0.895499">
Q :Obama keeps saying we need to sacrifice.
What sacrifices has he and the gov made collec-
tively and individually?
A1: Our hard earned tax dollars. 17 T, 2 1
A2: None and they never will. 18 T, 2 1
</listItem>
<bodyText confidence="0.9998294">
Psychological studies (Smith et al., 2008) suggest
that our brain has “Negativity Bias” - that is, people
automatically devote more attention to negative in-
formation than to positive information. Thus, our
attitudes may be more heavily influenced by nega-
tive opinions. Our hypothesis is that this kind of hu-
man cognitive bias would have measurable effects
on how users respond to information need in CQA
communities. Our goal in this paper is to under-
stand how question sentiment influence the dynam-
ics of the user interactions in CQA - that is, to un-
derstand how users respond to questions of different
sentiment, how question sentiment affects commu-
nity agreement on best answer and question popu-
larity.
</bodyText>
<sectionHeader confidence="0.970197" genericHeader="method">
2 Sentiment Influence
</sectionHeader>
<bodyText confidence="0.998937428571429">
While (Aji et al., 2010) suggests that question cat-
egory has a patent influence on interaction dynam-
ics, we mainly focus on sentiment in this exploratory
study, for the reason that sentiment is a high level
but prominent facet in every piece of content. We
focused on how may sentiment effect the following
dimensions:
</bodyText>
<listItem confidence="0.9998568">
• Answer Arrival: Measured as number of an-
swers arrived every minute.
• Vote Arrival: Measured as number of votes ar-
rived per answer.
• Community Agreement: Mean Reciprocal Rank
</listItem>
<bodyText confidence="0.89397675">
(MRR), computed by ranking the answers in or-
der of decreasing “Thumbs up” ratings, and iden-
tifying the rank of the actual “best” answer, as se-
lected by the asker.
</bodyText>
<equation confidence="0.987611666666667">
1
(1)
rank�
</equation>
<bodyText confidence="0.999917">
where rank, is the rank of the best answer among
the answers submitted for question i.
</bodyText>
<listItem confidence="0.9946916">
• Answer Length, Question Length: We examine
whether questions with different sentiment exhibit
variations in question and answer length.
• Interest “Stars”: How many users marked ques-
tion as interesting.
</listItem>
<sectionHeader confidence="0.986963" genericHeader="method">
3 Dataset Description
</sectionHeader>
<bodyText confidence="0.9986748">
For our study we tracked a total of approximately
10,000 questions, sampled from 20 categories from
Yahoo! Answers. Specifically, each new question in
our tracking list crawled every five minutes until it’s
closed. As a result, we obtained approximately 22
</bodyText>
<equation confidence="0.927919166666667">
1
MRR =
�Q1
∑N
Z=1
1
</equation>
<note confidence="0.807815">
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 1–2,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9997761">
million question-answer-feedback snapshots in to-
tal. Since labeling all the questions would be ex-
pensive, we randomly selected 2000 questions from
this dataset for human labeling. We then utilized the
Amazon Mechanical Turk Service1. Five workers
labeled each question as either positive, negative or
neutral; the ratings were filtered by using majority
opinion (at least 3 out of 5 labels). Overall statistics
of this dataset are reported in Table 1. The overall
inter-rater agreement was 65%.
</bodyText>
<tableCaption confidence="0.998694">
Table 1: Statistics of the Temporal dataset
</tableCaption>
<bodyText confidence="0.372556">
.
</bodyText>
<sectionHeader confidence="0.99827" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.992751428571429">
Figure 1 reports answer arrival dynamics for ques-
tion with varying sentiment. Answers to negative
questions arrive substantially faster than answers to
positive or neutral questions, whereas the difference
between positive and neutral questions are minor.
This strongly confirms the “Negative Bias” effect.
Given the fact that questions stay in the category
front page relatively same amount of time where
their visibility contributes potential answers, on av-
erage, negative sentiment questions managed to get
more answers than two other types of questions (4.3
vs. 3.3 and 3.5). It seems, sentiment expressed in a
question contributes to the answer arrival more than
visibility.
</bodyText>
<figureCaption confidence="0.999391">
Figure 1: Cumulative answer arrival
</figureCaption>
<bodyText confidence="0.821523692307692">
Figure 2 reports rating arrival dynamics. Interest-
ingly, positive ratings arrive much faster to negative
questions, whereas positive and negative ratings ar-
rive roughly at the same rate for positive and neutral
questions. While this might be partially due to the
fact that negative sentiment questions are more “at-
tention grabbing” than other types of questions, we
conjecture that this effect is caused by the selection
bias of the raters participating in negative question
threads, who tend to support answers that strongly
thttp://www.mturk.com
agree (or strongly disagree) with the question asker.
Surprisingly, community agreement(MRR) on the
</bodyText>
<table confidence="0.99876175">
Type MRR QLength ALength Stars
Negative 0.47 78 49 0.25
Positive 0.56 58 52 0.16
Neutral 0.57 52 47 0.15
</table>
<tableCaption confidence="0.983625">
Table 2: Agreement, Question length, Answer Length
and Star count averaged over question type
</tableCaption>
<bodyText confidence="0.999555">
best answer is lower for negative sentiment ques-
tions. On average, negative sentiment questions
were marked as interesting more than positive or
neutral questions were marked as interesting. Al-
though this may sound counterintuitive, it is not sur-
prising if we recall how the “Negative Bias” influ-
ences user behavior and may increase implicit “visi-
bility”. All the above mentioned differences are sta-
tistically significant(t-test p = 0.05).
In summary, our preliminary exploration indi-
cates that sentiment may have a powerful effect on
the content contribution dynamics in collaborative
question answering, and is a promising direction for
further study of knowledge sharing communities.
</bodyText>
<sectionHeader confidence="0.99209" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.840521">
We thank HP Social Computing Labs for support.
</bodyText>
<sectionHeader confidence="0.993838" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995195071428571">
Ablimit Aji. Eugene Agichtein. 2010. Deconstructing
Interaction Dynamics in Knowledge Sharing Commu-
nities. International Conference on Social Computing,
Behavioral Modeling, &amp; Prediction.
Gabor Szabo. Bernardo Huberman. 2008. Predicting the
popularity of online content. HP Labs Technical Re-
port.
Kristina Lerman. 2007. Social Information Processing
in Social News Aggregation. IEEE Internet Comput-
ing: Special Issue on Social Search.
N. Kyle Smith Jeff T. Larsen Tanya L. Chartrand John
T. Cacioppo 2006. Affective Context Moderates the
Attention Bias Toward Negative Information. Journal
of Personality and Social Psychology.
</reference>
<figure confidence="0.999141375">
Positive
Negative
Neutral
Total
379
173
548
1,100
1 10 100 1000
time (in minutes)
Answers
4.5
2.5
3.5
0.5
1.5
4
2
3
0
1
negative sentiment
neutral sentiment
positive sentiment
</figure>
<figureCaption confidence="0.811104">
Figure 2: Cumulative user ratings arrival
</figureCaption>
<figure confidence="0.999008266666667">
Ratings
0.5
0.4
0.3
0.2
0.1
0
1 10 100 1000
time (in minutes)
negative +
neutral +
positive +
negative -
neutral -
positive -
</figure>
<page confidence="0.988718">
2
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.429020">
<title confidence="0.966224">The “Nays” Have It: Exploring Effects of Sentiment in Knowledge Sharing</title>
<author confidence="0.915814">Ablimit Aji</author>
<affiliation confidence="0.917547">Mathematics &amp; Computer Science</affiliation>
<author confidence="0.550924">Emory</author>
<abstract confidence="0.999706285714286">In this paper we study what effects sentiment have on the temporal dynamics of user interaction and content generation in a knowledge sharing setting. We try to identify how sentiment influences interaction dynamics in terms of answer arrival, user ratings arrival, community agreement and content popularity. Our study suggests that “Negativity Bias” triggers more community attention and consequently more content contribution. Our findings provide insight into how users interact in online knowledge sharing communities, and helpful for improving existing systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
</authors>
<title>Deconstructing Interaction Dynamics in Knowledge Sharing</title>
<date>2010</date>
<booktitle>Communities. International Conference on Social Computing, Behavioral Modeling, &amp; Prediction.</booktitle>
<marker>Agichtein, 2010</marker>
<rawString>Ablimit Aji. Eugene Agichtein. 2010. Deconstructing Interaction Dynamics in Knowledge Sharing Communities. International Conference on Social Computing, Behavioral Modeling, &amp; Prediction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Huberman</author>
</authors>
<title>Predicting the popularity of online content.</title>
<date>2008</date>
<tech>HP Labs Technical Report.</tech>
<marker>Huberman, 2008</marker>
<rawString>Gabor Szabo. Bernardo Huberman. 2008. Predicting the popularity of online content. HP Labs Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Lerman</author>
</authors>
<title>Social Information Processing in Social News Aggregation.</title>
<date>2007</date>
<journal>IEEE Internet Computing: Special Issue on Social Search.</journal>
<marker>Lerman, 2007</marker>
<rawString>Kristina Lerman. 2007. Social Information Processing in Social News Aggregation. IEEE Internet Computing: Special Issue on Social Search.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kyle Smith Jeff T Larsen Tanya L Chartrand John T Cacioppo</author>
</authors>
<title>Affective Context Moderates the Attention Bias Toward Negative Information.</title>
<date>2006</date>
<journal>Journal of Personality and Social Psychology.</journal>
<marker>Cacioppo, 2006</marker>
<rawString>N. Kyle Smith Jeff T. Larsen Tanya L. Chartrand John T. Cacioppo 2006. Affective Context Moderates the Attention Bias Toward Negative Information. Journal of Personality and Social Psychology.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>