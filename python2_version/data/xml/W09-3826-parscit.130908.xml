<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000278">
<title confidence="0.97836">
Grammar Error Detection with Best Approximated Parse
</title>
<author confidence="0.865613">
Jean-Philippe Prost
</author>
<affiliation confidence="0.6170735">
LIFO, Universit´e d’Orl´eans
INRIA Lille - Nord Europe
</affiliation>
<email confidence="0.231553">
Jean-Philippe.Prost@univ-orleans.fr
</email>
<sectionHeader confidence="0.976841" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999792928571429">
In this paper, we propose that grammar er-
ror detection be disambiguated in generat-
ing the connected parse(s) of optimal merit
for the full input utterance, in overcom-
ing the cheapest error. The detected er-
ror(s) are described as violated grammat-
ical constraints in a framework for Model-
Theoretic Syntax (MTS). We present a
parsing algorithm for MTS, which only re-
lies on a grammar of well-formedness, in
that the process does not require any extra-
grammatical resources, additional rules
for constraint relaxation or error handling,
or any recovery process.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999678541666667">
Grammar error detection is a crucial part of
NLP applications such as Grammar Checking or
Computer-Assisted Language Learning (CALL).
The problem is made highly ambiguous depending
on which context is used for interpreting, and thus
pinpointing, the error. For example, a phrase may
look perfectly fine when isolated (e.g. brief inter-
view), but is erroneous in a specific context (e.g.
in *The judge grants brief interview to this plain-
tiff, or in *The judges brief interview this plain-
tiff). Robust partial parsing is often not enough to
precisely desambiguate those cases. The solution
we prescribe is to point out the error(s) as a set
of violated (atomic) constraints of minimal cost,
along with the structural context used for measur-
ing that cost. Given an ungrammatical input string,
the aim is then to provide an approximated rooted
parse tree for it, along with a description of all the
grammatical constraints it violates. For example,
Figure 1 illustrates an approximated parse for an
ill-formed sentence in French, and the error be-
ing detected in that context. Property Grammar
(Blache, 2001) provides an elegant framework for
that purpose.
</bodyText>
<figureCaption confidence="0.991918">
Figure 1: Approximated parse for an erroneous French sen-
tence (the Noun ’entretien’ requires a Determiner).
</figureCaption>
<bodyText confidence="0.999938444444444">
Most of the relevant approaches to robust
knowledge-based parsing addresses the problem
as a recovery process. More specifically, we
observe three families of approaches in that re-
spect: those relying on grammar mal-rules in or-
der to specify how to correctly parse what ought
to be ungrammatical (Bender et al., 2004; Foster,
2007); those relying on constraint relaxation ac-
cording to specified relaxation rules (Douglas and
Dale, 1992); and those relying on constraint re-
laxation with no relaxation rules, along with a re-
covery process based on weighted parsing (Fou-
vry, 2003; Foth et al., 2005). The first two are
actually quite similar, in that, through their use
of extra-grammatical rules, they both extend the
grammar’s coverage with a set of ought-to-be-
ungrammatical utterances. The main drawback
of those approaches is that when faced with un-
expected input at best their outcome remains un-
known, at worst the parsing process fails. With
robust weighted parsing, on the other hand, that
problem does not occur. The recovery process
consists of filtering out structures with respect to
their weights or the weights of the constraints be-
ing relaxed. However, these strategies usually
can not discriminate between grammatical and un-
grammatical sentences. The reason for that comes
</bodyText>
<figure confidence="0.994326870967742">
S15
D1
Le
The
NP3
N2
juge
judge
V8
octroie
grants
*NP7
APs
A4
bref
brief
VP9
N5
entretien
interview
P11
a`
to
PP10
D13
ce
this
NP12
N14
plaignant
plaintiff
</figure>
<page confidence="0.97035">
172
</page>
<bodyText confidence="0.982316037037037">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 172–175,
Paris, October 2009. c�2009 Association for Computational Linguistics
from the fact that grammaticality is disconnected
from grammar consistency: since the grammar
contains contradicting (universal) constraints, no
conclusion can be drawn with regard to the gram-
maticality of a syntactic structure, which violates
part of the constraint system. The same problem
occurs with Optimality Theory. In a different fash-
ion, Fouvry weighs unification constraints accord-
ing to “how much information it contains”. How-
ever, relaxation only seems possible for those uni-
fication constraints: error patterns such as word
order, co-occurrence, uniqueness, mutual exclu-
sion, ... can not be tackled. The same restriction is
observed in VanRullen (2005), though to a much
smaller extent in terms of unrelaxable constraints.
What we would like is (i) to detect any type
of errors, and present them as conditions of well-
formedness being violated in solely relying on the
knowledge of a grammar of well-formedness—as
opposed to an error grammar or mal-rules, and
(ii) to present, along-side the violated constraints,
an approximated parse for the full sentence, which
may explain which errors have been found and
overcome. We propose here a parsing algorithm
which meets these requirements.
</bodyText>
<sectionHeader confidence="0.842219" genericHeader="method">
2 Property Grammar
</sectionHeader>
<bodyText confidence="0.985307461538462">
The framework we are using for knowledge rep-
resentation is Property Grammar (Blache, 2001)
(PG), whose model-theoretical semantics was for-
malised by Duchier et al. (2009). Intuitively, a
PG grammar decomposes what would be rewriting
rules of a generative grammar into atomic syntac-
tic properties — a property being represented as a
boolean constraint. Take, for instance, the rewrit-
ing rule NP —* D N. That rule implicitely informs
on different properties (for French): (1) NP has a
D child; (2) the D child is unique; (3) NP has an
N child; (4) the N child is unique; (5) the D child
precedes the N child; (6) the N child requires the
</bodyText>
<listItem confidence="0.645306571428571">
D child. PG defines a set of axioms, each axiom
corresponding to a constraint type. The proper-
ties above are then specified in the grammar as the
following constraints: (1) NP : A D; (2) NP : D!;
(3) NP : A N; (4) NP : N!; (5) NP : D --&lt; N; (6)
NP: N ==&gt;- D. These constraints can be indepen-
dently violated. A PG grammar is traditionally
</listItem>
<bodyText confidence="0.915879">
presented as a collection of Categories (or Con-
structions), each of them being specified by a set
of constraints. Table 1 shows an example of a
category. The class of models we are working
</bodyText>
<table confidence="0.994706941176471">
NP (Noun Phrase)
Features Property Type: Properties
[AVM] obligation: NP� 4(N V PRO) GEND 1 –
uniqueness: NP� D! D 2
: NP� N! NUM
: NP� PP!
: NP� PRO!
linearity: NP� D N
: NP� D PRO
: NP� D AP
: NP� N PP
requirement: NP� N =&gt; D
: NP� AP =&gt; N
exclusion: NP� N is PRO
GEND 1 –
dependency : NP� N
NUM 2
</table>
<tableCaption confidence="0.999852">
Table 1: NP specification in Property Grammar
</tableCaption>
<bodyText confidence="0.999849230769231">
with is made up of trees labelled with categories,
whose surface realisations are the sentences Q of
language. A syntax tree of the realisation of the
well-formed sentence Q is a strong model of the
PG grammar !g iff it satisfies every constraint in !g.
The loose semantics also allows for constraints to
be relaxed. Informally, a syntax tree of the realisa-
tion of the ill-formed sentence Q is a loose model
of !g iff it maximises the proportion of satisfied
constraints in !g with respect to the total number
of evaluated ones for a given category. The set of
violated constraints provides a description of the
detected error(s).
</bodyText>
<sectionHeader confidence="0.987529" genericHeader="method">
3 Parsing Algorithm
</sectionHeader>
<bodyText confidence="0.999894458333333">
The class of models is further restricted to con-
stituent tree structures with no pairwise intersect-
ing constituents, satisfying at least one constraint.
Since the solution parse must have a single root,
should a category not be found for a node a wild-
card (called Star) is used instead. The Star cate-
gory is not specified by any constraint in the gram-
mar.
We introduce an algorithm for Loose Satisfac-
tion Chart Parsing (LSCP), presented as Algo-
rithm 1. We have named our implementation of it
Numbat. LSCP is based on the probabilistic CKY,
augmented with a process of loose constraint sat-
isfaction. However, LSCP differs from CKY in
various respects. While CKY requires a grammar
in Chomsky Normal Form (CNF), LSCP takes an
ordinary PG grammar, since no equivalent of the
CNF exists for PG. Consequently, LSCP gener-
ates n-ary structures. LSCP also uses scores of
merit instead of probabilities for the constituents.
That score can be optimised, since it only factors
through the influence of the constituent’s immedi-
ate descendants.
Steps 1 and 2 enumerate all the possible and
</bodyText>
<page confidence="0.993724">
173
</page>
<table confidence="0.592624384615385">
Algorithm 1 Loose Satisfaction Chart Parsing
/* Initialisation */
Create and clear the chart 7r: every score in 7r is set to 0
/* Base case: populate 7r with POS-tags for each word */
for i — 1 to num words
for (each POS-category T of w;)
if merit(T) &gt; 7r[i, 1, T] then
Create constituent wT , whose category is T
7r[i, 1, T] — {wT , merit(w&apos; )l
/* Recursive case */
/* Step 1: SELECTION of the current reference span */
for span — 1 to num words
for offset — 1 to num words — span + 1
</table>
<equation confidence="0.910135842105263">
end — offset + span — 1
K — 0
/* Step 2: ENUMERATION of all the configurations */
for (every set partition P in [offset, ... , end])
KP — buildConfigurations(P)
K — K U KP
/* Step 3: CHARACTERISATION of the constraint system from the grammar */
for (every configuration A E KP)
XA — characterisation(A)
/* Step 4: PROJECTION into categories */
/* CA is a set of candidate constituents */
CA — projection(XA)
checkpoint(CA)
/* Step 5: MEMOISATION of the optimal candidate constituent */
for (every candidate constituent x E CA, of construction C)
if merit(x) &gt; 7r[offset, span, C] then
7r[offset, span, C] — {x, merit(x)l
if 7r[offset, span] = 0 then
7r[offset, span] —preferred forest in K
</equation>
<bodyText confidence="0.9997078">
legal configurations of optimal sub-structures al-
ready stored in the chart for a given span and off-
set. At this stage, a configuration is a tree with
an unlabelled root. Note that Step 2 actually does
not calculate all the set partitions, but only the le-
gal ones, i.e. those which are made up of sub-
sets of contiguous elements. Step 3 evaluates the
constraint system, using a configuration as an as-
signment. The characterisation process is imple-
mented with Algorithm 2. Step 4 consists of mak-
</bodyText>
<equation confidence="0.590724333333333">
Algorithm 2 Characterisation Function
function characterisation(A = (cr, . . . , cn) : assignment,
9: grammar)
</equation>
<bodyText confidence="0.882976666666667">
returns the set of evaluated properties relevant to A,
and the set of projected categories for A.
/* For storing the result characterisation: */
create and clear XA [property]: table of boolean, indexed by property
/* For storing the result projected categories: */
create and clear CA: set of category
/* For temporarily storing the properties to be evaluated: */
create and clear S: set of property
for (mask E [1 ... 2n — 1])
key — applyBinaryMask(A, mask)
if (key is in the set of indexes for 9) then
/* Properties are retrieved from the grammar, then evaluated */
</bodyText>
<equation confidence="0.9866458">
S — 9[key].getProperties()
XA — evaluate(S)
/* Projection Step: fetch the categories to be projected */
CA — 9[key].getDominantCategories()
return XA, CA
</equation>
<bodyText confidence="0.985503586206897">
The key is a hash-code of a combination of constructions, used for fetching the
constraints this combination is concerned with.
ing a category judgement for a configuration, on
the basis of which constraints are satisfied and vi-
olated, in order to label its root. The process is a
simple table lookup, the grammar being indexed
by properties. Step 5 then memoises the optimal
sub-structures for every possible category. Note
that the uniqueness of the solution is not guaran-
teed, and there may well be many different parses
with exact same merit for a given input utterance.
Should the current cell in the chart not being
populated with any constituents, a preferred for-
est of partial parses (= Star category) is used in-
stead. The preferred forest is constructed on the
fly (as part of buildConfigurations); a pointer
is maintained to the preferred configuration dur-
ing enumeration. The preference goes to: (i) the
constituents with the widest span; (ii) the least
overall number of constituents. This translates
heuristically into a preference score PF computed
as follows (where F is the forest, and Ci its con-
stituents): PF = span · (merit(Ci) + span). In
that way, LSCP always delivers a parse for any
input. The technique is somehow similar to the
one of Riezler et al. (2002), where fragment parses
are allowed for achieving increased robustness, al-
though their solution requires the standard gram-
mar to be augmented with a fragment grammar.
</bodyText>
<sectionHeader confidence="0.996801" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.99995352173913">
In order to measure Numbat’s ability to (i) detect
errors in an ungrammatical sentence, and (ii) build
the best approximated parse for it, Numbat should,
ideally, be evaluated on a corpus of both well-
formed and ill-formed utterances annotated with
spannnig phrase structures. Unfortunately, such
a Gold Standard is not available to us. The de-
velopment of adequate resources is central to fu-
ture works. In order to (partially) overcome that
problem we have carried out two distinct evalua-
tions: one aims to measure Numbat’s performance
on grammatical sentences, and the other one on
ungrammatical sentences. Evaluation 1, whose re-
sults are reported in Table 2, follows the proto-
col devised for the EASY evaluation campaign of
parsers of French (Paroubek et al., 2003), with a
subset of the campaign’s corpus. For comparison,
Table 3 reports the performance measured under
the same circumstances for two other parsers: a
shallow one (VanRullen, 2005) also based on PG,
and a stochastic one (VanRullen et al., 2006). The
grammar used for that evaluation was developed
by VanRullen (2005). Evaluation 2 was run on
</bodyText>
<page confidence="0.993127">
174
</page>
<table confidence="0.999981636363636">
Precision Recall F
Total 0.7835 0.7057 0.7416
general lemonde 0.8187 0.7515 0.7837
general mlcc 0.7175 0.6366 0.6746
general senat 0.8647 0.7069 0.7779
litteraire 0.8124 0.7651 0.788
mail 0.7193 0.6951 0.707
medical 0.8573 0.678 0.757
oral delic 0.6817 0.621 0.649
questions amaryllis 0.8081 0.7432 0.7743
questions trec 0.8208 0.7069 0.7596
</table>
<tableCaption confidence="0.960325">
Table 2: EASY scores of Numbat (Eval. 1)
</tableCaption>
<table confidence="0.999907666666667">
Precision Recall F
shallow parser 0.7846 0.8376 0.8102
stochastic parser 0.9013 0.8978 0.8995
</table>
<tableCaption confidence="0.999847">
Table 3: Comparative EASY scores
</tableCaption>
<bodyText confidence="0.997490733333333">
a corpus of unannotated ungrammatical sentences
(Blache et al., 2006), where each of the ungram-
matical sentences (amounting to 94% of the cor-
pus) matches a controlled error pattern. Five ex-
pert annotators were asked whether the solution
trees were possible and acceptable syntactic parses
for their corresponding sentence. Specific instruc-
tions were given to make sure that the judgement
does not hold on the grammatical acceptability of
the surface sentence as such, but actually on the
parse associated with it. For that evaluation Van-
Rullen’s grammar was completed with nested cat-
egories (since the EASY annotation scheme only
has chunks). Given the nature of the material to
be assessed here, the Precision and Recall mea-
surements had to be modified. The total number
of input sentences is interpreted as the number of
predictions; the number of COMPLETE structures
is interpreted as the number of observations; and
the number of structures evaluated as CORRECT
by human judges is interpreted as the number of
correct solutions. Hence the following formula-
tions and scores: Precision=CORRECT/COMPLETE=0.74;
Recall=CORRECT/Total=0.68; F=0.71. 92% of the cor-
pus is analysed with a complete structure; 74% of
these complete parses were judged as syntactically
correct. The Recall score indicates that the correct
parses represent 68% of the corpus. In spite of a
lack of a real baseline, these scores compare with
those of grammatical parsers.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999632">
In this paper, we have proposed to address the
problem of grammar error detection in providing
a set of violated syntactic properties for an ill-
formed sentence, along with the best structural
context in the form of a connected syntax tree. We
have introduced an algorithm for Loose Satisfac-
tion Chart Parsing (LSCP) which meets those re-
quirements, and presented performance measures
for it. Future work includes optimisation of LSCP
and validation on more appropriate corpora.
</bodyText>
<sectionHeader confidence="0.973281" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.976125">
Partly funded by ANR-07-MDCO-03 (CRoTAL).
</bodyText>
<sectionHeader confidence="0.997539" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999240794871795">
E. M. Bender, D. Flickinger, S. Oepen, A. Walsh, and
T. Baldwin. 2004. Arboretum: Using a precision
grammar for grammar checking in CALL. In Proc.
of InSTIL/ICALL2004, volume 17, page 19.
P. Blache, B. Hemforth, and S. Rauzy. 2006. Ac-
ceptability Prediction by Means of Grammaticality
Quantification. In Proc. of CoLing/ACL, pages 57–
64. ACL.
P. Blache. 2001. Les Grammaires de Propri´et´es :
des contraintes pour le traitement automatique des
langues naturelles. Herm`es Sciences.
S. Douglas and R. Dale. 1992. Towards Robust PATR.
In Proc. of CoLing, volume 2, pages 468–474. ACL.
D. Duchier, J-P. Prost, and T-B-H. Dao. 2009.
A Model-Theoretic Framework for Grammaticality
Judgements. In To appear in Proc. of FG’09, vol-
ume 5591 of LNCS. FOLLI, Springer.
J. Foster. 2007. Real bad grammar: Realistic grammat-
ical description with grammaticality. Corpus Lin-
guistics and Lingustic Theory, 3(1):73–86.
K. Foth, W. Menzel, and I. Schr¨oder. 2005. Robust
Parsing with Weighted Constraints. Natural Lan-
guage Engineering, 11(1):1–25.
F. Fouvry. 2003. Constraint relaxation with weighted
feature structures. pages 103–114.
P. Paroubek, I. Robba, and A. Vilnat. 2003. EASY:
An Evaluation Protocol for Syntactic Parsers.
www.limsi.fr/RS2005/chm/lir/lir11/ (08/2008).
S. Riezler, T. H. King, R. M. Kaplan, R. Crouch,
J. T. III Maxwell, and M. Johnson. 2002.
Parsing the Wall Street Journal using a Lexical-
Functional Grammar and Discriminative Estimation
Techniques. In Proc. of ACL, pages 271–278. ACL.
T. VanRullen, P. Blache, and J-M. Balfourier. 2006.
Constraint-Based Parsing as an Efficient Solution:
Results from the Parsing Evaluation Campaign
EASy. In Proc. of LREC, pages 165–170.
T. VanRullen. 2005. Vers une analyse syntaxique a`
granularit´e variable. Th`ese de doctorat.
</reference>
<page confidence="0.998671">
175
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.397305">
<title confidence="0.99005">Grammar Error Detection with Best Approximated Parse</title>
<author confidence="0.761017">Jean-Philippe Prost</author>
<affiliation confidence="0.6205525">LIFO, Universit´e d’Orl´eans INRIA Lille - Nord Europe</affiliation>
<email confidence="0.706309">Jean-Philippe.Prost@univ-orleans.fr</email>
<abstract confidence="0.996452066666667">In this paper, we propose that grammar error detection be disambiguated in generating the connected parse(s) of optimal merit for the full input utterance, in overcoming the cheapest error. The detected error(s) are described as violated grammatical constraints in a framework for Model- Theoretic Syntax (MTS). We present a parsing algorithm for MTS, which only relies on a grammar of well-formedness, in that the process does not require any extragrammatical resources, additional rules for constraint relaxation or error handling, or any recovery process.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E M Bender</author>
<author>D Flickinger</author>
<author>S Oepen</author>
<author>A Walsh</author>
<author>T Baldwin</author>
</authors>
<title>Arboretum: Using a precision grammar for grammar checking in CALL.</title>
<date>2004</date>
<booktitle>In Proc. of InSTIL/ICALL2004,</booktitle>
<volume>17</volume>
<pages>19</pages>
<contexts>
<context position="2321" citStr="Bender et al., 2004" startWordPosition="359" endWordPosition="362">ustrates an approximated parse for an ill-formed sentence in French, and the error being detected in that context. Property Grammar (Blache, 2001) provides an elegant framework for that purpose. Figure 1: Approximated parse for an erroneous French sentence (the Noun ’entretien’ requires a Determiner). Most of the relevant approaches to robust knowledge-based parsing addresses the problem as a recovery process. More specifically, we observe three families of approaches in that respect: those relying on grammar mal-rules in order to specify how to correctly parse what ought to be ungrammatical (Bender et al., 2004; Foster, 2007); those relying on constraint relaxation according to specified relaxation rules (Douglas and Dale, 1992); and those relying on constraint relaxation with no relaxation rules, along with a recovery process based on weighted parsing (Fouvry, 2003; Foth et al., 2005). The first two are actually quite similar, in that, through their use of extra-grammatical rules, they both extend the grammar’s coverage with a set of ought-to-beungrammatical utterances. The main drawback of those approaches is that when faced with unexpected input at best their outcome remains unknown, at worst the</context>
</contexts>
<marker>Bender, Flickinger, Oepen, Walsh, Baldwin, 2004</marker>
<rawString>E. M. Bender, D. Flickinger, S. Oepen, A. Walsh, and T. Baldwin. 2004. Arboretum: Using a precision grammar for grammar checking in CALL. In Proc. of InSTIL/ICALL2004, volume 17, page 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blache</author>
<author>B Hemforth</author>
<author>S Rauzy</author>
</authors>
<title>Acceptability Prediction by Means of Grammaticality Quantification.</title>
<date>2006</date>
<booktitle>In Proc. of CoLing/ACL,</booktitle>
<pages>57--64</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="13733" citStr="Blache et al., 2006" startWordPosition="2299" endWordPosition="2302">llen (2005). Evaluation 2 was run on 174 Precision Recall F Total 0.7835 0.7057 0.7416 general lemonde 0.8187 0.7515 0.7837 general mlcc 0.7175 0.6366 0.6746 general senat 0.8647 0.7069 0.7779 litteraire 0.8124 0.7651 0.788 mail 0.7193 0.6951 0.707 medical 0.8573 0.678 0.757 oral delic 0.6817 0.621 0.649 questions amaryllis 0.8081 0.7432 0.7743 questions trec 0.8208 0.7069 0.7596 Table 2: EASY scores of Numbat (Eval. 1) Precision Recall F shallow parser 0.7846 0.8376 0.8102 stochastic parser 0.9013 0.8978 0.8995 Table 3: Comparative EASY scores a corpus of unannotated ungrammatical sentences (Blache et al., 2006), where each of the ungrammatical sentences (amounting to 94% of the corpus) matches a controlled error pattern. Five expert annotators were asked whether the solution trees were possible and acceptable syntactic parses for their corresponding sentence. Specific instructions were given to make sure that the judgement does not hold on the grammatical acceptability of the surface sentence as such, but actually on the parse associated with it. For that evaluation VanRullen’s grammar was completed with nested categories (since the EASY annotation scheme only has chunks). Given the nature of the ma</context>
</contexts>
<marker>Blache, Hemforth, Rauzy, 2006</marker>
<rawString>P. Blache, B. Hemforth, and S. Rauzy. 2006. Acceptability Prediction by Means of Grammaticality Quantification. In Proc. of CoLing/ACL, pages 57– 64. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blache</author>
</authors>
<title>Les Grammaires de Propri´et´es : des contraintes pour le traitement automatique des langues naturelles. Herm`es Sciences.</title>
<date>2001</date>
<contexts>
<context position="1848" citStr="Blache, 2001" startWordPosition="287" endWordPosition="288">). Robust partial parsing is often not enough to precisely desambiguate those cases. The solution we prescribe is to point out the error(s) as a set of violated (atomic) constraints of minimal cost, along with the structural context used for measuring that cost. Given an ungrammatical input string, the aim is then to provide an approximated rooted parse tree for it, along with a description of all the grammatical constraints it violates. For example, Figure 1 illustrates an approximated parse for an ill-formed sentence in French, and the error being detected in that context. Property Grammar (Blache, 2001) provides an elegant framework for that purpose. Figure 1: Approximated parse for an erroneous French sentence (the Noun ’entretien’ requires a Determiner). Most of the relevant approaches to robust knowledge-based parsing addresses the problem as a recovery process. More specifically, we observe three families of approaches in that respect: those relying on grammar mal-rules in order to specify how to correctly parse what ought to be ungrammatical (Bender et al., 2004; Foster, 2007); those relying on constraint relaxation according to specified relaxation rules (Douglas and Dale, 1992); and t</context>
<context position="4925" citStr="Blache, 2001" startWordPosition="767" endWordPosition="768">nt in terms of unrelaxable constraints. What we would like is (i) to detect any type of errors, and present them as conditions of wellformedness being violated in solely relying on the knowledge of a grammar of well-formedness—as opposed to an error grammar or mal-rules, and (ii) to present, along-side the violated constraints, an approximated parse for the full sentence, which may explain which errors have been found and overcome. We propose here a parsing algorithm which meets these requirements. 2 Property Grammar The framework we are using for knowledge representation is Property Grammar (Blache, 2001) (PG), whose model-theoretical semantics was formalised by Duchier et al. (2009). Intuitively, a PG grammar decomposes what would be rewriting rules of a generative grammar into atomic syntactic properties — a property being represented as a boolean constraint. Take, for instance, the rewriting rule NP —* D N. That rule implicitely informs on different properties (for French): (1) NP has a D child; (2) the D child is unique; (3) NP has an N child; (4) the N child is unique; (5) the D child precedes the N child; (6) the N child requires the D child. PG defines a set of axioms, each axiom corres</context>
</contexts>
<marker>Blache, 2001</marker>
<rawString>P. Blache. 2001. Les Grammaires de Propri´et´es : des contraintes pour le traitement automatique des langues naturelles. Herm`es Sciences.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Douglas</author>
<author>R Dale</author>
</authors>
<title>Towards Robust PATR.</title>
<date>1992</date>
<booktitle>In Proc. of CoLing,</booktitle>
<volume>2</volume>
<pages>468--474</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="2441" citStr="Douglas and Dale, 1992" startWordPosition="376" endWordPosition="379">roperty Grammar (Blache, 2001) provides an elegant framework for that purpose. Figure 1: Approximated parse for an erroneous French sentence (the Noun ’entretien’ requires a Determiner). Most of the relevant approaches to robust knowledge-based parsing addresses the problem as a recovery process. More specifically, we observe three families of approaches in that respect: those relying on grammar mal-rules in order to specify how to correctly parse what ought to be ungrammatical (Bender et al., 2004; Foster, 2007); those relying on constraint relaxation according to specified relaxation rules (Douglas and Dale, 1992); and those relying on constraint relaxation with no relaxation rules, along with a recovery process based on weighted parsing (Fouvry, 2003; Foth et al., 2005). The first two are actually quite similar, in that, through their use of extra-grammatical rules, they both extend the grammar’s coverage with a set of ought-to-beungrammatical utterances. The main drawback of those approaches is that when faced with unexpected input at best their outcome remains unknown, at worst the parsing process fails. With robust weighted parsing, on the other hand, that problem does not occur. The recovery proce</context>
</contexts>
<marker>Douglas, Dale, 1992</marker>
<rawString>S. Douglas and R. Dale. 1992. Towards Robust PATR. In Proc. of CoLing, volume 2, pages 468–474. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Duchier</author>
<author>J-P Prost</author>
<author>T-B-H Dao</author>
</authors>
<title>A Model-Theoretic Framework for Grammaticality Judgements. In To appear in</title>
<date>2009</date>
<booktitle>Proc. of FG’09,</booktitle>
<volume>5591</volume>
<publisher>FOLLI, Springer.</publisher>
<contexts>
<context position="5005" citStr="Duchier et al. (2009)" startWordPosition="777" endWordPosition="780">ect any type of errors, and present them as conditions of wellformedness being violated in solely relying on the knowledge of a grammar of well-formedness—as opposed to an error grammar or mal-rules, and (ii) to present, along-side the violated constraints, an approximated parse for the full sentence, which may explain which errors have been found and overcome. We propose here a parsing algorithm which meets these requirements. 2 Property Grammar The framework we are using for knowledge representation is Property Grammar (Blache, 2001) (PG), whose model-theoretical semantics was formalised by Duchier et al. (2009). Intuitively, a PG grammar decomposes what would be rewriting rules of a generative grammar into atomic syntactic properties — a property being represented as a boolean constraint. Take, for instance, the rewriting rule NP —* D N. That rule implicitely informs on different properties (for French): (1) NP has a D child; (2) the D child is unique; (3) NP has an N child; (4) the N child is unique; (5) the D child precedes the N child; (6) the N child requires the D child. PG defines a set of axioms, each axiom corresponding to a constraint type. The properties above are then specified in the gra</context>
</contexts>
<marker>Duchier, Prost, Dao, 2009</marker>
<rawString>D. Duchier, J-P. Prost, and T-B-H. Dao. 2009. A Model-Theoretic Framework for Grammaticality Judgements. In To appear in Proc. of FG’09, volume 5591 of LNCS. FOLLI, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Foster</author>
</authors>
<title>Real bad grammar: Realistic grammatical description with grammaticality.</title>
<date>2007</date>
<booktitle>Corpus Linguistics and Lingustic Theory,</booktitle>
<pages>3--1</pages>
<contexts>
<context position="2336" citStr="Foster, 2007" startWordPosition="363" endWordPosition="364">ted parse for an ill-formed sentence in French, and the error being detected in that context. Property Grammar (Blache, 2001) provides an elegant framework for that purpose. Figure 1: Approximated parse for an erroneous French sentence (the Noun ’entretien’ requires a Determiner). Most of the relevant approaches to robust knowledge-based parsing addresses the problem as a recovery process. More specifically, we observe three families of approaches in that respect: those relying on grammar mal-rules in order to specify how to correctly parse what ought to be ungrammatical (Bender et al., 2004; Foster, 2007); those relying on constraint relaxation according to specified relaxation rules (Douglas and Dale, 1992); and those relying on constraint relaxation with no relaxation rules, along with a recovery process based on weighted parsing (Fouvry, 2003; Foth et al., 2005). The first two are actually quite similar, in that, through their use of extra-grammatical rules, they both extend the grammar’s coverage with a set of ought-to-beungrammatical utterances. The main drawback of those approaches is that when faced with unexpected input at best their outcome remains unknown, at worst the parsing proces</context>
</contexts>
<marker>Foster, 2007</marker>
<rawString>J. Foster. 2007. Real bad grammar: Realistic grammatical description with grammaticality. Corpus Linguistics and Lingustic Theory, 3(1):73–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Foth</author>
<author>W Menzel</author>
<author>I Schr¨oder</author>
</authors>
<title>Robust Parsing with Weighted Constraints.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>1</issue>
<marker>Foth, Menzel, Schr¨oder, 2005</marker>
<rawString>K. Foth, W. Menzel, and I. Schr¨oder. 2005. Robust Parsing with Weighted Constraints. Natural Language Engineering, 11(1):1–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Fouvry</author>
</authors>
<title>Constraint relaxation with weighted feature structures.</title>
<date>2003</date>
<pages>103--114</pages>
<contexts>
<context position="2581" citStr="Fouvry, 2003" startWordPosition="401" endWordPosition="403">’entretien’ requires a Determiner). Most of the relevant approaches to robust knowledge-based parsing addresses the problem as a recovery process. More specifically, we observe three families of approaches in that respect: those relying on grammar mal-rules in order to specify how to correctly parse what ought to be ungrammatical (Bender et al., 2004; Foster, 2007); those relying on constraint relaxation according to specified relaxation rules (Douglas and Dale, 1992); and those relying on constraint relaxation with no relaxation rules, along with a recovery process based on weighted parsing (Fouvry, 2003; Foth et al., 2005). The first two are actually quite similar, in that, through their use of extra-grammatical rules, they both extend the grammar’s coverage with a set of ought-to-beungrammatical utterances. The main drawback of those approaches is that when faced with unexpected input at best their outcome remains unknown, at worst the parsing process fails. With robust weighted parsing, on the other hand, that problem does not occur. The recovery process consists of filtering out structures with respect to their weights or the weights of the constraints being relaxed. However, these strate</context>
</contexts>
<marker>Fouvry, 2003</marker>
<rawString>F. Fouvry. 2003. Constraint relaxation with weighted feature structures. pages 103–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Paroubek</author>
<author>I Robba</author>
<author>A Vilnat</author>
</authors>
<title>EASY: An Evaluation Protocol for Syntactic Parsers.</title>
<date>2003</date>
<tech>www.limsi.fr/RS2005/chm/lir/lir11/ (08/2008).</tech>
<contexts>
<context position="12806" citStr="Paroubek et al., 2003" startWordPosition="2157" endWordPosition="2160">t should, ideally, be evaluated on a corpus of both wellformed and ill-formed utterances annotated with spannnig phrase structures. Unfortunately, such a Gold Standard is not available to us. The development of adequate resources is central to future works. In order to (partially) overcome that problem we have carried out two distinct evaluations: one aims to measure Numbat’s performance on grammatical sentences, and the other one on ungrammatical sentences. Evaluation 1, whose results are reported in Table 2, follows the protocol devised for the EASY evaluation campaign of parsers of French (Paroubek et al., 2003), with a subset of the campaign’s corpus. For comparison, Table 3 reports the performance measured under the same circumstances for two other parsers: a shallow one (VanRullen, 2005) also based on PG, and a stochastic one (VanRullen et al., 2006). The grammar used for that evaluation was developed by VanRullen (2005). Evaluation 2 was run on 174 Precision Recall F Total 0.7835 0.7057 0.7416 general lemonde 0.8187 0.7515 0.7837 general mlcc 0.7175 0.6366 0.6746 general senat 0.8647 0.7069 0.7779 litteraire 0.8124 0.7651 0.788 mail 0.7193 0.6951 0.707 medical 0.8573 0.678 0.757 oral delic 0.6817</context>
</contexts>
<marker>Paroubek, Robba, Vilnat, 2003</marker>
<rawString>P. Paroubek, I. Robba, and A. Vilnat. 2003. EASY: An Evaluation Protocol for Syntactic Parsers. www.limsi.fr/RS2005/chm/lir/lir11/ (08/2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riezler</author>
<author>T H King</author>
<author>R M Kaplan</author>
<author>R Crouch</author>
<author>J T Maxwell</author>
<author>M Johnson</author>
</authors>
<title>Parsing the Wall Street Journal using a LexicalFunctional Grammar and Discriminative Estimation Techniques.</title>
<date>2002</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>271--278</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="11860" citStr="Riezler et al. (2002)" startWordPosition="2006" endWordPosition="2009">ferred forest of partial parses (= Star category) is used instead. The preferred forest is constructed on the fly (as part of buildConfigurations); a pointer is maintained to the preferred configuration during enumeration. The preference goes to: (i) the constituents with the widest span; (ii) the least overall number of constituents. This translates heuristically into a preference score PF computed as follows (where F is the forest, and Ci its constituents): PF = span · (merit(Ci) + span). In that way, LSCP always delivers a parse for any input. The technique is somehow similar to the one of Riezler et al. (2002), where fragment parses are allowed for achieving increased robustness, although their solution requires the standard grammar to be augmented with a fragment grammar. 4 Evaluation In order to measure Numbat’s ability to (i) detect errors in an ungrammatical sentence, and (ii) build the best approximated parse for it, Numbat should, ideally, be evaluated on a corpus of both wellformed and ill-formed utterances annotated with spannnig phrase structures. Unfortunately, such a Gold Standard is not available to us. The development of adequate resources is central to future works. In order to (parti</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>S. Riezler, T. H. King, R. M. Kaplan, R. Crouch, J. T. III Maxwell, and M. Johnson. 2002. Parsing the Wall Street Journal using a LexicalFunctional Grammar and Discriminative Estimation Techniques. In Proc. of ACL, pages 271–278. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T VanRullen</author>
<author>P Blache</author>
<author>J-M Balfourier</author>
</authors>
<title>Constraint-Based Parsing as an Efficient Solution: Results from the Parsing Evaluation Campaign EASy.</title>
<date>2006</date>
<booktitle>In Proc. of LREC,</booktitle>
<pages>165--170</pages>
<contexts>
<context position="13052" citStr="VanRullen et al., 2006" startWordPosition="2197" endWordPosition="2200">uture works. In order to (partially) overcome that problem we have carried out two distinct evaluations: one aims to measure Numbat’s performance on grammatical sentences, and the other one on ungrammatical sentences. Evaluation 1, whose results are reported in Table 2, follows the protocol devised for the EASY evaluation campaign of parsers of French (Paroubek et al., 2003), with a subset of the campaign’s corpus. For comparison, Table 3 reports the performance measured under the same circumstances for two other parsers: a shallow one (VanRullen, 2005) also based on PG, and a stochastic one (VanRullen et al., 2006). The grammar used for that evaluation was developed by VanRullen (2005). Evaluation 2 was run on 174 Precision Recall F Total 0.7835 0.7057 0.7416 general lemonde 0.8187 0.7515 0.7837 general mlcc 0.7175 0.6366 0.6746 general senat 0.8647 0.7069 0.7779 litteraire 0.8124 0.7651 0.788 mail 0.7193 0.6951 0.707 medical 0.8573 0.678 0.757 oral delic 0.6817 0.621 0.649 questions amaryllis 0.8081 0.7432 0.7743 questions trec 0.8208 0.7069 0.7596 Table 2: EASY scores of Numbat (Eval. 1) Precision Recall F shallow parser 0.7846 0.8376 0.8102 stochastic parser 0.9013 0.8978 0.8995 Table 3: Comparative </context>
</contexts>
<marker>VanRullen, Blache, Balfourier, 2006</marker>
<rawString>T. VanRullen, P. Blache, and J-M. Balfourier. 2006. Constraint-Based Parsing as an Efficient Solution: Results from the Parsing Evaluation Campaign EASy. In Proc. of LREC, pages 165–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T VanRullen</author>
</authors>
<title>Vers une analyse syntaxique a` granularit´e variable. Th`ese de doctorat.</title>
<date>2005</date>
<contexts>
<context position="4281" citStr="VanRullen (2005)" startWordPosition="664" endWordPosition="665"> from grammar consistency: since the grammar contains contradicting (universal) constraints, no conclusion can be drawn with regard to the grammaticality of a syntactic structure, which violates part of the constraint system. The same problem occurs with Optimality Theory. In a different fashion, Fouvry weighs unification constraints according to “how much information it contains”. However, relaxation only seems possible for those unification constraints: error patterns such as word order, co-occurrence, uniqueness, mutual exclusion, ... can not be tackled. The same restriction is observed in VanRullen (2005), though to a much smaller extent in terms of unrelaxable constraints. What we would like is (i) to detect any type of errors, and present them as conditions of wellformedness being violated in solely relying on the knowledge of a grammar of well-formedness—as opposed to an error grammar or mal-rules, and (ii) to present, along-side the violated constraints, an approximated parse for the full sentence, which may explain which errors have been found and overcome. We propose here a parsing algorithm which meets these requirements. 2 Property Grammar The framework we are using for knowledge repre</context>
<context position="12988" citStr="VanRullen, 2005" startWordPosition="2187" endWordPosition="2188">us. The development of adequate resources is central to future works. In order to (partially) overcome that problem we have carried out two distinct evaluations: one aims to measure Numbat’s performance on grammatical sentences, and the other one on ungrammatical sentences. Evaluation 1, whose results are reported in Table 2, follows the protocol devised for the EASY evaluation campaign of parsers of French (Paroubek et al., 2003), with a subset of the campaign’s corpus. For comparison, Table 3 reports the performance measured under the same circumstances for two other parsers: a shallow one (VanRullen, 2005) also based on PG, and a stochastic one (VanRullen et al., 2006). The grammar used for that evaluation was developed by VanRullen (2005). Evaluation 2 was run on 174 Precision Recall F Total 0.7835 0.7057 0.7416 general lemonde 0.8187 0.7515 0.7837 general mlcc 0.7175 0.6366 0.6746 general senat 0.8647 0.7069 0.7779 litteraire 0.8124 0.7651 0.788 mail 0.7193 0.6951 0.707 medical 0.8573 0.678 0.757 oral delic 0.6817 0.621 0.649 questions amaryllis 0.8081 0.7432 0.7743 questions trec 0.8208 0.7069 0.7596 Table 2: EASY scores of Numbat (Eval. 1) Precision Recall F shallow parser 0.7846 0.8376 0.8</context>
</contexts>
<marker>VanRullen, 2005</marker>
<rawString>T. VanRullen. 2005. Vers une analyse syntaxique a` granularit´e variable. Th`ese de doctorat.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>