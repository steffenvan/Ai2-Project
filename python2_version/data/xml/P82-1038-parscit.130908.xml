<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.174546">
<note confidence="0.527260666666667">
&amp;quot;NATURAL LANGUAGE TEXTS ARE NOT NECESSARILY GRAMMATICAL AND UNAMBIGUOUS
OR EVEN COMPLETE.&amp;quot;
Lance A. Miller
</note>
<bodyText confidence="0.991046628571429">
Behavioral Sciences and Linguistics Group
IBM Watson Research Center
P. 0. Box 218
Yorktown Heights, NY 10598
The EPISTLE system is being developed in a research
project for exploring the feasibility of a variety
of intelligent applications for the processing of
business and office text (1-3; the authors of 3
are the project workers). Although ultimately
intended functions include text generation (e.g.,
4), present efforts focus on text analysis: devel-
oping the capability to take in essentially
unconstrained business text and to output grammar
and style critiques, on a sentence by sentence
basis.
Briefly, we use a large on-line dictionary and a
bottom-up parser in connection with an Augmented
Phrase Structure Grammar (5) to obtain an approxi-
mately correct structural description of the
surface text (e.g., we posit no transformations or
recovery of deleted material to infer underlying
&amp;quot;deep&amp;quot; structures). In this process we always try
to force a single parse output, even in the pres-
ence of true ambiguity. Grammatical critiques are
provided by having very strong grammar restrictions
in an initial processing of the sentence; should
the application of grammar rules fail to lead to
the identification of a complete, syntactically
correct, sentence, we then process the material a
second time, adding other rules which essentially
relax certain constraints, such as subject-verb
number agreement, thereby permitting us to recog-
nize a wide variety of true grammatical errors.
The stylistic critiques are based on measurements
of the detailed hierarchical structure descriptions
produced by the parser, letting us detect a variety
of stylistic characteristics judged by &amp;quot;experts&amp;quot; to
be undesirable: too great a distance between
subject and verb, too much embedding, unbalanced
subject/predicate size, excessive negation or quan-
tification, etc.
The text corpus used for system construction and
testing is a set of some 400 business letters,
mostly written by individuals from within various
organizations to individuals outside those organ-
izations. These letters, which consist of approxi-
mately 2300 sentences, were selected from a larger
collection (about 2000 letters) as being represen-
tative of the wide variety of styles, tones,
subject matter, purposes, lengths, factual content,
and organization-type found in the overall popu-
lation of business letters. A corpus differing in
so many of the above features is also heterogeneous
with respect to syntactic structures -- and there-
fore with respect to the grammatical capabilities
that must be incorporated for correct recognition.
However, it was one thing to be prepared for struc-
tural diversity; it was quite another thing to be
faced with the fact that our business letters are
not some small to moderate subset of grammatical
phenomena. Rather, they include all of the common
and most of the arcane constructions one could find
in, say, Warriner and Griffith (6). For example,
the very first sentence we tackled was 29 words
long and began &amp;quot;How nice it was to receive your
letter complimenting our Manager, Bud Handy, on his
courtesy ...&amp;quot;: we ran into extraposition, inver-
sion, infinitive nominalization, gerund phrase, and
appositive all within the first 13 words! A prima-
ry consequence of this rich jumble of syntactic
scree was the frequent annoyance of being stopped
dead in our processing tracks as our grammar
revealed itself to be yet once more incomplete.
But it was not only the incompleteness of the gram-
mar (for correct sentences) that gave us trouble:
many words were not recognized, sometimes sentences
were incomplete, other times they were truly
ungrammatical (via normal abnormalities of grammar
or via what appeared to be a rather thoughtless --
or at least uninformed -- scattering of apostrophes
and semicolons within the text) and often we were
faced not with our desired single parse but with
many. These then are the situations which cried
out for techniques either to keep processing going
or, at least, to keep it alive long enough for it to
scratch out detailed informative guesses at struc-
ture on the parsing floor before expiring.
The techniques for hardiness and robustness which
we have developed in the two years of implementa-
tion, and particularly recently, are mostly
specific to the five trouble situations referred to
above. For (i) unrecognized words (words not in our
125K entry on-line dictionary) we check first
either for initial capitalization or for an inter-
nal hyphen, presuming a proper name -- noun -- part
of speech for the former and either noun or adjec-
tive for the latter. As we improve our dictionary
processing, to support efficient affix-stripping
and stem storage, we now plan to hypothesize parts
of speech based upon, in particular, the outer
suffixes (e.g., &amp;quot;1y&amp;quot; pretty conclusively estab-
lishes multi-syllabic words as adverbs). This more
&amp;quot;intelligent&amp;quot; processing at the part-of-speech
level is particularly important for avoiding multi-
ple false parses.
</bodyText>
<page confidence="0.995412">
167
</page>
<bodyText confidence="0.999973156862745">
For the two situations of either (ii) an incomplete
grammar failing to process a complete grammatical
sentence, or (iii) an actual incomplete sentence
(sentence fragment), we are no able to output a
single &amp;quot;best&amp;quot; structural description when the gram-
mar can do no more&apos; (Jensen and Heidorn,
forthcoming). This partial structure is &amp;quot;best&amp;quot; in
the sense that it provides the largest and most
continuous coverage of the input text string, and
it also adheres to certain orderings of parts of
speech and non-terminal constituents. Our experi-
ence with such structures is that they are quite
often correct, always better than a &amp;quot;CANNOT PARSE&amp;quot;
outcome, and appear to be fairly usable for style
critiquing. In the future we believe more can be
done with sentence fragments by assuming, first,
they are simply to be conjoined to some element of
the previous sentence, or, second, they are an
elaboration of an immediately preceding element; in
either case the partial structure output should
provide sufficient information to &amp;quot;hook&amp;quot; the frag-
ments in correctly.
For (iv) truly ungrammatical sentences, as
mentioned previously, we introduce a second pass
with a number of grammatical restrictions relaxed;
should any complete sentence structure result we
can determine which relaxations were responsible
and thereby actually identify the class of ungram-
maticality. From the point of view of useful
applications, this is much more of a desirable
user-oriented function than an internal robust
recovery procedure. Nonetheless, from the point of
view of the style critiques at the sentence and
paragraph levels, this procedure assures the best
possible starting point, despite &amp;quot;noise&amp;quot; in the
input text.
Finally, (v) the situation of multiple parses is
dealt with by two techniques. The first is the
deliberate attempt to construct the grammar rules
such that no more than a single parse can squeeze
through in most situations; the second is the
development of a metric which computes a real
number for each parse, based on its structural
features, with the decision rule simply being to
choose the parse with the smallest number (7).
Our experience with this metric is that it usually
leads to selection of the best all-around parse;
such errors as are made would seem to require
semantic -- and even pragmatic -- information to be
weighed in the metric, a capability presently
beyond our means.
</bodyText>
<sectionHeader confidence="0.991151" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.99996896969697">
1. Miller, Lance A. &amp;quot;Project EPISTLE: A system for
the automatic analysis of business correspond-
ence.&amp;quot; Proceedings of the First Annual
National Conference on Artificial
Intelligence, Stanford University, August,
1980, 280-282.
2. Miller, Lance A., George E. Heidorn, and Karen
Jensen &amp;quot;Text-Critiquing with the EPISTLE
System: An Author&apos;s Aid to Better Syntax.&amp;quot;
AFIPS Proceedings of the National Computer
Conference, Chicago, May 4-7, 1981, 649-655.
3. Heidorn, George E., Karen Jensen, Lance A. Mill-
er, Roy J. Byrd, and Martin S. Chodorow &amp;quot;The
EPISTLE Text-Critiquing System.&amp;quot; IBM Systems
Journal, to appear Fall, 1982.
4. Jensen, Karen &amp;quot;Computer Generation of Topic
Paragraphs: Structure and Style&amp;quot;. Paper
presented at the ACL Session of LSA Annual
Meeting, New York City, December, 1981 (IBM
Research Report, 1982).
5. Heidorn, George E. &amp;quot;Augmented Phrase Structure
Grammars&amp;quot;. In B. Nash-Webber and R. Schenk
(Eds.), Theoretical Issues in Natural Language
Processing, Association for Computational
Linguistics, 1975.
6. Warriner, J. E. and F. Griffith English Grammar
and Composition. New York: Harcourt, Brace and
World, Inc., 1963.
7. Heidorn, George E. &amp;quot;Experience with an easily
computed metric for ranking alternative
parses&amp;quot;. Presentation at the Association for
Computational Linguistics Meeting, Toronto,
Canada, June 17, 1982.
</reference>
<page confidence="0.997305">
168
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.010042">
<title confidence="0.997771">amp;quot;NATURAL LANGUAGE TEXTS ARE NOT NECESSARILY GRAMMATICAL AND UNAMBIGUOUS</title>
<author confidence="0.842704">OR EVEN COMPLETE Lance A Miller</author>
<affiliation confidence="0.997219">Behavioral Sciences and Linguistics Group IBM Watson Research Center</affiliation>
<address confidence="0.9604375">P. 0. Box 218 Yorktown Heights, NY 10598</address>
<abstract confidence="0.998975044585987">The EPISTLE system is being developed in a research project for exploring the feasibility of a variety of intelligent applications for the processing of business and office text (1-3; the authors of 3 are the project workers). Although ultimately intended functions include text generation (e.g., 4), present efforts focus on text analysis: developing the capability to take in essentially unconstrained business text and to output grammar and style critiques, on a sentence by sentence basis. Briefly, we use a large on-line dictionary and a bottom-up parser in connection with an Augmented Phrase Structure Grammar (5) to obtain an approximately correct structural description of the surfacetext (e.g., we posit no transformations or recovery of deleted material to infer underlying &amp;quot;deep&amp;quot; structures). In this process we always try to force a single parse output, even in the presof true ambiguity. critiquesare provided by having very strong grammar restrictions in an initial processing of the sentence; should the application of grammar rules fail to lead to of a complete, correct, sentence, we then process the material a second time, adding other rules which essentially relax certain constraints, such as subject-verb number agreement, thereby permitting us to recognize a wide variety of true grammatical errors. critiquesare based on measurements the hierarchical structure descriptions produced by the parser, letting us detect a variety of stylistic characteristics judged by &amp;quot;experts&amp;quot; to be undesirable: too great a distance between subject and verb, too much embedding, unbalanced subject/predicate size, excessive negation or quantification, etc. The text corpus used for system construction and testing is a set of some 400 business letters, mostly written by individuals from within various individuals outside those organletters, which consist of approximately 2300 sentences, were selected from a larger (about as being representative of the wide variety of styles, tones, subject matter, purposes, lengths, factual content, organization-type found overall population of business letters. A corpus differing in so many of the above features is also heterogeneous respect to syntactic structures -and therefore with respect to the grammatical capabilities that must be incorporated for correct recognition. However, it was one thing to be prepared for structural diversity; it was quite another thing to be faced with the fact that our business letters are not some small to moderate subset of grammatical Rather, they all of the common and most of the arcane constructions one could find say, Warriner and (6). For example, the very first sentence we tackled was 29 words long and began &amp;quot;How nice it was to receive your letter complimenting our Manager, Bud Handy, on his courtesy ...&amp;quot;: we ran into extraposition, inversion, infinitive nominalization, gerund phrase, and appositive all within the first 13 words! A primary consequence of this rich jumble of syntactic scree was the frequent annoyance of being stopped dead in our processing tracks as our grammar revealed itself to be yet once more incomplete. But it was not only the incompleteness of the grammar (for correct sentences) that gave us trouble: many words were not recognized, sometimes sentences were incomplete, other times they were truly ungrammatical (via normal abnormalities of grammar or via what appeared to be a rather thoughtless -or at least uninformed -scattering of apostrophes and semicolons within the text) and often we were not with our desired singleparse but with many. These then are the situations which cried out for techniques either to keep processing going or, at least, to keep it alive long enough for it to scratch out detailed informative guesses at structure on the parsing floor before expiring. The techniques for hardiness and robustness which we have developed in the two years of implementation, and particularly recently, are mostly specific to the five trouble situations referred to For (i) words(words not in our 125K entry on-line dictionary) we check first either for initial capitalization or for an internal hyphen, presuming a proper name -noun -part of speech for the former and either noun or adjective for the latter. As we improve our dictionary processing, to support efficient affix-stripping and stem storage, we now plan to hypothesize parts of speech based upon, in particular, the outer pretty conclusively establishes multi-syllabic words as adverbs). This more &amp;quot;intelligent&amp;quot; processing at the part-of-speech level is particularly important for avoiding multiple false parses. 167 the two situations of either (ii) an grammarfailing to process a complete grammatical or (iii) an actual sentence (sentence fragment), we are no able to output a single &amp;quot;best&amp;quot; structural description when the grammar can do no more&apos; (Jensen and Heidorn, forthcoming). This partial structure is &amp;quot;best&amp;quot; in the sense that it provides the largest and most continuous coverage of the input text string, and it also adheres to certain orderings of parts of speech and non-terminal constituents. Our experience with such structures is that they are quite often correct, always better than a &amp;quot;CANNOT PARSE&amp;quot; outcome, and appear to be fairly usable for style critiquing. In the future we believe more can be done with sentence fragments by assuming, first, they are simply to be conjoined to some element of the previous sentence, or, second, they are an elaboration of an immediately preceding element; in either case the partial structure output should provide sufficient information to &amp;quot;hook&amp;quot; the fragments in correctly. (iv) truly sentences,as mentioned previously, we introduce a second pass with a number of grammatical restrictions relaxed; should any complete sentence structure result we can determine which relaxations were responsible and thereby actually identify the class of ungrammaticality. From the point of view of useful applications, this is much more of a desirable user-oriented function than an internal robust recovery procedure. Nonetheless, from the point of view of the style critiques at the sentence and paragraph levels, this procedure assures the best possible starting point, despite &amp;quot;noise&amp;quot; in the input text. (v) the situation of parsesis dealt with by two techniques. The first is the deliberate attempt to construct the grammar rules such that no more than a single parse can squeeze through in most situations; the second is the development of a metric which computes a real number for each parse, based on its structural features, with the decision rule simply being to choose the parse with the smallest number (7). Our experience with this metric is that it usually leads to selection of the best all-around parse; such errors as are made would seem to require semantic -and even pragmatic -information to be weighed in the metric, a capability presently beyond our means. REFERENCES 1. Miller, Lance A. &amp;quot;Project EPISTLE: A system for the automatic analysis of business correspondof the Annual</abstract>
<affiliation confidence="0.734522">Conference Intelligence,Stanford University, August,</affiliation>
<address confidence="0.948295">1980, 280-282.</address>
<note confidence="0.83634375">2. Miller, Lance A., George E. Heidorn, and Karen Jensen &amp;quot;Text-Critiquing with the EPISTLE System: An Author&apos;s Aid to Better Syntax.&amp;quot; AFIPS Proceedings of the National Computer Conference,Chicago, May 4-7, 1981, 649-655. 3. Heidorn, George E., Karen Jensen, Lance A. Miller, Roy J. Byrd, and Martin S. Chodorow &amp;quot;The Text-Critiquing System.&amp;quot; Systems Journal,to appear Fall, 1982. 4. Jensen, Karen &amp;quot;Computer Generation of Topic Paragraphs: Structure and Style&amp;quot;. Paper presented at the ACL Session of LSA Annual New York City, December, 1981 Research Report, 1982). 5. Heidorn, George E. &amp;quot;Augmented Phrase Structure Grammars&amp;quot;. In B. Nash-Webber and R. Schenk Issues in Natural Language Processing,Association for Computational Linguistics, 1975. Warriner, J. E. and F. Griffith Grammar Composition.New York: Harcourt, Brace and World, Inc., 1963. 7. Heidorn, George E. &amp;quot;Experience with an easily computed metric for ranking alternative</note>
<author confidence="0.722088">parses Presentation at the Association for</author>
<affiliation confidence="0.881958">Computational Linguistics Meeting, Toronto,</affiliation>
<address confidence="0.925368">Canada, June 17, 1982.</address>
<intro confidence="0.549429">168</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lance A Miller</author>
</authors>
<title>Project EPISTLE: A system for the automatic analysis of business correspondence.&amp;quot;</title>
<date>1980</date>
<booktitle>Proceedings of the First Annual National Conference on Artificial Intelligence,</booktitle>
<pages>280--282</pages>
<institution>Stanford University,</institution>
<marker>1.</marker>
<rawString>Miller, Lance A. &amp;quot;Project EPISTLE: A system for the automatic analysis of business correspondence.&amp;quot; Proceedings of the First Annual National Conference on Artificial Intelligence, Stanford University, August, 1980, 280-282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Miller</author>
<author>George E Heidorn</author>
<author>Karen Jensen</author>
</authors>
<title>Text-Critiquing with the EPISTLE System: An Author&apos;s Aid to Better Syntax.&amp;quot;</title>
<date>1981</date>
<booktitle>AFIPS Proceedings of the National Computer Conference,</booktitle>
<pages>649--655</pages>
<location>Chicago,</location>
<marker>2.</marker>
<rawString>Miller, Lance A., George E. Heidorn, and Karen Jensen &amp;quot;Text-Critiquing with the EPISTLE System: An Author&apos;s Aid to Better Syntax.&amp;quot; AFIPS Proceedings of the National Computer Conference, Chicago, May 4-7, 1981, 649-655.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Heidorn</author>
<author>Karen Jensen</author>
<author>Lance A Miller</author>
<author>Roy J Byrd</author>
<author>S Martin</author>
</authors>
<title>Chodorow &amp;quot;The EPISTLE Text-Critiquing System.&amp;quot; IBM Systems Journal, to appear Fall,</title>
<date>1982</date>
<marker>3.</marker>
<rawString>Heidorn, George E., Karen Jensen, Lance A. Miller, Roy J. Byrd, and Martin S. Chodorow &amp;quot;The EPISTLE Text-Critiquing System.&amp;quot; IBM Systems Journal, to appear Fall, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Jensen</author>
</authors>
<title>Computer Generation of Topic Paragraphs: Structure and Style&amp;quot;. Paper presented at the ACL Session of LSA Annual Meeting,</title>
<date>1981</date>
<location>New York City,</location>
<note>IBM Research Report,</note>
<marker>4.</marker>
<rawString>Jensen, Karen &amp;quot;Computer Generation of Topic Paragraphs: Structure and Style&amp;quot;. Paper presented at the ACL Session of LSA Annual Meeting, New York City, December, 1981 (IBM Research Report, 1982).</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Heidorn</author>
</authors>
<title>Augmented Phrase Structure Grammars&amp;quot;. In</title>
<date>1975</date>
<booktitle>Theoretical Issues in Natural Language Processing, Association for Computational Linguistics,</booktitle>
<contexts>
<context position="837" citStr="(5)" startWordPosition="127" endWordPosition="127">m is being developed in a research project for exploring the feasibility of a variety of intelligent applications for the processing of business and office text (1-3; the authors of 3 are the project workers). Although ultimately intended functions include text generation (e.g., 4), present efforts focus on text analysis: developing the capability to take in essentially unconstrained business text and to output grammar and style critiques, on a sentence by sentence basis. Briefly, we use a large on-line dictionary and a bottom-up parser in connection with an Augmented Phrase Structure Grammar (5) to obtain an approximately correct structural description of the surface text (e.g., we posit no transformations or recovery of deleted material to infer underlying &amp;quot;deep&amp;quot; structures). In this process we always try to force a single parse output, even in the presence of true ambiguity. Grammatical critiques are provided by having very strong grammar restrictions in an initial processing of the sentence; should the application of grammar rules fail to lead to the identification of a complete, syntactically correct, sentence, we then process the material a second time, adding other rules which </context>
</contexts>
<marker>5.</marker>
<rawString>Heidorn, George E. &amp;quot;Augmented Phrase Structure Grammars&amp;quot;. In B. Nash-Webber and R. Schenk (Eds.), Theoretical Issues in Natural Language Processing, Association for Computational Linguistics, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Warriner</author>
<author>F Griffith</author>
</authors>
<title>English Grammar and Composition.</title>
<date>1963</date>
<publisher>Harcourt, Brace and World, Inc.,</publisher>
<location>New York:</location>
<contexts>
<context position="3034" citStr="(6)" startWordPosition="465" endWordPosition="465">the overall population of business letters. A corpus differing in so many of the above features is also heterogeneous with respect to syntactic structures -- and therefore with respect to the grammatical capabilities that must be incorporated for correct recognition. However, it was one thing to be prepared for structural diversity; it was quite another thing to be faced with the fact that our business letters are not some small to moderate subset of grammatical phenomena. Rather, they include all of the common and most of the arcane constructions one could find in, say, Warriner and Griffith (6). For example, the very first sentence we tackled was 29 words long and began &amp;quot;How nice it was to receive your letter complimenting our Manager, Bud Handy, on his courtesy ...&amp;quot;: we ran into extraposition, inversion, infinitive nominalization, gerund phrase, and appositive all within the first 13 words! A primary consequence of this rich jumble of syntactic scree was the frequent annoyance of being stopped dead in our processing tracks as our grammar revealed itself to be yet once more incomplete. But it was not only the incompleteness of the grammar (for correct sentences) that gave us trouble</context>
</contexts>
<marker>6.</marker>
<rawString>Warriner, J. E. and F. Griffith English Grammar and Composition. New York: Harcourt, Brace and World, Inc., 1963.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Heidorn</author>
</authors>
<title>Experience with an easily computed metric for ranking alternative parses&amp;quot;. Presentation at the Association for Computational Linguistics Meeting,</title>
<date>1982</date>
<location>Toronto, Canada,</location>
<marker>7.</marker>
<rawString>Heidorn, George E. &amp;quot;Experience with an easily computed metric for ranking alternative parses&amp;quot;. Presentation at the Association for Computational Linguistics Meeting, Toronto, Canada, June 17, 1982.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>