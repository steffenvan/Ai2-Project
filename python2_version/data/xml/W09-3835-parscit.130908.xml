<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000393">
<title confidence="0.992607">
Interactive Predictive Parsing 1
</title>
<author confidence="0.7948835">
Ricardo S´anchez-S´aez, Joan-Andreu S´anchez and Jos´e-Miguel BenediInstituto Tecnol´ogico de Inform´atica
Universidad Polit´ecnica de Valencia
</author>
<affiliation confidence="0.324661">
Camide Vera s/n, Valencia 46022 (Spain)
</affiliation>
<email confidence="0.575997">
{rsanchez, jandreu, jbenedi}dsic.upv.es
</email>
<sectionHeader confidence="0.995828" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982076923077">
This paper introduces a formal framework
that presents a novel Interactive Predic-
tive Parsing schema which can be oper-
ated by a user, tightly integrated into the
system, to obtain error free trees. This
compares to the classical two-step schema
of manually post-editing the erroneus con-
stituents produced by the parsing system.
We have simulated interaction and cal-
culated evalaution metrics, which estab-
lished that an IPP system results in a high
amount of effort reduction for a manual
annotator compared to a two-step system.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999874">
The aim of parsing is to obtain the linguistic in-
terpretation of sentences, that is, their underlying
syntactic structure. This task is one of the fun-
damental pieces needed by a computer to uns-
derstand language as used by humans, and has
many applications in Natural Language Process-
ing (Lease et al., 2006).
A wide array of parsing methods exist, in-
cluding those based on Probabilistic Context-Free
Grammars (PCFGs). (Charniak, 2000; Collins,
2003; Johnson, 1998; Klein and Manning, 2003;
Matsuzaki et al., 2005; Petrov and Klein, 2007).
The most impressive results are achieved by sub-
tree reranking systems, as shown in the semi-
supervised method of (McClosky et al., 2006),
or the forest reranking approximation of (Huang,
2008) in which packed parse forests (compact
structures that contain many possible tree deriva-
tions) are used.
These state-of-the-art parsers provide trees of
excelent quality. However, perfect results are vir-
</bodyText>
<footnote confidence="0.80922275">
1Work supported by the MIPRCV “Consolider Inge-
nio 2010” (CSD2007-00018), iTransDoc (TIN2006-15694-
CO2-01) and Prometeo (PROMETEO/2009/014) reserach
projects, and the FPU fellowship AP2006-01363.
</footnote>
<bodyText confidence="0.996092944444445">
tually never achieved. If the need of one-hundred-
percent error free trees arises, the supervision of a
user that post-edits and corrects the errors is un-
avoidable.
Error free trees are needed in many tasks such as
handwritten mathematical expressions recognition
(Yamamoto et al., 2006), or creation of new gold
standard treebanks (Delaclergerie et al., 2008)).
For example, in the creation of the Penn Tree-
bank grammar, a basic two-stage setup was em-
ployed: a rudimentary parsing system providad a
skeletal syntactic representation, which then was
manually corrected by human annotators (Marcus
et al., 1993).
In this paper, we introduce a new formal frame-
work that tightly integrates the user within the
parsing system itself, rather than keeping him iso-
lated from the automatic tools used in a classi-
cal two-step approach. This approach introduces
the user into the parsing system, and we will call
it “interactive predictive parsing”, or simply IPP.
An IPP system is interactive because the user is in
continuous contact with the parsing process, send-
ing and receiving feedback. An IPP system is also
predictive because it reacts to the user corrections:
it predicts and suggest new parse trees taking into
account the new gold knowledge received from
the user. Interactive predictive methods have been
studied and successfully used in fields like Auto-
matic Text Recognition (Toselli et al., 2008) and
Statistical Machine Translation (Barrachina et al.,
2009; Vidal et al., 2006) to ease the work of tran-
scriptor and translators.
Assessment of the amount of effort saved by the
IPP system will be measured by automatically cal-
culated metrics.
</bodyText>
<sectionHeader confidence="0.997061" genericHeader="method">
2 Interactive Predictive Parsing
</sectionHeader>
<bodyText confidence="0.998606">
A tree t, associated to a string xilxl, is composed
by substructures that are usually referred as con-
stituents or edges. A constituent cAij is a span de-
</bodyText>
<page confidence="0.963096">
222
</page>
<bodyText confidence="0.94223425">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 222–225,
Paris, October 2009. c�2009 Association for Computational Linguistics
fined by a nonterminal symbol (or syntactic tag) A
that covers the substring xij.
Assume that using a given probabilistic context-
free grammar G as the model, the parser analyzes
the input sentence x = x1 ... x|x |and produces
the parse tree tˆ
</bodyText>
<equation confidence="0.992839">
tˆ = arg max
tET
</equation>
<bodyText confidence="0.999933823529412">
where pG(tlx) is the probability of parse tree t
given the input string x using model G, and T is
the set of all possible parse trees for x.
In an interactive predictive scenario, after ob-
taining the (probably incorrect) best tree ˆt, the user
is able to modify the edges cAij that are incorrect.
The system reacts to each of the corrections intro-
duced by the human by proposing a new ˆt′ that
takes into account the corrected edge. The order
in which incorrect constituents are reviewed deter-
mines the amount of effort reduction given by the
degree of correctness of the subsequent proposed
trees.
There exist several ways in which a human ana-
lyzes a sentende. A top-to-bottom may be consid-
ered natural way of proceeding, and we follow this
approach in this work. This way, when a higher
level constituent is corrected, possible erroneous
constituents at lower levels are expectedly auto-
matically recalculated.
The introduced IPP interaction process is sim-
ilar to the ones already established in Computer-
Assisted Text Recognition and Computer-Assisted
Translation 1.
Within the IPP framework, the user reviews the
constituents contained in the tree to assess their
correctness. When the user find an incorrect edge
he modifies it, setting the correct label and span.
This action implicitly validates a subtree that is
composed by the corrected edge plus all its ances-
tor edges, which we will call the validated prefix
tree tp. When the user replaces the constituent cA ij
with the correct one c′Aij , the validated prefix tree
is:
</bodyText>
<equation confidence="0.9047416">
tp(c′A
ij ) = lcBmn : m G i, n &gt;
j (2)
d(cBmn) &gt; d(c′A
ij )�
</equation>
<bodyText confidence="0.981019888888889">
with d(cDpq) being the depth of constituent cD pq.
1In these fields, the user reads the sentence from left to
right. When the user finds and corrects an erroneus word, he
is implicitly validating the prefix sentence up to that word.
The remaining suffix sentence is recalculated by the system
taking into account the validated prefix sentece.
When a constituent correction is performed, the
prefix tree tp(c′Aij ) is fixed and a new tree ˆt′ that
takes into account the prefix is proposed
</bodyText>
<equation confidence="0.933663">
pG(t�x, tp(c′A
ij )). (3)
</equation>
<bodyText confidence="0.999259166666667">
Given that we are working with context-free
grammars, the only subtree that effectively needs
to be recalcuted is the one starting from the par-
ent of the corrected edge. Let the corrected edge
be c′A ijand its parent cDst, then the following tree is
proposed
</bodyText>
<equation confidence="0.991882666666667">
ˆt′ = arg max D
tET pG(t�x, tp) = (ˆt � ˆtDst) U t′st , (4)
with
D pG(tDst mn, c′Aij ) . (5)
t′st = arg max
tDstETst
</equation>
<bodyText confidence="0.966846323529412">
Expression (4) represents the newly proposed
tree ˆt′, which consists of original proposed tree
tˆ minus the subpart of the original proposed tree
ˆtDst (whose root is the parent of the corrected edge
cD) plus the newly calculated subtree
st
root is also the parent of the corrected constituent
cD, but also takes into account the corrected one
st
as shown in Expression (5)).
In Figure 1 we show an example that intends to
clarify the interactive predictive process. First, the
system provides a proposed parse tree (Fig. 1.a).
Then the user, which has in his mind the correct
reference tree, notices that it has two wrong con-
stituents (cX23 and cZ44) (Fig. 1.b), and choses to re-
place cX23 by cB22 (Fig. 1.c). Here, cB22 corresponds
to c′A ijfrom expressions (3) and (5).
As the user does this correction, the system au-
tomatically validates the correct prefix: all the an-
cestors of the modified constituent (dashed line in
the figure, tp(c′Aij ) from expression (2)). The sys-
tem also invalidates the subtrees related to the cor-
rected constituent (dotted line line in the figure,
from expression (4)).
Finally, the system automatically predicts a new
subtree (ˆt′D st from expression (4)) (Fig. 1.d). No-
tice how cZ34 changes its span and c4D4 is introduced
which provides the correct reference parse.
Within the example shown in Figure 1, the user
would obtain the gold tree with just one correction,
rather than the three operations needed on a two-
step system (one deletion, one substitution and one
insertion).
</bodyText>
<equation confidence="0.849777285714286">
pG(tIx), (1)
ˆt′ = arg max
tET
D
t′st (whose
ˆtD
st
</equation>
<page confidence="0.881603">
223
</page>
<figure confidence="0.980141232558139">
A
S
Y
B Z
C D
a b c d
S
A
X
B
a b c d
A
S
B
Y
2 7
2
7 7
a b c d
S
Y
A
a
B
3
Z
4
C D
b
c d
Y
Z
C
2 4
X 3 Z 4
B C
a b c d
A
S
Y
(a) Reference tree (b) Iteration 0: (c) Iteration 0: Er- (d) Iteration 1: (e) Iteration 1:
Proposed out- roneus constituents User corrected Proposed output
put tree 1 constituent tree 2
</figure>
<figureCaption confidence="0.999954">
Figure 1: Synthetic example of user interaction with the IPP system.
</figureCaption>
<sectionHeader confidence="0.997643" genericHeader="method">
3 IPP Evaluation
</sectionHeader>
<bodyText confidence="0.999994814814815">
The objective of the experimentation presented
here is to evaluate the amount of effort saved for
the user using the IPP system, compared to the ef-
fort required to manually correct the trees without
the use of an interactive system. In this section, we
define a standard automatic evaluation protocol,
akin to the ones used in Computer-Aided Trans-
lation and Computer Aided Text Recognition.
In the absence of testing of an interactive sys-
tem with real users, the gold reference trees were
used to simulate system interaction by a human
corrector. In order to do this, the constituents in
the proposed tree were automatically reviewed in a
preorder manner 2. In each step, the constituent in
the proposed tree was compared to the correspond-
ing one in the reference tree: if the constituent was
equivalent no action was taken. When one incor-
rect constituent was found in the proposed tree, it
was replaced by the correct one from the reference
tree. This precise step simulated what a human su-
pervisor would do, that is, to type the correct con-
stituent in place of the erroneus one.
The system then performed the predictive step
(i.e. recalculation of subtrees related to the cor-
rected constituent). We kept a correction count,
which was incremented by one after each predic-
tive step.
</bodyText>
<subsectionHeader confidence="0.997597">
3.1 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.915782666666667">
For evaluation, first we report a metric represent-
ing the amount of human correcting work needed
to obtain the gold tree in a classical two-step pro-
cess (i.e. the number of operations needed to post-
edit the proposed tree in orther to obtain the gold
2Interaction in this ordered manner guaranteed that the
evaluation protocol only needed to modify the label A and
the end point j of a given edge c, while i remained valid
given the modifications of previous constituents.
one). We then compare this value to a metric that
measures the amount of effort needed to obtain
the gold tree with the human interacting within the
presented IPP system.
Parsing quality is generally assessed by the clas-
sical evaluation metrics, precission, recall and F-
measure. We defined the following metric that
measures the amount of effort needed in order to
post-edit a proposed tree and obtain the gold ref-
erence parse tree, akin to the Word Error Rate
used in Statistical Machine Translation and related
fields:
</bodyText>
<listItem confidence="0.937613142857143">
• Tree Constituent Error Rate (TCER): Min-
imum number of constituent substitution,
deletion and insertion operations needed to
convert the proposed parse tree into the corre-
sponding gold reference tree, divided by the
total number of constituents in the reference
tree 3.
</listItem>
<bodyText confidence="0.99965875">
The TCER is in fact strongly related to the F-
measure: the higher the F-measure is, the lower
TCER will be.
Finally, the relevant evaluation metric that as-
sessed the IPP system performance represents the
amount effort that the operator would have to
spend using the system in order to obtain the gold
tree, and is directly comparable to the TCER:
</bodyText>
<listItem confidence="0.846944666666667">
• Tree Constituent Action Rate (TCAC): Num-
ber of constituent corrections performed us-
ing the IPP system to obtain the reference
</listItem>
<bodyText confidence="0.9557345">
tree, divided by the total number of con-
stituents in the reference tree.
</bodyText>
<sectionHeader confidence="0.994707" genericHeader="evaluation">
4 Experimental results
</sectionHeader>
<bodyText confidence="0.985264">
An IPP system was implemented over the classical
CYK-Viterbi algorithm. Experimentation was run
</bodyText>
<footnote confidence="0.998798">
3Edit distance is calcualted over the ordered set of tree
constituents. This is an approximation of the edit distance
between trees.
</footnote>
<page confidence="0.997791">
224
</page>
<bodyText confidence="0.9996101">
over the Penn Tree bank: sections 2 to 21 were
used to obtain a vanilla Penn Treebank Grammar;
test set was the whole section 23.
We obtained several binarized versions of the
train grammar for use with the CYK. The Chom-
sky Normal Form (CNF) transformation method
from the NLTK4 was used to obtain several right-
factored binary grammars of different sizes 5.
A basic schema was introduced for parsing sen-
tences with out-of-vocabulary words: when an
input word could not be derived by any of the
preterminals in the vanilla treebank grammar, a
very small probability for that word was uniformly
added to all of the preterminals.
Results for the metrics discussed on section 3.1
for different markovizations of the train grammar
can be seen in Table 1. We observe that the perc-
etage of corrections needed using the IPP system
is much lower than the rate of needed corrections
just post-editing the proposed trees: from 42% to
46% in effort reduction by the human supervisor.
These results clearly show that an interactive
predictive system can relieve manual annotators of
a lot of burden in their task.
Note that the presented experiments were done
using parsing models that perform far from the lat-
est F1 results; their intention was to assess the util-
ity of the IPP schema. Expected relative reduc-
tions with IPP systems incorporating state-of-the-
art parsers would not be so large.
</bodyText>
<table confidence="0.998108">
PCFG Baseline IPP RelRed
F1 TCER TCAC
h=0, v=1 0.67 0.40 0.22 45%
h=0, v=2 0.68 0.39 0.21 46%
h=0, v=3 0.70 0.38 0.22 42%
</table>
<tableCaption confidence="0.781347333333333">
Table 1: Results for the test set: F1 and TCER
for the baseline system; TCAC for the IPP system;
relative reduction beteween TCER and TCAC.
</tableCaption>
<sectionHeader confidence="0.999363" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999947">
We have introduced a novel Interactive Predictive
Parsing framewrok which can be operated by a
user to obtain error free trees. We have simulated
interaction with this system and calculated evalau-
tion metrics, which established that an IPP system
results in a high amount of effort reduction for a
manual annotator compared to a two-step system.
</bodyText>
<footnote confidence="0.937067333333333">
4http://nltk.sourceforge.net/
5This method implements the vertical (v value) and hori-
zontal (h value) markovizations (Klein and Manning, 2003).
</footnote>
<bodyText confidence="0.99415075">
Near term future work includes applying the
IPP scenario to state-of-the-art reranking and pars-
ing systems, as well as in the development of adap-
tative parsing systems
</bodyText>
<sectionHeader confidence="0.996089" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999685038461539">
Barrachina, Sergio, Oliver Bender, Francisco Casacu-
berta, Jorge Civera, Elsa Cubel, Shahram Khadivi,
Antonio Lagarda, Hermann Ney, Jess Toms, En-
rique Vidal, Juan-Miguel Vilar. 2009. Statistical ap-
proaches to computer-assisted translation. In Com-
putational Linguistics, 35(1) 3-28.
Charniak, Eugene. 2000. A maximum-entropy-
inspired parser. In NAACL ’00, 132-139.
Collins, Michael. 2003. Head-driven statistical mod-
els for natural language parsing. In Computational
Linguistics, 29(4):589-637.
De la Clergerie, ´Eric, Olivier Hamon, Djamel Mostefa,
Christelle Ayache, Patrick Paroubek and Anne Vil-
nat. 2008. PASSAGE: from French Parser Evalua-
tion to Large Sized Treebank. In LREC’08.
Huang, Liang. 2008. Forest reranking: discriminative
parsing with non-localfeatures. In ACL ’08.
Johnson, Mark. 1998. PCFG models of linguistic
tree representation. In Computational Linguistics,
24:613-632.
Klein, Dan and Chistopher D. Manning. 2003. Accu-
rate Unlexicalized Parsing. In ACL ’03, 423-430.
Lease, Matthew, Eugene Charniak, Mark Johnson and
David McClosky. 2006. A look at parsing and its
applications. In National Conference on Artificial
Intelligence, vol. 21-II, 1642-1645.
Marcus, Mitchell P., Mary Ann Marcinkiewicz and
Beatrice Santorini. 1995. Building a Large Anno-
tated Corpus of English: The Penn Treebank. Com-
putational Linguistics 19(2), 313-330.
Matsuzaki, Takuya, Yasuke Miyao and Jun’ichi Tsujii.
2005. Probabilistic CFG with latent annotations. In
ACL ’05, 75-82.
McClosky, David, Eugene Charniak and Mark John-
son. 2006. Effective self-training for parsing. In
HLT-NAACL ’06
Petrov, Slav and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In NAACL-HLT ’07.
Toselli, Alejandro, Ver´onica Romero and Enrique Vi-
dal. 2008. Computer Assisted Transcription of Text
Images and Multimodal Interaction. In MLMI ’08.
Vidal, Enrique, Francisco Casacuberta, Luis Ro-
driguez, Jorge Civera and Carlos D. Martnez Hinare-
jos. 2006. Computer-assisted translation using
speech recognition. In IEEE Trans. on Audio,
Speech, and Language Processing, 14(3), 941-951.
Yamamoto, Ryo, Shinji Sako, Takuya Nishimoto and
Shigeki Sagayama. 2006. On-line recognition
of handwritten mathematical expressions based on
stroke-based stochastic context-free grammar. In
10th International Workshop on Frontiers in Hand-
writing Recognition.
</reference>
<page confidence="0.998806">
225
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.278293">
<title confidence="0.996327">Predictive Parsing</title>
<author confidence="0.331283">Joan-Andreu S´anchez S´anchez-S´aez</author>
<author confidence="0.331283">Jos´e-Miguel Tecnol´ogico de_Inform´atica</author>
<affiliation confidence="0.648576">Universidad Polit´ecnica de</affiliation>
<address confidence="0.667107">Camide Vera s/n, Valencia 46022 (Spain)</address>
<email confidence="0.996477">jandreu,</email>
<abstract confidence="0.9995005">This paper introduces a formal framework that presents a novel Interactive Predictive Parsing schema which can be operated by a user, tightly integrated into the system, to obtain error free trees. This compares to the classical two-step schema of manually post-editing the erroneus constituents produced by the parsing system. We have simulated interaction and calculated evalaution metrics, which established that an IPP system results in a high amount of effort reduction for a manual annotator compared to a two-step system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sergio Barrachina</author>
<author>Oliver Bender</author>
</authors>
<title>Francisco Casacuberta, Jorge Civera, Elsa Cubel, Shahram Khadivi, Antonio Lagarda,</title>
<date>2009</date>
<journal>In Computational Linguistics,</journal>
<volume>35</volume>
<issue>1</issue>
<pages>3--28</pages>
<location>Hermann Ney, Jess Toms, Enrique Vidal, Juan-Miguel Vilar.</location>
<marker>Barrachina, Bender, 2009</marker>
<rawString>Barrachina, Sergio, Oliver Bender, Francisco Casacuberta, Jorge Civera, Elsa Cubel, Shahram Khadivi, Antonio Lagarda, Hermann Ney, Jess Toms, Enrique Vidal, Juan-Miguel Vilar. 2009. Statistical approaches to computer-assisted translation. In Computational Linguistics, 35(1) 3-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropyinspired parser.</title>
<date>2000</date>
<journal>In NAACL</journal>
<volume>00</volume>
<pages>132--139</pages>
<contexts>
<context position="1243" citStr="Charniak, 2000" startWordPosition="184" endWordPosition="185">alculated evalaution metrics, which established that an IPP system results in a high amount of effort reduction for a manual annotator compared to a two-step system. 1 Introduction The aim of parsing is to obtain the linguistic interpretation of sentences, that is, their underlying syntactic structure. This task is one of the fundamental pieces needed by a computer to unsderstand language as used by humans, and has many applications in Natural Language Processing (Lease et al., 2006). A wide array of parsing methods exist, including those based on Probabilistic Context-Free Grammars (PCFGs). (Charniak, 2000; Collins, 2003; Johnson, 1998; Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov and Klein, 2007). The most impressive results are achieved by subtree reranking systems, as shown in the semisupervised method of (McClosky et al., 2006), or the forest reranking approximation of (Huang, 2008) in which packed parse forests (compact structures that contain many possible tree derivations) are used. These state-of-the-art parsers provide trees of excelent quality. However, perfect results are vir1Work supported by the MIPRCV “Consolider Ingenio 2010” (CSD2007-00018), iTransDoc (TIN2006-15694- </context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Charniak, Eugene. 2000. A maximum-entropyinspired parser. In NAACL ’00, 132-139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<booktitle>In Computational Linguistics,</booktitle>
<pages>29--4</pages>
<contexts>
<context position="1258" citStr="Collins, 2003" startWordPosition="186" endWordPosition="187">tion metrics, which established that an IPP system results in a high amount of effort reduction for a manual annotator compared to a two-step system. 1 Introduction The aim of parsing is to obtain the linguistic interpretation of sentences, that is, their underlying syntactic structure. This task is one of the fundamental pieces needed by a computer to unsderstand language as used by humans, and has many applications in Natural Language Processing (Lease et al., 2006). A wide array of parsing methods exist, including those based on Probabilistic Context-Free Grammars (PCFGs). (Charniak, 2000; Collins, 2003; Johnson, 1998; Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov and Klein, 2007). The most impressive results are achieved by subtree reranking systems, as shown in the semisupervised method of (McClosky et al., 2006), or the forest reranking approximation of (Huang, 2008) in which packed parse forests (compact structures that contain many possible tree derivations) are used. These state-of-the-art parsers provide trees of excelent quality. However, perfect results are vir1Work supported by the MIPRCV “Consolider Ingenio 2010” (CSD2007-00018), iTransDoc (TIN2006-15694- CO2-01) and Pro</context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>Collins, Michael. 2003. Head-driven statistical models for natural language parsing. In Computational Linguistics, 29(4):589-637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>De la Clergerie</author>
<author>Olivier Hamon ´Eric</author>
</authors>
<title>Djamel Mostefa, Christelle Ayache, Patrick Paroubek and Anne Vilnat.</title>
<date>2008</date>
<booktitle>In LREC’08.</booktitle>
<marker>Clergerie, ´Eric, 2008</marker>
<rawString>De la Clergerie, ´Eric, Olivier Hamon, Djamel Mostefa, Christelle Ayache, Patrick Paroubek and Anne Vilnat. 2008. PASSAGE: from French Parser Evaluation to Large Sized Treebank. In LREC’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
</authors>
<title>Forest reranking: discriminative parsing with non-localfeatures.</title>
<date>2008</date>
<booktitle>In ACL ’08.</booktitle>
<contexts>
<context position="1540" citStr="Huang, 2008" startWordPosition="231" endWordPosition="232">ure. This task is one of the fundamental pieces needed by a computer to unsderstand language as used by humans, and has many applications in Natural Language Processing (Lease et al., 2006). A wide array of parsing methods exist, including those based on Probabilistic Context-Free Grammars (PCFGs). (Charniak, 2000; Collins, 2003; Johnson, 1998; Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov and Klein, 2007). The most impressive results are achieved by subtree reranking systems, as shown in the semisupervised method of (McClosky et al., 2006), or the forest reranking approximation of (Huang, 2008) in which packed parse forests (compact structures that contain many possible tree derivations) are used. These state-of-the-art parsers provide trees of excelent quality. However, perfect results are vir1Work supported by the MIPRCV “Consolider Ingenio 2010” (CSD2007-00018), iTransDoc (TIN2006-15694- CO2-01) and Prometeo (PROMETEO/2009/014) reserach projects, and the FPU fellowship AP2006-01363. tually never achieved. If the need of one-hundredpercent error free trees arises, the supervision of a user that post-edits and corrects the errors is unavoidable. Error free trees are needed in many </context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>Huang, Liang. 2008. Forest reranking: discriminative parsing with non-localfeatures. In ACL ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>PCFG models of linguistic tree representation.</title>
<date>1998</date>
<booktitle>In Computational Linguistics,</booktitle>
<pages>24--613</pages>
<contexts>
<context position="1273" citStr="Johnson, 1998" startWordPosition="188" endWordPosition="189">hich established that an IPP system results in a high amount of effort reduction for a manual annotator compared to a two-step system. 1 Introduction The aim of parsing is to obtain the linguistic interpretation of sentences, that is, their underlying syntactic structure. This task is one of the fundamental pieces needed by a computer to unsderstand language as used by humans, and has many applications in Natural Language Processing (Lease et al., 2006). A wide array of parsing methods exist, including those based on Probabilistic Context-Free Grammars (PCFGs). (Charniak, 2000; Collins, 2003; Johnson, 1998; Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov and Klein, 2007). The most impressive results are achieved by subtree reranking systems, as shown in the semisupervised method of (McClosky et al., 2006), or the forest reranking approximation of (Huang, 2008) in which packed parse forests (compact structures that contain many possible tree derivations) are used. These state-of-the-art parsers provide trees of excelent quality. However, perfect results are vir1Work supported by the MIPRCV “Consolider Ingenio 2010” (CSD2007-00018), iTransDoc (TIN2006-15694- CO2-01) and Prometeo (PROMETEO</context>
</contexts>
<marker>Johnson, 1998</marker>
<rawString>Johnson, Mark. 1998. PCFG models of linguistic tree representation. In Computational Linguistics, 24:613-632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Chistopher D Manning</author>
</authors>
<title>Accurate Unlexicalized Parsing.</title>
<date>2003</date>
<booktitle>In ACL ’03,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="1298" citStr="Klein and Manning, 2003" startWordPosition="190" endWordPosition="193">d that an IPP system results in a high amount of effort reduction for a manual annotator compared to a two-step system. 1 Introduction The aim of parsing is to obtain the linguistic interpretation of sentences, that is, their underlying syntactic structure. This task is one of the fundamental pieces needed by a computer to unsderstand language as used by humans, and has many applications in Natural Language Processing (Lease et al., 2006). A wide array of parsing methods exist, including those based on Probabilistic Context-Free Grammars (PCFGs). (Charniak, 2000; Collins, 2003; Johnson, 1998; Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov and Klein, 2007). The most impressive results are achieved by subtree reranking systems, as shown in the semisupervised method of (McClosky et al., 2006), or the forest reranking approximation of (Huang, 2008) in which packed parse forests (compact structures that contain many possible tree derivations) are used. These state-of-the-art parsers provide trees of excelent quality. However, perfect results are vir1Work supported by the MIPRCV “Consolider Ingenio 2010” (CSD2007-00018), iTransDoc (TIN2006-15694- CO2-01) and Prometeo (PROMETEO/2009/014) reserach proje</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, Dan and Chistopher D. Manning. 2003. Accurate Unlexicalized Parsing. In ACL ’03, 423-430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Lease</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
<author>David McClosky</author>
</authors>
<title>A look at parsing and its applications.</title>
<date>2006</date>
<booktitle>In National Conference on Artificial Intelligence,</booktitle>
<volume>21</volume>
<pages>1642--1645</pages>
<contexts>
<context position="1117" citStr="Lease et al., 2006" startWordPosition="164" endWordPosition="167">-step schema of manually post-editing the erroneus constituents produced by the parsing system. We have simulated interaction and calculated evalaution metrics, which established that an IPP system results in a high amount of effort reduction for a manual annotator compared to a two-step system. 1 Introduction The aim of parsing is to obtain the linguistic interpretation of sentences, that is, their underlying syntactic structure. This task is one of the fundamental pieces needed by a computer to unsderstand language as used by humans, and has many applications in Natural Language Processing (Lease et al., 2006). A wide array of parsing methods exist, including those based on Probabilistic Context-Free Grammars (PCFGs). (Charniak, 2000; Collins, 2003; Johnson, 1998; Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov and Klein, 2007). The most impressive results are achieved by subtree reranking systems, as shown in the semisupervised method of (McClosky et al., 2006), or the forest reranking approximation of (Huang, 2008) in which packed parse forests (compact structures that contain many possible tree derivations) are used. These state-of-the-art parsers provide trees of excelent quality. Howev</context>
</contexts>
<marker>Lease, Charniak, Johnson, McClosky, 2006</marker>
<rawString>Lease, Matthew, Eugene Charniak, Mark Johnson and David McClosky. 2006. A look at parsing and its applications. In National Conference on Artificial Intelligence, vol. 21-II, 1642-1645.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank.</title>
<date>1995</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313--330</pages>
<marker>Marcus, Marcinkiewicz, Santorini, 1995</marker>
<rawString>Marcus, Mitchell P., Mary Ann Marcinkiewicz and Beatrice Santorini. 1995. Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics 19(2), 313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takuya Matsuzaki</author>
</authors>
<title>Yasuke Miyao and Jun’ichi Tsujii.</title>
<date>2005</date>
<booktitle>In ACL ’05,</booktitle>
<pages>75--82</pages>
<marker>Matsuzaki, 2005</marker>
<rawString>Matsuzaki, Takuya, Yasuke Miyao and Jun’ichi Tsujii. 2005. Probabilistic CFG with latent annotations. In ACL ’05, 75-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Effective self-training for parsing.</title>
<date>2006</date>
<booktitle>In HLT-NAACL ’06</booktitle>
<contexts>
<context position="1484" citStr="McClosky et al., 2006" startWordPosition="221" endWordPosition="224">pretation of sentences, that is, their underlying syntactic structure. This task is one of the fundamental pieces needed by a computer to unsderstand language as used by humans, and has many applications in Natural Language Processing (Lease et al., 2006). A wide array of parsing methods exist, including those based on Probabilistic Context-Free Grammars (PCFGs). (Charniak, 2000; Collins, 2003; Johnson, 1998; Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov and Klein, 2007). The most impressive results are achieved by subtree reranking systems, as shown in the semisupervised method of (McClosky et al., 2006), or the forest reranking approximation of (Huang, 2008) in which packed parse forests (compact structures that contain many possible tree derivations) are used. These state-of-the-art parsers provide trees of excelent quality. However, perfect results are vir1Work supported by the MIPRCV “Consolider Ingenio 2010” (CSD2007-00018), iTransDoc (TIN2006-15694- CO2-01) and Prometeo (PROMETEO/2009/014) reserach projects, and the FPU fellowship AP2006-01363. tually never achieved. If the need of one-hundredpercent error free trees arises, the supervision of a user that post-edits and corrects the err</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>McClosky, David, Eugene Charniak and Mark Johnson. 2006. Effective self-training for parsing. In HLT-NAACL ’06</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In NAACL-HLT ’07.</booktitle>
<contexts>
<context position="1347" citStr="Petrov and Klein, 2007" startWordPosition="198" endWordPosition="201">effort reduction for a manual annotator compared to a two-step system. 1 Introduction The aim of parsing is to obtain the linguistic interpretation of sentences, that is, their underlying syntactic structure. This task is one of the fundamental pieces needed by a computer to unsderstand language as used by humans, and has many applications in Natural Language Processing (Lease et al., 2006). A wide array of parsing methods exist, including those based on Probabilistic Context-Free Grammars (PCFGs). (Charniak, 2000; Collins, 2003; Johnson, 1998; Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov and Klein, 2007). The most impressive results are achieved by subtree reranking systems, as shown in the semisupervised method of (McClosky et al., 2006), or the forest reranking approximation of (Huang, 2008) in which packed parse forests (compact structures that contain many possible tree derivations) are used. These state-of-the-art parsers provide trees of excelent quality. However, perfect results are vir1Work supported by the MIPRCV “Consolider Ingenio 2010” (CSD2007-00018), iTransDoc (TIN2006-15694- CO2-01) and Prometeo (PROMETEO/2009/014) reserach projects, and the FPU fellowship AP2006-01363. tually </context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Petrov, Slav and Dan Klein. 2007. Improved inference for unlexicalized parsing. In NAACL-HLT ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alejandro Toselli</author>
<author>Ver´onica Romero</author>
<author>Enrique Vidal</author>
</authors>
<title>Computer Assisted Transcription of Text Images and Multimodal Interaction.</title>
<date>2008</date>
<booktitle>In MLMI ’08.</booktitle>
<contexts>
<context position="3341" citStr="Toselli et al., 2008" startWordPosition="505" endWordPosition="508"> tools used in a classical two-step approach. This approach introduces the user into the parsing system, and we will call it “interactive predictive parsing”, or simply IPP. An IPP system is interactive because the user is in continuous contact with the parsing process, sending and receiving feedback. An IPP system is also predictive because it reacts to the user corrections: it predicts and suggest new parse trees taking into account the new gold knowledge received from the user. Interactive predictive methods have been studied and successfully used in fields like Automatic Text Recognition (Toselli et al., 2008) and Statistical Machine Translation (Barrachina et al., 2009; Vidal et al., 2006) to ease the work of transcriptor and translators. Assessment of the amount of effort saved by the IPP system will be measured by automatically calculated metrics. 2 Interactive Predictive Parsing A tree t, associated to a string xilxl, is composed by substructures that are usually referred as constituents or edges. A constituent cAij is a span de222 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 222–225, Paris, October 2009. c�2009 Association for Computational Linguistics</context>
</contexts>
<marker>Toselli, Romero, Vidal, 2008</marker>
<rawString>Toselli, Alejandro, Ver´onica Romero and Enrique Vidal. 2008. Computer Assisted Transcription of Text Images and Multimodal Interaction. In MLMI ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Enrique Vidal</author>
<author>Francisco Casacuberta</author>
<author>Luis Rodriguez</author>
<author>Jorge Civera</author>
<author>Carlos D Martnez Hinarejos</author>
</authors>
<title>Computer-assisted translation using speech recognition.</title>
<date>2006</date>
<booktitle>In IEEE Trans. on Audio, Speech, and Language Processing,</booktitle>
<volume>14</volume>
<issue>3</issue>
<pages>941--951</pages>
<contexts>
<context position="3423" citStr="Vidal et al., 2006" startWordPosition="517" endWordPosition="520"> the parsing system, and we will call it “interactive predictive parsing”, or simply IPP. An IPP system is interactive because the user is in continuous contact with the parsing process, sending and receiving feedback. An IPP system is also predictive because it reacts to the user corrections: it predicts and suggest new parse trees taking into account the new gold knowledge received from the user. Interactive predictive methods have been studied and successfully used in fields like Automatic Text Recognition (Toselli et al., 2008) and Statistical Machine Translation (Barrachina et al., 2009; Vidal et al., 2006) to ease the work of transcriptor and translators. Assessment of the amount of effort saved by the IPP system will be measured by automatically calculated metrics. 2 Interactive Predictive Parsing A tree t, associated to a string xilxl, is composed by substructures that are usually referred as constituents or edges. A constituent cAij is a span de222 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 222–225, Paris, October 2009. c�2009 Association for Computational Linguistics fined by a nonterminal symbol (or syntactic tag) A that covers the substring xij.</context>
</contexts>
<marker>Vidal, Casacuberta, Rodriguez, Civera, Hinarejos, 2006</marker>
<rawString>Vidal, Enrique, Francisco Casacuberta, Luis Rodriguez, Jorge Civera and Carlos D. Martnez Hinarejos. 2006. Computer-assisted translation using speech recognition. In IEEE Trans. on Audio, Speech, and Language Processing, 14(3), 941-951.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryo Yamamoto</author>
<author>Shinji Sako</author>
</authors>
<title>Takuya Nishimoto and Shigeki Sagayama.</title>
<date>2006</date>
<booktitle>In 10th International Workshop on Frontiers in Handwriting Recognition.</booktitle>
<marker>Yamamoto, Sako, 2006</marker>
<rawString>Yamamoto, Ryo, Shinji Sako, Takuya Nishimoto and Shigeki Sagayama. 2006. On-line recognition of handwritten mathematical expressions based on stroke-based stochastic context-free grammar. In 10th International Workshop on Frontiers in Handwriting Recognition.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>