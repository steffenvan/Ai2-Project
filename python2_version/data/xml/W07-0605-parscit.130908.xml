<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001176">
<title confidence="0.978673">
I will shoot your shopping down and you can shoot all my tins
Automatic Lexical Acquisition from the CHILDES Database
</title>
<author confidence="0.993175">
Paula Buttery and Anna Korhonen
</author>
<affiliation confidence="0.999737">
RCEAL, University of Cambridge
</affiliation>
<address confidence="0.927773">
9 West Road, Cambridge, CB3 9DB, UK
</address>
<email confidence="0.995267">
pjb48, alk23@cam.ac.uk
</email>
<sectionHeader confidence="0.995543" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999957222222222">
Empirical data regarding the syntactic com-
plexity of children’s speech is important for
theories of language acquisition. Currently
much of this data is absent in the annotated
versions of the CHILDES database. In this
perliminary study, we show that a state-of-
the-art subcategorization acquisition system of
Preiss et al. (2007) can be used to extract large-
scale subcategorization (frequency) informa-
tion from the (i) child and (ii) child-directed
speech within the CHILDES database without
any domain-specific tuning. We demonstrate
that the acquired information is sufficiently ac-
curate to confirm and extend previously re-
ported research findings. We also report quali-
tative results which can be used to further im-
prove parsing and lexical acquisition technol-
ogy for child language data in the future.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.972743727272727">
Large empirical data containing children’s speech are
the key to developing and evaluating different theo-
ries of child language acquisition (CLA). Particularly
important are data related to syntactic complexity of
child language since considerable evidence suggests
that syntactic information plays a central role during
language acquisition, e.g. (Lenneberg, 1967; Naigles,
1990; Fisher et al., 1994).
The standard corpus in the study of CLA is the
CHILDES database (MacWhinney, 2000)1 which pro-
vides 300MB of transcript data of interactions be-
</bodyText>
<footnote confidence="0.998803">
1See http://childes.psy.cmu.edu for details.
</footnote>
<page confidence="0.996264">
33
</page>
<bodyText confidence="0.999570441176471">
tween children and parents over 25 human languages.
CHILDES is currently available in raw, part-of-speech-
tagged and lemmatized formats. However, adequate
investigation of syntactic complexity requires deeper
annotations related to e.g. syntactic parses, subcatego-
rization frames (SCFs), lexical classes and predicate-
argument structures.
Although manual syntactic annotation is possible,
it is extremely costly. The alternative is to use natu-
ral language processing (NLP) techniques for annota-
tion. Automatic techniques are now viable, cost effec-
tive and, although not completely error-free, are suffi-
ciently accurate to yield annotations useful for linguis-
tic purposes. They also gather important qualitative
and quantitative information, which is difficult for hu-
mans to obtain, as a side-effect of the acquisition pro-
cess.
For instance, state-of-the-art statistical parsers,
e.g. (Charniak, 2000; Briscoe et al., 2006), have wide
coverage and yield grammatical representations capa-
ble of supporting various applications (e.g. summa-
rization, information extraction). In addition, lexi-
cal information (e.g. subcategorization, lexical classes)
can now be acquired automatically from parsed
data (McCarthy and Carroll, 2003; Schulte im Walde,
2006; Preiss et al., 2007). This information comple-
ments the basic grammatical analysis and provides ac-
cess to the underlying predicate-argument structure.
Containing considerable ellipsis and error, spoken
child language can be challenging for current NLP
techniques which are typically optimized for written
adult language. Yet Sagae et al. (2005) have recently
demonstrated that existing statistical parsing tech-
niques can be usefully modified to analyse CHILDES
</bodyText>
<note confidence="0.875977">
Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 33–40,
Prague, Czech Republic, June 2007 c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.971686208955224">
with promising accuracy. Although further improve- preferences but include some derived semi-predictable
ments are still required for optimal accuracy, this re- bounded dependency constructions, such as particle
search has opened up the exciting possibility of auto- and dative movement—this will be revised in future
matic grammatical annotation of the entire CHILDES versions of the SCF system.
database in the future. The system tokenizes, tags, lemmatizes and parses
However, no work has yet been conducted on au- input sentences using the recent (second) release of
tomatic acquisition of lexical information from child the RASP (Robust Accurate Statistical Parsing) system
speech. The only automatic lexical acquisition study (Briscoe et al., 2006) which parses arbitrary English
involving CHILDES that we are aware of is that of text with state-of-the-art levels of accuracy. SCFs are
Buttery and Korhonen (2005). The study involved extracted from the grammatical relations (GRs) output
extracting subcategorization information from (some of the parser using a rule-based classifier. This clas-
of) the adult (child-directed) speech in the database, sifier operates by exploiting the close correspondence
and showing that this information differs from that ex- between the dependency relationships which the GRs
tracted from the spoken part of the British National embody and the head-complement structure which
Corpus (BNC) (Burnard, 1995). subcategorization acquisition attempts to recover. Lex-
In this paper, we investigate whether state-of-the- ical entries of extracted SCFs are constructed for each
art subcategorization acquisition technology can be word in the corpus data. Finally, the entries may be
used—without any domain-specific tuning—to obtain optionally filtered to obtain a more accurate lexicon.
large-scale verb subcategorization frequency informa- This is done by setting empirically determined thresh-
tion from CHILDES which is accurate enough to show olds on the relative frequencies of SCFs.
differences and similarities between child and adult When evaluated on cross-domain corpora contain-
speech, and thus be able to provide support for syn- ing mainly adult language, this system achieves 68.9
tactic complexity studies in CLA. F-measure2 in detecting SCF types—a result which
We use the new system of Preiss et al. (2007) to compares favourably to those reported with other com-
extract SCF frequency data from the (i) child and parable SCF acquisition systems.
(ii) child-directed speech within CHILDES. We show
that the acquired information is sufficiently accu-
rate to confirm and extend previously reported SCF
(dis)similarities between the two types of data. In par-
ticular, we demonstrate that children and adults have
different preferences for certain types of verbs, and
that these preferences seem to influence the way chil-
dren acquire subcategorization. In addition, we report
qualitative results which can be used to further im-
prove parsing and lexical acquisition technology for
spoken child language data in the future.
2 Subcategorization Acquisition System
We used for subcategorization acquisition the new sys-
tem of Preiss, Briscoe and Korhonen (2007) which
is essentially a much improved and extended version
of Briscoe and Carroll’s (1997) system. It incorpo-
rates 168 SCF distinctions, a superset of those found
in the COMLEX Syntax (Grishman et al., 1994) and
ANLT (Boguraev et al., 1987) dictionaries. Currently,
SCFs abstract over specific lexically governed parti-
cles and prepositions and specific predicate selectional
34
3 Data
The English (British and American) sections of the
CHILDES database (MacWhinney, 2000) were used to
create two corpora: 1) CHILD and 2) CDS. Both cor-
pora contained c. 1 million utterances which were se-
lected from the data after some utterances contain-
ing un-transcribable sections were removed. Speak-
ers were identified using speaker-id codes within the
CHAT transcriptions of the data:3 CHILD contained
the utterances of speakers identified as target children;
CDS contained input from speakers identified as par-
ents/caretakers. The mean utterance length (measured
in words) in CHILD and CDS were 3.48 and 4.61, re-
spectively. The mean age of the child speaker in CHILD
is around 3 years 6 months.4
2See Section 4 for details ofF-measure.
3CHAT is the transcription and coding format used by all the
transcriptions within CHILDES.
4The complete age range is from 1 year and 1 month up to 7
years.
</bodyText>
<subsectionHeader confidence="0.999963">
3.1 Test Verbs and SCF Lexicons
</subsectionHeader>
<bodyText confidence="0.999964157894737">
We selected a set of 161 verbs for experimentation.
The words were selected at random, subject to the con-
straint that a sufficient number of SCFs would be ex-
tracted (&gt; 100) from both corpora to facilitate max-
imally useful comparisons. All sentences containing
an occurrence of one of the test verbs were extracted
from the two corpora and fed into the SCF acquisition
system described earlier in section 2.
In some of our experiments the two lexicons were
compared against the VALEX lexicon (Korhonen et al.,
2006)—a large subcategorization lexicon for English
which was acquired automatically from several cross-
domain corpora (containing both written and spoken
language). VALEX includes SCF and frequency infor-
mation for 6,397 English verbs. We employed the
most accurate version of the lexicon here (87.3 F-
measure)—this lexicon was obtained by selecting high
frequency SCFs and supplementing them with lower
frequency SCFs from manually built lexicons.
</bodyText>
<sectionHeader confidence="0.998175" genericHeader="method">
4 Analysis
</sectionHeader>
<subsectionHeader confidence="0.990273">
4.1 Methods for Analysis
</subsectionHeader>
<bodyText confidence="0.9918675">
The similarity between verb and SCF distributions in
the lexicons was examined. To maintain a robust anal-
ysis in the presence of noise, multiple similarity mea-
sures were used to compare the verb and SCF distri-
butions (Korhonen and Krymolowski, 2002). In the
following p = (pi) and q = (qi) where pi and qi are
the probabilities associated with SCFi in distributions
(lexicons) P and Q:
</bodyText>
<listItem confidence="0.92626025">
• Intersection (IS) - the intersection of non-zero probability
SCFs in p and q;
• Spearman rank correlation (RC) - lies in the range [1; 1], with
values near 0 denoting a low degree of association and val-
ues near -1 and 1 denoting strong association;
• Kullback-Leibler (KL) distance - a measure of the additional
information needed to describe p using q, KL is always &gt; 0
and = 0 only when p =_ q;
</listItem>
<bodyText confidence="0.999586125">
The SCFs distributions acquired from the corpora for
the chosen words were evaluated against: (i) a gold
standard SCF lexicon created by merging the SCFs in
the COMLEX and ANLT syntax dictionaries—this en-
abled us to determine the accuracy of the acquired
SCFs; (ii) another acquired SCF lexicon (as if it were
a gold standard)—this enabled us to determine simi-
larity of SCF types between two lexicons. In each case
</bodyText>
<table confidence="0.623424238095238">
Verb CHILD CDS
go 1 1
want 2 2
get 3 3
know 4 4
put 5 6
see 6 5
come 7 10
like 8 7
make 9 11
say 10 8
take 11 13
eat 12 14
play 13 15
need 14 16
look 15 12
fall 16 22
sit 17 21
think 18 9
break 19 27
give 20 17
</table>
<tableCaption confidence="0.7347005">
Table 1: Ranks of the 20 most frequent verbs in CHILD
and in CDS
</tableCaption>
<bodyText confidence="0.999510875">
we recorded the number of true positives (TPs), correct
SCFs, false positives (FPs), incorrect SCFs, and false
negatives (FNs), correct SCFs not in the gold standard.
Using these counts, we calculated type precision
(the percentage of SCF types in the acquired lexicon
which are correct), type recall (the percentage of SCF
types in the gold standard that are in the lexicon) and
F-measure:
</bodyText>
<equation confidence="0.664867333333333">
F
= 2 · precision · recall ( )
precision + recall 1
</equation>
<subsectionHeader confidence="0.995918">
4.2 Verb Analysis
</subsectionHeader>
<bodyText confidence="0.999943">
Before conducting the SCF comparisons we first com-
pared (i) our 161 test verbs and (ii) all the 1212
common verbs and their frequencies in CHILD and
CDS using the Spearman rank correlation (RC) and
the Kullback-Leibler distance (KL). The result was
a strong correlation between the 161 test verbs (RC =
0.920 + 0.0791, KL = 0.05) as well as between all the
1212 verbs (RC = 0.851 + 0.0287, KL = 0.07) in the
two corpora.
These figures suggest that the child-directed speech
(which is less diverse in general than speech between
adults, see e.g. the experiments of Buttery and Ko-
rhonen (2005)) contains a very similar distribution of
verbs to child speech. This is to be expected since the
</bodyText>
<page confidence="0.995944">
35
</page>
<bodyText confidence="0.999949088888889">
corpora essentially contain separate halves of the same
interactions.
However, our large-scale frequency data makes it
possible to investigate the cause for the apparently
small differences in the distributions. We did this by
examining the strength of correlation throughout the
ranking. We compared the ranks of the individual
verbs and discovered that the most frequent verbs in
the two corpora have indeed very similar ranks. Ta-
ble 1 lists the 20 most frequent verbs in CHILD (starting
from the highest ranked verb) and shows their ranks
in CDS. As illustrated in the table, the top 4 verbs
are identical in the two corpora (go, want, get, know)
while the top 15 are very similar (including many ac-
tion verbs e.g. put, look, sit, eat, and play).
Yet some of the lower ranked verbs turned out to
have large rank differences between the two corpora.
Two such relatively highly ranked verbs are included
in the table—think which has a notably higher rank
in CDS than in CHILD, and break which has a higher
rank in CHILD than in CDS. Many other similar cases
were found in particular among the medium and low
frequency verbs in the two corpora.
To obtain a better picture of this, we calculated for
each verb its rank difference between CHILD vs. CDS.
Table 2 lists 40 verbs with substantial rank differences
between the two corpora. The first column shows
verbs which have higher ranks in CHILD than in CDS,
and the second column shows verbs with higher ranks
in CDS than in CHILD. We can see e.g. that children
tend to prefer verbs such as shoot, die and kill while
adults prefer verbs such as remember, send and learn.
To investigate whether these differences in pref-
erences are random or motivated in some manner,
we classified the verbs with the largest differences
in ranks (&gt;10) into appropriate Levin-style lexical-
semantic classes (Levin, 1993) according to their pre-
dominant senses in the two corpora.5 We discovered
that the most frequent classes among the verbs that
children prefer are HIT (e.g. bump, hit, kick), BREAK
(e.g. crash, break, rip), HURT (e.g. hurt, burn, bite)
and MOTION (e.g. fly, jump, run) verbs. Overall, many
of the preferred verbs (regardless of the class) express
negative actions or feelings (e.g. shoot, die, scare,
hate).
</bodyText>
<footnote confidence="0.949572">
5This classification was done manually to obtain a reliable re-
sult.
</footnote>
<table confidence="0.999364181818182">
CHILD CDS
shoot tie remember hope
hate wish send suppose
die cut learn bet
write crash wipe kiss
use kick pay smell
bump scare feed guess
win step ask change
lock burn feel set
fight stand listen stand
jump care wait wonder
</table>
<tableCaption confidence="0.892002">
Table 2: 20 verbs ranked higher in (i) child speech and
(ii) child-directed speech.
</tableCaption>
<bodyText confidence="0.999464333333333">
In contrast, adults have a preference for verbs from
classes expressing cognitive processes (e.g. remember,
suppose, think, wonder, guess, believe, hope, learn) or
those that can be related to the education of children,
e.g. the WIPE verbs wash, wipe and brush and the PER-
FORMANCE verbs draw, dance and sing. In contrast to
children, adults prefer verbs which express positive ac-
tions and feelings (e.g. share, help, love, kiss).
It is commonly reported that child CLA is moti-
vated by a wish to communicate desires and emo-
tions, e.g. (Pinker, 1994), but a relative preference
in child speech over child-directed speech for certain
verb types or verbs expressing negative actions and
feelings has not been explicitly shown on such a scale
before. While this issue requires further investigation,
our findings already demonstrate the value of using
large scale corpora in producing novel data and hy-
potheses for research in CLA.
</bodyText>
<subsectionHeader confidence="0.96105">
4.3 SCF Analysis
4.3.1 Quantitative SCF Comparison
</subsectionHeader>
<bodyText confidence="0.9999545">
The average number of SCFs taken by studied verbs
in the two corpora proved quite similar. In unfil-
tered SCF distributions, verbs in CDS took on average
a larger number of SCFs (29) than those in CHILD (24),
but in the lexicons filtered for accuracy the numbers
were identical (8–10, depending on the filtering thresh-
old applied). The intersection between the CHILD /
CDS SCFs and those in the VALEX lexicon was around
0.5, indicating that the two lexicons included only
50% of the SCFs in the lexicon extracted from general
(cross-domain) adult language corpora. Recall against
VALEX was consequently low (between 48% and 68%
depending on the filtering threshold) but precision was
around 50-60% for both CHILDES and CDS lexicons
</bodyText>
<page confidence="0.983396">
36
</page>
<table confidence="0.999811285714286">
Measures Unfilt. Filt.
Precision (%) 82.9 88.7
Recall (%) 69.3 44.5
F-measure 75.5 59.2
IS 0.73 0.62
RC 0.69 0.72
KL 0.33 0.46
</table>
<tableCaption confidence="0.9934905">
Table 3: Average results when SCF distributions in
CHILD and CDS are compared against each other.
</tableCaption>
<bodyText confidence="0.999933411764706">
(also depending on the filtering threshold), which is
a relatively good result for the challenging CHILDES
data. However, it should be remembered that with this
type of data it would not be expected for the SCF sys-
tem to achieve as high precision and recall as it would
on, for instance, adult written text and that the missing
SCFs and/or misclassified SCFs are likely to provide us
with the most interesting information.
As expected, there were differences between the
SCF distributions in the two lexicons. Table 3 shows
the results when the CHILD and CDS lexicons are com-
pared against each other (i.e. using the CDS as a gold
standard). The comparison was done using both the
unfiltered and filtered (using relative frequency thresh-
old of 0.004) versions of the lexicons. The similarity
in SCF types is 75.5 according to F-measure in the un-
filtered lexicons and 59.2 in filtered ones.6
</bodyText>
<subsectionHeader confidence="0.672897">
4.3.2 Qualitative SCF Comparison
</subsectionHeader>
<bodyText confidence="0.999942733333333">
Our qualitative analysis of SCFs in the two corpora
revealed reasons for the differences. Table 4 lists the
10 most frequent SCFs in CHILD (starting from the
highest ranked SCF), along with their ranks in CDS
and VALEX. The top 3 SCFs (NP, INTRANSITIVE and
PP frames) are ranked quite similarly in all the cor-
pora. Looking at the top 10 SCFs, CHILD appears,
as expected, more similar to CDS than with VALEX,
but large differences can be detected in lower ranked
frames.
To identify those frames, we calculated for each SCF
its difference in rank between CHILD vs. CDS. Table 5
exemplifies some of the SCFs with the largest rank
differences. Many of these concern frames involving
sentential complementation. Children use more fre-
</bodyText>
<footnote confidence="0.99190875">
6The fact that the unfiltered lexicons appear so much more sim-
ilar suggests that some of the similarity is due to similarity in in-
correct SCFs (many of which are low in frequency, i.e. fall under
the threshold).
</footnote>
<bodyText confidence="0.999785846153846">
quently than adults SCFs involving THAT and HOW
complementation, while adults have a preference for
SCFs involving WHETHER, ING and IF complementa-
tion.
Although we have not yet looked at SCF differences
across ages, these discoveries are in line with previous
findings, e.g. (Brown, 1973), which indicate that chil-
dren master the sentential complementation SCFs pre-
ferred by adults (in our experiment) fairly late in the
acquisition process. With a mean utterance length for
CHILD at 3.48, we would expect to see relatively few of
these frames in the CHILD corpus—and consequently
a preference for the simpler THAT constructions.
</bodyText>
<subsectionHeader confidence="0.6619055">
4.4 The Impact of Verb Type Preferences on SCF
Differences
</subsectionHeader>
<bodyText confidence="0.999990833333333">
Given the new research findings reported in Sec-
tion 4.2 (i.e. the discovery that children and adults have
different preferences for many medium-low frequency
verbs) we investigated whether verb type preferences
play a role in SCF differences between the two corpora.
We chose for experimentation 10 verbs from 3 groups:
</bodyText>
<listItem confidence="0.921560333333333">
1. Group 1 – verbs with similar ranks in CHILD and CDS: bring,
find, give, know, need, put, see, show, tell, want
2. Group 2 – verbs with higher ranks in CDS: ask, feel, guess,
help, learn, like, pull, remember, start, think
3. Group 3 – verbs with higher ranks in CHILD: break, die,
forget, hate, hit, jump, scare, shoot, burn, wish
</listItem>
<bodyText confidence="0.999728">
The test verbs were selected randomly, subject to
the constraint that their absolute frequencies in the two
corpora were similar.7 We first correlated the unfil-
tered SCF distributions of each test verb in the two cor-
pora against each other and calculated the similarity in
the SCF types using the F-measure. We then evaluated
for each group, the accuracy of SCFs in unfiltered dis-
tributions against our gold standard (see Section 4.1).
Because the gold standard was too ambitious in terms
of recall, we only calculated the precision figures: the
average number of TP and FP SCFs taken by test verbs.
The results are included in Table 6. Verbs in Group
1 show the best SCF type correlation (84.7 F-measure)
between the two corpora although they are the rich-
est in terms of subcategorization (they take the highest
number of SCFs out of the three groups). The SCF cor-
relation is clearly lower in Groups 2 and 3, although
</bodyText>
<footnote confidence="0.9785395">
7This requirement was necessary because frequency may influ-
ence subcategorization acquisition performance.
</footnote>
<page confidence="0.995152">
37
</page>
<table confidence="0.997173818181818">
SCF Example sentence CHILD CDS VALEX
NP I love rabbits 1 1 1
INTRANS I sleep with a pillow and blanket 2 2 2
PP He can jump over the fence 3 4 3
PART I can’t give up 4 7 9
TO-INF-SC I want to play with something else 5 3 6
PART-NP/NP-PART He looked it up 6 6 7
NP-NP Ask her all these questions 7 5 18
NP-INF-OC Why don’t you help herput the blocks in the can ? 8 9 60
INTR-RECIP So the kitten and the dog won’tfight 9 8 48
NP-PP He put his breakfast in the bin 10 10 4
</table>
<tableCaption confidence="0.995058">
Table 4: 10 most frequent SCFs in CHILD, along with their ranks in CDS and VALEX.
</tableCaption>
<table confidence="0.999907363636364">
SCF Example sentence
CHILD MP I win twelve hundred dollars
INF-AC You can help me wash the dishes
PP-HOW-S He explained to her how she did it
HOW-TO-INF Daddy can you tell me how to spell Christmas carols?
NP-S He did not tell me that it was gonna cost me five dollars
CDS ING-PP Stop throwing a tantrum
NP-AS-NP Isent him as a messenger
NP-WH-S I’ll tell you whether you can take it off
IT WHS, SUBTYPE IF How would you like it ifshe pulled your hair?
NP-PP-PP He turned itfrom a disaster into a victory
</table>
<tableCaption confidence="0.915486">
Table 5: Typical SCFs with higher ranks in (i) CHILD and (ii) CDS.
</tableCaption>
<table confidence="0.999892">
Measures Group1 Group2 Group3
SCF similarity F-measure 84.7 72.17 75.60
SCF accuracy TPs CDS 12 11 7
TPs CHILD 10 9 8
FPs CDS 36 29 13
FPs CHILD 32 18 15
</table>
<tableCaption confidence="0.7698065">
Table 6: Average results for 3 groups when (i) unfil-
tered SCF distributions in CHILD and CDS are com-
</tableCaption>
<bodyText confidence="0.998450083333333">
pared against each other (SCF similarity) and when (ii)
the SCFs in the distributions are evaluated against a
gold standard (SCF accuracy).
the verbs in these groups take fewer SCFs. Interest-
ingly, Group 3 is the only group where children pro-
duce more TPs and FPs on average than adults do, i.e.
both correct and incorrect SCFs which are not exem-
plified in the adult speech. The frequency effects con-
trolled, the reason for these differences is likely to lie
in the differing relative preferences children and adults
have for verbs in groups 2 and 3, which we think may
impact the richness of their language.
</bodyText>
<subsectionHeader confidence="0.983971">
4.5 Further Analysis of TP and FP Differences
</subsectionHeader>
<bodyText confidence="0.998899055555556">
We looked further at the interesting TP and FP differ-
ences in Group 3 to investigate whether they tell us
something about (i) how children learn SCFs (via both
TPs and FPs), and (ii) how the parsing / SCF extraction
system could be improved for CHILDES data in the fu-
ture (via the FPs).
We first made a quantitative analysis of the rela-
tive difference in TPs and FPs for all the SCFs in both
corpora. The major finding of this high level anal-
ysis was a significantly high FP rate for some ING
frames (e.g. PART-ING-SC, ING-NP-OMIT, NP-ING-
OC) within CHILD (e.g. “car going hit”, “I hurt hand
moving”). This agrees with many previous studies,
e.g. (Brown, 1973), which have shown that children
overextend and incorrectly use the “ing” morpheme
during early acquisition.
A qualitative analysis of the verbs from Group 3 was
then carried out, looking for the following scenarios:
</bodyText>
<listItem confidence="0.986713818181818">
• SCF is a FP in both CHILD and CDS - either i) the
gold standard is incomplete, or ii) there is error in
the parser/subcategorization system with respect to the
CHILDES domain.
• SCF is a TP in CDS and not present in CHILD - children have
not acquired the frame despite exposure to it (perhaps it is
complicated to acquire).
• SCF is a TP in CHILD but not present in CDS - adults are
not using the frame but the children have acquired it. This
indicates that either i) children are acquiring the frame from
elsewhere in their environment (perhaps from a television),
</listItem>
<page confidence="0.99856">
38
</page>
<figureCaption confidence="0.999759">
Figure 1: SCFs obtained for the verb shoot
</figureCaption>
<bodyText confidence="0.995178172413793">
or ii) there is a misuse of the verb’s semantic class in child
speech.
• SCF is a FP in CHILD but not present in CDS -children should
not have been exposed to this frame but they have acquired
it. This indicates either i) a misuse of the verb’s semantic
class, or ii) error in the parsing/subcategorization technology
with respect to the child-speech domain.
These scenarios are illustrated in Figure 1 which
graphically depicts the differences in TPs and FPs for
the verb shoot. The SCFs have been arranged in a
complexity hierarchy where complexity is defined in
terms of increasing argument structure.8 SCFs found
within our ANLT-COMLEX gold standard lexicon for
shoot are indicated in bold-face. A right-angled rect-
angle drawn around a SCF indicates that the frame
is present in CHILD—a solid line indicating a strong
presence (relative frequency &gt; 0.010) and a dotted
line indicating a weak presence (relative frequency &gt;
0.005). Rounded-edge rectangles represent the pres-
ence of SCFs within CDS similarly. For example, the
frame NP represents a TP in both CHILD and CDS and
the frame NP-NP represents a FP within CHILD.
With reference to Figure 1, we notice that all of
the SCFs present in CHILD are directly connected
within the hierarchy and there is a tendency for weakly
present SCFs to inherit from those strongly present. A
possible explanation for this is that children are ex-
ploring SCFs—trying out frames that are slightly more
complex than those already acquired (for a learning
</bodyText>
<footnote confidence="0.97617925">
8For instance, the intransitive frame INTRANS is less complex
than the transitive frame NP, which in turn is less complex than the
di-transitive frame NP-NP. For a detailed description of all SCFs
see (Korhonen, 2002).
</footnote>
<bodyText confidence="0.99943346875">
algorithm that exploits such a hypothesis in general
see (Buttery, 2006)).
The SCF NP-NP is strongly present in CHILD de-
spite being a FP. Inspection of the associated utter-
ances reveals that some instances NP-NP are legitimate
but so uncommon in adult language that they are omit-
ted from the gold-standard (e.g. “can i shoot us all to
pieces”. However, other instances demonstrate a mis-
understanding of the semantic class of the verb; there
is possible confusion with the semantic class of send
or throw (e.g. “i shoot him home”).
The frame NP-INF is a FP in both corpora and a fre-
quent FP in CHILD. Inspection of the associated utter-
ances flags up a parsing problem. Frame NP-INF can
be illustrated by the sentences “he helped her bake the
cake” or “he made her sing”, however, within CHILD
the NP-INF has been acquired from utterances such
as “i want ta shoot him”. The RASP parser has mis-
tagged the word “ta” leading to a misclassification
by the SCF extraction system. This problem could be
solved by augmenting RASP’s current grammar with a
lexical entry specifying “ta” as an alternative to infini-
tival “to”.
In summary, our analysis of TP and FP differ-
ences has confirmed previous studies regarding the
nature of child speech (the over-extension of the
“ing” morpheme). It has also demonstrated that
TP/FP analysis can be a useful diagnostic for pars-
ing/subcategorization extraction problems within a
new data domain. Further, we suggest that analysis
of FPs can provide empirical data regarding the man-
ner in which children learn the semantic classes of
</bodyText>
<page confidence="0.997739">
39
</page>
<bodyText confidence="0.4887435">
verbs (a matter that has been much debated e.g. (Levin,
1993), (Brooks and Tomasello, 1999)).
</bodyText>
<sectionHeader confidence="0.902667" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999910233333333">
P. Buttery and A. Korhonen. 2005. Large-scale analysis of verb
subcategorization differences between child directed speech
and adult speech. In Proceedings of the Interdisciplinary Work-
shop on the Identification and Representation of Verb Features
and Verb Classes, Saarbrucken, Germany.
We have reported the first experiment for automatically
acquiring verbal subcategorization from both child and
child-directed parts of the CHILDES database. Our re-
sults show that a state-of-the-art subcategorization ac-
quisition system yields useful results on challenging
child language data even without any domain-specific
tuning. It produces data which is accurate enough
to confirm and extend several previous research find-
ings in CLA. We explore the discovery that children
and adults have different relative preferences for cer-
tain verb types, and that these preferences influence
the way children acquire subcategorization. Our work
demonstrates the value of using NLP technology to an-
notate child language data, particularly where manual
annotations are not readily available for research use.
Our pilot study yielded useful information which will
help us further improve both parsing and lexical ac-
quisition performance on spoken/child language data.
In the future, we plan to optimize the technology so
that it can produce higher quality data for investiga-
tion of syntactic complexity in this domain. Using the
improved technology we plan to then conduct a more
thorough investigation of the interesting CLA topics
discovered in this study—first concentrating on SCF
differences in child speech across age ranges.
</bodyText>
<sectionHeader confidence="0.99926" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999917546875">
B. Boguraev, J. Carroll, E. J. Briscoe, D. Carter, and C. Grover.
1987. The derivation of a grammatically-indexed lexicon from
the Longman Dictionary of Contemporary English. In Proc. of
the 25th Annual Meeting ofACL, pages 193–200, Stanford, CA.
E Briscoe and J Carroll. 1997. Automatic extraction of subcatego-
rization from corpora. In 5th ACL Conference on Applied Nat-
ural Language Processing, pages 356–363, Washington, DC.
ACL.
E. J. Briscoe, J. Carroll, and R. Watson. 2006. The second re-
lease of the rasp system. In Proc. of the COLING/ACL 2006
Interactive Presentation Sessions, Sydney, Australia.
P Brooks and M Tomasello. 1999. Young children learn to pro-
duce passives with nonce verbs. Developmental Psychology,
35:29–44.
R Brown. 1973. A first Language: the early stages. Harvard
University Press, Cambridge, MA.
L. Burnard, 1995. The BNC Users Reference Guide. British Na-
tional Corpus Consortium, Oxford, May.
P Buttery. 2006. Computational Models for First Language Ac-
quisition. Ph.D. thesis, University of Cambridge.
E. Charniak. 2000. A maximum-entropy-inspired parser. In Pro-
ceedings of the 1st Meeting of the North American Chapter of
the Association for Computational Linguistics, Seattle, WA.
C. Fisher, G. Hall, S. Rakowitz, and L. Gleitman. 1994. When
it is better to receive than to give: syntactic and conceptual
constraints on vocabulary growth. Lingua, 92(1–4):333–375,
April.
R. Grishman, C. Macleod, and A. Meyers. 1994. COMLEX Syn-
tax: Building a Computational Lexicon. In Proc. of COLING,
Kyoto.
A. Korhonen and Y. Krymolowski. 2002. On the Robustness of
Entropy-Based Similarity Measures in Evaluation of Subcate-
gorization Acquisition Systems. In Proc. of the 6th CoNLL,
pages 91–97, Taipei, Taiwan.
A. Korhonen, Y. Krymolowski, and E. J. Briscoe. 2006. A large
subcategorization lexicon for natural language processing ap-
plications. In Proc. of the 5th LREC, Genova, Italy.
A Korhonen. 2002. Subcategorization Acquisition. Ph.D. thesis,
University of Cambridge. Thesis published as Technical Report
UCAM-CL-TR-530.
E Lenneberg. 1967. Biological Foundations of Language. Wiley
Press, New York, NY.
B Levin. 1993. English Verb Classes and Alternations. Chicago
University Press, Chicago, IL.
B. MacWhinney. 2000. The CHILDES Project: Tools for Analyz-
ing Talk. Lawrence Erlbaum, Mahwah, NJ, 3rd edition.
D. McCarthy and J. Carroll. 2003. Disambiguating nouns, verbs,
and adjectives using automatically acquired selectional prefer-
ences. Computational Linguistics, 29(4).
L Naigles. 1990. Children use syntax to learn verb meanings.
Journal of Child Language, 17:357–374.
S Pinker. 1994. The Language Instinct: How the Mind Creates
Language. Harper Collins, New York, NY.
J. Preiss, E. J. Briscoe, and A. Korhonen. 2007. A system for
large-scale acquisition of verbal, nominal and adjectival sub-
categorization frames from corpora. In Proceedings of the 45th
Annual Meeting ofACL, Prague, Czech Republic. To appear.
K. Sagae, A. Lavie, and B. MacWhinney. 2005. Automatic mea-
surement of syntactic development in child langugage. In Pro-
ceedings of the 42nd Meeting of the Association for Computa-
tional Linguistics, Ann Arbor, Michigan.
S. Schulte im Walde. 2006. Experiments on the automatic induc-
tion of german semantic verb classes. Computational Linguis-
tics, 32(2):159–194.
</reference>
<page confidence="0.998637">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.310288">
<title confidence="0.920387">I will shoot your shopping down and you can shoot all my Automatic Lexical Acquisition from the CHILDES Database</title>
<author confidence="0.991392">Paula Buttery</author>
<author confidence="0.991392">Anna</author>
<affiliation confidence="0.976118">RCEAL, University of</affiliation>
<address confidence="0.422651">9 West Road, Cambridge, CB3 9DB,</address>
<email confidence="0.794184">pjb48,alk23@cam.ac.uk</email>
<abstract confidence="0.997611842105263">Empirical data regarding the syntactic complexity of children’s speech is important for theories of language acquisition. Currently much of this data is absent in the annotated of the In this perliminary study, we show that a state-ofthe-art subcategorization acquisition system of Preiss et al. (2007) can be used to extract largescale subcategorization (frequency) information from the (i) child and (ii) child-directed within the without any domain-specific tuning. We demonstrate that the acquired information is sufficiently accurate to confirm and extend previously reported research findings. We also report qualitative results which can be used to further improve parsing and lexical acquisition technology for child language data in the future.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Boguraev</author>
<author>J Carroll</author>
<author>E J Briscoe</author>
<author>D Carter</author>
<author>C Grover</author>
</authors>
<title>The derivation of a grammatically-indexed lexicon from the Longman Dictionary of Contemporary English.</title>
<date>1987</date>
<booktitle>In Proc. of the 25th Annual Meeting ofACL,</booktitle>
<pages>193--200</pages>
<location>Stanford, CA.</location>
<contexts>
<context position="6987" citStr="Boguraev et al., 1987" startWordPosition="1012" endWordPosition="1015">hese preferences seem to influence the way children acquire subcategorization. In addition, we report qualitative results which can be used to further improve parsing and lexical acquisition technology for spoken child language data in the future. 2 Subcategorization Acquisition System We used for subcategorization acquisition the new system of Preiss, Briscoe and Korhonen (2007) which is essentially a much improved and extended version of Briscoe and Carroll’s (1997) system. It incorporates 168 SCF distinctions, a superset of those found in the COMLEX Syntax (Grishman et al., 1994) and ANLT (Boguraev et al., 1987) dictionaries. Currently, SCFs abstract over specific lexically governed particles and prepositions and specific predicate selectional 34 3 Data The English (British and American) sections of the CHILDES database (MacWhinney, 2000) were used to create two corpora: 1) CHILD and 2) CDS. Both corpora contained c. 1 million utterances which were selected from the data after some utterances containing un-transcribable sections were removed. Speakers were identified using speaker-id codes within the CHAT transcriptions of the data:3 CHILD contained the utterances of speakers identified as target chi</context>
</contexts>
<marker>Boguraev, Carroll, Briscoe, Carter, Grover, 1987</marker>
<rawString>B. Boguraev, J. Carroll, E. J. Briscoe, D. Carter, and C. Grover. 1987. The derivation of a grammatically-indexed lexicon from the Longman Dictionary of Contemporary English. In Proc. of the 25th Annual Meeting ofACL, pages 193–200, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Briscoe</author>
<author>J Carroll</author>
</authors>
<title>Automatic extraction of subcategorization from corpora.</title>
<date>1997</date>
<booktitle>In 5th ACL Conference on Applied Natural Language Processing,</booktitle>
<pages>356--363</pages>
<publisher>ACL.</publisher>
<location>Washington, DC.</location>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>E Briscoe and J Carroll. 1997. Automatic extraction of subcategorization from corpora. In 5th ACL Conference on Applied Natural Language Processing, pages 356–363, Washington, DC. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E J Briscoe</author>
<author>J Carroll</author>
<author>R Watson</author>
</authors>
<title>The second release of the rasp system.</title>
<date>2006</date>
<booktitle>In Proc. of the COLING/ACL</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="2582" citStr="Briscoe et al., 2006" startWordPosition="372" endWordPosition="375">ses and predicateargument structures. Although manual syntactic annotation is possible, it is extremely costly. The alternative is to use natural language processing (NLP) techniques for annotation. Automatic techniques are now viable, cost effective and, although not completely error-free, are sufficiently accurate to yield annotations useful for linguistic purposes. They also gather important qualitative and quantitative information, which is difficult for humans to obtain, as a side-effect of the acquisition process. For instance, state-of-the-art statistical parsers, e.g. (Charniak, 2000; Briscoe et al., 2006), have wide coverage and yield grammatical representations capable of supporting various applications (e.g. summarization, information extraction). In addition, lexical information (e.g. subcategorization, lexical classes) can now be acquired automatically from parsed data (McCarthy and Carroll, 2003; Schulte im Walde, 2006; Preiss et al., 2007). This information complements the basic grammatical analysis and provides access to the underlying predicate-argument structure. Containing considerable ellipsis and error, spoken child language can be challenging for current NLP techniques which are t</context>
<context position="4307" citStr="Briscoe et al., 2006" startWordPosition="612" endWordPosition="615"> optimal accuracy, this re- bounded dependency constructions, such as particle search has opened up the exciting possibility of auto- and dative movement—this will be revised in future matic grammatical annotation of the entire CHILDES versions of the SCF system. database in the future. The system tokenizes, tags, lemmatizes and parses However, no work has yet been conducted on au- input sentences using the recent (second) release of tomatic acquisition of lexical information from child the RASP (Robust Accurate Statistical Parsing) system speech. The only automatic lexical acquisition study (Briscoe et al., 2006) which parses arbitrary English involving CHILDES that we are aware of is that of text with state-of-the-art levels of accuracy. SCFs are Buttery and Korhonen (2005). The study involved extracted from the grammatical relations (GRs) output extracting subcategorization information from (some of the parser using a rule-based classifier. This clasof) the adult (child-directed) speech in the database, sifier operates by exploiting the close correspondence and showing that this information differs from that ex- between the dependency relationships which the GRs tracted from the spoken part of the B</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>E. J. Briscoe, J. Carroll, and R. Watson. 2006. The second release of the rasp system. In Proc. of the COLING/ACL 2006 Interactive Presentation Sessions, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brooks</author>
<author>M Tomasello</author>
</authors>
<title>Young children learn to produce passives with nonce verbs.</title>
<date>1999</date>
<pages>35--29</pages>
<publisher>Developmental Psychology,</publisher>
<contexts>
<context position="27383" citStr="Brooks and Tomasello, 1999" startWordPosition="4541" endWordPosition="4544">t grammar with a lexical entry specifying “ta” as an alternative to infinitival “to”. In summary, our analysis of TP and FP differences has confirmed previous studies regarding the nature of child speech (the over-extension of the “ing” morpheme). It has also demonstrated that TP/FP analysis can be a useful diagnostic for parsing/subcategorization extraction problems within a new data domain. Further, we suggest that analysis of FPs can provide empirical data regarding the manner in which children learn the semantic classes of 39 verbs (a matter that has been much debated e.g. (Levin, 1993), (Brooks and Tomasello, 1999)). 5 Conclusion P. Buttery and A. Korhonen. 2005. Large-scale analysis of verb subcategorization differences between child directed speech and adult speech. In Proceedings of the Interdisciplinary Workshop on the Identification and Representation of Verb Features and Verb Classes, Saarbrucken, Germany. We have reported the first experiment for automatically acquiring verbal subcategorization from both child and child-directed parts of the CHILDES database. Our results show that a state-of-the-art subcategorization acquisition system yields useful results on challenging child language data even</context>
</contexts>
<marker>Brooks, Tomasello, 1999</marker>
<rawString>P Brooks and M Tomasello. 1999. Young children learn to produce passives with nonce verbs. Developmental Psychology, 35:29–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Brown</author>
</authors>
<title>A first Language: the early stages.</title>
<date>1973</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="18406" citStr="Brown, 1973" startWordPosition="2965" endWordPosition="2966">rgest rank differences. Many of these concern frames involving sentential complementation. Children use more fre6The fact that the unfiltered lexicons appear so much more similar suggests that some of the similarity is due to similarity in incorrect SCFs (many of which are low in frequency, i.e. fall under the threshold). quently than adults SCFs involving THAT and HOW complementation, while adults have a preference for SCFs involving WHETHER, ING and IF complementation. Although we have not yet looked at SCF differences across ages, these discoveries are in line with previous findings, e.g. (Brown, 1973), which indicate that children master the sentential complementation SCFs preferred by adults (in our experiment) fairly late in the acquisition process. With a mean utterance length for CHILD at 3.48, we would expect to see relatively few of these frames in the CHILD corpus—and consequently a preference for the simpler THAT constructions. 4.4 The Impact of Verb Type Preferences on SCF Differences Given the new research findings reported in Section 4.2 (i.e. the discovery that children and adults have different preferences for many medium-low frequency verbs) we investigated whether verb type </context>
<context position="23182" citStr="Brown, 1973" startWordPosition="3829" endWordPosition="3830">differences in Group 3 to investigate whether they tell us something about (i) how children learn SCFs (via both TPs and FPs), and (ii) how the parsing / SCF extraction system could be improved for CHILDES data in the future (via the FPs). We first made a quantitative analysis of the relative difference in TPs and FPs for all the SCFs in both corpora. The major finding of this high level analysis was a significantly high FP rate for some ING frames (e.g. PART-ING-SC, ING-NP-OMIT, NP-INGOC) within CHILD (e.g. “car going hit”, “I hurt hand moving”). This agrees with many previous studies, e.g. (Brown, 1973), which have shown that children overextend and incorrectly use the “ing” morpheme during early acquisition. A qualitative analysis of the verbs from Group 3 was then carried out, looking for the following scenarios: • SCF is a FP in both CHILD and CDS - either i) the gold standard is incomplete, or ii) there is error in the parser/subcategorization system with respect to the CHILDES domain. • SCF is a TP in CDS and not present in CHILD - children have not acquired the frame despite exposure to it (perhaps it is complicated to acquire). • SCF is a TP in CHILD but not present in CDS - adults ar</context>
</contexts>
<marker>Brown, 1973</marker>
<rawString>R Brown. 1973. A first Language: the early stages. Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Burnard</author>
</authors>
<title>The BNC Users Reference Guide. British National Corpus Consortium,</title>
<date>1995</date>
<location>Oxford,</location>
<contexts>
<context position="4998" citStr="Burnard, 1995" startWordPosition="714" endWordPosition="715">t of text with state-of-the-art levels of accuracy. SCFs are Buttery and Korhonen (2005). The study involved extracted from the grammatical relations (GRs) output extracting subcategorization information from (some of the parser using a rule-based classifier. This clasof) the adult (child-directed) speech in the database, sifier operates by exploiting the close correspondence and showing that this information differs from that ex- between the dependency relationships which the GRs tracted from the spoken part of the British National embody and the head-complement structure which Corpus (BNC) (Burnard, 1995). subcategorization acquisition attempts to recover. LexIn this paper, we investigate whether state-of-the- ical entries of extracted SCFs are constructed for each art subcategorization acquisition technology can be word in the corpus data. Finally, the entries may be used—without any domain-specific tuning—to obtain optionally filtered to obtain a more accurate lexicon. large-scale verb subcategorization frequency informa- This is done by setting empirically determined threshtion from CHILDES which is accurate enough to show olds on the relative frequencies of SCFs. differences and similariti</context>
</contexts>
<marker>Burnard, 1995</marker>
<rawString>L. Burnard, 1995. The BNC Users Reference Guide. British National Corpus Consortium, Oxford, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Buttery</author>
</authors>
<title>Computational Models for First Language Acquisition.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge.</institution>
<contexts>
<context position="25799" citStr="Buttery, 2006" startWordPosition="4273" endWordPosition="4274"> of the SCFs present in CHILD are directly connected within the hierarchy and there is a tendency for weakly present SCFs to inherit from those strongly present. A possible explanation for this is that children are exploring SCFs—trying out frames that are slightly more complex than those already acquired (for a learning 8For instance, the intransitive frame INTRANS is less complex than the transitive frame NP, which in turn is less complex than the di-transitive frame NP-NP. For a detailed description of all SCFs see (Korhonen, 2002). algorithm that exploits such a hypothesis in general see (Buttery, 2006)). The SCF NP-NP is strongly present in CHILD despite being a FP. Inspection of the associated utterances reveals that some instances NP-NP are legitimate but so uncommon in adult language that they are omitted from the gold-standard (e.g. “can i shoot us all to pieces”. However, other instances demonstrate a misunderstanding of the semantic class of the verb; there is possible confusion with the semantic class of send or throw (e.g. “i shoot him home”). The frame NP-INF is a FP in both corpora and a frequent FP in CHILD. Inspection of the associated utterances flags up a parsing problem. Fram</context>
</contexts>
<marker>Buttery, 2006</marker>
<rawString>P Buttery. 2006. Computational Models for First Language Acquisition. Ph.D. thesis, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="2559" citStr="Charniak, 2000" startWordPosition="370" endWordPosition="371">s), lexical classes and predicateargument structures. Although manual syntactic annotation is possible, it is extremely costly. The alternative is to use natural language processing (NLP) techniques for annotation. Automatic techniques are now viable, cost effective and, although not completely error-free, are sufficiently accurate to yield annotations useful for linguistic purposes. They also gather important qualitative and quantitative information, which is difficult for humans to obtain, as a side-effect of the acquisition process. For instance, state-of-the-art statistical parsers, e.g. (Charniak, 2000; Briscoe et al., 2006), have wide coverage and yield grammatical representations capable of supporting various applications (e.g. summarization, information extraction). In addition, lexical information (e.g. subcategorization, lexical classes) can now be acquired automatically from parsed data (McCarthy and Carroll, 2003; Schulte im Walde, 2006; Preiss et al., 2007). This information complements the basic grammatical analysis and provides access to the underlying predicate-argument structure. Containing considerable ellipsis and error, spoken child language can be challenging for current NLP</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>E. Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fisher</author>
<author>G Hall</author>
<author>S Rakowitz</author>
<author>L Gleitman</author>
</authors>
<title>When it is better to receive than to give: syntactic and conceptual constraints on vocabulary growth.</title>
<date>1994</date>
<tech>Lingua, 92(1–4):333–375,</tech>
<contexts>
<context position="1470" citStr="Fisher et al., 1994" startWordPosition="215" endWordPosition="218">and extend previously reported research findings. We also report qualitative results which can be used to further improve parsing and lexical acquisition technology for child language data in the future. 1 Introduction Large empirical data containing children’s speech are the key to developing and evaluating different theories of child language acquisition (CLA). Particularly important are data related to syntactic complexity of child language since considerable evidence suggests that syntactic information plays a central role during language acquisition, e.g. (Lenneberg, 1967; Naigles, 1990; Fisher et al., 1994). The standard corpus in the study of CLA is the CHILDES database (MacWhinney, 2000)1 which provides 300MB of transcript data of interactions be1See http://childes.psy.cmu.edu for details. 33 tween children and parents over 25 human languages. CHILDES is currently available in raw, part-of-speechtagged and lemmatized formats. However, adequate investigation of syntactic complexity requires deeper annotations related to e.g. syntactic parses, subcategorization frames (SCFs), lexical classes and predicateargument structures. Although manual syntactic annotation is possible, it is extremely costl</context>
</contexts>
<marker>Fisher, Hall, Rakowitz, Gleitman, 1994</marker>
<rawString>C. Fisher, G. Hall, S. Rakowitz, and L. Gleitman. 1994. When it is better to receive than to give: syntactic and conceptual constraints on vocabulary growth. Lingua, 92(1–4):333–375, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>C Macleod</author>
<author>A Meyers</author>
</authors>
<title>COMLEX Syntax: Building a Computational Lexicon.</title>
<date>1994</date>
<booktitle>In Proc. of COLING, Kyoto.</booktitle>
<contexts>
<context position="6954" citStr="Grishman et al., 1994" startWordPosition="1006" endWordPosition="1009">ertain types of verbs, and that these preferences seem to influence the way children acquire subcategorization. In addition, we report qualitative results which can be used to further improve parsing and lexical acquisition technology for spoken child language data in the future. 2 Subcategorization Acquisition System We used for subcategorization acquisition the new system of Preiss, Briscoe and Korhonen (2007) which is essentially a much improved and extended version of Briscoe and Carroll’s (1997) system. It incorporates 168 SCF distinctions, a superset of those found in the COMLEX Syntax (Grishman et al., 1994) and ANLT (Boguraev et al., 1987) dictionaries. Currently, SCFs abstract over specific lexically governed particles and prepositions and specific predicate selectional 34 3 Data The English (British and American) sections of the CHILDES database (MacWhinney, 2000) were used to create two corpora: 1) CHILD and 2) CDS. Both corpora contained c. 1 million utterances which were selected from the data after some utterances containing un-transcribable sections were removed. Speakers were identified using speaker-id codes within the CHAT transcriptions of the data:3 CHILD contained the utterances of </context>
</contexts>
<marker>Grishman, Macleod, Meyers, 1994</marker>
<rawString>R. Grishman, C. Macleod, and A. Meyers. 1994. COMLEX Syntax: Building a Computational Lexicon. In Proc. of COLING, Kyoto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Korhonen</author>
<author>Y Krymolowski</author>
</authors>
<title>On the Robustness of Entropy-Based Similarity Measures in Evaluation of Subcategorization Acquisition Systems.</title>
<date>2002</date>
<booktitle>In Proc. of the 6th CoNLL,</booktitle>
<pages>91--97</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="9302" citStr="Korhonen and Krymolowski, 2002" startWordPosition="1382" endWordPosition="1385">ssdomain corpora (containing both written and spoken language). VALEX includes SCF and frequency information for 6,397 English verbs. We employed the most accurate version of the lexicon here (87.3 Fmeasure)—this lexicon was obtained by selecting high frequency SCFs and supplementing them with lower frequency SCFs from manually built lexicons. 4 Analysis 4.1 Methods for Analysis The similarity between verb and SCF distributions in the lexicons was examined. To maintain a robust analysis in the presence of noise, multiple similarity measures were used to compare the verb and SCF distributions (Korhonen and Krymolowski, 2002). In the following p = (pi) and q = (qi) where pi and qi are the probabilities associated with SCFi in distributions (lexicons) P and Q: • Intersection (IS) - the intersection of non-zero probability SCFs in p and q; • Spearman rank correlation (RC) - lies in the range [1; 1], with values near 0 denoting a low degree of association and values near -1 and 1 denoting strong association; • Kullback-Leibler (KL) distance - a measure of the additional information needed to describe p using q, KL is always &gt; 0 and = 0 only when p =_ q; The SCFs distributions acquired from the corpora for the chosen </context>
</contexts>
<marker>Korhonen, Krymolowski, 2002</marker>
<rawString>A. Korhonen and Y. Krymolowski. 2002. On the Robustness of Entropy-Based Similarity Measures in Evaluation of Subcategorization Acquisition Systems. In Proc. of the 6th CoNLL, pages 91–97, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Korhonen</author>
<author>Y Krymolowski</author>
<author>E J Briscoe</author>
</authors>
<title>A large subcategorization lexicon for natural language processing applications.</title>
<date>2006</date>
<booktitle>In Proc. of the 5th LREC,</booktitle>
<location>Genova, Italy.</location>
<contexts>
<context position="8575" citStr="Korhonen et al., 2006" startWordPosition="1272" endWordPosition="1275"> CHILDES. 4The complete age range is from 1 year and 1 month up to 7 years. 3.1 Test Verbs and SCF Lexicons We selected a set of 161 verbs for experimentation. The words were selected at random, subject to the constraint that a sufficient number of SCFs would be extracted (&gt; 100) from both corpora to facilitate maximally useful comparisons. All sentences containing an occurrence of one of the test verbs were extracted from the two corpora and fed into the SCF acquisition system described earlier in section 2. In some of our experiments the two lexicons were compared against the VALEX lexicon (Korhonen et al., 2006)—a large subcategorization lexicon for English which was acquired automatically from several crossdomain corpora (containing both written and spoken language). VALEX includes SCF and frequency information for 6,397 English verbs. We employed the most accurate version of the lexicon here (87.3 Fmeasure)—this lexicon was obtained by selecting high frequency SCFs and supplementing them with lower frequency SCFs from manually built lexicons. 4 Analysis 4.1 Methods for Analysis The similarity between verb and SCF distributions in the lexicons was examined. To maintain a robust analysis in the prese</context>
</contexts>
<marker>Korhonen, Krymolowski, Briscoe, 2006</marker>
<rawString>A. Korhonen, Y. Krymolowski, and E. J. Briscoe. 2006. A large subcategorization lexicon for natural language processing applications. In Proc. of the 5th LREC, Genova, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Korhonen</author>
</authors>
<title>Subcategorization Acquisition.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge.</institution>
<note>Thesis published as Technical Report UCAM-CL-TR-530.</note>
<contexts>
<context position="25725" citStr="Korhonen, 2002" startWordPosition="4262" endWordPosition="4263">epresents a FP within CHILD. With reference to Figure 1, we notice that all of the SCFs present in CHILD are directly connected within the hierarchy and there is a tendency for weakly present SCFs to inherit from those strongly present. A possible explanation for this is that children are exploring SCFs—trying out frames that are slightly more complex than those already acquired (for a learning 8For instance, the intransitive frame INTRANS is less complex than the transitive frame NP, which in turn is less complex than the di-transitive frame NP-NP. For a detailed description of all SCFs see (Korhonen, 2002). algorithm that exploits such a hypothesis in general see (Buttery, 2006)). The SCF NP-NP is strongly present in CHILD despite being a FP. Inspection of the associated utterances reveals that some instances NP-NP are legitimate but so uncommon in adult language that they are omitted from the gold-standard (e.g. “can i shoot us all to pieces”. However, other instances demonstrate a misunderstanding of the semantic class of the verb; there is possible confusion with the semantic class of send or throw (e.g. “i shoot him home”). The frame NP-INF is a FP in both corpora and a frequent FP in CHILD</context>
</contexts>
<marker>Korhonen, 2002</marker>
<rawString>A Korhonen. 2002. Subcategorization Acquisition. Ph.D. thesis, University of Cambridge. Thesis published as Technical Report UCAM-CL-TR-530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Lenneberg</author>
</authors>
<title>Biological Foundations of Language.</title>
<date>1967</date>
<publisher>Wiley Press,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="1433" citStr="Lenneberg, 1967" startWordPosition="211" endWordPosition="212">ufficiently accurate to confirm and extend previously reported research findings. We also report qualitative results which can be used to further improve parsing and lexical acquisition technology for child language data in the future. 1 Introduction Large empirical data containing children’s speech are the key to developing and evaluating different theories of child language acquisition (CLA). Particularly important are data related to syntactic complexity of child language since considerable evidence suggests that syntactic information plays a central role during language acquisition, e.g. (Lenneberg, 1967; Naigles, 1990; Fisher et al., 1994). The standard corpus in the study of CLA is the CHILDES database (MacWhinney, 2000)1 which provides 300MB of transcript data of interactions be1See http://childes.psy.cmu.edu for details. 33 tween children and parents over 25 human languages. CHILDES is currently available in raw, part-of-speechtagged and lemmatized formats. However, adequate investigation of syntactic complexity requires deeper annotations related to e.g. syntactic parses, subcategorization frames (SCFs), lexical classes and predicateargument structures. Although manual syntactic annotati</context>
</contexts>
<marker>Lenneberg, 1967</marker>
<rawString>E Lenneberg. 1967. Biological Foundations of Language. Wiley Press, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>English Verb Classes and Alternations.</title>
<date>1993</date>
<publisher>Chicago University Press,</publisher>
<location>Chicago, IL.</location>
<contexts>
<context position="13534" citStr="Levin, 1993" startWordPosition="2152" endWordPosition="2153">LD vs. CDS. Table 2 lists 40 verbs with substantial rank differences between the two corpora. The first column shows verbs which have higher ranks in CHILD than in CDS, and the second column shows verbs with higher ranks in CDS than in CHILD. We can see e.g. that children tend to prefer verbs such as shoot, die and kill while adults prefer verbs such as remember, send and learn. To investigate whether these differences in preferences are random or motivated in some manner, we classified the verbs with the largest differences in ranks (&gt;10) into appropriate Levin-style lexicalsemantic classes (Levin, 1993) according to their predominant senses in the two corpora.5 We discovered that the most frequent classes among the verbs that children prefer are HIT (e.g. bump, hit, kick), BREAK (e.g. crash, break, rip), HURT (e.g. hurt, burn, bite) and MOTION (e.g. fly, jump, run) verbs. Overall, many of the preferred verbs (regardless of the class) express negative actions or feelings (e.g. shoot, die, scare, hate). 5This classification was done manually to obtain a reliable result. CHILD CDS shoot tie remember hope hate wish send suppose die cut learn bet write crash wipe kiss use kick pay smell bump scar</context>
<context position="27353" citStr="Levin, 1993" startWordPosition="4539" endWordPosition="4540">g RASP’s current grammar with a lexical entry specifying “ta” as an alternative to infinitival “to”. In summary, our analysis of TP and FP differences has confirmed previous studies regarding the nature of child speech (the over-extension of the “ing” morpheme). It has also demonstrated that TP/FP analysis can be a useful diagnostic for parsing/subcategorization extraction problems within a new data domain. Further, we suggest that analysis of FPs can provide empirical data regarding the manner in which children learn the semantic classes of 39 verbs (a matter that has been much debated e.g. (Levin, 1993), (Brooks and Tomasello, 1999)). 5 Conclusion P. Buttery and A. Korhonen. 2005. Large-scale analysis of verb subcategorization differences between child directed speech and adult speech. In Proceedings of the Interdisciplinary Workshop on the Identification and Representation of Verb Features and Verb Classes, Saarbrucken, Germany. We have reported the first experiment for automatically acquiring verbal subcategorization from both child and child-directed parts of the CHILDES database. Our results show that a state-of-the-art subcategorization acquisition system yields useful results on challe</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>B Levin. 1993. English Verb Classes and Alternations. Chicago University Press, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B MacWhinney</author>
</authors>
<title>The CHILDES Project: Tools for Analyzing Talk. Lawrence Erlbaum, Mahwah, NJ, 3rd edition.</title>
<date>2000</date>
<contexts>
<context position="1554" citStr="MacWhinney, 2000" startWordPosition="231" endWordPosition="232">ich can be used to further improve parsing and lexical acquisition technology for child language data in the future. 1 Introduction Large empirical data containing children’s speech are the key to developing and evaluating different theories of child language acquisition (CLA). Particularly important are data related to syntactic complexity of child language since considerable evidence suggests that syntactic information plays a central role during language acquisition, e.g. (Lenneberg, 1967; Naigles, 1990; Fisher et al., 1994). The standard corpus in the study of CLA is the CHILDES database (MacWhinney, 2000)1 which provides 300MB of transcript data of interactions be1See http://childes.psy.cmu.edu for details. 33 tween children and parents over 25 human languages. CHILDES is currently available in raw, part-of-speechtagged and lemmatized formats. However, adequate investigation of syntactic complexity requires deeper annotations related to e.g. syntactic parses, subcategorization frames (SCFs), lexical classes and predicateargument structures. Although manual syntactic annotation is possible, it is extremely costly. The alternative is to use natural language processing (NLP) techniques for annota</context>
<context position="7218" citStr="MacWhinney, 2000" startWordPosition="1045" endWordPosition="1046">the future. 2 Subcategorization Acquisition System We used for subcategorization acquisition the new system of Preiss, Briscoe and Korhonen (2007) which is essentially a much improved and extended version of Briscoe and Carroll’s (1997) system. It incorporates 168 SCF distinctions, a superset of those found in the COMLEX Syntax (Grishman et al., 1994) and ANLT (Boguraev et al., 1987) dictionaries. Currently, SCFs abstract over specific lexically governed particles and prepositions and specific predicate selectional 34 3 Data The English (British and American) sections of the CHILDES database (MacWhinney, 2000) were used to create two corpora: 1) CHILD and 2) CDS. Both corpora contained c. 1 million utterances which were selected from the data after some utterances containing un-transcribable sections were removed. Speakers were identified using speaker-id codes within the CHAT transcriptions of the data:3 CHILD contained the utterances of speakers identified as target children; CDS contained input from speakers identified as parents/caretakers. The mean utterance length (measured in words) in CHILD and CDS were 3.48 and 4.61, respectively. The mean age of the child speaker in CHILD is around 3 year</context>
</contexts>
<marker>MacWhinney, 2000</marker>
<rawString>B. MacWhinney. 2000. The CHILDES Project: Tools for Analyzing Talk. Lawrence Erlbaum, Mahwah, NJ, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>J Carroll</author>
</authors>
<title>Disambiguating nouns, verbs, and adjectives using automatically acquired selectional preferences.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="2883" citStr="McCarthy and Carroll, 2003" startWordPosition="411" endWordPosition="414">sufficiently accurate to yield annotations useful for linguistic purposes. They also gather important qualitative and quantitative information, which is difficult for humans to obtain, as a side-effect of the acquisition process. For instance, state-of-the-art statistical parsers, e.g. (Charniak, 2000; Briscoe et al., 2006), have wide coverage and yield grammatical representations capable of supporting various applications (e.g. summarization, information extraction). In addition, lexical information (e.g. subcategorization, lexical classes) can now be acquired automatically from parsed data (McCarthy and Carroll, 2003; Schulte im Walde, 2006; Preiss et al., 2007). This information complements the basic grammatical analysis and provides access to the underlying predicate-argument structure. Containing considerable ellipsis and error, spoken child language can be challenging for current NLP techniques which are typically optimized for written adult language. Yet Sagae et al. (2005) have recently demonstrated that existing statistical parsing techniques can be usefully modified to analyse CHILDES Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 33–40, Prague, Czech</context>
</contexts>
<marker>McCarthy, Carroll, 2003</marker>
<rawString>D. McCarthy and J. Carroll. 2003. Disambiguating nouns, verbs, and adjectives using automatically acquired selectional preferences. Computational Linguistics, 29(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Naigles</author>
</authors>
<title>Children use syntax to learn verb meanings.</title>
<date>1990</date>
<journal>Journal of Child Language,</journal>
<pages>17--357</pages>
<contexts>
<context position="1448" citStr="Naigles, 1990" startWordPosition="213" endWordPosition="214">ate to confirm and extend previously reported research findings. We also report qualitative results which can be used to further improve parsing and lexical acquisition technology for child language data in the future. 1 Introduction Large empirical data containing children’s speech are the key to developing and evaluating different theories of child language acquisition (CLA). Particularly important are data related to syntactic complexity of child language since considerable evidence suggests that syntactic information plays a central role during language acquisition, e.g. (Lenneberg, 1967; Naigles, 1990; Fisher et al., 1994). The standard corpus in the study of CLA is the CHILDES database (MacWhinney, 2000)1 which provides 300MB of transcript data of interactions be1See http://childes.psy.cmu.edu for details. 33 tween children and parents over 25 human languages. CHILDES is currently available in raw, part-of-speechtagged and lemmatized formats. However, adequate investigation of syntactic complexity requires deeper annotations related to e.g. syntactic parses, subcategorization frames (SCFs), lexical classes and predicateargument structures. Although manual syntactic annotation is possible,</context>
</contexts>
<marker>Naigles, 1990</marker>
<rawString>L Naigles. 1990. Children use syntax to learn verb meanings. Journal of Child Language, 17:357–374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pinker</author>
</authors>
<title>The Language Instinct: How the Mind Creates Language. Harper Collins,</title>
<date>1994</date>
<location>New York, NY.</location>
<contexts>
<context position="14865" citStr="Pinker, 1994" startWordPosition="2376" endWordPosition="2377">anked higher in (i) child speech and (ii) child-directed speech. In contrast, adults have a preference for verbs from classes expressing cognitive processes (e.g. remember, suppose, think, wonder, guess, believe, hope, learn) or those that can be related to the education of children, e.g. the WIPE verbs wash, wipe and brush and the PERFORMANCE verbs draw, dance and sing. In contrast to children, adults prefer verbs which express positive actions and feelings (e.g. share, help, love, kiss). It is commonly reported that child CLA is motivated by a wish to communicate desires and emotions, e.g. (Pinker, 1994), but a relative preference in child speech over child-directed speech for certain verb types or verbs expressing negative actions and feelings has not been explicitly shown on such a scale before. While this issue requires further investigation, our findings already demonstrate the value of using large scale corpora in producing novel data and hypotheses for research in CLA. 4.3 SCF Analysis 4.3.1 Quantitative SCF Comparison The average number of SCFs taken by studied verbs in the two corpora proved quite similar. In unfiltered SCF distributions, verbs in CDS took on average a larger number o</context>
</contexts>
<marker>Pinker, 1994</marker>
<rawString>S Pinker. 1994. The Language Instinct: How the Mind Creates Language. Harper Collins, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Preiss</author>
<author>E J Briscoe</author>
<author>A Korhonen</author>
</authors>
<title>A system for large-scale acquisition of verbal, nominal and adjectival subcategorization frames from corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting ofACL,</booktitle>
<location>Prague, Czech Republic.</location>
<note>To appear.</note>
<contexts>
<context position="2929" citStr="Preiss et al., 2007" startWordPosition="419" endWordPosition="422">r linguistic purposes. They also gather important qualitative and quantitative information, which is difficult for humans to obtain, as a side-effect of the acquisition process. For instance, state-of-the-art statistical parsers, e.g. (Charniak, 2000; Briscoe et al., 2006), have wide coverage and yield grammatical representations capable of supporting various applications (e.g. summarization, information extraction). In addition, lexical information (e.g. subcategorization, lexical classes) can now be acquired automatically from parsed data (McCarthy and Carroll, 2003; Schulte im Walde, 2006; Preiss et al., 2007). This information complements the basic grammatical analysis and provides access to the underlying predicate-argument structure. Containing considerable ellipsis and error, spoken child language can be challenging for current NLP techniques which are typically optimized for written adult language. Yet Sagae et al. (2005) have recently demonstrated that existing statistical parsing techniques can be usefully modified to analyse CHILDES Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 33–40, Prague, Czech Republic, June 2007 c�2007 Association for Co</context>
<context position="5905" citStr="Preiss et al. (2007)" startWordPosition="845" endWordPosition="848">omain-specific tuning—to obtain optionally filtered to obtain a more accurate lexicon. large-scale verb subcategorization frequency informa- This is done by setting empirically determined threshtion from CHILDES which is accurate enough to show olds on the relative frequencies of SCFs. differences and similarities between child and adult When evaluated on cross-domain corpora containspeech, and thus be able to provide support for syn- ing mainly adult language, this system achieves 68.9 tactic complexity studies in CLA. F-measure2 in detecting SCF types—a result which We use the new system of Preiss et al. (2007) to compares favourably to those reported with other comextract SCF frequency data from the (i) child and parable SCF acquisition systems. (ii) child-directed speech within CHILDES. We show that the acquired information is sufficiently accurate to confirm and extend previously reported SCF (dis)similarities between the two types of data. In particular, we demonstrate that children and adults have different preferences for certain types of verbs, and that these preferences seem to influence the way children acquire subcategorization. In addition, we report qualitative results which can be used </context>
</contexts>
<marker>Preiss, Briscoe, Korhonen, 2007</marker>
<rawString>J. Preiss, E. J. Briscoe, and A. Korhonen. 2007. A system for large-scale acquisition of verbal, nominal and adjectival subcategorization frames from corpora. In Proceedings of the 45th Annual Meeting ofACL, Prague, Czech Republic. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>A Lavie</author>
<author>B MacWhinney</author>
</authors>
<title>Automatic measurement of syntactic development in child langugage.</title>
<date>2005</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics,</booktitle>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="3252" citStr="Sagae et al. (2005)" startWordPosition="464" endWordPosition="467">tations capable of supporting various applications (e.g. summarization, information extraction). In addition, lexical information (e.g. subcategorization, lexical classes) can now be acquired automatically from parsed data (McCarthy and Carroll, 2003; Schulte im Walde, 2006; Preiss et al., 2007). This information complements the basic grammatical analysis and provides access to the underlying predicate-argument structure. Containing considerable ellipsis and error, spoken child language can be challenging for current NLP techniques which are typically optimized for written adult language. Yet Sagae et al. (2005) have recently demonstrated that existing statistical parsing techniques can be usefully modified to analyse CHILDES Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 33–40, Prague, Czech Republic, June 2007 c�2007 Association for Computational Linguistics with promising accuracy. Although further improve- preferences but include some derived semi-predictable ments are still required for optimal accuracy, this re- bounded dependency constructions, such as particle search has opened up the exciting possibility of auto- and dative movement—this will be</context>
</contexts>
<marker>Sagae, Lavie, MacWhinney, 2005</marker>
<rawString>K. Sagae, A. Lavie, and B. MacWhinney. 2005. Automatic measurement of syntactic development in child langugage. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Schulte im Walde</author>
</authors>
<title>Experiments on the automatic induction of german semantic verb classes.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>2</issue>
<contexts>
<context position="2907" citStr="Walde, 2006" startWordPosition="417" endWordPosition="418">ons useful for linguistic purposes. They also gather important qualitative and quantitative information, which is difficult for humans to obtain, as a side-effect of the acquisition process. For instance, state-of-the-art statistical parsers, e.g. (Charniak, 2000; Briscoe et al., 2006), have wide coverage and yield grammatical representations capable of supporting various applications (e.g. summarization, information extraction). In addition, lexical information (e.g. subcategorization, lexical classes) can now be acquired automatically from parsed data (McCarthy and Carroll, 2003; Schulte im Walde, 2006; Preiss et al., 2007). This information complements the basic grammatical analysis and provides access to the underlying predicate-argument structure. Containing considerable ellipsis and error, spoken child language can be challenging for current NLP techniques which are typically optimized for written adult language. Yet Sagae et al. (2005) have recently demonstrated that existing statistical parsing techniques can be usefully modified to analyse CHILDES Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 33–40, Prague, Czech Republic, June 2007 c�2</context>
</contexts>
<marker>Walde, 2006</marker>
<rawString>S. Schulte im Walde. 2006. Experiments on the automatic induction of german semantic verb classes. Computational Linguistics, 32(2):159–194.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>