<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<affiliation confidence="0.616701166666667">
Impact of Quality and Quantity of Corpora on Stochastic
Generation
John Chen*
Department of Computer
and Information Sciences
University of Delaware
</affiliation>
<address confidence="0.904114">
Newark, DE 19716
</address>
<email confidence="0.984767">
jchen@cis.udel.edu
</email>
<note confidence="0.580049">
Srini vas Bangalore
AT&amp;T Labs — Research
180 Park Ave
Florham Park, NJ 07932
</note>
<bodyText confidence="0.226039">
USA
srini@research . att . com
</bodyText>
<sectionHeader confidence="0.88683" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999868473684211">
Recently, there has been some interest in using
stochastic approaches in generation. However, there
has been little research so far on the question of
how the quality, size, and genre of training corpora
influence the quality of stochastic generation com-
ponents. In this paper, we investigate these issues
using the FERGUS system. FERGUS uses two
distinct stochastic models, a tree model which refers
to a grammar, and a linear language model. We use
automatic grammar extraction techniques to extract
grammars from different-sized tree banks, and then
use these extracted grammars to train the tree mod-
els. We also investigate the impact of the quality of
the annotated corpus, by using a hand-annotated
corpus as well as an automatically annotated cor-
pus. Our results show that automatic grammar ex-
traction is a viable alternative to hand crafted gram-
mars for generation; furthermore, as expected, both
quality and size of the training corpus matter
</bodyText>
<sectionHeader confidence="0.99571" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997079">
Recently, there has been some interest in using
stochastic approaches in generation (Knight and
Hatzivassiloglou, 1995; Langkilde and Knight, 1998;
Langkilde, 2000; Oh and Rudnicky, 2000; Ratna-
parkhi, 2000; Bangalore and Rambow, 2000). For
generation, stochastic methods promise to be supe-
rior to hand-crafted generators in (at least) two dif-
ferent contexts:
</bodyText>
<listItem confidence="0.9723628">
• When the range of output to be generated is
wide, for example in general-purpose machine
translation systems.
• When a generation system needs to be created
very quickly.
</listItem>
<bodyText confidence="0.999629166666667">
However, there has been little research so far on
the question of how the quality, size, and genre of
training corpora influence the quality of stochastic
generation components. These questions are crucial:
for both wide-range output and for rapid develop-
ment, we need to know whether the quality of the
</bodyText>
<note confidence="0.585818333333333">
* This work was done when the author was at AT&amp;T Labs-
Research, Shannon Laboratories, 180 Park Ave, Florham
Park NJ 07932
</note>
<figure confidence="0.2369754">
Owen Rambow
AT&amp;T Labs — Research
180 Park Ave
Florham Park, NJ 07932
USA
</figure>
<email confidence="0.94275">
rambow@research.att.com
</email>
<bodyText confidence="0.999857327868853">
generator can be brought to an adequate level by
increasing the size of the training corpus.
In this paper, we present answers to these ques-
tions using the framework developed for the FER-
GUS system (Bangalore and Rambow, 2000). In
FERGUS, an input dependency tree representing
lexical predicate-argument structure is first anno-
tated for syntactic information using a stochastic
tree model. This syntactic information is in the form
of supertags, i.e., references to trees from a Tree Ad-
joining Grammar (TAG). The dependency tree an-
notated with supertags allows several linearizations;
FERGUS uses a standard linear language model to
choose the best of these linearizations. Note the
presence of two distinct stochastic models, the tree
model which refers to a grammar, and the linear lan-
guage model. As we have shown in previous work,
the use of both models increases the performance of
the system over a version of the system with only one
of the two models. However, the use of two models
comes at a cost: the tree model requires both the ex-
istence of a hand-crafted grammar, and of a corpus
which has been syntactically annotated with refer-
ence to the hand-crafted grammar. If we wish to
generate in new languages, or if we wish to gener-
ate in new sublanguages of previously covered lan-
guages, such an approach is unappealing because of
the required amount of hand-crafting (of grammars
and annotated corpora).
We address this problem by using automatic
grammar extraction techniques. We use the TAG-
extraction algorithm of Chen and Vijay-Shanker
(2000) to extract grammars from different-sized an-
notated corpora, and then use these extracted gram-
mars to train the tree models. While performance
improvements still require the existence of a syntac-
tically annotated corpus, we no longer need a hand-
crafted grammar. Furthermore, we do not even re-
quire that the annotated corpus be hand-annotated:
we use a corpus which has been syntactically anno-
tated by an automatic parser. To our knowledge,
this is the first time that automatically extracted
grammars are used for generation. Using automatic
extraction of generation grammars, we then inves-
tigate the relation between corpus quality and size
on the one hand and output quality on the other
hand by learning different tree and language mod-
els. As expected, our results show that both quality
and size matter, and that the quality of the syntac-
tically annotated corpus can be traded against its
size.
The paper is structured as follows. In Section 2,
we present the grammar extraction algorithm of
Chen and Vijay-Shanker (2000). We then present
our generation system, FERGUS (Section 3). We
investigate the issue of the quality of the training
corpus in Section 4. The issue of size of corpora is
discussed in Section 5 and in Section 6, concentrat-
ing first on small corpora, and then on very large
corpora. We conclude with a summary and an out-
look.
</bodyText>
<sectionHeader confidence="0.8519185" genericHeader="method">
2 Automated TAG Extraction from
Bracketed Corpora
</sectionHeader>
<bodyText confidence="0.999979684210526">
There are a number of approaches for the extraction
of Tree Adjoining Grammars (TAGs) from corpora
annotated in the style of the Penn Treebank (Mar-
cus et al. (1993)), as work by Neumann (1998),
Xia (1999), and Chiang (2000) show. In fact, in
Chen and Vijay-Shanker (2000) alone, no fewer than
eight different kinds of extracted grammars are com-
pared. For the following experiments, we adopt one
out of the many approaches described in Chen and
Vijay-Shanker (2000) which we describe here. As
background, we review useful TAG terminology and
discuss the linguistic principles that guide the for-
mation of both manually constructed TAG gram-
mars and the automatically extracted variety; for a
more complete introduction, see (Abellle and Ram-
bow, 2000). Subsequently, We describe the details
of the grammar extraction algorithm and the mod-
ifications that are required in order to make the al-
gorithm work with different kinds of corpora.
</bodyText>
<subsectionHeader confidence="0.958339">
2.1 Background
</subsectionHeader>
<bodyText confidence="0.999940193548387">
A TAG G is defined as a set of elementary trees
T which are partitioned into a set I of initial trees
and a set A of auxiliary trees. If GC is lexical-
ized, the frontier of each elementary tree includes a
lexical anchor; the other nodes on the frontier are
substitution nodes, and in the case of an auxiliary
tree, one node on the frontier will be a foot node.
The foot node of a tree /3 is labeled identically with
the root node of /3. The spine of an auxiliary tree
is the path from its root to its foot node. It is to be
distinguished from the trunk of an elementary tree
which is the path from its root node to the lexical
anchor.
Although the formalism of TAG allows wide lat-
itude in how trees in T may be defined, several
linguistic principles generally guide their formation.
First, dependencies including long distance depen-
dencies are typically localized in the same elemen-
tary tree by appropriate grouping of syntactically
or semantically related elements; i.e. positions for
complements of a lexical item are included in the
same tree as the lexical item, as shown in Fig-
ure 1(b). Second, recursion is factored into sepa-
rate auxiliary trees. There are modifier auxiliary
trees which generally represent syntactic adjuncts;
the foot nodes in these trees represent the objects
of modification as shown in Figure 1(c). There are
also predicative auxiliary trees; the foot nodes in
these trees represent sentential complements. They
are used (rather than initial trees) in order to handle
long-distance extraction.
</bodyText>
<subsectionHeader confidence="0.932378">
2.2 Extraction from the Penn Treebank
</subsectionHeader>
<bodyText confidence="0.999963772727273">
Given a bracketed sentence S in the corpus, an ele-
mentary tree -y lexicalized by a word w E S is created
as follows. First, a head percolation table is used
to determine the trunk of -y. Introduced in Mager-
man (1995), a head percolation table assigns to each
node in S a headword using local structural infor-
mation. The trunk of -y is defined to be that path
through the tree for S whose nodes are labeled with
syntactic projections from the headword w. See Fig-
ure 2(a). Each node 77&apos; that is immediately domi-
nated by a node 77 on the trunk of -y may either be
itself on the trunk, a complement of w, or an adjunct
of w. If 77&apos; is a complement of w, then the node is
made into a substitution node of -y. (The subtree
rooted at 7)&apos; will be associated with a different head-
word, that of the complement.) If 77&apos; is an adjunct
of w, then it belongs to another (auxiliary) tree /3
which modifies -y.
It is therefore necessary to determine a node&apos;s sta-
tus as either complement or adjunct. The procedure
used by our algorithm is based on a similar one that
is used by Collins (1997). Like Collins (1997), it
bases its decision on the node&apos;s label, its semantic
tags (see Marcus et al. (1993)), and local structural
information. For example, a node that is labeled
NP-DIR would be labeled as an adjunct because of
the semantic tag DIR, signifying an adverbial that
answers the questions &amp;quot;from where?&amp;quot; or &amp;quot;to where?&amp;quot;
The main difference lies in our attempt to use lexical
predicate-argument structure as a basis for deter-
mining the shape of the trees in our grammar. For
instance, wh-moved constituents are treated by our
procedure as complements of their head and there-
fore positions for moved elements may be included in
verbal trees. Our procedure operates in two steps.
In the first step, the label and semantic tags of a
node 77 and the parent node of 77 are used as an index
into a manually constructed complement-adjunct
table which determines complement or adjunct sta-
tus. The table is sparse; should the index not be
found in the table then the second step of the pro-
cedure is invoked. This second step uses only the
semantic tags of node 77 to determine the comple-
ment or adjunct status. Should 77 lack any semantic
</bodyText>
<figure confidence="0.955038930555555">
soared
Prices
also
(c)
(a) (b)
substitution node
φ
VP
η
2
η1
S
VP
ADVP
NP-C
ADVP S
NP
NN
ADVP VP
RB
NN RB
RB
V
fell
stocks
rapidly
Yesterday stocks rapidly fell Yesterday
S
ADVP
V RB
S
NP VP
S
S
VP
NP
A
V
NP
A
N
VP
VP
V
NP
N
soared
Prices also
foot node
VP
VP
(a) (b)
TAG Derivation Tree
without Supertags
Tree Chooser
Tree
Model
One single semi-specified
TAG Derivation Trees
Unraveler
XTAG
Grammar
Word Lattice
LP Chooser
Language
Model
String
estimate
there
was no cost for
phase
the second
</figure>
<table confidence="0.996601285714286">
Grammar Size of Grammar StringAccuracy
Penn Treebank 444 0.742
(XTAG)
Penn Treebank 3063 0.749
(Extracted)
BLLIP Treebank 3763 0.727
(Extracted)
</table>
<tableCaption confidence="0.9236365">
Table 1: Results from FERGUS on training on 1 million words of annotated corpus with different qualities
of annotation
</tableCaption>
<bodyText confidence="0.999773772727273">
strings represented by each level of the derivation
tree. The lattice at the root of the derivation tree is
the result of the Unraveler.
Finally, the LP Chooser chooses the most likely
traversal of this lattice, given a linear language
model (n-gram). The lattice output from the Un-
raveler encodes all possible word sequences permit-
ted by the supertagged dependency structure. We
rank these word sequences in the order of their likeli-
hood by composing the lattice with a finite-state ma-
chine representing a trigram language model which
has been trained on an unannotated corpus, the
language model corpus. We pick the best path
through the lattice resulting from the composition
using the Viterbi algorithm, and this top ranking
word sequence is the output of the LP Chooser and
the generator. We evaluate the results of our gen-
erator by using the string-edit distance from a ref-
erence string. For a detailed discussion on evalua-
tion for FERGUS, including the limitations of the
string-edit distance and proposals for other evalua-
tion metrics, see (Bangalore et al., 2000).
</bodyText>
<sectionHeader confidence="0.935327" genericHeader="method">
4 Quality of Annotated Corpora
</sectionHeader>
<bodyText confidence="0.999986462686568">
The tree model in FERGUS is a stochastic model
that assigns supertags to the nodes of the input
derivation tree. The parameters of this model are es-
timated from a training corpus of annotated deriva-
tion trees, where each node is annotated with a su-
pertag from the grammar. The performance of the
tree model depends on two aspects: the grammar
which they refer to and the quality of annotation of
the corpus. In this section, we discuss the impact of
these aspects on the performance of FERGUS.
In order to investigate the impact of the qual-
ity of the grammar on the tree model, we used the
supertags of the XTAG grammar (XTAG-Group,
1999) and the supertags of a grammar extracted au-
tomatically from the Penn Treebank as described
above in Section 2. The grammar from XTAG con-
tains 444 supertags while the extracted grammar
contains 3063 supertags. Two tree models were
trained on the two versions of the same one million
word corpus annotated with the two supertag sets.
The performance of FERGUS using these two tree
models but with the same language model is shown
in rows one and two of Table 1. It is interesting to
note that the performance of FERGUS using the
extracted grammar is as good as2 the performance
using the XTAG grammar. The supertag-annotated
corpus based on the extracted grammar is more con-
sistent than the supertag annotated corpus based
on the XTAG grammar. This is because the Penn
Treebank and the XTAG grammar were developed
independently of each other, and as a result the an-
notations in the PTB and the structures in XTAG
are not congruent. As a result, assigning supertags
to the items in the PTB is based on heuristics, which
are often but not always correct. This suggests that
in future, grammars and treebanks should be devel-
oped so as to maintain this congruence.
In order to investigate the impact of the qual-
ity of the annotated corpus, we compared the tree
model trained on the Penn Treebank with the gram-
mar extracted from the PTB against a tree model
trained on the BLLIP Treebank (BTB) (Charniak,
2000), with the grammar extracted from the BTB.
The BLLIP Treebank has been automatically an-
notated with a statistical parser (Charniak, 2000).
We automatically extracted grammars from one mil-
lion words of each corpus. As mentioned earlier, the
grammar from the PTB has 3063 supertags, while
the BTB-extracted grammar has 3763 supertags.
The performance of FERGUS using these two tree
models but with the same language model is shown
in rows two and three of Table 1. As expected,
the performance of the tree model trained on the
BTB is worse than that of the model trained on the
PTB. However, the attraction of this model is that it
was trained on automatically annotated corpus and
hence it is straightforward to increase the quantity
of the corpus. The impact of the increase in quantity
of the corpus is illustrated in Section 6.
Our test suite is annotated for predicate-argument
structure independently of the grammar being used
for generation (we use the same test suite in all ex-
periments reported in this paper). As the figures
in Table 1 show, the performance of the automati-
cally extracted grammars is comparable to that of
the hand-crafted TAG. This means that the gram-
mars automatically extracted from the PTB and
</bodyText>
<footnote confidence="0.935026">
2Even slightly better, but that may not be significant.
</footnote>
<table confidence="0.994160875">
5K LM 10K LM 50K LM 100K LM 500K LM 1M LM
OK TM 0.434 0.480 0.561 0.599 0.661 0.701
5K TM 0.497 0.530 0.540 0.595 0.626 0.642
10K TM 0.507 0.574 0.542 0.651 0.672 0.690
50K TM 0.561 0.596 0.603 0.623 0.707 0.738
100K TM 0.563 0.595 0.610 0.644 0.697 0.729
500K TM 0.587 0.649 0.667 0.671 0.730 0.751
1M TM 0.600 0.627 0.645 0.658 0.738 0.750
</table>
<tableCaption confidence="0.9869385">
Table 2: Results from FERGUS on training on Penn Tree Bank tree models (y axis) and linear language
models (x axis) of different sizes
</tableCaption>
<bodyText confidence="0.99897947826087">
from the BTB not only account for the phrase struc-
tures found in these corpora, but also derive these
phrase structures in a linguistically plausible man-
ner (as we would expect from a hand-crafted TAG),
so that the input derivation structures in the test
suite can be used as derivation structures in those ex-
tracted grammars. This should be contrasted with,
for instance, the approach chosen in Data-Oriented
Parsing (Bod, 1998), where phrase structure is cut
up into pieces which are not motivated by linguistic
considerations. As a consequence, it is not clear how
a grammar of the type extracted in DOP could be
used for generation.
A point worth noting is that a TAG grammar
such as XTAG contains not only information that
maps predicate-argument to syntax, as do the auto-
matically extracted grammars, but also information
about grammatical roles (deep subject, deep object,
modifier, and so on).3 The impact of this informa-
tion on the performance is not tested in the exper-
iments presented here since the input is always as-
sumed to be an unannotated dependency tree with-
out role information.
</bodyText>
<sectionHeader confidence="0.96504" genericHeader="method">
5 Small Corpora
</sectionHeader>
<bodyText confidence="0.999955294117647">
In this section, we investigate the effect of resource
size when relatively small amounts of data (one mil-
lion words or fewer) are available. This is a typical
situation when a new generator is needed, either for
a new domain or for a new language. Unfortunately,
for the purpose of our investigation we need to resort
to the English Penn Treebank (PTB), since we did
not have access to any other tree bank of sufficiently
large size (neither for a new domain in English, nor
for a new language).
We assume that no hand-crafted grammar is avail-
able and that we will work with extracted grammars.
We vary both the size of the syntactically annotated
corpus from which the grammar is extracted and on
which the tree model is trained (the &amp;quot;TM corpus&amp;quot;),
and the size of the unannotated corpus on which the
linear language model is trained (the &amp;quot;LM corpus&amp;quot;).
</bodyText>
<footnote confidence="0.6241465">
3This information might be extractable from annotated
treebank as well.
</footnote>
<bodyText confidence="0.982870052631579">
The results are shown in Table 2 and garphically in
Figure 5. In this graph, each plot represents an LM
corpus of a fixed size; the x-axis shows the natural
logarithm of the size of the TM corpus, and the y-
axis shows the string accuracy. Needless to say, the
corpora for training the language model are easier
to come by, and in practical terms it is inconceiv-
able that the LM corpus would be smaller than the
TM corpus, but we give all figures for the sake of
completeness.
There are several conclusions to be drawn from
these results.
• By and large, more is better: with the size of
one model fixed, increasing the size of the other
model also increases the quality of the output.
There seems to be, however, a leveling-off ef-
fect at a TM corpus size of 500K, with little
improvement when the TM corpus is doubled
to 1M. Presumably, this is because of the in-
crease in grammar size from the larger TM, the
stochastic tree model becomes less precise.
• We see that the tree model contributes to the
quality of the output starting with tree models
of size 10K words; the 5K TM does not have a
great impact on quality, except for the smaller
language models. In fact, it appears that the
tree model must be at least a tenth the size of
the language model in order to have a positive
impact.
• On the face of it, the impact of increasing the
size of the LM is greater than the impact of
increased TM: for example, if we have a 5K TM
corpus and a 5K LM corpus with a performance
of 0.497, we are better off increasing the LM
corpus to 1M (0.642) than the TM corpus to 1M
(0.600). Of course, this is an unrealistic trade-
off, as the LM corpus will in practice always be
at least as large as the TM corpus.
</bodyText>
<listItem confidence="0.80380175">
• More practically, if we have a LM corpus, it is
worthwhile to increase the TM corpus to the
size of the LM corpus, i.e., to annotate the en-
tire LM corpus syntactically.
</listItem>
<figure confidence="0.9827114375">
String Accuracy x 10-3
0.00 2.00 4.00 6.00
log of TM size
5K LM
10K LM
50K LM
100K LM
500K LM
1M LM
750.00
700.00
650.00
600.00
550.00
500.00
450.00
</figure>
<bodyText confidence="0.999152">
the emphasis of the work reported in this sec-
tion has been the use of TM corpora of different
sizes.
</bodyText>
<sectionHeader confidence="0.98856" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.8843264">
We have shown that automatically extracted gram-
mars can be used in syntactic generation. We have
found:
• An automatically extracted grammar can per-
form as well as a hand-crafted grammar, pre-
sumably because the corpus annotation is not
perfect in case the hand-crafted grammar does
not match the hand-crafted corpus. (This prob-
lem can be overcome by developing grammars
and corpora in parallel.)
• Even a small amount of syntactically annotated
data for grammar extraction improves perfor-
mance over a system based solely on a linear
language model, though the tree model corpus
should be at least a tenth the size of the lan-
guage model corpus.
• If no syntactically annotated corpus is available,
but a high-performance parser is, a much larger
corpus can compensate for the lower quality of
the automatically annotated corpus.
This paper is about the relation between available
corpora and generation quality when automatically
extracting grammars. We observe, however, that
generation may provide a general test-bed for evalu-
ating the quality of grammars in a more application-
independent manner. Generation is the mapping
of a lexical (or semantic) predicate-argument struc-
ture to a surface string. The grammars that we
use in FERGUS are Tree-Adjoining Grammars, i.e.,
declarative grammars which are independent of any
application such as parsing or generation. We are
thus assessing the ability of our grammars to map
between surface string and some sort of meaning rep-
resentation - which is exactly what grammar is gen-
erally assumed to do.
</bodyText>
<sectionHeader confidence="0.998776" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998549956521739">
Anne Abeille and Owen Rainbow. 2000. Tree Adjoining
Grammar: An overview. In Anne Abeille and Owen
Rambow, editors, Tree Adjoining Grammars: For-
malisms, Linguistic Analyses and Processing, pages
1-68. CSLI Publications.
Srinivas Bangalore and Aravind Joshi. 1999. Supertag-
ging: An approach to almost parsing. Computational
Linguistics, 25(2):237-266.
Srinivas Bangalore and Owen Rambow. 2000. Exploit-
ing a probabilistic hierarchical model for generation.
In COLING2000, Saarbriicken, Germany.
Srinivas Bangalore, Owen Rainbow, and Steve Whit-
taker. 2000. Evaluation Metrics for Generation. In
Proceedings of International Conference on Natural
Language Generation, Mitzpe Ramon, Isreal.
Rens Bod. 1998. Beyond Grammar: An experience-
based theory of language. CSLI Publications, Cam-
bridge University Press.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the ANL/NAACL 2000
Workshop on Conversational Systems, Seattle. ACL.
John Chen and K. Vijay-Shanker. 2000. Automated ex-
traction of tags from the penn treebank. In Proceed-
ings of the Sixth International Workshop on Parsing
Technologies, pages 65-76.
David Chiang. 2000. Statistical parsing with an
automatically-extracted tree adjoining grammar. In
Proceedings of the the 38th Annual Meeting of the As-
sociation for Computational Linguistics, pages 456-
463, Hong Kong.
Michael Collins. 1997. Three generative lexicalized mod-
els for statistical parsing. In Proceedings of the 35th
Annual Meeting of the Association for Computational
Linguistics.
Kevin Knight and V. Hatzivassiloglou. 1995. Two-
level many paths generation. In Proceedings of ACL,
Boston. ACL.
Irene Langkilde and Kevin Knight. 1998. Generation
that exploits corpus-based statistical knowledge. In
ac198, pages 704-710, Montréal, Canada.
Irene Langkilde. 2000. Forest-based statistical sentence
generation. In ANLPOO, pages 170-177, Seattle, WA.
David M. Magerman. 1995. Statistical decision-tree
models for parsing. In Proceedings of the 33th Annual
Meeting of the Association for Computational Linguis-
tics.
Mitchell Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of english: the penn treebank. Computational
Linguistics, 19(2):313-330.
Gunter Neumann. 1998. Automatic extraction of
stochastic lexicalized tree grammars from treebanks.
In Proceedings of the Fourth International Workshop
on Tree Adjoining Grammars and Related Frame-
works, pages 120-123.
Alice H. Oh and Alexander I. Rudnicky. 2000. Stochas-
tic language generation for spoken dialog systems. In
Proceedings of the ANL/NAACL 2000 Workshop on
Conversational Systems, pages 27-32, Seattle. ACL.
Adwait Ratnaparkhi. 2000. Trainable methods for sur-
face natural language generation. In Proceedings of
First North American ACL, Seattle, USA, May.
Fei Xia. 1999. Extracting tree adjoining grammars from
bracketed corpora. In Fifth Natural Language Pro-
cessing Pacific Rim Symposium (NLPRS-99), Beijing,
China.
The XTAG-Group. 1999. A lexicalized Tree Ad-
joining Grammar for English. Technical Report
http://www.cis.upenn.edu/-xtag/tech-report/
</reference>
<affiliation confidence="0.645782">
tech-report.html, The Institute for Research in
Cognitive Science, University of Pennsylvania.
</affiliation>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.357128">
<title confidence="0.9971465">Impact of Quality and Quantity of Corpora on Stochastic Generation</title>
<author confidence="0.991994">John</author>
<affiliation confidence="0.9341635">Department of and Information University of Newark, DE</affiliation>
<email confidence="0.998625">jchen@cis.udel.edu</email>
<author confidence="0.966791">Srini vas</author>
<affiliation confidence="0.972965">AT&amp;T Labs —</affiliation>
<address confidence="0.9615465">180 Park Florham Park, NJ</address>
<email confidence="0.940861">srini@research.att.com</email>
<abstract confidence="0.97885855">Recently, there has been some interest in using stochastic approaches in generation. However, there has been little research so far on the question of how the quality, size, and genre of training corpora influence the quality of stochastic generation components. In this paper, we investigate these issues using the FERGUS system. FERGUS uses two distinct stochastic models, a tree model which refers to a grammar, and a linear language model. We use automatic grammar extraction techniques to extract grammars from different-sized tree banks, and then use these extracted grammars to train the tree models. We also investigate the impact of the quality of the annotated corpus, by using a hand-annotated corpus as well as an automatically annotated corpus. Our results show that automatic grammar extraction is a viable alternative to hand crafted grammars for generation; furthermore, as expected, both quality and size of the training corpus matter</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeille</author>
<author>Owen Rainbow</author>
</authors>
<title>Tree Adjoining Grammar: An overview.</title>
<date>2000</date>
<booktitle>In Anne Abeille and Owen Rambow, editors, Tree Adjoining Grammars: Formalisms, Linguistic Analyses and Processing,</booktitle>
<pages>1--68</pages>
<publisher>CSLI Publications.</publisher>
<marker>Abeille, Rainbow, 2000</marker>
<rawString>Anne Abeille and Owen Rainbow. 2000. Tree Adjoining Grammar: An overview. In Anne Abeille and Owen Rambow, editors, Tree Adjoining Grammars: Formalisms, Linguistic Analyses and Processing, pages 1-68. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Aravind Joshi</author>
</authors>
<title>Supertagging: An approach to almost parsing.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<pages>25--2</pages>
<marker>Bangalore, Joshi, 1999</marker>
<rawString>Srinivas Bangalore and Aravind Joshi. 1999. Supertagging: An approach to almost parsing. Computational Linguistics, 25(2):237-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Owen Rambow</author>
</authors>
<title>Exploiting a probabilistic hierarchical model for generation.</title>
<date>2000</date>
<booktitle>In COLING2000,</booktitle>
<location>Saarbriicken, Germany.</location>
<contexts>
<context position="1503" citStr="Bangalore and Rambow, 2000" startWordPosition="229" endWordPosition="232">rammars to train the tree models. We also investigate the impact of the quality of the annotated corpus, by using a hand-annotated corpus as well as an automatically annotated corpus. Our results show that automatic grammar extraction is a viable alternative to hand crafted grammars for generation; furthermore, as expected, both quality and size of the training corpus matter 1 Introduction Recently, there has been some interest in using stochastic approaches in generation (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998; Langkilde, 2000; Oh and Rudnicky, 2000; Ratnaparkhi, 2000; Bangalore and Rambow, 2000). For generation, stochastic methods promise to be superior to hand-crafted generators in (at least) two different contexts: • When the range of output to be generated is wide, for example in general-purpose machine translation systems. • When a generation system needs to be created very quickly. However, there has been little research so far on the question of how the quality, size, and genre of training corpora influence the quality of stochastic generation components. These questions are crucial: for both wide-range output and for rapid development, we need to know whether the quality of th</context>
</contexts>
<marker>Bangalore, Rambow, 2000</marker>
<rawString>Srinivas Bangalore and Owen Rambow. 2000. Exploiting a probabilistic hierarchical model for generation. In COLING2000, Saarbriicken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Owen Rainbow</author>
<author>Steve Whittaker</author>
</authors>
<title>Evaluation Metrics for Generation.</title>
<date>2000</date>
<booktitle>In Proceedings of International Conference on Natural Language Generation,</booktitle>
<location>Mitzpe Ramon, Isreal.</location>
<contexts>
<context position="11830" citStr="Bangalore et al., 2000" startWordPosition="1999" endWordPosition="2002">ng the lattice with a finite-state machine representing a trigram language model which has been trained on an unannotated corpus, the language model corpus. We pick the best path through the lattice resulting from the composition using the Viterbi algorithm, and this top ranking word sequence is the output of the LP Chooser and the generator. We evaluate the results of our generator by using the string-edit distance from a reference string. For a detailed discussion on evaluation for FERGUS, including the limitations of the string-edit distance and proposals for other evaluation metrics, see (Bangalore et al., 2000). 4 Quality of Annotated Corpora The tree model in FERGUS is a stochastic model that assigns supertags to the nodes of the input derivation tree. The parameters of this model are estimated from a training corpus of annotated derivation trees, where each node is annotated with a supertag from the grammar. The performance of the tree model depends on two aspects: the grammar which they refer to and the quality of annotation of the corpus. In this section, we discuss the impact of these aspects on the performance of FERGUS. In order to investigate the impact of the quality of the grammar on the t</context>
</contexts>
<marker>Bangalore, Rainbow, Whittaker, 2000</marker>
<rawString>Srinivas Bangalore, Owen Rainbow, and Steve Whittaker. 2000. Evaluation Metrics for Generation. In Proceedings of International Conference on Natural Language Generation, Mitzpe Ramon, Isreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rens Bod</author>
</authors>
<title>Beyond Grammar: An experiencebased theory of language.</title>
<date>1998</date>
<publisher>CSLI Publications, Cambridge University Press.</publisher>
<contexts>
<context position="16090" citStr="Bod, 1998" startWordPosition="2744" endWordPosition="2745">751 1M TM 0.600 0.627 0.645 0.658 0.738 0.750 Table 2: Results from FERGUS on training on Penn Tree Bank tree models (y axis) and linear language models (x axis) of different sizes from the BTB not only account for the phrase structures found in these corpora, but also derive these phrase structures in a linguistically plausible manner (as we would expect from a hand-crafted TAG), so that the input derivation structures in the test suite can be used as derivation structures in those extracted grammars. This should be contrasted with, for instance, the approach chosen in Data-Oriented Parsing (Bod, 1998), where phrase structure is cut up into pieces which are not motivated by linguistic considerations. As a consequence, it is not clear how a grammar of the type extracted in DOP could be used for generation. A point worth noting is that a TAG grammar such as XTAG contains not only information that maps predicate-argument to syntax, as do the automatically extracted grammars, but also information about grammatical roles (deep subject, deep object, modifier, and so on).3 The impact of this information on the performance is not tested in the experiments presented here since the input is always as</context>
</contexts>
<marker>Bod, 1998</marker>
<rawString>Rens Bod. 1998. Beyond Grammar: An experiencebased theory of language. CSLI Publications, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the ANL/NAACL 2000 Workshop on Conversational Systems,</booktitle>
<publisher>ACL.</publisher>
<location>Seattle.</location>
<contexts>
<context position="13905" citStr="Charniak, 2000" startWordPosition="2366" endWordPosition="2367"> grammar were developed independently of each other, and as a result the annotations in the PTB and the structures in XTAG are not congruent. As a result, assigning supertags to the items in the PTB is based on heuristics, which are often but not always correct. This suggests that in future, grammars and treebanks should be developed so as to maintain this congruence. In order to investigate the impact of the quality of the annotated corpus, we compared the tree model trained on the Penn Treebank with the grammar extracted from the PTB against a tree model trained on the BLLIP Treebank (BTB) (Charniak, 2000), with the grammar extracted from the BTB. The BLLIP Treebank has been automatically annotated with a statistical parser (Charniak, 2000). We automatically extracted grammars from one million words of each corpus. As mentioned earlier, the grammar from the PTB has 3063 supertags, while the BTB-extracted grammar has 3763 supertags. The performance of FERGUS using these two tree models but with the same language model is shown in rows two and three of Table 1. As expected, the performance of the tree model trained on the BTB is worse than that of the model trained on the PTB. However, the attrac</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of the ANL/NAACL 2000 Workshop on Conversational Systems, Seattle. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Chen</author>
<author>K Vijay-Shanker</author>
</authors>
<title>Automated extraction of tags from the penn treebank.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth International Workshop on Parsing Technologies,</booktitle>
<pages>65--76</pages>
<contexts>
<context position="3878" citStr="Chen and Vijay-Shanker (2000)" startWordPosition="621" endWordPosition="624"> with only one of the two models. However, the use of two models comes at a cost: the tree model requires both the existence of a hand-crafted grammar, and of a corpus which has been syntactically annotated with reference to the hand-crafted grammar. If we wish to generate in new languages, or if we wish to generate in new sublanguages of previously covered languages, such an approach is unappealing because of the required amount of hand-crafting (of grammars and annotated corpora). We address this problem by using automatic grammar extraction techniques. We use the TAGextraction algorithm of Chen and Vijay-Shanker (2000) to extract grammars from different-sized annotated corpora, and then use these extracted grammars to train the tree models. While performance improvements still require the existence of a syntactically annotated corpus, we no longer need a handcrafted grammar. Furthermore, we do not even require that the annotated corpus be hand-annotated: we use a corpus which has been syntactically annotated by an automatic parser. To our knowledge, this is the first time that automatically extracted grammars are used for generation. Using automatic extraction of generation grammars, we then investigate the</context>
<context position="5548" citStr="Chen and Vijay-Shanker (2000)" startWordPosition="901" endWordPosition="904">t our generation system, FERGUS (Section 3). We investigate the issue of the quality of the training corpus in Section 4. The issue of size of corpora is discussed in Section 5 and in Section 6, concentrating first on small corpora, and then on very large corpora. We conclude with a summary and an outlook. 2 Automated TAG Extraction from Bracketed Corpora There are a number of approaches for the extraction of Tree Adjoining Grammars (TAGs) from corpora annotated in the style of the Penn Treebank (Marcus et al. (1993)), as work by Neumann (1998), Xia (1999), and Chiang (2000) show. In fact, in Chen and Vijay-Shanker (2000) alone, no fewer than eight different kinds of extracted grammars are compared. For the following experiments, we adopt one out of the many approaches described in Chen and Vijay-Shanker (2000) which we describe here. As background, we review useful TAG terminology and discuss the linguistic principles that guide the formation of both manually constructed TAG grammars and the automatically extracted variety; for a more complete introduction, see (Abellle and Rambow, 2000). Subsequently, We describe the details of the grammar extraction algorithm and the modifications that are required in order</context>
</contexts>
<marker>Chen, Vijay-Shanker, 2000</marker>
<rawString>John Chen and K. Vijay-Shanker. 2000. Automated extraction of tags from the penn treebank. In Proceedings of the Sixth International Workshop on Parsing Technologies, pages 65-76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Statistical parsing with an automatically-extracted tree adjoining grammar.</title>
<date>2000</date>
<booktitle>In Proceedings of the the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>456--463</pages>
<location>Hong Kong.</location>
<contexts>
<context position="5500" citStr="Chiang (2000)" startWordPosition="895" endWordPosition="896">y-Shanker (2000). We then present our generation system, FERGUS (Section 3). We investigate the issue of the quality of the training corpus in Section 4. The issue of size of corpora is discussed in Section 5 and in Section 6, concentrating first on small corpora, and then on very large corpora. We conclude with a summary and an outlook. 2 Automated TAG Extraction from Bracketed Corpora There are a number of approaches for the extraction of Tree Adjoining Grammars (TAGs) from corpora annotated in the style of the Penn Treebank (Marcus et al. (1993)), as work by Neumann (1998), Xia (1999), and Chiang (2000) show. In fact, in Chen and Vijay-Shanker (2000) alone, no fewer than eight different kinds of extracted grammars are compared. For the following experiments, we adopt one out of the many approaches described in Chen and Vijay-Shanker (2000) which we describe here. As background, we review useful TAG terminology and discuss the linguistic principles that guide the formation of both manually constructed TAG grammars and the automatically extracted variety; for a more complete introduction, see (Abellle and Rambow, 2000). Subsequently, We describe the details of the grammar extraction algorithm </context>
</contexts>
<marker>Chiang, 2000</marker>
<rawString>David Chiang. 2000. Statistical parsing with an automatically-extracted tree adjoining grammar. In Proceedings of the the 38th Annual Meeting of the Association for Computational Linguistics, pages 456-463, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative lexicalized models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8858" citStr="Collins (1997)" startWordPosition="1487" endWordPosition="1488">ure 2(a). Each node 77&apos; that is immediately dominated by a node 77 on the trunk of -y may either be itself on the trunk, a complement of w, or an adjunct of w. If 77&apos; is a complement of w, then the node is made into a substitution node of -y. (The subtree rooted at 7)&apos; will be associated with a different headword, that of the complement.) If 77&apos; is an adjunct of w, then it belongs to another (auxiliary) tree /3 which modifies -y. It is therefore necessary to determine a node&apos;s status as either complement or adjunct. The procedure used by our algorithm is based on a similar one that is used by Collins (1997). Like Collins (1997), it bases its decision on the node&apos;s label, its semantic tags (see Marcus et al. (1993)), and local structural information. For example, a node that is labeled NP-DIR would be labeled as an adjunct because of the semantic tag DIR, signifying an adverbial that answers the questions &amp;quot;from where?&amp;quot; or &amp;quot;to where?&amp;quot; The main difference lies in our attempt to use lexical predicate-argument structure as a basis for determining the shape of the trees in our grammar. For instance, wh-moved constituents are treated by our procedure as complements of their head and therefore positions</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three generative lexicalized models for statistical parsing. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>Twolevel many paths generation.</title>
<date>1995</date>
<booktitle>In Proceedings of ACL,</booktitle>
<publisher>ACL.</publisher>
<location>Boston.</location>
<contexts>
<context position="1387" citStr="Knight and Hatzivassiloglou, 1995" startWordPosition="212" endWordPosition="215">utomatic grammar extraction techniques to extract grammars from different-sized tree banks, and then use these extracted grammars to train the tree models. We also investigate the impact of the quality of the annotated corpus, by using a hand-annotated corpus as well as an automatically annotated corpus. Our results show that automatic grammar extraction is a viable alternative to hand crafted grammars for generation; furthermore, as expected, both quality and size of the training corpus matter 1 Introduction Recently, there has been some interest in using stochastic approaches in generation (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998; Langkilde, 2000; Oh and Rudnicky, 2000; Ratnaparkhi, 2000; Bangalore and Rambow, 2000). For generation, stochastic methods promise to be superior to hand-crafted generators in (at least) two different contexts: • When the range of output to be generated is wide, for example in general-purpose machine translation systems. • When a generation system needs to be created very quickly. However, there has been little research so far on the question of how the quality, size, and genre of training corpora influence the quality of stochastic generation components. These qu</context>
</contexts>
<marker>Knight, Hatzivassiloglou, 1995</marker>
<rawString>Kevin Knight and V. Hatzivassiloglou. 1995. Twolevel many paths generation. In Proceedings of ACL, Boston. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In ac198,</booktitle>
<pages>704--710</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="1415" citStr="Langkilde and Knight, 1998" startWordPosition="216" endWordPosition="219">ues to extract grammars from different-sized tree banks, and then use these extracted grammars to train the tree models. We also investigate the impact of the quality of the annotated corpus, by using a hand-annotated corpus as well as an automatically annotated corpus. Our results show that automatic grammar extraction is a viable alternative to hand crafted grammars for generation; furthermore, as expected, both quality and size of the training corpus matter 1 Introduction Recently, there has been some interest in using stochastic approaches in generation (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998; Langkilde, 2000; Oh and Rudnicky, 2000; Ratnaparkhi, 2000; Bangalore and Rambow, 2000). For generation, stochastic methods promise to be superior to hand-crafted generators in (at least) two different contexts: • When the range of output to be generated is wide, for example in general-purpose machine translation systems. • When a generation system needs to be created very quickly. However, there has been little research so far on the question of how the quality, size, and genre of training corpora influence the quality of stochastic generation components. These questions are crucial: for bot</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. 1998. Generation that exploits corpus-based statistical knowledge. In ac198, pages 704-710, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
</authors>
<title>Forest-based statistical sentence generation.</title>
<date>2000</date>
<booktitle>In ANLPOO,</booktitle>
<pages>170--177</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="1432" citStr="Langkilde, 2000" startWordPosition="220" endWordPosition="221"> different-sized tree banks, and then use these extracted grammars to train the tree models. We also investigate the impact of the quality of the annotated corpus, by using a hand-annotated corpus as well as an automatically annotated corpus. Our results show that automatic grammar extraction is a viable alternative to hand crafted grammars for generation; furthermore, as expected, both quality and size of the training corpus matter 1 Introduction Recently, there has been some interest in using stochastic approaches in generation (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998; Langkilde, 2000; Oh and Rudnicky, 2000; Ratnaparkhi, 2000; Bangalore and Rambow, 2000). For generation, stochastic methods promise to be superior to hand-crafted generators in (at least) two different contexts: • When the range of output to be generated is wide, for example in general-purpose machine translation systems. • When a generation system needs to be created very quickly. However, there has been little research so far on the question of how the quality, size, and genre of training corpora influence the quality of stochastic generation components. These questions are crucial: for both wide-range outp</context>
</contexts>
<marker>Langkilde, 2000</marker>
<rawString>Irene Langkilde. 2000. Forest-based statistical sentence generation. In ANLPOO, pages 170-177, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Magerman</author>
</authors>
<title>Statistical decision-tree models for parsing.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7999" citStr="Magerman (1995)" startWordPosition="1320" endWordPosition="1322">e modifier auxiliary trees which generally represent syntactic adjuncts; the foot nodes in these trees represent the objects of modification as shown in Figure 1(c). There are also predicative auxiliary trees; the foot nodes in these trees represent sentential complements. They are used (rather than initial trees) in order to handle long-distance extraction. 2.2 Extraction from the Penn Treebank Given a bracketed sentence S in the corpus, an elementary tree -y lexicalized by a word w E S is created as follows. First, a head percolation table is used to determine the trunk of -y. Introduced in Magerman (1995), a head percolation table assigns to each node in S a headword using local structural information. The trunk of -y is defined to be that path through the tree for S whose nodes are labeled with syntactic projections from the headword w. See Figure 2(a). Each node 77&apos; that is immediately dominated by a node 77 on the trunk of -y may either be itself on the trunk, a complement of w, or an adjunct of w. If 77&apos; is a complement of w, then the node is made into a substitution node of -y. (The subtree rooted at 7)&apos; will be associated with a different headword, that of the complement.) If 77&apos; is an a</context>
</contexts>
<marker>Magerman, 1995</marker>
<rawString>David M. Magerman. 1995. Statistical decision-tree models for parsing. In Proceedings of the 33th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: the penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="5441" citStr="Marcus et al. (1993)" startWordPosition="882" endWordPosition="886">on 2, we present the grammar extraction algorithm of Chen and Vijay-Shanker (2000). We then present our generation system, FERGUS (Section 3). We investigate the issue of the quality of the training corpus in Section 4. The issue of size of corpora is discussed in Section 5 and in Section 6, concentrating first on small corpora, and then on very large corpora. We conclude with a summary and an outlook. 2 Automated TAG Extraction from Bracketed Corpora There are a number of approaches for the extraction of Tree Adjoining Grammars (TAGs) from corpora annotated in the style of the Penn Treebank (Marcus et al. (1993)), as work by Neumann (1998), Xia (1999), and Chiang (2000) show. In fact, in Chen and Vijay-Shanker (2000) alone, no fewer than eight different kinds of extracted grammars are compared. For the following experiments, we adopt one out of the many approaches described in Chen and Vijay-Shanker (2000) which we describe here. As background, we review useful TAG terminology and discuss the linguistic principles that guide the formation of both manually constructed TAG grammars and the automatically extracted variety; for a more complete introduction, see (Abellle and Rambow, 2000). Subsequently, W</context>
<context position="8967" citStr="Marcus et al. (1993)" startWordPosition="1504" endWordPosition="1507">elf on the trunk, a complement of w, or an adjunct of w. If 77&apos; is a complement of w, then the node is made into a substitution node of -y. (The subtree rooted at 7)&apos; will be associated with a different headword, that of the complement.) If 77&apos; is an adjunct of w, then it belongs to another (auxiliary) tree /3 which modifies -y. It is therefore necessary to determine a node&apos;s status as either complement or adjunct. The procedure used by our algorithm is based on a similar one that is used by Collins (1997). Like Collins (1997), it bases its decision on the node&apos;s label, its semantic tags (see Marcus et al. (1993)), and local structural information. For example, a node that is labeled NP-DIR would be labeled as an adjunct because of the semantic tag DIR, signifying an adverbial that answers the questions &amp;quot;from where?&amp;quot; or &amp;quot;to where?&amp;quot; The main difference lies in our attempt to use lexical predicate-argument structure as a basis for determining the shape of the trees in our grammar. For instance, wh-moved constituents are treated by our procedure as complements of their head and therefore positions for moved elements may be included in verbal trees. Our procedure operates in two steps. In the first step, </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: the penn treebank. Computational Linguistics, 19(2):313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunter Neumann</author>
</authors>
<title>Automatic extraction of stochastic lexicalized tree grammars from treebanks.</title>
<date>1998</date>
<booktitle>In Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks,</booktitle>
<pages>120--123</pages>
<contexts>
<context position="5469" citStr="Neumann (1998)" startWordPosition="890" endWordPosition="891">ction algorithm of Chen and Vijay-Shanker (2000). We then present our generation system, FERGUS (Section 3). We investigate the issue of the quality of the training corpus in Section 4. The issue of size of corpora is discussed in Section 5 and in Section 6, concentrating first on small corpora, and then on very large corpora. We conclude with a summary and an outlook. 2 Automated TAG Extraction from Bracketed Corpora There are a number of approaches for the extraction of Tree Adjoining Grammars (TAGs) from corpora annotated in the style of the Penn Treebank (Marcus et al. (1993)), as work by Neumann (1998), Xia (1999), and Chiang (2000) show. In fact, in Chen and Vijay-Shanker (2000) alone, no fewer than eight different kinds of extracted grammars are compared. For the following experiments, we adopt one out of the many approaches described in Chen and Vijay-Shanker (2000) which we describe here. As background, we review useful TAG terminology and discuss the linguistic principles that guide the formation of both manually constructed TAG grammars and the automatically extracted variety; for a more complete introduction, see (Abellle and Rambow, 2000). Subsequently, We describe the details of th</context>
</contexts>
<marker>Neumann, 1998</marker>
<rawString>Gunter Neumann. 1998. Automatic extraction of stochastic lexicalized tree grammars from treebanks. In Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks, pages 120-123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alice H Oh</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Stochastic language generation for spoken dialog systems.</title>
<date>2000</date>
<booktitle>In Proceedings of the ANL/NAACL 2000 Workshop on Conversational Systems,</booktitle>
<pages>27--32</pages>
<publisher>ACL.</publisher>
<location>Seattle.</location>
<contexts>
<context position="1455" citStr="Oh and Rudnicky, 2000" startWordPosition="222" endWordPosition="225">tree banks, and then use these extracted grammars to train the tree models. We also investigate the impact of the quality of the annotated corpus, by using a hand-annotated corpus as well as an automatically annotated corpus. Our results show that automatic grammar extraction is a viable alternative to hand crafted grammars for generation; furthermore, as expected, both quality and size of the training corpus matter 1 Introduction Recently, there has been some interest in using stochastic approaches in generation (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998; Langkilde, 2000; Oh and Rudnicky, 2000; Ratnaparkhi, 2000; Bangalore and Rambow, 2000). For generation, stochastic methods promise to be superior to hand-crafted generators in (at least) two different contexts: • When the range of output to be generated is wide, for example in general-purpose machine translation systems. • When a generation system needs to be created very quickly. However, there has been little research so far on the question of how the quality, size, and genre of training corpora influence the quality of stochastic generation components. These questions are crucial: for both wide-range output and for rapid develo</context>
</contexts>
<marker>Oh, Rudnicky, 2000</marker>
<rawString>Alice H. Oh and Alexander I. Rudnicky. 2000. Stochastic language generation for spoken dialog systems. In Proceedings of the ANL/NAACL 2000 Workshop on Conversational Systems, pages 27-32, Seattle. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>Trainable methods for surface natural language generation.</title>
<date>2000</date>
<booktitle>In Proceedings of First North American ACL,</booktitle>
<location>Seattle, USA,</location>
<contexts>
<context position="1474" citStr="Ratnaparkhi, 2000" startWordPosition="226" endWordPosition="228">e these extracted grammars to train the tree models. We also investigate the impact of the quality of the annotated corpus, by using a hand-annotated corpus as well as an automatically annotated corpus. Our results show that automatic grammar extraction is a viable alternative to hand crafted grammars for generation; furthermore, as expected, both quality and size of the training corpus matter 1 Introduction Recently, there has been some interest in using stochastic approaches in generation (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998; Langkilde, 2000; Oh and Rudnicky, 2000; Ratnaparkhi, 2000; Bangalore and Rambow, 2000). For generation, stochastic methods promise to be superior to hand-crafted generators in (at least) two different contexts: • When the range of output to be generated is wide, for example in general-purpose machine translation systems. • When a generation system needs to be created very quickly. However, there has been little research so far on the question of how the quality, size, and genre of training corpora influence the quality of stochastic generation components. These questions are crucial: for both wide-range output and for rapid development, we need to k</context>
</contexts>
<marker>Ratnaparkhi, 2000</marker>
<rawString>Adwait Ratnaparkhi. 2000. Trainable methods for surface natural language generation. In Proceedings of First North American ACL, Seattle, USA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
</authors>
<title>Extracting tree adjoining grammars from bracketed corpora.</title>
<date>1999</date>
<booktitle>In Fifth Natural Language Processing Pacific Rim Symposium (NLPRS-99),</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="5481" citStr="Xia (1999)" startWordPosition="892" endWordPosition="893">of Chen and Vijay-Shanker (2000). We then present our generation system, FERGUS (Section 3). We investigate the issue of the quality of the training corpus in Section 4. The issue of size of corpora is discussed in Section 5 and in Section 6, concentrating first on small corpora, and then on very large corpora. We conclude with a summary and an outlook. 2 Automated TAG Extraction from Bracketed Corpora There are a number of approaches for the extraction of Tree Adjoining Grammars (TAGs) from corpora annotated in the style of the Penn Treebank (Marcus et al. (1993)), as work by Neumann (1998), Xia (1999), and Chiang (2000) show. In fact, in Chen and Vijay-Shanker (2000) alone, no fewer than eight different kinds of extracted grammars are compared. For the following experiments, we adopt one out of the many approaches described in Chen and Vijay-Shanker (2000) which we describe here. As background, we review useful TAG terminology and discuss the linguistic principles that guide the formation of both manually constructed TAG grammars and the automatically extracted variety; for a more complete introduction, see (Abellle and Rambow, 2000). Subsequently, We describe the details of the grammar ex</context>
</contexts>
<marker>Xia, 1999</marker>
<rawString>Fei Xia. 1999. Extracting tree adjoining grammars from bracketed corpora. In Fifth Natural Language Processing Pacific Rim Symposium (NLPRS-99), Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>The XTAG-Group</author>
</authors>
<title>A lexicalized Tree Adjoining Grammar for English.</title>
<date>1999</date>
<tech>Technical Report http://www.cis.upenn.edu/-xtag/tech-report/</tech>
<contexts>
<context position="12501" citStr="XTAG-Group, 1999" startWordPosition="2121" endWordPosition="2122">GUS is a stochastic model that assigns supertags to the nodes of the input derivation tree. The parameters of this model are estimated from a training corpus of annotated derivation trees, where each node is annotated with a supertag from the grammar. The performance of the tree model depends on two aspects: the grammar which they refer to and the quality of annotation of the corpus. In this section, we discuss the impact of these aspects on the performance of FERGUS. In order to investigate the impact of the quality of the grammar on the tree model, we used the supertags of the XTAG grammar (XTAG-Group, 1999) and the supertags of a grammar extracted automatically from the Penn Treebank as described above in Section 2. The grammar from XTAG contains 444 supertags while the extracted grammar contains 3063 supertags. Two tree models were trained on the two versions of the same one million word corpus annotated with the two supertag sets. The performance of FERGUS using these two tree models but with the same language model is shown in rows one and two of Table 1. It is interesting to note that the performance of FERGUS using the extracted grammar is as good as2 the performance using the XTAG grammar.</context>
</contexts>
<marker>XTAG-Group, 1999</marker>
<rawString>The XTAG-Group. 1999. A lexicalized Tree Adjoining Grammar for English. Technical Report http://www.cis.upenn.edu/-xtag/tech-report/</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>