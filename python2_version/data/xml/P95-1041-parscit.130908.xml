<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.059122">
<title confidence="0.6995545">
Sense Disambiguation Using Semantic
Relations and Adjacency Information
Anil S. Chakravarthy
MIT Media Laboratory
</title>
<address confidence="0.6175575">
20 Ames Street E15-468a
Cambridge MA 02139
</address>
<email confidence="0.997019">
anil@media.mit.edu
</email>
<sectionHeader confidence="0.995589" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999933076923077">
This paper describes a heuristic-based approach to
word-sense disambiguation. The heuristics that are
applied to disambiguate a word depend on its part of
speech, and on its relationship to neighboring salient
words in the text. Parts of speech are found through a
tagger, and related neighboring words are identified by a
phrase extractor operating on the tagged text. To suggest
possible senses, each heuristic draws on semantic rela-
tions extracted from a Webster&apos;s dictionary and the
semantic thesaurus WordNet. For a given word, all
applicable heuristics are tried, and those senses that are
rejected by all heuristics are discarded. In all, the disam-
biguator uses 39 heuristics based on 12 relationships.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999766636363636">
Word-sense disambiguation has long been recognized as
a difficult problem in computational linguistics. As early
as 1960, Bar-Hillel [1] noted that a computer program
would find it challenging to recognize the two different
senses of the word &amp;quot;pen&amp;quot; in &amp;quot;The pen is in the box,&amp;quot; and
&amp;quot;The box is in the pen.&amp;quot; In recent years, there has been a
resurgence of interest in word-sense disambiguation due
to the availability of linguistic resources like dictionar-
ies and thesauri, and due to the importance of disambig-
uation in applications like information retrieval and
machine translation.
</bodyText>
<listItem confidence="0.560058142857143">
• The task of disambiguation is to assign a word to one or
more senses in a reference by taking into account the
context in which the word occurs. The reference can be
a standard dictionary or thesaurus, or a lexicon con-
structed specially for some application. The context is
provided by the text unit (paragraph, sentence, etc.) in
which the word occurs.
</listItem>
<bodyText confidence="0.999989514285714">
The disambiguator described in this paper is based on
two reference sources, the Webster&apos;s Seventh Dictionary
and the semantic thesaurus WordNet [12]. Before the
disambiguator is applied, the text input is processed first
by a part-of-speech tagger and then by a phrase extrac-
tor which detects phrase boundaries. Therefore, for each
ambiguous word, the disambiguator knows the part of
speech, and other phrase headwords and modifiers that
are adjacent to it. Based on this context information, the
disambiguator uses a set of heuristics to assign one or
more senses from the Webster&apos;s dictionary or WordNet
to the word. Here is an example of a heuristic that relies
on the fact that conjoined head nouns are likely to refer
to objects of the same category. Consider the ambiguous
word &amp;quot;snow&amp;quot; in the sentence &amp;quot;Slush and snow filled the
roads.&amp;quot; In this sentence, the tagger identifies &amp;quot;snow&amp;quot; as
a noun. The phrase extractor indicates that &amp;quot;snow&amp;quot; and
&amp;quot;slush&amp;quot; are conjoined head words of a noun phrase.
Then, the heuristic uses WordNet to identify the senses
of &amp;quot;slush&amp;quot; and &amp;quot;snow&amp;quot; that belong to a common cate-
gory. Therefore, the sense of &amp;quot;snow&amp;quot; as &amp;quot;cocaine&amp;quot; is dis-
carded by this heuristic.
The disambiguator has been incorporated into two infor-
mation retrieval applications which use semantic rela-
tions (like A-KIND-OF) from the dictionary and
WordNet to match queries to text. Since semantic rela-
tions are attached to particular word senses in the dictio-
nary and WordNet, disambiguated representations of the
text and the queries lead to targeted use of semantic rela-
tions in matching.
The rest of the paper is organized as follows. The next
section reviews existing approaches to disambiguation
with emphasis on directly related methods. Section 3
describes in more detail the heuristics and adjacency
relationships used by the disambiguator.
</bodyText>
<page confidence="0.99674">
293
</page>
<sectionHeader confidence="0.979016" genericHeader="introduction">
2 Previous Work on Disambiguation
</sectionHeader>
<bodyText confidence="0.99997097826087">
In computational linguistics, considerable effort has
been devoted to word-sense disambiguation [8]. These
approaches can be broadly classified based on the refer-
ence from which senses are assigned, and on the method
used to take the context of occurrence into account. The
references have ranged from detailed custom-built lexi-
cons (e.g., [11]) to standard resources like dictionaries
and thesauri like Roget&apos;s (e.g., [2, 10, 14]). To take the
context into account, researchers have used a variety of
statistical weighting and spreading activation models
(e.g., [9, 14, 15]). This section gives brief descriptions
of some approaches that use on-line dictionaries and
WordNet as references.
WordNet is a large, manually-constructed semantic net-
work built at Princeton University by George Miller and
his colleagues [12]. The basic unit of WordNet is a set of
synonyms, called a synset, e.g., [go, travel, move]. A
word (or a word collocation like &amp;quot;operating room&amp;quot;) can
occur in any number of synsets, with each synset reflect-
ing a different sense of the word. WordNet is organized
around a taxonomy of hypernyms (A-KIND-OF rela-
tions) and hyponyms (inverses of A-KIND-OF), and 10
other relations. The disambiguation algorithm described
by Voorhees [16] partitions WordNet into hoods, which
are then used as sense categories (like dictionary subject
codes and Roget&apos;s thesaurus classes). A single synset is
selected for nouns based on the hood overlap with the
surrounding text.
The research on extraction of semantic relations from
dictionary definitions (e.g., [5, 7]) has resulted in new
methods for disambiguation, e.g., [2, 15]. For example,
Vanderwende [15] uses semantic relations extracted
from LDOCE to interpret nominal compounds (noun
sequences). Her algorithm disambiguates noun
sequences by using the dictionary to search for pre-
defined relations between the two nouns; e.g., in the
sequence &amp;quot;bird sanctuary,&amp;quot; the correct sense of &amp;quot;sanctu-
ary&amp;quot; is chosen because the dictionary definition indi-
cates that a sanctuary is an area for birds or animals.
Our algorithm, which is described in the next section, is
in the same spirit as Vanderwende&apos;s but with two main
differences. In addition to noun sequences, the algo-
rithm has heuristics for handling 11 other adjacency
relationships. Second, the algorithm brings to bear both
WordNet and semantic relations extracted from an on-
line Webster&apos;s dictionary during disambiguation.
</bodyText>
<sectionHeader confidence="0.997575" genericHeader="method">
3 Sense Disambiguation with
Adjacency Information
</sectionHeader>
<bodyText confidence="0.998360581395349">
The input to the disambiguator is a pair of words, along
with the adjacency relationship that links them in the
input text. The adjacency relationship is obtained auto-
matically by processing the text through the Xerox
PARC part-of-speech tagger [6] and a phrase extractor.
The 12 adjacency relationships used by the disambigua-
tor are listed below. These adjacency relationships were
derived from an analysis of captions of news photo-
graphs provided by the Associated Press. The examples
from the captions also helped us identify the heuristic
rules necessary for automatic disambiguation using
WordNet and the Webster&apos;s dictionary. In the table
below, each adjacency category is accompanied by an
example. 39 heuristic rules are used currently.
Adjacency Relationship Example
Adjective modifying a noun Express train
Possessive modifying a noun Pharmacist&apos;s coat
Noun followed by a proper Tenor Luciano
name Pavarotti
Present participle gerund Training drill
modifying a noun
Noun noun Basketball fan
Conjoined nouns A church and a home
Noun modified by a noun at Barrel of the rifle
the head of a following &amp;quot;of&apos;
PP
Noun modified by a noun at A mortar with a shell
the head of a following &amp;quot;non-
of&apos; PP
Noun that is the subject of an A monitor displays
action verb information
Noun that is the object of an Write a mystery
action verb
Noun that is at the head of a Sentenced to life
prepositional phrase follow-
ing a verb
Nouns that are subject and The hawk found a
object of the same action perch
Given a pair of words and the adjacency relationship,
the disambiguator applies all heuristics corresponding to
that category, and those word senses that are rejected by
all heuristics are discarded. Due to space considerations,
we will not describe the heuristic rules individually but
</bodyText>
<page confidence="0.994647">
294
</page>
<bodyText confidence="0.9977895">
instead identify some common salient features. The heu-
ristics are described in detail in [3].
</bodyText>
<listItem confidence="0.975034076923077">
• Several heuristics look for a particular semantic rela-
tion like hypernymy or purpose linking the two input
words, e.g., &amp;quot;return&amp;quot; is a hypernym of &amp;quot;forehand.&amp;quot;
• Many heuristics look for particular semantic rela-
tions linking the two input words to a common word
or synset; e.g., a &amp;quot;church&amp;quot; and a &amp;quot;home&amp;quot; are both
buildings.
• Many heuristics look for analogous adjacency pat-
terns either in dictionary definitions or in example
sentences, e.g., &amp;quot;write a mystery&amp;quot; is disambiguated
by analogy to the example sentence &amp;quot;writes poems
and essays.&amp;quot;
• Some heuristics look for specific hypernyms such as
</listItem>
<bodyText confidence="0.989853333333333">
person or place in the input words; e.g., if a noun is
followed by a proper name (as in &amp;quot;tenor Luciano
Pavarotti&amp;quot; or &amp;quot;pitcher Curt Schilling&amp;quot;), those senses
of the noun that have &amp;quot;person&amp;quot; as a hypernym are
chosen.
The disambiguator has been used in two retrieval pro-
grams, ImEngine, a program for semantic retrieval of
image captions, and NetSerf, a program for finding
Internet information archives [3, 4]. The initial results
have not been promising, with both programs reporting
deterioration in performance when the disambiguator is
included. This agrees with the current wisdom in the IR
community that unless disambiguation is highly accu-
rate, it might not improve the retrieval system&apos;s perfor-
mance [13].
</bodyText>
<sectionHeader confidence="0.998602" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999936639344263">
1. Bar-Hillel, Yehoshua. 1960. &amp;quot;The Present Status of
Automatic Translation of Languages,&amp;quot; in Advances
in Computers, F. L. Alt, editor, Academic Press, New
York.
2. Braden-Harder, Lisa. 1992. &amp;quot;Sense Disambiguation
Using On-line Dictionaries,&amp;quot; in Natural Language
Processing: The PLNLP Approach, Jensen, K.,
Heidorn, G. E., and Richardson, S. D., editors, Klu-
wer Academic Publishers.
3. Chalcravarthy, Anil S. 1995. &amp;quot;Information Access
and Retrieval with Semantic Background Knowl-
edge&amp;quot; Ph.D thesis, MIT Media Laboratory.
4. Chalcravarthy, Anil S. and Haase, Kenneth B. 1995.
&amp;quot;NetSerf: Using Semantic Knowledge to Find Inter-
net Information Archives,&amp;quot; to appear in Proceedings
of SIGIR&apos;95.
5. Chodorow, Martin. S., Byrd, Roy. J., and Heidorn,
George. E. 1985. &amp;quot;Extracting Semantic Hierarchies
from a Large On-Line Dictionary,&amp;quot; in Proceedings of
the 23rd ACL.
6. Cutting, Doug, Julian Kupiec, Jan Pedersen, and
Penelope Sibun. 1992. &amp;quot;A Practical Part-of-Speech
Tagger,&amp;quot; in Proceedings of the Third Conference on
Applied NLP.
7. Dolan, William B., Lucy Vanderwende, and Richard-
son, Steven. D. 1993. &amp;quot;Automatically Deriving
Structured Knowledge Bases from On-line Dictio-
naries,&amp;quot; in Proceedings of the First Conference of
the Pacific Association for Computational Linguis-
tics, Vancouver.
8. Gale, William, Church, Kenneth. W., and David
Yarowsky. 1992. &amp;quot;Estimating Upper and Lower
Bounds on the Performance of Word-sense Disam-
biguation Programs,&amp;quot; in Proceedings of ACL-92.
9. Hearst, Marti. 1991. &amp;quot;Noun Homograph Disambigu-
ation Using Local Context in Large Text Corpora,&amp;quot;
Proceedings of the 7th Annual Conference of the UW
Centre for the New OED and Text Research, Oxford,
England.
10. Lesk, Michael. 1986. &amp;quot;Automatic Sense Disambigu-
ation: How to Tell a Pine Cone from an Ice Cream
Cone,&amp;quot; in Proceedings of the SIGDOC Conference
11. McRoy, Susan. 1992. &amp;quot;Using Multiple Knowledge
Sources for Word Sense Discrimination,&amp;quot; in Compu-
tational Linguistics, 18(1).
12. Miller, George A. 1990. &amp;quot;WordNet: An On-line Lex-
ical Database,&amp;quot; in International Journal of Lexicog-
raphy, 3(4).
13. Sanderson, Mark. 1994. &amp;quot;Word Sense Disambigua-
tion and Information Retrieval,&amp;quot; in Proceedings of
SIGIR&apos;94.
14. Yarowsky, David. 1992. &amp;quot;Word Sense Disambigua-
tion Using Statistical Models of Roget&apos;s Categories
Trained on Large Corpora,&amp;quot; in Proceedings of COL-
ING-92, Nantes, France.
15. Vanderwende, Lucy. 1994. &amp;quot;Algorithm for Auto-
matic Interpretation of Noun Sequences,&amp;quot; in Pro-
ceedings of COLING-94, Kyoto, Japan.
16. Voorhees, Ellen. M. 1993. &amp;quot;Using WordNet to Dis-
ambiguate Word Senses for Text Retrieval,&amp;quot; in Pro-
ceedings of SIGIR&apos;93.
</reference>
<page confidence="0.99857">
295
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.928483">
<title confidence="0.9998">Sense Disambiguation Using Semantic Relations and Adjacency Information</title>
<author confidence="0.999815">Anil S Chakravarthy</author>
<affiliation confidence="0.999949">MIT Media Laboratory</affiliation>
<address confidence="0.998543">20 Ames Street E15-468a Cambridge MA 02139</address>
<email confidence="0.999737">anil@media.mit.edu</email>
<abstract confidence="0.995052928571429">This paper describes a heuristic-based approach to word-sense disambiguation. The heuristics that are applied to disambiguate a word depend on its part of speech, and on its relationship to neighboring salient words in the text. Parts of speech are found through a tagger, and related neighboring words are identified by a phrase extractor operating on the tagged text. To suggest possible senses, each heuristic draws on semantic relations extracted from a Webster&apos;s dictionary and the semantic thesaurus WordNet. For a given word, all applicable heuristics are tried, and those senses that are rejected by all heuristics are discarded. In all, the disambiguator uses 39 heuristics based on 12 relationships.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yehoshua Bar-Hillel</author>
</authors>
<title>The Present Status of Automatic Translation of Languages,&amp;quot;</title>
<date>1960</date>
<booktitle>in Advances in Computers,</booktitle>
<editor>F. L. Alt, editor,</editor>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="1046" citStr="[1]" startWordPosition="154" endWordPosition="154">ough a tagger, and related neighboring words are identified by a phrase extractor operating on the tagged text. To suggest possible senses, each heuristic draws on semantic relations extracted from a Webster&apos;s dictionary and the semantic thesaurus WordNet. For a given word, all applicable heuristics are tried, and those senses that are rejected by all heuristics are discarded. In all, the disambiguator uses 39 heuristics based on 12 relationships. 1 Introduction Word-sense disambiguation has long been recognized as a difficult problem in computational linguistics. As early as 1960, Bar-Hillel [1] noted that a computer program would find it challenging to recognize the two different senses of the word &amp;quot;pen&amp;quot; in &amp;quot;The pen is in the box,&amp;quot; and &amp;quot;The box is in the pen.&amp;quot; In recent years, there has been a resurgence of interest in word-sense disambiguation due to the availability of linguistic resources like dictionaries and thesauri, and due to the importance of disambiguation in applications like information retrieval and machine translation. • The task of disambiguation is to assign a word to one or more senses in a reference by taking into account the context in which the word occurs. The r</context>
</contexts>
<marker>1.</marker>
<rawString>Bar-Hillel, Yehoshua. 1960. &amp;quot;The Present Status of Automatic Translation of Languages,&amp;quot; in Advances in Computers, F. L. Alt, editor, Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa Braden-Harder</author>
</authors>
<title>Sense Disambiguation Using On-line Dictionaries,&amp;quot;</title>
<date>1992</date>
<booktitle>in Natural Language Processing: The</booktitle>
<editor>PLNLP Approach, Jensen, K., Heidorn, G. E., and Richardson, S. D., editors,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="4160" citStr="[2, 10, 14]" startWordPosition="657" endWordPosition="659">emphasis on directly related methods. Section 3 describes in more detail the heuristics and adjacency relationships used by the disambiguator. 293 2 Previous Work on Disambiguation In computational linguistics, considerable effort has been devoted to word-sense disambiguation [8]. These approaches can be broadly classified based on the reference from which senses are assigned, and on the method used to take the context of occurrence into account. The references have ranged from detailed custom-built lexicons (e.g., [11]) to standard resources like dictionaries and thesauri like Roget&apos;s (e.g., [2, 10, 14]). To take the context into account, researchers have used a variety of statistical weighting and spreading activation models (e.g., [9, 14, 15]). This section gives brief descriptions of some approaches that use on-line dictionaries and WordNet as references. WordNet is a large, manually-constructed semantic network built at Princeton University by George Miller and his colleagues [12]. The basic unit of WordNet is a set of synonyms, called a synset, e.g., [go, travel, move]. A word (or a word collocation like &amp;quot;operating room&amp;quot;) can occur in any number of synsets, with each synset reflecting a</context>
</contexts>
<marker>2.</marker>
<rawString>Braden-Harder, Lisa. 1992. &amp;quot;Sense Disambiguation Using On-line Dictionaries,&amp;quot; in Natural Language Processing: The PLNLP Approach, Jensen, K., Heidorn, G. E., and Richardson, S. D., editors, Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anil S Chalcravarthy</author>
</authors>
<title>Information Access and Retrieval with Semantic Background Knowledge&amp;quot;</title>
<date>1995</date>
<tech>Ph.D thesis,</tech>
<institution>MIT Media Laboratory.</institution>
<contexts>
<context position="8089" citStr="[3]" startWordPosition="1283" endWordPosition="1283">Noun that is the object of an Write a mystery action verb Noun that is at the head of a Sentenced to life prepositional phrase following a verb Nouns that are subject and The hawk found a object of the same action perch Given a pair of words and the adjacency relationship, the disambiguator applies all heuristics corresponding to that category, and those word senses that are rejected by all heuristics are discarded. Due to space considerations, we will not describe the heuristic rules individually but 294 instead identify some common salient features. The heuristics are described in detail in [3]. • Several heuristics look for a particular semantic relation like hypernymy or purpose linking the two input words, e.g., &amp;quot;return&amp;quot; is a hypernym of &amp;quot;forehand.&amp;quot; • Many heuristics look for particular semantic relations linking the two input words to a common word or synset; e.g., a &amp;quot;church&amp;quot; and a &amp;quot;home&amp;quot; are both buildings. • Many heuristics look for analogous adjacency patterns either in dictionary definitions or in example sentences, e.g., &amp;quot;write a mystery&amp;quot; is disambiguated by analogy to the example sentence &amp;quot;writes poems and essays.&amp;quot; • Some heuristics look for specific hypernyms such as pers</context>
</contexts>
<marker>3.</marker>
<rawString>Chalcravarthy, Anil S. 1995. &amp;quot;Information Access and Retrieval with Semantic Background Knowledge&amp;quot; Ph.D thesis, MIT Media Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anil S Chalcravarthy</author>
<author>Kenneth B Haase</author>
</authors>
<title>NetSerf: Using Semantic Knowledge to Find Internet Information Archives,&amp;quot; to appear in</title>
<date>1995</date>
<booktitle>Proceedings of SIGIR&apos;95.</booktitle>
<marker>4.</marker>
<rawString>Chalcravarthy, Anil S. and Haase, Kenneth B. 1995. &amp;quot;NetSerf: Using Semantic Knowledge to Find Internet Information Archives,&amp;quot; to appear in Proceedings of SIGIR&apos;95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Byrd</author>
<author>J Roy</author>
<author>George E Heidorn</author>
</authors>
<title>Extracting Semantic Hierarchies from a Large On-Line Dictionary,&amp;quot;</title>
<date>1985</date>
<booktitle>in Proceedings of the 23rd ACL.</booktitle>
<contexts>
<context position="5297" citStr="[5, 7]" startWordPosition="834" endWordPosition="835">m&amp;quot;) can occur in any number of synsets, with each synset reflecting a different sense of the word. WordNet is organized around a taxonomy of hypernyms (A-KIND-OF relations) and hyponyms (inverses of A-KIND-OF), and 10 other relations. The disambiguation algorithm described by Voorhees [16] partitions WordNet into hoods, which are then used as sense categories (like dictionary subject codes and Roget&apos;s thesaurus classes). A single synset is selected for nouns based on the hood overlap with the surrounding text. The research on extraction of semantic relations from dictionary definitions (e.g., [5, 7]) has resulted in new methods for disambiguation, e.g., [2, 15]. For example, Vanderwende [15] uses semantic relations extracted from LDOCE to interpret nominal compounds (noun sequences). Her algorithm disambiguates noun sequences by using the dictionary to search for predefined relations between the two nouns; e.g., in the sequence &amp;quot;bird sanctuary,&amp;quot; the correct sense of &amp;quot;sanctuary&amp;quot; is chosen because the dictionary definition indicates that a sanctuary is an area for birds or animals. Our algorithm, which is described in the next section, is in the same spirit as Vanderwende&apos;s but with two ma</context>
</contexts>
<marker>5.</marker>
<rawString>Chodorow, Martin. S., Byrd, Roy. J., and Heidorn, George. E. 1985. &amp;quot;Extracting Semantic Hierarchies from a Large On-Line Dictionary,&amp;quot; in Proceedings of the 23rd ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Cutting</author>
<author>Julian Kupiec</author>
<author>Jan Pedersen</author>
<author>Penelope Sibun</author>
</authors>
<title>A Practical Part-of-Speech Tagger,&amp;quot;</title>
<date>1992</date>
<booktitle>in Proceedings of the Third Conference on Applied NLP.</booktitle>
<contexts>
<context position="6460" citStr="[6]" startWordPosition="1013" endWordPosition="1013"> spirit as Vanderwende&apos;s but with two main differences. In addition to noun sequences, the algorithm has heuristics for handling 11 other adjacency relationships. Second, the algorithm brings to bear both WordNet and semantic relations extracted from an online Webster&apos;s dictionary during disambiguation. 3 Sense Disambiguation with Adjacency Information The input to the disambiguator is a pair of words, along with the adjacency relationship that links them in the input text. The adjacency relationship is obtained automatically by processing the text through the Xerox PARC part-of-speech tagger [6] and a phrase extractor. The 12 adjacency relationships used by the disambiguator are listed below. These adjacency relationships were derived from an analysis of captions of news photographs provided by the Associated Press. The examples from the captions also helped us identify the heuristic rules necessary for automatic disambiguation using WordNet and the Webster&apos;s dictionary. In the table below, each adjacency category is accompanied by an example. 39 heuristic rules are used currently. Adjacency Relationship Example Adjective modifying a noun Express train Possessive modifying a noun Pha</context>
</contexts>
<marker>6.</marker>
<rawString>Cutting, Doug, Julian Kupiec, Jan Pedersen, and Penelope Sibun. 1992. &amp;quot;A Practical Part-of-Speech Tagger,&amp;quot; in Proceedings of the Third Conference on Applied NLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D</author>
</authors>
<title>Automatically Deriving Structured Knowledge Bases from On-line Dictionaries,&amp;quot;</title>
<date>1993</date>
<booktitle>in Proceedings of the First Conference of the Pacific Association for Computational Linguistics,</booktitle>
<location>Vancouver.</location>
<contexts>
<context position="5297" citStr="[5, 7]" startWordPosition="834" endWordPosition="835">m&amp;quot;) can occur in any number of synsets, with each synset reflecting a different sense of the word. WordNet is organized around a taxonomy of hypernyms (A-KIND-OF relations) and hyponyms (inverses of A-KIND-OF), and 10 other relations. The disambiguation algorithm described by Voorhees [16] partitions WordNet into hoods, which are then used as sense categories (like dictionary subject codes and Roget&apos;s thesaurus classes). A single synset is selected for nouns based on the hood overlap with the surrounding text. The research on extraction of semantic relations from dictionary definitions (e.g., [5, 7]) has resulted in new methods for disambiguation, e.g., [2, 15]. For example, Vanderwende [15] uses semantic relations extracted from LDOCE to interpret nominal compounds (noun sequences). Her algorithm disambiguates noun sequences by using the dictionary to search for predefined relations between the two nouns; e.g., in the sequence &amp;quot;bird sanctuary,&amp;quot; the correct sense of &amp;quot;sanctuary&amp;quot; is chosen because the dictionary definition indicates that a sanctuary is an area for birds or animals. Our algorithm, which is described in the next section, is in the same spirit as Vanderwende&apos;s but with two ma</context>
</contexts>
<marker>7.</marker>
<rawString>Dolan, William B., Lucy Vanderwende, and Richardson, Steven. D. 1993. &amp;quot;Automatically Deriving Structured Knowledge Bases from On-line Dictionaries,&amp;quot; in Proceedings of the First Conference of the Pacific Association for Computational Linguistics, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W</author>
<author>David Yarowsky</author>
</authors>
<title>Estimating Upper and Lower Bounds on the Performance of Word-sense Disambiguation Programs,&amp;quot;</title>
<date>1992</date>
<booktitle>in Proceedings of ACL-92.</booktitle>
<contexts>
<context position="3829" citStr="[8]" startWordPosition="606" endWordPosition="606">ince semantic relations are attached to particular word senses in the dictionary and WordNet, disambiguated representations of the text and the queries lead to targeted use of semantic relations in matching. The rest of the paper is organized as follows. The next section reviews existing approaches to disambiguation with emphasis on directly related methods. Section 3 describes in more detail the heuristics and adjacency relationships used by the disambiguator. 293 2 Previous Work on Disambiguation In computational linguistics, considerable effort has been devoted to word-sense disambiguation [8]. These approaches can be broadly classified based on the reference from which senses are assigned, and on the method used to take the context of occurrence into account. The references have ranged from detailed custom-built lexicons (e.g., [11]) to standard resources like dictionaries and thesauri like Roget&apos;s (e.g., [2, 10, 14]). To take the context into account, researchers have used a variety of statistical weighting and spreading activation models (e.g., [9, 14, 15]). This section gives brief descriptions of some approaches that use on-line dictionaries and WordNet as references. WordNet </context>
</contexts>
<marker>8.</marker>
<rawString>Gale, William, Church, Kenneth. W., and David Yarowsky. 1992. &amp;quot;Estimating Upper and Lower Bounds on the Performance of Word-sense Disambiguation Programs,&amp;quot; in Proceedings of ACL-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Noun Homograph Disambiguation Using Local Context in Large Text Corpora,&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of the 7th Annual Conference of the UW Centre for the New OED and Text Research,</booktitle>
<location>Oxford, England.</location>
<contexts>
<context position="4304" citStr="[9, 14, 15]" startWordPosition="679" endWordPosition="681">93 2 Previous Work on Disambiguation In computational linguistics, considerable effort has been devoted to word-sense disambiguation [8]. These approaches can be broadly classified based on the reference from which senses are assigned, and on the method used to take the context of occurrence into account. The references have ranged from detailed custom-built lexicons (e.g., [11]) to standard resources like dictionaries and thesauri like Roget&apos;s (e.g., [2, 10, 14]). To take the context into account, researchers have used a variety of statistical weighting and spreading activation models (e.g., [9, 14, 15]). This section gives brief descriptions of some approaches that use on-line dictionaries and WordNet as references. WordNet is a large, manually-constructed semantic network built at Princeton University by George Miller and his colleagues [12]. The basic unit of WordNet is a set of synonyms, called a synset, e.g., [go, travel, move]. A word (or a word collocation like &amp;quot;operating room&amp;quot;) can occur in any number of synsets, with each synset reflecting a different sense of the word. WordNet is organized around a taxonomy of hypernyms (A-KIND-OF relations) and hyponyms (inverses of A-KIND-OF), an</context>
</contexts>
<marker>9.</marker>
<rawString>Hearst, Marti. 1991. &amp;quot;Noun Homograph Disambiguation Using Local Context in Large Text Corpora,&amp;quot; Proceedings of the 7th Annual Conference of the UW Centre for the New OED and Text Research, Oxford, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic Sense Disambiguation: How to Tell a Pine Cone from an Ice Cream Cone,&amp;quot;</title>
<date>1986</date>
<booktitle>in Proceedings of the SIGDOC Conference</booktitle>
<contexts>
<context position="4160" citStr="[2, 10, 14]" startWordPosition="657" endWordPosition="659">emphasis on directly related methods. Section 3 describes in more detail the heuristics and adjacency relationships used by the disambiguator. 293 2 Previous Work on Disambiguation In computational linguistics, considerable effort has been devoted to word-sense disambiguation [8]. These approaches can be broadly classified based on the reference from which senses are assigned, and on the method used to take the context of occurrence into account. The references have ranged from detailed custom-built lexicons (e.g., [11]) to standard resources like dictionaries and thesauri like Roget&apos;s (e.g., [2, 10, 14]). To take the context into account, researchers have used a variety of statistical weighting and spreading activation models (e.g., [9, 14, 15]). This section gives brief descriptions of some approaches that use on-line dictionaries and WordNet as references. WordNet is a large, manually-constructed semantic network built at Princeton University by George Miller and his colleagues [12]. The basic unit of WordNet is a set of synonyms, called a synset, e.g., [go, travel, move]. A word (or a word collocation like &amp;quot;operating room&amp;quot;) can occur in any number of synsets, with each synset reflecting a</context>
</contexts>
<marker>10.</marker>
<rawString>Lesk, Michael. 1986. &amp;quot;Automatic Sense Disambiguation: How to Tell a Pine Cone from an Ice Cream Cone,&amp;quot; in Proceedings of the SIGDOC Conference</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan McRoy</author>
</authors>
<title>Using Multiple Knowledge Sources for Word Sense Discrimination,&amp;quot;</title>
<date>1992</date>
<booktitle>in Computational Linguistics,</booktitle>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="4074" citStr="[11]" startWordPosition="646" endWordPosition="646">s follows. The next section reviews existing approaches to disambiguation with emphasis on directly related methods. Section 3 describes in more detail the heuristics and adjacency relationships used by the disambiguator. 293 2 Previous Work on Disambiguation In computational linguistics, considerable effort has been devoted to word-sense disambiguation [8]. These approaches can be broadly classified based on the reference from which senses are assigned, and on the method used to take the context of occurrence into account. The references have ranged from detailed custom-built lexicons (e.g., [11]) to standard resources like dictionaries and thesauri like Roget&apos;s (e.g., [2, 10, 14]). To take the context into account, researchers have used a variety of statistical weighting and spreading activation models (e.g., [9, 14, 15]). This section gives brief descriptions of some approaches that use on-line dictionaries and WordNet as references. WordNet is a large, manually-constructed semantic network built at Princeton University by George Miller and his colleagues [12]. The basic unit of WordNet is a set of synonyms, called a synset, e.g., [go, travel, move]. A word (or a word collocation li</context>
</contexts>
<marker>11.</marker>
<rawString>McRoy, Susan. 1992. &amp;quot;Using Multiple Knowledge Sources for Word Sense Discrimination,&amp;quot; in Computational Linguistics, 18(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: An On-line Lexical Database,&amp;quot;</title>
<date>1990</date>
<journal>in International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="1999" citStr="[12]" startWordPosition="313" endWordPosition="313">e importance of disambiguation in applications like information retrieval and machine translation. • The task of disambiguation is to assign a word to one or more senses in a reference by taking into account the context in which the word occurs. The reference can be a standard dictionary or thesaurus, or a lexicon constructed specially for some application. The context is provided by the text unit (paragraph, sentence, etc.) in which the word occurs. The disambiguator described in this paper is based on two reference sources, the Webster&apos;s Seventh Dictionary and the semantic thesaurus WordNet [12]. Before the disambiguator is applied, the text input is processed first by a part-of-speech tagger and then by a phrase extractor which detects phrase boundaries. Therefore, for each ambiguous word, the disambiguator knows the part of speech, and other phrase headwords and modifiers that are adjacent to it. Based on this context information, the disambiguator uses a set of heuristics to assign one or more senses from the Webster&apos;s dictionary or WordNet to the word. Here is an example of a heuristic that relies on the fact that conjoined head nouns are likely to refer to objects of the same ca</context>
<context position="4549" citStr="[12]" startWordPosition="716" endWordPosition="716">d used to take the context of occurrence into account. The references have ranged from detailed custom-built lexicons (e.g., [11]) to standard resources like dictionaries and thesauri like Roget&apos;s (e.g., [2, 10, 14]). To take the context into account, researchers have used a variety of statistical weighting and spreading activation models (e.g., [9, 14, 15]). This section gives brief descriptions of some approaches that use on-line dictionaries and WordNet as references. WordNet is a large, manually-constructed semantic network built at Princeton University by George Miller and his colleagues [12]. The basic unit of WordNet is a set of synonyms, called a synset, e.g., [go, travel, move]. A word (or a word collocation like &amp;quot;operating room&amp;quot;) can occur in any number of synsets, with each synset reflecting a different sense of the word. WordNet is organized around a taxonomy of hypernyms (A-KIND-OF relations) and hyponyms (inverses of A-KIND-OF), and 10 other relations. The disambiguation algorithm described by Voorhees [16] partitions WordNet into hoods, which are then used as sense categories (like dictionary subject codes and Roget&apos;s thesaurus classes). A single synset is selected for n</context>
</contexts>
<marker>12.</marker>
<rawString>Miller, George A. 1990. &amp;quot;WordNet: An On-line Lexical Database,&amp;quot; in International Journal of Lexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Sanderson</author>
</authors>
<title>Word Sense Disambiguation and Information Retrieval,&amp;quot;</title>
<date>1994</date>
<booktitle>in Proceedings of SIGIR&apos;94.</booktitle>
<marker>13.</marker>
<rawString>Sanderson, Mark. 1994. &amp;quot;Word Sense Disambiguation and Information Retrieval,&amp;quot; in Proceedings of SIGIR&apos;94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Word Sense Disambiguation Using Statistical Models of Roget&apos;s Categories Trained on Large Corpora,&amp;quot;</title>
<date>1992</date>
<booktitle>in Proceedings of COLING-92,</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="4160" citStr="[2, 10, 14]" startWordPosition="657" endWordPosition="659">emphasis on directly related methods. Section 3 describes in more detail the heuristics and adjacency relationships used by the disambiguator. 293 2 Previous Work on Disambiguation In computational linguistics, considerable effort has been devoted to word-sense disambiguation [8]. These approaches can be broadly classified based on the reference from which senses are assigned, and on the method used to take the context of occurrence into account. The references have ranged from detailed custom-built lexicons (e.g., [11]) to standard resources like dictionaries and thesauri like Roget&apos;s (e.g., [2, 10, 14]). To take the context into account, researchers have used a variety of statistical weighting and spreading activation models (e.g., [9, 14, 15]). This section gives brief descriptions of some approaches that use on-line dictionaries and WordNet as references. WordNet is a large, manually-constructed semantic network built at Princeton University by George Miller and his colleagues [12]. The basic unit of WordNet is a set of synonyms, called a synset, e.g., [go, travel, move]. A word (or a word collocation like &amp;quot;operating room&amp;quot;) can occur in any number of synsets, with each synset reflecting a</context>
</contexts>
<marker>14.</marker>
<rawString>Yarowsky, David. 1992. &amp;quot;Word Sense Disambiguation Using Statistical Models of Roget&apos;s Categories Trained on Large Corpora,&amp;quot; in Proceedings of COLING-92, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucy Vanderwende</author>
</authors>
<title>Algorithm for Automatic Interpretation of Noun Sequences,&amp;quot;</title>
<date>1994</date>
<booktitle>in Proceedings of COLING-94,</booktitle>
<location>Kyoto, Japan.</location>
<contexts>
<context position="4304" citStr="[9, 14, 15]" startWordPosition="679" endWordPosition="681">93 2 Previous Work on Disambiguation In computational linguistics, considerable effort has been devoted to word-sense disambiguation [8]. These approaches can be broadly classified based on the reference from which senses are assigned, and on the method used to take the context of occurrence into account. The references have ranged from detailed custom-built lexicons (e.g., [11]) to standard resources like dictionaries and thesauri like Roget&apos;s (e.g., [2, 10, 14]). To take the context into account, researchers have used a variety of statistical weighting and spreading activation models (e.g., [9, 14, 15]). This section gives brief descriptions of some approaches that use on-line dictionaries and WordNet as references. WordNet is a large, manually-constructed semantic network built at Princeton University by George Miller and his colleagues [12]. The basic unit of WordNet is a set of synonyms, called a synset, e.g., [go, travel, move]. A word (or a word collocation like &amp;quot;operating room&amp;quot;) can occur in any number of synsets, with each synset reflecting a different sense of the word. WordNet is organized around a taxonomy of hypernyms (A-KIND-OF relations) and hyponyms (inverses of A-KIND-OF), an</context>
</contexts>
<marker>15.</marker>
<rawString>Vanderwende, Lucy. 1994. &amp;quot;Algorithm for Automatic Interpretation of Noun Sequences,&amp;quot; in Proceedings of COLING-94, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M</author>
</authors>
<title>Using WordNet to Disambiguate Word Senses for Text Retrieval,&amp;quot;</title>
<date>1993</date>
<booktitle>in Proceedings of SIGIR&apos;93.</booktitle>
<contexts>
<context position="4981" citStr="[16]" startWordPosition="787" endWordPosition="787">ine dictionaries and WordNet as references. WordNet is a large, manually-constructed semantic network built at Princeton University by George Miller and his colleagues [12]. The basic unit of WordNet is a set of synonyms, called a synset, e.g., [go, travel, move]. A word (or a word collocation like &amp;quot;operating room&amp;quot;) can occur in any number of synsets, with each synset reflecting a different sense of the word. WordNet is organized around a taxonomy of hypernyms (A-KIND-OF relations) and hyponyms (inverses of A-KIND-OF), and 10 other relations. The disambiguation algorithm described by Voorhees [16] partitions WordNet into hoods, which are then used as sense categories (like dictionary subject codes and Roget&apos;s thesaurus classes). A single synset is selected for nouns based on the hood overlap with the surrounding text. The research on extraction of semantic relations from dictionary definitions (e.g., [5, 7]) has resulted in new methods for disambiguation, e.g., [2, 15]. For example, Vanderwende [15] uses semantic relations extracted from LDOCE to interpret nominal compounds (noun sequences). Her algorithm disambiguates noun sequences by using the dictionary to search for predefined rel</context>
</contexts>
<marker>16.</marker>
<rawString>Voorhees, Ellen. M. 1993. &amp;quot;Using WordNet to Disambiguate Word Senses for Text Retrieval,&amp;quot; in Proceedings of SIGIR&apos;93.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>