<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000162">
<title confidence="0.885656">
Catching Metaphors
</title>
<author confidence="0.972394">
Matt Gedigian, John Bryant, Srini Narayanan, and Branimir Ciric
</author>
<affiliation confidence="0.959372">
International Computer Science Institute
</affiliation>
<address confidence="0.900555">
1947 Center Street. Suite 600
Berkeley, CA 94704, USA
</address>
<email confidence="0.993273">
{gedigian, jbryant, snarayan}@icsi.berkeley.edu
</email>
<sectionHeader confidence="0.995641" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999865666666667">
Metaphors are ubiquitous in language and
developing methods to identify and deal
with metaphors is an open problem in
Natural Language Processing (NLP). In
this paper we describe results from us-
ing a maximum entropy (ME) classifier
to identify metaphors. Using the Wall
Street Journal (WSJ) corpus, we anno-
tated all the verbal targets associated with
a set of frames which includes frames of
spatial motion, manipulation, and health.
One surprising finding was that over 90%
of annotated targets from these frames
are used metaphorically, underscoring the
importance of processing figurative lan-
guage. We then used this labeled data and
each verbal target’s PropBank annotation
to train a maximum entropy classifier to
make this literal vs. metaphoric distinc-
tion. Using the classifier, we reduce the
final error in the test set by 5% over the
verb-specific majority class baseline and
31% over the corpus-wide majority class
baseline.
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998669">
To move beyond “factoid” style questions, question
answering systems must rely on inferential mecha-
nisms. To answer such commonplace questions as
Which train should I take to get to the airport? re-
quires justifications, predictions and recommenda-
tions that can only be produced through inference.
</bodyText>
<page confidence="0.544527">
41
</page>
<bodyText confidence="0.999941411764706">
One such question answering system (Narayanan
and Harabagiu, 2004) takes PropBank/FrameNet an-
notations as input, uses the PropBank targets to in-
dicate which actions are being described with which
arguments and produces an answer using probabilis-
tic models of actions as the tools of inference. Initi-
ating these action models is called simulation.
Such action models provide deep inferential capa-
bilities for embodied domains. They can also, when
provided with appropriate metaphoric mappings, be
extended to cover metaphoric language (Narayanan,
1997). Exploiting the inferential capabilities of such
action models over the broadest domain requires a
system to determine whether a verb is being used lit-
erally or metaphorically. Such a system could then
activate the necessary metaphoric mappings and ini-
tiate the appropriate simulation.
</bodyText>
<sectionHeader confidence="0.996775" genericHeader="introduction">
2 Metaphor
</sectionHeader>
<bodyText confidence="0.9989355">
Work in Cognitive Semantics (Lakoff and Johnson,
1980; Johnson, 1987; Langacker, 1987; Lakoff,
1994) suggests that the structure of abstract actions
(such as states, causes, purposes, and means) are
characterized cognitively in terms of image schemas
which are schematized recurring patterns from the
embodied domains of force, motion, and space.
Consider our conceptualization of events as ex-
emplified in the mapping called the Event Structure
Metaphor.
</bodyText>
<listItem confidence="0.997276333333333">
• States are locations (bounded regions in space).
• Changes are movements (into or out of
bounded regions).
</listItem>
<note confidence="0.5338535">
Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48,
New York City, June 2006. c�2006 Association for Computational Linguistics
</note>
<listItem confidence="0.99969375">
• Causes are forces. The benefit of employing the metaphor-based ap-
• Actions are self-propelled movements. proach, as suggested in the introduction, comes
• Purposes are destinations. when performing inference. As shown by
• Difficulties are impediments to motion. (Narayanan, 1997), a metaphorical usage and a lit-
</listItem>
<bodyText confidence="0.996976761904762">
This mapping generalizes over an extremely wide eral usage share inferential structure. For example,
range of expressions for one or more aspects of event the aspectual structure of run is the same in either
structure. For example, take states and changes. We domain whether it is literal or metaphorical usage.
speak of being in or out of a state, of entering or Further, this sharing of inferential structure between
leaving it, of getting to a state or emerging from it. the source and target domains simplifies the repre-
This is a rich and complex metaphor whose parts sentational mechanisms used for inference making
interact in complex ways. To get an idea of how it easier to build the world models necessary for
it works, consider the submapping Difficulties are knowledge-intensive tasks like question answering
impediments to motion. In the metaphor, purpose- (Sinha and Narayanan, 2005).
ful action is self-propelled motion toward a destina- 3 Objective
tion. A difficulty is something that impedes such While this work in Cognitive Semantics is sugges-
motion. Metaphorical difficulties of this sort come tive, without a corpus-based analysis, it is hard to
in five types: blockages; features of the terrain; bur- accurately estimate the importance of metaphoric in-
dens; counterforces; lack of an energy source. Here formation for Natural Language Processing (NLP)
are examples of each: Blockages: He’s trying to get tasks such as Question Answering or Information
around the regulations. We’ve got him boxed into Distillation. Our work is a first step to remedy this
a corner. Features of the terrain: It’s been uphill all situation. We start with our computational defini-
the way. We’ve been hacking our way through a jun- tion of metaphor as a mapping from concrete to ab-
gle of regulations. Burdens: He’s carrying quite a stract domains. We then investigate the Wall Street
load. Get off my back! Counterforces: Quit pushing Journal (WSJ) corpus, selecting a subset of its ver-
me around. She’s leading him around by the nose. bal targets and labeling them as either metaphoric
Lack of an energy source: I’m out of gas. We’re run- or literal. While we had anticipated the pervasive-
ning out of steam. ness of metaphor, we could not anticipate just how
In summary, these metaphors are ontological pervasive with over 90% of the labeled data being
mappings across conceptual domains, from the metaphoric.
source domain of motion and forces to the target do- Provided with labeled training data, our task is to
main of abstract actions. The mapping is conven- automatically classify the verbal targets of unseen
tional, that is, it is a fixed part of our conceptual sys- utterances as either metaphoric or literal. Motivated
tem, one of our conventional ways of conceptualiz- by the intuition that the types of a target’s arguments
ing actions. Conventional metaphors capture gener- are important for making this determination, we ex-
alizations governing polysemy, over inference pat- tracted information about the arguments from the
terns, and governing novel metaphorical language PropBank (Kingsbury et al., 2002) annotation for
(Lakoff and Turner, 1989). each sentence, using WordNet (Fellbaum, 1998) as
2.1 Metaphors vs. Different Word Senses the type hierarchy.
Presumably, one could treat the metaphoric usage of 3.1 Using Verbal Arguments
run as a different sense, much in the same way that A metaphor is a structured mapping between the
move forward on a business plan is treated as a dif- roles of two frames that makes it possible to describe
ferent sense from literal move forward. From a pars- a (usually) more abstract concept in terms of a more
ing/information extraction point of view, these two concrete one (Lakoff and Johnson, 1980). The more
approaches are equivalent in terms of their represen- abstract concept is referred to as the target domain
tational requirements. while the more concrete concept is referred to as the
42
</bodyText>
<listItem confidence="0.996268333333333">
1. MET: Texas Air has {run} into difficulty...
2. LIT : “I was doing the laundry and nearly
broke my neck {running} upstairs to see ...
</listItem>
<figureCaption confidence="0.907745">
Figure 1: Examples taken from the WSJ Corpus.
</figureCaption>
<bodyText confidence="0.85445224">
MET indicates a metaphoric use of the target verb
and LIT indicates a literal use.
source domain. More precisely, the metaphor maps
roles of the target frame onto the source frame.
Figure 1 shows some example sentences with a
particular verbal target run in curly braces. Example
1 is a metaphoric usage (marked by MET) of run
where the destination role is filled by the state of
difficulty. Example 2 is a literal usage (marked by
LIT) of run.
The arguments of a verb are an important fac-
tor for determining whether that verb is being used
metaphorically. If they come from the source do-
main frame, then the likelihood is high that the verb
is being used literally. In the example literal sen-
tence from Figure 1, the theme is a person, which is
a physical object and thus part of the source domain.
If, on the other hand, the arguments come from
the target domain, then it is likely that the verb is
being used metaphorically. Consider the metaphor-
ical run from Figure 1. In that case, both the theme
and the goal of the action are from the target domain.
Thus any approach that tries to classify sentences as
literal or metaphoric must somehow incorporate in-
formation about verbal arguments.
</bodyText>
<sectionHeader confidence="0.997051" genericHeader="method">
4 Data
</sectionHeader>
<bodyText confidence="0.999865071428571">
Because no available corpus is labeled for the
metaphoric/literal distinction, we labeled a subset
of the WSJ corpus for our experiments. To focus
the task, we concentrated on motion-related frames
that act as the source domain for the Event Structure
Metaphor and some additional non-motion based
frames including Cure and Placing. Figure 2 shows
the selected frames along with example lexical units
from each frame.
To identify relevant sentences we first obtained
from FrameNet a list of lexical units that evoke
the selected source frames. Since WSJ is labeled
with PropBank word senses, we then had to deter-
mine which PropBank senses correspond to these
</bodyText>
<table confidence="0.981134125">
Frame Example LUs
Motion float, glide, go, soar
Motion-directional drop, fall, plummet
Self-motion amble, crawl, hobble
Cause-motion catapult, haul, throw, yank
Cotheme accompany, escort, pursue
Placing cram, heap, pocket, tuck
Cure cure, ease, heal, treat
</table>
<figureCaption confidence="0.980426">
Figure 2: The frames selected for annotation and
some of the lexical units that evoke them.
</figureCaption>
<figure confidence="0.625965625">
Cure Frame LU PropBank Sense
alleviate alleviate.01
cure cure.01
ease ease.02
heal heal.01
rehabilitate rehabilitate.01
resuscitate resuscitate.01
treat treat.03
</figure>
<figureCaption confidence="0.716025">
Figure 3: The lexical units that evoke the Cure frame
and each unit’s associated PropBank sense2.
FrameNet lexical items. The lexical items that evoke
the Cure frame and the corresponding PropBank
senses are shown in Figure 3.
</figureCaption>
<bodyText confidence="0.999744352941176">
As anyone who has inspected both PropBank and
FrameNet can attest, these two important lexical
resources have chosen different ways to describe
verbal senses and thus in many cases, determining
which PropBank sense corresponds to a particular
FrameNet sense is not a straightforward process.
Verbs like slide have a single PropBank sense used
to describe both the slid in The book slid off the ta-
ble and the slid in I slid the book off the table. While
FrameNet puts slide both in the Motion frame and
in the Cause-motion frame, PropBank uses the argu-
ment labeling to distinguish these two senses.
Periodically, PropBank has two senses, one for
the literal interpretation and one for the metaphoric
interpretation, where FrameNet uses a single sense.
Consider the word hobble and its two senses in Prop-
Bank:
</bodyText>
<listItem confidence="0.993641666666667">
• hobble.01 ”walk as if feet tied together”
• hobble.02 ”tie the feet of, metaphorically ’hin-
der’”
</listItem>
<page confidence="0.998176">
43
</page>
<table confidence="0.9987133125">
Frame #MET #LIT Total %MET
Cause-motion 461 44 505 91
Cotheme 926 8 934 99
Motion-directional 1087 21 1108 98
Placing 888 110 998 89
Self-motion 424 86 510 83
Cure 105 26 131 80
All Frames 3891 295 4186 93
Lexical Unit #MET #LIT
alleviate 8 0
cure 7 3
ease 81 0
heal 3 0
rehabilitate 1 0
resuscitate 2 0
treat 3 23
</table>
<figureCaption confidence="0.9690945">
Figure 4: The number of targets annotated
metaphoric or literal, broken down by frame.
</figureCaption>
<bodyText confidence="0.997995692307692">
Because we intended to classify both literal and
metaphoric language, both PropBank senses of hob-
ble were included. However most verbs do not have
distinct literal and metaphoric senses in PropBank.
The final step in obtaining the relevant portion of
the WSJ corpus is to use the lists of PropBank senses
that corresponding to the FrameNet frames and ex-
tract sentences with these targets. Because the Prop-
Bank annotations label which PropBank sense is be-
ing annotated, this process is straightforward.
Having obtained the WSJ sentences with items
that evoke the selected source frames, we labeled the
data using a three-way split:
</bodyText>
<listItem confidence="0.9931535">
• MET: indicating metaphoric use of the target
• LIT: indicating literal use of the target
• ? : indicating a target that the annotator was
unsure of
</listItem>
<bodyText confidence="0.99771575">
For our experiments, we concentrated only on those
cases where the label was MET or LIT and ignored
the unclear cases.
As is shown in Figure 4, the WSJ data is heav-
ily weighted towards metaphor over all the frames
that we annotated. This tremendous bias towards
metaphoric usage of motion/cause-motion lexical
items shows just how prevalent the Event Structure
Metaphor is, especially in the domain of economics
where it is used to describe market fluctuations and
policy decisions.
Figure 5 shows the breakdown for each lexical
item in the Cure frame. Note that most of the fre-
quently occurring verbs are strongly biased towards
either a literal or metaphoric usage. Ease, for ex-
ample, in all 81 of its uses describes the easing of an
</bodyText>
<figureCaption confidence="0.993922">
Figure 5: The lexical units that evoke the Cure frame
and each unit’s counts for metaphoric (#MET) and
literal (#LIT) usage.
</figureCaption>
<bodyText confidence="0.824191">
economic condition and not the easing of pain. Treat
on the other hand, is overwhelmingly biased towards
the treating of physical and psychological disorders
and is only rarely used for an abstract disorder.
</bodyText>
<sectionHeader confidence="0.984672" genericHeader="method">
5 The Approach
</sectionHeader>
<bodyText confidence="0.9855165">
As has been discussed in this paper, there are at
least two factors that are useful in determining
whether the verbal target of an utterance is being
used metaphorically:
</bodyText>
<listItem confidence="0.983064">
1. The bias of the verb
2. The arguments of the verbal target in that utter-
ance
</listItem>
<bodyText confidence="0.996589">
To determine whether the arguments suggest
a metaphoric or a literal interpretation, the sys-
tem needs access to information about which con-
stituents of the utterance correspond to the argu-
ments of the verbal target. The PropBank annota-
tions fill this role in our system. For each utterance
that is used for training or needs to be classified, the
gold standard PropBank annotation is used to deter-
mine the verbal target’s arguments.
For every verbal target in question, we used the
following method to extract the types of its argu-
ments:
</bodyText>
<listItem confidence="0.993008">
1. Used PropBank to extract the target’s argu-
ments.
2. For each argument, we extracted its head using
rules closely based on (Collins, 1999).
</listItem>
<page confidence="0.982234">
44
</page>
<table confidence="0.995983833333333">
Feature Schema Example Instantiation Comment
verb verb=treat The verbal target
ARG0 TYPE uninstantiated ARG0 (Doctor role) not present
ARG1 TYPE uninstantiated ARG1 (Patient role) not present
ARG2 TYPE ARG2 TYPE=anemia The WordNet type is anemia.
ARG3 TYPE ARG3 TYPE=drug The WordNet type is drug.
</table>
<figureCaption confidence="0.991649">
Figure 6: The feature schemas used for classification. The instantiated features are drawn from the sentence
</figureCaption>
<bodyText confidence="0.395482">
The drug is being used primarily to {treat} anemias.
</bodyText>
<listItem confidence="0.653600428571429">
3. If the head is a pronoun, use the pronoun type
(without coreference resolution) as the type of
the argument.
4. If the head is a named entity, use the Identi-
finder tag as the type of the argument (BBN
Identifinder, 2004).
5. If neither, use the name of the head’s WordNet
</listItem>
<bodyText confidence="0.995546692307692">
synset as the type of the argument.
Consider the sentence The drug is being used pri-
marily to {treat} anemias. The PropBank annota-
tion of this sentence marks the drug as ARG3 and
anemias as ARG2. We turned this information into
features for the classifier as shown in Figure 6.
The verb feature is intended to capture the bias
of the verb. The ARGX TYPE feature captures the
type of the arguments directly. To measure the trade-
offs between various combinations of features, we
randomly partitioned the data set into a training set
(65% of the data), a validation set (15% of the data),
and a test set (20% of the data).
</bodyText>
<sectionHeader confidence="0.999986" genericHeader="evaluation">
6 Results
</sectionHeader>
<subsectionHeader confidence="0.999027">
6.1 Classifier Choice
</subsectionHeader>
<bodyText confidence="0.9997285">
Because of its ease of use and Java compatibility,
we used an updated version of the Stanford condi-
tional log linear (aka maxent) classifier written by
Dan Klein (Stanford Classifier, 2003). Maxent clas-
sifiers are designed to maximize the conditional log
likelihood of the training data where the conditional
likelihood of a particular class c on training example
i is computed as:
</bodyText>
<equation confidence="0.87483">
1
Z exp(fi · Wc)
</equation>
<bodyText confidence="0.985649">
Here Z is a normalizing factor, fi is the vector of
features associated with example i and wc is the vec-
tor of weights associated with class c. Additionally,
the Stanford classifier uses by default a Gaussian
prior of 1 on the features, thus smoothing the fea-
ture weights and helping prevent overfitting.
</bodyText>
<subsectionHeader confidence="0.996557">
6.2 Baselines
</subsectionHeader>
<bodyText confidence="0.999877777777778">
We use two different baselines to assess perfor-
mance. They correspond to selecting the major-
ity class of the training set overall or the major-
ity class of verb specifically. The strong bias to-
ward metaphor is reflected in the overall baseline of
93.80% for the validation set. The verb baseline is
higher, 95.50% for the validation set, due to the pres-
ence of words such as treat which are predominantly
literal.
</bodyText>
<subsectionHeader confidence="0.996031">
6.3 Validation Set Results
</subsectionHeader>
<bodyText confidence="0.97261905882353">
Figure 7 shows the performance of the classifier on
the feature sets described in the previous section.
The overall and verb baselines are 605 and 616 out
of 645 total examples in the validation set.
The first feature set we experimented with was
just the verb. We then added each argument in turn;
trying ARG0 (Feature Set 2), ARG1 (Feature Set 3),
ARG2 (Feature Set 4) and ARG3 (Feature Set 5).
Adding ARG1 gave the best performance gain.
ARG1 corresponds to the semantic role of mover
in most of PropBank annotations for motion-related
verbs. For example, stocks is labeled as ARG1 in
both Stocks fell 10 points and Stocks were being
thrown out of windows3. Intuitively, the mover role
is highly informative in determining whether a mo-
tion verb is being used metaphorically, thus it makes
sense that adding ARG1 added the single biggest
</bodyText>
<footnote confidence="0.975435">
3This is an actual sentence from the training set.
</footnote>
<page confidence="0.996683">
45
</page>
<table confidence="0.9334531">
FSet Feature Schemas M L Total %Tot
1 verb 599/605 20/40 619/645 95.97
2 verb, ARG0 TYPE 601/605 17/40 618/645 95.81
3 verb, ARG1 TYPE 602/605 19/40 621/645 96.28
4 verb, ARG2 TYPE 600/605 19/40 619/645 95.97
5 verb, ARG3 TYPE 599/605 20/40 619/645 95.97
6 verb, ARG1 TYPE, ARG3 TYPE 602/605 19/40 621/645 96.28
7 verb, ARG1 TYPE, ARG2 TYPE, ARG3 TYPE 601/605 18/40 619/645 95.97
8 verb, ARG0 TYPE, ARG1 TYPE, ARG2 TYPE 602/605 18/40 620/645 96.12
9 verb, ARG0 TYPE, ARG1 TYPE, ARG2 TYPE, ARG3 TYPE 602/605 17/40 619/645 95.97
</table>
<figureCaption confidence="0.9958675">
Figure 7: For each Feature Set, the feature schemas that define it, along with the ratio of correct to total
examples on the validation set for metaphor (M), literal (L) and total (Total) is shown.
</figureCaption>
<bodyText confidence="0.999583363636364">
jump in performance compared to the other argu-
ments.
Once we determined that ARG1 was the best ar-
gument to add, we also experimented with combin-
ing ARG1 with the other arguments. Validation re-
sults are shown for these other feature combinations
(Feature Sets 6,7, 8 and 9)
Using the best feature sets (Feature Sets 3,6), 621
targets are correctly labeled by the classifier. The
accuracy is 96.98%, reducing error on the validation
set by 40% and 17% over the baselines.
</bodyText>
<subsectionHeader confidence="0.999871">
6.4 Test Set Results
</subsectionHeader>
<bodyText confidence="0.897517444444444">
We retrained the classifier using Feature Set 3 over
the training and validation sets, then tested it on the
test set. The overall and verb baselines are 800 and
817 out of 861 total examples, respectively. The
classifier correctly labeled 819 targets in the test set.
The results, broken down by frame, are shown in
Figure 8. The final accuracy of 95.12%, represents
a reduction of error by 31% and 5% over the base-
lines.
</bodyText>
<subsectionHeader confidence="0.949674">
6.5 Discussion
</subsectionHeader>
<bodyText confidence="0.999384272727273">
A comprehensive assessment of the classifier’s
performance requires a measure of interannotator
agreement. Interannotator agreement represents a
ceiling on the performance that can be expected on
the classification task. Due to the very high base-
line, even rare disagreements by human annotators
affects the interpretation of the classifier’s perfor-
mance. Unfortunately, we did not have the resources
available to redundantly annotate the corpus.
We examined the 42 remaining errors and catego-
rized them into four types:
</bodyText>
<listItem confidence="0.997723333333333">
• 13 fixable errors
• 27 errors caused by verbal biases
• 2 errors caused by bias in the training set
</listItem>
<bodyText confidence="0.999984642857143">
The fixable errors are those that could be fixed
given more experimentation with the feature sets and
more data. Many of these errors are probably caused
by the verbal bias, but a verbal bias that should not
be insurmountable (for example, 2 or 3 metaphor to
each 1 literal).
The 27 errors caused by verbal biases are ones
where the verb is so strongly biased to a particu-
lar metaphoric class that it is unsurprising that a test
example of the opposite class was missed. Verbs
like treat (0 metaphoric to 20 literal) and lead (345
metaphoric to 0 literal) are in this category.
The two remaining errors are cases where the verb
was not present in the training data.
</bodyText>
<sectionHeader confidence="0.999812" genericHeader="related work">
7 Related Work
</sectionHeader>
<bodyText confidence="0.9999047">
Previous work on automated metaphor detection
includes Fass (1991), Martin (1990), and Mason
(2004). Whereas our aim is to classify unseen
sentences as literal or metaphorical, these projects
address the related but distinct task of identifying
metaphorical mappings. All three use the selectional
preferences of verbs to identify metaphors. In lit-
eral usage, the arguments that fill particular roles of
a verb are frequently of a common type. For in-
stance, in the MEDICAL domain, the object of the
</bodyText>
<page confidence="0.997532">
46
</page>
<table confidence="0.999256875">
Frame M L Total %Tot %OBL %VBL
Cause motion 78/78 1/10 79/88 89.77 88.64 88.64
Cotheme 179/179 0/2 179/181 98.90 98.90 98.90
Cure 26/30 3/3 29/33 87.88 90.91 90.91
Motion directional 242/242 0/2 242/244 99.18 99.18 99.18
Placing 176/181 13/25 189/206 91.75 87.86 91.26
Self motion 87/90 14/19 101/109 92.66 82.57 91.74
All Frames 788/800 31/61 819/861 95.12 92.92 94.89
</table>
<figureCaption confidence="0.6942135">
Figure 8: The results of the classifier on the test set, using Feature Set 6. For each frame, the ratio of correct
to total examples for metaphor (M), literal (L) and total (Total) is shown. The total percent correct for the
frame (%Tot), the overall baseline percentage (%OBL), and the verb baseline percentage (%VBL) are also
shown. The cumulative performance over all frames is located in the bottom row of the table.
</figureCaption>
<bodyText confidence="0.999786790697675">
verb treat is usually a pathological state. In the FI-
NANCE domain, the object of treat is usually an
economic problem. This difference in selectional
preference suggests metaphorical usage. Further-
more, it suggests a metaphorical mapping between
health problems and economic problems.
The systems described by Fass and Martin exhibit
impressive reasoning capabilities such as identify-
ing novel metaphors, distinguishing metaphor from
metonymy, and interpreting some metaphorical sen-
tences. But they require hand-coded knowledge
bases and thus have limited coverage and are dif-
ficult to extend. More similar to our efforts, Ma-
son’s CorMet uses a corpus-based approach. In
CorMet, domains are characterized by certain key-
words which are used to compile domain-specific
corpora from the internet. Based on differences in
selectional preferences between domains, CorMet
seeks to identify metaphorical mappings between
concepts in those domains.
One shortcoming of using syntactic arguments
is reflected by CorMet’s mistaken identification of
a mapping between institutions and liquids. This
arises from sentences like The company dissolved
and The acid dissolved the compound. Such sen-
tences suggest a mapping between the subjects in
the target domain, institutions, and the subjects in
source domain, liquids. Using semantic roles avoids
this source of noise. This is not to suggest that the
syntactic features are unimportant, indeed the selec-
tional preferences determined by CorMet could be
used to select which arguments to use for features in
our classifier.
Our approach considers each sentence in isola-
tion. However the distribution of metaphorical us-
age is not uniform in the WSJ corpus (Martin,
1994),. It is therefore possible that the information
about surrounding sentences would be useful in de-
termining whether a usage is metaphorical. CorMet
incorporates context in a limited way, computing
a confidence rating, based in part upon whether a
metaphoric mapping co-occurs with others in a sys-
tematic way.
</bodyText>
<sectionHeader confidence="0.997374" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999929333333333">
Metaphors are a ubiquitous phenomenon in lan-
guage, and our corpus analysis clearly bears this out.
It is somewhat gratifying that with a judicious com-
bination of the available wide-coverage resources
(WordNet, FrameNet, PropBank) we were able to
build classifiers that could outperform the baseline
even in the most skewed cases. Our results show the
utility of our approach and more generally the matu-
rity of the current NLP technology to make progress
in attacking the challenging and important problem
of interpreting figurative language.
However, this is only the first step. As with all
semantic extraction methods and technologies, the
proof of utility is not in how good the extractor is
but how much it helps in an actual task. As far
as we can tell, this problem remains open for the
entire semantic parsing/role labeling/extraction field
despite the flurry of activity in the last four years. In
the case of metaphor interpretation, we have some
initial encouragement from the results published by
(Narayanan, 1997) and others.
</bodyText>
<page confidence="0.997225">
47
</page>
<bodyText confidence="0.999959363636364">
Our classifier relies on PropBank senses, so we
can use the high performance classifiers available
for PropBank. The price is that we have to con-
struct mappings from FrameNet frames to PropBank
senses. However, this is a one-time effort pursued
by many groups, so this should not present a prob-
lem to extending our approach to cover all frames
and metaphors. Additionally, we are in the process
of linking the metaphor detector to a metaphor infer-
ence system. We hope to have initial results to report
on by conference time.
</bodyText>
<sectionHeader confidence="0.999427" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9993292">
BBN Identifinder. 2004.
http://www.bbn.com/for government customers/
data indexing and mining/identifinder.html.
Michael Collins. 1999. Head-Driven Statistical Models
of Natural Language Parsing. Ph.D. thesis, University
of Pennsylvania.
Dan Fass. 1991. Met*: a method for discriminating
metonymy and metaphor by computer. Comput. Lin-
guist., 17(1):49–90.
Christine Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Mark Johnson. 1987. The Body in the Mind: The Bodily
Basis of Meaning, Imagination and Reason. Univer-
sity of Chicago Press.
Paul Kingsbury, Martha Palmer, and Mitchell Marcus.
2002. Adding semantic annotation to the penn tree-
bank. In Proceedings of the Human Language Tech-
nology Conference.
George Lakoff and Mark Johnson. 1980. Metaphors We
Live By. University of Chicago Press.
George Lakoff and Mark Turner. 1989. More Than Cool
Reason: A Field Guide to Poetic Metaphor. University
of Chicago Press.
George Lakoff. 1994. The contemporary theory of
metaphor. In Andrew Ortony, editor, Metaphor and
Thought. Cambridge University Press.
Ronald Langacker. 1987. Foundations of Cognitive
Grammar I: Theoretical Prerequisites. Stanford Uni-
versity Press.
James Martin. 1990. Computational Model of Metaphor
Interpretation. Academic Press.
J.H. Martin. 1994. A corpus-based analysis of context
effects on metaphor comprehension. Technical report,
Boulder: University of Colorado: Computer Science
Department.
Zachary J. Mason. 2004. Cormet: a computational,
corpus-based conventional metaphor extraction sys-
tem. Comput. Linguist., 30(1):23–44.
Srini Narayanan and Sanda Harabagiu. 2004. Question
answering based on semantic structures. In Proceed-
ings of the International Conference on Computational
Linguistics.
Srini Narayanan. 1997. Knowledge-Based Action Rep-
resentations for Metaphor and Aspect. Ph.D. thesis,
University of California at Berkeley.
Steve Sinha and Srini Narayanan. 2005. Model-based
answer selection. In Proceedings of the AAAI Work-
shop on Inference for Textual Question Answering.
Stanford Classifier. 2003.
http://nlp.stanford.edu/software/classifier.shtml.
</reference>
<page confidence="0.999304">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.870820">
<title confidence="0.99957">Catching Metaphors</title>
<author confidence="0.975739">John Bryant Gedigian</author>
<author confidence="0.975739">Srini Narayanan</author>
<affiliation confidence="0.998123">International Computer Science</affiliation>
<address confidence="0.9958695">1947 Center Street. Suite Berkeley, CA 94704,</address>
<email confidence="0.967766">jbryant,</email>
<abstract confidence="0.99647352">Metaphors are ubiquitous in language and developing methods to identify and deal with metaphors is an open problem in Natural Language Processing (NLP). In this paper we describe results from using a maximum entropy (ME) classifier to identify metaphors. Using the Wall Street Journal (WSJ) corpus, we annotated all the verbal targets associated with a set of frames which includes frames of spatial motion, manipulation, and health. surprising finding was that over of annotated targets from these frames are used metaphorically, underscoring the importance of processing figurative language. We then used this labeled data and each verbal target’s PropBank annotation to train a maximum entropy classifier to make this literal vs. metaphoric distinction. Using the classifier, we reduce the final error in the test set by 5% over the verb-specific majority class baseline and 31% over the corpus-wide majority class baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>BBN Identifinder</author>
</authors>
<title>http://www.bbn.com/for government customers/ data indexing and mining/identifinder.html.</title>
<date>2004</date>
<contexts>
<context position="14904" citStr="Identifinder, 2004" startWordPosition="2419" endWordPosition="2420"> verbal target ARG0 TYPE uninstantiated ARG0 (Doctor role) not present ARG1 TYPE uninstantiated ARG1 (Patient role) not present ARG2 TYPE ARG2 TYPE=anemia The WordNet type is anemia. ARG3 TYPE ARG3 TYPE=drug The WordNet type is drug. Figure 6: The feature schemas used for classification. The instantiated features are drawn from the sentence The drug is being used primarily to {treat} anemias. 3. If the head is a pronoun, use the pronoun type (without coreference resolution) as the type of the argument. 4. If the head is a named entity, use the Identifinder tag as the type of the argument (BBN Identifinder, 2004). 5. If neither, use the name of the head’s WordNet synset as the type of the argument. Consider the sentence The drug is being used primarily to {treat} anemias. The PropBank annotation of this sentence marks the drug as ARG3 and anemias as ARG2. We turned this information into features for the classifier as shown in Figure 6. The verb feature is intended to capture the bias of the verb. The ARGX TYPE feature captures the type of the arguments directly. To measure the tradeoffs between various combinations of features, we randomly partitioned the data set into a training set (65% of the data)</context>
</contexts>
<marker>Identifinder, 2004</marker>
<rawString>BBN Identifinder. 2004. http://www.bbn.com/for government customers/ data indexing and mining/identifinder.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models of Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="14216" citStr="Collins, 1999" startWordPosition="2307" endWordPosition="2308">eral interpretation, the system needs access to information about which constituents of the utterance correspond to the arguments of the verbal target. The PropBank annotations fill this role in our system. For each utterance that is used for training or needs to be classified, the gold standard PropBank annotation is used to determine the verbal target’s arguments. For every verbal target in question, we used the following method to extract the types of its arguments: 1. Used PropBank to extract the target’s arguments. 2. For each argument, we extracted its head using rules closely based on (Collins, 1999). 44 Feature Schema Example Instantiation Comment verb verb=treat The verbal target ARG0 TYPE uninstantiated ARG0 (Doctor role) not present ARG1 TYPE uninstantiated ARG1 (Patient role) not present ARG2 TYPE ARG2 TYPE=anemia The WordNet type is anemia. ARG3 TYPE ARG3 TYPE=drug The WordNet type is drug. Figure 6: The feature schemas used for classification. The instantiated features are drawn from the sentence The drug is being used primarily to {treat} anemias. 3. If the head is a pronoun, use the pronoun type (without coreference resolution) as the type of the argument. 4. If the head is a nam</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models of Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Fass</author>
</authors>
<title>Met*: a method for discriminating metonymy and metaphor by computer.</title>
<date>1991</date>
<journal>Comput. Linguist.,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="20684" citStr="Fass (1991)" startWordPosition="3417" endWordPosition="3418">e probably caused by the verbal bias, but a verbal bias that should not be insurmountable (for example, 2 or 3 metaphor to each 1 literal). The 27 errors caused by verbal biases are ones where the verb is so strongly biased to a particular metaphoric class that it is unsurprising that a test example of the opposite class was missed. Verbs like treat (0 metaphoric to 20 literal) and lead (345 metaphoric to 0 literal) are in this category. The two remaining errors are cases where the verb was not present in the training data. 7 Related Work Previous work on automated metaphor detection includes Fass (1991), Martin (1990), and Mason (2004). Whereas our aim is to classify unseen sentences as literal or metaphorical, these projects address the related but distinct task of identifying metaphorical mappings. All three use the selectional preferences of verbs to identify metaphors. In literal usage, the arguments that fill particular roles of a verb are frequently of a common type. For instance, in the MEDICAL domain, the object of the 46 Frame M L Total %Tot %OBL %VBL Cause motion 78/78 1/10 79/88 89.77 88.64 88.64 Cotheme 179/179 0/2 179/181 98.90 98.90 98.90 Cure 26/30 3/3 29/33 87.88 90.91 90.91 </context>
</contexts>
<marker>Fass, 1991</marker>
<rawString>Dan Fass. 1991. Met*: a method for discriminating metonymy and metaphor by computer. Comput. Linguist., 17(1):49–90.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christine Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christine Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>The Body in the Mind: The Bodily Basis of Meaning, Imagination and Reason.</title>
<date>1987</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="2403" citStr="Johnson, 1987" startWordPosition="357" endWordPosition="358"> these action models is called simulation. Such action models provide deep inferential capabilities for embodied domains. They can also, when provided with appropriate metaphoric mappings, be extended to cover metaphoric language (Narayanan, 1997). Exploiting the inferential capabilities of such action models over the broadest domain requires a system to determine whether a verb is being used literally or metaphorically. Such a system could then activate the necessary metaphoric mappings and initiate the appropriate simulation. 2 Metaphor Work in Cognitive Semantics (Lakoff and Johnson, 1980; Johnson, 1987; Langacker, 1987; Lakoff, 1994) suggests that the structure of abstract actions (such as states, causes, purposes, and means) are characterized cognitively in terms of image schemas which are schematized recurring patterns from the embodied domains of force, motion, and space. Consider our conceptualization of events as exemplified in the mapping called the Event Structure Metaphor. • States are locations (bounded regions in space). • Changes are movements (into or out of bounded regions). Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48, New York City, </context>
</contexts>
<marker>Johnson, 1987</marker>
<rawString>Mark Johnson. 1987. The Body in the Mind: The Bodily Basis of Meaning, Imagination and Reason. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
<author>Mitchell Marcus</author>
</authors>
<title>Adding semantic annotation to the penn treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Human Language Technology Conference.</booktitle>
<contexts>
<context position="6497" citStr="Kingsbury et al., 2002" startWordPosition="999" endWordPosition="1002">ta, our task is to main of abstract actions. The mapping is conven- automatically classify the verbal targets of unseen tional, that is, it is a fixed part of our conceptual sys- utterances as either metaphoric or literal. Motivated tem, one of our conventional ways of conceptualiz- by the intuition that the types of a target’s arguments ing actions. Conventional metaphors capture gener- are important for making this determination, we exalizations governing polysemy, over inference pat- tracted information about the arguments from the terns, and governing novel metaphorical language PropBank (Kingsbury et al., 2002) annotation for (Lakoff and Turner, 1989). each sentence, using WordNet (Fellbaum, 1998) as 2.1 Metaphors vs. Different Word Senses the type hierarchy. Presumably, one could treat the metaphoric usage of 3.1 Using Verbal Arguments run as a different sense, much in the same way that A metaphor is a structured mapping between the move forward on a business plan is treated as a dif- roles of two frames that makes it possible to describe ferent sense from literal move forward. From a pars- a (usually) more abstract concept in terms of a more ing/information extraction point of view, these two conc</context>
</contexts>
<marker>Kingsbury, Palmer, Marcus, 2002</marker>
<rawString>Paul Kingsbury, Martha Palmer, and Mitchell Marcus. 2002. Adding semantic annotation to the penn treebank. In Proceedings of the Human Language Technology Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="2388" citStr="Lakoff and Johnson, 1980" startWordPosition="353" endWordPosition="356">s of inference. Initiating these action models is called simulation. Such action models provide deep inferential capabilities for embodied domains. They can also, when provided with appropriate metaphoric mappings, be extended to cover metaphoric language (Narayanan, 1997). Exploiting the inferential capabilities of such action models over the broadest domain requires a system to determine whether a verb is being used literally or metaphorically. Such a system could then activate the necessary metaphoric mappings and initiate the appropriate simulation. 2 Metaphor Work in Cognitive Semantics (Lakoff and Johnson, 1980; Johnson, 1987; Langacker, 1987; Lakoff, 1994) suggests that the structure of abstract actions (such as states, causes, purposes, and means) are characterized cognitively in terms of image schemas which are schematized recurring patterns from the embodied domains of force, motion, and space. Consider our conceptualization of events as exemplified in the mapping called the Event Structure Metaphor. • States are locations (bounded regions in space). • Changes are movements (into or out of bounded regions). Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48, </context>
<context position="7132" citStr="Lakoff and Johnson, 1980" startWordPosition="1105" endWordPosition="1108">n for (Lakoff and Turner, 1989). each sentence, using WordNet (Fellbaum, 1998) as 2.1 Metaphors vs. Different Word Senses the type hierarchy. Presumably, one could treat the metaphoric usage of 3.1 Using Verbal Arguments run as a different sense, much in the same way that A metaphor is a structured mapping between the move forward on a business plan is treated as a dif- roles of two frames that makes it possible to describe ferent sense from literal move forward. From a pars- a (usually) more abstract concept in terms of a more ing/information extraction point of view, these two concrete one (Lakoff and Johnson, 1980). The more approaches are equivalent in terms of their represen- abstract concept is referred to as the target domain tational requirements. while the more concrete concept is referred to as the 42 1. MET: Texas Air has {run} into difficulty... 2. LIT : “I was doing the laundry and nearly broke my neck {running} upstairs to see ... Figure 1: Examples taken from the WSJ Corpus. MET indicates a metaphoric use of the target verb and LIT indicates a literal use. source domain. More precisely, the metaphor maps roles of the target frame onto the source frame. Figure 1 shows some example sentences w</context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>George Lakoff and Mark Johnson. 1980. Metaphors We Live By. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Turner</author>
</authors>
<title>More Than Cool Reason: A Field Guide to Poetic Metaphor.</title>
<date>1989</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="6538" citStr="Lakoff and Turner, 1989" startWordPosition="1005" endWordPosition="1008">ons. The mapping is conven- automatically classify the verbal targets of unseen tional, that is, it is a fixed part of our conceptual sys- utterances as either metaphoric or literal. Motivated tem, one of our conventional ways of conceptualiz- by the intuition that the types of a target’s arguments ing actions. Conventional metaphors capture gener- are important for making this determination, we exalizations governing polysemy, over inference pat- tracted information about the arguments from the terns, and governing novel metaphorical language PropBank (Kingsbury et al., 2002) annotation for (Lakoff and Turner, 1989). each sentence, using WordNet (Fellbaum, 1998) as 2.1 Metaphors vs. Different Word Senses the type hierarchy. Presumably, one could treat the metaphoric usage of 3.1 Using Verbal Arguments run as a different sense, much in the same way that A metaphor is a structured mapping between the move forward on a business plan is treated as a dif- roles of two frames that makes it possible to describe ferent sense from literal move forward. From a pars- a (usually) more abstract concept in terms of a more ing/information extraction point of view, these two concrete one (Lakoff and Johnson, 1980). The </context>
</contexts>
<marker>Lakoff, Turner, 1989</marker>
<rawString>George Lakoff and Mark Turner. 1989. More Than Cool Reason: A Field Guide to Poetic Metaphor. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
</authors>
<title>The contemporary theory of metaphor.</title>
<date>1994</date>
<editor>In Andrew Ortony, editor, Metaphor and Thought.</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="2435" citStr="Lakoff, 1994" startWordPosition="361" endWordPosition="362">imulation. Such action models provide deep inferential capabilities for embodied domains. They can also, when provided with appropriate metaphoric mappings, be extended to cover metaphoric language (Narayanan, 1997). Exploiting the inferential capabilities of such action models over the broadest domain requires a system to determine whether a verb is being used literally or metaphorically. Such a system could then activate the necessary metaphoric mappings and initiate the appropriate simulation. 2 Metaphor Work in Cognitive Semantics (Lakoff and Johnson, 1980; Johnson, 1987; Langacker, 1987; Lakoff, 1994) suggests that the structure of abstract actions (such as states, causes, purposes, and means) are characterized cognitively in terms of image schemas which are schematized recurring patterns from the embodied domains of force, motion, and space. Consider our conceptualization of events as exemplified in the mapping called the Event Structure Metaphor. • States are locations (bounded regions in space). • Changes are movements (into or out of bounded regions). Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48, New York City, June 2006. c�2006 Association fo</context>
</contexts>
<marker>Lakoff, 1994</marker>
<rawString>George Lakoff. 1994. The contemporary theory of metaphor. In Andrew Ortony, editor, Metaphor and Thought. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Langacker</author>
</authors>
<title>Foundations of Cognitive Grammar I: Theoretical Prerequisites.</title>
<date>1987</date>
<publisher>Stanford University Press.</publisher>
<contexts>
<context position="2420" citStr="Langacker, 1987" startWordPosition="359" endWordPosition="360">odels is called simulation. Such action models provide deep inferential capabilities for embodied domains. They can also, when provided with appropriate metaphoric mappings, be extended to cover metaphoric language (Narayanan, 1997). Exploiting the inferential capabilities of such action models over the broadest domain requires a system to determine whether a verb is being used literally or metaphorically. Such a system could then activate the necessary metaphoric mappings and initiate the appropriate simulation. 2 Metaphor Work in Cognitive Semantics (Lakoff and Johnson, 1980; Johnson, 1987; Langacker, 1987; Lakoff, 1994) suggests that the structure of abstract actions (such as states, causes, purposes, and means) are characterized cognitively in terms of image schemas which are schematized recurring patterns from the embodied domains of force, motion, and space. Consider our conceptualization of events as exemplified in the mapping called the Event Structure Metaphor. • States are locations (bounded regions in space). • Changes are movements (into or out of bounded regions). Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48, New York City, June 2006. c�2006</context>
</contexts>
<marker>Langacker, 1987</marker>
<rawString>Ronald Langacker. 1987. Foundations of Cognitive Grammar I: Theoretical Prerequisites. Stanford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Martin</author>
</authors>
<title>Computational Model of Metaphor Interpretation.</title>
<date>1990</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="20699" citStr="Martin (1990)" startWordPosition="3419" endWordPosition="3420">used by the verbal bias, but a verbal bias that should not be insurmountable (for example, 2 or 3 metaphor to each 1 literal). The 27 errors caused by verbal biases are ones where the verb is so strongly biased to a particular metaphoric class that it is unsurprising that a test example of the opposite class was missed. Verbs like treat (0 metaphoric to 20 literal) and lead (345 metaphoric to 0 literal) are in this category. The two remaining errors are cases where the verb was not present in the training data. 7 Related Work Previous work on automated metaphor detection includes Fass (1991), Martin (1990), and Mason (2004). Whereas our aim is to classify unseen sentences as literal or metaphorical, these projects address the related but distinct task of identifying metaphorical mappings. All three use the selectional preferences of verbs to identify metaphors. In literal usage, the arguments that fill particular roles of a verb are frequently of a common type. For instance, in the MEDICAL domain, the object of the 46 Frame M L Total %Tot %OBL %VBL Cause motion 78/78 1/10 79/88 89.77 88.64 88.64 Cotheme 179/179 0/2 179/181 98.90 98.90 98.90 Cure 26/30 3/3 29/33 87.88 90.91 90.91 Motion directio</context>
</contexts>
<marker>Martin, 1990</marker>
<rawString>James Martin. 1990. Computational Model of Metaphor Interpretation. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Martin</author>
</authors>
<title>A corpus-based analysis of context effects on metaphor comprehension.</title>
<date>1994</date>
<tech>Technical report,</tech>
<institution>Boulder: University of Colorado: Computer Science Department.</institution>
<contexts>
<context position="23616" citStr="Martin, 1994" startWordPosition="3875" endWordPosition="3876">s from sentences like The company dissolved and The acid dissolved the compound. Such sentences suggest a mapping between the subjects in the target domain, institutions, and the subjects in source domain, liquids. Using semantic roles avoids this source of noise. This is not to suggest that the syntactic features are unimportant, indeed the selectional preferences determined by CorMet could be used to select which arguments to use for features in our classifier. Our approach considers each sentence in isolation. However the distribution of metaphorical usage is not uniform in the WSJ corpus (Martin, 1994),. It is therefore possible that the information about surrounding sentences would be useful in determining whether a usage is metaphorical. CorMet incorporates context in a limited way, computing a confidence rating, based in part upon whether a metaphoric mapping co-occurs with others in a systematic way. 8 Conclusion Metaphors are a ubiquitous phenomenon in language, and our corpus analysis clearly bears this out. It is somewhat gratifying that with a judicious combination of the available wide-coverage resources (WordNet, FrameNet, PropBank) we were able to build classifiers that could out</context>
</contexts>
<marker>Martin, 1994</marker>
<rawString>J.H. Martin. 1994. A corpus-based analysis of context effects on metaphor comprehension. Technical report, Boulder: University of Colorado: Computer Science Department.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zachary J Mason</author>
</authors>
<title>Cormet: a computational, corpus-based conventional metaphor extraction system.</title>
<date>2004</date>
<journal>Comput. Linguist.,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="20717" citStr="Mason (2004)" startWordPosition="3422" endWordPosition="3423">bias, but a verbal bias that should not be insurmountable (for example, 2 or 3 metaphor to each 1 literal). The 27 errors caused by verbal biases are ones where the verb is so strongly biased to a particular metaphoric class that it is unsurprising that a test example of the opposite class was missed. Verbs like treat (0 metaphoric to 20 literal) and lead (345 metaphoric to 0 literal) are in this category. The two remaining errors are cases where the verb was not present in the training data. 7 Related Work Previous work on automated metaphor detection includes Fass (1991), Martin (1990), and Mason (2004). Whereas our aim is to classify unseen sentences as literal or metaphorical, these projects address the related but distinct task of identifying metaphorical mappings. All three use the selectional preferences of verbs to identify metaphors. In literal usage, the arguments that fill particular roles of a verb are frequently of a common type. For instance, in the MEDICAL domain, the object of the 46 Frame M L Total %Tot %OBL %VBL Cause motion 78/78 1/10 79/88 89.77 88.64 88.64 Cotheme 179/179 0/2 179/181 98.90 98.90 98.90 Cure 26/30 3/3 29/33 87.88 90.91 90.91 Motion directional 242/242 0/2 24</context>
</contexts>
<marker>Mason, 2004</marker>
<rawString>Zachary J. Mason. 2004. Cormet: a computational, corpus-based conventional metaphor extraction system. Comput. Linguist., 30(1):23–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Question answering based on semantic structures.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="1552" citStr="Narayanan and Harabagiu, 2004" startWordPosition="228" endWordPosition="231">a maximum entropy classifier to make this literal vs. metaphoric distinction. Using the classifier, we reduce the final error in the test set by 5% over the verb-specific majority class baseline and 31% over the corpus-wide majority class baseline. 1 Introduction To move beyond “factoid” style questions, question answering systems must rely on inferential mechanisms. To answer such commonplace questions as Which train should I take to get to the airport? requires justifications, predictions and recommendations that can only be produced through inference. 41 One such question answering system (Narayanan and Harabagiu, 2004) takes PropBank/FrameNet annotations as input, uses the PropBank targets to indicate which actions are being described with which arguments and produces an answer using probabilistic models of actions as the tools of inference. Initiating these action models is called simulation. Such action models provide deep inferential capabilities for embodied domains. They can also, when provided with appropriate metaphoric mappings, be extended to cover metaphoric language (Narayanan, 1997). Exploiting the inferential capabilities of such action models over the broadest domain requires a system to deter</context>
</contexts>
<marker>Narayanan, Harabagiu, 2004</marker>
<rawString>Srini Narayanan and Sanda Harabagiu. 2004. Question answering based on semantic structures. In Proceedings of the International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
</authors>
<title>Knowledge-Based Action Representations for Metaphor and Aspect.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California at Berkeley.</institution>
<contexts>
<context position="2037" citStr="Narayanan, 1997" startWordPosition="302" endWordPosition="303"> recommendations that can only be produced through inference. 41 One such question answering system (Narayanan and Harabagiu, 2004) takes PropBank/FrameNet annotations as input, uses the PropBank targets to indicate which actions are being described with which arguments and produces an answer using probabilistic models of actions as the tools of inference. Initiating these action models is called simulation. Such action models provide deep inferential capabilities for embodied domains. They can also, when provided with appropriate metaphoric mappings, be extended to cover metaphoric language (Narayanan, 1997). Exploiting the inferential capabilities of such action models over the broadest domain requires a system to determine whether a verb is being used literally or metaphorically. Such a system could then activate the necessary metaphoric mappings and initiate the appropriate simulation. 2 Metaphor Work in Cognitive Semantics (Lakoff and Johnson, 1980; Johnson, 1987; Langacker, 1987; Lakoff, 1994) suggests that the structure of abstract actions (such as states, causes, purposes, and means) are characterized cognitively in terms of image schemas which are schematized recurring patterns from the e</context>
<context position="3345" citStr="Narayanan, 1997" startWordPosition="494" endWordPosition="495">mplified in the mapping called the Event Structure Metaphor. • States are locations (bounded regions in space). • Changes are movements (into or out of bounded regions). Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48, New York City, June 2006. c�2006 Association for Computational Linguistics • Causes are forces. The benefit of employing the metaphor-based ap• Actions are self-propelled movements. proach, as suggested in the introduction, comes • Purposes are destinations. when performing inference. As shown by • Difficulties are impediments to motion. (Narayanan, 1997), a metaphorical usage and a litThis mapping generalizes over an extremely wide eral usage share inferential structure. For example, range of expressions for one or more aspects of event the aspectual structure of run is the same in either structure. For example, take states and changes. We domain whether it is literal or metaphorical usage. speak of being in or out of a state, of entering or Further, this sharing of inferential structure between leaving it, of getting to a state or emerging from it. the source and target domains simplifies the repreThis is a rich and complex metaphor whose pa</context>
</contexts>
<marker>Narayanan, 1997</marker>
<rawString>Srini Narayanan. 1997. Knowledge-Based Action Representations for Metaphor and Aspect. Ph.D. thesis, University of California at Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Sinha</author>
<author>Srini Narayanan</author>
</authors>
<title>Model-based answer selection.</title>
<date>2005</date>
<booktitle>In Proceedings of the AAAI Workshop on Inference for Textual Question Answering.</booktitle>
<contexts>
<context position="4273" citStr="Sinha and Narayanan, 2005" startWordPosition="643" endWordPosition="646">ther it is literal or metaphorical usage. speak of being in or out of a state, of entering or Further, this sharing of inferential structure between leaving it, of getting to a state or emerging from it. the source and target domains simplifies the repreThis is a rich and complex metaphor whose parts sentational mechanisms used for inference making interact in complex ways. To get an idea of how it easier to build the world models necessary for it works, consider the submapping Difficulties are knowledge-intensive tasks like question answering impediments to motion. In the metaphor, purpose- (Sinha and Narayanan, 2005). ful action is self-propelled motion toward a destina- 3 Objective tion. A difficulty is something that impedes such While this work in Cognitive Semantics is suggesmotion. Metaphorical difficulties of this sort come tive, without a corpus-based analysis, it is hard to in five types: blockages; features of the terrain; bur- accurately estimate the importance of metaphoric indens; counterforces; lack of an energy source. Here formation for Natural Language Processing (NLP) are examples of each: Blockages: He’s trying to get tasks such as Question Answering or Information around the regulations</context>
</contexts>
<marker>Sinha, Narayanan, 2005</marker>
<rawString>Steve Sinha and Srini Narayanan. 2005. Model-based answer selection. In Proceedings of the AAAI Workshop on Inference for Textual Question Answering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanford Classifier</author>
</authors>
<date>2003</date>
<note>http://nlp.stanford.edu/software/classifier.shtml.</note>
<contexts>
<context position="15797" citStr="Classifier, 2003" startWordPosition="2577" endWordPosition="2578">nto features for the classifier as shown in Figure 6. The verb feature is intended to capture the bias of the verb. The ARGX TYPE feature captures the type of the arguments directly. To measure the tradeoffs between various combinations of features, we randomly partitioned the data set into a training set (65% of the data), a validation set (15% of the data), and a test set (20% of the data). 6 Results 6.1 Classifier Choice Because of its ease of use and Java compatibility, we used an updated version of the Stanford conditional log linear (aka maxent) classifier written by Dan Klein (Stanford Classifier, 2003). Maxent classifiers are designed to maximize the conditional log likelihood of the training data where the conditional likelihood of a particular class c on training example i is computed as: 1 Z exp(fi · Wc) Here Z is a normalizing factor, fi is the vector of features associated with example i and wc is the vector of weights associated with class c. Additionally, the Stanford classifier uses by default a Gaussian prior of 1 on the features, thus smoothing the feature weights and helping prevent overfitting. 6.2 Baselines We use two different baselines to assess performance. They correspond t</context>
</contexts>
<marker>Classifier, 2003</marker>
<rawString>Stanford Classifier. 2003. http://nlp.stanford.edu/software/classifier.shtml.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>