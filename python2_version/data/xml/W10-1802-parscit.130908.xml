<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000112">
<title confidence="0.993837">
Error-tagged Learner Corpus of Czech
</title>
<author confidence="0.984646">
Jirka Hana
</author>
<affiliation confidence="0.8606765">
Charles University
Prague, Czech Republic
</affiliation>
<email confidence="0.977476">
first.last@gmail.com
</email>
<author confidence="0.986821">
Svatava Škodová
</author>
<affiliation confidence="0.8841235">
Technical University
Liberec, Czech Republic
</affiliation>
<email confidence="0.996053">
svatava.skodova@tul.cz
</email>
<sectionHeader confidence="0.993845" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999941833333333">
The paper describes a learner corpus of
Czech, currently under development. The
corpus captures Czech as used by non-
native speakers. We discuss its structure,
the layered annotation of errors and the an-
notation process.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999776517241379">
Corpora consisting of texts produced by non-
native speakers are becoming an invaluable source
of linguistic data, especially for foreign language
educators. In addition to morphosyntactic tag-
ging and lemmatisation, common in other corpora,
learner corpora can be annotated by information
relevant to the specific nonstandard language of
the learners. Cases of deviant use can be identi-
fied, emended and assigned a tag specifying the
type of the error, all of which helps to exploit the
richness of linguistic data in the texts. However,
annotation of this kind is a challenging tasks, even
more so for a language such as Czech, with its
rich inflection, derivation, agreement, and largely
information-structure-driven constituent order. A
typical learner of Czech makes errors across all
linguistic levels, often targeting the same form
several times.
The proposed annotation scheme is an attempt
to respond to the requirements of annotating a de-
viant text in such a language, striking a compro-
mise between the limitations of the annotation pro-
cess and the demands of the corpus user. The
three-level format allows for successive emenda-
tions, involving multiple forms in discontinuous
sequences. In many cases, the error type fol-
lows from the comparison of the faulty and cor-
rected forms and is assigned automatically, some-
times using information present in morphosyntac-
</bodyText>
<note confidence="0.715234333333333">
Alexandr Rosen
Charles University
Prague, Czech Republic
</note>
<email confidence="0.660294">
alexandr.rosen@ff.cuni.cz
</email>
<author confidence="0.855437">
Barbora Štindlová
</author>
<affiliation confidence="0.918146">
Technical University
Liberec, Czech Republic
</affiliation>
<email confidence="0.97155">
barbora.stindlova@tul.cz
</email>
<bodyText confidence="0.999920666666667">
tic tags, assigned by a tagger. In more complex
cases, the scheme allows for representing relations
making phenomena such as the violation of agree-
ment rules explicit.
After an overview of issues related to learner
corpora in §2 and a brief introduction to the project
of a learner corpus of Czech in §3 we present the
concept of our annotation scheme in §4, followed
by a description of the annotation process in §5.
</bodyText>
<sectionHeader confidence="0.944226" genericHeader="method">
2 Learner corpora
</sectionHeader>
<bodyText confidence="0.99991152173913">
A learner corpus, also called interlanguage or L2
corpus, is a computerised textual database of lan-
guage as produced by second language (L2) learn-
ers (Leech, 1998). Such a database is a very pow-
erful resource in research of second language ac-
quisition. It can be used to optimise the L2 learn-
ing process, to assist authors of textbooks and dic-
tionaries, and to tailor them to learners with a par-
ticular native language (L1).
More generally, a learner corpus – like other
corpora – serves as a repository of authentic data
about a language (Granger, 1998). In the do-
main of L2 acquisition and teaching of foreign lan-
guages, the language of the learners is called in-
terlanguage (Selinker, 1983).1 An interlanguage
includes both correct and deviant forms. The pos-
sibility to examine learners’ errors on the back-
ground of the correct language is the most impor-
tant aspect of learner corpora (Granger, 1998).
Investigating the interlanguage is easier when
the deviant forms are annotated at least by their
correct counterparts, or, even better, by tags mak-
ing the nature of the error explicit. Although
</bodyText>
<footnote confidence="0.988579">
1Interlanguage is distinguished by its highly individual
and dynamic nature. It is subject to constant changes as
the learner progresses through successive stages of acquiring
more competence, and can be seen as an individual and dy-
namic continuum between one’s native and target languages.
</footnote>
<page confidence="0.985003">
11
</page>
<note confidence="0.9561455">
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 11–19,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.942940625">
learner corpora tagged this way exist, the two
decades of research in this field have shown that
designing a tagset for the annotation of errors is a
task highly sensitive to the intended use of the cor-
pus and the results are not easily transferable from
one language to another.
Learner corpora can be classified according to
several criteria:
</bodyText>
<listItem confidence="0.949833868421053">
• Target language (TL): Most learner corpora
cover the language of learners of English as a
second or foreign language (ESL or EFL). The
number of learner corpora for other languages
is smaller but increasing.
• Medium: Learner corpora can capture written
or spoken texts, the latter much harder to com-
pile, thus less common.
• L1: The data can come from learners with the
same L1 or with various L1s.
• Proficiency in TL: Some corpora gather texts of
students at the same level, other include texts of
speakers at various levels. Most corpora focus
on advanced students.
• Annotation: Many learner corpora contain only
raw data, possibly with emendations, with-
out linguistic annotation; some include part-
of-speech (POS) tagging. Several include er-
ror tagging. Despite the time-consuming man-
ual effort involved, the number of error-tagged
learner corpora is growing.
Error-tagged corpora use the following tax-
onomies to classify the type of error:
• Taxonomies marking the source of error: The
level of granularity ranges from broad cate-
gories (morphology, lexis, syntax) to more spe-
cific ones (auxiliary, passive, etc.).
• Taxonomies based on formal types of alterna-
tion of the source text: omission, addition, mis-
formation, mis-ordering.
• Hierarchical taxonomies based on a combina-
tion of various aspects: error domain (formal,
grammatical, lexical, style errors), error cate-
gory (agglutination, diacritics, derivation inflec-
tion, auxiliaries, gender, mode, etc.), word cat-
egory (POS).
• Without error taxonomies, using only correction
as the implicit explanation for an error.
</listItem>
<bodyText confidence="0.989131">
In Table 1 we present a brief summary of ex-
isting learner corpora tagged by POS and/or er-
ror types, including the size of the corpus (in mil-
lions of words or Chinese characters), the mother
tongue of the learners, or – in case of learners
with different linguistic backgrounds – the num-
ber of mother tongues (L1), the TL and the learn-
ers’ level of proficiency in TL. For an extensive
overview see, for example (Pravec, 2002; Nessel-
hauf, 2004; Xiao, 2008).
</bodyText>
<figure confidence="0.799124181818182">
Size L1 TL TL proficiency
ICLE – Internat’l Corpus ofLearner English
3M 21 English advanced
CLC – Cambridge Learner Corpus
30M 130 English all levels
PELCRA – Polish Learner English Corpus
0.5M Polish English all levels
USE – Uppsala Student English Corpus
1.2M Swedish English advanced
HKUST – Hong Kong University of Science
and Technology Corpus ofLearner English
25M Chinese English advanced
CLEC – Chinese Learner English Corpus
1M Chinese English 5 levels
JEFLL – Japanese EFL Learner Corpus
0.7M Japanese English advanced
FALKO – Fehlerannotiertes Lernerkorpus
1.2M various German advanced
FRIDA – French Interlanguage Database
0.2M various French intermediate
CIC – Chinese Interlanguage Corpus
2M 96 Chinese intermediate
</figure>
<tableCaption confidence="0.995487">
Table 1: Some currently available learner corpora
</tableCaption>
<sectionHeader confidence="0.854785" genericHeader="method">
3 A learner corpus of Czech
</sectionHeader>
<bodyText confidence="0.999597111111111">
In many ways, building a learner corpus of Czech
as a second/foreign language is a unique enter-
prise. To the best of our knowledge, the CzeSL
corpus (Czech as a Second/Foreign Language) is
the first learner corpus ever built for a highly in-
flectional language, and one of the very few us-
ing multi-layer annotation (together with FALKO
– see Table 1). The corpus consists of 4 subcor-
pora according to the learners’ L1:
</bodyText>
<listItem confidence="0.9924994">
• The Russian subcorpus represents an interlan-
guage of learners with a Slavic L1.
• The Vietnamese subcorpus represents a numer-
ous minority of learners with very few points of
contact between L1 and Czech.
• The Romani subcorpus represents a linguistic
minority with very specific traits in the Czech
cultural context.
• The “remnant” subcorpus covers texts from
speakers of various L1s.
</listItem>
<bodyText confidence="0.9972315">
The whole extent of CzeSL will be two million
words (in 2012). Each subcorpus is again divided
</bodyText>
<page confidence="0.997557">
12
</page>
<bodyText confidence="0.999968294117647">
into two subcorpora of written and spoken texts;2
this division guarantees the representative charac-
ter of the corpus data. The corpus is based on
texts covering all language levels according to the
Common European Framework of Reference for
Languages, from real beginners (A1 level) to ad-
vanced learners (level B2 and higher). The texts
are elicited during various situations in classes;
they are not restricted to parts of written examina-
tion. This spectrum of various levels and situations
is unique in the context of other learner corpora.
Each text is equipped with the necessary back-
ground information, including sociological data
about the learner (age, gender, L1, country, lan-
guage level, other languages, etc.) and the sit-
uation (test, homework, school work without the
possibility to use a dictionary, etc.).
</bodyText>
<sectionHeader confidence="0.994297" genericHeader="method">
4 Annotation scheme
</sectionHeader>
<subsectionHeader confidence="0.9999">
4.1 The feasible and the desirable
</subsectionHeader>
<bodyText confidence="0.999933666666667">
The error tagging system for CzeSL is designed to
meet the requirements of Czech as an inflectional
language. Therefore, the scheme is:
</bodyText>
<listItem confidence="0.9845564">
• Detailed but manageable for the annotators.
• Informative – the annotation is appropriate to
Czech as a highly inflectional language.
• Open to future extensions – it allows for more
detailed taxonomy to be added in the future.
</listItem>
<bodyText confidence="0.999973315789474">
The annotators are no experts in Czech as a for-
eign language or in 2L learning and acquisition,
and they are unaware of possible interferences be-
tween languages the learner knows. Thus they
may fail to recognise an interferential error. A
sentence such as Tokio je pˇekný hrad ‘Tokio is a
nice castle’ is grammatically correct, but its au-
thor, a native speaker of Russian, was misled by
‘false friends’ and assumed hrad ‘castle’ as the
Czech equivalent of Russian gorod ‘town, city’.3
Similarly in Je tam hodnˇe sklep˚u ‘There are many
cellars.’ The formally correct sentence may strike
the reader as implausible in the context, but it is
impossible to identify and emend the error with-
out the knowledge that sklep in Russian means
‘grave’, not ‘cellar’ (= sklep in Czech).
For some types of errors, the problem is to de-
fine the limits of interpretation. The clause kdyby
citila na tebe zlobna is grammatically incorrect,
</bodyText>
<footnote confidence="0.914893">
2Transcripts of the spoken parts will be integrated with
the rest of the corpus at a later stage of the project.
3All examples are authentic.
</footnote>
<bodyText confidence="0.999914391304348">
yet roughly understandable as ‘if she felt angry at
you’. In such cases the task of the annotator is in-
terpretation rather than correction. The clause can
be rewritten as kdyby se na tebe cítila rozzlobená
‘if she felt angry at you’, or kdyby se na tebe zlo-
bila ‘if she were angry at you’; the former being
less natural but closer to the original, unlike the
latter. It is difficult to provide clear guidelines.
Errors in word order represent another specific
type. Czech constituent order reflects information
structure and it is sometimes difficult to decide
(even in a context) whether an error is present. The
sentence Rádio je taky na skˇríni ‘A radio is also on
the wardrobe’ suggests that there are at least two
radios in the room, although the more likely inter-
pretation is that among other things, there is also a
radio, which happens to sit on the wardrobe. Only
the latter interpretation would require a different
word order: Taky je na skˇríni rádio. Similarly
difficult may be decisions about errors labelled as
lexical and modality.
The phenomenon of Czech diglossia is reflected
in the problem of annotating non-standard lan-
guage, usually individual forms with colloquial
morphological endings. The learners may not be
aware of their status and/or an appropriate context
for their use, and the present solution assumes that
colloquial Czech is emended under the rationale
that the author expects the register of his text to be
perceived as unmarked.
On the other hand, there is the primary goal of
the corpus: to serve the needs of the corpus users.
The resulting error typology is a compromise be-
tween the limitations of the annotation process and
the demands of research into learner corpora.
The corpus can be used for comparisons among
learner varieties of Czech, studied as national in-
terlanguages (Russian, Vietnamese, Romani etc.)
using a matrix of statistic deviations. Similarly in-
teresting are the heterogeneous languages of learn-
ers on different stages of acquisition. From the
pedagogical point of view, corpus-based analy-
ses have led to a new inductive methodology of
data-driven learning, based on the usage of con-
cordances in exercises or to support students’ in-
dependent learning activities.
</bodyText>
<subsectionHeader confidence="0.974188">
4.2 The framework
</subsectionHeader>
<bodyText confidence="0.999617666666667">
Annotated learner corpora sometimes use data for-
mats and tools developed originally for annotating
speech. Such environments allow for an arbitrary
</bodyText>
<page confidence="0.994506">
13
</page>
<bodyText confidence="0.999849443181818">
segmentation of the input and multilevel annota-
tion of segments (Schmidt, 2009). Typically, the
annotator edits a table with columns correspond-
ing to words and rows to levels of annotation. A
cell can be split or more cells merged to allow for
annotating smaller or larger segments. This way,
phenomena such as agreement or word order can
be emended and tagged (LUdeling et al., 2005).
However, in the tabular format vertical corre-
spondences between the original word form and its
emended equivalents or annotations at other levels
may be lost. It is difficult to keep track of links
between forms merged into a single cell, spanning
multiple columns, and the annotations of a form
at other levels (rows). This may be a problem for
successive emendations involving a single form,
starting from a typo up to an ungrammatical word
order, but also for morphosyntactic tags assigned
to forms, whenever a form is involved in a multi-
word annotation and its equivalent or tag leaves
the column of the original form.
While in the tabular format the correspondences
between elements at various levels are captured
only implicitly, in our annotation scheme these
correspondences are explicitly encoded. Our for-
mat supports the option of preserving correspon-
dences across levels, both between individual
word forms and their annotations, while allowing
for arbitrary joining and splitting of any number
of non-contiguous segments. The annotation lev-
els are represented as a graph consisting of a set
of parallel paths (annotation levels) with links be-
tween them. Nodes along the paths always stand
for word tokens, correct or incorrect, and in a sen-
tence with nothing to correct the corresponding
word tokens in every pair of neighbouring paths
are linked 1:1. Additionally, the nodes can be as-
signed morphosyntactic tags, syntactic functions
or any other word-specific information. Whenever
a word form is emended, the type of error can be
specified as a label of the link connecting the in-
correct form at level Si with its emended form at
level Si+1. In general, these labelled relations can
link an arbitrary number of elements at one level
with an arbitrary number of elements at a neigh-
bouring level. The elements at one level partic-
ipating in this relation need not form a contigu-
ous sequence. Multiple words at any level are thus
identified as a single segment, which is related to a
segment at a neighbouring level, while any of the
participating word forms can retain their 1:1 links
with their counterparts at other levels. This is use-
ful for splitting and joining word forms, for chang-
ing word order, and for any other corrections in-
volving multiple words. Nodes can also be added
or omitted at any level to correct missing or odd
punctuation signs or syntactic constituents. See
Figure 1 below for an example of this multi-level
annotation scheme.
The option of relating multiple nodes as sin-
gle segments across levels could also be used for
treating morphosyntactic errors in concord and
government. However, in this case there is typ-
ically one correct form involved, e.g., the sub-
ject in subject-predicate agreement, the noun in
adjective-noun agreement, the verb assigning case
to a complement, the antecedent in pronominal
reference. Rather than treating both the correct
and the incorrect form as equals in a 2:2 relation
between the levels, the incorrect form is emended
using a 1:1 link with an option to refer to the cor-
rect form. Such references link pairs of forms at
neighbouring levels rather than the forms them-
selves to enable possible references from a multi-
word unit (or) to another multi-word unit. See Fig-
ure 1 below again, where such references are rep-
resented by arrows originating in labels val.
A single error may result in multiple incorrect
forms as shown in (1). The adjective velký ‘big-
NOM-SG-M(ASC)’ correctly agrees with the noun
pes ‘dog-NOM-SG-MASC’. However, the case of
the noun is incorrect – it should be in accusative
rather than nominative. When the noun’s case is
corrected, the case of the adjective has to be cor-
rected as well. Then multiple references are made:
to the verb as the case assigner for the noun, and
to the noun as the source of agreement for the ad-
jective.
</bodyText>
<listItem confidence="0.514355">
(1) a. *Vidˇel velký pes.
saw big-NOM-SG-M dog-NOM-SG-M
b. Vidˇel velkého psa.
</listItem>
<bodyText confidence="0.980605555555556">
saw big-ACC-SG-M dog-ACC-SG-M
‘He saw a big dog’
Annotation of learners’ texts is often far from
straightforward, and alternative interpretations are
available even in a broader context. The annota-
tion format supports alternatives, but for the time
being the annotation tool does not support local
disjunctions. This may be a problem if the anno-
tator has multiple target hypotheses in mind.
</bodyText>
<page confidence="0.994561">
14
</page>
<subsectionHeader confidence="0.980018">
4.3 Three levels of annotation
</subsectionHeader>
<bodyText confidence="0.99998785">
A multi-level annotation scheme calls for some
justification, and once such a scheme is adopted,
the question of the number of levels follows.
After a careful examination of alternatives, we
have arrived at a two-stage annotation design,
based on three levels. A flat, single-stage, two-
level annotation scheme would be appropriate if
we were interested only in the original text and
in the annotation at some specific level (fully
emended sentences, or some intermediate stage,
such as emended word forms). The flat design
could be used even if we insisted on registering
some intermediate stages of the passage from the
original to a fully emended text, and decided to
store such information with the word-form nodes.
However, such information might get lost in the
case of significant changes involving deletions or
additions (e.g., in Czech as a pro-drop language,
the annotator may decide that a misspelled per-
sonal pronoun in the subject position should be
deleted and the information about the spelling er-
ror would lost). The decision to use a multi-level
design was mainly due to our interest in annotat-
ing errors in single forms as well as those spanning
(potentially discontinuous) strings of words.
Once we have a scheme of multiple levels avail-
able, we can provide the levels with theoretical
significance and assign a linguistic interpretation
to each of them. In a world of unlimited re-
sources of annotators’ time and experience, this
would be the optimal solution. The first annota-
tion level would be concerned only with errors in
graphemics, followed by levels dedicated to mor-
phemics, morphosyntax, syntax, lexical phenom-
ena, semantics and pragmatics. More realistically,
there could be a level for errors in graphemics and
morphemics, another for errors in morphosyntax
(agreement, government) and one more for every-
thing else, including word order and phraseology.
Our solution is a compromise between corpus
users’ expected demands and limitations due to
the annotators’ time and experience. The anno-
tator has a choice of two levels of annotation, and
the distinction, based to a large extent on formal
criteria, is still linguistically relevant.
At the level of transcribed input (Level 0), the
nodes represent the original strings of graphemes.
At the level of orthographical and morphological
emendation (Level 1), only individual forms are
treated. The result is a string consisting of cor-
rect Czech forms, even though the sentence may
not be correct as a whole. The rule of “correct
forms only” has a few exceptions: a faulty form
is retained if no correct form could be used in the
context or if the annotator cannot decipher the au-
thor’s intention. On the other hand, a correct form
may be replaced by another correct form if the au-
thor clearly misspelled the latter, creating an un-
intended homograph with another form. All other
types of errors are emended at Level 2.
</bodyText>
<subsectionHeader confidence="0.996714">
4.4 Captured errors
</subsectionHeader>
<bodyText confidence="0.999988025641026">
A typical learner of Czech makes errors all along
the hierarchy of theoretically motivated linguistic
levels, starting from the level of graphemics up
to the level of pragmatics. Our goal is to emend
the input conservatively, modifying incorrect and
inappropriate forms and expressions to arrive at
a coherent and well-formed result, without any
ambition to produce a stylistically optimal solu-
tion. Emendation is possible only when the input
is comprehensible. In cases where the input or its
part is not comprehensible, it is left with a partial
or even no annotation.
The taxonomy of errors is rather coarse-grained,
a more detailed classification is previewed for a
later stage and a smaller corpus sample. It follows
the three-level distinction and is based on criteria
as straightforward as possible. Whenever the er-
ror type can be determined from the way the er-
ror is emended, the type is supplied automatically
by a post-processing module, together with mor-
phosyntactic tags and lemmas for the correct or
emended forms (see § 5.3).
Errors in individual word forms, treated at Level
1, include misspellings (also diacritics and capi-
talisation), misplaced word boundaries, missing or
misused punctuation, but also errors in inflectional
and derivational morphology and unknown stems.
These types of errors are emended manually, but
the annotator is not expected label them by their
type – the type of most errors at Level 1 is identi-
fied automatically. The only exception where the
error type must be assigned manually is when an
unknown stem or derivation affix is used.
Whenever the lexeme (its stem and/or suffix) is
unknown and can be replaced by a suitable form, it
is emended at Level 1. If possible, the form should
fit the syntactic context. If no suitable form can
be found, the form is retained and marked as un-
known. When the form exists, but is not appro-
</bodyText>
<page confidence="0.995144">
15
</page>
<bodyText confidence="0.9995065">
priate in context, it is emended at Level 2 – the
reason may be the violation of a syntactic rule or
semantic incompatibility of the lexeme.
Table 2 gives a list of error types emended at
Level 1. Some types actually include subtypes:
words can be incorrectly split or joined, punctu-
ation, diacritics or character(s) can be missing,
superfluous, misplaced or of a wrong kind. The
Links column gives the maximum number of po-
sitions at Level 0, followed by the maximum num-
ber of position at Level 1 that are related by links
for this type of error. The Id column says if the
error type is determined automatically or has to be
specified manually.
</bodyText>
<table confidence="0.47712325">
Error type Links Id
Word boundary m:n A
Punctuation 0:1, 1:0 A
Capitalisation 1:1 A
Diacritics 1:1 A
Character(s) 1:1 A
Inflection 1:1 A
Unknown lexeme 1:1 M
</table>
<tableCaption confidence="0.962756">
Table 2: Types of errors at Level 1
</tableCaption>
<bodyText confidence="0.999638333333333">
Emendations at Level 2 concern errors in agree-
ment, valency and pronominal reference, negative
concord, the choice of a lexical item or idiom,
and in word order. For the agreement, valency
and pronominal reference cases, there is typically
an incorrect form, which reflects some properties
(morphological categories, valency requirements)
of a correct form (the agreement source, syntac-
tic head, antecedent). Table 3 gives a list of error
types emended at Level 2. The Ref column gives
the number of pointers linking the incorrect form
with the correct “source”.
</bodyText>
<table confidence="0.997490090909091">
Error type Links Ref Id
Agreement 1:1 1 M
Valency 1:1 1 M
Pronominal reference 1:1 1 M
Complex verb forms m:n 0,1 M
Negation m:n 0,1 M
Missing constituent 0:1 0 M
Odd constituent 1:0 0 M
Modality 1:1 0 M
Word order m:n 0 M
Lexis &amp; phraseology m:n 0,1 M
</table>
<tableCaption confidence="0.999876">
Table 3: Types of errors at Level 2
</tableCaption>
<bodyText confidence="0.999980804347826">
The annotation scheme is illustrated in Figure 1,
using an authentic sentence, split in two halves for
space reasons. There are three parallel strings of
word forms, including punctuation signs, repre-
senting the three levels, with links for correspond-
ing forms. Any emendation is labelled with an er-
ror type.4 The first line is Level 0, imported from
the transcribed original, with English glosses be-
low (forms marked by asterisks are incorrect in
any context, but they may be comprehensible – as
is the case with all such forms in this example).
Correct words are linked directly with their copies
at Level 1, for emended words the link is labelled
with an error type. In the first half of the sentence,
unk for unknown form, dia for an error in diacrit-
ics, cap for an error in capitalisation. According to
the rules of Czech orthography, the negative parti-
cle ne is joined with the verb using an intermedi-
ate node bnd. A missing comma is introduced at
Level 1, labelled as a punctuation error. All the er-
ror labels above can be specified automatically in
the post-processing step.
Staying with the first half of the sentence, most
forms at Level 1 are linked directly with their
equivalents at Level 2 without emendations. The
reflexive particle se is misplaced as a second posi-
tion clitic, and is put into the proper position using
the link labelled wo for a word-order error.5 The
pronoun ona – ‘she’ in the nominative case – is
governed by the form líbit se, and should bear the
dative case: jí. The arrow to líbit makes the rea-
son for this emendation explicit. The result could
still be improved by positioning Praha after the
clitics and before the finite verb nebude, resulting
in a word order more in line with the underlying
information structure of the sentence, but our pol-
icy is to refrain from more subtle phenomena and
produce a grammatical rather than a perfect result.
In the second half of the sentence, there is only
one Level 1 error in diacritics, but quite a few er-
rors at Level 2. Proto ‘therefore’ is changed to
protože ‘because’ – a lexical emendation. The
main issue are the two finite verbs bylo and vadí.
The most likely intention of the author is best ex-
pressed by the conditional mood. The two non-
contiguous forms are replaced by the conditional
</bodyText>
<footnote confidence="0.978595428571429">
4The labels for error types used here are simplified for
reasons of space and mnemonics.
5In word-order errors it may be difficult to identify a spe-
cific word form violating a rule. The annotation scheme al-
lows for both se and jí to be blamed. However, here we pre-
fer the simpler option and identify just one, more prominent
word form. Similarly with mi below.
</footnote>
<page confidence="0.998409">
16
</page>
<bodyText confidence="0.999737363636363">
auxiliary and the content verb participle in one
step using a 2:2 relation. The intermediate node
is labelled by cplx for complex verb forms. The
prepositional phrase pro mnˇe ‘for me’ is another
complex issue. Its proper form is pro mˇe (homony-
mous with pro mnˇe, but with ‘me’ bearing ac-
cusative instead of dative), or pro mne. The ac-
cusative case is required by the preposition pro.
However, the head verb requires that this comple-
ment bears bare dative – mi. Additionally, this
form is a second position clitic, following the con-
ditional auxiliary (also a clitic) in the clitic cluster.
The change from PP to the bare dative pronoun
and the reordering are both properly represented,
including the pointer to the head verb. What is
missing is an explicit annotation of the faulty case
of the prepositional complement, which is lost
during the Level 1 – Level 2 transition, the price
for a simpler annotation scheme with fewer lev-
els. It might be possible to amend the PP at Level
1, but it would go against the rule that only forms
wrong in isolation are emended at Level 1.
</bodyText>
<figure confidence="0.828504">
Bojal jsem se že ona se ne bude libit prahu ,
*feared AUX RFL that she RFL not will *like prague ,
unk
</figure>
<figureCaption confidence="0.999914">
Figure 1: Annotation of a sample sentence
</figureCaption>
<subsectionHeader confidence="0.992322">
4.5 Data Format
</subsectionHeader>
<bodyText confidence="0.996982666666667">
To encode the layered annotation described above,
we have developed an annotation schema in the
Prague Markup Language (PML).6 PML is a
</bodyText>
<footnote confidence="0.900142">
6http://ufal.mff.cuni.cz/jazz/pml/
index_en.html
</footnote>
<figure confidence="0.992470219512195">
&lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&gt;
&lt;adata xmlns=&amp;quot;http://utkl.cuni.cz/czesl/&amp;quot;&gt;
&lt;head&gt;
&lt;schema href=&amp;quot;adata_schema.xml&amp;quot; /&gt;
&lt;references&gt;
&lt;reffile id=&amp;quot;w&amp;quot; name=&amp;quot;wdata&amp;quot; href=&amp;quot;r049.w.xml&amp;quot; /&gt;
&lt;/references&gt;
&lt;/head&gt;
&lt;doc id=&amp;quot;a-r049-d1&amp;quot; lowerdoc.rf=&amp;quot;w#w-r049-d1&amp;quot;&gt;
...
&lt;para id=&amp;quot;a-r049-d1p2&amp;quot; lowerpara.rf=&amp;quot;w#w-r049-d1p2&amp;quot;&gt;
...
&lt;s id=&amp;quot;a-r049-d1p2s5&amp;quot;&gt;
&lt;w id=&amp;quot;a-r049-d1p2w50&amp;quot;&gt;
&lt;token&gt;Bál&lt;/token&gt;
&lt;/w&gt;
&lt;w id=&amp;quot;a-r049-d1p2w51&amp;quot;&gt;
&lt;token&gt;jsem&lt;/token&gt;
&lt;/w&gt;
&lt;w id=&amp;quot;a-r049-d1p2w52&amp;quot;&gt;
&lt;token&gt;se&lt;/token&gt;
&lt;/w&gt;
...
&lt;/s&gt;
...
&lt;edge id=&amp;quot;a-r049-d1p2e54&amp;quot;&gt;
&lt;from&gt;w#w-r049-d1p2w46&lt;/from&gt;
&lt;to&gt;a-r049-d1p2w50&lt;/to&gt;
&lt;error&gt;
&lt;tag&gt;unk&lt;/tag&gt;
&lt;/error&gt;
&lt;/edge&gt;
&lt;edge id=&amp;quot;a-r049-d1p2e55&amp;quot;&gt;
&lt;from&gt;w#w-r049-d1p2w47&lt;/from&gt;
&lt;to&gt;a-r049-d1p2w51&lt;/to&gt;
&lt;/edge&gt;
...
&lt;/para&gt;
...
&lt;/doc&gt;
&lt;/adata&gt;
</figure>
<figureCaption confidence="0.9710895">
Figure 2: Portion of the Level 1 of the sample sen-
tence encoded in the PML data format.
</figureCaption>
<bodyText confidence="0.999907181818182">
generic XML-based data format, designed for the
representation of rich linguistic annotation organ-
ised into levels. In our schema, each of the higher
levels contains information about words on that
level, about the corrected errors and about rela-
tions to the tokens on the lower levels. Level 0
does not contain any relations, only links to the
neighbouring Level 1. In Figure 2, we show a por-
tion (first three words and first two relations) of
the Level 1 of the sample sentence encoded in our
annotation schema.
</bodyText>
<sectionHeader confidence="0.995045" genericHeader="method">
5 Annotation process
</sectionHeader>
<bodyText confidence="0.991917">
The whole annotation process proceeds as follows:
</bodyText>
<listItem confidence="0.990253909090909">
• A handwritten document is transcribed into
html using off-the-shelf tools (e.g. Open Office
Writer or Microsoft Word).
• The information in the html document is used to
generate Level 0 and a default Level 1 encoded
in the PML format.
• An annotator manually corrects the document
and provides some information about errors us-
ing our annotation tool.
• Error information that can be inferred automat-
ically is added.
</listItem>
<figure confidence="0.911058125">
val,wo
lex
cplx
proto to bylo velmí vadí pro mnˇe .
therefore it was *very resent for me .
dia
proto to bylo velmi vadí pro mnˇe .
protože to by mi velmi vadilo .
because I would be very unhappy about it.
p
bnd dia cap
Bál jsem se , že se jí nebude líbit Praha ,
I was afraid that she would not like Prague,
Bál jsem se , že ona se nebude líbit Prahu ,
wo val
val
</figure>
<page confidence="0.825476">
17
</page>
<figureCaption confidence="0.998541">
Figure 3: Sample sentence in the annotation tool.
</figureCaption>
<subsectionHeader confidence="0.923983">
5.1 Transcription
</subsectionHeader>
<bodyText confidence="0.999469965517241">
The original documents are hand-written, usually
the only available option, given that their most
common source are language courses and exams.
The avoidance of an electronic format is also due
to the concern about the use of automatic text-
editing tools by the students, which may signifi-
cantly distort the authentic interlanguage.
Therefore, the texts must be transcribed, which
is very time consuming. While we strive to cap-
ture only the information present in the original
hand-written text, often some interpretation is un-
avoidable. For example, the transcribers have to
take into account specifics of hand-writing of par-
ticular groups of students and even of each indi-
vidual student (the same glyph may be interpreted
as l in the hand-writing of one student, e of an-
other, and a of yet another). When a text allows
multiple interpretation, the transcribers may pro-
vide all variants. For example, the case of initial
letters or word boundaries are often unclear. Ob-
viously, parts of some texts may be completely il-
legible and are marked as such.
Also captured are corrections made by the stu-
dent (insertions, deletions, etc.), useful for investi-
gating the process of language acquisition.
The transcripts are not spell-checked automati-
cally. In a highly inflectional language, deviations
in spelling very often do not only reflect wrong
graphemics, but indicate an error in morphology.
</bodyText>
<subsectionHeader confidence="0.992442">
5.2 Annotation
</subsectionHeader>
<bodyText confidence="0.999997909090909">
The manual portion of annotation is supported by
an annotation tool we have developed. The anno-
tator corrects the text on appropriate levels, modi-
fies relations between elements (by default all re-
lations are 1:1) and annotates relations with error
tags as needed. The context of the annotated text
is shown both as a transcribed html document and
as a scan of the original document. The tool is
written in Java on top of the Netbeans platform.7
Figure 3 shows the annotation of the sample sen-
tence as displayed by the tool.
</bodyText>
<subsectionHeader confidence="0.984562">
5.3 Postprocessing
</subsectionHeader>
<bodyText confidence="0.999320666666667">
Manual annotation is followed by automatic post-
processing, providing the corpus with additional
information:
</bodyText>
<footnote confidence="0.978104">
7http://platform.netbeans.org/
</footnote>
<page confidence="0.99808">
18
</page>
<listItem confidence="0.9648115">
• Level 1: lemma, POS and morphological cate-
gories (this information can be ambiguous)
• Level 2: lemma, POS and morphological cate-
gories (disambiguated)
• Level 1: type of error (by comparing the origi-
nal and corrected strings), with the exception of
lexical errors that involve lemma changes (e.g.
*kadeˇrniˇcka – kadeinice ‘hair-dresser’)
• Level 2: type of morphosyntactic errors caused
by agreement or valency error (by comparing
morphosyntactic tags at Level 1 and 2)
• Formal error description: missing/extra expres-
sion, erroneous expression, wrong order
• In the future, we plan to automatically tag errors
in verb prefixes, inflectional endings, spelling,
palatalisation, metathesis, etc.
</listItem>
<sectionHeader confidence="0.998918" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999974878787879">
Error annotation is a very resource-intensive task,
but the return on investment is potentially enor-
mous. Depending on the annotation scheme, the
corpus user has access to detailed error statistics,
which is difficult to obtain otherwise. An error-
tagged corpus is an invaluable tool to obtain a re-
liable picture of the learners’ interlanguage and to
adapt teaching methods and learning materials by
identifying the most frequent error categories in
accordance with the learner’s proficiency level or
L1 background.
We are expecting plentiful feedback from the er-
ror annotation process, which is just starting. As
the goal of a sizable corpus requires a realistic
setup, we plan to experiment with more and less
detailed sets of error types, measuring the time and
inter-annotator agreement. A substantially more
elaborate classification of errors is previewed for a
limited subset of the corpus.
At the same time, the feedback of the annotators
will translate into the ongoing tuning of the an-
notation guidelines, represented by a comprehen-
sive error-tagging manual. We hope in progress in
dealing with thorny issues such as the uncertainty
about the author’s intended meaning, the inference
errors, the proper amount of interference with the
original, or the occurrence of colloquial language.
In all of this, we need to make sure that annotators
handle similar phenomena in the same way.
However, the real test of the corpus will come
with its usage. We are optimistic – some of the
future users are a crucial part of our team and their
needs and ideas are the driving force of the project.
</bodyText>
<sectionHeader confidence="0.998182" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9994025">
We wish to thank other members of the project
team, namely Milena Hnátková, Tomáš Jelínek,
Vladimír Petkeviˇc, and Hana Skoumalová for their
numerous stimulating ideas, acute insight and im-
portant feedback. We are especially grateful to
Karel Šebesta, for all of the above and for initi-
ating and guiding this enterprise.
The work described in this paper is funded by
the European Social Fund and the government of
the Czech Republic within the operational pro-
gramme ‘Education for Competitiveness’ as a part
of the project ‘Innovation in Education in the
Field of Czech as a Second Language’ (project
no. CZ.1.07/2.2.00/07.0259).
</bodyText>
<sectionHeader confidence="0.999312" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99990028125">
Sylviane Granger, editor. 1998. Learner English on
Computer. Addison Wesley Longman, London and
New York.
Geoffrey Leech. 1998. Preface. In Granger Sylviane,
editor, Learner English on Computer, pages xiv–xx.
Addison Wesley Longman, London and New York.
Anke Lüdeling, Maik Walter, Emil Kroymann, and Pe-
ter Adolphs. 2005. Multi-level error annotation in
learner corpora. In Proceedings of Corpus Linguis-
tics 2005, Birmingham.
Nadja Nesselhauf. 2004. Learner corpora and their po-
tential for language teaching. In John McHardy Sin-
clair, editor, How to use corpora in language teach-
ing, Studies in corpus linguistics, pages 125–152.
Benjamins, Amsterdam/Philadelphia.
Norma A. Pravec. 2002. Survery of learner corpora.
ICAME Journal, 26:81–114.
Thomas Schmidt. 2009. Creating and working with
spoken language corpora in EXMARaLDA. In
LULCL II: Lesser Used Languages &amp; Computer
Linguistics II, pages 151–164.
Larry Selinker. 1983. Interlanguage. In Betty W.
Robinett and Jacquelyn Schachter, editors, Second
Language Learning: Contrastive analysis, error
analysis, and related aspects, pages 173–196. The
University of Michigan Press, Ann Arbor, MI.
Richard Xiao. 2008. Well-known and influential
corpora. In Anke Lüdeling and Merja Kytö, ed-
itors, Corpus Linguistics. An International Hand-
book, volume 1 of Handbooks of Linguistics and
Communication Science [HSK] 29.1, pages 383–
457. Mouton de Gruyter, Berlin and New York.
</reference>
<page confidence="0.999332">
19
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.088101">
<title confidence="0.471010666666667">Error-tagged Learner Corpus of Czech Jirka Charles</title>
<author confidence="0.241179">Czech Prague</author>
<email confidence="0.999317">first.last@gmail.com</email>
<author confidence="0.839859">Svatava</author>
<affiliation confidence="0.73373">Technical</affiliation>
<address confidence="0.905684">Liberec, Czech</address>
<email confidence="0.973898">svatava.skodova@tul.cz</email>
<abstract confidence="0.995011857142857">The paper describes a learner corpus of Czech, currently under development. The corpus captures Czech as used by nonnative speakers. We discuss its structure, the layered annotation of errors and the annotation process.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Learner English on Computer.</title>
<date>1998</date>
<editor>Sylviane Granger, editor.</editor>
<publisher>Addison Wesley Longman,</publisher>
<location>London and New York.</location>
<marker>1998</marker>
<rawString>Sylviane Granger, editor. 1998. Learner English on Computer. Addison Wesley Longman, London and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Leech</author>
</authors>
<date>1998</date>
<booktitle>Learner English on Computer,</booktitle>
<pages>pages xiv–xx.</pages>
<editor>Preface. In Granger Sylviane, editor,</editor>
<publisher>Addison Wesley Longman,</publisher>
<location>London and New York.</location>
<contexts>
<context position="2578" citStr="Leech, 1998" startWordPosition="390" endWordPosition="391">dlova@tul.cz tic tags, assigned by a tagger. In more complex cases, the scheme allows for representing relations making phenomena such as the violation of agreement rules explicit. After an overview of issues related to learner corpora in §2 and a brief introduction to the project of a learner corpus of Czech in §3 we present the concept of our annotation scheme in §4, followed by a description of the annotation process in §5. 2 Learner corpora A learner corpus, also called interlanguage or L2 corpus, is a computerised textual database of language as produced by second language (L2) learners (Leech, 1998). Such a database is a very powerful resource in research of second language acquisition. It can be used to optimise the L2 learning process, to assist authors of textbooks and dictionaries, and to tailor them to learners with a particular native language (L1). More generally, a learner corpus – like other corpora – serves as a repository of authentic data about a language (Granger, 1998). In the domain of L2 acquisition and teaching of foreign languages, the language of the learners is called interlanguage (Selinker, 1983).1 An interlanguage includes both correct and deviant forms. The possib</context>
</contexts>
<marker>Leech, 1998</marker>
<rawString>Geoffrey Leech. 1998. Preface. In Granger Sylviane, editor, Learner English on Computer, pages xiv–xx. Addison Wesley Longman, London and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anke Lüdeling</author>
<author>Maik Walter</author>
<author>Emil Kroymann</author>
<author>Peter Adolphs</author>
</authors>
<title>Multi-level error annotation in learner corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of Corpus Linguistics 2005,</booktitle>
<location>Birmingham.</location>
<marker>Lüdeling, Walter, Kroymann, Adolphs, 2005</marker>
<rawString>Anke Lüdeling, Maik Walter, Emil Kroymann, and Peter Adolphs. 2005. Multi-level error annotation in learner corpora. In Proceedings of Corpus Linguistics 2005, Birmingham.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadja Nesselhauf</author>
</authors>
<title>Learner corpora and their potential for language teaching. In</title>
<date>2004</date>
<booktitle>How to use corpora in language teaching, Studies in corpus linguistics,</booktitle>
<pages>125--152</pages>
<editor>John McHardy Sinclair, editor,</editor>
<publisher>Benjamins, Amsterdam/Philadelphia.</publisher>
<contexts>
<context position="6338" citStr="Nesselhauf, 2004" startWordPosition="1001" endWordPosition="1003">ics, derivation inflection, auxiliaries, gender, mode, etc.), word category (POS). • Without error taxonomies, using only correction as the implicit explanation for an error. In Table 1 we present a brief summary of existing learner corpora tagged by POS and/or error types, including the size of the corpus (in millions of words or Chinese characters), the mother tongue of the learners, or – in case of learners with different linguistic backgrounds – the number of mother tongues (L1), the TL and the learners’ level of proficiency in TL. For an extensive overview see, for example (Pravec, 2002; Nesselhauf, 2004; Xiao, 2008). Size L1 TL TL proficiency ICLE – Internat’l Corpus ofLearner English 3M 21 English advanced CLC – Cambridge Learner Corpus 30M 130 English all levels PELCRA – Polish Learner English Corpus 0.5M Polish English all levels USE – Uppsala Student English Corpus 1.2M Swedish English advanced HKUST – Hong Kong University of Science and Technology Corpus ofLearner English 25M Chinese English advanced CLEC – Chinese Learner English Corpus 1M Chinese English 5 levels JEFLL – Japanese EFL Learner Corpus 0.7M Japanese English advanced FALKO – Fehlerannotiertes Lernerkorpus 1.2M various Germ</context>
</contexts>
<marker>Nesselhauf, 2004</marker>
<rawString>Nadja Nesselhauf. 2004. Learner corpora and their potential for language teaching. In John McHardy Sinclair, editor, How to use corpora in language teaching, Studies in corpus linguistics, pages 125–152. Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norma A Pravec</author>
</authors>
<title>Survery of learner corpora.</title>
<date>2002</date>
<journal>ICAME Journal,</journal>
<pages>26--81</pages>
<contexts>
<context position="6320" citStr="Pravec, 2002" startWordPosition="999" endWordPosition="1000">ation, diacritics, derivation inflection, auxiliaries, gender, mode, etc.), word category (POS). • Without error taxonomies, using only correction as the implicit explanation for an error. In Table 1 we present a brief summary of existing learner corpora tagged by POS and/or error types, including the size of the corpus (in millions of words or Chinese characters), the mother tongue of the learners, or – in case of learners with different linguistic backgrounds – the number of mother tongues (L1), the TL and the learners’ level of proficiency in TL. For an extensive overview see, for example (Pravec, 2002; Nesselhauf, 2004; Xiao, 2008). Size L1 TL TL proficiency ICLE – Internat’l Corpus ofLearner English 3M 21 English advanced CLC – Cambridge Learner Corpus 30M 130 English all levels PELCRA – Polish Learner English Corpus 0.5M Polish English all levels USE – Uppsala Student English Corpus 1.2M Swedish English advanced HKUST – Hong Kong University of Science and Technology Corpus ofLearner English 25M Chinese English advanced CLEC – Chinese Learner English Corpus 1M Chinese English 5 levels JEFLL – Japanese EFL Learner Corpus 0.7M Japanese English advanced FALKO – Fehlerannotiertes Lernerkorpus</context>
</contexts>
<marker>Pravec, 2002</marker>
<rawString>Norma A. Pravec. 2002. Survery of learner corpora. ICAME Journal, 26:81–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Schmidt</author>
</authors>
<title>Creating and working with spoken language corpora in EXMARaLDA.</title>
<date>2009</date>
<booktitle>In LULCL II: Lesser Used Languages &amp; Computer Linguistics II,</booktitle>
<pages>151--164</pages>
<contexts>
<context position="12841" citStr="Schmidt, 2009" startWordPosition="2065" endWordPosition="2066">g a matrix of statistic deviations. Similarly interesting are the heterogeneous languages of learners on different stages of acquisition. From the pedagogical point of view, corpus-based analyses have led to a new inductive methodology of data-driven learning, based on the usage of concordances in exercises or to support students’ independent learning activities. 4.2 The framework Annotated learner corpora sometimes use data formats and tools developed originally for annotating speech. Such environments allow for an arbitrary 13 segmentation of the input and multilevel annotation of segments (Schmidt, 2009). Typically, the annotator edits a table with columns corresponding to words and rows to levels of annotation. A cell can be split or more cells merged to allow for annotating smaller or larger segments. This way, phenomena such as agreement or word order can be emended and tagged (LUdeling et al., 2005). However, in the tabular format vertical correspondences between the original word form and its emended equivalents or annotations at other levels may be lost. It is difficult to keep track of links between forms merged into a single cell, spanning multiple columns, and the annotations of a fo</context>
</contexts>
<marker>Schmidt, 2009</marker>
<rawString>Thomas Schmidt. 2009. Creating and working with spoken language corpora in EXMARaLDA. In LULCL II: Lesser Used Languages &amp; Computer Linguistics II, pages 151–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larry Selinker</author>
</authors>
<title>Language Learning: Contrastive analysis, error analysis, and related aspects,</title>
<date>1983</date>
<pages>173--196</pages>
<editor>Interlanguage. In Betty W. Robinett and Jacquelyn Schachter, editors, Second</editor>
<publisher>The University of Michigan Press,</publisher>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="3107" citStr="Selinker, 1983" startWordPosition="484" endWordPosition="485">extual database of language as produced by second language (L2) learners (Leech, 1998). Such a database is a very powerful resource in research of second language acquisition. It can be used to optimise the L2 learning process, to assist authors of textbooks and dictionaries, and to tailor them to learners with a particular native language (L1). More generally, a learner corpus – like other corpora – serves as a repository of authentic data about a language (Granger, 1998). In the domain of L2 acquisition and teaching of foreign languages, the language of the learners is called interlanguage (Selinker, 1983).1 An interlanguage includes both correct and deviant forms. The possibility to examine learners’ errors on the background of the correct language is the most important aspect of learner corpora (Granger, 1998). Investigating the interlanguage is easier when the deviant forms are annotated at least by their correct counterparts, or, even better, by tags making the nature of the error explicit. Although 1Interlanguage is distinguished by its highly individual and dynamic nature. It is subject to constant changes as the learner progresses through successive stages of acquiring more competence, a</context>
</contexts>
<marker>Selinker, 1983</marker>
<rawString>Larry Selinker. 1983. Interlanguage. In Betty W. Robinett and Jacquelyn Schachter, editors, Second Language Learning: Contrastive analysis, error analysis, and related aspects, pages 173–196. The University of Michigan Press, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Xiao</author>
</authors>
<title>Well-known and influential corpora. In Anke Lüdeling and Merja Kytö, editors, Corpus Linguistics. An International Handbook,</title>
<date>2008</date>
<booktitle>of Handbooks of Linguistics and Communication Science [HSK] 29.1,</booktitle>
<volume>1</volume>
<pages>383--457</pages>
<location>Berlin and New York.</location>
<contexts>
<context position="6351" citStr="Xiao, 2008" startWordPosition="1004" endWordPosition="1005">flection, auxiliaries, gender, mode, etc.), word category (POS). • Without error taxonomies, using only correction as the implicit explanation for an error. In Table 1 we present a brief summary of existing learner corpora tagged by POS and/or error types, including the size of the corpus (in millions of words or Chinese characters), the mother tongue of the learners, or – in case of learners with different linguistic backgrounds – the number of mother tongues (L1), the TL and the learners’ level of proficiency in TL. For an extensive overview see, for example (Pravec, 2002; Nesselhauf, 2004; Xiao, 2008). Size L1 TL TL proficiency ICLE – Internat’l Corpus ofLearner English 3M 21 English advanced CLC – Cambridge Learner Corpus 30M 130 English all levels PELCRA – Polish Learner English Corpus 0.5M Polish English all levels USE – Uppsala Student English Corpus 1.2M Swedish English advanced HKUST – Hong Kong University of Science and Technology Corpus ofLearner English 25M Chinese English advanced CLEC – Chinese Learner English Corpus 1M Chinese English 5 levels JEFLL – Japanese EFL Learner Corpus 0.7M Japanese English advanced FALKO – Fehlerannotiertes Lernerkorpus 1.2M various German advanced F</context>
</contexts>
<marker>Xiao, 2008</marker>
<rawString>Richard Xiao. 2008. Well-known and influential corpora. In Anke Lüdeling and Merja Kytö, editors, Corpus Linguistics. An International Handbook, volume 1 of Handbooks of Linguistics and Communication Science [HSK] 29.1, pages 383– 457. Mouton de Gruyter, Berlin and New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>