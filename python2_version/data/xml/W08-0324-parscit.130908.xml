<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.039083">
<title confidence="0.9991605">
Statistical Transfer Systems for French–English
and German–English Machine Translation
</title>
<author confidence="0.992044">
Greg Hanneman and Edmund Huber and Abhaya Agarwal and Vamshi Ambati
</author>
<affiliation confidence="0.9095325">
and Alok Parlikar and Erik Peterson and Alon Lavie
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213 USA
</affiliation>
<email confidence="0.984457">
{ghannema, ehuber, abhayaa, vamshi, aup, eepeter, alavie}@cs.cmu.edu
</email>
<sectionHeader confidence="0.995549" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999933444444445">
We apply the Stat-XFER statistical transfer
machine translation framework to the task of
translating from French and German into En-
glish. We introduce statistical methods within
our framework that allow for the principled
extraction of syntax-based transfer rules from
parallel corpora given word alignments and
constituency parses. Performance is evaluated
on test sets from the 2007 WMT shared task.
</bodyText>
<sectionHeader confidence="0.998787" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999765416666667">
The Carnegie Mellon University statistical trans-
fer (Stat-XFER) framework is a general search-
based and syntax-driven framework for develop-
ing MT systems under a variety of data condi-
tions (Lavie, 2008). At its core is a transfer en-
gine using two language-pair-dependent resources:
a grammar of weighted synchronous context-free
rules (possibly augmented with unification-style fea-
ture constraints), and a probabilistic bilingual lexi-
con of syntax-based word- and phrase-level transla-
tions. The Stat-XFER framework has been used to
develop research MT systems for a number of lan-
guage pairs, including Chinese–English, Hebrew–
English, Urdu–English, and Hindi–English.
In this paper, we describe our use of the frame-
work to create new French–English and German–
English MT systems for the 2008 Workshop on Sta-
tistical Machine Translation shared translation task.
We first describe the acquisition and processing of
resources for each language pair and the roles of
those resources within the Stat-XFER system (Sec-
tion 2); we then report results on common test sets
(Section 3) and share some early analysis and future
directions (Section 4).
</bodyText>
<sectionHeader confidence="0.991473" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999145818181818">
Building a new machine translation system under
the Stat-XFER framework involves constructing a
bilingual translation lexicon and a transfer gram-
mar. Over the past six months, we have developed
new methods for extracting syntax-based translation
lexicons and transfer rules fully automatically from
parsed and word-aligned parallel corpora. These
new methods are described in detail by Lavie et
al. (2008). Below, we detail the statistical meth-
ods by which these resources were extracted for our
French–English and German–English systems.
</bodyText>
<subsectionHeader confidence="0.974497">
2.1 Lexicon
</subsectionHeader>
<bodyText confidence="0.999856461538461">
The bilingual lexicon is automatically extracted
from automatically parsed and word-aligned paral-
lel corpora. To obtain high-quality statistical word
alignments, we run GIZA++ (Och and Ney, 2003)
in both the source-to-target and target-to-source di-
rections, then combine the resulting alignments with
the Sym2 symmetric alignment heuristic of Ortiz-
Martinez et al. (2005)1. From this data, we extract a
lexicon of both word-to-word and syntactic phrase-
to-phrase translation equivalents.
The word-level correspondences are extracted di-
rectly from the word alignments: parts of speech for
these lexical entries are obtained from the preter-
</bodyText>
<footnote confidence="0.96097825">
1We use Sym2 over more well-known heuristics such as
“grow-diag-final” because Sym2 has been shown to give the
best results for the node-alignment subtask that is part of our
processing chain.
</footnote>
<page confidence="0.944681">
163
</page>
<note confidence="0.417853">
Proceedings of the Third Workshop on Statistical Machine Translation, pages 163–166,
</note>
<page confidence="0.330247">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<table confidence="0.9988241">
ws cs wt ct r
paru V appeared V 0.2054
paru V seemed V 0.1429
paru V found V 0.0893
paru V published V 0.0804
paru V felt V 0.0714
... ... ...
paru V already ADV 0.0089
paru V appear V 0.0089
paru V authoritative ADJ 0.0089
</table>
<tableCaption confidence="0.9888845">
Table 1: Part of the lexical entry distribution for the
French (source) word paru.
</tableCaption>
<bodyText confidence="0.9999572">
minal nodes of parse trees of the source and target
sentences. If parsers are unavailable for either lan-
guage, we have also experimented with determin-
ing parts of speech with independent taggers such
as TreeTagger (Schmid, 1995). Alternatively, parts
of speech may be projected through the word align-
ments from one language to the other if the infor-
mation is available on at least one side. Syntactic
phrase-level correspondences are extracted from the
parallel data by applying the PFA node alignment
algorithm described by Lavie et al. (2008). The
yields of the aligned parse tree nodes are extracted
as constituent-level translation equivalents.
Each entry in the lexicon is assigned a rule score,
r, based on its source-side part of speech cs, source-
side text ws, target-side part of speech ct, and target-
side text wt. The score is a maximum-likelihood es-
timate of the distribution of target-language transla-
tion and source- and target-language parts of speech,
given the source word or phrase.
</bodyText>
<equation confidence="0.999774333333333">
r = p(wt, ct, cs  |ws) (1)
� #(wt, ct, ws, cs)
#(ws) + 1 (2)
</equation>
<bodyText confidence="0.99999325">
We employ add-one smoothing in the denominator
of Equation 2 to counteract overestimation in the
case that #(ws) is small. Rule scores provide a way
to promote the more likely translation alternatives
while still retaining a high degree of diversity in the
lexicon. Table 1 shows part of the lexical distribu-
tion for the French (source) word paru.
The result of the statistical word alignment pro-
cess and lexical extraction is a bilingual lexicon con-
taining 1,064,755 entries for French–English and
1,111,510 entries for German–English. Sample lex-
ical entries are shown in Figure 1.
</bodyText>
<subsectionHeader confidence="0.990429">
2.2 Grammar
</subsectionHeader>
<bodyText confidence="0.999986923076923">
Transfer grammars for our earlier statistical transfer
systems were manually created by in-house experts
of the languages involved and were therefore small.
The Stat-XFER framework has since been extended
with procedures for automatic grammar acquisition
from a parallel corpus, given constituency parses for
source or target data or both. Our French and Ger-
man systems used the context-free grammar rule ex-
traction process described by Lavie et al. (2008).
For French, we used 300,000 parallel sentences from
the Europarl training data parsed on the English side
with the Stanford parser (Klein and Manning, 2003)
and on the French side with the Xerox XIP parser
(A¨ıt-Mokhtar et al., 2001). For German, we used
300,000 Europarl sentence pairs parsed with the En-
glish and German versions of the Stanford parser2.
The set of rules extracted from the parsed corpora
was filtered down after scoring to improve system
performance and run time. The final French rule set
was comprised of the 1500 most frequently occur-
ring rules. For German, rules that occurred less than
twice were filtered out, leaving a total of 16,469. In
each system, rule scores were again calculated by
Equation 2, with ws and wt representing the full
right-hand sides of the source and target grammar
rules.
A secondary version of our French system used a
word-level lexicon extracted from the intersection,
rather than the symmetricization, of the GIZA++
alignments in each direction; we hypothesize that
this tends to improve precision at the expense of re-
call. The word-level lexicon was supplemented with
syntax-based phrase-level entries obtained from the
PFA node alignment algorithm. The grammar
contained the 700 highest-frequency and the 500
highest-scoring rules extracted from the parallel
parsed corpus. This version had a total lexicon size
of 2,023,531 entries and a total grammar of 1034
rules after duplicates were removed. Figure 2 shows
</bodyText>
<footnote confidence="0.98211725">
2Due to a combination of time constraints and paucity of
computational resources, only a portion of the Europarl parallel
corpus was utilized, and none of the supplementary news com-
mentary training data was integrated.
</footnote>
<page confidence="0.984964">
164
</page>
<figure confidence="0.7197939">
{VS,248840}
V::V |: [&amp;quot;paru&amp;quot;] −&gt; [&amp;quot;appeared&amp;quot;]
(
(*score* 0.205357142857143)
)
{NP,2000012}
NP::NP |: [&amp;quot;ein&amp;quot; &amp;quot;Beispiel&amp;quot;] −&gt; [&amp;quot;an&amp;quot; &amp;quot;example&amp;quot;]
(
(*score* 0.763636363636364)
)
</figure>
<figureCaption confidence="0.998926">
Figure 1: Sample lexical entries for French and German.
</figureCaption>
<bodyText confidence="0.948441">
sample grammar rules automatically learned by the
process described above.
</bodyText>
<subsectionHeader confidence="0.996218">
2.3 Transfer Engine
</subsectionHeader>
<bodyText confidence="0.999962375">
The Stat-XFER transfer engine runs in a two-stage
process, first applying the grammar and lexicon
to an input sentence, then running a decoder over
the resulting lattice of scored translation pieces.
Scores for each translation piece are based on a
log-linear combination of several features: language
model probability, rule scores, source-given-target
and target-given-source lexical probabilities, parse
fragmentation, and length. For more details, see
Lavie (2008). The use of a German transfer gram-
mar an order of magnitude larger than the corre-
sponding French grammar was made possible due to
a recent optimization made in the engine. When en-
abled, it constrains the search of translation hypothe-
ses to the space of hypotheses whose structure satis-
fies the consituent structure of a source-side parse.
</bodyText>
<sectionHeader confidence="0.998969" genericHeader="evaluation">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.994061777777778">
We trained our model parameters on a subset of
the provided “dev2006” development set, optimiz-
ing for case-insensitive IBM-style BLEU (Papineni
et al., 2002) with several iterations of minimum error
rate training on n-best lists. In each iteration’s list,
we also included the lists from previous iterations in
order to maintain a diversity of hypothesis types and
scores. The provided “test2007” and “nc-test2007”
data sets, identical with the test data from the 2007
Workshop on Statistical Machine Translation shared
task, were used as internal development tests.
Tables 2, 3, and 4 report scores on these data sets
for our primary French, secondary French, and Ger-
man systems. We report case-insensitive scores for
version 0.6 of METEOR (Lavie and Agarwal, 2007)
with all modules enabled, version 1.04 of IBM-style
BLEU (Papineni et al., 2002), and version 5 of TER
(Snover et al., 2006).
</bodyText>
<table confidence="0.9994055">
Data Set METEOR BLEU TER
dev2006 0.5332 0.2063 64.81
test2007 0.5358 0.2078 64.75
nc-test2007 0.5369 0.1719 69.83
</table>
<tableCaption confidence="0.9214625">
Table 2: Results for the primary French–English system
on provided development and development test sets.
</tableCaption>
<table confidence="0.99979725">
Data Set METEOR BLEU TER
dev2006 0.5330 0.2086 65.02
test2007 0.5386 0.2129 64.29
nc-test2007 0.5311 0.1680 70.90
</table>
<tableCaption confidence="0.998055">
Table 3: Results for the secondary French–English sys-
tem on provided development and development test sets.
</tableCaption>
<sectionHeader confidence="0.852095" genericHeader="conclusions">
4 Analysis and Conclusions
</sectionHeader>
<bodyText confidence="0.99992505">
From the development test results in Section 3, we
note that the Stat-XFER systems’ performance cur-
rently lags behind the state-of-the-art scores on the
2007 test data3. This may be in part due to the low
volume of training data used for rule learning. A key
research question in our approach is how to distin-
guish low-frequency correct and useful transfer rules
from “noisy” rules that are due to parser errors and
incorrect word alignments. We believe that learning
rules from more data will help alleviate this prob-
lem by proportionally increasing the counts of good
rules compared to incorrect ones. We also plan to
study methods for more effective rule set pruning,
regardless of the volume of training data used.
The difference in metric scores between in-
domain and out-of-domain data is partly due to ef-
fects of reference length on the metrics used. De-
tailed output from METEOR and BLEU shows that
the reference translations for the test2007 set are
about 94% as long as the primary French–English
</bodyText>
<footnote confidence="0.989681">
3Top scores on the 2007 test data are approximately 0.60
METEOR, 0.33 BLEU, and 57.6 TER. See Callison-Burch et
al. (2007) for full results.
</footnote>
<page confidence="0.996802">
165
</page>
<figure confidence="0.995183384615385">
{PP,1627955}
PP:PP [PRE &amp;quot;d’&amp;quot; &amp;quot;autres&amp;quot; N] −&gt; [PRE &amp;quot;other&amp;quot; N]
(
(*score* 0.866050808314088
)
(X1::Y1)
(X4::Y3)
{PP,3000085}
PP:ADVP [&amp;quot;vor&amp;quot; CARD &amp;quot;Monaten&amp;quot;] −&gt; [NUM &amp;quot;months&amp;quot; &amp;quot;ago&amp;quot;]
(
(*score* 0.9375)
(X2::Y1)
) )
</figure>
<figureCaption confidence="0.994148">
Figure 2: Sample grammar rules for French and German.
</figureCaption>
<table confidence="0.99947325">
Data Set METEOR BLEU TER
dev2006 0.4967 0.1794 68.68
test2007 0.5052 0.1878 67.94
nc-test2007 0.4939 0.1347 74.38
</table>
<tableCaption confidence="0.9937435">
Table 4: Results for the German–English system on pro-
vided development and development test sets.
</tableCaption>
<bodyText confidence="0.999829545454545">
system’s translations. On this set, our system has
approximately balanced precision (0.62) and recall
(0.66). However, the nc-test2007 references are only
84% as long as our output, a situation that hurts our
system’s precision (0.57) but boosts its recall (0.68).
METEOR, as a metric that favors recall, shows a
negligible increase in score between these two test
sets, while BLEU and TER report significant relative
drops of 17.3% and 7.8%. This behavior appears to
be consistent on the test2007 and nc-test2007 data
sets across systems (Callison-Burch et al., 2007).
</bodyText>
<sectionHeader confidence="0.99764" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999863166666667">
This research was supported in part by NSF grants
IIS-0121631 (AVENUE) and IIS-0534217 (LE-
TRAS), and by the DARPA GALE program. We
thank the members of the Parsing and Semantics
group at Xerox Research Centre Europe for assisting
in parsing the French data using their XIP parser.
</bodyText>
<sectionHeader confidence="0.99854" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999593283018868">
Salah A¨ıt-Mokhtar, Jean-Pierre Chanod, and Claude
Roux. 2001. A multi-input dependency parser. In
Proceedings of the Seventh International Workshop on
Parsing Technologies, Beijing, China, October.
Chris Callison-Burch, Cameron Fordyce, Philipp Koehn,
Christof Monz, and Josh Schroeder. 2007. (Meta-)
evaluation of machine translation. In Proceedings of
the Second Workshop on Statistical Machine Transla-
tion, pages 136–158, Prague, Czech Republic, June.
Dan Klein and Christopher D. Manning. 2003. Fast exact
inference with a factored model for natural language
parsing. In Advances in Neural Information Process-
ing Systems 15, pages 3–10. MIT Press, Cambridge,
MA.
Alon Lavie and Abhaya Agarwal. 2007. METEOR: An
automatic metric for MT evaluation with high levels of
correlation with human judgments. In Proceedings of
the Second Workshop on Statistical Machine Transla-
tion, pages 228–231, Prague, Czech Republic, June.
Alon Lavie, Alok Parlikar, and Vamshi Ambati. 2008.
Syntax-driven learning of sub-sentential translation
equivalents and translation rules from parsed paral-
lel corpora. In Proceedings of the Second Work-
shop on Syntax and Structure in Statistical Transla-
tion, Columbus, OH, June. To appear.
Alon Lavie. 2008. Stat-XFER: A general search-based
syntax-driven framework for machine translation. In
Computational Linguistics and Intelligent Text Pro-
cessing, Lecture Notes in Computer Science, pages
362–375. Springer.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Daniel Ortiz-Martinez, Ismael Garcia-Varea, and Fran-
cisco Casacuberta. 2005. Thot: A toolkit to train
phrase-based models for statistical machine transla-
tion. In Proceedings of the 10th Machine Translation
Summit, pages 141–148, Phuket, Thailand, September.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic eva-
lution of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311–318, Philadelphia, PA,
July.
Helmut Schmid. 1995. Improvements in part-of-speech
tagging with an application to German. In Proceed-
ings of the ACL SIGDAT Workshop.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea
Micciulla, and John Makhoul. 2006. A study of trans-
lation edit rate with targeted human annotation. In
Proceedings of the Seventh Conference of the Associ-
ation for Machine Translation in the Americas, pages
223–231, Cambridge, MA, August.
</reference>
<page confidence="0.998764">
166
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.322674">
<title confidence="0.6806058">Statistical Transfer Systems for and German–English Machine Translation Hanneman Huber Agarwal Parlikar Peterson Language Technologies</title>
<affiliation confidence="0.981063">Carnegie Mellon</affiliation>
<address confidence="0.999562">Pittsburgh, PA 15213</address>
<email confidence="0.949961">ehuber,abhayaa,vamshi,aup,eepeter,</email>
<abstract confidence="0.9975113">We apply the Stat-XFER statistical transfer machine translation framework to the task of translating from French and German into English. We introduce statistical methods within our framework that allow for the principled extraction of syntax-based transfer rules from parallel corpora given word alignments and constituency parses. Performance is evaluated on test sets from the 2007 WMT shared task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Salah A¨ıt-Mokhtar</author>
<author>Jean-Pierre Chanod</author>
<author>Claude Roux</author>
</authors>
<title>A multi-input dependency parser.</title>
<date>2001</date>
<booktitle>In Proceedings of the Seventh International Workshop on Parsing Technologies,</booktitle>
<location>Beijing, China,</location>
<marker>A¨ıt-Mokhtar, Chanod, Roux, 2001</marker>
<rawString>Salah A¨ıt-Mokhtar, Jean-Pierre Chanod, and Claude Roux. 2001. A multi-input dependency parser. In Proceedings of the Seventh International Workshop on Parsing Technologies, Beijing, China, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Cameron Fordyce</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>(Meta-) evaluation of machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>136--158</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="11239" citStr="Callison-Burch et al. (2007)" startWordPosition="1750" endWordPosition="1753">alleviate this problem by proportionally increasing the counts of good rules compared to incorrect ones. We also plan to study methods for more effective rule set pruning, regardless of the volume of training data used. The difference in metric scores between indomain and out-of-domain data is partly due to effects of reference length on the metrics used. Detailed output from METEOR and BLEU shows that the reference translations for the test2007 set are about 94% as long as the primary French–English 3Top scores on the 2007 test data are approximately 0.60 METEOR, 0.33 BLEU, and 57.6 TER. See Callison-Burch et al. (2007) for full results. 165 {PP,1627955} PP:PP [PRE &amp;quot;d’&amp;quot; &amp;quot;autres&amp;quot; N] −&gt; [PRE &amp;quot;other&amp;quot; N] ( (*score* 0.866050808314088 ) (X1::Y1) (X4::Y3) {PP,3000085} PP:ADVP [&amp;quot;vor&amp;quot; CARD &amp;quot;Monaten&amp;quot;] −&gt; [NUM &amp;quot;months&amp;quot; &amp;quot;ago&amp;quot;] ( (*score* 0.9375) (X2::Y1) ) ) Figure 2: Sample grammar rules for French and German. Data Set METEOR BLEU TER dev2006 0.4967 0.1794 68.68 test2007 0.5052 0.1878 67.94 nc-test2007 0.4939 0.1347 74.38 Table 4: Results for the German–English system on provided development and development test sets. system’s translations. On this set, our system has approximately balanced precision (0.62) and recall </context>
</contexts>
<marker>Callison-Burch, Fordyce, Koehn, Monz, Schroeder, 2007</marker>
<rawString>Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2007. (Meta-) evaluation of machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 136–158, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Fast exact inference with a factored model for natural language parsing.</title>
<date>2003</date>
<booktitle>In Advances in Neural Information Processing Systems 15,</booktitle>
<pages>3--10</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="6072" citStr="Klein and Manning, 2003" startWordPosition="934" endWordPosition="937">2 Grammar Transfer grammars for our earlier statistical transfer systems were manually created by in-house experts of the languages involved and were therefore small. The Stat-XFER framework has since been extended with procedures for automatic grammar acquisition from a parallel corpus, given constituency parses for source or target data or both. Our French and German systems used the context-free grammar rule extraction process described by Lavie et al. (2008). For French, we used 300,000 parallel sentences from the Europarl training data parsed on the English side with the Stanford parser (Klein and Manning, 2003) and on the French side with the Xerox XIP parser (A¨ıt-Mokhtar et al., 2001). For German, we used 300,000 Europarl sentence pairs parsed with the English and German versions of the Stanford parser2. The set of rules extracted from the parsed corpora was filtered down after scoring to improve system performance and run time. The final French rule set was comprised of the 1500 most frequently occurring rules. For German, rules that occurred less than twice were filtered out, leaving a total of 16,469. In each system, rule scores were again calculated by Equation 2, with ws and wt representing t</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Fast exact inference with a factored model for natural language parsing. In Advances in Neural Information Processing Systems 15, pages 3–10. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Abhaya Agarwal</author>
</authors>
<title>METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>228--231</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="9516" citStr="Lavie and Agarwal, 2007" startWordPosition="1468" endWordPosition="1471">i et al., 2002) with several iterations of minimum error rate training on n-best lists. In each iteration’s list, we also included the lists from previous iterations in order to maintain a diversity of hypothesis types and scores. The provided “test2007” and “nc-test2007” data sets, identical with the test data from the 2007 Workshop on Statistical Machine Translation shared task, were used as internal development tests. Tables 2, 3, and 4 report scores on these data sets for our primary French, secondary French, and German systems. We report case-insensitive scores for version 0.6 of METEOR (Lavie and Agarwal, 2007) with all modules enabled, version 1.04 of IBM-style BLEU (Papineni et al., 2002), and version 5 of TER (Snover et al., 2006). Data Set METEOR BLEU TER dev2006 0.5332 0.2063 64.81 test2007 0.5358 0.2078 64.75 nc-test2007 0.5369 0.1719 69.83 Table 2: Results for the primary French–English system on provided development and development test sets. Data Set METEOR BLEU TER dev2006 0.5330 0.2086 65.02 test2007 0.5386 0.2129 64.29 nc-test2007 0.5311 0.1680 70.90 Table 3: Results for the secondary French–English system on provided development and development test sets. 4 Analysis and Conclusions From</context>
</contexts>
<marker>Lavie, Agarwal, 2007</marker>
<rawString>Alon Lavie and Abhaya Agarwal. 2007. METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 228–231, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Alok Parlikar</author>
<author>Vamshi Ambati</author>
</authors>
<title>Syntax-driven learning of sub-sentential translation equivalents and translation rules from parsed parallel corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the Second Workshop on Syntax and Structure in Statistical Translation,</booktitle>
<location>Columbus, OH,</location>
<note>To appear.</note>
<contexts>
<context position="2352" citStr="Lavie et al. (2008)" startWordPosition="339" endWordPosition="342">nd the roles of those resources within the Stat-XFER system (Section 2); we then report results on common test sets (Section 3) and share some early analysis and future directions (Section 4). 2 System Description Building a new machine translation system under the Stat-XFER framework involves constructing a bilingual translation lexicon and a transfer grammar. Over the past six months, we have developed new methods for extracting syntax-based translation lexicons and transfer rules fully automatically from parsed and word-aligned parallel corpora. These new methods are described in detail by Lavie et al. (2008). Below, we detail the statistical methods by which these resources were extracted for our French–English and German–English systems. 2.1 Lexicon The bilingual lexicon is automatically extracted from automatically parsed and word-aligned parallel corpora. To obtain high-quality statistical word alignments, we run GIZA++ (Och and Ney, 2003) in both the source-to-target and target-to-source directions, then combine the resulting alignments with the Sym2 symmetric alignment heuristic of OrtizMartinez et al. (2005)1. From this data, we extract a lexicon of both word-to-word and syntactic phraseto-</context>
<context position="4348" citStr="Lavie et al. (2008)" startWordPosition="654" endWordPosition="657"> Part of the lexical entry distribution for the French (source) word paru. minal nodes of parse trees of the source and target sentences. If parsers are unavailable for either language, we have also experimented with determining parts of speech with independent taggers such as TreeTagger (Schmid, 1995). Alternatively, parts of speech may be projected through the word alignments from one language to the other if the information is available on at least one side. Syntactic phrase-level correspondences are extracted from the parallel data by applying the PFA node alignment algorithm described by Lavie et al. (2008). The yields of the aligned parse tree nodes are extracted as constituent-level translation equivalents. Each entry in the lexicon is assigned a rule score, r, based on its source-side part of speech cs, sourceside text ws, target-side part of speech ct, and targetside text wt. The score is a maximum-likelihood estimate of the distribution of target-language translation and source- and target-language parts of speech, given the source word or phrase. r = p(wt, ct, cs |ws) (1) � #(wt, ct, ws, cs) #(ws) + 1 (2) We employ add-one smoothing in the denominator of Equation 2 to counteract overestima</context>
<context position="5914" citStr="Lavie et al. (2008)" startWordPosition="909" endWordPosition="912">ingual lexicon containing 1,064,755 entries for French–English and 1,111,510 entries for German–English. Sample lexical entries are shown in Figure 1. 2.2 Grammar Transfer grammars for our earlier statistical transfer systems were manually created by in-house experts of the languages involved and were therefore small. The Stat-XFER framework has since been extended with procedures for automatic grammar acquisition from a parallel corpus, given constituency parses for source or target data or both. Our French and German systems used the context-free grammar rule extraction process described by Lavie et al. (2008). For French, we used 300,000 parallel sentences from the Europarl training data parsed on the English side with the Stanford parser (Klein and Manning, 2003) and on the French side with the Xerox XIP parser (A¨ıt-Mokhtar et al., 2001). For German, we used 300,000 Europarl sentence pairs parsed with the English and German versions of the Stanford parser2. The set of rules extracted from the parsed corpora was filtered down after scoring to improve system performance and run time. The final French rule set was comprised of the 1500 most frequently occurring rules. For German, rules that occurre</context>
</contexts>
<marker>Lavie, Parlikar, Ambati, 2008</marker>
<rawString>Alon Lavie, Alok Parlikar, and Vamshi Ambati. 2008. Syntax-driven learning of sub-sentential translation equivalents and translation rules from parsed parallel corpora. In Proceedings of the Second Workshop on Syntax and Structure in Statistical Translation, Columbus, OH, June. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
</authors>
<title>Stat-XFER: A general search-based syntax-driven framework for machine translation.</title>
<date>2008</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing, Lecture Notes in Computer Science,</booktitle>
<pages>362--375</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="986" citStr="Lavie, 2008" startWordPosition="137" endWordPosition="138">ly the Stat-XFER statistical transfer machine translation framework to the task of translating from French and German into English. We introduce statistical methods within our framework that allow for the principled extraction of syntax-based transfer rules from parallel corpora given word alignments and constituency parses. Performance is evaluated on test sets from the 2007 WMT shared task. 1 Introduction The Carnegie Mellon University statistical transfer (Stat-XFER) framework is a general searchbased and syntax-driven framework for developing MT systems under a variety of data conditions (Lavie, 2008). At its core is a transfer engine using two language-pair-dependent resources: a grammar of weighted synchronous context-free rules (possibly augmented with unification-style feature constraints), and a probabilistic bilingual lexicon of syntax-based word- and phrase-level translations. The Stat-XFER framework has been used to develop research MT systems for a number of language pairs, including Chinese–English, Hebrew– English, Urdu–English, and Hindi–English. In this paper, we describe our use of the framework to create new French–English and German– English MT systems for the 2008 Workshop</context>
<context position="8397" citStr="Lavie (2008)" startWordPosition="1290" endWordPosition="1291">1: Sample lexical entries for French and German. sample grammar rules automatically learned by the process described above. 2.3 Transfer Engine The Stat-XFER transfer engine runs in a two-stage process, first applying the grammar and lexicon to an input sentence, then running a decoder over the resulting lattice of scored translation pieces. Scores for each translation piece are based on a log-linear combination of several features: language model probability, rule scores, source-given-target and target-given-source lexical probabilities, parse fragmentation, and length. For more details, see Lavie (2008). The use of a German transfer grammar an order of magnitude larger than the corresponding French grammar was made possible due to a recent optimization made in the engine. When enabled, it constrains the search of translation hypotheses to the space of hypotheses whose structure satisfies the consituent structure of a source-side parse. 3 Evaluation We trained our model parameters on a subset of the provided “dev2006” development set, optimizing for case-insensitive IBM-style BLEU (Papineni et al., 2002) with several iterations of minimum error rate training on n-best lists. In each iteration</context>
</contexts>
<marker>Lavie, 2008</marker>
<rawString>Alon Lavie. 2008. Stat-XFER: A general search-based syntax-driven framework for machine translation. In Computational Linguistics and Intelligent Text Processing, Lecture Notes in Computer Science, pages 362–375. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="2693" citStr="Och and Ney, 2003" startWordPosition="387" endWordPosition="390">d a transfer grammar. Over the past six months, we have developed new methods for extracting syntax-based translation lexicons and transfer rules fully automatically from parsed and word-aligned parallel corpora. These new methods are described in detail by Lavie et al. (2008). Below, we detail the statistical methods by which these resources were extracted for our French–English and German–English systems. 2.1 Lexicon The bilingual lexicon is automatically extracted from automatically parsed and word-aligned parallel corpora. To obtain high-quality statistical word alignments, we run GIZA++ (Och and Ney, 2003) in both the source-to-target and target-to-source directions, then combine the resulting alignments with the Sym2 symmetric alignment heuristic of OrtizMartinez et al. (2005)1. From this data, we extract a lexicon of both word-to-word and syntactic phraseto-phrase translation equivalents. The word-level correspondences are extracted directly from the word alignments: parts of speech for these lexical entries are obtained from the preter1We use Sym2 over more well-known heuristics such as “grow-diag-final” because Sym2 has been shown to give the best results for the node-alignment subtask that</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ortiz-Martinez</author>
<author>Ismael Garcia-Varea</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Thot: A toolkit to train phrase-based models for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th Machine Translation Summit,</booktitle>
<pages>141--148</pages>
<location>Phuket, Thailand,</location>
<marker>Ortiz-Martinez, Garcia-Varea, Casacuberta, 2005</marker>
<rawString>Daniel Ortiz-Martinez, Ismael Garcia-Varea, and Francisco Casacuberta. 2005. Thot: A toolkit to train phrase-based models for statistical machine translation. In Proceedings of the 10th Machine Translation Summit, pages 141–148, Phuket, Thailand, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evalution of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="8907" citStr="Papineni et al., 2002" startWordPosition="1372" endWordPosition="1375">d target-given-source lexical probabilities, parse fragmentation, and length. For more details, see Lavie (2008). The use of a German transfer grammar an order of magnitude larger than the corresponding French grammar was made possible due to a recent optimization made in the engine. When enabled, it constrains the search of translation hypotheses to the space of hypotheses whose structure satisfies the consituent structure of a source-side parse. 3 Evaluation We trained our model parameters on a subset of the provided “dev2006” development set, optimizing for case-insensitive IBM-style BLEU (Papineni et al., 2002) with several iterations of minimum error rate training on n-best lists. In each iteration’s list, we also included the lists from previous iterations in order to maintain a diversity of hypothesis types and scores. The provided “test2007” and “nc-test2007” data sets, identical with the test data from the 2007 Workshop on Statistical Machine Translation shared task, were used as internal development tests. Tables 2, 3, and 4 report scores on these data sets for our primary French, secondary French, and German systems. We report case-insensitive scores for version 0.6 of METEOR (Lavie and Agarw</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evalution of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Improvements in part-of-speech tagging with an application to German.</title>
<date>1995</date>
<booktitle>In Proceedings of the ACL SIGDAT Workshop.</booktitle>
<contexts>
<context position="4032" citStr="Schmid, 1995" startWordPosition="605" endWordPosition="606">umbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics ws cs wt ct r paru V appeared V 0.2054 paru V seemed V 0.1429 paru V found V 0.0893 paru V published V 0.0804 paru V felt V 0.0714 ... ... ... paru V already ADV 0.0089 paru V appear V 0.0089 paru V authoritative ADJ 0.0089 Table 1: Part of the lexical entry distribution for the French (source) word paru. minal nodes of parse trees of the source and target sentences. If parsers are unavailable for either language, we have also experimented with determining parts of speech with independent taggers such as TreeTagger (Schmid, 1995). Alternatively, parts of speech may be projected through the word alignments from one language to the other if the information is available on at least one side. Syntactic phrase-level correspondences are extracted from the parallel data by applying the PFA node alignment algorithm described by Lavie et al. (2008). The yields of the aligned parse tree nodes are extracted as constituent-level translation equivalents. Each entry in the lexicon is assigned a rule score, r, based on its source-side part of speech cs, sourceside text ws, target-side part of speech ct, and targetside text wt. The s</context>
</contexts>
<marker>Schmid, 1995</marker>
<rawString>Helmut Schmid. 1995. Improvements in part-of-speech tagging with an application to German. In Proceedings of the ACL SIGDAT Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Seventh Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="9641" citStr="Snover et al., 2006" startWordPosition="1490" endWordPosition="1493">d the lists from previous iterations in order to maintain a diversity of hypothesis types and scores. The provided “test2007” and “nc-test2007” data sets, identical with the test data from the 2007 Workshop on Statistical Machine Translation shared task, were used as internal development tests. Tables 2, 3, and 4 report scores on these data sets for our primary French, secondary French, and German systems. We report case-insensitive scores for version 0.6 of METEOR (Lavie and Agarwal, 2007) with all modules enabled, version 1.04 of IBM-style BLEU (Papineni et al., 2002), and version 5 of TER (Snover et al., 2006). Data Set METEOR BLEU TER dev2006 0.5332 0.2063 64.81 test2007 0.5358 0.2078 64.75 nc-test2007 0.5369 0.1719 69.83 Table 2: Results for the primary French–English system on provided development and development test sets. Data Set METEOR BLEU TER dev2006 0.5330 0.2086 65.02 test2007 0.5386 0.2129 64.29 nc-test2007 0.5311 0.1680 70.90 Table 3: Results for the secondary French–English system on provided development and development test sets. 4 Analysis and Conclusions From the development test results in Section 3, we note that the Stat-XFER systems’ performance currently lags behind the state-o</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of the Seventh Conference of the Association for Machine Translation in the Americas, pages 223–231, Cambridge, MA, August.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>