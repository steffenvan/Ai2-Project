<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.024521">
<title confidence="0.980276">
Recognizing Partial Textual Entailment
</title>
<author confidence="0.929673">
Omer Levy† Torsten Zesch§ Ido Dagan† Iryna Gurevych§
</author>
<affiliation confidence="0.950524666666667">
† Natural Language Processing Lab § Ubiquitous Knowledge Processing Lab
Computer Science Department Computer Science Department
Bar-Ilan University Technische Universit¨at Darmstadt
</affiliation>
<sectionHeader confidence="0.97847" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999467705882353">
Textual entailment is an asymmetric rela-
tion between two text fragments that de-
scribes whether one fragment can be in-
ferred from the other. It thus cannot cap-
ture the notion that the target fragment
is “almost entailed” by the given text.
The recently suggested idea of partial tex-
tual entailment may remedy this problem.
We investigate partial entailment under the
faceted entailment model and the possibil-
ity of adapting existing textual entailment
methods to this setting. Indeed, our results
show that these methods are useful for rec-
ognizing partial entailment. We also pro-
vide a preliminary assessment of how par-
tial entailment may be used for recogniz-
ing (complete) textual entailment.
</bodyText>
<sectionHeader confidence="0.998982" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999612016129032">
Approaches for applied semantic inference over
texts gained growing attention in recent years,
largely triggered by the textual entailment frame-
work (Dagan et al., 2009). Textual entailment is
a generic paradigm for semantic inference, where
the objective is to recognize whether a textual hy-
pothesis (labeled H) can be inferred from another
given text (labeled T). The definition of textual
entailment is in some sense strict, in that it requires
that H’s meaning be implied by T in its entirety.
This means that from an entailment perspective, a
text that contains the main ideas of a hypothesis,
but lacks a minor detail, is indiscernible from an
entirely unrelated text. For example, if T is “mus-
cles move bones”, and H “the main job of muscles
is to move bones”, then T does not entail H, and
we are left with no sense of how close (T, H) were
to entailment.
In the related problem of semantic text similar-
ity, gradual measures are already in use. The se-
mantic text similarity challenge in SemEval 2012
(Agirre et al., 2012) explicitly defined different
levels of similarity from 5 (semantic equivalence)
to 0 (no relation). For instance, 4 was defined
as “the two sentences are mostly equivalent, but
some unimportant details differ”, and 3 meant that
“the two sentences are roughly equivalent, but
some important information differs”. Though this
modeling does indeed provide finer-grained no-
tions of similarity, it is not appropriate for seman-
tic inference for two reasons. First, the term “im-
portant information” is vague; what makes one de-
tail more important than another? Secondly, simi-
larity is not sufficiently well-defined for sound se-
mantic inference; for example, “snowdrops bloom
in summer” and “snowdrops bloom in winter”
may be similar, but have contradictory meanings.
All in all, these measures of similarity do not quite
capture the gradual relation needed for semantic
inference.
An appealing approach to dealing with the
rigidity of textual entailment, while preserving the
more precise nature of the entailment definition, is
by breaking down the hypothesis into components,
and attempting to recognize whether each one is
individually entailed by T. It is called partial tex-
tual entailment, because we are only interested in
recognizing whether a single element of the hy-
pothesis is entailed. To differentiate the two tasks,
we will refer to the original textual entailment task
as complete textual entailment.
Partial textual entailment was first introduced
by Nielsen et al. (2009), who presented a ma-
chine learning approach and showed significant
improvement over baseline methods. Recently, a
public benchmark has become available through
the Joint Student Response Analysis and 8th Rec-
ognizing Textual Entailment (RTE) Challenge in
SemEval 2013 (Dzikovska et al., 2013), on which
we focus in this paper.
Our goal in this paper is to investigate the idea
of partial textual entailment, and assess whether
</bodyText>
<page confidence="0.983752">
451
</page>
<bodyText confidence="0.892492538461538">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 451–455,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
existing complete textual entailment methods can
be used to recognize it. We assume the facet
model presented in SemEval 2013, and adapt ex-
isting technologies to the task of recognizing par-
tial entailment (Section 3). Our work further ex-
pands upon (Nielsen et al., 2009) by evaluating
these adapted methods on the new RTE-8 bench-
mark (Section 4). Partial entailment may also fa-
cilitate an alternative divide and conquer approach
to complete textual entailment. We provide an ini-
tial investigation of this approach (Section 5).
</bodyText>
<sectionHeader confidence="0.976566" genericHeader="introduction">
2 Task Definition
</sectionHeader>
<bodyText confidence="0.999838533333333">
In order to tackle partial entailment, we need to
find a way to decompose a hypothesis. Nielsen et
al. (2009) defined a model of facets, where each
such facet is a pair of words in the hypothesis
and the direct semantic relation connecting those
two words. We assume the simplified model that
was used in RTE-8, where the relation between the
words is not explicitly stated. Instead, it remains
unstated, but its interpreted meaning should corre-
spond to the manner in which the words are related
in the hypothesis. For example, in the sentence
“the main job of muscles is to move bones”, the
pair (muscles, move) represents a facet. While it is
not explicitly stated, reading the original sentence
indicates that muscles is the agent of move.
Formally, the task of recognizing faceted entail-
ment is a binary classification task. Given a text T,
a hypothesis H, and a facet within the hypothesis
(w1, w2), determine whether the facet is either ex-
pressed or unaddressed by the text. Nielsen et al
included additional classes such as contradicting,
but in the scope of this paper we will only tend to
the binary case, as was done in RTE-8.
Consider the following example:
T: Muscles generate movement in the body.
H: The main job of muscles is to move bones.
The facet (muscles, move) refers to the agent role
in H, and is expressed by T. However, the facet
(move, bones), which refers to a theme or direct
object relation in H, is unaddressed by T.
</bodyText>
<sectionHeader confidence="0.97897" genericHeader="method">
3 Recognizing Faceted Entailment
</sectionHeader>
<bodyText confidence="0.999939777777778">
Our goal is to investigate whether existing entail-
ment recognition approaches can be adapted to
recognize faceted entailment. Hence, we speci-
fied relatively simple decision mechanisms over a
set of entailment detection modules. Given a text
and a facet, each module reports whether it rec-
ognizes entailment, and the decision mechanism
then determines the binary class (expressed or un-
addressed) accordingly.
</bodyText>
<subsectionHeader confidence="0.996607">
3.1 Entailment Modules
</subsectionHeader>
<bodyText confidence="0.999822">
Current textual entailment systems operate across
different linguistic levels, mainly on lexical infer-
ence and syntax. We examined three representa-
tive modules that reflect these levels: Exact Match,
Lexical Inference, and Syntactic Inference.
Exact Match We represent T as a bag-of-words
containing all tokens and lemmas appearing in the
text. We then check whether both facet lemmas
w1, w2 appear in the text’s bag-of-words. Exact
matching was used as a baseline in previous rec-
ognizing textual entailment challenges (Bentivogli
et al., 2011), and similar methods of lemma-
matching were used as a component in recogniz-
ing textual entailment systems (Clark and Harri-
son, 2010; Shnarch et al., 2011).
Lexical Inference This feature checks whether
both facet words, or semantically related words,
appear in T. We use WordNet (Fellbaum, 1998)
with the Resnik similarity measure (Resnik, 1995)
and count a facet term wz as matched if the sim-
ilarity score exceeds a certain threshold (0.9, em-
pirically determined on the training set). Both w1
and w2 must match for this module’s entailment
decision to be positive.
Syntactic Inference This module builds upon
the open source1 Bar-Ilan University Textual En-
tailment Engine (BIUTEE) (Stern and Dagan,
2011). BIUTEE operates on dependency trees by
applying a sequence of knowledge-based transfor-
mations that converts T into H. It determines en-
tailment according to the “cost” of generating the
hypothesis from the text. The cost model can be
automatically tuned with a relatively small train-
ing set. BIUTEE has shown state-of-the-art per-
formance on previous recognizing textual entail-
ment challenges (Stern and Dagan, 2012).
Since BIUTEE processes dependency trees,
both T and the facet must be parsed. We therefore
extract a path in H’s dependency tree that repre-
sents the facet. This is done by first parsing H,
and then locating the two nodes whose words com-
pose the facet. We then find their lowest common
ancestor (LCA), and extract the path P from w1 to
</bodyText>
<footnote confidence="0.537282">
1cs.biu.ac.il/˜nlp/downloads/biutee
</footnote>
<page confidence="0.995069">
452
</page>
<bodyText confidence="0.99949575">
w2 through the LCA. This path is in fact a depen-
dency tree. BIUTEE can now be given T and P
(as the hypothesis), and try to recognize whether
the former entails the latter.
</bodyText>
<subsectionHeader confidence="0.997339">
3.2 Decision Mechanisms
</subsectionHeader>
<bodyText confidence="0.998574888888889">
We started our experimentation process by defin-
ing Exact Match as a baseline. Though very sim-
ple, this unsupervised baseline performed surpris-
ingly well, with 0.96 precision and 0.32 recall on
expressed facets of the training data. Given its
very high precision, we decided to use this mod-
ule as an initial filter, and employ the others for
classifying the “harder” cases.
We present all the mechanisms that we tested:
</bodyText>
<figure confidence="0.7099672">
Baseline Exact
BaseLex Exact V Lexical
BaseSyn Exact V Syntactic
Disjunction Exact V Lexical V Syntactic
Majority Exact V (Lexical ∧ Syntactic)
</figure>
<bodyText confidence="0.9952828">
Note that since every facet that Exact Match
classifies as expressed is also expressed by Lexi-
cal Inference, BaseLex is essentially Lexical Infer-
ence on its own, and Majority is equivalent to the
majority rule on all three modules.
</bodyText>
<sectionHeader confidence="0.99946" genericHeader="method">
4 Empirical Evaluation
</sectionHeader>
<subsectionHeader confidence="0.993249">
4.1 Dataset: Student Response Analysis
</subsectionHeader>
<bodyText confidence="0.992918863636364">
We evaluated our methods as part of RTE-8. The
challenge focuses on the domain of scholastic
quizzes, and attempts to emulate the meticulous
marking process that teachers do on a daily basis.
Given a question, a student’s response, and a refer-
ence answer, the task of student response analysis
is to determine whether the student answered cor-
rectly. This task can be approximated as a special
case of textual entailment; by assigning the stu-
dent’s answer as T and the reference answer as H,
we are basically asking whether one can infer the
correct (reference) answer from the student’s re-
sponse.
Recall the example from Section 2. In this case,
H is a reference answer to the question:
Q: What is the main job of muscles?
T is essentially the student answer, though it is
also possible to define T as the union of both the
question and the student answer. In this work, we
chose to exclude the question.
There were two tracks in the challenge: com-
plete textual entailment (the main task) and partial
</bodyText>
<table confidence="0.999590285714286">
Unseen Unseen Unseen
Answers Questions Domains
Baseline .670 .688 .731
BaseLex .756 .710 .760
BaseSyn .744 .733 .770
Disjunction .695 .655 .703
Majority .782 .765 .816
</table>
<tableCaption confidence="0.930055">
Table 1: Micro-averaged F1 on the faceted Sci-
EntsBank test set.
</tableCaption>
<bodyText confidence="0.9955296">
entailment (the pilot task). Both tasks made use of
the SciEntsBank corpus (Dzikovska et al., 2012),
which is annotated at facet-level, and provides a
convenient test-bed for evaluation of both partial
and complete entailment. This dataset was split
into train and test subsets. The test set has 16,263
facet-response pairs based on 5,106 student re-
sponses over 15 domains (learning modules). Per-
formance was measured using micro-averaged F1,
over three different scenarios:
Unseen Answers Classify new answers to ques-
tions seen in training. Contains 464 student re-
sponses.
Unseen Questions Classify new answers to
questions that were not seen in training, but other
questions from the same domain were. Contains
631 student responses.
Unseen Domains Classify new answers to un-
seen questions from unseen domains. Contains
4,011 student responses.
</bodyText>
<sectionHeader confidence="0.698143" genericHeader="method">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999952333333333">
Table 1 shows the F1-measure of each configu-
ration in each scenario. There is some variance
between the different scenarios; this may be at-
tributed to the fact that there are much fewer Un-
seen Answers and Unseen Questions instances. In
all cases, Majority significantly outperformed the
other configurations. While BaseLex and BaseSyn
improve upon the baseline, they seem to make dif-
ferent mistakes, in particular false positives. Their
conjunction is thus a more conservative indicator
of entailment, and proves helpful in terms of F1.
All improvements over the baseline were found
to be statistically significant using McNemar’s test
with p &lt; 0.01 (excluding Disjunction). It is also
interesting to note that the systems’ performance
does not degrade in “harder” scenarios; this is a re-
sult of the mostly unsupervised nature of our mod-
ules.
</bodyText>
<page confidence="0.998685">
453
</page>
<bodyText confidence="0.999943">
Unfortunately, our system was the only submis-
sion in the partial entailment pilot track of RTE-
8, so we have no comparisons with other sys-
tems. However, the absolute improvement from
the exact-match baseline to the more sophisticated
Majority is in the same ballpark as that of the best
systems in previous recognizing textual entailment
challenges. For instance, in the previous recogniz-
ing textual entailment challenge (Bentivogli et al.,
2011), the best system yielded an F1 score of 0.48,
while the baseline scored 0.374. We can therefore
conclude that existing approaches for recognizing
textual entailment can indeed be adapted for rec-
ognizing partial entailment.
</bodyText>
<sectionHeader confidence="0.9691935" genericHeader="method">
5 Utilizing Partial Entailment for
Recognizing Complete Entailment
</sectionHeader>
<bodyText confidence="0.999915555555556">
Encouraged by our results, we ask whether the
same algorithms that performed well on the
faceted entailment task can be used for recogniz-
ing complete textual entailment. We performed an
initial experiment that examines this concept and
sheds some light on the potential role of partial en-
tailment as a possible facilitator for complete en-
tailment.
We suggest the following 3-stage architecture:
</bodyText>
<listItem confidence="0.9860955">
1. Decompose the hypothesis into facets.
2. Determine whether each facet is entailed.
3. Aggregate the individual facet results and de-
cide on complete entailment accordingly.
</listItem>
<bodyText confidence="0.999055333333333">
Facet Decomposition For this initial investiga-
tion, we use the facets provided in SciEntsBank;
i.e. we assume that the step offacet decomposition
has already been carried out. When the dataset
was created for RTE-8, many facets were extracted
automatically, but only a subset was selected. The
facet selection process was done manually, as part
of the dataset’s annotation. For example, in “the
main job of muscles is to move bones”, the facet
(job, muscles) was not selected, because it was not
critical for answering the question. We refer to the
issue of relying on manual input further below.
Recognizing Faceted Entailment This step was
carried out as explained in the previous sections.
We used the Baseline configuration and Majority,
which performed best in our experiments above.
In addition, we introduce GoldBased that uses the
gold annotation of faceted entailment, and thus
</bodyText>
<table confidence="0.999250666666667">
Unseen Unseen Unseen
Answers Questions Domains
Baseline .575 .582 .683
Majority .707 .673 .764
GoldBased .842 .897 .852
BestComplete .773 .745 .712
</table>
<tableCaption confidence="0.992369">
Table 2: Micro-averaged F1 on the 2-way com-
plete entailment SciEntsBank test set.
</tableCaption>
<bodyText confidence="0.997995575">
provides a certain upper bound on the perfor-
mance of determining complete entailment based
on facets.
Aggregation We chose the simplest sensible ag-
gregation rule to decide on overall entailment: a
student answer is classified as correct (i.e. it en-
tails the reference answer) if it expresses each
of the reference answer’s facets. Although this
heuristic is logical from a strict entailment per-
spective, it might yield false negatives on this par-
ticular dataset. This happens because tutors may
sometimes grade answers as valid even if they
omit some less important, or indirectly implied,
facets.
Table 2 shows the experiment’s results. The
first thing to notice is that GoldBased is not per-
fect. There are two reasons for this behavior.
First, the task of student response analysis is only
an approximation of textual entailment, albeit a
good one. This discrepancy was also observed
by the RTE-8 challenge organizers (Dzikovska et
al., 2013). The second reason is because some of
the original facets were filtered when creating the
dataset. This caused both false positives (when
important facets were filtered out) and false neg-
atives (when unimportant facets were retained).
Our Majority mechanism, which requires that
the two underlying methods for partial entailment
detection (Lexical Inference and Syntactic Infer-
ence) agree on a positive classification, bridges
about half the gap from the baseline to the gold
based method. As a rough point of comparison,
we also show the performance of BestComplete,
the winning entry in each setting of the RTE-8
main task. This measure is not directly compara-
ble to our facet-based systems, because it did not
rely on manually selected facets, and due to some
variations in the dataset size (about 20% of the stu-
dent responses were not included in the pilot task
dataset). However, these results may indicate the
</bodyText>
<page confidence="0.997557">
454
</page>
<bodyText confidence="0.99951">
prospects of using faceted entailment for complete
entailment recognition, suggesting it as an attrac-
tive research direction.
</bodyText>
<sectionHeader confidence="0.988879" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999969666666667">
In this paper, we presented an empirical attempt
to tackle the problem of partial textual entail-
ment. We demonstrated that existing methods for
recognizing (complete) textual entailment can be
successfully adapted to this setting. Our experi-
ments showed that boolean combinations of these
methods yield good results. Future research may
add additional features and more complex fea-
ture combination methods, such as weighted sums
tuned by machine learning. Furthermore, our
work focused on a specific decomposition model
– faceted entailment. Other flavors of partial en-
tailment should be investigated as well. Finally,
we examined the possibility of utilizing partial en-
tailment for recognizing complete entailment in a
semi-automatic setting, which relied on the man-
ual facet annotation in the RTE-8 dataset. Our
preliminary results suggest that this approach is
indeed feasible, and warrant further research on
facet-based entailment methods that rely on fully-
automatic facet extraction.
</bodyText>
<sectionHeader confidence="0.994948" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999938666666667">
This work has been supported by the Volk-
swagen Foundation as part of the Lichtenberg-
Professorship Program under grant No. I/82806,
and by the European Community’s Seventh
Framework Programme (FP7/2007-2013) under
grant agreement no. 287923 (EXCITEMENT).
We would like to thank the Minerva Foundation
for facilitating this cooperation with a short term
research grant.
</bodyText>
<sectionHeader confidence="0.998531" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999632609375">
Eneko Agirre, Daniel Cer, Mona Diab, and Aitor
Gonzalez-Agirre. 2012. SemEval-2012 Task 6:
A pilot on semantic textual similarity. In Proceed-
ings of the 6th International Workshop on Semantic
Evaluation, in conjunction with the 1st Joint Con-
ference on Lexical and Computational Semantics,
pages 385–393, Montreal, Canada.
Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Dang,
and Danilo Giampiccolo. 2011. The seventh pascal
recognizing textual entailment challenge. Proceed-
ings of TAC.
Peter Clark and Phil Harrison. 2010. Blue-lite: a
knowledge-based lexical entailment system for rte6.
Proc. of TAC.
Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan
Roth. 2009. Recognizing textual entailment: Ratio-
nale, evaluation and approaches. Natural Language
Engineering, 15(4):i–xvii.
Myroslava O Dzikovska, Rodney D Nielsen, and Chris
Brew. 2012. Towards effective tutorial feedback
for explanation questions: A dataset and baselines.
In Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 200–210. Association for Computational Lin-
guistics.
Myroslava O. Dzikovska, Rodney Nielsen, Chris Brew,
Claudia Leacock, Danilo Giampiccolo, Luisa Ben-
tivogli, Peter Clark, Ido Dagan, and Hoa Trang
Dang. 2013. Semeval-2013 task 7: The joint stu-
dent response analysis and 8th recognizing textual
entailment challenge. In *SEM 2013: The First
Joint Conference on Lexical and Computational Se-
mantics, Atlanta, Georgia, USA, 13-14 June. Asso-
ciation for Computational Linguistics.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
MA.
Rodney D Nielsen, Wayne Ward, and James H Mar-
tin. 2009. Recognizing entailment in intelligent
tutoring systems. Natural Language Engineering,
15(4):479–501.
Philip Resnik. 1995. Using information content to
evaluate semantic similarity in a taxonomy. In Pro-
ceedings of the 14th International Joint Conference
on Artificial Intelligence (IJCAI 1995), pages 448–
453.
Eyal Shnarch, Jacob Goldberger, and Ido Dagan. 2011.
A probabilistic modeling framework for lexical en-
tailment. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies, pages 558–
563, Portland, Oregon, USA, June. Association for
Computational Linguistics.
Asher Stern and Ido Dagan. 2011. A confidence
model for syntactically-motivated entailment proofs.
In Proceedings of the 8th International Conference
on Recent Advances in Natural Language Process-
ing (RANLP 2011), pages 455–462.
Asher Stern and Ido Dagan. 2012. Biutee: A mod-
ular open-source system for recognizing textual en-
tailment. In Proceedings of the ACL 2012 System
Demonstrations, pages 73–78, Jeju Island, Korea,
July. Association for Computational Linguistics.
</reference>
<page confidence="0.999055">
455
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.415945">
<title confidence="0.726667">Recognizing Partial Textual Entailment Language Processing Lab Knowledge Processing Lab</title>
<affiliation confidence="0.9972735">Computer Science Department Computer Science Department Bar-Ilan University Technische Universit¨at Darmstadt</affiliation>
<abstract confidence="0.994552111111111">Textual entailment is an asymmetric relation between two text fragments that describes whether one fragment can be inferred from the other. It thus cannot capture the notion that the target fragment is “almost entailed” by the given text. recently suggested idea of texentailment remedy this problem. We investigate partial entailment under the faceted entailment model and the possibility of adapting existing textual entailment methods to this setting. Indeed, our results show that these methods are useful for recognizing partial entailment. We also provide a preliminary assessment of how partial entailment may be used for recognizing (complete) textual entailment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Daniel Cer</author>
<author>Mona Diab</author>
<author>Aitor Gonzalez-Agirre</author>
</authors>
<title>SemEval-2012 Task 6: A pilot on semantic textual similarity.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation, in conjunction with the 1st Joint Conference on Lexical and Computational Semantics,</booktitle>
<pages>385--393</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="2020" citStr="Agirre et al., 2012" startWordPosition="322" endWordPosition="325">some sense strict, in that it requires that H’s meaning be implied by T in its entirety. This means that from an entailment perspective, a text that contains the main ideas of a hypothesis, but lacks a minor detail, is indiscernible from an entirely unrelated text. For example, if T is “muscles move bones”, and H “the main job of muscles is to move bones”, then T does not entail H, and we are left with no sense of how close (T, H) were to entailment. In the related problem of semantic text similarity, gradual measures are already in use. The semantic text similarity challenge in SemEval 2012 (Agirre et al., 2012) explicitly defined different levels of similarity from 5 (semantic equivalence) to 0 (no relation). For instance, 4 was defined as “the two sentences are mostly equivalent, but some unimportant details differ”, and 3 meant that “the two sentences are roughly equivalent, but some important information differs”. Though this modeling does indeed provide finer-grained notions of similarity, it is not appropriate for semantic inference for two reasons. First, the term “important information” is vague; what makes one detail more important than another? Secondly, similarity is not sufficiently well-</context>
</contexts>
<marker>Agirre, Cer, Diab, Gonzalez-Agirre, 2012</marker>
<rawString>Eneko Agirre, Daniel Cer, Mona Diab, and Aitor Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A pilot on semantic textual similarity. In Proceedings of the 6th International Workshop on Semantic Evaluation, in conjunction with the 1st Joint Conference on Lexical and Computational Semantics, pages 385–393, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Peter Clark</author>
<author>Ido Dagan</author>
<author>Hoa Dang</author>
<author>Danilo Giampiccolo</author>
</authors>
<title>The seventh pascal recognizing textual entailment challenge.</title>
<date>2011</date>
<booktitle>Proceedings of TAC.</booktitle>
<contexts>
<context position="7117" citStr="Bentivogli et al., 2011" startWordPosition="1133" endWordPosition="1136">the binary class (expressed or unaddressed) accordingly. 3.1 Entailment Modules Current textual entailment systems operate across different linguistic levels, mainly on lexical inference and syntax. We examined three representative modules that reflect these levels: Exact Match, Lexical Inference, and Syntactic Inference. Exact Match We represent T as a bag-of-words containing all tokens and lemmas appearing in the text. We then check whether both facet lemmas w1, w2 appear in the text’s bag-of-words. Exact matching was used as a baseline in previous recognizing textual entailment challenges (Bentivogli et al., 2011), and similar methods of lemmamatching were used as a component in recognizing textual entailment systems (Clark and Harrison, 2010; Shnarch et al., 2011). Lexical Inference This feature checks whether both facet words, or semantically related words, appear in T. We use WordNet (Fellbaum, 1998) with the Resnik similarity measure (Resnik, 1995) and count a facet term wz as matched if the similarity score exceeds a certain threshold (0.9, empirically determined on the training set). Both w1 and w2 must match for this module’s entailment decision to be positive. Syntactic Inference This module bu</context>
<context position="13053" citStr="Bentivogli et al., 2011" startWordPosition="2100" endWordPosition="2103">tion). It is also interesting to note that the systems’ performance does not degrade in “harder” scenarios; this is a result of the mostly unsupervised nature of our modules. 453 Unfortunately, our system was the only submission in the partial entailment pilot track of RTE8, so we have no comparisons with other systems. However, the absolute improvement from the exact-match baseline to the more sophisticated Majority is in the same ballpark as that of the best systems in previous recognizing textual entailment challenges. For instance, in the previous recognizing textual entailment challenge (Bentivogli et al., 2011), the best system yielded an F1 score of 0.48, while the baseline scored 0.374. We can therefore conclude that existing approaches for recognizing textual entailment can indeed be adapted for recognizing partial entailment. 5 Utilizing Partial Entailment for Recognizing Complete Entailment Encouraged by our results, we ask whether the same algorithms that performed well on the faceted entailment task can be used for recognizing complete textual entailment. We performed an initial experiment that examines this concept and sheds some light on the potential role of partial entailment as a possibl</context>
</contexts>
<marker>Bentivogli, Clark, Dagan, Dang, Giampiccolo, 2011</marker>
<rawString>Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Dang, and Danilo Giampiccolo. 2011. The seventh pascal recognizing textual entailment challenge. Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>Phil Harrison</author>
</authors>
<title>Blue-lite: a knowledge-based lexical entailment system for rte6.</title>
<date>2010</date>
<booktitle>Proc. of TAC.</booktitle>
<contexts>
<context position="7248" citStr="Clark and Harrison, 2010" startWordPosition="1154" endWordPosition="1158">ifferent linguistic levels, mainly on lexical inference and syntax. We examined three representative modules that reflect these levels: Exact Match, Lexical Inference, and Syntactic Inference. Exact Match We represent T as a bag-of-words containing all tokens and lemmas appearing in the text. We then check whether both facet lemmas w1, w2 appear in the text’s bag-of-words. Exact matching was used as a baseline in previous recognizing textual entailment challenges (Bentivogli et al., 2011), and similar methods of lemmamatching were used as a component in recognizing textual entailment systems (Clark and Harrison, 2010; Shnarch et al., 2011). Lexical Inference This feature checks whether both facet words, or semantically related words, appear in T. We use WordNet (Fellbaum, 1998) with the Resnik similarity measure (Resnik, 1995) and count a facet term wz as matched if the similarity score exceeds a certain threshold (0.9, empirically determined on the training set). Both w1 and w2 must match for this module’s entailment decision to be positive. Syntactic Inference This module builds upon the open source1 Bar-Ilan University Textual Entailment Engine (BIUTEE) (Stern and Dagan, 2011). BIUTEE operates on depen</context>
</contexts>
<marker>Clark, Harrison, 2010</marker>
<rawString>Peter Clark and Phil Harrison. 2010. Blue-lite: a knowledge-based lexical entailment system for rte6. Proc. of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
<author>Bernardo Magnini</author>
<author>Dan Roth</author>
</authors>
<title>Recognizing textual entailment: Rationale, evaluation and approaches.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="1160" citStr="Dagan et al., 2009" startWordPosition="169" endWordPosition="172">ted idea of partial textual entailment may remedy this problem. We investigate partial entailment under the faceted entailment model and the possibility of adapting existing textual entailment methods to this setting. Indeed, our results show that these methods are useful for recognizing partial entailment. We also provide a preliminary assessment of how partial entailment may be used for recognizing (complete) textual entailment. 1 Introduction Approaches for applied semantic inference over texts gained growing attention in recent years, largely triggered by the textual entailment framework (Dagan et al., 2009). Textual entailment is a generic paradigm for semantic inference, where the objective is to recognize whether a textual hypothesis (labeled H) can be inferred from another given text (labeled T). The definition of textual entailment is in some sense strict, in that it requires that H’s meaning be implied by T in its entirety. This means that from an entailment perspective, a text that contains the main ideas of a hypothesis, but lacks a minor detail, is indiscernible from an entirely unrelated text. For example, if T is “muscles move bones”, and H “the main job of muscles is to move bones”, t</context>
</contexts>
<marker>Dagan, Dolan, Magnini, Roth, 2009</marker>
<rawString>Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan Roth. 2009. Recognizing textual entailment: Rationale, evaluation and approaches. Natural Language Engineering, 15(4):i–xvii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myroslava O Dzikovska</author>
<author>Rodney D Nielsen</author>
<author>Chris Brew</author>
</authors>
<title>Towards effective tutorial feedback for explanation questions: A dataset and baselines.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>200--210</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="11001" citStr="Dzikovska et al., 2012" startWordPosition="1779" endWordPosition="1782">b of muscles? T is essentially the student answer, though it is also possible to define T as the union of both the question and the student answer. In this work, we chose to exclude the question. There were two tracks in the challenge: complete textual entailment (the main task) and partial Unseen Unseen Unseen Answers Questions Domains Baseline .670 .688 .731 BaseLex .756 .710 .760 BaseSyn .744 .733 .770 Disjunction .695 .655 .703 Majority .782 .765 .816 Table 1: Micro-averaged F1 on the faceted SciEntsBank test set. entailment (the pilot task). Both tasks made use of the SciEntsBank corpus (Dzikovska et al., 2012), which is annotated at facet-level, and provides a convenient test-bed for evaluation of both partial and complete entailment. This dataset was split into train and test subsets. The test set has 16,263 facet-response pairs based on 5,106 student responses over 15 domains (learning modules). Performance was measured using micro-averaged F1, over three different scenarios: Unseen Answers Classify new answers to questions seen in training. Contains 464 student responses. Unseen Questions Classify new answers to questions that were not seen in training, but other questions from the same domain w</context>
</contexts>
<marker>Dzikovska, Nielsen, Brew, 2012</marker>
<rawString>Myroslava O Dzikovska, Rodney D Nielsen, and Chris Brew. 2012. Towards effective tutorial feedback for explanation questions: A dataset and baselines. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 200–210. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Myroslava O Dzikovska</author>
<author>Rodney Nielsen</author>
<author>Chris Brew</author>
<author>Claudia Leacock</author>
<author>Danilo Giampiccolo</author>
<author>Luisa Bentivogli</author>
<author>Peter Clark</author>
<author>Ido Dagan</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Semeval-2013 task 7: The joint student response analysis and 8th recognizing textual entailment challenge.</title>
<date>2013</date>
<booktitle>In *SEM 2013: The First Joint Conference on Lexical and Computational Semantics,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="3791" citStr="Dzikovska et al., 2013" startWordPosition="591" endWordPosition="594">t is called partial textual entailment, because we are only interested in recognizing whether a single element of the hypothesis is entailed. To differentiate the two tasks, we will refer to the original textual entailment task as complete textual entailment. Partial textual entailment was first introduced by Nielsen et al. (2009), who presented a machine learning approach and showed significant improvement over baseline methods. Recently, a public benchmark has become available through the Joint Student Response Analysis and 8th Recognizing Textual Entailment (RTE) Challenge in SemEval 2013 (Dzikovska et al., 2013), on which we focus in this paper. Our goal in this paper is to investigate the idea of partial textual entailment, and assess whether 451 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 451–455, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics existing complete textual entailment methods can be used to recognize it. We assume the facet model presented in SemEval 2013, and adapt existing technologies to the task of recognizing partial entailment (Section 3). Our work further expands upon (Nielsen et al., 2009) by </context>
<context position="15975" citStr="Dzikovska et al., 2013" startWordPosition="2558" endWordPosition="2561">s facets. Although this heuristic is logical from a strict entailment perspective, it might yield false negatives on this particular dataset. This happens because tutors may sometimes grade answers as valid even if they omit some less important, or indirectly implied, facets. Table 2 shows the experiment’s results. The first thing to notice is that GoldBased is not perfect. There are two reasons for this behavior. First, the task of student response analysis is only an approximation of textual entailment, albeit a good one. This discrepancy was also observed by the RTE-8 challenge organizers (Dzikovska et al., 2013). The second reason is because some of the original facets were filtered when creating the dataset. This caused both false positives (when important facets were filtered out) and false negatives (when unimportant facets were retained). Our Majority mechanism, which requires that the two underlying methods for partial entailment detection (Lexical Inference and Syntactic Inference) agree on a positive classification, bridges about half the gap from the baseline to the gold based method. As a rough point of comparison, we also show the performance of BestComplete, the winning entry in each setti</context>
</contexts>
<marker>Dzikovska, Nielsen, Brew, Leacock, Giampiccolo, Bentivogli, Clark, Dagan, Dang, 2013</marker>
<rawString>Myroslava O. Dzikovska, Rodney Nielsen, Chris Brew, Claudia Leacock, Danilo Giampiccolo, Luisa Bentivogli, Peter Clark, Ido Dagan, and Hoa Trang Dang. 2013. Semeval-2013 task 7: The joint student response analysis and 8th recognizing textual entailment challenge. In *SEM 2013: The First Joint Conference on Lexical and Computational Semantics, Atlanta, Georgia, USA, 13-14 June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodney D Nielsen</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
</authors>
<title>Recognizing entailment in intelligent tutoring systems.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="3500" citStr="Nielsen et al. (2009)" startWordPosition="549" endWordPosition="552">tic inference. An appealing approach to dealing with the rigidity of textual entailment, while preserving the more precise nature of the entailment definition, is by breaking down the hypothesis into components, and attempting to recognize whether each one is individually entailed by T. It is called partial textual entailment, because we are only interested in recognizing whether a single element of the hypothesis is entailed. To differentiate the two tasks, we will refer to the original textual entailment task as complete textual entailment. Partial textual entailment was first introduced by Nielsen et al. (2009), who presented a machine learning approach and showed significant improvement over baseline methods. Recently, a public benchmark has become available through the Joint Student Response Analysis and 8th Recognizing Textual Entailment (RTE) Challenge in SemEval 2013 (Dzikovska et al., 2013), on which we focus in this paper. Our goal in this paper is to investigate the idea of partial textual entailment, and assess whether 451 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 451–455, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computati</context>
<context position="4771" citStr="Nielsen et al. (2009)" startWordPosition="748" endWordPosition="751">ent methods can be used to recognize it. We assume the facet model presented in SemEval 2013, and adapt existing technologies to the task of recognizing partial entailment (Section 3). Our work further expands upon (Nielsen et al., 2009) by evaluating these adapted methods on the new RTE-8 benchmark (Section 4). Partial entailment may also facilitate an alternative divide and conquer approach to complete textual entailment. We provide an initial investigation of this approach (Section 5). 2 Task Definition In order to tackle partial entailment, we need to find a way to decompose a hypothesis. Nielsen et al. (2009) defined a model of facets, where each such facet is a pair of words in the hypothesis and the direct semantic relation connecting those two words. We assume the simplified model that was used in RTE-8, where the relation between the words is not explicitly stated. Instead, it remains unstated, but its interpreted meaning should correspond to the manner in which the words are related in the hypothesis. For example, in the sentence “the main job of muscles is to move bones”, the pair (muscles, move) represents a facet. While it is not explicitly stated, reading the original sentence indicates t</context>
</contexts>
<marker>Nielsen, Ward, Martin, 2009</marker>
<rawString>Rodney D Nielsen, Wayne Ward, and James H Martin. 2009. Recognizing entailment in intelligent tutoring systems. Natural Language Engineering, 15(4):479–501.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI</booktitle>
<pages>448--453</pages>
<contexts>
<context position="7462" citStr="Resnik, 1995" startWordPosition="1189" endWordPosition="1190">bag-of-words containing all tokens and lemmas appearing in the text. We then check whether both facet lemmas w1, w2 appear in the text’s bag-of-words. Exact matching was used as a baseline in previous recognizing textual entailment challenges (Bentivogli et al., 2011), and similar methods of lemmamatching were used as a component in recognizing textual entailment systems (Clark and Harrison, 2010; Shnarch et al., 2011). Lexical Inference This feature checks whether both facet words, or semantically related words, appear in T. We use WordNet (Fellbaum, 1998) with the Resnik similarity measure (Resnik, 1995) and count a facet term wz as matched if the similarity score exceeds a certain threshold (0.9, empirically determined on the training set). Both w1 and w2 must match for this module’s entailment decision to be positive. Syntactic Inference This module builds upon the open source1 Bar-Ilan University Textual Entailment Engine (BIUTEE) (Stern and Dagan, 2011). BIUTEE operates on dependency trees by applying a sequence of knowledge-based transformations that converts T into H. It determines entailment according to the “cost” of generating the hypothesis from the text. The cost model can be autom</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Philip Resnik. 1995. Using information content to evaluate semantic similarity in a taxonomy. In Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI 1995), pages 448– 453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eyal Shnarch</author>
<author>Jacob Goldberger</author>
<author>Ido Dagan</author>
</authors>
<title>A probabilistic modeling framework for lexical entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>558--563</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="7271" citStr="Shnarch et al., 2011" startWordPosition="1159" endWordPosition="1162">, mainly on lexical inference and syntax. We examined three representative modules that reflect these levels: Exact Match, Lexical Inference, and Syntactic Inference. Exact Match We represent T as a bag-of-words containing all tokens and lemmas appearing in the text. We then check whether both facet lemmas w1, w2 appear in the text’s bag-of-words. Exact matching was used as a baseline in previous recognizing textual entailment challenges (Bentivogli et al., 2011), and similar methods of lemmamatching were used as a component in recognizing textual entailment systems (Clark and Harrison, 2010; Shnarch et al., 2011). Lexical Inference This feature checks whether both facet words, or semantically related words, appear in T. We use WordNet (Fellbaum, 1998) with the Resnik similarity measure (Resnik, 1995) and count a facet term wz as matched if the similarity score exceeds a certain threshold (0.9, empirically determined on the training set). Both w1 and w2 must match for this module’s entailment decision to be positive. Syntactic Inference This module builds upon the open source1 Bar-Ilan University Textual Entailment Engine (BIUTEE) (Stern and Dagan, 2011). BIUTEE operates on dependency trees by applying</context>
</contexts>
<marker>Shnarch, Goldberger, Dagan, 2011</marker>
<rawString>Eyal Shnarch, Jacob Goldberger, and Ido Dagan. 2011. A probabilistic modeling framework for lexical entailment. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 558– 563, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asher Stern</author>
<author>Ido Dagan</author>
</authors>
<title>A confidence model for syntactically-motivated entailment proofs.</title>
<date>2011</date>
<booktitle>In Proceedings of the 8th International Conference on Recent Advances in Natural Language Processing (RANLP</booktitle>
<pages>455--462</pages>
<contexts>
<context position="7822" citStr="Stern and Dagan, 2011" startWordPosition="1246" endWordPosition="1249">ual entailment systems (Clark and Harrison, 2010; Shnarch et al., 2011). Lexical Inference This feature checks whether both facet words, or semantically related words, appear in T. We use WordNet (Fellbaum, 1998) with the Resnik similarity measure (Resnik, 1995) and count a facet term wz as matched if the similarity score exceeds a certain threshold (0.9, empirically determined on the training set). Both w1 and w2 must match for this module’s entailment decision to be positive. Syntactic Inference This module builds upon the open source1 Bar-Ilan University Textual Entailment Engine (BIUTEE) (Stern and Dagan, 2011). BIUTEE operates on dependency trees by applying a sequence of knowledge-based transformations that converts T into H. It determines entailment according to the “cost” of generating the hypothesis from the text. The cost model can be automatically tuned with a relatively small training set. BIUTEE has shown state-of-the-art performance on previous recognizing textual entailment challenges (Stern and Dagan, 2012). Since BIUTEE processes dependency trees, both T and the facet must be parsed. We therefore extract a path in H’s dependency tree that represents the facet. This is done by first pars</context>
</contexts>
<marker>Stern, Dagan, 2011</marker>
<rawString>Asher Stern and Ido Dagan. 2011. A confidence model for syntactically-motivated entailment proofs. In Proceedings of the 8th International Conference on Recent Advances in Natural Language Processing (RANLP 2011), pages 455–462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asher Stern</author>
<author>Ido Dagan</author>
</authors>
<title>Biutee: A modular open-source system for recognizing textual entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 System Demonstrations,</booktitle>
<pages>73--78</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="8238" citStr="Stern and Dagan, 2012" startWordPosition="1310" endWordPosition="1313">2 must match for this module’s entailment decision to be positive. Syntactic Inference This module builds upon the open source1 Bar-Ilan University Textual Entailment Engine (BIUTEE) (Stern and Dagan, 2011). BIUTEE operates on dependency trees by applying a sequence of knowledge-based transformations that converts T into H. It determines entailment according to the “cost” of generating the hypothesis from the text. The cost model can be automatically tuned with a relatively small training set. BIUTEE has shown state-of-the-art performance on previous recognizing textual entailment challenges (Stern and Dagan, 2012). Since BIUTEE processes dependency trees, both T and the facet must be parsed. We therefore extract a path in H’s dependency tree that represents the facet. This is done by first parsing H, and then locating the two nodes whose words compose the facet. We then find their lowest common ancestor (LCA), and extract the path P from w1 to 1cs.biu.ac.il/˜nlp/downloads/biutee 452 w2 through the LCA. This path is in fact a dependency tree. BIUTEE can now be given T and P (as the hypothesis), and try to recognize whether the former entails the latter. 3.2 Decision Mechanisms We started our experimenta</context>
</contexts>
<marker>Stern, Dagan, 2012</marker>
<rawString>Asher Stern and Ido Dagan. 2012. Biutee: A modular open-source system for recognizing textual entailment. In Proceedings of the ACL 2012 System Demonstrations, pages 73–78, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>