<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.194579">
<title confidence="0.910493">
Narrated Animation: A Case for Generation
</title>
<author confidence="0.9413">
Norman Badler Mark Steedman Bonnie Lynn Webber
</author>
<affiliation confidence="0.895921333333333">
Department of Computer and Information Science
University of Pennsylvania
Philadelphia PA 19104-63891
</affiliation>
<sectionHeader confidence="0.997311" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99991875">
Our project rests on the belief that computer animation in the form of narrated animated
simulations can provide an engaging, effective and flexible medium for instructing agents of
varying capabilities to perform tasks that make varying demands in workplaces of varying layout.
To this end, we have been designing and implementing an integrated system which combines
</bodyText>
<listItem confidence="0.988548">
• animated agents which can demonstrate the behavior to be emulated;
• automatic generation of appropriate Natural Language narration which can explain what
is being done and why.
</listItem>
<bodyText confidence="0.88498737037037">
To date, our primary concern with Natural Language has been as input to the system, in
line with the strong claim we make in [I] that moving task animation beyond direct graphical
manipulation forces one to Natural Language as the only instruction source accessible to other
users than the current community of manually skilled (or programming-wise) animators. (To
this end, we have been analysing constructions commonly found in NL instructions, in terms of
their representational requirements [3].
However here our point of discussion is NL Generation. What makes us such eager con-
sumers of advances and technology in this area is that animated simulations without narration
(ultimately, spoken narration) is only half the story. As researchers studying plan inference
have shown [2], it may be well-nigh impossible to infer an agent&apos;s intentions simply by observing
his or her actions alone.&apos; And we know that the ability to perform an action effectively in a
range of environments requires understanding its intention, not just the physical motions used
in some performance. Thus, communicating intentions is as important to effective task instruc-
tion as demonstrating physical skills. Sharing the burden of communication between Natural
Language and graphics, as Feiner and McKeown have noted [4], takes advantage of the best of
both possible worlds.
While some parts of our system are further along than others, no work at all has yet been
done on generation. However, we have tried to take account of the needs of generation in
designing the system, so that we will not have painted ourselves in a hole from the start. We
clearly and hope to get further ideas and direction from this meeting. Basically, the system has
been designed so that the generator will receive information from three sources (see Figure 1.):
1T1)is research is partially supported by Lockheed Engineering and Management Services (NASA Johnson
Space Center), NASA Ames Grant NAG-2-426, FMC Corporation, Martin-Marietta Denver Aerospace, NSF
CISE Grant CDA88-22719, and ARO Grant DAAL03-89-C-0031 including participation by the U.S. Army Human
Engineering Laboratory.
2 Exaggerating behavior to make it more communicative may have the adverse effect of making it less veridical,
a situation inversely turned advantageous by skilled cartoon animators [5].
</bodyText>
<page confidence="0.991713">
189
</page>
<listItem confidence="0.999856">
• the partial global plan (an incrementally computed description of what the animated agent
is meant to do and why);
• the basic animation commands (for particulars of what&apos;s happening &amp;quot;now&amp;quot;)
• the visualization plan (for what can the viewer see).
</listItem>
<bodyText confidence="0.9998492">
The resulting narrative is thus meant to satisfy the joint communicative goals of providing
an overall context in which to view the events on the &amp;quot;screen&amp;quot; and explaining the reasons for
particular events that are happening, thereby transcending the merely visible portion of any
event, to augment and reinforce observable behavior. For a more detailed description of the
system and further discussion of instructions and task performance, the reader is referred to [1].
</bodyText>
<sectionHeader confidence="0.987888" genericHeader="references">
References
</sectionHeader>
<listItem confidence="0.980889230769231">
[1] Norman Badler, Bonnie Webber, Jeff Esakov and Jugal Kalita. Animation from Instruc-
tions. Making Them Move: Mechanics, Control and Animation of Articulated Figures.
Morgan-Kaufmann, 1990. (Also appears as Technical Report CIS-90-17, Dept. of Com-
puter and Information Science, Univ. of Pennsylvania, Philadelphia PA, 1990.)
[2] Phil Cohen. The Need for Referent Identification as a Planned Action. Proc. of Interna-
tional Joint Conference on Artificial Intelligence, August 1981, pp. 31-36,
[3] Bonnie Webber and Barbara Di Eugenio. Free Adjuncts in Natural Language Instructions.
Proc. of COLING-90. University of Helsinki, Finland. August 1990.
[4] Feiner, S. and McKeown, K. Coordinating Text and Graphics in Explanation Genera-
tion. Proc. ARPA Speech and Natural Language Workshop, October 1989, Los Altos CA:
Morgan Kaufmann, pp. 424-433.
[5] Frank Thomas and 011ie Johnston. Disney Animation: The Illusion of Life. Abbeville
Press, New York, 1981.
</listItem>
<page confidence="0.99674">
190
</page>
<figureCaption confidence="0.999739">
Figure 1: Design Framework
</figureCaption>
<figure confidence="0.999302658536586">
NL Instructions
Natural
Language
Processor
Workplace
Specs
Descriptions of
task-related actions
and conditions
Object
K-base
Incremental
Planner
(
.:TiittiatiPliiba1::
1.104:
Semantic
Mapper
Event v (ParameterizedTemplates
Simulator
(
Easic Animation
„Commands
V
Event
Feedback
Narrative Planner
&amp; Generator
• ..yisualilation
pititi......
Motion
Generators
NL Narrative
Frame-sliced
parameter bindings
Display
Process
(
iir... ..N....arr.....a-ted.....
lik Animation
&apos; .............................. &apos;
</figure>
<page confidence="0.962042">
191
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.607963">
<title confidence="0.999912">Narrated Animation: A Case for Generation</title>
<author confidence="0.999988">Norman Badler Mark Steedman Bonnie Lynn Webber</author>
<affiliation confidence="0.9995715">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.608389">PA</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>