<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000404">
<title confidence="0.955201">
Synchronous Rewriting in Treebanks
</title>
<author confidence="0.998355">
Laura Kallmeyer Wolfgang Maier Giorgio Satta
</author>
<affiliation confidence="0.9191395">
University of T¨ubingen University of T¨ubingen University of Padua
T¨ubingen, Germany T¨ubingen, Germany Padova, Italy
</affiliation>
<email confidence="0.955386">
lk@sfs.uni-tuebingen.de wo.maier@uni-tuebingen.de satta@dei.unipd.it
</email>
<sectionHeader confidence="0.994022" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999854375">
Several formalisms have been proposed
for modeling trees with discontinuous
phrases. Some of these formalisms allow
for synchronous rewriting. However, it
is unclear whether synchronous rewriting
is a necessary feature. This is an impor-
tant question, since synchronous rewrit-
ing greatly increases parsing complexity.
We present a characterization of recursive
synchronous rewriting in constituent tree-
banks with discontinuous annotation. An
empirical investigation reveals that syn-
chronous rewriting is actually a neces-
sary feature. Furthermore, we transfer this
property to grammars extracted from tree-
banks.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999966020408163">
Discontinuous phrases are frequent in natural
language, particularly in languages with a rela-
tively free word order. Several formalisms have
been proposed in the literature for modeling trees
containing such phrases. These include non-
projective dependency grammar (Nivre, 2006),
discontinuous phrase structure grammar (DPSG)
(Bunt et al., 1987), as well as linear context-
free rewriting systems (LCFRS) (Vijay-Shanker et
al., 1987) and the equivalent formalism of sim-
ple range concatenation grammar (sRCG) (Boul-
lier, 2000). Kuhlmann (2007) uses LCFRS for
non-projective dependency trees. DPSG have
been used in Plaehn (2004) for data-driven pars-
ing of treebanks with discontinuous constituent
annotation. Maier and Søgaard (2008) extract
sRCGs from treebanks with discontinuous con-
stituent structures.
Both LCFRS and sRCG can model discontinu-
ities and allow for synchronous rewriting as well.
We speak of synchronous rewriting when two or
more context-free derivation processes are instan-
tiated in a synchronous way. DPSG, which has
also been proposed for modeling discontinuities,
does not allow for synchronous rewriting because
the different discontinuous parts of the yield of a
non-terminal are treated locally, i.e., their deriva-
tions are independent from each other. So far, syn-
chronous rewriting has not been empirically mo-
tivated by linguistic data from treebanks. In this
paper, we fill this gap by investigating the exis-
tence of structures indicating synchronous rewrit-
ing in treebanks with discontinuous annotations.
The question of whether we can find evidence for
synchronous rewriting has consequences for the
complexity of parsing. In fact, parsing with syn-
chronous formalisms can be carried out in time
polynomial in the length of the input string, with
a polynomial degree depending on the maximum
number of synchronous branches one can find in
derivations (Seki et al., 1991).
In this paper, we characterize synchronous
rewriting as a property of trees with crossing
branches and in an empirical evaluation, we con-
firm that treebanks do contain recursive syn-
chronous rewriting which can be linguistically
motivated. Furthermore, we show how this char-
acterization transfers to the simple RCGs describ-
ing these trees.
</bodyText>
<sectionHeader confidence="0.5556565" genericHeader="method">
2 Synchronous Rewriting Trees in
German treebanks
</sectionHeader>
<bodyText confidence="0.9995337">
By synchronous rewriting we indicate the syn-
chronous instantiation of two or more context-free
derivation processes. As an example, consider the
language L = {anbncndn  |n ≥ 1}. Each
of the two halves of some w E L can be ob-
tained through a stand-alone context-free deriva-
tion, but for w to be in L the two derivations must
be synchronized somehow. For certain tasks, syn-
chronous rewriting is a desired property for a for-
malism. In machine translation, e.g., synchronous
</bodyText>
<page confidence="0.989643">
69
</page>
<bodyText confidence="0.985730657142858">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 69–72,
Paris, October 2009. c�2009 Association for Computational Linguistics
rewriting is extensively used to model the syn-
chronous dependence between the source and tar-
get languages (Chiang, 2007). The question we
are concerned with in this paper is whether we can
find instances of recursive synchronous rewriting
in treebanks that show discontinuous phrases.
We make the assumption that, if the annota-
tion of a treebank allows to express synchronous
rewriting, then all cases of synchronous rewriting
are present in the annotation. This means that, on
the one hand, there are no cases of synchronous
rewriting that the annotator “forgot” to encode.
Therefore unrelated cases of parallel iterations in
different parts of a tree are taken to be truly unre-
lated. On the other hand, if synchronous rewrit-
ing is annotated explicitely, then we take it to be a
case of true synchronous rewriting, even if, based
on the string, it would be possible to find an anal-
ysis that does not require synchronous rewriting.
This assumption allows us to concentrate only on
explicit cases of synchronous rewriting .
We concentrate on German treebanks annotated
with trees with crossing branches. In such trees,
synchronous rewriting amounts to cases where dif-
ferent components of a non-terminal category de-
velop in parallel. In particular, we search for cases
where the parallelism can be iterated. An exam-
ple is the relative clause in (1), found in TIGER.
Fig. 1 gives the annotation. As can be seen in
the annotation, we have two VP nodes, each of
which has a discontinuous span consisting of two
parts. The two parts are separated by lexical ma-
terial not belonging to the VPs. The two com-
ponents of the second VP (Pop-Idol and werden)
are included in the two components of the first,
higher, VP (genausogut auch Pop-Idol and wer-
den k¨onnen). In other words, the two VP compo-
nents are rewritten in parallel containing again two
smaller VP components.
(1) ...der genausogut
...who as well
“who could as well also become a pop-star”
Let us assume the following definitions: We
map the elements of a string to their positions. We
then say that the yield T of a node n in a tree is
the set of all indices i such that n dominates the
leaf labeled with the ith terminal. A yield T has a
gap if there are i1 &lt; i2 &lt; i3 such that i1, i3 E T
and i2 E/ T. For all i, j E T with i &lt; j, the set
T(i,j) _ {k  |i &lt; k &lt; j} is a component of T if
T(i,j) C T and i−1 E/ T and j+1 E/ T. We order
the components of T such that T(i1,j1) &lt; T(i2,j2)
if i1 &lt; i2.
Trees showing recursive synchronous rewrit-
ing can be characterized as follows: We have a
non-terminal node n1 with label A whose yield
has a gap. n1 dominates another node n2 with la-
bel A such that for some i _� j, the ith component
of the yield of n2 is contained in the ith component
of the yield of n1 and similar for the jth compo-
nent. We call the path from n1 to n2 a recursive
synchronous rewriting segment (RSRS).
Table 1 shows the results obtained from search-
ing for recursive synchronous rewriting in the Ger-
man TIGER and NeGra treebanks. In a prepro-
cessing step, punctuation has been removed, since
it is directly attached to the root node and therefore
not included in the annotation.
</bodyText>
<table confidence="0.808617">
TIGER NeGra
40,013 20,597
1476 600
2.13 2.12
5 4
</table>
<tableCaption confidence="0.997997">
Table 1: Synchronous rewriting in treebanks
</tableCaption>
<bodyText confidence="0.999728730769231">
Example (1) shows that we find instances of re-
cursive synchronous rewriting where each of the
rewriting steps adds something to both of the par-
allel components. (1) was not an isolated case.
The annotation of (1) in Fig. 1 could be turned
into a context-free structure if the lowest node
dominating the material in the gap while not
dominating the synchronous rewriting nodes (here
VAFIN) is attached lower, namely below the lower
VP node. (Note however that there is good linguis-
tic motivation for attaching it high.) Besides such
cases, we even encountered cases where the dis-
continuity cannot be removed this way. An exam-
ple is (2) (resp. Fig. 2) where we have a gap con-
taining an NP such that the lowest node dominat-
ing this NP while not dominating the synchronous
rewriting nodes has a daughter to the right of the
yields of the synchronous rewriting nodes, namely
the extraposed relative clause. This structure is of
the type ancbnd, where a and b depend on each
other in a left-to-right order and can be nested,
and c and d also depend on each other and must
be generated together. This is a structure that re-
quires synchronous rewriting, even on the basis of
the string language. Note that the nesting of VPs
can be iterated, as can be seen in (3).
</bodyText>
<figure confidence="0.973882">
(2) ... ob
... whether
auch
also
werden
become
k¨onnen
could
h¨atte
AUX
Pop-Idol
pop-star
</figure>
<figureCaption confidence="0.96111025">
number of trees
total num. of RSRS in all trees
av. RSRS length in all trees
max. RSRS length in all trees
</figureCaption>
<bodyText confidence="0.958566416666667">
der
the
deren
their
von
of
auf
on
Typ
type
Gel¨ande
premises
</bodyText>
<page confidence="0.956915">
70
</page>
<figure confidence="0.9847394">
S
VP
VP
PRELS ADV ADV NN VAFIN VAINF VMINF
der genausogut auch Pop-Idol hatte werden k¨onnen
</figure>
<figureCaption confidence="0.997337">
Figure 1: Example for recursive synchronous rewriting
</figureCaption>
<figure confidence="0.902284333333333">
Abstellanlage
parking facility
“whether on their premises precisely the type of parking
facility could be built, which... ”
(3) ...ob
... whether
Abstellanlage
parking facility
sollen, der ...
</figure>
<bodyText confidence="0.888357666666667">
should, which ...
“whether on their premises precisely the type of parking
facility should actually already have been built, which
. . . ”
As a conclusion from these empirical results,
we state that to account for the data we can find in
treebanks with discontinuities, i.e., with crossing
branches, we need a formalism that can express
synchronous rewriting.
</bodyText>
<sectionHeader confidence="0.790415" genericHeader="method">
3 Synchronous Rewriting in Grammars
Extracted from Treebanks
</sectionHeader>
<bodyText confidence="0.999847222222222">
In the following, we will use simple RCG (which
are equivalent to LCFRS) to model our treebank
annotations. We extract simple RCG rewriting
rules from NeGra and TIGER and check them for
the possibility to generate recursive synchronous
rewriting.
A simple RCG (Boullier, 2000) is a tuple G =
(N, T, V, P, S) where a) N is a finite set of pred-
icate names with an arity function dim: N —* N,
</bodyText>
<equation confidence="0.856240888888889">
b) T and V are disjoint finite sets of terminals and
variables, c) P is a finite set of clauses of the form
A(α1,... ,αdim(A)) → A1(X11),...,X(1)(A,))
··· Am(X(m)
1 , . . . , X(m) dim(Am))
for m &gt; 0 where A, A1, ... , Am E N, X(i)
j E
V for 1 &lt; i &lt; m,1 &lt; j &lt; dim(Ai) and αi E
(T U V )∗ for 1 &lt; i &lt; dim(A), and e) S E Nis
</equation>
<bodyText confidence="0.997411181818182">
the start predicate name with dim(S) = 1. For all
c E P, it holds that every variable X occurring in
c occurs exactly once in the left-hand side (LHS)
and exactly once in the RHS. A simple RCG G =
(N, T, V, P, S) is a simple k-RCG if for all A E
N, dim(A) &lt; k.
For the definition of the language of a simple
RCG, we borrow the LCFRS definitions here: Let
G = (N, T, V, P, S) be a simple RCG. For every
A E N, we define the yield of A, yield(A) as
follows:
</bodyText>
<equation confidence="0.861957642857143">
a) For every A(a) —* E, α� E yield(A);
b) For every clause
A(α1,... ,αdim(A)) → A1(X11),...,Xdt)(A,))
· · ·Am(X(m) 1 ,...,X(m)
dim(Am))
and all TZ E yield(Ai) for 1 &lt; i &lt; m,
(f(α1), ... , f(αdim(A))) E yield(A) where
f is defined as follows:
(i) f(t) = t for all t E T,
(ii) f(X(i)
j ) = TZ(j) for all 1 &lt; i &lt; m,1 &lt;
j &lt; dim(Ai) and
(iii) f(xy) = f(x)f(y) for all x, y E (T U
V )+.
</equation>
<bodyText confidence="0.939326">
c) Nothing else is in yield(A).
The language is then {w I (w) E yield(S)I.
We are using the algorithm from Maier and
Søgaard (2008) to extract simple RCGs from Ne-
Gra and TIGER. For the tree in Fig. 1, the algo-
rithm produces for instance the following clauses:
</bodyText>
<equation confidence="0.999919428571429">
PRELS(der) → E
ADV(genausogut) → E
. . .
S(X1X2X3X4) → PRELS(X1)VP2(X1,X4) VAFIN(X3)
VP2(X1X2X3,X4X5) → ADV(X1) ADV(X2)
VP2(X3,X4) VMINF(X5)
VP2(X1,X2) → NN(X1) VAINF(X2)
</equation>
<bodyText confidence="0.999961727272727">
We distinguish different usages of the same cat-
egory depending on their numbers of yield com-
ponents. E.g., we distinguish non-terminals VP1,
VP2, ... depending on the arity of the VP. We de-
fine cat(A) for A E N as the category of A, inde-
pendent from the arity, e.g., cat(VP2) =VP.
In terms of simple RCG, synchronous rewrit-
ing means that in a single clause distinct variables
occurring in two different arguments of the LHS
predicate are passed to two different arguments of
the same RHS predicate. We call this recursive
</bodyText>
<figure confidence="0.982988333333333">
gebaut werden k¨onne, der ...
built be could, which ...
der
the
deren
their
von
of
auf
on
Typ
type
Gelande
premises
eigentlich hatte schon gebaut werden
actually had already built be
71
NP
S
VP
VP
VP
PP NP
ob auf dem Gel¨ande der Typ von Abstellanlage ... h¨atte ... gebaut werden sollen, der...
</figure>
<figureCaption confidence="0.999404">
Figure 2: Iterable treebank example for synchronous rewriting
</figureCaption>
<bodyText confidence="0.995553282051282">
if, by a sequence of synchronous rewriting steps,
we can reach the same two arguments of the same
predicate again. Derivations using such cycles of
synchronous rewriting lead exactly to the recursive
synchronous rewriting trees characterized in sec-
tion 2. In the following, we check to which extent
the extracted simple RCG allows for such cycles.
In order to detect synchronous rewriting in a
simple k-RCG G, we build a labeled directed
graph !9 = (VG, EG, l) from the grammar with
VG a set of nodes, EG a set of arcs and l :
VG —* N′ x {0,...,k} x {0,...,k} where N′ =
{cat(A)  |A E N} a labeling function. !9 is con-
structed as follows. For each clause A0(a) —*
A1( 61) ... Am( cQ E P we consider all pairs of
variables X3, Xt for which the following condi-
tions hold: (i) X3 and Xt occur in different argu-
ments i and j of A0, 1 &lt; i &lt; j &lt; dim(A0); and
(ii) X3 and Xt occur in different arguments q and
r of the same occurrence of predicate Ap in the
RHS, 1 &lt; q &lt; r &lt; dim(Ap) and 1 &lt; p &lt; m.
For each of these pairs, two nodes with labels
[cat(A0), i, j] and [cat(Ap), q, r], respectively, are
added to VG (if they do not yet exist, otherwise we
take the already existing nodes) and a directed arc
from the first node to the second node is added to
EG. The intuition is that an arc in !9 represents
one or more clauses from the grammar in which
a gap between two variables in the LHS predicate
is transferred to the same RHS predicate. To de-
tect recursive synchronous rewriting, we then need
to discover all elementary cycles in !9, i.e., all cy-
cles in which no vertex appears twice. In order to
accomplish this task efficiently, we exploit the al-
gorithm presented in Johnson (1975). On a gram-
mar extracted from NeGra (19,100 clauses), the
algorithm yields a graph with 28 nodes containing
206,403 cycles of an average length of 12.86 and
a maximal length of 28.
</bodyText>
<sectionHeader confidence="0.999651" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999994117647059">
The starting point of this paper was the question
whether synchronous rewriting is a necessary fea-
ture of grammer formalisms for modelling natu-
ral languages. In order to answer this question,
we have characterized synchronous rewriting in
terms of properties of treebank trees with crossing
branches. Experiments have shown that recursive
cases of synchronous rewriting occur in treebanks
for German which leads to the conclusion that,
in order to model these data, we need formalisms
that allow for synchronous rewriting. In a second
part, we have extracted a simple RCG from these
treebanks and we have characterized the grammar
properties that are necessary to obtain recursive
synchronous rewriting. We then have investigated
the extent to which a grammar extracted from Ne-
Gra allows for recursive synchronous rewriting.
</bodyText>
<sectionHeader confidence="0.998745" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999830814814815">
Pierre Boullier. 2000. Range concatenation grammars.
In Proceedings ofIWPT.
Harry Bunt, Jan Thesingh, and Ko van der Sloot. 1987.
Discontinuous constituents in trees, rules and pars-
ing. In Proceedings of EACL.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics.
Donald B. Johnson. 1975. Finding all the elementary
circuits of a directed graph. SIAM Journal on Com-
puting.
Marco Kuhlmann. 2007. Dependency Structures and
Lexicalized Grammars. Dissertation, Saarland Uni-
versity.
Wolfgang Maier and Anders Søgaard. 2008. Tree-
banks and mild context-sensitivity. In Proceedings
ofFormal Grammar.
Joakim Nivre. 2006. Inductive Dependency Parsing.
Springer.
Oliver Plaehn. 2004. Computing the most probable
parse for a discontinuous phrase-structure grammar.
In New developments in parsing technology. Kluwer.
H. Seki, T. Matsumura, M. Fujii, and T. Kasami. 1991.
On multiple context-free grammars. Theoretical
Computer Science.
K. Vijay-Shanker, David Weir, and Aravind Joshi.
1987. Characterising structural descriptions used by
various formalisms. In Proceedings ofACL.
</reference>
<page confidence="0.998724">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.886374">
<title confidence="0.999831">Synchronous Rewriting in Treebanks</title>
<author confidence="0.999969">Laura Kallmeyer Wolfgang Maier Giorgio Satta</author>
<affiliation confidence="0.99988">University of T¨ubingen University of T¨ubingen University of Padua</affiliation>
<address confidence="0.986689">T¨ubingen, Germany T¨ubingen, Germany Padova, Italy</address>
<email confidence="0.964541">lk@sfs.uni-tuebingen.dewo.maier@uni-tuebingen.desatta@dei.unipd.it</email>
<abstract confidence="0.995858235294118">Several formalisms have been proposed for modeling trees with discontinuous phrases. Some of these formalisms allow for synchronous rewriting. However, it is unclear whether synchronous rewriting is a necessary feature. This is an important question, since synchronous rewriting greatly increases parsing complexity. We present a characterization of recursive synchronous rewriting in constituent treebanks with discontinuous annotation. An empirical investigation reveals that synchronous rewriting is actually a necessary feature. Furthermore, we transfer this property to grammars extracted from treebanks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pierre Boullier</author>
</authors>
<title>Range concatenation grammars.</title>
<date>2000</date>
<booktitle>In Proceedings ofIWPT.</booktitle>
<contexts>
<context position="1424" citStr="Boullier, 2000" startWordPosition="187" endWordPosition="189">. Furthermore, we transfer this property to grammars extracted from treebanks. 1 Introduction Discontinuous phrases are frequent in natural language, particularly in languages with a relatively free word order. Several formalisms have been proposed in the literature for modeling trees containing such phrases. These include nonprojective dependency grammar (Nivre, 2006), discontinuous phrase structure grammar (DPSG) (Bunt et al., 1987), as well as linear contextfree rewriting systems (LCFRS) (Vijay-Shanker et al., 1987) and the equivalent formalism of simple range concatenation grammar (sRCG) (Boullier, 2000). Kuhlmann (2007) uses LCFRS for non-projective dependency trees. DPSG have been used in Plaehn (2004) for data-driven parsing of treebanks with discontinuous constituent annotation. Maier and Søgaard (2008) extract sRCGs from treebanks with discontinuous constituent structures. Both LCFRS and sRCG can model discontinuities and allow for synchronous rewriting as well. We speak of synchronous rewriting when two or more context-free derivation processes are instantiated in a synchronous way. DPSG, which has also been proposed for modeling discontinuities, does not allow for synchronous rewriting</context>
<context position="9615" citStr="Boullier, 2000" startWordPosition="1590" endWordPosition="1591">y should actually already have been built, which . . . ” As a conclusion from these empirical results, we state that to account for the data we can find in treebanks with discontinuities, i.e., with crossing branches, we need a formalism that can express synchronous rewriting. 3 Synchronous Rewriting in Grammars Extracted from Treebanks In the following, we will use simple RCG (which are equivalent to LCFRS) to model our treebank annotations. We extract simple RCG rewriting rules from NeGra and TIGER and check them for the possibility to generate recursive synchronous rewriting. A simple RCG (Boullier, 2000) is a tuple G = (N, T, V, P, S) where a) N is a finite set of predicate names with an arity function dim: N —* N, b) T and V are disjoint finite sets of terminals and variables, c) P is a finite set of clauses of the form A(α1,... ,αdim(A)) → A1(X11),...,X(1)(A,)) ··· Am(X(m) 1 , . . . , X(m) dim(Am)) for m &gt; 0 where A, A1, ... , Am E N, X(i) j E V for 1 &lt; i &lt; m,1 &lt; j &lt; dim(Ai) and αi E (T U V )∗ for 1 &lt; i &lt; dim(A), and e) S E Nis the start predicate name with dim(S) = 1. For all c E P, it holds that every variable X occurring in c occurs exactly once in the left-hand side (LHS) and exactly on</context>
</contexts>
<marker>Boullier, 2000</marker>
<rawString>Pierre Boullier. 2000. Range concatenation grammars. In Proceedings ofIWPT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harry Bunt</author>
<author>Jan Thesingh</author>
<author>Ko van der Sloot</author>
</authors>
<title>Discontinuous constituents in trees, rules and parsing.</title>
<date>1987</date>
<booktitle>In Proceedings of EACL.</booktitle>
<marker>Bunt, Thesingh, van der Sloot, 1987</marker>
<rawString>Harry Bunt, Jan Thesingh, and Ko van der Sloot. 1987. Discontinuous constituents in trees, rules and parsing. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation. Computational Linguistics.</title>
<date>2007</date>
<contexts>
<context position="3944" citStr="Chiang, 2007" startWordPosition="577" endWordPosition="578"> language L = {anbncndn |n ≥ 1}. Each of the two halves of some w E L can be obtained through a stand-alone context-free derivation, but for w to be in L the two derivations must be synchronized somehow. For certain tasks, synchronous rewriting is a desired property for a formalism. In machine translation, e.g., synchronous 69 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 69–72, Paris, October 2009. c�2009 Association for Computational Linguistics rewriting is extensively used to model the synchronous dependence between the source and target languages (Chiang, 2007). The question we are concerned with in this paper is whether we can find instances of recursive synchronous rewriting in treebanks that show discontinuous phrases. We make the assumption that, if the annotation of a treebank allows to express synchronous rewriting, then all cases of synchronous rewriting are present in the annotation. This means that, on the one hand, there are no cases of synchronous rewriting that the annotator “forgot” to encode. Therefore unrelated cases of parallel iterations in different parts of a tree are taken to be truly unrelated. On the other hand, if synchronous </context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald B Johnson</author>
</authors>
<title>Finding all the elementary circuits of a directed graph.</title>
<date>1975</date>
<journal>SIAM Journal on Computing.</journal>
<contexts>
<context position="13878" citStr="Johnson (1975)" startWordPosition="2441" endWordPosition="2442"> q, r], respectively, are added to VG (if they do not yet exist, otherwise we take the already existing nodes) and a directed arc from the first node to the second node is added to EG. The intuition is that an arc in !9 represents one or more clauses from the grammar in which a gap between two variables in the LHS predicate is transferred to the same RHS predicate. To detect recursive synchronous rewriting, we then need to discover all elementary cycles in !9, i.e., all cycles in which no vertex appears twice. In order to accomplish this task efficiently, we exploit the algorithm presented in Johnson (1975). On a grammar extracted from NeGra (19,100 clauses), the algorithm yields a graph with 28 nodes containing 206,403 cycles of an average length of 12.86 and a maximal length of 28. 4 Conclusion The starting point of this paper was the question whether synchronous rewriting is a necessary feature of grammer formalisms for modelling natural languages. In order to answer this question, we have characterized synchronous rewriting in terms of properties of treebank trees with crossing branches. Experiments have shown that recursive cases of synchronous rewriting occur in treebanks for German which </context>
</contexts>
<marker>Johnson, 1975</marker>
<rawString>Donald B. Johnson. 1975. Finding all the elementary circuits of a directed graph. SIAM Journal on Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
</authors>
<title>Dependency Structures and Lexicalized Grammars. Dissertation,</title>
<date>2007</date>
<institution>Saarland University.</institution>
<contexts>
<context position="1441" citStr="Kuhlmann (2007)" startWordPosition="190" endWordPosition="191"> transfer this property to grammars extracted from treebanks. 1 Introduction Discontinuous phrases are frequent in natural language, particularly in languages with a relatively free word order. Several formalisms have been proposed in the literature for modeling trees containing such phrases. These include nonprojective dependency grammar (Nivre, 2006), discontinuous phrase structure grammar (DPSG) (Bunt et al., 1987), as well as linear contextfree rewriting systems (LCFRS) (Vijay-Shanker et al., 1987) and the equivalent formalism of simple range concatenation grammar (sRCG) (Boullier, 2000). Kuhlmann (2007) uses LCFRS for non-projective dependency trees. DPSG have been used in Plaehn (2004) for data-driven parsing of treebanks with discontinuous constituent annotation. Maier and Søgaard (2008) extract sRCGs from treebanks with discontinuous constituent structures. Both LCFRS and sRCG can model discontinuities and allow for synchronous rewriting as well. We speak of synchronous rewriting when two or more context-free derivation processes are instantiated in a synchronous way. DPSG, which has also been proposed for modeling discontinuities, does not allow for synchronous rewriting because the diff</context>
</contexts>
<marker>Kuhlmann, 2007</marker>
<rawString>Marco Kuhlmann. 2007. Dependency Structures and Lexicalized Grammars. Dissertation, Saarland University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Maier</author>
<author>Anders Søgaard</author>
</authors>
<title>Treebanks and mild context-sensitivity.</title>
<date>2008</date>
<booktitle>In Proceedings ofFormal Grammar.</booktitle>
<contexts>
<context position="1631" citStr="Maier and Søgaard (2008)" startWordPosition="215" endWordPosition="218"> word order. Several formalisms have been proposed in the literature for modeling trees containing such phrases. These include nonprojective dependency grammar (Nivre, 2006), discontinuous phrase structure grammar (DPSG) (Bunt et al., 1987), as well as linear contextfree rewriting systems (LCFRS) (Vijay-Shanker et al., 1987) and the equivalent formalism of simple range concatenation grammar (sRCG) (Boullier, 2000). Kuhlmann (2007) uses LCFRS for non-projective dependency trees. DPSG have been used in Plaehn (2004) for data-driven parsing of treebanks with discontinuous constituent annotation. Maier and Søgaard (2008) extract sRCGs from treebanks with discontinuous constituent structures. Both LCFRS and sRCG can model discontinuities and allow for synchronous rewriting as well. We speak of synchronous rewriting when two or more context-free derivation processes are instantiated in a synchronous way. DPSG, which has also been proposed for modeling discontinuities, does not allow for synchronous rewriting because the different discontinuous parts of the yield of a non-terminal are treated locally, i.e., their derivations are independent from each other. So far, synchronous rewriting has not been empirically </context>
<context position="11018" citStr="Maier and Søgaard (2008)" startWordPosition="1910" endWordPosition="1913"> here: Let G = (N, T, V, P, S) be a simple RCG. For every A E N, we define the yield of A, yield(A) as follows: a) For every A(a) —* E, α� E yield(A); b) For every clause A(α1,... ,αdim(A)) → A1(X11),...,Xdt)(A,)) · · ·Am(X(m) 1 ,...,X(m) dim(Am)) and all TZ E yield(Ai) for 1 &lt; i &lt; m, (f(α1), ... , f(αdim(A))) E yield(A) where f is defined as follows: (i) f(t) = t for all t E T, (ii) f(X(i) j ) = TZ(j) for all 1 &lt; i &lt; m,1 &lt; j &lt; dim(Ai) and (iii) f(xy) = f(x)f(y) for all x, y E (T U V )+. c) Nothing else is in yield(A). The language is then {w I (w) E yield(S)I. We are using the algorithm from Maier and Søgaard (2008) to extract simple RCGs from NeGra and TIGER. For the tree in Fig. 1, the algorithm produces for instance the following clauses: PRELS(der) → E ADV(genausogut) → E . . . S(X1X2X3X4) → PRELS(X1)VP2(X1,X4) VAFIN(X3) VP2(X1X2X3,X4X5) → ADV(X1) ADV(X2) VP2(X3,X4) VMINF(X5) VP2(X1,X2) → NN(X1) VAINF(X2) We distinguish different usages of the same category depending on their numbers of yield components. E.g., we distinguish non-terminals VP1, VP2, ... depending on the arity of the VP. We define cat(A) for A E N as the category of A, independent from the arity, e.g., cat(VP2) =VP. In terms of simple </context>
</contexts>
<marker>Maier, Søgaard, 2008</marker>
<rawString>Wolfgang Maier and Anders Søgaard. 2008. Treebanks and mild context-sensitivity. In Proceedings ofFormal Grammar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Inductive Dependency Parsing.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<contexts>
<context position="1180" citStr="Nivre, 2006" startWordPosition="152" endWordPosition="153">reases parsing complexity. We present a characterization of recursive synchronous rewriting in constituent treebanks with discontinuous annotation. An empirical investigation reveals that synchronous rewriting is actually a necessary feature. Furthermore, we transfer this property to grammars extracted from treebanks. 1 Introduction Discontinuous phrases are frequent in natural language, particularly in languages with a relatively free word order. Several formalisms have been proposed in the literature for modeling trees containing such phrases. These include nonprojective dependency grammar (Nivre, 2006), discontinuous phrase structure grammar (DPSG) (Bunt et al., 1987), as well as linear contextfree rewriting systems (LCFRS) (Vijay-Shanker et al., 1987) and the equivalent formalism of simple range concatenation grammar (sRCG) (Boullier, 2000). Kuhlmann (2007) uses LCFRS for non-projective dependency trees. DPSG have been used in Plaehn (2004) for data-driven parsing of treebanks with discontinuous constituent annotation. Maier and Søgaard (2008) extract sRCGs from treebanks with discontinuous constituent structures. Both LCFRS and sRCG can model discontinuities and allow for synchronous rewr</context>
</contexts>
<marker>Nivre, 2006</marker>
<rawString>Joakim Nivre. 2006. Inductive Dependency Parsing. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Plaehn</author>
</authors>
<title>Computing the most probable parse for a discontinuous phrase-structure grammar. In New developments in parsing technology.</title>
<date>2004</date>
<publisher>Kluwer.</publisher>
<contexts>
<context position="1526" citStr="Plaehn (2004)" startWordPosition="203" endWordPosition="204">ous phrases are frequent in natural language, particularly in languages with a relatively free word order. Several formalisms have been proposed in the literature for modeling trees containing such phrases. These include nonprojective dependency grammar (Nivre, 2006), discontinuous phrase structure grammar (DPSG) (Bunt et al., 1987), as well as linear contextfree rewriting systems (LCFRS) (Vijay-Shanker et al., 1987) and the equivalent formalism of simple range concatenation grammar (sRCG) (Boullier, 2000). Kuhlmann (2007) uses LCFRS for non-projective dependency trees. DPSG have been used in Plaehn (2004) for data-driven parsing of treebanks with discontinuous constituent annotation. Maier and Søgaard (2008) extract sRCGs from treebanks with discontinuous constituent structures. Both LCFRS and sRCG can model discontinuities and allow for synchronous rewriting as well. We speak of synchronous rewriting when two or more context-free derivation processes are instantiated in a synchronous way. DPSG, which has also been proposed for modeling discontinuities, does not allow for synchronous rewriting because the different discontinuous parts of the yield of a non-terminal are treated locally, i.e., t</context>
</contexts>
<marker>Plaehn, 2004</marker>
<rawString>Oliver Plaehn. 2004. Computing the most probable parse for a discontinuous phrase-structure grammar. In New developments in parsing technology. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Seki</author>
<author>T Matsumura</author>
<author>M Fujii</author>
<author>T Kasami</author>
</authors>
<title>On multiple context-free grammars. Theoretical Computer Science.</title>
<date>1991</date>
<contexts>
<context position="2796" citStr="Seki et al., 1991" startWordPosition="395" endWordPosition="398"> far, synchronous rewriting has not been empirically motivated by linguistic data from treebanks. In this paper, we fill this gap by investigating the existence of structures indicating synchronous rewriting in treebanks with discontinuous annotations. The question of whether we can find evidence for synchronous rewriting has consequences for the complexity of parsing. In fact, parsing with synchronous formalisms can be carried out in time polynomial in the length of the input string, with a polynomial degree depending on the maximum number of synchronous branches one can find in derivations (Seki et al., 1991). In this paper, we characterize synchronous rewriting as a property of trees with crossing branches and in an empirical evaluation, we confirm that treebanks do contain recursive synchronous rewriting which can be linguistically motivated. Furthermore, we show how this characterization transfers to the simple RCGs describing these trees. 2 Synchronous Rewriting Trees in German treebanks By synchronous rewriting we indicate the synchronous instantiation of two or more context-free derivation processes. As an example, consider the language L = {anbncndn |n ≥ 1}. Each of the two halves of some w</context>
</contexts>
<marker>Seki, Matsumura, Fujii, Kasami, 1991</marker>
<rawString>H. Seki, T. Matsumura, M. Fujii, and T. Kasami. 1991. On multiple context-free grammars. Theoretical Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David Weir</author>
<author>Aravind Joshi</author>
</authors>
<title>Characterising structural descriptions used by various formalisms.</title>
<date>1987</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="1333" citStr="Vijay-Shanker et al., 1987" startWordPosition="172" endWordPosition="175">notation. An empirical investigation reveals that synchronous rewriting is actually a necessary feature. Furthermore, we transfer this property to grammars extracted from treebanks. 1 Introduction Discontinuous phrases are frequent in natural language, particularly in languages with a relatively free word order. Several formalisms have been proposed in the literature for modeling trees containing such phrases. These include nonprojective dependency grammar (Nivre, 2006), discontinuous phrase structure grammar (DPSG) (Bunt et al., 1987), as well as linear contextfree rewriting systems (LCFRS) (Vijay-Shanker et al., 1987) and the equivalent formalism of simple range concatenation grammar (sRCG) (Boullier, 2000). Kuhlmann (2007) uses LCFRS for non-projective dependency trees. DPSG have been used in Plaehn (2004) for data-driven parsing of treebanks with discontinuous constituent annotation. Maier and Søgaard (2008) extract sRCGs from treebanks with discontinuous constituent structures. Both LCFRS and sRCG can model discontinuities and allow for synchronous rewriting as well. We speak of synchronous rewriting when two or more context-free derivation processes are instantiated in a synchronous way. DPSG, which ha</context>
</contexts>
<marker>Vijay-Shanker, Weir, Joshi, 1987</marker>
<rawString>K. Vijay-Shanker, David Weir, and Aravind Joshi. 1987. Characterising structural descriptions used by various formalisms. In Proceedings ofACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>