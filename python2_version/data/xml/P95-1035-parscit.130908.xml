<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000176">
<title confidence="0.988312">
An Efficient Generation Algorithm for Lexicalist MT
</title>
<author confidence="0.939432">
Victor Poznariski, John L. Beaven &amp; Pete Whitelock *
</author>
<affiliation confidence="0.8300715">
SHARP Laboratories of Europe Ltd.
Oxford Science Park, Oxford 0X4 4GA
</affiliation>
<address confidence="0.613537">
United Kingdom
</address>
<email confidence="0.785652">
{vp,j1b,pete}©sharp.co.uk
</email>
<sectionHeader confidence="0.994305" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999959222222222">
The lexicalist approach to Machine Trans-
lation offers significant advantages in
the development of linguistic descriptions.
However, the Shake-and-Bake generation
algorithm of (Whitelock, 1992) is NP-
complete. We present a polynomial time
algorithm for lexicalist MT generation pro-
vided that sufficient information can be
transferred to ensure more determinism.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999460294117647">
Lexicalist approaches to MT, particularly those in-
corporating the technique of Shake-and-Bake gen-
eration (Beaven, 1992a; Beaven, 1992b; Whitelock,
1994), combine the linguistic advantages of transfer
(Arnold et al., 1988; Allegranza et al., 1991) and
interlingual (Nirenburg et al., 1992; Dorr, 1993) ap-
proaches. Unfortunately, the generation algorithms
described to date have been intractable. In this pa-
per, we describe an alternative generation compo-
nent which has polynomial time complexity.
Shake-and-Bake translation assumes a source
grammar, a target grammar and a bilingual dictio-
nary which relates translationally equivalent sets of
lexical signs, carrying across the semantic dependen-
cies established by the source language analysis stage
into the target language generation stage.
The translation process consists of three phases:
</bodyText>
<listItem confidence="0.996701142857143">
1. A parsing phase, which outputs a multiset,
or bag, of source language signs instantiated
with sufficiently rich linguistic information es-
tablished by the parse to ensure adequate trans-
lations.
2. A lexical-semantic transfer phase which em-
ploys the bilingual dictionary to map the bag
</listItem>
<bodyText confidence="0.921603857142857">
*We wish to thank our colleagues Kerima Benkerimi,
David Elworthy, Peter Gibbins, Ian Johnson, Andrew
Kay and Antonio Sanfilippo at SLE, and our anonymous
reviewers for useful feedback and discussions on the re-
search reported here and on earlier drafts of this paper.
of instantiated source signs onto a bag of target
language signs.
</bodyText>
<listItem confidence="0.986001666666667">
3. A generation phase which imposes an order on
the bag of target signs which is guaranteed
grammatical according to the monolingual tar-
get grammar. This ordering must respect the
linguistic constraints which have been trans-
ferred into the target signs.
</listItem>
<bodyText confidence="0.998729914285714">
The Shake-and-Bake generation algorithm of
(Whitelock, 1992) combines target language signs
using the technique known as generate-and-test. In
effect, an arbitrary permutation of signs is input to a
shift-reduce parser which tests them for grammatical
well-formedness. If they are well-formed, the system
halts indicating success. If not, another permutation
is tried and the process repeated. The complexity of
this algorithm is 0(n!) because all permutations (n!
for an input of size n) may have to be explored to
find the correct answer, and indeed must be explored
in order to verify that there is no answer.
Proponents of the Shake-and-Bake approach have
employed various techniques to improve generation
efficiency. For example, (Beaven, 1992a) employs
a chart to avoid recalculating the same combina-
tions of signs more than once during testing, and
(Popowich, 1994) proposes a more general technique
for storing which rule applications have been at-
tempted; (Brew, 1992) avoids certain pathological
cases by employing global constraints on the solu-
tion space; researchers such as (Brown et al., 1990)
and (Chen and Lee, 1994) provide a system for bag
generation that is heuristically guided by probabil-
ities. However, none of these approaches is guar-
anteed to avoid protracted search times if an exact
answer is required, because bag generation is NP-
complete (Brew, 1992).
Our novel generation algorithm has polynomial
complexity (0(n4)). The reduction in theoretical
complexity is achieved by placing constraints on
the power of the target grammar when operating
on instantiated signs, and by using a more restric-
tive data structure than a bag, which we call a
target language normalised commutative bracketing
</bodyText>
<page confidence="0.995175">
261
</page>
<bodyText confidence="0.9998095">
(TNCB). A TNCB records dominance information
from derivations and is amenable to incremental up-
dates. This allows us to employ a greedy algorithm
to refine the structure progressively until either a
target constituent is found and generation has suc-
ceeded or no more changes can be made and gener-
ation has failed.
In the following sections, we will sketch the basic
algorithm, consider how to provide it with an initial
guess, and provide an informal proof of its efficiency.
</bodyText>
<sectionHeader confidence="0.979101" genericHeader="method">
2 A Greedy Incremental Generation
Algorithm
</sectionHeader>
<bodyText confidence="0.9995325">
We begin by describing the fundamentals of a greedy
incremental generation algorithm. The crucial data
structure that it employs is the TNCB. We give some
definitions, state some key assumptions about suit-
able TNCBs for generation, and then describe the
algorithm itself.
</bodyText>
<subsectionHeader confidence="0.964905">
2.1 TNCBs
</subsectionHeader>
<bodyText confidence="0.999951142857143">
We assume a sign-based grammar with binary rules,
each of which may be used to combine two signs
by unifying them with the daughter categories and
returning the mother. Combination is the commuta-
tive equivalent of rule application; the linear order-
ing of the daughters that leads to successful rule ap-
plication determines the orthography of the mother.
Whitelock&apos;s Shake-and-Bake generation algorithm
attempts to arrange the bag of target signs until
a grammatical ordering (an ordering which allows
all of the signs to combine to yield a single sign) is
found. However, the target derivation information
itself is not used to assist the algorithm. Even in
(Beaven, 1992a), the derivation information is used
simply to cache previous results to avoid exact re-
computation at a later stage, not to improve on pre-
vious guesses. The reason why we believe such im-
provement is possible is that, given adequate infor-
mation from the previous stages, two target signs
cannot combine by accident; they must do so be-
cause the underlying semantics within the signs li-
censes it.
If the linguistic data that two signs contain allows
them to combine, it is because they are providing
a semantics which might later become more spec-
ified. For example, consider the bag of signs that
have been derived through the Shake-and-Bake pro-
cess which represent the phrase:
</bodyText>
<listItem confidence="0.80841">
(1) The big brown dog
</listItem>
<bodyText confidence="0.775918333333333">
Now, since the determiner and adjectives all mod-
ify the same noun, most grammars will allow us to
construct the phrases:
</bodyText>
<listItem confidence="0.987173333333333">
(2) The dog
(3) The big dog
(4) The brown dog
</listItem>
<bodyText confidence="0.9988445">
as well as the &apos;correct&apos; one. Generation will fail if
all signs in the bag are not eventually incorporated
in the final result, but in the naive algorithm, the
intervening computation may be intractable.
In the algorithm presented here, we start from ob-
servation that the phrases (2) to (4) are not incorrect
semantically; they are simply under-specifications of
(1). We take advantage of this by recording the
constituents that have combined within the TNCB,
which is designed to allow further constituents to be
incorporated with minimal recomputation.
A TNCB is composed of a sign, and a history of
how it was derived from its children. The structure
is essentially a binary derivation tree whose children
are unordered. Concretely, it is either NIL, or a
triple:
</bodyText>
<equation confidence="0.602878">
TNCB • NIL I Value x TNCB x TNCB
Value • Sign I
INCONSISTENT I
UNDETERMINED
</equation>
<bodyText confidence="0.943516444444444">
The second and third items of the TNCB triple
are the child TNCBs. The value of a TNCB is
the sign that is formed from the combination of its
children, or INCONSISTENT, representing the fact
that they cannot grammatically combine, or UN-
DETERMINED, i.e. it has not yet been established
whether the signs combine.
Undetermined TNCBs are commutative, e.g. they
do not distinguish between the structures shown in
</bodyText>
<figureCaption confidence="0.807066">
Figure 1.
</figureCaption>
<figure confidence="0.899982">
S V V OS
</figure>
<figureCaption confidence="0.999803">
Figure 1: Equivalent TNCBs
</figureCaption>
<bodyText confidence="0.9941585">
In section 3 we will see that this property is im-
portant when starting up the generation process.
Let us introduce some terminology.
A TNCB is
</bodyText>
<listItem confidence="0.997964222222222">
• well-formed if its value is a sign,
• ill-formed if its value is INCONSISTENT,
• undetermined (and its value is UNDETER-
MINED) if it has not been demonstrated
whether it is well-formed or ill-formed.
• maximal if it is well-formed and its parent (if it
has one) is ill-formed. In other words, a maxi-
mal TNCB is a largest well-formed component
of a TNCB.
</listItem>
<page confidence="0.989088">
262
</page>
<bodyText confidence="0.998018882352941">
Since TNCBs are tree-like structures, if a
TNCB is undetermined or ill-formed then so are
all of its ancestors (the TNCBs that contain it).
We define five operations on a TNCB. The first
three are used to define the fourth transformation
(move) which improves ill-formed TNCBs. The fifth
is used to establish the well-formedness of undeter-
mined nodes. In the diagrams, we use a cross to
represent ill-formed nodes and a black circle to rep-
resent undetermined ones.
Deletion: A maximal TNCB can be deleted
from its current position. The structure above
it must be adjusted in order to maintain binary
branching. In figure 2, we see that when node
4 is deleted, so is its parent node 3. The new
node 6, representing the combination of 2 and
5, is marked undetermined.
</bodyText>
<figureCaption confidence="0.984067">
Figure 2: 4 is deleted, raising 5
</figureCaption>
<bodyText confidence="0.998142875">
Conjunction: A maximal TNCB can be con-
joined with another maximal TNCB if they may
be combined by rule. In figure 3, it can be seen
how the maximal TNCB composed of nodes 1,
2, and 3 is conjoined with the maximal TNCB
composed of nodes 4, 5 and 6 giving the TNCB
made up of nodes 1 to 7. The new node, 7, is
well-formed.
</bodyText>
<figure confidence="0.621048">
+
</figure>
<figureCaption confidence="0.995717">
Figure 4: 1 is adjoined next to 6 inside 4
</figureCaption>
<bodyText confidence="0.995865857142857">
Movement: This is a combination of a deletion
with a subsequent conjunction or adjunction. In
figure 5, we illustrate a move via conjunction.
In the left-hand figure, we assume we wish to
move the maximal TNCB 4 next to the maximal
TNCB 7. This first involves deleting TNCB 4
(noting it), and raising node 3 to replace node
2. We then introduce node 8 above node 7, and
make both nodes 7 and 4 its children. Note
that during deletion, we remove a surplus node
(node 2 in this case) and during conjunction or
adjunction we introduce a new one (node 8 in
this case) thus maintaining the same number of
nodes in the tree.
</bodyText>
<figureCaption confidence="0.597181333333333">
Figure 5: A conjoining move from 4 to 7
1 4 Evaluation: After a movement, the TNCB
A±A..._.. is undetermined as demonstrated in figure 5.
2 3 5 6 The signs of the affected parts must be recal-
culated by combining the recursively evaluated
child TNCBs.
</figureCaption>
<subsectionHeader confidence="0.999429">
2.2 Suitable Grammars
</subsectionHeader>
<bodyText confidence="0.997400909090909">
The Shake-and-Bake system of (Whitelock, 1992)
employs a bag generation algorithm because it is as-
sumed that the input to the generator is no more
than a collection of instantiated signs. Full-scale bag
generation is not necessary because sufficient infor-
mation can be transferred from the source language
to severely constrain the subsequent search during
generation.
The two properties required of TNCBs (and hence
the target grammars with instantiated lexical signs)
are:
</bodyText>
<listItem confidence="0.874562">
1. Precedence Monotonicity. The order of the
</listItem>
<figureCaption confidence="0.997272">
Figure 3: 1 is conjoined with 4 giving 7
</figureCaption>
<bodyText confidence="0.9990332">
Adjunction: A maximal TNCB can be in-
serted inside a maximal TNCB, i.e. conjoined
with a non-maximal TNCB, where the combina-
tion is licensed by rule. In figure 4, the TNCB
composed of nodes 1, 2, and 3 is inserted in-
side the TNCB composed of nodes 4, 5 and 6.
All nodes (only 8 in figure 4) which dominate
the node corresponding to the new combination
(node 7) must be marked undetermined — such
nodes are said to be disrupted.
</bodyText>
<page confidence="0.992126">
263
</page>
<bodyText confidence="0.999789">
orthographies of two combining signs in the or-
thography of the result must be determinate —
it must not depend on any subsequent combi-
nation that the result may undergo. This con-
straint says that if one constituent fails to com-
bine with another, no permutation of the ele-
ments making up either would render the com-
bination possible. This allows bottom-up eval-
uation to occur in linear time. In practice, this
restriction requires that sufficiently rich infor-
mation be transferred from the previous trans-
lation stages to ensure that sign combination is
deterministic.
</bodyText>
<listItem confidence="0.773562">
2. Dominance Monotonicity. If a maximal
</listItem>
<bodyText confidence="0.963474">
TNCB is adjoined at the highest possible place
inside another TNCB, the result will be well-
formed after it is re-evaluated. Adjunction is
only attempted if conjunction fails (in fact con-
junction is merely a special case of adjunction
in which no nodes are disrupted); an adjunction
which disrupts i nodes is attempted before one
which disrupts i 1 nodes. Dominance mono-
tonicity merely requires all nodes that are dis-
rupted under this top-down control regime to
be well-formed when re-evaluated. We will see
that this will ensure the termination of the gen-
eration algorithm within n — 1 steps, where n is
the number of lexical signs input to the process.
We are currently investigating the mathematical
characterisation of grammars and instantiated signs
that obey these constraints. So far, we have not
found these restrictions particularly problematic.
</bodyText>
<subsectionHeader confidence="0.999157">
2.3 The Generation Algorithm
</subsectionHeader>
<bodyText confidence="0.999952875">
The generator cycles through two phases: a test
phase and a rewrite phase. Imagine a bag of signs,
corresponding to &amp;quot;the big brown dog barked&amp;quot;, has
been passed to the generation phase. The first step
in the generation process is to convert it into some
arbitrary TNCB structure, say the one in figure 6.
In order to verify whether this structure is valid,
we evaluate the TNCB. This is the test phase. If
the TNCB evaluates successfully, the orthography
of its value is the desired result. If not, we enter the
rewrite phase.
If we were continuing in the spirit of the origi-
nal Shake-and-Bake generation process, we would
now form some arbitrary mutation of the TNCB and
retest, repeating this test-rewrite cycle until we ei-
ther found a well-formed TNCB or failed. However,
this would also be intractable due to the undirected-
ness of the search through the vast number of possi-
bilities. Given the added derivation information con-
tained within TNCBs and the properties mentioned
above, we can direct this search by incrementally
improving on previously evaluated results.
We enter the rewrite phase, then, with an ill-
formed TNCB. Each move operation must improve
</bodyText>
<note confidence="0.666999">
PST dog bark t e brown big
</note>
<figureCaption confidence="0.937452">
Figure 6: An arbitrary right-branching TNCB struc-
ture
</figureCaption>
<bodyText confidence="0.984361583333333">
it. Let us see why this is so.
The move operation maintains the same number
of nodes in the tree. The deletion of a maximal
TNCB removes two ill-formed nodes (figure 2). At
the deletion site, a new undetermined node is cre-
ated, which may or may not be ill-formed. At the
destination site of the movement (whether conjunc-
tion or adjunction), a new well-formed node is cre-
ated.
The ancestors of the new well-formed node will
be at least as well-formed as they were prior to the
movement. We can verify this by case:
</bodyText>
<listItem confidence="0.964033642857143">
1. When two maximal TNCBs are conjoined,
nodes dominating the new node, which were
previously ill-formed, become undetermined.
When re-evaluated, they may remain ill-formed
or some may now become well-formed.
2. When we adjoin a maximal TNCB within an-
other TNCB, nodes dominating the new well-
formed node are disrupted. By dominance
monotonicity, all nodes which were disrupted
by the adjunction must become well-formed af-
ter re-evaluation. And nodes dominating the
maximal disrupted node, which were previously
ill-formed, may become well-formed after re-
evaluation.
</listItem>
<bodyText confidence="0.999939789473684">
We thus see that rewriting and re-evaluating must
improve the TNCB.
Let us further consider the contrived worst-case
starting point provided in figure 6. After the test
phase, we discover that every single interior node is
ill-formed. We then scan the TNCB, say top-down
from left to right, looking for a maximal TNCB to
move. In this case, the first move will be PAST to
bark, by conjunction (figure 7).
Once again, the test phase fails to provide a well-
formed TNCB, so we repeat the rewrite phase, this
time finding dog to conjoin with the (figure 8 shows
the state just after the second pass through the test
phase).
After further testing, we again re-enter the rewrite
phase and this time note that brown can be inserted
in the maximal TNCB the dog barked adjoined with
dog (figure 9). Note how, after combining dog and
the, the parent sign reflects the correct orthography
</bodyText>
<page confidence="0.995193">
264
</page>
<figure confidence="0.606375">
PAST bark dog brown he 1 bi-g,
</figure>
<figureCaption confidence="0.973251166666667">
Figure 7: The initial guess
Figure 8: The TNCB after &amp;quot;PAST&amp;quot; is moved to
&amp;quot;bark&amp;quot;
even though they did not have the correct linear
precedence.
Figure 9: The TNCB after &amp;quot;dog&amp;quot; is moved to &amp;quot;the&amp;quot;
</figureCaption>
<bodyText confidence="0.998961866666667">
After finding that big may not be conjoined with
the brown dog, we try to adjoin it within the latter.
Since it will combine with brown dog, no adjunction
to a lower TNCB is attempted.
The final result is the TNCB in figure 11, whose
orthography is &amp;quot;the big brown dog barked&amp;quot;.
We thus see that during generation, we formed a
basic constituent, the dog, and incrementally refined
it by adjoining the modifiers in place. At the heart of
this approach is that, once well-formed, constituents
can only grow; they can never be dismantled.
Even if generation ultimately fails, maximal well-
formed fragments will have been built; the latter
may be presented to the user, allowing graceful
degradation of output quality.
</bodyText>
<figureCaption confidence="0.876679">
Figure 10: The TNCB after &amp;quot;brown&amp;quot; is moved to
&amp;quot;dog&amp;quot;
the big brown dog barked
Figure 11: The final TNCB after &amp;quot;big&amp;quot; is moved to
&amp;quot;brown dog&amp;quot;
</figureCaption>
<sectionHeader confidence="0.959128" genericHeader="method">
3 Initialising the Generator
</sectionHeader>
<bodyText confidence="0.99872825">
Considering the algorithm described above, we note
that the number of rewrites necessary to repair the
initial guess is no more than the number of ill-formed
TNCBs. This can never exceed the number of inte-
rior nodes of the TNCB formed from n lexical signs
(i.e. n —2). Consequently, the better formed the ini-
tial TNCB used by the generator, the fewer the num-
ber of rewrites required to complete generation. In
the last section, we deliberately illustrated an initial
guess which was as bad as possible. In this section,
we consider a heuristic for producing a motivated
guess for the initial TNCB.
Consider the TNCBs in figure 1. If we interpret
the S, 0 and V as Subject, Object and Verb we can
observe an equivalence between the structures with
the bracketings: (S (V 0)), (S (0 V)), ((V 0) 5),
and ((0 V) S). The implication of this equivalence
is that if, say, we are translating into a (S (V 0))
language from a head-final language and have iso-
morphic dominance structures between the source
and target parses, then simply mirroring the source
parse structure in the initial target TNCB will pro-
vide a correct initial guess. For example, the English
sentence (5):
</bodyText>
<figure confidence="0.980618722222222">
(5) the book is red
r - -
I dgi
L _ _ - -I
PAST bark
brown big
bar
PA T bark
r - - -1
the I brown! big
L _ _ _ J
the
b
the bi brown dog
big b •wn og
brow dog
PA T bark dog brown big
bar
</figure>
<page confidence="0.991197">
265
</page>
<bodyText confidence="0.954548">
has a corresponding Japanese equivalent (6):
</bodyText>
<listItem confidence="0.6915345">
(6) ((hon wa) (akai desu))
((book TOP) (red is))
</listItem>
<bodyText confidence="0.999914090909091">
If we mirror the Japanese bracketing structure in
English to form the initial TNCB, we obtain: ((book
the) (red is)). This will produce the correct answer
in the test phase of generation without the need to
rewrite at all.
Even if there is not an exact isomorphism between
the source and target commutative bracketings, the
first guess is still reasonable as long as the majority
of child commutative bracketings in the target lan-
guage are isomorphic with their equivalents in the
source language. Consider the French sentence:
</bodyText>
<listItem confidence="0.995772">
(7) ((le ((grand chien) brun)) aboya)
(8) ((the ((big dog) brown)) barked)
</listItem>
<bodyText confidence="0.999921">
The TNCB implied by the bracketing in (8) is
equivalent to that in figure 10 and requires just one
rewrite in order to make it well-formed. We thus
see how the TNCBs can mirror the dominance in-
formation in the source language parse in order to
furnish the generator with a good initial guess. On
the other hand, no matter how the SL and TL struc-
tures differ, the algorithm will still operate correctly
with polynomial complexity. Structural transfer can
be incorporated to improve the efficiency of genera-
tion, but it is never necessary for correctness or even
tractability.
</bodyText>
<sectionHeader confidence="0.992822" genericHeader="method">
4 The Complexity of the Generator
</sectionHeader>
<bodyText confidence="0.999973389830509">
The theoretical complexity of the generator is 0(n4),
where n is the size of the input. We give an informal
argument for this. The complexity of the test phase
is the number of evaluations that have to be made.
Each node must be tested no more than twice in the
worst case (due to precedence monotonicity), as one
might have to try to combine its children in either
direction according to the grammar rules. There are
always exactly n — 1 non-leaf nodes, so the complex-
ity of the test phase is 0(n). The complexity of
the rewrite phase is that of locating the two TNCBs
to be combined. In the worst case, we can imagine
picking an arbitrary child TNCB (0(n)) and then
trying to find another one with which it combines
(0(n)). The complexity of this phase is therefore
the product of the picking and combining complex-
ities, i.e. 0(n2). The combined complexity of the
test-rewrite cycle is thus 0(n3). Now, in section 3,
we argued that no more than n — 1 rewrites would
ever be necessary, thus the overall complexity of gen-
eration (even when no solution is found) is 0(n4).
Average case complexity is dependent on the qual-
ity of the first guess, how rapidly the TNCB struc-
ture is actually improved, and to what extent the
TNCB must be re-evaluated after rewriting. In the
SLEMaT system (Poznariski et al., 1993), we have
tried to form a good initial guess by mirroring the
source structure in the target TNCB, and allowing
some local structural modifications in the bilingual
equivalences.
Structural transfer operations only affect the ef-
ficiency and not the functionality of generation.
Transfer specifications may be incrementally refined
and empirically tested for efficiency. Since complete
specification of transfer operations is not required
for correct generation of grammatical target text,
the version of Shake-and-Bake translation presented
here maintains its advantage over traditional trans-
fer models, in this respect.
The monotonicity constraints, on the other hand,
might constitute a dilution of the Shake-and-Bake
ideal of independent grammars. For instance, prece-
dence monotonicity requires that the status of a
clause (strictly, its lexical head) as main or sub-
ordinate has to be transferred into German. It is
not that the transfer of information per se compro-
mises the ideal — such information must often ap-
pear in transfer entries to avoid grammatical but
incorrect translation (e.g. a great man translated
as un hornme grand). The problem is justifying
the main/subordinate distinction in every language
that we might wish to translate into German. This
distinction can be justified monolingually for the
other languages that we treat (English, French, and
Japanese). Whether the constraints will ultimately
require monolingual grammars to be enriched with
entirely unmotivated features will only become clear
as translation coverage is extended and new lan-
guage pairs are added.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999982642857143">
We have presented a polynomial complexity gener-
ation algorithm which can form part of any Shake-
and-Bake style MT system with suitable grammars
and information transfer. The transfer module is
free to attempt structural transfer in order to pro-
duce the best possible first guess. We tested a
TNCB-based generator in the SLEMaT MT sys-
tem with the pathological cases described in (Brew,
1992) against Whitelock&apos;s original generation algo-
rithm, and have obtained speed improvements of
several orders of magnitude. Somewhat more sur-
prisingly, even for short sentences which were not
problematic for Whitelock&apos;s system, the generation
component has performed consistently better.
</bodyText>
<sectionHeader confidence="0.999645" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998756833333333">
V. Allegranza, P. Bennett, J. Durand, F. van Eynde,
L. Humphreys, P. Schmidt, and E. Steiner. 1991.
Linguistics for Machine Translation: The Eurotra
Linguistic Specifications. In C. Copeland, J. Du-
rand, S. Krauwer, and B. Maegaard, editors, The
Eurotra Formal Specifications. Studies in Machine
</reference>
<page confidence="0.978728">
266
</page>
<reference confidence="0.998206818181818">
Translation and Natural Language Processing 2,
pages 15-124. Office for Official Publications of
the European Communities.
D. Arnold, S. Krauwer, L. des Tombe, and L. Sadler.
1988. &apos;Relaxed&apos; Compositionality in Machine
Translation. In Second International Conference
on Theoretical and Methodological Issues in Ma-
chine Translation of Natural Languages, Carnegie
Mellon Univ, Pittsburgh.
John L. Beaven. 1992a. Lexicalist Unification-based
Machine Translation. Ph.D. thesis, University of
Edinburgh, Edinburgh.
John L. Beaven. 1992b. Shake-and-Bake Machine
Translation. In Proceedings of COLING 92, pages
602-609, Nantes, France.
Chris Brew. 1992. Letting the Cat out of the Bag:
Generation for Shake-and-Bake MT. In Proceed-
ings of COLING 92, pages 29-34, Nantes, France.
Peter F. Brown, John Cocke, A Della Pietra, Vin-
cent J. Della Pietra, Fredrick Jelinek, John D.
Lafferty, Robert L. Mercer, and Paul S. Roossin.
1990. A Statistical Approach to Machine Trans-
lation. Computational Linguistics, 16(2):79-85,
June.
Hsin-Hsi Chen and Yue-Shi Lee. 1994. A Correc-
tive Training Algorithm for Adaptive Learning in
Bag Generation. In International Conference on
New Methods in Language Processing (NeMLaP),
pages 248-254, Manchester, UK. UMIST.
Bonnie Jean Dorr. 1993. Machine Translation: A
View from the Lexicon. Artificial Intelligence Se-
ries. The MIT Press, Cambridge, Mass.
Sergei Nirenburg, Jaime Carbonell, Masaru Tomita,
and Kenneth Goodman. 1992. Machine Trans-
lation: A Knowledge-Based Approach. Morgan
Kaaufmann, San Mateo, CA.
Fred Popowich. 1994. Improving the Efficiency
of a Generation Algorithm for Shake and Bake
Machine Translation using Head-Driven Phrase
Structure Grammar. Technical Report CMPT-
TR 94-07, School of Computing Science, Simon
Fraser University, Burnaby, British Columbia,
CANADA V5A 1S6.•
V. Poznaliski, John L. Beaven, and P. Whitelock.
1993. The Design of SLEMaT Mk II. Technical
Report IT-1993-19, Sharp Laboratories of Europe,
LTD, Edmund Halley Road, Oxford Science Park,
Oxford 0X4 4GA, July.
P. Whitelock. 1992. Shake and Bake Translation.
In Proceedings of COLING 92, pages 610-616,
Nantes, France.
P. Whitelock. 1994. Shake-and-Bake Translation.
In C. J. Rupp, M. A. Rosner, and R. L. Johnson,
editors, Constraints, Language and Computation,
pages 339-359. Academic Press, London.
</reference>
<page confidence="0.997297">
267
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.485722">
<title confidence="0.999542">An Efficient Generation Algorithm for Lexicalist MT</title>
<author confidence="0.997782">Victor Poznariski</author>
<author confidence="0.997782">John L Beaven</author>
<author confidence="0.997782">Pete Whitelock</author>
<affiliation confidence="0.825139666666667">of Europe Ltd. Oxford Science Park, Oxford 0X4 4GA United Kingdom</affiliation>
<email confidence="0.968334">vp©sharp.co.uk</email>
<email confidence="0.968334">j1b©sharp.co.uk</email>
<email confidence="0.968334">pete©sharp.co.uk</email>
<abstract confidence="0.996701">The lexicalist approach to Machine Translation offers significant advantages in the development of linguistic descriptions. However, the Shake-and-Bake generation algorithm of (Whitelock, 1992) is NPcomplete. We present a polynomial time algorithm for lexicalist MT generation provided that sufficient information can be transferred to ensure more determinism.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>V Allegranza</author>
<author>P Bennett</author>
<author>J Durand</author>
<author>F van Eynde</author>
<author>L Humphreys</author>
<author>P Schmidt</author>
<author>E Steiner</author>
</authors>
<title>Linguistics for Machine Translation: The Eurotra Linguistic Specifications. In</title>
<date>1991</date>
<booktitle>The Eurotra Formal Specifications. Studies in Machine Translation and Natural Language Processing 2,</booktitle>
<pages>15--124</pages>
<editor>C. Copeland, J. Durand, S. Krauwer, and B. Maegaard, editors,</editor>
<marker>Allegranza, Bennett, Durand, van Eynde, Humphreys, Schmidt, Steiner, 1991</marker>
<rawString>V. Allegranza, P. Bennett, J. Durand, F. van Eynde, L. Humphreys, P. Schmidt, and E. Steiner. 1991. Linguistics for Machine Translation: The Eurotra Linguistic Specifications. In C. Copeland, J. Durand, S. Krauwer, and B. Maegaard, editors, The Eurotra Formal Specifications. Studies in Machine Translation and Natural Language Processing 2, pages 15-124. Office for Official Publications of the European Communities.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Arnold</author>
<author>S Krauwer</author>
<author>L des Tombe</author>
<author>L Sadler</author>
</authors>
<title>Relaxed&apos; Compositionality in Machine Translation.</title>
<date>1988</date>
<booktitle>In Second International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,</booktitle>
<location>Carnegie Mellon Univ, Pittsburgh.</location>
<contexts>
<context position="821" citStr="Arnold et al., 1988" startWordPosition="108" endWordPosition="111">}©sharp.co.uk Abstract The lexicalist approach to Machine Translation offers significant advantages in the development of linguistic descriptions. However, the Shake-and-Bake generation algorithm of (Whitelock, 1992) is NPcomplete. We present a polynomial time algorithm for lexicalist MT generation provided that sufficient information can be transferred to ensure more determinism. 1 Introduction Lexicalist approaches to MT, particularly those incorporating the technique of Shake-and-Bake generation (Beaven, 1992a; Beaven, 1992b; Whitelock, 1994), combine the linguistic advantages of transfer (Arnold et al., 1988; Allegranza et al., 1991) and interlingual (Nirenburg et al., 1992; Dorr, 1993) approaches. Unfortunately, the generation algorithms described to date have been intractable. In this paper, we describe an alternative generation component which has polynomial time complexity. Shake-and-Bake translation assumes a source grammar, a target grammar and a bilingual dictionary which relates translationally equivalent sets of lexical signs, carrying across the semantic dependencies established by the source language analysis stage into the target language generation stage. The translation process cons</context>
</contexts>
<marker>Arnold, Krauwer, Tombe, Sadler, 1988</marker>
<rawString>D. Arnold, S. Krauwer, L. des Tombe, and L. Sadler. 1988. &apos;Relaxed&apos; Compositionality in Machine Translation. In Second International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages, Carnegie Mellon Univ, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John L Beaven</author>
</authors>
<title>Lexicalist Unification-based Machine Translation.</title>
<date>1992</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh,</institution>
<location>Edinburgh.</location>
<contexts>
<context position="719" citStr="Beaven, 1992" startWordPosition="96" endWordPosition="97">ARP Laboratories of Europe Ltd. Oxford Science Park, Oxford 0X4 4GA United Kingdom {vp,j1b,pete}©sharp.co.uk Abstract The lexicalist approach to Machine Translation offers significant advantages in the development of linguistic descriptions. However, the Shake-and-Bake generation algorithm of (Whitelock, 1992) is NPcomplete. We present a polynomial time algorithm for lexicalist MT generation provided that sufficient information can be transferred to ensure more determinism. 1 Introduction Lexicalist approaches to MT, particularly those incorporating the technique of Shake-and-Bake generation (Beaven, 1992a; Beaven, 1992b; Whitelock, 1994), combine the linguistic advantages of transfer (Arnold et al., 1988; Allegranza et al., 1991) and interlingual (Nirenburg et al., 1992; Dorr, 1993) approaches. Unfortunately, the generation algorithms described to date have been intractable. In this paper, we describe an alternative generation component which has polynomial time complexity. Shake-and-Bake translation assumes a source grammar, a target grammar and a bilingual dictionary which relates translationally equivalent sets of lexical signs, carrying across the semantic dependencies established by the </context>
<context position="3066" citStr="Beaven, 1992" startWordPosition="451" endWordPosition="452">st. In effect, an arbitrary permutation of signs is input to a shift-reduce parser which tests them for grammatical well-formedness. If they are well-formed, the system halts indicating success. If not, another permutation is tried and the process repeated. The complexity of this algorithm is 0(n!) because all permutations (n! for an input of size n) may have to be explored to find the correct answer, and indeed must be explored in order to verify that there is no answer. Proponents of the Shake-and-Bake approach have employed various techniques to improve generation efficiency. For example, (Beaven, 1992a) employs a chart to avoid recalculating the same combinations of signs more than once during testing, and (Popowich, 1994) proposes a more general technique for storing which rule applications have been attempted; (Brew, 1992) avoids certain pathological cases by employing global constraints on the solution space; researchers such as (Brown et al., 1990) and (Chen and Lee, 1994) provide a system for bag generation that is heuristically guided by probabilities. However, none of these approaches is guaranteed to avoid protracted search times if an exact answer is required, because bag generati</context>
<context position="5512" citStr="Beaven, 1992" startWordPosition="841" endWordPosition="842">which may be used to combine two signs by unifying them with the daughter categories and returning the mother. Combination is the commutative equivalent of rule application; the linear ordering of the daughters that leads to successful rule application determines the orthography of the mother. Whitelock&apos;s Shake-and-Bake generation algorithm attempts to arrange the bag of target signs until a grammatical ordering (an ordering which allows all of the signs to combine to yield a single sign) is found. However, the target derivation information itself is not used to assist the algorithm. Even in (Beaven, 1992a), the derivation information is used simply to cache previous results to avoid exact recomputation at a later stage, not to improve on previous guesses. The reason why we believe such improvement is possible is that, given adequate information from the previous stages, two target signs cannot combine by accident; they must do so because the underlying semantics within the signs licenses it. If the linguistic data that two signs contain allows them to combine, it is because they are providing a semantics which might later become more specified. For example, consider the bag of signs that have</context>
</contexts>
<marker>Beaven, 1992</marker>
<rawString>John L. Beaven. 1992a. Lexicalist Unification-based Machine Translation. Ph.D. thesis, University of Edinburgh, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John L Beaven</author>
</authors>
<title>Shake-and-Bake Machine Translation.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING 92,</booktitle>
<pages>602--609</pages>
<location>Nantes, France.</location>
<contexts>
<context position="719" citStr="Beaven, 1992" startWordPosition="96" endWordPosition="97">ARP Laboratories of Europe Ltd. Oxford Science Park, Oxford 0X4 4GA United Kingdom {vp,j1b,pete}©sharp.co.uk Abstract The lexicalist approach to Machine Translation offers significant advantages in the development of linguistic descriptions. However, the Shake-and-Bake generation algorithm of (Whitelock, 1992) is NPcomplete. We present a polynomial time algorithm for lexicalist MT generation provided that sufficient information can be transferred to ensure more determinism. 1 Introduction Lexicalist approaches to MT, particularly those incorporating the technique of Shake-and-Bake generation (Beaven, 1992a; Beaven, 1992b; Whitelock, 1994), combine the linguistic advantages of transfer (Arnold et al., 1988; Allegranza et al., 1991) and interlingual (Nirenburg et al., 1992; Dorr, 1993) approaches. Unfortunately, the generation algorithms described to date have been intractable. In this paper, we describe an alternative generation component which has polynomial time complexity. Shake-and-Bake translation assumes a source grammar, a target grammar and a bilingual dictionary which relates translationally equivalent sets of lexical signs, carrying across the semantic dependencies established by the </context>
<context position="3066" citStr="Beaven, 1992" startWordPosition="451" endWordPosition="452">st. In effect, an arbitrary permutation of signs is input to a shift-reduce parser which tests them for grammatical well-formedness. If they are well-formed, the system halts indicating success. If not, another permutation is tried and the process repeated. The complexity of this algorithm is 0(n!) because all permutations (n! for an input of size n) may have to be explored to find the correct answer, and indeed must be explored in order to verify that there is no answer. Proponents of the Shake-and-Bake approach have employed various techniques to improve generation efficiency. For example, (Beaven, 1992a) employs a chart to avoid recalculating the same combinations of signs more than once during testing, and (Popowich, 1994) proposes a more general technique for storing which rule applications have been attempted; (Brew, 1992) avoids certain pathological cases by employing global constraints on the solution space; researchers such as (Brown et al., 1990) and (Chen and Lee, 1994) provide a system for bag generation that is heuristically guided by probabilities. However, none of these approaches is guaranteed to avoid protracted search times if an exact answer is required, because bag generati</context>
<context position="5512" citStr="Beaven, 1992" startWordPosition="841" endWordPosition="842">which may be used to combine two signs by unifying them with the daughter categories and returning the mother. Combination is the commutative equivalent of rule application; the linear ordering of the daughters that leads to successful rule application determines the orthography of the mother. Whitelock&apos;s Shake-and-Bake generation algorithm attempts to arrange the bag of target signs until a grammatical ordering (an ordering which allows all of the signs to combine to yield a single sign) is found. However, the target derivation information itself is not used to assist the algorithm. Even in (Beaven, 1992a), the derivation information is used simply to cache previous results to avoid exact recomputation at a later stage, not to improve on previous guesses. The reason why we believe such improvement is possible is that, given adequate information from the previous stages, two target signs cannot combine by accident; they must do so because the underlying semantics within the signs licenses it. If the linguistic data that two signs contain allows them to combine, it is because they are providing a semantics which might later become more specified. For example, consider the bag of signs that have</context>
</contexts>
<marker>Beaven, 1992</marker>
<rawString>John L. Beaven. 1992b. Shake-and-Bake Machine Translation. In Proceedings of COLING 92, pages 602-609, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Brew</author>
</authors>
<title>Letting the Cat out of the Bag: Generation for Shake-and-Bake MT.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING 92,</booktitle>
<pages>29--34</pages>
<location>Nantes, France.</location>
<contexts>
<context position="3294" citStr="Brew, 1992" startWordPosition="487" endWordPosition="488">ed and the process repeated. The complexity of this algorithm is 0(n!) because all permutations (n! for an input of size n) may have to be explored to find the correct answer, and indeed must be explored in order to verify that there is no answer. Proponents of the Shake-and-Bake approach have employed various techniques to improve generation efficiency. For example, (Beaven, 1992a) employs a chart to avoid recalculating the same combinations of signs more than once during testing, and (Popowich, 1994) proposes a more general technique for storing which rule applications have been attempted; (Brew, 1992) avoids certain pathological cases by employing global constraints on the solution space; researchers such as (Brown et al., 1990) and (Chen and Lee, 1994) provide a system for bag generation that is heuristically guided by probabilities. However, none of these approaches is guaranteed to avoid protracted search times if an exact answer is required, because bag generation is NPcomplete (Brew, 1992). Our novel generation algorithm has polynomial complexity (0(n4)). The reduction in theoretical complexity is achieved by placing constraints on the power of the target grammar when operating on ins</context>
</contexts>
<marker>Brew, 1992</marker>
<rawString>Chris Brew. 1992. Letting the Cat out of the Bag: Generation for Shake-and-Bake MT. In Proceedings of COLING 92, pages 29-34, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>John Cocke</author>
<author>A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Fredrick Jelinek</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Paul S Roossin</author>
</authors>
<title>A Statistical Approach to Machine Translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--2</pages>
<contexts>
<context position="3424" citStr="Brown et al., 1990" startWordPosition="505" endWordPosition="508">) may have to be explored to find the correct answer, and indeed must be explored in order to verify that there is no answer. Proponents of the Shake-and-Bake approach have employed various techniques to improve generation efficiency. For example, (Beaven, 1992a) employs a chart to avoid recalculating the same combinations of signs more than once during testing, and (Popowich, 1994) proposes a more general technique for storing which rule applications have been attempted; (Brew, 1992) avoids certain pathological cases by employing global constraints on the solution space; researchers such as (Brown et al., 1990) and (Chen and Lee, 1994) provide a system for bag generation that is heuristically guided by probabilities. However, none of these approaches is guaranteed to avoid protracted search times if an exact answer is required, because bag generation is NPcomplete (Brew, 1992). Our novel generation algorithm has polynomial complexity (0(n4)). The reduction in theoretical complexity is achieved by placing constraints on the power of the target grammar when operating on instantiated signs, and by using a more restrictive data structure than a bag, which we call a target language normalised commutative</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>Peter F. Brown, John Cocke, A Della Pietra, Vincent J. Della Pietra, Fredrick Jelinek, John D. Lafferty, Robert L. Mercer, and Paul S. Roossin. 1990. A Statistical Approach to Machine Translation. Computational Linguistics, 16(2):79-85, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsin-Hsi Chen</author>
<author>Yue-Shi Lee</author>
</authors>
<title>A Corrective Training Algorithm for Adaptive Learning in Bag Generation.</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing (NeMLaP),</booktitle>
<pages>248--254</pages>
<publisher>UMIST.</publisher>
<location>Manchester, UK.</location>
<contexts>
<context position="3449" citStr="Chen and Lee, 1994" startWordPosition="510" endWordPosition="513"> to find the correct answer, and indeed must be explored in order to verify that there is no answer. Proponents of the Shake-and-Bake approach have employed various techniques to improve generation efficiency. For example, (Beaven, 1992a) employs a chart to avoid recalculating the same combinations of signs more than once during testing, and (Popowich, 1994) proposes a more general technique for storing which rule applications have been attempted; (Brew, 1992) avoids certain pathological cases by employing global constraints on the solution space; researchers such as (Brown et al., 1990) and (Chen and Lee, 1994) provide a system for bag generation that is heuristically guided by probabilities. However, none of these approaches is guaranteed to avoid protracted search times if an exact answer is required, because bag generation is NPcomplete (Brew, 1992). Our novel generation algorithm has polynomial complexity (0(n4)). The reduction in theoretical complexity is achieved by placing constraints on the power of the target grammar when operating on instantiated signs, and by using a more restrictive data structure than a bag, which we call a target language normalised commutative bracketing 261 (TNCB). A</context>
</contexts>
<marker>Chen, Lee, 1994</marker>
<rawString>Hsin-Hsi Chen and Yue-Shi Lee. 1994. A Corrective Training Algorithm for Adaptive Learning in Bag Generation. In International Conference on New Methods in Language Processing (NeMLaP), pages 248-254, Manchester, UK. UMIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Jean Dorr</author>
</authors>
<title>Machine Translation: A View from the Lexicon. Artificial Intelligence Series.</title>
<date>1993</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="901" citStr="Dorr, 1993" startWordPosition="122" endWordPosition="123"> advantages in the development of linguistic descriptions. However, the Shake-and-Bake generation algorithm of (Whitelock, 1992) is NPcomplete. We present a polynomial time algorithm for lexicalist MT generation provided that sufficient information can be transferred to ensure more determinism. 1 Introduction Lexicalist approaches to MT, particularly those incorporating the technique of Shake-and-Bake generation (Beaven, 1992a; Beaven, 1992b; Whitelock, 1994), combine the linguistic advantages of transfer (Arnold et al., 1988; Allegranza et al., 1991) and interlingual (Nirenburg et al., 1992; Dorr, 1993) approaches. Unfortunately, the generation algorithms described to date have been intractable. In this paper, we describe an alternative generation component which has polynomial time complexity. Shake-and-Bake translation assumes a source grammar, a target grammar and a bilingual dictionary which relates translationally equivalent sets of lexical signs, carrying across the semantic dependencies established by the source language analysis stage into the target language generation stage. The translation process consists of three phases: 1. A parsing phase, which outputs a multiset, or bag, of s</context>
</contexts>
<marker>Dorr, 1993</marker>
<rawString>Bonnie Jean Dorr. 1993. Machine Translation: A View from the Lexicon. Artificial Intelligence Series. The MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergei Nirenburg</author>
<author>Jaime Carbonell</author>
<author>Masaru Tomita</author>
<author>Kenneth Goodman</author>
</authors>
<title>Machine Translation: A Knowledge-Based Approach. Morgan Kaaufmann,</title>
<date>1992</date>
<location>San Mateo, CA.</location>
<contexts>
<context position="888" citStr="Nirenburg et al., 1992" startWordPosition="118" endWordPosition="121">ation offers significant advantages in the development of linguistic descriptions. However, the Shake-and-Bake generation algorithm of (Whitelock, 1992) is NPcomplete. We present a polynomial time algorithm for lexicalist MT generation provided that sufficient information can be transferred to ensure more determinism. 1 Introduction Lexicalist approaches to MT, particularly those incorporating the technique of Shake-and-Bake generation (Beaven, 1992a; Beaven, 1992b; Whitelock, 1994), combine the linguistic advantages of transfer (Arnold et al., 1988; Allegranza et al., 1991) and interlingual (Nirenburg et al., 1992; Dorr, 1993) approaches. Unfortunately, the generation algorithms described to date have been intractable. In this paper, we describe an alternative generation component which has polynomial time complexity. Shake-and-Bake translation assumes a source grammar, a target grammar and a bilingual dictionary which relates translationally equivalent sets of lexical signs, carrying across the semantic dependencies established by the source language analysis stage into the target language generation stage. The translation process consists of three phases: 1. A parsing phase, which outputs a multiset,</context>
</contexts>
<marker>Nirenburg, Carbonell, Tomita, Goodman, 1992</marker>
<rawString>Sergei Nirenburg, Jaime Carbonell, Masaru Tomita, and Kenneth Goodman. 1992. Machine Translation: A Knowledge-Based Approach. Morgan Kaaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Popowich</author>
</authors>
<title>Improving the Efficiency of a Generation Algorithm for Shake and Bake Machine Translation using Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<tech>Technical Report CMPTTR 94-07,</tech>
<institution>School of Computing Science, Simon Fraser University, Burnaby, British</institution>
<location>Columbia, CANADA</location>
<note>V5A 1S6.•</note>
<contexts>
<context position="3190" citStr="Popowich, 1994" startWordPosition="471" endWordPosition="472">formedness. If they are well-formed, the system halts indicating success. If not, another permutation is tried and the process repeated. The complexity of this algorithm is 0(n!) because all permutations (n! for an input of size n) may have to be explored to find the correct answer, and indeed must be explored in order to verify that there is no answer. Proponents of the Shake-and-Bake approach have employed various techniques to improve generation efficiency. For example, (Beaven, 1992a) employs a chart to avoid recalculating the same combinations of signs more than once during testing, and (Popowich, 1994) proposes a more general technique for storing which rule applications have been attempted; (Brew, 1992) avoids certain pathological cases by employing global constraints on the solution space; researchers such as (Brown et al., 1990) and (Chen and Lee, 1994) provide a system for bag generation that is heuristically guided by probabilities. However, none of these approaches is guaranteed to avoid protracted search times if an exact answer is required, because bag generation is NPcomplete (Brew, 1992). Our novel generation algorithm has polynomial complexity (0(n4)). The reduction in theoretica</context>
</contexts>
<marker>Popowich, 1994</marker>
<rawString>Fred Popowich. 1994. Improving the Efficiency of a Generation Algorithm for Shake and Bake Machine Translation using Head-Driven Phrase Structure Grammar. Technical Report CMPTTR 94-07, School of Computing Science, Simon Fraser University, Burnaby, British Columbia, CANADA V5A 1S6.•</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Poznaliski</author>
<author>John L Beaven</author>
<author>P Whitelock</author>
</authors>
<title>The Design of SLEMaT Mk II.</title>
<date>1993</date>
<tech>Technical Report IT-1993-19,</tech>
<pages>4</pages>
<institution>Sharp Laboratories of Europe, LTD, Edmund Halley Road, Oxford Science Park,</institution>
<location>Oxford</location>
<marker>Poznaliski, Beaven, Whitelock, 1993</marker>
<rawString>V. Poznaliski, John L. Beaven, and P. Whitelock. 1993. The Design of SLEMaT Mk II. Technical Report IT-1993-19, Sharp Laboratories of Europe, LTD, Edmund Halley Road, Oxford Science Park, Oxford 0X4 4GA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Whitelock</author>
</authors>
<title>Shake and Bake Translation.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING 92,</booktitle>
<pages>610--616</pages>
<location>Nantes, France.</location>
<contexts>
<context position="2378" citStr="Whitelock, 1992" startWordPosition="345" endWordPosition="346"> Kerima Benkerimi, David Elworthy, Peter Gibbins, Ian Johnson, Andrew Kay and Antonio Sanfilippo at SLE, and our anonymous reviewers for useful feedback and discussions on the research reported here and on earlier drafts of this paper. of instantiated source signs onto a bag of target language signs. 3. A generation phase which imposes an order on the bag of target signs which is guaranteed grammatical according to the monolingual target grammar. This ordering must respect the linguistic constraints which have been transferred into the target signs. The Shake-and-Bake generation algorithm of (Whitelock, 1992) combines target language signs using the technique known as generate-and-test. In effect, an arbitrary permutation of signs is input to a shift-reduce parser which tests them for grammatical well-formedness. If they are well-formed, the system halts indicating success. If not, another permutation is tried and the process repeated. The complexity of this algorithm is 0(n!) because all permutations (n! for an input of size n) may have to be explored to find the correct answer, and indeed must be explored in order to verify that there is no answer. Proponents of the Shake-and-Bake approach have </context>
<context position="10282" citStr="Whitelock, 1992" startWordPosition="1692" endWordPosition="1693">e 2. We then introduce node 8 above node 7, and make both nodes 7 and 4 its children. Note that during deletion, we remove a surplus node (node 2 in this case) and during conjunction or adjunction we introduce a new one (node 8 in this case) thus maintaining the same number of nodes in the tree. Figure 5: A conjoining move from 4 to 7 1 4 Evaluation: After a movement, the TNCB A±A..._.. is undetermined as demonstrated in figure 5. 2 3 5 6 The signs of the affected parts must be recalculated by combining the recursively evaluated child TNCBs. 2.2 Suitable Grammars The Shake-and-Bake system of (Whitelock, 1992) employs a bag generation algorithm because it is assumed that the input to the generator is no more than a collection of instantiated signs. Full-scale bag generation is not necessary because sufficient information can be transferred from the source language to severely constrain the subsequent search during generation. The two properties required of TNCBs (and hence the target grammars with instantiated lexical signs) are: 1. Precedence Monotonicity. The order of the Figure 3: 1 is conjoined with 4 giving 7 Adjunction: A maximal TNCB can be inserted inside a maximal TNCB, i.e. conjoined with</context>
</contexts>
<marker>Whitelock, 1992</marker>
<rawString>P. Whitelock. 1992. Shake and Bake Translation. In Proceedings of COLING 92, pages 610-616, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Whitelock</author>
</authors>
<title>Shake-and-Bake Translation. In</title>
<date>1994</date>
<booktitle>Constraints, Language and Computation,</booktitle>
<pages>339--359</pages>
<editor>C. J. Rupp, M. A. Rosner, and R. L. Johnson, editors,</editor>
<publisher>Academic Press,</publisher>
<location>London.</location>
<contexts>
<context position="753" citStr="Whitelock, 1994" startWordPosition="100" endWordPosition="101">. Oxford Science Park, Oxford 0X4 4GA United Kingdom {vp,j1b,pete}©sharp.co.uk Abstract The lexicalist approach to Machine Translation offers significant advantages in the development of linguistic descriptions. However, the Shake-and-Bake generation algorithm of (Whitelock, 1992) is NPcomplete. We present a polynomial time algorithm for lexicalist MT generation provided that sufficient information can be transferred to ensure more determinism. 1 Introduction Lexicalist approaches to MT, particularly those incorporating the technique of Shake-and-Bake generation (Beaven, 1992a; Beaven, 1992b; Whitelock, 1994), combine the linguistic advantages of transfer (Arnold et al., 1988; Allegranza et al., 1991) and interlingual (Nirenburg et al., 1992; Dorr, 1993) approaches. Unfortunately, the generation algorithms described to date have been intractable. In this paper, we describe an alternative generation component which has polynomial time complexity. Shake-and-Bake translation assumes a source grammar, a target grammar and a bilingual dictionary which relates translationally equivalent sets of lexical signs, carrying across the semantic dependencies established by the source language analysis stage int</context>
</contexts>
<marker>Whitelock, 1994</marker>
<rawString>P. Whitelock. 1994. Shake-and-Bake Translation. In C. J. Rupp, M. A. Rosner, and R. L. Johnson, editors, Constraints, Language and Computation, pages 339-359. Academic Press, London.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>