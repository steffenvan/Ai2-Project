<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001162">
<note confidence="0.68032875">
Transferring Coreference Resolvers with Posterior Regularization
Andr´e F. T. Martins*†
*Priberam Labs, Alameda D. Afonso Henriques, 41, 2°, 1000-123 Lisboa, Portugal
†Instituto de Telecomunicac¸˜oes, Instituto Superior T´ecnico, 1049-001 Lisboa, Portugal
</note>
<email confidence="0.864124">
atm@priberam.pt
</email>
<sectionHeader confidence="0.992184" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999910133333333">
We propose a cross-lingual framework
for learning coreference resolvers for
resource-poor target languages, given a re-
solver in a source language. Our method
uses word-aligned bitext to project infor-
mation from the source to the target. To
handle task-specific costs, we propose a
softmax-margin variant of posterior regu-
larization, and we use it to achieve robust-
ness to projection errors. We show empir-
ically that this strategy outperforms com-
petitive cross-lingual methods, such as
delexicalized transfer with bilingual word
embeddings, bitext direct projection, and
vanilla posterior regularization.
</bodyText>
<sectionHeader confidence="0.998428" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972862068966">
The goal of coreference resolution is to find the
mentions in text that refer to the same discourse
entity. While early work focused primarily on En-
glish (Soon et al., 2001; Ng and Cardie, 2002),
efforts have been made toward multilingual sys-
tems, this being addressed in recent shared tasks
(Recasens et al., 2010; Pradhan et al., 2012). How-
ever, the lack of annotated data hinders rapid sys-
tem deployment for new languages. Unsupervised
methods (Haghighi and Klein, 2007; Ng, 2008)
and rule-based approaches (Raghunathan et al.,
2010) avoid this data annotation bottleneck, but
they often require complex generative models or
expert linguistic knowledge.
We propose cross-lingual coreference resolu-
tion as a way of transferring information from
a rich-resource language to build coreference re-
solvers for languages with scarcer resources; as a
testbed, we transfer from English to Spanish and
to Brazilian Portuguese. We build upon the recent
successes of cross-lingual learning in NLP, which
proved quite effective in several structured predic-
tion tasks, such as POS tagging (T¨ackstr¨om et al.,
2013), named entity recognition (Wang and Man-
ning, 2014), dependency parsing (McDonald et
al., 2011), semantic role labeling (Titov and Kle-
mentiev, 2012), and fine-grained opinion mining
(Almeida et al., 2015). The potential of these tech-
niques, however, has never been fully exploited
in coreference resolution (despite some existing
work, reviewed in §6, but none resulting in an end-
to-end coreference resolver).
We bridge this gap by proposing a simple
learning-based method with weak supervision,
based on posterior regularization (Ganchev et
al., 2010). We adapt this framework to handle
softmax-margin objective functions (Gimpel and
Smith, 2010), leading to softmax-margin poste-
rior regularization (§4). This step, while fairly
simple, opens the door for incorporating task-
specific cost functions, which are important to
manage the precision/recall trade-offs in corefer-
ence resolution systems. We show that the result-
ing problem involves optimizing the difference of
two cost-augmented log-partition functions, mak-
ing a bridge with supervised systems based on la-
tent coreference trees (Fernandes et al., 2012;
Durrett and Klein, 2013), reviewed in §3. In-
spired by this idea, we consider a simple penal-
ized variant of posterior regularization that tunes
the Lagrange multipliers directly, bypassing the
saddle-point problem of existing EM and alternat-
ing stochastic gradient algorithms (Ganchev et al.,
2010; Liang et al., 2009). Experiments (§5) show
that the proposed method outperforms commonly
used cross-lingual approaches, such as delexical-
ized transfer with bilingual embeddings, direct
projection, and “vanilla” posterior regularization.
</bodyText>
<sectionHeader confidence="0.957236" genericHeader="introduction">
2 Architecture and Experimental Setup
</sectionHeader>
<bodyText confidence="0.9566255">
Our methodology, outlined as Algorithm 1, is in-
spired by the recent work of Ganchev and Das
(2013) on cross-lingual learning of sequence mod-
els. For simplicity, we call the source and tar-
</bodyText>
<page confidence="0.93678">
1427
</page>
<note confidence="0.987758333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1427–1437,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.964092333333333">
Figure 1: Excerpt of a bitext document with automatic coreference annotations (from FAPESP). The English side had its
coreferences resolved by a state-of-the-art system (Durrett and Klein, 2013). The predicted coreference chains {The pulmonary
alveoli, the alveoli, their} and {The pulmonary surfactant} are then projected to the Portuguese side, via word alignments.
</figureCaption>
<figure confidence="0.716470222222222">
Algorithm 1 Cross-Lingual Coreference Resolution via
Softmax-Margin Posterior Regularization
Input: Source coreference system Se, parallel data De and
Df, posterior constraints Q.
Output: Target coreference system Sf.
1: De↔f ← RUNWORDALIGNER(De, Df)
2: be ← RUNCOREF(Se, De)
3: Df ← PROJECTANDFILTERENTITIES(De↔f, De)
4: Sf ← LEARNCOREFWITHSOFTMARGPR(�Df, Q)
</figure>
<bodyText confidence="0.999714740740741">
get languages English (e) and “foreign” (f), re-
spectively, and we assume the existence of parallel
documents on the two languages (bitext).
The first two steps (lines 1–2) run a word aligner
and label the source side of the parallel data with
a pre-trained English coreference system. After-
wards, the predicted English entities are projected
to the target side of the parallel data (line 3), in-
ducing an automatic (and noisy) training dataset
for the foreign language. Finally, a coreference
system is trained in this dataset with the aid of
softmax-margin posterior regularization (line 4).
We next detail all the datasets and tools involved
in our experimental setup. Table 1 provides a sum-
mary, along with some statistics.
Parallel Data. As parallel data, we use a
sentence-aligned trilingual (English-Portuguese-
Spanish) parallel corpus based on the scien-
tific news Brazilian magazine Revista Pesquisa
FAPESP, collected by Aziz and Specia (2011).1
We preprocessed this dataset as follows. We la-
beled the English side with the Berkeley Corefer-
ence Resolution system v1.0, using the provided
English model (Durrett and Klein, 2013). Then,
we computed word alignments using the Berke-
ley aligner (Liang et al., 2006), intersected them
and filtered out all the alignments whose confi-
</bodyText>
<footnote confidence="0.99637275">
1We found that other commonly used parallel data (such
as Europarl or the UN corpus) have a predominance of direct
speech that is not suitable for our newswire test domain, so
we decided not to use these data.
</footnote>
<table confidence="0.999821333333333">
Dataset # Doc. # Sent. # Tok.
EN OntoNotes (train) 2,374 48,762 1,007,359
EN OntoNotes (dev) 303 6,894 136,257
EN OntoNotes (test) 322 8,262 152,728
ES FAPESP (aligned) 2,704 142,633 3,840,936
ES AnCora (train) 875 8,999 295,276
ES AnCora (dev) 140 1,417 46,167
ES AnCora (test) 168 1,704 53,042
PT FAPESP (aligned) 2,823 166,719 4,538,147
PT Summ-It (train) 30 469 11,771
PT Summ-It (dev) 7 111 2,983
PT Summ-It (test) 13 257 6,491
</table>
<tableCaption confidence="0.993887">
Table 1: Corpus statistics. EN, ES, and PT denote English,
Spanish, and Portuguese, respectively.
</tableCaption>
<bodyText confidence="0.999838857142857">
dence is below 0.95. After this, we projected En-
glish mentions to the target side using the maxi-
mal span heuristic of Yarowsky et al. (2001). We
filtered out documents where more than 15% of
the mentions were not aligned. At this point, we
obtained an automatically annotated corpus Df
in the target language. Figure 1 shows a small
excerpt where all mentions were correctly pro-
jected. In practice, not all documents are so well
behaved: in the English-Portuguese parallel data,
only 200,175 out of the original 271,122 mentions
(about 73.8%) were conserved after the projection
step. In Spanish, this number drops to 69.9%.
Monolingual Data. We also use monolingual
data for validation and comparison with super-
vised systems. The Berkeley Coreference Reso-
lution system is trained in the English OntoNotes
dataset used in the CoNLL 2011 shared task; this
dataset is also used to train delexicalized models.
For Spanish, we use the AnCora dataset (Re-
casens and Mart´ı, 2010) provided in the SemEval
2010 coreference task, which we preprocessed as
follows. We split all MWEs into individual tokens
(for consistency with the other corpora). We also
removed the extra gap tokens associated with zero-
anaphoric relations, and the anaphoric annotations
associated with relative pronouns (e.g., in “[una
central de ciclo combinado [que]1 debe empezar
</bodyText>
<page confidence="0.98821">
1428
</page>
<bodyText confidence="0.999754692307692">
a funcionar en mayo del 2002]1” we removed the
nested mention [que]1), since these are not anno-
tated in the English dataset.
For Portuguese, we used the Summ-It 3.0 cor-
pus (Collovini et al., 2007), which contains 50
documents annotated with coreferences, from the
science section of the Folha de S˜ao Paulo newspa-
per. This dataset is much smaller than OntoNotes
and AnCora, as shown in Table 1. We split the
data into train, development, and test partitions.
For both Spanish and Portuguese, we obtained
automatic POS tags and dependency parses by us-
ing TurboParser (Martins et al., 2013).
</bodyText>
<sectionHeader confidence="0.994636" genericHeader="method">
3 Coreference Resolution
</sectionHeader>
<subsectionHeader confidence="0.999984">
3.1 Problem Definition and Prior Work
</subsectionHeader>
<bodyText confidence="0.999769913043478">
In coreference resolution, we are given a set of
mentions M := {m1, ... , mM}, and the goal
is to cluster them into discourse entities, E :=
{e1,... , eE}, where each ej ⊆ M and ej =6 0.
The set E must form a partition of M, i.e., we must
have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j.
A variety of approaches have been proposed
to this problem, including entity-centric models
(Haghighi and Klein, 2010; Rahman and Ng,
2011; Durrett et al., 2013), pairwise models
(Bengtson and Roth, 2008; Versley et al., 2008),
greedy rule-based methods (Raghunathan et al.,
2010), and mention-ranking decoders (Denis and
Baldridge, 2008; Durrett and Klein, 2013). We
chose to base our coreference resolvers on this last
class of methods, which permit efficient decoding
by shifting from entity clusters to latent corefer-
ence trees. In particular, the inclusion of lexical-
ized features by Durrett and Klein (2013) yields
nearly state-of-the-art performance with surface
information only. Given that our goal is to pro-
totype resolvers for resource-poor languages, this
model is a good fit—we next describe it in detail.
</bodyText>
<subsectionHeader confidence="0.99987">
3.2 Latent Coreference Tree Models
</subsectionHeader>
<bodyText confidence="0.999939">
Let x be a document containing M mentions,
sorted from left to right. We associate to the mth
mention a random variable ym ∈ {0, 1, ... , m−1}
to denote its antecedent, where the value ym = 0
means that m is a singleton or starts a new coref-
erence chain. We denote by Y(x) the set of coref-
erence trees that can be formed by linking men-
tions to their antecedents; we represent each tree
as a vector y := hy1, ... , yMi. Note that each
tree y induces a unique clustering E, but that this
map is many-to-one, i.e., different trees may corre-
spond to the same set of entity clusters. We denote
by Y(E) the set of trees that are consistent with a
given clustering E.
We model the probability distribution p(y|x) as
an arc-factored log-linear model:
</bodyText>
<equation confidence="0.963598">
(EM )
pw(y|x) ∝ exp m=1 w&gt;f(x,m,ym) , (1)
</equation>
<bodyText confidence="0.996624521739131">
where w is a weight vector, and each f(x, m, ym)
is a local feature vector that depends on the
document x, the mention m, and its candi-
date antecedent ym. This model permits a
cheap computation of the most likely tree y :=
arg maxy∈Y(x) pw(y|x): simply compute the best
antecedent independently for each mention, and
collect them to form a tree. An analogous pro-
cedure can be employed to compute the posterior
marginals pw(ym|x) for every mention m.
Gold coreference tree annotations are rarely
available; datasets usually consist of documents
annotated with entity clusters, {hx(n),E(n)i}Nn=1.
Durrett and Klein (2013) proposed to learn the
probabilistic model in Eq. 1 by maximizing condi-
tional log-likelihood, treating the coreference trees
as latent variables. They also found advantageous
to incorporate a cost function `(y, Y(E)), measur-
ing the extent to which a prediction y differs from
the ones that are consistent with the gold entity set
E.2 Putting these pieces together, we arrive at the
following loss function to be minimized:
where p0w is the cost-augmented distribution:
</bodyText>
<equation confidence="0.997124">
p0w(y|x) ∝ pw(y|x)e`(y,Y(E)) . (3)
</equation>
<bodyText confidence="0.999910142857143">
The loss function in Eq. 2 can be seen as a prob-
abilistic analogous of the hinge loss of support
vector machines, and a model trained this way
is called a softmax-margin CRF (Gimpel and
Smith, 2010). Note that L(w) is non-convex, cor-
responding to the difference of two log-partition
functions (both convex on w),
</bodyText>
<equation confidence="0.9227839">
L(w) = En1 (log Z0(w, x(n)) − log �Z(w, x(n)))
(4)
above we denoted``
Z0(w, x) = EY∈Y(x) ewTf(x,y)+`(y,Y(E)) (5)
�Z(w, x) = Ey∈Y(E) ewTf(x,y), (6)
2A precise definition of this cost is provided in §4.3.
(E )
L(w) = − EN n=1 log y∈Y(E(n)) p0 w(y|x(n))
,
(2)
</equation>
<page confidence="0.955014">
1429
</page>
<bodyText confidence="0.999822230769231">
where f(x, y) := EMm=1 f(x, m, ym).3 Evaluat-
ing the gradient of the loss in Eq. 4 requires com-
puting marginals for the candidate antecedents of
each mention, which can be done in a mention-
synchronous fashion. This enables a simple
stochastic gradient descent algorithm, which was
the procedure taken by Durrett and Klein (2013).
Another way of regarding this framework, ex-
pressed through the marginalization in Eq. 2, is to
“pretend” that the outputs we care about are the
actual coreference trees, but that the datasets are
only “weakly labeled” with the entity clusters. We
build on this point of view in §4.1.
</bodyText>
<sectionHeader confidence="0.980805" genericHeader="method">
4 Cross-Lingual Coreference Resolution
</sectionHeader>
<bodyText confidence="0.999735">
We now adapt the framework above to learn coref-
erence resolvers in a cross-lingual manner.
</bodyText>
<subsectionHeader confidence="0.99919">
4.1 Softmax-Margin Posterior Regularization
</subsectionHeader>
<bodyText confidence="0.995800523809524">
In the weakly supervised case, the training data
may only be partially labeled or contain annota-
tion errors. For taking advantage of these data, we
need a procedure that handles uncertainty about
the missing data, and is robust to mislabelings. We
describe next an approach based on posterior reg-
ularization (PR) that fulfills these requirements.
For ease of explanation, we introduce corpus-
level counterparts for the variables in §3.2. We
use bold capital letters X := {x(1),... , x(N)} and
Y := {y(1), ... , y(N)} to denote the documents
and candidate coreference trees in our corpus. We
denote by pw(Y|X) := �Nn=1 pw(y|x(n)) the
conditional distribution of trees over the corpus,
induced by a model w, and similarly for the cost-
augmented distribution p&apos;w(Y|X).
In PR, we define a vector g(X, Y) of corpus-
level constraint features, and a vector b of upper
bounds for those features. We consider the family
of distributions over Y (call it Q) that satisfy these
constraints in a posteriori expectation,
</bodyText>
<equation confidence="0.998439">
Q := {q  |Eq[g(X,Y)] ≤ b}. (7)
</equation>
<bodyText confidence="0.994981161290323">
To make the analysis simpler, we assume that 0 ≤
b ≤ 1, and that for every j, miny gj(X, Y) = 0
and maxY gj(X, Y) = 1, where the min/max
above are over all possible coreference trees Y
that can be build from the documents X in the cor-
3Note that the scope of the sum is different in Eqs. 5 and 6:
Z&apos;(w, x) sums over all coreference trees, while Z(w, x)
sums only over those consistent with the gold clusters.
pus.4 Under this assumption, the two extreme val-
ues of the upper bounds have a precise meaning: if
bj = 0, the jth feature becomes a hard constraint,
(i.e., any feasible distribution in Q will vanish out-
side {Y  |gj(X, Y) = 0}), while bj = 1 turns it
into a vacuous feature.
We also make the usual assumption that the
constraint features decompose over documents,
g(X, Y) := ENn=1 g(x(n), y(n)); if this were not
the case, decoding would be much harder, as the
documents would be coupled.
In vanilla PR (Ganchev et al., 2010), one seeks
the model w minimizing the Kullback-Leibler di-
vergence between the set Q and the distribution
pw. Here, we go one step farther to consider the
cost-augmented distribution in Eq. 3. That is, we
minimize KL(Q||p&apos;w) := minqEQ KL(qkp&apos;w).
The next proposition shows that this expression
also corresponds to a difference of two log-
partition functions, as in Eq. 4.
Proposition 1. The (regularized) minimization of
the cost-augmented KL divergence is equivalent to
the following saddle-point problem:
</bodyText>
<equation confidence="0.954043222222222">
minw KL(Qkp&apos;w) + γ 2kwk2 = (8)
minw maxu&gt;0 F(w, u) − bTu +γ2kwk2,
where F(w, u) :=
EN (log Z&apos;(w, x(n)) − log Z&apos; u(w, x(n))) ,
n=1
with Z&apos;(w, x) as in Eq. 5, and
�Z&apos;u(w, x) := ewTf(x,y)+`(y,Y(_,))_uTg(x,y).
yEY(x)
Proof. See Appendix A.
</equation>
<bodyText confidence="0.9999">
In sum, what Proposition 1 shows is that we
can easily extend the vanilla PR framework of
Ganchev et al. (2010) to incorporate a task-specific
cost: by Lagrange duality, the resulting optimiza-
tion problem still amounts to finding a saddle
point of an objective function (Eq. 8), which in-
volves the difference of two log-partition func-
tions (Eq. 9). The difference is that these par-
tition functions now incorporate the cost term
`(y, Y(E)). If this cost term has a factorization
compatible with the features and the constraints,
this comes at no additional computational burden.
</bodyText>
<footnote confidence="0.9815115">
4We can always reduce the problem to this case by scaling
and adding a constant to the constraint feature vectors.
</footnote>
<page confidence="0.97863">
1430
</page>
<subsectionHeader confidence="0.984752">
4.2 Penalized Variant
</subsectionHeader>
<bodyText confidence="0.9999769375">
In their discriminative PR formulation for learning
sequence models, Ganchev and Das (2013) opti-
mize an objective similar to Eq. 8 by alternating
stochastic gradient updates with respect to w and
u. In their procedure, b was chosen a priori via
linear regression (see their Figure 2).
Here, we propose a different strategy, based on
Proposition 1 and a simple observation: while the
constraint values b have a more intuitive meaning
than the Lagrange multipliers u (since they may
correspond, e.g., to proportions of events observed
in the data), choosing these upper bounds is often
no easier than tuning u. In this case, a preferable
strategy is to specify u directly—this leaves this
variable fixed in Eq. 8, and allows us to get rid of
b. The resulting problem becomes
</bodyText>
<equation confidence="0.974547">
minw F(w, u) + γ2 kwk2, (11)
</equation>
<bodyText confidence="0.988983923076923">
which is a penalized variant of PR and no longer a
saddle point problem. This variant requires tuning
the Lagrange multipliers uj in the range [0, +∞],
for every constraint. The two extreme cases of
bj = 0 and bj = 1 correspond respectively to
uj = +∞ and uj = 0.5 Note that this grid search
is only appealing for a small number of posterior
constraints at corpus-level (since document-level
constraints would require tuning separate coeffi-
cients for each document).
The practical advantages of the penalized vari-
ant over the saddle-point formulation are illus-
trated in Figure 2, which compares the perfor-
mance of stochastic gradient algorithms for the
two formulations (there, η2 = 1 − b2).
An interesting aspect of this penalized formula-
tion is its resemblance to latent variable models.
Indeed, the objective of Eq. 11 is also a differ-
ence of log-partition functions, as the latent-tree
supervised case (cf. Eq. 4). The noticeable differ-
ence is that now both partition functions include
extra cost terms, either task-specific (`(y, Y(E))
in Z&apos;) or with soft constraints (uTg(x, y) in Z&apos;u).
In particular, if we set a single constrained feature
g1(x,y) := ff(`(y, Y(E)) =6 0) with weight u1 →
+∞, all non-zero-cost summands in Z&apos;u(w, x)
</bodyText>
<footnote confidence="0.829088333333333">
5This follows from Lagrange duality. If bj = 1, the
constraint is vacuous and by complementary slackness we
must have uj = 0. If bj = 0, this becomes a hard con-
straint, so for the nth document, any coreference tree y for
which gj(x(n), y) =� 0 must have probability zero—this cor-
responds to setting uj → +oo in Eq. 10.
</footnote>
<figureCaption confidence="0.987316333333333">
Figure 2: Comparison of saddle-point and penalized PR for
Spanish, using the setup in §5.5. Left: variation of the mul-
tiplier u2 over gradient iterations, with strong oscillations in
initial epochs and somewhat slow convergence. Right: im-
pact in the averaged F1 scores (on the dev-set). Contrast with
the more “stable” scores achieved by the penalized method.
</figureCaption>
<bodyText confidence="0.99925975">
vanish and we get Z&apos;u(w, x) = Z(w, x), recov-
ering the supervised case (see Eq. 6).
Intuitively, this formulation pushes probability
mass toward structures that respect the constraints
in Eq. 7, while moving away from those that have a
large task-specific cost. A similar idea, but applied
to the generative case, underlies the framework of
constrastive estimation (Smith and Eisner, 2005).
</bodyText>
<subsectionHeader confidence="0.998072">
4.3 Cost Function
</subsectionHeader>
<bodyText confidence="0.98978555">
Denote by Em the entire coreference chain of the
mth mention (so E = U mcM{Em}), and by
Msing := {m ∈ M  |Em = {m}} the set of men-
tions that are projected as singleton in the data (we
call this gold-singleton mentions).
We design a task-specific cost `(y, Y(E)) as
in Durrett and Klein (2013) to balance three
kinds of mistakes: (i) false anaphora (ym =6
0 while m ∈ Msing); (ii) false new (ym =
0 while m ∈/ Msing); and (iii) wrong link
(ym =6 0 but Em =6 Eym). Letting ffFA(ym, E),
ffFN(ym, E), and ffWL(gm, E) be indicators for
these events, we define a weighted Hamming cost
function: `(y, Y(E)) := EMm=1(αFAffFA(&amp;m, E)+
αFNffFN(ym, E) + αWLffWL(ym, E)). We set
αFA = 0.0, αFN = 3.0, and αWL = 1.0.6 Since
this cost decomposes as a sum over mentions, the
computation of cost-augmented marginals (neces-
sary to evaluate the gradient of Eq. 11) can still be
done with mention-ranking decoders.
</bodyText>
<subsectionHeader confidence="0.997728">
4.4 Constraint Features
</subsectionHeader>
<bodyText confidence="0.96532175">
Finally, we describe the constraint features (Eq. 7)
used in our softmax-margin PR formulation.
Constraint #1: Clusters should not split. Let
|M |− |E |be the number of anaphoric mentions
</bodyText>
<footnote confidence="0.94543025">
6The only difference with respect to Durrett and Klein
(2013) is that they set αFA = 0.1. We set this coefficient
to zero so that all configurations licensed by the constraint
features (to be made precise in §4.4) will have zero cost.
</footnote>
<page confidence="0.988938">
1431
</page>
<bodyText confidence="0.999791166666667">
in the projected data. We push these mentions to
preserve their anaphoricity (ym =6 0) and to have
their antecedent in the projected coreference chain
(Em = Eym). To do so, we force the fraction of
mentions satisfying these properties to be at least
η1. This can be enforced via a constraint feature
</bodyText>
<equation confidence="0.983137">
g1(X,Y) := (12)
− Pn=1 Pm(1 n) I(y(n)
m =6 0 ∧ E(n)
m = £yM)),
PN
</equation>
<bodyText confidence="0.991385454545455">
and an upper bound b1 := −η1 n=1(|M(n) |−
|E(n)|). (These quantities are summed by a con-
stant and rescaled to meet the assumption in §4.1.)
In our experiments, we set η1 = 1.0, turning this
into a hard constraint. This is equivalent to setting
u1 = +∞ in the penalized formulation.
Constraint #2: Most projected singletons
should become non-anaphoric. We define a
soft constraint so that a large fraction of the gold-
singleton mentions m ∈ Msing satisfy ym = 0.
This can be done via a constraint feature
</bodyText>
<equation confidence="0.920956857142857">
g2(X, Y) := (13)
− PN PM(n)
m=1 m = 0 ∧ E(n)
m = {m}),
n=1
PN
and an upper bound b2 := −η2 n=1 |M(n)
</equation>
<bodyText confidence="0.999667416666667">
sing|. In
our experiments, we varied η2 in the range [0, 1],
either directly or via the dual variable u2, as de-
scribed in §4.1. The extreme case η2 = 0 corre-
sponds to a vacuous constraint, while for η2 = 1
this becomes a hard constraint which, combined
with the previous constraint, recovers bitext direct
projection (see §5.3). The intermediate case makes
this a soft constraint which allows some single-
tons to be attached to existing entities (therefore
introducing some robustness to non-aligned men-
tions), but penalizes the number of reattachments.
</bodyText>
<sectionHeader confidence="0.999318" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9999886">
We now present experiments using the setup in
§2. We compare our coreference resolvers trained
with softmax-margin PR (§5.5) with three other
weakly-supervised baselines: delexicalized trans-
fer with cross-lingual embeddings (§5.2), bitext
projection (§5.3), and vanilla PR (§5.4). We also
run fully supervised systems (§5.1), to obtain up-
per bounds for the level of performance we expect
to achieve with the weakly-supervised systems.
An important step in coreference resolution sys-
tems is mention prediction. For English, mention
spans were predicted from the noun phrases given
by the Berkeley parser (Petrov and Klein, 2007),
the same procedure as Durrett and Klein (2013).
For Spanish and Portuguese, this prediction relied
on the output of the dependency parser, using a
simple heuristic: besides pronouns, each maximal
span formed by contiguous descendants of a noun
becomes a candidate mention. This heuristic is
quite effective, as shown by Attardi et al. (2010).
</bodyText>
<subsectionHeader confidence="0.99347">
5.1 Supervised Systems
</subsectionHeader>
<bodyText confidence="0.988058318181818">
Table 2 shows the performance of supervised sys-
tems for English, Spanish and Portuguese. All op-
timize Eq. 4 appended with an extra regularization
term γ2 kwk2, by running 20 epochs of stochastic
gradient descent (SGD; we set γ = 1.0 and se-
lected the best epoch using the dev-set). All lexi-
calized systems use the same features as the SUR-
FACE model of Durrett and Klein (2013), plus fea-
tures for gender and number.7 We collected a list
of pronouns for all languages along with their gen-
der, number, and person information. For English,
we trained on the WSJ portion of the OntoNotes
dataset, and for Spanish and Portuguese we trained
on the monolingual datasets described in §2.
We observe that the Spanish system obtains av-
eraged F1 scores around 44%, a few points below
the English figures.8 In Portuguese, these scores
are significantly lower (in the 37–39% range),
which is explained by the fact that the training
dataset is much smaller (cf. Table 1).
For English, we also report the performance of
delexicalized systems, i.e., systems where all the
lexical features were removed. The second row
of Table 2 shows a drop of 2–2.5 points with re-
spect to the lexicalized system. For the third and
fourth rows, the lexical features were replaced
by bilingual word embeddings (either English-
Spanish or English-Portuguese; a detailed descrip-
tion of these embeddings will be provided in §5.2).
Here the drop is small, and for English-Spanish it
looks on par with the lexicalized system.
7For English, the gender and number of nominal and
proper mentions were obtained from the statistics collected
by Bergsma and Lin (2006). For Spanish and Portuguese we
used a simple heuristic for nominal mentions, based on the
determiner preceding the noun (when there is one).
8We point out that the supervised Spanish system we
present here is strong enough to outperform all participating
systems in the SemEval 2010’s closed regular track. When
trained on the original Spanish SemEval data (with zero- and
relative pronoun anaphoras) and evaluated in the provided
scorer, it achieves 53.0% averaged F1 in the test partition; for
comparison, TALN-1 (Attardi et al., 2010), the best system at
the shared task, achieved 49.6% averaged F1.
</bodyText>
<page confidence="0.980888">
1432
</page>
<table confidence="0.9988525">
MUC Dev Avg. MUC Test Avg.
B3 CEAF, B3 CEAF,
EN lexicalized 58.35 50.75 52.08 53.73 59.07 49.25 48.78 52.37
EN delexicalized, no embed. 56.59 48.81 49.95 51.78 55.96 46.94 46.19 49.70
EN delexicalized, emb. EN-ES 57.55 49.83 51.21 52.86 59.00 49.25 49.00 52.42
EN delexicalized, emb. EN-PT 57.91 49.67 51.01 52.86 58.03 48.16 48.33 51.51
ES lexicalized 48.24 40.97 43.59 44.27 47.03 40.68 44.09 43.93
PT lexicalized 35.60 34.47 42.56 37.54 41.61 36.91 40.96 39.83
</table>
<tableCaption confidence="0.994685666666667">
Table 2: Results for the supervised systems. We show also the performance of delexicalized English systems, with and without
cross-lingual embeddings. Shown are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), and CEAF, (Luo, 2005), as
well their averaged F1 scores, all computed using the reference implementation of the CoNLL scorer (Pradhan et al., 2014).
</tableCaption>
<table confidence="0.999936">
MUC Dev Avg. MUC Test Avg.
B3 CEAF, B3 CEAF,
ES simple baseline 25.73 24.73 27.89 26.12 26.06 26.12 29.87 27.35
ES baseline #1 (delex. transfer) 33.04 27.47 32.71 31.07 34.35 28.69 34.42 32.49
ES baseline #2 (bitext dir. proj.) 39.42 30.04 38.25 35.90 37.21 29.72 35.97 34.30
ES baseline #3 (vanilla PR) 41.29 33.68 38.56 37.84 39.34 32.95 38.23 36.84
ES softmax-margin PR 42.34 35.53 39.95 39.27 41.22 35.30 39.94 38.82
PT simple baseline 26.04 26.67 33.19 28.63 22.72 23.91 27.35 24.66
PT baseline #1 (delex. transfer) 22.51 23.27 33.27 26.35 31.11 27.36 32.78 30.42
PT baseline #2 (bitext dir. proj.) 30.43 27.37 36.47 31.42 31.93 27.97 35.40 31.77
PT baseline #3 (vanilla PR) 30.97 27.82 35.14 31.31 38.39 33.34 38.73 36.82
PT softmax-margin PR 33.43 31.00 38.82 34.42 38.18 34.05 39.47 37.23
</table>
<tableCaption confidence="0.984503333333333">
Table 3: Results for all the cross-lingual systems. Bold indicates the overall highest scores. As a lower bound, we show a simple
deterministic baseline that, for pronominal mentions, selects the closest non-pronominal antecedent, and, for non-pronominal
mentions, selects the closest non-pronominal mention that is a superstring of the current mention.
</tableCaption>
<subsectionHeader confidence="0.9447235">
5.2 Baseline #1: Delexicalized Transfer With
Cross-Lingual Embeddings
</subsectionHeader>
<bodyText confidence="0.999990454545455">
We now turn to the cross-lingual systems. Delex-
icalized transfer is a popular strategy in NLP (Ze-
man and Resnik, 2008; McDonald et al., 2011),
recently strengthened with cross-lingual word rep-
resentations (T¨ackstr¨om et al., 2012). The proce-
dure works as follows: a delexicalized model for
the source language is trained by eliminating all
the language-specific features (such as lexical fea-
tures); then, this model is used directly in the tar-
get language. We report here the performance of
this baseline on coreference resolution for Span-
ish and Portuguese, using the delexicalized models
trained on the English data as mentioned in §5.1.
To achieve a unified feature representation, we
mapped all language-specific POS tags to univer-
sal tags (Petrov et al., 2012). All lexical features
were replaced either by cross-lingual word em-
beddings (for words that are not pronouns); or by
a universal representation containing the gender,
number, and person information of the pronoun.
To obtain the cross-lingual word embeddings, we
ran the method described by Hermann and Blun-
som (2014) for the English-Spanish and English-
Portuguese pairs, using the parallel sentences in
§2. When used as features, these 128-dimensional
continuous representations were scaled by a factor
of 0.5 (selected on the dev-set), using the proce-
dure of Turian et al. (2010).
The second and seventh rows in Table 3 show
the performance of this baseline, which is rather
disappointing. For Spanish, we observe a large
drop in performance when going from supervised
training to delexicalized transfer (about 11–13%
in averaged Fi). For Portuguese, where the super-
vised system is not so accurate, the difference is
less sharp (about 9–11%). These drops are mainly
due to the fact that this method does not take into
account the intricacies of each language—e.g.,
possessive forms have different agreement rules in
English and in Romance languages;9 those, on the
other hand, have clitic pronouns that are absent in
English. Feature weights that promote certain En-
glish agreement relations may then harm perfor-
mance more than they help.
</bodyText>
<subsectionHeader confidence="0.989899">
5.3 Baseline #2: Bitext Direct Projection
</subsectionHeader>
<bodyText confidence="0.999901857142857">
Another popular strategy for cross-lingual learn-
ing is bitext direct projection, which consists in
projecting annotations through parallel data in
the source and target languages (Yarowsky et al.,
2001; Hwa et al., 2005). This is essentially the
same as Algorithm 1, except that line 4 is replaced
by simple supervised learning, via a minimization
</bodyText>
<footnote confidence="0.990840666666667">
9For example, in Figure 1, their agrees in number with
the possessor (the alveoli), but the corresponding sua agrees
in number and gender with the thing possessed (func¸˜ao).
</footnote>
<page confidence="0.988355">
1433
</page>
<bodyText confidence="0.99997225">
of the loss function in Eq. 4 with `2-regularization.
This procedure has the disadvantage of being very
sensitive to annotation errors, as we shall see. For
Portuguese, this baseline is a near-reproduction of
Souza and Or˘asan (2011)’s work, discussed in §6.
The third and eighth rows in Table 3 show
that this baseline is stronger than the delexicalized
baseline, but still 6–8 points away from the super-
vised systems. This gap is due to a mix of two
factors: prediction errors in the English side of
the bitext, and missing alignments. Indeed, when
automatic alignments are used, false negatives for
coreferent pairs of mentions are common, due to
words that have not been aligned with sufficiently
high confidence. The direct projection method is
not robust to these annotation errors.
</bodyText>
<subsectionHeader confidence="0.980292">
5.4 Baseline #3: Vanilla PR
</subsectionHeader>
<bodyText confidence="0.999990470588236">
Our last baseline is a vanilla PR approach; this
is an adaptation of the procedure carried out by
Ganchev and Das (2013) to our coreference reso-
lution problem. The motivation is to increase the
robustness of bitext projection to annotation er-
rors, which we do by applying the soft constraints
in §4.4. We seek a saddle-point of the PR objec-
tive by running 20 epochs of SGD, alternating w-
updates and u-updates. The best results in the dev-
set were obtained with q1 = 1.0 and q2 = 0.9.
By looking at the fourth and ninth rows of Ta-
ble 3, we observe that vanilla PR manages to re-
duce the gap to supervised systems, obtaining con-
sistent gains over the bitext projection baseline
(with the exception of the Portuguese dev-set).
This confirms the ability of PR methods to handle
annotation mistakes in a robust manner.
</bodyText>
<subsectionHeader confidence="0.987665">
5.5 Our Proposal: Softmax-Margin PR
</subsectionHeader>
<bodyText confidence="0.999896117647059">
Finally, the fifth and last rows in Table 3 show the
performance of our systems trained with softmax-
margin PR, as described in §4.1. We optimized the
loss function in Eq. 11 with γ = 1.0 by running 20
epochs of SGD, setting u1 = +oo and u2 = 1.0
(cf. §4.4)—the last value was tuned in the dev-set.
As shown in Figure 2, this penalized variant was
more effective than the saddle point formulation.
From Table 3, we observe that softmax-margin
PR consistently beats all the baselines, narrow-
ing the gap with respect to supervised systems to
about 5 points for Spanish, and 2–3 points for Por-
tuguese. Gains over the vanilla PR procedure (the
strongest baseline) lie in the range 0.5–3%. These
gains come from the ability of softmax-margin PR
to handle task-specific cost functions, enabling a
better management of precision/recall tradeoffs.
</bodyText>
<subsectionHeader confidence="0.962298">
5.6 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999989042553192">
We carried out some error analysis, focused on
the Spanish development dataset, to better under-
stand where the improvements of softmax-margin
PR come from. The main conclusions carry out to
the Portuguese case, with a few exceptions, mostly
due to different human annotation criteria.
Table 4 shows the precision and recall scores
for mention prediction and the different corefer-
ence evaluation metrics. Note that all systems pre-
dict the same candidate mentions; however a final
post-processing discards all mentions that ended
up in singleton entities, for compliance with the
official scorer. Therefore, the mention prediction
score reflects how well a system does in predicting
if a mention is anaphoric or not. The first thing to
note is that the PR methods, due to their ability
to create new links during training (via constraint
#2) tend to predict fewer singletons than the direct
projection method. Indeed, we observe that soft
max-margin PR achieves 47.1% mention predic-
tion recall, which is more than 5% above the di-
rect projection method, and 10% above the delex-
icalized transfer method. Note also that, while
the vanilla PR method achieves higher recall than
the two other baselines, it is still almost 5% be-
low the system trained with soft-max margin PR.
This is because vanilla PR does not benefit from
the cost function in §4.3—such cost is able to pe-
nalize false non-anaphoric mentions and encour-
age larger clusters, allowing softmax-margin PR
to achieve a better precision-recall trade-off. From
Table 4, we can see that this improvement in men-
tion recall consistently translates into higher recall
for the MUC, B3 and CEAF, coreference metrics.
Further analysis revealed that a major source of
error for the delexicalized baseline is its inabil-
ity to handle pronominal mentions robustly across
languages—as hinted in footnote 9. In practice,
we found the delexicalized systems to be quite
conservative with possessive pronouns: for the
Spanish dataset, where the vast majority of pos-
sessive pronouns are anaphoric, the delexicalized
model incorrectly predicts 53.3% of these pro-
nouns as non-anaphoric. The direct projection
model is slightly less conservative, missing 30.1%
of the possessives (arguably due to its inability to
recover missing links in the projected data, dur-
</bodyText>
<page confidence="0.976756">
1434
</page>
<table confidence="0.9999352">
Mention MUC B3 CEAFe
delex. 37.1 / 62.2 25.6 / 46.5 19.6 / 45.7 27.9 / 39.5
dir. proj. 41.7 / 77.5 29.3 / 60.4 19.2 / 69.5 31.8 / 47.9
vanilla PR 42.2 / 78.0 30.9 / 62.3 23.2 / 61.7 31.9 / 48.8
our PR 47.1 / 74.1 33.7 / 57.1 26.0 / 56.1 34.9 / 46.7
</table>
<tableCaption confidence="0.987208">
Table 4: Recall/precision scores for mention prediction,
MUC, B3 and CEAFe, all computed in the Spanish dev set.
</tableCaption>
<bodyText confidence="0.999774666666667">
ing training). By comparison, the vanilla and soft-
max margin PR models only miss 4.9% and 3.4%
of the possessives, respectively. In Portuguese,
where many possessives are not annotated in the
gold data, we observe a similar but much less pro-
nounced trend.
</bodyText>
<sectionHeader confidence="0.999878" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999948547619048">
While multilingual coreference resolution has
been the subject of recent SemEval and CoNLL
shared tasks, no submitted system attempted
cross-lingual training. As shown by Recasens and
Hovy (2010), language-specific issues pose a chal-
lenge, due to phenomena as pronoun dropping and
grammatical gender that are absent in English but
exist in other languages. We have discussed some
of these issues in the scope of the present work.
Harabagiu and Maiorano (2000) and Postolache
et al. (2006) projected English corpora to Roma-
nian to bootstrap human annotation, either manu-
ally or via automatic alignments. Rahman and Ng
(2012) applied translation-based projection at test
time (but require an external translation service).
Hardmeier et al. (2013) addressed the related task
of cross-lingual pronoun prediction. While all
these approaches help alleviate the corpus annota-
tion bottleneck, none resulted in a full coreference
resolver, which our work accomplished.
The work most related with ours is Souza and
Or˘asan (2011), who also used parallel data to
transfer an English coreference resolver to Por-
tuguese, but could not beat a simple baseline that
clusters together mentions with the same head.
Their approach is similar to our bitext direct pro-
jection baseline, except that they used Reconcile
(Stoyanov et al., 2010) instead of the Berkeley
Coreference System, and a smaller version of the
FAPESP corpus. We have shown that our softmax-
margin PR procedure is superior to this approach.
Discriminative PR has been proposed by
Ganchev et al. (2010). The same idea underlies
the generalized expectation criterion (Mann and
McCallum, 2010; Wang and Manning, 2014). An
SGD algorithm for solving the resulting saddle
point problem has been proposed by Liang et al.
(2009), and used by Ganchev and Das (2013) for
cross-lingual learning of sequence models. We ex-
tended this framework in two aspects: by incorpo-
rating a task-specific cost in the objective function,
and by formulating a penalized variant of PR.
</bodyText>
<sectionHeader confidence="0.998261" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.99997725">
We presented a framework for cross-lingual trans-
fer of coreference resolvers. Our method uses
word-aligned bitext to project information from
the source to the target language. Robust-
ness to projection errors was achieved via a
PR framework, which we generalized to handle
task-specific costs, yielding softmax-margin PR.
We also proposed a penalized formulation that
is effective for a small number of corpus-based
constraints. Empirical gains were shown over
three popular cross-lingual methods: delexicalized
transfer, bitext direct projection, and vanilla PR.
</bodyText>
<sectionHeader confidence="0.997238" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999963555555556">
I would like to thank the reviewers for their
helpful comments, Jos´e Guilherme Camargo de
Souza for pointing to existing datasets, and Mar-
iana Almeida for valuable feedback. This work
was partially supported by the EU/FEDER pro-
gramme, QREN/POR Lisboa (Portugal), under
the Intelligo project (contract 2012/24803), and
by the FCT grants UID/EEA/50008/2013 and
PTDC/EEI-SII/2312/2012.
</bodyText>
<subsectionHeader confidence="0.820537">
A Proof of Proposition 1
</subsectionHeader>
<bodyText confidence="0.9653635">
Let us fix w and see how to evaluate KL(Q||p&apos;w) _
minqEQ KL(qIIp&apos; w). We have:
</bodyText>
<equation confidence="0.934502">
KL(qIIp&apos;w) _ −H(q) − PY q(Y) log p&apos;w(Y|X)
_ −H(q) + Pn log Z&apos;(w, x(n)) −
PY q(Y)(wTf(X, Y) + `(Y)),
where `(Y) :_ PNn=1 `(y, Y(E(n))) and f(X, Y) :_
PN n=1 f(x(n), y(n)). Introducing Lagrange multipliers u for
the posterior constraints, we get the Lagrangian function:
L(q, u) _ −H(q) + Pn log Z&apos;(w, x(n)) − bTu
− PY q(Y)(wTf(X, Y)+`(Y)−uTg(X, Y)).
</equation>
<bodyText confidence="0.99988875">
By standard variational arguments (namely, Fenchel duality
between the the log-partition function and the negative en-
tropy; see e.g. Martins et al. (2010)), we have that the optimal
q* that minimizes the Lagrangian is
</bodyText>
<equation confidence="0.9826785">
ewTf(X,Y)+`(Y)_Tg(X,Y)
QNn=1 Z&apos;u(w, x(n)) .
Plugging this in the Lagrangian yields Eq. 8.
q*(Y) _
</equation>
<page confidence="0.985311">
1435
</page>
<sectionHeader confidence="0.983644" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999587669565217">
Mariana S. C. Almeida, Cl´audia Pinto, Helena Figueira, Pe-
dro Mendes, and Andr´e F. T. Martins. 2015. Aligning
opinions: Cross-lingual opinion mining with dependen-
cies. In Proc. of the Annual Meeting of the Association
for Computational Linguistics.
Giuseppe Attardi, Stefano Dei Rossi, and Maria Simi. 2010.
TANL-1: coreference resolution by parse analysis and
similarity clustering. In Proc. of the International Work-
shop on Semantic Evaluation.
Wilker Aziz and Lucia Specia. 2011. Fully automatic com-
pilation of a Portuguese-English parallel corpus for statis-
tical machine translation. In STIL 2011.
Amit Bagga and Breck Baldwin. 1998. Algorithms for scor-
ing coreference chains. In Proc. of International Confer-
ence on Language Resources and Evaluation: Workshop
on Linguistics Coreference.
Eric Bengtson and Dan Roth. 2008. Understanding the value
of features for coreference resolution. In Proc. of Empiri-
cal Methods in Natural Language Processing.
Shane Bergsma and Dekang Lin. 2006. Bootstrapping path-
based pronoun resolution. In Proc. of the Annual Meeting
of the Association for Computational Linguistics.
Sandra Collovini, Thiago Carbonel, Juliana Thiesen Fuchs,
Jorge C´esar Coelho, L´ucia Rino, and Renata Vieira. 2007.
Summ-it: Um corpus anotado com informac¸˜oes discursi-
vas visando a sumarizac¸˜ao autom´atica. In Workshop em
Tecnologia da Informac¸˜ao e da Linguagem Humana.
Pascal Denis and Jason Baldridge. 2008. Specialized models
and ranking for coreference resolution. In Proc. of Empir-
ical Methods in Natural Language Processing.
Greg Durrett and Dan Klein. 2013. Easy victories and uphill
battles in coreference resolution. In Proc. of Empirical
Methods in Natural Language Processing.
Greg Durrett, David Hall, and Dan Klein. 2013. Decentral-
ized entity-level modeling for coreference resolution. In
Proc. of Annual Meeting of the Association for Computa-
tional Linguistics.
Eraldo Rezende Fernandes, C´ıcero Nogueira dos Santos, and
Ruy Luiz Milidi´u. 2012. Latent structure perceptron with
feature induction for unrestricted coreference resolution.
In Joint Conference on EMNLP and CoNLL-Shared Task,
pages 41–48.
Kuzman Ganchev and Dipanjan Das. 2013. Cross-lingual
discriminative learning of sequence models with posterior
regularization. In Proc. of Empirical Methods in Natural
Language Processing.
Kuzman Ganchev, Jo˜ao Grac¸a, Jennifer Gillenwater, and Ben
Taskar. 2010. Posterior regularization for structured latent
variable models. Journal of Machine Learning Research,
11:2001–2049.
Kevin Gimpel and Noah A. Smith. 2010. Softmax-Margin
CRFs: Training Log-Linear Models with Loss Functions.
In NAACL.
Aria Haghighi and Dan Klein. 2007. Unsupervised coref-
erence resolution in a nonparametric bayesian model. In
Proc. of Annual Meeting of the Association for Computa-
tional Linguistics.
Aria Haghighi and Dan Klein. 2010. Coreference resolution
in a modular, entity-centered model. In Proc. of Annual
Conference of the North American Chapter of the Associ-
ation for Computational Linguistics.
Sanda M Harabagiu and Steven J Maiorano. 2000. Multilin-
gual coreference resolution. In Proc. of the Conference on
Applied Natural Language Processing.
Christian Hardmeier, J¨org Tiedemann, and Joakim Nivre.
2013. Latent anaphora resolution for cross-lingual pro-
noun prediction. In Proc. of Empirical Methods in Natural
Language Processing.
Karl Moritz Hermann and Phil Blunsom. 2014. Multilingual
Models for Compositional Distributional Semantics. In
Proc. of the Annual Meeting of the Association for Com-
putational Linguistics.
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas,
and Okan Kolak. 2005. Bootstrapping parsers via syn-
tactic projection across parallel texts. Natural language
engineering, 11(3):311–325.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment
by agreement. In Proc. of North American Chapter of the
Association of Computational Linguistics.
Percy Liang, Michael I Jordan, and Dan Klein. 2009. Learn-
ing from measurements in exponential families. In Proc.
of International Conference on Machine Learning, pages
641–648.
Xiaoqiang Luo. 2005. On coreference resolution perfor-
mance metrics. In Proc. of Empirical Methods in Natu-
ral Language Processing. Association for Computational
Linguistics.
Gideon Mann and Andrew McCallum. 2010. General-
ized expectation criteria for semi-supervised learning with
weakly labeled data. Journal of Machine Learning Re-
search, 11:955–984.
Andr´e F. T Martins, Noah A. Smith, Eric P. Xing, Pedro
M. Q. Aguiar, and M´ario A. T. Figueiredo. 2010. Turbo
Parsers: Dependency Parsing by Approximate Variational
Inference. In Proc. ofEmpirical Methods for Natural Lan-
guage Processing.
Andr´e F. T Martins, Miguel B. Almeida, and Noah A.
Smith. 2013. Turning on the turbo: Fast third-order non-
projective turbo parsers. In Proc. of the Annual Meeting
of the Association for Computational Linguistics.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-
source transfer of delexicalized dependency parsers. In
Proc. of Empirical Methods in Natural Language Process-
ing.
Vincent Ng and Claire Cardie. 2002. Improving machine
learning approaches to coreference resolution. In Proc.
of the Annual Meeting on Association for Computational
Linguistics.
Vincent Ng. 2008. Unsupervised models for coreference res-
olution. In Proc. of Empirical Methods in Natural Lan-
guage Processing.
Slav Petrov and Dan Klein. 2007. Improved inference for
unlexicalized parsing. In Proc. of Annual Meeting of the
North American Chapter of the Association for Computa-
tional Linguistics, pages 404–411.
</reference>
<page confidence="0.833479">
1436
</page>
<reference confidence="0.999452094736842">
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A
universal part-of-speech tagset. In Proc. of LREC.
Oana Postolache, Dan Cristea, and Constantin Orasan. 2006.
Transferring coreference chains through word alignment.
In Proc. of the International Conference on Language Re-
sources and Evaluation.
Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga
Uryupina, and Yuchen Zhang. 2012. CoNLL-2012
Shared Task: Modeling multilingual unrestricted corefer-
ence in OntoNotes. In Proc. of the Conference on Compu-
tational Natural Language Learning: Shared Task.
Sameer Pradhan, Xiaoqiang Luo, Marta Recasens, Eduard
Hovy, Vincent Ng, and Michael Strube. 2014. Scoring
coreference partitions of predicted mentions: A reference
implementation. In Proc. of the Annual Meeting of the
Association for Computational Linguistics.
Karthik Raghunathan, Heeyoung Lee, Sudarshan Rangara-
jan, Nathanael Chambers, Mihai Surdeanu, Dan Jurafsky,
and Christopher Manning. 2010. A multi-pass sieve for
coreference resolution. In Proc. of Empirical Methods in
Natural Language Processing.
Altaf Rahman and Vincent Ng. 2011. Narrowing the
modeling gap: A cluster-ranking approach to coreference
resolution. Journal of Artificial Intelligence Research,
40(1):469–521.
Altaf Rahman and Vincent Ng. 2012. Translation-based pro-
jection for multilingual coreference resolution. In Proc.
of the Conference of the North American Chapter of the
Association for Computational Linguistics.
Marta Recasens and Eduard Hovy. 2010. Coreference res-
olution across corpora: Languages, coding schemes, and
preprocessing information. In Proc. of the Annual Meet-
ing of the Association for Computational Linguistics.
Marta Recasens and M Ant`onia Marti. 2010. Ancora-co:
Coreferentially annotated corpora for spanish and catalan.
Language resources and evaluation, 44(4):315–345.
Marta Recasens, Lluis M`arquez, Emili Sapena, M Ant`onia
Marti, Mariona Taul´e, V´eronique Hoste, Massimo Poesio,
and Yannick Versley. 2010. Semeval-2010 task 1: Coref-
erence resolution in multiple languages. In Proc. of the
International Workshop on Semantic Evaluation.
Noah A Smith and Jason Eisner. 2005. Contrastive es-
timation: Training log-linear models on unlabeled data.
In Proc. of Annual Meeting on Association for Computa-
tional Linguistics.
Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong
Lim. 2001. A machine learning approach to corefer-
ence resolution of noun phrases. Computational linguis-
tics, 27(4):521–544.
Jos´e Guilherme Camargo de Souza and Constantin Or˘asan.
2011. Can projected chains in parallel corpora help coref-
erence resolution? In Anaphora Processing and Applica-
tions, pages 59–69. Springer.
Veselin Stoyanov, Claire Cardie, Nathan Gilbert, Ellen Riloff,
David Buttler, and David Hysom. 2010. Coreference res-
olution with reconcile. In Proc. of the Annual Meeting of
the Association for Computational Linguistics.
Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit.
2012. Cross-lingual word clusters for direct transfer of
linguistic structure. In Proc. of the North American Chap-
ter of the Association for Computational Linguistics.
Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan McDon-
ald, and Joakim Nivre. 2013. Token and type constraints
for cross-lingual part-of-speech tagging. Transactions of
the Association for Computational Linguistics, 1:1–12.
Ivan Titov and Alexandre Klementiev. 2012. Cross-lingual
induction of semantic roles. In Proc. of the Annual Meet-
ing of the Association for Computational Linguistics.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word
representations: a simple and general method for semi-
supervised learning. In Proc. of the Annual Meeting of the
Association for Computational Linguistics.
Yannick Versley, Simone Paolo Ponzetto, Massimo Poesio,
Vladimir Eidelman, Alan Jern, Jason Smith, Xiaofeng
Yang, and Alessandro Moschitti. 2008. Bart: A modular
toolkit for coreference resolution. In Proc. of the Annual
Meeting of the Association for Computational Linguistics:
Demo Session.
Marc Vilain, John Burger, John Aberdeen, Dennis Connolly,
and Lynette Hirschman. 1995. A model-theoretic corefer-
ence scoring scheme. In Proc. of the Conference on Mes-
sage Understanding, pages 45–52. Association for Com-
putational Linguistics.
Mengqiu Wang and Chris Manning. 2014. Cross-lingual
projected expectation regularization for weakly super-
vised learning. Transactions of the Association for Com-
putational Linguistics, 2:55–66.
David Yarowsky, Grace Ngai, and Richard Wicentowski.
2001. Inducing multilingual text analysis tools via robust
projection across aligned corpora. In Proc. of the First In-
ternational Conference on Human Language Technology
Research.
Daniel Zeman and Philip Resnik. 2008. Cross-language
parser adaptation between related languages. In IJCNLP,
pages 35–42.
</reference>
<page confidence="0.993895">
1437
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.784347">
<title confidence="0.999623">Transferring Coreference Resolvers with Posterior Regularization</title>
<author confidence="0.975416">F T</author>
<affiliation confidence="0.9011655">Labs, Alameda D. Afonso Henriques, 41, 2°, 1000-123 Lisboa, de Instituto Superior T´ecnico, 1049-001 Lisboa,</affiliation>
<email confidence="0.988494">atm@priberam.pt</email>
<abstract confidence="0.9979985">We propose a cross-lingual framework for learning coreference resolvers for resource-poor target languages, given a resolver in a source language. Our method uses word-aligned bitext to project information from the source to the target. To handle task-specific costs, we propose a softmax-margin variant of posterior regularization, and we use it to achieve robustness to projection errors. We show empirically that this strategy outperforms competitive cross-lingual methods, such as delexicalized transfer with bilingual word embeddings, bitext direct projection, and vanilla posterior regularization.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mariana S C Almeida</author>
<author>Cl´audia Pinto</author>
<author>Helena Figueira</author>
<author>Pedro Mendes</author>
<author>Andr´e F T Martins</author>
</authors>
<title>Aligning opinions: Cross-lingual opinion mining with dependencies.</title>
<date>2015</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2208" citStr="Almeida et al., 2015" startWordPosition="319" endWordPosition="322">erence resolution as a way of transferring information from a rich-resource language to build coreference resolvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese. We build upon the recent successes of cross-lingual learning in NLP, which proved quite effective in several structured prediction tasks, such as POS tagging (T¨ackstr¨om et al., 2013), named entity recognition (Wang and Manning, 2014), dependency parsing (McDonald et al., 2011), semantic role labeling (Titov and Klementiev, 2012), and fine-grained opinion mining (Almeida et al., 2015). The potential of these techniques, however, has never been fully exploited in coreference resolution (despite some existing work, reviewed in §6, but none resulting in an endto-end coreference resolver). We bridge this gap by proposing a simple learning-based method with weak supervision, based on posterior regularization (Ganchev et al., 2010). We adapt this framework to handle softmax-margin objective functions (Gimpel and Smith, 2010), leading to softmax-margin posterior regularization (§4). This step, while fairly simple, opens the door for incorporating taskspecific cost functions, whic</context>
</contexts>
<marker>Almeida, Pinto, Figueira, Mendes, Martins, 2015</marker>
<rawString>Mariana S. C. Almeida, Cl´audia Pinto, Helena Figueira, Pedro Mendes, and Andr´e F. T. Martins. 2015. Aligning opinions: Cross-lingual opinion mining with dependencies. In Proc. of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giuseppe Attardi</author>
<author>Stefano Dei Rossi</author>
<author>Maria Simi</author>
</authors>
<title>TANL-1: coreference resolution by parse analysis and similarity clustering.</title>
<date>2010</date>
<booktitle>In Proc. of the International Workshop on Semantic Evaluation.</booktitle>
<contexts>
<context position="23715" citStr="Attardi et al. (2010)" startWordPosition="3906" endWordPosition="3909">for the level of performance we expect to achieve with the weakly-supervised systems. An important step in coreference resolution systems is mention prediction. For English, mention spans were predicted from the noun phrases given by the Berkeley parser (Petrov and Klein, 2007), the same procedure as Durrett and Klein (2013). For Spanish and Portuguese, this prediction relied on the output of the dependency parser, using a simple heuristic: besides pronouns, each maximal span formed by contiguous descendants of a noun becomes a candidate mention. This heuristic is quite effective, as shown by Attardi et al. (2010). 5.1 Supervised Systems Table 2 shows the performance of supervised systems for English, Spanish and Portuguese. All optimize Eq. 4 appended with an extra regularization term γ2 kwk2, by running 20 epochs of stochastic gradient descent (SGD; we set γ = 1.0 and selected the best epoch using the dev-set). All lexicalized systems use the same features as the SURFACE model of Durrett and Klein (2013), plus features for gender and number.7 We collected a list of pronouns for all languages along with their gender, number, and person information. For English, we trained on the WSJ portion of the Ont</context>
<context position="25898" citStr="Attardi et al., 2010" startWordPosition="4268" endWordPosition="4271">oper mentions were obtained from the statistics collected by Bergsma and Lin (2006). For Spanish and Portuguese we used a simple heuristic for nominal mentions, based on the determiner preceding the noun (when there is one). 8We point out that the supervised Spanish system we present here is strong enough to outperform all participating systems in the SemEval 2010’s closed regular track. When trained on the original Spanish SemEval data (with zero- and relative pronoun anaphoras) and evaluated in the provided scorer, it achieves 53.0% averaged F1 in the test partition; for comparison, TALN-1 (Attardi et al., 2010), the best system at the shared task, achieved 49.6% averaged F1. 1432 MUC Dev Avg. MUC Test Avg. B3 CEAF, B3 CEAF, EN lexicalized 58.35 50.75 52.08 53.73 59.07 49.25 48.78 52.37 EN delexicalized, no embed. 56.59 48.81 49.95 51.78 55.96 46.94 46.19 49.70 EN delexicalized, emb. EN-ES 57.55 49.83 51.21 52.86 59.00 49.25 49.00 52.42 EN delexicalized, emb. EN-PT 57.91 49.67 51.01 52.86 58.03 48.16 48.33 51.51 ES lexicalized 48.24 40.97 43.59 44.27 47.03 40.68 44.09 43.93 PT lexicalized 35.60 34.47 42.56 37.54 41.61 36.91 40.96 39.83 Table 2: Results for the supervised systems. We show also the per</context>
</contexts>
<marker>Attardi, Rossi, Simi, 2010</marker>
<rawString>Giuseppe Attardi, Stefano Dei Rossi, and Maria Simi. 2010. TANL-1: coreference resolution by parse analysis and similarity clustering. In Proc. of the International Workshop on Semantic Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wilker Aziz</author>
<author>Lucia Specia</author>
</authors>
<title>Fully automatic compilation of a Portuguese-English parallel corpus for statistical machine translation.</title>
<date>2011</date>
<booktitle>In STIL</booktitle>
<contexts>
<context position="5821" citStr="Aziz and Specia (2011)" startWordPosition="847" endWordPosition="850">s are projected to the target side of the parallel data (line 3), inducing an automatic (and noisy) training dataset for the foreign language. Finally, a coreference system is trained in this dataset with the aid of softmax-margin posterior regularization (line 4). We next detail all the datasets and tools involved in our experimental setup. Table 1 provides a summary, along with some statistics. Parallel Data. As parallel data, we use a sentence-aligned trilingual (English-PortugueseSpanish) parallel corpus based on the scientific news Brazilian magazine Revista Pesquisa FAPESP, collected by Aziz and Specia (2011).1 We preprocessed this dataset as follows. We labeled the English side with the Berkeley Coreference Resolution system v1.0, using the provided English model (Durrett and Klein, 2013). Then, we computed word alignments using the Berkeley aligner (Liang et al., 2006), intersected them and filtered out all the alignments whose confi1We found that other commonly used parallel data (such as Europarl or the UN corpus) have a predominance of direct speech that is not suitable for our newswire test domain, so we decided not to use these data. Dataset # Doc. # Sent. # Tok. EN OntoNotes (train) 2,374 </context>
</contexts>
<marker>Aziz, Specia, 2011</marker>
<rawString>Wilker Aziz and Lucia Specia. 2011. Fully automatic compilation of a Portuguese-English parallel corpus for statistical machine translation. In STIL 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Bagga</author>
<author>Breck Baldwin</author>
</authors>
<title>Algorithms for scoring coreference chains.</title>
<date>1998</date>
<booktitle>In Proc. of International Conference on Language Resources and Evaluation: Workshop on Linguistics Coreference.</booktitle>
<contexts>
<context position="26649" citStr="Bagga and Baldwin, 1998" startWordPosition="4389" endWordPosition="4392">zed 58.35 50.75 52.08 53.73 59.07 49.25 48.78 52.37 EN delexicalized, no embed. 56.59 48.81 49.95 51.78 55.96 46.94 46.19 49.70 EN delexicalized, emb. EN-ES 57.55 49.83 51.21 52.86 59.00 49.25 49.00 52.42 EN delexicalized, emb. EN-PT 57.91 49.67 51.01 52.86 58.03 48.16 48.33 51.51 ES lexicalized 48.24 40.97 43.59 44.27 47.03 40.68 44.09 43.93 PT lexicalized 35.60 34.47 42.56 37.54 41.61 36.91 40.96 39.83 Table 2: Results for the supervised systems. We show also the performance of delexicalized English systems, with and without cross-lingual embeddings. Shown are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), and CEAF, (Luo, 2005), as well their averaged F1 scores, all computed using the reference implementation of the CoNLL scorer (Pradhan et al., 2014). MUC Dev Avg. MUC Test Avg. B3 CEAF, B3 CEAF, ES simple baseline 25.73 24.73 27.89 26.12 26.06 26.12 29.87 27.35 ES baseline #1 (delex. transfer) 33.04 27.47 32.71 31.07 34.35 28.69 34.42 32.49 ES baseline #2 (bitext dir. proj.) 39.42 30.04 38.25 35.90 37.21 29.72 35.97 34.30 ES baseline #3 (vanilla PR) 41.29 33.68 38.56 37.84 39.34 32.95 38.23 36.84 ES softmax-margin PR 42.34 35.53 39.95 39.27 41.22 35.30 39.94 38.82 PT simple baseline 26.04 26.</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Amit Bagga and Breck Baldwin. 1998. Algorithms for scoring coreference chains. In Proc. of International Conference on Language Resources and Evaluation: Workshop on Linguistics Coreference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Bengtson</author>
<author>Dan Roth</author>
</authors>
<title>Understanding the value of features for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="9385" citStr="Bengtson and Roth, 2008" startWordPosition="1447" endWordPosition="1450">ags and dependency parses by using TurboParser (Martins et al., 2013). 3 Coreference Resolution 3.1 Problem Definition and Prior Work In coreference resolution, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e1,... , eE}, where each ej ⊆ M and ej =6 0. The set E must form a partition of M, i.e., we must have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j. A variety of approaches have been proposed to this problem, including entity-centric models (Haghighi and Klein, 2010; Rahman and Ng, 2011; Durrett et al., 2013), pairwise models (Bengtson and Roth, 2008; Versley et al., 2008), greedy rule-based methods (Raghunathan et al., 2010), and mention-ranking decoders (Denis and Baldridge, 2008; Durrett and Klein, 2013). We chose to base our coreference resolvers on this last class of methods, which permit efficient decoding by shifting from entity clusters to latent coreference trees. In particular, the inclusion of lexicalized features by Durrett and Klein (2013) yields nearly state-of-the-art performance with surface information only. Given that our goal is to prototype resolvers for resource-poor languages, this model is a good fit—we next describ</context>
</contexts>
<marker>Bengtson, Roth, 2008</marker>
<rawString>Eric Bengtson and Dan Roth. 2008. Understanding the value of features for coreference resolution. In Proc. of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
</authors>
<title>Bootstrapping pathbased pronoun resolution.</title>
<date>2006</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="25360" citStr="Bergsma and Lin (2006)" startWordPosition="4183" endWordPosition="4186">e of delexicalized systems, i.e., systems where all the lexical features were removed. The second row of Table 2 shows a drop of 2–2.5 points with respect to the lexicalized system. For the third and fourth rows, the lexical features were replaced by bilingual word embeddings (either EnglishSpanish or English-Portuguese; a detailed description of these embeddings will be provided in §5.2). Here the drop is small, and for English-Spanish it looks on par with the lexicalized system. 7For English, the gender and number of nominal and proper mentions were obtained from the statistics collected by Bergsma and Lin (2006). For Spanish and Portuguese we used a simple heuristic for nominal mentions, based on the determiner preceding the noun (when there is one). 8We point out that the supervised Spanish system we present here is strong enough to outperform all participating systems in the SemEval 2010’s closed regular track. When trained on the original Spanish SemEval data (with zero- and relative pronoun anaphoras) and evaluated in the provided scorer, it achieves 53.0% averaged F1 in the test partition; for comparison, TALN-1 (Attardi et al., 2010), the best system at the shared task, achieved 49.6% averaged </context>
</contexts>
<marker>Bergsma, Lin, 2006</marker>
<rawString>Shane Bergsma and Dekang Lin. 2006. Bootstrapping pathbased pronoun resolution. In Proc. of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Collovini</author>
<author>Thiago Carbonel</author>
<author>Juliana Thiesen Fuchs</author>
<author>Jorge C´esar Coelho</author>
<author>L´ucia Rino</author>
<author>Renata Vieira</author>
</authors>
<title>Summ-it: Um corpus anotado com informac¸˜oes discursivas visando a sumarizac¸˜ao autom´atica.</title>
<date>2007</date>
<booktitle>In Workshop em Tecnologia da Informac¸˜ao e da Linguagem Humana.</booktitle>
<contexts>
<context position="8439" citStr="Collovini et al., 2007" startWordPosition="1276" endWordPosition="1279">e use the AnCora dataset (Recasens and Mart´ı, 2010) provided in the SemEval 2010 coreference task, which we preprocessed as follows. We split all MWEs into individual tokens (for consistency with the other corpora). We also removed the extra gap tokens associated with zeroanaphoric relations, and the anaphoric annotations associated with relative pronouns (e.g., in “[una central de ciclo combinado [que]1 debe empezar 1428 a funcionar en mayo del 2002]1” we removed the nested mention [que]1), since these are not annotated in the English dataset. For Portuguese, we used the Summ-It 3.0 corpus (Collovini et al., 2007), which contains 50 documents annotated with coreferences, from the science section of the Folha de S˜ao Paulo newspaper. This dataset is much smaller than OntoNotes and AnCora, as shown in Table 1. We split the data into train, development, and test partitions. For both Spanish and Portuguese, we obtained automatic POS tags and dependency parses by using TurboParser (Martins et al., 2013). 3 Coreference Resolution 3.1 Problem Definition and Prior Work In coreference resolution, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e</context>
</contexts>
<marker>Collovini, Carbonel, Fuchs, Coelho, Rino, Vieira, 2007</marker>
<rawString>Sandra Collovini, Thiago Carbonel, Juliana Thiesen Fuchs, Jorge C´esar Coelho, L´ucia Rino, and Renata Vieira. 2007. Summ-it: Um corpus anotado com informac¸˜oes discursivas visando a sumarizac¸˜ao autom´atica. In Workshop em Tecnologia da Informac¸˜ao e da Linguagem Humana.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Jason Baldridge</author>
</authors>
<title>Specialized models and ranking for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="9519" citStr="Denis and Baldridge, 2008" startWordPosition="1465" endWordPosition="1468">k In coreference resolution, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e1,... , eE}, where each ej ⊆ M and ej =6 0. The set E must form a partition of M, i.e., we must have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j. A variety of approaches have been proposed to this problem, including entity-centric models (Haghighi and Klein, 2010; Rahman and Ng, 2011; Durrett et al., 2013), pairwise models (Bengtson and Roth, 2008; Versley et al., 2008), greedy rule-based methods (Raghunathan et al., 2010), and mention-ranking decoders (Denis and Baldridge, 2008; Durrett and Klein, 2013). We chose to base our coreference resolvers on this last class of methods, which permit efficient decoding by shifting from entity clusters to latent coreference trees. In particular, the inclusion of lexicalized features by Durrett and Klein (2013) yields nearly state-of-the-art performance with surface information only. Given that our goal is to prototype resolvers for resource-poor languages, this model is a good fit—we next describe it in detail. 3.2 Latent Coreference Tree Models Let x be a document containing M mentions, sorted from left to right. We associate </context>
</contexts>
<marker>Denis, Baldridge, 2008</marker>
<rawString>Pascal Denis and Jason Baldridge. 2008. Specialized models and ranking for coreference resolution. In Proc. of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Dan Klein</author>
</authors>
<title>Easy victories and uphill battles in coreference resolution.</title>
<date>2013</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="3141" citStr="Durrett and Klein, 2013" startWordPosition="455" endWordPosition="458">r regularization (Ganchev et al., 2010). We adapt this framework to handle softmax-margin objective functions (Gimpel and Smith, 2010), leading to softmax-margin posterior regularization (§4). This step, while fairly simple, opens the door for incorporating taskspecific cost functions, which are important to manage the precision/recall trade-offs in coreference resolution systems. We show that the resulting problem involves optimizing the difference of two cost-augmented log-partition functions, making a bridge with supervised systems based on latent coreference trees (Fernandes et al., 2012; Durrett and Klein, 2013), reviewed in §3. Inspired by this idea, we consider a simple penalized variant of posterior regularization that tunes the Lagrange multipliers directly, bypassing the saddle-point problem of existing EM and alternating stochastic gradient algorithms (Ganchev et al., 2010; Liang et al., 2009). Experiments (§5) show that the proposed method outperforms commonly used cross-lingual approaches, such as delexicalized transfer with bilingual embeddings, direct projection, and “vanilla” posterior regularization. 2 Architecture and Experimental Setup Our methodology, outlined as Algorithm 1, is inspir</context>
<context position="6005" citStr="Durrett and Klein, 2013" startWordPosition="876" endWordPosition="879">d in this dataset with the aid of softmax-margin posterior regularization (line 4). We next detail all the datasets and tools involved in our experimental setup. Table 1 provides a summary, along with some statistics. Parallel Data. As parallel data, we use a sentence-aligned trilingual (English-PortugueseSpanish) parallel corpus based on the scientific news Brazilian magazine Revista Pesquisa FAPESP, collected by Aziz and Specia (2011).1 We preprocessed this dataset as follows. We labeled the English side with the Berkeley Coreference Resolution system v1.0, using the provided English model (Durrett and Klein, 2013). Then, we computed word alignments using the Berkeley aligner (Liang et al., 2006), intersected them and filtered out all the alignments whose confi1We found that other commonly used parallel data (such as Europarl or the UN corpus) have a predominance of direct speech that is not suitable for our newswire test domain, so we decided not to use these data. Dataset # Doc. # Sent. # Tok. EN OntoNotes (train) 2,374 48,762 1,007,359 EN OntoNotes (dev) 303 6,894 136,257 EN OntoNotes (test) 322 8,262 152,728 ES FAPESP (aligned) 2,704 142,633 3,840,936 ES AnCora (train) 875 8,999 295,276 ES AnCora (d</context>
<context position="9545" citStr="Durrett and Klein, 2013" startWordPosition="1469" endWordPosition="1472">, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e1,... , eE}, where each ej ⊆ M and ej =6 0. The set E must form a partition of M, i.e., we must have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j. A variety of approaches have been proposed to this problem, including entity-centric models (Haghighi and Klein, 2010; Rahman and Ng, 2011; Durrett et al., 2013), pairwise models (Bengtson and Roth, 2008; Versley et al., 2008), greedy rule-based methods (Raghunathan et al., 2010), and mention-ranking decoders (Denis and Baldridge, 2008; Durrett and Klein, 2013). We chose to base our coreference resolvers on this last class of methods, which permit efficient decoding by shifting from entity clusters to latent coreference trees. In particular, the inclusion of lexicalized features by Durrett and Klein (2013) yields nearly state-of-the-art performance with surface information only. Given that our goal is to prototype resolvers for resource-poor languages, this model is a good fit—we next describe it in detail. 3.2 Latent Coreference Tree Models Let x be a document containing M mentions, sorted from left to right. We associate to the mth mention a rando</context>
<context position="11440" citStr="Durrett and Klein (2013)" startWordPosition="1797" endWordPosition="1800"> (1) where w is a weight vector, and each f(x, m, ym) is a local feature vector that depends on the document x, the mention m, and its candidate antecedent ym. This model permits a cheap computation of the most likely tree y := arg maxy∈Y(x) pw(y|x): simply compute the best antecedent independently for each mention, and collect them to form a tree. An analogous procedure can be employed to compute the posterior marginals pw(ym|x) for every mention m. Gold coreference tree annotations are rarely available; datasets usually consist of documents annotated with entity clusters, {hx(n),E(n)i}Nn=1. Durrett and Klein (2013) proposed to learn the probabilistic model in Eq. 1 by maximizing conditional log-likelihood, treating the coreference trees as latent variables. They also found advantageous to incorporate a cost function `(y, Y(E)), measuring the extent to which a prediction y differs from the ones that are consistent with the gold entity set E.2 Putting these pieces together, we arrive at the following loss function to be minimized: where p0w is the cost-augmented distribution: p0w(y|x) ∝ pw(y|x)e`(y,Y(E)) . (3) The loss function in Eq. 2 can be seen as a probabilistic analogous of the hinge loss of support</context>
<context position="12846" citStr="Durrett and Klein (2013)" startWordPosition="2037" endWordPosition="2040">tion functions (both convex on w), L(w) = En1 (log Z0(w, x(n)) − log �Z(w, x(n))) (4) above we denoted`` Z0(w, x) = EY∈Y(x) ewTf(x,y)+`(y,Y(E)) (5) �Z(w, x) = Ey∈Y(E) ewTf(x,y), (6) 2A precise definition of this cost is provided in §4.3. (E ) L(w) = − EN n=1 log y∈Y(E(n)) p0 w(y|x(n)) , (2) 1429 where f(x, y) := EMm=1 f(x, m, ym).3 Evaluating the gradient of the loss in Eq. 4 requires computing marginals for the candidate antecedents of each mention, which can be done in a mentionsynchronous fashion. This enables a simple stochastic gradient descent algorithm, which was the procedure taken by Durrett and Klein (2013). Another way of regarding this framework, expressed through the marginalization in Eq. 2, is to “pretend” that the outputs we care about are the actual coreference trees, but that the datasets are only “weakly labeled” with the entity clusters. We build on this point of view in §4.1. 4 Cross-Lingual Coreference Resolution We now adapt the framework above to learn coreference resolvers in a cross-lingual manner. 4.1 Softmax-Margin Posterior Regularization In the weakly supervised case, the training data may only be partially labeled or contain annotation errors. For taking advantage of these d</context>
<context position="20153" citStr="Durrett and Klein (2013)" startWordPosition="3293" endWordPosition="3296">Eq. 6). Intuitively, this formulation pushes probability mass toward structures that respect the constraints in Eq. 7, while moving away from those that have a large task-specific cost. A similar idea, but applied to the generative case, underlies the framework of constrastive estimation (Smith and Eisner, 2005). 4.3 Cost Function Denote by Em the entire coreference chain of the mth mention (so E = U mcM{Em}), and by Msing := {m ∈ M |Em = {m}} the set of mentions that are projected as singleton in the data (we call this gold-singleton mentions). We design a task-specific cost `(y, Y(E)) as in Durrett and Klein (2013) to balance three kinds of mistakes: (i) false anaphora (ym =6 0 while m ∈ Msing); (ii) false new (ym = 0 while m ∈/ Msing); and (iii) wrong link (ym =6 0 but Em =6 Eym). Letting ffFA(ym, E), ffFN(ym, E), and ffWL(gm, E) be indicators for these events, we define a weighted Hamming cost function: `(y, Y(E)) := EMm=1(αFAffFA(&amp;m, E)+ αFNffFN(ym, E) + αWLffWL(ym, E)). We set αFA = 0.0, αFN = 3.0, and αWL = 1.0.6 Since this cost decomposes as a sum over mentions, the computation of cost-augmented marginals (necessary to evaluate the gradient of Eq. 11) can still be done with mention-ranking decoder</context>
<context position="23420" citStr="Durrett and Klein (2013)" startWordPosition="3860" endWordPosition="3863">e compare our coreference resolvers trained with softmax-margin PR (§5.5) with three other weakly-supervised baselines: delexicalized transfer with cross-lingual embeddings (§5.2), bitext projection (§5.3), and vanilla PR (§5.4). We also run fully supervised systems (§5.1), to obtain upper bounds for the level of performance we expect to achieve with the weakly-supervised systems. An important step in coreference resolution systems is mention prediction. For English, mention spans were predicted from the noun phrases given by the Berkeley parser (Petrov and Klein, 2007), the same procedure as Durrett and Klein (2013). For Spanish and Portuguese, this prediction relied on the output of the dependency parser, using a simple heuristic: besides pronouns, each maximal span formed by contiguous descendants of a noun becomes a candidate mention. This heuristic is quite effective, as shown by Attardi et al. (2010). 5.1 Supervised Systems Table 2 shows the performance of supervised systems for English, Spanish and Portuguese. All optimize Eq. 4 appended with an extra regularization term γ2 kwk2, by running 20 epochs of stochastic gradient descent (SGD; we set γ = 1.0 and selected the best epoch using the dev-set).</context>
</contexts>
<marker>Durrett, Klein, 2013</marker>
<rawString>Greg Durrett and Dan Klein. 2013. Easy victories and uphill battles in coreference resolution. In Proc. of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>David Hall</author>
<author>Dan Klein</author>
</authors>
<title>Decentralized entity-level modeling for coreference resolution.</title>
<date>2013</date>
<booktitle>In Proc. of Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9343" citStr="Durrett et al., 2013" startWordPosition="1441" endWordPosition="1444"> Portuguese, we obtained automatic POS tags and dependency parses by using TurboParser (Martins et al., 2013). 3 Coreference Resolution 3.1 Problem Definition and Prior Work In coreference resolution, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e1,... , eE}, where each ej ⊆ M and ej =6 0. The set E must form a partition of M, i.e., we must have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j. A variety of approaches have been proposed to this problem, including entity-centric models (Haghighi and Klein, 2010; Rahman and Ng, 2011; Durrett et al., 2013), pairwise models (Bengtson and Roth, 2008; Versley et al., 2008), greedy rule-based methods (Raghunathan et al., 2010), and mention-ranking decoders (Denis and Baldridge, 2008; Durrett and Klein, 2013). We chose to base our coreference resolvers on this last class of methods, which permit efficient decoding by shifting from entity clusters to latent coreference trees. In particular, the inclusion of lexicalized features by Durrett and Klein (2013) yields nearly state-of-the-art performance with surface information only. Given that our goal is to prototype resolvers for resource-poor languages</context>
</contexts>
<marker>Durrett, Hall, Klein, 2013</marker>
<rawString>Greg Durrett, David Hall, and Dan Klein. 2013. Decentralized entity-level modeling for coreference resolution. In Proc. of Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<title>Eraldo Rezende Fernandes, C´ıcero Nogueira dos Santos, and Ruy Luiz Milidi´u.</title>
<date>2012</date>
<booktitle>In Joint Conference on EMNLP and CoNLL-Shared Task,</booktitle>
<pages>41--48</pages>
<contexts>
<context position="36775" citStr="(2012)" startWordPosition="6048" endWordPosition="6048">l coreference resolution has been the subject of recent SemEval and CoNLL shared tasks, no submitted system attempted cross-lingual training. As shown by Recasens and Hovy (2010), language-specific issues pose a challenge, due to phenomena as pronoun dropping and grammatical gender that are absent in English but exist in other languages. We have discussed some of these issues in the scope of the present work. Harabagiu and Maiorano (2000) and Postolache et al. (2006) projected English corpora to Romanian to bootstrap human annotation, either manually or via automatic alignments. Rahman and Ng (2012) applied translation-based projection at test time (but require an external translation service). Hardmeier et al. (2013) addressed the related task of cross-lingual pronoun prediction. While all these approaches help alleviate the corpus annotation bottleneck, none resulted in a full coreference resolver, which our work accomplished. The work most related with ours is Souza and Or˘asan (2011), who also used parallel data to transfer an English coreference resolver to Portuguese, but could not beat a simple baseline that clusters together mentions with the same head. Their approach is similar </context>
</contexts>
<marker>2012</marker>
<rawString>Eraldo Rezende Fernandes, C´ıcero Nogueira dos Santos, and Ruy Luiz Milidi´u. 2012. Latent structure perceptron with feature induction for unrestricted coreference resolution. In Joint Conference on EMNLP and CoNLL-Shared Task, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Dipanjan Das</author>
</authors>
<title>Cross-lingual discriminative learning of sequence models with posterior regularization.</title>
<date>2013</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="3788" citStr="Ganchev and Das (2013)" startWordPosition="549" endWordPosition="552">d by this idea, we consider a simple penalized variant of posterior regularization that tunes the Lagrange multipliers directly, bypassing the saddle-point problem of existing EM and alternating stochastic gradient algorithms (Ganchev et al., 2010; Liang et al., 2009). Experiments (§5) show that the proposed method outperforms commonly used cross-lingual approaches, such as delexicalized transfer with bilingual embeddings, direct projection, and “vanilla” posterior regularization. 2 Architecture and Experimental Setup Our methodology, outlined as Algorithm 1, is inspired by the recent work of Ganchev and Das (2013) on cross-lingual learning of sequence models. For simplicity, we call the source and tar1427 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1427–1437, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Figure 1: Excerpt of a bitext document with automatic coreference annotations (from FAPESP). The English side had its coreferences resolved by a state-of-the-art system (Durrett and Klein, 2013). The predicted coreference chains {The pulmonary</context>
<context position="16825" citStr="Ganchev and Das (2013)" startWordPosition="2719" endWordPosition="2722">ization problem still amounts to finding a saddle point of an objective function (Eq. 8), which involves the difference of two log-partition functions (Eq. 9). The difference is that these partition functions now incorporate the cost term `(y, Y(E)). If this cost term has a factorization compatible with the features and the constraints, this comes at no additional computational burden. 4We can always reduce the problem to this case by scaling and adding a constant to the constraint feature vectors. 1430 4.2 Penalized Variant In their discriminative PR formulation for learning sequence models, Ganchev and Das (2013) optimize an objective similar to Eq. 8 by alternating stochastic gradient updates with respect to w and u. In their procedure, b was chosen a priori via linear regression (see their Figure 2). Here, we propose a different strategy, based on Proposition 1 and a simple observation: while the constraint values b have a more intuitive meaning than the Lagrange multipliers u (since they may correspond, e.g., to proportions of events observed in the data), choosing these upper bounds is often no easier than tuning u. In this case, a preferable strategy is to specify u directly—this leaves this vari</context>
<context position="31633" citStr="Ganchev and Das (2013)" startWordPosition="5184" endWordPosition="5187">line is stronger than the delexicalized baseline, but still 6–8 points away from the supervised systems. This gap is due to a mix of two factors: prediction errors in the English side of the bitext, and missing alignments. Indeed, when automatic alignments are used, false negatives for coreferent pairs of mentions are common, due to words that have not been aligned with sufficiently high confidence. The direct projection method is not robust to these annotation errors. 5.4 Baseline #3: Vanilla PR Our last baseline is a vanilla PR approach; this is an adaptation of the procedure carried out by Ganchev and Das (2013) to our coreference resolution problem. The motivation is to increase the robustness of bitext projection to annotation errors, which we do by applying the soft constraints in §4.4. We seek a saddle-point of the PR objective by running 20 epochs of SGD, alternating wupdates and u-updates. The best results in the devset were obtained with q1 = 1.0 and q2 = 0.9. By looking at the fourth and ninth rows of Table 3, we observe that vanilla PR manages to reduce the gap to supervised systems, obtaining consistent gains over the bitext projection baseline (with the exception of the Portuguese dev-set)</context>
<context position="37956" citStr="Ganchev and Das (2013)" startWordPosition="6230" endWordPosition="6233">the same head. Their approach is similar to our bitext direct projection baseline, except that they used Reconcile (Stoyanov et al., 2010) instead of the Berkeley Coreference System, and a smaller version of the FAPESP corpus. We have shown that our softmaxmargin PR procedure is superior to this approach. Discriminative PR has been proposed by Ganchev et al. (2010). The same idea underlies the generalized expectation criterion (Mann and McCallum, 2010; Wang and Manning, 2014). An SGD algorithm for solving the resulting saddle point problem has been proposed by Liang et al. (2009), and used by Ganchev and Das (2013) for cross-lingual learning of sequence models. We extended this framework in two aspects: by incorporating a task-specific cost in the objective function, and by formulating a penalized variant of PR. 7 Conclusions We presented a framework for cross-lingual transfer of coreference resolvers. Our method uses word-aligned bitext to project information from the source to the target language. Robustness to projection errors was achieved via a PR framework, which we generalized to handle task-specific costs, yielding softmax-margin PR. We also proposed a penalized formulation that is effective for</context>
</contexts>
<marker>Ganchev, Das, 2013</marker>
<rawString>Kuzman Ganchev and Dipanjan Das. 2013. Cross-lingual discriminative learning of sequence models with posterior regularization. In Proc. of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jo˜ao Grac¸a</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>11--2001</pages>
<marker>Ganchev, Grac¸a, Gillenwater, Taskar, 2010</marker>
<rawString>Kuzman Ganchev, Jo˜ao Grac¸a, Jennifer Gillenwater, and Ben Taskar. 2010. Posterior regularization for structured latent variable models. Journal of Machine Learning Research, 11:2001–2049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Noah A Smith</author>
</authors>
<title>Softmax-Margin CRFs: Training Log-Linear Models with Loss Functions.</title>
<date>2010</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="2651" citStr="Gimpel and Smith, 2010" startWordPosition="384" endWordPosition="387">on (Wang and Manning, 2014), dependency parsing (McDonald et al., 2011), semantic role labeling (Titov and Klementiev, 2012), and fine-grained opinion mining (Almeida et al., 2015). The potential of these techniques, however, has never been fully exploited in coreference resolution (despite some existing work, reviewed in §6, but none resulting in an endto-end coreference resolver). We bridge this gap by proposing a simple learning-based method with weak supervision, based on posterior regularization (Ganchev et al., 2010). We adapt this framework to handle softmax-margin objective functions (Gimpel and Smith, 2010), leading to softmax-margin posterior regularization (§4). This step, while fairly simple, opens the door for incorporating taskspecific cost functions, which are important to manage the precision/recall trade-offs in coreference resolution systems. We show that the resulting problem involves optimizing the difference of two cost-augmented log-partition functions, making a bridge with supervised systems based on latent coreference trees (Fernandes et al., 2012; Durrett and Klein, 2013), reviewed in §3. Inspired by this idea, we consider a simple penalized variant of posterior regularization th</context>
<context position="12142" citStr="Gimpel and Smith, 2010" startWordPosition="1913" endWordPosition="1916">og-likelihood, treating the coreference trees as latent variables. They also found advantageous to incorporate a cost function `(y, Y(E)), measuring the extent to which a prediction y differs from the ones that are consistent with the gold entity set E.2 Putting these pieces together, we arrive at the following loss function to be minimized: where p0w is the cost-augmented distribution: p0w(y|x) ∝ pw(y|x)e`(y,Y(E)) . (3) The loss function in Eq. 2 can be seen as a probabilistic analogous of the hinge loss of support vector machines, and a model trained this way is called a softmax-margin CRF (Gimpel and Smith, 2010). Note that L(w) is non-convex, corresponding to the difference of two log-partition functions (both convex on w), L(w) = En1 (log Z0(w, x(n)) − log �Z(w, x(n))) (4) above we denoted`` Z0(w, x) = EY∈Y(x) ewTf(x,y)+`(y,Y(E)) (5) �Z(w, x) = Ey∈Y(E) ewTf(x,y), (6) 2A precise definition of this cost is provided in §4.3. (E ) L(w) = − EN n=1 log y∈Y(E(n)) p0 w(y|x(n)) , (2) 1429 where f(x, y) := EMm=1 f(x, m, ym).3 Evaluating the gradient of the loss in Eq. 4 requires computing marginals for the candidate antecedents of each mention, which can be done in a mentionsynchronous fashion. This enables a</context>
</contexts>
<marker>Gimpel, Smith, 2010</marker>
<rawString>Kevin Gimpel and Noah A. Smith. 2010. Softmax-Margin CRFs: Training Log-Linear Models with Loss Functions. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Unsupervised coreference resolution in a nonparametric bayesian model.</title>
<date>2007</date>
<booktitle>In Proc. of Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1372" citStr="Haghighi and Klein, 2007" startWordPosition="196" endWordPosition="199"> methods, such as delexicalized transfer with bilingual word embeddings, bitext direct projection, and vanilla posterior regularization. 1 Introduction The goal of coreference resolution is to find the mentions in text that refer to the same discourse entity. While early work focused primarily on English (Soon et al., 2001; Ng and Cardie, 2002), efforts have been made toward multilingual systems, this being addressed in recent shared tasks (Recasens et al., 2010; Pradhan et al., 2012). However, the lack of annotated data hinders rapid system deployment for new languages. Unsupervised methods (Haghighi and Klein, 2007; Ng, 2008) and rule-based approaches (Raghunathan et al., 2010) avoid this data annotation bottleneck, but they often require complex generative models or expert linguistic knowledge. We propose cross-lingual coreference resolution as a way of transferring information from a rich-resource language to build coreference resolvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese. We build upon the recent successes of cross-lingual learning in NLP, which proved quite effective in several structured prediction tasks, such as POS ta</context>
</contexts>
<marker>Haghighi, Klein, 2007</marker>
<rawString>Aria Haghighi and Dan Klein. 2007. Unsupervised coreference resolution in a nonparametric bayesian model. In Proc. of Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Coreference resolution in a modular, entity-centered model.</title>
<date>2010</date>
<booktitle>In Proc. of Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9299" citStr="Haghighi and Klein, 2010" startWordPosition="1433" endWordPosition="1436">ment, and test partitions. For both Spanish and Portuguese, we obtained automatic POS tags and dependency parses by using TurboParser (Martins et al., 2013). 3 Coreference Resolution 3.1 Problem Definition and Prior Work In coreference resolution, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e1,... , eE}, where each ej ⊆ M and ej =6 0. The set E must form a partition of M, i.e., we must have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j. A variety of approaches have been proposed to this problem, including entity-centric models (Haghighi and Klein, 2010; Rahman and Ng, 2011; Durrett et al., 2013), pairwise models (Bengtson and Roth, 2008; Versley et al., 2008), greedy rule-based methods (Raghunathan et al., 2010), and mention-ranking decoders (Denis and Baldridge, 2008; Durrett and Klein, 2013). We chose to base our coreference resolvers on this last class of methods, which permit efficient decoding by shifting from entity clusters to latent coreference trees. In particular, the inclusion of lexicalized features by Durrett and Klein (2013) yields nearly state-of-the-art performance with surface information only. Given that our goal is to pro</context>
</contexts>
<marker>Haghighi, Klein, 2010</marker>
<rawString>Aria Haghighi and Dan Klein. 2010. Coreference resolution in a modular, entity-centered model. In Proc. of Annual Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
<author>Steven J Maiorano</author>
</authors>
<title>Multilingual coreference resolution.</title>
<date>2000</date>
<booktitle>In Proc. of the Conference on Applied Natural Language Processing.</booktitle>
<contexts>
<context position="36611" citStr="Harabagiu and Maiorano (2000)" startWordPosition="6019" endWordPosition="6022"> possessives, respectively. In Portuguese, where many possessives are not annotated in the gold data, we observe a similar but much less pronounced trend. 6 Related Work While multilingual coreference resolution has been the subject of recent SemEval and CoNLL shared tasks, no submitted system attempted cross-lingual training. As shown by Recasens and Hovy (2010), language-specific issues pose a challenge, due to phenomena as pronoun dropping and grammatical gender that are absent in English but exist in other languages. We have discussed some of these issues in the scope of the present work. Harabagiu and Maiorano (2000) and Postolache et al. (2006) projected English corpora to Romanian to bootstrap human annotation, either manually or via automatic alignments. Rahman and Ng (2012) applied translation-based projection at test time (but require an external translation service). Hardmeier et al. (2013) addressed the related task of cross-lingual pronoun prediction. While all these approaches help alleviate the corpus annotation bottleneck, none resulted in a full coreference resolver, which our work accomplished. The work most related with ours is Souza and Or˘asan (2011), who also used parallel data to transfe</context>
</contexts>
<marker>Harabagiu, Maiorano, 2000</marker>
<rawString>Sanda M Harabagiu and Steven J Maiorano. 2000. Multilingual coreference resolution. In Proc. of the Conference on Applied Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Hardmeier</author>
<author>J¨org Tiedemann</author>
<author>Joakim Nivre</author>
</authors>
<title>Latent anaphora resolution for cross-lingual pronoun prediction.</title>
<date>2013</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="36896" citStr="Hardmeier et al. (2013)" startWordPosition="6061" endWordPosition="6064">tem attempted cross-lingual training. As shown by Recasens and Hovy (2010), language-specific issues pose a challenge, due to phenomena as pronoun dropping and grammatical gender that are absent in English but exist in other languages. We have discussed some of these issues in the scope of the present work. Harabagiu and Maiorano (2000) and Postolache et al. (2006) projected English corpora to Romanian to bootstrap human annotation, either manually or via automatic alignments. Rahman and Ng (2012) applied translation-based projection at test time (but require an external translation service). Hardmeier et al. (2013) addressed the related task of cross-lingual pronoun prediction. While all these approaches help alleviate the corpus annotation bottleneck, none resulted in a full coreference resolver, which our work accomplished. The work most related with ours is Souza and Or˘asan (2011), who also used parallel data to transfer an English coreference resolver to Portuguese, but could not beat a simple baseline that clusters together mentions with the same head. Their approach is similar to our bitext direct projection baseline, except that they used Reconcile (Stoyanov et al., 2010) instead of the Berkeley</context>
</contexts>
<marker>Hardmeier, Tiedemann, Nivre, 2013</marker>
<rawString>Christian Hardmeier, J¨org Tiedemann, and Joakim Nivre. 2013. Latent anaphora resolution for cross-lingual pronoun prediction. In Proc. of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karl Moritz Hermann</author>
<author>Phil Blunsom</author>
</authors>
<title>Multilingual Models for Compositional Distributional Semantics.</title>
<date>2014</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="29104" citStr="Hermann and Blunsom (2014)" startWordPosition="4775" endWordPosition="4779"> We report here the performance of this baseline on coreference resolution for Spanish and Portuguese, using the delexicalized models trained on the English data as mentioned in §5.1. To achieve a unified feature representation, we mapped all language-specific POS tags to universal tags (Petrov et al., 2012). All lexical features were replaced either by cross-lingual word embeddings (for words that are not pronouns); or by a universal representation containing the gender, number, and person information of the pronoun. To obtain the cross-lingual word embeddings, we ran the method described by Hermann and Blunsom (2014) for the English-Spanish and EnglishPortuguese pairs, using the parallel sentences in §2. When used as features, these 128-dimensional continuous representations were scaled by a factor of 0.5 (selected on the dev-set), using the procedure of Turian et al. (2010). The second and seventh rows in Table 3 show the performance of this baseline, which is rather disappointing. For Spanish, we observe a large drop in performance when going from supervised training to delexicalized transfer (about 11–13% in averaged Fi). For Portuguese, where the supervised system is not so accurate, the difference is</context>
</contexts>
<marker>Hermann, Blunsom, 2014</marker>
<rawString>Karl Moritz Hermann and Phil Blunsom. 2014. Multilingual Models for Compositional Distributional Semantics. In Proc. of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts. Natural language engineering,</title>
<date>2005</date>
<pages>11--3</pages>
<contexts>
<context position="30388" citStr="Hwa et al., 2005" startWordPosition="4978" endWordPosition="4981">hat this method does not take into account the intricacies of each language—e.g., possessive forms have different agreement rules in English and in Romance languages;9 those, on the other hand, have clitic pronouns that are absent in English. Feature weights that promote certain English agreement relations may then harm performance more than they help. 5.3 Baseline #2: Bitext Direct Projection Another popular strategy for cross-lingual learning is bitext direct projection, which consists in projecting annotations through parallel data in the source and target languages (Yarowsky et al., 2001; Hwa et al., 2005). This is essentially the same as Algorithm 1, except that line 4 is replaced by simple supervised learning, via a minimization 9For example, in Figure 1, their agrees in number with the possessor (the alveoli), but the corresponding sua agrees in number and gender with the thing possessed (func¸˜ao). 1433 of the loss function in Eq. 4 with `2-regularization. This procedure has the disadvantage of being very sensitive to annotation errors, as we shall see. For Portuguese, this baseline is a near-reproduction of Souza and Or˘asan (2011)’s work, discussed in §6. The third and eighth rows in Tabl</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural language engineering, 11(3):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In Proc. of North American Chapter of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="6088" citStr="Liang et al., 2006" startWordPosition="890" endWordPosition="893">ext detail all the datasets and tools involved in our experimental setup. Table 1 provides a summary, along with some statistics. Parallel Data. As parallel data, we use a sentence-aligned trilingual (English-PortugueseSpanish) parallel corpus based on the scientific news Brazilian magazine Revista Pesquisa FAPESP, collected by Aziz and Specia (2011).1 We preprocessed this dataset as follows. We labeled the English side with the Berkeley Coreference Resolution system v1.0, using the provided English model (Durrett and Klein, 2013). Then, we computed word alignments using the Berkeley aligner (Liang et al., 2006), intersected them and filtered out all the alignments whose confi1We found that other commonly used parallel data (such as Europarl or the UN corpus) have a predominance of direct speech that is not suitable for our newswire test domain, so we decided not to use these data. Dataset # Doc. # Sent. # Tok. EN OntoNotes (train) 2,374 48,762 1,007,359 EN OntoNotes (dev) 303 6,894 136,257 EN OntoNotes (test) 322 8,262 152,728 ES FAPESP (aligned) 2,704 142,633 3,840,936 ES AnCora (train) 875 8,999 295,276 ES AnCora (dev) 140 1,417 46,167 ES AnCora (test) 168 1,704 53,042 PT FAPESP (aligned) 2,823 16</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In Proc. of North American Chapter of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning from measurements in exponential families.</title>
<date>2009</date>
<booktitle>In Proc. of International Conference on Machine Learning,</booktitle>
<pages>641--648</pages>
<contexts>
<context position="3434" citStr="Liang et al., 2009" startWordPosition="500" endWordPosition="503">mportant to manage the precision/recall trade-offs in coreference resolution systems. We show that the resulting problem involves optimizing the difference of two cost-augmented log-partition functions, making a bridge with supervised systems based on latent coreference trees (Fernandes et al., 2012; Durrett and Klein, 2013), reviewed in §3. Inspired by this idea, we consider a simple penalized variant of posterior regularization that tunes the Lagrange multipliers directly, bypassing the saddle-point problem of existing EM and alternating stochastic gradient algorithms (Ganchev et al., 2010; Liang et al., 2009). Experiments (§5) show that the proposed method outperforms commonly used cross-lingual approaches, such as delexicalized transfer with bilingual embeddings, direct projection, and “vanilla” posterior regularization. 2 Architecture and Experimental Setup Our methodology, outlined as Algorithm 1, is inspired by the recent work of Ganchev and Das (2013) on cross-lingual learning of sequence models. For simplicity, we call the source and tar1427 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language P</context>
<context position="37920" citStr="Liang et al. (2009)" startWordPosition="6223" endWordPosition="6226"> clusters together mentions with the same head. Their approach is similar to our bitext direct projection baseline, except that they used Reconcile (Stoyanov et al., 2010) instead of the Berkeley Coreference System, and a smaller version of the FAPESP corpus. We have shown that our softmaxmargin PR procedure is superior to this approach. Discriminative PR has been proposed by Ganchev et al. (2010). The same idea underlies the generalized expectation criterion (Mann and McCallum, 2010; Wang and Manning, 2014). An SGD algorithm for solving the resulting saddle point problem has been proposed by Liang et al. (2009), and used by Ganchev and Das (2013) for cross-lingual learning of sequence models. We extended this framework in two aspects: by incorporating a task-specific cost in the objective function, and by formulating a penalized variant of PR. 7 Conclusions We presented a framework for cross-lingual transfer of coreference resolvers. Our method uses word-aligned bitext to project information from the source to the target language. Robustness to projection errors was achieved via a PR framework, which we generalized to handle task-specific costs, yielding softmax-margin PR. We also proposed a penaliz</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Percy Liang, Michael I Jordan, and Dan Klein. 2009. Learning from measurements in exponential families. In Proc. of International Conference on Machine Learning, pages 641–648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
</authors>
<title>On coreference resolution performance metrics.</title>
<date>2005</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="26672" citStr="Luo, 2005" startWordPosition="4395" endWordPosition="4396">25 48.78 52.37 EN delexicalized, no embed. 56.59 48.81 49.95 51.78 55.96 46.94 46.19 49.70 EN delexicalized, emb. EN-ES 57.55 49.83 51.21 52.86 59.00 49.25 49.00 52.42 EN delexicalized, emb. EN-PT 57.91 49.67 51.01 52.86 58.03 48.16 48.33 51.51 ES lexicalized 48.24 40.97 43.59 44.27 47.03 40.68 44.09 43.93 PT lexicalized 35.60 34.47 42.56 37.54 41.61 36.91 40.96 39.83 Table 2: Results for the supervised systems. We show also the performance of delexicalized English systems, with and without cross-lingual embeddings. Shown are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), and CEAF, (Luo, 2005), as well their averaged F1 scores, all computed using the reference implementation of the CoNLL scorer (Pradhan et al., 2014). MUC Dev Avg. MUC Test Avg. B3 CEAF, B3 CEAF, ES simple baseline 25.73 24.73 27.89 26.12 26.06 26.12 29.87 27.35 ES baseline #1 (delex. transfer) 33.04 27.47 32.71 31.07 34.35 28.69 34.42 32.49 ES baseline #2 (bitext dir. proj.) 39.42 30.04 38.25 35.90 37.21 29.72 35.97 34.30 ES baseline #3 (vanilla PR) 41.29 33.68 38.56 37.84 39.34 32.95 38.23 36.84 ES softmax-margin PR 42.34 35.53 39.95 39.27 41.22 35.30 39.94 38.82 PT simple baseline 26.04 26.67 33.19 28.63 22.72 23</context>
</contexts>
<marker>Luo, 2005</marker>
<rawString>Xiaoqiang Luo. 2005. On coreference resolution performance metrics. In Proc. of Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Generalized expectation criteria for semi-supervised learning with weakly labeled data.</title>
<date>2010</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>11--955</pages>
<contexts>
<context position="37789" citStr="Mann and McCallum, 2010" startWordPosition="6201" endWordPosition="6204">2011), who also used parallel data to transfer an English coreference resolver to Portuguese, but could not beat a simple baseline that clusters together mentions with the same head. Their approach is similar to our bitext direct projection baseline, except that they used Reconcile (Stoyanov et al., 2010) instead of the Berkeley Coreference System, and a smaller version of the FAPESP corpus. We have shown that our softmaxmargin PR procedure is superior to this approach. Discriminative PR has been proposed by Ganchev et al. (2010). The same idea underlies the generalized expectation criterion (Mann and McCallum, 2010; Wang and Manning, 2014). An SGD algorithm for solving the resulting saddle point problem has been proposed by Liang et al. (2009), and used by Ganchev and Das (2013) for cross-lingual learning of sequence models. We extended this framework in two aspects: by incorporating a task-specific cost in the objective function, and by formulating a penalized variant of PR. 7 Conclusions We presented a framework for cross-lingual transfer of coreference resolvers. Our method uses word-aligned bitext to project information from the source to the target language. Robustness to projection errors was achi</context>
</contexts>
<marker>Mann, McCallum, 2010</marker>
<rawString>Gideon Mann and Andrew McCallum. 2010. Generalized expectation criteria for semi-supervised learning with weakly labeled data. Journal of Machine Learning Research, 11:955–984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e F T Martins</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
<author>Pedro M Q Aguiar</author>
<author>M´ario A T Figueiredo</author>
</authors>
<title>Turbo Parsers: Dependency Parsing by Approximate Variational Inference.</title>
<date>2010</date>
<booktitle>In Proc. ofEmpirical Methods for Natural Language Processing.</booktitle>
<marker>Martins, Smith, Xing, Aguiar, Figueiredo, 2010</marker>
<rawString>Andr´e F. T Martins, Noah A. Smith, Eric P. Xing, Pedro M. Q. Aguiar, and M´ario A. T. Figueiredo. 2010. Turbo Parsers: Dependency Parsing by Approximate Variational Inference. In Proc. ofEmpirical Methods for Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e F T Martins</author>
<author>Miguel B Almeida</author>
<author>Noah A Smith</author>
</authors>
<title>Turning on the turbo: Fast third-order nonprojective turbo parsers.</title>
<date>2013</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8831" citStr="Martins et al., 2013" startWordPosition="1340" endWordPosition="1343">mbinado [que]1 debe empezar 1428 a funcionar en mayo del 2002]1” we removed the nested mention [que]1), since these are not annotated in the English dataset. For Portuguese, we used the Summ-It 3.0 corpus (Collovini et al., 2007), which contains 50 documents annotated with coreferences, from the science section of the Folha de S˜ao Paulo newspaper. This dataset is much smaller than OntoNotes and AnCora, as shown in Table 1. We split the data into train, development, and test partitions. For both Spanish and Portuguese, we obtained automatic POS tags and dependency parses by using TurboParser (Martins et al., 2013). 3 Coreference Resolution 3.1 Problem Definition and Prior Work In coreference resolution, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e1,... , eE}, where each ej ⊆ M and ej =6 0. The set E must form a partition of M, i.e., we must have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j. A variety of approaches have been proposed to this problem, including entity-centric models (Haghighi and Klein, 2010; Rahman and Ng, 2011; Durrett et al., 2013), pairwise models (Bengtson and Roth, 2008; Versley et al., 2008), greedy rule-based met</context>
</contexts>
<marker>Martins, Almeida, Smith, 2013</marker>
<rawString>Andr´e F. T Martins, Miguel B. Almeida, and Noah A. Smith. 2013. Turning on the turbo: Fast third-order nonprojective turbo parsers. In Proc. of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multisource transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2099" citStr="McDonald et al., 2011" startWordPosition="303" endWordPosition="306">ut they often require complex generative models or expert linguistic knowledge. We propose cross-lingual coreference resolution as a way of transferring information from a rich-resource language to build coreference resolvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese. We build upon the recent successes of cross-lingual learning in NLP, which proved quite effective in several structured prediction tasks, such as POS tagging (T¨ackstr¨om et al., 2013), named entity recognition (Wang and Manning, 2014), dependency parsing (McDonald et al., 2011), semantic role labeling (Titov and Klementiev, 2012), and fine-grained opinion mining (Almeida et al., 2015). The potential of these techniques, however, has never been fully exploited in coreference resolution (despite some existing work, reviewed in §6, but none resulting in an endto-end coreference resolver). We bridge this gap by proposing a simple learning-based method with weak supervision, based on posterior regularization (Ganchev et al., 2010). We adapt this framework to handle softmax-margin objective functions (Gimpel and Smith, 2010), leading to softmax-margin posterior regulariza</context>
<context position="28162" citStr="McDonald et al., 2011" startWordPosition="4630" endWordPosition="4633">argin PR 33.43 31.00 38.82 34.42 38.18 34.05 39.47 37.23 Table 3: Results for all the cross-lingual systems. Bold indicates the overall highest scores. As a lower bound, we show a simple deterministic baseline that, for pronominal mentions, selects the closest non-pronominal antecedent, and, for non-pronominal mentions, selects the closest non-pronominal mention that is a superstring of the current mention. 5.2 Baseline #1: Delexicalized Transfer With Cross-Lingual Embeddings We now turn to the cross-lingual systems. Delexicalized transfer is a popular strategy in NLP (Zeman and Resnik, 2008; McDonald et al., 2011), recently strengthened with cross-lingual word representations (T¨ackstr¨om et al., 2012). The procedure works as follows: a delexicalized model for the source language is trained by eliminating all the language-specific features (such as lexical features); then, this model is used directly in the target language. We report here the performance of this baseline on coreference resolution for Spanish and Portuguese, using the delexicalized models trained on the English data as mentioned in §5.1. To achieve a unified feature representation, we mapped all language-specific POS tags to universal t</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multisource transfer of delexicalized dependency parsers. In Proc. of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proc. of the Annual Meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1094" citStr="Ng and Cardie, 2002" startWordPosition="152" endWordPosition="155"> information from the source to the target. To handle task-specific costs, we propose a softmax-margin variant of posterior regularization, and we use it to achieve robustness to projection errors. We show empirically that this strategy outperforms competitive cross-lingual methods, such as delexicalized transfer with bilingual word embeddings, bitext direct projection, and vanilla posterior regularization. 1 Introduction The goal of coreference resolution is to find the mentions in text that refer to the same discourse entity. While early work focused primarily on English (Soon et al., 2001; Ng and Cardie, 2002), efforts have been made toward multilingual systems, this being addressed in recent shared tasks (Recasens et al., 2010; Pradhan et al., 2012). However, the lack of annotated data hinders rapid system deployment for new languages. Unsupervised methods (Haghighi and Klein, 2007; Ng, 2008) and rule-based approaches (Raghunathan et al., 2010) avoid this data annotation bottleneck, but they often require complex generative models or expert linguistic knowledge. We propose cross-lingual coreference resolution as a way of transferring information from a rich-resource language to build coreference r</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proc. of the Annual Meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Unsupervised models for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1383" citStr="Ng, 2008" startWordPosition="200" endWordPosition="201">lized transfer with bilingual word embeddings, bitext direct projection, and vanilla posterior regularization. 1 Introduction The goal of coreference resolution is to find the mentions in text that refer to the same discourse entity. While early work focused primarily on English (Soon et al., 2001; Ng and Cardie, 2002), efforts have been made toward multilingual systems, this being addressed in recent shared tasks (Recasens et al., 2010; Pradhan et al., 2012). However, the lack of annotated data hinders rapid system deployment for new languages. Unsupervised methods (Haghighi and Klein, 2007; Ng, 2008) and rule-based approaches (Raghunathan et al., 2010) avoid this data annotation bottleneck, but they often require complex generative models or expert linguistic knowledge. We propose cross-lingual coreference resolution as a way of transferring information from a rich-resource language to build coreference resolvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese. We build upon the recent successes of cross-lingual learning in NLP, which proved quite effective in several structured prediction tasks, such as POS tagging (T¨ac</context>
</contexts>
<marker>Ng, 2008</marker>
<rawString>Vincent Ng. 2008. Unsupervised models for coreference resolution. In Proc. of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proc. of Annual Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="23372" citStr="Petrov and Klein, 2007" startWordPosition="3852" endWordPosition="3855">ow present experiments using the setup in §2. We compare our coreference resolvers trained with softmax-margin PR (§5.5) with three other weakly-supervised baselines: delexicalized transfer with cross-lingual embeddings (§5.2), bitext projection (§5.3), and vanilla PR (§5.4). We also run fully supervised systems (§5.1), to obtain upper bounds for the level of performance we expect to achieve with the weakly-supervised systems. An important step in coreference resolution systems is mention prediction. For English, mention spans were predicted from the noun phrases given by the Berkeley parser (Petrov and Klein, 2007), the same procedure as Durrett and Klein (2013). For Spanish and Portuguese, this prediction relied on the output of the dependency parser, using a simple heuristic: besides pronouns, each maximal span formed by contiguous descendants of a noun becomes a candidate mention. This heuristic is quite effective, as shown by Attardi et al. (2010). 5.1 Supervised Systems Table 2 shows the performance of supervised systems for English, Spanish and Portuguese. All optimize Eq. 4 appended with an extra regularization term γ2 kwk2, by running 20 epochs of stochastic gradient descent (SGD; we set γ = 1.0</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proc. of Annual Meeting of the North American Chapter of the Association for Computational Linguistics, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>In Proc. of LREC.</booktitle>
<contexts>
<context position="28787" citStr="Petrov et al., 2012" startWordPosition="4727" endWordPosition="4730">ently strengthened with cross-lingual word representations (T¨ackstr¨om et al., 2012). The procedure works as follows: a delexicalized model for the source language is trained by eliminating all the language-specific features (such as lexical features); then, this model is used directly in the target language. We report here the performance of this baseline on coreference resolution for Spanish and Portuguese, using the delexicalized models trained on the English data as mentioned in §5.1. To achieve a unified feature representation, we mapped all language-specific POS tags to universal tags (Petrov et al., 2012). All lexical features were replaced either by cross-lingual word embeddings (for words that are not pronouns); or by a universal representation containing the gender, number, and person information of the pronoun. To obtain the cross-lingual word embeddings, we ran the method described by Hermann and Blunsom (2014) for the English-Spanish and EnglishPortuguese pairs, using the parallel sentences in §2. When used as features, these 128-dimensional continuous representations were scaled by a factor of 0.5 (selected on the dev-set), using the procedure of Turian et al. (2010). The second and sev</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oana Postolache</author>
<author>Dan Cristea</author>
<author>Constantin Orasan</author>
</authors>
<title>Transferring coreference chains through word alignment.</title>
<date>2006</date>
<booktitle>In Proc. of the International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="36640" citStr="Postolache et al. (2006)" startWordPosition="6024" endWordPosition="6027">tuguese, where many possessives are not annotated in the gold data, we observe a similar but much less pronounced trend. 6 Related Work While multilingual coreference resolution has been the subject of recent SemEval and CoNLL shared tasks, no submitted system attempted cross-lingual training. As shown by Recasens and Hovy (2010), language-specific issues pose a challenge, due to phenomena as pronoun dropping and grammatical gender that are absent in English but exist in other languages. We have discussed some of these issues in the scope of the present work. Harabagiu and Maiorano (2000) and Postolache et al. (2006) projected English corpora to Romanian to bootstrap human annotation, either manually or via automatic alignments. Rahman and Ng (2012) applied translation-based projection at test time (but require an external translation service). Hardmeier et al. (2013) addressed the related task of cross-lingual pronoun prediction. While all these approaches help alleviate the corpus annotation bottleneck, none resulted in a full coreference resolver, which our work accomplished. The work most related with ours is Souza and Or˘asan (2011), who also used parallel data to transfer an English coreference reso</context>
</contexts>
<marker>Postolache, Cristea, Orasan, 2006</marker>
<rawString>Oana Postolache, Dan Cristea, and Constantin Orasan. 2006. Transferring coreference chains through word alignment. In Proc. of the International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Alessandro Moschitti</author>
<author>Nianwen Xue</author>
<author>Olga Uryupina</author>
<author>Yuchen Zhang</author>
</authors>
<title>CoNLL-2012 Shared Task: Modeling multilingual unrestricted coreference in OntoNotes.</title>
<date>2012</date>
<booktitle>In Proc. of the Conference on Computational Natural Language Learning: Shared Task.</booktitle>
<contexts>
<context position="1237" citStr="Pradhan et al., 2012" startWordPosition="175" endWordPosition="178">d we use it to achieve robustness to projection errors. We show empirically that this strategy outperforms competitive cross-lingual methods, such as delexicalized transfer with bilingual word embeddings, bitext direct projection, and vanilla posterior regularization. 1 Introduction The goal of coreference resolution is to find the mentions in text that refer to the same discourse entity. While early work focused primarily on English (Soon et al., 2001; Ng and Cardie, 2002), efforts have been made toward multilingual systems, this being addressed in recent shared tasks (Recasens et al., 2010; Pradhan et al., 2012). However, the lack of annotated data hinders rapid system deployment for new languages. Unsupervised methods (Haghighi and Klein, 2007; Ng, 2008) and rule-based approaches (Raghunathan et al., 2010) avoid this data annotation bottleneck, but they often require complex generative models or expert linguistic knowledge. We propose cross-lingual coreference resolution as a way of transferring information from a rich-resource language to build coreference resolvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese. We build upon the</context>
</contexts>
<marker>Pradhan, Moschitti, Xue, Uryupina, Zhang, 2012</marker>
<rawString>Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and Yuchen Zhang. 2012. CoNLL-2012 Shared Task: Modeling multilingual unrestricted coreference in OntoNotes. In Proc. of the Conference on Computational Natural Language Learning: Shared Task.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Xiaoqiang Luo</author>
<author>Marta Recasens</author>
<author>Eduard Hovy</author>
<author>Vincent Ng</author>
<author>Michael Strube</author>
</authors>
<title>Scoring coreference partitions of predicted mentions: A reference implementation.</title>
<date>2014</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="26798" citStr="Pradhan et al., 2014" startWordPosition="4413" endWordPosition="4416">N-ES 57.55 49.83 51.21 52.86 59.00 49.25 49.00 52.42 EN delexicalized, emb. EN-PT 57.91 49.67 51.01 52.86 58.03 48.16 48.33 51.51 ES lexicalized 48.24 40.97 43.59 44.27 47.03 40.68 44.09 43.93 PT lexicalized 35.60 34.47 42.56 37.54 41.61 36.91 40.96 39.83 Table 2: Results for the supervised systems. We show also the performance of delexicalized English systems, with and without cross-lingual embeddings. Shown are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), and CEAF, (Luo, 2005), as well their averaged F1 scores, all computed using the reference implementation of the CoNLL scorer (Pradhan et al., 2014). MUC Dev Avg. MUC Test Avg. B3 CEAF, B3 CEAF, ES simple baseline 25.73 24.73 27.89 26.12 26.06 26.12 29.87 27.35 ES baseline #1 (delex. transfer) 33.04 27.47 32.71 31.07 34.35 28.69 34.42 32.49 ES baseline #2 (bitext dir. proj.) 39.42 30.04 38.25 35.90 37.21 29.72 35.97 34.30 ES baseline #3 (vanilla PR) 41.29 33.68 38.56 37.84 39.34 32.95 38.23 36.84 ES softmax-margin PR 42.34 35.53 39.95 39.27 41.22 35.30 39.94 38.82 PT simple baseline 26.04 26.67 33.19 28.63 22.72 23.91 27.35 24.66 PT baseline #1 (delex. transfer) 22.51 23.27 33.27 26.35 31.11 27.36 32.78 30.42 PT baseline #2 (bitext dir. p</context>
</contexts>
<marker>Pradhan, Luo, Recasens, Hovy, Ng, Strube, 2014</marker>
<rawString>Sameer Pradhan, Xiaoqiang Luo, Marta Recasens, Eduard Hovy, Vincent Ng, and Michael Strube. 2014. Scoring coreference partitions of predicted mentions: A reference implementation. In Proc. of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karthik Raghunathan</author>
<author>Heeyoung Lee</author>
<author>Sudarshan Rangarajan</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>A multi-pass sieve for coreference resolution.</title>
<date>2010</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1436" citStr="Raghunathan et al., 2010" startWordPosition="205" endWordPosition="208">beddings, bitext direct projection, and vanilla posterior regularization. 1 Introduction The goal of coreference resolution is to find the mentions in text that refer to the same discourse entity. While early work focused primarily on English (Soon et al., 2001; Ng and Cardie, 2002), efforts have been made toward multilingual systems, this being addressed in recent shared tasks (Recasens et al., 2010; Pradhan et al., 2012). However, the lack of annotated data hinders rapid system deployment for new languages. Unsupervised methods (Haghighi and Klein, 2007; Ng, 2008) and rule-based approaches (Raghunathan et al., 2010) avoid this data annotation bottleneck, but they often require complex generative models or expert linguistic knowledge. We propose cross-lingual coreference resolution as a way of transferring information from a rich-resource language to build coreference resolvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese. We build upon the recent successes of cross-lingual learning in NLP, which proved quite effective in several structured prediction tasks, such as POS tagging (T¨ackstr¨om et al., 2013), named entity recognition (Wang</context>
<context position="9462" citStr="Raghunathan et al., 2010" startWordPosition="1458" endWordPosition="1461">reference Resolution 3.1 Problem Definition and Prior Work In coreference resolution, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e1,... , eE}, where each ej ⊆ M and ej =6 0. The set E must form a partition of M, i.e., we must have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j. A variety of approaches have been proposed to this problem, including entity-centric models (Haghighi and Klein, 2010; Rahman and Ng, 2011; Durrett et al., 2013), pairwise models (Bengtson and Roth, 2008; Versley et al., 2008), greedy rule-based methods (Raghunathan et al., 2010), and mention-ranking decoders (Denis and Baldridge, 2008; Durrett and Klein, 2013). We chose to base our coreference resolvers on this last class of methods, which permit efficient decoding by shifting from entity clusters to latent coreference trees. In particular, the inclusion of lexicalized features by Durrett and Klein (2013) yields nearly state-of-the-art performance with surface information only. Given that our goal is to prototype resolvers for resource-poor languages, this model is a good fit—we next describe it in detail. 3.2 Latent Coreference Tree Models Let x be a document contai</context>
</contexts>
<marker>Raghunathan, Lee, Rangarajan, Chambers, Surdeanu, Jurafsky, Manning, 2010</marker>
<rawString>Karthik Raghunathan, Heeyoung Lee, Sudarshan Rangarajan, Nathanael Chambers, Mihai Surdeanu, Dan Jurafsky, and Christopher Manning. 2010. A multi-pass sieve for coreference resolution. In Proc. of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Narrowing the modeling gap: A cluster-ranking approach to coreference resolution.</title>
<date>2011</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>40</volume>
<issue>1</issue>
<contexts>
<context position="9320" citStr="Rahman and Ng, 2011" startWordPosition="1437" endWordPosition="1440"> For both Spanish and Portuguese, we obtained automatic POS tags and dependency parses by using TurboParser (Martins et al., 2013). 3 Coreference Resolution 3.1 Problem Definition and Prior Work In coreference resolution, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e1,... , eE}, where each ej ⊆ M and ej =6 0. The set E must form a partition of M, i.e., we must have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j. A variety of approaches have been proposed to this problem, including entity-centric models (Haghighi and Klein, 2010; Rahman and Ng, 2011; Durrett et al., 2013), pairwise models (Bengtson and Roth, 2008; Versley et al., 2008), greedy rule-based methods (Raghunathan et al., 2010), and mention-ranking decoders (Denis and Baldridge, 2008; Durrett and Klein, 2013). We chose to base our coreference resolvers on this last class of methods, which permit efficient decoding by shifting from entity clusters to latent coreference trees. In particular, the inclusion of lexicalized features by Durrett and Klein (2013) yields nearly state-of-the-art performance with surface information only. Given that our goal is to prototype resolvers for </context>
</contexts>
<marker>Rahman, Ng, 2011</marker>
<rawString>Altaf Rahman and Vincent Ng. 2011. Narrowing the modeling gap: A cluster-ranking approach to coreference resolution. Journal of Artificial Intelligence Research, 40(1):469–521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Translation-based projection for multilingual coreference resolution.</title>
<date>2012</date>
<booktitle>In Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="36775" citStr="Rahman and Ng (2012)" startWordPosition="6045" endWordPosition="6048">le multilingual coreference resolution has been the subject of recent SemEval and CoNLL shared tasks, no submitted system attempted cross-lingual training. As shown by Recasens and Hovy (2010), language-specific issues pose a challenge, due to phenomena as pronoun dropping and grammatical gender that are absent in English but exist in other languages. We have discussed some of these issues in the scope of the present work. Harabagiu and Maiorano (2000) and Postolache et al. (2006) projected English corpora to Romanian to bootstrap human annotation, either manually or via automatic alignments. Rahman and Ng (2012) applied translation-based projection at test time (but require an external translation service). Hardmeier et al. (2013) addressed the related task of cross-lingual pronoun prediction. While all these approaches help alleviate the corpus annotation bottleneck, none resulted in a full coreference resolver, which our work accomplished. The work most related with ours is Souza and Or˘asan (2011), who also used parallel data to transfer an English coreference resolver to Portuguese, but could not beat a simple baseline that clusters together mentions with the same head. Their approach is similar </context>
</contexts>
<marker>Rahman, Ng, 2012</marker>
<rawString>Altaf Rahman and Vincent Ng. 2012. Translation-based projection for multilingual coreference resolution. In Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Eduard Hovy</author>
</authors>
<title>Coreference resolution across corpora: Languages, coding schemes, and preprocessing information.</title>
<date>2010</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="36347" citStr="Recasens and Hovy (2010)" startWordPosition="5976" endWordPosition="5979">1 / 74.1 33.7 / 57.1 26.0 / 56.1 34.9 / 46.7 Table 4: Recall/precision scores for mention prediction, MUC, B3 and CEAFe, all computed in the Spanish dev set. ing training). By comparison, the vanilla and softmax margin PR models only miss 4.9% and 3.4% of the possessives, respectively. In Portuguese, where many possessives are not annotated in the gold data, we observe a similar but much less pronounced trend. 6 Related Work While multilingual coreference resolution has been the subject of recent SemEval and CoNLL shared tasks, no submitted system attempted cross-lingual training. As shown by Recasens and Hovy (2010), language-specific issues pose a challenge, due to phenomena as pronoun dropping and grammatical gender that are absent in English but exist in other languages. We have discussed some of these issues in the scope of the present work. Harabagiu and Maiorano (2000) and Postolache et al. (2006) projected English corpora to Romanian to bootstrap human annotation, either manually or via automatic alignments. Rahman and Ng (2012) applied translation-based projection at test time (but require an external translation service). Hardmeier et al. (2013) addressed the related task of cross-lingual pronou</context>
</contexts>
<marker>Recasens, Hovy, 2010</marker>
<rawString>Marta Recasens and Eduard Hovy. 2010. Coreference resolution across corpora: Languages, coding schemes, and preprocessing information. In Proc. of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>M Ant`onia Marti</author>
</authors>
<title>Ancora-co: Coreferentially annotated corpora for spanish and catalan. Language resources and evaluation,</title>
<date>2010</date>
<pages>44--4</pages>
<marker>Recasens, Marti, 2010</marker>
<rawString>Marta Recasens and M Ant`onia Marti. 2010. Ancora-co: Coreferentially annotated corpora for spanish and catalan. Language resources and evaluation, 44(4):315–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Lluis M`arquez</author>
<author>Emili Sapena</author>
<author>M Ant`onia Marti</author>
<author>Mariona Taul´e</author>
<author>V´eronique Hoste</author>
<author>Massimo Poesio</author>
<author>Yannick Versley</author>
</authors>
<title>Semeval-2010 task 1: Coreference resolution in multiple languages.</title>
<date>2010</date>
<booktitle>In Proc. of the International Workshop on Semantic Evaluation.</booktitle>
<marker>Recasens, M`arquez, Sapena, Marti, Taul´e, Hoste, Poesio, Versley, 2010</marker>
<rawString>Marta Recasens, Lluis M`arquez, Emili Sapena, M Ant`onia Marti, Mariona Taul´e, V´eronique Hoste, Massimo Poesio, and Yannick Versley. 2010. Semeval-2010 task 1: Coreference resolution in multiple languages. In Proc. of the International Workshop on Semantic Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proc. of Annual Meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="19842" citStr="Smith and Eisner, 2005" startWordPosition="3233" endWordPosition="3236"> u2 over gradient iterations, with strong oscillations in initial epochs and somewhat slow convergence. Right: impact in the averaged F1 scores (on the dev-set). Contrast with the more “stable” scores achieved by the penalized method. vanish and we get Z&apos;u(w, x) = Z(w, x), recovering the supervised case (see Eq. 6). Intuitively, this formulation pushes probability mass toward structures that respect the constraints in Eq. 7, while moving away from those that have a large task-specific cost. A similar idea, but applied to the generative case, underlies the framework of constrastive estimation (Smith and Eisner, 2005). 4.3 Cost Function Denote by Em the entire coreference chain of the mth mention (so E = U mcM{Em}), and by Msing := {m ∈ M |Em = {m}} the set of mentions that are projected as singleton in the data (we call this gold-singleton mentions). We design a task-specific cost `(y, Y(E)) as in Durrett and Klein (2013) to balance three kinds of mistakes: (i) false anaphora (ym =6 0 while m ∈ Msing); (ii) false new (ym = 0 while m ∈/ Msing); and (iii) wrong link (ym =6 0 but Em =6 Eym). Letting ffFA(ym, E), ffFN(ym, E), and ffWL(gm, E) be indicators for these events, we define a weighted Hamming cost fu</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>Noah A Smith and Jason Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In Proc. of Annual Meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational linguistics,</journal>
<pages>27--4</pages>
<contexts>
<context position="1072" citStr="Soon et al., 2001" startWordPosition="148" endWordPosition="151">d bitext to project information from the source to the target. To handle task-specific costs, we propose a softmax-margin variant of posterior regularization, and we use it to achieve robustness to projection errors. We show empirically that this strategy outperforms competitive cross-lingual methods, such as delexicalized transfer with bilingual word embeddings, bitext direct projection, and vanilla posterior regularization. 1 Introduction The goal of coreference resolution is to find the mentions in text that refer to the same discourse entity. While early work focused primarily on English (Soon et al., 2001; Ng and Cardie, 2002), efforts have been made toward multilingual systems, this being addressed in recent shared tasks (Recasens et al., 2010; Pradhan et al., 2012). However, the lack of annotated data hinders rapid system deployment for new languages. Unsupervised methods (Haghighi and Klein, 2007; Ng, 2008) and rule-based approaches (Raghunathan et al., 2010) avoid this data annotation bottleneck, but they often require complex generative models or expert linguistic knowledge. We propose cross-lingual coreference resolution as a way of transferring information from a rich-resource language </context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e Guilherme Camargo de Souza</author>
<author>Constantin Or˘asan</author>
</authors>
<title>Can projected chains in parallel corpora help coreference resolution?</title>
<date>2011</date>
<booktitle>In Anaphora Processing and Applications,</booktitle>
<pages>59--69</pages>
<publisher>Springer.</publisher>
<marker>de Souza, Or˘asan, 2011</marker>
<rawString>Jos´e Guilherme Camargo de Souza and Constantin Or˘asan. 2011. Can projected chains in parallel corpora help coreference resolution? In Anaphora Processing and Applications, pages 59–69. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veselin Stoyanov</author>
<author>Claire Cardie</author>
<author>Nathan Gilbert</author>
<author>Ellen Riloff</author>
<author>David Buttler</author>
<author>David Hysom</author>
</authors>
<title>Coreference resolution with reconcile.</title>
<date>2010</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="37472" citStr="Stoyanov et al., 2010" startWordPosition="6151" endWordPosition="6154"> translation service). Hardmeier et al. (2013) addressed the related task of cross-lingual pronoun prediction. While all these approaches help alleviate the corpus annotation bottleneck, none resulted in a full coreference resolver, which our work accomplished. The work most related with ours is Souza and Or˘asan (2011), who also used parallel data to transfer an English coreference resolver to Portuguese, but could not beat a simple baseline that clusters together mentions with the same head. Their approach is similar to our bitext direct projection baseline, except that they used Reconcile (Stoyanov et al., 2010) instead of the Berkeley Coreference System, and a smaller version of the FAPESP corpus. We have shown that our softmaxmargin PR procedure is superior to this approach. Discriminative PR has been proposed by Ganchev et al. (2010). The same idea underlies the generalized expectation criterion (Mann and McCallum, 2010; Wang and Manning, 2014). An SGD algorithm for solving the resulting saddle point problem has been proposed by Liang et al. (2009), and used by Ganchev and Das (2013) for cross-lingual learning of sequence models. We extended this framework in two aspects: by incorporating a task-s</context>
</contexts>
<marker>Stoyanov, Cardie, Gilbert, Riloff, Buttler, Hysom, 2010</marker>
<rawString>Veselin Stoyanov, Claire Cardie, Nathan Gilbert, Ellen Riloff, David Buttler, and David Hysom. 2010. Coreference resolution with reconcile. In Proc. of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Cross-lingual word clusters for direct transfer of linguistic structure.</title>
<date>2012</date>
<booktitle>In Proc. of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<marker>T¨ackstr¨om, McDonald, Uszkoreit, 2012</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit. 2012. Cross-lingual word clusters for direct transfer of linguistic structure. In Proc. of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Token and type constraints for cross-lingual part-of-speech tagging.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--1</pages>
<marker>T¨ackstr¨om, Das, Petrov, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013. Token and type constraints for cross-lingual part-of-speech tagging. Transactions of the Association for Computational Linguistics, 1:1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>Cross-lingual induction of semantic roles.</title>
<date>2012</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2152" citStr="Titov and Klementiev, 2012" startWordPosition="310" endWordPosition="314">or expert linguistic knowledge. We propose cross-lingual coreference resolution as a way of transferring information from a rich-resource language to build coreference resolvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese. We build upon the recent successes of cross-lingual learning in NLP, which proved quite effective in several structured prediction tasks, such as POS tagging (T¨ackstr¨om et al., 2013), named entity recognition (Wang and Manning, 2014), dependency parsing (McDonald et al., 2011), semantic role labeling (Titov and Klementiev, 2012), and fine-grained opinion mining (Almeida et al., 2015). The potential of these techniques, however, has never been fully exploited in coreference resolution (despite some existing work, reviewed in §6, but none resulting in an endto-end coreference resolver). We bridge this gap by proposing a simple learning-based method with weak supervision, based on posterior regularization (Ganchev et al., 2010). We adapt this framework to handle softmax-margin objective functions (Gimpel and Smith, 2010), leading to softmax-margin posterior regularization (§4). This step, while fairly simple, opens the </context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2012. Cross-lingual induction of semantic roles. In Proc. of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: a simple and general method for semisupervised learning.</title>
<date>2010</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="29367" citStr="Turian et al. (2010)" startWordPosition="4817" endWordPosition="4820"> to universal tags (Petrov et al., 2012). All lexical features were replaced either by cross-lingual word embeddings (for words that are not pronouns); or by a universal representation containing the gender, number, and person information of the pronoun. To obtain the cross-lingual word embeddings, we ran the method described by Hermann and Blunsom (2014) for the English-Spanish and EnglishPortuguese pairs, using the parallel sentences in §2. When used as features, these 128-dimensional continuous representations were scaled by a factor of 0.5 (selected on the dev-set), using the procedure of Turian et al. (2010). The second and seventh rows in Table 3 show the performance of this baseline, which is rather disappointing. For Spanish, we observe a large drop in performance when going from supervised training to delexicalized transfer (about 11–13% in averaged Fi). For Portuguese, where the supervised system is not so accurate, the difference is less sharp (about 9–11%). These drops are mainly due to the fact that this method does not take into account the intricacies of each language—e.g., possessive forms have different agreement rules in English and in Romance languages;9 those, on the other hand, ha</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for semisupervised learning. In Proc. of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
<author>Simone Paolo Ponzetto</author>
<author>Massimo Poesio</author>
<author>Vladimir Eidelman</author>
<author>Alan Jern</author>
<author>Jason Smith</author>
<author>Xiaofeng Yang</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Bart: A modular toolkit for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics: Demo Session.</booktitle>
<contexts>
<context position="9408" citStr="Versley et al., 2008" startWordPosition="1451" endWordPosition="1454"> by using TurboParser (Martins et al., 2013). 3 Coreference Resolution 3.1 Problem Definition and Prior Work In coreference resolution, we are given a set of mentions M := {m1, ... , mM}, and the goal is to cluster them into discourse entities, E := {e1,... , eE}, where each ej ⊆ M and ej =6 0. The set E must form a partition of M, i.e., we must have UEj=1 ej = M, and ei ∩ ej = 0 for i =6 j. A variety of approaches have been proposed to this problem, including entity-centric models (Haghighi and Klein, 2010; Rahman and Ng, 2011; Durrett et al., 2013), pairwise models (Bengtson and Roth, 2008; Versley et al., 2008), greedy rule-based methods (Raghunathan et al., 2010), and mention-ranking decoders (Denis and Baldridge, 2008; Durrett and Klein, 2013). We chose to base our coreference resolvers on this last class of methods, which permit efficient decoding by shifting from entity clusters to latent coreference trees. In particular, the inclusion of lexicalized features by Durrett and Klein (2013) yields nearly state-of-the-art performance with surface information only. Given that our goal is to prototype resolvers for resource-poor languages, this model is a good fit—we next describe it in detail. 3.2 Lat</context>
</contexts>
<marker>Versley, Ponzetto, Poesio, Eidelman, Jern, Smith, Yang, Moschitti, 2008</marker>
<rawString>Yannick Versley, Simone Paolo Ponzetto, Massimo Poesio, Vladimir Eidelman, Alan Jern, Jason Smith, Xiaofeng Yang, and Alessandro Moschitti. 2008. Bart: A modular toolkit for coreference resolution. In Proc. of the Annual Meeting of the Association for Computational Linguistics: Demo Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Vilain</author>
<author>John Burger</author>
<author>John Aberdeen</author>
<author>Dennis Connolly</author>
<author>Lynette Hirschman</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proc. of the Conference on Message Understanding,</booktitle>
<pages>45--52</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="26619" citStr="Vilain et al., 1995" startWordPosition="4384" endWordPosition="4387">CEAF, B3 CEAF, EN lexicalized 58.35 50.75 52.08 53.73 59.07 49.25 48.78 52.37 EN delexicalized, no embed. 56.59 48.81 49.95 51.78 55.96 46.94 46.19 49.70 EN delexicalized, emb. EN-ES 57.55 49.83 51.21 52.86 59.00 49.25 49.00 52.42 EN delexicalized, emb. EN-PT 57.91 49.67 51.01 52.86 58.03 48.16 48.33 51.51 ES lexicalized 48.24 40.97 43.59 44.27 47.03 40.68 44.09 43.93 PT lexicalized 35.60 34.47 42.56 37.54 41.61 36.91 40.96 39.83 Table 2: Results for the supervised systems. We show also the performance of delexicalized English systems, with and without cross-lingual embeddings. Shown are MUC (Vilain et al., 1995), B3 (Bagga and Baldwin, 1998), and CEAF, (Luo, 2005), as well their averaged F1 scores, all computed using the reference implementation of the CoNLL scorer (Pradhan et al., 2014). MUC Dev Avg. MUC Test Avg. B3 CEAF, B3 CEAF, ES simple baseline 25.73 24.73 27.89 26.12 26.06 26.12 29.87 27.35 ES baseline #1 (delex. transfer) 33.04 27.47 32.71 31.07 34.35 28.69 34.42 32.49 ES baseline #2 (bitext dir. proj.) 39.42 30.04 38.25 35.90 37.21 29.72 35.97 34.30 ES baseline #3 (vanilla PR) 41.29 33.68 38.56 37.84 39.34 32.95 38.23 36.84 ES softmax-margin PR 42.34 35.53 39.95 39.27 41.22 35.30 39.94 38.8</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Marc Vilain, John Burger, John Aberdeen, Dennis Connolly, and Lynette Hirschman. 1995. A model-theoretic coreference scoring scheme. In Proc. of the Conference on Message Understanding, pages 45–52. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Chris Manning</author>
</authors>
<title>Cross-lingual projected expectation regularization for weakly supervised learning.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>2--55</pages>
<contexts>
<context position="2055" citStr="Wang and Manning, 2014" startWordPosition="296" endWordPosition="300">010) avoid this data annotation bottleneck, but they often require complex generative models or expert linguistic knowledge. We propose cross-lingual coreference resolution as a way of transferring information from a rich-resource language to build coreference resolvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese. We build upon the recent successes of cross-lingual learning in NLP, which proved quite effective in several structured prediction tasks, such as POS tagging (T¨ackstr¨om et al., 2013), named entity recognition (Wang and Manning, 2014), dependency parsing (McDonald et al., 2011), semantic role labeling (Titov and Klementiev, 2012), and fine-grained opinion mining (Almeida et al., 2015). The potential of these techniques, however, has never been fully exploited in coreference resolution (despite some existing work, reviewed in §6, but none resulting in an endto-end coreference resolver). We bridge this gap by proposing a simple learning-based method with weak supervision, based on posterior regularization (Ganchev et al., 2010). We adapt this framework to handle softmax-margin objective functions (Gimpel and Smith, 2010), le</context>
<context position="37814" citStr="Wang and Manning, 2014" startWordPosition="6205" endWordPosition="6208">llel data to transfer an English coreference resolver to Portuguese, but could not beat a simple baseline that clusters together mentions with the same head. Their approach is similar to our bitext direct projection baseline, except that they used Reconcile (Stoyanov et al., 2010) instead of the Berkeley Coreference System, and a smaller version of the FAPESP corpus. We have shown that our softmaxmargin PR procedure is superior to this approach. Discriminative PR has been proposed by Ganchev et al. (2010). The same idea underlies the generalized expectation criterion (Mann and McCallum, 2010; Wang and Manning, 2014). An SGD algorithm for solving the resulting saddle point problem has been proposed by Liang et al. (2009), and used by Ganchev and Das (2013) for cross-lingual learning of sequence models. We extended this framework in two aspects: by incorporating a task-specific cost in the objective function, and by formulating a penalized variant of PR. 7 Conclusions We presented a framework for cross-lingual transfer of coreference resolvers. Our method uses word-aligned bitext to project information from the source to the target language. Robustness to projection errors was achieved via a PR framework, </context>
</contexts>
<marker>Wang, Manning, 2014</marker>
<rawString>Mengqiu Wang and Chris Manning. 2014. Cross-lingual projected expectation regularization for weakly supervised learning. Transactions of the Association for Computational Linguistics, 2:55–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proc. of the First International Conference on Human Language Technology Research.</booktitle>
<contexts>
<context position="7035" citStr="Yarowsky et al. (2001)" startWordPosition="1051" endWordPosition="1054">) 2,374 48,762 1,007,359 EN OntoNotes (dev) 303 6,894 136,257 EN OntoNotes (test) 322 8,262 152,728 ES FAPESP (aligned) 2,704 142,633 3,840,936 ES AnCora (train) 875 8,999 295,276 ES AnCora (dev) 140 1,417 46,167 ES AnCora (test) 168 1,704 53,042 PT FAPESP (aligned) 2,823 166,719 4,538,147 PT Summ-It (train) 30 469 11,771 PT Summ-It (dev) 7 111 2,983 PT Summ-It (test) 13 257 6,491 Table 1: Corpus statistics. EN, ES, and PT denote English, Spanish, and Portuguese, respectively. dence is below 0.95. After this, we projected English mentions to the target side using the maximal span heuristic of Yarowsky et al. (2001). We filtered out documents where more than 15% of the mentions were not aligned. At this point, we obtained an automatically annotated corpus Df in the target language. Figure 1 shows a small excerpt where all mentions were correctly projected. In practice, not all documents are so well behaved: in the English-Portuguese parallel data, only 200,175 out of the original 271,122 mentions (about 73.8%) were conserved after the projection step. In Spanish, this number drops to 69.9%. Monolingual Data. We also use monolingual data for validation and comparison with supervised systems. The Berkeley </context>
<context position="30369" citStr="Yarowsky et al., 2001" startWordPosition="4974" endWordPosition="4977">ainly due to the fact that this method does not take into account the intricacies of each language—e.g., possessive forms have different agreement rules in English and in Romance languages;9 those, on the other hand, have clitic pronouns that are absent in English. Feature weights that promote certain English agreement relations may then harm performance more than they help. 5.3 Baseline #2: Bitext Direct Projection Another popular strategy for cross-lingual learning is bitext direct projection, which consists in projecting annotations through parallel data in the source and target languages (Yarowsky et al., 2001; Hwa et al., 2005). This is essentially the same as Algorithm 1, except that line 4 is replaced by simple supervised learning, via a minimization 9For example, in Figure 1, their agrees in number with the possessor (the alveoli), but the corresponding sua agrees in number and gender with the thing possessed (func¸˜ao). 1433 of the loss function in Eq. 4 with `2-regularization. This procedure has the disadvantage of being very sensitive to annotation errors, as we shall see. For Portuguese, this baseline is a near-reproduction of Souza and Or˘asan (2011)’s work, discussed in §6. The third and </context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proc. of the First International Conference on Human Language Technology Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Philip Resnik</author>
</authors>
<title>Cross-language parser adaptation between related languages. In</title>
<date>2008</date>
<booktitle>IJCNLP,</booktitle>
<pages>35--42</pages>
<contexts>
<context position="28138" citStr="Zeman and Resnik, 2008" startWordPosition="4625" endWordPosition="4629">38.73 36.82 PT softmax-margin PR 33.43 31.00 38.82 34.42 38.18 34.05 39.47 37.23 Table 3: Results for all the cross-lingual systems. Bold indicates the overall highest scores. As a lower bound, we show a simple deterministic baseline that, for pronominal mentions, selects the closest non-pronominal antecedent, and, for non-pronominal mentions, selects the closest non-pronominal mention that is a superstring of the current mention. 5.2 Baseline #1: Delexicalized Transfer With Cross-Lingual Embeddings We now turn to the cross-lingual systems. Delexicalized transfer is a popular strategy in NLP (Zeman and Resnik, 2008; McDonald et al., 2011), recently strengthened with cross-lingual word representations (T¨ackstr¨om et al., 2012). The procedure works as follows: a delexicalized model for the source language is trained by eliminating all the language-specific features (such as lexical features); then, this model is used directly in the target language. We report here the performance of this baseline on coreference resolution for Spanish and Portuguese, using the delexicalized models trained on the English data as mentioned in §5.1. To achieve a unified feature representation, we mapped all language-specific</context>
</contexts>
<marker>Zeman, Resnik, 2008</marker>
<rawString>Daniel Zeman and Philip Resnik. 2008. Cross-language parser adaptation between related languages. In IJCNLP, pages 35–42.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>