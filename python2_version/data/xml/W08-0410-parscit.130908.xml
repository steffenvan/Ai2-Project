<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.9990935">
Inductive Detection of Language Features via Clustering Minimal Pairs:
Toward Feature-Rich Grammars in Machine Translation
</title>
<author confidence="0.998573">
Jonathan H. Clark, Robert Frederking, Lori Levin
</author>
<affiliation confidence="0.875293666666667">
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998869">
{jhclark,ref,lsl}@cs.cmu.edu
</email>
<sectionHeader confidence="0.995711" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.989935210526316">
Syntax-based Machine Translation systems
have recently become a focus of research
with much hope that they will outperform
traditional Phrase-Based Statistical Machine
Translation (PBSMT). Toward this goal, we
present a method for analyzing the mor-
phosyntactic content of language from an
Elicitation Corpus such as the one included in
the LDC’s upcoming LCTL language packs.
The presented method discovers a mapping
between morphemes and linguistically rele-
vant features. By providing this tool that
can augment structure-based MT models with
these rich features, we believe the discrimina-
tive power of current models can be improved.
We conclude by outlining how the resulting
output can then be used in inducing a mor-
phosyntactically feature-rich grammar for AV-
ENUE, a modern syntax-based MT system.
</bodyText>
<sectionHeader confidence="0.999131" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999614384615384">
Recent trends in Machine Translation have begun
moving toward the incorporation of syntax and
structure in translation models in hopes of gaining
better translation quality. In fact, some structure-
based systems have already shown that they can out-
perform phrase-based SMT systems (Chiang, 2005).
Still, even the best-performing data-driven systems
have not fully explored the depth of such linguistic
features as morphosyntax.
Certainly, many have brought linguistically moti-
vated features into their models in the past. Huang
and Knight (2006) explored relabeling of non-
terminal symbols to embed more information di-
</bodyText>
<page confidence="0.972271">
78
</page>
<bodyText confidence="0.999820666666667">
rectly into the backbone of the grammar. Bonneau-
Maynard et al. (2007) argue that incorporation of
morphosyntax in the form of a part of speech (POS)
language model can improve translation. While
these approaches do make use of various linguis-
tic features, we have only begun to scratch the sur-
face of what actually occurs in the languages of the
world. We wish to address such issues as case mark-
ing, subject-verb agreement, and numeral-classifier
agreement by providing models with information
about which morphemes correspond to which gram-
matical meanings.
</bodyText>
<sectionHeader confidence="0.976775" genericHeader="method">
2 Task Overview
</sectionHeader>
<bodyText confidence="0.99997145">
Feature Detection is the process of determining from
a corpus annotated with feature structures (Figure 2)
which feature values (Figure 1) have a distinct rep-
resentation in a target language in terms of mor-
phemes (Figure 3). By leveraging knowledge from
the field of language typology, we know what types
of phenomena are possible across languages and,
thus, which features to include in our feature speci-
fication.
But not every language will display each of these
phenomena. Our goal is to determine which fea-
ture values (e.g. singular, dual, plural) have a dis-
tinct encoding in a given target language. Viewed
differently, we can ask which feature values can be
clustered by similarity. For instance, in Chinese, we
would expect singular, plural and dual to be mem-
bers of the same cluster (since they are typically not
explicitly expressed), while for Arabic we should
place each of these into separate clusters to indicate
they are each grammaticalized differently. Similarly,
</bodyText>
<note confidence="0.9812">
Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 78–86,
ACL-08: HLT, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</note>
<table confidence="0.974370714285714">
Feature Name Feature Value Comment
np-gen m ,f, n Biological Gender
np-def +, - Definiteness
np-num sg, dl, pl Number
c-ten past, pres, fut Tense
np-function act, und Actor and undergoer participant roles
c-function main, rel Main and relative clause roles
</table>
<figureCaption confidence="0.73184">
Figure 1: An example feature specification.
</figureCaption>
<table confidence="0.982934384615385">
ID Source Language Target Language Lexical Cluster Feature Structure
s1 He loves her. El ama a ella. `1 ((act (np-gen m) (np-num sg) (np-def +))
(und (np-gen f) (np-num sg) (np-def +)) (c-ten pres))
s2 She loves her. Ella ama a ella. `1 ((act (np-gen f) (np-num sg) (np-def +))
(und (np-gen f) (np-num sg) (np-def +)) (c-ten pres))
s3 He loved her. El *ama a ella. `1 ((act (np-gen m) (np-num sg) (np-def +))
(und (np-gen f) (np-num sg) (np-def +)) (c-ten past))
s4 The boy eats. El ni˜no come. `2 ((act (np-gen m) (np-num sg) (np-def +)) (c-ten pres))
s5 The girl eats. La ni˜na come. `2 ((act (np-gen f) (np-num sg) (np-def +)) (c-ten pres))
s6 A girl eats. Una ni˜na come. `2 ((act (np-gen f) (np-num sg) (np-def -)) (c-ten pres))
s7 The girls eat. Las ni˜nas comen. `2 ((act (np-gen f) (np-num pl) (np-def +)) (c-ten pres))
s8 The girls eat. Las ni˜nas comen. `2 ((act (np-gen f) (np-num dl) (np-def +)) (c-ten pres))
s9 Girls eat. Unas ni˜nas comen. `2 ((act (np-gen f) (np-num pl) (np-def -)) (c-ten pres))
</table>
<figureCaption confidence="0.947719333333333">
Figure 2: An example of sentences that might be found in an elicitation corpus. Notice that each sentence differs from
some other sentence in the corpus by exactly one feature value. This enables us to see how the written form of the
language changes (or does not change) when the grammatical meaning changes.
</figureCaption>
<bodyText confidence="0.998098545454546">
English would have two clusters for the feature num-
ber: (singular) and (dual, plural). Further, we would
like to determine which morphemes express each of
these values (or value clusters). For example, En-
glish expresses negation with the morphemes no and
not, whereas questions are expressed by reordering
of the auxiliary verb or the addition of a wh-word.
Though many modern corpora contain feature-
annotated utterances, these corpora are often not
suitable for feature detection. For this purpose, we
use an Elicitation Corpus (see Figure 2), a corpus
that has been carefully constructed to provide a large
number of minimal pairs of sentences such as He
sings and She sings so that only a single feature (e.g.
gender) differs between the two sentences. Also, no-
tice that the feature structures are sometimes more
detailed than the source language sentence. For ex-
ample, English does not express dual number, but
we might want to include this feature in our Elicita-
tion Corpus (especially for a language such as Ara-
bic). For these cases, we include a context field for
the translator with an instruction such as “Translate
this sentence as if there are two girls.”
In the past, we proposed deductive (rule-based)
methods for feature detection (Clark et al., 2008).
In this paper, we propose the use of inductive fea-
ture detection, which operates directly on the feature
set that the corpus has been annotated with, remov-
ing the need for manually written rules. We define
inductive feature detection as a recall-oriented task
since its output is intended to be analyzed by a Mor-
phosyntactic Lexicon Generator, which will address
the issue of precision. This, in turn, allows us to in-
form a rule learner about which language features
can be clustered and handled by a single set of rules
and which must be given special attention. How-
ever, due to the complexity of this component, de-
scribing it is beyond the scope of this paper. We also
note that future work will include the integration of a
morphology analysis system such as ParaMor (Mon-
son et al., 2007) to extract and annotate the valuable
morphosyntactic information of inflected languages.
An example of this processing pipeline is given in
Figure 4.
</bodyText>
<page confidence="0.99742">
79
</page>
<table confidence="0.9958634">
Feature Value Candidate Morphemes
np-gen m el, ni˜no
np-gen f ella, ni˜na
np-gen n *unobserved*
np-def + el, la, las
np-def - una, unas
np-num sg el, ella, la, una, come, ni˜no, ni˜na
np-num dl-pl las, unas, comen, ni˜nas
c-ten past-pres –
c-ten fut *unobserved*
</table>
<figureCaption confidence="0.9958395">
Figure 3: An example of the output of our system for the above corpus: a list of feature-morpheme pairings.
Figure 4: An outline of the steps from an input Elicitation Corpus to the application of a morphosyntactically feature
rich grammar in a MT decoder. This paper discusses the highlighted inductive feature detection component. Note that
this is just one possible configuration for integrating inductive feature detection into system training.
</figureCaption>
<figure confidence="0.9990352">
Decoder
Inductive
Feature
Detection
Grammar
Rule
Learner
Morphosyntactic
Lexicon
Generator
Unsupervised
Morphology
Induction
Elicitation
Corpus
</figure>
<sectionHeader confidence="0.847061" genericHeader="method">
3 The Need to Observe Real Data
</sectionHeader>
<bodyText confidence="0.9999449">
One might argue that such information could be ob-
tained from a grammatical sketch of a language.
However, these sketches often focus on the “inter-
esting” features of a language, rather than those that
are most important for machine translation. Fur-
ther, not all grammatical functions are encoded in
the elements that most grammatical sketches focus
on. According to Construction Grammar, such in-
formation is also commonly found in constructions
(Kay, 2002). For example, future tense is not gram-
maticalized in Japanese according to most reference
sources, yet it may be expressed with a construction
such as watashi wa gakoo ni iku yode desu (lit. “I
have a plan to go to school.”) for I will go to school.
Feature detection informs us of such constructional-
ized encodings of language features for use in im-
proving machine translation models.
Recognizing the need for this type of data, the
LDC has included our Elicitation Corpus in their
Less Commonly Taught Languages (LCTL) lan-
guage packs (Simpson et al., 2008). Already, these
language packs have been translated into Thai, Ben-
gali, Urdu, Hungarian, Punjabi, Tamil, and Yoruba.
With structured elicitation corpora already being
produced on a wide scale, there exists plenty of data
that can be exploited via feature detection. Some of
these language packs have already been released for
use in MT competitions and they will start being re-
leased to the general research community this year
through LDC’s catalog.
</bodyText>
<sectionHeader confidence="0.999347" genericHeader="method">
4 Applications
</sectionHeader>
<subsectionHeader confidence="0.999875">
4.1 Induction of Feature-Rich Grammars
</subsectionHeader>
<bodyText confidence="0.999994214285714">
Given these outputs, a synchronous grammar in-
duction system can then use these feature-annotated
morphemes and the knowledge of which features are
expressed to create a feature rich grammar. Consider
the example in Figure 5, which shows Urdu subject-
verb agreement taking place while being separated
by 12 words. Traditional n-gram Language Mod-
els (LM’s) would not be able to detect any disagree-
ments more than n words away, which is the nor-
mal case for a trigram LM. Even most syntax-based
systems would not be able to detect this problem
without using a huge number of non-terminals, each
marked for all possible agreements. A syntax-based
system might be able to check this sort of agree-
</bodyText>
<page confidence="0.977965">
80
</page>
<bodyText confidence="0.677989666666667">
ek talb alm arshad jo mchhlyoN ke liye pani maiN aata phink raha tha ...
a.SG student named Irshad who fish for water in flour throw PROG.SG.M be.PAST.SG.M
“A student named Irshad who was throwing flour in the water for the fish ... ”
</bodyText>
<figureCaption confidence="0.978029">
Figure 5: A glossed example from parallel text in LDC’s Urdu-English LCTL language pack showing subject-verb
agreement being separated by 12 words.
</figureCaption>
<bodyText confidence="0.895852552631579">
ment if it produced a target-side dependency tree as
in Ding and Palmer (2005). However, we are not
aware of any systems that attempt this. Therefore,
the correct hypotheses, which have correct agree-
ment, will likely be produces as hypotheses of tra-
ditional beam-search MT systems, but their features
might not be able to discern the correct hypothe-
sis, allowing it to fall below the 1-best or out of the
beam entirely. By constructing a feature-rich gram-
mar in a framework that allows unification-based
feature constraints such as AVENUE (Carbonell et
al., 2002), we can prune these bad hypotheses lack-
ing agreement from the search space.
Returning to the example of subject-verb agree-
ment, consider the following Urdu sentences taken
from the Urdu-English Elicitation Corpus in LDC’s
LCTL language pack:
Danish ne Amna ko sza di
Danish ERG Amna DAT punish give.PERF
“Danish punished Amna.”
Danish Amna ko sza dita hai
Danish Amna DAT punish give.HAB be.PRES
“Danish punishes Amna.”
These examples show the split-ergativity of Urdu
in which the ergative marker ne is used only for
the subject of transitive, perfect aspect verbs. In
particular, since these sentences have the perfect
aspect marked on the light verb di, a closed-class
word (Poornima and Koenig, 2008), feature detec-
tion will allow the induction of a grammar that per-
colates a feature up from the VP containing di in-
dicating that its aspect is perfect. Likewise, the NP
containing Danish ne will percolate a feature up in-
dicating that the use of ne requires perfect aspect.
If, during translation, a hypothesis is proposed that
does not meet either of these conditions, unification
will fail and the hypothesis will be pruned 1.
Certainly, unification-based grammars are not the
</bodyText>
<footnote confidence="0.596432">
1If the reader is not familiar with Unification Grammars, we
recommend Kaplan (1995)
</footnote>
<bodyText confidence="0.998938466666667">
only way in which this rich source of linguistic infor-
mation could be used to augment a structure-based
translation system. One could also imagine a system
in which the feature annotations are simply used to
improve the discriminative power of a model. For
example, factored translation models (Koehn and
Hoang, 2007) retain the simplicity of phrase-based
SMT while adding the ability to incorporate addi-
tional features. Similarly, there exists a continuum
of degrees to which this linguistic information can
be used in current syntax-based MT systems. As
modern systems move toward integrating many fea-
tures (Liang et al., 2006), resources such as this will
become increasingly important in improving trans-
lation quality.
</bodyText>
<sectionHeader confidence="0.994183" genericHeader="method">
5 System Description
</sectionHeader>
<bodyText confidence="0.999842666666667">
In the following sections, we will describe the pro-
cess of inductive feature detection by way of a run-
ning example.
</bodyText>
<subsectionHeader confidence="0.990683">
5.1 Feature Specification
</subsectionHeader>
<bodyText confidence="0.9999923125">
The first input to our system is a feature specification
(Figure 1). The feature specification used for this ex-
periment was written by an expert in language typol-
ogy and is stored in a human-readable XML format.
It is intended to cover a large number of phenom-
ena that are possible in the languages of the world.
Note that features beginning with np- are partici-
pant (noun) features while features beginning with
c- are clause features. The feature specification al-
lows us to know which values are unobserved during
elicitation (that is, no sentence having that feature
value was given to the bilingual person to translate).
This is the case for the first four features and their
values in Figure 1. The last two function features
and their values tell us what possible roles partici-
pants and clauses can take in sentences.
</bodyText>
<page confidence="0.992437">
81
</page>
<subsectionHeader confidence="0.978562">
5.2 Elicitation Corpus
</subsectionHeader>
<bodyText confidence="0.999926756756757">
As outlined in Section 3, feature detection uses an
Elicitation Corpus (see Figure 2), a corpus that has
been carefully constructed to provide a large num-
ber of minimal pairs of sentences such as He sings
and She sings so that only a single feature (e.g. gen-
der) differs between the two sentences (Levin et al.,
2006; Alvarez et al., 2006). If two features had var-
ied at once (e.g. It sang) or lexical choice varied
(e.g. She reads), then making assertions about which
features the language does and does not express be-
comes much more difficult.
Notice that each input sentence has been tagged
with an identifier for a lexical cluster as a pre-
processing step. Specifying lexical clusters ensures
that we don’t compare sentences with different con-
tent just because their feature structures match. For
example, we would not want to compare Dog bites
man and Man bites dog nor The student snored
and The professor snored. Note that bag-of-words
matching is insufficient for this purpose.
Though any feature-annotated corpus can be used
in feature detection, the amount of useful informa-
tion extracted from the corpus is directly dependent
on how many minimal pairs can be formed from the
corpus. For instance, one might consider using a
morphologically annotated corpus or even an auto-
matically parsed corpus in place of the elicitation
corpus. Even though these resources are likely to
suffer from having very sparse minimal pairs due to
their uncontrolled usage of vocabulary, they might
still contain some amount of useful information.
However, since we seek both to apply these methods
to language for which there are currently no man-
ually annotated corpora and to investigate features
that existing parsers generally cannot identify (e.g.
generic nouns and evidentiality), we will not men-
tion these types of resources any further.
</bodyText>
<subsectionHeader confidence="0.991256">
5.3 Minimal Pair Clustering
</subsectionHeader>
<bodyText confidence="0.986520936170213">
Minimal pair clustering is the process of grouping
all possible sets of minimal pairs, those pairs of sen-
tences that have exactly one difference between their
feature structures. We use wildcard feature struc-
tures to represent each minimal pair cluster. We de-
fine a wildcard feature as any feature whose value
is *, which denotes that the value matches another *
rather than its original feature value. Similarly, we
define the feature context of the wildcard feature be
the enclosing participant and clause type for a np-
feature or the enclosing clause for a c- type fea-
ture. Then, for each sentence s in the corpus, we
substitute a wildcard feature for each of the values v
in its feature structure, and we append s to the list
of sentences associated with this wildcard feature
structure. A sample of some of the minimal pairs
for our running example are shown in Figure 6.
Here, we show minimal pairs for just one wild-
card, though multiple wildcards may be created if
one wishes to examine how features interact with
one another. This could be useful in cases such as
Hindi where the perfective verb aspect interacts with
the past verb tense and the actor NP function to add
the case marker ne (for split ergativity of Urdu, see
Section 4.1). That said, a downstream component
such as a Morphosyntactic Lexicon Generator would
perhaps be better suited for the analysis of feature in-
teractions. Also, note that the feature context is not
used when there is only one wildcard feature. The
feature context becomes useful when multiple wild-
cards are added in that it may also act as a wildcard
feature.
The next step is to organize the example sentences
into a table that helps us decide which examples can
be compared and stores information that will inform
our comparison. Briefly, any two sentences belong-
ing to the same minimal pair cluster and lexical clus-
ter will eventually get compared. As specified in Al-
gorithm 1, we create a table like that in Figure 7.
Having collected this information, we are now ready
to begin clustering feature values.
Algorithm 1 Organize()
Require: Minimal pairs, lexical clusters, and the
feature specification.
Ensure: A table T of comparable examples.
for all pair m E minimalPairs do
for all sentence s E m do
</bodyText>
<equation confidence="0.853770833333333">
f wildcardFeature(s, m)
v featureValue(s, f)
c featureContext(m)
E lexCluster(s)
T[f,m,c, E, v] T[f,m,c, E,v]U s
return T
</equation>
<page confidence="0.993302">
82
</page>
<table confidence="0.9949772">
ID Set Members Feature Feature Context Feature Structure
m1 {s1, s2} np-gen ((act)) ((act (np-gen *) (np-num sg) (np-def +))
(und (np-gen f) (np-num sg) (np-def +)) (c-ten pres))
m2 {s1, s3} np-ten () ((act (np-gen m) (np-num sg) (np-def +))
(und (np-gen f) (np-num sg) (np-def +)) (c-ten *))
m3 {s4, s5, s7, s8} np-gen ((act)) ((act (np-gen *) (np-num sg) (np-def +)) (c-ten pres))
m4 {s5, s7, s8} np-num ((act)) ((act (np-gen f) (np-num *) (np-def +)) (c-ten pres))
m5 {s6, s9} np-num ((act)) ((act (np-gen f) (np-num *) (np-def -)) (c-ten pres))
m6 {s5, s6} np-def ((act)) ((act (np-gen f) (np-num sg) (np-def *)) (c-ten pres))
m7 {s7, s9} np-def ((act)) ((act (np-gen f) (np-num pl) (np-def *)) (c-ten pres))
</table>
<figureCaption confidence="0.990019461538461">
Figure 6: An example subset of minimal pairs that can be formed from the corpus in Figure 2.
Feature Min. Pair Feat. Context Lex. Cluster Feat. Value. Sentence
np-gen m1 ((act)) `1 m s1
np-gen m1 ((act)) `1 f s2
np-ten m2 () `1 pres s1
np-ten m2 () `1 past s3
np-num m4 ((act)) `2 sg s5
np-num m4 ((act)) `2 pl s7
np-num m4 ((act)) `2 dl s8
np-num m5 ((act)) `2 sg s6
np-num m5 ((act)) `2 pl s9
Figure 7: An example subset of the organized items that can be formed from the minimal pairs in Figure 6. Each item
that has a matching minimal pair ID, feature context, and lexical cluster ID can be compared during feature detection.
</figureCaption>
<subsectionHeader confidence="0.967232">
5.4 Feature Value Clustering
</subsectionHeader>
<bodyText confidence="0.999963422222222">
During the process of feature value clustering, we
collapse feature values that do not have a distinct
encoding in the target language into a single group.
This is helpful both as information to components
using the output of inductive feature detection and
later as a method of reducing data sparseness when
creating morpheme-feature pairings. We represent
the relationship between the examples we have gath-
ered for each feature as a feature expression graph.
We define a feature expression graph (FEG) for a
feature f to be a graph on M vertices where v is
the number of possible values of f (though for most
non-trivial cases, it is more conveniently represented
as a triangular matrix).
Each vertex of the FEG corresponds to a feature
value (e.g. singular, dual) while each arc contains
the list of examples that are comparable according
to the table from the previous step. The examples at
each arc are organized into those that had the same
target language string, indicating that the feature val-
ues are not distinctly expressed, and those that had
a different target language string, indicating that the
change in grammatical meaning represented in the
feature structure has a distinct encoding in the tar-
get language. Algorithm 2 more formally specifies
the creation of a FEG. The FEG’s for our running
example are shown in Figure 8. From these statis-
tics generated from these graphs, we then estimate
the maximum likelihood probability of each feature
value pair being distinctly encoded as shown in Fig-
ure 9.
The interpretation of these probabilities might not
be obvious. They estimate the likelihood of a lan-
guage encoding a feature given that the meaning of
that feature is intended to be conveyed. These proba-
bilities should not be interpreted as a traditional like-
lihood of encountering a given lexical item.
Finally, we cluster by randomly selecting a start-
ing vertex for a new cluster and adding vertices to
that cluster, following arcs out from the cluster that
have a weight lower than some threshold 0. When
no more arcs may be followed, a new start vertex is
selected and another cluster is formed. This is re-
peated until all feature values have been assigned to
a cluster. For our running example, we use 0 = 0.6,
</bodyText>
<page confidence="0.988727">
83
</page>
<table confidence="0.678244785714286">
{(s1, s2, NEQ), (s4, s5, NEQ),
(s4, s7, NEQ), (s4, s8, NEQ)}
{(s5,s7, NEQ), (s6, s9, NEQ)}
pl
np-num
{(s5, s8, NEQ)} {(s7, s8, EQ)}
dl
{(s1, s2, NEQ)}
s
{(s5, s6, NEQ),
(s7, s9, NEQ))}
np-def
-
+
</table>
<figure confidence="0.953373375">
past pres
c-ten
{} {}
fut
np-gen
{} {}
m f
n
</figure>
<figureCaption confidence="0.993459666666667">
Figure 8: An example subset of the Feature Expression Graphs that are formed from the minimal pairs in Figure 7.
Figure 9: An example of how probabilities are estimated for each feature value pair in a Feature Expression Graph for
the feature np-gender.
</figureCaption>
<equation confidence="0.7829557">
 |ares[m,f] with (sm,sf,x,NEQ) |
 |ares[m,f] |
m
f
 |ares[m,n] with (sm,sn,x,NEQ) |
 |ares[m,n] |
 |ares[f,n] with (sf,sn,x,NEQ) |
 |ares[f,n] |
n
Algorithm 2 Collecting statistics for each FEG.
</equation>
<bodyText confidence="0.864143384615385">
Require: The table T from the previous step.
Ensure: A complete graph as an arc list with the
observed similarities and differences for each fea-
ture value.
for all si, sj E T s.t. (mi, ci, Ei) = (mj, cj, Ej)
do
(vi, vj) +— (featureValue(si), featureValue(sj))
if tgt(si) = tgt(sj) then
arcs[vi, vj] +— arcs[vi, vj] U (si, sj, m,EQ)
else
arcs[vi, vj] +— arcs[vi, vj] U (si, sj, m,NEQ)
return arcs
which results in the following clusters being formed:
</bodyText>
<listItem confidence="0.4439185">
np-gen: m, f
np-num: s, pl/dl
np-def: +, -
c-ten: past, pres
</listItem>
<subsectionHeader confidence="0.988244">
5.5 Morpheme-Feature Pairing
</subsectionHeader>
<bodyText confidence="0.999957533333333">
Finally, using the information from above about
which values should be examined as a group and
which sentence pairs exemplify an orthographic dif-
ference, we examine each pair of target language
sentences to determine which words changed to re-
flect the change in grammatical meaning. This pro-
cess is outlined in Algorithm 3. The general idea is
that for each arc going out of a feature value vertex
we examine all of the target language sentence pairs
that expressed a difference. We then take the words
that were in the vocabulary of the target sentence
for the current feature value, but not in the sentence
it was being compared to and add them to the list
of words that could be used to express this feature
value (Figure 3).
</bodyText>
<sectionHeader confidence="0.996652" genericHeader="evaluation">
6 Evaluation and Results
</sectionHeader>
<bodyText confidence="0.999990923076923">
We evaluated the output of feature detection with
one wildcard feature as applied to the Elicitation
Corpus from the LDC’s Urdu-English LCTL lan-
guage pack. Threshold parameters were set to small
values (0 = 0.05). Note that an increase in precision
might be possible by tuning this value; however, as
stated, we are most concerned with recall.
An initial attempt was made to create a gold stan-
dard against which recall could be directly calcu-
lated. However, the construction of this gold stan-
dard was both noisier and more time consuming
than expected. That is, even though the task is
based on how a linguistic field worker might col-
</bodyText>
<page confidence="0.993801">
84
</page>
<bodyText confidence="0.9093225">
Algorithm 3 Determine which morphemes are as-
sociated with which feature values.
</bodyText>
<note confidence="0.500543">
Require: List of clusters C and list of FEGs F
</note>
<bodyText confidence="0.966358666666667">
Ensure: A list of morphemes associated with each
feature value
for all feature E F do
for all vertex E feature do
for all arc E vertex do
for all (s1, s2, m,NEQ) E arc do
</bodyText>
<equation confidence="0.928773333333333">
v1 featureValue(s1,m)
v2 featureValue(s2,m)
if v1 7� v then (s1, v1) H (s2, v2)
w1 vocabulary(s1)
w2 vocabulary(s2)
δ W1 — W2
</equation>
<bodyText confidence="0.875918">
for all w E freq do
freq[w]++
for all w E freq do
</bodyText>
<equation confidence="0.428163">
p = freq[w] / E,,, freq[w]
if p &gt; θ&apos; then
morphemes[v] morphemes[v]U w
</equation>
<bodyText confidence="0.98662436">
return morphemes
lect data, it was more difficult for a human than
anticipated. Therefore, we instead produced a list
of hypothesized morpheme-feature pairs and had a
human trained in linguistics who was also bilingual
in Hindi/Urdu-English mark each pair as “Correct,”
“Incorrect,” or “Ambiguous.” The results of this
evaluation are summarized in Figure 10. The reader
may be surprised by how many incorrect hypothe-
ses were generated, given the controlled nature of
the Elicitation Corpus. However, there are two im-
portant factors to consider. First, features can in-
teract in complex and often unexpected ways. For
instance, in English, the only feature difference in
minimal pair Cats yawned and A cat yawned is the
number of the actor. However, this causes an in-
teraction with definiteness that would cause the pre-
sented algorithms to associate a with the number of
nouns even though it is canonically associated with
definiteness. Second, the bilingual people translat-
ing the Elicitation Corpus are prone to make errors.
Though a fair number of incorrect hypotheses
were produced, the number of correct hypotheses
is encouraging. We also note that the words be-
ing identified are largely function words and multi-
</bodyText>
<figure confidence="0.5738744">
Judgment Morpheme-Feature Pairings
Correct 68
Ambiguous 29
Incorrect 109
TOTAL 206
</figure>
<figureCaption confidence="0.9763286">
Figure 10: The results of feature detection. Being a
recall-oriented approach, inductive feature detection is
geared toward overproduction of morpheme-feature pair-
ings as shown in the number of ambiguous and incorrect
pairings.
</figureCaption>
<bodyText confidence="0.999904785714286">
morpheme tokens from which closed-class func-
tional morphemes will be extracted. One might
think the counts extracted seem low when compared
to the typical MT vocabulary size, but these function
words that we extract cover a much larger probabil-
ity mass of the language than content words.
We are confident that the Morphosyntactic Lex-
icon Generator designed to operate directly down-
stream from this process will be sufficiently discrim-
inant to use these morpheme-feature pairings to cre-
ate a high precision lexicon. However, since this
component is, in itself, highly complex, its specifics
are beyond the scope of this paper and so we leave it
to be discussed in future work.
</bodyText>
<sectionHeader confidence="0.99887" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999998909090909">
We have presented a method for inductive feature
detection of an annotated corpus, which determines
which feature values have a distinct representation
in a target language and what morphemes can be
used to express these grammatical meanings. This
method exploits the unique properties of an Elici-
tation Corpus, a resource which is becoming widely
available from the LDC. Finally, we have argued that
the output of feature detection is useful for exploit-
ing these linguistic features via a feature-rich gram-
mar for a machine translation system.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998989166666667">
We would like to thank our colleagues Alon Lavie,
Vamshi Ambati, Abhaya Agarwal, and Alok Par-
likar for their insights. Thanks to Keisuke Kamataki
for the Japanese example and to Shakthi Poornima
for her help with the Urdu examples. This work was
supported by US NSF Grant Number 0713-292.
</bodyText>
<page confidence="0.999668">
85
</page>
<sectionHeader confidence="0.995871" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999588953125">
Alison Alvarez, Lori Levin, Robert Frederking, Simon
Fung, Donna Gates, and Jeff Good. 2006. The MILE
corpus for less commonly taught languages. In HLT-
NAACL, New York, New York, June.
H. Bonneau-Maynard, A. Allauzen, D. D´echelotte, and
H. Schwenk. 2007. Combining morphosyntactic en-
riched representation with n-best reranking in statis-
tical translation. In Proceedings of the Workshop on
Structure and Syntax in Statistical Translation (SSST)
at NAACL-HLT.
Jaime Carbonell, Kathrina Probst, Erik Peterson, Chris-
tian Monson, Alon Lavie, Ralf Brown, and Lori Levin.
2002. Automatic rule learning for resource limited
MT. In Association for Machine Translation in the
Americas (AMTA), October.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Association for
Computational Linguistics (ACL).
Jonathan H. Clark, Robert Frederking, and Lori Levin.
2008. Toward active learning in corpus creation: Au-
tomatic discovery of language features during elicita-
tion. In Proceedings of the Language Resources and
Evaluation Conference (LREC).
Yuan Ding and Martha Palmer. 2005. Machine trans-
lation using probabilistic synchronous dependency in-
sertion grammars. In Proceedings of the 43rd Meeting
of the Association for Computational Linguistics ACL.
Bryant Huang and Kevin Knight. 2006. Relabeling syn-
tax trees to improve syntax-based machine translation
quality. In Proceedings of (NAACL-HLT).
Ronald Kaplan. 1995. The formal architecture of lexi-
cal functional grammar. In Mary Dalrymple, Ronald
Kaplan, J. Maxwell, and A. Zaenen, editors, Formal
Issues in Lexical Functional Grammar. CSLI Publica-
tions.
Paul Kay. 2002. An informal sketch of a formal archi-
tecture for construction grammar. In Grammars.
Phillipp Koehn and Hieu Hoang. 2007. Factored trans-
lation models. In Empirical Methods in Natural Lan-
guage Processing (EMNLP).
Lori Levin, Jeff Good, Alison Alvarez, and Robert Fred-
erking. 2006. Parallel reverse treebanks for the dis-
covery of morpho-syntactic markings. In Proceedings
of Treebanks and Linguistic Theory, Prague.
Percy Liang, Alexandre Bouchard-Cote, Dan Klein, and
Ben Taskar. 2006. An end-to-end discriminative ap-
proach to machine translation. In Proceedings of the
44th Annual Meeting of the Association for Computa-
tional Linguistics, Sydney.
Christian Monson, Jaime Carbonell, Alon Lavie, and Lori
Levin. 2007. Paramor: Minimally supervised induc-
tion of paradigm structure and morphological analysis.
In Proceedings of the 9th ACL SIGMORPH.
Shakthi Poornima and Jean-Pierre Koenig. 2008. Re-
verse complex predicates in Hindi. In Proceedings of
the 24th Northwest Linguistic Conference.
Heather Simpson, Christopher Cieri, Kazuaki Maeda,
Kathryn Baker, and Boyan Onyshkevych. 2008. Hu-
man language technology resources for less commonly
taught languages: Lessons learned toward creation of
basic language resources. In Proceedings of the LREC
2008 Workshop on Collaboration: interoperability be-
tween people in the creation of language resources for
less-resourced langauges.
</reference>
<page confidence="0.998496">
86
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.736799">
<title confidence="0.9995535">Inductive Detection of Language Features via Clustering Minimal Toward Feature-Rich Grammars in Machine Translation</title>
<author confidence="0.999778">Jonathan H Clark</author>
<author confidence="0.999778">Robert Frederking</author>
<author confidence="0.999778">Lori</author>
<affiliation confidence="0.9078875">Language Technologies Carnegie Mellon</affiliation>
<address confidence="0.992922">Pittsburgh, PA 15213,</address>
<abstract confidence="0.99527665">Syntax-based Machine Translation systems have recently become a focus of research with much hope that they will outperform traditional Phrase-Based Statistical Machine Translation (PBSMT). Toward this goal, we present a method for analyzing the morphosyntactic content of language from an Elicitation Corpus such as the one included in the LDC’s upcoming LCTL language packs. The presented method discovers a mapping between morphemes and linguistically relevant features. By providing this tool that can augment structure-based MT models with these rich features, we believe the discriminative power of current models can be improved. We conclude by outlining how the resulting output can then be used in inducing a morphosyntactically feature-rich grammar for AV- ENUE, a modern syntax-based MT system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alison Alvarez</author>
<author>Lori Levin</author>
<author>Robert Frederking</author>
<author>Simon Fung</author>
<author>Donna Gates</author>
<author>Jeff Good</author>
</authors>
<title>The MILE corpus for less commonly taught languages. In HLTNAACL,</title>
<date>2006</date>
<location>New York, New York,</location>
<contexts>
<context position="14720" citStr="Alvarez et al., 2006" startWordPosition="2391" endWordPosition="2394">e value was given to the bilingual person to translate). This is the case for the first four features and their values in Figure 1. The last two function features and their values tell us what possible roles participants and clauses can take in sentences. 81 5.2 Elicitation Corpus As outlined in Section 3, feature detection uses an Elicitation Corpus (see Figure 2), a corpus that has been carefully constructed to provide a large number of minimal pairs of sentences such as He sings and She sings so that only a single feature (e.g. gender) differs between the two sentences (Levin et al., 2006; Alvarez et al., 2006). If two features had varied at once (e.g. It sang) or lexical choice varied (e.g. She reads), then making assertions about which features the language does and does not express becomes much more difficult. Notice that each input sentence has been tagged with an identifier for a lexical cluster as a preprocessing step. Specifying lexical clusters ensures that we don’t compare sentences with different content just because their feature structures match. For example, we would not want to compare Dog bites man and Man bites dog nor The student snored and The professor snored. Note that bag-of-wor</context>
</contexts>
<marker>Alvarez, Levin, Frederking, Fung, Gates, Good, 2006</marker>
<rawString>Alison Alvarez, Lori Levin, Robert Frederking, Simon Fung, Donna Gates, and Jeff Good. 2006. The MILE corpus for less commonly taught languages. In HLTNAACL, New York, New York, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bonneau-Maynard</author>
<author>A Allauzen</author>
<author>D D´echelotte</author>
<author>H Schwenk</author>
</authors>
<title>Combining morphosyntactic enriched representation with n-best reranking in statistical translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Structure and Syntax in Statistical Translation (SSST) at NAACL-HLT.</booktitle>
<marker>Bonneau-Maynard, Allauzen, D´echelotte, Schwenk, 2007</marker>
<rawString>H. Bonneau-Maynard, A. Allauzen, D. D´echelotte, and H. Schwenk. 2007. Combining morphosyntactic enriched representation with n-best reranking in statistical translation. In Proceedings of the Workshop on Structure and Syntax in Statistical Translation (SSST) at NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Kathrina Probst</author>
<author>Erik Peterson</author>
<author>Christian Monson</author>
<author>Alon Lavie</author>
<author>Ralf Brown</author>
<author>Lori Levin</author>
</authors>
<title>Automatic rule learning for resource limited MT.</title>
<date>2002</date>
<booktitle>In Association for Machine Translation in the Americas (AMTA),</booktitle>
<contexts>
<context position="11377" citStr="Carbonell et al., 2002" startWordPosition="1839" endWordPosition="1842">showing subject-verb agreement being separated by 12 words. ment if it produced a target-side dependency tree as in Ding and Palmer (2005). However, we are not aware of any systems that attempt this. Therefore, the correct hypotheses, which have correct agreement, will likely be produces as hypotheses of traditional beam-search MT systems, but their features might not be able to discern the correct hypothesis, allowing it to fall below the 1-best or out of the beam entirely. By constructing a feature-rich grammar in a framework that allows unification-based feature constraints such as AVENUE (Carbonell et al., 2002), we can prune these bad hypotheses lacking agreement from the search space. Returning to the example of subject-verb agreement, consider the following Urdu sentences taken from the Urdu-English Elicitation Corpus in LDC’s LCTL language pack: Danish ne Amna ko sza di Danish ERG Amna DAT punish give.PERF “Danish punished Amna.” Danish Amna ko sza dita hai Danish Amna DAT punish give.HAB be.PRES “Danish punishes Amna.” These examples show the split-ergativity of Urdu in which the ergative marker ne is used only for the subject of transitive, perfect aspect verbs. In particular, since these sente</context>
</contexts>
<marker>Carbonell, Probst, Peterson, Monson, Lavie, Brown, Levin, 2002</marker>
<rawString>Jaime Carbonell, Kathrina Probst, Erik Peterson, Christian Monson, Alon Lavie, Ralf Brown, and Lori Levin. 2002. Automatic rule learning for resource limited MT. In Association for Machine Translation in the Americas (AMTA), October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="1407" citStr="Chiang, 2005" startWordPosition="199" endWordPosition="200">t can augment structure-based MT models with these rich features, we believe the discriminative power of current models can be improved. We conclude by outlining how the resulting output can then be used in inducing a morphosyntactically feature-rich grammar for AVENUE, a modern syntax-based MT system. 1 Introduction Recent trends in Machine Translation have begun moving toward the incorporation of syntax and structure in translation models in hopes of gaining better translation quality. In fact, some structurebased systems have already shown that they can outperform phrase-based SMT systems (Chiang, 2005). Still, even the best-performing data-driven systems have not fully explored the depth of such linguistic features as morphosyntax. Certainly, many have brought linguistically motivated features into their models in the past. Huang and Knight (2006) explored relabeling of nonterminal symbols to embed more information di78 rectly into the backbone of the grammar. BonneauMaynard et al. (2007) argue that incorporation of morphosyntax in the form of a part of speech (POS) language model can improve translation. While these approaches do make use of various linguistic features, we have only begun </context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan H Clark</author>
<author>Robert Frederking</author>
<author>Lori Levin</author>
</authors>
<title>Toward active learning in corpus creation: Automatic discovery of language features during elicitation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC).</booktitle>
<contexts>
<context position="6383" citStr="Clark et al., 2008" startWordPosition="1019" endWordPosition="1022">such as He sings and She sings so that only a single feature (e.g. gender) differs between the two sentences. Also, notice that the feature structures are sometimes more detailed than the source language sentence. For example, English does not express dual number, but we might want to include this feature in our Elicitation Corpus (especially for a language such as Arabic). For these cases, we include a context field for the translator with an instruction such as “Translate this sentence as if there are two girls.” In the past, we proposed deductive (rule-based) methods for feature detection (Clark et al., 2008). In this paper, we propose the use of inductive feature detection, which operates directly on the feature set that the corpus has been annotated with, removing the need for manually written rules. We define inductive feature detection as a recall-oriented task since its output is intended to be analyzed by a Morphosyntactic Lexicon Generator, which will address the issue of precision. This, in turn, allows us to inform a rule learner about which language features can be clustered and handled by a single set of rules and which must be given special attention. However, due to the complexity of </context>
</contexts>
<marker>Clark, Frederking, Levin, 2008</marker>
<rawString>Jonathan H. Clark, Robert Frederking, and Lori Levin. 2008. Toward active learning in corpus creation: Automatic discovery of language features during elicitation. In Proceedings of the Language Resources and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Ding</author>
<author>Martha Palmer</author>
</authors>
<title>Machine translation using probabilistic synchronous dependency insertion grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Meeting of the Association for Computational Linguistics ACL.</booktitle>
<contexts>
<context position="10892" citStr="Ding and Palmer (2005)" startWordPosition="1760" endWordPosition="1763">problem without using a huge number of non-terminals, each marked for all possible agreements. A syntax-based system might be able to check this sort of agree80 ek talb alm arshad jo mchhlyoN ke liye pani maiN aata phink raha tha ... a.SG student named Irshad who fish for water in flour throw PROG.SG.M be.PAST.SG.M “A student named Irshad who was throwing flour in the water for the fish ... ” Figure 5: A glossed example from parallel text in LDC’s Urdu-English LCTL language pack showing subject-verb agreement being separated by 12 words. ment if it produced a target-side dependency tree as in Ding and Palmer (2005). However, we are not aware of any systems that attempt this. Therefore, the correct hypotheses, which have correct agreement, will likely be produces as hypotheses of traditional beam-search MT systems, but their features might not be able to discern the correct hypothesis, allowing it to fall below the 1-best or out of the beam entirely. By constructing a feature-rich grammar in a framework that allows unification-based feature constraints such as AVENUE (Carbonell et al., 2002), we can prune these bad hypotheses lacking agreement from the search space. Returning to the example of subject-ve</context>
</contexts>
<marker>Ding, Palmer, 2005</marker>
<rawString>Yuan Ding and Martha Palmer. 2005. Machine translation using probabilistic synchronous dependency insertion grammars. In Proceedings of the 43rd Meeting of the Association for Computational Linguistics ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryant Huang</author>
<author>Kevin Knight</author>
</authors>
<title>Relabeling syntax trees to improve syntax-based machine translation quality.</title>
<date>2006</date>
<booktitle>In Proceedings of (NAACL-HLT).</booktitle>
<contexts>
<context position="1657" citStr="Huang and Knight (2006)" startWordPosition="233" endWordPosition="236">ature-rich grammar for AVENUE, a modern syntax-based MT system. 1 Introduction Recent trends in Machine Translation have begun moving toward the incorporation of syntax and structure in translation models in hopes of gaining better translation quality. In fact, some structurebased systems have already shown that they can outperform phrase-based SMT systems (Chiang, 2005). Still, even the best-performing data-driven systems have not fully explored the depth of such linguistic features as morphosyntax. Certainly, many have brought linguistically motivated features into their models in the past. Huang and Knight (2006) explored relabeling of nonterminal symbols to embed more information di78 rectly into the backbone of the grammar. BonneauMaynard et al. (2007) argue that incorporation of morphosyntax in the form of a part of speech (POS) language model can improve translation. While these approaches do make use of various linguistic features, we have only begun to scratch the surface of what actually occurs in the languages of the world. We wish to address such issues as case marking, subject-verb agreement, and numeral-classifier agreement by providing models with information about which morphemes correspo</context>
</contexts>
<marker>Huang, Knight, 2006</marker>
<rawString>Bryant Huang and Kevin Knight. 2006. Relabeling syntax trees to improve syntax-based machine translation quality. In Proceedings of (NAACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
</authors>
<title>The formal architecture of lexical functional grammar.</title>
<date>1995</date>
<booktitle>Formal Issues in Lexical Functional Grammar.</booktitle>
<editor>In Mary Dalrymple, Ronald Kaplan, J. Maxwell, and A. Zaenen, editors,</editor>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="12644" citStr="Kaplan (1995)" startWordPosition="2047" endWordPosition="2048">di, a closed-class word (Poornima and Koenig, 2008), feature detection will allow the induction of a grammar that percolates a feature up from the VP containing di indicating that its aspect is perfect. Likewise, the NP containing Danish ne will percolate a feature up indicating that the use of ne requires perfect aspect. If, during translation, a hypothesis is proposed that does not meet either of these conditions, unification will fail and the hypothesis will be pruned 1. Certainly, unification-based grammars are not the 1If the reader is not familiar with Unification Grammars, we recommend Kaplan (1995) only way in which this rich source of linguistic information could be used to augment a structure-based translation system. One could also imagine a system in which the feature annotations are simply used to improve the discriminative power of a model. For example, factored translation models (Koehn and Hoang, 2007) retain the simplicity of phrase-based SMT while adding the ability to incorporate additional features. Similarly, there exists a continuum of degrees to which this linguistic information can be used in current syntax-based MT systems. As modern systems move toward integrating many</context>
</contexts>
<marker>Kaplan, 1995</marker>
<rawString>Ronald Kaplan. 1995. The formal architecture of lexical functional grammar. In Mary Dalrymple, Ronald Kaplan, J. Maxwell, and A. Zaenen, editors, Formal Issues in Lexical Functional Grammar. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kay</author>
</authors>
<title>An informal sketch of a formal architecture for construction grammar. In Grammars.</title>
<date>2002</date>
<contexts>
<context position="8674" citStr="Kay, 2002" startWordPosition="1391" endWordPosition="1392">ure Detection Grammar Rule Learner Morphosyntactic Lexicon Generator Unsupervised Morphology Induction Elicitation Corpus 3 The Need to Observe Real Data One might argue that such information could be obtained from a grammatical sketch of a language. However, these sketches often focus on the “interesting” features of a language, rather than those that are most important for machine translation. Further, not all grammatical functions are encoded in the elements that most grammatical sketches focus on. According to Construction Grammar, such information is also commonly found in constructions (Kay, 2002). For example, future tense is not grammaticalized in Japanese according to most reference sources, yet it may be expressed with a construction such as watashi wa gakoo ni iku yode desu (lit. “I have a plan to go to school.”) for I will go to school. Feature detection informs us of such constructionalized encodings of language features for use in improving machine translation models. Recognizing the need for this type of data, the LDC has included our Elicitation Corpus in their Less Commonly Taught Languages (LCTL) language packs (Simpson et al., 2008). Already, these language packs have been</context>
</contexts>
<marker>Kay, 2002</marker>
<rawString>Paul Kay. 2002. An informal sketch of a formal architecture for construction grammar. In Grammars.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phillipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="12962" citStr="Koehn and Hoang, 2007" startWordPosition="2096" endWordPosition="2099">erfect aspect. If, during translation, a hypothesis is proposed that does not meet either of these conditions, unification will fail and the hypothesis will be pruned 1. Certainly, unification-based grammars are not the 1If the reader is not familiar with Unification Grammars, we recommend Kaplan (1995) only way in which this rich source of linguistic information could be used to augment a structure-based translation system. One could also imagine a system in which the feature annotations are simply used to improve the discriminative power of a model. For example, factored translation models (Koehn and Hoang, 2007) retain the simplicity of phrase-based SMT while adding the ability to incorporate additional features. Similarly, there exists a continuum of degrees to which this linguistic information can be used in current syntax-based MT systems. As modern systems move toward integrating many features (Liang et al., 2006), resources such as this will become increasingly important in improving translation quality. 5 System Description In the following sections, we will describe the process of inductive feature detection by way of a running example. 5.1 Feature Specification The first input to our system i</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Phillipp Koehn and Hieu Hoang. 2007. Factored translation models. In Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lori Levin</author>
<author>Jeff Good</author>
<author>Alison Alvarez</author>
<author>Robert Frederking</author>
</authors>
<title>Parallel reverse treebanks for the discovery of morpho-syntactic markings.</title>
<date>2006</date>
<booktitle>In Proceedings of Treebanks and Linguistic Theory,</booktitle>
<location>Prague.</location>
<contexts>
<context position="14697" citStr="Levin et al., 2006" startWordPosition="2387" endWordPosition="2390">e having that feature value was given to the bilingual person to translate). This is the case for the first four features and their values in Figure 1. The last two function features and their values tell us what possible roles participants and clauses can take in sentences. 81 5.2 Elicitation Corpus As outlined in Section 3, feature detection uses an Elicitation Corpus (see Figure 2), a corpus that has been carefully constructed to provide a large number of minimal pairs of sentences such as He sings and She sings so that only a single feature (e.g. gender) differs between the two sentences (Levin et al., 2006; Alvarez et al., 2006). If two features had varied at once (e.g. It sang) or lexical choice varied (e.g. She reads), then making assertions about which features the language does and does not express becomes much more difficult. Notice that each input sentence has been tagged with an identifier for a lexical cluster as a preprocessing step. Specifying lexical clusters ensures that we don’t compare sentences with different content just because their feature structures match. For example, we would not want to compare Dog bites man and Man bites dog nor The student snored and The professor snore</context>
</contexts>
<marker>Levin, Good, Alvarez, Frederking, 2006</marker>
<rawString>Lori Levin, Jeff Good, Alison Alvarez, and Robert Frederking. 2006. Parallel reverse treebanks for the discovery of morpho-syntactic markings. In Proceedings of Treebanks and Linguistic Theory, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Alexandre Bouchard-Cote</author>
<author>Dan Klein</author>
<author>Ben Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Sydney.</location>
<contexts>
<context position="13274" citStr="Liang et al., 2006" startWordPosition="2144" endWordPosition="2147">n which this rich source of linguistic information could be used to augment a structure-based translation system. One could also imagine a system in which the feature annotations are simply used to improve the discriminative power of a model. For example, factored translation models (Koehn and Hoang, 2007) retain the simplicity of phrase-based SMT while adding the ability to incorporate additional features. Similarly, there exists a continuum of degrees to which this linguistic information can be used in current syntax-based MT systems. As modern systems move toward integrating many features (Liang et al., 2006), resources such as this will become increasingly important in improving translation quality. 5 System Description In the following sections, we will describe the process of inductive feature detection by way of a running example. 5.1 Feature Specification The first input to our system is a feature specification (Figure 1). The feature specification used for this experiment was written by an expert in language typology and is stored in a human-readable XML format. It is intended to cover a large number of phenomena that are possible in the languages of the world. Note that features beginning w</context>
</contexts>
<marker>Liang, Bouchard-Cote, Klein, Taskar, 2006</marker>
<rawString>Percy Liang, Alexandre Bouchard-Cote, Dan Klein, and Ben Taskar. 2006. An end-to-end discriminative approach to machine translation. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Monson</author>
<author>Jaime Carbonell</author>
<author>Alon Lavie</author>
<author>Lori Levin</author>
</authors>
<title>Paramor: Minimally supervised induction of paradigm structure and morphological analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the 9th ACL SIGMORPH.</booktitle>
<contexts>
<context position="7176" citStr="Monson et al., 2007" startWordPosition="1157" endWordPosition="1161"> manually written rules. We define inductive feature detection as a recall-oriented task since its output is intended to be analyzed by a Morphosyntactic Lexicon Generator, which will address the issue of precision. This, in turn, allows us to inform a rule learner about which language features can be clustered and handled by a single set of rules and which must be given special attention. However, due to the complexity of this component, describing it is beyond the scope of this paper. We also note that future work will include the integration of a morphology analysis system such as ParaMor (Monson et al., 2007) to extract and annotate the valuable morphosyntactic information of inflected languages. An example of this processing pipeline is given in Figure 4. 79 Feature Value Candidate Morphemes np-gen m el, ni˜no np-gen f ella, ni˜na np-gen n *unobserved* np-def + el, la, las np-def - una, unas np-num sg el, ella, la, una, come, ni˜no, ni˜na np-num dl-pl las, unas, comen, ni˜nas c-ten past-pres – c-ten fut *unobserved* Figure 3: An example of the output of our system for the above corpus: a list of feature-morpheme pairings. Figure 4: An outline of the steps from an input Elicitation Corpus to the a</context>
</contexts>
<marker>Monson, Carbonell, Lavie, Levin, 2007</marker>
<rawString>Christian Monson, Jaime Carbonell, Alon Lavie, and Lori Levin. 2007. Paramor: Minimally supervised induction of paradigm structure and morphological analysis. In Proceedings of the 9th ACL SIGMORPH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shakthi Poornima</author>
<author>Jean-Pierre Koenig</author>
</authors>
<title>Reverse complex predicates in Hindi.</title>
<date>2008</date>
<booktitle>In Proceedings of the 24th Northwest Linguistic Conference.</booktitle>
<contexts>
<context position="12082" citStr="Poornima and Koenig, 2008" startWordPosition="1952" endWordPosition="1955">turning to the example of subject-verb agreement, consider the following Urdu sentences taken from the Urdu-English Elicitation Corpus in LDC’s LCTL language pack: Danish ne Amna ko sza di Danish ERG Amna DAT punish give.PERF “Danish punished Amna.” Danish Amna ko sza dita hai Danish Amna DAT punish give.HAB be.PRES “Danish punishes Amna.” These examples show the split-ergativity of Urdu in which the ergative marker ne is used only for the subject of transitive, perfect aspect verbs. In particular, since these sentences have the perfect aspect marked on the light verb di, a closed-class word (Poornima and Koenig, 2008), feature detection will allow the induction of a grammar that percolates a feature up from the VP containing di indicating that its aspect is perfect. Likewise, the NP containing Danish ne will percolate a feature up indicating that the use of ne requires perfect aspect. If, during translation, a hypothesis is proposed that does not meet either of these conditions, unification will fail and the hypothesis will be pruned 1. Certainly, unification-based grammars are not the 1If the reader is not familiar with Unification Grammars, we recommend Kaplan (1995) only way in which this rich source of</context>
</contexts>
<marker>Poornima, Koenig, 2008</marker>
<rawString>Shakthi Poornima and Jean-Pierre Koenig. 2008. Reverse complex predicates in Hindi. In Proceedings of the 24th Northwest Linguistic Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heather Simpson</author>
<author>Christopher Cieri</author>
<author>Kazuaki Maeda</author>
<author>Kathryn Baker</author>
<author>Boyan Onyshkevych</author>
</authors>
<title>Human language technology resources for less commonly taught languages: Lessons learned toward creation of basic language resources.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC</booktitle>
<contexts>
<context position="9233" citStr="Simpson et al., 2008" startWordPosition="1485" endWordPosition="1488">nformation is also commonly found in constructions (Kay, 2002). For example, future tense is not grammaticalized in Japanese according to most reference sources, yet it may be expressed with a construction such as watashi wa gakoo ni iku yode desu (lit. “I have a plan to go to school.”) for I will go to school. Feature detection informs us of such constructionalized encodings of language features for use in improving machine translation models. Recognizing the need for this type of data, the LDC has included our Elicitation Corpus in their Less Commonly Taught Languages (LCTL) language packs (Simpson et al., 2008). Already, these language packs have been translated into Thai, Bengali, Urdu, Hungarian, Punjabi, Tamil, and Yoruba. With structured elicitation corpora already being produced on a wide scale, there exists plenty of data that can be exploited via feature detection. Some of these language packs have already been released for use in MT competitions and they will start being released to the general research community this year through LDC’s catalog. 4 Applications 4.1 Induction of Feature-Rich Grammars Given these outputs, a synchronous grammar induction system can then use these feature-annotat</context>
</contexts>
<marker>Simpson, Cieri, Maeda, Baker, Onyshkevych, 2008</marker>
<rawString>Heather Simpson, Christopher Cieri, Kazuaki Maeda, Kathryn Baker, and Boyan Onyshkevych. 2008. Human language technology resources for less commonly taught languages: Lessons learned toward creation of basic language resources. In Proceedings of the LREC 2008 Workshop on Collaboration: interoperability between people in the creation of language resources for less-resourced langauges.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>