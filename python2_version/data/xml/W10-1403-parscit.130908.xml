<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000044">
<title confidence="0.9655895">
Two methods to incorporate local morphosyntactic features in Hindi de-
pendency parsing
</title>
<author confidence="0.716408">
Bharat Ram Ambati, Samar Husain, Sambhav Jain, Dipti Misra Sharma
and Rajeev Sangal
</author>
<affiliation confidence="0.880329">
Language Technologies Research Centre, IIIT-Hyderabad, India - 500032.
</affiliation>
<email confidence="0.963295">
{ambati,samar}@research.iiit.ac.in, sambhav-
jain@students.iiit.ac.in,{dipti,sangal}@mail.iiit.ac.in
</email>
<sectionHeader confidence="0.99359" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996856454545455">
In this paper we explore two strategies to in-
corporate local morphosyntactic features in
Hindi dependency parsing. These features are
obtained using a shallow parser. We first ex-
plore which information provided by the shal-
low parser is most beneficial and show that
local morphosyntactic features in the form of
chunk type, head/non-head information,
chunk boundary information, distance to the
end of the chunk and suffix concatenation are
very crucial in Hindi dependency parsing. We
then investigate the best way to incorporate
this information during dependency parsing.
Further, we compare the results of various ex-
periments based on various criterions and do
some error analysis. All the experiments were
done with two data-driven parsers, MaltParser
and MSTParser, on a part of multi-layered and
multi-representational Hindi Treebank which
is under development. This paper is also the
first attempt at complete sentence level pars-
ing for Hindi.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.988914076923077">
The dependency parsing community has since a
few years shown considerable interest in parsing
morphologically rich languages with flexible word
order. This is partly due to the increasing availabil-
ity of dependency treebanks for such languages,
but it is also motivated by the observation that the
performance obtained for these languages have not
been very high (Nivre et al., 2007a). Attempts at
handling various non-configurational aspects in
these languages have pointed towards shortcom-
ings in traditional parsing methodologies (Tsarfaty
and Sima&apos;an, 2008; Eryigit et al., 2008; Seddah et
al., 2009; Husain et al., 2009; Gadde et al., 2010).
</bodyText>
<page confidence="0.948566">
22
</page>
<bodyText confidence="0.999977">
Among other things, it has been pointed out that
the use of language specific features may play a
crucial role in improving the overall parsing per-
formance. Different languages tend to encode syn-
tactically relevant information in different ways,
and it has been hypothesized that the integration of
morphological and syntactic information could be
a key to better accuracy. However, it has also been
noted that incorporating these language specific
features in parsing is not always straightforward
and many intuitive features do not always work in
expected ways.
In this paper we explore various strategies to in-
corporate local morphosyntactic features in Hindi
dependency parsing. These features are obtained
using a shallow parser. We conducted experiments
with two data-driven parsers, MaltParser (Nivre et
al., 2007b) and MSTParser (McDonald et al.,
2006). We first explore which information pro-
vided by the shallow parser is most beneficial and
show that local morphosyntactic features in the
form of chunk type, head/non-head information,
chunk boundary information, distance to the end of
the chunk and suffix concatenation are very crucial
in Hindi dependency parsing. We then investigate
the best way to incorporate this information during
dependency parsing. All the experiments were
done on a part of multi-layered and multi-
representational Hindi Treebank (Bhatt et al.,
2009)1.
The shallow parser performs three tasks, (a) it
gives the POS tags for each lexical item, (b) pro-
vides morphological features for each lexical item,
and (c) performs chunking. A chunk is a minimal
(non-recursive) phrase consisting of correlated,
inseparable words/entities, such that the intra-
chunk dependencies are not distorted (Bharati et
</bodyText>
<footnote confidence="0.984605">
1 This Treebank is still under development. There are currently
27k tokens with complete sentence level annotation.
</footnote>
<note confidence="0.992796">
Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 22–30,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.994312945945946">
al., 2006). Together, a group of lexical items with
some POS tag and morphological features within a
chunk can be utilized to automatically compute
local morphosyntactic information. For example,
such information can represent the postposi-
tion/case-marking in the case of noun chunks, or it
may represent the tense, aspect and modality
(TAM) information in the case of verb chunks. In
the experiments conducted for this paper such local
information is automatically computed and incor-
porated as a feature to the head of a chunk. In gen-
eral, local morphosyntactic features correspond to
all the parsing relevant local linguistic features that
can be utilized using the notion of chunk. Previous-
ly, there have been some attempts at using chunk
information in dependency parsing. Attardi and
Dell’Orletta (2008) used chunking information in
parsing English. They got an increase of 0.35% in
labeled attachment accuracy and 0.47% in unla-
beled attachment accuracy over the state-of-the-art
dependency parser.
Among the three components (a-c, above), the
parsing accuracy obtained using the POS feature is
taken as baseline. We follow this by experiments
where we explore how each of morph and chunk
features help in improving dependency parsing
accuracy. In particular, we find that local morpho-
syntactic features are the most crucial. These expe-
riments are discussed in section 2. In section 3 we
will then see an alternative way to incorporate the
best features obtained in section 2. In all the pars-
ing experiments discussed in section 2 and 3, at
each step we explore all possible features and ex-
tract the best set of features. Best features of one
experiment are used when we go to the next set of
experiments. For example, when we explore the
effect of chunk information, all the relevant morph
information from previous set of experiments is
taken into account.
This paper is also the first attempt at complete
sentence level parsing for Hindi. Due to the availa-
bility of dependency treebank for Hindi (Begum et
al., 2008), there have been some previous attempts
at Hindi data-driven dependency parsing (Bharati
et al., 2008; Mannem et al., 2009; Husain et al.,
2009). Recently in ICON-09 NLP Tools Contest
(Husain, 2009; and the references therein), rule-
based, constraint based, statistical and hybrid ap-
proaches were explored for dependency parsing.
Previously, constraint based approaches to Indian
language (IL) dependency parsing have also been
explored (Bharati et al., 1993, 1995, 2009b,
2009c). All these attempts, however, were finding
inter-chunk dependency relations, given gold-
standard POS and chunk tags. Unlike these pre-
vious parsers, the dependencies in this work are
between lexical items, i.e. the dependency tree is
complete.
The paper is arranged as follows, in section 2
and 3, we discuss the parsing experiments. In sec-
tion 4, we describe the data and parser settings.
Section 5 gives the results and discusses some re-
lated issues. General discussion and possible future
work is mentioned in section 6. We conclude the
paper in section 7.
2 Getting the best linguistic features
As mentioned earlier, a shallow parser consists of
three main components, (a) POS tagger, (b) mor-
phological analyzer and (c) chunker. In this section
we systematically explore what is the effect of
each of these components. We’ll see in section 2.3
that the best features of a-c can be used to compute
local morphosyntactic features that, as the results
show, are extremely useful.
</bodyText>
<subsectionHeader confidence="0.999792">
2.1 Using POS as feature (PaF):
</subsectionHeader>
<bodyText confidence="0.999948833333333">
In this experiment we only use the POS tag infor-
mation of individual words during dependency
parsing. First a raw sentence is POS-tagged. This
POS-tagged sentence is then given to a parser to
predict the dependency relations. Figure 1, shows
the steps involved in this approach for (1).
</bodyText>
<listItem confidence="0.572724">
(1) raama ne eka seba khaayaa
</listItem>
<subsectionHeader confidence="0.6138575">
‘Ram’ ERG ‘one’ ‘apple’ ‘ate’
‘Ram ate an apple’
</subsectionHeader>
<figureCaption confidence="0.947222">
Figure 1: Dependency parsing using only POS informa-
tion from a shallow parser.
</figureCaption>
<page confidence="0.995824">
23
</page>
<bodyText confidence="0.9981546">
In (1) above, ‘NN’, ‘PSP’, ‘QC’, ‘NN’ and ‘VM’
are the POS tags2 for raama, ne, eka, seba and
khaayaa respectively. This information is provided
as a feature to the parser. The result of this experi-
ment forms our baseline accuracy.
</bodyText>
<subsectionHeader confidence="0.999961">
2.2 Using Morph as feature (MaF):
</subsectionHeader>
<bodyText confidence="0.9998474">
In addition to POS information, in this experiment
we also use the morph information for each token.
This morphological information is provided as a
feature to the parser. Morph has the following in-
formation
</bodyText>
<listItem confidence="0.999714857142857">
· Root: Root form of the word
· Category: Course grained POS
· Gender: Masculine/Feminine/Neuter
· Number: Singular/Plural
· Person: First/Second/Third person
· Case: Oblique/Direct case
· Suffix: Suffix of the word
</listItem>
<bodyText confidence="0.997450166666667">
Take raama in (1), its morph information com-
prises of root = ‘raama’, category = ‘noun’ gender
= ‘masculine’, number = ‘singular’, person =
‘third’, case = ‘direct’, suffix = ‘0’. Similarly,
khaayaa (‘ate’) has the following morph informa-
tion. root = ‘khaa’, category = ‘verb’ gender =
‘masculine’, numer = ‘singular’, person = ‘third’,
case = ‘direct’, suffix = ‘yaa’.
Through a series of experiments, the most cru-
cial morph features were selected. Root, case and
suffix turn out to be the most important features.
Results are discussed in section 5.
</bodyText>
<subsectionHeader confidence="0.9195555">
2.3 Using local morphosyntax as feature
(LMSaF)
</subsectionHeader>
<bodyText confidence="0.997454">
Along with POS and the most useful morph fea-
tures (root, case and suffix), in this experiment we
also use local morphosyntactic features that reflect
various chunk level information. These features
are:
</bodyText>
<listItem confidence="0.7551942">
· Type of the chunk
· Head/non-head of the chunk
2 NN: Common noun, PSP: Post position, QC: Cardinal, VM:
Verb. A list of complete POS tags can be found here:
http://ltrc.iiit.ac.in/MachineTrans/research/tb/POS-Tag-
List.pdf. The POS/chunk tag scheme followed in the Treebank
is described in Bharati et al. (2006).
· Chunk boundary information
· Distance to the end of the chunk
· Suffix concatenation
</listItem>
<bodyText confidence="0.999163727272727">
In example 1 (see section 2.1), there are two
noun chunks and one verb chunk. raama and seba
are the heads of the noun chunks. khaayaa is the
head of the verb chunk. We follow standard IOB3
notation for chunk boundary. raama, eka and
khaayaa are at the beginning (B) of their respective
chunks. ne and seba are inside (I) their respective
chunks. raama is at distance 1 from the end of the
chunk and ne is at a distance 0 from the end of the
chunk.
Once we have a chunk and morph feature like
suffix, we can perform suffix concatenation auto-
matically. A group of lexical items with some POS
tags and suffix information within a chunk can be
utilized to automatically compute this feature. This
feature can, for example, represent the postposi-
tion/case-marking in the case of noun chunk, or it
may represent the tense, aspect and modality
(TAM) information in the case of verb chunks.
Note that, this feature becomes part of the lexical
item that is the head of a chunk. Take (2) as a case
in point:
</bodyText>
<listItem confidence="0.396516">
(2) [NP raama/NNP ne/PSP] [NP seba/NN]
</listItem>
<bodyText confidence="0.3671395">
‘Ram’ ERG ‘apple’
[VGF khaa/VM liyaa/VAUX]
</bodyText>
<subsectionHeader confidence="0.5787485">
‘eat’ ‘PRFT’
‘Ram ate an apple’
</subsectionHeader>
<bodyText confidence="0.9999196">
The suffix concatenation feature for khaa, which
is the head of the VGF chunk, will be ‘0+yaa’ and
is formed by concatenating the suffix of the main
verb with that of its auxiliary. Similarly, the suffix
concatenation feature for raama, which is head of
the NP chunk, will be ‘0+ne’. This feature turns
out to be very important. This is because in Hindi
(and many other Indian languages) there is a direct
correlation between the TAM markers and the case
that appears on some nominals (Bharati et al.,
1995). In (2), for example, khaa liyaa together
gives the past perfective aspect for the verb khaa-
naa ‘to eat’. Since, Hindi is split ergative, the sub-
ject of the transitive verb takes an ergative case
marker when the verb is past perfective. Similar
</bodyText>
<page confidence="0.978054">
3 Inside, Outside, Beginning of the chunk.
24
</page>
<bodyText confidence="0.9989845">
correlation between the case markers and TAM
exist in many other cases.
</bodyText>
<sectionHeader confidence="0.355331" genericHeader="method">
3 An alternative approach to use best fea-
tures: A 2-stage setup (2stage)
</sectionHeader>
<bodyText confidence="0.986909608695652">
So far we have been using various information
such as POS, chunk, etc. as features. Rather than
using them as features and doing parsing at one go,
we can alternatively follow a 2-stage setup. In par-
ticular, we divide the task of parsing into:
· Intra-chunk dependency parsing
· Inter-chunk dependency parsing
We still use POS, best morphological features
(case, suffix, root) information as regular features
during parsing. But unlike LMSaF mentioned in
section 2.3, where we gave local morphosyntactic
information as a feature, we divided the task of
parsing into sub-tasks. A similar approach was also
proposed by Bharati et al. (2009c). During intra-
chunk dependency parsing, we try to find the de-
pendency relations of the words within a chunk.
Following which, chunk heads of each chunk with-
in a sentence are extracted. On these chunk heads
we run an inter-chunk dependency parser. For each
chunk head, in addition to POS tag, useful morpho-
logical features, any useful intra-chunk information
in the form of lexical item, suffix concatenation,
dependency relation are also given as a feature.
</bodyText>
<figureCaption confidence="0.9637075">
Figure 2: Dependency parsing using chunk information:
2-stage approach.
</figureCaption>
<bodyText confidence="0.998092375">
Figure 2 shows the steps involved in this ap-
proach for (1). There are two noun chunks and one
verb chunk in this sentence. raama and seba are
the heads of the noun chunks. khaaya is the head
of the verb chunk. The intra-chunk parser attaches
ne to raama and eka to seba with dependency la-
bels ‘lwg psp’ and ‘nmod__adj’4 respectively.
Heads of each chunk along with its POS, morpho-
logical features, local morphosyntactic features and
intra-chunk features are extracted and given to in-
ter-chunk parser. Using this information the inter-
chunk dependency parser marks the dependency
relations between chunk heads. khaaya becomes
the root of the dependency tree. raama and seba
are attached to khaaya with dependency labels ‘k1’
and ‘k2’5 respectively.
</bodyText>
<sectionHeader confidence="0.999523" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.997824">
In this section we describe the data and the parser
settings used for our experiments.
</bodyText>
<subsectionHeader confidence="0.961746">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.9999819">
For our experiments we took 1228 dependency
annotated sentences (27k tokens), which have
complete sentence level annotation from the new
multi-layered and multi-representational Hindi
Treebank (Bhatt et al., 2009). This treebank is still
under development. Average length of these sen-
tences is 22 tokens/sentence and 10
chunks/sentence. We divided the data into two
sets, 1000 sentences for training and 228 sentences
for testing.
</bodyText>
<subsectionHeader confidence="0.99465">
4.2 Parsers and settings
</subsectionHeader>
<bodyText confidence="0.903395428571429">
All experiments were performed using two data-
driven parsers, MaltParser6 (Nivre et al., 2007b),
and MSTParser7 (McDonald et al., 2006).
4 nmod__adj is an intra-chunk label for quantifier-noun mod-
ification. lwg psp is the label for post-position marker. De-
tails of the labels can be seen in the intra-chunk guidelines
http://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunk-
Dependency-Annotation-Guidelines.pdf
5 k1 (karta) and k2 (karma) are syntactico-semantic labels
which have some properties of both grammatical roles and
thematic roles. k1 behaves similar to subject and agent. k2
behaves similar to object and patient (Bharati et al., 1995;
Vaidya et al., 2009). For complete tagset, see (Bharati et al.,
2009).
</bodyText>
<page confidence="0.799219333333333">
6 Malt Version 1.3.1
7 MST Version 0.4b
25
</page>
<table confidence="0.999758285714286">
Malt MST+MaxEnt
Cross-validation Test-set Cross-validation Test-set
UAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LS
PaF 89.4 78.2 80.5 90.4 80.1 82.4 86.3 75.1 77.9 87.9 77.0 79.3
MaF 89.6 80.5 83.1 90.4 81.7 84.1 89.1 79.2 82.5 90.0 80.9 83.9
LMSaF 91.5 82.7 84.7 91.8 84.0 86.2 90.8 79.8 82.0 92.0 81.8 83.8
2stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2
</table>
<tableCaption confidence="0.999955">
Table 1: Results of all the four approaches using gold-standard shallow parser information.
</tableCaption>
<bodyText confidence="0.999643">
Malt is a classifier based shift/reduce parser. It
provides option for six parsing algorithms, namely,
arc-eager, arc-standard, convington projective, co-
vington non-projective, stack projective, stack ea-
ger and stack lazy. The parser also provides option
for libsvm and liblinear learning model. It uses
graph transformation to handle non-projective trees
(Nivre and Nilsson, 2005). MST uses Chu-Liu-
Edmonds (Chu and Liu, 1965; Edmonds, 1967)
Maximum Spanning Tree algorithm for non-
projective parsing and Eisner&apos;s algorithm for pro-
jective parsing (Eisner, 1996). It uses online large
margin learning as the learning algorithm (McDo-
nald et al., 2005). In this paper, we use MST only
for unlabeled dependency tree and use a separate
maximum entropy model8 (MaxEnt) for labeling.
Various combination of features such as node, its
parent, siblings and children were tried out before
arriving at the best results.
As the training data size is small we did 5-fold
cross validation on the training data for tuning the
parameters of the parsers and for feature selection.
Best settings obtained using cross-validated data
are applied on test set. We present the results both
on cross validated data and on test data.
For the Malt Parser, arc-eager algorithm gave
better performance over others in all the approach-
es. Libsvm consistently gave better performance
over liblinear in all the experiments. For SVM set-
tings, we tried out different combinations of best
SVM settings of the same parser on different lan-
guages in CoNLL-2007 shared task (Hall et al.,
2007) and applied the best settings. For feature
model, apart from trying best feature settings of the
same parser on different languages in CoNLL-
2007 shared task (Hall et al., 2007), we also tried
out different combinations of linguistically intui-
tive features and applied the best feature model.
The best feature model is same as the feature mod-
el used in Ambati et al. (2009a), which is the best
</bodyText>
<footnote confidence="0.636678">
8 http://maxent.sourceforge.net/
</footnote>
<bodyText confidence="0.9904295">
performing system in the ICON-2009 NLP Tools
Contest (Husain, 2009).
For the MSTParser, non-projective algorithm,
order=2 and training-k=5 gave best results in all
the approaches. For the MaxEnt, apart from some
general useful features, we experimented consider-
ing different combinations of features of node, par-
ent, siblings, and children of the node.
</bodyText>
<sectionHeader confidence="0.997823" genericHeader="evaluation">
5 Results and Analysis
</sectionHeader>
<bodyText confidence="0.999966857142857">
All the experiments discussed in section 2 and 3
were performed considering both gold-standard
shallow parser information and automatic shallow
parser9 information. Automatic shallow parser uses
a rule based system for morph analysis, a
CRF+TBL based POS-tagger and chunker. The
tagger and chunker are 93% and 87% accurate re-
spectively. These accuracies are obtained after us-
ing the approach of PVS and Gali, (2007) on larger
training data. In addition, while using automatic
shallow parser information to get the results, we
also explored using both gold-standard and auto-
matic information during training. As expected,
using automatic shallow parser information for
training gave better performance than using gold
while training.
Table 1 and Table 2 shows the results of the four
experiments using gold-standard and automatic
shallow parser information respectively. We eva-
luated our experiments based on unlabeled attach-
ment score (UAS), labeled attachment score (LAS)
and labeled score (LS) (Nivre et al., 2007a). Best
LAS on test data is 84.4% (with 2stage) and 75.4%
(with LMSaF) using gold and automatic shallow
parser information respectively. These results are
obtained using MaltParser. In the following sub-
section we discuss the results based on different
criterion.
</bodyText>
<footnote confidence="0.911136">
9 http://ltrc.iiit.ac.in/analyzer/hindi/
</footnote>
<page confidence="0.987889">
26
</page>
<table confidence="0.999547428571429">
Malt MST+MaxEnt
Cross-validation Test-set Cross-validation Test-set
UAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LS
PaF 82.2 69.3 73.4 84.6 72.9 76.5 79.4 66.5 70.7 81.6 69.4 73.1
MaF 82.5 71.6 76.1 84.0 73.6 77.6 82.3 70.4 75.4 83.4 72.7 77.3
LMSaF 83.2 73.0 77.0 85.5 75.4 78.9 82.6 71.3 76.1 85.0 73.4 77.3
2stage 79.0 69.5 75.6 79.6 71.1 76.8 78.8 66.6 72.6 80.1 69.7 75.4
</table>
<tableCaption confidence="0.999804">
Table 2: Results of all the four experiments using automatic shallow parser information.
</tableCaption>
<bodyText confidence="0.999876653846154">
POS tags provide very basic linguistic informa-
tion in the form of broad grained categories. The
best LAS for PaF while using gold and automatic
tagger were 80.1% and 72.9% respectively. The
morph information in the form of case, suffix and
root information proved to be the most important
features. But surprisingly, gender, number and per-
son features didn’t help. Agreement patterns in
Hindi are not straightforward. For example, the
verb agrees with k2 if the k1 has a post-position; it
may also sometimes take the default features. In a
passive sentence, the verb agrees only with k2. The
agreement problem worsens when there is coordi-
nation or when there is a complex verb. It is un-
derstandable then that the parser is unable to learn
the selective agreement pattern which needs to be
followed.
LMSaF on the other hand encode richer infor-
mation and capture some local linguistic patterns.
The first four features in LMSaF (chunk type,
chunk boundary, head/non-head of chunk and dis-
tance to the end of chunk) were found to be useful
consistently. The fifth feature, in the form of suffix
concatenation, gave us the biggest jump, and cap-
tures the correlation between the TAM markers of
the verbs and the case markers on the nominals.
</bodyText>
<subsectionHeader confidence="0.9901185">
5.1 Feature comparison: PaF, MaF vs.
LMSaF
</subsectionHeader>
<bodyText confidence="0.998600814814815">
Dependency labels can be classified as two types
based on their nature, namely, inter-chunk depen-
dency labels and intra-chunk labels. Inter-chunk
dependency labels are syntacto-semantic in nature.
Whereas intra-chunk dependency labels are purely
syntactic in nature.
Figure 3, shows the f-measure for top six inter-
chunk and intra-chunk dependency labels for PaF,
MaF, and LMSaF using Maltparser on test data
using automatic shallow parser information. The
first six labels (k1, k2, pof, r6, ccof, and k7p) are
the top six inter-chunk labels and the next six la-
bels (lwg psp, lwg__aux, lwg__cont, rsym,
nmod__adj, and pof__cn) are the top six intra-
chunk labels. First six labels (inter-chunk) corres-
pond to 28.41% and next six labels (intra-chunk)
correspond to 48.81% of the total labels in the test
data. The figure shows that with POS information
alone, f-measure for top four intra-chunk labels
reached more than 90% accuracy. The accuracy
increases marginally with the addition of morph
and local morphosytactic features. The results cor-
roborates with our intuition that intra-chunk de-
pendencies are mostly syntactic. For example,
consider an intra-chunk label ‘lwg psp’. This is
the label for postposition marker. A post-position
marker succeeding a noun is attached to that noun
with the label ‘lwg psp’. POS tag for post-
position marker is PSP. So, if a NN (common
noun) or a NNP (proper noun) is followed by a
PSP (post-position marker), then the PSP will be
attached to the preceding NN/NNP with the de-
pendency label ‘lwg_psp’. As a result, providing
POS information itself gave an f-measure of 98.3%
for ‘lwg_psp’. With morph and local morphosy-
tactic features, this got increased to 98.4%. How-
ever, f-measure for some labels like ‘nmod__adj’
is around 80% only. ‘nmod__adj’ is the label for
adjective-noun, quantifier-noun modifications.
Low accuracy for these labels is mainly due to two
reasons. One is POS tag errors. And the other is
attachment errors due to genuine ambiguities such
as compounding.
For inter-chunk labels (first six columns in the
figure 3), there is considerable improvement in the
f-measure using morph and local morphosytactic
features. As mentioned, local morphosyntactic fea-
tures provide local linguistic information. For ex-
ample, consider the case of verbs. At POS level,
there are only two tags ‘VM’ and ‘VAUX’ for
main verbs and auxiliary verbs respectively (Bha-
rati et al., 2006). Information about finite/non-
finiteness is not present in the POS tag. But, at
chunk level there are four different chunk tags for
</bodyText>
<page confidence="0.99404">
27
</page>
<table confidence="0.902079">
100 PaF
90 MaF
80 LMaF
70
60
50
40
30
k1 k2 pof r6 ccof k7p lwg__psp lwg__vaux lwg__cont rsym nmod__adj pof__cn
</table>
<figureCaption confidence="0.9940015">
Figure 3: F-measure of top 6, inter-chunk and intra-chunk labels for PaF, MaF and LMSaF approaches using Malt-
parser on test data using automatic shallow parser information.
</figureCaption>
<bodyText confidence="0.999970689655172">
verbs, namely VGF, VGNF, VGINF and VGNN.
They are respectively, finite, non-finite, infinitival
and gerundial chunk tags. The difference in the
verbal chunk tag is a good cue for helping the
parser in identifying different syntactic behavior of
these verbs. Moreover, a finite verb can become
the root of the sentence, whereas a non-finite or
infinitival verb can’t. Thus, providing chunk in-
formation also helped in improving the correct
identification of the root of the sentence.
Similar to Prague Treebank (Hajicova, 1998),
coordinating conjuncts are heads in the treebank
that we use. The relation between a conjunct and
its children is shown using ‘ccof’ label. A coordi-
nating conjuct takes children of similar type only.
For example, a coordinating conjuct can have two
finite verbs or two non-finite verbs as its children,
but not a finite verb and a non-finite verb. Such
instances are also handled more effectively if
chunk information is incorporated. The largest in-
crease in performance, however, was due to the
‘suffix concatenation’ feature. Significant im-
provement in the core inter-chunk dependency la-
bels (such as k1, k2, k4, etc.) due to this feature is
the main reason for the overall improvement in the
parsing accuracy. As mentioned earlier, this is be-
cause this feature captures the correlation between
the TAM markers of the verbs and the case mark-
ers on the nominals.
</bodyText>
<subsectionHeader confidence="0.999544">
5.2 Approach comparison: LMSaF vs. 2stage
</subsectionHeader>
<bodyText confidence="0.999461633333333">
Both LMSaF and 2stage use chunk information. In
LMSaF, chunk information is given as a feature
whereas in 2stage, sentence parsing is divided into
intra-chunk and inter-chunk parsing. Both the ap-
proaches have their pros and cons. In LMSaF as
everything is done in a single stage there is much
richer context to learn from. In 2stage, we can pro-
vide features specific to each stage which can’t be
done in a single stage approach (McDonald et al.,
2006). But in 2stage, as we are dividing the task,
accuracy of the division and the error propagation
might pose a problem. This is reflected in the re-
sults where the 2-stage performs better than the
single stage while using gold standard information,
but lags behind considerably when the features are
automatically computed.
During intra-chunk parsing in the 2stage setup,
we tried out using both a rule-based approach and
a statistical approach (using MaltParser). The rule
based system performed slightly better (0.1%
LAS) than statistical when gold chunks are consi-
dered. But, with automatic chunks, the statistical
approach outperformed rule-based system with a
difference of 7% in LAS. This is not surprising
because, the rules used are very robust and mostly
based on POS and chunk information. Due to er-
rors induced by the automatic POS tagger and
chunker, the rule-based system couldn’t perform
well. Consider a small example chunk given be-
low.
</bodyText>
<equation confidence="0.900593">
(( NP
meraa ‘my’ PRP
bhaaii ‘brother’ NN
</equation>
<bodyText confidence="0.944371428571429">
))
As per the Hindi chunking guidelines (Bharati et
al., 2006), meraa and bhaaii should be in two sepa-
rate chunks. And as per Hindi dependency annota-
tion guidelines (Bharati et al., 2009), meraa is
attached to bhaaii with a dependency label ‘r6’10.
When the chunker wrongly chunks them in a single
</bodyText>
<footnote confidence="0.738011">
10‘r6’ is the dependency label for genitive relation.
</footnote>
<page confidence="0.998045">
28
</page>
<bodyText confidence="0.99980025">
chunk, intra-chunk parser will assign the depen-
dency relation for meraa. Rule based system can
never assign ‘r6’ relation to meraa as it is an inter-
chunk label and the rules used cannot handle such
cases. But in a statistical system, if we train the
parser using automatic chunks instead of gold
chunks, the system can potentially assign ‘r6’ la-
bel.
</bodyText>
<subsectionHeader confidence="0.994479">
5.3 Parser comparison: MST vs. Malt
</subsectionHeader>
<bodyText confidence="0.999886571428571">
In all the experiments, results of MaltParser are
consistently better than MST+MaxEnt. We know
that Maltparser is good at short distance labeling
and MST is good at long distance labeling (McDo-
nald and Nivre, 2007). The root of the sentence is
better identified by MSTParser than MaltParser.
Our results also confirm this. MST+MaxEnt and
Malt could identify the root of the sentence with an
f-measure of 89.7% and 72.3% respectively. Pres-
ence of more short distance labels helped Malt to
outperform MST. Figure 5, shows the f-measure
relative to dependency length for both the parsers
on test data using automatic shallow parser infor-
mation for LMSaF.
</bodyText>
<figure confidence="0.966293">
0 5 10 15+
Dependency Length
</figure>
<figureCaption confidence="0.99384">
Figure 5: Dependency arc f-measure relative to depen-
dency length.
</figureCaption>
<sectionHeader confidence="0.997354" genericHeader="evaluation">
6 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.999978238095238">
We systematically explored the effect of various
linguistic features in Hindi dependency parsing.
Results show that POS, case, suffix, root, along
with local morphosyntactic features help depen-
dency parsing. We then described 2 methods to
incorporate such features during the parsing
process. These methods can be thought as different
paradigms of modularity. For practical reasons (i.e.
given the POS tagger/chunker accuracies), it is
wiser to use this information as features rather than
dividing the task into two stages.
As mentioned earlier, this is the first attempt at
complete sentence level parsing for Hindi. So, we
cannot compare our results with previous attempts
at Hindi dependency parsing, due to, (a) The data
used here is different and (b) we produce complete
sentence parses rather than chunk level parses.
As mentioned in section 5.1, accuracies of intra-
chunk dependencies are very high compared to
inter-chunk dependencies. Inter-chunk dependen-
cies are syntacto-semantic in nature. The parser
depends on surface syntactic cues to identify such
relations. But syntactic information alone is always
not sufficient, either due to unavailability or due to
ambiguity. In such cases, providing some semantic
information can help in improving the inter-chunk
dependency accuracy. There have been attempts at
using minimal semantic information in dependency
parsing for Hindi (Bharati et al., 2008). Recently,
Ambati et al. (2009b) used six semantic features
namely, human, non-human, in-animate, time,
place, and abstract for Hindi dependency parsing.
Using gold-standard semantic features, they
showed considerable improvement in the core in-
ter-chunk dependency accuracy. Some attempts at
using clause information in dependency parsing for
Hindi (Gadde et al., 2010) have also been made.
These attempts were at inter-chunk dependency
parsing using gold-standard POS tags and chunks.
We plan to see their effect in complete sentence
parsing using automatic shallow parser information
also.
</bodyText>
<sectionHeader confidence="0.998524" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99904925">
In this paper we explored two strategies to incorpo-
rate local morphosyntactic features in Hindi de-
pendency parsing. These features were obtained
using a shallow parser. We first explored which
information provided by the shallow parser is use-
ful and showed that local morphosyntactic fea-
tures in the form of chunk type, head/non-head
info, chunk boundary info, distance to the end of
the chunk and suffix concatenation are very crucial
for Hindi dependency parsing. We then investi-
gated the best way to incorporate this information
during dependency parsing. Further, we compared
the results of various experiments based on various
criterions and did some error analysis. This paper
was also the first attempt at complete sentence lev-
el parsing for Hindi.
</bodyText>
<figure confidence="0.986707636363636">
f-measure
100
40
90
80
70
60
50
30
Malt
MST+MaxEnt
</figure>
<page confidence="0.994642">
29
</page>
<sectionHeader confidence="0.989726" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999893201834863">
B. R. Ambati, P. Gadde, and K. Jindal. 2009a. Experi-
ments in Indian Language Dependency Parsing. In
Proc of the ICON09 NLP Tools Contest: Indian Lan-
guage Dependency Parsing, pp 32-37.
B. R. Ambati, P. Gade, C. GSK and S. Husain. 2009b.
Effect of Minimal Semantics on Dependency Pars-
ing. In Proc of RANLP09 student paper workshop.
G. Attardi and F. Dell’Orletta. 2008. Chunking and De-
pendency Parsing. In Proc of LREC Workshop on
Partial Parsing: Between Chunking and Deep Pars-
ing. Marrakech, Morocco.
R. Begum, S. Husain, A. Dhwaj, D. Sharma, L. Bai, and
R. Sangal. 2008. Dependency annotation scheme for
Indian languages. In Proc of IJCNLP-2008.
A. Bharati, V. Chaitanya and R. Sangal. 1995. Natural
Language Processing: A Paninian Perspective, Pren-
tice-Hall of India, New Delhi.
A. Bharati, S. Husain, B. Ambati, S. Jain, D. Sharma,
and R. Sangal. 2008. Two semantic features make all
the difference in parsing accuracy. In Proc of ICON.
A. Bharati, R. Sangal, D. M. Sharma and L. Bai. 2006.
AnnCorra: Annotating Corpora Guidelines for POS
and Chunk Annotation for Indian Languages. Tech-
nical Report (TR-LTRC-31), LTRC, IIIT-Hyderabad.
A. Bharati, D. M. Sharma, S. Husain, L. Bai, R. Begam
and R. Sangal. 2009a. AnnCorra: TreeBanks for In-
dian Languages, Guidelines for Annotating Hindi
TreeBank.
http://ltrc.iiit.ac.in/MachineTrans/research/tb/DS-
guidelines/DS-guidelines-ver2-28-05-09.pdf
A. Bharati, S. Husain, D. M. Sharma and R. Sangal.
2009b. Two stage constraint based hybrid approach
to free word order language dependency parsing. In
Proc. of IWPT.
A. Bharati, S. Husain, M. Vijay, K. Deepak, D. M.
Sharma and R. Sangal. 2009c. Constraint Based Hy-
brid Approach to Parsing Indian Languages. In Proc
of PACLIC 23. Hong Kong. 2009.
R. Bhatt, B. Narasimhan, M. Palmer, O. Rambow, D.
M. Sharma and F. Xia. 2009. Multi-Representational
and Multi-Layered Treebank for Hindi/Urdu. In
Proc. of the Third LAW at 47th ACL and 4th IJCNLP.
Y.J. Chu and T.H. Liu. 1965. On the shortest arbores-
cence of a directed graph. Science Sinica, 14:1396–
1400.
J. Edmonds. 1967. Optimum branchings. Journal of
Research of the National Bureau of Standards,
71B:233–240.
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: An exploration. In Proc of
COLING-96, pp. 340–345.
G. Eryigit, J. Nivre, and K. Oflazer. 2008. Dependency
Parsing of Turkish. Computational Linguistics 34(3),
357-389.
P. Gadde, K. Jindal, S. Husain, D. M. Sharma, and R.
Sangal. 2010. Improving Data Driven Dependency
Parsing using Clausal Information. In Proc of
NAACL-HLT 2010, Los Angeles, CA.
E. Hajicova. 1998. Prague Dependency Treebank: From
Analytic to Tectogrammatical Annotation. In Proc of
TSD’98.
J. Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi, M.
Nilsson and M. Saers. 2007. Single Malt or Blended?
A Study in Multilingual Parser Optimization. In Proc
of the CoNLL Shared Task Session of EMNLP-
CoNLL 2007, 933—939.
S. Husain. 2009. Dependency Parsers for Indian Lan-
guages. In Proc of ICON09 NLP Tools Contest: In-
dian Language Dependency Parsing. Hyderabad,
India.
S. Husain, P. Gadde, B. Ambati, D. M. Sharma and R.
Sangal. 2009. A modular cascaded approach to com-
plete parsing. In Proc. of the COLIPS IALP.
P. Mannem, A. Abhilash and A. Bharati. 2009. LTAG-
spinal Treebank and Parser for Hindi. In Proc of In-
ternational Conference on NLP, Hyderabad. 2009.
R. McDonald, K. Crammer, and F. Pereira. 2005. On-
line large-margin training of dependency parsers. In
Proc of ACL. pp. 91–98.
R. McDonald, K. Lerman, and F. Pereira. 2006. Multi-
lingual dependency analysis with a two-stage discri-
minative parser. In Proc of the Tenth (CoNLL-X), pp.
216–220.
R. McDonald and J. Nivre. 2007. Characterizing the
errors of data-driven dependency parsing models. In
Proc. of EMNLP-CoNLL.
J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson, S.
Riedel and D. Yuret. 2007a. The CoNLL 2007
Shared Task on Dependency Parsing. In Proc of
EMNLP/CoNLL-2007.
J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit, S.
Kübler, S. Marinov and E Marsi. 2007b. MaltParser:
A language-independent system for data-driven de-
pendency parsing. Natural Language Engineering,
13(2), 95-135.
J. Nivre and J. Nilsson. 2005. Pseudo-projective depen-
dency parsing. In Proc. of ACL-2005, pp. 99–106.
Avinesh PVS and K. Gali. 2007. Part-Of-Speech Tag-
ging and Chunking Using Conditional Random
Fields and Transformation Based Learning. In Proc
of the SPSAL workshop during IJCAI &apos;07.
D. Seddah, M. Candito and B. Crabbé. 2009. Cross
parser evaluation: a French Treebanks study. In Proc.
of IWPT, 150-161.
R. Tsarfaty and K. Sima&apos;an. 2008. Relational-
Realizational Parsing. In Proc. of CoLing, 889-896.
A. Vaidya, S. Husain, P. Mannem, and D. M. Sharma.
2009. A karaka-based dependency annotation scheme
for English. In Proc. of CICLing, 41-52.
</reference>
<page confidence="0.998813">
30
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.361255">
<title confidence="0.9597985">Two methods to incorporate local morphosyntactic features in Hindi dependency parsing</title>
<author confidence="0.975534">Bharat Ram Ambati</author>
<author confidence="0.975534">Samar Husain</author>
<author confidence="0.975534">Sambhav Jain</author>
<author confidence="0.975534">Dipti Misra</author>
<affiliation confidence="0.6567275">and Rajeev Language Technologies Research Centre, IIIT-Hyderabad, India -</affiliation>
<email confidence="0.886638">jain@students.iiit.ac.in,{dipti,sangal}@mail.iiit.ac.in</email>
<abstract confidence="0.990447173913044">In this paper we explore two strategies to incorporate local morphosyntactic features in Hindi dependency parsing. These features are obtained using a shallow parser. We first explore which information provided by the shallow parser is most beneficial and show that local morphosyntactic features in the form of chunk type, head/non-head information, chunk boundary information, distance to the end of the chunk and suffix concatenation are very crucial in Hindi dependency parsing. We then investigate the best way to incorporate this information during dependency parsing. Further, we compare the results of various experiments based on various criterions and do some error analysis. All the experiments were done with two data-driven parsers, MaltParser and MSTParser, on a part of multi-layered and multi-representational Hindi Treebank which is under development. This paper is also the first attempt at complete sentence level parsing for Hindi.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B R Ambati</author>
<author>P Gadde</author>
<author>K Jindal</author>
</authors>
<title>Experiments in Indian Language Dependency Parsing.</title>
<date>2009</date>
<booktitle>In Proc of the ICON09 NLP Tools Contest: Indian Language Dependency Parsing,</booktitle>
<pages>32--37</pages>
<contexts>
<context position="17575" citStr="Ambati et al. (2009" startWordPosition="2801" endWordPosition="2804">. Libsvm consistently gave better performance over liblinear in all the experiments. For SVM settings, we tried out different combinations of best SVM settings of the same parser on different languages in CoNLL-2007 shared task (Hall et al., 2007) and applied the best settings. For feature model, apart from trying best feature settings of the same parser on different languages in CoNLL2007 shared task (Hall et al., 2007), we also tried out different combinations of linguistically intuitive features and applied the best feature model. The best feature model is same as the feature model used in Ambati et al. (2009a), which is the best 8 http://maxent.sourceforge.net/ performing system in the ICON-2009 NLP Tools Contest (Husain, 2009). For the MSTParser, non-projective algorithm, order=2 and training-k=5 gave best results in all the approaches. For the MaxEnt, apart from some general useful features, we experimented considering different combinations of features of node, parent, siblings, and children of the node. 5 Results and Analysis All the experiments discussed in section 2 and 3 were performed considering both gold-standard shallow parser information and automatic shallow parser9 information. Auto</context>
<context position="29742" citStr="Ambati et al. (2009" startWordPosition="4759" endWordPosition="4762">s. As mentioned in section 5.1, accuracies of intrachunk dependencies are very high compared to inter-chunk dependencies. Inter-chunk dependencies are syntacto-semantic in nature. The parser depends on surface syntactic cues to identify such relations. But syntactic information alone is always not sufficient, either due to unavailability or due to ambiguity. In such cases, providing some semantic information can help in improving the inter-chunk dependency accuracy. There have been attempts at using minimal semantic information in dependency parsing for Hindi (Bharati et al., 2008). Recently, Ambati et al. (2009b) used six semantic features namely, human, non-human, in-animate, time, place, and abstract for Hindi dependency parsing. Using gold-standard semantic features, they showed considerable improvement in the core inter-chunk dependency accuracy. Some attempts at using clause information in dependency parsing for Hindi (Gadde et al., 2010) have also been made. These attempts were at inter-chunk dependency parsing using gold-standard POS tags and chunks. We plan to see their effect in complete sentence parsing using automatic shallow parser information also. 7 Conclusion In this paper we explored</context>
</contexts>
<marker>Ambati, Gadde, Jindal, 2009</marker>
<rawString>B. R. Ambati, P. Gadde, and K. Jindal. 2009a. Experiments in Indian Language Dependency Parsing. In Proc of the ICON09 NLP Tools Contest: Indian Language Dependency Parsing, pp 32-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B R Ambati</author>
<author>P Gade</author>
<author>C GSK</author>
<author>S Husain</author>
</authors>
<title>Effect of Minimal Semantics on Dependency Parsing.</title>
<date>2009</date>
<booktitle>In Proc of RANLP09</booktitle>
<note>student paper workshop.</note>
<contexts>
<context position="17575" citStr="Ambati et al. (2009" startWordPosition="2801" endWordPosition="2804">. Libsvm consistently gave better performance over liblinear in all the experiments. For SVM settings, we tried out different combinations of best SVM settings of the same parser on different languages in CoNLL-2007 shared task (Hall et al., 2007) and applied the best settings. For feature model, apart from trying best feature settings of the same parser on different languages in CoNLL2007 shared task (Hall et al., 2007), we also tried out different combinations of linguistically intuitive features and applied the best feature model. The best feature model is same as the feature model used in Ambati et al. (2009a), which is the best 8 http://maxent.sourceforge.net/ performing system in the ICON-2009 NLP Tools Contest (Husain, 2009). For the MSTParser, non-projective algorithm, order=2 and training-k=5 gave best results in all the approaches. For the MaxEnt, apart from some general useful features, we experimented considering different combinations of features of node, parent, siblings, and children of the node. 5 Results and Analysis All the experiments discussed in section 2 and 3 were performed considering both gold-standard shallow parser information and automatic shallow parser9 information. Auto</context>
<context position="29742" citStr="Ambati et al. (2009" startWordPosition="4759" endWordPosition="4762">s. As mentioned in section 5.1, accuracies of intrachunk dependencies are very high compared to inter-chunk dependencies. Inter-chunk dependencies are syntacto-semantic in nature. The parser depends on surface syntactic cues to identify such relations. But syntactic information alone is always not sufficient, either due to unavailability or due to ambiguity. In such cases, providing some semantic information can help in improving the inter-chunk dependency accuracy. There have been attempts at using minimal semantic information in dependency parsing for Hindi (Bharati et al., 2008). Recently, Ambati et al. (2009b) used six semantic features namely, human, non-human, in-animate, time, place, and abstract for Hindi dependency parsing. Using gold-standard semantic features, they showed considerable improvement in the core inter-chunk dependency accuracy. Some attempts at using clause information in dependency parsing for Hindi (Gadde et al., 2010) have also been made. These attempts were at inter-chunk dependency parsing using gold-standard POS tags and chunks. We plan to see their effect in complete sentence parsing using automatic shallow parser information also. 7 Conclusion In this paper we explored</context>
</contexts>
<marker>Ambati, Gade, GSK, Husain, 2009</marker>
<rawString>B. R. Ambati, P. Gade, C. GSK and S. Husain. 2009b. Effect of Minimal Semantics on Dependency Parsing. In Proc of RANLP09 student paper workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Attardi</author>
<author>F Dell’Orletta</author>
</authors>
<title>Chunking and Dependency Parsing.</title>
<date>2008</date>
<booktitle>In Proc of LREC Workshop on Partial Parsing: Between Chunking and Deep Parsing.</booktitle>
<location>Marrakech, Morocco.</location>
<marker>Attardi, Dell’Orletta, 2008</marker>
<rawString>G. Attardi and F. Dell’Orletta. 2008. Chunking and Dependency Parsing. In Proc of LREC Workshop on Partial Parsing: Between Chunking and Deep Parsing. Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Begum</author>
<author>S Husain</author>
<author>A Dhwaj</author>
<author>D Sharma</author>
<author>L Bai</author>
<author>R Sangal</author>
</authors>
<title>Dependency annotation scheme for Indian languages. In</title>
<date>2008</date>
<booktitle>Proc of IJCNLP-2008.</booktitle>
<contexts>
<context position="6044" citStr="Begum et al., 2008" startWordPosition="914" endWordPosition="917">e an alternative way to incorporate the best features obtained in section 2. In all the parsing experiments discussed in section 2 and 3, at each step we explore all possible features and extract the best set of features. Best features of one experiment are used when we go to the next set of experiments. For example, when we explore the effect of chunk information, all the relevant morph information from previous set of experiments is taken into account. This paper is also the first attempt at complete sentence level parsing for Hindi. Due to the availability of dependency treebank for Hindi (Begum et al., 2008), there have been some previous attempts at Hindi data-driven dependency parsing (Bharati et al., 2008; Mannem et al., 2009; Husain et al., 2009). Recently in ICON-09 NLP Tools Contest (Husain, 2009; and the references therein), rulebased, constraint based, statistical and hybrid approaches were explored for dependency parsing. Previously, constraint based approaches to Indian language (IL) dependency parsing have also been explored (Bharati et al., 1993, 1995, 2009b, 2009c). All these attempts, however, were finding inter-chunk dependency relations, given goldstandard POS and chunk tags. Unli</context>
</contexts>
<marker>Begum, Husain, Dhwaj, Sharma, Bai, Sangal, 2008</marker>
<rawString>R. Begum, S. Husain, A. Dhwaj, D. Sharma, L. Bai, and R. Sangal. 2008. Dependency annotation scheme for Indian languages. In Proc of IJCNLP-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>V Chaitanya</author>
<author>R Sangal</author>
</authors>
<title>Natural Language Processing: A Paninian Perspective, Prentice-Hall of India,</title>
<date>1995</date>
<location>New Delhi.</location>
<contexts>
<context position="11496" citStr="Bharati et al., 1995" startWordPosition="1825" endWordPosition="1828">(2) [NP raama/NNP ne/PSP] [NP seba/NN] ‘Ram’ ERG ‘apple’ [VGF khaa/VM liyaa/VAUX] ‘eat’ ‘PRFT’ ‘Ram ate an apple’ The suffix concatenation feature for khaa, which is the head of the VGF chunk, will be ‘0+yaa’ and is formed by concatenating the suffix of the main verb with that of its auxiliary. Similarly, the suffix concatenation feature for raama, which is head of the NP chunk, will be ‘0+ne’. This feature turns out to be very important. This is because in Hindi (and many other Indian languages) there is a direct correlation between the TAM markers and the case that appears on some nominals (Bharati et al., 1995). In (2), for example, khaa liyaa together gives the past perfective aspect for the verb khaanaa ‘to eat’. Since, Hindi is split ergative, the subject of the transitive verb takes an ergative case marker when the verb is past perfective. Similar 3 Inside, Outside, Beginning of the chunk. 24 correlation between the case markers and TAM exist in many other cases. 3 An alternative approach to use best features: A 2-stage setup (2stage) So far we have been using various information such as POS, chunk, etc. as features. Rather than using them as features and doing parsing at one go, we can alternat</context>
<context position="15069" citStr="Bharati et al., 1995" startWordPosition="2389" endWordPosition="2392">med using two datadriven parsers, MaltParser6 (Nivre et al., 2007b), and MSTParser7 (McDonald et al., 2006). 4 nmod__adj is an intra-chunk label for quantifier-noun modification. lwg psp is the label for post-position marker. Details of the labels can be seen in the intra-chunk guidelines http://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunkDependency-Annotation-Guidelines.pdf 5 k1 (karta) and k2 (karma) are syntactico-semantic labels which have some properties of both grammatical roles and thematic roles. k1 behaves similar to subject and agent. k2 behaves similar to object and patient (Bharati et al., 1995; Vaidya et al., 2009). For complete tagset, see (Bharati et al., 2009). 6 Malt Version 1.3.1 7 MST Version 0.4b 25 Malt MST+MaxEnt Cross-validation Test-set Cross-validation Test-set UAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LS PaF 89.4 78.2 80.5 90.4 80.1 82.4 86.3 75.1 77.9 87.9 77.0 79.3 MaF 89.6 80.5 83.1 90.4 81.7 84.1 89.1 79.2 82.5 90.0 80.9 83.9 LMSaF 91.5 82.7 84.7 91.8 84.0 86.2 90.8 79.8 82.0 92.0 81.8 83.8 2stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2 Table 1: Results of all the four approaches using gold-standard shallow parser information. Malt is a classifie</context>
</contexts>
<marker>Bharati, Chaitanya, Sangal, 1995</marker>
<rawString>A. Bharati, V. Chaitanya and R. Sangal. 1995. Natural Language Processing: A Paninian Perspective, Prentice-Hall of India, New Delhi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>S Husain</author>
<author>B Ambati</author>
<author>S Jain</author>
<author>D Sharma</author>
<author>R Sangal</author>
</authors>
<title>Two semantic features make all the difference in parsing accuracy.</title>
<date>2008</date>
<booktitle>In Proc of ICON.</booktitle>
<contexts>
<context position="6146" citStr="Bharati et al., 2008" startWordPosition="929" endWordPosition="932">iments discussed in section 2 and 3, at each step we explore all possible features and extract the best set of features. Best features of one experiment are used when we go to the next set of experiments. For example, when we explore the effect of chunk information, all the relevant morph information from previous set of experiments is taken into account. This paper is also the first attempt at complete sentence level parsing for Hindi. Due to the availability of dependency treebank for Hindi (Begum et al., 2008), there have been some previous attempts at Hindi data-driven dependency parsing (Bharati et al., 2008; Mannem et al., 2009; Husain et al., 2009). Recently in ICON-09 NLP Tools Contest (Husain, 2009; and the references therein), rulebased, constraint based, statistical and hybrid approaches were explored for dependency parsing. Previously, constraint based approaches to Indian language (IL) dependency parsing have also been explored (Bharati et al., 1993, 1995, 2009b, 2009c). All these attempts, however, were finding inter-chunk dependency relations, given goldstandard POS and chunk tags. Unlike these previous parsers, the dependencies in this work are between lexical items, i.e. the dependenc</context>
<context position="29711" citStr="Bharati et al., 2008" startWordPosition="4754" endWordPosition="4757">ses rather than chunk level parses. As mentioned in section 5.1, accuracies of intrachunk dependencies are very high compared to inter-chunk dependencies. Inter-chunk dependencies are syntacto-semantic in nature. The parser depends on surface syntactic cues to identify such relations. But syntactic information alone is always not sufficient, either due to unavailability or due to ambiguity. In such cases, providing some semantic information can help in improving the inter-chunk dependency accuracy. There have been attempts at using minimal semantic information in dependency parsing for Hindi (Bharati et al., 2008). Recently, Ambati et al. (2009b) used six semantic features namely, human, non-human, in-animate, time, place, and abstract for Hindi dependency parsing. Using gold-standard semantic features, they showed considerable improvement in the core inter-chunk dependency accuracy. Some attempts at using clause information in dependency parsing for Hindi (Gadde et al., 2010) have also been made. These attempts were at inter-chunk dependency parsing using gold-standard POS tags and chunks. We plan to see their effect in complete sentence parsing using automatic shallow parser information also. 7 Concl</context>
</contexts>
<marker>Bharati, Husain, Ambati, Jain, Sharma, Sangal, 2008</marker>
<rawString>A. Bharati, S. Husain, B. Ambati, S. Jain, D. Sharma, and R. Sangal. 2008. Two semantic features make all the difference in parsing accuracy. In Proc of ICON.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>R Sangal</author>
<author>D M Sharma</author>
<author>L Bai</author>
</authors>
<title>AnnCorra: Annotating Corpora Guidelines for POS and Chunk Annotation for Indian Languages.</title>
<date>2006</date>
<tech>Technical Report (TR-LTRC-31), LTRC, IIIT-Hyderabad.</tech>
<contexts>
<context position="9787" citStr="Bharati et al. (2006)" startWordPosition="1520" endWordPosition="1523">st important features. Results are discussed in section 5. 2.3 Using local morphosyntax as feature (LMSaF) Along with POS and the most useful morph features (root, case and suffix), in this experiment we also use local morphosyntactic features that reflect various chunk level information. These features are: · Type of the chunk · Head/non-head of the chunk 2 NN: Common noun, PSP: Post position, QC: Cardinal, VM: Verb. A list of complete POS tags can be found here: http://ltrc.iiit.ac.in/MachineTrans/research/tb/POS-TagList.pdf. The POS/chunk tag scheme followed in the Treebank is described in Bharati et al. (2006). · Chunk boundary information · Distance to the end of the chunk · Suffix concatenation In example 1 (see section 2.1), there are two noun chunks and one verb chunk. raama and seba are the heads of the noun chunks. khaayaa is the head of the verb chunk. We follow standard IOB3 notation for chunk boundary. raama, eka and khaayaa are at the beginning (B) of their respective chunks. ne and seba are inside (I) their respective chunks. raama is at distance 1 from the end of the chunk and ne is at a distance 0 from the end of the chunk. Once we have a chunk and morph feature like suffix, we can per</context>
<context position="23489" citStr="Bharati et al., 2006" startWordPosition="3743" endWordPosition="3747">r adjective-noun, quantifier-noun modifications. Low accuracy for these labels is mainly due to two reasons. One is POS tag errors. And the other is attachment errors due to genuine ambiguities such as compounding. For inter-chunk labels (first six columns in the figure 3), there is considerable improvement in the f-measure using morph and local morphosytactic features. As mentioned, local morphosyntactic features provide local linguistic information. For example, consider the case of verbs. At POS level, there are only two tags ‘VM’ and ‘VAUX’ for main verbs and auxiliary verbs respectively (Bharati et al., 2006). Information about finite/nonfiniteness is not present in the POS tag. But, at chunk level there are four different chunk tags for 27 100 PaF 90 MaF 80 LMaF 70 60 50 40 30 k1 k2 pof r6 ccof k7p lwg__psp lwg__vaux lwg__cont rsym nmod__adj pof__cn Figure 3: F-measure of top 6, inter-chunk and intra-chunk labels for PaF, MaF and LMSaF approaches using Maltparser on test data using automatic shallow parser information. verbs, namely VGF, VGNF, VGINF and VGNN. They are respectively, finite, non-finite, infinitival and gerundial chunk tags. The difference in the verbal chunk tag is a good cue for h</context>
<context position="26846" citStr="Bharati et al., 2006" startWordPosition="4299" endWordPosition="4302">l approach (using MaltParser). The rule based system performed slightly better (0.1% LAS) than statistical when gold chunks are considered. But, with automatic chunks, the statistical approach outperformed rule-based system with a difference of 7% in LAS. This is not surprising because, the rules used are very robust and mostly based on POS and chunk information. Due to errors induced by the automatic POS tagger and chunker, the rule-based system couldn’t perform well. Consider a small example chunk given below. (( NP meraa ‘my’ PRP bhaaii ‘brother’ NN )) As per the Hindi chunking guidelines (Bharati et al., 2006), meraa and bhaaii should be in two separate chunks. And as per Hindi dependency annotation guidelines (Bharati et al., 2009), meraa is attached to bhaaii with a dependency label ‘r6’10. When the chunker wrongly chunks them in a single 10‘r6’ is the dependency label for genitive relation. 28 chunk, intra-chunk parser will assign the dependency relation for meraa. Rule based system can never assign ‘r6’ relation to meraa as it is an interchunk label and the rules used cannot handle such cases. But in a statistical system, if we train the parser using automatic chunks instead of gold chunks, the</context>
</contexts>
<marker>Bharati, Sangal, Sharma, Bai, 2006</marker>
<rawString>A. Bharati, R. Sangal, D. M. Sharma and L. Bai. 2006. AnnCorra: Annotating Corpora Guidelines for POS and Chunk Annotation for Indian Languages. Technical Report (TR-LTRC-31), LTRC, IIIT-Hyderabad.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>D M Sharma</author>
<author>S Husain</author>
<author>L Bai</author>
<author>R Begam</author>
<author>R Sangal</author>
</authors>
<title>AnnCorra: TreeBanks for Indian Languages, Guidelines for Annotating Hindi TreeBank.</title>
<date>2009</date>
<pages>2--28</pages>
<contexts>
<context position="12570" citStr="Bharati et al. (2009" startWordPosition="2004" endWordPosition="2007">en using various information such as POS, chunk, etc. as features. Rather than using them as features and doing parsing at one go, we can alternatively follow a 2-stage setup. In particular, we divide the task of parsing into: · Intra-chunk dependency parsing · Inter-chunk dependency parsing We still use POS, best morphological features (case, suffix, root) information as regular features during parsing. But unlike LMSaF mentioned in section 2.3, where we gave local morphosyntactic information as a feature, we divided the task of parsing into sub-tasks. A similar approach was also proposed by Bharati et al. (2009c). During intrachunk dependency parsing, we try to find the dependency relations of the words within a chunk. Following which, chunk heads of each chunk within a sentence are extracted. On these chunk heads we run an inter-chunk dependency parser. For each chunk head, in addition to POS tag, useful morphological features, any useful intra-chunk information in the form of lexical item, suffix concatenation, dependency relation are also given as a feature. Figure 2: Dependency parsing using chunk information: 2-stage approach. Figure 2 shows the steps involved in this approach for (1). There ar</context>
<context position="15140" citStr="Bharati et al., 2009" startWordPosition="2401" endWordPosition="2404">nd MSTParser7 (McDonald et al., 2006). 4 nmod__adj is an intra-chunk label for quantifier-noun modification. lwg psp is the label for post-position marker. Details of the labels can be seen in the intra-chunk guidelines http://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunkDependency-Annotation-Guidelines.pdf 5 k1 (karta) and k2 (karma) are syntactico-semantic labels which have some properties of both grammatical roles and thematic roles. k1 behaves similar to subject and agent. k2 behaves similar to object and patient (Bharati et al., 1995; Vaidya et al., 2009). For complete tagset, see (Bharati et al., 2009). 6 Malt Version 1.3.1 7 MST Version 0.4b 25 Malt MST+MaxEnt Cross-validation Test-set Cross-validation Test-set UAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LS PaF 89.4 78.2 80.5 90.4 80.1 82.4 86.3 75.1 77.9 87.9 77.0 79.3 MaF 89.6 80.5 83.1 90.4 81.7 84.1 89.1 79.2 82.5 90.0 80.9 83.9 LMSaF 91.5 82.7 84.7 91.8 84.0 86.2 90.8 79.8 82.0 92.0 81.8 83.8 2stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2 Table 1: Results of all the four approaches using gold-standard shallow parser information. Malt is a classifier based shift/reduce parser. It provides option for six parsing algorit</context>
<context position="26971" citStr="Bharati et al., 2009" startWordPosition="4321" endWordPosition="4324">re considered. But, with automatic chunks, the statistical approach outperformed rule-based system with a difference of 7% in LAS. This is not surprising because, the rules used are very robust and mostly based on POS and chunk information. Due to errors induced by the automatic POS tagger and chunker, the rule-based system couldn’t perform well. Consider a small example chunk given below. (( NP meraa ‘my’ PRP bhaaii ‘brother’ NN )) As per the Hindi chunking guidelines (Bharati et al., 2006), meraa and bhaaii should be in two separate chunks. And as per Hindi dependency annotation guidelines (Bharati et al., 2009), meraa is attached to bhaaii with a dependency label ‘r6’10. When the chunker wrongly chunks them in a single 10‘r6’ is the dependency label for genitive relation. 28 chunk, intra-chunk parser will assign the dependency relation for meraa. Rule based system can never assign ‘r6’ relation to meraa as it is an interchunk label and the rules used cannot handle such cases. But in a statistical system, if we train the parser using automatic chunks instead of gold chunks, the system can potentially assign ‘r6’ label. 5.3 Parser comparison: MST vs. Malt In all the experiments, results of MaltParser </context>
</contexts>
<marker>Bharati, Sharma, Husain, Bai, Begam, Sangal, 2009</marker>
<rawString>A. Bharati, D. M. Sharma, S. Husain, L. Bai, R. Begam and R. Sangal. 2009a. AnnCorra: TreeBanks for Indian Languages, Guidelines for Annotating Hindi TreeBank. http://ltrc.iiit.ac.in/MachineTrans/research/tb/DSguidelines/DS-guidelines-ver2-28-05-09.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>S Husain</author>
<author>D M Sharma</author>
<author>R Sangal</author>
</authors>
<title>Two stage constraint based hybrid approach to free word order language dependency parsing.</title>
<date>2009</date>
<booktitle>In Proc. of IWPT.</booktitle>
<contexts>
<context position="12570" citStr="Bharati et al. (2009" startWordPosition="2004" endWordPosition="2007">en using various information such as POS, chunk, etc. as features. Rather than using them as features and doing parsing at one go, we can alternatively follow a 2-stage setup. In particular, we divide the task of parsing into: · Intra-chunk dependency parsing · Inter-chunk dependency parsing We still use POS, best morphological features (case, suffix, root) information as regular features during parsing. But unlike LMSaF mentioned in section 2.3, where we gave local morphosyntactic information as a feature, we divided the task of parsing into sub-tasks. A similar approach was also proposed by Bharati et al. (2009c). During intrachunk dependency parsing, we try to find the dependency relations of the words within a chunk. Following which, chunk heads of each chunk within a sentence are extracted. On these chunk heads we run an inter-chunk dependency parser. For each chunk head, in addition to POS tag, useful morphological features, any useful intra-chunk information in the form of lexical item, suffix concatenation, dependency relation are also given as a feature. Figure 2: Dependency parsing using chunk information: 2-stage approach. Figure 2 shows the steps involved in this approach for (1). There ar</context>
<context position="15140" citStr="Bharati et al., 2009" startWordPosition="2401" endWordPosition="2404">nd MSTParser7 (McDonald et al., 2006). 4 nmod__adj is an intra-chunk label for quantifier-noun modification. lwg psp is the label for post-position marker. Details of the labels can be seen in the intra-chunk guidelines http://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunkDependency-Annotation-Guidelines.pdf 5 k1 (karta) and k2 (karma) are syntactico-semantic labels which have some properties of both grammatical roles and thematic roles. k1 behaves similar to subject and agent. k2 behaves similar to object and patient (Bharati et al., 1995; Vaidya et al., 2009). For complete tagset, see (Bharati et al., 2009). 6 Malt Version 1.3.1 7 MST Version 0.4b 25 Malt MST+MaxEnt Cross-validation Test-set Cross-validation Test-set UAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LS PaF 89.4 78.2 80.5 90.4 80.1 82.4 86.3 75.1 77.9 87.9 77.0 79.3 MaF 89.6 80.5 83.1 90.4 81.7 84.1 89.1 79.2 82.5 90.0 80.9 83.9 LMSaF 91.5 82.7 84.7 91.8 84.0 86.2 90.8 79.8 82.0 92.0 81.8 83.8 2stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2 Table 1: Results of all the four approaches using gold-standard shallow parser information. Malt is a classifier based shift/reduce parser. It provides option for six parsing algorit</context>
<context position="26971" citStr="Bharati et al., 2009" startWordPosition="4321" endWordPosition="4324">re considered. But, with automatic chunks, the statistical approach outperformed rule-based system with a difference of 7% in LAS. This is not surprising because, the rules used are very robust and mostly based on POS and chunk information. Due to errors induced by the automatic POS tagger and chunker, the rule-based system couldn’t perform well. Consider a small example chunk given below. (( NP meraa ‘my’ PRP bhaaii ‘brother’ NN )) As per the Hindi chunking guidelines (Bharati et al., 2006), meraa and bhaaii should be in two separate chunks. And as per Hindi dependency annotation guidelines (Bharati et al., 2009), meraa is attached to bhaaii with a dependency label ‘r6’10. When the chunker wrongly chunks them in a single 10‘r6’ is the dependency label for genitive relation. 28 chunk, intra-chunk parser will assign the dependency relation for meraa. Rule based system can never assign ‘r6’ relation to meraa as it is an interchunk label and the rules used cannot handle such cases. But in a statistical system, if we train the parser using automatic chunks instead of gold chunks, the system can potentially assign ‘r6’ label. 5.3 Parser comparison: MST vs. Malt In all the experiments, results of MaltParser </context>
</contexts>
<marker>Bharati, Husain, Sharma, Sangal, 2009</marker>
<rawString>A. Bharati, S. Husain, D. M. Sharma and R. Sangal. 2009b. Two stage constraint based hybrid approach to free word order language dependency parsing. In Proc. of IWPT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>S Husain</author>
<author>M Vijay</author>
<author>K Deepak</author>
<author>D M Sharma</author>
<author>R Sangal</author>
</authors>
<title>Constraint Based Hybrid Approach to Parsing Indian Languages.</title>
<date>2009</date>
<booktitle>In Proc of PACLIC 23. Hong Kong.</booktitle>
<contexts>
<context position="12570" citStr="Bharati et al. (2009" startWordPosition="2004" endWordPosition="2007">en using various information such as POS, chunk, etc. as features. Rather than using them as features and doing parsing at one go, we can alternatively follow a 2-stage setup. In particular, we divide the task of parsing into: · Intra-chunk dependency parsing · Inter-chunk dependency parsing We still use POS, best morphological features (case, suffix, root) information as regular features during parsing. But unlike LMSaF mentioned in section 2.3, where we gave local morphosyntactic information as a feature, we divided the task of parsing into sub-tasks. A similar approach was also proposed by Bharati et al. (2009c). During intrachunk dependency parsing, we try to find the dependency relations of the words within a chunk. Following which, chunk heads of each chunk within a sentence are extracted. On these chunk heads we run an inter-chunk dependency parser. For each chunk head, in addition to POS tag, useful morphological features, any useful intra-chunk information in the form of lexical item, suffix concatenation, dependency relation are also given as a feature. Figure 2: Dependency parsing using chunk information: 2-stage approach. Figure 2 shows the steps involved in this approach for (1). There ar</context>
<context position="15140" citStr="Bharati et al., 2009" startWordPosition="2401" endWordPosition="2404">nd MSTParser7 (McDonald et al., 2006). 4 nmod__adj is an intra-chunk label for quantifier-noun modification. lwg psp is the label for post-position marker. Details of the labels can be seen in the intra-chunk guidelines http://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunkDependency-Annotation-Guidelines.pdf 5 k1 (karta) and k2 (karma) are syntactico-semantic labels which have some properties of both grammatical roles and thematic roles. k1 behaves similar to subject and agent. k2 behaves similar to object and patient (Bharati et al., 1995; Vaidya et al., 2009). For complete tagset, see (Bharati et al., 2009). 6 Malt Version 1.3.1 7 MST Version 0.4b 25 Malt MST+MaxEnt Cross-validation Test-set Cross-validation Test-set UAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LS PaF 89.4 78.2 80.5 90.4 80.1 82.4 86.3 75.1 77.9 87.9 77.0 79.3 MaF 89.6 80.5 83.1 90.4 81.7 84.1 89.1 79.2 82.5 90.0 80.9 83.9 LMSaF 91.5 82.7 84.7 91.8 84.0 86.2 90.8 79.8 82.0 92.0 81.8 83.8 2stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2 Table 1: Results of all the four approaches using gold-standard shallow parser information. Malt is a classifier based shift/reduce parser. It provides option for six parsing algorit</context>
<context position="26971" citStr="Bharati et al., 2009" startWordPosition="4321" endWordPosition="4324">re considered. But, with automatic chunks, the statistical approach outperformed rule-based system with a difference of 7% in LAS. This is not surprising because, the rules used are very robust and mostly based on POS and chunk information. Due to errors induced by the automatic POS tagger and chunker, the rule-based system couldn’t perform well. Consider a small example chunk given below. (( NP meraa ‘my’ PRP bhaaii ‘brother’ NN )) As per the Hindi chunking guidelines (Bharati et al., 2006), meraa and bhaaii should be in two separate chunks. And as per Hindi dependency annotation guidelines (Bharati et al., 2009), meraa is attached to bhaaii with a dependency label ‘r6’10. When the chunker wrongly chunks them in a single 10‘r6’ is the dependency label for genitive relation. 28 chunk, intra-chunk parser will assign the dependency relation for meraa. Rule based system can never assign ‘r6’ relation to meraa as it is an interchunk label and the rules used cannot handle such cases. But in a statistical system, if we train the parser using automatic chunks instead of gold chunks, the system can potentially assign ‘r6’ label. 5.3 Parser comparison: MST vs. Malt In all the experiments, results of MaltParser </context>
</contexts>
<marker>Bharati, Husain, Vijay, Deepak, Sharma, Sangal, 2009</marker>
<rawString>A. Bharati, S. Husain, M. Vijay, K. Deepak, D. M. Sharma and R. Sangal. 2009c. Constraint Based Hybrid Approach to Parsing Indian Languages. In Proc of PACLIC 23. Hong Kong. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bhatt</author>
<author>B Narasimhan</author>
<author>M Palmer</author>
<author>O Rambow</author>
<author>D M Sharma</author>
<author>F Xia</author>
</authors>
<title>Multi-Representational and Multi-Layered Treebank for Hindi/Urdu.</title>
<date>2009</date>
<booktitle>In Proc. of the Third LAW at 47th ACL and 4th IJCNLP.</booktitle>
<contexts>
<context position="3354" citStr="Bhatt et al., 2009" startWordPosition="490" endWordPosition="493">data-driven parsers, MaltParser (Nivre et al., 2007b) and MSTParser (McDonald et al., 2006). We first explore which information provided by the shallow parser is most beneficial and show that local morphosyntactic features in the form of chunk type, head/non-head information, chunk boundary information, distance to the end of the chunk and suffix concatenation are very crucial in Hindi dependency parsing. We then investigate the best way to incorporate this information during dependency parsing. All the experiments were done on a part of multi-layered and multirepresentational Hindi Treebank (Bhatt et al., 2009)1. The shallow parser performs three tasks, (a) it gives the POS tags for each lexical item, (b) provides morphological features for each lexical item, and (c) performs chunking. A chunk is a minimal (non-recursive) phrase consisting of correlated, inseparable words/entities, such that the intrachunk dependencies are not distorted (Bharati et 1 This Treebank is still under development. There are currently 27k tokens with complete sentence level annotation. Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 22–30, Los Angeles, Califo</context>
<context position="14179" citStr="Bhatt et al., 2009" startWordPosition="2261" endWordPosition="2264">extracted and given to inter-chunk parser. Using this information the interchunk dependency parser marks the dependency relations between chunk heads. khaaya becomes the root of the dependency tree. raama and seba are attached to khaaya with dependency labels ‘k1’ and ‘k2’5 respectively. 4 Experimental Setup In this section we describe the data and the parser settings used for our experiments. 4.1 Data For our experiments we took 1228 dependency annotated sentences (27k tokens), which have complete sentence level annotation from the new multi-layered and multi-representational Hindi Treebank (Bhatt et al., 2009). This treebank is still under development. Average length of these sentences is 22 tokens/sentence and 10 chunks/sentence. We divided the data into two sets, 1000 sentences for training and 228 sentences for testing. 4.2 Parsers and settings All experiments were performed using two datadriven parsers, MaltParser6 (Nivre et al., 2007b), and MSTParser7 (McDonald et al., 2006). 4 nmod__adj is an intra-chunk label for quantifier-noun modification. lwg psp is the label for post-position marker. Details of the labels can be seen in the intra-chunk guidelines http://ltrc.iiit.ac.in/MachineTrans/rese</context>
</contexts>
<marker>Bhatt, Narasimhan, Palmer, Rambow, Sharma, Xia, 2009</marker>
<rawString>R. Bhatt, B. Narasimhan, M. Palmer, O. Rambow, D. M. Sharma and F. Xia. 2009. Multi-Representational and Multi-Layered Treebank for Hindi/Urdu. In Proc. of the Third LAW at 47th ACL and 4th IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y J Chu</author>
<author>T H Liu</author>
</authors>
<title>On the shortest arborescence of a directed graph.</title>
<date>1965</date>
<journal>Science Sinica,</journal>
<volume>14</volume>
<pages>1400</pages>
<contexts>
<context position="16075" citStr="Chu and Liu, 1965" startWordPosition="2554" endWordPosition="2557">.2 90.8 79.8 82.0 92.0 81.8 83.8 2stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2 Table 1: Results of all the four approaches using gold-standard shallow parser information. Malt is a classifier based shift/reduce parser. It provides option for six parsing algorithms, namely, arc-eager, arc-standard, convington projective, covington non-projective, stack projective, stack eager and stack lazy. The parser also provides option for libsvm and liblinear learning model. It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005). MST uses Chu-LiuEdmonds (Chu and Liu, 1965; Edmonds, 1967) Maximum Spanning Tree algorithm for nonprojective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005). In this paper, we use MST only for unlabeled dependency tree and use a separate maximum entropy model8 (MaxEnt) for labeling. Various combination of features such as node, its parent, siblings and children were tried out before arriving at the best results. As the training data size is small we did 5-fold cross validation on the training data for tuning the parameters of t</context>
</contexts>
<marker>Chu, Liu, 1965</marker>
<rawString>Y.J. Chu and T.H. Liu. 1965. On the shortest arborescence of a directed graph. Science Sinica, 14:1396– 1400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Edmonds</author>
</authors>
<title>Optimum branchings.</title>
<date>1967</date>
<journal>Journal of Research of the National Bureau of Standards,</journal>
<pages>71--233</pages>
<contexts>
<context position="16091" citStr="Edmonds, 1967" startWordPosition="2558" endWordPosition="2559">2.0 81.8 83.8 2stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2 Table 1: Results of all the four approaches using gold-standard shallow parser information. Malt is a classifier based shift/reduce parser. It provides option for six parsing algorithms, namely, arc-eager, arc-standard, convington projective, covington non-projective, stack projective, stack eager and stack lazy. The parser also provides option for libsvm and liblinear learning model. It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005). MST uses Chu-LiuEdmonds (Chu and Liu, 1965; Edmonds, 1967) Maximum Spanning Tree algorithm for nonprojective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005). In this paper, we use MST only for unlabeled dependency tree and use a separate maximum entropy model8 (MaxEnt) for labeling. Various combination of features such as node, its parent, siblings and children were tried out before arriving at the best results. As the training data size is small we did 5-fold cross validation on the training data for tuning the parameters of the parsers and f</context>
</contexts>
<marker>Edmonds, 1967</marker>
<rawString>J. Edmonds. 1967. Optimum branchings. Journal of Research of the National Bureau of Standards, 71B:233–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proc of COLING-96,</booktitle>
<pages>340--345</pages>
<contexts>
<context position="16210" citStr="Eisner, 1996" startWordPosition="2575" endWordPosition="2576">ches using gold-standard shallow parser information. Malt is a classifier based shift/reduce parser. It provides option for six parsing algorithms, namely, arc-eager, arc-standard, convington projective, covington non-projective, stack projective, stack eager and stack lazy. The parser also provides option for libsvm and liblinear learning model. It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005). MST uses Chu-LiuEdmonds (Chu and Liu, 1965; Edmonds, 1967) Maximum Spanning Tree algorithm for nonprojective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005). In this paper, we use MST only for unlabeled dependency tree and use a separate maximum entropy model8 (MaxEnt) for labeling. Various combination of features such as node, its parent, siblings and children were tried out before arriving at the best results. As the training data size is small we did 5-fold cross validation on the training data for tuning the parameters of the parsers and for feature selection. Best settings obtained using cross-validated data are applied on test set. We present the results</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>J. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proc of COLING-96, pp. 340–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Eryigit</author>
<author>J Nivre</author>
<author>K Oflazer</author>
</authors>
<title>Dependency Parsing of Turkish.</title>
<date>2008</date>
<journal>Computational Linguistics</journal>
<volume>34</volume>
<issue>3</issue>
<pages>357--389</pages>
<contexts>
<context position="1898" citStr="Eryigit et al., 2008" startWordPosition="266" endWordPosition="269">vel parsing for Hindi. 1 Introduction The dependency parsing community has since a few years shown considerable interest in parsing morphologically rich languages with flexible word order. This is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages have not been very high (Nivre et al., 2007a). Attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (Tsarfaty and Sima&apos;an, 2008; Eryigit et al., 2008; Seddah et al., 2009; Husain et al., 2009; Gadde et al., 2010). 22 Among other things, it has been pointed out that the use of language specific features may play a crucial role in improving the overall parsing performance. Different languages tend to encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic information could be a key to better accuracy. However, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many intuitive features do no</context>
</contexts>
<marker>Eryigit, Nivre, Oflazer, 2008</marker>
<rawString>G. Eryigit, J. Nivre, and K. Oflazer. 2008. Dependency Parsing of Turkish. Computational Linguistics 34(3), 357-389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Gadde</author>
<author>K Jindal</author>
<author>S Husain</author>
<author>D M Sharma</author>
<author>R Sangal</author>
</authors>
<title>Improving Data Driven Dependency Parsing using Clausal Information.</title>
<date>2010</date>
<booktitle>In Proc of NAACL-HLT 2010,</booktitle>
<location>Los Angeles, CA.</location>
<contexts>
<context position="1961" citStr="Gadde et al., 2010" startWordPosition="278" endWordPosition="281">munity has since a few years shown considerable interest in parsing morphologically rich languages with flexible word order. This is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages have not been very high (Nivre et al., 2007a). Attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (Tsarfaty and Sima&apos;an, 2008; Eryigit et al., 2008; Seddah et al., 2009; Husain et al., 2009; Gadde et al., 2010). 22 Among other things, it has been pointed out that the use of language specific features may play a crucial role in improving the overall parsing performance. Different languages tend to encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic information could be a key to better accuracy. However, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many intuitive features do not always work in expected ways. In this paper we explore variou</context>
<context position="30081" citStr="Gadde et al., 2010" startWordPosition="4805" endWordPosition="4808"> or due to ambiguity. In such cases, providing some semantic information can help in improving the inter-chunk dependency accuracy. There have been attempts at using minimal semantic information in dependency parsing for Hindi (Bharati et al., 2008). Recently, Ambati et al. (2009b) used six semantic features namely, human, non-human, in-animate, time, place, and abstract for Hindi dependency parsing. Using gold-standard semantic features, they showed considerable improvement in the core inter-chunk dependency accuracy. Some attempts at using clause information in dependency parsing for Hindi (Gadde et al., 2010) have also been made. These attempts were at inter-chunk dependency parsing using gold-standard POS tags and chunks. We plan to see their effect in complete sentence parsing using automatic shallow parser information also. 7 Conclusion In this paper we explored two strategies to incorporate local morphosyntactic features in Hindi dependency parsing. These features were obtained using a shallow parser. We first explored which information provided by the shallow parser is useful and showed that local morphosyntactic features in the form of chunk type, head/non-head info, chunk boundary info, dis</context>
</contexts>
<marker>Gadde, Jindal, Husain, Sharma, Sangal, 2010</marker>
<rawString>P. Gadde, K. Jindal, S. Husain, D. M. Sharma, and R. Sangal. 2010. Improving Data Driven Dependency Parsing using Clausal Information. In Proc of NAACL-HLT 2010, Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hajicova</author>
</authors>
<title>Prague Dependency Treebank: From Analytic to Tectogrammatical Annotation.</title>
<date>1998</date>
<booktitle>In Proc of TSD’98.</booktitle>
<contexts>
<context position="24434" citStr="Hajicova, 1998" startWordPosition="3901" endWordPosition="3902">MSaF approaches using Maltparser on test data using automatic shallow parser information. verbs, namely VGF, VGNF, VGINF and VGNN. They are respectively, finite, non-finite, infinitival and gerundial chunk tags. The difference in the verbal chunk tag is a good cue for helping the parser in identifying different syntactic behavior of these verbs. Moreover, a finite verb can become the root of the sentence, whereas a non-finite or infinitival verb can’t. Thus, providing chunk information also helped in improving the correct identification of the root of the sentence. Similar to Prague Treebank (Hajicova, 1998), coordinating conjuncts are heads in the treebank that we use. The relation between a conjunct and its children is shown using ‘ccof’ label. A coordinating conjuct takes children of similar type only. For example, a coordinating conjuct can have two finite verbs or two non-finite verbs as its children, but not a finite verb and a non-finite verb. Such instances are also handled more effectively if chunk information is incorporated. The largest increase in performance, however, was due to the ‘suffix concatenation’ feature. Significant improvement in the core inter-chunk dependency labels (suc</context>
</contexts>
<marker>Hajicova, 1998</marker>
<rawString>E. Hajicova. 1998. Prague Dependency Treebank: From Analytic to Tectogrammatical Annotation. In Proc of TSD’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hall</author>
<author>J Nilsson</author>
<author>J Nivre</author>
<author>G Eryigit</author>
<author>B Megyesi</author>
<author>M Nilsson</author>
<author>M Saers</author>
</authors>
<title>Single Malt or Blended? A Study in Multilingual Parser Optimization.</title>
<date>2007</date>
<booktitle>In Proc of the CoNLL Shared Task Session of EMNLPCoNLL 2007,</booktitle>
<pages>933--939</pages>
<contexts>
<context position="17203" citStr="Hall et al., 2007" startWordPosition="2737" endWordPosition="2740">s small we did 5-fold cross validation on the training data for tuning the parameters of the parsers and for feature selection. Best settings obtained using cross-validated data are applied on test set. We present the results both on cross validated data and on test data. For the Malt Parser, arc-eager algorithm gave better performance over others in all the approaches. Libsvm consistently gave better performance over liblinear in all the experiments. For SVM settings, we tried out different combinations of best SVM settings of the same parser on different languages in CoNLL-2007 shared task (Hall et al., 2007) and applied the best settings. For feature model, apart from trying best feature settings of the same parser on different languages in CoNLL2007 shared task (Hall et al., 2007), we also tried out different combinations of linguistically intuitive features and applied the best feature model. The best feature model is same as the feature model used in Ambati et al. (2009a), which is the best 8 http://maxent.sourceforge.net/ performing system in the ICON-2009 NLP Tools Contest (Husain, 2009). For the MSTParser, non-projective algorithm, order=2 and training-k=5 gave best results in all the appro</context>
</contexts>
<marker>Hall, Nilsson, Nivre, Eryigit, Megyesi, Nilsson, Saers, 2007</marker>
<rawString>J. Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi, M. Nilsson and M. Saers. 2007. Single Malt or Blended? A Study in Multilingual Parser Optimization. In Proc of the CoNLL Shared Task Session of EMNLPCoNLL 2007, 933—939.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Husain</author>
</authors>
<title>Dependency Parsers for Indian Languages. In</title>
<date>2009</date>
<booktitle>Proc of ICON09 NLP Tools Contest: Indian Language Dependency Parsing.</booktitle>
<location>Hyderabad, India.</location>
<contexts>
<context position="6242" citStr="Husain, 2009" startWordPosition="947" endWordPosition="948">set of features. Best features of one experiment are used when we go to the next set of experiments. For example, when we explore the effect of chunk information, all the relevant morph information from previous set of experiments is taken into account. This paper is also the first attempt at complete sentence level parsing for Hindi. Due to the availability of dependency treebank for Hindi (Begum et al., 2008), there have been some previous attempts at Hindi data-driven dependency parsing (Bharati et al., 2008; Mannem et al., 2009; Husain et al., 2009). Recently in ICON-09 NLP Tools Contest (Husain, 2009; and the references therein), rulebased, constraint based, statistical and hybrid approaches were explored for dependency parsing. Previously, constraint based approaches to Indian language (IL) dependency parsing have also been explored (Bharati et al., 1993, 1995, 2009b, 2009c). All these attempts, however, were finding inter-chunk dependency relations, given goldstandard POS and chunk tags. Unlike these previous parsers, the dependencies in this work are between lexical items, i.e. the dependency tree is complete. The paper is arranged as follows, in section 2 and 3, we discuss the parsing</context>
<context position="17697" citStr="Husain, 2009" startWordPosition="2819" endWordPosition="2820">mbinations of best SVM settings of the same parser on different languages in CoNLL-2007 shared task (Hall et al., 2007) and applied the best settings. For feature model, apart from trying best feature settings of the same parser on different languages in CoNLL2007 shared task (Hall et al., 2007), we also tried out different combinations of linguistically intuitive features and applied the best feature model. The best feature model is same as the feature model used in Ambati et al. (2009a), which is the best 8 http://maxent.sourceforge.net/ performing system in the ICON-2009 NLP Tools Contest (Husain, 2009). For the MSTParser, non-projective algorithm, order=2 and training-k=5 gave best results in all the approaches. For the MaxEnt, apart from some general useful features, we experimented considering different combinations of features of node, parent, siblings, and children of the node. 5 Results and Analysis All the experiments discussed in section 2 and 3 were performed considering both gold-standard shallow parser information and automatic shallow parser9 information. Automatic shallow parser uses a rule based system for morph analysis, a CRF+TBL based POS-tagger and chunker. The tagger and c</context>
</contexts>
<marker>Husain, 2009</marker>
<rawString>S. Husain. 2009. Dependency Parsers for Indian Languages. In Proc of ICON09 NLP Tools Contest: Indian Language Dependency Parsing. Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Husain</author>
<author>P Gadde</author>
<author>B Ambati</author>
<author>D M Sharma</author>
<author>R Sangal</author>
</authors>
<title>A modular cascaded approach to complete parsing.</title>
<date>2009</date>
<booktitle>In Proc. of the COLIPS IALP.</booktitle>
<contexts>
<context position="1940" citStr="Husain et al., 2009" startWordPosition="274" endWordPosition="277">ependency parsing community has since a few years shown considerable interest in parsing morphologically rich languages with flexible word order. This is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages have not been very high (Nivre et al., 2007a). Attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (Tsarfaty and Sima&apos;an, 2008; Eryigit et al., 2008; Seddah et al., 2009; Husain et al., 2009; Gadde et al., 2010). 22 Among other things, it has been pointed out that the use of language specific features may play a crucial role in improving the overall parsing performance. Different languages tend to encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic information could be a key to better accuracy. However, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many intuitive features do not always work in expected ways. In this pa</context>
<context position="6189" citStr="Husain et al., 2009" startWordPosition="937" endWordPosition="940">h step we explore all possible features and extract the best set of features. Best features of one experiment are used when we go to the next set of experiments. For example, when we explore the effect of chunk information, all the relevant morph information from previous set of experiments is taken into account. This paper is also the first attempt at complete sentence level parsing for Hindi. Due to the availability of dependency treebank for Hindi (Begum et al., 2008), there have been some previous attempts at Hindi data-driven dependency parsing (Bharati et al., 2008; Mannem et al., 2009; Husain et al., 2009). Recently in ICON-09 NLP Tools Contest (Husain, 2009; and the references therein), rulebased, constraint based, statistical and hybrid approaches were explored for dependency parsing. Previously, constraint based approaches to Indian language (IL) dependency parsing have also been explored (Bharati et al., 1993, 1995, 2009b, 2009c). All these attempts, however, were finding inter-chunk dependency relations, given goldstandard POS and chunk tags. Unlike these previous parsers, the dependencies in this work are between lexical items, i.e. the dependency tree is complete. The paper is arranged a</context>
</contexts>
<marker>Husain, Gadde, Ambati, Sharma, Sangal, 2009</marker>
<rawString>S. Husain, P. Gadde, B. Ambati, D. M. Sharma and R. Sangal. 2009. A modular cascaded approach to complete parsing. In Proc. of the COLIPS IALP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Mannem</author>
<author>A Abhilash</author>
<author>A Bharati</author>
</authors>
<title>LTAGspinal Treebank and Parser for Hindi. In</title>
<date>2009</date>
<booktitle>Proc of International Conference on NLP,</booktitle>
<location>Hyderabad.</location>
<contexts>
<context position="6167" citStr="Mannem et al., 2009" startWordPosition="933" endWordPosition="936">ction 2 and 3, at each step we explore all possible features and extract the best set of features. Best features of one experiment are used when we go to the next set of experiments. For example, when we explore the effect of chunk information, all the relevant morph information from previous set of experiments is taken into account. This paper is also the first attempt at complete sentence level parsing for Hindi. Due to the availability of dependency treebank for Hindi (Begum et al., 2008), there have been some previous attempts at Hindi data-driven dependency parsing (Bharati et al., 2008; Mannem et al., 2009; Husain et al., 2009). Recently in ICON-09 NLP Tools Contest (Husain, 2009; and the references therein), rulebased, constraint based, statistical and hybrid approaches were explored for dependency parsing. Previously, constraint based approaches to Indian language (IL) dependency parsing have also been explored (Bharati et al., 1993, 1995, 2009b, 2009c). All these attempts, however, were finding inter-chunk dependency relations, given goldstandard POS and chunk tags. Unlike these previous parsers, the dependencies in this work are between lexical items, i.e. the dependency tree is complete. T</context>
</contexts>
<marker>Mannem, Abhilash, Bharati, 2009</marker>
<rawString>P. Mannem, A. Abhilash and A. Bharati. 2009. LTAGspinal Treebank and Parser for Hindi. In Proc of International Conference on NLP, Hyderabad. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proc of ACL.</booktitle>
<pages>91--98</pages>
<contexts>
<context position="16298" citStr="McDonald et al., 2005" startWordPosition="2587" endWordPosition="2591"> shift/reduce parser. It provides option for six parsing algorithms, namely, arc-eager, arc-standard, convington projective, covington non-projective, stack projective, stack eager and stack lazy. The parser also provides option for libsvm and liblinear learning model. It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005). MST uses Chu-LiuEdmonds (Chu and Liu, 1965; Edmonds, 1967) Maximum Spanning Tree algorithm for nonprojective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005). In this paper, we use MST only for unlabeled dependency tree and use a separate maximum entropy model8 (MaxEnt) for labeling. Various combination of features such as node, its parent, siblings and children were tried out before arriving at the best results. As the training data size is small we did 5-fold cross validation on the training data for tuning the parameters of the parsers and for feature selection. Best settings obtained using cross-validated data are applied on test set. We present the results both on cross validated data and on test data. For the Malt Parser, arc-eager algorithm</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005. Online large-margin training of dependency parsers. In Proc of ACL. pp. 91–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Lerman</author>
<author>F Pereira</author>
</authors>
<title>Multilingual dependency analysis with a two-stage discriminative parser.</title>
<date>2006</date>
<booktitle>In Proc of the Tenth (CoNLL-X),</booktitle>
<pages>216--220</pages>
<contexts>
<context position="2826" citStr="McDonald et al., 2006" startWordPosition="410" endWordPosition="413">t ways, and it has been hypothesized that the integration of morphological and syntactic information could be a key to better accuracy. However, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many intuitive features do not always work in expected ways. In this paper we explore various strategies to incorporate local morphosyntactic features in Hindi dependency parsing. These features are obtained using a shallow parser. We conducted experiments with two data-driven parsers, MaltParser (Nivre et al., 2007b) and MSTParser (McDonald et al., 2006). We first explore which information provided by the shallow parser is most beneficial and show that local morphosyntactic features in the form of chunk type, head/non-head information, chunk boundary information, distance to the end of the chunk and suffix concatenation are very crucial in Hindi dependency parsing. We then investigate the best way to incorporate this information during dependency parsing. All the experiments were done on a part of multi-layered and multirepresentational Hindi Treebank (Bhatt et al., 2009)1. The shallow parser performs three tasks, (a) it gives the POS tags fo</context>
<context position="14556" citStr="McDonald et al., 2006" startWordPosition="2319" endWordPosition="2322">d for our experiments. 4.1 Data For our experiments we took 1228 dependency annotated sentences (27k tokens), which have complete sentence level annotation from the new multi-layered and multi-representational Hindi Treebank (Bhatt et al., 2009). This treebank is still under development. Average length of these sentences is 22 tokens/sentence and 10 chunks/sentence. We divided the data into two sets, 1000 sentences for training and 228 sentences for testing. 4.2 Parsers and settings All experiments were performed using two datadriven parsers, MaltParser6 (Nivre et al., 2007b), and MSTParser7 (McDonald et al., 2006). 4 nmod__adj is an intra-chunk label for quantifier-noun modification. lwg psp is the label for post-position marker. Details of the labels can be seen in the intra-chunk guidelines http://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunkDependency-Annotation-Guidelines.pdf 5 k1 (karta) and k2 (karma) are syntactico-semantic labels which have some properties of both grammatical roles and thematic roles. k1 behaves similar to subject and agent. k2 behaves similar to object and patient (Bharati et al., 1995; Vaidya et al., 2009). For complete tagset, see (Bharati et al., 2009). 6 Malt Version</context>
<context position="25793" citStr="McDonald et al., 2006" startWordPosition="4128" endWordPosition="4131">this is because this feature captures the correlation between the TAM markers of the verbs and the case markers on the nominals. 5.2 Approach comparison: LMSaF vs. 2stage Both LMSaF and 2stage use chunk information. In LMSaF, chunk information is given as a feature whereas in 2stage, sentence parsing is divided into intra-chunk and inter-chunk parsing. Both the approaches have their pros and cons. In LMSaF as everything is done in a single stage there is much richer context to learn from. In 2stage, we can provide features specific to each stage which can’t be done in a single stage approach (McDonald et al., 2006). But in 2stage, as we are dividing the task, accuracy of the division and the error propagation might pose a problem. This is reflected in the results where the 2-stage performs better than the single stage while using gold standard information, but lags behind considerably when the features are automatically computed. During intra-chunk parsing in the 2stage setup, we tried out using both a rule-based approach and a statistical approach (using MaltParser). The rule based system performed slightly better (0.1% LAS) than statistical when gold chunks are considered. But, with automatic chunks, </context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>R. McDonald, K. Lerman, and F. Pereira. 2006. Multilingual dependency analysis with a two-stage discriminative parser. In Proc of the Tenth (CoNLL-X), pp. 216–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>J Nivre</author>
</authors>
<title>Characterizing the errors of data-driven dependency parsing models.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="27739" citStr="McDonald and Nivre, 2007" startWordPosition="4450" endWordPosition="4454">or genitive relation. 28 chunk, intra-chunk parser will assign the dependency relation for meraa. Rule based system can never assign ‘r6’ relation to meraa as it is an interchunk label and the rules used cannot handle such cases. But in a statistical system, if we train the parser using automatic chunks instead of gold chunks, the system can potentially assign ‘r6’ label. 5.3 Parser comparison: MST vs. Malt In all the experiments, results of MaltParser are consistently better than MST+MaxEnt. We know that Maltparser is good at short distance labeling and MST is good at long distance labeling (McDonald and Nivre, 2007). The root of the sentence is better identified by MSTParser than MaltParser. Our results also confirm this. MST+MaxEnt and Malt could identify the root of the sentence with an f-measure of 89.7% and 72.3% respectively. Presence of more short distance labels helped Malt to outperform MST. Figure 5, shows the f-measure relative to dependency length for both the parsers on test data using automatic shallow parser information for LMSaF. 0 5 10 15+ Dependency Length Figure 5: Dependency arc f-measure relative to dependency length. 6 Discussion and Future Work We systematically explored the effect </context>
</contexts>
<marker>McDonald, Nivre, 2007</marker>
<rawString>R. McDonald and J. Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proc. of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S Kubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>Shared Task on Dependency Parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proc of EMNLP/CoNLL-2007.</booktitle>
<contexts>
<context position="1698" citStr="Nivre et al., 2007" startWordPosition="240" endWordPosition="243">riven parsers, MaltParser and MSTParser, on a part of multi-layered and multi-representational Hindi Treebank which is under development. This paper is also the first attempt at complete sentence level parsing for Hindi. 1 Introduction The dependency parsing community has since a few years shown considerable interest in parsing morphologically rich languages with flexible word order. This is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages have not been very high (Nivre et al., 2007a). Attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (Tsarfaty and Sima&apos;an, 2008; Eryigit et al., 2008; Seddah et al., 2009; Husain et al., 2009; Gadde et al., 2010). 22 Among other things, it has been pointed out that the use of language specific features may play a crucial role in improving the overall parsing performance. Different languages tend to encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic infor</context>
<context position="14514" citStr="Nivre et al., 2007" startWordPosition="2313" endWordPosition="2316">e the data and the parser settings used for our experiments. 4.1 Data For our experiments we took 1228 dependency annotated sentences (27k tokens), which have complete sentence level annotation from the new multi-layered and multi-representational Hindi Treebank (Bhatt et al., 2009). This treebank is still under development. Average length of these sentences is 22 tokens/sentence and 10 chunks/sentence. We divided the data into two sets, 1000 sentences for training and 228 sentences for testing. 4.2 Parsers and settings All experiments were performed using two datadriven parsers, MaltParser6 (Nivre et al., 2007b), and MSTParser7 (McDonald et al., 2006). 4 nmod__adj is an intra-chunk label for quantifier-noun modification. lwg psp is the label for post-position marker. Details of the labels can be seen in the intra-chunk guidelines http://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunkDependency-Annotation-Guidelines.pdf 5 k1 (karta) and k2 (karma) are syntactico-semantic labels which have some properties of both grammatical roles and thematic roles. k1 behaves similar to subject and agent. k2 behaves similar to object and patient (Bharati et al., 1995; Vaidya et al., 2009). For complete tagset, </context>
<context position="19021" citStr="Nivre et al., 2007" startWordPosition="3016" endWordPosition="3019">S and Gali, (2007) on larger training data. In addition, while using automatic shallow parser information to get the results, we also explored using both gold-standard and automatic information during training. As expected, using automatic shallow parser information for training gave better performance than using gold while training. Table 1 and Table 2 shows the results of the four experiments using gold-standard and automatic shallow parser information respectively. We evaluated our experiments based on unlabeled attachment score (UAS), labeled attachment score (LAS) and labeled score (LS) (Nivre et al., 2007a). Best LAS on test data is 84.4% (with 2stage) and 75.4% (with LMSaF) using gold and automatic shallow parser information respectively. These results are obtained using MaltParser. In the following subsection we discuss the results based on different criterion. 9 http://ltrc.iiit.ac.in/analyzer/hindi/ 26 Malt MST+MaxEnt Cross-validation Test-set Cross-validation Test-set UAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LS PaF 82.2 69.3 73.4 84.6 72.9 76.5 79.4 66.5 70.7 81.6 69.4 73.1 MaF 82.5 71.6 76.1 84.0 73.6 77.6 82.3 70.4 75.4 83.4 72.7 77.3 LMSaF 83.2 73.0 77.0 85.5 75.4 78.9 82.6 71.3 76.1 8</context>
</contexts>
<marker>Nivre, Hall, Kubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson, S. Riedel and D. Yuret. 2007a. The CoNLL 2007 Shared Task on Dependency Parsing. In Proc of EMNLP/CoNLL-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>J Nilsson</author>
<author>A Chanev</author>
<author>G Eryigit</author>
<author>S Kübler</author>
<author>S Marinov</author>
<author>E Marsi</author>
</authors>
<title>MaltParser: A language-independent system for data-driven dependency parsing.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>2</issue>
<pages>95--135</pages>
<contexts>
<context position="1698" citStr="Nivre et al., 2007" startWordPosition="240" endWordPosition="243">riven parsers, MaltParser and MSTParser, on a part of multi-layered and multi-representational Hindi Treebank which is under development. This paper is also the first attempt at complete sentence level parsing for Hindi. 1 Introduction The dependency parsing community has since a few years shown considerable interest in parsing morphologically rich languages with flexible word order. This is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages have not been very high (Nivre et al., 2007a). Attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (Tsarfaty and Sima&apos;an, 2008; Eryigit et al., 2008; Seddah et al., 2009; Husain et al., 2009; Gadde et al., 2010). 22 Among other things, it has been pointed out that the use of language specific features may play a crucial role in improving the overall parsing performance. Different languages tend to encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic infor</context>
<context position="14514" citStr="Nivre et al., 2007" startWordPosition="2313" endWordPosition="2316">e the data and the parser settings used for our experiments. 4.1 Data For our experiments we took 1228 dependency annotated sentences (27k tokens), which have complete sentence level annotation from the new multi-layered and multi-representational Hindi Treebank (Bhatt et al., 2009). This treebank is still under development. Average length of these sentences is 22 tokens/sentence and 10 chunks/sentence. We divided the data into two sets, 1000 sentences for training and 228 sentences for testing. 4.2 Parsers and settings All experiments were performed using two datadriven parsers, MaltParser6 (Nivre et al., 2007b), and MSTParser7 (McDonald et al., 2006). 4 nmod__adj is an intra-chunk label for quantifier-noun modification. lwg psp is the label for post-position marker. Details of the labels can be seen in the intra-chunk guidelines http://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunkDependency-Annotation-Guidelines.pdf 5 k1 (karta) and k2 (karma) are syntactico-semantic labels which have some properties of both grammatical roles and thematic roles. k1 behaves similar to subject and agent. k2 behaves similar to object and patient (Bharati et al., 1995; Vaidya et al., 2009). For complete tagset, </context>
<context position="19021" citStr="Nivre et al., 2007" startWordPosition="3016" endWordPosition="3019">S and Gali, (2007) on larger training data. In addition, while using automatic shallow parser information to get the results, we also explored using both gold-standard and automatic information during training. As expected, using automatic shallow parser information for training gave better performance than using gold while training. Table 1 and Table 2 shows the results of the four experiments using gold-standard and automatic shallow parser information respectively. We evaluated our experiments based on unlabeled attachment score (UAS), labeled attachment score (LAS) and labeled score (LS) (Nivre et al., 2007a). Best LAS on test data is 84.4% (with 2stage) and 75.4% (with LMSaF) using gold and automatic shallow parser information respectively. These results are obtained using MaltParser. In the following subsection we discuss the results based on different criterion. 9 http://ltrc.iiit.ac.in/analyzer/hindi/ 26 Malt MST+MaxEnt Cross-validation Test-set Cross-validation Test-set UAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LS PaF 82.2 69.3 73.4 84.6 72.9 76.5 79.4 66.5 70.7 81.6 69.4 73.1 MaF 82.5 71.6 76.1 84.0 73.6 77.6 82.3 70.4 75.4 83.4 72.7 77.3 LMSaF 83.2 73.0 77.0 85.5 75.4 78.9 82.6 71.3 76.1 8</context>
</contexts>
<marker>Nivre, Hall, Nilsson, Chanev, Eryigit, Kübler, Marinov, Marsi, 2007</marker>
<rawString>J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit, S. Kübler, S. Marinov and E Marsi. 2007b. MaltParser: A language-independent system for data-driven dependency parsing. Natural Language Engineering, 13(2), 95-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Nilsson</author>
</authors>
<title>Pseudo-projective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proc. of ACL-2005,</booktitle>
<pages>99--106</pages>
<contexts>
<context position="16031" citStr="Nivre and Nilsson, 2005" startWordPosition="2546" endWordPosition="2549">.5 90.0 80.9 83.9 LMSaF 91.5 82.7 84.7 91.8 84.0 86.2 90.8 79.8 82.0 92.0 81.8 83.8 2stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2 Table 1: Results of all the four approaches using gold-standard shallow parser information. Malt is a classifier based shift/reduce parser. It provides option for six parsing algorithms, namely, arc-eager, arc-standard, convington projective, covington non-projective, stack projective, stack eager and stack lazy. The parser also provides option for libsvm and liblinear learning model. It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005). MST uses Chu-LiuEdmonds (Chu and Liu, 1965; Edmonds, 1967) Maximum Spanning Tree algorithm for nonprojective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005). In this paper, we use MST only for unlabeled dependency tree and use a separate maximum entropy model8 (MaxEnt) for labeling. Various combination of features such as node, its parent, siblings and children were tried out before arriving at the best results. As the training data size is small we did 5-fold cross validation on the </context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>J. Nivre and J. Nilsson. 2005. Pseudo-projective dependency parsing. In Proc. of ACL-2005, pp. 99–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avinesh PVS</author>
<author>K Gali</author>
</authors>
<title>Part-Of-Speech Tagging and Chunking Using Conditional Random Fields and Transformation Based Learning.</title>
<date>2007</date>
<booktitle>In Proc of the SPSAL workshop during IJCAI &apos;07.</booktitle>
<contexts>
<context position="18421" citStr="PVS and Gali, (2007)" startWordPosition="2927" endWordPosition="2930">roaches. For the MaxEnt, apart from some general useful features, we experimented considering different combinations of features of node, parent, siblings, and children of the node. 5 Results and Analysis All the experiments discussed in section 2 and 3 were performed considering both gold-standard shallow parser information and automatic shallow parser9 information. Automatic shallow parser uses a rule based system for morph analysis, a CRF+TBL based POS-tagger and chunker. The tagger and chunker are 93% and 87% accurate respectively. These accuracies are obtained after using the approach of PVS and Gali, (2007) on larger training data. In addition, while using automatic shallow parser information to get the results, we also explored using both gold-standard and automatic information during training. As expected, using automatic shallow parser information for training gave better performance than using gold while training. Table 1 and Table 2 shows the results of the four experiments using gold-standard and automatic shallow parser information respectively. We evaluated our experiments based on unlabeled attachment score (UAS), labeled attachment score (LAS) and labeled score (LS) (Nivre et al., 2007</context>
</contexts>
<marker>PVS, Gali, 2007</marker>
<rawString>Avinesh PVS and K. Gali. 2007. Part-Of-Speech Tagging and Chunking Using Conditional Random Fields and Transformation Based Learning. In Proc of the SPSAL workshop during IJCAI &apos;07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Seddah</author>
<author>M Candito</author>
<author>B Crabbé</author>
</authors>
<title>Cross parser evaluation: a French Treebanks study.</title>
<date>2009</date>
<booktitle>In Proc. of IWPT,</booktitle>
<pages>150--161</pages>
<contexts>
<context position="1919" citStr="Seddah et al., 2009" startWordPosition="270" endWordPosition="273"> 1 Introduction The dependency parsing community has since a few years shown considerable interest in parsing morphologically rich languages with flexible word order. This is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages have not been very high (Nivre et al., 2007a). Attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (Tsarfaty and Sima&apos;an, 2008; Eryigit et al., 2008; Seddah et al., 2009; Husain et al., 2009; Gadde et al., 2010). 22 Among other things, it has been pointed out that the use of language specific features may play a crucial role in improving the overall parsing performance. Different languages tend to encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic information could be a key to better accuracy. However, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many intuitive features do not always work in expe</context>
</contexts>
<marker>Seddah, Candito, Crabbé, 2009</marker>
<rawString>D. Seddah, M. Candito and B. Crabbé. 2009. Cross parser evaluation: a French Treebanks study. In Proc. of IWPT, 150-161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Tsarfaty</author>
<author>K Sima&apos;an</author>
</authors>
<title>RelationalRealizational Parsing.</title>
<date>2008</date>
<booktitle>In Proc. of CoLing,</booktitle>
<pages>889--896</pages>
<contexts>
<context position="1876" citStr="Tsarfaty and Sima&apos;an, 2008" startWordPosition="262" endWordPosition="265">empt at complete sentence level parsing for Hindi. 1 Introduction The dependency parsing community has since a few years shown considerable interest in parsing morphologically rich languages with flexible word order. This is partly due to the increasing availability of dependency treebanks for such languages, but it is also motivated by the observation that the performance obtained for these languages have not been very high (Nivre et al., 2007a). Attempts at handling various non-configurational aspects in these languages have pointed towards shortcomings in traditional parsing methodologies (Tsarfaty and Sima&apos;an, 2008; Eryigit et al., 2008; Seddah et al., 2009; Husain et al., 2009; Gadde et al., 2010). 22 Among other things, it has been pointed out that the use of language specific features may play a crucial role in improving the overall parsing performance. Different languages tend to encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic information could be a key to better accuracy. However, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many in</context>
</contexts>
<marker>Tsarfaty, Sima&apos;an, 2008</marker>
<rawString>R. Tsarfaty and K. Sima&apos;an. 2008. RelationalRealizational Parsing. In Proc. of CoLing, 889-896.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Vaidya</author>
<author>S Husain</author>
<author>P Mannem</author>
<author>D M Sharma</author>
</authors>
<title>A karaka-based dependency annotation scheme for English.</title>
<date>2009</date>
<booktitle>In Proc. of CICLing,</booktitle>
<pages>41--52</pages>
<contexts>
<context position="15091" citStr="Vaidya et al., 2009" startWordPosition="2393" endWordPosition="2396">en parsers, MaltParser6 (Nivre et al., 2007b), and MSTParser7 (McDonald et al., 2006). 4 nmod__adj is an intra-chunk label for quantifier-noun modification. lwg psp is the label for post-position marker. Details of the labels can be seen in the intra-chunk guidelines http://ltrc.iiit.ac.in/MachineTrans/research/tb/IntraChunkDependency-Annotation-Guidelines.pdf 5 k1 (karta) and k2 (karma) are syntactico-semantic labels which have some properties of both grammatical roles and thematic roles. k1 behaves similar to subject and agent. k2 behaves similar to object and patient (Bharati et al., 1995; Vaidya et al., 2009). For complete tagset, see (Bharati et al., 2009). 6 Malt Version 1.3.1 7 MST Version 0.4b 25 Malt MST+MaxEnt Cross-validation Test-set Cross-validation Test-set UAS LAS LS UAS LAS LS UAS LAS LS UAS LAS LS PaF 89.4 78.2 80.5 90.4 80.1 82.4 86.3 75.1 77.9 87.9 77.0 79.3 MaF 89.6 80.5 83.1 90.4 81.7 84.1 89.1 79.2 82.5 90.0 80.9 83.9 LMSaF 91.5 82.7 84.7 91.8 84.0 86.2 90.8 79.8 82.0 92.0 81.8 83.8 2stage 91.8 83.3 85.3 92.4 84.4 86.3 92.1 82.2 84.3 92.7 84.0 86.2 Table 1: Results of all the four approaches using gold-standard shallow parser information. Malt is a classifier based shift/reduce p</context>
</contexts>
<marker>Vaidya, Husain, Mannem, Sharma, 2009</marker>
<rawString>A. Vaidya, S. Husain, P. Mannem, and D. M. Sharma. 2009. A karaka-based dependency annotation scheme for English. In Proc. of CICLing, 41-52.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>