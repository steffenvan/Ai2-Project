<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.883442">
JU_CSE_TEMP: A First Step towards Evaluating Events, Time Ex-
pressions and Temporal Relations
</title>
<author confidence="0.994019">
Anup Kumar Kolya1, Asif Ekbal2 and Sivaji Bandyopadhyay3
</author>
<affiliation confidence="0.990438">
1,3Department of Computer Science and Engineering, Jadavpur University,
Kolkata-700032, India
2Department of Computational Linguistics, Heidelberg University,
</affiliation>
<address confidence="0.7064">
Heidelberg-69120, Germany
</address>
<email confidence="0.8044485">
Email: anup.kolya@gmail.com1, asif.ekbal@gmail.com2
and sivaji_cse_ju@yahoo.com3
</email>
<sectionHeader confidence="0.989377" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99998573076923">
Temporal information extraction is a
popular and interesting research field in
the area of Natural Language Processing
(NLP). In this paper, we report our works
on TempEval-2 shared task. This is our
first participation and we participated in
all the tasks, i.e., A, B, C, D, E and F. We
develop rule-based systems for Tasks A
and B, whereas the remaining tasks are
based on a machine learning approach,
namely Conditional Random Field
(CRF). All our systems are still in their
development stages, and we report the
very initial results. Evaluation results on
the shared task English datasets yield the
precision, recall and F-measure values of
55%, 17% and 26%, respectively for
Task A and 48%, 56% and 52%, respec-
tively for Task B (event recognition).
The rest of tasks, namely C, D, E and F
were evaluated with a relatively simpler
metric: the number of correct answers di-
vided by the number of answers. Experi-
ments on the English datasets yield the
accuracies of 63%, 80%, 56% and 56%
for tasks C, D, E and F, respectively.
</bodyText>
<sectionHeader confidence="0.998131" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994164">
Temporal information extraction is, nowadays, a
popular and interesting research area of Natural
Language Processing (NLP). Generally, events
are described in different newspaper texts, sto-
ries and other important documents where
events happen in time and the temporal location
and ordering of these events are specified. One
of the important tasks of text analysis clearly re-
quires identifying events described in a text and
locating these in time. This is also important in a
wide range of NLP applications that include
temporal question answering, machine transla-
tion and document summarization.
In the literature, temporal relation identifica-
tion based on machine learning approaches can
be found in Boguraev et el. (2005), Mani et al.
(2006), Chambers et al. (2007) and some of the
TempEval 2007 participants (Verhagen et al.,
2007). Most of these works tried to improve
classification accuracies through feature engi-
neering. The performance of any machine learn-
ing based system is often limited by the amount
of available training data. Mani et al. (2006) in-
troduced a temporal reasoning component that
greatly expands the available training data. The
training set was increased by a factor of 10 by
computing the closure of the various temporal
relations that exist in the training data. They re-
ported significant improvement of the classifica-
tion accuracies on event-event and event-time
relations. Their experimental result showed the
accuracies of 62.5%-94.95% and 73.68%-
90.16% for event-event and event-time relations,
respectively. However, this has two shortcom-
ings, namely feature vector duplication caused
by the data normalization process and the unreal-
istic evaluation scheme. The solutions to these
issues are briefly described in Mani et al. (2007).
In TempEval 2007 task, a common standard da-
taset was introduced that involves three temporal
relations. The participants reported F-measure
scores for event-event relations ranging from
42% to 55% and for event-time relations from
73% to 80%. Unlike (Mani et al., 2007; 2006),
event-event temporal relations were not dis-
course-wide (i.e., any pair of events can be tem-
porally linked) in TempEval 2007. Here, the
event-event relations were restricted to events
within two consecutive sentences. Thus, these
two frameworks produced highly dissimilar re-
</bodyText>
<page confidence="0.666291">
345
</page>
<note confidence="0.5985125">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 345–350,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.99997756097561">
sults for solving the problem of temporal relation
classification.
In order to apply various machine learning al-
gorithms, most of the authors formulated tempo-
ral relation as an event paired with a time or an-
other event and translated these into a set of fea-
ture values. Some of the popularly used machine
learning techniques were Naive-Bayes, Decision
Tree (C5.0), Maximum Entropy (ME) and Sup-
port Vector Machine (SVM). Machine learning
techniques alone cannot always yield good accu-
racies. To achieve reasonable accuracy, some
researchers (Mao et al., 2006) used hybrid ap-
proach. The basic principle of hybrid approach is
to combine the rule-based component with ma-
chine learning. It has been shown in (Mao et al.,
2006) that classifiers make most mistakes near
the decision plane in feature space. The authors
carried out a series of experiments for each of the
three tasks on four models, namely naive-Bayes,
decision tree (C5.0), maximum entropy and sup-
port vector machine. The system was designed in
such a way that they can take the advantage of
rule-based as well as machine learning during
final decision making. But, they did not explain
exactly in what situations machine learning or
rule based system should be used given a particu-
lar instance. They had the option to call either
component on the fly in different situations so
that they can take advantage of the two empirical
approaches in an integrated way.
The rest of the paper is structured as follows.
We present very brief descriptions of the differ-
ent tasks in Section 2. Section 3 describes our
approach in details with rule-based techniques
for tasks A and B in Subsection 3.1, CRF based
techniques in Subsection 3.2 for tasks C, D, E
and F, and features in Subsection 3.3. Detailed
evaluation results are reported in Section 4. Fi-
nally, Section 5 concludes the paper with a direc-
tion to future works.
</bodyText>
<sectionHeader confidence="0.975525" genericHeader="method">
2 Task Description
</sectionHeader>
<bodyText confidence="0.999948565217391">
The main research in this area involves identifi-
cation of all temporal referring expressions,
events and temporal relations within a text. The
main challenges involved in this task were first
addressed during TempEval-1 in 2007 (Verhagen
et al., 2007). This was an initial evaluation exer-
cise based on three limited tasks that were con-
sidered realistic both from the perspective of as-
sembling resources for development and testing
and from the perspective of developing systems
capable of addressing the tasks. In TempEval
2007, following types of event-time temporal
relations were considered: Task A (relation be-
tween the events and times within the same sen-
tence), Task B (relation between events and
document creation time) and Task C (relation
between verb events in adjacent sentences). The
data sets were based on TimeBank, a hand-built
gold standard of annotated texts using the Ti-
meML markup scheme1. The data sets included
sentence boundaries, timex3 tags (including the
special document creation time tag), and event
tags. For tasks A and B, a restricted set of events
was used, namely those events that occur more
than 5 times in TimeBank. For all three tasks, the
relation labels used were before, after, overlap,
before-or-overlap, overlap-or-after and vague.
Six teams participated in the TempEval tasks.
Three of the teams used statistics exclusively,
one used a rule-based system and the other two
employed a hybrid approach. For task A, the
range of F-measure scores were from 0.34 to
0.62 for the strict scheme and from 0.41 to 0.63
for the relaxed scheme. For task B, the scores
were from 0.66 to 0.80 (strict) and 0.71 to 0.81
(relaxed). Finally, task C scores range from 0.42
to 0.55 (strict) and from 0.56 to 0.66 (relaxed).
In TempEval-2, the following six tasks were
proposed:
A: The main task was to determine the extent of
the time expressions in a text as defined by the
TimeML timex3 tag. In addition, values of the
features type and val had to be determined. The
possible values of type are time, date, duration,
and set; the value of val is a normalized value as
defined by the timex2 and timex3 standards.
</bodyText>
<listItem confidence="0.852985571428571">
B. Task was to determine the extent of the events
in a text as defined by the TimeML event tag. In
addition, the values of the features tense, aspect,
polarity, and modality had to be determined.
C. Task was to determine the temporal relation
between an event and a time expression in the
same sentence.
D. Temporal relation between an event and the
document creation time had to be determined.
E. Temporal relation between two main events in
consecutive sentences had to be determined.
F. Temporal relation between two events, where
one event syntactically dominates the other
event.
</listItem>
<bodyText confidence="0.9992795">
In our present work, use handcrafted rules for
Task A and Task B. All the other tasks, i.e., C,
D, E and F are developed based on the well
known statistical algorithm, Conditional Random
</bodyText>
<footnote confidence="0.904698">
1www.timeml.org for details on TimeML
</footnote>
<page confidence="0.888512">
346
</page>
<bodyText confidence="0.9997271">
Field (CRF). For CRF, we use only those fea-
tures that are available in the training data. All
the systems are evaluated on the TempEval-
2 shared task English datasets. Evaluation results
yield the precision, recall and F-measure values
of 55%, 17% and 26%, respectively for Task A
and 48%, 56% and 52%, respectively for Task B.
Experiments on the other tasks demonstrate the
accuracies of 63%, 80%, 56% and 56% for C, D,
E and F, respectively.
</bodyText>
<sectionHeader confidence="0.971471" genericHeader="method">
3 Our Approach
</sectionHeader>
<bodyText confidence="0.999993222222222">
In this section, we present our systematic ap-
proach for evaluating events, time expressions
and temporal relations as part of our first partici-
pation in the TempEval shared task. We partici-
pated in all the six tasks of TempEval-2. Rule-
based systems are developed using a preliminary
handcrafted set of rules for tasks A and B. We
use machine learning approach, namely CRF for
solving the remaining tasks, i.e., C, D, E and F.
</bodyText>
<subsectionHeader confidence="0.984444">
3.1 Rules for Task A and Task B
</subsectionHeader>
<bodyText confidence="0.9999225">
We manually identify a set of rules studying the
various features available in the training data.
There were some exceptions to these rules. How-
ever, a rule is used if it is found to be correct
most of the time throughout the training data. It
is to be noted that these are the very preliminary
rules, and we are still working on finding out
more robust rules. Below, we present the rules
for tasks A and B.
Task A. The time expression is identified by de-
fining appropriate regular expression. The regu-
lar expressions are based on several entities that
denote month names, year, weekdays and the
various digit expressions. We also use a list of
keywords (e.g., day, time, AM, PM etc.) that de-
note the various time expressions. The values of
various attributes (e.g., type and value) of time
expressions are computed by some simple tem-
plate matching algorithms.
Task B. In case of Task B, the training data is
initially passed through the Stanford PoS tagger2.
We consider the tokens as the events that are
tagged with POS tags such as VB, VBG, VBN,
VBP, VBZ and VBD, denoting the various verb
expressions. Values of different attributes are
computed as follows.
</bodyText>
<footnote confidence="0.349076">
2 http://nlp.stanford.edu/software/tagger.shtml
</footnote>
<listItem confidence="0.98539776">
a. Tense: A manually augmented suffix list such
as: &amp;quot;ed&amp;quot;,&amp;quot;d&amp;quot;,&amp;quot;t&amp;quot; etc. is used to capture the proper
tense of any event verb from surface level ortho-
graphic variations.
b. Aspect: The Tense-Aspect-Modality (TAM)
for English verbs is generally associated with
auxiliaries. A list is manually prepared. Any oc-
currence of main verb with continuous aspect
leads to search for the adjacent previous auxil-
iary and rules are formulated to extract TAM
relation using the manually generated checklist.
A separate list of auxiliaries is prepared and suc-
cessfully used for detection of progressive verbs.
c. Polarity: Verb-wise polarity is assigned by the
occurrence of previous negation words. If any
negation word appears before any event verb
then the resultant polarity is negative; otherwise,
the verb considered as positive by default.
d. Modality: We prepare a manual list that con-
tains the words such as: may, could, would etc.
The presence of these modal auxiliaries gives
modal tag to the targeted verb in a sentence oth-
erwise it is considered a non-modal.
e. Class: We select ‘occurrence’ to be class val-
ue by default.
</listItem>
<subsectionHeader confidence="0.7046675">
3.2 Machine Learning Approach for Tasks
C, D, E and F
</subsectionHeader>
<bodyText confidence="0.999825153846154">
For tasks C-F, we use a supervised machine
learning approach that is based on CRF. We con-
sider the temporal relation identification task as a
pair-wise classification problem in which the
target pairs–a TIMEX3 tag and an EVENT–are
modelled using CRF, which can include arbitrary
set of features, and still can avoid overfitting in a
principled manner.
Introduction to CRF. CRF (Lafferty et al.,
2001), is used to calculate the conditional prob-
ability of values on designated output nodes
given values on other designated input nodes.
The conditional probability of a state sequence
</bodyText>
<equation confidence="0.874949">
S =&lt; s1, s2, ..., sT &gt; given an observation se-
quence =&lt; o , , oT) is calculated as:
O o1 , 2
1
(s |o) = exp(Z Z λkfk(st −1, st, o, t))
Zo t=1 k=1
</equation>
<bodyText confidence="0.7226915">
where, fk(st −1, st, o, t
whose weight λ is to be learned via training.
</bodyText>
<figure confidence="0.863957571428571">
k
The values of the feature functions may range
between − oc + oc , but typically they are
T K
PΛ
) is a feature function
347
</figure>
<bodyText confidence="0.911108">
binary. To make all conditional probabilities sum
up to 1, we must calculate the normalization
factor,
</bodyText>
<equation confidence="0.9997015">
T K
Z0 = ∑ ∑ ∑
s exp( λf s − 1 st, o t
k k t
( , ,
t = 1 k=1
</equation>
<bodyText confidence="0.976975222222222">
which, as in HMMs, can be obtained efficiently
by dynamic programming.
To train a CRF, the objective function to be
maximized is the penalized log-likelihood of the
state sequences given the observation sequence:
where, { &lt; o(i), s(i) &gt; } is the labeled training da-
ta. The second sum corresponds to a zero-mean,
σ -variance Gaussian prior over parameters,
2
which facilitates optimization by making the li-
kelihood surface strictly convex.
CRFs generally can use real-valued functions
but it is often required to incorporate the binary
valued features. A feature function
fk(st − 1, st, o, t) has a value of 0 for most cases
and is only set to 1, when st −1, st are certain
states and the observation has certain properties.
Here, we set parameters λ to maximize the pe-
nalized log-likelihood using Limited-memory
BFGS (Sha and Pereira, 2003) a quasi-Newton
method that is significantly more efficient, and
which results in only minor changes in accuracy
due to changes in σ .
We use the OpenNLP C++ based CRF++ pack-
age3, a simple, customizable, and open source
implementation of CRF for segmenting /labeling
sequential data.
</bodyText>
<subsectionHeader confidence="0.996792">
3.3 Features of Tasks C, D, E and F
</subsectionHeader>
<bodyText confidence="0.925006666666667">
We extract the gold-standard TimeBank features
for events and times in order to train/test the
CRF. In the present work, we mainly use the
various combinations of the following features:
(i). Part of Speech (POS) of event terms: It de-
notes the POS information of the event. The fea-
tures values may be either of ADJECTIVE,
NOUN, VERB, and PREP.
(ii). Event Tense: This feature is useful to cap-
ture the standard distinctions among the gram-
matical categories of verbal phrases. The tense
attribute can have values, PRESENT, PAST,
3http://crfpp.sourceforge.net
FUTURE, INFINITIVE, PRESPART, PAST-
PART, or NONE.
</bodyText>
<listItem confidence="0.746682538461538">
(iii). Event Aspect: It denotes the aspect of the
events. The aspect attribute may take values,
PROGRESSIVE, PERFECTIVE and PERFEC-
TIVE PROGRESSIVE or NONE.
(iv). Event Polarity: The polarity of an event
instance is a required attribute represented by the
boolean attribute, polarity. If it is set to ’NEG’,
the event instance is negated. If it is set to ’POS’
or not present in the annotation, the event in-
stance is not negated.
(v). Event Modality: The modality attribute is
only present if there is a modal word that modi-
fies the instance.
</listItem>
<bodyText confidence="0.972723475">
(vi). Event Class: This is denoted by the
‘EVENT’ tag and used to annotate those ele-
ments in a text that mark the semantic events
described by it. Typically, events are verbs but
can be nominal also. It may belong to one of the
following classes:
REPORTING: Describes the action of a person
or an organization declaring something, narrating
an event, informing about an event, etc. For ex-
ample, say, report, tell, explain, state etc.
PERCEPTION: Includes events involving the
physical perception of another event. Such
events are typically expressed by verbs like: see,
watch, glimpse, behold, view, hear, listen, over-
hear etc.
ASPECTUAL: Focuses on different facets of
event history. For example, initiation, reinitia-
tion, termination, culmination, continuation etc.
I_ACTION: An intentional action. It introduces
an event argument which must be in the text ex-
plicitly describing an action or situation from
which we can infer something given its relation
with the I_ ACTION.
I STATE: Similar to the I ACTION class. This
_ _
class includes states that refer to alternative or
possible words, which can be introduced by sub-
ordinated clauses, nominalizations, or untensed
verb phrases (VPs).
STATE: Describes circumstances in which
something obtains or holds true.
Occurrence: Includes all of the many other
kinds of events that describe something that hap-
pens or occurs in the world.
(vii). Type of temporal expression: It repre-
sents the temporal relationship holding between
events, times, or between an event and a time of
the event.
(viii). Event Stem: It denotes the stem of the
head event.
</bodyText>
<equation confidence="0.942707571428571">
N
L ∧ =∑
i
log(P∧ (sO)  |o(i) )) −∑
K
=1 k= 1
2
λ
k
,
2
2σ
)) ,
348
</equation>
<bodyText confidence="0.9835685">
(ix). Document Creation Time: The document
creation time of the event.
</bodyText>
<sectionHeader confidence="0.977356" genericHeader="evaluation">
4 Evaluation Results
</sectionHeader>
<bodyText confidence="0.9979785">
Each of the tasks is evaluated with the Tem-
pEval-2 shared task datasets.
</bodyText>
<subsectionHeader confidence="0.998911">
4.1 Evaluation Scheme
</subsectionHeader>
<bodyText confidence="0.9999375">
For the extents of events and time expressions
(tasks A and B), precision, recall and the F-
measure are used as evaluation metrics, using the
following formulas:
</bodyText>
<equation confidence="0.952223666666667">
Precision (P) = tp/ (tp + fp)
Recall (R) = tp/ (tp + fn)
F-measure = 2 *(P * R)/ (P + R)
</equation>
<bodyText confidence="0.996027928571429">
Where, tp is the number of tokens that are part
of an extent in both keys and response,
fp is the number of tokens that are part of an ex-
tent in the response but not in the key, and
fn is the number of tokens that are part of an ex-
tent in the key but not in the response.
An even simpler evaluation metric similar to
the definition of ‘accuracy’ is used to evaluate
the attributes of events and time expressions (the
second part of tasks, A and B) and for relation
types (tasks C through F). The metric, henceforth
referred to as ‘accuracy’, is defined as below:
Number of correct answers/ Number of an-
swers present in the test data
</bodyText>
<subsectionHeader confidence="0.694854">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.9993338">
For tasks A and B, we identify a set of rules from
the training set and apply them on the respective
test sets.
The tasks C, D, E and F are based on CRF. We
develop a number of models based on CRF using
the different features included into it. A feature
vector consisting of the subset of the available
features as described in Section 2.3 is extracted
for each of &lt;event, timex&gt;, &lt;event, DCT&gt;,
&lt;event, event&gt; and &lt;event, event&gt; pairs in tasks
</bodyText>
<equation confidence="0.765488333333333">
C, D, E and F, respectively. Now, we have a
training data in the form ( , , where, is
W i T i ) Wi
</equation>
<bodyText confidence="0.9650508">
the ith pair along with its feature vector and is
Tiit’s corresponding TempEval relation class.
Models are built based on the training data and
the feature template. The procedure of training is
summarized below:
</bodyText>
<listItem confidence="0.9796738">
1. Define the training corpus, C.
2. Extract the corresponding relation from
the training corpus.
3. Create a file of candidate features, in-
cluding lexical features derived from the
training corpus.
4. Define a feature template.
5. Compute the CRF weights λk for every fK
using the CRF toolkit with the training
file and feature template as input.
</listItem>
<bodyText confidence="0.999304166666667">
During evaluation, we consider the following
feature templates for the respective tasks:
(i) Task C: Feature vector consisting of current
token, polarity, POS, tense, class and value;
combination of token and type, combination of
tense and value of the current token, combination
of aspect and type of current token, combination
of aspect, value and type of the current token.
(ii) Task D: Feature vector consisting of current
token and POS; combination of POS and tense of
the current token, combination of polarity and
POS of the current token, combination of POS
and aspect of current token, combination of po-
larity and POS of current token, combination of
POS, tense and aspect of the current token.
(iii). Task E: Current token, combination of
event-class and event-id of the current token,
combination of POS tags of the pair of events,
combination of (tense, aspect) values of the event
pairs.
(iv). Task F: Current token, combination of POS
tags of the pair of events, combination of tense
values of the event pairs, combination of the as-
pect values of the event pairs, combination of the
event classes of the event pairs.
Experimental results of tasks A and B are re-
ported in Table 1 for English datasets. The re-
sults for task A, i.e., recognition and normaliza-
tion of time expressions, yield the precision, re-
call and F-measure values of 55%, 17% and
26%, respectively. For task B, i.e., event recogni-
tion, the system yields precision, recall and F-
measure values of 48%, 56% and 52%, respec-
tively. Event attribute identification shows the
accuracies of 98%, 98%, 30%, 95% and 53% for
polarity, mood, modality, tense, aspect and class,
respectively. These systems are the baseline
models, and the performance can further be im-
proved with a more carefully handcrafted set of
robust rules. In further experiments, we would
also like to apply machine learning methods to
these problems.
</bodyText>
<page confidence="0.764614">
349
</page>
<table confidence="0.9968265">
Task precision recall F-measure
(in %) (in %) (in %)
A 55% 17% 26%
B 48% 56% 52%
</table>
<tableCaption confidence="0.999844">
Table 1. Experimental results on tasks A and B
</tableCaption>
<bodyText confidence="0.999867315789474">
Evaluation results on the English datasets for
tasks C, D, E and F are presented in Table 2. Ex-
periments show the accuracies of 63%, 80%,
56% and 56% for tasks C, D, E and F, respec-
tively. Results show that our system performs
best for task D, i.e., relationships between event
and document creation time. The system
achieves an accuracy of 63% for task C that finds
the temporal relation between an event and a time
expression in the same sentence. The system per-
forms quite similarly for tasks E and F. It is to be
noted that there is still the room for performance
improvement. In the present work, we did not
carry out sufficient experiments to identify the
most suitable feature templates for each of the
tasks. In future, we would experiment after se-
lecting a development set for each task; and find
out appropriate feature template depending upon
the performance on the development set.
</bodyText>
<table confidence="0.9094574">
Task Accuracy (in %)
C 63%
D 80%
E 56%
F 56%
</table>
<tableCaption confidence="0.910407">
Table 2. Experimental results on tasks C, D, E
and F
</tableCaption>
<sectionHeader confidence="0.992123" genericHeader="conclusions">
5 Conclusion and Future Works
</sectionHeader>
<bodyText confidence="0.999965291666667">
In this paper, we report very preliminary results
of our first participation in the TempEval shared
task. We participated in all the tasks of Tem-
pEval-2, i.e., A, B, C, D, E and F for English.
We develop the rule-based systems for tasks A
and B, whereas the remaining tasks are based on
a machine learning approach, namely CRF. All
our systems are still in their development stages.
Evaluation results on the shared task English
datasets yield the precision, recall and F-measure
values of 55%, 17% and 26%, respectively for
Task A and 48%, 56% and 52%, respectively for
Task B (event recognition). Experiments on the
English datasets yield the accuracies of 63%,
80%, 56% and 56% for tasks C, D, E and F, re-
spectively.
Future works include identification of more
precise rules for tasks A and B. We would also
like to experiment with CRF for these two tasks.
We would experiment with the various feature
templates for tasks C, D, E and F. Future works
also include experimentations with other ma-
chine learning techniques like maximum entropy
and support vector machine.
</bodyText>
<sectionHeader confidence="0.998479" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999601923076923">
Boguraev, B. and R. K. Ando. 2005. TimeML
Compliant Text Analysis for Temporal Rea-
soning. In Proceedings of Nineteenth Interna-
tional Joint Conference on Artificial Intelli-
gence (IJCAI-05), Edinburgh, Scotland, Au-
gust, pages 997–1003.
Chambers, N., S., Wang, and D., Jurafsky. ,
2007. Classifying Temporal Relations between
Events. In Proceedings of the ACL 2007 Demo
and Poster Sessions, Prague, Czech Republic,
June, pages 173–176.
Lafferty, J., McCallum, A., and Pereira, F.
Conditional Random Fields: Probabilistic
Models for Segmenting and Labeling Se-
quence Data. In Proceedings of 18th Interna-
tional Conference on Machine Learning,
2001.
Mani, I., B., Wellner, M., Verhagen, and J.
Pustejovsky. 2007. Three Approaches to
Learning TLINKs in TimeML. Technical Re-
port CS-07-268, Computer Science Depart-
ment, Brandeis University, Waltham, USA.
Mani, I., Wellner, B., Verhagen, M., Lee C.M.,
Pustejovsky, J. 2006. Machine Learning of
Temporal Relation. In Proceedings of the
COLING/ACL, Sydney, Australia, ACL.
Mao, T., Li., T., Huang, D., Yang, Y. 2006. Hy-
brid Models for Chinese Named Entity Rec-
ognition. In Proceedings of the Fifth SIGHAN
Workshop on Chinese Language Processing.
Sha, F., Pereira, F. 2003. Shallow Parsing with
Conditional Random Fields. In Proceedings of
HLT-NAACL, 2003.
Verhagen, M., Gaizauskas, R., Schilder, F., Hep-
ple, M., Katz, G., Pustejovsky, and J.: SemE-
val-2007 Task 15: TempEval Temporal Rela-
tion Identification. 2007. In Proceedings of the
SemEval-2007, Prague, June 2007, pages 75-
80.
</reference>
<page confidence="0.86647">
350
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.813412">
<title confidence="0.9990685">A First Step towards Evaluating Events, Time pressions and Temporal Relations</title>
<author confidence="0.996284">Kumar Asif</author>
<author confidence="0.996284">Sivaji</author>
<affiliation confidence="0.99998">of Computer Science and Engineering, Jadavpur University,</affiliation>
<address confidence="0.979817">Kolkata-700032, India</address>
<affiliation confidence="0.998217">of Computational Linguistics, Heidelberg University,</affiliation>
<address confidence="0.999036">Heidelberg-69120, Germany</address>
<abstract confidence="0.992928481481482">Temporal information extraction is a popular and interesting research field in the area of Natural Language Processing (NLP). In this paper, we report our works on TempEval-2 shared task. This is our first participation and we participated in all the tasks, i.e., A, B, C, D, E and F. We develop rule-based systems for Tasks A and B, whereas the remaining tasks are based on a machine learning approach, namely Conditional Random Field (CRF). All our systems are still in their development stages, and we report the very initial results. Evaluation results on the shared task English datasets yield the precision, recall and F-measure values of 55%, 17% and 26%, respectively for Task A and 48%, 56% and 52%, respectively for Task B (event recognition). The rest of tasks, namely C, D, E and F were evaluated with a relatively simpler metric: the number of correct answers divided by the number of answers. Experiments on the English datasets yield the accuracies of 63%, 80%, 56% and 56% for tasks C, D, E and F, respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Boguraev</author>
<author>R K Ando</author>
</authors>
<title>TimeML Compliant Text Analysis for Temporal Reasoning.</title>
<date>2005</date>
<booktitle>In Proceedings of Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-05),</booktitle>
<pages>997--1003</pages>
<location>Edinburgh, Scotland,</location>
<marker>Boguraev, Ando, 2005</marker>
<rawString>Boguraev, B. and R. K. Ando. 2005. TimeML Compliant Text Analysis for Temporal Reasoning. In Proceedings of Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-05), Edinburgh, Scotland, August, pages 997–1003.</rawString>
</citation>
<citation valid="true">
<title>Classifying Temporal Relations between Events.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL 2007 Demo and Poster Sessions,</booktitle>
<pages>173--176</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2238" citStr="(2007)" startWordPosition="342" endWordPosition="342">rent newspaper texts, stories and other important documents where events happen in time and the temporal location and ordering of these events are specified. One of the important tasks of text analysis clearly requires identifying events described in a text and locating these in time. This is also important in a wide range of NLP applications that include temporal question answering, machine translation and document summarization. In the literature, temporal relation identification based on machine learning approaches can be found in Boguraev et el. (2005), Mani et al. (2006), Chambers et al. (2007) and some of the TempEval 2007 participants (Verhagen et al., 2007). Most of these works tried to improve classification accuracies through feature engineering. The performance of any machine learning based system is often limited by the amount of available training data. Mani et al. (2006) introduced a temporal reasoning component that greatly expands the available training data. The training set was increased by a factor of 10 by computing the closure of the various temporal relations that exist in the training data. They reported significant improvement of the classification accuracies on e</context>
</contexts>
<marker>2007</marker>
<rawString>Chambers, N., S., Wang, and D., Jurafsky. , 2007. Classifying Temporal Relations between Events. In Proceedings of the ACL 2007 Demo and Poster Sessions, Prague, Czech Republic, June, pages 173–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>In Proceedings of 18th International Conference on Machine Learning,</booktitle>
<contexts>
<context position="12514" citStr="Lafferty et al., 2001" startWordPosition="2039" endWordPosition="2042">l auxiliaries gives modal tag to the targeted verb in a sentence otherwise it is considered a non-modal. e. Class: We select ‘occurrence’ to be class value by default. 3.2 Machine Learning Approach for Tasks C, D, E and F For tasks C-F, we use a supervised machine learning approach that is based on CRF. We consider the temporal relation identification task as a pair-wise classification problem in which the target pairs–a TIMEX3 tag and an EVENT–are modelled using CRF, which can include arbitrary set of features, and still can avoid overfitting in a principled manner. Introduction to CRF. CRF (Lafferty et al., 2001), is used to calculate the conditional probability of values on designated output nodes given values on other designated input nodes. The conditional probability of a state sequence S =&lt; s1, s2, ..., sT &gt; given an observation sequence =&lt; o , , oT) is calculated as: O o1 , 2 1 (s |o) = exp(Z Z λkfk(st −1, st, o, t)) Zo t=1 k=1 where, fk(st −1, st, o, t whose weight λ is to be learned via training. k The values of the feature functions may range between − oc + oc , but typically they are T K PΛ ) is a feature function 347 binary. To make all conditional probabilities sum up to 1, we must calcula</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J., McCallum, A., and Pereira, F. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proceedings of 18th International Conference on Machine Learning, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>B Wellner</author>
<author>M Verhagen</author>
<author>J Pustejovsky</author>
</authors>
<title>Three Approaches to Learning TLINKs in TimeML.</title>
<date>2007</date>
<tech>Technical Report CS-07-268,</tech>
<institution>Computer Science Department, Brandeis University,</institution>
<location>Waltham, USA.</location>
<contexts>
<context position="3237" citStr="Mani et al. (2007)" startWordPosition="491" endWordPosition="494">a. The training set was increased by a factor of 10 by computing the closure of the various temporal relations that exist in the training data. They reported significant improvement of the classification accuracies on event-event and event-time relations. Their experimental result showed the accuracies of 62.5%-94.95% and 73.68%- 90.16% for event-event and event-time relations, respectively. However, this has two shortcomings, namely feature vector duplication caused by the data normalization process and the unrealistic evaluation scheme. The solutions to these issues are briefly described in Mani et al. (2007). In TempEval 2007 task, a common standard dataset was introduced that involves three temporal relations. The participants reported F-measure scores for event-event relations ranging from 42% to 55% and for event-time relations from 73% to 80%. Unlike (Mani et al., 2007; 2006), event-event temporal relations were not discourse-wide (i.e., any pair of events can be temporally linked) in TempEval 2007. Here, the event-event relations were restricted to events within two consecutive sentences. Thus, these two frameworks produced highly dissimilar re345 Proceedings of the 5th International Worksho</context>
</contexts>
<marker>Mani, Wellner, Verhagen, Pustejovsky, 2007</marker>
<rawString>Mani, I., B., Wellner, M., Verhagen, and J. Pustejovsky. 2007. Three Approaches to Learning TLINKs in TimeML. Technical Report CS-07-268, Computer Science Department, Brandeis University, Waltham, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>B Wellner</author>
<author>M Verhagen</author>
<author>C M Lee</author>
<author>J Pustejovsky</author>
</authors>
<title>Machine Learning of Temporal Relation.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL,</booktitle>
<location>Sydney, Australia, ACL.</location>
<contexts>
<context position="2214" citStr="Mani et al. (2006)" startWordPosition="335" endWordPosition="338">rally, events are described in different newspaper texts, stories and other important documents where events happen in time and the temporal location and ordering of these events are specified. One of the important tasks of text analysis clearly requires identifying events described in a text and locating these in time. This is also important in a wide range of NLP applications that include temporal question answering, machine translation and document summarization. In the literature, temporal relation identification based on machine learning approaches can be found in Boguraev et el. (2005), Mani et al. (2006), Chambers et al. (2007) and some of the TempEval 2007 participants (Verhagen et al., 2007). Most of these works tried to improve classification accuracies through feature engineering. The performance of any machine learning based system is often limited by the amount of available training data. Mani et al. (2006) introduced a temporal reasoning component that greatly expands the available training data. The training set was increased by a factor of 10 by computing the closure of the various temporal relations that exist in the training data. They reported significant improvement of the classi</context>
</contexts>
<marker>Mani, Wellner, Verhagen, Lee, Pustejovsky, 2006</marker>
<rawString>Mani, I., Wellner, B., Verhagen, M., Lee C.M., Pustejovsky, J. 2006. Machine Learning of Temporal Relation. In Proceedings of the COLING/ACL, Sydney, Australia, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mao</author>
<author>T Li</author>
<author>D Huang</author>
<author>Y Yang</author>
</authors>
<title>Hybrid Models for Chinese Named Entity Recognition.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing.</booktitle>
<contexts>
<context position="4529" citStr="Mao et al., 2006" startWordPosition="687" endWordPosition="690">uly 2010. c�2010 Association for Computational Linguistics sults for solving the problem of temporal relation classification. In order to apply various machine learning algorithms, most of the authors formulated temporal relation as an event paired with a time or another event and translated these into a set of feature values. Some of the popularly used machine learning techniques were Naive-Bayes, Decision Tree (C5.0), Maximum Entropy (ME) and Support Vector Machine (SVM). Machine learning techniques alone cannot always yield good accuracies. To achieve reasonable accuracy, some researchers (Mao et al., 2006) used hybrid approach. The basic principle of hybrid approach is to combine the rule-based component with machine learning. It has been shown in (Mao et al., 2006) that classifiers make most mistakes near the decision plane in feature space. The authors carried out a series of experiments for each of the three tasks on four models, namely naive-Bayes, decision tree (C5.0), maximum entropy and support vector machine. The system was designed in such a way that they can take the advantage of rule-based as well as machine learning during final decision making. But, they did not explain exactly in </context>
</contexts>
<marker>Mao, Li, Huang, Yang, 2006</marker>
<rawString>Mao, T., Li., T., Huang, D., Yang, Y. 2006. Hybrid Models for Chinese Named Entity Recognition. In Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sha</author>
<author>F Pereira</author>
</authors>
<title>Shallow Parsing with Conditional Random Fields.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<contexts>
<context position="14044" citStr="Sha and Pereira, 2003" startWordPosition="2332" endWordPosition="2335">, { &lt; o(i), s(i) &gt; } is the labeled training data. The second sum corresponds to a zero-mean, σ -variance Gaussian prior over parameters, 2 which facilitates optimization by making the likelihood surface strictly convex. CRFs generally can use real-valued functions but it is often required to incorporate the binary valued features. A feature function fk(st − 1, st, o, t) has a value of 0 for most cases and is only set to 1, when st −1, st are certain states and the observation has certain properties. Here, we set parameters λ to maximize the penalized log-likelihood using Limited-memory BFGS (Sha and Pereira, 2003) a quasi-Newton method that is significantly more efficient, and which results in only minor changes in accuracy due to changes in σ . We use the OpenNLP C++ based CRF++ package3, a simple, customizable, and open source implementation of CRF for segmenting /labeling sequential data. 3.3 Features of Tasks C, D, E and F We extract the gold-standard TimeBank features for events and times in order to train/test the CRF. In the present work, we mainly use the various combinations of the following features: (i). Part of Speech (POS) of event terms: It denotes the POS information of the event. The fe</context>
</contexts>
<marker>Sha, Pereira, 2003</marker>
<rawString>Sha, F., Pereira, F. 2003. Shallow Parsing with Conditional Random Fields. In Proceedings of HLT-NAACL, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Verhagen</author>
<author>R Gaizauskas</author>
<author>F Schilder</author>
<author>M Hepple</author>
<author>G Katz</author>
<author>Pustejovsky</author>
<author>J SemEval-2007</author>
</authors>
<title>Task 15: TempEval Temporal Relation Identification.</title>
<date>2007</date>
<booktitle>In Proceedings of the SemEval-2007,</booktitle>
<pages>75--80</pages>
<location>Prague,</location>
<contexts>
<context position="2305" citStr="Verhagen et al., 2007" startWordPosition="350" endWordPosition="353">ocuments where events happen in time and the temporal location and ordering of these events are specified. One of the important tasks of text analysis clearly requires identifying events described in a text and locating these in time. This is also important in a wide range of NLP applications that include temporal question answering, machine translation and document summarization. In the literature, temporal relation identification based on machine learning approaches can be found in Boguraev et el. (2005), Mani et al. (2006), Chambers et al. (2007) and some of the TempEval 2007 participants (Verhagen et al., 2007). Most of these works tried to improve classification accuracies through feature engineering. The performance of any machine learning based system is often limited by the amount of available training data. Mani et al. (2006) introduced a temporal reasoning component that greatly expands the available training data. The training set was increased by a factor of 10 by computing the closure of the various temporal relations that exist in the training data. They reported significant improvement of the classification accuracies on event-event and event-time relations. Their experimental result show</context>
<context position="6115" citStr="Verhagen et al., 2007" startWordPosition="956" endWordPosition="959">tasks in Section 2. Section 3 describes our approach in details with rule-based techniques for tasks A and B in Subsection 3.1, CRF based techniques in Subsection 3.2 for tasks C, D, E and F, and features in Subsection 3.3. Detailed evaluation results are reported in Section 4. Finally, Section 5 concludes the paper with a direction to future works. 2 Task Description The main research in this area involves identification of all temporal referring expressions, events and temporal relations within a text. The main challenges involved in this task were first addressed during TempEval-1 in 2007 (Verhagen et al., 2007). This was an initial evaluation exercise based on three limited tasks that were considered realistic both from the perspective of assembling resources for development and testing and from the perspective of developing systems capable of addressing the tasks. In TempEval 2007, following types of event-time temporal relations were considered: Task A (relation between the events and times within the same sentence), Task B (relation between events and document creation time) and Task C (relation between verb events in adjacent sentences). The data sets were based on TimeBank, a hand-built gold st</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, SemEval-2007, 2007</marker>
<rawString>Verhagen, M., Gaizauskas, R., Schilder, F., Hepple, M., Katz, G., Pustejovsky, and J.: SemEval-2007 Task 15: TempEval Temporal Relation Identification. 2007. In Proceedings of the SemEval-2007, Prague, June 2007, pages 75-80.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>