<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007647">
<title confidence="0.977876">
Discourse Cues for Broadcast News Segmentation
</title>
<author confidence="0.686047">
Mark T. Maybury
</author>
<affiliation confidence="0.375844">
The MITRE Corporation
</affiliation>
<address confidence="0.826604">
202 Burlington Road
Bedford, MA 01730, USA
</address>
<email confidence="0.969797">
maybury@mitre.org
</email>
<sectionHeader confidence="0.993201" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9980606">
This paper describes the design and application of
time-enhanced, finite state models of discourse
cues to the automated segmentation of broadcast
news. We describe our analysis of a broadcast
news corpus, the design of a discourse cue based
story segmentor that builds upon information
extraction techniques, and finally its computational
implementation and evaluation in the Broadcast
News Navigator (BNN) to support video news
browsing, retrieval, and summarization.
</bodyText>
<sectionHeader confidence="0.997449" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999856684210527">
Large video collections require content-based
information browsing, retrieval, extraction, and
summarization to ensure their value for tasks such
as real-time profiling and retrospective search.
Whereas image processing for video indexing
currently provides low level indeces such as visual
transitions and shot classification (Zhang et al.
1994), some research has investigated the use of
linguistic streams (e.g., closed captions, transcripts)
to provide keyword-based indexes to video. Story-
based segmentation remains illusive. For example,
traditional text tiling approaches often
undersegment broadcast news because of rapid
topic shifts (Mani et al. 1997). This paper takes a
corpus-based approach to this problem, building
linguistic models based on an analysis of a digital
collection of broadcast news, exploiting the
regularity utilized by humans in signaling topic
shifts to detect story segments.
</bodyText>
<sectionHeader confidence="0.98366" genericHeader="method">
2. Broadcast News Analysis
</sectionHeader>
<bodyText confidence="0.999821055555556">
Human communication is characterized by distinct
discourse structure (Grosz and Sidner 1986) which
is used for a variety of purposes including
managing interaction between participants,
mitigating limited attention, and signaling topic
shifts. In processing genre such as technical or
journalistic texts, programs can take advantage of
explicit discourse cues (e.g., &amp;quot;the first&amp;quot;, &amp;quot;the most
important&amp;quot;) to perform tasks such as summarization
(Paice 1981). Our initial inability to segment topics
in closed caption news text using thesaurus based
subject assessments (Liddy and Myaeng 1992)
motivated an investigation of explicit turn taking
signals (e.g., anchor to reporter handoff). We
analyzed programs (e.g., CNN PrimeNews) from an
over one year corpus of closed caption texts with the
intention of creating models of discourse and other
cues for segmentation.
</bodyText>
<figureCaption confidence="0.998382">
Figure 1. Closed Caption Challenges
</figureCaption>
<subsectionHeader confidence="0.551644">
(CNN Prime News, August 17, 1997)
</subsectionHeader>
<bodyText confidence="0.977207">
While human captioners employ standard cues to
signal discourse shifts in the closed caption stream
(e.g., &amp;quot;»&amp;quot; is used to signal a speaker shift whereas
&amp;quot;&gt;»&amp;quot; signals a subject change), these can be
erroneous, incomplete, or inconsistent. Figure 1
illustrates a typical excerpt from our corpus. Our
creation of a gold standard corpus of a variety of
broadcast sources indicates that transcription word
error rates range from 2% for pre-recorded programs
such as 60 Minutes news magazine to 20% for live
transcriptions (including errors of insertion,
deletion, and transposition). This noisy data
complicates robust story segmentation.
</bodyText>
<figure confidence="0.9991096">
a» TALKS BETWEEN REP SENTAT IVES FROM T TEAMSTERS UNION 15 UPS ARE
CONTINUING HERE I SHINGTON THE TWO SID ARE TRYING TO REAH A DEAL
THAT WOULD EN E COSTL I&apos; 13.0A,OLD STRIK THAT HAS CRIPPLED IFS AND
l/..3il.WroN;TairiztlirIlOrNrStOm:F:.PEOPLE FOR THE L TEST ON THOSE N lTIAT IONS
a&gt; GOOD EVENING, JEANNE THE CLOCK S STILL TICKI &apos;WE ARE NO
INTO THESE NONSTOP TALKS AND STILL NOOSE CAN L US WHET. HER&apos;SSRIDE
MILLION Da .sTEPWNE si,,ALcawalasail.......ITS TO
PRESIDENT
AS &apos;&apos;&apos;&apos;ECIrSIEAN EK RS TT?i DEAL, PS 1 0 DOING THE STFIVE 300
EXPLAINS I S NOT LKELY.TO HAPPEN -,I &apos; &amp;quot;C-P-RESP, T ..
qr6ERATRIKLE,S,1 VOLVNG THE TRANSPORTATION OF PEOPLE ARE RULED Elf CNE
WALKOUTS N THE PACKAGE SHIPPING INDUSTRY BY ANOTHER LETS
Omission
a a PRESIDENT CLINTON SAY THAT ALONE EXPLAINS HIS REFU
STOP THE UPS STAKE AS HE DID SD( MONTHS AGO WHEN
WERE WALKING OFF THE JON
ro s
AT VENE AND
iFXN PILOTS
EVA FEDERAL LAW WHICH GIVES THE SIDENT
a&gt; THE AIRLNE COMPANIES BECAUSE THEY TAKEAV SENESA REEN
ERVE
SLBSTANTIAL ECONOMIC DANGER OR EJOTHE COUNTRY THE UPS STRIKE
WITH THE TEAMSTERS IS NOT COVERED BY TB
Upcase
Segment
Discourse Cues Insertions
JEAM4 E ESERVE IN WASHING% LN OEN
COM PrIM•14•W • awn? to oo
Andww
</figure>
<page confidence="0.975397">
819
</page>
<subsectionHeader confidence="0.98405">
2.1 News Story Discourse Structure
</subsectionHeader>
<bodyText confidence="0.99207425">
Broadcast news has a prevalent structure with often
explicit cues to signal story shifts. For example,
analysis of the structure of ABC World News
Tonight indicates:
</bodyText>
<listItem confidence="0.999775">
• broadcasts start and end with the anchor
• reporter segments are preceded by an introductory
anchor segment and together they form a single story
• commercials serve as story boundaries
</listItem>
<bodyText confidence="0.990439857142857">
Similar but unique structure is also prevalent in
many other news programs such as CNN Prime
News (See Figure 1) or MS-NBC. For example,
the structure for the Jim Lehrer News Hour
provides not only segmentation information but
also content information for each segment. Thus,
the order of stories is consistently:
</bodyText>
<listItem confidence="0.999852625">
• preview of major stories of the day or in the broadcast
program
• sponsor messages
• summary of the day&apos;s news
(including some major stories)
• four to six major stories
• recap summary of the day&apos;s news
• sponsor messages
</listItem>
<bodyText confidence="0.9995738">
Recovering this structure would enable a user to
view the four minute opening summary, retrieve
daily news summaries, preview and retrieve major
stories, or browse a video table of contents, with or
without commercials.
</bodyText>
<subsectionHeader confidence="0.99984">
2.2 Discourse Cues and Named Entities
</subsectionHeader>
<bodyText confidence="0.9999065">
Manual and semi-automated analysis of our news
corpora reveals that regular cues are used to signal
these shifts in discourse, although this structure
varies dramatically from source to source. For
example, CNN discourse cues can be classified into
the following categories (examples from 8/18/97):
</bodyText>
<listItem confidence="0.982407363636364">
• Start of Broadcast
&apos;GOOD EVENING, I&apos;M KATHLEEN KENNEDY, SITTING
IN FOR JOIE CHEN.&apos;
• Anchor-to-Reporter Handoff
&apos;WE&apos;RE JOINED BY CNN&apos;S CHARLES ZEWE IN NEW
ORLEANS. CHARLES?
• Reporter-to-Anchor Handoff
&amp;quot;CHARLES ZEWE, CNN, NEW ORLEANS&amp;quot;
• Cataphoric Segment
&apos;&apos;STILL AHEAD ON PRIMENEWS&amp;quot;
• Broadcast End
</listItem>
<sectionHeader confidence="0.3134315" genericHeader="method">
THAT WRAPS UP THIS MONDAY EDITION OF
&amp;quot;PRIMENEWS&amp;quot;&amp;quot;
</sectionHeader>
<bodyText confidence="0.992725444444445">
The regularity of these discourse cues from
broadcast to broadcast provides an effective
foundation for discourse-based segmentation
routines. We have similarly discovered regular
discourse cues in other news programs. For
example, anchor/reporter and reporter/anchor
handoffs in CNN Prime News or ABC News and
other network programs are identified through
pattern matching of strings such as:
</bodyText>
<listItem confidence="0.999826">
• (word) (word) &amp;quot;, ABC NEWS&amp;quot;
• &amp;quot;ABC&apos;S CORRESPONDENT&amp;quot; (word) (word)
</listItem>
<bodyText confidence="0.9996389">
The pairs of words in parentheses correspond to the
reporter&apos;s first and last names. Combining the
handoffs with structural cues, such as knowing that
the first and last speaker in the program will be the
anchor, allow us differentiate anchor segments from
reporter segments. By preprocessing the closed
caption text with a part of speech tagger and named
entity detector (Aberdeen et at. 1995) retrained on
closed captions, we generalize search of text strings
to the following class of patterns:
</bodyText>
<listItem confidence="0.999859">
• (proper name) &amp;quot;, ABC NEWS&amp;quot;
• &amp;quot;ABC&apos;S CORRESPONDENT (proper name)
</listItem>
<sectionHeader confidence="0.789498" genericHeader="method">
3. Computational Implementation
</sectionHeader>
<bodyText confidence="0.999935769230769">
Our discourse cue story segmentor has been
implemented in the context of a multimedia (closed
captioned text, audio, video) analysis system for
web based broadcast news navigation. We employ a
finite state machine to represent discourse states
such as an anchor, reporter, or advertisting segment
(See Figure 2). We further enhance these with
multimedia cues (e.g. detected silence, black or logo
keyframes) and temporal knowledge (indicated as
time in Figure 2). For example, from statistical
analysis of CNN Prime News Programs, we know
that weather segments appear on average 18 minutes
after the start of the news.
</bodyText>
<page confidence="0.963303">
820
</page>
<figure confidence="0.997066972972973">
LogoBegte
Very Nett
Stan 17
Choose
Broadcast 1
Can Prime Nevr43 Wart For
roadcast Stan 2
4. Evaluation
Sacco
• IWPr491710714AA.
Story Start 6 ainle 30 End a
f to
Reporter
T. S &amp;quot; 7 ere 22
14111114° St III
Posabh
ii7A.4111441
Advert 13
Story bier
12
4;171&amp;quot;f
06*&amp;quot;.111111DEFAULT 114111111111111
DEPAEM
Atoll
000.01y
After Prune
Potable
Advert 15
SoleackB
Potable
Ead 18
OV,
lack
Bed SS 20
,&gt;.Pereon .Ptinte.BNA
Tiro 0
DEP IILE
</figure>
<bodyText confidence="0.99922075">
We evaluated segmentor performance by measuring
both the precision and recall of segment boundaries
compared to manual annotation of story boundaries
where:
</bodyText>
<listItem confidence="0.6879544">
# of correct segment tags
1. precision =
# of total segment tags
# of correct segment tags
2. Recall
</listItem>
<table confidence="0.9249696">
# of hand tags
Source Precision Recall
ABC World News 90 94
CNN Prime News 95 75
Jim Lehrer News Hour 77 52
</table>
<tableCaption confidence="0.994492">
Table 1. Segmentation Performance
</tableCaption>
<figure confidence="0.9646926">
&apos;Pane 90
Pante,Signon.lro Stan
rsorr.BNA r.
....&gt; Yarn e,Perton SNA
End 21
</figure>
<figureCaption confidence="0.999958">
Figure 2. Partial Time-Enhanced FSM
</figureCaption>
<bodyText confidence="0.975008111111111">
After segmentation, the user is presented with a
hierarchical navigation space of the news which
enables search and retrieval of segmented stories or
browsing stories by date, topic, named entity or
keyword (see Figure 3). This is MITRE&apos;s
Broadcast News Navigator
(hap://www.mitre.org/resources/centers/
advanced_info/g04f/bnnimmhomeexthtml).
Named Entities by Type Captions Story Summary
</bodyText>
<figureCaption confidence="0.983328">
Figure 3. Broadcast News Navigator
</figureCaption>
<bodyText confidence="0.999970692307692">
We leverage the story segments and extracted
named entities to select the sentence with the most
named entities to serve as a single sentence
summary of a given segment. Story structure is
also useful for multimedia summarization. For
example, we can select key frames or key words
from the substructure which will likely contain the
most meaningful content (e.g., an reporter segment
within an anchor segment).
Table 1 presents average precision and recall results
for multiple programs after applying generalized cue
patterns developed first for ABC as described in
Section 2.2. Recall degrades when porting these
same algorithms to different news programs (e.g.,
CNN, Jim Lehrer) given the genre differences as
described in Section 2.1.
Errors in story boundary detection include
erroneously splitting a single story segment into two
story segments, and merging two contiguous story
segments into a single story segment. Furthermore,
given our error-driven transformation based proper
name taggers operate at approximately 80%
precision and recall, this can adversely impact
discourse cue detections. Also, our preliminary
evaluation of speech transcription results in word
error rates of approximately 50%, which suggest
non captioned text is not yet feasible for this class of
segmentation.
We have just completed an empirical study (Merlino
and Maybury, forthcoming) with BNN users that
explores the optimal mixture of media elements
show in Figure 3 (e.g., keyframes, named entities,
topics) in terms of speed and accuracy of story
identification and comprehension tasks. Key
findings include that users perform better and prefer
mixed media presentations over just one media (e.g.,
named entities or topic lists), and they are quicker
and more accurate working from extracts and
summaries than from the source transcript or video.
</bodyText>
<figure confidence="0.919694666666667">
Video Date
Key Frame
Source
</figure>
<page confidence="0.990084">
821
</page>
<sectionHeader confidence="0.989887" genericHeader="conclusions">
6. Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999961578947368">
We have described and evaluated a news story
segmentation algorithm that detects news discourse
structure using discourse cues that exploit fixed
expressions and transformational-based, part of
speech and named entity taggers created using
error-driven learning. The implementation utilizes
a time-enhanced finite state automata that
represents discourse states and their expected
temporal occurance in a news broadcast based on
statistical analysis of the corpus. This provides an
important mechanism to enable topic tracking,
indeed we take the text from each segment an run
this through a commercial topic identification
routine an provide the user with a list of the top
classes associated with each story (See Figure 3).
The segmentor has been integrated into a system
(BNN) for content-based news access and has been
deployed in a corporate intranet and is currently
being evaluated for deployment in the US
government and a national broadcasting
corporation.
We have improved segmentation performance by
exploiting cues in audio and visual streams (e.g.,
speaker shifts, scene changes) (Maybury et al.
1997). To obtain a better indication of annotator
reliability and for comparative evaluation, we need
to measure interannotator agreement. Future
research includes investigating the relationship of
other linguistic properties, such as co-reference,
intonation contours, and lexical semantics
coherence to serve as a measure of cohesion that
might further support story segmentation. Finally,
we are currently evaluating in user studies which
mix of media elements (e.g., key frame, named
entities, key sentence) are most effective in
presenting story segments for different information
seeking tasks (e.g., story identification,
comprehension, correlation).
</bodyText>
<sectionHeader confidence="0.992153" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999526166666667">
Andy Merlino is the principal system developer of
BNN. The Alembic sub-system is the result of
efforts by MITRE&apos;s Language Processing Group
including Marc Vilain and John Aberdeen for part of
speech proper name taggers, and David Day for
training these on closed caption text.
</bodyText>
<sectionHeader confidence="0.99919" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999780487179487">
Aberdeen, J.; Burger, J.; Day, D.; Hirschman, L.;
Robinson, P. and Vilain, M. (1995) &amp;quot;Description of the
Alembic System Used for MUC-6&amp;quot;, Proceedings of the
Sixth Message Understanding Conference, Columbia,
MD, 6-8 November, 1995.
Brill, E. (1995) Transformation-based Error-Driven
Learning and Natural Language Processing: A Case
Study in Part of Speech Tagging. Computational
Linguistics, 21(4).
Grosz, B. J. and Sidner, C. July-September, (1986)
&amp;quot;Attention, Intentions, and the Structure of Discourse.&amp;quot;
Computational Linguistics 12(3):175-204.
Liddy, E. and Myaeng, S. (1992) &amp;quot;DR-LINK&apos;s
Linguistic-Conceptual Approach to Document
Detection&amp;quot;, Proceedings of the First Text Retrieval
Conference, 1992, NIST.
Mani, I., House, D., Maybury, M. and Green, M. (1997)
Towards Content-based Browsing of Broadcast News
Video. In Maybury, M. (ed.) Intelligent Multimedia
Information Retrieval, AAAI/MIT Press, 241-258.
Merlino, A. and Maybury, M. forthcoming. An
Empirical Study of the Optimal Presentation of
Multimedia Summaries of Broadcast News. In Mani, I.
and Maybury, M. (eds.) Automated Text
Summarization
Merlino, A., Morey, D. and Maybury, M. (1997)
&amp;quot;Broadcast News Navigation using Story Segments&amp;quot;,
Proceedings of the ACM International Multimedia
Conference, Seattle, WA, November 8-14, 381-391.
Paice, C. D. (1981) The Automatic Generation of
Literature Abstracts: An Approach Based on the
Identification of Self-Indicating Phrases. In Oddy, R.
N., Robertson, S. E. , van Rijsbergen, C. J., Williams,
P. W. (eds.) Information Retrieval Research. London:
Butterworths, 172-191.
Zhang, H. J.; Low, C. Y.; Smoliar, S. W. and Zhong, D.
(1995) Video Parsing, Retrieval, and Browsing: An
Integrated and Content-Based Solution. Proceedings of
ACM Multimedia 95. San Francisco, CA, p. 15-24.
</reference>
<page confidence="0.998039">
822
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.936337">
<title confidence="0.999809">Discourse Cues for Broadcast News Segmentation</title>
<author confidence="0.999997">Mark T Maybury</author>
<affiliation confidence="0.999649">The MITRE Corporation</affiliation>
<address confidence="0.9998225">202 Burlington Road Bedford, MA 01730, USA</address>
<email confidence="0.994755">maybury@mitre.org</email>
<abstract confidence="0.993669727272727">This paper describes the design and application of time-enhanced, finite state models of discourse cues to the automated segmentation of broadcast news. We describe our analysis of a broadcast news corpus, the design of a discourse cue based story segmentor that builds upon information extraction techniques, and finally its computational implementation and evaluation in the Broadcast News Navigator (BNN) to support video news browsing, retrieval, and summarization.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Aberdeen</author>
<author>J Burger</author>
<author>D Day</author>
<author>L Hirschman</author>
<author>P Robinson</author>
<author>M Vilain</author>
</authors>
<title>Description of the Alembic System Used for MUC-6&amp;quot;,</title>
<date>1995</date>
<booktitle>Proceedings of the Sixth Message Understanding Conference,</booktitle>
<pages>6--8</pages>
<location>Columbia, MD,</location>
<marker>Aberdeen, Burger, Day, Hirschman, Robinson, Vilain, 1995</marker>
<rawString>Aberdeen, J.; Burger, J.; Day, D.; Hirschman, L.; Robinson, P. and Vilain, M. (1995) &amp;quot;Description of the Alembic System Used for MUC-6&amp;quot;, Proceedings of the Sixth Message Understanding Conference, Columbia, MD, 6-8 November, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Transformation-based Error-Driven Learning and Natural Language Processing: A Case Study in Part of Speech Tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<marker>Brill, 1995</marker>
<rawString>Brill, E. (1995) Transformation-based Error-Driven Learning and Natural Language Processing: A Case Study in Part of Speech Tagging. Computational Linguistics, 21(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C July-September Sidner</author>
</authors>
<title>Attention, Intentions, and the Structure of Discourse.&amp;quot;</title>
<date>1986</date>
<journal>Computational Linguistics</journal>
<pages>12--3</pages>
<contexts>
<context position="1669" citStr="Grosz and Sidner 1986" startWordPosition="228" endWordPosition="231">ms (e.g., closed captions, transcripts) to provide keyword-based indexes to video. Storybased segmentation remains illusive. For example, traditional text tiling approaches often undersegment broadcast news because of rapid topic shifts (Mani et al. 1997). This paper takes a corpus-based approach to this problem, building linguistic models based on an analysis of a digital collection of broadcast news, exploiting the regularity utilized by humans in signaling topic shifts to detect story segments. 2. Broadcast News Analysis Human communication is characterized by distinct discourse structure (Grosz and Sidner 1986) which is used for a variety of purposes including managing interaction between participants, mitigating limited attention, and signaling topic shifts. In processing genre such as technical or journalistic texts, programs can take advantage of explicit discourse cues (e.g., &amp;quot;the first&amp;quot;, &amp;quot;the most important&amp;quot;) to perform tasks such as summarization (Paice 1981). Our initial inability to segment topics in closed caption news text using thesaurus based subject assessments (Liddy and Myaeng 1992) motivated an investigation of explicit turn taking signals (e.g., anchor to reporter handoff). We analy</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, B. J. and Sidner, C. July-September, (1986) &amp;quot;Attention, Intentions, and the Structure of Discourse.&amp;quot; Computational Linguistics 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Liddy</author>
<author>S Myaeng</author>
</authors>
<title>DR-LINK&apos;s Linguistic-Conceptual Approach to Document Detection&amp;quot;,</title>
<date>1992</date>
<booktitle>Proceedings of the First Text Retrieval Conference,</booktitle>
<pages>NIST.</pages>
<contexts>
<context position="2165" citStr="Liddy and Myaeng 1992" startWordPosition="299" endWordPosition="302">ments. 2. Broadcast News Analysis Human communication is characterized by distinct discourse structure (Grosz and Sidner 1986) which is used for a variety of purposes including managing interaction between participants, mitigating limited attention, and signaling topic shifts. In processing genre such as technical or journalistic texts, programs can take advantage of explicit discourse cues (e.g., &amp;quot;the first&amp;quot;, &amp;quot;the most important&amp;quot;) to perform tasks such as summarization (Paice 1981). Our initial inability to segment topics in closed caption news text using thesaurus based subject assessments (Liddy and Myaeng 1992) motivated an investigation of explicit turn taking signals (e.g., anchor to reporter handoff). We analyzed programs (e.g., CNN PrimeNews) from an over one year corpus of closed caption texts with the intention of creating models of discourse and other cues for segmentation. Figure 1. Closed Caption Challenges (CNN Prime News, August 17, 1997) While human captioners employ standard cues to signal discourse shifts in the closed caption stream (e.g., &amp;quot;»&amp;quot; is used to signal a speaker shift whereas &amp;quot;&gt;»&amp;quot; signals a subject change), these can be erroneous, incomplete, or inconsistent. Figure 1 illustr</context>
</contexts>
<marker>Liddy, Myaeng, 1992</marker>
<rawString>Liddy, E. and Myaeng, S. (1992) &amp;quot;DR-LINK&apos;s Linguistic-Conceptual Approach to Document Detection&amp;quot;, Proceedings of the First Text Retrieval Conference, 1992, NIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>D House</author>
<author>M Maybury</author>
<author>M Green</author>
</authors>
<title>Towards Content-based Browsing of Broadcast News Video.</title>
<date>1997</date>
<pages>241--258</pages>
<editor>In Maybury, M. (ed.)</editor>
<publisher>AAAI/MIT Press,</publisher>
<contexts>
<context position="1302" citStr="Mani et al. 1997" startWordPosition="175" endWordPosition="178">d information browsing, retrieval, extraction, and summarization to ensure their value for tasks such as real-time profiling and retrospective search. Whereas image processing for video indexing currently provides low level indeces such as visual transitions and shot classification (Zhang et al. 1994), some research has investigated the use of linguistic streams (e.g., closed captions, transcripts) to provide keyword-based indexes to video. Storybased segmentation remains illusive. For example, traditional text tiling approaches often undersegment broadcast news because of rapid topic shifts (Mani et al. 1997). This paper takes a corpus-based approach to this problem, building linguistic models based on an analysis of a digital collection of broadcast news, exploiting the regularity utilized by humans in signaling topic shifts to detect story segments. 2. Broadcast News Analysis Human communication is characterized by distinct discourse structure (Grosz and Sidner 1986) which is used for a variety of purposes including managing interaction between participants, mitigating limited attention, and signaling topic shifts. In processing genre such as technical or journalistic texts, programs can take ad</context>
</contexts>
<marker>Mani, House, Maybury, Green, 1997</marker>
<rawString>Mani, I., House, D., Maybury, M. and Green, M. (1997) Towards Content-based Browsing of Broadcast News Video. In Maybury, M. (ed.) Intelligent Multimedia Information Retrieval, AAAI/MIT Press, 241-258.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Merlino</author>
<author>M forthcoming Maybury</author>
</authors>
<title>An Empirical Study of the Optimal Presentation of Multimedia Summaries of Broadcast News.</title>
<booktitle>Automated Text Summarization</booktitle>
<editor>In Mani, I. and Maybury, M. (eds.)</editor>
<marker>Merlino, Maybury, </marker>
<rawString>Merlino, A. and Maybury, M. forthcoming. An Empirical Study of the Optimal Presentation of Multimedia Summaries of Broadcast News. In Mani, I. and Maybury, M. (eds.) Automated Text Summarization</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Merlino</author>
<author>D Morey</author>
<author>M Maybury</author>
</authors>
<title>Broadcast News Navigation using Story Segments&amp;quot;,</title>
<date>1997</date>
<booktitle>Proceedings of the ACM International Multimedia Conference,</booktitle>
<pages>381--391</pages>
<location>Seattle, WA,</location>
<marker>Merlino, Morey, Maybury, 1997</marker>
<rawString>Merlino, A., Morey, D. and Maybury, M. (1997) &amp;quot;Broadcast News Navigation using Story Segments&amp;quot;, Proceedings of the ACM International Multimedia Conference, Seattle, WA, November 8-14, 381-391.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Paice</author>
</authors>
<title>The Automatic Generation of Literature Abstracts: An Approach Based on the Identification of Self-Indicating Phrases.</title>
<date>1981</date>
<booktitle>Information Retrieval Research.</booktitle>
<pages>172--191</pages>
<editor>In Oddy, R. N., Robertson, S. E. , van Rijsbergen, C. J., Williams, P. W. (eds.)</editor>
<publisher>Butterworths,</publisher>
<location>London:</location>
<contexts>
<context position="2030" citStr="Paice 1981" startWordPosition="281" endWordPosition="282">tal collection of broadcast news, exploiting the regularity utilized by humans in signaling topic shifts to detect story segments. 2. Broadcast News Analysis Human communication is characterized by distinct discourse structure (Grosz and Sidner 1986) which is used for a variety of purposes including managing interaction between participants, mitigating limited attention, and signaling topic shifts. In processing genre such as technical or journalistic texts, programs can take advantage of explicit discourse cues (e.g., &amp;quot;the first&amp;quot;, &amp;quot;the most important&amp;quot;) to perform tasks such as summarization (Paice 1981). Our initial inability to segment topics in closed caption news text using thesaurus based subject assessments (Liddy and Myaeng 1992) motivated an investigation of explicit turn taking signals (e.g., anchor to reporter handoff). We analyzed programs (e.g., CNN PrimeNews) from an over one year corpus of closed caption texts with the intention of creating models of discourse and other cues for segmentation. Figure 1. Closed Caption Challenges (CNN Prime News, August 17, 1997) While human captioners employ standard cues to signal discourse shifts in the closed caption stream (e.g., &amp;quot;»&amp;quot; is used </context>
</contexts>
<marker>Paice, 1981</marker>
<rawString>Paice, C. D. (1981) The Automatic Generation of Literature Abstracts: An Approach Based on the Identification of Self-Indicating Phrases. In Oddy, R. N., Robertson, S. E. , van Rijsbergen, C. J., Williams, P. W. (eds.) Information Retrieval Research. London: Butterworths, 172-191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H J Zhang</author>
<author>C Y Low</author>
<author>S W Smoliar</author>
<author>D Zhong</author>
</authors>
<title>Video Parsing, Retrieval, and Browsing: An Integrated and Content-Based Solution.</title>
<date>1995</date>
<booktitle>Proceedings of ACM Multimedia 95.</booktitle>
<pages>15--24</pages>
<location>San Francisco, CA,</location>
<marker>Zhang, Low, Smoliar, Zhong, 1995</marker>
<rawString>Zhang, H. J.; Low, C. Y.; Smoliar, S. W. and Zhong, D. (1995) Video Parsing, Retrieval, and Browsing: An Integrated and Content-Based Solution. Proceedings of ACM Multimedia 95. San Francisco, CA, p. 15-24.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>