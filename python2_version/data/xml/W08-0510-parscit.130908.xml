<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.984466">
Design of the Moses Decoder for Statistical Machine Translation
</title>
<author confidence="0.995987">
Hieu Hoang
</author>
<affiliation confidence="0.994395">
University of Edinburgh
</affiliation>
<email confidence="0.983063">
h.hoang@sms.ed.ac.uk
</email>
<author confidence="0.984339">
Philipp Koehn
</author>
<affiliation confidence="0.987282">
University of Edinburgh
</affiliation>
<email confidence="0.988913">
pkoehn@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.993688" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999550769230769">
We present a description of the implemen-
tation of the open source decoder for statis-
tical machine translation which has become
popular with many researchers in SMT re-
search. The goal of the project is to create
an open, high quality phrase-based decoder
which can reduce the time and barrier to
entry for researchers wishing to do SMT
research. We discuss the major design ob-
jective for the Moses decoder, its perform-
ance relative to other SMT decoders, and
the steps we are taking to ensure that its
success will continue.
</bodyText>
<sectionHeader confidence="0.987902" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.996534196428572">
Phrase-based translation has been one of the
major advances in statistical machine translation
(Brown et al. 1990) in recent years and is currently
one of the techniques which can claim to be state-
of-the-art in machine translation. Phrase-based
models are a development of the word based mod-
els as exemplified by the (Brown et al. 1990). In
phrase-based translation, contiguous segments of
words in the input sentence are mapped to contigu-
ous segments of words in the output sentence.
In SMT, we are given a source language sen-
tence, s, which is to be translated into a target lan-
guage sentence, t. The goal of machine translation
is to find the translation, tˆ, which is defined as:
tˆ = arg maxt p(t  |s)
where p(t  |s) is the probability model. The argmax
implies a search for the best translation tˆ in the
space of possible translations t. This search is the
task of the decoder, which we will concentrate on
in this paper.
There have been numerous implementations of
phrase-based decoders for SMT prior to our work.
Early systems such as the Alignment Template
System (ATS) (Och and Ney 2004) and Pharaoh
(Koehn 2004) were widely used and accepted by
the research community. ATS is perhaps the cross-
over system, in that word classes were translated as
phrases but the surface words were translated word
by word. Pharaoh substituted the word classes with
surface words, thereby discarding the use of word
classes in decoding altogether.
There has been other phrase-based decoders
such as PORTAGE (Sadat et al. 2005), Phramer
(Olteanu et al. 2006), the MITLL/AFRL system
(Shen et al. 2005), ITC-irst (Bertoldi et al. 2004),
Ramses/Mood (Patry et al. 2006) to name but a
few. Other researchers such as (Kumar and Byrne
2003) have also used weighted finite state trans-
ducers but they have more difficulty modeling re-
ordering.
Many early systems came with restrictive li-
censes; ATS has never been publicly released,
Pharaoh was released in 2003 as a pre-compiled
binary with documentation. This severely limited
the extent to which other researchers can study and
enhance the decoder. Without access to the de-
coder source code research was generally restricted
to altering the input, augmenting it with extra in-
formation, or modifying the output or re-ranking
the n-best list output.
The main contribution of this paper is to show
how we have created an extensible decoder, has
acceptable run time performance compared to
similar systems, and the ease of use and develop-
ment that has made it the preferred choice for re-
searchers looking for a phrase-based SMT decoder.
</bodyText>
<page confidence="0.982362">
58
</page>
<subsubsectionHeader confidence="0.471894">
Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 58–65,
</subsubsectionHeader>
<page confidence="0.441119">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.999773692307692">
As an indication of the take-up of the Moses
toolkit, out of over 20 competing teams at the re-
cent IWSLT 2007 conference1, half used Moses.
As an indication of the extensibility of the de-
coder, there are currently four language model im-
plementations which has been integrated with the
decoder by various researchers. In addition, the
framework exists to integrate language models,
such as those described in (Bilmes and Kirchhoff
2003), which takes advantage of the factored rep-
resentation within Moses.
It is noted that Mood/Ramses also supports
multiple LM implementations, an internally devel-
oped language model, in additional to SRILM, to
overcome the latter’s licensing restrictions.
In addition, there are two built-in phrase table
implementations, one which loads all data into
memory for fast decoding, and a binary phrase ta-
ble as described in (Zens and Ney 2007) which
loads on demand to conserve memory usage.
The Moses decoder has the ability to accept
simple sentence input, confusion network or lattice
networks, in common with SMT decoders such as
the MITLL/AFRL or ITC-irst systems. The de-
coder also produces diverse types of output, rang-
ing from 1-best, n-best lists and word lattices.
</bodyText>
<sectionHeader confidence="0.647517" genericHeader="introduction">
2 Comparison with other projects
</sectionHeader>
<bodyText confidence="0.9998532">
The Moses decoder is designed within a strict
modular and object-oriented framework for easy
maintainability and extensibility.
In designing the decoder, we modeled the soft-
ware design methodology and aims on some re-
search-oriented software libraries outside of the
SMT and NLP field which is open source, written
in C++, have a large and diverse user-base, have
succeeded in becoming the industry norm in their
field.
Specifically, we modeled the software on the
CGAL library (Fabri et al. 2000), used in computa-
tional geometry, and DCMTK (Eichelberg et al.
2004) library used in medical imaging. We believe
they set good examples of the standards that we
should follow.
However, there are differences between our pro-
ject and CGAL or DCMTK.
The first difference is project size, for example,
whereas CGAL consists of over 500,000 lines of
</bodyText>
<footnote confidence="0.668451">
1 http://iwslt07.oitc.it/menu/program.html
</footnote>
<bodyText confidence="0.997063102040816">
code and multiple libraries and example program,
the Moses decoder consists of 20,000 lines in 2
libraries. The difference is scale makes implement-
ing some steps in the development life cycle im-
practical or unnecessary. For example, functional-
ity specification before implementation was de-
scribed for CGAL and is typical of large projects
but would have been cumbersome for Moses.
Secondly, the aims of Moses and these projects
are different. The goal of the CGAL project is to
‘make...computational geometry available for in-
dustrial application’2.
Both CGAL and DCMTK are used extensively
in commercial applications. Therefore, issues such
robustness, cross-platform compatibility and ease-
of-use are predominant for these projects.
Commercialization is not an aim of the Moses
project but we believe these issues are still as im-
portant as they affect the usability and uptake of
the system. Therefore, the Moses decoder was built
to address these issues without compromising the
academic priorities of the project.
Thirdly, the correct implementation is easier to
decide in libraries such as CGAL as the algorithms
are closely specified by the mathematical specifi-
cation, therefore, testing and specification writing
is more prevalent and easier than in Moses. For
DCMTK, the medical imaging standards and pro-
tocols offers a clear guide for implementation. By
contrast, the function of an SMT decoder is search
for which there are no correct implementation, we
can only measure its performance relative to previ-
ous versions and other similar decoders.
These differences are minor compared to the
similarities Moses has to CGAL and DCMTK, and
indeed, to any well developed software project.
Design goals such as robustness, flexibility, ease of
use and efficiency are commonality that we share
and which we will discuss in more detail in the
next section.
As a contrast to CGAL and DCMTK whose de-
sign we would like to emulate, we also looked at a
project within the NLP field which contains certain
aspect in the design we would like to avoid.
GIZA++ (Och and Ney 2003) is a very popular
system within SMT for creating word alignment
from parallel corpus, in fact, the Moses training
scripts uses it. The system was release under the
GPL open source license. However, its lack of
</bodyText>
<footnote confidence="0.85353">
2 http://cordis.europa.eu/esprit/src/21957.htm
</footnote>
<page confidence="0.998127">
59
</page>
<bodyText confidence="0.999980714285714">
clear design, documentation and obscure coding
style makes it difficult for other researcher to con-
tribute or extend the system. For a long time, it
couldn’t even be compiled on modern GCC com-
pilers. Other systems which seeks to improve word
alignment and segmentation, such as MTTK (Deng
et al. 2006), have been created to replace GIZA++.
</bodyText>
<sectionHeader confidence="0.992833" genericHeader="method">
3 Design Goals
</sectionHeader>
<bodyText confidence="0.999965">
We decided to develop the Moses decoder as a
C++ library.
We steered clear of scripting languages for per-
formance reasons and the fact they often offer even
less in the way of cross-platform compatibility.
Java was also avoided for performance reasons but
it’s rich library and multi-platform support would
have been useful.
We note that Hiero (Chiang 2005) is written in a
scripting language with performance critical com-
ponents rewritten in a compiled language. This is
not the approach we considered as we believed it
would have raised the complexity and reduce reli-
ability of the project having to develop (and debug)
in two languages and managing the interface be-
tween them. We also note that the LinearB and
Phramer decoders are implemented in Java and
have reported significantly worse run time speeds,
(Olteanu et al. 2006).
C++ can be inelegant and difficult for inexperi-
enced developers but using other object oriented
language such as Smalltalk or C# was out of the
question as they lack acceptance within the MT
research community.
</bodyText>
<subsectionHeader confidence="0.99974">
3.1 Comparable Performance
</subsectionHeader>
<bodyText confidence="0.999902105263158">
The Pharaoh decoder (Koehn 2004) represented
the state-of-the-art in phrase-based decoders prior
to the introduction of Moses. Moses was designed
to supersede Pharaoh in performance and function-
ality. Moses was used as the basis for the JHU
Workshop (Koehn et al. 2006) on Factored Ma-
chine Translation where it was extensively en-
hanced; we capitalized on the experience of col-
leagues at the workshop and used Pharaoh as the
baseline during development to ensure that we ob-
tain comparable performance. Table 1 shows the
comparison of the translation performance of Phar-
aoh and Moses for a typical decoding of 2000 sen-
tence trained on the news-commentary corpus3. We
also include Phramer as an example of a Java-
based decoder. Due to improvements in the search
algorithm, Moses can slightly outperform Pharaoh
on most tasks, which was confirmed by (Shen et al.
2007).
</bodyText>
<tableCaption confidence="0.996168">
Table 1 Comparison with pharaoh &amp; Phramer for a
typical fr-en translation of 2000 sentences
</tableCaption>
<table confidence="0.998866444444445">
Time Peak BLEU
taken memory
usage
Pharaoh 99min 46MB 19.57
Moses 69min 154MB 19.57
Moses, with load 102min 239MB 19.57
on-demand PT &amp;
LM
Phramer 649min 1218MB 19.44
</table>
<bodyText confidence="0.990727">
In addition, most of the functionality of Pharaoh
has been replicated.
</bodyText>
<subsectionHeader confidence="0.999887">
3.2 Integration of Word-Level Factors
</subsectionHeader>
<bodyText confidence="0.999972529411765">
The Moses decoder isn’t purely a clone of Phar-
aoh, it was created to conduct research into word-
level factors in phrase-base MT. Whereas tradi-
tional, non-factored SMT typically deals only with
the surface form of words, factored translation
models augments different factors, such as POS
tags or lemma, into source and target sentences to
improve translation. This transforms the represen-
tation of a word from a string to a vector of strings,
and a phrase or sentence from a sequence of words
to a sequence of vectors. Such a change to the ba-
sic data structure of a decoder propagated through-
out the rest of the system, therefore, it was simpler
to build the Moses decoder from scratch rather
than extend an existing decoder such as Pharaoh.
Some research into factored machine translation
has been published by (Koehn and Hoang 2007).
</bodyText>
<subsectionHeader confidence="0.994976">
3.3 Flexibility
</subsectionHeader>
<bodyText confidence="0.999571666666667">
Flexibility is an important software design goal
which will enable researchers to extend the use of
the Moses decoders to tasks that were not origi-
nally envisioned.
Following (Fabri et al. 2000), we identify four
sub-issues which affects flexibility:
</bodyText>
<footnote confidence="0.57752">
i. Modularity
3 http://www.statmt.org/wmt07/shared-task.html
</footnote>
<page confidence="0.873275">
60
</page>
<figure confidence="0.503302666666667">
ii. Adaptability
iii. Extensibility
iv. Openness
</figure>
<subsectionHeader confidence="0.966265">
3.4 Modularity
</subsectionHeader>
<bodyText confidence="0.999620125">
Firstly, software modularity enables developers
to work on one component of the decoder without
affecting other components. A modular design re-
duces the learning curve for developers by shield-
ing them from having to understand the entire sys-
tem if they are only developing a specific part.
Modularity also assists in the re-using of com-
ponents by separating the implementation details
from the module interface.
Moses takes advantage of C++ support for ob-
ject-oriented and generic programming to enable
modularity.
In keeping with the extensible design of CGAL
and DCMTK, the core of the decoder is compiled
as a static library which can interact with other
components through a well-defined API. The sim-
ple application which currently comes with the
decoder enables users to use the system via the
command line and also provides an example of the
API.
Therefore, the current typical compilation of the
decoder would combine the libraries from
IRSTLM, SRILM, Moses, and moses-cmd to cre-
ate a binary executable.
</bodyText>
<figureCaption confidence="0.929632">
Figure 1 Project Dependencies
</figureCaption>
<bodyText confidence="0.998775428571428">
Any of these libraries can be dropped or re-
placed with other components with the same API.
We detail some examples of the object-oriented
design of Moses below.
The input into the decoder can be one of three
types: a simple string (sentence), a confusion net-
work or a lattice network, Figure 2.
</bodyText>
<figureCaption confidence="0.938025">
Figure 2 Input Types
</figureCaption>
<bodyText confidence="0.9991908">
Language models are abstracted to enable different
implementations to be used and provide a frame-
work for more complex models such as factored
LM and the Bloom filter language model (Talbot
and Osborne 2007). Similarly, phrase tables are
abstracted to provide support for multiple imple-
mentations.
Each component model which contributes to the
log-linear hypothesis score inherits from the
ScoreProducer base class, Figure 3.
</bodyText>
<figureCaption confidence="0.631778">
Figure 3 Score Producer
</figureCaption>
<bodyText confidence="0.834246285714286">
The Moses library provide a simple API whose
main entry point is the class
Manager
This class is instantiated in the client application,
moses-cmd in our case. Each input is decoded by
calling the class method below:
ProcessSentence()
</bodyText>
<subsectionHeader confidence="0.898508">
3.5 Adaptability
</subsectionHeader>
<bodyText confidence="0.991099">
Phrase-based SMT is a fast moving research
field where virtually all aspects of the theory are
</bodyText>
<figure confidence="0.81025025">
SRILM IRSTLM
moses-
cmd
moses
</figure>
<page confidence="0.993052">
61
</page>
<bodyText confidence="0.99551178125">
still being explored and implementations can be
improved. The Moses decoder has to be amenable
to researchers to adapt any component of the de-
coder in ways that perhaps wasn’t foreseen in the
original implementation.
Certainly, modularity plays an important part
in this but it can also have the opposite effect of
allowing obtuse or badly written implementation to
hide behind the API, reducing the ability for re-
searchers to question, investigate or extend. As a
voluntary project, there is limited power to enforce
good implementation and it would be difficult not
to accept added functionality.
However, we use coding standards and designs
during the development of the decoder that we
hope makes the task of working with Moses easier
for developers, and that they will continue to use
those standards to uphold the clarity of the code.
These coding standards include:
i. strict object-oriented design
ii. descriptive variable, class, object and
function names
iii. consistent indentation
iv. use of STL containers
v. implementation of STL-compatible it-
erators for internal container classes.
The source code for the Moses decoder has con-
tributions from a number of developers in the last
two years, Figure 4, including four developers who
have made significant contributions but were not in
the original JHU Workshop. However, code clarity
has, by-and-large, remained intact.
</bodyText>
<figureCaption confidence="0.829271">
Figure 4 Code committed
</figureCaption>
<bodyText confidence="0.998031580645161">
We do not know how the decoder will be
changed in future, nor do we know where and by
whom it will be used. Moses is first and foremost
an academic project but that doesn’t exclude its use
in commercial applications.
We also believe that it will be useful as a teach-
ing tool for computational linguists, machine trans-
lation researchers or general computer science stu-
dents. It is important with such a diverse potential
user base, with widely varying degrees of C++ and
programming experience, that we make the devel-
opment and use of Moses as easy as possible,
without imposing a significant burden on advanced
users.
We would like to lower the learning curve by
letting users use Moses in an environment and
tools where they are most comfortable with. There-
fore, the Moses decoder is operating system and
compiler neutral. It is known to run on Windows
(natively, or with Cygwin), Linux 32 and 64 bits,
Mac OSX and OpenBSD. It is known to be com-
pileable with modern gcc compilers, Visual Stu-
dio.net, Intel C++ for both Linux and Windows.
We encourage the use of modern graphical inte-
grated development environments (IDE) for Moses
and include project files for Visual Studio, Eclipse
and XCode, in addition to conventional makefiles.
We note that almost half of the source code
downloads for the Moses toolkit from Sourceforge
are for the non-Unix version, and that 58% of the
visitors to the Moses website uses Windows,
</bodyText>
<figureCaption confidence="0.8599455">
Figure 5.
Figure 5 OS of Moses website visitors
</figureCaption>
<bodyText confidence="0.9998415">
This heterogeneous approach allows developers
who have previously been excluded to participate
within the SMT community and strengthens the
decoder by allowing people of different back-
grounds to apply their skills. This is of particular
concern to us as we are attempting to integrate lin-
</bodyText>
<figure confidence="0.991879">
%age of code commited
50%
40%
30%
20%
70%
60%
10%
0%
Window s
Linux
Mac
Other
</figure>
<page confidence="0.99465">
62
</page>
<bodyText confidence="0.9998360625">
guistic information into machine translation with
factored decoding.
It also enables best-of-breed tools to be bought
to the development of the decoder, regardless of
platform. For example, we use both open source
and commercial tools on Linux and Windows to
track down memory issues, as well as performance
profilers. This greatly enhances the efficiency of
development and the reliability of the decoder.
Other NLP libraries, such as SRILM (Stolcke
2002) can be compiled and executed under multi-
ple platforms but its development are very much
Unix-centric so requires porting tools for non-Unix
platforms. We believe the platform and compiler
agnostic approach is unique for a major open
source C++ project within recent NLP history.
</bodyText>
<subsectionHeader confidence="0.989627">
3.6 Openness
</subsectionHeader>
<bodyText confidence="0.999888322580645">
An important reason for initiating the Moses
project was the need to create a competitive de-
coder which could be extended with factors, as
well as other advances in phrase-based machine
translation. It is open source to enable other re-
searchers to extend a state-of-the-art decoder with-
out having to recreate what we have already built.
The decoder was improved at the JHU Work-
shop by a number of researchers so it needed to be
flexible from the beginning. From this experience,
we realize that releasing the source code is not
enough. The decoder must be written and struc-
tured in a clear way to enable other researchers to
contribute to the project.
Aside from the legalese of releasing the source
code under an open source license, we believe that
open source also means the source code is clear
and accessible to allow others to examine, critique
and contribute. Coding standards aimed at source
code clarity and support for modern tools backs
this goal.
Documentation of the algorithms used, and of
the source code are also essential to allow others to
understand the details of the decoder. Every class
and function in the Moses decoder is commented
in a Doxygen compatible format, HTML docu-
ments and figures, such as those in Figure 2 and
Figure 3, are generated automatically from these
comments and accessible via the Web4.
Development is done through a source control
system and all code changes are open to inspec-
</bodyText>
<footnote confidence="0.549779">
4 http://www.statmt.org/moses/html/
</footnote>
<bodyText confidence="0.999957161290323">
tion. We encourage and enable all developers to
use and extend Moses and feed back improve-
ments. However, to ensure that the performance of
the decoder is maintained and that changes to the
decoder doesn’t break existing setups, we maintain
certain controls over the commit process.
There is a regression test suite which should be
passed before any code can be committed to ensure
that unintended divergence haven’t crept in. A
framework exists for creation of regression tests,
developers who add new functionality to the de-
coder are encouraged to create additional tests to
ensure that their functionality will work in future.
However, no amount of automated testing can
be exhaustive. New committers are subject to peer
review by a more experience contributor before the
code is committed, and before the contributor is
granted write access to the source control system.
Also, code commits are monitored via email notifi-
cations to a public mailing list.
These measures add a little overhead to the de-
velopment process this is necessary to maintain the
quality of the system and assure to users and de-
velopers.
We have benefited from the examples of sound
software engineering principles set by the CGAL
and DCMTK project and hope that we will emulate
their success by bringing these engineering princi-
ples into NLP. In contrast to the ‘abandonware’
status of GIZA++, both CGAL and DCMTK are
still being developed.
</bodyText>
<sectionHeader confidence="0.927023" genericHeader="method">
4 Supporting Infrastructure
</sectionHeader>
<bodyText confidence="0.9716735">
Other factors have contributed to the wide adop-
tion of Moses.
</bodyText>
<subsectionHeader confidence="0.999194">
4.1 ‘One-Stop Shop’ for Phrase-Based SMT
</subsectionHeader>
<bodyText confidence="0.998881846153846">
The Moses project encompasses the decoder and
many of the other components necessary to create
a translation system which were previously avail-
able separately. These include scripts for creating
alignments from a parallel corpus, creating phrase
tables and language models, binarizing phrase ta-
bles, scripts for weight optimization using MERT
(Och 2003), and testing scripts.
Steps such as MERT and testing which are CPU
intensive have been re-engineered to run in parallel
using Sun Grid Engine.
All scripts have also been extended for factored
translation.
</bodyText>
<page confidence="0.997259">
63
</page>
<subsectionHeader confidence="0.991436">
4.2 Ongoing support
</subsectionHeader>
<bodyText confidence="0.999754416666667">
We assist in the adoption of Moses by offering
ongoing support to users and developers through
the support mailing list5 . Questions relating to
Moses, phrase-based translation or machine trans-
lation in general are often asked, and usually an-
swered. The archived emails are publicly available
and searchable, and have become an important
knowledge source for the community.
The mailing list popularity has been steadily in-
creasing since its inception, Figure 6, and is now
the most popular mailing list for machine transla-
tion, based on volume.
</bodyText>
<figure confidence="0.992373">
160
140
120
100
80
60
40
20
0
</figure>
<figureCaption confidence="0.990595">
Figure 6 Emails to Moses support mailing list
</figureCaption>
<sectionHeader confidence="0.998933" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.99990735">
There has been some important developments in
phrase-based translation in recent years, including
the hierarchical phrase-based model as described in
(Chiang 2005). Research have also been made into
alternatives to the current log-linear scoring model
such as discriminative models with millions of fea-
tures (Liang et al. 2006), or kernel based models
(Wang et al. 2007).
From a software engineering point of view,
these improvements would require fundamental
changes to the structure if they were to be imple-
mented into Moses.
We are also interested in seeing the Moses de-
coder employed in search tasks outside of machine
translation; Moses has been used for OCR correc-
tion, recasing, and transliteration.
Other improvements such as smaller, faster,
more efficient phrase tables are also welcomed.
Lastly, we would like to see the training and
tuning scripts re-engineered to the same modular
</bodyText>
<sectionHeader confidence="0.847349" genericHeader="method">
5 moses-support@mit.edu
</sectionHeader>
<bodyText confidence="0.9997902">
design as the decoder. The future direction of the
Moses decoder requires even more complex mod-
els which are already stretching the current script
implementation to the limit of adaptability and re-
liability.
</bodyText>
<sectionHeader confidence="0.998614" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999969625">
We have applied the sound software engineering
principles and design to the implementation of the
Moses decoder which has enabled other research-
ers to use and extend its functionality. We believe
this has been a major factor for the widespread
adoption of Moses within the SMT community.
We hope that the design of the decoder will enable
it to maintain it leading edge status into the future.
</bodyText>
<sectionHeader confidence="0.996935" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999284166666667">
This work was supported in part under the
GALE program of the Defense Advanced Re-
search Projects Agency, Contract No. HR0011-06-
C-0022 and in part under the EuroMatrix project
funded by the European Commission (6th Frame-
work Programme.
</bodyText>
<sectionHeader confidence="0.998165" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9996083">
Bertoldi, N., R. Cattoni, et al. (2004). The ITC-irst Sta-
tistical Machine Translation System for IWSLT-2004.
IWSLT, Kyoto, Japan.
Bilmes, J. A. and K. Kirchhoff (2003). Factored lan-
guage models and Generalized Parallel Backoff.
HLT/NACCL.
Brown, P. F., J. Cocke, et al. (1990). &amp;quot;A statistical ap-
proach to machine translation.&amp;quot;
Chiang, D. (2005). A hierarchical phrase-based model
for statistical machine translation. ACL.
Deng, Y., S. Kumar, et al. (2006). &amp;quot;Segmentation and
alignment of parallel text for statistical machine transla-
tion.&amp;quot; Natural Language Engineering.
Eichelberg, M., J. Riesmeier, et al. (2004). &amp;quot;Ten years of
medical imaging standardization and prototypical im-
plementation: the DICOM standard and the OFFIS DI-
COM toolkit (DCMTK).&amp;quot; Medical Imaging 2004:
PACS and Imaging Informatics 5371: 57-68 (2004).
Fabri, A., G.-J. Giezeman, et al. (2000). &amp;quot;On the Design
of CGAL, a Computational Geometry Algorithms Li-
</reference>
<figure confidence="0.9994950625">
Nov-06
Dec-06
Jan-07
Feb-07
Mar-07
Apr-07
May-07
Jun-07
Jul-07
Aug-07
Sep-07
Oct-07
Nov-07
Dec-07
Jan-08
Feb-08
</figure>
<page confidence="0.711684">
64
</page>
<bodyText confidence="0.3026918">
brary.&amp;quot; Software—Practice &amp; Experience 30(11, Spe-
cial issue on discrete algorithm engineering).
Stolcke, A. (2002). SRILM An Extensible Language
Modeling Toolkit. Intl. Conf. on Spoken Language
Processing.
</bodyText>
<reference confidence="0.999659914893617">
Koehn, P. (2004). Pharaoh: a Beam Search Decoder for
Phrase-Based Statistical Machine Translation Models.
AMTA.
Koehn, P., M. Federico, et al. (2006). Open Source
Toolkit for Statistical Machine Translation. Report of
the 2006 Summer Workshop at Johns Hopkins Univer-
sity.
Koehn, P. and H. Hoang (2007). Factored Translation
Models. EMNLP.
Kumar, S. and W. Byrne (2003). A weighted finite state
transducer implementation of the alignment template
model for statistical machine translation. ACL, Edmon-
ton, Canada.
Liang, P., A. Bouchard-Côté, et al. (2006). An End-to-
End Discriminative Approach to Machine Translation.
COLING/ACL.
Och, F. J. (2003). Minimum Error Rate Training for
Statistical Machine Translation. ACL.
Och, F. J. and H. Ney (2003). &amp;quot;A Systematic Compari-
son of Various Statistical Alignment Models.&amp;quot; Compu-
tational Linguistics 29(1): 19-51.
Och, F. J. and H. Ney (2004). &amp;quot;The alignment template
approach to statistical machine translation.&amp;quot; Computa-
tional Linguistics.
Olteanu, M., C. Davis, et al. (2006). Phramer - An Open
Source Statistical Phrase-Based Translator. ACL Work-
shop on Statistical Machine Translation.
Patry, A., F. Gotti, et al. (2006). Mood at work: Ramses
versus Pharaoh. ACL, New York City, USA.
Sadat, F., H. Johnson, et al. (2005). PORTAGE: A
Phrase-based Machine Translation System. ACL Work-
shop on Building and Using Parallel Texts: Data-Driven
Machine Translation and Beyond, Ann Arbor, Michigan,
USA.
Shen, W., B. Delaney, et al. (2005). The MITLL/AFRL
MT System. IWSLT, Pittsburgh, PA, USA.
Shen, Y., C.-k. Lo, et al. (2007). HKUST Statistical
Machine Translation Experiments for IWSLT 2007.
IWSLT, Trento.
Talbot, D. and M. Osborne (2007). Smoothed Bloom
filter language models: Tera-Scale LMs on the Cheap.
EMNLP, Prague, Czech Republic.
Wang, Z., J. Shawe-Taylor, et al. (2007). Kernel Re-
gression Based Machine Translation. NAACL HLT.
Zens, R. and H. Ney (2007). Efficient phrase-table rep-
resentation for machine translation with applications to
online MT and speech recognition. HLT/NAACL.
</reference>
<page confidence="0.999614">
65
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.047456">
<title confidence="0.998919">Design of the Moses Decoder for Statistical Machine Translation</title>
<author confidence="0.934473">Hieu</author>
<affiliation confidence="0.999719">University of Edinburgh</affiliation>
<email confidence="0.991808">h.hoang@sms.ed.ac.uk</email>
<author confidence="0.866589">Philipp</author>
<affiliation confidence="0.999721">University of Edinburgh</affiliation>
<email confidence="0.997353">pkoehn@inf.ed.ac.uk</email>
<abstract confidence="0.981290149253731">We present a description of the implementation of the open source decoder for statistical machine translation which has become popular with many researchers in SMT research. The goal of the project is to create an open, high quality phrase-based decoder which can reduce the time and barrier to entry for researchers wishing to do SMT research. We discuss the major design objective for the Moses decoder, its performance relative to other SMT decoders, and the steps we are taking to ensure that its success will continue. 1 Motivation Phrase-based translation has been one of the major advances in statistical machine translation (Brown et al. 1990) in recent years and is currently one of the techniques which can claim to be stateof-the-art in machine translation. Phrase-based models are a development of the word based models as exemplified by the (Brown et al. 1990). In phrase-based translation, contiguous segments of words in the input sentence are mapped to contiguous segments of words in the output sentence. In SMT, we are given a source language sentence, s, which is to be translated into a target language sentence, t. The goal of machine translation to find the translation, which is defined as: the probability model. The argmax a search for the best translation the space of possible translations t. This search is the task of the decoder, which we will concentrate on in this paper. There have been numerous implementations of phrase-based decoders for SMT prior to our work. Early systems such as the Alignment Template System (ATS) (Och and Ney 2004) and Pharaoh (Koehn 2004) were widely used and accepted by the research community. ATS is perhaps the crossover system, in that word classes were translated as phrases but the surface words were translated word by word. Pharaoh substituted the word classes with surface words, thereby discarding the use of word classes in decoding altogether. There has been other phrase-based decoders such as PORTAGE (Sadat et al. 2005), Phramer (Olteanu et al. 2006), the MITLL/AFRL system (Shen et al. 2005), ITC-irst (Bertoldi et al. 2004), Ramses/Mood (Patry et al. 2006) to name but a few. Other researchers such as (Kumar and Byrne 2003) have also used weighted finite state transducers but they have more difficulty modeling reordering. Many early systems came with restrictive licenses; ATS has never been publicly released, Pharaoh was released in 2003 as a pre-compiled binary with documentation. This severely limited the extent to which other researchers can study and enhance the decoder. Without access to the decoder source code research was generally restricted to altering the input, augmenting it with extra information, or modifying the output or re-ranking the n-best list output. The main contribution of this paper is to show how we have created an extensible decoder, has acceptable run time performance compared to similar systems, and the ease of use and development that has made it the preferred choice for researchers looking for a phrase-based SMT decoder. 58 Engineering, Testing, and Quality Assurance for Natural Language pages Ohio, USA, June 2008. Association for Computational Linguistics As an indication of the take-up of the Moses toolkit, out of over 20 competing teams at the re- IWSLT 2007 half used Moses. As an indication of the extensibility of the decoder, there are currently four language model implementations which has been integrated with the decoder by various researchers. In addition, the framework exists to integrate language models, such as those described in (Bilmes and Kirchhoff 2003), which takes advantage of the factored representation within Moses. It is noted that Mood/Ramses also supports multiple LM implementations, an internally developed language model, in additional to SRILM, to overcome the latter’s licensing restrictions. In addition, there are two built-in phrase table implementations, one which loads all data into memory for fast decoding, and a binary phrase table as described in (Zens and Ney 2007) which loads on demand to conserve memory usage. The Moses decoder has the ability to accept simple sentence input, confusion network or lattice networks, in common with SMT decoders such as the MITLL/AFRL or ITC-irst systems. The decoder also produces diverse types of output, ranging from 1-best, n-best lists and word lattices. 2 Comparison with other projects The Moses decoder is designed within a strict modular and object-oriented framework for easy maintainability and extensibility. In designing the decoder, we modeled the software design methodology and aims on some research-oriented software libraries outside of the SMT and NLP field which is open source, written in C++, have a large and diverse user-base, have succeeded in becoming the industry norm in their field. Specifically, we modeled the software on the CGAL library (Fabri et al. 2000), used in computational geometry, and DCMTK (Eichelberg et al. 2004) library used in medical imaging. We believe they set good examples of the standards that we should follow. However, there are differences between our project and CGAL or DCMTK. The first difference is project size, for example, whereas CGAL consists of over 500,000 lines of code and multiple libraries and example program, the Moses decoder consists of 20,000 lines in 2 libraries. The difference is scale makes implementing some steps in the development life cycle impractical or unnecessary. For example, functionality specification before implementation was described for CGAL and is typical of large projects but would have been cumbersome for Moses. Secondly, the aims of Moses and these projects are different. The goal of the CGAL project is to ‘make...computational geometry available for in- Both CGAL and DCMTK are used extensively in commercial applications. Therefore, issues such robustness, cross-platform compatibility and easeof-use are predominant for these projects. Commercialization is not an aim of the Moses project but we believe these issues are still as important as they affect the usability and uptake of the system. Therefore, the Moses decoder was built to address these issues without compromising the academic priorities of the project. Thirdly, the correct implementation is easier to decide in libraries such as CGAL as the algorithms are closely specified by the mathematical specification, therefore, testing and specification writing is more prevalent and easier than in Moses. For DCMTK, the medical imaging standards and protocols offers a clear guide for implementation. By contrast, the function of an SMT decoder is search for which there are no correct implementation, we can only measure its performance relative to previous versions and other similar decoders. These differences are minor compared to the similarities Moses has to CGAL and DCMTK, and indeed, to any well developed software project. Design goals such as robustness, flexibility, ease of use and efficiency are commonality that we share and which we will discuss in more detail in the next section. As a contrast to CGAL and DCMTK whose design we would like to emulate, we also looked at a project within the NLP field which contains certain aspect in the design we would like to avoid. GIZA++ (Och and Ney 2003) is a very popular system within SMT for creating word alignment from parallel corpus, in fact, the Moses training scripts uses it. The system was release under the GPL open source license. However, its lack of 59 clear design, documentation and obscure coding style makes it difficult for other researcher to contribute or extend the system. For a long time, it couldn’t even be compiled on modern GCC compilers. Other systems which seeks to improve word alignment and segmentation, such as MTTK (Deng et al. 2006), have been created to replace GIZA++. 3 Design Goals We decided to develop the Moses decoder as a C++ library. We steered clear of scripting languages for performance reasons and the fact they often offer even less in the way of cross-platform compatibility. Java was also avoided for performance reasons but it’s rich library and multi-platform support would have been useful. We note that Hiero (Chiang 2005) is written in a scripting language with performance critical components rewritten in a compiled language. This is not the approach we considered as we believed it would have raised the complexity and reduce reliability of the project having to develop (and debug) in two languages and managing the interface between them. We also note that the LinearB and Phramer decoders are implemented in Java and have reported significantly worse run time speeds, (Olteanu et al. 2006). C++ can be inelegant and difficult for inexperienced developers but using other object oriented language such as Smalltalk or C# was out of the question as they lack acceptance within the MT research community.</abstract>
<note confidence="0.808257333333333">3.1 Comparable Performance The Pharaoh decoder (Koehn 2004) represented the state-of-the-art in phrase-based decoders prior</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Bertoldi</author>
<author>R Cattoni</author>
</authors>
<date>2004</date>
<booktitle>The ITC-irst Statistical Machine Translation System for IWSLT-2004. IWSLT,</booktitle>
<location>Kyoto, Japan.</location>
<marker>Bertoldi, Cattoni, 2004</marker>
<rawString>Bertoldi, N., R. Cattoni, et al. (2004). The ITC-irst Statistical Machine Translation System for IWSLT-2004. IWSLT, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Bilmes</author>
<author>K Kirchhoff</author>
</authors>
<title>Factored language models and Generalized Parallel Backoff.</title>
<date>2003</date>
<publisher>HLT/NACCL.</publisher>
<contexts>
<context position="3910" citStr="Bilmes and Kirchhoff 2003" startWordPosition="636" endWordPosition="639">ecoder. 58 Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 58–65, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics As an indication of the take-up of the Moses toolkit, out of over 20 competing teams at the recent IWSLT 2007 conference1, half used Moses. As an indication of the extensibility of the decoder, there are currently four language model implementations which has been integrated with the decoder by various researchers. In addition, the framework exists to integrate language models, such as those described in (Bilmes and Kirchhoff 2003), which takes advantage of the factored representation within Moses. It is noted that Mood/Ramses also supports multiple LM implementations, an internally developed language model, in additional to SRILM, to overcome the latter’s licensing restrictions. In addition, there are two built-in phrase table implementations, one which loads all data into memory for fast decoding, and a binary phrase table as described in (Zens and Ney 2007) which loads on demand to conserve memory usage. The Moses decoder has the ability to accept simple sentence input, confusion network or lattice networks, in commo</context>
</contexts>
<marker>Bilmes, Kirchhoff, 2003</marker>
<rawString>Bilmes, J. A. and K. Kirchhoff (2003). Factored language models and Generalized Parallel Backoff. HLT/NACCL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J Cocke</author>
</authors>
<title>A statistical approach to machine translation.&amp;quot;</title>
<date>1990</date>
<marker>Brown, Cocke, 1990</marker>
<rawString>Brown, P. F., J. Cocke, et al. (1990). &amp;quot;A statistical approach to machine translation.&amp;quot;</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<publisher>ACL.</publisher>
<contexts>
<context position="8636" citStr="Chiang 2005" startWordPosition="1393" endWordPosition="1394">ribute or extend the system. For a long time, it couldn’t even be compiled on modern GCC compilers. Other systems which seeks to improve word alignment and segmentation, such as MTTK (Deng et al. 2006), have been created to replace GIZA++. 3 Design Goals We decided to develop the Moses decoder as a C++ library. We steered clear of scripting languages for performance reasons and the fact they often offer even less in the way of cross-platform compatibility. Java was also avoided for performance reasons but it’s rich library and multi-platform support would have been useful. We note that Hiero (Chiang 2005) is written in a scripting language with performance critical components rewritten in a compiled language. This is not the approach we considered as we believed it would have raised the complexity and reduce reliability of the project having to develop (and debug) in two languages and managing the interface between them. We also note that the LinearB and Phramer decoders are implemented in Java and have reported significantly worse run time speeds, (Olteanu et al. 2006). C++ can be inelegant and difficult for inexperienced developers but using other object oriented language such as Smalltalk o</context>
<context position="22378" citStr="Chiang 2005" startWordPosition="3632" endWordPosition="3633">e translation in general are often asked, and usually answered. The archived emails are publicly available and searchable, and have become an important knowledge source for the community. The mailing list popularity has been steadily increasing since its inception, Figure 6, and is now the most popular mailing list for machine translation, based on volume. 160 140 120 100 80 60 40 20 0 Figure 6 Emails to Moses support mailing list 5 Future Work There has been some important developments in phrase-based translation in recent years, including the hierarchical phrase-based model as described in (Chiang 2005). Research have also been made into alternatives to the current log-linear scoring model such as discriminative models with millions of features (Liang et al. 2006), or kernel based models (Wang et al. 2007). From a software engineering point of view, these improvements would require fundamental changes to the structure if they were to be implemented into Moses. We are also interested in seeing the Moses decoder employed in search tasks outside of machine translation; Moses has been used for OCR correction, recasing, and transliteration. Other improvements such as smaller, faster, more efficie</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>Chiang, D. (2005). A hierarchical phrase-based model for statistical machine translation. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Deng</author>
<author>S Kumar</author>
</authors>
<title>Segmentation and alignment of parallel text for statistical machine translation.&amp;quot; Natural Language Engineering.</title>
<date>2006</date>
<marker>Deng, Kumar, 2006</marker>
<rawString>Deng, Y., S. Kumar, et al. (2006). &amp;quot;Segmentation and alignment of parallel text for statistical machine translation.&amp;quot; Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Eichelberg</author>
<author>J Riesmeier</author>
</authors>
<title>Ten years of medical imaging standardization and prototypical implementation: the DICOM standard and the OFFIS DICOM toolkit (DCMTK).&amp;quot; Medical Imaging 2004: PACS and Imaging Informatics 5371:</title>
<date>2004</date>
<pages>57--68</pages>
<marker>Eichelberg, Riesmeier, 2004</marker>
<rawString>Eichelberg, M., J. Riesmeier, et al. (2004). &amp;quot;Ten years of medical imaging standardization and prototypical implementation: the DICOM standard and the OFFIS DICOM toolkit (DCMTK).&amp;quot; Medical Imaging 2004: PACS and Imaging Informatics 5371: 57-68 (2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fabri</author>
<author>G-J Giezeman</author>
</authors>
<title>On the Design of CGAL, a Computational Geometry Algorithms Li-</title>
<date>2000</date>
<marker>Fabri, Giezeman, 2000</marker>
<rawString>Fabri, A., G.-J. Giezeman, et al. (2000). &amp;quot;On the Design of CGAL, a Computational Geometry Algorithms Li-</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Pharaoh: a Beam Search Decoder for Phrase-Based Statistical Machine Translation Models.</title>
<date>2004</date>
<publisher>AMTA.</publisher>
<contexts>
<context position="1845" citStr="Koehn 2004" startWordPosition="307" endWordPosition="308">urce language sentence, s, which is to be translated into a target language sentence, t. The goal of machine translation is to find the translation, tˆ, which is defined as: tˆ = arg maxt p(t |s) where p(t |s) is the probability model. The argmax implies a search for the best translation tˆ in the space of possible translations t. This search is the task of the decoder, which we will concentrate on in this paper. There have been numerous implementations of phrase-based decoders for SMT prior to our work. Early systems such as the Alignment Template System (ATS) (Och and Ney 2004) and Pharaoh (Koehn 2004) were widely used and accepted by the research community. ATS is perhaps the crossover system, in that word classes were translated as phrases but the surface words were translated word by word. Pharaoh substituted the word classes with surface words, thereby discarding the use of word classes in decoding altogether. There has been other phrase-based decoders such as PORTAGE (Sadat et al. 2005), Phramer (Olteanu et al. 2006), the MITLL/AFRL system (Shen et al. 2005), ITC-irst (Bertoldi et al. 2004), Ramses/Mood (Patry et al. 2006) to name but a few. Other researchers such as (Kumar and Byrne 2</context>
<context position="9382" citStr="Koehn 2004" startWordPosition="1515" endWordPosition="1516">considered as we believed it would have raised the complexity and reduce reliability of the project having to develop (and debug) in two languages and managing the interface between them. We also note that the LinearB and Phramer decoders are implemented in Java and have reported significantly worse run time speeds, (Olteanu et al. 2006). C++ can be inelegant and difficult for inexperienced developers but using other object oriented language such as Smalltalk or C# was out of the question as they lack acceptance within the MT research community. 3.1 Comparable Performance The Pharaoh decoder (Koehn 2004) represented the state-of-the-art in phrase-based decoders prior to the introduction of Moses. Moses was designed to supersede Pharaoh in performance and functionality. Moses was used as the basis for the JHU Workshop (Koehn et al. 2006) on Factored Machine Translation where it was extensively enhanced; we capitalized on the experience of colleagues at the workshop and used Pharaoh as the baseline during development to ensure that we obtain comparable performance. Table 1 shows the comparison of the translation performance of Pharaoh and Moses for a typical decoding of 2000 sentence trained on</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Koehn, P. (2004). Pharaoh: a Beam Search Decoder for Phrase-Based Statistical Machine Translation Models. AMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>M Federico</author>
</authors>
<date>2006</date>
<booktitle>Open Source Toolkit for Statistical Machine Translation. Report of the 2006 Summer Workshop at Johns</booktitle>
<institution>Hopkins University.</institution>
<marker>Koehn, Federico, 2006</marker>
<rawString>Koehn, P., M. Federico, et al. (2006). Open Source Toolkit for Statistical Machine Translation. Report of the 2006 Summer Workshop at Johns Hopkins University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
</authors>
<title>Factored Translation Models.</title>
<date>2007</date>
<publisher>EMNLP.</publisher>
<contexts>
<context position="11414" citStr="Koehn and Hoang 2007" startWordPosition="1851" endWordPosition="1854">words, factored translation models augments different factors, such as POS tags or lemma, into source and target sentences to improve translation. This transforms the representation of a word from a string to a vector of strings, and a phrase or sentence from a sequence of words to a sequence of vectors. Such a change to the basic data structure of a decoder propagated throughout the rest of the system, therefore, it was simpler to build the Moses decoder from scratch rather than extend an existing decoder such as Pharaoh. Some research into factored machine translation has been published by (Koehn and Hoang 2007). 3.3 Flexibility Flexibility is an important software design goal which will enable researchers to extend the use of the Moses decoders to tasks that were not originally envisioned. Following (Fabri et al. 2000), we identify four sub-issues which affects flexibility: i. Modularity 3 http://www.statmt.org/wmt07/shared-task.html 60 ii. Adaptability iii. Extensibility iv. Openness 3.4 Modularity Firstly, software modularity enables developers to work on one component of the decoder without affecting other components. A modular design reduces the learning curve for developers by shielding them fr</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Koehn, P. and H. Hoang (2007). Factored Translation Models. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>W Byrne</author>
</authors>
<title>A weighted finite state transducer implementation of the alignment template model for statistical machine translation.</title>
<date>2003</date>
<publisher>ACL,</publisher>
<location>Edmonton, Canada.</location>
<contexts>
<context position="2449" citStr="Kumar and Byrne 2003" startWordPosition="404" endWordPosition="407">raoh (Koehn 2004) were widely used and accepted by the research community. ATS is perhaps the crossover system, in that word classes were translated as phrases but the surface words were translated word by word. Pharaoh substituted the word classes with surface words, thereby discarding the use of word classes in decoding altogether. There has been other phrase-based decoders such as PORTAGE (Sadat et al. 2005), Phramer (Olteanu et al. 2006), the MITLL/AFRL system (Shen et al. 2005), ITC-irst (Bertoldi et al. 2004), Ramses/Mood (Patry et al. 2006) to name but a few. Other researchers such as (Kumar and Byrne 2003) have also used weighted finite state transducers but they have more difficulty modeling reordering. Many early systems came with restrictive licenses; ATS has never been publicly released, Pharaoh was released in 2003 as a pre-compiled binary with documentation. This severely limited the extent to which other researchers can study and enhance the decoder. Without access to the decoder source code research was generally restricted to altering the input, augmenting it with extra information, or modifying the output or re-ranking the n-best list output. The main contribution of this paper is to </context>
</contexts>
<marker>Kumar, Byrne, 2003</marker>
<rawString>Kumar, S. and W. Byrne (2003). A weighted finite state transducer implementation of the alignment template model for statistical machine translation. ACL, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>A Bouchard-Côté</author>
</authors>
<title>An End-toEnd Discriminative Approach to Machine Translation.</title>
<date>2006</date>
<publisher>COLING/ACL.</publisher>
<marker>Liang, Bouchard-Côté, 2006</marker>
<rawString>Liang, P., A. Bouchard-Côté, et al. (2006). An End-toEnd Discriminative Approach to Machine Translation. COLING/ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum Error Rate Training for Statistical Machine Translation.</title>
<date>2003</date>
<publisher>ACL.</publisher>
<contexts>
<context position="21351" citStr="Och 2003" startWordPosition="3466" endWordPosition="3467">ering principles into NLP. In contrast to the ‘abandonware’ status of GIZA++, both CGAL and DCMTK are still being developed. 4 Supporting Infrastructure Other factors have contributed to the wide adoption of Moses. 4.1 ‘One-Stop Shop’ for Phrase-Based SMT The Moses project encompasses the decoder and many of the other components necessary to create a translation system which were previously available separately. These include scripts for creating alignments from a parallel corpus, creating phrase tables and language models, binarizing phrase tables, scripts for weight optimization using MERT (Och 2003), and testing scripts. Steps such as MERT and testing which are CPU intensive have been re-engineered to run in parallel using Sun Grid Engine. All scripts have also been extended for factored translation. 63 4.2 Ongoing support We assist in the adoption of Moses by offering ongoing support to users and developers through the support mailing list5 . Questions relating to Moses, phrase-based translation or machine translation in general are often asked, and usually answered. The archived emails are publicly available and searchable, and have become an important knowledge source for the communit</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, F. J. (2003). Minimum Error Rate Training for Statistical Machine Translation. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.&amp;quot;</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="7663" citStr="Och and Ney 2003" startWordPosition="1233" endWordPosition="1236">ation, we can only measure its performance relative to previous versions and other similar decoders. These differences are minor compared to the similarities Moses has to CGAL and DCMTK, and indeed, to any well developed software project. Design goals such as robustness, flexibility, ease of use and efficiency are commonality that we share and which we will discuss in more detail in the next section. As a contrast to CGAL and DCMTK whose design we would like to emulate, we also looked at a project within the NLP field which contains certain aspect in the design we would like to avoid. GIZA++ (Och and Ney 2003) is a very popular system within SMT for creating word alignment from parallel corpus, in fact, the Moses training scripts uses it. The system was release under the GPL open source license. However, its lack of 2 http://cordis.europa.eu/esprit/src/21957.htm 59 clear design, documentation and obscure coding style makes it difficult for other researcher to contribute or extend the system. For a long time, it couldn’t even be compiled on modern GCC compilers. Other systems which seeks to improve word alignment and segmentation, such as MTTK (Deng et al. 2006), have been created to replace GIZA++.</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, F. J. and H. Ney (2003). &amp;quot;A Systematic Comparison of Various Statistical Alignment Models.&amp;quot; Computational Linguistics 29(1): 19-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.&amp;quot; Computational Linguistics.</title>
<date>2004</date>
<contexts>
<context position="1820" citStr="Och and Ney 2004" startWordPosition="301" endWordPosition="304">ence. In SMT, we are given a source language sentence, s, which is to be translated into a target language sentence, t. The goal of machine translation is to find the translation, tˆ, which is defined as: tˆ = arg maxt p(t |s) where p(t |s) is the probability model. The argmax implies a search for the best translation tˆ in the space of possible translations t. This search is the task of the decoder, which we will concentrate on in this paper. There have been numerous implementations of phrase-based decoders for SMT prior to our work. Early systems such as the Alignment Template System (ATS) (Och and Ney 2004) and Pharaoh (Koehn 2004) were widely used and accepted by the research community. ATS is perhaps the crossover system, in that word classes were translated as phrases but the surface words were translated word by word. Pharaoh substituted the word classes with surface words, thereby discarding the use of word classes in decoding altogether. There has been other phrase-based decoders such as PORTAGE (Sadat et al. 2005), Phramer (Olteanu et al. 2006), the MITLL/AFRL system (Shen et al. 2005), ITC-irst (Bertoldi et al. 2004), Ramses/Mood (Patry et al. 2006) to name but a few. Other researchers s</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Och, F. J. and H. Ney (2004). &amp;quot;The alignment template approach to statistical machine translation.&amp;quot; Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Olteanu</author>
<author>C Davis</author>
</authors>
<title>Phramer - An Open Source Statistical Phrase-Based Translator.</title>
<date>2006</date>
<booktitle>ACL Workshop on Statistical Machine Translation.</booktitle>
<marker>Olteanu, Davis, 2006</marker>
<rawString>Olteanu, M., C. Davis, et al. (2006). Phramer - An Open Source Statistical Phrase-Based Translator. ACL Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Patry</author>
<author>F Gotti</author>
</authors>
<title>Mood at work: Ramses versus Pharaoh.</title>
<date>2006</date>
<publisher>ACL,</publisher>
<location>New York City, USA.</location>
<marker>Patry, Gotti, 2006</marker>
<rawString>Patry, A., F. Gotti, et al. (2006). Mood at work: Ramses versus Pharaoh. ACL, New York City, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sadat</author>
<author>H Johnson</author>
</authors>
<title>PORTAGE: A Phrase-based Machine Translation System.</title>
<date>2005</date>
<booktitle>ACL Workshop on Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond,</booktitle>
<location>Ann Arbor, Michigan, USA.</location>
<marker>Sadat, Johnson, 2005</marker>
<rawString>Sadat, F., H. Johnson, et al. (2005). PORTAGE: A Phrase-based Machine Translation System. ACL Workshop on Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond, Ann Arbor, Michigan, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Shen</author>
<author>B Delaney</author>
</authors>
<date>2005</date>
<booktitle>The MITLL/AFRL MT System. IWSLT,</booktitle>
<location>Pittsburgh, PA, USA.</location>
<marker>Shen, Delaney, 2005</marker>
<rawString>Shen, W., B. Delaney, et al. (2005). The MITLL/AFRL MT System. IWSLT, Pittsburgh, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Shen</author>
<author>C-k Lo</author>
</authors>
<date>2007</date>
<booktitle>HKUST Statistical Machine Translation Experiments for IWSLT</booktitle>
<publisher>IWSLT,</publisher>
<location>Trento.</location>
<marker>Shen, Lo, 2007</marker>
<rawString>Shen, Y., C.-k. Lo, et al. (2007). HKUST Statistical Machine Translation Experiments for IWSLT 2007. IWSLT, Trento.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Talbot</author>
<author>M Osborne</author>
</authors>
<title>Smoothed Bloom filter language models:</title>
<date>2007</date>
<booktitle>Tera-Scale LMs on the Cheap. EMNLP,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="13375" citStr="Talbot and Osborne 2007" startWordPosition="2163" endWordPosition="2166">rom IRSTLM, SRILM, Moses, and moses-cmd to create a binary executable. Figure 1 Project Dependencies Any of these libraries can be dropped or replaced with other components with the same API. We detail some examples of the object-oriented design of Moses below. The input into the decoder can be one of three types: a simple string (sentence), a confusion network or a lattice network, Figure 2. Figure 2 Input Types Language models are abstracted to enable different implementations to be used and provide a framework for more complex models such as factored LM and the Bloom filter language model (Talbot and Osborne 2007). Similarly, phrase tables are abstracted to provide support for multiple implementations. Each component model which contributes to the log-linear hypothesis score inherits from the ScoreProducer base class, Figure 3. Figure 3 Score Producer The Moses library provide a simple API whose main entry point is the class Manager This class is instantiated in the client application, moses-cmd in our case. Each input is decoded by calling the class method below: ProcessSentence() 3.5 Adaptability Phrase-based SMT is a fast moving research field where virtually all aspects of the theory are SRILM IRST</context>
</contexts>
<marker>Talbot, Osborne, 2007</marker>
<rawString>Talbot, D. and M. Osborne (2007). Smoothed Bloom filter language models: Tera-Scale LMs on the Cheap. EMNLP, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wang</author>
<author>J Shawe-Taylor</author>
</authors>
<title>Kernel Regression Based Machine Translation.</title>
<date>2007</date>
<tech>NAACL HLT.</tech>
<marker>Wang, Shawe-Taylor, 2007</marker>
<rawString>Wang, Z., J. Shawe-Taylor, et al. (2007). Kernel Regression Based Machine Translation. NAACL HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Efficient phrase-table representation for machine translation with applications to online MT and speech recognition.</title>
<date>2007</date>
<publisher>HLT/NAACL.</publisher>
<contexts>
<context position="4347" citStr="Zens and Ney 2007" startWordPosition="704" endWordPosition="707">h has been integrated with the decoder by various researchers. In addition, the framework exists to integrate language models, such as those described in (Bilmes and Kirchhoff 2003), which takes advantage of the factored representation within Moses. It is noted that Mood/Ramses also supports multiple LM implementations, an internally developed language model, in additional to SRILM, to overcome the latter’s licensing restrictions. In addition, there are two built-in phrase table implementations, one which loads all data into memory for fast decoding, and a binary phrase table as described in (Zens and Ney 2007) which loads on demand to conserve memory usage. The Moses decoder has the ability to accept simple sentence input, confusion network or lattice networks, in common with SMT decoders such as the MITLL/AFRL or ITC-irst systems. The decoder also produces diverse types of output, ranging from 1-best, n-best lists and word lattices. 2 Comparison with other projects The Moses decoder is designed within a strict modular and object-oriented framework for easy maintainability and extensibility. In designing the decoder, we modeled the software design methodology and aims on some research-oriented soft</context>
</contexts>
<marker>Zens, Ney, 2007</marker>
<rawString>Zens, R. and H. Ney (2007). Efficient phrase-table representation for machine translation with applications to online MT and speech recognition. HLT/NAACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>