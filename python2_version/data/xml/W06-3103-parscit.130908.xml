<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001435">
<title confidence="0.9813655">
Morpho-syntactic Arabic Preprocessing for Arabic-to-English Statistical
Machine Translation
</title>
<author confidence="0.913426">
Anas El Isbihani Shahram Khadivi Oliver Bender Hermann Ney
</author>
<affiliation confidence="0.94557">
Lehrstuhl f¨ur Informatik VI - Computer Science Department
RWTH Aachen University
</affiliation>
<address confidence="0.639493">
D-52056 Aachen, Germany
</address>
<email confidence="0.998082">
{isbihani,khadivi,bender,ney}@informatik.rwth-aachen.de
</email>
<sectionHeader confidence="0.996648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999716571428571">
The Arabic language has far richer sys-
tems of inflection and derivation than En-
glish which has very little morphology.
This morphology difference causes a large
gap between the vocabulary sizes in any
given parallel training corpus. Segmen-
tation of inflected Arabic words is a way
to smooth its highly morphological na-
ture. In this paper, we describe some
statistically and linguistically motivated
methods for Arabic word segmentation.
Then, we show the efficiency of proposed
methods on the Arabic-English BTEC and
NIST tasks.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999984903846154">
Arabic is a highly inflected language compared to
English which has very little morphology. This mor-
phological richness makes statistical machine trans-
lation from Arabic to English a challenging task. A
usual phenomenon in Arabic is the attachment of a
group of words which are semantically dependent on
each other. For instance, prepositions like “and” and
“then” are usually attached to the next word. This
applies also to the definite article “the”. In addi-
tion, personal pronouns are attached to the end of
verbs, whereas possessive pronouns are attached to
the end of the previous word, which constitutes the
possessed object. Hence, an Arabic word can be de-
composed into “prefixes, stem and suffixes”. We re-
strict the set of prefixes and suffixes to those showed
in Table 1 and 2, where each of the prefixes and suf-
fixes has at least one meaning which can be repre-
sented by a single word in the target language. Some
prefixes can be combined. For example the word
wbAlqlm ( PL9 which means “and with the pen”)
has a prefiix) which is a combination of three pre-
fixes, namely w, b and Al. The suffixes we handle
in this paper can not be combined with each other.
Thus, the compound word pattern handled here is
“prefixes-stem-suffix“.
All possible prefix combinations that do not con-
tain Al allow the stem to have a suffix. Note that
there are other suffixes that are not handled here,
such as At (ul), An ( 0l) and wn (09) which make
the plural form of a word. The reason why we omit
them is that they do not have their own meaning. The
impact of Arabic morphology is that the vocabulary
size and the number of singletons can be dramati-
cally high, i.e. the Arabic words are not seen often
enough to be learned by statistical machine transla-
tion models. This can lead to an inefficient align-
ment.
In order to deal with this problem and to improve
the performance of statistical machine translation,
each word must be decomposed into its parts. In
(Larkey et al., 2002) it was already shown that word
segmentation for Arabic improves information re-
trieval. In (Lee et al., 2003) a statistical approach
for Arabic word segmentation was presented. It de-
composes each word into a sequence of morphemes
(prefixes-stem-suffixes), where all possible prefixes
and suffixes (not only those we described in Table 1
and 2) are split from the original word. A compa-
rable work was done by (Diab et al., 2004), where
a POS tagging method for Arabic is also discussed.
As we have access to this tool, we test its impact
on the performance of our translation system. In
</bodyText>
<page confidence="0.979192">
15
</page>
<note confidence="0.961077">
Proceedings of the Workshop on Statistical Machine Translation, pages 15–22,
New York City, June 2006. c�2006 Association for Computational Linguistics
</note>
<tableCaption confidence="0.999467">
Table 1: Prefixes handled in this work and their meanings.
</tableCaption>
<bodyText confidence="0.937701166666667">
Prefix 9 j d J u J►
Transliteration w f k l b Al
Meaning and and then as, like in order to with, in the
(Habash and Rambow, 2005) a morphology analyzer
was used for the segementation and POS tagging. In
contrast to the methods mentioned above, our seg-
mentation method is unsupervised and rule based.
In this paper we first explain our statistical ma-
chine translation (SMT) system used for testing the
impact of the different segmentation methods, then
we introduce some preprocessing and normalization
tools for Arabic and explain the linguistic motiva-
tion beyond them. Afterwards, we present three
word segmentation methods, a supervised learning
approach, a finite state automaton-based segmenta-
tion, and a frequency-based method. In Section 5,
the experimental results are presented. Finally, the
paper is summarized in Section 6 .
</bodyText>
<sectionHeader confidence="0.961657" genericHeader="method">
2 Baseline SMT System
</sectionHeader>
<bodyText confidence="0.999980333333333">
In statistical machine translation, we are given a
source language sentence fJ1 = f1 ... fj ... fJ,
which is to be translated into a target language sen-
tence eI1 = e1 ... ei ... eI. Among all possible tar-
get language sentences, we will choose the sentence
with the highest probability:
</bodyText>
<equation confidence="0.993061333333333">
e ˆI {Pr(eI1|fJ1 )} (1)
1 = argmax
I,eI1
</equation>
<bodyText confidence="0.988875666666667">
The posterior probability Pr(eI1|fJ1 ) is modeled di-
rectly using a log-linear combination of several
models (Och and Ney, 2002):
</bodyText>
<equation confidence="0.981827333333333">
(�M )
exp m=1 λmhm(eI 1, fJ 1 )
E exp (EM1 λmhm(el I/
1 , fJ1 ))
e/I/
1
</equation>
<bodyText confidence="0.9834448">
(2)
The denominator represents a normalization factor
that depends only on the source sentence fJ1 . There-
fore, we can omit it during the search process. As a
decision rule, we obtain:
</bodyText>
<equation confidence="0.948079">
� M
E �
λmhm(eI1,fJ1 ) (3)
m=1
</equation>
<bodyText confidence="0.992367333333334">
This approach is a generalization of the source-
channel approach (Brown et al., 1990). It has the
advantage that additional models h(·) can be eas-
ily integrated into the overall system. The model
scaling factors λM1 are trained with respect to the fi-
nal translation quality measured by an error criterion
(Och, 2003).
We use a state-of-the-art phrase-based translation
system including the following models: an n-gram
language model, a phrase translation model and a
word-based lexicon model. The latter two mod-
els are used for both directions: p(f|e) and p(e|f).
Additionally, we use a word penalty and a phrase
penalty. More details about the baseline system can
be found in (Zens and Ney, 2004; Zens et al., 2005).
</bodyText>
<sectionHeader confidence="0.839307" genericHeader="method">
3 Preprocessing and Normalization Tools
</sectionHeader>
<subsectionHeader confidence="0.982833">
3.1 Tokenizer
</subsectionHeader>
<bodyText confidence="0.977751">
As for other languages, the corpora must be first to-
kenized. Here words and punctuations (except ab-
breviation) must be separated. Another criterion is
that Arabic has some characters that appear only at
the end of a word. We use this criterion to separate
words that are wrongly attached to each other.
</bodyText>
<subsectionHeader confidence="0.999485">
3.2 Normalization and Simplification
</subsectionHeader>
<bodyText confidence="0.999217642857143">
The Arabic written language does not contain vow-
els, instead diacritics are used to define the pronun-
ciation of a word, where a diacritic is written under
or above each character in the word. Usually these
diacritics are omitted, which increases the ambigu-
ity of a word. In this case, resolving the ambiguity
of a word is only dependent on the context. Some-
times, the authors write a diacritic on a word to help
the reader and give him a hint which word is really
meant. As a result, a single word with the same
meaning can be written in different ways. For exam-
ple $Eb (�� � ��) can be read1 as sha’ab (Eng. nation)
or sho’ab (Eng. options). If the author wants to give
the reader a hint that the second word is meant, he
</bodyText>
<footnote confidence="0.753128">
1There are other possible pronunciations for the word $Eb
than the two mentioned.
</footnote>
<equation confidence="0.806641">
Pr(eI1|fJ1 ) =
�e1 = argmax
ˆI
I,eI1
</equation>
<page confidence="0.998793">
16
</page>
<tableCaption confidence="0.999246">
Table 2: Suffixes handled in this work and their meanings.
</tableCaption>
<table confidence="0.959586875">
Suffix S i d �
� � �� c�� ct��
Transliteration y ny k kmA, km, kn
Meaning my me you, your (sing.) you, your (pl.)
Suffix t�� o tm �
�m cPm ct�m
Transliteration nA h hA hmA, hm, hn
Meaning us, our his, him her them, their
</table>
<bodyText confidence="0.9980618">
can write $uEb or $uEab To avoid
this problem we normalize the text by removing all
diacritics.
After segmenting the text, the size of the sen-
tences increases rapidly, where the number of the
stripped article Al is very high. Not every article in
an Arabic sentence matches to an article in the target
language. One of the reasons is that the adjective in
Arabic gets an article if the word it describes is def-
inite. So, if a word has the prefix Al, then its adjec-
tive will also have Al as a prefix. In order to reduce
the sentence size we decide to remove all these arti-
cles that are supposed to be attached to an adjective.
Another way for determiner deletion is described in
(Lee, 2004).
</bodyText>
<sectionHeader confidence="0.966821" genericHeader="method">
4 Word Segmentation
</sectionHeader>
<bodyText confidence="0.9998968">
One way to simplify inflected Arabic text for a SMT
system is to split the words in prefixes, stem and
suffixes. In (Lee et al., 2003), (Diab et al., 2004)
and (Habash and Rambow, 2005) three supervised
segmentation methods are introduced. However, in
these works the impact of the segmentation on the
translation quality is not studied. In the next subsec-
tions we will shortly describe the method of (Diab et
al., 2004). Then we present our unsupervised meth-
ods.
</bodyText>
<subsectionHeader confidence="0.998463">
4.1 Supervised Learning Approach (SL)
</subsectionHeader>
<bodyText confidence="0.999956384615385">
(Diab et al., 2004) propose solutions to word seg-
mentation and POS Tagging of Arabic text. For the
purpose of training the Arabic TreeBank is used,
which is an Arabic corpus containing news articles
of the newswire agency AFP. In the first step the text
must be transliterated to the Buckwalter translitera-
tion, which is a one-to-one mapping to ASCII char-
acters. In the second step it will be segmented and
tokenized. In the third step a partial lemmatization is
done. Finally a POS tagging is performed. We will
test the impact of the step 3 (segmentation + lemma-
tization) on the translation quality using our phrase
based system described in Section 2.
</bodyText>
<subsectionHeader confidence="0.994266">
4.2 Frequency-Based Approach (FB)
</subsectionHeader>
<bodyText confidence="0.999936285714286">
We provide a set of all prefixes and suffixes and
their possible combinations. Based on this set, we
may have different splitting points for a given com-
pound word. We decide whether and where to split
the composite word based on the frequency of dif-
ferent resulting stems and on the frequency of the
compound word, e.g. if the compound word has a
higher frequency than all possible stems, it will not
be split. This simple heuristic harmonizes the cor-
pus by reducing the size of vocabulary, singletons
and also unseen words from the test corpus. This
method is very similar to the method used for split-
ting German compound words (Koehn and Knight,
2003).
</bodyText>
<subsectionHeader confidence="0.840668">
4.3 Finite State Automaton-Based Approach
</subsectionHeader>
<bodyText confidence="0.976821066666667">
(FSA)
To segment Arabic words into prefixes, stem and one
suffix, we implemented two finite state automata.
One for stripping the prefixes and the other for the
suffixes. Then, we append the suffix automaton to
the other one for stripping prefixes. Figure 1 shows
the finite state automaton for stripping all possible
prefix combinations. We add the prefix s (_r), which
changes the verb tense to the future, to the set of
prefixes which must be stripped (see table 1). This
prefix can only be combined with w and f. Our mo-
tivation is that the future tense in English is built by
adding the separate word “will”.
The automaton showed in Figure 1 consists of the
following states:
</bodyText>
<listItem confidence="0.999946">
• S: the starting point of the automaton.
• E: tne end state, which can only be achieved if
</listItem>
<page confidence="0.996995">
17
</page>
<figureCaption confidence="0.9990705">
Figure 1: Finite state automaton for stripping pre-
fixes off Arabic words.
</figureCaption>
<bodyText confidence="0.970072">
the resulting stem exists already in the text.
</bodyText>
<listItem confidence="0.9249435">
• WF: is achieved if the word begins with w orf.
• And the states, K, L, B and AL are achieved if
the word begins with s, k, l, b and Al, respec-
tively.
</listItem>
<bodyText confidence="0.999869333333333">
To minimize the number of wrong segmentations,
we restricted the transition from one state to the
other to the condition that the produced stem occurs
at least one time in the corpus. To ensure that most
compound words are recognized and segmented, we
run the segmenter itteratively, where after each it-
eration the newly generated words are added to the
vocabulary. This will enable recognizing new com-
pound words in the next iteration. Experiments
showed that running the segmenter twice is suffi-
cient and in higher iterations most of the added seg-
mentations are wrong.
</bodyText>
<subsectionHeader confidence="0.579259">
4.4 Improved Finite State Automaton-Based
Approach (IFSA)
</subsectionHeader>
<bodyText confidence="0.999949037037037">
Although we restricted the finite state segmenter in
such a way that words will be segmented only if the
yielded stem already exists in the corpus, we still get
some wrongly segmented words. Thus, some new
stems, which do not make sense in Arabic, occur
in the segmented text. Another problem is that the
finite state segmenter does not care about ambigui-
ties and splits everything it recognizes. For example
let us examine the word frd (����). In one case, the
character f is an original one and therefore can not
be segmented. In this case the word means “per-
son”. In the other case, the word can be segmented
to “f rd” (which means “and then he answers” or
“and then an answer”). If the words Alfrd, frd and
rd(�� c�� I and ),) occur in the corpus, then the fi-
nite state segmenter will transform the Alfrd (which
means “the person”) to Alf rd (which can be trans-
lated to “the and then he answers”). Thus the mean-
ing of the original word is distorted. To solve all
these problems, we improved the last approach in a
way that prefixes and suffixes are recognized simul-
taneously. The segmentation of the ambiguous word
will be avoided. In doing that, we intend to postpone
resolving such ambiguities to our SMT system.
The question now is how can we avoid the seg-
mentation of ambiguous words. To do this, it is suf-
ficient to find a word that contains the prefix as an
original character. In the last example the word Al-
frd contains the prefix f as an original character and
therefore only Al can be stripped off the word. The
next question we can ask is, how can we decide if a
character belongs to the word or is a prefix. We can
extract this information using the invalid prefix com-
binations. For example Al is always the last prefix
that can occur. Therefore all characters that occur in
a word after Al are original characters. This method
can be applied for all invalid combinations to extract
new rules to decide whether a character in a word is
an original one or not.
On the other side, all suffixes we handle in this
work are pronouns. Therefore it is not possible to
combine them as a suffix. We use this fact to make
a decision whether the end characters in a word are
original or can be stripped. For example the word
trkhm (�_,) means “he lets them”. If we suppose
that hm is a suffix and therefore must be stripped,
then we can conclude that k is an original character
and not a suffix. In this way we are able to extract
from the corpus itself decisions whether and how a
word can be segmented.
In order to implement these changes the original
automaton was modified. Instead of splitting a word
we mark it with some properties which corespond
to the states traversed untill the end state. On the
</bodyText>
<figure confidence="0.999407714285714">
S K
WF
C
L
B
AL
E
</figure>
<page confidence="0.995534">
18
</page>
<bodyText confidence="0.999844857142857">
other side, we use the technique described above to
generate negative properties which avoid the corre-
sponding kind of splitting. If a property and its nega-
tion belong to the same word then the property is re-
moved and only the negation is considered. At the
end each word is split corresponding to the proper-
ties it is marked with.
</bodyText>
<sectionHeader confidence="0.990812" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.996345">
5.1 Corpus Statistics
</subsectionHeader>
<bodyText confidence="0.999989210526316">
The experiments were carried out on two tasks: the
corpora of the Arabic-English NIST task, which
contain news articles and UN reports, and the
Arabic-English corpus of the Basic Travel Expres-
sion Corpus (BTEC) task, which consists of typi-
cal travel domain phrases (Takezawa et al., 2002).
The corpus statistics of the NIST and BTEC corpora
are shown in Table 3 and 5. The statistics of the
news part of NIST corpus, consisting of the Ummah,
ATB, ANEWS1 and eTIRR corpora, is shown in Ta-
ble 4. In the NIST task, we make use of the NIST
2002 evaluation set as a development set and NIST
2004 evaluation set as a test set. Because the test
set contains four references for each senence we de-
cided to use only the first four references of the de-
velopment set for the optimization and evaluation.
In the BTEC task, C-Star’03 and IWSLT’04 copora
are considered as development and test sets, respec-
tively.
</bodyText>
<subsectionHeader confidence="0.992709">
5.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999975272727273">
The commonly used criteria to evaluate the trans-
lation results in the machine translation commu-
nity are: WER (word error rate), PER (position-
independent word error rate), BLEU (Papineni et
al., 2002), and NIST (Doddington, 2002). The four
criteria are computed with respect to multiple ref-
erences. The number of reference translations per
source sentence varies from 4 to 16 references. The
evaluation is case-insensitive for BTEC and case-
sensitive for NIST task. As the BLEU and NIST
scores measure accuracy, higher scores are better.
</bodyText>
<subsectionHeader confidence="0.997066">
5.3 Translation Results
</subsectionHeader>
<bodyText confidence="0.999679188679246">
To study the impact of different segmentation meth-
ods on the translation quality, we apply different
word segmentation methods to the Arabic part of the
BTEC and NIST corpora. Then, we make use of the
phrase-based machine translation system to translate
the development and test sets for each task.
First, we discuss the experimental results on the
BTEC task. In Table 6, the translation results on the
BTEC corpus are shown. The first row of the table is
the baseline system where none of the segmentation
methods is used. All segmentation methods improve
the baseline system, except the SL segmentation
method on the development corpus. The best per-
forming segmentation method is IFSA which gener-
ates the best translation results based on all evalua-
tion criteria, and it is consistent over both develop-
ment and evaluation sets. As we see, the segmen-
tation of Arabic words has a noticeable impact in
improving the translation quality on a small corpus.
To study the impact of word segmentation meth-
ods on a large task, we conduct two sets of experi-
ments on the NIST task using two different amounts
of the training corpus: only news corpora, and full
corpus. In Table 7, the translation results on the
NIST task are shown when just the news corpora
were used to train the machine translation models.
As the results show, except for the FB method, all
segmentation methods improve the baseline system.
For the NIST task, the SL method outperforms the
other segmentation methods, while it did not achieve
good results when comparing to the other methods
in the BTEC task.
We see that the SL, FSA and IFSA segmentation
methods consistently improve the translation results
in the BTEC and NIST tasks, but the FB method
failed on the NIST task, which has a larger training
corpus . The next step is to study the impact of the
segmentation methods on a very large task, the NIST
full corpus. Unfortunately, the SL method failed on
segmenting the large UN corpus, due to the large
processing time that it needs. Due to the negative
results of the FB method on the NIST news corpora,
and very similar results for FSA and IFSA, we were
interested to test the impact of IFSA on the NIST
full corpus. In Table 8, the translation results of the
baseline system and IFSA segmentation method for
the NIST full corpus are depicted. As it is shown in
table, the IFSA method slightly improves the trans-
lation results in the development and test sets.
The IFSA segmentation method generates the
best results among our proposed methods. It
acheives consistent improvements in all three tasks
over the baseline system. It also outperforms the SL
</bodyText>
<page confidence="0.999627">
19
</page>
<tableCaption confidence="0.965267">
Table 3: BTEC corpus statistics, where the Arabic part is tokenized and segmented with the SL, FB, FSA
and the IFSA methods.
</tableCaption>
<table confidence="0.999914181818182">
ARABIC ENGLISH
TOKENIZED SL FB FSA IFSA
Train: Sentences 20K
Running Words 159K 176.2K 185.5K 190.3K 189.1K 189K
Vocabulary 18,149 14,321 11,235 11,736 12,874 7,162
Dev: Sentences 506
Running Words 3,161 3,421 3,549 3,759 3,715 5,005
OOVs (Running Words) 163 129 149 98 118 NA
Test: Sentences 500
Running Words 3,240 3,578 3,675 3,813 3,778 4,986
OOVs (Running Words) 186 120 156 92 115 NA
</table>
<tableCaption confidence="0.9982715">
Table 4: Corpus statistics for the news part of the NIST task, where the Arabic part is tokenized and seg-
mented with SL, FB, FSA and IFSA methods.
</tableCaption>
<table confidence="0.999730363636364">
ARABIC ENGLISH
TOKENIZED SL FB FSA IFSA
Train: Sentences 284.9K
Running Words 8.9M 9.7M 12.2M 10.9M 10.9M 10.2M
Vocabulary 118.7K 90.5K 43.1K 68.4K 62.2K 56.1K
Dev: Sentences 1,043
Running Words 27.7K 29.1K 37.3K 34.4K 33.5K 33K
OOVs (Running Words) 714 558 396 515 486 NA
Test: Sentences 1,353
Running Words 37.9K 41.7K 52.6K 48.6K 48.3K 48.3K
OOVs (Running Words) 1,298 1,027 612 806 660 NA
</table>
<bodyText confidence="0.98533428125">
segmentation on the BTEC task.
Although the SL method outperforms the IFSA
method on the NIST tasks, the IFSA segmentation
method has a few notable advantages over the SL
system. First, it is consistent in improving the base-
line system over the three tasks. But, the SL method
failed in improving the BTEC development corpus.
Second, it is fast and robust, and capable of being
applied to the large corpora. Finally, it employs an
unsupervised learning method, therefore can easily
cope with a new task or corpus.
We observe that the relative improvement over
the baseline system is decreased by increasing the
size of the training corpus. This is a natural effect
of increasing the size of the training corpus. As
the larger corpus provides higher probability to have
more samples per word, this means higher chance
to learn the translation of a word in different con-
texts. Therefore, larger training corpus makes a bet-
ter translation system, i.e. a better baseline, then it
would be harder to outperform this better system.
Using the same reasoning, we can realize why the
FB method achieves good results on the BTEC task,
but not on the NIST task. By increasing the size
of the training corpus, the FB method tends to seg-
ment words more than the IFSA method. This over-
segmentation can be compensated by using longer
phrases during the translation, in order to consider
the same context compared to the non-segmented
corpus. Then, it would be harder for a phrase-based
machine translation system to learn the translation
of a word (stem) in different contexts.
</bodyText>
<sectionHeader confidence="0.999229" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9740505">
We presented three methods to segment Arabic
words: a supervised learning approach, a frequency-
</bodyText>
<page confidence="0.995593">
20
</page>
<tableCaption confidence="0.978526">
Table 5: NIST task corpus statistics, where the Arabic part is tokenized and segmented with the IFSA
method.
</tableCaption>
<table confidence="0.999418909090909">
ARABIC ENGLISH
TOKENIZED IFSA
Train: Sentences 8.5M
Running Words 260.5M 316.8M 279.2M
Vocabulary 510.3K 411.2K 301.2K
Dev: Sentences 1043
Running Words 30.2K 33.3K 33K
OOVs (Running Words) 809 399 NA
Test: Sentences 1353
Running Words 40K 47.9K 48.3K
OOVs (Running Words) 871 505 NA
</table>
<tableCaption confidence="0.928233">
Table 6: Case insensitive evaluation results for translating the development and test data of BTEC task after
performing divers preprocessing.
</tableCaption>
<table confidence="0.999738625">
Dev Test
mPER mWER BLEU NIST mPER mWER BLEU NIST
[%] [%] [%] [%] [%] [%]
Non-Segmented Data 21.4 24.6 63.9 10.0 23.5 27.2 58.1 9.6
SL Segmenter 21.2 24.4 62.5 9.7 23.4 27.4 59.2 9.7
FB Segmenter 20.9 24.4 65.3 10.1 22.1 25.8 59.8 9.7
FSA Segmenter 20.1 23.4 64.8 10.2 21.1 25.2 61.3 10.2
IFSA Segmenter 20.0 23.3 65.0 10.4 21.2 25.3 61.3 10.2
</table>
<bodyText confidence="0.999973888888889">
based approach and a finite state automaton-based
approach. We explained that the best of our pro-
posed methods, the improved finite state automaton,
has three advantages over the state-of-the-art Arabic
word segmentation method (Diab, 2000), supervised
learning. They are: consistency in improving the
baselines system over different tasks, its capability
to be efficiently applied on the large corpora, and its
ability to cope with different tasks.
</bodyText>
<sectionHeader confidence="0.995801" genericHeader="acknowledgments">
7 Acknowledgment
</sectionHeader>
<bodyText confidence="0.99681475">
This material is based upon work supported by
the Defense Advanced Research Projects Agency
(DARPA) under Contract No. HR0011-06-C-0023.
Any opinions, findings and conclusions or recom-
mendations expressed in this material are those of
the author(s) and do not necessarily reflect the views
of the Defense Advanced Research Projects Agency
(DARPA).
</bodyText>
<sectionHeader confidence="0.997858" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99958835">
P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della
Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and
P. S. Roossin. 1990. A statistical approach to machine
translation. Computational Linguistics, 16(2):79–85,
June.
M. Diab, K. Hacioglu, and D. Jurafsky. 2004. Automatic
tagging of arabic text: From raw text to base phrase
chunks. In D. M. Susan Dumais and S. Roukos, edi-
tors, HLT-NAACL 2004: Short Papers, Boston, Mas-
sachusetts, USA, May 2 - May 7. Association for
Computational Linguistics.
M. Diab. 2000. An unsupervised method for multi-
lingual word sense tagging using parallel corpora: A
preliminary investigation. In ACL-2000 Workshop on
Word Senses and Multilinguality, pages 1–9, Hong
Kong, October.
G. Doddington. 2002. Automatic evaluation of machine
translation quality using n-gram co-occurrence statis-
tics. In Proc. ARPA Workshop on Human Language
Technology.
</reference>
<page confidence="0.999815">
21
</page>
<tableCaption confidence="0.7778185">
Table 7: Case sensitive evaluation results for translating the development and test data of the news part of
the NIST task after performing divers preprocessing.
</tableCaption>
<table confidence="0.9998">
Dev Test
mPER mWER BLEU NIST mPER mWER BLEU NIST
[%] [%] [%] [%] [%] [%]
Non-Segmented Data 43.7 56.4 43.6 9.9 46.1 58.0 37.4 9.1
SL Segmenter 42.0 54.7 45.1 10.2 44.3 56.3 39.9 9.6
FB Segmenter 43.4 56.1 43.2 9.8 45.6 57.8 37.2 9.2
FSA Segmenter 42.9 55.7 43.7 9.9 44.8 56.9 38.7 9.4
IFSA Segmenter 42.6 55.0 44.6 9.9 44.5 56.6 38.8 9.4
</table>
<tableCaption confidence="0.99012">
Table 8: Case-sensitive evaluation results for translating development and test data of NIST task.
</tableCaption>
<table confidence="0.9558218">
Dev Test
mPER mWER BLEU NIST mPER mWER BLEU NIST
[%] [%] [%] [%] [%] [%]
Non-Segmented Data 41.5 53.5 46.4 10.3 42.5 53.9 42.6 10.0
IFSA Segmenter 41.1 53.2 46.7 10.2 42.1 53.6 43.4 10.1
</table>
<reference confidence="0.999239086206896">
N. Habash and O. Rambow. 2005. Arabic tokeniza-
tion, part-of-speech tagging and morphological dis-
ambiguation in one fell swoop. In Proc. of the 43rd
Annual Meeting of the Association for Computational
Linguistics (ACL’05), pages 573–580, Ann Arbor,
Michigan, June. Association for Computational Lin-
guistics.
P. Koehn and K. Knight. 2003. Empirical methods for
compound splitting. In Proc. 10th Conf. of the Europ.
Chapter of the Assoc. for Computational Linguistics
(EACL), pages 347–354, Budapest, Hungary, April.
L. S. Larkey, L. Ballesteros, and M. E. Connell. 2002.
Improving stemming for arabic information retrieval:
light stemming and co-occurrence analysis. In Proc.
of the 25th annual of the international Association
for Computing Machinery Special Interest Group on
Information Retrieval (ACM SIGIR), pages 275–282,
New York, NY, USA. ACM Press.
Y. S. Lee, K. Papineni, S. Roukos, O. Emam, and H. Has-
san. 2003. Language model based Arabic word seg-
mentation. In E. Hinrichs and D. Roth, editors, Proc.
of the 41st Annual Meeting ofthe Association for Com-
putational Linguistics.
Y. S. Lee. 2004. Morphological analysis for statisti-
cal machine translation. In D. M. Susan Dumais and
S. Roukos, editors, HLT-NAACL 2004: Short Papers,
pages 57–60, Boston, Massachusetts, USA, May 2 -
May 7. Association for Computational Linguistics.
F. J. Och and H. Ney. 2002. Discriminative training
and maximum entropy models for statistical machine
translation. In Proc. of the 40th Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 295–302, Philadelphia, PA, July.
F. J. Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proc. of the 41th Annual
Meeting ofthe Association for Computational Linguis-
tics (ACL), pages 160–167, Sapporo, Japan, July.
K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proc. of the 40th Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 311–318, Philadelphia, PA, July.
T. Takezawa, E. Sumita, F. Sugaya, H. Yamamoto, and
S. Yamamoto. 2002. Toward a broad-coverage bilin-
gual corpus for speech translation of travel conver-
sations in the real world. In Proc. of the Third Int.
Conf. on Language Resources and Evaluation (LREC),
pages 147–152, Las Palmas, Spain, May.
R. Zens and H. Ney. 2004. Improvements in phrase-
based statistical machine translation. In Proc. of the
Human Language Technology Conf. (HLT-NAACL),
pages 257–264, Boston, MA, May.
R. Zens, O. Bender, S. Hasan, S. Khadivi, E. Matusov,
J. Xu, Y. Zhang, and H. Ney. 2005. The RWTH
phrase-based statistical machine translation system. In
Proceedings of the International Workshop on Spoken
Language Translation (IWSLT), pages 155–162, Pitts-
burgh, PA, October.
</reference>
<page confidence="0.999031">
22
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.761559">
<title confidence="0.999592">Morpho-syntactic Arabic Preprocessing for Arabic-to-English Machine Translation</title>
<author confidence="0.999234">Anas El_Isbihani Shahram Khadivi Oliver Bender Hermann Ney</author>
<affiliation confidence="0.9295435">Lehrstuhl f¨ur Informatik VI - Computer Science RWTH Aachen</affiliation>
<address confidence="0.989618">D-52056 Aachen,</address>
<abstract confidence="0.992679266666667">The Arabic language has far richer systems of inflection and derivation than English which has very little morphology. This morphology difference causes a large gap between the vocabulary sizes in any given parallel training corpus. Segmentation of inflected Arabic words is a way to smooth its highly morphological nature. In this paper, we describe some statistically and linguistically motivated methods for Arabic word segmentation. Then, we show the efficiency of proposed methods on the Arabic-English BTEC and NIST tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J Cocke</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>F Jelinek</author>
<author>J D Lafferty</author>
<author>R L Mercer</author>
<author>P S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="5323" citStr="Brown et al., 1990" startWordPosition="890" endWordPosition="893">anguage sentences, we will choose the sentence with the highest probability: e ˆI {Pr(eI1|fJ1 )} (1) 1 = argmax I,eI1 The posterior probability Pr(eI1|fJ1 ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): (�M ) exp m=1 λmhm(eI 1, fJ 1 ) E exp (EM1 λmhm(el I/ 1 , fJ1 )) e/I/ 1 (2) The denominator represents a normalization factor that depends only on the source sentence fJ1 . Therefore, we can omit it during the search process. As a decision rule, we obtain: � M E � λmhm(eI1,fJ1 ) (3) m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f|e) and p(e|f). Additionally, we use a word penalty and a phrase penalty. More details about the baseline system can be found in (Zens an</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and P. S. Roossin. 1990. A statistical approach to machine translation. Computational Linguistics, 16(2):79–85, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Diab</author>
<author>K Hacioglu</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic tagging of arabic text: From raw text to base phrase chunks.</title>
<date>2004</date>
<booktitle>HLT-NAACL 2004: Short Papers,</booktitle>
<volume>2</volume>
<pages>-</pages>
<editor>In D. M. Susan Dumais and S. Roukos, editors,</editor>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="3265" citStr="Diab et al., 2004" startWordPosition="535" endWordPosition="538">fficient alignment. In order to deal with this problem and to improve the performance of statistical machine translation, each word must be decomposed into its parts. In (Larkey et al., 2002) it was already shown that word segmentation for Arabic improves information retrieval. In (Lee et al., 2003) a statistical approach for Arabic word segmentation was presented. It decomposes each word into a sequence of morphemes (prefixes-stem-suffixes), where all possible prefixes and suffixes (not only those we described in Table 1 and 2) are split from the original word. A comparable work was done by (Diab et al., 2004), where a POS tagging method for Arabic is also discussed. As we have access to this tool, we test its impact on the performance of our translation system. In 15 Proceedings of the Workshop on Statistical Machine Translation, pages 15–22, New York City, June 2006. c�2006 Association for Computational Linguistics Table 1: Prefixes handled in this work and their meanings. Prefix 9 j d J u J► Transliteration w f k l b Al Meaning and and then as, like in order to with, in the (Habash and Rambow, 2005) a morphology analyzer was used for the segementation and POS tagging. In contrast to the methods </context>
<context position="8341" citStr="Diab et al., 2004" startWordPosition="1437" endWordPosition="1440">n Arabic sentence matches to an article in the target language. One of the reasons is that the adjective in Arabic gets an article if the word it describes is definite. So, if a word has the prefix Al, then its adjective will also have Al as a prefix. In order to reduce the sentence size we decide to remove all these articles that are supposed to be attached to an adjective. Another way for determiner deletion is described in (Lee, 2004). 4 Word Segmentation One way to simplify inflected Arabic text for a SMT system is to split the words in prefixes, stem and suffixes. In (Lee et al., 2003), (Diab et al., 2004) and (Habash and Rambow, 2005) three supervised segmentation methods are introduced. However, in these works the impact of the segmentation on the translation quality is not studied. In the next subsections we will shortly describe the method of (Diab et al., 2004). Then we present our unsupervised methods. 4.1 Supervised Learning Approach (SL) (Diab et al., 2004) propose solutions to word segmentation and POS Tagging of Arabic text. For the purpose of training the Arabic TreeBank is used, which is an Arabic corpus containing news articles of the newswire agency AFP. In the first step the text</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>M. Diab, K. Hacioglu, and D. Jurafsky. 2004. Automatic tagging of arabic text: From raw text to base phrase chunks. In D. M. Susan Dumais and S. Roukos, editors, HLT-NAACL 2004: Short Papers, Boston, Massachusetts, USA, May 2 - May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Diab</author>
</authors>
<title>An unsupervised method for multilingual word sense tagging using parallel corpora: A preliminary investigation.</title>
<date>2000</date>
<booktitle>In ACL-2000 Workshop on Word Senses and Multilinguality,</booktitle>
<pages>1--9</pages>
<location>Hong Kong,</location>
<marker>Diab, 2000</marker>
<rawString>M. Diab. 2000. An unsupervised method for multilingual word sense tagging using parallel corpora: A preliminary investigation. In ACL-2000 Workshop on Word Senses and Multilinguality, pages 1–9, Hong Kong, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram co-occurrence statistics.</title>
<date>2002</date>
<booktitle>In Proc. ARPA Workshop on Human Language Technology.</booktitle>
<contexts>
<context position="16012" citStr="Doddington, 2002" startWordPosition="2802" endWordPosition="2803">T 2002 evaluation set as a development set and NIST 2004 evaluation set as a test set. Because the test set contains four references for each senence we decided to use only the first four references of the development set for the optimization and evaluation. In the BTEC task, C-Star’03 and IWSLT’04 copora are considered as development and test sets, respectively. 5.2 Evaluation Metrics The commonly used criteria to evaluate the translation results in the machine translation community are: WER (word error rate), PER (positionindependent word error rate), BLEU (Papineni et al., 2002), and NIST (Doddington, 2002). The four criteria are computed with respect to multiple references. The number of reference translations per source sentence varies from 4 to 16 references. The evaluation is case-insensitive for BTEC and casesensitive for NIST task. As the BLEU and NIST scores measure accuracy, higher scores are better. 5.3 Translation Results To study the impact of different segmentation methods on the translation quality, we apply different word segmentation methods to the Arabic part of the BTEC and NIST corpora. Then, we make use of the phrase-based machine translation system to translate the developmen</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>G. Doddington. 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In Proc. ARPA Workshop on Human Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>O Rambow</author>
</authors>
<title>Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop.</title>
<date>2005</date>
<booktitle>In Proc. of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>573--580</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="3767" citStr="Habash and Rambow, 2005" startWordPosition="625" endWordPosition="628">y those we described in Table 1 and 2) are split from the original word. A comparable work was done by (Diab et al., 2004), where a POS tagging method for Arabic is also discussed. As we have access to this tool, we test its impact on the performance of our translation system. In 15 Proceedings of the Workshop on Statistical Machine Translation, pages 15–22, New York City, June 2006. c�2006 Association for Computational Linguistics Table 1: Prefixes handled in this work and their meanings. Prefix 9 j d J u J► Transliteration w f k l b Al Meaning and and then as, like in order to with, in the (Habash and Rambow, 2005) a morphology analyzer was used for the segementation and POS tagging. In contrast to the methods mentioned above, our segmentation method is unsupervised and rule based. In this paper we first explain our statistical machine translation (SMT) system used for testing the impact of the different segmentation methods, then we introduce some preprocessing and normalization tools for Arabic and explain the linguistic motivation beyond them. Afterwards, we present three word segmentation methods, a supervised learning approach, a finite state automaton-based segmentation, and a frequency-based meth</context>
<context position="8371" citStr="Habash and Rambow, 2005" startWordPosition="1442" endWordPosition="1445">s to an article in the target language. One of the reasons is that the adjective in Arabic gets an article if the word it describes is definite. So, if a word has the prefix Al, then its adjective will also have Al as a prefix. In order to reduce the sentence size we decide to remove all these articles that are supposed to be attached to an adjective. Another way for determiner deletion is described in (Lee, 2004). 4 Word Segmentation One way to simplify inflected Arabic text for a SMT system is to split the words in prefixes, stem and suffixes. In (Lee et al., 2003), (Diab et al., 2004) and (Habash and Rambow, 2005) three supervised segmentation methods are introduced. However, in these works the impact of the segmentation on the translation quality is not studied. In the next subsections we will shortly describe the method of (Diab et al., 2004). Then we present our unsupervised methods. 4.1 Supervised Learning Approach (SL) (Diab et al., 2004) propose solutions to word segmentation and POS Tagging of Arabic text. For the purpose of training the Arabic TreeBank is used, which is an Arabic corpus containing news articles of the newswire agency AFP. In the first step the text must be transliterated to the</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>N. Habash and O. Rambow. 2005. Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop. In Proc. of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 573–580, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Empirical methods for compound splitting.</title>
<date>2003</date>
<booktitle>In Proc. 10th Conf. of the Europ. Chapter of the Assoc. for Computational Linguistics (EACL),</booktitle>
<pages>347--354</pages>
<location>Budapest, Hungary,</location>
<contexts>
<context position="10030" citStr="Koehn and Knight, 2003" startWordPosition="1724" endWordPosition="1727">es and suffixes and their possible combinations. Based on this set, we may have different splitting points for a given compound word. We decide whether and where to split the composite word based on the frequency of different resulting stems and on the frequency of the compound word, e.g. if the compound word has a higher frequency than all possible stems, it will not be split. This simple heuristic harmonizes the corpus by reducing the size of vocabulary, singletons and also unseen words from the test corpus. This method is very similar to the method used for splitting German compound words (Koehn and Knight, 2003). 4.3 Finite State Automaton-Based Approach (FSA) To segment Arabic words into prefixes, stem and one suffix, we implemented two finite state automata. One for stripping the prefixes and the other for the suffixes. Then, we append the suffix automaton to the other one for stripping prefixes. Figure 1 shows the finite state automaton for stripping all possible prefix combinations. We add the prefix s (_r), which changes the verb tense to the future, to the set of prefixes which must be stripped (see table 1). This prefix can only be combined with w and f. Our motivation is that the future tense</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>P. Koehn and K. Knight. 2003. Empirical methods for compound splitting. In Proc. 10th Conf. of the Europ. Chapter of the Assoc. for Computational Linguistics (EACL), pages 347–354, Budapest, Hungary, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Larkey</author>
<author>L Ballesteros</author>
<author>M E Connell</author>
</authors>
<title>Improving stemming for arabic information retrieval: light stemming and co-occurrence analysis.</title>
<date>2002</date>
<booktitle>In Proc. of the 25th annual of the international Association for Computing Machinery Special Interest Group on Information Retrieval (ACM SIGIR),</booktitle>
<pages>275--282</pages>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2838" citStr="Larkey et al., 2002" startWordPosition="464" endWordPosition="467">r suffixes that are not handled here, such as At (ul), An ( 0l) and wn (09) which make the plural form of a word. The reason why we omit them is that they do not have their own meaning. The impact of Arabic morphology is that the vocabulary size and the number of singletons can be dramatically high, i.e. the Arabic words are not seen often enough to be learned by statistical machine translation models. This can lead to an inefficient alignment. In order to deal with this problem and to improve the performance of statistical machine translation, each word must be decomposed into its parts. In (Larkey et al., 2002) it was already shown that word segmentation for Arabic improves information retrieval. In (Lee et al., 2003) a statistical approach for Arabic word segmentation was presented. It decomposes each word into a sequence of morphemes (prefixes-stem-suffixes), where all possible prefixes and suffixes (not only those we described in Table 1 and 2) are split from the original word. A comparable work was done by (Diab et al., 2004), where a POS tagging method for Arabic is also discussed. As we have access to this tool, we test its impact on the performance of our translation system. In 15 Proceedings</context>
</contexts>
<marker>Larkey, Ballesteros, Connell, 2002</marker>
<rawString>L. S. Larkey, L. Ballesteros, and M. E. Connell. 2002. Improving stemming for arabic information retrieval: light stemming and co-occurrence analysis. In Proc. of the 25th annual of the international Association for Computing Machinery Special Interest Group on Information Retrieval (ACM SIGIR), pages 275–282, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Lee</author>
<author>K Papineni</author>
<author>S Roukos</author>
<author>O Emam</author>
<author>H Hassan</author>
</authors>
<title>Language model based Arabic word segmentation.</title>
<date>2003</date>
<booktitle>Proc. of the 41st Annual Meeting ofthe Association for Computational Linguistics.</booktitle>
<editor>In E. Hinrichs and D. Roth, editors,</editor>
<contexts>
<context position="2947" citStr="Lee et al., 2003" startWordPosition="482" endWordPosition="485">. The reason why we omit them is that they do not have their own meaning. The impact of Arabic morphology is that the vocabulary size and the number of singletons can be dramatically high, i.e. the Arabic words are not seen often enough to be learned by statistical machine translation models. This can lead to an inefficient alignment. In order to deal with this problem and to improve the performance of statistical machine translation, each word must be decomposed into its parts. In (Larkey et al., 2002) it was already shown that word segmentation for Arabic improves information retrieval. In (Lee et al., 2003) a statistical approach for Arabic word segmentation was presented. It decomposes each word into a sequence of morphemes (prefixes-stem-suffixes), where all possible prefixes and suffixes (not only those we described in Table 1 and 2) are split from the original word. A comparable work was done by (Diab et al., 2004), where a POS tagging method for Arabic is also discussed. As we have access to this tool, we test its impact on the performance of our translation system. In 15 Proceedings of the Workshop on Statistical Machine Translation, pages 15–22, New York City, June 2006. c�2006 Associatio</context>
<context position="8320" citStr="Lee et al., 2003" startWordPosition="1433" endWordPosition="1436">t every article in an Arabic sentence matches to an article in the target language. One of the reasons is that the adjective in Arabic gets an article if the word it describes is definite. So, if a word has the prefix Al, then its adjective will also have Al as a prefix. In order to reduce the sentence size we decide to remove all these articles that are supposed to be attached to an adjective. Another way for determiner deletion is described in (Lee, 2004). 4 Word Segmentation One way to simplify inflected Arabic text for a SMT system is to split the words in prefixes, stem and suffixes. In (Lee et al., 2003), (Diab et al., 2004) and (Habash and Rambow, 2005) three supervised segmentation methods are introduced. However, in these works the impact of the segmentation on the translation quality is not studied. In the next subsections we will shortly describe the method of (Diab et al., 2004). Then we present our unsupervised methods. 4.1 Supervised Learning Approach (SL) (Diab et al., 2004) propose solutions to word segmentation and POS Tagging of Arabic text. For the purpose of training the Arabic TreeBank is used, which is an Arabic corpus containing news articles of the newswire agency AFP. In th</context>
</contexts>
<marker>Lee, Papineni, Roukos, Emam, Hassan, 2003</marker>
<rawString>Y. S. Lee, K. Papineni, S. Roukos, O. Emam, and H. Hassan. 2003. Language model based Arabic word segmentation. In E. Hinrichs and D. Roth, editors, Proc. of the 41st Annual Meeting ofthe Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Lee</author>
</authors>
<title>Morphological analysis for statistical machine translation.</title>
<date>2004</date>
<booktitle>HLT-NAACL 2004: Short Papers,</booktitle>
<volume>2</volume>
<pages>57--60</pages>
<editor>In D. M. Susan Dumais and S. Roukos, editors,</editor>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="8164" citStr="Lee, 2004" startWordPosition="1406" endWordPosition="1407"> all diacritics. After segmenting the text, the size of the sentences increases rapidly, where the number of the stripped article Al is very high. Not every article in an Arabic sentence matches to an article in the target language. One of the reasons is that the adjective in Arabic gets an article if the word it describes is definite. So, if a word has the prefix Al, then its adjective will also have Al as a prefix. In order to reduce the sentence size we decide to remove all these articles that are supposed to be attached to an adjective. Another way for determiner deletion is described in (Lee, 2004). 4 Word Segmentation One way to simplify inflected Arabic text for a SMT system is to split the words in prefixes, stem and suffixes. In (Lee et al., 2003), (Diab et al., 2004) and (Habash and Rambow, 2005) three supervised segmentation methods are introduced. However, in these works the impact of the segmentation on the translation quality is not studied. In the next subsections we will shortly describe the method of (Diab et al., 2004). Then we present our unsupervised methods. 4.1 Supervised Learning Approach (SL) (Diab et al., 2004) propose solutions to word segmentation and POS Tagging o</context>
</contexts>
<marker>Lee, 2004</marker>
<rawString>Y. S. Lee. 2004. Morphological analysis for statistical machine translation. In D. M. Susan Dumais and S. Roukos, editors, HLT-NAACL 2004: Short Papers, pages 57–60, Boston, Massachusetts, USA, May 2 -May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>295--302</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="4949" citStr="Och and Ney, 2002" startWordPosition="816" endWordPosition="819">entation, and a frequency-based method. In Section 5, the experimental results are presented. Finally, the paper is summarized in Section 6 . 2 Baseline SMT System In statistical machine translation, we are given a source language sentence fJ1 = f1 ... fj ... fJ, which is to be translated into a target language sentence eI1 = e1 ... ei ... eI. Among all possible target language sentences, we will choose the sentence with the highest probability: e ˆI {Pr(eI1|fJ1 )} (1) 1 = argmax I,eI1 The posterior probability Pr(eI1|fJ1 ) is modeled directly using a log-linear combination of several models (Och and Ney, 2002): (�M ) exp m=1 λmhm(eI 1, fJ 1 ) E exp (EM1 λmhm(el I/ 1 , fJ1 )) e/I/ 1 (2) The denominator represents a normalization factor that depends only on the source sentence fJ1 . Therefore, we can omit it during the search process. As a decision rule, we obtain: � M E � λmhm(eI1,fJ1 ) (3) m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM1 are trained with respect to the final translation quality measured by an error criterion (Och, </context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>F. J. Och and H. Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 295–302, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of the 41th Annual Meeting ofthe Association for Computational Linguistics (ACL),</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="5554" citStr="Och, 2003" startWordPosition="931" endWordPosition="932">2002): (�M ) exp m=1 λmhm(eI 1, fJ 1 ) E exp (EM1 λmhm(el I/ 1 , fJ1 )) e/I/ 1 (2) The denominator represents a normalization factor that depends only on the source sentence fJ1 . Therefore, we can omit it during the search process. As a decision rule, we obtain: � M E � λmhm(eI1,fJ1 ) (3) m=1 This approach is a generalization of the sourcechannel approach (Brown et al., 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f|e) and p(e|f). Additionally, we use a word penalty and a phrase penalty. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 3 Preprocessing and Normalization Tools 3.1 Tokenizer As for other languages, the corpora must be first tokenized. Here words and punctuations (except abbreviation) must be separated. Another criter</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. J. Och. 2003. Minimum error rate training in statistical machine translation. In Proc. of the 41th Annual Meeting ofthe Association for Computational Linguistics (ACL), pages 160–167, Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W J Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="15983" citStr="Papineni et al., 2002" startWordPosition="2796" endWordPosition="2799"> NIST task, we make use of the NIST 2002 evaluation set as a development set and NIST 2004 evaluation set as a test set. Because the test set contains four references for each senence we decided to use only the first four references of the development set for the optimization and evaluation. In the BTEC task, C-Star’03 and IWSLT’04 copora are considered as development and test sets, respectively. 5.2 Evaluation Metrics The commonly used criteria to evaluate the translation results in the machine translation community are: WER (word error rate), PER (positionindependent word error rate), BLEU (Papineni et al., 2002), and NIST (Doddington, 2002). The four criteria are computed with respect to multiple references. The number of reference translations per source sentence varies from 4 to 16 references. The evaluation is case-insensitive for BTEC and casesensitive for NIST task. As the BLEU and NIST scores measure accuracy, higher scores are better. 5.3 Translation Results To study the impact of different segmentation methods on the translation quality, we apply different word segmentation methods to the Arabic part of the BTEC and NIST corpora. Then, we make use of the phrase-based machine translation syste</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 311–318, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Takezawa</author>
<author>E Sumita</author>
<author>F Sugaya</author>
<author>H Yamamoto</author>
<author>S Yamamoto</author>
</authors>
<title>Toward a broad-coverage bilingual corpus for speech translation of travel conversations in the real world.</title>
<date>2002</date>
<booktitle>In Proc. of the Third Int. Conf. on Language Resources and Evaluation (LREC),</booktitle>
<pages>147--152</pages>
<location>Las Palmas, Spain,</location>
<contexts>
<context position="15149" citStr="Takezawa et al., 2002" startWordPosition="2648" endWordPosition="2651">above to generate negative properties which avoid the corresponding kind of splitting. If a property and its negation belong to the same word then the property is removed and only the negation is considered. At the end each word is split corresponding to the properties it is marked with. 5 Experimental Results 5.1 Corpus Statistics The experiments were carried out on two tasks: the corpora of the Arabic-English NIST task, which contain news articles and UN reports, and the Arabic-English corpus of the Basic Travel Expression Corpus (BTEC) task, which consists of typical travel domain phrases (Takezawa et al., 2002). The corpus statistics of the NIST and BTEC corpora are shown in Table 3 and 5. The statistics of the news part of NIST corpus, consisting of the Ummah, ATB, ANEWS1 and eTIRR corpora, is shown in Table 4. In the NIST task, we make use of the NIST 2002 evaluation set as a development set and NIST 2004 evaluation set as a test set. Because the test set contains four references for each senence we decided to use only the first four references of the development set for the optimization and evaluation. In the BTEC task, C-Star’03 and IWSLT’04 copora are considered as development and test sets, re</context>
</contexts>
<marker>Takezawa, Sumita, Sugaya, Yamamoto, Yamamoto, 2002</marker>
<rawString>T. Takezawa, E. Sumita, F. Sugaya, H. Yamamoto, and S. Yamamoto. 2002. Toward a broad-coverage bilingual corpus for speech translation of travel conversations in the real world. In Proc. of the Third Int. Conf. on Language Resources and Evaluation (LREC), pages 147–152, Las Palmas, Spain, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Improvements in phrasebased statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proc. of the Human Language Technology Conf. (HLT-NAACL),</booktitle>
<pages>257--264</pages>
<location>Boston, MA,</location>
<contexts>
<context position="5934" citStr="Zens and Ney, 2004" startWordPosition="990" endWordPosition="993">, 1990). It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f|e) and p(e|f). Additionally, we use a word penalty and a phrase penalty. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 3 Preprocessing and Normalization Tools 3.1 Tokenizer As for other languages, the corpora must be first tokenized. Here words and punctuations (except abbreviation) must be separated. Another criterion is that Arabic has some characters that appear only at the end of a word. We use this criterion to separate words that are wrongly attached to each other. 3.2 Normalization and Simplification The Arabic written language does not contain vowels, instead diacritics are used to define the pronunciation of a word, where a diacritic is written under or above each character in th</context>
</contexts>
<marker>Zens, Ney, 2004</marker>
<rawString>R. Zens and H. Ney. 2004. Improvements in phrasebased statistical machine translation. In Proc. of the Human Language Technology Conf. (HLT-NAACL), pages 257–264, Boston, MA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>O Bender</author>
<author>S Hasan</author>
<author>S Khadivi</author>
<author>E Matusov</author>
<author>J Xu</author>
<author>Y Zhang</author>
<author>H Ney</author>
</authors>
<title>The RWTH phrase-based statistical machine translation system.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<pages>155--162</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="5954" citStr="Zens et al., 2005" startWordPosition="994" endWordPosition="997">advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM1 are trained with respect to the final translation quality measured by an error criterion (Och, 2003). We use a state-of-the-art phrase-based translation system including the following models: an n-gram language model, a phrase translation model and a word-based lexicon model. The latter two models are used for both directions: p(f|e) and p(e|f). Additionally, we use a word penalty and a phrase penalty. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 3 Preprocessing and Normalization Tools 3.1 Tokenizer As for other languages, the corpora must be first tokenized. Here words and punctuations (except abbreviation) must be separated. Another criterion is that Arabic has some characters that appear only at the end of a word. We use this criterion to separate words that are wrongly attached to each other. 3.2 Normalization and Simplification The Arabic written language does not contain vowels, instead diacritics are used to define the pronunciation of a word, where a diacritic is written under or above each character in the word. Usually thes</context>
</contexts>
<marker>Zens, Bender, Hasan, Khadivi, Matusov, Xu, Zhang, Ney, 2005</marker>
<rawString>R. Zens, O. Bender, S. Hasan, S. Khadivi, E. Matusov, J. Xu, Y. Zhang, and H. Ney. 2005. The RWTH phrase-based statistical machine translation system. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT), pages 155–162, Pittsburgh, PA, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>