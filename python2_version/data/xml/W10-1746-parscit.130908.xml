<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012173">
<title confidence="0.964296">
JHU System Combination Scheme for WMT 2010
</title>
<author confidence="0.969576">
Sushant Narsale
</author>
<affiliation confidence="0.958137">
Johns Hopkins University
</affiliation>
<address confidence="0.590378">
Baltimore, USA.
</address>
<email confidence="0.995659">
sushant@jhu.edu
</email>
<sectionHeader confidence="0.993807" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999774789473684">
This paper describes the JHU system
combination scheme that was used in
the WMT 2010 submission. The in-
cremental alignment scheme of (Karakos
et.al, 2008) was used for confusion net-
work generation. The system order
in the alignment of each sentence was
learned using SVMs, following the work
of (Karakos et.al, 2010). Additionally,
web-scale n-grams from the Google cor-
pus were used to build language models
that improved the quality of the combi-
nation output. Experiments in Spanish-
English, French-English, German-English
and Czech-English language pairs were
conducted, and the results show approxi-
mately 1 BLEU point and 2 TER points
improvement over the best individual sys-
tem.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99995464">
System Combination refers to the method of com-
bining output of multiple MT systems, to pro-
duce a output better than each individual system.
Currently, there are several approaches to ma-
chine translation which can be classified as phrase-
based, hierarchical, syntax-based (Hildebrand and
Vogel, 2008) which are equally good in their trans-
lation quality even though the underlying frame-
works are completely different. The motivation
behind System Combination arises from this di-
versity in the state-of-art MT systems, which sug-
gests that systems with different paradigms make
different errors, and can be made better by com-
bining their strengths.
One approach of combining translations is
based on representing translations by confusion
network and then aligning these confusion net-
works using string alignment algorithms (Rosti
et.al, 2009), (Karakos and Khudanpur, 2008).
Another approach generates features for every
translation to train algorithms for ranking systems
based on their quality and the top ranking output
is considered to be a candidate translation, (Hilde-
brand and Vogel, 2008) is an example of ranking
based combination. We use ideas from ranking
based approaches to learn order in which systems
should be aligned in a confusion network based
approach.
Our approach is based on incremental align-
ment of confusion networks (Karakos et.al, 2008),
wherein each system output is represented by a
confusion network. The confusion networks are
then aligned in a pre-defined order to generate a
combination output. This paper contributes two
enhancements to (Karakos et.al, 2008). First,
use of Support Vector Machines to learn order in
which the system outputs should be aligned. Sec-
ond, we explore use of Google n-grams for build-
ing dynamic language model and interpolate the
resulting language model with a large static lan-
guage model for rescoring of system combination
outputs.
The rest of the paper is organized as follows:
Section 2 illustrates the idea and pipeline of the
baseline combination system; Section 3 gives de-
tails of SVM ranking for learning system order
for combination; Section 4 explains use of Google
n-gram based language models; Results are dis-
cussed in Section 5; Concluding remarks are given
in Section 6;
</bodyText>
<sectionHeader confidence="0.966818" genericHeader="method">
2 Baseline System Combination
</sectionHeader>
<bodyText confidence="0.996249">
This section summarizes the algorithm for base-
line combination. The baseline combination
pipeline includes three stages:
</bodyText>
<listItem confidence="0.8790955">
1. Representing translations by confusion net-
works.
</listItem>
<page confidence="0.904525">
311
</page>
<note confidence="0.3756155">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 311–314,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<listItem confidence="0.998541">
2. Generating between system confusion net-
works.
3. Rescoring the final confusion network.
</listItem>
<bodyText confidence="0.996328166666667">
Confusion networks are compressed form of
lattices with a constraint that all paths should pass
through all nodes. Each system output is repre-
sented by an equivalent confusion network. The
per-system confusion networks are aligned one at
a time. The order in which systems are aligned
is usually decided by evaluation of system’s per-
formance. Two alternatives for deciding the sys-
tem order are discussed in Section 3. Inversion-
Transduction Grammar (Wu, 1997) is used for
alignments and the cost function for aligning two
confusion networks is
</bodyText>
<equation confidence="0.976725">
1
|b1||b2 |wE vE c(v)c(w)1(w � v)
</equation>
<bodyText confidence="0.998723857142857">
where b1 and b2 are two different bins, |b1 |and |b2|
is the number of tokens in b1 and b2 respectively,
c(v) and c(w) are the number of words of token
v and token w. which are in b1 and b2 separately.
The idea of this cost is to compute the probability
that a word from bin b1 is not equal to a word from
bin b2.
</bodyText>
<equation confidence="0.708748">
cost(b1, b2) = Prob(v =� w, v E b1, w E b2)
</equation>
<bodyText confidence="0.999975083333333">
The final confusion network is rescored with a
5-gram language model with Kneser-Ney smooth-
ing. To generate the final output, we need to find
the best (minimum-cost) path through the rescored
confusion network. In the best path every bin in
the network contributes only one word to the out-
put.
Ordering the systems for incremental combina-
tion and use of different language models were the
two components of the pipeline that were experi-
mented with for WMT’2010 shared task. The fol-
lowing sections describe these variations in detail.
</bodyText>
<sectionHeader confidence="0.966712" genericHeader="method">
3 Learning to Order Systems for
Combination
</sectionHeader>
<bodyText confidence="0.999411428571429">
Determining the order in which systems are
aligned is critical step in our system combination
process. The first few aligned translations/systems
determine the word ordering in the final output and
have a significant influence on the final transla-
tion quality. For the baseline combination the sys-
tems are aligned in the increasing order of (TER-
BLEU) scores. TER and BLEU (Papineni et.al,
2002) scores are calculated over all the sentences
in the training set. This approach to ordering of
systems is static and results in a global order for
all the source segments. An alternative approach
is to learn local order of systems for every source
sentence using a SVM ranker.
</bodyText>
<subsectionHeader confidence="0.990378">
3.1 SVM Rank Method
</subsectionHeader>
<bodyText confidence="0.9999824">
This section describes an approach to order sys-
tems for alignment using SVMs (Karakos et.al,
2010). For each system output a number of fea-
tures are generated, the features fall broadly under
the following three categories:
</bodyText>
<subsectionHeader confidence="0.892436">
N-gram Agreements
</subsectionHeader>
<bodyText confidence="0.999903555555556">
These features capture the percentage of hypoth-
esis for a source sentence that contain same n-
grams as the candidate translation under consid-
eration. The n-gram matching is position indepen-
dent because phrases often appear in different or-
ders in sentences with same meaning and correct
grammar. The scores for each n-gram are summed
and normalized by sentence length. N-grams of
length 1 · · · 5 are used as five features.
</bodyText>
<subsectionHeader confidence="0.71659">
Length Feature
</subsectionHeader>
<bodyText confidence="0.999776666666667">
The ratio of length of the translation to the source
sentence is a good indication of quality of the
translation, for a lengthy source sentence a short
translation is most likely to be bad. Here, the ra-
tio of source sentence length to length of the target
sentence is calculated.
</bodyText>
<subsectionHeader confidence="0.874232">
Language Model Features
</subsectionHeader>
<bodyText confidence="0.998877">
Language models for target language are used to
calculate perplexity of a given translation. The
lower the perplexity the better is the translation
quality. We use two different language models:
(i) a large static 5-gram language model and (ii)a
dynamic language model generated from all the
translations of the same source segment. The
perplexity values are normalized by sentence
length.
Translations in training set are ranked based
on (TER-BLEU) scores. An SVM ranker is then
trained on this set. The SVM ranker (Joachims,
2002) returns a score for each translation, based
on its signed distance from the separating hyper-
plane. This value is used in the combination pro-
cess to weight the contribution of systems to the
final confusion network scores.
</bodyText>
<equation confidence="0.995174">
cost(b1,b2) =
</equation>
<page confidence="0.999296">
312
</page>
<tableCaption confidence="0.998272">
Table 1: Results for all Language pairs on development set
</tableCaption>
<table confidence="0.9991185">
Combination es-en fr-en cz-en de-en
BLEU TER BLEU TER BLEU TER BLEU TER
BEST SYSTEM 29.27 52.38 26.74 56.88 21.56 58.24 26.53 56.87
BASELINE 28.57 51.61 27.65 55.20 21.01 58.79 26.80 54.54
SVM 28.68 51.99 27.53 55.35 21.56 58.24 26.85 54.9
SVM+NGRAM 29.92 50.92 27.86 55.06 21.80 57.78 27.24 54.86
</table>
<sectionHeader confidence="0.985617" genericHeader="method">
4 Language Models
</sectionHeader>
<bodyText confidence="0.999985090909091">
In the system combination process, the final con-
fusion networks are rescored with language mod-
els. Language models are widely used to en-
sure a fluent output translation. I explored use of
two language models. The first language model
was trained on the English side of French-English
corpus, UN corpus and English Gigaword cor-
pus made available by WMT. The second lan-
guage model used counts generated from Google
n-grams. It was trained by generating all 1-gram
to 5-grams in the system outputs for a source
segment and then using the N-gram search en-
gine (Lin et.al, 2010) built over Google n-grams
to get the corresponding n-gram counts. The n-
gram counts were used to train a 5-gram language
model with Kneser-Ney smoothing. SRILM
toolkit (Stockle, 2002) was used for training the
language models.
The baseline combinations were rescored only
with the static language model. I always did a
weighted interpolation of the two language mod-
els when using n-gram based language model.
</bodyText>
<sectionHeader confidence="0.999929" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.978601209302326">
Results for four language pairs: Spanish-English,
French-English, Czech-English and German-
English are presented. The training data for
WMT’10 was divided into development and test
set, consisting of 208 and 247 segments respec-
tively. Table 1 shows TER and BLEU scores
on the TEST set for all the four language pairs
in the following settings: (i) Baseline corre-
sponds to procedure described in section 2, (ii)
SVM corresponds to using SVM ranker for learn-
ing order of systems as described in section 3.1
(iii)SVM+N-Grams corresponds to the use of a
SVM ranker along with weighted interpolation of
n-gram language model and the large static lan-
guage model. The ranking SVM was trained us-
ing SVM-light (Joachims, 2002) with a RBF ker-
nel. Two-fold cross-validation was done to pre-
vent over-fitting on development data. All the
scores are with lower-cased outputs, a tri-gram
language model was used to true-case the output
before the final submission. 1-best output from
only the primary systems were used for combina-
tion. The number of systems used for combination
in each language pair are: 6 for Czech-English,
8 in Spanish-English, 14 in French-English and
16 in German-English. The best results for base-
line combination were obtained with 3 systems
for Czech-English, 6 systems for German-English,
3 systems for Spanish-English and 9 systems for
French-English.
From the results, we conclude that for all lan-
guage pairs the combinations with SVM and n-
gram language models show gain over all the other
settings in both TER and BLEU evaluations. How-
ever, use of SVM with only one large language
model shows performance degradation on three
out of four language pairs. Size of training data
(208 segments) could be one reason for the degra-
dation and this issue needs further investigation.
For the final submission, the settings that per-
formed the best on (TER−BLEU) scale were cho-
2
sen.
</bodyText>
<sectionHeader confidence="0.99879" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999956916666667">
The system combination task gave us an opportu-
nity to evaluate enhancements added to the JHU
system combination pipeline. Experimental re-
sults show that web-scale language models can be
used to improve translation quality, this further un-
derlines the usefulness of web-scale resources like
Google n-grams. Further investigation is needed
to completely understand the reasons for incon-
sistency in the magnitude of gain across different
language pairs. Specifically the impact of training
data on SVMs for ranking in system combination
scenario needs to be analysed.
</bodyText>
<page confidence="0.999122">
313
</page>
<sectionHeader confidence="0.998332" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999903777777778">
This work was partially supported by the DARPA
GALE program Grant No HR0022-06-2-0001. I
would like to thank all the participants of WMT
2010 for their system outputs. I would also like
to thank Prof. Damianos Karakos for his guidance
and support. Many thanks go to the Center for
Language and Speech Processing at Johns Hop-
kins University for availability of their computer
clusters.
</bodyText>
<sectionHeader confidence="0.997809" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995242122807018">
Almut Silja Hildebrand and Stephan Vogel. 2008.
Combination of Machine Translation Systems via
Hypothesis Selection from Combined N-Best Lists.
In MT at work: Proceedings of the Eight Conference
of Association of Machine Translation in the Amer-
icas, pages 254-261, Waikiki, Hawaii, October. As-
sociation for Machine Translations in the Americas.
Almut Silja Hildebrand and Stephan Vogel. 2009.
CMU System Combination for WMT’09. Proceed-
ings of Fourth Workshop on Statistical Machine
Translation,Athen,Greece, March 2009.
Andreas Stockle. 2002. Srilm - an extensible language
modeling toolkit. In Proceedings International Con-
ference for Spoken Language Processing, Denver,
Colarado, September.
Antti-Veikko I. Rosti and Necip Fazil Ayan and Bing
Xiang and Spyros Matsoukas and Richard Schwartz
and Bonnie J. Dorr 2007. Combining Outputs from
Multiple Machine Translation Systems. In Proceed-
ings of the Third Workshop on Statistical Machine
Transaltion, pages 183-186, Colombus, Ohio, June.
Association for Computational Linguistics.
Damianos Karakos and Sanjeev Khudanpur 2008. Se-
quential System Combination for Machine Transla-
tion of Speech. In Proceedings of IEEE SLT-08, De-
cember 2008.
Damianos Karakos and Jason Smith and Sanjeev Khu-
danpur 2010. Hypothesis Ranking and Two-pass
Approaches for Machine Translation System Com-
bination. In Proceedings of ICASSP-2010, Dallas,
Texas, March 14-19 2010.
Damianos Karakos and Jason Eisner and Sanjeev Khu-
danpur and Markus Dreyer. 2008. Machine Trans-
lation system combination using ITG-based align-
ments. In Proceedings of ACL-08: HLT, Short Pa-
pers, pages 81-84, Colombus, Ohio, June. Associa-
tion for Computational Linguistics.
Dekang Lin and Kenneth Church and Heng Ji and
Satoshi Sekine and David Yarowsky and Shane
Bergsma and Kailash Patil and Emily Pitler Rachel
Lathbury and Vikram Rao and Kapil Dalwani and
Sushant Narsale 2010. New Tools for Web-Scale
N-grams. In the Proceedings of LREC, 2010.
D. Wu 1997. Stochastic inversion transduction gram-
mars and bilingual parsing of parallel corpora.
Computational Linguistics, vol.23,no.3,pp.377-403,
September 1997.
Kishore Papineni and Salim Roukos and Todd Ward
and Wei-Jing Zhu. 2002. BLEU: A method for
automatic evaluation of machine translation. In
Proceedings of 40th Annual Meeting of Associa-
tion for Computational Linguistics, pages 311-318.
Philadelphia, PA, July.
Thorsten Joachims 2002. Optimizing Search Engines
using Clickthrough Data. In Proceedings of ACM
Conference on Knowledge Discovery and Data Min-
ing(KDD), 2002.
</reference>
<page confidence="0.999134">
314
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.208067">
<title confidence="0.5740885">JHU System Combination Scheme for WMT 2010 Sushant</title>
<author confidence="0.738092">Johns Hopkins</author>
<affiliation confidence="0.626218">Baltimore,</affiliation>
<email confidence="0.999873">sushant@jhu.edu</email>
<abstract confidence="0.98800815">This paper describes the JHU system combination scheme that was used in the WMT 2010 submission. The incremental alignment scheme of (Karakos 2008) was used for confusion network generation. The system in the alignment of each sentence was learned using SVMs, following the work of (Karakos et.al, 2010). Additionally, web-scale n-grams from the Google corpus were used to build language models that improved the quality of the combination output. Experiments in Spanish- English, French-English, German-English and Czech-English language pairs were conducted, and the results show approximately 1 BLEU point and 2 TER points improvement over the best individual system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Almut Silja Hildebrand</author>
<author>Stephan Vogel</author>
</authors>
<title>Combination of Machine Translation Systems via Hypothesis Selection from Combined N-Best Lists.</title>
<date>2008</date>
<booktitle>In MT at work: Proceedings of the Eight Conference of Association of Machine Translation in the Americas,</booktitle>
<pages>254--261</pages>
<location>Waikiki, Hawaii,</location>
<contexts>
<context position="1120" citStr="Hildebrand and Vogel, 2008" startWordPosition="167" endWordPosition="170">rpus were used to build language models that improved the quality of the combination output. Experiments in SpanishEnglish, French-English, German-English and Czech-English language pairs were conducted, and the results show approximately 1 BLEU point and 2 TER points improvement over the best individual system. 1 Introduction System Combination refers to the method of combining output of multiple MT systems, to produce a output better than each individual system. Currently, there are several approaches to machine translation which can be classified as phrasebased, hierarchical, syntax-based (Hildebrand and Vogel, 2008) which are equally good in their translation quality even though the underlying frameworks are completely different. The motivation behind System Combination arises from this diversity in the state-of-art MT systems, which suggests that systems with different paradigms make different errors, and can be made better by combining their strengths. One approach of combining translations is based on representing translations by confusion network and then aligning these confusion networks using string alignment algorithms (Rosti et.al, 2009), (Karakos and Khudanpur, 2008). Another approach generates </context>
</contexts>
<marker>Hildebrand, Vogel, 2008</marker>
<rawString>Almut Silja Hildebrand and Stephan Vogel. 2008. Combination of Machine Translation Systems via Hypothesis Selection from Combined N-Best Lists. In MT at work: Proceedings of the Eight Conference of Association of Machine Translation in the Americas, pages 254-261, Waikiki, Hawaii, October. Association for Machine Translations in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Almut Silja Hildebrand</author>
<author>Stephan Vogel</author>
</authors>
<title>CMU System Combination for WMT’09.</title>
<date>2009</date>
<booktitle>Proceedings of Fourth Workshop on Statistical Machine Translation,Athen,Greece,</booktitle>
<marker>Hildebrand, Vogel, 2009</marker>
<rawString>Almut Silja Hildebrand and Stephan Vogel. 2009. CMU System Combination for WMT’09. Proceedings of Fourth Workshop on Statistical Machine Translation,Athen,Greece, March 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stockle</author>
</authors>
<title>Srilm - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings International Conference for Spoken Language Processing,</booktitle>
<location>Denver, Colarado,</location>
<contexts>
<context position="8642" citStr="Stockle, 2002" startWordPosition="1401" endWordPosition="1402"> fluent output translation. I explored use of two language models. The first language model was trained on the English side of French-English corpus, UN corpus and English Gigaword corpus made available by WMT. The second language model used counts generated from Google n-grams. It was trained by generating all 1-gram to 5-grams in the system outputs for a source segment and then using the N-gram search engine (Lin et.al, 2010) built over Google n-grams to get the corresponding n-gram counts. The ngram counts were used to train a 5-gram language model with Kneser-Ney smoothing. SRILM toolkit (Stockle, 2002) was used for training the language models. The baseline combinations were rescored only with the static language model. I always did a weighted interpolation of the two language models when using n-gram based language model. 5 Results Results for four language pairs: Spanish-English, French-English, Czech-English and GermanEnglish are presented. The training data for WMT’10 was divided into development and test set, consisting of 208 and 247 segments respectively. Table 1 shows TER and BLEU scores on the TEST set for all the four language pairs in the following settings: (i) Baseline correspo</context>
</contexts>
<marker>Stockle, 2002</marker>
<rawString>Andreas Stockle. 2002. Srilm - an extensible language modeling toolkit. In Proceedings International Conference for Spoken Language Processing, Denver, Colarado, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Necip Fazil Ayan</author>
<author>Bing Xiang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Combining Outputs from Multiple Machine Translation Systems.</title>
<date>2007</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Transaltion,</booktitle>
<pages>183--186</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Colombus, Ohio,</location>
<marker>Rosti, Ayan, Xiang, Matsoukas, Schwartz, Dorr, 2007</marker>
<rawString>Antti-Veikko I. Rosti and Necip Fazil Ayan and Bing Xiang and Spyros Matsoukas and Richard Schwartz and Bonnie J. Dorr 2007. Combining Outputs from Multiple Machine Translation Systems. In Proceedings of the Third Workshop on Statistical Machine Transaltion, pages 183-186, Colombus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Damianos Karakos</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Sequential System Combination for Machine Translation of Speech.</title>
<date>2008</date>
<booktitle>In Proceedings of IEEE SLT-08,</booktitle>
<contexts>
<context position="1691" citStr="Karakos and Khudanpur, 2008" startWordPosition="252" endWordPosition="255">, hierarchical, syntax-based (Hildebrand and Vogel, 2008) which are equally good in their translation quality even though the underlying frameworks are completely different. The motivation behind System Combination arises from this diversity in the state-of-art MT systems, which suggests that systems with different paradigms make different errors, and can be made better by combining their strengths. One approach of combining translations is based on representing translations by confusion network and then aligning these confusion networks using string alignment algorithms (Rosti et.al, 2009), (Karakos and Khudanpur, 2008). Another approach generates features for every translation to train algorithms for ranking systems based on their quality and the top ranking output is considered to be a candidate translation, (Hildebrand and Vogel, 2008) is an example of ranking based combination. We use ideas from ranking based approaches to learn order in which systems should be aligned in a confusion network based approach. Our approach is based on incremental alignment of confusion networks (Karakos et.al, 2008), wherein each system output is represented by a confusion network. The confusion networks are then aligned in</context>
</contexts>
<marker>Karakos, Khudanpur, 2008</marker>
<rawString>Damianos Karakos and Sanjeev Khudanpur 2008. Sequential System Combination for Machine Translation of Speech. In Proceedings of IEEE SLT-08, December 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Damianos Karakos</author>
<author>Jason Smith</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Hypothesis Ranking and Two-pass Approaches for Machine Translation System Combination.</title>
<date>2010</date>
<booktitle>In Proceedings of ICASSP-2010,</booktitle>
<location>Dallas, Texas,</location>
<marker>Karakos, Smith, Khudanpur, 2010</marker>
<rawString>Damianos Karakos and Jason Smith and Sanjeev Khudanpur 2010. Hypothesis Ranking and Two-pass Approaches for Machine Translation System Combination. In Proceedings of ICASSP-2010, Dallas, Texas, March 14-19 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Damianos Karakos</author>
<author>Jason Eisner</author>
<author>Sanjeev Khudanpur</author>
<author>Markus Dreyer</author>
</authors>
<title>Machine Translation system combination using ITG-based alignments.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers,</booktitle>
<pages>81--84</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Colombus, Ohio,</location>
<marker>Karakos, Eisner, Khudanpur, Dreyer, 2008</marker>
<rawString>Damianos Karakos and Jason Eisner and Sanjeev Khudanpur and Markus Dreyer. 2008. Machine Translation system combination using ITG-based alignments. In Proceedings of ACL-08: HLT, Short Papers, pages 81-84, Colombus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Kenneth Church</author>
<author>Heng Ji</author>
<author>Satoshi Sekine</author>
<author>David Yarowsky</author>
<author>Shane Bergsma</author>
</authors>
<title>New Tools for Web-Scale N-grams.</title>
<date>2010</date>
<booktitle>Kailash Patil and Emily Pitler Rachel Lathbury and Vikram Rao and Kapil Dalwani and Sushant Narsale</booktitle>
<marker>Lin, Church, Ji, Sekine, Yarowsky, Bergsma, 2010</marker>
<rawString>Dekang Lin and Kenneth Church and Heng Ji and Satoshi Sekine and David Yarowsky and Shane Bergsma and Kailash Patil and Emily Pitler Rachel Lathbury and Vikram Rao and Kapil Dalwani and Sushant Narsale 2010. New Tools for Web-Scale N-grams. In the Proceedings of LREC, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--3</pages>
<contexts>
<context position="4009" citStr="Wu, 1997" startWordPosition="612" endWordPosition="613">July 2010. c�2010 Association for Computational Linguistics 2. Generating between system confusion networks. 3. Rescoring the final confusion network. Confusion networks are compressed form of lattices with a constraint that all paths should pass through all nodes. Each system output is represented by an equivalent confusion network. The per-system confusion networks are aligned one at a time. The order in which systems are aligned is usually decided by evaluation of system’s performance. Two alternatives for deciding the system order are discussed in Section 3. InversionTransduction Grammar (Wu, 1997) is used for alignments and the cost function for aligning two confusion networks is 1 |b1||b2 |wE vE c(v)c(w)1(w � v) where b1 and b2 are two different bins, |b1 |and |b2| is the number of tokens in b1 and b2 respectively, c(v) and c(w) are the number of words of token v and token w. which are in b1 and b2 separately. The idea of this cost is to compute the probability that a word from bin b1 is not equal to a word from bin b2. cost(b1, b2) = Prob(v =� w, v E b1, w E b2) The final confusion network is rescored with a 5-gram language model with Kneser-Ney smoothing. To generate the final outpu</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>D. Wu 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, vol.23,no.3,pp.377-403, September 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni and Salim Roukos and Todd Ward and Wei-Jing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings of 40th Annual Meeting of Association for Computational Linguistics, pages 311-318. Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Optimizing Search Engines using Clickthrough Data.</title>
<date>2002</date>
<booktitle>In Proceedings of ACM Conference on Knowledge Discovery and Data Mining(KDD),</booktitle>
<contexts>
<context position="7270" citStr="Joachims, 2002" startWordPosition="1171" endWordPosition="1172">nce length to length of the target sentence is calculated. Language Model Features Language models for target language are used to calculate perplexity of a given translation. The lower the perplexity the better is the translation quality. We use two different language models: (i) a large static 5-gram language model and (ii)a dynamic language model generated from all the translations of the same source segment. The perplexity values are normalized by sentence length. Translations in training set are ranked based on (TER-BLEU) scores. An SVM ranker is then trained on this set. The SVM ranker (Joachims, 2002) returns a score for each translation, based on its signed distance from the separating hyperplane. This value is used in the combination process to weight the contribution of systems to the final confusion network scores. cost(b1,b2) = 312 Table 1: Results for all Language pairs on development set Combination es-en fr-en cz-en de-en BLEU TER BLEU TER BLEU TER BLEU TER BEST SYSTEM 29.27 52.38 26.74 56.88 21.56 58.24 26.53 56.87 BASELINE 28.57 51.61 27.65 55.20 21.01 58.79 26.80 54.54 SVM 28.68 51.99 27.53 55.35 21.56 58.24 26.85 54.9 SVM+NGRAM 29.92 50.92 27.86 55.06 21.80 57.78 27.24 54.86 4 </context>
<context position="9594" citStr="Joachims, 2002" startWordPosition="1555" endWordPosition="1556"> presented. The training data for WMT’10 was divided into development and test set, consisting of 208 and 247 segments respectively. Table 1 shows TER and BLEU scores on the TEST set for all the four language pairs in the following settings: (i) Baseline corresponds to procedure described in section 2, (ii) SVM corresponds to using SVM ranker for learning order of systems as described in section 3.1 (iii)SVM+N-Grams corresponds to the use of a SVM ranker along with weighted interpolation of n-gram language model and the large static language model. The ranking SVM was trained using SVM-light (Joachims, 2002) with a RBF kernel. Two-fold cross-validation was done to prevent over-fitting on development data. All the scores are with lower-cased outputs, a tri-gram language model was used to true-case the output before the final submission. 1-best output from only the primary systems were used for combination. The number of systems used for combination in each language pair are: 6 for Czech-English, 8 in Spanish-English, 14 in French-English and 16 in German-English. The best results for baseline combination were obtained with 3 systems for Czech-English, 6 systems for German-English, 3 systems for Sp</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>Thorsten Joachims 2002. Optimizing Search Engines using Clickthrough Data. In Proceedings of ACM Conference on Knowledge Discovery and Data Mining(KDD), 2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>