<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.972075">
Tagging and Linking Web Forum Posts
</title>
<author confidence="0.999611">
Su Nam Kim, Li Wang and Timothy Baldwin
</author>
<affiliation confidence="0.9996015">
Dept of Computer Science and Software Engineering
University of Melbourne, Australia
</affiliation>
<email confidence="0.993776">
sunamkim@gmail.com, li.wang.d@gmail.com,tb@ldwin.net
</email>
<sectionHeader confidence="0.993774" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999980388888889">
We propose a method for annotating post-
to-post discourse structure in online user
forum data, in the hopes of improving
troubleshooting-oriented information ac-
cess. We introduce the tasks of: (1) post
classification, based on a novel dialogue
act tag set; and (2) link classification. We
also introduce three feature sets (structural
features, post context features and seman-
tic features) and experiment with three dis-
criminative learners (maximum entropy,
SVM-HMM and CRF). We achieve above-
baseline results for both dialogue act and
link classification, with interesting diver-
gences in which feature sets perform well
over the two sub-tasks, and go on to per-
form preliminary investigation of the inter-
action between post tagging and linking.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999989442622951">
With the advent of Web 2.0, there has been an ex-
plosion of web authorship from individuals of all
walks of life. Notably, social networks, blogs and
web user forums have entered the mainstream of
modern-day society, creating both new opportuni-
ties and challenges for organisations seeking to en-
gage with clients or users of any description. One
area of particular interest is web-based user sup-
port, e.g. to aid a user in purchasing a gift for a
friend, or advising a customer on how to config-
ure a newly-acquired wireless router. While such
interactions traditionally took place on an indi-
vidual basis, leading to considerable redundancy
for frequently-arising requests or problems, user
forums support near-real-time user interaction in
the form of a targeted thread made up of individ-
ual user posts. Additionally, they have the poten-
tial for perpetual logging to allow other users to
benefit from them. This in turn facilitates “sup-
port sharing”—i.e. the ability for users to look
over the logs of past support interactions to deter-
mine whether there is a documented, immediately-
applicable solution to their current problem—on a
scale previously unimaginable. This research is
targeted at this task of enhanced support sharing,
in the form of text mining over troubleshooting-
oriented web user forum data (Baldwin et al., to
appear).
One facet of our proposed strategy for enhanc-
ing information access to troubleshooting-oriented
web user forum data is to preprocess threads to
uncover the “content structure” of the thread, in
the form of its post-to-post discourse structure.
Specifically, we identify which earlier post(s) a
given post responds to (linking) and in what man-
ner (tagging), in an amalgam of dialogue act tag-
ging (Stolcke et al., 2000) and coherence-based
discourse analysis (Carlson et al., 2001; Wolf and
Gibson, 2005). The reason we do this is gauge
the relative role/import of individual posts, to in-
dex and weight component terms accordingly, ul-
timately in an attempt to enhance information ac-
cess. Evidence to suggest that this structure can
enhance information retrieval effectiveness comes
from Xi et al. (2004) and Seo et al. (2009) (see
Section 2).
To illustrate the task, consider the thread from
the CNET forum shown in Figure 1, made up of
5 posts (Post 1, ..., Post 5) with 4 distinct partici-
pants (A, B, C, D). In the first post, A initiates the
thread by requesting assistance in creating a web
form. In response, B proposes a Javascript-based
solution (i.e. responds to the first post with a pro-
posed solution), and C proposes an independent
solution based on .NET (i.e. also responds to the
first post with a proposed solution). Next, A re-
sponds to C’s post asking for details of how to in-
clude this in a web page (i.e. responds to the third
post asking for clarification), and in the final post,
D proposes a different solution again (i.e. responds
to the first post with a different solution again).
</bodyText>
<page confidence="0.969143">
192
</page>
<note confidence="0.955345666666667">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 192–202,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
HTML Input Code - CNET Coding &amp; scripting Forums
</note>
<figureCaption confidence="0.673693105263158">
User A HTML Input Code
Post 1 ... Please can someone tell me how to create an
input box that asks the user to enter their ID,
and then allows them to press go. It will then
redirect to the page ...
User B Re: html input code
Post 2 Part 1: create a form with a text field. See
... Part 2: give it a Javascript action ...
User C asp.net c# video
Post 3 Ive prepared for you video.link click ...
User A Thank You!
Post 4 Thanks a lot for that ... I have Microsoft Vi-
sual Studio 6, what program should I do this
in? Lastly, how do I actually include this in my
site?...
User D A little more help
Post 5 ... You would simply do it this way: ... You
could also just ... An example of this is:.. .
Figure 1: Snippeted posts in a CNET thread
</figureCaption>
<figure confidence="0.829161">
Post 5
</figure>
<figureCaption confidence="0.991002">
Figure 2: Post links and dialogue act labels for the
example thread in Figure 1
</figureCaption>
<bodyText confidence="0.999811">
In this, we therefore end up with a tree-based de-
pendency link structure, with each post (other than
the initial post) relating back to a unique preced-
ing post via a range of link types, as indicated in
Figure 2. Note, however, that more generally, it
is possible for a post to link to multiple preced-
ing posts (e.g. refuting one proposed solution, and
proposing a different solution to the problem in the
initial post).
Our primary contributions in this paper are: (1)
a novel post label set for post structure in web
forum data, and associated dataset; and (2) a se-
ries of results for post dependency linking and la-
belling, which achieve strong results for the re-
spective tasks.
</bodyText>
<sectionHeader confidence="0.999827" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.996912280701755">
Related work exists in the broad fields of dialogue
processing, discourse analysis and information re-
trieval, and can be broken down into the following
tasks: (1) dialogue act tagging; (2) discourse “dis-
entanglement”; (3) community question answer-
ing; and (4) newsgroup/user forum search.
Dialogue act (DA) tagging is a means of cap-
turing the function of a given utterance relative
to an encompassing discourse, and has been pro-
posed variously as a means of enhancing dialogue
summarisation (Murray et al., 2006), and track-
ing commitments and promises in email (Cohen
et al., 2004; Lampert et al., 2008), as well as be-
ing shown to improve speech recognition accu-
racy (Stolcke et al., 2000). A wide range of DA
tag sets have been proposed, usually customised
to a particular medium such as speech dialogue
(Stolcke et al., 2000; Shriberg et al., 2004), task-
focused email (Cohen et al., 2004; Wang et al.,
2007; Lampert et al., 2008) or instant messag-
ing (Ivanovic, 2008). The most immediately rel-
evant DA-based work we are aware of is that of
Xi et al. (2004), who proposed a 5-way classifi-
cation for newsgroup data (including QUESTION
and AGREEMENT/AMMENDMENT), but did not
present any results based on the tagset.
A range of supervised models have been applied
to DA classification, including graphical mod-
els (Ji and Bilmes, 2005), kernel methods (Wang
et al., 2007), dependency networks (Carvalho
and Cohen, 2005), transformation-based learning
(Samuel et al., 1998), maxent models (Ang et
al., 2005) and HMMs (Ivanovic, 2008). There is
some contention about the import of context in DA
classification, with the prevailing view being that
context aids classification (Carvalho and Cohen,
2005; Ang et al., 2005; Ji and Bilmes, 2005), but
also evidence to suggest that strictly local mod-
elling is superior (Ries, 1999; Serafin and Di Eu-
genio, 2004).
In this work, we draw on existing work (esp.
Xi et al. (2004)) in proposing a novel DA tag
set customised to the analysis of troubleshooting-
oriented web user forums (Section 3), and com-
pare a range of text classification and structured
classification methods for post-level DA classifi-
cation.
Discourse disentanglement is the process of
automatically identifying coherent sub-discourses
in a single thread (in the context of user fo-
rums/mailing lists), chat session (in the context of
IRC chat data: Elsner and Charniak (2008)), sys-
tem interaction (in the context of HCI: Lemon et
al. (2002)) or document (Wolf and Gibson, 2005).
The exact definition of what constitutes a sub-
discourse varies across domains, but for our pur-
poses, entails an attempt to resolve the informa-
</bodyText>
<figure confidence="0.9939915">
Question-Question
Post 1
Answer-Answer
Post 2 Answer-Answer
Post 3
Answer-Clarification
Post 4
Answer-Answer
</figure>
<page confidence="0.998422">
193
</page>
<bodyText confidence="0.999573225806451">
tion need of the initiator by a particular approach;
if there are competing approaches proposed in a
single thread, multiple sub-discourses will neces-
sarily arise. The data structure used to represent
the disentangled discourse varies from a simple
connected sub-graph (Elsner and Charniak, 2008),
to a stack/tree (Grosz and Sidner, 1986; Lemon
et al., 2002; Seo et al., 2009), to a full directed
acyclic graph (DAG: Ros´e et al. (1995), Wolf and
Gibson (2005), Schuth et al. (2007)). Disentan-
glement has been carried out via analysis of di-
rect citation/user name references (Schuth et al.,
2007; Seo et al., 2009), topic modelling (Lin et al.,
2009), and clustering over content-based features
for pairs of posts, optionally incorporating various
constraints on post recency (Elsner and Charniak,
2008; Wang et al., 2008; Seo et al., 2009).
In this work, we follow Ros´e et al. (1995) and
Wolf and Gibson (2005) in adopting a DAG repre-
sentation of discourse structure, and draw on the
wide set of features used in discourse entangle-
ment to model coherence.
Community question answering (cQA) is the
task of identifying question–answer pairs in a
given thread, e.g. for the purposes of thread sum-
marisation (Shrestha and McKeown, 2004) or au-
tomated compilation of resources akin to Yahoo!
Answers. cQA has been applied to both mail-
ing list and user forum threads, conventionally
based on question classification, followed by rank-
ing of candidate answers relative to each question
(Shrestha and McKeown, 2004; Ding et al., 2008;
Cong et al., 2008; Cao et al., 2009). The task is
somewhat peripheral to our work, but relevant in
that it involves the implicit tagging of certain posts
as containing questions/answers, as well as link-
ing the posts together. Once again, we draw on the
features used in cQA in this research.
There has been a spike of recent interest in
newsgroup/user forum search. Xi et al. (2004)
proposed a structured information retrieval (IR)
model for newsgroup search, based on author fea-
tures, thread structure (based on the tree defined by
the reply-to structure), thread “topology” features
and content-based features, and used a supervised
ranking method to improve over a baseline IR sys-
tem. Elsas and Carbonell (2009) — building on
earlier work on blog search (Elsas et al., 2008) —
proposed a probabilistic IR approach which ranks
user forum threads relative to selected posts in the
overall thread, and again demonstrated the superi-
ority of this method over a model which ignores
thread structure. Finally, Seo et al. (2009) auto-
matically derived thread structure from user forum
threads, and demonstrated that the IR effectiveness
over the “threaded” structure was superior to that
using a monolithic document representation.
The observations and results of Xi et al. (2004)
and Seo et al. (2009) that threading information
(or in our case “disentangled” DAG structure) en-
hances IR effectiveness is a core motivator for this
research.
</bodyText>
<sectionHeader confidence="0.91094" genericHeader="method">
3 Post Label Set
</sectionHeader>
<bodyText confidence="0.999475416666667">
Our post label set contains 12 categories, intended
to capture the typical interactions that take place in
troubleshooting-oriented threads on technical fo-
rums. There are 2 super-categories (QUESTION,
ANSWER) and 3 singleton classes (RESOLUTION,
REPRODUCTION, and OTHER). QUESTION, in
turn, contains 4 sub-classes (QUESTION, ADD,
CONFIRMATION, CORRECTION), while ANSWER
contains 5 sub-classes (ANSWER, ADD, CONFIR-
MATION, CORRECTION, and OBJECTION), par-
tially mirroring the sub-structure of QUESTION.
We represent the amalgam of a super- and sub-
class as QUESTION-ADD, for example.
All tags other than QUESTION-QUESTION and
OTHER are relational, i.e. relate a given post to a
unique earlier post. A given post can potentially
be labelled with multiple tags (e.g. confirm details
of a proposed solution, in addition to providing ex-
tra details of the problem), although, based on the
strictly chronological ordering of posts in threads,
a post can only link to posts earlier in the thread
(and can also not cross thread boundaries). Addi-
tionally, the link structure is assumed to be tran-
sitive, in that if post A links to post B and post B
to post C, post A is implicitly linked to post C. As
such, an explicit link from post A to post C should
exist only in the case that the link between them is
not inferrable transitively.
Detailed definitions of each post tag are given
below. Note that initiator refers to the user who
started the thread with the first post.
QUESTION-QUESTION (Q-Q): the post con-
tains a new question, independent of the
thread context that precedes it. In general,
QUESTION-QUESTION is reserved for the
first post in a given thread.
</bodyText>
<sectionHeader confidence="0.437226" genericHeader="method">
QUESTION-ADD (Q-ADD): the post supple-
</sectionHeader>
<page confidence="0.99481">
194
</page>
<bodyText confidence="0.9998625">
ments a question by providing additional
information, or asking a follow-up question.
</bodyText>
<sectionHeader confidence="0.952692" genericHeader="method">
QUESTION-CONFIRMATION (Q-CONF): the
</sectionHeader>
<bodyText confidence="0.997874333333333">
post points out error(s) in a question without
correcting them, or confirms details of the
question.
</bodyText>
<sectionHeader confidence="0.715465" genericHeader="method">
QUESTION-CORRECTION (Q-CORR): the post
</sectionHeader>
<bodyText confidence="0.685411">
corrects error(s) in a question.
ANSWER-ANSWER (A-A): the post proposes an
answer to a question.
</bodyText>
<sectionHeader confidence="0.662051" genericHeader="method">
ANSWER-ADD (A-ADD): the post supplements
</sectionHeader>
<bodyText confidence="0.999814">
an answer by providing additional informa-
tion.
</bodyText>
<sectionHeader confidence="0.996606" genericHeader="method">
ANSWER-CONFIRMATION (A-CONF): the
</sectionHeader>
<bodyText confidence="0.995303333333333">
post points out error(s) in an answer without
correcting them, or confirms details of the
answer.
</bodyText>
<sectionHeader confidence="0.871762" genericHeader="method">
ANSWER-CORRECTION (A-CORR): the post
</sectionHeader>
<bodyText confidence="0.575254">
corrects error(s) in an answer.
</bodyText>
<sectionHeader confidence="0.91062" genericHeader="method">
ANSWER-OBJECTION (A-OBJ): the post ob-
</sectionHeader>
<bodyText confidence="0.989665666666666">
jects to an answer on experiential or theoreti-
cal grounds (e.g. It won’t work.).
RESOLUTION (RES): the post confirms that an
answer works, on the basis of implementing
it.
REPRODUCTION (REP): the post either: (1)
confirms that the same problem is being ex-
perienced (by a non-initiator, e.g. I’m seeing
the same thing.); or (2) confirms that the an-
swer should work.
OTHER (OTHER): the post does not belong to
any of the above classes.
</bodyText>
<sectionHeader confidence="0.994528" genericHeader="method">
4 Feature Description
</sectionHeader>
<bodyText confidence="0.999887">
In this section, we describe our post feature repre-
sentation, in the form of four feature types.
</bodyText>
<subsectionHeader confidence="0.997834">
4.1 Lexical features
</subsectionHeader>
<bodyText confidence="0.999951444444445">
As our first feature type, we use simple lexical fea-
tures, in the form of unigram and bigram tokens
contained within a given post (without stopping).
We also POS tagged and lemmatised the posts,
postfixing the lemmatised token with its POS tag
(using Lingua::EN::Tagger and morpha (Min-
nen et al., 2001)). Finally, we bin together the
counts for each token, and represent it via its raw
frequency.
</bodyText>
<subsectionHeader confidence="0.996959">
4.2 Structural features
</subsectionHeader>
<bodyText confidence="0.999993714285714">
The identity of the post author, and position of the
post within the thread, can be indicators of the
post/link structure of a given post. We represent
the post author as a simple binary feature indicat-
ing whether s/he is the thread initiator, and the post
position via its relative position in the thread (as a
ratio, relative to the total number of posts).
</bodyText>
<subsectionHeader confidence="0.99977">
4.3 Post context features
</subsectionHeader>
<bodyText confidence="0.999569476190476">
As mentioned in Section 2, post context has gen-
erally (but not always) been shown to enhance the
classification accuracy of DA tagging tasks, in the
form of Markov features providing predicted post
labels for previous posts, or more simply, post-to-
post similarity. We experiment with a range of
post context features, all of which are compatible
with features both from the same label set as that
being classified (e.g. link features for link classifi-
cation), as well as features from a second label set
(e.g. DA label features for link classification).
Previous Post: There is a strong prior for posts
to link to their immediately preceding post (as ob-
served for 79.9% of the data in our dataset), and
also strong sequentiality in our post label set (e.g.
a post following a Q-Q is most likely to be an A-
A). As such, we represent the predicted post label
of the immediately preceding post, as a first-order
Markov feature, as well as a binary feature to in-
dicate whether the author of the previous post also
authored the current post.
</bodyText>
<subsectionHeader confidence="0.778779">
Previous Post from Same Author: A given
</subsectionHeader>
<bodyText confidence="0.936518363636364">
user tends to author posts of the same basic type
(e.g. QUESTION or ANSWER) in a given thread,
and pairings such as A-A and A-CONF from a
given author are very rare. To capture this obser-
vation, we look to see if the author of the current
post has posted earlier in the thread, and if so, in-
clude the label and relative location (in posts) of
their most recent previous post.
Full History: As a final option, we include the
predictions for all posts Pi, ..., PZ_i preceding the
current post PZ.
</bodyText>
<subsectionHeader confidence="0.997002">
4.4 Semantic features
</subsectionHeader>
<bodyText confidence="0.999658">
We tested four semantic features based on post
content and title.
</bodyText>
<page confidence="0.99492">
195
</page>
<bodyText confidence="0.994398137931034">
Title Similarity: For forums such as CNET
which include titles for individual posts (as rep-
resented in Figure 1), a post having the same or
similar title as a previous post is often a strong
indicator that it responds to that post. This both
provides a strong indicator of which post a given
post responds (links) to, and can aid in DA tag-
ging. We use simple cosine similarity to find the
post with the most-similar title, and represent its
relative location to the current post.
Post Similarity: Posts of the same general type
tend to have similar content and be linked. For
example, A-A and A-ADD posts tend to share
content. We capture this by identifying the post
with most-similar content based on cosine similar-
ity, and represent its relative location to the current
post.
Post Characteristics: We separately represent
the number of question marks, exclamation marks
and URLs in the current post. In general, ques-
tion marks occur in QUESTION and CONFIRMA-
TION posts, exclamation marks occur in RES and
OBJECTION posts, and URLs occur in A-A and
A-ADD posts.
User Profile: Some authors tend to answer ques-
tions more, while others tend to ask more ques-
tions. We capture the class priors for the author of
the current post by the distribution of post labels
in their posts in the training data.
</bodyText>
<sectionHeader confidence="0.999079" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999982882352941">
As our dataset, we collected 320 threads contain-
ing a total of 1,332 posts from the Operating Sys-
tem, Software, Hardware, and Web Development
sub-forums of CNET.1
The annotation of post labels and links was car-
ried by two annotators in a custom-built web inter-
face which supported multiple labels and links for
a given post. For posts with multilabels, we used
a modified version of Cohen’s Kappa, which re-
turned r. values of 0.59 and 0.78 for the post label
and link annotations, respectively. Any disagree-
ments in labelling were resolved through adjudi-
cation.
Of the 1332 posts, 65 posts have multiple labels
(which possibly link to a common post) and 22
posts link to two different links. The majority post
label in the dataset is A-A (40.30%).
</bodyText>
<footnote confidence="0.945837">
1http://forums.cnet.com/?tag=
TOCleftColumn.0
</footnote>
<bodyText confidence="0.999972731707317">
We built machine learners using a conven-
tional Maximum Entropy (ME) learner,2 as well as
two structural learners, namely: (1) SVM-HMMs
(Joachims et al., 2009), as implemented in SVM-
struct3, with a linear kernel; and (2) conditional
random fields (CRFs) using CRF++.4 SVM-
HMMs and CRFs have been successfully applied
to a range of sequential tagging tasks such as
syllabification (Bartlett et al., 2009), chunk pars-
ing (Sha and Pereira, 2003) and word segmen-
tation (Zhao et al., 2006). Both are discrimina-
tive models which capture structural dependen-
cies, which is highly desirable in terms of mod-
elling sequential preferences between post labels
(e.g. A-CONF typically following a A-A). SVM-
HMM has the additional advantage of scaling to
large numbers of features (namely the lexical fea-
tures). As such, we only experiment with lexical
features for SVM-HMM and ME.
All of our evaluation is based on stratified 10-
fold cross-validation, stratifying at the thread level
to ensure that if a given post is contained in the
test data for a given iteration, all other posts in
that same thread are also in the test data (or more
pertinently, not in the training data). We evalu-
ate using micro-averaged precision, recall and F-
score (Q = 1). We test the statistical significance
of all above-baseline results using randomised es-
timation (p &lt; 0.05; Yeh (2000)), and present all
such results in bold in our results tables.
In our experiments, we first look at the post
classification task in isolation (i.e. we predict
which labels to associate with each post, under-
specifying which posts those labels relate to). We
then move on to look at the link classification task,
again in isolation (i.e. we predict which previous
posts each post links to, underspecifying the na-
ture of the link). Finally, we perform preliminary
investigation of the joint task of DA and link clas-
sification, by incorporating DA class features into
the link classification task.
</bodyText>
<sectionHeader confidence="0.998928" genericHeader="method">
6 DA Classification Results
</sectionHeader>
<bodyText confidence="0.999845">
Our first experiment is based on post-level dia-
logue act (DA) classification, ignoring link struc-
ture in the first instance. That is, we predict the
labels on edges emanating from each post in the
DAG representation of the post structure, without
</bodyText>
<footnote confidence="0.9999785">
2http://maxent.sourceforge.net/
3http://www.cs.cornell.edu/People/tj/
svm_light/svm_hmm.html
4http://crfpp.sourceforge.net/
</footnote>
<page confidence="0.986063">
196
</page>
<table confidence="0.955221666666667">
Features CRF SVM-HMM ME
Lexical — .566 .410
Structural .742 .638 .723
</table>
<tableCaption confidence="0.870111">
Table 1: DA classification F-score with lexical and
structural features (above-baseline results in bold)
</tableCaption>
<bodyText confidence="0.979918363636364">
specifying the edge destination. Returning to our
example in Figure 2, e.g., the gold-standard clas-
sification for Post 1 would be Q-Q, Post 2 would
be A-A, etc.
As a baseline for DA classification, simple ma-
jority voting attains an F-score of 0.403, based on
the A-A class. A more realistic baseline, how-
ever, is a position-conditioned variant, where the
first post is always classified as Q-Q, and all sub-
sequent posts are classified as A-A, achieving an
F-score of 0.641.
</bodyText>
<subsectionHeader confidence="0.990043">
6.1 Lexical and structural features
</subsectionHeader>
<bodyText confidence="0.999995142857143">
First, we experiment with lexical and structural
features (recalling that we are unable to scale the
CRF model to full lexical features). Lexical fea-
tures produce below-baseline performance, while
simple structural features immediately lead to an
improvement over the baseline for CRF and ME.
The reason for the poor performance with lex-
ical features is that our dataset contains only
around 1300 posts, each of which is less than 100
words in length on average. The models are sim-
ply unable to generalise over this small amount of
data, and in the case of SVM-HMM, the presence
of lexical features, if anything, appears to obscure
the structured nature of the labelling task (i.e. the
classifier is unable to learn the simple heuristic
used by the modified majority class baseline).
The success of the structural features, on the
other hand, points to the presence of predictable
sequences of post labels in the data. That SVM-
HMM is unable to achieve baseline performance
with structural features is slightly troubling.
</bodyText>
<subsectionHeader confidence="0.999703">
6.2 Post context features
</subsectionHeader>
<bodyText confidence="0.973884625">
Next, we test the two post context features: Previ-
ous Post (P) and Previous Post from Same Author
(A). Given the success of structural features, we
retain these in our experiments. Note that the la-
bels used in the post context are those which are
interactively learned by that model for the previ-
ous posts.
Table 2 presents the results for structural fea-
</bodyText>
<table confidence="0.999164833333333">
Features CRF SVM-HMM ME
Struct+R .740 .640 .632
Struct+A .742 .676 .693
Struct+F .744 .641 .577
Struct+RA .397 .636 .665
Struct+AF .405 .642 .586
</table>
<tableCaption confidence="0.960888">
Table 2: DA classification F-score with structural
</tableCaption>
<listItem confidence="0.7400825">
and DA-based post context features (R = “Previ-
ous Post”, A = “Previous Post from Same Author”,
and F = “Full History”; above-baseline results in
bold)
</listItem>
<bodyText confidence="0.999440263157895">
tures combined with DA-based post context; we
do not present any combinations of Previous Post
and Full History, as Full History includes the Pre-
vious Post.
Comparing back to the original results using
only the structural results, we can observe that Pre-
vious Post from Same Author and Full History (A
and F, resp., in the table) lead to a slight incre-
ment in F-score for both CRF and SVM-HMM,
but degrade the performance of ME. Previous Post
leads to either a marginal improvement, or a drop
in results, most noticeably for ME. It is slightly
surprising that the CRF should benefit from con-
text features at all, given that it is optimising over
the full tag sequence, but the impact is relatively
localised, and when all sets of context features
are used, the combined weight of noisy features
appears to swamp the learner, leading to a sharp
degradation in F-score.
</bodyText>
<subsectionHeader confidence="0.998243">
6.3 Semantic features
</subsectionHeader>
<bodyText confidence="0.999970058823529">
We next investigate the relative impact of the se-
mantic features, once again including structural
features in all experiments. Table 3 presents the F-
score using the different combinations of semantic
features.
Similarly to the post context features, the se-
mantic features produced slight increments over
the structural features in isolation, especially for
CRF and ME. For the first time, SVM-HMM
achieved above-baseline results, when incorporat-
ing title similarity and post characteristics. Of the
individual semantic features, title and post simi-
larity appear to be the best performers. Slightly
disappointingly, the combination of semantic fea-
tures generally led to a degradation in F-score, al-
most certainly due to data sparseness. The best
overall result was achieved with CRF, incorporat-
</bodyText>
<page confidence="0.994999">
197
</page>
<table confidence="0.9998108125">
Features CRF SVM-HMM ME
Struct+T .751 .636 .660
Struct+P .747 .636 .662
Struct+C .738 .587 .630
Struct+U .722 .564 .620
Struct+TP .740 .627 .720
Struct+TC .744 .646 .589
Struct+TU .738 .600 .609
Struct+PC .745 .630 .583
Struct+PU .736 .626 .605
Struct+CU .730 .599 .619
Struct+TPC .739 .622 .580
Struct+TPU .729 .613 .6120
Struct+TCU .750 .611 .6120
Struct+PCU .738 .616 .614
Struct+TPCU .737 .619 .605
</table>
<tableCaption confidence="0.8164655">
Table 3: DA classification F-score with semantic
features (T = “Title Similarity”, P = “Post Simi-
larity”, C = “Post Characteristics”, and U = “User
Profile”; above-baseline results in bold)
</tableCaption>
<bodyText confidence="0.948290615384616">
ing structural features and title similarity, at an F-
score of 0.751.
To further explore the interaction between post
context and semantic features, we built CRF clas-
sifiers for different combinations of post context
and semantic features, and present the results in
Table 4.5 We achieved moderate gains in F-score,
with all post context features, in combination with
structural features, post similarity and post char-
acteristics achieving an F-score of 0.753, slightly
higher than the best result achieved for just struc-
tural and post context features.
It is important to refer back to the results for
lexical features (comparable to what would have
been achieved with a standard text categorisation
approach to the task), and observe that we have
achieved far higher F-scores using features cus-
tomised to user forum data. It is also important
to reflect that post context (in terms of the features
and the structured classification results of CRF)
appears to markedly improve our results, contrast-
ing with the results of Ries (1999) and Serafin and
Di Eugenio (2004).
5We omit the results for Full History post context for rea-
sons of space, but there is relatively little deviation from the
numbers presented.
</bodyText>
<table confidence="0.9997191875">
Features R A RA
Struct+T .649 .649 .649
Struct+P .737 .736 .742
Struct+C .741 .741 .742
Struct+U .745 .742 .737
Struct+TP .645 .656 .658
Struct+TC .383 .402 .408
Struct+TU .650 .652 .652
Struct+PC .730 .743 .753
Struct+PU .232 .232 .286
Struct+CU .719 .471 .710
Struct+TPC .498 .469 .579
Struct+TPU .248 .232 .248
Struct+TCU .388 .377 .380
Struct+PCU .231 .231 .261
Struct+TPCU .231 .231 .231
</table>
<tableCaption confidence="0.987749">
Table 4: DA classification F-score for CRF with
</tableCaption>
<bodyText confidence="0.904068666666667">
different combinations of post context features and
semantic features (R = “Previous Post”, and A
= “Previous Post from Same Author”; T = “Ti-
tle Similarity”, P = “Post Similarity”, C = “Post
Characteristics”, and U = “User Profile”; above-
baseline results in bold)
</bodyText>
<sectionHeader confidence="0.895876" genericHeader="method">
7 Link Classification Results
</sectionHeader>
<bodyText confidence="0.999975666666667">
Our second experiment is based on link classifi-
cation in isolation. Here, we predict unlabelled
edges, e.g. in Figure 2, the gold-standard classifi-
cation for Post 1 would be NULL, Post 2 would be
Post 1, Post 3 would be Post 1, etc.
Note that the initial post cannot link to any other
post, and also that the second post always links
to the first post. As this is a hard constraint on
the data, and these posts simply act to inflate the
overall numbers, we exclude all first and second
posts from our evaluation of link classification.
We experimented with a range of baselines as
presented in Table 5, but found that the best per-
former by far was the simple heuristic of linking
each post (except for the initial post) to its imme-
diately preceding post. This leads to an F-score of
0.631, comparable to that for the post classifica-
tion task.
</bodyText>
<subsectionHeader confidence="0.998807">
7.1 Lexical and structural features
</subsectionHeader>
<bodyText confidence="0.9895365">
Once again, we started by exploring the effective-
ness of lexical and structural features using the
three learners, as detailed in Table 6.
Similarly to the results for post classification,
</bodyText>
<page confidence="0.995518">
198
</page>
<table confidence="0.949393444444445">
Baseline Prec Rec F-score
Previous post .641 .622 .631
First post .278 .269 .274
Title similarity .311 .301 .306
Post similarity .255 .247 .251
Table 5: Baselines for link classification
Features CRF SVM-HMM ME
Lexical — .154 .274
Structural .446 .220 .478
</table>
<tableCaption confidence="0.720378333333333">
Table 6: Link classification F-score with lexical
and structural features (above-baseline results in
bold)
</tableCaption>
<bodyText confidence="0.999637833333333">
structural features are more effective than lexical
features for link classification, but this time, nei-
ther feature set approaches the baseline F-score
for any of the learners. Once again, the results for
SVM-HMM are well below those for the other two
learners.
</bodyText>
<subsectionHeader confidence="0.999597">
7.2 Post context features
</subsectionHeader>
<bodyText confidence="0.999929523809524">
Next, we experiment with link-based post con-
text features, in combination with the structural
features, as the results were found to be consis-
tently better when combined with the structural
features (despite the below-baseline performance
of the structural features in this case). The link-
based post context features in all cases are gener-
ated using the CRF with structural features from
Table 6. As before, we do not present any combi-
nations of Previous Post and Full History, as Full
History includes the Previous Post
As seen in Table 9, here, for the first time, we
achieve an above-baseline result for link classifi-
cation, for SVM and ME based on Previous Post
from Same Author in isolation, and also some-
times in combination with the other feature sets.
The results for CRF also improve, but not to a
level of statistical significance over the baseline.
Similarly to the results for DA classification, the
results for CRF drop appreciably when we com-
bine feature sets.
</bodyText>
<subsectionHeader confidence="0.998838">
7.3 Semantic features
</subsectionHeader>
<bodyText confidence="0.9191635">
Finally, we experiment with semantic features,
once again in combination with structural features.
The results are presented in Table 8.
The results for semantic features largely mir-
</bodyText>
<table confidence="0.998364166666667">
Features CRF SVM-HMM ME
Struct+R .234 .605 .618
Struct+A .365 .665 .665
Struct+F .624 .648 .615
Struct+RA .230 .615 .661
Struct+AF .359 .663 .621
</table>
<tableCaption confidence="0.8202705">
Table 7: Link classification F-score with structural
and link-based post context features (R = “Previ-
</tableCaption>
<listItem confidence="0.690278">
ous Post”, A = “Previous Post from Same Author”,
and F = “Full History”; above-baseline results in
bold)
</listItem>
<table confidence="0.99961475">
Features CRF SVM-HMM ME
Struct+T .464 .223 .477
Struct+P .433 .198 .453
Struct+C .438 .213 .419
Struct+U .407 .160 .376
Struct+TP .459 .194 .491
Struct+TC .449 .229 .404
Struct+TU .456 .174 .353
Struct+PC .422 .152 .387
Struct+PU .439 .166 .349
Struct+CU .397 .178 .366
Struct+TPC .449 .185 .418
Struct+TPU .449 .160 .365
Struct+TCU .459 .185 .358
Struct+PCU .439 .161 .358
Struct+TPCU .443 .163 .365
</table>
<tableCaption confidence="0.70783275">
Table 8: Link classification F-score with semantic
features (T = “Title Similarity”, P = “Post Simi-
larity”, C = “Post Characteristics”, and U = “User
Profile”; above-baseline results in bold)
</tableCaption>
<bodyText confidence="0.999834181818182">
ror those for post classification: small improve-
ments are observed for title similarity with CRF,
but otherwise, the results degrade across the board,
and the combination of different feature sets com-
pounds this effect.
The best overall result achieved for link classifi-
cation is thus the 0.743 for CRF with the structural
and post context features.
We additionally experimented with combina-
tions of features as for post classification, but were
unable to improve on this result.
</bodyText>
<subsectionHeader confidence="0.998711">
7.4 Link Classification using DA Features
</subsectionHeader>
<bodyText confidence="0.999668">
Ultimately, we require both DA and link classifica-
tion of each post, which is possible by combining
the outputs of the component classifiers described
</bodyText>
<page confidence="0.995593">
199
</page>
<table confidence="0.998815">
Features CRF SVM-HMM ME
Struct+R .586 .352 .430
Struct+A .591 .278 .568
Struct+F .704 .477 .546
Struct+RA .637 .384 .551
Struct+AF .743 .527 .603
</table>
<tableCaption confidence="0.99207">
Table 9: Link classification F-score with structural
</tableCaption>
<bodyText confidence="0.938111">
and post-based post context features (R = “Previ-
ous Post”, A = “Previous Post from Same Author”,
and F = “Full History”; above-baseline results in
bold)
above, by rolling the two tasks into a single clas-
sification task, or alternatively by looking to joint
modelling methods. As a preliminary step in this
direction, and means of exploring the interaction
between the two tasks, we repeat the experiment
based on post context features from above (see
Section 7.2), but rather than using link-based post
context, we use DA-based post context.
As can be seen in Table 9, the results for SVM-
HMM and ME drop appreciably as compared to
the results using link-based post context in Table 9,
while the results for CRF jump to the highest level
achieved for the task for all three learners. The
effect can be ascribed to the ability of CRF to
natively model the (bidirectional) link classifica-
tion history in the process of performing structured
learning, and the newly-introduced post features
complementing the link classification task.
</bodyText>
<sectionHeader confidence="0.969985" genericHeader="discussions">
8 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.999992136363636">
Ultimately, we require both DA and link classifica-
tion of each post, which is possible in (at least) the
following three ways: (1) by combining the out-
puts of the component classifiers described above;
(2) by rolling the two tasks into a single classifi-
cation task; or (3) by looking to joint modelling
methods. Our results in Section 7.4 are suggestive
of the empirical potential of performing the two
tasks jointly, which we hope to explore in future
work.
One puzzling effect observed in our experi-
ments was the generally poor results for SVM. Er-
ror analysis indicates that the classifier was heav-
ily biased towards the high-frequency classes, e.g.
classifying all posts as either Q-Q or A-A for DA
classification. The classifications for the other two
learners were much more evenly spread across the
different classes.
CRF was limited in that it was unable to cap-
ture lexical features, but ultimately, lexical fea-
tures were found to be considerably less effec-
tive than structural and post context features for
both tasks, and the ability of the CRF to opti-
mise the post labelling over the full sequence of
posts in a thread more than compensated for this
shortcoming. Having said this, there is more work
to be done exploring synergies between the dif-
ferent feature sets, especially for DA classifica-
tion where all feature sets were found to produce
above-baseline results.
Another possible direction for future research is
to explore the impact of inter-post time on link
structure, based on the observation that follow-
up posts from the initiator tend to be tempo-
rally adjacent to posts they respond to with rela-
tively short time intervals, while posts from non-
initiators which are well spaced out tend not to re-
spond to one another. Combining this with pro-
filing of the cross-thread behaviour of individual
forum participants (Weimer et al., 2007; Lui and
Baldwin, 2009), and formal modelling of “forum
behaviour” is also a promising line of research,
taking the lead from the work of G¨otz et al. (2009),
inter alia.
</bodyText>
<sectionHeader confidence="0.996158" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999987">
In this work, we have proposed a method for
analysing post-to-post discourse structure in on-
line user forum data, in the form of post link-
ing and dialogue act tagging. We introduced
three feature sets: structural features, post con-
text features and semantic features. We exper-
imented with three learners (maximum entropy,
SVM-HMM and CRF), and established that CRF
is the superior approach to the task, achieving
above-baseline results for both post and link clas-
sification. We also demonstrated the complemen-
tarity of the proposed feature sets, especially for
the post classification task, and carried out a pre-
liminary exploration of the interaction between the
linking and dialogue act tagging tasks.
</bodyText>
<sectionHeader confidence="0.99671" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.7844845">
This research was supported in part by funding
from Microsoft Research Asia.
</bodyText>
<sectionHeader confidence="0.982848" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.698596">
Jeremy Ang, Yang Liu, and Elizabeth Shriberg. 2005.
Automatic dialog act segmentation and classifica-
</reference>
<page confidence="0.979924">
200
</page>
<reference confidence="0.999071145454546">
tion in multiparty meetings. In Proceedings of
the 2005 IEEE International Conference on Acous-
tics, Speech, and Signal Processing (ICASSP 2005),
pages 1061–1064, Philadelphia, USA.
Timothy Baldwin, David Martinez, Richard Penman,
Su Nam Kim, Marco Lui, Li Wang, and Andrew
MacKinlay. to appear. Intelligent Linux informa-
tion access by data mining: the ILIAD project. In
Proceedings of the NAACL 2010 Workshop on Com-
putational Linguistics in a World of Social Media:
#SocialMedia, Los Angeles, USA.
Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2009. On the syllabification of phonemes. In Pro-
ceedings of the North American Chapter of the As-
sociation for Computational Linguistics – Human
Language Technologies 2009 (NAACL HLT 2009),
pages 308–316, Boulder, USA.
Xin Cao, Gao Cong, Bin Cui, Christian S. Jensen, and
Ce Zhang. 2009. The use of categorization infor-
mation in language models for question retrieval. In
Proceedings of the 18th ACM Conference on Infor-
mation and Knowledge Management (CIKM 2009),
pages 265–274, Hong Kong, China.
Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski. 2001. Building a discourse-tagged
corpus in the framework of rhetorical structure the-
ory. In Proceedings of the Second SIGdial Work-
shop on Discourse and Dialogue, pages 1–10, Aal-
borg, Denmark. Association for Computational Lin-
guistics Morristown, NJ, USA.
Vitor R. Carvalho and William W. Cohen. 2005. On
the collective classification of email ”speech acts”.
In Proceedings of 28th International ACM-SIGIR
Conference on Research and Development in Infor-
mation Retrieval (SIGIR 2005), pages 345–352.
William W. Cohen, Vitor R. Carvalho, and Tom M.
Mitchell. 2004. Learning to classify email into
“speech acts”. In Proceedings of the 2004 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP 2004), pages 309–316,
Barcelona, Spain.
Gao Cong, Long Wang, Chin-Yew Lin, Young-In
Song, and Yueheng Sun. 2008. Finding question-
answer pairs from online forums. In Proceedings of
31st International ACM-SIGIR Conference on Re-
search and Development in Information Retrieval
(SIGIR’08), pages 467–474, Singapore.
Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan
Zhu. 2008. Using conditional random fields to ex-
tract context and answers of questions from online
forums. In Proceedings of the 46th Annual Meet-
ing of the ACL: HLT (ACL 2008), pages 710–718,
Columbus, USA.
Jonathan L. Elsas and Jaime G. Carbonell. 2009. It
pays to be picky: An evaluation of thread retrieval
in online forums. In Proceedings of 32nd Inter-
national ACM-SIGIR Conference on Research and
Development in Information Retrieval (SIGIR’09),
pages 714–715, Boston, USA.
Jonathan L. Elsas, Jaime Arguello, Jamie Callan, and
Jaime G. Carbonell. 2008. Retrieval and feed-
back models for blog feed search. In Proceedings of
31st International ACM-SIGIR Conference on Re-
search and Development in Information Retrieval
(SIGIR’08), pages 347–354, Singapore.
Micha Elsner and Eugene Charniak. 2008. You talk-
ing to me? a corpus and algorithm for conversation
disentanglement. In Proceedings of the 46th Annual
Meeting of the ACL: HLT (ACL 2008), pages 834–
842, Columbus, USA.
Michaela G¨otz, Jure Leskovec, Mary McGlohon, and
Christos Faloutsos. 2009. Modeling blog dynamics.
In Proceedings of the Third International Confer-
ence on Weblogs and Social Media (ICWSM 2009),
pages 26–33, San Jose, USA.
Barbara J. Grosz and Candace L. Sidner. 1986. Atten-
tion, intention and the structure of discourse. Com-
putational Linguistics, 12(3):175–204.
Edward Ivanovic. 2008. Automatic instant messaging
dialogue using statistical models and dialogue acts.
Master’s thesis, University of Melbourne.
Gang Ji and Jeff Bilmes. 2005. Dialog act tag-
ging using graphical models. In Proceedings of
the 2005 IEEE International Conference on Acous-
tics, Speech, and Signal Processing (ICASSP 2005),
pages 33–36, Philadelphia, USA.
Thorsten Joachims, Thomas Finley, and Chun-
Nam John Yu. 2009. Cutting-plane training of
structural SVMs. Machine Learning, 77(1):27–59.
Andrew Lampert, Robert Dale, and C´ecile Paris.
2008. The nature of requests and commitments in
email messages. In Proceedings of the AAAI 2008
Workshop on Enhanced Messaging, pages 42–47,
Chicago, USA.
Oliver Lemon, Alex Gruenstein, and Stanley Pe-
ters. 2002. Collaborative activities and multi-
tasking in dialogue systems. Traitement Automa-
tique des Langues (TAL), Special Issue on Dialogue,
43(2):131–154.
Chen Lin, Jiang-Ming Yang, Rui Cai, Xin-Jing Wang,
Wei Wang, and Lei Zhang. 2009. Modeling se-
mantics and structure of discussion threads. In Pro-
ceedings of the 18th International Conference on the
World Wide Web (WWW 2009), pages 1103–1104,
Madrid, Spain.
Marco Lui and Timothy Baldwin. 2009. You are what
you post: User-level features in threaded discourse.
In Proceedings of the Fourteenth Australasian Doc-
ument Computing Symposium (ADCS 2009), Syd-
ney, Australia.
</reference>
<page confidence="0.970365">
201
</page>
<reference confidence="0.999854277777778">
Guido Minnen, John Carroll, and Darren Pearce. 2001.
Applied morphological processing of English. Nat-
ural Language Engineering, 7(3):207–223.
Gabriel Murray, Steve Renals, Jean Carletta, and Jo-
hanna Moore. 2006. Incorporating speaker and dis-
course features into speech summarization. In Pro-
ceedings of the Main Conference on Human Lan-
guage Technology Conference of the North Amer-
ican Chapter of the Association of Computational
Linguistics, pages 367–374.
Klaus Ries. 1999. HMM and neural network
based speech act detection. In Proceedings of the
1999 IEEE International Conference on Acoustics,
Speech, and Signal Processing (ICASSP-99), pages
497–500, Phoenix, USA.
Carolyn Penstein Ros´e, Barbara Di Eugenio, Lori S.
Levin, and Carol Van Ess-Dykema. 1995.
Discourse processing of dialogues with multiple
threads. In Proceedings of the 33rd Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 31–38, Cambridge, USA.
Ken Samuel, Carbeery Sandra Carberry, and K. Vijay-
Shanker. 1998. Dialogue act tagging with
transformation-based learning. In Proceedings of
the 36th Annual Meeting of the ACL and 17th In-
ternational Conference on Computational Linguis-
tics (COLING/ACL-98), pages 1150–1156, Mon-
treal, Canada.
Anne Schuth, Maarten Marx, and Maarten de Rijke.
2007. Extracting the discussion structure in com-
ments on news-articles. In Proceedings of the 9th
Annual ACM International Workshop on Web Infor-
mation and Data Management, pages 97–104, Lis-
boa, Portugal.
Jangwon Seo, W. Bruce Croft, and David A. Smith.
2009. Online community search using thread struc-
ture. In Proceedings of the 18th ACM Conference
on Information and Knowledge Management (CIKM
2009), pages 1907–1910, Hong Kong, China.
Riccardo Serafin and Barbara Di Eugenio. 2004.
FLSA: Extending latent semantic analysis with fea-
tures for dialogue act classification. In Proceedings
of the 42nd Annual Meeting of the Association for
Computational Linguistics (ACL 2004), pages 692–
699, Barcelona, Spain.
Fei Sha and Fernando Pereira. 2003. Shallow pars-
ing with conditional random fields. In Proceedings
of the 3rd International Conference on Human Lan-
guage Technology Research and 4th Annual Meeting
of the NAACL (HLT-NAACL 2003), pages 213–220,
Edmonton, Canada.
Lokesh Shrestha and Kathleen McKeown. 2004. De-
tection of question-answer pairs in email conver-
sations. In Proceedings of the 20th International
Conference on Computational Linguistics (COLING
2004), pages 889–895, Geneva, Switzerland.
Elinzabeth Shriberg, Raj Dhillon, Sonali Bhagat,
Jeremy Ang, and Hannah Carvey. 2004. The ICSI
meeting recorder dialog act (MRDA) corpus. In
Proceedings of the 5th SIGdial Workshop on Dis-
course and Dialogue, pages 97–100, Cambridge,
USA.
Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliz-
abeth Shriberg, Rebecca Bates, Daniel Jurafsky,
Pail Taylor, Rachel Martin, Carol Van Ess-Dykema,
and Marie Meteer. 2000. Dialogue Act Mod-
eling for Automatic Tagging and Recognition of
Conversational Speech. Computational Linguistics,
26(3):339–373.
Yi-Chia Wang, Mahesh Joshi, and Carolyn Ros´e. 2007.
A feature based approach to leveraging context for
classifying newsgroup style discussion segments. In
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics Companion
Volume Proceedings of the Demo and Poster Ses-
sions (ACL 2007), pages 73–76, Prague, Czech Re-
public.
Yi-Chia Wang, Mahesh Joshi, William W. Cohen, and
Carolyn Ros´e. 2008. Recovering implicit thread
structure in newsgroup style conversations. In Pro-
ceedings of the Second International Conference on
Weblogs and Social Media (ICWSM 2008), pages
152–160, Seattle, USA.
Markus Weimer, Iryna Gurevych, and Max
M¨uhlh¨auser. 2007. Automatically assessing
the post quality in online discussions on software.
In Proceedings of the 45th Annual Meeting of
the ACL: Interactive Poster and Demonstration
Sessions, pages 125–128, Prague, Czech Republic.
Florian Wolf and Edward Gibson. 2005. Representing
discourse coherence: A corpus-based study. Com-
putational Linguistics, 31(2):249–287.
Wensi Xi, Jesper Lind, and Eric Brill. 2004. Learning
effective ranking functions for newsgroup search.
In Proceedings of 27th International ACM-SIGIR
Conference on Research and Development in In-
formation Retrieval (SIGIR 2004), pages 394–401.
Sheffield, UK.
Alexander Yeh. 2000. More accurate tests for the sta-
tistical significance of result differences. In Pro-
ceedings of the 18th International Conference on
Computational Linguistics (COLING 2000), pages
947–953, Saarbr¨ucken, Germany.
Hai Zhao, Chang-Ning Huang, and Mu Li. 2006. An
improved Chinese word segmentation system with
conditional random field. In Proceedings of the Fifth
SIGHAN Workshop on Chinese Language Process-
ing, pages 162–165. Sydney, Australia.
</reference>
<page confidence="0.998327">
202
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.937791">
<title confidence="0.999929">Tagging and Linking Web Forum Posts</title>
<author confidence="0.999531">Nam Kim</author>
<author confidence="0.999531">Li Wang</author>
<affiliation confidence="0.999916">Dept of Computer Science and Software University of Melbourne,</affiliation>
<abstract confidence="0.996749368421053">We propose a method for annotating postto-post discourse structure in online user forum data, in the hopes of improving troubleshooting-oriented information access. We introduce the tasks of: (1) post classification, based on a novel dialogue act tag set; and (2) link classification. We also introduce three feature sets (structural features, post context features and semantic features) and experiment with three discriminative learners (maximum entropy, SVM-HMM and CRF). We achieve abovebaseline results for both dialogue act and link classification, with interesting divergences in which feature sets perform well over the two sub-tasks, and go on to perform preliminary investigation of the interaction between post tagging and linking.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jeremy Ang</author>
<author>Yang Liu</author>
<author>Elizabeth Shriberg</author>
</authors>
<title>Automatic dialog act segmentation and classification in multiparty meetings.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2005 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP</booktitle>
<pages>1061--1064</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="7176" citStr="Ang et al., 2005" startWordPosition="1205" endWordPosition="1208">004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup data (including QUESTION and AGREEMENT/AMMENDMENT), but did not present any results based on the tagset. A range of supervised models have been applied to DA classification, including graphical models (Ji and Bilmes, 2005), kernel methods (Wang et al., 2007), dependency networks (Carvalho and Cohen, 2005), transformation-based learning (Samuel et al., 1998), maxent models (Ang et al., 2005) and HMMs (Ivanovic, 2008). There is some contention about the import of context in DA classification, with the prevailing view being that context aids classification (Carvalho and Cohen, 2005; Ang et al., 2005; Ji and Bilmes, 2005), but also evidence to suggest that strictly local modelling is superior (Ries, 1999; Serafin and Di Eugenio, 2004). In this work, we draw on existing work (esp. Xi et al. (2004)) in proposing a novel DA tag set customised to the analysis of troubleshootingoriented web user forums (Section 3), and compare a range of text classification and structured classification </context>
</contexts>
<marker>Ang, Liu, Shriberg, 2005</marker>
<rawString>Jeremy Ang, Yang Liu, and Elizabeth Shriberg. 2005. Automatic dialog act segmentation and classification in multiparty meetings. In Proceedings of the 2005 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2005), pages 1061–1064, Philadelphia, USA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Timothy Baldwin</author>
<author>David Martinez</author>
<author>Richard Penman</author>
<author>Su Nam Kim</author>
<author>Marco Lui</author>
<author>Li Wang</author>
<author>Andrew MacKinlay</author>
</authors>
<title>to appear. Intelligent Linux information access by data mining: the ILIAD project.</title>
<booktitle>In Proceedings of the NAACL 2010 Workshop on Computational Linguistics in a World of Social</booktitle>
<location>Media: #SocialMedia, Los Angeles, USA.</location>
<marker>Baldwin, Martinez, Penman, Kim, Lui, Wang, MacKinlay, </marker>
<rawString>Timothy Baldwin, David Martinez, Richard Penman, Su Nam Kim, Marco Lui, Li Wang, and Andrew MacKinlay. to appear. Intelligent Linux information access by data mining: the ILIAD project. In Proceedings of the NAACL 2010 Workshop on Computational Linguistics in a World of Social Media: #SocialMedia, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Bartlett</author>
<author>Grzegorz Kondrak</author>
<author>Colin Cherry</author>
</authors>
<title>On the syllabification of phonemes.</title>
<date>2009</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics – Human Language Technologies</booktitle>
<pages>308--316</pages>
<location>Boulder, USA.</location>
<contexts>
<context position="19324" citStr="Bartlett et al., 2009" startWordPosition="3211" endWordPosition="3214"> posts, 65 posts have multiple labels (which possibly link to a common post) and 22 posts link to two different links. The majority post label in the dataset is A-A (40.30%). 1http://forums.cnet.com/?tag= TOCleftColumn.0 We built machine learners using a conventional Maximum Entropy (ME) learner,2 as well as two structural learners, namely: (1) SVM-HMMs (Joachims et al., 2009), as implemented in SVMstruct3, with a linear kernel; and (2) conditional random fields (CRFs) using CRF++.4 SVMHMMs and CRFs have been successfully applied to a range of sequential tagging tasks such as syllabification (Bartlett et al., 2009), chunk parsing (Sha and Pereira, 2003) and word segmentation (Zhao et al., 2006). Both are discriminative models which capture structural dependencies, which is highly desirable in terms of modelling sequential preferences between post labels (e.g. A-CONF typically following a A-A). SVMHMM has the additional advantage of scaling to large numbers of features (namely the lexical features). As such, we only experiment with lexical features for SVM-HMM and ME. All of our evaluation is based on stratified 10- fold cross-validation, stratifying at the thread level to ensure that if a given post is </context>
</contexts>
<marker>Bartlett, Kondrak, Cherry, 2009</marker>
<rawString>Susan Bartlett, Grzegorz Kondrak, and Colin Cherry. 2009. On the syllabification of phonemes. In Proceedings of the North American Chapter of the Association for Computational Linguistics – Human Language Technologies 2009 (NAACL HLT 2009), pages 308–316, Boulder, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xin Cao</author>
<author>Gao Cong</author>
<author>Bin Cui</author>
<author>Christian S Jensen</author>
<author>Ce Zhang</author>
</authors>
<title>The use of categorization information in language models for question retrieval.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM</booktitle>
<pages>265--274</pages>
<location>Hong Kong, China.</location>
<contexts>
<context position="9974" citStr="Cao et al., 2009" startWordPosition="1657" endWordPosition="1660">f discourse structure, and draw on the wide set of features used in discourse entanglement to model coherence. Community question answering (cQA) is the task of identifying question–answer pairs in a given thread, e.g. for the purposes of thread summarisation (Shrestha and McKeown, 2004) or automated compilation of resources akin to Yahoo! Answers. cQA has been applied to both mailing list and user forum threads, conventionally based on question classification, followed by ranking of candidate answers relative to each question (Shrestha and McKeown, 2004; Ding et al., 2008; Cong et al., 2008; Cao et al., 2009). The task is somewhat peripheral to our work, but relevant in that it involves the implicit tagging of certain posts as containing questions/answers, as well as linking the posts together. Once again, we draw on the features used in cQA in this research. There has been a spike of recent interest in newsgroup/user forum search. Xi et al. (2004) proposed a structured information retrieval (IR) model for newsgroup search, based on author features, thread structure (based on the tree defined by the reply-to structure), thread “topology” features and content-based features, and used a supervised r</context>
</contexts>
<marker>Cao, Cong, Cui, Jensen, Zhang, 2009</marker>
<rawString>Xin Cao, Gao Cong, Bin Cui, Christian S. Jensen, and Ce Zhang. 2009. The use of categorization information in language models for question retrieval. In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM 2009), pages 265–274, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Carlson</author>
<author>Daniel Marcu</author>
<author>Mary Ellen Okurowski</author>
</authors>
<title>Building a discourse-tagged corpus in the framework of rhetorical structure theory.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics</institution>
<location>Aalborg, Denmark.</location>
<contexts>
<context position="2795" citStr="Carlson et al., 2001" startWordPosition="432" endWordPosition="435">is task of enhanced support sharing, in the form of text mining over troubleshootingoriented web user forum data (Baldwin et al., to appear). One facet of our proposed strategy for enhancing information access to troubleshooting-oriented web user forum data is to preprocess threads to uncover the “content structure” of the thread, in the form of its post-to-post discourse structure. Specifically, we identify which earlier post(s) a given post responds to (linking) and in what manner (tagging), in an amalgam of dialogue act tagging (Stolcke et al., 2000) and coherence-based discourse analysis (Carlson et al., 2001; Wolf and Gibson, 2005). The reason we do this is gauge the relative role/import of individual posts, to index and weight component terms accordingly, ultimately in an attempt to enhance information access. Evidence to suggest that this structure can enhance information retrieval effectiveness comes from Xi et al. (2004) and Seo et al. (2009) (see Section 2). To illustrate the task, consider the thread from the CNET forum shown in Figure 1, made up of 5 posts (Post 1, ..., Post 5) with 4 distinct participants (A, B, C, D). In the first post, A initiates the thread by requesting assistance in </context>
</contexts>
<marker>Carlson, Marcu, Okurowski, 2001</marker>
<rawString>Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski. 2001. Building a discourse-tagged corpus in the framework of rhetorical structure theory. In Proceedings of the Second SIGdial Workshop on Discourse and Dialogue, pages 1–10, Aalborg, Denmark. Association for Computational Linguistics Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vitor R Carvalho</author>
<author>William W Cohen</author>
</authors>
<title>On the collective classification of email ”speech acts”.</title>
<date>2005</date>
<booktitle>In Proceedings of 28th International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR</booktitle>
<pages>345--352</pages>
<contexts>
<context position="7089" citStr="Carvalho and Cohen, 2005" startWordPosition="1193" endWordPosition="1196">eech dialogue (Stolcke et al., 2000; Shriberg et al., 2004), taskfocused email (Cohen et al., 2004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup data (including QUESTION and AGREEMENT/AMMENDMENT), but did not present any results based on the tagset. A range of supervised models have been applied to DA classification, including graphical models (Ji and Bilmes, 2005), kernel methods (Wang et al., 2007), dependency networks (Carvalho and Cohen, 2005), transformation-based learning (Samuel et al., 1998), maxent models (Ang et al., 2005) and HMMs (Ivanovic, 2008). There is some contention about the import of context in DA classification, with the prevailing view being that context aids classification (Carvalho and Cohen, 2005; Ang et al., 2005; Ji and Bilmes, 2005), but also evidence to suggest that strictly local modelling is superior (Ries, 1999; Serafin and Di Eugenio, 2004). In this work, we draw on existing work (esp. Xi et al. (2004)) in proposing a novel DA tag set customised to the analysis of troubleshootingoriented web user forums</context>
</contexts>
<marker>Carvalho, Cohen, 2005</marker>
<rawString>Vitor R. Carvalho and William W. Cohen. 2005. On the collective classification of email ”speech acts”. In Proceedings of 28th International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2005), pages 345–352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
<author>Vitor R Carvalho</author>
<author>Tom M Mitchell</author>
</authors>
<title>Learning to classify email into “speech acts”.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP 2004),</booktitle>
<pages>309--316</pages>
<location>Barcelona,</location>
<contexts>
<context position="6253" citStr="Cohen et al., 2004" startWordPosition="1052" endWordPosition="1055"> the respective tasks. 2 Related Work Related work exists in the broad fields of dialogue processing, discourse analysis and information retrieval, and can be broken down into the following tasks: (1) dialogue act tagging; (2) discourse “disentanglement”; (3) community question answering; and (4) newsgroup/user forum search. Dialogue act (DA) tagging is a means of capturing the function of a given utterance relative to an encompassing discourse, and has been proposed variously as a means of enhancing dialogue summarisation (Murray et al., 2006), and tracking commitments and promises in email (Cohen et al., 2004; Lampert et al., 2008), as well as being shown to improve speech recognition accuracy (Stolcke et al., 2000). A wide range of DA tag sets have been proposed, usually customised to a particular medium such as speech dialogue (Stolcke et al., 2000; Shriberg et al., 2004), taskfocused email (Cohen et al., 2004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup data (including QUESTION and AGREEMENT/AMMENDMENT), but did not presen</context>
</contexts>
<marker>Cohen, Carvalho, Mitchell, 2004</marker>
<rawString>William W. Cohen, Vitor R. Carvalho, and Tom M. Mitchell. 2004. Learning to classify email into “speech acts”. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP 2004), pages 309–316, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gao Cong</author>
<author>Long Wang</author>
<author>Chin-Yew Lin</author>
<author>Young-In Song</author>
<author>Yueheng Sun</author>
</authors>
<title>Finding questionanswer pairs from online forums.</title>
<date>2008</date>
<booktitle>In Proceedings of 31st International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’08),</booktitle>
<pages>467--474</pages>
<contexts>
<context position="9955" citStr="Cong et al., 2008" startWordPosition="1653" endWordPosition="1656">AG representation of discourse structure, and draw on the wide set of features used in discourse entanglement to model coherence. Community question answering (cQA) is the task of identifying question–answer pairs in a given thread, e.g. for the purposes of thread summarisation (Shrestha and McKeown, 2004) or automated compilation of resources akin to Yahoo! Answers. cQA has been applied to both mailing list and user forum threads, conventionally based on question classification, followed by ranking of candidate answers relative to each question (Shrestha and McKeown, 2004; Ding et al., 2008; Cong et al., 2008; Cao et al., 2009). The task is somewhat peripheral to our work, but relevant in that it involves the implicit tagging of certain posts as containing questions/answers, as well as linking the posts together. Once again, we draw on the features used in cQA in this research. There has been a spike of recent interest in newsgroup/user forum search. Xi et al. (2004) proposed a structured information retrieval (IR) model for newsgroup search, based on author features, thread structure (based on the tree defined by the reply-to structure), thread “topology” features and content-based features, and </context>
</contexts>
<marker>Cong, Wang, Lin, Song, Sun, 2008</marker>
<rawString>Gao Cong, Long Wang, Chin-Yew Lin, Young-In Song, and Yueheng Sun. 2008. Finding questionanswer pairs from online forums. In Proceedings of 31st International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’08), pages 467–474, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shilin Ding</author>
<author>Gao Cong</author>
<author>Chin-Yew Lin</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Using conditional random fields to extract context and answers of questions from online forums.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the ACL: HLT (ACL</booktitle>
<pages>710--718</pages>
<location>Columbus, USA.</location>
<contexts>
<context position="9936" citStr="Ding et al., 2008" startWordPosition="1649" endWordPosition="1652">05) in adopting a DAG representation of discourse structure, and draw on the wide set of features used in discourse entanglement to model coherence. Community question answering (cQA) is the task of identifying question–answer pairs in a given thread, e.g. for the purposes of thread summarisation (Shrestha and McKeown, 2004) or automated compilation of resources akin to Yahoo! Answers. cQA has been applied to both mailing list and user forum threads, conventionally based on question classification, followed by ranking of candidate answers relative to each question (Shrestha and McKeown, 2004; Ding et al., 2008; Cong et al., 2008; Cao et al., 2009). The task is somewhat peripheral to our work, but relevant in that it involves the implicit tagging of certain posts as containing questions/answers, as well as linking the posts together. Once again, we draw on the features used in cQA in this research. There has been a spike of recent interest in newsgroup/user forum search. Xi et al. (2004) proposed a structured information retrieval (IR) model for newsgroup search, based on author features, thread structure (based on the tree defined by the reply-to structure), thread “topology” features and content-b</context>
</contexts>
<marker>Ding, Cong, Lin, Zhu, 2008</marker>
<rawString>Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan Zhu. 2008. Using conditional random fields to extract context and answers of questions from online forums. In Proceedings of the 46th Annual Meeting of the ACL: HLT (ACL 2008), pages 710–718, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan L Elsas</author>
<author>Jaime G Carbonell</author>
</authors>
<title>It pays to be picky: An evaluation of thread retrieval in online forums.</title>
<date>2009</date>
<booktitle>In Proceedings of 32nd International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’09),</booktitle>
<pages>714--715</pages>
<location>Boston, USA.</location>
<contexts>
<context position="10652" citStr="Elsas and Carbonell (2009)" startWordPosition="1767" endWordPosition="1770">elevant in that it involves the implicit tagging of certain posts as containing questions/answers, as well as linking the posts together. Once again, we draw on the features used in cQA in this research. There has been a spike of recent interest in newsgroup/user forum search. Xi et al. (2004) proposed a structured information retrieval (IR) model for newsgroup search, based on author features, thread structure (based on the tree defined by the reply-to structure), thread “topology” features and content-based features, and used a supervised ranking method to improve over a baseline IR system. Elsas and Carbonell (2009) — building on earlier work on blog search (Elsas et al., 2008) — proposed a probabilistic IR approach which ranks user forum threads relative to selected posts in the overall thread, and again demonstrated the superiority of this method over a model which ignores thread structure. Finally, Seo et al. (2009) automatically derived thread structure from user forum threads, and demonstrated that the IR effectiveness over the “threaded” structure was superior to that using a monolithic document representation. The observations and results of Xi et al. (2004) and Seo et al. (2009) that threading in</context>
</contexts>
<marker>Elsas, Carbonell, 2009</marker>
<rawString>Jonathan L. Elsas and Jaime G. Carbonell. 2009. It pays to be picky: An evaluation of thread retrieval in online forums. In Proceedings of 32nd International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’09), pages 714–715, Boston, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan L Elsas</author>
<author>Jaime Arguello</author>
<author>Jamie Callan</author>
<author>Jaime G Carbonell</author>
</authors>
<title>Retrieval and feedback models for blog feed search.</title>
<date>2008</date>
<booktitle>In Proceedings of 31st International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’08),</booktitle>
<pages>347--354</pages>
<contexts>
<context position="10715" citStr="Elsas et al., 2008" startWordPosition="1779" endWordPosition="1782">ontaining questions/answers, as well as linking the posts together. Once again, we draw on the features used in cQA in this research. There has been a spike of recent interest in newsgroup/user forum search. Xi et al. (2004) proposed a structured information retrieval (IR) model for newsgroup search, based on author features, thread structure (based on the tree defined by the reply-to structure), thread “topology” features and content-based features, and used a supervised ranking method to improve over a baseline IR system. Elsas and Carbonell (2009) — building on earlier work on blog search (Elsas et al., 2008) — proposed a probabilistic IR approach which ranks user forum threads relative to selected posts in the overall thread, and again demonstrated the superiority of this method over a model which ignores thread structure. Finally, Seo et al. (2009) automatically derived thread structure from user forum threads, and demonstrated that the IR effectiveness over the “threaded” structure was superior to that using a monolithic document representation. The observations and results of Xi et al. (2004) and Seo et al. (2009) that threading information (or in our case “disentangled” DAG structure) enhance</context>
</contexts>
<marker>Elsas, Arguello, Callan, Carbonell, 2008</marker>
<rawString>Jonathan L. Elsas, Jaime Arguello, Jamie Callan, and Jaime G. Carbonell. 2008. Retrieval and feedback models for blog feed search. In Proceedings of 31st International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’08), pages 347–354, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
<author>Eugene Charniak</author>
</authors>
<title>You talking to me? a corpus and algorithm for conversation disentanglement.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the ACL: HLT (ACL</booktitle>
<pages>834--842</pages>
<location>Columbus, USA.</location>
<contexts>
<context position="8051" citStr="Elsner and Charniak (2008)" startWordPosition="1346" endWordPosition="1349">ce to suggest that strictly local modelling is superior (Ries, 1999; Serafin and Di Eugenio, 2004). In this work, we draw on existing work (esp. Xi et al. (2004)) in proposing a novel DA tag set customised to the analysis of troubleshootingoriented web user forums (Section 3), and compare a range of text classification and structured classification methods for post-level DA classification. Discourse disentanglement is the process of automatically identifying coherent sub-discourses in a single thread (in the context of user forums/mailing lists), chat session (in the context of IRC chat data: Elsner and Charniak (2008)), system interaction (in the context of HCI: Lemon et al. (2002)) or document (Wolf and Gibson, 2005). The exact definition of what constitutes a subdiscourse varies across domains, but for our purposes, entails an attempt to resolve the informaQuestion-Question Post 1 Answer-Answer Post 2 Answer-Answer Post 3 Answer-Clarification Post 4 Answer-Answer 193 tion need of the initiator by a particular approach; if there are competing approaches proposed in a single thread, multiple sub-discourses will necessarily arise. The data structure used to represent the disentangled discourse varies from a</context>
</contexts>
<marker>Elsner, Charniak, 2008</marker>
<rawString>Micha Elsner and Eugene Charniak. 2008. You talking to me? a corpus and algorithm for conversation disentanglement. In Proceedings of the 46th Annual Meeting of the ACL: HLT (ACL 2008), pages 834– 842, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michaela G¨otz</author>
<author>Jure Leskovec</author>
<author>Mary McGlohon</author>
<author>Christos Faloutsos</author>
</authors>
<title>Modeling blog dynamics.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third International Conference on Weblogs and Social Media (ICWSM</booktitle>
<pages>26--33</pages>
<location>San Jose, USA.</location>
<marker>G¨otz, Leskovec, McGlohon, Faloutsos, 2009</marker>
<rawString>Michaela G¨otz, Jure Leskovec, Mary McGlohon, and Christos Faloutsos. 2009. Modeling blog dynamics. In Proceedings of the Third International Conference on Weblogs and Social Media (ICWSM 2009), pages 26–33, San Jose, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, intention and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="8747" citStr="Grosz and Sidner, 1986" startWordPosition="1453" endWordPosition="1456">ment (Wolf and Gibson, 2005). The exact definition of what constitutes a subdiscourse varies across domains, but for our purposes, entails an attempt to resolve the informaQuestion-Question Post 1 Answer-Answer Post 2 Answer-Answer Post 3 Answer-Clarification Post 4 Answer-Answer 193 tion need of the initiator by a particular approach; if there are competing approaches proposed in a single thread, multiple sub-discourses will necessarily arise. The data structure used to represent the disentangled discourse varies from a simple connected sub-graph (Elsner and Charniak, 2008), to a stack/tree (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), to a full directed acyclic graph (DAG: Ros´e et al. (1995), Wolf and Gibson (2005), Schuth et al. (2007)). Disentanglement has been carried out via analysis of direct citation/user name references (Schuth et al., 2007; Seo et al., 2009), topic modelling (Lin et al., 2009), and clustering over content-based features for pairs of posts, optionally incorporating various constraints on post recency (Elsner and Charniak, 2008; Wang et al., 2008; Seo et al., 2009). In this work, we follow Ros´e et al. (1995) and Wolf and Gibson (2005) in adopting a DAG repres</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intention and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Ivanovic</author>
</authors>
<title>Automatic instant messaging dialogue using statistical models and dialogue acts. Master’s thesis,</title>
<date>2008</date>
<institution>University of Melbourne.</institution>
<contexts>
<context position="6642" citStr="Ivanovic, 2008" startWordPosition="1123" endWordPosition="1124"> a given utterance relative to an encompassing discourse, and has been proposed variously as a means of enhancing dialogue summarisation (Murray et al., 2006), and tracking commitments and promises in email (Cohen et al., 2004; Lampert et al., 2008), as well as being shown to improve speech recognition accuracy (Stolcke et al., 2000). A wide range of DA tag sets have been proposed, usually customised to a particular medium such as speech dialogue (Stolcke et al., 2000; Shriberg et al., 2004), taskfocused email (Cohen et al., 2004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup data (including QUESTION and AGREEMENT/AMMENDMENT), but did not present any results based on the tagset. A range of supervised models have been applied to DA classification, including graphical models (Ji and Bilmes, 2005), kernel methods (Wang et al., 2007), dependency networks (Carvalho and Cohen, 2005), transformation-based learning (Samuel et al., 1998), maxent models (Ang et al., 2005) and HMMs (Ivanovic, 2008). There is some contention about the imp</context>
</contexts>
<marker>Ivanovic, 2008</marker>
<rawString>Edward Ivanovic. 2008. Automatic instant messaging dialogue using statistical models and dialogue acts. Master’s thesis, University of Melbourne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gang Ji</author>
<author>Jeff Bilmes</author>
</authors>
<title>Dialog act tagging using graphical models.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2005 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP</booktitle>
<pages>33--36</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="7005" citStr="Ji and Bilmes, 2005" startWordPosition="1181" endWordPosition="1184">g sets have been proposed, usually customised to a particular medium such as speech dialogue (Stolcke et al., 2000; Shriberg et al., 2004), taskfocused email (Cohen et al., 2004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup data (including QUESTION and AGREEMENT/AMMENDMENT), but did not present any results based on the tagset. A range of supervised models have been applied to DA classification, including graphical models (Ji and Bilmes, 2005), kernel methods (Wang et al., 2007), dependency networks (Carvalho and Cohen, 2005), transformation-based learning (Samuel et al., 1998), maxent models (Ang et al., 2005) and HMMs (Ivanovic, 2008). There is some contention about the import of context in DA classification, with the prevailing view being that context aids classification (Carvalho and Cohen, 2005; Ang et al., 2005; Ji and Bilmes, 2005), but also evidence to suggest that strictly local modelling is superior (Ries, 1999; Serafin and Di Eugenio, 2004). In this work, we draw on existing work (esp. Xi et al. (2004)) in proposing a no</context>
</contexts>
<marker>Ji, Bilmes, 2005</marker>
<rawString>Gang Ji and Jeff Bilmes. 2005. Dialog act tagging using graphical models. In Proceedings of the 2005 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2005), pages 33–36, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
<author>Thomas Finley</author>
<author>ChunNam John Yu</author>
</authors>
<title>Cutting-plane training of structural SVMs.</title>
<date>2009</date>
<booktitle>Machine Learning,</booktitle>
<volume>77</volume>
<issue>1</issue>
<contexts>
<context position="19081" citStr="Joachims et al., 2009" startWordPosition="3172" endWordPosition="3175">osts with multilabels, we used a modified version of Cohen’s Kappa, which returned r. values of 0.59 and 0.78 for the post label and link annotations, respectively. Any disagreements in labelling were resolved through adjudication. Of the 1332 posts, 65 posts have multiple labels (which possibly link to a common post) and 22 posts link to two different links. The majority post label in the dataset is A-A (40.30%). 1http://forums.cnet.com/?tag= TOCleftColumn.0 We built machine learners using a conventional Maximum Entropy (ME) learner,2 as well as two structural learners, namely: (1) SVM-HMMs (Joachims et al., 2009), as implemented in SVMstruct3, with a linear kernel; and (2) conditional random fields (CRFs) using CRF++.4 SVMHMMs and CRFs have been successfully applied to a range of sequential tagging tasks such as syllabification (Bartlett et al., 2009), chunk parsing (Sha and Pereira, 2003) and word segmentation (Zhao et al., 2006). Both are discriminative models which capture structural dependencies, which is highly desirable in terms of modelling sequential preferences between post labels (e.g. A-CONF typically following a A-A). SVMHMM has the additional advantage of scaling to large numbers of featu</context>
</contexts>
<marker>Joachims, Finley, Yu, 2009</marker>
<rawString>Thorsten Joachims, Thomas Finley, and ChunNam John Yu. 2009. Cutting-plane training of structural SVMs. Machine Learning, 77(1):27–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Lampert</author>
<author>Robert Dale</author>
<author>C´ecile Paris</author>
</authors>
<title>The nature of requests and commitments in email messages.</title>
<date>2008</date>
<booktitle>In Proceedings of the AAAI 2008 Workshop on Enhanced Messaging,</booktitle>
<pages>42--47</pages>
<location>Chicago, USA.</location>
<contexts>
<context position="6276" citStr="Lampert et al., 2008" startWordPosition="1056" endWordPosition="1059">s. 2 Related Work Related work exists in the broad fields of dialogue processing, discourse analysis and information retrieval, and can be broken down into the following tasks: (1) dialogue act tagging; (2) discourse “disentanglement”; (3) community question answering; and (4) newsgroup/user forum search. Dialogue act (DA) tagging is a means of capturing the function of a given utterance relative to an encompassing discourse, and has been proposed variously as a means of enhancing dialogue summarisation (Murray et al., 2006), and tracking commitments and promises in email (Cohen et al., 2004; Lampert et al., 2008), as well as being shown to improve speech recognition accuracy (Stolcke et al., 2000). A wide range of DA tag sets have been proposed, usually customised to a particular medium such as speech dialogue (Stolcke et al., 2000; Shriberg et al., 2004), taskfocused email (Cohen et al., 2004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup data (including QUESTION and AGREEMENT/AMMENDMENT), but did not present any results based on </context>
</contexts>
<marker>Lampert, Dale, Paris, 2008</marker>
<rawString>Andrew Lampert, Robert Dale, and C´ecile Paris. 2008. The nature of requests and commitments in email messages. In Proceedings of the AAAI 2008 Workshop on Enhanced Messaging, pages 42–47, Chicago, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Alex Gruenstein</author>
<author>Stanley Peters</author>
</authors>
<title>Collaborative activities and multitasking in dialogue systems.</title>
<date>2002</date>
<journal>Traitement Automatique des Langues (TAL), Special Issue on Dialogue,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="8116" citStr="Lemon et al. (2002)" startWordPosition="1358" endWordPosition="1361">afin and Di Eugenio, 2004). In this work, we draw on existing work (esp. Xi et al. (2004)) in proposing a novel DA tag set customised to the analysis of troubleshootingoriented web user forums (Section 3), and compare a range of text classification and structured classification methods for post-level DA classification. Discourse disentanglement is the process of automatically identifying coherent sub-discourses in a single thread (in the context of user forums/mailing lists), chat session (in the context of IRC chat data: Elsner and Charniak (2008)), system interaction (in the context of HCI: Lemon et al. (2002)) or document (Wolf and Gibson, 2005). The exact definition of what constitutes a subdiscourse varies across domains, but for our purposes, entails an attempt to resolve the informaQuestion-Question Post 1 Answer-Answer Post 2 Answer-Answer Post 3 Answer-Clarification Post 4 Answer-Answer 193 tion need of the initiator by a particular approach; if there are competing approaches proposed in a single thread, multiple sub-discourses will necessarily arise. The data structure used to represent the disentangled discourse varies from a simple connected sub-graph (Elsner and Charniak, 2008), to a sta</context>
</contexts>
<marker>Lemon, Gruenstein, Peters, 2002</marker>
<rawString>Oliver Lemon, Alex Gruenstein, and Stanley Peters. 2002. Collaborative activities and multitasking in dialogue systems. Traitement Automatique des Langues (TAL), Special Issue on Dialogue, 43(2):131–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Lin</author>
<author>Jiang-Ming Yang</author>
<author>Rui Cai</author>
<author>Xin-Jing Wang</author>
<author>Wei Wang</author>
<author>Lei Zhang</author>
</authors>
<title>Modeling semantics and structure of discussion threads.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th International Conference on the World Wide Web (WWW</booktitle>
<pages>1103--1104</pages>
<location>Madrid,</location>
<contexts>
<context position="9060" citStr="Lin et al., 2009" startWordPosition="1508" endWordPosition="1511">articular approach; if there are competing approaches proposed in a single thread, multiple sub-discourses will necessarily arise. The data structure used to represent the disentangled discourse varies from a simple connected sub-graph (Elsner and Charniak, 2008), to a stack/tree (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), to a full directed acyclic graph (DAG: Ros´e et al. (1995), Wolf and Gibson (2005), Schuth et al. (2007)). Disentanglement has been carried out via analysis of direct citation/user name references (Schuth et al., 2007; Seo et al., 2009), topic modelling (Lin et al., 2009), and clustering over content-based features for pairs of posts, optionally incorporating various constraints on post recency (Elsner and Charniak, 2008; Wang et al., 2008; Seo et al., 2009). In this work, we follow Ros´e et al. (1995) and Wolf and Gibson (2005) in adopting a DAG representation of discourse structure, and draw on the wide set of features used in discourse entanglement to model coherence. Community question answering (cQA) is the task of identifying question–answer pairs in a given thread, e.g. for the purposes of thread summarisation (Shrestha and McKeown, 2004) or automated c</context>
</contexts>
<marker>Lin, Yang, Cai, Wang, Wang, Zhang, 2009</marker>
<rawString>Chen Lin, Jiang-Ming Yang, Rui Cai, Xin-Jing Wang, Wei Wang, and Lei Zhang. 2009. Modeling semantics and structure of discussion threads. In Proceedings of the 18th International Conference on the World Wide Web (WWW 2009), pages 1103–1104, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Lui</author>
<author>Timothy Baldwin</author>
</authors>
<title>You are what you post: User-level features in threaded discourse.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourteenth Australasian Document Computing Symposium (ADCS 2009),</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="35591" citStr="Lui and Baldwin, 2009" startWordPosition="5873" endWordPosition="5876">fferent feature sets, especially for DA classification where all feature sets were found to produce above-baseline results. Another possible direction for future research is to explore the impact of inter-post time on link structure, based on the observation that followup posts from the initiator tend to be temporally adjacent to posts they respond to with relatively short time intervals, while posts from noninitiators which are well spaced out tend not to respond to one another. Combining this with profiling of the cross-thread behaviour of individual forum participants (Weimer et al., 2007; Lui and Baldwin, 2009), and formal modelling of “forum behaviour” is also a promising line of research, taking the lead from the work of G¨otz et al. (2009), inter alia. 9 Conclusion In this work, we have proposed a method for analysing post-to-post discourse structure in online user forum data, in the form of post linking and dialogue act tagging. We introduced three feature sets: structural features, post context features and semantic features. We experimented with three learners (maximum entropy, SVM-HMM and CRF), and established that CRF is the superior approach to the task, achieving above-baseline results for</context>
</contexts>
<marker>Lui, Baldwin, 2009</marker>
<rawString>Marco Lui and Timothy Baldwin. 2009. You are what you post: User-level features in threaded discourse. In Proceedings of the Fourteenth Australasian Document Computing Symposium (ADCS 2009), Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>John Carroll</author>
<author>Darren Pearce</author>
</authors>
<title>Applied morphological processing of English.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="14644" citStr="Minnen et al., 2001" startWordPosition="2404" endWordPosition="2408">erienced (by a non-initiator, e.g. I’m seeing the same thing.); or (2) confirms that the answer should work. OTHER (OTHER): the post does not belong to any of the above classes. 4 Feature Description In this section, we describe our post feature representation, in the form of four feature types. 4.1 Lexical features As our first feature type, we use simple lexical features, in the form of unigram and bigram tokens contained within a given post (without stopping). We also POS tagged and lemmatised the posts, postfixing the lemmatised token with its POS tag (using Lingua::EN::Tagger and morpha (Minnen et al., 2001)). Finally, we bin together the counts for each token, and represent it via its raw frequency. 4.2 Structural features The identity of the post author, and position of the post within the thread, can be indicators of the post/link structure of a given post. We represent the post author as a simple binary feature indicating whether s/he is the thread initiator, and the post position via its relative position in the thread (as a ratio, relative to the total number of posts). 4.3 Post context features As mentioned in Section 2, post context has generally (but not always) been shown to enhance the</context>
</contexts>
<marker>Minnen, Carroll, Pearce, 2001</marker>
<rawString>Guido Minnen, John Carroll, and Darren Pearce. 2001. Applied morphological processing of English. Natural Language Engineering, 7(3):207–223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Murray</author>
<author>Steve Renals</author>
<author>Jean Carletta</author>
<author>Johanna Moore</author>
</authors>
<title>Incorporating speaker and discourse features into speech summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>367--374</pages>
<contexts>
<context position="6185" citStr="Murray et al., 2006" startWordPosition="1040" endWordPosition="1043">ost dependency linking and labelling, which achieve strong results for the respective tasks. 2 Related Work Related work exists in the broad fields of dialogue processing, discourse analysis and information retrieval, and can be broken down into the following tasks: (1) dialogue act tagging; (2) discourse “disentanglement”; (3) community question answering; and (4) newsgroup/user forum search. Dialogue act (DA) tagging is a means of capturing the function of a given utterance relative to an encompassing discourse, and has been proposed variously as a means of enhancing dialogue summarisation (Murray et al., 2006), and tracking commitments and promises in email (Cohen et al., 2004; Lampert et al., 2008), as well as being shown to improve speech recognition accuracy (Stolcke et al., 2000). A wide range of DA tag sets have been proposed, usually customised to a particular medium such as speech dialogue (Stolcke et al., 2000; Shriberg et al., 2004), taskfocused email (Cohen et al., 2004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup da</context>
</contexts>
<marker>Murray, Renals, Carletta, Moore, 2006</marker>
<rawString>Gabriel Murray, Steve Renals, Jean Carletta, and Johanna Moore. 2006. Incorporating speaker and discourse features into speech summarization. In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 367–374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Ries</author>
</authors>
<title>HMM and neural network based speech act detection.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP-99),</booktitle>
<pages>497--500</pages>
<location>Phoenix, USA.</location>
<contexts>
<context position="7492" citStr="Ries, 1999" startWordPosition="1258" endWordPosition="1259">gset. A range of supervised models have been applied to DA classification, including graphical models (Ji and Bilmes, 2005), kernel methods (Wang et al., 2007), dependency networks (Carvalho and Cohen, 2005), transformation-based learning (Samuel et al., 1998), maxent models (Ang et al., 2005) and HMMs (Ivanovic, 2008). There is some contention about the import of context in DA classification, with the prevailing view being that context aids classification (Carvalho and Cohen, 2005; Ang et al., 2005; Ji and Bilmes, 2005), but also evidence to suggest that strictly local modelling is superior (Ries, 1999; Serafin and Di Eugenio, 2004). In this work, we draw on existing work (esp. Xi et al. (2004)) in proposing a novel DA tag set customised to the analysis of troubleshootingoriented web user forums (Section 3), and compare a range of text classification and structured classification methods for post-level DA classification. Discourse disentanglement is the process of automatically identifying coherent sub-discourses in a single thread (in the context of user forums/mailing lists), chat session (in the context of IRC chat data: Elsner and Charniak (2008)), system interaction (in the context of </context>
<context position="27016" citStr="Ries (1999)" startWordPosition="4458" endWordPosition="4459">istics achieving an F-score of 0.753, slightly higher than the best result achieved for just structural and post context features. It is important to refer back to the results for lexical features (comparable to what would have been achieved with a standard text categorisation approach to the task), and observe that we have achieved far higher F-scores using features customised to user forum data. It is also important to reflect that post context (in terms of the features and the structured classification results of CRF) appears to markedly improve our results, contrasting with the results of Ries (1999) and Serafin and Di Eugenio (2004). 5We omit the results for Full History post context for reasons of space, but there is relatively little deviation from the numbers presented. Features R A RA Struct+T .649 .649 .649 Struct+P .737 .736 .742 Struct+C .741 .741 .742 Struct+U .745 .742 .737 Struct+TP .645 .656 .658 Struct+TC .383 .402 .408 Struct+TU .650 .652 .652 Struct+PC .730 .743 .753 Struct+PU .232 .232 .286 Struct+CU .719 .471 .710 Struct+TPC .498 .469 .579 Struct+TPU .248 .232 .248 Struct+TCU .388 .377 .380 Struct+PCU .231 .231 .261 Struct+TPCU .231 .231 .231 Table 4: DA classification F-</context>
</contexts>
<marker>Ries, 1999</marker>
<rawString>Klaus Ries. 1999. HMM and neural network based speech act detection. In Proceedings of the 1999 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP-99), pages 497–500, Phoenix, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carolyn Penstein Ros´e</author>
<author>Barbara Di Eugenio</author>
<author>Lori S Levin</author>
<author>Carol Van Ess-Dykema</author>
</authors>
<title>Discourse processing of dialogues with multiple threads.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>31--38</pages>
<location>Cambridge, USA.</location>
<marker>Ros´e, Di Eugenio, Levin, Van Ess-Dykema, 1995</marker>
<rawString>Carolyn Penstein Ros´e, Barbara Di Eugenio, Lori S. Levin, and Carol Van Ess-Dykema. 1995. Discourse processing of dialogues with multiple threads. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 31–38, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Samuel</author>
<author>Carbeery Sandra Carberry</author>
<author>K VijayShanker</author>
</authors>
<title>Dialogue act tagging with transformation-based learning.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the ACL and 17th International Conference on Computational Linguistics (COLING/ACL-98),</booktitle>
<pages>1150--1156</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="7142" citStr="Samuel et al., 1998" startWordPosition="1199" endWordPosition="1202">), taskfocused email (Cohen et al., 2004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup data (including QUESTION and AGREEMENT/AMMENDMENT), but did not present any results based on the tagset. A range of supervised models have been applied to DA classification, including graphical models (Ji and Bilmes, 2005), kernel methods (Wang et al., 2007), dependency networks (Carvalho and Cohen, 2005), transformation-based learning (Samuel et al., 1998), maxent models (Ang et al., 2005) and HMMs (Ivanovic, 2008). There is some contention about the import of context in DA classification, with the prevailing view being that context aids classification (Carvalho and Cohen, 2005; Ang et al., 2005; Ji and Bilmes, 2005), but also evidence to suggest that strictly local modelling is superior (Ries, 1999; Serafin and Di Eugenio, 2004). In this work, we draw on existing work (esp. Xi et al. (2004)) in proposing a novel DA tag set customised to the analysis of troubleshootingoriented web user forums (Section 3), and compare a range of text classificat</context>
</contexts>
<marker>Samuel, Carberry, VijayShanker, 1998</marker>
<rawString>Ken Samuel, Carbeery Sandra Carberry, and K. VijayShanker. 1998. Dialogue act tagging with transformation-based learning. In Proceedings of the 36th Annual Meeting of the ACL and 17th International Conference on Computational Linguistics (COLING/ACL-98), pages 1150–1156, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Schuth</author>
<author>Maarten Marx</author>
<author>Maarten de Rijke</author>
</authors>
<title>Extracting the discussion structure in comments on news-articles.</title>
<date>2007</date>
<booktitle>In Proceedings of the 9th Annual ACM International Workshop on Web Information and Data Management,</booktitle>
<pages>97--104</pages>
<location>Lisboa, Portugal.</location>
<marker>Schuth, Marx, de Rijke, 2007</marker>
<rawString>Anne Schuth, Maarten Marx, and Maarten de Rijke. 2007. Extracting the discussion structure in comments on news-articles. In Proceedings of the 9th Annual ACM International Workshop on Web Information and Data Management, pages 97–104, Lisboa, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jangwon Seo</author>
<author>W Bruce Croft</author>
<author>David A Smith</author>
</authors>
<title>Online community search using thread structure.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM</booktitle>
<pages>1907--1910</pages>
<location>Hong Kong, China.</location>
<contexts>
<context position="3140" citStr="Seo et al. (2009)" startWordPosition="489" endWordPosition="492">its post-to-post discourse structure. Specifically, we identify which earlier post(s) a given post responds to (linking) and in what manner (tagging), in an amalgam of dialogue act tagging (Stolcke et al., 2000) and coherence-based discourse analysis (Carlson et al., 2001; Wolf and Gibson, 2005). The reason we do this is gauge the relative role/import of individual posts, to index and weight component terms accordingly, ultimately in an attempt to enhance information access. Evidence to suggest that this structure can enhance information retrieval effectiveness comes from Xi et al. (2004) and Seo et al. (2009) (see Section 2). To illustrate the task, consider the thread from the CNET forum shown in Figure 1, made up of 5 posts (Post 1, ..., Post 5) with 4 distinct participants (A, B, C, D). In the first post, A initiates the thread by requesting assistance in creating a web form. In response, B proposes a Javascript-based solution (i.e. responds to the first post with a proposed solution), and C proposes an independent solution based on .NET (i.e. also responds to the first post with a proposed solution). Next, A responds to C’s post asking for details of how to include this in a web page (i.e. res</context>
<context position="8786" citStr="Seo et al., 2009" startWordPosition="1461" endWordPosition="1464">nition of what constitutes a subdiscourse varies across domains, but for our purposes, entails an attempt to resolve the informaQuestion-Question Post 1 Answer-Answer Post 2 Answer-Answer Post 3 Answer-Clarification Post 4 Answer-Answer 193 tion need of the initiator by a particular approach; if there are competing approaches proposed in a single thread, multiple sub-discourses will necessarily arise. The data structure used to represent the disentangled discourse varies from a simple connected sub-graph (Elsner and Charniak, 2008), to a stack/tree (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), to a full directed acyclic graph (DAG: Ros´e et al. (1995), Wolf and Gibson (2005), Schuth et al. (2007)). Disentanglement has been carried out via analysis of direct citation/user name references (Schuth et al., 2007; Seo et al., 2009), topic modelling (Lin et al., 2009), and clustering over content-based features for pairs of posts, optionally incorporating various constraints on post recency (Elsner and Charniak, 2008; Wang et al., 2008; Seo et al., 2009). In this work, we follow Ros´e et al. (1995) and Wolf and Gibson (2005) in adopting a DAG representation of discourse structure, and dr</context>
<context position="10961" citStr="Seo et al. (2009)" startWordPosition="1819" endWordPosition="1822">nformation retrieval (IR) model for newsgroup search, based on author features, thread structure (based on the tree defined by the reply-to structure), thread “topology” features and content-based features, and used a supervised ranking method to improve over a baseline IR system. Elsas and Carbonell (2009) — building on earlier work on blog search (Elsas et al., 2008) — proposed a probabilistic IR approach which ranks user forum threads relative to selected posts in the overall thread, and again demonstrated the superiority of this method over a model which ignores thread structure. Finally, Seo et al. (2009) automatically derived thread structure from user forum threads, and demonstrated that the IR effectiveness over the “threaded” structure was superior to that using a monolithic document representation. The observations and results of Xi et al. (2004) and Seo et al. (2009) that threading information (or in our case “disentangled” DAG structure) enhances IR effectiveness is a core motivator for this research. 3 Post Label Set Our post label set contains 12 categories, intended to capture the typical interactions that take place in troubleshooting-oriented threads on technical forums. There are </context>
</contexts>
<marker>Seo, Croft, Smith, 2009</marker>
<rawString>Jangwon Seo, W. Bruce Croft, and David A. Smith. 2009. Online community search using thread structure. In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM 2009), pages 1907–1910, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Riccardo Serafin</author>
<author>Barbara Di Eugenio</author>
</authors>
<title>FLSA: Extending latent semantic analysis with features for dialogue act classification.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004),</booktitle>
<pages>692--699</pages>
<location>Barcelona,</location>
<marker>Serafin, Di Eugenio, 2004</marker>
<rawString>Riccardo Serafin and Barbara Di Eugenio. 2004. FLSA: Extending latent semantic analysis with features for dialogue act classification. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004), pages 692– 699, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Sha</author>
<author>Fernando Pereira</author>
</authors>
<title>Shallow parsing with conditional random fields.</title>
<date>2003</date>
<booktitle>In Proceedings of the 3rd International Conference on Human Language Technology Research and 4th Annual Meeting of the NAACL (HLT-NAACL</booktitle>
<pages>213--220</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="19363" citStr="Sha and Pereira, 2003" startWordPosition="3218" endWordPosition="3221">which possibly link to a common post) and 22 posts link to two different links. The majority post label in the dataset is A-A (40.30%). 1http://forums.cnet.com/?tag= TOCleftColumn.0 We built machine learners using a conventional Maximum Entropy (ME) learner,2 as well as two structural learners, namely: (1) SVM-HMMs (Joachims et al., 2009), as implemented in SVMstruct3, with a linear kernel; and (2) conditional random fields (CRFs) using CRF++.4 SVMHMMs and CRFs have been successfully applied to a range of sequential tagging tasks such as syllabification (Bartlett et al., 2009), chunk parsing (Sha and Pereira, 2003) and word segmentation (Zhao et al., 2006). Both are discriminative models which capture structural dependencies, which is highly desirable in terms of modelling sequential preferences between post labels (e.g. A-CONF typically following a A-A). SVMHMM has the additional advantage of scaling to large numbers of features (namely the lexical features). As such, we only experiment with lexical features for SVM-HMM and ME. All of our evaluation is based on stratified 10- fold cross-validation, stratifying at the thread level to ensure that if a given post is contained in the test data for a given </context>
</contexts>
<marker>Sha, Pereira, 2003</marker>
<rawString>Fei Sha and Fernando Pereira. 2003. Shallow parsing with conditional random fields. In Proceedings of the 3rd International Conference on Human Language Technology Research and 4th Annual Meeting of the NAACL (HLT-NAACL 2003), pages 213–220, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lokesh Shrestha</author>
<author>Kathleen McKeown</author>
</authors>
<title>Detection of question-answer pairs in email conversations.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004),</booktitle>
<pages>889--895</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="9645" citStr="Shrestha and McKeown, 2004" startWordPosition="1602" endWordPosition="1605"> 2009), topic modelling (Lin et al., 2009), and clustering over content-based features for pairs of posts, optionally incorporating various constraints on post recency (Elsner and Charniak, 2008; Wang et al., 2008; Seo et al., 2009). In this work, we follow Ros´e et al. (1995) and Wolf and Gibson (2005) in adopting a DAG representation of discourse structure, and draw on the wide set of features used in discourse entanglement to model coherence. Community question answering (cQA) is the task of identifying question–answer pairs in a given thread, e.g. for the purposes of thread summarisation (Shrestha and McKeown, 2004) or automated compilation of resources akin to Yahoo! Answers. cQA has been applied to both mailing list and user forum threads, conventionally based on question classification, followed by ranking of candidate answers relative to each question (Shrestha and McKeown, 2004; Ding et al., 2008; Cong et al., 2008; Cao et al., 2009). The task is somewhat peripheral to our work, but relevant in that it involves the implicit tagging of certain posts as containing questions/answers, as well as linking the posts together. Once again, we draw on the features used in cQA in this research. There has been </context>
</contexts>
<marker>Shrestha, McKeown, 2004</marker>
<rawString>Lokesh Shrestha and Kathleen McKeown. 2004. Detection of question-answer pairs in email conversations. In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004), pages 889–895, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elinzabeth Shriberg</author>
<author>Raj Dhillon</author>
<author>Sonali Bhagat</author>
<author>Jeremy Ang</author>
<author>Hannah Carvey</author>
</authors>
<title>The ICSI meeting recorder dialog act (MRDA) corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the 5th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>97--100</pages>
<location>Cambridge, USA.</location>
<contexts>
<context position="6523" citStr="Shriberg et al., 2004" startWordPosition="1100" endWordPosition="1103">ity question answering; and (4) newsgroup/user forum search. Dialogue act (DA) tagging is a means of capturing the function of a given utterance relative to an encompassing discourse, and has been proposed variously as a means of enhancing dialogue summarisation (Murray et al., 2006), and tracking commitments and promises in email (Cohen et al., 2004; Lampert et al., 2008), as well as being shown to improve speech recognition accuracy (Stolcke et al., 2000). A wide range of DA tag sets have been proposed, usually customised to a particular medium such as speech dialogue (Stolcke et al., 2000; Shriberg et al., 2004), taskfocused email (Cohen et al., 2004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup data (including QUESTION and AGREEMENT/AMMENDMENT), but did not present any results based on the tagset. A range of supervised models have been applied to DA classification, including graphical models (Ji and Bilmes, 2005), kernel methods (Wang et al., 2007), dependency networks (Carvalho and Cohen, 2005), transformation-based learning (S</context>
</contexts>
<marker>Shriberg, Dhillon, Bhagat, Ang, Carvey, 2004</marker>
<rawString>Elinzabeth Shriberg, Raj Dhillon, Sonali Bhagat, Jeremy Ang, and Hannah Carvey. 2004. The ICSI meeting recorder dialog act (MRDA) corpus. In Proceedings of the 5th SIGdial Workshop on Discourse and Dialogue, pages 97–100, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Klaus Ries</author>
<author>Noah Coccaro</author>
<author>Elizabeth Shriberg</author>
<author>Rebecca Bates</author>
<author>Daniel Jurafsky</author>
<author>Pail Taylor</author>
<author>Rachel Martin</author>
<author>Carol Van Ess-Dykema</author>
<author>Marie Meteer</author>
</authors>
<title>Dialogue Act Modeling for Automatic Tagging and Recognition of Conversational Speech.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>3</issue>
<marker>Stolcke, Ries, Coccaro, Shriberg, Bates, Jurafsky, Taylor, Martin, Van Ess-Dykema, Meteer, 2000</marker>
<rawString>Andreas Stolcke, Klaus Ries, Noah Coccaro, Elizabeth Shriberg, Rebecca Bates, Daniel Jurafsky, Pail Taylor, Rachel Martin, Carol Van Ess-Dykema, and Marie Meteer. 2000. Dialogue Act Modeling for Automatic Tagging and Recognition of Conversational Speech. Computational Linguistics, 26(3):339–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Chia Wang</author>
<author>Mahesh Joshi</author>
<author>Carolyn Ros´e</author>
</authors>
<title>A feature based approach to leveraging context for classifying newsgroup style discussion segments.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions (ACL</booktitle>
<pages>73--76</pages>
<location>Prague, Czech Republic.</location>
<marker>Wang, Joshi, Ros´e, 2007</marker>
<rawString>Yi-Chia Wang, Mahesh Joshi, and Carolyn Ros´e. 2007. A feature based approach to leveraging context for classifying newsgroup style discussion segments. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions (ACL 2007), pages 73–76, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Chia Wang</author>
<author>Mahesh Joshi</author>
<author>William W Cohen</author>
<author>Carolyn Ros´e</author>
</authors>
<title>Recovering implicit thread structure in newsgroup style conversations.</title>
<date>2008</date>
<booktitle>In Proceedings of the Second International Conference on Weblogs and Social Media (ICWSM</booktitle>
<pages>152--160</pages>
<location>Seattle, USA.</location>
<marker>Wang, Joshi, Cohen, Ros´e, 2008</marker>
<rawString>Yi-Chia Wang, Mahesh Joshi, William W. Cohen, and Carolyn Ros´e. 2008. Recovering implicit thread structure in newsgroup style conversations. In Proceedings of the Second International Conference on Weblogs and Social Media (ICWSM 2008), pages 152–160, Seattle, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Weimer</author>
<author>Iryna Gurevych</author>
<author>Max M¨uhlh¨auser</author>
</authors>
<title>Automatically assessing the post quality in online discussions on software.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL: Interactive Poster and Demonstration Sessions,</booktitle>
<pages>125--128</pages>
<location>Prague, Czech Republic.</location>
<marker>Weimer, Gurevych, M¨uhlh¨auser, 2007</marker>
<rawString>Markus Weimer, Iryna Gurevych, and Max M¨uhlh¨auser. 2007. Automatically assessing the post quality in online discussions on software. In Proceedings of the 45th Annual Meeting of the ACL: Interactive Poster and Demonstration Sessions, pages 125–128, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Wolf</author>
<author>Edward Gibson</author>
</authors>
<title>Representing discourse coherence: A corpus-based study.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>2</issue>
<contexts>
<context position="2819" citStr="Wolf and Gibson, 2005" startWordPosition="436" endWordPosition="439">pport sharing, in the form of text mining over troubleshootingoriented web user forum data (Baldwin et al., to appear). One facet of our proposed strategy for enhancing information access to troubleshooting-oriented web user forum data is to preprocess threads to uncover the “content structure” of the thread, in the form of its post-to-post discourse structure. Specifically, we identify which earlier post(s) a given post responds to (linking) and in what manner (tagging), in an amalgam of dialogue act tagging (Stolcke et al., 2000) and coherence-based discourse analysis (Carlson et al., 2001; Wolf and Gibson, 2005). The reason we do this is gauge the relative role/import of individual posts, to index and weight component terms accordingly, ultimately in an attempt to enhance information access. Evidence to suggest that this structure can enhance information retrieval effectiveness comes from Xi et al. (2004) and Seo et al. (2009) (see Section 2). To illustrate the task, consider the thread from the CNET forum shown in Figure 1, made up of 5 posts (Post 1, ..., Post 5) with 4 distinct participants (A, B, C, D). In the first post, A initiates the thread by requesting assistance in creating a web form. In </context>
<context position="8153" citStr="Wolf and Gibson, 2005" startWordPosition="1364" endWordPosition="1367">s work, we draw on existing work (esp. Xi et al. (2004)) in proposing a novel DA tag set customised to the analysis of troubleshootingoriented web user forums (Section 3), and compare a range of text classification and structured classification methods for post-level DA classification. Discourse disentanglement is the process of automatically identifying coherent sub-discourses in a single thread (in the context of user forums/mailing lists), chat session (in the context of IRC chat data: Elsner and Charniak (2008)), system interaction (in the context of HCI: Lemon et al. (2002)) or document (Wolf and Gibson, 2005). The exact definition of what constitutes a subdiscourse varies across domains, but for our purposes, entails an attempt to resolve the informaQuestion-Question Post 1 Answer-Answer Post 2 Answer-Answer Post 3 Answer-Clarification Post 4 Answer-Answer 193 tion need of the initiator by a particular approach; if there are competing approaches proposed in a single thread, multiple sub-discourses will necessarily arise. The data structure used to represent the disentangled discourse varies from a simple connected sub-graph (Elsner and Charniak, 2008), to a stack/tree (Grosz and Sidner, 1986; Lemo</context>
</contexts>
<marker>Wolf, Gibson, 2005</marker>
<rawString>Florian Wolf and Edward Gibson. 2005. Representing discourse coherence: A corpus-based study. Computational Linguistics, 31(2):249–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wensi Xi</author>
<author>Jesper Lind</author>
<author>Eric Brill</author>
</authors>
<title>Learning effective ranking functions for newsgroup search.</title>
<date>2004</date>
<booktitle>In Proceedings of 27th International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2004),</booktitle>
<pages>394--401</pages>
<publisher>Sheffield, UK.</publisher>
<contexts>
<context position="3118" citStr="Xi et al. (2004)" startWordPosition="484" endWordPosition="487">read, in the form of its post-to-post discourse structure. Specifically, we identify which earlier post(s) a given post responds to (linking) and in what manner (tagging), in an amalgam of dialogue act tagging (Stolcke et al., 2000) and coherence-based discourse analysis (Carlson et al., 2001; Wolf and Gibson, 2005). The reason we do this is gauge the relative role/import of individual posts, to index and weight component terms accordingly, ultimately in an attempt to enhance information access. Evidence to suggest that this structure can enhance information retrieval effectiveness comes from Xi et al. (2004) and Seo et al. (2009) (see Section 2). To illustrate the task, consider the thread from the CNET forum shown in Figure 1, made up of 5 posts (Post 1, ..., Post 5) with 4 distinct participants (A, B, C, D). In the first post, A initiates the thread by requesting assistance in creating a web form. In response, B proposes a Javascript-based solution (i.e. responds to the first post with a proposed solution), and C proposes an independent solution based on .NET (i.e. also responds to the first post with a proposed solution). Next, A responds to C’s post asking for details of how to include this i</context>
<context position="6731" citStr="Xi et al. (2004)" startWordPosition="1139" endWordPosition="1142">y as a means of enhancing dialogue summarisation (Murray et al., 2006), and tracking commitments and promises in email (Cohen et al., 2004; Lampert et al., 2008), as well as being shown to improve speech recognition accuracy (Stolcke et al., 2000). A wide range of DA tag sets have been proposed, usually customised to a particular medium such as speech dialogue (Stolcke et al., 2000; Shriberg et al., 2004), taskfocused email (Cohen et al., 2004; Wang et al., 2007; Lampert et al., 2008) or instant messaging (Ivanovic, 2008). The most immediately relevant DA-based work we are aware of is that of Xi et al. (2004), who proposed a 5-way classification for newsgroup data (including QUESTION and AGREEMENT/AMMENDMENT), but did not present any results based on the tagset. A range of supervised models have been applied to DA classification, including graphical models (Ji and Bilmes, 2005), kernel methods (Wang et al., 2007), dependency networks (Carvalho and Cohen, 2005), transformation-based learning (Samuel et al., 1998), maxent models (Ang et al., 2005) and HMMs (Ivanovic, 2008). There is some contention about the import of context in DA classification, with the prevailing view being that context aids cla</context>
<context position="10320" citStr="Xi et al. (2004)" startWordPosition="1717" endWordPosition="1720">rs. cQA has been applied to both mailing list and user forum threads, conventionally based on question classification, followed by ranking of candidate answers relative to each question (Shrestha and McKeown, 2004; Ding et al., 2008; Cong et al., 2008; Cao et al., 2009). The task is somewhat peripheral to our work, but relevant in that it involves the implicit tagging of certain posts as containing questions/answers, as well as linking the posts together. Once again, we draw on the features used in cQA in this research. There has been a spike of recent interest in newsgroup/user forum search. Xi et al. (2004) proposed a structured information retrieval (IR) model for newsgroup search, based on author features, thread structure (based on the tree defined by the reply-to structure), thread “topology” features and content-based features, and used a supervised ranking method to improve over a baseline IR system. Elsas and Carbonell (2009) — building on earlier work on blog search (Elsas et al., 2008) — proposed a probabilistic IR approach which ranks user forum threads relative to selected posts in the overall thread, and again demonstrated the superiority of this method over a model which ignores thr</context>
</contexts>
<marker>Xi, Lind, Brill, 2004</marker>
<rawString>Wensi Xi, Jesper Lind, and Eric Brill. 2004. Learning effective ranking functions for newsgroup search. In Proceedings of 27th International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2004), pages 394–401. Sheffield, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yeh</author>
</authors>
<title>More accurate tests for the statistical significance of result differences.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING</booktitle>
<pages>947--953</pages>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="20272" citStr="Yeh (2000)" startWordPosition="3373" endWordPosition="3374">ge numbers of features (namely the lexical features). As such, we only experiment with lexical features for SVM-HMM and ME. All of our evaluation is based on stratified 10- fold cross-validation, stratifying at the thread level to ensure that if a given post is contained in the test data for a given iteration, all other posts in that same thread are also in the test data (or more pertinently, not in the training data). We evaluate using micro-averaged precision, recall and Fscore (Q = 1). We test the statistical significance of all above-baseline results using randomised estimation (p &lt; 0.05; Yeh (2000)), and present all such results in bold in our results tables. In our experiments, we first look at the post classification task in isolation (i.e. we predict which labels to associate with each post, underspecifying which posts those labels relate to). We then move on to look at the link classification task, again in isolation (i.e. we predict which previous posts each post links to, underspecifying the nature of the link). Finally, we perform preliminary investigation of the joint task of DA and link classification, by incorporating DA class features into the link classification task. 6 DA C</context>
</contexts>
<marker>Yeh, 2000</marker>
<rawString>Alexander Yeh. 2000. More accurate tests for the statistical significance of result differences. In Proceedings of the 18th International Conference on Computational Linguistics (COLING 2000), pages 947–953, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Chang-Ning Huang</author>
<author>Mu Li</author>
</authors>
<title>An improved Chinese word segmentation system with conditional random field.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>162--165</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="19405" citStr="Zhao et al., 2006" startWordPosition="3226" endWordPosition="3229">osts link to two different links. The majority post label in the dataset is A-A (40.30%). 1http://forums.cnet.com/?tag= TOCleftColumn.0 We built machine learners using a conventional Maximum Entropy (ME) learner,2 as well as two structural learners, namely: (1) SVM-HMMs (Joachims et al., 2009), as implemented in SVMstruct3, with a linear kernel; and (2) conditional random fields (CRFs) using CRF++.4 SVMHMMs and CRFs have been successfully applied to a range of sequential tagging tasks such as syllabification (Bartlett et al., 2009), chunk parsing (Sha and Pereira, 2003) and word segmentation (Zhao et al., 2006). Both are discriminative models which capture structural dependencies, which is highly desirable in terms of modelling sequential preferences between post labels (e.g. A-CONF typically following a A-A). SVMHMM has the additional advantage of scaling to large numbers of features (namely the lexical features). As such, we only experiment with lexical features for SVM-HMM and ME. All of our evaluation is based on stratified 10- fold cross-validation, stratifying at the thread level to ensure that if a given post is contained in the test data for a given iteration, all other posts in that same th</context>
</contexts>
<marker>Zhao, Huang, Li, 2006</marker>
<rawString>Hai Zhao, Chang-Ning Huang, and Mu Li. 2006. An improved Chinese word segmentation system with conditional random field. In Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 162–165. Sydney, Australia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>