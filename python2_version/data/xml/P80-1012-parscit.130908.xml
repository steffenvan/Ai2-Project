<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008538">
<table confidence="0.5091165">
PHRASE STRUCTURE TREES BEAR MORE FRUIT THAN YOU WOULD HAVE THOUGHT*
Aravind K. Joshi and
Department of Computer and
Information Science
The Mbore School/D2
University of Pennsylvania
Philadelphia, PA 19104
EXTENDED ABSTRACT**
</table>
<bodyText confidence="0.998989071428571">
There is renewed interest in examining the descriptive
as well as generative power of phrase structure gram-
mars. The primary motivation has come fiuw the recent
investigations in alternatives to transformational
grammars [e.g., 1, 2, 3, 4]. We will present several
results and ideas related to phrase structure trees
which have significant relevance to computational lin-
guistics.
We want to accomplish several objectives in this paper.
1. We will give a brief survey of some recent results
and approaches by various investigators including, of
course, our own work, indicating their interrelation-
ships.
Here we will review the work related to the notion of
node admissibility starting with Chomsky, followed by
the work by McCawley, Peters and Ritchie, Joshi and
Levy, and more recent work of Gazdar.
We will also discuss other amendments to context-free
grammars which increase the descriptive power but not
the generative power. In particular, we will discuss
the notion of categories with holes as recently intro-
duced by Gazdar [3]. There is an interesting history
behind this notion. cAger&apos;s parser explicitly exploits
such a convention and, in fact, uses it to do some co-
ordinate structure computation. We suspect that some
other parsers have this feature also, perhaps implicit-
ly. We will discuss this matter, which obviously is
of great interest to computational linguists.
</bodyText>
<listItem confidence="0.965016384615385">
2. Our work on local constraints on structural descrip-
tions, [5, 6], which is computationally relevant both
to linguistics and programming language theory, has
attracted some attention recently; however, the demon-
stration of these results has remained somewhat inac-
cessible to many due to the technicalities of the tree
automata theory. Recently, we have found a way of
providing an intuitive explanation of these results in
terms of interacting, finite state machines (of the
usual kind). Besides providing an intuitive and a more
transparent explanation of our results, this approach
is computationally more interesting and allows us to
formulate an interesting question: How large a variable
Set (i.e., the set of nonterminals) is required for a
phrase structure grammar or how much information does
a nonterminal encode? We will present this new
approach.
3. We will present some new results which extend the
&amp;quot;power&amp;quot; of local constraints without affecting the char-
acter of earlier results. In particular, we will show
that local constraints can include, besides the proper
analysis (PA) predicates and domination (et) predicates,
* This work was partially supported by NSF grant MCS79-
08401.
** Full paper will be available at the time of the
meeting.
</listItem>
<bodyText confidence="0.65414775">
Leon S. Levy
Bell Telephone Laboratories
Whippany, NJ 07981
more complex predicates of the following form.
</bodyText>
<listItem confidence="0.646353">
(1) (PRED Ni N2 Nn)
</listItem>
<bodyText confidence="0.999311166666667">
where N1, N2, ... Nri are nonterminals mentioned in the
PA and/or jr constraint of the rule in which (1) appears
and FRED is a predicate which, roughly speaking, checks
for certain domination or left-of (or right-of) rela-
tionships among its arguments. Te o examples of inter-
est are as follows.
</bodyText>
<listItem confidence="0.9401108">
(2) (CCOMMAND A B C)
CCOMMAND holds if B immediately dominates A and B domi-
nates C, not necessarily immediately. Usually the B
node is an S node.
(3) (LEFTMOSTSISTER A B)
</listItem>
<bodyText confidence="0.996367777777778">
LEFTMOSTSISTER holds if A is the leftmost sister of B.
We will show that intivduction of predicates of the type
(1) do not change the character of our result on local
constraints. This extension of our earlier work has
relevance to the formulation of some long distance rules
without transformations (as well as without the use of
the categories with holes as suggested by Gazdar).
We will discuss some of the processing as well as lin-
guistic relevance of these results.
</bodyText>
<listItem confidence="0.9649828">
4. We will try to compare (at least along two dimen-
sions) the local constraint approach to that of (7,47dar&apos;s
(specifically his use of categories with holes) and to
that of Peters&apos; use of linked nodes (as presented
orally at Stanford recently).
</listItem>
<bodyText confidence="0.9014495">
The dimensions for comparison would be (a) economy of
representation, (b) proliferation of categories, by and
large semantically vacuous, and (c) computational rele-
vance of (a) and (b) above.
</bodyText>
<listItem confidence="0.9593161">
5. Compositional semantics [8] is usually context-free,
i.e., if nodes B and C are immediate descendants of
node A, then the semantics of A is a composition (de-
fined appropriately) of the semantics of B and semantics
of C. Semantics of A depends only on nodes B and C and
not on any other part of the structural description in
which A may appear. Our method of local constraints
(and to some extent Peters&apos; use of linked nodes) opens
the possibility of defining the semantics of A not only
in terms of the semantics of B and C, but also in terms
of some parts of the structural description in which A
appears. In this sense, the semantics will be context-
sensitive. We have achieved some success with this
approach to the semantics of programming languages. We
will discuss some of our preliminary ideas for extending
this approach to natural language, in partionlar, in
specifying scopes for variable binding.
6. While developing our theory of local constrains and
some other related work, we have discovered that it is
possible to characterize structural descriptions (for
</listItem>
<bodyText confidence="0.8894138">
phrase structure grammars) entirely in terms of trees
without any labels, i.e., trees which capture the group-
ing structure without the syntactic categories (which is
the same as the constituent structure without the node
labels [7]. This is a surprising result. This result
</bodyText>
<page confidence="0.998693">
41
</page>
<bodyText confidence="0.970677722222222">
provides a way of determining how such &amp;quot;structure&amp;quot;
nonterminals (syntactic categories) encode and there-
fore clearly, it has computational significance.
Moreover, to the extent that the claim that natural
languages are context-free is valid, this result has
significant relevance to learnability theories,
because our result suggests that it might be possible
to &amp;quot;infer&amp;quot; a phrase structure grammar from just the
grouping structure of the input (i.e., just the
phrase boundaries). Further, the set of structural
descriptions without labels are directly related to
the structura descriptions of a context-free grammar;
hence, we may be able to specify &amp;quot;natural&amp;quot; syntactic
categories.
In summary, we will present a selection of mathematical
results which have significant relevance to many aspects
of computational linguistics.
SELE= =UN=
</bodyText>
<reference confidence="0.993863">
[1] Bresnan, J.W., &amp;quot;Evidence for an unbounded theory of
transformations,&amp;quot; Linguistic Analysis, Vol. 2,
1976.
ClazdAr, G.J. N. &amp;quot;Phrase structure grammar,&amp;quot; to
appear in The Nature of Syntactic Representation,
(eds. P. Jacobson and G.K. Pullum), 1979.
(zazdAr, G.J.M., &amp;quot;English as a context-free language,&amp;quot;
unpublished ms., 1978.
PA,Aar, G.J.M., &amp;quot;Unbounded dependencies and co-
ordinate structure,&amp;quot; unpublished ms. 1979.
Joshi, A.K. and Levy, L.S., &amp;quot;Local tnwtsfarma-
tions,&amp;quot; SIAM Journal of Computing, 1977.
Joshi, A.K., Levy, L.S., and Yueh, K., &amp;quot;Local
constraints in the syntax and semantics of pro-
gramming languages,&amp;quot; to appear in Journal of
Thevvetical Computer Science, 1980.
Levy, L.S. and Joshi, A.K., &amp;quot;Skeletal structural
descriptions,&amp;quot; Information and Control, Nov. 1978.
Knuth, D.E., &amp;quot;Semantics of context-free languages,&amp;quot;
Mathematical Systems Theory, 1968.
Sager, N., &amp;quot;Syntactic analysis of natural lan-
guages,&amp;quot; in Advances in Computers (eds. M. Alt and
M. Rubinoff), vol. 8, Academic Press, New York,
1967.
</reference>
<page confidence="0.999295">
42
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.188510">
<title confidence="0.971917">PHRASE STRUCTURE TREES BEAR MORE FRUIT THAN YOU WOULD HAVE THOUGHT*</title>
<affiliation confidence="0.98424775">Department of Computer and Information Science The Mbore School/D2 University of Pennsylvania</affiliation>
<address confidence="0.998984">Philadelphia, PA 19104</address>
<abstract confidence="0.995999870370371">There is renewed interest in examining the descriptive as well as generative power of phrase structure grammars. The primary motivation has come fiuw the recent investigations in alternatives to transformational grammars [e.g., 1, 2, 3, 4]. We will present several results and ideas related to phrase structure trees which have significant relevance to computational linguistics. We want to accomplish several objectives in this paper. 1. We will give a brief survey of some recent results and approaches by various investigators including, of course, our own work, indicating their interrelationships. Here we will review the work related to the notion of node admissibility starting with Chomsky, followed by the work by McCawley, Peters and Ritchie, Joshi and Levy, and more recent work of Gazdar. We will also discuss other amendments to context-free grammars which increase the descriptive power but not the generative power. In particular, we will discuss the notion of categories with holes as recently introduced by Gazdar [3]. There is an interesting history behind this notion. cAger&apos;s parser explicitly exploits such a convention and, in fact, uses it to do some coordinate structure computation. We suspect that some other parsers have this feature also, perhaps implicitly. We will discuss this matter, which obviously is of great interest to computational linguists. 2. Our work on local constraints on structural descriptions, [5, 6], which is computationally relevant both to linguistics and programming language theory, has attracted some attention recently; however, the demonstration of these results has remained somewhat inaccessible to many due to the technicalities of the tree automata theory. Recently, we have found a way of providing an intuitive explanation of these results in of interacting,finite state machines (of the usual kind). Besides providing an intuitive and a more transparent explanation of our results, this approach is computationally more interesting and allows us to formulate an interesting question: How large a variable Set (i.e., the set of nonterminals) is required for a phrase structure grammar or how much information does a nonterminal encode? We will present this new approach. 3. We will present some new results which extend the &amp;quot;power&amp;quot; of local constraints without affecting the charof earlier results. In particular, we will that local constraints can include, besides the proper analysis (PA) predicates and domination (et) predicates, * This work was partially supported by NSF grant MCS79- 08401. ** Full paper will be available at the time of the meeting.</abstract>
<author confidence="0.99056">Leon S Levy</author>
<affiliation confidence="0.999572">Bell Telephone Laboratories</affiliation>
<address confidence="0.954619">Whippany, NJ 07981</address>
<abstract confidence="0.997828554054054">more complex predicates of the following form. (PRED Ni Nn) N1, N2, ... are nonterminals mentioned in the PA and/or jr constraint of the rule in which (1) appears and FRED is a predicate which, roughly speaking, checks for certain domination or left-of (or right-of) relationships among its arguments. Te o examples of interest are as follows. (2) (CCOMMAND A B C) CCOMMAND holds if B immediately dominates A and B dominates C, not necessarily immediately. Usually the B node is an S node. (3) (LEFTMOSTSISTER A B) LEFTMOSTSISTER holds if A is the leftmost sister of B. We will show that intivduction of predicates of the type (1) do not change the character of our result on local constraints. This extension of our earlier work has relevance to the formulation of some long distance rules without transformations (as well as without the use of the categories with holes as suggested by Gazdar). We will discuss some of the processing as well as linguistic relevance of these results. 4. We will try to compare (at least along two dimenthe local constraint approach to that of (specifically his use of categories with holes) and to that of Peters&apos; use of linked nodes (as presented orally at Stanford recently). The dimensions for comparison would be (a) economy of representation, (b) proliferation of categories, by and large semantically vacuous, and (c) computational relevance of (a) and (b) above. 5. Compositional semantics [8] is usually context-free, i.e., if nodes B and C are immediate descendants of node A, then the semantics of A is a composition (defined appropriately) of the semantics of B and semantics of C. Semantics of A depends only on nodes B and C and not on any other part of the structural description in which A may appear. Our method of local constraints (and to some extent Peters&apos; use of linked nodes) opens the possibility of defining the semantics of A not only in terms of the semantics of B and C, but also in terms of some parts of the structural description in which A appears. In this sense, the semantics will be contextsensitive. We have achieved some success with this approach to the semantics of programming languages. We will discuss some of our preliminary ideas for extending this approach to natural language, in partionlar, in specifying scopes for variable binding. 6. While developing our theory of local constrains and some other related work, we have discovered that it is possible to characterize structural descriptions (for phrase structure grammars) entirely in terms of trees without any labels, i.e., trees which capture the grouping structure without the syntactic categories (which is the same as the constituent structure without the node labels [7]. This is a surprising result. This result 41 provides a way of determining how such &amp;quot;structure&amp;quot; (syntactic categories) thereclearly, it significance. Moreover, to the extent that the claim that natural are context-free is valid, this result significant relevance to learnability theories, because our result suggests that it might be possible to &amp;quot;infer&amp;quot; a phrase structure grammar from just the grouping structure of the input (i.e., just the phrase boundaries). Further, the set of structural descriptions without labels are directly related to the structura descriptions of a context-free grammar; hence, we may be able to specify &amp;quot;natural&amp;quot; syntactic categories. In summary, we will present a selection of mathematical results which have significant relevance to many aspects of computational linguistics.</abstract>
<note confidence="0.931162923076923">SELE= =UN= [1] Bresnan, J.W., &amp;quot;Evidence for an unbounded theory of Analysis,Vol. 2, 1976. ClazdAr, G.J. N. &amp;quot;Phrase structure grammar,&amp;quot; to in Nature of Syntactic Representation, (eds. P. Jacobson and G.K. Pullum), 1979. G.J.M., &amp;quot;English context-free language,&amp;quot; unpublished ms., 1978. &amp;quot;Unbounded dependencies and coordinate structure,&amp;quot; unpublished ms. 1979. Joshi, A.K. and Levy, L.S., &amp;quot;Local tnwtsfarma- Journal of Computing,1977. Joshi, A.K., Levy, L.S., and Yueh, K., &amp;quot;Local constraints in the syntax and semantics of prolanguages,&amp;quot; to appear in of Computer Science,1980. Levy, L.S. and Joshi, A.K., &amp;quot;Skeletal structural and Control,Nov. 1978. Knuth, D.E., &amp;quot;Semantics of context-free languages,&amp;quot; Systems Theory,1968. Sager, N., &amp;quot;Syntactic analysis of natural lanin in Computers(eds. M. Alt and M. Rubinoff), vol. 8, Academic Press, New York, 1967. 42</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J W Bresnan</author>
</authors>
<title>Evidence for an unbounded theory of transformations,&amp;quot;</title>
<date>1976</date>
<journal>Linguistic Analysis,</journal>
<volume>2</volume>
<marker>Bresnan, 1976</marker>
<rawString>[1] Bresnan, J.W., &amp;quot;Evidence for an unbounded theory of transformations,&amp;quot; Linguistic Analysis, Vol. 2, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J N ClazdAr</author>
</authors>
<title>Phrase structure grammar,&amp;quot; to appear in</title>
<date>1979</date>
<booktitle>The Nature of Syntactic Representation,</booktitle>
<editor>(eds. P. Jacobson and G.K. Pullum),</editor>
<marker>ClazdAr, 1979</marker>
<rawString>ClazdAr, G.J. N. &amp;quot;Phrase structure grammar,&amp;quot; to appear in The Nature of Syntactic Representation, (eds. P. Jacobson and G.K. Pullum), 1979.</rawString>
</citation>
<citation valid="true">
<title>English as a context-free language,&amp;quot; unpublished ms.,</title>
<date>1978</date>
<marker>1978</marker>
<rawString>(zazdAr, G.J.M., &amp;quot;English as a context-free language,&amp;quot; unpublished ms., 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aar PA</author>
<author>G J M</author>
</authors>
<title>Unbounded dependencies and coordinate structure,&amp;quot; unpublished ms.</title>
<date>1979</date>
<marker>PA, M, 1979</marker>
<rawString>PA,Aar, G.J.M., &amp;quot;Unbounded dependencies and coordinate structure,&amp;quot; unpublished ms. 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>L S Levy</author>
</authors>
<title>Local tnwtsfarmations,&amp;quot;</title>
<date>1977</date>
<journal>SIAM Journal of Computing,</journal>
<marker>Joshi, Levy, 1977</marker>
<rawString>Joshi, A.K. and Levy, L.S., &amp;quot;Local tnwtsfarmations,&amp;quot; SIAM Journal of Computing, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>L S Levy</author>
<author>K Yueh</author>
</authors>
<title>Local constraints in the syntax and semantics of programming languages,&amp;quot; to appear in</title>
<date>1980</date>
<journal>Journal of Thevvetical Computer Science,</journal>
<marker>Joshi, Levy, Yueh, 1980</marker>
<rawString>Joshi, A.K., Levy, L.S., and Yueh, K., &amp;quot;Local constraints in the syntax and semantics of programming languages,&amp;quot; to appear in Journal of Thevvetical Computer Science, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Levy</author>
<author>A K Joshi</author>
</authors>
<title>Skeletal structural descriptions,&amp;quot;</title>
<date>1978</date>
<journal>Information and Control,</journal>
<marker>Levy, Joshi, 1978</marker>
<rawString>Levy, L.S. and Joshi, A.K., &amp;quot;Skeletal structural descriptions,&amp;quot; Information and Control, Nov. 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Knuth</author>
</authors>
<title>Semantics of context-free languages,&amp;quot;</title>
<date>1968</date>
<booktitle>Mathematical Systems Theory,</booktitle>
<marker>Knuth, 1968</marker>
<rawString>Knuth, D.E., &amp;quot;Semantics of context-free languages,&amp;quot; Mathematical Systems Theory, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Sager</author>
</authors>
<title>Syntactic analysis of natural languages,&amp;quot;</title>
<date>1967</date>
<booktitle>in Advances in Computers</booktitle>
<volume>8</volume>
<editor>(eds. M. Alt and M. Rubinoff),</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>Sager, 1967</marker>
<rawString>Sager, N., &amp;quot;Syntactic analysis of natural languages,&amp;quot; in Advances in Computers (eds. M. Alt and M. Rubinoff), vol. 8, Academic Press, New York, 1967.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>