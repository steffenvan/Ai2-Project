<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008147">
<title confidence="0.956984">
Building a Large Syntactically-Annotated Corpus of Vietnamese
</title>
<author confidence="0.99267">
Phuong-Thai Nguyen
</author>
<affiliation confidence="0.995538">
College of Technology, VNU
</affiliation>
<email confidence="0.989223">
thainp@vnu.edu.vn
</email>
<author confidence="0.912837">
Xuan-Luong Vu
</author>
<affiliation confidence="0.677684">
Vietnam Lexicography Cen-
tre
</affiliation>
<email confidence="0.994795">
vuluong@vietlex.vn
</email>
<author confidence="0.993066">
Thi-Minh-Huyen Nguyen
</author>
<affiliation confidence="0.997147">
University of Natural
</affiliation>
<address confidence="0.928899">
Sciences, VNU
</address>
<email confidence="0.998914">
huyenntm@vnu.edu.vn
</email>
<author confidence="0.999022">
Van-Hiep Nguyen Hong-Phuong Le
</author>
<affiliation confidence="0.99702">
University of Social Sciences and LORIA/INRIA Lorraine
</affiliation>
<email confidence="0.9711655">
Humanities, VNU lehong@loria.fr
hiepnv@vnu.edu.vn
</email>
<sectionHeader confidence="0.995539" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999958176470588">
Treebank is an important resource for
both research and application of natural
language processing. For Vietnamese, we
still lack such kind of corpora. This paper
presents up-to-date results of a project for
Vietnamese treebank construction. Since
Vietnamese is an isolating language and
has no word delimiter, there are many
ambiguities in sentence analysis. We sys-
tematically applied a lot of linguistic
techniques to handle such ambiguities.
Annotators are supported by automatic-
labeling tools and a tree-editor tool. Raw
texts are extracted from Tuoi Tre
(Youth), an online Vietnamese daily
newspaper. The current annotation
agreement is around 90 percent.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999806055555556">
Treebanks are used for training syntactic parsers,
part-of-speech taggers, and word segmenters.
These systems then can be used for applications
such as information extraction, machine transla-
tion, question answering, and text summariza-
tion. Treebanks are also useful for linguistic stu-
dies, for example the extraction of syntactic pat-
terns or the investigation of linguistic phenome-
na. Recently, treebanks and other large corpora
have become more important since the develop-
ment of powerful machine learning methods.
As mentioned above, Vietnamese is an isolat-
ing language. There is no word delimiter in Viet-
namese. The smallest unit in the construction of
words is syllables. Words can be single or com-
pound. Vietnamese script is invented based on
Latin alphabet in which the expansion includes
accent characters and stressed accents.
Since Vietnamese word order is quite fixed,
we choose to use constituency representation of
syntactic structures. For languages with freer
word order such as Japanese or Czech, depen-
dency representation is more suitable. We apply
annotation scheme proposed by Marcus et al.
(1993). This approach has been successfully ap-
plied to a number of languages such as English,
Chinese, Arabic, etc.
For Vietnamese, there are three annotation le-
vels including word segmentation, POS tagging,
and syntactic labeling. Word segmentation iden-
tifies word boundary in sentences. POS tagging
assigns correct POS tags to words. Syntactic
labeling recognizes both phrase-structure tags
and functional tags. Our main target is to build a
corpus of 10,000 syntactically-annotated sen-
tences (trees) and an additional POS tagged data
set of 10,000 sentences. Treebank construction is
a very complicated task including major phases:
investigation, guideline preparation, building
tools, raw text collection, and annotation. This is
a repeated process involving especially three
phases: annotation, guideline revision, and tool
upgrade. Raw texts are collected from a newspa-
per source, the Youth online daily newspaper,
with a number of topics including social and pol-
itics. We completed about 9,500 trees and 10,000
POS tagged sentences.
In order to deal with ambiguities occurring at
various levels of annotation, we systematically
applied linguistic analysis techniques such as
deletion, insertion, substitution, questioning,
transformation, etc. Notions for analysis tech-
niques are described in guideline. These tech-
niques are originated in literatures or proposed
</bodyText>
<page confidence="0.976889">
182
</page>
<note confidence="0.957346">
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 182–185,
Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999957846153846">
by our group. They are described with examples,
arguments, and alternatives. For automatic labe-
ling tools, we used advanced machine learning
methods such as CRFs for POS tagging or
LPCFGs for syntactic parsing. These tools
helped us speed up labeling process. Besides,
tree editor was also very helpful.
Our treebank project is a branch project of a
national project which aims to develop basic re-
sources and tools for Vietnamese language and
speech processing. This national project is called
VLSP 1 . In addition to treebank, other text-
processing resources and tools include: Vietnam-
ese machine readable dictionary, English-
Vietnamese parallel corpus, word segmenter,
POS tagger, chunker, and parser. Treebank and
tools are closely related. Tools are trained using
treebank data, and then they can be used in tree-
bank construction.
The rest of this paper is organized as follow:
First, we present issues in Vietnamese word
segmentation problem. Second, POS tagging and
syntactic parsing are described. Third, tools and
annotation process are represented. Fourth, we
present annotation agreement evaluation. And
last, some conclusion is drawn.
</bodyText>
<sectionHeader confidence="0.921364" genericHeader="method">
2 Word Segmentation
</sectionHeader>
<bodyText confidence="0.999979291666667">
There are many approaches to word definition,
for example based on morphology, based on syn-
tax, based on semantics, or linguistic compari-
son. We consider words as syntactic atoms
(Sciullo and Williams, 1987) according to the
sense that it is impossible to analyze word struc-
ture using syntactic rules, or that words are the
smallest unit which is syntactically independent.
We choose this criterion partly because the first
application of word segmentation is for syntactic
analysis (build trees).
According to application view, machine trans-
lation researchers may argue that Vietnamese
words and foreign words should match each oth-
er. The problem is that there are so many possi-
ble foreign languages which are different in vo-
cabulary. Dictionary editors may want to extract
phrases from text which need to be explained in
meaning. For this application, syntactic parsers
can be used as tool for editors. Parsers can ex-
tract candidates for phrase/word entry.
The following word types are considered in
word segmentation phase: single words, com-
pound words, repeated words, idioms, proper
</bodyText>
<subsectionHeader confidence="0.265766">
1 Vietnamese Language and Speech Processing
</subsectionHeader>
<bodyText confidence="0.998794428571429">
names, date/time, number expressions, foreign
words, abbreviations.
Word segmentation ambiguity is the major
problem annotators have to deal with. Suppose
that three words “nhà cửa”, “sắc đẹp”, and “hiệu
sách” are being considered. Annotators need to
identify these combinations as words in:
</bodyText>
<listItem confidence="0.989035428571429">
a. Nhà cửa bề bộn quá
b. Cô ấy giữ gìn sắc đẹp.
c. Ngoài hiệu sách có bán cuốn này
And not words in:
a. Ở nhà cửa ngõ chẳng đóng gì cả.
b. Bức này màu sắc đẹp hơn.
c. Ngoài cửa hiệu sách báo bày la liệt.
</listItem>
<bodyText confidence="0.999805">
We used dictionaries as a reference. In prac-
tice, we consider dictionary words as candidate
for word segmentation and make decision using
context.
</bodyText>
<sectionHeader confidence="0.997141" genericHeader="method">
3 POS Tagging and Syntactic Annota-
tion Guidelines
</sectionHeader>
<subsectionHeader confidence="0.997678">
3.1 POS Tag Set
</subsectionHeader>
<bodyText confidence="0.999977916666667">
For European languages, word classes closely
relate to morphological aspects such as gender,
number, case, etc. For Vietnamese, words are
often classified based on their combination abili-
ty, their syntactic functions, and their general
meaning. We choose first two criteria, combina-
tion ability and syntactic function, for POS tag
set design. Therefore our POS tag set will not
contain morphological information (number, as-
pect, tense, etc.), sub-categorization information
(transitive/intransitive verbs, verbs followed by
clauses, etc.), and semantic information.
</bodyText>
<subsectionHeader confidence="0.998412">
3.2 Syntactic Tag Set
</subsectionHeader>
<bodyText confidence="0.999989666666667">
Our tag set contains three tag types: constituency
tags, functional tags, and null-element tags. We
use the tag H to label phrase head. If a phrase has
more than one head, connected by coordination
conjunctions or commas, then all heads are la-
beled with H tag. Other treebanks often does not
use head tag. Therefore researchers on syntactic
parsing (Collins, 1999) used heuristic rules to
determine CFG rules’ head. Machine learning
methods also can be used (Chiang and Bikel,
2002). Null elements are often used for adjective
clauses, ellipsis, passive voice, and topic.
</bodyText>
<subsectionHeader confidence="0.9393695">
3.3 Sentence and Phrase Analysis Tech-
niques
</subsectionHeader>
<bodyText confidence="0.999822666666667">
Annotation of real text requires various tech-
niques to be applied. Ambiguity may occur in
many steps of analysis such as determining
</bodyText>
<page confidence="0.996352">
183
</page>
<bodyText confidence="0.999939125">
phrase’s head, discriminating between possible
complements, discriminating between adjuncts
and other sentence elements, etc. Sentence analy-
sis techniques include deletion, substitution, in-
sertion, transformation, questioning. These tech-
niques exploit contextual information, word
combination, word order, and functional words
to disambiguation between possible structures.
</bodyText>
<subsectionHeader confidence="0.984127">
3.4 Linguistics Issues
</subsectionHeader>
<bodyText confidence="0.999967230769231">
The problem of treebank construction can be
considered as an application of linguistic theories
though treebanks can also be used for linguistic
studies. However, there are still disagreements
among linguists as to solutions for many linguis-
tic issues. For example, that the classifier noun is
noun phrase’s head or pre-modifier is controver-
sial. Another example, Vietnamese sentence
structure is subject-predicate or topic-comment is
also controversial. Our treebank relies more on
subject-predicate structure. Moreover, we choose
linguistic solutions most appropriate to our de-
sign.
</bodyText>
<sectionHeader confidence="0.997547" genericHeader="method">
4 Tools
</sectionHeader>
<bodyText confidence="0.918922230769231">
We designed a tool for supporting annotators in
most all phases of the annotation process. Main
functions of our editor are as follows:
- Edit and view trees in both text mode and
graphical mode
- View log files, highlight modifications
- Search by words or syntactic patterns
- Predict errors (edit, spell, or syntax)
- Compute annotation agreement and high-
light differences
- Compute several kinds of statistics
For encoding the treebank, we have developed
an exchange format named vnSynAF, a syntactic
annotation framework which is conformed to the
standard framework SynAF of ISO. The frame-
work SynAF is built on top of an XML-based
annotation scheme which is recommended by
ISO for the encoding of treebanks2. Our tool also
supports bracketing representation (or Lisp style)
of Penn English Treebank. These formats can be
converted into each other.
For the task of word segmentation, we used
vnTokenizer, a highly accurate segmenter which
uses a hybrid approach to automatically tokenize
Vietnamese text. The approach combines both
finite-state automata technique, regular expres-
</bodyText>
<footnote confidence="0.992228333333333">
2 ISO/CD/24615, Language Resource Management-
Syntactic Annotation Framework (SynAF) TC37/SC 4
N421, 22th Aug 2007, http://tc37sc4.org/documents
</footnote>
<bodyText confidence="0.999729391304348">
sion parsing, and the maximal-matching strategy
which is augmented by statistical methods to re-
solve ambiguities of segmentation (Phuong et al.,
2008).
We used JVnTagger, a POS tagger based on
Conditional Random Fields (Lafferty et al.,
2001) and Maximum Entropy (Berger et al.,
1996). This tagger is also developed under sup-
ported of VLSP project. Training data size is
10,000 sentences. Experiments with 5-fold cross
validation showed that F1 scores for CRFs and
Maxent are 90.40% and 91.03% respectively.
A syntactic parser based on Lexicalized Prob-
abilistic Context-free Grammars (LPCFGs) is
another tool we used. Another group in VLSP
customized Bikel’s parser3 for parsing Vietnam-
ese text. This parser is a well designed and easy
to adapt to new languages. The group imple-
mented a Vietnamese language package which
handles treebank, training, finding head of CFG
rules, and word features. This parser can output
text with constituent tags only or both constituent
tags and functional tags.
</bodyText>
<sectionHeader confidence="0.952339" genericHeader="method">
5 Annotation Process and Agreement
</sectionHeader>
<bodyText confidence="0.999505">
There are three annotation levels: word segmen-
tation, POS tagging, and syntactic labeling. Since
the word segmentation tool had been available
before the start of our project, it was used for the
first annotation level (word segmentation) im-
mediately. As to the other annotation levels (POS
tagging and syntactic parsing), first several thou-
sand sentences were labeled manually. After that
a POS tagger and a parser are trained bimonthly,
then the annotation task becomes semi-
automatic. According to our annotation process,
each sentence is annotated and revised by at least
two annotators. The first annotator labels raw
sentences or revises automatically-analyzed sen-
tences. Then the second annotator revises the
output of the first annotator. In addition, we also
check corpus by syntactic phenomena, for exam-
ple direction words, questions, etc. This process
is supported by tool. So there are many sentences
which are revised more than twice.
Table 2 shows a number of important corpus
statistics such as sentence count, word count, and
syllable count for two data sets. We completed
the POS tagged data set and will complete the
syntactically-labeled data set soon. The average
sentence length is about 21.6 words.
</bodyText>
<footnote confidence="0.957034">
3 http://www.cis.upenn.edu/~dbikel/software.html
</footnote>
<page confidence="0.989353">
184
</page>
<table confidence="0.999478">
Data set Sentences Words Syllables
POS tagged 10,368 210,393 255,237
Syntactically 9,633 208,406 251,696
labeled
</table>
<tableCaption confidence="0.999915">
Table 1. Corpus statistics
</tableCaption>
<bodyText confidence="0.997147461538462">
Annotation agreement measures how similar
two texts annotated independently by different
annotators are. Since this problem is similar to
parsing evaluation, we use parseval measure.
First, syntactic constituents in the form (i, j, la-
bel) are extracted from syntactic trees. Then tree
comparison problem is transformed into consti-
tuent comparison. We can compute three kinds
of measurement: constituent and function simi-
larity, constituent similarity, and bracket simi-
larity. By using this method, we can evaluate
both overall agreement and constituency agree-
ment.
</bodyText>
<figure confidence="0.6517118">
Annotation agreement A between two annota-
tors can be computed as follows:
2 C
C1
 C2
</figure>
<bodyText confidence="0.982888571428571">
where C1 is the number of constituents in the
first annotator’s data set, C2 is the number of
constituents in the second annotator’s data set,
and C is the number of identical constituents.
Table 3 shows an example of constituent extrac-
tion from trees. From Table 3, we can compute:
C1=6; C2=7; C=6; A=12/13=0.92 .
</bodyText>
<table confidence="0.999365454545454">
1st annotator 2nd annotator
(S (NP (Np Hằng)) cling (S (NP (Np Hằng))
(VP (V ngắm) (VP (V ngắm)
(NP (N mưa)) (NP (NP (N mưa))
(PP (E trong) (PP (E trong)
(NP (N (NP (N
viên)))) cling viên)))))
(. .)) (. .))
(1,6,S); (1,1,NP); (2,5,VP); (1,6,S); (1,1,NP); (2,5,VP);
(3,3,NP); (4,5, PP); (5,5,NP) (3,3,NP); (3,5,NP); (4,5,
PP); (5,5,NP)
</table>
<tableCaption confidence="0.9999">
Table 2. Constituent extraction from trees
</tableCaption>
<bodyText confidence="0.999150333333333">
We carried out an experiment involving 3 an-
notators. They annotated 100 sentences and the
result is shown in Table 4.
</bodyText>
<table confidence="0.9992678">
Test A1-A2 A2-A3 A3-A1
Full tags 90.32% 91.26% 90.71%
Constituent 92.40% 93.57% 91.92%
tags
No tags 95.24% 96.33% 95.48%
</table>
<tableCaption confidence="0.999752">
Table 3. Annotation agreement
</tableCaption>
<sectionHeader confidence="0.997216" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999959375">
In this paper, we presented our most up-to-date
results on Vietnamese treebank construction.
This project is coming to final stage. We contin-
ue to annotate more text, revise data by syntactic
phenomenon and feedback from users. We also
use statistical techniques to analyze treebank data
to find out errors and fix them. We intend to pub-
lish these data on LDC this year.
</bodyText>
<sectionHeader confidence="0.998151" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.97754475">
This paper is supported by a national project
named Building Basic Resources and Tools for
Vietnamese Language and Speech Processing,
KC01.01/06-10.
</bodyText>
<sectionHeader confidence="0.976447" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.9994652">
Diệp Quang Ban. 2005. Ngfr pháp tiếng Việt (2 tập).
NXB Giáo duc.
Cao Xuân Hạo. 2006. Tiếng Việt soa thảo ngfr pháp
chức năng. NXB Khoa học Xã hội.
Nguyễn Minh Thuyết và Nguyễn Văn Hiệp. 1999.
Thành phần câu tiếng Việt. NXB ĐHQG Hà Nội.
Ủy ban Khoa học Xã hội Việt Nam. 1983. Ngfr pháp
tiếng Việt. NXB Khoa học Xã hội.
Adam Berger, Stephen D. Pietra, and Vincent D. Pie-
tra. 1996. A maximum entropy approach to natural
language processing. Computational Linguistics,
(22-1).
David Chiang and Daniel M. Bikel. 2002. Recovering
Latent Information in Treebanks. COLING.
Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. PhD thesis, Uni-
versity of Pennsylvania.
John Lafferty, Andrew McCallum, and Fernando Pe-
reira. 2001. Conditional random fields: Probabilis-
tic models for segmenting and labeling sequence
data. ICML.
Mitchell P. Marcus et al. Building a Large Annotated
Corpus of English: The Penn Treebank.
1993. Computational Linguistics.
L. H. Phuong, N. T. M. Huyen, R. Azim, H. T. Vinh.
A hybrid approach to word segmentation of Viet-
namese texts. Proceedings of the 2nd International
Conference on Language and Automata Theory
and Applications, Springer LNCS 5196, Tarragona,
Spain, 2008.
Anna M.D. Sciullo and Edwin Williams. 1987. On the
definition of word. The MIT Press.
Fei Xia et al. Developing Guidelines and Ensuring
Consistency for Chinese Text Annotation. 2000.
COLING.
</reference>
<figure confidence="0.523886">
A
</figure>
<page confidence="0.984955">
185
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.030085">
<title confidence="0.999935">Building a Large Syntactically-Annotated Corpus of Vietnamese</title>
<author confidence="0.979575">Phuong-Thai</author>
<affiliation confidence="0.998772">College of Technology,</affiliation>
<email confidence="0.861438">thainp@vnu.edu.vn</email>
<author confidence="0.896838">Xuan-Luong Vu Lexicography Cen-</author>
<email confidence="0.7849905">trevuluong@vietlex.vn</email>
<author confidence="0.995236">Thi-Minh-Huyen Nguyen</author>
<affiliation confidence="0.760537">University of Sciences, VNU</affiliation>
<email confidence="0.548711">huyenntm@vnu.edu.vn</email>
<author confidence="0.939918">Van-Hiep Nguyen Hong-Phuong Le</author>
<affiliation confidence="0.999237">University of Social Sciences and LORIA/INRIA Lorraine</affiliation>
<email confidence="0.5445795">VNUhiepnv@vnu.edu.vn</email>
<abstract confidence="0.994515611111111">Treebank is an important resource for both research and application of natural language processing. For Vietnamese, we still lack such kind of corpora. This paper presents up-to-date results of a project for Vietnamese treebank construction. Since Vietnamese is an isolating language and has no word delimiter, there are many ambiguities in sentence analysis. We systematically applied a lot of linguistic techniques to handle such ambiguities. Annotators are supported by automaticlabeling tools and a tree-editor tool. Raw texts are extracted from Tuoi Tre (Youth), an online Vietnamese daily newspaper. The current annotation agreement is around 90 percent.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Diệp Quang Ban</author>
</authors>
<date>2005</date>
<booktitle>Ngfr pháp tiếng Việt (2 tập). NXB Giáo duc.</booktitle>
<marker>Ban, 2005</marker>
<rawString>Diệp Quang Ban. 2005. Ngfr pháp tiếng Việt (2 tập). NXB Giáo duc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cao Xuân Hạo</author>
</authors>
<title>Tiếng Việt soa thảo ngfr pháp chức năng. NXB Khoa học Xã hội.</title>
<date>2006</date>
<marker>Hạo, 2006</marker>
<rawString>Cao Xuân Hạo. 2006. Tiếng Việt soa thảo ngfr pháp chức năng. NXB Khoa học Xã hội.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nguyễn Minh</author>
</authors>
<title>Thuyết và Nguyễn Văn Hiệp.</title>
<date>1999</date>
<journal>NXB ĐHQG Hà Nội.</journal>
<marker>Minh, 1999</marker>
<rawString>Nguyễn Minh Thuyết và Nguyễn Văn Hiệp. 1999. Thành phần câu tiếng Việt. NXB ĐHQG Hà Nội.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ủy ban</author>
</authors>
<title>Khoa học Xã hội Việt Nam.</title>
<date>1983</date>
<marker>ban, 1983</marker>
<rawString>Ủy ban Khoa học Xã hội Việt Nam. 1983. Ngfr pháp tiếng Việt. NXB Khoa học Xã hội.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Berger</author>
<author>Stephen D Pietra</author>
<author>Vincent D Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="10563" citStr="Berger et al., 1996" startWordPosition="1579" endWordPosition="1582"> used vnTokenizer, a highly accurate segmenter which uses a hybrid approach to automatically tokenize Vietnamese text. The approach combines both finite-state automata technique, regular expres2 ISO/CD/24615, Language Resource ManagementSyntactic Annotation Framework (SynAF) TC37/SC 4 N421, 22th Aug 2007, http://tc37sc4.org/documents sion parsing, and the maximal-matching strategy which is augmented by statistical methods to resolve ambiguities of segmentation (Phuong et al., 2008). We used JVnTagger, a POS tagger based on Conditional Random Fields (Lafferty et al., 2001) and Maximum Entropy (Berger et al., 1996). This tagger is also developed under supported of VLSP project. Training data size is 10,000 sentences. Experiments with 5-fold cross validation showed that F1 scores for CRFs and Maxent are 90.40% and 91.03% respectively. A syntactic parser based on Lexicalized Probabilistic Context-free Grammars (LPCFGs) is another tool we used. Another group in VLSP customized Bikel’s parser3 for parsing Vietnamese text. This parser is a well designed and easy to adapt to new languages. The group implemented a Vietnamese language package which handles treebank, training, finding head of CFG rules, and word</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam Berger, Stephen D. Pietra, and Vincent D. Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, (22-1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Daniel M Bikel</author>
</authors>
<title>Recovering Latent Information in Treebanks.</title>
<date>2002</date>
<publisher>COLING.</publisher>
<contexts>
<context position="7791" citStr="Chiang and Bikel, 2002" startWordPosition="1174" endWordPosition="1177">categorization information (transitive/intransitive verbs, verbs followed by clauses, etc.), and semantic information. 3.2 Syntactic Tag Set Our tag set contains three tag types: constituency tags, functional tags, and null-element tags. We use the tag H to label phrase head. If a phrase has more than one head, connected by coordination conjunctions or commas, then all heads are labeled with H tag. Other treebanks often does not use head tag. Therefore researchers on syntactic parsing (Collins, 1999) used heuristic rules to determine CFG rules’ head. Machine learning methods also can be used (Chiang and Bikel, 2002). Null elements are often used for adjective clauses, ellipsis, passive voice, and topic. 3.3 Sentence and Phrase Analysis Techniques Annotation of real text requires various techniques to be applied. Ambiguity may occur in many steps of analysis such as determining 183 phrase’s head, discriminating between possible complements, discriminating between adjuncts and other sentence elements, etc. Sentence analysis techniques include deletion, substitution, insertion, transformation, questioning. These techniques exploit contextual information, word combination, word order, and functional words to</context>
</contexts>
<marker>Chiang, Bikel, 2002</marker>
<rawString>David Chiang and Daniel M. Bikel. 2002. Recovering Latent Information in Treebanks. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>PhD thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="7673" citStr="Collins, 1999" startWordPosition="1157" endWordPosition="1158">ign. Therefore our POS tag set will not contain morphological information (number, aspect, tense, etc.), sub-categorization information (transitive/intransitive verbs, verbs followed by clauses, etc.), and semantic information. 3.2 Syntactic Tag Set Our tag set contains three tag types: constituency tags, functional tags, and null-element tags. We use the tag H to label phrase head. If a phrase has more than one head, connected by coordination conjunctions or commas, then all heads are labeled with H tag. Other treebanks often does not use head tag. Therefore researchers on syntactic parsing (Collins, 1999) used heuristic rules to determine CFG rules’ head. Machine learning methods also can be used (Chiang and Bikel, 2002). Null elements are often used for adjective clauses, ellipsis, passive voice, and topic. 3.3 Sentence and Phrase Analysis Techniques Annotation of real text requires various techniques to be applied. Ambiguity may occur in many steps of analysis such as determining 183 phrase’s head, discriminating between possible complements, discriminating between adjuncts and other sentence elements, etc. Sentence analysis techniques include deletion, substitution, insertion, transformatio</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. PhD thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<publisher>ICML.</publisher>
<contexts>
<context position="10521" citStr="Lafferty et al., 2001" startWordPosition="1572" endWordPosition="1575">other. For the task of word segmentation, we used vnTokenizer, a highly accurate segmenter which uses a hybrid approach to automatically tokenize Vietnamese text. The approach combines both finite-state automata technique, regular expres2 ISO/CD/24615, Language Resource ManagementSyntactic Annotation Framework (SynAF) TC37/SC 4 N421, 22th Aug 2007, http://tc37sc4.org/documents sion parsing, and the maximal-matching strategy which is augmented by statistical methods to resolve ambiguities of segmentation (Phuong et al., 2008). We used JVnTagger, a POS tagger based on Conditional Random Fields (Lafferty et al., 2001) and Maximum Entropy (Berger et al., 1996). This tagger is also developed under supported of VLSP project. Training data size is 10,000 sentences. Experiments with 5-fold cross validation showed that F1 scores for CRFs and Maxent are 90.40% and 91.03% respectively. A syntactic parser based on Lexicalized Probabilistic Context-free Grammars (LPCFGs) is another tool we used. Another group in VLSP customized Bikel’s parser3 for parsing Vietnamese text. This parser is a well designed and easy to adapt to new languages. The group implemented a Vietnamese language package which handles treebank, tra</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank.</title>
<date>1993</date>
<note>Computational Linguistics.</note>
<marker>Marcus, 1993</marker>
<rawString>Mitchell P. Marcus et al. Building a Large Annotated Corpus of English: The Penn Treebank. 1993. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L H Phuong</author>
<author>N T M Huyen</author>
<author>R Azim</author>
<author>H T Vinh</author>
</authors>
<title>A hybrid approach to word segmentation of Vietnamese texts.</title>
<date>2008</date>
<booktitle>Proceedings of the 2nd International Conference on Language and Automata Theory and Applications, Springer LNCS 5196,</booktitle>
<location>Tarragona,</location>
<contexts>
<context position="10429" citStr="Phuong et al., 2008" startWordPosition="1557" endWordPosition="1560">tation (or Lisp style) of Penn English Treebank. These formats can be converted into each other. For the task of word segmentation, we used vnTokenizer, a highly accurate segmenter which uses a hybrid approach to automatically tokenize Vietnamese text. The approach combines both finite-state automata technique, regular expres2 ISO/CD/24615, Language Resource ManagementSyntactic Annotation Framework (SynAF) TC37/SC 4 N421, 22th Aug 2007, http://tc37sc4.org/documents sion parsing, and the maximal-matching strategy which is augmented by statistical methods to resolve ambiguities of segmentation (Phuong et al., 2008). We used JVnTagger, a POS tagger based on Conditional Random Fields (Lafferty et al., 2001) and Maximum Entropy (Berger et al., 1996). This tagger is also developed under supported of VLSP project. Training data size is 10,000 sentences. Experiments with 5-fold cross validation showed that F1 scores for CRFs and Maxent are 90.40% and 91.03% respectively. A syntactic parser based on Lexicalized Probabilistic Context-free Grammars (LPCFGs) is another tool we used. Another group in VLSP customized Bikel’s parser3 for parsing Vietnamese text. This parser is a well designed and easy to adapt to ne</context>
</contexts>
<marker>Phuong, Huyen, Azim, Vinh, 2008</marker>
<rawString>L. H. Phuong, N. T. M. Huyen, R. Azim, H. T. Vinh. A hybrid approach to word segmentation of Vietnamese texts. Proceedings of the 2nd International Conference on Language and Automata Theory and Applications, Springer LNCS 5196, Tarragona, Spain, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna M D Sciullo</author>
<author>Edwin Williams</author>
</authors>
<title>On the definition of word.</title>
<date>1987</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="5087" citStr="Sciullo and Williams, 1987" startWordPosition="740" endWordPosition="743">ols are trained using treebank data, and then they can be used in treebank construction. The rest of this paper is organized as follow: First, we present issues in Vietnamese word segmentation problem. Second, POS tagging and syntactic parsing are described. Third, tools and annotation process are represented. Fourth, we present annotation agreement evaluation. And last, some conclusion is drawn. 2 Word Segmentation There are many approaches to word definition, for example based on morphology, based on syntax, based on semantics, or linguistic comparison. We consider words as syntactic atoms (Sciullo and Williams, 1987) according to the sense that it is impossible to analyze word structure using syntactic rules, or that words are the smallest unit which is syntactically independent. We choose this criterion partly because the first application of word segmentation is for syntactic analysis (build trees). According to application view, machine translation researchers may argue that Vietnamese words and foreign words should match each other. The problem is that there are so many possible foreign languages which are different in vocabulary. Dictionary editors may want to extract phrases from text which need to </context>
</contexts>
<marker>Sciullo, Williams, 1987</marker>
<rawString>Anna M.D. Sciullo and Edwin Williams. 1987. On the definition of word. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
</authors>
<title>Developing Guidelines and Ensuring Consistency for Chinese Text Annotation.</title>
<date>2000</date>
<publisher>COLING.</publisher>
<marker>Xia, 2000</marker>
<rawString>Fei Xia et al. Developing Guidelines and Ensuring Consistency for Chinese Text Annotation. 2000. COLING.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>