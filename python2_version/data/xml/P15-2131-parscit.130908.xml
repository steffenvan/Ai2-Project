<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<note confidence="0.580075">
Dialogue Management based on Sentence Clustering
</note>
<author confidence="0.864655">
Wendong Ge
</author>
<affiliation confidence="0.717967">
Institute of Automation,
Chinese Academy of Sciences,
Beijing, China
</affiliation>
<email confidence="0.992443">
wendong.ge@ia.ac.cn
</email>
<sectionHeader confidence="0.994672" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999811">
Dialogue Management (DM) is a key is-
sue in Spoken Dialogue System (SDS).
Most of the existing studies on DM use
Dialogue Act (DA) to represent seman-
tic information of sentence, which might
not represent the nuanced meaning some-
times. In this paper, we model DM based
on sentence clusters which have more
powerful semantic representation ability
than DAs. Firstly, sentences are clustered
not only based on the internal informa-
tion such as words and sentence structures,
but also based on the external information
such as context in dialogue via Recurren-
t Neural Networks. Additionally, the DM
problem is modeled as a Partially Observ-
able Markov Decision Processes (POMD-
P) with sentence clusters. Finally, exper-
imental results illustrate that the proposed
DM scheme is superior to the existing one.
</bodyText>
<sectionHeader confidence="0.998776" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999835941176471">
Dialogue Management (DM) is an important is-
sue in Spoken Dialogue Systems (SDS). (Paek et
al., 2008) Most of the existing studies on DM use
the abstract semantic representation such as Dia-
logue Act (DA) to represent the sentence intention.
In (Bohus et al., 2009), authors propose a plan-
based, task-independent DM framework, called
RavenClaw, which isolates the domain-specific as-
pects of the dialogue control logic from domain-
independent conversational skills. (Daubigney et
al., 2010) proposes a Kalman Temporal Differ-
ences based algorithm to learn efficiently in an off-
policy manner a strategy for a large scale dialogue
system. In (Emmanuel et al., 2013), authors pro-
pose a scheme to utilize a socially-based reward
function for reinforcement learning and use it to
fit the user adaptation issue for DM. (Young et al.,
</bodyText>
<note confidence="0.97088175">
Bo Xu
Institute of Automation,
Chinese Academy of Sciences,
Beijing, China
</note>
<email confidence="0.969473">
xubo@ia.ac.cn
</email>
<bodyText confidence="0.992436428571429">
2013) provides an overview of the current state of
the art in the development of POMDP-based spo-
ken dialog systems. (Hao et al., 2014) presents a
dialog manager based on a log-linear probabilistic
model and uses context-free grammars to impart
hierarchical structure to variables and features.
As we know, sentences in human-human dia-
logues are extremely complicated. The sentences
labeled with the same DA might contain differ-
ent extra meanings. Thus, it is difficult for DA
to represent the nuanced meaning of sentence in
dialogue. In this paper, we propose a novel DM
scheme based on sentence clustering. The contri-
butions of this work are as follows.
</bodyText>
<listItem confidence="0.9931918">
• Semantic representation of sentence in dia-
logue is defined as sentence cluster which
could represent more nuanced semantic in-
formation than DA. Sentence similarity for
clustering is calculated via internal informa-
tion such as words and sentence structures
and external information such as the dis-
tributed representation of sentence (vector)
from Recurrent Neural Networks (RNN).
• The DM problem is modeled as a POMD-
</listItem>
<bodyText confidence="0.877241428571429">
P, where state is defined as sequence of sen-
tence clusters, reward is defined as slot-filling
efficiency and sentence popularity, and state
transition probability is calculated by the pre-
diction model based on RNN, considering
historical dialogue information sufficiently.
The rest of this paper is organized as follows.
In Section 2, system model is introduced. Sec-
tion 3 describes sentence clustering and prediction
model based on RNN, and Section 4 models the
DM problem as a POMDP. Extensive experimen-
tal results are provided in Section 5 to illustrate the
performance comparison, and Section 6 concludes
this study.
</bodyText>
<page confidence="0.757626">
800
</page>
<note confidence="0.345526666666667">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 800–805,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999583">
Figure 1: sentence cluster vs. DA
Figure 2: system model
</figureCaption>
<sectionHeader confidence="0.949468" genericHeader="method">
2 System Model
</sectionHeader>
<bodyText confidence="0.9821601875">
In this paper, we establish a SDS via human-
human dialogue corpus, where sentence cluster
rather than DA is utilized to represent sentence in-
tention due to its ability of catching finer-grained
semantic information. For example, Fig. 1
shows some dialogue segments in hotel reserva-
tion. Both A1 and A2 could be labeled with “re-
quest (client quantity)”, because the aims of them
are requesting the quantity of clients. Howev-
er, A1 has an extra meaning that it is a necessity
for the reception to record the quantity of clients,
while A2 not, which might lead to different evo-
lutions of dialogues. Probably, we could add this
necessity to the DA corresponding to A1 manual-
ly, but it is infeasible for all the sentences to dis-
tinguish the fine-grained semantic information by
adding abstract symbol to DA. Thus, in this paper,
we automatically cluster all the sentences in dia-
logues, and utilize sentence clusters to represent
sentence intentions, which has more powerful ca-
pability to capture semantic information.
The SDS based on sentence clustering could be
divided into offline stage and online stage, illus-
trated in Fig. 2.
In offline stage:
Sentence Clustering: The sentence similarity
is calculated based on not only internal informa-
tion such as words and sentence structure, but also
external information such as the distributed rep-
resentation from RNN. And then the sentences in
dialogue corpus are clustered into different tiny
groups, which will be discussed in section 3.
</bodyText>
<figureCaption confidence="0.99132">
Figure 3: an online example
</figureCaption>
<bodyText confidence="0.966666939393939">
Dialogue Policy Training: We label the dia-
logues in corpus with the sentence clusters gen-
erated in the previous process. Thus, these labeled
dialogues could be utilized to train the optimal dia-
logue policy with Reinforcement Learning, which
will be introduced in section 4.
In online stage:
Automatic Speech Recognition (ASR): When
receiving user voice, ASR module transforms it in-
to text (Vinyals et al., 2012). As there might be
ambiguity and errors in ASR, it is difficult to ob-
tain the exact text corresponding to the input voice.
Thus, the distribution over possible texts is used to
represent the result of ASR.
Sentence Matching (SM): the function of SM
is to establish a mapping from the distribution over
possible texts to the distribution over possible sen-
tence clusters.
DM: Based on the distribution of clusters, D-
M model updates the belief state in POMDP and
selects the optimal action, namely the optimal ma-
chine sentence cluster, according to the dialogue
policy. The relevant slots are also filled based on
the user and machine sentence clusters.
Sentence Selection: This module selects the
most appropriate sentence from the output ma-
chine sentence cluster according to the user profile
such as personality character (Ball et al., 2000).
Text To Speech (TTS): This model transforms
the selected sentence text into the output voice as
a response (Zen et al., 2007).
Fig. 3 is a human-machine dialogue example in
online stage.
</bodyText>
<sectionHeader confidence="0.959594" genericHeader="method">
3 Sentence Clustering based on RNN
</sectionHeader>
<bodyText confidence="0.998117875">
In this section, we cluster the sentences for DM
modeling, which might be different from general
sentence clustering. Sentence similarity for clus-
tering are calculated from two aspects. Firstly,
it is calculated traditionally based on internal in-
formation such as words and sentence structures,
which is widely researched in (Li et al., 2006)
(Achananuparp et al., 2008). (Word embedding
</bodyText>
<figure confidence="0.988946324675325">
request (client quantity)
DA1
Ă
A1: I need to record the quantity of clients.
B1: Perhaps 3 persons.
Ă
Ă
Cluster 1
A2: please tell me the number of clients.
B2: Is it necessary?
A3: Yes, I need to record this.
B3: OK, 3 persons, maybe.
I have to know how many persons will live in.
It is necessary to record the number of clients.
...
DA1
Cluster 2
request (client quantity)
Do you mind telling me the quantity of clients?
Please let me know how many persons will live in.
...
offline
online
user
Dialogue Corpus
voice
voice text
ASR
TTS
text
Sentence
Matching
Sentence
Selecting
Sentence Clustering
cluster
cluster
DM
User:
Machine:
User:
Machine:
Hello, I want to reserve a double room
Two double room. Your check-in time?
I need only one double room.
I am sorry. One double room. OK.
...
ASR+SM
ASR+SM
TTS+SS
TTS+SS
C27: 0.63
C15: 0.37
C15: 0.88
C79: 0.12
C283
C125
room type double room
room num
room type double room
room num
...
...
slot filling
slot filling
DM
...
...
2
1
801
...
A6: Please give me your phone number.
B6: Unfortunately, I lost my cellphone.
A7: I am sorry. We need a phone number to contact you.
Could you please tell me your friend’s phone number?
... ...
</figure>
<figureCaption confidence="0.999547">
Figure 4: an example of sentence similarity
</figureCaption>
<bodyText confidence="0.999567904761905">
and sentence parsing might be used for this cal-
culation.) Additionally, for DM-based sentence
clustering, the sentences that we intend to put into
the same cluster are not only the sentences with
similar surface meaning, but also the sentences
with similar intention (Semantics or Pragmatics),
even if they might be different in surface meaning
sometimes. For example, illustrated in Fig. 4, B4
and B6 are different in surface meaning, but they
have similar intention, namely he or she might not
provide his or her phone number right now. Thus,
in the sentence clustering for DM modeling, they
should be clustered into the same group. It is diffi-
cult to give a high similarity score between B4 and
B6 only according to the internal information, but
we could observe that the sentences around them
in the context are similar. Thus, external informa-
tion is also important to the sentence clustering for
DM. In the following, we will discuss the cluster-
ing process.
{ We denote the sentence cluster set as Ck =
</bodyText>
<equation confidence="0.961813571428571">
}
ck 1, ck 2, · · · , ck , and the dialogue set as Dk =
Nk
{ C }
dk 1, dk 2, · · · , dk in the k-th iteration. Thus, the
Nk
�
</equation>
<bodyText confidence="0.953579">
steps of sentence clustering are:
Step 1: Initially, we only utilize the internal
information to cluster the sentences via Affinity
Propagation (AP) algorithm (Brendan et al., 2007)
and denote the clustering result as C0. If C0 is
used to label the sentences in dialogues, the j-th
dialogue could be denoted as a sequence of clus-
ters, namely d0j = { c01, c02, · · · , cO }.
</bodyText>
<equation confidence="0.750166">
l 7J
</equation>
<bodyText confidence="0.987516166666667">
Step 2: In the k-th iteration, we use cluster set
Ck to label dialogue set Dk.
Step 3: We utilize RNN to obtain the distribut-
ed representation of sentence, illustrated in Fig. 5.
The input of RNN is sentence cluster in each turn,
namely ckt . The input layer I (t) is the one-hot rep-
resentation of ckt . (Turian et al., 2010) (The size of
I (t) is equivalent to ICk1. There is only one 1 in
I (t) corresponding to the ckt position, and other
elements are zeros.) H (t) is defined as the hidden
layer. The output layer O (t) is the distribution
over possible ckt+1, which could be calculated as
</bodyText>
<figureCaption confidence="0.960035">
Figure 5: RNN for sentence clustering
follow. (Mikolov et al., 2010)
</figureCaption>
<equation confidence="0.7800284">
{H (t) = f (UI (t) + WH (t − 1)) (1)
O (t) = g (VH (t))
where f (x) = 1/(1 + e−x) and g (xi) =
/∑Ne
ex� i=1 ex�. The parameters of this RNN could
</equation>
<bodyText confidence="0.999318666666666">
be trained by the Back Propagation Through Time
(BPTT) algorithm. (Mikolov, 2012) From RNN,
we could obtain two significant results: one is the
distributed representation (vectors) of the sentence
clusters (U), which is used for sentence clustering;
the other is the prediction model for sentence clus-
ters, which is used for DM.
Step 4: we calculate the sentence similarity
based on vectors obtained in Step 3, and combine
it with the sentence similarity from internal infor-
mation (weighted mean), in order to cluster the set
Ck via AP algorithm, which is denoted as Ck+1.
</bodyText>
<equation confidence="0.982389">
Step 5: NC = ∑k+1
i=k−kth+2 NiC is defined as
</equation>
<bodyText confidence="0.907064">
the average number of clusters in the last kth iter-
ation. If ∑k+1 ~~Ni C− �NC �� &lt; Nth, stop the
i=k−kth+2
iteration of clustering, or go to Step 2, where Nth
is the variation threshold of quantity of clusters.
Thus, in the last iteration, we get the cluster set
</bodyText>
<equation confidence="0.9972045">
{ }
C k¯ = c¯k 1, c¯k 2, · · · , c¯k and prediction model
Nk
C
</equation>
<bodyText confidence="0.949208333333333">
for these sentence clusters. We divide all the sen-
tences in dialogue corpus into the sentence set spo-
ken by customers and the sentence set spoken by
customer service representatives, and then utilize
C k¯ to label them respectively, which is denoted as
Cu = {cu1, cu2, · · · , c ru }, namely the clusters of
user sentences, and &apos; = {cl c2 ,
` , CmNM },
namely the clusters of machine sentences.
</bodyText>
<sectionHeader confidence="0.94902" genericHeader="method">
4 DM based on Sentence Clustering
</sectionHeader>
<bodyText confidence="0.9999718">
The dialogue process mentioned in section 2 could
be formulized as follows, illustrated in Fig. 6. It
is defined X = {x1, · · · , xT} as inner (or exac-
t) sentence cluster corresponding to the user in-
put in each turn, which is unobservable and xt E
</bodyText>
<figure confidence="0.940157925925926">
U
V
k
I t
O t!
!
H t!
1
ck&amp;quot;
t
I t &amp;quot; 1!
W
W
c k &amp;quot;
t
2
I t &amp;quot; 2!
U
H t &amp;quot;
2!
U H t
1!
...
A4: Please tell me your phone number.
B4: Well, my cellphone is broken.
A5: I am sorry. We need a phone number to contact you.
Could you please give me your friend’s phone number?
</figure>
<page confidence="0.796324">
802
</page>
<figureCaption confidence="0.998518">
Figure 6: dialogue process
</figureCaption>
<bodyText confidence="0.999472">
Wu. E = {e1, · · · , eT} is defined as the input
voice, which is observable to infer xt in each turn.
Y = {y1, · · · , yT} is defined as the output clus-
ter of machine, where yt ∈ Wm. Thus, the DM
problem is to find out the optimal yt according to
{e1, y1, · · · , et}. In the following, the DM prob-
lem is modeled as a POMDP.
State in the t-th epoch is defined
as the sequence of clusters, namely
</bodyText>
<equation confidence="0.778736666666667">
st = {xt−τ, yt−τ, · · · , xt−1, yt−1, xt}, where
st ∈ Y . Action in the t-th epoch is defined as
at = yt, where at ∈ ,9/ . The state transition
probability Pr {st+1 |st, at } could be shown as
Pr {st+1 |st, at }
= Pr {xt+1 |yt, xt, ··· , yt−τ, xt−τ } (2)
</equation>
<bodyText confidence="0.977147">
which is calculated by the prediction model based
on RNN in section 3.
Observation is defined as ot = {et−τ, · · · , et},
where ot ∈ O. As {xt−τ, · · · , xt} in state st is
unobservable, belief state is defined to represent
the distribution over possible states, which is de-
noted as b (t) ∈ -4. According to (Kaelbling et
al., 1998), the belief state updating could be repre-
sented as
</bodyText>
<equation confidence="0.984656333333333">
Pr {ot+1 |st+1, at } pst+1
bt+1 (st+1) = (3)
Pr {ot+1 |bt, at }
</equation>
<bodyText confidence="0.999822">
where pst+1 = ∑stEY Pr {st+1 |st, at } bt (st).
According to Fig. 5, Pr {ot+1 |st+1, at } could be
shown as
</bodyText>
<equation confidence="0.998660333333333">
Pr {ot+1 |st+1, at }
= Pr {ot+1 |st+1 }
= Pr {et−τ+1, · · · , et+1 |xt−τ+1, · · · , yt, xt+1 }
= Pr {et−τ+1, · · · , et+1 |xt−τ+1, · · · , xt+1 }
t+1∏=
i=t−τ+1
</equation>
<bodyText confidence="0.936011142857143">
(4)
However, it is difficult to obtain the probabili-
ty Pr {et |xt }, as different people have different
habits of expression and pronunciation. Fortunate-
ly, Pr {xt |et } could be estimated based on ASR
and SM. Thus, based on Bayes Rules, we have the
following equation.
</bodyText>
<equation confidence="0.958484">
Pr {xi |ei } Pr {ei}
Pr{ei |xi } = (5)
Pr {xi}
</equation>
<bodyText confidence="0.999747333333333">
where Pr {xt} is the prior distribution of xt and
could be counted by corpus. With (4) and (5), (3)
could be rewritten as
</bodyText>
<equation confidence="0.963493090909091">
t+1∏� · pst+1 · Pr {xi |ei }
i=t−τ+1
t+1∏ Pr {xi}
i=t−τ+1
(6)
/Pr {ei} Pr{ot+1 |bt,at} (7)
is a normalization constant.
The reward function is defined as
rt (st, at, st+1) = A fr s a s + Aprp(st,at,st+1
( t, t, t+i
(8)
</equation>
<bodyText confidence="0.988210428571429">
where Af + Ap = 1 and rt (st, at, st+1) ∈ 9.
Firstly, rf(st,at,st+1) stands for the number of un-
filled slots that are filled by the sequence of sen-
tence clusters corresponding to (st, at, st+1). This
slot-filling process could be achieved by a clas-
sifier trained by the dialogues labeled with sen-
tence clusters and slot-filling information. (Input-
s are cluster sequences, and outputs are filled s-
lots.) Additionally, rp(st,at,st+1) is defined as the
normalized quantity of st+1 conditioned by st and
at, which could be counted in corpus and stands
for the popularity features of human-human dia-
logues. Thus, for the belief state, the reward func-
tion could be represented as
</bodyText>
<equation confidence="0.967384">
rt (bt, at) = ∑
st+1EY
· Pr (st+1 |st, at) bt (st)
</equation>
<bodyText confidence="0.99954">
Therefore, if we define the policy as a mapping
from belief state to action, namely C ∈ T : -4 →
, 9/, the POMDP-based DM problem is shown as
</bodyText>
<equation confidence="0.9889879375">
[ T
Eζ∑Ort (bt, at)]
t=1
s.t. bt+1 (st+1) = t+1∏ Pr{xi}
i=t−τ+1
· ∑ Pr {st+1 |st, at } bt (st)
stEY
Ă
x -
t 1
e - e e
t 1 t t 1
y -
t 1
xt
yt
x t
1
y
t 1
Ă
bt+1 (st+1) =
where
t+1
= ∏i=t−τ+1
∑ rt (st, at, st+1)
stEY (9)
Pr {ei |xi } max
ζEY
κ t+1∏ Pr{xi|ei }
i=t−τ+1
(10)
</equation>
<page confidence="0.994619">
803
</page>
<bodyText confidence="0.99991925">
where Q is the time discount factor and 0 &lt; Q &lt; 1.
This problem is a MDP problem with continuous
states, which could be solved by the Natural Actor
and Critic algorithm (Peters et al., 2008).
</bodyText>
<sectionHeader confidence="0.98047" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.998062266666667">
In this section, we compare the performances of
the proposed Sentence Clustering based Dialogue
Management (SCDM) scheme and the existing D-
M scheme. The existing scheme is designed ac-
cording to (Young et al., 2013), where DA is uti-
lized to represent the semantic information of sen-
tence and the dialogue policy is trained via Rein-
forcement Learning. It is also an extrinsic (or end-
to-end) evaluation to compare the semantic repre-
sentation ability between sentence cluster and DA.
In order to compare the performances of the
DM schemes, we collect 171 human-human di-
alogues in hotel reservation and utilize 100 dia-
logues of them to establish a SDS. The residual
71 dialogues are used to establish a simulated user
for testing (Schatzmann et al., 2006). We define
the slots requested from machine to user as “room
type”, “room quantity”, “checkin time”, “check-
out time”, “client name” and “client phone”. We
also define the slots requested from users to ma-
chine as “hotel address = No.95 East St.”, “room
type set = single room, double room, and deluxe
room”, “single room price = $80”, “double room
price = $100”, “deluxe room price = $150”. The
hotel reservation task could be considered as a pro-
cess of exchanging the slot information between
machine and user to some extent.
Fig. 7 illustrates the dialogue turn in the DM
schemes, using different training corpus. Here,
we vary the size of training corpus from 10 dia-
logues to 100 dialogues and define average turn
as the average dialogue turn cost to complete the
task. From this picture, we find out that the SCD-
M scheme has lower average turn than the existing
scheme, partly because the sentence are automati-
cally clustered into many small groups that could
represent more nuanced semantic information than
DAs, partly because RNN could estimate next sen-
tence cluster according to the vector in hidden lay-
er that contains abundant historical dialogue in-
formation. As the number of sentence clusters is
greater than number of DAs, RNN could also solve
the scarcity problem and smoothing problem in the
predicting process. Additionally, with the incre-
ment of training dialogue size, the average turn
</bodyText>
<subsubsectionHeader confidence="0.409827">
quantity of training dialogues
</subsubsectionHeader>
<figureCaption confidence="0.999743">
Figure 7: comparison of average turn
</figureCaption>
<bodyText confidence="0.999779333333333">
of dialogue decreases, which ought to be ascribed
to the fact that more training data could let SD-
S reach more states with more times and increase
the accuracy of the parameter estimation in RNN
and POMDP. Furthermore, with the increment of
training dialogue size, the dialogue turn improve-
ment of the proposed scheme turns less obvious,
because the number of new sentence pattern de-
ceases with the training size increment.
</bodyText>
<sectionHeader confidence="0.999016" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999976941176471">
In this paper, we focused on the DM scheme based
on sentence clustering. Firstly, sentence cluster is
defined as the semantic representation of sentence
in dialogue, which could describe more naunced
sentence intention than DA. Secondly, RNN is es-
tablished for sentence clustering, where sentence
similarity is calculated not only based on the inter-
nal information such as words and sentence struc-
ture, but also based on the external information
such as context in dialogue. Thirdly, the DM prob-
lem is modeled as a POMDP, where the state is
defined as the sequence of sentence clusters and
the state transition probability is estimated by RN-
N, considering the whole information of historical
dialogue. Finally, the experimental results illus-
trated that the proposed DM scheme is superior to
the existing one.
</bodyText>
<sectionHeader confidence="0.998028" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996146142857143">
This work is supported by the National Pro-
gram on Key Basic Research Project (973 Pro-
gram), basic theories and methods of Chinese Lan-
guage Processing and Deep Computing in Inter-
net environment, multi-lingual Automatic Speech
Recognition for complex environments. (No.
2013CB329302)
</bodyText>
<figure confidence="0.978860833333333">
11
10
9
8
7
6
5
4
10 20 30 40 50 60 70 80 90 100
the existing DM scheme
the SCDM scheme
average turns of testing dialogues
</figure>
<page confidence="0.993762">
804
</page>
<sectionHeader confidence="0.993235" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999911585714286">
Dan Bohus, Alexander, I. Rudnicky. 2009. The Raven-
Claw dialog management framework: Architecture
and systems Computer Speech and Language, vol.
23, pages: 332-361, 2009.
Emmanuel Ferreira, Fabrice Lefvre. 2013. Social sig-
nal and user adaptation in reinforcement learning-
based dialogue management. MLIS ’13, Aug, 2013.
Brendan J. Frey, Delbert Dueck. 2007 Clustering by
Passing Messages Between Data Points. Science,
2007.
Ball, G., Breese, J. 2000. Emotion and personality
in a conversational agent. Embodied conversational
agents, pages: 189-219, 2000.
Zen, H., Nose, T., Yamagishi, J., Sako, S., Masuko, T.,
Black, A. W., Tokuda, K. 2007 The HMM-based
speech synthesis system version 2.0. In Proc. 6th
ISCA Workshop on Speech Synthesis, Aug, 2007.
Schatzmann, J., Weilhammer, K., Stuttle, M., Young,
S. 2006 A survey of statistical user simulation tech-
niques for reinforcement-learning of dialogue man-
agement strategies. The knowledge engineering re-
view, 21(02), 97-126, 2006.
Turian, J., Ratinov, L., Bengio, Y. 2010 Word repre-
sentations: a simple and general method for semi-
supervised learning. In Proceedings of the 48th an-
nual meeting of the association for computational
linguistics, Jul, 2010.
Peters, J., Schaal, S. 2008 Natural actor-critic. Neuro-
computinge, 71(7), 1180-1190, 2008.
Kaelbling, L., Littman, M., and Cassandr, A. 1998
Planning and acting in partially observable stochas-
tic domains. Artif. Intell., vol.101, pages: 99-134,
1998.
Daubigney, L., Geist, M., Pietquin, O. 2012. Off-
policy learning in large-scale POMDP-based dia-
logue systems. EEE International Conference on A-
coustics, Speech and Signal Processing (ICASSP).,
pages: 4989-499, Mar, 2012.
Vinyals, O., Ravuri, S. V., Povey, D. 2012. Revis-
iting Recurrent Neural Networks for robust ASR.
2012 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), 2012.
Achananuparp, P., Hu, X., Shen, X. 2008. The evalua-
tion of sentence similarity measures. In Data Ware-
housing and Knowledge Discovery, pages: 305-316,
2008.
Young, S., Gasic, M., Thomson, B., Williams, J. D.
(2013). 2013. Pomdp-based statistical spoken di-
alog systems: A review. Proceedings of the IEEE,
101(5), pages: 1160-1179, 2013.
Mikolov, T. 2012 Statistical language models based on
neural networks. Presentation at Google, Mountain
View, 2012.
Mikolov, T., Karafit, M., Burget, L., Cernocky, J., Khu-
danpur, S. 2010 Recurrent neural network based
language model. 11th Annual Conference of the
International Speech Communication Association,
Sep, 2010.
Paek, T., Pieraccini, R. 2008. Automating spoken
dialogue management design using machine learn-
ing: An industry perspective. Speech communica-
tion, 50(8), 716-729, 2008.
Hao Tang, Watanabe, S., Marks, T. K., Hershey, J. R.
2014. Log-linear dialog manager. IEEE Interna-
tional Conference on Acoustics, Speech and Signal
Processing (ICASSP), May, 2014.
Li Y, McLean D, Bandar Z A, et al. 2006. Sen-
tence similarity based on semantic nets and corpus
statistics. Knowledge and Data Engineering, IEEE
Transactions on, 18(8), 1138-1150, 2006.
</reference>
<page confidence="0.998805">
805
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.231858">
<title confidence="0.981009">Dialogue Management based on Sentence Clustering</title>
<author confidence="0.601917">Wendong</author>
<affiliation confidence="0.605559666666667">Institute of Chinese Academy of Beijing,</affiliation>
<email confidence="0.986656">wendong.ge@ia.ac.cn</email>
<abstract confidence="0.998227571428571">Dialogue Management (DM) is a key issue in Spoken Dialogue System (SDS). Most of the existing studies on DM use Dialogue Act (DA) to represent semantic information of sentence, which might not represent the nuanced meaning sometimes. In this paper, we model DM based on sentence clusters which have more powerful semantic representation ability than DAs. Firstly, sentences are clustered not only based on the internal information such as words and sentence structures, but also based on the external information such as context in dialogue via Recurrent Neural Networks. Additionally, the DM problem is modeled as a Partially Observable Markov Decision Processes (POMD- P) with sentence clusters. Finally, experimental results illustrate that the proposed DM scheme is superior to the existing one.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dan Bohus</author>
<author>I Rudnicky Alexander</author>
</authors>
<title>The RavenClaw dialog management framework:</title>
<date>2009</date>
<journal>Architecture and systems Computer Speech and Language,</journal>
<volume>23</volume>
<pages>332--361</pages>
<marker>Bohus, Alexander, 2009</marker>
<rawString>Dan Bohus, Alexander, I. Rudnicky. 2009. The RavenClaw dialog management framework: Architecture and systems Computer Speech and Language, vol. 23, pages: 332-361, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Ferreira</author>
</authors>
<title>Fabrice Lefvre.</title>
<date>2013</date>
<tech>MLIS ’13,</tech>
<marker>Ferreira, 2013</marker>
<rawString>Emmanuel Ferreira, Fabrice Lefvre. 2013. Social signal and user adaptation in reinforcement learningbased dialogue management. MLIS ’13, Aug, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan J Frey</author>
<author>Delbert Dueck</author>
</authors>
<title>Clustering by Passing Messages Between Data Points. Science,</title>
<date>2007</date>
<marker>Frey, Dueck, 2007</marker>
<rawString>Brendan J. Frey, Delbert Dueck. 2007 Clustering by Passing Messages Between Data Points. Science, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ball</author>
<author>J Breese</author>
</authors>
<title>Emotion and personality in a conversational agent. Embodied conversational agents,</title>
<date>2000</date>
<pages>189--219</pages>
<marker>Ball, Breese, 2000</marker>
<rawString>Ball, G., Breese, J. 2000. Emotion and personality in a conversational agent. Embodied conversational agents, pages: 189-219, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zen</author>
<author>T Nose</author>
<author>J Yamagishi</author>
<author>S Sako</author>
<author>T Masuko</author>
<author>A W Black</author>
<author>K Tokuda</author>
</authors>
<title>The HMM-based speech synthesis system version 2.0. In</title>
<date>2007</date>
<booktitle>Proc. 6th ISCA Workshop on Speech Synthesis,</booktitle>
<contexts>
<context position="6818" citStr="Zen et al., 2007" startWordPosition="1084" endWordPosition="1087">sentence clusters. DM: Based on the distribution of clusters, DM model updates the belief state in POMDP and selects the optimal action, namely the optimal machine sentence cluster, according to the dialogue policy. The relevant slots are also filled based on the user and machine sentence clusters. Sentence Selection: This module selects the most appropriate sentence from the output machine sentence cluster according to the user profile such as personality character (Ball et al., 2000). Text To Speech (TTS): This model transforms the selected sentence text into the output voice as a response (Zen et al., 2007). Fig. 3 is a human-machine dialogue example in online stage. 3 Sentence Clustering based on RNN In this section, we cluster the sentences for DM modeling, which might be different from general sentence clustering. Sentence similarity for clustering are calculated from two aspects. Firstly, it is calculated traditionally based on internal information such as words and sentence structures, which is widely researched in (Li et al., 2006) (Achananuparp et al., 2008). (Word embedding request (client quantity) DA1 Ă A1: I need to record the quantity of clients. B1: Perhaps 3 persons. Ă Ă Cluster 1 </context>
</contexts>
<marker>Zen, Nose, Yamagishi, Sako, Masuko, Black, Tokuda, 2007</marker>
<rawString>Zen, H., Nose, T., Yamagishi, J., Sako, S., Masuko, T., Black, A. W., Tokuda, K. 2007 The HMM-based speech synthesis system version 2.0. In Proc. 6th ISCA Workshop on Speech Synthesis, Aug, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schatzmann</author>
<author>K Weilhammer</author>
<author>M Stuttle</author>
<author>S Young</author>
</authors>
<title>A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies. The knowledge engineering review,</title>
<date>2006</date>
<volume>21</volume>
<issue>02</issue>
<pages>97--126</pages>
<contexts>
<context position="16903" citStr="Schatzmann et al., 2006" startWordPosition="3051" endWordPosition="3054">he existing DM scheme. The existing scheme is designed according to (Young et al., 2013), where DA is utilized to represent the semantic information of sentence and the dialogue policy is trained via Reinforcement Learning. It is also an extrinsic (or endto-end) evaluation to compare the semantic representation ability between sentence cluster and DA. In order to compare the performances of the DM schemes, we collect 171 human-human dialogues in hotel reservation and utilize 100 dialogues of them to establish a SDS. The residual 71 dialogues are used to establish a simulated user for testing (Schatzmann et al., 2006). We define the slots requested from machine to user as “room type”, “room quantity”, “checkin time”, “checkout time”, “client name” and “client phone”. We also define the slots requested from users to machine as “hotel address = No.95 East St.”, “room type set = single room, double room, and deluxe room”, “single room price = $80”, “double room price = $100”, “deluxe room price = $150”. The hotel reservation task could be considered as a process of exchanging the slot information between machine and user to some extent. Fig. 7 illustrates the dialogue turn in the DM schemes, using different t</context>
</contexts>
<marker>Schatzmann, Weilhammer, Stuttle, Young, 2006</marker>
<rawString>Schatzmann, J., Weilhammer, K., Stuttle, M., Young, S. 2006 A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies. The knowledge engineering review, 21(02), 97-126, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Turian</author>
<author>L Ratinov</author>
<author>Y Bengio</author>
</authors>
<title>Word representations: a simple and general method for semisupervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th annual meeting of the association for computational linguistics,</booktitle>
<contexts>
<context position="10367" citStr="Turian et al., 2010" startWordPosition="1728" endWordPosition="1731">formation to cluster the sentences via Affinity Propagation (AP) algorithm (Brendan et al., 2007) and denote the clustering result as C0. If C0 is used to label the sentences in dialogues, the j-th dialogue could be denoted as a sequence of clusters, namely d0j = { c01, c02, · · · , cO }. l 7J Step 2: In the k-th iteration, we use cluster set Ck to label dialogue set Dk. Step 3: We utilize RNN to obtain the distributed representation of sentence, illustrated in Fig. 5. The input of RNN is sentence cluster in each turn, namely ckt . The input layer I (t) is the one-hot representation of ckt . (Turian et al., 2010) (The size of I (t) is equivalent to ICk1. There is only one 1 in I (t) corresponding to the ckt position, and other elements are zeros.) H (t) is defined as the hidden layer. The output layer O (t) is the distribution over possible ckt+1, which could be calculated as Figure 5: RNN for sentence clustering follow. (Mikolov et al., 2010) {H (t) = f (UI (t) + WH (t − 1)) (1) O (t) = g (VH (t)) where f (x) = 1/(1 + e−x) and g (xi) = /∑Ne ex� i=1 ex�. The parameters of this RNN could be trained by the Back Propagation Through Time (BPTT) algorithm. (Mikolov, 2012) From RNN, we could obtain two sign</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Turian, J., Ratinov, L., Bengio, Y. 2010 Word representations: a simple and general method for semisupervised learning. In Proceedings of the 48th annual meeting of the association for computational linguistics, Jul, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Peters</author>
<author>S Schaal</author>
</authors>
<date>2008</date>
<journal>Natural actor-critic. Neurocomputinge,</journal>
<volume>71</volume>
<issue>7</issue>
<pages>1180--1190</pages>
<marker>Peters, Schaal, 2008</marker>
<rawString>Peters, J., Schaal, S. 2008 Natural actor-critic. Neurocomputinge, 71(7), 1180-1190, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kaelbling</author>
<author>M Littman</author>
<author>A Cassandr</author>
</authors>
<title>Planning and acting in partially observable stochastic domains.</title>
<date>1998</date>
<journal>Artif. Intell.,</journal>
<volume>101</volume>
<pages>99--134</pages>
<contexts>
<context position="13753" citStr="Kaelbling et al., 1998" startWordPosition="2428" endWordPosition="2431">as the sequence of clusters, namely st = {xt−τ, yt−τ, · · · , xt−1, yt−1, xt}, where st ∈ Y . Action in the t-th epoch is defined as at = yt, where at ∈ ,9/ . The state transition probability Pr {st+1 |st, at } could be shown as Pr {st+1 |st, at } = Pr {xt+1 |yt, xt, ··· , yt−τ, xt−τ } (2) which is calculated by the prediction model based on RNN in section 3. Observation is defined as ot = {et−τ, · · · , et}, where ot ∈ O. As {xt−τ, · · · , xt} in state st is unobservable, belief state is defined to represent the distribution over possible states, which is denoted as b (t) ∈ -4. According to (Kaelbling et al., 1998), the belief state updating could be represented as Pr {ot+1 |st+1, at } pst+1 bt+1 (st+1) = (3) Pr {ot+1 |bt, at } where pst+1 = ∑stEY Pr {st+1 |st, at } bt (st). According to Fig. 5, Pr {ot+1 |st+1, at } could be shown as Pr {ot+1 |st+1, at } = Pr {ot+1 |st+1 } = Pr {et−τ+1, · · · , et+1 |xt−τ+1, · · · , yt, xt+1 } = Pr {et−τ+1, · · · , et+1 |xt−τ+1, · · · , xt+1 } t+1∏= i=t−τ+1 (4) However, it is difficult to obtain the probability Pr {et |xt }, as different people have different habits of expression and pronunciation. Fortunately, Pr {xt |et } could be estimated based on ASR and SM. Thus, </context>
</contexts>
<marker>Kaelbling, Littman, Cassandr, 1998</marker>
<rawString>Kaelbling, L., Littman, M., and Cassandr, A. 1998 Planning and acting in partially observable stochastic domains. Artif. Intell., vol.101, pages: 99-134, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Daubigney</author>
<author>M Geist</author>
<author>O Pietquin</author>
</authors>
<title>Offpolicy learning in large-scale POMDP-based dialogue systems.</title>
<date>2012</date>
<booktitle>EEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).,</booktitle>
<pages>4989--499</pages>
<marker>Daubigney, Geist, Pietquin, 2012</marker>
<rawString>Daubigney, L., Geist, M., Pietquin, O. 2012. Offpolicy learning in large-scale POMDP-based dialogue systems. EEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)., pages: 4989-499, Mar, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Vinyals</author>
<author>S V Ravuri</author>
<author>D Povey</author>
</authors>
<title>Revisiting Recurrent Neural Networks for robust ASR.</title>
<date>2012</date>
<booktitle>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),</booktitle>
<contexts>
<context position="5849" citStr="Vinyals et al., 2012" startWordPosition="923" endWordPosition="926">nformation such as the distributed representation from RNN. And then the sentences in dialogue corpus are clustered into different tiny groups, which will be discussed in section 3. Figure 3: an online example Dialogue Policy Training: We label the dialogues in corpus with the sentence clusters generated in the previous process. Thus, these labeled dialogues could be utilized to train the optimal dialogue policy with Reinforcement Learning, which will be introduced in section 4. In online stage: Automatic Speech Recognition (ASR): When receiving user voice, ASR module transforms it into text (Vinyals et al., 2012). As there might be ambiguity and errors in ASR, it is difficult to obtain the exact text corresponding to the input voice. Thus, the distribution over possible texts is used to represent the result of ASR. Sentence Matching (SM): the function of SM is to establish a mapping from the distribution over possible texts to the distribution over possible sentence clusters. DM: Based on the distribution of clusters, DM model updates the belief state in POMDP and selects the optimal action, namely the optimal machine sentence cluster, according to the dialogue policy. The relevant slots are also fill</context>
</contexts>
<marker>Vinyals, Ravuri, Povey, 2012</marker>
<rawString>Vinyals, O., Ravuri, S. V., Povey, D. 2012. Revisiting Recurrent Neural Networks for robust ASR. 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Achananuparp</author>
<author>X Hu</author>
<author>X Shen</author>
</authors>
<title>The evaluation of sentence similarity measures.</title>
<date>2008</date>
<booktitle>In Data Warehousing and Knowledge Discovery,</booktitle>
<pages>305--316</pages>
<contexts>
<context position="7285" citStr="Achananuparp et al., 2008" startWordPosition="1157" endWordPosition="1160">ty character (Ball et al., 2000). Text To Speech (TTS): This model transforms the selected sentence text into the output voice as a response (Zen et al., 2007). Fig. 3 is a human-machine dialogue example in online stage. 3 Sentence Clustering based on RNN In this section, we cluster the sentences for DM modeling, which might be different from general sentence clustering. Sentence similarity for clustering are calculated from two aspects. Firstly, it is calculated traditionally based on internal information such as words and sentence structures, which is widely researched in (Li et al., 2006) (Achananuparp et al., 2008). (Word embedding request (client quantity) DA1 Ă A1: I need to record the quantity of clients. B1: Perhaps 3 persons. Ă Ă Cluster 1 A2: please tell me the number of clients. B2: Is it necessary? A3: Yes, I need to record this. B3: OK, 3 persons, maybe. I have to know how many persons will live in. It is necessary to record the number of clients. ... DA1 Cluster 2 request (client quantity) Do you mind telling me the quantity of clients? Please let me know how many persons will live in. ... offline online user Dialogue Corpus voice voice text ASR TTS text Sentence Matching Sentence Selecting Se</context>
</contexts>
<marker>Achananuparp, Hu, Shen, 2008</marker>
<rawString>Achananuparp, P., Hu, X., Shen, X. 2008. The evaluation of sentence similarity measures. In Data Warehousing and Knowledge Discovery, pages: 305-316, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Young</author>
<author>M Gasic</author>
<author>B Thomson</author>
<author>J D Williams</author>
</authors>
<title>Pomdp-based statistical spoken dialog systems: A review.</title>
<date>2013</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<volume>101</volume>
<issue>5</issue>
<pages>1160--1179</pages>
<contexts>
<context position="16367" citStr="Young et al., 2013" startWordPosition="2960" endWordPosition="2963"> bt (st) stEY Ă x - t 1 e - e e t 1 t t 1 y - t 1 xt yt x t 1 y t 1 Ă bt+1 (st+1) = where t+1 = ∏i=t−τ+1 ∑ rt (st, at, st+1) stEY (9) Pr {ei |xi } max ζEY κ t+1∏ Pr{xi|ei } i=t−τ+1 (10) 803 where Q is the time discount factor and 0 &lt; Q &lt; 1. This problem is a MDP problem with continuous states, which could be solved by the Natural Actor and Critic algorithm (Peters et al., 2008). 5 Experimental Results In this section, we compare the performances of the proposed Sentence Clustering based Dialogue Management (SCDM) scheme and the existing DM scheme. The existing scheme is designed according to (Young et al., 2013), where DA is utilized to represent the semantic information of sentence and the dialogue policy is trained via Reinforcement Learning. It is also an extrinsic (or endto-end) evaluation to compare the semantic representation ability between sentence cluster and DA. In order to compare the performances of the DM schemes, we collect 171 human-human dialogues in hotel reservation and utilize 100 dialogues of them to establish a SDS. The residual 71 dialogues are used to establish a simulated user for testing (Schatzmann et al., 2006). We define the slots requested from machine to user as “room ty</context>
</contexts>
<marker>Young, Gasic, Thomson, Williams, 2013</marker>
<rawString>Young, S., Gasic, M., Thomson, B., Williams, J. D. (2013). 2013. Pomdp-based statistical spoken dialog systems: A review. Proceedings of the IEEE, 101(5), pages: 1160-1179, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mikolov</author>
</authors>
<title>Statistical language models based on neural networks. Presentation at Google,</title>
<date>2012</date>
<location>Mountain View,</location>
<contexts>
<context position="10932" citStr="Mikolov, 2012" startWordPosition="1843" endWordPosition="1844">hot representation of ckt . (Turian et al., 2010) (The size of I (t) is equivalent to ICk1. There is only one 1 in I (t) corresponding to the ckt position, and other elements are zeros.) H (t) is defined as the hidden layer. The output layer O (t) is the distribution over possible ckt+1, which could be calculated as Figure 5: RNN for sentence clustering follow. (Mikolov et al., 2010) {H (t) = f (UI (t) + WH (t − 1)) (1) O (t) = g (VH (t)) where f (x) = 1/(1 + e−x) and g (xi) = /∑Ne ex� i=1 ex�. The parameters of this RNN could be trained by the Back Propagation Through Time (BPTT) algorithm. (Mikolov, 2012) From RNN, we could obtain two significant results: one is the distributed representation (vectors) of the sentence clusters (U), which is used for sentence clustering; the other is the prediction model for sentence clusters, which is used for DM. Step 4: we calculate the sentence similarity based on vectors obtained in Step 3, and combine it with the sentence similarity from internal information (weighted mean), in order to cluster the set Ck via AP algorithm, which is denoted as Ck+1. Step 5: NC = ∑k+1 i=k−kth+2 NiC is defined as the average number of clusters in the last kth iteration. If ∑</context>
</contexts>
<marker>Mikolov, 2012</marker>
<rawString>Mikolov, T. 2012 Statistical language models based on neural networks. Presentation at Google, Mountain View, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mikolov</author>
<author>M Karafit</author>
<author>L Burget</author>
<author>J Cernocky</author>
<author>S Khudanpur</author>
</authors>
<title>Recurrent neural network based language model.</title>
<date>2010</date>
<booktitle>11th Annual Conference of the International Speech Communication Association,</booktitle>
<contexts>
<context position="10704" citStr="Mikolov et al., 2010" startWordPosition="1790" endWordPosition="1793">ster set Ck to label dialogue set Dk. Step 3: We utilize RNN to obtain the distributed representation of sentence, illustrated in Fig. 5. The input of RNN is sentence cluster in each turn, namely ckt . The input layer I (t) is the one-hot representation of ckt . (Turian et al., 2010) (The size of I (t) is equivalent to ICk1. There is only one 1 in I (t) corresponding to the ckt position, and other elements are zeros.) H (t) is defined as the hidden layer. The output layer O (t) is the distribution over possible ckt+1, which could be calculated as Figure 5: RNN for sentence clustering follow. (Mikolov et al., 2010) {H (t) = f (UI (t) + WH (t − 1)) (1) O (t) = g (VH (t)) where f (x) = 1/(1 + e−x) and g (xi) = /∑Ne ex� i=1 ex�. The parameters of this RNN could be trained by the Back Propagation Through Time (BPTT) algorithm. (Mikolov, 2012) From RNN, we could obtain two significant results: one is the distributed representation (vectors) of the sentence clusters (U), which is used for sentence clustering; the other is the prediction model for sentence clusters, which is used for DM. Step 4: we calculate the sentence similarity based on vectors obtained in Step 3, and combine it with the sentence similarit</context>
</contexts>
<marker>Mikolov, Karafit, Burget, Cernocky, Khudanpur, 2010</marker>
<rawString>Mikolov, T., Karafit, M., Burget, L., Cernocky, J., Khudanpur, S. 2010 Recurrent neural network based language model. 11th Annual Conference of the International Speech Communication Association, Sep, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Paek</author>
<author>R Pieraccini</author>
</authors>
<title>Automating spoken dialogue management design using machine learning: An industry perspective.</title>
<date>2008</date>
<journal>Speech communication,</journal>
<volume>50</volume>
<issue>8</issue>
<pages>716--729</pages>
<marker>Paek, Pieraccini, 2008</marker>
<rawString>Paek, T., Pieraccini, R. 2008. Automating spoken dialogue management design using machine learning: An industry perspective. Speech communication, 50(8), 716-729, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Tang</author>
<author>S Watanabe</author>
<author>T K Marks</author>
<author>J R Hershey</author>
</authors>
<title>Log-linear dialog manager.</title>
<date>2014</date>
<booktitle>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),</booktitle>
<marker>Tang, Watanabe, Marks, Hershey, 2014</marker>
<rawString>Hao Tang, Watanabe, S., Marks, T. K., Hershey, J. R. 2014. Log-linear dialog manager. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), May, 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Li</author>
<author>D McLean</author>
<author>Z A Bandar</author>
</authors>
<title>Sentence similarity based on semantic nets and corpus statistics.</title>
<date>2006</date>
<journal>Knowledge and Data Engineering, IEEE Transactions on,</journal>
<volume>18</volume>
<issue>8</issue>
<pages>1138--1150</pages>
<contexts>
<context position="7257" citStr="Li et al., 2006" startWordPosition="1153" endWordPosition="1156"> such as personality character (Ball et al., 2000). Text To Speech (TTS): This model transforms the selected sentence text into the output voice as a response (Zen et al., 2007). Fig. 3 is a human-machine dialogue example in online stage. 3 Sentence Clustering based on RNN In this section, we cluster the sentences for DM modeling, which might be different from general sentence clustering. Sentence similarity for clustering are calculated from two aspects. Firstly, it is calculated traditionally based on internal information such as words and sentence structures, which is widely researched in (Li et al., 2006) (Achananuparp et al., 2008). (Word embedding request (client quantity) DA1 Ă A1: I need to record the quantity of clients. B1: Perhaps 3 persons. Ă Ă Cluster 1 A2: please tell me the number of clients. B2: Is it necessary? A3: Yes, I need to record this. B3: OK, 3 persons, maybe. I have to know how many persons will live in. It is necessary to record the number of clients. ... DA1 Cluster 2 request (client quantity) Do you mind telling me the quantity of clients? Please let me know how many persons will live in. ... offline online user Dialogue Corpus voice voice text ASR TTS text Sentence Ma</context>
</contexts>
<marker>Li, McLean, Bandar, 2006</marker>
<rawString>Li Y, McLean D, Bandar Z A, et al. 2006. Sentence similarity based on semantic nets and corpus statistics. Knowledge and Data Engineering, IEEE Transactions on, 18(8), 1138-1150, 2006.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>