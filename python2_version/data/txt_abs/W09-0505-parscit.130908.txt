<newSection> Abstract We are interested in extracting semantic structures from spoken utterances generated within conversational systems.
Current Spoken Language Understanding systems rely either on hand-written semantic grammars or on flat attribute-value sequence labeling.
While the former approach is known to be limited in coverage and robustness, the latter lacks detailed relations amongst attribute-value pairs.
In this paper, we describe and analyze the human annotation process of rich semantic structures in order to train semantic statistical parsers.
We have annotated spoken conversations from both a human-machine and a human-human spoken dialog corpus.
Given a sentence of the transcribed corpora, domain concepts and other linguistic features are annotated, ranging from e.g. part-of-speech tagging and constituent chunking, to more advanced annotations, such as syntactic, dialog act and predicate argument structure.
In particular, the two latter annotation layers appear to be promising for the design of complex dialog systems.
Statistics and mutual information estimates amongst such features are reported and compared across corpora.