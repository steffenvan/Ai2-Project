<newSection> 1 Introduction The growing availability of on-line text has led to an increase in the use of automatic knowledge acquisition approaches from textual data.
In fact, a number of Information Extraction (IE) systems has emerged in the past few years in relation to the MUC conferencesl.
The aim of an IE system consists in automatically extracting pieces of information from text, being this information relevant for a set of prescribed concepts (scenario).
One of the main drawbacks of applying IE systems is the high cost involved in manually adapting them to new domains and text styles.
In recent years, a variety of Machine Learning (ML) techniques has been used to improve the portability of IE systems to new domains, as in SRV (Freitag, 1998), RAPIER (Calif and Mooney, 1997), LIEP (Huffman, 1996), CRYSTAL (Soderland et al., 1995) and WHISK (Soderland, 1999) . However, some drawbacks remain in the portability of these systems: a) existing systems generally depend on the supported text style and learn IE-rules either for structured texts, semi-structured texts or free text , b) IE systems are mostly single-concept learning systems, c) consequently, an extractor (e.g., a rule set) is learned for each concept within the scenario in an independent manner, d) the order of execution of the learners is set manually, and so are the scheduling and way of combination of the resulting extractors, and e) focusing on the training data, the size of available training corpora can be inadequate to accurately learn extractors for all the concepts within the scenario2.
This paper describes EVIUS, a multi-concept learning system for free text that follows a multi-strategy constructive learning approach (MCL) (Michalshi, 1993) and supports insufficient amounts of training corpora.
EVIUS is a component of a multilingual IE system, M-TURBIO (Turmo et al., 1999).
The input of EVIUS is both a partially-parsed semantically-tagged3 training corpus and a description of the desired target structure.
This description is provided as a set of concepts C related to a set of asymmetric binary relations, TZ.
In order to learn set S of IE rule sets for the whole C, EVIUS uses an MCL approach integrating constructive learning, closed-loop learning and deductive restructuring (Ko, 1998).
In this multi-concept situation, the system determines which concepts to learn and, later, incrementally updates S.
This can be relatively straightforward when using knowledge about the target structure in a closed-loop learning approach.
Starting with C, EVIUS reduces set U of unlearned concepts iteratively by selecting subset P C U formed by the primitive concepts in U and learning a rule set for each c E P 4.
For instance, the single colour scenario5 in figure 1 is provided to learn from instances of the following three related concepts: colour, such as in instance &quot;azul ligeramente claro&quot; (slightly pale blue), colour_interval, as in &quot;entre rosa y rojo sangre&quot; (between pink and blood red), and to_change, as in &quot;rojo vira a marron&quot; (red changes to brown).
Initially, U = C ={colour, colour_interval, to_change}.
Then, EVIUS calculates P ={colour} and once a rule set has been learned for colour, the new 14 .{colour_interval, to_change} is studied identifying P = U.
In order to learn a rule set for a concept, EVIUS uses the relational learning method explained in section 3, and defines the learning space by means of a dynamic predicate model.
As a pre-process of the system, the training corpus is translated into predicates using the following initial predicate model: a) attributive meta-predicates: pos_X(A), isa_X (A), has_hypernym_X (A), word_X (A) and lemma_X(A), where Xis instantiated with closed categories, b) relational meta-predicates: distance_le_X(A,B), stating that there are X terminal nodes, at most, between A and B, and c) relational predicates: ancestor(A,B), where B is the syntactic ancestor of A, and brother(A,B), where B is the right brother node of A sharing the syntactic ancestor.
Once a rule set for concept c is learned, new examples are added for further learning by means of a deductive restructuring approach: training examples are reduced to generate a more compact and useful knowledge of the learned concept.
This is achieved by using the induced rule set and a syntactico-semantic transformational grammar.
Further to all this, a new predicate isa_c is added to the model.
For instance, in figure 26, the Spanish sentence &quot;su color rojo vira a marron oscuro&quot; (its red colour changes to dark brown) has two examples of colour, n3 and n6+n7, being these &quot;rojo&quot; (red) and &quot;marrOn&quot;+&quot;oscuro&quot; (dark brown).
No reduction is required by the former.
However, the latter example is reduced to node n6'.
As a consequence, two new attributes are added to the model: isa_colour(n3) and isa_colour(n6').
This new knowledge will be used to learn the concepts to_change and colour_interval.