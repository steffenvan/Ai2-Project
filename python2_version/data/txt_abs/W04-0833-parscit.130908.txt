<newSection> Abstract In this paper, we describe our experiments on statistical word sense disambiguation (WSD) using two systems based on different approaches: Naive Bayes on word tokens and Maximum Entropy on local syntactic and semantic features.
In the first approach, we consider a context window and a sub-window within it around the word to disambiguate.
Within the outside window, only content words are considered, but within the sub-window, all words are taken into account.
Both window sizes are tuned by the system for each word to disambiguate and accuracies of 75% and 67% were respectively obtained for coarse and fine grained evaluations.
In the second system, sense resolution is done using an approximate syntactic structure as well as semantics of neighboring nouns as features to a Maximum Entropy learner.
Accuracies of 70% and 63% were obtained for coarse and fine grained evaluations.