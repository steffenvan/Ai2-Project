<newSection> 1 Introduction Spoken language dialogue systems and embodied conversational agents are being introduced in a rapidly increasing number of Human-Computer Interaction (HCI) applications.
The technologies involved in SLDSs (speech recognition, dialogue design, etc.) are mature enough to allow the creation of trustworthy applications.
However, robustness problems still arise in concrete limited dialogue systems because there are many error sources that may cause the system to perform poorly.
A common example is that users tend to repeat their previous utterance with some frustration when error recovery mechanisms come into play, which does not help the recognition process, and as a result using the system seems slow and unnatural (Boyce, 1999).
At the same time, embodied conversational agents (ECAs) are gaining prominence in HCI systems, since they make for more user-friendly applications while increasing communication effectiveness.
There are many studies on the effects — from psychological to efficiency in goal achievement— ECAs have on users of a variety of applications, see Bickmore et al.
(2004) and Brave et al.
(2005), but still very few (Bell and Gustafson, 2003) on the impact of ECAs in directed dialogue situations where robustness is a problem.
Our research explores the potential of ECAs to assist in, or resolve, certain difficult dialogue situations that have been identified by various leading authors in the field (Cassell and Thorisson, 1999; Cassell and Stone, 1999), as well as a few we