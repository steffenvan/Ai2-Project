<newSection> Abstract This paper describes our submission to the WMT10 Shared Evaluation Task and MetricsMATR10.
We present a version of the METEOR-NEXT metric with paraphrase tables for five target languages.
We describe the creation of these paraphrase tables and conduct a tuning experiment that demonstrates consistent improvement across all languages over baseline versions of the metric without paraphrase resources.