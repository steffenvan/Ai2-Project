<newSection> Abstract The next generation internet applications will feature not only the ability to understand spoken and written natural language text, (pen) gestures and body postures, they will also and importantly be able to engage with the user in a natural dialogue about the application.
In this paper we will describe the design of a multimodal dialogue and action management module, part of the COMIC demonstrator, which is aimed at these next generation applications.
The design uses well understood structures like stacks and augmented transition networks in a novel way to obtain the flexibility needed for mixed-initiative dialogue.
We also show how this is applied to the application of the COMIC demonstrator - bathroom design.