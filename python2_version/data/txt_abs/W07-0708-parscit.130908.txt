<newSection> Abstract In order to simultaneously translate speech into multiple languages an extension of stochastic finite-state transducers is proposed.
In this approach the speech translation model consists of a single network where acoustic models (in the input) and the multilingual model (in the output) are embedded.
The multi-target model has been evaluated in a practical situation, and the results have been compared with those obtained using several mono-target models.
Experimental results show that the multi-target one requires less amount of memory.
In addition, a single decoding is enough to get the speech translated into multiple languages.