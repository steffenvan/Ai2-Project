<newSection> COMPOSE-REDUCE PARSING achieve linear (indeed real-time) complexity by performing a constant-time step per word of the input.
The other took as its starting point tabular parsing (Earley, C KY), and sought to achieve linear complexity by performing a constant-time step for the identification/construction of constituents of each length from 0 to n.
The latter route has been widely canvassed, although to our knowledge has not yet been implemented—see (Nijholt 1989, 90) for extensive references.
The former route, whereby real-time parsing is achieved by processor forking at non-deterministic choice points in an extended shift-reduce parser, is to our knowledge new.
In this paper we present outlines of two such parsers, which we call compose-reduce parsers.
L COMPOSE-REDUCE PARSING Why couldn't a simple breadth-first chart parser achieve linear performance on an appropriate parallel system?
If you provided enough processors to immediately process all agenda entries as they were created, would not this give the desired result?
No, because the processing of a single word might require many serialised ABSTRACT Two new parsing algorithms for context-free phrase structure grammars are presented which perform a bounded amount of processing per word per analysis path, independently of sentence length.
They are thus capable of parsing in real-time in a parallel implementation which forks processors in response to non-deterministic choice points.
0. INTRODUCTION The work reported here grew out of our attempt to improve on the 0 (n2) performance of the SIMD parallel parser described in (Thompson 1991).
Rather than start with a commitment to a specific SIMD architecture, as that work had, we agreed that the best place to start was with a more abstract architecture-independent consideration of the CF-PSG parsing problem— given arbitrary resources, what algorithms could one envisage which could recognise and/or parse atomic category phrase-structure grammars in c) (n) ? In the end, two quite different approaches emerged.
One took as its starting point non-deterministic shift-reduce parsing, and sought to steps.
Consider processing the word &quot;park&quot; in the sentence &quot;The people who ran in the park got wet.&quot; Given a simple traditional sort of grammar, that word completes an NP, which in turn completes a P r, which in turn completes a VP , which in turn completes an s, which in turn completes a RE L, which in turn completes an NP.
The construction/recognition of these constituents is necessarily serialised, so regardless of the number of processors available a constant-time step is impossible.
(Note that this only precludes a real-time parse by this route, but not necessarily a linear one.)
In the shift-reduce approach to parsing, all this means is that for non-linear grammars, a single shift step may be followed by many reduce steps.
This in turn suggested the beginnings of a way out, based on categorial grammar, namely that multiple reduces can be avoided if composition is allowed.
To return to our example above, in a simple shift-reduce parser we would have had all the words preceding the word &quot;park&quot; in the stack.
When it was shifted in, there would follow six reduce steps.
If alternatively following a shift step one was allowed (non-deterministically) a compose step, this could be reduced (!) to a single reduce step.
Restricting ourselves to a simpler example, consider just &quot;run in the park&quot; as a VP, given rules With a composition step allowed, the parse would then proceed as follows: Shift run as a v Shift in as a p Compose v and p to give [vp v [PP p • NP]] where I use a combination of bracketed strings and the 'dotted rule' notation to indicate the result of composition.
The categorial equivalent would have been to notate v as VP / PP,P as PP /NP, and the result of the composition as therefore VP /NP.
[vp V [PP p [NE, d • nil] Reduce the dotted VP with n to give the complete result.
Although a number of details remained to be worked out, this simple move of allowing composition was the enabling step to achieving 0 (n) parsing.
Parallelism would arise by forking processors at each non-deterministic choice point, following the general model of Dixon's earlier work on parallelising the ATMS (Dixon & de Kleer 1988).
Simply allowing composition is not in itself sufficient to achieve o (n) performance.
Some means of guaranteeing that each step is constant time must still be provided.
Here we found two different ways forward.