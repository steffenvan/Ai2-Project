ment classification using abstracts and titles is compared with full-text classification.
In most cases, abstracts and titles show comparable performance to full-text.
Corpus We built a corpus around our interest in gene associations with breast cancer to leverage the domain expertise of the authors.
The corpus consisted of 247 sampled from 2571 papers associating breast cancer with a human gene in EntrezGene.
Manual Annotation Manual annotation was primarily performed by a graduate student in bioinformatics and a computer science Ph.D. with a research emphasis in bioinformatics.
Annotators were instructed to highlight direct mentions of experimental techniques.
During the study, we noted low interannotator agreement and stopped the manual process after annotating 102 of 247 documents.
Results were analyzed for linguistic characteristics.
Experimental technique mentions appear with varying frequency in 6 typical document sections: Title, Abstract, Introduction, Materials and Methods, Results and Discussion.
In some sections, such as Introduction, mentions are often for references and not the current document.
Techniques such as transfection and immunoblotting, demonstrated diverse morphology.
Other characteristics included use of synonyms and abbreviations, conjunctive phrases, and endophora.
Tagging Tagging is commonly used for named entity recognition.
In our context, associations are categorized by generating a list of all tagged techniques tagged in a document.
Two taggers were tested on 247 documents to investigate the efficacy of two lexicons — MeSH and UMLS — containing experimental techniques.
One approach used regular expressions for terms and permuted terms in the Investigative Techniques MeSH subhierarchy.
The other used a natural language approach based on MetaMap Transfer (Aronson, 2001), mapping text to UMLS entries with the Laboratory Procedure semantic type (ID: T059).
Low inter-annotator agreement between taggers was exhibited with a maximum n of 0.220.
Both taggers exhibited limitations — failing to properly tag phrases such as “Northern and Western analyses” — and neither one is clearly superior to the other.
tion was also used to obtain a list of utilized experimental techniques.
Each article is assigned to one or more classes corresponding to techniques used to generate results.
Two distinct questions were investigated.
First, how well does classification perform if only the abstract and title of the article are available?
Second, how does vocabulary size affect the classification?
Multinomial Naive Bayes models were implemented in Rainbow (McCallum, 1996; McCallum and Nigam, 1998) for 24 MeSH experimental techniques.
Document frequency in each class ranged from 10 (Pedigree) to 144 (Electrophoresis).
Vocabularies consist of top information gain ranked words.
Classifiers were evaluated by precision, recall, and F1-scores averaged over 100 runs.
The corpus was split into 2/3 training and 1/3 testing, randomly chosen for each run.
Selected results are shown in Table 1.
Full-text classifiers performed better than abstract based classifiers with a few exceptions: “Sequence Alignment” and “Gene Transfer Techniques”.
The performance of abstract and full-text classifiers is comparable: F1 scores often differ by less than 5 points.
Smaller vocabularies tend to improve the recall and overall F1 scores, while larger ones improved precision.
Classifiers for low frequency (< 25) techniques generally performed poorly.
One class, “Pedigree”, performed surprisingly well, with a maximum F1 of 76.6.
Considering that Naive Bayes models are often baseline models and the small size of the corpus, classification performance is good.
Related and Future Work For comprehensive reviews of current work in biomedical literature mining, refer to (Cohen and Hersh, 2005) and (Krallinger et al., 2005).
As future work, we will continue manual annotation, validate the informative capacity of sections with experiments similar to Sinclair and Webber (Sinclair and Webber, 2004), and investigate improvements in tagging and classification.