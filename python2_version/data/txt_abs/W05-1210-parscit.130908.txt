<newSection> Abstract In this paper we define two intermediate models of textual entailment, which correspond to lexical and lexical-syntactic levels of representation.
We manually annotated a sample from the RTE dataset according to each model, compared the outcome for the two models, and explored how well they approximate the notion of entailment.
We show that the lexical-syntactic model outperforms the lexical model, mainly due to a much lower rate of false-positives, but both models fail to achieve high recall.
Our analysis also shows that paraphrases stand out as a dominant contributor to the entailment task.
We suggest that our models and annotation methods can serve as an evaluation scheme for entailment at these levels.