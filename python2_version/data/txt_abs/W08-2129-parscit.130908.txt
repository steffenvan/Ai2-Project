<newSection> Abstract We present a puristic approach for combining dependency parsing and semantic role labeling.
In a first step, a data-driven strict incremental deterministic parser is used to compute a single syntactic dependency structure using a MEM trained on the syntactic part of the CoNLL 2008 training corpus.
In a second step, a cascade of MEMs is used to identify predicates, and, for each found predicate, to identify its arguments and their types.
All the MEMs used here are trained only with labeled data from the CoNLL 2008 corpus.
We participated in the closed challenge, and obtained a labeled macro F1 for WSJ+Brown of 19.93 (20.13 on WSJ only, 18.14 on Brown).
For the syntactic dependencies we got similar bad results (WSJ+Brown=16.25, WSJ= 16.22, Brown=16.47), as well as for the semantic dependencies (WSJ+Brown=22.36, WSJ=22.86, Brown=17.94).
The current results of the experiments suggest that our risky puristic approach of following a strict incremental parsing approach together with the closed data-driven perspective of a joined syntactic and semantic labeling was actually too optimistic and eventually too puristic.
The CoNLL 2008 shared task on joint parsing of syntactic and semantic dependencies (cf. Surdeanu, 2008) offered to us an opportunity to initiate, implement and test new ideas on large-scale data-driven incremental dependency parsing.
The topic and papers of the ACL-2004 workshop “Incremental Parsing: Bringing Engineering and Cognition Together” (accessible at http://aclweb.org/anthology-new/W/W04/#0300) present a good recent overview into the field of incremental processing from both an engineering and cognitive point of view.
Our particular interest is the exploration and development of strict incremental deterministic strategies as a means for fast data-driven dependency parsing of large-scale online natural language processing.
By strict incremental processing we mean, that the parser receives a stream of words w1 to wn word by word in left to right order, and that the parser only has information about the current word wi, and the previous words w1 to wi-1.1 By deterministic processing we mean that the parser has to decide immediately and uniquely whether and how to integrate the newly observed word wi with the already constructed (partial) dependency structure without the possibility of revising its decision at later stages.
The strategy is data-driven in the sense that the parsing decisions are made on basis of a statistical language model, which is trained on the syntactic part of the CoNLL 2008 training corpus.
The whole parsing strategy is based on Nivre (2007), but modifies it in several ways, see sec.
2 for details.
Note that there are other approaches of incremental deterministic dependency parsing that assume that the complete input string of a sentence is already given before parsing starts and that this additional right contextual information is also used as a feature source for language modeling, e.g., Nivre (2007).
In light of the CoNLL 2008 shared task, this actually means that, e.g., part-of-speech tagging and lemmatization has already been performed for the complete sentence before incremental parsing starts, so that this richer source of information is available for defining the feature space.
Since, important word-based information especially for a dependency analysis is already known for the whole sentence before parsing starts, and actually heavily used during parsing, one might wonder, what the benefit of such a weak incremental parsing approach is compared to a non-incremental approach.
Since, we thought that such an incremental processing perspective is a bit too wide (especially when considering the rich input of the CoNLL 2008 shared task), we wanted to explore a strict incremental strategy.
Semantic role labeling is considered as a postprocess that is applied on the output of the syntactic parser.
Following Hacioglu (2004), we consider the labeling of semantic roles as a classification problem of dependency relations into one of several semantic roles.
However, instead of post-processing a dependency tree firstly into a sequence of relations, as done by Hacioglu (2004), we apply a cascade of statistical models on the unmodified dependency tree in order to identify predicates, and, for each found predicate, to identify its arguments and their types.
All the language models used here are trained only with labeled data from the CoNLL 2008 corpus; cf. sec.
3 for more details.
Both, the syntactic parser and the semantic classifier are language independent in the sense that only information contained in the given training corpus is used (e.g., PoS tags, dependency labels, information about direction etc.), but no language specific features, e.g., no PropBank frames nor any other external language and knowledge specific sources.
The complete system has been designed and implemented from scratch after the announcement of the CoNLL 2008 shared task.
The main goal of our participation was therefore actually on being able to create some initial software implementation and baseline experimentations as a starting point for further research in the area of data-driven incremental deterministic parsing.
In the rest of this brief report, we will describe some more details of the syntactic and semantic component in the next two sections, followed by a description and discussion of the achieved results.