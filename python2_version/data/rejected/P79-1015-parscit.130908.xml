<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.658306">
<note confidence="0.92016275">
DISCOURSE: CODES AND CLUES IN CONTEXTS
Jane J. Robinson
Artificial Intelligence Center
SRI International, Menlo Park, California
</note>
<bodyText confidence="0.998698474137931">
Some of the meaning of a discourse is encoded in its
linguistic forms. This is the truth-conditional meaning
of the propositions those forms express and entail. Some
of the meaning is suggested (or &apos;implicated&apos;, as Grice
would sty) by the fact that the encoder expresses just
those propositions in just those linguistic forms in just
the given contexts [2]. The first kind of meaning is
usually labeled &apos;semantics&apos;; it is decoded. The second
is usually labeled &apos;pragmatics&apos;; it is inferred from
clues provided by code and context. Both kinds of
meaning are related to syntax in ways that we are coming
to understand better as work continues in analyzing
language and constructing processing models for
communication. We are also coming to a better
understanding of the relationship between the perceptual
and conceptual structures that organize human experience
and make it encodable in words. (Cf. [1], [4].)
I see this progress in understanding not as the result
of a revolution in the paradigm of computational
linguistics in which one approach to natural language
processing is abandoned for another, but rather as an
expansion of our ideas of what both language and
computers can do. We have been able to incorporate what
we learned earlier in the game in a broader approach to
more significant tasks.
Certainly within the last twenty years, the disoipline
of computational linguistics has expanded its view of its
object of concern. Twenty years ago, that view was
focussed on a central aspect of language, language as
code [3]. The paradigmatic task of our discipline then
was to transform a message encoded in one language into
the same message encoded in another, using dictionaries
and syntactic rules. (Originally, the task was not to
translate but to transform the input as an aid to human
translators.)
Coincidentally, those were the days of batch
processing and the typical inputs were scientific texts
-- written monologues that existed as completed, static
discourses before processing began. Then came
interactive processing, bringing with it the opportunity
for what is now called &apos;dialogue&apos; between user and
machine. At the same time, and perhaps not wholly
coincidentally, another aspect of language became salient
for computational linguistics -- the aspect of language
as behavior, with two or more people using the code to
engage in purposeful 4 communication. The inputs now
include discourse in which the amount of code to be
interpreted continues to grow as participants in dialogue
interact, and their interactions become part of the
contexts for on-going, dynamic interpretation.
The paradigmatic task now is to simulate in non-
trivial ways the procedures by which people reach
conclusions about what is in each other&apos;s minds.
Performing this task still requires processing language
as code, but it also requires analyzing the code in a
context, to identify clues to the pragmatic meaning of
its use. One way of representing this enlarged task to
conceive of it as requiring three concentric kinds of
knowledge:
intralinguistic knowledge, or knowledge of the
code
interlinguistic knowledge, or knowledge of
linguistic behavior
extralinguistio knowledge, or knowledge of the
perceptual and conceptual structures that
language users have, the things they attend to
and the goals they pursue
The papers we will hear today range over techniques
for identifying, representing and applying the various
kinds of knowledge for the processing of discourse.
McKeown exploits intralinguistic knowledge for
extralinguistic purposes. When the goal of a request for
new information is not uniquely identifiable, she
proposes to use syntactic transformations of the code of
the request to clarify its ambiguities and ensure that
its goal is subsequently understood. Shanon is also
concerned with appropriateness of answers, and reports an
investigation of the extralinguistic conceptual
structuring of space that affects the pragmatic rules
people follow in furnishing appropriate information in
response to questions about where things are.
Sidner identifies various kinds of intralinguistic
clues a discourse provides that indicate what entities
occupy the focus of attention of discourse paticipants as
discourse proceeds, and the use of focusing (an
extralinguistic process) to control the inferences made
in identifying the referents of pronominal anaphora.
Levin and Hutchinson analyze the clues in reports of
spatial reasoning that lead to identification of the
point of view of the speaker towards the entities talked
about. Like Sidner, they use syntactic clues and like
Shanon, they seek to identify the conceptual structures
that underlie behavior.
Code and behavior interact with intentions in ways
that are still mysterious but clearly important. The
last two papers stress the fact that using language is
intentional behavior and that understanding the purposes
a discourse serves is a necessary part of understanding
the discourse itself. Mann claims that dialogues are
comprehensible only because participants provide clues to
each other that make available knowledge of the goals
being pursued. Allen and Perrault note that intention
pervades all three layers of discourse, pointing out
that, in order to be successful, a speaker must intend
that the hearer recognize his intentions and infer his
goals, but that these intentions are not signaled in any
simple way in the code.
In all of these papers, language is viewed as
providing both codes for and clues to meaning, so that
when it is used in discourse, its forms can be decoded
and their import can be grasped. As language users, we
know that we can know, to a surprising extent, what
someone else means for us to know. We also sometimes
know that we don&apos;t know what someone else means for us to
know. As computational linguists, we are &apos;rying to
figure out precisely how we know such things.
</bodyText>
<sectionHeader confidence="0.998871" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999922571428572">
[1] Chafe, W.L. 1977. Creativity in Verbalization
and Its Implications for the Nature of Stored Knowledge.
In: Freedle, R.O. (ed)., &lt;&lt;Discourse Production and
Comprehension&gt;, Vol. 1, pp. 41-55. Ablex: Norwood, New
Jersey.
[2] Grioe, P.H. 1975. Logic and Conversation. In:
Davidson, D. and Harman, G. (eds.), &lt;&lt;The Logic of
Grammar&gt;. Dickenson: Encino, California
[3] Halliday, M.A.K., 1977. Language as Code and
Language as Behaviour. In: Lamb, S. and Makkai, A.
(eds.), &lt;&lt;Semiotics of Culture and Language&gt;.
[4] Miller, G.A. and Johnson-Laird, P.N. 1976.
&lt;&lt;Language and Perception&gt;. Harvard University Press:
Cambridge, Massachusetts
</reference>
<page confidence="0.999616">
65
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.123262">
<title confidence="0.999019">DISCOURSE: CODES AND CLUES IN CONTEXTS</title>
<author confidence="0.999998">Jane J Robinson</author>
<affiliation confidence="0.999221">Artificial Intelligence Center</affiliation>
<address confidence="0.610971">SRI International, Menlo Park, California</address>
<abstract confidence="0.989247025210084">Some of the meaning of a discourse is encoded in its linguistic forms. This is the truth-conditional meaning of the propositions those forms express and entail. Some of the meaning is suggested (or &apos;implicated&apos;, as Grice would sty) by the fact that the encoder expresses just those propositions in just those linguistic forms in just the given contexts [2]. The first kind of meaning is usually labeled &apos;semantics&apos;; it is decoded. The second is usually labeled &apos;pragmatics&apos;; it is inferred from clues provided by code and context. Both kinds of meaning are related to syntax in ways that we are coming to understand better as work continues in analyzing language and constructing processing models for communication. We are also coming to a better understanding of the relationship between the perceptual and conceptual structures that organize human experience and make it encodable in words. (Cf. [1], [4].) I see this progress in understanding not as the result of a revolution in the paradigm of computational linguistics in which one approach to natural language processing is abandoned for another, but rather as an expansion of our ideas of what both language and computers can do. We have been able to incorporate what we learned earlier in the game in a broader approach to more significant tasks. Certainly within the last twenty years, the disoipline of computational linguistics has expanded its view of its object of concern. Twenty years ago, that view was focussed on a central aspect of language, language as code [3]. The paradigmatic task of our discipline then was to transform a message encoded in one language into the same message encoded in another, using dictionaries and syntactic rules. (Originally, the task was not to translate but to transform the input as an aid to human translators.) those days of batch processing and the typical inputs were scientific texts -written monologues that existed as completed, static discourses before processing began. Then came interactive processing, bringing with it the opportunity for what is now called &apos;dialogue&apos; between user and machine. At the same time, and perhaps not wholly coincidentally, another aspect of language became salient for computational linguistics -the aspect of language as behavior, with two or more people using the code to in purposeful 4communication. The inputs now include discourse in which the amount of code to be interpreted continues to grow as participants in dialogue interact, and their interactions become part of the contexts for on-going, dynamic interpretation. The paradigmatic task now is to simulate in nontrivial ways the procedures by which people reach conclusions about what is in each other&apos;s minds. Performing this task still requires processing language code, but it also requires analyzing the code context, to identify clues to the pragmatic meaning of its use. One way of representing this enlarged task to conceive of it as requiring three concentric kinds of knowledge: intralinguistic knowledge, or knowledge of the code interlinguistic knowledge, or knowledge of linguistic behavior extralinguistio knowledge, or knowledge of the perceptual and conceptual structures that language users have, the things they attend to and the goals they pursue The papers we will hear today range over techniques for identifying, representing and applying the various kinds of knowledge for the processing of discourse. McKeown exploits intralinguistic knowledge for purposes. When of a request for new information is not uniquely identifiable, she proposes to use syntactic transformations of the code of the request to clarify its ambiguities and ensure that its goal is subsequently understood. Shanon is also concerned with appropriateness of answers, and reports an investigation of the extralinguistic conceptual structuring of space that affects the pragmatic rules people follow in furnishing appropriate information in response to questions about where things are. Sidner identifies various kinds of intralinguistic clues a discourse provides that indicate what entities occupy the focus of attention of discourse paticipants as discourse proceeds, and the use of focusing (an extralinguistic process) to control the inferences made identifying of pronominal anaphora. Levin and Hutchinson analyze the clues in reports of spatial reasoning that lead to identification of the point of view of the speaker towards the entities talked about. Like Sidner, they use syntactic clues and like Shanon, they seek to identify the conceptual structures that underlie behavior. Code and behavior interact with intentions in ways that are still mysterious but clearly important. The last two papers stress the fact that using language is intentional behavior and that understanding the purposes a discourse serves is a necessary part of understanding the discourse itself. Mann claims that dialogues are comprehensible only because participants provide clues to each other that make available knowledge of the goals being pursued. Allen and Perrault note that intention pervades all three layers of discourse, pointing out that, in order to be successful, a speaker must intend the hearer recognize his intentions and infer goals, but that these intentions are not signaled in any simple way in the code. In all of these papers, language is viewed as providing both codes for and clues to meaning, so that it in discourse, its forms can be decoded and their import can be grasped. As language users, we know that we can know, to a surprising extent, what someone else means for us to know. We also sometimes know that we don&apos;t know what someone else means for us to know. As computational linguists, we are &apos;rying to figure out precisely how we know such things. REFERENCES [1] Chafe, W.L. 1977. Creativity in Verbalization and Its Implications for the Nature of Stored Knowledge.</abstract>
<note confidence="0.910911384615385">In: Freedle, R.O. (ed)., &lt;&lt;Discourse Production and Comprehension&gt;, Vol. 1, pp. 41-55. Ablex: Norwood, New Jersey. [2] Grioe, P.H. 1975. Logic and Conversation. In: D. and Harman, G. (eds.), &lt;&lt;The Logic of Grammar&gt;. Dickenson: Encino, California Halliday, 1977. Language as Code and Language as Behaviour. In: Lamb, S. and Makkai, A. (eds.), &lt;&lt;Semiotics of Culture and Language&gt;. [4] Miller, G.A. and Johnson-Laird, P.N. 1976. &lt;&lt;Language and Perception&gt;. Harvard University Press: Cambridge, Massachusetts 65</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>W L Chafe</author>
</authors>
<title>Creativity in Verbalization and Its Implications for the Nature of Stored Knowledge.</title>
<date>1977</date>
<booktitle>Discourse Production and Comprehension&gt;,</booktitle>
<volume>1</volume>
<pages>41--55</pages>
<editor>(ed).,</editor>
<location>In: Freedle, R.O.</location>
<contexts>
<context position="1031" citStr="[1]" startWordPosition="161" endWordPosition="161">ust those linguistic forms in just the given contexts [2]. The first kind of meaning is usually labeled &apos;semantics&apos;; it is decoded. The second is usually labeled &apos;pragmatics&apos;; it is inferred from clues provided by code and context. Both kinds of meaning are related to syntax in ways that we are coming to understand better as work continues in analyzing language and constructing processing models for communication. We are also coming to a better understanding of the relationship between the perceptual and conceptual structures that organize human experience and make it encodable in words. (Cf. [1], [4].) I see this progress in understanding not as the result of a revolution in the paradigm of computational linguistics in which one approach to natural language processing is abandoned for another, but rather as an expansion of our ideas of what both language and computers can do. We have been able to incorporate what we learned earlier in the game in a broader approach to more significant tasks. Certainly within the last twenty years, the disoipline of computational linguistics has expanded its view of its object of concern. Twenty years ago, that view was focussed on a central aspect of</context>
</contexts>
<marker>[1]</marker>
<rawString>Chafe, W.L. 1977. Creativity in Verbalization and Its Implications for the Nature of Stored Knowledge. In: Freedle, R.O. (ed)., &lt;&lt;Discourse Production and Comprehension&gt;, Vol. 1, pp. 41-55. Ablex: Norwood, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P H Grioe</author>
</authors>
<title>Logic and Conversation.</title>
<date>1975</date>
<booktitle>The Logic of Grammar&gt;.</booktitle>
<editor>In: Davidson, D. and Harman, G. (eds.),</editor>
<location>Dickenson: Encino, California</location>
<marker>[2]</marker>
<rawString>Grioe, P.H. 1975. Logic and Conversation. In: Davidson, D. and Harman, G. (eds.), &lt;&lt;The Logic of Grammar&gt;. Dickenson: Encino, California</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>Language as Code and Language as Behaviour.</title>
<date>1977</date>
<booktitle>Semiotics of Culture and Language&gt;.</booktitle>
<editor>In: Lamb, S. and Makkai, A. (eds.),</editor>
<contexts>
<context position="1662" citStr="[3]" startWordPosition="267" endWordPosition="267">in understanding not as the result of a revolution in the paradigm of computational linguistics in which one approach to natural language processing is abandoned for another, but rather as an expansion of our ideas of what both language and computers can do. We have been able to incorporate what we learned earlier in the game in a broader approach to more significant tasks. Certainly within the last twenty years, the disoipline of computational linguistics has expanded its view of its object of concern. Twenty years ago, that view was focussed on a central aspect of language, language as code [3]. The paradigmatic task of our discipline then was to transform a message encoded in one language into the same message encoded in another, using dictionaries and syntactic rules. (Originally, the task was not to translate but to transform the input as an aid to human translators.) Coincidentally, those were the days of batch processing and the typical inputs were scientific texts -- written monologues that existed as completed, static discourses before processing began. Then came interactive processing, bringing with it the opportunity for what is now called &apos;dialogue&apos; between user and machin</context>
</contexts>
<marker>[3]</marker>
<rawString>Halliday, M.A.K., 1977. Language as Code and Language as Behaviour. In: Lamb, S. and Makkai, A. (eds.), &lt;&lt;Semiotics of Culture and Language&gt;.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>P N Johnson-Laird</author>
</authors>
<title>Language and Perception&gt;.</title>
<date>1976</date>
<publisher>Harvard University Press:</publisher>
<location>Cambridge, Massachusetts</location>
<contexts>
<context position="1036" citStr="[4]" startWordPosition="162" endWordPosition="162">hose linguistic forms in just the given contexts [2]. The first kind of meaning is usually labeled &apos;semantics&apos;; it is decoded. The second is usually labeled &apos;pragmatics&apos;; it is inferred from clues provided by code and context. Both kinds of meaning are related to syntax in ways that we are coming to understand better as work continues in analyzing language and constructing processing models for communication. We are also coming to a better understanding of the relationship between the perceptual and conceptual structures that organize human experience and make it encodable in words. (Cf. [1], [4].) I see this progress in understanding not as the result of a revolution in the paradigm of computational linguistics in which one approach to natural language processing is abandoned for another, but rather as an expansion of our ideas of what both language and computers can do. We have been able to incorporate what we learned earlier in the game in a broader approach to more significant tasks. Certainly within the last twenty years, the disoipline of computational linguistics has expanded its view of its object of concern. Twenty years ago, that view was focussed on a central aspect of lang</context>
</contexts>
<marker>[4]</marker>
<rawString>Miller, G.A. and Johnson-Laird, P.N. 1976. &lt;&lt;Language and Perception&gt;. Harvard University Press: Cambridge, Massachusetts</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>