<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.408231">
<note confidence="0.599788">
From Strings to Trees to Strings to Trees • •
</note>
<title confidence="0.690794">
(Abstract)
</title>
<author confidence="0.902128">
Aravind K. Joshi
</author>
<affiliation confidence="0.997897">
Dept. of Computer and Information Science
University of Pennsylvania, Philadelphia PA 19104
</affiliation>
<bodyText confidence="0.999490526315789">
Sentences are not just strings of words (or are they
?), they have some (hierarchical) structure. This much
is accepted by all grammar formalisms. But how much
structure is needed? The more the sentences are like
strings the less the need for structure.
A certain amount of structure is necessary simply be-
cause a clause may embed another clause, or one clause
may attach to another clause or parts of it. Leav-
ing this need of structure aside, the question then is
how much structure should a (minimal) clause have?
Grammar formalisms can differ significantly on this is-
sue. Minimal clauses can be just strings, or words
linked by dependencies (dependency trees), or with rich
phrase structure trees, or with flat (one level) phrase
structure trees (almost strings) and so on. How much
hierarchical structure is needed for a minimal clause
is still an open question, that is being debated heat-
edly. How are clauses put together? Are these oper-
ations more like string manipulations (concatenation,
insertion, or wrapping, for example) or are they more
like tree transformations (generalized transformations
of the early transformational grammars, for example)?
Curiously, the early transformational grammars, al-
though clearly using tree transformations, actually for-
mulated the transformations as pseudo string-like op-
erations! More recent non-transformational grammars
differ significantly with respect to their use of string
rewriting or tree rewriting operations.
Grammar formalisms differ with respect to their
stringiness or treeness. Also during their evolution,
they have gone back and forth between string-like and
tree-like representations, often combining them in dif-
ferent ways. These swings are a reflection of the com-
plex interplay between aspects of language structure
such as constituency, dependency, dominance, locality
of predicates and their arguments, adjacency, order,
and discontinuity. We will discuss these issues in an in-
formal manner, in the context of a range of formalisms.
</bodyText>
<page confidence="0.998891">
33
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.392602">
<title confidence="0.656792">From Strings to Trees to Strings to Trees • • (Abstract)</title>
<author confidence="0.999367">Aravind K Joshi</author>
<affiliation confidence="0.999982">Dept. of Computer and Information Science</affiliation>
<address confidence="0.772244">University of Pennsylvania, Philadelphia PA 19104</address>
<abstract confidence="0.999213184210527">Sentences are not just strings of words (or are they ?), they have some (hierarchical) structure. This much is accepted by all grammar formalisms. But how much structure is needed? The more the sentences are like strings the less the need for structure. A certain amount of structure is necessary simply because a clause may embed another clause, or one clause may attach to another clause or parts of it. Leaving this need of structure aside, the question then is how much structure should a (minimal) clause have? Grammar formalisms can differ significantly on this issue. Minimal clauses can be just strings, or words linked by dependencies (dependency trees), or with rich phrase structure trees, or with flat (one level) phrase structure trees (almost strings) and so on. How much hierarchical structure is needed for a minimal clause is still an open question, that is being debated heatedly. How are clauses put together? Are these operations more like string manipulations (concatenation, insertion, or wrapping, for example) or are they more like tree transformations (generalized transformations of the early transformational grammars, for example)? Curiously, the early transformational grammars, although clearly using tree transformations, actually formulated the transformations as pseudo string-like operations! More recent non-transformational grammars differ significantly with respect to their use of string rewriting or tree rewriting operations. Grammar formalisms differ with respect to their stringiness or treeness. Also during their evolution, they have gone back and forth between string-like and tree-like representations, often combining them in different ways. These swings are a reflection of the complex interplay between aspects of language structure such as constituency, dependency, dominance, locality of predicates and their arguments, adjacency, order, and discontinuity. We will discuss these issues in an informal manner, in the context of a range of formalisms.</abstract>
<intro confidence="0.840128">33</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>