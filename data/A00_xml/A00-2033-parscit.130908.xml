<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002993">
<title confidence="0.971864">
Removing Left Recursion from Context-Free Grammars
</title>
<author confidence="0.987921">
Robert C. Moore
</author>
<affiliation confidence="0.961663">
Microsoft Research
</affiliation>
<address confidence="0.944193">
One Microsoft Way
Redmond, Washington 98052
</address>
<email confidence="0.998879">
bobmoore@microsoft.corn
</email>
<sectionHeader confidence="0.997382" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999803272727273">
A long-standing issue regarding algorithms that ma-
nipulate context-free grammars (CFGs) in a &amp;quot;top-
down&amp;quot; left-to-right fashion is that left recursion can
lead to nontermination. An algorithm is known
that transforms any CFG into an equivalent non-
left-recursive CFG, but the resulting grammars are
often too large for practical use. We present a new
method for removing left recursion from CFGs that
is both theoretically superior to the standard algo-
rithm, and produces very compact non-left-recursive
CFGs in practice.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995887015151516">
A long-standing issue regarding algorithms that ma-
nipulate context-free grammars (CFGs) in a &amp;quot;top-
down&amp;quot; left-to-right fashion is that left recursion can
lead to nontermination. This is most familiar in the
case of top-down recursive-descent parsing (Aho et
al., 1986, pp. 181-182). A more recent motivation
is that off-the-shelf speech recognition systems are
now available (e.g., from Nuance Communications
and Microsoft) that accept CFGs as language models
for constraining recognition; but as these recogniz-
ers process CFGs top-down, they also require that
the CFGs used be non-left-recursive.
The source of the problem can be seen by consid-
ering a directly left-recursive grammar production
such as A -4 Aa. Suppose we are trying to parse,
or recognize using a speech recognizer, an A at a
given position in the input. If we apply this pro-
duction top-down and left-to-right, our first subgoal
will be to parse or recognize an A at the same input
position. This immediately puts us into an infinite
recursion. The same thing will happen with an indi-
rectly left-recursive grammar, via a chain of subgoals
that will lead us from the goal of parsing or recogniz-
ing an A at a given position to a descendant subgoal
of parsing or recognizing an A at that position.
In theory, the restriction to non-left-recursive
CFGs puts no additional constraints on the lan-
guages that can be described, because any CFG
can in principle be transformed into an equivalent
non-left-recursive CFG. However, the standard algo-
rithm for carrying out this transformation (Aho et
al., 1986, pp. 176-178) (Hoperoft and Ullman, 1979,
p. 96)—attributed to M. C. Paull by Hoperoft and
Ullman (1979, p. 106)—can produce transformed
grammars that are orders of magnitude larger than
the original grammars. In this paper we develop a
number of improvements to Paull&apos;s algorithm, which
help somewhat but do not completely solve the prob-
lem. We then go on to develop an alternative ap-
proach based on the left-corner grammar transform,
which makes it possible to remove left recursion with
no significant increase in size for several grammars
for which Paull&apos;s original algorithm is impractical.
2 Notation and Terminology
Grammar nonterminals will be designated by &amp;quot;low
order&amp;quot; upper-case letters (A, B, etc.); and termi-
nals will be designated by lower-case letters. We
will use &amp;quot;high order&amp;quot; upper-case letters (X, Y, Z)
to denote single symbols that could be either ter-
minals or nonterminals, and Greek letters to denote
(possibly empty) sequences of terminals and/or non-
terminals. Any production of the form A –* a will
be said to be an A-production, and a will be said to
be an expansion of A.
We will say that a symbol X is a direct left corner
of a nonterminal A, if there is an A-production with
X as the left-most symbol on the right-hand side.
We define the left-corner relation to be the reflexive
transitive closure of the direct-left-corner relation,
and we define the proper-left-corner relation to be
the transitive closure of the direct-left-corner rela-
tion. A nonterminal is left recursive if it is a proper
left corner of itself; a nonterminal is directly left re-
cursive if it is a direct left corner of itself; and a
nonterminal is indirectly left recursive if it is left re-
cursive, but not directly left recursive.
</bodyText>
<sectionHeader confidence="0.85968" genericHeader="method">
3 Test Grammars
</sectionHeader>
<bodyText confidence="0.99734475">
We will test the algorithms considered here on three
large, independently-motivated, natural-language
grammars. The CT grammar&apos; was compiled into
a CFG from a task-specific unification grammar
</bodyText>
<affiliation confidence="0.58213">
iCourtesy of John Dowding, SRI International
</affiliation>
<page confidence="0.998104">
249
</page>
<table confidence="0.999710375">
Toy CT ATIS PT
Grammar Grammar Grammar Grammar
Grammar size 88 55,830 16,872 67,904
Terminals 40 1,032 357 47
Nonterminals 16 3,946 192 38
Productions 55 24,456 4,592 15,039
LR nonterminals 4 535 9 33
Productions for LR nonterminals 27 2,211 1,109 14,993
</table>
<tableCaption confidence="0.999975">
Table 1: Grammars used for evaluation.
</tableCaption>
<bodyText confidence="0.99990130952381">
written for CommandTalk (Moore et al., 1997), a
spoken-language interface to a military simulation
system. The ATIS grammar was extracted from an
internally generated treebank of the DARPA ATIS3
training sentences (Dahl et al., 1994). The PT gram-
mar&apos; was extracted from the Penn Treebank (Mar-
cus et al., 1993). To these grammars we add a small
&amp;quot;toy&amp;quot; grammar, simply because some of the algo-
rithms cannot be run to completion on any of the
&amp;quot;real&amp;quot; grammars within reasonable time and space
bounds.
Some statistics on the test grammars are con-
tained in Table 1. The criterion we use to judge
effectiveness of the algorithms under test is the size
of the resulting grammar, measured in terms of the
total number of terminal and nonterminal symbols
needed to express the productions of the grammar.
We use a slightly nonstandard metric, counting the
symbols as if, for each nonterminal, there were a
single production of the form A ai I • • • I an.
This reflects the size of files and data structures typ-
ically used to store grammars for top-down process-
ing more accurately than counting a separate occur-
rence of the left-hand side for each distinct right-
hand side.
It should be noted that the CT grammar has a
very special property: none of the 535 left recursive
nonterminals is indirectly left recursive. The gram-
mar was designed to have this property specifically
because Paull&apos;s algorithm does not handle indirect
left recursion well.
It should also be noted that none of these gram-
mars contains empty productions or cycles, which
can cause problems for algorithms for removing left
recursion. It is relatively easy to trasform an arbi-
trary CFG into an equivalent grammar which does
not contain any of the probelmatical cases. In its
initial form the PT grammar contained cycles, but
these were removed at a cost of increasing the size
of the grammar by 78 productions and 89 total sym-
bols. No empty productions or cycles existed any-
where else in the original grammars.
</bodyText>
<affiliation confidence="0.602146">
2Courtesy of Eugene Charniak, Brown University
</affiliation>
<sectionHeader confidence="0.996471" genericHeader="method">
4 Paull&apos;s Algorithm
</sectionHeader>
<bodyText confidence="0.990899205882353">
Paull&apos;s algorithm for eliminating left recursion from
CFGs attacks the problem by an iterative procedure
for transforming indirect left recursion into direct
left recursion, with a subprocedure for eliminating
direct left recursion. This algorithm is perhaps more
familiar to some as the first phase of the textbook
algorithm for transfomrming CFGs to Greibach nor-
mal form (Greibach, 1965).3 The subprocedure to
eliminate direct left recursion performs the following
transformation (Hoperoft and Ullman, 1979, p. 96):
Let
be the set of all directly left recursive A-
productions, and let
A -4 /31 I • • 0&apos;8
be the remaining A-productions. Replace
all these productions with
--+ ■31A&apos; I )38 I fl.A&apos;,
and
A&apos; -4 al I aiA&apos; j ... f
where A&apos; is a new nonterminal not used
elsewhere in the grammar.
This transformation is embedded in the full algo-
rithm (Aho et al., 1986, p. 177), displayed in Fig-
ure 1.
The idea of the algorithm is to eliminate left re-
cursion by transforming the grammar so that all the
direct left corners of each nonterminal strictly follow
that nonterminal in a fixed total ordering, in which
case, no nonterminal can be left recursive. This is
accomplished by iteratively replacing direct left cor-
ners that precede a given nonterminal with all their
expansions in terms of other nonterminals that are
greater in the ordering, until the nonterminal has
only itself and greater nonterminals as direct left
</bodyText>
<footnote confidence="0.910615">
3This has led some readers to attribute the algorithm to
Greibach, but Greibach&apos;s original method was quite different
and much more complicated.
</footnote>
<page confidence="0.991948">
250
</page>
<bodyText confidence="0.950900857142857">
Assign an ordering A1, , Ar, to the nonterminals of the grammar.
for i 1 to It do begin
for j 1 to i — 1 do begin
for each production of the form A, Aia do begin
remove Ai -4 Aict from the grammar
for each production of the form A3 -4 # do begin
add Ai -4 fia to the grammar
</bodyText>
<listItem confidence="0.9622728">
end
end
end
transform the Ai-productions to eliminate direct left recursion
end
</listItem>
<figureCaption confidence="0.997894">
Figure 1: Paull&apos;s algorithm.
</figureCaption>
<table confidence="0.8919762">
Grammar Description Grammar Size
original toy grammar 88
PA, &amp;quot;best&amp;quot; ordering 156
PA, lexicographical ordering 970
PA, &amp;quot;worst&amp;quot; ordering 5696
</table>
<tableCaption confidence="0.994185">
Table 2: Effect of nonterminal ordering on Paull&apos;s algorithm.
</tableCaption>
<bodyText confidence="0.997323236363637">
corners. Any direct left recursion for that nonter-
minal is then eliminated by the first transformation
discussed.
The difficulty with this approach is that the it-
erated substitutions can lead to an exponential in-
crease in the size of the grammar. Consider the
grammar consisting of the productions A1 0 I 1,
plus A,+1 A,0 Ail for 1 &lt;i &lt;n. It is easy to see
that Paull&apos;s algorithm will transform the grammar
so that it consists of all possible Ai-productions with
a binary sequence of length i on the right-hand side,
for 1 &lt; i &lt; n, which is exponentially larger than
the original grammar. Notice that the efficiency of
Paull&apos;s algorithm crucially depends on the ordering
of the nonterminals. If the ordering is reversed in
the grammar of this example, Paull&apos;s algorithm will
make no changes, since the grammar will already
satisfy the condition that all the direct left corners
of each nonterminal strictly follow that nonterminal
in the revised ordering. The textbook discussions of
Paull&apos;s algorithm, however, are silent on this issue.
In the inner loop of Paull&apos;s algorithm, for nonter-
minals A, and Ai, such that i &gt; j and A3 is a direct
left corner of A, we replace all occurrences of A3 as a
direct left corner of Ai with all possible expansions
of Ai. This only contributes to elimination of left
recursion from the grammar if A, is a left-recursive
nonterminal, and A3 lies on a path that makes A,
left recursive; that is, if Ai is a left corner of A3 (in
addition to A3 being a left corner of Ai). We could
eliminate replacements that are useless in removing
left recursion if we could order the nonterminals of
the grammar so that, if i &gt; j and Ai is a direct left
corner of Ai, then A, is also a left corner of A3. We
can achieve this by ordering the nonterminals in de-
creasing order of the number of distinct left corners
they have. Since the left-corner relation is transitive,
if C is a direct left corner of B, every left corner of
C is also a left corner of B. In addition, since we
defined the left-corner relation to be reflexive, B is a
left corner of itself. Hence, if C is a direct left corner
of B, it must follow B in decreasing order of number
of distinct left corners, unless B is a left corner of
C.
Table 2 shows the effect on Paull&apos;s algorithm of
ordering the nonterminals according to decreasing
number of distinct left corners, with respect to the
toy grammar.4 In the table, &amp;quot;best&amp;quot; means an or-
dering consistent with this constraint. Note that
if a grammar has indirect left recursion, there will
be multiple orderings consistent with our constraint,
since indirect left recursion creates cycles in the the
left-corner relation, so every nonterminal in one of
these cycles will have the same set of left corners.
Our &amp;quot;best&amp;quot; ordering is simply an arbitrarily chosen
</bodyText>
<footnote confidence="0.938169">
4As mentioned previously, grammar sizes are given in
terms of total terminal and nonterminal symbols needed to
express the grammar.
</footnote>
<page confidence="0.960164">
251
</page>
<table confidence="0.9998435">
CT Grammar ATIS Grammar PT Grammar
original grammar 55,830 16,872 67,904
PA 62,499 &gt; 5, 000, 000 &gt; 5, 000, 000
LF 54,991 11,582 37,811
LF+PA 59,797 2,004,473 &gt; 5,000, 000
LF+NLRG+PA 57,924 72,035 &gt; 5,000, 000
</table>
<tableCaption confidence="0.999881">
Table 3: Grammar size comparisons with Paull&apos;s algorithm variants
</tableCaption>
<bodyText confidence="0.992830741573034">
ordering respecting the constraint; we are unaware
of any method for finding a unique best ordering,
other than trying all the orderings respecting the
constraint.
As a neutral comparison, we also ran the algo-
rithm with the nonterminals ordered lexicographi-
cally. Finally, to test how bad the algorithm could
be with a really poor choice of nonterminal ordering,
we defined a &amp;quot;worst&amp;quot; ordering to be one with increas-
ing numbers of distinct left corners. It should be
noted that with either the lexicographical or worst
ordering, on all of our three large grammars Paull&apos;s
algorithm exceeded a cut-off of 5,000,000 grammar
symbols, which we chose as being well beyond what
might be considered a tolerable increase in the size
of the grammar.
Let PA refer to Paull&apos;s algorithm with the non-
terminals ordered according to decreasing number
of distinct left corners. The second line of Table 3
shows the results of running PA on our three large
grammars. The CT grammar increases only mod-
estly in size, because as previously noted, it has no
indirect left recursion. Thus the combinatorial phase
of Paull&apos;s algorithm is never invoked, and the in-
crease is solely due to the transformation applied to
directly left-recursive productions. With the ATIS
grammar and PT grammar, which do not have this
special property, Paull&apos;s algorithm exceeded our cut-
off, even with our best ordering of nonterminals.
Some additional optimizations of Paull&apos;s aglo-
rithm are possible. One way to reduce the num-
ber of substitutions made by the inner loop of the
algorithm is to &amp;quot;left factor&amp;quot; the grammar (Aho et
al., 1986, pp. 178-179). The left-factoring transfor-
mation (LF) applies the following grammar rewrite
schema repeatedly, until it is no longer applicable:
LF: For each nonterminal A, let a be the
longest nonempty sequence such that there
is more than one grammar production of
the form A —&gt; af3. Replace the set of all
productions
A ath , . . . , A
with the productions
A —± , A&apos; th, • • , A&apos; ---&gt;
where A&apos; is a new nonterminal symbol.
With left factoring, for each nonterminal A there will
be only one A-production for each direct left corner
of A, which will in general reduce the number of
substitutions performed by the algorithm.
The effect of left factoring by itself is shown in
the third line of Table 3. Left factoring actually re-
duces the size of all three grammars, which may be
unintuitive, since left factoring necessarily increases
the number of productions in the grammar. How-
ever, the transformed productions are shorter, and
the grammar size as measured by total number of
symbols can be smaller because common left factors
are represented only once.
The result of applying PA to the left-factored
grammars is shown in the fourth line of Table 3
(LF+PA). This produces a modest decrease in the
size of the non-left-recursive form of the CT gram-
mar, and brings the non-left-recursive form of the
ATIS grammar under the cut-off size, but the non-
left-recursive form of the PT grammar still exceeds
the cut-off.
The final optimization we have developed for
Paull&apos;s algorithm is to transform the grammar to
combine all the non-left-recursive possibilities for
each left-recursive nonterminal under a new nonter-
minal symbol. This transformation, which we might
call &amp;quot;non-left-recursion grouping&amp;quot; (NLRG), can be
defined as follows:
NLRG: For each left-recursive nontermi-
nal A, let cu,.., an be all the expansions
of A that do not have a left recursive non-
terminal as the left most symbol. If n&gt; 1,
replace the set of productions
A al, , A
with the productions
A -4 A&apos;, A&apos; -4 al, . • • , -4 an,
where A&apos; is a new nonterminal symbol.
Since all the new nonterminals introduced by this
transformation will be non-left-recursive, Paull&apos;s al-
gorithm with our best ordering will never substitute
the expansions of any of these new nonterminals into
the productions for any other nonterminal, which
in general reduces the number of substitutions the
algorithm makes. We did not empirically measure
</bodyText>
<page confidence="0.994082">
252
</page>
<table confidence="0.9997725">
CT Grammar ATIS Grammar PT Grammar
original grammar 55,830 16,872 67,904
LF 54,991 11,582 37,811
LF+NLRG+PA 57,924 72,035 &gt; 5, 000, 000
LC 762,576 287,649 1,567,162
LC.Ln 60,556 40,660 1,498,112
LF+LCLR 58,893 13,641 67,167
LF+NLRG+LCLR 57,380 12,243 50,277
</table>
<tableCaption confidence="0.999844">
Table 4: Grammar size comparisons for LC transform variants
</tableCaption>
<bodyText confidence="0.964522964285714">
the effect on grammar size of applying the NLRG
transformation by itself, but it is easy to see that
it increases the grammar size by exactly two sym-
bols for each left-recursive nonterminal to which it
is applied. Thus an addition of twice the number of
left-recursive nonterminals will be an upper bound
on the increase in the size of the grammar, but since
not every left-recursive nonterminal necessarily has
more than one non-left-recursive expansion, the in-
crease may be less than this.
The fifth line of Table 3 (LF+NLRG+PA) shows
the result of applying LF, followed by NLRG, fol-
lowed by PA. This produces another modest de-
crease in the size of the non-left-recursive form of
the CT grammar and reduces the size of the non-
left-recursive form of the ATIS grammar by a factor
of 27.8, compared to LF+PA. The non-left-recursive
form of the PT grammar remains larger than the
cut-off size of 5,000,000 symbols, however.
5 Left-Recursion Elimination Based
on the Left-Corner Transform
An alternate approach to eliminating left-recursion
is based on the left-corner (LC) grammar transform
of Rosenkrantz and Lewis (1970) as presented and
modified by Johnson (1998). Johnson&apos;s second form
of the LC transform can be expressed as follows, with
expressions of the form A-a, A-X, and A-B being
new nonterminals in the transformed grammar:
</bodyText>
<listItem confidence="0.987477333333333">
1. If a terminal symbol a is a proper left corner of
A in the original grammar, add A ---&gt; aA-a to
the transformed grammar.
2. If B is a proper left corner of A and B X/3
is a production of the original grammar, add
A-X ,8A-B to the transformed grammar.
3. If X is a proper left corner of A and A --&gt; X0
is a production of the original grammar, add
A-X -+ 3 to the transformed grammar.
</listItem>
<bodyText confidence="0.999799979166667">
In Rosenkrantz and Lewis&apos;s original LC transform,
schema 2 applied whenever B is a left corner of A,
including all cases where B = A. In Johnson&apos;s ver-
sion schema 2 applies when B = A only if A is a
proper left corner of itself. Johnson then introduces
schema 3 handle the residual cases, without intro-
ducing instances of nonterminals of the form A-A
that need to be allowed to derive the empty string.
The original purpose of the LC transform is to
allow simulation of left-corner parsing by top-down
parsing, but it also eliminates left recursion from any
noncyclic CFG.5 Furthermore, in the worst case, the
total number of symbols in the transformed gram-
mar cannot exceed a fixed multiple of the square of
the number of symbols in the original grammar, in
contrast to Paull&apos;s algorithm, which exponentiates
the size of the grammar in the worst case.
Thus, we can use Johnson&apos;s version of the LC
transform directly to eliminate left-recursion. Be-
fore applying this idea, however, we have one gen-
eral improvement to make in the transform. Johnson
notes that in his version of the LC transform, a new
nonterminal of the form A-X is useless unless X is
a proper left corner of A. We further note that a
new nonterminal of the form A-X, as well as the
orginal nonterminal A, is useless in the transformed
grammar, unless A is either the top nonterminal of
the grammar or appears on the right-hand side of
an original grammar production in other than the
left-most position. This can be shown by induction
on the length of top-down derivations using the pro-
ductions of the transformed grammar. Therefore,
we will call the original nonterminals meeting this
condition &amp;quot;retained nonterminals&amp;quot; and restrict the
LC transform so that productions involving nonter-
minals of the form A-X are created only if A is a
retained nonterminal.
Let LC refer to Johnson&apos;s version of the LC trans-
form restricted to retained nonterminals. In Table 4
the first three lines repeat the previously shown sizes
for our three original grammars, their left-factored
form, and their non-left-recursive form using our
best variant of Paull&apos;s algorithm (LF+NLRG+PA).
The fourth line shows the results of applying LC to
the three original grammars. Note that this pro-
duces a non-left-recursive form of the PT gram-
mar smaller than the cut-off size, but the non-left-
recursive forms of the CT and ATIS grammars are
</bodyText>
<footnote confidence="0.8578595">
51n the case of a cyclic CFG, the schema 2 fails to guar-
antee a non-left-recursive transformed grammar.
</footnote>
<page confidence="0.997458">
253
</page>
<bodyText confidence="0.923382666666667">
considerably larger than the most compact versions
created with Paull&apos;s algorithm.
We can improve on this result by noting that,
since we are interested in the LC transform only as
a means of eliminating left-recursion, we can greatly
reduce the size of the transformed grammars by ap-
plying the transform only to left-recursive nonter-
minals. More precisely, we can retain in the trans-
formed grammar all the productions expanding non-
left-recursive nonterminals of the original grammar,
and for the purposes of the LC transform, we can
treat non-left-recursive nonterminals as if they were
terminals:
1. If a terminal symbol or non-left-recursive non-
terminal X is a proper left corner of a re-
tained left-recursive nonterminal A in the orig-
inal grammar, add A -4 X A-X to the trans-
formed grammar.
</bodyText>
<listItem confidence="0.9295671">
2. If B is a left-recursive proper left corner of a
retained left-recursive nonterminal A and B -4
X/3 is a production of the original grammar, add
A-X -4 #A-B to the transformed grammar.
3. If X is a proper left corner of a retained left-
recursive nonterminal A and A -4 X0 is a pro-
duction of the original grammar, add A-X -4 #
to the transformed grammar.
4. If A is a non-left-recursive nonterminal and A -4
13 is a production of the original grammar, add
</listItem>
<bodyText confidence="0.998728457142857">
A -÷ 0 to the transformed grammar.
Let LCLR refer to the LC transform restricted
by these modifications so as to apply only to left-
recursive nonterminals. The fifth line of Table 4
shows the results of applying LCLR to the three orig-
inal grammars. LCLR greatly reduces the size of the
non-left-recursive forms of the CT and ATIS gram-
mars, but the size of the non-left-recursive form of
the PT grammar is only slightly reduced. This is
not surprising if we note from Table 1 that almost
all the productions of the PT grammar are produc-
tions for left-recursive nonterminals. However, we
can apply the additional transformations that we
used with Paull&apos;s algorithm, to reduce the num-
ber of productions for left-recursive nonterminals
before applying our modified LC transform. The
effects of left factoring the grammar before apply-
ing LCLR (LF+LCLR), and additionally combining
non-left-recursive productions for left-recursive non-
terminals between left factoring and applying LCLR
(LF+NLRG+LCLR), are shown in the sixth and
seventh lines of Table 4.
With all optimizations applied, the non-left-
recursive forms of the ATIS and PT grammars are
smaller than the originals (although not smaller
than the left-factored forms of these grammars),
and the non-left-recursive form of the CT gram-
mar is only slightly larger than the original. In all
cases, LF+NLRG+LCLR produces more compact
grammars than LF+NLRG+PA, the best variant of
Paull&apos;s algorithm—slightly more compact in the case
of the CT grammar, more compact by a factor of 5.9
in the case of the ATIS grammar, and more compact
by at least two orders of magnitude in the case of the
PT grammar.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999977625">
We have shown that, in its textbook form,
the standard algorithm for eliminating left recur-
sion from CFGs is impractical for three diverse,
independently-motivated, natural-language gram-
mars. We apply a number of optimizations to the
algorithm—most notably a novel strategy for order-
ing the nonterminals of the grammar—but one of
the three grammars remains essentially intractable.
We then explore an alternative approach based on
the LC grammar transform. With several optimiza-
tions of this approach, we are able to obtain quite
compact non-left-recursive forms of all three gram-
mars. Given the diverse nature of these grammars,
we conclude that our techniques based on the LC
transform are likely to be applicable to a wide range
of CFGs used for natural-language processing.
</bodyText>
<sectionHeader confidence="0.998062" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999684448275862">
A. V. Aho, R. Sethi, and J. D. Ullman. 1986.
Compilers: Principles, Techniques, and Tools.
Addison-Wesley Publishing Company, Reading,
Massachusetts.
D. A. Dahl et al. 1994. Expanding the scope of the
ATIS task: the ATIS-3 corpus. In Proceedings of
the Spoken Language Technology Workshop, pages
3-8, Plainsboro, New Jersey. Advanced Research
Projects Agency.
S. A. Greibach. 1965. A new normal-form theorem
for context-free phrase structure grammars. Jour-
nal of the Association for Computing Machinery,
12(1):42-52, January.
J. E. Hoperoft and J. D. Ullman. 1979. Introduc-
tion to Automata Theory, Languages, and Com-
putation. Addison-Wesley Publishing Company,
Reading, Massachusetts.
M. Johnson. 1998. Finite-state approximation
of constraint-based grammars using left-corner
grammar transforms. In Proceedings, COLING-
ACL &apos;98, pages 619-623, Montreal, Quebec,
Canada. Association for Computational Linguis-
tics.
M. P. Marcus, B. Santorini, and M. A.
Marcinkiewicz. 1993. Building a large anno-
tated corpus of English: The Penn Treebank.
Computational Linguistics, 19(2):313-330, June.
R. Moore, J. Dowding, H. Bratt, J. M. Gawron,
Y. Gorfu, and A. Cheyer. 1997. Commandtalk:
</reference>
<page confidence="0.982838">
254
</page>
<reference confidence="0.926260333333333">
A spoken-language interface for battlefield simu-
lations. In Proceedings of the Fifth Conference on
Applied Natural Language Processing, pages 1-7,
Washington, DC. Association for Computational
Linguistics.
S. J. Rosenkrantz and P. M. Lewis. 1970. Deter-
ministic left corner parser. In IEEE Conference
Record of the 11th Annual Symposium on Switch-
ing and Automata Theory, pages 139-152.
</reference>
<page confidence="0.998304">
255
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.905779">
<title confidence="0.999969">Removing Left Recursion from Context-Free Grammars</title>
<author confidence="0.999907">Robert C Moore</author>
<affiliation confidence="0.999581">Microsoft Research</affiliation>
<address confidence="0.9944225">One Microsoft Way Redmond, Washington 98052</address>
<email confidence="0.963212">bobmoore@microsoft.corn</email>
<abstract confidence="0.995867166666667">A long-standing issue regarding algorithms that manipulate context-free grammars (CFGs) in a &amp;quot;topdown&amp;quot; left-to-right fashion is that left recursion can lead to nontermination. An algorithm is known that transforms any CFG into an equivalent nonleft-recursive CFG, but the resulting grammars are often too large for practical use. We present a new method for removing left recursion from CFGs that is both theoretically superior to the standard algorithm, and produces very compact non-left-recursive CFGs in practice.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>R Sethi</author>
<author>J D Ullman</author>
</authors>
<date>1986</date>
<booktitle>Compilers: Principles, Techniques, and Tools.</booktitle>
<publisher>Addison-Wesley Publishing Company,</publisher>
<location>Reading, Massachusetts.</location>
<contexts>
<context position="961" citStr="Aho et al., 1986" startWordPosition="136" endWordPosition="139">orithm is known that transforms any CFG into an equivalent nonleft-recursive CFG, but the resulting grammars are often too large for practical use. We present a new method for removing left recursion from CFGs that is both theoretically superior to the standard algorithm, and produces very compact non-left-recursive CFGs in practice. 1 Introduction A long-standing issue regarding algorithms that manipulate context-free grammars (CFGs) in a &amp;quot;topdown&amp;quot; left-to-right fashion is that left recursion can lead to nontermination. This is most familiar in the case of top-down recursive-descent parsing (Aho et al., 1986, pp. 181-182). A more recent motivation is that off-the-shelf speech recognition systems are now available (e.g., from Nuance Communications and Microsoft) that accept CFGs as language models for constraining recognition; but as these recognizers process CFGs top-down, they also require that the CFGs used be non-left-recursive. The source of the problem can be seen by considering a directly left-recursive grammar production such as A -4 Aa. Suppose we are trying to parse, or recognize using a speech recognizer, an A at a given position in the input. If we apply this production top-down and le</context>
<context position="2260" citStr="Aho et al., 1986" startWordPosition="351" endWordPosition="354"> position. This immediately puts us into an infinite recursion. The same thing will happen with an indirectly left-recursive grammar, via a chain of subgoals that will lead us from the goal of parsing or recognizing an A at a given position to a descendant subgoal of parsing or recognizing an A at that position. In theory, the restriction to non-left-recursive CFGs puts no additional constraints on the languages that can be described, because any CFG can in principle be transformed into an equivalent non-left-recursive CFG. However, the standard algorithm for carrying out this transformation (Aho et al., 1986, pp. 176-178) (Hoperoft and Ullman, 1979, p. 96)—attributed to M. C. Paull by Hoperoft and Ullman (1979, p. 106)—can produce transformed grammars that are orders of magnitude larger than the original grammars. In this paper we develop a number of improvements to Paull&apos;s algorithm, which help somewhat but do not completely solve the problem. We then go on to develop an alternative approach based on the left-corner grammar transform, which makes it possible to remove left recursion with no significant increase in size for several grammars for which Paull&apos;s original algorithm is impractical. 2 N</context>
<context position="7444" citStr="Aho et al., 1986" startWordPosition="1219" endWordPosition="1222">hm is perhaps more familiar to some as the first phase of the textbook algorithm for transfomrming CFGs to Greibach normal form (Greibach, 1965).3 The subprocedure to eliminate direct left recursion performs the following transformation (Hoperoft and Ullman, 1979, p. 96): Let be the set of all directly left recursive Aproductions, and let A -4 /31 I • • 0&apos;8 be the remaining A-productions. Replace all these productions with --+ ■31A&apos; I )38 I fl.A&apos;, and A&apos; -4 al I aiA&apos; j ... f where A&apos; is a new nonterminal not used elsewhere in the grammar. This transformation is embedded in the full algorithm (Aho et al., 1986, p. 177), displayed in Figure 1. The idea of the algorithm is to eliminate left recursion by transforming the grammar so that all the direct left corners of each nonterminal strictly follow that nonterminal in a fixed total ordering, in which case, no nonterminal can be left recursive. This is accomplished by iteratively replacing direct left corners that precede a given nonterminal with all their expansions in terms of other nonterminals that are greater in the ordering, until the nonterminal has only itself and greater nonterminals as direct left 3This has led some readers to attribute the </context>
<context position="13533" citStr="Aho et al., 1986" startWordPosition="2274" endWordPosition="2277">y modestly in size, because as previously noted, it has no indirect left recursion. Thus the combinatorial phase of Paull&apos;s algorithm is never invoked, and the increase is solely due to the transformation applied to directly left-recursive productions. With the ATIS grammar and PT grammar, which do not have this special property, Paull&apos;s algorithm exceeded our cutoff, even with our best ordering of nonterminals. Some additional optimizations of Paull&apos;s aglorithm are possible. One way to reduce the number of substitutions made by the inner loop of the algorithm is to &amp;quot;left factor&amp;quot; the grammar (Aho et al., 1986, pp. 178-179). The left-factoring transformation (LF) applies the following grammar rewrite schema repeatedly, until it is no longer applicable: LF: For each nonterminal A, let a be the longest nonempty sequence such that there is more than one grammar production of the form A —&gt; af3. Replace the set of all productions A ath , . . . , A with the productions A —± , A&apos; th, • • , A&apos; ---&gt; where A&apos; is a new nonterminal symbol. With left factoring, for each nonterminal A there will be only one A-production for each direct left corner of A, which will in general reduce the number of substitutions pe</context>
</contexts>
<marker>Aho, Sethi, Ullman, 1986</marker>
<rawString>A. V. Aho, R. Sethi, and J. D. Ullman. 1986. Compilers: Principles, Techniques, and Tools. Addison-Wesley Publishing Company, Reading, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Dahl</author>
</authors>
<title>Expanding the scope of the ATIS task: the ATIS-3 corpus.</title>
<date>1994</date>
<journal>Advanced Research Projects Agency.</journal>
<booktitle>In Proceedings of the Spoken Language Technology Workshop,</booktitle>
<pages>3--8</pages>
<location>Plainsboro, New Jersey.</location>
<marker>Dahl, 1994</marker>
<rawString>D. A. Dahl et al. 1994. Expanding the scope of the ATIS task: the ATIS-3 corpus. In Proceedings of the Spoken Language Technology Workshop, pages 3-8, Plainsboro, New Jersey. Advanced Research Projects Agency.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S A Greibach</author>
</authors>
<title>A new normal-form theorem for context-free phrase structure grammars.</title>
<date>1965</date>
<journal>Journal of the Association for Computing Machinery,</journal>
<pages>12--1</pages>
<contexts>
<context position="6972" citStr="Greibach, 1965" startWordPosition="1135" endWordPosition="1136">t of increasing the size of the grammar by 78 productions and 89 total symbols. No empty productions or cycles existed anywhere else in the original grammars. 2Courtesy of Eugene Charniak, Brown University 4 Paull&apos;s Algorithm Paull&apos;s algorithm for eliminating left recursion from CFGs attacks the problem by an iterative procedure for transforming indirect left recursion into direct left recursion, with a subprocedure for eliminating direct left recursion. This algorithm is perhaps more familiar to some as the first phase of the textbook algorithm for transfomrming CFGs to Greibach normal form (Greibach, 1965).3 The subprocedure to eliminate direct left recursion performs the following transformation (Hoperoft and Ullman, 1979, p. 96): Let be the set of all directly left recursive Aproductions, and let A -4 /31 I • • 0&apos;8 be the remaining A-productions. Replace all these productions with --+ ■31A&apos; I )38 I fl.A&apos;, and A&apos; -4 al I aiA&apos; j ... f where A&apos; is a new nonterminal not used elsewhere in the grammar. This transformation is embedded in the full algorithm (Aho et al., 1986, p. 177), displayed in Figure 1. The idea of the algorithm is to eliminate left recursion by transforming the grammar so that a</context>
</contexts>
<marker>Greibach, 1965</marker>
<rawString>S. A. Greibach. 1965. A new normal-form theorem for context-free phrase structure grammars. Journal of the Association for Computing Machinery, 12(1):42-52, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Hoperoft</author>
<author>J D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages, and Computation.</title>
<date>1979</date>
<publisher>Addison-Wesley Publishing Company,</publisher>
<location>Reading, Massachusetts.</location>
<contexts>
<context position="2301" citStr="Hoperoft and Ullman, 1979" startWordPosition="357" endWordPosition="360"> us into an infinite recursion. The same thing will happen with an indirectly left-recursive grammar, via a chain of subgoals that will lead us from the goal of parsing or recognizing an A at a given position to a descendant subgoal of parsing or recognizing an A at that position. In theory, the restriction to non-left-recursive CFGs puts no additional constraints on the languages that can be described, because any CFG can in principle be transformed into an equivalent non-left-recursive CFG. However, the standard algorithm for carrying out this transformation (Aho et al., 1986, pp. 176-178) (Hoperoft and Ullman, 1979, p. 96)—attributed to M. C. Paull by Hoperoft and Ullman (1979, p. 106)—can produce transformed grammars that are orders of magnitude larger than the original grammars. In this paper we develop a number of improvements to Paull&apos;s algorithm, which help somewhat but do not completely solve the problem. We then go on to develop an alternative approach based on the left-corner grammar transform, which makes it possible to remove left recursion with no significant increase in size for several grammars for which Paull&apos;s original algorithm is impractical. 2 Notation and Terminology Grammar nontermin</context>
<context position="7091" citStr="Hoperoft and Ullman, 1979" startWordPosition="1148" endWordPosition="1151">s existed anywhere else in the original grammars. 2Courtesy of Eugene Charniak, Brown University 4 Paull&apos;s Algorithm Paull&apos;s algorithm for eliminating left recursion from CFGs attacks the problem by an iterative procedure for transforming indirect left recursion into direct left recursion, with a subprocedure for eliminating direct left recursion. This algorithm is perhaps more familiar to some as the first phase of the textbook algorithm for transfomrming CFGs to Greibach normal form (Greibach, 1965).3 The subprocedure to eliminate direct left recursion performs the following transformation (Hoperoft and Ullman, 1979, p. 96): Let be the set of all directly left recursive Aproductions, and let A -4 /31 I • • 0&apos;8 be the remaining A-productions. Replace all these productions with --+ ■31A&apos; I )38 I fl.A&apos;, and A&apos; -4 al I aiA&apos; j ... f where A&apos; is a new nonterminal not used elsewhere in the grammar. This transformation is embedded in the full algorithm (Aho et al., 1986, p. 177), displayed in Figure 1. The idea of the algorithm is to eliminate left recursion by transforming the grammar so that all the direct left corners of each nonterminal strictly follow that nonterminal in a fixed total ordering, in which cas</context>
</contexts>
<marker>Hoperoft, Ullman, 1979</marker>
<rawString>J. E. Hoperoft and J. D. Ullman. 1979. Introduction to Automata Theory, Languages, and Computation. Addison-Wesley Publishing Company, Reading, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
</authors>
<title>Finite-state approximation of constraint-based grammars using left-corner grammar transforms.</title>
<date>1998</date>
<booktitle>In Proceedings, COLINGACL &apos;98,</booktitle>
<pages>619--623</pages>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Montreal, Quebec, Canada.</location>
<contexts>
<context position="17409" citStr="Johnson (1998)" startWordPosition="2925" endWordPosition="2926"> applying LF, followed by NLRG, followed by PA. This produces another modest decrease in the size of the non-left-recursive form of the CT grammar and reduces the size of the nonleft-recursive form of the ATIS grammar by a factor of 27.8, compared to LF+PA. The non-left-recursive form of the PT grammar remains larger than the cut-off size of 5,000,000 symbols, however. 5 Left-Recursion Elimination Based on the Left-Corner Transform An alternate approach to eliminating left-recursion is based on the left-corner (LC) grammar transform of Rosenkrantz and Lewis (1970) as presented and modified by Johnson (1998). Johnson&apos;s second form of the LC transform can be expressed as follows, with expressions of the form A-a, A-X, and A-B being new nonterminals in the transformed grammar: 1. If a terminal symbol a is a proper left corner of A in the original grammar, add A ---&gt; aA-a to the transformed grammar. 2. If B is a proper left corner of A and B X/3 is a production of the original grammar, add A-X ,8A-B to the transformed grammar. 3. If X is a proper left corner of A and A --&gt; X0 is a production of the original grammar, add A-X -+ 3 to the transformed grammar. In Rosenkrantz and Lewis&apos;s original LC tran</context>
</contexts>
<marker>Johnson, 1998</marker>
<rawString>M. Johnson. 1998. Finite-state approximation of constraint-based grammars using left-corner grammar transforms. In Proceedings, COLINGACL &apos;98, pages 619-623, Montreal, Quebec, Canada. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="4855" citStr="Marcus et al., 1993" startWordPosition="777" endWordPosition="781">nternational 249 Toy CT ATIS PT Grammar Grammar Grammar Grammar Grammar size 88 55,830 16,872 67,904 Terminals 40 1,032 357 47 Nonterminals 16 3,946 192 38 Productions 55 24,456 4,592 15,039 LR nonterminals 4 535 9 33 Productions for LR nonterminals 27 2,211 1,109 14,993 Table 1: Grammars used for evaluation. written for CommandTalk (Moore et al., 1997), a spoken-language interface to a military simulation system. The ATIS grammar was extracted from an internally generated treebank of the DARPA ATIS3 training sentences (Dahl et al., 1994). The PT grammar&apos; was extracted from the Penn Treebank (Marcus et al., 1993). To these grammars we add a small &amp;quot;toy&amp;quot; grammar, simply because some of the algorithms cannot be run to completion on any of the &amp;quot;real&amp;quot; grammars within reasonable time and space bounds. Some statistics on the test grammars are contained in Table 1. The criterion we use to judge effectiveness of the algorithms under test is the size of the resulting grammar, measured in terms of the total number of terminal and nonterminal symbols needed to express the productions of the grammar. We use a slightly nonstandard metric, counting the symbols as if, for each nonterminal, there were a single product</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313-330, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moore</author>
<author>J Dowding</author>
<author>H Bratt</author>
<author>J M Gawron</author>
<author>Y Gorfu</author>
<author>A Cheyer</author>
</authors>
<title>Commandtalk: A spoken-language interface for battlefield simulations.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Conference on Applied Natural Language Processing,</booktitle>
<pages>1--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Washington, DC.</location>
<contexts>
<context position="4590" citStr="Moore et al., 1997" startWordPosition="735" endWordPosition="738">rectly left recursive. 3 Test Grammars We will test the algorithms considered here on three large, independently-motivated, natural-language grammars. The CT grammar&apos; was compiled into a CFG from a task-specific unification grammar iCourtesy of John Dowding, SRI International 249 Toy CT ATIS PT Grammar Grammar Grammar Grammar Grammar size 88 55,830 16,872 67,904 Terminals 40 1,032 357 47 Nonterminals 16 3,946 192 38 Productions 55 24,456 4,592 15,039 LR nonterminals 4 535 9 33 Productions for LR nonterminals 27 2,211 1,109 14,993 Table 1: Grammars used for evaluation. written for CommandTalk (Moore et al., 1997), a spoken-language interface to a military simulation system. The ATIS grammar was extracted from an internally generated treebank of the DARPA ATIS3 training sentences (Dahl et al., 1994). The PT grammar&apos; was extracted from the Penn Treebank (Marcus et al., 1993). To these grammars we add a small &amp;quot;toy&amp;quot; grammar, simply because some of the algorithms cannot be run to completion on any of the &amp;quot;real&amp;quot; grammars within reasonable time and space bounds. Some statistics on the test grammars are contained in Table 1. The criterion we use to judge effectiveness of the algorithms under test is the size </context>
</contexts>
<marker>Moore, Dowding, Bratt, Gawron, Gorfu, Cheyer, 1997</marker>
<rawString>R. Moore, J. Dowding, H. Bratt, J. M. Gawron, Y. Gorfu, and A. Cheyer. 1997. Commandtalk: A spoken-language interface for battlefield simulations. In Proceedings of the Fifth Conference on Applied Natural Language Processing, pages 1-7, Washington, DC. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Rosenkrantz</author>
<author>P M Lewis</author>
</authors>
<title>Deterministic left corner parser.</title>
<date>1970</date>
<booktitle>In IEEE Conference Record of the 11th Annual Symposium on Switching and Automata Theory,</booktitle>
<pages>139--152</pages>
<contexts>
<context position="17365" citStr="Rosenkrantz and Lewis (1970)" startWordPosition="2916" endWordPosition="2919">The fifth line of Table 3 (LF+NLRG+PA) shows the result of applying LF, followed by NLRG, followed by PA. This produces another modest decrease in the size of the non-left-recursive form of the CT grammar and reduces the size of the nonleft-recursive form of the ATIS grammar by a factor of 27.8, compared to LF+PA. The non-left-recursive form of the PT grammar remains larger than the cut-off size of 5,000,000 symbols, however. 5 Left-Recursion Elimination Based on the Left-Corner Transform An alternate approach to eliminating left-recursion is based on the left-corner (LC) grammar transform of Rosenkrantz and Lewis (1970) as presented and modified by Johnson (1998). Johnson&apos;s second form of the LC transform can be expressed as follows, with expressions of the form A-a, A-X, and A-B being new nonterminals in the transformed grammar: 1. If a terminal symbol a is a proper left corner of A in the original grammar, add A ---&gt; aA-a to the transformed grammar. 2. If B is a proper left corner of A and B X/3 is a production of the original grammar, add A-X ,8A-B to the transformed grammar. 3. If X is a proper left corner of A and A --&gt; X0 is a production of the original grammar, add A-X -+ 3 to the transformed grammar.</context>
</contexts>
<marker>Rosenkrantz, Lewis, 1970</marker>
<rawString>S. J. Rosenkrantz and P. M. Lewis. 1970. Deterministic left corner parser. In IEEE Conference Record of the 11th Annual Symposium on Switching and Automata Theory, pages 139-152.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>