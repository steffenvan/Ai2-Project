<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000881">
<title confidence="0.997173">
Rapid Parser Development:
A Machine Learning Approach for Korean
</title>
<author confidence="0.908461">
Ulf Hermjakob
</author>
<affiliation confidence="0.800205">
USC Information Sciences Institute
</affiliation>
<address confidence="0.727706">
4676 Admiralty Way #1000 Marina del Rey, CA 90292 • USA
</address>
<email confidence="0.998533">
ulf@cs.utexas.edu
</email>
<sectionHeader confidence="0.993886" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999627333333333">
This paper demonstrates that machine learning is
a suitable approach for rapid parser development.
From 1000 newly treebanked Korean sentences we
generate a deterministic shift-reduce parser. The
quality of the treebank, particularly crucial given its
small size, is supported by a consistency checker.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999926032258065">
Given the enormous complexity of natural language,
parsing is hard enough as it is, but often unforeseen
events like the crises in Bosnia or East-Timor create
a sudden demand for parsers and machine transla-
tion systems for languages that have not benefited
from major attention of the computational linguis-
tics community up to that point.
Good machine translation relies strongly on the
context of the words to be translated, a context that
often goes well beyond neighboring surface words.
Often basic relationships, like that between a verb
and its direct object, provide crucial support for
translation. Such relationships are usually provided
by parsers.
The NLP resources for a language of sudden inter-
national interest are typically quite limited. There is
probably a dictionary, but most likely no treebank.
Maybe basic tools for morphological analysis, but
probably no semantic ontology.
This paper reports on the rapid development of
a parser based on very limited resources. We show
that by building a small treebank of only a thousand
sentences, we could develop a good basic parser us-
ing machine learning within only three months. For
the language we chose, Korean, a number of research
groups have been working on parsing and/or ma-
chine translation in recent years (Yoon, 1997; Seo,
1998; Lee, 1997), but advanced resources have not
been made publicly available, and we have not used
any, thereby so-to-speak at least simulating a low
density language scenario.
</bodyText>
<sectionHeader confidence="0.992914" genericHeader="introduction">
2 Korean
</sectionHeader>
<bodyText confidence="0.996032153846154">
Like Japanese, Korean is a head-final agglutinative
language. It is written in a phonetic alphabet called
hangul, in which each two-byte character represents
one syllable. While our parser operates on the orig-
inal Korean hangul, this paper presents examples
in a romanized transcription. In sentence (1) for
example, the verb is preceded by a number of so-
called eojeols (equivalent to bunsetsus in Japanese)
like &amp;quot;chaeg-eul&amp;quot;, which are typically composed of a
content part (&amp;quot;chaeg&amp;quot; = book) and a postposition,
which often corresponds to a preposition in English,
but is also used as a marker of topic, subject or ob-
ject ( &amp;quot;eul&amp;quot;).
</bodyText>
<equation confidence="0.520353">
1_112_ 01x11 2 la Alrf.
</equation>
<bodyText confidence="0.6363146">
Na-neun eo-je geu chaeg-eul sass-da.
/TOPIC yesterday this bookoar bought.
I bought this book yesterday.
Our parser produces a tree describing the structure
of a given sentence, including syntactic and semantic
roles, as well as additional information such as tense.
For example, the parse tree for sentence (1) is shown
below:
[1] na-nemn eo-je geu chaeg-eul sass-da. [S]
(SUBJ) [2] na-neun [NP]
(HEAD) [3] na [REG-NOUN]
(PARTICLE) [4] neun [DUPLICATE-PRT]
(TIME) [5] eo-je [REG-ADVERB]
(HEAD) [6] eo-je [REG-ADVERB]
(OBJ) [7] geu chaeg-eul [NP]
(MOD) [8] geu [DEMONSTR-ADNOMINAL]
(HEAD) [9] geu [DEMONSTR-ADNOMINAL]
(HEAD) [10] chaeg-eul [NP]
(HEAD) [11] chaeg [REG-NOUN]
(PARTICLE) [12] eul [OBJ-CASE-PRT]
</bodyText>
<listItem confidence="0.5959376">
(HEAD) [13] sass-da. [VERB; PAST-TENSE]
(HEAD) [14] sa [VERB-STEM]
(SUFFIX) [15] eoss [INTERMED-SUF-VERB]
(SUFFIX) [16] da [CONNECTIVE-SUF-VERB]
(DUMMY) [17] . [PERIOD]
</listItem>
<figureCaption confidence="0.99619">
Figure 1: Parse tree for sentence 1 (simplified)
</figureCaption>
<bodyText confidence="0.999338">
For preprocessing, we use a segmenter and mor-
phological analyzer, KMA, and a tagger, KTAG,
both provided by the research group of Prof. Rim of
</bodyText>
<equation confidence="0.921105">
(1)
</equation>
<page confidence="0.985418">
118
</page>
<bodyText confidence="0.99941025">
Korea University. KMA, which comes with a built-
in Korean lexicon, segments Korean text into eojeols
and provides a set of possible sub-segmentations and
morphological analyses. KTAG then tries to select
the most likely such interpretation. Our parser is
initialized with the result of KMA, preserving all
interpretations, but marking KTAG&apos;s choice as the
top alternative.
</bodyText>
<sectionHeader confidence="0.977709" genericHeader="method">
3 Treebanking Effort
</sectionHeader>
<bodyText confidence="0.996225666666667">
The additional resources used to train and test a
parser for Korean, which we will describe in more
detail in the next section, were (1) a 1187 sentence
treebank, (2) a set of 133 context features, and (3)
background knowledge in form of an &apos;is-a&apos; ontology
with about 1000 entries. These resources were built
by a team consisting of the principal researcher and
two graduate students, each contributing about 3
months.
</bodyText>
<subsectionHeader confidence="0.99698">
3.1 Treebank
</subsectionHeader>
<bodyText confidence="0.9992405">
The treebank sentences are taken from the Korean
newspaper Chosun, two-thirds from 1994 and the re-
mainder from 1999. Sentences represent continuous
articles with no sentences skipped for length or any
other reason. The average sentence length is 21.0
words.
</bodyText>
<subsectionHeader confidence="0.999888">
3.2 Feature Set
</subsectionHeader>
<bodyText confidence="0.999781454545454">
The feature set describes the context of a partially
parsed state, including syntactic features like the
part of speech of the constituent at the front/top
of the input list (as sketched in figure 2) or whether
the second constituent on the parse stack ends in a
comma, as well as semantic features like whether or
not a constituent is a time expression or contains
a location particle. The feature set can accommo-
date any type of feature as long as it is computable,
and can thus easily integrate different types of back-
ground knowledge.
</bodyText>
<subsectionHeader confidence="0.99985">
3.3 Background Knowledge
</subsectionHeader>
<bodyText confidence="0.999689888888889">
The features are supported by background knowl-
edge in the form of an ontology, which for example
has a time-particle concept with nine sub-concepts
(accounting for 9 of the 1000 entries mentioned
above). Most of the background knowledge groups
concepts like particles, suffixes, units (e.g. for lengths
or currencies), temporal adverbs — semantic classes
that are not covered by part of speech information
of the lexicon, yet provide valuable clues for parsing.
</bodyText>
<subsectionHeader confidence="0.995528">
3.4 Time Effort
</subsectionHeader>
<bodyText confidence="0.9484356">
The first graduate student, a native Korean and
linguistics major, hired for 11 weeks, spent about
2 weeks getting trained, 6 weeks on building two-
thirds of the treebank, 2 weeks providing most back-
ground knowledge entries and 1 week helping to
</bodyText>
<figureCaption confidence="0.998">
Figure 2: A typical parse action (simplified).
</figureCaption>
<bodyText confidence="0.997565545454545">
Boxes represent frames. The asterisk (*) represents the
current parse position. Optionally, parse actions can
have additional arguments, like target syntactic or se-
mantic classes to overwrite any default. Elements on the
input list are identified by positive integers, elements on
the parse stack by negative integers. The feature `Synt of
-1&apos; for example refers to the (main) syntactic category of
the top stack element. Before the reduce operation, the
feature `Synt of -1&apos; would evaluate to np (for &amp;quot;a book&amp;quot;),
after the operation to vp (for &amp;quot;bought a book&amp;quot;). The in-
put list is initialized with the morphologically analyzed
words, possibly still ambiguous. After a sequence of shift
(from input list to parse stack) and reduce (on the parse
stack) operations, the parser eventually ends up with a
single element on the parse stack, which is then returned
as the parse tree.
identify useful features. The other graduate student,
a native Korean and computer science major, in-
stalled Korean tools including a terminal for hangul
and the above mentioned KMA and KTAG, wrote a
number of scripts tying all tools together, made some
tool improvements, built one-third of the treebank
</bodyText>
<figure confidence="0.9850195">
parse stack top of front/top of
stack list
-nput list&gt;
-3 -2 -1 1
&amp;quot;John&amp;quot; &amp;quot;bought&amp;quot; &amp;quot;a book&amp;quot; &amp;quot;today&amp;quot;
synt: np synt: verb synt: np synt: adv
(R 210 S-VP AS PRED OBJ)
&amp;quot;reduce the 2 top elements of the parse stack
to a frame with syntax &apos;VP&apos;
and roles `pred&apos; and &apos;obj—
&amp;quot;John&amp;quot;
synt: np
/
&amp;quot;bought&amp;quot;
synt: verb
&amp;quot;a book&amp;quot;
synt: np
&amp;quot;today&amp;quot;
synt: adv
&amp;quot;bought a book&amp;quot;
synt: vp
sub: (pred) (obj)
</figure>
<page confidence="0.99228">
119
</page>
<bodyText confidence="0.9999505">
and also contributed to the feature set. The prin-
cipal researcher, who does not speak Korean, con-
tributed about 3 person months, coordinating the
project, training the graduate students, writing tree-
bank consistency checking rules (see section 6), mak-
ing extensions to the tree-to-parse-action-sequence
module (see section 4.1) and contributing to the
background knowledge and feature set.
</bodyText>
<sectionHeader confidence="0.86544" genericHeader="method">
4 Learning to Parse
</sectionHeader>
<bodyText confidence="0.994526191489362">
We base our training on the machine learning based
approach of (Hermjakob 86 Mooney, 1997), allow-
ing however unrestricted text and deriving the parse
action sequences required for training from a tree-
bank. The basic mechanism for parsing text into
a shallow semantic representation is a shift-reduce
type parser (Marcus, 1980) that breaks parsing into
an ordered sequence of small and manageable parse
actions. Figure 2 shows a typical reduce action. The
key task of machine learning then is to learn to pre-
dict which parse action to perform next.
Two key advantages of this type of deterministic
parsing are that its linear run-time complexity with
respect to sentence length makes the parser very
fast, and that the parser is very robust in that it
produces a parse tree for every input sentence.
Figure 3 shows the overall architecture of parser
training. From the treebank, we first automatically
generate a parse action sequence. Then, for every
step in the parse action sequence, typically several
dozens per sentence, we automatically compute the
value for every feature in the feature set, add on the
parse action as the proper classification of the parse
action example, and then feed these examples into a
machine learning program, for which we use an ex-
tension of decision trees (Quinlan, 1986; Hermjakob
Sz Mooney, 1997).
We built our parser incrementally. Starting with a
small set of syntactic features that are useful across
all languages, early training and testing runs reveal
machine learning conflict sets and parsing errors that
point to additionally required features and possibly
also additional background knowledge. A conflict
set is a set of training examples that have identical
values for all features, yet differ in their classification
(= parse action). Machine learning can therefore not
possibly learn how to handle all examples correctly.
This is typically resolved by adding an additional
feature that differentiates between the examples in
a linguistically relevant way.
Even treebanking benefits from an incremental ap-
proach. Trained on more and more sentences, and
at the same time with also more and more features,
parser quality improves, so that the parser as a tree-
banking tool has to be corrected less and less fre-
quently, thereby accelerating the treebanking pro-
cess.
</bodyText>
<table confidence="0.997168451612903">
Knowledge Base (&amp;quot;ontology&amp;quot;) Treebank
,
temporal-concept N N
,---------,- computer science
month-of-the-year
day-of-the-week
-.----------
Monday ... Sunday
syntactic-element lparse action sequence
verb noun adverb generator (automatic)
---------&apos;--- Parse action sequence:
count-noun mass-noun
hi Shift noun
Feature set: *, Shift noun
Reduce 2 as mod head
Done
gn grit Synt
1 of 1
1i! parse example generator (automatic)
Parse action examples:
Unavail Unavail Noun Shift noun
Unavail Noun Noun Shift noun
Noun Noun Unavail Reduce 2 as mod head
Unavail Noun Unavail I Done
&apos;11! decision structure builder (automatic)
Parse decision structure:
Synt of 1
Noun navail
Shift noun Synt of -2
Unav a oun
Done Reduce 2 as mod head
</table>
<figureCaption confidence="0.855579">
Figure 3: Derivation of the parser from a treebank
and a feature set. The resulting parser has the form
</figureCaption>
<bodyText confidence="0.9696364">
of a decision structure, an extension of decision trees.
Given a seen or unseen sentence in form of a list
of words, the decision structure keeps selecting the
next parse action until a single parse tree covering
the entire sentence has been built.
</bodyText>
<page confidence="0.987898">
120
</page>
<subsectionHeader confidence="0.851759">
4.1 Special Adaptation for Korean
</subsectionHeader>
<bodyText confidence="0.997770666666667">
The segmenter and morphological analyzer KMA re-
turns a list of alternatives for each eojeol. However,
the alternatives are not atomic but rather two-level
constituents, or mini-trees. Consider for example
the following fourl alternatives for the eojeol
(the 31st day of a month):
</bodyText>
<equation confidence="0.99991725">
31/NUMERAL + i/SUFFIX-NOUN + 1/OBJ-CASE-PRT
31/NUMERAL + i/NUMERAL + 1/OBJ-CASE-PRT
31/NUMERAL + il/UNIT-NOUN
31/NUMERAL + il/REGULAR-NOUN
</equation>
<bodyText confidence="0.99988">
The analyzer divides &apos;Mil&apos; into groups with varying
number of sub-components with different parts of
speech. When shifting in an element, the parser has
to decide which one to pick, the third one in this
case, using context of course.
The module generating parse action sequences
from a tree needs special split and merge operations
for cases where the correct segmentation is not of-
fered as a choice at all. To make things a little ugly,
these splits can not only occur in the middle of a leaf
constituent, but even in the middle of a character
that might have been contracted from two charac-
ters, each with its own meaning.
</bodyText>
<sectionHeader confidence="0.973917" genericHeader="method">
5 Chosun Newspaper Experiments
</sectionHeader>
<bodyText confidence="0.963575034482758">
Table 1 presents evaluation results with the number
of training sentences varying from 32 to 1024 and
with the remaining 163 sentences of the treebank
used for testing.
Precision:
number of correct constituents in system parse
number of constituents in system parse
Recall:
number of correct constituents in system parse
number of constituents in logged parse
Crossing brackets: number of constituents
which violate constituent boundaries with a con-
stituent in the logged parse. Labeled preci-
sion/recall measures not only structural correctness,
but also the correctness of the syntactic label. Cor-
rect operations measures the number of correct
operations during a parse that is continuously cor-
rected based on the logged sequence; it measures
the core machine learning algorithm performance in
isolation. A sentence has a correct operating se-
quence, if the system fully predicts the logged parse
action sequence, and a correct structure and la-
beling, if the structure and syntactic labeling of the
final system parse of a sentence is 100% correct, re-
gardless of the operations leading to it.
Figures 4 and 5 plot the learning curves for two
key metrics. While both curves are clearly heading
1KMA actually produces 10 different alternatives in this
case, of which only four are shown here.
</bodyText>
<figure confidence="0.93495125">
word level constituent
labeled precision
32 64 128 256 512 1024
number of training sentences
</figure>
<figureCaption confidence="0.9942495">
Figure 4: Learning curve for labeled precision corre-
sponding to table 1
</figureCaption>
<figure confidence="0.9991">
crossings brackets per sentence
2.1 —
2.0 —
1.9 —
1.8 —
1.7 —
1.6 —
1.5 —
32 64 128 256 512 1024
number of training sentences
</figure>
<figureCaption confidence="0.9543015">
Figure 5: Learning curve for crossing brackets per
sentence corresponding to table 1
</figureCaption>
<bodyText confidence="0.999965142857143">
in the right direction, up for precision, and down
for crossing brackets, their appearance is somewhat
jagged. For smaller data sets like in our case, this
can often be avoided by running an n-fold cross val-
idation test. However, we decided not to do so,
because many training sentences were also used for
feature set and background knowledge development
</bodyText>
<figure confidence="0.96178825">
87.0%—
86.0%—
85.0%—
84.0%—
</figure>
<page confidence="0.984269">
121
</page>
<table confidence="0.999940666666667">
Training sentences 32 64 128 256 512 1024
Precision 88.6% 88.1% 90.0% 89.6% 90.7% 91.0%
Recall 87.3% 87.4% 89.2% 89.1% 89.6% 89.8%
Labeled precision 84.1% 83.9% 85.8% 85.6% 86.7% 86.9%
Labeled recall 81.2% 81.9% 83.6% 83.6% 84.7% 85.0%
Tagging accuracy 94.3% 92.9% 93.9% 93.4% 94.0% 94.2%
Crossings/sentence 1.97 2.00 1.72 1.79 1.69 1.63
0 crossings 27.6% 35.0% 38.7% 40.5% 43.6% 42.9%
&lt; 1 crossing 56.4% 58.9% 63.2% 59.5% 64.4% 62.6%
&lt; 2 crossings 70.6% 72.4% 73.0% 71.8% 73.0% 74.2%
&lt; 3 crossings 81.0% 81.6% 82.2% 81.6% 82.2% 83.4%
&lt; 4 crossings 88.3% 84.0% 91.4% 89.0% 90.8% 89.6%
Correct operations 63.0% 68.3% 71.5% 73.4% 75.0% 76.3%
Operation Sequence 2.5% 6.1% 8.0% 8.6% 11.0% 7.4%
Structure&amp;Label 5.5% 12.9% 11.7% 16.0% 19.0% 16.0%
</table>
<tableCaption confidence="0.999947">
Table 1: Evaluation results with varying number of training sentences
</tableCaption>
<bodyText confidence="0.998499">
as well as for intermediate inspection, and therefore
might have unduly influenced the evaluation.
</bodyText>
<subsectionHeader confidence="0.999177">
5.1 Tagging accuracy
</subsectionHeader>
<bodyText confidence="0.999792033333333">
A particularly striking number is the tagging accu-
racy, 94.2%, which is dramatically below the equiv-
alent 98% to 99% range for a good English or
Japanese parser. In a Korean sentence, only larger
constituents that typically span several words are
separated by spaces, and even then not consistently,
so that segmentation errors are a major source for
tagging problems (as it is to some degree however
also for Japanese2). We found that the segmen-
tation part of KMA sometimes still struggles with
relatively simple issues like punctuation, proposing
for example words that contain a parenthesis in the
middle of standard alphabetic characters. We have
corrected some of these problems by pre- and post-
processing the results of KMA, but believe that there
is still a significant potential for further improve-
ment.
In order to assess the impact of the relatively low
tagging accuracy, we conducted experiments that
simulated a perfect tagger by initializing the parser
with the correctly segmented, morphologically ana-
lyzed and tagged sentence according to the treebank.
By construction, the tagging accuracy in table 2
rises to 100%. Since the segmenter/tagger returns
not just atomic but rather two-level constituents,
the precision and recall values benefit particularly
strongly, possibly inflating the improvements for
these metrics, but other metrics like crossing brack-
ets per sentence show substantial gains as well. Thus
we believe that refined pre-parsing tools, as they are
</bodyText>
<footnote confidence="0.866358">
2 While Japanese does not use spaces at all, script changes
between kanji, hiragana, and katakana provide a lot of seg-
mentation guidance. Modern Korean, however, almost exclu-
sively uses only a single phonetic script.
</footnote>
<table confidence="0.9989876">
Segmentation/ Regular Simulating
Tagging seg/tag as perfect
(&amp;quot;seg/tag&amp;quot;) implemented seg/tag
Labeled precision 86.9% 93.4%
Labeled recall 85.0% 92.9%
Tagging accuracy 94.2% 100.0%
Crossings/sentence 1.63 1.13
0 crossings 42.9% 48.5%
&lt; 2 crossings 74.2% 85.3%
Structure&amp;Label 16.0% 28.8%
</table>
<tableCaption confidence="0.998302">
Table 2: Impact of segmentation/tagging errors
</tableCaption>
<bodyText confidence="0.996490416666667">
in the process of becoming available for Korean, will
greatly improve parsing accuracy.
However, for true low density languages, such high
quality preprocessors are probably not available so
that our experimental scenario might be more re-
alistic for those conditions. On the other hand,
some low density languages like for example Tetun,
the principal indigenous language of East Timor,
are based on the Latin alphabet, separate words by
spaces and have relatively little inflection, and there-
fore make morphological analysis and segmentation
relatively simple.
</bodyText>
<sectionHeader confidence="0.989955" genericHeader="method">
6 Treebank Consistency Checking
</sectionHeader>
<bodyText confidence="0.999987555555556">
It is difficult to maintain a high treebank quality.
When training on a small treebank, this is particu-
larly important, because there is not enough data to
allow generous pruning.
Treebanking is done by humans and humans err.
Even with annotation guidelines there are often ad-
ditional inconsistencies when there are several an-
notators. In the Penn Treebank (Marcus, 1993) for
example, the word ago as in &apos;two years ago&apos;, is tagged
</bodyText>
<page confidence="0.992474">
122
</page>
<bodyText confidence="0.999934517241379">
414 times as an adverb and 150 times as a preposi-
tion.
In many treebanking efforts, basic taggers and
parsers suggest parts of speech and tree structures
that can be accepted or corrected, typically speed-
ing up the treebanking effort considerably. How-
ever, incorrect defaults can easily slip through, leav-
ing blatant inconsistencies like the one where the
constituent &apos;that&apos; as in &apos;the dog that bit her&apos; is tree-
banked as a noun phrase containing a conjunction
(as opposed to a pronoun).
From the very beginning of treebanking, we have
therefore passed all trees to be added to the tree-
bank through a consistency checker that looks for
any suspicious patterns in the new tree. For every
type of phrase, the consistency checker draws on a
list of acceptable patterns in a BNF style notation.
While this consistency checking certainly does not
guarantee to find all errors, and can produce false
alarms when encountering rare but legitimate con-
structions, we have found it a very useful tool to
maintain treebank quality from the very beginning,
easily offsetting the about three man days that it
took to adapt the consistency checker to Korean.
For a number of typical errors, we extended the
checker to automatically correct errors for which this
could be done safely, or, alternatively, suggest a
likely correction for errors and prompt for confir-
mation/correction by the treebanker.
</bodyText>
<sectionHeader confidence="0.999485" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999872846153846">
Comparisons with related work are unfortunately
very problematic, because the corpora are differ-
ent and are sometimes not even described in other
work. In most cases Korean research groups also use
other evaluation metrics, particularly dependency
accuracy, which is often used in dependency struc-
ture approaches. Training on about 40,000 sentences
(Collins, 1997) achieves a crossing brackets rate of
1.07, a better value than our 1.63 value for regular
parsing or the 1.13 value assuming perfect segmen-
tation/tagging, but even for similar text types, com-
parisons across languages are of course problematic.
It is clear to us that with more training sentences,
and with more features and background knowledge
to better leverage the increased number of train-
ing sentences, accuracy rates can still be improved
significantly. But we believe that the reduction of
parser development time from two years or more
down to three months is in many cases already very
valuable, even if the accuracy has not &apos;maxed out&apos;
yet. And given the experience we have gained from
this project, we hope this research to be only a first
step to an even steeper development time reduction.
A particularly promising research direction for this
is to harness knowledge and training resources across
languages.
</bodyText>
<sectionHeader confidence="0.997695" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999246">
I would like to thank Kyoosung Lee for installing,
improving and conncecting Korean pre-processing
tools like segmenter and tagger as well as starting
the treebanking, and Mina Lee, who did most of the
treebanking.
</bodyText>
<sectionHeader confidence="0.999235" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999871756756757">
M. J. Collins. 1997. Three Generative, Lexicalised
Models for Statistical Parsing. In 35th Proceedings
of the ACL, pages 16-23.
U. Hermjakob and R. J. Mooney. 1997. Learning
Parse and Translation Decisions From Examples
With Rich Context. In 35th Proceedings of the
ACL, pages 482-489.
URL: file://ftp.cs.utexas.edu/pub/mooney/papers
/contex-ac1-97.ps.Z
U. Hermjakob. 1997. Learning Parse and Transla-
tion Decisions From Examples With Rich Context.
Ph.D. thesis, University of Texas at Austin, Dept.
of Computer Sciences TR 97-12.
URL: file://ftp.cs.utexas.edu/pub/mooney/papers
ihermjakob-dissertation-97.ps.Z
Geunbae Lee, Jong-Hyeok Lee, and Hyuncheol Rho.
1997. Natural Language Processing for Session-
Based Information Retrieval Interface on the Web.
In Proceedings of LICAI-97 workshop on Al in dig-
ital libraries, pages 43-48.
M. P. Marcus. 1980. A Theory of Syntactic Recog-
nition for Natural Language. MIT Press.
M. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1993. Building a Large Annotated Corpus of En-
glish: The Penn Treebank. Computational Lin-
guistics 19(2), pages 313-330.
J. R. Quinlan. 1993. C4.5 Programs for Machine
Learning. Morgan Kaufmann Publishers, San Ma-
teo, California.
K. J. Seo, K. C. Nam, and K. S. Choi. 1998. A Prob-
abilistic Model for Dependency Parsing Consider-
ing Ascending Dependencies. Journal of Literary
and Linguistic Computing, Vol 13(2).
Juntae Yoon, Seonho Kim, and Mansuk Song. 1997.
New Parsing Method Using Global Association
Table. In Proc. of the International Workshop on
Parsing Technology.
</reference>
<page confidence="0.998949">
123
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.818944">
<title confidence="0.99813">Rapid Parser Development: A Machine Learning Approach for Korean</title>
<author confidence="0.861206">Ulf Hermjakob</author>
<affiliation confidence="0.999547">USC Information Sciences Institute</affiliation>
<address confidence="0.999713">4676 Admiralty Way #1000 Marina del Rey, CA 90292 • USA</address>
<email confidence="0.99985">ulf@cs.utexas.edu</email>
<abstract confidence="0.993267285714286">This paper demonstrates that machine learning is a suitable approach for rapid parser development. From 1000 newly treebanked Korean sentences we generate a deterministic shift-reduce parser. The quality of the treebank, particularly crucial given its small size, is supported by a consistency checker.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M J Collins</author>
</authors>
<title>Three Generative, Lexicalised Models for Statistical Parsing.</title>
<date>1997</date>
<booktitle>In 35th Proceedings of the ACL,</booktitle>
<pages>16--23</pages>
<contexts>
<context position="20446" citStr="Collins, 1997" startWordPosition="3261" endWordPosition="3262"> number of typical errors, we extended the checker to automatically correct errors for which this could be done safely, or, alternatively, suggest a likely correction for errors and prompt for confirmation/correction by the treebanker. 7 Conclusions Comparisons with related work are unfortunately very problematic, because the corpora are different and are sometimes not even described in other work. In most cases Korean research groups also use other evaluation metrics, particularly dependency accuracy, which is often used in dependency structure approaches. Training on about 40,000 sentences (Collins, 1997) achieves a crossing brackets rate of 1.07, a better value than our 1.63 value for regular parsing or the 1.13 value assuming perfect segmentation/tagging, but even for similar text types, comparisons across languages are of course problematic. It is clear to us that with more training sentences, and with more features and background knowledge to better leverage the increased number of training sentences, accuracy rates can still be improved significantly. But we believe that the reduction of parser development time from two years or more down to three months is in many cases already very valu</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>M. J. Collins. 1997. Three Generative, Lexicalised Models for Statistical Parsing. In 35th Proceedings of the ACL, pages 16-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hermjakob</author>
<author>R J Mooney</author>
</authors>
<title>Learning Parse and Translation Decisions From Examples With Rich Context.</title>
<date>1997</date>
<booktitle>In 35th Proceedings of the ACL,</booktitle>
<pages>482--489</pages>
<marker>Hermjakob, Mooney, 1997</marker>
<rawString>U. Hermjakob and R. J. Mooney. 1997. Learning Parse and Translation Decisions From Examples With Rich Context. In 35th Proceedings of the ACL, pages 482-489.</rawString>
</citation>
<citation valid="false">
<pages>1--97</pages>
<note>URL: file://ftp.cs.utexas.edu/pub/mooney/papers</note>
<marker></marker>
<rawString>URL: file://ftp.cs.utexas.edu/pub/mooney/papers /contex-ac1-97.ps.Z</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hermjakob</author>
</authors>
<title>Learning Parse and Translation Decisions From Examples With Rich Context.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<pages>97--12</pages>
<institution>University of Texas at Austin, Dept. of Computer Sciences</institution>
<marker>Hermjakob, 1997</marker>
<rawString>U. Hermjakob. 1997. Learning Parse and Translation Decisions From Examples With Rich Context. Ph.D. thesis, University of Texas at Austin, Dept. of Computer Sciences TR 97-12.</rawString>
</citation>
<citation valid="false">
<note>URL: file://ftp.cs.utexas.edu/pub/mooney/papers ihermjakob-dissertation-97.ps.Z</note>
<marker></marker>
<rawString>URL: file://ftp.cs.utexas.edu/pub/mooney/papers ihermjakob-dissertation-97.ps.Z</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geunbae Lee</author>
<author>Jong-Hyeok Lee</author>
<author>Hyuncheol Rho</author>
</authors>
<title>Natural Language Processing for SessionBased Information Retrieval Interface on the Web. In</title>
<date>1997</date>
<booktitle>Proceedings of LICAI-97 workshop on Al in digital libraries,</booktitle>
<pages>43--48</pages>
<marker>Lee, Lee, Rho, 1997</marker>
<rawString>Geunbae Lee, Jong-Hyeok Lee, and Hyuncheol Rho. 1997. Natural Language Processing for SessionBased Information Retrieval Interface on the Web. In Proceedings of LICAI-97 workshop on Al in digital libraries, pages 43-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
</authors>
<title>A Theory of Syntactic Recognition for Natural Language.</title>
<date>1980</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="8465" citStr="Marcus, 1980" startWordPosition="1351" endWordPosition="1352">nths, coordinating the project, training the graduate students, writing treebank consistency checking rules (see section 6), making extensions to the tree-to-parse-action-sequence module (see section 4.1) and contributing to the background knowledge and feature set. 4 Learning to Parse We base our training on the machine learning based approach of (Hermjakob 86 Mooney, 1997), allowing however unrestricted text and deriving the parse action sequences required for training from a treebank. The basic mechanism for parsing text into a shallow semantic representation is a shift-reduce type parser (Marcus, 1980) that breaks parsing into an ordered sequence of small and manageable parse actions. Figure 2 shows a typical reduce action. The key task of machine learning then is to learn to predict which parse action to perform next. Two key advantages of this type of deterministic parsing are that its linear run-time complexity with respect to sentence length makes the parser very fast, and that the parser is very robust in that it produces a parse tree for every input sentence. Figure 3 shows the overall architecture of parser training. From the treebank, we first automatically generate a parse action s</context>
</contexts>
<marker>Marcus, 1980</marker>
<rawString>M. P. Marcus. 1980. A Theory of Syntactic Recognition for Natural Language. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313--330</pages>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics 19(2), pages 313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<date>1993</date>
<booktitle>C4.5 Programs for Machine Learning.</booktitle>
<publisher>Morgan Kaufmann Publishers,</publisher>
<location>San Mateo, California.</location>
<marker>Quinlan, 1993</marker>
<rawString>J. R. Quinlan. 1993. C4.5 Programs for Machine Learning. Morgan Kaufmann Publishers, San Mateo, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Seo</author>
<author>K C Nam</author>
<author>K S Choi</author>
</authors>
<title>A Probabilistic Model for Dependency Parsing Considering Ascending Dependencies.</title>
<date>1998</date>
<journal>Journal of Literary and Linguistic Computing, Vol</journal>
<volume>13</volume>
<issue>2</issue>
<marker>Seo, Nam, Choi, 1998</marker>
<rawString>K. J. Seo, K. C. Nam, and K. S. Choi. 1998. A Probabilistic Model for Dependency Parsing Considering Ascending Dependencies. Journal of Literary and Linguistic Computing, Vol 13(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juntae Yoon</author>
<author>Seonho Kim</author>
<author>Mansuk Song</author>
</authors>
<title>New Parsing Method Using Global Association Table.</title>
<date>1997</date>
<booktitle>In Proc. of the International Workshop on Parsing Technology.</booktitle>
<marker>Yoon, Kim, Song, 1997</marker>
<rawString>Juntae Yoon, Seonho Kim, and Mansuk Song. 1997. New Parsing Method Using Global Association Table. In Proc. of the International Workshop on Parsing Technology.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>