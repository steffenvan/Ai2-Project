       Clique-Based Clustering for improving Named Entity Recognition systems   
 Julien Ah-Pine   
 Xerox Research Centre Europe    6, chemin de Maupertuis 38240 Meylan, France    julien.ah-pine@xrce.xerox.com   
 Guillaume
 Jacquet    Xerox Research Centre Europe    6, chemin de Maupertuis 38240 Meylan, France    guillaume.jacquet@xrce.xerox.com   
 Abstract   
 We propose a system which builds, in a semi-supervised manner, a resource that aims at helping a NER system to annotate corpus-specific named entities.
 This system is based on a distributional approach which uses syntactic dependencies for measuring similarities between named entities.
 The specificity of the presented method however, is to combine a clique-based approach and a clustering technique that amounts to a soft clustering method.
 Our experiments show that the resource constructed by using this cliquebased clustering system allows to improve different NER systems.   
 1 Introduction   
 In Information Extraction domain, named entities( NEs) are one of the most important textual units as they express an important part of the meaning of a document.
 Named entity recognition( NER) is not a new domain( see MUC1 and ACE2 conferences) but some new needs appeared concerning NEs processing.
 For instance the NE Oxford illustrates the different ambiguity types that are interesting to address:   • intraannotation ambiguity: Wikipedia lists more than 25 cities named Oxford in the world• systematic interannotation ambiguity: the name of cities could be used to refer to the university of this city or the football club of this city.
 This is the case for Oxford or Newcastle• non-systematic interannotation ambiguity:    Oxford is also a company unlike Newcastle.
 The main goal of our system is to act in a complementary way with an existing NER system, in order to enhance its results.
 We address two kinds    1http://wwwnlpir.nist.gov/ related projects/ muc/ 2http://www.nist.gov/ speech/ tests/ ace    of issues: first, we want to detect and correctly annotate corpus-specific NEs3 that the NER system could have missed; second, we want to correct some wrong annotations provided by the existing NER system due to ambiguity.
 In section 3, we give some examples of such corrections.
 The paper is organized as follows.
 We present, in section 2, the global architecture of our system and from§ 2.1 to§ 2.6, we give details about each of its steps.
 In section 3, we present the evaluation of our approach when it is combined with other classic NER systems.
 We show that the resulting hybrid systems perform better with respect to F-measure.
 In the best case, the latter increased by 4.84 points.
 Furthermore, we give examples of successful correction of NEs annotation thanks to our approach.
 Then, in section 4, we discuss about related works.
 Finally we sum up the main points of this paper in section 5.   
 2 Description of the system    Given a corpus, the main objectives of our system are: to detect potential NEs; to compute the possible annotations for each NE and then; to annotate each occurrence of these NEs with the right annotation by analyzing its local context.
 We assume that this corpus dependent approach allows an easier NE annotation.
 Indeed, even if a NE such as Oxford can have many annotation types, it will certainly have less annotation possibilities in a specific corpus.
 Figure 1 presents the global architecture of our system.
 The most important part concerns steps 3(§ 2.3) and 4(§ 2.4).
 The aim of these subprocesses is to group NEs which have the same annotation with respect to a given context.
 On the one hand, clique-based methods( see§ 2.3 for    3In
 our definition a corpus-specific NE is the one which does not appear in a classic NEs lexicon.
 Recent news articles for instance, are often constituted of NEs that are not in a classic NEs lexicon.   
 Proceedings of the 12th Conference of the European Chapter of the ACL, pages 51–59, Athens, Greece, 30 March– 3 April 2009.
 c � 2009 Association for Computational Linguistics    51   
 Figure 1:
 General description of our system    details on cliques) are interesting as they allow the same NE to be in different cliques.
 In other words, cliques allow to represent the different possible annotations of a NE.
 The clique-based approach drawback however, is the over production of cliques which corresponds to an artificial over production of possible annotations for a NE.
 On the other hand, clustering methods aim at structuring a data set and such techniques can be seen as data compression processes.
 However, a simple NEs hard clustering does n’t allow a NE to be in several clusters and thus to express its different annotations.
 Then, our proposal is to combine both methods in a clique-based clustering framework.
 This combination leads to a softclustering approach that we denote CBC system.
 The following paragraphs, from 2.1 to 2.6, describe the respective steps mentioned in Figure 1.
 relation with a noun as governee argument( e.g.    attribute president −−−−→ George Bush)   • a governee argument of a modifier syntactic relation with a noun as a governor argument(
 e.g.    modifier company ←−−−− Coca-Cola).   
 The list of potential NEs extracted from the corpus will be denoted NE and the number of NEs |NE|.   
 2.2 Distributional space of NEs    The distributional approach aims at evaluating a distance between words based on their syntactic distribution.
 This method assumes that words which appear in the same contexts are semantically similar( Harris, 1951).
 To construct the distributional space associated to a corpus, we use a robust parser( in our experiments, we used XIP parser( Ait et al., 2002)) to extract chunks( i.e. nouns, noun phrases,...) and syntactic dependencies between these chunks.
 Given this parser ’s output, we identify triple instances.
 Each triple has the form w1.R.w2 where w1 and w2 are chunks and R is a syntactic relation( Lin, 1998),
( Kilgarriff et al., 2004).
 One triple gives two contexts( 1.w1.R and 2.w2.R) and two chunks( w1 and w2).
 Then, we only select chunks w which belong to NE.
 Each point in the distributional space is a NE and each dimension is a syntactic context.
 CT denotes the set of all syntactic contexts and |CT |represents its cardinal.
 We illustrate this construction on the sentence“ provide Albania with food aid”.
 We obtain the three following triples( note that aid and food aid are considered as two different chunks): provide VERB•IOBJ•Albania NOUN provide VERB•PREP WITH•aid
 NOUN provide VERB•PREP WITH•food aid NP From these triples, we have the following chunks and contexts4:    Chunks:
 Contexts:    2.1 Detection of potential Named Entities    Different methods exist for detecting potential NEs.
 In our system, we used some lexicosyntactic constraints to extract expressions from a corpus because it allows to detect some corpusspecific NEs.
 In our approach, a potential NE is a noun starting with an upper-case letter or a noun phrase which is( see( Ehrmann and Jacquet, 2007) for similar use):   
• a governor argument of an attribute syntactic    1.provide VERB.IOBJ 1.provide VERB.PREP WITH
 2.Albania NOUN.IOBJ 2.aid NOUN.PREP WITH 2.food aid NP.PREP WITH
 According to the NEs detection method described previously, we only keep the chunks and contexts which are in bold in the above table.
 4In
 the context 1.VERB:
 provide.
 IOBJ, the figure
 1 means that the verb provide is the governor argument of the Indirect OBJect relation.
 provide VERB Albania NOUN aid NOUN food aid NP    52   
 We also use an heuristic in order to reduce the over production of chunks and contexts: in our experiments for example, each NE and each context should appear more than 10 times in the corpus for being considered.
 D is the resulting( |NE |x |CT|) NEContext matrix where ei: i = 1,..., |NE |is a NE and    cj: j = 1,..., |CT |is a syntactic context.
 Then we have: D(ei, cj) =
 Nb. of occ.
 of cj associated to ei( 1)    2.3 Cliques of NEs computation   
 A clique in a graph is a set of pairwise adjacent nodes which is equivalent to a complete subgraph.
 A maximal clique is a clique that is not a subset of any other clique.
 Maximal cliques computation was already employed for semantic space representation( Ploux and Victorri, 1998).
 In this work, cliques of lexical units are used to represent a precise meaning.
 Similarly, we compute cliques of NEs in order to represent a precise annotation.
 For example, Oxford is an ambiguous NE but a clique such as < Cambridge, Oxford, Edinburgh University, Edinburgh, Oxford University > allows to focus on the specific annotation < organization >( see( Ehrmann and Jacquet, 2007) for similar use).
 Given the distributional space described in the previous paragraph, we use a probabilistic framework for computing similarities between NEs.
 The approach that we propose is inspired from the language modeling framework introduced in the information retrieval field( see for example( Lavrenko and Croft, 2003)).
 Then, we construct cliques of NEs based on these similarities.   
 2.3.1 Similarity measures between NEs   
 We first compute the maximum likelihood estimation for a NE ei to be associated with a con</bodyText >   text cj: Pml(cj|ei) = D(ei, cj), where |ei |= |ei P|CT|    j=1 D(ei, cj) is the total occurrences of the NE ei in the corpus.
 This leads to sparse data which is not suitable for measuring similarities.
 In order to counter this problem, we use the Jelinek-Mercer smoothing method: D0(ei, cj) = λPml(cj|ei) +( 1 − λ)Pml(cj|CORP) where CORP is the corpus and    Pml( cj   |CORP) =
 Ei D(ee, cj).
 In our experiEi, j i, cj)    ments we took λ = 0.5.
 Given D0, we then use the crossentropy as a similarity measure between NEs.
 Let us denote by    s this similarity matrix, we have: Xs(ei, e0i) = − D0(ei, cj) log(D0(ei0, cj))
( 2) cj∈CT   
 2.3.2
 From similarity matrix to adjacency matrix Next, we convert s into an adjacency matrix denoted s.
 In a first step, we binarize s as follows.
 Let us denote fei1,..., ei|NE|}, the list of NEs ranked according to the descending order of their similarity with ei.
 Then, L(ei) is the list of NEs which are considered as the nearest neighbors of ei according to the following definition:    L(ei) =
( 3) Pp i0=1 s(ei, ei i0) fei 1,...
, ei p: |NE | < a; p < b} Pi0=1 s(ei, ei0)    where a E[ 0, 1] and b E f1,..., |NE|}. L(ei) gathers the most significant nearest neighbors of ei by choosing the ones which bring the a most relevant similarities providing that the neighborhood ’s size does n’t exceed b.
 This approach can be seen as a flexible k-nearest neighbor method.
 In our experiments we chose a = 20% and b = 10.
 Finally, we symmetrize the similarity matrix as follows and we obtain s: ~ 1 if ei0 E L(ei) or ei E L(ei0)    s(ei, ei0) =
( 4) 0 otherwise    2.3.3 Cliques computation   
 Given s, the adjacency matrix between NEs, we compute the set of maximal cliques of NEs denoted CLI.
 Then, we construct the matrix T of general term:    ~ T cli 1 if ei E clik 5( k, e Z) = 0
 otherwise()    where clik is an element of CLI.
 T will be the input matrix for the clustering method.
 In the following, we also use clik for denoting the vector represented by( T(clik, e1),..., T(clik, e|NE|)).
 Figure 2 shows some cliques which contain Oxford that we can obtain with this method.
 This figure also illustrates the over production of cliques since at least cli8, cli10 and cli12 can be annotated as < organization>.    53    Figure 2: Examples of cliques containing Oxford    2.4 Cliques clustering   
 We use a clustering technique in order to group cliques of NEs which are mutually highly similar.
 The clusters of cliques which contain a NE allow to find the different possible annotations of this NE.
 This clustering technique must be able to construct“ pure” clusters in order to have precise annotations.
 In that case, it is desirable to avoid fixing the number of clusters.
 That ’s the reason why we propose to use the Relational Analysis approach described below.   
 2.4.1
 The Relational Analysis approach   
 We propose to apply the Relational Analysis approach( RA) which is a clustering model that does n’t require to fix the number of clusters( Michaud and Marcotorchino, 1980),( B´ed´ecarrax and Warnesson, 1989).
 This approach takes as input a similarity matrix.
 In our context, since we want to cluster cliques of NEs, the corresponding similarity matrix S between cliques is given by the dot products matrix taken from T: S = T· T0.
 The general term of this similarity matrix is: S(clik, clik0) =
 Skk0 =( clik, clik0).
 Then, we want to maximize the following clustering function:    0(S, X) =
( 6) E(k00,k000)∈S+ Sk00k000 Skk0 − |S+| � N., �
 contkk0   
 where S+ ={( clik, clik0): Skk0 >
 0}.
 In other words, clik and clik0 have more chances to be in the same cluster providing that their similarity measure, Skk0, is greater or equal to the mean average of positive similarities.   
 X is the solution we are looking for.
 It is a binary relational matrix with general term:
 Xkk0 = 1, if clik is in the same cluster as clik0; and Xkk0 = 0, otherwise.
 X represents an equivalence relation.
 Thus, it must respect the following properties:• binarity: Xkk0 E{ 0,1}; bk, k0,• reflexivity: Xkk = 1; bk,• symmetry: Xkk0 − Xk0k = 0; bk, k0,• transitivity: Xkk0 + Xk0k00 − Xkk00: 5 1; bk, k0, k00.   
 As the objective function is linear with respect to X and as the constraints that X must respect are linear equations, we can solve the clustering problem using an integer linear programming solver.
 However, this problem is NP-hard.
 As a result, in practice, we use heuristics for dealing with large data sets.   
 2.4.2
 The Relational Analysis heuristic   
 The presented heuristic is quite similar to another algorithm described in( Hartigan, 1975) known as the“ leader
” algorithm.
 But unlike this last approach which is based upon euclidean distances and inertial criteria, the RA heuristic aims at maximizing the criterion given in( 6).
 A sketch of this heuristic is given in Algorithm 1,( see( Marcotorchino and Michaud, 1981) for further details).   
 Algorithm 1 RA heuristic Require: nbitr = number of iterations; rcm. =
 maximal number of clusters; S the similarity matrix E( k k0)∈S+ Skk0
 |S+|    Take the first clique clik as the first element of the first cluster rc = 1 where rc is the current number of cluster for q = 1 to nbitr do for k = 1 to JCLHJ do for l = 1 to rc
 do Compute the contribution of clique clik with cluster clul: contl = Eclik0
 ∈clul( Skk0 − m)    end for   
 clul∗ is the cluster i d which has the highest contribution with clique clik and contl∗ is the corresponding    contribution value if( contl∗ <( Skk − m)) n( rc < rcm.)
 then Create a new cluster where clique clik is the first element and rc +— rc + 1 else Assign clique clik to cluster clul∗ if the cluster where was taken clik before its new assignment, is empty then rc +— rc − 1    end if end if end for end for   
 We have to provide a number of iterations    |CLI| �
 k, k0=1 Xkk0 m
 +—    54    or/ and a delta threshold in order to have an approximate solution in a reasonable processing time.
 Besides, it is also required a maximum number of clusters but since we do n’t want to fix this parameter, we put by default κmax = |CLI|.
 Basically, this heuristic has a O(nbitr xκmax x |CLI|) computation cost.
 In general terms, we can assume that nbitr < < |CLI|, but not κmax < < |CLI|.
 Thus, in the worst case, the algorithm has    a O(κmax x |CLI|) computation cost.   
 Figure 3 gives some examples of clusters of cliques5 obtained using the RA approach.
 Figure 3: Examples of clusters of cliques( only the NEs are represented) and their associated contexts    2.5 NE resource construction using the CBC system
 ’s outputs   
 Now, we want to exploit the clusters of cliques in order to annotate NE occurrences.
 Then, we need to construct a NE resource where for each pair( NE x syntactic context) we have an annotation.
 To this end, we need first, to assign a cluster to each pair( NE x syntactic context)(§ 2.5.1) and second, to assign each cluster an annotation(§ 2.5.2).
 2.5.1 Cluster assignment to each pair( NE x syntactic context)
 For each cluster clul we provide a score Fc(cj, clul) for each context cj and a score 5We only represent the NEs and their frequency in the cluster which corresponds to the number of cliques which contain the NEs.
 Furthermore, we represent the most relevant contexts for this cluster according to equation( 7) introduced in the following.
 Fe(ei, clul) for each NE ei.
 These scores6 are given by:    Fc(cj, clul) =
( 7) D(ei, cj) E|S
 |D(e• C �)
 � 1{ D(ei, cj)
 � 0} i=1 a � 7 eiEclul where 1{P} equals 1 if P is true and 0 otherwise.
 Fe(ei, clul) =
#( clul, ei)( 8)    Given a NE ei and a syntactic context cj, we now introduce the contextual cluster assignment matrix Actxt(ei, cj) as follows: Actxt(ei, cj) =
 clu* where: clu* = Argmax{clul: clulE)ei;F,(ei, clul)>1}Fc(cj, clul).
 In other words, clu* is the cluster for which we find more than one occurrence of ei and the highest score related to the context cj.
 Furthermore, we compute a default cluster assignment matrix Adef, which does not depend on the local context: Adef(ei) =
 clu
* where: clu* = Argmax{clul: clulE){clik: clikE)ei}}|clik|.
 In other words, clu* is the cluster containing the biggest clique clik containing ei.   
 2.5.2
 Clusters annotation   
 So far, the different steps that we have introduced were unsupervised.
 In this paragraph, our aim is to give a correct annotation to each cluster( hence, to all NEs in this cluster).
 To this end, we need some annotation seeds and we propose two different semi-supervised approaches( regarding the classification given in( Nadeau and Sekine, 2007)).
 The first one is the manual annotation of some clusters.
 The second one proposes an automatic cluster annotation and assumes that we have some NEs that are already annotated.
 Manual annotation of clusters
 This method is fastidious but it is the best way to match the corpus data with a specific guidelines for annotating NEs.
 It also allows to identify new types of annotation.
 We used the ACE2007 guidelines for manually annotating each cluster.
 However, our CBC system leads to a high number of clusters of cliques and we ca n’t annotate each of them.
 Fortunately, it also leads to a distribution of the clusters’ size( number of cliques by cluster) which is    6For data fusion tasks in information retrieval field, the scoring method in equation( 7) is denoted CombMNZ( Fox and Shaw, 1994).
 Other scoring approaches can be used see for example( Cucchiarelli and Velardi, 2001).   
 �
 ei �
 clul    55    similar to a Zipf distribution.
 Consequently, in our experiments, if we annotate the 100 biggest clusters, we annotate around eighty percent of the detected NEs( see§ 3).
 Automatic annotation of clusters We suppose in this context that many NEs in NE are already annotated.
 Thus, under this assumption, we have in each cluster provided by the CBC system, both annotated and nonannotated NEs.
 Our goal is to exploit the available annotations for refining the annotation of a cluster by implicitly taking into account the syntactic contexts and for propagating the available annotations to NEs which have no annotation.
 Given a cluster clue of cliques,#( clue, ei) is the weight of the NE ei in this cluster: it is the number of cliques in clue that contain ei.
 For all annotations ap in the set of all possible annotations AN, we compute its associated score in cluster clue: it is the sum of the weights of NEs in clue that is annotated ap.
 Then, if the maximal annotation score is greater than a simple majority( half) of the total votes7, we assign the corresponding annotation to the cluster.
 We precise that the annotation < none>8 is processed in the same way as any other annotations.
 Thus, a cluster can be globally annotated < none>.
 The limit of this automatic approach is that it does n’t allow to annotate new NE types than the ones already available.
 In the following, we will denote by Aclu(clue) the annotation of the cluster clue.
 The cluster annotation matrix Aclu associated to the contextual cluster assignment matrix Aetxt and the default cluster assignment matrix Adef introduced previously will be called the CBC system ’s NE resource( or shortly the NE resource).
 2.6 NEs annotation processes using the NE resource In this paragraph, we describe how, given the CBC system ’s NE resource, we annotate occurrences of NEs in the studied corpus with respect to its local context.
 We precise that for an occurrence of a NE ei its associated local context is the set of syntactical dependencies cj in which ei is involved.   
 7The //total votes number is given by EegEclul# lclul, ei).
 8The NEs which do n’t have any annotation.   
 2.6.1 NEs annotation process for the CBC system
 Given a NE occurrence and its local context we can use Aetxt(ei, cj) and Adef(ei) in order to get the default annotation Aclu(Adef(ei)) and the list of contextual annotations{ Aclu(Aetxt(ei, cj))}j.
 Then for annotating this NE occurrence using our NE resource, we apply the following rules:   • if the list of contextual annotations{ Aclu(Aetxt(ei, cj))}j is conflictual, we annotate the NE occurrence as < none >,• if the list of contextual annotations is nonconflictual, then we use the corresponding annotation to annotate the NE occurrence• if the list of contextual annotations is empty, we use the default annotation Aclu(Adef(ei)).
 The NE resource plus the annotation process described in this paragraph lead to a NER system based on the CBC system.
 This NER system will be called CBCNER system and it will be tested in our experiments both alone and as a complementary resource.   
 2.6.2 NEs annotation process for an hybrid system
 We place ourselves into an hybrid situation where we have two NER systems( NER 1 + NER 2) which provide two different lists of annotated NEs.
 We want to combine these two systems when annotating NEs occurrences.
 Therefore, we resolve any conflicts by applying the following rules:   •
 If the same NE occurrence has two different annotations from the two systems then there are two cases.
 If one of the two system is CBCNER system then we take its annotation; otherwise we take the annotation provided by the NER system which gave the best precision.
•
 If a NE occurrence is included in another one we only keep the biggest one and its annotation.
 For example, if Jacques Chirac is annotated < person > by one system and Chirac by < person > by the other system, then we only keep the first annotation.
•
 If two NE occurrences are contiguous and have the same annotation, we merge the two NEs in one NE occurrence.   
 3 Experiments   
 The system described in this paper rather target corpus-specific NE annotation.
 Therefore, our ex</bodyText >   56    periments will deal with a corpus of recent news articles( see( Shinyama and Sekine, 2004) for motivations regarding our corpus choice) rather than well-known annotated corpora.
 Our corpus is constituted of news in English published on the web during two weeks in June 2008.
 This corpus is constituted of around 300,000 words( 10Mb) which does n’t represent a very large corpus.
 These texts were taken from various press sources and they involve different themes( sports, technology,...).
 We extracted randomly a subset of articles and manually annotated 916 NEs( in our experiments, we deal with three types of annotation namely < person >, < organization > and < location >).
 This subset constitutes our test set.
 In our experiments, first, we applied the XIP parser( Ait et al., 2002) to the whole corpus in order to construct the frequency matrix D given by( 1).
 Next, we computed the similarity matrix between NEs according to( 2) in order to obtain s defined by( 4).
 Using the latter, we computed cliques of NEs that allow us to obtain the assignment matrix T given by( 5).
 Then we applied the clustering heuristic described in Algorithm 1.
 At this stage, we want to build the NE resource using the clusters of cliques.
 Therefore, as described in§ 2.5, we applied two kinds of clusters annotations: the manual and the automatic processes.
 For the first one, we manually annotated the 100 biggest clusters of cliques.
 For the second one, we exploited the annotations provided by XIP NER(
 Brun and Hag`ege, 2004) and we propagated these annotations to the different clusters( see§ 2.5.2).
 The different materials that we obtained constitute the CBC system ’s NE resource.
 Our aim now is to exploit this resource and to show that it allows to improve the performances of different classic NER systems.
 The different NER systems that we tested are the following ones:   
•
 CBCNER system M( in short CBC M) based on the CBC system ’s NE resource using the manual cluster annotation( line 1 in Table 1),•
 CBCNER system A( in short CBC A) based on the CBC system ’s NE resource using the automatic cluster annotation( line 1 in Table 1),• XIP NER or in short XIP( Brun and Hag`ege, 2004)( line 2 in Table 1),
•
 Stanford NER( or in short Stanford) associated to the following model provided by the tool and which was trained on different news    Systems Prec.
 Rec.
 F-me.
 1 CBCNER system M 71.67
 23.47 35.36 CBCNER system
 A 70.66 32.86 44.86 2 XIP NER 77.77 56.55 65.48 XIP + CBC M 78.41 60.26 68.15 XIP +
 CBC A 76.31 60.48 67.48 Stanford NER 67.94 68.01
 67.97 3 Stanford + CBC M 69.40 71.07 70.23 Stanford + CBC A
 70.09 72.93 71.48 GATE NER
 63.30 56.88
 59.92 4 GATE + CBC M 66.43 61.79 64.03 GATE +
 CBC A 66.51 63.10 64.76 5 Stanford + XIP 72.85 75.87 74.33 Stanford + XIP + CBC M 72.94 77.70 75.24 Stanford + XIP + CBC A 73.55 78.93 76.15 GATE + XIP 69.38 66.04 67.67 6 GATE + XIP + CBC M 69.62 67.79 68.69 GATE + XIP +
 CBC A 69.87 69.10 69.48 GATE + Stanford 63.12 69.32 66.07 7 GATE + Stanford + CBC M
 65.09 72.05 68.39 GATE + Stanford + CBC A 65.66 73.25 69.25    Table 1: Results given by different hybrid NER systems and coupled with the CBCNER system    corpora( CoNLL, MUC6, MUC7 and ACE): ner-eng-ie.crf-3-all2008-distsim.ser.gz( Finkel et al., 2005)
( line 3 in Table 1),   • GATE NER or in short GATE
( Cunningham et al., 2002)
( line 4 in Table 1),• and
 several hybrid systems which are given by    the combination of pairs taken among the set of the three last-mentioned NER systems( lines 5 to 7 in Table 1).
 Notice that these baseline hybrid systems use the annotation combination process described in§ 2.6.1.
 In Table 1 we first reported in each line, the results given by each system when they are applied alone( figures in italics).
 These performances represent our baselines.
 Second, we tested for each baseline system, an extended hybrid system that integrates the CBCNER systems( with respect to the combination process detailed in§ 2.6.2).
 The first two lines of Table 1 show that the two CBCNER systems alone lead to rather poor results.
 However, our aim is to show that the CBCNER system is, despite its low performances alone, complementary to other basic NER systems.
 In other words, we want to show that the exploitation of the CBC system ’s NE resource is beneficial and non-redundant compared to other baseline NER systems.
 This is actually what we obtained in Table 1 as for each line from 2 to 7, the extended hybrid systems that integrate the CBCNER systems( M or    57    A) always perform better than the baseline either in terms of precision9 or recall.
 For each line, we put in bold the best performance according to the F-measure.
 These results allow us to show that the NE resource built using the CBC system is complementary to any baseline NER systems and that it allows to improve the results of the latter.
 In order to illustrate why the CBCNER systems are beneficial, we give below some examples taken from the test corpus for which the CBC system A had allowed to improve the performances by respectively disambiguating or correcting a wrong annotation or detecting corpus-specific NEs.
 First, in the sentence“ From the start, his parents, Lourdes and Hemery, were with him.
”, the baseline hybrid system Stanford + XIP annotated the ambiguous NE“ Lourdes” as < location > whereas Stanford + XIP + CBC A gave the correct annotation < person>.
 Second, in the sentence“ Got 3 percent chance of survival, what ya gon na do?
”
 The back read,” A)
 Fight Through, b)
 Stay Strong, c)
 Overcome
 Because I Am a Warrior.
”, the baseline hybrid system Stanford + XIP annotated“ Warrior” as < organization > whereas Stanford + XIP + CBC A corrected this annotation with < none>.
 Finally, in the sentence“ Matthew, also a favorite to win in his fifth and final appearance, was stunningly eliminated during the semifinal round Friday when he misspelled“
 secernent
”.
”, the baseline hybrid system Stanford + XIP did n’t give any annotation to“
 Matthew” whereas Stanford + XIP + CBC A allowed to give the annotation < person>.    4 Related works   
 Many previous works exist in NEs recognition and classification.
 However, most of them do not build a NEs resource but exploit external gazetteers( Bunescu and Pasca, 2006),( Cucerzan, 2007).
 A recent overview of the field is given in( Nadeau and Sekine, 2007).
 According to this paper, we can classify our method in the category of semi-supervised approaches.
 Our proposal is close to( Cucchiarelli and Velardi, 2001) as it uses syntactic relations(§ 2.2) and as it relies on existing NER systems(§ 2.6.2).
 However, the particularity of our method concerns the clustering of    9Except for XIP+CBC A in line 2 where the precision is slightly lower than XIP ’s one.   
 cliques of NEs that allows both to represent the different annotations of the NEs and to group the latter with respect to one precise annotation according to a local context.
 Regarding this aspect,( Lin and Pantel, 2001) and( Ngomo, 2008) also use a clique computation step and a clique merging method.
 However, they do not deal with ambiguity of lexical units nor with NEs.
 This means that, in their system, a lexical unit can be in only one merged clique.
 From a methodological point of view, our proposal is also close to( Ehrmann and Jacquet, 2007) as the latter proposes a system for NEs finegrained annotation, which is also corpus dependent.
 However, in the present paper we use all syntactic relations for measuring the similarity between NEs whereas in the previous mentioned work, only specific syntactic relations were exploited.
 Moreover, we use clustering techniques for dealing with the issue related to over production of cliques.
 In this paper, we construct a NE resource from the corpus that we want to analyze.
 In that context,( Pasca, 2004) presents a lightly supervised method for acquiring NEs in arbitrary categories from unstructured text of Web documents.
 However, Pasca wants to improve web search whereas we aim at annotating specific NEs of an analyzed corpus.
 Besides, as we want to focus on corpus-specific NEs, our work is also related to( Shinyama and Sekine, 2004).
 In this work, the authors found a significant correlation between the similarity of the time series distribution of a word and the likelihood of being a NE.
 This result motivated our choice to test our approach on recent news articles rather than on well-known annotated corpora.   
 5 Conclusion   
 We propose a system that allows to improve NE recognition.
 The core of this system is a cliquebased clustering method based upon a distributional approach.
 It allows to extract, analyze and discover highly relevant information for corpusspecific NEs annotation.
 As we have shown in our experiments, this system combined with another one can lead to strong improvements.
 Other applications are currently addressed in our team using this approach.
 For example, we intend to use the concept of clique-based clustering as a soft clustering method for other issues.   
 58   
 References    S. Ait, J.P. Chanod, and C. Roux.
 2002.
 Robustness beyond shallowness: incremental dependency parsing.
 NLE Journal.
 C. B´ed´ecarrax and I. Warnesson.
 1989.
 Relational analysis and dictionnaries.
 In Proceedings of ASMDA 1988, pages 131–151.
 Wiley, London, NewYork.
 C. Brun and C. Hag`ege.
 2004.
 Intertwining deep syntactic processing and named entity detection.
 In Proceedings of ESTAL 2004, Alicante, Spain.
 R. Bunescu and M. Pasca.
 2006.
 Using encyclopedic knowledge for named entity disambiguation.
 In Proceedings of EACL 2006.
 A. Cucchiarelli and P. Velardi.
 2001.
 Unsupervised Named Entity Recognition using syntactic and semantic contextual evidence.
 Computational Linguistics, 27(1).
 S. Cucerzan.
 2007.
 Large-scale named entity disambiguation based on wikipedia data.
 In Proceedings of EMNLP/ CoNLL 2007, Prague, Czech Republic.
 H. Cunningham, D. Maynard, K. Bontcheva, and V. Tablan.
 2002.
 GATE:
 A framework and graphical development environment for robust NLP tools and applications.
 In Proceedings ofACL 2002, Philadelphia.
 M. Ehrmann and G. Jacquet.
 2007.
 Vers une double annotation des entit´es nomm´ees.
 TraitementAutomatique des Langues, 47(3).
 J.R. Finkel, T. Grenager, and C. Manning.
 2005.
 Incorporating non-local information into information extraction systems by gibbs sampling.
 In Proceedings of ACL 2005.
 E.A. Fox and J.A. Shaw.
 1994.
 Combination of multiple searches.
 In Proceedings of the 3rd NIST TREC Conference, pages 105–109.
 Z. Harris.
 1951.
 Structural Linguistics.
 University of Chicago Press.
 J.A. Hartigan.
 1975.
 Clustering Algorithms.
 John Wiley and Sons.
 A. Kilgarriff, P. Rychly, P. Smr, and D. Tugwell.
 2004.
 The sketch engine.
 In In Proceedings of EURALEX 2004.
 V. Lavrenko and W.B. Croft.
 2003.
 Relevance models in information retrieval.
 In W.B. Croft and J. Lafferty( Eds), editors, Language modeling in information retrieval.
 Springer.
 D. Lin and P. Pantel.
 2001.
 Induction of semantic classes from natural language text.
 In Proceedings of ACM SIGKDD.
 D. Lin.
 1998.
 Using collocation statistics in information extraction.
 In Proceedings of MUC-7.
 J.F. Marcotorchino and P. Michaud.
 1981.
 Heuristic approach of the similarity aggregation problem.
 Methods of operation research, 43:395–404.
 P. Michaud and J.F. Marcotorchino.
 1980.
 Optimisation en analyse de donn´ees relationnelles.
 In Data Analysis and informatics.
 North Holland Amsterdam.
 D. Nadeau and S. Sekine.
 2007.
 A survey of Named Entity Recognition and Classification.
 Lingvisticae Investigationes, 30(1).
 A. C. Ngonga Ngomo.
 2008.
 Signum a graph algorithm for terminology extraction.
 In Proceedings of CICLING 2008, Haifa, Israel.
 M. Pasca.
 2004.
 Acquisition of categorized named entities for web search.
 In Proceedings of CIKM 2004, New York, NY, USA.
 S. Ploux and B. Victorri.
 1998.
 Construction d’espaces s´emantiques a ` l’aide de dictionnaires de synonymes.
 TAL, 39(1).
 Y. Shinyama and S. Sekine.
 2004.
 Named Entity Discovery using comparable news articles.
 In Proceedings of COLING 2004, Geneva.    59      
 Clique-Based Clustering for improving Named Entity Recognition systems Julien Ah-Pine Xerox Research Centre Europe 6, chemin de Maupertuis 38240 Meylan, France julien.ah-pine@xrce.xerox.com
 Guillaume Jacquet Xerox Research Centre Europe 6, chemin de Maupertuis 38240 Meylan, France guillaume.jacquet@xrce.xerox.com
 We propose a system which builds, in a semi-supervised manner, a resource that aims at helping a NER system to annotate corpus-specific named entities.
 This system is based on a distributional approach which uses syntactic dependencies for measuring similarities between named entities.
 The specificity of the presented method however, is to combine a clique-based approach and a clustering technique that amounts to a soft clustering method.
 Our experiments show that the resource constructed by using this cliquebased clustering system allows to improve different NER systems.       
 S Ait J P Chanod C Roux   Robustness beyond shallowness: incremental dependency parsing.
 2002 NLE Journal.  
 overnee argument of a modifier syntactic relation with a noun as a governor argument( e.g. modifier company
 ←−−−− Coca-Cola).
 The list of potential NEs extracted from the corpus will be denoted NE and the number of NEs |NE|.
 2.2 Distributional space of NEs
 The distributional approach aims at evaluating a distance between words based on their syntactic distribution.
 This method assumes that words which appear in the same contexts are semantically similar( Harris, 1951).
 To construct the distributional space associated to a corpus, we use a robust parser( in our experiments, we used XIP parser( Ait et al., 2002)) to extract chunks( i.e. nouns, noun phrases,...) and syntactic dependencies between these chunks.
 Given this parser ’s output, we identify triple instances.
 Each triple has the form w1.R.w2 where w1 and w2 are chunks and R is a syntactic relation( Lin, 1998),
( Kilgarriff et al., 2004).
 One triple gives two contexts( 1.w1.R and 2.w2.R) and two chunks( w1 and w2).
 Then, we only select chunks w which belong to NE.
 Each point in the distributional space is a NE and each dimension is a syntactic context.
 CT denotes the set of all syntactic contexts and |CT |represents its cardinal.
 We illustrate ted corpora.
 Our corpus is constituted of news in English published on the web during two weeks in June 2008.
 This corpus is constituted of around 300,000 words( 10Mb) which does n’t represent a very large corpus.
 These texts were taken from various press sources and they involve different themes( sports, technology,...).
 We extracted randomly a subset of articles and manually annotated 916 NEs( in our experiments, we deal with three types of annotation namely < person >, < organization > and < location >).
 This subset constitutes our test set.
 In our experiments, first, we applied the XIP parser( Ait et al., 2002) to the whole corpus in order to construct the frequency matrix D given by( 1).
 Next, we computed the similarity matrix between NEs according to( 2) in order to obtain s defined by( 4).
 Using the latter, we computed cliques of NEs that allow us to obtain the assignment matrix T given by( 5).
 Then we applied the clustering heuristic described in Algorithm 1.
 At this stage, we want to build the NE resource using the clusters of cliques.
 Therefore, as described in§ 2.5, we applied two kinds of clusters annotations: the manual and the automatic processes.
 For the first one, we manually annotated t   Ait, Chanod, Roux, 2002
 S. Ait, J.P. Chanod, and C. Roux.
 2002.
 Robustness beyond shallowness: incremental dependency parsing.
 NLE Journal.    
 C B´ed´ecarrax
 I Warnesson   Relational analysis and dictionnaries.
 1989
 In Proceedings of ASMDA 1988, 131-151 Wiley, London, NewYork.
 B´ed´ecarrax, Warnesson, 1989 C. B´ed´ecarrax and I. Warnesson.
 1989.
 Relational analysis and dictionnaries.
 In Proceedings of ASMDA 1988, pages 131–151.
 Wiley, London, NewYork.    
 C Brun C Hag`ege  
 Intertwining deep syntactic processing and named entity detection.
 2004
 In Proceedings of ESTAL 2004, Alicante, Brun, Hag`ege, 2004 C. Brun and C. Hag`ege.
 2004.
 Intertwining deep syntactic processing and named entity detection.
 In Proceedings of ESTAL 2004, Alicante, Spain.    
 R Bunescu M Pasca   Using encyclopedic knowledge for named entity disambiguation.
 2006
 In Proceedings of EACL   rrior” as < organization > whereas Stanford + XIP + CBC A corrected this annotation with < none>.
 Finally, in the sentence“ Matthew, also a favorite to win in his fifth and final appearance, was stunningly eliminated during the semifinal round Friday when he misspelled“
 secernent
”.
”, the baseline hybrid system Stanford + XIP did n’t give any annotation to“
 Matthew” whereas Stanford + XIP + CBC A allowed to give the annotation < person>.
 4 Related works Many previous works exist in NEs recognition and classification.
 However, most of them do not build a NEs resource but exploit external gazetteers( Bunescu and Pasca, 2006),( Cucerzan, 2007).
 A recent overview of the field is given in( Nadeau and Sekine, 2007).
 According to this paper, we can classify our method in the category of semi-supervised approaches.
 Our proposal is close to( Cucchiarelli and Velardi, 2001) as it uses syntactic relations(§ 2.2) and as it relies on existing NER systems(§ 2.6.2).
 However, the particularity of our method concerns the clustering of 9Except for XIP+CBC A in line 2 where the precision is slightly lower than XIP ’s one.
 cliques of NEs that allows both to represent the different annotations of the NEs and to group the latter with   Bunescu, Pasca, 2006 R. Bunescu and M. Pasca.
 2006.
 Using encyclopedic knowledge for named entity disambiguation.
 In Proceedings of EACL 2006.    
 A Cucchiarelli P Velardi   Unsupervised Named Entity Recognition using syntactic and semantic contextual evidence.
 2001 Computational Linguistics, 27 1   best way to match the corpus data with a specific guidelines for annotating NEs.
 It also allows to identify new types of annotation.
 We used the ACE2007 guidelines for manually annotating each cluster.
 However, our CBC system leads to a high number of clusters of cliques and we ca n’t annotate each of them.
 Fortunately, it also leads to a distribution of the clusters’ size( number of cliques by cluster) which is 6For data fusion tasks in information retrieval field, the scoring method in equation( 7) is denoted CombMNZ( Fox and Shaw, 1994).
 Other scoring approaches can be used see for example( Cucchiarelli and Velardi, 2001).
 �
 ei � clul 55 similar to a Zipf distribution.
 Consequently, in our experiments, if we annotate the 100 biggest clusters, we annotate around eighty percent of the detected NEs( see§ 3).
 Automatic annotation of clusters We suppose in this context that many NEs in NE are already annotated.
 Thus, under this assumption, we have in each cluster provided by the CBC system, both annotated and nonannotated NEs.
 Our goal is to exploit the available annotations for refining the annotation of a cluster by implicitly taking into account the syntactic contexts and for propagating the available annotations d Friday when he misspelled“ secernent
”.
”, the baseline hybrid system Stanford + XIP did n’t give any annotation to“
 Matthew” whereas Stanford + XIP + CBC A allowed to give the annotation < person>.
 4 Related works Many previous works exist in NEs recognition and classification.
 However, most of them do not build a NEs resource but exploit external gazetteers( Bunescu and Pasca, 2006),( Cucerzan, 2007).
 A recent overview of the field is given in( Nadeau and Sekine, 2007).
 According to this paper, we can classify our method in the category of semi-supervised approaches.
 Our proposal is close to( Cucchiarelli and Velardi, 2001) as it uses syntactic relations(§ 2.2) and as it relies on existing NER systems(§ 2.6.2).
 However, the particularity of our method concerns the clustering of 9Except for XIP+CBC A in line 2 where the precision is slightly lower than XIP ’s one.
 cliques of NEs that allows both to represent the different annotations of the NEs and to group the latter with respect to one precise annotation according to a local context.
 Regarding this aspect,( Lin and Pantel, 2001) and( Ngomo, 2008) also use a clique computation step and a clique merging method.
 However, they do not deal with ambiguity of lexical u   Cucchiarelli, Velardi, 2001 A. Cucchiarelli and P. Velardi.
 2001.
 Unsupervised Named Entity Recognition using syntactic and semantic contextual evidence.
 Computational Linguistics, 27(1).    
 S Cucerzan  
 Large-scale named entity disambiguation based on wikipedia data.
 2007
 In Proceedings of EMNLP/ CoNLL 2007, Prague, Czech Republic.  
 ereas Stanford + XIP + CBC A corrected this annotation with < none>.
 Finally, in the sentence“ Matthew, also a favorite to win in his fifth and final appearance, was stunningly eliminated during the semifinal round Friday when he misspelled“
 secernent
”.
”, the baseline hybrid system Stanford + XIP did n’t give any annotation to“
 Matthew” whereas Stanford + XIP + CBC A allowed to give the annotation < person>.
 4 Related works Many previous works exist in NEs recognition and classification.
 However, most of them do not build a NEs resource but exploit external gazetteers( Bunescu and Pasca, 2006),( Cucerzan, 2007).
 A recent overview of the field is given in( Nadeau and Sekine, 2007).
 According to this paper, we can classify our method in the category of semi-supervised approaches.
 Our proposal is close to( Cucchiarelli and Velardi, 2001) as it uses syntactic relations(§ 2.2) and as it relies on existing NER systems(§ 2.6.2).
 However, the particularity of our method concerns the clustering of 9Except for XIP+CBC A in line 2 where the precision is slightly lower than XIP ’s one.
 cliques of NEs that allows both to represent the different annotations of the NEs and to group the latter with respect to one pr   Cucerzan, 2007 S. Cucerzan.
 2007.
 Large-scale named entity disambiguation based on wikipedia data.
 In Proceedings of EMNLP/ CoNLL 2007, Prague, Czech Republic.    
 H Cunningham D Maynard K Bontcheva V Tablan   GATE:
 A framework and graphical development environment for robust NLP tools and applications.
 2002
 In Proceedings ofACL 2002, Philadelphia.  
 66.51 63.10 64.76 5 Stanford + XIP 72.85 75.87 74.33 Stanford + XIP + CBC M 72.94 77.70 75.24 Stanford + XIP + CBC A 73.55 78.93 76.15 GATE + XIP 69.38 66.04 67.67 6 GATE + XIP + CBC M 69.62 67.79 68.69 GATE + XIP +
 CBC A 69.87 69.10 69.48 GATE + Stanford 63.12 69.32 66.07 7 GATE + Stanford + CBC M
 65.09 72.05 68.39 GATE + Stanford + CBC A
 65.66 73.25 69.25 Table 1: Results given by different hybrid NER systems and coupled with the CBCNER system corpora( CoNLL, MUC6, MUC7 and ACE): ner-eng-ie.crf-3-all2008-distsim.ser.gz( Finkel et al., 2005)
( line 3 in Table 1),• GATE NER or in short GATE
( Cunningham et al., 2002)
( line 4 in Table 1),• and
 several hybrid systems which are given by the combination of pairs taken among the set of the three last-mentioned NER systems( lines 5 to 7 in Table 1).
 Notice that these baseline hybrid systems use the annotation combination process described in§ 2.6.1.
 In Table 1 we first reported in each line, the results given by each system when they are applied alone( figures in italics).
 These performances represent our baselines.
 Second, we tested for each baseline system, an extended hybrid system that integrates the CBCNER systems( with respect to the combination process   Cunningham, Maynard, Bontcheva, Tablan, 2002 H. Cunningham, D. Maynard, K. Bontcheva, and V. Tablan.
 2002.
 GATE:
 A framework and graphical development environment for robust NLP tools and applications.
 In Proceedings ofACL 2002, Philadelphia.    
 M Ehrmann G Jacquet   Vers une double annotation des entit´es nomm´ees.
 2007 TraitementAutomatique des Langues, 47 3  ( note that aid and food aid are considered as two different chunks): provide VERB•IOBJ•Albania NOUN provide VERB•PREP WITH•aid
 NOUN provide VERB•PREP WITH•food aid NP From these triples, we have the following chunks and contexts4:
 Chunks: Contexts: 2.1 Detection of potential Named Entities Different methods exist for detecting potential NEs.
 In our system, we used some lexicosyntactic constraints to extract expressions from a corpus because it allows to detect some corpusspecific NEs.
 In our approach, a potential NE is a noun starting with an upper-case letter or a noun phrase which is( see( Ehrmann and Jacquet, 2007) for similar use):• a governor argument of an attribute syntactic 1.provide VERB.IOBJ 1.provide VERB.PREP WITH 2.Albania NOUN.IOBJ 2.aid NOUN.PREP WITH 2.food aid NP.PREP WITH
 According to the NEs detection method described previously, we only keep the chunks and contexts which are in bold in the above table.
 4In
 the context 1.VERB:
 provide.
 IOBJ, the figure
 1 means that the verb provide is the governor argument of the Indirect OBJect relation.
 provide VERB Albania NOUN aid NOUN food aid NP 52
 We also use an heuristic in order to reduce the over production of chunks and contexts: in our expe e adjacent nodes which is equivalent to a complete subgraph.
 A maximal clique is a clique that is not a subset of any other clique.
 Maximal cliques computation was already employed for semantic space representation( Ploux and Victorri, 1998).
 In this work, cliques of lexical units are used to represent a precise meaning.
 Similarly, we compute cliques of NEs in order to represent a precise annotation.
 For example, Oxford is an ambiguous NE but a clique such as < Cambridge, Oxford, Edinburgh University, Edinburgh, Oxford University > allows to focus on the specific annotation < organization >( see( Ehrmann and Jacquet, 2007) for similar use).
 Given the distributional space described in the previous paragraph, we use a probabilistic framework for computing similarities between NEs.
 The approach that we propose is inspired from the language modeling framework introduced in the information retrieval field( see for example( Lavrenko and Croft, 2003)).
 Then, we construct cliques of NEs based on these similarities.
 2.3.1 Similarity measures between NEs
 We first compute the maximum likelihood estimation for a NE ei to be associated with a context cj: Pml(cj|ei) = D(ei, cj), where |ei |= |ei P|CT| j=1 D(ei, cj) is the to XIP+CBC A in line 2 where the precision is slightly lower than XIP ’s one.
 cliques of NEs that allows both to represent the different annotations of the NEs and to group the latter with respect to one precise annotation according to a local context.
 Regarding this aspect,( Lin and Pantel, 2001) and( Ngomo, 2008) also use a clique computation step and a clique merging method.
 However, they do not deal with ambiguity of lexical units nor with NEs.
 This means that, in their system, a lexical unit can be in only one merged clique.
 From a methodological point of view, our proposal is also close to( Ehrmann and Jacquet, 2007) as the latter proposes a system for NEs finegrained annotation, which is also corpus dependent.
 However, in the present paper we use all syntactic relations for measuring the similarity between NEs whereas in the previous mentioned work, only specific syntactic relations were exploited.
 Moreover, we use clustering techniques for dealing with the issue related to over production of cliques.
 In this paper, we construct a NE resource from the corpus that we want to analyze.
 In that context,( Pasca, 2004) presents a lightly supervised method for acquiring NEs in arbitrary categories from unstruct   Ehrmann, Jacquet, 2007 M. Ehrmann and G. Jacquet.
 2007.
 Vers une double annotation des entit´es nomm´ees.
 TraitementAutomatique des Langues, 47(3).    
 J R Finkel T Grenager C Manning  
 Incorporating non-local information into information extraction systems by gibbs sampling.
 2005
 In Proceedings of ACL   TE NER
 63.30 56.88
 59.92 4 GATE + CBC M 66.43 61.79 64.03 GATE +
 CBC A 66.51 63.10 64.76 5 Stanford + XIP 72.85 75.87 74.33 Stanford + XIP + CBC M 72.94 77.70 75.24 Stanford + XIP + CBC A 73.55 78.93 76.15 GATE + XIP 69.38 66.04 67.67 6 GATE + XIP + CBC M 69.62 67.79 68.69 GATE + XIP +
 CBC A 69.87 69.10 69.48 GATE + Stanford 63.12 69.32 66.07 7 GATE + Stanford + CBC M
 65.09 72.05 68.39 GATE + Stanford + CBC A
 65.66 73.25 69.25 Table 1: Results given by different hybrid NER systems and coupled with the CBCNER system corpora( CoNLL, MUC6, MUC7 and ACE): ner-eng-ie.crf-3-all2008-distsim.ser.gz( Finkel et al., 2005)
( line 3 in Table 1),• GATE NER or in short GATE
( Cunningham et al., 2002)
( line 4 in Table 1),• and
 several hybrid systems which are given by the combination of pairs taken among the set of the three last-mentioned NER systems( lines 5 to 7 in Table 1).
 Notice that these baseline hybrid systems use the annotation combination process described in§ 2.6.1.
 In Table 1 we first reported in each line, the results given by each system when they are applied alone( figures in italics).
 These performances represent our baselines.
 Second, we tested for each baseline system, an extended hybrid system
 t   Finkel, Grenager, Manning, 2005 J.R. Finkel, T. Grenager, and C. Manning.
 2005.
 Incorporating non-local information into information extraction systems by gibbs sampling.
 In Proceedings of ACL 2005.    
 E A Fox J A Shaw   Combination of multiple searches.
 1994
 In Proceedings of the 3rd NIST TREC Conference, 105-109   ted.
 Manual annotation of clusters
 This method is fastidious but it is the best way to match the corpus data with a specific guidelines for annotating NEs.
 It also allows to identify new types of annotation.
 We used the ACE2007 guidelines for manually annotating each cluster.
 However, our CBC system leads to a high number of clusters of cliques and we ca n’t annotate each of them.
 Fortunately, it also leads to a distribution of the clusters’ size( number of cliques by cluster) which is 6For data fusion tasks in information retrieval field, the scoring method in equation( 7) is denoted CombMNZ( Fox and Shaw, 1994).
 Other scoring approaches can be used see for example( Cucchiarelli and Velardi, 2001).
 �
 ei � clul 55 similar to a Zipf distribution.
 Consequently, in our experiments, if we annotate the 100 biggest clusters, we annotate around eighty percent of the detected NEs( see§ 3).
 Automatic annotation of clusters We suppose in this context that many NEs in NE are already annotated.
 Thus, under this assumption, we have in each cluster provided by the CBC system, both annotated and nonannotated NEs.
 Our goal is to exploit the available annotations for refining the annotation of a cluster by implicitly t   Fox, Shaw, 1994 E.A. Fox and J.A. Shaw.
 1994.
 Combination of multiple searches.
 In Proceedings of the 3rd NIST TREC Conference, pages 105–109.    
 Z Harris   Structural Linguistics.
 1951
 University of Chicago Press.  
 ribe the respective steps mentioned in Figure 1.
 relation with a noun as governee argument( e.g. attribute president −−−−→ George Bush)• a governee argument of a modifier syntactic relation with a noun as a governor argument( e.g. modifier company
 ←−−−− Coca-Cola).
 The list of potential NEs extracted from the corpus will be denoted NE and the number of NEs |NE|.
 2.2 Distributional space of NEs
 The distributional approach aims at evaluating a distance between words based on their syntactic distribution.
 This method assumes that words which appear in the same contexts are semantically similar( Harris, 1951).
 To construct the distributional space associated to a corpus, we use a robust parser( in our experiments, we used XIP parser( Ait et al., 2002)) to extract chunks( i.e. nouns, noun phrases,...) and syntactic dependencies between these chunks.
 Given this parser ’s output, we identify triple instances.
 Each triple has the form w1.R.w2 where w1 and w2 are chunks and R is a syntactic relation( Lin, 1998),
( Kilgarriff et al., 2004).
 One triple gives two contexts( 1.w1.R and 2.w2.R) and two chunks( w1 and w2).
 Then, we only select chunks w which belong to NE.
 Each point in the distributional spac   Harris, 1951 Z. Harris.
 1951.
 Structural Linguistics.
 University of Chicago Press.    
 J A Hartigan   Clustering Algorithms.
 1975 John Wiley and Sons.  
 wing properties:• binarity: Xkk0 E{ 0,1}; bk, k0,
•
 reflexivity:
 Xkk = 1; bk,• symmetry:
 Xkk0 − Xk0k = 0; bk, k0,• transitivity: Xkk0 + Xk0k00 − Xkk00: 5 1; bk, k0, k00.
 As the objective function is linear with respect to X and as the constraints that X must respect are linear equations, we can solve the clustering problem using an integer linear programming solver.
 However, this problem is NP-hard.
 As a result, in practice, we use heuristics for dealing with large data sets.
 2.4.2
 The Relational Analysis heuristic
 The presented heuristic is quite similar to another algorithm described in( Hartigan, 1975) known as the“ leader
” algorithm.
 But unlike this last approach which is based upon euclidean distances and inertial criteria, the RA heuristic aims at maximizing the criterion given in( 6).
 A sketch of this heuristic is given in Algorithm 1,( see( Marcotorchino and Michaud, 1981) for further details).
 Algorithm 1 RA heuristic Require: nbitr = number of iterations; rcm. = maximal number of clusters; S the similarity matrix E( k k0)∈S+ Skk0
 |S+| Take the first clique clik as the first element of the first cluster rc = 1 where rc is the current number of cluster for q = 1 to nbitr do for k = 1 t   Hartigan, 1975 J.A. Hartigan.
 1975.
 Clustering Algorithms.
 John Wiley and Sons.    
 A Kilgarriff P Rychly P Smr D Tugwell   The sketch engine.
 In 2004
 In Proceedings of EURALEX   ach aims at evaluating a distance between words based on their syntactic distribution.
 This method assumes that words which appear in the same contexts are semantically similar( Harris, 1951).
 To construct the distributional space associated to a corpus, we use a robust parser( in our experiments, we used XIP parser( Ait et al., 2002)) to extract chunks( i.e. nouns, noun phrases,...) and syntactic dependencies between these chunks.
 Given this parser ’s output, we identify triple instances.
 Each triple has the form w1.R.w2 where w1 and w2 are chunks and R is a syntactic relation( Lin, 1998),
( Kilgarriff et al., 2004).
 One triple gives two contexts( 1.w1.R and 2.w2.R) and two chunks( w1 and w2).
 Then, we only select chunks w which belong to NE.
 Each point in the distributional space is a NE and each dimension is a syntactic context.
 CT denotes the set of all syntactic contexts and |CT |represents its cardinal.
 We illustrate this construction on the sentence“ provide Albania with food aid”.
 We obtain the three following triples( note that aid and food aid are considered as two different chunks): provide VERB•IOBJ•Albania NOUN provide VERB•PREP WITH•aid
 NOUN provide VERB•PREP WITH•food aid NP From these tri   Kilgarriff, Rychly, Smr, Tugwell, 2004 A. Kilgarriff, P. Rychly, P. Smr, and D. Tugwell.
 2004.
 The sketch engine.
 In In Proceedings of EURALEX 2004.    
 V Lavrenko W B Croft   Relevance models in information retrieval.
 2003
 In W.B. Croft and J. Lafferty( Eds), editors, Springer.  
 arly, we compute cliques of NEs in order to represent a precise annotation.
 For example, Oxford is an ambiguous NE but a clique such as < Cambridge, Oxford, Edinburgh University, Edinburgh, Oxford University > allows to focus on the specific annotation < organization >( see( Ehrmann and Jacquet, 2007) for similar use).
 Given the distributional space described in the previous paragraph, we use a probabilistic framework for computing similarities between NEs.
 The approach that we propose is inspired from the language modeling framework introduced in the information retrieval field( see for example( Lavrenko and Croft, 2003)).
 Then, we construct cliques of NEs based on these similarities.
 2.3.1 Similarity measures between NEs
 We first compute the maximum likelihood estimation for a NE ei to be associated with a context cj: Pml(cj|ei) = D(ei, cj), where |ei |= |ei P|CT| j=1 D(ei, cj) is the total occurrences of the NE ei in the corpus.
 This leads to sparse data which is not suitable for measuring similarities.
 In order to counter this problem, we use the Jelinek-Mercer smoothing method: D0(ei, cj) = λPml(cj|ei) +( 1 − λ)Pml(cj|CORP) where CORP is the corpus and Pml( cj |CORP) =
 Ei D(ee, cj).
 In our experiEi, j i, cj   Lavrenko, Croft, 2003 V. Lavrenko and W.B. Croft.
 2003.
 Relevance models in information retrieval.
 In W.B. Croft and J. Lafferty( Eds), editors, Language modeling in information retrieval.
 Springer.    
 D Lin P Pantel   Induction of semantic classes from natural language text.
 2001
 In Proceedings of ACM SIGKDD.   
 According to this paper, we can classify our method in the category of semi-supervised approaches.
 Our proposal is close to( Cucchiarelli and Velardi, 2001) as it uses syntactic relations(§ 2.2) and as it relies on existing NER systems(§ 2.6.2).
 However, the particularity of our method concerns the clustering of 9Except for XIP+CBC A in line 2 where the precision is slightly lower than XIP ’s one.
 cliques of NEs that allows both to represent the different annotations of the NEs and to group the latter with respect to one precise annotation according to a local context.
 Regarding this aspect,( Lin and Pantel, 2001) and( Ngomo, 2008) also use a clique computation step and a clique merging method.
 However, they do not deal with ambiguity of lexical units nor with NEs.
 This means that, in their system, a lexical unit can be in only one merged clique.
 From a methodological point of view, our proposal is also close to( Ehrmann and Jacquet, 2007) as the latter proposes a system for NEs finegrained annotation, which is also corpus dependent.
 However, in the present paper we use all syntactic relations for measuring the similarity between NEs whereas in the previous mentioned work, only specific syntactic relat   Lin, Pantel, 2001 D. Lin and P. Pantel.
 2001.
 Induction of semantic classes from natural language text.
 In Proceedings of ACM SIGKDD.    
 D
 Lin   Using collocation statistics in information extraction.
 1998
 In Proceedings of MUC-7.  
 utional approach aims at evaluating a distance between words based on their syntactic distribution.
 This method assumes that words which appear in the same contexts are semantically similar( Harris, 1951).
 To construct the distributional space associated to a corpus, we use a robust parser( in our experiments, we used XIP parser( Ait et al., 2002)) to extract chunks( i.e. nouns, noun phrases,...) and syntactic dependencies between these chunks.
 Given this parser ’s output, we identify triple instances.
 Each triple has the form w1.R.w2 where w1 and w2 are chunks and R is a syntactic relation( Lin, 1998),
( Kilgarriff et al., 2004).
 One triple gives two contexts( 1.w1.R and 2.w2.R) and two chunks( w1 and w2).
 Then, we only select chunks w which belong to NE.
 Each point in the distributional space is a NE and each dimension is a syntactic context.
 CT denotes the set of all syntactic contexts and |CT |represents its cardinal.
 We illustrate this construction on the sentence“ provide Albania with food aid”.
 We obtain the three following triples( note that aid and food aid are considered as two different chunks): provide VERB•IOBJ•Albania NOUN provide VERB•PREP WITH•aid
 NOUN provide VERB•PREP WITH   Lin, 1998 D. Lin.
 1998.
 Using collocation statistics in information extraction.
 In Proceedings of MUC-7.    
 J F Marcotorchino P Michaud   Heuristic approach of the similarity aggregation problem.
 Methods of operation research, 1981 43-395   spect are linear equations, we can solve the clustering problem using an integer linear programming solver.
 However, this problem is NP-hard.
 As a result, in practice, we use heuristics for dealing with large data sets.
 2.4.2
 The Relational Analysis heuristic
 The presented heuristic is quite similar to another algorithm described in( Hartigan, 1975) known as the“ leader
” algorithm.
 But unlike this last approach which is based upon euclidean distances and inertial criteria, the RA heuristic aims at maximizing the criterion given in( 6).
 A sketch of this heuristic is given in Algorithm 1,( see( Marcotorchino and Michaud, 1981) for further details).
 Algorithm 1 RA heuristic Require: nbitr = number of iterations; rcm. = maximal number of clusters; S the similarity matrix E( k k0)∈S+ Skk0
 |S+| Take the first clique clik as the first element of the first cluster rc = 1 where rc is the current number of cluster for q = 1 to nbitr do for k = 1 to JCLHJ do for l = 1 to rc do Compute the contribution of clique clik with cluster clul: contl = Eclik0
 ∈clul( Skk0 − m) end for clul∗ is the cluster i d which has the highest contribution with clique clik and contl∗ is the corresponding contribution value if( contl∗ <( Skk − m)) n   Marcotorchino, Michaud, 1981 J.F. Marcotorchino and P. Michaud.
 1981.
 Heuristic approach of the similarity aggregation problem.
 Methods of operation research, 43:395–404.    
 P Michaud J F Marcotorchino   Optimisation en analyse de donn´ees relationnelles.
 In Data Analysis and informatics.
 North 1980 Holland Amsterdam.  
 up cliques of NEs which are mutually highly similar.
 The clusters of cliques which contain a NE allow to find the different possible annotations of this NE.
 This clustering technique must be able to construct“ pure” clusters in order to have precise annotations.
 In that case, it is desirable to avoid fixing the number of clusters.
 That ’s the reason why we propose to use the Relational Analysis approach described below.
 2.4.1
 The Relational Analysis approach We propose to apply the Relational Analysis approach( RA) which is a clustering model that does n’t require to fix the number of clusters( Michaud and Marcotorchino, 1980),( B´ed´ecarrax and Warnesson, 1989).
 This approach takes as input a similarity matrix.
 In our context, since we want to cluster cliques of NEs, the corresponding similarity matrix S between cliques is given by the dot products matrix taken from T: S = T· T0.
 The general term of this similarity matrix is: S(clik, clik0) =
 Skk0 =( clik, clik0).
 Then, we want to maximize the following clustering function: 0(S, X) =
( 6) E(k00,k000)∈S+ Sk00k000 Skk0 − |S+| � N., � contkk0 where S+ ={( clik, clik0): Skk0
 >
 0}.
 In other words, clik and clik0 have more chances to be in the same cluster providing th   Michaud, Marcotorchino, 1980 P. Michaud and J.F. Marcotorchino.
 1980.
 Optimisation en analyse de donn´ees relationnelles.
 In Data Analysis and informatics.
 North Holland Amsterdam.    
 D Nadeau S Sekine  
 A survey of Named Entity Recognition and Classification.
 Lingvisticae Investigationes, 2007 30 1   compute a default cluster assignment matrix Adef, which does not depend on the local context: Adef(ei) = clu* where: clu* = Argmax{clul: clulE){clik: clikE)ei}}|clik|.
 In other words, clu* is the cluster containing the biggest clique clik containing ei.
 2.5.2
 Clusters annotation So far, the different steps that we have introduced were unsupervised.
 In this paragraph, our aim is to give a correct annotation to each cluster( hence, to all NEs in this cluster).
 To this end, we need some annotation seeds and we propose two different semi-supervised approaches( regarding the classification given in( Nadeau and Sekine, 2007)).
 The first one is the manual annotation of some clusters.
 The second one proposes an automatic cluster annotation and assumes that we have some NEs that are already annotated.
 Manual annotation of clusters
 This method is fastidious but it is the best way to match the corpus data with a specific guidelines for annotating NEs.
 It also allows to identify new types of annotation.
 We used the ACE2007 guidelines for manually annotating each cluster.
 However, our CBC system leads to a high number of clusters of cliques and we ca n’t annotate each of them.
 Fortunately, it also leads to a distribution none>.
 Finally, in the sentence“ Matthew, also a favorite to win in his fifth and final appearance, was stunningly eliminated during the semifinal round Friday when he misspelled“
 secernent
”.
”, the baseline hybrid system Stanford + XIP did n’t give any annotation to“
 Matthew” whereas Stanford + XIP + CBC A allowed to give the annotation < person>.
 4 Related works Many previous works exist in NEs recognition and classification.
 However, most of them do not build a NEs resource but exploit external gazetteers( Bunescu and Pasca, 2006),( Cucerzan, 2007).
 A recent overview of the field is given in( Nadeau and Sekine, 2007).
 According to this paper, we can classify our method in the category of semi-supervised approaches.
 Our proposal is close to( Cucchiarelli and Velardi, 2001) as it uses syntactic relations(§ 2.2) and as it relies on existing NER systems(§ 2.6.2).
 However, the particularity of our method concerns the clustering of 9Except for XIP+CBC A in line 2 where the precision is slightly lower than XIP ’s one.
 cliques of NEs that allows both to represent the different annotations of the NEs and to group the latter with respect to one precise annotation according to a local context.
 Regarding this aspect,    Nadeau, Sekine, 2007 D. Nadeau and S. Sekine.
 2007.
 A survey of Named Entity Recognition and Classification.
 Lingvisticae Investigationes, 30(1).    
 A C Ngonga Ngomo   Signum a graph algorithm for terminology extraction.
 2008
 In Proceedings of CICLING 2008, Haifa,   e can classify our method in the category of semi-supervised approaches.
 Our proposal is close to( Cucchiarelli and Velardi, 2001) as it uses syntactic relations(§ 2.2) and as it relies on existing NER systems(§ 2.6.2).
 However, the particularity of our method concerns the clustering of 9Except for XIP+CBC A in line 2 where the precision is slightly lower than XIP ’s one.
 cliques of NEs that allows both to represent the different annotations of the NEs and to group the latter with respect to one precise annotation according to a local context.
 Regarding this aspect,( Lin and Pantel, 2001) and( Ngomo, 2008) also use a clique computation step and a clique merging method.
 However, they do not deal with ambiguity of lexical units nor with NEs.
 This means that, in their system, a lexical unit can be in only one merged clique.
 From a methodological point of view, our proposal is also close to( Ehrmann and Jacquet, 2007) as the latter proposes a system for NEs finegrained annotation, which is also corpus dependent.
 However, in the present paper we use all syntactic relations for measuring the similarity between NEs whereas in the previous mentioned work, only specific syntactic relations were exploite   Ngomo, 2008 A. C. Ngonga Ngomo.
 2008.
 Signum a graph algorithm for terminology extraction.
 In Proceedings of CICLING 2008, Haifa, Israel.    
 M Pasca   Acquisition of categorized named entities for web search.
 2004
 In Proceedings of CIKM 2004, New York, NY, USA.  
 ed clique.
 From a methodological point of view, our proposal is also close to( Ehrmann and Jacquet, 2007) as the latter proposes a system for NEs finegrained annotation, which is also corpus dependent.
 However, in the present paper we use all syntactic relations for measuring the similarity between NEs whereas in the previous mentioned work, only specific syntactic relations were exploited.
 Moreover, we use clustering techniques for dealing with the issue related to over production of cliques.
 In this paper, we construct a NE resource from the corpus that we want to analyze.
 In that context,( Pasca, 2004) presents a lightly supervised method for acquiring NEs in arbitrary categories from unstructured text of Web documents.
 However, Pasca wants to improve web search whereas we aim at annotating specific NEs of an analyzed corpus.
 Besides, as we want to focus on corpus-specific NEs, our work is also related to( Shinyama and Sekine, 2004).
 In this work, the authors found a significant correlation between the similarity of the time series distribution of a word and the likelihood of being a NE.
 This result motivated our choice to test our approach on recent news articles rather than on well-known    Pasca, 2004 M. Pasca.
 2004.
 Acquisition of categorized named entities for web search.
 In Proceedings of CIKM 2004, New York, NY, USA.    
 S Ploux B Victorri   Construction d’espaces s´emantiques a ` l’aide de dictionnaires de synonymes.
 1998 TAL, 39 1   ts for example, each NE and each context should appear more than 10 times in the corpus for being considered.
 D is the resulting( |NE |x |CT|) NEContext matrix where ei: i = 1,..., |NE |is a NE and cj: j = 1,..., |CT |is a syntactic context.
 Then we have: D(ei, cj) =
 Nb. of occ.
 of cj associated to ei( 1) 2.3 Cliques of NEs computation
 A clique in a graph is a set of pairwise adjacent nodes which is equivalent to a complete subgraph.
 A maximal clique is a clique that is not a subset of any other clique.
 Maximal cliques computation was already employed for semantic space representation( Ploux and Victorri, 1998).
 In this work, cliques of lexical units are used to represent a precise meaning.
 Similarly, we compute cliques of NEs in order to represent a precise annotation.
 For example, Oxford is an ambiguous NE but a clique such as < Cambridge, Oxford, Edinburgh University, Edinburgh, Oxford University > allows to focus on the specific annotation < organization >( see( Ehrmann and Jacquet, 2007) for similar use).
 Given the distributional space described in the previous paragraph, we use a probabilistic framework for computing similarities between NEs.
 The approach that we propose is inspired from the langu   Ploux, Victorri, 1998 S. Ploux and B. Victorri.
 1998.
 Construction d’espaces s´emantiques a ` l’aide de dictionnaires de synonymes.
 TAL, 39(1).    
 Y Shinyama S Sekine  
 Named Entity Discovery using comparable news articles.
 2004
 In Proceedings of COLING 2004, Geneva.  
 ion provided by the NER system which gave the best precision.
•
 If a NE occurrence is included in another one we only keep the biggest one and its annotation.
 For example, if Jacques Chirac is annotated < person > by one system and Chirac by < person > by the other system, then we only keep the first annotation.
•
 If two NE occurrences are contiguous and have the same annotation, we merge the two NEs in one NE occurrence.
 3 Experiments
 The system described in this paper rather target corpus-specific NE annotation.
 Therefore, our ex56 periments will deal with a corpus of recent news articles( see( Shinyama and Sekine, 2004) for motivations regarding our corpus choice) rather than well-known annotated corpora.
 Our corpus is constituted of news in English published on the web during two weeks in June 2008.
 This corpus is constituted of around 300,000 words( 10Mb) which does n’t represent a very large corpus.
 These texts were taken from various press sources and they involve different themes( sports, technology,...).
 We extracted randomly a subset of articles and manually annotated 916 NEs( in our experiments, we deal with three types of annotation namely < person >, < organization > and < location >).
 This subset const ious mentioned work, only specific syntactic relations were exploited.
 Moreover, we use clustering techniques for dealing with the issue related to over production of cliques.
 In this paper, we construct a NE resource from the corpus that we want to analyze.
 In that context,( Pasca, 2004) presents a lightly supervised method for acquiring NEs in arbitrary categories from unstructured text of Web documents.
 However, Pasca wants to improve web search whereas we aim at annotating specific NEs of an analyzed corpus.
 Besides, as we want to focus on corpus-specific NEs, our work is also related to( Shinyama and Sekine, 2004).
 In this work, the authors found a significant correlation between the similarity of the time series distribution of a word and the likelihood of being a NE.
 This result motivated our choice to test our approach on recent news articles rather than on well-known annotated corpora.
 5 Conclusion We propose a system that allows to improve NE recognition.
 The core of this system is a cliquebased clustering method based upon a distributional approach.
 It allows to extract, analyze and discover highly relevant information for corpusspecific NEs annotation.
 As we have shown in our experiments, this s   Shinyama, Sekine, 2004 Y. Shinyama and S. Sekine.
 2004.
 Named Entity Discovery using comparable news articles.
 In Proceedings of COLING 2004, Geneva.   