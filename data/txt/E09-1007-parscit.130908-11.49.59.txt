<newSection> Abstract We propose a system which builds, in a semi-supervised manner, a resource that aims at helping a NER system to annotate corpus-specific named entities.
This system is based on a distributional approach which uses syntactic dependencies for measuring similarities between named entities.
The specificity of the presented method however, is to combine a clique-based approach and a clustering technique that amounts to a soft clustering method.
Our experiments show that the resource constructed by using this clique-based clustering system allows to improve different NER systems.
<newSection> 1 Introduction In Information Extraction domain, named entities (NEs) are one of the most important textual units as they express an important part of the meaning of a document.
Named entity recognition (NER) is not a new domain (see MUC1 and ACE2 conferences) but some new needs appeared concerning NEs processing.
For instance the NE Oxford illustrates the different ambiguity types that are interesting to address: Oxford is also a company unlike Newcastle.
The main goal of our system is to act in a complementary way with an existing NER system, in order to enhance its results.
We address two kinds of issues: first, we want to detect and correctly annotate corpus-specific NEs3 that the NER system could have missed; second, we want to correct some wrong annotations provided by the existing NER system due to ambiguity.
In section 3, we give some examples of such corrections.
The paper is organized as follows.
We present, in section 2, the global architecture of our system and from §2.1 to §2.6, we give details about each of its steps.
In section 3, we present the evaluation of our approach when it is combined with other classic NER systems.
We show that the resulting hybrid systems perform better with respect to F-measure.
In the best case, the latter increased by 4.84 points.
Furthermore, we give examples of successful correction of NEs annotation thanks to our approach.
Then, in section 4, we discuss about related works.
Finally we sum up the main points of this paper in section 5.
<newSection> 2 Description of the system Given a corpus, the main objectives of our system are: to detect potential NEs; to compute the possible annotations for each NE and then; to annotate each occurrence of these NEs with the right annotation by analyzing its local context.
We assume that this corpus dependent approach allows an easier NE annotation.
Indeed, even if a NE such as Oxford can have many annotation types, it will certainly have less annotation possibilities in a specific corpus.
Figure 1 presents the global architecture of our system.
The most important part concerns steps 3 (§2.3) and 4 (§2.4).
The aim of these sub-processes is to group NEs which have the same annotation with respect to a given context.
On the one hand, clique-based methods (see §2.3 for details on cliques) are interesting as they allow the same NE to be in different cliques.
In other words, cliques allow to represent the different possible annotations of a NE.
The clique-based approach drawback however, is the over production of cliques which corresponds to an artificial over production of possible annotations for a NE.
On the other hand, clustering methods aim at structuring a data set and such techniques can be seen as data compression processes.
However, a simple NEs hard clustering doesn’t allow a NE to be in several clusters and thus to express its different annotations.
Then, our proposal is to combine both methods in a clique-based clustering framework.
This combination leads to a soft-clustering approach that we denote CBC system.
The following paragraphs, from 2.1 to 2.6, describe the respective steps mentioned in Figure 1.
relation with a noun as governee argument (e.g. The list of potential NEs extracted from the corpus will be denoted NE and the number of NEs |NE|.
The distributional approach aims at evaluating a distance between words based on their syntactic distribution.
This method assumes that words which appear in the same contexts are semantically similar (Harris, 1951).
To construct the distributional space associated to a corpus, we use a robust parser (in our experiments, we used XIP parser (Ait et al., 2002)) to extract chunks (i.e. nouns, noun phrases, ... ) and syntactic dependencies between these chunks.
Given this parser’s output, we identify triple instances.
Each triple has the form w1.R.w2 where w1 and w2 are chunks and R is a syntactic relation (Lin, 1998), (Kilgarriff et al., 2004).
One triple gives two contexts (1.w1.R and 2.w2.R) and two chunks (w1 and w2).
Then, we only select chunks w which belong to NE.
Each point in the distributional space is a NE and each dimension is a syntactic context.
CT denotes the set of all syntactic contexts and |CT |represents its cardinal.
We illustrate this construction on the sentence “provide Albania with food aid”.
We obtain the three following triples (note that aid and food aid are considered as two different chunks): provide VERB•I-OBJ•Albania NOUN provide VERB•PREP WITH•aid NOUN provide VERB•PREP WITH•food aid NP From these triples, we have the following chunks and contexts4: <newSection> Chunks: Contexts: Different methods exist for detecting potential NEs.
In our system, we used some lexico-syntactic constraints to extract expressions from a corpus because it allows to detect some corpus-specific NEs.
In our approach, a potential NE is a noun starting with an upper-case letter or a noun phrase which is (see (Ehrmann and Jacquet, 2007) for similar use): We also use an heuristic in order to reduce the over production of chunks and contexts: in our experiments for example, each NE and each context should appear more than 10 times in the corpus for being considered.
D is the resulting (|NE |x |CT|) NE-Context matrix where ei : i = 1, ...
, |NE |is a NE and A clique in a graph is a set of pairwise adjacent nodes which is equivalent to a complete subgraph.
A maximal clique is a clique that is not a subset of any other clique.
Maximal cliques computation was already employed for semantic space representation (Ploux and Victorri, 1998).
In this work, cliques of lexical units are used to represent a precise meaning.
Similarly, we compute cliques of NEs in order to represent a precise annotation.
For example, Oxford is an ambiguous NE but a clique such as <Cambridge, Oxford, Edinburgh University, Edinburgh, Oxford University> allows to focus on the specific annotation <organization> (see (Ehrmann and Jacquet, 2007) for similar use).
Given the distributional space described in the previous paragraph, we use a probabilistic framework for computing similarities between NEs.
The approach that we propose is inspired from the language modeling framework introduced in the information retrieval field (see for example (Lavrenko and Croft, 2003)).
Then, we construct cliques of NEs based on these similarities.
We first compute the maximum likelihood estimation for a NE ei to be associated with a conj=1 D(ei, cj) is the total occurrences of the NE ei in the corpus.
This leads to sparse data which is not suitable for measuring similarities.
In order to counter this problem, we use the Jelinek-Mercer smoothing method: D0(ei, cj) = λPml(cj|ei) + (1 − λ)Pml(cj|CORP) where CORP is the corpus and ments we took λ = 0.5.
Given D0, we then use the cross-entropy as a similarity measure between NEs.
Let us denote by 2.3.2 From similarity matrix to adjacency matrix Next, we convert s into an adjacency matrix denoted s.
In a first step, we binarize s as follows.
Let us denote fei1, ...
, ei|NE|}, the list of NEs ranked according to the descending order of their similarity with ei.
Then, L(ei) is the list of NEs which are considered as the nearest neighbors of ei according to the following definition: where a E [0, 1] and b E f1,..., |NE|}.
L(ei) gathers the most significant nearest neighbors of ei by choosing the ones which bring the a most relevant similarities providing that the neighborhood’s size doesn’t exceed b.
This approach can be seen as a flexible k-nearest neighbor method.
In our experiments we chose a = 20% and b = 10.
Finally, we symmetrize the similarity matrix as follows and we obtain s: ~ 1 if ei0 E L(ei) or ei E L(ei0) Given s, the adjacency matrix between NEs, we compute the set of maximal cliques of NEs denoted CLI.
Then, we construct the matrix T of general term: where clik is an element of CLI.
T will be the input matrix for the clustering method.
In the following, we also use clik for denoting the vector represented by (T(clik, e1), ... ,T(clik, e|NE|)).
Figure 2 shows some cliques which contain Oxford that we can obtain with this method.
This figure also illustrates the over production of cliques since at least cli8, cli10 and cli12 can be annotated as <organization>.
We use a clustering technique in order to group cliques of NEs which are mutually highly similar.
The clusters of cliques which contain a NE allow to find the different possible annotations of this NE.
This clustering technique must be able to construct “pure” clusters in order to have precise annotations.
In that case, it is desirable to avoid fixing the number of clusters.
That’s the reason why we propose to use the Relational Analysis approach described below.
We propose to apply the Relational Analysis approach (RA) which is a clustering model that doesn’t require to fix the number of clusters (Michaud and Marcotorchino, 1980), (B´ed´ecarrax and Warnesson, 1989).
This approach takes as input a similarity matrix.
In our context, since we want to cluster cliques of NEs, the corresponding similarity matrix S between cliques is given by the dot products matrix taken from T: S = T · T0.
The general term of this similarity matrix is: S(clik, clik0) = Skk0 = (clik, clik0).
Then, we want to maximize the following clustering function: where S+ = {(clik, clik0) : Skk0 > 0}.
In other words, clik and clik0 have more chances to be in the same cluster providing that their similarity measure, Skk0, is greater or equal to the mean average of positive similarities.
As the objective function is linear with respect to X and as the constraints that X must respect are linear equations, we can solve the clustering problem using an integer linear programming solver.
However, this problem is NP-hard.
As a result, in practice, we use heuristics for dealing with large data sets.
The presented heuristic is quite similar to another algorithm described in (Hartigan, 1975) known as the “leader” algorithm.
But unlike this last approach which is based upon euclidean distances and inertial criteria, the RA heuristic aims at maximizing the criterion given in (6).
A sketch of this heuristic is given in Algorithm 1, (see (Marco-torchino and Michaud, 1981) for further details).
Take the first clique clik as the first element of the first cluster rc = 1 where rc is the current number of cluster for q = 1 to nbitr do for k = 1 to JCLHJ do for l = 1 to rc do Compute the contribution of clique clik with cluster clul: contl = Eclik0 ∈clul (Skk0 − m) clul∗ is the cluster id which has the highest contribution with clique clik and contl∗ is the corresponding We have to provide a number of iterations or/and a delta threshold in order to have an approximate solution in a reasonable processing time.
Besides, it is also required a maximum number of clusters but since we don’t want to fix this parameter, we put by default κmax = |CLI|.
Basically, this heuristic has a O(nbitr xκmax x |CLI|) computation cost.
In general terms, we can assume that nbitr << |CLI|, but not κmax << |CLI|.
Thus, in the worst case, the algorithm has Now, we want to exploit the clusters of cliques in order to annotate NE occurrences.
Then, we need to construct a NE resource where for each pair (NE x syntactic context) we have an annotation.
To this end, we need first, to assign a cluster to each pair (NE x syntactic context) (§2.5.1) and second, to assign each cluster an annotation (§2.5.2).
2.5.1 Cluster assignment to each pair (NE x syntactic context) For each cluster clul we provide a score Fc(cj, clul) for each context cj and a score 5We only represent the NEs and their frequency in the cluster which corresponds to the number of cliques which contain the NEs.
Furthermore, we represent the most relevant contexts for this cluster according to equation (7) introduced in the following.
Fe(ei, clul) for each NE ei.
These scores6 are given by: Given a NE ei and a syntactic context cj, we now introduce the contextual cluster assignment matrix Actxt(ei, cj) as follows: Actxt(ei, cj) = clu* where: clu* = Argmax{clul:clulE)ei;F,(ei,clul)>1}Fc(cj, clul).
In other words, clu* is the cluster for which we find more than one occurrence of ei and the highest score related to the context cj.
Furthermore, we compute a default cluster assignment matrix Adef, which does not depend on the local context: Adef(ei) = clu* where: clu* = Argmax{clul:clulE){clik:clikE)ei}}|clik|.
In other words, clu* is the cluster containing the biggest clique clik containing ei.
So far, the different steps that we have introduced were unsupervised.
In this paragraph, our aim is to give a correct annotation to each cluster (hence, to all NEs in this cluster).
To this end, we need some annotation seeds and we propose two different semi-supervised approaches (regarding the classification given in (Nadeau and Sekine, 2007)).
The first one is the manual annotation of some clusters.
The second one proposes an automatic cluster annotation and assumes that we have some NEs that are already annotated.
Manual annotation of clusters This method is fastidious but it is the best way to match the corpus data with a specific guidelines for annotating NEs.
It also allows to identify new types of annotation.
We used the ACE2007 guidelines for manually annotating each cluster.
However, our CBC system leads to a high number of clusters of cliques and we can’t annotate each of them.
Fortunately, it also leads to a distribution of the clusters’ size (number of cliques by cluster) which is � ei�clul similar to a Zipf distribution.
Consequently, in our experiments, if we annotate the 100 biggest clusters, we annotate around eighty percent of the detected NEs (see §3).
Automatic annotation of clusters We suppose in this context that many NEs in NE are already annotated.
Thus, under this assumption, we have in each cluster provided by the CBC system, both annotated and non-annotated NEs.
Our goal is to exploit the available annotations for refining the annotation of a cluster by implicitly taking into account the syntactic contexts and for propagating the available annotations to NEs which have no annotation.
Given a cluster clue of cliques, #(clue, ei) is the weight of the NE ei in this cluster: it is the number of cliques in clue that contain ei.
For all annotations ap in the set of all possible annotations AN, we compute its associated score in cluster clue: it is the sum of the weights of NEs in clue that is annotated ap.
Then, if the maximal annotation score is greater than a simple majority (half) of the total votes7, we assign the corresponding annotation to the cluster.
We precise that the annotation <none>8 is processed in the same way as any other annotations.
Thus, a cluster can be globally annotated <none>.
The limit of this automatic approach is that it doesn’t allow to annotate new NE types than the ones already available.
In the following, we will denote by Aclu(clue) the annotation of the cluster clue.
The cluster annotation matrix Aclu associated to the contextual cluster assignment matrix Aetxt and the default cluster assignment matrix Adef introduced previously will be called the CBC system’s NE resource (or shortly the NE resource).
2.6 NEs annotation processes using the NE resource In this paragraph, we describe how, given the CBC system’s NE resource, we annotate occurrences of NEs in the studied corpus with respect to its local context.
We precise that for an occurrence of a NE ei its associated local context is the set of syntactical dependencies cj in which ei is involved.
2.6.1 NEs annotation process for the CBC system Given a NE occurrence and its local context we can use Aetxt(ei, cj) and Adef(ei) in order to get the default annotation Aclu(Adef(ei)) and the list of contextual annotations {Aclu(Aetxt(ei, cj))}j.
Then for annotating this NE occurrence using our NE resource, we apply the following rules: 2.6.2 NEs annotation process for an hybrid system We place ourselves into an hybrid situation where we have two NER systems (NER 1 + NER 2) which provide two different lists of annotated NEs.
We want to combine these two systems when annotating NEs occurrences.
Therefore, we resolve any conflicts by applying the following rules: <newSection> 3 Experiments The system described in this paper rather target corpus-specific NE annotation.
Therefore, our experiments will deal with a corpus of recent news articles (see (Shinyama and Sekine, 2004) for motivations regarding our corpus choice) rather than well-known annotated corpora.
Our corpus is constituted of news in English published on the web during two weeks in June 2008.
This corpus is constituted of around 300,000 words (10Mb) which doesn’t represent a very large corpus.
These texts were taken from various press sources and they involve different themes (sports, technology, ...
). We extracted randomly a subset of articles and manually annotated 916 NEs (in our experiments, we deal with three types of annotation namely <person>, <organization> and <location>).
This subset constitutes our test set.
In our experiments, first, we applied the XIP parser (Ait et al., 2002) to the whole corpus in order to construct the frequency matrix D given by (1).
Next, we computed the similarity matrix between NEs according to (2) in order to obtain s defined by (4).
Using the latter, we computed cliques of NEs that allow us to obtain the assignment matrix T given by (5).
Then we applied the clustering heuristic described in Algorithm 1.
At this stage, we want to build the NE resource using the clusters of cliques.
Therefore, as described in §2.5, we applied two kinds of clusters annotations: the manual and the automatic processes.
For the first one, we manually annotated the 100 biggest clusters of cliques.
For the second one, we exploited the annotations provided by XIP NER (Brun and Hag`ege, 2004) and we propagated these annotations to the different clusters (see §2.5.2).
The different materials that we obtained constitute the CBC system’s NE resource.
Our aim now is to exploit this resource and to show that it allows to improve the performances of different classic NER systems.
The different NER systems that we tested are the following ones: corpora (CoNLL, MUC6, MUC7 and ACE): ner-eng-ie.crf-3-all2008-distsim.ser.gz (Finkel et al., 2005) (line 3 in Table 1), the combination of pairs taken among the set of the three last-mentioned NER systems (lines 5 to 7 in Table 1).
Notice that these baseline hybrid systems use the annotation combination process described in §2.6.1.
In Table 1 we first reported in each line, the results given by each system when they are applied alone (figures in italics).
These performances represent our baselines.
Second, we tested for each baseline system, an extended hybrid system that integrates the CBC-NER systems (with respect to the combination process detailed in §2.6.2).
The first two lines of Table 1 show that the two CBC-NER systems alone lead to rather poor results.
However, our aim is to show that the CBC-NER system is, despite its low performances alone, complementary to other basic NER systems.
In other words, we want to show that the exploitation of the CBC system’s NE resource is beneficial and non-redundant compared to other baseline NER systems.
This is actually what we obtained in Table 1 as for each line from 2 to 7, the extended hybrid systems that integrate the CBC-NER systems (M or A) always perform better than the baseline either in terms of precision9 or recall.
For each line, we put in bold the best performance according to the F-measure.
These results allow us to show that the NE resource built using the CBC system is complementary to any baseline NER systems and that it allows to improve the results of the latter.
In order to illustrate why the CBC-NER systems are beneficial, we give below some examples taken from the test corpus for which the CBC system A had allowed to improve the performances by respectively disambiguating or correcting a wrong annotation or detecting corpus-specific NEs.
First, in the sentence “From the start, his parents, Lourdes and Hemery, were with him.”, the baseline hybrid system Stanford + XIP annotated the ambiguous NE “Lourdes” as <location> whereas Stanford + XIP + CBC A gave the correct annotation <person>.
Second, in the sentence “Got 3 percent chance of survival, what ya gonna do?”
The back read, ”A) Fight Through, b) Stay Strong, c) Overcome Because I Am a Warrior.”, the baseline hybrid system Stanford + XIP annotated “Warrior” as <organization> whereas Stanford + XIP + CBC A corrected this annotation with <none>.
Finally, in the sentence “Matthew, also a fa-vorite to win in his fifth and final appearance, was stunningly eliminated during the semifinal round Friday when he misspelled “secernent”.”, the baseline hybrid system Stanford + XIP didn’t give any annotation to “Matthew” whereas Stanford + XIP + CBC A allowed to give the annotation <person>.
<newSection> 4 Related works Many previous works exist in NEs recognition and classification.
However, most of them do not build a NEs resource but exploit external gazetteers (Bunescu and Pasca, 2006), (Cucerzan, 2007).
A recent overview of the field is given in (Nadeau and Sekine, 2007).
According to this paper, we can classify our method in the category of semi-supervised approaches.
Our proposal is close to (Cucchiarelli and Velardi, 2001) as it uses syntactic relations (§2.2) and as it relies on existing NER systems (§2.6.2).
However, the partic-ularity of our method concerns the clustering of cliques of NEs that allows both to represent the different annotations of the NEs and to group the latter with respect to one precise annotation according to a local context.
Regarding this aspect, (Lin and Pantel, 2001) and (Ngomo, 2008) also use a clique computation step and a clique merging method.
However, they do not deal with ambiguity of lexical units nor with NEs.
This means that, in their system, a lexical unit can be in only one merged clique.
From a methodological point of view, our proposal is also close to (Ehrmann and Jacquet, 2007) as the latter proposes a system for NEs fine-grained annotation, which is also corpus dependent.
However, in the present paper we use all syntactic relations for measuring the similarity between NEs whereas in the previous mentioned work, only specific syntactic relations were exploited.
Moreover, we use clustering techniques for dealing with the issue related to over production of cliques.
In this paper, we construct a NE resource from the corpus that we want to analyze.
In that context, (Pasca, 2004) presents a lightly supervised method for acquiring NEs in arbitrary categories from unstructured text of Web documents.
However, Pasca wants to improve web search whereas we aim at annotating specific NEs of an analyzed corpus.
Besides, as we want to focus on corpus-specific NEs, our work is also related to (Shinyama and Sekine, 2004).
In this work, the authors found a significant correlation between the similarity of the time series distribution of a word and the likelihood of being a NE.
This result motivated our choice to test our approach on recent news articles rather than on well-known annotated corpora.
<newSection> 5 Conclusion We propose a system that allows to improve NE recognition.
The core of this system is a clique-based clustering method based upon a distributional approach.
It allows to extract, analyze and discover highly relevant information for corpus-specific NEs annotation.
As we have shown in our experiments, this system combined with another one can lead to strong improvements.
Other applications are currently addressed in our team using this approach.
For example, we intend to use the concept of clique-based clustering as a soft clustering method for other issues.
<newSection> References