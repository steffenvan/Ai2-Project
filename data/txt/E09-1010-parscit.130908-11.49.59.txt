       Data-driven semantic ana/ ysis for mu/ ti/ ingua/ WSD and /exica/ se/ ection in trans/ ation    Marianna Apidianaki   
 National Centre for Language Technology School of Computing, Dublin City University   
 Dublin 9, Ireland    mapidianaki@c*mputing.dcu.ie    Abstract   
 A common way of describing the senses of ambiguous words in multilingual Word Sense Disambiguation( WSD) is by reference to their translation equivalents in another language.
 The theoretical soundness of the senses induced in this way can, however, be doubted.
 This type of crosslingual sense identification has implications for multilingual WSD and MT evaluation as well.
 In this article, we first present some arguments in favour of a more thorough analysis of the semantic information that may be induced by the equivalents of ambiguous words found in parallel corpora.
 Then, we present an unsupervised WSD method and a lexical selection method that exploit the results of a data-driven sense induction method.
 Finally, we show how this automatically acquired information can be exploited for a multilingual WSD and MT evaluation more sensitive to lexical semantics.   
 1 Word senses in a bi-(mu/ ti-)/ingua/ context    1.1 Cross-/ingua/ sense determination for WSD    Determining the senses of ambiguous words by reference to their translational equivalents constitutes a common practice in multilingual WSD: the candidate senses of an ambiguous word, from which one has to be selected during WSD, correspond to its equivalents in another language.
 This empirical approach to sense identification circumvents the need for predefined sense inventories and their disadvantages for automatic WSD.1
 The first to    1 Such as the high granularity, the great number and the striking similarity of the described senses, and their    adopt
 it were Brown et al.
( 1991), who represented the two main senses of a SL word by its two most frequent translations in the target language( TL).
 Further promoted by Resnik and Yarowsky( 2000) and endorsed in the multilingual tasks of the Senseval( Chklovski et al., 2004) and Semeval( Jin et al., 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT.
 From these works, only that of Carpuat and Wu( 2005) exploits an external hand-crafted sense inventory.
 The use of an external resource, not related to the training corpus of their Statistical Machine Translation( SMT) system, turned out to be one of the causes of the observed deterioration of translation quality.
 In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus( Cabezas and Resnik, 2005; Carpuat and Wu, 2007; Chan et al., 2007).
 Nevertheless, the theoretical soundness of these senses is not really addressed.   
 1.2 Advantages of cross-/ingua/ sense determination    Crosslingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings( Resnik, 2004).
 Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation.
 Conceiving WSD    irrelevance to the domains of the processed texts( Edmonds and Kilgarriff, 2002).   
 Proceedings of the 12th Conference of the European Chapter of the ACL, pages 77–85, Athens, Greece, 30 March– 3 April 2009.
 c � 2009 Association for Computational Linguistics    77    as lexical selection thus seems natural( Vickrey et al., 2005): it appears that there is no reason to pass through senses in order to arrive to translations.
 A correct translation may be attained even without WSD, as in the case of parallel ambiguities where the SL and TL words are similarly ambiguous( Resnik and Yarowsky, 2000).2    1.3 Disadvantages of cross-/ingua/ sense determination   
 However, this conception of senses is not theoretically sound, as translation equivalents do not always constitute valid sense indicators.
 This is often neglected in an attempt to render the sense inventory as close as possible to the training corpus of the SMT system.
 So, translation equivalents are considered as straightforward indicators of SL senses.
 This approach assumes and results in some type of uniformity regarding the nature of the induced senses: clear-cut( e.g. homonymic) and finer sense distinctions are all handled in the same way.
 Moreover, senses are enumerated without any description of their possible relations.
 For instance, a SL word w having three equivalents( a, b and c) is considered to have three distinct senses( described as ` w-a', ` w-b' et ` w-c)'.
 The assumption of biunivocal( one-to-one) correspondences between senses and equivalents disregards the fact that semantically similar equivalents may be used to translate the same sense of a SL word in context.
 However, this constitutes a common practice in translation and an advised technique for translators, in order to avoid repetitions in the translated texts.
 The phenomenon of translation ambiguity may pose some problems as well: it may not need to be resolved during translation but should be considered in multilingual WSD.
 Resolving this kind of ambiguity could also improve the quality of the results of applications such as multilingual information retrieval.   
 1.4 Impact of cross-/ingua//y defined senses on eva/ uation    Ignoring the relations between word senses may raise further problems during WSD evaluation, as errors concerning close or distant senses are considered as equally important.
 Thus, if a WSD algorithm selects a sense which is slightly 2 A typical example is that of the ambiguous English noun interestwhose& quot;personal&quot; and& quot;financial&quot; senses are translated by the same word in French( interet).
 different from the one effectively carried by an instance of an ambiguous word, but not totally wrong, this is directly considered as a false choice.
 A differing weighting of WSD errors would be preferable in these cases, if sense distance information was available( Resnik and Yarowsky, 2000).
 When WSD coincides with lexical selection in MT, the equivalents of a SL word( w) are perceived to be its candidate senses.
 The sense assigned to a new instance of w is considered to be correct if it corresponds to the reference translation( i.e. the translation of that instance in the test corpus).
 This strict requirement of exact correspondence constitutes one of the main critics addressed to MT evaluation metrics( Cabezas and Resnik, 2005; Callison-Burch, 2006; Chan et al., 2007) and is one of the main reasons that methods have been developed which go beyond pure string matching( Owczarzak et al., 2007).
 A central issue in MT evaluation is the high correlation of the metrics with human judgements of translation quality, which puts the accent on the identification of sense correspondences.
 Here too, it is essential to penalize errors relatively to their importance and so information relative to the semantics of the equivalents should be available.
 In the next section we will show how this information can be acquired using a data-driven sense induction method.   
 2 Data-driven semantic ana/ ysis in a bi/ ingua/ context   
 We propose to explore the semantic relations of the equivalents of ambiguous words using a parallel corpus and to exploit these relations for SL sense induction.
 A data-driven sense acquisition method based on this type of relations is presented in Apidianaki( 2008).
 The theoretical assumptions underlying this approach are the distributional hypotheses of meaning( Harris, 1954) and of semantic similarity( Miller and Charles, 1989), and that of sense correspondence between words in translation relation in real texts.
 Our training corpus is the English( EN)— Greek( GR) part of the lemmatized and POS-tagged INTERA corpus( Gavrilidou et al., 2004) which contains approximately four million words.
 The corpus has been sentence-and wordaligned at the level of tokens and types( Simard and Langlais, 2003).
 Two bilingual lexicons( one    78    for each translation direction: EN— GRiGR— EN are built from the alignment of word types.
 In these lexicons, each SL word(&) is associated with the set of the equivalents to which it is aligned, as shown hereafter:    imp/ ication:{
 /0123456( consequence), 437389/:( impact), 4353;<= >( complication)} variation:{?
 56=@A61/:( fluctuation),A486B <; >( alteration), 8C<3<3<7:/:( modification)}   
 The words in parentheses describe the senses of the Greek equivalents.
 In order to eliminate the noise present in the lexicons, two filters are used: a POS-filter, that keeps only the correspondences between words of the same category' and an intersection filter, which discards the translation correspondences not found in both translation lexicons.
 A lexical sample of 150 ambiguous English nouns having more than two equivalents is then created from the EN— GR lexicon °.
 At this stage, the semantic relations possibly existing between the equivalents are not yet evident, and so no conclusions can be extracted concerning the distinctiveness of the senses they can induce on the SL words.
 The core component of the sense induction method used is a semantic similarity calculation which aims at discovering the relations between the equivalents of a SL ambiguous word(&).
 First, the translation units( TUs) � in which& appears in the SL sentence(s) are extracted from the training corpus and are then grouped by reference to& 's equivalents.
 For instance, if& is translated by $,' and(, three sets of TUs are formed( where& is translated by $('& D$' TUs), by'('& D'' TUs), etc.).
 The SL context features corresponding to each equivalent( i.e. the set of lemmatized content words surrounding& in the SL side of the TUs corresponding to the equivalent) are extracted and treated as a' bag of words'.
 This distributional information serves to calculate the equivalents' similarity using a variation of the Weighted Jaccard coefficient( Grefenstette, 199 °).
 The similarity calculation is described in detail in Apidianaki( 2008).
 Each retained context feature is assigned a weight relatively to each equivalent, which' The noun equivalents of nouns, the verb equivalents of verbs, etc.
 ° Here
 we focus on nouns but the method is applicable to words of other POS categories.
 s
 A translation unit contains up to 2 sentences of each language linked by an alignment.
 serves to define its relevance for the estimation of the equivalents' similarity.
 The equivalents are compared in a pairwise manner and a similarity score is assigned to each pair.
 Two equivalents are considered as semantically related if the instances of& they translate in the training corpus occur in& quot;similar enough&quot; contexts.
 The pertinence of their relation is judged by comparing its score to a threshold, equal to the mean of the scores assigned to all the pairs of equivalents of&.
 The results of this calculation are exploited by a clustering algorithm which takes as input the set of equivalents of& and outputs clusters of similar equivalents illustrating its senses( Apidianaki, 2008).
 Clustered equivalents are semantically related' and considered as translating the same SL sense, while isolated ones translate distinct senses.
 The same calculation is performed by reference to the TL contexts of the equivalents, i.e. using the lemmatized content words surrounding the equivalents in the TL side of the corresponding TUs sets.
 Contrary to the SL results, the TL ones are not used for clustering.
 The TL distributional information relative to the clustered equivalents and acquired at this stage will be used for lexical selection, as we will show later in this paper.
 The sense clusters created for a word serve to identify its senses.
 We describe the senses acquired for the nouns)
 EF%)($&quot;)G* and H$+)$&quot;)G
*: imp/ ication:{ /0123456, 437389/:}: the& quot;impact&quot; sense{ 4353;<= >}: the& quot;complication&quot; sense variation:{?
 56=@A61/:}
: the& quot;fluctuation&quot; sense{ A486B<;>I 8C<3<3<7:/:}:
 the& quot;alteration&quot; sense The sense induction method presented above thus permits the automatic creation of a sense inventory from a parallel corpus.
 In what follows, we will show how this can be exploited for WSD.   
 3 Unsupervised WSD based on the semantic c/ ustering   
 The method described in section 2 provides, as a by-product, information that can be exploited by an unsupervised WSD classifier.
 In the case of a one-equivalent cluster, this information corresponds to the set of the equivalent 's' Most often nearsynonyms but they may be linked by other relations( hyperonymy, hyponymy, etc.).   
 79    e f L i=1 L j = 1    features, retained from the corresponding SL contexts of w.
 In the case of bigger clusters, it consists of the SL context features that reveal the equivalents' similarities: for a cluster of two equivalents, it consists of their assimilative contexts( i.e. the features they share)7; for a cluster of more than 2 equivalents, it consists of the intersection of the common features of the pairs of equivalents found in the cluster.
 As we have already said, each retained context feature is assigned a weight relatively to each equivalent.
 Here are the weighted features characterizing the clusters of variation:{ 8tax6ttavuqj: significant( 2.04), range( 0.76), pharmacokinetics(1.89), individual( 1.89), affect( 1.89), insulin( 1.89), woman( 1.89), year( 1.49), man( 1.19), considerable( 1.19), member( 1.12), old( 0.76), Ireland( 0.76), case( 0.72), increase( 0.76), group( 0.76), states( 0.71), external( 0.76), good( 0.76), expectancy( 0.76), Spain( 0.76), pressure( 0.76), Europe( 0.76)   { ipoaoaoiquq, ttmapok4j: minor( 2.25i1.83), 8 human( 2.01i1.13), number( 0.73i1.16)   
 In order to disambiguate a new instance of a word w, cooccurrence information coming from its context is compared to the sets of features characterizing the clusters.
 The new context must thus be lemmatized and POS-tagged as well.
 Here is an example of a new instance of variation: a.& quot;Although certain regions have been faced with an exodus of their endogenous population, most of the coastal zones are experiencing an increase in overall demographic pressure, as well as significant seasonal variations in employment, essentially linked to tourism.&quot; The features retained from this context are the lemmas of the content words( nouns, verbs and adjectives) surrounding w.
 If common features( CFs) are found between this context and just one cluster of w, this is selected as describing the sense of the new instance.
 On the contrary, if CFs with more than one cluster are found, a score is given to each context-cluster association.
 This score corresponds to the mean of the weights of the CFs relatively to each equivalent of the cluster and is given by the following formula.   
 7 Term used in the study of paraphrase( Fuchs, 1994).
 8 The two scores in parentheses correspond, respectively, to the score of the feature by reference to the first and the second equivalent of the cluster.   
 w( equivalenti, feature j
) e* f   
 In this formula, e is the number of the equivalents of a cluster and f is the number of its CFs with the new context.
 The cluster with the highest score is retained; it describes the sense carried by the new instance of w and could be used as its sense tag.
 The only cluster having CFs with the context of variation in( a) and is thus selected is J&axauavorl}( C F s: increase, pressure, significant).
 If any instances remain ambiguous at the end of the WSD process( i.e. no associations are established with the sense clusters), a small modification could increase the method 's coverage.
 If w has clusters of more than two equivalents, it is possible to use the assimilative contexts of the pairs of equivalents instead of their intersection.
 The coverage of the WSD method would be increased in this way, as the sets of assimilative contexts would contain more features than their intersection, and so it would become more probable to find CFs with the new contexts and to establish' context-cluster' associations.   
 4 Semantics-sensitive WSD eva/ uation    4.1
 The notion of enriched precision    In this section, we will present the evaluation of the proposed WSD method and we will show how the clustering information can be exploited at this stage.9
 The new instances of the nouns of our lexical sample, used for evaluation, come from our test corpus, the sentence aligned EN— GR part of EUROPARL( Koehn, 2005).
 The TUs containing the ambiguous nouns are extracted from the corpus.
 Lacking a goldstandard for evaluation, we exploit information relative to translations.
 In the multilingual tasks of Senseval and Semeval( Ckhlovski et al., 2004; Jin et al., 2007), the translations of the words in the parallel test corpus are considered as their sense tags.
 Here, we consider that the equivalent translating an ambiguous SL word in context( called reference translation) points to a sense described by a cluster.
 Consequently, what is being evaluated is the capacity of the WSD    9
 Some of the equivalents of w found in the training corpus and contained in the clusters may not be used in the test corpus.
 The evaluation concerns only those that are found in the test corpus.   
 80    method to predict this sense.
 The sense proposed for an instance of an ambiguous word is considered as correct if a) a 1-equivalent cluster is selected and the equivalent corresponds to the reference, or b) if a bigger cluster containing the reference is selected.
 Otherwise, the proposed sense is fa/ se.
 In the multilingual tasks where translations are regarded as sense tags, the proposed senses are considered as correct only if they correspond exactly to the reference translation.
 This is the principle ofprecision, underlying most of the existing MT evaluation metrics.
 From a quantitative point of view, this strict criterion has a negative impact on the WSD evaluation results.
 From a qualitative point of view, it ignores the fact that different equivalents may correspond to the same source sense and that an ambiguous word in context can have more than one good translation.
 The use of the sense clusters during WSD evaluation offers the possibility of capturing the semantic relations between the equivalents of ambiguous words, acquired during learning.
 In this case, the evaluation could be considered as based on a principle of enriched precision that exploits the paradigmatic relations of TL words.   
 4.2.
 Eva/ uation metrics   
 The metrics used for WSD evaluation are the following: number of correct predictions    recall = number of new instances precision =    number of correct predictions number of predictions
 The obtained results are compared to those of a baseline method.
 The baseline most often used in Senseval is that of the most frequent sense( i.e. the first sense given for a word in a predefined sense inventory).
 This is a very powerful heuristic because of the asymmetric distribution of word senses in real texts.
 Our baseline consists of choosing the most frequent equivalent( i.e. the one that translates w most frequently in the training corpus) as illustrating the sense of all its new instances.
 The asymmetric distribution of senses is, however, reflected at the level of the equivalents used to translate them: the most frequent equivalent in the training corpus is often the one that translates most of the instances of w in the test corpus.
 The baseline score corresponds to both recall and precision, as a prediction is made for all the new instances.
 This score is calculated, for each w, on the basis of the number of its instances for which the proposed sense is correct.
 This number coincides with the frequency of the most frequent equivalent of w in the test corpus.
 In order to facilitate the comparison between our results and the baseline, we use thef-measure( f-score) that combines precision and recall in a unique measure:    2*( precision*recall)
 f —score = precision + recall    We evaluate here the performance of our WSD method on the 150 ambiguous nouns of our sample.
 We observe that the f-score of our method easily overcomes the results of the baseline.
 base/ ine 51.42%
 enriched f-score 76.99%
 The difference between these scores indicates the positive impact of the clustering information on the WSD results.
 As the senses are situated at a higher level of abstraction, the correspondences with the reference are established at a more abstract level than that of exact unigram correspondences.
 Our results can be compared to those obtained in the multilingual lexical sample tasks of Senseval and SemEval.
 This comparison seems interesting although these tasks concern words of different parts of speech( nouns, verbs and adjectives).
 The systems participating at the multilingual English— Hindi lexical sample task of Senseval-3 are all supervised and they all perform better than the baseline( Chklovski et al., 2004).
 This is interpreted by the authors as an indication of the clarity of the sense distinctions performed using translations, which provide sufficient information for the training of supervised classifiers.
 The systems performed better on the sense-tagged part of the data, showing that sense information may be helpful for the task of targeted word translation.
 In the English— Chinese lexical sample task of SemEval the unsupervised systems perform    81    worse than the baseline, contrary to the supervised ones( Jin!& quot; $%., 2007).   
 5 Capturing semantic simi/ arity during trans/ ation    5.1 Lexica/ se/ ection based on WSD   
 In the experiments reported here,%!
 R)($%,!
%!
(& quot;)G
* refers to the translation of ambiguous SL nouns in context and not to that of whole sentences.
 Lexical selection is thus considered as a'% $* MDK)%%)*J task( Vickrey!& quot; $%.
, 2005):
 the equivalents translating the SL nouns in the TL sentences of the test TUs are automatically replaced by a blank which has to be filled by the WSD or the lexical selection method.
 We give an example of a test TU containing the noun)
 EF%)($&quot;)G*.    b)& quot;U*P( L$*J!& quot;G& quot;L!
( O++!*&quot;,)& quot;O$&quot;)G* EO,&quot;'!
 F+!(!N!N' P $ +) JG+GO,,& quot;ONP GK)& quot;, H$+)GO, implicationsI&)& quot;L& quot;L! G'X!(&quot;)H!
 $%& $ P,'!)
* J& quot;G JO$+$*&quot;!!
 $ L)JLDYO$%)&quot;P FO'%)
(,! + H)
(! $* N& quot;G +!& quot;$)*& quot;L!
( O++!*&quot; FO'%)
( GF!+$&quot;G+, $* N! R),&quot;)*J XG',W&quot; l& quot;Z37/:[I /4
 < 3<56?>3<84 A486B <; > 8:[ /:A4C51 >
[ = 68\/86/:[]
 6
 3C2345 3\186 16 3C<:^47865 A76 4A34C5/8689A21:
 A4;28: 891?
 56_<C485=`1[...]
 2a<186[?
 56C=
 `[ = 68\ 1<0 8 < /8ba
 < 8:[? 56/_\;5/:
[ A76
[ 3<5<85= >[?:
 Ab/56[ 03:C4/76[I 8:
[? 568>C:/:[
 891 /:A4C51`1?: A</791_ < C291 36C < a >[ 03:C4/5`1 = 65 8:[ = 68<a@C9/:[ 891 /:A4C51`1] 2/491 4C^6/76[W&quot;   
 If a one-equivalent cluster is selected by the WSD method, this equivalent is retained as the translation of the SL word( cf.( $), section 3).
 On the contrary, when a bigger sense cluster is proposed, the most adequate equivalent for the TL context has to be selected.
 This is done by the lexical selection method, which filters the cluster and fills the blank in the TL sentence with the best translation according to the TL context.
 The cluster retained during WSD as describing the sense of) EF%)($&quot;)G* in( b) is J/0123456I
 437389/:}.
 Most often the clustered equivalents are nearsynonyms translating the same source sense, but almost never absolute synonyms interchangeable in all TL contexts.
 Consequently, the cluster can be filtered by considering their differences.
 In order to judge the equivalents' adequacy in the new TL context, the lexical selection method compares information coming from this context to information learned during training.
 Given that the training was performed on a lemmatized and POS-tagged corpus, the new TL context must be lemmatized and POS-tagged as well, in order to retain only the lemmas of the content words10.
 The information acquired during training and exploited here concerns the context features that differentiate the equivalents in the TL, as shown by the semantic similarity calculation in the TL side of the training corpus( cf. section 2).
 The differentiating contexts of the equivalents characterize the sense clusters as well, as was the case with their assimilative contexts.11
 The equivalent retained by the lexical selection method for) EF%)($&quot;)G* in the example( b) is /0123456.
 This differs from the reference translation( 437389/:) but is closely related to it.
 Thus, it is a semantically plausible translation that can be used in this TL context.
 In a real Statistical Machine Translation( SMT) system, the clusters could be filtered by the language model, on the basis of word sequence probabilities in translations.
 In this way, the most probable translation in the TL context, among the semantically pertinent alternatives included in the cluster suggested during WSD, would be selected.   
 5.2 Eva/ uation of the /exica/ se/ ection   
 The lexical selection method has been applied to the WSD results on our lexical sample.
 The reference translations, found in the test corpus, serve for evaluation here as well.
 We calculate the results of this method first using the principle of,& quot;+)(&quot; F+!(),)G*( i.e. looking for exact correspondences with the reference) and then on the basis of!
* +)( L!N F+!(),)G*( i.e. exploiting the clustering information).
 The sense clusters serve here to estimate the semantic proximity of the proposed translation to the reference, in cases of no exact correspondence.
 Thus, a translation which is semantically similar to the reference is considered to be correct if they are both found in the cluster proposed during WSD.
 This renders the evaluation more flexible and significantly increases the quantity of semantically pertinent translations compared to the baseline.
 The strict and enrichedKDscores are estimated by considering as correct( score = 1) every translation that is pertinent according to the corresponding evaluation principles.
 The    10 Our test corpus has been tagged and lemmatized using the TreeTagger( Schmid, 1994).   
 11
 The SL contextual information exploited for WSD.
 82    results indicate the increase in pertinent translations.
 base/ ine 52.14%
 strict -f-score 48.37% enriched f-score 77.79%
 We observe that the strict f-score is lower than the baseline.
 This happens because our method proposes equivalents semantically similar to the reference for some instances for which the baseline predictions are correct.
 However, these pertinent predictions are not taken into account by the principle of strict precision.
 This is the case in example( b): the baseline prediction( e7chacouq) for this instance o f implication corresponds to the reference while the suggestion of our method( uvve7ceaa), even though semantically pertinent, is not considered as correct according to the principle of strict precision and is not rewarded.
 Nevertheless, it would be preferable to weigh differently the predictions related to the reference, by taking into account the strength of their relation.
 These predictions could be considered as almost correct and they could be, at the same time, penalized less than translations having a different sense and less rewarded than exact correspondences to the reference.
 For this to be done, a measure capable of capturing the semantic distance would be needed.
 Using a weighted coefficient is essential in tasks implicating semantics, not only in WSD( Resnik and Yarowsky, 2000) but also in tasks such as the estimation of interannotator agreement in semantic annotation( Artstein and Poesio, 2008).
 The common element between these tasks is that the distances between the categories( word senses) should be weighted, so that the WSD errors or the divergences between annotators be treated differently.
 We envisaged the possibility of weighting differently the proposed translations on the basis of their relation to the reference, by using as distance measure their similarity score in the TL.
 A semantically pertinent translation different from the reference was assigned a score equal to the similarity score of the two equivalents in the TL.
 A problem that we encountered, and that made us fall back to the solution of a uniform weighting of semantically pertinent translations, is that the comparison of these results to the baseline was not representative of the effective improvement( the great increase in the number of pertinent translation predictions) brought about by exploiting the clustering information.
 This happens because all the correct suggestions of the baseline are weighted by a score equal to 1, while the score of translations semantically related to the reference is always lower than 1, given that absolute synonyms are very rare in natural language.
 We envisage the elaboration of a more sophisticated coefficient for weighting semantically pertinent translations, that will permit a more conclusive comparison with the baseline.
 This coefficient could take into account not only the similarity score between a proposed translation and the reference but also the number of the SL word 's candidate translations, the number of its senses and their distinctiveness, as well as the number of the equivalents similar to the reference and their scores.
 Before concluding, we would like to take a look at the way the concern for lexical semantics is manifested and taken into account in existing MT evaluation metrics.   
 5.3 Semantic simi/ arity in existing MT eva/ uation metrics    Lexical semantic relations are supposed to be captured in BLEU by the use of multiple reference translations( Papineni et al., 2002).
 Finding many references for evaluation is, however, rather problematic( Callison-Burch, 2006).
 In METEOR
( Banerjee and Lavie, 2005), such relations are detected by exploiting WordNet( Miller et al., 1990).
 More precisely, the number of pertinent translations is increased using synset information: a translation is correct not only if it corresponds to the reference, but also if it is semantically similar to it, i.e. found in the same synset.
 One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call& quot;a poor-man 's synonymy detection
 algorithm&quot;. Consequently, the WNSynonymy module used maps two unigrams together simply if at least one sense of each word belongs to the same WordNet synset.
 Another problem is that the metric is strongly dependent on a predefined sense inventory.
 Given that such resources are publicly available for very few languages, the synonymy module often is not operational and is omitted.   
 83    Lavie and Agarwal( 2007) envisage the possibility of developing new synonymy modules for languages other than English, which would be based on alternative methods and could replace WordNet.
 In the previous sections, we showed how the information acquired by an unsupervised sense induction method can help to account for the words' semantic similarity.
 The created sense clusters, grouping semantically similar equivalents, can be compared to WordNet synsets.
 This kind of semantic information, extracted directly from text data, can constitute an alternative to the use of predefined sense inventories.
 A clear advantage of a metric based on the results of unsupervised semantic analysis, in comparison to one dependent on a predefined resource, is that it is language-independent and may be used for evaluation in languages where semantic resources are not available.   
 6 Conc/ usion and perspectives   
 In this paper, we have presented the advantages and weaknesses of crosslingual sense determination, often used in multilingual WSD and MT.
 We have put forward some arguments towards a more thorough semantic analysis of the translation equivalents of ambiguous words that serve as sense indicators, and we have shown how it could be of use in multilingual WSD and MT.
 The data-driven sense induction method used identifies the senses of ambiguous English nouns by clustering their translation equivalents according to their semantic similarity.
 Exploiting the sense inventory built in this way proves of benefit in multilingual WSD and lexical selection in MT.
 Their evaluation becomes more flexible as well, as it becomes possible to capture the semantic relations between the translations of ambiguous words.
 The problem of strictness of the MT evaluation metrics can thus be overcome without the need for a predefined inventory.
 This would allow for a more conclusive estimation of the effect of WSD in SMT.
 The integration of the cluster-based WSD method into a real SMT system and the evaluation of its impact on translation quality constitute the main perspectives of the work presented in this article and the object of future work.   
 Acknow/ edgments   
 I would like to thank Philippe Langlais for the word alignment and Andy Way for useful comments.
 This research is funded by SFI grant 05iINi1732.   
 References    Marianna Apidianaki.
 2008.
 Translation-oriented Sense Induction Based on Parallel Corpora, In Proceedings of the 6th Conference on Language Resources and Evaluation( LREC), Marrakech, Morocco.
 Ron Artstein and Massimo Poesio.
 2008.
 Inter-coder Agreement for Computational Linguistics,
 Computational Linguistics 34(4):
 555596.
 Satanjeev Banerjee and Alon Lavie.
 2005.
 METEOR:
 An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments.
 In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT andior Summarization, 43rd Annual Meeting of the Association for Computational Linguistics( ACL), Ann Arbor, Michigan, 65-72.
 Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra and Robert L. Mercer.
 1991.
 Wordsense disambiguation using statistical methods.
 In 29th Annual Meeting of the Association for Computational Linguistics( ACL), Berkeley, California, 264-270.
 Clara Cabezas and Philip Resnik.
 2005.
 Using WSD Techniques for Lexical Selection in Statistical Machine Translation.
 Technical Report CS
TR4736iLAMP-
 TR-124iUMIACSTR-2005-42.
 Chris Callison-Burch, Miles Osborne and Philipp Koehn.
 2006.
 Re-evaluating the Role of BLEU in Machine Translation Research.
 In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics( EACL), Trento, Italy, 249-256.
 Marine Carpuat and Dekai Wu.
 2005.
 Word Sense Disambiguation vs. Statistical Machine Translation.
 In 43rd Annual Meeting of the Association for Computational Linguistics( ACL).
 Ann Arbor, Michigan, 387-394.
 Marine Carpuat and Dekai Wu.
 2007.
 Improving Statistical Machine Translation using Word Sense Disambiguation.
 In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning( EMNLPCoNLL), Prague, Czech Republic, 61-72.
 Yee Seng Chan, Hwee Tou Ng and David Chiang.
 2 0 0 7.
 Word Sense Disambiguation Improves Statistical Machine Translation.
 In 45th Annual    84    Meeting of the Association for Computational Linguistics, Prague, Czech Republic, 33-40.
 Timothy Chklovski, Rada Mihalcea, Ted Pedersen and Amruta Purandare.
 2004.
 The senseval-3 multilingual EnglishHindi lexical sample task.
 Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems, Barcelona, Spain, 5-8.
 Philip Edmonds and Adam Kilgarriff.
 2002.
 Introduction to the special issue on evaluating word sense disambiguation systems.
 Natural Language Engineering 8(4):
 279-291.
 Catherine, Fuchs.
 1994.
 Paraphrase et 6nonciation.
 Editions Ophrys, Paris.
 Maria Gavrilidou, Peny Labropoulou, Elina Desipri, Voula Giouli, Vasilis Antonopoulos and Stelios Piperidis.
 2004.
 Building parallel corpora for eContent professionals.
 In Proceedings of the Workshop on Multilingual Linguistic Resources, 20th International Conference on Computational Linguistics( COLING), Geneva, Switzerland, 90-93.
 Gregory Grefenstette.
 1994.
 Explorations in Automatic Thesaurus Discovery.
 Kluwer Academic Publishers, BostoniDordrechtiLondon.
 Zellig Harris.
 1954.
 Distributional Structure.
 Word, 10: 146-162.
 Peng Jin, Yunfang Wu and Shiwen Yu.
 2007.
 SemEval-2007
 Task S: Multilingual ChineseEnglish Lexical Sample, In Proceedings of the 4th International Workshop on Semantic Evaluations( SemEval 2007), Prague, Czech Republic, 19-23.
 Philipp Koehn.
 2005.
 Europarl:
 A Parallel Corpus for Statistical Machine Translation.
 In Proceedings of MT Summit X, Phuket, Thailand, 79-86.
 Alon Lavie and Abhaya Agarwal.
 2007.
 METEOR:
 An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments.
 In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics( ACL), Prague, Czech Republic, 228-231.
 George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Groos and Katherine Miller.
 1990.
 Introduction to WordNet:
 An On-line Lexical Database.
 International Journal of Lexicography 3(4): 235-312.
 George A. Miller and Walter G. Charles.
 1991.
 Contextual correlates of semantic similarity.
 Language and Cognitive Processes 6(1): 1-28.
 Karolina Owczarzak, Josef van Genabith and Andy Way.
 2007.
 Labelled Dependencies in Machine Translation Evaluation.
 In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics( ACL), Prague, Czech Republic, 104-111.
 Kishore Papineni, Salim Roukos, Todd Ward and WeiJing Zhu.
 2002.
 BLEU:
 a Method for Automatic Evaluation of Machine Translation.
 In 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia, PA., 311-318.
 Philip Resnik.
 2004.
 Exploiting Hidden Meanings: Using Bilingual Text for Monolingual Annotation.
 In Gelbukh, A.( ed.), Lecture Notes in Computer Science 2945: Computational Linguistics and Intelligent Text Processing:
 Proceedings of the 5th International Conference CICLing, Seoul, Korea, 283-299.
 Philip Resnik and David Yarowsk.
 2000.
 Distinguishing Systems and Distinguishing Senses: New Evaluation Methods for Word Sense Disambiguation, Natural Language Engineering 5(3): 113133.
 Helmut Schmid.
 1994.
 Probabilistic Part-of-Speech Tagging Using Decision Trees.
 In Proceedings of the International Conference on New Methods in Language Processing, Manchester, 44-49.
 David Vickrey, Luke Biewald, Marc Teyssier and Daphne Koller.
 2005.
 Word-Sense Disambiguation for Machine Translation.
 In Proceedings of the Joint Conference on Human Language Technology
 i Empirical Methods in Natural Language Processing( HLTEMNLP), Vancouver, Canada, 771-778.   
 85       Data-driven semantic ana/ ysis for mu/ ti/ ingua/ WSD and /exica/ se/ ection in trans/ ation Marianna Apidianaki National Centre for Language Technology School of Computing, Dublin City University Dublin 9, Ireland
 mapidianaki@c*mputing.dcu.ie
 A common way of describing the senses of ambiguous words in multilingual Word Sense Disambiguation( WSD) is by reference to their translation equivalents in another language.
 The theoretical soundness of the senses induced in this way can, however, be doubted.
 This type of crosslingual sense identification has implications for multilingual WSD and MT evaluation as well.
 In this article, we first present some arguments in favour of a more thorough analysis of the semantic information that may be induced by the equivalents of ambiguous words found in parallel corpora.
 Then, we present an unsupervised WSD method and a lexical selection method that exploit the results of a data-driven sense induction method.
 Finally, we show how this automatically acquired information can be exploited for a multilingual WSD and MT evaluation more sensitive to lexical semantics.
 1 Word senses in a bi-(mu/ ti-)/ingua/ context 1.1 Cross-/ingua/ sense determination for WSD Determining the senses of ambiguous words by reference to their translational equivalents constitutes a common practice in multilingual WSD: the candidate senses of an ambiguous word, from which one has to be selected during WSD, correspond to its equivalents in another language.
 This empirical approach to sense identification circumvents the need for predefined sense inventories and their for automatic The first to as the high granularity, the great number and the striking similarity of the described senses, and their it were Brown( 1991), who represented the two main senses of a SL word by its two most frequent translations in the target language( TL).
 Further promoted by Resnik and Yarowsky( 2000) and endorsed in the tasks of the Senseval( Chklovski 2004) and Semeval( Jin 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT.
 From these works, only that of Carpuat and Wu( 2005) exploits an external hand-crafted sense inventory.
 The use of an external resource, not related to the training corpus of their Statistical Machine Translation( SMT) system, turned out to be one of the causes of the observed deterioration of translation quality.
 In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus( Cabezas and Resnik, 2005; Carpuat and 2007; Chan 2007).
 Nevertheless, the theoretical soundness of these senses is not really addressed.
 1.2 Advantages of cross-/ingua/ sense determination Crosslingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings( Resnik, 2004).
 Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation.
 Conceiving WSD irrelevance to the domains of the processed texts( Edmonds and Kilgarriff, 2002).
 of the 12th Conference of the European Chapter of the pages 77–85, Greece, 30 March– 3 April 2009.
 Association for Computational Linguistics 77 as lexical selection thus seems natural( Vickrey 2005): it appears that there is no reason to pass through senses in order to arrive to translations.
 A correct translation may be attained even without WSD, as in the case of parallel ambiguities where the SL and TL words are similarly ambiguous( Resnik and Yarowsky, 1.3 Disadvantages of cross-/ingua/ sense determination
 However, this conception of senses is not theoretically sound, as translation equivalents do not always constitute valid sense indicators.
 This is often neglected in an attempt to render the sense inventory as close as possible to the training corpus of the SMT system.
 So, translation equivalents are considered as straightforward indicators of SL senses.
 This approach assumes and results in some type of uniformity regarding the nature of the induced senses: clear-cut( e.g. homonymic) and finer sense distinctions are all handled in the same way.
 Moreover, senses are enumerated without any description of their possible For instance, a SL word three is considered to have distinct senses( described as et
 The assumption of biunivocal( one-to-one) correspondences between senses and equivalents disregards the fact that semantically similar equivalents may be used to translate the same sense of a SL word in context.
 However, this constitutes a common practice in translation and an advised technique for translators, in order to avoid repetitions in the translated texts.
 The phenomenon of translation ambiguity may pose some problems as well: it may not need to be resolved during translation but should be considered in multilingual WSD.
 Resolving this kind of ambiguity could also improve the quality of the results of applications such as multilingual information retrieval.
 1.4 Impact of cross-/ingua//y defined senses on eva/ uation Ignoring the relations between word senses may raise further problems during WSD evaluation, as errors concerning close or distant senses are considered as equally important.
 Thus, if a WSD algorithm selects a sense which is slightly 2A typical example is that of the ambiguous English noun& quot;personal&quot; and& quot;financial&quot; senses are by the same word in French different from the one effectively carried by an instance of an ambiguous word, but not totally wrong, this is directly considered as a false choice.
 A differing weighting of WSD errors would be preferable in these cases, if sense distance information was available( Resnik and Yarowsky, 2000).
 When WSD coincides with lexical selection MT, the equivalents of a SL word are perceived to be its candidate senses.
 The sense to a new instance of considered to be correct if it corresponds to the reference translation( i.e. the translation of that instance in the test corpus).
 This strict requirement of exact correspondence constitutes one of the main critics addressed to MT evaluation metrics( Cabezas and Resnik, 2005; Callison-Burch, Chan 2007) and is one of the main reasons that methods have been developed which beyond pure string matching( Owczarzak 2007).
 A central issue in MT evaluation is the high correlation of the metrics with human judgements of translation quality, which puts the accent on the identification of sense correspondences.
 Here too, it is essential to penalize errors relatively to their importance and so information relative to the semantics of the equivalents should be available.
 In the next section we will show how this information can be acquired using a data-driven sense induction method.
 2 Data-driven semantic ana/ ysis in a bi/ ingua/ context We propose to explore the semantic relations of the equivalents of ambiguous words using a parallel corpus and to exploit these relations for SL sense induction.
 A data-driven sense acquisition method based on this type of relations is presented in Apidianaki( 2008).
 The theoretical assumptions underlying this approach are the distributional hypotheses of meaning( Harris, 1954) and of semantic similarity( Miller and Charles, 1989), and that of sense correspondence between words in translation relation in real texts.
 Our training corpus is the English( EN)— Greek( GR) part of the lemmatized and INTERA corpus( Gavrilidou 2004) which contains approximately four million words.
 The corpus has been sentenceand wordaligned at the level of tokens and types( Simard and Langlais, 2003).
 Two bilingual lexicons( one 78 for each translation direction: EN— GRiGR— EN are built from the alignment of word types.
 In lexicons, each SL word is associated with the set of the equivalents to which it is aligned, as shown hereafter: The words in parentheses describe the senses of the Greek equivalents.
 In order to eliminate the noise present in the lexicons, two filters are used: a POS-filter, that keeps only the correspondences between words of the same an intersection filter, which discards the translation correspondences not found in both translation lexicons.
 A lexical sample of 150 ambiguous English nouns having more than two equivalents is then created from EN— GR
 At this stage, the semantic relations possibly existing between the equivalents are not yet evident, and so no conclusions can be extracted concerning the distinctiveness of the senses they can induce on the SL words.
 The core component of the sense induction method used is a semantic similarity calculation which aims at discovering the relations between equivalents of a SL ambiguous word the translation units which appears in the SL sentence(s) are extracted from the training corpus and are then grouped by to equivalents.
 For instance, if by three sets of TUs are( where translated by TUs), TUs), etc.).
 The SL context features corresponding to each equivalent( i.e. the set of lemmatized words surrounding the SL side of the TUs corresponding to the equivalent) are extracted and treated as a' bag of words'.
 This distributional information serves to calculate the equivalents' similarity using a variation of the Weighted Jaccard coefficient( Grefenstette, 199 °).
 The similarity calculation is described in detail in Apidianaki( 2008).
 Each retained context feature is assigned a weight relatively to each equivalent, which noun equivalents of nouns, the verb equivalents of verbs, etc.
 we focus on nouns but the method is applicable to words of other POS categories.
 sA translation unit contains up to 2 sentences of each language linked by an alignment.
 serves to define its relevance for the estimation of the equivalents' similarity.
 The equivalents are compared in a pairwise manner and a similarity score is assigned to each pair.
 Two equivalents are considered as semantically related if the of translate in the training corpus occur in& quot;similar enough&quot; contexts.
 The pertinence of their relation is judged by comparing its score to a threshold, equal to the mean of the scores assigned to all the pairs of of The results of this calculation are exploited by a clustering algorithm which takes as input set of equivalents of outputs clusters of similar equivalents illustrating its senses( Apidianaki, 2008).
 Clustered equivalents are considered as translating the same SL sense, while isolated ones translate distinct senses.
 The same calculation is performed by reference to the TL contexts of the equivalents, i.e. using the lemmatized content words surrounding the equivalents in the TL side of the corresponding TUs sets.
 Contrary to the SL results, the TL ones are not used for clustering.
 The TL distributional information relative to the clustered equivalents and acquired at this stage will be used for lexical selection, as we will show later in this paper.
 The sense clusters created for a word serve to identify its senses.
 We describe the senses for the nouns the& quot;impact&quot; sense the& quot;complication&quot; sense the& quot;fluctuation&quot; sense the& quot;alteration&quot; sense The sense induction method presented above thus permits the automatic creation of a sense inventory from a parallel corpus.
 In what follows, we will show how this can be exploited for WSD.
 3 Unsupervised WSD based on the semantic c/ ustering The method described in section 2 provides, as a by-product, information that can be exploited by an unsupervised WSD classifier.
 In the case of a one-equivalent cluster, this information corresponds to the set of the equivalent 's often nearsynonyms but they may be linked by other relations( hyperonymy, hyponymy, etc.).
 79
 e f L L features, retained from the corresponding SL of In the case of bigger clusters
, it consists of the SL context features that reveal the equivalents' similarities: for a cluster of two equivalents, it consists of their assimilative( i.e. the features they for a cluster of more than 2 equivalents, it consists of the intersection of the common features of the pairs of equivalents found in the cluster.
 As we have already said, each retained context feature is assigned a weight relatively to each equivalent.
 Here are the weighted features the clusters of ttmapok4j 8
 In order to disambiguate a new instance of a cooccurrence information coming from its context is compared to the sets of features characterizing the clusters.
 The new context must thus be lemmatized and POS-tagged as well.
 Here is an example of a new instance of certain regions have been faced with an exodus of their endogenous population, most of the coastal zones are experiencing an increase in overall demographic pressure, as as significant seasonal essentially linked to The features retained from this context are the lemmas of the content words( nouns, verbs adjectives) surrounding If common features( CFs) are found between this context just one cluster of this is selected as describing the sense of the new instance.
 On the contrary, if CFs with more than one cluster are a score is given to each association.
 This score corresponds to the mean of the weights of the CFs relatively to each equivalent of the cluster and is given by the following formula.
 7Term used in the study of paraphrase( Fuchs, 1994).
 8The
 two scores in parentheses correspond, respectively, to the score of the feature by reference to the first and the second equivalent of the cluster.
, feature this formula, the number of the of a cluster and the number of its CFs with the new context.
 The cluster with the highest score is retained; it describes the sense by the new instance w could be used as its sense tag.
 The only cluster having CFs the context of( a) and is thus is(
 C F s: If any instances remain ambiguous at the end of the WSD process( i.e. no associations are established with the sense clusters), a small modification could increase the method 's If clusters of more than two equivalents, it is possible to use the assimilative contexts of the pairs of equivalents instead of their intersection.
 The coverage of the WSD method would be increased in this way, as the sets of assimilative contexts would contain more features than their intersection, and so it would become more probable to find CFs with the new and to establish associations.
 4 Semantics-sensitive WSD eva/ uation
 The notion of precision In this section, we will present the evaluation of the proposed WSD method and we will show how the clustering information can be exploited this The new instances of the nouns of our lexical sample, used for evaluation, come from our test corpus, the sentence aligned EN— GR part of EUROPARL( Koehn, 2005).
 The TUs containing the ambiguous nouns are extracted from the corpus.
 Lacking a goldstandard for evaluation, we exploit information relative to translations.
 In the multilingual tasks of Senseval and( Ckhlovski 2004; Jin 2007), the translations of the words in the parallel test corpus are considered as their sense tags.
 Here, we consider that the equivalent translating an ambiguous SL word in context points to a sense described by a cluster.
 Consequently, what is being evaluated is the capacity of the WSD 9Some of the equivalents of in the training corpus and contained in the clusters may not be used in the test corpus.
 The evaluation concerns only those that are found in the test corpus.
 80 method to predict this sense.
 The sense proposed for an instance of an ambiguous word considered as a) a 1-equivalent cluster is selected and the equivalent corresponds to the reference, or b) if a bigger cluster containing the reference is selected.
 the proposed sense is In the multilingual tasks where translations are regarded as sense tags, the proposed senses are considered as correct only if they correspond exactly to the reference translation.
 This is the underlying most of the existing MT evaluation metrics.
 From a quantitative point of view, this strict criterion has a negative impact on the WSD evaluation results.
 From a qualitative point of view, it ignores the fact that different equivalents may correspond to the same source sense and that an ambiguous word in context can have more than one good translation.
 The use of the sense clusters during WSD evaluation offers the possibility of capturing the semantic relations between the equivalents of ambiguous words, acquired during learning.
 In this case, the evaluation could be considered as on a principle of precision exploits the paradigmatic relations of TL words.
 4.2.
 Eva/ uation metrics
 The metrics used for WSD evaluation are the following: number of correct predictions number of new instances number of correct predictions number of predictions
 The obtained results are compared to those of a baseline method.
 The baseline most often used in Senseval is that of the most frequent sense( i.e. the first sense given for a word in a predefined sense inventory).
 This is a very powerful heuristic because of the asymmetric distribution of word senses in real texts.
 Our baseline consists of choosing the most frequent( i.e. the one that translates frequently in the training corpus) as illustrating the sense of all its new instances.
 The asymmetric distribution of senses is, however, reflected at the level of the equivalents used to translate them: the most frequent equivalent in the training corpus is often the one that most of the instances of the test corpus.
 The baseline score corresponds to both recall and precision, as a prediction is made for all the new instances.
 This score is calculated, each on the basis of the number of its instances for which the proposed sense is correct.
 This number coincides with the of the most frequent equivalent of in the test corpus.
 In order to facilitate the comparison between our results and the we use that combines precision and recall in a unique measure: We evaluate here the performance of our WSD method on the 150 ambiguous nouns of sample.
 We observe that the our method easily overcomes the results of the baseline.
 base/ ine 51.42% 76.99%
 The difference between these scores indicates the positive impact of the clustering information on the WSD results.
 As the senses are situated at a higher level of abstraction, the correspondences with the reference are established at a more abstract level than that of exact unigram correspondences.
 Our results can be compared to those obtained in the multilingual lexical sample tasks of Senseval and SemEval.
 This comparison seems interesting although these tasks concern words of different parts of speech( nouns, verbs and adjectives).
 The systems participating at the multilingual English— Hindi lexical sample task of Senseval-3 are all supervised and they all better than the baseline( Chklovski 2004).
 This is interpreted by the authors as an indication of the clarity of the sense distinctions performed using translations, which provide sufficient information for the training of supervised classifiers.
 The systems performed better on the sense-tagged part of the data, showing that sense information may be helpful for the task of targeted word translation.
 In the English— Chinese lexical sample task of SemEval the unsupervised systems perform 81 worse than the baseline, contrary to the ones( Jin 5 Capturing semantic simi/ arity during trans/ ation 5.1 Lexica/ se/ ection based on WSD
 the experiments reported here, to the translation of ambiguous SL nouns in context and not to that of whole sentences.
 Lexical selection is thus considered a( Vickrey 2005): the equivalents translating the SL nouns in the TL sentences of the test TUs are automatically replaced by a blank which has to be filled by the WSD or the lexical selection method.
 We give an example of a test TU containing the noun( L$*J!& quot;G& quot;L!
( O++!*&quot;,)& quot;O$&quot;)G* EO,&quot;'!
 F+!(!N!N' P $ +) JG+GO,,& quot;ONP GK)& quot;, H$+)GO,&)& quot;L& quot;L! G'X!(&quot;)H!
 $%& $ P,'!)
* J& quot;G JO$+$*&quot;!!
 $ L)JLDYO$%)&quot;P FO'%)
(,! + H)
(! $* N& quot;G +!& quot;$)*& quot;L!
( O++!*&quot; FO'%)
( GF!+$&quot;G+, $* N
 l /4
 < 3<56?>3<84 A486B <; > 8:[ /:A4C51 >[ = 68\/86/:[] 6 3C2345 3\186 16 3C<:^47865 A76 4A34C5/8689A21: A4;28: 891 2a<186[?
 56C=
 `[ = 68\ 1<0 8 < /8ba
 < 8:[? 56/_\;5/:
[ A76[?:
 Ab/56[ 8:[?
 568>C:/:[
 891 /:A4C51`1?: A</791_ < C291 36C < a >[ 03:C4/5`1 = 65 8:[ = 68<a@C9/:[ 891 /:A4C51`1
 If a one-equivalent cluster is selected by the WSD method, this equivalent is retained as the of the SL word( cf. section 3).
 On the contrary, when a bigger sense cluster is proposed, the most adequate equivalent for the TL context has to be selected.
 This is done by the lexical selection method, which filters the cluster and fills the blank in the TL sentence with the best translation according to the TL context.
 The cluster retained during WSD as the sense of( b) is Most often the clustered equivalents are nearsynonyms translating the same source sense, but almost never absolute synonyms interchangeable in all TL contexts.
 Consequently, the cluster can be filtered by considering their differences.
 In order to judge the equivalents' adequacy in the new TL context, the lexical selection method compares information coming from this context to information learned during training.
 Given that the training was performed on a lemmatized and POS-tagged corpus, the new TL context must be lemmatized and POS-tagged as well, in order to retain only the lemmas of the The information acquired during training and exploited here concerns the context features that differentiate the equivalents in the TL, as shown by the semantic similarity calculation in the TL side of the training corpus( cf. section 2).
 The differentiating contexts of the equivalents characterize the sense clusters as well, as was case with their assimilative The equivalent retained by the lexical method for the example is This differs from the reference but is closely related to it.
 Thus, it is a semantically plausible translation that can be used in this TL context.
 In a real Statistical Machine Translation( SMT) system, the clusters could be filtered by the language model, on the basis of word sequence probabilities in translations.
 In this way, the most probable translation in the TL context, among the semantically pertinent alternatives included in the cluster suggested during WSD, would be selected.
 5.2 Eva/ uation of the /exica/ se/ ection
 The lexical selection method has been applied to the WSD results on our lexical sample.
 The reference translations, found in the test corpus, serve for evaluation here as well.
 We calculate the results of this method first using the of F+!(),)G* looking for exact correspondences with the reference) and on the basis of F+!(),)G* exploiting the clustering information).
 The sense clusters serve here to estimate the semantic proximity of the proposed translation to the reference, in cases of no exact correspondence.
 Thus, a translation which is semantically similar to the reference is considered to be correct if they are both found in the cluster proposed during WSD.
 This renders the evaluation more flexible and significantly increases the quantity of semantically pertinent translations compared to the baseline.
 strict and are estimated by considering as correct( score = 1)
 every translation that is pertinent according to the corresponding evaluation principles.
 The 10Our test corpus has been tagged and lemmatized using the TreeTagger( Schmid, 1994).
 11The SL contextual information exploited for WSD.
 82 results indicate the increase in pertinent translations.
 base/ ine 52.14% 48.37%
 77.79% observe that the strict lower than the baseline.
 This happens because our method proposes equivalents semantically similar to the reference for some instances for which the baseline predictions are correct.
 However, these pertinent predictions are not taken into account by the principle of strict precision.
 This is the case in example( b): the prediction for this instance f to the reference the suggestion of our method even though semantically pertinent, is not considered as correct according to the principle of strict precision and is not rewarded.
 Nevertheless, it would be preferable to weigh differently the predictions related to the reference, by taking into account the strength of their relation.
 These predictions could be as correct they could be, at the same time, penalized less than translations having a different sense and less rewarded than exact correspondences to the reference.
 For this to be done, a measure capable of capturing the semantic distance would be needed.
 Using a weighted coefficient is essential in tasks implicating semantics, not only in WSD( Resnik and Yarowsky, 2000) but also in tasks such as the estimation of interannotator agreement in semantic annotation( Artstein and Poesio, 2008).
 The common element between these tasks is that the distances between the categories( word senses) should be weighted, so that the WSD errors or the divergences between annotators be treated differently.
 We envisaged the possibility of weighting differently the proposed translations on the basis of their relation to the reference, by using as distance measure their similarity score in the TL.
 A semantically pertinent translation different from the reference was assigned a score equal to the similarity score of the two equivalents in the TL.
 A problem that we encountered, and that made us fall back to the solution of a uniform weighting of semantically pertinent translations, is that the comparison of these results to the baseline was not representative of the effective improvement( the great increase in the number of pertinent translation predictions) brought about by exploiting the clustering information.
 This happens because all the correct suggestions of the baseline are weighted by a score equal to 1, while the score of translations semantically related to the reference is always lower than 1, given that absolute synonyms are very rare in natural language.
 We envisage the elaboration of a more sophisticated coefficient for weighting semantically pertinent translations, that will permit a more conclusive comparison with the baseline.
 This coefficient could take into account not only the similarity score between a proposed translation and the reference but also the number of the SL word 's candidate translations, the number of its senses and their distinctiveness, as well as the number of the equivalents similar to the reference and their scores.
 Before concluding, we would like to take a look at the way the concern for lexical semantics is manifested and taken into account in existing MT evaluation metrics.
 5.3 Semantic simi/ arity in existing MT eva/ uation metrics Lexical semantic relations are supposed to be captured in BLEU by the use of multiple translations( Papineni al.
, Finding many references for evaluation is, however, rather problematic( Callison-Burch, 2006).
 In METEOR
( Banerjee and Lavie, 2005), such relations are detected by exploiting( Miller 1990).
 More precisely, the number of pertinent translations is increased using synset information: a translation is correct not only if it corresponds to the reference, but also if it is semantically similar to it, i.e. found in the same synset.
 One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call& quot;a poor-man 's synonymy detection
 algorithm&quot;. Consequently, the WNSynonymy module used maps two unigrams together simply if at least one sense of each word belongs to the same WordNet synset.
 Another problem is that the metric is strongly dependent on a predefined sense inventory.
 Given that such resources are publicly available for very few languages, the synonymy module often is not operational and is omitted.
 83 Lavie and Agarwal( 2007) envisage the possibility of developing new synonymy modules for languages other than English, which would be based on alternative methods and could replace WordNet.
 In the previous sections, we showed how the information acquired by an unsupervised sense induction method can help to account for the words' semantic similarity.
 The created sense clusters, grouping semantically similar equivalents, can be compared to WordNet synsets.
 This kind of semantic information, extracted directly from text data, can constitute an alternative to the use of predefined sense inventories.
 A clear advantage of a metric based on the results of unsupervised semantic analysis, in comparison to one dependent on a predefined resource, is that it is language-independent and may be used for evaluation in languages where semantic resources are not available.
 6 Conc/ usion and perspectives
 In this paper, we have presented the advantages and weaknesses of crosslingual sense determination, often used in multilingual WSD and MT.
 We have put forward some arguments towards a more thorough semantic analysis of the translation equivalents of ambiguous words that serve as sense indicators, and we have shown how it could be of use in multilingual WSD and MT.
 The data-driven sense induction method used identifies the senses of ambiguous English nouns by clustering their translation equivalents according to their semantic similarity.
 Exploiting the sense inventory built in this way proves of benefit in multilingual WSD and lexical selection in MT.
 Their evaluation becomes more flexible as well, as it becomes possible to capture the semantic relations between the translations of ambiguous words.
 The problem of strictness of the MT evaluation metrics can thus be overcome without the need for a predefined inventory.
 This would allow for a more conclusive estimation of the effect of WSD in SMT.
 The integration of the cluster-based WSD method into a real SMT system and the evaluation of its impact on translation quality constitute the main perspectives of the work presented in this article and the object of future work.
 Acknow/ edgments I would like to thank Philippe Langlais for the word alignment and Andy Way for useful comments.
 This research is funded by SFI grant 05iINi1732.
 References Apidianaki.
 2008.
 Induction Based on Parallel
 In of the Conference on Language Resources and Evaluation( LREC), Marrakech, Morocco.
 Artstein and Massimo Poesio.
 2008.
 for Computational Computational Linguistics 34(4): 555596.
 Banerjee and Alon Lavie.
 2005.
 An Automatic Metric for MT Evaluation with Correlation with Human In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT andior Annual Meeting of the Association for Computational Linguistics( ACL), Ann Arbor, Michigan, 65-72.
 Peter F. Brown, Stephen A. Della Pietra, Vincent J. Pietra and Robert L. Mercer.
 1991.
 Word-</note > disambiguation using statistical In Annual Meeting of the Association for Computational Linguistics( ACL), Berkeley, California, 264-270.
 Cabezas and Philip Resnik.
 2005.
 WSD Techniques for Lexical Selection in Statistical Technical Report CS
TR-</pubnum
 > 4736iLAMPTR-124iUMIACSTR-2005-42.
 Chris Callison-Burch, Miles Osborne and Philipp 2006.
 the Role of BLEU in Translation
 In Proceedings of Conference of the European Chapter of the Association for Computational Linguistics( EACL), Trento, Italy, 249-256.
 Carpuat and Dekai Wu.
 2005.
 Sense Disambiguation vs. Statistical Machine
 In Annual Meeting of the Association for Computational Linguistics( ACL).
 Ann Arbor, Michigan, 387-394.
 Carpuat and Dekai Wu.
 2007.
 Statistical Machine Translation using Word Sense
 In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning( EMNLPCoNLL), Prague, Czech Republic, 61-72.
 Yee Seng Chan, Hwee Tou Ng and David Chiang
. 0 0 7.
 Sense Disambiguation Improves Machine
 In Annual 84 Meeting of the Association for Computational Linguistics, Prague, Czech Republic, 33-40.
 Timothy Chklovski, Rada Mihalcea, Ted Pedersen and Purandare.
 2004.
 senseval-3 EnglishHindi lexical sample Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems, Barcelona, Spain, 5-8.
 Philip Edmonds and Adam Kilgarriff.
 2002.       
 Marianna Apidianaki  
 Translation-oriented Sense Induction Based on Parallel Corpora, 2008
 In Proceedings of the 6th Conference on Language Resources and Evaluation( LREC), Marrakech, Morocco.  
 nse correspondences.
 Here too, it is essential to penalize errors relatively to their importance and so information relative to the semantics of the equivalents should be available.
 In the next section we will show how this information can be acquired using a data-driven sense induction method.
 2 Data-driven semantic ana/ ysis in a bi/ ingua/ context We propose to explore the semantic relations of the equivalents of ambiguous words using a parallel corpus and to exploit these relations for SL sense induction.
 A data-driven sense acquisition method based on this type of relations is presented in Apidianaki( 2008).
 The theoretical assumptions underlying this approach are the distributional hypotheses of meaning( Harris, 1954) and of semantic similarity( Miller and Charles, 1989), and that of sense correspondence between words in translation relation in real texts.
 Our training corpus is the English( EN)— Greek( GR) part of the lemmatized and POS-tagged INTERA corpus( Gavrilidou et al., 2004) which contains approximately four million words.
 The corpus has been sentence-and wordaligned at the level of tokens and types( Simard and Langlais, 2003).
 Two bilingual lexicons( one 78 for each translation direc eference to& 's equivalents.
 For instance, if& is translated by $,' and(, three sets of TUs are formed( where& is translated by $('& D$' TUs), by'('& D'' TUs), etc.).
 The SL context features corresponding to each equivalent( i.e. the set of lemmatized content words surrounding& in the SL side of the TUs corresponding to the equivalent) are extracted and treated as a' bag of words'.
 This distributional information serves to calculate the equivalents' similarity using a variation of the Weighted Jaccard coefficient( Grefenstette, 199 °).
 The similarity calculation is described in detail in Apidianaki( 2008).
 Each retained context feature is assigned a weight relatively to each equivalent, which' The noun equivalents of nouns, the verb equivalents of verbs, etc.
 ° Here
 we focus on nouns but the method is applicable to words of other POS categories.
 s
 A translation unit contains up to 2 sentences of each language linked by an alignment.
 serves to define its relevance for the estimation of the equivalents' similarity.
 The equivalents are compared in a pairwise manner and a similarity score is assigned to each pair.
 Two equivalents are considered as semantically related if the instances of& they t   Apidianaki, 2008 Marianna Apidianaki.
 2008.
 Translation-oriented Sense Induction Based on Parallel Corpora, In Proceedings of the 6th Conference on Language Resources and Evaluation( LREC), Marrakech, Morocco.    
 Ron Artstein Massimo Poesio   2008
 Inter-coder Agreement for Computational Linguistics, Computational Linguistics
 34 4 555-596  
 s related to the reference, by taking into account the strength of their relation.
 These predictions could be considered as almost correct and they could be, at the same time, penalized less than translations having a different sense and less rewarded than exact correspondences to the reference.
 For this to be done, a measure capable of capturing the semantic distance would be needed.
 Using a weighted coefficient is essential in tasks implicating semantics, not only in WSD( Resnik and Yarowsky, 2000) but also in tasks such as the estimation of interannotator agreement in semantic annotation( Artstein and Poesio, 2008).
 The common element between these tasks is that the distances between the categories( word senses) should be weighted, so that the WSD errors or the divergences between annotators be treated differently.
 We envisaged the possibility of weighting differently the proposed translations on the basis of their relation to the reference, by using as distance measure their similarity score in the TL.
 A semantically pertinent translation different from the reference was assigned a score equal to the similarity score of the two equivalents in the TL.
 A problem that we encountered, and that made us fall   Artstein, Poesio, 2008 Ron Artstein and Massimo Poesio.
 2008.
 Inter-coder Agreement for Computational Linguistics,
 Computational Linguistics 34(4)
: 555596.    
 Satanjeev Banerjee Alon Lavie  
 METEOR:
 An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments.
 2005
 In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT andior Summarization, 43rd Annual Meeting of the Association for Computational Linguistics( ACL), 65-72 Ann Arbor, Michigan,    the number of its senses and their distinctiveness, as well as the number of the equivalents similar to the reference and their scores.
 Before concluding, we would like to take a look at the way the concern for lexical semantics is manifested and taken into account in existing MT evaluation metrics.
 5.3 Semantic simi/ arity in existing MT eva/ uation metrics Lexical semantic relations are supposed to be captured in BLEU by the use of multiple reference translations( Papineni et al., 2002).
 Finding many references for evaluation is, however, rather problematic( Callison-Burch, 2006).
 In METEOR
( Banerjee and Lavie, 2005), such relations are detected by exploiting WordNet( Miller et al., 1990).
 More precisely, the number of pertinent translations is increased using synset information: a translation is correct not only if it corresponds to the reference, but also if it is semantically similar to it, i.e. found in the same synset.
 One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call& quot;a poor-man 's synonymy detection
 algorithm&quot;. Consequently, the WNSynonymy module used maps two unigrams together simply if at least one sense o   Banerjee, Lavie, 2005 Satanjeev Banerjee and Alon Lavie.
 2005.
 METEOR:
 An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments.
 In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT andior Summarization, 43rd Annual Meeting of the Association for Computational Linguistics( ACL), Ann Arbor, Michigan, 65-72.    
 Peter F Brown Stephen A Della Pietra Vincent J Della Pietra Robert L Mercer   Wordsense disambiguation using statistical methods.
 1991
 In 29th Annual Meeting of the Association for Computational Linguistics( ACL), 264-270 Berkeley, California,   ngua/ sense determination for WSD Determining the senses of ambiguous words by reference to their translational equivalents constitutes a common practice in multilingual WSD: the candidate senses of an ambiguous word, from which one has to be selected during WSD, correspond to its equivalents in another language.
 This empirical approach to sense identification circumvents the need for predefined sense inventories and their disadvantages for automatic WSD.1
 The first to 1 Such as the high granularity, the great number and the striking similarity of the described senses, and their adopt it were Brown et al.
( 1991), who represented the two main senses of a SL word by its two most frequent translations in the target language( TL).
 Further promoted by Resnik and Yarowsky( 2000) and endorsed in the multilingual tasks of the Senseval( Chklovski et al., 2004) and Semeval( Jin et al., 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT.
 From these works, only that of Carpuat and Wu( 2005) exploits an external hand-crafted sense inventory.
 The use of an external resource, not related to the training corpus of their Statistical Machine Translation( SMT) syst   Brown, Pietra, Pietra, Mercer, 1991 Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra and Robert L. Mercer.
 1991.
 Wordsense disambiguation using statistical methods.
 In 29th Annual Meeting of the Association for Computational Linguistics( ACL), Berkeley, California, 264-270.    
 Clara Cabezas Philip Resnik   Using WSD Techniques for Lexical Selection in Statistical Machine Translation.
 2005
 Technical Report CSTR4736iLAMPTR-124iUMIACSTR-2005-42.  
 senses is still found in recent works on the integration of WSD in MT.
 From these works, only that of Carpuat and Wu( 2005) exploits an external hand-crafted sense inventory.
 The use of an external resource, not related to the training corpus of their Statistical Machine Translation( SMT) system, turned out to be one of the causes of the observed deterioration of translation quality.
 In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus( Cabezas and Resnik, 2005; Carpuat and Wu, 2007; Chan et al., 2007).
 Nevertheless, the theoretical soundness of these senses is not really addressed.
 1.2 Advantages of cross-/ingua/ sense determination Crosslingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings( Resnik, 2004).
 Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation.
 Conceiving W tly considered as a false choice.
 A differing weighting of WSD errors would be preferable in these cases, if sense distance information was available( Resnik and Yarowsky, 2000).
 When WSD coincides with lexical selection in MT, the equivalents of a SL word( w) are perceived to be its candidate senses.
 The sense assigned to a new instance of w is considered to be correct if it corresponds to the reference translation( i.e. the translation of that instance in the test corpus).
 This strict requirement of exact correspondence constitutes one of the main critics addressed to MT evaluation metrics( Cabezas and Resnik, 2005; Callison-Burch, 2006; Chan et al., 2007) and is one of the main reasons that methods have been developed which go beyond pure string matching( Owczarzak et al., 2007).
 A central issue in MT evaluation is the high correlation of the metrics with human judgements of translation quality, which puts the accent on the identification of sense correspondences.
 Here too, it is essential to penalize errors relatively to their importance and so information relative to the semantics of the equivalents should be available.
 In the next section we will show how this information can be acquired using a dat   Cabezas, Resnik, 2005 Clara Cabezas and Philip Resnik.
 2005.
 Using WSD Techniques for Lexical Selection in Statistical Machine Translation.
 Technical Report CS
TR4736iLAMPTR-124iUMIACSTR-2005-42.    
 Chris Callison-Burch Miles Osborne Philipp Koehn   Re-evaluating the Role of BLEU in Machine Translation Research.
 2006
 In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics( EACL), 249-256 Trento, Italy, Callison-Burch, Osborne, Koehn, 2006 Chris Callison-Burch, Miles Osborne and Philipp Koehn.
 2006.
 Re-evaluating the Role of BLEU in Machine Translation Research.
 In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics( EACL), Trento, Italy, 249-256.    
 Marine Carpuat Dekai Wu  
 Word Sense Disambiguation vs. Statistical Machine Translation.
 2005
 In 43rd Annual Meeting of the Association for Computational Linguistics( ACL).
 387-394 Ann Arbor, Michigan,   disadvantages for automatic WSD.1
 The first to 1 Such as the high granularity, the great number and the striking similarity of the described senses, and their adopt it were Brown et al.
( 1991), who represented the two main senses of a SL word by its two most frequent translations in the target language( TL).
 Further promoted by Resnik and Yarowsky( 2000) and endorsed in the multilingual tasks of the Senseval( Chklovski et al., 2004) and Semeval( Jin et al., 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT.
 From these works, only that of Carpuat and Wu( 2005) exploits an external hand-crafted sense inventory.
 The use of an external resource, not related to the training corpus of their Statistical Machine Translation( SMT) system, turned out to be one of the causes of the observed deterioration of translation quality.
 In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus( Cabezas and Resnik, 2005; Carpuat and Wu, 2007; Chan et al., 2007).
 Nevertheless, the theoretical soundness of these senses   Carpuat, Wu, 2005 Marine Carpuat and Dekai Wu.
 2005.
 Word Sense Disambiguation vs. Statistical Machine Translation.
 In 43rd Annual Meeting of the Association for Computational Linguistics( ACL).
 Ann Arbor, Michigan, 387-394.    
 Marine Carpuat Dekai Wu  
 Improving Statistical Machine Translation using Word Sense Disambiguation.
 2007
 In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning( EMNLPCoNLL), 61-72 Prague, Czech Republic,   ecent works on the integration of WSD in MT.
 From these works, only that of Carpuat and Wu( 2005) exploits an external hand-crafted sense inventory.
 The use of an external resource, not related to the training corpus of their Statistical Machine Translation( SMT) system, turned out to be one of the causes of the observed deterioration of translation quality.
 In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus( Cabezas and Resnik, 2005; Carpuat and Wu, 2007; Chan et al., 2007).
 Nevertheless, the theoretical soundness of these senses is not really addressed.
 1.2 Advantages of cross-/ingua/ sense determination Crosslingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings( Resnik, 2004).
 Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation.
 Conceiving WSD irrelevance to the    Carpuat, Wu, 2007 Marine Carpuat and Dekai Wu.
 2007.
 Improving Statistical Machine Translation using Word Sense Disambiguation.
 In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning( EMNLPCoNLL), Prague, Czech Republic, 61-72.    
 Yee Seng Chan
 Hwee Tou Ng David Chiang   7.
 Word Sense Disambiguation Improves Statistical Machine Translation.
 In 45th Annual Meeting of the Association for Computational Linguistics, 2 33-40 Prague, Czech Republic, Chan, Ng, Chiang,   Yee Seng Chan, Hwee Tou Ng and David Chiang.
 2 0 0 7.
 Word Sense Disambiguation Improves Statistical Machine Translation.
 In 45th Annual Meeting of the Association for Computational Linguistics, Prague, Czech Republic, 33-40.    
 Timothy Chklovski Rada
 Mihalcea Ted Pedersen Amruta Purandare  
 2004
 The senseval-3 multilingual EnglishHindi lexical sample task.
 Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems, 5--8 Barcelona,   be selected during WSD, correspond to its equivalents in another language.
 This empirical approach to sense identification circumvents the need for predefined sense inventories and their disadvantages for automatic WSD.1
 The first to 1 Such as the high granularity, the great number and the striking similarity of the described senses, and their adopt it were Brown et al.
( 1991), who represented the two main senses of a SL word by its two most frequent translations in the target language( TL).
 Further promoted by Resnik and Yarowsky( 2000) and endorsed in the multilingual tasks of the Senseval( Chklovski et al., 2004) and Semeval( Jin et al., 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT.
 From these works, only that of Carpuat and Wu( 2005) exploits an external hand-crafted sense inventory.
 The use of an external resource, not related to the training corpus of their Statistical Machine Translation( SMT) system, turned out to be one of the causes of the observed deterioration of translation quality.
 In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflec   WSD results.
 As the senses are situated at a higher level of abstraction, the correspondences with the reference are established at a more abstract level than that of exact unigram correspondences.
 Our results can be compared to those obtained in the multilingual lexical sample tasks of Senseval and SemEval.
 This comparison seems interesting although these tasks concern words of different parts of speech( nouns, verbs and adjectives).
 The systems participating at the multilingual English— Hindi lexical sample task of Senseval-3 are all supervised and they all perform better than the baseline( Chklovski et al., 2004).
 This is interpreted by the authors as an indication of the clarity of the sense distinctions performed using translations, which provide sufficient information for the training of supervised classifiers.
 The systems performed better on the sense-tagged part of the data, showing that sense information may be helpful for the task of targeted word translation.
 In the English— Chinese lexical sample task of SemEval the unsupervised systems perform 81 worse than the baseline, contrary to the supervised ones( Jin!& quot; $%.
, 2007).
 5 Capturing semantic simi/ arity during trans/ ation 5.1 Lexica/ se/ ectio   Chklovski, Mihalcea, Pedersen, Purandare, 2004 Timothy Chklovski, Rada Mihalcea, Ted Pedersen and Amruta Purandare.
 2004.
 The senseval-3 multilingual EnglishHindi lexical sample task.
 Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems, Barcelona, Spain, 5-8.    
 Philip Edmonds Adam Kilgarriff   Introduction to the special issue on evaluating word sense disambiguation systems.
 2002
 Natural Language Engineering 8 4 279-291   ss, the theoretical soundness of these senses is not really addressed.
 1.2 Advantages of cross-/ingua/ sense determination Crosslingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings( Resnik, 2004).
 Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation.
 Conceiving WSD irrelevance to the domains of the processed texts( Edmonds and Kilgarriff, 2002).
 Proceedings of the 12th Conference of the European Chapter of the ACL, pages 77–85, Athens, Greece, 30 March– 3 April 2009.
 c � 2009 Association for Computational Linguistics 77 as lexical selection thus seems natural( Vickrey et al., 2005): it appears that there is no reason to pass through senses in order to arrive to translations.
 A correct translation may be attained even without WSD, as in the case of parallel ambiguities where the SL and TL words are similarly ambiguous( Resnik and Yarowsky, 2000).2 1.3 Disadvantages of cross-/ingua/ sense determination However, this conception of sense   Edmonds, Kilgarriff, 2002 Philip Edmonds and Adam Kilgarriff.
 2002.
 Introduction to the special issue on evaluating word sense disambiguation systems.
 Natural Language Engineering 8(4):
 279-291.    
 Fuchs Catherine   1994
 Paraphrase et 6nonciation.
 Editions Ophrys, Paris.
 Catherine, 1994 Catherine, Fuchs.
 1994.
 Paraphrase et 6nonciation.
 Editions Ophrys, Paris.    
 Maria Gavrilidou   Peny Labropoulou, Elina Desipri, Voula Giouli, Vasilis Antonopoulos and Stelios Piperidis.
 2004
 In Proceedings of the Workshop on Multilingual Linguistic Resources, 20th International Conference on Computational Linguistics( COLING), 90-93 Geneva, Gavrilidou, 2004 Maria Gavrilidou, Peny Labropoulou, Elina Desipri, Voula Giouli, Vasilis Antonopoulos and Stelios Piperidis.
 2004.
 Building parallel corpora for eContent professionals.
 In Proceedings of the Workshop on Multilingual Linguistic Resources, 20th International Conference on Computational Linguistics( COLING), Geneva, Switzerland, 90-93.    
 Gregory Grefenstette   Explorations in Automatic Thesaurus Discovery.
 1994 Kluwer Academic Publishers, BostoniDordrechtiLondon.
 Grefenstette, 1994 Gregory Grefenstette.
 1994.
 Explorations in Automatic Thesaurus Discovery.
 Kluwer Academic Publishers, BostoniDordrechtiLondon.    
 Zellig Harris   1954 Distributional Structure.
 Word, 10 146-162   lative to the semantics of the equivalents should be available.
 In the next section we will show how this information can be acquired using a data-driven sense induction method.
 2 Data-driven semantic ana/ ysis in a bi/ ingua/ context We propose to explore the semantic relations of the equivalents of ambiguous words using a parallel corpus and to exploit these relations for SL sense induction.
 A data-driven sense acquisition method based on this type of relations is presented in Apidianaki( 2008).
 The theoretical assumptions underlying this approach are the distributional hypotheses of meaning( Harris, 1954) and of semantic similarity( Miller and Charles, 1989), and that of sense correspondence between words in translation relation in real texts.
 Our training corpus is the English( EN)— Greek( GR) part of the lemmatized and POS-tagged INTERA corpus( Gavrilidou et al., 2004) which contains approximately four million words.
 The corpus has been sentence-and wordaligned at the level of tokens and types( Simard and Langlais, 2003).
 Two bilingual lexicons( one 78 for each translation direction: EN— GRiGR— EN are built from the alignment of word types.
 In these lexicons, each SL word(&) is associated wi   Harris, 1954 Zellig Harris.
 1954.
 Distributional Structure.
 Word, 10: 146-162.    
 Peng Jin Yunfang Wu Shiwen Yu  
 SemEval-2007
 Task S: Multilingual ChineseEnglish Lexical Sample, 2007
 In Proceedings of the 4th International Workshop on Semantic Evaluations( SemEval Prague, Czech Republic,    its equivalents in another language.
 This empirical approach to sense identification circumvents the need for predefined sense inventories and their disadvantages for automatic WSD.1
 The first to 1 Such as the high granularity, the great number and the striking similarity of the described senses, and their adopt it were Brown et al.
( 1991), who represented the two main senses of a SL word by its two most frequent translations in the target language( TL).
 Further promoted by Resnik and Yarowsky( 2000) and endorsed in the multilingual tasks of the Senseval( Chklovski et al., 2004) and Semeval( Jin et al., 2007) exercises, this conception of senses is still found in recent works on the integration of WSD in MT.
 From these works, only that of Carpuat and Wu( 2005) exploits an external hand-crafted sense inventory.
 The use of an external resource, not related to the training corpus of their Statistical Machine Translation( SMT) system, turned out to be one of the causes of the observed deterioration of translation quality.
 In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found    eva/ uation 4.1
 The notion of enriched precision In this section, we will present the evaluation of the proposed WSD method and we will show how the clustering information can be exploited at this stage.9
 The new instances of the nouns of our lexical sample, used for evaluation, come from our test corpus, the sentence aligned EN— GR part of EUROPARL( Koehn, 2005).
 The TUs containing the ambiguous nouns are extracted from the corpus.
 Lacking a goldstandard for evaluation, we exploit information relative to translations.
 In the multilingual tasks of Senseval and Semeval( Ckhlovski et al., 2004; Jin et al., 2007), the translations of the words in the parallel test corpus are considered as their sense tags.
 Here, we consider that the equivalent translating an ambiguous SL word in context( called reference translation) points to a sense described by a cluster.
 Consequently, what is being evaluated is the capacity of the WSD 9 Some of the equivalents of w found in the training corpus and contained in the clusters may not be used in the test corpus.
 The evaluation concerns only those that are found in the test corpus.
 80 method to predict this sense.
 The sense proposed for an instance of an ambiguous word   Jin, Wu, Yu, 2007 Peng Jin, Yunfang Wu and Shiwen Yu.
 2007.
 SemEval-2007
 Task S: Multilingual ChineseEnglish Lexical Sample, In Proceedings of the 4th International Workshop on Semantic Evaluations( SemEval 2007), Prague, Czech Republic, 19-23.    
 Philipp Koehn   Europarl:
 A Parallel Corpus for Statistical Machine Translation.
 2005
 In Proceedings of MT Summit X, 79-86 Phuket, Thailand,   n this way, as the sets of assimilative contexts would contain more features than their intersection, and so it would become more probable to find CFs with the new contexts and to establish' context-cluster' associations.
 4 Semantics-sensitive WSD eva/ uation 4.1
 The notion of enriched precision In this section, we will present the evaluation of the proposed WSD method and we will show how the clustering information can be exploited at this stage.9
 The new instances of the nouns of our lexical sample, used for evaluation, come from our test corpus, the sentence aligned EN— GR part of EUROPARL( Koehn, 2005).
 The TUs containing the ambiguous nouns are extracted from the corpus.
 Lacking a goldstandard for evaluation, we exploit information relative to translations.
 In the multilingual tasks of Senseval and Semeval( Ckhlovski et al., 2004; Jin et al., 2007), the translations of the words in the parallel test corpus are considered as their sense tags.
 Here, we consider that the equivalent translating an ambiguous SL word in context( called reference translation) points to a sense described by a cluster.
 Consequently, what is being evaluated is the capacity of the WSD 9 Some of the equivalents of w f   Koehn, 2005 Philipp Koehn.
 2005.
 Europarl:
 A Parallel Corpus for Statistical Machine Translation.
 In Proceedings of MT Summit X, Phuket, Thailand, 79-86.    
 Alon Lavie Abhaya Agarwal  
 METEOR:
 An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments.
 2007
 In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics( ACL), 228-231 Prague, Czech Republic,    to it, i.e. found in the same synset.
 One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call& quot;a poor-man 's synonymy detection
 algorithm&quot;. Consequently, the WNSynonymy module used maps two unigrams together simply if at least one sense of each word belongs to the same WordNet synset.
 Another problem is that the metric is strongly dependent on a predefined sense inventory.
 Given that such resources are publicly available for very few languages, the synonymy module often is not operational and is omitted.
 83 Lavie and Agarwal( 2007) envisage the possibility of developing new synonymy modules for languages other than English, which would be based on alternative methods and could replace WordNet.
 In the previous sections, we showed how the information acquired by an unsupervised sense induction method can help to account for the words' semantic similarity.
 The created sense clusters, grouping semantically similar equivalents, can be compared to WordNet synsets.
 This kind of semantic information, extracted directly from text data, can constitute an alternative to the use of predefined sense inventories.
 A clear advantage of   Lavie, Agarwal, 2007 Alon Lavie and Abhaya Agarwal.
 2007.
 METEOR:
 An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments.
 In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics( ACL), Prague, Czech Republic, 228-231.    
 George A Miller Richard Beckwith Christiane Fellbaum Derek Groos Katherine Miller  
 Introduction to WordNet:
 An On-line Lexical Database.
 1990 International Journal of Lexicography 3 4 235-312   the equivalents similar to the reference and their scores.
 Before concluding, we would like to take a look at the way the concern for lexical semantics is manifested and taken into account in existing MT evaluation metrics.
 5.3 Semantic simi/ arity in existing MT eva/ uation metrics Lexical semantic relations are supposed to be captured in BLEU by the use of multiple reference translations( Papineni et al., 2002).
 Finding many references for evaluation is, however, rather problematic( Callison-Burch, 2006).
 In METEOR
( Banerjee and Lavie, 2005), such relations are detected by exploiting WordNet( Miller et al., 1990).
 More precisely, the number of pertinent translations is increased using synset information: a translation is correct not only if it corresponds to the reference, but also if it is semantically similar to it, i.e. found in the same synset.
 One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call& quot;a poor-man 's synonymy detection
 algorithm&quot;. Consequently, the WNSynonymy module used maps two unigrams together simply if at least one sense of each word belongs to the same WordNet synset.
 Another problem is that t   Miller, Beckwith, Fellbaum, Groos, Miller, 1990 George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Groos and Katherine Miller.
 1990.
 Introduction to WordNet:
 An On-line Lexical Database.
 International Journal of Lexicography 3(4):
 235-312.    
 George A Miller Walter G Charles   Contextual correlates of semantic similarity.
 1991 Language and Cognitive Processes 6 1 1-28 Miller, Charles, 1991 George A. Miller and Walter G. Charles.
 1991.
 Contextual correlates of semantic similarity.
 Language and Cognitive Processes 6(1):
 1-28.    
 Karolina Owczarzak Josef van Genabith
 Andy Way  
 Labelled Dependencies in Machine Translation Evaluation.
 2007
 In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics( ACL), 104-111 Prague, Czech Republic, Owczarzak, van Genabith, Way, 2007 Karolina Owczarzak, Josef van Genabith and Andy Way.
 2007.
 Labelled Dependencies in Machine Translation Evaluation.
 In Proceedings of the 2nd Workshop on Statistical Machine Translation, 45th Meeting of the Association for Computational Linguistics( ACL), Prague, Czech Republic, 104-111.    
 Kishore Papineni Salim Roukos Todd Ward WeiJing Zhu   BLEU: a Method for Automatic Evaluation of Machine Translation.
 2002
 In 40th Annual Meeting of the Association for Computational Linguistics, 311-318 Philadelphia, PA.,   the similarity score between a proposed translation and the reference but also the number of the SL word 's candidate translations, the number of its senses and their distinctiveness, as well as the number of the equivalents similar to the reference and their scores.
 Before concluding, we would like to take a look at the way the concern for lexical semantics is manifested and taken into account in existing MT evaluation metrics.
 5.3 Semantic simi/ arity in existing MT eva/ uation metrics Lexical semantic relations are supposed to be captured in BLEU by the use of multiple reference translations( Papineni et al., 2002).
 Finding many references for evaluation is, however, rather problematic( Callison-Burch, 2006).
 In METEOR
( Banerjee and Lavie, 2005), such relations are detected by exploiting WordNet( Miller et al., 1990).
 More precisely, the number of pertinent translations is increased using synset information: a translation is correct not only if it corresponds to the reference, but also if it is semantically similar to it, i.e. found in the same synset.
 One of the limitations of this metric is that the words being tested for synonymy are not disambiguated; that is what Banerjee and Lavie call& quot;a poor-man   Papineni, Roukos, Ward, Zhu, 2002 Kishore Papineni, Salim Roukos, Todd Ward and WeiJing Zhu.
 2002.
 BLEU:
 a Method for Automatic Evaluation of Machine Translation.
 In 40th Annual Meeting of the Association for Computational Linguistics, Philadelphia, PA., 311-318.    
 Philip Resnik  
 Exploiting Hidden Meanings:
 Using Bilingual Text for Monolingual Annotation.
 2004 Lecture Notes in Computer Science 2945: Computational Linguistics and Intelligent Text Processing: Proceedings of the 5th International Conference CICLing, Seoul, Korea, 283-299
 In Gelbukh, A.( ed.),   n quality.
 In later works on the subject, which show a more or less important improvement in translation quality, SL word senses are considered as directly reflected in their equivalents found in a parallel training corpus( Cabezas and Resnik, 2005; Carpuat and Wu, 2007; Chan et al., 2007).
 Nevertheless, the theoretical soundness of these senses is not really addressed.
 1.2 Advantages of cross-/ingua/ sense determination Crosslingual sense induction offers a standard criterion for sense delimitation: the translation equivalents of ambiguous words are supposed to reveal their hidden meanings( Resnik, 2004).
 Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation.
 Conceiving WSD irrelevance to the domains of the processed texts( Edmonds and Kilgarriff, 2002).
 Proceedings of the 12th Conference of the European Chapter of the ACL, pages 77–85, Athens, Greece, 30 March– 3 April 2009.
 c � 2009 Association for Computational Linguistics 77 as lexical selection thus seems natural( Vickrey et al., 2005): it appears that there is no reason to p   Resnik, 2004 Philip Resnik.
 2004.
 Exploiting Hidden Meanings: Using Bilingual Text for Monolingual Annotation.
 In Gelbukh, A.( ed.), Lecture Notes in Computer Science 2945: Computational Linguistics and Intelligent Text Processing:
 Proceedings of the 5th International Conference CICLing, Seoul, Korea, 283-299.    
 Philip Resnik David Yarowsk   Distinguishing Systems and Distinguishing Senses: New Evaluation Methods for Word Sense Disambiguation, 2000 Natural Language Engineering 5 3 113-133 Resnik, Yarowsk, 2000 Philip Resnik and David Yarowsk.
 2000.
 Distinguishing Systems and Distinguishing Senses: New Evaluation Methods for Word Sense Disambiguation, Natural Language Engineering 5(3): 113133.    
 Helmut Schmid   Probabilistic Part-of-Speech Tagging Using Decision Trees.
 1994
 In Proceedings of the International Conference on New Methods in Language Processing, 44-49 Manchester,   reference, in cases of no exact correspondence.
 Thus, a translation which is semantically similar to the reference is considered to be correct if they are both found in the cluster proposed during WSD.
 This renders the evaluation more flexible and significantly increases the quantity of semantically pertinent translations compared to the baseline.
 The strict and enrichedKDscores are estimated by considering as correct( score = 1) every translation that is pertinent according to the corresponding evaluation principles.
 The 10 Our test corpus has been tagged and lemmatized using the TreeTagger( Schmid, 1994).
 11
 The SL contextual information exploited for WSD.
 82 results indicate the increase in pertinent translations.
 base/ ine 52.14%
 strict -f-score 48.37% enriched f-score 77.79%
 We observe that the strict f-score is lower than the baseline.
 This happens because our method proposes equivalents semantically similar to the reference for some instances for which the baseline predictions are correct.
 However, these pertinent predictions are not taken into account by the principle of strict precision.
 This is the case in example( b): the baseline prediction( e7chacouq) for this instance o f implicati   Schmid, 1994 Helmut Schmid.
 1994.
 Probabilistic Part-of-Speech Tagging Using Decision Trees.
 In Proceedings of the International Conference on New Methods in Language Processing, Manchester, 44-49.    
 David Vickrey Luke Biewald Marc Teyssier Daphne Koller   Word-Sense Disambiguation for Machine Translation.
 2005
 In Proceedings of the Joint Conference on Human Language Technology
 i Empirical Methods in Natural Language Processing( HLTEMNLP), 771-778 Vancouver, Canada,   ds are supposed to reveal their hidden meanings( Resnik, 2004).
 Additional advantages become evident in MT: when the candidate senses of an ambiguous word consist of its possible translations, identifying the sense carried by a new instance of the word coincides with its translation.
 Conceiving WSD irrelevance to the domains of the processed texts( Edmonds and Kilgarriff, 2002).
 Proceedings of the 12th Conference of the European Chapter of the ACL, pages 77–85, Athens, Greece, 30 March– 3 April 2009.
 c � 2009 Association for Computational Linguistics 77 as lexical selection thus seems natural( Vickrey et al., 2005): it appears that there is no reason to pass through senses in order to arrive to translations.
 A correct translation may be attained even without WSD, as in the case of parallel ambiguities where the SL and TL words are similarly ambiguous( Resnik and Yarowsky, 2000).2 1.3 Disadvantages of cross-/ingua/ sense determination However, this conception of senses is not theoretically sound, as translation equivalents do not always constitute valid sense indicators.
 This is often neglected in an attempt to render the sense inventory as close as possible to the training corpus of the SMT system.
 So,    Vickrey, Biewald, Teyssier, Koller, 2005 David Vickrey, Luke Biewald, Marc Teyssier and Daphne Koller.
 2005.
 Word-Sense Disambiguation for Machine Translation.
 In Proceedings of the Joint Conference on Human Language Technology
 i Empirical Methods in Natural Language Processing( HLTEMNLP), Vancouver, Canada, 771-778.   