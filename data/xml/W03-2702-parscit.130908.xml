<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000571">
<title confidence="0.949821">
Why a static interpretation is not sufficient in spatial communication*
</title>
<author confidence="0.922942">
John A. Bateman
</author>
<affiliation confidence="0.89481325">
FB 10: Faculty of Linguistics and
Literary Sciences
University of Bremen
Bremen, Germany
</affiliation>
<email confidence="0.6086225">
bateman@uni-
bremen.de
</email>
<author confidence="0.828014">
Kerstin Fischer
</author>
<affiliation confidence="0.8566745">
FB 10: Faculty of Linguistics and
Literary Sciences
University of Bremen
Bremen, Germany
</affiliation>
<email confidence="0.6007555">
kerstinf@uni-
bremen.de
</email>
<note confidence="0.6993995">
Thora Tenbrink
FB 10: Faculty of Linguistics and
</note>
<author confidence="0.754822">
Literary Sciences
</author>
<affiliation confidence="0.882512">
University of Bremen
Bremen, Germany
</affiliation>
<bodyText confidence="0.448498">
tenbrink@informa-
tik.uni-bremen.de
</bodyText>
<sectionHeader confidence="0.993034" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999638583333333">
This paper proposes a research methodol-
ogy for attacking the problem of
providing fluent and natural discourse
about space and spatially situated tasks
between naive users and robots. We sug-
gest flexible and adaptive ontology me-
diation, parameterized according to
empirically determined discourse and
contextual factors, as a suitable architec-
ture with clear applications for the treat-
ment of natural human-human dialog
also.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989748461538462">
Linguistic communication about space in a
situated human-robot interaction scenario in-
volves more complex and flexible interpretation
mechanisms than might be expected. In addition
to the inherent complexity of interpreting situa-
tionally dependent – and interactively negotiated
– spatial language, users unfamiliar with their
artificial interlocutor address the system accord-
ing to assumptions about its abilities that are
often inaccurate. This paper aims at identifying
central problems involved in spatial communica-
tion between humans and robots, and presents
our approach to solving them.
Natural language is an essential mode of inter-
action between users and sophisticated spatially-
aware systems such as mobile assistance robots.
* The authors are listed in alphabetical order.
Providing suitably sophisticated and flexible
natural language capabilities for ever more com-
plex interaction scenarios is a major problem.
Such interaction needs to be as natural and non-
intrusive as possible in order to support the
widest possible range of potential users.
However, most of the features that make interac-
tion &apos;natural&apos; still present substantial challenges
for dialog systems.
The consideration of robots and humans in real
communicative situations presents a valuable
research environment for investigating dialog
systems further. The abilities, knowledge and
linguistic responses of the robots can be varied
experimentally in a manner not possible in hu-
man-human interaction. The combination of the
necessary modules in a complete dialog system
is, however, a major research challenge in its
own right—one which again has similarities with
the development of accounts for human dialog
alone. In particular, the lack of appropriate
modularizations of the technical components
involved in complete systems that combine
spatial and linguistic capabilities is a significant
bottleneck.
One particularly effective strategy for
modularization is the adoption of linguistically
motivated ontologies that mediate between do-
main or application knowledge and Human
Language Technology (HLT) components. It
might therefore be expected that some kind of
ontology mediation could be usefully applicable
to the modeling of dialog capabilities.
Problematic, however, is that many results
concerning natural dialog between humans have
</bodyText>
<page confidence="0.975643">
1
</page>
<bodyText confidence="0.999975735294117">
now established that the form of linguistic ex-
pressions employed during dialog depends cru-
cially on the interaction situation. This effect is
especially strong when dealing with settings
which involve discourse participants with differ-
ing perceptual and linguistic abilities and prefer-
ences or when those settings are themselves
highly complex and change while the discourse
develops as the participants move around. Such
settings represent the standard case in mobile
robot interaction scenarios. Current strategies for
ontology mediation exhibit a rigidity that is
inappropriate for the relationships observed in
real interactions. Here, a negotiation of mediation
within &apos;conversational&apos; interaction appears
crucial both for ontology design and for achiev-
ing inter-operability.
This combines several directions of research in
a new way. Our purpose in this paper is to briefly
motivate the research domain of human-robot
interaction as a methodology for investigating
dialog and to set out our own investigative meth-
ods and modeling goals as projected in our newly
established research groupt. Our particular focus
is on the specific effect of a robot interaction
partner on the linguistic and spatial choices of a
human speaker, and on the negotiative processes
involved in achieving common ground. These
factors are to be investigated as situational pa-
rameters determining the linguistic properties of
the language employed. Inter-ontology mediation
will then be used to parameterize mappings
between situational factors and linguistic proc-
essing and generation.
</bodyText>
<sectionHeader confidence="0.7543095" genericHeader="method">
2 Spatial Communication in a Robotic
Scenario
</sectionHeader>
<bodyText confidence="0.9913556875">
The empirical questions we address are located in
two problem areas: first, the complexity of the
interpretation of spatial expressions based on the
considerable variability of implicitly underlying
reference systems and the associated negotiation
processes between the interactants; second, the
peculiarities pertaining to the choice of linguistic
expressions in an unfamiliar interaction situation
involving an artificial interlocutor. Both problem
areas combine in linguistic interaction scenarios
in which users are required to communicate with
an unfamiliar robot about spatial surroundings.
The research project II-OntoSpace, directed by John Bateman, Kerstin
Fischer, and Reinhard Moratz, is part of the newly established Collaborative
Research Center (SFB) &amp;quot;Spatial Cognition&amp;quot; located at the universities of
Bremen and Freiburg.
</bodyText>
<subsectionHeader confidence="0.995725">
2.1 Interpreting Spatial Expressions
</subsectionHeader>
<bodyText confidence="0.99997883018868">
In the communication of spatial information,
work has addressed the formal analysis of the
meaning of spatial expressions on the one hand,
and their choice under certain specifiable circum-
stances on the other. Lexical semantic ap-
proaches discuss the possibility of a core
semantic meaning for spatial expressions from
which possible deviations can be derived (e.g.,
Eschenbach 1999); psychologically inspired
work has revealed the importance of functional
categorizations (Garrod and Sanford 1988; Cov-
entry, 1998); while work from robotics has
introduced the notion of a field potential for
describing degrees of likelihood of positioning
(cf. Stopp et al., 1994).
Psycholinguistic experimental studies on spa-
tial situations focus on different kinds of mental
representations that are reflected verbally in the
speakers&apos; utterances. A central concept underly-
ing much spatial expression work is that of
reference systems (Hermann and Grabowski,
1994). Such systems may be intrinsic, relative,
and absolute (Levinson, 1996), all of which may
— depending on various factors of the actual
situation — be employed from either of three
different perspectives: speaker-centered, listener-
centered, or third-party point of view. In intrinsic
reference systems, objects are located by refer-
ring to the intrinsic properties of another entity,
such as the speaker&apos;s front in &amp;quot;The ball is in front
of me&amp;quot;. Relative reference systems depend on the
presence of a further entity (the so-called rela-
turn), as in &amp;quot;The ball is in front of the table&amp;quot;. If
(at least) one similar entity is present rather than
a different relatum, speakers employ group-based
reference (Moratz et al., 2001). Absolute refer-
ence systems depend on the earth&apos;s cardinal
directions, such as north or south.
In tasks involving route descriptions rather
than the localisation of objects, further kinds of
perspectives, and combinations of perspectives,
are available to the speaker: for instance, one can
assume the perspective of an &amp;quot;imaginary wan-
derer&amp;quot; (an imagined person that walks along the
route described). At the same time speakers may
refer to landmarks available in the scenery
(Hermann and Grabowski, 1994), and they may
adapt their linguistic choices of spatial expres-
sions flexibly according to the changing visual
perception.
The complexity of the repertory of available
spatial reference systems requires a high degree
of flexibility and awareness of possible misun-
</bodyText>
<page confidence="0.988278">
2
</page>
<bodyText confidence="0.999983324324324">
derstandings in natural interaction, all the more
so as the intended kind of reference is seldom
explicitly specified and subsequently retained
throughout a communication situation. Rather, it
is negotiated and changed during the interaction
(Tversky et al., 1999). Especially in cases of
qualitative or vague spatial instructions, there is
often a need for interactive negotiation about the
exact semantics of the instruction (Wachsmuth
and Cao, 1995). Conversational participants often
agree on situationally dependent representations,
such as metonymies, in order to achieve smooth
and effective communication (e.g., Rieser, 1996).
Reference resolution is achieved in dependence
on the visual as well as the linguistic context;
influenced, for instance, by the current focus of
attention (Kessler et al., 1999). This process may
reach a high level of complexity if the discourse
situation offers a wide range of conceptual repre-
sentations.
Speakers also react to their interaction part-
ner&apos;s contributions, and appear to attune their
linguistic choices to what they believe to be
suitable for their partner in the situation at hand.
For example, Schegloff (1972) shows how &amp;quot;for-
mulating place&amp;quot; depends on the recipient for
whom the description is designed. Schober
(1993) found that speakers attend to their hearers&apos;
clues as to whether they have understood the
instruction in the sense that the references have
been grounded (Clark and Wilkes-Gibbs, 1986).
Garrod and Anderson (1987) found that commu-
nication partners interactively developed distinct
but consistent description schemes, which re-
flected different kinds of underlying mental
representations. These were dependent on the
interaction itself as well as on the given task.
</bodyText>
<subsectionHeader confidence="0.991098">
2.2 Communicating with Artificial In-
terlocutors
</subsectionHeader>
<bodyText confidence="0.999984354166667">
In the same way as the use of spatial expressions
depends on the recipient and on the negotiation
processes between the interlocutors, linguistic
choices in general are influenced by the speakers&apos;
understanding of their communication partner
and the interactive negotiation of this conceptu-
alization during the interaction (cf. Sacks, 1992).
This is most obvious in the communication with
artificial interlocutors; human-computer interac-
tion has therefore been suggested to constitute a
special linguistic register (Krause &amp; Hitzenber-
ger,1992).
Several studies on human-computer interaction
have shown that users may differ considerably in
the language they direct to a system and thus that
the communication with artificial systems is not
homogeneous. Instead, the linguistic properties
of the utterances depend very much on the way
speakers conceptualize the system (cf. Fischer
2000) and on the system&apos;s output (cf. Fischer &amp;
Batliner, 2000). Since speakers design their
speech for their recipients, the way they think
about their communication partner may have a
strong impact on the form of their utterances.
Particularly the conceptualization of the robot as
a tool versus as human-like may lead to signifi-
cantly different linguistic behavior (Fischer
2000).
This insight corresponds to previous findings
of psycholinguistic studies that show that the
negotiation of linguistic behavior, or alignment,
takes place on all linguistic levels (Garrod, 1999;
Clark, 1996), a result supported and suggested by
findings in human-computer interaction (Amal-
berti et al. 1993; Fischer 1999, 2000) and now
again forcefully argued in Pickering and Garrod
(in press).
Thus, human-computer conversation cannot be
regarded as a single rigidly defined linguistic
variety, but instead is constantly negotiated and
adapted, influenced both by the system design
and by the users&apos; conceptualizations of the sys-
tem. The question remains as to whether it is
possible to specify limits and constraints on this
variability. It is precisely this flexibility that
makes this kind of interaction particularly rele-
vant for research into the mechanisms of dia-
logue and interaction in general.
</bodyText>
<sectionHeader confidence="0.960812" genericHeader="method">
3 Our approach
</sectionHeader>
<bodyText confidence="0.999988666666667">
Our approach has two interacting components.
On the one hand, we undertake the controlled
elicitation of data in experimental settings, vary-
ing particular situational parameters and relating
the linguistic choices speakers make in the inter-
action with the robot to those parameters. On the
other hand, we use the data to motivate particular
models of the dialogue mechanisms involved,
which will then be used for developing a dia-
logue system enabling more natural communica-
tion. The improved system will then be employed
for further rounds of experiments.
Experiments, outlined in more detail below,
will give insights about the effect different be-
haviors, appearances, and linguistic output of the
robot may have on the users&apos; ways of thinking
about the robot and how these different concep-
tualizations influence the users&apos; linguistic behav-
</bodyText>
<page confidence="0.994961">
3
</page>
<bodyText confidence="0.999992434343435">
ior. The linguistic properties affected by different
conceptualizations of the robots are expected to
be found on all linguistic levels, including lexical
choices (e.g. basic level vs. abstract categories),
syntactic constructions (e.g. the use of impera-
tive), morphological reduction, and phonological/
prosodic features (e.g., syllable lengthening,
speech rate, and other error resolution strategies).
An important aspect of the model to be con-
structed is the requirement that very different
kinds of representations are integrated within a
single functioning system. The robots, and their
controlling software, typically incorporate spatial
representations that may be arbitrarily far re-
moved from those assumed by the human inter-
actants and expressed in their linguistic
utterances. The flexibility required during nego-
tiation of shared discourse strategies within any
interaction argues strongly against the &apos;pre-
wired&apos; solutions common in such work.
Here our approach draws on a standard tech-
nique for achieving modularity that has been
pursued within several branches of NLP. This
involves employing, either explicitly or implic-
itly, ontologies that represent information at
various levels of abstraction within a system. One
of the first systems to employ this technique for
re-use was the Penman text generation system
(Mann and Matthiessen, 1985), within which the
Penman Upper Model was developed (Bateman
et al., 1990). Re-use for natural language genera-
tion within this framework was described in
detail by, e.g., Bateman (1990), and follows the
strategy of subordinating domain model concepts
to upper model concepts so that domain concepts
inherit the linguistic possibilities for expression
available to their superordinate upper model
concepts. For example, if a domain object—such
as some entity recognized by the robot—is sub-
ordinated to the upper model concept Nonde -
c ompo s ab 1 e - Obj ec t, then the generation
component knows which kinds of linguistic
constructions may be used for describing this
concept and which not. This approach has since
been widely employed.
Although an obvious benefit of this approach
is that it enables semantic specifications to make
direct use of domain model concepts, it also has a
striking deficiency. This was revealed most
clearly in research efforts aimed at multiple
register generation—that is, the generation by
single generic text generation systems of texts
belonging to diverse text types and for varying
levels of reader/user expertise (cf. Bateman and
Paris, 1989). Different registers can easily require
single domain concepts to be expressed so diver-
gently that any single upper model concept
assignment is invalidated. What one type of text
may consider nondecomposable might in another
be treated as non-atomic and decomposable into
parts.
This necessitates the maintenance of at least
two distinct levels of ontological information—
one purely linguistic semantic, that of the upper
model, and one for the domain model—with
flexible mapping relationships between them. In
the context of our experiments here, the domain
model will focus particularly on spatial relation-
ships and object attributes shown to be relevant
for forming spatial expressions.
The preservation of two distinct levels of in-
formation is echoed in a range of very diverse
approaches (cf., e.g., the distinction between LF
and QLF in Alshawi, 1992; in temporal seman-
tics in Herweg, 1991; and ontology-based utter-
ance analysis in Lang, 1991), the extent and
range of the flexibility required in mappings
between levels has not been mapped out satis-
factorily. It has also not been anchored as firmly
as is necessary in the details of linguistic nego-
tiation within dialog.
Our experiments will seek to provide crucial
data concerning the range and flexibility of the
mappings required, focusing on the area of
spatial relations and their linguistic expression.
The allocation of spatial configurations to par-
ticular linguistically expressed orientations is
known to vary according to the interactional
context and the kinds of spatial configurations
encountered. As a very simple illustration, for
example, whether a speaker uses &apos;on&apos; or in&apos; a
location reflects as much a negotiated reference
system within an interaction as it does a state-
ment about a priori dimensionality of the loca-
tion referred to. Such allocations, expressed in
terms of links between selections from the spatial
and linguistic ontologies, are to be parameterized
according to aspects of the negotiated communi-
cation revealed by the experiments.
</bodyText>
<sectionHeader confidence="0.993599" genericHeader="method">
4 Empirically-derived Linguistic Pa-
rameterization
</sectionHeader>
<bodyText confidence="0.999936428571429">
We address the parameterization of ontology
mappings related to spatial configurations by
making the relationship between situational
variables and linguistic properties transparent.
For instance, the users&apos; choices of spatial refer-
ence systems and of strategies for referring to
landmarks are central parameters of linguistic
</bodyText>
<page confidence="0.987945">
4
</page>
<bodyText confidence="0.999952166666667">
variability in human-robot interaction. Users may
(justifiably!) be uncertain about what the robot
can perceive, and so the lack of mutual and
reflexive common ground for the interactants
regarding the spatial situation can lead to insecu-
rity about which objects may serve as landmarks
and how they can be referred to. This variability
can be experimentally controlled. Closely related
to this factor are the participants&apos; linguistic and
spatial choices concerning group-based reference
— a kind of reference system often neglected in
the literature — using further similar objects
instead of a different object as a relatum to spec-
ify the target object&apos;s position (Moratz et al.,
2001). Such issues are addressed by confronting
users with tasks involving different configura-
tions of diverse (similar and differing) objects,
the robot, and the user.
</bodyText>
<subsectionHeader confidence="0.997827">
4.1 An Example: Perspective Taking
</subsectionHeader>
<bodyText confidence="0.999895543859649">
In previous work we have established that con-
trolled experimental settings yield significant
information concerning modeling requirements.
In Moratz et al. (2001) it was shown that all users
consistently — and often inexplicitly — took the
robot&apos;s perspective in their linguistic expressions.
Subsequently, in order to see whether the previ-
ous finding was an artifact of the experimental
setting, we carried out further studies involving
different conditions designed for prompting
variation in perspective taking. The experimental
situation was designed to reveal whether goal
instructions would be made relative to the lis-
tener (the robot or another human) or the speaker,
whether extrinsic reference systems would be
employed (e.g. &apos;drive north&apos;), and whether a
group of similar objects would be used for object
localization.
We varied a number of different scenarios, ex-
perimenting with different positions of human
instructor and robot, and with different address-
ees (a human and a robot instructee). In all set-
tings, the human instructors were told to instruct
their (human or robot) communication partner to
localize objects on the basis of their spatial
position with respect to similar objects by means
of written instructions. In one scenario,
instructors were seated in front of a computer in
which they should type their instructions. The
robot&apos;s task was to measure the distance between
the objects indicated. The position of the robot (a
Pioneer 2) with respect to the objects and the
instructor was varied (see Figure 1 where the
robot is located at Pos. C) in order to identify
factors influencing perspective taking. This
scenario was repeated with 21 instructors.
In another scenario the same task was carried
out by 17 instructors who communicated with a
human communication partner by means of
written instructions. Here the task for the human
instructee (replacing the robot in the previous
experiment) was simply to point to the object
described (instead of measuring distances).
A preliminary analysis revealed that the data in
the human-to-human experiment basically repli-
cate the results obtained by Schober (1998):
instructors varied in taking either their own or the
other&apos;s perspective, marking their choice usually
only in the case of problems after a negotiation
process. In contrast, in the human-robot scenario,
irrespective of the position of the robot with
respect to the instructor, instructors only took the
robot&apos;s perspective. This strategy was often
explicitly marked. If the task was to measure the
distance between an object and the robot itself,
the robot was often not addressed itself but
referred to as robot or robby.
</bodyText>
<figureCaption confidence="0.997419">
Figure 1. Experimental Scenario.
</figureCaption>
<subsectionHeader confidence="0.999482">
4.2 Determinants of Linguistic Choices
</subsectionHeader>
<bodyText confidence="0.996857166666667">
The results of the previous experiments sug-
gest that in human-robot interaction, irrespective
of the particular spatial configuration, human
instructors reliably take the robot&apos;s point of view.
This behavior differs from that found in human-
human interaction and so needs to be considered
in designing dialog interpretation strategies for
such systems.
From this starting point it is necessary to in-
vestigate more closely the precise conditions
which trigger the difference in observed dialog
behavior. So far, we have used only one type of
</bodyText>
<figure confidence="0.988878111111111">
ED, 114cm
0 d-le
Pos. A
I 54 73 0
Pos. C
40 cm
oo
Pos. B
I,&apos;
</figure>
<page confidence="0.957013">
5
</page>
<bodyText confidence="0.999977891891892">
robot in the experiments, and the linguistic output
by the robot was tightly constrained for meth-
odological reasons (Fischer, in press). Further
plans now are to carry out experiments with a
different type of robot (the Aibo from Sony, a
robot resembling a small dog) and employing
more advanced linguistic capabilities on the part
of the robot. This allows us to vary the communi-
cative situation between the original simple robot
scenario and human-human communication in a
precisely controlled fashion. This should reveal
the determining factors for instructor&apos;s choices
with respect to perspective taking.
Currently we hypothesize that this behavior is
conditioned by the level of sophistication of the
robot&apos;s output on the one hand, and the complex-
ity of the spatial setting on the other. Thus, more
challenging scenarios that we now plan to ex-
plore will require the human users to employ
localization sequences in order to achieve the
communicative goal, which may consist in in-
structing the robot to move along a certain path
towards a specific location. Along that path
diverse kinds of objects can be placed that may
or may not be used by the test subjects as land-
marks for the route instruction. Here, a specific
research issue is that of consistency in the in-
struction chains used in route instructions. For
this purpose, experimental scenarios will be used
which at certain places offer themselves for
diverse kinds of reference systems. The precise
linguistic behavior of the robot during the ex-
periment will also be varied. Our expectation is
that moving through an environment with several
differing elements will lead the user to employ
varying kinds of reference systems in single
localization sequences.
</bodyText>
<subsectionHeader confidence="0.999796">
4.3 Parameterized Ontology Mapping
</subsectionHeader>
<bodyText confidence="0.999778564102564">
We are planning to employ inter-ontology map-
pings in order to link abstract spatial representa-
tions with their possible linguistic expressions in
a flexible manner. The users&apos; choices in different
experimental scenarios and in different dialog
situations allow us to explore the limits and
requirements of these variable mappings.
We can illustrate the potential role of param-
eterization of this kind of mediation by consid-
ering again the reference systems introduced
above. For each reference system, various objects
located spatially need to be assigned to specific
roles within the reference system—e.g., as land-
marks—and to receive an orientation. If the
speaker is facing the robot, and the robot is
assumed by the speaker to be facing him or her,
then a choice of reference system relative to the
speaker will allocate &apos;left&apos; and &apos;right&apos; in one
orientation whereas a choice relative to the robot
will allocate the same terms to the directly oppo-
site orientation. This means that the assignment
between concrete objects and relations in the
spatial domain will be mapped to quite distinct
objects and directions in the linguistic domain.
This relationship can be captured as a relation
between the two ontology levels. Which assign-
ment is made may be left implicit in the utter-
ances of the speaker, may be indicated explicitly
or, the case of particular interest to us, may be
determined by other factors in the communicative
situation—including both how the robot appears
to the human and the linguistic behavior of the
robot.
The flexibility of mediation is to be modeled
by the parameterization of the particular inter-
ontology mapping constructed, while the kinds
and limits of parameterization needed will be
explored experimentally. This relationship is
summarized graphically in Figure 2.
</bodyText>
<figure confidence="0.820826666666667">
linguistic behaviour
reference
system 1
</figure>
<figureCaption confidence="0.9894965">
Figure 2. Parameterized Inter-Ontology
Mediation.
</figureCaption>
<bodyText confidence="0.99991575">
The references systems are represented by
particular configurations of concepts and rela-
tions in the linguistic ontology. These are then
mapped to the spatial representations. The pa-
rameterization of this mapping falls into two
main categories: situational and interactional.
The situational parameters include the appear-
ance of the robot, the language complexity,
spatial complexity and task complexity; the
interactional parameters include the particular
linguistic forms used in the interaction and the
dialog strategies employed.
</bodyText>
<figure confidence="0.992993235294118">
&amp;quot;left-right&amp;quot; &amp;quot;right-left&amp;quot;
1342 0.1e1
Spatially augmented
domain representation
relevant for the robot
Robot sensory data
reference
system 2
selection
parameter-
ised by
context and
lingustic
cues
---------------- :ran.
0
00 0 13411
</figure>
<page confidence="0.988064">
6
</page>
<bodyText confidence="0.999956333333333">
For the perspective-taking problem illustrated
here, for instance, the users&apos; view of the robot
seems to entail that their instructional choice will
generally be to take the robot&apos;s perspective. This
is then accounted for by specifying appropriate
constraints on the particular subordination em-
ployed between spatial and linguistic ontology.
More complex considerations will involve the
mapping of spatial relations in the spatial ontol-
ogy to appropriate configurations in the linguistic
ontology: this again depends on both situational
and interactional context.
</bodyText>
<sectionHeader confidence="0.989252" genericHeader="conclusions">
5 Conclusion and Outlook
</sectionHeader>
<bodyText confidence="0.999989136363637">
The main feature of the research method we
propose is a combination of experimental control
and considerable flexibility in the environment in
which the human and artificial agents are inter-
acting. This flexibility of the environment is
directly mirrored in the language found in the
various situations: the linguistic properties of the
users&apos; utterances, and the corresponding require-
ments for natural language analysis and genera-
tion in the dialog system, will depend at least on
the perspective of the user, the arrangement of
objects and landmarks, the user&apos;s conception of
their artificial communication partner, the inter-
actional history, and whether user and system
share the same spatial position. This variability
demands not particular solutions to selected
problems, but generic and re-usable techniques.
Such techniques may be supported by param-
eterized ontology mediation of the kind sug-
gested. Moreover, there is a direct link between
this kind of approach and earlier work on multi-
ple register generation and analysis. The situ-
ational parameters correspond to traditional
notions of register variation—i.e., depending on
the situational features holding, differing linguis-
tic features occur with higher or lower probabil-
ity (cf. Biber, 1993). Another way of viewing this
process is to say that the domain ontology con-
figurations are associated with differing &apos;views&apos;
of the linguistic system. As the register changes,
so does the linguistic behavior observed.
We now take this further by adding in the in-
teractional parameters. This means that the
precise correspondences between linguistic and
domain configurations, as well as the &apos;view&apos; of
the linguistic system, can vary within an interac-
tion; this has been termed microregister variation
in Bateman (1986). Microregisters follow closely
the spirit of Garrod and Sanford (1988) and the
use of dialog interaction to construct `ontologies&apos;
of the domain of discourse on the fly, while more
explicitly considering shared (or aligned) lin-
guistic representations as shown to be necessary
in Pickering and Garrod (in press).
</bodyText>
<sectionHeader confidence="0.990278" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999961666666667">
This work is part of the project Il-OntoSpace of
the newly established SFB/TR8 &amp;quot;Spatial Cogni-
tion&amp;quot; coordinated by Christian Freksa. We are
grateful for the financial support of the DFG and
to Reinhard Moratz for useful discussions and
cooperation in the robotics area.
</bodyText>
<sectionHeader confidence="0.998487" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981558631578947">
Alshawi, H. (ed.)(1992) The Core Language Engine,
Cambridge, Massachusetts: MIT Press.
Amalberti, R., N. Carbonell, and P. Falzon (1993)
User Representations of Computer Systems in Hu-
man-Computer speech interaction. International
Journal of Man-Machine Studies, 38:547-566.
Bateman, J.A. (1986) Utterances in context: towards a
systemic theory of the intersubjective achievement
of discourse, PhD dissertation. University of Edin-
burgh, Scotland.
Bateman, J.A. (1990) Upper Modeling: Organizing
Knowledge for Natural Language Processing. In:
Proceedings of the Fifth International Natural
Language Generation Workshop, pp. 54--60. Daw-
son, PA.
Bateman, J.A. and Paris, C.L. (1989) Phrasing a Text
in Terms the User Can Understand. In: Proceedings
of the Eleventh International Joint Conference on
Artificial Intelligence, pp. 1511--1517. Detroit,
Michigan.
Bateman, J.A., Kasper, R.T., Moore, J.D. and Whit-
ney, R.A. (1990) A general organization of Knowl-
edge for natural language processing: the
PENMAN Upper Model, Marina del Rey, Califor-
nia: USC/Information Sciences Institute .
Biber, D. (1993) Using register-diversified corpora for
general language studies. Computational Lingui-
stics 19, 219--242.
Clark, H.H. (1996) Using Language. Cambridge:
Cambridge University Press.
Clark, H. and Wilkes-Gibbs, D. (1986). Referring as a
collaborative process. Cognition, 22:1-39.
Coventry, K.R. (1998) Spatial Prepositions, Func-
tional Relations, and Lexical Specification. In
Olivier, Patrick and Klaus-Peter Gapp (eds.) Repre-
sentation and Processing of Spatial Expressions.
Mahwah, New Jersey: Lawrence Erlbaum, pp. 247-
262
</reference>
<page confidence="0.996829">
7
</page>
<reference confidence="0.999805844660194">
Eschenbach, C. (1999) Geometric structures of frames
of reference and natural language semantics. Spa-
tial Cognition and Computation, 1 (4), 329-348.
Fischer, K. (1999) Repeats, Reformulations, and
Emotional Speech: Evidence for the Design of
Human-Computer Speech Interfaces. In Bullinger,
H. &amp; Ziegler, J. (eds.): Human-Computer Interac-
tion: Ergonomics and User Interfaces. Lawrence
Erlbaum Ass., London, pp. 560-565.
Fischer, K. (2000) What Is a Situation? Proceedings of
Gotalog 2000, Fourth Workshop on the Semantics
and Pragmatics of Dialogue, Goteborg University,
15-17 June 2000. Gothenburg Papers in Computa-
tional Linguistics 00-5, pp. 85-92.
Fischer (in press). Linguistic Methods for Investigat-
ing Concepts in Use. In: Stolz, Th. and Kolbe, K.
(eds.): Methodologie in der Linguistik. Frankfurt
a.M.: Lang.
Fischer, K. and Batliner, A. (2000) What Makes
Speakers Angry in Human-Computer Conversation.
Proceedings of the Third Workshop on Human-
Computer Conversation, Bellagio, Italy, 3-5 July
2000.
Garrod, S. (1999): The Challenge of Dialogue for
Theories of Language Processing. In: Garrod, S.
and Pickering, M.J. (eds.): Language Processing.
Hove: Psychology Press.
Garrod, S. and Anderson, A. (1987). Saying what you
mean in dialogue: A study in conceptual and se-
mantic coordination. Cognition 27: 181-218.
Garrod, S.C., and A.J. Sanford (1988) Discourse
models as interfaces between language and the
spatial world. Journal of Semantics, 6:147-160.
Herrmann, T. and Grabowski, J. (1994) Sprechen:
Psychologie der Sprachproduktion. Heidelberg:
Spektrum Verlag.
Herweg, M. (1991) Aspectual requirements of tempo-
ral connectives: evidence for a two-level approach
to semantics. In: Pustejoysky, J. and Bergler, S.,
(eds.) Proceedings of the 1991 ACL Workshop on
Lexical Semantics and Knowledge Representation,
pp. 152--164. Berkeley, CA.
Kessler, K., Duwe, I. and Strohner, H. (1999)
Grounding Mental Models: Subconceptual Dy-
namics in the Resolution of Reference in Dis-
course. In: Gert Rickheit and Christopher Habel
(eds.), Mental Models in Discourse Processing and
Reasoning. Amsterdam: Elsevier.
Krause, J. and Hitzenberger, L (1992). Computertalk.
Hildesheim: Olms.
Lang, E. (1991) The LILOG ontology from a linguis-
tic point of view. In: Herzog, 0. and Rollinger, C.
(eds.) Text understanding in LILOG: integrating
computational linguistics and artificial intelligence,
Final report on the IBM Germany LILOG-Project,
pp. 464--481. Berlin: Springer.
Levinson, St. C. (1996). Frames of reference and
Molyneux&apos;s question: Crosslinguistic evidence. In
P. Bloom, M.A. Peterson, L. Nadel and M.F.
Garrett (eds.), Language and Space (pp. 109-169).
Cambridge, MA: MIT Press.
Mann, W.C. and Matthiessen, C.M.I.M. (1985)
Demonstration of the Nigel Text Generation Com-
puter Program. In: Benson, J.D. and Greaves, W.S.,
(eds.) Systemic Perspectives on Discourse, Volume
1, pp. 50--83. Norwood, New Jersey : Ablex.
Moratz, R., K. Fischer, and T. Tenbrink. (2001)
Cognitive Modelling of Spatial Reference for Hu-
man-Robot Interaction. International Journal On
Artificial Intelligence Tools, 10:4, World Scientific
Publishing, Singapur.
Pickering, M.J and Garrod. S. (in press) Toward a
mechanistic psychology of dialogue. Behavioural
and Brain Sciences.
Rieser, H. (1996) Reprasentations-Metonymie, Per-
spektive und Koordination in aufgabenorientierten
Dialogen. In: C. Umbach, M. Grabski and R. Hor-
nig (Hrsg.). Perspektive in Sprache und Raum.
Wiesbaden: Deutscher Universitats-Verlag.
Sacks, H. (1992): Lectures on Conversation. Oxford:
Blackwell.
Schegloff, E. A. (1972) Notes on a conversational
practice: formulating place. In Giglioli, Per Paolo
(ed.): Language and social context. Harmond-
sworth: Penguin.
Schober, M.F. (1993). Spatial Perspective-Taking in
Conversation, Cognition 47: 1-24.
Schober, M.F. (1998). How addressees affect spatial
perspective choice in dialogue. In P.L. Olivier &amp;
K.-P. Gapp (Eds.), Representation and processing
of spatial expressions (pp. 231-245). Mahwah, NJ:
Lawrence Erlbaum.
Stopp, E., Gapp K.-P., Herzog, G. Laengle, T. and
Leuth, T. (1994) Utilizing spatial relations for natu-
ral language access to an autonomous mobile robot.
Proceedings of KI-94, pp39-50.
Tversky, B., P. Lee, and S. Mainwaring. (1999) Why
do speakers mix perspectives? Spatial Cognition
and Computation, 1:399-412.
Wachsmuth, I. and Y. Cao (1995) Interactive Graphics
Design with Situated Agents. In W. Strasser and F.
Wahl (eds.): Graphics and Robotics (pp. 73- 85),
Berlin Heidelberg New York: Springer.
</reference>
<page confidence="0.998492">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.491002">
<title confidence="0.994118">a static interpretation is not sufficient in spatial</title>
<author confidence="0.99989">John A Bateman</author>
<affiliation confidence="0.929718333333333">FB 10: Faculty of Linguistics and Literary Sciences University of Bremen</affiliation>
<address confidence="0.995933">Bremen, Germany</address>
<email confidence="0.997852">bremen.de</email>
<author confidence="0.997212">Kerstin Fischer</author>
<affiliation confidence="0.926825">FB 10: Faculty of Linguistics and Literary Sciences University of Bremen</affiliation>
<address confidence="0.99594">Bremen, Germany</address>
<email confidence="0.99906">bremen.de</email>
<author confidence="0.994019">Thora Tenbrink</author>
<affiliation confidence="0.956886666666667">FB 10: Faculty of Linguistics and Literary Sciences University of</affiliation>
<address confidence="0.992323">Bremen, Germany</address>
<email confidence="0.986973">tenbrink@informatik.uni-bremen.de</email>
<abstract confidence="0.990854461538461">This paper proposes a research methodology for attacking the problem of providing fluent and natural discourse about space and spatially situated tasks between naive users and robots. We suggest flexible and adaptive ontology mediation, parameterized according to empirically determined discourse and contextual factors, as a suitable architecture with clear applications for the treatment of natural human-human dialog also.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>H Alshawi</author>
</authors>
<title>(ed.)(1992) The Core Language Engine,</title>
<publisher>MIT Press.</publisher>
<location>Cambridge, Massachusetts:</location>
<marker>Alshawi, </marker>
<rawString>Alshawi, H. (ed.)(1992) The Core Language Engine, Cambridge, Massachusetts: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Amalberti</author>
<author>N Carbonell</author>
<author>P Falzon</author>
</authors>
<title>User Representations of Computer Systems in Human-Computer speech interaction.</title>
<date>1993</date>
<journal>International Journal of Man-Machine Studies,</journal>
<pages>38--547</pages>
<contexts>
<context position="11517" citStr="Amalberti et al. 1993" startWordPosition="1674" endWordPosition="1678">e speakers design their speech for their recipients, the way they think about their communication partner may have a strong impact on the form of their utterances. Particularly the conceptualization of the robot as a tool versus as human-like may lead to significantly different linguistic behavior (Fischer 2000). This insight corresponds to previous findings of psycholinguistic studies that show that the negotiation of linguistic behavior, or alignment, takes place on all linguistic levels (Garrod, 1999; Clark, 1996), a result supported and suggested by findings in human-computer interaction (Amalberti et al. 1993; Fischer 1999, 2000) and now again forcefully argued in Pickering and Garrod (in press). Thus, human-computer conversation cannot be regarded as a single rigidly defined linguistic variety, but instead is constantly negotiated and adapted, influenced both by the system design and by the users&apos; conceptualizations of the system. The question remains as to whether it is possible to specify limits and constraints on this variability. It is precisely this flexibility that makes this kind of interaction particularly relevant for research into the mechanisms of dialogue and interaction in general. 3</context>
</contexts>
<marker>Amalberti, Carbonell, Falzon, 1993</marker>
<rawString>Amalberti, R., N. Carbonell, and P. Falzon (1993) User Representations of Computer Systems in Human-Computer speech interaction. International Journal of Man-Machine Studies, 38:547-566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Bateman</author>
</authors>
<title>Utterances in context: towards a systemic theory of the intersubjective achievement of discourse, PhD dissertation.</title>
<date>1986</date>
<institution>University of Edinburgh,</institution>
<location>Scotland.</location>
<contexts>
<context position="28915" citStr="Bateman (1986)" startWordPosition="4353" endWordPosition="4354">holding, differing linguistic features occur with higher or lower probability (cf. Biber, 1993). Another way of viewing this process is to say that the domain ontology configurations are associated with differing &apos;views&apos; of the linguistic system. As the register changes, so does the linguistic behavior observed. We now take this further by adding in the interactional parameters. This means that the precise correspondences between linguistic and domain configurations, as well as the &apos;view&apos; of the linguistic system, can vary within an interaction; this has been termed microregister variation in Bateman (1986). Microregisters follow closely the spirit of Garrod and Sanford (1988) and the use of dialog interaction to construct `ontologies&apos; of the domain of discourse on the fly, while more explicitly considering shared (or aligned) linguistic representations as shown to be necessary in Pickering and Garrod (in press). Acknowledgements This work is part of the project Il-OntoSpace of the newly established SFB/TR8 &amp;quot;Spatial Cognition&amp;quot; coordinated by Christian Freksa. We are grateful for the financial support of the DFG and to Reinhard Moratz for useful discussions and cooperation in the robotics area. R</context>
</contexts>
<marker>Bateman, 1986</marker>
<rawString>Bateman, J.A. (1986) Utterances in context: towards a systemic theory of the intersubjective achievement of discourse, PhD dissertation. University of Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Bateman</author>
</authors>
<title>Upper Modeling: Organizing Knowledge for Natural Language Processing. In:</title>
<date>1990</date>
<booktitle>Proceedings of the Fifth International Natural Language Generation Workshop,</booktitle>
<pages>54--60</pages>
<location>Dawson, PA.</location>
<contexts>
<context position="14514" citStr="Bateman (1990)" startWordPosition="2129" endWordPosition="2130">lutions common in such work. Here our approach draws on a standard technique for achieving modularity that has been pursued within several branches of NLP. This involves employing, either explicitly or implicitly, ontologies that represent information at various levels of abstraction within a system. One of the first systems to employ this technique for re-use was the Penman text generation system (Mann and Matthiessen, 1985), within which the Penman Upper Model was developed (Bateman et al., 1990). Re-use for natural language generation within this framework was described in detail by, e.g., Bateman (1990), and follows the strategy of subordinating domain model concepts to upper model concepts so that domain concepts inherit the linguistic possibilities for expression available to their superordinate upper model concepts. For example, if a domain object—such as some entity recognized by the robot—is subordinated to the upper model concept Nonde - c ompo s ab 1 e - Obj ec t, then the generation component knows which kinds of linguistic constructions may be used for describing this concept and which not. This approach has since been widely employed. Although an obvious benefit of this approach is</context>
</contexts>
<marker>Bateman, 1990</marker>
<rawString>Bateman, J.A. (1990) Upper Modeling: Organizing Knowledge for Natural Language Processing. In: Proceedings of the Fifth International Natural Language Generation Workshop, pp. 54--60. Dawson, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Bateman</author>
<author>C L Paris</author>
</authors>
<title>Phrasing a Text in Terms the User Can Understand. In:</title>
<date>1989</date>
<booktitle>Proceedings of the Eleventh International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1511--1517</pages>
<location>Detroit, Michigan.</location>
<contexts>
<context position="15508" citStr="Bateman and Paris, 1989" startWordPosition="2284" endWordPosition="2287">ec t, then the generation component knows which kinds of linguistic constructions may be used for describing this concept and which not. This approach has since been widely employed. Although an obvious benefit of this approach is that it enables semantic specifications to make direct use of domain model concepts, it also has a striking deficiency. This was revealed most clearly in research efforts aimed at multiple register generation—that is, the generation by single generic text generation systems of texts belonging to diverse text types and for varying levels of reader/user expertise (cf. Bateman and Paris, 1989). Different registers can easily require single domain concepts to be expressed so divergently that any single upper model concept assignment is invalidated. What one type of text may consider nondecomposable might in another be treated as non-atomic and decomposable into parts. This necessitates the maintenance of at least two distinct levels of ontological information— one purely linguistic semantic, that of the upper model, and one for the domain model—with flexible mapping relationships between them. In the context of our experiments here, the domain model will focus particularly on spatia</context>
</contexts>
<marker>Bateman, Paris, 1989</marker>
<rawString>Bateman, J.A. and Paris, C.L. (1989) Phrasing a Text in Terms the User Can Understand. In: Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, pp. 1511--1517. Detroit, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Bateman</author>
<author>R T Kasper</author>
<author>J D Moore</author>
<author>R A Whitney</author>
</authors>
<title>A general organization of Knowledge for natural language processing: the PENMAN Upper Model, Marina del Rey, California: USC/Information Sciences Institute .</title>
<date>1990</date>
<contexts>
<context position="14403" citStr="Bateman et al., 1990" startWordPosition="2110" endWordPosition="2113">red during negotiation of shared discourse strategies within any interaction argues strongly against the &apos;prewired&apos; solutions common in such work. Here our approach draws on a standard technique for achieving modularity that has been pursued within several branches of NLP. This involves employing, either explicitly or implicitly, ontologies that represent information at various levels of abstraction within a system. One of the first systems to employ this technique for re-use was the Penman text generation system (Mann and Matthiessen, 1985), within which the Penman Upper Model was developed (Bateman et al., 1990). Re-use for natural language generation within this framework was described in detail by, e.g., Bateman (1990), and follows the strategy of subordinating domain model concepts to upper model concepts so that domain concepts inherit the linguistic possibilities for expression available to their superordinate upper model concepts. For example, if a domain object—such as some entity recognized by the robot—is subordinated to the upper model concept Nonde - c ompo s ab 1 e - Obj ec t, then the generation component knows which kinds of linguistic constructions may be used for describing this conce</context>
</contexts>
<marker>Bateman, Kasper, Moore, Whitney, 1990</marker>
<rawString>Bateman, J.A., Kasper, R.T., Moore, J.D. and Whitney, R.A. (1990) A general organization of Knowledge for natural language processing: the PENMAN Upper Model, Marina del Rey, California: USC/Information Sciences Institute .</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Biber</author>
</authors>
<title>Using register-diversified corpora for general language studies.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<pages>219--242</pages>
<contexts>
<context position="28396" citStr="Biber, 1993" startWordPosition="4272" endWordPosition="4273"> and whether user and system share the same spatial position. This variability demands not particular solutions to selected problems, but generic and re-usable techniques. Such techniques may be supported by parameterized ontology mediation of the kind suggested. Moreover, there is a direct link between this kind of approach and earlier work on multiple register generation and analysis. The situational parameters correspond to traditional notions of register variation—i.e., depending on the situational features holding, differing linguistic features occur with higher or lower probability (cf. Biber, 1993). Another way of viewing this process is to say that the domain ontology configurations are associated with differing &apos;views&apos; of the linguistic system. As the register changes, so does the linguistic behavior observed. We now take this further by adding in the interactional parameters. This means that the precise correspondences between linguistic and domain configurations, as well as the &apos;view&apos; of the linguistic system, can vary within an interaction; this has been termed microregister variation in Bateman (1986). Microregisters follow closely the spirit of Garrod and Sanford (1988) and the u</context>
</contexts>
<marker>Biber, 1993</marker>
<rawString>Biber, D. (1993) Using register-diversified corpora for general language studies. Computational Linguistics 19, 219--242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Clark</author>
</authors>
<title>Using Language. Cambridge:</title>
<date>1996</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="11418" citStr="Clark, 1996" startWordPosition="1662" endWordPosition="1663"> system (cf. Fischer 2000) and on the system&apos;s output (cf. Fischer &amp; Batliner, 2000). Since speakers design their speech for their recipients, the way they think about their communication partner may have a strong impact on the form of their utterances. Particularly the conceptualization of the robot as a tool versus as human-like may lead to significantly different linguistic behavior (Fischer 2000). This insight corresponds to previous findings of psycholinguistic studies that show that the negotiation of linguistic behavior, or alignment, takes place on all linguistic levels (Garrod, 1999; Clark, 1996), a result supported and suggested by findings in human-computer interaction (Amalberti et al. 1993; Fischer 1999, 2000) and now again forcefully argued in Pickering and Garrod (in press). Thus, human-computer conversation cannot be regarded as a single rigidly defined linguistic variety, but instead is constantly negotiated and adapted, influenced both by the system design and by the users&apos; conceptualizations of the system. The question remains as to whether it is possible to specify limits and constraints on this variability. It is precisely this flexibility that makes this kind of interacti</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>Clark, H.H. (1996) Using Language. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Clark</author>
<author>D Wilkes-Gibbs</author>
</authors>
<title>Referring as a collaborative process.</title>
<date>1986</date>
<journal>Cognition,</journal>
<pages>22--1</pages>
<contexts>
<context position="9619" citStr="Clark and Wilkes-Gibbs, 1986" startWordPosition="1399" endWordPosition="1402">may reach a high level of complexity if the discourse situation offers a wide range of conceptual representations. Speakers also react to their interaction partner&apos;s contributions, and appear to attune their linguistic choices to what they believe to be suitable for their partner in the situation at hand. For example, Schegloff (1972) shows how &amp;quot;formulating place&amp;quot; depends on the recipient for whom the description is designed. Schober (1993) found that speakers attend to their hearers&apos; clues as to whether they have understood the instruction in the sense that the references have been grounded (Clark and Wilkes-Gibbs, 1986). Garrod and Anderson (1987) found that communication partners interactively developed distinct but consistent description schemes, which reflected different kinds of underlying mental representations. These were dependent on the interaction itself as well as on the given task. 2.2 Communicating with Artificial Interlocutors In the same way as the use of spatial expressions depends on the recipient and on the negotiation processes between the interlocutors, linguistic choices in general are influenced by the speakers&apos; understanding of their communication partner and the interactive negotiation</context>
</contexts>
<marker>Clark, Wilkes-Gibbs, 1986</marker>
<rawString>Clark, H. and Wilkes-Gibbs, D. (1986). Referring as a collaborative process. Cognition, 22:1-39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R Coventry</author>
</authors>
<title>Spatial Prepositions, Functional Relations, and Lexical Specification.</title>
<date>1998</date>
<booktitle>Representation and Processing of Spatial Expressions. Mahwah,</booktitle>
<pages>247--262</pages>
<editor>In Olivier, Patrick and Klaus-Peter Gapp (eds.)</editor>
<publisher>Erlbaum,</publisher>
<location>New Jersey: Lawrence</location>
<contexts>
<context position="6238" citStr="Coventry, 1998" startWordPosition="885" endWordPosition="887">l Cognition&amp;quot; located at the universities of Bremen and Freiburg. 2.1 Interpreting Spatial Expressions In the communication of spatial information, work has addressed the formal analysis of the meaning of spatial expressions on the one hand, and their choice under certain specifiable circumstances on the other. Lexical semantic approaches discuss the possibility of a core semantic meaning for spatial expressions from which possible deviations can be derived (e.g., Eschenbach 1999); psychologically inspired work has revealed the importance of functional categorizations (Garrod and Sanford 1988; Coventry, 1998); while work from robotics has introduced the notion of a field potential for describing degrees of likelihood of positioning (cf. Stopp et al., 1994). Psycholinguistic experimental studies on spatial situations focus on different kinds of mental representations that are reflected verbally in the speakers&apos; utterances. A central concept underlying much spatial expression work is that of reference systems (Hermann and Grabowski, 1994). Such systems may be intrinsic, relative, and absolute (Levinson, 1996), all of which may — depending on various factors of the actual situation — be employed from</context>
</contexts>
<marker>Coventry, 1998</marker>
<rawString>Coventry, K.R. (1998) Spatial Prepositions, Functional Relations, and Lexical Specification. In Olivier, Patrick and Klaus-Peter Gapp (eds.) Representation and Processing of Spatial Expressions. Mahwah, New Jersey: Lawrence Erlbaum, pp. 247-262</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Eschenbach</author>
</authors>
<title>Geometric structures of frames of reference and natural language semantics.</title>
<date>1999</date>
<journal>Spatial Cognition and Computation,</journal>
<volume>1</volume>
<issue>4</issue>
<pages>329--348</pages>
<contexts>
<context position="6107" citStr="Eschenbach 1999" startWordPosition="869" endWordPosition="870"> by John Bateman, Kerstin Fischer, and Reinhard Moratz, is part of the newly established Collaborative Research Center (SFB) &amp;quot;Spatial Cognition&amp;quot; located at the universities of Bremen and Freiburg. 2.1 Interpreting Spatial Expressions In the communication of spatial information, work has addressed the formal analysis of the meaning of spatial expressions on the one hand, and their choice under certain specifiable circumstances on the other. Lexical semantic approaches discuss the possibility of a core semantic meaning for spatial expressions from which possible deviations can be derived (e.g., Eschenbach 1999); psychologically inspired work has revealed the importance of functional categorizations (Garrod and Sanford 1988; Coventry, 1998); while work from robotics has introduced the notion of a field potential for describing degrees of likelihood of positioning (cf. Stopp et al., 1994). Psycholinguistic experimental studies on spatial situations focus on different kinds of mental representations that are reflected verbally in the speakers&apos; utterances. A central concept underlying much spatial expression work is that of reference systems (Hermann and Grabowski, 1994). Such systems may be intrinsic, </context>
</contexts>
<marker>Eschenbach, 1999</marker>
<rawString>Eschenbach, C. (1999) Geometric structures of frames of reference and natural language semantics. Spatial Cognition and Computation, 1 (4), 329-348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Fischer</author>
</authors>
<title>Repeats, Reformulations, and Emotional Speech: Evidence for the Design of Human-Computer Speech Interfaces.</title>
<date>1999</date>
<pages>560--565</pages>
<editor>In Bullinger, H. &amp; Ziegler, J. (eds.): Human-Computer</editor>
<location>London,</location>
<contexts>
<context position="11531" citStr="Fischer 1999" startWordPosition="1679" endWordPosition="1680"> speech for their recipients, the way they think about their communication partner may have a strong impact on the form of their utterances. Particularly the conceptualization of the robot as a tool versus as human-like may lead to significantly different linguistic behavior (Fischer 2000). This insight corresponds to previous findings of psycholinguistic studies that show that the negotiation of linguistic behavior, or alignment, takes place on all linguistic levels (Garrod, 1999; Clark, 1996), a result supported and suggested by findings in human-computer interaction (Amalberti et al. 1993; Fischer 1999, 2000) and now again forcefully argued in Pickering and Garrod (in press). Thus, human-computer conversation cannot be regarded as a single rigidly defined linguistic variety, but instead is constantly negotiated and adapted, influenced both by the system design and by the users&apos; conceptualizations of the system. The question remains as to whether it is possible to specify limits and constraints on this variability. It is precisely this flexibility that makes this kind of interaction particularly relevant for research into the mechanisms of dialogue and interaction in general. 3 Our approach </context>
</contexts>
<marker>Fischer, 1999</marker>
<rawString>Fischer, K. (1999) Repeats, Reformulations, and Emotional Speech: Evidence for the Design of Human-Computer Speech Interfaces. In Bullinger, H. &amp; Ziegler, J. (eds.): Human-Computer Interaction: Ergonomics and User Interfaces. Lawrence Erlbaum Ass., London, pp. 560-565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Fischer</author>
</authors>
<title>What Is a Situation?</title>
<date>2000</date>
<booktitle>Proceedings of Gotalog 2000, Fourth Workshop on the Semantics and Pragmatics of Dialogue,</booktitle>
<pages>85--92</pages>
<institution>Goteborg University,</institution>
<contexts>
<context position="10832" citStr="Fischer 2000" startWordPosition="1574" endWordPosition="1575"> of this conceptualization during the interaction (cf. Sacks, 1992). This is most obvious in the communication with artificial interlocutors; human-computer interaction has therefore been suggested to constitute a special linguistic register (Krause &amp; Hitzenberger,1992). Several studies on human-computer interaction have shown that users may differ considerably in the language they direct to a system and thus that the communication with artificial systems is not homogeneous. Instead, the linguistic properties of the utterances depend very much on the way speakers conceptualize the system (cf. Fischer 2000) and on the system&apos;s output (cf. Fischer &amp; Batliner, 2000). Since speakers design their speech for their recipients, the way they think about their communication partner may have a strong impact on the form of their utterances. Particularly the conceptualization of the robot as a tool versus as human-like may lead to significantly different linguistic behavior (Fischer 2000). This insight corresponds to previous findings of psycholinguistic studies that show that the negotiation of linguistic behavior, or alignment, takes place on all linguistic levels (Garrod, 1999; Clark, 1996), a result sup</context>
</contexts>
<marker>Fischer, 2000</marker>
<rawString>Fischer, K. (2000) What Is a Situation? Proceedings of Gotalog 2000, Fourth Workshop on the Semantics and Pragmatics of Dialogue, Goteborg University, 15-17 June 2000. Gothenburg Papers in Computational Linguistics 00-5, pp. 85-92.</rawString>
</citation>
<citation valid="false">
<title>Linguistic Methods for Investigating Concepts</title>
<booktitle>Methodologie in der Linguistik. Frankfurt a.M.: Lang.</booktitle>
<editor>Fischer (in press).</editor>
<marker></marker>
<rawString>Fischer (in press). Linguistic Methods for Investigating Concepts in Use. In: Stolz, Th. and Kolbe, K. (eds.): Methodologie in der Linguistik. Frankfurt a.M.: Lang.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Fischer</author>
<author>A Batliner</author>
</authors>
<title>What Makes Speakers Angry in Human-Computer Conversation.</title>
<date>2000</date>
<booktitle>Proceedings of the Third Workshop on HumanComputer Conversation,</booktitle>
<location>Bellagio,</location>
<contexts>
<context position="10890" citStr="Fischer &amp; Batliner, 2000" startWordPosition="1582" endWordPosition="1585">ion (cf. Sacks, 1992). This is most obvious in the communication with artificial interlocutors; human-computer interaction has therefore been suggested to constitute a special linguistic register (Krause &amp; Hitzenberger,1992). Several studies on human-computer interaction have shown that users may differ considerably in the language they direct to a system and thus that the communication with artificial systems is not homogeneous. Instead, the linguistic properties of the utterances depend very much on the way speakers conceptualize the system (cf. Fischer 2000) and on the system&apos;s output (cf. Fischer &amp; Batliner, 2000). Since speakers design their speech for their recipients, the way they think about their communication partner may have a strong impact on the form of their utterances. Particularly the conceptualization of the robot as a tool versus as human-like may lead to significantly different linguistic behavior (Fischer 2000). This insight corresponds to previous findings of psycholinguistic studies that show that the negotiation of linguistic behavior, or alignment, takes place on all linguistic levels (Garrod, 1999; Clark, 1996), a result supported and suggested by findings in human-computer interac</context>
</contexts>
<marker>Fischer, Batliner, 2000</marker>
<rawString>Fischer, K. and Batliner, A. (2000) What Makes Speakers Angry in Human-Computer Conversation. Proceedings of the Third Workshop on HumanComputer Conversation, Bellagio, Italy, 3-5 July 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Garrod</author>
</authors>
<title>The Challenge of Dialogue for Theories of Language Processing.</title>
<date>1999</date>
<booktitle>Language Processing.</booktitle>
<editor>In: Garrod, S. and Pickering, M.J. (eds.):</editor>
<publisher>Hove: Psychology Press.</publisher>
<contexts>
<context position="11404" citStr="Garrod, 1999" startWordPosition="1660" endWordPosition="1661">ceptualize the system (cf. Fischer 2000) and on the system&apos;s output (cf. Fischer &amp; Batliner, 2000). Since speakers design their speech for their recipients, the way they think about their communication partner may have a strong impact on the form of their utterances. Particularly the conceptualization of the robot as a tool versus as human-like may lead to significantly different linguistic behavior (Fischer 2000). This insight corresponds to previous findings of psycholinguistic studies that show that the negotiation of linguistic behavior, or alignment, takes place on all linguistic levels (Garrod, 1999; Clark, 1996), a result supported and suggested by findings in human-computer interaction (Amalberti et al. 1993; Fischer 1999, 2000) and now again forcefully argued in Pickering and Garrod (in press). Thus, human-computer conversation cannot be regarded as a single rigidly defined linguistic variety, but instead is constantly negotiated and adapted, influenced both by the system design and by the users&apos; conceptualizations of the system. The question remains as to whether it is possible to specify limits and constraints on this variability. It is precisely this flexibility that makes this kin</context>
</contexts>
<marker>Garrod, 1999</marker>
<rawString>Garrod, S. (1999): The Challenge of Dialogue for Theories of Language Processing. In: Garrod, S. and Pickering, M.J. (eds.): Language Processing. Hove: Psychology Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Garrod</author>
<author>A Anderson</author>
</authors>
<title>Saying what you mean in dialogue: A study in conceptual and semantic coordination.</title>
<date>1987</date>
<journal>Cognition</journal>
<volume>27</volume>
<pages>181--218</pages>
<contexts>
<context position="9647" citStr="Garrod and Anderson (1987)" startWordPosition="1403" endWordPosition="1406">exity if the discourse situation offers a wide range of conceptual representations. Speakers also react to their interaction partner&apos;s contributions, and appear to attune their linguistic choices to what they believe to be suitable for their partner in the situation at hand. For example, Schegloff (1972) shows how &amp;quot;formulating place&amp;quot; depends on the recipient for whom the description is designed. Schober (1993) found that speakers attend to their hearers&apos; clues as to whether they have understood the instruction in the sense that the references have been grounded (Clark and Wilkes-Gibbs, 1986). Garrod and Anderson (1987) found that communication partners interactively developed distinct but consistent description schemes, which reflected different kinds of underlying mental representations. These were dependent on the interaction itself as well as on the given task. 2.2 Communicating with Artificial Interlocutors In the same way as the use of spatial expressions depends on the recipient and on the negotiation processes between the interlocutors, linguistic choices in general are influenced by the speakers&apos; understanding of their communication partner and the interactive negotiation of this conceptualization d</context>
</contexts>
<marker>Garrod, Anderson, 1987</marker>
<rawString>Garrod, S. and Anderson, A. (1987). Saying what you mean in dialogue: A study in conceptual and semantic coordination. Cognition 27: 181-218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Garrod</author>
<author>A J Sanford</author>
</authors>
<title>Discourse models as interfaces between language and the spatial world.</title>
<date>1988</date>
<journal>Journal of Semantics,</journal>
<pages>6--147</pages>
<contexts>
<context position="6221" citStr="Garrod and Sanford 1988" startWordPosition="881" endWordPosition="884">arch Center (SFB) &amp;quot;Spatial Cognition&amp;quot; located at the universities of Bremen and Freiburg. 2.1 Interpreting Spatial Expressions In the communication of spatial information, work has addressed the formal analysis of the meaning of spatial expressions on the one hand, and their choice under certain specifiable circumstances on the other. Lexical semantic approaches discuss the possibility of a core semantic meaning for spatial expressions from which possible deviations can be derived (e.g., Eschenbach 1999); psychologically inspired work has revealed the importance of functional categorizations (Garrod and Sanford 1988; Coventry, 1998); while work from robotics has introduced the notion of a field potential for describing degrees of likelihood of positioning (cf. Stopp et al., 1994). Psycholinguistic experimental studies on spatial situations focus on different kinds of mental representations that are reflected verbally in the speakers&apos; utterances. A central concept underlying much spatial expression work is that of reference systems (Hermann and Grabowski, 1994). Such systems may be intrinsic, relative, and absolute (Levinson, 1996), all of which may — depending on various factors of the actual situation —</context>
</contexts>
<marker>Garrod, Sanford, 1988</marker>
<rawString>Garrod, S.C., and A.J. Sanford (1988) Discourse models as interfaces between language and the spatial world. Journal of Semantics, 6:147-160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Herrmann</author>
<author>J Grabowski</author>
</authors>
<title>Sprechen: Psychologie der Sprachproduktion.</title>
<date>1994</date>
<publisher>Spektrum Verlag.</publisher>
<location>Heidelberg:</location>
<marker>Herrmann, Grabowski, 1994</marker>
<rawString>Herrmann, T. and Grabowski, J. (1994) Sprechen: Psychologie der Sprachproduktion. Heidelberg: Spektrum Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Herweg</author>
</authors>
<title>Aspectual requirements of temporal connectives: evidence for a two-level approach to semantics.</title>
<date>1991</date>
<booktitle>Proceedings of the 1991 ACL Workshop on Lexical Semantics and Knowledge Representation,</booktitle>
<pages>152--164</pages>
<editor>In: Pustejoysky, J. and Bergler, S., (eds.)</editor>
<location>Berkeley, CA.</location>
<contexts>
<context position="16405" citStr="Herweg, 1991" startWordPosition="2425" endWordPosition="2426">necessitates the maintenance of at least two distinct levels of ontological information— one purely linguistic semantic, that of the upper model, and one for the domain model—with flexible mapping relationships between them. In the context of our experiments here, the domain model will focus particularly on spatial relationships and object attributes shown to be relevant for forming spatial expressions. The preservation of two distinct levels of information is echoed in a range of very diverse approaches (cf., e.g., the distinction between LF and QLF in Alshawi, 1992; in temporal semantics in Herweg, 1991; and ontology-based utterance analysis in Lang, 1991), the extent and range of the flexibility required in mappings between levels has not been mapped out satisfactorily. It has also not been anchored as firmly as is necessary in the details of linguistic negotiation within dialog. Our experiments will seek to provide crucial data concerning the range and flexibility of the mappings required, focusing on the area of spatial relations and their linguistic expression. The allocation of spatial configurations to particular linguistically expressed orientations is known to vary according to the i</context>
</contexts>
<marker>Herweg, 1991</marker>
<rawString>Herweg, M. (1991) Aspectual requirements of temporal connectives: evidence for a two-level approach to semantics. In: Pustejoysky, J. and Bergler, S., (eds.) Proceedings of the 1991 ACL Workshop on Lexical Semantics and Knowledge Representation, pp. 152--164. Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kessler</author>
<author>I Duwe</author>
<author>H Strohner</author>
</authors>
<title>Grounding Mental Models:</title>
<date>1999</date>
<booktitle>Subconceptual Dynamics in the Resolution of Reference in Discourse. In: Gert Rickheit and Christopher Habel (eds.), Mental Models in Discourse Processing and Reasoning.</booktitle>
<publisher>Elsevier.</publisher>
<location>Amsterdam:</location>
<contexts>
<context position="8975" citStr="Kessler et al., 1999" startWordPosition="1297" endWordPosition="1300"> is negotiated and changed during the interaction (Tversky et al., 1999). Especially in cases of qualitative or vague spatial instructions, there is often a need for interactive negotiation about the exact semantics of the instruction (Wachsmuth and Cao, 1995). Conversational participants often agree on situationally dependent representations, such as metonymies, in order to achieve smooth and effective communication (e.g., Rieser, 1996). Reference resolution is achieved in dependence on the visual as well as the linguistic context; influenced, for instance, by the current focus of attention (Kessler et al., 1999). This process may reach a high level of complexity if the discourse situation offers a wide range of conceptual representations. Speakers also react to their interaction partner&apos;s contributions, and appear to attune their linguistic choices to what they believe to be suitable for their partner in the situation at hand. For example, Schegloff (1972) shows how &amp;quot;formulating place&amp;quot; depends on the recipient for whom the description is designed. Schober (1993) found that speakers attend to their hearers&apos; clues as to whether they have understood the instruction in the sense that the references have </context>
</contexts>
<marker>Kessler, Duwe, Strohner, 1999</marker>
<rawString>Kessler, K., Duwe, I. and Strohner, H. (1999) Grounding Mental Models: Subconceptual Dynamics in the Resolution of Reference in Discourse. In: Gert Rickheit and Christopher Habel (eds.), Mental Models in Discourse Processing and Reasoning. Amsterdam: Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Krause</author>
<author>L Hitzenberger</author>
</authors>
<date>1992</date>
<publisher>Computertalk.</publisher>
<location>Hildesheim: Olms.</location>
<marker>Krause, Hitzenberger, 1992</marker>
<rawString>Krause, J. and Hitzenberger, L (1992). Computertalk. Hildesheim: Olms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Lang</author>
</authors>
<title>The LILOG ontology from a linguistic point of view.</title>
<date>1991</date>
<booktitle>Text understanding in LILOG: integrating computational linguistics and artificial intelligence, Final report on the IBM Germany LILOG-Project,</booktitle>
<pages>464--481</pages>
<editor>In: Herzog, 0. and Rollinger, C. (eds.)</editor>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<contexts>
<context position="16459" citStr="Lang, 1991" startWordPosition="2433" endWordPosition="2434">evels of ontological information— one purely linguistic semantic, that of the upper model, and one for the domain model—with flexible mapping relationships between them. In the context of our experiments here, the domain model will focus particularly on spatial relationships and object attributes shown to be relevant for forming spatial expressions. The preservation of two distinct levels of information is echoed in a range of very diverse approaches (cf., e.g., the distinction between LF and QLF in Alshawi, 1992; in temporal semantics in Herweg, 1991; and ontology-based utterance analysis in Lang, 1991), the extent and range of the flexibility required in mappings between levels has not been mapped out satisfactorily. It has also not been anchored as firmly as is necessary in the details of linguistic negotiation within dialog. Our experiments will seek to provide crucial data concerning the range and flexibility of the mappings required, focusing on the area of spatial relations and their linguistic expression. The allocation of spatial configurations to particular linguistically expressed orientations is known to vary according to the interactional context and the kinds of spatial configur</context>
</contexts>
<marker>Lang, 1991</marker>
<rawString>Lang, E. (1991) The LILOG ontology from a linguistic point of view. In: Herzog, 0. and Rollinger, C. (eds.) Text understanding in LILOG: integrating computational linguistics and artificial intelligence, Final report on the IBM Germany LILOG-Project, pp. 464--481. Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C</author>
</authors>
<title>Frames of reference and Molyneux&apos;s question: Crosslinguistic evidence.</title>
<date>1996</date>
<booktitle>Language and Space</booktitle>
<pages>109--169</pages>
<editor>In P. Bloom, M.A. Peterson, L. Nadel and M.F. Garrett (eds.),</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>C, 1996</marker>
<rawString>Levinson, St. C. (1996). Frames of reference and Molyneux&apos;s question: Crosslinguistic evidence. In P. Bloom, M.A. Peterson, L. Nadel and M.F. Garrett (eds.), Language and Space (pp. 109-169). Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>C M I M Matthiessen</author>
</authors>
<title>Demonstration of the Nigel Text Generation Computer Program.</title>
<date>1985</date>
<booktitle>Systemic Perspectives on Discourse,</booktitle>
<volume>1</volume>
<pages>50--83</pages>
<editor>In: Benson, J.D. and Greaves, W.S., (eds.)</editor>
<publisher>Ablex.</publisher>
<location>Norwood, New Jersey :</location>
<contexts>
<context position="14329" citStr="Mann and Matthiessen, 1985" startWordPosition="2098" endWordPosition="2101">interactants and expressed in their linguistic utterances. The flexibility required during negotiation of shared discourse strategies within any interaction argues strongly against the &apos;prewired&apos; solutions common in such work. Here our approach draws on a standard technique for achieving modularity that has been pursued within several branches of NLP. This involves employing, either explicitly or implicitly, ontologies that represent information at various levels of abstraction within a system. One of the first systems to employ this technique for re-use was the Penman text generation system (Mann and Matthiessen, 1985), within which the Penman Upper Model was developed (Bateman et al., 1990). Re-use for natural language generation within this framework was described in detail by, e.g., Bateman (1990), and follows the strategy of subordinating domain model concepts to upper model concepts so that domain concepts inherit the linguistic possibilities for expression available to their superordinate upper model concepts. For example, if a domain object—such as some entity recognized by the robot—is subordinated to the upper model concept Nonde - c ompo s ab 1 e - Obj ec t, then the generation component knows whi</context>
</contexts>
<marker>Mann, Matthiessen, 1985</marker>
<rawString>Mann, W.C. and Matthiessen, C.M.I.M. (1985) Demonstration of the Nigel Text Generation Computer Program. In: Benson, J.D. and Greaves, W.S., (eds.) Systemic Perspectives on Discourse, Volume 1, pp. 50--83. Norwood, New Jersey : Ablex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moratz</author>
<author>K Fischer</author>
<author>T Tenbrink</author>
</authors>
<title>Cognitive Modelling of Spatial Reference for Human-Robot Interaction.</title>
<date>2001</date>
<journal>International Journal On Artificial Intelligence Tools,</journal>
<volume>10</volume>
<institution>World Scientific Publishing,</institution>
<location>Singapur.</location>
<contexts>
<context position="7393" citStr="Moratz et al., 2001" startWordPosition="1064" endWordPosition="1067">ing on various factors of the actual situation — be employed from either of three different perspectives: speaker-centered, listenercentered, or third-party point of view. In intrinsic reference systems, objects are located by referring to the intrinsic properties of another entity, such as the speaker&apos;s front in &amp;quot;The ball is in front of me&amp;quot;. Relative reference systems depend on the presence of a further entity (the so-called relaturn), as in &amp;quot;The ball is in front of the table&amp;quot;. If (at least) one similar entity is present rather than a different relatum, speakers employ group-based reference (Moratz et al., 2001). Absolute reference systems depend on the earth&apos;s cardinal directions, such as north or south. In tasks involving route descriptions rather than the localisation of objects, further kinds of perspectives, and combinations of perspectives, are available to the speaker: for instance, one can assume the perspective of an &amp;quot;imaginary wanderer&amp;quot; (an imagined person that walks along the route described). At the same time speakers may refer to landmarks available in the scenery (Hermann and Grabowski, 1994), and they may adapt their linguistic choices of spatial expressions flexibly according to the c</context>
<context position="18600" citStr="Moratz et al., 2001" startWordPosition="2755" endWordPosition="2758">e uncertain about what the robot can perceive, and so the lack of mutual and reflexive common ground for the interactants regarding the spatial situation can lead to insecurity about which objects may serve as landmarks and how they can be referred to. This variability can be experimentally controlled. Closely related to this factor are the participants&apos; linguistic and spatial choices concerning group-based reference — a kind of reference system often neglected in the literature — using further similar objects instead of a different object as a relatum to specify the target object&apos;s position (Moratz et al., 2001). Such issues are addressed by confronting users with tasks involving different configurations of diverse (similar and differing) objects, the robot, and the user. 4.1 An Example: Perspective Taking In previous work we have established that controlled experimental settings yield significant information concerning modeling requirements. In Moratz et al. (2001) it was shown that all users consistently — and often inexplicitly — took the robot&apos;s perspective in their linguistic expressions. Subsequently, in order to see whether the previous finding was an artifact of the experimental setting, we c</context>
</contexts>
<marker>Moratz, Fischer, Tenbrink, 2001</marker>
<rawString>Moratz, R., K. Fischer, and T. Tenbrink. (2001) Cognitive Modelling of Spatial Reference for Human-Robot Interaction. International Journal On Artificial Intelligence Tools, 10:4, World Scientific Publishing, Singapur.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S</author>
</authors>
<title>(in press) Toward a mechanistic psychology of dialogue. Behavioural and Brain Sciences.</title>
<marker>S, </marker>
<rawString>Pickering, M.J and Garrod. S. (in press) Toward a mechanistic psychology of dialogue. Behavioural and Brain Sciences.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Rieser</author>
</authors>
<title>Reprasentations-Metonymie, Perspektive und Koordination in aufgabenorientierten Dialogen. In:</title>
<date>1996</date>
<institution>Deutscher Universitats-Verlag.</institution>
<location>Wiesbaden:</location>
<contexts>
<context position="8795" citStr="Rieser, 1996" startWordPosition="1271" endWordPosition="1272">ral interaction, all the more so as the intended kind of reference is seldom explicitly specified and subsequently retained throughout a communication situation. Rather, it is negotiated and changed during the interaction (Tversky et al., 1999). Especially in cases of qualitative or vague spatial instructions, there is often a need for interactive negotiation about the exact semantics of the instruction (Wachsmuth and Cao, 1995). Conversational participants often agree on situationally dependent representations, such as metonymies, in order to achieve smooth and effective communication (e.g., Rieser, 1996). Reference resolution is achieved in dependence on the visual as well as the linguistic context; influenced, for instance, by the current focus of attention (Kessler et al., 1999). This process may reach a high level of complexity if the discourse situation offers a wide range of conceptual representations. Speakers also react to their interaction partner&apos;s contributions, and appear to attune their linguistic choices to what they believe to be suitable for their partner in the situation at hand. For example, Schegloff (1972) shows how &amp;quot;formulating place&amp;quot; depends on the recipient for whom the </context>
</contexts>
<marker>Rieser, 1996</marker>
<rawString>Rieser, H. (1996) Reprasentations-Metonymie, Perspektive und Koordination in aufgabenorientierten Dialogen. In: C. Umbach, M. Grabski and R. Hornig (Hrsg.). Perspektive in Sprache und Raum. Wiesbaden: Deutscher Universitats-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sacks</author>
</authors>
<title>Lectures on Conversation.</title>
<date>1992</date>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="10286" citStr="Sacks, 1992" startWordPosition="1496" endWordPosition="1497">artners interactively developed distinct but consistent description schemes, which reflected different kinds of underlying mental representations. These were dependent on the interaction itself as well as on the given task. 2.2 Communicating with Artificial Interlocutors In the same way as the use of spatial expressions depends on the recipient and on the negotiation processes between the interlocutors, linguistic choices in general are influenced by the speakers&apos; understanding of their communication partner and the interactive negotiation of this conceptualization during the interaction (cf. Sacks, 1992). This is most obvious in the communication with artificial interlocutors; human-computer interaction has therefore been suggested to constitute a special linguistic register (Krause &amp; Hitzenberger,1992). Several studies on human-computer interaction have shown that users may differ considerably in the language they direct to a system and thus that the communication with artificial systems is not homogeneous. Instead, the linguistic properties of the utterances depend very much on the way speakers conceptualize the system (cf. Fischer 2000) and on the system&apos;s output (cf. Fischer &amp; Batliner, 2</context>
</contexts>
<marker>Sacks, 1992</marker>
<rawString>Sacks, H. (1992): Lectures on Conversation. Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E A Schegloff</author>
</authors>
<title>Notes on a conversational practice: formulating place.</title>
<date>1972</date>
<editor>In Giglioli, Per Paolo (ed.):</editor>
<publisher>Harmondsworth: Penguin.</publisher>
<contexts>
<context position="9326" citStr="Schegloff (1972)" startWordPosition="1355" endWordPosition="1356">tonymies, in order to achieve smooth and effective communication (e.g., Rieser, 1996). Reference resolution is achieved in dependence on the visual as well as the linguistic context; influenced, for instance, by the current focus of attention (Kessler et al., 1999). This process may reach a high level of complexity if the discourse situation offers a wide range of conceptual representations. Speakers also react to their interaction partner&apos;s contributions, and appear to attune their linguistic choices to what they believe to be suitable for their partner in the situation at hand. For example, Schegloff (1972) shows how &amp;quot;formulating place&amp;quot; depends on the recipient for whom the description is designed. Schober (1993) found that speakers attend to their hearers&apos; clues as to whether they have understood the instruction in the sense that the references have been grounded (Clark and Wilkes-Gibbs, 1986). Garrod and Anderson (1987) found that communication partners interactively developed distinct but consistent description schemes, which reflected different kinds of underlying mental representations. These were dependent on the interaction itself as well as on the given task. 2.2 Communicating with Artif</context>
</contexts>
<marker>Schegloff, 1972</marker>
<rawString>Schegloff, E. A. (1972) Notes on a conversational practice: formulating place. In Giglioli, Per Paolo (ed.): Language and social context. Harmondsworth: Penguin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Schober</author>
</authors>
<title>Spatial Perspective-Taking in Conversation,</title>
<date>1993</date>
<journal>Cognition</journal>
<volume>47</volume>
<pages>1--24</pages>
<contexts>
<context position="9434" citStr="Schober (1993)" startWordPosition="1372" endWordPosition="1373"> achieved in dependence on the visual as well as the linguistic context; influenced, for instance, by the current focus of attention (Kessler et al., 1999). This process may reach a high level of complexity if the discourse situation offers a wide range of conceptual representations. Speakers also react to their interaction partner&apos;s contributions, and appear to attune their linguistic choices to what they believe to be suitable for their partner in the situation at hand. For example, Schegloff (1972) shows how &amp;quot;formulating place&amp;quot; depends on the recipient for whom the description is designed. Schober (1993) found that speakers attend to their hearers&apos; clues as to whether they have understood the instruction in the sense that the references have been grounded (Clark and Wilkes-Gibbs, 1986). Garrod and Anderson (1987) found that communication partners interactively developed distinct but consistent description schemes, which reflected different kinds of underlying mental representations. These were dependent on the interaction itself as well as on the given task. 2.2 Communicating with Artificial Interlocutors In the same way as the use of spatial expressions depends on the recipient and on the ne</context>
</contexts>
<marker>Schober, 1993</marker>
<rawString>Schober, M.F. (1993). Spatial Perspective-Taking in Conversation, Cognition 47: 1-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Schober</author>
</authors>
<title>How addressees affect spatial perspective choice in dialogue.</title>
<date>1998</date>
<booktitle>In P.L. Olivier &amp; K.-P. Gapp (Eds.), Representation and processing of spatial expressions</booktitle>
<pages>231--245</pages>
<location>Mahwah, NJ: Lawrence Erlbaum.</location>
<contexts>
<context position="20938" citStr="Schober (1998)" startWordPosition="3118" endWordPosition="3119"> Figure 1 where the robot is located at Pos. C) in order to identify factors influencing perspective taking. This scenario was repeated with 21 instructors. In another scenario the same task was carried out by 17 instructors who communicated with a human communication partner by means of written instructions. Here the task for the human instructee (replacing the robot in the previous experiment) was simply to point to the object described (instead of measuring distances). A preliminary analysis revealed that the data in the human-to-human experiment basically replicate the results obtained by Schober (1998): instructors varied in taking either their own or the other&apos;s perspective, marking their choice usually only in the case of problems after a negotiation process. In contrast, in the human-robot scenario, irrespective of the position of the robot with respect to the instructor, instructors only took the robot&apos;s perspective. This strategy was often explicitly marked. If the task was to measure the distance between an object and the robot itself, the robot was often not addressed itself but referred to as robot or robby. Figure 1. Experimental Scenario. 4.2 Determinants of Linguistic Choices The</context>
</contexts>
<marker>Schober, 1998</marker>
<rawString>Schober, M.F. (1998). How addressees affect spatial perspective choice in dialogue. In P.L. Olivier &amp; K.-P. Gapp (Eds.), Representation and processing of spatial expressions (pp. 231-245). Mahwah, NJ: Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Stopp</author>
<author>K-P Gapp</author>
<author>G Laengle Herzog</author>
<author>T</author>
<author>T Leuth</author>
</authors>
<title>Utilizing spatial relations for natural language access to an autonomous mobile robot.</title>
<date>1994</date>
<booktitle>Proceedings of KI-94,</booktitle>
<pages>39--50</pages>
<contexts>
<context position="6388" citStr="Stopp et al., 1994" startWordPosition="908" endWordPosition="911"> work has addressed the formal analysis of the meaning of spatial expressions on the one hand, and their choice under certain specifiable circumstances on the other. Lexical semantic approaches discuss the possibility of a core semantic meaning for spatial expressions from which possible deviations can be derived (e.g., Eschenbach 1999); psychologically inspired work has revealed the importance of functional categorizations (Garrod and Sanford 1988; Coventry, 1998); while work from robotics has introduced the notion of a field potential for describing degrees of likelihood of positioning (cf. Stopp et al., 1994). Psycholinguistic experimental studies on spatial situations focus on different kinds of mental representations that are reflected verbally in the speakers&apos; utterances. A central concept underlying much spatial expression work is that of reference systems (Hermann and Grabowski, 1994). Such systems may be intrinsic, relative, and absolute (Levinson, 1996), all of which may — depending on various factors of the actual situation — be employed from either of three different perspectives: speaker-centered, listenercentered, or third-party point of view. In intrinsic reference systems, objects are</context>
</contexts>
<marker>Stopp, Gapp, Herzog, T, Leuth, 1994</marker>
<rawString>Stopp, E., Gapp K.-P., Herzog, G. Laengle, T. and Leuth, T. (1994) Utilizing spatial relations for natural language access to an autonomous mobile robot. Proceedings of KI-94, pp39-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Tversky</author>
<author>P Lee</author>
<author>S Mainwaring</author>
</authors>
<title>Why do speakers mix perspectives? Spatial Cognition and Computation,</title>
<date>1999</date>
<pages>1--399</pages>
<contexts>
<context position="8426" citStr="Tversky et al., 1999" startWordPosition="1219" endWordPosition="1222"> time speakers may refer to landmarks available in the scenery (Hermann and Grabowski, 1994), and they may adapt their linguistic choices of spatial expressions flexibly according to the changing visual perception. The complexity of the repertory of available spatial reference systems requires a high degree of flexibility and awareness of possible misun2 derstandings in natural interaction, all the more so as the intended kind of reference is seldom explicitly specified and subsequently retained throughout a communication situation. Rather, it is negotiated and changed during the interaction (Tversky et al., 1999). Especially in cases of qualitative or vague spatial instructions, there is often a need for interactive negotiation about the exact semantics of the instruction (Wachsmuth and Cao, 1995). Conversational participants often agree on situationally dependent representations, such as metonymies, in order to achieve smooth and effective communication (e.g., Rieser, 1996). Reference resolution is achieved in dependence on the visual as well as the linguistic context; influenced, for instance, by the current focus of attention (Kessler et al., 1999). This process may reach a high level of complexity</context>
</contexts>
<marker>Tversky, Lee, Mainwaring, 1999</marker>
<rawString>Tversky, B., P. Lee, and S. Mainwaring. (1999) Why do speakers mix perspectives? Spatial Cognition and Computation, 1:399-412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Wachsmuth</author>
<author>Y Cao</author>
</authors>
<title>Interactive Graphics Design with Situated Agents.</title>
<date>1995</date>
<booktitle>Graphics and Robotics (pp. 73- 85),</booktitle>
<editor>In W. Strasser and F. Wahl (eds.):</editor>
<publisher>Springer.</publisher>
<location>Berlin Heidelberg New York:</location>
<contexts>
<context position="8614" citStr="Wachsmuth and Cao, 1995" startWordPosition="1247" endWordPosition="1250">e changing visual perception. The complexity of the repertory of available spatial reference systems requires a high degree of flexibility and awareness of possible misun2 derstandings in natural interaction, all the more so as the intended kind of reference is seldom explicitly specified and subsequently retained throughout a communication situation. Rather, it is negotiated and changed during the interaction (Tversky et al., 1999). Especially in cases of qualitative or vague spatial instructions, there is often a need for interactive negotiation about the exact semantics of the instruction (Wachsmuth and Cao, 1995). Conversational participants often agree on situationally dependent representations, such as metonymies, in order to achieve smooth and effective communication (e.g., Rieser, 1996). Reference resolution is achieved in dependence on the visual as well as the linguistic context; influenced, for instance, by the current focus of attention (Kessler et al., 1999). This process may reach a high level of complexity if the discourse situation offers a wide range of conceptual representations. Speakers also react to their interaction partner&apos;s contributions, and appear to attune their linguistic choic</context>
</contexts>
<marker>Wachsmuth, Cao, 1995</marker>
<rawString>Wachsmuth, I. and Y. Cao (1995) Interactive Graphics Design with Situated Agents. In W. Strasser and F. Wahl (eds.): Graphics and Robotics (pp. 73- 85), Berlin Heidelberg New York: Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>