<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002622">
<title confidence="0.9816025">
Random-Walk Term Weighting
for Improved Text Classification
</title>
<author confidence="0.986091">
Samer Hassan and Carmen Banea
</author>
<affiliation confidence="0.9994445">
Department of Computer Science
University of North Texas
</affiliation>
<address confidence="0.925355">
Denton, TX 76203
</address>
<email confidence="0.997329">
samer@unt.edu, carmen@unt.edu
</email>
<sectionHeader confidence="0.998601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999992210526316">
This paper describes a new approach for
estimating term weights in a text classifi-
cation task. The approach uses term co-
occurrence as a measure of dependency
between word features. A random walk
model is applied on a graph encoding
words and co-occurrence dependencies,
resulting in scores that represent a quan-
tification of how a particular word feature
contributes to a given context. We argue
that by modeling feature weights using
these scores, as opposed to the traditional
frequency-based scores, we can achieve
better results in a text classification task.
Experiments performed on four standard
classification datasets show that the new
random-walk based approach outperforms
the traditional term frequency approach to
feature weighting.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997288">
Term frequency has long been adapted as a measure
of term significance in a specific context (Robert-
son and Jones, 1997). The logic behind it is that the
more a certain term is encountered in a certain con-
text, the more it carries or contributes to the mean-
ing of the context. Due to this belief, term frequency
has been a major factor in estimating the probabilis-
tic distribution of features using maximum likeli-
hood estimates and hence has been incorporated in a
broad spectrum of tasks ranging from feature selec-
</bodyText>
<page confidence="0.988813">
53
</page>
<bodyText confidence="0.978966125">
tion techniques (Yang and Pedersen, 1997; Schutze
et al., 1995) to language models (Bahl et al., 1983).
In this paper we introduce a new measure of term
weighting, which integrates the locality of a term
and its relation to the surrounding context. We
model this local contribution using a co-occurrence
relation in which terms that co-occur in a certain
context are likely to share between them some of
their importance (or significance). Note that in this
model the relation between a given term and its con-
text is not linear, since the context itself consists of
a collection of other terms, which in turn have a
dependency relation with their own context, which
might include the original given term. In order to
model this recursive relation we use a graph-based
ranking algorithm, namely the PageRank random-
walk algorithms (Brin and Page, 1998), and its Text-
Rank adaption to text processing applications (Mi-
halcea and Tarau, 2004). TextRank takes as in-
put a set of textual entities and relations between
them, and uses a graph-based ranking algorithm
(also known as random walk algorithm) to produce
a set of scores that represent the accumulated weight
or rank for each textual entity in their context. The
TextRank model was so far evaluated on three nat-
ural language processing tasks: document summa-
rization, word sense disambiguation, and keyword
extraction, and despite being fully unsupervised, it
has been shown to be competitive with other some-
time supervised state-of-the-art algorithms.
In this paper, we show how TextRank can be
used to model the probabilistic distribution of word
features in a document, by making further use of
the scores produced by the random-walk model.
Workshop on TextGraphs, at HLT-NAACL 2006, pages 53–60,
New York City, June 2006. c�2006 Association for Computational Linguistics
Through experiments performed on a text classifi-
cation task, we show that these random walk scores
outperform the traditional term frequencies typically
used to model the feature weights for this task.
</bodyText>
<sectionHeader confidence="0.973092" genericHeader="method">
2 Graph-based Ranking Algorithms
</sectionHeader>
<bodyText confidence="0.99989975862069">
The basic idea implemented by an iterative graph-
based ranking algorithm is that of “voting” or “rec-
ommendation”. When one vertex links to another
one, it is basically casting a vote for that other ver-
tex. The higher the number of votes that are cast
for a vertex, the higher the importance of the ver-
tex. Moreover, the importance of the vertex casting
a vote determines how important the vote itself is,
and this information is also taken into account by
the ranking algorithm. Hence, the score associated
with a vertex is determined based on the votes that
are cast for it, and the scores of the vertices casting
these votes.
While there are several graph-based ranking algo-
rithms previously proposed in the literature (Herings
et al., 2001), we focus on only one such algorithm,
namely PageRank (Brin and Page, 1998), as it was
previously found successful in a number of applica-
tions, including Web link analysis (Brin and Page,
1998), social networks (Dom et al., 2003), citation
analysis, and more recently in several text process-
ing applications (Mihalcea and Tarau, 2004), (Erkan
and Radev, 2004).
Given a graph G = (V, E), let In(Va) be the
set of vertices that point to vertex Va (predecessors),
and let Out(Va) be the set of vertices that vertex Va
points to (successors). The PageRank score associ-
ated with the vertex Va is then defined using a recur-
sive function that integrates the scores of its prede-
</bodyText>
<equation confidence="0.949319">
cessors:
1]
S(Va) = (1 − d) + d *
VbEIn(Va)
</equation>
<bodyText confidence="0.999341714285714">
where d is a parameter that is set between 0 and 11.
The score of each vertex is recalculated upon each
iteration based on the new weights that the neighbor-
ing vertices have accumulated. The algorithm termi-
nates when the convergence point is reached for all
the vertices, meaning that the error rate for each ver-
tex falls below a pre-defined threshold. Formally,
</bodyText>
<footnote confidence="0.995677">
1The typical value for d is 0.85 (Brin and Page, 1998), and
this is the value we are also using in our implementation.
</footnote>
<bodyText confidence="0.988858333333333">
for a vertex Vi let Sk(Vi) be the rank or the score
at iteration k and Sk+1(Vi) be the score at iteration
k + 1. The error rate ER is defined as:
</bodyText>
<equation confidence="0.999518">
ER =
Sk+1(Vi) − Sk(Vi) (2)
</equation>
<bodyText confidence="0.999893870967742">
This vertex scoring scheme is based on a ran-
dom walk model, where a walker takes random steps
on the graph G, with the walk being modeled as
a Markov process – that is, the decision on what
edge to follow is solely based on the vertex where
the walker is currently located. Under certain con-
ditions, this model converges to a stationary dis-
tribution of probabilities, associated with vertices
in the graph. Based on the Ergodic theorem for
Markov chains (Grimmett and Stirzaker, 1989), the
algorithm is guaranteed to converge if the graph is
both aperiodic and irreducible. The first condition is
achieved for any graph that is a non-bipartite graph,
while the second condition holds for any strongly
connected graph – property achieved by PageRank
through the random jumps introduced by the (1− d)
factor. In matrix notation, the PageRank vector of
stationary probabilities is the principal eigenvector
for the matrix Arow, which is obtained from the ad-
jacency matrix A representing the graph, with all
rows normalized to sum to 1: (P = ATrowP).
Intuitively, the stationary probability associated
with a vertex in the graph represents the probability
of finding the walker at that vertex during the ran-
dom walk, and thus it represents the importance of
the vertex within the graph. In the context of se-
quence data labeling, the random walk is performed
on the label graph associated with a sequence of
words, and thus the resulting stationary distribution
of probabilities can be used to decide on the most
probable set of labels for the given sequence.
</bodyText>
<subsectionHeader confidence="0.967398">
2.1 TeztRank
</subsectionHeader>
<bodyText confidence="0.99812825">
Given a natural language processing task, the Text-
Rank model includes four general steps for the
application of a graph-based ranking algorithm to
graph structures derived from natural language texts:
</bodyText>
<listItem confidence="0.9920275">
1. Identify text units that best define the proposed
task and add them as vertices in the graph.
2. Identify relations that connect such test units,
and use these relations to draw edges between
</listItem>
<equation confidence="0.9996765">
S(Vb) (1)
|Out(Vb) |
</equation>
<page confidence="0.988826">
54
</page>
<bodyText confidence="0.992291">
vertices in the graph. Edges can be directed or
undirected, weighted or un-weighted.
</bodyText>
<listItem confidence="0.96947825">
3. Iterate the graph ranking algorithm to conver-
gence.
4. Sort vertices based on their final score. Use the
values attached to each vertex for ranking.
</listItem>
<bodyText confidence="0.999972481481481">
The strength of this model lies in the global repre-
sentation of the context and its ability to model how
the co-occurrence between features might propagate
across the context and affect other distant features.
While TextRank has already been applied to sev-
eral language processing tasks, we focus here on the
keyword extraction task, since it best relates to our
approach. The goal of a keyword extraction tool is
to find a set of words or phrases that best describe a
given document. The co-occurrence relation within
a specific window is used to portray the correlation
between words, which are represented as vertices in
the graph. Two vertices are connected if their cor-
responding lexical units co-occur within a window
of at most N words, where N can be set to any
value greater than two. The TextRank application
to keyword extraction has also used different syn-
tactic filters for vertex selection, including all open
class words, nouns and verbs, nouns and adjectives,
and others. The algorithm was found to provide the
best results using nouns and adjectives with a win-
dow size of two.
Our approach follows the same main steps as used
in the TextRank keyword extraction application. We
are however incorporating a larger number of lexical
units, and we use different window sizes, as we will
show in the following section.
</bodyText>
<sectionHeader confidence="0.999555" genericHeader="method">
3 TextRank for Term Weighting
</sectionHeader>
<bodyText confidence="0.999784588235294">
The goal of the work reported in this paper is to
study the ranking scores obtained using TextRank,
and evaluate their potential usefulness as a new mea-
sure of term weighting.
To understand how the random-walk weights
(rw) might be a good replacement for the traditional
term frequency weights (tf), consider the example
in Figure 1. The example represents a sample doc-
ument from the Reuters collection. A graph is con-
structed as follows. If a term has not been previously
seen, then a node is added to the graph to represent
this term. A term can only be represented by one
node in the graph. An undirected edge is drawn be-
tween two nodes if they co-occur within a certain
window size. This example assumes a window size
of two, corresponding to two consecutive terms in
the text (e.g. London is linked to based).
</bodyText>
<figureCaption confidence="0.5975525">
London-based sugar operator Kaines Ltd con-
firmed it sold two cargoes of white sugar to India
out of an estimated overall sales total offour orfive
cargoes in which other brokers participated. The
sugar, for April/May and April/June shipment, was
sold at between 214 and 218 dlrs a tonne cif, it said.
Figure 1: Sample Reuters document
Figure 2: Sample graph
</figureCaption>
<bodyText confidence="0.99985225">
Table 1 shows the tf and rw weights, also plotted
in Figure 3. By analyzing the rw weights, we can
observe a non-linear correlation with the tf weights,
with an emphasis given to terms surrounding impor-
tant key term like e.g. “sugar” or “cargoes.” This
spatial locality has resulted in higher ranks for terms
like “operator” compared to other terms like “lon-
don”2.
</bodyText>
<footnote confidence="0.818313">
2All the missing words (e.g. “Ltd,” “it”) that are not shown
in the graph are common-words that were eliminated in the pre-
processing phase.
</footnote>
<figure confidence="0.997646714285714">
cif
based
tonne
London
dlrs
shipment
sugar
June May
participated
total
brokers
April
operator
Kaines
confirmed
sold
cargoes
white
sales
estimated
India
</figure>
<page confidence="0.791838">
55
</page>
<table confidence="0.960358909090909">
Term rw tf
sugar 2.248 3
sold 1.594 2
april 1.407 2
cargoes 1.542 2
cif 0.600 1
sales 0.891 1
london 0.546 1
tonne 1.059 1
shipment 0.829 1
based 0.933 1
estimated 0.888 1
dlrs 0.938 1
kaines 0.871 1
confirmed 0.859 1
total 0.856 1
white 0.796 1
india 0.846 1
operator 0.839 1
brokers 0.826 1
june 0.801 1
participated 0.819 1
</table>
<tableCaption confidence="0.999441">
Table 1: tf &amp; rw scores
</tableCaption>
<figure confidence="0.6876735625">
sugar
sold
cargoes
april
tonne
dlrs
based
sales
estimated
kaines
confirmed
total
india
operator
shipment
brokers
participated
june
white
cif
london
3.5
3
2.5
Frequency
2
1.5
1
0.5
0
r.w
t.f
</figure>
<bodyText confidence="0.997709454545455">
Smart retrieval system 3.
Next, the resulting text is processed to extract both
tf and rw weights for each term in the document.
Note that we do not apply any syntactic filters, as
it was previously done in applications of TextRank.
Instead, we consider each word as a potential fea-
ture. To determine tf we simply count the frequen-
cies of each word in the document. To determine
rw, all the terms are added as vertices in a graph
representing the document. A co-occurrence scan-
ner is then applied to the text to relate the terms that
co-occur within a given window size . For a given
term, all the terms that fall in the vicinity of this
term are considered dependent terms. This is rep-
resented by a set of edges that connect this term to
all the other terms in the window. Experiments are
performed for window sizes of 2, 4, 6, and 8. Once
the graph is constructed and the edges are in place,
the TextRank algorithm is applied4. The result of the
ranking process is a list of all input terms and their
corresponding rw scores.
We then calculate tf.idf and rw.idf as follows:
</bodyText>
<equation confidence="0.948472666666667">
ND
tf.idf = tf * log
n
</equation>
<bodyText confidence="0.940824">
where ND represent the total number of documents
in the collection and n is the number of documents
in which the target term appeared at least once.
Similarly,
</bodyText>
<figureCaption confidence="0.992887">
Figure 3: tf &amp; rw plots
</figureCaption>
<sectionHeader confidence="0.998882" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999946">
To evaluate our random-walk based approach to fea-
ture weighting, we integrate it in a text classification
algorithm, and evaluate its performance on several
standard text classification data sets.
</bodyText>
<subsectionHeader confidence="0.994304">
4.1 Random-Walk Term Weighting
</subsectionHeader>
<bodyText confidence="0.999874428571429">
Starting with a given document, we determine a
ranking over the words in the document by using the
approach described in Section 3.
First, we tokenize the document for punctuation,
special symbols, word abbreviations. We also re-
move the common words, using a list of approx-
imately 500 frequently used words as used in the
</bodyText>
<equation confidence="0.896136666666667">
ND
rw.idf = rw * log
n
</equation>
<bodyText confidence="0.999093">
These term weights (tf.idf or rw.idf) are then
used to create a feature vector for each document.
The vectors are fed to a traditional text classifica-
tion system, using one of the learning algorithms de-
scribed below. The results obtained using tf.idf will
act as a baseline in our evaluation.
</bodyText>
<subsectionHeader confidence="0.961309">
4.2 Text Classification
</subsectionHeader>
<bodyText confidence="0.999006">
Text classification is a problem typically formulated
as a machine learning task, where a classifier learns
how to distinguish between categories in a given set
</bodyText>
<footnote confidence="0.9234366">
3ftp://ftp.cs.cornell.edu/pub/smart.
4We use an implementation where the maximum number of
iterations is limited to 100, the damping factor is set to 0.85, and
convergence threshold to 0.0001. Each graph node is assigned
with an initial weight of 0.25.
</footnote>
<page confidence="0.998461">
56
</page>
<bodyText confidence="0.999968338983051">
using features automatically extracted from a collec-
tion of training documents. There is a large body
of algorithms previously tested on text classification
problems, due also to the fact that this task is one
of the testbeds of choice for machine learning algo-
rithms. In the experiments reported here, we com-
pare results obtained with four frequently used text
classifiers – Rocchio, Naive Bayes, Nearest Neigh-
bor, and Support Vector Machines, selected based on
their diversity of learning methodologies.
Naive Bayes. The basic idea in a Naive Bayes
text classifier is to estimate the probability of a
category given a document using joint probabili-
ties of words and documents. Naive Bayes as-
sumes word independence, which means that the
conditional probability of a word given a category
is assumed to be independent of the conditional
probability of other words given the same category.
Despite this simplification, Naive Bayes classifiers
were shown to perform surprisingly well on text
classification (Joachims, 1997), (Schneider, 2004).
While there are several versions of Naive Bayes
classifiers (variations of multinomial and multivari-
ate Bernoulli), we use the multinomial model (Mc-
Callum and Nigam, 1998), which was shown to be
more effective.
Rocchio. This is an adaptation of the relevance
feedback method developed in information retrieval
(Rocchio, 1971). It uses standard tf.idf weighted
vectors to represent documents, and builds a pro-
totype vector for each category by summing up the
vectors of the training documents in each category.
Test documents are then assigned to the category
that has the closest prototype vector, based on a
cosine similarity. Text classification experiments
with different versions of the Rocchio algorithm
showed competitive results on standard benchmarks
(Joachims, 1997), (Moschitti, 2003).
KNN. K-Nearest Neighbor is one of the earliest text
categorization approaches (Makoto and Takenobu,
1995; Masand et al., 1992). The algorithm classifies
a test document based on the best class label identi-
fied for the nearest K-neighbors in the training doc-
uments. The best class label is chosen by weighting
the class of each similar training document with its
similarity to the target test document.
SVM. Support Vector Machines (Vapnik, 1995) is
a state-of-the-art machine learning approach based
on decision plans. The algorithm defines the best
hyper-plan which separates set of points associated
with different class labels with a maximum-margin.
The unlabeled examples are then classified by de-
ciding in which side of the hyper-surface they re-
side. The hyper-plan can be a simple linear plan as
first proposed by Vapnik, or a non-linear plan such
as e.g. polynomial, radial, or sigmoid. In our eval-
uation we used the linear kernel since it was proved
to be as powerful as the other kernels when tested on
text classification data sets (Yang and Liu, 1999).
</bodyText>
<subsectionHeader confidence="0.99901">
4.3 Data Sets
</subsectionHeader>
<bodyText confidence="0.998753342857143">
In our experiments we use Reuters-21578,
WebKB, 20Newsgroups, and Ling5pam
datasets. These datasets are commonly used for text
classification evaluations (Joachims, 1996; Craven
et al., 1998; Androutsopoulos et al., 2000; Mihalcea
and Hassan, 2005).
Reuter-21578. This is a publicly available subset of
the Reuters news, containing about 120 categories.
We use the standard ModApte data split (Apte et
al., 1994). The unlabeled documents were discarded
and only the documents with one or more class la-
bels were used in the classification experiments.
WebKB. This is a data set collected from com-
puter science departments of various universities by
the CMU text learning group. The dataset contains
seven class labels which are Project, Student, De-
partment, Faculty, Staff, Course, and Other. The
Other label was removed from the dataset for evalu-
ation purposes. Most of the evaluations in the liter-
ature have been performed on only four of the cate-
gories (Project, Student, Faculty, and Course) since
they represent the largest categories. However, since
we wanted to see how our system behaves when only
a few training examples were available as e.g. in the
Staff and the Department classes, we performed our
evaluations on two versions of WebKB: one with
the four categories version (W ebKB4) and one with
the six categories (W ebKB6).
20-Newsgroups. This is a collection of 20,000 mes-
sages from 20 different newsgroups, corresponding
to different topics or subjects. Each newsgroup has
about 1000 message split into 400 test and 600 train
documents.
LingSpam. This is a spam corpus, consisting of
email messages organized in 10 collections to al-
</bodyText>
<page confidence="0.996516">
57
</page>
<bodyText confidence="0.9998785">
low for 10-fold cross validation. Each collection has
roughly 300 spam and legitimate messages. There
are four versions of the corpus standing for bare,
stop-word filtered, lemmatized, and stop-word and
lemmatized. We use the bare collection with a stan-
dard 10-fold cross validation.
</bodyText>
<subsectionHeader confidence="0.997645">
4.4 Performance Measures
</subsectionHeader>
<bodyText confidence="0.999947346153846">
To evaluate the classification system we used the tra-
ditional accuracy measure defined as the number of
correct predictions divided with the number of eval-
uated examples.
We also use the correlation coefficient (p) as
a diversity measure to evaluate the dissimilarity
between the weighting models. Pairwise diver-
sity measures have been traditionally used to mea-
sure the statistical independence among ensemble of
classifiers (Kuncheva and Whitaker, 2003). Here,
we use them to measure the correlation between our
random-walk approach and the traditional term fre-
quency approach. The typical setting in which the
pairwise diversity measures are used is a set of dif-
ferent classifiers which are used to classify the same
set of feature vectors or documents over a given
dataset. In our evaluation we use the same classifier
to evaluate two different sets of feature vectors that
are produced by different weighting features: the rw
random walk weighting, and the tf term frequency
weighting. Since the two feature vector collections
are evaluated by one classifier at a time, the resulted
diversity scores will reflect the diversity of the two
systems.
Let Di and Dj be two feature weighting models
with the following contingency table.
</bodyText>
<table confidence="0.998418333333333">
Dj correct=Y Dj correct=N
Di correct=Y a b
Di correct=N c d
</table>
<tableCaption confidence="0.998491">
Table 2: Di &amp; Dj Contingency table
</tableCaption>
<bodyText confidence="0.883263">
The correlation coefficient (p) is defined as:
ad − bc
</bodyText>
<footnote confidence="0.799087">
pij = �/(a + b)(c + d)(a + c)(b + d)
5The symbol tindicates a statistically significant result using
</footnote>
<tableCaption confidence="0.988302">
Table 3: Naive Bayes Results5
</tableCaption>
<table confidence="0.999921">
N.B. tf rw2 rw4 rw6 rw8
WebKB4 81.9 81.9 82.8 82.7 81.2
WebKB6 71.7 73.0 74.21 74.41 73.5
Reuter 83.2 82.5 82.9 83.0 82.8
20NG 81.7 82.0 82.3$ 82.3$ 82.11
L5pam 99.3 99.4 99.3 99.3 99.3
</table>
<tableCaption confidence="0.951581">
Table 4: Rocchio Results
</tableCaption>
<table confidence="0.9998395">
ROC tf rw2 rw4 rw6 rw8
WebKB4 71.9 77.5$ 78.6$ 80.8$ 80.9$
WebKB6 58.3 69.6$ 72.0$ 76.5$ 76.2$
Reuter 78.2 80.8$ 81.1$ 81.0$ 81.4$
20NG 76.2 77.3$ 77.1$ 77.2$ 77.4$
L5pam 97.5 97.8 97.8 97.7 97.8
</table>
<sectionHeader confidence="0.986167" genericHeader="evaluation">
5 Evaluation and Discussion
</sectionHeader>
<bodyText confidence="0.998542071428572">
Tables 3, 4, 5, 6 show the classification results for
WebKB4, WebKB6, Ling5pam, Reuter, and
20Newsgroups respectively. The rw2, rw4, rw6,
and rw8 represent the accuracies achieved using
random-walk weighting under window sizes of 2,
4, 6, and 8 respectively. The tf column represents
the results obtained with a term frequency weighting
scheme.
By examining the results we can see that the
rw.idf model outperforms the tf.idf model on all
the classifiers and datasets with only one excep-
tion in the case of a Naive Bayes classifier under
Reuter. The error reductions range from 3.5% as in
{20Newsgroups, NaiveBayes, rw41 to 44% as in
the case of {WebKB6, Rocchio, rw61. The system
gives, in its worst performance, a comparable result
to the tf.idf baseline. The system shows a consis-
tent performance with different window sizes, with
no clear cut window size that would give the best
result. By further analyzing the results using statis-
tical paired t-tests we can see that windows of size
4 and 6 supply the most significant results across all
the classifiers as well as the datasets.
Comparing WebKB4 and WebKB6 fine-grained
results, we found that both systems failed to pre-
dict the class Staff; however the significant improve-
a paired t-test, with p &lt; 0.05. The result is marked by t when
p &lt; 0.001.
</bodyText>
<page confidence="0.99932">
58
</page>
<tableCaption confidence="0.995171">
Table 5: KNN Results
</tableCaption>
<table confidence="0.999966">
KNN tf rw2 rw4 rw6 rw8
WebKB4 59.2 68.6‡ 67.0‡ 64.6‡ 66.6‡
WebKB6 55.8 63.7‡ 55.8 59.9† 61.0‡
Reuter 73.6 76.9‡ 78.1‡ 78.5‡ 78.5‡
20NG 70.3 76.1‡ 76.5‡ 77.2‡ 77.8‡
LSpam 97.5 97.8 97.8 98.1† 97.9
</table>
<tableCaption confidence="0.728598">
Table 8: Rocchio Correlation p
</tableCaption>
<table confidence="0.999970333333333">
ROC rw2 rw4 rw6 rw8
WebKB4 0.49 0.51 0.53 0.54
WebKB6 0.40 0.40 0.41 0.42
Reuter 0.75 0.77 0.75 0.71
20NG 0.77 0.77 0.77 0.77
LSpam 0.82 0.85 0.81 0.78
</table>
<tableCaption confidence="0.831973">
Table 6: SVM Results
</tableCaption>
<table confidence="0.999259166666667">
SVM tf rw2 rw4 rw6 rw8
WebKB4 87.7 87.9 87.9 89† 88.5
WebKB6 82.5 84.5‡ 85.2‡ 85.2‡ 84.6‡
Reuter 83.2 84.5‡ 84.4‡ 84.6‡ 84.1†
20NG 95.2 95.5‡ 95.6‡ 95.6‡ 95.4†
LSpam 95.6 96.4‡ 96.4‡ 96.2‡ 96.3‡
</table>
<bodyText confidence="0.994627777777778">
ment was over the class Department, in which our
rw model scores an accuracy of 47% compared to
4% in using tf.idf. This indicates how successful
rw.idf model is in cases where there are few train-
ing examples. This could be due to the ability of the
model to extract more realistic and smoother distri-
bution of terms as seen in the rw curve plotted in
Figure 3, hence reducing the feature bias imposed
by the limited number of training examples.
</bodyText>
<tableCaption confidence="0.996805">
Table 7: Naive Bayes Correlation p
</tableCaption>
<table confidence="0.9986405">
N.B. rw2 rw4 rw6 rw8
WebKB4 0.68 0.70 0.70 0.66
WebKB6 0.71 0.71 0.71 0.65
Reuter 0.86 0.87 0.87 0.85
20NG 0.82 0.84 0.83 0.82
LSpam 0.89 0.89 0.92 0.92
</table>
<bodyText confidence="0.999572833333333">
By also examining the diversity of the classifi-
cation systems based on rw and tf weighting, as
shown in Table 7, 8, 9, 10, we can see an inter-
esting property of the system. The two models are
generally more diverse and less correlated when us-
ing windows of size 6 and 8 than using windows of
size 2 and 4. This could be due to the increasing
drift from the feature independence assumption that
is implied by tf.idf. However increasing the depen-
dency is not always desirable as seen in the reported
accuracies. We expect that at a certain window size
the system performance will degrade to tf.idf. This
</bodyText>
<tableCaption confidence="0.977882">
Table 9: KNN Correlation p
</tableCaption>
<table confidence="0.9989745">
KNN rw2 rw4 rw6 rw8
WebKB4 0.35 0.32 0.36 0.37
WebKB6 0.35 0.35 0.37 0.37
Reuter 0.74 0.70 0.68 0.67
20NG 0.62 0.64 0.63 0.59
LSpam 0.66 0.69 0.63 0.57
</table>
<bodyText confidence="0.996365333333333">
threshold window size will be equal to the document
size. In such a case each term will depend on all the
remaining terms resulting in an almost completely
connected graph. Consequently, each feature contri-
bution to the surrounding will be equal resulting in
similar rw scores to all the features.
</bodyText>
<sectionHeader confidence="0.998933" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99998235">
Based on results obtained in text classification ex-
periments, the TextRank random-walk model to
term weighting was found to achieve error rate re-
ductions of 3.5–44% as compared to the traditional
frequency-based approach. The evaluation results
have shown that the system performance varies de-
pending on window size, dataset, as well as classi-
fier, with the greatest boost in performance recorded
for KNN ,Rocchio, and SVM. We believe that these
results support our claim that random-walk models
can accurately estimate term weights, and can be
used as a technique to model the probabilistic dis-
tribution of features in a document.
The evaluations reported in this paper has shown
that the TextRank model can accurately provide uni-
gram probabilities for a sequence of words. In future
work we will try to extend the TextRank model and
use it to define a formal language model in which
we can estimate the probability of entire sequences
of words (n-grams).
</bodyText>
<page confidence="0.999384">
59
</page>
<tableCaption confidence="0.987959">
Table 10: SVM Correlation p
</tableCaption>
<table confidence="0.999799166666667">
SVM rw2 rw4 rw6 rw8
WebKB4 0.73 0.77 0.78 0.82
WebKB6 0.73 0.76 0.78 0.80
Reuter 0.80 0.83 0.82 0.82
20NG 0.80 0.78 0.82 0.83
LSpam 0.86 0.88 0.88 0.89
</table>
<sectionHeader confidence="0.995385" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999889346938775">
I. Androutsopoulos, J. Koutsias, K. V. Chandrinos,
G. Paliouras, and C. D. Spyropoulos. 2000. An eval-
uation of naive bayesian anti-spam filtering. In Pro-
ceedings of the workshop on Machine Learning in the
New Information Age.
C. Apte, F. Damerau, and S. M. Weiss. 1994. Towards
language independent automated learning of text cat-
egorisation models. In Proceedings of the 17th ACM
SIGIR Conference on Research and Development in
Information Retrieval.
L. Bahl, F. Jelinek, and R. Mercer. 1983. A maximum
likelihood approach to continuous speech recognition.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 5(2).
S. Brin and L. Page. 1998. The anatomy of a large-scale
hypertextual Web search engine. Computer Networks
andISDNSystems, 30(1–7).
M. Craven, D. DiPasquo, D. Freitag, A. McCallum,
T. Mitchell, K. Nigam, and S. Slattery. 1998. Learn-
ing to extract symbolic knowledge from the World
Wide Web. In Proceedings of the 15th Conference of
the American Association for Artificial Intelligence.
B. Dom, I. Eiron, A. Cozzi, and Y. Shang. 2003. Graph-
based ranking algorithms for e-mail expertise analysis.
In Proceedings of the 8th ACM SIGMOD workshop on
Research issues in data mining and knowledge discov-
ery, San Diego, California.
G. Erkan and D. Radev. 2004. Lexpagerank: Prestige in
multi-document text summarization. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, Barcelona, Spain, July.
G. Grimmett and D. Stirzaker. 1989. Probability and
Random Processes. Oxford University Press.
P.J. Herings, G. van der Laan, and D. Talman. 2001.
Measuring the power of nodes in digraphs. Technical
report, Tinbergen Institute.
T. Joachims. 1996. A probabilistic analysis of the roc-
chio algorithm with tf.idf for text categorization. In
Proceedings of the 14th International Conference on
Machine Learning.
T. Joachims. 1997. A probabilistic analysis of the Roc-
chio algorithm with TFIDF for text categorization. In
Proceedings of ICML-97, 14th International Confer-
ence on Machine Learning, Nashville, US.
L. Kuncheva and C. Whitaker. 2003. Measures of diver-
sity in classifier ensembles and their relationship with
the ensemble accuracy. Machine Learning, 51.
I. Makoto and T. Takenobu. 1995. Cluster-based text cat-
egorization: A comparison of category search starte-
gies. In Proceedings of the 18th ACM International
Conference on Research and Development in Informa-
tion Retrieval.
B. Masand, G. Linoff, and D. Waltz. 1992. Classify-
ing news stories using memory based reasoning. In
Proceedings of the 15th International Conference on
Research and Development in information Retrieval.
A. McCallum and K. Nigam. 1998. A comparison of
event models for Naive Bayes text classification. In
Proceedings of AAAI-98 Workshop on Learning for
Text Categorization.
R. Mihalcea and S. Hassan. 2005. Using the essence of
texts to improve document classification. In Proceed-
ings of the Conference on Recent Advances in Natural
Language Processing (RANLP), Borovetz, Bulgaria.
R. Mihalcea and P. Tarau. 2004. TextRank – bringing
order into texts. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP 2004), Barcelona, Spain.
A. Moschitti. 2003. A study on optimal paramter tun-
ing for Rocchio text classifier. In Proceedings of the
European Conference on Information Retrieval, Pisa,
Italy.
R. Robertson and K. Sparck Jones. 1997. Simple, proven
approaches to text retrieval. Technical report.
J. Rocchio, 1971. Relevance feedback in information re-
trieval. Prentice Hall, Ing. Englewood Cliffs, New Jer-
sey.
K. Schneider. 2004. A new feature selection score for
multinomial naive bayes text classification based on
kl-divergence. In The Companion Volume to the Pro-
ceedings of 42st Annual Meeting of the Association for
Computational Linguistics, Barcelona, Spain, July.
H. Schutze, D. A. Hull, and J. O. Pedersen. 1995. A
comparison of classifiers and document representa-
tions for the routing problem. In Proceedings of the
18th annual international ACM SIGIR conference on
Research and development in information retrieval,
Seattle, Washington.
V. Vapnik. 1995. The Nature of Statistical Learning The-
ory. Springer, New York.
Y. Yang and X. Liu. 1999. A reexamination of text cate-
gorization methods. In Proceedings of the 22nd ACM
SIGIR Conference on Research and Development in
Information Retrieval.
Y. Yang and J. O. Pedersen. 1997. A comparative study
on feature selection in text categorization. In Proceed-
ings of the 14th International Conference on Machine
Learning, Nashville, US.
</reference>
<page confidence="0.998412">
60
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.725779">
<title confidence="0.999182">Random-Walk Term for Improved Text Classification</title>
<author confidence="0.990709">Hassan</author>
<affiliation confidence="0.9999585">Department of Computer University of North</affiliation>
<address confidence="0.759975">Denton, TX</address>
<email confidence="0.999676">samer@unt.edu,carmen@unt.edu</email>
<abstract confidence="0.99827135">This paper describes a new approach for estimating term weights in a text classification task. The approach uses term cooccurrence as a measure of dependency between word features. A random walk model is applied on a graph encoding words and co-occurrence dependencies, resulting in scores that represent a quantification of how a particular word feature contributes to a given context. We argue that by modeling feature weights using these scores, as opposed to the traditional frequency-based scores, we can achieve better results in a text classification task. Experiments performed on four standard classification datasets show that the new random-walk based approach outperforms the traditional term frequency approach to feature weighting.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Androutsopoulos</author>
<author>J Koutsias</author>
<author>K V Chandrinos</author>
<author>G Paliouras</author>
<author>C D Spyropoulos</author>
</authors>
<title>An evaluation of naive bayesian anti-spam filtering.</title>
<date>2000</date>
<booktitle>In Proceedings of the workshop on Machine Learning in the New Information Age.</booktitle>
<contexts>
<context position="17362" citStr="Androutsopoulos et al., 2000" startWordPosition="2899" endWordPosition="2902">mples are then classified by deciding in which side of the hyper-surface they reside. The hyper-plan can be a simple linear plan as first proposed by Vapnik, or a non-linear plan such as e.g. polynomial, radial, or sigmoid. In our evaluation we used the linear kernel since it was proved to be as powerful as the other kernels when tested on text classification data sets (Yang and Liu, 1999). 4.3 Data Sets In our experiments we use Reuters-21578, WebKB, 20Newsgroups, and Ling5pam datasets. These datasets are commonly used for text classification evaluations (Joachims, 1996; Craven et al., 1998; Androutsopoulos et al., 2000; Mihalcea and Hassan, 2005). Reuter-21578. This is a publicly available subset of the Reuters news, containing about 120 categories. We use the standard ModApte data split (Apte et al., 1994). The unlabeled documents were discarded and only the documents with one or more class labels were used in the classification experiments. WebKB. This is a data set collected from computer science departments of various universities by the CMU text learning group. The dataset contains seven class labels which are Project, Student, Department, Faculty, Staff, Course, and Other. The Other label was removed </context>
</contexts>
<marker>Androutsopoulos, Koutsias, Chandrinos, Paliouras, Spyropoulos, 2000</marker>
<rawString>I. Androutsopoulos, J. Koutsias, K. V. Chandrinos, G. Paliouras, and C. D. Spyropoulos. 2000. An evaluation of naive bayesian anti-spam filtering. In Proceedings of the workshop on Machine Learning in the New Information Age.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Apte</author>
<author>F Damerau</author>
<author>S M Weiss</author>
</authors>
<title>Towards language independent automated learning of text categorisation models.</title>
<date>1994</date>
<booktitle>In Proceedings of the 17th ACM SIGIR Conference on Research and Development in Information Retrieval.</booktitle>
<contexts>
<context position="17554" citStr="Apte et al., 1994" startWordPosition="2929" endWordPosition="2932">, radial, or sigmoid. In our evaluation we used the linear kernel since it was proved to be as powerful as the other kernels when tested on text classification data sets (Yang and Liu, 1999). 4.3 Data Sets In our experiments we use Reuters-21578, WebKB, 20Newsgroups, and Ling5pam datasets. These datasets are commonly used for text classification evaluations (Joachims, 1996; Craven et al., 1998; Androutsopoulos et al., 2000; Mihalcea and Hassan, 2005). Reuter-21578. This is a publicly available subset of the Reuters news, containing about 120 categories. We use the standard ModApte data split (Apte et al., 1994). The unlabeled documents were discarded and only the documents with one or more class labels were used in the classification experiments. WebKB. This is a data set collected from computer science departments of various universities by the CMU text learning group. The dataset contains seven class labels which are Project, Student, Department, Faculty, Staff, Course, and Other. The Other label was removed from the dataset for evaluation purposes. Most of the evaluations in the literature have been performed on only four of the categories (Project, Student, Faculty, and Course) since they repres</context>
</contexts>
<marker>Apte, Damerau, Weiss, 1994</marker>
<rawString>C. Apte, F. Damerau, and S. M. Weiss. 1994. Towards language independent automated learning of text categorisation models. In Proceedings of the 17th ACM SIGIR Conference on Research and Development in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bahl</author>
<author>F Jelinek</author>
<author>R Mercer</author>
</authors>
<title>A maximum likelihood approach to continuous speech recognition.</title>
<date>1983</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="1584" citStr="Bahl et al., 1983" startWordPosition="246" endWordPosition="249">rm frequency has long been adapted as a measure of term significance in a specific context (Robertson and Jones, 1997). The logic behind it is that the more a certain term is encountered in a certain context, the more it carries or contributes to the meaning of the context. Due to this belief, term frequency has been a major factor in estimating the probabilistic distribution of features using maximum likelihood estimates and hence has been incorporated in a broad spectrum of tasks ranging from feature selec53 tion techniques (Yang and Pedersen, 1997; Schutze et al., 1995) to language models (Bahl et al., 1983). In this paper we introduce a new measure of term weighting, which integrates the locality of a term and its relation to the surrounding context. We model this local contribution using a co-occurrence relation in which terms that co-occur in a certain context are likely to share between them some of their importance (or significance). Note that in this model the relation between a given term and its context is not linear, since the context itself consists of a collection of other terms, which in turn have a dependency relation with their own context, which might include the original given ter</context>
</contexts>
<marker>Bahl, Jelinek, Mercer, 1983</marker>
<rawString>L. Bahl, F. Jelinek, and R. Mercer. 1983. A maximum likelihood approach to continuous speech recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 5(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brin</author>
<author>L Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual Web search engine.</title>
<date>1998</date>
<journal>Computer Networks andISDNSystems,</journal>
<pages>30--1</pages>
<contexts>
<context position="2332" citStr="Brin and Page, 1998" startWordPosition="371" endWordPosition="374">rrounding context. We model this local contribution using a co-occurrence relation in which terms that co-occur in a certain context are likely to share between them some of their importance (or significance). Note that in this model the relation between a given term and its context is not linear, since the context itself consists of a collection of other terms, which in turn have a dependency relation with their own context, which might include the original given term. In order to model this recursive relation we use a graph-based ranking algorithm, namely the PageRank randomwalk algorithms (Brin and Page, 1998), and its TextRank adaption to text processing applications (Mihalcea and Tarau, 2004). TextRank takes as input a set of textual entities and relations between them, and uses a graph-based ranking algorithm (also known as random walk algorithm) to produce a set of scores that represent the accumulated weight or rank for each textual entity in their context. The TextRank model was so far evaluated on three natural language processing tasks: document summarization, word sense disambiguation, and keyword extraction, and despite being fully unsupervised, it has been shown to be competitive with ot</context>
<context position="4360" citStr="Brin and Page, 1998" startWordPosition="700" endWordPosition="703">ertex. The higher the number of votes that are cast for a vertex, the higher the importance of the vertex. Moreover, the importance of the vertex casting a vote determines how important the vote itself is, and this information is also taken into account by the ranking algorithm. Hence, the score associated with a vertex is determined based on the votes that are cast for it, and the scores of the vertices casting these votes. While there are several graph-based ranking algorithms previously proposed in the literature (Herings et al., 2001), we focus on only one such algorithm, namely PageRank (Brin and Page, 1998), as it was previously found successful in a number of applications, including Web link analysis (Brin and Page, 1998), social networks (Dom et al., 2003), citation analysis, and more recently in several text processing applications (Mihalcea and Tarau, 2004), (Erkan and Radev, 2004). Given a graph G = (V, E), let In(Va) be the set of vertices that point to vertex Va (predecessors), and let Out(Va) be the set of vertices that vertex Va points to (successors). The PageRank score associated with the vertex Va is then defined using a recursive function that integrates the scores of its predecesso</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>S. Brin and L. Page. 1998. The anatomy of a large-scale hypertextual Web search engine. Computer Networks andISDNSystems, 30(1–7).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Craven</author>
<author>D DiPasquo</author>
<author>D Freitag</author>
<author>A McCallum</author>
<author>T Mitchell</author>
<author>K Nigam</author>
<author>S Slattery</author>
</authors>
<title>Learning to extract symbolic knowledge from the World Wide Web.</title>
<date>1998</date>
<booktitle>In Proceedings of the 15th Conference of the American Association for Artificial Intelligence.</booktitle>
<contexts>
<context position="17332" citStr="Craven et al., 1998" startWordPosition="2895" endWordPosition="2898">in. The unlabeled examples are then classified by deciding in which side of the hyper-surface they reside. The hyper-plan can be a simple linear plan as first proposed by Vapnik, or a non-linear plan such as e.g. polynomial, radial, or sigmoid. In our evaluation we used the linear kernel since it was proved to be as powerful as the other kernels when tested on text classification data sets (Yang and Liu, 1999). 4.3 Data Sets In our experiments we use Reuters-21578, WebKB, 20Newsgroups, and Ling5pam datasets. These datasets are commonly used for text classification evaluations (Joachims, 1996; Craven et al., 1998; Androutsopoulos et al., 2000; Mihalcea and Hassan, 2005). Reuter-21578. This is a publicly available subset of the Reuters news, containing about 120 categories. We use the standard ModApte data split (Apte et al., 1994). The unlabeled documents were discarded and only the documents with one or more class labels were used in the classification experiments. WebKB. This is a data set collected from computer science departments of various universities by the CMU text learning group. The dataset contains seven class labels which are Project, Student, Department, Faculty, Staff, Course, and Other</context>
</contexts>
<marker>Craven, DiPasquo, Freitag, McCallum, Mitchell, Nigam, Slattery, 1998</marker>
<rawString>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam, and S. Slattery. 1998. Learning to extract symbolic knowledge from the World Wide Web. In Proceedings of the 15th Conference of the American Association for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dom</author>
<author>I Eiron</author>
<author>A Cozzi</author>
<author>Y Shang</author>
</authors>
<title>Graphbased ranking algorithms for e-mail expertise analysis.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th ACM SIGMOD workshop on Research issues in</booktitle>
<location>San Diego, California.</location>
<contexts>
<context position="4514" citStr="Dom et al., 2003" startWordPosition="726" endWordPosition="729">ote determines how important the vote itself is, and this information is also taken into account by the ranking algorithm. Hence, the score associated with a vertex is determined based on the votes that are cast for it, and the scores of the vertices casting these votes. While there are several graph-based ranking algorithms previously proposed in the literature (Herings et al., 2001), we focus on only one such algorithm, namely PageRank (Brin and Page, 1998), as it was previously found successful in a number of applications, including Web link analysis (Brin and Page, 1998), social networks (Dom et al., 2003), citation analysis, and more recently in several text processing applications (Mihalcea and Tarau, 2004), (Erkan and Radev, 2004). Given a graph G = (V, E), let In(Va) be the set of vertices that point to vertex Va (predecessors), and let Out(Va) be the set of vertices that vertex Va points to (successors). The PageRank score associated with the vertex Va is then defined using a recursive function that integrates the scores of its predecessors: 1] S(Va) = (1 − d) + d * VbEIn(Va) where d is a parameter that is set between 0 and 11. The score of each vertex is recalculated upon each iteration b</context>
</contexts>
<marker>Dom, Eiron, Cozzi, Shang, 2003</marker>
<rawString>B. Dom, I. Eiron, A. Cozzi, and Y. Shang. 2003. Graphbased ranking algorithms for e-mail expertise analysis. In Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery, San Diego, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Erkan</author>
<author>D Radev</author>
</authors>
<title>Lexpagerank: Prestige in multi-document text summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Barcelona, Spain,</location>
<contexts>
<context position="4644" citStr="Erkan and Radev, 2004" startWordPosition="745" endWordPosition="748">nce, the score associated with a vertex is determined based on the votes that are cast for it, and the scores of the vertices casting these votes. While there are several graph-based ranking algorithms previously proposed in the literature (Herings et al., 2001), we focus on only one such algorithm, namely PageRank (Brin and Page, 1998), as it was previously found successful in a number of applications, including Web link analysis (Brin and Page, 1998), social networks (Dom et al., 2003), citation analysis, and more recently in several text processing applications (Mihalcea and Tarau, 2004), (Erkan and Radev, 2004). Given a graph G = (V, E), let In(Va) be the set of vertices that point to vertex Va (predecessors), and let Out(Va) be the set of vertices that vertex Va points to (successors). The PageRank score associated with the vertex Va is then defined using a recursive function that integrates the scores of its predecessors: 1] S(Va) = (1 − d) + d * VbEIn(Va) where d is a parameter that is set between 0 and 11. The score of each vertex is recalculated upon each iteration based on the new weights that the neighboring vertices have accumulated. The algorithm terminates when the convergence point is rea</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G. Erkan and D. Radev. 2004. Lexpagerank: Prestige in multi-document text summarization. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Grimmett</author>
<author>D Stirzaker</author>
</authors>
<title>Probability and Random Processes.</title>
<date>1989</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="6138" citStr="Grimmett and Stirzaker, 1989" startWordPosition="1023" endWordPosition="1026">e the rank or the score at iteration k and Sk+1(Vi) be the score at iteration k + 1. The error rate ER is defined as: ER = Sk+1(Vi) − Sk(Vi) (2) This vertex scoring scheme is based on a random walk model, where a walker takes random steps on the graph G, with the walk being modeled as a Markov process – that is, the decision on what edge to follow is solely based on the vertex where the walker is currently located. Under certain conditions, this model converges to a stationary distribution of probabilities, associated with vertices in the graph. Based on the Ergodic theorem for Markov chains (Grimmett and Stirzaker, 1989), the algorithm is guaranteed to converge if the graph is both aperiodic and irreducible. The first condition is achieved for any graph that is a non-bipartite graph, while the second condition holds for any strongly connected graph – property achieved by PageRank through the random jumps introduced by the (1− d) factor. In matrix notation, the PageRank vector of stationary probabilities is the principal eigenvector for the matrix Arow, which is obtained from the adjacency matrix A representing the graph, with all rows normalized to sum to 1: (P = ATrowP). Intuitively, the stationary probabili</context>
</contexts>
<marker>Grimmett, Stirzaker, 1989</marker>
<rawString>G. Grimmett and D. Stirzaker. 1989. Probability and Random Processes. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Herings</author>
<author>G van der Laan</author>
<author>D Talman</author>
</authors>
<title>Measuring the power of nodes in digraphs.</title>
<date>2001</date>
<tech>Technical report,</tech>
<institution>Tinbergen Institute.</institution>
<marker>Herings, van der Laan, Talman, 2001</marker>
<rawString>P.J. Herings, G. van der Laan, and D. Talman. 2001. Measuring the power of nodes in digraphs. Technical report, Tinbergen Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>A probabilistic analysis of the rocchio algorithm with tf.idf for text categorization.</title>
<date>1996</date>
<booktitle>In Proceedings of the 14th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="17311" citStr="Joachims, 1996" startWordPosition="2893" endWordPosition="2894">h a maximum-margin. The unlabeled examples are then classified by deciding in which side of the hyper-surface they reside. The hyper-plan can be a simple linear plan as first proposed by Vapnik, or a non-linear plan such as e.g. polynomial, radial, or sigmoid. In our evaluation we used the linear kernel since it was proved to be as powerful as the other kernels when tested on text classification data sets (Yang and Liu, 1999). 4.3 Data Sets In our experiments we use Reuters-21578, WebKB, 20Newsgroups, and Ling5pam datasets. These datasets are commonly used for text classification evaluations (Joachims, 1996; Craven et al., 1998; Androutsopoulos et al., 2000; Mihalcea and Hassan, 2005). Reuter-21578. This is a publicly available subset of the Reuters news, containing about 120 categories. We use the standard ModApte data split (Apte et al., 1994). The unlabeled documents were discarded and only the documents with one or more class labels were used in the classification experiments. WebKB. This is a data set collected from computer science departments of various universities by the CMU text learning group. The dataset contains seven class labels which are Project, Student, Department, Faculty, Sta</context>
</contexts>
<marker>Joachims, 1996</marker>
<rawString>T. Joachims. 1996. A probabilistic analysis of the rocchio algorithm with tf.idf for text categorization. In Proceedings of the 14th International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.</title>
<date>1997</date>
<booktitle>In Proceedings of ICML-97, 14th International Conference on Machine Learning,</booktitle>
<location>Nashville, US.</location>
<contexts>
<context position="15247" citStr="Joachims, 1997" startWordPosition="2574" endWordPosition="2575">eighbor, and Support Vector Machines, selected based on their diversity of learning methodologies. Naive Bayes. The basic idea in a Naive Bayes text classifier is to estimate the probability of a category given a document using joint probabilities of words and documents. Naive Bayes assumes word independence, which means that the conditional probability of a word given a category is assumed to be independent of the conditional probability of other words given the same category. Despite this simplification, Naive Bayes classifiers were shown to perform surprisingly well on text classification (Joachims, 1997), (Schneider, 2004). While there are several versions of Naive Bayes classifiers (variations of multinomial and multivariate Bernoulli), we use the multinomial model (McCallum and Nigam, 1998), which was shown to be more effective. Rocchio. This is an adaptation of the relevance feedback method developed in information retrieval (Rocchio, 1971). It uses standard tf.idf weighted vectors to represent documents, and builds a prototype vector for each category by summing up the vectors of the training documents in each category. Test documents are then assigned to the category that has the closest</context>
</contexts>
<marker>Joachims, 1997</marker>
<rawString>T. Joachims. 1997. A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization. In Proceedings of ICML-97, 14th International Conference on Machine Learning, Nashville, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kuncheva</author>
<author>C Whitaker</author>
</authors>
<title>Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy.</title>
<date>2003</date>
<booktitle>Machine Learning,</booktitle>
<volume>51</volume>
<contexts>
<context position="19556" citStr="Kuncheva and Whitaker, 2003" startWordPosition="3246" endWordPosition="3249">tanding for bare, stop-word filtered, lemmatized, and stop-word and lemmatized. We use the bare collection with a standard 10-fold cross validation. 4.4 Performance Measures To evaluate the classification system we used the traditional accuracy measure defined as the number of correct predictions divided with the number of evaluated examples. We also use the correlation coefficient (p) as a diversity measure to evaluate the dissimilarity between the weighting models. Pairwise diversity measures have been traditionally used to measure the statistical independence among ensemble of classifiers (Kuncheva and Whitaker, 2003). Here, we use them to measure the correlation between our random-walk approach and the traditional term frequency approach. The typical setting in which the pairwise diversity measures are used is a set of different classifiers which are used to classify the same set of feature vectors or documents over a given dataset. In our evaluation we use the same classifier to evaluate two different sets of feature vectors that are produced by different weighting features: the rw random walk weighting, and the tf term frequency weighting. Since the two feature vector collections are evaluated by one cl</context>
</contexts>
<marker>Kuncheva, Whitaker, 2003</marker>
<rawString>L. Kuncheva and C. Whitaker. 2003. Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy. Machine Learning, 51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Makoto</author>
<author>T Takenobu</author>
</authors>
<title>Cluster-based text categorization: A comparison of category search startegies.</title>
<date>1995</date>
<booktitle>In Proceedings of the 18th ACM International Conference on Research and Development in Information Retrieval.</booktitle>
<contexts>
<context position="16168" citStr="Makoto and Takenobu, 1995" startWordPosition="2707" endWordPosition="2710">developed in information retrieval (Rocchio, 1971). It uses standard tf.idf weighted vectors to represent documents, and builds a prototype vector for each category by summing up the vectors of the training documents in each category. Test documents are then assigned to the category that has the closest prototype vector, based on a cosine similarity. Text classification experiments with different versions of the Rocchio algorithm showed competitive results on standard benchmarks (Joachims, 1997), (Moschitti, 2003). KNN. K-Nearest Neighbor is one of the earliest text categorization approaches (Makoto and Takenobu, 1995; Masand et al., 1992). The algorithm classifies a test document based on the best class label identified for the nearest K-neighbors in the training documents. The best class label is chosen by weighting the class of each similar training document with its similarity to the target test document. SVM. Support Vector Machines (Vapnik, 1995) is a state-of-the-art machine learning approach based on decision plans. The algorithm defines the best hyper-plan which separates set of points associated with different class labels with a maximum-margin. The unlabeled examples are then classified by decid</context>
</contexts>
<marker>Makoto, Takenobu, 1995</marker>
<rawString>I. Makoto and T. Takenobu. 1995. Cluster-based text categorization: A comparison of category search startegies. In Proceedings of the 18th ACM International Conference on Research and Development in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Masand</author>
<author>G Linoff</author>
<author>D Waltz</author>
</authors>
<title>Classifying news stories using memory based reasoning.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th International Conference on Research and Development in information Retrieval.</booktitle>
<contexts>
<context position="16190" citStr="Masand et al., 1992" startWordPosition="2711" endWordPosition="2714">trieval (Rocchio, 1971). It uses standard tf.idf weighted vectors to represent documents, and builds a prototype vector for each category by summing up the vectors of the training documents in each category. Test documents are then assigned to the category that has the closest prototype vector, based on a cosine similarity. Text classification experiments with different versions of the Rocchio algorithm showed competitive results on standard benchmarks (Joachims, 1997), (Moschitti, 2003). KNN. K-Nearest Neighbor is one of the earliest text categorization approaches (Makoto and Takenobu, 1995; Masand et al., 1992). The algorithm classifies a test document based on the best class label identified for the nearest K-neighbors in the training documents. The best class label is chosen by weighting the class of each similar training document with its similarity to the target test document. SVM. Support Vector Machines (Vapnik, 1995) is a state-of-the-art machine learning approach based on decision plans. The algorithm defines the best hyper-plan which separates set of points associated with different class labels with a maximum-margin. The unlabeled examples are then classified by deciding in which side of t</context>
</contexts>
<marker>Masand, Linoff, Waltz, 1992</marker>
<rawString>B. Masand, G. Linoff, and D. Waltz. 1992. Classifying news stories using memory based reasoning. In Proceedings of the 15th International Conference on Research and Development in information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>K Nigam</author>
</authors>
<title>A comparison of event models for Naive Bayes text classification.</title>
<date>1998</date>
<booktitle>In Proceedings of AAAI-98 Workshop on Learning for Text Categorization.</booktitle>
<contexts>
<context position="15439" citStr="McCallum and Nigam, 1998" startWordPosition="2599" endWordPosition="2603">bability of a category given a document using joint probabilities of words and documents. Naive Bayes assumes word independence, which means that the conditional probability of a word given a category is assumed to be independent of the conditional probability of other words given the same category. Despite this simplification, Naive Bayes classifiers were shown to perform surprisingly well on text classification (Joachims, 1997), (Schneider, 2004). While there are several versions of Naive Bayes classifiers (variations of multinomial and multivariate Bernoulli), we use the multinomial model (McCallum and Nigam, 1998), which was shown to be more effective. Rocchio. This is an adaptation of the relevance feedback method developed in information retrieval (Rocchio, 1971). It uses standard tf.idf weighted vectors to represent documents, and builds a prototype vector for each category by summing up the vectors of the training documents in each category. Test documents are then assigned to the category that has the closest prototype vector, based on a cosine similarity. Text classification experiments with different versions of the Rocchio algorithm showed competitive results on standard benchmarks (Joachims, 1</context>
</contexts>
<marker>McCallum, Nigam, 1998</marker>
<rawString>A. McCallum and K. Nigam. 1998. A comparison of event models for Naive Bayes text classification. In Proceedings of AAAI-98 Workshop on Learning for Text Categorization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>S Hassan</author>
</authors>
<title>Using the essence of texts to improve document classification.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Recent Advances in Natural Language Processing (RANLP),</booktitle>
<location>Borovetz, Bulgaria.</location>
<contexts>
<context position="17390" citStr="Mihalcea and Hassan, 2005" startWordPosition="2903" endWordPosition="2906">eciding in which side of the hyper-surface they reside. The hyper-plan can be a simple linear plan as first proposed by Vapnik, or a non-linear plan such as e.g. polynomial, radial, or sigmoid. In our evaluation we used the linear kernel since it was proved to be as powerful as the other kernels when tested on text classification data sets (Yang and Liu, 1999). 4.3 Data Sets In our experiments we use Reuters-21578, WebKB, 20Newsgroups, and Ling5pam datasets. These datasets are commonly used for text classification evaluations (Joachims, 1996; Craven et al., 1998; Androutsopoulos et al., 2000; Mihalcea and Hassan, 2005). Reuter-21578. This is a publicly available subset of the Reuters news, containing about 120 categories. We use the standard ModApte data split (Apte et al., 1994). The unlabeled documents were discarded and only the documents with one or more class labels were used in the classification experiments. WebKB. This is a data set collected from computer science departments of various universities by the CMU text learning group. The dataset contains seven class labels which are Project, Student, Department, Faculty, Staff, Course, and Other. The Other label was removed from the dataset for evaluat</context>
</contexts>
<marker>Mihalcea, Hassan, 2005</marker>
<rawString>R. Mihalcea and S. Hassan. 2005. Using the essence of texts to improve document classification. In Proceedings of the Conference on Recent Advances in Natural Language Processing (RANLP), Borovetz, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>P Tarau</author>
</authors>
<title>TextRank – bringing order into texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2004),</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="2418" citStr="Mihalcea and Tarau, 2004" startWordPosition="384" endWordPosition="388">n in which terms that co-occur in a certain context are likely to share between them some of their importance (or significance). Note that in this model the relation between a given term and its context is not linear, since the context itself consists of a collection of other terms, which in turn have a dependency relation with their own context, which might include the original given term. In order to model this recursive relation we use a graph-based ranking algorithm, namely the PageRank randomwalk algorithms (Brin and Page, 1998), and its TextRank adaption to text processing applications (Mihalcea and Tarau, 2004). TextRank takes as input a set of textual entities and relations between them, and uses a graph-based ranking algorithm (also known as random walk algorithm) to produce a set of scores that represent the accumulated weight or rank for each textual entity in their context. The TextRank model was so far evaluated on three natural language processing tasks: document summarization, word sense disambiguation, and keyword extraction, and despite being fully unsupervised, it has been shown to be competitive with other sometime supervised state-of-the-art algorithms. In this paper, we show how TextRa</context>
<context position="4619" citStr="Mihalcea and Tarau, 2004" startWordPosition="741" endWordPosition="744">by the ranking algorithm. Hence, the score associated with a vertex is determined based on the votes that are cast for it, and the scores of the vertices casting these votes. While there are several graph-based ranking algorithms previously proposed in the literature (Herings et al., 2001), we focus on only one such algorithm, namely PageRank (Brin and Page, 1998), as it was previously found successful in a number of applications, including Web link analysis (Brin and Page, 1998), social networks (Dom et al., 2003), citation analysis, and more recently in several text processing applications (Mihalcea and Tarau, 2004), (Erkan and Radev, 2004). Given a graph G = (V, E), let In(Va) be the set of vertices that point to vertex Va (predecessors), and let Out(Va) be the set of vertices that vertex Va points to (successors). The PageRank score associated with the vertex Va is then defined using a recursive function that integrates the scores of its predecessors: 1] S(Va) = (1 − d) + d * VbEIn(Va) where d is a parameter that is set between 0 and 11. The score of each vertex is recalculated upon each iteration based on the new weights that the neighboring vertices have accumulated. The algorithm terminates when the</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>R. Mihalcea and P. Tarau. 2004. TextRank – bringing order into texts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2004), Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
</authors>
<title>A study on optimal paramter tuning for Rocchio text classifier.</title>
<date>2003</date>
<booktitle>In Proceedings of the European Conference on Information Retrieval,</booktitle>
<location>Pisa, Italy.</location>
<contexts>
<context position="16062" citStr="Moschitti, 2003" startWordPosition="2694" endWordPosition="2695"> was shown to be more effective. Rocchio. This is an adaptation of the relevance feedback method developed in information retrieval (Rocchio, 1971). It uses standard tf.idf weighted vectors to represent documents, and builds a prototype vector for each category by summing up the vectors of the training documents in each category. Test documents are then assigned to the category that has the closest prototype vector, based on a cosine similarity. Text classification experiments with different versions of the Rocchio algorithm showed competitive results on standard benchmarks (Joachims, 1997), (Moschitti, 2003). KNN. K-Nearest Neighbor is one of the earliest text categorization approaches (Makoto and Takenobu, 1995; Masand et al., 1992). The algorithm classifies a test document based on the best class label identified for the nearest K-neighbors in the training documents. The best class label is chosen by weighting the class of each similar training document with its similarity to the target test document. SVM. Support Vector Machines (Vapnik, 1995) is a state-of-the-art machine learning approach based on decision plans. The algorithm defines the best hyper-plan which separates set of points associa</context>
</contexts>
<marker>Moschitti, 2003</marker>
<rawString>A. Moschitti. 2003. A study on optimal paramter tuning for Rocchio text classifier. In Proceedings of the European Conference on Information Retrieval, Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Robertson</author>
<author>K Sparck Jones</author>
</authors>
<title>Simple, proven approaches to text retrieval.</title>
<date>1997</date>
<tech>Technical report.</tech>
<contexts>
<context position="1084" citStr="Robertson and Jones, 1997" startWordPosition="157" endWordPosition="161"> dependencies, resulting in scores that represent a quantification of how a particular word feature contributes to a given context. We argue that by modeling feature weights using these scores, as opposed to the traditional frequency-based scores, we can achieve better results in a text classification task. Experiments performed on four standard classification datasets show that the new random-walk based approach outperforms the traditional term frequency approach to feature weighting. 1 Introduction Term frequency has long been adapted as a measure of term significance in a specific context (Robertson and Jones, 1997). The logic behind it is that the more a certain term is encountered in a certain context, the more it carries or contributes to the meaning of the context. Due to this belief, term frequency has been a major factor in estimating the probabilistic distribution of features using maximum likelihood estimates and hence has been incorporated in a broad spectrum of tasks ranging from feature selec53 tion techniques (Yang and Pedersen, 1997; Schutze et al., 1995) to language models (Bahl et al., 1983). In this paper we introduce a new measure of term weighting, which integrates the locality of a ter</context>
</contexts>
<marker>Robertson, Jones, 1997</marker>
<rawString>R. Robertson and K. Sparck Jones. 1997. Simple, proven approaches to text retrieval. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rocchio</author>
</authors>
<title>Relevance feedback in information retrieval.</title>
<date>1971</date>
<publisher>Prentice Hall,</publisher>
<location>Ing. Englewood Cliffs, New Jersey.</location>
<contexts>
<context position="15593" citStr="Rocchio, 1971" startWordPosition="2625" endWordPosition="2626">bability of a word given a category is assumed to be independent of the conditional probability of other words given the same category. Despite this simplification, Naive Bayes classifiers were shown to perform surprisingly well on text classification (Joachims, 1997), (Schneider, 2004). While there are several versions of Naive Bayes classifiers (variations of multinomial and multivariate Bernoulli), we use the multinomial model (McCallum and Nigam, 1998), which was shown to be more effective. Rocchio. This is an adaptation of the relevance feedback method developed in information retrieval (Rocchio, 1971). It uses standard tf.idf weighted vectors to represent documents, and builds a prototype vector for each category by summing up the vectors of the training documents in each category. Test documents are then assigned to the category that has the closest prototype vector, based on a cosine similarity. Text classification experiments with different versions of the Rocchio algorithm showed competitive results on standard benchmarks (Joachims, 1997), (Moschitti, 2003). KNN. K-Nearest Neighbor is one of the earliest text categorization approaches (Makoto and Takenobu, 1995; Masand et al., 1992). T</context>
</contexts>
<marker>Rocchio, 1971</marker>
<rawString>J. Rocchio, 1971. Relevance feedback in information retrieval. Prentice Hall, Ing. Englewood Cliffs, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Schneider</author>
</authors>
<title>A new feature selection score for multinomial naive bayes text classification based on kl-divergence.</title>
<date>2004</date>
<booktitle>In The Companion Volume to the Proceedings of 42st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Barcelona, Spain,</location>
<contexts>
<context position="15266" citStr="Schneider, 2004" startWordPosition="2576" endWordPosition="2577">rt Vector Machines, selected based on their diversity of learning methodologies. Naive Bayes. The basic idea in a Naive Bayes text classifier is to estimate the probability of a category given a document using joint probabilities of words and documents. Naive Bayes assumes word independence, which means that the conditional probability of a word given a category is assumed to be independent of the conditional probability of other words given the same category. Despite this simplification, Naive Bayes classifiers were shown to perform surprisingly well on text classification (Joachims, 1997), (Schneider, 2004). While there are several versions of Naive Bayes classifiers (variations of multinomial and multivariate Bernoulli), we use the multinomial model (McCallum and Nigam, 1998), which was shown to be more effective. Rocchio. This is an adaptation of the relevance feedback method developed in information retrieval (Rocchio, 1971). It uses standard tf.idf weighted vectors to represent documents, and builds a prototype vector for each category by summing up the vectors of the training documents in each category. Test documents are then assigned to the category that has the closest prototype vector, </context>
</contexts>
<marker>Schneider, 2004</marker>
<rawString>K. Schneider. 2004. A new feature selection score for multinomial naive bayes text classification based on kl-divergence. In The Companion Volume to the Proceedings of 42st Annual Meeting of the Association for Computational Linguistics, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schutze</author>
<author>D A Hull</author>
<author>J O Pedersen</author>
</authors>
<title>A comparison of classifiers and document representations for the routing problem.</title>
<date>1995</date>
<booktitle>In Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<location>Seattle, Washington.</location>
<contexts>
<context position="1545" citStr="Schutze et al., 1995" startWordPosition="239" endWordPosition="242">ch to feature weighting. 1 Introduction Term frequency has long been adapted as a measure of term significance in a specific context (Robertson and Jones, 1997). The logic behind it is that the more a certain term is encountered in a certain context, the more it carries or contributes to the meaning of the context. Due to this belief, term frequency has been a major factor in estimating the probabilistic distribution of features using maximum likelihood estimates and hence has been incorporated in a broad spectrum of tasks ranging from feature selec53 tion techniques (Yang and Pedersen, 1997; Schutze et al., 1995) to language models (Bahl et al., 1983). In this paper we introduce a new measure of term weighting, which integrates the locality of a term and its relation to the surrounding context. We model this local contribution using a co-occurrence relation in which terms that co-occur in a certain context are likely to share between them some of their importance (or significance). Note that in this model the relation between a given term and its context is not linear, since the context itself consists of a collection of other terms, which in turn have a dependency relation with their own context, whi</context>
</contexts>
<marker>Schutze, Hull, Pedersen, 1995</marker>
<rawString>H. Schutze, D. A. Hull, and J. O. Pedersen. 1995. A comparison of classifiers and document representations for the routing problem. In Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer,</publisher>
<location>New York.</location>
<contexts>
<context position="16509" citStr="Vapnik, 1995" startWordPosition="2765" endWordPosition="2766">Text classification experiments with different versions of the Rocchio algorithm showed competitive results on standard benchmarks (Joachims, 1997), (Moschitti, 2003). KNN. K-Nearest Neighbor is one of the earliest text categorization approaches (Makoto and Takenobu, 1995; Masand et al., 1992). The algorithm classifies a test document based on the best class label identified for the nearest K-neighbors in the training documents. The best class label is chosen by weighting the class of each similar training document with its similarity to the target test document. SVM. Support Vector Machines (Vapnik, 1995) is a state-of-the-art machine learning approach based on decision plans. The algorithm defines the best hyper-plan which separates set of points associated with different class labels with a maximum-margin. The unlabeled examples are then classified by deciding in which side of the hyper-surface they reside. The hyper-plan can be a simple linear plan as first proposed by Vapnik, or a non-linear plan such as e.g. polynomial, radial, or sigmoid. In our evaluation we used the linear kernel since it was proved to be as powerful as the other kernels when tested on text classification data sets (Ya</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>V. Vapnik. 1995. The Nature of Statistical Learning Theory. Springer, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Yang</author>
<author>X Liu</author>
</authors>
<title>A reexamination of text categorization methods.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd ACM SIGIR Conference on Research and Development in Information Retrieval.</booktitle>
<contexts>
<context position="17126" citStr="Yang and Liu, 1999" startWordPosition="2866" endWordPosition="2869">5) is a state-of-the-art machine learning approach based on decision plans. The algorithm defines the best hyper-plan which separates set of points associated with different class labels with a maximum-margin. The unlabeled examples are then classified by deciding in which side of the hyper-surface they reside. The hyper-plan can be a simple linear plan as first proposed by Vapnik, or a non-linear plan such as e.g. polynomial, radial, or sigmoid. In our evaluation we used the linear kernel since it was proved to be as powerful as the other kernels when tested on text classification data sets (Yang and Liu, 1999). 4.3 Data Sets In our experiments we use Reuters-21578, WebKB, 20Newsgroups, and Ling5pam datasets. These datasets are commonly used for text classification evaluations (Joachims, 1996; Craven et al., 1998; Androutsopoulos et al., 2000; Mihalcea and Hassan, 2005). Reuter-21578. This is a publicly available subset of the Reuters news, containing about 120 categories. We use the standard ModApte data split (Apte et al., 1994). The unlabeled documents were discarded and only the documents with one or more class labels were used in the classification experiments. WebKB. This is a data set collect</context>
</contexts>
<marker>Yang, Liu, 1999</marker>
<rawString>Y. Yang and X. Liu. 1999. A reexamination of text categorization methods. In Proceedings of the 22nd ACM SIGIR Conference on Research and Development in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Yang</author>
<author>J O Pedersen</author>
</authors>
<title>A comparative study on feature selection in text categorization.</title>
<date>1997</date>
<booktitle>In Proceedings of the 14th International Conference on Machine Learning,</booktitle>
<location>Nashville, US.</location>
<contexts>
<context position="1522" citStr="Yang and Pedersen, 1997" startWordPosition="235" endWordPosition="238">nal term frequency approach to feature weighting. 1 Introduction Term frequency has long been adapted as a measure of term significance in a specific context (Robertson and Jones, 1997). The logic behind it is that the more a certain term is encountered in a certain context, the more it carries or contributes to the meaning of the context. Due to this belief, term frequency has been a major factor in estimating the probabilistic distribution of features using maximum likelihood estimates and hence has been incorporated in a broad spectrum of tasks ranging from feature selec53 tion techniques (Yang and Pedersen, 1997; Schutze et al., 1995) to language models (Bahl et al., 1983). In this paper we introduce a new measure of term weighting, which integrates the locality of a term and its relation to the surrounding context. We model this local contribution using a co-occurrence relation in which terms that co-occur in a certain context are likely to share between them some of their importance (or significance). Note that in this model the relation between a given term and its context is not linear, since the context itself consists of a collection of other terms, which in turn have a dependency relation with</context>
</contexts>
<marker>Yang, Pedersen, 1997</marker>
<rawString>Y. Yang and J. O. Pedersen. 1997. A comparative study on feature selection in text categorization. In Proceedings of the 14th International Conference on Machine Learning, Nashville, US.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>