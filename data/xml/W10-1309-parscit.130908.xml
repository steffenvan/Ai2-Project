<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.054896">
<title confidence="0.934690571428571">
Workshop on Speech and Language Processing for Assistive Technologies
Demo Session
1 “How was School today...?” A Prototype
System that Uses Environmental Sensors
and NLG to Support Personal Narrative
for Children with Complex
Communication Needs
</title>
<author confidence="0.7027485">
Rolf Black, Joseph Reddington, Ehud Reiter, Nava
Tintarev and Annalu Waller
</author>
<bodyText confidence="0.999919222222222">
We will show an in-situ sensor based proto-
type that supports personal narrative for children
with complex communication needs. We will
demonstrate the process from data collection, story
generation and editing, to the interactive narration
of stories about a child’s school day. The challeng-
ing environment of a special school for prototype
testing will be discussed and improvements of the
next generation prototype presented.
</bodyText>
<sectionHeader confidence="0.983964" genericHeader="method">
2 Interactive SIGHT Demo: Textual
</sectionHeader>
<subsectionHeader confidence="0.946587">
Summaries of Simple Bar Charts
</subsectionHeader>
<bodyText confidence="0.990961818181818">
Seniz Demir, David Oliver, Edward Schwartz,
Stephanie Elzer, Sandra Carberry and Kathleen F.
McCoy
Interactive SIGHT is intended to provide peo-
ple with visual impairments access to the kind
of information graphics found in popular media.
It works as a browser extension, and is able to
generate a summary of a simple bar chart containing
its high-level intention as natural language text.
The user may request further information about the
graphic through a follow-up question facility.
</bodyText>
<sectionHeader confidence="0.969545" genericHeader="method">
3 Project Jumbo: Transcription as an
Assistive Technology for Instant
Messaging
</sectionHeader>
<bodyText confidence="0.9743516">
Ira R. Forman and Allen K. Wilson
The integration of VoIP into Instant Messaging
may be a boon for most of us, but not for those
who are deaf and hard of hearing. The IBM Human
Ability &amp; Accessibility Center initiated Project
Jumbo to address this problem. Our remedy is to
add a speech-to-text capability to augment voice
services with transcripts. In particular, Project
Jumbo augments IBM Lotus Sametime. Project
Jumbo, which is transitioning to product status
under name IBM AbilityLab Sametime Conference
Transcriber, will be demonstrated. The demo
consists of a chat between the demonstrator and a
remote colleague in which the demonstrator speaks
rather than types. A major point of the demo is
that interactive communication is a new domain
for ASR. This domain differs from dictation in a
number of ways; prominent among them is that
most speech recognition errors do not need to be
corrected.
</bodyText>
<sectionHeader confidence="0.992521" genericHeader="method">
4 COMUNICA - A Voice Question
Answering System for Portuguese
</sectionHeader>
<bodyText confidence="0.926883181818182">
Rodrigo Wilkens, Aline Villavicencio, Leandro
Wives, Daniel Muller, Fabio da Silva and Stanley
Loh
This is a voice QA system for Brazilian Por-
tuguese that performs speech recognition, text
processing, database access and speech synthesis
for consulting both structured and unstructured
datasets. This system provides multi-modal com-
munication and has the potential to help users with
disabilities to access relevant information, and may
help to significantly increase digital inclusion.
</bodyText>
<page confidence="0.97424">
71
</page>
<reference confidence="0.6419555">
Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies, page 71,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001921">
<title confidence="0.991749">Workshop on Speech and Language Processing for Assistive Technologies</title>
<author confidence="0.839667">Demo Session</author>
<note confidence="0.534191">1 “How was School today...?” A Prototype</note>
<title confidence="0.97691375">System that Uses Environmental Sensors and NLG to Support Personal Narrative for Children with Complex Communication Needs</title>
<author confidence="0.991277">Rolf Black</author>
<author confidence="0.991277">Joseph Reddington</author>
<author confidence="0.991277">Ehud Reiter</author>
<author confidence="0.991277">Nava</author>
<abstract confidence="0.800845608695652">Tintarev and Annalu Waller We will show an in-situ sensor based prototype that supports personal narrative for children with complex communication needs. We will demonstrate the process from data collection, story generation and editing, to the interactive narration of stories about a child’s school day. The challenging environment of a special school for prototype testing will be discussed and improvements of the next generation prototype presented. 2 Interactive SIGHT Demo: Textual Summaries of Simple Bar Charts Seniz Demir, David Oliver, Edward Schwartz, Stephanie Elzer, Sandra Carberry and Kathleen F. McCoy Interactive SIGHT is intended to provide people with visual impairments access to the kind of information graphics found in popular media. It works as a browser extension, and is able to generate a summary of a simple bar chart containing its high-level intention as natural language text. The user may request further information about the graphic through a follow-up question facility.</abstract>
<note confidence="0.481418">3 Project Jumbo: Transcription as an</note>
<title confidence="0.968046">Assistive Technology for Instant Messaging</title>
<author confidence="0.998">Ira R Forman</author>
<author confidence="0.998">Allen K Wilson</author>
<abstract confidence="0.975868315789474">The integration of VoIP into Instant Messaging may be a boon for most of us, but not for those who are deaf and hard of hearing. The IBM Human Ability &amp; Accessibility Center initiated Project Jumbo to address this problem. Our remedy is to add a speech-to-text capability to augment voice services with transcripts. In particular, Project Jumbo augments IBM Lotus Sametime. Project Jumbo, which is transitioning to product status under name IBM AbilityLab Sametime Conference Transcriber, will be demonstrated. The demo consists of a chat between the demonstrator and a remote colleague in which the demonstrator speaks rather than types. A major point of the demo is that interactive communication is a new domain for ASR. This domain differs from dictation in a number of ways; prominent among them is that most speech recognition errors do not need to be corrected.</abstract>
<title confidence="0.919305">4 COMUNICA - A Voice Question Answering System for Portuguese</title>
<author confidence="0.996369">Rodrigo Wilkens</author>
<author confidence="0.996369">Aline Villavicencio</author>
<author confidence="0.996369">Leandro</author>
<affiliation confidence="0.810685">Wives, Daniel Muller, Fabio da Silva and Stanley</affiliation>
<abstract confidence="0.935809111111111">Loh This is a voice QA system for Brazilian Portuguese that performs speech recognition, text processing, database access and speech synthesis for consulting both structured and unstructured datasets. This system provides multi-modal communication and has the potential to help users with disabilities to access relevant information, and may help to significantly increase digital inclusion.</abstract>
<note confidence="0.889819666666667">71 of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive page Angeles, California, June 2010. Association for Computational Linguistics</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>2010</date>
<booktitle>Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies,</booktitle>
<pages>71</pages>
<location>Los Angeles, California,</location>
<marker>2010</marker>
<rawString>Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies, page 71, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>