<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000014">
<title confidence="0.9942175">
Analysis System of Speech Acts and Discourse Structures Using
Maximum Entropy Model.
</title>
<author confidence="0.980705">
Won Seug Choi, Jeong-Mi Cho and Jungyun Seo
</author>
<affiliation confidence="0.994871">
Dept. of Computer Science, Sogang University
</affiliation>
<address confidence="0.932454">
Sinsu-dong 1, Mapo-gu
Seoul, Korea, 121-742
</address>
<email confidence="0.950294">
dolhana, jmcho } @nlprep.sogang.ac.kr, seojy @ccs.sogang.ac.kr
</email>
<sectionHeader confidence="0.993207" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989833333334">
We propose a statistical dialogue analysis
model to determine discourse structures as
well as speech acts using maximum entropy
model. The model can automatically acquire
probabilistic discourse knowledge from a
discourse tagged corpus to resolve
ambiguities. We propose the idea of tagging
discourse segment boundaries to represent
the structural information of discourse.
Using this representation we can effectively
combine speech act analysis and discourse
structure analysis in one framework.
</bodyText>
<sectionHeader confidence="0.959583" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999881736842105">
To understand a natural language dialogue, a
computer system must be sensitive to the
speaker&apos;s intentions indicated through utterances.
Since identifying the speech acts of utterances is
very important to identify speaker&apos;s intentions, it
is an essential part of a dialogue analysis system.
It is difficult, however, to infer the speech act
from a surface utterance since an utterance may
represent more than one speech act according to
the context. Most works done in the past on the
dialogue analysis has analyzed speech acts based
on knowledge such as recipes for plan inference
and domain specific knowledge (Litman (1987),
Caberry (1989), Hinkelman (1990), Lambert
(1991), Lambert (1993), Lee (1998)). Since
these knowledge-based models depend on costly
hand-crafted knowledge, these models are
difficult to be scaled up and expanded to other
domains.
</bodyText>
<footnote confidence="0.906047">
* This work was supported by KOSEF under the
contract 97-0102-0301-3.
</footnote>
<bodyText confidence="0.999393783783784">
Recently, machine learning models using a
discourse tagged corpus are utilized to analyze
speech acts in order to overcome such problems
(Nagata (1994a), Nagata (1994b), Reithinger
(1997), Lee (1997), Samuel (1998)). Machine
learning offers promise as a means of
associating features of utterances with particular
speech acts, since computers can automatically
analyze large quantities of data and consider
many different feature interactions. These
models are based on the features such as cue
phrases, change of speaker, short utterances,
utterance length, speech acts tag n-grams, and
word n-grams, etc. Especially, in many cases,
the speech act of an utterance influenced by the
context of the utterance, i.e., previous utterances.
So it is very important to reflect the information
about the context to the model.
Discourse structures of dialogues are usually
represented as hierarchical structures, which
reflect embedding sub-dialogues (Grosz (1986))
and provide very useful context for speech act
analysis. For example, utterance 7 in Figure 1
has several surface speech acts such as
acknowledge, inform, and response. Such an
ambiguity can be solved by analyzing the
context. If we consider the n utterances linearly
adjacent to utterance 7, i.e., utterances 6, 5, etc.,
as context, we will get acknowledge or inform
with high probabilities as the speech act of
utterance 7. However, as shown in Figure 1,
utterance 7 is a response utterance to utterance 2
that is hierarchically recent to utterance 7
according to the discourse structure of the
dialogue. If we know the discourse structure of
the dialogue, we can determine the speech act of
utterance 7 as response.
</bodyText>
<page confidence="0.98912">
230
</page>
<bodyText confidence="0.975927916666667">
Some researchers have used the structural
information of discourse to the speech act
analysis (Lee (1997), Lee (1998)). It is not,
however, enough to cover various dialogues
since they used a restricted rule-based model
such as RDTN (Recursive Dialogue Transition
Networks) for discourse structure analysis. Most
of the previous related works, to our knowledge,
tried to determine the speech act of an utterance,
but did not mention about statistical models to
determine the discourse structure of a dialogue.
DUser I would like to reserve a room. request
</bodyText>
<listItem confidence="0.99067275">
2) Agent : What kind of room do you want? ask-ref
3) User : What kind of room do you have? ask-ref
4) Agent We have single and double rooms. response
5) User: How much are those rooms? ask-ref
6) Agent Single coos 30,000 won and double costs 40,000 won. response
acknowledge
7) User: A single room, please. inform
re_spj_inse
</listItem>
<figureCaption confidence="0.986912">
Figure I: An example of a dialogue with speech acts
</figureCaption>
<bodyText confidence="0.999984590909091">
In this paper, we propose a dialogue analysis
model to determine both the speech acts of
utterances and the discourse structure of a
dialogue using maximum entropy model. In the
proposed model, the speech act analysis and the
discourse structure analysis are combined in one
framework so that they can easily provide
feedback to each other. For the discourse
structure analysis, we suggest a statistical model
with discourse segment boundaries (DSBs)
similar to the idea of gaps suggested for a
statistical parsing (Collins (1996)). For training,
we use a corpus tagged with various discourse
knowledge. To overcome the problem of data
sparseness, which is common for corpus-based
works, we use split partial context as well as
whole context.
After explaining the tagged dialogue corpus we
used in section 1, we discuss the statistical
models in detail in section 2. In section 3, we
explain experimental results. Finally, we
conclude in section 4.
</bodyText>
<sectionHeader confidence="0.926368" genericHeader="method">
1 Discourse tagging
</sectionHeader>
<bodyText confidence="0.994376">
In this paper, we use Korean dialogue corpus
transcribed from recordings in real fields such as
hotel reservation, airline reservation and tour
reservation. This corpus consists of 528
dialogues, 10,285 utterances (19.48 utterances
per dialogue). Each utterance in dialogues is
manually annotated with discourse knowledge
such as speaker (SP), syntactic pattern (ST),
speech acts (SA) and discourse structure (DS)
information. Figure 2 shows a part of the
annotated dialogue corpus&apos;. SP has a value
either &amp;quot;User&amp;quot; or &amp;quot;Agent&amp;quot; depending on the
speaker.
</bodyText>
<figureCaption confidence="0.998276">
Figure 2: A part of the annotated dialogue corpus
</figureCaption>
<bodyText confidence="0.971098482758621">
The syntactic pattern consists of the selected
syntactic features of an utterance, which
approximate the utterance. In a real dialogue, a
speaker can express identical contents with
different surface utterances according to a
personal linguistic sense. The syntactic pattern
generalizes these surface utterances using
syntactic features. The syntactic pattern used in
(Lee (1997)) consists of four syntactic features
such as Sentence Type, Main-Verb, Aux-Verb
and Clue-Word because these features provide
strong cues to infer speech acts. We add two
more syntactic features, Tense and Negative
Sentence, to the syntactic pattern and elaborate
the values of the syntactic features. Table 1
shows the syntactic features of a syntactic
pattern with possible values. The syntactic
features are automatically extracted from the
corpus using a conventional parser (Kim
(1994)).
Manual tagging of speech acts and discourse
structure information was done by graduate
students majoring in dialogue analysis and post-
processed for consistency. The classification of
speech acts is very subjective without an agreed
criterion. In this paper, we classified the 17
types of speech acts that appear in the dialogue
&apos; KS represents the Korean sentence and EN
represents the translated English sentence.
</bodyText>
<figure confidence="0.97516246875">
/SP/User
/KS/°] 0i0t&apos;ZE.yr-.11 1171- &apos;111
ttAg °,1
/EN/I&apos;m a student and registered for a
language course at University of Georgia in
U.S.
/ST/ldecl,be,presentno,none,none]
/SA/introducing-oneself
/DS/[2]
/SP/ User
/KS/ 4,=21--1 uJn 0&gt;0&gt;0&gt; 400]al01
.0-.
/EN/1 have some questions about lodgings.
/ST/Idecl,paa,present,no,none,none]
/SA/ask-ref
/DS/[2]
-4 Continue
/SP/Agent
/ICS/r&amp;quot;ftAt ttP-i 0;714-- 401-
71 A&amp;quot; A13-&apos; tt a 91-1.i q
/EN/There is a dormitory in University Cl
Georgia for language course students.
/ST/[deapvg,present,no,nonenonel
/SA/response
/DS/[2]
/SP/User
/KS/ 0&gt;]0&gt;5ril=u1.11 0101
010&gt;
/EN/Then, is meal included in tuition fee?
/ST/[yn_quest.pvg,presentno,none,thent
ISA/ask-if
/DS/12.1]
</figure>
<page confidence="0.989033">
231
</page>
<bodyText confidence="0.970229142857143">
corpus. Table 2 shows the distribution of speech
acts in the tagged dialogue corpus.
Discourse structures are determined by focusing
on the subject of current dialogue and are
hierarchically constructed according to the
subject. Discourse structure information tagged
in the corpus is an index that represents the
hierarchical structure of discourse reflecting the
depth of the indentation of discourse segments.
The proposed system transforms this index
information to discourse segment boundary
(DSB) information to acquire various statistical
information. In section 2.2.1, we will describe
the DSBs in detail.
</bodyText>
<table confidence="0.948558307692308">
Syntactic feature Values Notes
Sentence Type decl, imperative, The mood of an utterance
wh_question, yn_question
Main-Verb pvg, pvd, paa, pad, be, The type of the main verb. For
know, ask, etc. special verbs, lexical items are
(total 88 kinds) used.
Tense past, present, future. The tense of an utterance
Negative Sentence Yes or No Yes if an utterance is negative.
Aux-Verb serve, seem, want, will, The modality of an utterance.
etc. (total 31 kinds)
Clue-Ward Yes, No, OK., etc. The special word used in the
(total 26 kinds) utterance having particular
speech acts.
</table>
<tableCaption confidence="0.962063">
Table I: Syntactic features used in the syntactic pattern
</tableCaption>
<table confidence="0.9998778">
Speech Act Type Ratio(%) Speech Act Type Ratio(%)
Accept 2.49 Introducing-oneself 6.75
Acknowledge 5.75 Offer 0.40
Ask-confirm 3.16 Opening 6.58
Ask-if 5.36 Promise 2.42
Ask-ref 13.39 Reject 1.07
Closing 3.39 Request 4.96
Correct 0.03 Response 24.73
Expressive 5.64 Suggest 1.98
Worm 11.90 Total 100.00
</table>
<tableCaption confidence="0.999649">
Table 2: The distributio of speech acts in corpus
</tableCaption>
<sectionHeader confidence="0.954317" genericHeader="method">
2 Statistical models
</sectionHeader>
<bodyText confidence="0.9999518">
We construct two statistical models: one for
speech act analysis and the other for discourse
structure analysis. We integrate the two models
using maximum entropy model. In the following
subsections, we describe these models in detail.
</bodyText>
<subsectionHeader confidence="0.996724">
2.1 Speech act analysis model
</subsectionHeader>
<bodyText confidence="0.984502875">
Let Ui, ,, denote a dialogue which consists of a
sequence of n utterances, Ui, U2,..., Un, and let
S, denote the speech act of U. With these
notations, P(S, IU 1, ,) means the probability
that Si becomes the speech act of utterance U,
given a sequence of utterances Ui, U2,..., U.
We can approximate the probability
P(S, I Ui. ,) by the product of the sentential
</bodyText>
<equation confidence="0.9525844">
probability P(U, I Si) and the contextual
probability P(S, IU - 1, S 1, , -i). Also we can
approximate P(S, IU 1, - 1, S 1, - i) by
P(S, I Si, i - i) (Chamiak (1993)).
P(Si I Ui,) P(Si I Si,- i)P(Ui I Si) (1)
</equation>
<bodyText confidence="0.994437615384616">
It has been widely believed that there is a strong
relation between the speaker&apos;s speech act and
the surface utterances expressing that speech act
(Hinkelman (1989), Andernach (1996)). That is,
the speaker utters a sentence, which most well
expresses his/her intention (speech act) so that
the hearer can easily infer what the speaker&apos;s
speech act is. The sentential probability
P(U, I Si) represents the relationship between
the speech acts and the features of surface
sentences. Therefore, we approximate the
sentential probability using the syntactic pattern
P,.
</bodyText>
<equation confidence="0.699992">
P(U; I Si) P(Pi I Si) (2)
</equation>
<bodyText confidence="0.8842415">
The contextual probability P(S, I Si, - 1) is the
probability that utterance with speech act S, is
uttered given that utterances with speech act
Si, S2,..., S, - I were previously uttered. Since it
is impossible to consider all preceding
utterances Si, S2,..., S, - i as contextual
information, we use the n-gram model.
Generally, dialogues have a hierarchical
discourse structure. So we approximate the
context as speech acts of n utterances that are
hierarchically recent to the utterance. An
utterance A is hierarchically recent to an
utterance B if A is adjacent to B in the tree
structure of the discourse (Walker (1996)).
Equation (3) represents the approximated
contextual probability in the case of using
</bodyText>
<footnote confidence="0.754218">
trigram where and Ilk are hierarchically
recent to the utterance U,, where
1 jk5A-1.
</footnote>
<page confidence="0.902151">
232
</page>
<equation confidence="0.915623">
P(Si I i -1) P(Si I SJ, Sk) (3)
</equation>
<bodyText confidence="0.9635815">
As a result, the statistical model for speech act
analysis is represented in equation (4).
</bodyText>
<equation confidence="0.905261">
P(Si I U &gt;) P(Si I Si, - OP(Ui I Si) (4)
P(Si I Si, Sk)P(Pi I Si)
</equation>
<subsectionHeader confidence="0.997059">
2.2 Discourse structure analysis model
</subsectionHeader>
<subsubsectionHeader confidence="0.997734">
2.2.1 Discourse segment boundary tagging
</subsubsectionHeader>
<bodyText confidence="0.993969428571429">
We define a set of discourse segment boundaries
(DSBs) as the markers for discourse structure
tagging. A DSB represents the relationship
between two consecutive utterances in a
dialogue. Table 3 shows DSBs and their
meanings, and Figure 3 shows an example of
DSB tagged dialogue.
</bodyText>
<table confidence="0.997947666666667">
DSB Meaning
DE Start a new dialogue
DC Continue a dialogue
SS Start a sub-dialogue
nE End n level sub-dialogues
nB nE and then SS
</table>
<tableCaption confidence="0.994955">
Table 3: DSBs and their meanings
</tableCaption>
<listItem confidence="0.885645375">
I) User I would like to reserve a room. DS DSB
2) Agent : What kind of room do you want? NULL
3) User : What kind of room do you have? 1.1 SS
4) Agent : We have single and double rooms. 1.1.1 SS
5) User; How much are those rooms? 1.1.1 DC
6) Agent Single costs 30,000 won and double costs 40,000 won. 1.1.2 IB
7) User : A single room, please. 1.1.2 DC
1.1 1E
</listItem>
<figureCaption confidence="0.996917">
Figure 3: An example of DSB tagging
</figureCaption>
<bodyText confidence="0.998357">
Since the DSB of an utterance represents a
relationship between the utterance and the
previous utterance, the DSB of utterance 1 in the
example dialogue becomes NULL. By
comparing utterance 2 with utterance 1 in Figure
3, we know that a new sub-dialogue starts at
utterance 2. Therefore the DSB of utterance 2
becomes SS. Similarly, the DSB of utterance 3
is SS. Since utterance 4 is a response for
utterance 3, utterance 3 and 4 belong to the same
discourse segment. So the DSB of utterance 4
becomes DC. Since a sub-dialogue of one level
(i.e., the DS 1.1.2) consisting of utterances 3 and
4 ends, and new sub-dialogue starts at utterance
5. Therefore, the DSB of utterance 5 becomes
1B. Finally, utterance 7 is a response for
utterance 2, i.e., the sub-dialogue consisting of
utterances 5 and 6 ends and the segment 1.1 is
resumed. Therefore the DSB of utterance 7
becomes 1E.
</bodyText>
<subsubsectionHeader confidence="0.9926625">
2.2.2 Statistical model for discourse structure
analysis
</subsubsectionHeader>
<bodyText confidence="0.981703117647059">
We construct a statistical model for discourse
structure analysis using DSBs. In the training
phase, the model transforms discourse structure
(DS) information in the corpus into DSBs by
comparing the DS information of an utterance
with that of the previous utterance. After
transformation, we estimate probabilities for
DSBs. In the analyzing process, the goal of the
system is simply determining the DSB of a
current utterance using the probabilities. Now
we describe the model in detail.
Let G. denote the DSB of U. With this notation,
P(G, I U Li) means the probability that G,
becomes the DSB of utterance U, given a
sequence of utterances U 1, U 2, , . As shown
in the equation (5), we can approximate
P(Gi I U 1, ,) by the product of the sentential
</bodyText>
<equation confidence="0.86139625">
probability P(U, I GO and the contextual
probability P(G, I U 1, i - 1, GI, , -1):
P(Gi I U i)
P(Gi I U - - i)P(Ui I Gi)
</equation>
<bodyText confidence="0.984985">
In order to analyze discourse structure, we
consider the speech act of each corresponding
utterance. Thus we can approximate each
utterance by the corresponding speech act in the
sentential probability P(11, I G):
</bodyText>
<equation confidence="0.938533">
P(Ui I Gi) ne P(Si I Gi) (6)
(5)
</equation>
<page confidence="0.838059">
233
</page>
<bodyText confidence="0.739875">
Let F, be a pair of the speech act and DSB of U,
to simplify notations:
</bodyText>
<equation confidence="0.9954625">
F (7)
We can approximate the contextual probability
P(Gi I U 1, - 1, GI, -1) as equation (8) in the
case of using trigram.
P(Gi I U -1,GLi -1)
P(Gi I F - P(Gi I F - 2,Fi - (8)
</equation>
<bodyText confidence="0.993713333333333">
As a result, the statistical model for the
discourse structure analysis is represented as
equation (9).
</bodyText>
<equation confidence="0.999233666666667">
P(Gi Li)
P(G I Ui,1 - i, Gt, -1)P(Ui (9)
P(Gi I F - 2, - i)P(Si I Gi)
</equation>
<bodyText confidence="0.940212285714286">
2.3 Integrated dialogue analysis model
Given a dialogue Ui, n, P(Si, a I U1, i) means
the probability that S, and G, will be,
respectively, the speech act and the DSB of an
utterance U, given a sequence of utterances
Ul,U2,...,U,. By using a chain rule, we can
rewrite the probability as in equation (10).
</bodyText>
<equation confidence="0.9974355">
P(Si,Gi I U
P(Si I I 11, i)P(Gi I Si,U1,i) (10)
</equation>
<bodyText confidence="0.999991181818182">
In the right hand side (RHS) of equation (10),
the first term is equal to the speech act analysis
model shown in section 2.1. The second term
can be approximated as the discourse structure
analysis model shown in section 2.2 because the
discourse structure analysis model is formulated
by considering utterances and speech acts
together. Finally the integrated dialogue analysis
model can be formulated as the product of the
speech act analysis model and the discourse
structure analysis model:
</bodyText>
<equation confidence="0.98487425">
P(Si,Gi I Ui,i)
P(Si ILI i)P(Gi I U
P(Si I Si, Sk)P(Pi I Si)
x P(Gi I F - 2, Fi -1)P(Si I Gi)
</equation>
<subsectionHeader confidence="0.9884">
2.4 Maximum entropy model
</subsectionHeader>
<bodyText confidence="0.999963">
All terms in RHS of equation (11) are
represented by conditional probabilities. We
estimate the probability of each term using the
following representative equation:
</bodyText>
<equation confidence="0.999271">
P(a,b)
P(a I b) =
</equation>
<bodyText confidence="0.866232333333333">
We can evaluate P(a,b) using maximum
entropy model shown in equation (13) (Reynar
1997).
</bodyText>
<equation confidence="0.981629">
P(a,b). 7cHaima,b) (13)
</equation>
<bodyText confidence="0.999932866666667">
where 0 &lt; &lt;o0, i = {1,2,..., k}
In equation (13), a is either a speech act or a
DSB depending on the term, b is the context (or
history) of a, jr is a normalization constant, and
a, is the model parameter corresponding to each
feature function!.
In this paper, we use two feature functions:
unified feature function and separated feature
function. The former uses the whole context b as
shown in equation (12), and the latter uses
partial context split-up from the whole context
to cope with data sparseness problems. Equation
(14) and (15) show examples of these feature
functions for estimating the sentential
probability of the speech act analysis model.
</bodyText>
<equation confidence="0.688414066666667">
iff a = response and (14)
b = User: [decl, pvd, future, no, will, then]
otherwise
iff a = response and (15)
SentenceType(b) = User : decl
otherwise
Equation (14) represents a unified feature
function constructed with a syntactic pattern
P(a&apos; ,b)
a&apos;
(12)
f (a, b) ={1
0
f (a, b) ={1
0
</equation>
<page confidence="0.994556">
234
</page>
<bodyText confidence="0.999985833333334">
having all syntactic features, and equation (15)
represents a separated feature function
constructed with only one feature, named
Sentence Type, among all syntactic features in
the pattern. The interpretation of the unified
feature function shown in equation (14) is that if
the current utterance is uttered by &amp;quot;User&amp;quot;, the
syntactic pattern of the utterance is
[decl,pvd,future,no,will,then] and the speech act
of the current utterance is response then f(a,b)=1
else f(a,b)=0. We can construct five more
separated feature functions using the other
syntactic features. The feature functions for the
contextual probability can be constructed in
similar ways as the sentential probability. Those
are unified feature functions with feature
trigrams and separated feature functions with
distance-1 bigrams and distance-2 bigrams.
Equation (16) shows an example of an unified
feature function, and equation (17) and (18)
which are delivered by separating the condition
of b in equation (16) show examples of
separated feature functions for the contextual
probability of the speech act analysis model.
</bodyText>
<equation confidence="0.984509">
{
1 iff a = response and
f (a,b)= b = User : request, Agent: ask — ref
</equation>
<bodyText confidence="0.91557075">
o otherwise
where b is the information of (hand Uk
defined in equation (3)
{iff a = response and
</bodyText>
<equation confidence="0.9055">
, 1
f (a, b) = b1 = Agent : ask — ref
</equation>
<bodyText confidence="0.85777">
o otherwise
where b _ is the information of (Jo defined in equation (3)
</bodyText>
<equation confidence="0.772761">
f (a,b)=
0 otherwise
where b, is the information of Uidefined in equation (3)
</equation>
<bodyText confidence="0.9999578">
Similarly, we can construct feature functions for
the discourse structure analysis model. For the
sentential probability of the discourse structure
analysis model, the unified feature function is
identical to the separated feature function since
the whole context includes only a speech act.
Using the separated feature functions, we can
solve the data sparseness problem when there
are not enough training examples to which the
unified feature function is applicable.
</bodyText>
<sectionHeader confidence="0.963671" genericHeader="evaluation">
3 Experiments and results
</sectionHeader>
<bodyText confidence="0.999918">
In order to experiment the proposed model, we
used the tagged corpus shown in section 1. The
corpus is divided into the training corpus with
428 dialogues, 8,349 utterances (19.51
utterances per dialogue), and the testing corpus
with 100 dialogues, 1,936 utterances (19.36
utterances per dialogue). Using the Maximum
Entropy Modeling Toolkit (Ristad 1996), we
estimated the model parameter a, corresponding
to each feature function f, in equation (13).
We made experiments with two models for each
analysis model. Model-I uses only the unified
feature function, and Model-II uses the unified
feature function and the separated feature
function together. Among the ways to combine
the unified feature function with the separated
feature function, we choose the combination in
which the separated feature function is used only
when there is no training example applicable for
the unified feature function.
First, we tested the speech act analysis model
and the discourse analysis model. Table 4 and 5
show the results for each analysis model. The
results shown in table 4 are obtained by using
the correct structural information of discourse,
i.e., DSB, as marked in the tagged corpus.
Similarly those in table 5 are obtained by using
the correct speech act information from the
tagged corpus.
</bodyText>
<table confidence="0.998500142857143">
Accuracy (Closed test) Accuracy (Open test)
Candidates Top-1 Top-3 Top-1 Top-3
Lee (1997) 78.59% 97.88%
Samuel (1998) 73.17%
Reithinger (1997) 74.70%
Model I 90.65% 99.66% 81.61% 93.18%
Model II 90.65% 99.66% 83.37% 95.35%
</table>
<tableCaption confidence="0.858083">
Tabl 4. Results of speech act analysis
</tableCaption>
<table confidence="0.99926075">
Accuracy(Open test)
Candidates Top-I Top-3
Model 1 81.51% 98.55%
Model II 83.21% 99.02%
</table>
<tableCaption confidence="0.999791">
Table 5. Results of discourse structure analysis
</tableCaption>
<bodyText confidence="0.995513714285714">
In the closed test in table 4, the results of Model-
1 and Model-II are the same since the
probabilities of the unified feature functions
always exist in this case. As shown in table 4,
the proposed models show better results than
previous work, Lee (1997). As shown in table 4
and 5, Model-II shows better results than Model-
</bodyText>
<equation confidence="0.687039">
{1 iff a = response; and b_2 = User: request (18)
</equation>
<page confidence="0.991909">
235
</page>
<bodyText confidence="0.999874448275862">
I in all cases. We believe that the separated
feature functions are effective for the data
sparseness problem. In the open test in table 4, it
is difficult to compare the proposed model
directly with the previous works like Samuel
(1998) and Reithinger (1997) because test data
used in those works consists of English
dialogues while we use Korean dialogues.
Furthermore the speech acts used in the
experiments are different. We will test our
model using the same data with the same speech
acts as used in those works in the future work.
We tested the integrated dialogue analysis model
in which speech act and discourse structure
analysis models are integrated. The integrated
model uses Model-II for each analysis model
because it showed better performance. In this
model, after the system determing the speech act
and DSB of an utterance, it uses the results to
process the next utterance, recursively. The
experimental results are shown in table 6.
As shown in table 6, the results of the integrated
model are worse than the results of each analysis
model. For top-1 candidate, the performance of
the speech act analysis fell off about 2.89% and
that of the discourse structure analysis about
7.07%. Nevertheless, the integrated model still
shows better performance than previous work in
the speech act analysis.
</bodyText>
<table confidence="0.9956955">
Accuracy(Open test)
Candidates Top-1 Top-3
Result of speech act 80.48% 94.58%
analysis
Result of discourse 76.14% 95.45%
structure analysis
</table>
<tableCaption confidence="0.984985">
Table 6. Results of the integrated analysis model
</tableCaption>
<sectionHeader confidence="0.936973" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.99995205">
In this paper, we propose a statistical dialogue
analysis model which can perform both speech
act analysis and discourse structure analysis
using maximum entropy model. The model can
automatically acquire discourse knowledge from
a discourse tagged corpus to resolve ambiguities.
We defined the DSBs to represent the structural
relationship of discourse between two
consecutive utterances in a dialogue and used
them for statistically analyzing both the speech
act of an utterance and the discourse structure of
a dialogue. By using the separated feature
functions together with the unified feature
functions, we could alleviate the data sparseness
problems to improve the system performance.
The model can, we believe, analyze dialogues
more effectively than other previous works
because it manages speech act analysis and
discourse structure analysis at the same time
using the same framework.
</bodyText>
<sectionHeader confidence="0.994732" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9995295">
Authors are grateful to the anonymous reviewer
for their valuable comments on this paper.
Without their comments, we may miss important
mistakes made in the original draft.
</bodyText>
<sectionHeader confidence="0.998788" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99910178125">
Andernach, T. 1996. A Machine Learning Approach
to the Classification of Dialogue Utterances.
Proceedings of NeMLaP-2.
Berger, Adam L., Stephen A. Della Pietra, and
Vincent J. Della Pietra. 1996. A Maximum Entropy
Approach to Natural Language Processing.
Computational Linguistics, 22(1):39-71.
Caberry, Sandra. 1989. A Pragmatics-Based
Approach to Ellipsis Resolution. Computational
Linguistics, 15(2):75-96.
Carniak, Eugene. 1993. Statistical Language
Learning. A Bradford Book, The MIT Press,
Cambridge, Massachusetts, London, England.
Collins, M. J. 1996. A New Statistical Parser Based
on Bigram Lexical Dependencies. Proceedings of
the 34th Annual Meeting of the Association for
Computational Linguistics, pages 184-191.
Grosz, Barbara J. and Candace L. Sidner. 1986.
Attention, Intentions, and the Structure of
Discourse. Computational Linguistics, 12(3):175-
204.
Hinkelman, E. A. 1990. Linguistic and Pragmatic
Constraints on Utterance Interpretation. Ph.D.
Dissertation, University of Rochester, Rochester,
New York.
Hinkelman, E. A. and J. F. Allen. 1989. Two
Constraints on Speech Act Ambiguity.
Proceedings of the 27th Annual Meeting of the
Association of Computational Linguistics, pages
212-219.
Kim, Chang-Hyun, Jae-Hoon Kim, Jungyun Seo, and
Gil Chang Kim. 1994. A Right-to-Left Chart
</reference>
<page confidence="0.977249">
236
</page>
<reference confidence="0.99956812962963">
Parsing for Dependency Grammar using Headable
Path. Proceeding of the 1994 International
Conference on Computer Processing of Oriental
Languages (ICCPOL), pages 175-180.
Lambert, Lynn. 1993. Recognizing Complex
Discourse Acts: A Tripartite Plan-Based Model of
Dialogue. Ph.D. Dissertation, The University of
Delaware, Newark, Delaware.
Lambert, Lynn and Sandra Caberry. 1991. A
Tripartite Plan-based Model of Dialogue.
Proceedings of ACL, pages 47-54.
Lee, Jae-won, Jungyun Seo, Gil Chang Kim. 1997. A
Dialogue Analysis Model With Statistical Speech
Act Processing For Dialogue Machine Translation.
Proceedings of Spoken Language Translation
(Workshop in conjunction with (E)ACL&apos;97), pages
10-15.
Lee, Hyunjung, Jae-Won Lee and Jungyun Seo. 1998.
Speech Act Analysis Model of Korean Utterances
for Automatic Dialog Translation. Journal of
Korea Information Science Society (B): Software
and Applications, 25(10):1443-1552 (In Korean).
Litman, Diane J. and James F. Allen. 1987. A Plan
Recognition Model for Subdialogues in
Conversations. Cognitive Science, pages 163-200.
Nagata, M. and T. Morimoto. 1994a. First steps
toward statistical modeling of dialogue to predict
the speech act type of the next utterance. Speech
Communication, 15: 193-203.
Nagata, M. and T. Morimoto. 19941). An
information-theoretic model of discourse for next
utterance type prediction. Transactions of
Information Processing Society of Japan,
35(6):1050-1061.
Reithinger, N. and M. Klesen. 1997. Dialogue act
classification using language models. Proceedings
of EuroSpeech-97, pages 2235-2238.
Reynar, J. C. and A. Ratnaparkhi. 1997. A Maximum
Entropy Approach to Identifying Sentence
Boundaries. In Proceeding of the Fifth Conference
on Applied Natural Language Processing, pages
16-19.
Ristad, E. 1996. Maximum Entropy Modeling
Toolkit. Technical Report, Department of
Computer Science, Princeton University.
Samuel, Ken, Sandra Caberry, and K. Vijay-Shanker.
1998. Computing Dialogue Acts from Features
with Transformation-Based Learning. Applying
Machine Learning to Discourse Processing:
Papers from the 1998 AAAI Spring Symposium.
Stanford, California. Pages 90-97.
Walker, Marilyn A. 1996. Limited Attention and
Discourse Structure. Computational Linguistics,
22(2):255-264.
</reference>
<page confidence="0.99741">
237
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.638019">
<title confidence="0.881152">Analysis System of Speech Acts and Discourse Structures Using Maximum Entropy Model.</title>
<author confidence="0.942325">Won Seug Choi</author>
<author confidence="0.942325">Jeong-Mi Cho</author>
<author confidence="0.942325">Jungyun Seo</author>
<affiliation confidence="0.999992">Dept. of Computer Science, Sogang University</affiliation>
<address confidence="0.9518565">Sinsu-dong 1, Mapo-gu Seoul, Korea, 121-742</address>
<email confidence="0.945721">dolhana,jmcho}@nlprep.sogang.ac.kr,seojy@ccs.sogang.ac.kr</email>
<abstract confidence="0.999274">We propose a statistical dialogue analysis model to determine discourse structures as well as speech acts using maximum entropy model. The model can automatically acquire probabilistic discourse knowledge from a discourse tagged corpus to resolve ambiguities. We propose the idea of tagging discourse segment boundaries to represent the structural information of discourse. Using this representation we can effectively combine speech act analysis and discourse structure analysis in one framework.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Andernach</author>
</authors>
<title>A Machine Learning Approach to the Classification of Dialogue Utterances.</title>
<date>1996</date>
<booktitle>Proceedings of NeMLaP-2.</booktitle>
<contexts>
<context position="10546" citStr="Andernach (1996)" startWordPosition="1621" endWordPosition="1622">se notations, P(S, IU 1, ,) means the probability that Si becomes the speech act of utterance U, given a sequence of utterances Ui, U2,..., U. We can approximate the probability P(S, I Ui. ,) by the product of the sentential probability P(U, I Si) and the contextual probability P(S, IU - 1, S 1, , -i). Also we can approximate P(S, IU 1, - 1, S 1, - i) by P(S, I Si, i - i) (Chamiak (1993)). P(Si I Ui,) P(Si I Si,- i)P(Ui I Si) (1) It has been widely believed that there is a strong relation between the speaker&apos;s speech act and the surface utterances expressing that speech act (Hinkelman (1989), Andernach (1996)). That is, the speaker utters a sentence, which most well expresses his/her intention (speech act) so that the hearer can easily infer what the speaker&apos;s speech act is. The sentential probability P(U, I Si) represents the relationship between the speech acts and the features of surface sentences. Therefore, we approximate the sentential probability using the syntactic pattern P,. P(U; I Si) P(Pi I Si) (2) The contextual probability P(S, I Si, - 1) is the probability that utterance with speech act S, is uttered given that utterances with speech act Si, S2,..., S, - I were previously uttered. S</context>
</contexts>
<marker>Andernach, 1996</marker>
<rawString>Andernach, T. 1996. A Machine Learning Approach to the Classification of Dialogue Utterances. Proceedings of NeMLaP-2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, Adam L., Stephen A. Della Pietra, and Vincent J. Della Pietra. 1996. A Maximum Entropy Approach to Natural Language Processing. Computational Linguistics, 22(1):39-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Caberry</author>
</authors>
<title>A Pragmatics-Based Approach to Ellipsis Resolution.</title>
<date>1989</date>
<journal>Computational Linguistics,</journal>
<pages>15--2</pages>
<contexts>
<context position="1444" citStr="Caberry (1989)" startWordPosition="208" endWordPosition="209">age dialogue, a computer system must be sensitive to the speaker&apos;s intentions indicated through utterances. Since identifying the speech acts of utterances is very important to identify speaker&apos;s intentions, it is an essential part of a dialogue analysis system. It is difficult, however, to infer the speech act from a surface utterance since an utterance may represent more than one speech act according to the context. Most works done in the past on the dialogue analysis has analyzed speech acts based on knowledge such as recipes for plan inference and domain specific knowledge (Litman (1987), Caberry (1989), Hinkelman (1990), Lambert (1991), Lambert (1993), Lee (1998)). Since these knowledge-based models depend on costly hand-crafted knowledge, these models are difficult to be scaled up and expanded to other domains. * This work was supported by KOSEF under the contract 97-0102-0301-3. Recently, machine learning models using a discourse tagged corpus are utilized to analyze speech acts in order to overcome such problems (Nagata (1994a), Nagata (1994b), Reithinger (1997), Lee (1997), Samuel (1998)). Machine learning offers promise as a means of associating features of utterances with particular s</context>
</contexts>
<marker>Caberry, 1989</marker>
<rawString>Caberry, Sandra. 1989. A Pragmatics-Based Approach to Ellipsis Resolution. Computational Linguistics, 15(2):75-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Carniak</author>
</authors>
<title>Statistical Language Learning. A Bradford Book,</title>
<date>1993</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts, London, England.</location>
<marker>Carniak, 1993</marker>
<rawString>Carniak, Eugene. 1993. Statistical Language Learning. A Bradford Book, The MIT Press, Cambridge, Massachusetts, London, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Collins</author>
</authors>
<title>A New Statistical Parser Based on Bigram Lexical Dependencies.</title>
<date>1996</date>
<booktitle>Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>184--191</pages>
<contexts>
<context position="4874" citStr="Collins (1996)" startWordPosition="751" endWordPosition="752">oom, please. inform re_spj_inse Figure I: An example of a dialogue with speech acts In this paper, we propose a dialogue analysis model to determine both the speech acts of utterances and the discourse structure of a dialogue using maximum entropy model. In the proposed model, the speech act analysis and the discourse structure analysis are combined in one framework so that they can easily provide feedback to each other. For the discourse structure analysis, we suggest a statistical model with discourse segment boundaries (DSBs) similar to the idea of gaps suggested for a statistical parsing (Collins (1996)). For training, we use a corpus tagged with various discourse knowledge. To overcome the problem of data sparseness, which is common for corpus-based works, we use split partial context as well as whole context. After explaining the tagged dialogue corpus we used in section 1, we discuss the statistical models in detail in section 2. In section 3, we explain experimental results. Finally, we conclude in section 4. 1 Discourse tagging In this paper, we use Korean dialogue corpus transcribed from recordings in real fields such as hotel reservation, airline reservation and tour reservation. This</context>
</contexts>
<marker>Collins, 1996</marker>
<rawString>Collins, M. J. 1996. A New Statistical Parser Based on Bigram Lexical Dependencies. Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, pages 184-191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<date>1986</date>
<booktitle>Attention, Intentions, and the Structure of Discourse. Computational Linguistics,</booktitle>
<pages>12--3</pages>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, Barbara J. and Candace L. Sidner. 1986. Attention, Intentions, and the Structure of Discourse. Computational Linguistics, 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E A Hinkelman</author>
</authors>
<title>Linguistic and Pragmatic Constraints on Utterance Interpretation.</title>
<date>1990</date>
<institution>Ph.D. Dissertation, University of Rochester,</institution>
<location>Rochester, New York.</location>
<contexts>
<context position="1462" citStr="Hinkelman (1990)" startWordPosition="210" endWordPosition="211">computer system must be sensitive to the speaker&apos;s intentions indicated through utterances. Since identifying the speech acts of utterances is very important to identify speaker&apos;s intentions, it is an essential part of a dialogue analysis system. It is difficult, however, to infer the speech act from a surface utterance since an utterance may represent more than one speech act according to the context. Most works done in the past on the dialogue analysis has analyzed speech acts based on knowledge such as recipes for plan inference and domain specific knowledge (Litman (1987), Caberry (1989), Hinkelman (1990), Lambert (1991), Lambert (1993), Lee (1998)). Since these knowledge-based models depend on costly hand-crafted knowledge, these models are difficult to be scaled up and expanded to other domains. * This work was supported by KOSEF under the contract 97-0102-0301-3. Recently, machine learning models using a discourse tagged corpus are utilized to analyze speech acts in order to overcome such problems (Nagata (1994a), Nagata (1994b), Reithinger (1997), Lee (1997), Samuel (1998)). Machine learning offers promise as a means of associating features of utterances with particular speech acts, since </context>
</contexts>
<marker>Hinkelman, 1990</marker>
<rawString>Hinkelman, E. A. 1990. Linguistic and Pragmatic Constraints on Utterance Interpretation. Ph.D. Dissertation, University of Rochester, Rochester, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E A Hinkelman</author>
<author>J F Allen</author>
</authors>
<title>Two Constraints on Speech Act Ambiguity.</title>
<date>1989</date>
<booktitle>Proceedings of the 27th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>212--219</pages>
<marker>Hinkelman, Allen, 1989</marker>
<rawString>Hinkelman, E. A. and J. F. Allen. 1989. Two Constraints on Speech Act Ambiguity. Proceedings of the 27th Annual Meeting of the Association of Computational Linguistics, pages 212-219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chang-Hyun Kim</author>
<author>Jae-Hoon Kim</author>
<author>Jungyun Seo</author>
<author>Gil Chang Kim</author>
</authors>
<title>A Right-to-Left Chart Parsing for Dependency Grammar using Headable Path.</title>
<date>1994</date>
<booktitle>Proceeding of the 1994 International Conference on Computer Processing of Oriental Languages (ICCPOL),</booktitle>
<pages>175--180</pages>
<marker>Kim, Kim, Seo, Kim, 1994</marker>
<rawString>Kim, Chang-Hyun, Jae-Hoon Kim, Jungyun Seo, and Gil Chang Kim. 1994. A Right-to-Left Chart Parsing for Dependency Grammar using Headable Path. Proceeding of the 1994 International Conference on Computer Processing of Oriental Languages (ICCPOL), pages 175-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Lambert</author>
</authors>
<title>Recognizing Complex Discourse Acts: A Tripartite Plan-Based Model of Dialogue.</title>
<date>1993</date>
<institution>The University of Delaware,</institution>
<location>Newark, Delaware.</location>
<note>Ph.D. Dissertation,</note>
<contexts>
<context position="1494" citStr="Lambert (1993)" startWordPosition="214" endWordPosition="215">to the speaker&apos;s intentions indicated through utterances. Since identifying the speech acts of utterances is very important to identify speaker&apos;s intentions, it is an essential part of a dialogue analysis system. It is difficult, however, to infer the speech act from a surface utterance since an utterance may represent more than one speech act according to the context. Most works done in the past on the dialogue analysis has analyzed speech acts based on knowledge such as recipes for plan inference and domain specific knowledge (Litman (1987), Caberry (1989), Hinkelman (1990), Lambert (1991), Lambert (1993), Lee (1998)). Since these knowledge-based models depend on costly hand-crafted knowledge, these models are difficult to be scaled up and expanded to other domains. * This work was supported by KOSEF under the contract 97-0102-0301-3. Recently, machine learning models using a discourse tagged corpus are utilized to analyze speech acts in order to overcome such problems (Nagata (1994a), Nagata (1994b), Reithinger (1997), Lee (1997), Samuel (1998)). Machine learning offers promise as a means of associating features of utterances with particular speech acts, since computers can automatically anal</context>
</contexts>
<marker>Lambert, 1993</marker>
<rawString>Lambert, Lynn. 1993. Recognizing Complex Discourse Acts: A Tripartite Plan-Based Model of Dialogue. Ph.D. Dissertation, The University of Delaware, Newark, Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Lambert</author>
<author>Sandra Caberry</author>
</authors>
<title>A Tripartite Plan-based Model of Dialogue.</title>
<date>1991</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>47--54</pages>
<marker>Lambert, Caberry, 1991</marker>
<rawString>Lambert, Lynn and Sandra Caberry. 1991. A Tripartite Plan-based Model of Dialogue. Proceedings of ACL, pages 47-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jae-won Lee</author>
<author>Jungyun Seo</author>
<author>Gil Chang Kim</author>
</authors>
<title>A Dialogue Analysis Model With Statistical Speech Act Processing For Dialogue Machine Translation.</title>
<date>1997</date>
<booktitle>Proceedings of Spoken Language Translation (Workshop in conjunction with (E)ACL&apos;97),</booktitle>
<pages>10--15</pages>
<marker>Lee, Seo, Kim, 1997</marker>
<rawString>Lee, Jae-won, Jungyun Seo, Gil Chang Kim. 1997. A Dialogue Analysis Model With Statistical Speech Act Processing For Dialogue Machine Translation. Proceedings of Spoken Language Translation (Workshop in conjunction with (E)ACL&apos;97), pages 10-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyunjung Lee</author>
<author>Jae-Won Lee</author>
<author>Jungyun Seo</author>
</authors>
<title>Speech Act Analysis Model of Korean Utterances for Automatic Dialog Translation.</title>
<date>1998</date>
<journal>Journal of Korea Information Science Society (B): Software and Applications,</journal>
<pages>25--10</pages>
<location>(In Korean).</location>
<marker>Lee, Lee, Seo, 1998</marker>
<rawString>Lee, Hyunjung, Jae-Won Lee and Jungyun Seo. 1998. Speech Act Analysis Model of Korean Utterances for Automatic Dialog Translation. Journal of Korea Information Science Society (B): Software and Applications, 25(10):1443-1552 (In Korean).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane J Litman</author>
<author>James F Allen</author>
</authors>
<title>A Plan Recognition Model for Subdialogues in Conversations. Cognitive Science,</title>
<date>1987</date>
<pages>163--200</pages>
<marker>Litman, Allen, 1987</marker>
<rawString>Litman, Diane J. and James F. Allen. 1987. A Plan Recognition Model for Subdialogues in Conversations. Cognitive Science, pages 163-200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagata</author>
<author>T Morimoto</author>
</authors>
<title>First steps toward statistical modeling of dialogue to predict the speech act type of the next utterance.</title>
<date>1994</date>
<journal>Speech Communication,</journal>
<volume>15</volume>
<pages>193--203</pages>
<marker>Nagata, Morimoto, 1994</marker>
<rawString>Nagata, M. and T. Morimoto. 1994a. First steps toward statistical modeling of dialogue to predict the speech act type of the next utterance. Speech Communication, 15: 193-203.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagata</author>
<author>T Morimoto</author>
</authors>
<title>An information-theoretic model of discourse for next utterance type prediction.</title>
<date>1994</date>
<journal>Transactions of Information Processing Society of Japan,</journal>
<pages>35--6</pages>
<marker>Nagata, Morimoto, 1994</marker>
<rawString>Nagata, M. and T. Morimoto. 19941). An information-theoretic model of discourse for next utterance type prediction. Transactions of Information Processing Society of Japan, 35(6):1050-1061.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Reithinger</author>
<author>M Klesen</author>
</authors>
<title>Dialogue act classification using language models.</title>
<date>1997</date>
<booktitle>Proceedings of EuroSpeech-97,</booktitle>
<pages>2235--2238</pages>
<marker>Reithinger, Klesen, 1997</marker>
<rawString>Reithinger, N. and M. Klesen. 1997. Dialogue act classification using language models. Proceedings of EuroSpeech-97, pages 2235-2238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Reynar</author>
<author>A Ratnaparkhi</author>
</authors>
<title>A Maximum Entropy Approach to Identifying Sentence Boundaries.</title>
<date>1997</date>
<booktitle>In Proceeding of the Fifth Conference on Applied Natural Language Processing,</booktitle>
<pages>16--19</pages>
<marker>Reynar, Ratnaparkhi, 1997</marker>
<rawString>Reynar, J. C. and A. Ratnaparkhi. 1997. A Maximum Entropy Approach to Identifying Sentence Boundaries. In Proceeding of the Fifth Conference on Applied Natural Language Processing, pages 16-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ristad</author>
</authors>
<title>Maximum Entropy Modeling Toolkit.</title>
<date>1996</date>
<tech>Technical Report,</tech>
<institution>Department of Computer Science, Princeton University.</institution>
<contexts>
<context position="19864" citStr="Ristad 1996" startWordPosition="3243" endWordPosition="3244">n since the whole context includes only a speech act. Using the separated feature functions, we can solve the data sparseness problem when there are not enough training examples to which the unified feature function is applicable. 3 Experiments and results In order to experiment the proposed model, we used the tagged corpus shown in section 1. The corpus is divided into the training corpus with 428 dialogues, 8,349 utterances (19.51 utterances per dialogue), and the testing corpus with 100 dialogues, 1,936 utterances (19.36 utterances per dialogue). Using the Maximum Entropy Modeling Toolkit (Ristad 1996), we estimated the model parameter a, corresponding to each feature function f, in equation (13). We made experiments with two models for each analysis model. Model-I uses only the unified feature function, and Model-II uses the unified feature function and the separated feature function together. Among the ways to combine the unified feature function with the separated feature function, we choose the combination in which the separated feature function is used only when there is no training example applicable for the unified feature function. First, we tested the speech act analysis model and </context>
</contexts>
<marker>Ristad, 1996</marker>
<rawString>Ristad, E. 1996. Maximum Entropy Modeling Toolkit. Technical Report, Department of Computer Science, Princeton University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Samuel</author>
<author>Sandra Caberry</author>
<author>K Vijay-Shanker</author>
</authors>
<title>Computing Dialogue Acts from Features with Transformation-Based Learning.</title>
<date>1998</date>
<booktitle>Applying Machine Learning to Discourse Processing: Papers from the</booktitle>
<pages>90--97</pages>
<location>Stanford, California.</location>
<marker>Samuel, Caberry, Vijay-Shanker, 1998</marker>
<rawString>Samuel, Ken, Sandra Caberry, and K. Vijay-Shanker. 1998. Computing Dialogue Acts from Features with Transformation-Based Learning. Applying Machine Learning to Discourse Processing: Papers from the 1998 AAAI Spring Symposium. Stanford, California. Pages 90-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<date>1996</date>
<booktitle>Limited Attention and Discourse Structure. Computational Linguistics,</booktitle>
<pages>22--2</pages>
<contexts>
<context position="11581" citStr="Walker (1996)" startWordPosition="1791" endWordPosition="1792">al probability P(S, I Si, - 1) is the probability that utterance with speech act S, is uttered given that utterances with speech act Si, S2,..., S, - I were previously uttered. Since it is impossible to consider all preceding utterances Si, S2,..., S, - i as contextual information, we use the n-gram model. Generally, dialogues have a hierarchical discourse structure. So we approximate the context as speech acts of n utterances that are hierarchically recent to the utterance. An utterance A is hierarchically recent to an utterance B if A is adjacent to B in the tree structure of the discourse (Walker (1996)). Equation (3) represents the approximated contextual probability in the case of using trigram where and Ilk are hierarchically recent to the utterance U,, where 1 jk5A-1. 232 P(Si I i -1) P(Si I SJ, Sk) (3) As a result, the statistical model for speech act analysis is represented in equation (4). P(Si I U &gt;) P(Si I Si, - OP(Ui I Si) (4) P(Si I Si, Sk)P(Pi I Si) 2.2 Discourse structure analysis model 2.2.1 Discourse segment boundary tagging We define a set of discourse segment boundaries (DSBs) as the markers for discourse structure tagging. A DSB represents the relationship between two conse</context>
</contexts>
<marker>Walker, 1996</marker>
<rawString>Walker, Marilyn A. 1996. Limited Attention and Discourse Structure. Computational Linguistics, 22(2):255-264.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>