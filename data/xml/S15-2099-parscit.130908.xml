<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002364">
<title confidence="0.9980205">
UNIBA: Sentiment Analysis of English Tweets Combining Micro-blogging,
Lexicon and Semantic Features
</title>
<author confidence="0.976262">
Pierpaolo Basile and Nicole Novielli
</author>
<affiliation confidence="0.998422">
Department of Computer Science, University of Bari Aldo Moro
</affiliation>
<address confidence="0.957491">
Via, E. Orabona, 4 - 70125 Bari (Italy)
</address>
<email confidence="0.999421">
{pierpaolo.basile,nicole.novielli}@uniba.it
</email>
<sectionHeader confidence="0.996667" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999932833333333">
This paper describes the UNIBA team partic-
ipation in the Sentiment Analysis in Twitter
task (Task 10) at SemEval-2015. We propose a
supervised approach relying on keyword, lex-
icon and micro-blogging features as well as
representation of tweets in a word space.
</bodyText>
<sectionHeader confidence="0.998427" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974434782609">
Sentiment analysis is the study of the subjectivity
and polarity (positive vs. negative) of a text (Pang
and Lee, 2008). With the worldwide diffusion of
social media, a huge amount of textual data has
been made available, thus attracting the interest of
researchers in this domain (Rosenthal et al., 2014).
Sentiment analysis on such informal texts poses new
challenges due to the presence of slang, misspelled
words and micro-blogging features such as hash-
tags or links and traditional approaches may not be
successfully exploited in this domain. Previous re-
search has successfully exploited approaches based
on lexical and micro-blogging features (Mohammad
et al., 2013). In this study, we investigate a su-
pervised approach including three kinds of features
based on keywords and micro-blogging properties
of tweets, sentiment lexicons and semantics. Rather
than using word-sense disambiguation (Miura et al.,
2014), we represent tweets in a distributional seman-
tic model (DSM) (Vanzo et al., 2014), which is able
to learn the context of usage of words analysing co-
occurrences in large corpora.
This paper describes our participation at the Se-
mEval 2015 Sentiment Analysis in Twitter task
(Rosenthal et al., 2015). We discuss methods and
results of our experimental study for the overall po-
larity classification of tweets (message level sub-
task B). The Sentiment Analysis task focuses on En-
glish tweets. Data provided for training are anno-
tated according to the overall polarity of each tweet
(i.e., ’negative’, ’positive’ or ’neutral’). The sys-
tem evaluation is performed on different test sets.
In particular, the rank of the systems is calculated
on the offical Twitter 2015 test set. Further evalu-
ation is performed on a progress set including test
instances from the previous edition of the task, to
allow comparision with previous studies (Rosenthal
et al., 2014). We build a supervised system based
on our sentiment classifier for Italian tweets, which
ranked 1st in both the polarity and subjectivity tasks
at Evalita 2014 (Basile and Novielli, 2014).
The paper is structured as follows: we introduce
our system and report the details about features in
Section 2. We describe the evaluation and the sys-
tem setup in Section 3. We conclude by reporting
results and discussion in Section 4.
</bodyText>
<sectionHeader confidence="0.986722" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.995505625">
Our system is built upon our classifier for senti-
ment analysis of Italian tweets (Basile and Novielli,
2014). We adopt a supervised approach using Sup-
port Vector Machine as a classification algorithm.
We investigate three groups of features based on:
(i) keyword and micro-blogging characteristics, (ii)
sentiment lexicons, and (iii) a Distributional Seman-
tic Model (DSM).
</bodyText>
<page confidence="0.980839">
595
</page>
<bodyText confidence="0.9556584">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 595–600,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
Keywords and micro-blogging features.
Keyword-based features exploit tokens occur-
ring in the tweets (Table 1). During the tokenization
we replace the user mentions, URLs and hashtags
with three metatokens, “ USER ”, “ URL ” and
” TAG ”, for which we also count the total occur-
rences. As for keywords, we consider unigrams and
bigrams. To deal with negations, all the n-grams
occurring in a negated context receive the neg suffix.
A negated context is a tweet fragment starting with a
negation word1 and ending with a punctuation mark
(Pang et al., 2002). Moreover, we create features
capturing typical aspects of micro-blogging, such
as the use of upper case ratio and character repeti-
tions2, positive and negative emoticons, informal
expressions of laughters3, as well as the presence
of exclamation and interrogative marks, negations,
intensifiers 4. Finally we include features based on
word count for 1000 large-scale word clusters built
on English tweets5.
Lexicon-based Features. The second group con-
tains features calculated for each of the eight lexi-
cons we consider in this study. These lexicons can
be differentiated based on how they represent the in-
formation about prior polarity of words.
The NRC Emotion Lexicon (Mohammad and Tur-
ney, 2010), the MPQA Lexicon (Wilson et al., 2005)
and the Bing Liu Lexicon (Hu and Liu, 2004) pro-
vide lists of positive and negative words. We assign
a positive score equal to 1 to the positive sentiment
terms, and a negative score equal to 1 to the negative
ones. Similarly, the NRC Hashtag Sentiment Lexi-
con and the Sentiment140 Lexicon provide a list of
words with their sentiment association score, calcu-
lated as pointwise mutual information with respect
to collections of positive and negative tweets (Mo-
hammad et al., 2013). Positive and negative scores
are associated, respectively, to positive and negative
</bodyText>
<footnote confidence="0.9856102">
1The complete list of negation words provided by Christo-
pher Potts in his tutorial on sentiment http://sentiment.
christopherpotts.net/.
2These features usually plays the same role of intensifiers in
informal writing contexts.
3i.e., sequences of “ah”.
4The list of booster words is the same used by Sentistrength:
http://sentistrength.wlv.ac.uk/
5Twitter Word Clusters: http://www.ark.cs.cmu.
edu/TweetNLP/#resources
</footnote>
<bodyText confidence="0.9999894">
sentiment, while the magnitude indicates the degree
of association. We consider also the lexicon used by
SentiStrength6, a state-of-the-art tool for extracting
sentiment strength from informal English text on so-
cial media (Thelwall et al., 2010). The SentiStrength
lexicon is structured as a list of words with scores
ranging in [−5,+5]. A set of booster words is also
provided, to increase or decrease the strength of the
prior polarity of terms. Finally, we use a list of
emoticons as taken from Wikipedia7: we assign +1
and -1 as a score for positive and negative emoti-
cons, respectively. In all the lexicons mentioned so
far either a positive or negative score is associated
to each term. Using these lexicons, we extract a set
of features based on prior polarity of words occur-
ing in the tweets, as reported in Table 2. The fea-
tures are computed separately for terms in affirma-
tive contexts and terms in negated contexts.
In addition, we use SentiWordNet 3.0 (Esuli and
Sebastiani, 2006). SentiWordNet extends Word-
Net by associating positive, negative and objective
scores to each synset, where the three scores sum up
to 1. A lemma can receive multiple polarity scores if
it occurs in more than one synset. In such cases, we
select the most frequent sense for the lemma, with
respect to its part-of-speech. Thanks to the availabil-
ity of the objective scores, additional features can be
computed to model the presence of neutral terms,
as reported in (Basile and Novielli, 2014). Also the
features based on SentiWordNet are calculated sep-
arately for affirmative and negated contexts.
Finally, we consider the word classes defined in
the Linguistic Inquiry and Word Count (LIWC) tax-
onomy, developed in the scope of psycholinguistic
research (Pennebaker and Francis, 2001). LIWC or-
ganizes words into psychologically meaningful cat-
egories based on the assumption that words and lan-
guage reflect most part of cognitive and emotional
phenomena involved in communication. Previous
research has shown how the language use varies with
respect to the communicative intention, thus making
possible to distinguish between objective and sub-
jective statements as well as between agreement and
disagreement expressions (Novielli and Strapparava,
2013). Therefore, we include word count features
</bodyText>
<footnote confidence="0.9999045">
6http://sentistrength.wlv.ac.uk/
7http://it.wikipedia.org/wiki/Emoticon
</footnote>
<page confidence="0.997534">
596
</page>
<bodyText confidence="0.976386842105263">
for each word class in LIWC. Similarly, we include
word count features for the emotion word classes in
the NRC Emotion Lexicon.
Semantic Features. Finally, we calculate features
based on the Distributional Semantic Model (DSM).
Given a set of 15M unlabelled downloaded tweets,
we build a geometric space in which each word
is represented as a mathematical point (Sahlgren,
2006). The similarity between words is computed
as their closeness in the space. To represent a tweet
in the geometric space, we adopt the superposition
operator (Smolensky, 1990), that is the vector sum
of all the vectors of words occurring in the tweet.
��
We use the tweet vector t as a semantic feature in
training our classifier.
In the same fashion, we build prototype vectors
for each class based on the sentiment lexicons that
provide prior polarity scores for words (i.e. Sen-
tiWordNet, SentiStrength, and the merge of NRC
Hashtag and the Sentiment140). For example, the
prototype vector for the positive class ���
p��� based on
SentiStrength is obtained by summing up all the vec-
tors of words with positive prior polarity in the Sen-
tiStrength lexicon. We use three prototype vectors to
represent, for each lexicon, the positive ���
p���, nega-
tive ���
p���, and subjective ps class (defined by consid-
ering both positive and negative words). In the case
of SentiWordNet, objectivity scores are also avail-
able and allow us to build a prototype for objectivity
p�. To capture the subjectivity and the polarity of a
��
��
tweet t , we compute the cosine similarity between
t and each prototype vector.
</bodyText>
<sectionHeader confidence="0.998938" genericHeader="method">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999344545454545">
The message level subtask (subtask B) is designed
for evaluating systems on their ability to predict the
overall polarity of a given tweet, with respect to
three classes: positive, negative, and neutral.
Organizers provided 8,006 manually annotated
tweets as training data. We use the training set8
to extract the features described in Section 2. De-
tails on our system setup are reported in Section
3.1. As test set, organizers provided a collection
of 2,390 manually annotated tweets (Official 2015
test set). Further data from different sources (8,987
</bodyText>
<footnote confidence="0.9433355">
8Further development data provided by the organizers are
not used for training
</footnote>
<bodyText confidence="0.999827111111111">
tweets overall) are included in the progress test set
and are provided to allow comparison with systems
participating in previous editions. Systems are com-
pared against the gold standard of the official test
set in terms of macro average F measure calculated
over the positive and negative classes. For the sake
of completeness, we report also weighted F measure
considering all the three categories in the classifica-
tion task (see Section 4).
</bodyText>
<subsectionHeader confidence="0.9988">
3.1 System Setup
</subsectionHeader>
<bodyText confidence="0.999983615384615">
The system is completely developed in JAVA. We
used the Liblinear9 implementation of L2-loss sup-
port vector classifier. Tweets are tokenized using the
Twitter NLP and Part-of-Speech Tagging API10. We
use both the tokenizer and the part-of-speech tagger
to preprocess the data.
Regarding the DSM, we download 15 million
tweets using the Twitter Streaming API. Tweets are
downloaded by querying the API using three lexi-
cons extracted from the training data for each class,
based on Kullback-Leibler divergence (KLD) as de-
scribed in (Basile and Novielli, 2014).
We download the same number of tweets for each
lexicon. We exploit these unlabeled tweets to build
a DSM, using the “word2vec”11 tool based on a re-
vised implementation of the Recurrent Neural Net
Language Model (Mikolov et al., 2013) using a log-
linear approach. We use the skipgram model, which
is more accurate in presence of infrequent words,
with 300 vector dimensions and remove the terms
with less than ten occurrences, obtaining 308,493
terms overall.
In training our classifier, we set the C parameter to
0.01. We select this value after a 10-fold validation
on training data to select the best combination. The
total number of features exploited is 145,967.
</bodyText>
<sectionHeader confidence="0.999577" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.99995925">
The final ranking issued by the organizers considers
the system performance in terms of average between
F measures for the positive and negative classes
only. Table 3 reports the system performance and
</bodyText>
<footnote confidence="0.99316175">
9http://www.csie.ntu.edu.tw/˜cjlin/
liblinear/
10http://www.ark.cs.cmu.edu/TweetNLP/
11https://code.google.com/p/word2vec/
</footnote>
<page confidence="0.996676">
597
</page>
<bodyText confidence="0.982789058823529">
Keyword and micro-blogging features
n − grams uni- and bi-grams are considered. User mentions, URLs and hashtag are replaced
with metatokens
countUSER total occurrences of user mentions
countURL total occurrences of URLs
countTAG total occurrences of hashtags
uppercaseratio the ratio between the number of upper case characters and the total number of
characters
emopos the number of positive emoticons
emoneg the number of negative emoticons
countLaugh the count of sequences of ’ah’ as slang expression of laughters
countIntensif the ratio between the number of tokens with repeated characters and the total num-
ber of tokens
countQMark the total occurrences of question marks
countExMark the total occurrences of exclamation marks
countNegation the total occurrences of negation words
countclusteri the total occurrences of words belonging to the i-th cluster
</bodyText>
<tableCaption confidence="0.891575666666667">
Table 1: Description of keyword and micro-blogging features.
Sentiment lexicon based features
Table 2: Description of sentiment lexicon features.
</tableCaption>
<figure confidence="0.74098">
the number of tokens with positive score
the number of tokens with negative score
the number of tokens with either positive or negative score
</figure>
<figureCaption confidence="0.856377">
the score of the last positive token in the tweet
the score of the last negative token in the tweet
the score of the last emoticon in the tweet
the sum of positive scores for the tokens in the tweet
the sum of negative scores for the tokens in the tweet
</figureCaption>
<figure confidence="0.842501">
the subjectivity polarity, it is the sum of the positive and negative scores
the maximum positive score observed for tokens in the tweet
the maximum negative score observed for tokens in the tweet
the total occurrences of words belonging to the i-th word class Ci, where word
classes are defined by the LIWC and NRC Emotion Lexicon taxonomies
opos
oneg
osubj
lastpos
lastneg
lastemo
sumpos
sumneg
sumsubj
sumMaxpos
sumMaxneg
countCi
</figure>
<bodyText confidence="0.9985469">
its rank. The system rank on the progress set is cal-
culated on the performance on the Twitter 2014 sub-
set. For completeness, we report also the F mea-
sure calculated considering all the three classes in
our model, including the neutral category 4.
The results are very encouraging: even if far from
optimum, the system differs for only 3.29 points
from the first ranked one (F=64.84). Furthermore,
we observe that even if our system is trained only
on tweets it is able to generalize on datasets from
other domains, such as SMS and other microblog-
ging services (i.e., LiveJournal). Conversely, the
system performance drops on the Twitter 2014 Sar-
casm set. This is consistent with results observed
in our previous study (Basile and Novielli, 2014) on
Italian tweets (Basile et al., 2014), where the 43% of
misclassified negative cases were mostly ironic and
would require common sense reasoning to detect the
negative opinion expressed. Moreover a drop in per-
fomance on the sarcasm test set had been already
</bodyText>
<page confidence="0.993873">
598
</page>
<table confidence="0.999844166666667">
System Positive Negative Neutral F
P R F P R F P R F
All features 85.42 55.30 67.13 60.51 52.05 55.96 61.11 86.93 71.77 64.95
w/o keyword 88.23 49.81 63.67 59.62 51.78 55.43 59.18 89.16 71.14 63.41 (-2.37%)
w/o semantic 84.12 54.62 66.24 58.16 53.70 55.84 61,.28 85.61 71.43 64.50 (-0.69%)
w/o lexicons 83.31 52.89 64.70 60.92 39.73 48.09 58.14 58.14 70.00 60.93 (-6.19%)
</table>
<tableCaption confidence="0.96431">
Table 4: System results for all feature settings and all classes on the official test set Twitter 2015.
</tableCaption>
<table confidence="0.9993345">
Test set AVG Rank
Official 2015 (Fpos,Fneg) 12/40
61.55
Twitter 2014 65.11 25/40
LiveJournal 2014 70.05 -
SMS 2013 65.50 -
Twitter 2013 61.66 -
Twitter 2014 Sarcasm 37.30 -
</table>
<tableCaption confidence="0.999785">
Table 3: Task results.
</tableCaption>
<bodyText confidence="0.999968083333334">
observed for systems participating in the previous
edition of the task (Rosenthal et al., 2014) and can
be observed for all systems in the current edition.
However, our system had a greater than average per-
formance drop and we are currently studying this is-
sue.
Observing the detailed scores for each class (first
row of Table 4) we discover that the system per-
forms better in the recognition of positive and neu-
tral cases, in contrast with previous evidence from
the experiment on the Italian corpus.
To further investigate the predictive power of the
features in our model, we perform an ablation test on
the Twitter 2015 test set, for which organizers pro-
vided the gold standard. We remove each group of
features to assess the decrease of F measure on test
data with respect to the setting including all features.
Results are reported in Table 4 and demonstrate the
importance of all feature groups.
Removing the sentiment lexicon group of features
causes the highest decrease in performance. This is
in contrast with previous evidence of our experiment
on the Italian dataset of tweets, where a drop of per-
formance of only 1% was observed. We provide a
possible explanation to this by observing that only
one sentiment lexicon was adopted in the study on
the Italian dataset. On the contrary, in the current ex-
periment on English tweets we can rely on a richer
set of features due to the avaliablity of numerous lex-
icons, as explained in Section 2. Moreover, the Sen-
timent140 Lexicon and the Hashtag Sentiment Lexi-
con are both developed specifically to address senti-
ment analysis of tweets, thus providing higher cov-
erage of lexical cues that are typical of microblog-
ging.
Keyword and microblogging features are the sec-
ond most useful group. This is consistent with ev-
idence from the Italian experiment, for which we
observe a comparable drop in performance on the
polarity detection task. However, in the current ex-
periment we also consider n-grams, which are not
included in the feature set of the system for Italian.
This consideration suggest that n-grams might con-
tribute differently to the performance of sentiment
classifiers depending on the language being used,
thus suggesting directions for further investigation.
Finally, semantic features lead to the smaller drop
in F measure when removed (-0.69%). This is in
contrast with our previous findings in the Italian set-
ting, where the semantic features plays a key role.
This might be due to the prevalence of political top-
ics in the Italian dataset, possibly causing a bias
in our classifier due to the domain-specific lexicon
about politics. This discrepancy indicates further
directions for future investigation on the ability of
semantic features in disambiguating polarity in mi-
croblogging, with respect to the topic being dis-
cussed and the language being used.
Future replications of this study will involve fur-
ther data to validate and generalize our findings.
</bodyText>
<sectionHeader confidence="0.991985" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.699921333333333">
Pierpaolo Basile and Nicole Novielli. 2014. UNIBA at
EVALITA 2014-SENTIPOLC Task: Predicting tweet
sentiment polarity combining micro-blogging, lexicon
</reference>
<page confidence="0.994731">
599
</page>
<reference confidence="0.998679620689655">
and semantic features. In Proceedings of EVALITA
2014, pages 58–63.
Valerio Basile, Andrea Bolioli, Malvina Nissim, Viviana
Patti, and Paolo Rosso. 2014. Overview of the Evalita
2014 SENTIment POLarity Classification Task. In
Proc. of EVALITA 2014, Pisa, Italy.
Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiword-
net: A publicly available lexical resource for opinion
mining. In Proceedings of LREC, volume 6, pages
417–422.
Minqing Hu and Bing Liu. 2004. Mining and Summa-
rizing Customer Reviews. In Proceedings of the Tenth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, pages 168–177.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient Estimation of Word Represen-
tations in Vector Space. CoRR, abs/1301.3781.
Yasuhide Miura, Shigeyuki Sakaki, Keigo Hattori, and
Tomoko Ohkuma. 2014. TeamX: A Sentiment An-
alyzer with Enhanced Lexicon Mapping and Weight-
ing Scheme for Unbalanced Data. In Proceedings of
the 8th International Workshop on Semantic Evalua-
tion (SemEval 2014), pages 628–632, Dublin, Ireland,
August.
Saif M. Mohammad and Peter D. Turney. 2010. Emo-
tions Evoked by Common Words and Phrases: Using
Mechanical Turk to Create an Emotion Lexicon. In
Proceedings of the NAACL HLT 2010 Workshop on
Computational Approaches to Analysis and Genera-
tion of Emotion in Text, CAAGET ’10, pages 26–34.
Saif Mohammad, Svetlana Kiritchenko, and Xiaodan
Zhu. 2013. Nrc-canada: Building the state-of-the-
art in sentiment analysis of tweets. In Second Joint
Conference on Lexical and Computational Semantics
(*SEM), Volume 2: Proceedings of the Seventh Inter-
national Workshop on Semantic Evaluation (SemEval
2013), pages 321–327, Atlanta, Georgia, USA, June.
Nicole Novielli and Carlo Strapparava. 2013. The
Role of Affect Analysis in Dialogue Act Identification.
IEEE Transactions on Affective Computing, 4:439–
451.
Bo Pang and Lillian Lee. 2008. Opinion Mining and
Sentiment Analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135, January.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment Classification using
Machine Learning Techniques. In Proceedings of the
2002 Conference on Empirical Methods in Natural
Language Processing, pages 79–86, July.
J. Pennebaker and M. Francis. 2001. Linguistic Inquiry
and Word Count: LIWC. Erlbaum Publishers.
Sara Rosenthal, Alan Ritter, Preslav Nakov, and Veselin
Stoyanov. 2014. SemEval-2014 Task 9: Sentiment
Analysis in Twitter. In Proceedings of the 8th Inter-
national Workshop on Semantic Evaluation (SemEval
2014), pages 73–80, Dublin, Ireland, August.
Sara Rosenthal, Preslav Nakov, Svetlana Kiritchenko,
Saif M Mohammad, Alan Ritter, and Veselin Stoy-
anov. 2015. SemEval-2015 Task 10: Sentiment Anal-
ysis in Twitter. In Proceedings of the 9th International
Workshop on Semantic Evaluation, SemEval ’2015,
Denver, Colorado, June.
Magnus Sahlgren. 2006. The Word-Space Model: Us-
ing distributional analysis to represent syntagmatic
and paradigmatic relations between words in high-
dimensional vector spaces. Ph.D. thesis.
Paul Smolensky. 1990. Tensor product variable bind-
ing and the representation of symbolic structures in
connectionist systems. Artificial Intelligence, 46(1-
2):159–216, November.
Mike Thelwall, Kevan Buckley, Georgios Paltoglou,
Di Cai, and Arvid Kappas. 2010. Sentiment in
Short Strength Detection Informal Text. Journal of the
American Society for Information Science and Tech-
nology, 61(12):2544–2558, December.
Andrea Vanzo, Danilo Croce, and Roberto Basili. 2014.
A context-based model for Sentiment Analysis in
Twitter. In Proceedings of COLING 2014, the 25th In-
ternational Conference on Computational Linguistics:
Technical Papers, pages 2345–2354, Dublin, Ireland,
August.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing Contextual Polarity in Phrase-level
Sentiment Analysis. In Proceedings of the Conference
on Human Language Technology and Empirical Meth-
ods in Natural Language Processing, HLT ’05, pages
347–354.
</reference>
<page confidence="0.996688">
600
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.940254">
<title confidence="0.9983125">UNIBA: Sentiment Analysis of English Tweets Combining Micro-blogging, Lexicon and Semantic Features</title>
<author confidence="0.999938">Basile Novielli</author>
<affiliation confidence="0.999622">Department of Computer Science, University of Bari Aldo Moro</affiliation>
<address confidence="0.947147">Via, E. Orabona, 4 - 70125 Bari (Italy)</address>
<abstract confidence="0.999449">This paper describes the UNIBA team participation in the Sentiment Analysis in Twitter task (Task 10) at SemEval-2015. We propose a supervised approach relying on keyword, lexicon and micro-blogging features as well as representation of tweets in a word space.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pierpaolo Basile</author>
<author>Nicole Novielli</author>
</authors>
<title>UNIBA at EVALITA 2014-SENTIPOLC Task: Predicting tweet sentiment polarity combining micro-blogging, lexicon and semantic features.</title>
<date>2014</date>
<booktitle>In Proceedings of EVALITA 2014,</booktitle>
<pages>58--63</pages>
<contexts>
<context position="2627" citStr="Basile and Novielli, 2014" startWordPosition="401" endWordPosition="404">re annotated according to the overall polarity of each tweet (i.e., ’negative’, ’positive’ or ’neutral’). The system evaluation is performed on different test sets. In particular, the rank of the systems is calculated on the offical Twitter 2015 test set. Further evaluation is performed on a progress set including test instances from the previous edition of the task, to allow comparision with previous studies (Rosenthal et al., 2014). We build a supervised system based on our sentiment classifier for Italian tweets, which ranked 1st in both the polarity and subjectivity tasks at Evalita 2014 (Basile and Novielli, 2014). The paper is structured as follows: we introduce our system and report the details about features in Section 2. We describe the evaluation and the system setup in Section 3. We conclude by reporting results and discussion in Section 4. 2 System Description Our system is built upon our classifier for sentiment analysis of Italian tweets (Basile and Novielli, 2014). We adopt a supervised approach using Support Vector Machine as a classification algorithm. We investigate three groups of features based on: (i) keyword and micro-blogging characteristics, (ii) sentiment lexicons, and (iii) a Distr</context>
<context position="7206" citStr="Basile and Novielli, 2014" startWordPosition="1127" endWordPosition="1130">tely for terms in affirmative contexts and terms in negated contexts. In addition, we use SentiWordNet 3.0 (Esuli and Sebastiani, 2006). SentiWordNet extends WordNet by associating positive, negative and objective scores to each synset, where the three scores sum up to 1. A lemma can receive multiple polarity scores if it occurs in more than one synset. In such cases, we select the most frequent sense for the lemma, with respect to its part-of-speech. Thanks to the availability of the objective scores, additional features can be computed to model the presence of neutral terms, as reported in (Basile and Novielli, 2014). Also the features based on SentiWordNet are calculated separately for affirmative and negated contexts. Finally, we consider the word classes defined in the Linguistic Inquiry and Word Count (LIWC) taxonomy, developed in the scope of psycholinguistic research (Pennebaker and Francis, 2001). LIWC organizes words into psychologically meaningful categories based on the assumption that words and language reflect most part of cognitive and emotional phenomena involved in communication. Previous research has shown how the language use varies with respect to the communicative intention, thus making</context>
<context position="11328" citStr="Basile and Novielli, 2014" startWordPosition="1773" endWordPosition="1776">egories in the classification task (see Section 4). 3.1 System Setup The system is completely developed in JAVA. We used the Liblinear9 implementation of L2-loss support vector classifier. Tweets are tokenized using the Twitter NLP and Part-of-Speech Tagging API10. We use both the tokenizer and the part-of-speech tagger to preprocess the data. Regarding the DSM, we download 15 million tweets using the Twitter Streaming API. Tweets are downloaded by querying the API using three lexicons extracted from the training data for each class, based on Kullback-Leibler divergence (KLD) as described in (Basile and Novielli, 2014). We download the same number of tweets for each lexicon. We exploit these unlabeled tweets to build a DSM, using the “word2vec”11 tool based on a revised implementation of the Recurrent Neural Net Language Model (Mikolov et al., 2013) using a loglinear approach. We use the skipgram model, which is more accurate in presence of infrequent words, with 300 vector dimensions and remove the terms with less than ten occurrences, obtaining 308,493 terms overall. In training our classifier, we set the C parameter to 0.01. We select this value after a 10-fold validation on training data to select the b</context>
<context position="14933" citStr="Basile and Novielli, 2014" startWordPosition="2342" endWordPosition="2345">ness, we report also the F measure calculated considering all the three classes in our model, including the neutral category 4. The results are very encouraging: even if far from optimum, the system differs for only 3.29 points from the first ranked one (F=64.84). Furthermore, we observe that even if our system is trained only on tweets it is able to generalize on datasets from other domains, such as SMS and other microblogging services (i.e., LiveJournal). Conversely, the system performance drops on the Twitter 2014 Sarcasm set. This is consistent with results observed in our previous study (Basile and Novielli, 2014) on Italian tweets (Basile et al., 2014), where the 43% of misclassified negative cases were mostly ironic and would require common sense reasoning to detect the negative opinion expressed. Moreover a drop in perfomance on the sarcasm test set had been already 598 System Positive Negative Neutral F P R F P R F P R F All features 85.42 55.30 67.13 60.51 52.05 55.96 61.11 86.93 71.77 64.95 w/o keyword 88.23 49.81 63.67 59.62 51.78 55.43 59.18 89.16 71.14 63.41 (-2.37%) w/o semantic 84.12 54.62 66.24 58.16 53.70 55.84 61,.28 85.61 71.43 64.50 (-0.69%) w/o lexicons 83.31 52.89 64.70 60.92 39.73 48</context>
</contexts>
<marker>Basile, Novielli, 2014</marker>
<rawString>Pierpaolo Basile and Nicole Novielli. 2014. UNIBA at EVALITA 2014-SENTIPOLC Task: Predicting tweet sentiment polarity combining micro-blogging, lexicon and semantic features. In Proceedings of EVALITA 2014, pages 58–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valerio Basile</author>
<author>Andrea Bolioli</author>
<author>Malvina Nissim</author>
<author>Viviana Patti</author>
<author>Paolo Rosso</author>
</authors>
<title>SENTIment POLarity Classification Task.</title>
<date>2014</date>
<journal>Overview of the Evalita</journal>
<booktitle>In Proc. of EVALITA 2014,</booktitle>
<location>Pisa, Italy.</location>
<contexts>
<context position="14973" citStr="Basile et al., 2014" startWordPosition="2349" endWordPosition="2352">considering all the three classes in our model, including the neutral category 4. The results are very encouraging: even if far from optimum, the system differs for only 3.29 points from the first ranked one (F=64.84). Furthermore, we observe that even if our system is trained only on tweets it is able to generalize on datasets from other domains, such as SMS and other microblogging services (i.e., LiveJournal). Conversely, the system performance drops on the Twitter 2014 Sarcasm set. This is consistent with results observed in our previous study (Basile and Novielli, 2014) on Italian tweets (Basile et al., 2014), where the 43% of misclassified negative cases were mostly ironic and would require common sense reasoning to detect the negative opinion expressed. Moreover a drop in perfomance on the sarcasm test set had been already 598 System Positive Negative Neutral F P R F P R F P R F All features 85.42 55.30 67.13 60.51 52.05 55.96 61.11 86.93 71.77 64.95 w/o keyword 88.23 49.81 63.67 59.62 51.78 55.43 59.18 89.16 71.14 63.41 (-2.37%) w/o semantic 84.12 54.62 66.24 58.16 53.70 55.84 61,.28 85.61 71.43 64.50 (-0.69%) w/o lexicons 83.31 52.89 64.70 60.92 39.73 48.09 58.14 58.14 70.00 60.93 (-6.19%) Tab</context>
</contexts>
<marker>Basile, Bolioli, Nissim, Patti, Rosso, 2014</marker>
<rawString>Valerio Basile, Andrea Bolioli, Malvina Nissim, Viviana Patti, and Paolo Rosso. 2014. Overview of the Evalita 2014 SENTIment POLarity Classification Task. In Proc. of EVALITA 2014, Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>417--422</pages>
<contexts>
<context position="6715" citStr="Esuli and Sebastiani, 2006" startWordPosition="1045" endWordPosition="1048">lso provided, to increase or decrease the strength of the prior polarity of terms. Finally, we use a list of emoticons as taken from Wikipedia7: we assign +1 and -1 as a score for positive and negative emoticons, respectively. In all the lexicons mentioned so far either a positive or negative score is associated to each term. Using these lexicons, we extract a set of features based on prior polarity of words occuring in the tweets, as reported in Table 2. The features are computed separately for terms in affirmative contexts and terms in negated contexts. In addition, we use SentiWordNet 3.0 (Esuli and Sebastiani, 2006). SentiWordNet extends WordNet by associating positive, negative and objective scores to each synset, where the three scores sum up to 1. A lemma can receive multiple polarity scores if it occurs in more than one synset. In such cases, we select the most frequent sense for the lemma, with respect to its part-of-speech. Thanks to the availability of the objective scores, additional features can be computed to model the presence of neutral terms, as reported in (Basile and Novielli, 2014). Also the features based on SentiWordNet are calculated separately for affirmative and negated contexts. Fin</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In Proceedings of LREC, volume 6, pages 417–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and Summarizing Customer Reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="4783" citStr="Hu and Liu, 2004" startWordPosition="742" endWordPosition="745">cons, informal expressions of laughters3, as well as the presence of exclamation and interrogative marks, negations, intensifiers 4. Finally we include features based on word count for 1000 large-scale word clusters built on English tweets5. Lexicon-based Features. The second group contains features calculated for each of the eight lexicons we consider in this study. These lexicons can be differentiated based on how they represent the information about prior polarity of words. The NRC Emotion Lexicon (Mohammad and Turney, 2010), the MPQA Lexicon (Wilson et al., 2005) and the Bing Liu Lexicon (Hu and Liu, 2004) provide lists of positive and negative words. We assign a positive score equal to 1 to the positive sentiment terms, and a negative score equal to 1 to the negative ones. Similarly, the NRC Hashtag Sentiment Lexicon and the Sentiment140 Lexicon provide a list of words with their sentiment association score, calculated as pointwise mutual information with respect to collections of positive and negative tweets (Mohammad et al., 2013). Positive and negative scores are associated, respectively, to positive and negative 1The complete list of negation words provided by Christopher Potts in his tuto</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and Summarizing Customer Reviews. In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient Estimation of Word Representations in Vector Space.</title>
<date>2013</date>
<location>CoRR, abs/1301.3781.</location>
<contexts>
<context position="11563" citStr="Mikolov et al., 2013" startWordPosition="1813" endWordPosition="1816">-of-Speech Tagging API10. We use both the tokenizer and the part-of-speech tagger to preprocess the data. Regarding the DSM, we download 15 million tweets using the Twitter Streaming API. Tweets are downloaded by querying the API using three lexicons extracted from the training data for each class, based on Kullback-Leibler divergence (KLD) as described in (Basile and Novielli, 2014). We download the same number of tweets for each lexicon. We exploit these unlabeled tweets to build a DSM, using the “word2vec”11 tool based on a revised implementation of the Recurrent Neural Net Language Model (Mikolov et al., 2013) using a loglinear approach. We use the skipgram model, which is more accurate in presence of infrequent words, with 300 vector dimensions and remove the terms with less than ten occurrences, obtaining 308,493 terms overall. In training our classifier, we set the C parameter to 0.01. We select this value after a 10-fold validation on training data to select the best combination. The total number of features exploited is 145,967. 4 Results and Discussion The final ranking issued by the organizers considers the system performance in terms of average between F measures for the positive and negati</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. CoRR, abs/1301.3781.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhide Miura</author>
<author>Shigeyuki Sakaki</author>
<author>Keigo Hattori</author>
<author>Tomoko Ohkuma</author>
</authors>
<title>TeamX: A Sentiment Analyzer with Enhanced Lexicon Mapping and Weighting Scheme for Unbalanced Data.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>628--632</pages>
<location>Dublin, Ireland,</location>
<contexts>
<context position="1484" citStr="Miura et al., 2014" startWordPosition="215" endWordPosition="218">, 2014). Sentiment analysis on such informal texts poses new challenges due to the presence of slang, misspelled words and micro-blogging features such as hashtags or links and traditional approaches may not be successfully exploited in this domain. Previous research has successfully exploited approaches based on lexical and micro-blogging features (Mohammad et al., 2013). In this study, we investigate a supervised approach including three kinds of features based on keywords and micro-blogging properties of tweets, sentiment lexicons and semantics. Rather than using word-sense disambiguation (Miura et al., 2014), we represent tweets in a distributional semantic model (DSM) (Vanzo et al., 2014), which is able to learn the context of usage of words analysing cooccurrences in large corpora. This paper describes our participation at the SemEval 2015 Sentiment Analysis in Twitter task (Rosenthal et al., 2015). We discuss methods and results of our experimental study for the overall polarity classification of tweets (message level subtask B). The Sentiment Analysis task focuses on English tweets. Data provided for training are annotated according to the overall polarity of each tweet (i.e., ’negative’, ’po</context>
</contexts>
<marker>Miura, Sakaki, Hattori, Ohkuma, 2014</marker>
<rawString>Yasuhide Miura, Shigeyuki Sakaki, Keigo Hattori, and Tomoko Ohkuma. 2014. TeamX: A Sentiment Analyzer with Enhanced Lexicon Mapping and Weighting Scheme for Unbalanced Data. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 628–632, Dublin, Ireland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Emotions Evoked by Common Words and Phrases: Using Mechanical Turk to Create an Emotion Lexicon.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, CAAGET ’10,</booktitle>
<pages>26--34</pages>
<contexts>
<context position="4699" citStr="Mohammad and Turney, 2010" startWordPosition="725" endWordPosition="729">, such as the use of upper case ratio and character repetitions2, positive and negative emoticons, informal expressions of laughters3, as well as the presence of exclamation and interrogative marks, negations, intensifiers 4. Finally we include features based on word count for 1000 large-scale word clusters built on English tweets5. Lexicon-based Features. The second group contains features calculated for each of the eight lexicons we consider in this study. These lexicons can be differentiated based on how they represent the information about prior polarity of words. The NRC Emotion Lexicon (Mohammad and Turney, 2010), the MPQA Lexicon (Wilson et al., 2005) and the Bing Liu Lexicon (Hu and Liu, 2004) provide lists of positive and negative words. We assign a positive score equal to 1 to the positive sentiment terms, and a negative score equal to 1 to the negative ones. Similarly, the NRC Hashtag Sentiment Lexicon and the Sentiment140 Lexicon provide a list of words with their sentiment association score, calculated as pointwise mutual information with respect to collections of positive and negative tweets (Mohammad et al., 2013). Positive and negative scores are associated, respectively, to positive and neg</context>
</contexts>
<marker>Mohammad, Turney, 2010</marker>
<rawString>Saif M. Mohammad and Peter D. Turney. 2010. Emotions Evoked by Common Words and Phrases: Using Mechanical Turk to Create an Emotion Lexicon. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, CAAGET ’10, pages 26–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
</authors>
<title>Nrc-canada: Building the state-of-theart in sentiment analysis of tweets.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>321--327</pages>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="1239" citStr="Mohammad et al., 2013" startWordPosition="180" endWordPosition="183">y and polarity (positive vs. negative) of a text (Pang and Lee, 2008). With the worldwide diffusion of social media, a huge amount of textual data has been made available, thus attracting the interest of researchers in this domain (Rosenthal et al., 2014). Sentiment analysis on such informal texts poses new challenges due to the presence of slang, misspelled words and micro-blogging features such as hashtags or links and traditional approaches may not be successfully exploited in this domain. Previous research has successfully exploited approaches based on lexical and micro-blogging features (Mohammad et al., 2013). In this study, we investigate a supervised approach including three kinds of features based on keywords and micro-blogging properties of tweets, sentiment lexicons and semantics. Rather than using word-sense disambiguation (Miura et al., 2014), we represent tweets in a distributional semantic model (DSM) (Vanzo et al., 2014), which is able to learn the context of usage of words analysing cooccurrences in large corpora. This paper describes our participation at the SemEval 2015 Sentiment Analysis in Twitter task (Rosenthal et al., 2015). We discuss methods and results of our experimental stud</context>
<context position="5219" citStr="Mohammad et al., 2013" startWordPosition="814" endWordPosition="818">ent the information about prior polarity of words. The NRC Emotion Lexicon (Mohammad and Turney, 2010), the MPQA Lexicon (Wilson et al., 2005) and the Bing Liu Lexicon (Hu and Liu, 2004) provide lists of positive and negative words. We assign a positive score equal to 1 to the positive sentiment terms, and a negative score equal to 1 to the negative ones. Similarly, the NRC Hashtag Sentiment Lexicon and the Sentiment140 Lexicon provide a list of words with their sentiment association score, calculated as pointwise mutual information with respect to collections of positive and negative tweets (Mohammad et al., 2013). Positive and negative scores are associated, respectively, to positive and negative 1The complete list of negation words provided by Christopher Potts in his tutorial on sentiment http://sentiment. christopherpotts.net/. 2These features usually plays the same role of intensifiers in informal writing contexts. 3i.e., sequences of “ah”. 4The list of booster words is the same used by Sentistrength: http://sentistrength.wlv.ac.uk/ 5Twitter Word Clusters: http://www.ark.cs.cmu. edu/TweetNLP/#resources sentiment, while the magnitude indicates the degree of association. We consider also the lexicon</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Saif Mohammad, Svetlana Kiritchenko, and Xiaodan Zhu. 2013. Nrc-canada: Building the state-of-theart in sentiment analysis of tweets. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 321–327, Atlanta, Georgia, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Novielli</author>
<author>Carlo Strapparava</author>
</authors>
<title>The Role of Affect Analysis in Dialogue Act Identification.</title>
<date>2013</date>
<journal>IEEE Transactions on Affective Computing,</journal>
<volume>4</volume>
<pages>451</pages>
<contexts>
<context position="7965" citStr="Novielli and Strapparava, 2013" startWordPosition="1237" endWordPosition="1240">he word classes defined in the Linguistic Inquiry and Word Count (LIWC) taxonomy, developed in the scope of psycholinguistic research (Pennebaker and Francis, 2001). LIWC organizes words into psychologically meaningful categories based on the assumption that words and language reflect most part of cognitive and emotional phenomena involved in communication. Previous research has shown how the language use varies with respect to the communicative intention, thus making possible to distinguish between objective and subjective statements as well as between agreement and disagreement expressions (Novielli and Strapparava, 2013). Therefore, we include word count features 6http://sentistrength.wlv.ac.uk/ 7http://it.wikipedia.org/wiki/Emoticon 596 for each word class in LIWC. Similarly, we include word count features for the emotion word classes in the NRC Emotion Lexicon. Semantic Features. Finally, we calculate features based on the Distributional Semantic Model (DSM). Given a set of 15M unlabelled downloaded tweets, we build a geometric space in which each word is represented as a mathematical point (Sahlgren, 2006). The similarity between words is computed as their closeness in the space. To represent a tweet in th</context>
</contexts>
<marker>Novielli, Strapparava, 2013</marker>
<rawString>Nicole Novielli and Carlo Strapparava. 2013. The Role of Affect Analysis in Dialogue Act Identification. IEEE Transactions on Affective Computing, 4:439– 451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion Mining and Sentiment Analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="686" citStr="Pang and Lee, 2008" startWordPosition="96" endWordPosition="99">g, Lexicon and Semantic Features Pierpaolo Basile and Nicole Novielli Department of Computer Science, University of Bari Aldo Moro Via, E. Orabona, 4 - 70125 Bari (Italy) {pierpaolo.basile,nicole.novielli}@uniba.it Abstract This paper describes the UNIBA team participation in the Sentiment Analysis in Twitter task (Task 10) at SemEval-2015. We propose a supervised approach relying on keyword, lexicon and micro-blogging features as well as representation of tweets in a word space. 1 Introduction Sentiment analysis is the study of the subjectivity and polarity (positive vs. negative) of a text (Pang and Lee, 2008). With the worldwide diffusion of social media, a huge amount of textual data has been made available, thus attracting the interest of researchers in this domain (Rosenthal et al., 2014). Sentiment analysis on such informal texts poses new challenges due to the presence of slang, misspelled words and micro-blogging features such as hashtags or links and traditional approaches may not be successfully exploited in this domain. Previous research has successfully exploited approaches based on lexical and micro-blogging features (Mohammad et al., 2013). In this study, we investigate a supervised ap</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion Mining and Sentiment Analysis. Foundations and trends in information retrieval, 2(1-2):1–135, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment Classification using Machine Learning Techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="3999" citStr="Pang et al., 2002" startWordPosition="619" endWordPosition="622">June 4-5, 2015. c�2015 Association for Computational Linguistics Keywords and micro-blogging features. Keyword-based features exploit tokens occurring in the tweets (Table 1). During the tokenization we replace the user mentions, URLs and hashtags with three metatokens, “ USER ”, “ URL ” and ” TAG ”, for which we also count the total occurrences. As for keywords, we consider unigrams and bigrams. To deal with negations, all the n-grams occurring in a negated context receive the neg suffix. A negated context is a tweet fragment starting with a negation word1 and ending with a punctuation mark (Pang et al., 2002). Moreover, we create features capturing typical aspects of micro-blogging, such as the use of upper case ratio and character repetitions2, positive and negative emoticons, informal expressions of laughters3, as well as the presence of exclamation and interrogative marks, negations, intensifiers 4. Finally we include features based on word count for 1000 large-scale word clusters built on English tweets5. Lexicon-based Features. The second group contains features calculated for each of the eight lexicons we consider in this study. These lexicons can be differentiated based on how they represen</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment Classification using Machine Learning Techniques. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 79–86, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pennebaker</author>
<author>M Francis</author>
</authors>
<title>Linguistic Inquiry and Word Count: LIWC.</title>
<date>2001</date>
<publisher>Erlbaum Publishers.</publisher>
<contexts>
<context position="7498" citStr="Pennebaker and Francis, 2001" startWordPosition="1170" endWordPosition="1173">ive multiple polarity scores if it occurs in more than one synset. In such cases, we select the most frequent sense for the lemma, with respect to its part-of-speech. Thanks to the availability of the objective scores, additional features can be computed to model the presence of neutral terms, as reported in (Basile and Novielli, 2014). Also the features based on SentiWordNet are calculated separately for affirmative and negated contexts. Finally, we consider the word classes defined in the Linguistic Inquiry and Word Count (LIWC) taxonomy, developed in the scope of psycholinguistic research (Pennebaker and Francis, 2001). LIWC organizes words into psychologically meaningful categories based on the assumption that words and language reflect most part of cognitive and emotional phenomena involved in communication. Previous research has shown how the language use varies with respect to the communicative intention, thus making possible to distinguish between objective and subjective statements as well as between agreement and disagreement expressions (Novielli and Strapparava, 2013). Therefore, we include word count features 6http://sentistrength.wlv.ac.uk/ 7http://it.wikipedia.org/wiki/Emoticon 596 for each word</context>
</contexts>
<marker>Pennebaker, Francis, 2001</marker>
<rawString>J. Pennebaker and M. Francis. 2001. Linguistic Inquiry and Word Count: LIWC. Erlbaum Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Alan Ritter</author>
<author>Preslav Nakov</author>
<author>Veselin Stoyanov</author>
</authors>
<title>SemEval-2014 Task 9: Sentiment Analysis in Twitter.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>73--80</pages>
<location>Dublin, Ireland,</location>
<contexts>
<context position="872" citStr="Rosenthal et al., 2014" startWordPosition="126" endWordPosition="129">basile,nicole.novielli}@uniba.it Abstract This paper describes the UNIBA team participation in the Sentiment Analysis in Twitter task (Task 10) at SemEval-2015. We propose a supervised approach relying on keyword, lexicon and micro-blogging features as well as representation of tweets in a word space. 1 Introduction Sentiment analysis is the study of the subjectivity and polarity (positive vs. negative) of a text (Pang and Lee, 2008). With the worldwide diffusion of social media, a huge amount of textual data has been made available, thus attracting the interest of researchers in this domain (Rosenthal et al., 2014). Sentiment analysis on such informal texts poses new challenges due to the presence of slang, misspelled words and micro-blogging features such as hashtags or links and traditional approaches may not be successfully exploited in this domain. Previous research has successfully exploited approaches based on lexical and micro-blogging features (Mohammad et al., 2013). In this study, we investigate a supervised approach including three kinds of features based on keywords and micro-blogging properties of tweets, sentiment lexicons and semantics. Rather than using word-sense disambiguation (Miura e</context>
<context position="2438" citStr="Rosenthal et al., 2014" startWordPosition="371" endWordPosition="374">of our experimental study for the overall polarity classification of tweets (message level subtask B). The Sentiment Analysis task focuses on English tweets. Data provided for training are annotated according to the overall polarity of each tweet (i.e., ’negative’, ’positive’ or ’neutral’). The system evaluation is performed on different test sets. In particular, the rank of the systems is calculated on the offical Twitter 2015 test set. Further evaluation is performed on a progress set including test instances from the previous edition of the task, to allow comparision with previous studies (Rosenthal et al., 2014). We build a supervised system based on our sentiment classifier for Italian tweets, which ranked 1st in both the polarity and subjectivity tasks at Evalita 2014 (Basile and Novielli, 2014). The paper is structured as follows: we introduce our system and report the details about features in Section 2. We describe the evaluation and the system setup in Section 3. We conclude by reporting results and discussion in Section 4. 2 System Description Our system is built upon our classifier for sentiment analysis of Italian tweets (Basile and Novielli, 2014). We adopt a supervised approach using Suppo</context>
<context position="15965" citStr="Rosenthal et al., 2014" startWordPosition="2518" endWordPosition="2521">49.81 63.67 59.62 51.78 55.43 59.18 89.16 71.14 63.41 (-2.37%) w/o semantic 84.12 54.62 66.24 58.16 53.70 55.84 61,.28 85.61 71.43 64.50 (-0.69%) w/o lexicons 83.31 52.89 64.70 60.92 39.73 48.09 58.14 58.14 70.00 60.93 (-6.19%) Table 4: System results for all feature settings and all classes on the official test set Twitter 2015. Test set AVG Rank Official 2015 (Fpos,Fneg) 12/40 61.55 Twitter 2014 65.11 25/40 LiveJournal 2014 70.05 - SMS 2013 65.50 - Twitter 2013 61.66 - Twitter 2014 Sarcasm 37.30 - Table 3: Task results. observed for systems participating in the previous edition of the task (Rosenthal et al., 2014) and can be observed for all systems in the current edition. However, our system had a greater than average performance drop and we are currently studying this issue. Observing the detailed scores for each class (first row of Table 4) we discover that the system performs better in the recognition of positive and neutral cases, in contrast with previous evidence from the experiment on the Italian corpus. To further investigate the predictive power of the features in our model, we perform an ablation test on the Twitter 2015 test set, for which organizers provided the gold standard. We remove ea</context>
</contexts>
<marker>Rosenthal, Ritter, Nakov, Stoyanov, 2014</marker>
<rawString>Sara Rosenthal, Alan Ritter, Preslav Nakov, and Veselin Stoyanov. 2014. SemEval-2014 Task 9: Sentiment Analysis in Twitter. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 73–80, Dublin, Ireland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Preslav Nakov</author>
<author>Svetlana Kiritchenko</author>
<author>Saif M Mohammad</author>
<author>Alan Ritter</author>
<author>Veselin Stoyanov</author>
</authors>
<title>SemEval-2015 Task 10: Sentiment Analysis in Twitter.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="1782" citStr="Rosenthal et al., 2015" startWordPosition="265" endWordPosition="268"> approaches based on lexical and micro-blogging features (Mohammad et al., 2013). In this study, we investigate a supervised approach including three kinds of features based on keywords and micro-blogging properties of tweets, sentiment lexicons and semantics. Rather than using word-sense disambiguation (Miura et al., 2014), we represent tweets in a distributional semantic model (DSM) (Vanzo et al., 2014), which is able to learn the context of usage of words analysing cooccurrences in large corpora. This paper describes our participation at the SemEval 2015 Sentiment Analysis in Twitter task (Rosenthal et al., 2015). We discuss methods and results of our experimental study for the overall polarity classification of tweets (message level subtask B). The Sentiment Analysis task focuses on English tweets. Data provided for training are annotated according to the overall polarity of each tweet (i.e., ’negative’, ’positive’ or ’neutral’). The system evaluation is performed on different test sets. In particular, the rank of the systems is calculated on the offical Twitter 2015 test set. Further evaluation is performed on a progress set including test instances from the previous edition of the task, to allow co</context>
</contexts>
<marker>Rosenthal, Nakov, Kiritchenko, Mohammad, Ritter, Stoyanov, 2015</marker>
<rawString>Sara Rosenthal, Preslav Nakov, Svetlana Kiritchenko, Saif M Mohammad, Alan Ritter, and Veselin Stoyanov. 2015. SemEval-2015 Task 10: Sentiment Analysis in Twitter. In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015, Denver, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
</authors>
<title>The Word-Space Model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in highdimensional vector spaces.</title>
<date>2006</date>
<tech>Ph.D. thesis.</tech>
<contexts>
<context position="8463" citStr="Sahlgren, 2006" startWordPosition="1308" endWordPosition="1309"> and subjective statements as well as between agreement and disagreement expressions (Novielli and Strapparava, 2013). Therefore, we include word count features 6http://sentistrength.wlv.ac.uk/ 7http://it.wikipedia.org/wiki/Emoticon 596 for each word class in LIWC. Similarly, we include word count features for the emotion word classes in the NRC Emotion Lexicon. Semantic Features. Finally, we calculate features based on the Distributional Semantic Model (DSM). Given a set of 15M unlabelled downloaded tweets, we build a geometric space in which each word is represented as a mathematical point (Sahlgren, 2006). The similarity between words is computed as their closeness in the space. To represent a tweet in the geometric space, we adopt the superposition operator (Smolensky, 1990), that is the vector sum of all the vectors of words occurring in the tweet. �� We use the tweet vector t as a semantic feature in training our classifier. In the same fashion, we build prototype vectors for each class based on the sentiment lexicons that provide prior polarity scores for words (i.e. SentiWordNet, SentiStrength, and the merge of NRC Hashtag and the Sentiment140). For example, the prototype vector for the p</context>
</contexts>
<marker>Sahlgren, 2006</marker>
<rawString>Magnus Sahlgren. 2006. The Word-Space Model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in highdimensional vector spaces. Ph.D. thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Smolensky</author>
</authors>
<title>Tensor product variable binding and the representation of symbolic structures in connectionist systems.</title>
<date>1990</date>
<journal>Artificial Intelligence,</journal>
<pages>46--1</pages>
<contexts>
<context position="8637" citStr="Smolensky, 1990" startWordPosition="1335" endWordPosition="1336">istrength.wlv.ac.uk/ 7http://it.wikipedia.org/wiki/Emoticon 596 for each word class in LIWC. Similarly, we include word count features for the emotion word classes in the NRC Emotion Lexicon. Semantic Features. Finally, we calculate features based on the Distributional Semantic Model (DSM). Given a set of 15M unlabelled downloaded tweets, we build a geometric space in which each word is represented as a mathematical point (Sahlgren, 2006). The similarity between words is computed as their closeness in the space. To represent a tweet in the geometric space, we adopt the superposition operator (Smolensky, 1990), that is the vector sum of all the vectors of words occurring in the tweet. �� We use the tweet vector t as a semantic feature in training our classifier. In the same fashion, we build prototype vectors for each class based on the sentiment lexicons that provide prior polarity scores for words (i.e. SentiWordNet, SentiStrength, and the merge of NRC Hashtag and the Sentiment140). For example, the prototype vector for the positive class ��� p��� based on SentiStrength is obtained by summing up all the vectors of words with positive prior polarity in the SentiStrength lexicon. We use three proto</context>
</contexts>
<marker>Smolensky, 1990</marker>
<rawString>Paul Smolensky. 1990. Tensor product variable binding and the representation of symbolic structures in connectionist systems. Artificial Intelligence, 46(1-2):159–216, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Thelwall</author>
<author>Kevan Buckley</author>
<author>Georgios Paltoglou</author>
<author>Di Cai</author>
<author>Arvid Kappas</author>
</authors>
<title>Sentiment in Short Strength Detection Informal Text.</title>
<date>2010</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>61</volume>
<issue>12</issue>
<marker>Thelwall, Buckley, Paltoglou, Di Cai, Kappas, 2010</marker>
<rawString>Mike Thelwall, Kevan Buckley, Georgios Paltoglou, Di Cai, and Arvid Kappas. 2010. Sentiment in Short Strength Detection Informal Text. Journal of the American Society for Information Science and Technology, 61(12):2544–2558, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Vanzo</author>
<author>Danilo Croce</author>
<author>Roberto Basili</author>
</authors>
<title>A context-based model for Sentiment Analysis in Twitter.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,</booktitle>
<pages>2345--2354</pages>
<location>Dublin, Ireland,</location>
<contexts>
<context position="1567" citStr="Vanzo et al., 2014" startWordPosition="229" endWordPosition="232">presence of slang, misspelled words and micro-blogging features such as hashtags or links and traditional approaches may not be successfully exploited in this domain. Previous research has successfully exploited approaches based on lexical and micro-blogging features (Mohammad et al., 2013). In this study, we investigate a supervised approach including three kinds of features based on keywords and micro-blogging properties of tweets, sentiment lexicons and semantics. Rather than using word-sense disambiguation (Miura et al., 2014), we represent tweets in a distributional semantic model (DSM) (Vanzo et al., 2014), which is able to learn the context of usage of words analysing cooccurrences in large corpora. This paper describes our participation at the SemEval 2015 Sentiment Analysis in Twitter task (Rosenthal et al., 2015). We discuss methods and results of our experimental study for the overall polarity classification of tweets (message level subtask B). The Sentiment Analysis task focuses on English tweets. Data provided for training are annotated according to the overall polarity of each tweet (i.e., ’negative’, ’positive’ or ’neutral’). The system evaluation is performed on different test sets. I</context>
</contexts>
<marker>Vanzo, Croce, Basili, 2014</marker>
<rawString>Andrea Vanzo, Danilo Croce, and Roberto Basili. 2014. A context-based model for Sentiment Analysis in Twitter. In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 2345–2354, Dublin, Ireland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing Contextual Polarity in Phrase-level Sentiment Analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>347--354</pages>
<contexts>
<context position="4739" citStr="Wilson et al., 2005" startWordPosition="733" endWordPosition="736">acter repetitions2, positive and negative emoticons, informal expressions of laughters3, as well as the presence of exclamation and interrogative marks, negations, intensifiers 4. Finally we include features based on word count for 1000 large-scale word clusters built on English tweets5. Lexicon-based Features. The second group contains features calculated for each of the eight lexicons we consider in this study. These lexicons can be differentiated based on how they represent the information about prior polarity of words. The NRC Emotion Lexicon (Mohammad and Turney, 2010), the MPQA Lexicon (Wilson et al., 2005) and the Bing Liu Lexicon (Hu and Liu, 2004) provide lists of positive and negative words. We assign a positive score equal to 1 to the positive sentiment terms, and a negative score equal to 1 to the negative ones. Similarly, the NRC Hashtag Sentiment Lexicon and the Sentiment140 Lexicon provide a list of words with their sentiment association score, calculated as pointwise mutual information with respect to collections of positive and negative tweets (Mohammad et al., 2013). Positive and negative scores are associated, respectively, to positive and negative 1The complete list of negation wor</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing Contextual Polarity in Phrase-level Sentiment Analysis. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 347–354.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>