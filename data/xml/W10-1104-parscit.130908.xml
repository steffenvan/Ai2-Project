<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012109">
<title confidence="0.9986655">
Using Domain Knowledge about Medications to Correct Recognition Errors
in Medical Report Creation
</title>
<author confidence="0.923751">
Stephanie Schreitter
Alexandra Klein
Johannes Matiasek
</author>
<affiliation confidence="0.905527">
Austrian Research Institute
for Artificial Intelligence (OFAI)
</affiliation>
<address confidence="0.881393">
Freyung 6/6
1010 Vienna, Austria
</address>
<email confidence="0.997424">
firstname.lastname@ofai.at
</email>
<author confidence="0.988478">
Harald Trost
</author>
<affiliation confidence="0.98949625">
Section for Artificial Intelligence
Center for Med. Statistics, Informatics,
and Intelligent Systems
Medical University of Vienna
</affiliation>
<address confidence="0.8707995">
Freyung 6/2
1010 Vienna, Austria
</address>
<email confidence="0.998342">
harald.trost@meduniwien.ac.at
</email>
<sectionHeader confidence="0.995629" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999939129032258">
We present an approach to analysing auto-
matic speech recognition (ASR) hypotheses
for dictated medical reports based on back-
ground knowledge. Our application area is
prescriptions of medications, which are a fre-
quent source of misrecognitions: In a sam-
ple report corpus, we found that about 40%
of the active substances or trade names and
dosages were recognized incorrectly. In about
25% of these errors, the correct string of words
was contained in the word graph. We have
built a knowledge base of medications based
on information contained in the Unified Med-
ical Language System (UMLS), consisting
of trade names, active substances, strengths
and dosages. From this, we generate a va-
riety of linguistic realizations for prescrip-
tions. Whenever an inconsistency in a pre-
scription is encountered on the best path of
the word graph, the system searches for alter-
native paths which contain valid linguistic re-
alizations of prescriptions consistent with the
knowledge base. If such a path exists, a new
concept edge with a better score is added to
the word graph, resulting in a higher plausi-
bility for this reading. The concept edge can
be used for rescoring the word graph to obtain
a new best path. A preliminary evaluation led
to encouraging results: in nearly half of the
cases where the word graph contained the cor-
rect variant, the correction was successful.
</bodyText>
<sectionHeader confidence="0.999332" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999802055555556">
Automatic speech recognition (ASR) is widely used
in the domain of medical reporting. Users appreciate
the fact that the records can be accessed immediately
after their creation and that speech recognition pro-
vides a hands-free input mode, which is important as
physicians often simultaneously handle documents
such as notes and X-rays (Alapetite et al., 2009).
A drawback of using ASR is the fact that speech-
recognition errors have to be corrected manually by
medical experts before the resulting texts can be
used for electronic patient records, quality control
and billing purposes. This manual post-processing is
time-consuming, which slows down hospital work-
flows.
A number of recognition errors could be avoided
by incorporating explicit domain knowledge. We
consider prescriptions of medications a good start-
ing point as they are common and frequent in the
various medical fields. Furthermore, they contain
trade names and dosages, i.e. proper names and dig-
its, which are frequently misrecognized by ASR in
all domains.
For our approach, we have extracted and adapted
information about medications from the Unified
Medical Language System (UMLS) (Lindberg et al.,
1993). This data contains information about trade
names, active substances, strengths and dosages and
can easily be modified, e.g. when new medications
are released.
In the first step, we assessed the potential for im-
provement by analyzing a sample corpus of medical
reports. It turned out that in 4383 dictated reports
which were processed by a speech-recognition sys-
tem, the word-error rate for medications was about
40%, which is slightly higher than the the average
word-error rate of the reports. Examining a sample
</bodyText>
<page confidence="0.995413">
22
</page>
<note confidence="0.756485">
Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 22–28,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999578">
of word graphs for the reports, we realized that in
about 30% of these errors, the correct string of words
was contained in the word graph, but not ranked as
the best path.
In the following sections, we will first give
an overview of previous approaches to detecting
speech-recognition errors and semantic rescoring of
word-graph hypotheses. Then, we will describe
how we have adapted information about medications
from the UMLS to enhance the word graph with
concept nodes representing domain-specific infor-
mation. Finally, we will illustrate the potential for
improving the speech-recognition result by means
of an evaluation of word graphs for medical reports
which were processed by our system.
</bodyText>
<subsectionHeader confidence="0.612614">
2 Extraction of Medication Information,
Error Handling and Semantic Rescoring
</subsectionHeader>
<bodyText confidence="0.999941233766234">
(Gold et al., 2008) gives an overview on extract-
ing structured medication information from clinical
narratives. Extracted medication information may
serve as a base for quality control, pharmaceutical
research and the automatic creation of Electronic
Health Records (EHR) from clinical narratives. The
i2b2 Shared Task 2009 focussed on medication ex-
traction, e.g. (Patrick and Li, 2009; Halgrim et al.,
2010). These approaches work on written narrative
texts from clinical settings, which may have been
typed by physicians, transcribed by medical tran-
scriptionists or recognized by ASR and corrected by
medical transcriptionists.
In contrast, our approach takes as input word
graphs produced by an ASR system from dictated
texts and aims at minimizing the post-processing re-
quired by human experts.
Speech-recognition systems turn acoustic input
into word graphs, which are directed acyclic graphs
representing the recognized spoken forms and their
confidence scores (Oerder and Ney, 1993). In most
speech-recognition systems, meaning is implicitly
represented in the language model (LM), indicat-
ing the plausibility of sequences of words in terms
of n-grams. It has often been stated that the intro-
duction of an explicit representation of the utterance
meaning will improve recognition results. Naturally,
this works best in limited domains: the larger an
application domain, the more difficult it is to build
an optimal knowledge representation for all possi-
ble user utterances. Limited domains seem to be
more rewarding with regard to coverage and perfor-
mance. Consequently, combining speech recogni-
tion and speech understanding has so far mostly re-
sulted in applications in the field of dialogue systems
where knowledge about the domain is represented in
terms of the underlying database, e.g. (Seneff and
Polifroni, 2000).
Several approaches have investigated the poten-
tial of improving the mapping between the user ut-
terance and the underlying database by constructing
a representation of the utterance meaning. Mean-
ing analysis is either a separate post-processing step
or an integral part of the recognition process. In
some approaches, the recognition result is analyzed
with regards to content to support the dialogue man-
ager in dealing with inconsistencies (Macherey et
al., 2003). As far as dictated input is concerned,
which is not controlled by a dialogue manager, (Voll,
2006) developed a post-ASR error-detection mech-
anism for radiology reports. The hybrid approach
uses statistical as well as rule-based methods. The
knowledge source UMLS is employed for measur-
ing the semantic distance between concepts and for
assessing the coherence of the recognition result.
In other approaches, the analysis of meaning
is integrated into the recognition process. Se-
mantic confidence measurement annotates recogni-
tion hypotheses with additional information about
their assumed plausibility based on semantic scores
(Zhang and Rudnicky, 2001; Sarikaya et al., 2003).
(Gurevych and Porzel, 2003; Gurevych et al., 2003)
present a rescoring approach where the hypothe-
ses in the word graph are reordered according to
semantic information. Usually, conceptual parsers
are employed which construct a parse tree of con-
cepts representing the input text for mapping be-
tween the recognition result and the underlying rep-
resentation. Semantic language modeling (Wanget
al., 2004; Buehler et al., 2005) enhances the lan-
guage model to incorporate sequences of concepts
which are considered coherent and typical for a spe-
cific context. In these approaches, the representa-
tions of the underlying knowledge are created spe-
cially for the applications or are derived from a text
corpus.
In our approach, we aim at developing a prototype
</bodyText>
<page confidence="0.988191">
23
</page>
<bodyText confidence="0.999985454545455">
for integrating available knowledge sources into the
analysis of the word graph during the recognition
process. We have decided not to integrate the com-
ponent directly into the ASR system but to introduce
a separate post-processing step for the recognition of
information about medications with the word graphs
as interface. This makes it easier to update the med-
ication knowledge base, e.g. if new medications are
released. Furthermore, it is not necessary to retrain
the ASR system language model for each new ver-
sion of the medication knowledge base.
</bodyText>
<sectionHeader confidence="0.817994" genericHeader="method">
3 Knowledge Base and Text Corpus
</sectionHeader>
<bodyText confidence="0.99997775">
For our approach, we prepared a knowledge base
concerning medications and dosages, and we used
a corpus of medical reports, dictated by physicians
in hospitals. The ASR result and a manual transcrip-
tion is available for each report. For a subset of the
corpus, word graphs could be obtained. By aligning
the recognition result with the manual transcriptions,
error regions can be extracted.
</bodyText>
<subsectionHeader confidence="0.998865">
3.1 Knowledge Base
</subsectionHeader>
<bodyText confidence="0.996961846153846">
As it is our aim to find correct dosages of med-
ications in the word graph, we built a domain-
specific knowledge base which contains medica-
tions and strengths as they occur in prescriptions.
In our sample of medical reports, about 1/3 of the
medications occurred as active ingredients while the
rest were trade names. Therefore, both had to be
covered in our knowledge base which is based on
RxNorm (Liu et al., 2005). RxNorm is a standard-
ized nomenclature for clinical drugs and drug de-
livery devices and part of UMLS, ensuring a broad
coverage of trade names and active ingredients. Of
several available versions of RxNorm, the semantic
branded drug form is the most suitable one for our
purposes as it contains pharmaceutical ingredients,
strengths, and trade names. For example, the trade
name Synthroid® is listed as follows:
Thyroxine 0.025 MG Oral Tablet [Synthroid R�J
Thyroxine is the active ingredient with the dosage
value 0.025 and the dosage unit milligrams. The
dosage unit form is oral tablet.
We used a RxNorm version with 1,508 active sub-
stances and 7,688 trade names (11,263 trade names
counting the different dosages). The active ingre-
dients in RxNorm are associated with Anatomical
Therapeutic Chemical (ATC) Codes.
</bodyText>
<subsectionHeader confidence="0.998503">
3.2 Sample Corpus
</subsectionHeader>
<bodyText confidence="0.999980636363636">
The corpus is a random sample of 924 clinical re-
ports which were dictated by physicians from var-
ious specialties and hospitals. The dications were
processed by an ASR system and transcribed by hu-
man experts. Word graphs marked with the best path
(indicating the highest acoustic and language-model
scores) represent the recognition result. Tradenames
are part of the recognition lexicon, but they are fre-
quently misrecognized.
Of the 9196 medications (i.e. trade names and
active substances) in RxNorm, only 330 (3.6%) ap-
peared in the sample corpus.
We searched the corpus for recognition errors
concerning trade names, active ingredients and their
dosages by comparing the manual transcriptions to
the best paths in the word graphs, and a list of the
mismatches (i.e. recognition errors) and their fre-
quencies was compiled. It turned out that 39.3% of
all trade names and active ingredients were recog-
nized incorrectly. The average ASR word-error rate
of the reports was 38.1%. Aproximately 1-2% of the
trade names were not covered by RxNorm.
</bodyText>
<sectionHeader confidence="0.998506" genericHeader="method">
4 Approach
</sectionHeader>
<bodyText confidence="0.999927857142857">
Our approach consists of a generation mechanism
which anticipates possible spoken forms for the
content of the knowledge base. The word graphs
are searched for trade names or active substances
and, subsequently, matching dosages. New concept
edges are inserted if valid prescriptions are found in
the word graph.
</bodyText>
<subsectionHeader confidence="0.998024">
4.1 Detecting Medications in the Word Graph
</subsectionHeader>
<bodyText confidence="0.999951428571428">
The (multi-edge) word graphs are scanned, and the
words associated with each edge are compared to the
medications in the knowledge base. Figure 1 shows
a word graph consisting of hypotheses generated by
ASR, which is the input to our system. The dashed
edges indicate the best path, while dotted lines are
hypotheses which are not on the best path.
</bodyText>
<page confidence="0.997851">
24
</page>
<figureCaption confidence="0.999234">
Figure 1: Sample word graph fragment
</figureCaption>
<bodyText confidence="0.999105666666667">
In case a match, i.e. a trade name or an active sub-
stance, is found, all edges succeeding the medica-
tion edge are searched for dosage values and dosage
units. So far, we only examine the context to the
right-hand side; in the data, we did not encounter
any medications where the dosage occurred before
the trade name or active substance. The following
kinds of fillers between the trade name or active sub-
stance and the dosage are allowed: ’to’ and ’of’
as well as non-utterances such as hesitation, noise
and silence; in the corpus, we did not encounter any
other fillers.
</bodyText>
<subsectionHeader confidence="0.999403">
4.2 Generation of Spoken Forms and Mapping
</subsectionHeader>
<bodyText confidence="0.999333129032258">
The medication found in the word graph is looked up
in RxNorm, and all possible spoken forms of valid
dosage values and dosage units for this medication
are generated. Spoken forms for the medication
names consist of the trade names and the active sub-
stances. Variation in the pronunciation of the trade
names or active substances is handled by the ASR
recognition lexicon. For generating spoken forms of
the dosage values, finite-state tools were used. For
dosage units, we wrote a small grammar. Looking
at two examples, the medication Synthroid® and
Colace® (the latter appears in the word graphs in
Figure 2 and Figure 1), the spoken forms shown in
Table 1 are generated. Each box contains the al-
ternative spoken variants. Synthroid® contains the
active substance Thyroxine and Colace® contains
the active substance Docusate; users may either re-
fer to the trade name or the active substance, so both
possibilities are generated for each medication and
dosage. RxNorm does not contain the dosage unit
’mcg’ (micrograms), which occurred in the reports.
Therefore, microgram dosage values were converted
to milligrams. Since both ’miligram(s)’ and ’mi-
crogram(s)’ may occur for Synthroid R�, dosage val-
ues for both dosage units are generated. Although
strictly, ’twenty five’ and ’twenty-five’ are identical
spoken forms, both versions may appear in the word
graph and thus are provided by our system.
Sometimes, a medication may contain several ac-
tive substances, e.g. Hyzaar R�, a medication against
high blood pressure:
</bodyText>
<footnote confidence="0.6660015">
Hydrochlorothiazide 12.5 MG /Losartan 50 MG
Oral Tablet [Hyzaar]
</footnote>
<page confidence="0.990851">
25
</page>
<table confidence="0.985541666666667">
trade name/ dosage value dosage unit
active
substance
’Synthroid’ ’zero point zero two five’ ’milligram’
’Thyroxine’ ’zero point O two five’ ’milligrams’
’O point zero two five’
’O point O two five’
’point zero two five’
’point O two five’
’twenty five’ ’microgram’
’twenty-five’ ’micrograms’
’two five’
’Colace’ ’one hundred’ ’miligram’
’Docusate’ ’a hundred’ ’miligrams’
’hundred’
</table>
<tableCaption confidence="0.99995">
Table 1: Generated spoken forms found in the word graph
</tableCaption>
<bodyText confidence="0.9999618">
In these cases, the generation of possible spoken
forms also includes different permutations of sub-
stances, as well as a spoken forms containing the
dosage unit either only at the end or after each value
if the dosage unit is identical.
</bodyText>
<subsectionHeader confidence="0.997166">
4.3 Inserting Concept Edges
</subsectionHeader>
<bodyText confidence="0.999982366666667">
The sequences of words which constitute the word
graph are compared to the spoken forms generated
for the RxNorm knowledge base. The active sub-
stances or trade names serve as a starting point: in
case a trade name is found in the word graph, the
spoken forms for dosages of all active substances are
generated in all permutations. If an active substance
is found in the word graph, only the spoken forms
for the substance dosage are searched in the word
graph.
A new concept edge is inserted into the word
graph for each path matching one of the generated
spoken forms of the medications data base. The in-
serted concept edges span from the first matching
node to the last matching node on the path. Fig-
ure 2 shows the word graph from Figure 1 with an in-
serted concept edge (in bold). For each inserted con-
cept edge, new concept-edge attributes are assigned
containing the IDs of the original edges as children,
their added scores plus an additional concept score
and the sequence of words. Since no large-scale ex-
periments have yet been carried out, so far the con-
cept score which is added to the individual scores of
the children is an arbitrary number which improves
the score of the medication subpath in constrast to
paths which do not contain valid medication infor-
mation. If several competing medication paths are
found, a concept edge is inserted for each path, and
the concept edges can be ranked according to their
acoustic and language-model scores.
</bodyText>
<sectionHeader confidence="0.990964" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.998766428571429">
In the first step, we examined a report sample in or-
der to determine if there are cases where a valid pre-
scription is recognised although the physician did
not mention a prescription. We did not encounter
this phenomenon in our report corpus.
We then applied our method to a sample of 924
word graphs. In this sample,
</bodyText>
<listItem confidence="0.9706085">
• 481 valid dosages could be found, although
• only 325 of these were on the best path.
</listItem>
<bodyText confidence="0.999734866666667">
With our approach, for the 156 prescriptions
(32%) which were not on the best path, alternatives
could be reconstructed from the word graph. Based
on the inserted concept edges, the best path can be
rescored.
In order to measure recall, i.e. how many of all
existing prescriptions in the reports can be detected
with our knowledge base, we manually checked
a sample of 132 reports (containing manual tran-
scriptions and ASR results). In this sample, 85 er-
rors concerning medications and/or prescriptions oc-
curred. For 19 of the 85 errors, the correct result was
contained in the word graph. For 8 errors, it could
be reconstructed. So about 9% of the errors concern-
ing medications can be corrected in our sample. For
the cases where the prescription could not be recon-
structed although it was contained in the word graph,
an analysis of the errors is shown in Table 2.
Since new medications are constantly being re-
leased, and trade names change frequently, mis-
matches may be due to the fact that our version of
RxNorm was from a more recent point in time than
the report corpus. We assume that under real-world
conditions, both RxNorm and the medications pre-
scribed by physicians reflect the current situation.
Some problems concerning medication names
and dosage units were caused by missing spoken
forms containing abbreviations, e.g. of dosage units
(mg vs. mg/ml) or names (Lantus vs. Lantus in-
sulin). Here, the coverage needs to be improved.
</bodyText>
<page confidence="0.997021">
26
</page>
<figureCaption confidence="0.5678358">
Figure 2: Sample word graph fragment with inserted concept node (left)
Table 2: Error types found in manual evaluation
type of error # example
Word Graph RxNorm
differences in medication names 3 Cardizem CD 120 mg Cardizem 120 mg
between the knowledge base and the word graph
differences in dosage values 4 Tapazole 60 mg Tapazole 10 mg
between the knowledge base and the word graph
differences in dosage units 4 Epogen 20000 units Epogen 20000 ml
between the knowledge base and the word graph
</figureCaption>
<bodyText confidence="0.99980775">
There are also cases where two medications appear
in the word graph, and both had the valid prescrip-
tion strength, therefore the system was not able to
determine the correct medication.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99987935">
In this paper, we present an attempt to reduce
the number of speech-recognition errors concern-
ing prescriptions of medications based on a domain-
specific knowledge base. Our approach uses word
graphs as input and creates new versions of the word
graph with inserted concept edges if more plausi-
ble prescriptions are found. The concept edges can
be used for rescoring the best path. An evaluation
showed that 32% of prescriptions found in the word
graphs were not on the best path but could be re-
constructed. The manual evaluation of 132 reports
shows that our method covers 42% of the prescrip-
tions which are actually spoken during the dictation.
At present, we have only investigated the reduc-
tion of medication misrecognitions in our evalua-
tion. In a larger evaluation, we will determine the ac-
tual impact of our method on the word-error rate of
medical reports. Furthermore, we are working on in-
tegrating additional available knowledge sources so
that the plausibility of prescriptions can also be as-
</bodyText>
<page confidence="0.992679">
27
</page>
<bodyText confidence="0.999892">
sessed from a broader medical point of view, e.g. in
case two subsequent prescriptions are encountered
in the word graph which are incompatible due to
drug interactions. As a next step, the system can
be extended to compare the prescriptions with the
patient record, e.g. if a patient has medication al-
lergies. So far, our simple solution integrating only
available, constantly updated knowledge about med-
ications has already turned out to be a good starting
point for rescoring word graphs based on domain
knowledge.
</bodyText>
<sectionHeader confidence="0.997383" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999954083333333">
The work presented here has been carried out in
the context of the Austrian KNet competence net-
work COAST. We gratefully acknowledge funding
by the Austrian Federal Ministry of Economics and
Labour, and ZIT Zentrum fuer Innovation und Tech-
nologie, Vienna. The Austrian Research Institute
for Artificial Intelligence is supported by the Aus-
trian Federal Ministry for Transport, Innovation, and
Technology and by the Austrian Federal Ministry
for Science and Research. The authors would like
to thank the anonymous reviewers for their helpful
comments.
</bodyText>
<sectionHeader confidence="0.995467" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981375776315789">
A. Alapetite, A., H.B. Andersen, H.B. and M. Hertzumb.
Acceptance of speech recognition by physicians: A
survey of expectations, experiences, and social in-
fluence. International Journal of Human-Computer
Studies 67(1) (2009) 36–49
D. B¨uhler, W. Minker and A. Elciyanti. Us-
ing language modelling to integrate speech
recognition with a flat semantic analysis. In:
6th SIGdial Workshop on Discourse and Di-
alogue, Lisbon, Portugal (September 2005)
http://www.sigdial.org/workshops/workshop6/proceed-
ings/pdf/86-paper.pdf.
S. Gold, N. Elhadad, X. Zhu, J.J. Cimino, G. Hripcsak.
Extracting Structured Medication Event Information
from Discharge Summaries. In: Proceedings of the
AMIA 2008 Symposium.
I. Gurevych and R. Porzel. Using knowledge-based
scores for identifying best speech recognition hy-
pothesis. In: Proceedings of ISCA Tutorial and
Research Workshop on Error Handling in Spoken
Dialogue Systems, Chateau-d’Oex-Vaud, Switzer-
land (2003) 77–81 http://proffs.tk.informatik.tu-
darmstadt.de/TK/abstracts.php3?lang=en&amp;bibtex=1&amp;-
paperID=431.
R. Porzel, I. Gurevych and C. M¨uller. Ontology-based
contextual coherence scoring. Technical report, Euro-
pean Media Laboratory, Heidelberg, Germany (2003)
http://citeseer.ist.psu.edu/649012.html.
S.R. Halgrim, F. Xia, I. Solti, E. Cadag and O. Uzuner.
Statistical Extraction of Medication Information from
Clinical Records. In: Proc. ofAMIA Summit on Trans-
lational Bioinformatics, San Francisco, CA, March
10-12, 2010.
D.A. Lindberg, B.L. Humphreys and A.T. McCray. The
unified medical language system. Methods of In-
formation in Medicine 32(4) (August 1993) 281–291
http://www.nlm.nih.gov/research/umls/.
S. Liu, W. Ma, R. Moore, V. Ganesan and S. Nelson.
Rxnorm: Prescription for electronic drug information
exchange. IT Professional 7(5) (September/October
2005) 17–23
K. Macherey, O. Bender and H. Ney. Multi-level er-
ror handling for tree based dialogue course man-
agement. In: Proceedings of ISCA Tutorial and
Research Workshop on Error Handling in Spo-
ken Dialogue Systems, Chateau-d’Oex-Vaud, Switzer-
land (2003) 123–128, http://www-i6.informatik.rwth-
aachen.de/˜bender/papers/isca tutorial 2003.pdf.
M. Oerder and H. Ney. Word graphs: An efficient inter-
face between continuous speech recognition and lan-
guage understanding. In: Proc. IEEE ICASSP’93. Vol-
ume 2. 119–122.
J. Patrick and M. Li. A Cascade Approach to Extracting
Medication Events. In: Proc. Australasian Language
Technology Workshop (ALTA) 2009.
R. Sarikaya, Y. Gao and M. Picheny. Word level confi-
dence measurement using semantic features. In: Proc.
of IEEE ICASSP2003. Volume 1. (April 2003) 604–
607.
S. Seneff and J. Polifroni. Dialogue Management in the
MERCURY Flight Reservation System. In: Satel-
lite Dialogue Workshop, ANLP-NAACL, Seattle (April
2000).
K.D. Voll. A Methodology of Error Detection:
Improving Speech Recognition in Radiology.
PhD thesis, Simon Fraser University (2006)
http://ir.lib.sfu.ca/handle/1892/2734.
K. Wang, Y.Y. Wang and A. Acero. Use and acquisition
of semantic language model. In: HLT-NAACL. (2004)
http://www.aclweb.org/anthology-new/N/N04/N04-
3011.pdf.
R. Zhang and A.I. Rudnicky. Word level confi-
dence annotation using combinations of fea-
tures. In: Proceedings of Eurospeech. (2001)
http://www.speech.cs.cmu.edu/Communicator/papers/-
RecoConf2001.pdf.
</reference>
<page confidence="0.999067">
28
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.148473">
<title confidence="0.881987666666667">Using Domain Knowledge about Medications to Correct Recognition Errors in Medical Report Creation Stephanie</title>
<author confidence="0.702227">Alexandra Johannes</author>
<affiliation confidence="0.928609">Austrian Research for Artificial Intelligence</affiliation>
<address confidence="0.97564">Freyung 1010 Vienna,</address>
<email confidence="0.996176">firstname.lastname@ofai.at</email>
<author confidence="0.731797">Harald</author>
<affiliation confidence="0.92127825">Section for Artificial Center for Med. Statistics, and Intelligent Medical University of</affiliation>
<address confidence="0.925944">Freyung 1010 Vienna,</address>
<email confidence="0.995679">harald.trost@meduniwien.ac.at</email>
<abstract confidence="0.99885390625">We present an approach to analysing automatic speech recognition (ASR) hypotheses for dictated medical reports based on background knowledge. Our application area is prescriptions of medications, which are a frequent source of misrecognitions: In a sample report corpus, we found that about 40% of the active substances or trade names and dosages were recognized incorrectly. In about 25% of these errors, the correct string of words was contained in the word graph. We have built a knowledge base of medications based on information contained in the Unified Medical Language System (UMLS), consisting of trade names, active substances, strengths and dosages. From this, we generate a variety of linguistic realizations for prescriptions. Whenever an inconsistency in a prescription is encountered on the best path of the word graph, the system searches for alternative paths which contain valid linguistic realizations of prescriptions consistent with the knowledge base. If such a path exists, a new concept edge with a better score is added to the word graph, resulting in a higher plausibility for this reading. The concept edge can be used for rescoring the word graph to obtain a new best path. A preliminary evaluation led to encouraging results: in nearly half of the cases where the word graph contained the correct variant, the correction was successful.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Alapetite</author>
<author>H B Andersen A</author>
<author>H B</author>
<author>M Hertzumb</author>
</authors>
<title>Acceptance of speech recognition by physicians: A survey of expectations, experiences, and social influence.</title>
<date>2009</date>
<journal>International Journal of Human-Computer Studies</journal>
<volume>67</volume>
<issue>1</issue>
<pages>36--49</pages>
<contexts>
<context position="2231" citStr="Alapetite et al., 2009" startWordPosition="336" endWordPosition="339">he concept edge can be used for rescoring the word graph to obtain a new best path. A preliminary evaluation led to encouraging results: in nearly half of the cases where the word graph contained the correct variant, the correction was successful. 1 Introduction Automatic speech recognition (ASR) is widely used in the domain of medical reporting. Users appreciate the fact that the records can be accessed immediately after their creation and that speech recognition provides a hands-free input mode, which is important as physicians often simultaneously handle documents such as notes and X-rays (Alapetite et al., 2009). A drawback of using ASR is the fact that speechrecognition errors have to be corrected manually by medical experts before the resulting texts can be used for electronic patient records, quality control and billing purposes. This manual post-processing is time-consuming, which slows down hospital workflows. A number of recognition errors could be avoided by incorporating explicit domain knowledge. We consider prescriptions of medications a good starting point as they are common and frequent in the various medical fields. Furthermore, they contain trade names and dosages, i.e. proper names and</context>
</contexts>
<marker>Alapetite, A, B, Hertzumb, 2009</marker>
<rawString>A. Alapetite, A., H.B. Andersen, H.B. and M. Hertzumb. Acceptance of speech recognition by physicians: A survey of expectations, experiences, and social influence. International Journal of Human-Computer Studies 67(1) (2009) 36–49</rawString>
</citation>
<citation valid="true">
<authors>
<author>D B¨uhler</author>
<author>W Minker</author>
<author>A Elciyanti</author>
</authors>
<title>Using language modelling to integrate speech recognition with a flat semantic analysis.</title>
<date>2005</date>
<booktitle>In: 6th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<location>Lisbon, Portugal</location>
<note>http://www.sigdial.org/workshops/workshop6/proceedings/pdf/86-paper.pdf.</note>
<marker>B¨uhler, Minker, Elciyanti, 2005</marker>
<rawString>D. B¨uhler, W. Minker and A. Elciyanti. Using language modelling to integrate speech recognition with a flat semantic analysis. In: 6th SIGdial Workshop on Discourse and Dialogue, Lisbon, Portugal (September 2005) http://www.sigdial.org/workshops/workshop6/proceedings/pdf/86-paper.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gold</author>
<author>N Elhadad</author>
<author>X Zhu</author>
<author>J J Cimino</author>
<author>G Hripcsak</author>
</authors>
<title>Extracting Structured Medication Event Information from Discharge Summaries. In:</title>
<date>2008</date>
<booktitle>Proceedings of the AMIA</booktitle>
<note>Symposium.</note>
<contexts>
<context position="4561" citStr="Gold et al., 2008" startWordPosition="697" endWordPosition="700">e following sections, we will first give an overview of previous approaches to detecting speech-recognition errors and semantic rescoring of word-graph hypotheses. Then, we will describe how we have adapted information about medications from the UMLS to enhance the word graph with concept nodes representing domain-specific information. Finally, we will illustrate the potential for improving the speech-recognition result by means of an evaluation of word graphs for medical reports which were processed by our system. 2 Extraction of Medication Information, Error Handling and Semantic Rescoring (Gold et al., 2008) gives an overview on extracting structured medication information from clinical narratives. Extracted medication information may serve as a base for quality control, pharmaceutical research and the automatic creation of Electronic Health Records (EHR) from clinical narratives. The i2b2 Shared Task 2009 focussed on medication extraction, e.g. (Patrick and Li, 2009; Halgrim et al., 2010). These approaches work on written narrative texts from clinical settings, which may have been typed by physicians, transcribed by medical transcriptionists or recognized by ASR and corrected by medical transcri</context>
</contexts>
<marker>Gold, Elhadad, Zhu, Cimino, Hripcsak, 2008</marker>
<rawString>S. Gold, N. Elhadad, X. Zhu, J.J. Cimino, G. Hripcsak. Extracting Structured Medication Event Information from Discharge Summaries. In: Proceedings of the AMIA 2008 Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Gurevych</author>
<author>R Porzel</author>
</authors>
<title>Using knowledge-based scores for identifying best speech recognition hypothesis. In:</title>
<date>2003</date>
<booktitle>Proceedings of ISCA Tutorial and Research Workshop on Error Handling in Spoken Dialogue Systems,</booktitle>
<pages>77--81</pages>
<location>Chateau-d’Oex-Vaud, Switzerland</location>
<contexts>
<context position="7539" citStr="Gurevych and Porzel, 2003" startWordPosition="1141" endWordPosition="1144">nager, (Voll, 2006) developed a post-ASR error-detection mechanism for radiology reports. The hybrid approach uses statistical as well as rule-based methods. The knowledge source UMLS is employed for measuring the semantic distance between concepts and for assessing the coherence of the recognition result. In other approaches, the analysis of meaning is integrated into the recognition process. Semantic confidence measurement annotates recognition hypotheses with additional information about their assumed plausibility based on semantic scores (Zhang and Rudnicky, 2001; Sarikaya et al., 2003). (Gurevych and Porzel, 2003; Gurevych et al., 2003) present a rescoring approach where the hypotheses in the word graph are reordered according to semantic information. Usually, conceptual parsers are employed which construct a parse tree of concepts representing the input text for mapping between the recognition result and the underlying representation. Semantic language modeling (Wanget al., 2004; Buehler et al., 2005) enhances the language model to incorporate sequences of concepts which are considered coherent and typical for a specific context. In these approaches, the representations of the underlying knowledge ar</context>
</contexts>
<marker>Gurevych, Porzel, 2003</marker>
<rawString>I. Gurevych and R. Porzel. Using knowledge-based scores for identifying best speech recognition hypothesis. In: Proceedings of ISCA Tutorial and Research Workshop on Error Handling in Spoken Dialogue Systems, Chateau-d’Oex-Vaud, Switzerland (2003) 77–81 http://proffs.tk.informatik.tudarmstadt.de/TK/abstracts.php3?lang=en&amp;bibtex=1&amp;-paperID=431.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Porzel</author>
<author>I Gurevych</author>
<author>C M¨uller</author>
</authors>
<title>Ontology-based contextual coherence scoring.</title>
<date>2003</date>
<tech>Technical report,</tech>
<institution>European Media Laboratory,</institution>
<location>Heidelberg, Germany</location>
<note>http://citeseer.ist.psu.edu/649012.html.</note>
<marker>Porzel, Gurevych, M¨uller, 2003</marker>
<rawString>R. Porzel, I. Gurevych and C. M¨uller. Ontology-based contextual coherence scoring. Technical report, European Media Laboratory, Heidelberg, Germany (2003) http://citeseer.ist.psu.edu/649012.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Halgrim</author>
<author>F Xia</author>
<author>I Solti</author>
<author>E Cadag</author>
<author>O Uzuner</author>
</authors>
<title>Statistical Extraction of Medication Information from Clinical Records. In:</title>
<date>2010</date>
<booktitle>Proc. ofAMIA Summit on Translational Bioinformatics,</booktitle>
<location>San Francisco, CA,</location>
<contexts>
<context position="4950" citStr="Halgrim et al., 2010" startWordPosition="753" endWordPosition="756">proving the speech-recognition result by means of an evaluation of word graphs for medical reports which were processed by our system. 2 Extraction of Medication Information, Error Handling and Semantic Rescoring (Gold et al., 2008) gives an overview on extracting structured medication information from clinical narratives. Extracted medication information may serve as a base for quality control, pharmaceutical research and the automatic creation of Electronic Health Records (EHR) from clinical narratives. The i2b2 Shared Task 2009 focussed on medication extraction, e.g. (Patrick and Li, 2009; Halgrim et al., 2010). These approaches work on written narrative texts from clinical settings, which may have been typed by physicians, transcribed by medical transcriptionists or recognized by ASR and corrected by medical transcriptionists. In contrast, our approach takes as input word graphs produced by an ASR system from dictated texts and aims at minimizing the post-processing required by human experts. Speech-recognition systems turn acoustic input into word graphs, which are directed acyclic graphs representing the recognized spoken forms and their confidence scores (Oerder and Ney, 1993). In most speech-re</context>
</contexts>
<marker>Halgrim, Xia, Solti, Cadag, Uzuner, 2010</marker>
<rawString>S.R. Halgrim, F. Xia, I. Solti, E. Cadag and O. Uzuner. Statistical Extraction of Medication Information from Clinical Records. In: Proc. ofAMIA Summit on Translational Bioinformatics, San Francisco, CA, March 10-12, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Lindberg</author>
<author>B L Humphreys</author>
<author>A T McCray</author>
</authors>
<title>The unified medical language system.</title>
<date>1993</date>
<journal>Methods of Information in Medicine</journal>
<volume>32</volume>
<issue>4</issue>
<pages>281--291</pages>
<contexts>
<context position="3047" citStr="Lindberg et al., 1993" startWordPosition="461" endWordPosition="464">y control and billing purposes. This manual post-processing is time-consuming, which slows down hospital workflows. A number of recognition errors could be avoided by incorporating explicit domain knowledge. We consider prescriptions of medications a good starting point as they are common and frequent in the various medical fields. Furthermore, they contain trade names and dosages, i.e. proper names and digits, which are frequently misrecognized by ASR in all domains. For our approach, we have extracted and adapted information about medications from the Unified Medical Language System (UMLS) (Lindberg et al., 1993). This data contains information about trade names, active substances, strengths and dosages and can easily be modified, e.g. when new medications are released. In the first step, we assessed the potential for improvement by analyzing a sample corpus of medical reports. It turned out that in 4383 dictated reports which were processed by a speech-recognition system, the word-error rate for medications was about 40%, which is slightly higher than the the average word-error rate of the reports. Examining a sample 22 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining o</context>
</contexts>
<marker>Lindberg, Humphreys, McCray, 1993</marker>
<rawString>D.A. Lindberg, B.L. Humphreys and A.T. McCray. The unified medical language system. Methods of Information in Medicine 32(4) (August 1993) 281–291 http://www.nlm.nih.gov/research/umls/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Liu</author>
<author>W Ma</author>
<author>R Moore</author>
<author>V Ganesan</author>
<author>S Nelson</author>
</authors>
<title>Rxnorm: Prescription for electronic drug information exchange.</title>
<date>2005</date>
<journal>IT Professional</journal>
<volume>7</volume>
<issue>5</issue>
<pages>17--23</pages>
<contexts>
<context position="9680" citStr="Liu et al., 2005" startWordPosition="1492" endWordPosition="1495">ailable for each report. For a subset of the corpus, word graphs could be obtained. By aligning the recognition result with the manual transcriptions, error regions can be extracted. 3.1 Knowledge Base As it is our aim to find correct dosages of medications in the word graph, we built a domainspecific knowledge base which contains medications and strengths as they occur in prescriptions. In our sample of medical reports, about 1/3 of the medications occurred as active ingredients while the rest were trade names. Therefore, both had to be covered in our knowledge base which is based on RxNorm (Liu et al., 2005). RxNorm is a standardized nomenclature for clinical drugs and drug delivery devices and part of UMLS, ensuring a broad coverage of trade names and active ingredients. Of several available versions of RxNorm, the semantic branded drug form is the most suitable one for our purposes as it contains pharmaceutical ingredients, strengths, and trade names. For example, the trade name Synthroid® is listed as follows: Thyroxine 0.025 MG Oral Tablet [Synthroid R�J Thyroxine is the active ingredient with the dosage value 0.025 and the dosage unit milligrams. The dosage unit form is oral tablet. We used </context>
</contexts>
<marker>Liu, Ma, Moore, Ganesan, Nelson, 2005</marker>
<rawString>S. Liu, W. Ma, R. Moore, V. Ganesan and S. Nelson. Rxnorm: Prescription for electronic drug information exchange. IT Professional 7(5) (September/October 2005) 17–23</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Macherey</author>
<author>O Bender</author>
<author>H Ney</author>
</authors>
<title>Multi-level error handling for tree based dialogue course management. In:</title>
<date>2003</date>
<booktitle>Proceedings of ISCA Tutorial and Research Workshop on Error Handling in Spoken Dialogue Systems,</booktitle>
<location>Chateau-d’Oex-Vaud, Switzerland</location>
<contexts>
<context position="6833" citStr="Macherey et al., 2003" startWordPosition="1038" endWordPosition="1041">tions in the field of dialogue systems where knowledge about the domain is represented in terms of the underlying database, e.g. (Seneff and Polifroni, 2000). Several approaches have investigated the potential of improving the mapping between the user utterance and the underlying database by constructing a representation of the utterance meaning. Meaning analysis is either a separate post-processing step or an integral part of the recognition process. In some approaches, the recognition result is analyzed with regards to content to support the dialogue manager in dealing with inconsistencies (Macherey et al., 2003). As far as dictated input is concerned, which is not controlled by a dialogue manager, (Voll, 2006) developed a post-ASR error-detection mechanism for radiology reports. The hybrid approach uses statistical as well as rule-based methods. The knowledge source UMLS is employed for measuring the semantic distance between concepts and for assessing the coherence of the recognition result. In other approaches, the analysis of meaning is integrated into the recognition process. Semantic confidence measurement annotates recognition hypotheses with additional information about their assumed plausibil</context>
</contexts>
<marker>Macherey, Bender, Ney, 2003</marker>
<rawString>K. Macherey, O. Bender and H. Ney. Multi-level error handling for tree based dialogue course management. In: Proceedings of ISCA Tutorial and Research Workshop on Error Handling in Spoken Dialogue Systems, Chateau-d’Oex-Vaud, Switzerland (2003) 123–128, http://www-i6.informatik.rwthaachen.de/˜bender/papers/isca tutorial 2003.pdf.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Oerder</author>
<author>H Ney</author>
</authors>
<title>Word graphs: An efficient interface between continuous speech recognition and language understanding. In:</title>
<booktitle>Proc. IEEE ICASSP’93.</booktitle>
<volume>2</volume>
<pages>119--122</pages>
<marker>Oerder, Ney, </marker>
<rawString>M. Oerder and H. Ney. Word graphs: An efficient interface between continuous speech recognition and language understanding. In: Proc. IEEE ICASSP’93. Volume 2. 119–122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Patrick</author>
<author>M Li</author>
</authors>
<title>A Cascade Approach to Extracting Medication Events. In:</title>
<date>2009</date>
<booktitle>Proc. Australasian Language Technology Workshop</booktitle>
<location>(ALTA)</location>
<contexts>
<context position="4927" citStr="Patrick and Li, 2009" startWordPosition="749" endWordPosition="752">e the potential for improving the speech-recognition result by means of an evaluation of word graphs for medical reports which were processed by our system. 2 Extraction of Medication Information, Error Handling and Semantic Rescoring (Gold et al., 2008) gives an overview on extracting structured medication information from clinical narratives. Extracted medication information may serve as a base for quality control, pharmaceutical research and the automatic creation of Electronic Health Records (EHR) from clinical narratives. The i2b2 Shared Task 2009 focussed on medication extraction, e.g. (Patrick and Li, 2009; Halgrim et al., 2010). These approaches work on written narrative texts from clinical settings, which may have been typed by physicians, transcribed by medical transcriptionists or recognized by ASR and corrected by medical transcriptionists. In contrast, our approach takes as input word graphs produced by an ASR system from dictated texts and aims at minimizing the post-processing required by human experts. Speech-recognition systems turn acoustic input into word graphs, which are directed acyclic graphs representing the recognized spoken forms and their confidence scores (Oerder and Ney, 1</context>
</contexts>
<marker>Patrick, Li, 2009</marker>
<rawString>J. Patrick and M. Li. A Cascade Approach to Extracting Medication Events. In: Proc. Australasian Language Technology Workshop (ALTA) 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sarikaya</author>
<author>Y Gao</author>
<author>M Picheny</author>
</authors>
<title>Word level confidence measurement using semantic features. In:</title>
<date>2003</date>
<booktitle>Proc. of IEEE ICASSP2003.</booktitle>
<volume>1</volume>
<pages>604--607</pages>
<contexts>
<context position="7511" citStr="Sarikaya et al., 2003" startWordPosition="1137" endWordPosition="1140">ntrolled by a dialogue manager, (Voll, 2006) developed a post-ASR error-detection mechanism for radiology reports. The hybrid approach uses statistical as well as rule-based methods. The knowledge source UMLS is employed for measuring the semantic distance between concepts and for assessing the coherence of the recognition result. In other approaches, the analysis of meaning is integrated into the recognition process. Semantic confidence measurement annotates recognition hypotheses with additional information about their assumed plausibility based on semantic scores (Zhang and Rudnicky, 2001; Sarikaya et al., 2003). (Gurevych and Porzel, 2003; Gurevych et al., 2003) present a rescoring approach where the hypotheses in the word graph are reordered according to semantic information. Usually, conceptual parsers are employed which construct a parse tree of concepts representing the input text for mapping between the recognition result and the underlying representation. Semantic language modeling (Wanget al., 2004; Buehler et al., 2005) enhances the language model to incorporate sequences of concepts which are considered coherent and typical for a specific context. In these approaches, the representations of</context>
</contexts>
<marker>Sarikaya, Gao, Picheny, 2003</marker>
<rawString>R. Sarikaya, Y. Gao and M. Picheny. Word level confidence measurement using semantic features. In: Proc. of IEEE ICASSP2003. Volume 1. (April 2003) 604– 607.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Seneff</author>
<author>J Polifroni</author>
</authors>
<title>Dialogue Management in the MERCURY Flight Reservation System. In: Satellite Dialogue Workshop,</title>
<date>2000</date>
<location>ANLP-NAACL, Seattle</location>
<contexts>
<context position="6368" citStr="Seneff and Polifroni, 2000" startWordPosition="967" endWordPosition="970">duction of an explicit representation of the utterance meaning will improve recognition results. Naturally, this works best in limited domains: the larger an application domain, the more difficult it is to build an optimal knowledge representation for all possible user utterances. Limited domains seem to be more rewarding with regard to coverage and performance. Consequently, combining speech recognition and speech understanding has so far mostly resulted in applications in the field of dialogue systems where knowledge about the domain is represented in terms of the underlying database, e.g. (Seneff and Polifroni, 2000). Several approaches have investigated the potential of improving the mapping between the user utterance and the underlying database by constructing a representation of the utterance meaning. Meaning analysis is either a separate post-processing step or an integral part of the recognition process. In some approaches, the recognition result is analyzed with regards to content to support the dialogue manager in dealing with inconsistencies (Macherey et al., 2003). As far as dictated input is concerned, which is not controlled by a dialogue manager, (Voll, 2006) developed a post-ASR error-detecti</context>
</contexts>
<marker>Seneff, Polifroni, 2000</marker>
<rawString>S. Seneff and J. Polifroni. Dialogue Management in the MERCURY Flight Reservation System. In: Satellite Dialogue Workshop, ANLP-NAACL, Seattle (April 2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K D Voll</author>
</authors>
<title>A Methodology of Error Detection: Improving Speech Recognition in Radiology.</title>
<date>2006</date>
<tech>PhD thesis,</tech>
<institution>Simon Fraser University</institution>
<note>http://ir.lib.sfu.ca/handle/1892/2734.</note>
<contexts>
<context position="6933" citStr="Voll, 2006" startWordPosition="1057" endWordPosition="1058">ng database, e.g. (Seneff and Polifroni, 2000). Several approaches have investigated the potential of improving the mapping between the user utterance and the underlying database by constructing a representation of the utterance meaning. Meaning analysis is either a separate post-processing step or an integral part of the recognition process. In some approaches, the recognition result is analyzed with regards to content to support the dialogue manager in dealing with inconsistencies (Macherey et al., 2003). As far as dictated input is concerned, which is not controlled by a dialogue manager, (Voll, 2006) developed a post-ASR error-detection mechanism for radiology reports. The hybrid approach uses statistical as well as rule-based methods. The knowledge source UMLS is employed for measuring the semantic distance between concepts and for assessing the coherence of the recognition result. In other approaches, the analysis of meaning is integrated into the recognition process. Semantic confidence measurement annotates recognition hypotheses with additional information about their assumed plausibility based on semantic scores (Zhang and Rudnicky, 2001; Sarikaya et al., 2003). (Gurevych and Porzel</context>
</contexts>
<marker>Voll, 2006</marker>
<rawString>K.D. Voll. A Methodology of Error Detection: Improving Speech Recognition in Radiology. PhD thesis, Simon Fraser University (2006) http://ir.lib.sfu.ca/handle/1892/2734.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Wang</author>
<author>Y Y Wang</author>
<author>A Acero</author>
</authors>
<title>Use and acquisition of semantic language model. In: HLT-NAACL.</title>
<date>2004</date>
<pages>04--04</pages>
<marker>Wang, Wang, Acero, 2004</marker>
<rawString>K. Wang, Y.Y. Wang and A. Acero. Use and acquisition of semantic language model. In: HLT-NAACL. (2004) http://www.aclweb.org/anthology-new/N/N04/N04-3011.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zhang</author>
<author>A I Rudnicky</author>
</authors>
<title>Word level confidence annotation using combinations of features. In:</title>
<date>2001</date>
<booktitle>Proceedings of Eurospeech.</booktitle>
<note>http://www.speech.cs.cmu.edu/Communicator/papers/-RecoConf2001.pdf.</note>
<contexts>
<context position="7487" citStr="Zhang and Rudnicky, 2001" startWordPosition="1133" endWordPosition="1136">concerned, which is not controlled by a dialogue manager, (Voll, 2006) developed a post-ASR error-detection mechanism for radiology reports. The hybrid approach uses statistical as well as rule-based methods. The knowledge source UMLS is employed for measuring the semantic distance between concepts and for assessing the coherence of the recognition result. In other approaches, the analysis of meaning is integrated into the recognition process. Semantic confidence measurement annotates recognition hypotheses with additional information about their assumed plausibility based on semantic scores (Zhang and Rudnicky, 2001; Sarikaya et al., 2003). (Gurevych and Porzel, 2003; Gurevych et al., 2003) present a rescoring approach where the hypotheses in the word graph are reordered according to semantic information. Usually, conceptual parsers are employed which construct a parse tree of concepts representing the input text for mapping between the recognition result and the underlying representation. Semantic language modeling (Wanget al., 2004; Buehler et al., 2005) enhances the language model to incorporate sequences of concepts which are considered coherent and typical for a specific context. In these approaches</context>
</contexts>
<marker>Zhang, Rudnicky, 2001</marker>
<rawString>R. Zhang and A.I. Rudnicky. Word level confidence annotation using combinations of features. In: Proceedings of Eurospeech. (2001) http://www.speech.cs.cmu.edu/Communicator/papers/-RecoConf2001.pdf.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>