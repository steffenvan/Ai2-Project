<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012040">
<title confidence="0.9995195">
Exploration of the LTAG-Spinal Formalism and Treebank
for Semantic Role Labeling
</title>
<author confidence="0.998438">
Yudong Liu and Anoop Sarkar
</author>
<affiliation confidence="0.982118">
School of Computing Science
Simon Fraser University
</affiliation>
<email confidence="0.975372">
{yudongl,anoop}@cs.sfu.ca
</email>
<sectionHeader confidence="0.997094" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999909052631579">
LTAG-spinal is a novel variant of tradi-
tional Lexicalized Tree Adjoining Gram-
mar (LTAG) introduced by (Shen, 2006).
The LTAG-spinal Treebank (Shen et al.,
2008) combines elementary trees ex-
tracted from the Penn Treebank with Prop-
bank annotation. In this paper, we present
a semantic role labeling (SRL) system
based on this new resource and provide an
experimental comparison with CCGBank
and a state-of-the-art SRL system based
on Treebank phrase-structure trees. Deep
linguistic information such as predicate-
argument relationships that are either im-
plicit or absent from the original Penn
Treebank are made explicit and accessible
in the LTAG-spinal Treebank, which we
show to be a useful resource for semantic
role labeling.
</bodyText>
<sectionHeader confidence="0.999515" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99653321875">
Semantic Role Labeling (SRL) aims to identify
and label all the arguments for each predicate in
a sentence. Specifically, it involves identifying
portions of the sentence that represent the pred-
icate’s arguments and assigning pre-specified se-
mantic roles to them.
[A0seller Ports of Call Inc.] reached agreements to
[Vverb sell] [A1thing its remaining seven aircraft]
[A2buyer to buyers that weren’t disclosed] .
is an example of SRL annotation from the Prop-
Bank corpus (Palmer et al., 2005), where the sub-
scripted information maps the semantic roles A0,
A1 and A2 to arguments for the predicate sell as
defined in the PropBank Frame Scheme.
The availability of annotated corpora like Prop-
Bank and FrameNet (Fillmore et al., 2001) have
provided rapid development of research into
SRL (Gildea and Jurafsky, 2002; Gildea and
Palmer, 2002; Surdeanu et al., 2003; Chen and
Rambow, 2003; Gildea and Hockenmaier, 2003;
Xue and Palmer, 2004; Pradhan et al., 2004; Prad-
han et al., 2005). The shared tasks in CoNLL-
2004 (Carreras and M`arquez, 2004), CoNLL-
2005 (Carreras and M`arquez, 2005) and CoNLL-
2008 (Surdeanu et al., 2008) were all focused on
SRL.
SRL systems (Gildea and Jurafsky, 2002;
Gildea and Palmer, 2002) have extensively used
features defined over Penn Treebank phrase-
structure trees. Other syntactic representations
such as CCG derivations (Gildea and Hocken-
maier, 2003) and dependency trees (Hacioglu,
2004; Surdeanu et al., 2008) have also been ex-
plored. It has been previously noted that LTAG,
which has the useful property of extended domain
of locality (EDL), is well-suited to address the
SRL task, c.f. (Chen and Rambow, 2003; Liu and
Sarkar, 2007). However, LTAG elementary trees
were extracted from the derived parse trees by
using Magerman-Collins style head-percolation
based heuristic rules (Liu and Sarkar, 2007). The
LTAG-spinal Treebank (Shen et al., 2008) pro-
vided a corpus of derivation trees where elemen-
tary trees were extracted from the Penn Tree-
bank in combination with the Propbank predicate-
argument annotation. The LTAG-spinal Treebank
can be used to overcome some of the limitations of
the previous work on SRL using LTAG: (Liu and
Sarkar, 2007) uses LTAG-based features extracted
from phrase-structure trees as an additional source
of features and combined them with features from
a phrase-structure based SRL framework; (Chen
and Rambow, 2003) only considers those comple-
ment/adjunct semantic roles that can be localized
in LTAG elementary trees, which leads to a loss
of over 17% instances of semantic roles even from
gold-standard trees.
The LTAG-spinal formalism was initially pro-
posed for automatic treebank extraction and sta-
tistical parsing (Shen and Joshi, 2005). However,
its Propbank-guided treebank extraction process
further strengthens the connection between the
LTAG-spinal and semantic role labeling. In this
paper, we present an SRL system that was built to
</bodyText>
<page confidence="0.822421">
1
</page>
<note confidence="0.998959">
Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks, ACL-IJCNLP 2009, pages 1–9,
Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999867333333333">
explore the utility of this new formalism, its Tree-
bank and the output of its statistical parser. Ex-
periments show that our LTAG-spinal based SRL
system achieves very high precision on both gold-
standard and automatic parses, and significantly
outperforms the one using CCGbank. More im-
portantly, it shows that LTAG-spinal is an useful
resource for semantic role labeling, with the po-
tential for further improvement.
</bodyText>
<sectionHeader confidence="0.840758" genericHeader="method">
2 LTAG-spinal, its Treebank and Parsers
</sectionHeader>
<bodyText confidence="0.99991825">
This section gives a brief introduction of LTAG-
spinal formalism, its Treebank that is extracted
with the help of Propbank annotation, and its two
statistical parsers that are trained on the Tree-
bank. Predicate-argument relations encoded in the
LTAG-spinal treebank will also be discussed to il-
lustrate its compatibility with Propbank and their
potential utility for the SRL task.
</bodyText>
<subsectionHeader confidence="0.996998">
2.1 LTAG-spinal
</subsectionHeader>
<bodyText confidence="0.999931838709677">
The LTAG-spinal formalism (Shen et al., 2008)
is a variant of Lexicalized Tree Adjoining Gram-
mar (LTAG) (Abeill´e and Rambow, 2001). Com-
pared to traditional LTAG, the two types of ele-
mentary trees (e-tree for short), initial and auxil-
iary trees, are in spinal form with no substitution
nodes for arguments appearing in the predicate e-
tree: a spinal initial tree is composed of a lexi-
cal spine from the root to the anchor, and noth-
ing else; a spinal auxiliary tree is composed of a
lexical spine and a recursive spine from the root
to the foot node. For example, in Figure 1 (from
(Shen et al., 2008)), the lexical spine for the auxil-
iary tree is Bl,.., Bi,.., B, the recursive spine is
Bi, .., Bi, .., Bi. Two operations attachment and
adjunction are defined in LTAG-spinal where ad-
junction is the same as adjunction in the traditional
LTAG; attachment stems from sister adjunction as
defined in Tree Insertion Grammar (TIG) (Schabes
and Shieber, 1994), which corresponds to the case
where the root of an initial tree is taken as a child
of another spinal e-tree. The two operations are
applied to LTAG-spinal e-tree pairs resulting in an
LTAG derivation tree which is similar to a depen-
dency tree (see Figure 2). In Figure 2, e-tree an-
chored with continue is the only auxiliary tree; all
other e-trees are initial trees. The arrow is directed
from parent to child, with the type of operation
labeled on the arc. The operation types are: att
denotes attachment operation; adj denotes adjunc-
tion operation. The sibling nodes may have differ-
</bodyText>
<figure confidence="0.69638625">
initial: auxiliary:
A1 B1
Bi
An Bn B1*
</figure>
<figureCaption confidence="0.999437">
Figure 1: Spinal elementary trees
</figureCaption>
<bodyText confidence="0.999837641025641">
ent landing site along the parent spine. For ex-
ample, among the child nodes of stabilize e-tree,
to e-tree has VP as landing site; while even has S
as landing site. Such information, on some level,
turns out to be helpful to differentiate the semantic
role played by the different child nodes.
So far, we can see that in contrast with tradi-
tional LTAG where arguments refer to obligatory
constituents only, subcategorization frames and
argument-adjunct distinction are underspecified
in LTAG-spinal. Since argument-adjunct disam-
biguation is one of the major challenges faced by
LTAG treebank construction, LTAG-spinal works
around this issue by leaving the disambiguation
task for further deep processing, such as seman-
tic role labeling.
LTAG-spinal is weakly equivalent to traditional
LTAG with adjunction constraints1 (Shen, 2006).
The Propbank (Palmer et al., 2005) is an an-
notated corpus of verb subcategorization and al-
ternations which was created by adding a layer
of predicate-argument annotation over the phrase
structure trees in the Penn Treebank. The LTAG-
spinal Treebank is extracted from the Penn Tree-
bank by exploiting Propbank annotation. Specif-
ically, as described in (Shen et al., 2008), a Penn
Treebank syntax tree is taken as an LTAG-spinal
derived tree; then information from the Penn Tree-
bank and Propbank is merged using tree transfor-
mations. For instance, LTAG predicate coordina-
tion and instances of adjunction are recognized
using Propbank annotation. LTAG elementary
trees are then extracted from the transformed Penn
Treebank trees recursively, using the Propbank an-
notation and a Magerman-Collins style head per-
colation table.
This guided extraction process allows syntax
and semantic role information to be combined in
LTAG-spinal derivation trees. For example, the
</bodyText>
<footnote confidence="0.9563995">
1null adjunction (NA), obligatory adjunction (OA) and se-
lective adjunction (SA)
</footnote>
<page confidence="0.993578">
2
</page>
<figureCaption confidence="0.990032666666667">
Figure 2: An example of LTAG-spinal sub-derivation tree, from LTAG-spinal Treebank Section 22
Figure 3: Three examples of LTAG-spinal derivation trees where predicates and their Propbank style
argument labels are given. These examples are from LTAG-spinal Treebank Section 22.
</figureCaption>
<bodyText confidence="0.999926735849057">
Penn Treebank does not differentiate raising verbs
and control verbs, however, based on the Propbank
information, LTAG-spinal makes this distinction
explicit. Thus, the error of taking a subject ar-
gument which is not semantically an argument of
the raising verb can be avoided. Another prop-
erty of LTAG-spinal Treebank extraction lies in the
flexibility and simplicity of the treatment of pred-
icate coordination (see (Shen et al., 2008)). Fig-
ure 3 shows three examples of Propbank annota-
tion as decorations over the LTAG-spinal deriva-
tion trees. In each derivation tree, each node is
associated with LTAG-spinal e-trees. Each argu-
ment (A0, A1, etc.) is referred to as A and the
predicate is called P. In most cases, the argument
is found locally in the derivation tree due to the
extended domain of locality in e-trees. Thus, most
arguments are identified by the pattern P —* A or
P +— A. The next section contains a discussion of
such patterns in more detail.
Two statistical parsers have been developed
by Libin Shen specifically for training on the
LTAG-spinal treebank: a left-to-right incremental
parser (Shen and Joshi, 2005) and a bidirectional
incremental parser (Shen and Joshi, 2008). If one
compares the output of these two parsers, the left-
to-right parser produces full LTAG-spinal deriva-
tion trees (including all the information about
specific elementary trees used in the derivation
and the attachment information within the e-trees)
while the bidirectional parser produces derivation
trees without information about elementary trees
or attachment points (similar to output from a de-
pendency parser). In this paper, we use the left-
to-right incremental parser for its richer output
because our SRL system uses feature functions
that use information about the elementary trees in
the derivation tree and the attachment points be-
tween e-trees. The landing site of child node along
the parent spine is useful for identifying different
types of arguments in SRL. For example, assume
the parent spine is “S-VP-VB-anchor” (the root la-
bel is S, and “anchor” is where the lexical item is
inserted). Along with direction information, the
landing site label “S” is likely to be a good indi-
cator for argument A0 (subject) while the landing
site label “VP” could be a good indicator for “A1”
(object). In this sense, the incremental left-to-
right parser is preferable for semantic role label-
ing. However, having been developed earlier than
the bidirectional parser, the incremental parser ob-
tains 1.2% less in dependency accuracy compared
to the bidirectional parser (Shen and Joshi, 2008).
</bodyText>
<subsectionHeader confidence="0.998857">
2.2 Predicate-argument relations in the
LTAG-spinal Treebank
</subsectionHeader>
<bodyText confidence="0.999714666666667">
The Propbank-guided extraction process for
LTAG-spinal treebank naturally creates a close
connection between these two resources. To ex-
amine the compatibility of the LTAG-spinal Tree-
bank with Propbank, (Shen et al., 2008) provides
the frequency for specific types of paths from
the predicate to the argument in the LTAG-spinal
derivation trees from the LTAG-spinal Treebank.
The 8 most frequent patterns account for 95.5%
of the total predicate-argument pairs of the LTAG-
spinal Treebank, of which 88.4% are directly con-
nected pairs. These statistics not only provide em-
</bodyText>
<page confidence="0.997379">
3
</page>
<table confidence="0.9996327">
Path Pattern Number Percent
1 P—*A 8294 81.3
2 P+—A, V+—A 720 7.1
3 P+—Px—*A 437 4.3
4 P+—Coord—*Px—*A 216 2.1
5 P+—Ax+—Py—*A 84 0.82
6 P+—Coord+—Px—*A 40 0.39
7 P+—Px+—Py—*A 13 0.13
total recovered w/ patterns 9804 96.1
total 10206 100.0
</table>
<tableCaption confidence="0.99788">
Table 1: Distribution of the 7 most frequent
</tableCaption>
<bodyText confidence="0.974594695652174">
predicate-argument pair patterns in LTAG-spinal
Treebank Section 22. P: predicate, A: argument,
V : modifying verb, Coord: predicate coordina-
tion.
pirical justification for the notion of the extended
domain of locality (EDL) in LTAG-spinal (Shen et
al., 2008), they also provide motivation to explore
this Treebank for the SRL task.
We collected similar statistics from Treebank
Section 22 for the SRL task, shown in Table 1,
where 7 instead of 8 patterns suffice in our setting.
Each pattern describes one type of P(redicate)-
A(rgument) pair with respect to their dependency
relation and distance in the LTAG-spinal deriva-
tion tree. The reason that we combine the two pat-
terns P+—A and V+—A into one is that from SRL
perspective, they are equivalent in terms of the de-
pendency relation and distance between the pred-
icate. Each token present in the patterns, such as
P, Px, Py, V, A, Ax and Coord, denotes a spinal
e-tree in the LTAG-spinal derivation tree.
To explain the patterns more specifically, take
the LTAG-spinal sub-derivation tree in Figure 2
as an example, Assume P(redicate) in question is
stabilize then (stabilize —* even), (stabilize —*
if), (stabilize —* Street), (stabilize —* continue),
(stabilize —* to) all belong to pattern 1; but only
(stabilize —* Street) is actual predicate-argument
pair. Similarly, when take continue as P, the
predicate-argument pair (continue +— stabilize)
belongs to pattern 2, where stabilize corresponds
to A(rgument) in the pattern; (continue, Street) in
(Street +— stabilize —* continue) is an example of
pattern 3, where stabilize corresponds to Px and
Street corresponds to A in the pattern 3 schema.
Pattern 4 denotes the case where argument (A) is
shared between coordinated predicates (P and Px);
The main difference of pattern 5-7 exists where
the sibling node of A(rgument) is categorized into:
predicate (Px) in pattern 7, predicate coordination
node (Coord) in pattern 6 and others (Ax) in pat-
tern 5. We will retain this difference instead of
merging it since the semantic relation between P
and A varies based on these differences. Example
sentences for other (rarer) patterns can be found
in (Shen et al., 2008).
</bodyText>
<sectionHeader confidence="0.995309" genericHeader="method">
3 LTAG-spinal based SRL System De-
scription
</sectionHeader>
<bodyText confidence="0.999951515151515">
In this section, we describe our LTAG-spinal based
SRL system. So far, we have studied LTAG-spinal
formalism, its treebank and parsers. In particular,
the frequency distribution of the seven most seen
predicate-argument pair patterns in LTAG-spinal
Treebank tells us that predicate-argument relation-
ships typical to semantic role labeling are often lo-
cal in LTAG-spinal derivation trees.
Pruning, argument identification and argument
classification – the 3-stage architecture now stan-
dard in SRL systems is also used in this paper.
Specifically, for the sake of efficiency, nodes with
high probability of being NULL (non-argument)
should be filtered at the beginning; usually filter-
ing is done based on some heuristic rules; after the
pruning stage, argument identification takes place
with the goal of classifying the pruning-survival
nodes into argument and non-argument; for those
nodes that have been classified as arguments, ar-
gument classification component will further label
them with different argument types, such as A0,
A1, etc. Argument identification and classifica-
tion are highly ambiguous tasks and are usually
accomplished using a machine learning method.
For our LTAG-spinal based SRL system, we
first collect the argument candidates for each pred-
icate from the LTAG-spinal derivation tree. For
each candidate, features are extracted to capture
the predicate-argument relations. Binary classi-
fiers for identification and classification are trained
using SVMs and combined in a one-vs-all model.
The results are evaluated using precision/recall/f-
score.
</bodyText>
<subsectionHeader confidence="0.997482">
3.1 Candidate Locations for Arguments
</subsectionHeader>
<bodyText confidence="0.999612142857143">
In SRL systems that perform role labeling of con-
stituents in a phrase-structure tree, statistics show
that after pruning, —98% of the SRL argument
nodes are retained in the gold-standard trees in
the Penn Treebank, which provides a high upper-
bound for the recall of the SRL system. Pruning
away unnecessary nodes using a heuristic makes
</bodyText>
<page confidence="0.987948">
4
</page>
<bodyText confidence="0.999961147058823">
learning easier as well, as many of the false posi-
tives are pruned away leading to a more balanced
binary classification problem during the seman-
tic role identification and classification steps. We
need a similar heuristic over LTAG-spinal nodes
that will have high coverage with respect to SRL
arguments and provide a high upper-bound for re-
call.
As previously shown that the seven most fre-
quent predicate-argument pair patterns that are
used to describe the specific types of paths from
the predicate to the argument account for —96% of
the total number of predicate-argument pairs in the
LTAG-spinal Treebank. These patterns provide a
natural candidate selection strategy for our SRL.
Table 2 shows a similar oracle test applied to the
output of the LTAG-spinal parser on Section 22.
The total drop in oracle predicate-argument iden-
tifiation drops 10.5% compared to gold-standard
trees. 9.8% is lost from patterns 1 and 2. If ex-
clude those pairs that belong to pattern i in tree-
bank but belong to pattern j (i 7� j) in automatic
parses (so the pattern exists but is the wrong one
for that constituent), the number drops to 81.6%
from 85.6%. This indicates that in terms of the
impact of the syntactic parser errors for SRL, the
LTAG-spinal parser will suffer even more than the
phase structure parser. An alternative is to exhaus-
tively search for predicate-argument pairs without
considering patterns, which we found introduces
too much noise in the learner to be feasible. Thus,
the predicate-argument pairs selected through this
phase are considered as argument candidates for
our SRL system.
</bodyText>
<subsectionHeader confidence="0.941874">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.9858335">
Based on the patterns, features are defined on
predicate-argument pairs from LTAG derivation
</bodyText>
<table confidence="0.9995327">
Path Pattern Number Percent
1 P—*A 7441 72.9
2 P+—A, V+—A 583 5.7
3 P+—Px—*A 384 3.8
4 P+—Coord—*Px—*A 180 1.76
5 P+—Ax+—Py—*A 75 0.73
6 P+—Coord+—Px—*A 48 0.47
7 P+—Px+—Py—*A 22 0.21
total recovered w/ patterns 8733 85.6
total 10206 100.0
</table>
<tableCaption confidence="0.887393">
Table 2: Distribution of the 7 patterns in LTAG-
spinal parser output for Section 22.
</tableCaption>
<bodyText confidence="0.998700260869565">
tree, mainly including predicate e-trees, argument
e-trees, intermediate e-trees and their “topological
relationships” such as operation, spine node, rel-
ative position and distance. The following are the
specific features used in our classifiers:
Features from predicate e-tree and its variants
predicate lemma, POS tag of predicate, predicate
voice, spine of the predicate e-tree, 2 variants of
predicate e-tree: replacing anchor in the spine
with predicate lemma, replacing anchor POS in
the spine with voice. In Figure 2, if take stabi-
lize as predicate, these two variants are S-VP-VB-
stabilize and S-VP-VB-active respectively.
Features from argument e-tree and its variants
argument lemma, POS tag of argument, Named
Entity (NE) label of the argument, spine of the ar-
gument e-tree, 2 variants of argument e-tree: re-
placing anchor in the spine with argument lemma,
replacing anchor POS with NE label if any, label
of root node of the argument spine. In Figure 2,
if take stabilize as predicate, and Street as argu-
ment, the two variants are XP-NNP-street and XP-
ORGANIZATION2 respectively.
PP content word of argument e-tree if the root
label of the argument e-tree is PP, anchor of the
last daughter node. NE variant of this feature: re-
place its POS with the NE label if any.
Features from the spine node (SP1) spine node is
the landing site between predicate e-tree and argu-
ment e-tree. Features include the index along the
host spine3, label of the node, operation involved
(att or adj).
Relative position of predicate and argument in the
sentence: before/after.
Order of current child node among its siblings.
In pattern 1, predicate e-tree is parent, and argu-
ment e-tree is child. This feature refers to the order
of argument e-tree among its siblings nodes (with
predicate e-tree as parent).
Distance of predicate e-tree and argument tree in
the LTAG derivation tree: For example, for pattern
1 and 2, the distance has value 0; for pattern 3, the
distance has value 1.
Pattern ID valued 1-7. (see Table 1 and Table 2)
Combination of position and pattern ID, combi-
nation of distance and pattern ID, combination of
</bodyText>
<footnote confidence="0.9843995">
2XP-NNP is a normalized e-tree form used in (Shen et
al., 2008) for efficiency and to avoid the problem of sparse
data over too many e-trees.
3it can either be predicate e-tree or argument e-tree. For
example, for pattern Pt-A, the A(rgument) e-tree is the host
spine.
</footnote>
<page confidence="0.995999">
5
</page>
<bodyText confidence="0.997685884615385">
position and order.
Features from intermediate predicate e-tree
same features as predicate e-tree features.
Features from spine node of intermediate pred-
icate e-tree and argument e-tree (SP2) for
predicate-argument pairs of pattern 3-7. These
features are similar to the SP1 features but instead
between intermediate predicate e-tree and argu-
ment e-tree.
Relative position between predicate e-tree and in-
termediate e-tree.
Combination relative positions of argument e-tree
and intermediate predicate e-tree + relative posi-
tion of argument e-tree and predicate e-tree.
The features listed above are used to represent
each candidate constituent (or node) in the LTAG-
spinal derivation tree in training and test data. In
both cases, we identify SRLs for nodes for each
predicate. In training each node comes with the
appropriate semantic role label, or NULL if it does
not have any (for the predicate). In test data,
we first identify nodes as arguments using these
features (ARG v.s. NULL classification) and then
classify a node identified as an argument with the
particular SRL using one-vs-all binary classifica-
tion.
</bodyText>
<sectionHeader confidence="0.999568" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.990822">
4.1 Data Set
</subsectionHeader>
<bodyText confidence="0.9999863125">
Following the usual convention for parsing and
SRL experiments, LTAG-spinal Treebank Section
2-21 is used for training and Section 23 for test-
ing. Propbank argument set is used which includes
numbered arguments A0 to A5 and 13 adjunct-like
arguments. 454 sentences in the Penn Treebank
are skipped from the LTAG-spinal Treebank (Shen
et al., 2008)4, which results in 115 predicate-
argument pairs ignored in the test set.
We applied SVM-light (Joachims, 1999) with
default linear kernel to feature vectors. 30% of
the training samples are used to fine tune the reg-
ularization parameter c and the loss-function cost
parameter j for both argument identification and
classification. With parameter validation experi-
ments, we set c = 0.1 and j = 1 for {A0, AM-
</bodyText>
<footnote confidence="0.887776285714286">
4Based on (Shen et al., 2008), the skipped 454 sentences
amount to less than 1% of the total sentences. 314 of these
454 sentences have gapping structures. Since PTB does not
annotate the trace of deleted predicates, additional manual
annotation is required to handle these sentences. For the rest
of the 146 sentences, abnormal structures are generated due
to tagging errors.
</footnote>
<bodyText confidence="0.999951529411765">
NEG}, c = 0.1, j = 2 for {A1, A2, A4, AM-
EXT} and c = 0.1 and j = 4 for the rest.
For comparison, we also built up a standard 3-
stage phrase-structure based SRL system, where
exactly the same data set5 is used from 2004
February release of the Propbank. SVM-light with
linear kernel is used to train on a standard fea-
ture set (Xue and Palmer, 2004). The Charniak
and Johnson parser (2006) is used to produce the
automatic parses. Note that this phrase-structure
based SRL system is state-of-the-art and we have
included all the features proposed in the litera-
ture that use phrase-structure trees. This system
obtains a higher SRL accuracy which can be im-
proved only by using global inference and other
ways (such as using multiple parsers) to improve
the accuracy on automatic parses.
</bodyText>
<sectionHeader confidence="0.522402" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999982333333333">
We compared our LTAG-spinal based SRL system
with phrase-structure based one (see the descrip-
tion in earlier sections), for argument identifica-
tion and classification. In order to analyze the im-
pact of errors in syntactic parsers, results are pre-
sented on both gold-standard trees and automatic
parses. Based on the fact that nearly 97% e-trees
that correspond to the core arguments6 belong to
pattern 1 and 2, which accounts for the largest por-
tion of argument loss in automatic parses, the clas-
sification results are also given for these core argu-
ments. We also compare with the CCG-based SRL
presented in (Gildea and Hockenmaier, 2003)7,
which has a similar motivation as this paper, ex-
cept they use the Combinatory Categorial Gram-
mar formalism and the CCGBank syntactic Tree-
bank which was converted from the Penn Tree-
bank.
Scoring strategy To have a fair evaluation of argu-
ments between the LTAG-spinal dependency parse
and the Penn Treebank phrase structure, we report
the root/head-word based scoring strategy for per-
formance comparison, where a case is counted as
positive as long as the root of the argument e-tree
is correctly identified in LTAG-spinal and the head
word of the argument constituent is correctly iden-
tified in phrase structure. In contrast, boundary-
</bodyText>
<footnote confidence="0.996839571428571">
5The same 454 sentences are ignored.
6A0, A1, A2, A3, A4, A5
7Their data includes the 454 sentences. However, the
missing 115 predicate-argument pairs account for less than
1% of the total number of predicate-argument pairs in the test
data, so even if we award these cases to the CCGBank system
the system performance gap still remains.
</footnote>
<page confidence="0.998683">
6
</page>
<bodyText confidence="0.99566693877551">
based scoring is more strict in that the string span
of the argument must be correctly identified in
identification and classification.
Results from using gold standard trees Ta-
ble 3 shows the results when gold standard trees
are used. We can see that with gold-standard
derivations, LTAG-spinal obtains the highest pre-
cision on identification and classification; it also
achieves a competitive f-score (highest f-score for
identification) with the recall upper-bound lower
by 2-3% than phrase-structure based SRL. How-
ever, the recall gap between the two SRL systems
gets larger for classification compared to identifi-
cation8, which is due to the low recall that is ob-
served with our LTAG-spinal based SRL based on
our current set of features. If compare the differ-
ence between the root/head-word based score and
the boundary based score in the 3 scenarios, we
notice that the difference reflects the discrepancy
between the argument boundaries. It is not sur-
prising to see that phrase-structure based one has
the best match. However, CCGBank appears to
have a large degree of mismatch. In this sense,
root/head word based scoring provides fair com-
parison between LTAG-spinal SRL system and the
CCGBank SRL system.
Recent work (Boxwell and White, 2008)
changes some structures in the CCGBank to cor-
respond more closely with the Probbank annota-
tions. They also resolve split arguments that occur
in Propbank and add these annotations into a re-
vised version of the CCGBank. As a result they
show that the oracle f-score improves by over 2
points over the (Gildea and Hockenmaier, 2003)
oracle results for the numbered arguments only
(A0, ..., A5). It remains an open question whether
a full SRL system based on a CCG parser trained
on this new version of the CCGBank will be com-
petitive against the LTAG-spinal based and phrase-
structure based SRL systems.
Results from using automatic parses Table 4
shows the results when automatic parses are used.
With automatic parses, the advantage of LTAG-
spinal in the precision scores still exists: giving
a higher score in both identification and core argu-
ment classification; only 0.5% lower for full argu-
ment classification. However, with over 6% dif-
ference in upper-bound of recall (685.6% from
LTAG-spinal; —91.7% from Charniak’s parser),
</bodyText>
<footnote confidence="0.6875525">
8no NULL examples are involved when training for argu-
ment classification.
</footnote>
<bodyText confidence="0.999669">
the gap in recall becomes larger: increased to
—10% in automatic parses from —6% in gold-
standard trees.
The identification result is not available for
CCG-based SRL. In terms of argument classifica-
tion, it is significantly outperformed by the LTAG-
spinal based SRL. In particular, it can be seen that
the LTAG-spinal parser performs much better on
argument boundaries than CCG-based one.
One thing worth mentioning is that since neither
the LTAG-spinal parser nor Charniak’s parser pro-
vides trace (empty category) information in their
output, no trace information is used for LTAG-
spinal based SRL or the phrase-structure based
SRL even though it is available in their gold-
standard trees.
</bodyText>
<sectionHeader confidence="0.998297" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.998359911764706">
With a small feature set, the LTAG-spinal based
SRL system described in this paper provides the
highest precision in almost all the scenarios, which
indicates that the shallow semantic relations, e.g.,
the predicate-argument relations that are encoded
in the LTAG-spinal Treebank are useful for SRL,
especially when compared to the phrase structure
Penn Treebank. (Shen et al., 2008) achieves an f-
score of 91.6% for non-trace SRL identification on
the entire Treebank by employing a simple rule-
based system, which also suggested this conclu-
sion. In other words, there is a tighter connection
between the syntax and semantic role labels in the
LTAG-spinal representation.
However, in contrast to the high precision, the
recall performance of LTAG-spinal based SRL
needs a further improvement, especially for the ar-
gument classification task. From SRL perspective,
on one hand, this may be due to the pattern-based
candidate selection, which upper-bounds the num-
ber of predicate-argument pairs that can be re-
covered for SRL; on the other hand, it suggests
that the features for argument classification need
to be looked at more carefully, compared to the
feature selection for argument identification, es-
pecially for A2 and A3 (as indicated by our error
analysis on the results on the development set). A
possible solution is to customize a different fea-
ture set for each argument type during classifica-
tion, especially for contextual information.
Experiments show that when following the
pipelined architecture, the performance of LTAG-
based SRL is more severely degraded by the syn-
tactic parser, compared to the SRL using phrase
</bodyText>
<page confidence="0.999244">
7
</page>
<table confidence="0.9999414">
Identification gold-standard trees (p/r/f%)
Scoring LTAG phrase CCG
Root/head-word 96.0/92.1/94.0 93.0/94.0/93.5 n/a
classification (core) gold-standard trees (p/r/f%)
Scoring LTAG phrase CCG
Root/head-word 90.6/83.4/86.9 87.2/88.4/87.8 82.4/78.6/80.4
classification (full) gold-standard trees (p/r/f%)
Scoring LTAG phrase CCG
Root/head-word 88.2/81.7/84.8 86.1/87.1/86.6 76.3/67.8/71.8
Boundary 87.4/81.0/84.1 86.0/87.0/86.5 67.5/60.0/63.5
</table>
<tableCaption confidence="0.997888">
Table 3: Using gold standard trees: comparison of the three SRL systems for argument identification,
core and full argument classification
</tableCaption>
<table confidence="0.9999523">
Identification automatic parses (p/r/f%)
Scoring LTAG phrase CCG
Root/head-word 85.8/80.0/82.8 85.8/87.7/86.7 n/a
classification (core) automatic parses (p/r/f%)
Scoring LTAG phrase CCG
Root/head-word 81.0/71.5/76.0 80.1/82.8/81.4 76.1/73.5/74.8
classification (full) automatic parses (p/r/f%)
Scoring LTAG phrase CCG
Root/head-word 78.0/70.0/73.7 78.5/80.3/79.4 71.0/63.1/66.8
Boundary 72.3/65.0/68.5 73.8/75.5/74.7 55.7/49.5/52.4
</table>
<tableCaption confidence="0.8474415">
Table 4: Using automatic parses: comparison of the three SRL systems for argument identification, core
and full argument classification
</tableCaption>
<bodyText confidence="0.999958818181818">
structure and CCG formalism. Even though the
left-to-right statistical parser that was trained and
evaluated on the LTAG-spinal Treebank achieves
an f-score of 89.3% for dependencies on Section
23 of this treebank (Shen and Joshi, 2005), the
SRL that used this output is worse than expected.
An oracle test shows that via the same 7 patterns,
only 81.6% predicate-argument pairs can be re-
covered from the automatic parses, which is a big
drop from 96.1% when we use the LTAG-spinal
Treebank trees. Parser accuracy is high overall,
but needs to be more accurate in recovering the
dependencies between predicate and argument.
Based on the observation that the low recall
occurs not only to the SRL when the automatic
parses are used but also when the gold trees are
used, we would expect that a thorough error analy-
sis and feature calibrating can give us a better idea
in terms of how to increase the recall in both cases.
In on-going work, we also plan to improve
the dependency accuracy for predicate and argu-
ment dependencies by using the SRL predictions
as feedback for the syntactic parser. Our hypoth-
esis is that this approach combined with features
that would improve the recall numbers would lead
to a highly accurate SRL system.
As a final note, we believe that our effort on us-
ing LTAG-spinal for SRL is a valuable exploration
of the LTAG-spinal formalism and its Treebank re-
source. We hope our work will provide useful in-
formation on how to better utilize this formalism
and the Treebank resource for semantic role label-
ing.
</bodyText>
<sectionHeader confidence="0.998021" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999971142857143">
We would like to thank Aravind Joshi and Lu-
cas Champollion for their useful comments and
for providing us access to the LTAG-spinal Tree-
bank. We would especially like to thank Libin
Shen for providing us with the LTAG-spinal sta-
tistical parser for our experiments and for many
helpful comments.
</bodyText>
<page confidence="0.996982">
8
</page>
<sectionHeader confidence="0.998325" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999918121212121">
A. Abeill´e and O. Rambow, editors. 2001. Tree Ad-
joining Grammars: Formalisms, Linguistic Analysis
and Processing. Center for the Study of Language
and Information.
Stephen A. Boxwell and Michael White. 2008. Pro-
jecting propbank roles onto the ccgbank. In LREC-
2008.
X. Carreras and L. M`arquez. 2004. Introduction to the
CoNLL-2004 Shared Task. In CoNLL-2004.
X. Carreras and L. M`arquez. 2005. Introduction to the
CoNLL-2005 Shared Task. In CoNLL-2005.
J. Chen and O. Rambow. 2003. Use of deep linguistic
features for the recognition and labeling of semantic
arguments. In EMNLP-2003.
C.J. Fillmore, C. Wooters, and C.F. Baker. 2001.
Building a large lexical databank which provides
deep semantics. In PACLIC15-2001.
D. Gildea and J. Hockenmaier. 2003. Identifying se-
mantic roles using combinatory categorial grammar.
In EMNLP-2003.
D. Gildea and D. Jurafsky. 2002. Automatic label-
ing of semantic roles. Computational Linguistics,
58(3):245–288.
D. Gildea and M. Palmer. 2002. The necessity of
parsing for predicate argument recognition. In ACL-
2002.
K. Hacioglu. 2004. Semantic role labeling using de-
pendency trees. In COLING-2004.
T. Joachims. 1999. Making large-scale svm learning
practical. Advances in Kernel Methods - Support
Vector Machines.
Y. Liu and A. Sarkar. 2007. Experimental evaluation
of LTAG-based features for semantic role labeling.
In EMNLP-2007.
M. Palmer, D. Gildea, and P. Kingsbury. 2005. The
proposition bank: An annotated corpus of semantic
roles. Computational Linguistics, 31(1).
S. Pradhan, W. Ward, K. Hacioglu, , J. H. Martin, and
D. Jurafsky. 2004. Shallow Semantic Parsing Using
Support Vector Machines. In HLT-NAACL-2004.
S. Pradhan, W. Ward, K. Hacioglu, , J. H. Martin, and
D. Jurafsky. 2005. Semantic role labeling using dif-
ferent syntactic views. In ACL-2005.
Yves Schabes and Stuart M. Shieber. 1994. An
alternative conception of tree-adjoining derivation.
Computational Linguistics, 20(1):91–124.
L. Shen and Aravind Joshi. 2005. Incremental ltag
parsing. In HLT-EMNLP-2005.
L. Shen and A. Joshi. 2008. Ltag dependency pars-
ing with bidirectional incremental construction. In
EMNLP-2008.
L. Shen, L. Champollion, and A. Joshi. 2008. Ltag-
spinal and the treebank: A new resource for in-
cremental, dependency and semantic parsing. Lan-
guage Resources and Evaluation, 42(1):1–19.
L. Shen. 2006. Statistical LTAG Parsing. Ph.D. thesis,
University of Pennsylvania.
M. Surdeanu, S. Harabagiu, J. Williams, and
P. Aarseth. 2003. Using predicate-argument struc-
tures for information extraction. In ACL-2003.
M. Surdeanu, R. Johansson, A. Meyers, L. M`arquez,
and J. Nivre. 2008. The conll 2008 shared task
on joint parsing of syntactic and semantic dependen-
cies. In CoNLL-2008.
N. Xue and M. Palmer. 2004. Calibrating features for
semantic role labeling. In EMNLP-2004.
</reference>
<page confidence="0.997107">
9
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.850515">
<title confidence="0.9971355">Exploration of the LTAG-Spinal Formalism and for Semantic Role Labeling</title>
<author confidence="0.921766">Liu</author>
<affiliation confidence="0.969787">School of Computing Simon Fraser University</affiliation>
<abstract confidence="0.9985399">LTAG-spinal is a novel variant of traditional Lexicalized Tree Adjoining Grammar (LTAG) introduced by (Shen, 2006). The LTAG-spinal Treebank (Shen et al., 2008) combines elementary trees extracted from the Penn Treebank with Propbank annotation. In this paper, we present a semantic role labeling (SRL) system based on this new resource and provide an experimental comparison with CCGBank and a state-of-the-art SRL system based on Treebank phrase-structure trees. Deep linguistic information such as predicateargument relationships that are either implicit or absent from the original Penn Treebank are made explicit and accessible in the LTAG-spinal Treebank, which we show to be a useful resource for semantic role labeling.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Abeill´e</author>
<author>O Rambow</author>
<author>editors</author>
</authors>
<title>Tree Adjoining Grammars: Formalisms, Linguistic Analysis and Processing. Center for the Study of Language and Information.</title>
<date>2001</date>
<marker>Abeill´e, Rambow, editors, 2001</marker>
<rawString>A. Abeill´e and O. Rambow, editors. 2001. Tree Adjoining Grammars: Formalisms, Linguistic Analysis and Processing. Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen A Boxwell</author>
<author>Michael White</author>
</authors>
<title>Projecting propbank roles onto the ccgbank.</title>
<date>2008</date>
<booktitle>In LREC2008.</booktitle>
<contexts>
<context position="26648" citStr="Boxwell and White, 2008" startWordPosition="4265" endWordPosition="4268">hich is due to the low recall that is observed with our LTAG-spinal based SRL based on our current set of features. If compare the difference between the root/head-word based score and the boundary based score in the 3 scenarios, we notice that the difference reflects the discrepancy between the argument boundaries. It is not surprising to see that phrase-structure based one has the best match. However, CCGBank appears to have a large degree of mismatch. In this sense, root/head word based scoring provides fair comparison between LTAG-spinal SRL system and the CCGBank SRL system. Recent work (Boxwell and White, 2008) changes some structures in the CCGBank to correspond more closely with the Probbank annotations. They also resolve split arguments that occur in Propbank and add these annotations into a revised version of the CCGBank. As a result they show that the oracle f-score improves by over 2 points over the (Gildea and Hockenmaier, 2003) oracle results for the numbered arguments only (A0, ..., A5). It remains an open question whether a full SRL system based on a CCG parser trained on this new version of the CCGBank will be competitive against the LTAG-spinal based and phrasestructure based SRL systems</context>
</contexts>
<marker>Boxwell, White, 2008</marker>
<rawString>Stephen A. Boxwell and Michael White. 2008. Projecting propbank roles onto the ccgbank. In LREC2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>L M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2004 Shared Task.</title>
<date>2004</date>
<booktitle>In CoNLL-2004.</booktitle>
<marker>Carreras, M`arquez, 2004</marker>
<rawString>X. Carreras and L. M`arquez. 2004. Introduction to the CoNLL-2004 Shared Task. In CoNLL-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>L M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2005 Shared Task.</title>
<date>2005</date>
<booktitle>In CoNLL-2005.</booktitle>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>X. Carreras and L. M`arquez. 2005. Introduction to the CoNLL-2005 Shared Task. In CoNLL-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chen</author>
<author>O Rambow</author>
</authors>
<title>Use of deep linguistic features for the recognition and labeling of semantic arguments.</title>
<date>2003</date>
<booktitle>In EMNLP-2003.</booktitle>
<contexts>
<context position="1820" citStr="Chen and Rambow, 2003" startWordPosition="276" endWordPosition="279">em. [A0seller Ports of Call Inc.] reached agreements to [Vverb sell] [A1thing its remaining seven aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 2008) have also been explored. It has been previo</context>
<context position="3314" citStr="Chen and Rambow, 2003" startWordPosition="510" endWordPosition="513">an-Collins style head-percolation based heuristic rules (Liu and Sarkar, 2007). The LTAG-spinal Treebank (Shen et al., 2008) provided a corpus of derivation trees where elementary trees were extracted from the Penn Treebank in combination with the Propbank predicateargument annotation. The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG: (Liu and Sarkar, 2007) uses LTAG-based features extracted from phrase-structure trees as an additional source of features and combined them with features from a phrase-structure based SRL framework; (Chen and Rambow, 2003) only considers those complement/adjunct semantic roles that can be localized in LTAG elementary trees, which leads to a loss of over 17% instances of semantic roles even from gold-standard trees. The LTAG-spinal formalism was initially proposed for automatic treebank extraction and statistical parsing (Shen and Joshi, 2005). However, its Propbank-guided treebank extraction process further strengthens the connection between the LTAG-spinal and semantic role labeling. In this paper, we present an SRL system that was built to 1 Proceedings of the 2009 Workshop on Grammar Engineering Across Frame</context>
</contexts>
<marker>Chen, Rambow, 2003</marker>
<rawString>J. Chen and O. Rambow. 2003. Use of deep linguistic features for the recognition and labeling of semantic arguments. In EMNLP-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
<author>C Wooters</author>
<author>C F Baker</author>
</authors>
<title>Building a large lexical databank which provides deep semantics.</title>
<date>2001</date>
<journal>In</journal>
<pages>15--2001</pages>
<contexts>
<context position="1669" citStr="Fillmore et al., 2001" startWordPosition="252" endWordPosition="255">Specifically, it involves identifying portions of the sentence that represent the predicate’s arguments and assigning pre-specified semantic roles to them. [A0seller Ports of Call Inc.] reached agreements to [Vverb sell] [A1thing its remaining seven aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as </context>
</contexts>
<marker>Fillmore, Wooters, Baker, 2001</marker>
<rawString>C.J. Fillmore, C. Wooters, and C.F. Baker. 2001. Building a large lexical databank which provides deep semantics. In PACLIC15-2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>J Hockenmaier</author>
</authors>
<title>Identifying semantic roles using combinatory categorial grammar.</title>
<date>2003</date>
<booktitle>In EMNLP-2003.</booktitle>
<contexts>
<context position="1850" citStr="Gildea and Hockenmaier, 2003" startWordPosition="280" endWordPosition="283">Call Inc.] reached agreements to [Vverb sell] [A1thing its remaining seven aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 2008) have also been explored. It has been previously noted that LTAG, which ha</context>
<context position="24420" citStr="Gildea and Hockenmaier, 2003" startWordPosition="3904" endWordPosition="3907">ed our LTAG-spinal based SRL system with phrase-structure based one (see the description in earlier sections), for argument identification and classification. In order to analyze the impact of errors in syntactic parsers, results are presented on both gold-standard trees and automatic parses. Based on the fact that nearly 97% e-trees that correspond to the core arguments6 belong to pattern 1 and 2, which accounts for the largest portion of argument loss in automatic parses, the classification results are also given for these core arguments. We also compare with the CCG-based SRL presented in (Gildea and Hockenmaier, 2003)7, which has a similar motivation as this paper, except they use the Combinatory Categorial Grammar formalism and the CCGBank syntactic Treebank which was converted from the Penn Treebank. Scoring strategy To have a fair evaluation of arguments between the LTAG-spinal dependency parse and the Penn Treebank phrase structure, we report the root/head-word based scoring strategy for performance comparison, where a case is counted as positive as long as the root of the argument e-tree is correctly identified in LTAG-spinal and the head word of the argument constituent is correctly identified in phr</context>
<context position="26979" citStr="Gildea and Hockenmaier, 2003" startWordPosition="4322" endWordPosition="4325">t surprising to see that phrase-structure based one has the best match. However, CCGBank appears to have a large degree of mismatch. In this sense, root/head word based scoring provides fair comparison between LTAG-spinal SRL system and the CCGBank SRL system. Recent work (Boxwell and White, 2008) changes some structures in the CCGBank to correspond more closely with the Probbank annotations. They also resolve split arguments that occur in Propbank and add these annotations into a revised version of the CCGBank. As a result they show that the oracle f-score improves by over 2 points over the (Gildea and Hockenmaier, 2003) oracle results for the numbered arguments only (A0, ..., A5). It remains an open question whether a full SRL system based on a CCG parser trained on this new version of the CCGBank will be competitive against the LTAG-spinal based and phrasestructure based SRL systems. Results from using automatic parses Table 4 shows the results when automatic parses are used. With automatic parses, the advantage of LTAGspinal in the precision scores still exists: giving a higher score in both identification and core argument classification; only 0.5% lower for full argument classification. However, with ove</context>
</contexts>
<marker>Gildea, Hockenmaier, 2003</marker>
<rawString>D. Gildea and J. Hockenmaier. 2003. Identifying semantic roles using combinatory categorial grammar. In EMNLP-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>58</volume>
<issue>3</issue>
<contexts>
<context position="1749" citStr="Gildea and Jurafsky, 2002" startWordPosition="264" endWordPosition="267"> the predicate’s arguments and assigning pre-specified semantic roles to them. [A0seller Ports of Call Inc.] reached agreements to [Vverb sell] [A1thing its remaining seven aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea and D. Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 58(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>M Palmer</author>
</authors>
<title>The necessity of parsing for predicate argument recognition.</title>
<date>2002</date>
<booktitle>In ACL2002.</booktitle>
<contexts>
<context position="1774" citStr="Gildea and Palmer, 2002" startWordPosition="268" endWordPosition="271">and assigning pre-specified semantic roles to them. [A0seller Ports of Call Inc.] reached agreements to [Vverb sell] [A1thing its remaining seven aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 200</context>
</contexts>
<marker>Gildea, Palmer, 2002</marker>
<rawString>D. Gildea and M. Palmer. 2002. The necessity of parsing for predicate argument recognition. In ACL2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hacioglu</author>
</authors>
<title>Semantic role labeling using dependency trees.</title>
<date>2004</date>
<booktitle>In COLING-2004.</booktitle>
<contexts>
<context position="2352" citStr="Hacioglu, 2004" startWordPosition="361" endWordPosition="362">afsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 2008) have also been explored. It has been previously noted that LTAG, which has the useful property of extended domain of locality (EDL), is well-suited to address the SRL task, c.f. (Chen and Rambow, 2003; Liu and Sarkar, 2007). However, LTAG elementary trees were extracted from the derived parse trees by using Magerman-Collins style head-percolation based heuristic rules (Liu and Sarkar, 2007). The LTAG-spinal Treebank (Shen et al., 2008) provided a corpus of derivation trees where elementary trees were extracted from the Penn Treebank in combination with the Propbank pre</context>
</contexts>
<marker>Hacioglu, 2004</marker>
<rawString>K. Hacioglu. 2004. Semantic role labeling using dependency trees. In COLING-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Making large-scale svm learning practical. Advances in Kernel Methods - Support Vector Machines.</title>
<date>1999</date>
<contexts>
<context position="22312" citStr="Joachims, 1999" startWordPosition="3546" endWordPosition="3547">classification) and then classify a node identified as an argument with the particular SRL using one-vs-all binary classification. 4 Experiments 4.1 Data Set Following the usual convention for parsing and SRL experiments, LTAG-spinal Treebank Section 2-21 is used for training and Section 23 for testing. Propbank argument set is used which includes numbered arguments A0 to A5 and 13 adjunct-like arguments. 454 sentences in the Penn Treebank are skipped from the LTAG-spinal Treebank (Shen et al., 2008)4, which results in 115 predicateargument pairs ignored in the test set. We applied SVM-light (Joachims, 1999) with default linear kernel to feature vectors. 30% of the training samples are used to fine tune the regularization parameter c and the loss-function cost parameter j for both argument identification and classification. With parameter validation experiments, we set c = 0.1 and j = 1 for {A0, AM4Based on (Shen et al., 2008), the skipped 454 sentences amount to less than 1% of the total sentences. 314 of these 454 sentences have gapping structures. Since PTB does not annotate the trace of deleted predicates, additional manual annotation is required to handle these sentences. For the rest of the</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T. Joachims. 1999. Making large-scale svm learning practical. Advances in Kernel Methods - Support Vector Machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Liu</author>
<author>A Sarkar</author>
</authors>
<title>Experimental evaluation of LTAG-based features for semantic role labeling.</title>
<date>2007</date>
<booktitle>In EMNLP-2007.</booktitle>
<contexts>
<context position="2600" citStr="Liu and Sarkar, 2007" startWordPosition="402" endWordPosition="405"> CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 2008) have also been explored. It has been previously noted that LTAG, which has the useful property of extended domain of locality (EDL), is well-suited to address the SRL task, c.f. (Chen and Rambow, 2003; Liu and Sarkar, 2007). However, LTAG elementary trees were extracted from the derived parse trees by using Magerman-Collins style head-percolation based heuristic rules (Liu and Sarkar, 2007). The LTAG-spinal Treebank (Shen et al., 2008) provided a corpus of derivation trees where elementary trees were extracted from the Penn Treebank in combination with the Propbank predicateargument annotation. The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG: (Liu and Sarkar, 2007) uses LTAG-based features extracted from phrase-structure trees as an additional sourc</context>
</contexts>
<marker>Liu, Sarkar, 2007</marker>
<rawString>Y. Liu and A. Sarkar. 2007. Experimental evaluation of LTAG-based features for semantic role labeling. In EMNLP-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>D Gildea</author>
<author>P Kingsbury</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="1430" citStr="Palmer et al., 2005" startWordPosition="212" endWordPosition="215">cit and accessible in the LTAG-spinal Treebank, which we show to be a useful resource for semantic role labeling. 1 Introduction Semantic Role Labeling (SRL) aims to identify and label all the arguments for each predicate in a sentence. Specifically, it involves identifying portions of the sentence that represent the predicate’s arguments and assigning pre-specified semantic roles to them. [A0seller Ports of Call Inc.] reached agreements to [Vverb sell] [A1thing its remaining seven aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2</context>
<context position="7336" citStr="Palmer et al., 2005" startWordPosition="1161" endWordPosition="1164">tic role played by the different child nodes. So far, we can see that in contrast with traditional LTAG where arguments refer to obligatory constituents only, subcategorization frames and argument-adjunct distinction are underspecified in LTAG-spinal. Since argument-adjunct disambiguation is one of the major challenges faced by LTAG treebank construction, LTAG-spinal works around this issue by leaving the disambiguation task for further deep processing, such as semantic role labeling. LTAG-spinal is weakly equivalent to traditional LTAG with adjunction constraints1 (Shen, 2006). The Propbank (Palmer et al., 2005) is an annotated corpus of verb subcategorization and alternations which was created by adding a layer of predicate-argument annotation over the phrase structure trees in the Penn Treebank. The LTAGspinal Treebank is extracted from the Penn Treebank by exploiting Propbank annotation. Specifically, as described in (Shen et al., 2008), a Penn Treebank syntax tree is taken as an LTAG-spinal derived tree; then information from the Penn Treebank and Propbank is merged using tree transformations. For instance, LTAG predicate coordination and instances of adjunction are recognized using Propbank anno</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>M. Palmer, D. Gildea, and P. Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>W Ward</author>
<author>K Hacioglu</author>
</authors>
<title>Shallow Semantic Parsing Using Support Vector Machines.</title>
<date>2004</date>
<booktitle>In HLT-NAACL-2004.</booktitle>
<contexts>
<context position="1894" citStr="Pradhan et al., 2004" startWordPosition="288" endWordPosition="291">ng its remaining seven aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 2008) have also been explored. It has been previously noted that LTAG, which has the useful property of extended domain of </context>
</contexts>
<marker>Pradhan, Ward, Hacioglu, 2004</marker>
<rawString>S. Pradhan, W. Ward, K. Hacioglu, , J. H. Martin, and D. Jurafsky. 2004. Shallow Semantic Parsing Using Support Vector Machines. In HLT-NAACL-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>W Ward</author>
<author>K Hacioglu</author>
</authors>
<title>Semantic role labeling using different syntactic views.</title>
<date>2005</date>
<booktitle>In ACL-2005.</booktitle>
<contexts>
<context position="1917" citStr="Pradhan et al., 2005" startWordPosition="292" endWordPosition="296"> aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 2008) have also been explored. It has been previously noted that LTAG, which has the useful property of extended domain of locality (EDL), is well</context>
</contexts>
<marker>Pradhan, Ward, Hacioglu, 2005</marker>
<rawString>S. Pradhan, W. Ward, K. Hacioglu, , J. H. Martin, and D. Jurafsky. 2005. Semantic role labeling using different syntactic views. In ACL-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Stuart M Shieber</author>
</authors>
<title>An alternative conception of tree-adjoining derivation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="5808" citStr="Schabes and Shieber, 1994" startWordPosition="913" endWordPosition="916">dicate etree: a spinal initial tree is composed of a lexical spine from the root to the anchor, and nothing else; a spinal auxiliary tree is composed of a lexical spine and a recursive spine from the root to the foot node. For example, in Figure 1 (from (Shen et al., 2008)), the lexical spine for the auxiliary tree is Bl,.., Bi,.., B, the recursive spine is Bi, .., Bi, .., Bi. Two operations attachment and adjunction are defined in LTAG-spinal where adjunction is the same as adjunction in the traditional LTAG; attachment stems from sister adjunction as defined in Tree Insertion Grammar (TIG) (Schabes and Shieber, 1994), which corresponds to the case where the root of an initial tree is taken as a child of another spinal e-tree. The two operations are applied to LTAG-spinal e-tree pairs resulting in an LTAG derivation tree which is similar to a dependency tree (see Figure 2). In Figure 2, e-tree anchored with continue is the only auxiliary tree; all other e-trees are initial trees. The arrow is directed from parent to child, with the type of operation labeled on the arc. The operation types are: att denotes attachment operation; adj denotes adjunction operation. The sibling nodes may have differinitial: auxi</context>
</contexts>
<marker>Schabes, Shieber, 1994</marker>
<rawString>Yves Schabes and Stuart M. Shieber. 1994. An alternative conception of tree-adjoining derivation. Computational Linguistics, 20(1):91–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>Aravind Joshi</author>
</authors>
<title>Incremental ltag parsing.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP-2005.</booktitle>
<contexts>
<context position="3640" citStr="Shen and Joshi, 2005" startWordPosition="560" endWordPosition="563">overcome some of the limitations of the previous work on SRL using LTAG: (Liu and Sarkar, 2007) uses LTAG-based features extracted from phrase-structure trees as an additional source of features and combined them with features from a phrase-structure based SRL framework; (Chen and Rambow, 2003) only considers those complement/adjunct semantic roles that can be localized in LTAG elementary trees, which leads to a loss of over 17% instances of semantic roles even from gold-standard trees. The LTAG-spinal formalism was initially proposed for automatic treebank extraction and statistical parsing (Shen and Joshi, 2005). However, its Propbank-guided treebank extraction process further strengthens the connection between the LTAG-spinal and semantic role labeling. In this paper, we present an SRL system that was built to 1 Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks, ACL-IJCNLP 2009, pages 1–9, Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP explore the utility of this new formalism, its Treebank and the output of its statistical parser. Experiments show that our LTAG-spinal based SRL system achieves very high precision on both goldstandard and automatic parses, and signifi</context>
<context position="9752" citStr="Shen and Joshi, 2005" startWordPosition="1540" endWordPosition="1543">r the LTAG-spinal derivation trees. In each derivation tree, each node is associated with LTAG-spinal e-trees. Each argument (A0, A1, etc.) is referred to as A and the predicate is called P. In most cases, the argument is found locally in the derivation tree due to the extended domain of locality in e-trees. Thus, most arguments are identified by the pattern P —* A or P +— A. The next section contains a discussion of such patterns in more detail. Two statistical parsers have been developed by Libin Shen specifically for training on the LTAG-spinal treebank: a left-to-right incremental parser (Shen and Joshi, 2005) and a bidirectional incremental parser (Shen and Joshi, 2008). If one compares the output of these two parsers, the leftto-right parser produces full LTAG-spinal derivation trees (including all the information about specific elementary trees used in the derivation and the attachment information within the e-trees) while the bidirectional parser produces derivation trees without information about elementary trees or attachment points (similar to output from a dependency parser). In this paper, we use the leftto-right incremental parser for its richer output because our SRL system uses feature </context>
<context position="31482" citStr="Shen and Joshi, 2005" startWordPosition="4977" endWordPosition="4980">CG Root/head-word 81.0/71.5/76.0 80.1/82.8/81.4 76.1/73.5/74.8 classification (full) automatic parses (p/r/f%) Scoring LTAG phrase CCG Root/head-word 78.0/70.0/73.7 78.5/80.3/79.4 71.0/63.1/66.8 Boundary 72.3/65.0/68.5 73.8/75.5/74.7 55.7/49.5/52.4 Table 4: Using automatic parses: comparison of the three SRL systems for argument identification, core and full argument classification structure and CCG formalism. Even though the left-to-right statistical parser that was trained and evaluated on the LTAG-spinal Treebank achieves an f-score of 89.3% for dependencies on Section 23 of this treebank (Shen and Joshi, 2005), the SRL that used this output is worse than expected. An oracle test shows that via the same 7 patterns, only 81.6% predicate-argument pairs can be recovered from the automatic parses, which is a big drop from 96.1% when we use the LTAG-spinal Treebank trees. Parser accuracy is high overall, but needs to be more accurate in recovering the dependencies between predicate and argument. Based on the observation that the low recall occurs not only to the SRL when the automatic parses are used but also when the gold trees are used, we would expect that a thorough error analysis and feature calibra</context>
</contexts>
<marker>Shen, Joshi, 2005</marker>
<rawString>L. Shen and Aravind Joshi. 2005. Incremental ltag parsing. In HLT-EMNLP-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>A Joshi</author>
</authors>
<title>Ltag dependency parsing with bidirectional incremental construction.</title>
<date>2008</date>
<booktitle>In EMNLP-2008.</booktitle>
<contexts>
<context position="9814" citStr="Shen and Joshi, 2008" startWordPosition="1549" endWordPosition="1552">ach node is associated with LTAG-spinal e-trees. Each argument (A0, A1, etc.) is referred to as A and the predicate is called P. In most cases, the argument is found locally in the derivation tree due to the extended domain of locality in e-trees. Thus, most arguments are identified by the pattern P —* A or P +— A. The next section contains a discussion of such patterns in more detail. Two statistical parsers have been developed by Libin Shen specifically for training on the LTAG-spinal treebank: a left-to-right incremental parser (Shen and Joshi, 2005) and a bidirectional incremental parser (Shen and Joshi, 2008). If one compares the output of these two parsers, the leftto-right parser produces full LTAG-spinal derivation trees (including all the information about specific elementary trees used in the derivation and the attachment information within the e-trees) while the bidirectional parser produces derivation trees without information about elementary trees or attachment points (similar to output from a dependency parser). In this paper, we use the leftto-right incremental parser for its richer output because our SRL system uses feature functions that use information about the elementary trees in t</context>
<context position="11210" citStr="Shen and Joshi, 2008" startWordPosition="1770" endWordPosition="1773">RL. For example, assume the parent spine is “S-VP-VB-anchor” (the root label is S, and “anchor” is where the lexical item is inserted). Along with direction information, the landing site label “S” is likely to be a good indicator for argument A0 (subject) while the landing site label “VP” could be a good indicator for “A1” (object). In this sense, the incremental left-toright parser is preferable for semantic role labeling. However, having been developed earlier than the bidirectional parser, the incremental parser obtains 1.2% less in dependency accuracy compared to the bidirectional parser (Shen and Joshi, 2008). 2.2 Predicate-argument relations in the LTAG-spinal Treebank The Propbank-guided extraction process for LTAG-spinal treebank naturally creates a close connection between these two resources. To examine the compatibility of the LTAG-spinal Treebank with Propbank, (Shen et al., 2008) provides the frequency for specific types of paths from the predicate to the argument in the LTAG-spinal derivation trees from the LTAG-spinal Treebank. The 8 most frequent patterns account for 95.5% of the total predicate-argument pairs of the LTAGspinal Treebank, of which 88.4% are directly connected pairs. Thes</context>
</contexts>
<marker>Shen, Joshi, 2008</marker>
<rawString>L. Shen and A. Joshi. 2008. Ltag dependency parsing with bidirectional incremental construction. In EMNLP-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>L Champollion</author>
<author>A Joshi</author>
</authors>
<title>Ltagspinal and the treebank: A new resource for incremental, dependency and semantic parsing.</title>
<date>2008</date>
<journal>Language Resources and Evaluation,</journal>
<volume>42</volume>
<issue>1</issue>
<contexts>
<context position="2816" citStr="Shen et al., 2008" startWordPosition="432" endWordPosition="435">reebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 2008) have also been explored. It has been previously noted that LTAG, which has the useful property of extended domain of locality (EDL), is well-suited to address the SRL task, c.f. (Chen and Rambow, 2003; Liu and Sarkar, 2007). However, LTAG elementary trees were extracted from the derived parse trees by using Magerman-Collins style head-percolation based heuristic rules (Liu and Sarkar, 2007). The LTAG-spinal Treebank (Shen et al., 2008) provided a corpus of derivation trees where elementary trees were extracted from the Penn Treebank in combination with the Propbank predicateargument annotation. The LTAG-spinal Treebank can be used to overcome some of the limitations of the previous work on SRL using LTAG: (Liu and Sarkar, 2007) uses LTAG-based features extracted from phrase-structure trees as an additional source of features and combined them with features from a phrase-structure based SRL framework; (Chen and Rambow, 2003) only considers those complement/adjunct semantic roles that can be localized in LTAG elementary trees</context>
<context position="4901" citStr="Shen et al., 2008" startWordPosition="753" endWordPosition="756">ore importantly, it shows that LTAG-spinal is an useful resource for semantic role labeling, with the potential for further improvement. 2 LTAG-spinal, its Treebank and Parsers This section gives a brief introduction of LTAGspinal formalism, its Treebank that is extracted with the help of Propbank annotation, and its two statistical parsers that are trained on the Treebank. Predicate-argument relations encoded in the LTAG-spinal treebank will also be discussed to illustrate its compatibility with Propbank and their potential utility for the SRL task. 2.1 LTAG-spinal The LTAG-spinal formalism (Shen et al., 2008) is a variant of Lexicalized Tree Adjoining Grammar (LTAG) (Abeill´e and Rambow, 2001). Compared to traditional LTAG, the two types of elementary trees (e-tree for short), initial and auxiliary trees, are in spinal form with no substitution nodes for arguments appearing in the predicate etree: a spinal initial tree is composed of a lexical spine from the root to the anchor, and nothing else; a spinal auxiliary tree is composed of a lexical spine and a recursive spine from the root to the foot node. For example, in Figure 1 (from (Shen et al., 2008)), the lexical spine for the auxiliary tree is</context>
<context position="7670" citStr="Shen et al., 2008" startWordPosition="1215" endWordPosition="1218">reebank construction, LTAG-spinal works around this issue by leaving the disambiguation task for further deep processing, such as semantic role labeling. LTAG-spinal is weakly equivalent to traditional LTAG with adjunction constraints1 (Shen, 2006). The Propbank (Palmer et al., 2005) is an annotated corpus of verb subcategorization and alternations which was created by adding a layer of predicate-argument annotation over the phrase structure trees in the Penn Treebank. The LTAGspinal Treebank is extracted from the Penn Treebank by exploiting Propbank annotation. Specifically, as described in (Shen et al., 2008), a Penn Treebank syntax tree is taken as an LTAG-spinal derived tree; then information from the Penn Treebank and Propbank is merged using tree transformations. For instance, LTAG predicate coordination and instances of adjunction are recognized using Propbank annotation. LTAG elementary trees are then extracted from the transformed Penn Treebank trees recursively, using the Propbank annotation and a Magerman-Collins style head percolation table. This guided extraction process allows syntax and semantic role information to be combined in LTAG-spinal derivation trees. For example, the 1null ad</context>
<context position="9057" citStr="Shen et al., 2008" startWordPosition="1422" endWordPosition="1425">igure 3: Three examples of LTAG-spinal derivation trees where predicates and their Propbank style argument labels are given. These examples are from LTAG-spinal Treebank Section 22. Penn Treebank does not differentiate raising verbs and control verbs, however, based on the Propbank information, LTAG-spinal makes this distinction explicit. Thus, the error of taking a subject argument which is not semantically an argument of the raising verb can be avoided. Another property of LTAG-spinal Treebank extraction lies in the flexibility and simplicity of the treatment of predicate coordination (see (Shen et al., 2008)). Figure 3 shows three examples of Propbank annotation as decorations over the LTAG-spinal derivation trees. In each derivation tree, each node is associated with LTAG-spinal e-trees. Each argument (A0, A1, etc.) is referred to as A and the predicate is called P. In most cases, the argument is found locally in the derivation tree due to the extended domain of locality in e-trees. Thus, most arguments are identified by the pattern P —* A or P +— A. The next section contains a discussion of such patterns in more detail. Two statistical parsers have been developed by Libin Shen specifically for </context>
<context position="11494" citStr="Shen et al., 2008" startWordPosition="1809" endWordPosition="1812">P” could be a good indicator for “A1” (object). In this sense, the incremental left-toright parser is preferable for semantic role labeling. However, having been developed earlier than the bidirectional parser, the incremental parser obtains 1.2% less in dependency accuracy compared to the bidirectional parser (Shen and Joshi, 2008). 2.2 Predicate-argument relations in the LTAG-spinal Treebank The Propbank-guided extraction process for LTAG-spinal treebank naturally creates a close connection between these two resources. To examine the compatibility of the LTAG-spinal Treebank with Propbank, (Shen et al., 2008) provides the frequency for specific types of paths from the predicate to the argument in the LTAG-spinal derivation trees from the LTAG-spinal Treebank. The 8 most frequent patterns account for 95.5% of the total predicate-argument pairs of the LTAGspinal Treebank, of which 88.4% are directly connected pairs. These statistics not only provide em3 Path Pattern Number Percent 1 P—*A 8294 81.3 2 P+—A, V+—A 720 7.1 3 P+—Px—*A 437 4.3 4 P+—Coord—*Px—*A 216 2.1 5 P+—Ax+—Py—*A 84 0.82 6 P+—Coord+—Px—*A 40 0.39 7 P+—Px+—Py—*A 13 0.13 total recovered w/ patterns 9804 96.1 total 10206 100.0 Table 1: Di</context>
<context position="14302" citStr="Shen et al., 2008" startWordPosition="2267" endWordPosition="2270"> pattern 3, where stabilize corresponds to Px and Street corresponds to A in the pattern 3 schema. Pattern 4 denotes the case where argument (A) is shared between coordinated predicates (P and Px); The main difference of pattern 5-7 exists where the sibling node of A(rgument) is categorized into: predicate (Px) in pattern 7, predicate coordination node (Coord) in pattern 6 and others (Ax) in pattern 5. We will retain this difference instead of merging it since the semantic relation between P and A varies based on these differences. Example sentences for other (rarer) patterns can be found in (Shen et al., 2008). 3 LTAG-spinal based SRL System Description In this section, we describe our LTAG-spinal based SRL system. So far, we have studied LTAG-spinal formalism, its treebank and parsers. In particular, the frequency distribution of the seven most seen predicate-argument pair patterns in LTAG-spinal Treebank tells us that predicate-argument relationships typical to semantic role labeling are often local in LTAG-spinal derivation trees. Pruning, argument identification and argument classification – the 3-stage architecture now standard in SRL systems is also used in this paper. Specifically, for the s</context>
<context position="20503" citStr="Shen et al., 2008" startWordPosition="3260" endWordPosition="3263">. Order of current child node among its siblings. In pattern 1, predicate e-tree is parent, and argument e-tree is child. This feature refers to the order of argument e-tree among its siblings nodes (with predicate e-tree as parent). Distance of predicate e-tree and argument tree in the LTAG derivation tree: For example, for pattern 1 and 2, the distance has value 0; for pattern 3, the distance has value 1. Pattern ID valued 1-7. (see Table 1 and Table 2) Combination of position and pattern ID, combination of distance and pattern ID, combination of 2XP-NNP is a normalized e-tree form used in (Shen et al., 2008) for efficiency and to avoid the problem of sparse data over too many e-trees. 3it can either be predicate e-tree or argument e-tree. For example, for pattern Pt-A, the A(rgument) e-tree is the host spine. 5 position and order. Features from intermediate predicate e-tree same features as predicate e-tree features. Features from spine node of intermediate predicate e-tree and argument e-tree (SP2) for predicate-argument pairs of pattern 3-7. These features are similar to the SP1 features but instead between intermediate predicate e-tree and argument e-tree. Relative position between predicate e</context>
<context position="22202" citStr="Shen et al., 2008" startWordPosition="3527" endWordPosition="3530"> any (for the predicate). In test data, we first identify nodes as arguments using these features (ARG v.s. NULL classification) and then classify a node identified as an argument with the particular SRL using one-vs-all binary classification. 4 Experiments 4.1 Data Set Following the usual convention for parsing and SRL experiments, LTAG-spinal Treebank Section 2-21 is used for training and Section 23 for testing. Propbank argument set is used which includes numbered arguments A0 to A5 and 13 adjunct-like arguments. 454 sentences in the Penn Treebank are skipped from the LTAG-spinal Treebank (Shen et al., 2008)4, which results in 115 predicateargument pairs ignored in the test set. We applied SVM-light (Joachims, 1999) with default linear kernel to feature vectors. 30% of the training samples are used to fine tune the regularization parameter c and the loss-function cost parameter j for both argument identification and classification. With parameter validation experiments, we set c = 0.1 and j = 1 for {A0, AM4Based on (Shen et al., 2008), the skipped 454 sentences amount to less than 1% of the total sentences. 314 of these 454 sentences have gapping structures. Since PTB does not annotate the trace </context>
<context position="28851" citStr="Shen et al., 2008" startWordPosition="4619" endWordPosition="4622">provides trace (empty category) information in their output, no trace information is used for LTAGspinal based SRL or the phrase-structure based SRL even though it is available in their goldstandard trees. 5 Conclusion and Future Work With a small feature set, the LTAG-spinal based SRL system described in this paper provides the highest precision in almost all the scenarios, which indicates that the shallow semantic relations, e.g., the predicate-argument relations that are encoded in the LTAG-spinal Treebank are useful for SRL, especially when compared to the phrase structure Penn Treebank. (Shen et al., 2008) achieves an fscore of 91.6% for non-trace SRL identification on the entire Treebank by employing a simple rulebased system, which also suggested this conclusion. In other words, there is a tighter connection between the syntax and semantic role labels in the LTAG-spinal representation. However, in contrast to the high precision, the recall performance of LTAG-spinal based SRL needs a further improvement, especially for the argument classification task. From SRL perspective, on one hand, this may be due to the pattern-based candidate selection, which upper-bounds the number of predicate-argume</context>
</contexts>
<marker>Shen, Champollion, Joshi, 2008</marker>
<rawString>L. Shen, L. Champollion, and A. Joshi. 2008. Ltagspinal and the treebank: A new resource for incremental, dependency and semantic parsing. Language Resources and Evaluation, 42(1):1–19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
</authors>
<date>2006</date>
<tech>Statistical LTAG Parsing. Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="7300" citStr="Shen, 2006" startWordPosition="1157" endWordPosition="1158"> to differentiate the semantic role played by the different child nodes. So far, we can see that in contrast with traditional LTAG where arguments refer to obligatory constituents only, subcategorization frames and argument-adjunct distinction are underspecified in LTAG-spinal. Since argument-adjunct disambiguation is one of the major challenges faced by LTAG treebank construction, LTAG-spinal works around this issue by leaving the disambiguation task for further deep processing, such as semantic role labeling. LTAG-spinal is weakly equivalent to traditional LTAG with adjunction constraints1 (Shen, 2006). The Propbank (Palmer et al., 2005) is an annotated corpus of verb subcategorization and alternations which was created by adding a layer of predicate-argument annotation over the phrase structure trees in the Penn Treebank. The LTAGspinal Treebank is extracted from the Penn Treebank by exploiting Propbank annotation. Specifically, as described in (Shen et al., 2008), a Penn Treebank syntax tree is taken as an LTAG-spinal derived tree; then information from the Penn Treebank and Propbank is merged using tree transformations. For instance, LTAG predicate coordination and instances of adjunctio</context>
</contexts>
<marker>Shen, 2006</marker>
<rawString>L. Shen. 2006. Statistical LTAG Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>S Harabagiu</author>
<author>J Williams</author>
<author>P Aarseth</author>
</authors>
<title>Using predicate-argument structures for information extraction.</title>
<date>2003</date>
<booktitle>In ACL-2003.</booktitle>
<contexts>
<context position="1797" citStr="Surdeanu et al., 2003" startWordPosition="272" endWordPosition="275">ed semantic roles to them. [A0seller Ports of Call Inc.] reached agreements to [Vverb sell] [A1thing its remaining seven aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 2008) have also been explo</context>
</contexts>
<marker>Surdeanu, Harabagiu, Williams, Aarseth, 2003</marker>
<rawString>M. Surdeanu, S. Harabagiu, J. Williams, and P. Aarseth. 2003. Using predicate-argument structures for information extraction. In ACL-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>R Johansson</author>
<author>A Meyers</author>
<author>L M`arquez</author>
<author>J Nivre</author>
</authors>
<title>The conll</title>
<date>2008</date>
<booktitle>In CoNLL-2008.</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>M. Surdeanu, R. Johansson, A. Meyers, L. M`arquez, and J. Nivre. 2008. The conll 2008 shared task on joint parsing of syntactic and semantic dependencies. In CoNLL-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
<author>M Palmer</author>
</authors>
<title>Calibrating features for semantic role labeling.</title>
<date>2004</date>
<booktitle>In EMNLP-2004.</booktitle>
<contexts>
<context position="1872" citStr="Xue and Palmer, 2004" startWordPosition="284" endWordPosition="287">to [Vverb sell] [A1thing its remaining seven aircraft] [A2buyer to buyers that weren’t disclosed] . is an example of SRL annotation from the PropBank corpus (Palmer et al., 2005), where the subscripted information maps the semantic roles A0, A1 and A2 to arguments for the predicate sell as defined in the PropBank Frame Scheme. The availability of annotated corpora like PropBank and FrameNet (Fillmore et al., 2001) have provided rapid development of research into SRL (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Surdeanu et al., 2003; Chen and Rambow, 2003; Gildea and Hockenmaier, 2003; Xue and Palmer, 2004; Pradhan et al., 2004; Pradhan et al., 2005). The shared tasks in CoNLL2004 (Carreras and M`arquez, 2004), CoNLL2005 (Carreras and M`arquez, 2005) and CoNLL2008 (Surdeanu et al., 2008) were all focused on SRL. SRL systems (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002) have extensively used features defined over Penn Treebank phrasestructure trees. Other syntactic representations such as CCG derivations (Gildea and Hockenmaier, 2003) and dependency trees (Hacioglu, 2004; Surdeanu et al., 2008) have also been explored. It has been previously noted that LTAG, which has the useful property </context>
<context position="23333" citStr="Xue and Palmer, 2004" startWordPosition="3727" endWordPosition="3730">314 of these 454 sentences have gapping structures. Since PTB does not annotate the trace of deleted predicates, additional manual annotation is required to handle these sentences. For the rest of the 146 sentences, abnormal structures are generated due to tagging errors. NEG}, c = 0.1, j = 2 for {A1, A2, A4, AMEXT} and c = 0.1 and j = 4 for the rest. For comparison, we also built up a standard 3- stage phrase-structure based SRL system, where exactly the same data set5 is used from 2004 February release of the Propbank. SVM-light with linear kernel is used to train on a standard feature set (Xue and Palmer, 2004). The Charniak and Johnson parser (2006) is used to produce the automatic parses. Note that this phrase-structure based SRL system is state-of-the-art and we have included all the features proposed in the literature that use phrase-structure trees. This system obtains a higher SRL accuracy which can be improved only by using global inference and other ways (such as using multiple parsers) to improve the accuracy on automatic parses. 4.2 Results We compared our LTAG-spinal based SRL system with phrase-structure based one (see the description in earlier sections), for argument identification and</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>N. Xue and M. Palmer. 2004. Calibrating features for semantic role labeling. In EMNLP-2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>