<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006997">
<title confidence="0.93653">
The SAWA Corpus: a Parallel Corpus English - Swahili
</title>
<author confidence="0.921443">
Guy De Pauw
</author>
<affiliation confidence="0.862028">
CNTS - Language Technology Group, University of Antwerp, Belgium
School of Computing and Informatics, University of Nairobi, Kenya
</affiliation>
<email confidence="0.941418">
guy.depauw@ua.ac.be
</email>
<author confidence="0.996077">
Peter Waiganjo Wagacha
</author>
<affiliation confidence="0.993817">
School of Computing and Informatics, University of Nairobi, Kenya
</affiliation>
<email confidence="0.986531">
waiganjo@uonbi.ac.ke
</email>
<author confidence="0.70596">
Gilles-Maurice de Schryver
</author>
<affiliation confidence="0.8343675">
African Languages and Cultures, Ghent University, Belgium
Xhosa Department, University of the Western Cape, South Africa
</affiliation>
<email confidence="0.978169">
gillesmaurice.deschryver@ugent.be
</email>
<sectionHeader confidence="0.995427" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999663736842105">
Research in data-driven methods for Ma-
chine Translation has greatly benefited
from the increasing availability of paral-
lel corpora. Processing the same text in
two different languages yields useful in-
formation on how words and phrases are
translated from a source language into a
target language. To investigate this, a par-
allel corpus is typically aligned by linking
linguistic tokens in the source language to
the corresponding units in the target lan-
guage. An aligned parallel corpus there-
fore facilitates the automatic development
of a machine translation system and can
also bootstrap annotation through projec-
tion. In this paper, we describe data col-
lection and annotation efforts and prelim-
inary experimental results with a parallel
corpus English - Swahili.
</bodyText>
<sectionHeader confidence="0.99913" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999821">
Language technology applications such as ma-
chine translation can provide an invaluable, but
all too often ignored, impetus in bridging the dig-
ital divide between the Western world and Africa.
Quite a few localization efforts are currently un-
derway that improve ICT access in local African
languages. Vernacular content is now increasingly
being published on the Internet, and the need for
robust language technology applications that can
process this data is high.
For a language like Swahili, digital resources
have become increasingly important in everyday
life, both in urban and rural areas, particularly
thanks to the increasing number of web-enabled
mobile phone users in the language area. But most
research efforts in the field of natural language
processing (NLP) for African languages are still
firmly rooted in the rule-based paradigm. Lan-
guage technology components in this sense are
usually straight implementations of insights de-
rived from grammarians. While the rule-based
approach definitely has its merits, particularly in
terms of design transparency, it has the distinct
disadvantage of being highly language-dependent
and costly to develop, as it typically involves a lot
of expert manual effort.
Furthermore, many of these systems are decid-
edly competence-based. The systems are often
tweaked and tuned towards a small set of ideal
sample words or sentences, ignoring the fact that
real-world language technology applications have
to be principally able to handle the performance
aspect of language. Many researchers in the field
are quite rightly growing weary of publications
that ignore quantitative evaluation on real-world
data or that report incredulously high accuracy
scores, excused by the erroneously perceived reg-
ularity of African languages.
In a linguistically diverse and increasingly com-
puterized continent such as Africa, the need for a
more empirical approach to language technology
is high. The data-driven, corpus-based approach
described in this paper establishes such an alter-
native, so far not yet extensively investigated for
African languages. The main advantage of this
</bodyText>
<note confidence="0.949528">
Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages – AfLaT 2009, pages 9–16,
Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.996587">
9
</page>
<bodyText confidence="0.999940818181818">
approach is its language independence: all that is
needed is (linguistically annotated) language data,
which is fairly cheap to compile. Given this data,
existing state-of-the-art algorithms and resources
can consequently be re-used to quickly develop ro-
bust language applications and tools.
Most African languages are however resource-
scarce, meaning that digital text resources are few.
An increasing number of publications however are
showing that carefully selected procedures can in-
deed bootstrap language technology for Swahili
(De Pauw et al., 2006; De Pauw and de Schryver,
2008), Northern Sotho (de Schryver and De Pauw,
2007) and smaller African languages (Wagacha et
al., 2006a; Wagacha et al., 2006b; De Pauw and
Wagacha, 2007; De Pauw et al., 2007a; De Pauw
et al., 2007b).
In this paper we outline on-going research on
the development of a parallel corpus English -
Swahili. The parallel corpus is designed to boot-
strap a data-driven machine translation system for
the language pair in question, as well as open up
possibilities for projection of annotation.
We start off with a short survey of the different
approaches to machine translation (Section 2) and
showcase the possibility of projection of annota-
tion (Section 3). We then concentrate on the re-
quired data collection and annotation efforts (Sec-
tion 4) and describe preliminary experiments on
sentence, word and morpheme alignment (Sec-
tions 5 and 6). We conclude with a discussion of
the current limitations to the approach and provide
pointers for future research (Section 7).
</bodyText>
<sectionHeader confidence="0.986407" genericHeader="introduction">
2 Machine Translation
</sectionHeader>
<bodyText confidence="0.991474405405405">
The main task of Machine Translation (MT) can
be defined as having a computer take a text in-
put in one language, the Source language (SL),
decode its meaning and re-encode it producing as
output a similar-meaning text in another language,
the Target language (TL). The idea of building
an application to automatically convert text from
one language to an equivalent text-meaning in
a second language traces its roots back to Cold
War intelligence efforts in the 1950’s and 60’s for
Russian-English text translations. Since then a
large number of MT systems have been developed
with varying degrees of success. For an excellent
overview of the history of MT, we refer the reader
to Hutchins (1986).
The original dream of creating a fully automatic
MT system has long since been abandoned and
most research in the field currently concentrates
on minimizing human pre- and post-processing ef-
fort. A human translator is thus considered to
work alongside the MT system to produce faster
and more consistent translations.
The Internet brought in an interesting new di-
mension to the purpose of MT. In the mid 1990s,
free on-line translation services began to surface
with an increasing number of MT vendors. The
most famous example is Yahoo!’s Babelfish , of-
fering on-line versions of Systran to translate En-
glish, French, German, Spanish and other Indo-
European languages. Currently Google.inc is also
offering translation services. While these systems
provide far from perfect output, they can often
give readers a sense of what is being talked about
on a web page in a language (and often even char-
acter set) foreign to them.
There are roughly three types of approaches to
machine translation:
</bodyText>
<listItem confidence="0.979928588235294">
1. Rule-based methods perform translation us-
ing extensive lexicons with morphological,
syntactic and semantic information, and large
sets of manually compiled rules, making
them very labor intensive to develop.
2. Statistical methods entail the collection and
statistical analysis of bilingual text corpora,
i.e. parallel corpora. The technique tries
to find the highest probability translation of
a sentence or phrase among the exponential
number of choices.
3. Example-based methods are similar to sta-
tistical methods in that they are parallel cor-
pus driven. An Example-Based Machine
Translator (EBMT) scans for patterns in both
languages and relates them in a translation
memory.
</listItem>
<bodyText confidence="0.9990325">
Most MT systems currently under development
are based on methods (2) and/or (3). Research
in these fields has greatly benefited from the in-
creasing availability of parallel corpora, which are
needed to bootstrap these approaches. Such a par-
allel corpus is typically aligned by linking, either
automatically or manually, linguistic tokens in the
source language to the corresponding units in the
target language. Processing this data enables the
development of fast and effective MT systems in
both directions with a minimum of human involve-
ment.
</bodyText>
<page confidence="0.992109">
10
</page>
<table confidence="0.9997557">
English Swahili English Swahili
Sentences Sentences Words Words
New Testament 7.9k 189.2k 151.1k
Quran 6.2k 165.5k 124.3k
Declaration of HR 0.2k 1.8k 1.8k
Kamusi.org 5.6k 35.5k 26.7k
Movie Subtitles 9.0k 72.2k 58.4k
Investment Reports 3.2k 3.1k 52.9k 54.9k
Local Translator 1.5k 1.6k 25.0k 25.7k
Full Corpus Total 33.6k 33.6k 542.1k 442.9k
</table>
<tableCaption confidence="0.999858">
Table 1: Overview of the data in the SAWA Corpus
</tableCaption>
<sectionHeader confidence="0.775222" genericHeader="method">
3 Projection of Annotation
</sectionHeader>
<bodyText confidence="0.997978179487179">
While machine translation constitutes the most
straightforward application of a parallel corpus,
projection of annotation has recently become an
interesting alternative use of this type of resource.
As previously mentioned, most African languages
are resource-scarce: annotated data is not only un-
available, but commercial interest to develop these
resources is limited. Unsupervised approaches
can be used to bootstrap annotation of a resource-
scarce language (De Pauw and Wagacha, 2007; De
Pauw et al., 2007a) by automatically finding lin-
guistic patterns in large amounts of raw text.
Projection of annotation attempts to achieve the
same goal, but through the use of a parallel cor-
pus. These techniques try to transport the annota-
tion of a well resourced source language, such as
English, to texts in a target language. As a natu-
ral extension of the domain of machine translation,
these methods employ parallel corpora which are
aligned at the sentence and word level. The di-
rect correspondence assumption coined in Hwa et
al. (2002) hypothesizes that words that are aligned
between source and target language, must share
linguistic features as well. It therefore allows for
the annotation of the words in the source language
to be projected unto the text in the target language.
The following general principle holds: the closer
source and target language are related, the more
accurate this projection can be performed. Even
though lexical and structural differences between
languages prevent a simple one-to-one mapping,
knowledge transfer is often able to generate a well
directed annotation of the target language.
This holds particular promise for the annotation
of dependency analyses for Swahili, as exempli-
fied in Figure 1, since dependency grammar fo-
main
root The cat fell into the water
root Paka alianguka ndani ya maji
</bodyText>
<figureCaption confidence="0.9031535">
Figure 1: Projection of Dependency Analysis An-
notation
</figureCaption>
<bodyText confidence="0.999386285714286">
cuses on semantic relationships, rather than core
syntactic properties, that are much more trouble-
some to project across languages. The idea is that
a relationship that holds between two words in the
source language (for instance the subj relationship
between cat and fell), also holds for the corre-
sponding linguistic tokens in the target language,
i.e. paka and alianguka.
In the next section we describe data collection
and preprocessing efforts on the SAWA Corpus,
a parallel corpus English - Swahili (cf. Table 1),
which will enable this type of projection of anno-
tation, as well as the development of a data-driven
machine translation system.
</bodyText>
<sectionHeader confidence="0.925552" genericHeader="method">
4 Data Collection and Annotation
</sectionHeader>
<bodyText confidence="0.990819">
While digital data is increasingly becoming avail-
able for Swahili on the Internet, sourcing useful
</bodyText>
<figure confidence="0.9679862">
comp
dt subj pp dt
main comp
subj pp
??
</figure>
<page confidence="0.813146">
11
</page>
<figureCaption confidence="0.998398">
Figure 2: Manual word alignment using the UMIACS interface
</figureCaption>
<bodyText confidence="0.999972846153846">
bilingual data is far from trivial. At this stage in
the development of the MT system, it is paramount
to use faithfully translated material, as this benefits
further automated processing. The corpus-based
MT approaches we wish to employ, require word
alignment to be performed on the texts, during
which the words in the source language are linked
to the corresponding words in the target language
(also see Figures 1 and 2).
But before we can do this, we need to perform
sentence-alignment, during which we establish an
unambiguous mapping between the sentences in
the source text and the sentences in the target text.
While some data is inherently sentence-aligned,
other texts require significant preprocessing before
word alignment can be performed.
The SAWA Corpus currently consists of a rea-
sonable amount of data (roughly half a million
words in each language), although this is not
comparable to the resources available to Indo-
European language pairs, such as the Hansard cor-
pus (Roukos et al., 1997) (2.87 million sentence
pairs). Table 1 gives an overview of the data avail-
able in the SAWA Corpus. For each segment it lists
the number of sentences and words in the respec-
tive languages.
</bodyText>
<subsectionHeader confidence="0.963692">
4.1 Sentence-aligned Resources
</subsectionHeader>
<bodyText confidence="0.999970666666667">
We found digitally available Swahili versions of
the New Testament and the Quran for which we
sourced the English counterparts. This is not a
trivial task when, as in the case of the Swahili
documents, the exact source of the translation is
not provided. By carefully examining subtle dif-
ferences in the English versions, we were how-
ever able to track down the most likely candidate.
While religious material has a specific register and
may not constitute ideal training material for an
open-ended MT system, it does have the advan-
tage of being inherently aligned on the verse level,
facilitating further sentence alignment. Another
typical bilingual text is the UN Declaration of Hu-
man Rights, which is available in many of the
world’s languages, including Swahili. The manual
sentence alignment of this text is greatly facilitated
by the fixed structure of the document.
The downloadable version of the on-line dictio-
nary English-Swahili (Benjamin, 2009) contains
individual example sentences associated with the
dictionary entries. These can be extracted and
used as parallel data in the SAWA corpus. Since
at a later point, we also wish to study the specific
linguistic aspects of spoken language, we opted
to have some movie subtitles manually translated.
These can be extracted from DVDs and while the
</bodyText>
<page confidence="0.994011">
12
</page>
<bodyText confidence="0.9998158">
language is compressed to fit on screen and con-
stitutes scripted language, they nevertheless pro-
vide a reasonable approximation of spoken lan-
guage. Another advantage of this data is that it
is inherently sentence-aligned, thanks to the tech-
nical time-coding information. It also opens up
possibilities for MT systems with other language
pairs, since a commercial DVD typically contains
subtitles for a large number of other languages as
well.
</bodyText>
<subsectionHeader confidence="0.935562">
4.2 Paragraph-aligned Resources
</subsectionHeader>
<bodyText confidence="0.999972884615385">
The rest of the material consists of paragraph-
aligned data, which was manually sentence-
aligned. We obtained a substantial amount of data
from a local Kenyan translator. Finally, we also
included Kenyan investment reports. These are
yearly reports from local companies and are pre-
sented in both English and Swahili. A major dif-
ficulty was extracting the data from these docu-
ments. The company reports are presented in col-
orful brochures in PDF format, meaning automatic
text exports require manual post-processing and
paragraph alignment (Figure 3). They neverthe-
less provide a valuable resource, since they come
from a fairly specific domain and are a good sam-
ple of the type of text the projected MT system
may need to process in a practical setting.
The reader may note that there is a very diverse
variety of texts within the SAWA corpus, ranging
from movie subtitles to religious texts. While it
certainly benefits the evaluation to use data from
texts in one specific language register, we have
chosen to maintain variety in the language data at
this point. Upon evaluating the decoder at a later
stage, we will however investigate the bias intro-
duced by the specific language registers in the cor-
pus.
</bodyText>
<subsectionHeader confidence="0.998777">
4.3 Word Alignment
</subsectionHeader>
<bodyText confidence="0.9998395">
All of the data in the corpus was subsequently
tokenized, which involves automatically cleaning
up the texts, conversion to UTF-8, and splitting
punctuation from word forms. The next step in-
volved scanning for sentence boundaries in the
paragraph-aligned text, to facilitate the automatic
sentence alignment method described in Section 5.
While not necessary for further processing, we
also performed manual word-alignment annota-
tion. This task can be done automatically, but it
is useful to have a gold-standard reference against
which we can evaluate the automated method.
</bodyText>
<figureCaption confidence="0.8599775">
Figure 3: Text Extraction from Bilingual Invest-
ment Report
</figureCaption>
<bodyText confidence="0.998856666666667">
Monitoring the accuracy of the automatic word-
alignment method against the human reference,
will allow us to tweak parameters to arrive at the
optimal settings for this language pair.
We used the UMIACS word alignment interface
(Hwa and Madnani, 2004) for this purpose and
asked the annotators to link the words between the
two sentences (Figure 2). Given the linguistic dif-
ferences between English and Swahili, this is by
no means a trivial task. Particularly the morpho-
logical richness of Swahili means that there is a lot
of convergence from words in English to words
in Swahili (also see Section 6). This alignment
was done on some of the manual translations of
movie subtitles, giving us a gold-standard word-
alignment reference of about 5,000 words. Each
annotator’s work was cross-checked by another
annotator to improve correctness and consistency.
</bodyText>
<sectionHeader confidence="0.989234" genericHeader="method">
5 Alignment Experiments
</sectionHeader>
<bodyText confidence="0.9919935">
There are a number of packages available to
process parallel corpora. To preprocess the
paragraph-aligned texts, we used Microsoft’s
bilingual sentence aligner (Moore, 2002). The
</bodyText>
<page confidence="0.998914">
13
</page>
<table confidence="0.99912">
Precision Recall F(Q = 1) Precision Recall F(Q = 1)
39.4% 44.5% 41.79% 50.2% 64.5% 55.8%
</table>
<tableCaption confidence="0.9901675">
Table 2: Precision, Recall and F-score for the
word-alignment task using GIZA++
Table 3: Precision, Recall and F-score for the
morpheme/word-alignment task using GIZA++
</tableCaption>
<bodyText confidence="0.996226">
output of the sentence alignment was conse-
quently manually corrected. We found that 95% of
the sentences were correctly aligned with most er-
rors being made on sentences that were not present
in English, i.e. instances where the translator de-
cided to add an extra clarifying sentence to the di-
rect translation from English. This also explains
why there are more Swahili words in the paragraph
aligned texts than in English, while the situation is
reversed for the sentence aligned data.
For word-alignment, the state-of-the-art method
is GIZA++ (Och and Ney, 2003), which imple-
ments the word alignment methods IBM1 to IBM5
and HMM. While this method has a strong Indo-
European bias, it is nevertheless interesting to see
how far we can get with the default approach used
in statistical MT.
We evaluate by looking at the word alignments
proposed by GIZA++ and compare them to the
manually word-aligned section of the SAWA Cor-
pus. We can quantify the evaluation by calculat-
ing precision and recall and their harmonic mean,
the F-score (Table 2). The former expresses how
many links are correct, divided by the total num-
ber of links suggested by GIZA++. The latter is
calculated by dividing the number of correct links,
by the total number of links in the manual annota-
tion. The underwhelming results presented in Ta-
ble 2 can be attributed to the strong Indo-European
bias of the current approaches. It is clear that extra
linguistic data sources and a more elaborate explo-
ration of the experimental parameters of GIZA++
will be needed, as well as a different approach to
word-alignment. In the next section, we describe
a potential solution to the problem by defining the
problem on the level of the morpheme.
</bodyText>
<sectionHeader confidence="0.931939" genericHeader="method">
6 Alignment into an Agglutinating
Language
</sectionHeader>
<bodyText confidence="0.99955875">
The main problem in training a GIZA++ model for
the language pair English - Swahili is the strong
agglutinating nature of the latter. Alignment pat-
terns such as the one in Figures 1 and 2 are not
impossible to retrieve. But no corpus is exhaus-
tive enough to provide enough linguistic evidence
to unearth strongly converging alignment patterns,
such as the one in Example 1.
</bodyText>
<equation confidence="0.3355545">
(1) I have turned him down
Nimemkatalia
</equation>
<bodyText confidence="0.969556945945946">
Morphologically deconstructing the word how-
ever can greatly relieve the sparse data problem for
this task:
(2) I have turned him down
Ni- me- m- katalia
The isolated Swahili morphemes can more eas-
ily be linked to their English counterparts, since
there will be more linguistic evidence in the par-
allel corpus, linking for example ni to I and m
to him. To perform this kind of morphological
analysis, we developed a machine learning system
trained and evaluated on the Helsinki corpus of
Swahili (Hurskainen, 2004). Experimental results
show that the data-driven approach achieves state-
of-the-art performance in a direct comparison with
a rule-based method, with the added advantage of
being robust to word forms for previously unseen
lemmas (De Pauw and de Schryver, 2008). We
can consequently use morphological deconstruc-
tion as a preprocessing step for the alignment task,
similar to the method described by Goldwater and
McClosky (2005), Oflazer (2008) and Stymne et
al. (2008).
We have no morphologically aligned parallel
data available, so evaluation of the morphology-
based approach needs to be done in a roundabout
way. We first morphologically decompose the
Swahili data and run GIZA++ again. Then we re-
compile the Swahili words from the morphemes
and group the word alignment links accordingly.
Incompatible linkages are removed. The updated
scores are presented in Table 3. While this cer-
tainly improves on the scores in Table 2, we need
to be aware of the difficulty that the morphological
preprocessing step will introduce in the decoding
phase, necessitating the introduction of a language
model that not only works on the word level, but
</bodyText>
<page confidence="0.997762">
14
</page>
<bodyText confidence="0.999547545454546">
also on the level of the morpheme.
For the purpose of projection of annotation, this
is however not an issue. We performed a prelim-
inary experiment with a dependency-parsed En-
glish corpus, projected unto the morphologically
decompounded tokens in Swahili. We are cur-
rently lacking the annotated gold-standard data to
perform quantitative evaluation, but have observed
interesting annotation results, that open up pos-
sibilities for the morphological analysis of more
resource-scarce languages.
</bodyText>
<sectionHeader confidence="0.997024" genericHeader="discussions">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999783116666667">
In this paper we presented parallel corpus collec-
tion work that will enable the construction of a
machine translation system for the language pair
English - Swahili, as well as open up the possibil-
ity of corpus annotation through projection. We
are confident that we are approaching a critical
amount of data that will enable good word align-
ment that can subsequently be used as a model for
an MT decoding system, such as the Moses pack-
age (Koehn et al., 2007). While the currently re-
ported scores are not yet state-of-the-art, we are
confident that further experimentation and the ad-
dition of more bilingual data as well as the intro-
duction of extra linguistic features will raise the
accuracy level of the proposed MT system.
Apart from the morphological deconstruction
described in Section 6, the most straightforward
addition is the introduction of part-of-speech tags
as an extra layer of linguistic description, which
can be used in word alignment model IBM5. The
current word alignment method tries to link word
forms, but knowing that for instance a word in the
source language is a noun, will facilitate linking
it to a corresponding noun in the target language,
rather than considering a verb as a possible match.
Both for English (Ratnaparkhi, 1996) and Swahili
(De Pauw et al., 2006), we have highly accurate
part-of-speech taggers available.
Another extra information source that we have
so far ignored is a digital dictionary as a seed for
the word alignment. The kamusiproject.org elec-
tronic dictionary will be included in further word-
alignment experiments and will undoubtedly im-
prove the quality of the output.
Once we have a stable word alignment mod-
ule, we will further conduct learning curve exper-
iments, in which we train the system with grad-
ually increasing amounts of data. This will pro-
vide us with information on how much more data
we need to achieve state-of-the-art performance.
This additional data can be automatically found
by parallel web mining, for which a few sys-
tems have recently become available (Resnik and
Smith, 2003).
Furthermore, we will also look into the use
of comparable corpora, i.e. bilingual texts that
are not straight translations, but deal with the
same subject matter. These have been found to
work as additional material within a parallel cor-
pus (McEnery and Xiao, 2007) and may further
help improve the development of a robust, open-
ended and bidirectional machine translation sys-
tem for the language pair English - Swahili. The
most innovative prospect of the parallel corpus is
the annotation of dependency analysis in Swahili,
not only on the syntactic level, but also on the
level of the morphology. The preliminary exper-
iments indicate that this approach might provide a
valuable technique to bootstrap annotation in truly
resource-scarce languages.
</bodyText>
<sectionHeader confidence="0.997474" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999939818181818">
The research presented in this paper was made
possible through the support of the VLIR-IUC-
UON program and was partly funded by the SAWA
BOF UA-2007 project. The first author is funded
as a Postdoctoral Fellow of the Research Founda-
tion - Flanders (FWO). We are greatly indebted to
Dr. James Omboga Zaja for contributing some of
his translated data, to Mahmoud Shokrollahi-Far
for his advice on the Quran and to Anne Kimani,
Chris Wangai Njoka and Naomi Maajabu for their
annotation efforts.
</bodyText>
<sectionHeader confidence="0.998538" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996046928571429">
M. Benjamin. 2009. The Kamusi Project. Available at:
http://www.kamusiproject.org (Accessed: 14 Jan-
uary 2009).
G. De Pauw and G.-M. de Schryver. 2008. Improv-
ing the computational morphological analysis of a
Swahili corpus for lexicographic purposes. Lexikos,
18:303–318.
G. De Pauw and P.W. Wagacha. 2007. Bootstrapping
morphological analysis of Gik˜uy˜u using unsuper-
vised maximum entropy learning. In Proceedings
of the eighth INTERSPEECH conference, Antwerp,
Belgium.
G. De Pauw, G.-M. de Schryver, and P.W. Wa-
gacha. 2006. Data-driven part-of-speech tagging of
</reference>
<page confidence="0.983494">
15
</page>
<reference confidence="0.99921652293578">
Kiswahili. In P. Sojka, I. Kopeˇcek, and K. Pala, edi-
tors, Proceedings of Text, Speech and Dialogue, 9th
International Conference, volume 4188 of Lecture
Notes in Computer Science, pages 197–204, Berlin,
Germany. Springer Verlag.
G. De Pauw, P.W. Wagacha, and D.A. Abade. 2007a.
Unsupervised induction of Dholuo word classes
using maximum entropy learning. In K. Getao
and E. Omwenga, editors, Proceedings of the First
International Computer Science and ICT Confer-
ence, pages 139–143, Nairobi, Kenya. University of
Nairobi.
G. De Pauw, P.W. Wagacha, and G.-M. de Schryver.
2007b. Automatic diacritic restoration for resource-
scarce languages. In V´aclav Matouˇsek and Pavel
Mautner, editors, Proceedings of Text, Speech and
Dialogue, Tenth International Conference, volume
4629 of Lecture Notes in Computer Science, pages
170–179, Heidelberg, Germany. Springer Verlag.
G.-M. de Schryver and G. De Pauw. 2007. Dictio-
nary writing system (DWS) + corpus query package
(CQP): The case of Tshwanelex. Lexikos, 17:226–
246.
S. Goldwater and D. McClosky. 2005. Improving sta-
tistical MT through morphological analysis. In Pro-
ceedings of the Human Language Technology Con-
ference and Conference on Empirical Methods in
Natural Language Processing, pages 676–683, Van-
couver, Canada.
Google. 2009. Google Translate. Available
at http://www.google.com/translate (Accessed: 14
January 2009.
A. Hurskainen. 2004. HCS 2004 – Helsinki Corpus of
Swahili. Technical report, Compilers: Institute for
Asian and African Studies (University of Helsinki)
and CSC.
W.J. Hutchins. 1986. Machine translation: past,
present, future. Ellis, Chichester.
R. Hwa and N. Madnani. 2004. The UMI-
ACS Word Alignment Interface. Available at:
http://www.umiacs.umd.edu/˜nmadnani/alignment/
forclip.htm (Accessed: 14 January 2009).
R. Hwa, Ph. Resnik, A. Weinberg, and O. Kolak. 2002.
Evaluating translational correspondence using anno-
tation projection. In Proceedings of the 40th Annual
Meeting of the Association for Computational Lin-
guistics, pages 392–399, Philadelphia, PA, USA.
Ph. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Annual Meet-
ing of the Association for Computational Linguistics
(ACL), demonstration session, Prague, Czech Re-
public.
A.M. McEnery and R.Z Xiao. 2007. Parallel and
comparable corpora: What are they up to? In In-
corporating Corpora: Translation and the Linguist.
Translating Europe. Multilingual Matters, Cleve-
don, UK.
R.C. Moore. 2002. Fast and accurate sentence align-
ment of bilingual corpora. In Proceedings of the 5th
Conference of the Association for Machine Transla-
tion in the Americas on Machine Translation: From
Research to Real Users, volume 2499 of Lecture
Notes in Computer Science, pages 135–144, Berlin,
Germany. Springer Verlag.
F.J. Och and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29(1):19–51.
K. Oflazer. 2008. Statistical machine translation into
a morphologically complex language. In Compu-
tational Linguistics and Intelligent Text Processing,
pages 376–388, Berlin, Germany. Springer Verlag.
A. Ratnaparkhi. 1996. A maximum entropy model for
part-of-speech tagging. In E. Brill and K. Church,
editors, Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
133–142. Association for Computational Linguis-
tics.
Ph. Resnik and N.A. Smith. 2003. The web as a par-
allel corpus. Computational Linguistics, 29(1):349–
380.
S. Roukos, D. Graff, and D. Melamed. 1997.
Hansard French/English. Available at:
http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC95T20 (Accessed: 14 January
2009).
S. Stymne, M. Holmqvist, and L. Ahrenberg. 2008.
Effects of morphological analysis in translation be-
tween German and English. In Proceedings of the
Third Workshop on Statistical Machine Translation,
pages 135–138, Columbus, USA.
P.W. Wagacha, G. De Pauw, and K. Getao. 2006a.
Development of a corpus for Gik˜uy˜u using machine
learning techniques. In J.C. Roux, editor, Proceed-
ings of LREC workshop - Networking the develop-
ment of language resources for African languages,
pages 27–30, Genoa, Italy, May, 2006. European
Language Resources Association, ELRA.
P.W. Wagacha, G. De Pauw, and P.W. Githinji. 2006b.
A grapheme-based approach for accent restoration
in Gik˜uy˜u. In Proceedings of the Fifth International
Conference on Language Resources and Evaluation,
pages 1937–1940, Genoa, Italy, May, 2006. Euro-
pean Language Resources Association, ELRA.
Yahoo! 2009. Babelfish. Available at
http://babelfish.yahoo.com (Accessed: 14 January
2009).
</reference>
<page confidence="0.998683">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.210532">
<title confidence="0.991275">a Parallel Corpus English - Swahili</title>
<author confidence="0.999551">Guy De</author>
<affiliation confidence="0.9981405">CNTS - Language Technology Group, University of Antwerp, School of Computing and Informatics, University of Nairobi,</affiliation>
<email confidence="0.982104">guy.depauw@ua.ac.be</email>
<author confidence="0.996732">Peter Waiganjo Wagacha</author>
<affiliation confidence="0.999687">School of Computing and Informatics, University of Nairobi,</affiliation>
<email confidence="0.978755">waiganjo@uonbi.ac.ke</email>
<affiliation confidence="0.574073">Gilles-Maurice de African Languages and Cultures, Ghent University,</affiliation>
<address confidence="0.330498">Xhosa Department, University of the Western Cape, South</address>
<email confidence="0.982681">gillesmaurice.deschryver@ugent.be</email>
<abstract confidence="0.99397715">Research in data-driven methods for Machine Translation has greatly benefited from the increasing availability of parallel corpora. Processing the same text in two different languages yields useful information on how words and phrases are translated from a source language into a target language. To investigate this, a parallel corpus is typically aligned by linking linguistic tokens in the source language to the corresponding units in the target language. An aligned parallel corpus therefore facilitates the automatic development of a machine translation system and can also bootstrap annotation through projection. In this paper, we describe data collection and annotation efforts and preliminary experimental results with a parallel corpus English - Swahili.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Benjamin</author>
</authors>
<title>The Kamusi Project. Available at: http://www.kamusiproject.org (Accessed:</title>
<date>2009</date>
<contexts>
<context position="13473" citStr="Benjamin, 2009" startWordPosition="2100" endWordPosition="2101">e to track down the most likely candidate. While religious material has a specific register and may not constitute ideal training material for an open-ended MT system, it does have the advantage of being inherently aligned on the verse level, facilitating further sentence alignment. Another typical bilingual text is the UN Declaration of Human Rights, which is available in many of the world’s languages, including Swahili. The manual sentence alignment of this text is greatly facilitated by the fixed structure of the document. The downloadable version of the on-line dictionary English-Swahili (Benjamin, 2009) contains individual example sentences associated with the dictionary entries. These can be extracted and used as parallel data in the SAWA corpus. Since at a later point, we also wish to study the specific linguistic aspects of spoken language, we opted to have some movie subtitles manually translated. These can be extracted from DVDs and while the 12 language is compressed to fit on screen and constitutes scripted language, they nevertheless provide a reasonable approximation of spoken language. Another advantage of this data is that it is inherently sentence-aligned, thanks to the technical</context>
</contexts>
<marker>Benjamin, 2009</marker>
<rawString>M. Benjamin. 2009. The Kamusi Project. Available at: http://www.kamusiproject.org (Accessed: 14 January 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G De Pauw</author>
<author>G-M de Schryver</author>
</authors>
<title>Improving the computational morphological analysis of a Swahili corpus for lexicographic purposes.</title>
<date>2008</date>
<journal>Lexikos,</journal>
<pages>18--303</pages>
<marker>De Pauw, de Schryver, 2008</marker>
<rawString>G. De Pauw and G.-M. de Schryver. 2008. Improving the computational morphological analysis of a Swahili corpus for lexicographic purposes. Lexikos, 18:303–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G De Pauw</author>
<author>P W Wagacha</author>
</authors>
<title>Bootstrapping morphological analysis of Gik˜uy˜u using unsupervised maximum entropy learning.</title>
<date>2007</date>
<booktitle>In Proceedings of the eighth INTERSPEECH conference,</booktitle>
<location>Antwerp, Belgium.</location>
<marker>De Pauw, Wagacha, 2007</marker>
<rawString>G. De Pauw and P.W. Wagacha. 2007. Bootstrapping morphological analysis of Gik˜uy˜u using unsupervised maximum entropy learning. In Proceedings of the eighth INTERSPEECH conference, Antwerp, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G De Pauw</author>
<author>G-M de Schryver</author>
<author>P W Wagacha</author>
</authors>
<title>Data-driven part-of-speech tagging of Kiswahili. In</title>
<date>2006</date>
<booktitle>Proceedings of Text, Speech and Dialogue, 9th International Conference,</booktitle>
<volume>4188</volume>
<pages>197--204</pages>
<editor>P. Sojka, I. Kopeˇcek, and K. Pala, editors,</editor>
<publisher>Springer Verlag.</publisher>
<location>Berlin, Germany.</location>
<marker>De Pauw, de Schryver, Wagacha, 2006</marker>
<rawString>G. De Pauw, G.-M. de Schryver, and P.W. Wagacha. 2006. Data-driven part-of-speech tagging of Kiswahili. In P. Sojka, I. Kopeˇcek, and K. Pala, editors, Proceedings of Text, Speech and Dialogue, 9th International Conference, volume 4188 of Lecture Notes in Computer Science, pages 197–204, Berlin, Germany. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G De Pauw</author>
<author>P W Wagacha</author>
<author>D A Abade</author>
</authors>
<title>Unsupervised induction of Dholuo word classes using maximum entropy learning.</title>
<date>2007</date>
<booktitle>Proceedings of the First International Computer Science and ICT Conference,</booktitle>
<pages>139--143</pages>
<editor>In K. Getao and E. Omwenga, editors,</editor>
<institution>Nairobi, Kenya. University of Nairobi.</institution>
<marker>De Pauw, Wagacha, Abade, 2007</marker>
<rawString>G. De Pauw, P.W. Wagacha, and D.A. Abade. 2007a. Unsupervised induction of Dholuo word classes using maximum entropy learning. In K. Getao and E. Omwenga, editors, Proceedings of the First International Computer Science and ICT Conference, pages 139–143, Nairobi, Kenya. University of Nairobi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G De Pauw</author>
<author>P W Wagacha</author>
<author>G-M de Schryver</author>
</authors>
<title>Automatic diacritic restoration for resourcescarce languages.</title>
<date>2007</date>
<booktitle>Proceedings of Text, Speech and Dialogue, Tenth International Conference,</booktitle>
<volume>4629</volume>
<pages>170--179</pages>
<editor>In V´aclav Matouˇsek and Pavel Mautner, editors,</editor>
<publisher>Springer Verlag.</publisher>
<location>Heidelberg, Germany.</location>
<marker>De Pauw, Wagacha, de Schryver, 2007</marker>
<rawString>G. De Pauw, P.W. Wagacha, and G.-M. de Schryver. 2007b. Automatic diacritic restoration for resourcescarce languages. In V´aclav Matouˇsek and Pavel Mautner, editors, Proceedings of Text, Speech and Dialogue, Tenth International Conference, volume 4629 of Lecture Notes in Computer Science, pages 170–179, Heidelberg, Germany. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G-M de Schryver</author>
<author>G De Pauw</author>
</authors>
<title>Dictionary writing system (DWS) + corpus query package (CQP): The case of Tshwanelex. Lexikos,</title>
<date>2007</date>
<pages>17--226</pages>
<marker>de Schryver, De Pauw, 2007</marker>
<rawString>G.-M. de Schryver and G. De Pauw. 2007. Dictionary writing system (DWS) + corpus query package (CQP): The case of Tshwanelex. Lexikos, 17:226– 246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
<author>D McClosky</author>
</authors>
<title>Improving statistical MT through morphological analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>676--683</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="20584" citStr="Goldwater and McClosky (2005)" startWordPosition="3252" endWordPosition="3255">linking for example ni to I and m to him. To perform this kind of morphological analysis, we developed a machine learning system trained and evaluated on the Helsinki corpus of Swahili (Hurskainen, 2004). Experimental results show that the data-driven approach achieves stateof-the-art performance in a direct comparison with a rule-based method, with the added advantage of being robust to word forms for previously unseen lemmas (De Pauw and de Schryver, 2008). We can consequently use morphological deconstruction as a preprocessing step for the alignment task, similar to the method described by Goldwater and McClosky (2005), Oflazer (2008) and Stymne et al. (2008). We have no morphologically aligned parallel data available, so evaluation of the morphologybased approach needs to be done in a roundabout way. We first morphologically decompose the Swahili data and run GIZA++ again. Then we recompile the Swahili words from the morphemes and group the word alignment links accordingly. Incompatible linkages are removed. The updated scores are presented in Table 3. While this certainly improves on the scores in Table 2, we need to be aware of the difficulty that the morphological preprocessing step will introduce in th</context>
</contexts>
<marker>Goldwater, McClosky, 2005</marker>
<rawString>S. Goldwater and D. McClosky. 2005. Improving statistical MT through morphological analysis. In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 676–683, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Google</author>
</authors>
<title>Google Translate. Available at http://www.google.com/translate (Accessed:</title>
<date>2009</date>
<marker>Google, 2009</marker>
<rawString>Google. 2009. Google Translate. Available at http://www.google.com/translate (Accessed: 14 January 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hurskainen</author>
</authors>
<title>HCS</title>
<date>2004</date>
<tech>Technical report, Compilers:</tech>
<institution>Institute for Asian and African Studies (University of Helsinki) and CSC.</institution>
<contexts>
<context position="20158" citStr="Hurskainen, 2004" startWordPosition="3190" endWordPosition="3191">ly converging alignment patterns, such as the one in Example 1. (1) I have turned him down Nimemkatalia Morphologically deconstructing the word however can greatly relieve the sparse data problem for this task: (2) I have turned him down Ni- me- m- katalia The isolated Swahili morphemes can more easily be linked to their English counterparts, since there will be more linguistic evidence in the parallel corpus, linking for example ni to I and m to him. To perform this kind of morphological analysis, we developed a machine learning system trained and evaluated on the Helsinki corpus of Swahili (Hurskainen, 2004). Experimental results show that the data-driven approach achieves stateof-the-art performance in a direct comparison with a rule-based method, with the added advantage of being robust to word forms for previously unseen lemmas (De Pauw and de Schryver, 2008). We can consequently use morphological deconstruction as a preprocessing step for the alignment task, similar to the method described by Goldwater and McClosky (2005), Oflazer (2008) and Stymne et al. (2008). We have no morphologically aligned parallel data available, so evaluation of the morphologybased approach needs to be done in a rou</context>
</contexts>
<marker>Hurskainen, 2004</marker>
<rawString>A. Hurskainen. 2004. HCS 2004 – Helsinki Corpus of Swahili. Technical report, Compilers: Institute for Asian and African Studies (University of Helsinki) and CSC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Hutchins</author>
</authors>
<title>Machine translation: past, present, future. Ellis,</title>
<date>1986</date>
<location>Chichester.</location>
<contexts>
<context position="5875" citStr="Hutchins (1986)" startWordPosition="892" endWordPosition="893">e a text input in one language, the Source language (SL), decode its meaning and re-encode it producing as output a similar-meaning text in another language, the Target language (TL). The idea of building an application to automatically convert text from one language to an equivalent text-meaning in a second language traces its roots back to Cold War intelligence efforts in the 1950’s and 60’s for Russian-English text translations. Since then a large number of MT systems have been developed with varying degrees of success. For an excellent overview of the history of MT, we refer the reader to Hutchins (1986). The original dream of creating a fully automatic MT system has long since been abandoned and most research in the field currently concentrates on minimizing human pre- and post-processing effort. A human translator is thus considered to work alongside the MT system to produce faster and more consistent translations. The Internet brought in an interesting new dimension to the purpose of MT. In the mid 1990s, free on-line translation services began to surface with an increasing number of MT vendors. The most famous example is Yahoo!’s Babelfish , offering on-line versions of Systran to transla</context>
</contexts>
<marker>Hutchins, 1986</marker>
<rawString>W.J. Hutchins. 1986. Machine translation: past, present, future. Ellis, Chichester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>N Madnani</author>
</authors>
<title>The UMIACS Word Alignment Interface. Available at: http://www.umiacs.umd.edu/˜nmadnani/alignment/ forclip.htm (Accessed:</title>
<date>2004</date>
<contexts>
<context position="16413" citStr="Hwa and Madnani, 2004" startWordPosition="2568" endWordPosition="2571">o facilitate the automatic sentence alignment method described in Section 5. While not necessary for further processing, we also performed manual word-alignment annotation. This task can be done automatically, but it is useful to have a gold-standard reference against which we can evaluate the automated method. Figure 3: Text Extraction from Bilingual Investment Report Monitoring the accuracy of the automatic wordalignment method against the human reference, will allow us to tweak parameters to arrive at the optimal settings for this language pair. We used the UMIACS word alignment interface (Hwa and Madnani, 2004) for this purpose and asked the annotators to link the words between the two sentences (Figure 2). Given the linguistic differences between English and Swahili, this is by no means a trivial task. Particularly the morphological richness of Swahili means that there is a lot of convergence from words in English to words in Swahili (also see Section 6). This alignment was done on some of the manual translations of movie subtitles, giving us a gold-standard wordalignment reference of about 5,000 words. Each annotator’s work was cross-checked by another annotator to improve correctness and consiste</context>
</contexts>
<marker>Hwa, Madnani, 2004</marker>
<rawString>R. Hwa and N. Madnani. 2004. The UMIACS Word Alignment Interface. Available at: http://www.umiacs.umd.edu/˜nmadnani/alignment/ forclip.htm (Accessed: 14 January 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Weinberg Resnik</author>
<author>O Kolak</author>
</authors>
<title>Evaluating translational correspondence using annotation projection.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>392--399</pages>
<location>Philadelphia, PA, USA.</location>
<marker>Resnik, Kolak, 2002</marker>
<rawString>R. Hwa, Ph. Resnik, A. Weinberg, and O. Kolak. 2002. Evaluating translational correspondence using annotation projection. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 392–399, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hoang Koehn</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="22265" citStr="Koehn et al., 2007" startWordPosition="3525" endWordPosition="3528">n, but have observed interesting annotation results, that open up possibilities for the morphological analysis of more resource-scarce languages. 7 Discussion In this paper we presented parallel corpus collection work that will enable the construction of a machine translation system for the language pair English - Swahili, as well as open up the possibility of corpus annotation through projection. We are confident that we are approaching a critical amount of data that will enable good word alignment that can subsequently be used as a model for an MT decoding system, such as the Moses package (Koehn et al., 2007). While the currently reported scores are not yet state-of-the-art, we are confident that further experimentation and the addition of more bilingual data as well as the introduction of extra linguistic features will raise the accuracy level of the proposed MT system. Apart from the morphological deconstruction described in Section 6, the most straightforward addition is the introduction of part-of-speech tags as an extra layer of linguistic description, which can be used in word alignment model IBM5. The current word alignment method tries to link word forms, but knowing that for instance a wo</context>
</contexts>
<marker>Koehn, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Ph. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M McEnery</author>
<author>R Z Xiao</author>
</authors>
<title>Parallel and comparable corpora: What are they up to? In Incorporating Corpora: Translation and the Linguist. Translating Europe. Multilingual Matters,</title>
<date>2007</date>
<location>Clevedon, UK.</location>
<contexts>
<context position="24129" citStr="McEnery and Xiao, 2007" startWordPosition="3829" endWordPosition="3832">ning curve experiments, in which we train the system with gradually increasing amounts of data. This will provide us with information on how much more data we need to achieve state-of-the-art performance. This additional data can be automatically found by parallel web mining, for which a few systems have recently become available (Resnik and Smith, 2003). Furthermore, we will also look into the use of comparable corpora, i.e. bilingual texts that are not straight translations, but deal with the same subject matter. These have been found to work as additional material within a parallel corpus (McEnery and Xiao, 2007) and may further help improve the development of a robust, openended and bidirectional machine translation system for the language pair English - Swahili. The most innovative prospect of the parallel corpus is the annotation of dependency analysis in Swahili, not only on the syntactic level, but also on the level of the morphology. The preliminary experiments indicate that this approach might provide a valuable technique to bootstrap annotation in truly resource-scarce languages. Acknowledgments The research presented in this paper was made possible through the support of the VLIR-IUCUON progr</context>
</contexts>
<marker>McEnery, Xiao, 2007</marker>
<rawString>A.M. McEnery and R.Z Xiao. 2007. Parallel and comparable corpora: What are they up to? In Incorporating Corpora: Translation and the Linguist. Translating Europe. Multilingual Matters, Clevedon, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>Fast and accurate sentence alignment of bilingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the 5th Conference of the Association for Machine Translation in the Americas on Machine Translation: From Research to Real Users,</booktitle>
<volume>2499</volume>
<pages>135--144</pages>
<publisher>Springer Verlag.</publisher>
<location>Berlin, Germany.</location>
<contexts>
<context position="17215" citStr="Moore, 2002" startWordPosition="2695" endWordPosition="2696"> task. Particularly the morphological richness of Swahili means that there is a lot of convergence from words in English to words in Swahili (also see Section 6). This alignment was done on some of the manual translations of movie subtitles, giving us a gold-standard wordalignment reference of about 5,000 words. Each annotator’s work was cross-checked by another annotator to improve correctness and consistency. 5 Alignment Experiments There are a number of packages available to process parallel corpora. To preprocess the paragraph-aligned texts, we used Microsoft’s bilingual sentence aligner (Moore, 2002). The 13 Precision Recall F(Q = 1) Precision Recall F(Q = 1) 39.4% 44.5% 41.79% 50.2% 64.5% 55.8% Table 2: Precision, Recall and F-score for the word-alignment task using GIZA++ Table 3: Precision, Recall and F-score for the morpheme/word-alignment task using GIZA++ output of the sentence alignment was consequently manually corrected. We found that 95% of the sentences were correctly aligned with most errors being made on sentences that were not present in English, i.e. instances where the translator decided to add an extra clarifying sentence to the direct translation from English. This also </context>
</contexts>
<marker>Moore, 2002</marker>
<rawString>R.C. Moore. 2002. Fast and accurate sentence alignment of bilingual corpora. In Proceedings of the 5th Conference of the Association for Machine Translation in the Americas on Machine Translation: From Research to Real Users, volume 2499 of Lecture Notes in Computer Science, pages 135–144, Berlin, Germany. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="18045" citStr="Och and Ney, 2003" startWordPosition="2827" endWordPosition="2830">core for the morpheme/word-alignment task using GIZA++ output of the sentence alignment was consequently manually corrected. We found that 95% of the sentences were correctly aligned with most errors being made on sentences that were not present in English, i.e. instances where the translator decided to add an extra clarifying sentence to the direct translation from English. This also explains why there are more Swahili words in the paragraph aligned texts than in English, while the situation is reversed for the sentence aligned data. For word-alignment, the state-of-the-art method is GIZA++ (Och and Ney, 2003), which implements the word alignment methods IBM1 to IBM5 and HMM. While this method has a strong IndoEuropean bias, it is nevertheless interesting to see how far we can get with the default approach used in statistical MT. We evaluate by looking at the word alignments proposed by GIZA++ and compare them to the manually word-aligned section of the SAWA Corpus. We can quantify the evaluation by calculating precision and recall and their harmonic mean, the F-score (Table 2). The former expresses how many links are correct, divided by the total number of links suggested by GIZA++. The latter is </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F.J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Oflazer</author>
</authors>
<title>Statistical machine translation into a morphologically complex language.</title>
<date>2008</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>376--388</pages>
<publisher>Springer Verlag.</publisher>
<location>Berlin, Germany.</location>
<contexts>
<context position="20600" citStr="Oflazer (2008)" startWordPosition="3256" endWordPosition="3257"> m to him. To perform this kind of morphological analysis, we developed a machine learning system trained and evaluated on the Helsinki corpus of Swahili (Hurskainen, 2004). Experimental results show that the data-driven approach achieves stateof-the-art performance in a direct comparison with a rule-based method, with the added advantage of being robust to word forms for previously unseen lemmas (De Pauw and de Schryver, 2008). We can consequently use morphological deconstruction as a preprocessing step for the alignment task, similar to the method described by Goldwater and McClosky (2005), Oflazer (2008) and Stymne et al. (2008). We have no morphologically aligned parallel data available, so evaluation of the morphologybased approach needs to be done in a roundabout way. We first morphologically decompose the Swahili data and run GIZA++ again. Then we recompile the Swahili words from the morphemes and group the word alignment links accordingly. Incompatible linkages are removed. The updated scores are presented in Table 3. While this certainly improves on the scores in Table 2, we need to be aware of the difficulty that the morphological preprocessing step will introduce in the decoding phase</context>
</contexts>
<marker>Oflazer, 2008</marker>
<rawString>K. Oflazer. 2008. Statistical machine translation into a morphologically complex language. In Computational Linguistics and Intelligent Text Processing, pages 376–388, Berlin, Germany. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>133--142</pages>
<editor>In E. Brill and K. Church, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<contexts>
<context position="23065" citStr="Ratnaparkhi, 1996" startWordPosition="3656" endWordPosition="3657">of extra linguistic features will raise the accuracy level of the proposed MT system. Apart from the morphological deconstruction described in Section 6, the most straightforward addition is the introduction of part-of-speech tags as an extra layer of linguistic description, which can be used in word alignment model IBM5. The current word alignment method tries to link word forms, but knowing that for instance a word in the source language is a noun, will facilitate linking it to a corresponding noun in the target language, rather than considering a verb as a possible match. Both for English (Ratnaparkhi, 1996) and Swahili (De Pauw et al., 2006), we have highly accurate part-of-speech taggers available. Another extra information source that we have so far ignored is a digital dictionary as a seed for the word alignment. The kamusiproject.org electronic dictionary will be included in further wordalignment experiments and will undoubtedly improve the quality of the output. Once we have a stable word alignment module, we will further conduct learning curve experiments, in which we train the system with gradually increasing amounts of data. This will provide us with information on how much more data we </context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>A. Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In E. Brill and K. Church, editors, Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 133–142. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Resnik</author>
<author>N A Smith</author>
</authors>
<title>The web as a parallel corpus.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<pages>380</pages>
<contexts>
<context position="23862" citStr="Resnik and Smith, 2003" startWordPosition="3785" endWordPosition="3788">onary as a seed for the word alignment. The kamusiproject.org electronic dictionary will be included in further wordalignment experiments and will undoubtedly improve the quality of the output. Once we have a stable word alignment module, we will further conduct learning curve experiments, in which we train the system with gradually increasing amounts of data. This will provide us with information on how much more data we need to achieve state-of-the-art performance. This additional data can be automatically found by parallel web mining, for which a few systems have recently become available (Resnik and Smith, 2003). Furthermore, we will also look into the use of comparable corpora, i.e. bilingual texts that are not straight translations, but deal with the same subject matter. These have been found to work as additional material within a parallel corpus (McEnery and Xiao, 2007) and may further help improve the development of a robust, openended and bidirectional machine translation system for the language pair English - Swahili. The most innovative prospect of the parallel corpus is the annotation of dependency analysis in Swahili, not only on the syntactic level, but also on the level of the morphology.</context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>Ph. Resnik and N.A. Smith. 2003. The web as a parallel corpus. Computational Linguistics, 29(1):349– 380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Roukos</author>
<author>D Graff</author>
<author>D Melamed</author>
</authors>
<title>Hansard French/English. Available at: http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?</title>
<date>1997</date>
<booktitle>catalogId=LDC95T20 (Accessed: 14</booktitle>
<contexts>
<context position="12297" citStr="Roukos et al., 1997" startWordPosition="1907" endWordPosition="1910"> language (also see Figures 1 and 2). But before we can do this, we need to perform sentence-alignment, during which we establish an unambiguous mapping between the sentences in the source text and the sentences in the target text. While some data is inherently sentence-aligned, other texts require significant preprocessing before word alignment can be performed. The SAWA Corpus currently consists of a reasonable amount of data (roughly half a million words in each language), although this is not comparable to the resources available to IndoEuropean language pairs, such as the Hansard corpus (Roukos et al., 1997) (2.87 million sentence pairs). Table 1 gives an overview of the data available in the SAWA Corpus. For each segment it lists the number of sentences and words in the respective languages. 4.1 Sentence-aligned Resources We found digitally available Swahili versions of the New Testament and the Quran for which we sourced the English counterparts. This is not a trivial task when, as in the case of the Swahili documents, the exact source of the translation is not provided. By carefully examining subtle differences in the English versions, we were however able to track down the most likely candida</context>
</contexts>
<marker>Roukos, Graff, Melamed, 1997</marker>
<rawString>S. Roukos, D. Graff, and D. Melamed. 1997. Hansard French/English. Available at: http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp? catalogId=LDC95T20 (Accessed: 14 January 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stymne</author>
<author>M Holmqvist</author>
<author>L Ahrenberg</author>
</authors>
<title>Effects of morphological analysis in translation between German and English.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>135--138</pages>
<location>Columbus, USA.</location>
<contexts>
<context position="20625" citStr="Stymne et al. (2008)" startWordPosition="3259" endWordPosition="3262">rm this kind of morphological analysis, we developed a machine learning system trained and evaluated on the Helsinki corpus of Swahili (Hurskainen, 2004). Experimental results show that the data-driven approach achieves stateof-the-art performance in a direct comparison with a rule-based method, with the added advantage of being robust to word forms for previously unseen lemmas (De Pauw and de Schryver, 2008). We can consequently use morphological deconstruction as a preprocessing step for the alignment task, similar to the method described by Goldwater and McClosky (2005), Oflazer (2008) and Stymne et al. (2008). We have no morphologically aligned parallel data available, so evaluation of the morphologybased approach needs to be done in a roundabout way. We first morphologically decompose the Swahili data and run GIZA++ again. Then we recompile the Swahili words from the morphemes and group the word alignment links accordingly. Incompatible linkages are removed. The updated scores are presented in Table 3. While this certainly improves on the scores in Table 2, we need to be aware of the difficulty that the morphological preprocessing step will introduce in the decoding phase, necessitating the intro</context>
</contexts>
<marker>Stymne, Holmqvist, Ahrenberg, 2008</marker>
<rawString>S. Stymne, M. Holmqvist, and L. Ahrenberg. 2008. Effects of morphological analysis in translation between German and English. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 135–138, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Wagacha</author>
<author>G De Pauw</author>
<author>K Getao</author>
</authors>
<title>Development of a corpus for Gik˜uy˜u using machine learning techniques.</title>
<date>2006</date>
<booktitle>Proceedings of LREC workshop - Networking the development of language resources for African languages,</booktitle>
<pages>27--30</pages>
<editor>In J.C. Roux, editor,</editor>
<location>Genoa, Italy,</location>
<marker>Wagacha, De Pauw, Getao, 2006</marker>
<rawString>P.W. Wagacha, G. De Pauw, and K. Getao. 2006a. Development of a corpus for Gik˜uy˜u using machine learning techniques. In J.C. Roux, editor, Proceedings of LREC workshop - Networking the development of language resources for African languages, pages 27–30, Genoa, Italy, May, 2006. European Language Resources Association, ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Wagacha</author>
<author>G De Pauw</author>
<author>P W Githinji</author>
</authors>
<title>A grapheme-based approach for accent restoration in Gik˜uy˜u.</title>
<date>2006</date>
<journal>European Language Resources Association, ELRA.</journal>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation,</booktitle>
<pages>1937--1940</pages>
<location>Genoa, Italy,</location>
<marker>Wagacha, De Pauw, Githinji, 2006</marker>
<rawString>P.W. Wagacha, G. De Pauw, and P.W. Githinji. 2006b. A grapheme-based approach for accent restoration in Gik˜uy˜u. In Proceedings of the Fifth International Conference on Language Resources and Evaluation, pages 1937–1940, Genoa, Italy, May, 2006. European Language Resources Association, ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yahoo</author>
</authors>
<title>Babelfish. Available at http://babelfish.yahoo.com (Accessed:</title>
<date>2009</date>
<marker>Yahoo, 2009</marker>
<rawString>Yahoo! 2009. Babelfish. Available at http://babelfish.yahoo.com (Accessed: 14 January 2009).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>