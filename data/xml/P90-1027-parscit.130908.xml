<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.561044">
AUTOMATED INVERSION OF LOGIC GRAMMARS FOR GENERATION
</title>
<author confidence="0.463263">
Tomek Strzalkowski and Ping Peng
</author>
<affiliation confidence="0.469437">
Courant Institute of Mathematical Sciences
</affiliation>
<address confidence="0.550328">
New York University
251 Mercer Street
New York, NY 10012
</address>
<email confidence="0.647298">
ABSTRACT
</email>
<bodyText confidence="0.999724">
We describe a system of reversible grammar in
which, given a logic-grammar specification of a
natural language, two efficient PROLOG programs are
derived by an off-line compilation process: a parser
and a generator for this language. The centerpiece of
the system is the inversion algorithm designed to
compute the generator code from the parser&apos;s PRO-
LOG code, using the collection of minimal sets of
essential arguments (MSEA) for predicates. The sys-
tem has been implemented to work with Definite
Clause Grammars (DCG) and is a part of an
English-Japanese machine translation project
currently under development at NYU&apos;s Courant Insti-
tute.
</bodyText>
<sectionHeader confidence="0.989868" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999963434782609">
The results reported in this paper are part of the
ongoing research project to explore possibilities of an
automated derivation of both an efficient parser and
an efficient generator for natural language, such as
English or Japanese, from a formal specification for
this language. Thus, given a grammar-like descrip-
tion of a language, specifying both its syntax as well
as &amp;quot;semantics&amp;quot; (by which we mean a correspondence
of well-formed expressions of natural language to
expressions of a formal representation language) we
want to obtain, by a fully automatic process, two pos-
sibly different programs: a parser and a generator.
The parser will translate well-formed expression of
the source language into expressions of the language
of &amp;quot;semantic&amp;quot; representation, such as regularized
operator-argument forms, or formulas in logic. The
generator, on the other hand, will accept well-formed
expressions of the semantic representation language
and produce corresponding expressions in the source
natural language.
Among the arguments for adopting the bidirec-
tional design in NLP the following are perhaps the
most widely shared:
</bodyText>
<listItem confidence="0.75184">
• A bidirectional NLP system, or a system whose
inverse can be derived by a fully automated pro-
cess, greatly reduces effort required for the sys-
tem development, since we need to write only one
</listItem>
<bodyText confidence="0.995691625">
program or specification instead of two. The
actual amount of savings ultimately depends upon
the extend to which the NLP system is made
bidirectional, for example, how much of the
language analysis process can be inverted for gen-
eration. At present we reverse just a little more
than a syntactic parser, but the method can be
applied to more advanced analyzers as well.
</bodyText>
<listItem confidence="0.987775217391304">
• Using a single specification (a grammar) underly-
ing both the analysis and the synthesis processes
leads to more accurate capturing of the language.
Although no NLP grammar is ever complete, the
grammars used in parsing tend to be &amp;quot;too loose&amp;quot;,
or unsound, in that they would frequently accept
various ill-formed strings as legitimate sentences,
while the grammars used for generation are usu-
ally made &amp;quot;too tight&amp;quot; as a result of limiting their
output to the &amp;quot;best&amp;quot; surface forms. A reversible
system for both parsing and generation requires a
finely balanced grammar which is sound and as
complete as possible.
• A reversible grammar provides, by design, the
match between system&apos;s analysis and generation
capabilities, which is especially important in
interactive systems. A discrepancy in this capa-
city may mislead the user, who tends to assume
that what is generated as output is also acceptable
as input, and vice-versa.
• Finally, a bidirectional system can be expected to
be more robust, easier to maintain and modify,
and altogether more perspicuous.
</listItem>
<bodyText confidence="0.999643866666667">
In the work reported here we concentrated on
unification-based formalisms, in particular Definite
Clause Grammars (Pereira &amp; Warren, 1980), which
can be compiled dually into PROLOG parser and gen-
erator, where the generator is obtained from the
parser&apos;s code with the inversion procedure described
below. As noted by Dymetman and Isabelle (198,8),
this transformation must involve rearranging the
order of literals on the right-hand side of some
clauses. We noted that the design of the string gram-
mar (Sager, 1981) makes it more suitable as a basis
of a reversible system than other grammar designs,
although other grammars can be &amp;quot;normalized&amp;quot;
(Strzalkowski, 1989). We also would like to point out
that our main emphasis is on the problem of
</bodyText>
<page confidence="0.995827">
212
</page>
<bodyText confidence="0.957110333333333">
reversibility rather than generation, the latter involv-
ing many problems that we don&apos;t deal with here (see,
e.g. Derr &amp; McKeown, 1984; McKeown, 1985).
</bodyText>
<sectionHeader confidence="0.992132" genericHeader="related work">
RELATED WORK
</sectionHeader>
<bodyText confidence="0.9873726875">
The idea that a generator for a language might
be considered as an inverse of the parser for the same
language has been around for some time, but it was
only recently that more serious attention started to be
paid to the problem. We look here only very briefly
at some most recent work in unification-based gram-
mars. Dymetman and Isabelle (1988) address the
problem of inverting a definite clause parser into a
generator in context of a machine translation system
and describe a top-down interpreter with dynamic
selection of AND goals&apos; (and therefore more flexible
than, say, left-to-right interpreter) that can execute a
given DCG grammar in either direction depending
only upon the binding status of arguments in the top-
level literal. This approach, although conceptually
quite general, proves far too expensive in practice.
The main source of overhead comes, it is pointed out,
from employing the trick known as goal freezing
(Colmerauer, 1982; Naish, 1986), that stops expan-
sion of currently active AND goals until certain vari-
ables get instantiated. The cost, however, is not the
only reason why the goal freezing techniques, and
their variations, are not satisfactory. As Shieber et al.
(1989) point out, the inherently top-down character
of goal freezing interpreters may occasionally cause
serious troubles during execution of certain types of
recursive goals. They propose to replace the
dynamic ordering of AND goals by a mixed top-
down/bottom-up interpretation. In this technique, cer-
tain goals, namely those whose expansion is defined
by the so-called &amp;quot;chain rules&amp;quot;2, are not expanded dur-
ing the top-down phase of the interpreter, but instead
they are passed over until a nearest non-chain rule is
reached. In the bottom-up phase the missing parts of
the goal-expansion tree will be filled in by applying
the chain rules in a backward manner. This tech-
nique, still substantially more expensive than a
fixed-order top-down interpreter, does not by itself
guarantee that we can use the underlying grammar
formalism bidirectionally. The reason is that in order
to achieve bidirectionality, we need either to impose
a proper static ordering of the &amp;quot;non-chain&amp;quot; AND
1 Literals Orl the right-hand side of a clause create AND
goals; literals with the same predicate names on the left-hand sides
of different clauses create OR goals.
a A chain rule is one where the main binding-carrying argu-
ment is passed unchanged from the left-hand side to the right. For
example, assert (P) --&gt; aubj (P1) , verb (P2) ,
</bodyText>
<equation confidence="0.386358">
obi (P1 P ) is a chain rule with respect to the amument P.
</equation>
<bodyText confidence="0.999282090909091">
goals (i.e., those which are not responsible for mak-
ing a rule a &amp;quot;chain rule&amp;quot;), or resort to dynamic order-
ing of such goals, putting the goal freezing back into
the picture.
In contrast with the above, the parser inversion
procedure described in this paper does not require a
run-time overhead and can be performed by an off-
line compilation process. It may, however, require
that the grammar is normalized prior to its inversion.
We briefly discuss the grammar normalization prob-
lem at the end of this paper.
</bodyText>
<sectionHeader confidence="0.989018" genericHeader="method">
IN AND OUT ARGUMENTS
</sectionHeader>
<bodyText confidence="0.9996212">
Arguments in a PROLOG literal can be marked
as either &amp;quot;in&amp;quot; or &amp;quot;out&amp;quot; depending on whether they are
bound at the time the literal is submitted for execu-
tion or after the computation is completed. For
example, in
</bodyText>
<sectionHeader confidence="0.515532" genericHeader="method">
tovo ( [to, eat, fish] , T4,
InPrEnyjohn]],P3)
</sectionHeader>
<bodyText confidence="0.987050666666667">
the first and the third arguments are &amp;quot;in&amp;quot;, while the
remaining two are &amp;quot;out&amp;quot;. When tovo is used for
generation, i.e.,
</bodyText>
<construct confidence="0.600586666666667">
tovo (T1, T4,P1,
(eat, (rip, john] ] ,
(rip, (n, fish] ] ] )
</construct>
<bodyText confidence="0.999430333333333">
then the last argument is &amp;quot;in&amp;quot;, while the first and the
third are &amp;quot;out&amp;quot;; T4 is neither &amp;quot;in&amp;quot; nor &amp;quot;out&amp;quot;. The
information about &amp;quot;in&amp;quot; and &amp;quot;out&amp;quot; status of arguments
is important in determining the &amp;quot;direction&amp;quot; in which
predicates containing them can be runs. Below we
present a simple method for computing &amp;quot;in&amp;quot; and
</bodyText>
<sectionHeader confidence="0.386964" genericHeader="method">
&amp;quot;out&amp;quot; arguments in PROLOG fiterals.4
</sectionHeader>
<subsectionHeader confidence="0.560425">
An argument X of literal pred(• • • X • • - ) on
</subsectionHeader>
<bodyText confidence="0.989118428571429">
the rhs of a clause is &amp;quot;in&amp;quot; if (A) it is a constant; or (B)
it is a function and all its arguments are &amp;quot;in&amp;quot;; or (C) it
is &amp;quot;in&amp;quot; or &amp;quot;out&amp;quot; in some previous literal on the rhs of
the same clause, i.e., /(Y) r (X,Y),pred (X); or (D)
it is &amp;quot;in&amp;quot; in the head literal L on ills of the same
clause.
An argument X is &amp;quot;in&amp;quot; in the head literal
</bodyText>
<equation confidence="0.687914">
L = pred ( - • • X- • • ) of a clause if (A), or (B), or (E)
</equation>
<bodyText confidence="0.987833">
L is the top-level literal and X is &amp;quot;in&amp;quot; in it (known a
priori); or (F) X occurs more than once in L and at
</bodyText>
<footnote confidence="0.720736">
3 For a discussion on directed predicates in PROLOG see (Sho-
ham and McDermott, 1984), and (Debray, 1989).
4 This simple algorithm is all we need to complete the exper-
iment at hand. A general method for computing &amp;quot;in&amp;quot;/&amp;quot;our argu-
ments is given in (Strzalkowsld, 1989). In this and further algo-
rithms we use abbreviations rhs and lhs to stand for right-hand side
and left-hand side (of a clause), respectively.
</footnote>
<page confidence="0.998348">
213
214
</page>
<bodyText confidence="0.991195344827586">
least one of these occurrences is &amp;quot;in&amp;quot;; or (G) for
every literal L = pred ( • • • Y • • • ) unifiable with L
on the rhs of any clause with the head predicate
pred1 different than pred, and such that Y unifies
with X, Y is &amp;quot;in&amp;quot; in Li.
A similar algorithm can be proposed for com-
puting &amp;quot;out&amp;quot; arguments. We introduce &amp;quot;unknwn&amp;quot; as a
third status marker for arguments occurring in certain
recursive clauses.
An argument X of literal pred(• • • X • • •) on
the rhs of a clause is &amp;quot;out&amp;quot; if (A) it is &amp;quot;in&amp;quot; in
pred( • • • X- • •); or (B) it is a functional expression
and all its arguments are either &amp;quot;in&amp;quot; or &amp;quot;out&amp;quot;; or (C)
for every clause with the head literal
pred( • • • Y • • &apos;)unifiable with pred( • • •X • • -) and
such that Y unifies with X, Y is either &amp;quot;in&amp;quot;, &amp;quot;out&amp;quot; or
&amp;quot;unknwn&amp;quot;, and I is marked &amp;quot;in&amp;quot; or &amp;quot;out&amp;quot; in at least
one case.
An argument X of literal pred(• • • X -- • ) on
the lhs of a clause is &amp;quot;out&amp;quot; if (D) it is &amp;quot;in&amp;quot; in
pred( • • • X • • • ); or (E) it is &amp;quot;out&amp;quot; in literal
predi(• • • X • • .) on the rhs of this clause, providing
that predi* pred;5 if predi= pred then X is marked
&amp;quot;unknwn&amp;quot;.
Note that this method predicts the &amp;quot;in&amp;quot; and
&amp;quot;out&amp;quot; status of arguments in a literal only if the
evaluation of this literal ends successfully. In case it
does not (a failure or a loop) the &amp;quot;in&amp;quot;/&amp;quot;out&amp;quot; status of
arguments becomes irrelevant.
</bodyText>
<sectionHeader confidence="0.970188" genericHeader="method">
COMPUTING ESSENTIAL ARGUMENTS
</sectionHeader>
<bodyText confidence="0.998189833333333">
Some arguments of every literal are essential in
the sense that the literal cannot be executed success-
fully unless all of them are bound, at least partially, at
the time of execution. For example, the predicate
tovo(T1,T4,P1,P3) that recognizes
&amp;quot;to+verb+object&amp;quot; object strings can be executed only
if either Ti or P3 is bound.6 7 If tovo is used to
parse then Ti. must be bound; if it is used to gen-
erate then P3 must be bound. In general, a literal
may have several alternative (possibly overlapping)
sets of essential arguments. If all arguments in any
one of such sets of essential arguments are bound,
</bodyText>
<construct confidence="0.9525692">
5 Again, we must take provisions to avoid infinite descend.
c.f. (G) in &amp;quot;in&amp;quot; algorithm.
a Assuming that tovo is defined as follows (simplified):
tovo (T1, Pl, P3) : - to (11, r2) , v (T2, T3,P2) ,
object (T3, T4,P1,P2,P3)
</construct>
<bodyText confidence="0.981715181818182">
An argument is considered fully bound is it is a constant or
it is bound by a constant; an argument is partially bound if it is, or
is bound by, a functional expression (not a variable) in which at
least one variable is unbound.
then the literal can be executed. Any set of essential
arguments which has the above property is called
essential. We shall call a set MSEA of essential argu-
ments a minimal set of essential arguments if it is
essential, and no proper subset of MSEA is essential.
A collection of minimal sets of essential argu-
ments (MSEA&apos;s) of a predicate depends upon the way
this predicate is defined. If we alter the ordering of
the rhs literals in the definition of a predicate, we
may also change its set of MSEA&apos;s. We call the set
of MSEA&apos;s existing for a current definition of a predi-
cate the set of active MSEA&apos;s for this predicate. To
run a predicate in a certain direction requires that a
specific MSEA is among the currently active MSEA&apos;s
for this predicate, and if this is not already the case,
then we have to alter the definition of this predicate
so as to make this MSEA become active. Consider
the following abstract clause defining predicate Ri:
</bodyText>
<equation confidence="0.99936075">
Ri(X 1, • • • ,Xk) :— (D1)
Q1(
Q2(• • •),
Qn( • • • ).
</equation>
<bodyText confidence="0.990443666666667">
Suppose that, as defined by (D1), Ri has the set MS; =
(m • • of active MSEA&apos;s, and let MRi MSi
be the set of all MSEA for Ri that can be obtained by
permuting the order of literals on the right-hand side
of (D1). Let us assume further that Ri occurs on rhs
of some other clause, as shown below:
</bodyText>
<equation confidence="0.998300666666667">
P (X , • • - (Cl)
Rau, •••,X
R 2(X 2,1 , • ,X 2,k,),
</equation>
<bodyText confidence="0.99909215625">
We want to compute MS, the set of active MSEA&apos;s
for P, as defined by (C1), where 0, assuming that
we know the sets of active MSEA for each Ri on the
rhs. s If s=0, that is P has no rhs in its definition, then
if P (X 1, • • - ,X„) is a call to P on the rhs of some
clause and X* is a subset of (X1, • • • ,X,,) then X* is
a MSEA in P if X* is the smallest set such that all
arguments in X* consistently unify (at the same time)
with the corresponding arguments in at most 1
occurrence of P on the lhs anywhere in the program.9
MSEA&apos;s of basic predicates, such as contest, are assumed to
he known a pion; MSEA&apos;s for recursive predicates are first com-
puted from non-recursive clauses.
9 The at most 1 requirement is the strictest possible, and it
can be relaxed to at most a in specific applications. The choice of n
may depend upon the nature of the input language being processed
(it may be n-degree ambiguous), and/or the cost of backing up
from unsuccessful calls. For example, consider the words every
and an: both can he translated into a single universal quantifier, but
upon generation we face ambiguity. If the representation from
When s 1, that is, P has at least one literal on
the rhs, we use the recursive procedure MSEAS to
compute the set of MSEA&apos;s for P. providing that we
already know the set of MSEA&apos;s for each literal
occurring on the rhs. Let T be a set of terms, that is,
variables and functional expressions, then VAR (7&apos;) is
the set of all variables occurring in the terms of T.
Thus VAR(ff (X),Y,g (c,f (Z),X))) = [X,Y,Z). We
assume that symbols X; in definitions (C1) and (D1)
above represent terms, not just variables. The follow-
ing algorithm is suggested for computing sets of
active MSEA&apos;s in P where i
</bodyText>
<equation confidence="0.874024">
MSEAS (MS,MSEA,VP,i3OUT)
</equation>
<bodyText confidence="0.630782">
Start with VP = VAR ((X 1, - • • ,X,1)), MSEA =
0, i=1, and OUT = 0. When the computation is
completed. MS is bound to the set of active
MSEA&apos;s for P.
</bodyText>
<listItem confidence="0.94347">
(2) Let MR I be the set of active MSEA&apos;s of R 1, and
let MRU I be obtained from MR1 by replacing all
variables in each member of MR1 by their
corresponding actual arguments of R1 on the rhs
of (C1).
(3) If RI =Pthenforeverym1e MRU1 if every
argument Y, e m i.k is always unifiable with its
corresponding argument X, in P then remove
m Lk from MRU 1. For every m set
— - -1.ki= M 1,k L--)
</listItem>
<bodyText confidence="0.9381574">
(X , where Ku is an argument in R1 such
that it is not already in m Lk and it is not always
unttiabk with its corresponding argument in P,
and m 1.ki is not a superset of any other m
remaining in MRU 1, add m i.kj to MRU1.1°
</bodyText>
<listItem confidence="0.9915955">
(4) For each m11 € MRE (1=1 • • • r1) compute
:= VAR (m11) n VP. Let Mi&apos;1 = (t.tu I
0(1•114),j=l• - • r), where r&gt;0, and 4)4h.i) =
0 or (t.tu = 0 and VAR (m = 0)1 If
Mi&apos;1 = 0 then QUIT: (Cl) is ill-formed and can-
not be executed.
</listItem>
<bodyText confidence="0.873423833333334">
which we generate is devoid of any constraints on the lexical
number of surface words, we may have to tolerate multiple
choices, at some point. Any decision made at this level as to which
arguments are to be essential, may affect the reversibility of the
grammar.
An argument Y is alwayv unifiable with an argument X if
they unify regardless of the possible bindings of any variables oc-
curring in Y (variables standardized apart), while the variables oc-
curring in X are unbound. Thus, any term is always unifiable with
a variable; however, a variable is not always unifiable with a non-
variable. For example, variable Xis not always unifiable with f (Y)
because if we substitute g (Z) for X then the so obtained terms do
not unify. The purpose of including steps (3) and (7) is to elim-
inate from consideration certain &apos;obviously&apos; 01-formed recursive
clauses. A more elaborate version of this condition is needed to
take care of less obvious cases.
(5) For each ti.0 e MP1 we do the following: (a)
assume that ti,1,1 is &amp;quot;in&amp;quot; in R1; (b) compute set
OUT14 of &amp;quot;out&amp;quot; arguments for R1; (c) call
MSEAS (MS Lj,t4 J,VP ,2,OUT Li); (d) assign
MS := L...) MS J.
(6) In some i-th step, where 1&lt;is, and MSEA =
let&apos;s suppose that MR; and MRU ; are the
sets of active MSEA&apos;s and their instantiations
with actual arguments of Ri, for the literal R; on
the rhs of (C1).
(7) If R; = P then for every mi E MRU ; if every
argument Y, E m1, is always unifiable with its
corresponding argument X, in P then remove
m,.. from MRU For every set mi.„i = mi,„ u
(Xij) where X1, is an argument in R; such that it
is not already in mi.. and it is not always
unifiable with its corresponding argument in P
and mi.„i is not a superset of any other mo
remaining in MRUi, add m1,,, to MRUI.
(8) Again, we compute the set MP; = I
</bodyText>
<equation confidence="0.901833">
j=1 • • • ri), where = (VAR (rui.i) —
</equation>
<bodyText confidence="0.974366">
OUT,_1,k), where OUTi_i,k is the set of all &amp;quot;out&amp;quot;
arguments in literals R1 to Ri_1.
</bodyText>
<listItem confidence="0.8539411875">
(9) For each laid remaining in MP; where i5S do the
following:
(a) if = 0 then: (i) compute the set OUTi of
&amp;quot;out&amp;quot; arguments of Ri; (ii) compute the union
OUT := OUTJ U OUT,; (iii) call
MSEAS (MS ;J,tt; _Lk, VP ,i +1,OUT4j);
(b) otherwise, if tki 0 then find all distinct
minimal size sets v, ç VP such that whenever
the arguments in v, are &amp;quot;in&amp;quot;, then the argu-
ments in tt, J are &amp;quot;out&amp;quot;. If such vs&apos;s exist, then
for every v, do: (i) assume v, is &amp;quot;in&amp;quot; in P; (ii)
compute the set OUT, of &amp;quot;out&amp;quot; arguments in
all literals from R1 to R•; (iii) call
MSEAS (MS,,h kuv„VP,i +LOUT f,h);
(c) otherwise, if no such v, exist, MS,,i := 0.
(10) Compute MS := u MS 0;
</listItem>
<equation confidence="0.907424">
j=1..r
(11)For i=s+1 set MS := (MSEA1.
</equation>
<bodyText confidence="0.999807285714286">
The procedure presented here can be modified to
compute the set of all MSEA&apos;s for P by considering
all feasible orderings of literals on the rhs of (C1) and
using information about all MSEA&apos;s for R; &apos;s. This
modified procedure would regard the rhs of (Cl) as
an unordered set of literals, and use various heuristics
to consider only selected orderings.
</bodyText>
<sectionHeader confidence="0.98785" genericHeader="method">
REORDERING LITERALS IN CLAUSES
</sectionHeader>
<bodyText confidence="0.998204">
When attempting to expand a literal on the rhs
of any clause the following basic rule should be
</bodyText>
<equation confidence="0.900296">
(1)
</equation>
<page confidence="0.994047">
215
</page>
<bodyText confidence="0.980609906976745">
observed: never expand a literal before at least one its
active MSEA&apos;s is &amp;quot;in&amp;quot;, which means that all argu-
ments in at least one MSEA are bound. The following
algorithm uses this simple principle to reorder rhs of
parser clauses for reversed use in generation. This
algorithm uses the information about &amp;quot;in&amp;quot; and &amp;quot;out&amp;quot;
arguments for literals and sets of MSEA&apos;s for predi-
cates. If the &amp;quot;in&amp;quot; MSEA of a literal is not active then
the rhs&apos;s of every definition of this predicate is recur-
sively reordered so that the selected MSEA becomes
active. We proceed top-down altering definitions of
predicates of the literals to make their MSEA&apos;s active
as necessary. When reversing a parser, we start with
the top level predicate pars_gen (S, P) assuming
that variable P is bound to the regularized parse
structure of a sentence. We explicitly identify and
mark P as &amp;quot;in&amp;quot; and add the requirement that S must
be marked &amp;quot;out&amp;quot; upon completion of rhs reordering.
We proceed to adjust the definition of pars_gen to
reflect that now P) is an active MSEA. We continue
until we reach the level of atomic or non-reversible
primitives such as concat, member, or dictionary
look-up routines. If this top-down process succeeds at
reversing predicate definitions at each levet down to
the primitives, and the primitives need no re-
definition, then the process is successful, and the
reversed-parser generator is obtained. The algorithm
can be extended in many ways, including inter-
clausal reordering of literals, which may be required
in some situations (Strzalkowski, 1989).
INVERSE(&amp;quot;head old-rhs&amp;quot;,ins,outs);
ins and outs are subsets of VAR(head) which
are &amp;quot;in&amp;quot; and are required to be &amp;quot;out&amp;quot;, respectively)
begin
compute M the set of all MSEA&apos;s for head;
for every MSEA m e M do
begin
OUT := 0;
if m is an active MSEA such that mcins then
begin
compute &amp;quot;out&amp;quot; arguments in head;
add them to OUT;
if outscOUT then DONE(&amp;quot;head:-old-rhs&amp;quot;)
</bodyText>
<equation confidence="0.8166684">
end
else if m is a non-active MSEA and mcins then
begin
new-rhs := 0; QUTT := false;
old-rhs-1 := old-rhs;
</equation>
<bodyText confidence="0.972287380952381">
for every literal L do
ML
(done only once during the inversion)
repeat
mark &amp;quot;in&amp;quot; old-rhs-1 arguments which are
either constants, or marked &amp;quot;in&amp;quot; in head,
or marked &amp;quot;in&amp;quot;, or &amp;quot;out&amp;quot; in new-rhs;
select a literal L in old-rhs-1 which has
an &amp;quot;in&amp;quot; MSEA mL and if mL is not active in L
then either M = 0 or m E ML;
set up a backtracking point containing
all the remaining alternatives
to select L from old-rhs-1;
if L exists then
begin
if m is non-active in L then
begin
if ML = 0 then ML := ML L.)
for every clause &amp;quot;Ll rhsu&amp;quot; such that
LI has the same predicate as L do
begin
</bodyText>
<equation confidence="0.856986">
INVERSE(&apos;L1 rhsLi&amp;quot;,ML,0);
</equation>
<bodyText confidence="0.828333571428571">
if GIVEUP returned then backup, undoing
all changes, to the latest backtracking
point and select another alternative
end
end;
compute &amp;quot;in&amp;quot; and &amp;quot;out&amp;quot; arguments in L;
add &amp;quot;out&amp;quot; arguments to OUT;
</bodyText>
<equation confidence="0.988515666666667">
new-rhs := APPEND-AT-THE-END(new-rhs,L);
old-rhs-1 := REMOVE(old-rhs-1,L)
end (if)
</equation>
<bodyText confidence="0.9420806">
else begin
backup, undoing all changes, to the latest
backtracking point and select another
alternative;
if no such backtracking point exists then
</bodyText>
<equation confidence="0.801650222222222">
QUIT := true
end (else)
until old-rhs-1 = 0 or QUFF;
if outscOUT and not QUIT then
DONE(&amp;quot;head:-new-rhs&amp;quot;)
end felseif)
end; (for)
GIVEUP(&amp;quot;can&apos;t invert as specified&amp;quot;)
end;
</equation>
<sectionHeader confidence="0.716389" genericHeader="method">
THE IMPLEMENTATION
</sectionHeader>
<bodyText confidence="0.997510235294118">
We have implemented an interpreter, which
translates Definite Clause Grammar dually into a
parser and a generator. The interpreter first
transforms a DCG grammar into equivalent PROLOG
code, which is subsequently inverted into a generator.
For each predicate we compute the minimal sets of
essential arguments that would need to be active if
the program were used in the generation mode. Next,
we rearrange the order of the right hand side literals
for each clause in such a way that the set of essential
arguments in each literal is guaranteed to be bound
whenever the literal is chosen for expansion. To
implement the algorithm efficiently, we compute the
2 16 minimal sets of essential arguments and reorder the
literals in the right-hand sides of clauses in one pass
through the parser program. As an example, we con-
sider the following rule in our DCG grammar:&amp;quot;
</bodyText>
<table confidence="0.81442353125">
assertion(S) -›
sa(S1),
subject (Sb),
sa(S2),
verb (V),
(Sb:np:number V:number),
sa(S3),
object(0,V,Vp,S13,4).
sa(S4),
(S:verb:head Vp:head},
(S:verb:number V:number),
(S:tense W:tense,0:tense)1,
(S:subject :: Sp),
(S:object 0:corel,
(S:sa
(S1:sa,S2:sa,S3:sa,0:sa,S4:sal).
When translated into PROLOG, it yields the following
clause in the parser:
assertion (S,L1, L2) : -
sa (Si., 1.1, L3)
subject (Sb, L3, L4) ,
sa (S2, L4,L5) ,
verb (V, L5, L6) ,
Sb:np:number V:number,
sa (S3, L6,L7) ,
object (0, V, Vp, Sb, Sp, L7 , LS) ,
Eta (S4,L8,L2) ,
S:verb:head Vp:head,
S:verb:number V:number,
S:tense W:tense,0:tensel,
S:subject :: Sp,
S:object :: 0:core,
</table>
<subsectionHeader confidence="0.742332">
S:sa
</subsectionHeader>
<bodyText confidence="0.995082613636364">
[S1:sa,S2:sa,S3:sa,0:sa,S4:sa].
The parser program is now inverted using the algo-
rithms described in previous sections. As a result, the
assertion clause above is inverted into a genera-
tor clause by rearranging the order of the literals on
its right-hand side. The literals are examined from the
left to right: if a set of essential arguments is bound,
the literal is put into the output queue, otherwise the
n The grammar design is based upon string grammar (Sager,
1981). Nonterrninal sa stands for a string of sentence adjuncts,
such as prepositional or adverbial phrases; : : is a PRoLoh-defined
predicate. We show only one rule of the grammar due to the lack
of space.
literal is put into the waiting stack. In the example at
hand, the literal sa (S1 Ll , L3) is examined first.
Its MSEA is (Si.), and since it is not a subset of the
set of variables appearing in the head literal, this set
cannot receive a binding when the execution of
assertion starts. It may, however, contain &amp;quot;out&amp;quot;
arguments in some other literals on the right-hand
side of the clause. We thus remove the first sa
literal from the clause and place it on hold until its
MSEA becomes fully instantiated. We proceed to
consider the remaining literals in the clause in the
same manner, until we reach S : verb : head : :
Vp: head. One MSEA for this literal is (S ), which is
a subset of the arguments in the head literal. We also
determine that S is not an &amp;quot;out&amp;quot; argument in any
other literal in the clause, anti thus it must be bound
in assertion whenever the clause is to be exe-
cuted. This means, in turn, that S is an essential
argument in assertion. As we continue this pro-
cess we find that no further essential arguments are
required, that is, (s) is a MSEA for assertion.
The literal s :verb : head : Vp: head is out-
put and becomes the top element on the right-hand
side of the inverted clause. After all literals in the
original clause are processed, we repeat this analysis
for all those remaining in the waiting stack until all
the literals are output. We add prefix g to each
inverted predicate in the generator to distinguish
them from their non-inverted versions in the parser.
The inverted assertion predicate as it appears in
the generator is shown below.
</bodyText>
<table confidence="0.7947323125">
g assertion(S,L1,L2) :-
S:verb:head Vp:head,
S:verb:number V:number,
S:tense (V:tense,0:tense],
S:subject :: Sp,
S:object :: 0:core,
S:sa
[S1.:ati,S2:sa., $3: sa,0:aa, $4 : sal,
g_sa (S4, L3,L2)
gobject (0, V, Vp, Sb, Sp, L4, L3) ,
g_sa(S3, L5, L4) ,
Sb:np:number V:number,
g verb (V, L6,1.5) ,
g sa (S2,L7, L6)
g subject (Sb, L8 , L7 ) ,
g sa(S1,L1,L8) .
</table>
<bodyText confidence="0.999658333333333">
A single grammar is thus used both for sentence pars-
ing and for generation. The parser or the generator is
invoked using the same top-level predicate
pars_gen (3,P) depending upon the binding
status of its arguments: if S is bound then the parser
is invoked, if P is bound the generator is called.
</bodyText>
<page confidence="0.991463">
217
</page>
<figure confidence="0.4295566">
I ?- load gram(grammar).
yes
1 ?- pars_gen ( [Jane, takes, a, course] , P ) .
P = Hcatlassertion],
[tense,present,[1],
</figure>
<bodyText confidence="0.9487984375">
[verbItake],
[subject,
[np,[headljane],
[numberlsingular],
(classInstudentl.
[tpos],
[apos],
[modifier, null] ] ] ,
[object,
[np,[head1course].
[numberlsingular],
[classIncourse],
[tpos1a],
[apes],
(modifier, null]]],
Esa, El (1, (3, El, Cl l]
</bodyText>
<sectionHeader confidence="0.410066" genericHeader="method">
yes
</sectionHeader>
<bodyText confidence="0.993665157894737">
?- pars_gen (S ,
((cat I assertion] ,
[tense, present []
[verbItake].
[subject,
[np,[headljanel.
[numberlsingular],
[classInstudent],
[tpos],
(aposl.
[modifier, null] ] ,
[object,
[np, [head! course] 1
[number I singular] ,
[class I ncourse] ,
[tpos la],
(apes),
[modifier, null] ] I,
[sa, [1, [] [1 • C], Inn .
</bodyText>
<sectionHeader confidence="0.925295333333333" genericHeader="method">
S = [jane,takes,a,course]
yes
GRAMMAR NORMALIZATION
</sectionHeader>
<bodyText confidence="0.999894375">
Thus far we have tacitly assumed that the
grammar upon which our parser is based is written in
such a way that it can be executed by a top-down
interpreter, such as the one used by PROLOG. If this is
not the case, that is, if the grammar requires a dif-
ferent kind of interpreter, then the question of inverti-
bility can only be related to this particular type of
interpreter. If we want to use the inversion algorithm
described here to invert a parser written for an inter-
preter different than top-down and left-to-right, we
need to convert the parser, or the grammar on which
it is based, into a version which can be evaluated in a
top-down fashion.
One situation where such normalization may
be required involves certain types of non-standard
recursive goals, as depicted schematically below.
</bodyText>
<construct confidence="0.626968333333333">
vp (A, P) -&gt; vp (f (A, P1) , compl (PI) .
vp (A, P) -&gt; v (A, P ) .
v (A, P) -&gt; lex.
</construct>
<bodyText confidence="0.979156909090909">
If vp is invoked by a top-down, left-to-right inter-
preter, with the variable P instantiated, and if P3. is
the essential argument in comp]., then there is no
way we can successfully execute the first clause,
even if we alter the ordering of the literals on its
right-hand side, unless, that is, we employ the goal
skipping technique discussed by Shieber et al. How-
ever, we can easily normalize this code by replacing
the first two clauses with functionally equivalent ones
that get the recursion firmly under control, and that
can be evaluated in a top-down fashion. We assume
that P is the essential argument in v (A, P) and that
A is &amp;quot;out&amp;quot;. The normalized grammar is given below.
vp(A,P) -7 v(B,P),vpl(B,A).
vpl(f(S,P1),A) -] vp1(13,A),compl(P1).
vpl(A,A).
v(A,P) -] lex.
In this new code the recursive second clause will be
used so long as its first argument has a form frot.13),
where a and fi are fully instantiated terms, and it will
stop otherwise (either succeed or fail depending upon
initial binding to A). In general, the fact that a recur-
sive clause is unfit for a top-down execution can be
established by computing the collection of minimal
sets of essential arguments for its head predicate. If
this collection turns out to be empty, the predicate&apos;s
definition need to he normalized.
Other types of normalization include elimina-
tion of some of the chain rules in the grammar, espe-
cially if their presence induces undue non-
determinism in the generator. We may also, if neces-
sary, tighten the criteria for selecting the essential
arguments, to further enhance the efficiency of the
</bodyText>
<page confidence="0.993816">
218
</page>
<bodyText confidence="0.9996775">
generator, providing, of course, that this move does
not render the grammar non-reversible. For a further
discussion of these and related problems the reader is
referred to (Strzalkowski, 1989).
</bodyText>
<sectionHeader confidence="0.985125" genericHeader="conclusions">
CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.9997165">
In this paper we presented an algorithm for
automated inversion of a unification parser for
natural language into an efficient unification genera-
tor. The inverted program of the generator is obtained
by an off-line compilation process which directly
manipulates the PROLOG code of the parser program.
We distinguish two logical stages of this transforma-
tion: computing the minimal sets of essential argu-
ments (MSEA&apos;s) for predicates, and generating the
inverted program code with INVERSE. The method
described here is contrasted with the approaches that
seek to define a generalized but computationally
expensive evaluation strategy for running a grammar
in either direction without manipulating its rules
(Shieber, 1988), (Shieber et al., 1989), (Wedekind,
1989), and see also (Naish, 1986) for some relevant
techniques. We have completed a first implementa-
tion of the system and used it to derive both a parser
and a generator from a single DCG grammar for
English. We note that the present version of
INVERSE can operate only upon the declarative
specification of a logic grammar and is not prepared
to deal with extra-logical control operators such as
the cut.
</bodyText>
<sectionHeader confidence="0.992671" genericHeader="acknowledgments">
ACKNOWLEDGMENTS
</sectionHeader>
<bodyText confidence="0.99683875">
Ralph Grishman and other members of the
Natural Language Discussion Group provided valu-
able comments to earlier versions of this paper. We
also thank anonymous reviewers for their sugges-
tions. This paper is based upon work supported by
the Defense Advanced Research Project Agency
under Contract N00014-85-K-0163 from the Office
of Naval Research.
</bodyText>
<sectionHeader confidence="0.997621" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.998279">
Colmerauer, Alain. 1982. PROLOG II:
Manuel de reference et modele theorique. Groupe
d&apos;Intelligence Artificielle, Facuite de Sciences de
Luminy, Marseille.
Debray, Saurnya, K. 1989. &amp;quot;Static Inference
Modes and Data Dependencies in Logic Programs.&amp;quot;
ACM Transactions on Programming Languages and
Systems, 11(3), July 1989, pp. 418-450.
Derr, Marcia A. and McKeown, Kathleen R.
1984. &amp;quot;Using Focus to Generate Complex and Sim-
ple Sentences.&amp;quot; Proceedings of 10th COLING,
Bonn, Germany, pp. 319-326.
Dymetman, Marc and Isabelle, Pierre. 1988.
&amp;quot;Reversible Logic Grammars for Machine Transla-
tion.&amp;quot; Proc. of the Second Int. Conference on
Machine Translation, Pittsburgh, PA.
Grishman, Ralph. 1986, Proteus Parser Refer-
ence Manual. Proteus Project Memorandum #4,
Courant Institute of Mathematical Sciences, New
York University.
McKeown, Kathleen R. 1985. Text Genera-
tion: Using Discourse Strategies and Focus Con-
straints to Generate Natural Language Text. Cam-
bridge University Press.
Naish, Lee. 1986. Negation and Control in
PROLOG. Lecture Notes in Computer Science, 238,
Springer.
Pereira, Fernando C.N. and Warren, David
H.D. 1980. &amp;quot;Definite clause grammars for language
analysis.&amp;quot; Artificial Intelligence, 13, pp. 231-278.
Sager, Naomi. 1981. Natural Language Infor-
mation Processing. Addison-Wesley.
Shieber, Stuart M. 1988. &amp;quot;A uniform architec-
ture for parsing and generation.&amp;quot; Proceedings of the
12th COLING, Budapest, Hungary (1988), pp. 614-
619.
Shieber, Stuart M., van Noord, Gertjan, Moore,
Robert C. and Pereira, Fernando C.N. 1989. &amp;quot;A
Semantic-Head-Driven Generation Algorithm for
Unification-Based Formalisms.&amp;quot; Proceedings of the
27th Meeting of the ACL, Vancouver, B.C., pp. 7-17.
Shoham, Yoav and McDermott, Drew V. 1984.
&amp;quot;Directed Relations and Inversion of PROLOG Pro-
grams.&amp;quot; Proc. of the Int. Conference of Fifth Gen-
eration Computer Systems.
Strzalkowski, Tomek. 1989. Automated Inver-
sion of a Unification Parser into a Unification Gen-
erator. Technical Report 465, Department of Com-
puter Science, Courant Institute of Mathematical Sci-
ences, New York University.
Strzalkowski, Tomek. 1990. &amp;quot;An algorithm
for inverting a unification grammar into an efficient
unification generator.&amp;quot; Applied Mathematics Letters,
vol. 3, no. 1, pp. 93-96. Pergamon Press.
Wedekind, Jurgen. 1988. &amp;quot;Generation as
structure driven derivation.&amp;quot; Proceedings of the 12th
COLING Budapest, Hungary, pp. 732-737.
</reference>
<page confidence="0.999211">
219
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.636803">
<title confidence="0.999115">AUTOMATED INVERSION OF LOGIC GRAMMARS FOR GENERATION</title>
<author confidence="0.995438">Tomek Strzalkowski</author>
<author confidence="0.995438">Ping Peng</author>
<affiliation confidence="0.9973525">Courant Institute of Mathematical Sciences New York University</affiliation>
<address confidence="0.9995405">251 Mercer Street New York, NY 10012</address>
<abstract confidence="0.974920733333333">We describe a system of reversible grammar in which, given a logic-grammar specification of a language, two efficient are derived by an off-line compilation process: a parser and a generator for this language. The centerpiece of the system is the inversion algorithm designed to the generator code from the parser&apos;s PROusing the collection of minimal sets of arguments predicates. The system has been implemented to work with Definite Clause Grammars (DCG) and is a part of an English-Japanese machine translation project currently under development at NYU&apos;s Courant Institute.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alain Colmerauer</author>
</authors>
<title>PROLOG II: Manuel de reference et modele theorique.</title>
<date>1982</date>
<booktitle>Groupe d&apos;Intelligence Artificielle, Facuite de Sciences de Luminy,</booktitle>
<location>Marseille.</location>
<contexts>
<context position="5452" citStr="Colmerauer, 1982" startWordPosition="865" endWordPosition="866">sabelle (1988) address the problem of inverting a definite clause parser into a generator in context of a machine translation system and describe a top-down interpreter with dynamic selection of AND goals&apos; (and therefore more flexible than, say, left-to-right interpreter) that can execute a given DCG grammar in either direction depending only upon the binding status of arguments in the toplevel literal. This approach, although conceptually quite general, proves far too expensive in practice. The main source of overhead comes, it is pointed out, from employing the trick known as goal freezing (Colmerauer, 1982; Naish, 1986), that stops expansion of currently active AND goals until certain variables get instantiated. The cost, however, is not the only reason why the goal freezing techniques, and their variations, are not satisfactory. As Shieber et al. (1989) point out, the inherently top-down character of goal freezing interpreters may occasionally cause serious troubles during execution of certain types of recursive goals. They propose to replace the dynamic ordering of AND goals by a mixed topdown/bottom-up interpretation. In this technique, certain goals, namely those whose expansion is defined </context>
</contexts>
<marker>Colmerauer, 1982</marker>
<rawString>Colmerauer, Alain. 1982. PROLOG II: Manuel de reference et modele theorique. Groupe d&apos;Intelligence Artificielle, Facuite de Sciences de Luminy, Marseille.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saurnya Debray</author>
<author>K</author>
</authors>
<title>Static Inference Modes and Data Dependencies in Logic Programs.&amp;quot;</title>
<date>1989</date>
<journal>ACM Transactions on Programming Languages and Systems,</journal>
<volume>11</volume>
<issue>3</issue>
<pages>418--450</pages>
<marker>Debray, K, 1989</marker>
<rawString>Debray, Saurnya, K. 1989. &amp;quot;Static Inference Modes and Data Dependencies in Logic Programs.&amp;quot; ACM Transactions on Programming Languages and Systems, 11(3), July 1989, pp. 418-450.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcia A Derr</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Using Focus to Generate Complex and Simple Sentences.&amp;quot;</title>
<date>1984</date>
<booktitle>Proceedings of 10th COLING,</booktitle>
<pages>319--326</pages>
<location>Bonn, Germany,</location>
<contexts>
<context position="4474" citStr="Derr &amp; McKeown, 1984" startWordPosition="704" endWordPosition="707">ith the inversion procedure described below. As noted by Dymetman and Isabelle (198,8), this transformation must involve rearranging the order of literals on the right-hand side of some clauses. We noted that the design of the string grammar (Sager, 1981) makes it more suitable as a basis of a reversible system than other grammar designs, although other grammars can be &amp;quot;normalized&amp;quot; (Strzalkowski, 1989). We also would like to point out that our main emphasis is on the problem of 212 reversibility rather than generation, the latter involving many problems that we don&apos;t deal with here (see, e.g. Derr &amp; McKeown, 1984; McKeown, 1985). RELATED WORK The idea that a generator for a language might be considered as an inverse of the parser for the same language has been around for some time, but it was only recently that more serious attention started to be paid to the problem. We look here only very briefly at some most recent work in unification-based grammars. Dymetman and Isabelle (1988) address the problem of inverting a definite clause parser into a generator in context of a machine translation system and describe a top-down interpreter with dynamic selection of AND goals&apos; (and therefore more flexible tha</context>
</contexts>
<marker>Derr, McKeown, 1984</marker>
<rawString>Derr, Marcia A. and McKeown, Kathleen R. 1984. &amp;quot;Using Focus to Generate Complex and Simple Sentences.&amp;quot; Proceedings of 10th COLING, Bonn, Germany, pp. 319-326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Dymetman</author>
<author>Pierre Isabelle</author>
</authors>
<title>Reversible Logic Grammars for Machine Translation.&amp;quot;</title>
<date>1988</date>
<booktitle>Proc. of the Second Int. Conference on Machine Translation,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="4850" citStr="Dymetman and Isabelle (1988)" startWordPosition="770" endWordPosition="773"> be &amp;quot;normalized&amp;quot; (Strzalkowski, 1989). We also would like to point out that our main emphasis is on the problem of 212 reversibility rather than generation, the latter involving many problems that we don&apos;t deal with here (see, e.g. Derr &amp; McKeown, 1984; McKeown, 1985). RELATED WORK The idea that a generator for a language might be considered as an inverse of the parser for the same language has been around for some time, but it was only recently that more serious attention started to be paid to the problem. We look here only very briefly at some most recent work in unification-based grammars. Dymetman and Isabelle (1988) address the problem of inverting a definite clause parser into a generator in context of a machine translation system and describe a top-down interpreter with dynamic selection of AND goals&apos; (and therefore more flexible than, say, left-to-right interpreter) that can execute a given DCG grammar in either direction depending only upon the binding status of arguments in the toplevel literal. This approach, although conceptually quite general, proves far too expensive in practice. The main source of overhead comes, it is pointed out, from employing the trick known as goal freezing (Colmerauer, 19</context>
</contexts>
<marker>Dymetman, Isabelle, 1988</marker>
<rawString>Dymetman, Marc and Isabelle, Pierre. 1988. &amp;quot;Reversible Logic Grammars for Machine Translation.&amp;quot; Proc. of the Second Int. Conference on Machine Translation, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
</authors>
<title>Proteus Parser Reference Manual.</title>
<date>1986</date>
<booktitle>Proteus Project Memorandum #4, Courant Institute of Mathematical Sciences,</booktitle>
<location>New York University.</location>
<marker>Grishman, 1986</marker>
<rawString>Grishman, Ralph. 1986, Proteus Parser Reference Manual. Proteus Project Memorandum #4, Courant Institute of Mathematical Sciences, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
</authors>
<title>Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text.</title>
<date>1985</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4490" citStr="McKeown, 1985" startWordPosition="708" endWordPosition="709">edure described below. As noted by Dymetman and Isabelle (198,8), this transformation must involve rearranging the order of literals on the right-hand side of some clauses. We noted that the design of the string grammar (Sager, 1981) makes it more suitable as a basis of a reversible system than other grammar designs, although other grammars can be &amp;quot;normalized&amp;quot; (Strzalkowski, 1989). We also would like to point out that our main emphasis is on the problem of 212 reversibility rather than generation, the latter involving many problems that we don&apos;t deal with here (see, e.g. Derr &amp; McKeown, 1984; McKeown, 1985). RELATED WORK The idea that a generator for a language might be considered as an inverse of the parser for the same language has been around for some time, but it was only recently that more serious attention started to be paid to the problem. We look here only very briefly at some most recent work in unification-based grammars. Dymetman and Isabelle (1988) address the problem of inverting a definite clause parser into a generator in context of a machine translation system and describe a top-down interpreter with dynamic selection of AND goals&apos; (and therefore more flexible than, say, left-to-</context>
</contexts>
<marker>McKeown, 1985</marker>
<rawString>McKeown, Kathleen R. 1985. Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lee Naish</author>
</authors>
<title>Negation and Control in PROLOG.</title>
<date>1986</date>
<journal>Lecture Notes in Computer Science,</journal>
<volume>238</volume>
<publisher>Springer.</publisher>
<contexts>
<context position="5466" citStr="Naish, 1986" startWordPosition="867" endWordPosition="868">ress the problem of inverting a definite clause parser into a generator in context of a machine translation system and describe a top-down interpreter with dynamic selection of AND goals&apos; (and therefore more flexible than, say, left-to-right interpreter) that can execute a given DCG grammar in either direction depending only upon the binding status of arguments in the toplevel literal. This approach, although conceptually quite general, proves far too expensive in practice. The main source of overhead comes, it is pointed out, from employing the trick known as goal freezing (Colmerauer, 1982; Naish, 1986), that stops expansion of currently active AND goals until certain variables get instantiated. The cost, however, is not the only reason why the goal freezing techniques, and their variations, are not satisfactory. As Shieber et al. (1989) point out, the inherently top-down character of goal freezing interpreters may occasionally cause serious troubles during execution of certain types of recursive goals. They propose to replace the dynamic ordering of AND goals by a mixed topdown/bottom-up interpretation. In this technique, certain goals, namely those whose expansion is defined by the so-call</context>
<context position="30811" citStr="Naish, 1986" startWordPosition="5453" endWordPosition="5454">enerator is obtained by an off-line compilation process which directly manipulates the PROLOG code of the parser program. We distinguish two logical stages of this transformation: computing the minimal sets of essential arguments (MSEA&apos;s) for predicates, and generating the inverted program code with INVERSE. The method described here is contrasted with the approaches that seek to define a generalized but computationally expensive evaluation strategy for running a grammar in either direction without manipulating its rules (Shieber, 1988), (Shieber et al., 1989), (Wedekind, 1989), and see also (Naish, 1986) for some relevant techniques. We have completed a first implementation of the system and used it to derive both a parser and a generator from a single DCG grammar for English. We note that the present version of INVERSE can operate only upon the declarative specification of a logic grammar and is not prepared to deal with extra-logical control operators such as the cut. ACKNOWLEDGMENTS Ralph Grishman and other members of the Natural Language Discussion Group provided valuable comments to earlier versions of this paper. We also thank anonymous reviewers for their suggestions. This paper is bas</context>
</contexts>
<marker>Naish, 1986</marker>
<rawString>Naish, Lee. 1986. Negation and Control in PROLOG. Lecture Notes in Computer Science, 238, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>David H D Warren</author>
</authors>
<title>Definite clause grammars for language analysis.&amp;quot;</title>
<date>1980</date>
<journal>Artificial Intelligence,</journal>
<volume>13</volume>
<pages>231--278</pages>
<contexts>
<context position="3733" citStr="Pereira &amp; Warren, 1980" startWordPosition="581" endWordPosition="584">is sound and as complete as possible. • A reversible grammar provides, by design, the match between system&apos;s analysis and generation capabilities, which is especially important in interactive systems. A discrepancy in this capacity may mislead the user, who tends to assume that what is generated as output is also acceptable as input, and vice-versa. • Finally, a bidirectional system can be expected to be more robust, easier to maintain and modify, and altogether more perspicuous. In the work reported here we concentrated on unification-based formalisms, in particular Definite Clause Grammars (Pereira &amp; Warren, 1980), which can be compiled dually into PROLOG parser and generator, where the generator is obtained from the parser&apos;s code with the inversion procedure described below. As noted by Dymetman and Isabelle (198,8), this transformation must involve rearranging the order of literals on the right-hand side of some clauses. We noted that the design of the string grammar (Sager, 1981) makes it more suitable as a basis of a reversible system than other grammar designs, although other grammars can be &amp;quot;normalized&amp;quot; (Strzalkowski, 1989). We also would like to point out that our main emphasis is on the problem</context>
</contexts>
<marker>Pereira, Warren, 1980</marker>
<rawString>Pereira, Fernando C.N. and Warren, David H.D. 1980. &amp;quot;Definite clause grammars for language analysis.&amp;quot; Artificial Intelligence, 13, pp. 231-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naomi Sager</author>
</authors>
<title>Natural Language Information Processing.</title>
<date>1981</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="4109" citStr="Sager, 1981" startWordPosition="644" endWordPosition="645">an be expected to be more robust, easier to maintain and modify, and altogether more perspicuous. In the work reported here we concentrated on unification-based formalisms, in particular Definite Clause Grammars (Pereira &amp; Warren, 1980), which can be compiled dually into PROLOG parser and generator, where the generator is obtained from the parser&apos;s code with the inversion procedure described below. As noted by Dymetman and Isabelle (198,8), this transformation must involve rearranging the order of literals on the right-hand side of some clauses. We noted that the design of the string grammar (Sager, 1981) makes it more suitable as a basis of a reversible system than other grammar designs, although other grammars can be &amp;quot;normalized&amp;quot; (Strzalkowski, 1989). We also would like to point out that our main emphasis is on the problem of 212 reversibility rather than generation, the latter involving many problems that we don&apos;t deal with here (see, e.g. Derr &amp; McKeown, 1984; McKeown, 1985). RELATED WORK The idea that a generator for a language might be considered as an inverse of the parser for the same language has been around for some time, but it was only recently that more serious attention started t</context>
<context position="24177" citStr="Sager, 1981" startWordPosition="4323" endWordPosition="4324">7 , LS) , Eta (S4,L8,L2) , S:verb:head Vp:head, S:verb:number V:number, S:tense W:tense,0:tensel, S:subject :: Sp, S:object :: 0:core, S:sa [S1:sa,S2:sa,S3:sa,0:sa,S4:sa]. The parser program is now inverted using the algorithms described in previous sections. As a result, the assertion clause above is inverted into a generator clause by rearranging the order of the literals on its right-hand side. The literals are examined from the left to right: if a set of essential arguments is bound, the literal is put into the output queue, otherwise the n The grammar design is based upon string grammar (Sager, 1981). Nonterrninal sa stands for a string of sentence adjuncts, such as prepositional or adverbial phrases; : : is a PRoLoh-defined predicate. We show only one rule of the grammar due to the lack of space. literal is put into the waiting stack. In the example at hand, the literal sa (S1 Ll , L3) is examined first. Its MSEA is (Si.), and since it is not a subset of the set of variables appearing in the head literal, this set cannot receive a binding when the execution of assertion starts. It may, however, contain &amp;quot;out&amp;quot; arguments in some other literals on the right-hand side of the clause. We thus r</context>
</contexts>
<marker>Sager, 1981</marker>
<rawString>Sager, Naomi. 1981. Natural Language Information Processing. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>A uniform architecture for parsing and generation.&amp;quot;</title>
<date>1988</date>
<booktitle>Proceedings of the 12th COLING,</booktitle>
<pages>614--619</pages>
<location>Budapest, Hungary</location>
<contexts>
<context position="30741" citStr="Shieber, 1988" startWordPosition="5442" endWordPosition="5443">e into an efficient unification generator. The inverted program of the generator is obtained by an off-line compilation process which directly manipulates the PROLOG code of the parser program. We distinguish two logical stages of this transformation: computing the minimal sets of essential arguments (MSEA&apos;s) for predicates, and generating the inverted program code with INVERSE. The method described here is contrasted with the approaches that seek to define a generalized but computationally expensive evaluation strategy for running a grammar in either direction without manipulating its rules (Shieber, 1988), (Shieber et al., 1989), (Wedekind, 1989), and see also (Naish, 1986) for some relevant techniques. We have completed a first implementation of the system and used it to derive both a parser and a generator from a single DCG grammar for English. We note that the present version of INVERSE can operate only upon the declarative specification of a logic grammar and is not prepared to deal with extra-logical control operators such as the cut. ACKNOWLEDGMENTS Ralph Grishman and other members of the Natural Language Discussion Group provided valuable comments to earlier versions of this paper. We a</context>
</contexts>
<marker>Shieber, 1988</marker>
<rawString>Shieber, Stuart M. 1988. &amp;quot;A uniform architecture for parsing and generation.&amp;quot; Proceedings of the 12th COLING, Budapest, Hungary (1988), pp. 614-619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Gertjan van Noord</author>
<author>Robert C Moore</author>
<author>Fernando C N Pereira</author>
</authors>
<title>A Semantic-Head-Driven Generation Algorithm for Unification-Based Formalisms.&amp;quot;</title>
<date>1989</date>
<booktitle>Proceedings of the 27th Meeting of the ACL,</booktitle>
<pages>7--17</pages>
<location>Vancouver, B.C.,</location>
<marker>Shieber, van Noord, Moore, Pereira, 1989</marker>
<rawString>Shieber, Stuart M., van Noord, Gertjan, Moore, Robert C. and Pereira, Fernando C.N. 1989. &amp;quot;A Semantic-Head-Driven Generation Algorithm for Unification-Based Formalisms.&amp;quot; Proceedings of the 27th Meeting of the ACL, Vancouver, B.C., pp. 7-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Shoham</author>
<author>Drew V McDermott</author>
</authors>
<title>Directed Relations and Inversion of PROLOG Programs.&amp;quot;</title>
<date>1984</date>
<booktitle>Proc. of the Int. Conference of Fifth Generation Computer Systems.</booktitle>
<contexts>
<context position="9020" citStr="Shoham and McDermott, 1984" startWordPosition="1508" endWordPosition="1512">ument X of literal pred(• • • X • • - ) on the rhs of a clause is &amp;quot;in&amp;quot; if (A) it is a constant; or (B) it is a function and all its arguments are &amp;quot;in&amp;quot;; or (C) it is &amp;quot;in&amp;quot; or &amp;quot;out&amp;quot; in some previous literal on the rhs of the same clause, i.e., /(Y) r (X,Y),pred (X); or (D) it is &amp;quot;in&amp;quot; in the head literal L on ills of the same clause. An argument X is &amp;quot;in&amp;quot; in the head literal L = pred ( - • • X- • • ) of a clause if (A), or (B), or (E) L is the top-level literal and X is &amp;quot;in&amp;quot; in it (known a priori); or (F) X occurs more than once in L and at 3 For a discussion on directed predicates in PROLOG see (Shoham and McDermott, 1984), and (Debray, 1989). 4 This simple algorithm is all we need to complete the experiment at hand. A general method for computing &amp;quot;in&amp;quot;/&amp;quot;our arguments is given in (Strzalkowsld, 1989). In this and further algorithms we use abbreviations rhs and lhs to stand for right-hand side and left-hand side (of a clause), respectively. 213 214 least one of these occurrences is &amp;quot;in&amp;quot;; or (G) for every literal L = pred ( • • • Y • • • ) unifiable with L on the rhs of any clause with the head predicate pred1 different than pred, and such that Y unifies with X, Y is &amp;quot;in&amp;quot; in Li. A similar algorithm can be proposed</context>
</contexts>
<marker>Shoham, McDermott, 1984</marker>
<rawString>Shoham, Yoav and McDermott, Drew V. 1984. &amp;quot;Directed Relations and Inversion of PROLOG Programs.&amp;quot; Proc. of the Int. Conference of Fifth Generation Computer Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
</authors>
<title>Automated Inversion of a Unification Parser into a Unification Generator.</title>
<date>1989</date>
<tech>Technical Report 465,</tech>
<institution>Department of Computer Science, Courant Institute of Mathematical Sciences, New York University.</institution>
<contexts>
<context position="4259" citStr="Strzalkowski, 1989" startWordPosition="667" endWordPosition="668">unification-based formalisms, in particular Definite Clause Grammars (Pereira &amp; Warren, 1980), which can be compiled dually into PROLOG parser and generator, where the generator is obtained from the parser&apos;s code with the inversion procedure described below. As noted by Dymetman and Isabelle (198,8), this transformation must involve rearranging the order of literals on the right-hand side of some clauses. We noted that the design of the string grammar (Sager, 1981) makes it more suitable as a basis of a reversible system than other grammar designs, although other grammars can be &amp;quot;normalized&amp;quot; (Strzalkowski, 1989). We also would like to point out that our main emphasis is on the problem of 212 reversibility rather than generation, the latter involving many problems that we don&apos;t deal with here (see, e.g. Derr &amp; McKeown, 1984; McKeown, 1985). RELATED WORK The idea that a generator for a language might be considered as an inverse of the parser for the same language has been around for some time, but it was only recently that more serious attention started to be paid to the problem. We look here only very briefly at some most recent work in unification-based grammars. Dymetman and Isabelle (1988) address </context>
<context position="20510" citStr="Strzalkowski, 1989" startWordPosition="3715" endWordPosition="3716">f rhs reordering. We proceed to adjust the definition of pars_gen to reflect that now P) is an active MSEA. We continue until we reach the level of atomic or non-reversible primitives such as concat, member, or dictionary look-up routines. If this top-down process succeeds at reversing predicate definitions at each levet down to the primitives, and the primitives need no redefinition, then the process is successful, and the reversed-parser generator is obtained. The algorithm can be extended in many ways, including interclausal reordering of literals, which may be required in some situations (Strzalkowski, 1989). INVERSE(&amp;quot;head old-rhs&amp;quot;,ins,outs); ins and outs are subsets of VAR(head) which are &amp;quot;in&amp;quot; and are required to be &amp;quot;out&amp;quot;, respectively) begin compute M the set of all MSEA&apos;s for head; for every MSEA m e M do begin OUT := 0; if m is an active MSEA such that mcins then begin compute &amp;quot;out&amp;quot; arguments in head; add them to OUT; if outscOUT then DONE(&amp;quot;head:-old-rhs&amp;quot;) end else if m is a non-active MSEA and mcins then begin new-rhs := 0; QUTT := false; old-rhs-1 := old-rhs; for every literal L do ML (done only once during the inversion) repeat mark &amp;quot;in&amp;quot; old-rhs-1 arguments which are either constants, or m</context>
<context position="30006" citStr="Strzalkowski, 1989" startWordPosition="5334" endWordPosition="5335">arguments for its head predicate. If this collection turns out to be empty, the predicate&apos;s definition need to he normalized. Other types of normalization include elimination of some of the chain rules in the grammar, especially if their presence induces undue nondeterminism in the generator. We may also, if necessary, tighten the criteria for selecting the essential arguments, to further enhance the efficiency of the 218 generator, providing, of course, that this move does not render the grammar non-reversible. For a further discussion of these and related problems the reader is referred to (Strzalkowski, 1989). CONCLUSIONS In this paper we presented an algorithm for automated inversion of a unification parser for natural language into an efficient unification generator. The inverted program of the generator is obtained by an off-line compilation process which directly manipulates the PROLOG code of the parser program. We distinguish two logical stages of this transformation: computing the minimal sets of essential arguments (MSEA&apos;s) for predicates, and generating the inverted program code with INVERSE. The method described here is contrasted with the approaches that seek to define a generalized but</context>
</contexts>
<marker>Strzalkowski, 1989</marker>
<rawString>Strzalkowski, Tomek. 1989. Automated Inversion of a Unification Parser into a Unification Generator. Technical Report 465, Department of Computer Science, Courant Institute of Mathematical Sciences, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
</authors>
<title>An algorithm for inverting a unification grammar into an efficient unification generator.&amp;quot;</title>
<date>1990</date>
<journal>Applied Mathematics Letters,</journal>
<volume>3</volume>
<pages>93--96</pages>
<publisher>Pergamon Press.</publisher>
<marker>Strzalkowski, 1990</marker>
<rawString>Strzalkowski, Tomek. 1990. &amp;quot;An algorithm for inverting a unification grammar into an efficient unification generator.&amp;quot; Applied Mathematics Letters, vol. 3, no. 1, pp. 93-96. Pergamon Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jurgen Wedekind</author>
</authors>
<title>Generation as structure driven derivation.&amp;quot;</title>
<date>1988</date>
<booktitle>Proceedings of the 12th COLING Budapest, Hungary,</booktitle>
<pages>732--737</pages>
<marker>Wedekind, 1988</marker>
<rawString>Wedekind, Jurgen. 1988. &amp;quot;Generation as structure driven derivation.&amp;quot; Proceedings of the 12th COLING Budapest, Hungary, pp. 732-737.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>