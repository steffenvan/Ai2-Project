<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006999">
<title confidence="0.986042">
Ordering Among Premodifiers
</title>
<author confidence="0.997197">
James Shaw and Vasileios Hatzivassiloglou
</author>
<affiliation confidence="0.9956975">
Department of Computer Science
Columbia University
</affiliation>
<address confidence="0.7603655">
New York, N.Y. 10027, USA
{ shaw, vh}Ocs columbia edu
</address>
<sectionHeader confidence="0.852191" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999824272727273">
We present a corpus-based study of the se-
quential ordering among premodifiers in noun
phrases. This information is important for the
fluency of generated text in practical appli-
cations. We propose and evaluate three ap-
proaches to identify sequential order among pre-
modifiers: direct evidence, transitive closure,
and clustering. Our implemented system can
make over 94% of such ordering decisions cor-
rectly, as evaluated on a large, previously un-
seen test corpus.
</bodyText>
<sectionHeader confidence="0.99551" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970439393939">
Sequential ordering among premodifiers affects
the fluency of text, e.g., &amp;quot;large foreign finan-
cial firms&amp;quot; or &amp;quot;zero-coupon global bonds&amp;quot; are
desirable, while &amp;quot;foreign large financial firms&amp;quot;
or &amp;quot;global zero-coupon bonds&amp;quot; sound odd. The
difficulties in specifying a consistent ordering of
adjectives have already been noted by linguists
[Whorf 1956; Vendler 19681. During the process
of generating complex sentences by combining
multiple clauses, there are situations where mul-
tiple adjectives or nouns modify the same head
noun. The text generation system must order
these modifiers in a similar way as domain ex-
perts use them to ensure fluency of the text. For
example, the description of the age of a patient
precedes his ethnicity and gender in medical do-
main as in &amp;quot;a 50 year-old white female patient&amp;quot;.
Yet, general lexicons such as WordNet [Miller et
al. 19901 and COMLEX [Grishman et al. 1994],
do not store such information.
In this paper, we present automated tech-
niques for addressing this problem of determin-
ing, given two premodifiers A and B, the pre-
ferred ordering between them. Our methods
rely on and generalize empirical evidence ob-
tained from large corpora, and are evaluated
objectively on such corpora. They are informed
and motivated by our practical need for order-
ing multiple premodifiers in the MAGIC system
[Dalal et al. 1996]. MAGIC utilizes co-ordinated
text, speech, and graphics to convey informa-
tion about a patient&apos;s status after coronary by-
pass surgery; it generates concise but complex
descriptions that frequently involve four or more
premodifiers in the same noun phrase.
To demonstrate that a significant portion of
noun phrases have multiple premodifiers, we
extracted all the noun phrases (NPs, exclud-
ing pronouns) in a two million word corpus of
medical discharge summaries and a 1.5 million
word Wall Street Journal (WSJ) corpus (see
Section 4 for a more detailed description of the
corpora). In the medical corpus, out of 612,718
NPs, 12% have multiple premodifiers and 6%
contain solely multiple adjectival premodifiers.
In the WSJ corpus, the percentages are a little
lower, 8% and 2%, respectively. These percent-
ages imply that one in ten NPs contains mul-
tiple premodifiers while one in 25 contains just
multiple adjectives.
Traditionally, linguists study the premodifier
ordering problem using a class-based approach.
Based on a corpus, they propose various se-
mantic classes, such as color, size, or national-
ity, and specify a sequential order among the
classes. However, it is not always clear how
to map premodifiers to these classes, especially
in domain-specific applications. This justifies
the exploration of empirical, corpus-based al-
ternatives, where the ordering between A and
B is determined either from direct prior evi-
dence in the corpus or indirectly through other
words whose relative order to A and B has al-
ready been established. The corpus-based ap-
proach lacks the ontological knowledge used by
linguists, but uses a much larger amount of di-
</bodyText>
<page confidence="0.997995">
135
</page>
<bodyText confidence="0.999915416666667">
rect evidence, provides answers for many more
premodifier orderings, and is portable to differ-
ent domains.
In the next section, we briefly describe prior
linguistic research on this topic. Sections 3 and
4 describe the methodology and corpus used in
our analysis, while the results of our experi-
ments are presented in Section 5. In Section 6,
we demonstrate how we incorporated our or-
dering results in a general text generation sys-
tem. Finally, Section 7 discusses possible im-
provements to our current approach.
</bodyText>
<sectionHeader confidence="0.99827" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.992827806451613">
The order of adjectives (and, by analogy, nom-
inal premodifiers) seems to be outside of the
grammar; it is influenced by factors such as
polarity [Malkiel 1959], scope, and colloca-
tional restrictions [Bache 1978]. Linguists [Goy-
vaerts 1968; Vendler 1968; Quirk and Green-
baum 1973; Bache 1978; Dixon 1982] have per-
formed manual analyses of (small) corpora and
pointed out various tendencies, such as the facts
that underived adjectives often precede derived
adjectives, and shorter modifiers precede longer
ones. Given the difficulty of adequately describ-
ing all factors that influence the order of pre-
modifiers, most earlier work is based on plac-
ing the premodifiers into broad semantic classes,
and specifying an order among these classes.
More than ten classes have been proposed, with
some of them further broken down into sub-
classes. Though not all these studies agree on
the details, they demonstrate that there is fairly
rigid regularity in the ordering of adjectives.
For example, Goyvaerts [1968, p. 27] proposed
the order quality size/length/shape
old/new/young -‹ color nationality -‹
style gerund denominall; Quirk and
Greenbaum [1973, p. 404] the order general
age -&lt; color participle provenance
noun denominal; and Dixon [1982, p.
24] the order value -‹ dimension physical
property speed human propensity -‹ age
-‹ color.
</bodyText>
<footnote confidence="0.990592">
Researchers have also looked at adjective or-
dering across languages [Dixon 1982; Frawley
1992]. Frawley [1992], for example, observed
that English, German, Hungarian, Polish, Turk-
ish, Hindi, Persian, Indonesian, and Basque, all
1Where A B stands for &amp;quot;A precedes B&amp;quot;.
</footnote>
<bodyText confidence="0.998728627906977">
order value before size and both of those before
color.
As with most manual analyses, the corpora
used in these analyses are relatively small com-
pared with modern corpora-based studies. Fur-
thermore, different criteria were used to ar-
rive at the classes. To illustrate, the adjec-
tive &amp;quot;beautiful&amp;quot; can be classified into at least
two different classes because the phrase &amp;quot;beau-
tiful dancer&amp;quot; can be transformed from either the
phrase &amp;quot;dancer who is beautiful&amp;quot;, or &amp;quot;dancer
who dances beautifully&amp;quot;.
Several deep semantic features have been pro-
posed to explain the regularity among the po-
sitional behavior of adjectives. Teyssier [1968]
first proposed that adjectival functions, i.e.
identification, characterization, and classifica-
tion, affect adjective order. Martin [1970] car-
ried out psycholinguistic studies of adjective
ordering. Frawley [1992] extended the work
by Kamp [1975] and proposed that intensional
modifiers precede extensional ones. However,
while these studies offer insights at the complex
phenomenon of adjective ordering, they cannot
be directly mapped to a computational proce-
dure.
On the other hand, recent computational
work on sentence planning [Bateman et al.
1998; Shaw 1998b] indicates that generation re-
search has progressed to a point where hard
problems such as ellipsis, conjunctions, and or-
dering of paradigmatically related constituents
are addressed. Computational corpus stud-
ies related to adjectives were performed by
[Justeson and Katz 1991; Hatzivassiloglou and
McKeown 1993; Hatzivassiloglou and McKeown
1997], but none was directly on the ordering
problem. [Knight and Hatzivassiloglou 1995]
and [Langkilde and Knight 1998] have proposed
models for incorporating statistical information
into a text generation system, an approach that
is similar to our way of using the evidence ob-
tained from corpus in our actual generator.
</bodyText>
<sectionHeader confidence="0.998453" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.999941666666667">
In this section, we discuss how we obtain the
premodifier sequences from the corpus for anal-
ysis and the three approaches we use for estab-
lishing ordering relationships: direct corpus ev-
idence, transitive closure, and clustering analy-
sis. The result of our analysis is embodied in a
</bodyText>
<page confidence="0.998151">
136
</page>
<bodyText confidence="0.999187225">
function, compute_order (A, B), which returns
the sequential ordering between two premodi-
fiers, word A and word B.
To identify orderings among premodifiers,
premodifier sequences are extracted from sim-
plex NPs. A simplex NP is a maximal noun
phrase that includes premodifiers such as de-
terminers and possessives but not post-nominal
constituents such as prepositional phrases or
relative clauses. We use a part-of-speech tag-
ger [Brill 19921 and a finite-state grammar to
extract simplex NPs. The noun phrases we ex-
tract start with an optional determiner (DT) or
possessive pronoun (PRP$), followed by a se-
quence of cardinal numbers (CDs), adjectives
(115), nouns (NNs), and end with a noun. We
include cardinal numbers in NPs to capture the
ordering of numerical information such as age
and amounts. Gerunds (tagged as VBG) or past
participles (tagged as VBN), such as &amp;quot;heated&amp;quot;
in &amp;quot;heated debate&amp;quot;, are considered as adjectives
if the word in front of them is a determiner,
possessive pronoun, or adjective, thus separat-
ing adjectival and verbal forms that are con-
flated by the tagger. A morphology module
transforms plural nouns and comparative and
superlative adjectives into their base forms to
ensure maximization of our frequency counts.
There is a regular expression filter which re-
moves obvious concatenations of simplex NPs
such as &amp;quot;takeover bid last week&amp;quot; and &amp;quot;Tylenol
40 milligrams&amp;quot;.
After simplex NPs are extracted, sequences
of premodifiers are obtained by dropping deter-
miners, genitives, cardinal numbers and head
nouns. Our subsequent analysis operates on the
resulting premodifier sequences, and involves
three stages: direct evidence, transitive closure,
and clustering. We describe each stage in more
detail in the following subsections.
</bodyText>
<subsectionHeader confidence="0.998835">
3.1 Direct Evidence
</subsectionHeader>
<bodyText confidence="0.998560583333333">
Our analysis proceeds on the hypothesis that
the relative order of two premodifiers is fixed
and independent of context. Given two premod-
ifiers A and B, there are three possible under-
lying orderings, and our system should strive
to find which is true in this particular case: ei-
ther A comes before B, B comes before A, or
the order between A and B is truly unimpor-
tant. Our first stage relies on frequency data
collected from a training corpus to predict the
order of adjective and noun premodifiers in an
unseen test corpus.
To collect direct evidence on the order of
premodifiers, we extract all the premodifiers
from the corpus as described in the previous
subsection. We first transform the premodi-
fier sequences into ordered pairs. For example,
the phrase &amp;quot;well-known traditional brand-name
drug&amp;quot; has three ordered pairs, &amp;quot;well-known -&lt;
traditional&amp;quot;, &amp;quot;well-known -&lt; brand-name&amp;quot;, and
&amp;quot;traditional -&lt; brand-name&amp;quot;. A phrase with n
premodifiers will have (n2) ordered pairs. From
these ordered pairs, we construct a wx w matrix
Count, where w the number of distinct modi-
fiers. The cell [A, g in this matrix represents
the number of occurrences of the pair &amp;quot;A -&lt; B&amp;quot;,
in that order, in the corpus.
Assuming that there is a preferred ordering
between premodifiers A and B, one of the cells
Count[A, 13] and Count[B, A] should be much
larger than the other, at least if the corpus be-
comes arbitrarily large. However, given a corpus
of a fixed size there will be many cases where
the frequency counts will both be small. This
data sparseness problem is exacerbated by the
inevitable occurrence of errors during the data
extraction process, which will introduce some
spurious pairs (and orderings) of premodifiers.
We therefore apply probabilistic reasoning to
determine when the data is strong enough to
decide that A -&lt; B or B -‹ A. Under the null
hypothesis that the two premodifiers order is ar-
bitrary, the number of times we have seen one of
them follows the binomial distribution with pa-
rameter p = 0.5. The probability that we would
see the actually observed number of cases with
A -&lt; B, say m, among n pairs involving A and
Bis
</bodyText>
<listItem confidence="0.40756725">
7\1, (n) . pk . (1 _ p ) ( n - k )
4-• k
k=m&apos;
which for the special case p = 0.5 becomes
</listItem>
<equation confidence="0.936228333333333">
NI, (n) . 0.5k . 0.5(n-k) . Ti (n) . 0.5n (2)
k k
k=m k=m
</equation>
<bodyText confidence="0.998294666666667">
If this probability is low, we reject the null hy-
pothesis and conclude that A indeed precedes
(or follows, as indicated by the relative frequen-
</bodyText>
<equation confidence="0.7437355">
cies) B.
(1)
</equation>
<page confidence="0.979352">
137
</page>
<subsectionHeader confidence="0.995628">
3.2 Transitivity
</subsectionHeader>
<bodyText confidence="0.999965122222222">
As we mentioned before, sparse data is a seri-
ous problem in our analysis. For example, the
matrix of frequencies for adjectives in our train-
ing corpus from the medical domain is 99.8%
empty—only 9,106 entries in the 2,232 x 2,232
matrix contain non-zero values. To compen-
sate for this problem, we explore the transi-
tive properties between ordered pairs by com-
puting the transitive closure of the ordering re-
lation. Utilizing transitivity information corre-
sponds to making the inference that A -‹ C fol-
lows from A -‹ B and B C, even if we have no
direct evidence for the pair (A, C) but provided
that there is no contradictory evidence to this
inference either. This approach allows us to fill
from 15% (WSJ) to 30% (medical corpus) of the
entries in the matrix.
To compute the transitive closure of the order
relation, we map our underlying data to special
cases of commutative semirings [Pereira and Ri-
ley 1997]. Each word is represented as a node of
a graph, while arcs between nodes correspond to
ordering relationships and are labeled with ele-
ments from the chosen semiring. This formal-
ism can be used for a variety of problems, us-
ing appropriate definitions of the two binary op-
erators (collection and extension) that operate
on the semiring&apos;s elements. For example, the
all-pairs shortest-paths problem in graph the-
ory can be formulated in a min-plus semiring
over the real numbers with the operators min
for collection and + for extension. Similarly,
finding the transitive closure of a binary relation
can be formulated in a max-min semi-ring or a
or-and semiring over the set {0, 1}. Once the
proper operators have been chosen, the generic
Floyd-Warshall algorithm [Aho et al. 1974] can
solve the corresponding problem without modi-
fications.
We explored three semirings appropriate to
our problem. First, we apply the statistical de-
cision procedure of the previous subsection and
assign to each pair of premodifiers either 0 (if
we don&apos;t have enough information about their
preferred ordering) or 1 (if we do). Then we use
the or-and semiring over the {0,1} set; in the
transitive closure, the ordering A B will be
present if at least one path connecting A and B
via ordered pairs exists. Note that it is possible
for both A B and B -&lt; A to be present in the
transitive closure.
This model involves conversions of the corpus
evidence for each pair into hard decisions on
whether one of the words in the pair precedes
the other. To avoid such early commitments,
we use a second, refined model for transitive
closure where the arc from A to B is labeled
with the probability that A precedes indeed B.
The natural extension of the ({0, 1}, or, and)
semiring when the set of labels is replaced with
the interval [0, 1] is then ([0, 1], max, min).
We estimate the probability that A precedes B
as one minus the probability of reaching that
conclusion in error, according to the statistical
test of the previous subsection (i.e., one minus
the sum specified in equation (2). We obtained
similar results with this estimator and with the
maximal likelihood estimator (the ratio of the
number of times A appeared before B to the
total number of pairs involving A and B).
Finally, we consider a third model in which
we explore an alternative to transitive closure.
Rather than treating the number attached to
each arc as a probability, we treat it as a cost,
the cost of erroneously assuming that the corre-
sponding ordering exists. We assign to an edge
(A, B) the negative logarithm of the probability
that A precedes B; probabilities are estimated
as in the previous paragraph. Then our prob-
lem becomes identical to the all-pairs shortest-
path problem in graph theory; the correspond-
ing semiring is ((0, +oo), min, +). We use log-
arithms to address computational precision is-
sues stemming from the multiplication of small
probabilities, and negate the logarithms so that
we cast the problem as a minimization task (i.e.,
we find the path in the graph the minimizes
the total sum of negative log probabilities, and
therefore maximizes the product of the original
probabilities).
</bodyText>
<subsectionHeader confidence="0.998313">
3.3 Clustering
</subsectionHeader>
<bodyText confidence="0.9999852">
As noted earlier, earlier linguistic work on
the ordering problem puts words into seman-
tic classes and generalizes the task from order-
ing between specific words to ordering the cor-
responding classes. We follow a similar, but
evidence-based, approach for the pairs of words
that neither direct evidence nor transitivity can
resolve. We compute an order similarity mea-
sure between any two premodifiers, reflecting
whether the two words share the same pat-
</bodyText>
<page confidence="0.99364">
138
</page>
<bodyText confidence="0.998981255813953">
tern of relative order with other premodifiers
for which we have sufficient evidence. For each
pair of premodifiers A and B, we examine ev-
ery other premodifier in the corpus, X; if both
A -‹ X and B -&lt; X, or both A ›- X and B ›- X,
one point is added to the similarity score be-
tween A and B. If on the other hand A -‹ X and
B X, or A X and B -‹ X, one point is sub-
tracted. X does not contribute to the similarity
score if there is not sufficient prior evidence for
the relative order of X and A, or of X and B.
This procedure closely parallels non-parametric
distributional tests such as Kendall&apos;s T [Kendall
1938].
The similarity scores are then converted into
dissimilarities and fed into a non-hierarchical
clustering algorithm [Spath 1985], which sep-
arates the premodifiers in groups. This is
achieved by minimizing an objective function,
defined as the sum of within-group dissimilari-
ties over all groups. In this manner, premodi-
fiers that are closely similar in terms of sharing
the same relative order with other premodifiers
are placed in the same group.
Once classes of premodifiers have been in-
duced, we examine every pair of classes and de-
cide which precedes the other. For two classes
C1 and C2, we extract all pairs of premodifiers
(x,y) with x E C1 and y E C2. If we have evi-
dence (either direct or through transitivity) that
x y, one point is added in favor of C1 C2i
similarly, one point is subtracted if x y. After
all such pairs have been considered, we can then
predict the relative order between words in the
two clusters which we haven&apos;t seen together ear-
lier. This method makes (weak) predictions for
any pair (A, B) of words, except if (a) both A
and B are placed in the same cluster; (b) no or-
dered pairs (x, y) with one element in the class
of A and one in the class of B have been identi-
fied; or (c) the evidence for one class preceding
the other is in the aggregate equally strong in
both directions.
</bodyText>
<sectionHeader confidence="0.995836" genericHeader="method">
4 The Corpus
</sectionHeader>
<bodyText confidence="0.999985684210527">
We used two corpora for our analysis: hospi-
tal discharge summaries from 1991 to 1997 from
the Columbia-Presbyterian Medical Center, and
the January 1996 part of the Wall Street Jour-
nal corpus from the Penn TreeBank [Marcus et
al. 1993]. To facilitate comparisons across the
two corpora, we intentionally limited ourselves
to only one month of the WSJ corpus, so that
approximately the same amount of data would
be examined in each case. The text in each cor-
pus is divided into a training part (2.3 million
words for the medical corpus and 1.5 million
words for the WSJ) and a test part (1.2 million
words for the medical corpus and 1.6 million
words for the WSJ).
All domain-specific markup was removed, and
the text was processed by the MXTERMINATOR
sentence boundary detector [Reynar and Rat-
naparkhi 1997] and Brill&apos;s part-of-speech tag-
ger [Brill 1992]. Noun phrases and pairs of pre-
modifiers were extracted from the tagged corpus
according to the methods of Section 3. From
the medical corpus, we retrieved 934,823 sim-
plex NPs, of which 115,411 have multiple pre-
modifiers and 53,235 multiple adjectives only.
The corresponding numbers for the WSJ cor-
pus were 839,921 NPs, 68,153 NPs with multiple
premodifiers, and 16,325 NPs with just multiple
adjectives.
We separately analyze two groups of premodi-
fiers: adjectives, and adjectives plus nouns mod-
ifying the head noun. Although our techniques
are identical in both cases, the division is moti-
vated by our expectation that the task will be
easier when modifiers are limited to adjectives,
because nouns tend to be harder to match cor-
rectly with our finite-state grammar and the in-
put data is sparser for nouns.
</bodyText>
<sectionHeader confidence="0.999799" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.999971882352941">
We applied the three ordering algorithms pro-
posed in this paper to the two corpora sepa-
rately for adjectives and adjectives plus nouns.
For our first technique of directly using evidence
from a separate training corpus, we filled the
Count matrix (see Section 3.1) with the fre-
quencies of each ordering for each pair of pre-
modifiers using the training corpora. Then, we
calculated which of those pairs correspond to a
true underlying order relation, i.e., pass the sta-
tistical test of Section 3.1 with the probability
given by equation (2) less than or equal to 50%.
We then examined each instance of ordered pre-
modifiers in the corresponding test corpus, and
counted how many of those the direct evidence
method could predict correctly. Note that if A
and B occur sometimes as A -‹ B and some-
</bodyText>
<page confidence="0.996913">
139
</page>
<table confidence="0.999347833333333">
Corpus Test Direct evidence Transitivity Transitivity
pairs (max-min) (min-plus)
Medical/ 27,670 92.67% (88.20%-98.47%) 89.60% (94.94%-91.79%) 94.93% (97.20%-96.16%)
adjectives
Financial/ 9,925 75.41% (53.85%-98.37%) 79.92% (72.76%-90.79%) 80.77% (76.36%-90.18%)
adjectives
Medical/ 74,664 88.79% (80.38%-98.35%) 87.69% (90.86%-91.50%) 90.67% (91.90%-94.27%)
adjectives
and nouns
Financial/ 62,383 65.93% (35.76%-95.27%) 69.61% (56.63%-84.51%) 71.04% (62.48%-83.55%)
adjectives
and nouns
</table>
<tableCaption confidence="0.999189">
Table 1: Accuracy of direct-evidence and transitivity methods on different data strata of our test
</tableCaption>
<bodyText confidence="0.99590123943662">
corpora. In each case, overall accuracy is listed first in bold, and then, in parentheses, the percentage
of the test pairs that the method has an opinion for (rather than randomly assign a decision because
of lack of evidence) and the accuracy of the method within that subset of test cases.
times as B A, no prediction method can get
all those instances correct. We elected to follow
this evaluation approach, which lowers the ap-
parent scores of our method, rather than forcing
each pair in the test corpus to one unambiguous
category (A -‹ B, B -‹ A, or arbitrary).
Under this evaluation method, stage one of
our system achieves on adjectives in the medi-
cal domain 98.47% correct decisions on pairs for
which a determination of order could be made.
Since 11.80% of the total pairs in the test corpus
involve previously unseen combinations of ad-
jectives and/or new adjectives, the overall accu-
racy is 92.67%. The corresponding accuracy on
data for which we can make a prediction and the
overall accuracy is 98.35% and 88.79% for adjec-
tives plus nouns in the medical domain, 98.37%
and 75.41% for adjectives in the WSJ data, and
95.27% and 65.93% for adjectives plus nouns in
the WSJ data. Note that the WSJ corpus is
considerably more sparse, with 64.24% unseen
combinations of adjective and noun premodi-
fiers in the test part. Using lower thresholds
in equation (2) results in a lower percentage of
cases for which the system has an opinion but a
higher accuracy for those decisions. For exam-
ple, a threshold of 25% results in the ability to
predict 83.72% of the test adjective pairs in the
medical corpus with 99.01% accuracy for these
cases.
We subsequently applied the transitivity
stage, testing the three semiring models dis-
cussed in Section 3.2. Early experimentation
indicated that the or-and model performed
poorly, which we attribute to the extensive
propagation of decisions (once a decision in fa-
vor of the existence of an ordering relationship is
made, it cannot be revised even in the presence
of conflicting evidence). Therefore we report re-
sults below for the other two semiring models.
Of those, the rain-plus semiring achieved higher
performance. That model offers additional pre-
dictions for 9.00% of adjective pairs and 11.52%
of adjective-plus-noun pairs in the medical cor-
pus, raising overall accuracy of our predictions
to 94.93% and 90.67% respectively. Overall ac-
curacy in the WSJ test data was 80.77% for ad-
jectives and 71.04% for adjectives plus nouns.
Table 1 summarizes the results of these two
stages.
Finally, we applied our third, clustering ap-
proach on each data stratum. Due to data
sparseness and computational complexity is-
sues, we clustered the most frequent words in
each set of premodifiers (adjectives or adjectives
plus nouns), selecting those that occurred at
least 50 times in the training part of the cor-
pus being analyzed. We report results for the
adjectives selected in this manner (472 frequent
adjectives from the medical corpus and 307 ad-
jectives from the WSJ corpus). For these words,
the information collected by the first two stages
of the system covers most pairs. Out of the
111,176 (=472.471/2) possible pairs in the med-
ical data, the direct evidence and transitivity
stages make predictions for 105,335 (94.76%);
the corresponding number for the WSJ data is
40,476 out of 46,971 possible pairs (86.17%).
</bodyText>
<page confidence="0.99261">
140
</page>
<bodyText confidence="0.999931195652174">
The clustering technique makes ordering pre-
dictions for a part of the remaining pairs—on
average, depending on how many clusters are
created, this method produces answers for 80%
of the ordering cases that remained unanswered
after the first two stages in the medical corpus,
and for 54% of the unanswered cases in the WSJ
corpus. Its accuracy on these predictions is 56%
on the medical corpus, and slightly worse than
the baseline 50% on the WSJ corpus; this lat-
ter, aberrant result is due to a single, very fre-
quent pair, chief executive, in which executive
is consistently mistagged as an adjective by the
part-of-speech tagger.
Qualitative analysis of the third stage&apos;s out-
put indicates that it identifies many interest-
ing relationships between premodifiers; for ex-
ample, the pair of most similar premodifiers on
the basis of positional information is left and
right, which clearly fall in a class similar to the
semantic classes manually constructed by lin-
guists. Other sets of adjectives with strongly
similar members include {mild, severe, signifi-
cant} and {cardiac, pulmonary, respiratory}.
We conclude our empirical analysis by test-
ing whether a separate model is needed for pre-
dicting adjective order in each different domain.
We trained the first two stages of our system
on the medical corpus and tested them on the
WSJ corpus, obtaining an overall prediction ac-
curacy of 54% for adjectives and 52% for adjec-
tives plus nouns. Similar results were obtained
when we trained on the financial domain and
tested on medical data (58% and 56%). These
results are not much better than what would
have been obtained by chance, and are clearly
inferior to those reported in Table 1. Although
the two corpora share a large number of ad-
jectives (1,438 out of 5,703 total adjectives in
the medical corpus and 8,240 in the WSJ cor-
pus), they share only 2 to 5% of the adjective
pairs. This empirical evidence indicates that ad-
jectives are used differently in the two domains,
and hence domain-specific probabilities must be
estimated, which increases the value of an au-
tomated procedure for the prediction task.
</bodyText>
<sectionHeader confidence="0.678947" genericHeader="method">
6 Using Ordered Premodifiers in
Text Generation
</sectionHeader>
<bodyText confidence="0.9763875">
Extracting sequential ordering information of
premodifiers is an off-line process, the results of
</bodyText>
<listItem confidence="0.7157056">
(a) &amp;quot;John is a diabetic male white 74-
year-old hypertensive patient
with a red swollen mass in the
left groin.&amp;quot;
(b) &amp;quot;John is a 74-year-old
</listItem>
<bodyText confidence="0.666082666666667">
hypertensive diabetic white male
patient with a swollen red mass
in the left groin.&amp;quot;
</bodyText>
<figureCaption confidence="0.874419">
Figure 1: (a) Output of the generator without
our ordering module, containing several errors.
(b) Output of the generator with our ordering
module.
</figureCaption>
<bodyText confidence="0.996985833333333">
which can be easily incorporated into the over-
all generation architecture. We have integrated
the function compute_order(A,B) into our mul-
timedia presentation system MAGIC [Dalal et
al. 1996] in the medical domain and resolved
numerous premodifier ordering tasks correctly.
Example cases where the statistical prediction
module was helpful in producing a more fluent
description in MAGIC include placing age infor-
mation before ethnicity information and the lat-
ter before gender information, as well as spe-
cific ordering preferences, such as &amp;quot;thick&amp;quot; before
&amp;quot;yellow&amp;quot; and &amp;quot;acute&amp;quot; before &amp;quot;severe&amp;quot;. mAGIc&apos;s
output is being evaluated by medical doctors,
who provide us with feedback on different com-
ponents of the system, including the fluency of
the generated text and its similarity to human-
produced reports.
Lexicalization is inherently domain depen-
dent, so traditional lexica cannot be ported
across domains without major modifications.
Our approach, in contrast, is based on words
extracted from a domain corpus and not on
concepts, therefore it can be easily applied to
new domains. In our MAGIC system, aggre-
gation operators, such as conjunction, ellip-
sis, and transformations of clauses to adjectival
phrases and relative clauses, are performed to
combine related clauses together and increase
conciseness [Shaw 1998a; Shaw 199813]. We
wrote a function, reorder_premod( ), which is
called after the aggregation operators, takes the
whole lexicalized semantic representation, and
reorders the premodifiers right before the lin-
guistic realizer is invoked. Figure 1 shows the
difference in the output produced by our gener-
</bodyText>
<page confidence="0.995011">
141
</page>
<bodyText confidence="0.854076">
ator with and without the ordering component.
</bodyText>
<sectionHeader confidence="0.967942" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999992111111111">
We have presented three techniques for explor-
ing prior corpus evidence in predicting the order
of premodifiers within noun phrases. Our meth-
ods expand on observable data, by inferring
new relationships between premodifiers even for
combinations of premodifiers that do not occur
in the training corpus. We have empirically val-
idated our approach, showing that we can pre-
dict order with more than 94% accuracy when
enough corpus data is available. We have also
implemented our procedure in a text generator,
producing more fluent output sentences.
We are currently exploring alternative ways
to integrate the classes constructed by the third
stage of our system into our generator. In
the future, we will experiment with semantic
(rather than positional) clustering of premodi-
fiers, using techniques such as those proposed in
[Hatzivassiloglou and McKeown 1993; Pereira et
al. 19931. The qualitative analysis of the output
of our clustering module shows that frequently
positional and semantic classes overlap, and we
are interested in measuring the extent of this
phenomenon quantitatively. Conditioning the
premodifier ordering on the head noun is an-
other promising approach, at least for very fre-
quent nouns.
</bodyText>
<sectionHeader confidence="0.995775" genericHeader="acknowledgments">
8 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999968692307692">
We are grateful to Kathy McKeown for numer-
ous discussions during the development of this
work. The research is supported in part by
the National Library of Medicine under grant
R01-LM06593-01 and the Columbia University
Center for Advanced Technology in High Per-
formance Computing and Communications in
Healthcare (funded by the New York State Sci-
ence and Technology Foundation). Any opin-
ions, findings, or recommendations expressed in
this paper are those of the authors and do not
necessarily reflect the views of the above agen-
cies.
</bodyText>
<sectionHeader confidence="0.995558" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998262734693878">
Alfred V. Aho, John E. Hoperoft, and Jeffrey D.
Ullman. The Design and Analysis of Com-
puter Algorithms. Addison-Wesley, Reading,
Massachusetts, 1974.
Carl Bache. The Order of Premodifying Adjec-
tives in Present-Day English. Odense Univer-
sity Press, 1978.
John A. Bateman, Thomas Kamps, Jorg Kleinz,
and Klaus Reichenberger. Communicative
Goal-Driven NL Generation and Data-Driven
Graphics Generation: An Architectural Syn-
thesis for Multimedia Page Generation. In
Proceedings of the 9th International Work-
shop on Natural Language Generation., pages
8-17, 1998.
Eric Brill. A Simple Rule-Based Part of Speech
Tagger. In Proceedings of the Third Confer-
ence on Applied Natural Language Process-
ing, Trento, Italy, 1992. Association for Com-
putational Linguistics.
Mukesh Dalal, Steven K. Feiner, Kathleen R.
McKeown, Desmond A. Jordan, Barry Allen,
and Yasser al Safadi. MAGIC: An Exper-
imental System for Generating Multimedia
Briefings about Post-Bypass Patient Status.
In Proceedings of the 1996 Annual Fall Sym-
posium of the American Medical Informat-
ics Association (AMIA-96), pages 684-688,
Washington, D.C., October 26-30 1996.
R. M. W. Dixon. Where Have All the Adjectives
Gone? Mouton, New York, 1982.
William Frawley. Linguistic Semantics.
Lawrence Erlbaum Associates, Hillsdale, New
Jersey, 1992.
D. L. Goyvaerts. An Introductory Study on the
Ordering of a String of Adjectives in Present-
Day English. Philologica Pragensia, 11:12-
28, 1968.
Ralph Grishman, Catherine Macleod, and
Adam Meyers. COMLEX Syntax: Building
a Computational Lexicon. In Proceedings of
the 15th International Conference on Com-
putational Linguistics (COLING-94), Kyoto,
Japan, 1994.
Vasileios Hatzivassiloglou and Kathleen McKe-
own. Towards the Automatic Identification of
Adjectival Scales: Clustering Adjectives Ac-
cording to Meaning. In Proceedings of the
31st Annual Meeting of the ACL, pages 172-
</reference>
<page confidence="0.978247">
142
</page>
<reference confidence="0.999863819148937">
182, Columbus, Ohio, June 1993. Association
for Computational Linguistics.
Vasileios Hatzivassiloglou and Kathleen McKe-
own. Predicting the Semantic Orientation of
Adjectives. In Proceedings of the 35th Annual
Meeting of the ACL, pages 174-181, Madrid,
Spain, July 1997. Association for Computa-
tional Linguistics.
John S. Justeson and Slava M. Katz. Co-
occurrences of Antonymous Adjectives and
Their Contexts. Computational Linguistics,
17(1):1-19, 1991.
J. A. W. Kamp. Two Theories of Adjectives.
In E. L. Keenan, editor, Formal Semantics
of Natural Language. Cambridge University
Press, Cambridge, England, 1975.
Maurice G. Kendall. A New Measure of
Rank Correlation. Biometrika, 30(1-2):81—
93, June 1938.
Kevin Knight and Vasileios Hatzivassiloglou.
Two-Level, Many-Paths Generation. In Pro-
ceedings of the 33rd Annual Meeting of the
A CL, pages 252-260, Boston, Massachusetts,
June 1995. Association for Computational
Linguistics.
Irene Langkilde and Kevin Knight. Genera-
tion that Exploits Corpus-Based Statistical
Knowledge. In Proceedings of the 36th An-
nual Meeting of the ACL and the 17th Inter-
national Conference on Computational Lin-
guistics (ACL/COLING-98), pages 704-710,
Montreal, Canada, 1998.
Yakov Malkiel. Studies in Irreversible Bino-
mials. Lingua, 8(2):113-160, May 1959.
Reprinted in [Malkiel 19681.
Yakov Malkiel. Essays on Linguistic Themes.
Blackwell, Oxford, 1968.
Mitchell P. Marcus, Beatrice Santorini, and
Mary Ann Marcinkiewicz. Building a large
annotated corpus of English: The Penn Tree-
bank. Computational Linguistics, 19:313-
330, 1993.
J. E. Martin. Adjective Order and Juncture.
Journal of Verbal Learning and Verbal Behav-
ior, 9:379-384, 1970.
George A. Miller, Richard Beckwith, Christiane
Fellbaum, Derek Gross, and Katherine J.
Miller. Introduction to WordNet: An On-
Line Lexical Database. International Journal
of Lexicography (special issue), 3(4):235-312,
1990.
Fernando C. N. Pereira and Michael D. Ri-
ley. Speech Recognition by Composition of
Weighted Finite Automata. In Emmanuel
Roche and Yves Schabes, editors, Finite-
State Language Processing, pages 431-453.
MIT Press, Cambridge, Massachusetts, 1997.
Fernando Pereira, Naftali Tishby, and Lillian
Lee. Distributional Clustering of English
Words. In Proceedings of the 31st Annual
Meeting of the ACL, pages 183-190, Colum-
bus, Ohio, June 1993. Association for Com-
putational Linguistics.
Randolph Quirk and Sidney Greenbaum. A
Concise Grammar of Contemporary English.
Harcourt Brace Jovanovich, Inc., London,
1973.
Jeffrey C. Reynar and Adwait Ratnaparkhi. A
Maximum Entropy Approach to Identifying
Sentence Boundaries. In Proc. of the 5th Ap-
plied Natural Language Conference (ANLP-
97), Washington, D.C., April 1997.
James Shaw. Clause Aggregation Using Lin-
guistic Knowledge. In Proceedings of the 9th
International Workshop on Natural Language
Generation., pages 138-147, 1998.
James Shaw. Segregatory Coordination and El-
lipsis in Text Generation. In Proceedings of
the 36th Annual Meeting of the ACL and the
17th International Conference on Computa-
tional Linguistics (ACL/COLING-98), pages
1220-1226, Montreal, Canada, 1998.
Helmuth Spath. Cluster Dissection and Anal-
ysis: Theory, FORTRAN Programs, Exam-
ples. Ellis Horwood, Chichester, England,
1985.
J. Teyssier. Notes on the Syntax of the Adjec-
tive in Modern English. Behavioral Science,
20:225-249, 1968.
Zeno Vendler. Adjectives and Nom,inalizations.
Mouton and Co., The Netherlands, 1968.
Benjamin Lee Whorf. Language, Thought, and
Reality; Selected Writings. MIT Press, Cam-
bridge, Massachusetts, 1956.
</reference>
<page confidence="0.999133">
143
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.487834">
<title confidence="0.999881">Ordering Among Premodifiers</title>
<author confidence="0.99995">Shaw Hatzivassiloglou</author>
<affiliation confidence="0.999895">Department of Computer Science Columbia University</affiliation>
<address confidence="0.998884">New York, N.Y. 10027, USA</address>
<email confidence="0.497447">shawOcscolumbiaedu</email>
<email confidence="0.497447">vhOcscolumbiaedu</email>
<abstract confidence="0.99829825">present corpus-based study of the sequential ordering among premodifiers in noun phrases. This information is important for the fluency of generated text in practical applications. We propose and evaluate three approaches to identify sequential order among premodifiers: direct evidence, transitive closure, and clustering. Our implemented system can make over 94% of such ordering decisions correctly, as evaluated on a large, previously unseen test corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>John E Hoperoft</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>The Design and Analysis of Computer Algorithms.</title>
<date>1974</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Massachusetts,</location>
<contexts>
<context position="13873" citStr="Aho et al. 1974" startWordPosition="2240" endWordPosition="2243">ng. This formalism can be used for a variety of problems, using appropriate definitions of the two binary operators (collection and extension) that operate on the semiring&apos;s elements. For example, the all-pairs shortest-paths problem in graph theory can be formulated in a min-plus semiring over the real numbers with the operators min for collection and + for extension. Similarly, finding the transitive closure of a binary relation can be formulated in a max-min semi-ring or a or-and semiring over the set {0, 1}. Once the proper operators have been chosen, the generic Floyd-Warshall algorithm [Aho et al. 1974] can solve the corresponding problem without modifications. We explored three semirings appropriate to our problem. First, we apply the statistical decision procedure of the previous subsection and assign to each pair of premodifiers either 0 (if we don&apos;t have enough information about their preferred ordering) or 1 (if we do). Then we use the or-and semiring over the {0,1} set; in the transitive closure, the ordering A B will be present if at least one path connecting A and B via ordered pairs exists. Note that it is possible for both A B and B -&lt; A to be present in the transitive closure. Th</context>
</contexts>
<marker>Aho, Hoperoft, Ullman, 1974</marker>
<rawString>Alfred V. Aho, John E. Hoperoft, and Jeffrey D. Ullman. The Design and Analysis of Computer Algorithms. Addison-Wesley, Reading, Massachusetts, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Bache</author>
</authors>
<title>The Order of Premodifying Adjectives in Present-Day English.</title>
<date>1978</date>
<publisher>Odense University Press,</publisher>
<contexts>
<context position="4404" citStr="Bache 1978" startWordPosition="697" endWordPosition="698"> we briefly describe prior linguistic research on this topic. Sections 3 and 4 describe the methodology and corpus used in our analysis, while the results of our experiments are presented in Section 5. In Section 6, we demonstrate how we incorporated our ordering results in a general text generation system. Finally, Section 7 discusses possible improvements to our current approach. 2 Related Work The order of adjectives (and, by analogy, nominal premodifiers) seems to be outside of the grammar; it is influenced by factors such as polarity [Malkiel 1959], scope, and collocational restrictions [Bache 1978]. Linguists [Goyvaerts 1968; Vendler 1968; Quirk and Greenbaum 1973; Bache 1978; Dixon 1982] have performed manual analyses of (small) corpora and pointed out various tendencies, such as the facts that underived adjectives often precede derived adjectives, and shorter modifiers precede longer ones. Given the difficulty of adequately describing all factors that influence the order of premodifiers, most earlier work is based on placing the premodifiers into broad semantic classes, and specifying an order among these classes. More than ten classes have been proposed, with some of them further br</context>
</contexts>
<marker>Bache, 1978</marker>
<rawString>Carl Bache. The Order of Premodifying Adjectives in Present-Day English. Odense University Press, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bateman</author>
<author>Thomas Kamps</author>
<author>Jorg Kleinz</author>
<author>Klaus Reichenberger</author>
</authors>
<title>Communicative Goal-Driven NL Generation and Data-Driven Graphics Generation: An Architectural Synthesis for Multimedia Page Generation.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th International Workshop on Natural Language Generation.,</booktitle>
<pages>8--17</pages>
<contexts>
<context position="6976" citStr="Bateman et al. 1998" startWordPosition="1087" endWordPosition="1090">rity among the positional behavior of adjectives. Teyssier [1968] first proposed that adjectival functions, i.e. identification, characterization, and classification, affect adjective order. Martin [1970] carried out psycholinguistic studies of adjective ordering. Frawley [1992] extended the work by Kamp [1975] and proposed that intensional modifiers precede extensional ones. However, while these studies offer insights at the complex phenomenon of adjective ordering, they cannot be directly mapped to a computational procedure. On the other hand, recent computational work on sentence planning [Bateman et al. 1998; Shaw 1998b] indicates that generation research has progressed to a point where hard problems such as ellipsis, conjunctions, and ordering of paradigmatically related constituents are addressed. Computational corpus studies related to adjectives were performed by [Justeson and Katz 1991; Hatzivassiloglou and McKeown 1993; Hatzivassiloglou and McKeown 1997], but none was directly on the ordering problem. [Knight and Hatzivassiloglou 1995] and [Langkilde and Knight 1998] have proposed models for incorporating statistical information into a text generation system, an approach that is similar to </context>
</contexts>
<marker>Bateman, Kamps, Kleinz, Reichenberger, 1998</marker>
<rawString>John A. Bateman, Thomas Kamps, Jorg Kleinz, and Klaus Reichenberger. Communicative Goal-Driven NL Generation and Data-Driven Graphics Generation: An Architectural Synthesis for Multimedia Page Generation. In Proceedings of the 9th International Workshop on Natural Language Generation., pages 8-17, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>A Simple Rule-Based Part of Speech Tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the Third Conference on Applied Natural Language Processing,</booktitle>
<location>Trento, Italy,</location>
<contexts>
<context position="8392" citStr="Brill 1992" startWordPosition="1305" endWordPosition="1306">aches we use for establishing ordering relationships: direct corpus evidence, transitive closure, and clustering analysis. The result of our analysis is embodied in a 136 function, compute_order (A, B), which returns the sequential ordering between two premodifiers, word A and word B. To identify orderings among premodifiers, premodifier sequences are extracted from simplex NPs. A simplex NP is a maximal noun phrase that includes premodifiers such as determiners and possessives but not post-nominal constituents such as prepositional phrases or relative clauses. We use a part-of-speech tagger [Brill 19921 and a finite-state grammar to extract simplex NPs. The noun phrases we extract start with an optional determiner (DT) or possessive pronoun (PRP$), followed by a sequence of cardinal numbers (CDs), adjectives (115), nouns (NNs), and end with a noun. We include cardinal numbers in NPs to capture the ordering of numerical information such as age and amounts. Gerunds (tagged as VBG) or past participles (tagged as VBN), such as &amp;quot;heated&amp;quot; in &amp;quot;heated debate&amp;quot;, are considered as adjectives if the word in front of them is a determiner, possessive pronoun, or adjective, thus separating adjectival and v</context>
<context position="19524" citStr="Brill 1992" startWordPosition="3241" endWordPosition="3242">ilitate comparisons across the two corpora, we intentionally limited ourselves to only one month of the WSJ corpus, so that approximately the same amount of data would be examined in each case. The text in each corpus is divided into a training part (2.3 million words for the medical corpus and 1.5 million words for the WSJ) and a test part (1.2 million words for the medical corpus and 1.6 million words for the WSJ). All domain-specific markup was removed, and the text was processed by the MXTERMINATOR sentence boundary detector [Reynar and Ratnaparkhi 1997] and Brill&apos;s part-of-speech tagger [Brill 1992]. Noun phrases and pairs of premodifiers were extracted from the tagged corpus according to the methods of Section 3. From the medical corpus, we retrieved 934,823 simplex NPs, of which 115,411 have multiple premodifiers and 53,235 multiple adjectives only. The corresponding numbers for the WSJ corpus were 839,921 NPs, 68,153 NPs with multiple premodifiers, and 16,325 NPs with just multiple adjectives. We separately analyze two groups of premodifiers: adjectives, and adjectives plus nouns modifying the head noun. Although our techniques are identical in both cases, the division is motivated b</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Eric Brill. A Simple Rule-Based Part of Speech Tagger. In Proceedings of the Third Conference on Applied Natural Language Processing, Trento, Italy, 1992. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MAGIC</author>
</authors>
<title>An Experimental System for Generating Multimedia Briefings about Post-Bypass Patient Status.</title>
<date>1996</date>
<booktitle>In Proceedings of the 1996 Annual Fall Symposium of the American Medical Informatics Association (AMIA-96),</booktitle>
<pages>684--688</pages>
<location>Washington, D.C.,</location>
<marker>MAGIC, 1996</marker>
<rawString>Mukesh Dalal, Steven K. Feiner, Kathleen R. McKeown, Desmond A. Jordan, Barry Allen, and Yasser al Safadi. MAGIC: An Experimental System for Generating Multimedia Briefings about Post-Bypass Patient Status. In Proceedings of the 1996 Annual Fall Symposium of the American Medical Informatics Association (AMIA-96), pages 684-688, Washington, D.C., October 26-30 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M W Dixon</author>
</authors>
<title>Where Have All the Adjectives Gone?</title>
<date>1982</date>
<location>Mouton, New York,</location>
<contexts>
<context position="4496" citStr="Dixon 1982" startWordPosition="712" endWordPosition="713">methodology and corpus used in our analysis, while the results of our experiments are presented in Section 5. In Section 6, we demonstrate how we incorporated our ordering results in a general text generation system. Finally, Section 7 discusses possible improvements to our current approach. 2 Related Work The order of adjectives (and, by analogy, nominal premodifiers) seems to be outside of the grammar; it is influenced by factors such as polarity [Malkiel 1959], scope, and collocational restrictions [Bache 1978]. Linguists [Goyvaerts 1968; Vendler 1968; Quirk and Greenbaum 1973; Bache 1978; Dixon 1982] have performed manual analyses of (small) corpora and pointed out various tendencies, such as the facts that underived adjectives often precede derived adjectives, and shorter modifiers precede longer ones. Given the difficulty of adequately describing all factors that influence the order of premodifiers, most earlier work is based on placing the premodifiers into broad semantic classes, and specifying an order among these classes. More than ten classes have been proposed, with some of them further broken down into subclasses. Though not all these studies agree on the details, they demonstra</context>
</contexts>
<marker>Dixon, 1982</marker>
<rawString>R. M. W. Dixon. Where Have All the Adjectives Gone? Mouton, New York, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Frawley</author>
</authors>
<title>Linguistic Semantics. Lawrence Erlbaum Associates,</title>
<date>1992</date>
<location>Hillsdale, New Jersey,</location>
<contexts>
<context position="5621" citStr="Frawley 1992" startWordPosition="886" endWordPosition="887">down into subclasses. Though not all these studies agree on the details, they demonstrate that there is fairly rigid regularity in the ordering of adjectives. For example, Goyvaerts [1968, p. 27] proposed the order quality size/length/shape old/new/young -‹ color nationality -‹ style gerund denominall; Quirk and Greenbaum [1973, p. 404] the order general age -&lt; color participle provenance noun denominal; and Dixon [1982, p. 24] the order value -‹ dimension physical property speed human propensity -‹ age -‹ color. Researchers have also looked at adjective ordering across languages [Dixon 1982; Frawley 1992]. Frawley [1992], for example, observed that English, German, Hungarian, Polish, Turkish, Hindi, Persian, Indonesian, and Basque, all 1Where A B stands for &amp;quot;A precedes B&amp;quot;. order value before size and both of those before color. As with most manual analyses, the corpora used in these analyses are relatively small compared with modern corpora-based studies. Furthermore, different criteria were used to arrive at the classes. To illustrate, the adjective &amp;quot;beautiful&amp;quot; can be classified into at least two different classes because the phrase &amp;quot;beautiful dancer&amp;quot; can be transformed from either the phras</context>
</contexts>
<marker>Frawley, 1992</marker>
<rawString>William Frawley. Linguistic Semantics. Lawrence Erlbaum Associates, Hillsdale, New Jersey, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Goyvaerts</author>
</authors>
<title>An Introductory Study on the Ordering of a String of Adjectives</title>
<date>1968</date>
<booktitle>in PresentDay English. Philologica Pragensia,</booktitle>
<pages>11--12</pages>
<contexts>
<context position="4432" citStr="Goyvaerts 1968" startWordPosition="700" endWordPosition="702">or linguistic research on this topic. Sections 3 and 4 describe the methodology and corpus used in our analysis, while the results of our experiments are presented in Section 5. In Section 6, we demonstrate how we incorporated our ordering results in a general text generation system. Finally, Section 7 discusses possible improvements to our current approach. 2 Related Work The order of adjectives (and, by analogy, nominal premodifiers) seems to be outside of the grammar; it is influenced by factors such as polarity [Malkiel 1959], scope, and collocational restrictions [Bache 1978]. Linguists [Goyvaerts 1968; Vendler 1968; Quirk and Greenbaum 1973; Bache 1978; Dixon 1982] have performed manual analyses of (small) corpora and pointed out various tendencies, such as the facts that underived adjectives often precede derived adjectives, and shorter modifiers precede longer ones. Given the difficulty of adequately describing all factors that influence the order of premodifiers, most earlier work is based on placing the premodifiers into broad semantic classes, and specifying an order among these classes. More than ten classes have been proposed, with some of them further broken down into subclasses. T</context>
</contexts>
<marker>Goyvaerts, 1968</marker>
<rawString>D. L. Goyvaerts. An Introductory Study on the Ordering of a String of Adjectives in PresentDay English. Philologica Pragensia, 11:12-28, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>Catherine Macleod</author>
<author>Adam Meyers</author>
</authors>
<title>COMLEX Syntax: Building a Computational Lexicon.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics (COLING-94),</booktitle>
<location>Kyoto, Japan,</location>
<contexts>
<context position="1559" citStr="Grishman et al. 1994" startWordPosition="238" endWordPosition="241">dering of adjectives have already been noted by linguists [Whorf 1956; Vendler 19681. During the process of generating complex sentences by combining multiple clauses, there are situations where multiple adjectives or nouns modify the same head noun. The text generation system must order these modifiers in a similar way as domain experts use them to ensure fluency of the text. For example, the description of the age of a patient precedes his ethnicity and gender in medical domain as in &amp;quot;a 50 year-old white female patient&amp;quot;. Yet, general lexicons such as WordNet [Miller et al. 19901 and COMLEX [Grishman et al. 1994], do not store such information. In this paper, we present automated techniques for addressing this problem of determining, given two premodifiers A and B, the preferred ordering between them. Our methods rely on and generalize empirical evidence obtained from large corpora, and are evaluated objectively on such corpora. They are informed and motivated by our practical need for ordering multiple premodifiers in the MAGIC system [Dalal et al. 1996]. MAGIC utilizes co-ordinated text, speech, and graphics to convey information about a patient&apos;s status after coronary bypass surgery; it generates </context>
</contexts>
<marker>Grishman, Macleod, Meyers, 1994</marker>
<rawString>Ralph Grishman, Catherine Macleod, and Adam Meyers. COMLEX Syntax: Building a Computational Lexicon. In Proceedings of the 15th International Conference on Computational Linguistics (COLING-94), Kyoto, Japan, 1994.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen McKeown</author>
</authors>
<title>Towards the Automatic Identification of Adjectival Scales: Clustering Adjectives According to Meaning.</title>
<booktitle>In Proceedings of the 31st Annual Meeting of the ACL,</booktitle>
<pages>172</pages>
<marker>Hatzivassiloglou, McKeown, </marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen McKeown. Towards the Automatic Identification of Adjectival Scales: Clustering Adjectives According to Meaning. In Proceedings of the 31st Annual Meeting of the ACL, pages 172-</rawString>
</citation>
<citation valid="true">
<authors>
<author>Columbus</author>
</authors>
<title>Association for Computational Linguistics.</title>
<date>1993</date>
<location>Ohio,</location>
<marker>Columbus, 1993</marker>
<rawString>182, Columbus, Ohio, June 1993. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen McKeown</author>
</authors>
<title>Predicting the Semantic Orientation of Adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the ACL,</booktitle>
<pages>174--181</pages>
<location>Madrid, Spain,</location>
<contexts>
<context position="7334" citStr="Hatzivassiloglou and McKeown 1997" startWordPosition="1137" endWordPosition="1140">odifiers precede extensional ones. However, while these studies offer insights at the complex phenomenon of adjective ordering, they cannot be directly mapped to a computational procedure. On the other hand, recent computational work on sentence planning [Bateman et al. 1998; Shaw 1998b] indicates that generation research has progressed to a point where hard problems such as ellipsis, conjunctions, and ordering of paradigmatically related constituents are addressed. Computational corpus studies related to adjectives were performed by [Justeson and Katz 1991; Hatzivassiloglou and McKeown 1993; Hatzivassiloglou and McKeown 1997], but none was directly on the ordering problem. [Knight and Hatzivassiloglou 1995] and [Langkilde and Knight 1998] have proposed models for incorporating statistical information into a text generation system, an approach that is similar to our way of using the evidence obtained from corpus in our actual generator. 3 Methodology In this section, we discuss how we obtain the premodifier sequences from the corpus for analysis and the three approaches we use for establishing ordering relationships: direct corpus evidence, transitive closure, and clustering analysis. The result of our analysis is</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen McKeown. Predicting the Semantic Orientation of Adjectives. In Proceedings of the 35th Annual Meeting of the ACL, pages 174-181, Madrid, Spain, July 1997. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<date>1991</date>
<booktitle>Cooccurrences of Antonymous Adjectives and Their Contexts. Computational Linguistics,</booktitle>
<pages>17--1</pages>
<contexts>
<context position="7264" citStr="Justeson and Katz 1991" startWordPosition="1129" endWordPosition="1132">ded the work by Kamp [1975] and proposed that intensional modifiers precede extensional ones. However, while these studies offer insights at the complex phenomenon of adjective ordering, they cannot be directly mapped to a computational procedure. On the other hand, recent computational work on sentence planning [Bateman et al. 1998; Shaw 1998b] indicates that generation research has progressed to a point where hard problems such as ellipsis, conjunctions, and ordering of paradigmatically related constituents are addressed. Computational corpus studies related to adjectives were performed by [Justeson and Katz 1991; Hatzivassiloglou and McKeown 1993; Hatzivassiloglou and McKeown 1997], but none was directly on the ordering problem. [Knight and Hatzivassiloglou 1995] and [Langkilde and Knight 1998] have proposed models for incorporating statistical information into a text generation system, an approach that is similar to our way of using the evidence obtained from corpus in our actual generator. 3 Methodology In this section, we discuss how we obtain the premodifier sequences from the corpus for analysis and the three approaches we use for establishing ordering relationships: direct corpus evidence, tran</context>
</contexts>
<marker>Justeson, Katz, 1991</marker>
<rawString>John S. Justeson and Slava M. Katz. Cooccurrences of Antonymous Adjectives and Their Contexts. Computational Linguistics, 17(1):1-19, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A W Kamp</author>
</authors>
<title>Two Theories of Adjectives.</title>
<date>1975</date>
<booktitle>Formal Semantics of Natural Language.</booktitle>
<editor>In E. L. Keenan, editor,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England,</location>
<marker>Kamp, 1975</marker>
<rawString>J. A. W. Kamp. Two Theories of Adjectives. In E. L. Keenan, editor, Formal Semantics of Natural Language. Cambridge University Press, Cambridge, England, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maurice G Kendall</author>
</authors>
<title>A New Measure of Rank Correlation.</title>
<date>1938</date>
<tech>Biometrika, 30(1-2):81— 93,</tech>
<contexts>
<context position="17343" citStr="Kendall 1938" startWordPosition="2855" endWordPosition="2856">ern of relative order with other premodifiers for which we have sufficient evidence. For each pair of premodifiers A and B, we examine every other premodifier in the corpus, X; if both A -‹ X and B -&lt; X, or both A ›- X and B ›- X, one point is added to the similarity score between A and B. If on the other hand A -‹ X and B X, or A X and B -‹ X, one point is subtracted. X does not contribute to the similarity score if there is not sufficient prior evidence for the relative order of X and A, or of X and B. This procedure closely parallels non-parametric distributional tests such as Kendall&apos;s T [Kendall 1938]. The similarity scores are then converted into dissimilarities and fed into a non-hierarchical clustering algorithm [Spath 1985], which separates the premodifiers in groups. This is achieved by minimizing an objective function, defined as the sum of within-group dissimilarities over all groups. In this manner, premodifiers that are closely similar in terms of sharing the same relative order with other premodifiers are placed in the same group. Once classes of premodifiers have been induced, we examine every pair of classes and decide which precedes the other. For two classes C1 and C2, we ex</context>
</contexts>
<marker>Kendall, 1938</marker>
<rawString>Maurice G. Kendall. A New Measure of Rank Correlation. Biometrika, 30(1-2):81— 93, June 1938.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Two-Level, Many-Paths Generation.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the A CL,</booktitle>
<pages>252--260</pages>
<location>Boston, Massachusetts,</location>
<contexts>
<context position="7417" citStr="Knight and Hatzivassiloglou 1995" startWordPosition="1149" endWordPosition="1152">e complex phenomenon of adjective ordering, they cannot be directly mapped to a computational procedure. On the other hand, recent computational work on sentence planning [Bateman et al. 1998; Shaw 1998b] indicates that generation research has progressed to a point where hard problems such as ellipsis, conjunctions, and ordering of paradigmatically related constituents are addressed. Computational corpus studies related to adjectives were performed by [Justeson and Katz 1991; Hatzivassiloglou and McKeown 1993; Hatzivassiloglou and McKeown 1997], but none was directly on the ordering problem. [Knight and Hatzivassiloglou 1995] and [Langkilde and Knight 1998] have proposed models for incorporating statistical information into a text generation system, an approach that is similar to our way of using the evidence obtained from corpus in our actual generator. 3 Methodology In this section, we discuss how we obtain the premodifier sequences from the corpus for analysis and the three approaches we use for establishing ordering relationships: direct corpus evidence, transitive closure, and clustering analysis. The result of our analysis is embodied in a 136 function, compute_order (A, B), which returns the sequential ord</context>
</contexts>
<marker>Knight, Hatzivassiloglou, 1995</marker>
<rawString>Kevin Knight and Vasileios Hatzivassiloglou. Two-Level, Many-Paths Generation. In Proceedings of the 33rd Annual Meeting of the A CL, pages 252-260, Boston, Massachusetts, June 1995. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>Generation that Exploits Corpus-Based Statistical Knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the ACL and the 17th International Conference on Computational Linguistics (ACL/COLING-98),</booktitle>
<pages>704--710</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="7449" citStr="Langkilde and Knight 1998" startWordPosition="1154" endWordPosition="1157">ing, they cannot be directly mapped to a computational procedure. On the other hand, recent computational work on sentence planning [Bateman et al. 1998; Shaw 1998b] indicates that generation research has progressed to a point where hard problems such as ellipsis, conjunctions, and ordering of paradigmatically related constituents are addressed. Computational corpus studies related to adjectives were performed by [Justeson and Katz 1991; Hatzivassiloglou and McKeown 1993; Hatzivassiloglou and McKeown 1997], but none was directly on the ordering problem. [Knight and Hatzivassiloglou 1995] and [Langkilde and Knight 1998] have proposed models for incorporating statistical information into a text generation system, an approach that is similar to our way of using the evidence obtained from corpus in our actual generator. 3 Methodology In this section, we discuss how we obtain the premodifier sequences from the corpus for analysis and the three approaches we use for establishing ordering relationships: direct corpus evidence, transitive closure, and clustering analysis. The result of our analysis is embodied in a 136 function, compute_order (A, B), which returns the sequential ordering between two premodifiers, </context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. Generation that Exploits Corpus-Based Statistical Knowledge. In Proceedings of the 36th Annual Meeting of the ACL and the 17th International Conference on Computational Linguistics (ACL/COLING-98), pages 704-710, Montreal, Canada, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yakov Malkiel</author>
</authors>
<title>Studies in Irreversible Binomials.</title>
<date>1959</date>
<tech>Lingua, 8(2):113-160,</tech>
<note>Reprinted in [Malkiel 19681.</note>
<contexts>
<context position="4352" citStr="Malkiel 1959" startWordPosition="690" endWordPosition="691">is portable to different domains. In the next section, we briefly describe prior linguistic research on this topic. Sections 3 and 4 describe the methodology and corpus used in our analysis, while the results of our experiments are presented in Section 5. In Section 6, we demonstrate how we incorporated our ordering results in a general text generation system. Finally, Section 7 discusses possible improvements to our current approach. 2 Related Work The order of adjectives (and, by analogy, nominal premodifiers) seems to be outside of the grammar; it is influenced by factors such as polarity [Malkiel 1959], scope, and collocational restrictions [Bache 1978]. Linguists [Goyvaerts 1968; Vendler 1968; Quirk and Greenbaum 1973; Bache 1978; Dixon 1982] have performed manual analyses of (small) corpora and pointed out various tendencies, such as the facts that underived adjectives often precede derived adjectives, and shorter modifiers precede longer ones. Given the difficulty of adequately describing all factors that influence the order of premodifiers, most earlier work is based on placing the premodifiers into broad semantic classes, and specifying an order among these classes. More than ten clas</context>
</contexts>
<marker>Malkiel, 1959</marker>
<rawString>Yakov Malkiel. Studies in Irreversible Binomials. Lingua, 8(2):113-160, May 1959. Reprinted in [Malkiel 19681.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yakov Malkiel</author>
</authors>
<title>Essays on Linguistic Themes.</title>
<date>1968</date>
<publisher>Blackwell,</publisher>
<location>Oxford,</location>
<marker>Malkiel, 1968</marker>
<rawString>Yakov Malkiel. Essays on Linguistic Themes. Blackwell, Oxford, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="18905" citStr="Marcus et al. 1993" startWordPosition="3134" endWordPosition="3137">t seen together earlier. This method makes (weak) predictions for any pair (A, B) of words, except if (a) both A and B are placed in the same cluster; (b) no ordered pairs (x, y) with one element in the class of A and one in the class of B have been identified; or (c) the evidence for one class preceding the other is in the aggregate equally strong in both directions. 4 The Corpus We used two corpora for our analysis: hospital discharge summaries from 1991 to 1997 from the Columbia-Presbyterian Medical Center, and the January 1996 part of the Wall Street Journal corpus from the Penn TreeBank [Marcus et al. 1993]. To facilitate comparisons across the two corpora, we intentionally limited ourselves to only one month of the WSJ corpus, so that approximately the same amount of data would be examined in each case. The text in each corpus is divided into a training part (2.3 million words for the medical corpus and 1.5 million words for the WSJ) and a test part (1.2 million words for the medical corpus and 1.6 million words for the WSJ). All domain-specific markup was removed, and the text was processed by the MXTERMINATOR sentence boundary detector [Reynar and Ratnaparkhi 1997] and Brill&apos;s part-of-speech</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19:313-330, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Martin</author>
</authors>
<title>Adjective Order and Juncture.</title>
<date>1970</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<pages>9--379</pages>
<marker>Martin, 1970</marker>
<rawString>J. E. Martin. Adjective Order and Juncture. Journal of Verbal Learning and Verbal Behavior, 9:379-384, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine J Miller</author>
</authors>
<title>Introduction to WordNet: An OnLine Lexical Database.</title>
<date>1990</date>
<journal>International Journal of Lexicography (special issue),</journal>
<pages>3--4</pages>
<contexts>
<context position="1525" citStr="Miller et al. 1990" startWordPosition="232" endWordPosition="235">es in specifying a consistent ordering of adjectives have already been noted by linguists [Whorf 1956; Vendler 19681. During the process of generating complex sentences by combining multiple clauses, there are situations where multiple adjectives or nouns modify the same head noun. The text generation system must order these modifiers in a similar way as domain experts use them to ensure fluency of the text. For example, the description of the age of a patient precedes his ethnicity and gender in medical domain as in &amp;quot;a 50 year-old white female patient&amp;quot;. Yet, general lexicons such as WordNet [Miller et al. 19901 and COMLEX [Grishman et al. 1994], do not store such information. In this paper, we present automated techniques for addressing this problem of determining, given two premodifiers A and B, the preferred ordering between them. Our methods rely on and generalize empirical evidence obtained from large corpora, and are evaluated objectively on such corpora. They are informed and motivated by our practical need for ordering multiple premodifiers in the MAGIC system [Dalal et al. 1996]. MAGIC utilizes co-ordinated text, speech, and graphics to convey information about a patient&apos;s status after coro</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J. Miller. Introduction to WordNet: An OnLine Lexical Database. International Journal of Lexicography (special issue), 3(4):235-312, 1990.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fernando C N Pereira</author>
<author>Michael D Riley</author>
</authors>
<title>Speech Recognition by Composition of Weighted Finite Automata.</title>
<booktitle>FiniteState Language Processing,</booktitle>
<pages>431--453</pages>
<editor>In Emmanuel Roche and Yves Schabes, editors,</editor>
<marker>Pereira, Riley, </marker>
<rawString>Fernando C. N. Pereira and Michael D. Riley. Speech Recognition by Composition of Weighted Finite Automata. In Emmanuel Roche and Yves Schabes, editors, FiniteState Language Processing, pages 431-453.</rawString>
</citation>
<citation valid="false">
<date>1997</date>
<publisher>MIT Press,</publisher>
<institution>Fernando Pereira, Naftali Tishby, and Lillian Lee. Distributional Clustering of English</institution>
<location>Cambridge, Massachusetts,</location>
<marker>1997</marker>
<rawString>MIT Press, Cambridge, Massachusetts, 1997. Fernando Pereira, Naftali Tishby, and Lillian Lee. Distributional Clustering of English</rawString>
</citation>
<citation valid="true">
<authors>
<author>Words</author>
</authors>
<title>Association for Computational Linguistics.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the ACL,</booktitle>
<pages>183--190</pages>
<location>Columbus, Ohio,</location>
<marker>Words, 1993</marker>
<rawString>Words. In Proceedings of the 31st Annual Meeting of the ACL, pages 183-190, Columbus, Ohio, June 1993. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randolph Quirk</author>
<author>Sidney Greenbaum</author>
</authors>
<title>A Concise Grammar of Contemporary English.</title>
<date>1973</date>
<publisher>Harcourt Brace Jovanovich, Inc.,</publisher>
<location>London,</location>
<contexts>
<context position="4472" citStr="Quirk and Greenbaum 1973" startWordPosition="705" endWordPosition="709"> topic. Sections 3 and 4 describe the methodology and corpus used in our analysis, while the results of our experiments are presented in Section 5. In Section 6, we demonstrate how we incorporated our ordering results in a general text generation system. Finally, Section 7 discusses possible improvements to our current approach. 2 Related Work The order of adjectives (and, by analogy, nominal premodifiers) seems to be outside of the grammar; it is influenced by factors such as polarity [Malkiel 1959], scope, and collocational restrictions [Bache 1978]. Linguists [Goyvaerts 1968; Vendler 1968; Quirk and Greenbaum 1973; Bache 1978; Dixon 1982] have performed manual analyses of (small) corpora and pointed out various tendencies, such as the facts that underived adjectives often precede derived adjectives, and shorter modifiers precede longer ones. Given the difficulty of adequately describing all factors that influence the order of premodifiers, most earlier work is based on placing the premodifiers into broad semantic classes, and specifying an order among these classes. More than ten classes have been proposed, with some of them further broken down into subclasses. Though not all these studies agree on the</context>
</contexts>
<marker>Quirk, Greenbaum, 1973</marker>
<rawString>Randolph Quirk and Sidney Greenbaum. A Concise Grammar of Contemporary English. Harcourt Brace Jovanovich, Inc., London, 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jeffrey</author>
</authors>
<title>Reynar and Adwait Ratnaparkhi. A Maximum Entropy Approach to Identifying Sentence Boundaries.</title>
<date>1997</date>
<booktitle>In Proc. of the 5th Applied Natural Language Conference (ANLP97),</booktitle>
<location>Washington, D.C.,</location>
<marker>Jeffrey, 1997</marker>
<rawString>Jeffrey C. Reynar and Adwait Ratnaparkhi. A Maximum Entropy Approach to Identifying Sentence Boundaries. In Proc. of the 5th Applied Natural Language Conference (ANLP97), Washington, D.C., April 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
</authors>
<title>Clause Aggregation Using Linguistic Knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th International Workshop on Natural Language Generation.,</booktitle>
<pages>138--147</pages>
<contexts>
<context position="6987" citStr="Shaw 1998" startWordPosition="1091" endWordPosition="1092">onal behavior of adjectives. Teyssier [1968] first proposed that adjectival functions, i.e. identification, characterization, and classification, affect adjective order. Martin [1970] carried out psycholinguistic studies of adjective ordering. Frawley [1992] extended the work by Kamp [1975] and proposed that intensional modifiers precede extensional ones. However, while these studies offer insights at the complex phenomenon of adjective ordering, they cannot be directly mapped to a computational procedure. On the other hand, recent computational work on sentence planning [Bateman et al. 1998; Shaw 1998b] indicates that generation research has progressed to a point where hard problems such as ellipsis, conjunctions, and ordering of paradigmatically related constituents are addressed. Computational corpus studies related to adjectives were performed by [Justeson and Katz 1991; Hatzivassiloglou and McKeown 1993; Hatzivassiloglou and McKeown 1997], but none was directly on the ordering problem. [Knight and Hatzivassiloglou 1995] and [Langkilde and Knight 1998] have proposed models for incorporating statistical information into a text generation system, an approach that is similar to our way of </context>
<context position="29042" citStr="Shaw 1998" startWordPosition="4774" endWordPosition="4775">ystem, including the fluency of the generated text and its similarity to humanproduced reports. Lexicalization is inherently domain dependent, so traditional lexica cannot be ported across domains without major modifications. Our approach, in contrast, is based on words extracted from a domain corpus and not on concepts, therefore it can be easily applied to new domains. In our MAGIC system, aggregation operators, such as conjunction, ellipsis, and transformations of clauses to adjectival phrases and relative clauses, are performed to combine related clauses together and increase conciseness [Shaw 1998a; Shaw 199813]. We wrote a function, reorder_premod( ), which is called after the aggregation operators, takes the whole lexicalized semantic representation, and reorders the premodifiers right before the linguistic realizer is invoked. Figure 1 shows the difference in the output produced by our gener141 ator with and without the ordering component. 7 Conclusions and Future Work We have presented three techniques for exploring prior corpus evidence in predicting the order of premodifiers within noun phrases. Our methods expand on observable data, by inferring new relationships between premodi</context>
</contexts>
<marker>Shaw, 1998</marker>
<rawString>James Shaw. Clause Aggregation Using Linguistic Knowledge. In Proceedings of the 9th International Workshop on Natural Language Generation., pages 138-147, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
</authors>
<title>Segregatory Coordination and Ellipsis in Text Generation.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the ACL and the 17th International Conference on Computational Linguistics (ACL/COLING-98),</booktitle>
<pages>1220--1226</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="6987" citStr="Shaw 1998" startWordPosition="1091" endWordPosition="1092">onal behavior of adjectives. Teyssier [1968] first proposed that adjectival functions, i.e. identification, characterization, and classification, affect adjective order. Martin [1970] carried out psycholinguistic studies of adjective ordering. Frawley [1992] extended the work by Kamp [1975] and proposed that intensional modifiers precede extensional ones. However, while these studies offer insights at the complex phenomenon of adjective ordering, they cannot be directly mapped to a computational procedure. On the other hand, recent computational work on sentence planning [Bateman et al. 1998; Shaw 1998b] indicates that generation research has progressed to a point where hard problems such as ellipsis, conjunctions, and ordering of paradigmatically related constituents are addressed. Computational corpus studies related to adjectives were performed by [Justeson and Katz 1991; Hatzivassiloglou and McKeown 1993; Hatzivassiloglou and McKeown 1997], but none was directly on the ordering problem. [Knight and Hatzivassiloglou 1995] and [Langkilde and Knight 1998] have proposed models for incorporating statistical information into a text generation system, an approach that is similar to our way of </context>
<context position="29042" citStr="Shaw 1998" startWordPosition="4774" endWordPosition="4775">ystem, including the fluency of the generated text and its similarity to humanproduced reports. Lexicalization is inherently domain dependent, so traditional lexica cannot be ported across domains without major modifications. Our approach, in contrast, is based on words extracted from a domain corpus and not on concepts, therefore it can be easily applied to new domains. In our MAGIC system, aggregation operators, such as conjunction, ellipsis, and transformations of clauses to adjectival phrases and relative clauses, are performed to combine related clauses together and increase conciseness [Shaw 1998a; Shaw 199813]. We wrote a function, reorder_premod( ), which is called after the aggregation operators, takes the whole lexicalized semantic representation, and reorders the premodifiers right before the linguistic realizer is invoked. Figure 1 shows the difference in the output produced by our gener141 ator with and without the ordering component. 7 Conclusions and Future Work We have presented three techniques for exploring prior corpus evidence in predicting the order of premodifiers within noun phrases. Our methods expand on observable data, by inferring new relationships between premodi</context>
</contexts>
<marker>Shaw, 1998</marker>
<rawString>James Shaw. Segregatory Coordination and Ellipsis in Text Generation. In Proceedings of the 36th Annual Meeting of the ACL and the 17th International Conference on Computational Linguistics (ACL/COLING-98), pages 1220-1226, Montreal, Canada, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmuth Spath</author>
</authors>
<title>Cluster Dissection and Analysis: Theory, FORTRAN Programs, Examples. Ellis Horwood,</title>
<date>1985</date>
<location>Chichester, England,</location>
<contexts>
<context position="17472" citStr="Spath 1985" startWordPosition="2872" endWordPosition="2873">ine every other premodifier in the corpus, X; if both A -‹ X and B -&lt; X, or both A ›- X and B ›- X, one point is added to the similarity score between A and B. If on the other hand A -‹ X and B X, or A X and B -‹ X, one point is subtracted. X does not contribute to the similarity score if there is not sufficient prior evidence for the relative order of X and A, or of X and B. This procedure closely parallels non-parametric distributional tests such as Kendall&apos;s T [Kendall 1938]. The similarity scores are then converted into dissimilarities and fed into a non-hierarchical clustering algorithm [Spath 1985], which separates the premodifiers in groups. This is achieved by minimizing an objective function, defined as the sum of within-group dissimilarities over all groups. In this manner, premodifiers that are closely similar in terms of sharing the same relative order with other premodifiers are placed in the same group. Once classes of premodifiers have been induced, we examine every pair of classes and decide which precedes the other. For two classes C1 and C2, we extract all pairs of premodifiers (x,y) with x E C1 and y E C2. If we have evidence (either direct or through transitivity) that x </context>
</contexts>
<marker>Spath, 1985</marker>
<rawString>Helmuth Spath. Cluster Dissection and Analysis: Theory, FORTRAN Programs, Examples. Ellis Horwood, Chichester, England, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Teyssier</author>
</authors>
<title>Notes on the Syntax of the Adjective in Modern English.</title>
<date>1968</date>
<journal>Behavioral Science,</journal>
<pages>20--225</pages>
<marker>Teyssier, 1968</marker>
<rawString>J. Teyssier. Notes on the Syntax of the Adjective in Modern English. Behavioral Science, 20:225-249, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeno Vendler</author>
</authors>
<title>Adjectives and Nom,inalizations. Mouton and Co., The Netherlands,</title>
<date>1968</date>
<contexts>
<context position="1022" citStr="Vendler 1968" startWordPosition="148" endWordPosition="149"> to identify sequential order among premodifiers: direct evidence, transitive closure, and clustering. Our implemented system can make over 94% of such ordering decisions correctly, as evaluated on a large, previously unseen test corpus. 1 Introduction Sequential ordering among premodifiers affects the fluency of text, e.g., &amp;quot;large foreign financial firms&amp;quot; or &amp;quot;zero-coupon global bonds&amp;quot; are desirable, while &amp;quot;foreign large financial firms&amp;quot; or &amp;quot;global zero-coupon bonds&amp;quot; sound odd. The difficulties in specifying a consistent ordering of adjectives have already been noted by linguists [Whorf 1956; Vendler 19681. During the process of generating complex sentences by combining multiple clauses, there are situations where multiple adjectives or nouns modify the same head noun. The text generation system must order these modifiers in a similar way as domain experts use them to ensure fluency of the text. For example, the description of the age of a patient precedes his ethnicity and gender in medical domain as in &amp;quot;a 50 year-old white female patient&amp;quot;. Yet, general lexicons such as WordNet [Miller et al. 19901 and COMLEX [Grishman et al. 1994], do not store such information. In this paper, we present aut</context>
<context position="4446" citStr="Vendler 1968" startWordPosition="703" endWordPosition="704">search on this topic. Sections 3 and 4 describe the methodology and corpus used in our analysis, while the results of our experiments are presented in Section 5. In Section 6, we demonstrate how we incorporated our ordering results in a general text generation system. Finally, Section 7 discusses possible improvements to our current approach. 2 Related Work The order of adjectives (and, by analogy, nominal premodifiers) seems to be outside of the grammar; it is influenced by factors such as polarity [Malkiel 1959], scope, and collocational restrictions [Bache 1978]. Linguists [Goyvaerts 1968; Vendler 1968; Quirk and Greenbaum 1973; Bache 1978; Dixon 1982] have performed manual analyses of (small) corpora and pointed out various tendencies, such as the facts that underived adjectives often precede derived adjectives, and shorter modifiers precede longer ones. Given the difficulty of adequately describing all factors that influence the order of premodifiers, most earlier work is based on placing the premodifiers into broad semantic classes, and specifying an order among these classes. More than ten classes have been proposed, with some of them further broken down into subclasses. Though not all </context>
</contexts>
<marker>Vendler, 1968</marker>
<rawString>Zeno Vendler. Adjectives and Nom,inalizations. Mouton and Co., The Netherlands, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Language</author>
</authors>
<title>Thought, and Reality; Selected Writings.</title>
<date>1956</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts,</location>
<marker>Language, 1956</marker>
<rawString>Benjamin Lee Whorf. Language, Thought, and Reality; Selected Writings. MIT Press, Cambridge, Massachusetts, 1956.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>