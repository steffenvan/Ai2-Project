<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000647">
<title confidence="0.998945">
What’s in a Domain? Analyzing Genre and Topic Differences
in Statistical Machine Translation
</title>
<author confidence="0.897076">
Marlies van der Wees Arianna Bisazza Wouter Weerkamp♦ Christof Monz
</author>
<affiliation confidence="0.9701835">
Informatics Institute
University of Amsterdam
</affiliation>
<email confidence="0.970413">
{m.e.vanderwees,a.bisazza,c.monz}@uva.nl
</email>
<address confidence="0.524873">
♦904Labs, Amsterdam
</address>
<email confidence="0.9773">
wouter@904labs.com
</email>
<sectionHeader confidence="0.99702" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999178125">
Domain adaptation is an active field of
research in statistical machine translation
(SMT), but so far most work has ignored
the distinction between the topic and genre
of documents. In this paper we quan-
tify and disentangle the impact of genre
and topic differences on translation qual-
ity by introducing a new data set that has
controlled topic and genre distributions.
In addition, we perform a detailed analy-
sis showing that differences across topics
only explain to a limited degree transla-
tion performance differences across gen-
res, and that genre-specific errors are more
attributable to model coverage than to sub-
optimal scoring of translation candidates.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999874566666666">
Training corpora for statistical machine translation
(SMT) are typically collected from a wide variety
of sources and therefore have varying textual char-
acteristics such as writing style and vocabulary.
The test set, on the other hand, is much smaller and
usually more homogeneous. The resulting mis-
match between the test data and the majority of
the training data can lead to suboptimal translation
performance. In such situations, it is beneficial to
adapt the translation system to the translation task
at hand, which is exactly the challenge of domain
adaptation in SMT.
The concept of a domain, however, is not unam-
biguously defined across existing domain adapta-
tion methods. Commonly used interpretations of
domains neglect the fact that topic and genre are
two distinct properties of text (Lee and Myaeng,
2002; Stein and Meyer Zu Eissen, 2006). Two
texts can discuss a similar topic, but using different
styles. Since most work on domain adaptation in
SMT uses in-domain and out-of-domain data that
differ on both the topic and the genre level, it is un-
clear whether the proposed solutions address topic
or genre differences.
In this work we take a step back and disentan-
gle the concepts topic and genre, then we analyze
and quantify their effect on SMT, which we be-
lieve is a necessary step towards further improv-
ing domain adaptation for SMT. Concretely, we
address the following questions:
</bodyText>
<listItem confidence="0.784969">
(i) Can we clarify the ambiguous use of the con-
cept domain with regard to adaptation in SMT?
(ii) Which of two intrinsic text properties, topic
and genre, presents a larger challenge to SMT?
(iii) To what extent do topic and genre differ
with respect to SMT model coverage and observed
out-of-vocabulary (OOV) types?
</listItem>
<bodyText confidence="0.99989825">
To answer these questions, we introduce a new
data set with controlled topic-genre distributions,
which we use for an in-depth analysis of the im-
pact of topic and genre differences on SMT.
</bodyText>
<sectionHeader confidence="0.933874" genericHeader="introduction">
2 Topic and genre differences in SMT
</sectionHeader>
<bodyText confidence="0.996987909090909">
The definition of a domain varies across work on
domain adaptation and is often imprecise. In this
work we avoid using this ambiguous term, and in-
stead focus on the text properties topic and genre.
Topic is the general subject of a document. Top-
ics can be determined on multiple levels, rang-
ing from very broad to more detailed. Examples
of topics include sports, politics, and science
(high-level), or football and tennis (low-level).
Genre is harder to define, as there is no single
definition in literature (Swales, 1990; Karlgren,
</bodyText>
<page confidence="0.791735">
560
</page>
<bodyText confidence="0.837633222222222">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 560–566,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
Topic Newswire sentence User-generated sentence
Culture The 12 contestants competed during a May 3rd
Prime before a panel of judges and millions of
viewers across the Arab world.
Your program’s name is “Arab Idol”, which is in English,
and you allowed Barwas to participate and represent Iraq
while she sings in Kurdish!!!
Economy Yemen is mulling the establishment of 13 indus-
trial zones across its six planned administrative
regions in a bid to stimulate development and
create job opportunities.
What development in Yemen are you talking about? We will
continue to call for freedom until independence and liber-
ation and the routing of the northern occupation from our
lands.
</bodyText>
<tableCaption confidence="0.9668905">
Table 1: English-side samples from the Gen&amp;Topic data set. All pairs of newswire (NW) and user-
generated (UG) fragments in the data set discuss the same article and are topically related.
</tableCaption>
<bodyText confidence="0.9998066">
2004). Based on previous definitions, Santini
(2004) concludes that the term genre is used
as a concept complementary to topic, covering
the non-topical text properties function, style,
and text type. Like topics, genres can also ex-
hibit different levels of granularity (Lee, 2001).
Examples of genres include formal or informal
text (high-level), and newswire, editorials, and
user-generated text (low-level).
Topic and genre are both intrinsic properties of
texts, but most work on domain adaptation uses
provenance or subcorpus information to adapt
SMT systems to a specific translation task (Fos-
ter and Kuhn, 2007; Duh et al., 2010; Bisazza
et al., 2011; Sennrich, 2012; Bisazza and Fed-
erico, 2012; Haddow and Koehn, 2012, among
others). In recent years, some work has explicitly
addressed topic adaptation for SMT (Eidelman et
al., 2012; Hewavitharana et al., 2013; Hasler et al.,
2014a; Hasler et al., 2014c) using latent Dirich-
let allocation (Blei et al., 2003). While Hasler et
al. (2014b) showed that provenance and topic can
serve as complements to each other, the effects of
genre and topic on SMT have not been systemati-
cally studied.
</bodyText>
<sectionHeader confidence="0.97263" genericHeader="method">
3 The Gen&amp;Topic benchmark set
</sectionHeader>
<bodyText confidence="0.997226692307692">
To analyze the impact of genre and topic differ-
ences in SMT, we need a test set where both
dimensions are controlled as much as possible.
Unfortunately, currently available and commonly
used benchmarks meet this requirement only to
a limited degree. For instance, while the NIST
OpenMT sets do contain documents drawn from
two genres, newswire and web, both genres ex-
hibit a different distribution over topics, i.e., the
same topic might not be equally represented across
genres, and vice versa.
To overcome this limitation, we introduce a
new Arabic-English parallel benchmark set, the
</bodyText>
<equation confidence="0.748564842105263">
Genre
Topic NW UG Total
segments 654 507 1161
Culture
tokens 15.5K 14.9K 30.4K
segments 500 578 1078
Economy
tokens 16.0K 15.5K 31.5K
segments 384 319 703
Health
tokens 9.7K 9.3K 19.1K
segments 494 646 1140
Politics
tokens 15.8K 15.8K 31.6K
Security segments 532 826 1358
tokens 16.1K 15.9K 32.0K
segments 2564 2876 5440
Total
tokens 73.2K 71.3K 144.5K
</equation>
<tableCaption confidence="0.876958">
Table 2: Statistics of the Arabic-English
</tableCaption>
<bodyText confidence="0.996581333333333">
Gen&amp;Topic data set containing five topics and
two genres: newswire (NW) and user-generated
(UG) text. Tokens are counted on the Arabic side.
Gen&amp;Topic data set, that contains documents with
controlled topic and genre distributions. This
benchmark set consists of manually translated
news articles crawled from the web with their
corresponding, manually translated readers’ com-
ments and thus comprises the genres newswire
(NW) and user-generated (UG) text. Since each
pair of NW and UG documents originates from the
same article, we can assume that both documents
discuss the same topic, for which labels are pro-
vided by the source websites. By including com-
parable numbers of tokens per genre for each arti-
cle, we enforce equal topic distributions across the
genres. Two examples of NW-UG pairs are shown
in Table 1. Note that the selected UG sentences in
the Gen&amp;Topic data set are well-formulated com-
ments rather than dialog-oriented content such as
SMS or chat messages, which pose substantially
larger challenges to SMT than the Gen&amp;Topic
comments (van der Wees et al., 2015).
For parameter estimation purposes, we split the
</bodyText>
<page confidence="0.986745">
561
</page>
<bodyText confidence="0.999499714285714">
complete benchmark into a development and a test
set, such that the development set contains approx-
imately one-third of the data, while ensuring that
articles in each set originate from non-overlapping
time periods. Table 2 lists the specifications of the
complete benchmark, which we make available for
download1.
</bodyText>
<table confidence="0.9567018">
NW UG All
Culture 19.2 17.6 19.3 ⎫
Economy 19.9 15.9 18.9 ⎪⎪
Health 19.3 17.7 18.8 ⎬ ⎪
Politics 21.3 13.6 18.2 Avg. diff.: ±0.6
Security 19.3 16.2 18.5 ⎪
⎭⎪⎪
All 19.9 16.0 18.9
v
Avg. diff.: ±3.9
</table>
<sectionHeader confidence="0.6429755" genericHeader="method">
4 Quantifying the impact of genre and
topic differences on SMT
</sectionHeader>
<bodyText confidence="0.9999665">
To quantify the impact of multiple genres and top-
ics in a test corpus, we run a series of experiments
in which we measure translation quality, model
coverage, and observed OOV types.
</bodyText>
<subsectionHeader confidence="0.995597">
4.1 Translation quality
</subsectionHeader>
<bodyText confidence="0.995891636363636">
We first run a translation experiment on the
Gen&amp;Topic test set using our in-house phrase-
based SMT system similar to Moses (Koehn et
al., 2007). Features include lexicalized reordering,
linear distortion with limit 5, and lexical weight-
ing. In addition, we use a 5-gram linearly inter-
polated language model, trained on 1.6B words
with Kneser-Ney smoothing (Chen and Goodman,
1999), that covers all topics and genres contained
in the benchmark. We tune our system on the
Gen&amp;Topic development set using pairwise rank-
ing optimization (PRO) (Hopkins and May, 2011).
Naturally, performance differences across top-
ics and genres depend on the degree to which both
are represented in the parallel training data. To
allow for fair comparison, we down-sample our
available training data to be as balanced as pos-
sible in terms of topics and genres. The resulting
system is trained on approximately 200K sentence
pairs with 6M source tokens per genre, as much
as is available for UG. All data originates from the
same web sources as the documents in the bench-
mark. Our more competitive system (van der Wees
et al., 2015) that uses also LDC-distributed data
yields slightly higher BLEU scores, but is more fa-
vorable for NW than for UG translation tasks. Due
to the strict data requirements in terms of topic and
genre distributions, as well as the availability of
sizable parallel training data, our current experi-
mental set-up covers Arabic-English only.
Table 3 compares BLEU scores (Papineni et al.,
2002, 1 reference) of the Gen&amp;Topic data, split
down by topics and genres. We observe that trans-
</bodyText>
<footnote confidence="0.947165">
1http://ilps.science.uva.nl/resources/
gen-topic/
</footnote>
<tableCaption confidence="0.977786">
Table 3: Arabic-to-English BLEU scores on the
</tableCaption>
<bodyText confidence="0.936067842105263">
Gen&amp;Topic test set (1 reference translation) per
topic-genre combination. Tuning was done on the
complete Gen&amp;Topic development set. Variations
in translation quality are represented by average
pairwise BLEU score differences.
lation performance fluctuates much more across
genres than across topics: There is a large gap of
3.9 BLEU points between NW and UG, which can
be entirely attributed to actual genre differences
given the construction of the Gen&amp;Topic data set
and the use of down-sampled training data. On
the other hand, the gap between different topics is
only 0.6 BLEU points on average, and at most 1.1
(between culture and politics). A translation qual-
ity gap between genres has also been observed in
past OpenMT evaluation campaigns. However, as
the NIST benchmarks have not been controlled for
topics across genres, it is unclear to what extent
this gap can be attributed to genre differences.
</bodyText>
<subsectionHeader confidence="0.99649">
4.2 Model coverage analysis
</subsectionHeader>
<bodyText confidence="0.998590315789474">
Next, to explain the large performance gap be-
tween genres, we analyze the phrase lengths
within Viterbi translations, source phrase and
phrase pair recall, and phrase pair OOV of the
Gen&amp;Topic test set (Table 4).
Average source-side phrase length We first
compute the average number of source words con-
tained in the phrases that our SMT system uses to
produce the 1-best translations for the Gen&amp;Topic
test set. One can see that UG is translated with
shorter phrases than NW, and that differences be-
tween genres are more pronounced than among
topics. This difference, in turn, can be due to
unreliable translation probabilities but also to the
mere lack of translation options in the models.
We quantify the impact of the latter by measuring
phrase recall on each test portion.
Phrase recall and phrase pair OOV To com-
pute phrase recall, we first automatically word-
</bodyText>
<page confidence="0.974159">
562
</page>
<table confidence="0.999934666666667">
Gen&amp;Topic BLEU Avg.phr. Source phrase recall Src-trg phrase pair recall Phr.pair
portion length 1 2 3 4+ 1 2 3 4+ OOV
NW 19.9 1.45 99.3 81.4 41.8 7.1 73.8 39.4 13.7 1.8 71.5
UG 16.0 1.38 97.2 74.7 36.0 6.3 56.2 28.8 8.7 1.1 76.0
Culture 19.3 1.39 98.2 77.6 36.5 5.3 66.2 35.2 10.7 1.2 74.2
Economy 18.9 1.42 98.4 78.7 39.4 6.5 65.3 33.5 10.9 1.4 73.8
Health 18.8 1.41 98.3 76.6 37.1 5.4 64.5 33.5 11.0 1.2 75.2
Politics 18.2 1.41 98.1 78.6 39.8 7.7 60.8 33.1 11.2 1.5 73.4
Security 18.4 1.42 97.6 77.0 40.2 8.4 62.7 33.3 11.6 1.8 73.3
</table>
<tableCaption confidence="0.999731">
Table 4: Impact of genre and topic differences on various indicators of SMT model quality.
</tableCaption>
<bodyText confidence="0.998550222222222">
align the test set and extract from it a set of ref-
erence phrase pairs using the same procedure ap-
plied to the training data. Then, we count the num-
ber of reference phrase pairs whose source side is
covered by the translation models (source phrase
recall) and the number of reference phrase pairs
that are fully covered by the translation models
(source-target phrase pair recall). Formally, we
define the set of source-matching phrases as:
</bodyText>
<equation confidence="0.606794">
MS = {( ¯f, ¯e)  |( ¯f,-) E Ptest ∧ ( ¯f,-) E Ptrain},
</equation>
<bodyText confidence="0.997027318181818">
where Pd refers to the set of phrase pairs ( f, ¯e)
that can be extracted from corpus d. Source phrase
recall RSn for phrases of length n is then defined as:
where ctest(f, ¯e) denotes the frequency of phrase
pair (¯f, ¯e) in the test set. Analogously, we define
the set of source-target-matching phrase pairs as:
MS,T = {( ¯f, ¯e)  |( ¯f, ¯e) E Ptest ∧ (¯f, ¯e) E Ptrain}
and the source-target phrase pair recall RS,T
n for
phrases of length n as:
Finally, we call phrase pair OOV the portion of
reference phrase pairs that are not covered by the
translation models, that is: 1 - EN n RS,T
n , where
N is the phrase limit used for phrase extraction.
The results of our analysis, broken down by
source phrase length, show that source phrase re-
call is much lower in UG than in NW, while vari-
ations among topics are only very small. The
stronger impact of genre differences is even more
visible on phrase pair recall: for instance, our
system knows the correct translation of 73.8% of
the single-source-word phrase pairs in the NW
genre. In UG this is only 56.2%, despite the equal
amounts of training data per genre in our system.
These figures suggest that model coverage—both
mono- and bilingual—is an important reason for
the low SMT quality on UG data.
Most existing approaches to domain adaptation
focus on domain-sensitive scoring or selection of
existing translation candidates (Matsoukas et al.,
2009; Foster et al., 2010; Axelrod et al., 2011;
Chen et al., 2013, among others). This strat-
egy is supported by the error analysis of Irvine
et al. (2013), who show that scoring errors are
more common across domains than errors caused
by OOVs, in the source as well as the target lan-
guage. Across genres however, our results in Ta-
ble 4 show that both word-level and phrase-level
OOVs are a more likely explanation for the per-
formance differences. This stresses the need to ad-
dress model coverage, for example by paraphras-
ing (Callison-Burch et al., 2006) or translation
synthesis (Irvine and Callison-Burch, 2014).
</bodyText>
<subsectionHeader confidence="0.997746">
4.3 Manual OOV analysis
</subsectionHeader>
<bodyText confidence="0.99992475">
To get a better understanding of the OOVs ob-
served for the genres and topics in the Gen&amp;Topic
set, we perform a fine-grained manual analysis2.
For this analysis a bilingual speaker manually an-
notated 500 sentences on the source side (equally
distributed over genres and topics) to identify the
class of each OOV. Annotations are done for top
and sub-level classes (e.g., replaced letter, which
</bodyText>
<footnote confidence="0.8982645">
2Available with the benchmark data at http://ilps.
science.uva.nl/resources/gen-topic/
</footnote>
<equation confidence="0.982066555555556">
S ¯e)EMS∧|j|=n ctest(
Rn = F-
(¯f,¯e)EPtest∧|¯f |=n ctest(
f, ¯e)
¯f, ¯e), (1)
RS,T = F- ¯e)EMS,T ∧ |f  |=n ctest (
(¯f,¯e)EPtest ∧|¯f |=n ctest(
f, ¯e)
¯f, ¯e) . (2)
</equation>
<page confidence="0.997879">
563
</page>
<table confidence="0.999582666666667">
Arabic OOV English translation Explanation of OOV Main OOV class
•«@X ~New proper noun Rare but correct (Rare)
@ñ‚��J Missing Dialectal future tense Dialectal forms (Dial)
ë Wrong Third person plural present tense Morphological variants (Morph)
�� ISIL blank Spelling errors (Spell)
®K (they) will forget but understandable spelling Colloquialisms (Coll)
àñƒY (they) revere
­� KA �£ñË@Q���¯ñ�K creationofjobs
á��J�«ñ¢�JÖÏ@ volunteeeers
</table>
<tableCaption confidence="0.991103">
Table 5: Examples of OOVs observed in the Gen&amp;Topic set with their respective main OOV class.
</tableCaption>
<table confidence="0.999943">
Gen&amp;Topic Rare Dial OOV type Coll Other
portion Morph Spel
NW 77.8 0.0 16.7 5.6 0.0 0.0
UG 17.2
9.8 9.0 42.6 12.3 9.0
Culture 17.4 0.0 17.4 52.2 8.7 4.3
Economy 0.0
Health
Politics
Security
13.8 34.5 31.0 13.8 6.9
15.8 10.5 15.8 36.8 10.5 10.5
25.0 25.0 12.5 25.0 0.0 12.5
23.5 8.8 5.9 41.2 14.7 5.9
</table>
<tableCaption confidence="0.964341">
Table 6: Error percentages per Gen&amp;Topic por-
</tableCaption>
<bodyText confidence="0.989326730769231">
tion of main OOV classes, see Table 5 for expla-
nation. Other events include words that are not un-
derstandable or occur in the phrase table but only
captured in a different context.
is a subclass of spelling errors). In total, we con-
sider 17 subclasses which we group into five main
classes, see Table 5 for examples.
Table 6 shows the type level percentages3 for
each main OOV class per genre or topic. When
comparing the two genres, a number of observa-
tions emerge. Firstly, rare but correct words (e.g.,
proper nouns and technical terms, both regular is-
sues for adaptation in SMT) make up the vast ma-
jority of the OOVs in NW, but are relatively in-
frequent in UG. By contrast, OOVs containing un-
seen morphological variants are equally common
in both genres. Although complex morphology is
language-specific, a rare morphological word in
Arabic often maps to a rare multi-word phrase in
English, resulting in phrase-level OOVs. Next, not
entirely surprising, the majority of OOVs in UG
are due to spelling errors. Finally, OOVs assigned
to the remaining classes are never observed in NW
but occasionally occur in UG.
Next, a comparison of the main OOV classes
among the various topics shows a few notable
</bodyText>
<footnote confidence="0.973923666666667">
3We also collected token level frequencies which are very
similar to the listed type level statistics, except for a small
number of repeatedly occurring proper nouns.
</footnote>
<bodyText confidence="0.999086846153846">
distributions. Dialectal forms, for example, are
rare in all topics except politics, where they are
commonly observed in the form of Egyptian fu-
ture tense. This can be explained by the presence
of news articles about elections in Egypt in the
Gen&amp;Topic set. Next, while spelling errors are
common in all topics, its abundance is most promi-
nent in culture. Most spelling errors concern miss-
ing or inserted blanks, suggesting that comments
are likely written on mobile devices. Finally, un-
seen morphological variants are more frequent in
economy than in other topics, however with no
conclusive explanation.
</bodyText>
<sectionHeader confidence="0.983739" genericHeader="conclusions">
5 Conclusions and implications
</sectionHeader>
<bodyText confidence="0.999973157894737">
Despite the fact that domain adaptation is an ac-
tive field of research in SMT, there is little con-
sensus on what exactly constitutes a domain. By
introducing and analyzing a new benchmark with
balanced topic and genre distributions, we have
shown that earlier findings explaining the differ-
ences across topics only explain to a limited de-
gree translation performance differences across
genres. Our analysis shows that genre-specific er-
rors are more attributable to model-coverage er-
rors than to suboptimal scoring of existing trans-
lation candidates. This suggests that future work
on improving SMT across genres needs to inves-
tigate approaches that increase model coverage.
Our fine-grained manual error analysis at the word
level also suggests that source coverage could ben-
efit from text normalization (Bertoldi et al., 2010).
Finally, we make both our benchmark and the
manual OOV annotations publicly available.
</bodyText>
<sectionHeader confidence="0.991427" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996551">
This research was funded in part by the Nether-
lands Organization for Scientific Research (NWO)
under project number 639.022.213. We thank
Rachel Cotterill, Nigel Dewdney, and the anony-
mous reviewers for their valuable comments.
</bodyText>
<page confidence="0.997897">
564
</page>
<sectionHeader confidence="0.996346" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999691166666666">
Amittai Axelrod, Xiaodong He, and Jianfeng Gao.
2011. Domain adaptation via pseudo in-domain data
selection. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Process-
ing, pages 355–362.
Nicola Bertoldi, Mauro Cettolo, and Marcello Fed-
erico. 2010. Statistical machine translation of texts
with misspelled words. In HLT ’10: Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 412–419.
Arianna Bisazza and Marcello Federico. 2012. Cutting
the long tail: Hybrid language models for translation
style adaptation. In Proceedings of the 13th Confer-
ence of the European Chapter of the Association for
Computational Linguistics, pages 439–448.
Arianna Bisazza, Nick Ruiz, and Marcello Federico.
2011. Fill-up versus interpolation methods for
phrase-based SMT adaptation. In Proceedings of
the 8th International Workshop on Spoken Language
Translation, pages 136–143.
David Blei, Andrew Ng, and Michael Jordan. 2003.
Latent dirichlet allocation. Journal of Machine
Learning Research, 3:993–1022.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine trans-
lation using paraphrases. In Proceedings of the
Human Language Technology Conference of the
NAACL, Main Conference, pages 17–24.
Stanley F. Chen and Joshua Goodman. 1999. An
empirical study of smoothing techniques for lan-
guage modeling. Computer Speech and Language,
13(4):359–393.
Boxing Chen, Roland Kuhn, and George Foster. 2013.
Vector space model for adaptation in statistical ma-
chine translation. In Proceedings of the 51st Annual
Meeting of the Association for Computational Lin-
guistics, pages 1285–1293.
Kevin Duh, Katsuhito Sudoh, and Hajime Tsukada.
2010. Analysis of translation model adaptation in
statistical machine translation. In Proceedings of
the 7th International Workshop on Spoken Language
Translation (IWSLT 2010), pages 243–250.
Vladimir Eidelman, Jordan Boyd-Graber, and Philip
Resnik. 2012. Topic models for dynamic translation
model adaptation. In Proceedings of the 50th An-
nual Meeting of the Association for Computational
Linguistics, pages 115–119.
George Foster and Roland Kuhn. 2007. Mixture-
model adaptation for SMT. In Proceedings of the
Second Workshop on Statistical Machine Transla-
tion, pages 128–135.
George Foster, Cyril Goutte, and Roland Kuhn. 2010.
Discriminative instance weighting for domain adap-
tation in statistical machine translation. In Proceed-
ings of the 2010 Conference on Empirical Methods
in Natural Language Processing, pages 451–459.
Barry Haddow and Philipp Koehn. 2012. Analysing
the effect of out-of-domain data on SMT systems. In
Proceedings of the Seventh Workshop on Statistical
Machine Translation, pages 422–432.
Eva Hasler, Phil Blunsom, Philipp Koehn, and Barry
Haddow. 2014a. Dynamic topic adaptation for
phrase-based MT. In Proceedings of the 14th Con-
ference of the European Chapter of The Association
for Computational Linguistics, pages 328–337.
Eva Hasler, Barry Haddow, and Philipp Koehn. 2014b.
Combining domain and topic adaptation for SMT.
In Proceedings of the 11th Conference of the As-
sociation for Machine Translation in the Americas,
pages 139–151.
Eva Hasler, Barry Haddow, and Philipp Koehn. 2014c.
Dynamic topic adaptation for SMT using distribu-
tional profiles. In Proceedings of the Ninth Work-
shop on Statistical Machine Translation, pages 445–
456.
Sanjika Hewavitharana, Dennis Mehay, Sankara-
narayanan Ananthakrishnan, and Prem Natarajan.
2013. Incremental topic-based translation model
adaptation for conversational spoken language trans-
lation. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 697–701.
Mark Hopkins and Jonathan May. 2011. Tuning as
ranking. In Proceedings of the 2011 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 1352–1362. Association for Compu-
tational Linguistics.
Ann Irvine and Chris Callison-Burch. 2014. Halluci-
nating phrase translations for low resource MT. In
Proceedings of the Eighteenth Conference on Com-
putational Natural Language Learning, pages 160–
170.
Ann Irvine, John Morgan, Marine Carpuat, Hal
Daum´e III, and Dragos Stefan Munteanu. 2013.
Measuring machine translation errors in new do-
mains. Transactions of the Association for Compu-
tational Linguistics, 1:429–440.
Jussi Karlgren. 2004. The wheres and whyfores for
studying text genre computationally. In Workshop
on Style and Meaning in Language, Art, Music, and
Design.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
</reference>
<page confidence="0.982124">
565
</page>
<reference confidence="0.998014465116279">
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
pages 177–180.
Yong-Bae Lee and Sung Hyon Myaeng. 2002.
Text genre classification with genre-revealing and
subject-revealing features. In Proceedings of the
25th annual international ACM SIGIR conference
on Research and development in information re-
trieval, pages 145–150.
David Y.W. Lee. 2001. Genres, registers, text types,
domains and styles: Clarifying the concepts and
navigating a path through the BNC jungle. Lan-
guage Learning &amp; Technology, 5(3):37–72.
Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing
Zhang. 2009. Discriminative corpus weight estima-
tion for machine translation. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, pages 708–717.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics, pages 311–318.
Marina Santini. 2004. State-of-the-art on automatic
genre identification. Technical Report ITRI-04-03,
Information Technology Research Institute, Univer-
sity of Brighton.
Rico Sennrich. 2012. Perplexity minimization for
translation model domain adaptation in statistical
machine translation. In Proceedings of the 13th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 539–549.
Benno Stein and Sven Meyer Zu Eissen. 2006. Distin-
guishing topic from genre. In Proceedings of the
6th International Conference on Knowledge Man-
agement (I-KNOW 06), pages 449–456.
John M. Swales. 1990. Genre Analysis. Cambridge
University Press., Cambridge, UK.
Marlies van der Wees, Arianna Bisazza, and Christof
Monz. 2015. Five shades of noise: analyzing ma-
chine translation errors in user-generated text. In
Proceedings of the ACL 2015 Workshop on Noisy
User-generated Text.
</reference>
<page confidence="0.998455">
566
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.692386">
<title confidence="0.998864">What’s in a Domain? Analyzing Genre and Topic in Statistical Machine Translation</title>
<author confidence="0.999434">van_der_Wees Arianna Bisazza Wouter Monz</author>
<affiliation confidence="0.9996195">Informatics Institute University of Amsterdam</affiliation>
<email confidence="0.850311">♦904Labs,wouter@904labs.com</email>
<abstract confidence="0.999466882352941">Domain adaptation is an active field of research in statistical machine translation (SMT), but so far most work has ignored distinction between the of documents. In this paper we quantify and disentangle the impact of genre and topic differences on translation quality by introducing a new data set that has controlled topic and genre distributions. In addition, we perform a detailed analysis showing that differences across topics only explain to a limited degree translation performance differences across genres, and that genre-specific errors are more attributable to model coverage than to suboptimal scoring of translation candidates.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amittai Axelrod</author>
<author>Xiaodong He</author>
<author>Jianfeng Gao</author>
</authors>
<title>Domain adaptation via pseudo in-domain data selection.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>355--362</pages>
<contexts>
<context position="14731" citStr="Axelrod et al., 2011" startWordPosition="2417" endWordPosition="2420"> The stronger impact of genre differences is even more visible on phrase pair recall: for instance, our system knows the correct translation of 73.8% of the single-source-word phrase pairs in the NW genre. In UG this is only 56.2%, despite the equal amounts of training data per genre in our system. These figures suggest that model coverage—both mono- and bilingual—is an important reason for the low SMT quality on UG data. Most existing approaches to domain adaptation focus on domain-sensitive scoring or selection of existing translation candidates (Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011; Chen et al., 2013, among others). This strategy is supported by the error analysis of Irvine et al. (2013), who show that scoring errors are more common across domains than errors caused by OOVs, in the source as well as the target language. Across genres however, our results in Table 4 show that both word-level and phrase-level OOVs are a more likely explanation for the performance differences. This stresses the need to address model coverage, for example by paraphrasing (Callison-Burch et al., 2006) or translation synthesis (Irvine and Callison-Burch, 2014). 4.3 Manual OOV analysis To get </context>
</contexts>
<marker>Axelrod, He, Gao, 2011</marker>
<rawString>Amittai Axelrod, Xiaodong He, and Jianfeng Gao. 2011. Domain adaptation via pseudo in-domain data selection. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 355–362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
<author>Marcello Federico</author>
</authors>
<title>Statistical machine translation of texts with misspelled words.</title>
<date>2010</date>
<booktitle>In HLT ’10: Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>412--419</pages>
<marker>Bertoldi, Cettolo, Federico, 2010</marker>
<rawString>Nicola Bertoldi, Mauro Cettolo, and Marcello Federico. 2010. Statistical machine translation of texts with misspelled words. In HLT ’10: Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 412–419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arianna Bisazza</author>
<author>Marcello Federico</author>
</authors>
<title>Cutting the long tail: Hybrid language models for translation style adaptation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>439--448</pages>
<contexts>
<context position="5298" citStr="Bisazza and Federico, 2012" startWordPosition="832" endWordPosition="836">m genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set where both dimensions are controlled as much</context>
</contexts>
<marker>Bisazza, Federico, 2012</marker>
<rawString>Arianna Bisazza and Marcello Federico. 2012. Cutting the long tail: Hybrid language models for translation style adaptation. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 439–448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arianna Bisazza</author>
<author>Nick Ruiz</author>
<author>Marcello Federico</author>
</authors>
<title>Fill-up versus interpolation methods for phrase-based SMT adaptation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 8th International Workshop on Spoken Language Translation,</booktitle>
<pages>136--143</pages>
<contexts>
<context position="5254" citStr="Bisazza et al., 2011" startWordPosition="826" endWordPosition="829"> Santini (2004) concludes that the term genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set </context>
</contexts>
<marker>Bisazza, Ruiz, Federico, 2011</marker>
<rawString>Arianna Bisazza, Nick Ruiz, and Marcello Federico. 2011. Fill-up versus interpolation methods for phrase-based SMT adaptation. In Proceedings of the 8th International Workshop on Spoken Language Translation, pages 136–143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Andrew Ng</author>
<author>Michael Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="5565" citStr="Blei et al., 2003" startWordPosition="876" endWordPosition="879">d newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set where both dimensions are controlled as much as possible. Unfortunately, currently available and commonly used benchmarks meet this requirement only to a limited degree. For instance, while the NIST OpenMT sets do contain documents drawn from two genres, newswire and web, both genres exhibit a different distri</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David Blei, Andrew Ng, and Michael Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="15239" citStr="Callison-Burch et al., 2006" startWordPosition="2506" endWordPosition="2509">oring or selection of existing translation candidates (Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011; Chen et al., 2013, among others). This strategy is supported by the error analysis of Irvine et al. (2013), who show that scoring errors are more common across domains than errors caused by OOVs, in the source as well as the target language. Across genres however, our results in Table 4 show that both word-level and phrase-level OOVs are a more likely explanation for the performance differences. This stresses the need to address model coverage, for example by paraphrasing (Callison-Burch et al., 2006) or translation synthesis (Irvine and Callison-Burch, 2014). 4.3 Manual OOV analysis To get a better understanding of the OOVs observed for the genres and topics in the Gen&amp;Topic set, we perform a fine-grained manual analysis2. For this analysis a bilingual speaker manually annotated 500 sentences on the source side (equally distributed over genres and topics) to identify the class of each OOV. Annotations are done for top and sub-level classes (e.g., replaced letter, which 2Available with the benchmark data at http://ilps. science.uva.nl/resources/gen-topic/ S ¯e)EMS∧|j|=n ctest( Rn = F(¯f,¯e</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1999</date>
<journal>Computer Speech and Language,</journal>
<volume>13</volume>
<issue>4</issue>
<contexts>
<context position="9050" citStr="Chen and Goodman, 1999" startWordPosition="1445" endWordPosition="1448"> genre and topic differences on SMT To quantify the impact of multiple genres and topics in a test corpus, we run a series of experiments in which we measure translation quality, model coverage, and observed OOV types. 4.1 Translation quality We first run a translation experiment on the Gen&amp;Topic test set using our in-house phrasebased SMT system similar to Moses (Koehn et al., 2007). Features include lexicalized reordering, linear distortion with limit 5, and lexical weighting. In addition, we use a 5-gram linearly interpolated language model, trained on 1.6B words with Kneser-Ney smoothing (Chen and Goodman, 1999), that covers all topics and genres contained in the benchmark. We tune our system on the Gen&amp;Topic development set using pairwise ranking optimization (PRO) (Hopkins and May, 2011). Naturally, performance differences across topics and genres depend on the degree to which both are represented in the parallel training data. To allow for fair comparison, we down-sample our available training data to be as balanced as possible in terms of topics and genres. The resulting system is trained on approximately 200K sentence pairs with 6M source tokens per genre, as much as is available for UG. All dat</context>
</contexts>
<marker>Chen, Goodman, 1999</marker>
<rawString>Stanley F. Chen and Joshua Goodman. 1999. An empirical study of smoothing techniques for language modeling. Computer Speech and Language, 13(4):359–393.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boxing Chen</author>
<author>Roland Kuhn</author>
<author>George Foster</author>
</authors>
<title>Vector space model for adaptation in statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1285--1293</pages>
<contexts>
<context position="14750" citStr="Chen et al., 2013" startWordPosition="2421" endWordPosition="2424">f genre differences is even more visible on phrase pair recall: for instance, our system knows the correct translation of 73.8% of the single-source-word phrase pairs in the NW genre. In UG this is only 56.2%, despite the equal amounts of training data per genre in our system. These figures suggest that model coverage—both mono- and bilingual—is an important reason for the low SMT quality on UG data. Most existing approaches to domain adaptation focus on domain-sensitive scoring or selection of existing translation candidates (Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011; Chen et al., 2013, among others). This strategy is supported by the error analysis of Irvine et al. (2013), who show that scoring errors are more common across domains than errors caused by OOVs, in the source as well as the target language. Across genres however, our results in Table 4 show that both word-level and phrase-level OOVs are a more likely explanation for the performance differences. This stresses the need to address model coverage, for example by paraphrasing (Callison-Burch et al., 2006) or translation synthesis (Irvine and Callison-Burch, 2014). 4.3 Manual OOV analysis To get a better understand</context>
</contexts>
<marker>Chen, Kuhn, Foster, 2013</marker>
<rawString>Boxing Chen, Roland Kuhn, and George Foster. 2013. Vector space model for adaptation in statistical machine translation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1285–1293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
</authors>
<title>Analysis of translation model adaptation in statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Workshop on Spoken Language Translation (IWSLT</booktitle>
<pages>243--250</pages>
<contexts>
<context position="5232" citStr="Duh et al., 2010" startWordPosition="822" endWordPosition="825">vious definitions, Santini (2004) concludes that the term genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SM</context>
</contexts>
<marker>Duh, Sudoh, Tsukada, 2010</marker>
<rawString>Kevin Duh, Katsuhito Sudoh, and Hajime Tsukada. 2010. Analysis of translation model adaptation in statistical machine translation. In Proceedings of the 7th International Workshop on Spoken Language Translation (IWSLT 2010), pages 243–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Eidelman</author>
<author>Jordan Boyd-Graber</author>
<author>Philip Resnik</author>
</authors>
<title>Topic models for dynamic translation model adaptation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>115--119</pages>
<contexts>
<context position="5438" citStr="Eidelman et al., 2012" startWordPosition="855" endWordPosition="858"> can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set where both dimensions are controlled as much as possible. Unfortunately, currently available and commonly used benchmarks meet this requirement only to a limited degree. For instance, </context>
</contexts>
<marker>Eidelman, Boyd-Graber, Resnik, 2012</marker>
<rawString>Vladimir Eidelman, Jordan Boyd-Graber, and Philip Resnik. 2012. Topic models for dynamic translation model adaptation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 115–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Mixturemodel adaptation for SMT.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>128--135</pages>
<contexts>
<context position="5214" citStr="Foster and Kuhn, 2007" startWordPosition="817" endWordPosition="821">ed. 2004). Based on previous definitions, Santini (2004) concludes that the term genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic</context>
</contexts>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. 2007. Mixturemodel adaptation for SMT. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 128–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Cyril Goutte</author>
<author>Roland Kuhn</author>
</authors>
<title>Discriminative instance weighting for domain adaptation in statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>451--459</pages>
<contexts>
<context position="14709" citStr="Foster et al., 2010" startWordPosition="2413" endWordPosition="2416"> are only very small. The stronger impact of genre differences is even more visible on phrase pair recall: for instance, our system knows the correct translation of 73.8% of the single-source-word phrase pairs in the NW genre. In UG this is only 56.2%, despite the equal amounts of training data per genre in our system. These figures suggest that model coverage—both mono- and bilingual—is an important reason for the low SMT quality on UG data. Most existing approaches to domain adaptation focus on domain-sensitive scoring or selection of existing translation candidates (Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011; Chen et al., 2013, among others). This strategy is supported by the error analysis of Irvine et al. (2013), who show that scoring errors are more common across domains than errors caused by OOVs, in the source as well as the target language. Across genres however, our results in Table 4 show that both word-level and phrase-level OOVs are a more likely explanation for the performance differences. This stresses the need to address model coverage, for example by paraphrasing (Callison-Burch et al., 2006) or translation synthesis (Irvine and Callison-Burch, 2014). 4.3 Manua</context>
</contexts>
<marker>Foster, Goutte, Kuhn, 2010</marker>
<rawString>George Foster, Cyril Goutte, and Roland Kuhn. 2010. Discriminative instance weighting for domain adaptation in statistical machine translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 451–459.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barry Haddow</author>
<author>Philipp Koehn</author>
</authors>
<title>Analysing the effect of out-of-domain data on SMT systems.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>422--432</pages>
<contexts>
<context position="5322" citStr="Haddow and Koehn, 2012" startWordPosition="837" endWordPosition="840"> complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set where both dimensions are controlled as much as possible. Unfortunat</context>
</contexts>
<marker>Haddow, Koehn, 2012</marker>
<rawString>Barry Haddow and Philipp Koehn. 2012. Analysing the effect of out-of-domain data on SMT systems. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 422–432.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva Hasler</author>
<author>Phil Blunsom</author>
<author>Philipp Koehn</author>
<author>Barry Haddow</author>
</authors>
<title>Dynamic topic adaptation for phrase-based MT.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of The Association for Computational Linguistics,</booktitle>
<pages>328--337</pages>
<contexts>
<context position="5487" citStr="Hasler et al., 2014" startWordPosition="863" endWordPosition="866">Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set where both dimensions are controlled as much as possible. Unfortunately, currently available and commonly used benchmarks meet this requirement only to a limited degree. For instance, while the NIST OpenMT sets do contain documents d</context>
</contexts>
<marker>Hasler, Blunsom, Koehn, Haddow, 2014</marker>
<rawString>Eva Hasler, Phil Blunsom, Philipp Koehn, and Barry Haddow. 2014a. Dynamic topic adaptation for phrase-based MT. In Proceedings of the 14th Conference of the European Chapter of The Association for Computational Linguistics, pages 328–337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva Hasler</author>
<author>Barry Haddow</author>
<author>Philipp Koehn</author>
</authors>
<title>Combining domain and topic adaptation for SMT.</title>
<date>2014</date>
<booktitle>In Proceedings of the 11th Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>139--151</pages>
<contexts>
<context position="5487" citStr="Hasler et al., 2014" startWordPosition="863" endWordPosition="866">Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set where both dimensions are controlled as much as possible. Unfortunately, currently available and commonly used benchmarks meet this requirement only to a limited degree. For instance, while the NIST OpenMT sets do contain documents d</context>
</contexts>
<marker>Hasler, Haddow, Koehn, 2014</marker>
<rawString>Eva Hasler, Barry Haddow, and Philipp Koehn. 2014b. Combining domain and topic adaptation for SMT. In Proceedings of the 11th Conference of the Association for Machine Translation in the Americas, pages 139–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva Hasler</author>
<author>Barry Haddow</author>
<author>Philipp Koehn</author>
</authors>
<title>Dynamic topic adaptation for SMT using distributional profiles.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth Workshop on Statistical Machine Translation,</booktitle>
<pages>445--456</pages>
<contexts>
<context position="5487" citStr="Hasler et al., 2014" startWordPosition="863" endWordPosition="866">Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set where both dimensions are controlled as much as possible. Unfortunately, currently available and commonly used benchmarks meet this requirement only to a limited degree. For instance, while the NIST OpenMT sets do contain documents d</context>
</contexts>
<marker>Hasler, Haddow, Koehn, 2014</marker>
<rawString>Eva Hasler, Barry Haddow, and Philipp Koehn. 2014c. Dynamic topic adaptation for SMT using distributional profiles. In Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 445– 456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanjika Hewavitharana</author>
<author>Dennis Mehay</author>
<author>Sankaranarayanan Ananthakrishnan</author>
<author>Prem Natarajan</author>
</authors>
<title>Incremental topic-based translation model adaptation for conversational spoken language translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>697--701</pages>
<contexts>
<context position="5466" citStr="Hewavitharana et al., 2013" startWordPosition="859" endWordPosition="862">rent levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set where both dimensions are controlled as much as possible. Unfortunately, currently available and commonly used benchmarks meet this requirement only to a limited degree. For instance, while the NIST OpenMT sets d</context>
</contexts>
<marker>Hewavitharana, Mehay, Ananthakrishnan, Natarajan, 2013</marker>
<rawString>Sanjika Hewavitharana, Dennis Mehay, Sankaranarayanan Ananthakrishnan, and Prem Natarajan. 2013. Incremental topic-based translation model adaptation for conversational spoken language translation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 697–701.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hopkins</author>
<author>Jonathan May</author>
</authors>
<title>Tuning as ranking.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1352--1362</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9231" citStr="Hopkins and May, 2011" startWordPosition="1474" endWordPosition="1477">el coverage, and observed OOV types. 4.1 Translation quality We first run a translation experiment on the Gen&amp;Topic test set using our in-house phrasebased SMT system similar to Moses (Koehn et al., 2007). Features include lexicalized reordering, linear distortion with limit 5, and lexical weighting. In addition, we use a 5-gram linearly interpolated language model, trained on 1.6B words with Kneser-Ney smoothing (Chen and Goodman, 1999), that covers all topics and genres contained in the benchmark. We tune our system on the Gen&amp;Topic development set using pairwise ranking optimization (PRO) (Hopkins and May, 2011). Naturally, performance differences across topics and genres depend on the degree to which both are represented in the parallel training data. To allow for fair comparison, we down-sample our available training data to be as balanced as possible in terms of topics and genres. The resulting system is trained on approximately 200K sentence pairs with 6M source tokens per genre, as much as is available for UG. All data originates from the same web sources as the documents in the benchmark. Our more competitive system (van der Wees et al., 2015) that uses also LDC-distributed data yields slightly</context>
</contexts>
<marker>Hopkins, May, 2011</marker>
<rawString>Mark Hopkins and Jonathan May. 2011. Tuning as ranking. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1352–1362. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Irvine</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Hallucinating phrase translations for low resource MT.</title>
<date>2014</date>
<booktitle>In Proceedings of the Eighteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>160--170</pages>
<contexts>
<context position="15298" citStr="Irvine and Callison-Burch, 2014" startWordPosition="2513" endWordPosition="2516">Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011; Chen et al., 2013, among others). This strategy is supported by the error analysis of Irvine et al. (2013), who show that scoring errors are more common across domains than errors caused by OOVs, in the source as well as the target language. Across genres however, our results in Table 4 show that both word-level and phrase-level OOVs are a more likely explanation for the performance differences. This stresses the need to address model coverage, for example by paraphrasing (Callison-Burch et al., 2006) or translation synthesis (Irvine and Callison-Burch, 2014). 4.3 Manual OOV analysis To get a better understanding of the OOVs observed for the genres and topics in the Gen&amp;Topic set, we perform a fine-grained manual analysis2. For this analysis a bilingual speaker manually annotated 500 sentences on the source side (equally distributed over genres and topics) to identify the class of each OOV. Annotations are done for top and sub-level classes (e.g., replaced letter, which 2Available with the benchmark data at http://ilps. science.uva.nl/resources/gen-topic/ S ¯e)EMS∧|j|=n ctest( Rn = F(¯f,¯e)EPtest∧|¯f |=n ctest( f, ¯e) ¯f, ¯e), (1) RS,T = F- ¯e)EMS</context>
</contexts>
<marker>Irvine, Callison-Burch, 2014</marker>
<rawString>Ann Irvine and Chris Callison-Burch. 2014. Hallucinating phrase translations for low resource MT. In Proceedings of the Eighteenth Conference on Computational Natural Language Learning, pages 160– 170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Irvine</author>
<author>John Morgan</author>
<author>Marine Carpuat</author>
<author>Hal Daum´e</author>
<author>Dragos Stefan Munteanu</author>
</authors>
<title>Measuring machine translation errors in new domains.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--429</pages>
<marker>Irvine, Morgan, Carpuat, Daum´e, Munteanu, 2013</marker>
<rawString>Ann Irvine, John Morgan, Marine Carpuat, Hal Daum´e III, and Dragos Stefan Munteanu. 2013. Measuring machine translation errors in new domains. Transactions of the Association for Computational Linguistics, 1:429–440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jussi Karlgren</author>
</authors>
<title>The wheres and whyfores for studying text genre computationally.</title>
<date>2004</date>
<booktitle>In Workshop on Style and Meaning in Language,</booktitle>
<location>Art, Music, and Design.</location>
<marker>Karlgren, 2004</marker>
<rawString>Jussi Karlgren. 2004. The wheres and whyfores for studying text genre computationally. In Workshop on Style and Meaning in Language, Art, Music, and Design.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondˇrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions,</booktitle>
<pages>177--180</pages>
<location>Alexandra</location>
<contexts>
<context position="8813" citStr="Koehn et al., 2007" startWordPosition="1410" endWordPosition="1413">ownload1. NW UG All Culture 19.2 17.6 19.3 ⎫ Economy 19.9 15.9 18.9 ⎪⎪ Health 19.3 17.7 18.8 ⎬ ⎪ Politics 21.3 13.6 18.2 Avg. diff.: ±0.6 Security 19.3 16.2 18.5 ⎪ ⎭⎪⎪ All 19.9 16.0 18.9 v Avg. diff.: ±3.9 4 Quantifying the impact of genre and topic differences on SMT To quantify the impact of multiple genres and topics in a test corpus, we run a series of experiments in which we measure translation quality, model coverage, and observed OOV types. 4.1 Translation quality We first run a translation experiment on the Gen&amp;Topic test set using our in-house phrasebased SMT system similar to Moses (Koehn et al., 2007). Features include lexicalized reordering, linear distortion with limit 5, and lexical weighting. In addition, we use a 5-gram linearly interpolated language model, trained on 1.6B words with Kneser-Ney smoothing (Chen and Goodman, 1999), that covers all topics and genres contained in the benchmark. We tune our system on the Gen&amp;Topic development set using pairwise ranking optimization (PRO) (Hopkins and May, 2011). Naturally, performance differences across topics and genres depend on the degree to which both are represented in the parallel training data. To allow for fair comparison, we down-</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yong-Bae Lee</author>
<author>Sung Hyon Myaeng</author>
</authors>
<title>Text genre classification with genre-revealing and subject-revealing features.</title>
<date>2002</date>
<booktitle>In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>145--150</pages>
<contexts>
<context position="1790" citStr="Lee and Myaeng, 2002" startWordPosition="266" endWordPosition="269">lary. The test set, on the other hand, is much smaller and usually more homogeneous. The resulting mismatch between the test data and the majority of the training data can lead to suboptimal translation performance. In such situations, it is beneficial to adapt the translation system to the translation task at hand, which is exactly the challenge of domain adaptation in SMT. The concept of a domain, however, is not unambiguously defined across existing domain adaptation methods. Commonly used interpretations of domains neglect the fact that topic and genre are two distinct properties of text (Lee and Myaeng, 2002; Stein and Meyer Zu Eissen, 2006). Two texts can discuss a similar topic, but using different styles. Since most work on domain adaptation in SMT uses in-domain and out-of-domain data that differ on both the topic and the genre level, it is unclear whether the proposed solutions address topic or genre differences. In this work we take a step back and disentangle the concepts topic and genre, then we analyze and quantify their effect on SMT, which we believe is a necessary step towards further improving domain adaptation for SMT. Concretely, we address the following questions: (i) Can we clari</context>
</contexts>
<marker>Lee, Myaeng, 2002</marker>
<rawString>Yong-Bae Lee and Sung Hyon Myaeng. 2002. Text genre classification with genre-revealing and subject-revealing features. In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, pages 145–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Y W Lee</author>
</authors>
<title>Genres, registers, text types, domains and styles: Clarifying the concepts and navigating a path through the BNC jungle.</title>
<date>2001</date>
<journal>Language Learning &amp; Technology,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="4878" citStr="Lee, 2001" startWordPosition="770" endWordPosition="771">king about? We will continue to call for freedom until independence and liberation and the routing of the northern occupation from our lands. Table 1: English-side samples from the Gen&amp;Topic data set. All pairs of newswire (NW) and usergenerated (UG) fragments in the data set discuss the same article and are topically related. 2004). Based on previous definitions, Santini (2004) concludes that the term genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et </context>
</contexts>
<marker>Lee, 2001</marker>
<rawString>David Y.W. Lee. 2001. Genres, registers, text types, domains and styles: Clarifying the concepts and navigating a path through the BNC jungle. Language Learning &amp; Technology, 5(3):37–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spyros Matsoukas</author>
<author>Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
</authors>
<title>Discriminative corpus weight estimation for machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>708--717</pages>
<contexts>
<context position="14688" citStr="Matsoukas et al., 2009" startWordPosition="2409" endWordPosition="2412"> variations among topics are only very small. The stronger impact of genre differences is even more visible on phrase pair recall: for instance, our system knows the correct translation of 73.8% of the single-source-word phrase pairs in the NW genre. In UG this is only 56.2%, despite the equal amounts of training data per genre in our system. These figures suggest that model coverage—both mono- and bilingual—is an important reason for the low SMT quality on UG data. Most existing approaches to domain adaptation focus on domain-sensitive scoring or selection of existing translation candidates (Matsoukas et al., 2009; Foster et al., 2010; Axelrod et al., 2011; Chen et al., 2013, among others). This strategy is supported by the error analysis of Irvine et al. (2013), who show that scoring errors are more common across domains than errors caused by OOVs, in the source as well as the target language. Across genres however, our results in Table 4 show that both word-level and phrase-level OOVs are a more likely explanation for the performance differences. This stresses the need to address model coverage, for example by paraphrasing (Callison-Burch et al., 2006) or translation synthesis (Irvine and Callison-Bu</context>
</contexts>
<marker>Matsoukas, Rosti, Zhang, 2009</marker>
<rawString>Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing Zhang. 2009. Discriminative corpus weight estimation for machine translation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 708–717.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="10165" citStr="Papineni et al., 2002" startWordPosition="1630" endWordPosition="1633">approximately 200K sentence pairs with 6M source tokens per genre, as much as is available for UG. All data originates from the same web sources as the documents in the benchmark. Our more competitive system (van der Wees et al., 2015) that uses also LDC-distributed data yields slightly higher BLEU scores, but is more favorable for NW than for UG translation tasks. Due to the strict data requirements in terms of topic and genre distributions, as well as the availability of sizable parallel training data, our current experimental set-up covers Arabic-English only. Table 3 compares BLEU scores (Papineni et al., 2002, 1 reference) of the Gen&amp;Topic data, split down by topics and genres. We observe that trans1http://ilps.science.uva.nl/resources/ gen-topic/ Table 3: Arabic-to-English BLEU scores on the Gen&amp;Topic test set (1 reference translation) per topic-genre combination. Tuning was done on the complete Gen&amp;Topic development set. Variations in translation quality are represented by average pairwise BLEU score differences. lation performance fluctuates much more across genres than across topics: There is a large gap of 3.9 BLEU points between NW and UG, which can be entirely attributed to actual genre dif</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina Santini</author>
</authors>
<title>State-of-the-art on automatic genre identification.</title>
<date>2004</date>
<tech>Technical Report ITRI-04-03,</tech>
<institution>Information Technology Research Institute, University of Brighton.</institution>
<contexts>
<context position="4649" citStr="Santini (2004)" startWordPosition="734" endWordPosition="735">sings in Kurdish!!! Economy Yemen is mulling the establishment of 13 industrial zones across its six planned administrative regions in a bid to stimulate development and create job opportunities. What development in Yemen are you talking about? We will continue to call for freedom until independence and liberation and the routing of the northern occupation from our lands. Table 1: English-side samples from the Gen&amp;Topic data set. All pairs of newswire (NW) and usergenerated (UG) fragments in the data set discuss the same article and are topically related. 2004). Based on previous definitions, Santini (2004) concludes that the term genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al.,</context>
</contexts>
<marker>Santini, 2004</marker>
<rawString>Marina Santini. 2004. State-of-the-art on automatic genre identification. Technical Report ITRI-04-03, Information Technology Research Institute, University of Brighton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rico Sennrich</author>
</authors>
<title>Perplexity minimization for translation model domain adaptation in statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>539--549</pages>
<contexts>
<context position="5270" citStr="Sennrich, 2012" startWordPosition="830" endWordPosition="831">des that the term genre is used as a concept complementary to topic, covering the non-topical text properties function, style, and text type. Like topics, genres can also exhibit different levels of granularity (Lee, 2001). Examples of genres include formal or informal text (high-level), and newswire, editorials, and user-generated text (low-level). Topic and genre are both intrinsic properties of texts, but most work on domain adaptation uses provenance or subcorpus information to adapt SMT systems to a specific translation task (Foster and Kuhn, 2007; Duh et al., 2010; Bisazza et al., 2011; Sennrich, 2012; Bisazza and Federico, 2012; Haddow and Koehn, 2012, among others). In recent years, some work has explicitly addressed topic adaptation for SMT (Eidelman et al., 2012; Hewavitharana et al., 2013; Hasler et al., 2014a; Hasler et al., 2014c) using latent Dirichlet allocation (Blei et al., 2003). While Hasler et al. (2014b) showed that provenance and topic can serve as complements to each other, the effects of genre and topic on SMT have not been systematically studied. 3 The Gen&amp;Topic benchmark set To analyze the impact of genre and topic differences in SMT, we need a test set where both dimen</context>
</contexts>
<marker>Sennrich, 2012</marker>
<rawString>Rico Sennrich. 2012. Perplexity minimization for translation model domain adaptation in statistical machine translation. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 539–549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benno Stein</author>
<author>Sven Meyer Zu Eissen</author>
</authors>
<title>Distinguishing topic from genre.</title>
<date>2006</date>
<booktitle>In Proceedings of the 6th International Conference on Knowledge Management (I-KNOW 06),</booktitle>
<pages>449--456</pages>
<marker>Stein, Eissen, 2006</marker>
<rawString>Benno Stein and Sven Meyer Zu Eissen. 2006. Distinguishing topic from genre. In Proceedings of the 6th International Conference on Knowledge Management (I-KNOW 06), pages 449–456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Swales</author>
</authors>
<title>Genre Analysis.</title>
<date>1990</date>
<publisher>Cambridge University Press.,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="3440" citStr="Swales, 1990" startWordPosition="549" endWordPosition="550">f the impact of topic and genre differences on SMT. 2 Topic and genre differences in SMT The definition of a domain varies across work on domain adaptation and is often imprecise. In this work we avoid using this ambiguous term, and instead focus on the text properties topic and genre. Topic is the general subject of a document. Topics can be determined on multiple levels, ranging from very broad to more detailed. Examples of topics include sports, politics, and science (high-level), or football and tennis (low-level). Genre is harder to define, as there is no single definition in literature (Swales, 1990; Karlgren, 560 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 560–566, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Topic Newswire sentence User-generated sentence Culture The 12 contestants competed during a May 3rd Prime before a panel of judges and millions of viewers across the Arab world. Your program’s name is “Arab Idol”, which is in English, and you allowed Barwas to participate and represent Iraq while she sings</context>
</contexts>
<marker>Swales, 1990</marker>
<rawString>John M. Swales. 1990. Genre Analysis. Cambridge University Press., Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marlies van der Wees</author>
<author>Arianna Bisazza</author>
<author>Christof Monz</author>
</authors>
<title>Five shades of noise: analyzing machine translation errors in user-generated text.</title>
<date>2015</date>
<booktitle>In Proceedings of the ACL 2015 Workshop on Noisy User-generated Text.</booktitle>
<marker>van der Wees, Bisazza, Monz, 2015</marker>
<rawString>Marlies van der Wees, Arianna Bisazza, and Christof Monz. 2015. Five shades of noise: analyzing machine translation errors in user-generated text. In Proceedings of the ACL 2015 Workshop on Noisy User-generated Text.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>