<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009262">
<title confidence="0.8592404">
Prosodic turn-yielding Cues with and without optical Feedback
Caroline Clemens
Technische Universität Berlin
Deutsche Telekom Laboratories
Ernst-Reuter-Platz 7
</title>
<address confidence="0.589658">
10587 Berlin
</address>
<email confidence="0.989968">
Caroline.Clemens@telekom.de
</email>
<sectionHeader confidence="0.99364" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999599764705882">
The authors present a study of prosodic
turn-taking indicators. The aim was to
investigate whether some of the prosodic
cues increase in quality or quantity if the
optical feedback channel in the verbal
conversation is missing. For the study we
built up an experimental setup in which
conversational partners held a conversa-
tion once with and once without an opti-
cal feedback channel. A detailed tran-
scription of the recorded speech material
was segmented into turns. In each turn
the topic units were identified and the
syllables were labelled. We measured
and compared prosodic feature character-
istics between turn-final and turn-medial
topic units.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99990885">
In a verbal conversation the roles of speaker and
listener have to be defined. Sacks et al. (1974)
stated “minimize gap and overlap” as the first
rule for a working turn-taking-mechanism.
According to them, the end of turn has to be
marked in some way. Since linguistic cues are
rarely found, it is obvious that this marking has
to be realized by prosodic features. This
supposition was corroborated by the findings of
Lehiste (1975), that listeners got the ability to
identify the position of clauses within a turn,
even if the clauses were represented in isolation.
In the speaker’s turn several prosodic cues are
presumed to indicate to the listener whether the
speaker wants to keep or end the turn. At points
with high speaker switch potential noticeable
gestural and mimic cues can be found. It is
unknown how important those non-verbal
aspects are for the turn-taking indication. The
main research question of the presented study is:
</bodyText>
<subsectionHeader confidence="0.9840606">
Christoph Diekhaus
Technische Universität Berlin
Department f. Language and Communication
Straße des 17. Juni 135
10623 Berlin
</subsectionHeader>
<bodyText confidence="0.990816">
c.diekhaus@alice-dsl.net
Do prosodic cues compensate if the optical
feedback channel is missing in the verbal
conversation?
</bodyText>
<sectionHeader confidence="0.9065725" genericHeader="introduction">
2 Prosodic and non-verbal turn-taking
indicators
</sectionHeader>
<bodyText confidence="0.999903766666667">
Duncan (1972) sorted turn-taking signals by their
function. He classified the signals as turn-
yielding, turn-demanding (listener), attempt-
suppressing, and back-channel-communication
(listener response).
We focused on turn-yielding as those signals
are easy to locate, and because most found pro-
sodic and non-verbal cues belong to this class.
Beattie (1981) and Oreström (1983) showed that
a noticeable rising or falling movement of fun-
damental frequency acts as a prosodic turn-
yielding cue. According to Oreström (1983), the
final syllable of the turn is lengthened and some-
times the syllable frequency is increased. Duncan
(1972) and Oreström (1983) documented a de-
crease of intensity at the end of a turn.
In addition, non-verbal cues for turn-yielding
have been suggested. Kendon (1967) noticed that
a speaker often doesn’t look at the listener during
an utterance but does so at the end of the turn.
An explanation is that at those points of the con-
versation visual contact is required. Exline
(1965) discovered that participants in a conversa-
tion look at their dialogue partner more often
while they are listening. Duncan (1972) found
several non-verbal cues in the behaviour of a
speaker as turn-yielding signals: Relaxation of a
tensed hand-position, completion of a gesture,
regression of the torso, and relaxation of the fa-
cial expression.
</bodyText>
<sectionHeader confidence="0.996788" genericHeader="method">
3 Data Retrieval
</sectionHeader>
<subsectionHeader confidence="0.999343">
3.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999647">
In our experiment speakers held two conversa-
tions, both in two conditions: first with eye-
</bodyText>
<subsubsectionHeader confidence="0.791449">
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 107–110,
</subsubsectionHeader>
<affiliation confidence="0.947806">
Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics
</affiliation>
<page confidence="0.999344">
107
</page>
<bodyText confidence="0.9999256">
contact and then without. Speakers didn’t know
each other. The given task was to plan a party by
seating guests on a map of the party location. For
solving the task it was necessary that the conver-
sational partners share their information.
</bodyText>
<subsectionHeader confidence="0.9931675">
3.2 Preparation of recorded speech mate-
rial
</subsectionHeader>
<bodyText confidence="0.999990454545455">
There were four speakers in two bilateral conver-
sations. During the first half of a conversation
the speakers could see each other. After they had
accomplished half of the task a screen foreclosed
eye-contact. The recordings were transliterated
into orthographic text by a phonetic expert. This
detailed transliteration contains information like
word fragments, hesitations, pauses, and vocal
events like laughter. The transcribed text was
then segmented into turns. In each turn the topic
units were identified according to our definition:
</bodyText>
<listItem confidence="0.9876696">
• A topic unit can be considered as seman-
tically and grammatically complete and
• there is no further division possible in
grammatically and semantically complete
units.
</listItem>
<bodyText confidence="0.99678275">
Table 1 shows the number of topic units we
found in our material. The syllables were la-
belled and the F0-contours were determined by
manual judgment.
</bodyText>
<tableCaption confidence="0.995503">
Table 1: Numbers of topic units for each speaker.
</tableCaption>
<subsectionHeader confidence="0.999359">
3.3 Acoustic Measurements
</subsectionHeader>
<bodyText confidence="0.999812272727273">
In the analysis of the acoustic speech signal we
focused on features that have been suspected as
turn-yielding signals in former studies. Each end
of a topic unit has the potential to be the end of
the turn and to initiate a turn taking. We assumed
that a speaker marks topic units in turn-final po-
sition compared to turn-medial topic units by
prosodic differences and that those differences
change if the optical feedback channel is miss-
ing.
We observed the following prosodic features:
</bodyText>
<listItem confidence="0.996324714285714">
• Speech rate (syllables per second)
• Average intensity across topic units
• Difference of intensity of final last three
syllables and non-final last three syllable
of topic units (in Hertz)
• Mean F0 in topic units (in Hertz)
• Mean range of F0 in topic units (in
Hertz)
• Difference in duration between final and
non-final syllables of topic units (in ms)
• Relative distribution of five different
closing F0-contours in the topic units
• Characteristic F0-values of five different
closing F0-contours (manual judgment)
</listItem>
<sectionHeader confidence="0.996729" genericHeader="method">
4 Findings
</sectionHeader>
<bodyText confidence="0.999915090909091">
We intended to examine whether the differences
between turn-final and turn-medial topic units
differ in the feature characteristics between the
two conditions. Feature characteristics could dif-
fer in quality or quantity. For a variation in quan-
tity the number of potential signals would in-
crease or decrease between the two conditions. A
variation in quality could only be analyzed if the
potential signal appears in both conditions and
occurs as an increase or decrease of the strength
of the feature.
</bodyText>
<subsectionHeader confidence="0.973269">
4.1 Duration
</subsectionHeader>
<bodyText confidence="0.999759125">
The mean syllable rate of final topic unit and
non-final topic unit was compared. Our results
indicate an increased syllable frequency at the
end of the turn in condition 2. But there is no
significant difference between the two condi-
tions. One speaker even decreased syllable fre-
quency in turn-final positions compared to non-
turn-final positions.
</bodyText>
<subsectionHeader confidence="0.8441">
4.2 Intensity
</subsectionHeader>
<bodyText confidence="0.9919445">
For the intensity we analyzed differences be-
tween
</bodyText>
<listItem confidence="0.9903855">
• the overall intensity of the topic units in
final and in non-final position, and
• the internal reduction of intensity at the
end of the topic units in final and non-final
</listItem>
<bodyText confidence="0.872977285714286">
position (by comparing the last three syl-
lables to the others).
The overall intensity of topic units in turn-
final position is significantly decreased for two
(of four) speakers in the condition with sight and
for three speakers in the condition without sight.
That is, there seems to be a signal function which
</bodyText>
<page confidence="0.998384">
108
</page>
<bodyText confidence="0.999959428571428">
is used by one more speaker in condition 2.
However, this is just a quantitative difference
between the two conditions. For the speakers,
using this potential signal in both conditions,
there’s no detectable qualitative variation in con-
dition 2 (no enhanced difference between the
intensity of topic units in final and non-final po-
sition).
For all topic units a decrease of intensity at the
end has been found. Due to the decrease of air
pressure during an utterance this was expected.
This reduction of intensity is for all four speakers
only significant for topic units in final position.
That is, that in topic units at the end of a turn the
final reduction of intensity is much greater than
in the other topic units. One could assume a sig-
nal function. Further analyses showed that this
distinction is intensified by two of the speakers
in condition 2, while it is weaker for the other
two speakers. The modifications in condition 2
don’t have a mutual direction.
</bodyText>
<subsectionHeader confidence="0.997759">
4.3 Fundamental frequency
</subsectionHeader>
<bodyText confidence="0.901427596153846">
Concerning the fundamental frequency, we ex-
amined the following issues by comparing the
two conditions:
• The over-all F0-mean and F0-range of
the topic units in final and non-final posi-
tion
• The percentage distribution of final F0-
contours at the end of the topic units in fi-
nal and non-final position
• The representative last F0-values of
these contours in final and non-final posi-
tion (last level tone for movements and
F0-mean for sustained F0).
The speakers (exception is one speaker in condi-
tion 2) realized the turn-final topic units with
lower fundamental frequency; which is signifi-
cant only for two speakers in both conditions.
These two speakers made a stronger distinction
between final and non-final topic units in condi-
tion 2 by increasing the difference of mean F0.
The other two speakers diminish this distinction
in condition 2.
Equivalent is the finding for the F0-range. The
same two speakers who decreased the mean fre-
quency decreased also the F0-range in final topic
units. For these speakers there’s also a noticeable
intensification of the distinction in condition 2,
while the other speakers behave contrarily.
Analyzing the percentage distribution of F0-
movements, we distinguished five F0-contours at
the end of the topic units: Sustain, Fall, Rise,
Rise/fall, and Fall/rise.
None of these contours seemed to appear more
often in turn-final position. This includes the fal-
ling and rising F0-movements, which were as-
sumed to be turn-yielding signals. In contrast
most of the topic units where realized with a fi-
nal sustain and there was no higher occurrence of
rise or fall in turn-final position detectable.
For the final level tone (F0-mean for sustain)
we found only for sustain, fall and rise/fall dif-
ferences between final and non-final topic units.
These contours had lower final level tones (lower
F0-mean for sustain) in turn-final position for at
least one speaker in condition 1 and 2 speakers in
condition 2. These findings accounted for the
general lowering of F0 in final topic units. Al-
though this distinction between final and non-
final position doesn’t change qualitatively be-
tween conditions, there’s some evidence for a
quantitative change, because more speakers seem
to use these signals in condition 2.
</bodyText>
<sectionHeader confidence="0.996713" genericHeader="discussions">
5 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.999967366666667">
To examine whether turn-yielding signals are
intensified in the condition without sight, we
constituted the criterion that a cue has to appear
in one of the conditions for at least three of the
speakers to be considered. For those cues we de-
veloped a comparison chart in which qualitative
and quantitative changes between condition 1
and 2 (with and without sight) were inscribed
(Table 2).
Qualitative differences could only occur if a
speaker shows the signal in both conditions.
They are treated dichotomous (as increased and
decreased). Quantitative differences are marked
as added or omitted signals for each speaker.
Table 2 shows that none of the signals under-
goes changes of the same direction for more than
two speakers. For syllable frequency there’s no
change between the conditions at all. For inten-
sity of topic units, F0-mean of sustain, and last
level-tone of fall there’s only a quantitative
change for one speaker. That is, one more
speaker added this signal in condition 2, while
one or more speaker use it in both conditions,
without qualitative shades.
Only the last level-tone of rise/fall and the dif-
ference of intensity between final and non-final
syllable groups show changes for more than one
speaker. But while the difference of intensity
between final and non-final syllable groups is
increased in condition 2 for the conversation
</bodyText>
<page confidence="0.997413">
109
</page>
<bodyText confidence="0.999837590909091">
partners in group 1, it is decreased for group 2.
The results cancel each other.
Only the last level-tone of rise/fall was modi-
fied in condition 2 by more than one speaker
without being modified by other speakers in the
contrary way. That is, it was added. For the mean
F0 and the F0-range one speaker omitted the sig-
nals in condition 2 and one speaker increased
their distinctive function.
Taking a look at the sum of shown signals, we
recognize that for none of the speakers there’s a
remarkable raise in the total number of shown
signals in condition 2. Finally, every increased
distinctive function of a signal, which could be
judged as compensation, has a negative counter-
part like decrease or omission. Based on the re-
sults of this study one can’t assume, that the ana-
lyzed prosodic cues compensate if the optical
feedback channel is missing. This leaves the
question whether optical cues are necessary sig-
nals or just added as redundant indicators to in-
tensify the effect of the prosodic cues.
</bodyText>
<tableCaption confidence="0.968425">
Table 2: Main results of the analysis of some analyzed prosodic features.
</tableCaption>
<sectionHeader confidence="0.972791" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.975532">
We thank the test speakers for volunteering.
</bodyText>
<sectionHeader confidence="0.99915" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999286807692307">
Adam Kendon. 1967. Some functions of gaze-
direction in social interaction. Acta Psychologica
26: 22-63.
Bengt Oreström. 1983. Turn-taking in English Con-
versation. Lund studies in english 66, Infotryck
AB, Malmö.
Harvey Sacks, Emanuel A. Schegloff, and Gail Jeffer-
son. 1974. A simplest systematics for the organisa-
tion for turn-taking for conversations. Language
50: 396-735.
Ilse Lehiste. 1975. The phonetic structure of para-
graphs. Structure and process in speech perception.
Proceedings of the symposium of dynamic aspects
of speech perception. Cohen / Nooteboom (Eds.),
Springer Berlin / Heidelberg. 195-206.
Ralph V. Exline, David Gray, and Dorothy Schuette.
1965. Visual behavior in a dyad as affected by in-
terview content and sex of respondent. Journal of
Personality and Social Psychology 1: 201-209.
Starkey Duncan, Jr.. 1972. Some signals and rules for
taking speaking turns in conversations. Journal of
Personality and Social Psychology 23: 283-292.
W. Geoffrey Beattie. 1981. The regulation of speaker
turns in face-to-face conversation: Some implica-
tions for conversation in sound-only communica-
tion channels. Semiotica 34: 55-70.
</reference>
<page confidence="0.998392">
110
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.125371">
<title confidence="0.81547825">Prosodic turn-yielding Cues with and without optical Feedback Caroline Technische Universität Deutsche Telekom</title>
<author confidence="0.262134">Ernst-Reuter-Platz</author>
<address confidence="0.808145">10587 Berlin</address>
<email confidence="0.675347">Caroline.Clemens@telekom.de</email>
<abstract confidence="0.999360166666667">The authors present a study of prosodic turn-taking indicators. The aim was to investigate whether some of the prosodic cues increase in quality or quantity if the optical feedback channel in the verbal conversation is missing. For the study we built up an experimental setup in which conversational partners held a conversation once with and once without an optical feedback channel. A detailed transcription of the recorded speech material was segmented into turns. In each turn the topic units were identified and the syllables were labelled. We measured and compared prosodic feature characteristics between turn-final and turn-medial topic units.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam Kendon</author>
</authors>
<title>Some functions of gazedirection in social interaction.</title>
<date>1967</date>
<journal>Acta Psychologica</journal>
<volume>26</volume>
<pages>22--63</pages>
<contexts>
<context position="2906" citStr="Kendon (1967)" startWordPosition="440" endWordPosition="441">ation (listener response). We focused on turn-yielding as those signals are easy to locate, and because most found prosodic and non-verbal cues belong to this class. Beattie (1981) and Oreström (1983) showed that a noticeable rising or falling movement of fundamental frequency acts as a prosodic turnyielding cue. According to Oreström (1983), the final syllable of the turn is lengthened and sometimes the syllable frequency is increased. Duncan (1972) and Oreström (1983) documented a decrease of intensity at the end of a turn. In addition, non-verbal cues for turn-yielding have been suggested. Kendon (1967) noticed that a speaker often doesn’t look at the listener during an utterance but does so at the end of the turn. An explanation is that at those points of the conversation visual contact is required. Exline (1965) discovered that participants in a conversation look at their dialogue partner more often while they are listening. Duncan (1972) found several non-verbal cues in the behaviour of a speaker as turn-yielding signals: Relaxation of a tensed hand-position, completion of a gesture, regression of the torso, and relaxation of the facial expression. 3 Data Retrieval 3.1 Experimental setup </context>
</contexts>
<marker>Kendon, 1967</marker>
<rawString>Adam Kendon. 1967. Some functions of gazedirection in social interaction. Acta Psychologica 26: 22-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bengt Oreström</author>
</authors>
<title>Turn-taking in English Conversation. Lund studies in english 66, Infotryck AB,</title>
<date>1983</date>
<location>Malmö.</location>
<contexts>
<context position="2493" citStr="Oreström (1983)" startWordPosition="373" endWordPosition="374">f. Language and Communication Straße des 17. Juni 135 10623 Berlin c.diekhaus@alice-dsl.net Do prosodic cues compensate if the optical feedback channel is missing in the verbal conversation? 2 Prosodic and non-verbal turn-taking indicators Duncan (1972) sorted turn-taking signals by their function. He classified the signals as turnyielding, turn-demanding (listener), attemptsuppressing, and back-channel-communication (listener response). We focused on turn-yielding as those signals are easy to locate, and because most found prosodic and non-verbal cues belong to this class. Beattie (1981) and Oreström (1983) showed that a noticeable rising or falling movement of fundamental frequency acts as a prosodic turnyielding cue. According to Oreström (1983), the final syllable of the turn is lengthened and sometimes the syllable frequency is increased. Duncan (1972) and Oreström (1983) documented a decrease of intensity at the end of a turn. In addition, non-verbal cues for turn-yielding have been suggested. Kendon (1967) noticed that a speaker often doesn’t look at the listener during an utterance but does so at the end of the turn. An explanation is that at those points of the conversation visual contac</context>
</contexts>
<marker>Oreström, 1983</marker>
<rawString>Bengt Oreström. 1983. Turn-taking in English Conversation. Lund studies in english 66, Infotryck AB, Malmö.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harvey Sacks</author>
<author>Emanuel A Schegloff</author>
<author>Gail Jefferson</author>
</authors>
<title>A simplest systematics for the organisation for turn-taking for conversations.</title>
<date>1974</date>
<journal>Language</journal>
<volume>50</volume>
<pages>396--735</pages>
<contexts>
<context position="975" citStr="Sacks et al. (1974)" startWordPosition="141" endWordPosition="144">r quantity if the optical feedback channel in the verbal conversation is missing. For the study we built up an experimental setup in which conversational partners held a conversation once with and once without an optical feedback channel. A detailed transcription of the recorded speech material was segmented into turns. In each turn the topic units were identified and the syllables were labelled. We measured and compared prosodic feature characteristics between turn-final and turn-medial topic units. 1 Introduction In a verbal conversation the roles of speaker and listener have to be defined. Sacks et al. (1974) stated “minimize gap and overlap” as the first rule for a working turn-taking-mechanism. According to them, the end of turn has to be marked in some way. Since linguistic cues are rarely found, it is obvious that this marking has to be realized by prosodic features. This supposition was corroborated by the findings of Lehiste (1975), that listeners got the ability to identify the position of clauses within a turn, even if the clauses were represented in isolation. In the speaker’s turn several prosodic cues are presumed to indicate to the listener whether the speaker wants to keep or end the </context>
</contexts>
<marker>Sacks, Schegloff, Jefferson, 1974</marker>
<rawString>Harvey Sacks, Emanuel A. Schegloff, and Gail Jefferson. 1974. A simplest systematics for the organisation for turn-taking for conversations. Language 50: 396-735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilse Lehiste</author>
</authors>
<title>The phonetic structure of paragraphs. Structure and process in speech perception. Proceedings of the symposium of dynamic aspects of speech perception.</title>
<date>1975</date>
<journal>Cohen / Nooteboom (Eds.),</journal>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<contexts>
<context position="1310" citStr="Lehiste (1975)" startWordPosition="199" endWordPosition="200">opic units were identified and the syllables were labelled. We measured and compared prosodic feature characteristics between turn-final and turn-medial topic units. 1 Introduction In a verbal conversation the roles of speaker and listener have to be defined. Sacks et al. (1974) stated “minimize gap and overlap” as the first rule for a working turn-taking-mechanism. According to them, the end of turn has to be marked in some way. Since linguistic cues are rarely found, it is obvious that this marking has to be realized by prosodic features. This supposition was corroborated by the findings of Lehiste (1975), that listeners got the ability to identify the position of clauses within a turn, even if the clauses were represented in isolation. In the speaker’s turn several prosodic cues are presumed to indicate to the listener whether the speaker wants to keep or end the turn. At points with high speaker switch potential noticeable gestural and mimic cues can be found. It is unknown how important those non-verbal aspects are for the turn-taking indication. The main research question of the presented study is: Christoph Diekhaus Technische Universität Berlin Department f. Language and Communication St</context>
</contexts>
<marker>Lehiste, 1975</marker>
<rawString>Ilse Lehiste. 1975. The phonetic structure of paragraphs. Structure and process in speech perception. Proceedings of the symposium of dynamic aspects of speech perception. Cohen / Nooteboom (Eds.), Springer Berlin / Heidelberg. 195-206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph V Exline</author>
<author>David Gray</author>
<author>Dorothy Schuette</author>
</authors>
<title>Visual behavior in a dyad as affected by interview content and sex of respondent.</title>
<date>1965</date>
<journal>Journal of Personality and Social Psychology</journal>
<volume>1</volume>
<pages>201--209</pages>
<marker>Exline, Gray, Schuette, 1965</marker>
<rawString>Ralph V. Exline, David Gray, and Dorothy Schuette. 1965. Visual behavior in a dyad as affected by interview content and sex of respondent. Journal of Personality and Social Psychology 1: 201-209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Starkey Duncan</author>
<author>Jr</author>
</authors>
<title>Some signals and rules for taking speaking turns in conversations.</title>
<date>1972</date>
<journal>Journal of Personality and Social Psychology</journal>
<volume>23</volume>
<pages>283--292</pages>
<marker>Duncan, Jr, 1972</marker>
<rawString>Starkey Duncan, Jr.. 1972. Some signals and rules for taking speaking turns in conversations. Journal of Personality and Social Psychology 23: 283-292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Geoffrey Beattie</author>
</authors>
<title>The regulation of speaker turns in face-to-face conversation: Some implications for conversation in sound-only communication channels.</title>
<date>1981</date>
<journal>Semiotica</journal>
<volume>34</volume>
<pages>55--70</pages>
<contexts>
<context position="2473" citStr="Beattie (1981)" startWordPosition="370" endWordPosition="371"> Berlin Department f. Language and Communication Straße des 17. Juni 135 10623 Berlin c.diekhaus@alice-dsl.net Do prosodic cues compensate if the optical feedback channel is missing in the verbal conversation? 2 Prosodic and non-verbal turn-taking indicators Duncan (1972) sorted turn-taking signals by their function. He classified the signals as turnyielding, turn-demanding (listener), attemptsuppressing, and back-channel-communication (listener response). We focused on turn-yielding as those signals are easy to locate, and because most found prosodic and non-verbal cues belong to this class. Beattie (1981) and Oreström (1983) showed that a noticeable rising or falling movement of fundamental frequency acts as a prosodic turnyielding cue. According to Oreström (1983), the final syllable of the turn is lengthened and sometimes the syllable frequency is increased. Duncan (1972) and Oreström (1983) documented a decrease of intensity at the end of a turn. In addition, non-verbal cues for turn-yielding have been suggested. Kendon (1967) noticed that a speaker often doesn’t look at the listener during an utterance but does so at the end of the turn. An explanation is that at those points of the conver</context>
</contexts>
<marker>Beattie, 1981</marker>
<rawString>W. Geoffrey Beattie. 1981. The regulation of speaker turns in face-to-face conversation: Some implications for conversation in sound-only communication channels. Semiotica 34: 55-70.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>