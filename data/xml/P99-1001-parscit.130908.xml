<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000475">
<title confidence="0.983566">
Untangling Text Data Mining
</title>
<author confidence="0.98279">
Marti A. Hearst
</author>
<affiliation confidence="0.9982105">
School of Information Management &amp; Systems
University of California, Berkeley
</affiliation>
<address confidence="0.8633305">
102 South Hall
Berkeley, CA 94720-4600
</address>
<email confidence="0.972148">
http://www.sims.berkeley.edurhearst
</email>
<sectionHeader confidence="0.996804" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999761">
The possibilities for data mining from large text
collections are virtually untapped. Text ex-
presses a vast, rich range of information, but en-
codes this information in a form that is difficult
to decipher automatically. Perhaps for this rea-
son, there has been little work in text data min-
ing to date, and most people who have talked
about it have either conflated it with informa-
tion access or have not made use of text directly
to discover heretofore unknown information.
In this paper I will first define data mining,
information access, and corpus-based computa-
tional linguistics, and then discuss the relation-
ship of these to text data mining. The intent
behind these contrasts is to draw attention to
exciting new kinds of problems for computa-
tional linguists. I describe examples of what I
consider to be real text data mining efforts and
briefly outline recent ideas about how to pursue
exploratory data analysis over text.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964034482759">
The nascent field of text data mining (TDM)
has the peculiar distinction of having a name
and a fair amount of hype but as yet almost
no practitioners. I suspect this has happened
because people assume TDM is a natural ex-
tension of the slightly less nascent field of data
mining (DM), also known as knowledge dis-
covery in databases (Fayyad and Uthurusamy,
1999), and information archeology (Brachman
et al., 1993). Additionally, there are some
disagreements about what actually constitutes
data mining. It turns out that &amp;quot;mining&amp;quot; is not a
very good metaphor for what people in the field
actually do. Mining implies extracting precious
nuggets of ore from otherwise worthless rock.
If data mining really followed this metaphor, it
would mean that people were discovering new
factoids within their inventory databases. How-
ever, in practice this is not really the case.
Instead, data mining applications tend to be
(semi)automated discovery of trends and pat-
terns across very large datasets, usually for the
purposes of decision making (Fayyad and Uthu-
rusamy, 1999; Fayyad, 1997). Part of what I
wish to argue here is that in the case of text,
it can be interesting to take the mining-for-
nuggets metaphor seriously.
The various contrasts discussed below are
summarized in Table 1.
</bodyText>
<sectionHeader confidence="0.966249" genericHeader="method">
2 TDM vs. Information Access
</sectionHeader>
<bodyText confidence="0.999980346153846">
It is important to differentiate between text
data mining and information access (or infor-
mation retrieval, as it is more widely known).
The goal of information access is to help users
find documents that satisfy their information
needs (Baeza-Yates and Ribeiro-Neto, 1999).
The standard procedure is akin to looking for
needles in a needlestack — the problem isn&apos;t so
much that the desired information is not known,
but rather that the desired information coex-
ists with many other valid pieces of information.
Just because a user is currently interested in
NAFTA and not Furbies does not mean that all
descriptions of Furbies are worthless. The prob-
lem is one of homing in on what is currently of
interest to the user.
As noted above, the goal of data mining is to
discover or derive new information from data,
finding patterns across datasets, and/or sepa-
rating signal from noise. The fact that an infor-
mation retrieval system can return a document
that contains the information a user requested
implies that no new discovery is being made:
the information had to have already been known
to the author of the text; otherwise the author
could not have written it down.
</bodyText>
<page confidence="0.996951">
3
</page>
<bodyText confidence="0.999912465116279">
I have observed that many people, when
asked about text data mining, assume it should
have something to do with &amp;quot;making things eas-
ier to find on the web&amp;quot;. For example, the de-
scription of the KDD-97 panel on Data Mining
and the Web stated:
... Two challenges are predominant for
data mining on the Web. The first goal is
to help users in finding useful information
on the Web and in discovering knowledge
about a domain that is represented by a
collection of Web-documents. The second
goal is to analyse the transactions run in
a Web-based system, be it to optimize the
system or to find information about the
clients using the system.1
This search-centric view misses the point that
we might actually want to treat the information
in the web as a large knowledge base from which
we can extract new, never-before encountered
information (Craven et al., 1998).
On the other hand, the results of certain types
of text processing can yield tools that indirectly
aid in the information access process. Exam-
ples include text clustering to create thematic
overviews of text collections (Cutting et al.,
1992; Chalmers and Chitson, 1992; Rennison,
1994; Wise et al., 1995; Lin et al., 1991; Chen
et al., 1998), automatically generating term as-
sociations to aid in query expansion (Peat and
Willett, 1991; Voorhees, 1994; Xu and Croft,
1996), and using co-citation analysis to find gen-
eral topics within a collection or identify central
web pages (White and McCain, 1989; Larson,
1996; Kleinberg, 1998).
Aside from providing tools to aid in the stan-
dard information access process, I think text
data mining can contribute along another di-
mension. In future I hope to see information
access systems supplemented with tools for ex-
ploratory data analysis. Our efforts in this di-
rection are embodied in the LINDI project, de-
scribed in Section 5 below.
</bodyText>
<sectionHeader confidence="0.973444" genericHeader="method">
3 TDM and Computational
Linguistics
</sectionHeader>
<bodyText confidence="0.965017487804878">
If we extrapolate from data mining (as prac-
ticed) on numerical data to data mining from
text collections, we discover that there already
&apos;http://www.aaai.org/Conferences/KDD/1997/kdd97-
schedule.html
exists a field engaged in text data mining:
corpus-based computational linguistics! Empir-
ical computational linguistics computes statis-
tics over large text collections in order to dis-
cover useful patterns. These patterns are used
to inform algorithms for various subproblems
within natural language processing, such as
part-of-speech tagging, word sense disambigua-
tion, and bilingual dictionary creation (Arm-
strong, 1994).
It is certainly of interest to a computational
linguist that the words &amp;quot;prices, prescription,
and patent&amp;quot; are highly likely to co-occur with
the medical sense of &amp;quot;drug&amp;quot; while &amp;quot;abuse, para-
phernalia, and illicit&amp;quot; are likely to co-occur with
the illegal drug sense of this word (Church and
Liberman, 1991). This kind of information can
also be used to improve information retrieval al-
gorithms. However, the kinds of patterns found
and used in computational linguistics are not
likely to be what the general business commu-
nity hopes for when they use the term text data
mining.
Within the computational linguistics frame-
work, efforts in automatic augmentation of ex-
isting lexical structures seem to fit the data-
mining-as-ore-extraction metaphor. Examples
include automatic augmentation of WordNet re-
lations (Fellbaum, 1998) by identifying lexico-
syntactic patterns that unambiguously indicate
those relations (Hearst, 1998), and automatic
acquisition of subcategorization data from large
text corpora (Manning, 1993). However, these
serve the specific needs of computational lin-
guistics and are not applicable to a broader au-
dience.
</bodyText>
<sectionHeader confidence="0.968859" genericHeader="method">
4 TDM and Category Metadata
</sectionHeader>
<bodyText confidence="0.999779692307692">
Some researchers have claimed that text cate-
gorization should be considered text data min-
ing. Although analogies can be found in the
data mining literature (e.g., referring to classifi-
cation of astronomical phenomena as data min-
ing (Fayyad and Uthurusamy, 1999)), I believe
when applied to text categorization this is a mis-
nomer. Text categorization is a boiling down of
the specific content of a document into one (or
more) of a set of pre-defined labels. This does
not lead to discovery of new information; pre-
sumably the person who wrote the document
knew what it was about. Rather, it produces a
</bodyText>
<page confidence="0.991596">
4
</page>
<table confidence="0.9995686">
Finding Patterns Novel Finding
Nuggets
Non-Novel
Non-textual data standard data mining ? database queries
Textual data computational linguistics real TDM information retrieval
</table>
<tableCaption confidence="0.999636">
Table 1: A classification of data mining and text data mining applications.
</tableCaption>
<bodyText confidence="0.998043333333334">
compact summary of something that is already
known.
However, there are two recent areas of in-
quiry that make use of text categorization and
do seem to fit within the conceptual framework
of discovery of trends and patterns within tex-
tual data for more general purpose usage.
One body of work uses text category labels
(associated with Reuters newswire) to find &amp;quot;un-
expected patterns&amp;quot; among text articles (Feld-
man and Dagan, 1995; Dagan et al., 1996; Feld-
man et al., 1997). The main approach is to
compare distributions of category assignments
within subsets of the document collection. For
instance, distributions of commodities in coun-
try Cl are compared against those of country
C2 to see if interesting or unexpected trends
can be found. Extending this idea, one coun-
try&apos;s export trends might be compared against
those of a set of countries that are seen as an
economic unit (such as the 0-7).
Another effort is that of the DARPA Topic
Detection and Tracking initiative (Allan et
al., 1998). While several of the tasks within
this initiative are standard text analysis prob-
lems (such as categorization and segmentation),
there is an interesting task called On-line New
Event Detection, whose input is a stream of
news stories in chronological order, and whose
output is a yes/no decision for each story, made
at the time the story arrives, indicating whether
the story is the first reference to a newly occur-
ring event. In other words, the system must
detect the first instance of what will become a
series of reports on some important topic. Al-
though this can be viewed as a standard clas-
sification task (where the class is a binary as-
signment to the new-event class) it is more in
the spirit of data mining, in that the focus is
on discovery of the beginning of a new theme or
trend.
The reason I consider this examples — using
multiple occurrences of text categories to de-
tect trends or patterns — to be &amp;quot;real&amp;quot; data min-
ing is that they use text metadata to tell us
something about the world, outside of the text
collection itself. (However, since this applica-
tion uses metadata associated with text docu-
ments, rather than the text directly, it is un-
clear if it should be considered text data min-
ing or standard data mining.) The computa-
tional linguistics applications tell us about how
to improve language analysis, but they do not
discover more widely usable information.
</bodyText>
<sectionHeader confidence="0.903354" genericHeader="method">
5 Text Data Mining as Exploratory
</sectionHeader>
<subsectionHeader confidence="0.750572">
Data Analysis
</subsectionHeader>
<bodyText confidence="0.999945642857143">
Another way to view text data mining is as
a process of exploratory data analysis (Tukey,
1977; Hoaglin et al., 1983) that leads to the dis-
covery of heretofore unknown information, or
to answers for questions for which the answer is
not currently known.
Of course, it can be argued that the stan-
dard practice of reading textbooks, journal ar-
ticles and other documents helps researchers in
the discovery of new information, since this is
an integral part of the research process. How-
ever, the idea here is to use text for discovery
in a more direct manner. Two examples are de-
scribed below.
</bodyText>
<subsectionHeader confidence="0.9635945">
5.1 Using Text to Form Hypotheses
about Disease
</subsectionHeader>
<bodyText confidence="0.999899571428572">
For more than a decade, Don Swanson has elo-
quently argued why it is plausible to expect
new information to be derivable from text col-
lections: experts can only read a small subset
of what is published in their fields and are of-
ten unaware of developments in related fields.
Thus it should be possible to find useful link-
ages between information in related literatures,
if the authors of those literatures rarely refer to
one another&apos;s work. Swanson has shown how
chains of causal implication within the medical
literature can lead to hypotheses for causes of
rare diseases, some of which have received sup-
porting experimental evidence (Swanson, 1987;
</bodyText>
<page confidence="0.966411">
5
</page>
<bodyText confidence="0.990947">
Swanson, 1991; Swanson and Smalheiser, 1994;
Swanson and Smalheiser, 1997).
For example, when investigating causes of mi-
graine headaches, he extracted various pieces of
evidence from titles of articles in the biomedi-
cal literature. Some of these clues can be para-
phrased as follows:
</bodyText>
<listItem confidence="0.999022846153846">
• stress is associated with migraines
• stress can lead to loss of magnesium
• calcium channel blockers prevent some mi-
graines
• magnesium is a natural calcium channel
blocker
• spreading cortical depression (SCD) is im-
plicated in some migraines
• high leveles of magnesium inhibit SCD
• migraine patients have high platelet aggre-
gability
• magnesium can suppress platelet aggrega-
bility
</listItem>
<bodyText confidence="0.99987392">
These clues suggest that magnesium defi-
ciency may play a role in some kinds of mi-
graine headache; a hypothesis which did not ex-
ist in the literature at the time Swanson found
these links. The hypothesis has to be tested via
non-textual means, but the important point is
that a new, potentially plausible medical hy-
pothesis was derived from a combination of
text fragments and the explorer&apos;s medical ex-
pertise. (According to Swanson (1991), subse-
quent study found support for the magnesium-
migraine hypothesis (Ramadan et al., 1989).)
This approach has been only partially auto-
mated. There is, of course, a potential for com-
binatorial explosion of potentially valid links.
Beeferman (1998) has developed a flexible in-
terface and analysis tool for exploring certain
kinds of chains of links among lexical relations
within WordNet.2 However, sophisticated new
algorithms are needed for helping in the prun-
ing process, since a good pruning algorithm will
want to take into account various kinds of se-
mantic constraints. This may be an interest-
ing area of investigation for computational lin-
guists.
</bodyText>
<footnote confidence="0.74905">
2 See http://www.link.cs.cmu.edu/lexfn
</footnote>
<subsectionHeader confidence="0.980027">
5.2 Using Text to Uncover Social
Impact
</subsectionHeader>
<bodyText confidence="0.999632857142857">
Switching to an entirely different domain, con-
sider a recent effort to determine the effects
of publicly financed research on industrial ad-
vances (Narin et al., 1997). After years of
preliminary studies and building special pur-
pose tools, the authors found that the tech-
nology industry relies more heavily than ever
on government-sponsored research results. The
authors explored relationships among patent
text and the published research literature, us-
ing a procedure which was reported as follows
in Broad (1997):
The CHI Research team examined the
science references on the front pages of
American patents in two recent periods —
1987 and 1988, as well as 1993 and 1994 —
looking at all the 397,660 patents issued.
It found 242,000 identifiable science ref-
erences and zeroed in on those published
in the preceding 11 years, which turned
out to be 80 percent of them. Searches of
computer databases allowed the linking of
109,000 of these references to known jour-
nals and authors&apos; addresses. After elim-
inating redundant citations to the same
paper, as well as articles with no known
American author, the study had a core col-
lection of 45,000 papers. Armies of aides
then fanned out to libraries to look up
the papers and examine their closing lines,
which often say who financed the research.
That detective work revealed an extensive
reliance on publicly financed science.
Further narrowing its focus, the study set
aside patents given to schools and govern-
ments and zeroed in on those awarded to
industry. For 2,841 patents issued in 1993
and 1994, it examined the peak year of lit-
erature references, 1988, and found 5,217
citations to science papers.
Of these, it found that 73.3 percent had
been written at public institutions — uni-
versities, government labs and other pub-
lic agencies, both in the United States and
abroad.
Thus a heterogeneous mix of operations was
required to conduct a complex analyses over
large text collections. These operations in-
cluded:
</bodyText>
<page confidence="0.997104">
6
</page>
<listItem confidence="0.822223769230769">
1 Retrieval of articles from a particular col-
lection (patents) within a particular date
range.
2 Identification of the citation pool (articles
cited by the patents).
3 Bracketing of this pool by date, creating a
new subset of articles.
4 Computation of the percentage of articles
that remain after bracketing.
5 Joining these results with those of other
collections to identify the publishers of ar-
ticles in the pool.
6 Elimination of redundant articles.
7 Elimination of articles based on an at-
tribute type (author nationality).
8 Location of full-text versions of the articles.
9 Extraction of a special attribute from the
full text (the acknowledgement of funding).
10 Classification of this attribute (by institu-
tion type).
11 Narrowing the set of articles to consider by
an attribute (institution type).
12 Computation of statistics over one of the
attributes (peak year)
13 Computation of the percentage of arti-
cles for which one attribute has been as-
</listItem>
<bodyText confidence="0.999868285714286">
signed another attribute type (whose cita-
tion attribute has a particular institution
attribute).
Because all the data was not available online,
much of the work had to be done by hand, and
special purpose tools were required to perform
the operations.
</bodyText>
<subsectionHeader confidence="0.997317">
5.3 The LINDI Project
</subsectionHeader>
<bodyText confidence="0.98792986440678">
The objectives of the LINDI project3 are to in-
vestigate how researchers can use large text col-
lections in the discovery of new important infor-
mation, and to build software systems to help
support this process. The main tools for dis-
covering new information are of two types: sup-
port for issuing sequences of queries and related
operations across text collections, and tightly
coupled statistical and visualization tools for
the examination of associations among concepts
that co-occur within the retrieved documents.
Both sets of tools make use of attributes as-
sociated specifically with text collections and
3LINDI: Linking Information for Novel Discovery and
Insight.
their metadata. Thus the broadening, narrow-
ing, and linking of relations seen in the patent
example should be tightly integrated with anal-
ysis and interpretation tools as needed in the
biomedical example.
Following Amant (1996), the interaction
paradigm is that of a mixed-initiative balance
of control between user and system. The inter-
action is a cycle in which the system suggests
hypotheses and strategies for investigating these
hypotheses, and the user either uses or ignores
these suggestions and decides on the next move.
We are interested in an important problem
in molecular biology, that of automating the
discovery of the function of newly sequenced
genes (Walker et al., 1998). Human genome
researchers perform experiments in which they
analyze co-expression of tens of thousands of
novel and known genes simultaneously.4 Given
this huge collection of genetic information, the
goal is to determine which of the novel genes
are medically interesting, meaning that they
are co-expressed with already understood genes
which are known to be involved in disease. Our
strategy is to explore the biomedical literature,
trying to formulate plausible hypotheses about
which genes are of interest.
Most information access systems require the
user to execute and keep track of tactical moves,
often distracting from the thought-intensive as-
pects of the problem (Bates, 1990). The LINDI
interface provides a facility for users to build
and so reuse sequences of query operations via
a drag-and-drop interface. These allow the user
to repeat the same sequence of actions for differ-
ent queries. In the gene example, this allows the
user to specify a sequence of operations to ap-
ply to one co-expressed gene, and then iterate
this sequence over a list of other co-expressed
genes that can be dragged onto the template.
(The Visage interface (Derthick et al., 1997)
implements this kind of functionality within its
information-centric framework.) These include
the following operations (see Figure 1):
</bodyText>
<listItem confidence="0.985602333333333">
• Iteration of an operation over the items
within a set. (This allows each item re-
trieved in a previous query to be use as a
</listItem>
<footnote confidence="0.895238">
4A gene g&apos; co-expresses with gene g when both are
found to be activated in the same cells at the same time
with much more likelihood than chance.
</footnote>
<page confidence="0.999409">
7
</page>
<bodyText confidence="0.973132">
search terms for a new query.)
</bodyText>
<listItem confidence="0.9439282">
• Transformation, i.e., applying an operation
to an item and returning a transformed
item (such as extracting a feature).
• Ranking, i.e., applying an operation to a
set of items and returning a (possibly) re-
ordered set of items with the same cardi-
nality.
• Selection, i.e., applying an operation to
a set of items and returning a (possibly)
reordered set of items with the same or
smaller cardinality.
• Reduction, i.e., applying an operation to
one or more sets of items to yield a sin-
gleton result (e.g., to compute percentages
and averages).
</listItem>
<bodyText confidence="0.999921454545455">
This system will allow maintenance of sev-
eral different types of history including history
of commands issued, history of strategies em-
ployed, and history of hypotheses tested. For
the history view, we plan to use a &amp;quot;spreadsheet&amp;quot;
layout (Hendry and Harper, 1997) as well as a
variation on a &amp;quot;slide sorter&amp;quot; view which Visage
uses for presentation creation but not for his-
tory retention (Roth et al., 1997).
Since gene function discovery is a new area,
there is not yet a known set of exploration
strategies. So initially the system must help
an expert user generate and record good explo-
ration strategies. The user interface provides
a mechanism for recording and modifying se-
quences of actions. These include facilities that
refer to metadata structure, allowing, for exam-
ple, query terms to be expanded by terms one
level above or below them in a subject hierarchy.
Once a successful set of strategies has been de-
vised, they can be re-used by other researchers
and (with luck) by an automated version of the
system. The intent is to build up enough strate-
gies that the system will begin to be used as an
assistant or advisor (Amant, 1996), ranking hy-
potheses according to projected importance and
plausibility.
Thus the emphasis of this system is to
help automate the tedious parts of the text
manipulation process and to integrate un-
derlying computationally-driven text analysis
with human-guided decision making within ex-
ploratory data analysis over text.
</bodyText>
<sectionHeader confidence="0.935593" genericHeader="conclusions">
6 Summary
</sectionHeader>
<bodyText confidence="0.9896018125">
For almost a decade the computational linguis-
tics community has viewed large text collections
as a resource to be tapped in order to produce
better text analysis algorithms. In this paper, I
have attempted to suggest a new emphasis: the
use of large online text collections to discover
new facts and trends about the world itself. I
suggest that to make progress we do not need
fully artificial intelligent text analysis; rather,
a mixture of computationally-driven and user-
guided analysis may open the door to exciting
new results.
Acknowledgements. Hao Chen, Ketan
Mayer-Patel, and Vijayshankar Raman helped
design and did all the implementation of the
first LINDI prototype.
</bodyText>
<sectionHeader confidence="0.990973" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999311555555555">
J. Allan, J. Carbonell, G. Doddington, J. Yamron,
and Y. Yang. 1998. Topic detection and tracking
pilot study: Final report. In Proceedings of the
DARPA Broadcast News Transcription and Un-
derstanding Workshop, pages 194-218.
Robert St. Amant. 1996. A Mixed-Initiative
Planning Approach to Exploratory Data Analy-
sis. Ph.D. thesis, Univeristy of Massachusetts,
Amherst.
Susan Armstrong, editor. 1994. Using Large Cor-
pora. MIT Press.
Ricardo Baeza-Yates and Berthier Ribeiro-Neto.
1999. Modern Information Retrieval. Addison-
Wesley Longman Publishing Company.
Marcia J. Bates. 1990. The berry-picking search:
User interface design. In Harold Thimbleby, edi-
tor, User Interface Design. Addison-Wesley.
Douglas Beeferman. 1998. Lexical discovery with
an enriched semantic network. In Proceedings of
the ACL/COLING Workshop on Applications of
WordNet in Natural Language Processing Sys-
tems, pages 358-364.
R. J. Brachman, P. G. Selfridge, L. G. Terveen,
B. Altman, A Borgida, F. Halper, T. Kirk,
A. Lazar, D. L. McGuinness, and L. A. Resnick.
1993. Integrated support for data archaeology.
International Journal of Intelligent and Cooper-
ative Information Systems, 2(2):159-185.
William J. Broad. 1997. Study finds public science
is pillar of industry. In The New York Times, May
13.
Matthew Chalmers and Paul Chitson. 1992. Bead:
Exploration in information visualization. In
Proceedings of the 15th Annual International
ACM/SIGIR Conference, pages 330-337, Copen-
hagen, Denmark.
</reference>
<page confidence="0.998492">
8
</page>
<figureCaption confidence="0.606711333333333">
Figure 1: A hypothetical sequence of operations for the exploration of gene function within a
biomedical text collection, where the functions of genes A, B, and C are known, and commonalities
are sought to hypothesize the function of the unknown gene. The mapping operation imposes a
rank ordering on the selected keywords. The final operation is a selection of only those documents
that contain at least one of the top-ranked keywords and that contain mentions of all three known
genes.
</figureCaption>
<figure confidence="0.974794333333333">
Explore Functions of New Gene X
Possible Function
For Gene-X
Keywords
ti
IP. Keywords
</figure>
<bodyText confidence="0.720583818181818">
Hsinchen Chen, Andrea L. Houston, Robin R.
Sewell, and Bruce R. Schatz. 1998. Internet
browsing and searching: User evaluations of cate-
gory map and concept space techniques. Journal
of the American Society for Information Sciences
(JASIS), 49(7).
Kenneth W. Church and Mark Y. Liberman. 1991.
A status report on the ACL/DCI. In The Pro-
ceedings of the 7th Annual Conference of the UW
Centre for the New OED and Text Research: Us-
ing Corpora, pages 84-91, Oxford.
</bodyText>
<reference confidence="0.996990081081081">
M. Craven, D. DiPasquo, D. Freitag, A. McCallum,
T. Mitchell, K. Nigam, and S. Slattery. 1998.
Learning to extract symbolic knowledge from the
world wide web. In Proceedings of AAAI.
Douglass R. Cutting, Jan 0. Pedersen, David
Karger, and John W. Tukey. 1992. Scat-
ter/Gather: A cluster-based approach to brows-
ing large document collections. In Proceedings of
the 15th Annual International ACM/SIGIR Con-
ference, pages 318-329, Copenhagen, Denmark.
Ido Dagan, Ronen Feldman, and Haym Hirsh. 1996.
Keyword-based browsing and analysis of large
document sets. In Proceedings of the Fifth Annual
Symposium on Document Analysis and Informa-
tion Retrieval (SDAIR), Las Vegas, NV.
Mark Derthick, John Kolojejchick, and Steven F.
Roth. 1997. An interactive visualization environ-
ment for data exploration. In Proceedings of the
Third Annual Conference on Knowledge Discov-
ery and Data Mining (KDD), Newport Beach.
Usama Fayyad and Ramasamy Uthurusamy.
1999. Data mining and knowledge discovery
in databases: Introduction to the special issue.
Communications of the ACM, 39(11), November.
Usama Fayyad. 1997. Editorial. Data Mining and
Knowledge Discovery, 1(1).
Ronen Feldman and Ido Dagan. 1995. KDT —
knowledge discovery in texts. In Proceedings of
the First Annual Conference on Knowledge Dis-
covery and Data Mining (KDD), Montreal.
Ronen Feldman, Will Klosgen, and Amir Zilber-
stein. 1997. Visualization techniques to explore
data mining results for document collections. In
Proceedings of the Third Annual Conference on
Knowledge Discovery and Data Mining (KDD),
Newport Beach.
Christiane Fellbaum, editor. 1998. WordNet: An
</reference>
<page confidence="0.977425">
9
</page>
<reference confidence="0.999475695652174">
Electronic Lexical Database. MIT Press.
Marti A. Hearst. 1998. Automated discovery of
wordnet relations. In Christiane Fellbaum, editor,
WordNet: An Electronic Lexical Database. MIT
Press, Cambridge, MA.
David G. Hendry and David J. Harper. 1997. An in-
formal information-seeking environment. Journal
of the American Society for Information Science,
48(11):1036-1048.
David C. Hoaglin, Frederick Mosteller, and John W.
Tukey. 1983. Understanding Robust and Ex-
ploratory Data Analysis. John Wiley Sz Sons, Inc.
Jon Kleinberg. 1998. Authoritative sources in a hy-
perlinked environment. In Proceedings of the 9th
ACM-SIAM Symposium on Discrete Algorithms.
Ray R. Larson. 1996. Bibliometrics of the world
wide web: An exploratory analysis of the intellec-
tual structure of cyberspace. In ASIS &apos;96: Pro-
ceedings of the 1996 Annual ASIS Meeting.
Xia Lin, Dagobert Soergel, and Gary Marchion-
ini. 1991. A self-organizing semantic map for in-
formation retrieval. In Proceedings of the 14th
Annual International ACM/SIGIR Conference,
pages 262-269, Chicago.
Christopher D. Manning. 1993. Automatic acquisi-
tion of a large subcategorization dictionary from
corpora. In Proceedings of the 31st Annual Meet-
ing of the Association for Computational Lin-
gusitics, pages 235-242, Columbus, OH.
Francis Narin, Kimberly S. Hamilton, and Dominic
Olivastro. 1997. The increasing linkage between
us technology and public science. Research Pol-
icy, 26(3):317-330.
Helen J. Peat and Peter Willett. 1991. The limi-
tations of term co-occurence data for query ex-
pansion in document retrieval systems. JASIS,
42(5):378-383.
N. M. Ramadan, H. Halvorson, A. Vandelinde, and
S.R. Levine. 1989. Low brain magnesium in mi-
graine. Headache, 29(7):416-419.
Earl Rennison. 1994. Galaxy of news: An approach
to visualizing and understanding expansive news
landscapes. In Proceedings of UIST 94, ACM
Symposium on User Interface Software and Tech-
nology, pages 3-12, New York.
Steven F. Roth, Mei C. Chuah, Stephan Kerped-
jiev, John A. Kolojejchick, and Peter Lucas. 1997.
Towards an information visualization workspace:
Combining multiple means of expression. Human-
Computer Interaction, 12(1-2):131-185.
Don R. Swanson and N. R. Smalheiser. 1994. As-
sessing a gap in the biomedical literature: Mag-
nesium deficiency and neurologic disease. Neuro-
science Research Communications, 15:1-9.
Don R. Swanson and N. R. Smalheiser. 1997. An in-
teractive system for finding complementary litera-
tures: a stimulus to scientific discovery. Artificial
Intelligence, 91:183-203.
Don R. Swanson. 1987. Two medical literatures
that are logically but not bibliographically con-
nected. JASIS, 38(4):228-233.
Don R. Swanson. 1991. Complementary structures
in disjoint science literatures. In Proceedings of
the 14th Annual International ACM/SIGIR Con-
ference, pages 280-289.
John W. Tukey. 1977. Exploratory Data Analysis.
Addison-Wesley Publishing Company.
Ellen M. Voorhees. 1994. Query expansion using
lexical-semantic relations. In Proceedings of the
17th Annual International ACM/SIGIR Confer-
ence, pages 61-69, Dublin, Ireland.
Michael G. Walker, Walter Volkmuth, Einat Sprin-
zak, David Hodgson, and Tod Klingler. 1998.
Prostate cancer genes identified by genome-scale
expression analysis. Technical Report (unnum-
bered), Incyte Pharmaceuticals, July.
H. D. White and K. W. McCain. 1989. Bibliomet-
rics. Annual Review of Information Science and
Technology, 24:119-186.
James A. Wise, James J. Thomas, Kelly Pennock,
David Lantrip, Marc Pottier, and Anne Schur.
1995. Visualizing the non-visual: Spatial analysis
and interaction with information from text docu-
ments. In Proceedings of the Information Visual-
ization Symposium 95, pages 51-58. IEEE Com-
puter Society Press.
J. Xu and W. B. Croft. 1996. Query expansion us-
ing local and global document analysis. In SI-
GIR &apos;96: Proceedings of the 19th Annual Interna-
tional ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 4-
11, Zurich.
</reference>
<page confidence="0.997788">
10
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.969179">
<title confidence="0.999822">Untangling Text Data Mining</title>
<author confidence="0.999994">Marti A Hearst</author>
<affiliation confidence="0.997019">School of Information Management &amp; Systems University of California, Berkeley</affiliation>
<address confidence="0.99914">102 South Hall Berkeley, CA 94720-4600</address>
<web confidence="0.988547">http://www.sims.berkeley.edurhearst</web>
<abstract confidence="0.999424571428571">The possibilities for data mining from large text collections are virtually untapped. Text expresses a vast, rich range of information, but encodes this information in a form that is difficult to decipher automatically. Perhaps for this reason, there has been little work in text data mining to date, and most people who have talked about it have either conflated it with information access or have not made use of text directly to discover heretofore unknown information. In this paper I will first define data mining, information access, and corpus-based computational linguistics, and then discuss the relationship of these to text data mining. The intent behind these contrasts is to draw attention to exciting new kinds of problems for computational linguists. I describe examples of what I consider to be real text data mining efforts and briefly outline recent ideas about how to pursue exploratory data analysis over text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allan</author>
<author>J Carbonell</author>
<author>G Doddington</author>
<author>J Yamron</author>
<author>Y Yang</author>
</authors>
<title>Topic detection and tracking pilot study: Final report.</title>
<date>1998</date>
<booktitle>In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop,</booktitle>
<pages>194--218</pages>
<contexts>
<context position="9131" citStr="Allan et al., 1998" startWordPosition="1472" endWordPosition="1475">patterns&amp;quot; among text articles (Feldman and Dagan, 1995; Dagan et al., 1996; Feldman et al., 1997). The main approach is to compare distributions of category assignments within subsets of the document collection. For instance, distributions of commodities in country Cl are compared against those of country C2 to see if interesting or unexpected trends can be found. Extending this idea, one country&apos;s export trends might be compared against those of a set of countries that are seen as an economic unit (such as the 0-7). Another effort is that of the DARPA Topic Detection and Tracking initiative (Allan et al., 1998). While several of the tasks within this initiative are standard text analysis problems (such as categorization and segmentation), there is an interesting task called On-line New Event Detection, whose input is a stream of news stories in chronological order, and whose output is a yes/no decision for each story, made at the time the story arrives, indicating whether the story is the first reference to a newly occurring event. In other words, the system must detect the first instance of what will become a series of reports on some important topic. Although this can be viewed as a standard class</context>
</contexts>
<marker>Allan, Carbonell, Doddington, Yamron, Yang, 1998</marker>
<rawString>J. Allan, J. Carbonell, G. Doddington, J. Yamron, and Y. Yang. 1998. Topic detection and tracking pilot study: Final report. In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop, pages 194-218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amant</author>
</authors>
<title>A Mixed-Initiative Planning Approach to Exploratory Data Analysis.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>Univeristy of Massachusetts,</institution>
<location>Amherst.</location>
<contexts>
<context position="17795" citStr="Amant (1996)" startWordPosition="2908" endWordPosition="2909">r issuing sequences of queries and related operations across text collections, and tightly coupled statistical and visualization tools for the examination of associations among concepts that co-occur within the retrieved documents. Both sets of tools make use of attributes associated specifically with text collections and 3LINDI: Linking Information for Novel Discovery and Insight. their metadata. Thus the broadening, narrowing, and linking of relations seen in the patent example should be tightly integrated with analysis and interpretation tools as needed in the biomedical example. Following Amant (1996), the interaction paradigm is that of a mixed-initiative balance of control between user and system. The interaction is a cycle in which the system suggests hypotheses and strategies for investigating these hypotheses, and the user either uses or ignores these suggestions and decides on the next move. We are interested in an important problem in molecular biology, that of automating the discovery of the function of newly sequenced genes (Walker et al., 1998). Human genome researchers perform experiments in which they analyze co-expression of tens of thousands of novel and known genes simultane</context>
<context position="21556" citStr="Amant, 1996" startWordPosition="3536" endWordPosition="3537">tem must help an expert user generate and record good exploration strategies. The user interface provides a mechanism for recording and modifying sequences of actions. These include facilities that refer to metadata structure, allowing, for example, query terms to be expanded by terms one level above or below them in a subject hierarchy. Once a successful set of strategies has been devised, they can be re-used by other researchers and (with luck) by an automated version of the system. The intent is to build up enough strategies that the system will begin to be used as an assistant or advisor (Amant, 1996), ranking hypotheses according to projected importance and plausibility. Thus the emphasis of this system is to help automate the tedious parts of the text manipulation process and to integrate underlying computationally-driven text analysis with human-guided decision making within exploratory data analysis over text. 6 Summary For almost a decade the computational linguistics community has viewed large text collections as a resource to be tapped in order to produce better text analysis algorithms. In this paper, I have attempted to suggest a new emphasis: the use of large online text collecti</context>
</contexts>
<marker>Amant, 1996</marker>
<rawString>Robert St. Amant. 1996. A Mixed-Initiative Planning Approach to Exploratory Data Analysis. Ph.D. thesis, Univeristy of Massachusetts, Amherst.</rawString>
</citation>
<citation valid="true">
<title>Using Large Corpora.</title>
<date>1994</date>
<editor>Susan Armstrong, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1994</marker>
<rawString>Susan Armstrong, editor. 1994. Using Large Corpora. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ricardo Baeza-Yates</author>
<author>Berthier Ribeiro-Neto</author>
</authors>
<title>Modern Information Retrieval.</title>
<date>1999</date>
<publisher>AddisonWesley Longman Publishing Company.</publisher>
<contexts>
<context position="2732" citStr="Baeza-Yates and Ribeiro-Neto, 1999" startWordPosition="436" endWordPosition="439">ds and patterns across very large datasets, usually for the purposes of decision making (Fayyad and Uthurusamy, 1999; Fayyad, 1997). Part of what I wish to argue here is that in the case of text, it can be interesting to take the mining-fornuggets metaphor seriously. The various contrasts discussed below are summarized in Table 1. 2 TDM vs. Information Access It is important to differentiate between text data mining and information access (or information retrieval, as it is more widely known). The goal of information access is to help users find documents that satisfy their information needs (Baeza-Yates and Ribeiro-Neto, 1999). The standard procedure is akin to looking for needles in a needlestack — the problem isn&apos;t so much that the desired information is not known, but rather that the desired information coexists with many other valid pieces of information. Just because a user is currently interested in NAFTA and not Furbies does not mean that all descriptions of Furbies are worthless. The problem is one of homing in on what is currently of interest to the user. As noted above, the goal of data mining is to discover or derive new information from data, finding patterns across datasets, and/or separating signal fr</context>
</contexts>
<marker>Baeza-Yates, Ribeiro-Neto, 1999</marker>
<rawString>Ricardo Baeza-Yates and Berthier Ribeiro-Neto. 1999. Modern Information Retrieval. AddisonWesley Longman Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcia J Bates</author>
</authors>
<title>The berry-picking search: User interface design.</title>
<date>1990</date>
<booktitle>User Interface Design.</booktitle>
<editor>In Harold Thimbleby, editor,</editor>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="18944" citStr="Bates, 1990" startWordPosition="3085" endWordPosition="3086">ression of tens of thousands of novel and known genes simultaneously.4 Given this huge collection of genetic information, the goal is to determine which of the novel genes are medically interesting, meaning that they are co-expressed with already understood genes which are known to be involved in disease. Our strategy is to explore the biomedical literature, trying to formulate plausible hypotheses about which genes are of interest. Most information access systems require the user to execute and keep track of tactical moves, often distracting from the thought-intensive aspects of the problem (Bates, 1990). The LINDI interface provides a facility for users to build and so reuse sequences of query operations via a drag-and-drop interface. These allow the user to repeat the same sequence of actions for different queries. In the gene example, this allows the user to specify a sequence of operations to apply to one co-expressed gene, and then iterate this sequence over a list of other co-expressed genes that can be dragged onto the template. (The Visage interface (Derthick et al., 1997) implements this kind of functionality within its information-centric framework.) These include the following oper</context>
</contexts>
<marker>Bates, 1990</marker>
<rawString>Marcia J. Bates. 1990. The berry-picking search: User interface design. In Harold Thimbleby, editor, User Interface Design. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Beeferman</author>
</authors>
<title>Lexical discovery with an enriched semantic network.</title>
<date>1998</date>
<booktitle>In Proceedings of the ACL/COLING Workshop on Applications of WordNet in Natural Language Processing Systems,</booktitle>
<pages>358--364</pages>
<contexts>
<context position="13213" citStr="Beeferman (1998)" startWordPosition="2167" endWordPosition="2168">inds of migraine headache; a hypothesis which did not exist in the literature at the time Swanson found these links. The hypothesis has to be tested via non-textual means, but the important point is that a new, potentially plausible medical hypothesis was derived from a combination of text fragments and the explorer&apos;s medical expertise. (According to Swanson (1991), subsequent study found support for the magnesiummigraine hypothesis (Ramadan et al., 1989).) This approach has been only partially automated. There is, of course, a potential for combinatorial explosion of potentially valid links. Beeferman (1998) has developed a flexible interface and analysis tool for exploring certain kinds of chains of links among lexical relations within WordNet.2 However, sophisticated new algorithms are needed for helping in the pruning process, since a good pruning algorithm will want to take into account various kinds of semantic constraints. This may be an interesting area of investigation for computational linguists. 2 See http://www.link.cs.cmu.edu/lexfn 5.2 Using Text to Uncover Social Impact Switching to an entirely different domain, consider a recent effort to determine the effects of publicly financed r</context>
</contexts>
<marker>Beeferman, 1998</marker>
<rawString>Douglas Beeferman. 1998. Lexical discovery with an enriched semantic network. In Proceedings of the ACL/COLING Workshop on Applications of WordNet in Natural Language Processing Systems, pages 358-364.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Brachman</author>
<author>P G Selfridge</author>
<author>L G Terveen</author>
<author>B Altman</author>
<author>A Borgida</author>
<author>F Halper</author>
<author>T Kirk</author>
<author>A Lazar</author>
<author>D L McGuinness</author>
<author>L A Resnick</author>
</authors>
<title>Integrated support for data archaeology.</title>
<date>1993</date>
<journal>International Journal of Intelligent and Cooperative Information Systems,</journal>
<pages>2--2</pages>
<contexts>
<context position="1565" citStr="Brachman et al., 1993" startWordPosition="250" endWordPosition="253">for computational linguists. I describe examples of what I consider to be real text data mining efforts and briefly outline recent ideas about how to pursue exploratory data analysis over text. 1 Introduction The nascent field of text data mining (TDM) has the peculiar distinction of having a name and a fair amount of hype but as yet almost no practitioners. I suspect this has happened because people assume TDM is a natural extension of the slightly less nascent field of data mining (DM), also known as knowledge discovery in databases (Fayyad and Uthurusamy, 1999), and information archeology (Brachman et al., 1993). Additionally, there are some disagreements about what actually constitutes data mining. It turns out that &amp;quot;mining&amp;quot; is not a very good metaphor for what people in the field actually do. Mining implies extracting precious nuggets of ore from otherwise worthless rock. If data mining really followed this metaphor, it would mean that people were discovering new factoids within their inventory databases. However, in practice this is not really the case. Instead, data mining applications tend to be (semi)automated discovery of trends and patterns across very large datasets, usually for the purposes</context>
</contexts>
<marker>Brachman, Selfridge, Terveen, Altman, Borgida, Halper, Kirk, Lazar, McGuinness, Resnick, 1993</marker>
<rawString>R. J. Brachman, P. G. Selfridge, L. G. Terveen, B. Altman, A Borgida, F. Halper, T. Kirk, A. Lazar, D. L. McGuinness, and L. A. Resnick. 1993. Integrated support for data archaeology. International Journal of Intelligent and Cooperative Information Systems, 2(2):159-185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William J Broad</author>
</authors>
<title>Study finds public science is pillar of industry.</title>
<date>1997</date>
<booktitle>In The</booktitle>
<location>New York Times,</location>
<contexts>
<context position="14211" citStr="Broad (1997)" startWordPosition="2321" endWordPosition="2322">tational linguists. 2 See http://www.link.cs.cmu.edu/lexfn 5.2 Using Text to Uncover Social Impact Switching to an entirely different domain, consider a recent effort to determine the effects of publicly financed research on industrial advances (Narin et al., 1997). After years of preliminary studies and building special purpose tools, the authors found that the technology industry relies more heavily than ever on government-sponsored research results. The authors explored relationships among patent text and the published research literature, using a procedure which was reported as follows in Broad (1997): The CHI Research team examined the science references on the front pages of American patents in two recent periods — 1987 and 1988, as well as 1993 and 1994 — looking at all the 397,660 patents issued. It found 242,000 identifiable science references and zeroed in on those published in the preceding 11 years, which turned out to be 80 percent of them. Searches of computer databases allowed the linking of 109,000 of these references to known journals and authors&apos; addresses. After eliminating redundant citations to the same paper, as well as articles with no known American author, the study ha</context>
</contexts>
<marker>Broad, 1997</marker>
<rawString>William J. Broad. 1997. Study finds public science is pillar of industry. In The New York Times, May 13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Chalmers</author>
<author>Paul Chitson</author>
</authors>
<title>Bead: Exploration in information visualization.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th Annual International ACM/SIGIR Conference,</booktitle>
<pages>330--337</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="4759" citStr="Chalmers and Chitson, 1992" startWordPosition="786" endWordPosition="789"> the transactions run in a Web-based system, be it to optimize the system or to find information about the clients using the system.1 This search-centric view misses the point that we might actually want to treat the information in the web as a large knowledge base from which we can extract new, never-before encountered information (Craven et al., 1998). On the other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory</context>
</contexts>
<marker>Chalmers, Chitson, 1992</marker>
<rawString>Matthew Chalmers and Paul Chitson. 1992. Bead: Exploration in information visualization. In Proceedings of the 15th Annual International ACM/SIGIR Conference, pages 330-337, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Craven</author>
<author>D DiPasquo</author>
<author>D Freitag</author>
<author>A McCallum</author>
<author>T Mitchell</author>
<author>K Nigam</author>
<author>S Slattery</author>
</authors>
<title>Learning to extract symbolic knowledge from the world wide web.</title>
<date>1998</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="4488" citStr="Craven et al., 1998" startWordPosition="743" endWordPosition="746">: ... Two challenges are predominant for data mining on the Web. The first goal is to help users in finding useful information on the Web and in discovering knowledge about a domain that is represented by a collection of Web-documents. The second goal is to analyse the transactions run in a Web-based system, be it to optimize the system or to find information about the clients using the system.1 This search-centric view misses the point that we might actually want to treat the information in the web as a large knowledge base from which we can extract new, never-before encountered information (Craven et al., 1998). On the other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, </context>
</contexts>
<marker>Craven, DiPasquo, Freitag, McCallum, Mitchell, Nigam, Slattery, 1998</marker>
<rawString>M. Craven, D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigam, and S. Slattery. 1998. Learning to extract symbolic knowledge from the world wide web. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Karger Pedersen</author>
<author>John W Tukey</author>
</authors>
<title>Scatter/Gather: A cluster-based approach to browsing large document collections.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th Annual International ACM/SIGIR Conference,</booktitle>
<pages>318--329</pages>
<location>Copenhagen, Denmark.</location>
<marker>Pedersen, Tukey, 1992</marker>
<rawString>Douglass R. Cutting, Jan 0. Pedersen, David Karger, and John W. Tukey. 1992. Scatter/Gather: A cluster-based approach to browsing large document collections. In Proceedings of the 15th Annual International ACM/SIGIR Conference, pages 318-329, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Ronen Feldman</author>
<author>Haym Hirsh</author>
</authors>
<title>Keyword-based browsing and analysis of large document sets.</title>
<date>1996</date>
<booktitle>In Proceedings of the Fifth Annual Symposium on Document Analysis and Information Retrieval (SDAIR),</booktitle>
<location>Las Vegas, NV.</location>
<contexts>
<context position="8586" citStr="Dagan et al., 1996" startWordPosition="1380" endWordPosition="1383">ining ? database queries Textual data computational linguistics real TDM information retrieval Table 1: A classification of data mining and text data mining applications. compact summary of something that is already known. However, there are two recent areas of inquiry that make use of text categorization and do seem to fit within the conceptual framework of discovery of trends and patterns within textual data for more general purpose usage. One body of work uses text category labels (associated with Reuters newswire) to find &amp;quot;unexpected patterns&amp;quot; among text articles (Feldman and Dagan, 1995; Dagan et al., 1996; Feldman et al., 1997). The main approach is to compare distributions of category assignments within subsets of the document collection. For instance, distributions of commodities in country Cl are compared against those of country C2 to see if interesting or unexpected trends can be found. Extending this idea, one country&apos;s export trends might be compared against those of a set of countries that are seen as an economic unit (such as the 0-7). Another effort is that of the DARPA Topic Detection and Tracking initiative (Allan et al., 1998). While several of the tasks within this initiative are</context>
</contexts>
<marker>Dagan, Feldman, Hirsh, 1996</marker>
<rawString>Ido Dagan, Ronen Feldman, and Haym Hirsh. 1996. Keyword-based browsing and analysis of large document sets. In Proceedings of the Fifth Annual Symposium on Document Analysis and Information Retrieval (SDAIR), Las Vegas, NV.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Derthick</author>
<author>John Kolojejchick</author>
<author>Steven F Roth</author>
</authors>
<title>An interactive visualization environment for data exploration.</title>
<date>1997</date>
<booktitle>In Proceedings of the Third Annual Conference on Knowledge Discovery and Data Mining (KDD),</booktitle>
<location>Newport Beach.</location>
<contexts>
<context position="19430" citStr="Derthick et al., 1997" startWordPosition="3166" endWordPosition="3169"> the user to execute and keep track of tactical moves, often distracting from the thought-intensive aspects of the problem (Bates, 1990). The LINDI interface provides a facility for users to build and so reuse sequences of query operations via a drag-and-drop interface. These allow the user to repeat the same sequence of actions for different queries. In the gene example, this allows the user to specify a sequence of operations to apply to one co-expressed gene, and then iterate this sequence over a list of other co-expressed genes that can be dragged onto the template. (The Visage interface (Derthick et al., 1997) implements this kind of functionality within its information-centric framework.) These include the following operations (see Figure 1): • Iteration of an operation over the items within a set. (This allows each item retrieved in a previous query to be use as a 4A gene g&apos; co-expresses with gene g when both are found to be activated in the same cells at the same time with much more likelihood than chance. 7 search terms for a new query.) • Transformation, i.e., applying an operation to an item and returning a transformed item (such as extracting a feature). • Ranking, i.e., applying an operatio</context>
</contexts>
<marker>Derthick, Kolojejchick, Roth, 1997</marker>
<rawString>Mark Derthick, John Kolojejchick, and Steven F. Roth. 1997. An interactive visualization environment for data exploration. In Proceedings of the Third Annual Conference on Knowledge Discovery and Data Mining (KDD), Newport Beach.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Usama Fayyad</author>
<author>Ramasamy Uthurusamy</author>
</authors>
<title>Data mining and knowledge discovery in databases: Introduction to the special issue.</title>
<date>1999</date>
<journal>Communications of the ACM,</journal>
<volume>39</volume>
<issue>11</issue>
<contexts>
<context position="1513" citStr="Fayyad and Uthurusamy, 1999" startWordPosition="243" endWordPosition="246">ts is to draw attention to exciting new kinds of problems for computational linguists. I describe examples of what I consider to be real text data mining efforts and briefly outline recent ideas about how to pursue exploratory data analysis over text. 1 Introduction The nascent field of text data mining (TDM) has the peculiar distinction of having a name and a fair amount of hype but as yet almost no practitioners. I suspect this has happened because people assume TDM is a natural extension of the slightly less nascent field of data mining (DM), also known as knowledge discovery in databases (Fayyad and Uthurusamy, 1999), and information archeology (Brachman et al., 1993). Additionally, there are some disagreements about what actually constitutes data mining. It turns out that &amp;quot;mining&amp;quot; is not a very good metaphor for what people in the field actually do. Mining implies extracting precious nuggets of ore from otherwise worthless rock. If data mining really followed this metaphor, it would mean that people were discovering new factoids within their inventory databases. However, in practice this is not really the case. Instead, data mining applications tend to be (semi)automated discovery of trends and patterns </context>
<context position="7546" citStr="Fayyad and Uthurusamy, 1999" startWordPosition="1208" endWordPosition="1211">Net relations (Fellbaum, 1998) by identifying lexicosyntactic patterns that unambiguously indicate those relations (Hearst, 1998), and automatic acquisition of subcategorization data from large text corpora (Manning, 1993). However, these serve the specific needs of computational linguistics and are not applicable to a broader audience. 4 TDM and Category Metadata Some researchers have claimed that text categorization should be considered text data mining. Although analogies can be found in the data mining literature (e.g., referring to classification of astronomical phenomena as data mining (Fayyad and Uthurusamy, 1999)), I believe when applied to text categorization this is a misnomer. Text categorization is a boiling down of the specific content of a document into one (or more) of a set of pre-defined labels. This does not lead to discovery of new information; presumably the person who wrote the document knew what it was about. Rather, it produces a 4 Finding Patterns Novel Finding Nuggets Non-Novel Non-textual data standard data mining ? database queries Textual data computational linguistics real TDM information retrieval Table 1: A classification of data mining and text data mining applications. compact</context>
</contexts>
<marker>Fayyad, Uthurusamy, 1999</marker>
<rawString>Usama Fayyad and Ramasamy Uthurusamy. 1999. Data mining and knowledge discovery in databases: Introduction to the special issue. Communications of the ACM, 39(11), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Usama Fayyad</author>
</authors>
<date>1997</date>
<journal>Editorial. Data Mining and Knowledge Discovery,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="2228" citStr="Fayyad, 1997" startWordPosition="355" endWordPosition="356"> what actually constitutes data mining. It turns out that &amp;quot;mining&amp;quot; is not a very good metaphor for what people in the field actually do. Mining implies extracting precious nuggets of ore from otherwise worthless rock. If data mining really followed this metaphor, it would mean that people were discovering new factoids within their inventory databases. However, in practice this is not really the case. Instead, data mining applications tend to be (semi)automated discovery of trends and patterns across very large datasets, usually for the purposes of decision making (Fayyad and Uthurusamy, 1999; Fayyad, 1997). Part of what I wish to argue here is that in the case of text, it can be interesting to take the mining-fornuggets metaphor seriously. The various contrasts discussed below are summarized in Table 1. 2 TDM vs. Information Access It is important to differentiate between text data mining and information access (or information retrieval, as it is more widely known). The goal of information access is to help users find documents that satisfy their information needs (Baeza-Yates and Ribeiro-Neto, 1999). The standard procedure is akin to looking for needles in a needlestack — the problem isn&apos;t so </context>
</contexts>
<marker>Fayyad, 1997</marker>
<rawString>Usama Fayyad. 1997. Editorial. Data Mining and Knowledge Discovery, 1(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
<author>Ido Dagan</author>
</authors>
<title>KDT — knowledge discovery in texts.</title>
<date>1995</date>
<booktitle>In Proceedings of the First Annual Conference on Knowledge Discovery and Data Mining (KDD),</booktitle>
<location>Montreal.</location>
<contexts>
<context position="8566" citStr="Feldman and Dagan, 1995" startWordPosition="1375" endWordPosition="1379">tual data standard data mining ? database queries Textual data computational linguistics real TDM information retrieval Table 1: A classification of data mining and text data mining applications. compact summary of something that is already known. However, there are two recent areas of inquiry that make use of text categorization and do seem to fit within the conceptual framework of discovery of trends and patterns within textual data for more general purpose usage. One body of work uses text category labels (associated with Reuters newswire) to find &amp;quot;unexpected patterns&amp;quot; among text articles (Feldman and Dagan, 1995; Dagan et al., 1996; Feldman et al., 1997). The main approach is to compare distributions of category assignments within subsets of the document collection. For instance, distributions of commodities in country Cl are compared against those of country C2 to see if interesting or unexpected trends can be found. Extending this idea, one country&apos;s export trends might be compared against those of a set of countries that are seen as an economic unit (such as the 0-7). Another effort is that of the DARPA Topic Detection and Tracking initiative (Allan et al., 1998). While several of the tasks within</context>
</contexts>
<marker>Feldman, Dagan, 1995</marker>
<rawString>Ronen Feldman and Ido Dagan. 1995. KDT — knowledge discovery in texts. In Proceedings of the First Annual Conference on Knowledge Discovery and Data Mining (KDD), Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
<author>Will Klosgen</author>
<author>Amir Zilberstein</author>
</authors>
<title>Visualization techniques to explore data mining results for document collections.</title>
<date>1997</date>
<booktitle>In Proceedings of the Third Annual Conference on Knowledge Discovery and Data Mining (KDD),</booktitle>
<location>Newport Beach.</location>
<contexts>
<context position="8609" citStr="Feldman et al., 1997" startWordPosition="1384" endWordPosition="1388">ries Textual data computational linguistics real TDM information retrieval Table 1: A classification of data mining and text data mining applications. compact summary of something that is already known. However, there are two recent areas of inquiry that make use of text categorization and do seem to fit within the conceptual framework of discovery of trends and patterns within textual data for more general purpose usage. One body of work uses text category labels (associated with Reuters newswire) to find &amp;quot;unexpected patterns&amp;quot; among text articles (Feldman and Dagan, 1995; Dagan et al., 1996; Feldman et al., 1997). The main approach is to compare distributions of category assignments within subsets of the document collection. For instance, distributions of commodities in country Cl are compared against those of country C2 to see if interesting or unexpected trends can be found. Extending this idea, one country&apos;s export trends might be compared against those of a set of countries that are seen as an economic unit (such as the 0-7). Another effort is that of the DARPA Topic Detection and Tracking initiative (Allan et al., 1998). While several of the tasks within this initiative are standard text analysis</context>
</contexts>
<marker>Feldman, Klosgen, Zilberstein, 1997</marker>
<rawString>Ronen Feldman, Will Klosgen, and Amir Zilberstein. 1997. Visualization techniques to explore data mining results for document collections. In Proceedings of the Third Annual Conference on Knowledge Discovery and Data Mining (KDD), Newport Beach.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="13213" citStr="(1998)" startWordPosition="2168" endWordPosition="2168">graine headache; a hypothesis which did not exist in the literature at the time Swanson found these links. The hypothesis has to be tested via non-textual means, but the important point is that a new, potentially plausible medical hypothesis was derived from a combination of text fragments and the explorer&apos;s medical expertise. (According to Swanson (1991), subsequent study found support for the magnesiummigraine hypothesis (Ramadan et al., 1989).) This approach has been only partially automated. There is, of course, a potential for combinatorial explosion of potentially valid links. Beeferman (1998) has developed a flexible interface and analysis tool for exploring certain kinds of chains of links among lexical relations within WordNet.2 However, sophisticated new algorithms are needed for helping in the pruning process, since a good pruning algorithm will want to take into account various kinds of semantic constraints. This may be an interesting area of investigation for computational linguists. 2 See http://www.link.cs.cmu.edu/lexfn 5.2 Using Text to Uncover Social Impact Switching to an entirely different domain, consider a recent effort to determine the effects of publicly financed r</context>
</contexts>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automated discovery of wordnet relations.</title>
<date>1998</date>
<booktitle>In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="7047" citStr="Hearst, 1998" startWordPosition="1133" endWordPosition="1134">his kind of information can also be used to improve information retrieval algorithms. However, the kinds of patterns found and used in computational linguistics are not likely to be what the general business community hopes for when they use the term text data mining. Within the computational linguistics framework, efforts in automatic augmentation of existing lexical structures seem to fit the datamining-as-ore-extraction metaphor. Examples include automatic augmentation of WordNet relations (Fellbaum, 1998) by identifying lexicosyntactic patterns that unambiguously indicate those relations (Hearst, 1998), and automatic acquisition of subcategorization data from large text corpora (Manning, 1993). However, these serve the specific needs of computational linguistics and are not applicable to a broader audience. 4 TDM and Category Metadata Some researchers have claimed that text categorization should be considered text data mining. Although analogies can be found in the data mining literature (e.g., referring to classification of astronomical phenomena as data mining (Fayyad and Uthurusamy, 1999)), I believe when applied to text categorization this is a misnomer. Text categorization is a boiling</context>
</contexts>
<marker>Hearst, 1998</marker>
<rawString>Marti A. Hearst. 1998. Automated discovery of wordnet relations. In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David G Hendry</author>
<author>David J Harper</author>
</authors>
<title>An informal information-seeking environment.</title>
<date>1997</date>
<journal>Journal of the American Society for Information Science,</journal>
<pages>48--11</pages>
<contexts>
<context position="20679" citStr="Hendry and Harper, 1997" startWordPosition="3380" endWordPosition="3383">eturning a (possibly) reordered set of items with the same cardinality. • Selection, i.e., applying an operation to a set of items and returning a (possibly) reordered set of items with the same or smaller cardinality. • Reduction, i.e., applying an operation to one or more sets of items to yield a singleton result (e.g., to compute percentages and averages). This system will allow maintenance of several different types of history including history of commands issued, history of strategies employed, and history of hypotheses tested. For the history view, we plan to use a &amp;quot;spreadsheet&amp;quot; layout (Hendry and Harper, 1997) as well as a variation on a &amp;quot;slide sorter&amp;quot; view which Visage uses for presentation creation but not for history retention (Roth et al., 1997). Since gene function discovery is a new area, there is not yet a known set of exploration strategies. So initially the system must help an expert user generate and record good exploration strategies. The user interface provides a mechanism for recording and modifying sequences of actions. These include facilities that refer to metadata structure, allowing, for example, query terms to be expanded by terms one level above or below them in a subject hierar</context>
</contexts>
<marker>Hendry, Harper, 1997</marker>
<rawString>David G. Hendry and David J. Harper. 1997. An informal information-seeking environment. Journal of the American Society for Information Science, 48(11):1036-1048.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David C Hoaglin</author>
<author>Frederick Mosteller</author>
<author>John W Tukey</author>
</authors>
<title>Understanding Robust and Exploratory Data Analysis.</title>
<date>1983</date>
<publisher>John Wiley Sz Sons, Inc.</publisher>
<contexts>
<context position="10682" citStr="Hoaglin et al., 1983" startWordPosition="1744" endWordPosition="1747">ining is that they use text metadata to tell us something about the world, outside of the text collection itself. (However, since this application uses metadata associated with text documents, rather than the text directly, it is unclear if it should be considered text data mining or standard data mining.) The computational linguistics applications tell us about how to improve language analysis, but they do not discover more widely usable information. 5 Text Data Mining as Exploratory Data Analysis Another way to view text data mining is as a process of exploratory data analysis (Tukey, 1977; Hoaglin et al., 1983) that leads to the discovery of heretofore unknown information, or to answers for questions for which the answer is not currently known. Of course, it can be argued that the standard practice of reading textbooks, journal articles and other documents helps researchers in the discovery of new information, since this is an integral part of the research process. However, the idea here is to use text for discovery in a more direct manner. Two examples are described below. 5.1 Using Text to Form Hypotheses about Disease For more than a decade, Don Swanson has eloquently argued why it is plausible t</context>
</contexts>
<marker>Hoaglin, Mosteller, Tukey, 1983</marker>
<rawString>David C. Hoaglin, Frederick Mosteller, and John W. Tukey. 1983. Understanding Robust and Exploratory Data Analysis. John Wiley Sz Sons, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th ACM-SIAM Symposium on Discrete Algorithms.</booktitle>
<contexts>
<context position="5124" citStr="Kleinberg, 1998" startWordPosition="847" endWordPosition="848"> the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory data analysis. Our efforts in this direction are embodied in the LINDI project, described in Section 5 below. 3 TDM and Computational Linguistics If we extrapolate from data mining (as practiced) on numerical data to data mining from text collections, we discover that there already &apos;http://www.aaai.org/Conferences/KDD/1997/kdd97- schedule.html exists a field eng</context>
</contexts>
<marker>Kleinberg, 1998</marker>
<rawString>Jon Kleinberg. 1998. Authoritative sources in a hyperlinked environment. In Proceedings of the 9th ACM-SIAM Symposium on Discrete Algorithms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray R Larson</author>
</authors>
<title>Bibliometrics of the world wide web: An exploratory analysis of the intellectual structure of cyberspace.</title>
<date>1996</date>
<booktitle>In ASIS &apos;96: Proceedings of the 1996 Annual ASIS Meeting.</booktitle>
<contexts>
<context position="5106" citStr="Larson, 1996" startWordPosition="845" endWordPosition="846">he other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory data analysis. Our efforts in this direction are embodied in the LINDI project, described in Section 5 below. 3 TDM and Computational Linguistics If we extrapolate from data mining (as practiced) on numerical data to data mining from text collections, we discover that there already &apos;http://www.aaai.org/Conferences/KDD/1997/kdd97- schedule.html </context>
</contexts>
<marker>Larson, 1996</marker>
<rawString>Ray R. Larson. 1996. Bibliometrics of the world wide web: An exploratory analysis of the intellectual structure of cyberspace. In ASIS &apos;96: Proceedings of the 1996 Annual ASIS Meeting.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xia Lin</author>
<author>Dagobert Soergel</author>
<author>Gary Marchionini</author>
</authors>
<title>A self-organizing semantic map for information retrieval.</title>
<date>1991</date>
<booktitle>In Proceedings of the 14th Annual International ACM/SIGIR Conference,</booktitle>
<pages>262--269</pages>
<location>Chicago.</location>
<contexts>
<context position="4812" citStr="Lin et al., 1991" startWordPosition="796" endWordPosition="799">the system or to find information about the clients using the system.1 This search-centric view misses the point that we might actually want to treat the information in the web as a large knowledge base from which we can extract new, never-before encountered information (Craven et al., 1998). On the other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory data analysis. Our efforts in this direction are emb</context>
</contexts>
<marker>Lin, Soergel, Marchionini, 1991</marker>
<rawString>Xia Lin, Dagobert Soergel, and Gary Marchionini. 1991. A self-organizing semantic map for information retrieval. In Proceedings of the 14th Annual International ACM/SIGIR Conference, pages 262-269, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
</authors>
<title>Automatic acquisition of a large subcategorization dictionary from corpora.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Lingusitics,</booktitle>
<pages>235--242</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="7140" citStr="Manning, 1993" startWordPosition="1145" endWordPosition="1146">r, the kinds of patterns found and used in computational linguistics are not likely to be what the general business community hopes for when they use the term text data mining. Within the computational linguistics framework, efforts in automatic augmentation of existing lexical structures seem to fit the datamining-as-ore-extraction metaphor. Examples include automatic augmentation of WordNet relations (Fellbaum, 1998) by identifying lexicosyntactic patterns that unambiguously indicate those relations (Hearst, 1998), and automatic acquisition of subcategorization data from large text corpora (Manning, 1993). However, these serve the specific needs of computational linguistics and are not applicable to a broader audience. 4 TDM and Category Metadata Some researchers have claimed that text categorization should be considered text data mining. Although analogies can be found in the data mining literature (e.g., referring to classification of astronomical phenomena as data mining (Fayyad and Uthurusamy, 1999)), I believe when applied to text categorization this is a misnomer. Text categorization is a boiling down of the specific content of a document into one (or more) of a set of pre-defined labels</context>
</contexts>
<marker>Manning, 1993</marker>
<rawString>Christopher D. Manning. 1993. Automatic acquisition of a large subcategorization dictionary from corpora. In Proceedings of the 31st Annual Meeting of the Association for Computational Lingusitics, pages 235-242, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Narin</author>
<author>Kimberly S Hamilton</author>
<author>Dominic Olivastro</author>
</authors>
<title>The increasing linkage between us technology and public science.</title>
<date>1997</date>
<journal>Research Policy,</journal>
<pages>26--3</pages>
<contexts>
<context position="13864" citStr="Narin et al., 1997" startWordPosition="2267" endWordPosition="2270">ace and analysis tool for exploring certain kinds of chains of links among lexical relations within WordNet.2 However, sophisticated new algorithms are needed for helping in the pruning process, since a good pruning algorithm will want to take into account various kinds of semantic constraints. This may be an interesting area of investigation for computational linguists. 2 See http://www.link.cs.cmu.edu/lexfn 5.2 Using Text to Uncover Social Impact Switching to an entirely different domain, consider a recent effort to determine the effects of publicly financed research on industrial advances (Narin et al., 1997). After years of preliminary studies and building special purpose tools, the authors found that the technology industry relies more heavily than ever on government-sponsored research results. The authors explored relationships among patent text and the published research literature, using a procedure which was reported as follows in Broad (1997): The CHI Research team examined the science references on the front pages of American patents in two recent periods — 1987 and 1988, as well as 1993 and 1994 — looking at all the 397,660 patents issued. It found 242,000 identifiable science references </context>
</contexts>
<marker>Narin, Hamilton, Olivastro, 1997</marker>
<rawString>Francis Narin, Kimberly S. Hamilton, and Dominic Olivastro. 1997. The increasing linkage between us technology and public science. Research Policy, 26(3):317-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helen J Peat</author>
<author>Peter Willett</author>
</authors>
<title>The limitations of term co-occurence data for query expansion in document retrieval systems.</title>
<date>1991</date>
<journal>JASIS,</journal>
<pages>42--5</pages>
<contexts>
<context position="4926" citStr="Peat and Willett, 1991" startWordPosition="814" endWordPosition="817">oint that we might actually want to treat the information in the web as a large knowledge base from which we can extract new, never-before encountered information (Craven et al., 1998). On the other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory data analysis. Our efforts in this direction are embodied in the LINDI project, described in Section 5 below. 3 TDM and Computational Linguistics If we extrapolate fr</context>
</contexts>
<marker>Peat, Willett, 1991</marker>
<rawString>Helen J. Peat and Peter Willett. 1991. The limitations of term co-occurence data for query expansion in document retrieval systems. JASIS, 42(5):378-383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N M Ramadan</author>
<author>H Halvorson</author>
<author>A Vandelinde</author>
<author>S R Levine</author>
</authors>
<date>1989</date>
<pages>29--7</pages>
<note>Low brain magnesium in migraine. Headache,</note>
<contexts>
<context position="13056" citStr="Ramadan et al., 1989" startWordPosition="2141" endWordPosition="2144"> patients have high platelet aggregability • magnesium can suppress platelet aggregability These clues suggest that magnesium deficiency may play a role in some kinds of migraine headache; a hypothesis which did not exist in the literature at the time Swanson found these links. The hypothesis has to be tested via non-textual means, but the important point is that a new, potentially plausible medical hypothesis was derived from a combination of text fragments and the explorer&apos;s medical expertise. (According to Swanson (1991), subsequent study found support for the magnesiummigraine hypothesis (Ramadan et al., 1989).) This approach has been only partially automated. There is, of course, a potential for combinatorial explosion of potentially valid links. Beeferman (1998) has developed a flexible interface and analysis tool for exploring certain kinds of chains of links among lexical relations within WordNet.2 However, sophisticated new algorithms are needed for helping in the pruning process, since a good pruning algorithm will want to take into account various kinds of semantic constraints. This may be an interesting area of investigation for computational linguists. 2 See http://www.link.cs.cmu.edu/lexf</context>
</contexts>
<marker>Ramadan, Halvorson, Vandelinde, Levine, 1989</marker>
<rawString>N. M. Ramadan, H. Halvorson, A. Vandelinde, and S.R. Levine. 1989. Low brain magnesium in migraine. Headache, 29(7):416-419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Earl Rennison</author>
</authors>
<title>Galaxy of news: An approach to visualizing and understanding expansive news landscapes.</title>
<date>1994</date>
<booktitle>In Proceedings of UIST 94, ACM Symposium on User Interface Software and Technology,</booktitle>
<pages>3--12</pages>
<location>New York.</location>
<contexts>
<context position="4775" citStr="Rennison, 1994" startWordPosition="790" endWordPosition="791">eb-based system, be it to optimize the system or to find information about the clients using the system.1 This search-centric view misses the point that we might actually want to treat the information in the web as a large knowledge base from which we can extract new, never-before encountered information (Craven et al., 1998). On the other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory data analysis. </context>
</contexts>
<marker>Rennison, 1994</marker>
<rawString>Earl Rennison. 1994. Galaxy of news: An approach to visualizing and understanding expansive news landscapes. In Proceedings of UIST 94, ACM Symposium on User Interface Software and Technology, pages 3-12, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven F Roth</author>
<author>Mei C Chuah</author>
<author>Stephan Kerpedjiev</author>
<author>John A Kolojejchick</author>
<author>Peter Lucas</author>
</authors>
<title>Towards an information visualization workspace: Combining multiple means of expression.</title>
<date>1997</date>
<journal>HumanComputer Interaction,</journal>
<pages>12--1</pages>
<contexts>
<context position="20821" citStr="Roth et al., 1997" startWordPosition="3406" endWordPosition="3409">possibly) reordered set of items with the same or smaller cardinality. • Reduction, i.e., applying an operation to one or more sets of items to yield a singleton result (e.g., to compute percentages and averages). This system will allow maintenance of several different types of history including history of commands issued, history of strategies employed, and history of hypotheses tested. For the history view, we plan to use a &amp;quot;spreadsheet&amp;quot; layout (Hendry and Harper, 1997) as well as a variation on a &amp;quot;slide sorter&amp;quot; view which Visage uses for presentation creation but not for history retention (Roth et al., 1997). Since gene function discovery is a new area, there is not yet a known set of exploration strategies. So initially the system must help an expert user generate and record good exploration strategies. The user interface provides a mechanism for recording and modifying sequences of actions. These include facilities that refer to metadata structure, allowing, for example, query terms to be expanded by terms one level above or below them in a subject hierarchy. Once a successful set of strategies has been devised, they can be re-used by other researchers and (with luck) by an automated version of</context>
</contexts>
<marker>Roth, Chuah, Kerpedjiev, Kolojejchick, Lucas, 1997</marker>
<rawString>Steven F. Roth, Mei C. Chuah, Stephan Kerpedjiev, John A. Kolojejchick, and Peter Lucas. 1997. Towards an information visualization workspace: Combining multiple means of expression. HumanComputer Interaction, 12(1-2):131-185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don R Swanson</author>
<author>N R Smalheiser</author>
</authors>
<title>Assessing a gap in the biomedical literature: Magnesium deficiency and neurologic disease.</title>
<date>1994</date>
<journal>Neuroscience Research Communications,</journal>
<pages>15--1</pages>
<contexts>
<context position="11899" citStr="Swanson and Smalheiser, 1994" startWordPosition="1951" endWordPosition="1954">plausible to expect new information to be derivable from text collections: experts can only read a small subset of what is published in their fields and are often unaware of developments in related fields. Thus it should be possible to find useful linkages between information in related literatures, if the authors of those literatures rarely refer to one another&apos;s work. Swanson has shown how chains of causal implication within the medical literature can lead to hypotheses for causes of rare diseases, some of which have received supporting experimental evidence (Swanson, 1987; 5 Swanson, 1991; Swanson and Smalheiser, 1994; Swanson and Smalheiser, 1997). For example, when investigating causes of migraine headaches, he extracted various pieces of evidence from titles of articles in the biomedical literature. Some of these clues can be paraphrased as follows: • stress is associated with migraines • stress can lead to loss of magnesium • calcium channel blockers prevent some migraines • magnesium is a natural calcium channel blocker • spreading cortical depression (SCD) is implicated in some migraines • high leveles of magnesium inhibit SCD • migraine patients have high platelet aggregability • magnesium can suppr</context>
</contexts>
<marker>Swanson, Smalheiser, 1994</marker>
<rawString>Don R. Swanson and N. R. Smalheiser. 1994. Assessing a gap in the biomedical literature: Magnesium deficiency and neurologic disease. Neuroscience Research Communications, 15:1-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don R Swanson</author>
<author>N R Smalheiser</author>
</authors>
<title>An interactive system for finding complementary literatures: a stimulus to scientific discovery.</title>
<date>1997</date>
<journal>Artificial Intelligence,</journal>
<pages>91--183</pages>
<contexts>
<context position="11930" citStr="Swanson and Smalheiser, 1997" startWordPosition="1955" endWordPosition="1958">ation to be derivable from text collections: experts can only read a small subset of what is published in their fields and are often unaware of developments in related fields. Thus it should be possible to find useful linkages between information in related literatures, if the authors of those literatures rarely refer to one another&apos;s work. Swanson has shown how chains of causal implication within the medical literature can lead to hypotheses for causes of rare diseases, some of which have received supporting experimental evidence (Swanson, 1987; 5 Swanson, 1991; Swanson and Smalheiser, 1994; Swanson and Smalheiser, 1997). For example, when investigating causes of migraine headaches, he extracted various pieces of evidence from titles of articles in the biomedical literature. Some of these clues can be paraphrased as follows: • stress is associated with migraines • stress can lead to loss of magnesium • calcium channel blockers prevent some migraines • magnesium is a natural calcium channel blocker • spreading cortical depression (SCD) is implicated in some migraines • high leveles of magnesium inhibit SCD • migraine patients have high platelet aggregability • magnesium can suppress platelet aggregability Thes</context>
</contexts>
<marker>Swanson, Smalheiser, 1997</marker>
<rawString>Don R. Swanson and N. R. Smalheiser. 1997. An interactive system for finding complementary literatures: a stimulus to scientific discovery. Artificial Intelligence, 91:183-203.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don R Swanson</author>
</authors>
<title>Two medical literatures that are logically but not bibliographically connected.</title>
<date>1987</date>
<journal>JASIS,</journal>
<pages>38--4</pages>
<contexts>
<context position="11852" citStr="Swanson, 1987" startWordPosition="1946" endWordPosition="1947">has eloquently argued why it is plausible to expect new information to be derivable from text collections: experts can only read a small subset of what is published in their fields and are often unaware of developments in related fields. Thus it should be possible to find useful linkages between information in related literatures, if the authors of those literatures rarely refer to one another&apos;s work. Swanson has shown how chains of causal implication within the medical literature can lead to hypotheses for causes of rare diseases, some of which have received supporting experimental evidence (Swanson, 1987; 5 Swanson, 1991; Swanson and Smalheiser, 1994; Swanson and Smalheiser, 1997). For example, when investigating causes of migraine headaches, he extracted various pieces of evidence from titles of articles in the biomedical literature. Some of these clues can be paraphrased as follows: • stress is associated with migraines • stress can lead to loss of magnesium • calcium channel blockers prevent some migraines • magnesium is a natural calcium channel blocker • spreading cortical depression (SCD) is implicated in some migraines • high leveles of magnesium inhibit SCD • migraine patients have hi</context>
</contexts>
<marker>Swanson, 1987</marker>
<rawString>Don R. Swanson. 1987. Two medical literatures that are logically but not bibliographically connected. JASIS, 38(4):228-233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don R Swanson</author>
</authors>
<title>Complementary structures in disjoint science literatures.</title>
<date>1991</date>
<booktitle>In Proceedings of the 14th Annual International ACM/SIGIR Conference,</booktitle>
<pages>280--289</pages>
<contexts>
<context position="11869" citStr="Swanson, 1991" startWordPosition="1949" endWordPosition="1950">gued why it is plausible to expect new information to be derivable from text collections: experts can only read a small subset of what is published in their fields and are often unaware of developments in related fields. Thus it should be possible to find useful linkages between information in related literatures, if the authors of those literatures rarely refer to one another&apos;s work. Swanson has shown how chains of causal implication within the medical literature can lead to hypotheses for causes of rare diseases, some of which have received supporting experimental evidence (Swanson, 1987; 5 Swanson, 1991; Swanson and Smalheiser, 1994; Swanson and Smalheiser, 1997). For example, when investigating causes of migraine headaches, he extracted various pieces of evidence from titles of articles in the biomedical literature. Some of these clues can be paraphrased as follows: • stress is associated with migraines • stress can lead to loss of magnesium • calcium channel blockers prevent some migraines • magnesium is a natural calcium channel blocker • spreading cortical depression (SCD) is implicated in some migraines • high leveles of magnesium inhibit SCD • migraine patients have high platelet aggre</context>
</contexts>
<marker>Swanson, 1991</marker>
<rawString>Don R. Swanson. 1991. Complementary structures in disjoint science literatures. In Proceedings of the 14th Annual International ACM/SIGIR Conference, pages 280-289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John W Tukey</author>
</authors>
<title>Exploratory Data Analysis.</title>
<date>1977</date>
<publisher>Addison-Wesley Publishing Company.</publisher>
<contexts>
<context position="10659" citStr="Tukey, 1977" startWordPosition="1742" endWordPosition="1743">&amp;quot;real&amp;quot; data mining is that they use text metadata to tell us something about the world, outside of the text collection itself. (However, since this application uses metadata associated with text documents, rather than the text directly, it is unclear if it should be considered text data mining or standard data mining.) The computational linguistics applications tell us about how to improve language analysis, but they do not discover more widely usable information. 5 Text Data Mining as Exploratory Data Analysis Another way to view text data mining is as a process of exploratory data analysis (Tukey, 1977; Hoaglin et al., 1983) that leads to the discovery of heretofore unknown information, or to answers for questions for which the answer is not currently known. Of course, it can be argued that the standard practice of reading textbooks, journal articles and other documents helps researchers in the discovery of new information, since this is an integral part of the research process. However, the idea here is to use text for discovery in a more direct manner. Two examples are described below. 5.1 Using Text to Form Hypotheses about Disease For more than a decade, Don Swanson has eloquently argue</context>
</contexts>
<marker>Tukey, 1977</marker>
<rawString>John W. Tukey. 1977. Exploratory Data Analysis. Addison-Wesley Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Query expansion using lexical-semantic relations.</title>
<date>1994</date>
<booktitle>In Proceedings of the 17th Annual International ACM/SIGIR Conference,</booktitle>
<pages>61--69</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="4942" citStr="Voorhees, 1994" startWordPosition="818" endWordPosition="819">lly want to treat the information in the web as a large knowledge base from which we can extract new, never-before encountered information (Craven et al., 1998). On the other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory data analysis. Our efforts in this direction are embodied in the LINDI project, described in Section 5 below. 3 TDM and Computational Linguistics If we extrapolate from data mining (</context>
</contexts>
<marker>Voorhees, 1994</marker>
<rawString>Ellen M. Voorhees. 1994. Query expansion using lexical-semantic relations. In Proceedings of the 17th Annual International ACM/SIGIR Conference, pages 61-69, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael G Walker</author>
<author>Walter Volkmuth</author>
<author>Einat Sprinzak</author>
<author>David Hodgson</author>
<author>Tod Klingler</author>
</authors>
<title>Prostate cancer genes identified by genome-scale expression analysis.</title>
<date>1998</date>
<tech>Technical Report (unnumbered), Incyte Pharmaceuticals,</tech>
<contexts>
<context position="18257" citStr="Walker et al., 1998" startWordPosition="2980" endWordPosition="2983">ons seen in the patent example should be tightly integrated with analysis and interpretation tools as needed in the biomedical example. Following Amant (1996), the interaction paradigm is that of a mixed-initiative balance of control between user and system. The interaction is a cycle in which the system suggests hypotheses and strategies for investigating these hypotheses, and the user either uses or ignores these suggestions and decides on the next move. We are interested in an important problem in molecular biology, that of automating the discovery of the function of newly sequenced genes (Walker et al., 1998). Human genome researchers perform experiments in which they analyze co-expression of tens of thousands of novel and known genes simultaneously.4 Given this huge collection of genetic information, the goal is to determine which of the novel genes are medically interesting, meaning that they are co-expressed with already understood genes which are known to be involved in disease. Our strategy is to explore the biomedical literature, trying to formulate plausible hypotheses about which genes are of interest. Most information access systems require the user to execute and keep track of tactical m</context>
</contexts>
<marker>Walker, Volkmuth, Sprinzak, Hodgson, Klingler, 1998</marker>
<rawString>Michael G. Walker, Walter Volkmuth, Einat Sprinzak, David Hodgson, and Tod Klingler. 1998. Prostate cancer genes identified by genome-scale expression analysis. Technical Report (unnumbered), Incyte Pharmaceuticals, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H D White</author>
<author>K W McCain</author>
</authors>
<date>1989</date>
<booktitle>Bibliometrics. Annual Review of Information Science and Technology,</booktitle>
<pages>24--119</pages>
<contexts>
<context position="5092" citStr="White and McCain, 1989" startWordPosition="841" endWordPosition="844">aven et al., 1998). On the other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory data analysis. Our efforts in this direction are embodied in the LINDI project, described in Section 5 below. 3 TDM and Computational Linguistics If we extrapolate from data mining (as practiced) on numerical data to data mining from text collections, we discover that there already &apos;http://www.aaai.org/Conferences/KDD/1997/kdd97- </context>
</contexts>
<marker>White, McCain, 1989</marker>
<rawString>H. D. White and K. W. McCain. 1989. Bibliometrics. Annual Review of Information Science and Technology, 24:119-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James A Wise</author>
<author>James J Thomas</author>
<author>Kelly Pennock</author>
<author>David Lantrip</author>
<author>Marc Pottier</author>
<author>Anne Schur</author>
</authors>
<title>Visualizing the non-visual: Spatial analysis and interaction with information from text documents.</title>
<date>1995</date>
<booktitle>In Proceedings of the Information Visualization Symposium 95,</booktitle>
<pages>51--58</pages>
<publisher>IEEE Computer Society Press.</publisher>
<contexts>
<context position="4794" citStr="Wise et al., 1995" startWordPosition="792" endWordPosition="795"> be it to optimize the system or to find information about the clients using the system.1 This search-centric view misses the point that we might actually want to treat the information in the web as a large knowledge base from which we can extract new, never-before encountered information (Craven et al., 1998). On the other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory data analysis. Our efforts in this</context>
</contexts>
<marker>Wise, Thomas, Pennock, Lantrip, Pottier, Schur, 1995</marker>
<rawString>James A. Wise, James J. Thomas, Kelly Pennock, David Lantrip, Marc Pottier, and Anne Schur. 1995. Visualizing the non-visual: Spatial analysis and interaction with information from text documents. In Proceedings of the Information Visualization Symposium 95, pages 51-58. IEEE Computer Society Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Xu</author>
<author>W B Croft</author>
</authors>
<title>Query expansion using local and global document analysis.</title>
<date>1996</date>
<booktitle>In SIGIR &apos;96: Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>4--11</pages>
<location>Zurich.</location>
<contexts>
<context position="4963" citStr="Xu and Croft, 1996" startWordPosition="820" endWordPosition="823">t the information in the web as a large knowledge base from which we can extract new, never-before encountered information (Craven et al., 1998). On the other hand, the results of certain types of text processing can yield tools that indirectly aid in the information access process. Examples include text clustering to create thematic overviews of text collections (Cutting et al., 1992; Chalmers and Chitson, 1992; Rennison, 1994; Wise et al., 1995; Lin et al., 1991; Chen et al., 1998), automatically generating term associations to aid in query expansion (Peat and Willett, 1991; Voorhees, 1994; Xu and Croft, 1996), and using co-citation analysis to find general topics within a collection or identify central web pages (White and McCain, 1989; Larson, 1996; Kleinberg, 1998). Aside from providing tools to aid in the standard information access process, I think text data mining can contribute along another dimension. In future I hope to see information access systems supplemented with tools for exploratory data analysis. Our efforts in this direction are embodied in the LINDI project, described in Section 5 below. 3 TDM and Computational Linguistics If we extrapolate from data mining (as practiced) on nume</context>
</contexts>
<marker>Xu, Croft, 1996</marker>
<rawString>J. Xu and W. B. Croft. 1996. Query expansion using local and global document analysis. In SIGIR &apos;96: Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 4-11, Zurich.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>