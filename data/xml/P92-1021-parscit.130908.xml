<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001456">
<note confidence="0.809425">
LATTICE-BASED WORD IDENTIFICATION IN CLARE
</note>
<author confidence="0.650996">
David M. Carter
</author>
<affiliation confidence="0.4945495">
SRI International
Cambridge Computer Science Research Centre
</affiliation>
<address confidence="0.9857925">
23 Millers Yard
Cambridge CB2 1RQ, U.K.
</address>
<email confidence="0.965923">
dmcacam.sri.com
</email>
<sectionHeader confidence="0.992484" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9999043125">
I argue that because of spelling and typing
errors and other properties of typed text, the
identification of words and word boundaries
in general requires syntactic and semantic
knowledge. A lattice representation is there-
fore appropriate for lexical analysis. I show
how the use of such a representation in the
CLARE system allows different kinds of hy-
pothesis about word identity to be integrated
in a uniform framework. I then describe a
quantitative evaluation of CLARE&apos;s perfor-
mance on a set of sentences into which ty-
pographic errors have been introduced. The
results show that syntax and semantics can be
applied as powerful sources of constraint on
the possible corrections for misspelled words.
</bodyText>
<sectionHeader confidence="0.999553" genericHeader="keywords">
1 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999575595744681">
In many language processing systems, uncer-
tainty in the boundaries of linguistic units,
at various levels, means that data are repre-
sented not as a well-defined sequence of units
but as a lattice of possibilities. It is common
for speech recognizers to maintain a lattice of
overlapping word hypotheses from which one
or more plausible complete paths are subse-
quently selected. Syntactic parsing, of either
spoken or written language, frequently makes
use of a chart or well-formed substring ta-
ble because the correct bracketing of a sen-
tence cannot (easily) be calculated determin-
istically. And lattices are also often used in
the task of converting Japanese text typed in
kana (syllabic symbols) to kanji; the lack of in-
terword spacing in written Japanese and the
complex morphology of the language mean
that lexical items and their boundaries cannot
be reliably identified without applying syntac-
tic and semantic knowledge (Abe et al, 1986).
In contrast, however, it is often assumed
that, for languages written with interword
spaces, it is sufficient to group an input char-
acter stream deterministically into a sequence
of words, punctuation symbols and perhaps
other items, and to hand this sequence to
the parser, possibly after word-by-word mor-
phological analysis. Such an approach is
sometimes adopted even when typographi-
cally complex inputs are handled; see, for ex-
ample, Futrelle et al, 1991.
In this paper I observe that, for typed in-
put, spaces do not necessarily correspond to
boundaries between lexical items, both for lin-
guistic reasons and because of the possibil-
ity of typographic errors. This means that a
lattice representation, not a simple sequence,
should be used throughout front end (pre-
parsing) analysis. The CLARE system under
development at SRI Cambridge uses such a
representation, allowing it to deal straightfor-
wardly with combinations or multiple occur-
rences of phenomena that would be difficult
or impossible to process correctly under a se-
quence representation. As evidence for the
performance of the approach taken, I describe
</bodyText>
<page confidence="0.997983">
159
</page>
<bodyText confidence="0.999970454545455">
an evaluation of CLARE&apos;s ability to deal with
typing and spelling errors. Such errors are es-
pecially common in interactive use, for which
CLARE is designed, and the correction of as
many of them as possible can make an appre-
ciable difference to the usability of a system.
The word identity and word boundary am-
biguities encountered in the interpretation of
errorful input often require the application
of syntactic and semantic knowledge on a
phrasal or even sentential scale. Such knowl-
edge may be applied as soon as the problem
is encountered; however, this brings major
problems with it, such as the need for ad-
equate lookahead, and the difficulties of en-
gineering large systems where the processing
levels are tightly coupled. To avoid these diffi-
culties, CLARE adopts a staged architecture,
in which indeterminacy is preserved until the
knowledge needed to resolve it is ready to be
applied. An appropriate representation is of
course the key to doing this efficiently.
</bodyText>
<sectionHeader confidence="0.9985075" genericHeader="introduction">
2 SPACES AND WORD
BOUNDARIES
</sectionHeader>
<bodyText confidence="0.982074485294118">
In general, typing errors are not just a matter
of one intended input token being rniskeyed as
another one. Spaces between tokens may be
deleted (so that two or more intended words
appear as one) or inserted (so that one word
appears as two or more). Multiple errors,
involving both spaces and other characters,
may be combined in the same intended or ac-
tual token. A reliable spelling corrector must
allow for all these possibilities, which must,
in addition, be distinguished from the use of
correctly-typed words that happen to fall out-
side the system&apos;s lexicon.
However, even in the absence of &amp;quot;noise&amp;quot; of
this kind, spaces do not always correspond
to lexical item boundaries, at least if lexical
items are defined in a way that is most con-
venient for grammatical purposes. For exam-
ple, &amp;quot;special&amp;quot; forms such as telephone num-
bers or e-mail addresses, which are common
in many domains, may contain spaces. In
CLARE, these are analysed using regular ex-
pressions (cf Grosz et al, 1987), which may
include space characters. When such an ex-
pression is realised, an analysis of it, connect-
ing non-adjacent vertices if it contains spaces,
is added to the lattice.
The complexities of punctuation are an-
other source of uncertainty: many punctu-
ation symbols have several uses, not all of
which necessarily lead to the same way of seg-
menting the input. For example, periods may
indicate either the end of a sentence or an ab-
breviation, and slashes may be simple word-
internal characters (e.g. X11/NeWS) or func-
tion lexically as disjunctions, as in
[1] I&apos;m looking for suggestions for
vendors to deal with/avoid. 1
Here, the character string &amp;quot;with/avoid&amp;quot;, al-
though it contains no spaces, represents three
lexical items that do not even form a syntactic
constituent.
CLARE&apos;s architecture and formalism allow
for all these possibilities, and, as an exten-
sion, also permit multiple-token phrases, such
as idioms, to be defined as equivalent to other
tokens or token sequences. This facility is
especially useful when CLARE is being tai-
lored for use in a particular domain, since
it allows people not expert in linguistics or
the CLARE grammar to extend grammati-
cal coverage in simple and approximate, but
often practically important, ways. For ex-
ample, if an application developer finds that
inputs such as &amp;quot;What number of employees
have cars?&amp;quot; are common, but that the con-
struction &amp;quot;what number of ...&amp;quot; is not han-
dled by the grammar, he can define the se-
quence &amp;quot;what number of&amp;quot; as equivalent to
&amp;quot;how many&amp;quot;. This will provide an extension
of coverage without the developer needing to
know how any of the phrases involved are
treated in the grammar. Extending the gram-
mar is, of course, a more thorough solution if
the expertise is available; the phrasal equiv-
alence suggested here will not, for example,
&apos;These two examples are taken from the Sun-spots
computer bulletin board.
</bodyText>
<page confidence="0.994897">
160
</page>
<bodyText confidence="0.9947345">
cope correctly with the query &amp;quot;What number The lexicon proper is first accessed at this
of the employees have cars?&amp;quot;. stage.
</bodyText>
<sectionHeader confidence="0.998939" genericHeader="method">
3 CLARE&apos;S PROCESSING STAGES
</sectionHeader>
<bodyText confidence="0.994849833333334">
The CLARE system is intended to provide
language processing capabilities (both anal-
ysis and generation) and some reasoning fa-
cilities for a range of possible applications.
English sentences are mapped, via a num-
ber of stages, into logical representations of
their literal meanings, from which reasoning
can proceed. Stages are linked by well-defined
representations. The key intermediate repre-
sentation is that of quasi logical form (QLF;
Alshawi, 1990, 1992), a version of slightly
extended first order logic augmented with
constructs for phenomena such as anaphora
and quantification that can only be resolved
by reference to context. The unification of
declarative linguistic data is the basic process-
ing operation.
The specific task considered in this paper is
the process of mapping single sentences from
character strings to QLF. Two kinds of issue
are therefore not discussed here. These are
the problem of segmenting a text into sen-
tences and dealing with any markup instruc-
tions (cf Futrelle et al, 1991), which is logically
prior to producing character strings; and pos-
sible context-dependence of the lexical phe-
nomena discussed, which would need to be
dealt with after the creation of QLFs.
In the analysis direction, CLARE&apos;s front
end processing stages are as follows.
</bodyText>
<listItem confidence="0.983074090909091">
1. A sentence is divided into a sequence of
clusters separated by white space.
2. Each cluster is divided into one or more
tokens: words (possibly inflected), punc-
tuation characters, and other items. To-
kenization is nondeterministic, and so a
lattice is used at this and subsequent
stages.
3. Each token is analysed as a sequence of
one or more segments. For normal lexi-
cal items, these segments are morphemes.
4. A variety of strategies for error recovery
(including but not limited to spelling/
typing correction) are attempted on to-
kens for which no segmentation could
be found. Edges without segmentations
are then deleted; if no complete path re-
mains, sentence processing is abandoned.
5. Further edges, possibly spanning non-
adjacent vertices, are added to the lat-
tice by the phrasal equivalence mecha-
nism discussed earlier.
</listItem>
<bodyText confidence="0.99943803125">
Morphological, syntactic and semantic stages
then apply to produce one or more QLFs.
These are checked for adherence to sortal (se-
lectional) restrictions, and, possibly with the
help of user intervention, one is selected for
further processing.
Because tokenization is nondeterministic
and does not involve lexical access, it will
produce many possible tokens that cannot be
further analysed. If sentence [1] above were
processed, with/avoid would be one such to-
ken. It is important that analyses are found
for as many tokens and token sequences as
possible, but that error recovery, especially if
it involves user interaction, is not attempted
unless really necessary. More generally, the
system must decide which techniques to apply
to which problem tokens, and how the results
of doing so should be combined.
CLARE&apos;s token segmentation phase there-
fore attempts to find analyses for all the sin-
gle tokens in the lattice, and for any special
forms, which may include spaces and therefore
span multiple tokens. Next, a series of recov-
ery methods, which may be augmented or re-
ordered by the application developer, are ap-
plied. Global methods apply to the lattice as a
whole, and are intended to modify its contents
or create required lexicon entries on a scale
larger than the individual token. Local meth-
ods apply only to single still-unanalysed to-
kens, and may either supply analyses for them
</bodyText>
<page confidence="0.991196">
161
</page>
<bodyText confidence="0.999933805555556">
or alter them to other tokens. The default
methods, all of which may be switched on or
off using system commands, supply facilities
for inferring entries through access to an ex-
ternal machine-readable dictionary; for defin-
ing sequences of capitalized tokens as proper
names; for spelling correction (described in
detail in the next section); and for interacting
with the user who may suggest a replacement
word or phrase or enter the VEX lexical ac-
quisition subsystem (Carter, 1989) to create
the required entries.
After a method has been applied, the lat-
tice is, if possible, pruned: edges labelled by
unanalysed tokens are provisionally removed,
as are other edges and vertices that then do
not lie on a complete path. If pruning suc-
ceeds (i.e. if at least one problem-free path
remains) then token analysis is deemed to
have succeeded, and unanalysed tokens (such
as with/avoid) are forgotten; any remaining
global methods are invoked, because they may
provide analyses for token sequences, but re-
maining local ones are not. If full pruning
does not succeed, any subpath in the lattice
containing more unrecognized tokens than an
alternative subpath is eliminated. Subpaths
containing tokens with with non-alphabetic
characters are penalized more heavily; this
ensures that if the cluster &amp;quot;b000ks,&amp;quot; is in-
put, the token sequence &amp;quot;b000ks ,&amp;quot; (in which
&amp;quot;b000ks&amp;quot; is an unrecognized token and &amp;quot;,&amp;quot;
is a comma) is preferred to the single token
&amp;quot;b000ks,&amp;quot; (where the comma is part of the
putative lexical item). The next method is
then applied.&apos;
</bodyText>
<sectionHeader confidence="0.999307" genericHeader="method">
4 SEGMENTATION AND
SPELLING CORRECTION
</sectionHeader>
<bodyText confidence="0.998982">
A fairly simple affix-stripping approach to to-
ken segmentation is adopted in CLARE be-
</bodyText>
<footnote confidence="0.533197333333333">
2In fact, for completeness, CLARE allows the ap-
plication of two or more methods in tandem and will
combines the results without any intermediate prun-
ing. This option would be useful if, in a given appli-
cation, two sources of knowledge were deemed to be
about equally reliable in their predictions.
</footnote>
<bodyText confidence="0.999970044444444">
cause inflectional morphological changes in
English tend not to be complex enough to
warrant more powerful, and potentially less
efficient, treatments such as two-level mor-
phology (Koskenniemi, 1983). Derivational
morphological relationships typically involve
semantic peculiarities as well, necessitating
the definition of derived words in the lexicon
in their own right.
The rules for dividing clusters into tokens
have the same form as those for segmenting
tokens into morphemes, and are processed by
the same mechanism. Thus &amp;quot;,&amp;quot;, like, say,
&amp;quot;ed&amp;quot;, is defined as a suffix, but one that is
treated by the grammar as a separate word
rather than a bound morpheme. Rules for
punctuation characters are very simple be-
cause no spelling changes are ever involved.
However, the possessive ending &amp;quot;s&amp;quot; is treated
as a separate word in the CLARE grammar to
allow the correct analysis of phrases such as
&amp;quot;the man in the corner&apos;s wife&amp;quot;, and spelling
changes can be involved here. Like segmenta-
tion, tokenization can yield multiple results,
mainly because there is no reason for a com-
plex cluster like Mr. or King&apos;s not also to be
defined as a lexical item.
One major advantage of the simplicity of
the affix-stripping mechanism is that spelling
correction can be interleaved directly with it.
Root forms in the lexicon are represented in
a discrimination net for efficient access (cf
Emirkanian and Bouchard, 1988). When the
spelling corrector is called to suggest possible
corrections for a word, the number of simple
errors (of deletion, insertion, substitution and
transposition; e.g. Pollock and Zamora, 1984)
to assume is given. Normal segmentation is
just the special case of this with the number
of errors set to zero. The mechanism nonde-
terministically removes affixes from each end
of the word, postulating errors if appropriate,
and then looks up the resulting string in the
discrimination net, again considering the pos-
sibility of error.3
</bodyText>
<footnote confidence="0.507629">
3This is the reverse of Veronis&apos; (1988) algorithm,
where roots are matched before affixes. However, it
</footnote>
<page confidence="0.992096">
162
</page>
<bodyText confidence="0.986468075">
Interleaving correction with segmentation
like this promotes efficiency in the following
way. As in most other correctors, only up
to two simple errors are considered along a
given search path. Therefore, either the affix-
stripping phase or the lookup phase is fairly
quick and produces a fairly small number of
results, and so the two do not combine to
slow processing down. Another beneficial con-
sequence of the interleaving is that no spe-
cial treatment is required for the otherwise
awkward case where errors overlap morpheme
boundaries; thus desigend is corrected to de-
signed as easily as deisgned or designde are.
If one or more possible corrections to a to-
ken are found, they may either be presented
to the user for selection or approval, or, if
the number of them does not exceed a pre-
set threshold, all be preserved as alternatives
for disambiguation at the later syntactic or
semantic stages. The lattice representation
allows multiple-word corrections to be pre-
served along with single-word ones.
It is generally recognized that spelling er-
rors in typed input are of two kinds: compe-
tence errors, where the user does not know, or
has forgotten, how to spell a word; and per-
formance errors, where the wrong sequence of
keys is hit. CLARE&apos;s correction mechanism is
oriented towards the latter. Other work (e.g.
Veronis, 1988, Emirkanian and Bouchard,
1988, van Berkel and De Smedt, 1988) em-
phasizes the former, often on the grounds that
competence errors are both harder for the user
to correct and tend to make a worse impres-
sion on a human reader. However, Emirka-
nian and Bouchard identify the many-to-one
nature of French spelling-sound correspon-
dence as responsible for the predominance of
such errors in that language, which they say
does not hold in English; and material typed
to CLARE tends to be processed further (for
seems easier and more efficient to match affixes first,
because then the hypothesized root can be looked up
without having to allow for any spelling changes; and
if both prefixes and suffixes are to be handled, as they
are in CLARE, there is no obvious single starting point
for searching for the root first.
database access, translation, etc) rather than
reproduced for potentially embarrassing hu-
man consumption. A performance-error ap-
proach also has the practical advantage of
not depending on extensive linguistic knowl-
edge; and many competence errors can be de-
tected by a performance approach, especially
if some straightforward adjustments (e.g. to
prefer doubling to other kinds of letter inser-
tion) are made to the algorithm.
As well as coping quite easily with mor-
pheme boundaries, CLARE&apos;s algorithm can
also handle the insertion or deletion of word
boundary spaces. For the token witha,
CLARE postulates both with and with a as
corrections, and (depending on the current
switch settings) both may go into the lat-
tice. The choice will only finally be made
when a QLF is selected on sortal and other
grounds after parsing and semantic analy-
sis. For the token pair nev er, CLARE pos-
tulates the single correction never, because
this involves assuming only one simple er-
ror (the insertion of a space) rather than
two or more to &amp;quot;correct&amp;quot; each token individ-
ually. Multiple overlapping possibilities can
also be handled; the input Th m n worked
causes CLARE to transform the initial lattice
th worked
• • • • •
into a corrected lattice containing analyses of
the words shown here:
</bodyText>
<equation confidence="0.872561333333333">
man/men
a/an/in/ \ worked
ino/on/,/1/I
</equation>
<bodyText confidence="0.999697555555556">
The edges labelled &amp;quot;them&amp;quot; and &amp;quot;man/men&amp;quot;
are constructed first by the &amp;quot;global&amp;quot; spelling
correction method, which looks for possible
corrections across token boundaries. The edge
for the token &amp;quot;m&amp;quot; is then removed because,
given that it connects only to errorful tokens
on both sides, it cannot form part of any
potentially optimal path through the lattice.
Corrections are, however, sought for &amp;quot;th&amp;quot; and
</bodyText>
<figure confidence="0.915117333333333">
the/to
them
•
</figure>
<page confidence="0.99784">
163
</page>
<bodyText confidence="0.99992">
&amp;quot;n&amp;quot; as single tokens when the local spelling
correction method is invoked. The corrected
lattice then undergoes syntactic and semantic
processing, and QLFs for the sequences &amp;quot;the
man worked&amp;quot; and &amp;quot;the men worked&amp;quot;, but not
for any sequence starting with &amp;quot;them&amp;quot; or &amp;quot;to&amp;quot;,
are produced.
</bodyText>
<sectionHeader confidence="0.989827" genericHeader="evaluation">
5 AN EVALUATION
</sectionHeader>
<bodyText confidence="0.999943892857143">
To assess the usefulness of syntactico-
semantic constraints in CLARE&apos;s spelling cor-
rection, the following experiment, intended
to simulate performance (typographic) er-
rors, was carried out. Five hundred sen-
tences, of up to ten words in length, falling
within CLARE&apos;s current core lexical (1600
root forms) and grammatical coverage were
taken at random from the LOB corpus. These
sentences were passed, character by charac-
ter, through a channel which transmitted a
character without alteration with probability
0.99, and with probability 0.01 introduced a
simple error. The relative probabilities of the
four different kinds of error were deduced from
Table X of Pollock and Zamora, 1984; where
a new character had to be inserted or sub-
stituted, it was selected at random from the
original sentence set. This process produced a
total of 102 sentences that differed from their
originals. The average length was 6.46 words,
and there were 123 corrupted tokens in all,
some containing more than one simple error.
Because longer sentences were more likely to
be changed, the average length of a changed
sentence was some 15% more than that of an
original one.
The corrupted sentence set was then pro-
cessed by CLARE with only the spelling cor-
rection recovery method in force and with
no user intervention. Up to two simple er-
rors were considered per token. No domain-
specific or context-dependent knowledge was
used.
Of the 123 corrupted tokens, ten were cor-
rupted into other known words, and so no
correction was attempted. Parsing failed in
nine of these cases; in the tenth, the cor-
rupted word made as much sense as the orig-
inal out of discourse context. In three further
cases, the original token was not suggested as
a correction; one was a special form, and for
the other two, alternative corrections involved
fewer simple errors. The corrections for two
other tokens were not used because a corrup-
tion into a known word elsewhere in the same
sentence caused parsing to fail.
Only one correction (the right one) was sug-
gested for 59 of the remaining 108 tokens.
Multiple-token correction, involving the ma-
nipulation of space characters, took place in
24 of these cases.
This left 49 tokens for which more than one
correction was suggested, requiring syntactic
and semantic processing for further disam-
biguation. The average number of corrections
suggested for these 49 was 4.57. However,
only an average of 1.69 candidates (including,
because of the way the corpus was selected,
all the right ones) appeared in QLFs satis-
fying selectional restrictions; thus only 19%
of the wrong candidates found their way into
any QLF. If, in the absence of frequency in-
formation, we take all candidates as equally
likely, then syntactic and semantic processing
reduced the average entropy from 1.92 to 0.54,
removing 72% of the uncertainty (see Carter,
1987, for a discussion of why entropy is the
best measure to use in contexts like this).
When many QLFs are produced for a sen-
tence, CLARE orders them according to a set
of scoring functions encoding syntactic and
semantic preferences. For the 49 multiple-
candidate tokens, removing all but the best-
scoring QLF(s) eliminated 7 (21%) of the 34
wrong candidates surviving to the QLF stage;
however, it also eliminated 5 (10%) of the
right candidates. It is expected that future
development of the scoring functions will fur-
ther improve these figures, which are summa-
rized in Table 1.
The times taken to parse lattices containing
multiple spelling candidates reflect the char-
acteristics of CLARE&apos;s parser, which uses a
</bodyText>
<page confidence="0.995724">
164
</page>
<table confidence="0.997013666666667">
Stage Right Wrong Average
cand&apos;s cand&apos;s number
Suggested 49 175 4.57
In any QLF 49 34 1.69
In best-scoring 44 27 1.45
QLF(s)
</table>
<tableCaption confidence="0.978798">
Table 1: Correction candidates for the 49
multiple-candidate tokens
</tableCaption>
<bodyText confidence="0.999385717391304">
backtracking, left-corner algorithm and stores
well-formed constituents so as to avoid repeat-
ing work where possible. In general, when a
problem token appears late in the sentence
and/or when several candidate corrections are
syntactically plausible, the lattice approach is
several times faster than processing the al-
ternative strings separately (which tends to
be very time-consuming). When the problem
token occurs early and has only one plausi-
ble correction, the two methods are about the
same speed.
For example, in one case, a corrupted to-
ken with 13 candidate corrections occurred
in sixth position in an eight-word sentence.
Parsing the resulting lattice was three times
faster than parsing each alternative full string
separately. The lattice representation avoided
repetition of work on the first six words. How-
ever, in another case, where the corrupted
token occurred second in an eight-word sen-
tence, and had six candidates, only one of
which was syntactically plausible, the lattice
representation was no faster, as the incorrect
candidates in five of the strings led to the
parse being abandoned early.
An analogous experiment was carried out
with 500 sentences from the same corpus
which CLARE could not parse. 131 of the
sentences, with average length 7.39 words, suf-
fered the introduction of errors. Of these, only
seven (5%) received a parse. Four of the seven
received no sortally valid QLFs, leaving only
three (2%) &amp;quot;false positives&amp;quot;. This low figure
is consistent with the results from the origi-
nally parseable sentence set; nine out of the
ten corruptions into known words in that ex-
periment led to parse failure, and only 19%
of wrong suggested candidates led to a sor-
tally valid QLF. If, as those figures suggest,
the replacement of one word by another only
rarely maps one sentence inside coverage to
another, then a corresponding replacement on
a sentence outside coverage should yield some-
thing within coverage even more rarely, and
this does appear to be the case.
</bodyText>
<sectionHeader confidence="0.999988" genericHeader="conclusions">
6 CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.999921419354839">
These experimental results suggest that gen-
eral syntactic and semantic information is an
effective source of constraint for correcting
typing errors, and that a conceptually fairly
simple staged architecture, where word iden-
tity and word boundary ambiguities are only
resolved when the relevant knowledge is ready
to be applied, can be acceptably efficient. The
lattice representation also allows the system
to deal cleanly with word boundary uncer-
tainty not caused by noise in the input.
A fairly small vocabulary was used in
the experiment. However, these words were
originally selected on the basis of frequency
of occurrence, so that expanding the lexi-
con would involve introducing proportionately
fewer short words than longer ones. Mistyped
short words tend to be the ones with many
correction candidates, so the complexity of
the problem should grow less fast than might
be expected with vocabulary size. Further-
more, more use could be made of statistical
information: relative frequency of occurrence
could be used as a criterion for pruning rela-
tively unlikely correction candidates, as could
more sophisticated statistics in the sugges-
tion algorithm, along the lines of Kernighan
et al (1990). Phonological knowledge, to al-
low competence errors to be tackled more di-
rectly, would provide another useful source of
constraint.
</bodyText>
<footnote confidence="0.427583">
1 65
</footnote>
<sectionHeader confidence="0.992787" genericHeader="acknowledgments">
ACKNOWLEDGMENTS
</sectionHeader>
<bodyText confidence="0.727478166666667">
CLARE is being developed as part of a collab-
orative project involving SRI International,
British Aerospace, BP Research, British Tele-
com, Cambridge University, the UK Defence
Research Agency, and the UK Department of
Trade and Industry.
</bodyText>
<sectionHeader confidence="0.97741" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.99985725">
Abe, M., Y. Oshima, K. Yuura and N. Take-
ichi (1986) &amp;quot;A Kana-Kanji Translation
System for Non-Segmented Input Sen-
tences Based on Syntactic and Seman-
tic Analysis&amp;quot;, Proceedings of the Eleventh
International Conference on Computa-
tional Linguistics, pp 280-285.
Alshawi, H. (1990) &amp;quot;Resolving Quasi Logical
Forms&amp;quot;, Computational Linguistics 16:3,
pp. 133-144.
Alshawi, H. (ed.) (1992) The Core Language
Engine, M.I.T. Press.
van Berkel, B., and K. De Smedt (1988) &amp;quot;Tri-
phone Analysis: A Combined Method for
the Correction of Orthographical and Ty-
pographical Errors&amp;quot;, Proceedings of the
Second Conference on Applied Natural
Language Processing, pp. 77-83.
Carter, D.M. (1987) &amp;quot;An Information-
theoretic Analysis of Phonetic Dictionary
Access&amp;quot;, Computer Speech and Language,
2:1-11.
Carter, D.M. (1989) &amp;quot;Lexical Acquisition in
the Core Language Engine&amp;quot;, Proceedings
of the Fourth Conference of the European
Chapter of the Association for Computa-
tional Linguistics, pp 137-144.
Emirkanian, L., and L.H. Bouchard (1988)
&amp;quot;Knowledge Integration in a Robust
and Efficient Morpho-syntactic Analyser
for French&amp;quot;, Proceedings of the Twelfth
International Conference on Computa-
tional Linguistics, pp 166-171.
Futrelle, R.P., C.E. Dunn, D.S. Ellis and
M.J. Pescitelli, Jr. (1991) &amp;quot;Preprocessing
and Lexicon Design for Parsing Technical
Text&amp;quot;, Proceedings of the Second Inter-
national Workshop on Parsing Technolo-
gies, pp. 31-40.
Grosz, B. J., D. E. Appelt, P. Martin, and
F. Pereira (1987). &amp;quot;TEAM: An Exper-
iment in the Design of Transportable
Natural-Language Interfaces&amp;quot;. Artificial
Intelligence 32: 173-243.
Kernighan, M.D., K.W. Church, and W.A.
Gale (1990). &amp;quot;A Spelling Correction Pro-
gram Based on a Noisy Channel Model&amp;quot;,
Proceedings of the Thirteenth Interna-
tional Conference on Computational Lin-
guistics, pp 205-210.
Koskenniemi, K. (1983) Two-level morphol-
ogy: a general computational model for
word-form recognition and production.
University of Helsinki, Department of
General Linguistics, Publications, No. 11.
Pollock, J.J., and A. Zamora (1984) &amp;quot;Au-
tomatic Spelling Correction in Scientific
and Scholarly Text&amp;quot;, Communications of
the ACM, 27:4, pp 358-368.
Veronis, J. (1988) &amp;quot;Morphosyntactic Correc-
tion in Natural Language Interfaces&amp;quot;,
Proceedings of the Twelfth International
Conference on Computational Linguis-
tics, pp 708-713.
</reference>
<page confidence="0.998758">
166
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.921809">
<title confidence="0.998068">LATTICE-BASED WORD IDENTIFICATION IN CLARE</title>
<author confidence="0.999999">David M Carter</author>
<affiliation confidence="0.9736185">SRI International Cambridge Computer Science Research Centre</affiliation>
<address confidence="0.9966995">23 Millers Yard Cambridge CB2 1RQ, U.K.</address>
<email confidence="0.999835">dmcacam.sri.com</email>
<abstract confidence="0.998775764705882">I argue that because of spelling and typing errors and other properties of typed text, the identification of words and word boundaries in general requires syntactic and semantic knowledge. A lattice representation is therefore appropriate for lexical analysis. I show how the use of such a representation in the CLARE system allows different kinds of hypothesis about word identity to be integrated in a uniform framework. I then describe a quantitative evaluation of CLARE&apos;s performance on a set of sentences into which typographic errors have been introduced. The results show that syntax and semantics can be applied as powerful sources of constraint on the possible corrections for misspelled words.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Abe</author>
<author>Y Oshima</author>
<author>K Yuura</author>
<author>N Takeichi</author>
</authors>
<title>A Kana-Kanji Translation System for Non-Segmented Input Sentences Based on Syntactic and Semantic Analysis&amp;quot;,</title>
<date>1986</date>
<booktitle>Proceedings of the Eleventh International Conference on Computational Linguistics,</booktitle>
<pages>280--285</pages>
<contexts>
<context position="1847" citStr="Abe et al, 1986" startWordPosition="287" endWordPosition="290">lausible complete paths are subsequently selected. Syntactic parsing, of either spoken or written language, frequently makes use of a chart or well-formed substring table because the correct bracketing of a sentence cannot (easily) be calculated deterministically. And lattices are also often used in the task of converting Japanese text typed in kana (syllabic symbols) to kanji; the lack of interword spacing in written Japanese and the complex morphology of the language mean that lexical items and their boundaries cannot be reliably identified without applying syntactic and semantic knowledge (Abe et al, 1986). In contrast, however, it is often assumed that, for languages written with interword spaces, it is sufficient to group an input character stream deterministically into a sequence of words, punctuation symbols and perhaps other items, and to hand this sequence to the parser, possibly after word-by-word morphological analysis. Such an approach is sometimes adopted even when typographically complex inputs are handled; see, for example, Futrelle et al, 1991. In this paper I observe that, for typed input, spaces do not necessarily correspond to boundaries between lexical items, both for linguisti</context>
</contexts>
<marker>Abe, Oshima, Yuura, Takeichi, 1986</marker>
<rawString>Abe, M., Y. Oshima, K. Yuura and N. Takeichi (1986) &amp;quot;A Kana-Kanji Translation System for Non-Segmented Input Sentences Based on Syntactic and Semantic Analysis&amp;quot;, Proceedings of the Eleventh International Conference on Computational Linguistics, pp 280-285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Alshawi</author>
</authors>
<title>Resolving Quasi Logical Forms&amp;quot;,</title>
<date>1990</date>
<journal>Computational Linguistics</journal>
<volume>16</volume>
<pages>133--144</pages>
<contexts>
<context position="7448" citStr="Alshawi, 1990" startWordPosition="1209" endWordPosition="1210">rd. 160 cope correctly with the query &amp;quot;What number The lexicon proper is first accessed at this of the employees have cars?&amp;quot;. stage. 3 CLARE&apos;S PROCESSING STAGES The CLARE system is intended to provide language processing capabilities (both analysis and generation) and some reasoning facilities for a range of possible applications. English sentences are mapped, via a number of stages, into logical representations of their literal meanings, from which reasoning can proceed. Stages are linked by well-defined representations. The key intermediate representation is that of quasi logical form (QLF; Alshawi, 1990, 1992), a version of slightly extended first order logic augmented with constructs for phenomena such as anaphora and quantification that can only be resolved by reference to context. The unification of declarative linguistic data is the basic processing operation. The specific task considered in this paper is the process of mapping single sentences from character strings to QLF. Two kinds of issue are therefore not discussed here. These are the problem of segmenting a text into sentences and dealing with any markup instructions (cf Futrelle et al, 1991), which is logically prior to producing</context>
</contexts>
<marker>Alshawi, 1990</marker>
<rawString>Alshawi, H. (1990) &amp;quot;Resolving Quasi Logical Forms&amp;quot;, Computational Linguistics 16:3, pp. 133-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Alshawi</author>
</authors>
<title>The Core Language Engine,</title>
<date>1992</date>
<publisher>M.I.T. Press.</publisher>
<marker>Alshawi, 1992</marker>
<rawString>Alshawi, H. (ed.) (1992) The Core Language Engine, M.I.T. Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B van Berkel</author>
<author>K De Smedt</author>
</authors>
<title>Triphone Analysis: A Combined Method for the Correction of Orthographical and Typographical Errors&amp;quot;,</title>
<date>1988</date>
<booktitle>Proceedings of the Second Conference on Applied Natural Language Processing,</booktitle>
<pages>77--83</pages>
<marker>van Berkel, De Smedt, 1988</marker>
<rawString>van Berkel, B., and K. De Smedt (1988) &amp;quot;Triphone Analysis: A Combined Method for the Correction of Orthographical and Typographical Errors&amp;quot;, Proceedings of the Second Conference on Applied Natural Language Processing, pp. 77-83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Carter</author>
</authors>
<title>An Informationtheoretic Analysis of Phonetic Dictionary Access&amp;quot;,</title>
<date>1987</date>
<journal>Computer Speech and Language,</journal>
<pages>2--1</pages>
<contexts>
<context position="21528" citStr="Carter, 1987" startWordPosition="3515" endWordPosition="3516">ggested, requiring syntactic and semantic processing for further disambiguation. The average number of corrections suggested for these 49 was 4.57. However, only an average of 1.69 candidates (including, because of the way the corpus was selected, all the right ones) appeared in QLFs satisfying selectional restrictions; thus only 19% of the wrong candidates found their way into any QLF. If, in the absence of frequency information, we take all candidates as equally likely, then syntactic and semantic processing reduced the average entropy from 1.92 to 0.54, removing 72% of the uncertainty (see Carter, 1987, for a discussion of why entropy is the best measure to use in contexts like this). When many QLFs are produced for a sentence, CLARE orders them according to a set of scoring functions encoding syntactic and semantic preferences. For the 49 multiplecandidate tokens, removing all but the bestscoring QLF(s) eliminated 7 (21%) of the 34 wrong candidates surviving to the QLF stage; however, it also eliminated 5 (10%) of the right candidates. It is expected that future development of the scoring functions will further improve these figures, which are summarized in Table 1. The times taken to pars</context>
</contexts>
<marker>Carter, 1987</marker>
<rawString>Carter, D.M. (1987) &amp;quot;An Informationtheoretic Analysis of Phonetic Dictionary Access&amp;quot;, Computer Speech and Language, 2:1-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Carter</author>
</authors>
<title>Lexical Acquisition in the Core Language Engine&amp;quot;,</title>
<date>1989</date>
<booktitle>Proceedings of the Fourth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>137--144</pages>
<contexts>
<context position="10987" citStr="Carter, 1989" startWordPosition="1784" endWordPosition="1785">than the individual token. Local methods apply only to single still-unanalysed tokens, and may either supply analyses for them 161 or alter them to other tokens. The default methods, all of which may be switched on or off using system commands, supply facilities for inferring entries through access to an external machine-readable dictionary; for defining sequences of capitalized tokens as proper names; for spelling correction (described in detail in the next section); and for interacting with the user who may suggest a replacement word or phrase or enter the VEX lexical acquisition subsystem (Carter, 1989) to create the required entries. After a method has been applied, the lattice is, if possible, pruned: edges labelled by unanalysed tokens are provisionally removed, as are other edges and vertices that then do not lie on a complete path. If pruning succeeds (i.e. if at least one problem-free path remains) then token analysis is deemed to have succeeded, and unanalysed tokens (such as with/avoid) are forgotten; any remaining global methods are invoked, because they may provide analyses for token sequences, but remaining local ones are not. If full pruning does not succeed, any subpath in the l</context>
</contexts>
<marker>Carter, 1989</marker>
<rawString>Carter, D.M. (1989) &amp;quot;Lexical Acquisition in the Core Language Engine&amp;quot;, Proceedings of the Fourth Conference of the European Chapter of the Association for Computational Linguistics, pp 137-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Emirkanian</author>
<author>L H Bouchard</author>
</authors>
<title>Knowledge Integration in a Robust and Efficient Morpho-syntactic Analyser for French&amp;quot;,</title>
<date>1988</date>
<booktitle>Proceedings of the Twelfth International Conference on Computational Linguistics,</booktitle>
<pages>166--171</pages>
<contexts>
<context position="13869" citStr="Emirkanian and Bouchard, 1988" startWordPosition="2249" endWordPosition="2252">ossessive ending &amp;quot;s&amp;quot; is treated as a separate word in the CLARE grammar to allow the correct analysis of phrases such as &amp;quot;the man in the corner&apos;s wife&amp;quot;, and spelling changes can be involved here. Like segmentation, tokenization can yield multiple results, mainly because there is no reason for a complex cluster like Mr. or King&apos;s not also to be defined as a lexical item. One major advantage of the simplicity of the affix-stripping mechanism is that spelling correction can be interleaved directly with it. Root forms in the lexicon are represented in a discrimination net for efficient access (cf Emirkanian and Bouchard, 1988). When the spelling corrector is called to suggest possible corrections for a word, the number of simple errors (of deletion, insertion, substitution and transposition; e.g. Pollock and Zamora, 1984) to assume is given. Normal segmentation is just the special case of this with the number of errors set to zero. The mechanism nondeterministically removes affixes from each end of the word, postulating errors if appropriate, and then looks up the resulting string in the discrimination net, again considering the possibility of error.3 3This is the reverse of Veronis&apos; (1988) algorithm, where roots a</context>
<context position="15874" citStr="Emirkanian and Bouchard, 1988" startWordPosition="2577" endWordPosition="2580"> approval, or, if the number of them does not exceed a preset threshold, all be preserved as alternatives for disambiguation at the later syntactic or semantic stages. The lattice representation allows multiple-word corrections to be preserved along with single-word ones. It is generally recognized that spelling errors in typed input are of two kinds: competence errors, where the user does not know, or has forgotten, how to spell a word; and performance errors, where the wrong sequence of keys is hit. CLARE&apos;s correction mechanism is oriented towards the latter. Other work (e.g. Veronis, 1988, Emirkanian and Bouchard, 1988, van Berkel and De Smedt, 1988) emphasizes the former, often on the grounds that competence errors are both harder for the user to correct and tend to make a worse impression on a human reader. However, Emirkanian and Bouchard identify the many-to-one nature of French spelling-sound correspondence as responsible for the predominance of such errors in that language, which they say does not hold in English; and material typed to CLARE tends to be processed further (for seems easier and more efficient to match affixes first, because then the hypothesized root can be looked up without having to a</context>
</contexts>
<marker>Emirkanian, Bouchard, 1988</marker>
<rawString>Emirkanian, L., and L.H. Bouchard (1988) &amp;quot;Knowledge Integration in a Robust and Efficient Morpho-syntactic Analyser for French&amp;quot;, Proceedings of the Twelfth International Conference on Computational Linguistics, pp 166-171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R P Futrelle</author>
<author>C E Dunn</author>
<author>D S Ellis</author>
<author>M J Pescitelli</author>
</authors>
<title>Preprocessing and Lexicon Design for Parsing Technical Text&amp;quot;,</title>
<date>1991</date>
<booktitle>Proceedings of the Second International Workshop on Parsing Technologies,</booktitle>
<pages>31--40</pages>
<contexts>
<context position="2306" citStr="Futrelle et al, 1991" startWordPosition="359" endWordPosition="362">gy of the language mean that lexical items and their boundaries cannot be reliably identified without applying syntactic and semantic knowledge (Abe et al, 1986). In contrast, however, it is often assumed that, for languages written with interword spaces, it is sufficient to group an input character stream deterministically into a sequence of words, punctuation symbols and perhaps other items, and to hand this sequence to the parser, possibly after word-by-word morphological analysis. Such an approach is sometimes adopted even when typographically complex inputs are handled; see, for example, Futrelle et al, 1991. In this paper I observe that, for typed input, spaces do not necessarily correspond to boundaries between lexical items, both for linguistic reasons and because of the possibility of typographic errors. This means that a lattice representation, not a simple sequence, should be used throughout front end (preparsing) analysis. The CLARE system under development at SRI Cambridge uses such a representation, allowing it to deal straightforwardly with combinations or multiple occurrences of phenomena that would be difficult or impossible to process correctly under a sequence representation. As evi</context>
<context position="8009" citStr="Futrelle et al, 1991" startWordPosition="1298" endWordPosition="1301">esentation is that of quasi logical form (QLF; Alshawi, 1990, 1992), a version of slightly extended first order logic augmented with constructs for phenomena such as anaphora and quantification that can only be resolved by reference to context. The unification of declarative linguistic data is the basic processing operation. The specific task considered in this paper is the process of mapping single sentences from character strings to QLF. Two kinds of issue are therefore not discussed here. These are the problem of segmenting a text into sentences and dealing with any markup instructions (cf Futrelle et al, 1991), which is logically prior to producing character strings; and possible context-dependence of the lexical phenomena discussed, which would need to be dealt with after the creation of QLFs. In the analysis direction, CLARE&apos;s front end processing stages are as follows. 1. A sentence is divided into a sequence of clusters separated by white space. 2. Each cluster is divided into one or more tokens: words (possibly inflected), punctuation characters, and other items. Tokenization is nondeterministic, and so a lattice is used at this and subsequent stages. 3. Each token is analysed as a sequence of</context>
</contexts>
<marker>Futrelle, Dunn, Ellis, Pescitelli, 1991</marker>
<rawString>Futrelle, R.P., C.E. Dunn, D.S. Ellis and M.J. Pescitelli, Jr. (1991) &amp;quot;Preprocessing and Lexicon Design for Parsing Technical Text&amp;quot;, Proceedings of the Second International Workshop on Parsing Technologies, pp. 31-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>D E Appelt</author>
<author>P Martin</author>
<author>F Pereira</author>
</authors>
<title>TEAM: An Experiment in the Design of Transportable Natural-Language Interfaces&amp;quot;.</title>
<date>1987</date>
<journal>Artificial Intelligence</journal>
<volume>32</volume>
<pages>173--243</pages>
<contexts>
<context position="4958" citStr="Grosz et al, 1987" startWordPosition="799" endWordPosition="802">A reliable spelling corrector must allow for all these possibilities, which must, in addition, be distinguished from the use of correctly-typed words that happen to fall outside the system&apos;s lexicon. However, even in the absence of &amp;quot;noise&amp;quot; of this kind, spaces do not always correspond to lexical item boundaries, at least if lexical items are defined in a way that is most convenient for grammatical purposes. For example, &amp;quot;special&amp;quot; forms such as telephone numbers or e-mail addresses, which are common in many domains, may contain spaces. In CLARE, these are analysed using regular expressions (cf Grosz et al, 1987), which may include space characters. When such an expression is realised, an analysis of it, connecting non-adjacent vertices if it contains spaces, is added to the lattice. The complexities of punctuation are another source of uncertainty: many punctuation symbols have several uses, not all of which necessarily lead to the same way of segmenting the input. For example, periods may indicate either the end of a sentence or an abbreviation, and slashes may be simple wordinternal characters (e.g. X11/NeWS) or function lexically as disjunctions, as in [1] I&apos;m looking for suggestions for vendors t</context>
</contexts>
<marker>Grosz, Appelt, Martin, Pereira, 1987</marker>
<rawString>Grosz, B. J., D. E. Appelt, P. Martin, and F. Pereira (1987). &amp;quot;TEAM: An Experiment in the Design of Transportable Natural-Language Interfaces&amp;quot;. Artificial Intelligence 32: 173-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church Kernighan</author>
<author>W A Gale</author>
</authors>
<title>A Spelling Correction Program Based on a Noisy Channel Model&amp;quot;,</title>
<date>1990</date>
<booktitle>Proceedings of the Thirteenth International Conference on Computational Linguistics,</booktitle>
<pages>205--210</pages>
<marker>Kernighan, Gale, 1990</marker>
<rawString>Kernighan, M.D., K.W. Church, and W.A. Gale (1990). &amp;quot;A Spelling Correction Program Based on a Noisy Channel Model&amp;quot;, Proceedings of the Thirteenth International Conference on Computational Linguistics, pp 205-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Two-level morphology: a general computational model for word-form recognition and production.</title>
<date>1983</date>
<volume>11</volume>
<publisher>Publications,</publisher>
<institution>University of Helsinki, Department of General Linguistics,</institution>
<contexts>
<context position="12665" citStr="Koskenniemi, 1983" startWordPosition="2054" endWordPosition="2055">EGMENTATION AND SPELLING CORRECTION A fairly simple affix-stripping approach to token segmentation is adopted in CLARE be2In fact, for completeness, CLARE allows the application of two or more methods in tandem and will combines the results without any intermediate pruning. This option would be useful if, in a given application, two sources of knowledge were deemed to be about equally reliable in their predictions. cause inflectional morphological changes in English tend not to be complex enough to warrant more powerful, and potentially less efficient, treatments such as two-level morphology (Koskenniemi, 1983). Derivational morphological relationships typically involve semantic peculiarities as well, necessitating the definition of derived words in the lexicon in their own right. The rules for dividing clusters into tokens have the same form as those for segmenting tokens into morphemes, and are processed by the same mechanism. Thus &amp;quot;,&amp;quot;, like, say, &amp;quot;ed&amp;quot;, is defined as a suffix, but one that is treated by the grammar as a separate word rather than a bound morpheme. Rules for punctuation characters are very simple because no spelling changes are ever involved. However, the possessive ending &amp;quot;s&amp;quot; is tr</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, K. (1983) Two-level morphology: a general computational model for word-form recognition and production. University of Helsinki, Department of General Linguistics, Publications, No. 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Pollock</author>
<author>A Zamora</author>
</authors>
<title>Automatic Spelling Correction in Scientific and Scholarly Text&amp;quot;,</title>
<date>1984</date>
<journal>Communications of the ACM,</journal>
<volume>27</volume>
<pages>358--368</pages>
<contexts>
<context position="14068" citStr="Pollock and Zamora, 1984" startWordPosition="2278" endWordPosition="2281">mentation, tokenization can yield multiple results, mainly because there is no reason for a complex cluster like Mr. or King&apos;s not also to be defined as a lexical item. One major advantage of the simplicity of the affix-stripping mechanism is that spelling correction can be interleaved directly with it. Root forms in the lexicon are represented in a discrimination net for efficient access (cf Emirkanian and Bouchard, 1988). When the spelling corrector is called to suggest possible corrections for a word, the number of simple errors (of deletion, insertion, substitution and transposition; e.g. Pollock and Zamora, 1984) to assume is given. Normal segmentation is just the special case of this with the number of errors set to zero. The mechanism nondeterministically removes affixes from each end of the word, postulating errors if appropriate, and then looks up the resulting string in the discrimination net, again considering the possibility of error.3 3This is the reverse of Veronis&apos; (1988) algorithm, where roots are matched before affixes. However, it 162 Interleaving correction with segmentation like this promotes efficiency in the following way. As in most other correctors, only up to two simple errors are </context>
<context position="19372" citStr="Pollock and Zamora, 1984" startWordPosition="3149" endWordPosition="3152"> CLARE&apos;s spelling correction, the following experiment, intended to simulate performance (typographic) errors, was carried out. Five hundred sentences, of up to ten words in length, falling within CLARE&apos;s current core lexical (1600 root forms) and grammatical coverage were taken at random from the LOB corpus. These sentences were passed, character by character, through a channel which transmitted a character without alteration with probability 0.99, and with probability 0.01 introduced a simple error. The relative probabilities of the four different kinds of error were deduced from Table X of Pollock and Zamora, 1984; where a new character had to be inserted or substituted, it was selected at random from the original sentence set. This process produced a total of 102 sentences that differed from their originals. The average length was 6.46 words, and there were 123 corrupted tokens in all, some containing more than one simple error. Because longer sentences were more likely to be changed, the average length of a changed sentence was some 15% more than that of an original one. The corrupted sentence set was then processed by CLARE with only the spelling correction recovery method in force and with no user </context>
</contexts>
<marker>Pollock, Zamora, 1984</marker>
<rawString>Pollock, J.J., and A. Zamora (1984) &amp;quot;Automatic Spelling Correction in Scientific and Scholarly Text&amp;quot;, Communications of the ACM, 27:4, pp 358-368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Veronis</author>
</authors>
<title>Morphosyntactic Correction in Natural Language Interfaces&amp;quot;,</title>
<date>1988</date>
<booktitle>Proceedings of the Twelfth International Conference on Computational Linguistics,</booktitle>
<pages>708--713</pages>
<contexts>
<context position="15843" citStr="Veronis, 1988" startWordPosition="2575" endWordPosition="2576">or selection or approval, or, if the number of them does not exceed a preset threshold, all be preserved as alternatives for disambiguation at the later syntactic or semantic stages. The lattice representation allows multiple-word corrections to be preserved along with single-word ones. It is generally recognized that spelling errors in typed input are of two kinds: competence errors, where the user does not know, or has forgotten, how to spell a word; and performance errors, where the wrong sequence of keys is hit. CLARE&apos;s correction mechanism is oriented towards the latter. Other work (e.g. Veronis, 1988, Emirkanian and Bouchard, 1988, van Berkel and De Smedt, 1988) emphasizes the former, often on the grounds that competence errors are both harder for the user to correct and tend to make a worse impression on a human reader. However, Emirkanian and Bouchard identify the many-to-one nature of French spelling-sound correspondence as responsible for the predominance of such errors in that language, which they say does not hold in English; and material typed to CLARE tends to be processed further (for seems easier and more efficient to match affixes first, because then the hypothesized root can b</context>
</contexts>
<marker>Veronis, 1988</marker>
<rawString>Veronis, J. (1988) &amp;quot;Morphosyntactic Correction in Natural Language Interfaces&amp;quot;, Proceedings of the Twelfth International Conference on Computational Linguistics, pp 708-713.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>