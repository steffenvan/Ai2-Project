<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001325">
<title confidence="0.9957875">
FBK-irst: Lexical Substitution Task Exploiting
Domain and Syntagmatic Coherence
</title>
<author confidence="0.728184">
Claudio Giuliano and Alfio Gliozzo and Carlo Strapparava
</author>
<address confidence="0.438995">
FBK-irst, I-38050, Povo, Trento, ITALY
</address>
<email confidence="0.983317">
{giuliano, gliozzo, strappa}@itc.it
</email>
<sectionHeader confidence="0.998587" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999914307692308">
This paper summarizes FBK-irst participa-
tion at the lexical substitution task of the
SEMEVAL competition. We submitted two
different systems, both exploiting synonym
lists extracted from dictionaries. For each
word to be substituted, the systems rank the
associated synonym list according to a simi-
larity metric based on Latent Semantic Anal-
ysis and to the occurrences in the Web 1T
5-gram corpus, respectively. In particular,
the latter system achieves the state-of-the-art
performance, largely surpassing the baseline
proposed by the organizers.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998413535714286">
The lexical substitution (Glickman et al., 2006a) can
be regarded as a subtask of the lexical entailment,
in which for a given word in context the system is
asked to select an alternative word that can be re-
placed in that context preserving the meaning. Lex-
ical Entailment, and in particular lexical reference
(Glickman et al., 2006b)1, is in turn a subtask of tex-
tual entailment, which is formally defined as a rela-
tionship between a coherent text T and a language
expression, the hypothesis H. T is said to entail H,
denoted by T —* H, if the meaning of H can be in-
ferred from the meaning of T (Dagan et al., 2005;
Dagan and Glickman., 2004). Even though this no-
tion has been only recently proposed in the computa-
tional linguistics literature, it attracts more and more
attention due to the high generality of its settings and
to the usefulness of its (potential) applications.
&apos;In the literature, slight variations of this problem have been
also referred to as sense matching (Dagan et al., 2006).
With respect to lexical entailment, the lexical sub-
stitution task has a more restrictive criterion. In
fact, two words can be substituted when meaning is
preserved, while the criterion for lexical entailment
is that the meaning of the thesis is implied by the
meaning of the hypothesis. The latter condition is in
general ensured by substituting either hyperonyms
or synonyms, while the former is more rigid because
only synonyms are in principle accepted.
Formally, in a lexical entailment task a system is
asked to decide whether the substitution of a par-
ticular term w with the term e in a coherent text
H,,, = HlwH&apos; generates a sentence He = HleH&apos;
such that H,,, —* He, where Hl and H&apos; denote the
left and the right context of w, respectively. For
example, given the source word ‘weapon’ a system
may substitute it with the target synonym ‘arm’, in
order to identify relevant texts that denote the sought
concept using the latter term.
A particular case of lexical entailment is recog-
nizing synonymy, where both H,,, —* He and He —*
H,,, hold. The lexical substitution task at SEMEVAL
addresses exactly this problem. The task is not easy
since lists of candidate entailed words are not pro-
vided by the organizers. Therefore the system is
asked first to identify a set of candidate words, and
then to select only those words that fit in a particu-
lar context. To promote unsupervised methods, the
organizers did not provide neither labeled data for
training nor dictionaries or list of synonyms explain-
ing the meanings of the entailing words.
In this paper, we describe our approach to the
Lexical Substitution task at SEMEVAL 2007. We
developed two different systems (named IRST1-lsa
and IRST2-syn in the official task ranking), both ex-
ploiting a common lists of synonyms extracted from
dictionaries (i.e. WordNet and the Oxford Dictio-
</bodyText>
<page confidence="0.991196">
145
</page>
<bodyText confidence="0.984922523809524">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 145–148,
Prague, June 2007. c�2007 Association for Computational Linguistics
nary) and ranking them according to two different
criteria:
No other resources were used and the sense rank-
ing in WordNet was not considered at all. Therefore
our system is fully unsupervised.
Domain Proximity: the similarity between each
candidate entailed word and the context of the
entailing word is estimated by means of a co-
sine between their corresponding vectors in the
LSA space.
Syntagmatic Coherence: querying a large corpus,
the system finds all occurrences of the target
sentence, in which the entailing word is substi-
tuted with each synonym, and it assigns scores
proportional to the occurrence frequencies.
Results show that both methods are effective. In
particular, the second method achieved the best per-
formance in the competition, defining the state-of-
the-art for the lexical substitution task.
</bodyText>
<sectionHeader confidence="0.980093" genericHeader="method">
2 Lexical Substitution Systems
</sectionHeader>
<bodyText confidence="0.999892285714286">
The lexical substitution task is a textual entailment
subtask in which the system is asked to provide one
or more terms e E E C_ syn(w) that can be sub-
stituted to w in a particular context Hw = HlwHr
generating a sentence He = HleHr such that both
Hw —* He and He —* Hw hold, where syn(w) is the
set of synonyms lemmata obtained from all synset in
which w appears in WordNet and Hl and Hr denote
the left and the right context of w, respectively.
The first step, common to both systems, consists
of determining the set of synonyms syn(w) for each
entailing word (see Section 2.1). Then, each system
ranks the extracted lists according to the criteria de-
scribed in Section 2.2 and 2.3.
</bodyText>
<subsectionHeader confidence="0.998081">
2.1 Used Lexical Resources
</subsectionHeader>
<bodyText confidence="0.999787666666667">
For selecting the synonym candidates we used two
lexical repositories: WordNet 2.0 and the Oxford
American Writer Thesaurus (1st Edition). For each
target word, we simply collect all the synonyms for
all the word senses in both these resources.
We exploited two corpora for our systems: the
British National Corpus for acquiring the LSA space
for ranking with domain proximity measure (Sec-
tion 2.2) and the Web 1T 5-gram Version 1 corpus
from Google (distributed by Linguistic Data Consor-
tium)2 for ranking the proposed synonyms accord-
ing to syntagmatic coherence (Section 2.3).
</bodyText>
<footnote confidence="0.9640655">
2Available from http://www.ldc.upenn.edu/Catalog/
CatalogEntry.jsp?catalogId=LDC2006T13.
</footnote>
<subsectionHeader confidence="0.995473">
2.2 Domain Proximity
</subsectionHeader>
<bodyText confidence="0.952093694444444">
Semantic Domains are common areas of human dis-
cussion, such as Economics, Politics, Law (Magnini
et al., 2002). Semantic Domains can be described
by DMs (Gliozzo, 2005), by defining a set of term
clusters, each representing a Semantic Domain, i.e.
a set of terms having similar topics. A DM is repre-
sented by a k x k&apos; rectangular matrix D, containing
the domain relevance for each term with respect to
each domain.
DMs can be acquired from texts by exploiting
term clustering algorithms. The degree of associ-
ation among terms and clusters, estimated by the
learning algorithm, provides a domain relevance
function. For our experiments we adopted a clus-
tering strategy based on Latent Semantic Analy-
sis (LSA) (Deerwester et al., 1990), following the
methodology described in (Gliozzo, 2005).
The input of the LSA process is a Term by Docu-
ment matrix T of the frequencies in the whole cor-
pus for each term. In this work we indexed all lem-
matized terms. The so obtained matrix is then de-
composed by means of a Singular Value Decompo-
sition, identifying the principal components of T.
Once a DM has been defined by the matrix D, the
Domain Space is a k&apos; dimensional space, in which
both texts and terms are associated to Domain Vec-
tors (DVs), i.e. vectors representing their domain
relevance with respect to each domain. The DV t&apos;i
for the term ti E V is the ith row of D, where
V = {t1, t2, ... , tkI is the vocabulary of the cor-
pus. The DVs for texts are obtained by mapping the
�
document vectors dj, represented in the vector space
�
model, into the vectors
fined by d&apos;j in the Domain Space, de-
</bodyText>
<equation confidence="0.8565555">
D(dj) = dj(IIDFD) = �d&apos; (1)
j
</equation>
<bodyText confidence="0.968898454545454">
where IIDF is a diagonal matrix such that iIDF
i,i =
IDF(wi) and IDF(wi) is the Inverse Document
Frequency of wi. The similarity among both texts
and terms in the Domain Space is then estimated by
the cosine operation.
To implement our lexical substitution criterion we
ranked the candidate entailed words according to
their domain proximity, following the intuition that
if two words can be substituted in a particular con-
text, then the entailed word should belong to the
</bodyText>
<page confidence="0.995293">
146
</page>
<bodyText confidence="0.999199125">
same semantic domain of the context in which the
entailing word is located.
The intuition above can be modeled by estimating
the similarity in the LSA space between the pseudo
document, estimated by Equation 1, formed by all
the words in the context of the entailing word (i.e.
the union of Hl and Hr), and each candidate en-
tailed word in syn(w).
</bodyText>
<subsectionHeader confidence="0.998152">
2.3 Syntagmatic Coherence
</subsectionHeader>
<bodyText confidence="0.996219">
The syntagmatic coherence criterion is based on the
following observation. If the entailing word w in
its context Hw = HlwHr is actually entailed by
a word e, then there exist some occurrences on the
WEB of the expression He = HleHr, obtained
by replacing the entailing word with the candidate
entailed word. This intuition can be easily imple-
mented by looking for occurrences of He in the Web
1T 5-gram Version 1 corpus.
Figure 1 presents pseudo-code for the synonym
scoring procedure. The procedure takes as input the
set of candidate entailed words E = syn(w) for the
entailing word w, the context Hw in which w oc-
curs, the length of the n-gram (2 S n S 5) and the
target word itself. For each candidate entailed word
ei, the procedure ngrams(Hw, w, ei, n) is invoked
to substitute w with ei in Hw, obtaining Hez, and re-
turns the set Q of all n-grams containing ei. For ex-
ample, all 3-grams obtained replacing “bright” with
the synonym “intelligent” in the sentence “He was
bright and independent and proud.” are “He was in-
telligent”, “was intelligent and” and “intelligent and
independent”. The maximum number of n-grams
generated is E5n�2 n. Each candidate synonym is
then assigned a score by summing all the frequen-
cies in the Web 1T corpus of the so generated n-
grams3. The set of synonyms is ranked according
the so obtained scores. However, candidates which
appear in longer n-grams are preferred to candidates
appearing in shorter ones. Therefore, the ranked list
contains first the candidate entailed words appearing
in 5-grams, if any, then those appearing in 4-grams,
and so on. For example, a candidate e1 that appears
only once in 5-grams is preferred to a candidate e2
that appears 1000 times in 4-grams. Note that this
strategy could lead to an output list with repetitions.
3Note that n-grams with frequency lower than 40 are not
present in the corpus.
</bodyText>
<listItem confidence="0.96704475">
1: Given E, the set of candidate synonyms
2: Given H, the context in which w occurs
3: Given n, the length of the n-gram
4: Given w, the word to be substituted
5: E&apos; +— 0
6: for each ei in E do
7: Q +— ngrams(H, w, ei, n)
8: scorei +— 0
9: for each qj in Q do
10: Get the frequency fj of qj
11: scorei +— scorei + fj
12: end for
13: if scorei &gt; 0 then add the pair {scorei, eiI
in E&apos;
14: end for
15: Return E&apos;
</listItem>
<figureCaption confidence="0.998161">
Figure 1: The synonym scoring procedure
</figureCaption>
<sectionHeader confidence="0.995507" genericHeader="evaluation">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999971095238095">
There are basically two scoring methodologies: (i)
BEST, which scores the best substitute for a given
item, and (ii) OOT, which scores for the best 10 sub-
stitutes for a given item, and systems do not benefit
from providing less responses4.
BEST. Table 1 and 2 report the performance for the
domain proximity and syntagmatic coherence rank-
ing. Please note that in Table 2 we report both the
official score and a score that takes into account just
the first proposal of the systems, as the usual in-
terpretation of BEST score methodology would sug-
gest5.
OOT. Table 4 and 5 report the performance for the
domain proximity and syntagmatic coherence rank-
ing, scoring for the 10 best substitutes. The results
are quite good especially in the case of syntagmatic
coherence ranking.
Baselines. Table 3 displays the baselines respec-
tively for the BEST and OOT using WordNet 2.1
as calculated by the task organizers. They pro-
pose many baseline measures, but we report only the
</bodyText>
<footnote confidence="0.578839444444444">
4The task proposed a third scoring measure MW that scores
precision and recall for detection and identification of multi-
words in the input sentences. However our systems were not
designed for this functionality. For the details of all scoring
methodologies please refer to the task description documents.
5We misinterpreted that the official scorer divides anyway
the figures by the number of proposals. So for the competition
we submitted the oot result file without cutting the words after
the first one.
</footnote>
<page confidence="0.984231">
147
</page>
<table confidence="0.7995845">
P R Mode P Mode R
all 8.06 8.06 13.09 13.09
</table>
<tableCaption confidence="0.953761">
Table 1: BEST results for LSA ranking (IRST1-lsa)
</tableCaption>
<table confidence="0.987691666666667">
P R Mode P Mode R
all 12.93 12.91 20.33 20.33
all (official) 6.95 6.94 20.33 20.33
</table>
<tableCaption confidence="0.950577">
Table 2: BEST results for Syntagmatic ranking
(IRST2-syn)
</tableCaption>
<bodyText confidence="0.891167666666667">
WordNet one, as it is the higher scoring baseline. We
can observe that globally our systems perform quite
good with respect to the baselines.
</bodyText>
<sectionHeader confidence="0.999445" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.996743222222222">
In this paper we reported a detailed description of
the FBK-irst systems submitted to the Lexical En-
tailment task at the SEMEVAL 2007 evaluation cam-
paign. Our techniques are totally unsupervised, as
they do not require neither the availability of sense
tagged data nor an estimation of sense priors, not
considering the WordNet sense order information.
Results are quite good, as in general they signifi-
cantly outperform all the baselines proposed by the
organizers. In addition, the method based on syn-
tagmatic coherence estimated on the WEB outper-
forms, to our knowledge, the other systems sub-
mitted to the competition. For the future, we plan
to avoid the use of dictionaries by adopting term
similarity techniques to select the candidate entailed
words and to exploit this methodology in some spe-
cific applications such as taxonomy induction and
ontology population.
</bodyText>
<sectionHeader confidence="0.997774" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.969327333333333">
Claudio Giuliano is supported by the X-Media
project (http://www.x-media-project.
org), sponsored by the European Commission
as part of the Information Society Technologies
(IST) programme under EC grant number IST-FP6-
026978. Alfio Gliozzo is supported by FIRB-Israel
</bodyText>
<table confidence="0.994705">
P R Mode P Mode R
WN BEST 9.95 9.95 15.28 15.28
WN OOT 29.70 29.35 40.57 40.57
</table>
<tableCaption confidence="0.991204">
Table 3: WordNet Baselines
</tableCaption>
<table confidence="0.866766">
P R Mode P Mode R
all 41.23 41.20 55.28 55.28
</table>
<tableCaption confidence="0.987303">
Table 4: OOT results for LSA ranking (IRST1-lsa)
</tableCaption>
<table confidence="0.895453">
P R Mode P Mode R
all 69.03 68.90 58.54 58.54
</table>
<tableCaption confidence="0.966683">
Table 5: OOT results for Syntagmatic ranking
(IRST2-syn)
</tableCaption>
<bodyText confidence="0.942377">
research project N. RBIN045PXH.
</bodyText>
<sectionHeader confidence="0.995101" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999096875">
I. Dagan and O. Glickman. 2004. Probabilistic tex-
tual entailment: Generic applied modeling of language
variability. In proceedings of the PASCAL Workshop
on Learning Methods for Text Understanding and Min-
ing, Grenoble.
I. Dagan, O. Glickman, and B. Magnini. 2005. The pas-
cal recognising textual entailment challenge. Proceed-
ings of the PASCAL Challenges Workshop on Recog-
nising Textual Entailment.
I. Dagan, O. Glickman, A. Gliozzo, E. Marmorshtein,
and C. Strapparava. 2006. Direct word sense match-
ing for lexical substitution. In Proceedings ACL-2006,
pages 449–456, Sydney, Australia, July.
S. Deerwester, S. Dumais, G. Furnas, T. Landauer, and
R. Harshman. 1990. Indexing by latent semantic anal-
ysis. Journal of the American Society of Information
Science.
O. Glickman, I. Dagan, M. Keller, S. Bengio, and
W. Daelemans. 2006a. Investigating lexical substi-
tution scoring for subtitle generation tenth conference
on computational natural language learning. In Pro-
ceedings of CoNLL-2006.
O. Glickman, E. Shnarch, and I. Dagan. 2006b. Lexical
reference: a semantic matching subtask. In proceed-
ings of EMNLP 2006.
A. Gliozzo. 2005. Semantic Domains in Computa-
tional Linguistics. Ph.D. thesis, ITC-irst/University of
Trento.
B. Magnini, C. Strapparava, G. Pezzulo, and A. Gliozzo.
2002. The role of domain information in word
sense disambiguation. Natural Language Engineer-
ing, 8(4):359–373.
</reference>
<page confidence="0.996846">
148
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.897703">
<title confidence="0.998145">FBK-irst: Lexical Substitution Task Exploiting Domain and Syntagmatic Coherence</title>
<author confidence="0.999359">Claudio Giuliano</author>
<author confidence="0.999359">Alfio Gliozzo</author>
<author confidence="0.999359">Carlo Strapparava</author>
<address confidence="0.967427">FBK-irst, I-38050, Povo, Trento, ITALY</address>
<email confidence="0.99152">gliozzo,</email>
<abstract confidence="0.995446142857143">This paper summarizes FBK-irst participation at the lexical substitution task of the We submitted two different systems, both exploiting synonym lists extracted from dictionaries. For each word to be substituted, the systems rank the associated synonym list according to a similarity metric based on Latent Semantic Analysis and to the occurrences in the Web 1T 5-gram corpus, respectively. In particular, the latter system achieves the state-of-the-art performance, largely surpassing the baseline proposed by the organizers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
</authors>
<title>Probabilistic textual entailment: Generic applied modeling of language variability.</title>
<date>2004</date>
<booktitle>In proceedings of the PASCAL Workshop on Learning Methods for Text Understanding and Mining,</booktitle>
<location>Grenoble.</location>
<marker>Dagan, Glickman, 2004</marker>
<rawString>I. Dagan and O. Glickman. 2004. Probabilistic textual entailment: Generic applied modeling of language variability. In proceedings of the PASCAL Workshop on Learning Methods for Text Understanding and Mining, Grenoble.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
<author>B Magnini</author>
</authors>
<title>The pascal recognising textual entailment challenge.</title>
<date>2005</date>
<booktitle>Proceedings of the PASCAL Challenges Workshop on Recognising Textual Entailment.</booktitle>
<contexts>
<context position="1399" citStr="Dagan et al., 2005" startWordPosition="219" endWordPosition="222">on The lexical substitution (Glickman et al., 2006a) can be regarded as a subtask of the lexical entailment, in which for a given word in context the system is asked to select an alternative word that can be replaced in that context preserving the meaning. Lexical Entailment, and in particular lexical reference (Glickman et al., 2006b)1, is in turn a subtask of textual entailment, which is formally defined as a relationship between a coherent text T and a language expression, the hypothesis H. T is said to entail H, denoted by T —* H, if the meaning of H can be inferred from the meaning of T (Dagan et al., 2005; Dagan and Glickman., 2004). Even though this notion has been only recently proposed in the computational linguistics literature, it attracts more and more attention due to the high generality of its settings and to the usefulness of its (potential) applications. &apos;In the literature, slight variations of this problem have been also referred to as sense matching (Dagan et al., 2006). With respect to lexical entailment, the lexical substitution task has a more restrictive criterion. In fact, two words can be substituted when meaning is preserved, while the criterion for lexical entailment is tha</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2005</marker>
<rawString>I. Dagan, O. Glickman, and B. Magnini. 2005. The pascal recognising textual entailment challenge. Proceedings of the PASCAL Challenges Workshop on Recognising Textual Entailment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
<author>A Gliozzo</author>
<author>E Marmorshtein</author>
<author>C Strapparava</author>
</authors>
<title>Direct word sense matching for lexical substitution.</title>
<date>2006</date>
<booktitle>In Proceedings ACL-2006,</booktitle>
<pages>449--456</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="1783" citStr="Dagan et al., 2006" startWordPosition="281" endWordPosition="284"> which is formally defined as a relationship between a coherent text T and a language expression, the hypothesis H. T is said to entail H, denoted by T —* H, if the meaning of H can be inferred from the meaning of T (Dagan et al., 2005; Dagan and Glickman., 2004). Even though this notion has been only recently proposed in the computational linguistics literature, it attracts more and more attention due to the high generality of its settings and to the usefulness of its (potential) applications. &apos;In the literature, slight variations of this problem have been also referred to as sense matching (Dagan et al., 2006). With respect to lexical entailment, the lexical substitution task has a more restrictive criterion. In fact, two words can be substituted when meaning is preserved, while the criterion for lexical entailment is that the meaning of the thesis is implied by the meaning of the hypothesis. The latter condition is in general ensured by substituting either hyperonyms or synonyms, while the former is more rigid because only synonyms are in principle accepted. Formally, in a lexical entailment task a system is asked to decide whether the substitution of a particular term w with the term e in a coher</context>
</contexts>
<marker>Dagan, Glickman, Gliozzo, Marmorshtein, Strapparava, 2006</marker>
<rawString>I. Dagan, O. Glickman, A. Gliozzo, E. Marmorshtein, and C. Strapparava. 2006. Direct word sense matching for lexical substitution. In Proceedings ACL-2006, pages 449–456, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S Dumais</author>
<author>G Furnas</author>
<author>T Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society of Information Science.</journal>
<contexts>
<context position="6776" citStr="Deerwester et al., 1990" startWordPosition="1099" endWordPosition="1102">). Semantic Domains can be described by DMs (Gliozzo, 2005), by defining a set of term clusters, each representing a Semantic Domain, i.e. a set of terms having similar topics. A DM is represented by a k x k&apos; rectangular matrix D, containing the domain relevance for each term with respect to each domain. DMs can be acquired from texts by exploiting term clustering algorithms. The degree of association among terms and clusters, estimated by the learning algorithm, provides a domain relevance function. For our experiments we adopted a clustering strategy based on Latent Semantic Analysis (LSA) (Deerwester et al., 1990), following the methodology described in (Gliozzo, 2005). The input of the LSA process is a Term by Document matrix T of the frequencies in the whole corpus for each term. In this work we indexed all lemmatized terms. The so obtained matrix is then decomposed by means of a Singular Value Decomposition, identifying the principal components of T. Once a DM has been defined by the matrix D, the Domain Space is a k&apos; dimensional space, in which both texts and terms are associated to Domain Vectors (DVs), i.e. vectors representing their domain relevance with respect to each domain. The DV t&apos;i for th</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>S. Deerwester, S. Dumais, G. Furnas, T. Landauer, and R. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society of Information Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Glickman</author>
<author>I Dagan</author>
<author>M Keller</author>
<author>S Bengio</author>
<author>W Daelemans</author>
</authors>
<title>Investigating lexical substitution scoring for subtitle generation tenth conference on computational natural language learning.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL-2006.</booktitle>
<contexts>
<context position="831" citStr="Glickman et al., 2006" startWordPosition="111" endWordPosition="114">t Abstract This paper summarizes FBK-irst participation at the lexical substitution task of the SEMEVAL competition. We submitted two different systems, both exploiting synonym lists extracted from dictionaries. For each word to be substituted, the systems rank the associated synonym list according to a similarity metric based on Latent Semantic Analysis and to the occurrences in the Web 1T 5-gram corpus, respectively. In particular, the latter system achieves the state-of-the-art performance, largely surpassing the baseline proposed by the organizers. 1 Introduction The lexical substitution (Glickman et al., 2006a) can be regarded as a subtask of the lexical entailment, in which for a given word in context the system is asked to select an alternative word that can be replaced in that context preserving the meaning. Lexical Entailment, and in particular lexical reference (Glickman et al., 2006b)1, is in turn a subtask of textual entailment, which is formally defined as a relationship between a coherent text T and a language expression, the hypothesis H. T is said to entail H, denoted by T —* H, if the meaning of H can be inferred from the meaning of T (Dagan et al., 2005; Dagan and Glickman., 2004). Ev</context>
</contexts>
<marker>Glickman, Dagan, Keller, Bengio, Daelemans, 2006</marker>
<rawString>O. Glickman, I. Dagan, M. Keller, S. Bengio, and W. Daelemans. 2006a. Investigating lexical substitution scoring for subtitle generation tenth conference on computational natural language learning. In Proceedings of CoNLL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Glickman</author>
<author>E Shnarch</author>
<author>I Dagan</author>
</authors>
<title>Lexical reference: a semantic matching subtask.</title>
<date>2006</date>
<booktitle>In proceedings of EMNLP</booktitle>
<contexts>
<context position="831" citStr="Glickman et al., 2006" startWordPosition="111" endWordPosition="114">t Abstract This paper summarizes FBK-irst participation at the lexical substitution task of the SEMEVAL competition. We submitted two different systems, both exploiting synonym lists extracted from dictionaries. For each word to be substituted, the systems rank the associated synonym list according to a similarity metric based on Latent Semantic Analysis and to the occurrences in the Web 1T 5-gram corpus, respectively. In particular, the latter system achieves the state-of-the-art performance, largely surpassing the baseline proposed by the organizers. 1 Introduction The lexical substitution (Glickman et al., 2006a) can be regarded as a subtask of the lexical entailment, in which for a given word in context the system is asked to select an alternative word that can be replaced in that context preserving the meaning. Lexical Entailment, and in particular lexical reference (Glickman et al., 2006b)1, is in turn a subtask of textual entailment, which is formally defined as a relationship between a coherent text T and a language expression, the hypothesis H. T is said to entail H, denoted by T —* H, if the meaning of H can be inferred from the meaning of T (Dagan et al., 2005; Dagan and Glickman., 2004). Ev</context>
</contexts>
<marker>Glickman, Shnarch, Dagan, 2006</marker>
<rawString>O. Glickman, E. Shnarch, and I. Dagan. 2006b. Lexical reference: a semantic matching subtask. In proceedings of EMNLP 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gliozzo</author>
</authors>
<date>2005</date>
<booktitle>Semantic Domains in Computational Linguistics. Ph.D. thesis, ITC-irst/University of Trento.</booktitle>
<contexts>
<context position="6211" citStr="Gliozzo, 2005" startWordPosition="1006" endWordPosition="1007">. We exploited two corpora for our systems: the British National Corpus for acquiring the LSA space for ranking with domain proximity measure (Section 2.2) and the Web 1T 5-gram Version 1 corpus from Google (distributed by Linguistic Data Consortium)2 for ranking the proposed synonyms according to syntagmatic coherence (Section 2.3). 2Available from http://www.ldc.upenn.edu/Catalog/ CatalogEntry.jsp?catalogId=LDC2006T13. 2.2 Domain Proximity Semantic Domains are common areas of human discussion, such as Economics, Politics, Law (Magnini et al., 2002). Semantic Domains can be described by DMs (Gliozzo, 2005), by defining a set of term clusters, each representing a Semantic Domain, i.e. a set of terms having similar topics. A DM is represented by a k x k&apos; rectangular matrix D, containing the domain relevance for each term with respect to each domain. DMs can be acquired from texts by exploiting term clustering algorithms. The degree of association among terms and clusters, estimated by the learning algorithm, provides a domain relevance function. For our experiments we adopted a clustering strategy based on Latent Semantic Analysis (LSA) (Deerwester et al., 1990), following the methodology describ</context>
</contexts>
<marker>Gliozzo, 2005</marker>
<rawString>A. Gliozzo. 2005. Semantic Domains in Computational Linguistics. Ph.D. thesis, ITC-irst/University of Trento.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>C Strapparava</author>
<author>G Pezzulo</author>
<author>A Gliozzo</author>
</authors>
<title>The role of domain information in word sense disambiguation.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="6153" citStr="Magnini et al., 2002" startWordPosition="995" endWordPosition="998"> all the synonyms for all the word senses in both these resources. We exploited two corpora for our systems: the British National Corpus for acquiring the LSA space for ranking with domain proximity measure (Section 2.2) and the Web 1T 5-gram Version 1 corpus from Google (distributed by Linguistic Data Consortium)2 for ranking the proposed synonyms according to syntagmatic coherence (Section 2.3). 2Available from http://www.ldc.upenn.edu/Catalog/ CatalogEntry.jsp?catalogId=LDC2006T13. 2.2 Domain Proximity Semantic Domains are common areas of human discussion, such as Economics, Politics, Law (Magnini et al., 2002). Semantic Domains can be described by DMs (Gliozzo, 2005), by defining a set of term clusters, each representing a Semantic Domain, i.e. a set of terms having similar topics. A DM is represented by a k x k&apos; rectangular matrix D, containing the domain relevance for each term with respect to each domain. DMs can be acquired from texts by exploiting term clustering algorithms. The degree of association among terms and clusters, estimated by the learning algorithm, provides a domain relevance function. For our experiments we adopted a clustering strategy based on Latent Semantic Analysis (LSA) (D</context>
</contexts>
<marker>Magnini, Strapparava, Pezzulo, Gliozzo, 2002</marker>
<rawString>B. Magnini, C. Strapparava, G. Pezzulo, and A. Gliozzo. 2002. The role of domain information in word sense disambiguation. Natural Language Engineering, 8(4):359–373.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>