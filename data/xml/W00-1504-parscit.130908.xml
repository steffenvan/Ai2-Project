<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000208">
<title confidence="0.9490195">
A Modular Toolkit for Machine Translation Based on Layered
Charts
</title>
<author confidence="0.396762">
Jan W. Amtrup and Remi Zajac
</author>
<affiliation confidence="0.308393">
Computing Research Lab, New Mexico State University
</affiliation>
<email confidence="0.44154">
fjamtrup,zajaclOcrl.nmsu.edu
</email>
<sectionHeader confidence="0.985659" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997343125">
We present a freely available toolkit for building ma-
chine translation systems for a large variety of lan-
guages. The toolkit uses standard linguistic data
representation based on charts and typed feature
structures; A modular open architecture based on
standardized interfaces and processing architecture,
enabling the addition of external language process-
ing components and the configuration of new ap-
plications (plug-and-play); An open library of basic
parameterizable language processing components in-
cluding a morphological finite-state processor, dic-
tionary components, an island chart parser, chart
generator, and chart-based transfer engine (for MT
systems). It is open-source: the C++ source code is
available, and portable: targeted systems are Unix
and Windows systems.
</bodyText>
<sectionHeader confidence="0.998525" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999969434782609">
The MEAT&apos; machine translation toolkit was devel-
oped in order to significantly shorten the develop-
ment cycle for machine translation prototypes. In
addition, systems developed using the toolkit should
be robust and their performance (both qualitative
and quantitative) should be predictable. Finally,
basic components should be easily reconfigured or
modified to adapt to new applications or languages.
The toolkit is geared towards multilingual pro-
cessing and offers a well-founded uniform represen-
tation of all processing steps. Based on modern com-
putational linguistic concepts, the aim is to incorpo-
rate best practice in language engineering.
The toolkit uses throughout a standard linguistic
data representation based on charts to represent pro-
cessing results and typed feature structures to rep-
resent linguistic structures. The toolkit is based on
a modular open architecture that uses standardized
interfaces for processing components and a single
simple processing architecture. The architecture en-
ables the addition of external NLP processing com-
ponents and the configuration of new applications
(plug-and-play).
</bodyText>
<subsectionHeader confidence="0.468806">
&apos;Multilingual Architecture for Advanced Translation
</subsectionHeader>
<bodyText confidence="0.999835636363636">
The system includes an open library of basic pa-
rameterizable NLP components that include a mor-
phological finite-state processor, dictionary compo-
nents, an island chart parser, a generator, and a
transfer component. Complex components such as
the parser or the morphological analyzer are param-
eterized by using high-level declarative languages for
the linguist. The system has been implemented in
C++ and the source code is available. The system is
portable and currently exists in a Unix version and
a Windows version.
</bodyText>
<sectionHeader confidence="0.994694" genericHeader="introduction">
2 Representation
</sectionHeader>
<bodyText confidence="0.999985333333333">
The architecture is derived from previous work on
NLP architectures within the Tipster framework
(Zajac et al., 1997; Zajac, 1998; Steven Bird, 1999)
and combines ideas from early modular NLP sys-
tems such as Q-systems (Colmerauer, 1971) and
tree-transducers such as GRADE (Nakamura, 1984)
or ROBRA (Vauquois and Boitet, 1985), which pro-
vide the linguist which very flexible ways of decom-
posing a complex system into small building blocks
which can be developed, tested and executed one
by one. It uses a uniform central data structure
which is shared by all components of the system,
much like in blackboard systems (Boitet and Selig-
man, 1994), and incorporating ideas on chart-based
NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup,
1997; Amtrup and Weber, 1998; Amtrup, 1999; Za-
jac et al., 1999). All linguistic structures are en-
coded as Typed Features Structure and the associa-
tion of linguistic structures to the text is maintained
through the use of a Chart. The Chart itself is the
main processing data structure.
</bodyText>
<subsectionHeader confidence="0.959085">
2.1 Typed Feature Structures
</subsectionHeader>
<bodyText confidence="0.999964228571429">
A declarative, efficient and theoretically well-
founded formalism to describe linguistic objects is an
essential ingredient in any natural language process-
ing system. A uniform data structure that is used by
all components of a system offers several advantages
over the use of multiple description systems. In par-
ticular, it simplifies enormously communication be-
tween NLP modules. All linguistic information in
the system is encoded using Typed Feature Struc-
tures which is a versatile standard for representing
linguistic structures. Typed Feature Structures are
an extension of the traditional notion of linguistic
features (Kay, 1979; Ait-Kaci, 1986; Pollard and
Sag, 1987) and are used in all modern computational
linguistic frameworks (LFG, HPSG, etc.). The TFS
formalism also unifies object-oriented concepts and
theorem proving techniques. TFSs are declarative
with a sound logical semantics; they are associated
to a small set of logical operators and can benefit of
efficient implementations.
In the toolkit, the Typed Feature Structure sys-
tem uses a version where types define their appro-
priate features (and type of their values), see e.g.
Carpenter (1992). To improve the runtime behavior
of the system, no complex constraints are associated
to types as for example in the formalism presented
in Zajac (1992). Feature structures provide a sim-
ple, versatile and uniform way of describing linguis-
tic objects while a type system with appropriateness
ensures the validity of feature descriptions and in-
creases efficiency. Descriptions of words, syntactic
structures, as well as rules for the various compo-
nents can uniformly be coded as feature structures.
The use of types enforces a type discipline for linguis-
tic data: all legal linguistic structures are specified
as a set of type definitions. Therefore, one of the ini-
tial task of the linguist building a system using the
toolkit is to build and inventory of kinds of linguis-
tic structures built during processing and formalize
this inventory as a set of types and type definitions.
The type definitions will then be used (1) by vari-
ous compilers to compile (and type-check) linguistic
resources such as dictionaries or grammar rules, and
(2) at run-time by the various components accessing
and manipulating feature structures to ensure that
all feature structures created in the system are le-
gal (i.e., conform to the type definitions). The type
definitions themselves are compiled and the binary
file is used as a runtime parameter by the TFS C++
library.
The formalism we developed uses a consecutive
memory model for feature structures. Feature struc-
tures are stored as arrays of memory words rather
than having a representation relying on the use of
pointers. This is mainly done to reduce the pro-
cessing needed for input/output operations and also
targets at the distributed employment of a formal-
ism. Similar representations are used for implemen-
tations of formalisms oriented towards abstract ma-
chine operations (Carpenter and Qu, 1995; Wintner
and Francez, 1995). The formalism itself is imple-
mented as a set of C++ classes representing types
and feature structures. Apart from the usual opera-
tions for feature structures (subsumption and unifi-
cation), the system also provides an API to destruc-
tively manipulate feature structures, a property that
has to be used with care, but is extremely useful at
times. The efficiency of the implementation is satis-
factory and currently, we reach 4500 unifications per
second in a translation application.
</bodyText>
<equation confidence="0.998957307692308">
MainVerb[
exp : &amp;quot;sufrir&amp;quot;,
infl : InflMorph[
number : Singular,
tense : Past,
gender: Masculine,
mood : Participle],
lex : LexMorph[
subcat : Transitive],
trans : &lt;:
LSign[exp : &amp;quot;suffer&amp;quot;,
lex : LexMorph[
regular : True]]:&gt;]
</equation>
<subsectionHeader confidence="0.937144">
2.2 Charts
</subsectionHeader>
<bodyText confidence="0.998705411764706">
Charts are a standard for representing sets of em-
bedded linguistic structures (Hockett, 1958; Kay,
1973). They are also a versatile computational data
structure for parsing (text and speech), generation
and transfer (MT). A chart represents partial results
independently of processing strategies and process-
ing peculiarities (Kay, 1973; Sheil, 1976; Haruno et
al., 1993; Kay, 1999). Formally a directed, acyclic,
rooted graph, a chart can be viewed as a general-
ization of a well-formed substring table, capable not
only of representing complete constituents (&apos; inac-
tive edges&apos;), but also storing partial results (&apos;active
edges&apos;) (Sheil, 1976). The basic functions that op-
erate on a chart are very simple. Since chart-based
algorithms are almost always designed to be mono-
tonic2, a chart parser for example uses two main
rules to add edges to the chart:
</bodyText>
<listItem confidence="0.927052375">
• The Hypothesize rule takes an edge of the chart
and consults a grammar to propose new promis-
ing hypotheses that should be pursued;
• The Combination rule takes two edges, one of
them active, the other inactive, and tries to
combine them. If this combination succeeds,
a new edge is created and eventually inserted
into the chart.
</listItem>
<bodyText confidence="0.999378777777778">
The main advantage of formulating a natural lan-
guage processing task as a chart-based process is the
division of describing what has to be computed from
how the individual operations have to be carried out.
Kay (1980) calls the specification of a task that does
not specify search and processing strategies an al-
gorithm schema. In practice, one can experiment
with various dimensions of strategies, e.g. top down
vs. bottom up, left-to-right vs. right-to-left vs.
</bodyText>
<figure confidence="0.5065315">
2See Wiren (1992) for a notable exception.
Chart Structure
</figure>
<figureCaption confidence="0.999903">
Figure 1: A layered chart.
</figureCaption>
<bodyText confidence="0.980419708333334">
mixed strategies or depth first search vs. breadth
first search.
In our system, charts are layered. A layered chart
is modular and declarative representation of the data
manipulated by multiple processes. The traditional
chart structure, which stores linguistic information
on edges and where nodes represent a time-point in
the input stream, are augmented, following Tipster
ideas on &apos;annotations&apos;, with tags which define the
kind of content an edge bears, and with spans (pairs
of integers) pointing to a segment of the input stream
covered by the edge. Spans are used for example in
debugging and displaying a chart with edges posi-
tioned relative to the input text they cover. Tags
identify for example edges built by a tokenizer, mor-
phological analyzer, or a syntactic parser, and define
sub-graphs of the whole chart that are input to some
component. The chart is implemented as a C++
class which provides a set of methods to traverse
the graph and manipulate edges and their content.
By attaching tags to edges that define what kind of
content an edge bears, charts can be used to store in-
formation for more than one component. In this lay-
ered chart&apos; each component sees only the fraction of
information that it needs to operate on. Therefore,
the content of the chart gives a precise view of the
current state of operations within the system, and
interfaces between two modules become extremely
easy to implement, as the exchange of information
rests on a common concept, that of a chart edge.
At runtime, the chart is kept in memory and the
various components of an application work on the
same chart. Each component processes only a subset
of layers, typically only two: the input layer and
the output layer. For example, a parser will look at
morphological edges and produce syntactic edges.
3The type of chart we use here is a weaker version of the
layered charts defined in Amtrup and Weber (1998), as we do
not distribute the chart, and we don&apos;t use parallel processing
on the component side.
The chart is actually implemented as a lattice (di-
rected rooted acyclic graph) where nodes can be
time-aligned but where two time-aligned nodes are
not necessarily identical. In the general case, nodes
are partially ordered (with respect to time), and not
completely ordered as in the traditional chart. This
enables, the implementation of processes that create
a sequence of edges covering a single input edge:4
</bodyText>
<listItem confidence="0.956307">
• Normalization of contraction and elision phe-
nomena: English contraction don&apos;t expanded as
do not, or French elision du expanded as de le
for example.
• POS disambiguation: sequences such as
French la porte are ambiguous between de-
</listItem>
<bodyText confidence="0.997381">
terminer/pronoun and noun/verb. A dis-
ambiguation process would eliminate the in-
correct sequences determiner+verb and pro-
noun+noun, leaving only two valid sequences
determiner+noun and pronoun+verb, creating
2 additional distinct intermediary nodes in be-
tween the two words la porte.
</bodyText>
<listItem confidence="0.958383333333333">
• Chart generation, where an input edge results
in a sequence of sub-edges covered by the input
edge, but unrelated to other edges in the graph.
</listItem>
<sectionHeader confidence="0.765585" genericHeader="method">
3 Architecture
</sectionHeader>
<bodyText confidence="0.776976">
The toolkit is architectured around the following
three notions:
</bodyText>
<listItem confidence="0.999373333333333">
1. A module performs a complete elementary pro-
cessing step.
2. An application is defined as a sequence of mod-
ules.
3. A module is an instance of a component from
the component library.
</listItem>
<footnote confidence="0.997428">
4This also allows to represent directly the output of a
speech recognizer, a word lattice.
</footnote>
<figure confidence="0.99652476">
Ale Tags
Vertices
60
Edges
mu
Start pos
Set I
lz sh ITO Prs
63 66 69 73 77
Inc IY &apos;sdydy
04 90
Y1110 1st
96 1011 111
hyklry
Edge:
Content:
1:per.Rule.Sentence -
2:per.Rule.Sentence
3:per.Rule.Sentence
4:per.Rule.Sentence
5:per.Rule.Sentence
6:per.Rule.Sentence
7:per.Rule.Sentence
0:per.Rule.Sentence
9:per.Rule.Sentence
</figure>
<table confidence="0.950336411764706">
10 :per. Rule. Sentence
11 per. Rule. Sentence
12 per. Rule. Sentence
13 per. Rule. Sentence
14:per. Rule. Sentence
10 per. Rule. Sentence
ISYNTAX(63-96): 21§020L1 U øu 19.4U gf OU 2,0§U 0 000 0-u U
entence [
aEr es [ [ [ [Preposition [ [ [ [ [Nume r al] Nu]c&apos; ]NumP ] Spec [ Noun N&apos; ]NP o [ [ [Noun] N NP ]NP ] PP I X] EP 1 1 IN
un [Ad] e o tive ] A ] AP] N1NP o]NP Verb FOP ] S.&apos;,
herd: VerlsPhr as e
head Entry I
form . F orm [
morph Ve rbhorphology [
lex Ve rbalL exic al [
pro . Verb,
presentStem .y
regular . True],
inf 1 : Verb alInf lectiord
vo ice Undefined,
clitic . [
function Null]
tense Par ticlpial,
causatIve False,
person : Undefined,
mood Undefined,
numb erhgr e ement . Undefined.
p ar tic iple Pot,
ne gat,. on : Pals ]
oath Orthography]
crap &amp;quot;ylftn&amp;quot;]],
key
trans : EnaTranslationl
N
</table>
<figureCaption confidence="0.919708">
Figure 2: Viewing a complex analysis with the Chart Viewer.
</figureCaption>
<subsectionHeader confidence="0.990944">
3.1 Applications
</subsectionHeader>
<bodyText confidence="0.999972288888889">
An application is basically a sequence of modules.
The standard I/O for a module is a layered chart,
which is a global parameter for an application (spe-
cial modules can also deal with files). Another global
parameter for an application is the set of type defini-
tions specifying the set of legal linguistic structures
that can be stored on chart edges.
A working system (an application) can easily be
assembled from a set of components by writing a
resource file, called an application definition file.
This file uses a simple scripting language to de-
scribe instantiations of components, the calling se-
quence of components and various global variables
and parameters. Assembling components together
is done using a composition operator which behaves
much like the Unix pipe. When, in a Unix com-
mand, data between programs is transmitted using
files (stdin/stdout) and programs are combined us-
ing the pipe &apos; &apos; command, in M, the data transmit-
ted between components is a chart, and syntactically
the sequence of component is combined using the &apos;:&apos;
composition operator. In effect, the MEAT system
is a specialized shell for building NLP systems. The
implementation language is C++, but external com-
ponents can be integrated in the system by writing
wrappers (as done for several morphological analyz-
ers previously built or used at CRL).
An application definition file consists of three sec-
tions. (1) variable definitions reduce typing and en-
hance the transparency of application definition files.
(2) Application definitions specify the sequence of
modules that compose a given application. (3) Mod-
ule definitions define named building blocks for ap-
plications and the parameters that they receive dur-
ing a system run.
Variables provide symbolic names for long path
names and make it easy to switch configuration val-
ues that pertain to several modules. Once defined,
the variable name can be used instead of its value
throughout the application definition file. We sup-
port both variables defined in the application def-
inition as well as environment variables. Variable
definitions in an application definition file can refer
to other variables for their values. Typically, this is
used in contexts like this:
</bodyText>
<equation confidence="0.998739666666667">
$ROOT = /home/user/M
$SYNGRAM = $ROOT/per/SynGram.cbolero
$MORPHGRAM = $ROOT/per/Morph.samba
</equation>
<bodyText confidence="0.982420793103448">
Aside from variables that are defined inside an
application definition file and environment variables,
we also support command line variables which are
passed to the application.
Applications are defined as sequences of Modules
that have to be executed to achieve a certain task.
Each application is defined by its name together with
the names of modules that have to be processed in
turn:
application lookup =
Tok($ifile=$1):Morph:Dictionary:ChartSaver
This application would first perform tokenization.
The variable equation in the definition for the tok-
enizer specifies that the variable $if lie is set to the
value of the first command line parameter. Any ref-
erence to that variable for this particular execution
of the Tokenizer module would use the value given
by the user on the command line. This binding is
strictly local to the module for which it is defined.
After Tokenization, a number of other modules are
executed, including the morphological analyzer that
we described earlier.
Currently, we restrict the model of operation to
a sequence of modules without alternatives. We do
not support graphs of modules as a model for an ap-
plication. Thus, we do not support multi-threading
or otherwise concurrently executed modules. Appli-
cations can be executed using a shell command or
through a graphical interface (see below).
</bodyText>
<subsectionHeader confidence="0.997155">
3.2 Modules
</subsectionHeader>
<bodyText confidence="0.999874222222222">
Conceptually, a module performs a single linguis-
tic task on the data currently present in the chart.
Thus, a module would take some edges of the chart
as input data and provide new edges as output. In
some cases, however, a module may be executed for
its side effects. For instance, an input component
might read a file and produce edges.
A sample module definition (performing morpho-
logical analysis of Persian text) looks like this:
</bodyText>
<equation confidence="0.989705">
module MorphAnalyzer {
class = MorphAnalyzer
grammar = SRES/morph.samba
rule = Morphology
type = chart
sourceTag = TOKEN
targetTag = MATOKEN
</equation>
<bodyText confidence="0.99995241025641">
A module is an instance of a component from the
MEAT component library (a set of C++ classes).
Every module definition must specify at least one pa-
rameter, the name of the component (C++ class) of
which the module is an instance (parameter class).
By parameterizing the class representing the module
within the main program, the same component can
be used several times within one application. For
instance, there could be several parsers within one
application.
Additional parameters can be provided according
to the specifications of the module in question. In
the example above, the morphological grammar and
initial rule need to be specified, as well as the tags
that define the input and output sub-graphs of the
chart.
Parameters can also be defined as global and used
outside the scope of a module definition. In this
case, they are global and inherited by all modules
of an application. However, the local definition of
a parameter overrides the global behavior. Thus,
if one would define verbose = false on the global
level, and define it as being true for only a subset of
the components, then only those components would
issue logging messages.
In the current implementation, all modules are
linked in the main executable at compile time and
the model does not support distributed processing.
Although we have experimented with distributed ar-
chitectures (Zajac et al., 1997) in the past, the over-
head can be significant and the architecture must
be carefully designed to support the needs for dis-
tributed components while minimizing overhead. In
particular, a distributed architecture can be de-
signed to support either collaborative research (with
remote execution of components) or parallel process-
ing on the same text. The requirements are fairly
different and could be difficult to reconciliate within
a single model.
</bodyText>
<subsectionHeader confidence="0.997174">
3.3 Library
</subsectionHeader>
<bodyText confidence="0.999701142857143">
The toolkit includes libraries of approximately 30
processing components. Most of these components
perform simple tasks and are parameterized directly
in the application file. Some more complex compo-
nent have external parameters such as a unification-
based grammar or a dictionary file. The core library
include components that have a general use:
</bodyText>
<listItem confidence="0.9988686">
• Utilities: Unicode tokenizer; Store/Load charts
(for debugging)
• Dictionary: compiler; indexer; lookup (single
words, compounds).
• Morphology: wrappers; parameterized ana-
lyzer/generator.
• Parsing: modular bi-directional island parser.
• Generation: linearizer.
• Transfer: lexical transfer; morphological feature
transfer.
</listItem>
<bodyText confidence="0.998347724137931">
Each component is a C++ class that implements
a pre-defined interface. The core library can easily
be extended by creating a new class in the user li-
brary and linking to the other libraries at compile
time. User-defined components can be used in ap-
plications as if there were native components. At
runtime, the MEAT interpreter instantiates modules NounBarNoEzafe = per.Rule[
defined in the application file by creating an instance lhs: per.NounBar[
of the corresponding C++ class with the appropri- head: #head,
ate parameters as specified in the module definition boundary: per.NPtrue],
(in particular, an obligatory parameter is the set of rhs: &lt;:
types definitions defining legal feature structures). #head=per.NounOrNounCompound[
The module is executed by calling the run() method infl:
(which is implemented as part of the component in- [ezafe: per.EzFalse,
terface). indefEncl: False,
3.4 External Components clitic.function: per. Null]]
It is possible to integrate external software modules :&gt;
via special components that act as wrappers. For ex- island: #head
ample, the current implementation includes a mor- 1;
phological wrapper component that reads a file of Most of the language resource files are compiled
tokens in a standard format to build a chart which is before runtime and components load compact binary
then used for further processing. This wrapper has files instead of text source files. The toolkit provides
been used to integrate several morphological ana- compilers for the various formalisms and for dictio-
lyzers (Prolog for a Spanish morphological analyzer, naries; dictionaries are compiled as one data file and
Lisp for a Russian one, Java for a Serbo-Croatian, one or more index files (tries). Since all resources
and C for a Japanese and Korean). files use typed feature structures as the basic repre-
We are currently working on extending this mech- sentation formalism, all resource files include a set
anism to provide a more general wrapping mecha- of type definitions which is used by the compilers
nism that can work on any kind of input chart, and to create binary instances of feature structures (lin-
not only a linear sequence of (possibly ambiguous) ear arrays of integers), and by runtime components
tokens. Note that it is also relatively easy to develop to create in memory instances (using the same array
C++ components that implement wrappers commu- layout) or to print feature structure in a text format.
nicating with some software module with its API if The type definitions themselves are stored in a sep-
available. arate text file which must be itself compiled before
4 Linguistic Knowledge compilation of any other resource file. The type def-
All linguistic knowledge used by the components of inition file specifies the set of types used in a given
the core library (morphological analyzer and gener- application (type definitions are global to an appli-
ator, parser, generator, dictionary lookup, transfer) cation and are an obligory parameter to each of the
is defined in external resource files that parameterize components). A type definition defines super-types
the runtime components. For example, a unification or sub-types (inheritance hierarchy), and the set of
grammar used by the parser component is stored appropriate features for that type (and the types of
in a text file that contains the set of rules for that their values), not but complex type constraints as in
grammar. During the initialization phase at run- (Zajac, 1992) for example.
time, an instance of the parser component reads the 5 Development Environment
file containing the rules that will drive the parsing The development environment consist currently of
algorithm. Since both input and output of the parser two tools: the Chart Viewer and the application
are charts, it is possible to to create several parser Runner. The chart built by some application can
instances with different grammars and apply them be saved in a file at any point during processing for
in sequence on a chart (Zajac and Amtrup, 2000). further inspection. The chart can then be displayed
A rule is specified in the feature structure nota- using the Chart Viewer which allows the selective
tion and each syntactic element follows the general display of chart layers (by tags), and the selective
feature structure syntax. Although this makes it display of feature structures.
sometimes a little bit awkward, it allows to compile The MEAT Application Runner can be run from
rules as feature structures which are themselves com- the command line by passing to the MEAT inter-
piled as compact arrays of integers5 and enable very preter the application file, the name of the applica-
fast access of the rule at runtime (see for example tion to be executed and the application parameters:
(Wintner, 1997)). % meat -v app lookup test/docl.txt
There is also a graphical tool that allows to exe-
</bodyText>
<table confidence="0.975706166666667">
cute applications defined in an application file using
a graphical interface. This tool basically provides a
5 The unification algorithm operates on this data structure.
Arrays of integers can also be written or loaded from a file
very efficiently.
Ale Language
Recompile Source: fhomeiamtrup/mcmisrcfCRUlangfturi../..flatigfturicorpuslltsl-01.txt
i ABn4fakIlombalarsaTurkrye&apos; ye mallyet1 en az bIrrnelsr kad a
Everythng ararLk.Erlzek.nsmlylrdu J
I
Tango module III
I
Dictionary I III 11-.&gt;
Translation
Grammars I If USA bombs Irag to Turkey cost at least as las had wIll be
Run (Turkish) h avy Gras. struck economy p
Translate 1-....11
I ....,
Viewer System inessa
I
Sentences Select SynGen: Saze=768K, resadent=360K, total=768, CPU=0 050s
Executing Module Char tSayer
001 -01.txt her tSayer . Sine= OK, resident=0K, total=0, CPU=0. 010e
txl -02.txt Executing Module Surf Gen
txl -03.txt Surf acegenerator Starting
tx1-04.txt Surf aceGenerutor FInrshed
Surnen Saze=0K, reeldent=0K, total=0, 0511=0 000s
Total; SIze.52M, reszdent.40M, total. 99000, 1511=2. 3005 (cumul
txl -05.txt 1.1 tei
1—
</table>
<figureCaption confidence="0.991056">
Figure 3: Executing applications from the Runner.
</figureCaption>
<bodyText confidence="0.953649333333333">
graphical view of the application file and allows ex-
ecution of applications. (NB: this tool is still under
development).
</bodyText>
<sectionHeader confidence="0.997763" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999855117647059">
This toolkit has been used to develop a Persian-
English MT system; to port previously devel-
oped glossary-based MT systems and to develop
a Turkish-English MT system; and as the Ma-
chine Translation infrastructure of an elicitation-
based MT system. The architecture and the
core library is also used in new projects on
multilingual information extraction and multi-
lingual question-answering systems. Documenta-
tion, sources and binaries (Unix and Windows) avail-
able at http://crl.nmsu.edu/meat.
The toolkit is still under development as new com-
ponents are added to the core library and previous
components are enhanced or corrected. In the near
future, we plan to enhance the library with new
components for machine translation, including bet-
ter transfer and generation components.
</bodyText>
<sectionHeader confidence="0.996863" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9977728">
The MEAT system has been implemented by Jan
Amtrup and Mike Freider with contributions from
many other people at CRL.
This research has been funded in part by DoD,
Maryland Procurement Office, MDA904-96-C-1040.
</bodyText>
<sectionHeader confidence="0.990483" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.980204045045045">
Hassan AR-Kaci. 1986. An Algebraic Semantics Ap-
proach to the Effective Resolution of Type Equa-
tions. Theoretical Computer Science, 54:293-351.
Jan W. Amtrup and Volker Weber. 1998. Time
Mapping with Hypergraphs. In Proc. of the 17 th
COLING, Montreal, Canada.
Jan W. Amtrup. 1995. Chart-based Incremental
Transfer in Machine Translation. In Proceedings
of the Sixth International Conference on Theoret-
ical and Methodological Issues in Machine Trans-
lation, TMI &apos;95, pages 188-195, Leuven, Belgium,
July.
Jan W. Amtrup. 1997. Layered Charts for Speech
Translation. In Proceedings of the Seventh Inter-
national Conference on Theoretical and Method-
ological Issues in Machine Translation, TMI &apos;97,
Santa Fe, NM, July.
Jan W. Amtrup. 1999. Incremental Speech Transla-
tion. Number 1735 in Lecture Notes in Artificial
Intelligence. Springer Verlag, Berlin, Heidelberg,
New York.
Christian Boitet and Mark Seligman. 1994. The
&amp;quot;Whiteboard&amp;quot; Architecture: A Way to Integrate
Heterogeneous Components of NLP systems. In
COLING-94: The 15th International Conference
on Computational Linguistics, Kyoto, Japan.
Bob Carpenter and Yan Qu. 1995. An Abstract
Machine for Attribute-Value Logics. In Proceed-
ings of the 4th International Workshop on Pars-
ing Technologies (IWPT95), pages 59-70, Prague.
Charles University.
Bob Carpenter. 1992. The Logic of Typed Feature
Structures. Tracts in Theoretical Computer Sci-
ence. Cambridge University Press, Cambridge.
Alain Colmerauer. 1971. Les systemes-q: un for-
malisme pour analyser et synthetiser des phrases
sur ordinateur. Technical report, Groupe TAUM,
Universite de Montreal.
Masahiko Haruno, Yasuharu Den, Yuji Mastumoto,
and Makato Nagao. 1993. Bidirectional chart gen-
eration of natural language texts. In Proc. of
AAAI-93, pages 350-356.
C. F. Hockett. 1958. A course in modern linguistics.
Macmillan, New-York.
Martin Kay. 1973. The MIND System. In
R. Rustin, editor, Natural Language Processing,
pages 155-188. Algorithmic Press, New York.
Martin Kay. 1979. Functional grammar. In
C. Chiarelloet et al., editor, Proc. 5th Annual
Meeting of the Berekeley Linguistic Society, pages
142-158, Berkeley, CA.
Martin Kay. 1980. Algorithmic Schemata and Data
Structures in Syntactic Processing. Technical Re-
port CSL-80-12, Xerox Palo Alto Research Center,
Palo Alto, CA.
Martin Kay. 1996. Chart generation. In Proc. of
the 34 nd ACL, pages 200-204, Santa Cruz, CA,
June.
Martin Kay. 1999. Chart Translation. In Machine
Translation Summit VII, pages 9-14, Singapore.
Makoto Nagao Nakamura, J. Juni-Ichi Tsujii. 1984.
Grammar Writing System (GRADE) of Mu-
Machine Translation Projects and its Character-
istics. In Proc. of the 10 th COLING, Stanford,
CA.
Carl Pollard and Ivan A. Sag. 1987. Information-
based Syntax and Semantics. Vol 1: Fundamen-
tals. CSLI Lecture Notes 13, Stanford, CA.
B. A. Sheil. 1976. Observations on Context-Free
Parsing. Statistical Methods in Linguistics, 6:71-
109.
Mark Liberman Steven Bird. 1999. A Formal
Framework for Linguistic Annotation. Technical
Report MS-CIS-99-01, Dept of Computer and In-
formation Science, University of Pennsylvania.
Bernard Vauquois and Christian Boitet. 1985. Au-
tomated Translation at Grenoble University .
Computational Linguistics, 11(1):28-36.
Shuly Wintner and Nissim Francez. 1995. Abstract
Machine for Typed Feature Structures. In Pro-
ceedings of the 5th Workshop on Natural Language
Understanding and Logic Programming, Lisbon,
Spain.
Shuly Wintner. 1997. An Abstract Machine for Uni-
fication Grammars. Ph.D. thesis, Technion - Is-
rael Institute of Technology, Haifa, Israel, Jan-
uary.
Mats Wiren. 1992. Studies in Incremental Natural-
Language Analysis. Ph.D. thesis, Linkoping Uni-
versity, Linkoping, Sweden.
Remi Zajac and Jan W. Amtrup. 2000. Modular
Unification-Based Parsers. In Proc. Sixth Interna-
tional Workshop on Parsing Technologies, trento,
Italy, February.
Remi Zajac, Marc Casper, and Nigel Sharples. 1997.
An Open Distributed Architecture for Reuse and
Integration of Heterogeneous NLP Components.
In Proc. of the 5 th Conference on Applied Natural
Language Processing, Washington, D.C.
Remi Zajac, Malek Boualem, and Jan W. Amtrup.
1999. Specification and Implementation of In-
put Methods Using Finite-State Transducers.
In Fourteenth International Unicode Conference,
Boston, MA, March.
Remi Zajac. 1992. Inheritance and Constraint-
Based Grammar Formalisms. Computational Lin-
guistics, 18(2):159-182.
Remi Zajac. 1998. Annotation Management for
Large-Scale NLP. In ESSLLI-98 Workshop on
Recent Advances in Corpus Annotation, Saar-
bruken, Germany.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.944140">
<title confidence="0.9972715">A Modular Toolkit for Machine Translation Based on Layered Charts</title>
<author confidence="0.998919">Jan W Amtrup</author>
<author confidence="0.998919">Remi</author>
<affiliation confidence="0.972796">Computing Research Lab, New Mexico State</affiliation>
<email confidence="0.999821">fjamtrup,zajaclOcrl.nmsu.edu</email>
<abstract confidence="0.998553764705882">We present a freely available toolkit for building machine translation systems for a large variety of languages. The toolkit uses standard linguistic data representation based on charts and typed feature structures; A modular open architecture based on standardized interfaces and processing architecture, enabling the addition of external language processing components and the configuration of new applications (plug-and-play); An open library of basic parameterizable language processing components including a morphological finite-state processor, dictionary components, an island chart parser, chart generator, and chart-based transfer engine (for MT systems). It is open-source: the C++ source code is available, and portable: targeted systems are Unix and Windows systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hassan AR-Kaci</author>
</authors>
<title>An Algebraic Semantics Approach to the Effective Resolution of Type Equations.</title>
<date>1986</date>
<journal>Theoretical Computer Science,</journal>
<pages>54--293</pages>
<marker>AR-Kaci, 1986</marker>
<rawString>Hassan AR-Kaci. 1986. An Algebraic Semantics Approach to the Effective Resolution of Type Equations. Theoretical Computer Science, 54:293-351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan W Amtrup</author>
<author>Volker Weber</author>
</authors>
<title>Time Mapping with Hypergraphs.</title>
<date>1998</date>
<booktitle>In Proc. of the 17 th COLING,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="3450" citStr="Amtrup and Weber, 1998" startWordPosition="505" endWordPosition="508">ird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded as Typed Features Structure and the association of linguistic structures to the text is maintained through the use of a Chart. The Chart itself is the main processing data structure. 2.1 Typed Feature Structures A declarative, efficient and theoretically wellfounded formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that is used by all components of a system offers several advantages over the use of multiple description systems. In part</context>
<context position="11131" citStr="Amtrup and Weber (1998)" startWordPosition="1748" endWordPosition="1751">cise view of the current state of operations within the system, and interfaces between two modules become extremely easy to implement, as the exchange of information rests on a common concept, that of a chart edge. At runtime, the chart is kept in memory and the various components of an application work on the same chart. Each component processes only a subset of layers, typically only two: the input layer and the output layer. For example, a parser will look at morphological edges and produce syntactic edges. 3The type of chart we use here is a weaker version of the layered charts defined in Amtrup and Weber (1998), as we do not distribute the chart, and we don&apos;t use parallel processing on the component side. The chart is actually implemented as a lattice (directed rooted acyclic graph) where nodes can be time-aligned but where two time-aligned nodes are not necessarily identical. In the general case, nodes are partially ordered (with respect to time), and not completely ordered as in the traditional chart. This enables, the implementation of processes that create a sequence of edges covering a single input edge:4 • Normalization of contraction and elision phenomena: English contraction don&apos;t expanded a</context>
</contexts>
<marker>Amtrup, Weber, 1998</marker>
<rawString>Jan W. Amtrup and Volker Weber. 1998. Time Mapping with Hypergraphs. In Proc. of the 17 th COLING, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan W Amtrup</author>
</authors>
<title>Chart-based Incremental Transfer in Machine Translation.</title>
<date>1995</date>
<booktitle>In Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation, TMI &apos;95,</booktitle>
<pages>188--195</pages>
<location>Leuven, Belgium,</location>
<contexts>
<context position="3412" citStr="Amtrup, 1995" startWordPosition="501" endWordPosition="502"> 1997; Zajac, 1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded as Typed Features Structure and the association of linguistic structures to the text is maintained through the use of a Chart. The Chart itself is the main processing data structure. 2.1 Typed Feature Structures A declarative, efficient and theoretically wellfounded formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that is used by all components of a system offers several advantages over the use of</context>
</contexts>
<marker>Amtrup, 1995</marker>
<rawString>Jan W. Amtrup. 1995. Chart-based Incremental Transfer in Machine Translation. In Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation, TMI &apos;95, pages 188-195, Leuven, Belgium, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan W Amtrup</author>
</authors>
<title>Layered Charts for Speech Translation.</title>
<date>1997</date>
<booktitle>In Proceedings of the Seventh International Conference on Theoretical and Methodological Issues in Machine Translation, TMI &apos;97,</booktitle>
<location>Santa Fe, NM,</location>
<contexts>
<context position="3426" citStr="Amtrup, 1997" startWordPosition="503" endWordPosition="504">1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded as Typed Features Structure and the association of linguistic structures to the text is maintained through the use of a Chart. The Chart itself is the main processing data structure. 2.1 Typed Feature Structures A declarative, efficient and theoretically wellfounded formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that is used by all components of a system offers several advantages over the use of multiple desc</context>
</contexts>
<marker>Amtrup, 1997</marker>
<rawString>Jan W. Amtrup. 1997. Layered Charts for Speech Translation. In Proceedings of the Seventh International Conference on Theoretical and Methodological Issues in Machine Translation, TMI &apos;97, Santa Fe, NM, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan W Amtrup</author>
</authors>
<title>Incremental Speech Translation.</title>
<date>1999</date>
<journal>Number</journal>
<booktitle>in Lecture Notes in Artificial Intelligence.</booktitle>
<volume>1735</volume>
<publisher>Springer Verlag,</publisher>
<location>Berlin, Heidelberg, New York.</location>
<contexts>
<context position="3464" citStr="Amtrup, 1999" startWordPosition="509" endWordPosition="510">ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded as Typed Features Structure and the association of linguistic structures to the text is maintained through the use of a Chart. The Chart itself is the main processing data structure. 2.1 Typed Feature Structures A declarative, efficient and theoretically wellfounded formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that is used by all components of a system offers several advantages over the use of multiple description systems. In particular, it sim</context>
</contexts>
<marker>Amtrup, 1999</marker>
<rawString>Jan W. Amtrup. 1999. Incremental Speech Translation. Number 1735 in Lecture Notes in Artificial Intelligence. Springer Verlag, Berlin, Heidelberg, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Boitet</author>
<author>Mark Seligman</author>
</authors>
<title>The &amp;quot;Whiteboard&amp;quot; Architecture: A Way to Integrate Heterogeneous Components of NLP systems.</title>
<date>1994</date>
<booktitle>In COLING-94: The 15th International Conference on Computational Linguistics, Kyoto,</booktitle>
<contexts>
<context position="3332" citStr="Boitet and Seligman, 1994" startWordPosition="486" endWordPosition="490">is derived from previous work on NLP architectures within the Tipster framework (Zajac et al., 1997; Zajac, 1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded as Typed Features Structure and the association of linguistic structures to the text is maintained through the use of a Chart. The Chart itself is the main processing data structure. 2.1 Typed Feature Structures A declarative, efficient and theoretically wellfounded formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that</context>
</contexts>
<marker>Boitet, Seligman, 1994</marker>
<rawString>Christian Boitet and Mark Seligman. 1994. The &amp;quot;Whiteboard&amp;quot; Architecture: A Way to Integrate Heterogeneous Components of NLP systems. In COLING-94: The 15th International Conference on Computational Linguistics, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
<author>Yan Qu</author>
</authors>
<title>An Abstract Machine for Attribute-Value Logics.</title>
<date>1995</date>
<booktitle>In Proceedings of the 4th International Workshop on Parsing Technologies (IWPT95),</booktitle>
<pages>59--70</pages>
<publisher>Charles University.</publisher>
<location>Prague.</location>
<contexts>
<context position="6742" citStr="Carpenter and Qu, 1995" startWordPosition="1024" endWordPosition="1027">pe definitions). The type definitions themselves are compiled and the binary file is used as a runtime parameter by the TFS C++ library. The formalism we developed uses a consecutive memory model for feature structures. Feature structures are stored as arrays of memory words rather than having a representation relying on the use of pointers. This is mainly done to reduce the processing needed for input/output operations and also targets at the distributed employment of a formalism. Similar representations are used for implementations of formalisms oriented towards abstract machine operations (Carpenter and Qu, 1995; Wintner and Francez, 1995). The formalism itself is implemented as a set of C++ classes representing types and feature structures. Apart from the usual operations for feature structures (subsumption and unification), the system also provides an API to destructively manipulate feature structures, a property that has to be used with care, but is extremely useful at times. The efficiency of the implementation is satisfactory and currently, we reach 4500 unifications per second in a translation application. MainVerb[ exp : &amp;quot;sufrir&amp;quot;, infl : InflMorph[ number : Singular, tense : Past, gender: Masc</context>
</contexts>
<marker>Carpenter, Qu, 1995</marker>
<rawString>Bob Carpenter and Yan Qu. 1995. An Abstract Machine for Attribute-Value Logics. In Proceedings of the 4th International Workshop on Parsing Technologies (IWPT95), pages 59-70, Prague. Charles University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures. Tracts in Theoretical Computer Science.</title>
<date>1992</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="4903" citStr="Carpenter (1992)" startWordPosition="730" endWordPosition="731">ructures are an extension of the traditional notion of linguistic features (Kay, 1979; Ait-Kaci, 1986; Pollard and Sag, 1987) and are used in all modern computational linguistic frameworks (LFG, HPSG, etc.). The TFS formalism also unifies object-oriented concepts and theorem proving techniques. TFSs are declarative with a sound logical semantics; they are associated to a small set of logical operators and can benefit of efficient implementations. In the toolkit, the Typed Feature Structure system uses a version where types define their appropriate features (and type of their values), see e.g. Carpenter (1992). To improve the runtime behavior of the system, no complex constraints are associated to types as for example in the formalism presented in Zajac (1992). Feature structures provide a simple, versatile and uniform way of describing linguistic objects while a type system with appropriateness ensures the validity of feature descriptions and increases efficiency. Descriptions of words, syntactic structures, as well as rules for the various components can uniformly be coded as feature structures. The use of types enforces a type discipline for linguistic data: all legal linguistic structures are s</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Bob Carpenter. 1992. The Logic of Typed Feature Structures. Tracts in Theoretical Computer Science. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alain Colmerauer</author>
</authors>
<title>Les systemes-q: un formalisme pour analyser et synthetiser des phrases sur ordinateur.</title>
<date>1971</date>
<tech>Technical report, Groupe TAUM,</tech>
<institution>Universite de Montreal.</institution>
<contexts>
<context position="2925" citStr="Colmerauer, 1971" startWordPosition="421" endWordPosition="422">island chart parser, a generator, and a transfer component. Complex components such as the parser or the morphological analyzer are parameterized by using high-level declarative languages for the linguist. The system has been implemented in C++ and the source code is available. The system is portable and currently exists in a Unix version and a Windows version. 2 Representation The architecture is derived from previous work on NLP architectures within the Tipster framework (Zajac et al., 1997; Zajac, 1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded </context>
</contexts>
<marker>Colmerauer, 1971</marker>
<rawString>Alain Colmerauer. 1971. Les systemes-q: un formalisme pour analyser et synthetiser des phrases sur ordinateur. Technical report, Groupe TAUM, Universite de Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masahiko Haruno</author>
<author>Yasuharu Den</author>
<author>Yuji Mastumoto</author>
<author>Makato Nagao</author>
</authors>
<title>Bidirectional chart generation of natural language texts.</title>
<date>1993</date>
<booktitle>In Proc. of AAAI-93,</booktitle>
<pages>350--356</pages>
<contexts>
<context position="7856" citStr="Haruno et al., 1993" startWordPosition="1197" endWordPosition="1200">on application. MainVerb[ exp : &amp;quot;sufrir&amp;quot;, infl : InflMorph[ number : Singular, tense : Past, gender: Masculine, mood : Participle], lex : LexMorph[ subcat : Transitive], trans : &lt;: LSign[exp : &amp;quot;suffer&amp;quot;, lex : LexMorph[ regular : True]]:&gt;] 2.2 Charts Charts are a standard for representing sets of embedded linguistic structures (Hockett, 1958; Kay, 1973). They are also a versatile computational data structure for parsing (text and speech), generation and transfer (MT). A chart represents partial results independently of processing strategies and processing peculiarities (Kay, 1973; Sheil, 1976; Haruno et al., 1993; Kay, 1999). Formally a directed, acyclic, rooted graph, a chart can be viewed as a generalization of a well-formed substring table, capable not only of representing complete constituents (&apos; inactive edges&apos;), but also storing partial results (&apos;active edges&apos;) (Sheil, 1976). The basic functions that operate on a chart are very simple. Since chart-based algorithms are almost always designed to be monotonic2, a chart parser for example uses two main rules to add edges to the chart: • The Hypothesize rule takes an edge of the chart and consults a grammar to propose new promising hypotheses that sh</context>
</contexts>
<marker>Haruno, Den, Mastumoto, Nagao, 1993</marker>
<rawString>Masahiko Haruno, Yasuharu Den, Yuji Mastumoto, and Makato Nagao. 1993. Bidirectional chart generation of natural language texts. In Proc. of AAAI-93, pages 350-356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C F Hockett</author>
</authors>
<title>A course in modern linguistics.</title>
<date>1958</date>
<location>Macmillan, New-York.</location>
<contexts>
<context position="7579" citStr="Hockett, 1958" startWordPosition="1159" endWordPosition="1160">ystem also provides an API to destructively manipulate feature structures, a property that has to be used with care, but is extremely useful at times. The efficiency of the implementation is satisfactory and currently, we reach 4500 unifications per second in a translation application. MainVerb[ exp : &amp;quot;sufrir&amp;quot;, infl : InflMorph[ number : Singular, tense : Past, gender: Masculine, mood : Participle], lex : LexMorph[ subcat : Transitive], trans : &lt;: LSign[exp : &amp;quot;suffer&amp;quot;, lex : LexMorph[ regular : True]]:&gt;] 2.2 Charts Charts are a standard for representing sets of embedded linguistic structures (Hockett, 1958; Kay, 1973). They are also a versatile computational data structure for parsing (text and speech), generation and transfer (MT). A chart represents partial results independently of processing strategies and processing peculiarities (Kay, 1973; Sheil, 1976; Haruno et al., 1993; Kay, 1999). Formally a directed, acyclic, rooted graph, a chart can be viewed as a generalization of a well-formed substring table, capable not only of representing complete constituents (&apos; inactive edges&apos;), but also storing partial results (&apos;active edges&apos;) (Sheil, 1976). The basic functions that operate on a chart are </context>
</contexts>
<marker>Hockett, 1958</marker>
<rawString>C. F. Hockett. 1958. A course in modern linguistics. Macmillan, New-York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>The MIND System. In</title>
<date>1973</date>
<booktitle>Natural Language Processing,</booktitle>
<pages>155--188</pages>
<editor>R. Rustin, editor,</editor>
<publisher>Algorithmic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="3387" citStr="Kay, 1973" startWordPosition="497" endWordPosition="498">amework (Zajac et al., 1997; Zajac, 1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded as Typed Features Structure and the association of linguistic structures to the text is maintained through the use of a Chart. The Chart itself is the main processing data structure. 2.1 Typed Feature Structures A declarative, efficient and theoretically wellfounded formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that is used by all components of a system offers several a</context>
<context position="7591" citStr="Kay, 1973" startWordPosition="1161" endWordPosition="1162">ides an API to destructively manipulate feature structures, a property that has to be used with care, but is extremely useful at times. The efficiency of the implementation is satisfactory and currently, we reach 4500 unifications per second in a translation application. MainVerb[ exp : &amp;quot;sufrir&amp;quot;, infl : InflMorph[ number : Singular, tense : Past, gender: Masculine, mood : Participle], lex : LexMorph[ subcat : Transitive], trans : &lt;: LSign[exp : &amp;quot;suffer&amp;quot;, lex : LexMorph[ regular : True]]:&gt;] 2.2 Charts Charts are a standard for representing sets of embedded linguistic structures (Hockett, 1958; Kay, 1973). They are also a versatile computational data structure for parsing (text and speech), generation and transfer (MT). A chart represents partial results independently of processing strategies and processing peculiarities (Kay, 1973; Sheil, 1976; Haruno et al., 1993; Kay, 1999). Formally a directed, acyclic, rooted graph, a chart can be viewed as a generalization of a well-formed substring table, capable not only of representing complete constituents (&apos; inactive edges&apos;), but also storing partial results (&apos;active edges&apos;) (Sheil, 1976). The basic functions that operate on a chart are very simple.</context>
</contexts>
<marker>Kay, 1973</marker>
<rawString>Martin Kay. 1973. The MIND System. In R. Rustin, editor, Natural Language Processing, pages 155-188. Algorithmic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Functional grammar. In</title>
<date>1979</date>
<booktitle>Proc. 5th Annual Meeting of the Berekeley Linguistic Society,</booktitle>
<pages>142--158</pages>
<editor>C. Chiarelloet et al., editor,</editor>
<location>Berkeley, CA.</location>
<contexts>
<context position="4372" citStr="Kay, 1979" startWordPosition="649" endWordPosition="650">nd theoretically wellfounded formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that is used by all components of a system offers several advantages over the use of multiple description systems. In particular, it simplifies enormously communication between NLP modules. All linguistic information in the system is encoded using Typed Feature Structures which is a versatile standard for representing linguistic structures. Typed Feature Structures are an extension of the traditional notion of linguistic features (Kay, 1979; Ait-Kaci, 1986; Pollard and Sag, 1987) and are used in all modern computational linguistic frameworks (LFG, HPSG, etc.). The TFS formalism also unifies object-oriented concepts and theorem proving techniques. TFSs are declarative with a sound logical semantics; they are associated to a small set of logical operators and can benefit of efficient implementations. In the toolkit, the Typed Feature Structure system uses a version where types define their appropriate features (and type of their values), see e.g. Carpenter (1992). To improve the runtime behavior of the system, no complex constrain</context>
</contexts>
<marker>Kay, 1979</marker>
<rawString>Martin Kay. 1979. Functional grammar. In C. Chiarelloet et al., editor, Proc. 5th Annual Meeting of the Berekeley Linguistic Society, pages 142-158, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Algorithmic Schemata and Data Structures in Syntactic Processing.</title>
<date>1980</date>
<tech>Technical Report CSL-80-12,</tech>
<institution>Xerox Palo Alto Research Center,</institution>
<location>Palo Alto, CA.</location>
<contexts>
<context position="8889" citStr="Kay (1980)" startWordPosition="1374" endWordPosition="1375">r for example uses two main rules to add edges to the chart: • The Hypothesize rule takes an edge of the chart and consults a grammar to propose new promising hypotheses that should be pursued; • The Combination rule takes two edges, one of them active, the other inactive, and tries to combine them. If this combination succeeds, a new edge is created and eventually inserted into the chart. The main advantage of formulating a natural language processing task as a chart-based process is the division of describing what has to be computed from how the individual operations have to be carried out. Kay (1980) calls the specification of a task that does not specify search and processing strategies an algorithm schema. In practice, one can experiment with various dimensions of strategies, e.g. top down vs. bottom up, left-to-right vs. right-to-left vs. 2See Wiren (1992) for a notable exception. Chart Structure Figure 1: A layered chart. mixed strategies or depth first search vs. breadth first search. In our system, charts are layered. A layered chart is modular and declarative representation of the data manipulated by multiple processes. The traditional chart structure, which stores linguistic infor</context>
</contexts>
<marker>Kay, 1980</marker>
<rawString>Martin Kay. 1980. Algorithmic Schemata and Data Structures in Syntactic Processing. Technical Report CSL-80-12, Xerox Palo Alto Research Center, Palo Alto, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Chart generation.</title>
<date>1996</date>
<booktitle>In Proc. of the 34 nd ACL,</booktitle>
<pages>200--204</pages>
<location>Santa Cruz, CA,</location>
<contexts>
<context position="3398" citStr="Kay, 1996" startWordPosition="499" endWordPosition="500">jac et al., 1997; Zajac, 1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded as Typed Features Structure and the association of linguistic structures to the text is maintained through the use of a Chart. The Chart itself is the main processing data structure. 2.1 Typed Feature Structures A declarative, efficient and theoretically wellfounded formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that is used by all components of a system offers several advantages o</context>
</contexts>
<marker>Kay, 1996</marker>
<rawString>Martin Kay. 1996. Chart generation. In Proc. of the 34 nd ACL, pages 200-204, Santa Cruz, CA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Chart Translation.</title>
<date>1999</date>
<booktitle>In Machine Translation Summit VII,</booktitle>
<pages>9--14</pages>
<contexts>
<context position="7868" citStr="Kay, 1999" startWordPosition="1201" endWordPosition="1202">erb[ exp : &amp;quot;sufrir&amp;quot;, infl : InflMorph[ number : Singular, tense : Past, gender: Masculine, mood : Participle], lex : LexMorph[ subcat : Transitive], trans : &lt;: LSign[exp : &amp;quot;suffer&amp;quot;, lex : LexMorph[ regular : True]]:&gt;] 2.2 Charts Charts are a standard for representing sets of embedded linguistic structures (Hockett, 1958; Kay, 1973). They are also a versatile computational data structure for parsing (text and speech), generation and transfer (MT). A chart represents partial results independently of processing strategies and processing peculiarities (Kay, 1973; Sheil, 1976; Haruno et al., 1993; Kay, 1999). Formally a directed, acyclic, rooted graph, a chart can be viewed as a generalization of a well-formed substring table, capable not only of representing complete constituents (&apos; inactive edges&apos;), but also storing partial results (&apos;active edges&apos;) (Sheil, 1976). The basic functions that operate on a chart are very simple. Since chart-based algorithms are almost always designed to be monotonic2, a chart parser for example uses two main rules to add edges to the chart: • The Hypothesize rule takes an edge of the chart and consults a grammar to propose new promising hypotheses that should be purs</context>
</contexts>
<marker>Kay, 1999</marker>
<rawString>Martin Kay. 1999. Chart Translation. In Machine Translation Summit VII, pages 9-14, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Nagao Nakamura</author>
<author>J Juni-Ichi Tsujii</author>
</authors>
<title>Grammar Writing System (GRADE) of MuMachine Translation Projects and its Characteristics.</title>
<date>1984</date>
<booktitle>In Proc. of the 10 th COLING,</booktitle>
<location>Stanford, CA.</location>
<marker>Nakamura, Tsujii, 1984</marker>
<rawString>Makoto Nagao Nakamura, J. Juni-Ichi Tsujii. 1984. Grammar Writing System (GRADE) of MuMachine Translation Projects and its Characteristics. In Proc. of the 10 th COLING, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Informationbased Syntax and Semantics. Vol 1: Fundamentals.</title>
<date>1987</date>
<booktitle>CSLI Lecture Notes 13,</booktitle>
<location>Stanford, CA.</location>
<contexts>
<context position="4412" citStr="Pollard and Sag, 1987" startWordPosition="653" endWordPosition="656">d formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that is used by all components of a system offers several advantages over the use of multiple description systems. In particular, it simplifies enormously communication between NLP modules. All linguistic information in the system is encoded using Typed Feature Structures which is a versatile standard for representing linguistic structures. Typed Feature Structures are an extension of the traditional notion of linguistic features (Kay, 1979; Ait-Kaci, 1986; Pollard and Sag, 1987) and are used in all modern computational linguistic frameworks (LFG, HPSG, etc.). The TFS formalism also unifies object-oriented concepts and theorem proving techniques. TFSs are declarative with a sound logical semantics; they are associated to a small set of logical operators and can benefit of efficient implementations. In the toolkit, the Typed Feature Structure system uses a version where types define their appropriate features (and type of their values), see e.g. Carpenter (1992). To improve the runtime behavior of the system, no complex constraints are associated to types as for exampl</context>
</contexts>
<marker>Pollard, Sag, 1987</marker>
<rawString>Carl Pollard and Ivan A. Sag. 1987. Informationbased Syntax and Semantics. Vol 1: Fundamentals. CSLI Lecture Notes 13, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B A Sheil</author>
</authors>
<date>1976</date>
<booktitle>Observations on Context-Free Parsing. Statistical Methods in Linguistics,</booktitle>
<pages>6--71</pages>
<contexts>
<context position="7835" citStr="Sheil, 1976" startWordPosition="1195" endWordPosition="1196">n a translation application. MainVerb[ exp : &amp;quot;sufrir&amp;quot;, infl : InflMorph[ number : Singular, tense : Past, gender: Masculine, mood : Participle], lex : LexMorph[ subcat : Transitive], trans : &lt;: LSign[exp : &amp;quot;suffer&amp;quot;, lex : LexMorph[ regular : True]]:&gt;] 2.2 Charts Charts are a standard for representing sets of embedded linguistic structures (Hockett, 1958; Kay, 1973). They are also a versatile computational data structure for parsing (text and speech), generation and transfer (MT). A chart represents partial results independently of processing strategies and processing peculiarities (Kay, 1973; Sheil, 1976; Haruno et al., 1993; Kay, 1999). Formally a directed, acyclic, rooted graph, a chart can be viewed as a generalization of a well-formed substring table, capable not only of representing complete constituents (&apos; inactive edges&apos;), but also storing partial results (&apos;active edges&apos;) (Sheil, 1976). The basic functions that operate on a chart are very simple. Since chart-based algorithms are almost always designed to be monotonic2, a chart parser for example uses two main rules to add edges to the chart: • The Hypothesize rule takes an edge of the chart and consults a grammar to propose new promisi</context>
</contexts>
<marker>Sheil, 1976</marker>
<rawString>B. A. Sheil. 1976. Observations on Context-Free Parsing. Statistical Methods in Linguistics, 6:71-109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Liberman Steven Bird</author>
</authors>
<title>A Formal Framework for Linguistic Annotation.</title>
<date>1999</date>
<tech>Technical Report MS-CIS-99-01,</tech>
<institution>Dept of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="2838" citStr="Bird, 1999" startWordPosition="407" endWordPosition="408">s that include a morphological finite-state processor, dictionary components, an island chart parser, a generator, and a transfer component. Complex components such as the parser or the morphological analyzer are parameterized by using high-level declarative languages for the linguist. The system has been implemented in C++ and the source code is available. The system is portable and currently exists in a Unix version and a Windows version. 2 Representation The architecture is derived from previous work on NLP architectures within the Tipster framework (Zajac et al., 1997; Zajac, 1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and</context>
</contexts>
<marker>Bird, 1999</marker>
<rawString>Mark Liberman Steven Bird. 1999. A Formal Framework for Linguistic Annotation. Technical Report MS-CIS-99-01, Dept of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Vauquois</author>
<author>Christian Boitet</author>
</authors>
<title>Automated Translation at Grenoble University .</title>
<date>1985</date>
<journal>Computational Linguistics,</journal>
<pages>11--1</pages>
<contexts>
<context position="3014" citStr="Vauquois and Boitet, 1985" startWordPosition="432" endWordPosition="435">uch as the parser or the morphological analyzer are parameterized by using high-level declarative languages for the linguist. The system has been implemented in C++ and the source code is available. The system is portable and currently exists in a Unix version and a Windows version. 2 Representation The architecture is derived from previous work on NLP architectures within the Tipster framework (Zajac et al., 1997; Zajac, 1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded as Typed Features Structure and the association of linguistic structures to the text is m</context>
</contexts>
<marker>Vauquois, Boitet, 1985</marker>
<rawString>Bernard Vauquois and Christian Boitet. 1985. Automated Translation at Grenoble University . Computational Linguistics, 11(1):28-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuly Wintner</author>
<author>Nissim Francez</author>
</authors>
<title>Abstract Machine for Typed Feature Structures.</title>
<date>1995</date>
<booktitle>In Proceedings of the 5th Workshop on Natural Language Understanding and Logic Programming,</booktitle>
<location>Lisbon,</location>
<contexts>
<context position="6770" citStr="Wintner and Francez, 1995" startWordPosition="1028" endWordPosition="1031">e definitions themselves are compiled and the binary file is used as a runtime parameter by the TFS C++ library. The formalism we developed uses a consecutive memory model for feature structures. Feature structures are stored as arrays of memory words rather than having a representation relying on the use of pointers. This is mainly done to reduce the processing needed for input/output operations and also targets at the distributed employment of a formalism. Similar representations are used for implementations of formalisms oriented towards abstract machine operations (Carpenter and Qu, 1995; Wintner and Francez, 1995). The formalism itself is implemented as a set of C++ classes representing types and feature structures. Apart from the usual operations for feature structures (subsumption and unification), the system also provides an API to destructively manipulate feature structures, a property that has to be used with care, but is extremely useful at times. The efficiency of the implementation is satisfactory and currently, we reach 4500 unifications per second in a translation application. MainVerb[ exp : &amp;quot;sufrir&amp;quot;, infl : InflMorph[ number : Singular, tense : Past, gender: Masculine, mood : Participle], l</context>
</contexts>
<marker>Wintner, Francez, 1995</marker>
<rawString>Shuly Wintner and Nissim Francez. 1995. Abstract Machine for Typed Feature Structures. In Proceedings of the 5th Workshop on Natural Language Understanding and Logic Programming, Lisbon, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuly Wintner</author>
</authors>
<title>An Abstract Machine for Unification Grammars.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Technion - Israel Institute of Technology,</institution>
<location>Haifa, Israel,</location>
<contexts>
<context position="25398" citStr="Wintner, 1997" startWordPosition="4048" endWordPosition="4049">elective tion and each syntactic element follows the general display of chart layers (by tags), and the selective feature structure syntax. Although this makes it display of feature structures. sometimes a little bit awkward, it allows to compile The MEAT Application Runner can be run from rules as feature structures which are themselves com- the command line by passing to the MEAT interpiled as compact arrays of integers5 and enable very preter the application file, the name of the applicafast access of the rule at runtime (see for example tion to be executed and the application parameters: (Wintner, 1997)). % meat -v app lookup test/docl.txt There is also a graphical tool that allows to execute applications defined in an application file using a graphical interface. This tool basically provides a 5 The unification algorithm operates on this data structure. Arrays of integers can also be written or loaded from a file very efficiently. Ale Language Recompile Source: fhomeiamtrup/mcmisrcfCRUlangfturi../..flatigfturicorpuslltsl-01.txt i ABn4fakIlombalarsaTurkrye&apos; ye mallyet1 en az bIrrnelsr kad a Everythng ararLk.Erlzek.nsmlylrdu J I Tango module III I Dictionary I III 11-.&gt; Translation Grammars I</context>
</contexts>
<marker>Wintner, 1997</marker>
<rawString>Shuly Wintner. 1997. An Abstract Machine for Unification Grammars. Ph.D. thesis, Technion - Israel Institute of Technology, Haifa, Israel, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Wiren</author>
</authors>
<title>Studies in Incremental NaturalLanguage Analysis.</title>
<date>1992</date>
<tech>Ph.D. thesis,</tech>
<institution>Linkoping University, Linkoping, Sweden.</institution>
<contexts>
<context position="9153" citStr="Wiren (1992)" startWordPosition="1415" endWordPosition="1416">r inactive, and tries to combine them. If this combination succeeds, a new edge is created and eventually inserted into the chart. The main advantage of formulating a natural language processing task as a chart-based process is the division of describing what has to be computed from how the individual operations have to be carried out. Kay (1980) calls the specification of a task that does not specify search and processing strategies an algorithm schema. In practice, one can experiment with various dimensions of strategies, e.g. top down vs. bottom up, left-to-right vs. right-to-left vs. 2See Wiren (1992) for a notable exception. Chart Structure Figure 1: A layered chart. mixed strategies or depth first search vs. breadth first search. In our system, charts are layered. A layered chart is modular and declarative representation of the data manipulated by multiple processes. The traditional chart structure, which stores linguistic information on edges and where nodes represent a time-point in the input stream, are augmented, following Tipster ideas on &apos;annotations&apos;, with tags which define the kind of content an edge bears, and with spans (pairs of integers) pointing to a segment of the input str</context>
</contexts>
<marker>Wiren, 1992</marker>
<rawString>Mats Wiren. 1992. Studies in Incremental NaturalLanguage Analysis. Ph.D. thesis, Linkoping University, Linkoping, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi Zajac</author>
<author>Jan W Amtrup</author>
</authors>
<title>Modular Unification-Based Parsers. In</title>
<date>2000</date>
<booktitle>Proc. Sixth International Workshop on Parsing Technologies,</booktitle>
<location>trento, Italy,</location>
<contexts>
<context position="24638" citStr="Zajac and Amtrup, 2000" startWordPosition="3921" endWordPosition="3924">aints as in grammar. During the initialization phase at run- (Zajac, 1992) for example. time, an instance of the parser component reads the 5 Development Environment file containing the rules that will drive the parsing The development environment consist currently of algorithm. Since both input and output of the parser two tools: the Chart Viewer and the application are charts, it is possible to to create several parser Runner. The chart built by some application can instances with different grammars and apply them be saved in a file at any point during processing for in sequence on a chart (Zajac and Amtrup, 2000). further inspection. The chart can then be displayed A rule is specified in the feature structure nota- using the Chart Viewer which allows the selective tion and each syntactic element follows the general display of chart layers (by tags), and the selective feature structure syntax. Although this makes it display of feature structures. sometimes a little bit awkward, it allows to compile The MEAT Application Runner can be run from rules as feature structures which are themselves com- the command line by passing to the MEAT interpiled as compact arrays of integers5 and enable very preter the </context>
</contexts>
<marker>Zajac, Amtrup, 2000</marker>
<rawString>Remi Zajac and Jan W. Amtrup. 2000. Modular Unification-Based Parsers. In Proc. Sixth International Workshop on Parsing Technologies, trento, Italy, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi Zajac</author>
<author>Marc Casper</author>
<author>Nigel Sharples</author>
</authors>
<title>An Open Distributed Architecture for Reuse and Integration of Heterogeneous NLP Components.</title>
<date>1997</date>
<booktitle>In Proc. of the 5 th Conference on Applied Natural Language Processing,</booktitle>
<location>Washington, D.C.</location>
<contexts>
<context position="2805" citStr="Zajac et al., 1997" startWordPosition="400" endWordPosition="403">y of basic parameterizable NLP components that include a morphological finite-state processor, dictionary components, an island chart parser, a generator, and a transfer component. Complex components such as the parser or the morphological analyzer are parameterized by using high-level declarative languages for the linguist. The system has been implemented in C++ and the source code is available. The system is portable and currently exists in a Unix version and a Windows version. 2 Representation The architecture is derived from previous work on NLP architectures within the Tipster framework (Zajac et al., 1997; Zajac, 1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtru</context>
<context position="19464" citStr="Zajac et al., 1997" startWordPosition="3116" endWordPosition="3119">and used outside the scope of a module definition. In this case, they are global and inherited by all modules of an application. However, the local definition of a parameter overrides the global behavior. Thus, if one would define verbose = false on the global level, and define it as being true for only a subset of the components, then only those components would issue logging messages. In the current implementation, all modules are linked in the main executable at compile time and the model does not support distributed processing. Although we have experimented with distributed architectures (Zajac et al., 1997) in the past, the overhead can be significant and the architecture must be carefully designed to support the needs for distributed components while minimizing overhead. In particular, a distributed architecture can be designed to support either collaborative research (with remote execution of components) or parallel processing on the same text. The requirements are fairly different and could be difficult to reconciliate within a single model. 3.3 Library The toolkit includes libraries of approximately 30 processing components. Most of these components perform simple tasks and are parameterized</context>
</contexts>
<marker>Zajac, Casper, Sharples, 1997</marker>
<rawString>Remi Zajac, Marc Casper, and Nigel Sharples. 1997. An Open Distributed Architecture for Reuse and Integration of Heterogeneous NLP Components. In Proc. of the 5 th Conference on Applied Natural Language Processing, Washington, D.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi Zajac</author>
<author>Malek Boualem</author>
<author>Jan W Amtrup</author>
</authors>
<title>Specification and Implementation of Input Methods Using Finite-State Transducers.</title>
<date>1999</date>
<booktitle>In Fourteenth International Unicode Conference,</booktitle>
<location>Boston, MA,</location>
<contexts>
<context position="3485" citStr="Zajac et al., 1999" startWordPosition="511" endWordPosition="515">ly modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtrup, 1997; Amtrup and Weber, 1998; Amtrup, 1999; Zajac et al., 1999). All linguistic structures are encoded as Typed Features Structure and the association of linguistic structures to the text is maintained through the use of a Chart. The Chart itself is the main processing data structure. 2.1 Typed Feature Structures A declarative, efficient and theoretically wellfounded formalism to describe linguistic objects is an essential ingredient in any natural language processing system. A uniform data structure that is used by all components of a system offers several advantages over the use of multiple description systems. In particular, it simplifies enormously co</context>
</contexts>
<marker>Zajac, Boualem, Amtrup, 1999</marker>
<rawString>Remi Zajac, Malek Boualem, and Jan W. Amtrup. 1999. Specification and Implementation of Input Methods Using Finite-State Transducers. In Fourteenth International Unicode Conference, Boston, MA, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi Zajac</author>
</authors>
<title>Inheritance and ConstraintBased Grammar Formalisms.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--2</pages>
<contexts>
<context position="5056" citStr="Zajac (1992)" startWordPosition="755" endWordPosition="756">utational linguistic frameworks (LFG, HPSG, etc.). The TFS formalism also unifies object-oriented concepts and theorem proving techniques. TFSs are declarative with a sound logical semantics; they are associated to a small set of logical operators and can benefit of efficient implementations. In the toolkit, the Typed Feature Structure system uses a version where types define their appropriate features (and type of their values), see e.g. Carpenter (1992). To improve the runtime behavior of the system, no complex constraints are associated to types as for example in the formalism presented in Zajac (1992). Feature structures provide a simple, versatile and uniform way of describing linguistic objects while a type system with appropriateness ensures the validity of feature descriptions and increases efficiency. Descriptions of words, syntactic structures, as well as rules for the various components can uniformly be coded as feature structures. The use of types enforces a type discipline for linguistic data: all legal linguistic structures are specified as a set of type definitions. Therefore, one of the initial task of the linguist building a system using the toolkit is to build and inventory o</context>
<context position="24089" citStr="Zajac, 1992" startWordPosition="3832" endWordPosition="3833">s are global to an appliator, parser, generator, dictionary lookup, transfer) cation and are an obligory parameter to each of the is defined in external resource files that parameterize components). A type definition defines super-types the runtime components. For example, a unification or sub-types (inheritance hierarchy), and the set of grammar used by the parser component is stored appropriate features for that type (and the types of in a text file that contains the set of rules for that their values), not but complex type constraints as in grammar. During the initialization phase at run- (Zajac, 1992) for example. time, an instance of the parser component reads the 5 Development Environment file containing the rules that will drive the parsing The development environment consist currently of algorithm. Since both input and output of the parser two tools: the Chart Viewer and the application are charts, it is possible to to create several parser Runner. The chart built by some application can instances with different grammars and apply them be saved in a file at any point during processing for in sequence on a chart (Zajac and Amtrup, 2000). further inspection. The chart can then be display</context>
</contexts>
<marker>Zajac, 1992</marker>
<rawString>Remi Zajac. 1992. Inheritance and ConstraintBased Grammar Formalisms. Computational Linguistics, 18(2):159-182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi Zajac</author>
</authors>
<title>Annotation Management for Large-Scale NLP.</title>
<date>1998</date>
<booktitle>In ESSLLI-98 Workshop on Recent Advances in Corpus Annotation,</booktitle>
<location>Saarbruken, Germany.</location>
<contexts>
<context position="2818" citStr="Zajac, 1998" startWordPosition="404" endWordPosition="405">izable NLP components that include a morphological finite-state processor, dictionary components, an island chart parser, a generator, and a transfer component. Complex components such as the parser or the morphological analyzer are parameterized by using high-level declarative languages for the linguist. The system has been implemented in C++ and the source code is available. The system is portable and currently exists in a Unix version and a Windows version. 2 Representation The architecture is derived from previous work on NLP architectures within the Tipster framework (Zajac et al., 1997; Zajac, 1998; Steven Bird, 1999) and combines ideas from early modular NLP systems such as Q-systems (Colmerauer, 1971) and tree-transducers such as GRADE (Nakamura, 1984) or ROBRA (Vauquois and Boitet, 1985), which provide the linguist which very flexible ways of decomposing a complex system into small building blocks which can be developed, tested and executed one by one. It uses a uniform central data structure which is shared by all components of the system, much like in blackboard systems (Boitet and Seligman, 1994), and incorporating ideas on chart-based NLP (Kay, 1973; Kay, 1996; Amtrup, 1995; Amtr</context>
</contexts>
<marker>Zajac, 1998</marker>
<rawString>Remi Zajac. 1998. Annotation Management for Large-Scale NLP. In ESSLLI-98 Workshop on Recent Advances in Corpus Annotation, Saarbruken, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>