<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000020">
<title confidence="0.98168">
Learning Tense Translation from Bilingual Corpora
</title>
<author confidence="0.932541">
Michael Schiehlen*
</author>
<affiliation confidence="0.816647">
Institute for Computational Linguistics, University of Stuttgart,
</affiliation>
<address confidence="0.548155">
Azenbergstr. 12, 70174 Stuttgart
</address>
<email confidence="0.933487">
mike@adler.ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.996695" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999959333333333">
This paper studies and evaluates disambigua-
tion strategies for the translation of tense be-
tween German and English, using a bilingual
corpus of appointment scheduling dialogues. It
describes a scheme to detect complex verb pred-
icates based on verb form subcategorization and
grammatical knowledge. The extracted verb
and tense information is presented and the role
of different context factors is discussed.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998159677419355">
A problem for translation is its context depen-
dence. For every ambiguous word, the part of
the context relevant for disambiguation must be
identified (disambiguation strategy), and every
word potentially occurring in this context must
be assigned a bias for the translation decision
(disambiguation information). Manual con-
struction of disambiguation components is quite
a chore. Fortunately, the task can be (partly)
automated if the tables associating words with
biases are learned from a corpus. Statistical
approaches also support empirical evaluation of
different disambiguation strategies.
The paper studies disambiguation strategies
for tense translation between German and En-
glish. The experiments are based on a corpus
of appointment scheduling dialogues counting
150,281 German and 154,773 English word to-
kens aligned in 16,857 turns. The dialogues were
recorded, transcribed and translated in the Ger-
man national Verbmobil project that aims to
develop a tri-lingual spoken language transla-
tion system. Tense is interesting, since it oc-
curs in nearly every sentence. Tense can be ex-
This work was funded by the German Federal Min-
istry of Education, Science, Research and Technology
(BMBF) in the framework of the Verbmobil Project un-
der Grant 01 IV 101 U. Many thanks are due to G. Car-
roll, M. Emele, U. Heid and the colleagues in Verbmobil.
pressed on the surface lexically as well as mor-
phosyntactically (analytic tenses).
</bodyText>
<sectionHeader confidence="0.980699" genericHeader="method">
2 Words Are Not Enough
</sectionHeader>
<bodyText confidence="0.9161405">
Often, sentence meaning is not compositional
but arises from combinations of words (1).
</bodyText>
<figure confidence="0.851372">
(1) a. Ich habe ihn gestern gesehen.
I have him yesterday seen
I saw him yesterday.
b. Ich schlage Montag vor.
I beat Monday forward
I suggest Monday.
</figure>
<bodyText confidence="0.910106538461538">
c. Ich mochte mich beschweren.
I &apos;d like to myself weigh down
I&apos;d like to make a complaint.
For translation, the discontinuous words must
be amalgamated into single semantic items.
Single words or pairs of lemma and part of
speech tag (L-POS pairs) are not appropriate.
To verify this claim, we aligned the L-POS pairs
of the Verbmobil corpus using the completely
language-independent method of Dagan et
al. (1993). Below find the results for seheni
(see) in order of frequency and some frequent
alignments for reflexive pronouns.
</bodyText>
<table confidence="0.85345775">
72 sehen:VVFIN be:VBZ (aussehen)
44 sehen:VVFIN do:VBP (do-support)
39 sehen:VVFIN have:VBP (perfect)
35 sehen:VVFIN see:VB
</table>
<listItem confidence="0.811227666666667">
176 wir:PRF meet:VB (sich treffen)
33 wir:PRF we:PP
30 sich:PRF spell:VBN (sich schreiben)
16 ich:PRF forward:RP (sich freuen auf)
14 wir:PRF agree:VB (sich einigen)
13 ich:PRF myself:PP
</listItem>
<footnote confidence="0.998133333333333">
1The prefix verb aus-sehen (look, be) is very frequent
in the corpus, it often occurs in questions. Present sehen
was frequently translated into perfect discover.
</footnote>
<page confidence="0.990542">
1183
</page>
<sectionHeader confidence="0.99051" genericHeader="method">
3 Partial Parsing
</sectionHeader>
<bodyText confidence="0.99989675">
A full syntactic analysis of the sort of unre-
stricted spoken language text found in the Verb-
mobil corpus is still beyond reach. Hence, we
took a partial parsing approach.
</bodyText>
<subsectionHeader confidence="0.998971">
3.1 Complex Verb Predicates
</subsectionHeader>
<bodyText confidence="0.999046">
Both German and English exhibit complex verb
predicates (CVPs), see (2). Every verb and verb
particle belongs to such a CVP and there is only
one CVP per clause.
</bodyText>
<listItem confidence="0.75175">
(2) He would not have called me up.
</listItem>
<bodyText confidence="0.9997552">
The following two grammar fragments describe
the relevant CVP syntax for English and Ger-
man. Every auxiliary verb governs only one
verb, so the CVP grammar is basically2 regu-
lar and implementable with finite-state devices.
</bodyText>
<equation confidence="0.991688875">
S —&gt; ... VP ...
VP hd:V (to) VP
VP —&gt; hd:V ... (Particle)
S hd:Vfin (Refl) ... VC ...
S (Refl) ... VC ...
S ... VC hd:Vfin (Refl)
VC —&gt; (VC) (zu) hd:V
VC SeparatedVerbPrefix
</equation>
<bodyText confidence="0.834352">
English CVPs are left-headed, while German
CVPs are partly left-, partly right-headed.
</bodyText>
<sectionHeader confidence="0.292137" genericHeader="method">
, CVP
</sectionHeader>
<footnote confidence="0.91152825">
2The grammar does not handle insertion of CVPs into
other CVPs and partially fronted verb complexes (3).
(3) Versuchen hatte ich es schon gerne wollen.
try &apos;d have I it liked to
</footnote>
<bodyText confidence="0.680794">
I&apos;d have liked to try it.
</bodyText>
<subsectionHeader confidence="0.99389">
3.2 Verb Form Subcategorization
</subsectionHeader>
<bodyText confidence="0.999951">
Auxiliary verbs form a closed class. Thus, the
set sub(v) of infinite verb forms for which an
auxiliary verb v subcategorizes can be specified
by hand. English and German auxiliary verbs
govern the following verb forms.
</bodyText>
<listItem confidence="0.999658909090909">
• infinitive e.g. will
• to-infinitive (T) e.g. want
• past participle (P) e.g. get
• P V T e.g. have
• present participle VPVT e.g. be
• infinitive (I) e.g. miissen
• zu-infinitive (Z) e.g. scheinen
• perf.part. with haben (H) e.g. bekommen
•HVI e.g. werden
•HVIVZ e.g. haben
• perf. part. with seinVHVIVZ e.g.sein
</listItem>
<subsectionHeader confidence="0.551911">
3.3 Transducers
</subsectionHeader>
<bodyText confidence="0.999558111111111">
Two partial parsers (rather: transducers) are
used to detect English and German CVPs
and to translate them into predicate argument
structures (verb chains). The parsers presup-
pose POS tagging and lemmatization. A data
base associates verbs v with sets mor(v) of pos-
sible tenses or infinite verb forms.
Let m = Ilmor(v) : Verb v11 and n = I{.sub(v) :
Verb v }I. Then the English CVP parser needs
n + 1 states to encode which verb forms, if
any, are expected by a preceding auxiliary verb.
Verb particles are attached to the preceding
verb. The German CVP parser is more compli-
cated, but also more restrictive as all verbs in
a verb complex (VC) must be adjacent. It op-
erates in left-headed (S) or right-headed mode
(VC). In VC-mode (i.e. inside VCs) the order
of the verbs put on the output tape is reversed.
In S-mode, n + 1 states again record the verb
form expected by a preceding finite verb Vfin.
VC-mode is entered when an infinite verb form
is encountered. A state in VC-mode records the
verb form expected by Vfin (n + 1), the infinite
verb form of the last verb encountered (m), and
the verb form expected by the VC verb, if the
VC consists of only one verb (n + 1). So there
are m* (n +1)2 states. As soon as a non-verb is
encountered in VC-mode or the verb form of the
previous verb does not fit the subcategorization
requirements of the current verb, a test is per-
formed to see if the verb form of the last verb
He will have to have done it.
Er wird es
he will it
getan haben mhssen
done have must
</bodyText>
<page confidence="0.982086">
1184
</page>
<figureCaption confidence="0.999792">
Figure 1: translation frequencies G--4E (left: simple tenses, right: progressive tenses)
</figureCaption>
<figure confidence="0.999891918367347">
100000
10000
1000
100
10
past perfect -*—
past
future past
present perfect --4(
present
future perfect -e--
future
\
1
0
pluperf . preterite perfect
present future
100000
10000
1000
100
10
1
past perfect -*—
past
future past rAs.,
present perfect -4(
present /
future perfect -*-7&apos;
_ future --y--
-----
\
2: • &amp;quot;
•
pluperf . preterite perfect present future
100000
10000
1000
100
10
1
0
Pas tPer f (prog)
pluperfect - &lt;&gt;-
preterite -4--
perfect -0-
present -4---
future-a---
Past
</figure>
<figureCaption confidence="0.792918">
(prog) FutPast PresPf (prog) Present (prog) FutPerf Future (prog)
Figure 2: translation frequencies
</figureCaption>
<bodyText confidence="0.99872225">
in VC fits the verb form required by Vfin. If it
does or there is no such finite verb, one CVP has
been detected. Else Vfin forms a separate CVP.
In case the VC consists of only one verb that
can be interpreted as finite, the expected verb
form is recorded in a new S-mode state. Sep-
arated verb prefixes are attached to the finite
verb, first in the chain.
</bodyText>
<subsectionHeader confidence="0.974834">
3.4 Alignment
</subsectionHeader>
<bodyText confidence="0.999975363636364">
In the CVP alignment, only 78 % of the turns
proved to have CVPs on both sides, only 19 %
had more than one CVP on some side. CVPs
were further aligned by maximizing the trans-
lation probability of the full verbs (yielding
16,575 CVP pairs). To ensure correctness, turns
with multiple CVPs were inspected by hand.
In word alignment inside CVPs, surplus tense-
bearing auxiliary verbs were aligned with a
tense-marked NULL auxiliary (similar to the
English auxiliary do).
</bodyText>
<subsectionHeader confidence="0.994888">
3.5 Alignment Results
</subsectionHeader>
<bodyText confidence="0.999933166666667">
The domain biases the corpus towards the fu-
ture. So only 5 out of 6 German tenses and
12 out of 16 English tenses occurred in the cor-
pus. Both will and be going to were analysed as
future, while would was taken to indicate con-
ditional mood, hence present.
</bodyText>
<listItem confidence="0.999878">
• present (15,710) • perfect (344)
• preterite (331) • pluperfect (49)
• future (150)
</listItem>
<page confidence="0.885606">
1185
</page>
<listItem confidence="0.999466666666667">
• present (12,252; progressive: 358)
• past (594; progressive: 23)
• present perfect (227; progressive: 7)
• past perfect (1; progressive: 1)
• future (1,429; progressive: 23)
• future perfect (10) • future in the past (3)
</listItem>
<bodyText confidence="0.9810656">
In some cases, tense was ambiguous when con-
sidered in isolation, and had to be resolved
in tandem with tense translation. Ambiguous
tenses on the target side were disambiguated to
fit the particular disambiguation strategy.
</bodyText>
<listItem confidence="0.99756025">
• G present/perfect (verreist sein) (39)
• G present/past (sollte, ging) (229)
• E pres./present perfect (have got) (500)
• E pres./past (should, could, must) (1,218)
</listItem>
<sectionHeader confidence="0.995317" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999962375">
Formally, we define source tense and target
tense as two random variables S and T. Disam-
biguation strategies are modeled as functions tr
from source to target tense. Precision figures
give the proportion of source tense tokens t,
that the strategy correctly translates to target
tense tt, recall gives the proportion of source-
target tense pairs that the strategy finds out.
</bodyText>
<equation confidence="0.9956575">
(4) precisiontr(ts, tt) =
P(T = tti S = ts, tr (ts) = tt)
recalltr(ts , tt) =
P (tr (ts) = ttl S = t, , T = tt)
</equation>
<bodyText confidence="0.999956">
Combined precision and recall values are formed
by taking the sum of the frequencies in numer-
ator and denominator for all source and target
tenses. Performance was cross-validated with
test sets of 10 % of all CVP pairs.
</bodyText>
<subsectionHeader confidence="0.993993">
4.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999947714285714">
A baseline strategy assigns to every source
tense the most likely target tense (tr(ts) =
arg maxt,P(ttlts), strategy t). The most likely
target tenses can be read off Figures 1 and 2.
Past tenses rarely denote logical past, as dis-
cussion circles around a future meeting event,
they are rather used for politeness.
</bodyText>
<listItem confidence="0.656845">
(5) a. Ich wollte Sie fragen, wie das aussieht.
</listItem>
<bodyText confidence="0.901584">
I wanted to ask you what is on.
b. Ubermorgen war ich ja auf diesem Kon-
gra in Zurich.
the day after tomorrow, I&apos;ll be (lit: was)
at this conference in Zurich.
</bodyText>
<subsectionHeader confidence="0.998152">
4.2 Full Verb Information
</subsectionHeader>
<bodyText confidence="0.99864675">
Three more disambiguation strategies condi-
tion the choice of tense on the full verb in
a CVP, viz, the source verb (tr (t , v5) =
arg maxt,P(tt Its, vs), strategy vs), the target
verb (tr (t , vt), strategy Vt), and the combina-
tion of source and target verb (tr(ts, (vs, Vt)),
strategy Vst). The table below gives preci-
sion and recall values for these strategies and
for the strategies obtained by smoothing (e.g.
vst, vs, Vt, t is vst smoothed first with vs, then
with Vt, and finally with t). Smoothing with t
results in identical precision and recall figures.
</bodyText>
<table confidence="0.997244875">
G-4E E-4G
prec. recall , t prec. recall , t
.865 .865 .865 .957 .957 .957
Vs .885 .854 .879 .970 .941 .965
Vt .900 .876 .896 .973 .933 .966
Vst .916 .819 .899 .979 .874 .965
Vst, Vt, Vs .902 .892 .900 .970 .956 .967
Vst, vs, Vt .899 .889 .897 .971 .957 .967
</table>
<bodyText confidence="0.999507">
We see that inclusion of verb information im-
proves performance. Translation pairs approx-
imate the verb semantics better than single
source or target verbs. The full verb contexts of
tenses can also be used for verb classifications.
Aspectual classification: The aspect of a
verb often depends on its reading and thus can
be better extrapolated from an aligned corpus
(e.g. I am having a drink (trinken)). German
allows punctual events in the present, English
prefers present perfect (e.g. sehen, finden, fest-
stellen(discover, find, see); em fallen (occur, re-
member); treffen, erwischen, sehen (meet)).
World knowledge: In many cases perfect
maps an event to its result state.
finish fertig sein
forget nicht mehr wissen
denken an have in mind
sich verabreden have an appointment
sich vertun be wrong
settle a question (the question) is settled
</bodyText>
<subsectionHeader confidence="0.999247">
4.3 Subordinating Conjunctions
</subsectionHeader>
<bodyText confidence="0.978326">
Conjunctions often engender different mood.
</bodyText>
<listItem confidence="0.76382425">
• In conditional clauses English past tenses usu-
ally denote present tenses. Interpreting hypo-
thetical past as present increases performance
by about 0.3 %.
</listItem>
<page confidence="0.944549">
1186
</page>
<listItem confidence="0.774087875">
• In subjunctive environments logical future is
expressed by English simple present. The verbs
vorschlagen (suggest) (in 11 out of 14 cases) and
sagen (say) (2/5) force simple present on verbs
that normally prefer a translation to future.
(6) I suggest that we meet on the tenth.
• Certain matrix verbs3 trigger translation of
German present to English future.
</listItem>
<subsectionHeader confidence="0.998368">
4.4 Representation of Tense
</subsectionHeader>
<bodyText confidence="0.987154">
Tense can not only be viewed as a single item
(as sketched above, representation rt). In com-
positional analyses of tense, source tense S and
target tense T are decomposed into compo-
nents (S1, ,S) and (T1, ,T). A disam-
biguation strategy tr is correct if Vi : tr(S,) =
T,.
One decomposition is suggested by the en-
coding of tense on the surface ((present/past,
0/ will/ be going to/ werden, 01 havel habenl sein,
</bodyText>
<table confidence="0.56568925">
0/ be), representation rs). Another widely
used framework in tense analysis (Reichenbach,
1947) ((E&lt;/r----/&gt;R, ±progr), repre-
sentation rr) analyses English tenses as follows:
RS R&lt;S R&gt;S
ER present past
E&lt;R present perf. past perf. fut. perf.
E&gt;R future future past
</table>
<bodyText confidence="0.99810225">
A similar classification can be used for German
except that present and perfect are analysed as
ambiguous between present and future (E&gt;R2--S
and E&lt;R&gt;S).
</bodyText>
<table confidence="0.967627727272728">
repr. strat. G-*E E-4G
prec. recall ,t prec. recall ,t
rt t .865 .865 .865 .957 .957 .957
7.5 t .859 .859 .859 .955 .955 .955
T., vs .883 .853 .876 .966 .938 .961
T., vt .894 .871 .890 .971 .933 .964
T., vst .912 .815 .894 .978 .874 .962
Tr t .861 .861 .861 .964 .964 .964
rr vs .885 .855 .879 .973 .945 .970
rr vt .898 .875 .894 .977 .939 .972
r, vst .915 .817 .897 .982 .878 .970
</table>
<bodyText confidence="0.9992692">
The poor performance of strategy 7-5 corrob-
orates the expectation that tense disambigua-
tion is helped by recognition of analytic tenses.
Strategy r, performs slightly worse than rt. The
really hard step with Reichenbach seems to be
</bodyText>
<footnote confidence="0.6148675">
3ausgehen von, denken, meinen (think), hoffen
(hope), schade sein (be a pity)
</footnote>
<bodyText confidence="0.974615">
the mapping from surface tense to abstract rep-
resentation (e.g. deciding if (polite) past is
mapped to logical present or past). r,. per-
forms slightly better in E-&gt;G, since the burden
of choosing surface tense is shifted to genera-
tion.
repr. strat. G-4E E--+G
prec. recall , t prec. recall , t
.861 .861 .861 .957 .957 .957
re vs .883 .853 .877 .968 .940 .963
re vt .895 .872 .891 .971 .933 .965
re vst .913 .816 .895 .979 .875 .964
</bodyText>
<sectionHeader confidence="0.99919" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999989">
The paper presents a way to test disambigua-
tion strategies on real data and to measure the
influence of diverse factors ranging from sen-
tence internal context to the choice of represen-
tation. The pertaining disambiguation informa-
tion learned from the corpus is put into action
in the symbolic transfer component of the Verb-
mobil system (Dorna and Emele, 1996).
The only other empirical study of tense transla-
tion (Santos, 1994) I am aware of was conducted
on a manually annotated Portuguese-English
corpus (48,607 English, 43,492 Portuguese word
tokens and 6,334 tense translation pairs). It nei-
ther gives results for all tenses nor considers dis-
ambiguation factors. Still, it acknowledges the
surprising divergence of tense across languages
and argues against the widely held belief that
surface tenses can be mapped directly into an
interlingual representation. Although the find-
ings reported here support this conclusion, it
should be noted that a bilingual corpus can only
give one of several possible translations.
</bodyText>
<sectionHeader confidence="0.999409" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999240714285714">
Ido Dagan, Kenneth W. Church, and William A.
Gale. 1993. Robust Bilingual Word Alignment for
Machine-Aided Translation. In Proceedings of the
Workshop on Very Large Corpora: Academic and
Industrial Perspectives, pages 1-8.
Michael Dorna and Martin C. Emele. 1996.
Semantic-Based Transfer. In Proceedings of the 16th
International Conference on Computational Lin-
guistics (COLING &apos;96), Copenhagen, Denmark.
Hans Reichenbach. 1947. Elements of Symbolic
Logic. Macmillan, London.
Diana Santos. 1994. Bilingual Alignment and Tense.
In Proceedings of the Second Annual Workshop on
Very Large Corpora, pages 129-141, Kyoto, August.
</reference>
<page confidence="0.995166">
1187
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.975871">
<title confidence="0.99995">Learning Tense Translation from Bilingual Corpora</title>
<author confidence="0.999751">Michael Schiehlen</author>
<affiliation confidence="0.999752">Institute for Computational Linguistics, University of Stuttgart,</affiliation>
<address confidence="0.988356">Azenbergstr. 12, 70174 Stuttgart</address>
<abstract confidence="0.9987582">This paper studies and evaluates disambiguation strategies for the translation of tense between German and English, using a bilingual corpus of appointment scheduling dialogues. It describes a scheme to detect complex verb predicates based on verb form subcategorization and grammatical knowledge. The extracted verb and tense information is presented and the role of different context factors is discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>Robust Bilingual Word Alignment for Machine-Aided Translation.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="2742" citStr="Dagan et al. (1993)" startWordPosition="416" endWordPosition="419">positional but arises from combinations of words (1). (1) a. Ich habe ihn gestern gesehen. I have him yesterday seen I saw him yesterday. b. Ich schlage Montag vor. I beat Monday forward I suggest Monday. c. Ich mochte mich beschweren. I &apos;d like to myself weigh down I&apos;d like to make a complaint. For translation, the discontinuous words must be amalgamated into single semantic items. Single words or pairs of lemma and part of speech tag (L-POS pairs) are not appropriate. To verify this claim, we aligned the L-POS pairs of the Verbmobil corpus using the completely language-independent method of Dagan et al. (1993). Below find the results for seheni (see) in order of frequency and some frequent alignments for reflexive pronouns. 72 sehen:VVFIN be:VBZ (aussehen) 44 sehen:VVFIN do:VBP (do-support) 39 sehen:VVFIN have:VBP (perfect) 35 sehen:VVFIN see:VB 176 wir:PRF meet:VB (sich treffen) 33 wir:PRF we:PP 30 sich:PRF spell:VBN (sich schreiben) 16 ich:PRF forward:RP (sich freuen auf) 14 wir:PRF agree:VB (sich einigen) 13 ich:PRF myself:PP 1The prefix verb aus-sehen (look, be) is very frequent in the corpus, it often occurs in questions. Present sehen was frequently translated into perfect discover. 1183 3 Pa</context>
</contexts>
<marker>Dagan, Church, Gale, 1993</marker>
<rawString>Ido Dagan, Kenneth W. Church, and William A. Gale. 1993. Robust Bilingual Word Alignment for Machine-Aided Translation. In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives, pages 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Dorna</author>
<author>Martin C Emele</author>
</authors>
<title>Semantic-Based Transfer.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING &apos;96),</booktitle>
<publisher>Macmillan,</publisher>
<location>Copenhagen, Denmark. Hans Reichenbach.</location>
<contexts>
<context position="14931" citStr="Dorna and Emele, 1996" startWordPosition="2545" endWordPosition="2548"> of choosing surface tense is shifted to generation. repr. strat. G-4E E--+G prec. recall , t prec. recall , t .861 .861 .861 .957 .957 .957 re vs .883 .853 .877 .968 .940 .963 re vt .895 .872 .891 .971 .933 .965 re vst .913 .816 .895 .979 .875 .964 5 Conclusion The paper presents a way to test disambiguation strategies on real data and to measure the influence of diverse factors ranging from sentence internal context to the choice of representation. The pertaining disambiguation information learned from the corpus is put into action in the symbolic transfer component of the Verbmobil system (Dorna and Emele, 1996). The only other empirical study of tense translation (Santos, 1994) I am aware of was conducted on a manually annotated Portuguese-English corpus (48,607 English, 43,492 Portuguese word tokens and 6,334 tense translation pairs). It neither gives results for all tenses nor considers disambiguation factors. Still, it acknowledges the surprising divergence of tense across languages and argues against the widely held belief that surface tenses can be mapped directly into an interlingual representation. Although the findings reported here support this conclusion, it should be noted that a bilingua</context>
</contexts>
<marker>Dorna, Emele, 1996</marker>
<rawString>Michael Dorna and Martin C. Emele. 1996. Semantic-Based Transfer. In Proceedings of the 16th International Conference on Computational Linguistics (COLING &apos;96), Copenhagen, Denmark. Hans Reichenbach. 1947. Elements of Symbolic Logic. Macmillan, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Santos</author>
</authors>
<title>Bilingual Alignment and Tense.</title>
<date>1994</date>
<booktitle>In Proceedings of the Second Annual Workshop on Very Large Corpora,</booktitle>
<pages>129--141</pages>
<location>Kyoto,</location>
<contexts>
<context position="14999" citStr="Santos, 1994" startWordPosition="2558" endWordPosition="2559">prec. recall , t prec. recall , t .861 .861 .861 .957 .957 .957 re vs .883 .853 .877 .968 .940 .963 re vt .895 .872 .891 .971 .933 .965 re vst .913 .816 .895 .979 .875 .964 5 Conclusion The paper presents a way to test disambiguation strategies on real data and to measure the influence of diverse factors ranging from sentence internal context to the choice of representation. The pertaining disambiguation information learned from the corpus is put into action in the symbolic transfer component of the Verbmobil system (Dorna and Emele, 1996). The only other empirical study of tense translation (Santos, 1994) I am aware of was conducted on a manually annotated Portuguese-English corpus (48,607 English, 43,492 Portuguese word tokens and 6,334 tense translation pairs). It neither gives results for all tenses nor considers disambiguation factors. Still, it acknowledges the surprising divergence of tense across languages and argues against the widely held belief that surface tenses can be mapped directly into an interlingual representation. Although the findings reported here support this conclusion, it should be noted that a bilingual corpus can only give one of several possible translations. Referen</context>
</contexts>
<marker>Santos, 1994</marker>
<rawString>Diana Santos. 1994. Bilingual Alignment and Tense. In Proceedings of the Second Annual Workshop on Very Large Corpora, pages 129-141, Kyoto, August.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>