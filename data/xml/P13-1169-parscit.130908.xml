<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000371">
<title confidence="0.990378">
Deceptive Answer Prediction with User Preference Graph
</title>
<author confidence="0.947366">
Fangtao Li§, Yang Gao†, Shuchang Zhou§‡, Xiance Si§, and Decheng Dai§
</author>
<affiliation confidence="0.8319385">
§Google Research, Mountain View
‡State Key Laboratory of Computer Architecture, Institute of Computing Technology, CAS
</affiliation>
<email confidence="0.949397">
{lifangtao,georgezhou,sxc,decheng}@google.com
</email>
<affiliation confidence="0.978368">
†Department of Computer Science and Technology, Tsinghua University
</affiliation>
<email confidence="0.960286">
gao young@163.com
</email>
<sectionHeader confidence="0.996527" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99989523076923">
In Community question answering (QA)
sites, malicious users may provide decep-
tive answers to promote their products or
services. It is important to identify and fil-
ter out these deceptive answers. In this
paper, we first solve this problem with
the traditional supervised learning meth-
ods. Two kinds of features, including tex-
tual and contextual features, are investi-
gated for this task. We further propose
to exploit the user relationships to identify
the deceptive answers, based on the hy-
pothesis that similar users will have simi-
lar behaviors to post deceptive or authentic
answers. To measure the user similarity,
we propose a new user preference graph
based on the answer preference expressed
by users, such as “helpful” voting and
“best answer” selection. The user prefer-
ence graph is incorporated into traditional
supervised learning framework with the
graph regularization technique. The ex-
periment results demonstrate that the user
preference graph can indeed help improve
the performance of deceptive answer pre-
diction.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998803333333333">
Currently, Community QA sites, such as Yahoo!
Answers1 and WikiAnswers2, have become one of
the most important information acquisition meth-
ods. In addition to the general-purpose web search
engines, the Community QA sites have emerged as
popular, and often effective, means of information
seeking on the web. By posting questions for other
participants to answer, users can obtain answers
to their specific questions. The Community QA
</bodyText>
<footnote confidence="0.9999405">
1http://answers.yahoo.com
2http://wiki.answers.com
</footnote>
<bodyText confidence="0.999495536585365">
sites are growing rapidly in popularity. Currently
there are hundreds of millions of answers and mil-
lions of questions accumulated on the Community
QA sites. These resources of past questions and
answers are proving to be a valuable knowledge
base. From the Community QA sites, users can di-
rectly get the answers to meet some specific infor-
mation need, rather than browse the list of returned
documents to find the answers. Hence, in recent
years, knowledge mining in Community QA sites
has become a popular topic in the field of artifi-
cial intelligence (Adamic et al., 2008; Wei et al.,
2011).
However, some answers may be deceptive. In
the Community QA sites, there are millions of
users each day. As the answers can guide the
user’s behavior, some malicious users are moti-
vated to give deceptive answers to promote their
products or services. For example, if someone
asks for recommendations about restaurants in the
Community QA site, the malicious user may post a
deceptive answer to promote the target restaurant.
Indeed, because of lucrative financial rewards, in
several Community QA sites, some business own-
ers provide incentives for users to post deceptive
answers for product promotion.
There are at least two major problems that the
deceptive answers cause. On the user side, the
deceptive answers are misleading to users. If
the users rely on the deceptive answers, they will
make the wrong decisions. Or even worse, the pro-
moted link may lead to illegitimate products. On
the Community QA side, the deceptive answers
will hurt the health of the Community QA sites. A
Community QA site without control of deceptive
answers could only benefit spammers but could
not help askers at all. If the asker was cheated by
the provided answers, he will not trust and visit
this site again. Therefore, it is a fundamental task
to predict and filter out the deceptive answers.
In this paper, we propose to predict deceptive
</bodyText>
<page confidence="0.747604">
1723
</page>
<note confidence="0.9145445">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1723–1732,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999967586206897">
answer, which is defined as the answer, whose pur-
pose is not only to answer the question, but also
to promote the authors’ self-interest. In the first
step, we consider the deceptive answer prediction
as a general binary-classification task. We extract
two types of features: one is textual features from
answer content, including unigram/bigram, URL,
phone number, email, and answer length; the other
is contextual features from the answer context, in-
cluding the relevance between answer and the cor-
responding question, the author of the answer, an-
swer evaluation from other users and duplication
with other answers. We further investigate the user
relationship for deceptive answer prediction. We
assume that similar users tend to have similar be-
haviors, i.e. posting deceptive answers or post-
ing authentic answers. To measure the user rela-
tionship, we propose a new user preference graph,
which is constructed based on the answer evalu-
ation expressed by users, such as “helpful” vot-
ing and “best answer” selection. The user prefer-
ence graph is incorporated into traditional super-
vised learning framework with graph regulariza-
tion, which can make answers, from users with
same preference, tend to have the same category
(deceptive or authentic). The experiment results
demonstrate that the user preference graph can fur-
ther help improve the performance for deceptive
answer prediction.
</bodyText>
<sectionHeader confidence="0.999893" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999981583333334">
In the past few years, it has become a popular task
to mine knowledge from the Community QA sites.
Various studies, including retrieving the accumu-
lated question-answer pairs to find the related an-
swer for a new question, finding the expert in a
specific domain, summarizing single or multiple
answers to provide a concise result, are conducted
in the Community QA sites (Jeon et al., 2005;
Adamic et al., 2008; Liu et al., 2008; Song et
al., 2008; Si et al., 2010a; Figueroa and Atkin-
son, 2011). However, an important issue which
has been neglected so far is the detection of decep-
tive answers. If the acquired question-answer cor-
pus contains many deceptive answers, it would be
meaningless to perform further knowledge mining
tasks. Therefore, as the first step, we need to pre-
dict and filter out the deceptive answers. Among
previous work, answer quality prediction (Song et
al., 2010; Harper et al., 2008; Shah and Pomer-
antz, 2010; Ishikawa et al., 2010) is most related to
the deceptive answer prediction task. But these are
still significant differences between two tasks. An-
swer quality prediction measures the overall qual-
ity of the answers, which refers to the accuracy,
readability, completeness of the answer. While
the deceptive answer prediction aims to predict if
the main purpose of the provided answer is only
to answer the specific question, or includes the
user’s self-interest to promote something. Some
of the previous work (Song et al., 2010; Ishikawa
et al., 2010; Bian et al., 2009) views the “best
answer” as high quality answers, which are se-
lected by the askers in the Community QA sites.
However, the deceptive answer may be selected as
high-quality answer by the spammer, or because
the general users are mislead. Meanwhile, some
answers from non-native speakers may have lin-
guistic errors, which are low-quality answers, but
are still authentic answers. Our experiments also
show that answer quality prediction is much dif-
ferent from deceptive answer prediction.
Previous QA studies also analyze the user graph
to investigate the user relationship (Jurczyk and
Agichtein, 2007; Liu et al., 2011). They mainly
construct the user graph with asker-answerer rela-
tionship to estimate the expertise score in Commu-
nity QA sites. They assume the answerer is more
knowledgeable than the asker. However, we don’t
care which user is more knowledgeable, but are
more likely to know if two users are both spam-
mers or authentic users. In this paper, we pro-
pose a novel user preference graph based on their
preference towards the target answers. We assume
that the spammers may collaboratively promote
the target deceptive answers, while the authen-
tic users may generally promote the authentic an-
swers and demote the deceptive answers. The user
preference graph is constructed based on their an-
swer evaluation, such as “helpful” voting or “best
answer” selection.
</bodyText>
<sectionHeader confidence="0.987706" genericHeader="method">
3 Proposed Features
</sectionHeader>
<bodyText confidence="0.99999375">
We first view the deceptive answer prediction as a
binary-classification problem. Two kinds of fea-
tures, including textual features and contextual
features, are described as follows:
</bodyText>
<subsectionHeader confidence="0.999228">
3.1 Textual Features
</subsectionHeader>
<bodyText confidence="0.99956">
We first aim to predict the deceptive answer by an-
alyzing the answer content. Several textual fea-
tures are extracted from the answer content:
</bodyText>
<subsectionHeader confidence="0.838208">
3.1.1 Unigrams and Bigrams
</subsectionHeader>
<bodyText confidence="0.9983105">
The most common type of feature for text classi-
fication is the bag-of-word. We use an effective
</bodyText>
<page confidence="0.990123">
1724
</page>
<bodyText confidence="0.90569075">
feature selection method x2 (Yang and Pedersen,
1997) to select the top 200 unigrams and bigrams
as features. The top ten unigrams related to decep-
tive answers are shown on Table 1. We can see that
these words are related to the intent for promotion.
professional service advice address
site telephone therapy recommend
hospital expert
</bodyText>
<tableCaption confidence="0.993094">
Table 1: Top 10 Deceptive Related Unigrams
</tableCaption>
<subsectionHeader confidence="0.866585">
3.1.2 URL Features
</subsectionHeader>
<bodyText confidence="0.953754777777778">
Some malicious users may promote their products
by linking a URL. We find that URL is good indi-
cator for deceptive answers. However, some URLs
may provide the references for the authentic an-
swers. For example, if you ask the weather in
mountain view, someone may just post the link
to ”http://www.weather.com/”. Therefore, besides
the existence of URL, we also use the following
URL features:
</bodyText>
<listItem confidence="0.9967756">
1). Length of the URLs: we observe that the
longer urls are more likely to be spam.
2). PageRank Score: We employ the PageRank
(Page et al., 1999) score of each URL as popularity
score.
</listItem>
<subsectionHeader confidence="0.945094">
3.1.3 Phone Numbers and Emails
</subsectionHeader>
<bodyText confidence="0.99996725">
There are a lot of contact information mentioned
in the Community QA sites, such as phone num-
bers and email addresses, which are very likely to
be deceptive, as good answers are found to be less
likely to refer to phone numbers or email addresses
than the malicious ones. We extract the number of
occurrences of email and phone numbers as fea-
tures.
</bodyText>
<subsectionHeader confidence="0.913615">
3.1.4 Length
</subsectionHeader>
<bodyText confidence="0.999963285714285">
We have also observed some interesting patterns
about the length of answer. Deceptive ones tend
to be longer than authentic ones. This can be ex-
plained as the deceptive answers may be well pre-
pared to promote the target. We also employ the
number of words and sentences in the answer as
features.
</bodyText>
<subsectionHeader confidence="0.999672">
3.2 Contextual Features
</subsectionHeader>
<bodyText confidence="0.977000333333333">
Besides the answer textual features, we further in-
vestigate various features from the context of the
target answer:
</bodyText>
<subsectionHeader confidence="0.970722">
3.2.1 Question Answer Relevance
</subsectionHeader>
<bodyText confidence="0.999870428571429">
The main characteristic of answer in Community
QA site is that the answer is provided to answer
the corresponding question. We can use the corre-
sponding question as one of the context features by
measuring the relevance between the answer and
the question. We employ three different models
for Question-Answer relevance:
</bodyText>
<subsectionHeader confidence="0.607579">
Vector Space Model
</subsectionHeader>
<bodyText confidence="0.999980285714286">
Each answer or question is viewed as a word
vector. Given a question q and the answer a, our
vector model uses weighted word counts(e.g.TF-
IDF) as well as the cosine similarity (q · a) of
their word vectors as relevant function (Salton and
McGill, 1986). However, vector model only con-
sider the exact word match, which is a big prob-
lem, especially when the question and answer are
generally short compared to the document. For ex-
ample, Barack Obama and the president of the US
are the same person. But the vector model would
indicate them to be different. To remedy the word-
mismatch problem, we also look for the relevance
models in higher semantic levels.
</bodyText>
<subsectionHeader confidence="0.974681">
Translation Model
</subsectionHeader>
<bodyText confidence="0.999927307692308">
A translation model is a mathematical model in
which the language translation is modeled in a sta-
tistical way. The probability of translating a source
sentence (as answer here) into target sentence (as
question here) is obtained by aligning the words
to maximize the product of all the word probabil-
ities. We train a translation model (Brown et al.,
1990; Och and Ney, 2003) using the Community
QA data, with the question as the target language,
and the corresponding best answer as the source
language. With translation model, we can com-
pute the translation score for new question and an-
swer.
</bodyText>
<subsectionHeader confidence="0.993033">
Topic Model
</subsectionHeader>
<bodyText confidence="0.9999966">
To reduce the false negatives of word mismatch
in vector model, we also use the topic models to
extend matching to semantic topic level. The topic
model, such as Latent Dirichlet Allocation (LDA)
(Blei et al., 2003), considers a collection of doc-
uments with K latent topics, where K is much
smaller than the number of words. In essence,
LDA maps information from the word dimen-
sion to a semantic topic dimension, to address the
shortcomings of the vector model.
</bodyText>
<subsubsectionHeader confidence="0.600428">
3.2.2 User Profile Features
</subsubsectionHeader>
<bodyText confidence="0.9997335">
We extract several user’s activity statistics to con-
struct the user profile features, including the level
</bodyText>
<page confidence="0.941669">
1725
</page>
<bodyText confidence="0.9998885">
of the user in the Community QA site, the number
of questions asked by this user, the number of an-
swers provided by this user, and the best answer
ratio of this user.
</bodyText>
<subsectionHeader confidence="0.821896">
3.2.3 User Authority Score
</subsectionHeader>
<bodyText confidence="0.998692">
Motivated by expert finding task (Jurczyk and
Agichtein, 2007; Si et al., 2010a; Li et al., 2011),
the second type of author related feature is author-
ity score, which denotes the expertise score of this
user. To compute the authority score, we first con-
struct a directed user graph with the user interac-
tions in the community. The nodes of the graph
represent users. An edge between two users in-
dicates a contribution from one user to the other.
Specifically, on a Q&amp;A site, an edge from A to
B is established when user B answered a question
asked by A, which shows user B is more likely to
be an expert than A. The weight of an edge indi-
cates the number of interactions. We compute the
user’s authority score (AS) based on the link anal-
ysis algorithm PageRank:
</bodyText>
<equation confidence="0.996499666666667">
1 − d �
AS(ui) = N + d
uj∈M(ui)
</equation>
<bodyText confidence="0.999978285714286">
where u1, ... , uN are the users in the collection,
N is the total number of users, M(ui) is the set
of users whose answers are provided by user ui,
L(ui) is the number of users who answer ui’s
questions, d is a damping factor, which is set as
0.85. The authority score can be computed itera-
tively with random initial values.
</bodyText>
<subsectionHeader confidence="0.498347">
3.2.4 Robot Features
</subsectionHeader>
<bodyText confidence="0.999946888888889">
The third type of author related feature is used for
detecting whether the author is a robot, which are
scripts crafted by malicious users to automatically
post answers. We observe that the distributions of
the answer-posting time are very different between
general user and robot. For example, some robots
may make posts continuously and mechanically,
hence the time increment may be smaller that hu-
man users who would need time to think and pro-
cess between two posts. Based on this observa-
tion, we design an time sequence feature for robot
detection. For each author, we can get a list of
time points to post answers, T = {t0, t1, ..., tn},
where ti is the time point when posting the ith an-
swer. We first convert the time sequence T to time
interval sequence OT = {Ot0, Ot1, ..., Otn−1},
where Oti = ti+1 − ti. Based on the interval
sequences for all users, we then construct a ma-
trix Xm×b whose rows correspond to users and
columns correspond to interval histogram with
predefined range. We can use each row vector as
time sequence pattern to detect robot. To reduce
the noise and sparse problem, we use the dimen-
sion reduction techniques to extract the latent se-
mantic features with Singular Value Decomposi-
tion (SVD) (Deerwester et al., 1990; Kim et al.,
2006).
</bodyText>
<subsectionHeader confidence="0.824532">
3.2.5 Evaluation from Other Users
</subsectionHeader>
<bodyText confidence="0.9985034">
In the Community QA sites, other users can ex-
press their opinions or evaluations on the answer.
For example, the asker can choose one of the an-
swers as best answer. We use a bool feature to de-
note if this answer is selected as the best answer.
In addition, other users can label each answer as
“helpful” or “not helpful”. We also use this helpful
evaluation by other users as the contextual feature,
which is defined as the ratio between the number
of “helpful” votes and the number of total votes.
</bodyText>
<subsectionHeader confidence="0.905227">
3.2.6 Duplication with Other Answers
</subsectionHeader>
<bodyText confidence="0.999572266666667">
The malicious user may post the pre-written prod-
uct promotion documents to many answers, or just
change the product name. We also compute the
similarity between different answers. If the two
answers are totally same, but the question is differ-
ent, these answer is potentially as a deceptive an-
swer. Here, we don’t want to measure the semantic
similarity between two answers, but just measure
if two answers are similar to the word level, there-
fore, we apply BleuScore (Papineni et al., 2002),
which is a standard metric in machine translation
for measuring the overlap between n-grams of two
text fragments r and c. The duplication score of
each answer is the maximum BleuScore compared
to all other answers.
</bodyText>
<sectionHeader confidence="0.835593" genericHeader="method">
4 Deceptive Answer Prediction with User
Preference Graph
</sectionHeader>
<bodyText confidence="0.999131777777778">
Besides the textual and contextual features, we
also investigate the user relationship for decep-
tive answer prediction. We assume that similar
users tend to perform similar behaviors (posting
deceptive answers or posting authentic answers).
In this section, we first show how to compute the
user similarity (user preference graph construc-
tion), and then introduce how to employ the user
relationship for deceptive answer prediction.
</bodyText>
<subsectionHeader confidence="0.989703">
4.1 User Preference Graph Construction
</subsectionHeader>
<bodyText confidence="0.99751">
In this section, we propose a new user graph to de-
scribe the relationship among users. Figure 1 (a)
shows the general process in a question answering
</bodyText>
<equation confidence="0.7784385">
AS(uj) (1)
L(uj)
</equation>
<page confidence="0.782314">
1726
</page>
<figure confidence="0.999245727272727">
U�
U�
U,
Best Answer
Answer1
Answer2
Question
U.
U.
U�
(a) Question Answering (b) User Preference Relation (c) User Preference Graph
</figure>
<figureCaption confidence="0.999976">
Figure 1: User Preference Graph Construction
</figureCaption>
<bodyText confidence="0.999982444444445">
thread. The asker, i.e. u1, asks a question. Then,
there will be several answers to answer this ques-
tion from other users, for example, answerers u2
and u3. After the answers are provides, users can
also vote each answer as “helpful” or “not help-
ful” to show their evaluation towards the answer .
For example, users u4, u5 vote the first answer as
“not helpful”, and user u6 votes the second answer
as “helpful”. Finally, the asker will select one an-
swer as the best answer among all answers. For
example, the asker u1 selects the first answer as
the “best answer”.
To mine the relationship among users, previous
studies mainly focus on the asker-answerer rela-
tionship (Jurczyk and Agichtein, 2007; Liu et al.,
2011). They assume the answerer is more knowl-
edgeable than the asker. Based on this assump-
tion, they can extract the expert in the commu-
nity, as discussed in Section 3.2.3. However, we
don’t care which user is more knowledgeable, but
are more interested in whether two users are both
malicious users or authentic users. Here, we pro-
pose a new user graph based on the user prefer-
ence. The preference is defined based on the an-
swer evaluation. If two users show same pref-
erence towards the target answer, they will have
the user-preference relationship. We mainly use
two kinds of information: “helpful” evaluation and
“best answer” selection. If two users give same
“helpful” or “not helpful” to the target answer, we
view these two users have same user preference.
For example, user u4 and user u5 both give “not
helpful” evaluation towards the first answer, we
can say that they have same user preference. Be-
sides the real “helpful” evaluation, we also assume
the author of the answer gives the “helpful” evalu-
ation to his or her own answer. Then if user u6 give
“helpful” evaluation to the second answer, we will
view user u6 has same preference as user u3, who
is the author of the second answer. We also can ex-
tract the user preference with “best answer” selec-
tion. If the asker selects the “best answer” among
all answers, we will view that the asker has same
preference as the author of the “best answer”. For
example, we will view user u1 and user u2 have
same preference.
Based on the two above assumptions, we can
extract three user preference relationships (with
same preference) from the question answering ex-
ample in Figure 1 (a): u4 — u5, u3 — u6, u1 — u2,
as shown in Figure1 (b). After extracting all user
preference relationships, we can construct the user
preference graph as shown in Figure 1 (c). Each
node represents a user. If two users have the user
preference relationship, there will be an edge be-
tween them. The edge weight is the number of
user preference relationships.
In the Community QA sites, the spammers
mainly promote their target products by promoting
the deceptive answers. The spammers can collab-
oratively make the deceptive answers look good,
by voting them as high-quality answer, or select-
ing them as “best answer”. However, the authen-
tic users generally have their own judgements to
the good and bad answers. Therefore, the evalu-
ation towards the answer reflects the relationship
among users. Although there maybe noisy rela-
tionship, for example, an authentic user may be
cheated, and selects the deceptive answer as “best
answer”, we hope the overall user preference rela-
tion can perform better results than previous user
interaction graph for this task.
</bodyText>
<page confidence="0.984243">
1727
</page>
<subsectionHeader confidence="0.996334">
4.2 Incorporating User Preference Graph
</subsectionHeader>
<bodyText confidence="0.999975727272727">
To use the user graph, we can just compute the
feature value from the graph, and add it into the
supervised method as the features introduced in
Section 3. Here, we propose a new technique to
employ the user preference graph. We utilize the
graph regularizer (Zhang et al., 2006; Lu et al.,
2010) to constrain the supervised parameter learn-
ing. We will introduce this technique based on
a commonly used model f(·), the linear weight
model, where the function value is determined by
linear combination of the input features:
</bodyText>
<equation confidence="0.998097">
Xf(xi) = wT · xi = wk · xik (2)
k
</equation>
<bodyText confidence="0.999957">
where xi is a K dimension feature vector for the
ith answer, the parameter value wk captures the
effect of the kth feature in predicting the deceptive
answer. The best parameters w* can be found by
minimizing the following objective function:
</bodyText>
<equation confidence="0.995316">
XQ1(w) = L(wT xi, yi) + α · |w|2F (3)
i
</equation>
<bodyText confidence="0.999753761904762">
where L(wTxi,yi) is a loss function that mea-
sures discrepancy between the predicted label
wT · xi and the true label yi, where yi ∈
{+1, −1}. The common used loss functions in-
clude L(p, y) = (p − y)2 (least square), L(p, y) =
ln (1 + exp (−py)) (logistic regression). For sim-
plicity, here we use the least square loss function.
|w|2F = Pk w2k is a regularization term defined
in terms of the Frobenius norm of the parameter
vector w and plays the role of penalizing overly
complex models in order to avoid fitting.
We want to incorporate the user preference re-
lationship into the supervised learning framework.
The hypothesis is that similar users tend to have
similar behaviors, i.e. posting deceptive answers
or authentic answers. Here, we employ the user
preference graph to denote the user relationship.
Based on this intuition, we propose to incorporate
the user graph into the linear weight model with
graph regularization. The new objective function
is changed as:
</bodyText>
<equation confidence="0.99406925">
XQ2(w) = L(wTxi,yi) + α · |w|2F +
i
0 X X wui,uj(f(x) − f(y))2 (4)
ui,ujENu xEAui,yEAuj
</equation>
<bodyText confidence="0.995154714285714">
where Nu is the set of neighboring user pairs in
user preference graph, i.e, the user pairs with same
preference. Aui is the set of all answers posted by
user ui. wui,uj is the weight of edge between ui
and uj in user preference graph. In the above ob-
jective function, we impose a user graph regular-
ization term
</bodyText>
<equation confidence="0.9746815">
0 X X wui,uj(f(x) − f(y))2
ui,ujENu xEAui,yEAuj
</equation>
<bodyText confidence="0.999979">
to minimize the answer authenticity difference
among users with same preference. This regu-
larization term smoothes the labels on the graph
structure, where adjacent users with same prefer-
ence tend to post answers with same label.
</bodyText>
<sectionHeader confidence="0.999916" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.985321">
5.1 Experiment Setting
</subsectionHeader>
<subsubsectionHeader confidence="0.687652">
5.1.1 Dataset Construction
</subsubsectionHeader>
<bodyText confidence="0.99999555">
In this paper, we employ the Confucius (Si et
al., 2010b) data to construct the deceptive an-
swer dataset. Confucius is a community question
answering site, developed by Google. We first
crawled about 10 million question threads within
a time range. Among these data, we further sam-
ple a small data set, and ask three trained annota-
tors to manually label the answer as deceptive or
not. If two or more people annotate the answer as
deceptive, we will extract this answer as a decep-
tive answer. In total, 12446 answers are marked
as deceptive answers. Similarly, we also manu-
ally annotate 12446 authentic answers. Finally,
we get 24892 answers with deceptive and authen-
tic labels as our dataset. With our labeled data,
we employ supervised methods to predict decep-
tive answers. We conduct 5-fold cross-validation
for experiments. The larger question threads data
is employed for feature learning, such as transla-
tion model, and topic model training.
</bodyText>
<subsubsectionHeader confidence="0.867302">
5.1.2 Evaluation Metrics
</subsubsectionHeader>
<bodyText confidence="0.982554">
The evaluation metrics are precision, recall and
F-score for authentic answer category and de-
ceptive answer category: precision = SpnSc p
</bodyText>
<equation confidence="0.497737">
S
,
SpnSc 2*precision*recall
</equation>
<bodyText confidence="0.998082285714286">
recall = Sc , and F = precision+recall , where
Sc is the set of gold-standard positive instances for
the target category, Sp is the set of predicted re-
sults. We also use the accuracy as one metric,
which is computed as the number of answers pre-
dicted correctly, divided by the number of total an-
swers.
</bodyText>
<page confidence="0.965609">
1728
</page>
<table confidence="0.99995425">
Deceptive Answer Authentic Answer Overall
Prec. Rec. F-Score Prec. Rec. F-Score Acc.
Random 0.50 0.50 0.50 0.50 0.50 0.50 0.50
Unigram/Bigram (UB) 0.61 0.71 0.66 0.66 0.55 0.60 0.63
URL 0.93 0.26 0.40 0.57 0.98 0.72 0.62
Phone/Mail 0.94 0.15 0.25 0.53 0.99 0.70 0.57
Length 0.56 0.91 0.69 0.76 0.28 0.41 0.60
All Textual Features 0.64 0.67 0.66 0.66 0.63 0.64 0.65
QA Relevance 0.66 0.57 0.61 0.62 0.71 0.66 0.64
User Profile 0.62 0.53 0.57 0.59 0.67 0.63 0.60
User Authority 0.54 0.80 0.65 0.62 0.33 0.43 0.56
Robot 0.66 0.62 0.64 0.61 0.66 0.64 0.64
Answer Evaluation 0.55 0.53 0.54 0.55 0.57 0.56 0.55
Answer Duplication 0.69 0.71 0.70 0.70 0.68 0.69 0.69
All Contextual Feature 0.78 0.74 0.76 0.75 0.79 0.77 0.77
Textutal + Contextual 0.80 0.82 0.81 0.82 0.79 0.80 0.81
</table>
<tableCaption confidence="0.999186">
Table 2: Results With Textual and Contextual Features
</tableCaption>
<subsectionHeader confidence="0.977989">
5.2 Results with Textual and Contextual
Features
</subsectionHeader>
<bodyText confidence="0.999811741935484">
We tried several different classifiers, including
SVM, ME and the linear weight models with least
square and logistic regression. We find that they
can achieve similar results. For simplicity, the lin-
ear weight with least square is employed in our
experiment. Table 2 shows the experiment results.
For textual features, it achieves much better re-
sult with unigram/bigram features than the ran-
dom guess. This is very different from the an-
swer quality prediction task. The previous stud-
ies (Jeon et al., 2006; Song et al., 2010) find that
the word features can’t improve the performance
on answer quality prediction. However, from Ta-
ble 1, we can see that the word features can pro-
vide some weak signals for deceptive answer pre-
diction, for example, words “recommend”, “ad-
dress”, “professional” express some kinds of pro-
motion intent. Besides unigram and bigram, the
most effective textual feature is URL. The phone
and email features perform similar results with
URL. The observation of length feature for decep-
tive answer prediction is very different from previ-
ous answer quality prediction. For answer quality
prediction, length is an effective feature, for exam-
ple, long-length provides very strong signals for
high-quality answer (Shah and Pomerantz, 2010;
Song et al., 2010). However, for deceptive answer
prediction, we find that the long answers are more
potential to be deceptive. This is because most of
deceptive answers are well prepared for product
promotion. They will write detailed answers to at-
tract user’s attention and promote their products.
Finally, with all textual features, the experiment
achieves the best result, 0.65 in accuracy.
For contextual features, we can see that, the
most effective contextual feature is answer dupli-
cation. The malicious users may copy the pre-
pared deceptive answers or just simply edit the tar-
get name to answer different questions. Question-
answer relevance and robot are the second most
useful single features for deceptive answer predic-
tion. The main characteristics of the Community
QA sites is to accumulate the answers for the tar-
get questions. Therefore, all the answers should be
relevant to the question. If the answer is not rel-
evant to the corresponding question, this answer
is more likely to be deceptive. Robot is one of
main sources for deceptive answers. It automat-
ically post the deceptive answers to target ques-
tions. Here, we formulate the time series as in-
terval sequence. The experiment result shows that
the robot indeed has his own posting behavior pat-
terns. The user profile feature also can contribute
a lot to deceptive answer prediction. Among the
user profile features, the user level in the Com-
munity QA site is a good indicator. The other
two contextual features, including user authority
and answer evaluation, provide limited improve-
ment. We find the following reasons: First, some
malicious users post answers to various questions
for product promotion, but don’t ask any question.
From Equation 1, when iteratively computing the
</bodyText>
<page confidence="0.979028">
1729
</page>
<table confidence="0.999495166666667">
Deceptive Answer Authentic Answer Overall
Prec. Rec. F-Score Prec. Rec. F-Score Acc.
Interaction Graph as Feature 0.80 0.82 0.81 0.82 0.79 0.80 0.81
Interaction Graph as Regularizer 0.80 0.83 0.82 0.82 0.80 0.81 0.82
Preference Graph as Feature 0.79 0.83 0.81 0.82 0.78 0.80 0.81
Preference Graph as Regularizer 0.83 0.86 0.85 0.85 0.83 0.84 0.85
</table>
<tableCaption confidence="0.999877">
Table 3: Results With User Preference Graph
</tableCaption>
<bodyText confidence="0.9999359375">
final scores, the authority scores for these mali-
cious users will be accumulated to large values.
Therefore, it is hard to distinguish whether the
high authority score represents real expert or mali-
cious user. Second, the “best answer” is not a good
signal for deceptive answer prediction. This may
be selected by malicious users, or the authentic
asker was misled, and chose the deceptive answer
as “best answer”. This also demonstrates that the
deceptive answer prediction is very different from
the answer quality prediction. When combining
all the contextual features, it can achieve the over-
all accuracy 0.77, which is much better than the
textual features. Finally, with all the textual and
contextual features, we achieve the overall result,
0.81 in accuracy.
</bodyText>
<subsectionHeader confidence="0.974895">
5.3 Results with User Preference Graph
</subsectionHeader>
<bodyText confidence="0.990849461538462">
Table 3 shows the results with user preference
graph. We compare with several baselines. Inter-
action graph is constructed by the asker-answerer
relationship introduced in Section 3.2.3. When
using the user graph as feature, we compute the
authority score for each user with PageRank as
shown in Equation 1. We also incorporating the
interaction graph with a regularizer as shown in
Equation 4. Note that we didn’t consider the edge
direction when using interaction graph as a regu-
larizer. From the table, we can see that when in-
corporating user preference graph as a feature, it
can’t achieve a better result than the interaction
graph. The reason is similar as the interaction
graph. The higher authority score may boosted
by other spammer, and can’t be a good indica-
tor to distinguish deceptive and authentic answers.
When we incorporate the user preference graph
as a regularizer, it can achieve about 4% further
improvement, which demonstrates that the user
evaluation towards answers, such as “helpful” vot-
ing and “best answer” selection, is a good signal
to generate user relationship for deceptive answer
prediction, and the graph regularization is an ef-
fective technique to incorporate the user prefer-
ence graph. We also analyze the parameter sen-
</bodyText>
<figureCaption confidence="0.989136">
Figure 2: Results with different values of 0
</figureCaption>
<bodyText confidence="0.9999608">
sitivity. 0 is the tradeoff weight for graph regular-
ization term. Figure 2 shows the results with dif-
ferent values of 0. We can see that when 0 ranges
from 10−4 ∼ 10−2, the deceptive answer predic-
tion can achieve best results.
</bodyText>
<sectionHeader confidence="0.998933" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99994675">
In this paper, we discuss the deceptive answer
prediction task in Community QA sites. With
the manually labeled data set, we first predict the
deceptive answers with traditional classification
method. Two types of features, including textual
features and contextual features, are extracted and
analyzed. We also introduce a new user prefer-
ence graph, constructed based on the user evalua-
tions towards the target answer, such as “helpful”
voting and “best answer” selection. A graph reg-
ularization method is proposed to incorporate the
user preference graph for deceptive answer predic-
tion. The experiments are conducted to discuss
the effects of different features. The experiment
results also show that the method with user pref-
erence graph can achieve more accurate results for
deceptive answer prediction.
In the future work, it is interesting to incorpo-
rate more features into deceptive answer predic-
tion. It is also important to predict the deceptive
question threads, which are posted and answered
both by malicious users for product promotion.
Malicious user group detection is also an impor-
tant task in the future.
</bodyText>
<figure confidence="0.998690833333333">
0.88
0.86
General supervised method
Interaction Graph as Regularizer
Preference Graph as Regularizer
0.84
0.82
0.8
0.78
0.76
10−5 10−4 10−3 10−2 10−1 100
Accuracy
</figure>
<page confidence="0.952625">
1730
</page>
<sectionHeader confidence="0.985155" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998199504672898">
Lada A. Adamic, Jun Zhang, Eytan Bakshy, and
Mark S. Ackerman. 2008. Knowledge sharing
and yahoo answers: everyone knows something. In
Proceedings of the 17th international conference on
World Wide Web, WWW ’08, pages 665–674, New
York, NY, USA. ACM.
Jiang Bian, Yandong Liu, Ding Zhou, Eugene
Agichtein, and Hongyuan Zha. 2009. Learning to
recognize reliable users and content in social media
with coupled mutual reinforcement. In Proceedings
of the 18th international conference on World wide
web, WWW ’09, pages 51–60, NY, USA. ACM.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. J. Mach. Learn.
Res., 3:993–1022, March.
Peter F. Brown, John Cocke, Stephen A. Della Pietra,
Vincent J. Della Pietra, Fredrick Jelinek, John D.
Lafferty, Robert L. Mercer, and Paul S. Roossin.
1990. A statistical approach to machine translation.
Comput. Linguist., 16:79–85, June.
S. Deerwester, S.T. Dumais, G.W. Furnas, T.K. Lan-
dauer, and R. Harshman. 1990. Indexing by latent
semantic analysis. Journal of the American society
for information science, 41(6):391–407.
A. Figueroa and J. Atkinson. 2011. Maximum entropy
context models for ranking biographical answers to
open-domain definition questions. In Twenty-Fifth
AAAI Conference on Artificial Intelligence.
F. Maxwell Harper, Daphne Raban, Sheizaf Rafaeli,
and Joseph A. Konstan. 2008. Predictors of answer
quality in online q&amp;a sites. In Proceedings of the
twenty-sixth annual SIGCHI conference on Human
factors in computing systems, CHI ’08, pages 865–
874, New York, NY, USA. ACM.
Daisuke Ishikawa, Tetsuya Sakai, and Noriko Kando,
2010. Overview of the NTCIR-8 Community QA Pi-
lot Task (Part I): The Test Collection and the Task,
pages 421–432. Number Part I.
Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee. 2005.
Finding similar questions in large question and an-
swer archives. In Proceedings of the 14th ACM
CIKM conference, 05, pages 84–90, NY, USA.
ACM.
J. Jeon, W.B. Croft, J.H. Lee, and S. Park. 2006. A
framework to predict the quality of answers with
non-textual features. In Proceedings of the 29th an-
nual international ACM SIGIR conference on Re-
search and development in information retrieval,
pages 228–235. ACM.
P. Jurczyk and E. Agichtein. 2007. Discovering au-
thorities in question answer communities by using
link analysis. In Proceedings of the sixteenth ACM
CIKM conference, pages 919–922. ACM.
H. Kim, P. Howland, and H. Park. 2006. Dimension
reduction in text classification with support vector
machines. Journal of Machine Learning Research,
6(1):37.
Fangtao Li, Minlie Huang, Yi Yang, and Xiaoyan Zhu.
2011. Learning to identify review spam. In Pro-
ceedings of the Twenty-Second international joint
conference on Artificial Intelligence-Volume Volume
Three, pages 2488–2493. AAAI Press.
Yuanjie Liu, Shasha Li, Yunbo Cao, Chin-Yew Lin,
Dingyi Han, and Yong Yu. 2008. Understand-
ing and summarizing answers in community-based
question answering services. In Proceedings of the
22nd International Conference on Computational
Linguistics - Volume 1, COLING ’08, pages 497–
504, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Jing Liu, Young-In Song, and Chin-Yew Lin. 2011.
Competition-based user expertise score estimation.
In Proceedings of the 34th international ACM SI-
GIR conference on Research and development in In-
formation Retrieval, pages 425–434. ACM.
Yue Lu, Panayiotis Tsaparas, Alexandros Ntoulas, and
Livia Polanyi. 2010. Exploiting social context for
review quality prediction. In Proceedings of the
19th international conference on World wide web,
pages 691–700. ACM.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Comput. Linguist., 29:19–51, March.
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web. Technical Report
1999-66, Stanford InfoLab, November. SIDL-WP-
1999-0120.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of
the 40th Annual Meeting on Association for Com-
putational Linguistics, ACL ’02, pages 311–318,
Stroudsburg, PA, USA. ACL.
Gerard Salton and Michael J. McGill. 1986. Intro-
duction to Modern Information Retrieval. McGraw-
Hill, Inc., New York, NY, USA.
Chirag Shah and Jefferey Pomerantz. 2010. Evaluat-
ing and predicting answer quality in community qa.
In Proceedings of the 33rd international ACM SIGIR
conference on Research and development in infor-
mation retrieval, SIGIR ’10, pages 411–418, New
York, NY, USA. ACM.
X. Si, Z. Gyongyi, and E. Y. Chang. 2010a. Scal-
able mining of topic-dependent user reputation for
improving user generated content search quality. In
Google Technical Report.
</reference>
<page confidence="0.813119">
1731
</page>
<reference confidence="0.999853892857143">
Xiance Si, Edward Y. Chang, Zolt´an Gy¨ongyi, and
Maosong Sun. 2010b. Confucius and its intelli-
gent disciples: integrating social with search. Proc.
VLDB Endow., 3:1505–1516, September.
Young-In Song, Chin-Yew Lin, Yunbo Cao, and Hae-
Chang Rim. 2008. Question utility: a novel static
ranking of question search. In Proceedings of the
23rd national conference on Artificial intelligence
- Volume 2, AAAI’08, pages 1231–1236. AAAI
Press.
Y.I. Song, J. Liu, T. Sakai, X.J. Wang, G. Feng, Y. Cao,
H. Suzuki, and C.Y. Lin. 2010. Microsoft research
asia with redmond at the ntcir-8 community qa pilot
task. In Proceedings of NTCIR.
Wei Wei, Gao Cong, Xiaoli Li, See-Kiong Ng, and
Guohui Li. 2011. Integrating community question
and answer archives. In AAAI.
Y. Yang and J.O. Pedersen. 1997. A compara-
tive study on feature selection in text categoriza-
tion. In MACHINE LEARNING-INTERNATIONAL
WORKSHOP THEN CONFERENCE-, pages 412–
420. MORGAN KAUFMANN PUBLISHERS.
Tong Zhang, Alexandrin Popescul, and Byron Dom.
2006. Linear prediction models with graph regu-
larization for web-page categorization. In Proceed-
ings of the 12th ACM SIGKDD international con-
ference on Knowledge discovery and data mining,
pages 821–826. ACM.
</reference>
<page confidence="0.994228">
1732
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.225584">
<title confidence="0.999117">Deceptive Answer Prediction with User Preference Graph</title>
<author confidence="0.549411">Yang Shuchang Xiance</author>
<author confidence="0.549411">Decheng</author>
<affiliation confidence="0.7155805">Research, Mountain Key Laboratory of Computer Architecture, Institute of Computing Technology,</affiliation>
<address confidence="0.935025">of Computer Science and Technology, Tsinghua</address>
<email confidence="0.782319">gaoyoung@163.com</email>
<abstract confidence="0.989974">In Community question answering (QA) sites, malicious users may provide deceptive answers to promote their products or services. It is important to identify and filter out these deceptive answers. In this paper, we first solve this problem with the traditional supervised learning methods. Two kinds of features, including textual and contextual features, are investigated for this task. We further propose to exploit the user relationships to identify the deceptive answers, based on the hypothesis that similar users will have similar behaviors to post deceptive or authentic answers. To measure the user similarity, we propose a new user preference graph based on the answer preference expressed by users, such as “helpful” voting and “best answer” selection. The user preference graph is incorporated into traditional supervised learning framework with the graph regularization technique. The experiment results demonstrate that the user preference graph can indeed help improve the performance of deceptive answer prediction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lada A Adamic</author>
<author>Jun Zhang</author>
<author>Eytan Bakshy</author>
<author>Mark S Ackerman</author>
</authors>
<title>Knowledge sharing and yahoo answers: everyone knows something.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th international conference on World Wide Web, WWW ’08,</booktitle>
<pages>665--674</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2491" citStr="Adamic et al., 2008" startWordPosition="368" endWordPosition="371">//answers.yahoo.com 2http://wiki.answers.com sites are growing rapidly in popularity. Currently there are hundreds of millions of answers and millions of questions accumulated on the Community QA sites. These resources of past questions and answers are proving to be a valuable knowledge base. From the Community QA sites, users can directly get the answers to meet some specific information need, rather than browse the list of returned documents to find the answers. Hence, in recent years, knowledge mining in Community QA sites has become a popular topic in the field of artificial intelligence (Adamic et al., 2008; Wei et al., 2011). However, some answers may be deceptive. In the Community QA sites, there are millions of users each day. As the answers can guide the user’s behavior, some malicious users are motivated to give deceptive answers to promote their products or services. For example, if someone asks for recommendations about restaurants in the Community QA site, the malicious user may post a deceptive answer to promote the target restaurant. Indeed, because of lucrative financial rewards, in several Community QA sites, some business owners provide incentives for users to post deceptive answers</context>
<context position="5849" citStr="Adamic et al., 2008" startWordPosition="907" endWordPosition="910">d to have the same category (deceptive or authentic). The experiment results demonstrate that the user preference graph can further help improve the performance for deceptive answer prediction. 2 Related Work In the past few years, it has become a popular task to mine knowledge from the Community QA sites. Various studies, including retrieving the accumulated question-answer pairs to find the related answer for a new question, finding the expert in a specific domain, summarizing single or multiple answers to provide a concise result, are conducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction </context>
</contexts>
<marker>Adamic, Zhang, Bakshy, Ackerman, 2008</marker>
<rawString>Lada A. Adamic, Jun Zhang, Eytan Bakshy, and Mark S. Ackerman. 2008. Knowledge sharing and yahoo answers: everyone knows something. In Proceedings of the 17th international conference on World Wide Web, WWW ’08, pages 665–674, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Bian</author>
<author>Yandong Liu</author>
<author>Ding Zhou</author>
<author>Eugene Agichtein</author>
<author>Hongyuan Zha</author>
</authors>
<title>Learning to recognize reliable users and content in social media with coupled mutual reinforcement.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th international conference on World wide web, WWW ’09,</booktitle>
<pages>51--60</pages>
<publisher>ACM.</publisher>
<location>NY, USA.</location>
<contexts>
<context position="6944" citStr="Bian et al., 2009" startWordPosition="1088" endWordPosition="1091">; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction task. But these are still significant differences between two tasks. Answer quality prediction measures the overall quality of the answers, which refers to the accuracy, readability, completeness of the answer. While the deceptive answer prediction aims to predict if the main purpose of the provided answer is only to answer the specific question, or includes the user’s self-interest to promote something. Some of the previous work (Song et al., 2010; Ishikawa et al., 2010; Bian et al., 2009) views the “best answer” as high quality answers, which are selected by the askers in the Community QA sites. However, the deceptive answer may be selected as high-quality answer by the spammer, or because the general users are mislead. Meanwhile, some answers from non-native speakers may have linguistic errors, which are low-quality answers, but are still authentic answers. Our experiments also show that answer quality prediction is much different from deceptive answer prediction. Previous QA studies also analyze the user graph to investigate the user relationship (Jurczyk and Agichtein, 2007</context>
</contexts>
<marker>Bian, Liu, Zhou, Agichtein, Zha, 2009</marker>
<rawString>Jiang Bian, Yandong Liu, Ding Zhou, Eugene Agichtein, and Hongyuan Zha. 2009. Learning to recognize reliable users and content in social media with coupled mutual reinforcement. In Proceedings of the 18th international conference on World wide web, WWW ’09, pages 51–60, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>3--993</pages>
<contexts>
<context position="12485" citStr="Blei et al., 2003" startWordPosition="2012" endWordPosition="2015">uestion here) is obtained by aligning the words to maximize the product of all the word probabilities. We train a translation model (Brown et al., 1990; Och and Ney, 2003) using the Community QA data, with the question as the target language, and the corresponding best answer as the source language. With translation model, we can compute the translation score for new question and answer. Topic Model To reduce the false negatives of word mismatch in vector model, we also use the topic models to extend matching to semantic topic level. The topic model, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), considers a collection of documents with K latent topics, where K is much smaller than the number of words. In essence, LDA maps information from the word dimension to a semantic topic dimension, to address the shortcomings of the vector model. 3.2.2 User Profile Features We extract several user’s activity statistics to construct the user profile features, including the level 1725 of the user in the Community QA site, the number of questions asked by this user, the number of answers provided by this user, and the best answer ratio of this user. 3.2.3 User Authority Score Motivated by expert </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993–1022, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>John Cocke</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Fredrick Jelinek</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Paul S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Comput. Linguist.,</journal>
<pages>16--79</pages>
<contexts>
<context position="12018" citStr="Brown et al., 1990" startWordPosition="1932" endWordPosition="1935">e document. For example, Barack Obama and the president of the US are the same person. But the vector model would indicate them to be different. To remedy the wordmismatch problem, we also look for the relevance models in higher semantic levels. Translation Model A translation model is a mathematical model in which the language translation is modeled in a statistical way. The probability of translating a source sentence (as answer here) into target sentence (as question here) is obtained by aligning the words to maximize the product of all the word probabilities. We train a translation model (Brown et al., 1990; Och and Ney, 2003) using the Community QA data, with the question as the target language, and the corresponding best answer as the source language. With translation model, we can compute the translation score for new question and answer. Topic Model To reduce the false negatives of word mismatch in vector model, we also use the topic models to extend matching to semantic topic level. The topic model, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), considers a collection of documents with K latent topics, where K is much smaller than the number of words. In essence, LDA maps in</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>Peter F. Brown, John Cocke, Stephen A. Della Pietra, Vincent J. Della Pietra, Fredrick Jelinek, John D. Lafferty, Robert L. Mercer, and Paul S. Roossin. 1990. A statistical approach to machine translation. Comput. Linguist., 16:79–85, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S T Dumais</author>
<author>G W Furnas</author>
<author>T K Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American society for information science,</journal>
<pages>41--6</pages>
<contexts>
<context position="15453" citStr="Deerwester et al., 1990" startWordPosition="2549" endWordPosition="2552">{t0, t1, ..., tn}, where ti is the time point when posting the ith answer. We first convert the time sequence T to time interval sequence OT = {Ot0, Ot1, ..., Otn−1}, where Oti = ti+1 − ti. Based on the interval sequences for all users, we then construct a matrix Xm×b whose rows correspond to users and columns correspond to interval histogram with predefined range. We can use each row vector as time sequence pattern to detect robot. To reduce the noise and sparse problem, we use the dimension reduction techniques to extract the latent semantic features with Singular Value Decomposition (SVD) (Deerwester et al., 1990; Kim et al., 2006). 3.2.5 Evaluation from Other Users In the Community QA sites, other users can express their opinions or evaluations on the answer. For example, the asker can choose one of the answers as best answer. We use a bool feature to denote if this answer is selected as the best answer. In addition, other users can label each answer as “helpful” or “not helpful”. We also use this helpful evaluation by other users as the contextual feature, which is defined as the ratio between the number of “helpful” votes and the number of total votes. 3.2.6 Duplication with Other Answers The malic</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>S. Deerwester, S.T. Dumais, G.W. Furnas, T.K. Landauer, and R. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American society for information science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Figueroa</author>
<author>J Atkinson</author>
</authors>
<title>Maximum entropy context models for ranking biographical answers to open-domain definition questions.</title>
<date>2011</date>
<booktitle>In Twenty-Fifth AAAI Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="5934" citStr="Figueroa and Atkinson, 2011" startWordPosition="923" endWordPosition="927"> demonstrate that the user preference graph can further help improve the performance for deceptive answer prediction. 2 Related Work In the past few years, it has become a popular task to mine knowledge from the Community QA sites. Various studies, including retrieving the accumulated question-answer pairs to find the related answer for a new question, finding the expert in a specific domain, summarizing single or multiple answers to provide a concise result, are conducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction task. But these are still significant differences between two tasks. Answer quality p</context>
</contexts>
<marker>Figueroa, Atkinson, 2011</marker>
<rawString>A. Figueroa and J. Atkinson. 2011. Maximum entropy context models for ranking biographical answers to open-domain definition questions. In Twenty-Fifth AAAI Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Maxwell Harper</author>
<author>Daphne Raban</author>
<author>Sheizaf Rafaeli</author>
<author>Joseph A Konstan</author>
</authors>
<title>Predictors of answer quality in online q&amp;a sites.</title>
<date>2008</date>
<booktitle>In Proceedings of the twenty-sixth annual SIGCHI conference on Human factors in computing systems, CHI ’08,</booktitle>
<pages>865--874</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6347" citStr="Harper et al., 2008" startWordPosition="991" endWordPosition="994">iple answers to provide a concise result, are conducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction task. But these are still significant differences between two tasks. Answer quality prediction measures the overall quality of the answers, which refers to the accuracy, readability, completeness of the answer. While the deceptive answer prediction aims to predict if the main purpose of the provided answer is only to answer the specific question, or includes the user’s self-interest to promote something. Some of the previous work (Song et al., 2010; Ishikawa et al., 2010; Bian et al., 2009) vi</context>
</contexts>
<marker>Harper, Raban, Rafaeli, Konstan, 2008</marker>
<rawString>F. Maxwell Harper, Daphne Raban, Sheizaf Rafaeli, and Joseph A. Konstan. 2008. Predictors of answer quality in online q&amp;a sites. In Proceedings of the twenty-sixth annual SIGCHI conference on Human factors in computing systems, CHI ’08, pages 865– 874, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Ishikawa</author>
<author>Tetsuya Sakai</author>
<author>Noriko Kando</author>
</authors>
<date>2010</date>
<booktitle>Overview of the NTCIR-8 Community QA Pilot Task (Part I): The Test Collection and the Task,</booktitle>
<pages>421--432</pages>
<note>Number Part I.</note>
<contexts>
<context position="6397" citStr="Ishikawa et al., 2010" startWordPosition="1000" endWordPosition="1003">onducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction task. But these are still significant differences between two tasks. Answer quality prediction measures the overall quality of the answers, which refers to the accuracy, readability, completeness of the answer. While the deceptive answer prediction aims to predict if the main purpose of the provided answer is only to answer the specific question, or includes the user’s self-interest to promote something. Some of the previous work (Song et al., 2010; Ishikawa et al., 2010; Bian et al., 2009) views the “best answer” as high quality answers, whi</context>
</contexts>
<marker>Ishikawa, Sakai, Kando, 2010</marker>
<rawString>Daisuke Ishikawa, Tetsuya Sakai, and Noriko Kando, 2010. Overview of the NTCIR-8 Community QA Pilot Task (Part I): The Test Collection and the Task, pages 421–432. Number Part I.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwoon Jeon</author>
<author>W Bruce Croft</author>
<author>Joon Ho Lee</author>
</authors>
<title>Finding similar questions in large question and answer archives.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM CIKM conference, 05,</booktitle>
<pages>84--90</pages>
<publisher>ACM.</publisher>
<location>NY, USA.</location>
<contexts>
<context position="5828" citStr="Jeon et al., 2005" startWordPosition="903" endWordPosition="906">ame preference, tend to have the same category (deceptive or authentic). The experiment results demonstrate that the user preference graph can further help improve the performance for deceptive answer prediction. 2 Related Work In the past few years, it has become a popular task to mine knowledge from the Community QA sites. Various studies, including retrieving the accumulated question-answer pairs to find the related answer for a new question, finding the expert in a specific domain, summarizing single or multiple answers to provide a concise result, are conducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the decepti</context>
</contexts>
<marker>Jeon, Croft, Lee, 2005</marker>
<rawString>Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee. 2005. Finding similar questions in large question and answer archives. In Proceedings of the 14th ACM CIKM conference, 05, pages 84–90, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jeon</author>
<author>W B Croft</author>
<author>J H Lee</author>
<author>S Park</author>
</authors>
<title>A framework to predict the quality of answers with non-textual features.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>228--235</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="26470" citStr="Jeon et al., 2006" startWordPosition="4430" endWordPosition="4433">80 0.81 Table 2: Results With Textual and Contextual Features 5.2 Results with Textual and Contextual Features We tried several different classifiers, including SVM, ME and the linear weight models with least square and logistic regression. We find that they can achieve similar results. For simplicity, the linear weight with least square is employed in our experiment. Table 2 shows the experiment results. For textual features, it achieves much better result with unigram/bigram features than the random guess. This is very different from the answer quality prediction task. The previous studies (Jeon et al., 2006; Song et al., 2010) find that the word features can’t improve the performance on answer quality prediction. However, from Table 1, we can see that the word features can provide some weak signals for deceptive answer prediction, for example, words “recommend”, “address”, “professional” express some kinds of promotion intent. Besides unigram and bigram, the most effective textual feature is URL. The phone and email features perform similar results with URL. The observation of length feature for deceptive answer prediction is very different from previous answer quality prediction. For answer qua</context>
</contexts>
<marker>Jeon, Croft, Lee, Park, 2006</marker>
<rawString>J. Jeon, W.B. Croft, J.H. Lee, and S. Park. 2006. A framework to predict the quality of answers with non-textual features. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 228–235. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Jurczyk</author>
<author>E Agichtein</author>
</authors>
<title>Discovering authorities in question answer communities by using link analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM CIKM conference,</booktitle>
<pages>919--922</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="7544" citStr="Jurczyk and Agichtein, 2007" startWordPosition="1181" endWordPosition="1184">., 2010; Bian et al., 2009) views the “best answer” as high quality answers, which are selected by the askers in the Community QA sites. However, the deceptive answer may be selected as high-quality answer by the spammer, or because the general users are mislead. Meanwhile, some answers from non-native speakers may have linguistic errors, which are low-quality answers, but are still authentic answers. Our experiments also show that answer quality prediction is much different from deceptive answer prediction. Previous QA studies also analyze the user graph to investigate the user relationship (Jurczyk and Agichtein, 2007; Liu et al., 2011). They mainly construct the user graph with asker-answerer relationship to estimate the expertise score in Community QA sites. They assume the answerer is more knowledgeable than the asker. However, we don’t care which user is more knowledgeable, but are more likely to know if two users are both spammers or authentic users. In this paper, we propose a novel user preference graph based on their preference towards the target answers. We assume that the spammers may collaboratively promote the target deceptive answers, while the authentic users may generally promote the authent</context>
<context position="13126" citStr="Jurczyk and Agichtein, 2007" startWordPosition="2122" endWordPosition="2125">collection of documents with K latent topics, where K is much smaller than the number of words. In essence, LDA maps information from the word dimension to a semantic topic dimension, to address the shortcomings of the vector model. 3.2.2 User Profile Features We extract several user’s activity statistics to construct the user profile features, including the level 1725 of the user in the Community QA site, the number of questions asked by this user, the number of answers provided by this user, and the best answer ratio of this user. 3.2.3 User Authority Score Motivated by expert finding task (Jurczyk and Agichtein, 2007; Si et al., 2010a; Li et al., 2011), the second type of author related feature is authority score, which denotes the expertise score of this user. To compute the authority score, we first construct a directed user graph with the user interactions in the community. The nodes of the graph represent users. An edge between two users indicates a contribution from one user to the other. Specifically, on a Q&amp;A site, an edge from A to B is established when user B answered a question asked by A, which shows user B is more likely to be an expert than A. The weight of an edge indicates the number of int</context>
<context position="18329" citStr="Jurczyk and Agichtein, 2007" startWordPosition="3031" endWordPosition="3034">al answers to answer this question from other users, for example, answerers u2 and u3. After the answers are provides, users can also vote each answer as “helpful” or “not helpful” to show their evaluation towards the answer . For example, users u4, u5 vote the first answer as “not helpful”, and user u6 votes the second answer as “helpful”. Finally, the asker will select one answer as the best answer among all answers. For example, the asker u1 selects the first answer as the “best answer”. To mine the relationship among users, previous studies mainly focus on the asker-answerer relationship (Jurczyk and Agichtein, 2007; Liu et al., 2011). They assume the answerer is more knowledgeable than the asker. Based on this assumption, they can extract the expert in the community, as discussed in Section 3.2.3. However, we don’t care which user is more knowledgeable, but are more interested in whether two users are both malicious users or authentic users. Here, we propose a new user graph based on the user preference. The preference is defined based on the answer evaluation. If two users show same preference towards the target answer, they will have the user-preference relationship. We mainly use two kinds of informa</context>
</contexts>
<marker>Jurczyk, Agichtein, 2007</marker>
<rawString>P. Jurczyk and E. Agichtein. 2007. Discovering authorities in question answer communities by using link analysis. In Proceedings of the sixteenth ACM CIKM conference, pages 919–922. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kim</author>
<author>P Howland</author>
<author>H Park</author>
</authors>
<title>Dimension reduction in text classification with support vector machines.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="15472" citStr="Kim et al., 2006" startWordPosition="2553" endWordPosition="2556">ti is the time point when posting the ith answer. We first convert the time sequence T to time interval sequence OT = {Ot0, Ot1, ..., Otn−1}, where Oti = ti+1 − ti. Based on the interval sequences for all users, we then construct a matrix Xm×b whose rows correspond to users and columns correspond to interval histogram with predefined range. We can use each row vector as time sequence pattern to detect robot. To reduce the noise and sparse problem, we use the dimension reduction techniques to extract the latent semantic features with Singular Value Decomposition (SVD) (Deerwester et al., 1990; Kim et al., 2006). 3.2.5 Evaluation from Other Users In the Community QA sites, other users can express their opinions or evaluations on the answer. For example, the asker can choose one of the answers as best answer. We use a bool feature to denote if this answer is selected as the best answer. In addition, other users can label each answer as “helpful” or “not helpful”. We also use this helpful evaluation by other users as the contextual feature, which is defined as the ratio between the number of “helpful” votes and the number of total votes. 3.2.6 Duplication with Other Answers The malicious user may post </context>
</contexts>
<marker>Kim, Howland, Park, 2006</marker>
<rawString>H. Kim, P. Howland, and H. Park. 2006. Dimension reduction in text classification with support vector machines. Journal of Machine Learning Research, 6(1):37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Minlie Huang</author>
<author>Yi Yang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Learning to identify review spam.</title>
<date>2011</date>
<booktitle>In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Three,</booktitle>
<pages>2488--2493</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="13162" citStr="Li et al., 2011" startWordPosition="2130" endWordPosition="2133">here K is much smaller than the number of words. In essence, LDA maps information from the word dimension to a semantic topic dimension, to address the shortcomings of the vector model. 3.2.2 User Profile Features We extract several user’s activity statistics to construct the user profile features, including the level 1725 of the user in the Community QA site, the number of questions asked by this user, the number of answers provided by this user, and the best answer ratio of this user. 3.2.3 User Authority Score Motivated by expert finding task (Jurczyk and Agichtein, 2007; Si et al., 2010a; Li et al., 2011), the second type of author related feature is authority score, which denotes the expertise score of this user. To compute the authority score, we first construct a directed user graph with the user interactions in the community. The nodes of the graph represent users. An edge between two users indicates a contribution from one user to the other. Specifically, on a Q&amp;A site, an edge from A to B is established when user B answered a question asked by A, which shows user B is more likely to be an expert than A. The weight of an edge indicates the number of interactions. We compute the user’s aut</context>
</contexts>
<marker>Li, Huang, Yang, Zhu, 2011</marker>
<rawString>Fangtao Li, Minlie Huang, Yi Yang, and Xiaoyan Zhu. 2011. Learning to identify review spam. In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Three, pages 2488–2493. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanjie Liu</author>
<author>Shasha Li</author>
<author>Yunbo Cao</author>
<author>Chin-Yew Lin</author>
<author>Dingyi Han</author>
<author>Yong Yu</author>
</authors>
<title>Understanding and summarizing answers in community-based question answering services.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING ’08,</booktitle>
<pages>497--504</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5867" citStr="Liu et al., 2008" startWordPosition="911" endWordPosition="914">tegory (deceptive or authentic). The experiment results demonstrate that the user preference graph can further help improve the performance for deceptive answer prediction. 2 Related Work In the past few years, it has become a popular task to mine knowledge from the Community QA sites. Various studies, including retrieving the accumulated question-answer pairs to find the related answer for a new question, finding the expert in a specific domain, summarizing single or multiple answers to provide a concise result, are conducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction task. But these ar</context>
</contexts>
<marker>Liu, Li, Cao, Lin, Han, Yu, 2008</marker>
<rawString>Yuanjie Liu, Shasha Li, Yunbo Cao, Chin-Yew Lin, Dingyi Han, and Yong Yu. 2008. Understanding and summarizing answers in community-based question answering services. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING ’08, pages 497– 504, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Liu</author>
<author>Young-In Song</author>
<author>Chin-Yew Lin</author>
</authors>
<title>Competition-based user expertise score estimation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,</booktitle>
<pages>425--434</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="7563" citStr="Liu et al., 2011" startWordPosition="1185" endWordPosition="1188">iews the “best answer” as high quality answers, which are selected by the askers in the Community QA sites. However, the deceptive answer may be selected as high-quality answer by the spammer, or because the general users are mislead. Meanwhile, some answers from non-native speakers may have linguistic errors, which are low-quality answers, but are still authentic answers. Our experiments also show that answer quality prediction is much different from deceptive answer prediction. Previous QA studies also analyze the user graph to investigate the user relationship (Jurczyk and Agichtein, 2007; Liu et al., 2011). They mainly construct the user graph with asker-answerer relationship to estimate the expertise score in Community QA sites. They assume the answerer is more knowledgeable than the asker. However, we don’t care which user is more knowledgeable, but are more likely to know if two users are both spammers or authentic users. In this paper, we propose a novel user preference graph based on their preference towards the target answers. We assume that the spammers may collaboratively promote the target deceptive answers, while the authentic users may generally promote the authentic answers and demo</context>
<context position="18348" citStr="Liu et al., 2011" startWordPosition="3035" endWordPosition="3038">stion from other users, for example, answerers u2 and u3. After the answers are provides, users can also vote each answer as “helpful” or “not helpful” to show their evaluation towards the answer . For example, users u4, u5 vote the first answer as “not helpful”, and user u6 votes the second answer as “helpful”. Finally, the asker will select one answer as the best answer among all answers. For example, the asker u1 selects the first answer as the “best answer”. To mine the relationship among users, previous studies mainly focus on the asker-answerer relationship (Jurczyk and Agichtein, 2007; Liu et al., 2011). They assume the answerer is more knowledgeable than the asker. Based on this assumption, they can extract the expert in the community, as discussed in Section 3.2.3. However, we don’t care which user is more knowledgeable, but are more interested in whether two users are both malicious users or authentic users. Here, we propose a new user graph based on the user preference. The preference is defined based on the answer evaluation. If two users show same preference towards the target answer, they will have the user-preference relationship. We mainly use two kinds of information: “helpful” eva</context>
</contexts>
<marker>Liu, Song, Lin, 2011</marker>
<rawString>Jing Liu, Young-In Song, and Chin-Yew Lin. 2011. Competition-based user expertise score estimation. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pages 425–434. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Panayiotis Tsaparas</author>
<author>Alexandros Ntoulas</author>
<author>Livia Polanyi</author>
</authors>
<title>Exploiting social context for review quality prediction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th international conference on World wide web,</booktitle>
<pages>691--700</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="21381" citStr="Lu et al., 2010" startWordPosition="3558" endWordPosition="3561">mong users. Although there maybe noisy relationship, for example, an authentic user may be cheated, and selects the deceptive answer as “best answer”, we hope the overall user preference relation can perform better results than previous user interaction graph for this task. 1727 4.2 Incorporating User Preference Graph To use the user graph, we can just compute the feature value from the graph, and add it into the supervised method as the features introduced in Section 3. Here, we propose a new technique to employ the user preference graph. We utilize the graph regularizer (Zhang et al., 2006; Lu et al., 2010) to constrain the supervised parameter learning. We will introduce this technique based on a commonly used model f(·), the linear weight model, where the function value is determined by linear combination of the input features: Xf(xi) = wT · xi = wk · xik (2) k where xi is a K dimension feature vector for the ith answer, the parameter value wk captures the effect of the kth feature in predicting the deceptive answer. The best parameters w* can be found by minimizing the following objective function: XQ1(w) = L(wT xi, yi) + α · |w|2F (3) i where L(wTxi,yi) is a loss function that measures discr</context>
</contexts>
<marker>Lu, Tsaparas, Ntoulas, Polanyi, 2010</marker>
<rawString>Yue Lu, Panayiotis Tsaparas, Alexandros Ntoulas, and Livia Polanyi. 2010. Exploiting social context for review quality prediction. In Proceedings of the 19th international conference on World wide web, pages 691–700. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.,</journal>
<pages>29--19</pages>
<contexts>
<context position="12038" citStr="Och and Ney, 2003" startWordPosition="1936" endWordPosition="1939">ple, Barack Obama and the president of the US are the same person. But the vector model would indicate them to be different. To remedy the wordmismatch problem, we also look for the relevance models in higher semantic levels. Translation Model A translation model is a mathematical model in which the language translation is modeled in a statistical way. The probability of translating a source sentence (as answer here) into target sentence (as question here) is obtained by aligning the words to maximize the product of all the word probabilities. We train a translation model (Brown et al., 1990; Och and Ney, 2003) using the Community QA data, with the question as the target language, and the corresponding best answer as the source language. With translation model, we can compute the translation score for new question and answer. Topic Model To reduce the false negatives of word mismatch in vector model, we also use the topic models to extend matching to semantic topic level. The topic model, such as Latent Dirichlet Allocation (LDA) (Blei et al., 2003), considers a collection of documents with K latent topics, where K is much smaller than the number of words. In essence, LDA maps information from the w</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist., 29:19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1999</date>
<tech>Technical Report 1999-66,</tech>
<pages>1999--0120</pages>
<institution>Stanford InfoLab,</institution>
<contexts>
<context position="9748" citStr="Page et al., 1999" startWordPosition="1544" endWordPosition="1547"> hospital expert Table 1: Top 10 Deceptive Related Unigrams 3.1.2 URL Features Some malicious users may promote their products by linking a URL. We find that URL is good indicator for deceptive answers. However, some URLs may provide the references for the authentic answers. For example, if you ask the weather in mountain view, someone may just post the link to ”http://www.weather.com/”. Therefore, besides the existence of URL, we also use the following URL features: 1). Length of the URLs: we observe that the longer urls are more likely to be spam. 2). PageRank Score: We employ the PageRank (Page et al., 1999) score of each URL as popularity score. 3.1.3 Phone Numbers and Emails There are a lot of contact information mentioned in the Community QA sites, such as phone numbers and email addresses, which are very likely to be deceptive, as good answers are found to be less likely to refer to phone numbers or email addresses than the malicious ones. We extract the number of occurrences of email and phone numbers as features. 3.1.4 Length We have also observed some interesting patterns about the length of answer. Deceptive ones tend to be longer than authentic ones. This can be explained as the deceptiv</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The pagerank citation ranking: Bringing order to the web. Technical Report 1999-66, Stanford InfoLab, November. SIDL-WP1999-0120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>311--318</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="16535" citStr="Papineni et al., 2002" startWordPosition="2738" endWordPosition="2741"> is defined as the ratio between the number of “helpful” votes and the number of total votes. 3.2.6 Duplication with Other Answers The malicious user may post the pre-written product promotion documents to many answers, or just change the product name. We also compute the similarity between different answers. If the two answers are totally same, but the question is different, these answer is potentially as a deceptive answer. Here, we don’t want to measure the semantic similarity between two answers, but just measure if two answers are similar to the word level, therefore, we apply BleuScore (Papineni et al., 2002), which is a standard metric in machine translation for measuring the overlap between n-grams of two text fragments r and c. The duplication score of each answer is the maximum BleuScore compared to all other answers. 4 Deceptive Answer Prediction with User Preference Graph Besides the textual and contextual features, we also investigate the user relationship for deceptive answer prediction. We assume that similar users tend to perform similar behaviors (posting deceptive answers or posting authentic answers). In this section, we first show how to compute the user similarity (user preference g</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 311–318, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Michael J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1986</date>
<publisher>McGrawHill, Inc.,</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="11242" citStr="Salton and McGill, 1986" startWordPosition="1799" endWordPosition="1802">3.2.1 Question Answer Relevance The main characteristic of answer in Community QA site is that the answer is provided to answer the corresponding question. We can use the corresponding question as one of the context features by measuring the relevance between the answer and the question. We employ three different models for Question-Answer relevance: Vector Space Model Each answer or question is viewed as a word vector. Given a question q and the answer a, our vector model uses weighted word counts(e.g.TFIDF) as well as the cosine similarity (q · a) of their word vectors as relevant function (Salton and McGill, 1986). However, vector model only consider the exact word match, which is a big problem, especially when the question and answer are generally short compared to the document. For example, Barack Obama and the president of the US are the same person. But the vector model would indicate them to be different. To remedy the wordmismatch problem, we also look for the relevance models in higher semantic levels. Translation Model A translation model is a mathematical model in which the language translation is modeled in a statistical way. The probability of translating a source sentence (as answer here) i</context>
</contexts>
<marker>Salton, McGill, 1986</marker>
<rawString>Gerard Salton and Michael J. McGill. 1986. Introduction to Modern Information Retrieval. McGrawHill, Inc., New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chirag Shah</author>
<author>Jefferey Pomerantz</author>
</authors>
<title>Evaluating and predicting answer quality in community qa.</title>
<date>2010</date>
<booktitle>In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’10,</booktitle>
<pages>411--418</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6373" citStr="Shah and Pomerantz, 2010" startWordPosition="995" endWordPosition="999">de a concise result, are conducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction task. But these are still significant differences between two tasks. Answer quality prediction measures the overall quality of the answers, which refers to the accuracy, readability, completeness of the answer. While the deceptive answer prediction aims to predict if the main purpose of the provided answer is only to answer the specific question, or includes the user’s self-interest to promote something. Some of the previous work (Song et al., 2010; Ishikawa et al., 2010; Bian et al., 2009) views the “best answer” as h</context>
<context position="27222" citStr="Shah and Pomerantz, 2010" startWordPosition="4548" endWordPosition="4551"> 1, we can see that the word features can provide some weak signals for deceptive answer prediction, for example, words “recommend”, “address”, “professional” express some kinds of promotion intent. Besides unigram and bigram, the most effective textual feature is URL. The phone and email features perform similar results with URL. The observation of length feature for deceptive answer prediction is very different from previous answer quality prediction. For answer quality prediction, length is an effective feature, for example, long-length provides very strong signals for high-quality answer (Shah and Pomerantz, 2010; Song et al., 2010). However, for deceptive answer prediction, we find that the long answers are more potential to be deceptive. This is because most of deceptive answers are well prepared for product promotion. They will write detailed answers to attract user’s attention and promote their products. Finally, with all textual features, the experiment achieves the best result, 0.65 in accuracy. For contextual features, we can see that, the most effective contextual feature is answer duplication. The malicious users may copy the prepared deceptive answers or just simply edit the target name to a</context>
</contexts>
<marker>Shah, Pomerantz, 2010</marker>
<rawString>Chirag Shah and Jefferey Pomerantz. 2010. Evaluating and predicting answer quality in community qa. In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’10, pages 411–418, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Si</author>
<author>Z Gyongyi</author>
<author>E Y Chang</author>
</authors>
<title>Scalable mining of topic-dependent user reputation for improving user generated content search quality. In Google</title>
<date>2010</date>
<tech>Technical Report.</tech>
<contexts>
<context position="5903" citStr="Si et al., 2010" startWordPosition="919" endWordPosition="922">experiment results demonstrate that the user preference graph can further help improve the performance for deceptive answer prediction. 2 Related Work In the past few years, it has become a popular task to mine knowledge from the Community QA sites. Various studies, including retrieving the accumulated question-answer pairs to find the related answer for a new question, finding the expert in a specific domain, summarizing single or multiple answers to provide a concise result, are conducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction task. But these are still significant differences betw</context>
<context position="13143" citStr="Si et al., 2010" startWordPosition="2126" endWordPosition="2129">K latent topics, where K is much smaller than the number of words. In essence, LDA maps information from the word dimension to a semantic topic dimension, to address the shortcomings of the vector model. 3.2.2 User Profile Features We extract several user’s activity statistics to construct the user profile features, including the level 1725 of the user in the Community QA site, the number of questions asked by this user, the number of answers provided by this user, and the best answer ratio of this user. 3.2.3 User Authority Score Motivated by expert finding task (Jurczyk and Agichtein, 2007; Si et al., 2010a; Li et al., 2011), the second type of author related feature is authority score, which denotes the expertise score of this user. To compute the authority score, we first construct a directed user graph with the user interactions in the community. The nodes of the graph represent users. An edge between two users indicates a contribution from one user to the other. Specifically, on a Q&amp;A site, an edge from A to B is established when user B answered a question asked by A, which shows user B is more likely to be an expert than A. The weight of an edge indicates the number of interactions. We com</context>
<context position="23695" citStr="Si et al., 2010" startWordPosition="3964" endWordPosition="3967">th same preference. Aui is the set of all answers posted by user ui. wui,uj is the weight of edge between ui and uj in user preference graph. In the above objective function, we impose a user graph regularization term 0 X X wui,uj(f(x) − f(y))2 ui,ujENu xEAui,yEAuj to minimize the answer authenticity difference among users with same preference. This regularization term smoothes the labels on the graph structure, where adjacent users with same preference tend to post answers with same label. 5 Experiments 5.1 Experiment Setting 5.1.1 Dataset Construction In this paper, we employ the Confucius (Si et al., 2010b) data to construct the deceptive answer dataset. Confucius is a community question answering site, developed by Google. We first crawled about 10 million question threads within a time range. Among these data, we further sample a small data set, and ask three trained annotators to manually label the answer as deceptive or not. If two or more people annotate the answer as deceptive, we will extract this answer as a deceptive answer. In total, 12446 answers are marked as deceptive answers. Similarly, we also manually annotate 12446 authentic answers. Finally, we get 24892 answers with deceptiv</context>
</contexts>
<marker>Si, Gyongyi, Chang, 2010</marker>
<rawString>X. Si, Z. Gyongyi, and E. Y. Chang. 2010a. Scalable mining of topic-dependent user reputation for improving user generated content search quality. In Google Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiance Si</author>
<author>Edward Y Chang</author>
<author>Zolt´an Gy¨ongyi</author>
<author>Maosong Sun</author>
</authors>
<title>Confucius and its intelligent disciples: integrating social with search.</title>
<date>2010</date>
<booktitle>Proc. VLDB Endow.,</booktitle>
<pages>3--1505</pages>
<marker>Si, Chang, Gy¨ongyi, Sun, 2010</marker>
<rawString>Xiance Si, Edward Y. Chang, Zolt´an Gy¨ongyi, and Maosong Sun. 2010b. Confucius and its intelligent disciples: integrating social with search. Proc. VLDB Endow., 3:1505–1516, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-In Song</author>
<author>Chin-Yew Lin</author>
<author>Yunbo Cao</author>
<author>HaeChang Rim</author>
</authors>
<title>Question utility: a novel static ranking of question search.</title>
<date>2008</date>
<booktitle>In Proceedings of the 23rd national conference on Artificial intelligence - Volume 2, AAAI’08,</booktitle>
<pages>1231--1236</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="5886" citStr="Song et al., 2008" startWordPosition="915" endWordPosition="918">or authentic). The experiment results demonstrate that the user preference graph can further help improve the performance for deceptive answer prediction. 2 Related Work In the past few years, it has become a popular task to mine knowledge from the Community QA sites. Various studies, including retrieving the accumulated question-answer pairs to find the related answer for a new question, finding the expert in a specific domain, summarizing single or multiple answers to provide a concise result, are conducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction task. But these are still significant</context>
</contexts>
<marker>Song, Lin, Cao, Rim, 2008</marker>
<rawString>Young-In Song, Chin-Yew Lin, Yunbo Cao, and HaeChang Rim. 2008. Question utility: a novel static ranking of question search. In Proceedings of the 23rd national conference on Artificial intelligence - Volume 2, AAAI’08, pages 1231–1236. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y I Song</author>
<author>J Liu</author>
<author>T Sakai</author>
<author>X J Wang</author>
<author>G Feng</author>
<author>Y Cao</author>
<author>H Suzuki</author>
<author>C Y Lin</author>
</authors>
<title>Microsoft research asia with redmond at the ntcir-8 community qa pilot task.</title>
<date>2010</date>
<booktitle>In Proceedings of NTCIR.</booktitle>
<contexts>
<context position="6326" citStr="Song et al., 2010" startWordPosition="987" endWordPosition="990">zing single or multiple answers to provide a concise result, are conducted in the Community QA sites (Jeon et al., 2005; Adamic et al., 2008; Liu et al., 2008; Song et al., 2008; Si et al., 2010a; Figueroa and Atkinson, 2011). However, an important issue which has been neglected so far is the detection of deceptive answers. If the acquired question-answer corpus contains many deceptive answers, it would be meaningless to perform further knowledge mining tasks. Therefore, as the first step, we need to predict and filter out the deceptive answers. Among previous work, answer quality prediction (Song et al., 2010; Harper et al., 2008; Shah and Pomerantz, 2010; Ishikawa et al., 2010) is most related to the deceptive answer prediction task. But these are still significant differences between two tasks. Answer quality prediction measures the overall quality of the answers, which refers to the accuracy, readability, completeness of the answer. While the deceptive answer prediction aims to predict if the main purpose of the provided answer is only to answer the specific question, or includes the user’s self-interest to promote something. Some of the previous work (Song et al., 2010; Ishikawa et al., 2010; </context>
<context position="26490" citStr="Song et al., 2010" startWordPosition="4434" endWordPosition="4437">sults With Textual and Contextual Features 5.2 Results with Textual and Contextual Features We tried several different classifiers, including SVM, ME and the linear weight models with least square and logistic regression. We find that they can achieve similar results. For simplicity, the linear weight with least square is employed in our experiment. Table 2 shows the experiment results. For textual features, it achieves much better result with unigram/bigram features than the random guess. This is very different from the answer quality prediction task. The previous studies (Jeon et al., 2006; Song et al., 2010) find that the word features can’t improve the performance on answer quality prediction. However, from Table 1, we can see that the word features can provide some weak signals for deceptive answer prediction, for example, words “recommend”, “address”, “professional” express some kinds of promotion intent. Besides unigram and bigram, the most effective textual feature is URL. The phone and email features perform similar results with URL. The observation of length feature for deceptive answer prediction is very different from previous answer quality prediction. For answer quality prediction, len</context>
</contexts>
<marker>Song, Liu, Sakai, Wang, Feng, Cao, Suzuki, Lin, 2010</marker>
<rawString>Y.I. Song, J. Liu, T. Sakai, X.J. Wang, G. Feng, Y. Cao, H. Suzuki, and C.Y. Lin. 2010. Microsoft research asia with redmond at the ntcir-8 community qa pilot task. In Proceedings of NTCIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wei</author>
<author>Gao Cong</author>
<author>Xiaoli Li</author>
<author>See-Kiong Ng</author>
<author>Guohui Li</author>
</authors>
<title>Integrating community question and answer archives.</title>
<date>2011</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="2510" citStr="Wei et al., 2011" startWordPosition="372" endWordPosition="375">http://wiki.answers.com sites are growing rapidly in popularity. Currently there are hundreds of millions of answers and millions of questions accumulated on the Community QA sites. These resources of past questions and answers are proving to be a valuable knowledge base. From the Community QA sites, users can directly get the answers to meet some specific information need, rather than browse the list of returned documents to find the answers. Hence, in recent years, knowledge mining in Community QA sites has become a popular topic in the field of artificial intelligence (Adamic et al., 2008; Wei et al., 2011). However, some answers may be deceptive. In the Community QA sites, there are millions of users each day. As the answers can guide the user’s behavior, some malicious users are motivated to give deceptive answers to promote their products or services. For example, if someone asks for recommendations about restaurants in the Community QA site, the malicious user may post a deceptive answer to promote the target restaurant. Indeed, because of lucrative financial rewards, in several Community QA sites, some business owners provide incentives for users to post deceptive answers for product promot</context>
</contexts>
<marker>Wei, Cong, Li, Ng, Li, 2011</marker>
<rawString>Wei Wei, Gao Cong, Xiaoli Li, See-Kiong Ng, and Guohui Li. 2011. Integrating community question and answer archives. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Yang</author>
<author>J O Pedersen</author>
</authors>
<title>A comparative study on feature selection in text categorization.</title>
<date>1997</date>
<booktitle>In MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE-,</booktitle>
<pages>412--420</pages>
<publisher>MORGAN KAUFMANN PUBLISHERS.</publisher>
<contexts>
<context position="8864" citStr="Yang and Pedersen, 1997" startWordPosition="1394" endWordPosition="1397">heir answer evaluation, such as “helpful” voting or “best answer” selection. 3 Proposed Features We first view the deceptive answer prediction as a binary-classification problem. Two kinds of features, including textual features and contextual features, are described as follows: 3.1 Textual Features We first aim to predict the deceptive answer by analyzing the answer content. Several textual features are extracted from the answer content: 3.1.1 Unigrams and Bigrams The most common type of feature for text classification is the bag-of-word. We use an effective 1724 feature selection method x2 (Yang and Pedersen, 1997) to select the top 200 unigrams and bigrams as features. The top ten unigrams related to deceptive answers are shown on Table 1. We can see that these words are related to the intent for promotion. professional service advice address site telephone therapy recommend hospital expert Table 1: Top 10 Deceptive Related Unigrams 3.1.2 URL Features Some malicious users may promote their products by linking a URL. We find that URL is good indicator for deceptive answers. However, some URLs may provide the references for the authentic answers. For example, if you ask the weather in mountain view, some</context>
</contexts>
<marker>Yang, Pedersen, 1997</marker>
<rawString>Y. Yang and J.O. Pedersen. 1997. A comparative study on feature selection in text categorization. In MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE-, pages 412– 420. MORGAN KAUFMANN PUBLISHERS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tong Zhang</author>
<author>Alexandrin Popescul</author>
<author>Byron Dom</author>
</authors>
<title>Linear prediction models with graph regularization for web-page categorization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>821--826</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="21363" citStr="Zhang et al., 2006" startWordPosition="3554" endWordPosition="3557">s the relationship among users. Although there maybe noisy relationship, for example, an authentic user may be cheated, and selects the deceptive answer as “best answer”, we hope the overall user preference relation can perform better results than previous user interaction graph for this task. 1727 4.2 Incorporating User Preference Graph To use the user graph, we can just compute the feature value from the graph, and add it into the supervised method as the features introduced in Section 3. Here, we propose a new technique to employ the user preference graph. We utilize the graph regularizer (Zhang et al., 2006; Lu et al., 2010) to constrain the supervised parameter learning. We will introduce this technique based on a commonly used model f(·), the linear weight model, where the function value is determined by linear combination of the input features: Xf(xi) = wT · xi = wk · xik (2) k where xi is a K dimension feature vector for the ith answer, the parameter value wk captures the effect of the kth feature in predicting the deceptive answer. The best parameters w* can be found by minimizing the following objective function: XQ1(w) = L(wT xi, yi) + α · |w|2F (3) i where L(wTxi,yi) is a loss function t</context>
</contexts>
<marker>Zhang, Popescul, Dom, 2006</marker>
<rawString>Tong Zhang, Alexandrin Popescul, and Byron Dom. 2006. Linear prediction models with graph regularization for web-page categorization. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 821–826. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>