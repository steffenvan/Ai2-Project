<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002254">
<title confidence="0.985296">
Exploring Features for Identifying Edited Regions in Disfluent Sentences
</title>
<author confidence="0.999048">
Qi Zhang Fuliang Weng
</author>
<affiliation confidence="0.998257">
Department of Computer Science Research and Technology Center
Fudan University Robert Bosch Corp.
</affiliation>
<address confidence="0.506678">
Shanghai, P.R.China 200433 Palo Alto, CA 94304
</address>
<email confidence="0.990956">
qi_zhang@fudan.edu.cn fuliang.weng@rtc.bosch.com
</email>
<sectionHeader confidence="0.996531" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999790095238095">
This paper describes our effort on the task
of edited region identification for parsing
disfluent sentences in the Switchboard
corpus. We focus our attention on
exploring feature spaces and selecting
good features and start with analyzing the
distributions of the edited regions and
their components in the targeted corpus.
We explore new feature spaces of a part-
of-speech (POS) hierarchy and relaxed for
rough copy in the experiments. These
steps result in an improvement of 43.98%
percent relative error reduction in F-score
over an earlier best result in edited
detection when punctuation is included in
both training and testing data [Charniak
and Johnson 2001], and 20.44% percent
relative error reduction in F-score over the
latest best result where punctuation is
excluded from the training and testing
data [Johnson and Charniak 2004].
</bodyText>
<sectionHeader confidence="0.998884" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999562977777778">
Repairs, hesitations, and restarts are common in
spoken language, and understanding spoken
language requires accurate methods for identifying
such disfluent phenomena. Processing speech
repairs properly poses a challenge to spoken dialog
systems. Early work in this field is primarily based
on small and proprietary corpora, which makes the
comparison of the proposed methods difficult
[Young and Matessa 1991, Bear et al. 1992,
Heeman &amp; Allen 1994]. Because of the availability
of the Switchboard corpus [Godfrey et al. 1992]
and other conversational telephone speech (CTS)
corpora, there has been an increasing interest in
improving the performance of identifying the
edited regions for parsing disfluent sentences
[Charniak and Johnson 2001, Johnson and
Charniak 2004, Ostendorf et al. 2004, Liu et al.
2005].
In this paper we describe our effort towards the
task of edited region identification with the
intention of parsing disfluent sentences in the
Switchboard corpus. A clear benefit of having
accurate edited regions for parsing has been
demonstrated by a concurrent effort on parsing
conversational speech [Kahn et al 2005]. Since
different machine learning methods provide similar
performances on many NLP tasks, in this paper,
we focus our attention on exploring feature spaces
and selecting good features for identifying edited
regions. We start by analyzing the distributions of
the edited regions and their components in the
targeted corpus. We then design several feature
spaces to cover the disfluent regions in the training
data. In addition, we also explore new feature
spaces of a part-of-speech hierarchy and extend
candidate pools in the experiments. These steps
result in a significant improvement in F-score over
the earlier best result reported in [Charniak and
Johnson 2001], where punctuation is included in
both the training and testing data of the
Switchboard corpus, and a significant error
reduction in F-score over the latest best result
[Johnson and Charniak 2004], where punctuation
is ignored in both the training and testing data of
the Switchboard corpus.
</bodyText>
<page confidence="0.982619">
179
</page>
<bodyText confidence="0.980543307692308">
Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 179–185,
Vancouver, October 2005. c�2005 Association for Computational Linguistics
In this paper, we follow the definition of [Shriberg
1994] and others for speech repairs: A speech
repair is divided into three parts: the reparandum,
the part that is repaired; the interregnum, the part
that can be either empty or fillers; and the
repair/repeat, the part that replaces or repeats the
reparandum. The definition can also be
exemplified via the following utterance:
without punctuation are given in Fig. 1. The
reparanda with lengths of less than 7 words make
up 95.98% of such edited regions in the training
data. When we remove the punctuation marks,
those with lengths of less than 6 words reach
roughly 96%. Thus, the patterns that consider only
reparanda of length 6 or less will have very good
coverage.
This paper is organized as follows. In section 2, we
examine the distributions of the editing regions in
Switchboard data. Section 3, then, presents the
Boosting method, the baseline system and the
feature spaces we want to explore. Section 4
describes, step by step, a set of experiments that
lead to a large performance improvement. Section
5 concludes with discussion and future work.
</bodyText>
<sectionHeader confidence="0.960679" genericHeader="method">
2 Repair Distributions in Switchboard
</sectionHeader>
<bodyText confidence="0.999838269230769">
We start by analyzing the speech repairs in the
Switchboard corpus. Switchboard has over one
million words, with telephone conversations on
prescribed topics [Godfrey et al. 1992]. It is full of
disfluent utterances, and [Shriberg 1994, Shriberg
1996] gives a thorough analysis and categorization
of them. [Engel et al. 2002] also showed detailed
distributions of the interregnum, including
interjections and parentheticals. Since the majority
of the disfluencies involve all the three parts
(reparandum, interregnum, and repair/repeat), the
distributions of all three parts will be very helpful
in constructing patterns that are used to identify
edited regions.
For the reparandum and repair types, we include
their distributions with and without punctuation.
We include the distributions with punctuation is to
match with the baseline system reported in
[Charniak and Johnson 2001], where punctuation
is included to identify the edited regions. Resent
research showed that certain punctuation/prosody
marks can be produced when speech signals are
available [Liu et al. 2003]. The interregnum type,
by definition, does not include punctuation.
The length distributions of the reparanda in the
training part of the Switchboard data with and
</bodyText>
<figureCaption confidence="0.977146666666667">
Figure 1. Length distribution of reparanda in
Switchboard training data.
Figure 2. Length distribution of
repairs/repeats/restarts in Switchboard training data.
Figure 3. Length distribution of interregna in
Switchboard training data.
</figureCaption>
<bodyText confidence="0.999596">
The two repair/repeat part distributions in the
training part of the Switchboard are given in Fig. 2.
The repairs/repeats with lengths less than 7 words
</bodyText>
<figure confidence="0.996844548387097">
50%
40%
30%
20%
10%
0%
1 2 3 4 5 6 7 8 9 10
Length distribution of reparanda
With punctation Without punctation
Length distribution of
repairs/repeats/restarts
0 1 2 3 4 5 6 7 8 9
With punctation Without punctation
50%
40%
30%
20%
10%
0%
Length distribution of interregna
100%
80%
60%
40%
20%
0%
0 1 2 3 4 5 6 7 8 9 10
This ���is, you �����know, this is a big problem.
N
reparandarepeat
interregnum
</figure>
<page confidence="0.975736">
180
</page>
<bodyText confidence="0.9881605">
make 98.86% of such instances in the training data.
This gives us an excellent coverage if we use 7 as
the threshold for constructing repair/repeat patterns.
The length distribution of the interregna of the
training part of the Switchboard corpus is shown in
Fig. 3. We see that the overwhelming majority has
the length of one, which are mostly words such as
“uh”, “yeah”, or “uh-huh”.
In examining the Switchboard data, we noticed that
a large number of reparanda and repair/repeat pairs
differ on less than two words, i.e. “as to, you know,
when to”1, and the amount of the pairs differing on
less than two POS tags is even bigger. There are
also cases where some of the pairs have different
lengths. These findings provide a good base for our
feature space.
</bodyText>
<sectionHeader confidence="0.964368" genericHeader="method">
3 Feature Space Selection for Boosting
</sectionHeader>
<bodyText confidence="0.99996775">
We take as our baseline system the work by
[Charniak and Johnson 2001]. In their approach,
rough copy is defined to produce candidates for
any potential pairs of reparanda and repairs. A
boosting algorithm [Schapire and Singer 1999] is
used to detect whether a word is edited. A total of
18 variables are used in the algorithm. In the rest
of the section, we first briefly introduce the
boosting algorithm, then describe the method used
in [Charniak and Johnson 2001], and finally we
contrast our improvements with the baseline
system.
</bodyText>
<subsectionHeader confidence="0.999876">
3.1 Boosting Algorithm
</subsectionHeader>
<bodyText confidence="0.970743">
Intuitively, the boosting algorithm is to combine a
set of simple learners iteratively based on their
classification results on a set of training data.
Different parts of the training data are scaled at
each iteration so that the parts of the data previous
classifiers performed poorly on are weighted
higher. The weighting factors of the learners are
adjusted accordingly.
We re-implement the boosting algorithm reported
by [Charniak and Johnson 2001] as our baseline
system in order to clearly identify contributing
1 “as to” is the edited region. Italicized words in the
examples are edited words
factors in performance. Each word token is
characterized by a finite tuple of random variables
(Y,X1,...,Xm).
Y is the conditioned variables and ranges from
{-1,+1}, with Y = +1 indicating that the word is
edited. X1,...,Xm are the conditioning variables;
each variable Xj ranges over a finite set Xj . The
goal of the classifer is to predict the value of Y
given a value for X1,...,Xm.
A boosting classifier is a linear combination of n
features to define the prediction variable Z.
</bodyText>
<equation confidence="0.9782735">
α (1)
iFi
</equation>
<bodyText confidence="0.999260333333333">
where αi is the weight to be estimated for feature Oi.
Oi is a set of variable-value pairs, and each Fi has
the form of:
</bodyText>
<equation confidence="0.998166333333333">
Fi = (X j = x j)
11 (2)
&lt;Xj ,x j &gt;EOi
</equation>
<bodyText confidence="0.839623">
with X’s being conditioning variables and x’s being
values.
Each component in the production for Fi is
defined as:
</bodyText>
<equation confidence="0.9972095">
h &lt; Xi = xi &gt;E Oi
tO otherwise (3)
</equation>
<bodyText confidence="0.9216808">
In other words, Fi is 1 if and only if all the
variable-value pairs for the current position belong
to Oi.
The prediction made by the classifier is
sign(Z) = Z/  |Z |. Intuitively, our goal is to adjust
</bodyText>
<equation confidence="0.78829">
K
</equation>
<bodyText confidence="0.989657">
the vector of feature weights α = (α1 ,...., αn) to
minimize the expected misclassification rate
E[sign(Z) # Y] . This function is difficult to
minimize, so our boosting classifier minimizes the
</bodyText>
<equation confidence="0.666703333333333">
ˆ
expected boost loss Et[(exp(-YZ)] as in [Collins
ˆ
</equation>
<bodyText confidence="0.952683428571429">
2000], where E t[.] is the expectation on the
empirical training corpus distribution. In our
implementation, each learner contains only one
variable. The feature weights are adjusted
iteratively, one weight per iteration. At each
iteration, it reduces the boost loss on the training
corpus. In our experiments, αK is obtained after
</bodyText>
<equation confidence="0.9897222">
n
Z
�=
i 1
(Xj = x j) =
</equation>
<page confidence="0.920991">
181
</page>
<bodyText confidence="0.8318085">
1500 iterations, and contains around 1350 non-zero sequences of an interregnum string (see
feature weights. below) followed by optional punctuation.
</bodyText>
<subsectionHeader confidence="0.999319">
3.2 Charniak-Johnson approach
</subsectionHeader>
<bodyText confidence="0.994948117647059">
In [Charniak and Johnson 2001], identifying edited
regions is considered as a classification problem,
where each word is classified either as edited or
normal. The approach takes two steps. The first
step is to find rough copy. Then, a number of
variables are extracted for the boosting algorithm.
In particular, a total of 18 different conditioning
variables are used to predict whether the current
word is an edited word or a non-edited word. The
18 different variables listed in Table 1 correspond
to the 18 different dimensions/factors for the
current word position. Among the 18 variables, six
of them, Nm, Nu, Ni, Nl, Nr and Tf , depend on the
identification of a rough copy.
For convenience, their definition of a rough copy is
repeated here. A rough copy in a string of tagged
words has the form of ∂1βλ∂2 , where:
</bodyText>
<listItem confidence="0.9848736">
1. ∂1 (the source) and ∂2 (the copy) both
begin with non-punctuation,
2. the strings of non-punctuation POS tag
of ∂1 and ∂2 are identical,
3. β (the free final) consists of zero or
</listItem>
<bodyText confidence="0.917376125">
more sequences of a free final word (see
below) followed by optional punctuation,
4. λ (the interregnum) consists of
The set of free final words includes all partial
words and a small set of conjunctions, adverbs and
miscellanea. The set of interregnum strings
consists of a small set of expressions such as uh,
you know, I guess, I mean, etc.
</bodyText>
<subsectionHeader confidence="0.998919">
3.3 New Improvements
</subsectionHeader>
<bodyText confidence="0.9999376">
Our improvements to the Charniak-Johnson
method can be classified into three categories with
the first two corresponding to the twp steps in their
method. The three categories of improvements are
described in details in the following subsections.
</bodyText>
<subsectionHeader confidence="0.827238">
3.3.1 Relaxing Rough Copy
</subsectionHeader>
<bodyText confidence="0.999968769230769">
We relax the definition for rough copy, because
more than 94% of all edits have both reparandum
and repair, while the rough copy defined in
[Charniak and Johnson 2001] only covers 77.66%
of such instances.
Two methods are used to relax the rough copy
definition. The first one is to adopt a hierarchical
POS tag set: all the Switchboard POS tags are
further classified into four major categories: N
(noun related), V (verb related), Adj (noun
modifiers), Adv (verb modifiers). Instead of
requiring the exact match of two POS tag
sequences, we also consider two sequences as a
</bodyText>
<table confidence="0.962839">
Variables Name Short description
X1 W0 The current orthographic word.
X2 – X5 P0,P1,P2,Pf Partial word flags for the current position, the next two to the right, and the first one
in a sequence of free-final words (partial, conjunctions, etc.) to the right of the
current position.
X6 – X10 T-1,T0,T1,T2,Tf Part of speech tags for the left position, the current position, the next two positions
to the right, and the first free-final word position to the right of the current position.
X11 Nm Number of words in common in reparandum and repair
X12 Nn Number of words in reparandum but not repair
X13 Ni Number of words in interregnum
X14 Nl Number of words to the left edge of reparandum
X15 Nr Number of words to the right edge of reparandum
X16 Ct The first non-punctuation tag to the right of the current position
X17 Cw The first non-punctuation word to the right of the current position
X18 Ti The tag of the first word right after the interregnum that is right after the current
word.
</table>
<tableCaption confidence="0.999513">
Table 1. Descriptions of the 18 conditioning variables from [Charniak and Johnson 2001]
</tableCaption>
<page confidence="0.997865">
182
</page>
<bodyText confidence="0.9998895">
rough copy if their corresponding major categories
match. This relaxation increases the rough copy
coverage, (the percent of words in edited regions
found through the definition of rough copy), from
77.66% to 79.68%.
The second is to allow one mismatch in the two
POS sequences. The mismatches can be an
addition, deletion, or substitution. This relaxation
improves the coverage from 77.66% to 85.45%.
Subsequently, the combination of the two
relaxations leads to a significantly higher coverage
of 87.70%. Additional relaxation leads to excessive
candidates and worse performance in the
development set.
</bodyText>
<subsectionHeader confidence="0.974074">
3.3.2 Adding New Features
</subsectionHeader>
<bodyText confidence="0.9999308">
We also include new features in the feature set:
one is the shortest distance (the number of words)
between the current word and a word of the same
orthographic form to the right, if that repeated
word exists; another is the words around the
current position. Based on the distributional
analysis in section 2, we also increase the window
sizes for POS tags ( T−5,..., T5 ) and words
(W − 5,..., W5 ) to ±5 and partial words (P − 3,..., P3 )
to ±3, extending Ti and Pj.
</bodyText>
<subsectionHeader confidence="0.861362">
3.3.3 Post Processing Step
</subsectionHeader>
<bodyText confidence="0.992274111111111">
In addition to the two categories, we try to use
contextual patterns to address the independency of
variables in the features. The patterns have been
extracted from development and training data, to
deal with certain sequence-related errors, e.g.,
E N E Æ E E E,
which means that if the neighbors on both sides of
a word are classified into EDITED, it should be
classified into EDITED as well.
</bodyText>
<sectionHeader confidence="0.991656" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999789178571429">
We conducted a number of experiments to test the
effectiveness of our feature space exploration.
Since the original code from [Charniak and
Johnson 2001] is not available, we conducted our
first experiment to replicate the result of their
baseline system described in section 3. We used
the exactly same training and testing data from the
Switchboard corpus as in [Charniak and Johnson
2001]. The training subset consists of all files in
the sections 2 and 3 of the Switchboard corpus.
Section 4 is split into three approximately equal
size subsets. The first of the three, i.e., files
sw4004.mrg to sw4153.mrg, is the testing corpus.
The files sw4519.mrg to sw4936.mrg are the
development corpus. The rest files are reserved for
other purposes. When punctuation is included in
both training and testing, the re-established
baseline has the precision, recall, and F-score of
94.73%, 68.71% and 79.65%, respectively. These
results are comparable with the results from
[Charniak &amp; Johnson 2001], i.e., 95.2%, 67.8%,
and 79.2% for precision, recall, and f-score,
correspondingly.
In the subsequent experiments, the set of additional
feature spaces described in section 3 are added,
step-by-step. The first addition includes the
shortest distance to the same word and window
size increases. This step gives a 2.27%
improvement on F-score over the baseline. The
next addition is the introduction of the POS
hierarchy in finding rough copies. This also gives
more than 3% absolute improvement over the
baseline and 1.19% over the expanded feature set
model. The addition of the feature spaces of
relaxed matches for words, POS tags, and POS
hierarchy tags all give additive improvements,
which leads to an overall of 8.95% absolute
improvement over the re-implemented baseline, or
43.98% relative error reduction on F-score.
When compared with the latest results from
[Johnson and Charniak 2004], where no
punctuations are used for either training or testing
data, we also observe the same trend of the
improved results. Our best result gives 4.15%
absolute improvement over their best result, or
20.44% relative error reduction in f-scores. As a
sanity check, when evaluated on the training data
as a cheating experiment, we show a remarkable
consistency with the results for testing data.
For error analysis, we randomly selected 100
sentences with 1673 words total from the test
sentences that have at least one mistake. Errors can
be divided into two types, miss (should be edited)
and false alarm (should be noraml). Among the
207 misses, about 70% of them require some
phrase level analysis or acoustic cues for phrases.
</bodyText>
<page confidence="0.996696">
183
</page>
<table confidence="0.998262466666667">
Method codes Results on training data Results on testing data
with punctuation
Punctuation on both No punctuation on both
Precision Recall f-score Precision Recall f-score Precision Recall f-score
CJ’01 95.2 67.8 79.2
JC’04 p 82.0 77.8 79.7
R CJ’01 94.9 71.9 81.81 94.73 68.71 79.65 91.46 64.42 75.59
+d 94.56 78.37 85.71 94.47 72.31 81.92 91.79 68.13 78.21
+d+h 94.23 81.32 87.30 94.58 74.12 83.11 91.56 71.33 80.19
+d+rh 94.12 82.61 87.99 92.61 77.15 84.18 89.92 72.68 80.39
+d+rw 96.13 82.45 88.77 94.79 75.43 84.01 92.17 70.79 80.08
+d+rw+rh 94.42 84.67 89.28 94.57 77.93 85.45 92.61 73.46 81.93
+d+rw+rt+wt 94.43 84.79 89.35 94.65 76.61 84.68 92.08 72.61 81.19
+d+rw+rh+wt 94.58 85.21 89.65 94.72 79.22 86.28 92.69 75.30 83.09
+d+rw+rh+wt+ps 93.69 88.62 91.08 93.81 83.94 88.60 89.70 78.71 83.85
</table>
<tableCaption confidence="0.998247">
Table 2. Result summary for various feature spaces.
</tableCaption>
<table confidence="0.999897142857143">
Method codes Method description
CJ’01 Charniak and Johnson 2001
JC’04 p Johnson and Charniak 2004, parser results
R CJ’01 Duplicated results for Charniak and Johnson 2001
+d Distance + window sizes
+d+h Distance + window sizes + POS hierarchy in rough copy
+d+rh Distance + window sizes + relaxed POS hierarchy in rough copy
+d+rw Distance + window sizes + relaxed word in rough copy
+d+rw+rh Distance + window sizes + relaxed word and POS hierarchy in rough copy
+d+rw+rt+wt Distance + window sizes + word &amp; tag pairs + relaxed word and POS in rough copy
+d+rw+rh+wt Distance + window sizes + word &amp; tag pairs + relaxed word and POS hierarchy in
rough copy
+d+rw+rh+wt+ps Distance + window sizes + word &amp; tag pairs + relaxed word and POS hierarchy in
rough copy + pattern substitution
</table>
<tableCaption confidence="0.99972">
Table 3. Description of method codes used in the result table.
</tableCaption>
<bodyText confidence="0.999942461538462">
For example, one miss is “because of the friends
because of many other things”, an error we would
have a much better chance of correct identification,
if we were able to identify prepositional phrases
reliably. Another example is “most of all my
family”. Since it is grammatical by itself, certain
prosodic information in between “most of” and “all
my family” may help the identification. [Ostendorf
et al. 2004] reported that interruption point could
help parsers to improve results. [Kahn et al. 2005]
also showed that prosody information could help
parse disfluent sentences. The second major class
of the misses is certain short words that are not
labeled consistently in the corpus. For example,
“so”, “and”, and “or”, when they occur in the
beginning of a sentence, are sometimes labeled as
edited, and sometimes just as normal. The last
category of the misses, about 5.3%, contains the
ones where the distances between reparanda and
repairs are often more than 10 words.
Among the 95 false alarms, more than three
quarters of misclassified ones are related to certain
grammatical constructions. Examples include cases
like, “the more ... the more” and “I think I
should ...”. These cases may be fixable if more
elaborated grammar-based features are used.
</bodyText>
<sectionHeader confidence="0.999503" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9982645">
This paper reports our work on identifying edited
regions in the Switchboard corpus. In addition to a
</bodyText>
<page confidence="0.996127">
184
</page>
<bodyText confidence="0.999977052631579">
distributional analysis for the edited regions, a
number of feature spaces have been explored and
tested to show their effectiveness. We observed a
43.98% relative error reduction on F-scores for the
baseline with punctuation in both training and
testing [Charniak and Johnson 2001]. Compared
with the reported best result, the same approach
produced a 20.44% of relative error reduction on
F-scores when punctuation is ignored in training
and testing data [Johnson and Charniak 2004]. The
inclusion of both hierarchical POS tags and the
relaxation for rough copy definition gives large
additive improvements, and their combination has
contributed to nearly half of the gain for the test
set with punctuation and about 60% of the gain for
the data without punctuation.
Future research would include the use of other
features, such as prosody, and the integration of
the edited region identification with parsing.
</bodyText>
<sectionHeader confidence="0.998747" genericHeader="acknowledgments">
6 Acknowledgement
</sectionHeader>
<bodyText confidence="0.99997275">
This work has been done while the first author is
working at the Research and Technology Center of
Robert Bosch Corp. The research is partly
supported by the NIST ATP program. The authors
would also like to express their thanks to Tess
Hand-Bender for her proof-reading and Jeremy G.
Kahn for many useful comments. Nevertheless, all
the remaining errors are ours.
</bodyText>
<sectionHeader confidence="0.998979" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999299596491228">
John Bear, John Dowding and Elizabeth Shriberg. 1992.
Integrating Multiple Knowledge Sources for Detection
and Correction of Repairs in Human-Computer Dialog.
Proc. Annual Meeting of the Association for
Computational Linguistics. 1992.
Charniak, Eugene and Mark Johnson. 2001. Edit
Detection and Parsing for Transcribed Speech. Proc. of
the 2nd Meeting of the North American Chapter of the
Association for Computational Linguistics, pp 118-126.
Collins, M. 2000. Discriminative reranking for natural
language parsing. Proc. ICML 2000.
Engel, Donald, Eugene Charniak, and Mark Johnson.
2002. Parsing and Disfluency Placement. Proc.
EMNLP, pp 49-54, 2002.
Godfrey, J.J., Holliman, E.C. and McDaniel, J.
SWITCHBOARD: Telephone speech corpus for
research and development, Proc. ICASSP, pp 517-520,
1992.
Heeman, Peter, and James Allen. 1994. Detecting and
Correcting Speech Repairs. Proc. of the annual meeting
of the Association for Computational Linguistics. Las
Cruces, New Mexico, pp 295-302, 1994.
Johnson, Mark, and Eugene Charniak. 2004. A TAG-
based noisy-channel model of speech repairs. Proc. of
the 42nd Annual Meeting of the Association for
Computational Linguistics.
Kahn, Jeremy G., Mari Ostendorf, and Ciprian Chelba.
2004. Parsing Conversational Speech Using Enhanced
Segmentation. Proc. of HLT-NAACL, pp 125-138, 2004.
Kahn, Jeremy G., Matthew Lease, Eugene Charniak,
Mark Johnson and Mari Ostendorf 2005. Effective Use
of Prosody in Parsing Conversational Speech. Proc.
EMNLP, 2005.
Liu, Yang, Elizabeth Shriberg, Andreas Stolcke,
Barbara Peskin, Jeremy Ang, Dustin Hillard, Mari
Ostendorf, Marcus Tomalin, Phil Woodland, Mary
Harper. 2005. Structural Metadata Research in the
EARS Program. Proc. ICASSP, 2005.
Liu, Yang, Elizabeth Shriberg, Andreas Stolcke. 2003.
Automatic disfluency identification in conversational
speech using multiple knowledge sources Proc.
Eurospeech, 2003
Ostendorf, Mari, Jeremy G. Kahn, Darby Wong, Dustin
Hillard, and William McNeill. Leveraging Structural
MDE in Language Processing. EARS RT04 Workshop,
2004.
Robert E. Schapire and Yoram Singer, 1999. Improved
Boosting Algorithms Using Confidence-rated
Predictions. Machine Learning 37(3): 297-336, 1999.
Shriberg, Elizabeth. 1994. Preliminaries to a Theory of
Speech Disfluencies. Ph.D. Thesis. UC Berkeley,1994.
Shriberg, Elizabeth. 1996. Disfluencies in Switchboard.
Proc. of ICSLP. 1996.
Young, S. R. and Matessa, M. (1991). Using pragmatic
and semantic knowledge to correct parsing of spoken
language utterances. Proc. Eurospeech 91, Genova,
Italy.
</reference>
<page confidence="0.99884">
185
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.889682">
<title confidence="0.999886">Exploring Features for Identifying Edited Regions in Disfluent Sentences</title>
<author confidence="0.999654">Qi Zhang Fuliang Weng</author>
<affiliation confidence="0.996307">Department of Computer Science Research and Technology Center Fudan University Robert Bosch Corp.</affiliation>
<address confidence="0.999746">Shanghai, P.R.China 200433 Palo Alto, CA 94304</address>
<email confidence="0.991544">qi_zhang@fudan.edu.cnfuliang.weng@rtc.bosch.com</email>
<abstract confidence="0.995584545454545">This paper describes our effort on the task of edited region identification for parsing disfluent sentences in the Switchboard corpus. We focus our attention on exploring feature spaces and selecting good features and start with analyzing the distributions of the edited regions and their components in the targeted corpus. We explore new feature spaces of a partof-speech (POS) hierarchy and relaxed for rough copy in the experiments. These steps result in an improvement of 43.98% percent relative error reduction in F-score over an earlier best result in edited detection when punctuation is included in both training and testing data [Charniak and Johnson 2001], and 20.44% percent relative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004].</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Bear</author>
<author>John Dowding</author>
<author>Elizabeth Shriberg</author>
</authors>
<title>Integrating Multiple Knowledge Sources for Detection and Correction of Repairs in Human-Computer Dialog.</title>
<date>1992</date>
<booktitle>Proc. Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1584" citStr="Bear et al. 1992" startWordPosition="227" endWordPosition="230"> 20.44% percent relative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004]. 1 Introduction Repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such disfluent phenomena. Processing speech repairs properly poses a challenge to spoken dialog systems. Early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [Young and Matessa 1991, Bear et al. 1992, Heeman &amp; Allen 1994]. Because of the availability of the Switchboard corpus [Godfrey et al. 1992] and other conversational telephone speech (CTS) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences [Charniak and Johnson 2001, Johnson and Charniak 2004, Ostendorf et al. 2004, Liu et al. 2005]. In this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the Switchboard corpus. A clear benefit of having accurate edited regions f</context>
</contexts>
<marker>Bear, Dowding, Shriberg, 1992</marker>
<rawString>John Bear, John Dowding and Elizabeth Shriberg. 1992. Integrating Multiple Knowledge Sources for Detection and Correction of Repairs in Human-Computer Dialog. Proc. Annual Meeting of the Association for Computational Linguistics. 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Edit Detection and Parsing for Transcribed Speech.</title>
<date>2001</date>
<booktitle>Proc. of the 2nd Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>118--126</pages>
<contexts>
<context position="962" citStr="Charniak and Johnson 2001" startWordPosition="136" endWordPosition="139">task of edited region identification for parsing disfluent sentences in the Switchboard corpus. We focus our attention on exploring feature spaces and selecting good features and start with analyzing the distributions of the edited regions and their components in the targeted corpus. We explore new feature spaces of a partof-speech (POS) hierarchy and relaxed for rough copy in the experiments. These steps result in an improvement of 43.98% percent relative error reduction in F-score over an earlier best result in edited detection when punctuation is included in both training and testing data [Charniak and Johnson 2001], and 20.44% percent relative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004]. 1 Introduction Repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such disfluent phenomena. Processing speech repairs properly poses a challenge to spoken dialog systems. Early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [Young and Matessa </context>
<context position="2956" citStr="Charniak and Johnson 2001" startWordPosition="437" endWordPosition="440">s provide similar performances on many NLP tasks, in this paper, we focus our attention on exploring feature spaces and selecting good features for identifying edited regions. We start by analyzing the distributions of the edited regions and their components in the targeted corpus. We then design several feature spaces to cover the disfluent regions in the training data. In addition, we also explore new feature spaces of a part-of-speech hierarchy and extend candidate pools in the experiments. These steps result in a significant improvement in F-score over the earlier best result reported in [Charniak and Johnson 2001], where punctuation is included in both the training and testing data of the Switchboard corpus, and a significant error reduction in F-score over the latest best result [Johnson and Charniak 2004], where punctuation is ignored in both the training and testing data of the Switchboard corpus. 179 Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 179–185, Vancouver, October 2005. c�2005 Association for Computational Linguistics In this paper, we follow the definition of [Shriberg 1994] and others for speech repairs: A speech repair is divided into three parts</context>
<context position="5457" citStr="Charniak and Johnson 2001" startWordPosition="824" endWordPosition="827"> a thorough analysis and categorization of them. [Engel et al. 2002] also showed detailed distributions of the interregnum, including interjections and parentheticals. Since the majority of the disfluencies involve all the three parts (reparandum, interregnum, and repair/repeat), the distributions of all three parts will be very helpful in constructing patterns that are used to identify edited regions. For the reparandum and repair types, we include their distributions with and without punctuation. We include the distributions with punctuation is to match with the baseline system reported in [Charniak and Johnson 2001], where punctuation is included to identify the edited regions. Resent research showed that certain punctuation/prosody marks can be produced when speech signals are available [Liu et al. 2003]. The interregnum type, by definition, does not include punctuation. The length distributions of the reparanda in the training part of the Switchboard data with and Figure 1. Length distribution of reparanda in Switchboard training data. Figure 2. Length distribution of repairs/repeats/restarts in Switchboard training data. Figure 3. Length distribution of interregna in Switchboard training data. The tw</context>
<context position="7476" citStr="Charniak and Johnson 2001" startWordPosition="1166" endWordPosition="1169">us is shown in Fig. 3. We see that the overwhelming majority has the length of one, which are mostly words such as “uh”, “yeah”, or “uh-huh”. In examining the Switchboard data, we noticed that a large number of reparanda and repair/repeat pairs differ on less than two words, i.e. “as to, you know, when to”1, and the amount of the pairs differing on less than two POS tags is even bigger. There are also cases where some of the pairs have different lengths. These findings provide a good base for our feature space. 3 Feature Space Selection for Boosting We take as our baseline system the work by [Charniak and Johnson 2001]. In their approach, rough copy is defined to produce candidates for any potential pairs of reparanda and repairs. A boosting algorithm [Schapire and Singer 1999] is used to detect whether a word is edited. A total of 18 variables are used in the algorithm. In the rest of the section, we first briefly introduce the boosting algorithm, then describe the method used in [Charniak and Johnson 2001], and finally we contrast our improvements with the baseline system. 3.1 Boosting Algorithm Intuitively, the boosting algorithm is to combine a set of simple learners iteratively based on their classifi</context>
<context position="10389" citStr="Charniak and Johnson 2001" startWordPosition="1665" endWordPosition="1668">the ˆ expected boost loss Et[(exp(-YZ)] as in [Collins ˆ 2000], where E t[.] is the expectation on the empirical training corpus distribution. In our implementation, each learner contains only one variable. The feature weights are adjusted iteratively, one weight per iteration. At each iteration, it reduces the boost loss on the training corpus. In our experiments, αK is obtained after n Z �= i 1 (Xj = x j) = 181 1500 iterations, and contains around 1350 non-zero sequences of an interregnum string (see feature weights. below) followed by optional punctuation. 3.2 Charniak-Johnson approach In [Charniak and Johnson 2001], identifying edited regions is considered as a classification problem, where each word is classified either as edited or normal. The approach takes two steps. The first step is to find rough copy. Then, a number of variables are extracted for the boosting algorithm. In particular, a total of 18 different conditioning variables are used to predict whether the current word is an edited word or a non-edited word. The 18 different variables listed in Table 1 correspond to the 18 different dimensions/factors for the current word position. Among the 18 variables, six of them, Nm, Nu, Ni, Nl, Nr an</context>
<context position="12169" citStr="Charniak and Johnson 2001" startWordPosition="1969" endWordPosition="1972">mall set of conjunctions, adverbs and miscellanea. The set of interregnum strings consists of a small set of expressions such as uh, you know, I guess, I mean, etc. 3.3 New Improvements Our improvements to the Charniak-Johnson method can be classified into three categories with the first two corresponding to the twp steps in their method. The three categories of improvements are described in details in the following subsections. 3.3.1 Relaxing Rough Copy We relax the definition for rough copy, because more than 94% of all edits have both reparandum and repair, while the rough copy defined in [Charniak and Johnson 2001] only covers 77.66% of such instances. Two methods are used to relax the rough copy definition. The first one is to adopt a hierarchical POS tag set: all the Switchboard POS tags are further classified into four major categories: N (noun related), V (verb related), Adj (noun modifiers), Adv (verb modifiers). Instead of requiring the exact match of two POS tag sequences, we also consider two sequences as a Variables Name Short description X1 W0 The current orthographic word. X2 – X5 P0,P1,P2,Pf Partial word flags for the current position, the next two to the right, and the first one in a seque</context>
<context position="13656" citStr="Charniak and Johnson 2001" startWordPosition="2228" endWordPosition="2231">he right of the current position. X11 Nm Number of words in common in reparandum and repair X12 Nn Number of words in reparandum but not repair X13 Ni Number of words in interregnum X14 Nl Number of words to the left edge of reparandum X15 Nr Number of words to the right edge of reparandum X16 Ct The first non-punctuation tag to the right of the current position X17 Cw The first non-punctuation word to the right of the current position X18 Ti The tag of the first word right after the interregnum that is right after the current word. Table 1. Descriptions of the 18 conditioning variables from [Charniak and Johnson 2001] 182 rough copy if their corresponding major categories match. This relaxation increases the rough copy coverage, (the percent of words in edited regions found through the definition of rough copy), from 77.66% to 79.68%. The second is to allow one mismatch in the two POS sequences. The mismatches can be an addition, deletion, or substitution. This relaxation improves the coverage from 77.66% to 85.45%. Subsequently, the combination of the two relaxations leads to a significantly higher coverage of 87.70%. Additional relaxation leads to excessive candidates and worse performance in the develo</context>
<context position="15359" citStr="Charniak and Johnson 2001" startWordPosition="2514" endWordPosition="2517"> to ±3, extending Ti and Pj. 3.3.3 Post Processing Step In addition to the two categories, we try to use contextual patterns to address the independency of variables in the features. The patterns have been extracted from development and training data, to deal with certain sequence-related errors, e.g., E N E Æ E E E, which means that if the neighbors on both sides of a word are classified into EDITED, it should be classified into EDITED as well. 4 Experimental Results We conducted a number of experiments to test the effectiveness of our feature space exploration. Since the original code from [Charniak and Johnson 2001] is not available, we conducted our first experiment to replicate the result of their baseline system described in section 3. We used the exactly same training and testing data from the Switchboard corpus as in [Charniak and Johnson 2001]. The training subset consists of all files in the sections 2 and 3 of the Switchboard corpus. Section 4 is split into three approximately equal size subsets. The first of the three, i.e., files sw4004.mrg to sw4153.mrg, is the testing corpus. The files sw4519.mrg to sw4936.mrg are the development corpus. The rest files are reserved for other purposes. When p</context>
<context position="18748" citStr="Charniak and Johnson 2001" startWordPosition="3053" endWordPosition="3056">.42 75.59 +d 94.56 78.37 85.71 94.47 72.31 81.92 91.79 68.13 78.21 +d+h 94.23 81.32 87.30 94.58 74.12 83.11 91.56 71.33 80.19 +d+rh 94.12 82.61 87.99 92.61 77.15 84.18 89.92 72.68 80.39 +d+rw 96.13 82.45 88.77 94.79 75.43 84.01 92.17 70.79 80.08 +d+rw+rh 94.42 84.67 89.28 94.57 77.93 85.45 92.61 73.46 81.93 +d+rw+rt+wt 94.43 84.79 89.35 94.65 76.61 84.68 92.08 72.61 81.19 +d+rw+rh+wt 94.58 85.21 89.65 94.72 79.22 86.28 92.69 75.30 83.09 +d+rw+rh+wt+ps 93.69 88.62 91.08 93.81 83.94 88.60 89.70 78.71 83.85 Table 2. Result summary for various feature spaces. Method codes Method description CJ’01 Charniak and Johnson 2001 JC’04 p Johnson and Charniak 2004, parser results R CJ’01 Duplicated results for Charniak and Johnson 2001 +d Distance + window sizes +d+h Distance + window sizes + POS hierarchy in rough copy +d+rh Distance + window sizes + relaxed POS hierarchy in rough copy +d+rw Distance + window sizes + relaxed word in rough copy +d+rw+rh Distance + window sizes + relaxed word and POS hierarchy in rough copy +d+rw+rt+wt Distance + window sizes + word &amp; tag pairs + relaxed word and POS in rough copy +d+rw+rh+wt Distance + window sizes + word &amp; tag pairs + relaxed word and POS hierarchy in rough copy +d+rw</context>
<context position="21197" citStr="Charniak and Johnson 2001" startWordPosition="3461" endWordPosition="3464">assified ones are related to certain grammatical constructions. Examples include cases like, “the more ... the more” and “I think I should ...”. These cases may be fixable if more elaborated grammar-based features are used. 5 Conclusions This paper reports our work on identifying edited regions in the Switchboard corpus. In addition to a 184 distributional analysis for the edited regions, a number of feature spaces have been explored and tested to show their effectiveness. We observed a 43.98% relative error reduction on F-scores for the baseline with punctuation in both training and testing [Charniak and Johnson 2001]. Compared with the reported best result, the same approach produced a 20.44% of relative error reduction on F-scores when punctuation is ignored in training and testing data [Johnson and Charniak 2004]. The inclusion of both hierarchical POS tags and the relaxation for rough copy definition gives large additive improvements, and their combination has contributed to nearly half of the gain for the test set with punctuation and about 60% of the gain for the data without punctuation. Future research would include the use of other features, such as prosody, and the integration of the edited regi</context>
</contexts>
<marker>Charniak, Johnson, 2001</marker>
<rawString>Charniak, Eugene and Mark Johnson. 2001. Edit Detection and Parsing for Transcribed Speech. Proc. of the 2nd Meeting of the North American Chapter of the Association for Computational Linguistics, pp 118-126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2000</date>
<booktitle>Proc. ICML</booktitle>
<marker>Collins, 2000</marker>
<rawString>Collins, M. 2000. Discriminative reranking for natural language parsing. Proc. ICML 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Engel</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Parsing and Disfluency Placement.</title>
<date>2002</date>
<booktitle>Proc. EMNLP,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="4899" citStr="Engel et al. 2002" startWordPosition="745" endWordPosition="748"> then, presents the Boosting method, the baseline system and the feature spaces we want to explore. Section 4 describes, step by step, a set of experiments that lead to a large performance improvement. Section 5 concludes with discussion and future work. 2 Repair Distributions in Switchboard We start by analyzing the speech repairs in the Switchboard corpus. Switchboard has over one million words, with telephone conversations on prescribed topics [Godfrey et al. 1992]. It is full of disfluent utterances, and [Shriberg 1994, Shriberg 1996] gives a thorough analysis and categorization of them. [Engel et al. 2002] also showed detailed distributions of the interregnum, including interjections and parentheticals. Since the majority of the disfluencies involve all the three parts (reparandum, interregnum, and repair/repeat), the distributions of all three parts will be very helpful in constructing patterns that are used to identify edited regions. For the reparandum and repair types, we include their distributions with and without punctuation. We include the distributions with punctuation is to match with the baseline system reported in [Charniak and Johnson 2001], where punctuation is included to identi</context>
</contexts>
<marker>Engel, Charniak, Johnson, 2002</marker>
<rawString>Engel, Donald, Eugene Charniak, and Mark Johnson. 2002. Parsing and Disfluency Placement. Proc. EMNLP, pp 49-54, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Godfrey</author>
<author>E C Holliman</author>
<author>J McDaniel</author>
</authors>
<title>SWITCHBOARD: Telephone speech corpus for research and development,</title>
<date>1992</date>
<booktitle>Proc. ICASSP,</booktitle>
<pages>517--520</pages>
<contexts>
<context position="1682" citStr="Godfrey et al. 1992" startWordPosition="243" endWordPosition="246">on is excluded from the training and testing data [Johnson and Charniak 2004]. 1 Introduction Repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such disfluent phenomena. Processing speech repairs properly poses a challenge to spoken dialog systems. Early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [Young and Matessa 1991, Bear et al. 1992, Heeman &amp; Allen 1994]. Because of the availability of the Switchboard corpus [Godfrey et al. 1992] and other conversational telephone speech (CTS) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences [Charniak and Johnson 2001, Johnson and Charniak 2004, Ostendorf et al. 2004, Liu et al. 2005]. In this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the Switchboard corpus. A clear benefit of having accurate edited regions for parsing has been demonstrated by a concurrent effort on parsing conversational speech [Kahn et </context>
<context position="4753" citStr="Godfrey et al. 1992" startWordPosition="722" endWordPosition="725">good coverage. This paper is organized as follows. In section 2, we examine the distributions of the editing regions in Switchboard data. Section 3, then, presents the Boosting method, the baseline system and the feature spaces we want to explore. Section 4 describes, step by step, a set of experiments that lead to a large performance improvement. Section 5 concludes with discussion and future work. 2 Repair Distributions in Switchboard We start by analyzing the speech repairs in the Switchboard corpus. Switchboard has over one million words, with telephone conversations on prescribed topics [Godfrey et al. 1992]. It is full of disfluent utterances, and [Shriberg 1994, Shriberg 1996] gives a thorough analysis and categorization of them. [Engel et al. 2002] also showed detailed distributions of the interregnum, including interjections and parentheticals. Since the majority of the disfluencies involve all the three parts (reparandum, interregnum, and repair/repeat), the distributions of all three parts will be very helpful in constructing patterns that are used to identify edited regions. For the reparandum and repair types, we include their distributions with and without punctuation. We include the di</context>
</contexts>
<marker>Godfrey, Holliman, McDaniel, 1992</marker>
<rawString>Godfrey, J.J., Holliman, E.C. and McDaniel, J. SWITCHBOARD: Telephone speech corpus for research and development, Proc. ICASSP, pp 517-520, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Heeman</author>
<author>James Allen</author>
</authors>
<title>Detecting and Correcting Speech Repairs.</title>
<date>1994</date>
<booktitle>Proc. of the annual meeting of the Association for Computational Linguistics. Las</booktitle>
<pages>295--302</pages>
<location>Cruces, New</location>
<contexts>
<context position="1605" citStr="Heeman &amp; Allen 1994" startWordPosition="231" endWordPosition="234">lative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004]. 1 Introduction Repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such disfluent phenomena. Processing speech repairs properly poses a challenge to spoken dialog systems. Early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [Young and Matessa 1991, Bear et al. 1992, Heeman &amp; Allen 1994]. Because of the availability of the Switchboard corpus [Godfrey et al. 1992] and other conversational telephone speech (CTS) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences [Charniak and Johnson 2001, Johnson and Charniak 2004, Ostendorf et al. 2004, Liu et al. 2005]. In this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the Switchboard corpus. A clear benefit of having accurate edited regions for parsing has been d</context>
</contexts>
<marker>Heeman, Allen, 1994</marker>
<rawString>Heeman, Peter, and James Allen. 1994. Detecting and Correcting Speech Repairs. Proc. of the annual meeting of the Association for Computational Linguistics. Las Cruces, New Mexico, pp 295-302, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Eugene Charniak</author>
</authors>
<title>A TAGbased noisy-channel model of speech repairs.</title>
<date>2004</date>
<booktitle>Proc. of the 42nd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1139" citStr="Johnson and Charniak 2004" startWordPosition="163" endWordPosition="166">d start with analyzing the distributions of the edited regions and their components in the targeted corpus. We explore new feature spaces of a partof-speech (POS) hierarchy and relaxed for rough copy in the experiments. These steps result in an improvement of 43.98% percent relative error reduction in F-score over an earlier best result in edited detection when punctuation is included in both training and testing data [Charniak and Johnson 2001], and 20.44% percent relative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004]. 1 Introduction Repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such disfluent phenomena. Processing speech repairs properly poses a challenge to spoken dialog systems. Early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [Young and Matessa 1991, Bear et al. 1992, Heeman &amp; Allen 1994]. Because of the availability of the Switchboard corpus [Godfrey et al. 1992] and other conversational telephone speech (CTS) corpora</context>
<context position="3153" citStr="Johnson and Charniak 2004" startWordPosition="468" endWordPosition="471"> the distributions of the edited regions and their components in the targeted corpus. We then design several feature spaces to cover the disfluent regions in the training data. In addition, we also explore new feature spaces of a part-of-speech hierarchy and extend candidate pools in the experiments. These steps result in a significant improvement in F-score over the earlier best result reported in [Charniak and Johnson 2001], where punctuation is included in both the training and testing data of the Switchboard corpus, and a significant error reduction in F-score over the latest best result [Johnson and Charniak 2004], where punctuation is ignored in both the training and testing data of the Switchboard corpus. 179 Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 179–185, Vancouver, October 2005. c�2005 Association for Computational Linguistics In this paper, we follow the definition of [Shriberg 1994] and others for speech repairs: A speech repair is divided into three parts: the reparandum, the part that is repaired; the interregnum, the part that can be either empty or fillers; and the repair/repeat, the part that replaces or repeats the reparandum. The definition c</context>
<context position="17095" citStr="Johnson and Charniak 2004" startWordPosition="2786" endWordPosition="2789"> window size increases. This step gives a 2.27% improvement on F-score over the baseline. The next addition is the introduction of the POS hierarchy in finding rough copies. This also gives more than 3% absolute improvement over the baseline and 1.19% over the expanded feature set model. The addition of the feature spaces of relaxed matches for words, POS tags, and POS hierarchy tags all give additive improvements, which leads to an overall of 8.95% absolute improvement over the re-implemented baseline, or 43.98% relative error reduction on F-score. When compared with the latest results from [Johnson and Charniak 2004], where no punctuations are used for either training or testing data, we also observe the same trend of the improved results. Our best result gives 4.15% absolute improvement over their best result, or 20.44% relative error reduction in f-scores. As a sanity check, when evaluated on the training data as a cheating experiment, we show a remarkable consistency with the results for testing data. For error analysis, we randomly selected 100 sentences with 1673 words total from the test sentences that have at least one mistake. Errors can be divided into two types, miss (should be edited) and fals</context>
<context position="18782" citStr="Johnson and Charniak 2004" startWordPosition="3059" endWordPosition="3062">47 72.31 81.92 91.79 68.13 78.21 +d+h 94.23 81.32 87.30 94.58 74.12 83.11 91.56 71.33 80.19 +d+rh 94.12 82.61 87.99 92.61 77.15 84.18 89.92 72.68 80.39 +d+rw 96.13 82.45 88.77 94.79 75.43 84.01 92.17 70.79 80.08 +d+rw+rh 94.42 84.67 89.28 94.57 77.93 85.45 92.61 73.46 81.93 +d+rw+rt+wt 94.43 84.79 89.35 94.65 76.61 84.68 92.08 72.61 81.19 +d+rw+rh+wt 94.58 85.21 89.65 94.72 79.22 86.28 92.69 75.30 83.09 +d+rw+rh+wt+ps 93.69 88.62 91.08 93.81 83.94 88.60 89.70 78.71 83.85 Table 2. Result summary for various feature spaces. Method codes Method description CJ’01 Charniak and Johnson 2001 JC’04 p Johnson and Charniak 2004, parser results R CJ’01 Duplicated results for Charniak and Johnson 2001 +d Distance + window sizes +d+h Distance + window sizes + POS hierarchy in rough copy +d+rh Distance + window sizes + relaxed POS hierarchy in rough copy +d+rw Distance + window sizes + relaxed word in rough copy +d+rw+rh Distance + window sizes + relaxed word and POS hierarchy in rough copy +d+rw+rt+wt Distance + window sizes + word &amp; tag pairs + relaxed word and POS in rough copy +d+rw+rh+wt Distance + window sizes + word &amp; tag pairs + relaxed word and POS hierarchy in rough copy +d+rw+rh+wt+ps Distance + window sizes </context>
<context position="21399" citStr="Johnson and Charniak 2004" startWordPosition="3492" endWordPosition="3495">ed features are used. 5 Conclusions This paper reports our work on identifying edited regions in the Switchboard corpus. In addition to a 184 distributional analysis for the edited regions, a number of feature spaces have been explored and tested to show their effectiveness. We observed a 43.98% relative error reduction on F-scores for the baseline with punctuation in both training and testing [Charniak and Johnson 2001]. Compared with the reported best result, the same approach produced a 20.44% of relative error reduction on F-scores when punctuation is ignored in training and testing data [Johnson and Charniak 2004]. The inclusion of both hierarchical POS tags and the relaxation for rough copy definition gives large additive improvements, and their combination has contributed to nearly half of the gain for the test set with punctuation and about 60% of the gain for the data without punctuation. Future research would include the use of other features, such as prosody, and the integration of the edited region identification with parsing. 6 Acknowledgement This work has been done while the first author is working at the Research and Technology Center of Robert Bosch Corp. The research is partly supported b</context>
</contexts>
<marker>Johnson, Charniak, 2004</marker>
<rawString>Johnson, Mark, and Eugene Charniak. 2004. A TAGbased noisy-channel model of speech repairs. Proc. of the 42nd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeremy G Kahn</author>
<author>Mari Ostendorf</author>
<author>Ciprian Chelba</author>
</authors>
<title>Parsing Conversational Speech Using Enhanced Segmentation.</title>
<date>2004</date>
<booktitle>Proc. of HLT-NAACL,</booktitle>
<pages>125--138</pages>
<marker>Kahn, Ostendorf, Chelba, 2004</marker>
<rawString>Kahn, Jeremy G., Mari Ostendorf, and Ciprian Chelba. 2004. Parsing Conversational Speech Using Enhanced Segmentation. Proc. of HLT-NAACL, pp 125-138, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeremy G Kahn</author>
<author>Matthew Lease</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
<author>Mari Ostendorf</author>
</authors>
<date>2005</date>
<booktitle>Effective Use of Prosody in Parsing Conversational Speech. Proc. EMNLP,</booktitle>
<contexts>
<context position="2289" citStr="Kahn et al 2005" startWordPosition="335" endWordPosition="338">al. 1992] and other conversational telephone speech (CTS) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences [Charniak and Johnson 2001, Johnson and Charniak 2004, Ostendorf et al. 2004, Liu et al. 2005]. In this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the Switchboard corpus. A clear benefit of having accurate edited regions for parsing has been demonstrated by a concurrent effort on parsing conversational speech [Kahn et al 2005]. Since different machine learning methods provide similar performances on many NLP tasks, in this paper, we focus our attention on exploring feature spaces and selecting good features for identifying edited regions. We start by analyzing the distributions of the edited regions and their components in the targeted corpus. We then design several feature spaces to cover the disfluent regions in the training data. In addition, we also explore new feature spaces of a part-of-speech hierarchy and extend candidate pools in the experiments. These steps result in a significant improvement in F-score </context>
<context position="20036" citStr="Kahn et al. 2005" startWordPosition="3275" endWordPosition="3278">POS hierarchy in rough copy + pattern substitution Table 3. Description of method codes used in the result table. For example, one miss is “because of the friends because of many other things”, an error we would have a much better chance of correct identification, if we were able to identify prepositional phrases reliably. Another example is “most of all my family”. Since it is grammatical by itself, certain prosodic information in between “most of” and “all my family” may help the identification. [Ostendorf et al. 2004] reported that interruption point could help parsers to improve results. [Kahn et al. 2005] also showed that prosody information could help parse disfluent sentences. The second major class of the misses is certain short words that are not labeled consistently in the corpus. For example, “so”, “and”, and “or”, when they occur in the beginning of a sentence, are sometimes labeled as edited, and sometimes just as normal. The last category of the misses, about 5.3%, contains the ones where the distances between reparanda and repairs are often more than 10 words. Among the 95 false alarms, more than three quarters of misclassified ones are related to certain grammatical constructions. </context>
</contexts>
<marker>Kahn, Lease, Charniak, Johnson, Ostendorf, 2005</marker>
<rawString>Kahn, Jeremy G., Matthew Lease, Eugene Charniak, Mark Johnson and Mari Ostendorf 2005. Effective Use of Prosody in Parsing Conversational Speech. Proc. EMNLP, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Elizabeth Shriberg</author>
<author>Andreas Stolcke</author>
<author>Barbara Peskin</author>
<author>Jeremy Ang</author>
</authors>
<date>2005</date>
<booktitle>Structural Metadata Research in the EARS Program. Proc. ICASSP,</booktitle>
<location>Dustin Hillard, Mari Ostendorf, Marcus Tomalin, Phil Woodland, Mary Harper.</location>
<contexts>
<context position="1967" citStr="Liu et al. 2005" startWordPosition="285" endWordPosition="288">roperly poses a challenge to spoken dialog systems. Early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [Young and Matessa 1991, Bear et al. 1992, Heeman &amp; Allen 1994]. Because of the availability of the Switchboard corpus [Godfrey et al. 1992] and other conversational telephone speech (CTS) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences [Charniak and Johnson 2001, Johnson and Charniak 2004, Ostendorf et al. 2004, Liu et al. 2005]. In this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the Switchboard corpus. A clear benefit of having accurate edited regions for parsing has been demonstrated by a concurrent effort on parsing conversational speech [Kahn et al 2005]. Since different machine learning methods provide similar performances on many NLP tasks, in this paper, we focus our attention on exploring feature spaces and selecting good features for identifying edited regions. We start by analyzing the distributions of the edited region</context>
</contexts>
<marker>Liu, Shriberg, Stolcke, Peskin, Ang, 2005</marker>
<rawString>Liu, Yang, Elizabeth Shriberg, Andreas Stolcke, Barbara Peskin, Jeremy Ang, Dustin Hillard, Mari Ostendorf, Marcus Tomalin, Phil Woodland, Mary Harper. 2005. Structural Metadata Research in the EARS Program. Proc. ICASSP, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Elizabeth Shriberg</author>
<author>Andreas Stolcke</author>
</authors>
<title>Automatic disfluency identification in conversational speech using multiple knowledge sources</title>
<date>2003</date>
<booktitle>Proc. Eurospeech,</booktitle>
<contexts>
<context position="5650" citStr="Liu et al. 2003" startWordPosition="852" endWordPosition="855">ies involve all the three parts (reparandum, interregnum, and repair/repeat), the distributions of all three parts will be very helpful in constructing patterns that are used to identify edited regions. For the reparandum and repair types, we include their distributions with and without punctuation. We include the distributions with punctuation is to match with the baseline system reported in [Charniak and Johnson 2001], where punctuation is included to identify the edited regions. Resent research showed that certain punctuation/prosody marks can be produced when speech signals are available [Liu et al. 2003]. The interregnum type, by definition, does not include punctuation. The length distributions of the reparanda in the training part of the Switchboard data with and Figure 1. Length distribution of reparanda in Switchboard training data. Figure 2. Length distribution of repairs/repeats/restarts in Switchboard training data. Figure 3. Length distribution of interregna in Switchboard training data. The two repair/repeat part distributions in the training part of the Switchboard are given in Fig. 2. The repairs/repeats with lengths less than 7 words 50% 40% 30% 20% 10% 0% 1 2 3 4 5 6 7 8 9 10 Le</context>
</contexts>
<marker>Liu, Shriberg, Stolcke, 2003</marker>
<rawString>Liu, Yang, Elizabeth Shriberg, Andreas Stolcke. 2003. Automatic disfluency identification in conversational speech using multiple knowledge sources Proc. Eurospeech, 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mari Ostendorf</author>
<author>Jeremy G Kahn</author>
<author>Darby Wong</author>
<author>Dustin Hillard</author>
<author>William McNeill</author>
</authors>
<date>2004</date>
<booktitle>Leveraging Structural MDE in Language Processing. EARS RT04 Workshop,</booktitle>
<contexts>
<context position="1950" citStr="Ostendorf et al. 2004" startWordPosition="281" endWordPosition="284">essing speech repairs properly poses a challenge to spoken dialog systems. Early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [Young and Matessa 1991, Bear et al. 1992, Heeman &amp; Allen 1994]. Because of the availability of the Switchboard corpus [Godfrey et al. 1992] and other conversational telephone speech (CTS) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences [Charniak and Johnson 2001, Johnson and Charniak 2004, Ostendorf et al. 2004, Liu et al. 2005]. In this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the Switchboard corpus. A clear benefit of having accurate edited regions for parsing has been demonstrated by a concurrent effort on parsing conversational speech [Kahn et al 2005]. Since different machine learning methods provide similar performances on many NLP tasks, in this paper, we focus our attention on exploring feature spaces and selecting good features for identifying edited regions. We start by analyzing the distributions of </context>
<context position="19945" citStr="Ostendorf et al. 2004" startWordPosition="3261" endWordPosition="3264">rchy in rough copy +d+rw+rh+wt+ps Distance + window sizes + word &amp; tag pairs + relaxed word and POS hierarchy in rough copy + pattern substitution Table 3. Description of method codes used in the result table. For example, one miss is “because of the friends because of many other things”, an error we would have a much better chance of correct identification, if we were able to identify prepositional phrases reliably. Another example is “most of all my family”. Since it is grammatical by itself, certain prosodic information in between “most of” and “all my family” may help the identification. [Ostendorf et al. 2004] reported that interruption point could help parsers to improve results. [Kahn et al. 2005] also showed that prosody information could help parse disfluent sentences. The second major class of the misses is certain short words that are not labeled consistently in the corpus. For example, “so”, “and”, and “or”, when they occur in the beginning of a sentence, are sometimes labeled as edited, and sometimes just as normal. The last category of the misses, about 5.3%, contains the ones where the distances between reparanda and repairs are often more than 10 words. Among the 95 false alarms, more t</context>
</contexts>
<marker>Ostendorf, Kahn, Wong, Hillard, McNeill, 2004</marker>
<rawString>Ostendorf, Mari, Jeremy G. Kahn, Darby Wong, Dustin Hillard, and William McNeill. Leveraging Structural MDE in Language Processing. EARS RT04 Workshop, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>Improved Boosting Algorithms Using Confidence-rated Predictions.</title>
<date>1999</date>
<journal>Machine Learning</journal>
<volume>37</volume>
<issue>3</issue>
<pages>297--336</pages>
<contexts>
<context position="7638" citStr="Schapire and Singer 1999" startWordPosition="1191" endWordPosition="1194">chboard data, we noticed that a large number of reparanda and repair/repeat pairs differ on less than two words, i.e. “as to, you know, when to”1, and the amount of the pairs differing on less than two POS tags is even bigger. There are also cases where some of the pairs have different lengths. These findings provide a good base for our feature space. 3 Feature Space Selection for Boosting We take as our baseline system the work by [Charniak and Johnson 2001]. In their approach, rough copy is defined to produce candidates for any potential pairs of reparanda and repairs. A boosting algorithm [Schapire and Singer 1999] is used to detect whether a word is edited. A total of 18 variables are used in the algorithm. In the rest of the section, we first briefly introduce the boosting algorithm, then describe the method used in [Charniak and Johnson 2001], and finally we contrast our improvements with the baseline system. 3.1 Boosting Algorithm Intuitively, the boosting algorithm is to combine a set of simple learners iteratively based on their classification results on a set of training data. Different parts of the training data are scaled at each iteration so that the parts of the data previous classifiers per</context>
</contexts>
<marker>Schapire, Singer, 1999</marker>
<rawString>Robert E. Schapire and Yoram Singer, 1999. Improved Boosting Algorithms Using Confidence-rated Predictions. Machine Learning 37(3): 297-336, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elizabeth Shriberg</author>
</authors>
<title>Preliminaries to a Theory of Speech Disfluencies.</title>
<date>1994</date>
<tech>Ph.D. Thesis. UC Berkeley,1994.</tech>
<contexts>
<context position="3480" citStr="Shriberg 1994" startWordPosition="516" endWordPosition="517">mprovement in F-score over the earlier best result reported in [Charniak and Johnson 2001], where punctuation is included in both the training and testing data of the Switchboard corpus, and a significant error reduction in F-score over the latest best result [Johnson and Charniak 2004], where punctuation is ignored in both the training and testing data of the Switchboard corpus. 179 Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 179–185, Vancouver, October 2005. c�2005 Association for Computational Linguistics In this paper, we follow the definition of [Shriberg 1994] and others for speech repairs: A speech repair is divided into three parts: the reparandum, the part that is repaired; the interregnum, the part that can be either empty or fillers; and the repair/repeat, the part that replaces or repeats the reparandum. The definition can also be exemplified via the following utterance: without punctuation are given in Fig. 1. The reparanda with lengths of less than 7 words make up 95.98% of such edited regions in the training data. When we remove the punctuation marks, those with lengths of less than 6 words reach roughly 96%. Thus, the patterns that consi</context>
<context position="4810" citStr="Shriberg 1994" startWordPosition="733" endWordPosition="734">, we examine the distributions of the editing regions in Switchboard data. Section 3, then, presents the Boosting method, the baseline system and the feature spaces we want to explore. Section 4 describes, step by step, a set of experiments that lead to a large performance improvement. Section 5 concludes with discussion and future work. 2 Repair Distributions in Switchboard We start by analyzing the speech repairs in the Switchboard corpus. Switchboard has over one million words, with telephone conversations on prescribed topics [Godfrey et al. 1992]. It is full of disfluent utterances, and [Shriberg 1994, Shriberg 1996] gives a thorough analysis and categorization of them. [Engel et al. 2002] also showed detailed distributions of the interregnum, including interjections and parentheticals. Since the majority of the disfluencies involve all the three parts (reparandum, interregnum, and repair/repeat), the distributions of all three parts will be very helpful in constructing patterns that are used to identify edited regions. For the reparandum and repair types, we include their distributions with and without punctuation. We include the distributions with punctuation is to match with the baselin</context>
</contexts>
<marker>Shriberg, 1994</marker>
<rawString>Shriberg, Elizabeth. 1994. Preliminaries to a Theory of Speech Disfluencies. Ph.D. Thesis. UC Berkeley,1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elizabeth Shriberg</author>
</authors>
<date>1996</date>
<booktitle>Disfluencies in Switchboard. Proc. of ICSLP.</booktitle>
<contexts>
<context position="4825" citStr="Shriberg 1996" startWordPosition="735" endWordPosition="736">e distributions of the editing regions in Switchboard data. Section 3, then, presents the Boosting method, the baseline system and the feature spaces we want to explore. Section 4 describes, step by step, a set of experiments that lead to a large performance improvement. Section 5 concludes with discussion and future work. 2 Repair Distributions in Switchboard We start by analyzing the speech repairs in the Switchboard corpus. Switchboard has over one million words, with telephone conversations on prescribed topics [Godfrey et al. 1992]. It is full of disfluent utterances, and [Shriberg 1994, Shriberg 1996] gives a thorough analysis and categorization of them. [Engel et al. 2002] also showed detailed distributions of the interregnum, including interjections and parentheticals. Since the majority of the disfluencies involve all the three parts (reparandum, interregnum, and repair/repeat), the distributions of all three parts will be very helpful in constructing patterns that are used to identify edited regions. For the reparandum and repair types, we include their distributions with and without punctuation. We include the distributions with punctuation is to match with the baseline system report</context>
</contexts>
<marker>Shriberg, 1996</marker>
<rawString>Shriberg, Elizabeth. 1996. Disfluencies in Switchboard. Proc. of ICSLP. 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Young</author>
<author>M Matessa</author>
</authors>
<title>Using pragmatic and semantic knowledge to correct parsing of spoken language utterances.</title>
<date>1991</date>
<booktitle>Proc. Eurospeech 91,</booktitle>
<location>Genova, Italy.</location>
<contexts>
<context position="1566" citStr="Young and Matessa 1991" startWordPosition="223" endWordPosition="226">k and Johnson 2001], and 20.44% percent relative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004]. 1 Introduction Repairs, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such disfluent phenomena. Processing speech repairs properly poses a challenge to spoken dialog systems. Early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [Young and Matessa 1991, Bear et al. 1992, Heeman &amp; Allen 1994]. Because of the availability of the Switchboard corpus [Godfrey et al. 1992] and other conversational telephone speech (CTS) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences [Charniak and Johnson 2001, Johnson and Charniak 2004, Ostendorf et al. 2004, Liu et al. 2005]. In this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the Switchboard corpus. A clear benefit of having accurat</context>
</contexts>
<marker>Young, Matessa, 1991</marker>
<rawString>Young, S. R. and Matessa, M. (1991). Using pragmatic and semantic knowledge to correct parsing of spoken language utterances. Proc. Eurospeech 91, Genova, Italy.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>