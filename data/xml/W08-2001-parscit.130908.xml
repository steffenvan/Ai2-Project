<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001096">
<title confidence="0.9977145">
Acquistion of the morphological structure of the lexicon
based on lexical similarity and formal analogy
</title>
<author confidence="0.837044">
Nabil Hathout
</author>
<affiliation confidence="0.730108">
Université de Toulouse
</affiliation>
<email confidence="0.574037">
Nabil.Hathout@univ-tlse2.fr
</email>
<sectionHeader confidence="0.987131" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999905266666667">
The paper presents a computational model
aiming at making the morphological struc-
ture of the lexicon emerge from the for-
mal and semantic regularities of the words
it contains. The model is purely lexeme-
based. The proposed morphological struc-
ture consists of (1) binary relations that
connect each headword with words that
are morphologically related, and especially
with the members of its morphological
family and its derivational series, and of
(2) the analogies that hold between the
words. The model has been tested on the
lexicon of French using the TLFi machine
readable dictionary.
</bodyText>
<sectionHeader confidence="0.984928" genericHeader="keywords">
1 Lexeme-based morphology
</sectionHeader>
<bodyText confidence="0.999731">
Morphology is traditionally considered to be the
field of linguistics that studies the structure of
words. In this conception, words are made of
morphemes which combine according to rules
of inflexion, derivation and composition. If the
morpheme-based theoretical framework is both el-
egant and easy to implement, it suffers many draw-
backs pointed out by several authors (Anderson,
1992; Aronoff, 1994). The alternative theoreti-
cal models that have been proposed falls within
lexeme-based or word-based morphology in which
the minimal units are words instead of morphemes.
Words then do not have any structure at all and
morphology becomes a level of organization of the
lexicon based on the sharing of semantic and for-
mal properties.
</bodyText>
<footnote confidence="0.90297425">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.9998332">
The morpheme-based / lexeme-based distinc-
tion shows up on the computational level. In
the morpheme-based conception, the morpholog-
ical analysis of a word aims at segmenting it into
a sequence of morphemes (Déjean, 1998; Gold-
smith, 2001; Creutz and Lagus, 2002; Bernhard,
2006). In a lexeme-based approach, it is to dis-
cover the relations between the word and the other
lexical items. These relations serve to identify
the morphological family of the word, its deriva-
tional series, and the analogies in which it is in-
volved. For instance, the analysis of the French
word dérivation may be considered as satisfac-
tory if it connects dérivation with enough mem-
bers of its family (dériver ‘derivate’, dérivationnel
‘derivational’, dérivable, dérive ‘drift’, dériveur
‘sailing dinghy’, etc.) and of its derivational
series (formation ‘education’, séduction, varia-
tion, émission, etc.). Each of these relations
is integrated into a large collection of analogies
that characterizes it semantically and formally.
For instance, the relation between dérivation and
dérivable is part of a series of analogies which
includes dérivation:dérivable::variation:variable,
dérivation:dérivable::modification:modifiable, etc.
Similarly, dérivation and variation participates in
a series of analogies such as dérivation:varia-
tion::dériver:varier, dérivation:variation::dériva-
tionnel:variationnel, dérivation:variation::dériva-
ble:variable.
</bodyText>
<sectionHeader confidence="0.985812" genericHeader="introduction">
2 Computational modeling
</sectionHeader>
<bodyText confidence="0.999923166666667">
The paper describes a computational model aiming
at making the morphological derivational structure
of the lexicon emerge from the semantic and the
formal regularities of the words it contains. A first
experiment is currently underway on the lexicon
of French using the TLFi machine readable dictio-
</bodyText>
<page confidence="0.821934">
1
</page>
<note confidence="0.9548995">
Coling 2008: Proceedings of 3rd Textgraphs workshop on Graph-Based Algorithms in Natural Language Processing, pages 1–8
Manchester, August 2008
</note>
<bodyText confidence="0.996383058823529">
nary.1 The main novelty of the paper is the com-
bination of lexical proximity with formal analogy.
We first use lexical similarity in order to select a
set of words that are likely to be morphologically
related to each other. Then, these candidates are
checked by means of analogy.
The two techniques are complementary. The
first one brings closer the words that are morpho-
logically close and especially the ones that are
members of the same morphological families and
the same derivational series. It is able to deal with
large number of words, but it is too coarse-grained
to discriminate the words that are actually mor-
phological related from the ones that are not. The
second technique, formal analogy, is then used to
perform a fine-grained filtering. Technically, our
model joins:
</bodyText>
<listItem confidence="0.996980555555555">
1. the representation of the lexicon as a graph
and its exploration through random walks,
along the line of (Gaume et al., 2002; Gaume
et al., 2005; Muller et al., 2006), and
2. formal analogies on words (Lepage, 1998;
Stroppa and Yvon, 2005). This approach does
do not make use of morphemes. Correspon-
dence between words is calculated directly on
their graphemic representations.
</listItem>
<bodyText confidence="0.600537">
More generally, our approach is original in that:
</bodyText>
<listItem confidence="0.960347133333333">
1. Our computational model is pure lexeme-
based. The discovery of morphological rela-
tions between words do not involve the no-
tions of morpheme, affix, morphological ex-
ponent, etc. nor any representation of these
concepts.
2. The membership to the families and series is
gradient. It accounts, for instance, for the fact
that dériveur is morphologically and semanti-
cally closer to dérive than to dérivationnelle-
ment, even if the three words belong to the
same family. The model connects the words
that share semantic and / or formal features.
The more features are shared, the closer the
words are.
</listItem>
<bodyText confidence="0.98529175">
Besides, the model integrates semantic and for-
mal informations in a uniform manner. All kind
of semantic informations (lexicographic defini-
tions, synonyms, synsets, etc.) and formal ones
</bodyText>
<footnote confidence="0.975287">
1Trésor de la Langue Française (http://atilf.atilf.fr/).
</footnote>
<bodyText confidence="0.9998082">
(graphemic, phonological, etc.) can be used. They
can be cumulated easily in spite of the differences
in nature and origin. The model takes advantage of
the redundancy of the features and is fairly insen-
sitive to variation and exceptions.
</bodyText>
<sectionHeader confidence="0.999894" genericHeader="method">
3 Related work
</sectionHeader>
<bodyText confidence="0.999933484848485">
Many works in the field of computational mor-
phology aim at the discovery of relations be-
tween lexical units. All of them rely primarily on
finding similarities between the word graphemic
forms. These relations are mainly prefixal or suf-
fixal with two exceptions, (Yarowsky and Wicen-
towski, 2000) and (Baroni et al., 2002), who use
string edit distances to estimate formal similarity.
As far as we know, all the other perform some sort
of segmentation even when the goal is not to find
morphemes as in (Neuvel and Fulop, 2002). Our
model differs from these approaches in that the
graphemic similarities are determined solely on the
basis of the sharing of graphemic features. It is the
main contribution of this paper.
Our model is also related to approaches that
combine graphemic and semantic cues in order
to identify morphemes or morphological relations
between words. Usually, these semantic infor-
mations are automatically acquired from corpora
by means of various techniques as latent semantic
analysis (Schone and Jurafsky, 2000), mutual in-
formation (Baroni et al., 2002) or co-occurrence in
an n-word window (Xu and Croft, 1998; Zweigen-
baum and Grabar, 2003). In the experiment we
present here, semantic informations are extracted
from a machine readable dictionary and semantic
similarity is calculated through random walks in a
lexical graph. Our approach can also be compared
with (Hathout, 2002) where morphological knowl-
edge is acquired by using semantic informations
extracted from dictionaries of synonyms or from
WordNet.
</bodyText>
<sectionHeader confidence="0.991854" genericHeader="method">
4 Lexeme Description
</sectionHeader>
<bodyText confidence="0.999937888888889">
In our model, the lexical units and their properties
are represented in a bipartite graph with the ver-
tices representing the lexemes in one sub-set and
the vertices representing the formal and semantic
features in the other. Lexeme vertices are identi-
fied by the lemma and the grammatical category.
In the experiment reported in the paper, the for-
mal properties are the n-grams of letters that occur
in the lexemes lemma. Figure 1 shows a sub-set of
</bodyText>
<page confidence="0.733657">
2
</page>
<equation confidence="0.984152">
$or; $ori; $orie; ...
$orientation; ori; orie; ...
orientation; orientation$; ...
tio; tion; tion$; ion; ion$; on$
</equation>
<figureCaption confidence="0.9871175">
Figure 1: Excerpt of the formal features associated
with the noun orientation.
</figureCaption>
<table confidence="0.879239555555556">
N.action; N.action X.de; N.action
X.de V.orienter; X.de; X.de
V.orienter; V.orienter; X.de
V.s’orienter; V.s’orienter;
N.résultat; N.résultat X.de;
N.résultat X.de X.ce; N.résultat
X.de X.ce N.action; X.de X.ce;
X.de X.ce N.action; X.ce; X.ce
N.action; N.action
</table>
<figureCaption confidence="0.994748714285714">
Figure 2: Semantic features induced by the defi-
nition “Action d’orienter, de s’orienter ; résultat de
cette action.” of the noun orientation
Figure 3: Excerpt of the bipartite graph which rep-
resents the lexicon. Words are displayed in ovals,
semantic feature in rectangles and formal features
in octagons. The graph is symmetric.
</figureCaption>
<figure confidence="0.996869818181818">
N.action X.de
N.résultat X.de X.ce
N.orientation
V.orienter
A.original
orient
entati
$ori
$or
N.fermentation
N.pointage
</figure>
<bodyText confidence="0.9994011">
the formal features associated with the word orien-
tation. The beginning and the end of the lemma are
marked by the character $. We impose a minimum
size on the n-grams (n ≥ 3).
The model is pure lexeme-based because this
decomposition does not confer a special status to
any of the individual n-grams which character-
ize the lexemes. All n-grams play the same role
and therefore no one has the status of morpheme.
These features are only used to bring closer the
words that share the same sounds.
The semantic properties we have used are ex-
tracted from the TLFi definitions. Each headword
is provided with the n-grams of words that occur
in its definitions. The n-grams that contain punc-
tuation marks are eliminated. In other words, we
only use n-grams of words that occur between two
punctuation marks. For instance, the semantic fea-
tures induced by the definition Action d’orienter,
de s’orienter; résultat de cette action. (‘act of ori-
enting, of finding one’s way; result of this action’)
of the noun orientation are presented in figure 2.
The words in the definitions are POS tagged and
lemmatized. The tags are A for adjectives, N for
nouns, R for adverbs, V for verbs and X for all
other categories.
This is a very coarse semantic representation in-
spired from the repeated segments (Lebart et al.,
1998). It offers three advantages: (1) being heav-
ily redundant, it can capture various levels of sim-
ilarity between the definitions; (2) it integrates in-
formations of a syntagmatic nature without a deep
syntactic analysis of the definitions; (3) it slightly
reduces the strong variations in the lexicographi-
cal treatment of the headwords, especially in the
division into sub-senses and in the definitions.
The bipartite graph is built up by symmetrically
connecting each headword to its semantic and for-
mal features. For instance, the noun orientation
is connected with the formal feature $or, $ori,
$orie, $orien, etc. which are in turn connected
with the words orienter, orientable, orientement
‘orientation’, orienteur ‘orientor’, etc. Likewise,
orientation is connected with the semantic fea-
tures N.action X.de, N.résultat X.de
X.ce N.action, etc. which are themselves
connected with the nouns orientement, harmoni-
sation ‘synchronization’, pointage ‘checking’, etc.
The general schema is illustrated in figure 4. This
representation corresponds precisely to the Net-
work Model of Bybee (1995).
We use a bipartite graph mainly for two reasons:
(1) We can spread an activation synchronously into
the formal and the semantic sub-graphs. (2) It con-
tains representations of the formal and the seman-
tic properties of the lexemes which, for instance,
could be used in order to describe the semantics of
the -able suffixation or the characteristic endings
of the boat names (-ier, -eur, etc.). However, the
bipartite structure is not essential and we only need
</bodyText>
<page confidence="0.994959">
3
</page>
<bodyText confidence="0.9989745">
to be able to compute morphological distances be-
tween words.
</bodyText>
<sectionHeader confidence="0.981864" genericHeader="method">
5 Random walks
</sectionHeader>
<bodyText confidence="0.9964719375">
The computational side of the method is based on
the estimation of the proximity between words rep-
resented in a lexical graph (Gaume et al., 2002;
Gaume et al., 2005; Muller et al., 2006). The
graphs used in this approach are slightly different
from the ones presented above. All their vertices
represent words and the edges describe semantic
relations such as synonymy. The proximity is com-
puted by simulating the spreading into the graph of
an activation initiated at a vertice. Following the
spreading, the nodes which are most excited are
regarded as being the closest to the initial vertice.
The same method can be used to estimate the
morphological proximity between words that are
described in a bipartite graph like the one we pro-
pose (see figure 4). It then connects words that
have the same semantic and formal features. One
has just to propagate the activation into the bipar-
tite graph for an even number of times. When the
graph is heavily redundant, two steps of propaga-
tion are sufficient to obtain the intended proximity
estimations.
In the example in figure 4, the morphological
neighbors of the noun orientation are identified by
activating the vertice which represents it. In the
first step, the activation is spread toward the ver-
tices which represent its formal and semantic fea-
tures. In the second step, the activation located on
the feature vertices is spread toward the headword
vertices. For instance, orienter becomes activated
via the formal features $or, $ori, orien and
fermentation through the formal feature entati
and the semantic feature N.résultat X.de
X.ce. The greater the number of features shared
by a headword with orientation, the stronger the
activation it receives.
The spreading of activation is simulated as a ran-
dom walk in the lexical graph, classically com-
puted as a multiplication of the stochastic adja-
cency matrix. More precisely, let G = (V, E, w)
be a weighted graph consisting of a set of ver-
tices V = {v1, ... , vn}, a set of edges E C V 2
and of a weight function w : E —* R. Let A
be the adjacency matrix of G, that is a n x n
matrix such that Aij = 0 if (vi, vj) E� E and
Aij = w(vi, vj) if (vi, vj) E E. (In the experi-
ment, w(e) = 1, be E E.) We normalize the rows
of A in order to get a stochastic matrix M. Mn ij
is
the probability of reaching node vj from the node
vi through a walk of n steps. This probability can
also be regarded as an activation level of node vj
following an n-step spreading initiated at vertice
vi.
In the experiment presented in this paper, the ac-
tivation is spread for one half toward the seman-
tic feature and for the other toward the formal fea-
tures. The edges of the bipartite graph can be di-
vided in three parts E = J U K U L where J con-
tains the edges that connect a headword to a for-
mal feature, K the edges that connect a headword
to a semantic feature and L the edges that connect
a formal or semantic feature to a headword. The
values of M are defined as follows:
</bodyText>
<equation confidence="0.9734554375">
z� 7 —
•ifeii(v vj)EJ,Mi-- Aij if
ih
z� 7 2�.e EJ Aih
vi is connected to a semantic feature and
M, , — Aij otherwise.
z,� �eik∈J Aik
• if eik = (vi,vk) E K, Mik = 2 E+ Aik A if
L.eih∈K ih
vi is connected to a formal feature and
Mik = Aik otherwise.
Leih∈K Aih
• if e
il = (v Ail
z� v l) E L + Mil
eih∈L Aih .
</equation>
<sectionHeader confidence="0.987179" genericHeader="method">
6 Lexical neighborhood
</sectionHeader>
<bodyText confidence="0.999981304347826">
The graph used in the experiment has been built
from the definitions of the TLFi. We only removed
the definitions of non standard uses (old, slang,
etc.). The extraction and cleaning-up of the defi-
nitions have been carried out in collaboration with
Bruno Gaume and Philippe Muller. The bipartite
graph has been created from 225 529 definitions
describing 75 024 headwords (lexemes). We then
removed all the features associated only with one
headword. This reduces the size of the graph sig-
nificantly without changing the connections that
hold between the headwords. Table 1 shows that
this reduction is stronger for the semantic feature
(93%) than it is for the formal ones (69%). Indeed,
semantic descriptions show greater variability than
formal ones.
The use of the graph is illustrated in figure 4. It
shows the 20 nearest neighbors of the verb fruc-
tifier for various propagation configurations. The
examples in (a) and (b) show clearly that formal
features are the more predictive ones while seman-
tic features are the less reliable ones. The example
in (c) illustrates the contribution of the semantic
</bodyText>
<page confidence="0.970758">
4
</page>
<figure confidence="0.999507">
(a) V.fructifier N.fructification A.fructificateur A.fructifiant A.fructifère V.sanctifier V.rectifier
A.rectifier V.fructidoriser N.fructidorien N.fructidor N.fructuosité R.fructueusement A.fructueux
N.rectifieur A.obstructif A.instructif A.destructif A.constructif N.infructuosité
(b) V.fructifier V.trouver N.missionnaire N.mission A.missionnaire N.saisie N.police N.hangar N.dîme
N.ban V.affruiter N.melon N.saisonnement N.azédarach A.fruitier A.bifère V.saisonner N.roman
N.troubadour V.contaminer
(c) V.fructifier A.fructifiant N.fructification A.fructificateur V.trouver A.fructifère V.rectifier
V.sanctifier A.rectifier V.fructidoriser N.fructidor N.fructidorien N.missionnaire N.mission
A.missionnaire A.fructueux R.fructueusement N.fructuosité N.rectifieur N.saisie
</figure>
<figureCaption confidence="0.982131666666667">
Figure 4: The 20 nearest neighbors of the verb fructifier when the activation is spread (a) only toward
the formal features, (b) only toward the semantic ones, (c) toward both the semantic and formal features.
Words that do not belong to the family or series of fructifier are emphasized.
</figureCaption>
<table confidence="0.971588333333333">
graph complete reduced
formal features 1 306 497 400 915
semantic features 7 650 490 548 641
</table>
<tableCaption confidence="0.94186">
Table 1: Number of the semantic and formal fea-
tures coming from TLFi.
</tableCaption>
<bodyText confidence="0.9998702">
features. They reorder the formal neighbors and
introduce among them the nearest semantic neigh-
bors. We see in the lists in (a) and (c) that the fam-
ily members are the nearest neighbors and that the
members of the series come next.
</bodyText>
<sectionHeader confidence="0.996072" genericHeader="method">
7 Analogy
</sectionHeader>
<bodyText confidence="0.999930259259259">
The members of the series and families are mas-
sively involved in the analogies which structure the
lexicon. A word x belonging to a family Fx partic-
ipates in several analogies with a large number of
other members of Fx. The analogies that involve
two words (x, y) ∈ F2 include two other words
(z, t) that belong to one same family F0. On the
other hand, if x is a complex word that belongs
to a series Sx, then z ∈ Sx, x ∈ Sz, y ∈ St
and t ∈ Sy. For instance, the couple of words
fructifier and fructification form analogies with of
members of other families (rectifier, rectification),
(certifier, certification), (plastifier, plastification),
etc. Moreover, the first elements of these couples
belong to series offructifier and the second ones to
the series of fructification.
In a dual manner, a word u belonging to a se-
ries S participates in a set of analogies with a large
number of other members of S. The analogies that
involve two elements of the same series are made
up with words which themselves belong to a same
series. For instance, fructifier and sanctifier form
analogies with the members of other series (fruc-
tificateur, sanctificateur), (fructification, sanctifi-
cation) or (fructifiant, sanctifiant). These couples
are respectively made of members of the families
of fructifier and sanctifier.
</bodyText>
<subsectionHeader confidence="0.994164">
7.1 Analogies and neighborhoods
</subsectionHeader>
<bodyText confidence="0.999303181818182">
The analogies that involve members of families
and series can be used to efficiently filter the
morphological neighbors that are identified by the
method presented above. If v is a correct morpho-
logical neighbor of w, then it is either a member of
the family of m or a member of its series. There-
fore, it exists another neighbor v0 of w (v0 belong
to the family of w if v belongs to the series of w
or vice versa) such that it exists a neighbor w0 of v
and of v0 such that w : v :: v0 : w0.2 Therefore, we
have two configurations:
</bodyText>
<listItem confidence="0.85007675">
1. if v ∈ F,,,, then ∃v0 ∈ S,,,, ∃w0 ∈ S„∩F„,, w :
v :: v0 : w0
2. if v ∈ S,,,, then ∃v0 ∈ F,,,, ∃w0 ∈ F„∩S„,, w :
v :: v0 : w0
</listItem>
<bodyText confidence="0.999685">
The first case is illustrated by the above examples
with w = fructifier and v = fructification, and the
second one with w = fructifier et v = rectifier.
</bodyText>
<subsectionHeader confidence="0.99674">
7.2 Formal analogy
</subsectionHeader>
<bodyText confidence="0.999720666666667">
A formal or graphemic analogy is a relation
a : b :: c : d that holds between four strings
such that the graphemic differences between a
</bodyText>
<footnote confidence="0.717187">
2The notation a : b :: c : d is used as a shorthand for the
statement that (a, b, c, d) forms an analogical quadruplet, or
in other words that a is to b as c is to d.
</footnote>
<page confidence="0.993195">
5
</page>
<bodyText confidence="0.999099666666667">
and b are the same as the ones between c and d.
It can be exemplified with the four Arabic words
kataba:maktoubon::fa3ala:maf3oulon
which respectively are transcriptions of the verb
‘write’, the noun ‘document’, the verb ‘do’ and
the noun ‘effect.’3 The differences between the
first two words and between the two last ones can
be described as in figure 5. They are identical for
the two couples of words.
</bodyText>
<figure confidence="0.9911638">
E k a t a b a
ma k E t ou b on
f 3 l
E a a a
ma f E 3 ou l on
</figure>
<figureCaption confidence="0.846384666666667">
Figure 5: Formal analogy kataba:
maktoubon::fa3ala:maf3oulon. The
differences are locates in frame boxes.
</figureCaption>
<bodyText confidence="0.999657823529412">
More generally, formal analogies can be
defined in terms of factorization (Stroppa and
Yvon, 2005). Let L be an alphabet and a E L*
a string over L. A factorization of a is a se-
quence f = (f1, • • • , fn) E L*n such that
a = f1 ® • • • ® fn where ® denotes the concate-
nation. For instance, (ma, k, E, t, ou, b, on)
is a factorization of length 7 of maktoubon.
Morphological analogies can be defined as
follows. Let (a, b, c, d) E L*4 be for strings.
a : b :: c : d is a formal analogy iff there exists
n E N and four factorizations of length n of the
four strings (f(a), f(b), f(c), f(d)) E L*4
such that, Vi E [1, n], (fi(b), fi(c)) E
I(fi(a), fi(d)), (fi(d), fi(a))1. For the analogy
kataba:maktoubon::fa3ala:maf3oulon,
the property holds for n = 7 (see figure 5).
</bodyText>
<subsectionHeader confidence="0.99706">
7.3 Implementation
</subsectionHeader>
<bodyText confidence="0.999908727272727">
A formal analogy a : b :: c : d can be easily
checked by comparing the sequences of string
edit operations between (a, b) and between (c, d).
Both sequences must minimize Levenshtein edit
distance (i.e. have a minimal cost). Each sequence
corresponds to a path in the edit lattices of the
couple of words. The lattice are represented by
a matrix computed using the standard string edit
algorithm (Jurafsky and Martin, 2000). The path
which describes the sequence of string edit opera-
tions starts at the last cell of the matrix and climbs
</bodyText>
<footnote confidence="0.9947385">
3This example is adapted from examples in (Lepage,
1998; Lepage, 2003).
</footnote>
<bodyText confidence="0.999674590909091">
to the first one. Only three directions are allowed:
upward (deletion), to the left (insertion) or in
the upper left diagonal direction (substitution).
Figure 6 shows the sequence of edit operations for
the couple fructueux:infructueusement.
Sequences of edit operations can be simplified
by merging the series of identical character
matchings. The sequence in figure 6 then becomes
((I,E,i), (I,E,n), (M,fructueu,fructueu),
(S,x,s), (I,E,e), (I,E,m), (I,E,e), (I,E,n), (I,E,t)).
This simplified sequence is identical to the one
for the couple soucieux:insoucieusement
except for the matching operation: ((I,E,i),
(I,E,n), (M,soucieu,soucieu), (S,x,s), (I,E,e),
(I,E,m), (I,E,e), (I,E,n), (I,E,t)). The two se-
quences can be made identical if the matching
sub-strings are not specified. The resulting
sequence can then be assigned to both cou-
ples as their edit signatures (σ). The formal
analogy fructueux:infructueusement::
soucieux:insoucieusement can be stated
in terms of identity the edit signatures:
</bodyText>
<equation confidence="0.997731">
σ(fructueux,infructueusement) =
σ(soucieux, insoucieusement) =
((I,E,i), (I,E,n),(M,O°,O°), (S,x,s), (I,E,e),
(I,E,m), (I,E,e), (I,E,n), (I,E,t))
</equation>
<bodyText confidence="0.939399">
More generally, four strings (a, b, c, d) E L*4 form
a formal analogy a : b :: c : d iff σ(a, b) = σ(c, d)
or σ(a, c) = σ(b, d).
</bodyText>
<subsectionHeader confidence="0.998995">
7.4 First results
</subsectionHeader>
<bodyText confidence="0.996733076923077">
The computational model we have just presented
has been implemented and a first experiment has
been carried out. It consists in determining the
100 closest neighbors of every headword for the
three configurations presented in § 6. All the for-
mal analogies that hold between these words have
then been collected. We have not been able to do a
standard evaluation in terms of recall and precision
because of the lack of morphological resources for
French. However, we have manually checked the
analogies of 22 headwords belonging to 4 morpho-
logical families. An analogy a : b :: c : d is ac-
cepted as correct if:
</bodyText>
<listItem confidence="0.997909">
• b belongs to the family of a, c belongs to the
series of a, d belongs to series of b and to the
family of c, or
• b belongs to the series of a, c belongs to the
family of a, d belongs to family of b and to
the series of c.
</listItem>
<page confidence="0.966746">
6
</page>
<figure confidence="0.972628666666667">
I I M M M M M M M M S I I I I I
E E f r u c t u e u x E E E E E
i n f r u c t u e u s e m e n t
</figure>
<figureCaption confidence="0.989926">
Figure 6: Sequence of edit operations that transform fructueux into infructueusement. The
</figureCaption>
<bodyText confidence="0.435687">
type of each operation is indicated on the first line: D for deletion, I for insertion, M for matching and S
for a substitution by a different character.
</bodyText>
<table confidence="0.9972895">
configuration analogies correct errors
formal 169 163 3.6%
semantics 5 5 0.0%
sem + form 130 128 1.5%
</table>
<tableCaption confidence="0.843263">
Table 2: Number of the analogies collected for a
sample of 22 headwords and error rate.
</tableCaption>
<bodyText confidence="0.928730142857143">
The results are summarized in table 2. Their qual-
ity is quite satisfactory. However, the number of
analogies strongly depends on the configuration of
propagation. The best trade-off is a simultaneous
propagation toward the semantic and formal fea-
tures. Here are some of the correct and erroneous
analogies collected:
</bodyText>
<table confidence="0.973974875">
• R.fructueusement:R.affectueusement::
A.infructueux:A.inaffectueux
length analogies correct errors
4 29 15 51.7%
5 22 8 36.4%
6 8 1 12.5%
7 10 2 20.0%
8 55 1 1.8%
9 29 2 6.9%
10 30 0 0.0%
11 32 0 0.0%
12 19 0 0.0%
13 11 0 0.0%
14 35 0 0.0%
15 63 0 0.0%
16 39 0 0.0%
</table>
<tableCaption confidence="0.8674205">
Table 3: Number of the analogies and error rate for
headwords of length 4 to 16.
</tableCaption>
<listItem confidence="0.98759775">
• N.fructification:N.identification::
V.fructifier:V.identifier
• N.fruiterie:N.fruitier::N.laiterie:N.laitier
• * N.fruit:N.bruit::V.frusquer:V.brusquer
</listItem>
<bodyText confidence="0.999969111111111">
The first example is particularly interesting be-
cause it involves on one side suffixed words and
on the other prefixed ones.
The performance of the method strongly de-
pends on the length of the headwords. Table 3
presents the number of analogies and the error rate
for 13 groups of 5 words. The words of each group
are of the same length. Lengths range from 4 to 16
letters.
</bodyText>
<sectionHeader confidence="0.998306" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999984666666667">
We have presented a computational model that
makes the morphological structure of the lexicon
emerge from the formal and semantic regularities
of the words it contains. The model is radically
lexeme-based. It integrates the semantic and for-
mal properties of the words in a uniform manner
and represents them into a bipartite graph. Ran-
dom walks are used to simulate the spreading of
activations in this lexical network. The level of
activation obtained after the propagation indicates
the lexical relatedness of the words. The members
of the morphological family and the derivational
series of each word are then identified among its
lexical neighbors by means of formal analogies.
This is work in progress and we still have to sep-
arate the members of the families from the mem-
bers of the series. We also intend to conduct a
similar experiment on the English lexicon and to
evaluate our results in a more classical manner by
using the CELEX database (Baayen et al., 1995)
as gold standard. The evaluation should also be
done with respect to well known systems like Lin-
guistica (Goldsmith, 2001) or the morphological
analyzer of Bernhard (2006).
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999759285714286">
I would like to thank the ATILF laboratory and
Jean-Marie Pierrel for making available to me the
TLFi. I am in debt to Bruno Gaume and Philippe
Muller for the many discussions and exchanges we
have had on the cleaning-up of the TFLi and its ex-
ploitation through random walks. I am also grate-
ful to Gilles Boyé, Olivier Haute-Cœur and Lu-
</bodyText>
<page confidence="0.997694">
7
</page>
<bodyText confidence="0.981441">
dovic Tanguy for their comments and suggestions. Conference on Language Resources and Evalua-
All errors are mine. tion, pages 1478–1484, Las Palmas de Gran Canaria.
ELRA.
</bodyText>
<sectionHeader confidence="0.989174" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999932085106383">
Anderson, Stephen R. 1992. A-Morphous Morphol-
ogy. Cambridge University Press, Cambridge, UK.
Aronoff, Mark. 1994. Morphology by Itself. Stem and
Inflexional Classes. MIT Press, Cambridge, Mass.
Baayen, R. Harald, Richard Piepenbrock, and Leon Gu-
likers. 1995. The CELEX lexical database (release
2). CD-ROM. Linguistic Data Consortium, Univer-
sity of Pennsylvania, Pennsylvania, USA.
Baroni, Marco, Johannes Matiasek, and Harald Trost.
2002. Unsupervised discovery of morphologically
related words based on orthographic and semantic
similarity. In Proceedings of the Workshop on Mor-
phological and Phonological Learning ofACL-2002,
pages 48–57, Philadelphia. ACL.
Bernhard, Delphine. 2006. Automatic acquisition of
semantic relationships from morphological related-
ness. In Advances in Natural Language Processing,
Proceedings of the 5th International Conference on
NLP, FinTAL 2006, volume 4139 of Lecture Notes in
Computer Science, pages 121–13. Springer.
Bybee, Joan L. 1995. Regular morphology and the lex-
icon. Language and cognitive processes, 10(5):425–
455.
Creutz, Mathias and Krista Lagus. 2002. Unsuper-
vised discovery of morphemes. In Proceedings of
the ACL Workshop on Morphological and Phono-
logical Learning, pages 21–30, Philadelphia, Penn.
ACL.
Déjean, Hervé. 1998. Morphemes as necessary con-
cept for structures discovery from untagged corpora.
In Proceedings of the Workshop on Paradigms and
Grounding in Natural Language Learning, pages
295–299, Adelaide, Australia.
Gaume, Bruno, Karine Duvigneau, Olivier Gasquet,
and Marie-Dominique Gineste. 2002. Forms of
meaning, meaning of forms. Journal of Experimen-
tal and Theoretical Artificial Intelligence, 14(1):61–
74.
Gaume, B., F. Venant, and B. Victorri. 2005. Hierar-
chy in lexical organization of natural language. In
Pumain, D., editor, Hierarchy in natural and social
sciences, Methodos series, pages 121–143. Kluwer.
Goldsmith, John. 2001. Unsupervised learning of
the morphology of natural language. Computational
Linguistics, 27(2):153–198.
Hathout, Nabil. 2002. From wordnet to celex: acquir-
ing morphological links from dictionaries of syn-
onyms. In Proceedings of the Third International
Jurafsky, Daniel and James H. Martin. 2000. Speech
and language processing. Prentice-Hall.
Lebart, Ludovic, André Salem, and Lisette Berry.
1998. Exploring textual data. Kluwer Academic
Publishers, Dordrecht.
Lepage, Yves. 1998. Solving analogies on words: an
algorithm. In Proceedings of COLING-ACL’98, vol-
ume 2, pages 728–735, Montréal, Canada.
Lepage, Yves. 2003. De l’analogie rendant compte de
la commutation en linguistique. Mémoire de HDR,
Université Joseph Fourier, Grenoble.
Muller, Philippe, Nabil Hathout, and Bruno Gaume.
2006. Synonym extraction using a semantic dis-
tance on a dictionary. In Radev, Dragomir and Rada
Mihalcea, editors, Proceedings of the HLT/NAACL
workshop Textgraphs, pages 65–72, New York, NY.
Association for Computational Linguistics.
Neuvel, Sylvain and Sean A. Fulop. 2002. Unsuper-
vised learning of morphology without morphemes.
In Proceedings of the Workshop on Morphologi-
cal and Phonological Learning 2002, Philadelphia.
ACL Publications.
Schone, Patrick and Daniel S. Jurafsky. 2000.
Knowledge-free induction of morphology using la-
tent semantic analysis. In Proceedings of the Confer-
ence on Natural Language Learning 2000 (CoNLL-
2000), pages 67–72, Lisbon, Portugal.
Stroppa, Nicolas and François Yvon. 2005. An analog-
ical learner for morphological analysis. In Proceed-
ings of the 9th Conference on Computational Natural
Language Learning (CoNLL-2005), pages 120–127,
Ann Arbor, Michigan, June. Association for Compu-
tational Linguistics.
Xu, Jinxi and W. Bruce Croft. 1998. Corpus-based
stemming using co-occurrence of word variants.
ACM Transaction on Information Systems, 16(1):61–
81.
Yarowsky, David and Richard Wicentowski. 2000.
Minimally supervised morphological analysis by
multimodal alignment. In Proceedings of the As-
sociation of Computational Linguistics (ACL-2000),
pages 207–216, Hong Kong.
Zweigenbaum, Pierre and Natalia Grabar. 2003.
Learning derived words from medical corpora. In
9th Conference on Artificial Intelligence in Medicine
Europe, pages 189–198, Cyprus.
</reference>
<page confidence="0.998492">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.8175285">Acquistion of the morphological structure of the based on lexical similarity and formal analogy</title>
<author confidence="0.673328">Nabil Hathout</author>
<affiliation confidence="0.855393">Université de Toulouse</affiliation>
<email confidence="0.515405">Nabil.Hathout@univ-tlse2.fr</email>
<abstract confidence="0.998004115942029">The paper presents a computational model aiming at making the morphological structure of the lexicon emerge from the formal and semantic regularities of the words it contains. The model is purely lexemebased. The proposed morphological structure consists of (1) binary relations that connect each headword with words that are morphologically related, and especially with the members of its morphological family and its derivational series, and of (2) the analogies that hold between the words. The model has been tested on the lexicon of French using the TLFi machine readable dictionary. 1 Lexeme-based morphology Morphology is traditionally considered to be the field of linguistics that studies the structure of words. In this conception, words are made of morphemes which combine according to rules of inflexion, derivation and composition. If the morpheme-based theoretical framework is both elegant and easy to implement, it suffers many drawbacks pointed out by several authors (Anderson, 1992; Aronoff, 1994). The alternative theoretical models that have been proposed falls within lexeme-based or word-based morphology in which the minimal units are words instead of morphemes. Words then do not have any structure at all and morphology becomes a level of organization of the lexicon based on the sharing of semantic and formal properties. Licensed under the Commons Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. The morpheme-based / lexeme-based distinction shows up on the computational level. In the morpheme-based conception, the morphological analysis of a word aims at segmenting it into a sequence of morphemes (Déjean, 1998; Goldsmith, 2001; Creutz and Lagus, 2002; Bernhard, 2006). In a lexeme-based approach, it is to discover the relations between the word and the other lexical items. These relations serve to identify the morphological family of the word, its derivational series, and the analogies in which it is involved. For instance, the analysis of the French be considered as satisfacif it connects enough memof its family ‘sailing dinghy’, etc.) and of its derivational variaetc.). Each of these relations is integrated into a large collection of analogies that characterizes it semantically and formally. instance, the relation between part of a series of analogies which etc. in series of analogies such as 2 Computational modeling The paper describes a computational model aiming at making the morphological derivational structure of the lexicon emerge from the semantic and the formal regularities of the words it contains. A first experiment is currently underway on the lexicon French using the TLFi machine readable dictio-</abstract>
<note confidence="0.336001">1 2008: Proceedings of 3rd Textgraphs workshop on Graph-Based Algorithms in Natural Language Processing, 1–8</note>
<date confidence="0.43695">Manchester, August 2008</date>
<abstract confidence="0.995831854368932">The main novelty of the paper is the combination of lexical proximity with formal analogy. We first use lexical similarity in order to select a set of words that are likely to be morphologically related to each other. Then, these candidates are checked by means of analogy. The two techniques are complementary. The first one brings closer the words that are morphologically close and especially the ones that are members of the same morphological families and the same derivational series. It is able to deal with large number of words, but it is too coarse-grained to discriminate the words that are actually morphological related from the ones that are not. The second technique, formal analogy, is then used to perform a fine-grained filtering. Technically, our model joins: 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lexemebased. The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts. 2. The membership to the families and series is gradient. It accounts, for instance, for the fact morphologically and semanticloser to to dérivationnelleeven if the three words belong to the same family. The model connects the words that share semantic and / or formal features. The more features are shared, the closer the words are. Besides, the model integrates semantic and formal informations in a uniform manner. All kind of semantic informations (lexicographic definitions, synonyms, synsets, etc.) and formal ones de la Langue Française (graphemic, phonological, etc.) can be used. They can be cumulated easily in spite of the differences in nature and origin. The model takes advantage of the redundancy of the features and is fairly insensitive to variation and exceptions. 3 Related work Many works in the field of computational morphology aim at the discovery of relations between lexical units. All of them rely primarily on finding similarities between the word graphemic forms. These relations are mainly prefixal or suffixal with two exceptions, (Yarowsky and Wicentowski, 2000) and (Baroni et al., 2002), who use string edit distances to estimate formal similarity. As far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (Neuvel and Fulop, 2002). Our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features. It is the main contribution of this paper. Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (Schone and Jurafsky, 2000), mutual information (Baroni et al., 2002) or co-occurrence in window (Xu and Croft, 1998; Zweigenbaum and Grabar, 2003). In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph. Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet. 4 Lexeme Description In our model, the lexical units and their properties are represented in a bipartite graph with the vertices representing the lexemes in one sub-set and the vertices representing the formal and semantic features in the other. Lexeme vertices are identified by the lemma and the grammatical category. In the experiment reported in the paper, the forproperties are the of letters that occur in the lexemes lemma. Figure 1 shows a sub-set of 2 $or; $ori; $orie; ... $orientation; ori; orie; ... orientation; orientation$; ... tio; tion; tion$; ion; ion$; on$ Figure 1: Excerpt of the formal features associated the noun</abstract>
<keyword confidence="0.669265">N.action; N.action X.de; N.action X.de V.orienter; X.de; X.de V.orienter; V.orienter; X.de V.s’orienter; V.s’orienter;</keyword>
<title confidence="0.8297996">N.résultat; N.résultat X.de; N.résultat X.de X.ce; N.résultat X.de X.ce N.action; X.de X.ce; X.de X.ce N.action; X.ce; X.ce N.action; N.action</title>
<abstract confidence="0.990755714285714">Figure 2: Semantic features induced by the definition “Action d’orienter, de s’orienter ; résultat de action.” of the noun Figure 3: Excerpt of the bipartite graph which represents the lexicon. Words are displayed in ovals, semantic feature in rectangles and formal features in octagons. The graph is symmetric.</abstract>
<title confidence="0.872015">N.action X.de N.résultat X.de X.ce N.orientation V.orienter</title>
<abstract confidence="0.99664351497006">A.original orient entati $ori $or N.fermentation N.pointage formal features associated with the word orien- The beginning and the end of the lemma are by the character We impose a minimum on the The model is pure lexeme-based because this decomposition does not confer a special status to of the individual which characterthe lexemes. All play the same role and therefore no one has the status of morpheme. These features are only used to bring closer the words that share the same sounds. The semantic properties we have used are extracted from the TLFi definitions. Each headword provided with the of words that occur its definitions. The that contain punctuation marks are eliminated. In other words, we use of words that occur between two punctuation marks. For instance, the semantic feainduced by the definition d’orienter, s’orienter; résultat de cette action. of orienting, of finding one’s way; result of this action’) the noun presented in figure 2. The words in the definitions are POS tagged and lemmatized. The tags are A for adjectives, N for nouns, R for adverbs, V for verbs and X for all other categories. This is a very coarse semantic representation inspired from the repeated segments (Lebart et al., 1998). It offers three advantages: (1) being heavily redundant, it can capture various levels of similarity between the definitions; (2) it integrates informations of a syntagmatic nature without a deep syntactic analysis of the definitions; (3) it slightly reduces the strong variations in the lexicographical treatment of the headwords, especially in the division into sub-senses and in the definitions. The bipartite graph is built up by symmetrically connecting each headword to its semantic and forfeatures. For instance, the noun connected with the formal feature etc. which are in turn connected the words etc. Likewise, connected with the semantic fea- X.de etc. which are themselves with the nouns harmonietc. The general schema is illustrated in figure 4. This representation corresponds precisely to the Network Model of Bybee (1995). We use a bipartite graph mainly for two reasons: (1) We can spread an activation synchronously into the formal and the semantic sub-graphs. (2) It contains representations of the formal and the semantic properties of the lexemes which, for instance, could be used in order to describe the semantics of or the characteristic endings the boat names etc.). However, the bipartite structure is not essential and we only need 3 to be able to compute morphological distances between words. 5 Random walks The computational side of the method is based on the estimation of the proximity between words represented in a lexical graph (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006). The graphs used in this approach are slightly different from the ones presented above. All their vertices represent words and the edges describe semantic relations such as synonymy. The proximity is computed by simulating the spreading into the graph of an activation initiated at a vertice. Following the spreading, the nodes which are most excited are regarded as being the closest to the initial vertice. The same method can be used to estimate the morphological proximity between words that are described in a bipartite graph like the one we propose (see figure 4). It then connects words that have the same semantic and formal features. One has just to propagate the activation into the bipartite graph for an even number of times. When the graph is heavily redundant, two steps of propagation are sufficient to obtain the intended proximity estimations. In the example in figure 4, the morphological of the noun identified by activating the vertice which represents it. In the first step, the activation is spread toward the vertices which represent its formal and semantic features. In the second step, the activation located on the feature vertices is spread toward the headword For instance, activated the formal features the formal feature the semantic feature X.de The greater the number of features shared a headword with the stronger the activation it receives. The spreading of activation is simulated as a random walk in the lexical graph, classically computed as a multiplication of the stochastic adjamatrix. More precisely, let E, be a weighted graph consisting of a set of ver- ... , a set of edges of a weight function Let the adjacency matrix of that is a such that 0 (In the experi- = We normalize the rows order to get a stochastic matrix ij is probability of reaching node the node a walk of This probability can be regarded as an activation level of node an spreading initiated at vertice In the experiment presented in this paper, the activation is spread for one half toward the semantic feature and for the other toward the formal features. The edges of the bipartite graph can be diin three parts contains the edges that connect a headword to a forfeature, edges that connect a headword a semantic feature and edges that connect a formal or semantic feature to a headword. The of defined as follows: • ih 7 connected to a semantic feature and if ih connected to a formal feature and if 6 Lexical neighborhood The graph used in the experiment has been built from the definitions of the TLFi. We only removed the definitions of non standard uses (old, slang, etc.). The extraction and cleaning-up of the definitions have been carried out in collaboration with Bruno Gaume and Philippe Muller. The bipartite graph has been created from 225 529 definitions describing 75 024 headwords (lexemes). We then removed all the features associated only with one headword. This reduces the size of the graph significantly without changing the connections that hold between the headwords. Table 1 shows that this reduction is stronger for the semantic feature (93%) than it is for the formal ones (69%). Indeed, semantic descriptions show greater variability than formal ones. The use of the graph is illustrated in figure 4. It the 20 nearest neighbors of the verb frucvarious propagation configurations. The examples in (a) and (b) show clearly that formal features are the more predictive ones while semantic features are the less reliable ones. The example in (c) illustrates the contribution of the semantic 4</abstract>
<title confidence="0.914750375">(a) V.fructifier N.fructification A.fructificateur A.fructifiant A.fructifère V.sanctifier V.rectifier V.fructidoriser N.fructidorien N.fructidor R.fructueusement A.fructueux A.obstructif A.instructif A.destructif A.constructif V.fructifier N.missionnaire N.mission A.missionnaire N.saisie N.police N.hangar N.dîme N.ban V.affruiter N.melon N.saisonnement N.azédarach A.fruitier A.bifère V.saisonner N.roman N.troubadour V.contaminer V.fructifier A.fructifiant N.fructification A.fructificateur V.rectifier V.fructidoriser N.fructidor N.fructidorien N.missionnaire N.mission</title>
<author confidence="0.649446">R fructueusement N fructuosité N saisie</author>
<abstract confidence="0.971503529411765">4: The 20 nearest neighbors of the verb the activation is spread (a) only toward the formal features, (b) only toward the semantic ones, (c) toward both the semantic and formal features. that do not belong to the family or series of emphasized. graph complete reduced formal features 1 306 497 400 915 semantic features 7 650 490 548 641 Table 1: Number of the semantic and formal features coming from TLFi. features. They reorder the formal neighbors and introduce among them the nearest semantic neighbors. We see in the lists in (a) and (c) that the family members are the nearest neighbors and that the members of the series come next. 7 Analogy The members of the series and families are massively involved in the analogies which structure the A word to a family participates in several analogies with a large number of members of The analogies that involve words include two other words belong to one same family On the hand, if a complex word that belongs a series then For instance, the couple of words analogies with of of other families etc. Moreover, the first elements of these couples to series the second ones to series of a dual manner, a word to a sein a set of analogies with a large of other members of The analogies that involve two elements of the same series are made up with words which themselves belong to a same For instance, with the members of other series sanctifior These couples are respectively made of members of the families 7.1 Analogies and neighborhoods The analogies that involve members of families and series can be used to efficiently filter the morphological neighbors that are identified by the presented above. If a correct morphoneighbor of then it is either a member of family of a member of its series. Thereit exists another neighbor of belong the family of to the series of vice versa) such that it exists a neighbor of of such that : Therefore, we have two configurations: if then ∈ ∈ w : if then ∈ ∈ w : The first case is illustrated by the above examples and the one with 7.2 Formal analogy A formal or graphemic analogy is a relation holds between four strings that the graphemic differences between notation used as a shorthand for the that b, c, an analogical quadruplet, or other words that to to 5 the same as the ones between It can be exemplified with the four Arabic words which respectively are transcriptions of the verb ‘write’, the noun ‘document’, the verb ‘do’ and noun The differences between the first two words and between the two last ones can be described as in figure 5. They are identical for the two couples of words. E k a t a b a ma k E t ou b on f 3 l E a a a ma f E 3 ou l on 5: Formal analogy differences are locates in frame boxes. More generally, formal analogies can be defined in terms of factorization (Stroppa and 2005). Let an alphabet and string over A factorization of a se- • • such that • • • ® where the concate- For instance, a factorization of length Morphological analogies can be defined as Let b, c, be for strings. a formal analogy iff there exists four factorizations of length the strings that, For the analogy property holds for 7 figure 5). 7.3 Implementation formal analogy be easily checked by comparing the sequences of string operations between between Both sequences must minimize Levenshtein edit distance (i.e. have a minimal cost). Each sequence corresponds to a path in the edit lattices of the couple of words. The lattice are represented by a matrix computed using the standard string edit algorithm (Jurafsky and Martin, 2000). The path which describes the sequence of string edit operations starts at the last cell of the matrix and climbs example is adapted from examples in (Lepage, 1998; Lepage, 2003). to the first one. Only three directions are allowed: upward (deletion), to the left (insertion) or in the upper left diagonal direction (substitution). Figure 6 shows the sequence of edit operations for couple Sequences of edit operations can be simplified by merging the series of identical character matchings. The sequence in figure 6 then becomes This simplified sequence is identical to the one the couple for the matching operation: The two quences can be made identical if the matching sub-strings are not specified. The sequence can then be assigned to both couas their edit signatures The formal be stated in terms of identity the edit signatures: = = generally, four strings b, c, form formal analogy = = 7.4 First results The computational model we have just presented has been implemented and a first experiment has been carried out. It consists in determining the 100 closest neighbors of every headword for the three configurations presented in § 6. All the formal analogies that hold between these words have then been collected. We have not been able to do a standard evaluation in terms of recall and precision because of the lack of morphological resources for French. However, we have manually checked the analogies of 22 headwords belonging to 4 morphofamilies. An analogy accepted as correct if: b to the family of to the of to series of to the of or b to the series of to the of to family of to series of 6 I I M M M M M M M M S I I I I I E r u c t u e u x E E E i n f r u c t u e u s e m e n t 6: Sequence of edit operations that transform The type of each operation is indicated on the first line: D for deletion, I for insertion, M for matching and S for a substitution by a different character. configuration analogies correct errors formal 169 163 3.6% semantics 5 5 0.0% 130 128 1.5% Table 2: Number of the analogies collected for a sample of 22 headwords and error rate. The results are summarized in table 2. Their quality is quite satisfactory. However, the number of analogies strongly depends on the configuration of propagation. The best trade-off is a simultaneous propagation toward the semantic and formal features. Here are some of the correct and erroneous analogies collected: • R.fructueusement:R.affectueusement:: A.infructueux:A.inaffectueux length analogies correct errors 4 29 15 51.7% 5 22 8 36.4% 6 8 1 12.5% 7 10 2 20.0% 8 55 1 1.8% 9 29 2 6.9% 10 30 0 0.0% 11 32 0 0.0% 12 19 0 0.0% 13 11 0 0.0% 14 35 0 0.0% 15 63 0 0.0% 16 39 0 0.0% Table 3: Number of the analogies and error rate for headwords of length 4 to 16. • N.fructification:N.identification:: V.fructifier:V.identifier • N.fruiterie:N.fruitier::N.laiterie:N.laitier • * N.fruit:N.bruit::V.frusquer:V.brusquer The first example is particularly interesting because it involves on one side suffixed words and on the other prefixed ones. The performance of the method strongly depends on the length of the headwords. Table 3 presents the number of analogies and the error rate for 13 groups of 5 words. The words of each group are of the same length. Lengths range from 4 to 16 letters. 8 Conclusion We have presented a computational model that makes the morphological structure of the lexicon emerge from the formal and semantic regularities of the words it contains. The model is radically lexeme-based. It integrates the semantic and formal properties of the words in a uniform manner and represents them into a bipartite graph. Random walks are used to simulate the spreading of activations in this lexical network. The level of activation obtained after the propagation indicates the lexical relatedness of the words. The members of the morphological family and the derivational series of each word are then identified among its lexical neighbors by means of formal analogies. This is work in progress and we still have to separate the members of the families from the members of the series. We also intend to conduct a similar experiment on the English lexicon and to evaluate our results in a more classical manner by using the CELEX database (Baayen et al., 1995) as gold standard. The evaluation should also be with respect to well known systems like Lin- 2001) or the morphological analyzer of Bernhard (2006). Acknowledgments I would like to thank the ATILF laboratory and Jean-Marie Pierrel for making available to me the TLFi. I am in debt to Bruno Gaume and Philippe Muller for the many discussions and exchanges we have had on the cleaning-up of the TFLi and its exploitation through random walks. I am also grateto Gilles Boyé, Olivier Haute-Cœur and Lu-</abstract>
<note confidence="0.7130835">7 Tanguy for their comments and suggestions. on Language Resources and Evaluaerrors are mine. pages 1478–1484, Las Palmas de Gran Canaria. ELRA.</note>
<title confidence="0.715481">References</title>
<author confidence="0.833706">R Stephen</author>
<affiliation confidence="0.762713">Cambridge University Press, Cambridge, UK.</affiliation>
<author confidence="0.464096">by Itself Stem</author>
<affiliation confidence="0.342071">MIT Press, Cambridge, Mass.</affiliation>
<address confidence="0.291852">Baayen, R. Harald, Richard Piepenbrock, and Leon Gu-</address>
<abstract confidence="0.741527363636364">likers. 1995. The CELEX lexical database (release 2). CD-ROM. Linguistic Data Consortium, University of Pennsylvania, Pennsylvania, USA. Baroni, Marco, Johannes Matiasek, and Harald Trost. 2002. Unsupervised discovery of morphologically related words based on orthographic and semantic In of the Workshop on Morand Phonological Learning pages 48–57, Philadelphia. ACL. Bernhard, Delphine. 2006. Automatic acquisition of semantic relationships from morphological related-</abstract>
<note confidence="0.9218085">In in Natural Language Processing, Proceedings of the 5th International Conference on FinTAL volume 4139 of Notes in pages 121–13. Springer. Bybee, Joan L. 1995. Regular morphology and the lexand cognitive 10(5):425– 455. Creutz, Mathias and Krista Lagus. 2002. Unsuperdiscovery of morphemes. In of the ACL Workshop on Morphological and Phonopages 21–30, Philadelphia, Penn. ACL. Déjean, Hervé. 1998. Morphemes as necessary concept for structures discovery from untagged corpora.</note>
<title confidence="0.311327">of the Workshop on Paradigms and in Natural Language pages</title>
<address confidence="0.869973">295–299, Adelaide, Australia.</address>
<author confidence="0.509439">Bruno Gaume</author>
<author confidence="0.509439">Karine Duvigneau</author>
<author confidence="0.509439">Olivier Gasquet</author>
<affiliation confidence="0.3249485">and Marie-Dominique Gineste. 2002. Forms of meaning of forms. of Experimen-</affiliation>
<note confidence="0.616086084745763">and Theoretical Artificial 14(1):61– 74. Gaume, B., F. Venant, and B. Victorri. 2005. Hierarchy in lexical organization of natural language. In D., editor, in natural and social Methodos series, pages 121–143. Kluwer. Goldsmith, John. 2001. Unsupervised learning of morphology of natural language. 27(2):153–198. Hathout, Nabil. 2002. From wordnet to celex: acquiring morphological links from dictionaries of syn- In of the Third International Daniel and James H. Martin. 2000. language Prentice-Hall. Lebart, Ludovic, André Salem, and Lisette Berry. textual Kluwer Academic Publishers, Dordrecht. Lepage, Yves. 1998. Solving analogies on words: an In of volume 2, pages 728–735, Montréal, Canada. Yves. 2003. l’analogie rendant compte de commutation en Mémoire de HDR, Université Joseph Fourier, Grenoble. Muller, Philippe, Nabil Hathout, and Bruno Gaume. 2006. Synonym extraction using a semantic distance on a dictionary. In Radev, Dragomir and Rada editors, of the HLT/NAACL pages 65–72, New York, NY. Association for Computational Linguistics. Neuvel, Sylvain and Sean A. Fulop. 2002. Unsupervised learning of morphology without morphemes. of the Workshop on Morphologiand Phonological Learning Philadelphia. ACL Publications. Schone, Patrick and Daniel S. Jurafsky. 2000. Knowledge-free induction of morphology using lasemantic analysis. In of the Conference on Natural Language Learning 2000 (CoNLLpages 67–72, Lisbon, Portugal. Stroppa, Nicolas and François Yvon. 2005. An analoglearner for morphological analysis. In Proceedings of the 9th Conference on Computational Natural Learning pages 120–127, Ann Arbor, Michigan, June. Association for Computational Linguistics. Xu, Jinxi and W. Bruce Croft. 1998. Corpus-based stemming using co-occurrence of word variants. Transaction on Information 16(1):61– 81. Yarowsky, David and Richard Wicentowski. 2000. Minimally supervised morphological analysis by alignment. In of the Asof Computational Linguistics pages 207–216, Hong Kong. Zweigenbaum, Pierre and Natalia Grabar. 2003. Learning derived words from medical corpora. In 9th Conference on Artificial Intelligence in Medicine pages 189–198, Cyprus. 8</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stephen R Anderson</author>
</authors>
<title>A-Morphous Morphology.</title>
<date>1992</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="1178" citStr="Anderson, 1992" startWordPosition="176" endWordPosition="177">its morphological family and its derivational series, and of (2) the analogies that hold between the words. The model has been tested on the lexicon of French using the TLFi machine readable dictionary. 1 Lexeme-based morphology Morphology is traditionally considered to be the field of linguistics that studies the structure of words. In this conception, words are made of morphemes which combine according to rules of inflexion, derivation and composition. If the morpheme-based theoretical framework is both elegant and easy to implement, it suffers many drawbacks pointed out by several authors (Anderson, 1992; Aronoff, 1994). The alternative theoretical models that have been proposed falls within lexeme-based or word-based morphology in which the minimal units are words instead of morphemes. Words then do not have any structure at all and morphology becomes a level of organization of the lexicon based on the sharing of semantic and formal properties. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. The morpheme-based / lexeme-based distinction shows up on the computation</context>
</contexts>
<marker>Anderson, 1992</marker>
<rawString>Anderson, Stephen R. 1992. A-Morphous Morphology. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Aronoff</author>
</authors>
<title>Morphology by Itself. Stem and Inflexional Classes.</title>
<date>1994</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="1194" citStr="Aronoff, 1994" startWordPosition="178" endWordPosition="179">l family and its derivational series, and of (2) the analogies that hold between the words. The model has been tested on the lexicon of French using the TLFi machine readable dictionary. 1 Lexeme-based morphology Morphology is traditionally considered to be the field of linguistics that studies the structure of words. In this conception, words are made of morphemes which combine according to rules of inflexion, derivation and composition. If the morpheme-based theoretical framework is both elegant and easy to implement, it suffers many drawbacks pointed out by several authors (Anderson, 1992; Aronoff, 1994). The alternative theoretical models that have been proposed falls within lexeme-based or word-based morphology in which the minimal units are words instead of morphemes. Words then do not have any structure at all and morphology becomes a level of organization of the lexicon based on the sharing of semantic and formal properties. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. The morpheme-based / lexeme-based distinction shows up on the computational level. In the</context>
</contexts>
<marker>Aronoff, 1994</marker>
<rawString>Aronoff, Mark. 1994. Morphology by Itself. Stem and Inflexional Classes. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Harald Baayen</author>
<author>Richard Piepenbrock</author>
<author>Leon Gulikers</author>
</authors>
<date>1995</date>
<booktitle>The CELEX lexical database (release 2). CD-ROM. Linguistic Data</booktitle>
<institution>Consortium, University of Pennsylvania,</institution>
<location>Pennsylvania, USA.</location>
<contexts>
<context position="26917" citStr="Baayen et al., 1995" startWordPosition="4491" endWordPosition="4494">ed to simulate the spreading of activations in this lexical network. The level of activation obtained after the propagation indicates the lexical relatedness of the words. The members of the morphological family and the derivational series of each word are then identified among its lexical neighbors by means of formal analogies. This is work in progress and we still have to separate the members of the families from the members of the series. We also intend to conduct a similar experiment on the English lexicon and to evaluate our results in a more classical manner by using the CELEX database (Baayen et al., 1995) as gold standard. The evaluation should also be done with respect to well known systems like Linguistica (Goldsmith, 2001) or the morphological analyzer of Bernhard (2006). Acknowledgments I would like to thank the ATILF laboratory and Jean-Marie Pierrel for making available to me the TLFi. I am in debt to Bruno Gaume and Philippe Muller for the many discussions and exchanges we have had on the cleaning-up of the TFLi and its exploitation through random walks. I am also grateful to Gilles Boyé, Olivier Haute-Cœur and Lu7 dovic Tanguy for their comments and suggestions. Conference on Language </context>
</contexts>
<marker>Baayen, Piepenbrock, Gulikers, 1995</marker>
<rawString>Baayen, R. Harald, Richard Piepenbrock, and Leon Gulikers. 1995. The CELEX lexical database (release 2). CD-ROM. Linguistic Data Consortium, University of Pennsylvania, Pennsylvania, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Johannes Matiasek</author>
<author>Harald Trost</author>
</authors>
<title>Unsupervised discovery of morphologically related words based on orthographic and semantic similarity.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Morphological and Phonological Learning ofACL-2002,</booktitle>
<pages>48--57</pages>
<publisher>ACL.</publisher>
<location>Philadelphia.</location>
<contexts>
<context position="6225" citStr="Baroni et al., 2002" startWordPosition="936" endWordPosition="939">a Langue Française (http://atilf.atilf.fr/). (graphemic, phonological, etc.) can be used. They can be cumulated easily in spite of the differences in nature and origin. The model takes advantage of the redundancy of the features and is fairly insensitive to variation and exceptions. 3 Related work Many works in the field of computational morphology aim at the discovery of relations between lexical units. All of them rely primarily on finding similarities between the word graphemic forms. These relations are mainly prefixal or suffixal with two exceptions, (Yarowsky and Wicentowski, 2000) and (Baroni et al., 2002), who use string edit distances to estimate formal similarity. As far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (Neuvel and Fulop, 2002). Our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features. It is the main contribution of this paper. Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automati</context>
</contexts>
<marker>Baroni, Matiasek, Trost, 2002</marker>
<rawString>Baroni, Marco, Johannes Matiasek, and Harald Trost. 2002. Unsupervised discovery of morphologically related words based on orthographic and semantic similarity. In Proceedings of the Workshop on Morphological and Phonological Learning ofACL-2002, pages 48–57, Philadelphia. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delphine Bernhard</author>
</authors>
<title>Automatic acquisition of semantic relationships from morphological relatedness.</title>
<date>2006</date>
<booktitle>In Advances in Natural Language Processing, Proceedings of the 5th International Conference on NLP, FinTAL</booktitle>
<volume>4139</volume>
<pages>121--13</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1981" citStr="Bernhard, 2006" startWordPosition="292" endWordPosition="293">ords then do not have any structure at all and morphology becomes a level of organization of the lexicon based on the sharing of semantic and formal properties. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. The morpheme-based / lexeme-based distinction shows up on the computational level. In the morpheme-based conception, the morphological analysis of a word aims at segmenting it into a sequence of morphemes (Déjean, 1998; Goldsmith, 2001; Creutz and Lagus, 2002; Bernhard, 2006). In a lexeme-based approach, it is to discover the relations between the word and the other lexical items. These relations serve to identify the morphological family of the word, its derivational series, and the analogies in which it is involved. For instance, the analysis of the French word dérivation may be considered as satisfactory if it connects dérivation with enough members of its family (dériver ‘derivate’, dérivationnel ‘derivational’, dérivable, dérive ‘drift’, dériveur ‘sailing dinghy’, etc.) and of its derivational series (formation ‘education’, séduction, variation, émission, etc</context>
</contexts>
<marker>Bernhard, 2006</marker>
<rawString>Bernhard, Delphine. 2006. Automatic acquisition of semantic relationships from morphological relatedness. In Advances in Natural Language Processing, Proceedings of the 5th International Conference on NLP, FinTAL 2006, volume 4139 of Lecture Notes in Computer Science, pages 121–13. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan L Bybee</author>
</authors>
<title>Regular morphology and the lexicon. Language and cognitive processes,</title>
<date>1995</date>
<volume>10</volume>
<issue>5</issue>
<pages>455</pages>
<contexts>
<context position="11218" citStr="Bybee (1995)" startWordPosition="1724" endWordPosition="1725">its semantic and formal features. For instance, the noun orientation is connected with the formal feature $or, $ori, $orie, $orien, etc. which are in turn connected with the words orienter, orientable, orientement ‘orientation’, orienteur ‘orientor’, etc. Likewise, orientation is connected with the semantic features N.action X.de, N.résultat X.de X.ce N.action, etc. which are themselves connected with the nouns orientement, harmonisation ‘synchronization’, pointage ‘checking’, etc. The general schema is illustrated in figure 4. This representation corresponds precisely to the Network Model of Bybee (1995). We use a bipartite graph mainly for two reasons: (1) We can spread an activation synchronously into the formal and the semantic sub-graphs. (2) It contains representations of the formal and the semantic properties of the lexemes which, for instance, could be used in order to describe the semantics of the -able suffixation or the characteristic endings of the boat names (-ier, -eur, etc.). However, the bipartite structure is not essential and we only need 3 to be able to compute morphological distances between words. 5 Random walks The computational side of the method is based on the estimati</context>
</contexts>
<marker>Bybee, 1995</marker>
<rawString>Bybee, Joan L. 1995. Regular morphology and the lexicon. Language and cognitive processes, 10(5):425– 455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathias Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Unsupervised discovery of morphemes.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Workshop on Morphological and Phonological Learning,</booktitle>
<pages>21--30</pages>
<publisher>ACL.</publisher>
<location>Philadelphia, Penn.</location>
<contexts>
<context position="1964" citStr="Creutz and Lagus, 2002" startWordPosition="288" endWordPosition="291"> instead of morphemes. Words then do not have any structure at all and morphology becomes a level of organization of the lexicon based on the sharing of semantic and formal properties. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. The morpheme-based / lexeme-based distinction shows up on the computational level. In the morpheme-based conception, the morphological analysis of a word aims at segmenting it into a sequence of morphemes (Déjean, 1998; Goldsmith, 2001; Creutz and Lagus, 2002; Bernhard, 2006). In a lexeme-based approach, it is to discover the relations between the word and the other lexical items. These relations serve to identify the morphological family of the word, its derivational series, and the analogies in which it is involved. For instance, the analysis of the French word dérivation may be considered as satisfactory if it connects dérivation with enough members of its family (dériver ‘derivate’, dérivationnel ‘derivational’, dérivable, dérive ‘drift’, dériveur ‘sailing dinghy’, etc.) and of its derivational series (formation ‘education’, séduction, variati</context>
</contexts>
<marker>Creutz, Lagus, 2002</marker>
<rawString>Creutz, Mathias and Krista Lagus. 2002. Unsupervised discovery of morphemes. In Proceedings of the ACL Workshop on Morphological and Phonological Learning, pages 21–30, Philadelphia, Penn. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hervé Déjean</author>
</authors>
<title>Morphemes as necessary concept for structures discovery from untagged corpora.</title>
<date>1998</date>
<booktitle>In Proceedings of the Workshop on Paradigms and Grounding in Natural Language Learning,</booktitle>
<pages>295--299</pages>
<location>Adelaide, Australia.</location>
<contexts>
<context position="1923" citStr="Déjean, 1998" startWordPosition="283" endWordPosition="284">ich the minimal units are words instead of morphemes. Words then do not have any structure at all and morphology becomes a level of organization of the lexicon based on the sharing of semantic and formal properties. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. The morpheme-based / lexeme-based distinction shows up on the computational level. In the morpheme-based conception, the morphological analysis of a word aims at segmenting it into a sequence of morphemes (Déjean, 1998; Goldsmith, 2001; Creutz and Lagus, 2002; Bernhard, 2006). In a lexeme-based approach, it is to discover the relations between the word and the other lexical items. These relations serve to identify the morphological family of the word, its derivational series, and the analogies in which it is involved. For instance, the analysis of the French word dérivation may be considered as satisfactory if it connects dérivation with enough members of its family (dériver ‘derivate’, dérivationnel ‘derivational’, dérivable, dérive ‘drift’, dériveur ‘sailing dinghy’, etc.) and of its derivational series (</context>
</contexts>
<marker>Déjean, 1998</marker>
<rawString>Déjean, Hervé. 1998. Morphemes as necessary concept for structures discovery from untagged corpora. In Proceedings of the Workshop on Paradigms and Grounding in Natural Language Learning, pages 295–299, Adelaide, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Gaume</author>
<author>Karine Duvigneau</author>
<author>Olivier Gasquet</author>
<author>Marie-Dominique Gineste</author>
</authors>
<title>Forms of meaning, meaning of forms.</title>
<date>2002</date>
<journal>Journal of Experimental and Theoretical Artificial Intelligence,</journal>
<volume>14</volume>
<issue>1</issue>
<pages>74</pages>
<contexts>
<context position="4505" citStr="Gaume et al., 2002" startWordPosition="661" endWordPosition="664">ques are complementary. The first one brings closer the words that are morphologically close and especially the ones that are members of the same morphological families and the same derivational series. It is able to deal with large number of words, but it is too coarse-grained to discriminate the words that are actually morphological related from the ones that are not. The second technique, formal analogy, is then used to perform a fine-grained filtering. Technically, our model joins: 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lexemebased. The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts. 2. The membership to the families and series is gradient. It accounts, for </context>
<context position="11902" citStr="Gaume et al., 2002" startWordPosition="1839" endWordPosition="1842">ad an activation synchronously into the formal and the semantic sub-graphs. (2) It contains representations of the formal and the semantic properties of the lexemes which, for instance, could be used in order to describe the semantics of the -able suffixation or the characteristic endings of the boat names (-ier, -eur, etc.). However, the bipartite structure is not essential and we only need 3 to be able to compute morphological distances between words. 5 Random walks The computational side of the method is based on the estimation of the proximity between words represented in a lexical graph (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006). The graphs used in this approach are slightly different from the ones presented above. All their vertices represent words and the edges describe semantic relations such as synonymy. The proximity is computed by simulating the spreading into the graph of an activation initiated at a vertice. Following the spreading, the nodes which are most excited are regarded as being the closest to the initial vertice. The same method can be used to estimate the morphological proximity between words that are described in a bipartite graph like the one we propose (s</context>
</contexts>
<marker>Gaume, Duvigneau, Gasquet, Gineste, 2002</marker>
<rawString>Gaume, Bruno, Karine Duvigneau, Olivier Gasquet, and Marie-Dominique Gineste. 2002. Forms of meaning, meaning of forms. Journal of Experimental and Theoretical Artificial Intelligence, 14(1):61– 74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Gaume</author>
<author>F Venant</author>
<author>B Victorri</author>
</authors>
<title>Hierarchy in lexical organization of natural language.</title>
<date>2005</date>
<booktitle>Hierarchy in natural and social sciences, Methodos series,</booktitle>
<pages>121--143</pages>
<editor>In Pumain, D., editor,</editor>
<publisher>Kluwer.</publisher>
<contexts>
<context position="4525" citStr="Gaume et al., 2005" startWordPosition="665" endWordPosition="668">ry. The first one brings closer the words that are morphologically close and especially the ones that are members of the same morphological families and the same derivational series. It is able to deal with large number of words, but it is too coarse-grained to discriminate the words that are actually morphological related from the ones that are not. The second technique, formal analogy, is then used to perform a fine-grained filtering. Technically, our model joins: 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lexemebased. The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts. 2. The membership to the families and series is gradient. It accounts, for instance, for the fa</context>
<context position="11922" citStr="Gaume et al., 2005" startWordPosition="1843" endWordPosition="1846">chronously into the formal and the semantic sub-graphs. (2) It contains representations of the formal and the semantic properties of the lexemes which, for instance, could be used in order to describe the semantics of the -able suffixation or the characteristic endings of the boat names (-ier, -eur, etc.). However, the bipartite structure is not essential and we only need 3 to be able to compute morphological distances between words. 5 Random walks The computational side of the method is based on the estimation of the proximity between words represented in a lexical graph (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006). The graphs used in this approach are slightly different from the ones presented above. All their vertices represent words and the edges describe semantic relations such as synonymy. The proximity is computed by simulating the spreading into the graph of an activation initiated at a vertice. Following the spreading, the nodes which are most excited are regarded as being the closest to the initial vertice. The same method can be used to estimate the morphological proximity between words that are described in a bipartite graph like the one we propose (see figure 4). It the</context>
</contexts>
<marker>Gaume, Venant, Victorri, 2005</marker>
<rawString>Gaume, B., F. Venant, and B. Victorri. 2005. Hierarchy in lexical organization of natural language. In Pumain, D., editor, Hierarchy in natural and social sciences, Methodos series, pages 121–143. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Goldsmith</author>
</authors>
<title>Unsupervised learning of the morphology of natural language.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<contexts>
<context position="1940" citStr="Goldsmith, 2001" startWordPosition="285" endWordPosition="287">l units are words instead of morphemes. Words then do not have any structure at all and morphology becomes a level of organization of the lexicon based on the sharing of semantic and formal properties. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. The morpheme-based / lexeme-based distinction shows up on the computational level. In the morpheme-based conception, the morphological analysis of a word aims at segmenting it into a sequence of morphemes (Déjean, 1998; Goldsmith, 2001; Creutz and Lagus, 2002; Bernhard, 2006). In a lexeme-based approach, it is to discover the relations between the word and the other lexical items. These relations serve to identify the morphological family of the word, its derivational series, and the analogies in which it is involved. For instance, the analysis of the French word dérivation may be considered as satisfactory if it connects dérivation with enough members of its family (dériver ‘derivate’, dérivationnel ‘derivational’, dérivable, dérive ‘drift’, dériveur ‘sailing dinghy’, etc.) and of its derivational series (formation ‘educat</context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>Goldsmith, John. 2001. Unsupervised learning of the morphology of natural language. Computational Linguistics, 27(2):153–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nabil Hathout</author>
</authors>
<title>From wordnet to celex: acquiring morphological links from dictionaries of synonyms.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International</booktitle>
<contexts>
<context position="7310" citStr="Hathout, 2002" startWordPosition="1110" endWordPosition="1111">c cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (Schone and Jurafsky, 2000), mutual information (Baroni et al., 2002) or co-occurrence in an n-word window (Xu and Croft, 1998; Zweigenbaum and Grabar, 2003). In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph. Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet. 4 Lexeme Description In our model, the lexical units and their properties are represented in a bipartite graph with the vertices representing the lexemes in one sub-set and the vertices representing the formal and semantic features in the other. Lexeme vertices are identified by the lemma and the grammatical category. In the experiment reported in the paper, the formal properties are the n-grams of letters that occur in the lexemes lemma. Figure 1 shows a sub-set o</context>
</contexts>
<marker>Hathout, 2002</marker>
<rawString>Hathout, Nabil. 2002. From wordnet to celex: acquiring morphological links from dictionaries of synonyms. In Proceedings of the Third International</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and language processing.</title>
<date>2000</date>
<publisher>Prentice-Hall.</publisher>
<contexts>
<context position="21888" citStr="Jurafsky and Martin, 2000" startWordPosition="3621" endWordPosition="3624">f(d)) E L*4 such that, Vi E [1, n], (fi(b), fi(c)) E I(fi(a), fi(d)), (fi(d), fi(a))1. For the analogy kataba:maktoubon::fa3ala:maf3oulon, the property holds for n = 7 (see figure 5). 7.3 Implementation A formal analogy a : b :: c : d can be easily checked by comparing the sequences of string edit operations between (a, b) and between (c, d). Both sequences must minimize Levenshtein edit distance (i.e. have a minimal cost). Each sequence corresponds to a path in the edit lattices of the couple of words. The lattice are represented by a matrix computed using the standard string edit algorithm (Jurafsky and Martin, 2000). The path which describes the sequence of string edit operations starts at the last cell of the matrix and climbs 3This example is adapted from examples in (Lepage, 1998; Lepage, 2003). to the first one. Only three directions are allowed: upward (deletion), to the left (insertion) or in the upper left diagonal direction (substitution). Figure 6 shows the sequence of edit operations for the couple fructueux:infructueusement. Sequences of edit operations can be simplified by merging the series of identical character matchings. The sequence in figure 6 then becomes ((I,E,i), (I,E,n), (M,fructueu</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Jurafsky, Daniel and James H. Martin. 2000. Speech and language processing. Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ludovic Lebart</author>
<author>André Salem</author>
<author>Lisette Berry</author>
</authors>
<title>Exploring textual data.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="10128" citStr="Lebart et al., 1998" startWordPosition="1561" endWordPosition="1564">ation marks are eliminated. In other words, we only use n-grams of words that occur between two punctuation marks. For instance, the semantic features induced by the definition Action d’orienter, de s’orienter; résultat de cette action. (‘act of orienting, of finding one’s way; result of this action’) of the noun orientation are presented in figure 2. The words in the definitions are POS tagged and lemmatized. The tags are A for adjectives, N for nouns, R for adverbs, V for verbs and X for all other categories. This is a very coarse semantic representation inspired from the repeated segments (Lebart et al., 1998). It offers three advantages: (1) being heavily redundant, it can capture various levels of similarity between the definitions; (2) it integrates informations of a syntagmatic nature without a deep syntactic analysis of the definitions; (3) it slightly reduces the strong variations in the lexicographical treatment of the headwords, especially in the division into sub-senses and in the definitions. The bipartite graph is built up by symmetrically connecting each headword to its semantic and formal features. For instance, the noun orientation is connected with the formal feature $or, $ori, $orie</context>
</contexts>
<marker>Lebart, Salem, Berry, 1998</marker>
<rawString>Lebart, Ludovic, André Salem, and Lisette Berry. 1998. Exploring textual data. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Lepage</author>
</authors>
<title>Solving analogies on words: an algorithm.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL’98,</booktitle>
<volume>2</volume>
<pages>728--735</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="4595" citStr="Lepage, 1998" startWordPosition="679" endWordPosition="680"> especially the ones that are members of the same morphological families and the same derivational series. It is able to deal with large number of words, but it is too coarse-grained to discriminate the words that are actually morphological related from the ones that are not. The second technique, formal analogy, is then used to perform a fine-grained filtering. Technically, our model joins: 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lexemebased. The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts. 2. The membership to the families and series is gradient. It accounts, for instance, for the fact that dériveur is morphologically and semantically closer to dérive </context>
<context position="22058" citStr="Lepage, 1998" startWordPosition="3653" endWordPosition="3654">7.3 Implementation A formal analogy a : b :: c : d can be easily checked by comparing the sequences of string edit operations between (a, b) and between (c, d). Both sequences must minimize Levenshtein edit distance (i.e. have a minimal cost). Each sequence corresponds to a path in the edit lattices of the couple of words. The lattice are represented by a matrix computed using the standard string edit algorithm (Jurafsky and Martin, 2000). The path which describes the sequence of string edit operations starts at the last cell of the matrix and climbs 3This example is adapted from examples in (Lepage, 1998; Lepage, 2003). to the first one. Only three directions are allowed: upward (deletion), to the left (insertion) or in the upper left diagonal direction (substitution). Figure 6 shows the sequence of edit operations for the couple fructueux:infructueusement. Sequences of edit operations can be simplified by merging the series of identical character matchings. The sequence in figure 6 then becomes ((I,E,i), (I,E,n), (M,fructueu,fructueu), (S,x,s), (I,E,e), (I,E,m), (I,E,e), (I,E,n), (I,E,t)). This simplified sequence is identical to the one for the couple soucieux:insoucieusement except for the</context>
</contexts>
<marker>Lepage, 1998</marker>
<rawString>Lepage, Yves. 1998. Solving analogies on words: an algorithm. In Proceedings of COLING-ACL’98, volume 2, pages 728–735, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Lepage</author>
</authors>
<title>De l’analogie rendant compte de la commutation en linguistique. Mémoire de HDR, Université Joseph Fourier,</title>
<date>2003</date>
<location>Grenoble.</location>
<contexts>
<context position="22073" citStr="Lepage, 2003" startWordPosition="3655" endWordPosition="3656">tion A formal analogy a : b :: c : d can be easily checked by comparing the sequences of string edit operations between (a, b) and between (c, d). Both sequences must minimize Levenshtein edit distance (i.e. have a minimal cost). Each sequence corresponds to a path in the edit lattices of the couple of words. The lattice are represented by a matrix computed using the standard string edit algorithm (Jurafsky and Martin, 2000). The path which describes the sequence of string edit operations starts at the last cell of the matrix and climbs 3This example is adapted from examples in (Lepage, 1998; Lepage, 2003). to the first one. Only three directions are allowed: upward (deletion), to the left (insertion) or in the upper left diagonal direction (substitution). Figure 6 shows the sequence of edit operations for the couple fructueux:infructueusement. Sequences of edit operations can be simplified by merging the series of identical character matchings. The sequence in figure 6 then becomes ((I,E,i), (I,E,n), (M,fructueu,fructueu), (S,x,s), (I,E,e), (I,E,m), (I,E,e), (I,E,n), (I,E,t)). This simplified sequence is identical to the one for the couple soucieux:insoucieusement except for the matching opera</context>
</contexts>
<marker>Lepage, 2003</marker>
<rawString>Lepage, Yves. 2003. De l’analogie rendant compte de la commutation en linguistique. Mémoire de HDR, Université Joseph Fourier, Grenoble.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Muller</author>
<author>Nabil Hathout</author>
<author>Bruno Gaume</author>
</authors>
<title>Synonym extraction using a semantic distance on a dictionary.</title>
<date>2006</date>
<booktitle>In Radev, Dragomir and Rada Mihalcea, editors, Proceedings of the HLT/NAACL workshop Textgraphs,</booktitle>
<pages>65--72</pages>
<publisher>Association for Computational Linguistics.</publisher>
<location>New York, NY.</location>
<contexts>
<context position="4547" citStr="Muller et al., 2006" startWordPosition="669" endWordPosition="672">ings closer the words that are morphologically close and especially the ones that are members of the same morphological families and the same derivational series. It is able to deal with large number of words, but it is too coarse-grained to discriminate the words that are actually morphological related from the ones that are not. The second technique, formal analogy, is then used to perform a fine-grained filtering. Technically, our model joins: 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lexemebased. The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts. 2. The membership to the families and series is gradient. It accounts, for instance, for the fact that dériveur is mo</context>
<context position="11944" citStr="Muller et al., 2006" startWordPosition="1847" endWordPosition="1850">formal and the semantic sub-graphs. (2) It contains representations of the formal and the semantic properties of the lexemes which, for instance, could be used in order to describe the semantics of the -able suffixation or the characteristic endings of the boat names (-ier, -eur, etc.). However, the bipartite structure is not essential and we only need 3 to be able to compute morphological distances between words. 5 Random walks The computational side of the method is based on the estimation of the proximity between words represented in a lexical graph (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006). The graphs used in this approach are slightly different from the ones presented above. All their vertices represent words and the edges describe semantic relations such as synonymy. The proximity is computed by simulating the spreading into the graph of an activation initiated at a vertice. Following the spreading, the nodes which are most excited are regarded as being the closest to the initial vertice. The same method can be used to estimate the morphological proximity between words that are described in a bipartite graph like the one we propose (see figure 4). It then connects words that </context>
</contexts>
<marker>Muller, Hathout, Gaume, 2006</marker>
<rawString>Muller, Philippe, Nabil Hathout, and Bruno Gaume. 2006. Synonym extraction using a semantic distance on a dictionary. In Radev, Dragomir and Rada Mihalcea, editors, Proceedings of the HLT/NAACL workshop Textgraphs, pages 65–72, New York, NY. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Neuvel</author>
<author>Sean A Fulop</author>
</authors>
<title>Unsupervised learning of morphology without morphemes.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Morphological and Phonological Learning 2002,</booktitle>
<publisher>ACL Publications.</publisher>
<location>Philadelphia.</location>
<contexts>
<context position="6429" citStr="Neuvel and Fulop, 2002" startWordPosition="973" endWordPosition="976"> redundancy of the features and is fairly insensitive to variation and exceptions. 3 Related work Many works in the field of computational morphology aim at the discovery of relations between lexical units. All of them rely primarily on finding similarities between the word graphemic forms. These relations are mainly prefixal or suffixal with two exceptions, (Yarowsky and Wicentowski, 2000) and (Baroni et al., 2002), who use string edit distances to estimate formal similarity. As far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (Neuvel and Fulop, 2002). Our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features. It is the main contribution of this paper. Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (Schone and Jurafsky, 2000), mutual information (Baroni et al., 2002) or co-occurrence in an n-word window (Xu and Cr</context>
</contexts>
<marker>Neuvel, Fulop, 2002</marker>
<rawString>Neuvel, Sylvain and Sean A. Fulop. 2002. Unsupervised learning of morphology without morphemes. In Proceedings of the Workshop on Morphological and Phonological Learning 2002, Philadelphia. ACL Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Schone</author>
<author>Daniel S Jurafsky</author>
</authors>
<title>Knowledge-free induction of morphology using latent semantic analysis.</title>
<date>2000</date>
<booktitle>In Proceedings of the Conference on Natural Language Learning</booktitle>
<pages>67--72</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="6939" citStr="Schone and Jurafsky, 2000" startWordPosition="1050" endWordPosition="1053">e other perform some sort of segmentation even when the goal is not to find morphemes as in (Neuvel and Fulop, 2002). Our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features. It is the main contribution of this paper. Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (Schone and Jurafsky, 2000), mutual information (Baroni et al., 2002) or co-occurrence in an n-word window (Xu and Croft, 1998; Zweigenbaum and Grabar, 2003). In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph. Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet. 4 Lexeme Description In our model, the lexical units and their properties are represented in a bip</context>
</contexts>
<marker>Schone, Jurafsky, 2000</marker>
<rawString>Schone, Patrick and Daniel S. Jurafsky. 2000. Knowledge-free induction of morphology using latent semantic analysis. In Proceedings of the Conference on Natural Language Learning 2000 (CoNLL2000), pages 67–72, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolas Stroppa</author>
<author>François Yvon</author>
</authors>
<title>An analogical learner for morphological analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL-2005),</booktitle>
<pages>120--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="4620" citStr="Stroppa and Yvon, 2005" startWordPosition="681" endWordPosition="684">e ones that are members of the same morphological families and the same derivational series. It is able to deal with large number of words, but it is too coarse-grained to discriminate the words that are actually morphological related from the ones that are not. The second technique, formal analogy, is then used to perform a fine-grained filtering. Technically, our model joins: 1. the representation of the lexicon as a graph and its exploration through random walks, along the line of (Gaume et al., 2002; Gaume et al., 2005; Muller et al., 2006), and 2. formal analogies on words (Lepage, 1998; Stroppa and Yvon, 2005). This approach does do not make use of morphemes. Correspondence between words is calculated directly on their graphemic representations. More generally, our approach is original in that: 1. Our computational model is pure lexemebased. The discovery of morphological relations between words do not involve the notions of morpheme, affix, morphological exponent, etc. nor any representation of these concepts. 2. The membership to the families and series is gradient. It accounts, for instance, for the fact that dériveur is morphologically and semantically closer to dérive than to dérivationnelleme</context>
<context position="20777" citStr="Stroppa and Yvon, 2005" startWordPosition="3403" endWordPosition="3406">t can be exemplified with the four Arabic words kataba:maktoubon::fa3ala:maf3oulon which respectively are transcriptions of the verb ‘write’, the noun ‘document’, the verb ‘do’ and the noun ‘effect.’3 The differences between the first two words and between the two last ones can be described as in figure 5. They are identical for the two couples of words. E k a t a b a ma k E t ou b on f 3 l E a a a ma f E 3 ou l on Figure 5: Formal analogy kataba: maktoubon::fa3ala:maf3oulon. The differences are locates in frame boxes. More generally, formal analogies can be defined in terms of factorization (Stroppa and Yvon, 2005). Let L be an alphabet and a E L* a string over L. A factorization of a is a sequence f = (f1, • • • , fn) E L*n such that a = f1 ® • • • ® fn where ® denotes the concatenation. For instance, (ma, k, E, t, ou, b, on) is a factorization of length 7 of maktoubon. Morphological analogies can be defined as follows. Let (a, b, c, d) E L*4 be for strings. a : b :: c : d is a formal analogy iff there exists n E N and four factorizations of length n of the four strings (f(a), f(b), f(c), f(d)) E L*4 such that, Vi E [1, n], (fi(b), fi(c)) E I(fi(a), fi(d)), (fi(d), fi(a))1. For the analogy kataba:makto</context>
</contexts>
<marker>Stroppa, Yvon, 2005</marker>
<rawString>Stroppa, Nicolas and François Yvon. 2005. An analogical learner for morphological analysis. In Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL-2005), pages 120–127, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxi Xu</author>
<author>W Bruce Croft</author>
</authors>
<title>Corpus-based stemming using co-occurrence of word variants.</title>
<date>1998</date>
<journal>ACM Transaction on Information Systems,</journal>
<volume>16</volume>
<issue>1</issue>
<pages>81</pages>
<contexts>
<context position="7038" citStr="Xu and Croft, 1998" startWordPosition="1067" endWordPosition="1070">op, 2002). Our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features. It is the main contribution of this paper. Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (Schone and Jurafsky, 2000), mutual information (Baroni et al., 2002) or co-occurrence in an n-word window (Xu and Croft, 1998; Zweigenbaum and Grabar, 2003). In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph. Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet. 4 Lexeme Description In our model, the lexical units and their properties are represented in a bipartite graph with the vertices representing the lexemes in one sub-set and the vertices representin</context>
</contexts>
<marker>Xu, Croft, 1998</marker>
<rawString>Xu, Jinxi and W. Bruce Croft. 1998. Corpus-based stemming using co-occurrence of word variants. ACM Transaction on Information Systems, 16(1):61– 81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Richard Wicentowski</author>
</authors>
<title>Minimally supervised morphological analysis by multimodal alignment.</title>
<date>2000</date>
<booktitle>In Proceedings of the Association of Computational Linguistics (ACL-2000),</booktitle>
<pages>207--216</pages>
<location>Hong Kong.</location>
<contexts>
<context position="6199" citStr="Yarowsky and Wicentowski, 2000" startWordPosition="930" endWordPosition="934">s, etc.) and formal ones 1Trésor de la Langue Française (http://atilf.atilf.fr/). (graphemic, phonological, etc.) can be used. They can be cumulated easily in spite of the differences in nature and origin. The model takes advantage of the redundancy of the features and is fairly insensitive to variation and exceptions. 3 Related work Many works in the field of computational morphology aim at the discovery of relations between lexical units. All of them rely primarily on finding similarities between the word graphemic forms. These relations are mainly prefixal or suffixal with two exceptions, (Yarowsky and Wicentowski, 2000) and (Baroni et al., 2002), who use string edit distances to estimate formal similarity. As far as we know, all the other perform some sort of segmentation even when the goal is not to find morphemes as in (Neuvel and Fulop, 2002). Our model differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features. It is the main contribution of this paper. Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words. Usually, these semantic</context>
</contexts>
<marker>Yarowsky, Wicentowski, 2000</marker>
<rawString>Yarowsky, David and Richard Wicentowski. 2000. Minimally supervised morphological analysis by multimodal alignment. In Proceedings of the Association of Computational Linguistics (ACL-2000), pages 207–216, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Zweigenbaum</author>
<author>Natalia Grabar</author>
</authors>
<title>Learning derived words from medical corpora.</title>
<date>2003</date>
<booktitle>In 9th Conference on Artificial Intelligence in Medicine Europe,</booktitle>
<pages>189--198</pages>
<contexts>
<context position="7069" citStr="Zweigenbaum and Grabar, 2003" startWordPosition="1071" endWordPosition="1075"> differs from these approaches in that the graphemic similarities are determined solely on the basis of the sharing of graphemic features. It is the main contribution of this paper. Our model is also related to approaches that combine graphemic and semantic cues in order to identify morphemes or morphological relations between words. Usually, these semantic informations are automatically acquired from corpora by means of various techniques as latent semantic analysis (Schone and Jurafsky, 2000), mutual information (Baroni et al., 2002) or co-occurrence in an n-word window (Xu and Croft, 1998; Zweigenbaum and Grabar, 2003). In the experiment we present here, semantic informations are extracted from a machine readable dictionary and semantic similarity is calculated through random walks in a lexical graph. Our approach can also be compared with (Hathout, 2002) where morphological knowledge is acquired by using semantic informations extracted from dictionaries of synonyms or from WordNet. 4 Lexeme Description In our model, the lexical units and their properties are represented in a bipartite graph with the vertices representing the lexemes in one sub-set and the vertices representing the formal and semantic featu</context>
</contexts>
<marker>Zweigenbaum, Grabar, 2003</marker>
<rawString>Zweigenbaum, Pierre and Natalia Grabar. 2003. Learning derived words from medical corpora. In 9th Conference on Artificial Intelligence in Medicine Europe, pages 189–198, Cyprus.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>