<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003486">
<title confidence="0.998184">
Paraphrase Acquisition for Information Extraction
</title>
<author confidence="0.995836">
Yusuke Shinyama
</author>
<affiliation confidence="0.99983">
Department of Computer Science
</affiliation>
<address confidence="0.7591535">
New York University
715, Broadway, 7th Floor, NY, 10003
</address>
<email confidence="0.998684">
yusuke@cs.nyu.edu
</email>
<author confidence="0.979242">
Satoshi Sekine
</author>
<affiliation confidence="0.999507">
Department of Computer Science
</affiliation>
<address confidence="0.759237">
New York University
715, Broadway, 7th Floor, NY, 10003
</address>
<email confidence="0.99909">
sekine@cs.nyu.edu
</email>
<sectionHeader confidence="0.998601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999968851851852">
We are trying to find paraphrases from
Japanese news articles which can be used
for Information Extraction. We focused
on the fact that a single event can be re-
ported in more than one article in differ-
ent ways. However, certain kinds of noun
phrases such as names, dates and numbers
behave as “anchors” which are unlikely to
change across articles. Our key idea is to
identify these anchors among comparable
articles and extract portions of expressions
which share the anchors. This way we
can extract expressions which convey the
same information. Obtained paraphrases
are generalized as templates and stored for
future use.
In this paper, first we describe our ba-
sic idea of paraphrase acquisition. Our
method is divided into roughly four steps,
each of which is explained in turn. Then
we illustrate several issues which we en-
counter in real texts. To solve these prob-
lems, we introduce two techniques: coref-
erence resolution and structural restriction
of possible portions of expressions. Fi-
nally we discuss the experimental results
and conclusions.
</bodyText>
<sectionHeader confidence="0.99951" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999959245283019">
We are trying to obtain paraphrases which can be
used for Information Extraction (IE) systems. IE
systems scan articles and retrieve specific informa-
tion which is required for a certain domain defined
in advance. Currently, many IE tasks are performed
by pattern matching. For example, if the system re-
ceives a sentence “Two more people have died in
Hong Kong from SARS,” and the system has a pat-
tern “NUMBER people die in LOCATION” in its in-
ventory, then the system can apply the pattern to
the sentence and fill the slots, and obtain informa-
tion such as “NUMBER = two more, LOCATION =
Hong Kong”. In most IE systems, the performance
of the system is dependent on these well-designed
patterns.
In natural language sentences, a single event can
be expressed in many different ways. So we need
to prepare patterns for various kinds of expressions
used in articles. We are interested in clustering
IE patterns which capture the same information.
For example, a pattern such as “LOCATION reports
NUMBER deaths” can be used for the same purpose
as the previous one, since this pattern could also cap-
ture the casualties occurring in a certain location.
Prior work to relate two IE patterns was reported by
(Shinyama et al., 2002). However, in this attempt
only limited forms of expressions could be obtained.
Furthermore, the obtained paraphrases were limited
to existing IE patterns only. We are interested in col-
lecting various kinds of clues, including similar IE
patterns themselves, to connect two patterns. In this
paper, we tried to obtain more varied paraphrases.
Although our current method is intended for use in
Information Extraction, we think the same approach
can be applied to obtain paraphrases for other pur-
poses, such as machine translation or text summa-
rization.
There have been several attempts to obtain para-
phrases. (Barzilay and McKeown, 2001) applied
text alignment to parallel translations of a single
text and used a part-of-speech tagger to obtain para-
phrases. (Lin and Pantel, 2001) used mutual infor-
mation of word distribution to calculate the simi-
larity of expressions. (Pang et al., 2003) also used
text alignment and obtained a finite state automaton
which generates paraphrases. (Ravichandran and
Hovy, 2002) used pairs of questions and answers
to obtain varied patterns which give the same an-
swer. Our approach is different from these works in
that we used comparable news articles as a source of
paraphrases and used Named Entity tagging and de-
pendency analysis to extract corresponding expres-
sions.
</bodyText>
<sectionHeader confidence="0.997247" genericHeader="introduction">
2 Overall Procedure of Paraphrase
Acquisition
</sectionHeader>
<bodyText confidence="0.998317769230769">
Our main goal is to obtain pattern clusters for IE,
which consist of sets of equivalent patterns captur-
ing the same information. So we tried to discover
paraphrases contained in Japanese news articles for
a specific domain. Our basic idea is to search news
articles from the same day. We focused on the fact
that various newspapers describe a single event in
different ways. So if we can discover an event
which is reported in more then one newspaper, we
can hope these articles can be used as the source of
paraphrases. For example, the following articles ap-
peared in “Health” sections in different newspapers
on Apr. 11:
</bodyText>
<listItem confidence="0.962841555555556">
1. “The government has announced that two more
people have died in Hong Kong after contract-
ing the SARS virus and 61 new cases of the
illness have been detected.” (Reuters, Apr. 11)
2. “Hong Kong reported two more deaths and 61
fresh cases of SARS Friday as governments
across the world took tough steps to stop the
killer virus at their borders.” (Channel News
Asia, Apr. 11)
</listItem>
<bodyText confidence="0.99907408">
In these articles, we can find several correspond-
ing parts, such as “NUMBER people have died in
LOCATION” and “LOCATION reported NUMBER
deaths”. Although their syntactic structures are dif-
ferent, they still convey the same single fact. Here
it is worth noting that even if a different expression
is used, some noun phrases such as “Hong Kong”
or “two more” are preserved across the two arti-
cles. We found that these words shared by the two
sentences provide firm anchors for two different ex-
pressions. In particular, Named Entities (NEs) such
as names, locations, dates or numbers can be the
firmest anchors since they are indispensable to re-
port an event and difficult to paraphrase.
We tried to obtain paraphrases by using this prop-
erty. First we collect a set of comparable articles
which reports the same event, and pull appropriate
portions out of the sentences which share the same
anchors. If we carefully choose appropriate portions
of the sentences, the extracted expressions will con-
vey the same information; i.e. they are paraphrases.
After corresponding portions are obtained, we gen-
eralize the expressions to templates of paraphrases
which can be used in future.
Our method is divided into four steps:
</bodyText>
<listItem confidence="0.966137428571429">
1. Find comparable sentences which report the
same event from different newspapers.
2. Identify anchors in the comparable sentences.
3. Extract corresponding portions from the sen-
tences.
4. Generalize the obtained expressions to para-
phrase templates.
</listItem>
<bodyText confidence="0.977101333333333">
Figure 1 shows the overall procedure. In the re-
mainder of this section, we describe each step in
turn.
</bodyText>
<subsectionHeader confidence="0.993502">
2.1 Find Comparable Sentences
</subsectionHeader>
<bodyText confidence="0.9999929">
To find comparable articles and sentences, we used
methods developed for Topic Detection and Track-
ing (Wayne, 1998). The actual process is divided
into two parts: article level matching and sentence
level matching. Currently we assume that a pair
of paraphrases can be found in a single sentence
of each article and corresponding expressions don’t
range across two or more sentences. Article level
matching is first required to narrow the search space
and reduce erroneous matching of anchors.
</bodyText>
<figure confidence="0.990593047619048">
(Articles on
the same day)
Article
A
Article
B
SARS
1
SARS
2
&amp;quot;NUMBER
people die
in LOCATION&amp;quot;
&amp;quot;LOCTION
reports
NUMBER
deaths&amp;quot;
anchors paraphrases
Find comparable Identify Extract Generalize
articles and anchors corrsponding expressions
sentences portions
</figure>
<figureCaption confidence="0.999995">
Figure 1: The overall procedure
</figureCaption>
<bodyText confidence="0.99995675">
Before applying this technique, we first prepro-
cessed the articles by stripping off the strings which
are not considered as sentences. Then we used a
part-of-speech tagger to obtain segmented words. In
the actual matching process we used a method de-
scribed in (Papka et al., 1999) to find a set of com-
parable articles. Then we use a simple vector space
model for sentence matching.
</bodyText>
<subsectionHeader confidence="0.995468">
2.2 Identify Anchors
</subsectionHeader>
<bodyText confidence="0.999975083333333">
Before extracting paraphrases, we find anchors in
comparable sentences. We used Extended Named
Entity tagging to identify anchors. A Named Entity
tagger identifies proper expressions such as names,
locations and dates in sentences. In addition to these
expressions, an Extended Named Entity tagger iden-
tifies some common nouns such as disease names or
numbers, that are also unlikely to change (Sekine
et al., 2002). For each corresponding pair of sen-
tences, we apply the tagger and identify the same
noun phrases which appear in both sentences as an-
chors.
</bodyText>
<subsectionHeader confidence="0.998694">
2.3 Extract Corresponding Sentence Portions
</subsectionHeader>
<bodyText confidence="0.999987370370371">
Now we identify appropriate boundaries of expres-
sions which share the anchors identified in the pre-
vious stage. To avoid extracting non-grammatical
expressions, we operate on syntactically structured
text rather than sequences of words. Dependency
analysis is suitable for this purpose, since using de-
pendency trees we can reconstruct grammatically
correct expressions from a spanning subtree whose
root is a predicate. Dependency analysis also allows
us to extract expressions which are subtrees but do
not correspond to a single contiguous sequence of
words.
We applied a dependency analyzer to a pair of
corresponding sentences and obtained tree structures
for each sentence. Each node of the tree is either a
predicate such as a verb or an adjective, or an argu-
ment such as a noun or a pronoun. Each predicate
can take one or more arguments. We generated all
possible combinations of subtrees from each depen-
dency tree, and compared the anchors which are in-
cluded in both subtrees. After a pair of correspond-
ing subtrees which share the anchors is found, the
subtree pair can be recognized as paraphrases. In ac-
tual experiments, we put some restrictions on these
subtrees, which will be discussed later. This way
we can obtain grammatically well-formed portions
of sentences (Figure 2).
</bodyText>
<subsectionHeader confidence="0.977719">
2.4 Generalize Expressions
</subsectionHeader>
<bodyText confidence="0.999879733333334">
After corresponding portions are obtained, we gen-
eralize the expressions to form usable templates of
paraphrases. Actually this is already done by Ex-
tended Named Entity tagging. An Extended Named
Entity tagger classifies proper expressions into sev-
eral categories. This is similar to a part-of-speech
tagger as it classifies words into several part-of-
speech categories. For example, “Hong Kong” is
tagged as a location name, and “two more” as a
number. So an expression such as “two more peo-
ple die in Hong Kong” is finally converted into the
form “NUMBER people die in LOCATION” where
NUMBER and LOCATION are slots to fill in. This
way we obtain expressions which can be used as IE
patterns.
</bodyText>
<figure confidence="0.979523789473684">
two more people
in Hong Kong
the government
have died
has announced
anchors
in
subject
object
subject
paraphrases
two more deaths
Hong Kong
LOCATION is included.
NUMBER is included.
reported
object
subject
predicates predicates
</figure>
<figureCaption confidence="0.998152">
Figure 2: Extracting portions of sentences
</figureCaption>
<sectionHeader confidence="0.97118" genericHeader="method">
3 Handling Problems in Real Texts
</sectionHeader>
<bodyText confidence="0.999603">
In the previous section we described our method for
obtaining paraphrases in principle. However there
are several issues in actual texts which pose difficul-
ties for our method.
The first one is in finding anchors which refer to
the same entity. In actual articles, names are some-
time referred to in a slightly different form. For ex-
ample, “President Bush” can also be referred to as
“Mr. Bush”. Additionally, sometime it is referred
to by a pronoun, such as “he”. Since our method
relies on the fact that those anchors are preserved
across articles, anchors which appear in these var-
ied forms may reduce the actual number of obtained
paraphrases.
To handle this problem, we extended the notion
of anchors to include not just Extended Named En-
tities, but also pronouns and common nouns such
as “the president”. We used a simple corefer-
ence resolver after Extended Named Entity tag-
ging. Currently this is done by simply assigning
the most recent antecedent to pronouns and finding
a longest common subsequence (LCS) between two
noun groups. Since it is possible to form a com-
pound noun such as “President-Bush” in Japanese,
we computed LCS for each character in the two
noun groups. We used the following condition to
decide whether two noun groups s1 and s2 are coref-
erential:
</bodyText>
<listItem confidence="0.9878025">
• if 2 G_ min(|s1|, |s2|) G_ |LCS(s1, s2)|, then
s1 and s2 are considered coreferential.
</listItem>
<bodyText confidence="0.994067698412698">
Here |s |denotes the length of noun group s and
LCS(s1, s2) is the LCS of two noun groups s1 and
s2.
The second problem is to extract appropriate por-
tions as paraphrase expressions. Since we use a tree
structure to represent the expressions, finding com-
mon subtrees may take an exponential number of
steps. For example, if a dependency tree in one
article has one single predicate which has n argu-
ments, the number of possible subtrees which can
be obtained from the tree is 2n. So the matching
process between arbitrary combinations of subtrees
may grow exponentially with the length of the sen-
tences. Even worse, it can generate many combina-
tions of sentence portions which don’t make sense as
paraphrases. For example, from the expression “two
more people have died in Hong Kong” and “Hong
Kong reported two more deaths”, we could extract
expressions “in Hong Kong” and “Hong Kong re-
ported”. Although both of them share one anchor,
this is not a correct paraphrase. To avoid this sort of
error, we need to put some additional restrictions on
the expressions.
(Shinyama et al., 2002) used the frequency of ex-
pressions to filter these incorrect pairs of expres-
sions. First the system obtained a set of IE patterns
from corpora (Sudo and Sekine, 2001), and then cal-
culated the score for each candidate paraphrase by
counting how many times that expression appears as
an IE pattern in the whole corpus. However, with
this method, obtainable expressions are limited to
existing IE patterns only. Since we wanted to ob-
tain a broader range of expressions not limited to
IE patterns themselves, we tried to use other restric-
tions which can be acquired independently of the IE
system.
We partly solve this problem by calculating the
plausibility of each tree structure. In Japanese sen-
tences, the case of each argument which modifies
a predicate is represented by a case marker (post-
position or joshi) which follows a noun phrase, just
like prepositions in English but in the opposite order.
These arguments include subjects and objects that
are elucidated syntactically in English sentences.
We collected frequent cases occurring with a spe-
cific predicate in advance. We applied this restric-
tion when generating subtrees from a dependency
tree by calculating a score for each predicate as fol-
lows:
Let an instance of predicate p have cases C =
{c1, c2, ..., cn} and a function Np(I) be the number
of instances of p in the corpus whose cases are I =
{c1, c2, ..., cm}. We compute the score Sp(C) of the
instance:
Using this metric, a predicate which doesn’t have
cases that it should usually have is given a lower
score. A subtree which includes a predicate whose
score is less than a certain threshold is filtered out.
This way we can filter out expressions such as
“Hong Kong reported” in Japanese since it would
lack an object case which normally the verb “re-
port” should have. Moreover, this greatly reduces
the number of possible combinations of subtrees.
</bodyText>
<sectionHeader confidence="0.99982" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999567454545454">
We used Japanese news articles for this experi-
ment. First we collected articles for a specific do-
main from two different newspapers (Mainichi and
Nikkei). Then we used a Japanese part-of-speech
tagger (Kurohashi and Nagao, 1998) and Extended
Named Entity tagger to process documents, and put
them into a Topic Detection and Tracking system.
In this experiment, we used a modified version of a
Japanese Extended Named Entity tagger (Uchimoto
et al., 2000). This tagger tags person names, orga-
nization names, locations, dates, times and numbers.
</bodyText>
<table confidence="0.969790875">
Article pairs:
Obtained Correct
System 195 156
(80%)
Sentence pairs:
(from top 20 article pairs)
Obtained Correct
Manual 93 93
W/o coref. 55 41 (75%)
W coref. 75 52 (69%)
Paraphrase pairs:
Obtained Correct
W/o coref. or restriction 106 25 (24%)
W/o coref., w restriction 32 18 (56%)
W coref. and restriction 37 23 (62%)
Manual (in 5 hours) (100) (100)
</table>
<tableCaption confidence="0.8910595">
Table 1: Results in the murder cases domain
Sample 1:
</tableCaption>
<listItem confidence="0.99463">
• PERSON] killed PERSON2.
• PERSON] let PERSON2 die from loss of blood.
Sample 2:
• PERSON] shadowed PERSON2.
• PERSON] kept his eyes on PERSON2.
</listItem>
<figureCaption confidence="0.90081">
Figure 3: Sample correct paraphrases obtained
(translated from Japanese)
</figureCaption>
<listItem confidence="0.889289714285714">
Sample 3:
• PERSON] fled to LOCATION.
• PERSON] fled and lay in ambush to LOCATION.
Sample 4:
• PERSON] cohabited with PERSON2.
• PERSON] murdered in the room for cohabitation
with PERSON2.
</listItem>
<figureCaption confidence="0.989902">
Figure 4: Sample incorrect paraphrases obtained
(translated from Japanese)
</figureCaption>
<equation confidence="0.586002">
� I⊂C Np(I)
Sp(C) =
.
</equation>
<bodyText confidence="0.978026529411765">
the number of instances of p in the corpus
Next we applied a simple vector space method to ob-
tain pairs of sentences which report the same event.
After that, we used a simple coreference resolver to
identify anchors. Finally we used a dependency an-
alyzer (Kurohashi, 1998) to extract portions of sen-
tences which share at least one anchor.
In this experiment, we used a set of articles which
reports murder cases. The results are shown in Ta-
ble 1. First, with Topic Detection and Tracking,
there were 156 correct pairs of articles out of 193
pairs obtained. To simplify the evaluation process,
we actually obtained paraphrases from the top 20
pairs of articles which had the highest similarities.
Obtained paraphrases were reviewed manually. We
used the following criteria for judging the correct-
ness of paraphrases:
</bodyText>
<listItem confidence="0.989988666666667">
1. They has to be describing the same event.
2. They should capture the same information if we
use them in an actual IE application.
</listItem>
<bodyText confidence="0.999992933333333">
We tried several conditions to extract paraphrases.
First we tried to extract paraphrases using neither
coreference resolution nor case restriction. Then we
applied only the case restriction with the threshold
0.3 &lt; SP(C), and observed the precision went up
from 24% to 56%. Furthermore, we added a sim-
ple coreference resolution and the precision rose to
62%. We got 23 correct paraphrases. We found
that several interesting paraphrases are obtained.
Some examples are shown in Figure 3 (correct para-
phrases) and Figure 4 (incorrect paraphrases).
It is hard to say how many paraphrases can be ul-
timately obtained from these articles. However, it is
worth noting that after spending about 5 hours for
this corpus we obtained 100 paraphrases manually.
</bodyText>
<sectionHeader confidence="0.999861" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999968117647059">
Some paraphrases were incorrectly obtained. There
were two major causes. The first one was depen-
dency analysis errors. Since our method recognizes
boundaries of expressions using dependency trees, if
some predicates in a tree take extra arguments, this
may result in including extraneous portions of the
sentence in the paraphrase. For example, the predi-
cate “lay in ambush” in Sample 3 should have taken
a different noun as its subject. If so, the predicate
doesn’t share the anchors any more and could be
eliminated.
The second cause was the lack of recognizing
contexts. In Sample 4, we observed that even if two
expressions share multiple anchors, an obtained pair
can be still incorrect. We hope that this kind of error
can be reduced by considering the contexts around
expressions more extensively.
</bodyText>
<sectionHeader confidence="0.999803" genericHeader="method">
6 Future Work
</sectionHeader>
<bodyText confidence="0.999991219512195">
We hope to apply our approach further to ob-
tain more varied paraphrases. After a certain
number of paraphrases are obtained, we can use
the obtained paraphrases as anchors to obtain
additional paraphrases. For example, if we know
“A dismantle B” and “A destroy B” are para-
phrases, we could apply them to “U.N. reported
Iraq dismantling more missiles” and “U.N. official
says Iraq destroyed more Al-Samoud 2 missiles”,
and obtain another pair of paraphrases “X reports Y”
and “X says Y”.
This approach can be extended in the other direc-
tion. Some entities can be referred to by completely
different names in certain situations, such as “North
Korea” and “Pyongyang”. We are also planning to
identify these varied external forms of a single entity
by applying previously obtained paraphrases. For
example, if we know “A restarted B” and “A reac-
tivated B” as paraphrases, we could apply them to
“North Korea restarted its nuclear facility” and “Py-
ongyang has reactivated the atomic facility”. This
way we know “North Korea” and “Pyongyang” can
refer to the same entity in a certain context.
In addition, we are planning to give some credi-
bility score to anchors for improving accuracy. We
found that some anchors are less reliable than oth-
ers even if they are considered as proper expres-
sions. For example, in most U.S. newspapers the
word “U.S.” is used in much wider contexts than
word such as “Thailand” although both of them are
country names. So we want to give less credit to
these widely used names.
We noticed that there are several issues in general-
izing paraphrases. Currently we simply label every
Named Entity as a slot. However expressions such
as “the governor of LOCATION” can take only a cer-
tain kind of locations. Also some paraphrases might
require a narrower context than others and are not
truly interchangeable. For example, “PERSON was
sworn” can be replaced with “PERSON took office”,
but not vice versa.
</bodyText>
<sectionHeader confidence="0.99907" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999981166666667">
In this paper, we described a method to obtain para-
phrases automatically from corpora. Our key notion
is to use comparable articles which report the same
event on the same day. Some noun phrases, espe-
cially Extended Named Entities such as names, lo-
cations and numbers, are preserved across articles
even if the event is reported using different expres-
sions. We used these noun phrases as anchors and
extracted portions which share these anchors. Then
we generalized the obtained expressions as usable
paraphrases.
We adopted dependency trees as a format for ex-
pressions which preserve syntactic constraints when
extracting paraphrases. We generate possible sub-
trees from dependency trees and find pairs which
share the anchors. However, simply generating all
subtrees ends up obtaining many inappropriate por-
tions of sentences. We tackled this problem by cal-
culating a score which tells us how plausible ex-
tracted candidates are. We confirmed that it con-
tributed to the overall accuracy. This metric was
also useful to trimming the search space for match-
ing subtrees. We used a simple coreference resolver
to handle some additional anchors such as pronouns.
</bodyText>
<sectionHeader confidence="0.99897" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996198333333333">
This research is supported by the Defense Advanced
Research Projects Agency as part of the Translin-
gual Information Detection, Extraction and Sum-
marization (TIDES) program, under Grant N66001-
001-1-8917 from the Space and Naval Warfare Sys-
tems Center San Diego, and by the National Science
Foundation under Grant IIS-0081962. This paper
does not necessarily reflect the position or the pol-
icy of the U.S. Government.
</bodyText>
<sectionHeader confidence="0.999487" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999893690476191">
Regina Barzilay and Kathleen R. McKeown. 2001. Ex-
tracting Paraphrases from a Parallel Corpus. In Pro-
ceedings of the ACL/EACL.
Sadao Kurohashi and Makoto Nagao, 1998. Japanese
Morphological Analysis System JUMAN. Kyoto Uni-
versity, version 3.61 edition.
Sadao Kurohashi, 1998. Kurohashi-Nagao parser. Ky-
oto University, version 2.0 b6 edition.
Dekang Lin and Patrick Pantel. 2001. Discovery of In-
ference Rules for Question Answering. Natural Lan-
guage Engineering, 7(4):343–360.
Bo Pang, Kevin Knight, and Danial Marcu. 2003.
Syntax-based Alignment of Multiple Translations: Ex-
tracting Paraphrases and Generating New Sentences.
In NAACL-HLT.
Ron Papka, James Allen, and Victor Lavrenko. 1999.
UMASS Approaches to Detection and Tracking at
TDT2. In DARPA: Broadcast News Workshop.
Deepak Ravichandran and Eduard Hovy. 2002. Learning
surface text patterns for a question answering system.
In Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics (ACL).
Satoshi Sekine, Kiyoshi sudo, and Chikashi Nobata.
2002. Extended Named Entity Hierarchy. In Proceed-
ings of the LREC.
Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo, and
Ralph Grishman. 2002. Automatic Paraphrase Ac-
quisition from News Articles. In Proceedings of the
Second International Conference on Human Language
Technology Research.
Kiyoshi Sudo and Satoshi Sekine. 2001. Automatic Pat-
tern Acquisition for Japanese Information Extraction.
In Proceedings of the HLT.
Kiyotaka Uchimoto, Masaki Murata, Qing Ma, Hiromi
Ozaku, and Hitoshi Isahara. 2000. Named Entity Ex-
traction Based on A Maximum Entropy Model and
Transformation Rules. In Proceedings of the 38th
Annual Meeting of the Association for Computational
Linguistics (ACL), pages 326–335.
Charles L. Wayne. 1998. Topic Detection &amp; Tracking: A
Case Study in Corpus Creation &amp; Evaluation Method-
ologies. In Proceedings of the LREC.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.672665">
<title confidence="0.999853">Paraphrase Acquisition for Information Extraction</title>
<author confidence="0.94069">Yusuke</author>
<affiliation confidence="0.997655">Department of Computer</affiliation>
<address confidence="0.951689">New York 715, Broadway, 7th Floor, NY,</address>
<email confidence="0.999761">yusuke@cs.nyu.edu</email>
<author confidence="0.890499">Satoshi</author>
<affiliation confidence="0.999588">Department of Computer</affiliation>
<address confidence="0.9530955">New York 715, Broadway, 7th Floor, NY,</address>
<email confidence="0.99983">sekine@cs.nyu.edu</email>
<abstract confidence="0.999193392857143">We are trying to find paraphrases from Japanese news articles which can be used for Information Extraction. We focused on the fact that a single event can be reported in more than one article in different ways. However, certain kinds of noun phrases such as names, dates and numbers behave as “anchors” which are unlikely to change across articles. Our key idea is to identify these anchors among comparable articles and extract portions of expressions which share the anchors. This way we can extract expressions which convey the same information. Obtained paraphrases are generalized as templates and stored for future use. In this paper, first we describe our basic idea of paraphrase acquisition. Our method is divided into roughly four steps, each of which is explained in turn. Then we illustrate several issues which we encounter in real texts. To solve these problems, we introduce two techniques: coreference resolution and structural restriction of possible portions of expressions. Finally we discuss the experimental results and conclusions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting Paraphrases from a Parallel Corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL/EACL.</booktitle>
<contexts>
<context position="3230" citStr="Barzilay and McKeown, 2001" startWordPosition="517" endWordPosition="520"> in this attempt only limited forms of expressions could be obtained. Furthermore, the obtained paraphrases were limited to existing IE patterns only. We are interested in collecting various kinds of clues, including similar IE patterns themselves, to connect two patterns. In this paper, we tried to obtain more varied paraphrases. Although our current method is intended for use in Information Extraction, we think the same approach can be applied to obtain paraphrases for other purposes, such as machine translation or text summarization. There have been several attempts to obtain paraphrases. (Barzilay and McKeown, 2001) applied text alignment to parallel translations of a single text and used a part-of-speech tagger to obtain paraphrases. (Lin and Pantel, 2001) used mutual information of word distribution to calculate the similarity of expressions. (Pang et al., 2003) also used text alignment and obtained a finite state automaton which generates paraphrases. (Ravichandran and Hovy, 2002) used pairs of questions and answers to obtain varied patterns which give the same answer. Our approach is different from these works in that we used comparable news articles as a source of paraphrases and used Named Entity t</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen R. McKeown. 2001. Extracting Paraphrases from a Parallel Corpus. In Proceedings of the ACL/EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>Japanese Morphological Analysis System JUMAN. Kyoto University, version 3.61 edition.</title>
<date>1998</date>
<contexts>
<context position="15206" citStr="Kurohashi and Nagao, 1998" startWordPosition="2500" endWordPosition="2503">should usually have is given a lower score. A subtree which includes a predicate whose score is less than a certain threshold is filtered out. This way we can filter out expressions such as “Hong Kong reported” in Japanese since it would lack an object case which normally the verb “report” should have. Moreover, this greatly reduces the number of possible combinations of subtrees. 4 Experiments We used Japanese news articles for this experiment. First we collected articles for a specific domain from two different newspapers (Mainichi and Nikkei). Then we used a Japanese part-of-speech tagger (Kurohashi and Nagao, 1998) and Extended Named Entity tagger to process documents, and put them into a Topic Detection and Tracking system. In this experiment, we used a modified version of a Japanese Extended Named Entity tagger (Uchimoto et al., 2000). This tagger tags person names, organization names, locations, dates, times and numbers. Article pairs: Obtained Correct System 195 156 (80%) Sentence pairs: (from top 20 article pairs) Obtained Correct Manual 93 93 W/o coref. 55 41 (75%) W coref. 75 52 (69%) Paraphrase pairs: Obtained Correct W/o coref. or restriction 106 25 (24%) W/o coref., w restriction 32 18 (56%) W</context>
</contexts>
<marker>Kurohashi, Nagao, 1998</marker>
<rawString>Sadao Kurohashi and Makoto Nagao, 1998. Japanese Morphological Analysis System JUMAN. Kyoto University, version 3.61 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
</authors>
<title>Kurohashi-Nagao parser. Kyoto University, version 2.0 b6 edition.</title>
<date>1998</date>
<contexts>
<context position="16706" citStr="Kurohashi, 1998" startWordPosition="2754" endWordPosition="2755"> correct paraphrases obtained (translated from Japanese) Sample 3: • PERSON] fled to LOCATION. • PERSON] fled and lay in ambush to LOCATION. Sample 4: • PERSON] cohabited with PERSON2. • PERSON] murdered in the room for cohabitation with PERSON2. Figure 4: Sample incorrect paraphrases obtained (translated from Japanese) � I⊂C Np(I) Sp(C) = . the number of instances of p in the corpus Next we applied a simple vector space method to obtain pairs of sentences which report the same event. After that, we used a simple coreference resolver to identify anchors. Finally we used a dependency analyzer (Kurohashi, 1998) to extract portions of sentences which share at least one anchor. In this experiment, we used a set of articles which reports murder cases. The results are shown in Table 1. First, with Topic Detection and Tracking, there were 156 correct pairs of articles out of 193 pairs obtained. To simplify the evaluation process, we actually obtained paraphrases from the top 20 pairs of articles which had the highest similarities. Obtained paraphrases were reviewed manually. We used the following criteria for judging the correctness of paraphrases: 1. They has to be describing the same event. 2. They sho</context>
</contexts>
<marker>Kurohashi, 1998</marker>
<rawString>Sadao Kurohashi, 1998. Kurohashi-Nagao parser. Kyoto University, version 2.0 b6 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of Inference Rules for Question Answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="3374" citStr="Lin and Pantel, 2001" startWordPosition="540" endWordPosition="543"> We are interested in collecting various kinds of clues, including similar IE patterns themselves, to connect two patterns. In this paper, we tried to obtain more varied paraphrases. Although our current method is intended for use in Information Extraction, we think the same approach can be applied to obtain paraphrases for other purposes, such as machine translation or text summarization. There have been several attempts to obtain paraphrases. (Barzilay and McKeown, 2001) applied text alignment to parallel translations of a single text and used a part-of-speech tagger to obtain paraphrases. (Lin and Pantel, 2001) used mutual information of word distribution to calculate the similarity of expressions. (Pang et al., 2003) also used text alignment and obtained a finite state automaton which generates paraphrases. (Ravichandran and Hovy, 2002) used pairs of questions and answers to obtain varied patterns which give the same answer. Our approach is different from these works in that we used comparable news articles as a source of paraphrases and used Named Entity tagging and dependency analysis to extract corresponding expressions. 2 Overall Procedure of Paraphrase Acquisition Our main goal is to obtain pa</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of Inference Rules for Question Answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Kevin Knight</author>
<author>Danial Marcu</author>
</authors>
<title>Syntax-based Alignment of Multiple Translations: Extracting Paraphrases and Generating New Sentences.</title>
<date>2003</date>
<booktitle>In NAACL-HLT.</booktitle>
<contexts>
<context position="3483" citStr="Pang et al., 2003" startWordPosition="558" endWordPosition="561">o patterns. In this paper, we tried to obtain more varied paraphrases. Although our current method is intended for use in Information Extraction, we think the same approach can be applied to obtain paraphrases for other purposes, such as machine translation or text summarization. There have been several attempts to obtain paraphrases. (Barzilay and McKeown, 2001) applied text alignment to parallel translations of a single text and used a part-of-speech tagger to obtain paraphrases. (Lin and Pantel, 2001) used mutual information of word distribution to calculate the similarity of expressions. (Pang et al., 2003) also used text alignment and obtained a finite state automaton which generates paraphrases. (Ravichandran and Hovy, 2002) used pairs of questions and answers to obtain varied patterns which give the same answer. Our approach is different from these works in that we used comparable news articles as a source of paraphrases and used Named Entity tagging and dependency analysis to extract corresponding expressions. 2 Overall Procedure of Paraphrase Acquisition Our main goal is to obtain pattern clusters for IE, which consist of sets of equivalent patterns capturing the same information. So we tri</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>Bo Pang, Kevin Knight, and Danial Marcu. 2003. Syntax-based Alignment of Multiple Translations: Extracting Paraphrases and Generating New Sentences. In NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Papka</author>
<author>James Allen</author>
<author>Victor Lavrenko</author>
</authors>
<title>UMASS Approaches to Detection and Tracking at TDT2.</title>
<date>1999</date>
<booktitle>In DARPA: Broadcast News Workshop.</booktitle>
<contexts>
<context position="7604" citStr="Papka et al., 1999" startWordPosition="1231" endWordPosition="1234">arch space and reduce erroneous matching of anchors. (Articles on the same day) Article A Article B SARS 1 SARS 2 &amp;quot;NUMBER people die in LOCATION&amp;quot; &amp;quot;LOCTION reports NUMBER deaths&amp;quot; anchors paraphrases Find comparable Identify Extract Generalize articles and anchors corrsponding expressions sentences portions Figure 1: The overall procedure Before applying this technique, we first preprocessed the articles by stripping off the strings which are not considered as sentences. Then we used a part-of-speech tagger to obtain segmented words. In the actual matching process we used a method described in (Papka et al., 1999) to find a set of comparable articles. Then we use a simple vector space model for sentence matching. 2.2 Identify Anchors Before extracting paraphrases, we find anchors in comparable sentences. We used Extended Named Entity tagging to identify anchors. A Named Entity tagger identifies proper expressions such as names, locations and dates in sentences. In addition to these expressions, an Extended Named Entity tagger identifies some common nouns such as disease names or numbers, that are also unlikely to change (Sekine et al., 2002). For each corresponding pair of sentences, we apply the tagge</context>
</contexts>
<marker>Papka, Allen, Lavrenko, 1999</marker>
<rawString>Ron Papka, James Allen, and Victor Lavrenko. 1999. UMASS Approaches to Detection and Tracking at TDT2. In DARPA: Broadcast News Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="3605" citStr="Ravichandran and Hovy, 2002" startWordPosition="575" endWordPosition="578">or use in Information Extraction, we think the same approach can be applied to obtain paraphrases for other purposes, such as machine translation or text summarization. There have been several attempts to obtain paraphrases. (Barzilay and McKeown, 2001) applied text alignment to parallel translations of a single text and used a part-of-speech tagger to obtain paraphrases. (Lin and Pantel, 2001) used mutual information of word distribution to calculate the similarity of expressions. (Pang et al., 2003) also used text alignment and obtained a finite state automaton which generates paraphrases. (Ravichandran and Hovy, 2002) used pairs of questions and answers to obtain varied patterns which give the same answer. Our approach is different from these works in that we used comparable news articles as a source of paraphrases and used Named Entity tagging and dependency analysis to extract corresponding expressions. 2 Overall Procedure of Paraphrase Acquisition Our main goal is to obtain pattern clusters for IE, which consist of sets of equivalent patterns capturing the same information. So we tried to discover paraphrases contained in Japanese news articles for a specific domain. Our basic idea is to search news art</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning surface text patterns for a question answering system. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
<author>Kiyoshi sudo</author>
<author>Chikashi Nobata</author>
</authors>
<title>Extended Named Entity Hierarchy.</title>
<date>2002</date>
<booktitle>In Proceedings of the LREC.</booktitle>
<contexts>
<context position="8142" citStr="Sekine et al., 2002" startWordPosition="1317" endWordPosition="1320"> In the actual matching process we used a method described in (Papka et al., 1999) to find a set of comparable articles. Then we use a simple vector space model for sentence matching. 2.2 Identify Anchors Before extracting paraphrases, we find anchors in comparable sentences. We used Extended Named Entity tagging to identify anchors. A Named Entity tagger identifies proper expressions such as names, locations and dates in sentences. In addition to these expressions, an Extended Named Entity tagger identifies some common nouns such as disease names or numbers, that are also unlikely to change (Sekine et al., 2002). For each corresponding pair of sentences, we apply the tagger and identify the same noun phrases which appear in both sentences as anchors. 2.3 Extract Corresponding Sentence Portions Now we identify appropriate boundaries of expressions which share the anchors identified in the previous stage. To avoid extracting non-grammatical expressions, we operate on syntactically structured text rather than sequences of words. Dependency analysis is suitable for this purpose, since using dependency trees we can reconstruct grammatically correct expressions from a spanning subtree whose root is a predi</context>
</contexts>
<marker>Sekine, sudo, Nobata, 2002</marker>
<rawString>Satoshi Sekine, Kiyoshi sudo, and Chikashi Nobata. 2002. Extended Named Entity Hierarchy. In Proceedings of the LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
<author>Kiyoshi Sudo</author>
<author>Ralph Grishman</author>
</authors>
<title>Automatic Paraphrase Acquisition from News Articles.</title>
<date>2002</date>
<booktitle>In Proceedings of the Second International Conference on Human Language Technology Research.</booktitle>
<contexts>
<context position="2593" citStr="Shinyama et al., 2002" startWordPosition="418" endWordPosition="421">most IE systems, the performance of the system is dependent on these well-designed patterns. In natural language sentences, a single event can be expressed in many different ways. So we need to prepare patterns for various kinds of expressions used in articles. We are interested in clustering IE patterns which capture the same information. For example, a pattern such as “LOCATION reports NUMBER deaths” can be used for the same purpose as the previous one, since this pattern could also capture the casualties occurring in a certain location. Prior work to relate two IE patterns was reported by (Shinyama et al., 2002). However, in this attempt only limited forms of expressions could be obtained. Furthermore, the obtained paraphrases were limited to existing IE patterns only. We are interested in collecting various kinds of clues, including similar IE patterns themselves, to connect two patterns. In this paper, we tried to obtain more varied paraphrases. Although our current method is intended for use in Information Extraction, we think the same approach can be applied to obtain paraphrases for other purposes, such as machine translation or text summarization. There have been several attempts to obtain para</context>
<context position="13094" citStr="Shinyama et al., 2002" startWordPosition="2142" endWordPosition="2145">the tree is 2n. So the matching process between arbitrary combinations of subtrees may grow exponentially with the length of the sentences. Even worse, it can generate many combinations of sentence portions which don’t make sense as paraphrases. For example, from the expression “two more people have died in Hong Kong” and “Hong Kong reported two more deaths”, we could extract expressions “in Hong Kong” and “Hong Kong reported”. Although both of them share one anchor, this is not a correct paraphrase. To avoid this sort of error, we need to put some additional restrictions on the expressions. (Shinyama et al., 2002) used the frequency of expressions to filter these incorrect pairs of expressions. First the system obtained a set of IE patterns from corpora (Sudo and Sekine, 2001), and then calculated the score for each candidate paraphrase by counting how many times that expression appears as an IE pattern in the whole corpus. However, with this method, obtainable expressions are limited to existing IE patterns only. Since we wanted to obtain a broader range of expressions not limited to IE patterns themselves, we tried to use other restrictions which can be acquired independently of the IE system. We par</context>
</contexts>
<marker>Shinyama, Sekine, Sudo, Grishman, 2002</marker>
<rawString>Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo, and Ralph Grishman. 2002. Automatic Paraphrase Acquisition from News Articles. In Proceedings of the Second International Conference on Human Language Technology Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoshi Sudo</author>
<author>Satoshi Sekine</author>
</authors>
<title>Automatic Pattern Acquisition for Japanese Information Extraction.</title>
<date>2001</date>
<booktitle>In Proceedings of the HLT.</booktitle>
<contexts>
<context position="13260" citStr="Sudo and Sekine, 2001" startWordPosition="2171" endWordPosition="2174">e many combinations of sentence portions which don’t make sense as paraphrases. For example, from the expression “two more people have died in Hong Kong” and “Hong Kong reported two more deaths”, we could extract expressions “in Hong Kong” and “Hong Kong reported”. Although both of them share one anchor, this is not a correct paraphrase. To avoid this sort of error, we need to put some additional restrictions on the expressions. (Shinyama et al., 2002) used the frequency of expressions to filter these incorrect pairs of expressions. First the system obtained a set of IE patterns from corpora (Sudo and Sekine, 2001), and then calculated the score for each candidate paraphrase by counting how many times that expression appears as an IE pattern in the whole corpus. However, with this method, obtainable expressions are limited to existing IE patterns only. Since we wanted to obtain a broader range of expressions not limited to IE patterns themselves, we tried to use other restrictions which can be acquired independently of the IE system. We partly solve this problem by calculating the plausibility of each tree structure. In Japanese sentences, the case of each argument which modifies a predicate is represen</context>
</contexts>
<marker>Sudo, Sekine, 2001</marker>
<rawString>Kiyoshi Sudo and Satoshi Sekine. 2001. Automatic Pattern Acquisition for Japanese Information Extraction. In Proceedings of the HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyotaka Uchimoto</author>
<author>Masaki Murata</author>
<author>Qing Ma</author>
<author>Hiromi Ozaku</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Named Entity Extraction Based on A Maximum Entropy Model and Transformation Rules.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>326--335</pages>
<contexts>
<context position="15432" citStr="Uchimoto et al., 2000" startWordPosition="2537" endWordPosition="2540">t would lack an object case which normally the verb “report” should have. Moreover, this greatly reduces the number of possible combinations of subtrees. 4 Experiments We used Japanese news articles for this experiment. First we collected articles for a specific domain from two different newspapers (Mainichi and Nikkei). Then we used a Japanese part-of-speech tagger (Kurohashi and Nagao, 1998) and Extended Named Entity tagger to process documents, and put them into a Topic Detection and Tracking system. In this experiment, we used a modified version of a Japanese Extended Named Entity tagger (Uchimoto et al., 2000). This tagger tags person names, organization names, locations, dates, times and numbers. Article pairs: Obtained Correct System 195 156 (80%) Sentence pairs: (from top 20 article pairs) Obtained Correct Manual 93 93 W/o coref. 55 41 (75%) W coref. 75 52 (69%) Paraphrase pairs: Obtained Correct W/o coref. or restriction 106 25 (24%) W/o coref., w restriction 32 18 (56%) W coref. and restriction 37 23 (62%) Manual (in 5 hours) (100) (100) Table 1: Results in the murder cases domain Sample 1: • PERSON] killed PERSON2. • PERSON] let PERSON2 die from loss of blood. Sample 2: • PERSON] shadowed PER</context>
</contexts>
<marker>Uchimoto, Murata, Ma, Ozaku, Isahara, 2000</marker>
<rawString>Kiyotaka Uchimoto, Masaki Murata, Qing Ma, Hiromi Ozaku, and Hitoshi Isahara. 2000. Named Entity Extraction Based on A Maximum Entropy Model and Transformation Rules. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL), pages 326–335.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles L Wayne</author>
</authors>
<title>Topic Detection &amp; Tracking: A Case Study in Corpus Creation &amp; Evaluation Methodologies.</title>
<date>1998</date>
<booktitle>In Proceedings of the LREC.</booktitle>
<contexts>
<context position="6659" citStr="Wayne, 1998" startWordPosition="1085" endWordPosition="1086"> the expressions to templates of paraphrases which can be used in future. Our method is divided into four steps: 1. Find comparable sentences which report the same event from different newspapers. 2. Identify anchors in the comparable sentences. 3. Extract corresponding portions from the sentences. 4. Generalize the obtained expressions to paraphrase templates. Figure 1 shows the overall procedure. In the remainder of this section, we describe each step in turn. 2.1 Find Comparable Sentences To find comparable articles and sentences, we used methods developed for Topic Detection and Tracking (Wayne, 1998). The actual process is divided into two parts: article level matching and sentence level matching. Currently we assume that a pair of paraphrases can be found in a single sentence of each article and corresponding expressions don’t range across two or more sentences. Article level matching is first required to narrow the search space and reduce erroneous matching of anchors. (Articles on the same day) Article A Article B SARS 1 SARS 2 &amp;quot;NUMBER people die in LOCATION&amp;quot; &amp;quot;LOCTION reports NUMBER deaths&amp;quot; anchors paraphrases Find comparable Identify Extract Generalize articles and anchors corrspondin</context>
</contexts>
<marker>Wayne, 1998</marker>
<rawString>Charles L. Wayne. 1998. Topic Detection &amp; Tracking: A Case Study in Corpus Creation &amp; Evaluation Methodologies. In Proceedings of the LREC.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>