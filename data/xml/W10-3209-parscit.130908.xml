<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009068">
<title confidence="0.997546">
Constructing Thai Opinion Mining Resource:
A Case Study on Hotel Reviews
</title>
<author confidence="0.8723485">
Choochart Haruechaiyasak, Alisa Kongthon,
Pornpimon Palingoon and Chatchawal Sangkeettrakarn
</author>
<affiliation confidence="0.910738">
Human Language Technology Laboratory (HLT)
National Electronics and Computer Technology Center (NECTEC)
</affiliation>
<email confidence="0.9886145">
choochart.har@nectec.or.th, alisa.kon@nectec.or.th,
pornpimon.pal@nectec.or.th, chatchawal.san@nectec.or.th
</email>
<sectionHeader confidence="0.993833" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999871538461539">
Opinion mining and sentiment analy-
sis has recently gained increasing atten-
tion among the NLP community. Opin-
ion mining is considered a domain-
dependent task. Constructing lexicons
for different domains is labor intensive.
In this paper, we propose a framework
for constructing Thai language resource
for feature-based opinion mining. The
feature-based opinion mining essentially
relies on the use of two main lexicons,
features and polar words. Our approach
for extracting features and polar words
from opinionated texts is based on syn-
tactic pattern analysis. The evaluation
is performed with a case study on ho-
tel reviews. The proposed method has
shown to be very effective in most cases.
However, in some cases, the extraction
is not quite straightforward. The rea-
sons are due to, firstly, the use of conver-
sational language in written opinionated
texts and, secondly, the language seman-
tic. We provide discussion with possible
solutions on pattern extraction for some
of the challenging cases.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999618032258064">
With the popularity of Web 2.0 or social net-
working websites, the amount of user-generated
contents has increased exponentially. One in-
teresting type of these user-generated contents
is texts which are written with some opinions
and/or sentiments. An in-depth analysis of these
opinionated texts could reveal potentially use-
ful information regarding the preferences of peo-
ple towards many different topics including news
events, social issues and commercial products.
Opinion mining and sentiment analysis is such
task for analyzing and summarizing what people
think about a certain topic.
Due to its potential and useful applications,
opinion mining has gained a lot of interest in text
mining and NLP communities (Ding et al., 2008;
Jin et al., 2009). Much work in this area focused
on evaluating reviews as being positive or nega-
tive either at the document level (Turney, 2002;
Pang et al., 2002; Dave et al., 2003; Beineke
et al., 2004) or sentence level (Kim and Hovy,
2004; Wiebe and Riloff, 2005; Wilson et al.,
2009; Yu and Hatzivassiloglou, 2003). For in-
stance, given some reviews of a product, the sys-
tem classifies them into positive or negative re-
views. No specific details or features are identi-
fied about what customers like or dislike. To ob-
tain such details, a feature-based opinion mining
approach has been proposed (Hu and Liu, 2004;
Popescu and Etzioni, 2005). This approach typi-
cally consists of two following steps.
</bodyText>
<listItem confidence="0.986718166666667">
1. Identifying and extracting features of an ob-
ject, topic or event from each sentence upon
which the reviewers expressed their opin-
ion.
2. Determining whether the opinions regard-
ing the features are positive or negative.
</listItem>
<bodyText confidence="0.99984">
The feature-based opinion mining could pro-
vide users with some insightful information re-
lated to opinions on a particular topic. For exam-
ple, for hotel reviews, the feature-based opinion
</bodyText>
<page confidence="0.992695">
64
</page>
<note confidence="0.59534">
Proceedings of the 8th Workshop on Asian Language Resources, pages 64–71,
Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing
</note>
<bodyText confidence="0.999995462686567">
mining allows users to view positive or negative
opinions on hotel-related features such as price,
service, breakfast, room, facilities and activities.
Breaking down opinions into feature level is very
essential for decision making. Different cus-
tomers could have different preferences when se-
lecting hotels to stay for vacation. For example,
some might prefer hotels which provide full fa-
cilities, however, some might prefer to have good
room service.
The main drawback of the feature-based opin-
ion mining is the preparation of different lex-
icons including features and polar words. To
make things worse, these lexicons, especially the
features, are domain-dependent. For a partic-
ular domain, a set of features and polar words
must be prepared. The process for language
resource construction is generally labor inten-
sive and time consuming. Some previous works
have proposed different approaches for automat-
ically constructing the lexicons for the feature-
based opinion mining (Qiu et al., 2009; Riloff
and Wiebe, 2003; Sarmento et al., 2009). Most
approaches applied some machine learning al-
gorithms for learning the rules from the corpus.
The rules are used for extracting new features
and polar words from untagged corpus. Reviews
of different approaches are given in the related
work section.
In this paper, we propose a framework for
constructing Thai language resource for the
feature-based opinion mining. Our approach
is based on syntactic pattern analysis of two
lexicon types: domain-dependent and domain-
independent. The domain-dependent lexicons
include features, sub-features and polar words.
The domain-independent lexicons are particles,
negative words, degree words, auxiliary verbs,
prepositions and stop words. Using these lexi-
cons, we could construct a set of syntactic rules
based on the frequently occurred patterns. The
rule set can be used for extracting more unseen
sub-features and polar words from untagged cor-
pus.
We evaluated the proposed framework on the
domain of hotel reviews. The experimental re-
sults showed that our proposed method is very
effective in most cases, especially for extracting
polar words. However, in some cases, the extrac-
tion is not quite straightforward due to the use of
conversational language, idioms and hidden se-
mantic. We provide some discussion on the chal-
lenging cases and suggest some solutions as the
future work.
The remainder of this paper is organized as
follows. In next section, we review some related
works on different approaches for constructing
language resources for opinion mining and sen-
timent analysis. In Section 3, we present the pro-
posed framework for constructing Thai opinion
mining resource by using the dual pattern extrac-
tion method. In Section 4, we apply the proposed
framework with a case study of hotel reviews.
The performance evaluation is given with the ex-
periment results. Some difficult cases are dis-
cussed along with some possible solutions. Sec-
tion 5 concludes the paper with the future work.
</bodyText>
<sectionHeader confidence="0.999424" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.99998704">
The problem of developing subjectivity lexicons
for training and testing sentiment classifiers has
recently attracted some attention. The Multi-
perspective Question Answering (MPQA) opin-
ion corpus is a well-known resource for senti-
ment analysis in English (Wiebe et al., 2005).
It is a collection of news articles from a vari-
ety of news sources manually annotated at word
and phrase levels for opinions and other private
states (i.e., beliefs, emotions, sentiments, spec-
ulations, etc.). The annotation in this work also
took into account the context, which is essential
for resolving possible ambiguities and accurately
determining polarity.
Although most of the reference corpora has
been focused on English language, work on other
languages is growing as well. Kanayama et
al. (2006) proposed an unsupervised method to
detect sentiment words in Japanese. In this work,
they used clause level context coherency to iden-
tify candidate sentiment words from sentences
that appear successively with sentences contain-
ing seed sentiment words. Their assumption is
that unless the context is changed with adver-
sative expressions, sentences appearing together
</bodyText>
<page confidence="0.99789">
65
</page>
<bodyText confidence="0.999972717948718">
in that context tend to have the same polari-
ties. Hence, if one of them contains sentiments
words, the other successive sentences are likely
to contain sentiment words as well. Ku and
Chen (2007) proposed the bag-of-characters ap-
proach to determine sentiment words in Chinese.
This approach calculates the observation proba-
bilities of characters from a set of seed sentiment
words first, then dynamically expands the set and
adjusts their probabilities. Later in 2009, Ku
et al. (2009), extended their bag-of-characters
approach by including morphological structures
and syntactic structures between sentence seg-
ment. Their experiments showed better perfor-
mance of word polarity detection and opinion
sentence extraction.
Some other methods to automatically gener-
ate resources for subjectivity analysis for a for-
eign language have leveraged the resources and
tools available for English. For example, Be-
nea et al. (2008) applied machine translation and
standard Naive Bayes and SVM for subjectiv-
ity classification for Romanian. Their exper-
iments showed promising results for applying
automatic translation to construct resources and
tools for opinion mining in a foreign language.
Wan (2009) also leveraged an available English
corpus for Chinese sentiment classification by
using the co-training approach to make full use
of both English and Chinese features in a uni-
fied framework. Jijkoun and Hofmann (2009)
also described a method for creating a Dutch
subjectivity lexicon based on an English lexi-
con. They applied a PageRank-like algorithm
that bootstraps a subjectivity lexicon from the
translation of the English lexicon and rank the
words in the thesaurus by polarity using the net-
work of lexical relations (e.g., synonymy, hy-
ponymy) in Wordnet.
</bodyText>
<sectionHeader confidence="0.959257" genericHeader="method">
3 The proposed framework
</sectionHeader>
<bodyText confidence="0.9999535">
The performance of the feature-based opinion
mining relies on the design and completeness
of related lexicons. Our lexicon design dis-
tinguishes lexicons into two types, domain-
dependent and domain-independent. The design
of domain-dependent lexicons is based on the
feature-based opinion mining framework pro-
posed by Liu et al. (2005). The framework starts
by setting the domain scope such as digital cam-
era. The next step is to design a set of features
associated with the given domain. For the do-
main of digital camera, features could be, for in-
stance, “price”, “screen size” and “picture qual-
ity”. Features could contain sub-features. For
example, the picture quality could have the sub-
features as “macro mode”, “portrait mode” and
“night mode”. Preparing multiple feature levels
could be time-consuming, therefore, we limit the
features into two levels: main features and sub-
features.
Another domain-dependent lexicon is po-
lar words. Polar words are sentiment words
which represent either positive or negative views
on features. Although some polar words are
domain-independent and have explicit meanings
such as “excellent”, “beautiful”, “expensive”
and “terrible”. Some polar words are domain-
dependent and have implicit meanings depend-
ing on the contexts. For example, the word
“large” is generally considered positive for the
screen size feature of digital camera domain.
However, for the dimension feature of mobile
phone domain, the word “large” could be con-
sidered as negative.
On the other hand, the domain-independent
lexicons are regular words which provide differ-
ent parts of speech (POS) and functions in the
sentence. For opinion mining task, we design
six different domain-independent lexicons as fol-
lows (some examples are shown in Table 1).
</bodyText>
<listItem confidence="0.919588692307692">
• Particles (PAR): In Thai language, these
words refer to the sentence endings which
are normally used to add politeness of the
speakers (Cooke, 1992).
• Negative words (NEG): Like English,
these words are used to invert the opinion
polarity. Examples are “not”, “unlikely”
and “never”.
• Degree words (DEG): These words are
used as an intensifier to the polar words.
Examples are “large”, “very”, “enormous”.
66
• Auxiliary verbs (AUX): These words are
used to modify verbs. Examples are
“should”, “must” and “then”.
• Prepositions (PRE): Like English, Thai
prepositions are used to mark the relations
between two words.
• Stop words (STO): These words are used
for grammaticalization. Thai language is
considered an isolating language, to form a
noun the words “karn” and “kwam” are nor-
mally placed in front of a verb or a noun,
respectively. Therefore, these words could
be neglected when analyzing opinionated
texts.
</listItem>
<tableCaption confidence="0.994619">
Table 1: Domain-independent lexicons
</tableCaption>
<bodyText confidence="0.999483380952381">
Although some of the above lexicons are sim-
ilar to English, however, some words are placed
in different position in a sentence. For example,
in Thai, a degree word is usually placed after a
polar word. For example, “very good” would be
written as “good very” in Thai.
Figure 1 shows all processes and work flow
under the proposed framework. The process
starts with a corpus which is tagged based on
two lexicon types. From the tagged corpus,
we construct patterns and lexicons. The pat-
tern construction is performed by collecting text
segments which contain both features and polar
words. All patterns are sorted by the frequency
of occurrence. The lexicon construction is per-
formed by simply collecting words which are al-
ready tagged with the lexicon types. The lex-
icons are used for performing the feature-based
opinion mining task such as classifying and sum-
marizing the reviews as positive and negative
based on different features. The completeness of
</bodyText>
<figureCaption confidence="0.85421825">
lexicons is very important for the feature-based
opinion mining. To collect more lexicons, pat-
terns are used in the dual pattern extraction pro-
cess to extract more features and polar words
from the untagged corpus.
Figure 1: The proposed opinion resource con-
struction framework based on the dual pattern
extraction.
</figureCaption>
<sectionHeader confidence="0.980799" genericHeader="method">
4 A case study of hotel reviews
</sectionHeader>
<bodyText confidence="0.999818142857143">
To evaluate the proposed framework, we per-
form some experiments with a case study of
hotel reviews. In Thailand, tourism is ranked
as one of the top industries. From the statis-
tics provided by the Office of Tourism Develop-
ment1, the number of international tourists vis-
iting Thailand in 2009 is approximately 14 mil-
</bodyText>
<footnote confidence="0.9868855">
1The Office of Tourism Development,
http://www.tourism.go.th
</footnote>
<page confidence="0.999604">
67
</page>
<bodyText confidence="0.999944">
lions. The number of registered hotels in all re-
gions of Thailand is approximately 5,000. Pro-
viding an opinion mining system on hotel re-
views could be very useful for tourists to make
decision on hotel choice when planning a trip.
</bodyText>
<subsectionHeader confidence="0.997307">
4.1 Corpus preparation
</subsectionHeader>
<bodyText confidence="0.999967128205128">
We collected customer reviews from the Agoda
website2. The total number of reviews in the cor-
pus is 8,436. Each review contains the name of
the hotel as the title and comments in free-form
text format. We designed a set of 13 main fea-
tures: service, cleanliness, hotel condition, loca-
tion, food, breakfast, room, facilities, price, com-
fort, quality, activities and security. The set of
main features is designed based on the features
obtained from the Agoda website. Some addi-
tional features, such as activities and security, are
added to provide users with more dimensions.
In this paper, we focus on two main fea-
tures: breakfast and service. Table 2 shows the
domain-dependent lexicons related to the break-
fast feature. For breakfast main feature (FEA),
we include all synonyms which could be used to
describe breakfast in Thai. These include En-
glish terms with their synonyms, transliterated
terms and abbreviations.
The breakfast sub-features (FEA*) are spe-
cific concepts of breakfast. Examples include
“menu”, “taste”, “service” and “coffee”. It can
be observed that some of the sub-features could
also act as a main feature. For example, the
sub-feature “service” of breakfast is also used
as the main feature “service”. Providing sub-
feature level could help revealing more insight-
ful dimension for the users. However, designing
multiple feature levels could be time-consuming,
therefore, we limit the features into two levels,
i.e., main feature and sub-feature. The polar
words (POL) are also shown in the table. We
denote the positive and negative polar words by
placing [+] and [-] after each word. It can be
observed that some polar words are dependent
on sub-features. For example, the polar word
“long line” can only be used for the sub-feature
“restaurant”.
</bodyText>
<footnote confidence="0.983347">
2Agoda website: http://www.agoda.com
</footnote>
<tableCaption confidence="0.9429935">
Table 2: Domain-dependent lexicons for the
breakfast feature.
</tableCaption>
<bodyText confidence="0.977213071428571">
Table 3 shows the domain-dependent lexicons
related to the service feature. The main fea-
tures include synonyms, transliterated and En-
glish terms which describe the concept service.
The service sub-features are, for example, “re-
ception”, “security guard”, “maid”, “waiter” and
“concierge”. Unlike the breakfast feature, the
polar words for the service feature are quite gen-
eral and could mostly be applied for all sub-
features. Another observation is that some of the
polar words are based on Thai idiom. For ex-
ample, the phrase “having rigid hands” in Thai
means “impolite”. In Thai culture, people show
politeness by doing the “wai” gesture.
</bodyText>
<subsectionHeader confidence="0.991941">
4.2 Experiments and results
</subsectionHeader>
<bodyText confidence="0.999535846153846">
Using the tagged corpus and the extracted lexi-
cons, we construct the most frequently occurred
patterns. For two main features, breakfast and
service, the numbers of tagged reviews for each
feature are 301 and 831, respectively. We ran-
domly split the corpus into 80% as training set
and 20% as test set. We only consider the pat-
terns which contain both features (either main
features or sub-features) and polar words. For
the breakfast feature, the total number of ex-
tracted patterns is 86. For the service feature, the
total number of extracted patterns is 192. Table
4 and 5 show some examples of most frequently
</bodyText>
<page confidence="0.999565">
68
</page>
<tableCaption confidence="0.966905">
Table 4: Top-ranked breakfast patterns with ex-
amples
Table 3: Domain-dependent lexicons for the ser-
vice feature.
</tableCaption>
<bodyText confidence="0.998545034482759">
occurred patterns extracted from the corpus. The
symbols of the tag set are as shown in Table 1
and 2 with the tag &lt;OTH&gt; denoting any other
words.
From the tables, two patterns which occur fre-
quently for both features are &lt;FEA&gt;&lt;POL&gt;
and &lt;FEA*&gt;&lt;POL&gt;. These two patterns are
very simple and show that the opinionated texts
in Thai are mostly very simple. Users just simply
write a word describing the feature followed by
a polar word (either positive or negative) with-
out using any verb in between. Some examples
for the pattern &lt;FEA*&gt;&lt;POL&gt; are &lt;coffee
cup&gt;&lt;dirty&gt; and &lt;employee&gt;&lt;friendly&gt;. In
English, a verb “to be” (is/am/are) is usually re-
quired between &lt;FEA*&gt; and &lt;POL&gt;.
Using the extracted patterns, we perform the
dual pattern extraction process to collect the
sub-features and polar words from the test data
set. Table 6 shows the evaluation results of
sub-features and polar words extraction for both
breakfast and service features. It can be observed
that the set of patterns could extract polar words
(POL) with higher accuracy than sub-features
(FEA*). This could be due to the patterns used to
describe the polar words are straightforward and
not complicated. This is especially true for the
case of breakfast feature in which the accuracy
is approximately 95%.
</bodyText>
<tableCaption confidence="0.792054">
Table 5: Top-ranked service patterns with exam-
ples
</tableCaption>
<subsectionHeader confidence="0.982158">
4.3 Discussion
</subsectionHeader>
<bodyText confidence="0.900979">
Table 7 and 8 show some examples of challeng-
ing cases for breakfast and service features, re-
spectively. The polar words shown in both tables
are very difficult to extract since the patterns can
</bodyText>
<page confidence="0.995262">
69
</page>
<table confidence="0.9901445">
Feature Accuracy (%)
FEA* POL
Breakfast 80.00 95.74
Service 82.56 89.29
</table>
<tableCaption confidence="0.9609475">
Table 6: Evaluation results of features and polar
words extraction.
</tableCaption>
<bodyText confidence="0.997497090909091">
not be easily captured. The difficulties are due to
many reasons including the language semantic
and the need of world knowledge. For example,
in case #5 of service feature, the whole phrase
can be interpreted as “attentive”. It is difficult
for the system to generate the pattern based on
this phrase. Another example is case #4 of both
tables, the customers express their opinions by
comparing to other hotels. To analyze the senti-
ment correctly would require the knowledge of a
particular hotel or hotels in specific locations.
</bodyText>
<tableCaption confidence="0.867832333333333">
Table 7: Examples of difficult cases of breakfast
feature
Table 8: Examples of difficult cases of service
</tableCaption>
<bodyText confidence="0.98250055">
feature
was done with a collection of hotel reviews ob-
tained from a hotel reservation website. From
the experimental results, polar words could be
extracted more easily than sub-features. This
is due to the polar words often appear in spe-
cific positions with repeated contexts in the opin-
ionated texts. In some cases, extraction of sub-
features and polar words are not straightforward
due to the difficulties in generalizing patterns.
For example, some subjectivity requires com-
plete phrases to describe the polarity. In some
cases, the sub-features are not explicitly shown
in the sentence. For future work, we plan to com-
plete the construction of the corpus by consider-
ing the rest of main features. Another plan is to
include the semantic analysis into the pattern ex-
traction process. For example, the phrase “forget
something” could imply negative polarity for the
service feature.
</bodyText>
<sectionHeader confidence="0.974185" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.9999871">
We proposed a framework for constructing Thai
opinion mining resource with a case study on
hotel reviews. Two sets of lexicons, domain-
dependent and domain-independent, are de-
signed to support the pattern extraction process.
The proposed method first constructs a set of pat-
terns from a tagged corpus. The extracted pat-
terns are then used to automatically extract and
collect more sub-features and polars words from
an untagged corpus. The performance evaluation
</bodyText>
<sectionHeader confidence="0.998533" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993687909090909">
Banea, Carmen, Rada Mihalcea, Janyce Wiebe, and
Samer Hassan. 2008. Multilingual subjectivity
analysis using machine translation. Proc. of the
2008 empirical methods in natural language pro-
cessing, 127–135.
Beineke, Philip, Trevor Hastie and Shivakumar
Vaithyanathan. 2004. The sentimental factor: im-
proving review classification via human-provided
information. Proc. of the 42nd Annual Meeting on
Association for Computational Linguistics, 263–
270.
</reference>
<page confidence="0.986684">
70
</page>
<reference confidence="0.999342616161616">
Cooke, J.R. 1992. Thai sentence particles: putting
the puzzle together. Proc. of the The Third Inter-
national Symposium on Language and Linguistics,
1105–1119.
Dave, Kushal, Steve Lawrence and David M. Pen-
nock. 2003. Mining the peanut gallery: opinion
extraction and semantic classification of product
reviews. Proc. of the 12th international confer-
ence on World Wide Web, 519–528.
Ding, Xiaowen, Bing Liu and Philip S. Yu. 2008. A
holistic lexicon-based approach to opinion mining.
Proc. of the int. conf. on web search and web data
mining, 231–240.
Hu, Minqing and Bing Liu. 2004. Mining and sum-
marizing customer reviews. Proc. of the 10th ACM
SIGKDD international conference on Knowledge
discovery and data mining, 168–177.
Jin, Wei, Hung Hay Ho and Rohini K. Srihari. 2009.
OpinionMiner: a novel machine learning system
for web opinion mining and extraction. Proc. of
the 15th ACM SIGKDD, 1195–1204.
Kim, Soo-Min and Eduard Hovy. 2004. Determining
the sentiment of opinions. Proc. of the 20th inter-
national conference on Computational Linguistics,
1367–1373.
Qiu, Guang, Bing Liu, Jiajun Bu, and Chun Chen.
2009. Expanding domain sentiment lexicon
through double propagation. Proc. of the 21st In-
ternational Joint Conferences on Artificial Intelli-
gence, 1199–1204.
Jijkoun, Valentin and Katja Hofmann. 2009. Gener-
ating a non-English subjectivity lexicon: relations
that matter. Proc. of the 12th Conference of the
European Chapter of the Association for Compu-
tational Linguistics, 398–405.
Kanayama, Hiroshi and Tetsuya Nasukawa. 2006.
Fully automatic lexicon expansion for domain-
oriented sentiment analysis. Proc. of the 2006
Conference on Empirical Methods in Natural Lan-
guage Processing, 355–363.
Ku, Lun-Wei and Hsin-Hsi Chen. 2007 Mining opin-
ions from the Web: Beyond relevance retrieval.
Journal of American Society for Information Sci-
ence and Technology, 58(12):1838–1850.
Ku, Lun-Wei, Ting-Hao Huang and Hsin-Hsi Chen.
2009. Using morphological and syntactic struc-
tures for Chinese opinion analysis. Proc. of the
2009 empirical methods in natural language pro-
cessing, 1260–1269.
Liu, Bing, Minqing Hu and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opin-
ions on the Web. Proc. of the 14th World Wide
Web, 342–351.
Pang, Bo, Lillian Lee and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. Proc. of the ACL-
02 conf. on empirical methods in natural language
processing, 79–86.
Popescu, Ana-Maria and Oren Etzioni. 2005. Ex-
tracting product features and opinions from re-
views. Proc. of the conf. on human language tech-
nology and empirical methods in natural language
processing, 339–346.
Riloff, Ellen and Janyce Wiebe. 2003. Learning ex-
traction patterns for subjective expressions. Proc.
of the 2003 conference on empirical methods in
natural language processing, 105–112.
Sarmento, Lu´ıs, Paula Carvalho, M´ario J. Silva, and
Eug´enio de Oliveira. 2009. Automatic creation
of a reference corpus for political opinion min-
ing in user-generated content. Proc. of the 1st
CIKM workshop on topic-sentiment analysis for
mass opinion, 29–36.
Turney, Peter D. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised clas-
sification of reviews. Proc. of the 40th ACL, 417–
424.
Wan, Xiaojun. 2009. Co-training for cross-lingual
sentiment classification. Proc. of the joint conf. of
ACL and IJCNLP, 235–243.
Wiebe, Janyce and Ellen Riloff. 2005. Creating
subjective and objective sentence classifiers from
unannotated texts. Proc. of Conference on Intelli-
gent Text Processing and Computational Linguis-
tics, 486–497.
Wiebe, Janyce, Theresa Wilson and Claire Cardie.
2005. Annotating expressions of opinions and
emotions in language. Language Resources and
Evaluation, 39(2-3):165–210.
Wilson, Theresa, Janyce Wiebe and Paul Hoffmann.
2009. Recognizing contextual polarity: An explo-
ration of features for phrase-level sentiment analy-
sis. Comput. Linguist., 35(3):399–433.
Yu, Hong and Vasileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: separating
facts from opinions and identifying the polarity of
opinion sentences. Proc. of the Conference on Em-
pirical Methods in Natural Language Processing,
129–136.
</reference>
<page confidence="0.999138">
71
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.151025">
<title confidence="0.9962605">Constructing Thai Opinion Mining A Case Study on Hotel Reviews</title>
<author confidence="0.675985">Choochart Haruechaiyasak</author>
<author confidence="0.675985">Alisa</author>
<affiliation confidence="0.782576666666667">Palingoon Human Language Technology Laboratory National Electronics and Computer Technology Center (NECTEC)</affiliation>
<email confidence="0.584344">choochart.har@nectec.or.th,pornpimon.pal@nectec.or.th,chatchawal.san@nectec.or.th</email>
<abstract confidence="0.999837703703704">Opinion mining and sentiment analysis has recently gained increasing attention among the NLP community. Opinion mining is considered a domaindependent task. Constructing lexicons for different domains is labor intensive. In this paper, we propose a framework for constructing Thai language resource mining. The feature-based opinion mining essentially relies on the use of two main lexicons, Our approach for extracting features and polar words from opinionated texts is based on syntactic pattern analysis. The evaluation is performed with a case study on hotel reviews. The proposed method has shown to be very effective in most cases. However, in some cases, the extraction is not quite straightforward. The reasons are due to, firstly, the use of conversational language in written opinionated texts and, secondly, the language semantic. We provide discussion with possible solutions on pattern extraction for some of the challenging cases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
<author>Janyce Wiebe</author>
<author>Samer Hassan</author>
</authors>
<title>Multilingual subjectivity analysis using machine translation.</title>
<date>2008</date>
<booktitle>Proc. of the 2008 empirical methods in natural language processing,</booktitle>
<pages>127--135</pages>
<marker>Banea, Mihalcea, Wiebe, Hassan, 2008</marker>
<rawString>Banea, Carmen, Rada Mihalcea, Janyce Wiebe, and Samer Hassan. 2008. Multilingual subjectivity analysis using machine translation. Proc. of the 2008 empirical methods in natural language processing, 127–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Beineke</author>
<author>Trevor Hastie</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>The sentimental factor: improving review classification via human-provided information.</title>
<date>2004</date>
<booktitle>Proc. of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="2339" citStr="Beineke et al., 2004" startWordPosition="341" endWordPosition="344">y useful information regarding the preferences of people towards many different topics including news events, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of an object, topic or event from each sentence upon which the r</context>
</contexts>
<marker>Beineke, Hastie, Vaithyanathan, 2004</marker>
<rawString>Beineke, Philip, Trevor Hastie and Shivakumar Vaithyanathan. 2004. The sentimental factor: improving review classification via human-provided information. Proc. of the 42nd Annual Meeting on Association for Computational Linguistics, 263– 270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Cooke</author>
</authors>
<title>Thai sentence particles: putting the puzzle together.</title>
<date>1992</date>
<booktitle>Proc. of the The Third International Symposium on Language and Linguistics,</booktitle>
<pages>1105--1119</pages>
<contexts>
<context position="11256" citStr="Cooke, 1992" startWordPosition="1723" endWordPosition="1724">erally considered positive for the screen size feature of digital camera domain. However, for the dimension feature of mobile phone domain, the word “large” could be considered as negative. On the other hand, the domain-independent lexicons are regular words which provide different parts of speech (POS) and functions in the sentence. For opinion mining task, we design six different domain-independent lexicons as follows (some examples are shown in Table 1). • Particles (PAR): In Thai language, these words refer to the sentence endings which are normally used to add politeness of the speakers (Cooke, 1992). • Negative words (NEG): Like English, these words are used to invert the opinion polarity. Examples are “not”, “unlikely” and “never”. • Degree words (DEG): These words are used as an intensifier to the polar words. Examples are “large”, “very”, “enormous”. 66 • Auxiliary verbs (AUX): These words are used to modify verbs. Examples are “should”, “must” and “then”. • Prepositions (PRE): Like English, Thai prepositions are used to mark the relations between two words. • Stop words (STO): These words are used for grammaticalization. Thai language is considered an isolating language, to form a no</context>
</contexts>
<marker>Cooke, 1992</marker>
<rawString>Cooke, J.R. 1992. Thai sentence particles: putting the puzzle together. Proc. of the The Third International Symposium on Language and Linguistics, 1105–1119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kushal Dave</author>
<author>Steve Lawrence</author>
<author>David M Pennock</author>
</authors>
<title>Mining the peanut gallery: opinion extraction and semantic classification of product reviews.</title>
<date>2003</date>
<booktitle>Proc. of the 12th international conference on World Wide Web,</booktitle>
<pages>519--528</pages>
<contexts>
<context position="2316" citStr="Dave et al., 2003" startWordPosition="337" endWordPosition="340">d reveal potentially useful information regarding the preferences of people towards many different topics including news events, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of an object, topic or event from each se</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Dave, Kushal, Steve Lawrence and David M. Pennock. 2003. Mining the peanut gallery: opinion extraction and semantic classification of product reviews. Proc. of the 12th international conference on World Wide Web, 519–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>Proc. of the int. conf. on</booktitle>
<pages>231--240</pages>
<contexts>
<context position="2132" citStr="Ding et al., 2008" startWordPosition="303" endWordPosition="306">ponentially. One interesting type of these user-generated contents is texts which are written with some opinions and/or sentiments. An in-depth analysis of these opinionated texts could reveal potentially useful information regarding the preferences of people towards many different topics including news events, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed </context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Ding, Xiaowen, Bing Liu and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. Proc. of the int. conf. on web search and web data mining, 231–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>Proc. of the 10th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="2749" citStr="Hu and Liu, 2004" startWordPosition="411" endWordPosition="414"> Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of an object, topic or event from each sentence upon which the reviewers expressed their opinion. 2. Determining whether the opinions regarding the features are positive or negative. The feature-based opinion mining could provide users with some insightful information related to opinions on a particular topic. For example, for hotel reviews, the feature-based opinion 64 Proceedings of the 8th Workshop on Asian Language Resources, pages 64–71, Beijing, China, 21-22 Augus</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Hu, Minqing and Bing Liu. 2004. Mining and summarizing customer reviews. Proc. of the 10th ACM SIGKDD international conference on Knowledge discovery and data mining, 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
<author>Rohini K Srihari</author>
</authors>
<title>OpinionMiner: a novel machine learning system for web opinion mining and extraction.</title>
<date>2009</date>
<booktitle>Proc. of the 15th ACM SIGKDD,</booktitle>
<pages>1195--1204</pages>
<contexts>
<context position="2151" citStr="Jin et al., 2009" startWordPosition="307" endWordPosition="310">teresting type of these user-generated contents is texts which are written with some opinions and/or sentiments. An in-depth analysis of these opinionated texts could reveal potentially useful information regarding the preferences of people towards many different topics including news events, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; </context>
</contexts>
<marker>Jin, Ho, Srihari, 2009</marker>
<rawString>Jin, Wei, Hung Hay Ho and Rohini K. Srihari. 2009. OpinionMiner: a novel machine learning system for web opinion mining and extraction. Proc. of the 15th ACM SIGKDD, 1195–1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>Proc. of the 20th international conference on Computational Linguistics,</booktitle>
<pages>1367--1373</pages>
<contexts>
<context position="2377" citStr="Kim and Hovy, 2004" startWordPosition="348" endWordPosition="351">ences of people towards many different topics including news events, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of an object, topic or event from each sentence upon which the reviewers expressed their opinion. 2. D</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Kim, Soo-Min and Eduard Hovy. 2004. Determining the sentiment of opinions. Proc. of the 20th international conference on Computational Linguistics, 1367–1373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Expanding domain sentiment lexicon through double propagation.</title>
<date>2009</date>
<booktitle>Proc. of the 21st International Joint Conferences on Artificial Intelligence,</booktitle>
<pages>1199--1204</pages>
<contexts>
<context position="4407" citStr="Qiu et al., 2009" startWordPosition="665" endWordPosition="668">ide full facilities, however, some might prefer to have good room service. The main drawback of the feature-based opinion mining is the preparation of different lexicons including features and polar words. To make things worse, these lexicons, especially the features, are domain-dependent. For a particular domain, a set of features and polar words must be prepared. The process for language resource construction is generally labor intensive and time consuming. Some previous works have proposed different approaches for automatically constructing the lexicons for the featurebased opinion mining (Qiu et al., 2009; Riloff and Wiebe, 2003; Sarmento et al., 2009). Most approaches applied some machine learning algorithms for learning the rules from the corpus. The rules are used for extracting new features and polar words from untagged corpus. Reviews of different approaches are given in the related work section. In this paper, we propose a framework for constructing Thai language resource for the feature-based opinion mining. Our approach is based on syntactic pattern analysis of two lexicon types: domain-dependent and domainindependent. The domain-dependent lexicons include features, sub-features and po</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>Qiu, Guang, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding domain sentiment lexicon through double propagation. Proc. of the 21st International Joint Conferences on Artificial Intelligence, 1199–1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
<author>Katja Hofmann</author>
</authors>
<title>Generating a non-English subjectivity lexicon: relations that matter.</title>
<date>2009</date>
<booktitle>Proc. of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>398--405</pages>
<contexts>
<context position="8978" citStr="Jijkoun and Hofmann (2009)" startWordPosition="1366" endWordPosition="1369">jectivity analysis for a foreign language have leveraged the resources and tools available for English. For example, Benea et al. (2008) applied machine translation and standard Naive Bayes and SVM for subjectivity classification for Romanian. Their experiments showed promising results for applying automatic translation to construct resources and tools for opinion mining in a foreign language. Wan (2009) also leveraged an available English corpus for Chinese sentiment classification by using the co-training approach to make full use of both English and Chinese features in a unified framework. Jijkoun and Hofmann (2009) also described a method for creating a Dutch subjectivity lexicon based on an English lexicon. They applied a PageRank-like algorithm that bootstraps a subjectivity lexicon from the translation of the English lexicon and rank the words in the thesaurus by polarity using the network of lexical relations (e.g., synonymy, hyponymy) in Wordnet. 3 The proposed framework The performance of the feature-based opinion mining relies on the design and completeness of related lexicons. Our lexicon design distinguishes lexicons into two types, domaindependent and domain-independent. The design of domain-d</context>
</contexts>
<marker>Jijkoun, Hofmann, 2009</marker>
<rawString>Jijkoun, Valentin and Katja Hofmann. 2009. Generating a non-English subjectivity lexicon: relations that matter. Proc. of the 12th Conference of the European Chapter of the Association for Computational Linguistics, 398–405.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Fully automatic lexicon expansion for domainoriented sentiment analysis.</title>
<date>2006</date>
<booktitle>Proc. of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>355--363</pages>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>Kanayama, Hiroshi and Tetsuya Nasukawa. 2006. Fully automatic lexicon expansion for domainoriented sentiment analysis. Proc. of the 2006 Conference on Empirical Methods in Natural Language Processing, 355–363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lun-Wei Ku</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Mining opinions from the Web: Beyond relevance retrieval.</title>
<date>2007</date>
<journal>Journal of American Society for Information Science and Technology,</journal>
<volume>58</volume>
<issue>12</issue>
<contexts>
<context position="7763" citStr="Ku and Chen (2007)" startWordPosition="1188" endWordPosition="1191"> languages is growing as well. Kanayama et al. (2006) proposed an unsupervised method to detect sentiment words in Japanese. In this work, they used clause level context coherency to identify candidate sentiment words from sentences that appear successively with sentences containing seed sentiment words. Their assumption is that unless the context is changed with adversative expressions, sentences appearing together 65 in that context tend to have the same polarities. Hence, if one of them contains sentiments words, the other successive sentences are likely to contain sentiment words as well. Ku and Chen (2007) proposed the bag-of-characters approach to determine sentiment words in Chinese. This approach calculates the observation probabilities of characters from a set of seed sentiment words first, then dynamically expands the set and adjusts their probabilities. Later in 2009, Ku et al. (2009), extended their bag-of-characters approach by including morphological structures and syntactic structures between sentence segment. Their experiments showed better performance of word polarity detection and opinion sentence extraction. Some other methods to automatically generate resources for subjectivity a</context>
</contexts>
<marker>Ku, Chen, 2007</marker>
<rawString>Ku, Lun-Wei and Hsin-Hsi Chen. 2007 Mining opinions from the Web: Beyond relevance retrieval. Journal of American Society for Information Science and Technology, 58(12):1838–1850.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lun-Wei Ku</author>
<author>Ting-Hao Huang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Using morphological and syntactic structures for Chinese opinion analysis.</title>
<date>2009</date>
<booktitle>Proc. of the 2009 empirical methods in natural language processing,</booktitle>
<pages>1260--1269</pages>
<contexts>
<context position="8053" citStr="Ku et al. (2009)" startWordPosition="1232" endWordPosition="1235">timent words. Their assumption is that unless the context is changed with adversative expressions, sentences appearing together 65 in that context tend to have the same polarities. Hence, if one of them contains sentiments words, the other successive sentences are likely to contain sentiment words as well. Ku and Chen (2007) proposed the bag-of-characters approach to determine sentiment words in Chinese. This approach calculates the observation probabilities of characters from a set of seed sentiment words first, then dynamically expands the set and adjusts their probabilities. Later in 2009, Ku et al. (2009), extended their bag-of-characters approach by including morphological structures and syntactic structures between sentence segment. Their experiments showed better performance of word polarity detection and opinion sentence extraction. Some other methods to automatically generate resources for subjectivity analysis for a foreign language have leveraged the resources and tools available for English. For example, Benea et al. (2008) applied machine translation and standard Naive Bayes and SVM for subjectivity classification for Romanian. Their experiments showed promising results for applying a</context>
</contexts>
<marker>Ku, Huang, Chen, 2009</marker>
<rawString>Ku, Lun-Wei, Ting-Hao Huang and Hsin-Hsi Chen. 2009. Using morphological and syntactic structures for Chinese opinion analysis. Proc. of the 2009 empirical methods in natural language processing, 1260–1269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the Web.</title>
<date>2005</date>
<booktitle>Proc. of the 14th World Wide Web,</booktitle>
<pages>342--351</pages>
<contexts>
<context position="9680" citStr="Liu et al. (2005)" startWordPosition="1474" endWordPosition="1477">h lexicon. They applied a PageRank-like algorithm that bootstraps a subjectivity lexicon from the translation of the English lexicon and rank the words in the thesaurus by polarity using the network of lexical relations (e.g., synonymy, hyponymy) in Wordnet. 3 The proposed framework The performance of the feature-based opinion mining relies on the design and completeness of related lexicons. Our lexicon design distinguishes lexicons into two types, domaindependent and domain-independent. The design of domain-dependent lexicons is based on the feature-based opinion mining framework proposed by Liu et al. (2005). The framework starts by setting the domain scope such as digital camera. The next step is to design a set of features associated with the given domain. For the domain of digital camera, features could be, for instance, “price”, “screen size” and “picture quality”. Features could contain sub-features. For example, the picture quality could have the subfeatures as “macro mode”, “portrait mode” and “night mode”. Preparing multiple feature levels could be time-consuming, therefore, we limit the features into two levels: main features and subfeatures. Another domain-dependent lexicon is polar wor</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Liu, Bing, Minqing Hu and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the Web. Proc. of the 14th World Wide Web, 342–351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>Proc. of the ACL02 conf. on empirical methods in natural language processing,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="2297" citStr="Pang et al., 2002" startWordPosition="333" endWordPosition="336">nionated texts could reveal potentially useful information regarding the preferences of people towards many different topics including news events, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of an object, topic or</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Pang, Bo, Lillian Lee and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. Proc. of the ACL02 conf. on empirical methods in natural language processing, 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>Proc. of the conf. on human language technology and empirical methods in natural language processing,</booktitle>
<pages>339--346</pages>
<contexts>
<context position="2777" citStr="Popescu and Etzioni, 2005" startWordPosition="415" endWordPosition="418">. Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of an object, topic or event from each sentence upon which the reviewers expressed their opinion. 2. Determining whether the opinions regarding the features are positive or negative. The feature-based opinion mining could provide users with some insightful information related to opinions on a particular topic. For example, for hotel reviews, the feature-based opinion 64 Proceedings of the 8th Workshop on Asian Language Resources, pages 64–71, Beijing, China, 21-22 August 2010. c�2010 Asian Federat</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Popescu, Ana-Maria and Oren Etzioni. 2005. Extracting product features and opinions from reviews. Proc. of the conf. on human language technology and empirical methods in natural language processing, 339–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>Proc. of the 2003 conference on empirical methods in natural language processing,</booktitle>
<pages>105--112</pages>
<contexts>
<context position="4431" citStr="Riloff and Wiebe, 2003" startWordPosition="669" endWordPosition="672">s, however, some might prefer to have good room service. The main drawback of the feature-based opinion mining is the preparation of different lexicons including features and polar words. To make things worse, these lexicons, especially the features, are domain-dependent. For a particular domain, a set of features and polar words must be prepared. The process for language resource construction is generally labor intensive and time consuming. Some previous works have proposed different approaches for automatically constructing the lexicons for the featurebased opinion mining (Qiu et al., 2009; Riloff and Wiebe, 2003; Sarmento et al., 2009). Most approaches applied some machine learning algorithms for learning the rules from the corpus. The rules are used for extracting new features and polar words from untagged corpus. Reviews of different approaches are given in the related work section. In this paper, we propose a framework for constructing Thai language resource for the feature-based opinion mining. Our approach is based on syntactic pattern analysis of two lexicon types: domain-dependent and domainindependent. The domain-dependent lexicons include features, sub-features and polar words. The domain-in</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Riloff, Ellen and Janyce Wiebe. 2003. Learning extraction patterns for subjective expressions. Proc. of the 2003 conference on empirical methods in natural language processing, 105–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu´ıs Sarmento</author>
<author>Paula Carvalho</author>
<author>M´ario J Silva</author>
<author>Eug´enio de Oliveira</author>
</authors>
<title>Automatic creation of a reference corpus for political opinion mining in user-generated content.</title>
<date>2009</date>
<booktitle>Proc. of the 1st CIKM workshop on topic-sentiment analysis for mass opinion,</booktitle>
<pages>29--36</pages>
<marker>Sarmento, Carvalho, Silva, de Oliveira, 2009</marker>
<rawString>Sarmento, Lu´ıs, Paula Carvalho, M´ario J. Silva, and Eug´enio de Oliveira. 2009. Automatic creation of a reference corpus for political opinion mining in user-generated content. Proc. of the 1st CIKM workshop on topic-sentiment analysis for mass opinion, 29–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>Proc. of the 40th ACL, 417–</booktitle>
<pages>424</pages>
<contexts>
<context position="2278" citStr="Turney, 2002" startWordPosition="331" endWordPosition="332">s of these opinionated texts could reveal potentially useful information regarding the preferences of people towards many different topics including news events, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of </context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Turney, Peter D. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews. Proc. of the 40th ACL, 417– 424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
</authors>
<title>Co-training for cross-lingual sentiment classification.</title>
<date>2009</date>
<booktitle>Proc. of the joint conf. of ACL and IJCNLP,</booktitle>
<pages>235--243</pages>
<contexts>
<context position="8759" citStr="Wan (2009)" startWordPosition="1334" endWordPosition="1335">structures between sentence segment. Their experiments showed better performance of word polarity detection and opinion sentence extraction. Some other methods to automatically generate resources for subjectivity analysis for a foreign language have leveraged the resources and tools available for English. For example, Benea et al. (2008) applied machine translation and standard Naive Bayes and SVM for subjectivity classification for Romanian. Their experiments showed promising results for applying automatic translation to construct resources and tools for opinion mining in a foreign language. Wan (2009) also leveraged an available English corpus for Chinese sentiment classification by using the co-training approach to make full use of both English and Chinese features in a unified framework. Jijkoun and Hofmann (2009) also described a method for creating a Dutch subjectivity lexicon based on an English lexicon. They applied a PageRank-like algorithm that bootstraps a subjectivity lexicon from the translation of the English lexicon and rank the words in the thesaurus by polarity using the network of lexical relations (e.g., synonymy, hyponymy) in Wordnet. 3 The proposed framework The performa</context>
</contexts>
<marker>Wan, 2009</marker>
<rawString>Wan, Xiaojun. 2009. Co-training for cross-lingual sentiment classification. Proc. of the joint conf. of ACL and IJCNLP, 235–243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Ellen Riloff</author>
</authors>
<title>Creating subjective and objective sentence classifiers from unannotated texts.</title>
<date>2005</date>
<booktitle>Proc. of Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<pages>486--497</pages>
<contexts>
<context position="2401" citStr="Wiebe and Riloff, 2005" startWordPosition="352" endWordPosition="355">rds many different topics including news events, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of an object, topic or event from each sentence upon which the reviewers expressed their opinion. 2. Determining whether the o</context>
</contexts>
<marker>Wiebe, Riloff, 2005</marker>
<rawString>Wiebe, Janyce and Ellen Riloff. 2005. Creating subjective and objective sentence classifiers from unannotated texts. Proc. of Conference on Intelligent Text Processing and Computational Linguistics, 486–497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language. Language Resources and Evaluation,</title>
<date>2005</date>
<pages>39--2</pages>
<contexts>
<context position="6689" citStr="Wiebe et al., 2005" startWordPosition="1020" endWordPosition="1023">ning resource by using the dual pattern extraction method. In Section 4, we apply the proposed framework with a case study of hotel reviews. The performance evaluation is given with the experiment results. Some difficult cases are discussed along with some possible solutions. Section 5 concludes the paper with the future work. 2 Related work The problem of developing subjectivity lexicons for training and testing sentiment classifiers has recently attracted some attention. The Multiperspective Question Answering (MPQA) opinion corpus is a well-known resource for sentiment analysis in English (Wiebe et al., 2005). It is a collection of news articles from a variety of news sources manually annotated at word and phrase levels for opinions and other private states (i.e., beliefs, emotions, sentiments, speculations, etc.). The annotation in this work also took into account the context, which is essential for resolving possible ambiguities and accurately determining polarity. Although most of the reference corpora has been focused on English language, work on other languages is growing as well. Kanayama et al. (2006) proposed an unsupervised method to detect sentiment words in Japanese. In this work, they </context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Wiebe, Janyce, Theresa Wilson and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation, 39(2-3):165–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis.</title>
<date>2009</date>
<journal>Comput. Linguist.,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="2422" citStr="Wilson et al., 2009" startWordPosition="356" endWordPosition="359">s including news events, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of an object, topic or event from each sentence upon which the reviewers expressed their opinion. 2. Determining whether the opinions regarding the</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2009</marker>
<rawString>Wilson, Theresa, Janyce Wiebe and Paul Hoffmann. 2009. Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis. Comput. Linguist., 35(3):399–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>Proc. of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>129--136</pages>
<contexts>
<context position="2454" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="360" endWordPosition="363">ts, social issues and commercial products. Opinion mining and sentiment analysis is such task for analyzing and summarizing what people think about a certain topic. Due to its potential and useful applications, opinion mining has gained a lot of interest in text mining and NLP communities (Ding et al., 2008; Jin et al., 2009). Much work in this area focused on evaluating reviews as being positive or negative either at the document level (Turney, 2002; Pang et al., 2002; Dave et al., 2003; Beineke et al., 2004) or sentence level (Kim and Hovy, 2004; Wiebe and Riloff, 2005; Wilson et al., 2009; Yu and Hatzivassiloglou, 2003). For instance, given some reviews of a product, the system classifies them into positive or negative reviews. No specific details or features are identified about what customers like or dislike. To obtain such details, a feature-based opinion mining approach has been proposed (Hu and Liu, 2004; Popescu and Etzioni, 2005). This approach typically consists of two following steps. 1. Identifying and extracting features of an object, topic or event from each sentence upon which the reviewers expressed their opinion. 2. Determining whether the opinions regarding the features are positive or negati</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Yu, Hong and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: separating facts from opinions and identifying the polarity of opinion sentences. Proc. of the Conference on Empirical Methods in Natural Language Processing, 129–136.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>