<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.948609">
COMBINATORY CATEGORIAL GRAMMARS: GENERATIVE POWER AND
RELATIONSHIP TO LINEAR CONTEXT-FREE REWRITING SYSTEMS*
David J. Weir Aravind K. Joshi
</note>
<affiliation confidence="0.6798855">
Department of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.25208">
Philadelphia, PA 19104-6389
</address>
<sectionHeader confidence="0.968102" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999692583333334">
Recent results have established that there is a family of
languages that is exactly the class of languages generated
by three independently developed grammar formalisms:
Tree Adjoining Grammars, Head Grammars, and Linear
Indexed Grammars. In this paper we show that Combina-
tory Categorial Grammars also generates the same class
of languages. We discuss the structural descriptions pro-
duced by Combinatory Categorial Grammars and com-
pare them to those of grammar formalisms in the class of
Linear Context-Free Rewriting Systems. We also discuss
certain extensions of Combinatory Categorial Grammars
and their effect on the weak generative capacity.
</bodyText>
<sectionHeader confidence="0.999092" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999944">
There have been a number of results concerning the rela-
tionship between the weak generative capacity (family of
string languages) associated with different grammar for-
malisms; for example, the theorem of Gaifman, et al. [3]
that Classical Categorial Grammars are weakly equivalent
to Context-Free Grammars (CFG&apos;s). More recently it has
been found that there is a class of languages slightly larger
than the class of Context-Free languages that.is generated
by several different formalisms. In particular, Tree Ad-
joining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s)
have been shown to be weakly equivalent [15], and these
formalism are also equivalent to a restriction of Indexed
Grammars considered by Gazdar [6] called Linear In-
dexed Grammars (110&apos;s) [13].
In this paper, we examine Combinatory Categorial
Grammars (CCG&apos;s), an extension of Classical Catego-
rial Grammars developed by Steedman and his collab-
orators [1,12,9,10,111. The main result in this paper is
</bodyText>
<note confidence="0.57381825">
&apos;This work was partially supported by NSF grants MCS-82-19116-
CER. MCS-82-07294, DCR-84-10413, ARO grant DAA29434-9-0027,
and DARPA grant N0014435-K0018. We are very grateful to Mark
Steedman, K. Vijay-Shanker and Remo Pareschi for helpful discussions.
</note>
<bodyText confidence="0.999825025641026">
that CCG&apos;s are weakly equivalent to TAG&apos;s, HG&apos;s, and
LIG&apos;s. We prove this by showing in Section 3 that Com-
binatory Categorial Languages (CCL&apos;s) are included in
Linear Indexed Languages (LIL&apos;s), and that Tree Adjoin-
ing Languages (TAL&apos;s) are included in CCL&apos;s.
After considering their weak generative capacity, we
investigate the relationship between the structural descrip-
tions produced by CCG&apos;s and those of other grammar for-
malisms. In [14] a number of grammar formalisms were
compared and it was suggested that an important aspect
of their descriptive capacity was reflected by the deriva-
tion structures that they produced. Several formalisms
that had previously been described as mildly context-
sensitive were found to share a number of properties. In
particular, the derivations of a grammar could be repre-
sented with trees that always formed the tree set of a
context-free grammar. Formalisms that share these prop-
erties were called Linear Context-Free Rewriting Systems
(LCFRS&apos;s) [14].
On the basis of their weak generative capacity, it ap-
pears that CCG&apos;s should be classified as mildly context-
sensitive. In Section 4 we consider whether CCG&apos;s should
be included in the class of LCFRS&apos;s. The derivation tree
sets traditionally associated with CCG&apos;s have Context-free
path sets, and are similar to those of LIG&apos;s, and therefore
differ from those of LCFRS&apos;s. This does not, however,
rule out the possibility that there may be alternative ways
of representing the derivation of CCG&apos;s that will allow
for their classification as LCFRS&apos;s.
Extensions to CCG&apos;s have been considered that enable
them to compare two unbounded structures (for example,
in [12]). It has been argued that this may be needed in
the analysis of certain coordination phenomena in Dutch.
In Section 5 we discuss how these additional features
increase the power of the formalism. In so doing, we
also give an example demonstrating that the Parenthesis-
free Categorial Grammar formalism [5,4] is more pow-
erful that CCG&apos;s as defined here. Extensions to TAG&apos;s
(Multicomponent TAG) have been considered for similar
</bodyText>
<page confidence="0.995009">
278
</page>
<bodyText confidence="0.983588142857143">
Restrictions can be associated with the use of the com-
binatory rule in R. These restrictions take the form of
constraints on the instantiations of variables in the rules.
These can be constrained in two ways.
reasons. However, in this paper, we will not investigate
the relationship between the extension of CCG&apos;s and Mul-
ticomponent TAG.
</bodyText>
<sectionHeader confidence="0.717805" genericHeader="method">
2 Description of Formalisms
</sectionHeader>
<bodyText confidence="0.991541666666667">
In this section we describe Combinatory Categorial Gram-
mars, Tree Adjoining Grammars, and Linear Indexed
Grammars.
</bodyText>
<subsectionHeader confidence="0.981254">
2.1 Combinatory Categorial Grammars
</subsectionHeader>
<bodyText confidence="0.822958">
Combinatory Categorial Grammar (CCG), as defined here,
is the most recent version of a system that has evolved in
a number of papers [1,12,9,10,11].
</bodyText>
<figure confidence="0.7577974">
A CCG, G, is denoted by (VT,VN,S, f,R) where
VT is a finite set of terminals (lexical items),
VN is a finite set of nontenninaLs (atomic categories),
S is a distinguished member of VN,
f is a function that maps elements of VT U {E} to
finite subsets of C(VN), the set of categories&apos;, where
VN C C(VN) and
if c1,c2 E C(VN) then
(Cl/c2) E C(VN) and (ct \c2) E C(VN).
R is a finite set of combinatory rules, described below.
</figure>
<bodyText confidence="0.9963485">
We now give the combinatory rules, where x, y, z are
variables over categories, and each I; denotes either \ or
</bodyText>
<listItem confidence="0.906896">
I.
1. forward application:
(01Y) y
2. backward application:
y (x\y)
3. generalized forward composition for some n &gt; 1:
(x/Y) (• • • (Ylizt)12 • • Inzn)
(• • •(xlizt)I2 • • • Inzn)
4. generalized backward composition for some n &gt; 1:
</listItem>
<equation confidence="0.6283755">
(• • • (YI1Z1)12 • • • InZn) (x\y) --+
(-- • (xlizi)I2 • • Inzn)
</equation>
<bodyText confidence="0.699720333333333">
&apos;Note that f can assign categories to the empty string, 6, though,
to our knowledge, this feature has not been employed in the linguistic
applications of CCG.
</bodyText>
<listItem confidence="0.92228575">
1. The initial nonterminal of the category to which x is
instantiated can be restricted.
2. The entire category to which y is instantiated can be
restricted.
</listItem>
<bodyText confidence="0.891819">
Derivations in a CCG involve the use of the combi-
natory rules in R. Let the derives relation be defined as
follows.
</bodyText>
<equation confidence="0.655662">
acf3 ct acic20
</equation>
<bodyText confidence="0.950343">
if R contains a combinatory rule that has c1c2 c as
an instance, and a and # are (possibly empty) strings of
categories. The string languages, L(G), generated by a
CCG, G, is defined as follows.
</bodyText>
<equation confidence="0.848688">
fai ...an I S .1# c1.••cn,
E f(ai), a; E VT U {E} ,1 &lt; i &lt; n}
</equation>
<bodyText confidence="0.999535">
Although there is no type-raising rule, its effect can be
achieved to a limited extent since f can assign type-raised
categories to lexical items, which is the scheme employed
in Steedman&apos;s recent work.
</bodyText>
<subsectionHeader confidence="0.998979">
2.2 Linear Indexed Grammars
</subsectionHeader>
<bodyText confidence="0.990991888888889">
Linear Indexed Grammars (LIG&apos;s) were introduced by
Gazdar [6], and are a restriction of Indexed Grammars
introduced by Aho [2]. LIG&apos;s can be seen as an exten-
sion of CFG&apos;s in which each nontenninal is associated
with a stack.
An LIG, G, is denoted by G = (VN,VT,VS,S, P) where
VN is a finite set of nontenninals,
VT is a finite set of terminals,
Vs is a finite set of stack symbols,
</bodyText>
<equation confidence="0.9961362">
S E VN is the start symbol, and
P is a finite set of productions, having the form
•—■ a
A[.&apos; -- Ai fl • • • A[..] • • •An[i
AF&apos;i Al0 • • •Ai[- • • •An0
</equation>
<bodyText confidence="0.9881885">
where An E Vii, 1€ Vs, and a€ VT U {E}.
The notation for stacks uses [. 1] to denote an arbi-
trary stack whose top symbol is 1. This system is called
Linear Indexed Grammars because it can be viewed as a
</bodyText>
<page confidence="0.988112">
279
</page>
<bodyText confidence="0.99632375">
restriction of Indexed Grammars in which only one of the
non-terminals on the right-hand-side of a production can
inherit the stack from the left-hand-side.
The derives relation is defined as follows.
</bodyText>
<construct confidence="0.713442">
aA[1„„ .111]13r a•Ain • • • Ai[lm • • • li] • • • AnD5
if 1] Ain . An[] E P
aA[1,n .1]f3 . Ai[1,n .111] . • • An 0/9
if --• A1[].. .A1[. — Ann E P
• aftl[]fl aal3
</construct>
<bodyText confidence="0.672871">
if An a E P
The language, L(G), generated by G is
{w1wE w
</bodyText>
<subsectionHeader confidence="0.761445">
23 Tree Adjoining Grammars
</subsectionHeader>
<bodyText confidence="0.989400482758621">
A TAG [8,7] is denoted G= (VN ,VT ,S,I, A) where
VN is a finite set of nonterminals,
VT is a finite set of terminals,
S is a distinguished nonterminal,
/ is a finite set of initial trees and
A is a finite set of auxiliary trees.
Initial trees are rooted in S with w E Ig on their fron-
tier. Each internal node is labeled by a member of
VN
Auxiliary trees have w1Atv2 E ViWNV4; on their fron-
tier. The node on the frontier labeled A is called
the foot node, and the root is also labeled A. Each
internal node is labeled by a member of VN •
Trees are composed by tree adjunction. When a tree
7&apos; is adjoined at a node ry in a tree -y the tree that results,
-y&amp;quot;, is obtained by excising the subtree under q from 7
and inserting 7&apos; in its place. The excised subtree is then
substituted for the foot node of 7&apos;. This operation is
illustrated in the following figure.
Each node in an auxiliary tree labeled by a nontenninal
is associated with adjoining constraints. These constraints
specify a set of auxiliary trees that can be adjoined at
that node, and may specify that the node has obligatory
adjunction (OA). When no tree can be adjoined at a node
that node has a null adjoining (NA) constraint
The string language L(G) generated by a TAG, G, is
the set of all strings lying on the frontier of some tree that
can be derived from an initial trees with a finite number
of adjtmctions, where that tree has no OA constraints.
</bodyText>
<sectionHeader confidence="0.982142" genericHeader="method">
3 Weak Generative Capacity
</sectionHeader>
<bodyText confidence="0.999940125">
In this section we show that CCG&apos;s are weakly equivalent
to TAG&apos;s, HG&apos;s, and 1.10&apos;s. We do this by showing the
inclusion of CCL&apos;s in L1L&apos;s, and the inclusion of TAL&apos;s in
CCL&apos;s. It is know that TAG and LIG are equivalent [13],
and that TAG and HG are equivalent [15]. Thus, the two
inclusions shown here imply the weak equivalence of all
four systems. We have not included complete details of
the proofs which can be found in [16].
</bodyText>
<subsectionHeader confidence="0.998556">
3.1 CCL&apos;s C L1L&apos;s
</subsectionHeader>
<bodyText confidence="0.953895214285714">
We describe how to construct a LIG, , from an arbi-
trary CCG, G such that G and GI are equivalent. Let
us assume that categories are written without parentheses,
unless they are needed to override the left associativity of
the slashes.
A category c is minimally parenthesized if and
only if one of the following holds.
c = A for A E VN
C = (C011C112 • • • Incn), for n &gt; 1,
where co E VN and each ci is mini-
mally parenthesized.
It will be useful to be able to refer to the components of
a category, c. We first define the immediate components
of c.
</bodyText>
<page confidence="0.961148">
280
</page>
<bodyText confidence="0.989664761904762">
when c = A the immediate component is A,
when c = (colic1i2 • • !nen ) the immediate
components are co, c1,..., en.
The components of a category C are its immediate com-
ponents, as well as the components of its immediate com-
ponents.
Although in CCG&apos;s there is no bound on the number
of categories that are derivable during a derivation (cate-
gories resulting from the use of a combinatory rule), there
is a bound on the number of components that derivable
categories may have. This would no longer hold if unre-
stricted type-raising were allowed during a derivation.
Let the set Dc(G) be defined as follows.
E Dc(G) if c is a component of c&apos; where
c&apos; E f (a) for some a E VT U {e}.
Clearly for any CCG, G, Dc(G) is a finite set. Dc(G)
contains the set of all derivable components because for
every category c that can appear in a sentential form of
a derivation in some CCG, G, each component of c is in
Dc (G). This can be shown, since, for each combinatory
rule, if it holds of the categories on the left of the rule
then it will hold of the category on the right.
Each of the combinatory rules in a CCG can be viewed
as a statement about how a pair of categories can be com-
bined. For the sake of this discussion, let us name the
members of the pair according to their role in the rule.
The first of the pair in forward rules and the second of
the pair in backward rules will be named the primary cate-
gory. The second of the pair in forward rules and the first
of the pair in backward rules will be named the secondary
category.
As a result of the form that combinatory rules can take
in a CCG, they have the following property. When a
combinatory rule is used, there is a bound on the number
of immediate components that the secondary categories of
that rule may have. Thus, because immediate constituents
must belong to Dc(G) (a finite set), there is a bound on
the number of categories that can fill the role of secondary
categories in the use of a combinatory rule. Thus, there is
a bound on the number of instantiations of the variables y
and zi in the combinatory rules in Section 2.1. The only
variable that can be instantiated to an unbounded number
of categories is x. Thus, by enumerating each of the finite
number of variable bindings for y and each z, the number
of combinatory rules in R can be increased in such a way
that only x is needed. Notice that x will appears only
once on each side of the rules (i.e. they are linear).
We are now in a position to describe how to represent
each of the combinatory rules by a production in the LIG,
G&apos;. In the combinatory rules, categories can be viewed
as stacks since symbols need only be added and removed
from the right. The secondary category of each rule will
be a ground category: either A, or (Alicti2 • • Incn), for
some n &gt; 1. These can be represented in a LIG as AO
or An c,i] , respectively. The primary category
in a combinatory rule will be unspecified except for the
identity of its left and rightmost immediate components.
Its leftmost component is a nonterminal, A, and its right-
most component is a member of Dc(G), c. This can be
represented in a LIG by A[•
In addition to mapping combinatory rules onto produc-
tions we must include productions in G&apos; for the mappings
from lexical items.
</bodyText>
<construct confidence="0.86203675">
If c E f(a) where a€ VT U {e} then
if c = A then AO a E P
if c = (Abel 12 • • • lc) then
A[lieilz • • • ken] a E P
</construct>
<bodyText confidence="0.99998">
We are assuming an extension of the notation for produc-
tions that is given in Section 2.2. Rather than adding or
removing a single symbol from the stack, a fixed number
of symbols can be removed and added in one produc-
tion. Furthermore, any of the nonterminals on the right
of productions can be given stacks of some fixed size.
</bodyText>
<subsectionHeader confidence="0.996629">
3.2 TAL&apos;s C CCL&apos;s
</subsectionHeader>
<bodyText confidence="0.999944578947368">
We briefly describe the construction of a CCG, G&apos; from
a TAG, G, such that G and G&apos; are equivalent.
For each nonterminal, A of G there will be two nonter-
minaLs Aa and AC in G&apos;. The nonterminal of G&apos; will also
include a nonterminal Ai for each terminal ai of the TAG.
The terminal alphabets will be the same. The combinatory
rules of G&apos; are as follows.
Forward and backward application are restricted to
cases where the secondary category is some X°, and
the left immediate component of the primary cate-
gory is some ya.
Forward and backward composition are restricted to
cases where the secondary category has the form
(()Cc I )I2e2), and the left immediate component
of the primary category is some Ya.
An effect of the restrictions on the use of combinatory
rules is that only categories that can fill the secondary role
during composition are categories assigned to terminals by
f. Notice that the combinatory rules of G&apos; depend only
</bodyText>
<page confidence="0.992024">
281
</page>
<figure confidence="0.59097775">
5. For each tree of the following form include Aa I Ai E
(c), AC/AE 1(c) and Ai E (ai)
A NA
ANA ai
</figure>
<bodyText confidence="0.988691166666667">
on the terminal and nonterminal alphabet of the TAG, and
are independent of the elementary trees.
f is defined on the basis of the auxiliary trees in G.
Without loss of generality we assume that the TAG, G,
has trees of the following form.
I contains one initial tree:
</bodyText>
<subsectionHeader confidence="0.917611">
S OA
</subsectionHeader>
<bodyText confidence="0.966267">
Thus, in considering the language derived by G, we
need only be concerned with trees derived from auxiliary
trees whose root and foot are labeled by S.
There are 5 kinds of auxiliary trees in A.
</bodyText>
<listItem confidence="0.686296">
1. For each tree of the following form include
A3 IC&apos; IB` E f(c) and AVCal13` E f(e)
</listItem>
<figure confidence="0.979096833333333">
ANA
BOA C OA
ANA
2. For each tree of the following form include
Aa\BI I IC` E (c) and Aa\Ba/Ca E 1(0
A NA
BOA C OA
A NA
3. For each tree of the following form include
AalB`IC E f(c) and Aa/Ba/C` E 1(0
ANA
BOA
C OA
ANA
4. For each tree of the following form include Aa \A E
(c), E f (c) and Ai E f(a)
A NA
\
</figure>
<subsectionHeader confidence="0.643886">
at ANA
</subsectionHeader>
<bodyText confidence="0.99733075">
The CCG, G&apos;, in deriving a string, can be understood as
mimicking a derivation in G of that string in which trees
are adjoined in a particular order, that we now describe.
We define this order by describing the set, Ti(G), of all
trees produced in i or fewer steps, for i &gt; 0.
To(G) is the set of auxiliary trees of G.
Ti(G) is the union of Ti—i(G) with the set of all trees -y
produced in one of the following two ways.
</bodyText>
<listItem confidence="0.981095444444445">
1. Let 7&apos; and 7&amp;quot; be trees in (G) such that
there is a unique lowest OA node, n, in 7&apos; that
does not dominate the foot node, and .yli has no
OA nodes. 7 is produced by adjoining 7&amp;quot; at n
in 7&apos;.
2. Let 7&apos; be trees in Ti_i(G) such that there is
OA node, q, in 7&apos; that dominates the foot node
and has no lower OA nodes. 7 is produced by
adjoining an auxiliary tree fl at rj in 7&apos;.
</listItem>
<bodyText confidence="0.982868470588235">
Each tree 7 E Z(G) with frontier w1Aw2 has the prop-
erty that it has a single spine from the root to a node that
dominates the entire string wlAw2. All of the OA nodes
remaining in the tree fall on this spine, or hang immedi-
ately to its right or left. For each such tree 7 there will
be a derivation tree in G&apos;, whose root is labeled by a
category C and with frontier wi w2, where c encodes the
remaining obligatory adjunctions on this spine in 7.
Each OA nodes on the spine is encoded in C by a slash
and nonterminal symbol in the appropriate position. Sup-
pose the OA node is labeled by some A. When the OA
node falls on the spine C will contain /A&apos; (in this case
the direction of the slash was arbitrarily chosen to be for-
ward). When the OA node falls to the left of the spine c
will contain \Aa, and when the OA node falls to the right
of the spine c will contain /A°. For example, the follow-
ing tree is encoded by the category A\AT/AVAAA1
</bodyText>
<page confidence="0.979933">
282
</page>
<note confidence="0.499758">
Ai OA A2 OA
</note>
<equation confidence="0.889308333333333">
/ A3 OA
Asol\\
W2
</equation>
<bodyText confidence="0.994206">
We now give an example of a TAG for the language
{ a&apos;b&apos; I n &gt; 0} with crossing dependencies. We then
give the CCG that would be produced according to this
construction.
</bodyText>
<figure confidence="0.9177840625">
S2 NA
S NA S OA
S OA 52 OA S3 OA
SNA 52 NA
S1 NA S3 NA
/\ r‘N
a s INA S3 NA b
S NA
SNA
Sa\Sfl E Sc\S?/.9 E
SVS`/Sg E f(e) SVS&apos;IS§ E f(e)
Sf\A E Sf\A E
sgiB E f(E) SVB E f(e)
A E f(a) B E f(b)
SaVe E f(e) Se\SE E
S, E
</figure>
<sectionHeader confidence="0.959392" genericHeader="method">
4 Derivations Trees
</sectionHeader>
<bodyText confidence="0.999738869565217">
Vijay-Shanlcer, Weir and Joshi [14] described several
properties that were common to various constrained
grammatical systems, and defined a class of such
systems called Linear Context-Free Rewriting Systems
(LCFRS&apos;s). LCFRS&apos;s am constrained to have linear non-
erasing composition operations and derivation trees that
are structurally identical to those of context-free gram-
mars. The intuition behind the latter restriction is that
the rewriting (whether it be of strings, trees or graphs)
be performed in a context-free way; i.e., choices about
how to rewrite a structure should not be dependent on
an unbounded amount of the previous or future context
of the derivation. Several well-known formalisms fall
into this class including Context-Free Grammars, Gener-
alized Phrase Structure Grammars (GPSG), Head Gram-
mars, Tree Adjoining Grammars, and Multicomponent
Tree Adjoining Grammars. In [14] it is shown that each
formalism in the class generates semffinear languages that
can be recognized in polynomial time.
In this section, we examine derivation trees of CCG&apos;s
and compare them with respect to those of formalisms that
are known to be LCFRS&apos;s. In order to compare CCG&apos;s
with other systems we must choose a suitable method for
</bodyText>
<listItem confidence="0.9354194">
• the representation of derivations in a CCG. In the case of
CPU, TAG, HG, for example, it is fairly clear what the
elementary structures and composition operations should
be, and as a result, in the case of these formalisms, it is
apparent how to represent derivations.
</listItem>
<bodyText confidence="0.999979185185185">
The traditional way in which derivations of a CCG
have been represented has involved a binary tree whose
nodes are labeled by categories with annotations indicat-
ing which combinatory rule was used at each stage. These
derivation trees are different from those systems in the
class of LCFRS&apos;s in two ways. They have context-free
path sets, and the set of categories labeling nodes may
be infinite. A property that they share with LCFRS&apos;s is
that there is no dependence between unbounded paths. In
fact, the derivation trees sets produced by CCG&apos;s have
the same properties as those produced by LIG&apos;s (this is
apparent from the construction in Section 3.1).
Although the derivation trees that are traditionally as-
sociated with CCG&apos;s differ from those of LCFRS&apos;s, this
does not preclude the possibility that there may be an al-
ternative way of representing derivations. What appears
to be needed is some characterization of CCG&apos;s that iden-
tifies a finite set of elementary structures and a finite set
of composition operations.
The equivalence of TAG&apos;s and CCG&apos;s suggests one way
of doing this. The construction that we gave from TAG&apos;s
to CCG&apos;s produced CCG&apos;s having a specific form which
can be thought of as a normal form for CCG&apos;s. We can
represent the derivations of grammars in this form with
the same tree sets as the derivation tree sets of the TAG
from which they were constructed. Hence CCG&apos;s in this
normal form can be classified as LCFRS&apos;s.
</bodyText>
<page confidence="0.993899">
283
</page>
<bodyText confidence="0.999951388888889">
TAG derivation trees encode the adjunction of specified
elementary trees at specified nodes of other elementary
trees. Thus, the nodes of the derivation trees are labeled
by the names of elementary trees and tree addresses. In
the construction used in Section 3.2, each auxiliary tree
produces assignments of elementary categories to lexical
items. CCG derivations can be represented .with trees
whose nodes identify elementary categories and specify
which combinatory rule was used to combine it.
For grammars in this normal form, a unique derivation
can be recovered from these trees, but this is not true
of arbitrary CCG&apos;s where different orders of combination
of the elementary categories can result in derivations that
must be distinguished. In this normal form, the combina-
tory rules are so restrictive that there is only one order in
which elementary categories can be combined. Without
such restrictions, this style of derivation tree must encode
the order of derivation.
</bodyText>
<sectionHeader confidence="0.973128" genericHeader="method">
5 Additions to CCG&apos;s
</sectionHeader>
<bodyText confidence="0.999811714285714">
CCG&apos;s have not always been defined in the same way.
Although TAG&apos;s, HG&apos;s, and CCG&apos;s, can produce the
crossing dependencies appearing in Dutch, two additions
to CCG&apos;s have been considered by Steedman in [12]
to describe certain coordination phenomena occurring in
Dutch. For each addition, we discuss its effect on the
power of the system.
</bodyText>
<subsectionHeader confidence="0.969845">
5.1 Unbounded Dependent Structures
</subsectionHeader>
<bodyText confidence="0.977443933333333">
A characteristic feature of LCFRS&apos;s is that they are un-
able to produce two structures exhibiting an unbounded
dependence. It has been suggested that this capability
may be needed in the analysis of coordination in Dutch,
and an extension of CCG&apos;s has been proposed by Steed-
man [12] in which this is possible. The following schema
is included.
x* conj x
where, in the analysis given of Dutch, x is allowed to
match categories of arbitrary size. Two arbitrarily large
structures can be encoded with two arbitrarily large cat-
egories. This schema has the effect of checking that the
encodings are identical. The addition of rules such as
this increases the generative power of CCG&apos;s, e.g., the
following language can be generated.
</bodyText>
<sectionHeader confidence="0.521358" genericHeader="method">
{(wc)n I WE {a, b}}
</sectionHeader>
<bodyText confidence="0.9933016">
In giving analysis of coordination in languages other than
Dutch, only a finite number of instances of this schema
are required since only bounded categories are involved.
This form of coordination does not cause problems for
LCFRS&apos; s.
</bodyText>
<subsectionHeader confidence="0.986974">
5.2 Generalized Composition
</subsectionHeader>
<bodyText confidence="0.999897">
Steedman [12] considers a CCG in which there are an
infinite number of composition rules for each n &gt; 1 of
the form
</bodyText>
<equation confidence="0.99730825">
(z/Y) (• • • (vli zi)I2 • • • Inn) —
( • • Inzn)
(• • • (Ylizi)12 •• • Inzn) (z\Y)
(• • • (zli zi)I2 • • • Inzn)
</equation>
<bodyText confidence="0.999654777777778">
This form of composition is permitted in Parenthesis-free
Categorial Grammars which have been studied in [5,4],
and the results of this section also apply to this system.
With this addition, the generative power of CCG&apos;s in-
creases. We show this by giving a grammar for a language
that is known not to be a Tree Adjoining language. Con-
sider the following CCG. We allow unrestricted use of
arbitrarily many combinatory rules for forward or back-
wards generalized composition and application.
</bodyText>
<equation confidence="0.9736644">
1(0 = {S}
f(a2)= {A1} f(b1) = {B1}
f(a2)= {A2} f(b2) = {B2}
f(ci) = {S\AdDi/S\Bi} f(di) = {D1}
f(c2) = {S\A2/D2/S\B2} f (d2) = {D2}
</equation>
<bodyText confidence="0.9332733">
When the language, L, generated by this grammar is in-
tersected with the regular language
aT a; VI b;c; }
we get the following language.
{ cill&apos;a32b71c7&apos;142ce212(13241 I n1 , n2 &gt; }
The pumping lemma for Tree Adjoining Grammars [13]
can be used to show that this is not a Tree Adjoining
Language. Since Tree Adjoining Languages are closed
under intersection with Regular Languages, L can not be
a Tree Adjoining Language either.
</bodyText>
<sectionHeader confidence="0.999827" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.991044666666667">
In this paper we have considered the string languages
and derivation trees produced by CCL&apos;s. We have shown
that CCG&apos;s generate the same class of string languages
</bodyText>
<page confidence="0.98981">
284
</page>
<bodyText confidence="0.999982461538462">
as TAG&apos;s, HG&apos;s, and LIG&apos;s. The derivation tree sets nor-
mally associated with CCG&apos;s are found to be the same
as those of LIG&apos;s. They have context-free path sets, and
nodes labeled by an unbounded alphabet. A consequence
of the proof of equivalence with TAG is the existence of
a normal form for CCG&apos;s having the property that deriva-
tion trees can be given for grammars in this normal form
that are structurally the same as the derivation trees of
CFG&apos;s. The question of whether there is a method of
representing the derivations of arbitrary CCG&apos;s with tree
sets similar to those of CFG&apos;s remains open. Thus, it is
unclear, whether, despite their restricted weak generative
power, CCG&apos;s can be classified as LCFRS&apos;s.
</bodyText>
<sectionHeader confidence="0.999501" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99998475">
[1] A. E. Ades and M. J. Steedman. On the order of
words. Ling. and Philosophy, 3:517-558, 1982.
[2] A. V. Aho. Indexed grammars — An extension to
context free grammars. J. ACM, 15:647-671, 1968.
[3] Y. Bar-Hillel, C. Gaifman, and E. Shamir. On cate-
gorial and phrase structure grammars. In Language
and Information, Addison-Wesley, Reading, MA,
1964.
[4] J. Friedman, D. Dai, and W. Wang. The weak gen-
erative capacity of parenthesis-free categorial gram-
mars. In 11th Intern. Conf. on Comput. Ling., 1986.
[5] J. Friedman and R. Venkatesan. Categorial and Non-
Categorial languages. In 241h meeting Assoc. Com-
put. Ling., 1986.
[6] G. Gazdar. Applicability of Indexed Grammars to
Natural Languages. Technical Report CSLI-85-
34, Center for Study of Language and Information,
1985.
[7] A. K. Joshi. How much context-sensitivity is nec-
essary for characterizing structural descriptions —
Tree Adjoining Grammars. In D. Dowty, L Kart-
tunen, and A. Zwicky, editors, Natural Language
Processing — Theoretical, Computational and Psy-
chological Perspective, Cambridge University Press,
New York, NY, 1985. Originally presented in 1983.
[8] A. K. Joshi, L. S. Levy, and M. Takahashi. Tree ad-
junct grammars. J. Comput. Syst. Sci., 10(1), 1975.
[9] M. Steedman. Combinators and grammars. In R.
Oehrle, E. Bach, and D. Wheeler, editors, Categorial
Grammars and Natural Language Structures, Foris,
Dordrecht, 1986.
[10] M. Steedman. Combinatory grammars and para-
sitic gaps. Natural Language and Linguistic Theory,
1987.
[11] M. Steedman. Gapping as constituent coordination.
1987. m.s. University of Edinburgh.
[12] M. J. Steedman. Dependency and coordination in the
grammar of Dutch and English. Language, 61:523-
568, 1985.
[13] K. Vijay-Shanker. A Study of Tree Adjoining Gram-
mars. PhD thesis, University of Pennsylvania,
Philadelphia, Pa, 1987.
[14] K. Vijay-Shanker, D. J. Weir, and A. K. Joshi. Char-
acterizing structural descriptions produced by vari-
ous grammatical formalisms. In 25&apos;h meeting Assoc.
Comput. Ling., 1987.
[15] K. Vijay-Shanker, D. J. Weir, and A. K. Joshi. Tree
adjoining and head wrapping. In ll&apos; International
Conference on Comput. Ling., 1986.
[16] D. J. Weir. Characterizing Mildly Context-Sensitive
Grammar Formalisms. PhD thesis, University of
Pennsylvania, Philadelphia, Pa, in prep.
</reference>
<page confidence="0.998528">
285
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959574">
<title confidence="0.997203">COMBINATORY CATEGORIAL GRAMMARS: GENERATIVE POWER AND RELATIONSHIP TO LINEAR CONTEXT-FREE REWRITING SYSTEMS*</title>
<author confidence="1">David J Weir Aravind K Joshi</author>
<affiliation confidence="0.999908">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.999088">Philadelphia, PA 19104-6389</address>
<abstract confidence="0.996089153846154">Recent results have established that there is a family of languages that is exactly the class of languages generated by three independently developed grammar formalisms: Tree Adjoining Grammars, Head Grammars, and Linear Indexed Grammars. In this paper we show that Combinatory Categorial Grammars also generates the same class of languages. We discuss the structural descriptions produced by Combinatory Categorial Grammars and compare them to those of grammar formalisms in the class of Linear Context-Free Rewriting Systems. We also discuss certain extensions of Combinatory Categorial Grammars and their effect on the weak generative capacity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A E Ades</author>
<author>M J Steedman</author>
</authors>
<title>On the order of words.</title>
<date>1982</date>
<journal>Ling. and Philosophy,</journal>
<pages>3--517</pages>
<contexts>
<context position="4878" citStr="[1,12,9,10,11]" startWordPosition="743" endWordPosition="743"> combinatory rule in R. These restrictions take the form of constraints on the instantiations of variables in the rules. These can be constrained in two ways. reasons. However, in this paper, we will not investigate the relationship between the extension of CCG&apos;s and Multicomponent TAG. 2 Description of Formalisms In this section we describe Combinatory Categorial Grammars, Tree Adjoining Grammars, and Linear Indexed Grammars. 2.1 Combinatory Categorial Grammars Combinatory Categorial Grammar (CCG), as defined here, is the most recent version of a system that has evolved in a number of papers [1,12,9,10,11]. A CCG, G, is denoted by (VT,VN,S, f,R) where VT is a finite set of terminals (lexical items), VN is a finite set of nontenninaLs (atomic categories), S is a distinguished member of VN, f is a function that maps elements of VT U {E} to finite subsets of C(VN), the set of categories&apos;, where VN C C(VN) and if c1,c2 E C(VN) then (Cl/c2) E C(VN) and (ct \c2) E C(VN). R is a finite set of combinatory rules, described below. We now give the combinatory rules, where x, y, z are variables over categories, and each I; denotes either \ or I. 1. forward application: (01Y) y 2. backward application: y (x</context>
</contexts>
<marker>[1]</marker>
<rawString>A. E. Ades and M. J. Steedman. On the order of words. Ling. and Philosophy, 3:517-558, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A V Aho</author>
</authors>
<title>Indexed grammars — An extension to context free grammars.</title>
<date>1968</date>
<journal>J. ACM,</journal>
<pages>15--647</pages>
<contexts>
<context position="6773" citStr="[2]" startWordPosition="1096" endWordPosition="1096">ns a combinatory rule that has c1c2 c as an instance, and a and # are (possibly empty) strings of categories. The string languages, L(G), generated by a CCG, G, is defined as follows. fai ...an I S .1# c1.••cn, E f(ai), a; E VT U {E} ,1 &lt; i &lt; n} Although there is no type-raising rule, its effect can be achieved to a limited extent since f can assign type-raised categories to lexical items, which is the scheme employed in Steedman&apos;s recent work. 2.2 Linear Indexed Grammars Linear Indexed Grammars (LIG&apos;s) were introduced by Gazdar [6], and are a restriction of Indexed Grammars introduced by Aho [2]. LIG&apos;s can be seen as an extension of CFG&apos;s in which each nontenninal is associated with a stack. An LIG, G, is denoted by G = (VN,VT,VS,S, P) where VN is a finite set of nontenninals, VT is a finite set of terminals, Vs is a finite set of stack symbols, S E VN is the start symbol, and P is a finite set of productions, having the form •—■ a A[.&apos; -- Ai fl • • • A[..] • • •An[i AF&apos;i Al0 • • •Ai[- • • •An0 where An E Vii, 1€ Vs, and a€ VT U {E}. The notation for stacks uses [. 1] to denote an arbitrary stack whose top symbol is 1. This system is called Linear Indexed Grammars because it can be v</context>
</contexts>
<marker>[2]</marker>
<rawString>A. V. Aho. Indexed grammars — An extension to context free grammars. J. ACM, 15:647-671, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
<author>C Gaifman</author>
<author>E Shamir</author>
</authors>
<title>On categorial and phrase structure grammars.</title>
<date>1964</date>
<booktitle>In Language and Information,</booktitle>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA,</location>
<contexts>
<context position="1137" citStr="[3]" startWordPosition="163" endWordPosition="163">orial Grammars also generates the same class of languages. We discuss the structural descriptions produced by Combinatory Categorial Grammars and compare them to those of grammar formalisms in the class of Linear Context-Free Rewriting Systems. We also discuss certain extensions of Combinatory Categorial Grammars and their effect on the weak generative capacity. 1 Introduction There have been a number of results concerning the relationship between the weak generative capacity (family of string languages) associated with different grammar formalisms; for example, the theorem of Gaifman, et al. [3] that Classical Categorial Grammars are weakly equivalent to Context-Free Grammars (CFG&apos;s). More recently it has been found that there is a class of languages slightly larger than the class of Context-Free languages that.is generated by several different formalisms. In particular, Tree Adjoining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s) have been shown to be weakly equivalent [15], and these formalism are also equivalent to a restriction of Indexed Grammars considered by Gazdar [6] called Linear Indexed Grammars (110&apos;s) [13]. In this paper, we examine Combinatory Categorial Grammars (CCG&apos;s), a</context>
</contexts>
<marker>[3]</marker>
<rawString>Y. Bar-Hillel, C. Gaifman, and E. Shamir. On categorial and phrase structure grammars. In Language and Information, Addison-Wesley, Reading, MA, 1964.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Friedman</author>
<author>D Dai</author>
<author>W Wang</author>
</authors>
<title>The weak generative capacity of parenthesis-free categorial grammars.</title>
<date>1986</date>
<booktitle>In 11th Intern. Conf. on Comput. Ling.,</booktitle>
<contexts>
<context position="4090" citStr="[5,4]" startWordPosition="619" endWordPosition="619">RS&apos;s. This does not, however, rule out the possibility that there may be alternative ways of representing the derivation of CCG&apos;s that will allow for their classification as LCFRS&apos;s. Extensions to CCG&apos;s have been considered that enable them to compare two unbounded structures (for example, in [12]). It has been argued that this may be needed in the analysis of certain coordination phenomena in Dutch. In Section 5 we discuss how these additional features increase the power of the formalism. In so doing, we also give an example demonstrating that the Parenthesisfree Categorial Grammar formalism [5,4] is more powerful that CCG&apos;s as defined here. Extensions to TAG&apos;s (Multicomponent TAG) have been considered for similar 278 Restrictions can be associated with the use of the combinatory rule in R. These restrictions take the form of constraints on the instantiations of variables in the rules. These can be constrained in two ways. reasons. However, in this paper, we will not investigate the relationship between the extension of CCG&apos;s and Multicomponent TAG. 2 Description of Formalisms In this section we describe Combinatory Categorial Grammars, Tree Adjoining Grammars, and Linear Indexed Gramm</context>
<context position="23769" citStr="[5,4]" startWordPosition="4287" endWordPosition="4287">} In giving analysis of coordination in languages other than Dutch, only a finite number of instances of this schema are required since only bounded categories are involved. This form of coordination does not cause problems for LCFRS&apos; s. 5.2 Generalized Composition Steedman [12] considers a CCG in which there are an infinite number of composition rules for each n &gt; 1 of the form (z/Y) (• • • (vli zi)I2 • • • Inn) — ( • • Inzn) (• • • (Ylizi)12 •• • Inzn) (z\Y) (• • • (zli zi)I2 • • • Inzn) This form of composition is permitted in Parenthesis-free Categorial Grammars which have been studied in [5,4], and the results of this section also apply to this system. With this addition, the generative power of CCG&apos;s increases. We show this by giving a grammar for a language that is known not to be a Tree Adjoining language. Consider the following CCG. We allow unrestricted use of arbitrarily many combinatory rules for forward or backwards generalized composition and application. 1(0 = {S} f(a2)= {A1} f(b1) = {B1} f(a2)= {A2} f(b2) = {B2} f(ci) = {S\AdDi/S\Bi} f(di) = {D1} f(c2) = {S\A2/D2/S\B2} f (d2) = {D2} When the language, L, generated by this grammar is intersected with the regular language </context>
</contexts>
<marker>[4]</marker>
<rawString>J. Friedman, D. Dai, and W. Wang. The weak generative capacity of parenthesis-free categorial grammars. In 11th Intern. Conf. on Comput. Ling., 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Friedman</author>
<author>R Venkatesan</author>
</authors>
<title>Categorial and NonCategorial languages.</title>
<date>1986</date>
<booktitle>In 241h meeting Assoc. Comput. Ling.,</booktitle>
<contexts>
<context position="4090" citStr="[5,4]" startWordPosition="619" endWordPosition="619">RS&apos;s. This does not, however, rule out the possibility that there may be alternative ways of representing the derivation of CCG&apos;s that will allow for their classification as LCFRS&apos;s. Extensions to CCG&apos;s have been considered that enable them to compare two unbounded structures (for example, in [12]). It has been argued that this may be needed in the analysis of certain coordination phenomena in Dutch. In Section 5 we discuss how these additional features increase the power of the formalism. In so doing, we also give an example demonstrating that the Parenthesisfree Categorial Grammar formalism [5,4] is more powerful that CCG&apos;s as defined here. Extensions to TAG&apos;s (Multicomponent TAG) have been considered for similar 278 Restrictions can be associated with the use of the combinatory rule in R. These restrictions take the form of constraints on the instantiations of variables in the rules. These can be constrained in two ways. reasons. However, in this paper, we will not investigate the relationship between the extension of CCG&apos;s and Multicomponent TAG. 2 Description of Formalisms In this section we describe Combinatory Categorial Grammars, Tree Adjoining Grammars, and Linear Indexed Gramm</context>
<context position="23769" citStr="[5,4]" startWordPosition="4287" endWordPosition="4287">} In giving analysis of coordination in languages other than Dutch, only a finite number of instances of this schema are required since only bounded categories are involved. This form of coordination does not cause problems for LCFRS&apos; s. 5.2 Generalized Composition Steedman [12] considers a CCG in which there are an infinite number of composition rules for each n &gt; 1 of the form (z/Y) (• • • (vli zi)I2 • • • Inn) — ( • • Inzn) (• • • (Ylizi)12 •• • Inzn) (z\Y) (• • • (zli zi)I2 • • • Inzn) This form of composition is permitted in Parenthesis-free Categorial Grammars which have been studied in [5,4], and the results of this section also apply to this system. With this addition, the generative power of CCG&apos;s increases. We show this by giving a grammar for a language that is known not to be a Tree Adjoining language. Consider the following CCG. We allow unrestricted use of arbitrarily many combinatory rules for forward or backwards generalized composition and application. 1(0 = {S} f(a2)= {A1} f(b1) = {B1} f(a2)= {A2} f(b2) = {B2} f(ci) = {S\AdDi/S\Bi} f(di) = {D1} f(c2) = {S\A2/D2/S\B2} f (d2) = {D2} When the language, L, generated by this grammar is intersected with the regular language </context>
</contexts>
<marker>[5]</marker>
<rawString>J. Friedman and R. Venkatesan. Categorial and NonCategorial languages. In 241h meeting Assoc. Comput. Ling., 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
</authors>
<title>Applicability of Indexed Grammars to Natural Languages.</title>
<date>1985</date>
<tech>Technical Report CSLI-85-34,</tech>
<institution>Center for Study of Language and Information,</institution>
<contexts>
<context position="1623" citStr="[6]" startWordPosition="236" endWordPosition="236">ly of string languages) associated with different grammar formalisms; for example, the theorem of Gaifman, et al. [3] that Classical Categorial Grammars are weakly equivalent to Context-Free Grammars (CFG&apos;s). More recently it has been found that there is a class of languages slightly larger than the class of Context-Free languages that.is generated by several different formalisms. In particular, Tree Adjoining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s) have been shown to be weakly equivalent [15], and these formalism are also equivalent to a restriction of Indexed Grammars considered by Gazdar [6] called Linear Indexed Grammars (110&apos;s) [13]. In this paper, we examine Combinatory Categorial Grammars (CCG&apos;s), an extension of Classical Categorial Grammars developed by Steedman and his collaborators [1,12,9,10,111. The main result in this paper is &apos;This work was partially supported by NSF grants MCS-82-19116- CER. MCS-82-07294, DCR-84-10413, ARO grant DAA29434-9-0027, and DARPA grant N0014435-K0018. We are very grateful to Mark Steedman, K. Vijay-Shanker and Remo Pareschi for helpful discussions. that CCG&apos;s are weakly equivalent to TAG&apos;s, HG&apos;s, and LIG&apos;s. We prove this by showing in Sectio</context>
<context position="6708" citStr="[6]" startWordPosition="1085" endWordPosition="1085">erives relation be defined as follows. acf3 ct acic20 if R contains a combinatory rule that has c1c2 c as an instance, and a and # are (possibly empty) strings of categories. The string languages, L(G), generated by a CCG, G, is defined as follows. fai ...an I S .1# c1.••cn, E f(ai), a; E VT U {E} ,1 &lt; i &lt; n} Although there is no type-raising rule, its effect can be achieved to a limited extent since f can assign type-raised categories to lexical items, which is the scheme employed in Steedman&apos;s recent work. 2.2 Linear Indexed Grammars Linear Indexed Grammars (LIG&apos;s) were introduced by Gazdar [6], and are a restriction of Indexed Grammars introduced by Aho [2]. LIG&apos;s can be seen as an extension of CFG&apos;s in which each nontenninal is associated with a stack. An LIG, G, is denoted by G = (VN,VT,VS,S, P) where VN is a finite set of nontenninals, VT is a finite set of terminals, Vs is a finite set of stack symbols, S E VN is the start symbol, and P is a finite set of productions, having the form •—■ a A[.&apos; -- Ai fl • • • A[..] • • •An[i AF&apos;i Al0 • • •Ai[- • • •An0 where An E Vii, 1€ Vs, and a€ VT U {E}. The notation for stacks uses [. 1] to denote an arbitrary stack whose top symbol is 1. </context>
</contexts>
<marker>[6]</marker>
<rawString>G. Gazdar. Applicability of Indexed Grammars to Natural Languages. Technical Report CSLI-85-34, Center for Study of Language and Information, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>How much context-sensitivity is necessary for characterizing structural descriptions — Tree Adjoining Grammars. In</title>
<date>1985</date>
<booktitle>Natural Language Processing — Theoretical, Computational and Psychological Perspective,</booktitle>
<editor>D. Dowty, L Karttunen, and A. Zwicky, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY,</location>
<note>Originally presented in</note>
<contexts>
<context position="7848" citStr="[8,7]" startWordPosition="1326" endWordPosition="1326">s uses [. 1] to denote an arbitrary stack whose top symbol is 1. This system is called Linear Indexed Grammars because it can be viewed as a 279 restriction of Indexed Grammars in which only one of the non-terminals on the right-hand-side of a production can inherit the stack from the left-hand-side. The derives relation is defined as follows. aA[1„„ .111]13r a•Ain • • • Ai[lm • • • li] • • • AnD5 if 1] Ain . An[] E P aA[1,n .1]f3 . Ai[1,n .111] . • • An 0/9 if --• A1[].. .A1[. — Ann E P • aftl[]fl aal3 if An a E P The language, L(G), generated by G is {w1wE w 23 Tree Adjoining Grammars A TAG [8,7] is denoted G= (VN ,VT ,S,I, A) where VN is a finite set of nonterminals, VT is a finite set of terminals, S is a distinguished nonterminal, / is a finite set of initial trees and A is a finite set of auxiliary trees. Initial trees are rooted in S with w E Ig on their frontier. Each internal node is labeled by a member of VN Auxiliary trees have w1Atv2 E ViWNV4; on their frontier. The node on the frontier labeled A is called the foot node, and the root is also labeled A. Each internal node is labeled by a member of VN • Trees are composed by tree adjunction. When a tree 7&apos; is adjoined at a nod</context>
</contexts>
<marker>[7]</marker>
<rawString>A. K. Joshi. How much context-sensitivity is necessary for characterizing structural descriptions — Tree Adjoining Grammars. In D. Dowty, L Karttunen, and A. Zwicky, editors, Natural Language Processing — Theoretical, Computational and Psychological Perspective, Cambridge University Press, New York, NY, 1985. Originally presented in 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>L S Levy</author>
<author>M Takahashi</author>
</authors>
<title>Tree adjunct grammars.</title>
<date>1975</date>
<journal>J. Comput. Syst. Sci.,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="7848" citStr="[8,7]" startWordPosition="1326" endWordPosition="1326">s uses [. 1] to denote an arbitrary stack whose top symbol is 1. This system is called Linear Indexed Grammars because it can be viewed as a 279 restriction of Indexed Grammars in which only one of the non-terminals on the right-hand-side of a production can inherit the stack from the left-hand-side. The derives relation is defined as follows. aA[1„„ .111]13r a•Ain • • • Ai[lm • • • li] • • • AnD5 if 1] Ain . An[] E P aA[1,n .1]f3 . Ai[1,n .111] . • • An 0/9 if --• A1[].. .A1[. — Ann E P • aftl[]fl aal3 if An a E P The language, L(G), generated by G is {w1wE w 23 Tree Adjoining Grammars A TAG [8,7] is denoted G= (VN ,VT ,S,I, A) where VN is a finite set of nonterminals, VT is a finite set of terminals, S is a distinguished nonterminal, / is a finite set of initial trees and A is a finite set of auxiliary trees. Initial trees are rooted in S with w E Ig on their frontier. Each internal node is labeled by a member of VN Auxiliary trees have w1Atv2 E ViWNV4; on their frontier. The node on the frontier labeled A is called the foot node, and the root is also labeled A. Each internal node is labeled by a member of VN • Trees are composed by tree adjunction. When a tree 7&apos; is adjoined at a nod</context>
</contexts>
<marker>[8]</marker>
<rawString>A. K. Joshi, L. S. Levy, and M. Takahashi. Tree adjunct grammars. J. Comput. Syst. Sci., 10(1), 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Combinators and grammars. In</title>
<date>1986</date>
<booktitle>Categorial Grammars and Natural Language Structures,</booktitle>
<editor>R. Oehrle, E. Bach, and D. Wheeler, editors,</editor>
<location>Foris, Dordrecht,</location>
<contexts>
<context position="4878" citStr="[1,12,9,10,11]" startWordPosition="743" endWordPosition="743"> combinatory rule in R. These restrictions take the form of constraints on the instantiations of variables in the rules. These can be constrained in two ways. reasons. However, in this paper, we will not investigate the relationship between the extension of CCG&apos;s and Multicomponent TAG. 2 Description of Formalisms In this section we describe Combinatory Categorial Grammars, Tree Adjoining Grammars, and Linear Indexed Grammars. 2.1 Combinatory Categorial Grammars Combinatory Categorial Grammar (CCG), as defined here, is the most recent version of a system that has evolved in a number of papers [1,12,9,10,11]. A CCG, G, is denoted by (VT,VN,S, f,R) where VT is a finite set of terminals (lexical items), VN is a finite set of nontenninaLs (atomic categories), S is a distinguished member of VN, f is a function that maps elements of VT U {E} to finite subsets of C(VN), the set of categories&apos;, where VN C C(VN) and if c1,c2 E C(VN) then (Cl/c2) E C(VN) and (ct \c2) E C(VN). R is a finite set of combinatory rules, described below. We now give the combinatory rules, where x, y, z are variables over categories, and each I; denotes either \ or I. 1. forward application: (01Y) y 2. backward application: y (x</context>
</contexts>
<marker>[9]</marker>
<rawString>M. Steedman. Combinators and grammars. In R. Oehrle, E. Bach, and D. Wheeler, editors, Categorial Grammars and Natural Language Structures, Foris, Dordrecht, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Combinatory grammars and parasitic gaps. Natural Language and Linguistic Theory,</title>
<date>1987</date>
<contexts>
<context position="4878" citStr="[1,12,9,10,11]" startWordPosition="743" endWordPosition="743"> combinatory rule in R. These restrictions take the form of constraints on the instantiations of variables in the rules. These can be constrained in two ways. reasons. However, in this paper, we will not investigate the relationship between the extension of CCG&apos;s and Multicomponent TAG. 2 Description of Formalisms In this section we describe Combinatory Categorial Grammars, Tree Adjoining Grammars, and Linear Indexed Grammars. 2.1 Combinatory Categorial Grammars Combinatory Categorial Grammar (CCG), as defined here, is the most recent version of a system that has evolved in a number of papers [1,12,9,10,11]. A CCG, G, is denoted by (VT,VN,S, f,R) where VT is a finite set of terminals (lexical items), VN is a finite set of nontenninaLs (atomic categories), S is a distinguished member of VN, f is a function that maps elements of VT U {E} to finite subsets of C(VN), the set of categories&apos;, where VN C C(VN) and if c1,c2 E C(VN) then (Cl/c2) E C(VN) and (ct \c2) E C(VN). R is a finite set of combinatory rules, described below. We now give the combinatory rules, where x, y, z are variables over categories, and each I; denotes either \ or I. 1. forward application: (01Y) y 2. backward application: y (x</context>
</contexts>
<marker>[10]</marker>
<rawString>M. Steedman. Combinatory grammars and parasitic gaps. Natural Language and Linguistic Theory, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Gapping as constituent coordination.</title>
<date>1987</date>
<institution>m.s. University of Edinburgh.</institution>
<contexts>
<context position="4878" citStr="[1,12,9,10,11]" startWordPosition="743" endWordPosition="743"> combinatory rule in R. These restrictions take the form of constraints on the instantiations of variables in the rules. These can be constrained in two ways. reasons. However, in this paper, we will not investigate the relationship between the extension of CCG&apos;s and Multicomponent TAG. 2 Description of Formalisms In this section we describe Combinatory Categorial Grammars, Tree Adjoining Grammars, and Linear Indexed Grammars. 2.1 Combinatory Categorial Grammars Combinatory Categorial Grammar (CCG), as defined here, is the most recent version of a system that has evolved in a number of papers [1,12,9,10,11]. A CCG, G, is denoted by (VT,VN,S, f,R) where VT is a finite set of terminals (lexical items), VN is a finite set of nontenninaLs (atomic categories), S is a distinguished member of VN, f is a function that maps elements of VT U {E} to finite subsets of C(VN), the set of categories&apos;, where VN C C(VN) and if c1,c2 E C(VN) then (Cl/c2) E C(VN) and (ct \c2) E C(VN). R is a finite set of combinatory rules, described below. We now give the combinatory rules, where x, y, z are variables over categories, and each I; denotes either \ or I. 1. forward application: (01Y) y 2. backward application: y (x</context>
</contexts>
<marker>[11]</marker>
<rawString>M. Steedman. Gapping as constituent coordination. 1987. m.s. University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Steedman</author>
</authors>
<title>Dependency and coordination in the grammar of Dutch</title>
<date>1985</date>
<pages>61--523</pages>
<contexts>
<context position="3783" citStr="[12]" startWordPosition="569" endWordPosition="569">that CCG&apos;s should be classified as mildly contextsensitive. In Section 4 we consider whether CCG&apos;s should be included in the class of LCFRS&apos;s. The derivation tree sets traditionally associated with CCG&apos;s have Context-free path sets, and are similar to those of LIG&apos;s, and therefore differ from those of LCFRS&apos;s. This does not, however, rule out the possibility that there may be alternative ways of representing the derivation of CCG&apos;s that will allow for their classification as LCFRS&apos;s. Extensions to CCG&apos;s have been considered that enable them to compare two unbounded structures (for example, in [12]). It has been argued that this may be needed in the analysis of certain coordination phenomena in Dutch. In Section 5 we discuss how these additional features increase the power of the formalism. In so doing, we also give an example demonstrating that the Parenthesisfree Categorial Grammar formalism [5,4] is more powerful that CCG&apos;s as defined here. Extensions to TAG&apos;s (Multicomponent TAG) have been considered for similar 278 Restrictions can be associated with the use of the combinatory rule in R. These restrictions take the form of constraints on the instantiations of variables in the rules</context>
<context position="22251" citStr="[12]" startWordPosition="4023" endWordPosition="4023">rue of arbitrary CCG&apos;s where different orders of combination of the elementary categories can result in derivations that must be distinguished. In this normal form, the combinatory rules are so restrictive that there is only one order in which elementary categories can be combined. Without such restrictions, this style of derivation tree must encode the order of derivation. 5 Additions to CCG&apos;s CCG&apos;s have not always been defined in the same way. Although TAG&apos;s, HG&apos;s, and CCG&apos;s, can produce the crossing dependencies appearing in Dutch, two additions to CCG&apos;s have been considered by Steedman in [12] to describe certain coordination phenomena occurring in Dutch. For each addition, we discuss its effect on the power of the system. 5.1 Unbounded Dependent Structures A characteristic feature of LCFRS&apos;s is that they are unable to produce two structures exhibiting an unbounded dependence. It has been suggested that this capability may be needed in the analysis of coordination in Dutch, and an extension of CCG&apos;s has been proposed by Steedman [12] in which this is possible. The following schema is included. x* conj x where, in the analysis given of Dutch, x is allowed to match categories of arbi</context>
</contexts>
<marker>[12]</marker>
<rawString>M. J. Steedman. Dependency and coordination in the grammar of Dutch and English. Language, 61:523-568, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
</authors>
<title>A Study of Tree Adjoining Grammars.</title>
<date>1987</date>
<tech>PhD thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, Pa,</location>
<contexts>
<context position="1667" citStr="[13]" startWordPosition="243" endWordPosition="243">ferent grammar formalisms; for example, the theorem of Gaifman, et al. [3] that Classical Categorial Grammars are weakly equivalent to Context-Free Grammars (CFG&apos;s). More recently it has been found that there is a class of languages slightly larger than the class of Context-Free languages that.is generated by several different formalisms. In particular, Tree Adjoining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s) have been shown to be weakly equivalent [15], and these formalism are also equivalent to a restriction of Indexed Grammars considered by Gazdar [6] called Linear Indexed Grammars (110&apos;s) [13]. In this paper, we examine Combinatory Categorial Grammars (CCG&apos;s), an extension of Classical Categorial Grammars developed by Steedman and his collaborators [1,12,9,10,111. The main result in this paper is &apos;This work was partially supported by NSF grants MCS-82-19116- CER. MCS-82-07294, DCR-84-10413, ARO grant DAA29434-9-0027, and DARPA grant N0014435-K0018. We are very grateful to Mark Steedman, K. Vijay-Shanker and Remo Pareschi for helpful discussions. that CCG&apos;s are weakly equivalent to TAG&apos;s, HG&apos;s, and LIG&apos;s. We prove this by showing in Section 3 that Combinatory Categorial Languages (C</context>
<context position="9506" citStr="[13]" startWordPosition="1642" endWordPosition="1642">he node has obligatory adjunction (OA). When no tree can be adjoined at a node that node has a null adjoining (NA) constraint The string language L(G) generated by a TAG, G, is the set of all strings lying on the frontier of some tree that can be derived from an initial trees with a finite number of adjtmctions, where that tree has no OA constraints. 3 Weak Generative Capacity In this section we show that CCG&apos;s are weakly equivalent to TAG&apos;s, HG&apos;s, and 1.10&apos;s. We do this by showing the inclusion of CCL&apos;s in L1L&apos;s, and the inclusion of TAL&apos;s in CCL&apos;s. It is know that TAG and LIG are equivalent [13], and that TAG and HG are equivalent [15]. Thus, the two inclusions shown here imply the weak equivalence of all four systems. We have not included complete details of the proofs which can be found in [16]. 3.1 CCL&apos;s C L1L&apos;s We describe how to construct a LIG, , from an arbitrary CCG, G such that G and GI are equivalent. Let us assume that categories are written without parentheses, unless they are needed to override the left associativity of the slashes. A category c is minimally parenthesized if and only if one of the following holds. c = A for A E VN C = (C011C112 • • • Incn), for n &gt; 1, wh</context>
<context position="24511" citStr="[13]" startWordPosition="4418" endWordPosition="4418">giving a grammar for a language that is known not to be a Tree Adjoining language. Consider the following CCG. We allow unrestricted use of arbitrarily many combinatory rules for forward or backwards generalized composition and application. 1(0 = {S} f(a2)= {A1} f(b1) = {B1} f(a2)= {A2} f(b2) = {B2} f(ci) = {S\AdDi/S\Bi} f(di) = {D1} f(c2) = {S\A2/D2/S\B2} f (d2) = {D2} When the language, L, generated by this grammar is intersected with the regular language aT a; VI b;c; } we get the following language. { cill&apos;a32b71c7&apos;142ce212(13241 I n1 , n2 &gt; } The pumping lemma for Tree Adjoining Grammars [13] can be used to show that this is not a Tree Adjoining Language. Since Tree Adjoining Languages are closed under intersection with Regular Languages, L can not be a Tree Adjoining Language either. 6 Conclusions In this paper we have considered the string languages and derivation trees produced by CCL&apos;s. We have shown that CCG&apos;s generate the same class of string languages 284 as TAG&apos;s, HG&apos;s, and LIG&apos;s. The derivation tree sets normally associated with CCG&apos;s are found to be the same as those of LIG&apos;s. They have context-free path sets, and nodes labeled by an unbounded alphabet. A consequence of </context>
</contexts>
<marker>[13]</marker>
<rawString>K. Vijay-Shanker. A Study of Tree Adjoining Grammars. PhD thesis, University of Pennsylvania, Philadelphia, Pa, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>D J Weir</author>
<author>A K Joshi</author>
</authors>
<title>Characterizing structural descriptions produced by various grammatical formalisms. In 25&apos;h meeting Assoc.</title>
<date>1987</date>
<publisher>Comput. Ling.,</publisher>
<contexts>
<context position="2570" citStr="[14]" startWordPosition="377" endWordPosition="377">413, ARO grant DAA29434-9-0027, and DARPA grant N0014435-K0018. We are very grateful to Mark Steedman, K. Vijay-Shanker and Remo Pareschi for helpful discussions. that CCG&apos;s are weakly equivalent to TAG&apos;s, HG&apos;s, and LIG&apos;s. We prove this by showing in Section 3 that Combinatory Categorial Languages (CCL&apos;s) are included in Linear Indexed Languages (LIL&apos;s), and that Tree Adjoining Languages (TAL&apos;s) are included in CCL&apos;s. After considering their weak generative capacity, we investigate the relationship between the structural descriptions produced by CCG&apos;s and those of other grammar formalisms. In [14] a number of grammar formalisms were compared and it was suggested that an important aspect of their descriptive capacity was reflected by the derivation structures that they produced. Several formalisms that had previously been described as mildly contextsensitive were found to share a number of properties. In particular, the derivations of a grammar could be represented with trees that always formed the tree set of a context-free grammar. Formalisms that share these properties were called Linear Context-Free Rewriting Systems (LCFRS&apos;s) [14]. On the basis of their weak generative capacity, it</context>
<context position="18125" citStr="[14]" startWordPosition="3356" endWordPosition="3356"> node falls to the right of the spine c will contain /A°. For example, the following tree is encoded by the category A\AT/AVAAA1 282 Ai OA A2 OA / A3 OA Asol\\ W2 We now give an example of a TAG for the language { a&apos;b&apos; I n &gt; 0} with crossing dependencies. We then give the CCG that would be produced according to this construction. S2 NA S NA S OA S OA 52 OA S3 OA SNA 52 NA S1 NA S3 NA /\ r‘N a s INA S3 NA b S NA SNA Sa\Sfl E Sc\S?/.9 E SVS`/Sg E f(e) SVS&apos;IS§ E f(e) Sf\A E Sf\A E sgiB E f(E) SVB E f(e) A E f(a) B E f(b) SaVe E f(e) Se\SE E S, E 4 Derivations Trees Vijay-Shanlcer, Weir and Joshi [14] described several properties that were common to various constrained grammatical systems, and defined a class of such systems called Linear Context-Free Rewriting Systems (LCFRS&apos;s). LCFRS&apos;s am constrained to have linear nonerasing composition operations and derivation trees that are structurally identical to those of context-free grammars. The intuition behind the latter restriction is that the rewriting (whether it be of strings, trees or graphs) be performed in a context-free way; i.e., choices about how to rewrite a structure should not be dependent on an unbounded amount of the previous o</context>
</contexts>
<marker>[14]</marker>
<rawString>K. Vijay-Shanker, D. J. Weir, and A. K. Joshi. Characterizing structural descriptions produced by various grammatical formalisms. In 25&apos;h meeting Assoc. Comput. Ling., 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>D J Weir</author>
<author>A K Joshi</author>
</authors>
<title>Tree adjoining and head wrapping.</title>
<date>1986</date>
<booktitle>In ll&apos; International Conference on Comput. Ling.,</booktitle>
<contexts>
<context position="1520" citStr="[15]" startWordPosition="220" endWordPosition="220">ere have been a number of results concerning the relationship between the weak generative capacity (family of string languages) associated with different grammar formalisms; for example, the theorem of Gaifman, et al. [3] that Classical Categorial Grammars are weakly equivalent to Context-Free Grammars (CFG&apos;s). More recently it has been found that there is a class of languages slightly larger than the class of Context-Free languages that.is generated by several different formalisms. In particular, Tree Adjoining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s) have been shown to be weakly equivalent [15], and these formalism are also equivalent to a restriction of Indexed Grammars considered by Gazdar [6] called Linear Indexed Grammars (110&apos;s) [13]. In this paper, we examine Combinatory Categorial Grammars (CCG&apos;s), an extension of Classical Categorial Grammars developed by Steedman and his collaborators [1,12,9,10,111. The main result in this paper is &apos;This work was partially supported by NSF grants MCS-82-19116- CER. MCS-82-07294, DCR-84-10413, ARO grant DAA29434-9-0027, and DARPA grant N0014435-K0018. We are very grateful to Mark Steedman, K. Vijay-Shanker and Remo Pareschi for helpful disc</context>
<context position="9547" citStr="[15]" startWordPosition="1650" endWordPosition="1650">hen no tree can be adjoined at a node that node has a null adjoining (NA) constraint The string language L(G) generated by a TAG, G, is the set of all strings lying on the frontier of some tree that can be derived from an initial trees with a finite number of adjtmctions, where that tree has no OA constraints. 3 Weak Generative Capacity In this section we show that CCG&apos;s are weakly equivalent to TAG&apos;s, HG&apos;s, and 1.10&apos;s. We do this by showing the inclusion of CCL&apos;s in L1L&apos;s, and the inclusion of TAL&apos;s in CCL&apos;s. It is know that TAG and LIG are equivalent [13], and that TAG and HG are equivalent [15]. Thus, the two inclusions shown here imply the weak equivalence of all four systems. We have not included complete details of the proofs which can be found in [16]. 3.1 CCL&apos;s C L1L&apos;s We describe how to construct a LIG, , from an arbitrary CCG, G such that G and GI are equivalent. Let us assume that categories are written without parentheses, unless they are needed to override the left associativity of the slashes. A category c is minimally parenthesized if and only if one of the following holds. c = A for A E VN C = (C011C112 • • • Incn), for n &gt; 1, where co E VN and each ci is minimally pare</context>
</contexts>
<marker>[15]</marker>
<rawString>K. Vijay-Shanker, D. J. Weir, and A. K. Joshi. Tree adjoining and head wrapping. In ll&apos; International Conference on Comput. Ling., 1986.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D J Weir</author>
</authors>
<title>Characterizing Mildly Context-Sensitive Grammar Formalisms.</title>
<tech>PhD thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, Pa,</location>
<note>in prep.</note>
<contexts>
<context position="9711" citStr="[16]" startWordPosition="1679" endWordPosition="1679"> on the frontier of some tree that can be derived from an initial trees with a finite number of adjtmctions, where that tree has no OA constraints. 3 Weak Generative Capacity In this section we show that CCG&apos;s are weakly equivalent to TAG&apos;s, HG&apos;s, and 1.10&apos;s. We do this by showing the inclusion of CCL&apos;s in L1L&apos;s, and the inclusion of TAL&apos;s in CCL&apos;s. It is know that TAG and LIG are equivalent [13], and that TAG and HG are equivalent [15]. Thus, the two inclusions shown here imply the weak equivalence of all four systems. We have not included complete details of the proofs which can be found in [16]. 3.1 CCL&apos;s C L1L&apos;s We describe how to construct a LIG, , from an arbitrary CCG, G such that G and GI are equivalent. Let us assume that categories are written without parentheses, unless they are needed to override the left associativity of the slashes. A category c is minimally parenthesized if and only if one of the following holds. c = A for A E VN C = (C011C112 • • • Incn), for n &gt; 1, where co E VN and each ci is minimally parenthesized. It will be useful to be able to refer to the components of a category, c. We first define the immediate components of c. 280 when c = A the immediate com</context>
</contexts>
<marker>[16]</marker>
<rawString>D. J. Weir. Characterizing Mildly Context-Sensitive Grammar Formalisms. PhD thesis, University of Pennsylvania, Philadelphia, Pa, in prep.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>