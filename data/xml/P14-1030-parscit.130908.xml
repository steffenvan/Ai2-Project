<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9889195">
Extracting Opinion Targets and Opinion Words from Online Reviews
with Graph Co-ranking
</title>
<author confidence="0.999603">
Kang Liu, Liheng Xu and Jun Zhao
</author>
<affiliation confidence="0.996183">
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China
</affiliation>
<email confidence="0.983919">
{kliu, lhxu, jzhao}@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.99495" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999958428571428">
Extracting opinion targets and opinion
words from online reviews are two fun-
damental tasks in opinion mining. This
paper proposes a novel approach to col-
lectively extract them with graph co-
ranking. First, compared to previous
methods which solely employed opinion
relations among words, our method con-
structs a heterogeneous graph to model
two types of relations, including seman-
tic relations and opinion relations. Next,
a co-ranking algorithm is proposed to es-
timate the confidence of each candidate,
and the candidates with higher confidence
will be extracted as opinion targets/words.
In this way, different relations make coop-
erative effects on candidates‚Äô confidence
estimation. Moreover, word preference
is captured and incorporated into our co-
ranking algorithm. In this way, our co-
ranking is personalized and each candi-
date‚Äôs confidence is only determined by its
preferred collocations. It helps to improve
the extraction precision. The experimen-
tal results on three data sets with differ-
ent sizes and languages show that our ap-
proach achieves better performance than
state-of-the-art methods.
</bodyText>
<sectionHeader confidence="0.998131" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997552549019608">
In opinion mining, extracting opinion targets and
opinion words are two fundamental subtasks.
Opinion targets are objects about which users‚Äô
opinions are expressed, and opinion words are
words which indicate opinions‚Äô polarities. Ex-
tracting them can provide essential information
for obtaining fine-grained analysis on customers‚Äô
opinions. Thus, it has attracted a lot of attentions
(Hu and Liu, 2004b; Liu et al., 2012; Moghaddam
and Ester, 2011; Mukherjee and Liu, 2012).
To this end, previous work usually employed a
collective extraction strategy (Qiu et al., 2009; Hu
and Liu, 2004b; Liu et al., 2013b). Their intuition
is: opinion words usually co-occur with opinion
targets in sentences, and there are strong modifi-
cation relationship between them (called opinion
relation in (Liu et al., 2012)). If a word is an
opinion word, other words with which that word
having opinion relations will have highly proba-
bility to be opinion targets, and vice versa. In this
way, extraction is alternatively performed and mu-
tual reinforced between opinion targets and opin-
ion words. Although this strategy has been widely
employed by previous approaches, it still has sev-
eral limitations.
1) Only considering opinion relations is in-
sufficient. Previous methods mainly focused on
employing opinion relations among words for
opinion target/word co-extraction. They have in-
vestigated a series of techniques to enhance opin-
ion relations identification performance, such as
nearest neighbor rules (Liu et al., 2005), syntactic
patterns (Zhang et al., 2010; Popescu and Etzioni,
2005), word alignment models (Liu et al., 2012;
Liu et al., 2013b; Liu et al., 2013a), etc. How-
ever, we are curious that whether merely employ-
ing opinion relations among words is enough for
opinion target/word extraction? We note that there
are additional types of relations among words. For
example, ‚ÄúLCD‚Äù and ‚ÄúLED‚Äù both denote the same
aspect ‚Äúscreen‚Äù in TV set domain, and they are
topical related. We call such relations between
homogeneous words as semantic relations. If we
have known ‚ÄúLCD‚Äù to be an opinion target, ‚ÄúLED‚Äù
is naturally to be an opinion target. Intuitively,
besides opinion relations, semantic relations may
provide additional rich clues for indicating opin-
ion targets/words. Which kind of relations is more
effective for opinion targets/words extraction? Is it
beneficial to consider these two types of relations
together for the extraction? To our best knowl-
</bodyText>
<note confidence="0.797731666666667">
314
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 314‚Äì324,
Baltimore, Maryland, USA, June 23-25 2014. cÔøΩ2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.97882170886076">
edge, these problems have seldom been studied
before (see Section 2).
2) Ignoring word preference. When employ-
ing opinion relations to perform mutual reinforc-
ing extraction between opinion targets and opin-
ion words, previous methods depended on opin-
ion associations among words, but seldom consid-
ered word preference. Word preference denotes
a word‚Äôs preferred collocations. Intuitively, the
confidence of a candidate being an opinion tar-
get (opinion word) should mostly be determined
by its word preferences rather than all words hav-
ing opinion relations with it. For example
‚ÄúThis camera‚Äôs price is expensive for me.‚Äù
‚ÄúIt‚Äôs price is good.‚Äù
‚ÄúCanon 40D has a good price.‚Äù
In these three sentences, ‚Äúprice‚Äù is modified by
‚Äúgood‚Äù more times than ‚Äúexpensive‚Äù. In tradi-
tional extraction strategy, opinion associations are
usually computed based on the co-occurrence fre-
quency. Thus, ‚Äúgood‚Äù has more strong opinion
association with ‚Äúprice‚Äù than ‚Äúexpensive‚Äù, and it
would have more contributions on determining
‚Äúprice‚Äù to be an opinion target or not. It‚Äôs un-
reasonable. ‚ÄúExpensive‚Äù actually has more re-
latedness with ‚Äúprice‚Äù than ‚Äúgood‚Äù, and ‚Äúexpen-
sive‚Äù is likely to be a word preference for ‚Äúprice‚Äù.
The confidence of ‚Äúprice‚Äù being an opinion target
should be influenced by ‚Äúexpensive‚Äù in greater ex-
tent than ‚Äúgood‚Äù. In this way, we argue that the
extraction will be more precise.
Figure 1: Heterogeneous Graph: OC means opin-
ion word candidates. TC means opinion target
candidates. Solid curves and dotted lines respec-
tively mean semantic relations and opinion rela-
tions between two candidates.
Thus, to resolve these two problems, we present
a novel approach with graph co-ranking. The col-
lective extraction of opinion targets/words is per-
formed in a co-ranking process. First, we oper-
ate over a heterogeneous graph to model seman-
tic relations and opinion relations into a unified
model. Specifically, our heterogeneous graph is
composed of three subgraphs which model differ-
ent relation types and candidates, as shown in Fig-
ure 1. The first subgraph Ga represents semantic
relations among opinion target candidates, and the
second subgraph G&amp;quot; models semantic relations
among opinion word candidates. The third part
is a bipartite subgraph G&amp;quot;, which models opinion
relations among different candidate types and con-
nects the above two subgraphs together. Then we
perform a random walk algorithm on Ga, G&amp;quot; and
G&amp;quot; separately, to estimate all candidates‚Äô confi-
dence, and the entries with higher confidence than
a threshold are correspondingly extracted as opin-
ion targets/words. The results could reflect which
type of relation is more useful for the extraction.
Second, a co-ranking algorithm, which incor-
porates three separate random walks on Ga, G&amp;quot;
and G&amp;quot; into a unified process, is proposed to
perform candidate confidence estimation. Differ-
ent relations may cooperatively affect candidate
confidence estimation and generate more global
ranking results. Moreover, we discover each can-
didate‚Äôs preferences through topics. Such word
preference will be different for different candi-
dates. We add word preference information into
our algorithm and make our co-ranking algorithm
be personalized. A candidate‚Äôs confidence would
mainly absorb the contributions from its word
preferences rather than its all neighbors with opin-
ion relations, which may be beneficial for improv-
ing extraction precision.
We perform experiments on real-world datasets
from different languages and different domains.
Results show that our approach effectively im-
proves extraction performance compared to the
state-of-the-art approaches.
</bodyText>
<sectionHeader confidence="0.999786" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999966307692308">
There are many significant research efforts on
opinion targets/words extraction (sentence level
and corpus level). In sentence level extraction,
previous methods (Wu et al., 2009; Ma and Wan,
2010; Li et al., 2010; Yang and Cardie, 2013)
mainly aimed to identify all opinion target/word
mentions in sentences. They regarded it as a se-
quence labeling task, where several classical mod-
els were used, such as CRFs (Li et al., 2010) and
SVM (Wu et al., 2009).
This paper belongs to corpus level extraction,
and aims to generate a sentiment lexicon and a
target list rather than to identify mentions in sen-
</bodyText>
<equation confidence="0.785666363636364">
ùê∫ùê∫ùë°ùë°ùë°ùë°
ùëáùëáùëÇùëÇ1
ùëÇùëÇùëÇùëÇ1 ùëÇùëÇùëÇùëÇ2 ùëÇùëÇùëÇùëÇ3 ùëÇùëÇùëÇùëÇ4 ùëÇùëÇùëÇùëÇ5 ùëÇùëÇùëÇùëÇ6
ùê∫ùê∫ùëúùëúùëúùëú
ùê∫ùê∫ ùë°ùë°ùëúùëú
ùëáùëáùëÇùëÇ2
ùëáùëáùëÇùëÇ3
ùëáùëáùëÇùëÇ4
ùëáùëáùëÇùëÇ5
ùëáùëáùëÇùëÇ6
315
</equation>
<bodyText confidence="0.999969327272727">
tences. Most of previous corpus-level methods
adopted a co-extraction framework, where opin-
ion targets and opinion words reinforce each other
according to their opinion relations. Thus, how
to improve opinion relations identification perfor-
mance was their main focus. (Hu and Liu, 2004a)
exploited nearest neighbor rules to mine opinion
relations among words. (Popescu and Etzioni,
2005) and (Qiu et al., 2011) designed syntactic
patterns to perform this task. (Zhang et al., 2010)
promoted Qiu‚Äôs method. They adopted some spe-
cial designed patterns to increase recall. (Liu et
al., 2012; Liu et al., 2013a; Liu et al., 2013b) em-
ployed word alignment model to capture opinion
relations rather than syntactic parsing. The exper-
imental results showed that these alignment-based
methods are more effective than syntax-based ap-
proaches for online informal texts. However, all
aforementioned methods only employed opinion
relations for the extraction, but ignore consider-
ing semantic relations among homogeneous can-
didates. Moreover, they all ignored word prefer-
ence in the extraction process.
In terms of considering semantic relations
among words, our method is related with sev-
eral approaches based on topic model (Zhao et
al., 2010; Moghaddam and Ester, 2011; Moghad-
dam and Ester, 2012a; Moghaddam and Ester,
2012b; Mukherjee and Liu, 2012). The main
goals of these methods weren‚Äôt to extract opin-
ion targets/words, but to categorize all given as-
pect terms and sentiment words. Although these
models could be used for our task according to the
associations between candidates and topics, solely
employing semantic relations is still one-sided and
insufficient to obtain expected performance.
Furthermore, there is little work which consid-
ered these two types of relations globally (Su et
al., 2008; Hai et al., 2012; Bross and Ehrig, 2013).
They usually captured different relations using co-
occurrence information. That was too coarse to
obtain expected results (Liu et al., 2012). In ad-
dition, (Hai et al., 2012) extracted opinion tar-
gets/words in a bootstrapping process, which had
an error propagation problem. In contrast, we per-
form extraction with a global graph co-ranking
process, where error propagation can be effec-
tively alleviated. (Su et al., 2008) used heteroge-
neous relations to find implicit sentiment associ-
ations among words. Their aim was only to per-
form aspect terms categorization but not to extract
opinion targets/words. They extracted opinion tar-
gets/words in advanced through simple phrase de-
tection. Thus, the extraction performance is far
from expectation.
</bodyText>
<sectionHeader confidence="0.990412" genericHeader="method">
3 The Proposed Method
</sectionHeader>
<bodyText confidence="0.999192483870968">
In this section, we propose our method in detail.
We formulate opinion targets/words extraction as
a co-ranking task. All nouns/noun phrases are re-
garded as opinion target candidates, and all ad-
jectives/verbs are regarded as opinion word candi-
dates, which are widely adopted by pervious meth-
ods (Hu and Liu, 2004a; Qiu et al., 2011; Wang
and Wang, 2008; Liu et al., 2012). Then each can-
didate will be assigned a confidence and ranked,
and the candidates with higher confidence than a
threshold will be extracted as the results.
Different from traditional methods, besides
opinion relations among words, we additionally
capture semantic relations among homogeneous
candidates. To this end, a heterogeneous undi-
rected graph G = (V, E) is constructed. V =
V t U V o denotes the vertex set, which includes
opinion target candidates vt E V t and opinion
word candidates vo E V o. E denotes the edge
set, where eij E E means that there is a relation
between two vertices. Ett C E represents the se-
mantic relations between two opinion target candi-
dates. Eoo C E represents the semantic relations
between two opinion word candidates. Eto C E
represents the opinion relations between opinion
target candidates and opinion word candidates.
Based on different relation types, we used three
matrices Mtt E R|V t|√ó|V t|, Moo E R|V o|√ó|V o|
and Mto E R|V t|√ó|V o |to record the association
weights between any two vertices, respectively.
Section 3.4 will illustrate how to construct them.
</bodyText>
<subsectionHeader confidence="0.998963">
3.1 Only Considering Opinion Relations
</subsectionHeader>
<bodyText confidence="0.99951425">
To estimate the confidence of each candidate, we
use a random walk algorithm on our graph to per-
form co-ranking. Most previous methods (Hu and
Liu, 2004a; Qiu et al., 2011; Wang and Wang,
2008; Liu et al., 2012) only considered opinion
relations among words. Their basic assumption is
as follows.
Assumption 1: If a word is likely to
be an opinion word, the words which
it has opinion relation with will have
higher confidence to be opinion targets,
and vice versa.
</bodyText>
<page confidence="0.797986">
316
</page>
<bodyText confidence="0.98758075">
In this way, candidates‚Äô confidences (vt or vo) are
collectively determined by each other iteratively.
It equals to making random walk on subgraph
Gto = (V, Eto) of G. Thus we have
</bodyText>
<equation confidence="0.998239333333333">
Ct = (1 ‚àí ¬µ) x Mto x Co + ¬µ x It
(1)
Co = (1 ‚àí ¬µ) x MT to x Ct + ¬µ x Io
</equation>
<bodyText confidence="0.9884556875">
where Ct and Co respectively represent confi-
dences of opinion targets and opinion words.
mto
i,j E Mto means the association weight between
the ith opinion target and the jth opinion word ac-
cording to their opinion relations.
It‚Äôs worthy noting that It and Io respectively de-
note prior confidences of opinion target candidates
and opinion word candidates. We argue that opin-
ion targets are usually domain-specific, and there
are remarkably distribution difference of them on
different domains (in-domain Din vs. out-domain
Dout). If a candidate is salient in Din but common
in Dout, it‚Äôs likely to be an opinion target in Din.
Thus, we use a domain relevance measure (DR)
(Hai et al., 2013) to compute It.
</bodyText>
<equation confidence="0.9746737">
R(t, Din)
DR(t) = (2)
R(t, Dout)
N 1
x EN 1(wtj ‚àí 1Wj
x
EWj
k=1 wkj) represents candidate relevance with
domain D. wtj = (1 + logTFtj) x log N
DFt
</equation>
<bodyText confidence="0.877753714285714">
is a TF-IDF-like weight of candidate t in doc-
ument j. TFtj is the frequency of the candi-
date t in the jth document, and DFt is docu-
ment frequency. N means the document num-
ber in domain D. R(t, D) includes two mea-
sures to reflect the salient of a candidate in D. 1)
wtj ‚àí Wj x ÔøΩWj
1 k=1 wkj reflects how frequently a
term is mentioned in a particular document. Wj
wt
st
quantifies how significantly a term is mentioned
across all documents in D. ¬Øwt = 1Nx ENk=1 wtk
denotes average weight across all documents for
</bodyText>
<equation confidence="0.887627">
ÔøΩ 1 N x ÔøΩN
t. st = j=1 (wtj ‚àí ¬Øwj)2 denotes the
</equation>
<bodyText confidence="0.999784625">
standard variance of term t. We use the given
reviews as in-domain collection Din and Google
n-gram corpus1 as out-domain collection Dout.
Finally, each entry in It is a normalized DR(t)
score. In contrast, opinion words are usually
domain-independent. Users may use same words
to express theirs opinions, like ‚Äúgood‚Äù, ‚Äúbad‚Äù, etc.
But there are still some domain-dependent opinion
</bodyText>
<footnote confidence="0.325604">
1http://books.google.com/ngrams/datasets
</footnote>
<bodyText confidence="0.999981166666667">
words, like ‚Äúdelicious‚Äù in the restaurant domain,
‚Äúpowerful‚Äù in the car domain. It‚Äôs difficult to dis-
criminate them from other words by using statisti-
cal information. So we simply set all entries in Io
to be 1. ¬µ E [0, 1] in Eq.1 determines the impact
of the prior confidence on results.
</bodyText>
<subsectionHeader confidence="0.999561">
3.2 Only Considering Semantic Relations
</subsectionHeader>
<bodyText confidence="0.998170285714286">
To estimate candidates‚Äô confidences by only con-
sidering semantic relations among words, we
make two separately random walks on the sub-
graphs of G, Gtt = (V, Ett) and Goo = (V, Eoo).
The basic assumption is as follows:
Assumption 2: If a word is likely to
be an opinion target (opinion word), the
words which it has strong semantic rela-
tion with will have higher confidence to
be opinion targets (opinion words).
In this way, the confidence of the candidate is
determined only by its homogeneous neighbours.
There is no mutual reinforcement between opinion
targets and opinion words. Thus we have
</bodyText>
<equation confidence="0.917124">
Ct = (1 ‚àí ŒΩ) x Mtt x Ct + ŒΩ x It
(3)
Co = (1 ‚àí ŒΩ)
x Moo x Co + ŒΩ x Io
ŒΩ
Eq.1.
</equation>
<bodyText confidence="0.972399454545455">
where
has the same role as ¬µ in
confidence is collectively
determined by its neighbours according to differ-
ent relation types. Meanwhile, each item may
make influence on
neighbours.
an
candidate‚Äôs
it‚Äôs
It‚Äôs
</bodyText>
<equation confidence="0.8766535">
iterative
reinforcement process. Thus, we have
Ct = (1 ‚àí A ‚àí ¬µ) x Mto x Co
+AxMttxCt+¬µx It
Co = (1 ‚àí A ‚àí ¬µ) x MTto xCt
+ A x Moo x Co + ¬µ x Io
</equation>
<subsectionHeader confidence="0.998683">
3.3 Considering Semantic Relations and
Opinion Relations Together
</subsectionHeader>
<bodyText confidence="0.82360819047619">
To jointly model semantic relations and opinion
relations for opinion targets/words extraction, we
couple two random walking algorithms mentioned
above together. Here, Assumption 1 and As-
sumption 2 are both satisfied. Thus, an opinion
target/word
where A E [0, 1] determines which type of rela-
tions dominates candidate confidence estimation.
A = 0 means that each
confidence
is estimated by only considering opinion relations
among words, which equals to
Otherwise,
when A = 1, can
candidate‚Äôs
Eq.1.
didate confidence estimation only
where R(t, D) =
¬Øwt
st
denotes the word number in document j. 2)
</bodyText>
<equation confidence="0.226155">
(4)
317
</equation>
<bodyText confidence="0.979255178571428">
considers semantic relations among words, which
equals to Eq.3. ¬µ, Io and It have the same meaning
in Eq.1. Our algorithm will run iteratively until it
converges or in a fixed iteration number Iter. In
experiments, we set Iter = 200.
Obtaining Word Preference. The co-ranking
algorithm in Eq.4 is based on a standard random
walking algorithm, which randomly selects a link
according to the association matrix Mto, Mtt and
Moo, or jumps to a random node with prior confi-
dence value. However, it generates a global rank-
ing over all candidates without taking the node
preference (word preference) into account. As
mentioned in the first section, each opinion tar-
get/word has its preferred collocations, it‚Äôs reason-
able that the confidence of an opinion target (opin-
ion word) candidate should be preferentially de-
termined by its preferences, rather than all of its
neighbors with opinion relations.
To obtain the word preference, we resort to top-
ics. We believe that if an opinion word vio is
topical related with a target word vjt, vio can be
regarded as a word preference for vjt, and vice
versa. For example, ‚Äúprice‚Äù and ‚Äúexpensive‚Äù are
topically related in phone‚Äôs domain, so they are a
word preference for each other.
Specifically, we use a vector PTi =
[PTi
</bodyText>
<equation confidence="0.956933">
1 ,...,PTi
k ,...,P Ti
</equation>
<bodyText confidence="0.878683363636364">
|V o|]1√ó|V o |to represent word
preference of the ith opinion target candidate.
PTi
k means the preferred probability of the ith
potential opinion target for the kth potential
opinion words. To compute
PTi
k , we first use
Kullback-Leibler divergence to measure the
semantic distance between any two candidates on
the bridge of topics. Thus, we have
</bodyText>
<equation confidence="0.763640833333333">
1
D(vi,vj) = 2Œ£z(KLz(viJJvj) + KLz(vjJJvi))
where KLz(viJJvj) = p(zJvi)log pÔøΩz|vi) means the
z|vj)
KL-divergence from candidate vi to vj based on
topic z. p(zJv) = p(vJz)p(z)
</equation>
<bodyText confidence="0.9976112">
p(v), where p(vJz) is the
probability of the candidate v to topic z (see Sec-
tion 3.4). p(z) is the probability that topic z in
reviews. p(v) is the probability that a candidate
occurs in reviews. Then, a logistic function is used
</bodyText>
<equation confidence="0.894092666666667">
to map D(vi, vj) into [0, 1].
1
SA(vi, vj) = (5)
1 + eD(vi,vj)
Then, we calculate P Ti
k by normalize SA(vi, vj)
score, i.e. PTi = SA(vi,vk) For demon-
k E|V o |SA(vt vo)
p=1 i,p
</equation>
<bodyText confidence="0.993893">
stration, we give some examples in Table 1, where
each entry denotes a SA(vi, vj) score between two
candidates. We can see that using topics can suc-
cessfully capture the preference information for
each opinion target/word.
</bodyText>
<table confidence="0.99094775">
expensive good long colorful
price 0.265 0.043 0.003 0.000
LED 0.002 0.035 0.007 0.098
battery 0.000 0.015 0.159 0.001
</table>
<tableCaption confidence="0.993801">
Table 1: Examples of Calculated Word Preference
</tableCaption>
<bodyText confidence="0.652106">
And we use a vector POj =
</bodyText>
<equation confidence="0.5804695">
[POj 1 , ...,POj q, ..., POj
|V t|]1√ó|V t |to represent
</equation>
<bodyText confidence="0.9224515">
the preference information of the jth opin-
ion word candidate. Similarly, we have
</bodyText>
<equation confidence="0.967072">
P Oj
q = SA(vt q,vo j ) E|V t |j).
k=1 SA(vt k,vo
</equation>
<bodyText confidence="0.973642272727273">
Incorporating Word Preference into Co-
ranking. To consider such word preference in
our co-ranking algorithm, we incorporate it into
the random walking on Gto. Intuitively, prefer-
ence vectors will be different for different can-
didates. Thus, the co-ranking algorithm would
be personalized. It allows that the candidate
confidence propagates to other candidates only
in its preference cluster. Specifically, we make
modification on original transition matrix Mto =
(Mto
</bodyText>
<equation confidence="0.9942528">
1 , Mto
2 , ..., Mto
|V t|) and add each candidate‚Äôs
ÀÜMto
1 , ÀÜMto
</equation>
<bodyText confidence="0.849566222222222">
2 ,..., ÀÜMto |V t|)
be the modified transition matrix, which records
the associations between opinion target candi-
dates and opinion word candidates. Here Mto
k E
R1√ó|V o |and ÀÜMto kE R1√ó|V o |denotes the kth col-
umn vector in Mto and ÀÜMto, respectively. And
let Diag(PTk) denote a diagonal matrix whose
eigenvalue is vector PTk, we have
</bodyText>
<equation confidence="0.990460666666667">
ÀÜMto
k = Mto
k Diag(PTk)
Similarly, let Uto
k E R1√ó|V t |and ÀÜUto
k E R1√ó|V t|
</equation>
<bodyText confidence="0.745042666666667">
denotes the kth row vector in MTto and ÀÜMTto, re-
spectively. Diag(POk) denote a diagonal matrix
whose eigenvalue is vector POk. Then we have
</bodyText>
<equation confidence="0.988154666666667">
ÀÜUto
k = Uto
k Diag(POk)
</equation>
<bodyText confidence="0.958440666666667">
In this way, each candidate‚Äôs preference is in-
corporated into original associations based on
opinion relation Mto through Diag(POk) and
Diag(PTk). And candidates‚Äô confidences will
mainly come from the contributions of its prefer-
ences. Thus, Ct and Co in Eq.4 become:
</bodyText>
<equation confidence="0.668000833333333">
preference in it. Let ÀÜMto = (
318
Ct = (1 ‚àí Œª ‚àí ¬µ) x ÀÜMto x Co
+ Œª x Mtt x Ct + ¬µ x It
Co = (1 ‚àí Œª ‚àí ¬µ) x ÀÜMTto x Ct
+ Œª x Moo x Co + ¬µ x Io
</equation>
<subsectionHeader confidence="0.9833525">
3.4 Capturing Semantic and Opinion
Relations
</subsectionHeader>
<bodyText confidence="0.99536468">
In this section, we explain how to capture seman-
tic relations and opinion relations for constructing
transition matrices Mtt, Moo and Mto.
Capturing Semantic Relations: For captur-
ing semantic relations among homogenous candi-
dates, we employ topics. We believe that if two
candidates share similar topics in the corpus, there
is a strong semantic relation between them. Thus,
we employ a LDA variation (Mukherjee and Liu,
2012), an extension of (Zhao et al., 2010), to dis-
cover topic distribution on words, which sampled
all words into two separated observations: opinion
targets and opinion words. It‚Äôs because that we are
only interested in topic distribution of opinion tar-
gets/words, regardless of other useless words, in-
cluding conjunctions, prepositions etc. This model
has been proven to be better than the standard
LDA model and other LDA variations for opinion
mining (Mukherjee and Liu, 2012).
After topic modeling, we obtain the proba-
bility of the candidates (vt and vo) to topic z,
i.e. p(z|vt) and p(z|vo), and topic distribution
p(z). Then, a symmetric Kullback-Leibler diver-
gence as same as Eq.5 is used to calculate the se-
mantical associations between any two homoge-
nous candidates. Thus, we obtain SA(vt, vt) and
SA(vo, vo), which correspond to the entries in
Mtt and Moo, respectively.
Capturing Opinion Relations: To capture
opinion relations among words and construct the
transition matrix Mto, we used an alignment-
based method proposed in (Liu et al., 2013b).
This approach models capturing opinion relations
as a monolingual word alignment process. Each
opinion target can find its corresponding mod-
ifiers in sentences through alignment, in which
multiple factors are considered globally, such as
co-occurrence information, word position in sen-
tence, etc. Moreover, this model adopted a par-
tially supervised framework to combine syntac-
tic information with alignment results, which has
been proven to be more precise than the state-of-
the-art approaches for opinion relations identifica-
tion (Liu et al., 2013b).
After performing word alignment, we obtain
a set of word pairs composed of a noun (noun
phrase) and its corresponding modified word.
Then, we simply employ Pointwise Mutual Infor-
mation (PMI) to calculate the opinion associations
among words as the entries in Mto. OA(vt, vo) =
</bodyText>
<equation confidence="0.708791">
log p(vt,vo)
</equation>
<bodyText confidence="0.999274428571429">
p(vt)p(vo), where vt and vo denote an opinion
target candidate and an opinion word candidate,
respectively. p(vt, vo) is the co-occurrence prob-
ability of vt and vo based on the opinion relation
identification results. p(vt) and p(vo) give the in-
dependent occurrence probability of of vt and vo,
respectively
</bodyText>
<sectionHeader confidence="0.999855" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.998979">
4.1 Datasets and Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999099730769231">
Datasets: To evaluate the proposed method, we
used three datasets. The first one is Customer
Review Datasets (CRD), used in (Hu and Liu,
2004a), which contains reviews about five prod-
ucts. The second one is COAE2008 dataset22,
which contains Chinese reviews about four prod-
ucts. The third one is Large, also used in (Wang
et al., 2011; Liu et al., 2012; Liu et al., 2013a),
where two domains are selected (Mp3 and Hotel).
As mentioned in (Liu et al., 2012), Large con-
tains 6,000 sentences for each domain. Opinion
targets/words are manually annotated, where three
annotators were involved. Two annotators were
required to annotate out opinion words/targets in
reviews. When conflicts occur, the third annota-
tor make final judgement. In total, we respectively
obtain 1,112, 1,241 opinion targets and 334, 407
opinion words in Hotel, MP3.
Pre-processing: All sentences are tagged to
obtain words‚Äô part-of-speech tags using Stanford
NLP tool3. And noun phrases are identified using
the method in (Zhu et al., 2009) before extraction.
Evaluation Metrics: We select precision(P),
recall(R) and f-measure(F) as metrics. And a sig-
nificant test is performed, i.e., a t-test with a de-
fault significant level of 0.05.
</bodyText>
<sectionHeader confidence="0.4633515" genericHeader="method">
4.2 Our Method vs. The State-of-the-art
Methods
</sectionHeader>
<bodyText confidence="0.999567333333333">
To prove the effectiveness of the proposed method,
we select some state-of-the-art methods for com-
parison as follows:
</bodyText>
<figure confidence="0.368794">
2http://ir-china.org.cn/coae2008.html
3http://nlp.stanford.edu/software/tagger.shtml
(6)
</figure>
<page confidence="0.547024">
319
</page>
<table confidence="0.9987238">
Methods D1 D2 D3 D4 D5 Avg.
P R F P R F P R F P R F P R F F
Hu 0.75 0.82 0.78 0.71 0.79 0.75 0.72 0.76 0.74 0.69 0.82 0.75 0.74 0.80 0.77 0.758
DP 0.87 0.81 0.84 0.90 0.81 0.85 0.90 0.86 0.88 0.81 0.84 0.82 0.92 0.86 0.89 0.856
Zhang 0.83 0.84 0.83 0.86 0.85 0.85 0.86 0.88 0.87 0.80 0.85 0.82 0.86 0.86 0.86 0.846
SAS 0.80 0.79 0.79 0.82 0.76 0.79 0.79 0.74 0.76 0.77 0.78 0.77 0.80 0.76 0.78 0.778
Liu 0.84 0.85 0.84 0.87 0.85 0.86 0.88 0.89 0.88 0.81 0.85 0.83 0.89 0.87 0.88 0.858
Hai 0.77 0.87 0.83 0.79 0.86 0.82 0.79 0.89 0.84 0.72 0.88 0.79 0.74 0.88 0.81 0.818
CR 0.84 0.86 0.85 0.87 0.85 0.86 0.87 0.90 0.88 0.81 0.87 0.83 0.89 0.88 0.89 0.862
CR WP 0.86 0.86 0.86 0.88 0.86 0.87 0.89 0.90 0.89 0.81 0.87 0.83 0.91 0.89 0.90 0.870
</table>
<tableCaption confidence="0.983415">
Table 2: Results of Opinion Targets Extraction on Customer Review Dataset
</tableCaption>
<table confidence="0.9986353">
Methods Camera Car Laptop Phone Mp3 Hotel Avg.
P R F P R F P R F P R F P R F P R F F
Hu 0.63 0.65 0.64 0.62 0.58 0.60 0.51 0.67 0.58 0.69 0.60 0.64 0.61 0.68 0.64 0.60 0.65 0.62 0.587
DP 0.71 0.70 0.70 0.72 0.65 0.68 0.58 0.69 0.63 0.78 0.66 0.72 0.69 0.70 0.69 0.67 0.69 0.68 0.683
Zhang 0.71 0.78 0.74 0.69 0.68 0.68 0.57 0.80 0.67 0.80 0.71 0.75 0.67 0.77 0.72 0.67 0.76 0.71 0.712
SAS 0.72 0.72 0.72 0.71 0.64 0.67 0.59 0.72 0.65 0.78 0.69 0.73 0.69 0.75 0.72 0.69 0.74 0.71 0.700
Liu 0.75 0.81 0.78 0.71 0.71 0.71 0.61 0.85 0.71 0.83 0.74 0.78 0.70 0.82 0.76 0.71 0.80 0.75 0.749
Hai 0.68 0.84 0.76 0.69 0.75 0.72 0.58 0.86 0.72 0.75 0.76 0.76 0.65 0.83 0.74 0.62 0.82 0.75 0.742
CR 0.75 0.83 0.79 0.72 0.74 0.73 0.60 0.85 0.70 0.83 0.77 0.80 0.70 0.84 0.76 0.71 0.83 0.77 0.758
CR WP 0.78 0.84 0.81 0.74 0.75 0.74 0.64 0.85 0.73 0.84 0.76 0.80 0.74 0.84 0.79 0.74 0.82 0.78 0.773
</table>
<tableCaption confidence="0.999926">
Table 3: Results of Opinion Targets Extraction on COAE 2008 and Large
</tableCaption>
<bodyText confidence="0.999822448979592">
Hu extracted opinion targets/words using asso-
ciation mining rules (Hu and Liu, 2004a).
DP used syntax-based patterns to capture opin-
ion relations in sentences, and then used a boot-
strapping process to extract opinion targets/words
(Qiu et al., 2011),.
Zhang is proposed by (Zhang et al., 2010).
They also used syntactic patterns to capture opin-
ion relations between words. Then a HITS (Klein-
berg, 1999) algorithm is employed to extract opin-
ion targets.
Liu is proposed by (Liu et al., 2013a), an ex-
tension of (Liu et al., 2012). They employed a
word alignment model to capture opinion relations
among words, and then used a random walking al-
gorithm to extract opinion targets.
Hai is proposed by (Hai et al., 2012), which is
similar to our method. They employed both of se-
mantic relations and opinion relations to extract
opinion words/targets in a bootstrapping frame-
work. But they captured relations only using co-
occurrence statistics. Moreover, word preference
was not considered.
SAS is proposed by (Mukher ee and Liu, 2012),
an extended lda-based model of (Zhao et al.,
2010). The top K items for each aspect are ex-
tracted as opinion targets/words. It means that
only semantic relations among words are consid-
ered in SAS. And we set aspects number to be 9 as
same as (Mukher ee and Liu, 2012).
CR: is the proposed method in this paper by us-
ing co-ranking, referring to Eq.4. CR doesn‚Äôt con-
sider word preference.
CR WP: is the full implementation of our
method, referring to Eq.6.
Hu, DP, Zhang and Liu are the methods which
only consider opinion relations among words.
SAS is the methods which only consider seman-
tic relations among words. Hai, CR and CR WP
consider these two types of relations together. The
parameter settings of state-of-the-art methods are
same as their original paper. In CR and CR WP,
we set A = 0.4 and ¬µ = 0.1. The experimental
results are shown in Table 2, 3, 4 and 5, where the
last column presents the average F-measure scores
for multiple domains. Since Liu and Zhang aren‚Äôt
designed for opinion words extraction, we don‚Äôt
present their results in Table 4 and 5. From exper-
imental results, we can see.
</bodyText>
<listItem confidence="0.956612571428572">
1) Our methods (CR and CR WP) outperform
other methods not only on opinion targets extrac-
tion but on opinion words extraction in most do-
mains. It proves the effectiveness of the proposed
method.
2) CR and CR WP have much better perfor-
mance than Liu and Zhang, especially on Recall.
Liu and Zhang also use a ranking framework like
ours, but they only employ opinion relations for
extraction. In contrast, besides opinion relations,
CR and CR WP further take semantic relations
into account. Thus, more opinion targets/words
can be extracted. Furthermore, we observe that
CR and CR WP outperform SAS. SAS only ex-
ploits semantic relations, but ignores opinion re-
lations among words. Its extraction is performed
separately and neglects the reinforcement between
opinion targets and opinion words. Thus, SAS has
worse performance than our methods. It demon-
strates the usefulness of considering multiple rela-
tion types.
</listItem>
<table confidence="0.956863222222222">
320
Methods D1 D2 D3 D4 D5 Avg.
P R F P R F P R F P R F P R F F
Hu 0.57 0.75 0.65 0.51 0.76 0.61 0.57 0.73 0.64 0.54 0.62 0.58 0.62 0.67 0.64 0.624
DP 0.64 0.73 0.68 0.57 0.79 0.66 0.65 0.70 0.67 0.61 0.65 0.63 0.70 0.68 0.69 0.666
SAS 0.64 0.68 0.66 0.55 0.70 0.62 0.62 0.65 0.63 0.60 0.61 0.60 0.68 0.63 0.65 0.632
Hai 0.62 0.77 0.69 0.52 0.80 0.64 0.60 0.74 0.67 0.56 0.69 0.62 0.66 0.70 0.68 0.660
CR 0.62 0.75 0.68 0.57 0.79 0.67 0.64 0.75 0.69 0.63 0.69 0.66 0.68 0.69 0.69 0.678
CR WP 0.65 0.75 0.70 0.59 0.80 0.68 0.65 0.74 0.70 0.66 0.68 0.67 0.71 0.70 0.70 0.690
</table>
<tableCaption confidence="0.995294">
Table 4: Results of Opinion Words Extraction on Customer Review Dataset
</tableCaption>
<table confidence="0.997924625">
Methods Camera Car Laptop Phone Mp3 Hotel Avg.
P R F P R F P R F P R F P R F P R F F
Hu 0.72 0.74 0.73 0.70 0.71 0.70 0.66 0.70 0.68 0.70 0.70 0.70 0.48 0.67 0.56 0.52 0.69 0.59 0.660
DP 0.80 0.73 0.76 0.79 0.71 0.75 0.75 0.69 0.72 0.78 0.68 0.73 0.60 0.65 0.62 0.61 0.66 0.63 0.702
SAS 0.73 0.70 0.71 0.75 0.68 0.71 0.72 0.68 0.69 0.71 0.66 0.68 0.64 0.62 0.63 0.66 0.61 0.63 0.675
Hai 0.76 0.74 0.75 0.72 0.74 0.73 0.69 0.72 0.70 0.72 0.70 0.71 0.61 0.69 0.64 0.59 0.68 0.64 0.690
CR 0.80 0.75 0.77 0.77 0.74 0.75 0.73 0.71 0.72 0.75 0.71 0.73 0.63 0.69 0.64 0.63 0.68 0.66 0.710
CR WP 0.80 0.75 0.77 0.80 0.74 0.77 0.77 0.71 0.74 0.78 0.72 0.75 0.66 0.68 0.67 0.67 0.69 0.68 0.730
</table>
<tableCaption confidence="0.998924">
Table 5: Results of Opinion Words Extraction on COAE 2008 and Large
</tableCaption>
<listItem confidence="0.875081333333333">
3) CR and CR WP both outperform Hai. We
believe the reasons are as follows. First, CR and
CR WP considers multiple relations in a unified
process by using graph co-ranking. In contrast,
Hai adopts a bootstrapping framework which per-
forms extraction step by step and may have the
problem of error propagation. It demonstrates
that our graph co-ranking is more suitable for this
task than bootstrapping-based strategy. Second,
our method captures semantic relations using topic
modeling and captures opinion relations through
word alignments, which are more precise than Hai
which merely uses co-occurrence information to
indicate such relations among words. In addition,
word preference is not handled in Hai, but pro-
cessed in CR WP. The results show the usefulness
of word preference for opinion targets/words ex-
traction.
4) CR WP outperforms CR, especially on pre-
cision. The only difference between them is that
CR WP considers word preference when perform-
ing graph ranking for candidate confidence esti-
mation, but CR does not. Each candidate confi-
dence estimation in CR WP gives more weights
</listItem>
<bodyText confidence="0.9831315">
for this candidate‚Äôs preferred words than CR.
Thus, the precision can be improved.
</bodyText>
<subsectionHeader confidence="0.991806">
4.3 Semantic Relation vs. Opinion Relation
</subsectionHeader>
<bodyText confidence="0.999884333333333">
In this section, we discuss which relation type
is more effective for this task. For comparison,
we design two baselines, called OnlySA and On-
lyOA. OnlyOA only employs opinion relations
among words, which equals to Eq.1. OnlySA only
employs semantic relations among words, which
equals to Eq.3. Moreover, Combine is our method
which considers both of opinion relations and se-
mantic relations together, referring to Eq.4 with
</bodyText>
<figure confidence="0.728888">
(e) Opinion Word Extraction Results
</figure>
<figureCaption confidence="0.910144">
Figure 2: Semantic Relations vs. Opinion Rela-
tions
</figureCaption>
<bodyText confidence="0.999982375">
Œª = 0.5. Figure 2 presents experimental results.
The left graph presents opinion targets extraction
results and the right graph presents opinion words
extraction results. Because of space limitation, we
only shown the results of four domains (MP3, Ho-
tel, Laptop and Phone).
From results, we observe that OnlyOA outper-
forms OnlySA in all domains. It demonstrates
that employing opinion relations are more useful
than semantic relations for co-extracting opinion
targets/words. And it is necessary to utilize the
mutual reinforcement relationship between opin-
ion words and opinion targets. Moreover, Com-
bine outperforms OnlySA and OnlyOA in all do-
mains. It indicates that combining different rela-
tions among words together is effective.
</bodyText>
<subsectionHeader confidence="0.9667615">
4.4 The Effectiveness of Considering Word
Preference
</subsectionHeader>
<bodyText confidence="0.999085333333333">
In this section, we try to prove the necessity of
considering word preference in Eq.6. Besides the
comparison between CR and CR WP performed
</bodyText>
<figure confidence="0.968266727272728">
.95
.90
OnlySA
OnlyOA
Combine
.85
.80
.75
.70
.65
MP3 Hotel Laptop Phone
(a) Opinion Target Extraction Results
.80
.75
OnlySA
OnlyOA
Combine
.70
.65
.60
MP3 Hotel Laptop Phone
321
</figure>
<bodyText confidence="0.998466333333333">
in the main experiment in Section 4.2, we fur-
ther incorporate word preference in aforemen-
tioned OnlyOA, named as OnlyOA WP, which
only employs opinion relations among words and
equals to Eq.6 with A = 0. Experimental results
are shown in Figure 3. Because of space limita-
tion, we only show the results of the same domains
in section 4.3,
Form results, we observe that CR WP out-
performs CR, and OnlyOA WP outperforms On-
lyOA in all domains, especially on precision.
These observations demonstrate that considering
word preference is very important for opinion tar-
gets/words extraction. We believe the reason is
that exploiting word preference can provide more
fine information for opinion target/word candi-
dates‚Äô confidence estimation. Thus the perfor-
mance can be improved.
</bodyText>
<figure confidence="0.981130857142857">
.90
.85
.80
.75
.70
.65
.60
</figure>
<bodyText confidence="0.918748111111111">
cial from their combination. In the right graphs in
Figure 4 and 5, the best performance is obtained
when ¬µ = 0.1. It indicates prior knowledge is
useful for extraction. When ¬µ increases, perfor-
mance, however, decreases. It demonstrates that
incorporating more prior knowledge into our al-
gorithm would restrain other useful clues on esti-
mating candidate confidence, and hurt the perfor-
mance.
</bodyText>
<figure confidence="0.988349727272727">
.85
.80
.75
.75
.70
MP3
Hotel
Laptop
Phone
.65
0.0 .1 .2 .3 .4 .5 .6 .7 .8 .9 0.0 .1 .2 .3 .4 .5 .6
</figure>
<figureCaption confidence="0.987781">
Figure 4: Opinion targets extraction results
</figureCaption>
<figure confidence="0.9988485">
.80
.75
.75
.70
.70
.65
.60
MP3
Hotel
Laptop
Phone
0.0 .1 .2 .3 .4 .5 .6 .7 .8 .9 0.0 .1 .2 .3 .4 .5 .6
Onl,OA
Onl,OA_WP
CR
CR_WP
.95
.90
.85
.80
.75
.70
OnlyOA
CR
CR_WP
.85
.80
.65
.60
MP3
Hotel
Laptop
Phone
.70
.80
.65
.60
.55
.55
.50
MP3
Hotel
Laptop
Phone
MP3 Hotel Laptop Phone MP3 Hotel Laptop Phone
(a) Opinion Target Extraction Results
.80
.75
.70
.65
.60
MP3 Hotel Laptop Phone MP3 Hotel Laptop Phone
(b) Opinion Word Extraction Results
OnlyOA_WP
</figure>
<figureCaption confidence="0.986698">
Figure 3: Experimental results when considering
word preference
</figureCaption>
<subsectionHeader confidence="0.975692">
4.5 Parameter Sensitivity
</subsectionHeader>
<bodyText confidence="0.9999475625">
In this subsection, we discuss the variation of ex-
traction performance when changing A and ¬µ in
Eq.6. Due to space limitation, we only show the
F-measure of CR WP on four domains. Experi-
mental results are shown in Figure 4 and Figure
5. The left graphs in Figure 4 and 5 present the
performance variation of CR WP with varying A
from 0 to 0.9 and fixing ¬µ = 0.1. The right graphs
in Figure 4 and 5 present the performance varia-
tion of CR WP with varying ¬µ from 0 to 0.6 and
fixing A = 0.4.
In the left graphs in Figure 4 and 5, we observe
the best performance is obtained when A = 0.4.
It indicates that opinion relations and semantic re-
lations are both useful for extracting opinion tar-
gets/words. The extraction performance is benefi-
</bodyText>
<figureCaption confidence="0.974366">
Figure 5: Opinion words extraction results
</figureCaption>
<sectionHeader confidence="0.999202" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999928">
This paper presents a novel method with graph co-
ranking to co-extract opinion targets/words. We
model extracting opinion targets/words as a co-
ranking process, where multiple heterogenous re-
lations are modeled in a unified model to make co-
operative effects on the extraction. In addition, we
especially consider word preference in co-ranking
process to perform more precise extraction. Com-
pared to the state-of-the-art methods, experimental
results prove the effectiveness of our method.
</bodyText>
<sectionHeader confidence="0.954503" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.996045125">
This work was sponsored by the National
Basic Research Program of China (No.
2014CB340500), the National Natural Sci-
ence Foundation of China (No. 61272332
and No. 61202329), the National High Tech-
nology Development 863 Program of China
(No. 2012AA011102), and CCF-Tencent Open
Research Fund.
</bodyText>
<sectionHeader confidence="0.970102" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.84132">
Juergen Bross and Heiko Ehrig. 2013. Automatic con-
struction of domain and aspect specific sentiment
</bodyText>
<figure confidence="0.998525769230769">
Onl,On
Onl,On_WP
CR
CR_WP
.80
.75
.70
.65
.60
OnlyOx
OnlyOx_WP
CR
CR_WP
</figure>
<reference confidence="0.998578073394496">
lexicons for customer review mining. In Proceed-
ings of the 22nd ACM international conference on
Conference on information &amp; knowledge man-
agement, CIKM ‚Äô13, pages 1077‚Äì1086, New York,
NY, USA. ACM.
Zhen Hai, Kuiyu Chang, and Gao Cong. 2012. One
seed to find them all: mining opinion features via
association. In CIKM, pages 255‚Äì264.
Zhen Hai, Kuiyu Chang, Jung-Jae Kim, and Christo-
pher C. Yang. 2013. Identifying features in opinion
mining via intrinsic and extrinsic domain relevance.
IEEE Transactions on Knowledge and Data Engi-
neering, 99(PrePrints):1.
Mingqin Hu and Bing Liu. 2004a. Mining opinion fea-
tures in customer reviews. In Proceedings of Con-
ference on Artificial Intelligence (AAAI).
Minqing Hu and Bing Liu. 2004b. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ‚Äô04, pages
168‚Äì177, New York, NY, USA. ACM.
Jon M. Kleinberg. 1999. Authoritative sources in a
hyperlinked environment. J. ACM, 46(5):604‚Äì632,
September.
Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu,
Yingju Xia, Shu Zhang, and Hao Yu. 2010.
Structure-aware review mining and summarization.
In Chu-Ren Huang and Dan Jurafsky, editors, COL-
ING, pages 653‚Äì661. Tsinghua University Press.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opin-
ions on the web. In Allan Ellis and Tatsuya Hagino,
editors, WWW, pages 342‚Äì351. ACM.
Kang Liu, Liheng Xu, and Jun Zhao. 2012. Opin-
ion target extraction using word-based translation
model. In Proceedings of the 2012 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 1346‚Äì1356, Jeju Island, Korea,
July. Association for Computational Linguistics.
Kang Liu, Liheng Xu, Yang Liu, and Jun Zhao. 2013a.
Opinion target extraction using partially supervised
word alignment model.
Kang Liu, Liheng Xu, and Jun Zhao. 2013b. Syntactic
patterns versus word alignment: Extracting opinion
targets from online reviews.
Tengfei Ma and Xiaojun Wan. 2010. Opinion tar-
get extraction in chinese news comments. In Chu-
Ren Huang and Dan Jurafsky, editors, COLING
(Posters), pages 782‚Äì790. Chinese Information Pro-
cessing Society of China.
Samaneh Moghaddam and Martin Ester. 2011. Ilda:
Interdependent lda model for learning latent aspects
and their ratings from online product reviews. In
Proceedings of the 34th International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, SIGIR ‚Äô11, pages 665‚Äì674, New
York, NY, USA. ACM.
Samaneh Moghaddam and Martin Ester. 2012a.
Aspect-based opinion mining from product reviews.
In Proceedings of the 35th International ACM SIGIR
Conference on Research and Development in In-
formation Retrieval, SIGIR ‚Äô12, pages 1184‚Äì1184,
New York, NY, USA. ACM.
Samaneh Moghaddam and Martin Ester. 2012b. On
the design of lda models for aspect-based opinion
mining. In CIKM, pages 803‚Äì812.
Arjun Mukherjee and Bing Liu. 2012. Aspect extrac-
tion through semi-supervised modeling. In Proceed-
ings of the 50th Annual Meeting of the Association
for Computational Linguistics: Long Papers - Vol-
ume 1, ACL ‚Äô12, pages 339‚Äì348, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Ana-Maria Popescu and Oren Etzioni. 2005. Ex-
tracting product features and opinions from reviews.
In Proceedings of the conference on Human Lan-
guage Technology and Empirical Methods in Natu-
ral Language Processing, HLT ‚Äô05, pages 339‚Äì346,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Che. 2009.
Expanding domain sentiment lexicon through dou-
ble propagation.
Guang Qiu, Bing Liu 0001, Jiajun Bu, and Chun Chen.
2011. Opinion word expansion and target extraction
through double propagation. Computational Lin-
guistics, 37(1):9‚Äì27.
Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian
Wu, Xiaoxun Zhang, Bin Swen, and Zhong Su.
2008. Hidden sentiment association in chinese web
opinion mining. In Jinpeng Huai, Robin Chen,
Hsiao-Wuen Hon, Yunhao Liu, Wei-Ying Ma, An-
drew Tomkins, and Xiaodong Zhang 0001, editors,
WWW, pages 959‚Äì968. ACM.
Bo Wang and Houfeng Wang. 2008. Bootstrapping
both product features and opinion words from chi-
nese customer reviews with cross-inducing.
Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011.
Latent aspect rating analysis without aspect key-
word supervision. In Chid Apt, Joydeep Ghosh,
and Padhraic Smyth, editors, KDD, pages 618‚Äì626.
ACM.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion min-
ing. In EMNLP, pages 1533‚Äì1541. ACL.
Bishan Yang and Claire Cardie. 2013. Joint infer-
ence for fine-grained opinion extraction. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
</reference>
<page confidence="0.722888">
323
</page>
<reference confidence="0.999641285714285">
Papers), pages 1640‚Äì1649, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn
O‚ÄôBrien-Strain. 2010. Extracting and ranking
product features in opinion documents. In Chu-
Ren Huang and Dan Jurafsky, editors, COLING
(Posters), pages 1462‚Äì1470. Chinese Information
Processing Society of China.
Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaom-
ing Li. 2010. Jointly modeling aspects and opin-
ions with a maxent-lda hybrid. In Proceedings of
the 2010 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP ‚Äô10, pages 56‚Äì
65, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and
Muhua Zhu. 2009. Multi-aspect opinion polling
from textual reviews. In David Wai-Lok Cheung,
Il-Yeol Song, Wesley W. Chu, Xiaohua Hu, and
Jimmy J. Lin, editors, CIKM, pages 1799‚Äì1802.
ACM.
</reference>
<page confidence="0.947488">
324
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.534874">
<title confidence="0.998645">Extracting Opinion Targets and Opinion Words from Online with Graph Co-ranking</title>
<author confidence="0.993086">Kang Liu</author>
<author confidence="0.993086">Liheng Xu</author>
<author confidence="0.993086">Jun</author>
<affiliation confidence="0.998447">National Laboratory of Pattern</affiliation>
<address confidence="0.552317">Institute of Automation, Chinese Academy of Sciences, Beijing, 100190,</address>
<email confidence="0.979001">lhxu,</email>
<abstract confidence="0.999514172413793">Extracting opinion targets and opinion words from online reviews are two fundamental tasks in opinion mining. This paper proposes a novel approach to collectively extract them with graph coranking. First, compared to previous methods which solely employed opinion relations among words, our method constructs a heterogeneous graph to model two types of relations, including semantic relations and opinion relations. Next, a co-ranking algorithm is proposed to estimate the confidence of each candidate, and the candidates with higher confidence will be extracted as opinion targets/words. In this way, different relations make cooperative effects on candidates‚Äô confidence estimation. Moreover, word preference is captured and incorporated into our coranking algorithm. In this way, our coranking is personalized and each candidate‚Äôs confidence is only determined by its preferred collocations. It helps to improve the extraction precision. The experimental results on three data sets with different sizes and languages show that our approach achieves better performance than state-of-the-art methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>lexicons for customer review mining.</title>
<booktitle>In Proceedings of the 22nd ACM international conference on Conference on information &amp;#38; knowledge management, CIKM ‚Äô13,</booktitle>
<pages>1077--1086</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker></marker>
<rawString>lexicons for customer review mining. In Proceedings of the 22nd ACM international conference on Conference on information &amp;#38; knowledge management, CIKM ‚Äô13, pages 1077‚Äì1086, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhen Hai</author>
<author>Kuiyu Chang</author>
<author>Gao Cong</author>
</authors>
<title>One seed to find them all: mining opinion features via association. In</title>
<date>2012</date>
<booktitle>CIKM,</booktitle>
<pages>255--264</pages>
<contexts>
<context position="10178" citStr="Hai et al., 2012" startWordPosition="1557" endWordPosition="1560">n topic model (Zhao et al., 2010; Moghaddam and Ester, 2011; Moghaddam and Ester, 2012a; Moghaddam and Ester, 2012b; Mukherjee and Liu, 2012). The main goals of these methods weren‚Äôt to extract opinion targets/words, but to categorize all given aspect terms and sentiment words. Although these models could be used for our task according to the associations between candidates and topics, solely employing semantic relations is still one-sided and insufficient to obtain expected performance. Furthermore, there is little work which considered these two types of relations globally (Su et al., 2008; Hai et al., 2012; Bross and Ehrig, 2013). They usually captured different relations using cooccurrence information. That was too coarse to obtain expected results (Liu et al., 2012). In addition, (Hai et al., 2012) extracted opinion targets/words in a bootstrapping process, which had an error propagation problem. In contrast, we perform extraction with a global graph co-ranking process, where error propagation can be effectively alleviated. (Su et al., 2008) used heterogeneous relations to find implicit sentiment associations among words. Their aim was only to perform aspect terms categorization but not to ex</context>
<context position="28084" citStr="Hai et al., 2012" startWordPosition="4685" endWordPosition="4688">ntax-based patterns to capture opinion relations in sentences, and then used a bootstrapping process to extract opinion targets/words (Qiu et al., 2011),. Zhang is proposed by (Zhang et al., 2010). They also used syntactic patterns to capture opinion relations between words. Then a HITS (Kleinberg, 1999) algorithm is employed to extract opinion targets. Liu is proposed by (Liu et al., 2013a), an extension of (Liu et al., 2012). They employed a word alignment model to capture opinion relations among words, and then used a random walking algorithm to extract opinion targets. Hai is proposed by (Hai et al., 2012), which is similar to our method. They employed both of semantic relations and opinion relations to extract opinion words/targets in a bootstrapping framework. But they captured relations only using cooccurrence statistics. Moreover, word preference was not considered. SAS is proposed by (Mukher ee and Liu, 2012), an extended lda-based model of (Zhao et al., 2010). The top K items for each aspect are extracted as opinion targets/words. It means that only semantic relations among words are considered in SAS. And we set aspects number to be 9 as same as (Mukher ee and Liu, 2012). CR: is the prop</context>
</contexts>
<marker>Hai, Chang, Cong, 2012</marker>
<rawString>Zhen Hai, Kuiyu Chang, and Gao Cong. 2012. One seed to find them all: mining opinion features via association. In CIKM, pages 255‚Äì264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhen Hai</author>
<author>Kuiyu Chang</author>
<author>Jung-Jae Kim</author>
<author>Christopher C Yang</author>
</authors>
<title>Identifying features in opinion mining via intrinsic and extrinsic domain relevance.</title>
<date>2013</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<pages>99--1</pages>
<contexts>
<context position="13896" citStr="Hai et al., 2013" startWordPosition="2192" endWordPosition="2195"> opinion words. mto i,j E Mto means the association weight between the ith opinion target and the jth opinion word according to their opinion relations. It‚Äôs worthy noting that It and Io respectively denote prior confidences of opinion target candidates and opinion word candidates. We argue that opinion targets are usually domain-specific, and there are remarkably distribution difference of them on different domains (in-domain Din vs. out-domain Dout). If a candidate is salient in Din but common in Dout, it‚Äôs likely to be an opinion target in Din. Thus, we use a domain relevance measure (DR) (Hai et al., 2013) to compute It. R(t, Din) DR(t) = (2) R(t, Dout) N 1 x EN 1(wtj ‚àí 1Wj x EWj k=1 wkj) represents candidate relevance with domain D. wtj = (1 + logTFtj) x log N DFt is a TF-IDF-like weight of candidate t in document j. TFtj is the frequency of the candidate t in the jth document, and DFt is document frequency. N means the document number in domain D. R(t, D) includes two measures to reflect the salient of a candidate in D. 1) wtj ‚àí Wj x ÔøΩWj 1 k=1 wkj reflects how frequently a term is mentioned in a particular document. Wj wt st quantifies how significantly a term is mentioned across all document</context>
</contexts>
<marker>Hai, Chang, Kim, Yang, 2013</marker>
<rawString>Zhen Hai, Kuiyu Chang, Jung-Jae Kim, and Christopher C. Yang. 2013. Identifying features in opinion mining via intrinsic and extrinsic domain relevance. IEEE Transactions on Knowledge and Data Engineering, 99(PrePrints):1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mingqin Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining opinion features in customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of Conference on Artificial Intelligence (AAAI).</booktitle>
<contexts>
<context position="1800" citStr="Hu and Liu, 2004" startWordPosition="261" endWordPosition="264">ps to improve the extraction precision. The experimental results on three data sets with different sizes and languages show that our approach achieves better performance than state-of-the-art methods. 1 Introduction In opinion mining, extracting opinion targets and opinion words are two fundamental subtasks. Opinion targets are objects about which users‚Äô opinions are expressed, and opinion words are words which indicate opinions‚Äô polarities. Extracting them can provide essential information for obtaining fine-grained analysis on customers‚Äô opinions. Thus, it has attracted a lot of attentions (Hu and Liu, 2004b; Liu et al., 2012; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012). To this end, previous work usually employed a collective extraction strategy (Qiu et al., 2009; Hu and Liu, 2004b; Liu et al., 2013b). Their intuition is: opinion words usually co-occur with opinion targets in sentences, and there are strong modification relationship between them (called opinion relation in (Liu et al., 2012)). If a word is an opinion word, other words with which that word having opinion relations will have highly probability to be opinion targets, and vice versa. In this way, extraction is alternatively</context>
<context position="8650" citStr="Hu and Liu, 2004" startWordPosition="1321" endWordPosition="1324">l classical models were used, such as CRFs (Li et al., 2010) and SVM (Wu et al., 2009). This paper belongs to corpus level extraction, and aims to generate a sentiment lexicon and a target list rather than to identify mentions in senùê∫ùê∫ùë°ùë°ùë°ùë° ùëáùëáùëÇùëÇ1 ùëÇùëÇùëÇùëÇ1 ùëÇùëÇùëÇùëÇ2 ùëÇùëÇùëÇùëÇ3 ùëÇùëÇùëÇùëÇ4 ùëÇùëÇùëÇùëÇ5 ùëÇùëÇùëÇùëÇ6 ùê∫ùê∫ùëúùëúùëúùëú ùê∫ùê∫ ùë°ùë°ùëúùëú ùëáùëáùëÇùëÇ2 ùëáùëáùëÇùëÇ3 ùëáùëáùëÇùëÇ4 ùëáùëáùëÇùëÇ5 ùëáùëáùëÇùëÇ6 315 tences. Most of previous corpus-level methods adopted a co-extraction framework, where opinion targets and opinion words reinforce each other according to their opinion relations. Thus, how to improve opinion relations identification performance was their main focus. (Hu and Liu, 2004a) exploited nearest neighbor rules to mine opinion relations among words. (Popescu and Etzioni, 2005) and (Qiu et al., 2011) designed syntactic patterns to perform this task. (Zhang et al., 2010) promoted Qiu‚Äôs method. They adopted some special designed patterns to increase recall. (Liu et al., 2012; Liu et al., 2013a; Liu et al., 2013b) employed word alignment model to capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned</context>
<context position="11281" citStr="Hu and Liu, 2004" startWordPosition="1730" endWordPosition="1733">licit sentiment associations among words. Their aim was only to perform aspect terms categorization but not to extract opinion targets/words. They extracted opinion targets/words in advanced through simple phrase detection. Thus, the extraction performance is far from expectation. 3 The Proposed Method In this section, we propose our method in detail. We formulate opinion targets/words extraction as a co-ranking task. All nouns/noun phrases are regarded as opinion target candidates, and all adjectives/verbs are regarded as opinion word candidates, which are widely adopted by pervious methods (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012). Then each candidate will be assigned a confidence and ranked, and the candidates with higher confidence than a threshold will be extracted as the results. Different from traditional methods, besides opinion relations among words, we additionally capture semantic relations among homogeneous candidates. To this end, a heterogeneous undirected graph G = (V, E) is constructed. V = V t U V o denotes the vertex set, which includes opinion target candidates vt E V t and opinion word candidates vo E V o. E denotes the edge set, where eij E E</context>
<context position="12635" citStr="Hu and Liu, 2004" startWordPosition="1961" endWordPosition="1964"> C E represents the semantic relations between two opinion word candidates. Eto C E represents the opinion relations between opinion target candidates and opinion word candidates. Based on different relation types, we used three matrices Mtt E R|V t|√ó|V t|, Moo E R|V o|√ó|V o| and Mto E R|V t|√ó|V o |to record the association weights between any two vertices, respectively. Section 3.4 will illustrate how to construct them. 3.1 Only Considering Opinion Relations To estimate the confidence of each candidate, we use a random walk algorithm on our graph to perform co-ranking. Most previous methods (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012) only considered opinion relations among words. Their basic assumption is as follows. Assumption 1: If a word is likely to be an opinion word, the words which it has opinion relation with will have higher confidence to be opinion targets, and vice versa. 316 In this way, candidates‚Äô confidences (vt or vo) are collectively determined by each other iteratively. It equals to making random walk on subgraph Gto = (V, Eto) of G. Thus we have Ct = (1 ‚àí ¬µ) x Mto x Co + ¬µ x It (1) Co = (1 ‚àí ¬µ) x MT to x Ct + ¬µ x Io where Ct and Co respectively </context>
<context position="24273" citStr="Hu and Liu, 2004" startWordPosition="3995" endWordPosition="3998">Information (PMI) to calculate the opinion associations among words as the entries in Mto. OA(vt, vo) = log p(vt,vo) p(vt)p(vo), where vt and vo denote an opinion target candidate and an opinion word candidate, respectively. p(vt, vo) is the co-occurrence probability of vt and vo based on the opinion relation identification results. p(vt) and p(vo) give the independent occurrence probability of of vt and vo, respectively 4 Experiments 4.1 Datasets and Evaluation Metrics Datasets: To evaluate the proposed method, we used three datasets. The first one is Customer Review Datasets (CRD), used in (Hu and Liu, 2004a), which contains reviews about five products. The second one is COAE2008 dataset22, which contains Chinese reviews about four products. The third one is Large, also used in (Wang et al., 2011; Liu et al., 2012; Liu et al., 2013a), where two domains are selected (Mp3 and Hotel). As mentioned in (Liu et al., 2012), Large contains 6,000 sentences for each domain. Opinion targets/words are manually annotated, where three annotators were involved. Two annotators were required to annotate out opinion words/targets in reviews. When conflicts occur, the third annotator make final judgement. In total</context>
<context position="27453" citStr="Hu and Liu, 2004" startWordPosition="4577" endWordPosition="4580"> 0.72 0.65 0.78 0.69 0.73 0.69 0.75 0.72 0.69 0.74 0.71 0.700 Liu 0.75 0.81 0.78 0.71 0.71 0.71 0.61 0.85 0.71 0.83 0.74 0.78 0.70 0.82 0.76 0.71 0.80 0.75 0.749 Hai 0.68 0.84 0.76 0.69 0.75 0.72 0.58 0.86 0.72 0.75 0.76 0.76 0.65 0.83 0.74 0.62 0.82 0.75 0.742 CR 0.75 0.83 0.79 0.72 0.74 0.73 0.60 0.85 0.70 0.83 0.77 0.80 0.70 0.84 0.76 0.71 0.83 0.77 0.758 CR WP 0.78 0.84 0.81 0.74 0.75 0.74 0.64 0.85 0.73 0.84 0.76 0.80 0.74 0.84 0.79 0.74 0.82 0.78 0.773 Table 3: Results of Opinion Targets Extraction on COAE 2008 and Large Hu extracted opinion targets/words using association mining rules (Hu and Liu, 2004a). DP used syntax-based patterns to capture opinion relations in sentences, and then used a bootstrapping process to extract opinion targets/words (Qiu et al., 2011),. Zhang is proposed by (Zhang et al., 2010). They also used syntactic patterns to capture opinion relations between words. Then a HITS (Kleinberg, 1999) algorithm is employed to extract opinion targets. Liu is proposed by (Liu et al., 2013a), an extension of (Liu et al., 2012). They employed a word alignment model to capture opinion relations among words, and then used a random walking algorithm to extract opinion targets. Hai is</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Mingqin Hu and Bing Liu. 2004a. Mining opinion features in customer reviews. In Proceedings of Conference on Artificial Intelligence (AAAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ‚Äô04,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1800" citStr="Hu and Liu, 2004" startWordPosition="261" endWordPosition="264">ps to improve the extraction precision. The experimental results on three data sets with different sizes and languages show that our approach achieves better performance than state-of-the-art methods. 1 Introduction In opinion mining, extracting opinion targets and opinion words are two fundamental subtasks. Opinion targets are objects about which users‚Äô opinions are expressed, and opinion words are words which indicate opinions‚Äô polarities. Extracting them can provide essential information for obtaining fine-grained analysis on customers‚Äô opinions. Thus, it has attracted a lot of attentions (Hu and Liu, 2004b; Liu et al., 2012; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012). To this end, previous work usually employed a collective extraction strategy (Qiu et al., 2009; Hu and Liu, 2004b; Liu et al., 2013b). Their intuition is: opinion words usually co-occur with opinion targets in sentences, and there are strong modification relationship between them (called opinion relation in (Liu et al., 2012)). If a word is an opinion word, other words with which that word having opinion relations will have highly probability to be opinion targets, and vice versa. In this way, extraction is alternatively</context>
<context position="8650" citStr="Hu and Liu, 2004" startWordPosition="1321" endWordPosition="1324">l classical models were used, such as CRFs (Li et al., 2010) and SVM (Wu et al., 2009). This paper belongs to corpus level extraction, and aims to generate a sentiment lexicon and a target list rather than to identify mentions in senùê∫ùê∫ùë°ùë°ùë°ùë° ùëáùëáùëÇùëÇ1 ùëÇùëÇùëÇùëÇ1 ùëÇùëÇùëÇùëÇ2 ùëÇùëÇùëÇùëÇ3 ùëÇùëÇùëÇùëÇ4 ùëÇùëÇùëÇùëÇ5 ùëÇùëÇùëÇùëÇ6 ùê∫ùê∫ùëúùëúùëúùëú ùê∫ùê∫ ùë°ùë°ùëúùëú ùëáùëáùëÇùëÇ2 ùëáùëáùëÇùëÇ3 ùëáùëáùëÇùëÇ4 ùëáùëáùëÇùëÇ5 ùëáùëáùëÇùëÇ6 315 tences. Most of previous corpus-level methods adopted a co-extraction framework, where opinion targets and opinion words reinforce each other according to their opinion relations. Thus, how to improve opinion relations identification performance was their main focus. (Hu and Liu, 2004a) exploited nearest neighbor rules to mine opinion relations among words. (Popescu and Etzioni, 2005) and (Qiu et al., 2011) designed syntactic patterns to perform this task. (Zhang et al., 2010) promoted Qiu‚Äôs method. They adopted some special designed patterns to increase recall. (Liu et al., 2012; Liu et al., 2013a; Liu et al., 2013b) employed word alignment model to capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned</context>
<context position="11281" citStr="Hu and Liu, 2004" startWordPosition="1730" endWordPosition="1733">licit sentiment associations among words. Their aim was only to perform aspect terms categorization but not to extract opinion targets/words. They extracted opinion targets/words in advanced through simple phrase detection. Thus, the extraction performance is far from expectation. 3 The Proposed Method In this section, we propose our method in detail. We formulate opinion targets/words extraction as a co-ranking task. All nouns/noun phrases are regarded as opinion target candidates, and all adjectives/verbs are regarded as opinion word candidates, which are widely adopted by pervious methods (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012). Then each candidate will be assigned a confidence and ranked, and the candidates with higher confidence than a threshold will be extracted as the results. Different from traditional methods, besides opinion relations among words, we additionally capture semantic relations among homogeneous candidates. To this end, a heterogeneous undirected graph G = (V, E) is constructed. V = V t U V o denotes the vertex set, which includes opinion target candidates vt E V t and opinion word candidates vo E V o. E denotes the edge set, where eij E E</context>
<context position="12635" citStr="Hu and Liu, 2004" startWordPosition="1961" endWordPosition="1964"> C E represents the semantic relations between two opinion word candidates. Eto C E represents the opinion relations between opinion target candidates and opinion word candidates. Based on different relation types, we used three matrices Mtt E R|V t|√ó|V t|, Moo E R|V o|√ó|V o| and Mto E R|V t|√ó|V o |to record the association weights between any two vertices, respectively. Section 3.4 will illustrate how to construct them. 3.1 Only Considering Opinion Relations To estimate the confidence of each candidate, we use a random walk algorithm on our graph to perform co-ranking. Most previous methods (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012) only considered opinion relations among words. Their basic assumption is as follows. Assumption 1: If a word is likely to be an opinion word, the words which it has opinion relation with will have higher confidence to be opinion targets, and vice versa. 316 In this way, candidates‚Äô confidences (vt or vo) are collectively determined by each other iteratively. It equals to making random walk on subgraph Gto = (V, Eto) of G. Thus we have Ct = (1 ‚àí ¬µ) x Mto x Co + ¬µ x It (1) Co = (1 ‚àí ¬µ) x MT to x Ct + ¬µ x Io where Ct and Co respectively </context>
<context position="24273" citStr="Hu and Liu, 2004" startWordPosition="3995" endWordPosition="3998">Information (PMI) to calculate the opinion associations among words as the entries in Mto. OA(vt, vo) = log p(vt,vo) p(vt)p(vo), where vt and vo denote an opinion target candidate and an opinion word candidate, respectively. p(vt, vo) is the co-occurrence probability of vt and vo based on the opinion relation identification results. p(vt) and p(vo) give the independent occurrence probability of of vt and vo, respectively 4 Experiments 4.1 Datasets and Evaluation Metrics Datasets: To evaluate the proposed method, we used three datasets. The first one is Customer Review Datasets (CRD), used in (Hu and Liu, 2004a), which contains reviews about five products. The second one is COAE2008 dataset22, which contains Chinese reviews about four products. The third one is Large, also used in (Wang et al., 2011; Liu et al., 2012; Liu et al., 2013a), where two domains are selected (Mp3 and Hotel). As mentioned in (Liu et al., 2012), Large contains 6,000 sentences for each domain. Opinion targets/words are manually annotated, where three annotators were involved. Two annotators were required to annotate out opinion words/targets in reviews. When conflicts occur, the third annotator make final judgement. In total</context>
<context position="27453" citStr="Hu and Liu, 2004" startWordPosition="4577" endWordPosition="4580"> 0.72 0.65 0.78 0.69 0.73 0.69 0.75 0.72 0.69 0.74 0.71 0.700 Liu 0.75 0.81 0.78 0.71 0.71 0.71 0.61 0.85 0.71 0.83 0.74 0.78 0.70 0.82 0.76 0.71 0.80 0.75 0.749 Hai 0.68 0.84 0.76 0.69 0.75 0.72 0.58 0.86 0.72 0.75 0.76 0.76 0.65 0.83 0.74 0.62 0.82 0.75 0.742 CR 0.75 0.83 0.79 0.72 0.74 0.73 0.60 0.85 0.70 0.83 0.77 0.80 0.70 0.84 0.76 0.71 0.83 0.77 0.758 CR WP 0.78 0.84 0.81 0.74 0.75 0.74 0.64 0.85 0.73 0.84 0.76 0.80 0.74 0.84 0.79 0.74 0.82 0.78 0.773 Table 3: Results of Opinion Targets Extraction on COAE 2008 and Large Hu extracted opinion targets/words using association mining rules (Hu and Liu, 2004a). DP used syntax-based patterns to capture opinion relations in sentences, and then used a bootstrapping process to extract opinion targets/words (Qiu et al., 2011),. Zhang is proposed by (Zhang et al., 2010). They also used syntactic patterns to capture opinion relations between words. Then a HITS (Kleinberg, 1999) algorithm is employed to extract opinion targets. Liu is proposed by (Liu et al., 2013a), an extension of (Liu et al., 2012). They employed a word alignment model to capture opinion relations among words, and then used a random walking algorithm to extract opinion targets. Hai is</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004b. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ‚Äô04, pages 168‚Äì177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1999</date>
<journal>J. ACM,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="27772" citStr="Kleinberg, 1999" startWordPosition="4630" endWordPosition="4632"> 0.80 0.70 0.84 0.76 0.71 0.83 0.77 0.758 CR WP 0.78 0.84 0.81 0.74 0.75 0.74 0.64 0.85 0.73 0.84 0.76 0.80 0.74 0.84 0.79 0.74 0.82 0.78 0.773 Table 3: Results of Opinion Targets Extraction on COAE 2008 and Large Hu extracted opinion targets/words using association mining rules (Hu and Liu, 2004a). DP used syntax-based patterns to capture opinion relations in sentences, and then used a bootstrapping process to extract opinion targets/words (Qiu et al., 2011),. Zhang is proposed by (Zhang et al., 2010). They also used syntactic patterns to capture opinion relations between words. Then a HITS (Kleinberg, 1999) algorithm is employed to extract opinion targets. Liu is proposed by (Liu et al., 2013a), an extension of (Liu et al., 2012). They employed a word alignment model to capture opinion relations among words, and then used a random walking algorithm to extract opinion targets. Hai is proposed by (Hai et al., 2012), which is similar to our method. They employed both of semantic relations and opinion relations to extract opinion words/targets in a bootstrapping framework. But they captured relations only using cooccurrence statistics. Moreover, word preference was not considered. SAS is proposed by</context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg. 1999. Authoritative sources in a hyperlinked environment. J. ACM, 46(5):604‚Äì632, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
</authors>
<title>Chao Han, Minlie Huang, Xiaoyan Zhu, Yingju Xia, Shu Zhang, and Hao Yu.</title>
<date>2010</date>
<booktitle>In Chu-Ren Huang and</booktitle>
<pages>653--661</pages>
<editor>Dan Jurafsky, editors, COLING,</editor>
<publisher>Tsinghua University Press.</publisher>
<marker>Li, 2010</marker>
<rawString>Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Yingju Xia, Shu Zhang, and Hao Yu. 2010. Structure-aware review mining and summarization. In Chu-Ren Huang and Dan Jurafsky, editors, COLING, pages 653‚Äì661. Tsinghua University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the web.</title>
<date>2005</date>
<pages>342--351</pages>
<editor>In Allan Ellis and Tatsuya Hagino, editors, WWW,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="2903" citStr="Liu et al., 2005" startWordPosition="433" endWordPosition="436">tions will have highly probability to be opinion targets, and vice versa. In this way, extraction is alternatively performed and mutual reinforced between opinion targets and opinion words. Although this strategy has been widely employed by previous approaches, it still has several limitations. 1) Only considering opinion relations is insufficient. Previous methods mainly focused on employing opinion relations among words for opinion target/word co-extraction. They have investigated a series of techniques to enhance opinion relations identification performance, such as nearest neighbor rules (Liu et al., 2005), syntactic patterns (Zhang et al., 2010; Popescu and Etzioni, 2005), word alignment models (Liu et al., 2012; Liu et al., 2013b; Liu et al., 2013a), etc. However, we are curious that whether merely employing opinion relations among words is enough for opinion target/word extraction? We note that there are additional types of relations among words. For example, ‚ÄúLCD‚Äù and ‚ÄúLED‚Äù both denote the same aspect ‚Äúscreen‚Äù in TV set domain, and they are topical related. We call such relations between homogeneous words as semantic relations. If we have known ‚ÄúLCD‚Äù to be an opinion target, ‚ÄúLED‚Äù is natura</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the web. In Allan Ellis and Tatsuya Hagino, editors, WWW, pages 342‚Äì351. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Jun Zhao</author>
</authors>
<title>Opinion target extraction using word-based translation model.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1346--1356</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="1819" citStr="Liu et al., 2012" startWordPosition="265" endWordPosition="268">xtraction precision. The experimental results on three data sets with different sizes and languages show that our approach achieves better performance than state-of-the-art methods. 1 Introduction In opinion mining, extracting opinion targets and opinion words are two fundamental subtasks. Opinion targets are objects about which users‚Äô opinions are expressed, and opinion words are words which indicate opinions‚Äô polarities. Extracting them can provide essential information for obtaining fine-grained analysis on customers‚Äô opinions. Thus, it has attracted a lot of attentions (Hu and Liu, 2004b; Liu et al., 2012; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012). To this end, previous work usually employed a collective extraction strategy (Qiu et al., 2009; Hu and Liu, 2004b; Liu et al., 2013b). Their intuition is: opinion words usually co-occur with opinion targets in sentences, and there are strong modification relationship between them (called opinion relation in (Liu et al., 2012)). If a word is an opinion word, other words with which that word having opinion relations will have highly probability to be opinion targets, and vice versa. In this way, extraction is alternatively performed and mutu</context>
<context position="8951" citStr="Liu et al., 2012" startWordPosition="1368" endWordPosition="1371">2 ùëáùëáùëÇùëÇ3 ùëáùëáùëÇùëÇ4 ùëáùëáùëÇùëÇ5 ùëáùëáùëÇùëÇ6 315 tences. Most of previous corpus-level methods adopted a co-extraction framework, where opinion targets and opinion words reinforce each other according to their opinion relations. Thus, how to improve opinion relations identification performance was their main focus. (Hu and Liu, 2004a) exploited nearest neighbor rules to mine opinion relations among words. (Popescu and Etzioni, 2005) and (Qiu et al., 2011) designed syntactic patterns to perform this task. (Zhang et al., 2010) promoted Qiu‚Äôs method. They adopted some special designed patterns to increase recall. (Liu et al., 2012; Liu et al., 2013a; Liu et al., 2013b) employed word alignment model to capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned methods only employed opinion relations for the extraction, but ignore considering semantic relations among homogeneous candidates. Moreover, they all ignored word preference in the extraction process. In terms of considering semantic relations among words, our method is related with several approac</context>
<context position="10343" citStr="Liu et al., 2012" startWordPosition="1582" endWordPosition="1585">se methods weren‚Äôt to extract opinion targets/words, but to categorize all given aspect terms and sentiment words. Although these models could be used for our task according to the associations between candidates and topics, solely employing semantic relations is still one-sided and insufficient to obtain expected performance. Furthermore, there is little work which considered these two types of relations globally (Su et al., 2008; Hai et al., 2012; Bross and Ehrig, 2013). They usually captured different relations using cooccurrence information. That was too coarse to obtain expected results (Liu et al., 2012). In addition, (Hai et al., 2012) extracted opinion targets/words in a bootstrapping process, which had an error propagation problem. In contrast, we perform extraction with a global graph co-ranking process, where error propagation can be effectively alleviated. (Su et al., 2008) used heterogeneous relations to find implicit sentiment associations among words. Their aim was only to perform aspect terms categorization but not to extract opinion targets/words. They extracted opinion targets/words in advanced through simple phrase detection. Thus, the extraction performance is far from expectati</context>
<context position="12694" citStr="Liu et al., 2012" startWordPosition="1973" endWordPosition="1976"> word candidates. Eto C E represents the opinion relations between opinion target candidates and opinion word candidates. Based on different relation types, we used three matrices Mtt E R|V t|√ó|V t|, Moo E R|V o|√ó|V o| and Mto E R|V t|√ó|V o |to record the association weights between any two vertices, respectively. Section 3.4 will illustrate how to construct them. 3.1 Only Considering Opinion Relations To estimate the confidence of each candidate, we use a random walk algorithm on our graph to perform co-ranking. Most previous methods (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012) only considered opinion relations among words. Their basic assumption is as follows. Assumption 1: If a word is likely to be an opinion word, the words which it has opinion relation with will have higher confidence to be opinion targets, and vice versa. 316 In this way, candidates‚Äô confidences (vt or vo) are collectively determined by each other iteratively. It equals to making random walk on subgraph Gto = (V, Eto) of G. Thus we have Ct = (1 ‚àí ¬µ) x Mto x Co + ¬µ x It (1) Co = (1 ‚àí ¬µ) x MT to x Ct + ¬µ x Io where Ct and Co respectively represent confidences of opinion targets and opinion words.</context>
<context position="24484" citStr="Liu et al., 2012" startWordPosition="4032" endWordPosition="4035">respectively. p(vt, vo) is the co-occurrence probability of vt and vo based on the opinion relation identification results. p(vt) and p(vo) give the independent occurrence probability of of vt and vo, respectively 4 Experiments 4.1 Datasets and Evaluation Metrics Datasets: To evaluate the proposed method, we used three datasets. The first one is Customer Review Datasets (CRD), used in (Hu and Liu, 2004a), which contains reviews about five products. The second one is COAE2008 dataset22, which contains Chinese reviews about four products. The third one is Large, also used in (Wang et al., 2011; Liu et al., 2012; Liu et al., 2013a), where two domains are selected (Mp3 and Hotel). As mentioned in (Liu et al., 2012), Large contains 6,000 sentences for each domain. Opinion targets/words are manually annotated, where three annotators were involved. Two annotators were required to annotate out opinion words/targets in reviews. When conflicts occur, the third annotator make final judgement. In total, we respectively obtain 1,112, 1,241 opinion targets and 334, 407 opinion words in Hotel, MP3. Pre-processing: All sentences are tagged to obtain words‚Äô part-of-speech tags using Stanford NLP tool3. And noun ph</context>
<context position="27897" citStr="Liu et al., 2012" startWordPosition="4653" endWordPosition="4656">.74 0.82 0.78 0.773 Table 3: Results of Opinion Targets Extraction on COAE 2008 and Large Hu extracted opinion targets/words using association mining rules (Hu and Liu, 2004a). DP used syntax-based patterns to capture opinion relations in sentences, and then used a bootstrapping process to extract opinion targets/words (Qiu et al., 2011),. Zhang is proposed by (Zhang et al., 2010). They also used syntactic patterns to capture opinion relations between words. Then a HITS (Kleinberg, 1999) algorithm is employed to extract opinion targets. Liu is proposed by (Liu et al., 2013a), an extension of (Liu et al., 2012). They employed a word alignment model to capture opinion relations among words, and then used a random walking algorithm to extract opinion targets. Hai is proposed by (Hai et al., 2012), which is similar to our method. They employed both of semantic relations and opinion relations to extract opinion words/targets in a bootstrapping framework. But they captured relations only using cooccurrence statistics. Moreover, word preference was not considered. SAS is proposed by (Mukher ee and Liu, 2012), an extended lda-based model of (Zhao et al., 2010). The top K items for each aspect are extracted</context>
</contexts>
<marker>Liu, Xu, Zhao, 2012</marker>
<rawString>Kang Liu, Liheng Xu, and Jun Zhao. 2012. Opinion target extraction using word-based translation model. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1346‚Äì1356, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Yang Liu</author>
<author>Jun Zhao</author>
</authors>
<title>Opinion target extraction using partially supervised word alignment model.</title>
<date>2013</date>
<contexts>
<context position="2005" citStr="Liu et al., 2013" startWordPosition="296" endWordPosition="299">troduction In opinion mining, extracting opinion targets and opinion words are two fundamental subtasks. Opinion targets are objects about which users‚Äô opinions are expressed, and opinion words are words which indicate opinions‚Äô polarities. Extracting them can provide essential information for obtaining fine-grained analysis on customers‚Äô opinions. Thus, it has attracted a lot of attentions (Hu and Liu, 2004b; Liu et al., 2012; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012). To this end, previous work usually employed a collective extraction strategy (Qiu et al., 2009; Hu and Liu, 2004b; Liu et al., 2013b). Their intuition is: opinion words usually co-occur with opinion targets in sentences, and there are strong modification relationship between them (called opinion relation in (Liu et al., 2012)). If a word is an opinion word, other words with which that word having opinion relations will have highly probability to be opinion targets, and vice versa. In this way, extraction is alternatively performed and mutual reinforced between opinion targets and opinion words. Although this strategy has been widely employed by previous approaches, it still has several limitations. 1) Only considering opi</context>
<context position="8969" citStr="Liu et al., 2013" startWordPosition="1372" endWordPosition="1375">5 ùëáùëáùëÇùëÇ6 315 tences. Most of previous corpus-level methods adopted a co-extraction framework, where opinion targets and opinion words reinforce each other according to their opinion relations. Thus, how to improve opinion relations identification performance was their main focus. (Hu and Liu, 2004a) exploited nearest neighbor rules to mine opinion relations among words. (Popescu and Etzioni, 2005) and (Qiu et al., 2011) designed syntactic patterns to perform this task. (Zhang et al., 2010) promoted Qiu‚Äôs method. They adopted some special designed patterns to increase recall. (Liu et al., 2012; Liu et al., 2013a; Liu et al., 2013b) employed word alignment model to capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned methods only employed opinion relations for the extraction, but ignore considering semantic relations among homogeneous candidates. Moreover, they all ignored word preference in the extraction process. In terms of considering semantic relations among words, our method is related with several approaches based on topic</context>
<context position="22929" citStr="Liu et al., 2013" startWordPosition="3786" endWordPosition="3789"> opinion mining (Mukherjee and Liu, 2012). After topic modeling, we obtain the probability of the candidates (vt and vo) to topic z, i.e. p(z|vt) and p(z|vo), and topic distribution p(z). Then, a symmetric Kullback-Leibler divergence as same as Eq.5 is used to calculate the semantical associations between any two homogenous candidates. Thus, we obtain SA(vt, vt) and SA(vo, vo), which correspond to the entries in Mtt and Moo, respectively. Capturing Opinion Relations: To capture opinion relations among words and construct the transition matrix Mto, we used an alignmentbased method proposed in (Liu et al., 2013b). This approach models capturing opinion relations as a monolingual word alignment process. Each opinion target can find its corresponding modifiers in sentences through alignment, in which multiple factors are considered globally, such as co-occurrence information, word position in sentence, etc. Moreover, this model adopted a partially supervised framework to combine syntactic information with alignment results, which has been proven to be more precise than the state-ofthe-art approaches for opinion relations identification (Liu et al., 2013b). After performing word alignment, we obtain a </context>
<context position="24502" citStr="Liu et al., 2013" startWordPosition="4036" endWordPosition="4039">, vo) is the co-occurrence probability of vt and vo based on the opinion relation identification results. p(vt) and p(vo) give the independent occurrence probability of of vt and vo, respectively 4 Experiments 4.1 Datasets and Evaluation Metrics Datasets: To evaluate the proposed method, we used three datasets. The first one is Customer Review Datasets (CRD), used in (Hu and Liu, 2004a), which contains reviews about five products. The second one is COAE2008 dataset22, which contains Chinese reviews about four products. The third one is Large, also used in (Wang et al., 2011; Liu et al., 2012; Liu et al., 2013a), where two domains are selected (Mp3 and Hotel). As mentioned in (Liu et al., 2012), Large contains 6,000 sentences for each domain. Opinion targets/words are manually annotated, where three annotators were involved. Two annotators were required to annotate out opinion words/targets in reviews. When conflicts occur, the third annotator make final judgement. In total, we respectively obtain 1,112, 1,241 opinion targets and 334, 407 opinion words in Hotel, MP3. Pre-processing: All sentences are tagged to obtain words‚Äô part-of-speech tags using Stanford NLP tool3. And noun phrases are identifi</context>
<context position="27859" citStr="Liu et al., 2013" startWordPosition="4645" endWordPosition="4648"> 0.73 0.84 0.76 0.80 0.74 0.84 0.79 0.74 0.82 0.78 0.773 Table 3: Results of Opinion Targets Extraction on COAE 2008 and Large Hu extracted opinion targets/words using association mining rules (Hu and Liu, 2004a). DP used syntax-based patterns to capture opinion relations in sentences, and then used a bootstrapping process to extract opinion targets/words (Qiu et al., 2011),. Zhang is proposed by (Zhang et al., 2010). They also used syntactic patterns to capture opinion relations between words. Then a HITS (Kleinberg, 1999) algorithm is employed to extract opinion targets. Liu is proposed by (Liu et al., 2013a), an extension of (Liu et al., 2012). They employed a word alignment model to capture opinion relations among words, and then used a random walking algorithm to extract opinion targets. Hai is proposed by (Hai et al., 2012), which is similar to our method. They employed both of semantic relations and opinion relations to extract opinion words/targets in a bootstrapping framework. But they captured relations only using cooccurrence statistics. Moreover, word preference was not considered. SAS is proposed by (Mukher ee and Liu, 2012), an extended lda-based model of (Zhao et al., 2010). The top</context>
</contexts>
<marker>Liu, Xu, Liu, Zhao, 2013</marker>
<rawString>Kang Liu, Liheng Xu, Yang Liu, and Jun Zhao. 2013a. Opinion target extraction using partially supervised word alignment model.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Jun Zhao</author>
</authors>
<title>Syntactic patterns versus word alignment: Extracting opinion targets from online reviews.</title>
<date>2013</date>
<contexts>
<context position="2005" citStr="Liu et al., 2013" startWordPosition="296" endWordPosition="299">troduction In opinion mining, extracting opinion targets and opinion words are two fundamental subtasks. Opinion targets are objects about which users‚Äô opinions are expressed, and opinion words are words which indicate opinions‚Äô polarities. Extracting them can provide essential information for obtaining fine-grained analysis on customers‚Äô opinions. Thus, it has attracted a lot of attentions (Hu and Liu, 2004b; Liu et al., 2012; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012). To this end, previous work usually employed a collective extraction strategy (Qiu et al., 2009; Hu and Liu, 2004b; Liu et al., 2013b). Their intuition is: opinion words usually co-occur with opinion targets in sentences, and there are strong modification relationship between them (called opinion relation in (Liu et al., 2012)). If a word is an opinion word, other words with which that word having opinion relations will have highly probability to be opinion targets, and vice versa. In this way, extraction is alternatively performed and mutual reinforced between opinion targets and opinion words. Although this strategy has been widely employed by previous approaches, it still has several limitations. 1) Only considering opi</context>
<context position="8969" citStr="Liu et al., 2013" startWordPosition="1372" endWordPosition="1375">5 ùëáùëáùëÇùëÇ6 315 tences. Most of previous corpus-level methods adopted a co-extraction framework, where opinion targets and opinion words reinforce each other according to their opinion relations. Thus, how to improve opinion relations identification performance was their main focus. (Hu and Liu, 2004a) exploited nearest neighbor rules to mine opinion relations among words. (Popescu and Etzioni, 2005) and (Qiu et al., 2011) designed syntactic patterns to perform this task. (Zhang et al., 2010) promoted Qiu‚Äôs method. They adopted some special designed patterns to increase recall. (Liu et al., 2012; Liu et al., 2013a; Liu et al., 2013b) employed word alignment model to capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned methods only employed opinion relations for the extraction, but ignore considering semantic relations among homogeneous candidates. Moreover, they all ignored word preference in the extraction process. In terms of considering semantic relations among words, our method is related with several approaches based on topic</context>
<context position="22929" citStr="Liu et al., 2013" startWordPosition="3786" endWordPosition="3789"> opinion mining (Mukherjee and Liu, 2012). After topic modeling, we obtain the probability of the candidates (vt and vo) to topic z, i.e. p(z|vt) and p(z|vo), and topic distribution p(z). Then, a symmetric Kullback-Leibler divergence as same as Eq.5 is used to calculate the semantical associations between any two homogenous candidates. Thus, we obtain SA(vt, vt) and SA(vo, vo), which correspond to the entries in Mtt and Moo, respectively. Capturing Opinion Relations: To capture opinion relations among words and construct the transition matrix Mto, we used an alignmentbased method proposed in (Liu et al., 2013b). This approach models capturing opinion relations as a monolingual word alignment process. Each opinion target can find its corresponding modifiers in sentences through alignment, in which multiple factors are considered globally, such as co-occurrence information, word position in sentence, etc. Moreover, this model adopted a partially supervised framework to combine syntactic information with alignment results, which has been proven to be more precise than the state-ofthe-art approaches for opinion relations identification (Liu et al., 2013b). After performing word alignment, we obtain a </context>
<context position="24502" citStr="Liu et al., 2013" startWordPosition="4036" endWordPosition="4039">, vo) is the co-occurrence probability of vt and vo based on the opinion relation identification results. p(vt) and p(vo) give the independent occurrence probability of of vt and vo, respectively 4 Experiments 4.1 Datasets and Evaluation Metrics Datasets: To evaluate the proposed method, we used three datasets. The first one is Customer Review Datasets (CRD), used in (Hu and Liu, 2004a), which contains reviews about five products. The second one is COAE2008 dataset22, which contains Chinese reviews about four products. The third one is Large, also used in (Wang et al., 2011; Liu et al., 2012; Liu et al., 2013a), where two domains are selected (Mp3 and Hotel). As mentioned in (Liu et al., 2012), Large contains 6,000 sentences for each domain. Opinion targets/words are manually annotated, where three annotators were involved. Two annotators were required to annotate out opinion words/targets in reviews. When conflicts occur, the third annotator make final judgement. In total, we respectively obtain 1,112, 1,241 opinion targets and 334, 407 opinion words in Hotel, MP3. Pre-processing: All sentences are tagged to obtain words‚Äô part-of-speech tags using Stanford NLP tool3. And noun phrases are identifi</context>
<context position="27859" citStr="Liu et al., 2013" startWordPosition="4645" endWordPosition="4648"> 0.73 0.84 0.76 0.80 0.74 0.84 0.79 0.74 0.82 0.78 0.773 Table 3: Results of Opinion Targets Extraction on COAE 2008 and Large Hu extracted opinion targets/words using association mining rules (Hu and Liu, 2004a). DP used syntax-based patterns to capture opinion relations in sentences, and then used a bootstrapping process to extract opinion targets/words (Qiu et al., 2011),. Zhang is proposed by (Zhang et al., 2010). They also used syntactic patterns to capture opinion relations between words. Then a HITS (Kleinberg, 1999) algorithm is employed to extract opinion targets. Liu is proposed by (Liu et al., 2013a), an extension of (Liu et al., 2012). They employed a word alignment model to capture opinion relations among words, and then used a random walking algorithm to extract opinion targets. Hai is proposed by (Hai et al., 2012), which is similar to our method. They employed both of semantic relations and opinion relations to extract opinion words/targets in a bootstrapping framework. But they captured relations only using cooccurrence statistics. Moreover, word preference was not considered. SAS is proposed by (Mukher ee and Liu, 2012), an extended lda-based model of (Zhao et al., 2010). The top</context>
</contexts>
<marker>Liu, Xu, Zhao, 2013</marker>
<rawString>Kang Liu, Liheng Xu, and Jun Zhao. 2013b. Syntactic patterns versus word alignment: Extracting opinion targets from online reviews.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tengfei Ma</author>
<author>Xiaojun Wan</author>
</authors>
<title>Opinion target extraction in chinese news comments.</title>
<date>2010</date>
<booktitle>In ChuRen Huang and</booktitle>
<pages>782--790</pages>
<editor>Dan Jurafsky, editors, COLING (Posters),</editor>
<contexts>
<context position="7862" citStr="Ma and Wan, 2010" startWordPosition="1190" endWordPosition="1193">s confidence would mainly absorb the contributions from its word preferences rather than its all neighbors with opinion relations, which may be beneficial for improving extraction precision. We perform experiments on real-world datasets from different languages and different domains. Results show that our approach effectively improves extraction performance compared to the state-of-the-art approaches. 2 Related Work There are many significant research efforts on opinion targets/words extraction (sentence level and corpus level). In sentence level extraction, previous methods (Wu et al., 2009; Ma and Wan, 2010; Li et al., 2010; Yang and Cardie, 2013) mainly aimed to identify all opinion target/word mentions in sentences. They regarded it as a sequence labeling task, where several classical models were used, such as CRFs (Li et al., 2010) and SVM (Wu et al., 2009). This paper belongs to corpus level extraction, and aims to generate a sentiment lexicon and a target list rather than to identify mentions in senùê∫ùê∫ùë°ùë°ùë°ùë° ùëáùëáùëÇùëÇ1 ùëÇùëÇùëÇùëÇ1 ùëÇùëÇùëÇùëÇ2 ùëÇùëÇùëÇùëÇ3 ùëÇùëÇùëÇùëÇ4 ùëÇùëÇùëÇùëÇ5 ùëÇùëÇùëÇùëÇ6 ùê∫ùê∫ùëúùëúùëúùëú ùê∫ùê∫ ùë°ùë°ùëúùëú ùëáùëáùëÇùëÇ2 ùëáùëáùëÇùëÇ3 ùëáùëáùëÇùëÇ4 ùëáùëáùëÇùëÇ5 ùëáùëáùëÇùëÇ6 315 tences. Most of previous corpus-level methods adopted a co-extraction framework, where opinion ta</context>
</contexts>
<marker>Ma, Wan, 2010</marker>
<rawString>Tengfei Ma and Xiaojun Wan. 2010. Opinion target extraction in chinese news comments. In ChuRen Huang and Dan Jurafsky, editors, COLING (Posters), pages 782‚Äì790. Chinese Information Processing Society of China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samaneh Moghaddam</author>
<author>Martin Ester</author>
</authors>
<title>Ilda: Interdependent lda model for learning latent aspects and their ratings from online product reviews.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ‚Äô11,</booktitle>
<pages>665--674</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1846" citStr="Moghaddam and Ester, 2011" startWordPosition="269" endWordPosition="272">n. The experimental results on three data sets with different sizes and languages show that our approach achieves better performance than state-of-the-art methods. 1 Introduction In opinion mining, extracting opinion targets and opinion words are two fundamental subtasks. Opinion targets are objects about which users‚Äô opinions are expressed, and opinion words are words which indicate opinions‚Äô polarities. Extracting them can provide essential information for obtaining fine-grained analysis on customers‚Äô opinions. Thus, it has attracted a lot of attentions (Hu and Liu, 2004b; Liu et al., 2012; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012). To this end, previous work usually employed a collective extraction strategy (Qiu et al., 2009; Hu and Liu, 2004b; Liu et al., 2013b). Their intuition is: opinion words usually co-occur with opinion targets in sentences, and there are strong modification relationship between them (called opinion relation in (Liu et al., 2012)). If a word is an opinion word, other words with which that word having opinion relations will have highly probability to be opinion targets, and vice versa. In this way, extraction is alternatively performed and mutual reinforced between opini</context>
<context position="9621" citStr="Moghaddam and Ester, 2011" startWordPosition="1469" endWordPosition="1472">yed word alignment model to capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned methods only employed opinion relations for the extraction, but ignore considering semantic relations among homogeneous candidates. Moreover, they all ignored word preference in the extraction process. In terms of considering semantic relations among words, our method is related with several approaches based on topic model (Zhao et al., 2010; Moghaddam and Ester, 2011; Moghaddam and Ester, 2012a; Moghaddam and Ester, 2012b; Mukherjee and Liu, 2012). The main goals of these methods weren‚Äôt to extract opinion targets/words, but to categorize all given aspect terms and sentiment words. Although these models could be used for our task according to the associations between candidates and topics, solely employing semantic relations is still one-sided and insufficient to obtain expected performance. Furthermore, there is little work which considered these two types of relations globally (Su et al., 2008; Hai et al., 2012; Bross and Ehrig, 2013). They usually capt</context>
</contexts>
<marker>Moghaddam, Ester, 2011</marker>
<rawString>Samaneh Moghaddam and Martin Ester. 2011. Ilda: Interdependent lda model for learning latent aspects and their ratings from online product reviews. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ‚Äô11, pages 665‚Äì674, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samaneh Moghaddam</author>
<author>Martin Ester</author>
</authors>
<title>Aspect-based opinion mining from product reviews.</title>
<date>2012</date>
<booktitle>In Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ‚Äô12,</booktitle>
<pages>1184--1184</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="9648" citStr="Moghaddam and Ester, 2012" startWordPosition="1473" endWordPosition="1477"> capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned methods only employed opinion relations for the extraction, but ignore considering semantic relations among homogeneous candidates. Moreover, they all ignored word preference in the extraction process. In terms of considering semantic relations among words, our method is related with several approaches based on topic model (Zhao et al., 2010; Moghaddam and Ester, 2011; Moghaddam and Ester, 2012a; Moghaddam and Ester, 2012b; Mukherjee and Liu, 2012). The main goals of these methods weren‚Äôt to extract opinion targets/words, but to categorize all given aspect terms and sentiment words. Although these models could be used for our task according to the associations between candidates and topics, solely employing semantic relations is still one-sided and insufficient to obtain expected performance. Furthermore, there is little work which considered these two types of relations globally (Su et al., 2008; Hai et al., 2012; Bross and Ehrig, 2013). They usually captured different relations us</context>
</contexts>
<marker>Moghaddam, Ester, 2012</marker>
<rawString>Samaneh Moghaddam and Martin Ester. 2012a. Aspect-based opinion mining from product reviews. In Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ‚Äô12, pages 1184‚Äì1184, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samaneh Moghaddam</author>
<author>Martin Ester</author>
</authors>
<title>On the design of lda models for aspect-based opinion mining.</title>
<date>2012</date>
<booktitle>In CIKM,</booktitle>
<pages>803--812</pages>
<contexts>
<context position="9648" citStr="Moghaddam and Ester, 2012" startWordPosition="1473" endWordPosition="1477"> capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned methods only employed opinion relations for the extraction, but ignore considering semantic relations among homogeneous candidates. Moreover, they all ignored word preference in the extraction process. In terms of considering semantic relations among words, our method is related with several approaches based on topic model (Zhao et al., 2010; Moghaddam and Ester, 2011; Moghaddam and Ester, 2012a; Moghaddam and Ester, 2012b; Mukherjee and Liu, 2012). The main goals of these methods weren‚Äôt to extract opinion targets/words, but to categorize all given aspect terms and sentiment words. Although these models could be used for our task according to the associations between candidates and topics, solely employing semantic relations is still one-sided and insufficient to obtain expected performance. Furthermore, there is little work which considered these two types of relations globally (Su et al., 2008; Hai et al., 2012; Bross and Ehrig, 2013). They usually captured different relations us</context>
</contexts>
<marker>Moghaddam, Ester, 2012</marker>
<rawString>Samaneh Moghaddam and Martin Ester. 2012b. On the design of lda models for aspect-based opinion mining. In CIKM, pages 803‚Äì812.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
</authors>
<title>Aspect extraction through semi-supervised modeling.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ‚Äô12,</booktitle>
<pages>339--348</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1872" citStr="Mukherjee and Liu, 2012" startWordPosition="273" endWordPosition="276"> on three data sets with different sizes and languages show that our approach achieves better performance than state-of-the-art methods. 1 Introduction In opinion mining, extracting opinion targets and opinion words are two fundamental subtasks. Opinion targets are objects about which users‚Äô opinions are expressed, and opinion words are words which indicate opinions‚Äô polarities. Extracting them can provide essential information for obtaining fine-grained analysis on customers‚Äô opinions. Thus, it has attracted a lot of attentions (Hu and Liu, 2004b; Liu et al., 2012; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012). To this end, previous work usually employed a collective extraction strategy (Qiu et al., 2009; Hu and Liu, 2004b; Liu et al., 2013b). Their intuition is: opinion words usually co-occur with opinion targets in sentences, and there are strong modification relationship between them (called opinion relation in (Liu et al., 2012)). If a word is an opinion word, other words with which that word having opinion relations will have highly probability to be opinion targets, and vice versa. In this way, extraction is alternatively performed and mutual reinforced between opinion targets and opinion wor</context>
<context position="9703" citStr="Mukherjee and Liu, 2012" startWordPosition="1482" endWordPosition="1485">. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned methods only employed opinion relations for the extraction, but ignore considering semantic relations among homogeneous candidates. Moreover, they all ignored word preference in the extraction process. In terms of considering semantic relations among words, our method is related with several approaches based on topic model (Zhao et al., 2010; Moghaddam and Ester, 2011; Moghaddam and Ester, 2012a; Moghaddam and Ester, 2012b; Mukherjee and Liu, 2012). The main goals of these methods weren‚Äôt to extract opinion targets/words, but to categorize all given aspect terms and sentiment words. Although these models could be used for our task according to the associations between candidates and topics, solely employing semantic relations is still one-sided and insufficient to obtain expected performance. Furthermore, there is little work which considered these two types of relations globally (Su et al., 2008; Hai et al., 2012; Bross and Ehrig, 2013). They usually captured different relations using cooccurrence information. That was too coarse to ob</context>
<context position="21879" citStr="Mukherjee and Liu, 2012" startWordPosition="3617" endWordPosition="3620">.4 become: preference in it. Let ÀÜMto = ( 318 Ct = (1 ‚àí Œª ‚àí ¬µ) x ÀÜMto x Co + Œª x Mtt x Ct + ¬µ x It Co = (1 ‚àí Œª ‚àí ¬µ) x ÀÜMTto x Ct + Œª x Moo x Co + ¬µ x Io 3.4 Capturing Semantic and Opinion Relations In this section, we explain how to capture semantic relations and opinion relations for constructing transition matrices Mtt, Moo and Mto. Capturing Semantic Relations: For capturing semantic relations among homogenous candidates, we employ topics. We believe that if two candidates share similar topics in the corpus, there is a strong semantic relation between them. Thus, we employ a LDA variation (Mukherjee and Liu, 2012), an extension of (Zhao et al., 2010), to discover topic distribution on words, which sampled all words into two separated observations: opinion targets and opinion words. It‚Äôs because that we are only interested in topic distribution of opinion targets/words, regardless of other useless words, including conjunctions, prepositions etc. This model has been proven to be better than the standard LDA model and other LDA variations for opinion mining (Mukherjee and Liu, 2012). After topic modeling, we obtain the probability of the candidates (vt and vo) to topic z, i.e. p(z|vt) and p(z|vo), and top</context>
</contexts>
<marker>Mukherjee, Liu, 2012</marker>
<rawString>Arjun Mukherjee and Bing Liu. 2012. Aspect extraction through semi-supervised modeling. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ‚Äô12, pages 339‚Äì348, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ‚Äô05,</booktitle>
<pages>339--346</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2971" citStr="Popescu and Etzioni, 2005" startWordPosition="443" endWordPosition="446">nd vice versa. In this way, extraction is alternatively performed and mutual reinforced between opinion targets and opinion words. Although this strategy has been widely employed by previous approaches, it still has several limitations. 1) Only considering opinion relations is insufficient. Previous methods mainly focused on employing opinion relations among words for opinion target/word co-extraction. They have investigated a series of techniques to enhance opinion relations identification performance, such as nearest neighbor rules (Liu et al., 2005), syntactic patterns (Zhang et al., 2010; Popescu and Etzioni, 2005), word alignment models (Liu et al., 2012; Liu et al., 2013b; Liu et al., 2013a), etc. However, we are curious that whether merely employing opinion relations among words is enough for opinion target/word extraction? We note that there are additional types of relations among words. For example, ‚ÄúLCD‚Äù and ‚ÄúLED‚Äù both denote the same aspect ‚Äúscreen‚Äù in TV set domain, and they are topical related. We call such relations between homogeneous words as semantic relations. If we have known ‚ÄúLCD‚Äù to be an opinion target, ‚ÄúLED‚Äù is naturally to be an opinion target. Intuitively, besides opinion relations,</context>
<context position="8752" citStr="Popescu and Etzioni, 2005" startWordPosition="1335" endWordPosition="1338"> paper belongs to corpus level extraction, and aims to generate a sentiment lexicon and a target list rather than to identify mentions in senùê∫ùê∫ùë°ùë°ùë°ùë° ùëáùëáùëÇùëÇ1 ùëÇùëÇùëÇùëÇ1 ùëÇùëÇùëÇùëÇ2 ùëÇùëÇùëÇùëÇ3 ùëÇùëÇùëÇùëÇ4 ùëÇùëÇùëÇùëÇ5 ùëÇùëÇùëÇùëÇ6 ùê∫ùê∫ùëúùëúùëúùëú ùê∫ùê∫ ùë°ùë°ùëúùëú ùëáùëáùëÇùëÇ2 ùëáùëáùëÇùëÇ3 ùëáùëáùëÇùëÇ4 ùëáùëáùëÇùëÇ5 ùëáùëáùëÇùëÇ6 315 tences. Most of previous corpus-level methods adopted a co-extraction framework, where opinion targets and opinion words reinforce each other according to their opinion relations. Thus, how to improve opinion relations identification performance was their main focus. (Hu and Liu, 2004a) exploited nearest neighbor rules to mine opinion relations among words. (Popescu and Etzioni, 2005) and (Qiu et al., 2011) designed syntactic patterns to perform this task. (Zhang et al., 2010) promoted Qiu‚Äôs method. They adopted some special designed patterns to increase recall. (Liu et al., 2012; Liu et al., 2013a; Liu et al., 2013b) employed word alignment model to capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned methods only employed opinion relations for the extraction, but ignore considering semantic relations</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ‚Äô05, pages 339‚Äì346, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Che</author>
</authors>
<title>Expanding domain sentiment lexicon through double propagation.</title>
<date>2009</date>
<contexts>
<context position="1968" citStr="Qiu et al., 2009" startWordPosition="288" endWordPosition="291">e than state-of-the-art methods. 1 Introduction In opinion mining, extracting opinion targets and opinion words are two fundamental subtasks. Opinion targets are objects about which users‚Äô opinions are expressed, and opinion words are words which indicate opinions‚Äô polarities. Extracting them can provide essential information for obtaining fine-grained analysis on customers‚Äô opinions. Thus, it has attracted a lot of attentions (Hu and Liu, 2004b; Liu et al., 2012; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012). To this end, previous work usually employed a collective extraction strategy (Qiu et al., 2009; Hu and Liu, 2004b; Liu et al., 2013b). Their intuition is: opinion words usually co-occur with opinion targets in sentences, and there are strong modification relationship between them (called opinion relation in (Liu et al., 2012)). If a word is an opinion word, other words with which that word having opinion relations will have highly probability to be opinion targets, and vice versa. In this way, extraction is alternatively performed and mutual reinforced between opinion targets and opinion words. Although this strategy has been widely employed by previous approaches, it still has several</context>
</contexts>
<marker>Qiu, Liu, Bu, Che, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Che. 2009. Expanding domain sentiment lexicon through double propagation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Opinion word expansion and target extraction through double propagation.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>1</issue>
<marker>Bu, Chen, 2011</marker>
<rawString>Guang Qiu, Bing Liu 0001, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through double propagation. Computational Linguistics, 37(1):9‚Äì27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Su</author>
</authors>
<title>Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu, Xiaoxun Zhang, Bin Swen, and Zhong Su.</title>
<date>2008</date>
<pages>959--968</pages>
<editor>In Jinpeng Huai, Robin Chen, Hsiao-Wuen Hon, Yunhao Liu, Wei-Ying Ma, Andrew Tomkins, and Xiaodong Zhang 0001, editors, WWW,</editor>
<publisher>ACM.</publisher>
<marker>Su, 2008</marker>
<rawString>Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu, Xiaoxun Zhang, Bin Swen, and Zhong Su. 2008. Hidden sentiment association in chinese web opinion mining. In Jinpeng Huai, Robin Chen, Hsiao-Wuen Hon, Yunhao Liu, Wei-Ying Ma, Andrew Tomkins, and Xiaodong Zhang 0001, editors, WWW, pages 959‚Äì968. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Wang</author>
<author>Houfeng Wang</author>
</authors>
<title>Bootstrapping both product features and opinion words from chinese customer reviews with cross-inducing.</title>
<date>2008</date>
<contexts>
<context position="11321" citStr="Wang and Wang, 2008" startWordPosition="1738" endWordPosition="1741">rds. Their aim was only to perform aspect terms categorization but not to extract opinion targets/words. They extracted opinion targets/words in advanced through simple phrase detection. Thus, the extraction performance is far from expectation. 3 The Proposed Method In this section, we propose our method in detail. We formulate opinion targets/words extraction as a co-ranking task. All nouns/noun phrases are regarded as opinion target candidates, and all adjectives/verbs are regarded as opinion word candidates, which are widely adopted by pervious methods (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012). Then each candidate will be assigned a confidence and ranked, and the candidates with higher confidence than a threshold will be extracted as the results. Different from traditional methods, besides opinion relations among words, we additionally capture semantic relations among homogeneous candidates. To this end, a heterogeneous undirected graph G = (V, E) is constructed. V = V t U V o denotes the vertex set, which includes opinion target candidates vt E V t and opinion word candidates vo E V o. E denotes the edge set, where eij E E means that there is a relation between </context>
<context position="12675" citStr="Wang and Wang, 2008" startWordPosition="1969" endWordPosition="1972">s between two opinion word candidates. Eto C E represents the opinion relations between opinion target candidates and opinion word candidates. Based on different relation types, we used three matrices Mtt E R|V t|√ó|V t|, Moo E R|V o|√ó|V o| and Mto E R|V t|√ó|V o |to record the association weights between any two vertices, respectively. Section 3.4 will illustrate how to construct them. 3.1 Only Considering Opinion Relations To estimate the confidence of each candidate, we use a random walk algorithm on our graph to perform co-ranking. Most previous methods (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008; Liu et al., 2012) only considered opinion relations among words. Their basic assumption is as follows. Assumption 1: If a word is likely to be an opinion word, the words which it has opinion relation with will have higher confidence to be opinion targets, and vice versa. 316 In this way, candidates‚Äô confidences (vt or vo) are collectively determined by each other iteratively. It equals to making random walk on subgraph Gto = (V, Eto) of G. Thus we have Ct = (1 ‚àí ¬µ) x Mto x Co + ¬µ x It (1) Co = (1 ‚àí ¬µ) x MT to x Ct + ¬µ x Io where Ct and Co respectively represent confidences of opinion targets</context>
</contexts>
<marker>Wang, Wang, 2008</marker>
<rawString>Bo Wang and Houfeng Wang. 2008. Bootstrapping both product features and opinion words from chinese customer reviews with cross-inducing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Yue Lu</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Latent aspect rating analysis without aspect keyword supervision.</title>
<date>2011</date>
<pages>618--626</pages>
<editor>In Chid Apt, Joydeep Ghosh, and Padhraic Smyth, editors, KDD,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="24466" citStr="Wang et al., 2011" startWordPosition="4028" endWordPosition="4031">on word candidate, respectively. p(vt, vo) is the co-occurrence probability of vt and vo based on the opinion relation identification results. p(vt) and p(vo) give the independent occurrence probability of of vt and vo, respectively 4 Experiments 4.1 Datasets and Evaluation Metrics Datasets: To evaluate the proposed method, we used three datasets. The first one is Customer Review Datasets (CRD), used in (Hu and Liu, 2004a), which contains reviews about five products. The second one is COAE2008 dataset22, which contains Chinese reviews about four products. The third one is Large, also used in (Wang et al., 2011; Liu et al., 2012; Liu et al., 2013a), where two domains are selected (Mp3 and Hotel). As mentioned in (Liu et al., 2012), Large contains 6,000 sentences for each domain. Opinion targets/words are manually annotated, where three annotators were involved. Two annotators were required to annotate out opinion words/targets in reviews. When conflicts occur, the third annotator make final judgement. In total, we respectively obtain 1,112, 1,241 opinion targets and 334, 407 opinion words in Hotel, MP3. Pre-processing: All sentences are tagged to obtain words‚Äô part-of-speech tags using Stanford NLP </context>
</contexts>
<marker>Wang, Lu, Zhai, 2011</marker>
<rawString>Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011. Latent aspect rating analysis without aspect keyword supervision. In Chid Apt, Joydeep Ghosh, and Padhraic Smyth, editors, KDD, pages 618‚Äì626. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining. In</title>
<date>2009</date>
<booktitle>EMNLP,</booktitle>
<pages>1533--1541</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="7844" citStr="Wu et al., 2009" startWordPosition="1186" endWordPosition="1189">zed. A candidate‚Äôs confidence would mainly absorb the contributions from its word preferences rather than its all neighbors with opinion relations, which may be beneficial for improving extraction precision. We perform experiments on real-world datasets from different languages and different domains. Results show that our approach effectively improves extraction performance compared to the state-of-the-art approaches. 2 Related Work There are many significant research efforts on opinion targets/words extraction (sentence level and corpus level). In sentence level extraction, previous methods (Wu et al., 2009; Ma and Wan, 2010; Li et al., 2010; Yang and Cardie, 2013) mainly aimed to identify all opinion target/word mentions in sentences. They regarded it as a sequence labeling task, where several classical models were used, such as CRFs (Li et al., 2010) and SVM (Wu et al., 2009). This paper belongs to corpus level extraction, and aims to generate a sentiment lexicon and a target list rather than to identify mentions in senùê∫ùê∫ùë°ùë°ùë°ùë° ùëáùëáùëÇùëÇ1 ùëÇùëÇùëÇùëÇ1 ùëÇùëÇùëÇùëÇ2 ùëÇùëÇùëÇùëÇ3 ùëÇùëÇùëÇùëÇ4 ùëÇùëÇùëÇùëÇ5 ùëÇùëÇùëÇùëÇ6 ùê∫ùê∫ùëúùëúùëúùëú ùê∫ùê∫ ùë°ùë°ùëúùëú ùëáùëáùëÇùëÇ2 ùëáùëáùëÇùëÇ3 ùëáùëáùëÇùëÇ4 ùëáùëáùëÇùëÇ5 ùëáùëáùëÇùëÇ6 315 tences. Most of previous corpus-level methods adopted a co-extraction framework</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In EMNLP, pages 1533‚Äì1541. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bishan Yang</author>
<author>Claire Cardie</author>
</authors>
<title>Joint inference for fine-grained opinion extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1640--1649</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="7903" citStr="Yang and Cardie, 2013" startWordPosition="1198" endWordPosition="1201">e contributions from its word preferences rather than its all neighbors with opinion relations, which may be beneficial for improving extraction precision. We perform experiments on real-world datasets from different languages and different domains. Results show that our approach effectively improves extraction performance compared to the state-of-the-art approaches. 2 Related Work There are many significant research efforts on opinion targets/words extraction (sentence level and corpus level). In sentence level extraction, previous methods (Wu et al., 2009; Ma and Wan, 2010; Li et al., 2010; Yang and Cardie, 2013) mainly aimed to identify all opinion target/word mentions in sentences. They regarded it as a sequence labeling task, where several classical models were used, such as CRFs (Li et al., 2010) and SVM (Wu et al., 2009). This paper belongs to corpus level extraction, and aims to generate a sentiment lexicon and a target list rather than to identify mentions in senùê∫ùê∫ùë°ùë°ùë°ùë° ùëáùëáùëÇùëÇ1 ùëÇùëÇùëÇùëÇ1 ùëÇùëÇùëÇùëÇ2 ùëÇùëÇùëÇùëÇ3 ùëÇùëÇùëÇùëÇ4 ùëÇùëÇùëÇùëÇ5 ùëÇùëÇùëÇùëÇ6 ùê∫ùê∫ùëúùëúùëúùëú ùê∫ùê∫ ùë°ùë°ùëúùëú ùëáùëáùëÇùëÇ2 ùëáùëáùëÇùëÇ3 ùëáùëáùëÇùëÇ4 ùëáùëáùëÇùëÇ5 ùëáùëáùëÇùëÇ6 315 tences. Most of previous corpus-level methods adopted a co-extraction framework, where opinion targets and opinion words reinforce each ot</context>
</contexts>
<marker>Yang, Cardie, 2013</marker>
<rawString>Bishan Yang and Claire Cardie. 2013. Joint inference for fine-grained opinion extraction. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1640‚Äì1649, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Zhang</author>
<author>Bing Liu</author>
</authors>
<title>Suk Hwan Lim, and Eamonn O‚ÄôBrien-Strain.</title>
<date>2010</date>
<booktitle>In ChuRen Huang</booktitle>
<pages>1462--1470</pages>
<editor>and Dan Jurafsky, editors, COLING (Posters),</editor>
<marker>Zhang, Liu, 2010</marker>
<rawString>Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn O‚ÄôBrien-Strain. 2010. Extracting and ranking product features in opinion documents. In ChuRen Huang and Dan Jurafsky, editors, COLING (Posters), pages 1462‚Äì1470. Chinese Information Processing Society of China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Xin Zhao</author>
<author>Jing Jiang</author>
<author>Hongfei Yan</author>
<author>Xiaoming Li</author>
</authors>
<title>Jointly modeling aspects and opinions with a maxent-lda hybrid.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ‚Äô10,</booktitle>
<pages>56--65</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9594" citStr="Zhao et al., 2010" startWordPosition="1465" endWordPosition="1468">t al., 2013b) employed word alignment model to capture opinion relations rather than syntactic parsing. The experimental results showed that these alignment-based methods are more effective than syntax-based approaches for online informal texts. However, all aforementioned methods only employed opinion relations for the extraction, but ignore considering semantic relations among homogeneous candidates. Moreover, they all ignored word preference in the extraction process. In terms of considering semantic relations among words, our method is related with several approaches based on topic model (Zhao et al., 2010; Moghaddam and Ester, 2011; Moghaddam and Ester, 2012a; Moghaddam and Ester, 2012b; Mukherjee and Liu, 2012). The main goals of these methods weren‚Äôt to extract opinion targets/words, but to categorize all given aspect terms and sentiment words. Although these models could be used for our task according to the associations between candidates and topics, solely employing semantic relations is still one-sided and insufficient to obtain expected performance. Furthermore, there is little work which considered these two types of relations globally (Su et al., 2008; Hai et al., 2012; Bross and Ehri</context>
<context position="21916" citStr="Zhao et al., 2010" startWordPosition="3624" endWordPosition="3627">18 Ct = (1 ‚àí Œª ‚àí ¬µ) x ÀÜMto x Co + Œª x Mtt x Ct + ¬µ x It Co = (1 ‚àí Œª ‚àí ¬µ) x ÀÜMTto x Ct + Œª x Moo x Co + ¬µ x Io 3.4 Capturing Semantic and Opinion Relations In this section, we explain how to capture semantic relations and opinion relations for constructing transition matrices Mtt, Moo and Mto. Capturing Semantic Relations: For capturing semantic relations among homogenous candidates, we employ topics. We believe that if two candidates share similar topics in the corpus, there is a strong semantic relation between them. Thus, we employ a LDA variation (Mukherjee and Liu, 2012), an extension of (Zhao et al., 2010), to discover topic distribution on words, which sampled all words into two separated observations: opinion targets and opinion words. It‚Äôs because that we are only interested in topic distribution of opinion targets/words, regardless of other useless words, including conjunctions, prepositions etc. This model has been proven to be better than the standard LDA model and other LDA variations for opinion mining (Mukherjee and Liu, 2012). After topic modeling, we obtain the probability of the candidates (vt and vo) to topic z, i.e. p(z|vt) and p(z|vo), and topic distribution p(z). Then, a symmetr</context>
<context position="28450" citStr="Zhao et al., 2010" startWordPosition="4743" endWordPosition="4746">oposed by (Liu et al., 2013a), an extension of (Liu et al., 2012). They employed a word alignment model to capture opinion relations among words, and then used a random walking algorithm to extract opinion targets. Hai is proposed by (Hai et al., 2012), which is similar to our method. They employed both of semantic relations and opinion relations to extract opinion words/targets in a bootstrapping framework. But they captured relations only using cooccurrence statistics. Moreover, word preference was not considered. SAS is proposed by (Mukher ee and Liu, 2012), an extended lda-based model of (Zhao et al., 2010). The top K items for each aspect are extracted as opinion targets/words. It means that only semantic relations among words are considered in SAS. And we set aspects number to be 9 as same as (Mukher ee and Liu, 2012). CR: is the proposed method in this paper by using co-ranking, referring to Eq.4. CR doesn‚Äôt consider word preference. CR WP: is the full implementation of our method, referring to Eq.6. Hu, DP, Zhang and Liu are the methods which only consider opinion relations among words. SAS is the methods which only consider semantic relations among words. Hai, CR and CR WP consider these tw</context>
</contexts>
<marker>Zhao, Jiang, Yan, Li, 2010</marker>
<rawString>Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaoming Li. 2010. Jointly modeling aspects and opinions with a maxent-lda hybrid. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ‚Äô10, pages 56‚Äì 65, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jingbo Zhu</author>
<author>Huizhen Wang</author>
<author>Benjamin K Tsou</author>
<author>Muhua Zhu</author>
</authors>
<title>Multi-aspect opinion polling from textual reviews. In</title>
<date>2009</date>
<pages>1799--1802</pages>
<editor>David Wai-Lok Cheung, Il-Yeol Song, Wesley W. Chu, Xiaohua Hu, and Jimmy J. Lin, editors, CIKM,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="25143" citStr="Zhu et al., 2009" startWordPosition="4134" endWordPosition="4137">e selected (Mp3 and Hotel). As mentioned in (Liu et al., 2012), Large contains 6,000 sentences for each domain. Opinion targets/words are manually annotated, where three annotators were involved. Two annotators were required to annotate out opinion words/targets in reviews. When conflicts occur, the third annotator make final judgement. In total, we respectively obtain 1,112, 1,241 opinion targets and 334, 407 opinion words in Hotel, MP3. Pre-processing: All sentences are tagged to obtain words‚Äô part-of-speech tags using Stanford NLP tool3. And noun phrases are identified using the method in (Zhu et al., 2009) before extraction. Evaluation Metrics: We select precision(P), recall(R) and f-measure(F) as metrics. And a significant test is performed, i.e., a t-test with a default significant level of 0.05. 4.2 Our Method vs. The State-of-the-art Methods To prove the effectiveness of the proposed method, we select some state-of-the-art methods for comparison as follows: 2http://ir-china.org.cn/coae2008.html 3http://nlp.stanford.edu/software/tagger.shtml (6) 319 Methods D1 D2 D3 D4 D5 Avg. P R F P R F P R F P R F P R F F Hu 0.75 0.82 0.78 0.71 0.79 0.75 0.72 0.76 0.74 0.69 0.82 0.75 0.74 0.80 0.77 0.758 </context>
</contexts>
<marker>Zhu, Wang, Tsou, Zhu, 2009</marker>
<rawString>Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and Muhua Zhu. 2009. Multi-aspect opinion polling from textual reviews. In David Wai-Lok Cheung, Il-Yeol Song, Wesley W. Chu, Xiaohua Hu, and Jimmy J. Lin, editors, CIKM, pages 1799‚Äì1802. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>