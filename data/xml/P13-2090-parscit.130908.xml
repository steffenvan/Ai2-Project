<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000124">
<title confidence="0.998576">
Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues
from Multilingual Twitter Streams
</title>
<author confidence="0.949677">
Svitlana Volkova
</author>
<affiliation confidence="0.8366155">
CLSP
Johns Hopkins University
</affiliation>
<address confidence="0.875935">
Baltimore, MD
</address>
<email confidence="0.998404">
svitlana@jhu.edu
</email>
<note confidence="0.452929">
Theresa Wilson
HLTCOE
</note>
<address confidence="0.6369845">
Johns Hopkins University
Baltimore, MD
</address>
<email confidence="0.998426">
taw@jhu.edu
</email>
<author confidence="0.925567">
David Yarowsky
</author>
<affiliation confidence="0.8133465">
CLSP
Johns Hopkins University
</affiliation>
<address confidence="0.873403">
Baltimore, MD
</address>
<email confidence="0.99913">
yarowsky@cs.jhu.edu
</email>
<sectionHeader confidence="0.9939" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999867142857143">
We study subjective language in social
media and create Twitter-specific lexi-
cons via bootstrapping sentiment-bearing
terms from multilingual Twitter streams.
Starting with a domain-independent, high-
precision sentiment lexicon and a large
pool of unlabeled data, we bootstrap
Twitter-specific sentiment lexicons, us-
ing a small amount of labeled data to
guide the process. Our experiments on
English, Spanish and Russian show that
the resulting lexicons are effective for
sentiment classification for many under-
explored languages in social media.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999933488372093">
The language that people use to express opinions
and sentiment is extremely diverse. This is true for
well-formed data, such as news and reviews, and
it is particularly true for data from social media.
Communication in social media is informal, ab-
breviations and misspellings abound, and the per-
son communicating is often trying to be funny,
creative, and entertaining. Topics change rapidly,
and people invent new words and phrases.
The dynamic nature of social media together
with the extreme diversity of subjective language
has implications for any system with the goal
of analyzing sentiment in this domain. General,
domain-independent sentiment lexicons have low
coverage. Even models trained specifically on so-
cial media data may degrade somewhat over time
as topics change and new sentiment-bearing terms
crop up. For example, the word “occupy” would
not have been indicative of sentiment before 2011.
Most of the previous work on sentiment lexicon
construction relies on existing natural language
processing tools, e.g., syntactic parsers (Wiebe,
2000), information extraction (IE) tools (Riloff
and Wiebe, 2003) or rich lexical resources such
as WordNet (Esuli and Sebastiani, 2006). How-
ever, such tools and lexical resources are not avail-
able for many languages spoken in social media.
While English is still the top language in Twitter,
it is no longer the majority. Thus, the applicabil-
ity of these approaches is limited. Any method for
analyzing sentiment in microblogs or other social
media streams must be easily adapted to (1) many
low-resource languages, (2) the dynamic nature of
social media, and (3) working in a streaming mode
with limited or no supervision.
Although bootstrapping has been used for learn-
ing sentiment lexicons in other domains (Turney
and Littman, 2002; Banea et al., 2008), it has not
yet been applied to learning sentiment lexicons for
microblogs. In this paper, we present an approach
for bootstrapping subjectivity clues from Twitter
data, and evaluate our approach on English, Span-
ish and Russian Twitter streams. Our approach:
</bodyText>
<listItem confidence="0.99014905882353">
• handles the informality, creativity and the dy-
namic nature of social media;
• does not rely on language-dependent tools;
• scales to the hundreds of new under-explored
languages and dialects in social media;
• classifies sentiment in a streaming mode.
To bootstrap subjectivity clues from Twitter
streams we rely on three main assumptions:
i. sentiment-bearing terms of similar orienta-
tion tend to co-occur at the tweet level (Tur-
ney and Littman, 2002);
ii. sentiment-bearing terms of opposite orienta-
tion do not co-occur at the tweet level (Ga-
mon and Aue, 2005);
iii. the co-occurrence of domain-specific and
domain-independent subjective terms serves
as a signal of subjectivity.
</listItem>
<page confidence="0.969892">
505
</page>
<note confidence="0.5301245">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 505–510,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.998962" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999964428571429">
Mihalcea et.al (2012) classifies methods for boot-
strapping subjectivity lexicons into two types:
corpus-based and dictionary-based.
Dictionary-based methods rely on existing lex-
ical resources to bootstrap sentiment lexicons.
Many researchers have explored using relations in
WordNet (Miller, 1995), e.g., Esuli and Sabastiani
(2006), Andreevskaia and Bergler (2006) for En-
glish, Rao and Ravichandran (2009) for Hindi and
French, and Perez-Rosas et al. (2012) for Spanish.
Mohammad et al. (2009) use a thesaurus to aid
in the construction of a sentiment lexicon for En-
glish. Other works (Clematide and Klenner, 2010;
Abdul-Mageed et al., 2011) automatically expands
and evaluates German and Arabic lexicons. How-
ever, the lexical resources that dictionary-based
methods need, do not yet exist for the majority of
languages in social media. There is also a mis-
match between the formality of many language re-
sources, such as WordNet, and the extremely in-
formal language of social media.
Corpus-based methods extract subjectivity and
sentiment lexicons from large amounts of unla-
beled data using different similarity metrics to
measure the relatedness between words. Hatzivas-
siloglou and McKeown (1997) were the first to ex-
plore automatically learning the polarity of words
from corpora. Early work by Wiebe (2000) iden-
tifies clusters of subjectivity clues based on their
distributional similarity, using a small amount of
data to bootstrap the process. Turney (2002) and
Velikovich et al. (2010) bootstrap sentiment lexi-
cons for English from the web by using Pointwise
Mutual Information (PMI) and graph propaga-
tion approach, respectively. Kaji and Kitsuregawa
(2007) propose a method for building sentiment
lexicon for Japanese from HTML pages. Banea
et al. (2008) experiment with Lexical Semantic
Analysis (LSA) (Dumais et al., 1988) to bootstrap
a subjectivity lexicon for Romanian. Kanayama
and Nasukawa (2006) bootstrap subjectivity lexi-
cons for Japanese by generating subjectivity can-
didates based on word co-occurrence patterns.
In contrast to other corpus-based bootstrapping
methods, we evaluate our approach on multiple
languages, specifically English, Spanish, and Rus-
sian. Also, as our approach relies only on the
availability of a bilingual dictionary for translating
an English subjectivity lexicon and crowdsourcing
for help in selecting seeds, it is more scalable and
better able to handle the informality and the dy-
namic nature of social media. It also can be effec-
tively used to bootstrap sentiment lexicons for any
language for which a bilingual dictionary is avail-
able or can be automatically induced from parallel
corpora.
</bodyText>
<sectionHeader confidence="0.993956" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999941611111111">
For the experiments in this paper, we use three
sets of data for each language: 1M unlabeled
tweets (BOOT) for bootstrapping Twitter-specific
lexicons, 2K labeled tweets for development data
(DEV), and 2K labeled tweets for evaluation
(TEST). DEV is used for parameter tuning while
bootstrapping, and TEST is used to evaluating the
quality of the bootstrapped lexicons.
We take English tweets from the corpus con-
structed by Burger et al. (2011) which con-
tains 2.9M tweets (excluding retweets) from 184K
users.1 English tweets are identified automati-
cally using a compression-based language identifi-
cation (LID) tool (Bergsma et al., 2012). Accord-
ing to LID, there are 1.8M (63.6%) English tweets,
which we randomly sample to create BOOT, DEV
and TEST sets for English. Unfortunately, Burger’s
corpus does not include Russian and Spanish data
on the same scale as English. Therefore, for
other languages we construct a new Twitter corpus
by downloading tweets from followers of region-
specific news and media feeds.
Sentiment labels for tweets in DEV and TEST
sets for all languages are obtained using Amazon
Mechanical Turk. For each tweet we collect an-
notations from five workers and use majority vote
to determine the final label for the tweet. Snow
et al. (2008) show that for a similar task, labeling
emotion and valence, on average four non-expert
labelers are needed to achieve an expert level of
annotation. Table 1 gives the distribution of tweets
over sentiment labels for the development and test
sets for English (E-DEV, E-TEST), Spanish (S-
DEV, S-TEST), and Russian (R-DEV, R-TEST).
Below are examples of tweets in Russian with En-
glish translations labeled with sentiment:
</bodyText>
<listItem confidence="0.997993">
• Positive: B IIJlaaax BxycablH 3aBTpax
H xy&apos;qa CbIIJlbMOB (Planning for delicious
breakfast and lots of movies);
• Negative: XO&apos;qy cgOxayTb, H x 9TO cgeJlalo
(I want to die and I will do that);
</listItem>
<footnote confidence="0.9427995">
1They provided the tweet IDs, and we used the Twitter
Corpus Tools to download the tweets.
</footnote>
<page confidence="0.986576">
506
</page>
<table confidence="0.999679571428572">
Data Positive Neg Both Neutral
E-DEV 617 357 202 824
E-TEST 596 347 195 862
S-DEV 358 354 86 1,202
S-TEST 317 387 93 1203
R-DEV 452 463 156 929
R-TEST 488 380 149 983
</table>
<tableCaption confidence="0.863724">
Table 1: Sentiment label distribution in develop-
ment DEV and test TEST datasets across languages.
</tableCaption>
<listItem confidence="0.99892">
• Both: Хочется написать грубее про
фильм но не буду. Хотя актеры хоро-
ши (I want to write about the movie rougher
but I will not. Although the actors are good);
• Neutral: Почему умные мысли приходят
только ночью? (Why clever thoughts come
only at night?).
</listItem>
<sectionHeader confidence="0.957347" genericHeader="method">
4 Lexicon Bootstrapping
</sectionHeader>
<bodyText confidence="0.999926">
To create a Twitter-specific sentiment lexicon for
a given language, we start with a general-purpose,
high-precision sentiment lexicon2 and bootstrap
from the unlabeled data (BOOT) using the labeled
development data (DEV) to guide the process.
</bodyText>
<subsectionHeader confidence="0.998418">
4.1 High-Precision Subjectivity Lexicons
</subsectionHeader>
<bodyText confidence="0.999702375">
For English we seed the bootstrapping pro-
cess with the strongly subjective terms from the
MPQA lexicon3 (Wilson et al., 2005). These
terms have been previously shown to be high-
precision for recognizing subjective sentences
(Riloff and Wiebe, 2003).
For the other languages, the subjective seed
terms are obtained by translating English seed
terms using a bilingual dictionary, and then col-
lecting judgments about term subjectivity from
Mechanical Turk. Terms that truly are strongly
subjective in translation are used for seed terms
in the new language, with term polarity projected
from the English. Finally, we expand the lexicons
with plurals and inflectional forms for adverbs, ad-
jectives and verbs.
</bodyText>
<subsectionHeader confidence="0.998945">
4.2 Bootstrapping Approach
</subsectionHeader>
<bodyText confidence="0.99990175">
To bootstrap, first the new lexicon LB(0) is seeded
with the strongly subjective terms from the orig-
inal lexicon LI. On each iteration i &gt; 1, tweets
in the unlabeled data are labeled using the lexicon
</bodyText>
<footnote confidence="0.99160725">
2Other works on generating domain-specific sentiment
lexicons e.g., from blog data (Jijkoun et al., 2010) also start
with a general, domain-specific lexicon.
3http://www.cs.pitt.edu/mpqa/
</footnote>
<bodyText confidence="0.999925684210526">
from the previous iteration, LB(i−1). If a tweet
contains one or more terms from LB(i−1) it is con-
sidered subjective, otherwise objective. The polar-
ity of subjective tweets is determined in a similar
way: if the tweet contains &gt; 1 positive terms, tak-
ing into account the negation, it is considered neg-
ative; if it contains &gt; 1 negative terms, taking into
account the negation, it is considered positive.4 If
it contains both positive and negative terms, it is
considered to be both. Then, for every term not in
LB(i−1) that has a frequency &gt; θfreq, the proba-
bility of that term being subjective is calculated as
shown in Algorithm 1 line 10. The top θk terms
with a subjective probability &gt; θpr are then added
to LB(i). The polarity of new terms is determined
based on the probability of the term appearing in
positive or negative tweets as shown in line 18.5
The bootstrapping process terminates when there
are no more new terms meeting the criteria to add.
</bodyText>
<figure confidence="0.969130695652174">
Algorithm 1 BOOTSTRAP (σ, θpr, θfreq, θtopK)
1: iter = 0, σ = 0.5, LB(�B) +- LI(σ)
2: while (stop =� true) do
3: Liter
B (B) +- 0, ΔLiter
B (B) +- 0
4: for each new term w E {V \ LB(B)} do
5: for each tweet t E T do
6: if w E t then
7: UPDATE c(w, LB(0)), c(w, Lpos
B (�B)), c(w)
8: end if
9: end for
10: psubj(w) +- c(w,LB(
c(w)
ppos(w) +- c(w,Lpos
B (~θ))
11: c(w,LB(~θ))
12: Liter
B (B) +- w, psubj(w), ppol(w)
13: end for
14: SORT Liter() by psubj(w)
15: while (K &lt;_\ BtopK) do
16: for each new term w E Liter
B (B) do
17: if [psubj(w) &gt; Bpr and cw &gt; Bfreq then
18: I�if [ppos(w) &gt; 0.5] then
19: wpol +- positive
20: else
21: wpol +- negative
22: end if
23: ΔLiter
B (�B) +- ΔLiter
B (B) + wpol
24: end if
25: end for
26: K = K + 1
27: end while
28: if [ΔLiter
B (B) == 0] then
29: stop +- true
30: end if
31: LB(B) +- LB(B) + ΔLiter
B (�B)
32: iter = iter + 1
33: end while
</figure>
<footnote confidence="0.993724666666667">
4If there is a negation in the two words before a sentiment
term, we flip its polarity.
5Polarity association probabilities should sum up to 1
</footnote>
<equation confidence="0.994157">
ppos(w|LB(�B)) + pneg(w|LB(�B)) = 1.
~θ))
</equation>
<page confidence="0.992676">
507
</page>
<table confidence="0.922473666666667">
English Spanish Russian
LE LE LS LS LR LR
I B I B I B
Pos 2.3 16.8 2.9 7.7 1.4 5.3
Neg 2.8 4.7 5.2 14.6 2.3 5.5
Total 5.1 21.5 8.1 22.3 3.7 10.8
</table>
<tableCaption confidence="0.995052">
Table 2: The original and the bootstrapped (high-
</tableCaption>
<bodyText confidence="0.922826">
lighted) lexicon term count (LI ⊂ LB) with polar-
ity across languages (thousands).
The set of parameters θ�is optimized using a grid
search on the development data using F-measure
for subjectivity classification. As a result, for En-
glish θ� = [0.7, 5, 50] meaning that on each itera-
tion the top 50 new terms with a frequency &gt; 5
and probability &gt; 0.7 are added to the lexicon.
For Spanish, the set of optimal parameters θ� =
[0.65, 3, 50] and for Russian - θ� = [0.65, 3, 50]. In
Table 2 we report size and term polarity from the
original LI and the bootstrapped LB lexicons.
</bodyText>
<sectionHeader confidence="0.989496" genericHeader="method">
5 Lexicon Evaluations
</sectionHeader>
<bodyText confidence="0.999939148148148">
We evaluate our bootstrapped sentiment lexicons
English LEB, Spanish LSB and Russian LRB by com-
paring them with existing dictionary-expanded
lexicons that have been previously shown to be ef-
fective for subjectivity and polarity classification
(Esuli and Sebastiani, 2006; Perez-Rosas et al.,
2012; Chetviorkin and Loukachevitch, 2012). For
that we perform subjectivity and polarity classifi-
cation using rule-based classifiers6 on the test data
E-TEST, S-TEST and R-TEST.
We consider how the various lexicons perform
for rule-based classifiers for both subjectivity and
polarity. The subjectivity classifier predicts that
a tweet is subjective if it contains a) at least one,
or b) at least two subjective terms from the lexi-
con. For the polarity classifier, we predict a tweet
to be positive (negative) if it contains at least one
positive (negative) term taking into account nega-
tion. If the tweet contains both positive and nega-
tive terms, we take the majority label.
For English we compare our bootstrapped lex-
icon LEB against the original lexicon LEI and
strongly subjective terms from SentiWordNet 3.0
(Esuli and Sebastiani, 2006). To make a fair
comparison, we automatically expand SentiWord-
Net with noun plural forms and verb inflectional
forms. In Figure 1 we report precision, recall
</bodyText>
<footnote confidence="0.5724745">
6Similar approach to a rule-based classification using
terms from he MPQA lexicon (Riloff and Wiebe, 2003).
</footnote>
<bodyText confidence="0.9991844">
and F-measure results. They show that our boot-
strapped lexicon significantly outperforms Senti-
WordNet for subjectivity classification. For polar-
ity classification we get comparable F-measure but
much higher recall for LEB compared to SWN.
</bodyText>
<table confidence="0.931918857142857">
(a) Subj &gt; 1 (b) Subj &gt; 2 (c) Polarity
Lexicon Fsubj&gt;1 Fsubj&gt;2 Fpolarity
SWN 0.57 0.27 0.78
LE 0.71 0.48 0.82
I 0.75 0.72 0.78
LE
B
</table>
<figureCaption confidence="0.724047">
Figure 1: Precision (x-axis), recall (y-axis) and
F-measure (in the table) for English: LEI = ini-
tial lexicon, LEB = bootstrapped lexicon, SWN =
strongly subjective terms from SentiWordNet.
</figureCaption>
<bodyText confidence="0.999686636363636">
For Spanish we compare our bootstrapped lex-
icon LSB against the original LSI lexicon, and the
full and medium strength terms from the Span-
ish sentiment lexicon constructed by Perez-Rosas
et el. (2012). We report precision, recall and F-
measure in Figure 2. We observe that our boot-
strapped lexicon yields significantly better perfor-
mance for subjectivity classification compared to
both full and medium strength terms. However,
our bootstrapped lexicon yields lower recall and
similar precision for polarity classification.
</bodyText>
<table confidence="0.9366">
(a) Subj &gt; 1 (b) Subj &gt; 2 (c) Polarity
Lexicon Fsubj&gt;1 Fsubj&gt;2 Fpolarity
SM 0.44 0.17 0.64
SF 0.47 0.13 0.66
LS 0.59 0.45 0.58
I 0.59 0.59 0.55
LS
B
</table>
<figureCaption confidence="0.977551">
Figure 2: Precision (x-axis), recall (y-axis) and F-
</figureCaption>
<bodyText confidence="0.706490666666667">
measure (in the table) for Spanish: LSI = initial
lexicon, LSB = bootstrapped lexicon, SF = full
strength terms; SM = medium strength terms.
</bodyText>
<page confidence="0.993796">
508
</page>
<bodyText confidence="0.999933176470588">
For Russian we compare our bootstrapped lex-
icon LRB against the original LRI lexicon, and the
Russian sentiment lexicon constructed by Chetv-
iorkin and Loukachevitchet (2012). The external
lexicon in Russian P was built for the domain
of product reviews and does not include polarity
judgments for subjective terms. As before, we
expand the external lexicon with the inflectional
forms for adverbs, adjectives and verbs. We report
results for Russian in Figure 3. We find that for
subjectivity our bootstrapped lexicon shows better
performance compared to the external lexicon (5k
terms). However, the expanded external lexicon
(17k terms) yields higher recall with a significant
drop in precision. Note that for Russian, we report
polarity classification results for LRB and LR I lexi-
cons only because P does not have polarity labels.
</bodyText>
<table confidence="0.944614125">
(a) Subj &gt; 1 (b) Subj &gt; 2 (c) Polarity
Lexicon Fsubj&gt;1 Fsubj&gt;2 Fpolarity
P 0.62 0.47 0.73
PX 0.46 0.13 0.73
LR 0.61 0.35
I
LR
B
</table>
<figureCaption confidence="0.984463">
Figure 3: Precision (x-axis), recall (y-axis) and F-
</figureCaption>
<bodyText confidence="0.993894235294118">
measure for Russian: LR I = initial lexicon, LRB =
bootstrapped lexicon, P = external sentiment lex-
icon, PX = expanded external lexicon.
We next perform error analysis for subjectiv-
ity and polarity classification for all languages and
identify common errors to address them in future.
For subjectivity classification we observe that
applying part-of-speech tagging during the boot-
strapping could improve results for all languages.
We could further improve the quality of the lex-
icon and reduce false negative errors (subjec-
tive tweets classified as neutral) by focusing on
sentiment-bearing terms such as adjective, adverbs
and verbs. However, POS taggers for Twitter are
only available for a limited number of languages
such as English (Gimpel et al., 2011). Other false
negative errors are often caused by misspellings.7
</bodyText>
<footnote confidence="0.969691333333333">
7For morphologically-rich languages, our approach cov-
ers different linguistic forms of terms but not their mis-
spellings. However, it can be fixed by an edit-distance check.
</footnote>
<bodyText confidence="0.999921411764706">
We also find subjective tweets with philosophi-
cal thoughts and opinions misclassified, especially
in Russian, e.g., Иногда мы бываем не готовы
к исполнению заветной мечты но все рав-
но так не хочется ее спугнуть (Sometimes we
are not ready to fulfill our dreams yet but, at the
same time, we do not want to scare them). Such
tweets are difficult to classify using lexicon-based
approaches and require deeper linguistic analysis.
False positive errors for subjectivity classifica-
tion happen because some terms are weakly sub-
jective and can be used in both subjective and
neutral tweets e.g., the Russian term хвастаться
(brag) is often used as subjective, but in a tweet
никогда не стоит хвастаться будущим (never
brag about your future) it is used as neutral. Simi-
larly, the Spanish term buenas (good) is often used
subjectively but it is used as neutral in the follow-
ing tweet “@Diveke me falto el buenas! jaja que
onda que ha pasado” (I miss the good times we
had, haha that wave has passed!).
For polarity classification, most errors happen
because our approach relies on either positive or
negative polarity scores for a term but not both.8
However, in the real world terms may sometimes
have both usages. Thus, some tweets are misclas-
sified (e.g., “It is too warm outside”). We can
fix this by summing over weighted probabilities
rather than over term counts. Additional errors
happen because tweets are very short and convey
multiple messages (e.g., “What do you mean by
unconventional? Sounds exciting!”) Thus, our ap-
proach can be further improved by adding word
sense disambiguation and anaphora resolution.
</bodyText>
<sectionHeader confidence="0.999551" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999527454545455">
We propose a scalable and language independent
bootstrapping approach for learning subjectivity
clues from Twitter streams. We demonstrate the
effectiveness of the bootstrapping procedure by
comparing the resulting subjectivity lexicons with
state-of the-art sentiment lexicons. We perform
error analysis to address the most common error
types in the future. The results confirm that the
approach can be effectively exploited and further
improved for subjectivity classification for many
under-explored languages in social media.
</bodyText>
<footnote confidence="0.9768198">
8During the bootstrapping we calculate probability for a
term to be positive and negative, e.g., p(warm|+) = 0.74
and p(warm|−) = 0.26. But during polarity classification
we rely on the highest probability score and consider it to be
“the polarity” for the term e.g., positive for warm.
</footnote>
<page confidence="0.99678">
509
</page>
<sectionHeader confidence="0.989318" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99985104">
Muhammad Abdul-Mageed, Mona T. Diab, and Mo-
hammed Korayem. 2011. Subjectivity and senti-
ment analysis of modern standard arabic. In Pro-
ceedings of ACL/HLT.
Alina Andreevskaia and Sabine Bergler. 2006. Min-
ing wordnet for fuzzy sentiment: Sentiment tag ex-
traction from WordNet glosses. In Proceedings of
EACL.
Carmen Banea, Rada Mihalcea, and Janyce Wiebe.
2008. A bootstrapping method for building subjec-
tivity lexicons for languages with scarce resources.
In Proceedings of LREC.
Shane Bergsma, Paul McNamee, Mossaab Bagdouri,
Clayton Fink, and Theresa Wilson. 2012. Language
identification for creating language-specific Twitter
collections. In Proceedings of 2nd Workshop on
Language in Social Media.
John D. Burger, John C. Henderson, George Kim, and
Guido Zarrella. 2011. Discriminating gender on
Twittier. In Proceedings of EMNLP.
Ilia Chetviorkin and Natalia V. Loukachevitch. 2012.
Extraction of Russian sentiment lexicon for product
meta-domain. In Proceedings of COLING.
Simon Clematide and Manfred Klenner. 2010. Eval-
uation and extension of a polarity lexicon for Ger-
man. In Proceedings of the 1st Workshop on Com-
putational Approaches to Subjectivity and Sentiment
Analysis.
Susan T. Dumais, George W. Furnas, Thomas K. Lan-
dauer, Scott Deerwester, and Richard Harshman.
1988. Using latent semantic analysis to improve
access to textual information. In Proceedings of
SIGCHI.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
WordNet: A publicly available lexical resource for
opinion mining. In Proceedings of LREC.
Michael Gamon and Anthony Aue. 2005. Automatic
identification of sentiment vocabulary: exploiting
low association with known sentiment terms. In
Proceedings of the ACL Workshop on Feature Engi-
neering for Machine Learning in Natural Language
Processing.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for Twittier: annotation, features, and experiments.
In Proceedings of ACL.
Vasileios Hatzivassiloglou and Kathy McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proceedings of ACL.
Valentin Jijkoun, Maarten de Rijke, and Wouter
Weerkamp. 2010. Generating focused topic-
specific sentiment lexicons. In Proceedings ofACL.
Nobuhiro Kaji and Masaru Kitsuregawa. 2007. Build-
ing lexicon for sentiment analysis from massive
collection of html documents. In Proceedings of
EMNLP.
Hiroshi Kanayama and Tetsuya Nasukawa. 2006.
Fully automatic lexicon expansion for domain-
oriented sentiment analysis. In Proceedings of
EMNLP.
Rada Mihalcea, Carmen Banea, and Janyce Wiebe.
2012. Multilingual subjectivity and sentiment anal-
ysis. In Proceedings of ACL.
George A. Miller. 1995. Wordnet: a lexical database
for English. Communications of the ACM, 38(11).
Saif Mohammad, Cody Dunne, and Bonnie Dorr.
2009. Generating high-coverage semantic orienta-
tion lexicons from overtly marked words and a the-
saurus. In Proceedings of EMNLP.
Veronica Perez-Rosas, Carmen Banea, and Rada Mi-
halcea. 2012. Learning sentiment lexicons in Span-
ish. In Proceedings of LREC.
Delip Rao and Deepak Ravichandran. 2009. Semi-
supervised polarity lexicon induction. In Proceed-
ings of EACL.
Ellen Riloff and Janyce Wiebe. 2003. Learning extrac-
tion patterns for subjective expressions. In Proceed-
ings of EMNLP.
Rion Snow, Brendan O’Connor, Daniel Jurafsky, and
Andrew Y. Ng. 2008. Cheap and fast – but is it
good?: Evaluating non-expert annotations for natu-
ral language tasks. In Proceedings of EMNLP.
Peter D. Turney and Michael L. Littman. 2002. Un-
supervised learning of semantic orientation from a
hundred-billion-word corpus. Computing Research
Repository.
Peter D. Turney. 2002. Thumbs up or thumbs down?:
Semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of ACL.
Leonid Velikovich, Sasha Blair-Goldensohn, Kerry
Hannan, and Ryan McDonald. 2010. The viabil-
ity of web-derived polarity lexicons. In Proceedings
of NAACL.
Janyce Wiebe. 2000. Learning subjective adjectives
from corpora. In Proceedings of AAAI.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of EMNLP.
</reference>
<page confidence="0.996671">
510
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.024028">
<title confidence="0.833391">Exploring Sentiment in Social Media: Bootstrapping Subjectivity from Multilingual Twitter Streams Svitlana</title>
<author confidence="0.721581">Johns Hopkins</author>
<affiliation confidence="0.645237">Baltimore,</affiliation>
<email confidence="0.999332">svitlana@jhu.edu</email>
<author confidence="0.954225">Theresa</author>
<affiliation confidence="0.5901815">HLTCOE Johns Hopkins</affiliation>
<address confidence="0.513569">Baltimore,</address>
<email confidence="0.999729">taw@jhu.edu</email>
<author confidence="0.830308">David</author>
<affiliation confidence="0.610717">Johns Hopkins</affiliation>
<address confidence="0.401625">Baltimore,</address>
<email confidence="0.999902">yarowsky@cs.jhu.edu</email>
<abstract confidence="0.996579">We study subjective language in social media and create Twitter-specific lexicons via bootstrapping sentiment-bearing terms from multilingual Twitter streams. Starting with a domain-independent, highprecision sentiment lexicon and a large pool of unlabeled data, we bootstrap Twitter-specific sentiment lexicons, using a small amount of labeled data to guide the process. Our experiments on English, Spanish and Russian show that the resulting lexicons are effective for sentiment classification for many underexplored languages in social media.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Muhammad Abdul-Mageed</author>
<author>Mona T Diab</author>
<author>Mohammed Korayem</author>
</authors>
<title>Subjectivity and sentiment analysis of modern standard arabic.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL/HLT.</booktitle>
<contexts>
<context position="4509" citStr="Abdul-Mageed et al., 2011" startWordPosition="668" endWordPosition="671">2012) classifies methods for bootstrapping subjectivity lexicons into two types: corpus-based and dictionary-based. Dictionary-based methods rely on existing lexical resources to bootstrap sentiment lexicons. Many researchers have explored using relations in WordNet (Miller, 1995), e.g., Esuli and Sabastiani (2006), Andreevskaia and Bergler (2006) for English, Rao and Ravichandran (2009) for Hindi and French, and Perez-Rosas et al. (2012) for Spanish. Mohammad et al. (2009) use a thesaurus to aid in the construction of a sentiment lexicon for English. Other works (Clematide and Klenner, 2010; Abdul-Mageed et al., 2011) automatically expands and evaluates German and Arabic lexicons. However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. There is also a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language of social media. Corpus-based methods extract subjectivity and sentiment lexicons from large amounts of unlabeled data using different similarity metrics to measure the relatedness between words. Hatzivassiloglou and McKeown (1997) were the first to explore automatically lear</context>
</contexts>
<marker>Abdul-Mageed, Diab, Korayem, 2011</marker>
<rawString>Muhammad Abdul-Mageed, Mona T. Diab, and Mohammed Korayem. 2011. Subjectivity and sentiment analysis of modern standard arabic. In Proceedings of ACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>Mining wordnet for fuzzy sentiment: Sentiment tag extraction from WordNet glosses.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="4232" citStr="Andreevskaia and Bergler (2006)" startWordPosition="621" endWordPosition="624">endent subjective terms serves as a signal of subjectivity. 505 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 505–510, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2 Related Work Mihalcea et.al (2012) classifies methods for bootstrapping subjectivity lexicons into two types: corpus-based and dictionary-based. Dictionary-based methods rely on existing lexical resources to bootstrap sentiment lexicons. Many researchers have explored using relations in WordNet (Miller, 1995), e.g., Esuli and Sabastiani (2006), Andreevskaia and Bergler (2006) for English, Rao and Ravichandran (2009) for Hindi and French, and Perez-Rosas et al. (2012) for Spanish. Mohammad et al. (2009) use a thesaurus to aid in the construction of a sentiment lexicon for English. Other works (Clematide and Klenner, 2010; Abdul-Mageed et al., 2011) automatically expands and evaluates German and Arabic lexicons. However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. There is also a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language</context>
</contexts>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2006. Mining wordnet for fuzzy sentiment: Sentiment tag extraction from WordNet glosses. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
<author>Janyce Wiebe</author>
</authors>
<title>A bootstrapping method for building subjectivity lexicons for languages with scarce resources.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="2717" citStr="Banea et al., 2008" startWordPosition="399" endWordPosition="402">However, such tools and lexical resources are not available for many languages spoken in social media. While English is still the top language in Twitter, it is no longer the majority. Thus, the applicability of these approaches is limited. Any method for analyzing sentiment in microblogs or other social media streams must be easily adapted to (1) many low-resource languages, (2) the dynamic nature of social media, and (3) working in a streaming mode with limited or no supervision. Although bootstrapping has been used for learning sentiment lexicons in other domains (Turney and Littman, 2002; Banea et al., 2008), it has not yet been applied to learning sentiment lexicons for microblogs. In this paper, we present an approach for bootstrapping subjectivity clues from Twitter data, and evaluate our approach on English, Spanish and Russian Twitter streams. Our approach: • handles the informality, creativity and the dynamic nature of social media; • does not rely on language-dependent tools; • scales to the hundreds of new under-explored languages and dialects in social media; • classifies sentiment in a streaming mode. To bootstrap subjectivity clues from Twitter streams we rely on three main assumptions</context>
<context position="5628" citStr="Banea et al. (2008)" startWordPosition="840" endWordPosition="843">ness between words. Hatzivassiloglou and McKeown (1997) were the first to explore automatically learning the polarity of words from corpora. Early work by Wiebe (2000) identifies clusters of subjectivity clues based on their distributional similarity, using a small amount of data to bootstrap the process. Turney (2002) and Velikovich et al. (2010) bootstrap sentiment lexicons for English from the web by using Pointwise Mutual Information (PMI) and graph propagation approach, respectively. Kaji and Kitsuregawa (2007) propose a method for building sentiment lexicon for Japanese from HTML pages. Banea et al. (2008) experiment with Lexical Semantic Analysis (LSA) (Dumais et al., 1988) to bootstrap a subjectivity lexicon for Romanian. Kanayama and Nasukawa (2006) bootstrap subjectivity lexicons for Japanese by generating subjectivity candidates based on word co-occurrence patterns. In contrast to other corpus-based bootstrapping methods, we evaluate our approach on multiple languages, specifically English, Spanish, and Russian. Also, as our approach relies only on the availability of a bilingual dictionary for translating an English subjectivity lexicon and crowdsourcing for help in selecting seeds, it is</context>
</contexts>
<marker>Banea, Mihalcea, Wiebe, 2008</marker>
<rawString>Carmen Banea, Rada Mihalcea, and Janyce Wiebe. 2008. A bootstrapping method for building subjectivity lexicons for languages with scarce resources. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Paul McNamee</author>
<author>Mossaab Bagdouri</author>
<author>Clayton Fink</author>
<author>Theresa Wilson</author>
</authors>
<title>Language identification for creating language-specific Twitter collections.</title>
<date>2012</date>
<booktitle>In Proceedings of 2nd Workshop on Language in Social Media.</booktitle>
<contexts>
<context position="7152" citStr="Bergsma et al., 2012" startWordPosition="1073" endWordPosition="1076">ts in this paper, we use three sets of data for each language: 1M unlabeled tweets (BOOT) for bootstrapping Twitter-specific lexicons, 2K labeled tweets for development data (DEV), and 2K labeled tweets for evaluation (TEST). DEV is used for parameter tuning while bootstrapping, and TEST is used to evaluating the quality of the bootstrapped lexicons. We take English tweets from the corpus constructed by Burger et al. (2011) which contains 2.9M tweets (excluding retweets) from 184K users.1 English tweets are identified automatically using a compression-based language identification (LID) tool (Bergsma et al., 2012). According to LID, there are 1.8M (63.6%) English tweets, which we randomly sample to create BOOT, DEV and TEST sets for English. Unfortunately, Burger’s corpus does not include Russian and Spanish data on the same scale as English. Therefore, for other languages we construct a new Twitter corpus by downloading tweets from followers of regionspecific news and media feeds. Sentiment labels for tweets in DEV and TEST sets for all languages are obtained using Amazon Mechanical Turk. For each tweet we collect annotations from five workers and use majority vote to determine the final label for the</context>
</contexts>
<marker>Bergsma, McNamee, Bagdouri, Fink, Wilson, 2012</marker>
<rawString>Shane Bergsma, Paul McNamee, Mossaab Bagdouri, Clayton Fink, and Theresa Wilson. 2012. Language identification for creating language-specific Twitter collections. In Proceedings of 2nd Workshop on Language in Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Burger</author>
<author>John C Henderson</author>
<author>George Kim</author>
<author>Guido Zarrella</author>
</authors>
<title>Discriminating gender on Twittier.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="6958" citStr="Burger et al. (2011)" startWordPosition="1045" endWordPosition="1048">e effectively used to bootstrap sentiment lexicons for any language for which a bilingual dictionary is available or can be automatically induced from parallel corpora. 3 Data For the experiments in this paper, we use three sets of data for each language: 1M unlabeled tweets (BOOT) for bootstrapping Twitter-specific lexicons, 2K labeled tweets for development data (DEV), and 2K labeled tweets for evaluation (TEST). DEV is used for parameter tuning while bootstrapping, and TEST is used to evaluating the quality of the bootstrapped lexicons. We take English tweets from the corpus constructed by Burger et al. (2011) which contains 2.9M tweets (excluding retweets) from 184K users.1 English tweets are identified automatically using a compression-based language identification (LID) tool (Bergsma et al., 2012). According to LID, there are 1.8M (63.6%) English tweets, which we randomly sample to create BOOT, DEV and TEST sets for English. Unfortunately, Burger’s corpus does not include Russian and Spanish data on the same scale as English. Therefore, for other languages we construct a new Twitter corpus by downloading tweets from followers of regionspecific news and media feeds. Sentiment labels for tweets in</context>
</contexts>
<marker>Burger, Henderson, Kim, Zarrella, 2011</marker>
<rawString>John D. Burger, John C. Henderson, George Kim, and Guido Zarrella. 2011. Discriminating gender on Twittier. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilia Chetviorkin</author>
<author>Natalia V Loukachevitch</author>
</authors>
<title>Extraction of Russian sentiment lexicon for product meta-domain.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="13591" citStr="Chetviorkin and Loukachevitch, 2012" startWordPosition="2211" endWordPosition="2214">0 new terms with a frequency &gt; 5 and probability &gt; 0.7 are added to the lexicon. For Spanish, the set of optimal parameters θ� = [0.65, 3, 50] and for Russian - θ� = [0.65, 3, 50]. In Table 2 we report size and term polarity from the original LI and the bootstrapped LB lexicons. 5 Lexicon Evaluations We evaluate our bootstrapped sentiment lexicons English LEB, Spanish LSB and Russian LRB by comparing them with existing dictionary-expanded lexicons that have been previously shown to be effective for subjectivity and polarity classification (Esuli and Sebastiani, 2006; Perez-Rosas et al., 2012; Chetviorkin and Loukachevitch, 2012). For that we perform subjectivity and polarity classification using rule-based classifiers6 on the test data E-TEST, S-TEST and R-TEST. We consider how the various lexicons perform for rule-based classifiers for both subjectivity and polarity. The subjectivity classifier predicts that a tweet is subjective if it contains a) at least one, or b) at least two subjective terms from the lexicon. For the polarity classifier, we predict a tweet to be positive (negative) if it contains at least one positive (negative) term taking into account negation. If the tweet contains both positive and negative</context>
</contexts>
<marker>Chetviorkin, Loukachevitch, 2012</marker>
<rawString>Ilia Chetviorkin and Natalia V. Loukachevitch. 2012. Extraction of Russian sentiment lexicon for product meta-domain. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Clematide</author>
<author>Manfred Klenner</author>
</authors>
<title>Evaluation and extension of a polarity lexicon for German.</title>
<date>2010</date>
<booktitle>In Proceedings of the 1st Workshop on Computational Approaches to Subjectivity and Sentiment Analysis.</booktitle>
<contexts>
<context position="4481" citStr="Clematide and Klenner, 2010" startWordPosition="664" endWordPosition="667">Related Work Mihalcea et.al (2012) classifies methods for bootstrapping subjectivity lexicons into two types: corpus-based and dictionary-based. Dictionary-based methods rely on existing lexical resources to bootstrap sentiment lexicons. Many researchers have explored using relations in WordNet (Miller, 1995), e.g., Esuli and Sabastiani (2006), Andreevskaia and Bergler (2006) for English, Rao and Ravichandran (2009) for Hindi and French, and Perez-Rosas et al. (2012) for Spanish. Mohammad et al. (2009) use a thesaurus to aid in the construction of a sentiment lexicon for English. Other works (Clematide and Klenner, 2010; Abdul-Mageed et al., 2011) automatically expands and evaluates German and Arabic lexicons. However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. There is also a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language of social media. Corpus-based methods extract subjectivity and sentiment lexicons from large amounts of unlabeled data using different similarity metrics to measure the relatedness between words. Hatzivassiloglou and McKeown (1997) were the first t</context>
</contexts>
<marker>Clematide, Klenner, 2010</marker>
<rawString>Simon Clematide and Manfred Klenner. 2010. Evaluation and extension of a polarity lexicon for German. In Proceedings of the 1st Workshop on Computational Approaches to Subjectivity and Sentiment Analysis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan T Dumais</author>
<author>George W Furnas</author>
<author>Thomas K Landauer</author>
<author>Scott Deerwester</author>
<author>Richard Harshman</author>
</authors>
<title>Using latent semantic analysis to improve access to textual information.</title>
<date>1988</date>
<booktitle>In Proceedings of SIGCHI.</booktitle>
<contexts>
<context position="5698" citStr="Dumais et al., 1988" startWordPosition="850" endWordPosition="853">t to explore automatically learning the polarity of words from corpora. Early work by Wiebe (2000) identifies clusters of subjectivity clues based on their distributional similarity, using a small amount of data to bootstrap the process. Turney (2002) and Velikovich et al. (2010) bootstrap sentiment lexicons for English from the web by using Pointwise Mutual Information (PMI) and graph propagation approach, respectively. Kaji and Kitsuregawa (2007) propose a method for building sentiment lexicon for Japanese from HTML pages. Banea et al. (2008) experiment with Lexical Semantic Analysis (LSA) (Dumais et al., 1988) to bootstrap a subjectivity lexicon for Romanian. Kanayama and Nasukawa (2006) bootstrap subjectivity lexicons for Japanese by generating subjectivity candidates based on word co-occurrence patterns. In contrast to other corpus-based bootstrapping methods, we evaluate our approach on multiple languages, specifically English, Spanish, and Russian. Also, as our approach relies only on the availability of a bilingual dictionary for translating an English subjectivity lexicon and crowdsourcing for help in selecting seeds, it is more scalable and better able to handle the informality and the dynam</context>
</contexts>
<marker>Dumais, Furnas, Landauer, Deerwester, Harshman, 1988</marker>
<rawString>Susan T. Dumais, George W. Furnas, Thomas K. Landauer, Scott Deerwester, and Richard Harshman. 1988. Using latent semantic analysis to improve access to textual information. In Proceedings of SIGCHI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="2096" citStr="Esuli and Sebastiani, 2006" startWordPosition="296" endWordPosition="299">the goal of analyzing sentiment in this domain. General, domain-independent sentiment lexicons have low coverage. Even models trained specifically on social media data may degrade somewhat over time as topics change and new sentiment-bearing terms crop up. For example, the word “occupy” would not have been indicative of sentiment before 2011. Most of the previous work on sentiment lexicon construction relies on existing natural language processing tools, e.g., syntactic parsers (Wiebe, 2000), information extraction (IE) tools (Riloff and Wiebe, 2003) or rich lexical resources such as WordNet (Esuli and Sebastiani, 2006). However, such tools and lexical resources are not available for many languages spoken in social media. While English is still the top language in Twitter, it is no longer the majority. Thus, the applicability of these approaches is limited. Any method for analyzing sentiment in microblogs or other social media streams must be easily adapted to (1) many low-resource languages, (2) the dynamic nature of social media, and (3) working in a streaming mode with limited or no supervision. Although bootstrapping has been used for learning sentiment lexicons in other domains (Turney and Littman, 2002</context>
<context position="13527" citStr="Esuli and Sebastiani, 2006" startWordPosition="2203" endWordPosition="2206"> [0.7, 5, 50] meaning that on each iteration the top 50 new terms with a frequency &gt; 5 and probability &gt; 0.7 are added to the lexicon. For Spanish, the set of optimal parameters θ� = [0.65, 3, 50] and for Russian - θ� = [0.65, 3, 50]. In Table 2 we report size and term polarity from the original LI and the bootstrapped LB lexicons. 5 Lexicon Evaluations We evaluate our bootstrapped sentiment lexicons English LEB, Spanish LSB and Russian LRB by comparing them with existing dictionary-expanded lexicons that have been previously shown to be effective for subjectivity and polarity classification (Esuli and Sebastiani, 2006; Perez-Rosas et al., 2012; Chetviorkin and Loukachevitch, 2012). For that we perform subjectivity and polarity classification using rule-based classifiers6 on the test data E-TEST, S-TEST and R-TEST. We consider how the various lexicons perform for rule-based classifiers for both subjectivity and polarity. The subjectivity classifier predicts that a tweet is subjective if it contains a) at least one, or b) at least two subjective terms from the lexicon. For the polarity classifier, we predict a tweet to be positive (negative) if it contains at least one positive (negative) term taking into ac</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. SentiWordNet: A publicly available lexical resource for opinion mining. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
<author>Anthony Aue</author>
</authors>
<title>Automatic identification of sentiment vocabulary: exploiting low association with known sentiment terms.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing.</booktitle>
<contexts>
<context position="3541" citStr="Gamon and Aue, 2005" startWordPosition="530" endWordPosition="534">ish, Spanish and Russian Twitter streams. Our approach: • handles the informality, creativity and the dynamic nature of social media; • does not rely on language-dependent tools; • scales to the hundreds of new under-explored languages and dialects in social media; • classifies sentiment in a streaming mode. To bootstrap subjectivity clues from Twitter streams we rely on three main assumptions: i. sentiment-bearing terms of similar orientation tend to co-occur at the tweet level (Turney and Littman, 2002); ii. sentiment-bearing terms of opposite orientation do not co-occur at the tweet level (Gamon and Aue, 2005); iii. the co-occurrence of domain-specific and domain-independent subjective terms serves as a signal of subjectivity. 505 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 505–510, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2 Related Work Mihalcea et.al (2012) classifies methods for bootstrapping subjectivity lexicons into two types: corpus-based and dictionary-based. Dictionary-based methods rely on existing lexical resources to bootstrap sentiment lexicons. Many researchers have explored using relations in</context>
</contexts>
<marker>Gamon, Aue, 2005</marker>
<rawString>Michael Gamon and Anthony Aue. 2005. Automatic identification of sentiment vocabulary: exploiting low association with known sentiment terms. In Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for Twittier: annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for Twittier: annotation, features, and experiments. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathy McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="5064" citStr="Hatzivassiloglou and McKeown (1997)" startWordPosition="751" endWordPosition="755">or English. Other works (Clematide and Klenner, 2010; Abdul-Mageed et al., 2011) automatically expands and evaluates German and Arabic lexicons. However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. There is also a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language of social media. Corpus-based methods extract subjectivity and sentiment lexicons from large amounts of unlabeled data using different similarity metrics to measure the relatedness between words. Hatzivassiloglou and McKeown (1997) were the first to explore automatically learning the polarity of words from corpora. Early work by Wiebe (2000) identifies clusters of subjectivity clues based on their distributional similarity, using a small amount of data to bootstrap the process. Turney (2002) and Velikovich et al. (2010) bootstrap sentiment lexicons for English from the web by using Pointwise Mutual Information (PMI) and graph propagation approach, respectively. Kaji and Kitsuregawa (2007) propose a method for building sentiment lexicon for Japanese from HTML pages. Banea et al. (2008) experiment with Lexical Semantic An</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathy McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
<author>Maarten de Rijke</author>
<author>Wouter Weerkamp</author>
</authors>
<title>Generating focused topicspecific sentiment lexicons.</title>
<date>2010</date>
<booktitle>In Proceedings ofACL.</booktitle>
<marker>Jijkoun, de Rijke, Weerkamp, 2010</marker>
<rawString>Valentin Jijkoun, Maarten de Rijke, and Wouter Weerkamp. 2010. Generating focused topicspecific sentiment lexicons. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuhiro Kaji</author>
<author>Masaru Kitsuregawa</author>
</authors>
<title>Building lexicon for sentiment analysis from massive collection of html documents.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="5530" citStr="Kaji and Kitsuregawa (2007)" startWordPosition="824" endWordPosition="827">nt lexicons from large amounts of unlabeled data using different similarity metrics to measure the relatedness between words. Hatzivassiloglou and McKeown (1997) were the first to explore automatically learning the polarity of words from corpora. Early work by Wiebe (2000) identifies clusters of subjectivity clues based on their distributional similarity, using a small amount of data to bootstrap the process. Turney (2002) and Velikovich et al. (2010) bootstrap sentiment lexicons for English from the web by using Pointwise Mutual Information (PMI) and graph propagation approach, respectively. Kaji and Kitsuregawa (2007) propose a method for building sentiment lexicon for Japanese from HTML pages. Banea et al. (2008) experiment with Lexical Semantic Analysis (LSA) (Dumais et al., 1988) to bootstrap a subjectivity lexicon for Romanian. Kanayama and Nasukawa (2006) bootstrap subjectivity lexicons for Japanese by generating subjectivity candidates based on word co-occurrence patterns. In contrast to other corpus-based bootstrapping methods, we evaluate our approach on multiple languages, specifically English, Spanish, and Russian. Also, as our approach relies only on the availability of a bilingual dictionary fo</context>
</contexts>
<marker>Kaji, Kitsuregawa, 2007</marker>
<rawString>Nobuhiro Kaji and Masaru Kitsuregawa. 2007. Building lexicon for sentiment analysis from massive collection of html documents. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Fully automatic lexicon expansion for domainoriented sentiment analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="5777" citStr="Kanayama and Nasukawa (2006)" startWordPosition="861" endWordPosition="864"> Early work by Wiebe (2000) identifies clusters of subjectivity clues based on their distributional similarity, using a small amount of data to bootstrap the process. Turney (2002) and Velikovich et al. (2010) bootstrap sentiment lexicons for English from the web by using Pointwise Mutual Information (PMI) and graph propagation approach, respectively. Kaji and Kitsuregawa (2007) propose a method for building sentiment lexicon for Japanese from HTML pages. Banea et al. (2008) experiment with Lexical Semantic Analysis (LSA) (Dumais et al., 1988) to bootstrap a subjectivity lexicon for Romanian. Kanayama and Nasukawa (2006) bootstrap subjectivity lexicons for Japanese by generating subjectivity candidates based on word co-occurrence patterns. In contrast to other corpus-based bootstrapping methods, we evaluate our approach on multiple languages, specifically English, Spanish, and Russian. Also, as our approach relies only on the availability of a bilingual dictionary for translating an English subjectivity lexicon and crowdsourcing for help in selecting seeds, it is more scalable and better able to handle the informality and the dynamic nature of social media. It also can be effectively used to bootstrap sentime</context>
</contexts>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully automatic lexicon expansion for domainoriented sentiment analysis. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Carmen Banea</author>
<author>Janyce Wiebe</author>
</authors>
<title>Multilingual subjectivity and sentiment analysis.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Mihalcea, Banea, Wiebe, 2012</marker>
<rawString>Rada Mihalcea, Carmen Banea, and Janyce Wiebe. 2012. Multilingual subjectivity and sentiment analysis. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: a lexical database for English.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="4164" citStr="Miller, 1995" startWordPosition="614" endWordPosition="615"> co-occurrence of domain-specific and domain-independent subjective terms serves as a signal of subjectivity. 505 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 505–510, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2 Related Work Mihalcea et.al (2012) classifies methods for bootstrapping subjectivity lexicons into two types: corpus-based and dictionary-based. Dictionary-based methods rely on existing lexical resources to bootstrap sentiment lexicons. Many researchers have explored using relations in WordNet (Miller, 1995), e.g., Esuli and Sabastiani (2006), Andreevskaia and Bergler (2006) for English, Rao and Ravichandran (2009) for Hindi and French, and Perez-Rosas et al. (2012) for Spanish. Mohammad et al. (2009) use a thesaurus to aid in the construction of a sentiment lexicon for English. Other works (Clematide and Klenner, 2010; Abdul-Mageed et al., 2011) automatically expands and evaluates German and Arabic lexicons. However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. There is also a mismatch between the formality of many lang</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: a lexical database for English. Communications of the ACM, 38(11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Cody Dunne</author>
<author>Bonnie Dorr</author>
</authors>
<title>Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="4361" citStr="Mohammad et al. (2009)" startWordPosition="643" endWordPosition="646">l Linguistics, pages 505–510, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2 Related Work Mihalcea et.al (2012) classifies methods for bootstrapping subjectivity lexicons into two types: corpus-based and dictionary-based. Dictionary-based methods rely on existing lexical resources to bootstrap sentiment lexicons. Many researchers have explored using relations in WordNet (Miller, 1995), e.g., Esuli and Sabastiani (2006), Andreevskaia and Bergler (2006) for English, Rao and Ravichandran (2009) for Hindi and French, and Perez-Rosas et al. (2012) for Spanish. Mohammad et al. (2009) use a thesaurus to aid in the construction of a sentiment lexicon for English. Other works (Clematide and Klenner, 2010; Abdul-Mageed et al., 2011) automatically expands and evaluates German and Arabic lexicons. However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. There is also a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language of social media. Corpus-based methods extract subjectivity and sentiment lexicons from large amounts of unlabeled data using dif</context>
</contexts>
<marker>Mohammad, Dunne, Dorr, 2009</marker>
<rawString>Saif Mohammad, Cody Dunne, and Bonnie Dorr. 2009. Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronica Perez-Rosas</author>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
</authors>
<title>Learning sentiment lexicons in Spanish.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="4325" citStr="Perez-Rosas et al. (2012)" startWordPosition="637" endWordPosition="640">ing of the Association for Computational Linguistics, pages 505–510, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2 Related Work Mihalcea et.al (2012) classifies methods for bootstrapping subjectivity lexicons into two types: corpus-based and dictionary-based. Dictionary-based methods rely on existing lexical resources to bootstrap sentiment lexicons. Many researchers have explored using relations in WordNet (Miller, 1995), e.g., Esuli and Sabastiani (2006), Andreevskaia and Bergler (2006) for English, Rao and Ravichandran (2009) for Hindi and French, and Perez-Rosas et al. (2012) for Spanish. Mohammad et al. (2009) use a thesaurus to aid in the construction of a sentiment lexicon for English. Other works (Clematide and Klenner, 2010; Abdul-Mageed et al., 2011) automatically expands and evaluates German and Arabic lexicons. However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. There is also a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language of social media. Corpus-based methods extract subjectivity and sentiment lexicons from large</context>
<context position="13553" citStr="Perez-Rosas et al., 2012" startWordPosition="2207" endWordPosition="2210">n each iteration the top 50 new terms with a frequency &gt; 5 and probability &gt; 0.7 are added to the lexicon. For Spanish, the set of optimal parameters θ� = [0.65, 3, 50] and for Russian - θ� = [0.65, 3, 50]. In Table 2 we report size and term polarity from the original LI and the bootstrapped LB lexicons. 5 Lexicon Evaluations We evaluate our bootstrapped sentiment lexicons English LEB, Spanish LSB and Russian LRB by comparing them with existing dictionary-expanded lexicons that have been previously shown to be effective for subjectivity and polarity classification (Esuli and Sebastiani, 2006; Perez-Rosas et al., 2012; Chetviorkin and Loukachevitch, 2012). For that we perform subjectivity and polarity classification using rule-based classifiers6 on the test data E-TEST, S-TEST and R-TEST. We consider how the various lexicons perform for rule-based classifiers for both subjectivity and polarity. The subjectivity classifier predicts that a tweet is subjective if it contains a) at least one, or b) at least two subjective terms from the lexicon. For the polarity classifier, we predict a tweet to be positive (negative) if it contains at least one positive (negative) term taking into account negation. If the twe</context>
</contexts>
<marker>Perez-Rosas, Banea, Mihalcea, 2012</marker>
<rawString>Veronica Perez-Rosas, Carmen Banea, and Rada Mihalcea. 2012. Learning sentiment lexicons in Spanish. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Semisupervised polarity lexicon induction.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="4273" citStr="Rao and Ravichandran (2009)" startWordPosition="628" endWordPosition="631"> subjectivity. 505 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 505–510, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2 Related Work Mihalcea et.al (2012) classifies methods for bootstrapping subjectivity lexicons into two types: corpus-based and dictionary-based. Dictionary-based methods rely on existing lexical resources to bootstrap sentiment lexicons. Many researchers have explored using relations in WordNet (Miller, 1995), e.g., Esuli and Sabastiani (2006), Andreevskaia and Bergler (2006) for English, Rao and Ravichandran (2009) for Hindi and French, and Perez-Rosas et al. (2012) for Spanish. Mohammad et al. (2009) use a thesaurus to aid in the construction of a sentiment lexicon for English. Other works (Clematide and Klenner, 2010; Abdul-Mageed et al., 2011) automatically expands and evaluates German and Arabic lexicons. However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. There is also a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language of social media. Corpus-based methods ex</context>
</contexts>
<marker>Rao, Ravichandran, 2009</marker>
<rawString>Delip Rao and Deepak Ravichandran. 2009. Semisupervised polarity lexicon induction. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="2025" citStr="Riloff and Wiebe, 2003" startWordPosition="285" endWordPosition="288">ersity of subjective language has implications for any system with the goal of analyzing sentiment in this domain. General, domain-independent sentiment lexicons have low coverage. Even models trained specifically on social media data may degrade somewhat over time as topics change and new sentiment-bearing terms crop up. For example, the word “occupy” would not have been indicative of sentiment before 2011. Most of the previous work on sentiment lexicon construction relies on existing natural language processing tools, e.g., syntactic parsers (Wiebe, 2000), information extraction (IE) tools (Riloff and Wiebe, 2003) or rich lexical resources such as WordNet (Esuli and Sebastiani, 2006). However, such tools and lexical resources are not available for many languages spoken in social media. While English is still the top language in Twitter, it is no longer the majority. Thus, the applicability of these approaches is limited. Any method for analyzing sentiment in microblogs or other social media streams must be easily adapted to (1) many low-resource languages, (2) the dynamic nature of social media, and (3) working in a streaming mode with limited or no supervision. Although bootstrapping has been used for</context>
<context position="9567" citStr="Riloff and Wiebe, 2003" startWordPosition="1472" endWordPosition="1475"> приходят только ночью? (Why clever thoughts come only at night?). 4 Lexicon Bootstrapping To create a Twitter-specific sentiment lexicon for a given language, we start with a general-purpose, high-precision sentiment lexicon2 and bootstrap from the unlabeled data (BOOT) using the labeled development data (DEV) to guide the process. 4.1 High-Precision Subjectivity Lexicons For English we seed the bootstrapping process with the strongly subjective terms from the MPQA lexicon3 (Wilson et al., 2005). These terms have been previously shown to be highprecision for recognizing subjective sentences (Riloff and Wiebe, 2003). For the other languages, the subjective seed terms are obtained by translating English seed terms using a bilingual dictionary, and then collecting judgments about term subjectivity from Mechanical Turk. Terms that truly are strongly subjective in translation are used for seed terms in the new language, with term polarity projected from the English. Finally, we expand the lexicons with plurals and inflectional forms for adverbs, adjectives and verbs. 4.2 Bootstrapping Approach To bootstrap, first the new lexicon LB(0) is seeded with the strongly subjective terms from the original lexicon LI.</context>
<context position="14656" citStr="Riloff and Wiebe, 2003" startWordPosition="2380" endWordPosition="2383"> to be positive (negative) if it contains at least one positive (negative) term taking into account negation. If the tweet contains both positive and negative terms, we take the majority label. For English we compare our bootstrapped lexicon LEB against the original lexicon LEI and strongly subjective terms from SentiWordNet 3.0 (Esuli and Sebastiani, 2006). To make a fair comparison, we automatically expand SentiWordNet with noun plural forms and verb inflectional forms. In Figure 1 we report precision, recall 6Similar approach to a rule-based classification using terms from he MPQA lexicon (Riloff and Wiebe, 2003). and F-measure results. They show that our bootstrapped lexicon significantly outperforms SentiWordNet for subjectivity classification. For polarity classification we get comparable F-measure but much higher recall for LEB compared to SWN. (a) Subj &gt; 1 (b) Subj &gt; 2 (c) Polarity Lexicon Fsubj&gt;1 Fsubj&gt;2 Fpolarity SWN 0.57 0.27 0.78 LE 0.71 0.48 0.82 I 0.75 0.72 0.78 LE B Figure 1: Precision (x-axis), recall (y-axis) and F-measure (in the table) for English: LEI = initial lexicon, LEB = bootstrapped lexicon, SWN = strongly subjective terms from SentiWordNet. For Spanish we compare our bootstrapp</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Ellen Riloff and Janyce Wiebe. 2003. Learning extraction patterns for subjective expressions. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Brendan O’Connor</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Cheap and fast – but is it good?: Evaluating non-expert annotations for natural language tasks.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<marker>Snow, O’Connor, Jurafsky, Ng, 2008</marker>
<rawString>Rion Snow, Brendan O’Connor, Daniel Jurafsky, and Andrew Y. Ng. 2008. Cheap and fast – but is it good?: Evaluating non-expert annotations for natural language tasks. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Unsupervised learning of semantic orientation from a hundred-billion-word corpus. Computing Research Repository.</title>
<date>2002</date>
<contexts>
<context position="2696" citStr="Turney and Littman, 2002" startWordPosition="395" endWordPosition="398">li and Sebastiani, 2006). However, such tools and lexical resources are not available for many languages spoken in social media. While English is still the top language in Twitter, it is no longer the majority. Thus, the applicability of these approaches is limited. Any method for analyzing sentiment in microblogs or other social media streams must be easily adapted to (1) many low-resource languages, (2) the dynamic nature of social media, and (3) working in a streaming mode with limited or no supervision. Although bootstrapping has been used for learning sentiment lexicons in other domains (Turney and Littman, 2002; Banea et al., 2008), it has not yet been applied to learning sentiment lexicons for microblogs. In this paper, we present an approach for bootstrapping subjectivity clues from Twitter data, and evaluate our approach on English, Spanish and Russian Twitter streams. Our approach: • handles the informality, creativity and the dynamic nature of social media; • does not rely on language-dependent tools; • scales to the hundreds of new under-explored languages and dialects in social media; • classifies sentiment in a streaming mode. To bootstrap subjectivity clues from Twitter streams we rely on t</context>
</contexts>
<marker>Turney, Littman, 2002</marker>
<rawString>Peter D. Turney and Michael L. Littman. 2002. Unsupervised learning of semantic orientation from a hundred-billion-word corpus. Computing Research Repository.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="5329" citStr="Turney (2002)" startWordPosition="796" endWordPosition="797">so a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language of social media. Corpus-based methods extract subjectivity and sentiment lexicons from large amounts of unlabeled data using different similarity metrics to measure the relatedness between words. Hatzivassiloglou and McKeown (1997) were the first to explore automatically learning the polarity of words from corpora. Early work by Wiebe (2000) identifies clusters of subjectivity clues based on their distributional similarity, using a small amount of data to bootstrap the process. Turney (2002) and Velikovich et al. (2010) bootstrap sentiment lexicons for English from the web by using Pointwise Mutual Information (PMI) and graph propagation approach, respectively. Kaji and Kitsuregawa (2007) propose a method for building sentiment lexicon for Japanese from HTML pages. Banea et al. (2008) experiment with Lexical Semantic Analysis (LSA) (Dumais et al., 1988) to bootstrap a subjectivity lexicon for Romanian. Kanayama and Nasukawa (2006) bootstrap subjectivity lexicons for Japanese by generating subjectivity candidates based on word co-occurrence patterns. In contrast to other corpus-ba</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonid Velikovich</author>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
</authors>
<title>The viability of web-derived polarity lexicons.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="5358" citStr="Velikovich et al. (2010)" startWordPosition="799" endWordPosition="802">een the formality of many language resources, such as WordNet, and the extremely informal language of social media. Corpus-based methods extract subjectivity and sentiment lexicons from large amounts of unlabeled data using different similarity metrics to measure the relatedness between words. Hatzivassiloglou and McKeown (1997) were the first to explore automatically learning the polarity of words from corpora. Early work by Wiebe (2000) identifies clusters of subjectivity clues based on their distributional similarity, using a small amount of data to bootstrap the process. Turney (2002) and Velikovich et al. (2010) bootstrap sentiment lexicons for English from the web by using Pointwise Mutual Information (PMI) and graph propagation approach, respectively. Kaji and Kitsuregawa (2007) propose a method for building sentiment lexicon for Japanese from HTML pages. Banea et al. (2008) experiment with Lexical Semantic Analysis (LSA) (Dumais et al., 1988) to bootstrap a subjectivity lexicon for Romanian. Kanayama and Nasukawa (2006) bootstrap subjectivity lexicons for Japanese by generating subjectivity candidates based on word co-occurrence patterns. In contrast to other corpus-based bootstrapping methods, we</context>
</contexts>
<marker>Velikovich, Blair-Goldensohn, Hannan, McDonald, 2010</marker>
<rawString>Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Hannan, and Ryan McDonald. 2010. The viability of web-derived polarity lexicons. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
</authors>
<title>Learning subjective adjectives from corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="1965" citStr="Wiebe, 2000" startWordPosition="279" endWordPosition="280">ure of social media together with the extreme diversity of subjective language has implications for any system with the goal of analyzing sentiment in this domain. General, domain-independent sentiment lexicons have low coverage. Even models trained specifically on social media data may degrade somewhat over time as topics change and new sentiment-bearing terms crop up. For example, the word “occupy” would not have been indicative of sentiment before 2011. Most of the previous work on sentiment lexicon construction relies on existing natural language processing tools, e.g., syntactic parsers (Wiebe, 2000), information extraction (IE) tools (Riloff and Wiebe, 2003) or rich lexical resources such as WordNet (Esuli and Sebastiani, 2006). However, such tools and lexical resources are not available for many languages spoken in social media. While English is still the top language in Twitter, it is no longer the majority. Thus, the applicability of these approaches is limited. Any method for analyzing sentiment in microblogs or other social media streams must be easily adapted to (1) many low-resource languages, (2) the dynamic nature of social media, and (3) working in a streaming mode with limited</context>
<context position="5176" citStr="Wiebe (2000)" startWordPosition="773" endWordPosition="774">lexicons. However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. There is also a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language of social media. Corpus-based methods extract subjectivity and sentiment lexicons from large amounts of unlabeled data using different similarity metrics to measure the relatedness between words. Hatzivassiloglou and McKeown (1997) were the first to explore automatically learning the polarity of words from corpora. Early work by Wiebe (2000) identifies clusters of subjectivity clues based on their distributional similarity, using a small amount of data to bootstrap the process. Turney (2002) and Velikovich et al. (2010) bootstrap sentiment lexicons for English from the web by using Pointwise Mutual Information (PMI) and graph propagation approach, respectively. Kaji and Kitsuregawa (2007) propose a method for building sentiment lexicon for Japanese from HTML pages. Banea et al. (2008) experiment with Lexical Semantic Analysis (LSA) (Dumais et al., 1988) to bootstrap a subjectivity lexicon for Romanian. Kanayama and Nasukawa (2006</context>
</contexts>
<marker>Wiebe, 2000</marker>
<rawString>Janyce Wiebe. 2000. Learning subjective adjectives from corpora. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="9445" citStr="Wilson et al., 2005" startWordPosition="1454" endWordPosition="1457">и (I want to write about the movie rougher but I will not. Although the actors are good); • Neutral: Почему умные мысли приходят только ночью? (Why clever thoughts come only at night?). 4 Lexicon Bootstrapping To create a Twitter-specific sentiment lexicon for a given language, we start with a general-purpose, high-precision sentiment lexicon2 and bootstrap from the unlabeled data (BOOT) using the labeled development data (DEV) to guide the process. 4.1 High-Precision Subjectivity Lexicons For English we seed the bootstrapping process with the strongly subjective terms from the MPQA lexicon3 (Wilson et al., 2005). These terms have been previously shown to be highprecision for recognizing subjective sentences (Riloff and Wiebe, 2003). For the other languages, the subjective seed terms are obtained by translating English seed terms using a bilingual dictionary, and then collecting judgments about term subjectivity from Mechanical Turk. Terms that truly are strongly subjective in translation are used for seed terms in the new language, with term polarity projected from the English. Finally, we expand the lexicons with plurals and inflectional forms for adverbs, adjectives and verbs. 4.2 Bootstrapping App</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>