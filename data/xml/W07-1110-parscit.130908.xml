<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000099">
<title confidence="0.975537">
Semantic Labeling of Compound Nominalization in Chinese
</title>
<author confidence="0.99905">
Jinglei Zhao, Hui Liu &amp; Ruzhan Lu
</author>
<affiliation confidence="0.997139">
Department of Computer Science
Shanghai Jiao Tong University
</affiliation>
<address confidence="0.918093">
800 Dongchuan Road Shanghai, China
</address>
<email confidence="0.996071">
{zjl,lh charles,rzlu}@sjtu.edu.cn
</email>
<sectionHeader confidence="0.99857" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999991866666667">
This paper discusses the semantic interpre-
tation of compound nominalizations in Chi-
nese. We propose four coarse-grained se-
mantic roles of the noun modifier and use a
Maximum Entropy Model to label such re-
lations in a compound nominalization. The
feature functions used for the model are
web-based statistics acquired via role related
paraphrase patterns, which are formed by a
set of word instances of prepositions, sup-
port verbs, feature nouns and aspect mark-
ers. By applying a sub-linear transformation
and discretization of the raw statistics, a rate
of approximately 77% is obtained for classi-
fication of the four semantic relations.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999980183673469">
A nominal compound (NC) is the concatenation of
any two or more nominal concepts which functions
as a third nominal concept (Finin, 1980). (Leonard,
1984) observed that the amount of NCs had been in-
creasing explosively in English in recent years. NCs
such as satellite navigation system are abundant in
news and technical texts. In other languages such as
Chinese, NCs have been more productive since ear-
lier days as evidenced by the fact that many simple
words in Chinese are actually a result of compound-
ing of morphemes.
Many aspects in Natural Language Processing
(NLP), such as machine translation, information re-
trieval, question answering, etc. call for the auto-
matic interpretation of NCs, that is, making explicit
the underlying semantic relationships between the
constituent concepts. For example, the semantic re-
lations involved in satellite communication system
can be expressed by the conceptual graph (Sowa,
1984) in Figure 1, in which, for instance, the se-
mantic relation between satellite and communica-
tion is MANNER. Due to the productivity of NCs
and the lack of syntactic clues to guide the interpre-
tation process, the automatic interpretation of NCs
has been proven to be a very difficult problem in
NLP.
In this paper, we deal with the semantic interpre-
tation of NCs in Chinese. Especially, we will fo-
cus on a subset of NCs in which the head word is a
verb nominalization. Nominalization is a common
phenomenon across languages in which a predica-
tive expression is transformed to refer to an event
or a property. For example, the English verb com-
municate has the related nominalized form commu-
nication. Different from English, Chinese has little
morphology. Verb nominalization in Chinese has the
same form as the verb predicate.
Nominalizations retain the argument structure of
the corresponding predicates. The semantic relation
between a noun modifier and a verb nominalization
head can be characterized by the semantic role the
modifier can take respecting to the corresponding
verb predicate. Our method uses a Maximum En-
tropy model to label coarse-grained semantic roles
in Chinese compound nominalizations. Unlike most
approaches in compound interpretation and seman-
tic role labeling, we don’t exploit features from
any parsed texts or lexical knowledge sources. In-
stead, features are acquired using web-based statis-
</bodyText>
<page confidence="0.988788">
73
</page>
<note confidence="0.945967">
Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 73–80,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<figure confidence="0.630537">
[satellite]F(MANNER)F[communication]F(TELIC)F[system]
</figure>
<figureCaption confidence="0.999913">
Figure 1: The conceptual graph for satellite communication system
</figureCaption>
<bodyText confidence="0.9782949">
tics (PMI-IR) produced from paraphrase patterns of
the compound Nominalization.
The remainder of the paper is organized as fol-
lows: Section 2 describes related works. Section
3 describes the semantic relations for our labeling
task. Section 4 introduces the paraphrase patterns
used. Section 5 gives a detailed description of our
algorithm. Section 6 presents the experimental re-
sult. Finally, in Section 7, we give the conclusions
and discuss future work.
</bodyText>
<sectionHeader confidence="0.999932" genericHeader="introduction">
2 Related Works
</sectionHeader>
<subsectionHeader confidence="0.996734">
2.1 Nominal Compound Interpretation
</subsectionHeader>
<bodyText confidence="0.99848534375">
The methods used in the semantic interpretation of
NCs fall into two main categories: rule-based ones
and statistic-based ones. The rule-based approaches
such as (Finin, 1980; Mcdonald, 1982; Leonard,
1984; Vanderwende, 1995) think that the interpreta-
tion of NCs depends heavily on the constituent con-
cepts and model the semantic interpretation as a slot-
filling process. Various rules are employed by such
approaches to determine, for example, whether the
modifier can fill in one slot of the head.
The statistic-based approaches view the seman-
tic interpretation as a multi-class classification prob-
lem. (Rosario and Hearst, 2001; Moldovan et al.,
2004; Kim and Baldwin, 2005) use supervised meth-
ods and explore classification features from a simple
structured type hierarchy. (Kim and Baldwin, 2006)
use a set of seed verbs to characterize the semantic
relation between the constituent nouns and explores
a parsed corpus to classify NCs. (Turney, 2005) uses
latent relational analysis to classify NCs. The simi-
larity between two NCs is characterized by the sim-
ilarity between their related pattern set.
(Lauer, 1995) is the first to use paraphrase based
unsupervised statistical models to classify semantic
relations of NCs. (Lapata, 2000; Grover et al., 2005;
Nicholson, 2005) use paraphrase statistics computed
from parsed texts to interpret compound nominaliza-
tion, but the relations used are purely syntactic. La-
pata(2000) only classifies syntactic relations of sub-
ject and object. Grover(2005) and Nicholson (2005)
classify relations of subject, object and prepositional
object.
</bodyText>
<subsectionHeader confidence="0.999635">
2.2 Semantic Role Labeling of Nominalization
</subsectionHeader>
<bodyText confidence="0.99966092">
Most previous work on semantic role labeling of
nominalizations are conducted in the situation where
a verb nominalization is the head of a general noun
phrase. (Dahl et al., 1987; Hull and Gomez, 1996)
use hand-coded slot-filling rules to determine the se-
mantic roles of the arguments of a nominalization.
In such approaches, first, parsers are used to identify
syntactic clues such as prepositional types. Then,
rules are applied to label semantic roles according
to clues and constraints of different roles.
Supervised machine learning methods become
prevalent in recent years in semantic role labeling
of verb nominalizations as part of the resurgence
of research in shallow semantic analysis. (Pradhan
et al., 2004) use a SVM classifier for the semantic
role labeling of nominalizations in English and Chi-
nese based on the FrameNet database and the Chi-
nese PropBank respectively. (Xue, 2006) uses the
Chinese Nombank to label nominalizations in Chi-
nese. Compared to English, the main difficulty of
using supervised method for Chinese, as noted by
Xue (2006), is that the precision of current parsers
of Chinese is very low due to the lack of morphol-
ogy, difficulty in segmentation and lack of sufficient
training materials in Chinese.
</bodyText>
<subsectionHeader confidence="0.998181">
2.3 Web as a large Corpus
</subsectionHeader>
<bodyText confidence="0.999464363636364">
Data sparseness is the most notorious hinder for ap-
plying statistical methods in natural language pro-
cessing. However, the World Wide Web can be seen
as a large corpus. (Grefenstette and Nioche, 2000;
Jones and Ghani, 2000) use the web to generate cor-
pora for languages for which electronic resources
are scarce. (Zhu and Rosenfeld, 2001) use Web-
based n-gram counts for language modeling. (Keller
and Lapata, 2003) show that Web page counts and
n-gram frequency counts are highly correlated in a
log scale.
</bodyText>
<page confidence="0.999167">
74
</page>
<sectionHeader confidence="0.994105" genericHeader="method">
3 Semantic Relations
</sectionHeader>
<bodyText confidence="0.999962642857143">
Although verb nominalization is commonly con-
sidered to have arguments as the verb predicate,
Xue(2006) finds that there tend to be fewer argu-
ments and fewer types of adjuncts in verb nomi-
nalizations compared to verb predicates in Chinese.
We argue that this phenomenon is more obvious in
compound nominalization. By analyzing a set of
compound nominalizations of length two from a bal-
anced corpus(Jin et al., 2003), we find the semantic
relations between a noun modifier and a verb nomi-
nalization head can be characterized by four coarse-
grained semantic roles: Proto-Agent (PA), Proto-
Patient (PP), Range (RA) and Manner (MA). This
is illustrated by Table1.
</bodyText>
<figure confidence="0.976247444444444">
Relations Examples
PA hAVT,(Blood Circulation)
A a it4k (Bird Migration)
PP � JL n(Enterprise Management)
ÄÔ ©a(Animal Categorization)
MA (Laser Storage)
¥I A_ U (Satellite Communication)
RA 1 * 1/2 (Global Positioning)
��uA(Long-time Development)
</figure>
<tableCaption confidence="0.7402275">
Table 1: Semantic Relations between Noun Modifier
and Verb Nominalization Head.
</tableCaption>
<bodyText confidence="0.999224">
Due to the linking between semantic roles and
syntactic roles (Dowty, 1991), the relations above
overlap with syntactic roles, for example, Proto-
Agent with Subject and Proto-Patient with Object,
but they are not the same, as illustrated by the
example Ä Ô © a(Animal Categorization). Al-
though the predicate ©a(categorize) in Chinese is
an intransitive verb, the semantic relation between
ÄÔ(animal) and©a(categorization) is Proto-
Patient.
</bodyText>
<sectionHeader confidence="0.984654" genericHeader="method">
4 Paraphrase Patterns
</sectionHeader>
<subsectionHeader confidence="0.984096">
4.1 Motivations
</subsectionHeader>
<bodyText confidence="0.9943602">
Syntactic patterns provide clues for semantic rela-
tions (Hearst, 1992). For example, Hearst(1992)
uses the pattern ”NP such as List” to indicate that
nouns in List are hyponyms of NP. To classify the
four semantic relations listed in section 3, we pro-
pose some domain independent surface paraphrase
patterns to characterize each semantic relation. The
patterns we adopted mainly exploit a set of word in-
stances of prepositions, support verbs, feature nouns
and aspect markers.
Prepositions are strong indicators of semantic
roles in Chinese. For example, in sentence 1), the
preposition46(ba) indicates that the noun17(door)
and Mn(Zhangsan) is the Proto-Patient and Proto-
Agent of verb R(lock) respectively.
</bodyText>
<listItem confidence="0.834388">
1) a.Mn4617Vþ
b. Zhangsan ba door locked.
c. Zhangsan locked the door.
</listItem>
<bodyText confidence="0.987837">
The prepositions we use to characterize each rela-
tion are listed in table 2.
</bodyText>
<equation confidence="0.7701494">
Relations Prepositional Indicators
PP A(bei),4(rang),11�(jiao),i1(you)
PA 46(ba),*(jiang),flsuo),é(dui)
MA Al (tongguo),#1(yong),v),(yi)
RA A(zai),t(yu),,1)_(cong)
</equation>
<bodyText confidence="0.87985475">
Table 2: Prepositional indicators of different rela-
tions in Chinese.
Support verbs such as # fT(conduct), Aja v), (put-
to) can take verb nominalizations as objects. When
combined with prepositions, they could be good
indicators of semantic roles. For example in 2),
the verb # fT(conduct) together with the preposi-
tion é (dui) indicate that the relation between
</bodyText>
<listItem confidence="0.906073">
(categorization) and ÄÔ(animal) is PA.
2) a.éÄÔ# fT©a
b. dui animal conduct categorization.
c. conduct categorization regarding animal.
</listItem>
<bodyText confidence="0.9986306">
Nouns such as •{(method), • (manner), ‰
Œ(range) and /: (place) can be used as features
when co-occurring with the compound nominaliza-
tions under consideration. For example, if I� J*
‰ Œ (global range) co-occurs frequently with 1/2
(positioning), it will indicate a possible RA rela-
tion between 1*(global) and 1/2 (positioning).
Another set of word instances we use is as-
pect, tense and modal markers. As we have men-
tioned, verb nominalizations have the same form as
</bodyText>
<page confidence="0.993207">
75
</page>
<bodyText confidence="0.997139666666667">
the corresponding verb predicates in Chinese. As-
pect,tense and modal markers make a good indica-
tor for recognizing a verb predicate. For example if
a verb is directly followed by an aspect marker such
as 7 (le), which indicates a finished state, it could
be safely viewed as a predicate. Such markers are
very useful in paraphrase patterns. This can be illus-
trated by 3), in which, the tense marker -)&apos;� 4Q (start)
indicates a strong agentive meaning of the noun A
</bodyText>
<listItem confidence="0.9361505">
(bird) and provides good clues of the relation PP
between A k(bird) and i£lk(migration) in the com-
pound Aki£lk(bird migration).
3) a.iQ�
b. Bird start migrate.
c. Birds start to migrate.
</listItem>
<subsectionHeader confidence="0.980558">
4.2 Paraphrase Pattern Templates
</subsectionHeader>
<bodyText confidence="0.999930636363636">
We use the set of word instances above to form
pattern templates which could be instantiated by
the compound nominalization under consideration
to form paraphrase patterns. The templates are ex-
pressed using the employed search engine’s query
language. Currently, we employ totally 30 feature
templates for the four semantic relations. A sample
of the pattern templates is listed in Tabel 3, in which,
x, y is the variable which need to be instantiated by
the noun modifier and verb nominalization respec-
tively.
</bodyText>
<table confidence="0.1836666">
Relations Paraphrase Pattern Templates
PP ”�x #4Ty” (”dui x conduct y”)
”4e,x” ”y” (”ba x” ”y”)
”y*x” (”y zhe x”)
”x#” ”y” (”x bei” ”y”)
PA ”#x” ”y” (”bei x” ”y”)
”x-)1�4Qy” (”x start y”)
”x” ”T—v),y” (”x” ”can y”)
”xRry” (”x suo y”)
MA ”�fix” ”y” -”�Oxy”
(”tongguo x” ”y” -”tongguo xy”)
”x &gt;4e” ”y” (”x method” ”y”)
RA ”Ax” ”y” -”Ay”(”zai x” ”y” -”zai y”)
”Ax” ”y” (”cong x” ”y”)
”xe.Q” ”y” (”x range” ”y”)
</table>
<tableCaption confidence="0.979609">
Table 3: A Sample Set of the Paraphrase Pattern
Templates.
</tableCaption>
<sectionHeader confidence="0.58795" genericHeader="method">
5 System Description
</sectionHeader>
<subsectionHeader confidence="0.456463">
5.1 Data Source
</subsectionHeader>
<figureCaption confidence="0.998388">
Figure 2: System Architecture
</figureCaption>
<bodyText confidence="0.991287692307692">
Figure 2 illustrates the system architecture of our
approach. We view the semantic labeling of com-
pound nominalization as a data-driven classification
problem. The data used for the experiment is auto-
extracted from the Chinese National Corpus (Jin et
al., 2003), which is a balanced segmented and POS
tagged corpus with 8M characters. Because the cor-
pus doesn’t distinguish verb predicates with verb
nominalizations, a verb nominalization recognizer is
first used to recognize all the verb nominalizations
in the corpus, and then, a compound extractor identi-
fies all the compound nominalizations having a noun
modifier and a verb nominalization head in the cor-
pus. We manually examined a sample of the result
set and finally randomly select 300 correct noun-
nominalization pairs as our training and testing set
for semantic interpretation.
One PHD student majored in computer science
and one in linguistics were employed to label all
the 300 data samples simultaneously according to
the relation set given in section 3. The annotator’s
agreement was measured using the Kappa statistic
(Siegel and Castellan, 1988) illustrated in (1), of
which Pr(A) is the probability of the actual out-
come and Pr(E) is the probability of the expected
outcome as predicted by chance. The Kappa score
</bodyText>
<figure confidence="0.9980145">
Nominalization
Recognizer
Corpus
PMI Statistic
Compound
Extractor
Search Engine
Data Preprocessing
ME
Classifier
Pattern
Templates
Compound
Nominalizations
Semantic
Relations
</figure>
<page confidence="0.756762">
76
</page>
<bodyText confidence="0.696522">
of the annotation is 87.3%.
</bodyText>
<equation confidence="0.995436333333333">
Pr(A) − Pr(E)
K = (1)
1 − Pr(E)
</equation>
<bodyText confidence="0.999894444444444">
After discussion, the two annotators reached
agreement on a final version of the data sample la-
beling. In which, the proportion of relations PP, PA,
MA, RA is 45.6%, 27.7%, 16.7% and 10% respec-
tively, giving a baseline of 45.6% of the classifica-
tion problem by viewing all the relations to be PP.
Finally, the 300 data instances were partitioned into
a training set and a testing set containing 225 and 75
instances respectively.
</bodyText>
<subsectionHeader confidence="0.989666">
5.2 Maximum Entropy Model
</subsectionHeader>
<bodyText confidence="0.9999755">
We use the Maximum Entropy (ME) Model (Berger
et al., 1996) for our classification task. Given a set
of training examples of a random process, ME is
a method of estimating the conditional probability
p(y|x) that, given a context x, the process will out-
put y. In our task, the output corresponds to the four
relation labels PP, PA, MA and RA.
The modeling of ME is based on the Maximum
Entropy Principle, that is, modeling all that is known
and assuming nothing about what is unknown. The
computation of p(y|x) is illustrated as the formula
(2). fi(x, y) are binary valued feature functions with
the parameter Ai used to express the statistics of the
data sample. Zλ(x) is a normalization factor.
</bodyText>
<subsectionHeader confidence="0.99105">
5.3 PMI-IR Score as Features
</subsectionHeader>
<bodyText confidence="0.999735066666667">
The feature functions we adopted for ME differen-
tiate from most other works on the semantic label-
ing task, which mainly exploited features from well-
parsed text. Instead, we use a web-based statis-
tic called PMI-IR which mainly measures the co-
occurrence between the data to classify and the set of
paraphrase pattern templates we stated in section 4.
The PMI-IR measure was first adopted by (Turney,
2001) for mining synonyms from the Web. (Etzioni
et al., 2004) uses the PMI-IR measure to evaluate the
information extracted from the Web.
Given a compound nominalization pair p(x, y)
and a set of paraphrase pattern templates t1, t2,�,
tn, the PMI-IR score between p and ti can be com-
puted by formula (3).
</bodyText>
<equation confidence="0.998475333333333">
Hits(p, ti)
PMI(p, ti) = (3)
Hits(p)
</equation>
<bodyText confidence="0.997439375">
In which, PMI(p, ti) is the co-occurrence web
page counts of p(x, y) and ti. For example, if
the template t is ”é(dui) x_4t(conduct) y”
and the compound nominalization is the pair p(7�
*(animal),��- (categorization)), then Hits(p, t)
is the web counts returned from the search engine for
the pattern ”,f (dui) 7� *(animal) _4t(conduct)
(categorization)”.
</bodyText>
<subsectionHeader confidence="0.99933">
5.4 Scaling of PMI Features
</subsectionHeader>
<bodyText confidence="0.99984590625">
Web counts are inflated which need to be scaled to
attain a good estimation of the underlying probabil-
ity density function in ME. In our approach, first, a
log sub-linear transformation is used to preprocess
the raw PMI-IR feature function for the ME model.
Then, a discretization algorithm called CAIM (Kur-
gan and Cios, 2004) is used to transform the contin-
uous feature functions into discrete ones.
CAIM is a supervised discretization algorithm
which can discretize an attribute into the smallest
number of intervals and maximize the class-attribute
interdependency. Suppose that the data set consists
of M examples and each example belongs to only
one of the S classes. F indicates the continuous fea-
ture functions produced from paraphrase patterns in
our task. D is a discretization scheme on F, which
discretizes F into n non-overlapping discrete inter-
vals. The class variable and the discretization vari-
able of attribute F are treated as two random varibles
defining a two-dimensional frequency matrix(called
quanta matrix) that is shown in Table 4, in which,
qir is the total number of continuous values belong-
ing to the ith class that are within interval (dr−1, dr],
while Mi+ is the total number of values belong-
ing to the ith class, and M+r is the total number
of values of attribute F that are within the interval
(dr−1, dr], for i = 1, 2, ..., 5 and r = 1, 2, ..., n.
The CAIM algorithm uses a greedy search to find
the specific discretization sechme D according to
the Class-Attribute Interdependency Maximization
(CAIM) criterion defined as(4), where maxr is the
maximum value among all qir values.
</bodyText>
<equation confidence="0.995623">
pλ(y|x) = Zλ(x) exp E Aifi(x, y)J (2)
i
</equation>
<page confidence="0.996663">
77
</page>
<table confidence="0.999699571428571">
Class [d0,d1] ... [dr_1,dr] ... [dn_1,dn] Class Total
C1 q11 ... q1r ... q1n M1+
: : ... : ... : :
Ci qi1 ... qir ... qin Mi+
: : ... : ... : :
Cs qS1 ... qSr ... qSn MS+
Interval Total M+1 ... M+r ... M+n M
</table>
<tableCaption confidence="0.999688">
Table 4: The Quanta Matrix for Attribute F and Discretization Scheme D
</tableCaption>
<equation confidence="0.7164225">
maxi (4)
M+r
</equation>
<sectionHeader confidence="0.999121" genericHeader="evaluation">
6 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999987579710145">
In this section, we present our experimental results
on the semantic relation labeling of our Compound
Nominalization Dataset. We compared the perfor-
mance between two different engines, also, between
the raw PMI and the scaled one.
Two search engines, Google (www.google.com)
and Baidu (www.baidu.com) are used and compared
to obtain the PMI scores between a verb nominaliza-
tion pair and the set of paraphrase patterns. The re-
sult of using Google and Baidu are comparable. For
example, when using raw PMI score as the features
of ME classification model, Google based algorithm
obtains a correct classification rate of 65.3%, while
Baidu based algorithm obtains a correct classifica-
tion rate of 62.7%. The main difference between the
two search engines is their indexing and rating algo-
rithm of the web pages. Compared to Google, Baidu
uses a stop wordlist, including empty markers such
as7(le), to filter the queries. While this is benefi-
cial for common users, it hurts our algorithm which
depends heavily on such information.
Compared with using raw PMI as the classifi-
cation features, feature scaling improves much on
the classification result. Using Log transformation,
Both Google based and Baidu based algorithm in-
crease about 4 percent on the correct classification
rate and when CAIM algorithm is employed to pre-
process the data, both algorithm’s correct classifica-
tion rates increase more than 8 percent. We think
that the usefulness of log sub-linear transformation
is mainly due to the fact that the Web is extremely
biased and inflated. The compression of the inflated
feature space can enable the ME model to give a
good estimation of the underlying probability den-
sity function of the data. As to the usefulness of
the discretization of the data, we think that it is
mainly because that the web-based statistics contain
much noise and the features produced from para-
phrase patterns are highly correlated with specific
classes. CAIM discretization algorithm can maxi-
mize the class-attribute interdependence in the data
and can be seen as a noise pruning process in some
sense.
Among the four semantic relations labeled, PP
gets the best precision and recall overall and rela-
tions such as RA gets a lower F-score. We think
that this is mainly due to the difficulty in selecting
paraphrase patterns for RA compared to PP. Some
patterns are not as indicative as others for the rela-
tions considered. For example, the paraphrase pat-
terns ”Ax” ”y” -”Ay” (”in x” ”y” -”in y”) for RA
is not as indicative as the pattern ”,fx #4Ty” (dui
x conduct y) for PP. Discovering and selecting the
most indicative patterns for each relation is the key
element for our algorithm.
We can make a rough comparison to the related
works in the literature. In syntactic relation label-
ing of compound nominalization in English, Lap-
ata (2000) and Grover et al. (2005) both apply
parsed text and obtains 87.3%, 77% accuracy for
the subject-object and subject-object-prepositional
objects classification tasks respectively. Nicholson
(2005) uses both the parsed text and the web for the
classification of subject-object-prepositional objects
and the result is comparatively poor. Compared to
such works, the relations we exploited in the label-
ing task is purely semantic which makes the clas-
sification task more difficult and we don’t use any
parsed text as input. Considering the difficulty of
</bodyText>
<figure confidence="0.570905333333333">
1
CAIM(C, D�F ) =
n
n
E
r=1
</figure>
<page confidence="0.988061">
78
</page>
<table confidence="0.99996065">
Google F-Score precision Baidu F-Score
Precision Recall Recall
Raw PMI
PP 72.5 82.9 77.3 65.3 88.9 75.2
PA 47.6 50.0 48.8 50.0 42.1 45.7
MA 75.0 50.0 60.0 50.0 27.3 35.3
RA 66.7 50.0 57.1 80.0 44.4 57.1
Rate 65.3 62.7
Log
PP 66.7 85.7 75.0 68.2 83.3 75.0
PA 64.7 55.0 59.5 60.0 47.4 52.9
MA 80.0 66.7 72.7 66.7 54.5 60.0
RA 100 37.5 54.5 71.4 55.5 62.5
Rate 69.3 66.7
Log+Discretization
PP 82.5 94.3 88.0 80.9 94.4 87.2
PA 81.3 65.0 72.2 64.7 57.9 61.1
MA 75.0 50.0 60.0 87.5 63.6 73.7
RA 54.5 75.0 63.2 64.5 55.6 58.8
Rate 77.3 76.0
</table>
<tableCaption confidence="0.991141">
Table 5: Results comparing different search engines, raw PMI as features vs. scaled features. Rate is the
</tableCaption>
<bodyText confidence="0.915637">
correct classification rate for the four semantic relations overall.
the problem and the unsupervised nature of our al-
gorithm, the results (accuracy 77.3%) are very en-
couraging.
</bodyText>
<sectionHeader confidence="0.998391" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999975576923077">
In this paper, we view the semantic relation label-
ing of compound nominalization as a classification
problem. We propose four coarse-grained semantic
roles of the noun modifier for the verb nominaliza-
tion head. A Maximum Entropy model is applied
for the classification task. The features used for the
model are web-based statistics acquired via class re-
lated paraphrase patterns, which mainly use a set of
word instances of prepositions, support verbs, fea-
ture nouns and aspect markers. The experimental
result illustrates that our method is very effective.
We believe that the method we proposed is not
only limited in the semantic interpretation of com-
pound nominalizations, but can also be used as a
way to compensate the low accuracy of the more
general task of semantic role labeling of nominal-
ization phrases caused by the inefficiency of Chinese
parsers.
The major limitation of our approach is that the
paraphrase pattern templates we use now are hand-
coded according to the linguistic theory. To achieve
more generality of our method, in the future, we
should study automatic template induction and fea-
ture selection algorithms for the classifier to select
the set of most indicative pattern templates for each
semantic relation.
</bodyText>
<sectionHeader confidence="0.998241" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.968432333333333">
This work is supported by NSFC Major Research
Program 60496326: Basic Theory and Core Tech-
niques of Non Canonical Knowledge.
</bodyText>
<sectionHeader confidence="0.999251" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.926596625">
A.L. Berger, V.J. Della Pietra, and S.A. Della Pietra.
1996. A maximum entropy approach to natural
language processing. Computational Linguistics,
22(1):39–71.
D.A. Dahl, M.S. Palmer, and R.J. Passonneau. 1987.
Nominalizations in PUNDIT. Proceedings of the 25th
Annual Meeting of the Association for Computational
Linguistics, Stanford University, Stanford, CA, July.
</reference>
<page confidence="0.993729">
79
</page>
<reference confidence="0.998956865979381">
DR Dowty. 1991. Thematic ProtoRoles and Argu-
ment Selection. Second Conference on Maritime Ter-
monology, Turku, 33:31–38.
O. Etzioni, M. Cafarella, D. Downey, S. Kok, A.M.
Popescu, T. Shaked, S. Soderland, D.S. Weld, and
A. Yates. 2004. Web-scale information extraction
in knowitall:(preliminary results). Proceedings of the
13th international conference on World Wide Web,
pages 100–110.
T.W. Finin. 1980. The semantic interpretation of com-
pound nominals. Dissertation Abstracts International
Part B: Science and Engineering[DISS. ABST. INT.
PT. B- SCI. &amp; ENG.],, 41(6):1980.
G. Grefenstette and J. Nioche. 2000. Estimation of En-
glish and non-English Language Use on the WWW.
Arxiv preprint cs.CL/0006032.
C. Grover, A. Lascarides, and M. Lapata. 2005. A com-
parison of parsing technologies for the biomedical do-
main. Natural Language Engineering, 11(01):27–65.
M.A. Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. Proceedings of the 14th con-
ference on Computational linguistics-Volume 2, pages
539–545.
R.D. Hull and F. Gomez. 1996. Semantic interpretation
of nominalizations. AAAI Conference, pages 1062–
1068.
Guangjin Jin, Shulun Guo, Hang Xiao, and Yunfan
Zhang. 2003. Standardization for Corpus Processing.
Applied Linguistics, pages 16–24.
R. Jones and R. Ghani. 2000. Automatically building
a corpus for a minority language from the web. Pro-
ceedings of the Student Research Workshop at the 38th
Annual Meeting of the Association for Computational
Linguistics, pages 29–36.
F. Keller and M. Lapata. 2003. Using the web to ob-
tain frequencies for unseen bigrams. Computational
Linguistics, 29(3):459–484.
S.N. Kim and T. Baldwin. 2005. Automatic interpre-
tation of noun compounds using WordNet similarity.
Proc. ofIJCNLP-05, pages 945–956.
S.N. Kim and T. Baldwin. 2006. Interpreting Seman-
tic Relations in Noun Compounds via Verb Semantics.
Proceedings of the COLING/ACL 2006 Main Confer-
ence Poster Sessions, pages 491–498.
LA Kurgan and KJ Cios. 2004. CAIM discretization
algorithm. Knowledge and Data Engineering, IEEE
Transactions on, 16(2):145–153.
M. Lapata. 2000. The automatic interpretation of nomi-
nalizations. Proceedings ofAAAI.
M. Lauer. 1995. Designing Statistical Language Learn-
ers: Experiments on Compound Nouns. Ph.D. thesis,
Ph. D. thesis, Macquarie University, Sydney.
R. Leonard. 1984. The interpretation of English noun
sequences on the computer. North-Holland.
D.B. Mcdonald. 1982. Understanding noun compounds.
Carnegie-Mellon University.
D. Moldovan, A. Badulescu, M. Tatu, D. Antohe, and
R. Girju. 2004. Models for the semantic classification
of noun phrases. Proceedings of HLT/NAACL-2004
Workshop on Computational Lexical Semantics.
J. Nicholson. 2005. Statistical Interpretation of Com-
pound Nouns. Ph.D. thesis, University of Melbourne.
S. Pradhan, H. Sun, W. Ward, J.H. Martin, and D. Juraf-
sky. 2004. Parsing Arguments of Nominalizations in
English and Chinese. Proc. ofHLT-NAACL.
B. Rosario and M. Hearst. 2001. Classifying the seman-
tic relations in noun compounds via a domain-specific
lexical hierarchy. Proceedings of the 2001 Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP-01), pages 82–90.
S. Siegel and NJ Castellan. 1988. Nonparametric statis-
tics for the behavioral sciences. McGraw-HiU Book
Company, New York.
JF Sowa. 1984. Conceptual structures: information pro-
cessing in mind and machine. Addison-Wesley Long-
man Publishing Co., Inc. Boston, MA, USA.
P.D. Turney. 2001. Mining the Web for synonyms:
PMI-IR versus LSA on TOEFL. Proceedings of the
Twelfth European Conference on Machine Learning,
pages 491–502.
P.D. Turney. 2005. Measuring semantic similarity by
latent relational analysis. Proceedings of the Nine-
teenth International Joint Conference on Artificial In-
telligence (IJCAI-05), pages 1136–1141.
L.H. Vanderwende. 1995. The analysis of noun se-
quences using semantic information extractedfrom on-
line dictionaries. Ph.D. thesis, Georgetown Univer-
sity.
N. Xue. 2006. Semantic Role Labeling of Nominalized
Predicates in Chinese. Proceedings ofthe Human Lan-
guage Technology Conference of the North American
Chapter of the ACL.
X. Zhu and R. Rosenfeld. 2001. Improving trigram lan-
guage modeling with the World Wide Web. Acous-
tics, Speech, and Signal Processing, 2001. Proceed-
ings.(ICASSP’01). 2001 IEEE International Confer-
ence on, 1.
</reference>
<page confidence="0.998248">
80
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.752342">
<title confidence="0.999379">Semantic Labeling of Compound Nominalization in Chinese</title>
<author confidence="0.998502">Jinglei Zhao</author>
<author confidence="0.998502">Hui Liu</author>
<author confidence="0.998502">Ruzhan</author>
<affiliation confidence="0.999403">Department of Computer</affiliation>
<address confidence="0.8796565">Shanghai Jiao Tong 800 Dongchuan Road Shanghai,</address>
<abstract confidence="0.99884575">This paper discusses the semantic interpretation of compound nominalizations in Chinese. We propose four coarse-grained semantic roles of the noun modifier and use a Maximum Entropy Model to label such relations in a compound nominalization. The feature functions used for the model are web-based statistics acquired via role related paraphrase patterns, which are formed by a set of word instances of prepositions, support verbs, feature nouns and aspect markers. By applying a sub-linear transformation and discretization of the raw statistics, a rate of approximately 77% is obtained for classification of the four semantic relations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>V J Della Pietra</author>
<author>S A Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="14658" citStr="Berger et al., 1996" startWordPosition="2293" endWordPosition="2296">mpound Nominalizations Semantic Relations 76 of the annotation is 87.3%. Pr(A) − Pr(E) K = (1) 1 − Pr(E) After discussion, the two annotators reached agreement on a final version of the data sample labeling. In which, the proportion of relations PP, PA, MA, RA is 45.6%, 27.7%, 16.7% and 10% respectively, giving a baseline of 45.6% of the classification problem by viewing all the relations to be PP. Finally, the 300 data instances were partitioned into a training set and a testing set containing 225 and 75 instances respectively. 5.2 Maximum Entropy Model We use the Maximum Entropy (ME) Model (Berger et al., 1996) for our classification task. Given a set of training examples of a random process, ME is a method of estimating the conditional probability p(y|x) that, given a context x, the process will output y. In our task, the output corresponds to the four relation labels PP, PA, MA and RA. The modeling of ME is based on the Maximum Entropy Principle, that is, modeling all that is known and assuming nothing about what is unknown. The computation of p(y|x) is illustrated as the formula (2). fi(x, y) are binary valued feature functions with the parameter Ai used to express the statistics of the data samp</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A.L. Berger, V.J. Della Pietra, and S.A. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Dahl</author>
<author>M S Palmer</author>
<author>R J Passonneau</author>
</authors>
<date>1987</date>
<booktitle>Nominalizations in PUNDIT. Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Stanford University, Stanford, CA,</location>
<contexts>
<context position="5827" citStr="Dahl et al., 1987" startWordPosition="886" endWordPosition="889">assify semantic relations of NCs. (Lapata, 2000; Grover et al., 2005; Nicholson, 2005) use paraphrase statistics computed from parsed texts to interpret compound nominalization, but the relations used are purely syntactic. Lapata(2000) only classifies syntactic relations of subject and object. Grover(2005) and Nicholson (2005) classify relations of subject, object and prepositional object. 2.2 Semantic Role Labeling of Nominalization Most previous work on semantic role labeling of nominalizations are conducted in the situation where a verb nominalization is the head of a general noun phrase. (Dahl et al., 1987; Hull and Gomez, 1996) use hand-coded slot-filling rules to determine the semantic roles of the arguments of a nominalization. In such approaches, first, parsers are used to identify syntactic clues such as prepositional types. Then, rules are applied to label semantic roles according to clues and constraints of different roles. Supervised machine learning methods become prevalent in recent years in semantic role labeling of verb nominalizations as part of the resurgence of research in shallow semantic analysis. (Pradhan et al., 2004) use a SVM classifier for the semantic role labeling of nom</context>
</contexts>
<marker>Dahl, Palmer, Passonneau, 1987</marker>
<rawString>D.A. Dahl, M.S. Palmer, and R.J. Passonneau. 1987. Nominalizations in PUNDIT. Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics, Stanford University, Stanford, CA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DR Dowty</author>
</authors>
<date>1991</date>
<booktitle>Thematic ProtoRoles and Argument Selection. Second Conference on Maritime Termonology,</booktitle>
<pages>33--31</pages>
<location>Turku,</location>
<contexts>
<context position="8505" citStr="Dowty, 1991" startWordPosition="1314" endWordPosition="1315">etween a noun modifier and a verb nominalization head can be characterized by four coarsegrained semantic roles: Proto-Agent (PA), ProtoPatient (PP), Range (RA) and Manner (MA). This is illustrated by Table1. Relations Examples PA hAVT,(Blood Circulation) A a it4k (Bird Migration) PP � JL n(Enterprise Management) ÄÔ ©a(Animal Categorization) MA (Laser Storage) ¥I A_ U (Satellite Communication) RA 1 * 1/2 (Global Positioning) ��uA(Long-time Development) Table 1: Semantic Relations between Noun Modifier and Verb Nominalization Head. Due to the linking between semantic roles and syntactic roles (Dowty, 1991), the relations above overlap with syntactic roles, for example, ProtoAgent with Subject and Proto-Patient with Object, but they are not the same, as illustrated by the example Ä Ô © a(Animal Categorization). Although the predicate ©a(categorize) in Chinese is an intransitive verb, the semantic relation between ÄÔ(animal) and©a(categorization) is ProtoPatient. 4 Paraphrase Patterns 4.1 Motivations Syntactic patterns provide clues for semantic relations (Hearst, 1992). For example, Hearst(1992) uses the pattern ”NP such as List” to indicate that nouns in List are hyponyms of NP. To classify the</context>
</contexts>
<marker>Dowty, 1991</marker>
<rawString>DR Dowty. 1991. Thematic ProtoRoles and Argument Selection. Second Conference on Maritime Termonology, Turku, 33:31–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Etzioni</author>
<author>M Cafarella</author>
<author>D Downey</author>
<author>S Kok</author>
<author>A M Popescu</author>
<author>T Shaked</author>
<author>S Soderland</author>
<author>D S Weld</author>
<author>A Yates</author>
</authors>
<title>Web-scale information extraction in knowitall:(preliminary results).</title>
<date>2004</date>
<booktitle>Proceedings of the 13th international conference on World Wide Web,</booktitle>
<pages>100--110</pages>
<contexts>
<context position="15784" citStr="Etzioni et al., 2004" startWordPosition="2487" endWordPosition="2490"> valued feature functions with the parameter Ai used to express the statistics of the data sample. Zλ(x) is a normalization factor. 5.3 PMI-IR Score as Features The feature functions we adopted for ME differentiate from most other works on the semantic labeling task, which mainly exploited features from wellparsed text. Instead, we use a web-based statistic called PMI-IR which mainly measures the cooccurrence between the data to classify and the set of paraphrase pattern templates we stated in section 4. The PMI-IR measure was first adopted by (Turney, 2001) for mining synonyms from the Web. (Etzioni et al., 2004) uses the PMI-IR measure to evaluate the information extracted from the Web. Given a compound nominalization pair p(x, y) and a set of paraphrase pattern templates t1, t2,�, tn, the PMI-IR score between p and ti can be computed by formula (3). Hits(p, ti) PMI(p, ti) = (3) Hits(p) In which, PMI(p, ti) is the co-occurrence web page counts of p(x, y) and ti. For example, if the template t is ”é(dui) x_4t(conduct) y” and the compound nominalization is the pair p(7� *(animal),��- (categorization)), then Hits(p, t) is the web counts returned from the search engine for the pattern ”,f (dui) 7� *(anim</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Kok, Popescu, Shaked, Soderland, Weld, Yates, 2004</marker>
<rawString>O. Etzioni, M. Cafarella, D. Downey, S. Kok, A.M. Popescu, T. Shaked, S. Soderland, D.S. Weld, and A. Yates. 2004. Web-scale information extraction in knowitall:(preliminary results). Proceedings of the 13th international conference on World Wide Web, pages 100–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T W Finin</author>
</authors>
<title>The semantic interpretation of compound nominals.</title>
<date>1980</date>
<booktitle>Dissertation Abstracts International Part B: Science and Engineering[DISS. ABST. INT. PT. B- SCI. &amp; ENG.],,</booktitle>
<pages>41--6</pages>
<contexts>
<context position="1019" citStr="Finin, 1980" startWordPosition="154" endWordPosition="155">opy Model to label such relations in a compound nominalization. The feature functions used for the model are web-based statistics acquired via role related paraphrase patterns, which are formed by a set of word instances of prepositions, support verbs, feature nouns and aspect markers. By applying a sub-linear transformation and discretization of the raw statistics, a rate of approximately 77% is obtained for classification of the four semantic relations. 1 Introduction A nominal compound (NC) is the concatenation of any two or more nominal concepts which functions as a third nominal concept (Finin, 1980). (Leonard, 1984) observed that the amount of NCs had been increasing explosively in English in recent years. NCs such as satellite navigation system are abundant in news and technical texts. In other languages such as Chinese, NCs have been more productive since earlier days as evidenced by the fact that many simple words in Chinese are actually a result of compounding of morphemes. Many aspects in Natural Language Processing (NLP), such as machine translation, information retrieval, question answering, etc. call for the automatic interpretation of NCs, that is, making explicit the underlying</context>
<context position="4192" citStr="Finin, 1980" startWordPosition="639" endWordPosition="640">zation. The remainder of the paper is organized as follows: Section 2 describes related works. Section 3 describes the semantic relations for our labeling task. Section 4 introduces the paraphrase patterns used. Section 5 gives a detailed description of our algorithm. Section 6 presents the experimental result. Finally, in Section 7, we give the conclusions and discuss future work. 2 Related Works 2.1 Nominal Compound Interpretation The methods used in the semantic interpretation of NCs fall into two main categories: rule-based ones and statistic-based ones. The rule-based approaches such as (Finin, 1980; Mcdonald, 1982; Leonard, 1984; Vanderwende, 1995) think that the interpretation of NCs depends heavily on the constituent concepts and model the semantic interpretation as a slotfilling process. Various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head. The statistic-based approaches view the semantic interpretation as a multi-class classification problem. (Rosario and Hearst, 2001; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarch</context>
</contexts>
<marker>Finin, 1980</marker>
<rawString>T.W. Finin. 1980. The semantic interpretation of compound nominals. Dissertation Abstracts International Part B: Science and Engineering[DISS. ABST. INT. PT. B- SCI. &amp; ENG.],, 41(6):1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Grefenstette</author>
<author>J Nioche</author>
</authors>
<date>2000</date>
<booktitle>Estimation of English and non-English Language Use on the WWW. Arxiv preprint cs.CL/0006032.</booktitle>
<contexts>
<context position="7113" citStr="Grefenstette and Nioche, 2000" startWordPosition="1093" endWordPosition="1096"> database and the Chinese PropBank respectively. (Xue, 2006) uses the Chinese Nombank to label nominalizations in Chinese. Compared to English, the main difficulty of using supervised method for Chinese, as noted by Xue (2006), is that the precision of current parsers of Chinese is very low due to the lack of morphology, difficulty in segmentation and lack of sufficient training materials in Chinese. 2.3 Web as a large Corpus Data sparseness is the most notorious hinder for applying statistical methods in natural language processing. However, the World Wide Web can be seen as a large corpus. (Grefenstette and Nioche, 2000; Jones and Ghani, 2000) use the web to generate corpora for languages for which electronic resources are scarce. (Zhu and Rosenfeld, 2001) use Webbased n-gram counts for language modeling. (Keller and Lapata, 2003) show that Web page counts and n-gram frequency counts are highly correlated in a log scale. 74 3 Semantic Relations Although verb nominalization is commonly considered to have arguments as the verb predicate, Xue(2006) finds that there tend to be fewer arguments and fewer types of adjuncts in verb nominalizations compared to verb predicates in Chinese. We argue that this phenomenon</context>
</contexts>
<marker>Grefenstette, Nioche, 2000</marker>
<rawString>G. Grefenstette and J. Nioche. 2000. Estimation of English and non-English Language Use on the WWW. Arxiv preprint cs.CL/0006032.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Grover</author>
<author>A Lascarides</author>
<author>M Lapata</author>
</authors>
<title>A comparison of parsing technologies for the biomedical domain.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>01</issue>
<contexts>
<context position="5278" citStr="Grover et al., 2005" startWordPosition="806" endWordPosition="809">t al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs to characterize the semantic relation between the constituent nouns and explores a parsed corpus to classify NCs. (Turney, 2005) uses latent relational analysis to classify NCs. The similarity between two NCs is characterized by the similarity between their related pattern set. (Lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of NCs. (Lapata, 2000; Grover et al., 2005; Nicholson, 2005) use paraphrase statistics computed from parsed texts to interpret compound nominalization, but the relations used are purely syntactic. Lapata(2000) only classifies syntactic relations of subject and object. Grover(2005) and Nicholson (2005) classify relations of subject, object and prepositional object. 2.2 Semantic Role Labeling of Nominalization Most previous work on semantic role labeling of nominalizations are conducted in the situation where a verb nominalization is the head of a general noun phrase. (Dahl et al., 1987; Hull and Gomez, 1996) use hand-coded slot-filling</context>
<context position="21273" citStr="Grover et al. (2005)" startWordPosition="3421" endWordPosition="3424">nk that this is mainly due to the difficulty in selecting paraphrase patterns for RA compared to PP. Some patterns are not as indicative as others for the relations considered. For example, the paraphrase patterns ”Ax” ”y” -”Ay” (”in x” ”y” -”in y”) for RA is not as indicative as the pattern ”,fx #4Ty” (dui x conduct y) for PP. Discovering and selecting the most indicative patterns for each relation is the key element for our algorithm. We can make a rough comparison to the related works in the literature. In syntactic relation labeling of compound nominalization in English, Lapata (2000) and Grover et al. (2005) both apply parsed text and obtains 87.3%, 77% accuracy for the subject-object and subject-object-prepositional objects classification tasks respectively. Nicholson (2005) uses both the parsed text and the web for the classification of subject-object-prepositional objects and the result is comparatively poor. Compared to such works, the relations we exploited in the labeling task is purely semantic which makes the classification task more difficult and we don’t use any parsed text as input. Considering the difficulty of 1 CAIM(C, D�F ) = n n E r=1 78 Google F-Score precision Baidu F-Score Prec</context>
</contexts>
<marker>Grover, Lascarides, Lapata, 2005</marker>
<rawString>C. Grover, A. Lascarides, and M. Lapata. 2005. A comparison of parsing technologies for the biomedical domain. Natural Language Engineering, 11(01):27–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>Proceedings of the 14th conference on Computational linguistics-Volume 2,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="8976" citStr="Hearst, 1992" startWordPosition="1382" endWordPosition="1383">ntic Relations between Noun Modifier and Verb Nominalization Head. Due to the linking between semantic roles and syntactic roles (Dowty, 1991), the relations above overlap with syntactic roles, for example, ProtoAgent with Subject and Proto-Patient with Object, but they are not the same, as illustrated by the example Ä Ô © a(Animal Categorization). Although the predicate ©a(categorize) in Chinese is an intransitive verb, the semantic relation between ÄÔ(animal) and©a(categorization) is ProtoPatient. 4 Paraphrase Patterns 4.1 Motivations Syntactic patterns provide clues for semantic relations (Hearst, 1992). For example, Hearst(1992) uses the pattern ”NP such as List” to indicate that nouns in List are hyponyms of NP. To classify the four semantic relations listed in section 3, we propose some domain independent surface paraphrase patterns to characterize each semantic relation. The patterns we adopted mainly exploit a set of word instances of prepositions, support verbs, feature nouns and aspect markers. Prepositions are strong indicators of semantic roles in Chinese. For example, in sentence 1), the preposition46(ba) indicates that the noun17(door) and Mn(Zhangsan) is the Proto-Patient and Pro</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>M.A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. Proceedings of the 14th conference on Computational linguistics-Volume 2, pages 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R D Hull</author>
<author>F Gomez</author>
</authors>
<title>Semantic interpretation of nominalizations.</title>
<date>1996</date>
<booktitle>AAAI Conference,</booktitle>
<pages>1062--1068</pages>
<contexts>
<context position="5850" citStr="Hull and Gomez, 1996" startWordPosition="890" endWordPosition="893">ations of NCs. (Lapata, 2000; Grover et al., 2005; Nicholson, 2005) use paraphrase statistics computed from parsed texts to interpret compound nominalization, but the relations used are purely syntactic. Lapata(2000) only classifies syntactic relations of subject and object. Grover(2005) and Nicholson (2005) classify relations of subject, object and prepositional object. 2.2 Semantic Role Labeling of Nominalization Most previous work on semantic role labeling of nominalizations are conducted in the situation where a verb nominalization is the head of a general noun phrase. (Dahl et al., 1987; Hull and Gomez, 1996) use hand-coded slot-filling rules to determine the semantic roles of the arguments of a nominalization. In such approaches, first, parsers are used to identify syntactic clues such as prepositional types. Then, rules are applied to label semantic roles according to clues and constraints of different roles. Supervised machine learning methods become prevalent in recent years in semantic role labeling of verb nominalizations as part of the resurgence of research in shallow semantic analysis. (Pradhan et al., 2004) use a SVM classifier for the semantic role labeling of nominalizations in English</context>
</contexts>
<marker>Hull, Gomez, 1996</marker>
<rawString>R.D. Hull and F. Gomez. 1996. Semantic interpretation of nominalizations. AAAI Conference, pages 1062– 1068.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guangjin Jin</author>
<author>Shulun Guo</author>
<author>Hang Xiao</author>
<author>Yunfan Zhang</author>
</authors>
<title>Standardization for Corpus Processing. Applied Linguistics,</title>
<date>2003</date>
<pages>16--24</pages>
<contexts>
<context position="7859" citStr="Jin et al., 2003" startWordPosition="1216" endWordPosition="1219">eld, 2001) use Webbased n-gram counts for language modeling. (Keller and Lapata, 2003) show that Web page counts and n-gram frequency counts are highly correlated in a log scale. 74 3 Semantic Relations Although verb nominalization is commonly considered to have arguments as the verb predicate, Xue(2006) finds that there tend to be fewer arguments and fewer types of adjuncts in verb nominalizations compared to verb predicates in Chinese. We argue that this phenomenon is more obvious in compound nominalization. By analyzing a set of compound nominalizations of length two from a balanced corpus(Jin et al., 2003), we find the semantic relations between a noun modifier and a verb nominalization head can be characterized by four coarsegrained semantic roles: Proto-Agent (PA), ProtoPatient (PP), Range (RA) and Manner (MA). This is illustrated by Table1. Relations Examples PA hAVT,(Blood Circulation) A a it4k (Bird Migration) PP � JL n(Enterprise Management) ÄÔ ©a(Animal Categorization) MA (Laser Storage) ¥I A_ U (Satellite Communication) RA 1 * 1/2 (Global Positioning) ��uA(Long-time Development) Table 1: Semantic Relations between Noun Modifier and Verb Nominalization Head. Due to the linking between se</context>
<context position="12884" citStr="Jin et al., 2003" startWordPosition="2007" endWordPosition="2010">start y”) ”x” ”T—v),y” (”x” ”can y”) ”xRry” (”x suo y”) MA ”�fix” ”y” -”�Oxy” (”tongguo x” ”y” -”tongguo xy”) ”x &gt;4e” ”y” (”x method” ”y”) RA ”Ax” ”y” -”Ay”(”zai x” ”y” -”zai y”) ”Ax” ”y” (”cong x” ”y”) ”xe.Q” ”y” (”x range” ”y”) Table 3: A Sample Set of the Paraphrase Pattern Templates. 5 System Description 5.1 Data Source Figure 2: System Architecture Figure 2 illustrates the system architecture of our approach. We view the semantic labeling of compound nominalization as a data-driven classification problem. The data used for the experiment is autoextracted from the Chinese National Corpus (Jin et al., 2003), which is a balanced segmented and POS tagged corpus with 8M characters. Because the corpus doesn’t distinguish verb predicates with verb nominalizations, a verb nominalization recognizer is first used to recognize all the verb nominalizations in the corpus, and then, a compound extractor identifies all the compound nominalizations having a noun modifier and a verb nominalization head in the corpus. We manually examined a sample of the result set and finally randomly select 300 correct nounnominalization pairs as our training and testing set for semantic interpretation. One PHD student majore</context>
</contexts>
<marker>Jin, Guo, Xiao, Zhang, 2003</marker>
<rawString>Guangjin Jin, Shulun Guo, Hang Xiao, and Yunfan Zhang. 2003. Standardization for Corpus Processing. Applied Linguistics, pages 16–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jones</author>
<author>R Ghani</author>
</authors>
<title>Automatically building a corpus for a minority language from the web.</title>
<date>2000</date>
<booktitle>Proceedings of the Student Research Workshop at the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>29--36</pages>
<contexts>
<context position="7137" citStr="Jones and Ghani, 2000" startWordPosition="1097" endWordPosition="1100">ank respectively. (Xue, 2006) uses the Chinese Nombank to label nominalizations in Chinese. Compared to English, the main difficulty of using supervised method for Chinese, as noted by Xue (2006), is that the precision of current parsers of Chinese is very low due to the lack of morphology, difficulty in segmentation and lack of sufficient training materials in Chinese. 2.3 Web as a large Corpus Data sparseness is the most notorious hinder for applying statistical methods in natural language processing. However, the World Wide Web can be seen as a large corpus. (Grefenstette and Nioche, 2000; Jones and Ghani, 2000) use the web to generate corpora for languages for which electronic resources are scarce. (Zhu and Rosenfeld, 2001) use Webbased n-gram counts for language modeling. (Keller and Lapata, 2003) show that Web page counts and n-gram frequency counts are highly correlated in a log scale. 74 3 Semantic Relations Although verb nominalization is commonly considered to have arguments as the verb predicate, Xue(2006) finds that there tend to be fewer arguments and fewer types of adjuncts in verb nominalizations compared to verb predicates in Chinese. We argue that this phenomenon is more obvious in comp</context>
</contexts>
<marker>Jones, Ghani, 2000</marker>
<rawString>R. Jones and R. Ghani. 2000. Automatically building a corpus for a minority language from the web. Proceedings of the Student Research Workshop at the 38th Annual Meeting of the Association for Computational Linguistics, pages 29–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keller</author>
<author>M Lapata</author>
</authors>
<title>Using the web to obtain frequencies for unseen bigrams.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="7328" citStr="Keller and Lapata, 2003" startWordPosition="1128" endWordPosition="1131">(2006), is that the precision of current parsers of Chinese is very low due to the lack of morphology, difficulty in segmentation and lack of sufficient training materials in Chinese. 2.3 Web as a large Corpus Data sparseness is the most notorious hinder for applying statistical methods in natural language processing. However, the World Wide Web can be seen as a large corpus. (Grefenstette and Nioche, 2000; Jones and Ghani, 2000) use the web to generate corpora for languages for which electronic resources are scarce. (Zhu and Rosenfeld, 2001) use Webbased n-gram counts for language modeling. (Keller and Lapata, 2003) show that Web page counts and n-gram frequency counts are highly correlated in a log scale. 74 3 Semantic Relations Although verb nominalization is commonly considered to have arguments as the verb predicate, Xue(2006) finds that there tend to be fewer arguments and fewer types of adjuncts in verb nominalizations compared to verb predicates in Chinese. We argue that this phenomenon is more obvious in compound nominalization. By analyzing a set of compound nominalizations of length two from a balanced corpus(Jin et al., 2003), we find the semantic relations between a noun modifier and a verb n</context>
</contexts>
<marker>Keller, Lapata, 2003</marker>
<rawString>F. Keller and M. Lapata. 2003. Using the web to obtain frequencies for unseen bigrams. Computational Linguistics, 29(3):459–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Kim</author>
<author>T Baldwin</author>
</authors>
<title>Automatic interpretation of noun compounds using WordNet similarity.</title>
<date>2005</date>
<booktitle>Proc. ofIJCNLP-05,</booktitle>
<pages>945--956</pages>
<contexts>
<context position="4694" citStr="Kim and Baldwin, 2005" startWordPosition="715" endWordPosition="718"> fall into two main categories: rule-based ones and statistic-based ones. The rule-based approaches such as (Finin, 1980; Mcdonald, 1982; Leonard, 1984; Vanderwende, 1995) think that the interpretation of NCs depends heavily on the constituent concepts and model the semantic interpretation as a slotfilling process. Various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head. The statistic-based approaches view the semantic interpretation as a multi-class classification problem. (Rosario and Hearst, 2001; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs to characterize the semantic relation between the constituent nouns and explores a parsed corpus to classify NCs. (Turney, 2005) uses latent relational analysis to classify NCs. The similarity between two NCs is characterized by the similarity between their related pattern set. (Lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of NCs. (Lapata, 2000; Grover et al., 2005; Nicholson, 200</context>
</contexts>
<marker>Kim, Baldwin, 2005</marker>
<rawString>S.N. Kim and T. Baldwin. 2005. Automatic interpretation of noun compounds using WordNet similarity. Proc. ofIJCNLP-05, pages 945–956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Kim</author>
<author>T Baldwin</author>
</authors>
<title>Interpreting Semantic Relations in Noun Compounds via Verb Semantics.</title>
<date>2006</date>
<booktitle>Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>491--498</pages>
<contexts>
<context position="4818" citStr="Kim and Baldwin, 2006" startWordPosition="733" endWordPosition="736">donald, 1982; Leonard, 1984; Vanderwende, 1995) think that the interpretation of NCs depends heavily on the constituent concepts and model the semantic interpretation as a slotfilling process. Various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head. The statistic-based approaches view the semantic interpretation as a multi-class classification problem. (Rosario and Hearst, 2001; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs to characterize the semantic relation between the constituent nouns and explores a parsed corpus to classify NCs. (Turney, 2005) uses latent relational analysis to classify NCs. The similarity between two NCs is characterized by the similarity between their related pattern set. (Lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of NCs. (Lapata, 2000; Grover et al., 2005; Nicholson, 2005) use paraphrase statistics computed from parsed texts to interpret compound nominalization, but the relations used are pur</context>
</contexts>
<marker>Kim, Baldwin, 2006</marker>
<rawString>S.N. Kim and T. Baldwin. 2006. Interpreting Semantic Relations in Noun Compounds via Verb Semantics. Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 491–498.</rawString>
</citation>
<citation valid="true">
<authors>
<author>LA Kurgan</author>
<author>KJ Cios</author>
</authors>
<title>CAIM discretization algorithm.</title>
<date>2004</date>
<journal>Knowledge and Data Engineering, IEEE Transactions on,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="16774" citStr="Kurgan and Cios, 2004" startWordPosition="2652" endWordPosition="2656">e, if the template t is ”é(dui) x_4t(conduct) y” and the compound nominalization is the pair p(7� *(animal),��- (categorization)), then Hits(p, t) is the web counts returned from the search engine for the pattern ”,f (dui) 7� *(animal) _4t(conduct) (categorization)”. 5.4 Scaling of PMI Features Web counts are inflated which need to be scaled to attain a good estimation of the underlying probability density function in ME. In our approach, first, a log sub-linear transformation is used to preprocess the raw PMI-IR feature function for the ME model. Then, a discretization algorithm called CAIM (Kurgan and Cios, 2004) is used to transform the continuous feature functions into discrete ones. CAIM is a supervised discretization algorithm which can discretize an attribute into the smallest number of intervals and maximize the class-attribute interdependency. Suppose that the data set consists of M examples and each example belongs to only one of the S classes. F indicates the continuous feature functions produced from paraphrase patterns in our task. D is a discretization scheme on F, which discretizes F into n non-overlapping discrete intervals. The class variable and the discretization variable of attribute</context>
</contexts>
<marker>Kurgan, Cios, 2004</marker>
<rawString>LA Kurgan and KJ Cios. 2004. CAIM discretization algorithm. Knowledge and Data Engineering, IEEE Transactions on, 16(2):145–153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lapata</author>
</authors>
<title>The automatic interpretation of nominalizations.</title>
<date>2000</date>
<booktitle>Proceedings ofAAAI.</booktitle>
<contexts>
<context position="5257" citStr="Lapata, 2000" startWordPosition="804" endWordPosition="805">01; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs to characterize the semantic relation between the constituent nouns and explores a parsed corpus to classify NCs. (Turney, 2005) uses latent relational analysis to classify NCs. The similarity between two NCs is characterized by the similarity between their related pattern set. (Lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of NCs. (Lapata, 2000; Grover et al., 2005; Nicholson, 2005) use paraphrase statistics computed from parsed texts to interpret compound nominalization, but the relations used are purely syntactic. Lapata(2000) only classifies syntactic relations of subject and object. Grover(2005) and Nicholson (2005) classify relations of subject, object and prepositional object. 2.2 Semantic Role Labeling of Nominalization Most previous work on semantic role labeling of nominalizations are conducted in the situation where a verb nominalization is the head of a general noun phrase. (Dahl et al., 1987; Hull and Gomez, 1996) use ha</context>
<context position="21248" citStr="Lapata (2000)" startWordPosition="3417" endWordPosition="3419">er F-score. We think that this is mainly due to the difficulty in selecting paraphrase patterns for RA compared to PP. Some patterns are not as indicative as others for the relations considered. For example, the paraphrase patterns ”Ax” ”y” -”Ay” (”in x” ”y” -”in y”) for RA is not as indicative as the pattern ”,fx #4Ty” (dui x conduct y) for PP. Discovering and selecting the most indicative patterns for each relation is the key element for our algorithm. We can make a rough comparison to the related works in the literature. In syntactic relation labeling of compound nominalization in English, Lapata (2000) and Grover et al. (2005) both apply parsed text and obtains 87.3%, 77% accuracy for the subject-object and subject-object-prepositional objects classification tasks respectively. Nicholson (2005) uses both the parsed text and the web for the classification of subject-object-prepositional objects and the result is comparatively poor. Compared to such works, the relations we exploited in the labeling task is purely semantic which makes the classification task more difficult and we don’t use any parsed text as input. Considering the difficulty of 1 CAIM(C, D�F ) = n n E r=1 78 Google F-Score pre</context>
</contexts>
<marker>Lapata, 2000</marker>
<rawString>M. Lapata. 2000. The automatic interpretation of nominalizations. Proceedings ofAAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lauer</author>
</authors>
<title>Designing Statistical Language Learners: Experiments on Compound Nouns.</title>
<date>1995</date>
<tech>Ph.D. thesis, Ph. D. thesis,</tech>
<institution>Macquarie University, Sydney.</institution>
<contexts>
<context position="5135" citStr="Lauer, 1995" startWordPosition="786" endWordPosition="787">atistic-based approaches view the semantic interpretation as a multi-class classification problem. (Rosario and Hearst, 2001; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs to characterize the semantic relation between the constituent nouns and explores a parsed corpus to classify NCs. (Turney, 2005) uses latent relational analysis to classify NCs. The similarity between two NCs is characterized by the similarity between their related pattern set. (Lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of NCs. (Lapata, 2000; Grover et al., 2005; Nicholson, 2005) use paraphrase statistics computed from parsed texts to interpret compound nominalization, but the relations used are purely syntactic. Lapata(2000) only classifies syntactic relations of subject and object. Grover(2005) and Nicholson (2005) classify relations of subject, object and prepositional object. 2.2 Semantic Role Labeling of Nominalization Most previous work on semantic role labeling of nominalizations are conducted in the si</context>
</contexts>
<marker>Lauer, 1995</marker>
<rawString>M. Lauer. 1995. Designing Statistical Language Learners: Experiments on Compound Nouns. Ph.D. thesis, Ph. D. thesis, Macquarie University, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leonard</author>
</authors>
<title>The interpretation of English noun sequences on the computer.</title>
<date>1984</date>
<journal>North-Holland. D.B. Mcdonald.</journal>
<institution>Carnegie-Mellon University.</institution>
<contexts>
<context position="1036" citStr="Leonard, 1984" startWordPosition="156" endWordPosition="157">bel such relations in a compound nominalization. The feature functions used for the model are web-based statistics acquired via role related paraphrase patterns, which are formed by a set of word instances of prepositions, support verbs, feature nouns and aspect markers. By applying a sub-linear transformation and discretization of the raw statistics, a rate of approximately 77% is obtained for classification of the four semantic relations. 1 Introduction A nominal compound (NC) is the concatenation of any two or more nominal concepts which functions as a third nominal concept (Finin, 1980). (Leonard, 1984) observed that the amount of NCs had been increasing explosively in English in recent years. NCs such as satellite navigation system are abundant in news and technical texts. In other languages such as Chinese, NCs have been more productive since earlier days as evidenced by the fact that many simple words in Chinese are actually a result of compounding of morphemes. Many aspects in Natural Language Processing (NLP), such as machine translation, information retrieval, question answering, etc. call for the automatic interpretation of NCs, that is, making explicit the underlying semantic relatio</context>
<context position="4223" citStr="Leonard, 1984" startWordPosition="643" endWordPosition="644">paper is organized as follows: Section 2 describes related works. Section 3 describes the semantic relations for our labeling task. Section 4 introduces the paraphrase patterns used. Section 5 gives a detailed description of our algorithm. Section 6 presents the experimental result. Finally, in Section 7, we give the conclusions and discuss future work. 2 Related Works 2.1 Nominal Compound Interpretation The methods used in the semantic interpretation of NCs fall into two main categories: rule-based ones and statistic-based ones. The rule-based approaches such as (Finin, 1980; Mcdonald, 1982; Leonard, 1984; Vanderwende, 1995) think that the interpretation of NCs depends heavily on the constituent concepts and model the semantic interpretation as a slotfilling process. Various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head. The statistic-based approaches view the semantic interpretation as a multi-class classification problem. (Rosario and Hearst, 2001; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use </context>
</contexts>
<marker>Leonard, 1984</marker>
<rawString>R. Leonard. 1984. The interpretation of English noun sequences on the computer. North-Holland. D.B. Mcdonald. 1982. Understanding noun compounds. Carnegie-Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>A Badulescu</author>
<author>M Tatu</author>
<author>D Antohe</author>
<author>R Girju</author>
</authors>
<title>Models for the semantic classification of noun phrases.</title>
<date>2004</date>
<booktitle>Proceedings of HLT/NAACL-2004 Workshop on Computational Lexical Semantics.</booktitle>
<contexts>
<context position="4670" citStr="Moldovan et al., 2004" startWordPosition="711" endWordPosition="714">c interpretation of NCs fall into two main categories: rule-based ones and statistic-based ones. The rule-based approaches such as (Finin, 1980; Mcdonald, 1982; Leonard, 1984; Vanderwende, 1995) think that the interpretation of NCs depends heavily on the constituent concepts and model the semantic interpretation as a slotfilling process. Various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head. The statistic-based approaches view the semantic interpretation as a multi-class classification problem. (Rosario and Hearst, 2001; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs to characterize the semantic relation between the constituent nouns and explores a parsed corpus to classify NCs. (Turney, 2005) uses latent relational analysis to classify NCs. The similarity between two NCs is characterized by the similarity between their related pattern set. (Lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of NCs. (Lapata, 2000; Grover et a</context>
</contexts>
<marker>Moldovan, Badulescu, Tatu, Antohe, Girju, 2004</marker>
<rawString>D. Moldovan, A. Badulescu, M. Tatu, D. Antohe, and R. Girju. 2004. Models for the semantic classification of noun phrases. Proceedings of HLT/NAACL-2004 Workshop on Computational Lexical Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nicholson</author>
</authors>
<title>Statistical Interpretation of Compound Nouns.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Melbourne.</institution>
<contexts>
<context position="5296" citStr="Nicholson, 2005" startWordPosition="810" endWordPosition="811">Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs to characterize the semantic relation between the constituent nouns and explores a parsed corpus to classify NCs. (Turney, 2005) uses latent relational analysis to classify NCs. The similarity between two NCs is characterized by the similarity between their related pattern set. (Lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of NCs. (Lapata, 2000; Grover et al., 2005; Nicholson, 2005) use paraphrase statistics computed from parsed texts to interpret compound nominalization, but the relations used are purely syntactic. Lapata(2000) only classifies syntactic relations of subject and object. Grover(2005) and Nicholson (2005) classify relations of subject, object and prepositional object. 2.2 Semantic Role Labeling of Nominalization Most previous work on semantic role labeling of nominalizations are conducted in the situation where a verb nominalization is the head of a general noun phrase. (Dahl et al., 1987; Hull and Gomez, 1996) use hand-coded slot-filling rules to determin</context>
<context position="21444" citStr="Nicholson (2005)" startWordPosition="3443" endWordPosition="3444">. For example, the paraphrase patterns ”Ax” ”y” -”Ay” (”in x” ”y” -”in y”) for RA is not as indicative as the pattern ”,fx #4Ty” (dui x conduct y) for PP. Discovering and selecting the most indicative patterns for each relation is the key element for our algorithm. We can make a rough comparison to the related works in the literature. In syntactic relation labeling of compound nominalization in English, Lapata (2000) and Grover et al. (2005) both apply parsed text and obtains 87.3%, 77% accuracy for the subject-object and subject-object-prepositional objects classification tasks respectively. Nicholson (2005) uses both the parsed text and the web for the classification of subject-object-prepositional objects and the result is comparatively poor. Compared to such works, the relations we exploited in the labeling task is purely semantic which makes the classification task more difficult and we don’t use any parsed text as input. Considering the difficulty of 1 CAIM(C, D�F ) = n n E r=1 78 Google F-Score precision Baidu F-Score Precision Recall Recall Raw PMI PP 72.5 82.9 77.3 65.3 88.9 75.2 PA 47.6 50.0 48.8 50.0 42.1 45.7 MA 75.0 50.0 60.0 50.0 27.3 35.3 RA 66.7 50.0 57.1 80.0 44.4 57.1 Rate 65.3 6</context>
</contexts>
<marker>Nicholson, 2005</marker>
<rawString>J. Nicholson. 2005. Statistical Interpretation of Compound Nouns. Ph.D. thesis, University of Melbourne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>H Sun</author>
<author>W Ward</author>
<author>J H Martin</author>
<author>D Jurafsky</author>
</authors>
<date>2004</date>
<booktitle>Parsing Arguments of Nominalizations in English and Chinese. Proc. ofHLT-NAACL.</booktitle>
<contexts>
<context position="6368" citStr="Pradhan et al., 2004" startWordPosition="968" endWordPosition="971">e a verb nominalization is the head of a general noun phrase. (Dahl et al., 1987; Hull and Gomez, 1996) use hand-coded slot-filling rules to determine the semantic roles of the arguments of a nominalization. In such approaches, first, parsers are used to identify syntactic clues such as prepositional types. Then, rules are applied to label semantic roles according to clues and constraints of different roles. Supervised machine learning methods become prevalent in recent years in semantic role labeling of verb nominalizations as part of the resurgence of research in shallow semantic analysis. (Pradhan et al., 2004) use a SVM classifier for the semantic role labeling of nominalizations in English and Chinese based on the FrameNet database and the Chinese PropBank respectively. (Xue, 2006) uses the Chinese Nombank to label nominalizations in Chinese. Compared to English, the main difficulty of using supervised method for Chinese, as noted by Xue (2006), is that the precision of current parsers of Chinese is very low due to the lack of morphology, difficulty in segmentation and lack of sufficient training materials in Chinese. 2.3 Web as a large Corpus Data sparseness is the most notorious hinder for apply</context>
</contexts>
<marker>Pradhan, Sun, Ward, Martin, Jurafsky, 2004</marker>
<rawString>S. Pradhan, H. Sun, W. Ward, J.H. Martin, and D. Jurafsky. 2004. Parsing Arguments of Nominalizations in English and Chinese. Proc. ofHLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Rosario</author>
<author>M Hearst</author>
</authors>
<title>Classifying the semantic relations in noun compounds via a domain-specific lexical hierarchy.</title>
<date>2001</date>
<booktitle>Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP-01),</booktitle>
<pages>82--90</pages>
<contexts>
<context position="4647" citStr="Rosario and Hearst, 2001" startWordPosition="707" endWordPosition="710">ethods used in the semantic interpretation of NCs fall into two main categories: rule-based ones and statistic-based ones. The rule-based approaches such as (Finin, 1980; Mcdonald, 1982; Leonard, 1984; Vanderwende, 1995) think that the interpretation of NCs depends heavily on the constituent concepts and model the semantic interpretation as a slotfilling process. Various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head. The statistic-based approaches view the semantic interpretation as a multi-class classification problem. (Rosario and Hearst, 2001; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs to characterize the semantic relation between the constituent nouns and explores a parsed corpus to classify NCs. (Turney, 2005) uses latent relational analysis to classify NCs. The similarity between two NCs is characterized by the similarity between their related pattern set. (Lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of NCs. (La</context>
</contexts>
<marker>Rosario, Hearst, 2001</marker>
<rawString>B. Rosario and M. Hearst. 2001. Classifying the semantic relations in noun compounds via a domain-specific lexical hierarchy. Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP-01), pages 82–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>NJ Castellan</author>
</authors>
<title>Nonparametric statistics for the behavioral sciences.</title>
<date>1988</date>
<publisher>McGraw-HiU Book Company,</publisher>
<location>New York.</location>
<contexts>
<context position="13735" citStr="Siegel and Castellan, 1988" startWordPosition="2140" endWordPosition="2143">verb nominalizations in the corpus, and then, a compound extractor identifies all the compound nominalizations having a noun modifier and a verb nominalization head in the corpus. We manually examined a sample of the result set and finally randomly select 300 correct nounnominalization pairs as our training and testing set for semantic interpretation. One PHD student majored in computer science and one in linguistics were employed to label all the 300 data samples simultaneously according to the relation set given in section 3. The annotator’s agreement was measured using the Kappa statistic (Siegel and Castellan, 1988) illustrated in (1), of which Pr(A) is the probability of the actual outcome and Pr(E) is the probability of the expected outcome as predicted by chance. The Kappa score Nominalization Recognizer Corpus PMI Statistic Compound Extractor Search Engine Data Preprocessing ME Classifier Pattern Templates Compound Nominalizations Semantic Relations 76 of the annotation is 87.3%. Pr(A) − Pr(E) K = (1) 1 − Pr(E) After discussion, the two annotators reached agreement on a final version of the data sample labeling. In which, the proportion of relations PP, PA, MA, RA is 45.6%, 27.7%, 16.7% and 10% respe</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>S. Siegel and NJ Castellan. 1988. Nonparametric statistics for the behavioral sciences. McGraw-HiU Book Company, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JF Sowa</author>
</authors>
<title>Conceptual structures: information processing in mind and machine.</title>
<date>1984</date>
<publisher>Addison-Wesley Longman Publishing Co., Inc.</publisher>
<location>Boston, MA, USA.</location>
<contexts>
<context position="1809" citStr="Sowa, 1984" startWordPosition="277" endWordPosition="278">nical texts. In other languages such as Chinese, NCs have been more productive since earlier days as evidenced by the fact that many simple words in Chinese are actually a result of compounding of morphemes. Many aspects in Natural Language Processing (NLP), such as machine translation, information retrieval, question answering, etc. call for the automatic interpretation of NCs, that is, making explicit the underlying semantic relationships between the constituent concepts. For example, the semantic relations involved in satellite communication system can be expressed by the conceptual graph (Sowa, 1984) in Figure 1, in which, for instance, the semantic relation between satellite and communication is MANNER. Due to the productivity of NCs and the lack of syntactic clues to guide the interpretation process, the automatic interpretation of NCs has been proven to be a very difficult problem in NLP. In this paper, we deal with the semantic interpretation of NCs in Chinese. Especially, we will focus on a subset of NCs in which the head word is a verb nominalization. Nominalization is a common phenomenon across languages in which a predicative expression is transformed to refer to an event or a pro</context>
</contexts>
<marker>Sowa, 1984</marker>
<rawString>JF Sowa. 1984. Conceptual structures: information processing in mind and machine. Addison-Wesley Longman Publishing Co., Inc. Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Mining the Web for synonyms: PMI-IR versus LSA on TOEFL.</title>
<date>2001</date>
<booktitle>Proceedings of the Twelfth European Conference on Machine Learning,</booktitle>
<pages>491--502</pages>
<contexts>
<context position="15727" citStr="Turney, 2001" startWordPosition="2479" endWordPosition="2480">lustrated as the formula (2). fi(x, y) are binary valued feature functions with the parameter Ai used to express the statistics of the data sample. Zλ(x) is a normalization factor. 5.3 PMI-IR Score as Features The feature functions we adopted for ME differentiate from most other works on the semantic labeling task, which mainly exploited features from wellparsed text. Instead, we use a web-based statistic called PMI-IR which mainly measures the cooccurrence between the data to classify and the set of paraphrase pattern templates we stated in section 4. The PMI-IR measure was first adopted by (Turney, 2001) for mining synonyms from the Web. (Etzioni et al., 2004) uses the PMI-IR measure to evaluate the information extracted from the Web. Given a compound nominalization pair p(x, y) and a set of paraphrase pattern templates t1, t2,�, tn, the PMI-IR score between p and ti can be computed by formula (3). Hits(p, ti) PMI(p, ti) = (3) Hits(p) In which, PMI(p, ti) is the co-occurrence web page counts of p(x, y) and ti. For example, if the template t is ”é(dui) x_4t(conduct) y” and the compound nominalization is the pair p(7� *(animal),��- (categorization)), then Hits(p, t) is the web counts returned f</context>
</contexts>
<marker>Turney, 2001</marker>
<rawString>P.D. Turney. 2001. Mining the Web for synonyms: PMI-IR versus LSA on TOEFL. Proceedings of the Twelfth European Conference on Machine Learning, pages 491–502.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Measuring semantic similarity by latent relational analysis.</title>
<date>2005</date>
<booktitle>Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-05),</booktitle>
<pages>1136--1141</pages>
<contexts>
<context position="4971" citStr="Turney, 2005" startWordPosition="760" endWordPosition="761">tion as a slotfilling process. Various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head. The statistic-based approaches view the semantic interpretation as a multi-class classification problem. (Rosario and Hearst, 2001; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs to characterize the semantic relation between the constituent nouns and explores a parsed corpus to classify NCs. (Turney, 2005) uses latent relational analysis to classify NCs. The similarity between two NCs is characterized by the similarity between their related pattern set. (Lauer, 1995) is the first to use paraphrase based unsupervised statistical models to classify semantic relations of NCs. (Lapata, 2000; Grover et al., 2005; Nicholson, 2005) use paraphrase statistics computed from parsed texts to interpret compound nominalization, but the relations used are purely syntactic. Lapata(2000) only classifies syntactic relations of subject and object. Grover(2005) and Nicholson (2005) classify relations of subject, o</context>
</contexts>
<marker>Turney, 2005</marker>
<rawString>P.D. Turney. 2005. Measuring semantic similarity by latent relational analysis. Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-05), pages 1136–1141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L H Vanderwende</author>
</authors>
<title>The analysis of noun sequences using semantic information extractedfrom online dictionaries.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>Georgetown University.</institution>
<contexts>
<context position="4243" citStr="Vanderwende, 1995" startWordPosition="645" endWordPosition="646">zed as follows: Section 2 describes related works. Section 3 describes the semantic relations for our labeling task. Section 4 introduces the paraphrase patterns used. Section 5 gives a detailed description of our algorithm. Section 6 presents the experimental result. Finally, in Section 7, we give the conclusions and discuss future work. 2 Related Works 2.1 Nominal Compound Interpretation The methods used in the semantic interpretation of NCs fall into two main categories: rule-based ones and statistic-based ones. The rule-based approaches such as (Finin, 1980; Mcdonald, 1982; Leonard, 1984; Vanderwende, 1995) think that the interpretation of NCs depends heavily on the constituent concepts and model the semantic interpretation as a slotfilling process. Various rules are employed by such approaches to determine, for example, whether the modifier can fill in one slot of the head. The statistic-based approaches view the semantic interpretation as a multi-class classification problem. (Rosario and Hearst, 2001; Moldovan et al., 2004; Kim and Baldwin, 2005) use supervised methods and explore classification features from a simple structured type hierarchy. (Kim and Baldwin, 2006) use a set of seed verbs </context>
</contexts>
<marker>Vanderwende, 1995</marker>
<rawString>L.H. Vanderwende. 1995. The analysis of noun sequences using semantic information extractedfrom online dictionaries. Ph.D. thesis, Georgetown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
</authors>
<title>Semantic Role Labeling of Nominalized Predicates in Chinese.</title>
<date>2006</date>
<booktitle>Proceedings ofthe Human Language Technology Conference of the North American Chapter of the ACL.</booktitle>
<contexts>
<context position="6544" citStr="Xue, 2006" startWordPosition="999" endWordPosition="1000">of a nominalization. In such approaches, first, parsers are used to identify syntactic clues such as prepositional types. Then, rules are applied to label semantic roles according to clues and constraints of different roles. Supervised machine learning methods become prevalent in recent years in semantic role labeling of verb nominalizations as part of the resurgence of research in shallow semantic analysis. (Pradhan et al., 2004) use a SVM classifier for the semantic role labeling of nominalizations in English and Chinese based on the FrameNet database and the Chinese PropBank respectively. (Xue, 2006) uses the Chinese Nombank to label nominalizations in Chinese. Compared to English, the main difficulty of using supervised method for Chinese, as noted by Xue (2006), is that the precision of current parsers of Chinese is very low due to the lack of morphology, difficulty in segmentation and lack of sufficient training materials in Chinese. 2.3 Web as a large Corpus Data sparseness is the most notorious hinder for applying statistical methods in natural language processing. However, the World Wide Web can be seen as a large corpus. (Grefenstette and Nioche, 2000; Jones and Ghani, 2000) use th</context>
</contexts>
<marker>Xue, 2006</marker>
<rawString>N. Xue. 2006. Semantic Role Labeling of Nominalized Predicates in Chinese. Proceedings ofthe Human Language Technology Conference of the North American Chapter of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>R Rosenfeld</author>
</authors>
<title>Improving trigram language modeling with the World Wide Web. Acoustics, Speech, and Signal Processing,</title>
<date>2001</date>
<booktitle>Proceedings.(ICASSP’01). 2001 IEEE International Conference on,</booktitle>
<pages>1</pages>
<contexts>
<context position="7252" citStr="Zhu and Rosenfeld, 2001" startWordPosition="1116" endWordPosition="1119">the main difficulty of using supervised method for Chinese, as noted by Xue (2006), is that the precision of current parsers of Chinese is very low due to the lack of morphology, difficulty in segmentation and lack of sufficient training materials in Chinese. 2.3 Web as a large Corpus Data sparseness is the most notorious hinder for applying statistical methods in natural language processing. However, the World Wide Web can be seen as a large corpus. (Grefenstette and Nioche, 2000; Jones and Ghani, 2000) use the web to generate corpora for languages for which electronic resources are scarce. (Zhu and Rosenfeld, 2001) use Webbased n-gram counts for language modeling. (Keller and Lapata, 2003) show that Web page counts and n-gram frequency counts are highly correlated in a log scale. 74 3 Semantic Relations Although verb nominalization is commonly considered to have arguments as the verb predicate, Xue(2006) finds that there tend to be fewer arguments and fewer types of adjuncts in verb nominalizations compared to verb predicates in Chinese. We argue that this phenomenon is more obvious in compound nominalization. By analyzing a set of compound nominalizations of length two from a balanced corpus(Jin et al.</context>
</contexts>
<marker>Zhu, Rosenfeld, 2001</marker>
<rawString>X. Zhu and R. Rosenfeld. 2001. Improving trigram language modeling with the World Wide Web. Acoustics, Speech, and Signal Processing, 2001. Proceedings.(ICASSP’01). 2001 IEEE International Conference on, 1.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>