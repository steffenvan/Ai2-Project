<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.998928">
Dependency-Based Semantic Role Labeling using
Convolutional Neural Networks
</title>
<author confidence="0.992934">
William R. Foland Jr.
</author>
<affiliation confidence="0.936258">
OKRobotGo, Ltd.
</affiliation>
<address confidence="0.8465285">
5345 Dunraven Circle
Golden, Co, 80403, USA
</address>
<email confidence="0.99847">
bill.foland@okrobotgo.com
</email>
<author confidence="0.994438">
James H. Martin
</author>
<affiliation confidence="0.999176">
Department of Computer Science and
Institute of Cognitive Science
University of Colorado
</affiliation>
<address confidence="0.684479">
Boulder, CO 80309
</address>
<email confidence="0.998035">
James.Martin@colorado.edu
</email>
<sectionHeader confidence="0.995624" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99925">
We describe a semantic role labeler with state-
of-the-art performance and low computational
requirements, which uses convolutional and
time-domain neural networks. The system is
designed to work with features derived from
a dependency parser output. Various system
options and architectural details are discussed.
Incremental experiments were run to explore
the benefits of adding increasingly more com-
plex dependency-based features to the system;
results are presented for both in-domain and
out-of-domain datasets.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995665222222222">
Semantic role labeling (Gildea and Jurafsky [2002]),
the task of identifying and classifying the semantic
arguments of verbal and nominal predicates in text,
represents one of the most complex NLP tasks to
be addressed by supervised machine learning tech-
niques. In the standard supervised approach to
building SRL systems, collections of multiway clas-
sifiers are trained using annotated corpora such as
PropBank (Palmer et al. [2005]). In this approach,
classifiers are trained using features derived directly
from the original source text, as well as from subse-
quent syntactic and semantic processing.
As reported in several shared tasks (Carreras and
M`arquez [2004],Carreras and M`arquez [2005],Hajiˇc
et al. [2009]), SRL systems trained in this manner
can achieve high performance. State-of-the-art sys-
tems employ classifiers such as support vector ma-
chines trained with large numbers of relatively com-
plex combinations of features, often combined with
279
re-ranking based on multiple syntactic analyses. Un-
fortunately, these approaches have a number of non-
trivial limitations including the computational cost
of the syntactic parsing and the sparse nature of the
complex features on which they rely. This latter lim-
itation is particularly critical since it leads to signif-
icant degradation in performance when the trained
system is applied to texts from new domains.
However, recent results using multilayer neu-
ral networks and pre-trained word embeddings
have demonstrated high performance using a much
smaller number of minimalist features. The archi-
tecture described by Collobert et al. [2011] com-
bines time delay convolutional neural networks
(Waibel et al. [1989]) and pre-trained word embed-
dings for a number of NLP tasks. They develop four
components and compare their performance to pre-
vious benchmarks, one of which is an SRL system
which uses features derived from a phrase-structure
parse as input, based on the CoNLL 2005 shared
task (Carreras and M`arquez [2005]).
The work described here adopts the basic archi-
tecture from Collobert et al. [2011] and explores
issues related to the use of this architecture in the
context of the CoNLL 2009 shared task. In partic-
ular, we present Daisy, a system that (1) employs
features derived from dependency parse as input,
(2) assigns semantic roles to both verbal and nom-
inal predicates, and (3) automatically assigns word
senses to the predicates as described in the CoNLL
2009 shared task (Hajiˇc et al. [2009]).
The following sections will describe the architec-
ture of the Daisy system, present state-of-the-art per-
formance on the CoNLL 2009 shared task, and ex-
</bodyText>
<note confidence="0.9319335">
Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 279–288,
Denver, Colorado, June 4–5, 2015.
</note>
<bodyText confidence="0.997463">
plore the utility of features derived from dependency
parses, including a version of the traditional SRL
syntactic path feature.
</bodyText>
<sectionHeader confidence="0.996474" genericHeader="method">
2 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999815461538462">
The CoNLL 2009 shared task consists of identify-
ing the sense and semantic arguments for each given
argument-bearing token (predicate). In addition to
the words themselves, the training data provides the
part of speech, syntactic head, and syntactic depen-
dency relation to the head for each word in the sen-
tence. Table 1 shows an example sentence and its
representation in the dataset. The PDEPREL and
PHEAD features are the head word and dependency
relation predicted automatically by a dependency
parser. In the example sentence, there are two pred-
icates identified for labeling: announce, and close.
The system should output two arguments for an-
nounce: results:A1 (Object), and after:AM-TEMP
(Temporal Marker). Similarly, market:A1 should be
output for the predicate close. In addition to role
identification, the word sense for each predicate is
output, in the example, the expected sense for an-
nounce is 01, and for close is 02.
The training, validation, and evaluation datasets
are annotated sentences from the Wall Street Jour-
nal. An additional out of domain dataset mostly
from the Brown corpus was also supplied. A com-
prehensive F1 score was generated for both role
labels and sense predictions using the provided
eval09.pl perl script.
</bodyText>
<sectionHeader confidence="0.991978" genericHeader="method">
3 Semantic Role Labeling System
</sectionHeader>
<bodyText confidence="0.998452909090909">
The general block diagrams for the Daisy SRL sys-
tem are shown in Figure 1. The input to the system
is a list of words wz from w1 to wn, a list of pred-
icate positions, and dependency parse tree informa-
tion for the sentence. We treat role labeling and the
sense identification as two separate tasks. For each
predicate in a given sentence, the Role Subsystem
outputs the list of predicted role tags for all words
(SRLi), and the Sense Subsystem outputs the sense
tag of the predicate. The system is composed of five
major components:
</bodyText>
<listItem confidence="0.999882">
• Word Preprocessing and Word Derived Feature
Convolution (Figure 2).
• Predicate Position Feature Convolution.
</listItem>
<figure confidence="0.999452882352941">
Sentence Words
w�
Dependency Tree
Word POS
Word
Derived
A B
Predicate Position Word
and Path Position C
Viterbi Decoder
D
Role Neural Network and
Feature Vector Convolution
Sentence SRL Tags
SRL;
(a) Role Subsystem
(b) Sense Subsystem
</figure>
<figureCaption confidence="0.999573">
Figure 1: SRL Role and Sense Block Diagrams
</figureCaption>
<listItem confidence="0.999008333333333">
• Word Position Feature Convolution.
• Neural Network and Viterbi (Figure 4).
• Predicate Sense Neural Network (Figure 5).
</listItem>
<subsectionHeader confidence="0.774491">
3.1 Word Derived Feature Convolution Section
</subsectionHeader>
<bodyText confidence="0.997205318181818">
The Word Derived Features and Convolution sec-
tion, shown in Figure 2, is sourced by five features
which are derived on a word by word basis.
The upper portion of Figure 2 depicts the process
of looking up features from the words and parse tree
information. The numeric information from the fea-
tures for each word is concatenated together to form
one long feature vector, shown in the diagram as a
multi-shaded set of rectangles. Three words of fea-
ture information (the word and its two neighbors)
from the Word Derived Feature Vector are multi-
plied by the the weights and bias of Θ4 and stored
in the Convolved Word Derived Feature Vector, for
each word in the sentence. For the default convo-
lution width of 300, this results in a long vector of
300 · n, where n is the number of words in the sen-
tence.
Each feature lookup table contains an entry for
PADDING. In order to allow the window to extend
beyond boundaries of the sentence for early and
late words the Feature Vector is padded with the
PADDING value from each lookup table. If a fea-
</bodyText>
<figure confidence="0.99214253125">
Sentence Words
Wi
Dependency Tree
Word POS
Feature Vector Convolution
Word
Derived
Predicate Position
and Path
A B
Predicate Lemma
Predicate Senses
Sense Neural Network
E
280
ID FORM LEMMA PLEMMA POS PPOS FEAT PFEAT HEAD PHEAD DEPREL PDEPREL
1 The the the DT DT 2 2 NMOD NMOD
2 results result result NNS NNS 3 3 SBJ SBJ
3 were be be VBD VBD 0 0 ROOT ROOT
4 announced announce announce VBN VBN 3 3 VC VC
5 after after after IN IN 4 4 TMP TMP
6 the the the DT DT 8 8 NMOD NMOD
7 stock stock stock NN NN 8 8 NMOD NMOD
8 market market market NN NN 9 9 SBJ SBJ
9 closed close close VBD VBD 5 5 SUB SUB
10 . . . . . 3 3 P P
FILLPRED PRED A[announce] A[close]
A1
Y announce.01
AM-TMP
A1
Y close.02
</figure>
<tableCaption confidence="0.973656">
Table 1: CoNLL format SRL Dependency Parse Input Test Sentence Example
</tableCaption>
<figureCaption confidence="0.988964666666667">
Figure 2: Word Preprocessing, Word Derived Features,
and Word Derived Feature Convolution. A in figures
1(a) and 1(b).
</figureCaption>
<bodyText confidence="0.9932104375">
ture is in the table, the associated vector is output,
otherwise the vector corresponding to the special to-
ken UNKNOWN is output. The PADDING and UN-
KNOWN vectors are trained during supervised train-
ing.
To train the word representations from scratch, all
except the 0.63% least common unique words from
the training set are added to the lookup table. The
remaining words are therefore trained as the UN-
KNOWN word, which can then be used to represent
any word encountered outside the trained word list.
For other features, the representation for the most
probable token is used as the UNKNOWN represen-
tation.
The five types of word-derived features tested for
the SRL Dependency Parse tagger are:
</bodyText>
<listItem confidence="0.9999306">
• Word Embeddings
• Capitalization
• POS tag of word
• Dependency Relation
• POS tag of head
</listItem>
<subsectionHeader confidence="0.868512">
3.1.1 Word Pre-processing
</subsectionHeader>
<bodyText confidence="0.999976">
The input data provided for the CoNLL 2009
task has already gone through some initial tokeniz-
ing. This prevents tokenization differences of differ-
ent systems from influencing the results, which are
meant to allow comparison of the SRL tagging ar-
chitecture itself. The Daisy pre-processor does not
split hyphenated input words, so each input word
will result in a single pre-processed word. Numeric
values are collapsed to the single common 0 token,
and words are lower-cased to create a word repre-
sentation lookup word.
</bodyText>
<subsectionHeader confidence="0.966268">
3.1.2 Word Embeddings
</subsectionHeader>
<bodyText confidence="0.999939466666667">
Words are transformed to numeric representations
using a lookup table. Like all other feature lookup
tables in the system, the word representation vec-
tors can be initialized to small random values to start
with, and then trained using the supervised training
algorithm.
A method of training the word representations
from untagged databases has been very successfully
applied to create a starting set of vectors that can
be used to initialize a network, which is then fine-
tuned with supervised training to execute a specific
task. By ”pre-training” these word representations
using large amounts of untagged text, very infor-
mative word relationships can be inexpensively ex-
tracted, and later used as the starting point for task
</bodyText>
<figure confidence="0.999377742857143">
Dependency
Tree
Sentence
Words
Word POS
Wi
word pre-
processing
and index
calculation
h
h
⇥ward.
⇥cap.
⇥dep
⇥POS
⇥POSh
130K
450
47
47
5
50
5
5
5
5
pad W1 W2 ... W. pad
⇥4 = W4, b4
per word
300
195 = 3 &apos; (50+5+5+5)
Convolved word feature vector
300 &apos; n
300 &apos; n
</figure>
<page confidence="0.990649">
281
</page>
<bodyText confidence="0.999783875">
specific application learning, see for example Hin-
ton et al. [2006], Bengio et al. [2007] and Weston
et al. [2012].
The word representations, or embeddings, used as
input to the Daisy SRL System for the experiments
described here were generated by Collobert et al.
[2011] and were created using a pairwise ranking
approach (Schapire and Singer [1998]).
</bodyText>
<subsectionHeader confidence="0.907151">
3.1.3 Capitalization
</subsectionHeader>
<bodyText confidence="0.99994425">
Prior to lower casing, each word is checked for all
capitals, initial capital, any capital, or no capitals,
and this criteria is used to lookup a vector (default
length 5) from the caps table.
</bodyText>
<subsectionHeader confidence="0.638541">
3.1.4 Predicted Dependency Relation
</subsectionHeader>
<bodyText confidence="0.999911">
The PDEPREL column from the training data,
shown in table 1.
</bodyText>
<subsubsectionHeader confidence="0.478064">
3.1.5 Predicted POS tag of word and of head
</subsubsectionHeader>
<bodyText confidence="0.9995906">
The Predicted Part-of-speech tag is provided in
PPOS column of the training data. The head part
of speech tag is found by following the PHEAD col-
umn and extracting the PPOS column. (see Table
1).
</bodyText>
<subsectionHeader confidence="0.9995025">
3.2 Predicate Position and Path Feature
Convolution Section
</subsectionHeader>
<bodyText confidence="0.999183333333333">
Predicate Position and optional Path features are ex-
tracted on a per word basis and convolved, once per
predicate (the outer loop of two).
</bodyText>
<subsubsectionHeader confidence="0.514392">
3.2.1 Predicate Position Feature
</subsubsectionHeader>
<bodyText confidence="0.9999785">
The position of each word relative to the predicate
being evaluated is represented by 25 vectors, based
on distances of -12 to +12, and distances outside this
range are saturated.
</bodyText>
<subsectionHeader confidence="0.796691">
3.2.2 Dependency Path Feature
</subsectionHeader>
<bodyText confidence="0.9834986875">
Information about the path from each word to a
given predicate is maintained in a lookup table and is
provided in the Predicate Position Convolution sec-
tion as a per word feature.
Generic Path: The sequence of up and down
transitions to traverse the tree from a word to a given
predicate is referred to here as the Generic Path. The
dependency parse trees for each of the two predi-
cates from the example training sentence shown in
Table 1 are diagrammed in Figure 3. The Generic
uud ud d o u uuuu uuuu uuu uu ud
DT NNS VBD VBN IN DT NN NN VBD
The results were announced after the stock market closed
uuddd uddd ddd dd d uu uu
DT NNS VBD VBN IN DT NN
The results were announced after the stock
</bodyText>
<figureCaption confidence="0.997043">
Figure 3: Dependency Parse and Generic Paths
</figureCaption>
<bodyText confidence="0.997805444444445">
Path for each word is shown in the diagram, above
the part of speech tag for the word.
Labeled Path: These are path descriptions which
include both the arc direction (Generic Path) and
the dependency relation of the arc within the depen-
dency tree. After several rounds of experimentation,
we chose to include paths which occur at least five
times in the training data, which resulted in about
77K unique path types.
</bodyText>
<subsectionHeader confidence="0.998034">
3.3 Word Position Feature Convolution Section
</subsectionHeader>
<bodyText confidence="0.999839625">
The position of every word with respect to the spe-
cific word being evaluated is extracted once per
word, per predicate (the inner loop of two). In a sim-
ilar fashion to the predicate position feature, the po-
sition of each word relative to the word being evalu-
ated is represented by 25 vectors, based on distances
of -12 to +12, and distances outside this range are
saturated.
</bodyText>
<subsectionHeader confidence="0.981177">
3.4 Role Neural Network and Viterbi
</subsectionHeader>
<bodyText confidence="0.998491090909091">
Figure 4 shows the process of combining the Con-
volved Feature Vectors, processing with a neural
network, and finding the most likely role sequence
with a Viterbi detector. Both the Role and Sense
neural networks are constructed with a single non-
linear layer followed by an output layer. The param-
eters for each layer are referred to here as Θ, which
includes a matrix of weights, W, and a vector of bias
terms b. Each layer’s output, prior to the activation
function, can be calculated from the previous layer’s
activation output and parameters.
</bodyText>
<figure confidence="0.992162263157894">
announce.01 SUB
root
NMOD SBJ
VC TMP
NMOD
NMOD SBJ
close.02
root
NMOD SBJ
SUB
NMOD
VC TMP
NMOD SBJ
A1
AM-TMP
A1
u o uddd
NN VBD
market closed
</figure>
<page confidence="0.941279">
282
</page>
<equation confidence="0.9970115">
flΘ = Wl−1fl−1
Θ + bl−1 (1)
</equation>
<bodyText confidence="0.99734">
The tanh function is used as the nonlinear activa-
tion function.
</bodyText>
<figureCaption confidence="0.991048">
Figure 4: SRL Neural Network and Viterbi. D in figure
1(a).
</figureCaption>
<bodyText confidence="0.9999002">
network, and finding the most likely sense for a
given predicate. The neural network parameters for
the sense subsystem are managed with a lookup ta-
ble holding parameters for each lemma in the train-
ing set that is mapped to multiple senses.
</bodyText>
<figureCaption confidence="0.9954775">
Figure 5: SRL Neural Network for Predicate Sense. E
in figure1(b).
</figureCaption>
<figure confidence="0.99816672972973">
o o ol o
• o
• o o
• o o o
300 * n
Max
300
tanb
500
⇥aut
per word, per verb
186
SRL Tag Scores
(and 6a-t,-t)
⇥t = Wt,bi
n (number of words) Sentence
SRL Tags
SRL;
SRL
Tag Scores
Sequence Detector
(Viterbi)
⇥initial
⇥transition
o o o) o
• o
• o o
300 * n
Max
300
⇥sns = Wsns, bsns
300
⇥sns out
20
Predicate Sense
(one set per Lemma)
tonh
</figure>
<bodyText confidence="0.99415125">
The three Convolved Feature Vectors (dia-
grammed separately) are summed, then the maxi-
mum for each index within each group of 300 is
determined. This results in a 300 element vector
which will be the input to the Neural Network. A
single layer neural network followed by a single out-
put layer is used to create a ”score” for each possi-
ble role ”tag”, for the word and predicate being an-
alyzed. After running all words through the system
for a single predicate, a matrix of SRL roles scores
of size tags × words is created, which will be used
as the input to the Viterbi sequence decoder.
</bodyText>
<subsectionHeader confidence="0.984571">
3.5 Sequence Decoder (Viterbi)
</subsectionHeader>
<bodyText confidence="0.999926857142857">
The Viterbi decoding algorithm input is a matrix
which consists of a vector of SRL role scores for
each word. The algorithm is initialized with a
learned set of weights per tag, and computes the log-
likelihood of transitioning from each state to the next
by applying a learned set of weights from the transi-
tion matrix.
</bodyText>
<subsectionHeader confidence="0.966383">
3.6 Predicate Sense Neural Network
</subsectionHeader>
<bodyText confidence="0.990382">
Figure 5 shows the process of combining the Con-
volved Feature Vectors, processing with a neural
</bodyText>
<sectionHeader confidence="0.806979" genericHeader="method">
4 Sense Labeler Training and Forward
Model Creation
</sectionHeader>
<bodyText confidence="0.999854142857143">
Both the Role and Sense subsystems are trained us-
ing stochastic gradient descent. A forward pass is
first run on the system, during which the indices of
the maximum values of the sum of the convolutions
layers (word-derived and predicate) are saved.
Back-propagation of the Sense Neural Network is
based on minimizing a log-likelihood objective:
</bodyText>
<equation confidence="0.8371395">
log p(y|x, Θ) = f[x, Θ]y − log( � e(f[x,Θ],)) (2)
j
</equation>
<bodyText confidence="0.9996891">
The two Sense and Role subsystems have the
same convolution structures (See figures 1(a) and
1(b)). Experiments run using a common structure
for both tasks resulted in about 0.5% worse perfor-
mance, so the the systems were kept independent.
A separate neural network was trained for each
lemma found in the training data set, and the param-
eters for each network were stored in a lookup table.
This results in very large memory requirements dur-
ing training, especially since Adagrad (Duchi et al.
</bodyText>
<page confidence="0.963559">
283
</page>
<bodyText confidence="0.926934177419355">
[2011] was used to decrease training time. To min- 6 Results
imize memory requirements and training time, the 6.1 Benchmark
sense for lemmas which always train to the same
sense in the training data are stored in a dictionary.
During forward processing, when a lemma is en-
countered that was not trained (and therefore is not
in the parameter lookup table), the sense from the
dictionary is output. If the lemma never occurred
during training, it won’t be in the dictionary, and the
most commonly occurring sense of ”01” is output by
default.
5 Role Labeler Training and Forward
Model Creation
During a forward pass, the activation layers and
maxIndices are saved and reused during training.
5.1 Cost Calculation
The Viterbi parameters for initial score and tran-
sition probabilities are trained using the Sentence
Level Log-Likelihood (SLL) cost function.
This cost function is based on Sentence Level
Likelihood and is similar to equation 2, except the
reference path score must be normalized by using
the sum of the exponential of all path scores (the
sum of unnormalized probabilities for all possible
paths, instead of for all possible tags). A recursive
method, developed in Rabiner [1989] and specified
in Collobert et al. [2011], provides an important and
efficient means of computing the sum of the expo-
nential of all path scores. An intermediate vector, 6,
is calculated, which will contain the unnormalized
log probability that any path through the trellis will
pass through a particular state k for the particular
word t. The 6 vectors have a dimension of N, the
number of tags, and they are re-used for the gradient
calculation during back-propagation.
5.2 Back-propagation
The recursion described in Collobert et al. [2011] is
used to calculate Viterbi delta terms and gradients.
The error is then back-propagated through the sys-
tem in reverse, ending with the feature lookup ta-
bles. This is done for each word, for each predi-
cate, requiring two nested loops for training a full
sentence. The loop structure makes for long train-
ing times, roughly three days on a 2015 compute-
optimized AWS core.
284
The best ConLL 2009, English, SRL F1 score,
is labeled Nugues, and the system is described in
Bj¨orkelund et al. [2009]. To the best of our knowl-
edge, the current state of the art for this dataset is
represented by these results, and we therefore use
them as a benchmark (See section 7). To generate
these benchmark results, 20 features were used for
argument identification, including the Dependency
Relation Path, and Part of Speech of Dependency
Relation Path. A reranker was then run on the out-
put of multiple system outputs.
Table 2 compares the benchmark with a complete
Daisy system using a labeled path, with a cutoff of
5, and two separate systems for sense and role la-
bels. F1 scores are 0.41% higher for the WSJ Eval
dataset, and 2.59% higher for the out of domain
</bodyText>
<table confidence="0.862277">
(OOD) Brown dataset.
System Description WSJ F1 Brown F1
Benchmark 85.63% 73.31%
(CoNLL2009)
Daisy 86.04% 75.90%
Table 2: SRL Dependency Parse Test F1
6.2 Metrics
In all experiments, we strictly followed the standard
</table>
<bodyText confidence="0.995442352941177">
evaluation procedure of the CoNLL 2009 challenge.
A simple validation procedure using the specified
validation set was used to choose system hyper pa-
rameters, and the provided eval09.pl perl script was
used to generate all system F1 scores. The system
F1 score is the harmonic mean of precision and re-
call for both role and sense labels. Since we treated
the predicate sense disambiguation and the predicate
role assignment tasks as independent, it is interest-
ing to view the performance of the two tasks sep-
arately. The predicate sense task requires a label
for each given predicate, so a per predicate accuracy
was calculated (SenseAcc). Similarly we generated
a role label F1 score (RoleF1) that is independent of
the sense labels. These subsystem performance met-
rics were also calculated on the CoNLL 2009 bench-
mark results for comparison.
</bodyText>
<subsectionHeader confidence="0.998247">
6.3 Incremental Experiments and Results
</subsectionHeader>
<bodyText confidence="0.9883535">
Feature abbreviations used in the descriptions are
shown in Table 3.
</bodyText>
<table confidence="0.785540833333334">
Abbrev. Feature Description
W words, initialized randomly prior to
training
C capitalization
P Part of Speech
HP Part of Speech of head word
DR Dependency Relation
GP Generic path
TW words, initialized with pre-trained
word embeddings prior to training
LP5 Labeled paths that occur at least five
times in the training data.
</table>
<tableCaption confidence="0.99304">
Table 3: Feature Abbreviations
</tableCaption>
<figure confidence="0.549643">
WSJ (Eval) Incremental Feature Progression
</figure>
<figureCaption confidence="0.9908725">
Figure 6: Scatter Plot of Dev F1 vs. Eval F1 for Various
Feature Configurations (See also Table 4)
</figureCaption>
<bodyText confidence="0.998172833333333">
Incremental experiments were run to explore
the benefits of adding increasingly more complex
dependency-based features to the system.
We began with a basic configuration of only
words (randomly initialized) and capitalization
(W,C), Following this, a simple per-token part of
speech was added (W,C,P). Information from the
dependency parser is then added in two steps, first
the head word part of speech and dependency re-
lation (W,C,P,HP,DR), and next the generic path
(W,C,P,HP,DR,GP). The word representations were
then seeded with the pre-trained embeddings de-
</bodyText>
<figure confidence="0.9864583125">
OOD (Brown) Incremental Feature Progression
78.0%
77.0%
76.0%
75.0%
74.0%
(73.31%)
73.0%
Daisy(W,C)
Daisy(W,C,P)
Daisy(W,C,P,HP,DR)
Daisy(W,C,P,HP,DR,GP)
Daisy(TW,C,P,HP,DR,GP)
Daisy(TW,C,P,HP,DR,LP5)
81.0% 82.0% 83.0% 84.0% 85.0% 86.0%
Development systemF1
</figure>
<figureCaption confidence="0.994406">
Figure 7: Dev F1 vs. Brown (OOD) F1 for Various Fea-
ture Configurations (See also Table 5)
</figureCaption>
<bodyText confidence="0.97081678125">
scribed in section 3.1.2 (TW,C,P,HP,DR,GP). Fi-
nally, the labeled path was used instead of the
generic path, still seeding the words with pre-trained
embeddings (TW,C,P,HP,DR,LP5).
For each system configuration, 12 role subsys-
tems and 8 sense subsystems were trained and
tested, using the WSJ development F1 score dur-
ing training to determine the best model parameter
state. After model generation, the WSJ development
scores for different systems don’t correlate well with
the WSJ eval or Brown scores. For example, mod-
els with high development scores don’t necessarily
correspond to best scoring models for the WSJ or
Brown data tests.
The CoNLL2009 results used as benchmarks
were given as single data points so statistics are not
available.
Figure 7 shows the relationship between the de-
velopment and Evaluation F1 scores, as well as the
general performance improvement as features were
added.
Tables 4 and 5 show the statistical performance of
the system with WSJ and Brown test data.
For the WSJ (evaluation) dataset, the role subsys-
tem F1 improves much more dramatically than the
sense subsystem as POS (+1.52%) and dependency
parser information (+1.68%) is added. The mean
System F1 score is -0.25% under the benchmark
without the pre-trained word embeddings. Adding
the embeddings boosts performance such that even
the lowest scoring systems beat the benchmark, and
the mean F1 score is about 0.41% higher.
</bodyText>
<figure confidence="0.982779078947368">
86.0%
(85.63%)
81.0%
81.0% 82.0% 83.0% 84.0% 85.0% 86.0%
Development systemF1
87.0%
WSJ Eval systemF1
85.0%
84.0%
83.0%
82.0%
Daisy(W,C)
Daisy(W,C,P)
Daisy(W,C,P,HP,DR)
Daisy(W,C,P,HP,DR,GP)
Daisy(TW,C,P,HP,DR,GP)
Daisy(TW,C,P,HP,DR,LP5)
Out of Domain systemF1
72.0%
71.0%
70.0%
69.0%
285
SystemF1
Min Mean (A) Max
RoleF1
Mean (A)
SenseAcc
Mean (A)
System Description
SystemF1
Min Mean (A) Max
RoleF1
Mean (A)
SenseAcc
Mean (A)
System Description
65.49
</figure>
<equation confidence="0.89090325">
67.87 (+0.09)
70.80 (+2.59)
85.08
85.71 (+0.48)
87.40 (+0.69)
67.38 (+1.89)
67.78 (+0.40)
68.21 (+0.34)
70.62 (-0.18)
85.23 (-0.43)
86.04 (+0.33)
86.72 (+0.68)
85.66 (+0.59)
71.70
73.48 (+0.17)
75.90 (+0.09)
73.13 (+1.43)
73.31 (+0.18)
73.83 (+0.36)
75.80 (+1.97)
</equation>
<figure confidence="0.953448947368421">
70.50
72.45
72.47
73.17
74.85
75.19
72.43
73.78
74.43
74.23
76.46
76.93
Daisy(W,C)
Daisy(W,C,P)
Benchmark (CoNLL2009)
Daisy(W,C,P,HP,DR)
Daisy(W,C,P,HP,DR,GP)
Daisy(TW,C,P,HP,DR,GP)
Daisy(TW,C,P,HP,DR,LP5)
</figure>
<tableCaption confidence="0.9998625">
Table 5: Performance on Brown Dataset (OOD) for Various System Configurations
Table 4: Performance on WSJ Eval Dataset for Various System Configurations
</tableCaption>
<figure confidence="0.97547135">
Daisy(W,C)
Daisy(W,C,P)
Daisy(W,C,P,HP,DR)
Daisy(W,C,P,HP,DR,GP)
Benchmark (CoNLL2009)
Daisy(TW,C,P,HP,DR,GP)
Daisy(TW,C,P,HP,DR,LP5)
82.86
83.83
84.46
85.05
85.64
85.77
83.03
84.79 (+0.67)
85.63 (+0.25)
86.04 (+0.13)
83.24
84.43
85.10
85.78
86.17
86.31
77.47
79.92 (+0.92)
81.00 (+0.31)
81.53 (+0.13)
94.92
95.29 (+0.13)
95.59 (+0.13)
95.77 (+0.11)
84.12 (+1.09)
85.38 (+0.58)
85.92 (+0.29)
79.00 (+1.52)
80.69 (+0.76)
81.40 (+0.40)
95.15 (+0.23)
95.46 (+0.17)
95.66 (+0.07)
</figure>
<bodyText confidence="0.999305272727273">
For the Brown (OOD) dataset, the role subsys-
tem F1 improves significantly with POS and depen-
dency parse information (+2.72%) while the sense
subsystem benefits less (0.96%). The role subsys-
tem dramatically improves when pre-trained words
are added (2.59%), due in large part to a better abil-
ity to handle unseen words. The mean System F1
scores are higher than the benchmark as soon as de-
pendency parser information is supplied, and the F1
is significantly better for the fully populated system
(+2.59%).
</bodyText>
<sectionHeader confidence="0.999959" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999855032258064">
The same Semantic Role Labeling system used to
generate the results used as our benchmark was
later tested using improved dependency parsing in
Bj¨orkelund et al. [2010]. Woodsend and Lapata
[2014] explore text rewriting and compare results
with the benchmark, which they accept as the cur-
rent state-of-the-art.
Kanerva and Ginter [2014] use the CoNLL 2009
data as a benchmark for investigating the use of Fin-
ish and English word vector relationships, and the
relationships of word vectors as they relate to se-
mantic roles.
In Socher et al. [2013], the authors present a Re-
cursive Neural Tensor Network (RNTN) which uses
word vectors as a primary input and which is used to
recursively generate a phrase tree structure for each
sentence. The resulting structures are then further
used to generate fine-grained sentiment analysis es-
timates.
Convolutional neural networks which include
character level structures have been effectively used
for sentiment analysis by dos Santos and Gatti
[2014]. The characters are not pre-trained, and syn-
tactic trees are not used as input to the network.
In Luong et al. [2013], words are broken down
into morphemes as the input to a recursive neural
network to capture morphological compositionality
with the goal of improving the vector representa-
tions of scarce words.
The characteristics and semantic expressive
power of various word embedding collections are in-
</bodyText>
<note confidence="0.739513">
vestigated by Mikolov et al. [2013] and Chen et al. 36. Association for Computational Linguistics,
[2013]. 2010.
</note>
<sectionHeader confidence="0.922739" genericHeader="conclusions">
8 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99998196">
We have presented a dependency-based semantic
role labeler using neural networks, inspired by Col-
lobert et al. [2011] and others to reduce the use
of hand-crafted features and make use of unsuper-
vised techniques. Experimental evaluations show
that our architecture improves the state of the art
performance for this task significantly, for both in
domain and out of domain test data. A key element
of the system’s performance is based on the use of
features derived from syntactic dependency parses.
The use of a dependency-based path feature, in par-
ticular, provides a significant boost in performance
over simpler feature sets.
Promising future directions suggested by these re-
sults include whether proxies for the dependency-
based features can be derived from a similar archi-
tecture without the direct need for a full dependency
analysis, thus eliminating the pre-processing parser
cost. Another future direction involves the pred-
icate disambiguation system. Although this sense
disambiguation task is part of the CoNLL 2009 SRL
evaluation, it is more properly a word sense disam-
biguation problem. A more thorough investigation
of sense disambiguation in the context of an SRL
system is warranted.
</bodyText>
<sectionHeader confidence="0.99924" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999720948275862">
Yoshua Bengio, Pascal Lamblin, Dan Popovici, and
Hugo Larochelle. Greedy layer-wise training of
deep networks. Advances in neural information
processing systems, 19:153, 2007.
Anders Bj¨orkelund, Love Hafdell, and Pierre
Nugues. Multilingual semantic role labeling.
In Proceedings of the Thirteenth Conference
on Computational Natural Language Learning:
Shared Task, pages 43–48. Association for Com-
putational Linguistics, 2009.
Anders Bj¨orkelund, Bernd Bohnet, Love Hafdell,
and Pierre Nugues. A high-performance syntactic
and semantic dependency parser. In Proceedings
of the 23rd International Conference on Compu-
tational Linguistics: Demonstrations, pages 33–
Xavier Carreras and Lluis M`arquez. Introduction
to the conll-2004 shared task: Semantic role la-
beling. In Proceedings of the Eighth Confer-
ence on Computational Natural Language Learn-
ing, CoNLL 2004, Held in cooperation with HLT-
NAACL 2004, Boston, Massachusetts, USA, May
6-7, 2004, pages 89–97, 2004.
Xavier Carreras and Lluis M`arquez. Introduction
to the conll-2005 shared task: Semantic role la-
beling. In Proceedings of the Ninth Conference
on Computational Natural Language Learning,
pages 152–164. Association for Computational
Linguistics, 2005.
Yanqing Chen, Bryan Perozzi, Rami Al-Rfou, and
Steven Skiena. The expressive power of word em-
beddings. arXiv preprint arXiv:1301.3226, 2013.
Ronan Collobert, Jason Weston, L´eon Bottou,
Michael Karlen, Koray Kavukcuoglu, and Pavel
Kuksa. Natural language processing (almost)
from scratch. The Journal of Machine Learning
Research, 12:2493–2537, 2011.
Cıcero Nogueira dos Santos and Maıra Gatti. Deep
convolutional neural networks for sentiment anal-
ysis of short texts. In Proceedings of the 25th
International Conference on Computational Lin-
guistics (COLING), Dublin, Ireland, 2014.
John Duchi, Elad Hazan, and Yoram Singer. Adap-
tive subgradient methods for online learning and
stochastic optimization. The Journal of Machine
Learning Research, 12:2121–2159, 2011.
Daniel Gildea and Daniel Jurafsky. Automatic label-
ing of semantic roles. Computational Linguistics,
28(3):245–288, 2002.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Marti,
Lluis M`arquez, Adam Meyers, Joakim Nivre, Se-
bastian Pad´o, Jan ˇStˇep´anek, et al. The conll-2009
shared task: Syntactic and semantic dependen-
cies in multiple languages. In Proceedings of the
Thirteenth Conference on Computational Natural
Language Learning: Shared Task, pages 1–18.
Association for Computational Linguistics, 2009.
Geoffrey Hinton, Simon Osindero, and Yee-Whye
</reference>
<page confidence="0.960856">
287
</page>
<reference confidence="0.999557442307692">
Teh. A fast learning algorithm for deep be-
lief nets. Neural computation, 18(7):1527–1554,
2006.
Jenna Kanerva and Filip Ginter. Post-hoc manip-
ulations of vector space models with application
to semantic role labeling. In Proceedings of the
2nd Workshop on Continuous Vector Space Mod-
els and their Compositionality (CVSC)@ EACL,
pages 1–10, 2014.
Minh-Thang Luong, Richard Socher, and Christo-
pher D Manning. Better word representations
with recursive neural networks for morphology.
CoNLL-2013, 104, 2013.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
Linguistic regularities in continuous space word
representations. In Proceedings of NAACL-HLT,
pages 746–751, 2013.
Martha Palmer, Paul Kingsbury, and Daniel Gildea.
The proposition bank: An annotated corpus of se-
mantic roles. Computational Linguistics, 31(1):
71–106, 2005.
Lawrence Rabiner. A tutorial on hidden markov
models and selected applications in speech recog-
nition. Proceedings of the IEEE, 77(2):257–286,
1989.
William W Cohen Robert E Schapire and Yoram
Singer. Learning to order things. In Advances
in Neural Information Processing Systems 10:
Proceedings of the 1997 Conference, volume 10,
page 451. MIT Press, 1998.
Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. Recursive deep models
for semantic compositionality over a sentiment
treebank. In Proceedings of the conference on
empirical methods in natural language process-
ing (EMNLP), volume 1631, page 1642. Citeseer,
2013.
Alex Waibel, Toshiyuki Hanazawa, Geoffrey Hin-
ton, Kiyohiro Shikano, and Kevin J Lang.
Phoneme recognition using time-delay neural net-
works. Acoustics, Speech and Signal Processing,
IEEE Transactions on, 37(3):328–339, 1989.
Jason Weston, Fr´ed´eric Ratle, Hossein Mobahi,
and Ronan Collobert. Deep learning via semi-
supervised embedding. In Neural Networks:
Tricks of the Trade, pages 639–655. Springer,
2012.
Kristian Woodsend and Mirella Lapata. Text rewrit-
ing improves semantic role labeling. Journal of
Artificial Intelligence Research, pages 133–164,
2014.
</reference>
<page confidence="0.997125">
288
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.450521">
<title confidence="0.9984655">Dependency-Based Semantic Role Labeling Convolutional Neural Networks</title>
<author confidence="0.999955">William R Foland</author>
<email confidence="0.510955">OKRobotGo,</email>
<address confidence="0.9829985">5345 Dunraven Golden, Co, 80403,</address>
<email confidence="0.999768">bill.foland@okrobotgo.com</email>
<author confidence="0.99991">H James</author>
<affiliation confidence="0.999927333333333">Department of Computer Science Institute of Cognitive University of</affiliation>
<address confidence="0.962855">Boulder, CO</address>
<email confidence="0.979512">James.Martin@colorado.edu</email>
<abstract confidence="0.999091076923077">We describe a semantic role labeler with stateof-the-art performance and low computational requirements, which uses convolutional and time-domain neural networks. The system is designed to work with features derived from a dependency parser output. Various system options and architectural details are discussed. Incremental experiments were run to explore the benefits of adding increasingly more complex dependency-based features to the system; results are presented for both in-domain and out-of-domain datasets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>Pascal Lamblin</author>
<author>Dan Popovici</author>
<author>Hugo Larochelle</author>
</authors>
<title>Greedy layer-wise training of deep networks. Advances in neural information processing systems,</title>
<date>2007</date>
<pages>19--153</pages>
<marker>Bengio, Lamblin, Popovici, Larochelle, 2007</marker>
<rawString>Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. Greedy layer-wise training of deep networks. Advances in neural information processing systems, 19:153, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>Multilingual semantic role labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>43--48</pages>
<marker>Bj¨orkelund, Hafdell, Nugues, 2009</marker>
<rawString>Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues. Multilingual semantic role labeling. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, pages 43–48. Association for Computational Linguistics, 2009.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Bernd Bohnet</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>A high-performance syntactic and semantic dependency parser.</title>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations,</booktitle>
<pages>33</pages>
<marker>Bj¨orkelund, Bohnet, Hafdell, Nugues, </marker>
<rawString>Anders Bj¨orkelund, Bernd Bohnet, Love Hafdell, and Pierre Nugues. A high-performance syntactic and semantic dependency parser. In Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations, pages 33–</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis M`arquez</author>
</authors>
<title>Introduction to the conll-2004 shared task: Semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of the Eighth Conference on Computational Natural Language Learning, CoNLL 2004, Held in cooperation with HLTNAACL 2004,</booktitle>
<pages>89--97</pages>
<location>Boston, Massachusetts, USA,</location>
<marker>Carreras, M`arquez, 2004</marker>
<rawString>Xavier Carreras and Lluis M`arquez. Introduction to the conll-2004 shared task: Semantic role labeling. In Proceedings of the Eighth Conference on Computational Natural Language Learning, CoNLL 2004, Held in cooperation with HLTNAACL 2004, Boston, Massachusetts, USA, May 6-7, 2004, pages 89–97, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis M`arquez</author>
</authors>
<title>Introduction to the conll-2005 shared task: Semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning,</booktitle>
<pages>152--164</pages>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>Xavier Carreras and Lluis M`arquez. Introduction to the conll-2005 shared task: Semantic role labeling. In Proceedings of the Ninth Conference on Computational Natural Language Learning, pages 152–164. Association for Computational Linguistics, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanqing Chen</author>
<author>Bryan Perozzi</author>
<author>Rami Al-Rfou</author>
<author>Steven Skiena</author>
</authors>
<title>The expressive power of word embeddings. arXiv preprint arXiv:1301.3226,</title>
<date>2013</date>
<marker>Chen, Perozzi, Al-Rfou, Skiena, 2013</marker>
<rawString>Yanqing Chen, Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. The expressive power of word embeddings. arXiv preprint arXiv:1301.3226, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>12</volume>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. Natural language processing (almost) from scratch. The Journal of Machine Learning Research, 12:2493–2537, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cıcero Nogueira dos Santos</author>
<author>Maıra Gatti</author>
</authors>
<title>Deep convolutional neural networks for sentiment analysis of short texts.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics (COLING),</booktitle>
<location>Dublin, Ireland,</location>
<marker>Santos, Gatti, 2014</marker>
<rawString>Cıcero Nogueira dos Santos and Maıra Gatti. Deep convolutional neural networks for sentiment analysis of short texts. In Proceedings of the 25th International Conference on Computational Linguistics (COLING), Dublin, Ireland, 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Duchi</author>
<author>Elad Hazan</author>
<author>Yoram Singer</author>
</authors>
<title>Adaptive subgradient methods for online learning and stochastic optimization.</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>12</volume>
<marker>Duchi, Hazan, Singer, 2011</marker>
<rawString>John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, 12:2121–2159, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288, 2002.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Marti</author>
<author>Lluis M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Stˇep´anek, et al. The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date></date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>1--18</pages>
<publisher>Association</publisher>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Marti, M`arquez, Meyers, Nivre, Pad´o, </marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Marti, Lluis M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, et al. The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, pages 1–18. Association for Computational Linguistics, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Hinton</author>
<author>Simon Osindero</author>
<author>Yee-Whye Teh</author>
</authors>
<title>A fast learning algorithm for deep belief nets.</title>
<date>2006</date>
<journal>Neural computation,</journal>
<volume>18</volume>
<issue>7</issue>
<marker>Hinton, Osindero, Teh, 2006</marker>
<rawString>Geoffrey Hinton, Simon Osindero, and Yee-Whye Teh. A fast learning algorithm for deep belief nets. Neural computation, 18(7):1527–1554, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenna Kanerva</author>
<author>Filip Ginter</author>
</authors>
<title>Post-hoc manipulations of vector space models with application to semantic role labeling.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC)@ EACL,</booktitle>
<pages>1--10</pages>
<marker>Kanerva, Ginter, 2014</marker>
<rawString>Jenna Kanerva and Filip Ginter. Post-hoc manipulations of vector space models with application to semantic role labeling. In Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC)@ EACL, pages 1–10, 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minh-Thang Luong</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>Better word representations with recursive neural networks for morphology.</title>
<date>2013</date>
<journal>CoNLL-2013,</journal>
<volume>104</volume>
<marker>Luong, Socher, Manning, 2013</marker>
<rawString>Minh-Thang Luong, Richard Socher, and Christopher D Manning. Better word representations with recursive neural networks for morphology. CoNLL-2013, 104, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Wen-tau Yih</author>
<author>Geoffrey Zweig</author>
</authors>
<title>Linguistic regularities in continuous space word representations.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>746--751</pages>
<marker>Mikolov, Yih, Zweig, 2013</marker>
<rawString>Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. Linguistic regularities in continuous space word representations. In Proceedings of NAACL-HLT, pages 746–751, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Paul Kingsbury</author>
<author>Daniel Gildea</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<pages>71--106</pages>
<marker>Palmer, Kingsbury, Gildea, 2005</marker>
<rawString>Martha Palmer, Paul Kingsbury, and Daniel Gildea. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1): 71–106, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Rabiner</author>
</authors>
<title>A tutorial on hidden markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<volume>77</volume>
<issue>2</issue>
<marker>Rabiner, 1989</marker>
<rawString>Lawrence Rabiner. A tutorial on hidden markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2):257–286, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>Learning to order things.</title>
<date>1998</date>
<booktitle>In Advances in Neural Information Processing Systems 10: Proceedings of the 1997 Conference,</booktitle>
<volume>10</volume>
<pages>451</pages>
<publisher>MIT Press,</publisher>
<marker>Schapire, Singer, 1998</marker>
<rawString>William W Cohen Robert E Schapire and Yoram Singer. Learning to order things. In Advances in Neural Information Processing Systems 10: Proceedings of the 1997 Conference, volume 10, page 451. MIT Press, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Y Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank.</title>
<date>2013</date>
<booktitle>In Proceedings of the conference on empirical methods in natural language processing (EMNLP),</booktitle>
<volume>1631</volume>
<pages>1642</pages>
<location>Citeseer,</location>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the conference on empirical methods in natural language processing (EMNLP), volume 1631, page 1642. Citeseer, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Waibel</author>
<author>Toshiyuki Hanazawa</author>
<author>Geoffrey Hinton</author>
<author>Kiyohiro Shikano</author>
<author>Kevin J Lang</author>
</authors>
<title>Phoneme recognition using time-delay neural networks.</title>
<date>1989</date>
<journal>Acoustics, Speech and Signal Processing, IEEE Transactions on,</journal>
<volume>37</volume>
<issue>3</issue>
<marker>Waibel, Hanazawa, Hinton, Shikano, Lang, 1989</marker>
<rawString>Alex Waibel, Toshiyuki Hanazawa, Geoffrey Hinton, Kiyohiro Shikano, and Kevin J Lang. Phoneme recognition using time-delay neural networks. Acoustics, Speech and Signal Processing, IEEE Transactions on, 37(3):328–339, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Weston</author>
</authors>
<title>Fr´ed´eric Ratle, Hossein Mobahi, and Ronan Collobert. Deep learning via semisupervised embedding.</title>
<date>2012</date>
<booktitle>In Neural Networks: Tricks of the Trade,</booktitle>
<pages>639--655</pages>
<publisher>Springer,</publisher>
<marker>Weston, 2012</marker>
<rawString>Jason Weston, Fr´ed´eric Ratle, Hossein Mobahi, and Ronan Collobert. Deep learning via semisupervised embedding. In Neural Networks: Tricks of the Trade, pages 639–655. Springer, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristian Woodsend</author>
<author>Mirella Lapata</author>
</authors>
<title>Text rewriting improves semantic role labeling.</title>
<date>2014</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>133--164</pages>
<marker>Woodsend, Lapata, 2014</marker>
<rawString>Kristian Woodsend and Mirella Lapata. Text rewriting improves semantic role labeling. Journal of Artificial Intelligence Research, pages 133–164, 2014.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>