<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.095428">
<title confidence="0.6194395">
Invited Talk
Knowing a word(sense) by its company
</title>
<author confidence="0.755626">
Martha Palmer
</author>
<affiliation confidence="0.878942">
Department of Linguistics
University of Colorado
Boulder, Colorado, USA
</affiliation>
<email confidence="0.994238">
Martha.Palmer@colorado.edu
</email>
<sectionHeader confidence="0.988512" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999721875">
Supervised word sense disambiguation requires training corpora that
have been tagged with word senses, and these word senses typically come
from a pre-existing sense inventory. Space limitations imposed by dictio-
nary publishers have biased the field towards lists of discrete senses for an
individual lexeme. This approach does not capture information about relat-
edness of individual senses. How important is this information to knowing
which sense distinctions are critical for particular types of NLP applications?
How much does sense relatedness affect automatic word sense disambigua-
tion performance? Recent psycholinguistic evidence seems to indicate that
closely related word senses may be represented in the mental lexicon much
like a single sense, whereas distantly related senses may be represented more
like discrete entities. These results suggest that, for the purposes of WSD,
closely related word senses can be clustered together into a more general
sense with little meaning loss. This talk will describe the relatedness of verb
senses and its impact on NLP applications and WSD components as well as
recent psycholinguistic research results.
</bodyText>
<page confidence="0.819113">
2
</page>
<bodyText confidence="0.4767285">
Proceedings of the 8th International Conference on Computational Semantics, page 2,
Tilburg, January 2009. cï¿½2009 International Conference on Computational Semantics
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.539090">
<title confidence="0.981872">Invited Talk Knowing a word(sense) by its company</title>
<author confidence="0.998963">Martha</author>
<affiliation confidence="0.999683">Department of University of</affiliation>
<address confidence="0.666796">Boulder, Colorado,</address>
<email confidence="0.999354">Martha.Palmer@colorado.edu</email>
<abstract confidence="0.988559736842105">Supervised word sense disambiguation requires training corpora that have been tagged with word senses, and these word senses typically come from a pre-existing sense inventory. Space limitations imposed by dictionary publishers have biased the field towards lists of discrete senses for an individual lexeme. This approach does not capture information about relatedness of individual senses. How important is this information to knowing which sense distinctions are critical for particular types of NLP applications? How much does sense relatedness affect automatic word sense disambiguation performance? Recent psycholinguistic evidence seems to indicate that closely related word senses may be represented in the mental lexicon much like a single sense, whereas distantly related senses may be represented more like discrete entities. These results suggest that, for the purposes of WSD, closely related word senses can be clustered together into a more general sense with little meaning loss. This talk will describe the relatedness of verb senses and its impact on NLP applications and WSD components as well as recent psycholinguistic research results. 2 of the 8th International Conference on Computational page 2,</abstract>
<intro confidence="0.902367">January 2009. International Conference on Computational Semantics</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>