<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001341">
<title confidence="0.9959305">
Feeding OWL: Extracting and Representing
the Content of Pathology Reports
</title>
<author confidence="0.996081">
David Schlangen and Manfred Stede
</author>
<affiliation confidence="0.9979425">
Department of Linguistics
University of Potsdam
</affiliation>
<address confidence="0.943713">
P.O. Box 601553
D-14415 Potsdam, Germany
</address>
<email confidence="0.998745">
{das|stede}@ling.uni-potsdam.de
</email>
<author confidence="0.980645">
Elena Paslaru Bontas
</author>
<affiliation confidence="0.997396">
Institute for Computer Science
</affiliation>
<address confidence="0.771895333333333">
Freie Universit¨at Berlin
Takustr.9
D-14195 Berlin, Germany
</address>
<email confidence="0.996948">
paslaru@inf.fu-berlin.de
</email>
<sectionHeader confidence="0.997361" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999468727272727">
This paper reports on an ongoing project that com-
bines NLP with semantic web technologies to sup-
port a content-based storage and retrieval of medical
pathology reports. We describe the NLP component
of the project (a robust parser) and the background
knowledge component (a domain ontology repre-
sented in OWL), and how they work together during
extraction of domain specific information from nat-
ural language reports. The system provides a good
example of how NLP techniques can be used to pop-
ulate the Semantic Web.
</bodyText>
<sectionHeader confidence="0.99939" genericHeader="categories and subject descriptors">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999938766666666">
Clinical pathologists work with and produce vast
amounts of data: images of biological samples and
written reports of their findings. Digital Pathology
is the cover term for a number of efforts to intro-
duce digital processing into the work-flow of the
pathologist. While previous projects have focussed
on storage and distribution of images and reports
(e.g. in Tele-Pathology-projects, (Slodowksa et al.,
2002; Demichellis et al., 2002)), the work reported
here explores the use of Natural Language Process-
ing (NLP) and Semantic Web technologies to sup-
port a content-based storage and retrieval of case
reports. The system that we are building, LUPUS
(Lung Pathology System), consists of an NLP com-
ponent (a robust parser) and a Semantic Web com-
ponent (a domain ontology represented in OWL, and
a Description Logic reasoner), which work closely
together, with the domain ontology guiding the in-
formation extraction process.
The remainder of the paper is organised as fol-
lows. In the next section we describe the context
and intended application of the system, we discuss
linguistic properties of the input material we are
working with, and we give some details of the back-
ground ontology we are using. In Section 3 we go
into the technical details of the process of extracting
information from natural language reports and rep-
resenting it in an OWL representation, after which
we describe a preliminary evaluation. We close with
discussing related work, and planned future work.
</bodyText>
<sectionHeader confidence="0.997026" genericHeader="general terms">
2 Digital Pathology
</sectionHeader>
<subsectionHeader confidence="0.823703">
2.1 The Application
</subsectionHeader>
<bodyText confidence="0.998464054545455">
LUPUS is intended to support the pathologist in two
ways. First, it is used to semantically annotate a
large archive of case reports, turning them into a
valuable resource for diagnosis and teaching. The
system uses the case reports produced by experts
(the pathologists) to extract information about the
accompanying images (of the tissue samples), and
thus produces semantic annotation both for the re-
port and for those images.
This corpus of cases can then be searched in a
fast, content-based manner to retrieve case reports
(the textual reports together with the images of tis-
sue samples) that might be relevant for a case the
pathologist is working on. The search is content-
based in that it can make use of semantic relation-
ships between search concepts and those occuring
in the text. We also encode in rules knowledge
about certain diagnostics tasks, so that for example
queries asking for ‘differential diagnosis’ (“show
me cases of diagnoses which are known to be easily
confusable with the diagnosis I am thinking of for
the present case”) can be processed—tasks which
normally require consultation of textbooks. These
search capabilities are useful both during diagnosis
and for teaching, where it makes interesting exam-
ples immediately available to students.
Another use case is quality control during input
of new reports. Using our system, such reports can
be entered in a purpose-built editor (which com-
bines digital microscopy facilities (Saeger et al.,
2003) with our semantic annotator / search engine),
where they are analysed on-the-fly, and potential
inconsistencies with respect to the background do-
main ontology are spotted.1 During the develop-
ment phase of the system, we are using this feature
1Naturally, to gain acceptance by working pathologists, this
process has to be “minimally invasive”.
to detect where the coverage of the system must be
extended.
The present paper focuses on the process of ex-
tracting the relevant information from natural lan-
guage reports and representing it in a semantic
web-ready format as a precondition for performing
searches; we leave the description of the search and
retrieval functions to another paper. To give an idea
of the kind of data we are dealing with, and of the in-
tended target representation, Figure 1 shows an ex-
ample report (at the top of the figure) and the repre-
sentation of its content computed by our system (at
the bottom).2 We discuss the input format in the fol-
lowing subsection, and the target representation to-
gether with the domain knowledge available to us in
Subsection 2.3; discussion of the intermediate for-
mat that is also shown in the figure is deferred until
Section 3.
</bodyText>
<subsectionHeader confidence="0.997591">
2.2 Pathology Reports
</subsectionHeader>
<bodyText confidence="0.999980074074074">
During the development phase of the system, we
are using a corpus of 90 randomly selected case re-
ports (ca. 13,000 words; i.e. the average length of
the reports is ca. 140 words, with a standard devia-
tion of 12 words) for testing and grammar develop-
ment. Linguistically, these reports are quite distin-
guished: they are written in a “telegram”-style, with
verbs largely being absent (a rough examination of
the corpus showed that only about every 43rd token
is a verb, compared to every 11th in a comparable
corpus of German newspaper). Also, the vocabulary
is rather controlled, with very little variation—this
of course is good news for automatically process-
ing such input. On the discourse level we also find
a strict structure, with a fixed number of semanti-
cally grouped sections. E.g., information about the
diagnosis made will normally be found in the sec-
tion “Kritischer Bericht” (critical report), and the in-
formation in the “Makroskopie” and “Mikroskopie”
sections (macroscopy and microscopy, respectively)
will be about the same parts of the sample, but on
different levels of granularity.
The last peculiarity we note is the relatively high
frequency of compound nouns. These are especially
important for our task, since technical concepts in
German tend to be expressed by such compound
nouns (rather than by noun groups). While some
</bodyText>
<footnote confidence="0.7731855">
2What is shown in the figure is actually already the result
of a preprocessing step; the cases as stored in the database con-
tain patient data as well, and are formatted to comply with the
HL7 standard for medical data (The HL7 Consortium, 2003).
Moreover, the italicisation in the input representation and the
numbers in square brackets are added here for ease of refer-
ence and are not part of the actual representations maintained
by the system.
</footnote>
<bodyText confidence="0.992868">
of those will denote individual concepts and hence
will be recorded in the domain lexicon, others must
be analysed and their semantics must be composed
out of that of their parts (see below).
</bodyText>
<subsectionHeader confidence="0.99959">
2.3 Lung Pathology Knowledge in OWL
</subsectionHeader>
<bodyText confidence="0.992691">
The result of processing such reports with LUPUS
is a representation of (relevant aspects of) their con-
tent. This representation has the form of instances
of concepts and assertions of properties that are de-
fined in an ontology, which constitutes the domain
knowledge of the system (at the moment focussed
on pathologies of the lung). This ontology is spec-
ified in OWL DL (W3C WebOnt WG, 2004), a ver-
sion of OWL with a formal semantics and a complete
and decidable calculus. Consequently, the content
of the texts is represented in OWD DL as well, and
so the knowledge base of the system consists of the
ontology and the instances.
The ontology we use is compiled out of sev-
eral medical sources (such as UMLS (The UMLS
Consortium, 2003) and SNOMED (SNOMED Inter-
national, 2004)), but since these sources often were
not intended for machine reasoning (i.e., are not
necessarily consistent, and use rather loosely de-
fined relations), considerable effort has been spent
(and is being spent) on cleaning them up.3 At the
moment, about 1,000 domain-level concepts and
ca. 160 upper-level concepts have been identified,
which are connected by about 50 core relation types.
To our knowledge, this makes it one of the biggest
OWL-ontologies currently in use.
Besides representing concepts relevant to our do-
main, the ontology also lists properties that in-
stances of these concepts can have. These proper-
ties are represented as two-place relations; to give
an example, the property “green” attributed to an
entity x will in our system not be represented as
“green(x)”, but rather as something like “colour(x,
green)”. This allows us to enforce consistency
checks, by demanding that for each second-order
predicate (colour, malignity, consistency, etc.) ap-
propriate for a given concept only one value is
chosen.4 This choice of representation has conse-
quences for the way the semantics of adjectives is
represented in the lexicon, as we will see presently.
3There are several current research projects with a similar
aim of extracting stricter ontologies from sources like those
mentioned above (see e.g. (Schulz and Hahn, 2001; Burgun and
Bodenreider, 2001)), and this is by no means a trivial task. The
present paper, however, focuses on a different (but of course in-
terdependent) problem, namely that of extracting information
such that it can be represented in the way described here.
4Technically, these constraints are realised by functional
data-properties relating entities to enumerated data types.
An example report (with translation):
</bodyText>
<figure confidence="0.990757894736842">
&lt;befund&gt;
&lt;makroskopie&gt;
Stanzzylinder von 15 mm L¨ange und 1 mm Durchmesser. [1]
&lt;/makroskopie&gt;
&lt;mikroskopie&gt;
Stanzbiopsat [2] eingenommen durch Infiltrate einer soliden malignen epithelialen Neoplasie. [3]
Die Tumorzellen mit distinkten Zellgrenzen [4], zum Teil interzellul¨ar Spaltr¨aume [5], zwischen
denen stellenweise kleine Br¨ucken [6] nachweisbar sind. Das Zytoplasma leicht basophil,
z.T. auch breit und eosinphil, [7] die Zellkerne hochgradigpolymorph mit zum Teil
multiplen basophilen Nukleolen. [8] Deutliche desmoplastische Stromareaktion. [9]
&lt;/mikroskopie&gt;
&lt;kritischer bericht&gt;
Stanzbiopsat aus einer Manifestation eines soliden Karzinoms [10]
(klinisch rechte Lunge apikal).
&lt;/kritischer bericht&gt;
&lt;kommentar&gt;
...
&lt;/kommentar&gt;
&lt;/befund&gt;
</figure>
<bodyText confidence="0.715827833333333">
( Biopsy cylinder of 15 mm length and 1 mm diameter.  |Biobsy infiltrated by a solid
malignant epithelial neoplasia. The tumor cells with distinct cell borders, partially intercel-
lular spatia, between which sporadically small bridges are verifiable. The cytoplasm lightly
basophil, in part also broad and eosinphile, the nuclei highly polymorphic, partially with
multiple basophile nucleoli. Distinct desmoplastic stroma reaction.  |Biopsy cylinder from
a manifestation of a solid carcinoma (clinical right lung apical). )
</bodyText>
<figure confidence="0.914809916666667">
4
Intermediate Representation (excerpt):
[2] unspec det(x2) ∧ punch biopsat(x2) [3] unspec plur det(x3) ∧ infiltrate(x3, x4) ∧
indef det(x4) ∧ solid(x4) ∧ malign(x4) ∧ epithelial(x4) ∧ neoplasia(x4)
[4] def plur det(x5)∧tumorcell(x5)∧with rel(x5,x6)∧unspec plur det(x6)∧distinctive(x6)∧
cell borders(x6) [7] spec det(x9) ∧ low degree(d1) ∧ basophile(x9, d1) ∧ partially(d2) ∧
broad(x9, d2) ∧ eosinphile(x9, d2) ∧ cytoplasm(x9)
[8] def plur det(x10) ∧ high degree(d3) ∧ polymorpheous(x10, d3) ∧ nucleus(x10) ∧
with rel(x10, x11)∧unspec plur det(x11)∧partially(d4)∧multiple(x11, d4)∧basophile(x11)∧
nucleoli(x11)
4
Target Representation (excerpt):
&lt;Malignant Epithelial Neoplasm C0432650 rdf:ID=”neoplasia x4”&gt;
&lt;solidity rdf:datatype=”http://www.w3.org/2001/XMLSchema#float”&gt;1.0&lt;/solidity&gt;
&lt;/Malignant Epithelial Neoplasm&gt;
&lt;Cell Border C0032743 rdf:ID=”cell border x61”/&gt;
&lt;Tumor cells C0431085 rdf:ID=”tumor cell x52”&gt;
&lt;hasBoundary rdf:resource=”file:...#cell boundary x61”/&gt;
&lt;/Tumor cells C0431085&gt;
&lt;cytoplasm C0326583 rdf:ID=”cytoplasm1”&gt;
&lt;broad rdf:datatype=”http://www.w3.org/2001/XMLSchema#float”&gt;1.0&lt;/broad&gt;
&lt;eosinphil rdf:datatype=”http://www.w3.org/2001/XMLSchema#float”&gt;1.0&lt;/eosinphil&gt;
&lt;basophil rdf:datatype=”http://www.w3.org/2001/XMLSchema#float”&gt;0.5&lt;/basophil&gt;
&lt;/cytoplasm&gt;
</figure>
<figureCaption confidence="0.999993">
Figure 1: Input, Intermediate and Target Representation
Figure 2: Flowchart
</figureCaption>
<bodyText confidence="0.999863">
Using OWL DL as a representation format for
natural language content means certain limitations
have to be accepted. Being a fragment of FOL, it
is not expressive enough to represent certain finer
semantic details, as will be discussed below. How-
ever, the advantage of using an emerging standard
for delivering and sharing information outweighs
these drawbacks.
</bodyText>
<sectionHeader confidence="0.995183" genericHeader="keywords">
3 Implementation
</sectionHeader>
<subsectionHeader confidence="0.986238">
3.1 Overview
</subsectionHeader>
<bodyText confidence="0.99990175">
As mentioned above, most of the sentences in our
corpus do not contain a finite verb; i.e., according to
standard rules of grammar they are elliptical. While
a theoretically motivated approach should strive to
resolve this ellipsis contextually (for example as de-
scribed in (Schlangen, 2003)), in view of the in-
tended application and for reasons of robustness we
have decided to focus only on extracting informa-
tion about the entities introduced in the reports—
that is, on recognising nominal phrases, leaving
aside the question of how verbal meanings are to
be resolved.
Our strategy is to combine a “shallow” prepro-
cessing stage (based on finite-state methods and sta-
tistical approaches) with a symbolic phase, in which
the semantics of the NPs is assembled.5 A require-
ment for the processing is that it must be robust, in
two ways: it must be able to deal with unknown
tokens (i.e., “out of vocabulary” items) and with un-
known structure (i.e., “out of grammar” construc-
tions), degrading gracefully and not just failing.
Figure 2 shows a flow chart of the system; the
individual modules are described in the following
sections.
</bodyText>
<footnote confidence="0.67825">
5This strategy sits somewhere between Information Extrac-
tion, where also only certain phrases are extracted, for which,
however, normally no compositional semantics is computed,
and “full” parsing, where such a semantics is computed only if
the whole input can be parsed.
</footnote>
<subsectionHeader confidence="0.998383">
3.2 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999940060606061">
The first step, tokenising and sentence splitting, is
fairly standard, and so we skip over it here. The
second step, morpho-syntactic analysis, is more in-
teresting. It is performed by an independently de-
veloped module called TAGH, a huge finite-state
machine that makes use of a German word-stem
lexicon (containing about 90,000 entries for nouns,
17,000 for verbs, 20,000 adjectives and adverbs,
and about 1,500 closed class word forms). The
transducer is implemented in C++ and has a very
high throughput (about 20,000 words per second
on modern machines). The coverage achieved on
a balanced corpus of German is around 96% (Ju-
rish, 2003), for our domain the lexicon had to be
extended with some domain specific vocabulary.
To give an example of the results of the analysis,
Figure 3 shows (excerpts of) the output for Sentence
2 of the example report. Note that this is already the
POS-disambiguated output, and we only show one
analysis for each token. In most cases, we will get
several analyses for each token at this stage, differ-
ing with respect to their part of speech tag or other
morphological features (e.g., case) that are not fully
determined by their form. (The average is 5.7 anal-
yses per token.) Note also that the actual output of
the module is in an XML format (as indeed are all
intermediate representations); only for readability is
it presented here as a table.
Another useful feature of TAGH is that it pro-
vides derivational information about compound
nouns. To give an example, (1) shows one analysis
of the noun “Untersuchungsergebnis” (examination
result).
</bodyText>
<equation confidence="0.2570825">
(1) Untersuchungsergebnis
untersuch(V)∼ung(n)/s#Ergebnis
</equation>
<bodyText confidence="0.99946675">
As this shows, the analysis gives us information
about the stems of the compounds; this can be used
to guide the computation of the meaning of the com-
plex noun. However, this meaning is not fully com-
</bodyText>
<table confidence="0.9949643">
Token Type Analysis
Stanzbiopsat Stanzbiopsat [NN Gender=neut Number=sg Case=nom]
eingenommen ein|nehm∼en [VVPP2]
durch durch [APPR]
Infiltrate Infiltrat [NN Gender=neut Number=pl Case=acc]
einer eine [ARTINDEF Number=sg Case=gen Gender=fem]
soliden solid [ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed]
malignen maligne [ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed]
epithelialen epithelial [ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed]
Neoplasie Neoplasie [NN Gender=fem Number=sg Case=*]
</table>
<figureCaption confidence="0.997432">
Figure 3: Result of Morphological Analysis / POS-tag disambiguation for Sentence 2
</figureCaption>
<bodyText confidence="0.999963794117647">
positional, as the nature of the relation between the
compounds is underspecified. We represent this by
use of an underspecified relation rel that holds be-
tween the compounds, and which has to be specified
later on in the processing chain.
The output of this module is then fed into a statis-
tically trained POS-disambiguator, which finds the
most likely path through the lattice of morpholog-
ical analyses (Jurish, 2003) (with an accuracy of
96%). In cases where morphology failed to provide
an analysis, the syntagmatically most likely POS tag
is chosen. At the end of this stage all analyses for
a given token agree on its part of speech; however,
other features (number, person, case, etc.) might
still not be disambiguated.
At the next stage, certain sequences of tokens
are grouped together, namely multi-word expres-
sion that denote a single concept in our ontology
(e.g., “anthrakotische Lymphknoten” denotes a sin-
gle concept, and hence is marked as one token of
type NN at this step), and certain other phrases (e.g.
specifications of spatial dimensions) which can be
recognised easily but would require very specialised
grammar rules later on.6
Then, the domain-specific lexicon is accessed,
which maps “concept names” (nouns, or phrases as
recognised in the previous step) to the concept IDs
used in the ontology.7 Tokens for which there is no
entry in that lexicon, and which are hence deemed
‘irrelevant’ for the domain, are assigned a ‘dummy’
semantics appropriate for their part of speech, so
that they do not confuse the later parsing stage.
(More details about this kind of robustness will be
given shortly.)
</bodyText>
<footnote confidence="0.9980075">
6See for example (Grover et al., 2002) for a discussion of
the utility of a named entitiy recognition preprocessing stage
for robust symbolic parsing.
7Note that this lexicon is one single resource out of which
also the domain specfic additions to the morphology-lexicon
and the list of multi-word expressions are compiled.
</footnote>
<subsectionHeader confidence="0.998283">
3.3 Chunk Parsing
</subsectionHeader>
<bodyText confidence="0.999768931034483">
Next, the analyses of the tokens are transformed
into a feature structure format, and are passed to
the parsing component.8 The output of this stage
is an intermediate semantic representation of (as-
pects of) the content (of which the notation shown
in 1 is a variant). This format is akin to traditional
logical forms and still has to be mapped into OWL;
we decided on this strategy because such a format
is closer to surface structure and hence easier to
build compositionally (see discussion below in Sec-
tion 3.5). Also note that the semantics is “flat”, and
does not represent scope of quantifiers (which only
very rarely occur in our data, and cannot be repre-
sented OWL in any case).
To get an idea of the feature geometry used by the
grammar see Figure 4; this figure also shows the se-
mantic representations generated at this stage (in a
different notation than in Figure fig:reps). Note the
‘simulation’ of typing of feature structures, and the
representation of properties via second order prop-
erties as discussed above. Chunk parsing is per-
formed by a chart parser running a grammar that is
loosely inspired by HPSG (Pollard and Sag, 1994).9
The grammar contains context-free rules for fairly
complex NPs (allowing arguments of Ns, modifi-
cation by PPs, and coordination). When extracting
chunks, the strategy followed by the system is to al-
ways extract the largest non-overlapping chunks.10
An example might help to illustrate the robust-
</bodyText>
<footnote confidence="0.774668153846154">
8Up until here, all steps are performed in one go for the
whole document. The subsequent steps, on the other hand, are
performed incrementally for each sentence. This allows the
system to remove ambiguity when it occurs, rather than having
to maintain and later filter out different analyses.
9The parser is implemented in PROLOG, and based on the
simple algorithm given in (Gazdar and Mellish, 1989). It also
uses code by Michael Covington for dealing with feature struc-
tures in PROLOG, which is described in (Covington, 1994).
10That strategy will prefer lenght of individual chunks over
coverage of input, for example when there is one big chunk and
two overlapping smaller chunks at each side of that chunk, that
however together span more input.
</footnote>
<figure confidence="0.993923878378379">
⎡
CAT np ⎡ ⎤
⎢ CASE nom
⎢ HEAD NUM sg
AGR ⎣PER dr
GEN neu
COMP nil
⎡ *�RELTYPE det ��RELTYPE ent �
TYPE
⎢ RESTR TYPE unspec stanzbiopsat
⎣ARG x3 INST x3
INDEX x3
⎤ ⎤ ⎡
⎦⎥ ⎥ ⎢
⎥ ⎢
⎥ ⎢SYN
⎥ ⎢
⎥ ⎢
⎥ ⎢
⎥ ⎢
⎥ ⎢
⎥ ⎢
⎥ ⎢
⎥ ⎢
⎥ ⎢
⎦ ⎢ ⎢ ⎢SEM
⎢ ⎢ ⎢ ⎢ ⎣
⎤
⎦⎥⎥⎥
⎡
⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣
SYN
SEM
⎤
⎥⎥⎥⎥⎥⎥⎥
⎤⎥⎥⎥
+⎥⎥
⎥⎥
⎥⎥
⎥⎥
⎥⎥
⎥⎥
⎥⎥
⎦⎦⎥⎥
⎡
CAT np ⎡ ⎤
⎢ CASE acc
⎢ �NUM pl �
⎢ ⎣ ⎦
HEAD
AGR
⎣ PER dr
GEN fem
COMP nil
⎡ �RELTYPE det �&amp;quot;RELTYPE ent #�RELTYPE det �&amp;quot;RELTYPE prop
TYPE infiltrat TYPE consistency
⎢ TYPE unspec plur TYPE
* indef
ARG ARG
⎢ x2 x2
ARG
⎢ x1 ARG x2
INST x1 VALUE solid
⎢ RESTR
⎢ &amp;quot;RELTYPE prop #&amp;quot;RELTYPE prop #�RELTYPE ent �
⎢ TYPE malignity TYPE position
TYPE
⎢ neoplasia
ARG
⎣ x2 ARG x2 INST x2
VALUE malign VALUE epithelial
INDEX x1
⎤
⎦⎥⎥⎥
</figure>
<figureCaption confidence="0.999993">
Figure 4: The chunks extracted from Sentence 2
</figureCaption>
<bodyText confidence="0.999849666666667">
ness of the system. (2) shows a full syntactic analy-
sis of our example sentence. Our system only recog-
nises the chunks indicated by the brackets printed
in bold typeface: since it can’t recognise the pred-
icative use of the verb here, it is satisfied with just
building parses for the NPs it does recognise. (The
round brackets around the analysis of the first word
indicate that this parse is strictly speaking not cor-
rect if the full structure is respected.)
</bodyText>
<listItem confidence="0.825888">
(2) [NP ([NP) [NOM Stanzbiopsat] (]), [ADJP [VVPP2
eingenommen] [PP [P durch] [NP Infiltrate einer
soliden malignen epithelialen Neoplasie.]]]]”
</listItem>
<bodyText confidence="0.999867875">
This is an example of the system’s tolerance to un-
known structure; (3) shows a (constructed) exam-
ple of an NP where the structure is covered by the
grammar, but there are ‘unknown’ (or rather, irrele-
vant) lexical items. As described above, we assign
a ‘dummy semantics’ (here, a property that is true
of all entities) to words that are irrelevant to the do-
main, and so parsing can proceed.
</bodyText>
<listItem confidence="0.8138855">
(3) Solid, hardly detectable tumor cells. →
solid(x) ∧ true(x) ∧ tumor cell(x)
</listItem>
<bodyText confidence="0.970361652173913">
A few last remarks about the grammar. First, as
shown in Figure 4, NPs without determiner intro-
duce an underspecified relation unspec det, and in-
formation about definiteness and number of deter-
miners is represented. This means that all infor-
mation to do discourse processing (bridging of def-
inites to antecedents) is there; we plan to exploit
such information in later incarnations of the sys-
tem. Secondly, it can of course occur that there is
more than one analysis spanning the same input;
i.e., we can have syntactic ambiguity. This will be
dealt with in the transformation component, where
domain knowledge is used to only let through “plau-
sible” analyses.
Lastly, prepositions are another source for under-
specification. For instance, given as input the string
(4), the parser will compute a semantics where an
underspecified with rel connects the two entities
tumor and alveolar; this relation will be specified
in the next step, using domain knowledge, to a rela-
tion contains.
(4) Ein Tumor mit freien Alveolaren.
A tumor with free alveolars.
</bodyText>
<subsectionHeader confidence="0.9953725">
3.4 Resolution of Underspecification using
Ontologies
</subsectionHeader>
<bodyText confidence="0.999991875">
As described in the previous sections, the output of
the parser (and of the morphological analysis) might
still contain underspecified relations. These are re-
solved in the module described in this section. This
module sends a query to a reasoning component that
can perform inference over the ontology, asking for
possible relations that can hold between (instances
of) entities. For example (4) above, this will return
the answer contains, since the ontology specifies
that ‘alveolars” are parts of tumours (via a chain of
is-a-relations linking tumours with cells, and cells
with alveolars). In a similar way the underspecifi-
cation of compound nouns is resolved. This process
proceeds recursively, “inside-out”, since compound
nouns can of course be embedded in NPs that are
parts of PPs, and so on.
</bodyText>
<subsectionHeader confidence="0.990216">
3.5 Mapping LF to OWL
</subsectionHeader>
<bodyText confidence="0.997526321428571">
In the final step, the logical forms produced by the
parser and specified by the previous module are
transformed into OWL-compliant representations.
This process is fairly straightforward, as should be
clear from comparing the intermediate representa-
tion in Figure 1 with the target representation: a)
unique identifiers for the instances of concepts are
generated; b) in cases of plural entities (“three sam-
ples” → card(x, 3) ∧ sample(x)), several separate
instances are created; and c) appropriateness condi-
tions for properties are applied: if a property is not
defined for a certain type of entity, the analysis is
rejected.
This translation step also handles potential syn-
tactic ambiguity, since it can filter out analyses
if they specify inconsistent information. Note
also that certain information, e.g. about second
order properties, might be lost, due to the re-
stricted expressivity of OWL. E.g., an expres-
sion like “highly polymorpheous” in Figure 1 ei-
ther has to be converted into a representation like
polymorphism : high, or the modification is lost
(polymorpheous(x)).
This ends our brief description of the system. We
now discuss a preliminary evaluation of the mod-
ules, related work, and further extensions of the sys-
tem we are currently working on or which we are
planning.
</bodyText>
<sectionHeader confidence="0.99964" genericHeader="introduction">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9999796">
At the moment, we have only evaluated the mod-
ules individually, and—since the system is still un-
der developement—this evaluation only provides a
snapshot of the current state of developement. A
full-scale evaluation of the whole system in its ap-
plication context is planned as soon as the modules
are finalised; plans for this are discussed below.
The coverage of the morphology module and the
POS-tagger have already been reported above, so we
concentrate here on the chunk-parser. To evaluate
this module, we have manually annotated the NPs
in a randomly selected test set of 20 reports (ca.
2,800 words; we found about 500 NPs). The re-
ports were then morphologically analysed and POS-
filtered, and the results were manually checked and
corrected, to ensure that the input was optimal and
really only the performance of the chunker was eval-
uated. We then computed precision and recall based
on two different matching criteria: for exact match-
ing, where only exact congruence of chunks counts,
a precision of 48% and a recall of 63% was com-
puted; the numbers improve when partial matches,
i.e. smaller chunks within the target chunk, receive
partial credit (by a factor of .25), resulting in a (re-
laxed) precision of 61% and a (relaxed) recall of
80%. This difference can be explained by the fact
that some of the more complex NP-constructions
(with quite complex modifications) in our data are
not yet covered by the grammar, and only their con-
stituent NPs are recognised.
Note that this evaluation just takes into account
the boundaries of the chunks and not the correct-
ness of the computed semantic representations. For
a full-scale evaluation, we will manually annotate
these NPs with semantic representations, and we
will use this to compute precision and recall also
with respect to semantics, and ultimately with re-
spect to sample search queries. This annotation,
however, is very resource-intensive, and so will only
be done once the modules have been finalised.
</bodyText>
<sectionHeader confidence="0.999983" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99996609375">
Acquisition of information from texts especially
from the medical domain is a lively research area.
Among the many projects in that field, we share
some of our central concerns with the medSyn-
diKAte system (Hahn et al., 2002): robust text anal-
ysis of medical reports; a background knowledge
base for guiding the analysis and storing the text’s
content; emphasis on handling co-reference phe-
nomena. What distinguishes LUPUS from medSyn-
diKAte, though, is foremost the parsing scheme: the
language used in the reports analysed by Hahn et al.
is much closer to ‘natural’ language in that it con-
tains sentences with tensed verbs. Accordingly, they
use a variant of dependency parsing which is driven
by verb information. As described in Section 2.2
above, this is not an option for us, given the style of
our input texts, and hence our data renders a bottom-
up chart parsing approach much more promising.
Besides this difference, the work in medSynDiKAte
predates the emergence of XML/web ontology stan-
dards and thus uses an earlier description logic
knowledge representation language; we are hoping
that by using a standard we will be able to allow
even future semantic web technologies to work with
our data.
As for the robust analysis side, (Grover et al.,
2002), also use a similar preprocessing pipeline
in combination with parsing. However, they also
focus on more “natural” input texts (Medline ab-
stracts), and they use statistical rather than sym-
bolic/ontology based methods for computing the
meaning of compound nouns.
</bodyText>
<sectionHeader confidence="0.995782" genericHeader="conclusions">
6 Summary and Further Work
</sectionHeader>
<bodyText confidence="0.999977666666667">
We have described LUPUS, an NLP system that
makes use of a domain ontology to guide extraction
of information about entities from medical texts,
and represents this information as instances of con-
cepts from that ontology. Besides its direct use for
content-based search on these texts, the fact that the
system relies entirely on emerging semantic web
standards will make the resulting annotated infor-
mation usable for all kinds of agents working with
such data.
As a next step, we plan to add discourse process-
ing to the pipeline (see e.g. (Hahn et al., 1998) for
a discussion why such a step is required even for
such relatively simple texts). As mentioned above,
the prerequisite information (about definite articles,
for example) is already there; we plan to use the
available domain knowledge to guide the search for
antecedents for bridging. As a more technical im-
provement we are investigating ways of making the
architecture less pipeline-y, and to integrate domain
reasoning in computing edges in the chart. Lastly,
we are also working on a large-scale evaluation of
the system, by manually annotating reports to com-
pute precision and recall.
</bodyText>
<sectionHeader confidence="0.999024" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999538">
We thank the anonymous reviewers for their helpful
comments. Thanks are also due to Thomas Hanneforth
and Bryan Jurish for their help with integrating their
modules, and to our student assistant Sebastian Maar for
doing much of the actual coding.
</bodyText>
<sectionHeader confidence="0.999408" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999709">
Anita Burgun and Oliver Bodenreider. 2001. Mapping
the UMLS semantic network into general ontologies.
In Proceedings of the AMIA Symposium.
Michael A. Covington. 1994. GULP 3.1: An extension
of prolog for unification-based grammar. Technical
Report AI-1994-06, University of Georgia.
F. Demichellis, V. Della Mea, S. Forti, P. Dalla Palma,
and C.A. Beltrami. 2002. Digital storage of glass
slide for quality assurance in histopathology and cy-
topathology. Telemedicine and Telecare, 8(3):138–
142.
Gerald Gazdar and Chris Mellish. 1989. Natural Lan-
guage Processing in PROLOG. Addison-Wesley,
Wokingham, England.
Claire Grover, Ewan Klein, Mirella Lapata, and
Alex Lascarides. 2002. XML-based NLP tools for
analysing and annotating medical language. In Pro-
ceedings of the 2nd Workshop on NLP and XML,
Taipei, Taiwan, September.
Udo Hahn, Martin Romacker, and Stefan Schulz. 1998.
Why discourse structures in medical reports matter
for the validity of automatically generated text knowl-
edge bases. In MedInfo ’98 – Proceedings of the 9th
World Congress on Medical Informatics, pages 633–
638, Seoul, Korea, August.
Udo Hahn, Martin Romacker, and Stefan Schulz. 2002.
Creating knowledge repositories from biomedical re-
ports: The medsyndikate text mining system. In Pa-
cific Symposium on Biocomputing, pages 338–349,
Hawai, USA, January.
Bryan Jurish. 2003. Part-of-speech tagging with finite
state morphology. In Proceedings of the Workshop on
Collocations and Idioms: Linguistic, Computational
and Psycholinguistic Perspectives, Berlin, Germany,
September.
Carl Pollard and Ivan Sag. 1994. Head-Driven Phrase
Structure Grammar. CSLI / The University of
Chicago Press, Chicago and London.
Kai Saeger, Karsten Schl¨uns, Thomas Schrader, and Pe-
ter Hufnagl. 2003. The virtual microscope for routine
pathology based on a pacs system for 6 gb images.
In Proceedings of the 17th International Congress on
Computer Assisted Radiology and Surgery (CARS),
pages 299–304, London, UK, June.
David Schlangen. 2003. A Coherence-Based Approach
to the Interpretation of Non-Sentential Utterances in
Dialogue. Ph.D. thesis, School of Informatics, Uni-
versity of Edinburgh, Edinburgh, UK.
Stefan Schulz and Udo Hahn. 2001. Medical knowledge
engineering–converting major portions of the umls
into a terminological knowledge base. International
Journal ofMedical Informatics.
J. Slodowksa, K. Kayser, and P. Hasleton. 2002. Tele-
consultation in the chest disorders. European Journal
for Medical Research, 7(Suppl.I):80.
SNOMED International. 2004. SNOMED clinical terms.
http://www.snomed.org/index.html.
The HL7 Consortium. 2003. HL7 version 2.5 ANSI
standard, June. http://www.hl7.org.
The UMLS Consortium. 2003. UMLS release 2003AC.
http://www.nlm.nih.gov/research/umls/.
W3C WebOnt WG. 2004. OWL web ontology language
overview. W3C recommendation, W3C, Febru-
ary. http://www.w3.org/TR/2004/REC-owl-features-
20040210/.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.359697">
<title confidence="0.9981115">Feeding OWL: Extracting and the Content of Pathology Reports</title>
<author confidence="0.998974">David Schlangen</author>
<author confidence="0.998974">Manfred</author>
<affiliation confidence="0.9972995">Department of University of</affiliation>
<address confidence="0.727884">P.O. Box D-14415 Potsdam,</address>
<author confidence="0.972163">Elena Paslaru</author>
<affiliation confidence="0.985337">Institute for Computer Freie Universit¨at</affiliation>
<address confidence="0.904739">D-14195 Berlin,</address>
<email confidence="0.996502">paslaru@inf.fu-berlin.de</email>
<abstract confidence="0.991536416666667">This paper reports on an ongoing project that combines NLP with semantic web technologies to support a content-based storage and retrieval of medical pathology reports. We describe the NLP component of the project (a robust parser) and the background knowledge component (a domain ontology represented in OWL), and how they work together during extraction of domain specific information from natural language reports. The system provides a good example of how NLP techniques can be used to populate the Semantic Web.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anita Burgun</author>
<author>Oliver Bodenreider</author>
</authors>
<title>Mapping the UMLS semantic network into general ontologies.</title>
<date>2001</date>
<booktitle>In Proceedings of the AMIA Symposium.</booktitle>
<contexts>
<context position="9280" citStr="Burgun and Bodenreider, 2001" startWordPosition="1494" endWordPosition="1497">system not be represented as “green(x)”, but rather as something like “colour(x, green)”. This allows us to enforce consistency checks, by demanding that for each second-order predicate (colour, malignity, consistency, etc.) appropriate for a given concept only one value is chosen.4 This choice of representation has consequences for the way the semantics of adjectives is represented in the lexicon, as we will see presently. 3There are several current research projects with a similar aim of extracting stricter ontologies from sources like those mentioned above (see e.g. (Schulz and Hahn, 2001; Burgun and Bodenreider, 2001)), and this is by no means a trivial task. The present paper, however, focuses on a different (but of course interdependent) problem, namely that of extracting information such that it can be represented in the way described here. 4Technically, these constraints are realised by functional data-properties relating entities to enumerated data types. An example report (with translation): &lt;befund&gt; &lt;makroskopie&gt; Stanzzylinder von 15 mm L¨ange und 1 mm Durchmesser. [1] &lt;/makroskopie&gt; &lt;mikroskopie&gt; Stanzbiopsat [2] eingenommen durch Infiltrate einer soliden malignen epithelialen Neoplasie. [3] Die Tu</context>
</contexts>
<marker>Burgun, Bodenreider, 2001</marker>
<rawString>Anita Burgun and Oliver Bodenreider. 2001. Mapping the UMLS semantic network into general ontologies. In Proceedings of the AMIA Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>GULP 3.1: An extension of prolog for unification-based grammar.</title>
<date>1994</date>
<tech>Technical Report AI-1994-06,</tech>
<institution>University of Georgia.</institution>
<contexts>
<context position="20497" citStr="Covington, 1994" startWordPosition="3161" endWordPosition="3162">ract the largest non-overlapping chunks.10 An example might help to illustrate the robust8Up until here, all steps are performed in one go for the whole document. The subsequent steps, on the other hand, are performed incrementally for each sentence. This allows the system to remove ambiguity when it occurs, rather than having to maintain and later filter out different analyses. 9The parser is implemented in PROLOG, and based on the simple algorithm given in (Gazdar and Mellish, 1989). It also uses code by Michael Covington for dealing with feature structures in PROLOG, which is described in (Covington, 1994). 10That strategy will prefer lenght of individual chunks over coverage of input, for example when there is one big chunk and two overlapping smaller chunks at each side of that chunk, that however together span more input. ⎡ CAT np ⎡ ⎤ ⎢ CASE nom ⎢ HEAD NUM sg AGR ⎣PER dr GEN neu COMP nil ⎡ *�RELTYPE det ��RELTYPE ent � TYPE ⎢ RESTR TYPE unspec stanzbiopsat ⎣ARG x3 INST x3 INDEX x3 ⎤ ⎤ ⎡ ⎦⎥ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢SYN ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎦ ⎢ ⎢ ⎢SEM ⎢ ⎢ ⎢ ⎢ ⎣ ⎤ ⎦⎥⎥⎥ ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ SYN SEM ⎤ ⎥⎥⎥⎥⎥⎥⎥ ⎤⎥⎥⎥ +⎥⎥ ⎥⎥ ⎥⎥ ⎥⎥ ⎥⎥ ⎥⎥ ⎥⎥ ⎦⎦⎥⎥ ⎡ CAT np ⎡ ⎤ ⎢ CASE acc ⎢ �NUM pl � ⎢ ⎣ ⎦ HEAD A</context>
</contexts>
<marker>Covington, 1994</marker>
<rawString>Michael A. Covington. 1994. GULP 3.1: An extension of prolog for unification-based grammar. Technical Report AI-1994-06, University of Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Demichellis</author>
<author>V Della Mea</author>
<author>S Forti</author>
<author>P Dalla Palma</author>
<author>C A Beltrami</author>
</authors>
<title>Digital storage of glass slide for quality assurance in histopathology and cytopathology.</title>
<date>2002</date>
<journal>Telemedicine and Telecare,</journal>
<volume>8</volume>
<issue>3</issue>
<pages>142</pages>
<contexts>
<context position="1344" citStr="Demichellis et al., 2002" startWordPosition="193" endWordPosition="196"> extraction of domain specific information from natural language reports. The system provides a good example of how NLP techniques can be used to populate the Semantic Web. 1 Introduction Clinical pathologists work with and produce vast amounts of data: images of biological samples and written reports of their findings. Digital Pathology is the cover term for a number of efforts to introduce digital processing into the work-flow of the pathologist. While previous projects have focussed on storage and distribution of images and reports (e.g. in Tele-Pathology-projects, (Slodowksa et al., 2002; Demichellis et al., 2002)), the work reported here explores the use of Natural Language Processing (NLP) and Semantic Web technologies to support a content-based storage and retrieval of case reports. The system that we are building, LUPUS (Lung Pathology System), consists of an NLP component (a robust parser) and a Semantic Web component (a domain ontology represented in OWL, and a Description Logic reasoner), which work closely together, with the domain ontology guiding the information extraction process. The remainder of the paper is organised as follows. In the next section we describe the context and intended app</context>
</contexts>
<marker>Demichellis, Mea, Forti, Palma, Beltrami, 2002</marker>
<rawString>F. Demichellis, V. Della Mea, S. Forti, P. Dalla Palma, and C.A. Beltrami. 2002. Digital storage of glass slide for quality assurance in histopathology and cytopathology. Telemedicine and Telecare, 8(3):138– 142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
<author>Chris Mellish</author>
</authors>
<date>1989</date>
<booktitle>Natural Language Processing in PROLOG.</booktitle>
<publisher>Addison-Wesley,</publisher>
<location>Wokingham, England.</location>
<contexts>
<context position="20370" citStr="Gazdar and Mellish, 1989" startWordPosition="3138" endWordPosition="3141">ng arguments of Ns, modification by PPs, and coordination). When extracting chunks, the strategy followed by the system is to always extract the largest non-overlapping chunks.10 An example might help to illustrate the robust8Up until here, all steps are performed in one go for the whole document. The subsequent steps, on the other hand, are performed incrementally for each sentence. This allows the system to remove ambiguity when it occurs, rather than having to maintain and later filter out different analyses. 9The parser is implemented in PROLOG, and based on the simple algorithm given in (Gazdar and Mellish, 1989). It also uses code by Michael Covington for dealing with feature structures in PROLOG, which is described in (Covington, 1994). 10That strategy will prefer lenght of individual chunks over coverage of input, for example when there is one big chunk and two overlapping smaller chunks at each side of that chunk, that however together span more input. ⎡ CAT np ⎡ ⎤ ⎢ CASE nom ⎢ HEAD NUM sg AGR ⎣PER dr GEN neu COMP nil ⎡ *�RELTYPE det ��RELTYPE ent � TYPE ⎢ RESTR TYPE unspec stanzbiopsat ⎣ARG x3 INST x3 INDEX x3 ⎤ ⎤ ⎡ ⎦⎥ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢SYN ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎦ ⎢ ⎢ ⎢SEM ⎢ ⎢ ⎢ ⎢ ⎣ ⎤ ⎦⎥⎥⎥</context>
</contexts>
<marker>Gazdar, Mellish, 1989</marker>
<rawString>Gerald Gazdar and Chris Mellish. 1989. Natural Language Processing in PROLOG. Addison-Wesley, Wokingham, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Ewan Klein</author>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>XML-based NLP tools for analysing and annotating medical language.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2nd Workshop on NLP and XML,</booktitle>
<location>Taipei, Taiwan,</location>
<contexts>
<context position="18221" citStr="Grover et al., 2002" startWordPosition="2782" endWordPosition="2785">spatial dimensions) which can be recognised easily but would require very specialised grammar rules later on.6 Then, the domain-specific lexicon is accessed, which maps “concept names” (nouns, or phrases as recognised in the previous step) to the concept IDs used in the ontology.7 Tokens for which there is no entry in that lexicon, and which are hence deemed ‘irrelevant’ for the domain, are assigned a ‘dummy’ semantics appropriate for their part of speech, so that they do not confuse the later parsing stage. (More details about this kind of robustness will be given shortly.) 6See for example (Grover et al., 2002) for a discussion of the utility of a named entitiy recognition preprocessing stage for robust symbolic parsing. 7Note that this lexicon is one single resource out of which also the domain specfic additions to the morphology-lexicon and the list of multi-word expressions are compiled. 3.3 Chunk Parsing Next, the analyses of the tokens are transformed into a feature structure format, and are passed to the parsing component.8 The output of this stage is an intermediate semantic representation of (aspects of) the content (of which the notation shown in 1 is a variant). This format is akin to trad</context>
<context position="29069" citStr="Grover et al., 2002" startWordPosition="4636" endWordPosition="4639">hey use a variant of dependency parsing which is driven by verb information. As described in Section 2.2 above, this is not an option for us, given the style of our input texts, and hence our data renders a bottomup chart parsing approach much more promising. Besides this difference, the work in medSynDiKAte predates the emergence of XML/web ontology standards and thus uses an earlier description logic knowledge representation language; we are hoping that by using a standard we will be able to allow even future semantic web technologies to work with our data. As for the robust analysis side, (Grover et al., 2002), also use a similar preprocessing pipeline in combination with parsing. However, they also focus on more “natural” input texts (Medline abstracts), and they use statistical rather than symbolic/ontology based methods for computing the meaning of compound nouns. 6 Summary and Further Work We have described LUPUS, an NLP system that makes use of a domain ontology to guide extraction of information about entities from medical texts, and represents this information as instances of concepts from that ontology. Besides its direct use for content-based search on these texts, the fact that the system</context>
</contexts>
<marker>Grover, Klein, Lapata, Lascarides, 2002</marker>
<rawString>Claire Grover, Ewan Klein, Mirella Lapata, and Alex Lascarides. 2002. XML-based NLP tools for analysing and annotating medical language. In Proceedings of the 2nd Workshop on NLP and XML, Taipei, Taiwan, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Martin Romacker</author>
<author>Stefan Schulz</author>
</authors>
<title>Why discourse structures in medical reports matter for the validity of automatically generated text knowledge bases.</title>
<date>1998</date>
<booktitle>In MedInfo ’98 – Proceedings of the 9th World Congress on Medical Informatics,</booktitle>
<pages>633--638</pages>
<location>Seoul, Korea,</location>
<contexts>
<context position="29919" citStr="Hahn et al., 1998" startWordPosition="4775" endWordPosition="4778">the meaning of compound nouns. 6 Summary and Further Work We have described LUPUS, an NLP system that makes use of a domain ontology to guide extraction of information about entities from medical texts, and represents this information as instances of concepts from that ontology. Besides its direct use for content-based search on these texts, the fact that the system relies entirely on emerging semantic web standards will make the resulting annotated information usable for all kinds of agents working with such data. As a next step, we plan to add discourse processing to the pipeline (see e.g. (Hahn et al., 1998) for a discussion why such a step is required even for such relatively simple texts). As mentioned above, the prerequisite information (about definite articles, for example) is already there; we plan to use the available domain knowledge to guide the search for antecedents for bridging. As a more technical improvement we are investigating ways of making the architecture less pipeline-y, and to integrate domain reasoning in computing edges in the chart. Lastly, we are also working on a large-scale evaluation of the system, by manually annotating reports to compute precision and recall. Acknowle</context>
</contexts>
<marker>Hahn, Romacker, Schulz, 1998</marker>
<rawString>Udo Hahn, Martin Romacker, and Stefan Schulz. 1998. Why discourse structures in medical reports matter for the validity of automatically generated text knowledge bases. In MedInfo ’98 – Proceedings of the 9th World Congress on Medical Informatics, pages 633– 638, Seoul, Korea, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Martin Romacker</author>
<author>Stefan Schulz</author>
</authors>
<title>Creating knowledge repositories from biomedical reports: The medsyndikate text mining system.</title>
<date>2002</date>
<booktitle>In Pacific Symposium on Biocomputing,</booktitle>
<pages>338--349</pages>
<location>Hawai, USA,</location>
<contexts>
<context position="28035" citStr="Hahn et al., 2002" startWordPosition="4465" endWordPosition="4468">semantic representations. For a full-scale evaluation, we will manually annotate these NPs with semantic representations, and we will use this to compute precision and recall also with respect to semantics, and ultimately with respect to sample search queries. This annotation, however, is very resource-intensive, and so will only be done once the modules have been finalised. 5 Related Work Acquisition of information from texts especially from the medical domain is a lively research area. Among the many projects in that field, we share some of our central concerns with the medSyndiKAte system (Hahn et al., 2002): robust text analysis of medical reports; a background knowledge base for guiding the analysis and storing the text’s content; emphasis on handling co-reference phenomena. What distinguishes LUPUS from medSyndiKAte, though, is foremost the parsing scheme: the language used in the reports analysed by Hahn et al. is much closer to ‘natural’ language in that it contains sentences with tensed verbs. Accordingly, they use a variant of dependency parsing which is driven by verb information. As described in Section 2.2 above, this is not an option for us, given the style of our input texts, and henc</context>
</contexts>
<marker>Hahn, Romacker, Schulz, 2002</marker>
<rawString>Udo Hahn, Martin Romacker, and Stefan Schulz. 2002. Creating knowledge repositories from biomedical reports: The medsyndikate text mining system. In Pacific Symposium on Biocomputing, pages 338–349, Hawai, USA, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryan Jurish</author>
</authors>
<title>Part-of-speech tagging with finite state morphology.</title>
<date>2003</date>
<booktitle>In Proceedings of the Workshop on Collocations and Idioms: Linguistic, Computational and Psycholinguistic Perspectives,</booktitle>
<location>Berlin, Germany,</location>
<contexts>
<context position="14754" citStr="Jurish, 2003" startWordPosition="2241" endWordPosition="2243">and sentence splitting, is fairly standard, and so we skip over it here. The second step, morpho-syntactic analysis, is more interesting. It is performed by an independently developed module called TAGH, a huge finite-state machine that makes use of a German word-stem lexicon (containing about 90,000 entries for nouns, 17,000 for verbs, 20,000 adjectives and adverbs, and about 1,500 closed class word forms). The transducer is implemented in C++ and has a very high throughput (about 20,000 words per second on modern machines). The coverage achieved on a balanced corpus of German is around 96% (Jurish, 2003), for our domain the lexicon had to be extended with some domain specific vocabulary. To give an example of the results of the analysis, Figure 3 shows (excerpts of) the output for Sentence 2 of the example report. Note that this is already the POS-disambiguated output, and we only show one analysis for each token. In most cases, we will get several analyses for each token at this stage, differing with respect to their part of speech tag or other morphological features (e.g., case) that are not fully determined by their form. (The average is 5.7 analyses per token.) Note also that the actual o</context>
<context position="16979" citStr="Jurish, 2003" startWordPosition="2580" endWordPosition="2581">[ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed] Neoplasie Neoplasie [NN Gender=fem Number=sg Case=*] Figure 3: Result of Morphological Analysis / POS-tag disambiguation for Sentence 2 positional, as the nature of the relation between the compounds is underspecified. We represent this by use of an underspecified relation rel that holds between the compounds, and which has to be specified later on in the processing chain. The output of this module is then fed into a statistically trained POS-disambiguator, which finds the most likely path through the lattice of morphological analyses (Jurish, 2003) (with an accuracy of 96%). In cases where morphology failed to provide an analysis, the syntagmatically most likely POS tag is chosen. At the end of this stage all analyses for a given token agree on its part of speech; however, other features (number, person, case, etc.) might still not be disambiguated. At the next stage, certain sequences of tokens are grouped together, namely multi-word expression that denote a single concept in our ontology (e.g., “anthrakotische Lymphknoten” denotes a single concept, and hence is marked as one token of type NN at this step), and certain other phrases (e</context>
</contexts>
<marker>Jurish, 2003</marker>
<rawString>Bryan Jurish. 2003. Part-of-speech tagging with finite state morphology. In Proceedings of the Workshop on Collocations and Idioms: Linguistic, Computational and Psycholinguistic Perspectives, Berlin, Germany, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<tech>CSLI</tech>
<institution>The University of Chicago Press, Chicago and London.</institution>
<contexts>
<context position="19672" citStr="Pollard and Sag, 1994" startWordPosition="3027" endWordPosition="3030">e that the semantics is “flat”, and does not represent scope of quantifiers (which only very rarely occur in our data, and cannot be represented OWL in any case). To get an idea of the feature geometry used by the grammar see Figure 4; this figure also shows the semantic representations generated at this stage (in a different notation than in Figure fig:reps). Note the ‘simulation’ of typing of feature structures, and the representation of properties via second order properties as discussed above. Chunk parsing is performed by a chart parser running a grammar that is loosely inspired by HPSG (Pollard and Sag, 1994).9 The grammar contains context-free rules for fairly complex NPs (allowing arguments of Ns, modification by PPs, and coordination). When extracting chunks, the strategy followed by the system is to always extract the largest non-overlapping chunks.10 An example might help to illustrate the robust8Up until here, all steps are performed in one go for the whole document. The subsequent steps, on the other hand, are performed incrementally for each sentence. This allows the system to remove ambiguity when it occurs, rather than having to maintain and later filter out different analyses. 9The pars</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan Sag. 1994. Head-Driven Phrase Structure Grammar. CSLI / The University of Chicago Press, Chicago and London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Saeger</author>
<author>Karsten Schl¨uns</author>
<author>Thomas Schrader</author>
<author>Peter Hufnagl</author>
</authors>
<title>The virtual microscope for routine pathology based on a pacs system for 6 gb images.</title>
<date>2003</date>
<booktitle>In Proceedings of the 17th International Congress on Computer Assisted Radiology and Surgery (CARS),</booktitle>
<pages>299--304</pages>
<location>London, UK,</location>
<marker>Saeger, Schl¨uns, Schrader, Hufnagl, 2003</marker>
<rawString>Kai Saeger, Karsten Schl¨uns, Thomas Schrader, and Peter Hufnagl. 2003. The virtual microscope for routine pathology based on a pacs system for 6 gb images. In Proceedings of the 17th International Congress on Computer Assisted Radiology and Surgery (CARS), pages 299–304, London, UK, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Schlangen</author>
</authors>
<title>A Coherence-Based Approach to the Interpretation of Non-Sentential Utterances in Dialogue.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>School of Informatics, University of Edinburgh,</institution>
<location>Edinburgh, UK.</location>
<contexts>
<context position="12984" citStr="Schlangen, 2003" startWordPosition="1953" endWordPosition="1954">nt means certain limitations have to be accepted. Being a fragment of FOL, it is not expressive enough to represent certain finer semantic details, as will be discussed below. However, the advantage of using an emerging standard for delivering and sharing information outweighs these drawbacks. 3 Implementation 3.1 Overview As mentioned above, most of the sentences in our corpus do not contain a finite verb; i.e., according to standard rules of grammar they are elliptical. While a theoretically motivated approach should strive to resolve this ellipsis contextually (for example as described in (Schlangen, 2003)), in view of the intended application and for reasons of robustness we have decided to focus only on extracting information about the entities introduced in the reports— that is, on recognising nominal phrases, leaving aside the question of how verbal meanings are to be resolved. Our strategy is to combine a “shallow” preprocessing stage (based on finite-state methods and statistical approaches) with a symbolic phase, in which the semantics of the NPs is assembled.5 A requirement for the processing is that it must be robust, in two ways: it must be able to deal with unknown tokens (i.e., “out</context>
</contexts>
<marker>Schlangen, 2003</marker>
<rawString>David Schlangen. 2003. A Coherence-Based Approach to the Interpretation of Non-Sentential Utterances in Dialogue. Ph.D. thesis, School of Informatics, University of Edinburgh, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Schulz</author>
<author>Udo Hahn</author>
</authors>
<title>Medical knowledge engineering–converting major portions of the umls into a terminological knowledge base.</title>
<date>2001</date>
<journal>International Journal ofMedical Informatics.</journal>
<contexts>
<context position="9249" citStr="Schulz and Hahn, 2001" startWordPosition="1490" endWordPosition="1493">n entity x will in our system not be represented as “green(x)”, but rather as something like “colour(x, green)”. This allows us to enforce consistency checks, by demanding that for each second-order predicate (colour, malignity, consistency, etc.) appropriate for a given concept only one value is chosen.4 This choice of representation has consequences for the way the semantics of adjectives is represented in the lexicon, as we will see presently. 3There are several current research projects with a similar aim of extracting stricter ontologies from sources like those mentioned above (see e.g. (Schulz and Hahn, 2001; Burgun and Bodenreider, 2001)), and this is by no means a trivial task. The present paper, however, focuses on a different (but of course interdependent) problem, namely that of extracting information such that it can be represented in the way described here. 4Technically, these constraints are realised by functional data-properties relating entities to enumerated data types. An example report (with translation): &lt;befund&gt; &lt;makroskopie&gt; Stanzzylinder von 15 mm L¨ange und 1 mm Durchmesser. [1] &lt;/makroskopie&gt; &lt;mikroskopie&gt; Stanzbiopsat [2] eingenommen durch Infiltrate einer soliden malignen epi</context>
</contexts>
<marker>Schulz, Hahn, 2001</marker>
<rawString>Stefan Schulz and Udo Hahn. 2001. Medical knowledge engineering–converting major portions of the umls into a terminological knowledge base. International Journal ofMedical Informatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Slodowksa</author>
<author>K Kayser</author>
<author>P Hasleton</author>
</authors>
<title>Teleconsultation in the chest disorders.</title>
<date>2002</date>
<journal>European Journal for Medical Research,</journal>
<pages>7--80</pages>
<contexts>
<context position="1317" citStr="Slodowksa et al., 2002" startWordPosition="189" endWordPosition="192">hey work together during extraction of domain specific information from natural language reports. The system provides a good example of how NLP techniques can be used to populate the Semantic Web. 1 Introduction Clinical pathologists work with and produce vast amounts of data: images of biological samples and written reports of their findings. Digital Pathology is the cover term for a number of efforts to introduce digital processing into the work-flow of the pathologist. While previous projects have focussed on storage and distribution of images and reports (e.g. in Tele-Pathology-projects, (Slodowksa et al., 2002; Demichellis et al., 2002)), the work reported here explores the use of Natural Language Processing (NLP) and Semantic Web technologies to support a content-based storage and retrieval of case reports. The system that we are building, LUPUS (Lung Pathology System), consists of an NLP component (a robust parser) and a Semantic Web component (a domain ontology represented in OWL, and a Description Logic reasoner), which work closely together, with the domain ontology guiding the information extraction process. The remainder of the paper is organised as follows. In the next section we describe t</context>
</contexts>
<marker>Slodowksa, Kayser, Hasleton, 2002</marker>
<rawString>J. Slodowksa, K. Kayser, and P. Hasleton. 2002. Teleconsultation in the chest disorders. European Journal for Medical Research, 7(Suppl.I):80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SNOMED International</author>
</authors>
<date>2004</date>
<note>SNOMED clinical terms. http://www.snomed.org/index.html.</note>
<contexts>
<context position="7909" citStr="International, 2004" startWordPosition="1281" endWordPosition="1283">f concepts and assertions of properties that are defined in an ontology, which constitutes the domain knowledge of the system (at the moment focussed on pathologies of the lung). This ontology is specified in OWL DL (W3C WebOnt WG, 2004), a version of OWL with a formal semantics and a complete and decidable calculus. Consequently, the content of the texts is represented in OWD DL as well, and so the knowledge base of the system consists of the ontology and the instances. The ontology we use is compiled out of several medical sources (such as UMLS (The UMLS Consortium, 2003) and SNOMED (SNOMED International, 2004)), but since these sources often were not intended for machine reasoning (i.e., are not necessarily consistent, and use rather loosely defined relations), considerable effort has been spent (and is being spent) on cleaning them up.3 At the moment, about 1,000 domain-level concepts and ca. 160 upper-level concepts have been identified, which are connected by about 50 core relation types. To our knowledge, this makes it one of the biggest OWL-ontologies currently in use. Besides representing concepts relevant to our domain, the ontology also lists properties that instances of these concepts can </context>
</contexts>
<marker>International, 2004</marker>
<rawString>SNOMED International. 2004. SNOMED clinical terms. http://www.snomed.org/index.html.</rawString>
</citation>
<citation valid="true">
<date></date>
<booktitle>The HL7 Consortium. 2003. HL7 version 2.5 ANSI standard,</booktitle>
<marker></marker>
<rawString>The HL7 Consortium. 2003. HL7 version 2.5 ANSI standard, June. http://www.hl7.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>The UMLS Consortium</author>
</authors>
<date>2003</date>
<note>UMLS release 2003AC. http://www.nlm.nih.gov/research/umls/.</note>
<contexts>
<context position="6702" citStr="Consortium, 2003" startWordPosition="1075" endWordPosition="1076"> (macroscopy and microscopy, respectively) will be about the same parts of the sample, but on different levels of granularity. The last peculiarity we note is the relatively high frequency of compound nouns. These are especially important for our task, since technical concepts in German tend to be expressed by such compound nouns (rather than by noun groups). While some 2What is shown in the figure is actually already the result of a preprocessing step; the cases as stored in the database contain patient data as well, and are formatted to comply with the HL7 standard for medical data (The HL7 Consortium, 2003). Moreover, the italicisation in the input representation and the numbers in square brackets are added here for ease of reference and are not part of the actual representations maintained by the system. of those will denote individual concepts and hence will be recorded in the domain lexicon, others must be analysed and their semantics must be composed out of that of their parts (see below). 2.3 Lung Pathology Knowledge in OWL The result of processing such reports with LUPUS is a representation of (relevant aspects of) their content. This representation has the form of instances of concepts an</context>
</contexts>
<marker>Consortium, 2003</marker>
<rawString>The UMLS Consortium. 2003. UMLS release 2003AC. http://www.nlm.nih.gov/research/umls/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W3C WebOnt WG</author>
</authors>
<title>OWL web ontology language overview.</title>
<date>2004</date>
<booktitle>W3C recommendation, W3C,</booktitle>
<note>http://www.w3.org/TR/2004/REC-owl-features20040210/.</note>
<contexts>
<context position="7526" citStr="WG, 2004" startWordPosition="1214" endWordPosition="1215">l denote individual concepts and hence will be recorded in the domain lexicon, others must be analysed and their semantics must be composed out of that of their parts (see below). 2.3 Lung Pathology Knowledge in OWL The result of processing such reports with LUPUS is a representation of (relevant aspects of) their content. This representation has the form of instances of concepts and assertions of properties that are defined in an ontology, which constitutes the domain knowledge of the system (at the moment focussed on pathologies of the lung). This ontology is specified in OWL DL (W3C WebOnt WG, 2004), a version of OWL with a formal semantics and a complete and decidable calculus. Consequently, the content of the texts is represented in OWD DL as well, and so the knowledge base of the system consists of the ontology and the instances. The ontology we use is compiled out of several medical sources (such as UMLS (The UMLS Consortium, 2003) and SNOMED (SNOMED International, 2004)), but since these sources often were not intended for machine reasoning (i.e., are not necessarily consistent, and use rather loosely defined relations), considerable effort has been spent (and is being spent) on cle</context>
</contexts>
<marker>WG, 2004</marker>
<rawString>W3C WebOnt WG. 2004. OWL web ontology language overview. W3C recommendation, W3C, February. http://www.w3.org/TR/2004/REC-owl-features20040210/.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>