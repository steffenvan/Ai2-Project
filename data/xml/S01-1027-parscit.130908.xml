<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.031085">
<note confidence="0.66453">
Using Domain Information for Word Sense Disambiguation
Bernardo Magnini, Carlo Strapparava, Giovanni Pezzulo and Alfio Gliozzo
ITC-irst, Istituto per la Ricerca Scientifica e Tecnologica, 1-38050 Trento, ITALY
email: {magnini, strappa, pezzulo, gliozzo}©itc.it
</note>
<sectionHeader confidence="0.932708" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999803538461538">
The major goal in ITC-irst&apos;s participation at
SENSEVAL-2 was to test the role of domain in-
formation in word sense disambiguation. The
underlying working hypothesis is that domain
labels, such as MEDICINE, ARCHITECTURE and
SPORT provide a natural way to establish se-
mantic relations among word senses, which can
be profitably used during the disambiguation
process. For each task in which we participated
(i.e. English all words, English &apos;lexical sample&apos;
and Italian &apos;lexical sample&apos;) a different mix of
knowledge based and statistical techniques were
implemented.
</bodyText>
<sectionHeader confidence="0.993733" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999919864864865">
Current investigation in Word Sense Disam-
biguation (WSD) at ITC-irst focuses on the role
of domain information. The hypothesis is that
domain labels (such as MEDICINE, ARCHITEC-
TURE and SPORT) provide a natural and pow-
erful way to establish semantic relations among
word senses, which can be profitably used dur-
ing the disambiguation process. In particular,
domains constitute a fundamental feature of
text coherence, such that word senses occurring
in a coherent portion of text tend to maximize
domain similarity. The importance of domain
information in WSD has been remarked in sev-
eral works, including (Gonzalo et al., 1998) and
(Buitelaar and Sacaleanu, 2001). In (Magnini
and Strapparava, 2000) we introduced &amp;quot;Word
Domain Disambiguation&amp;quot; (WDD) as a variant
of WSD where for each word in a text a domain
label (among those allowed by the word) has to
be chosen instead of a sense label. We also ar-
gued that WDD can be applied to disambigua-
tion tasks that do not require fine grained sense
distinctions, such as information retrieval and
content-based user modeling. For SENSEVAL-
2 the goal was to evaluate the role of domain
information in WSD: no other syntactic or se-
mantic information has been used (e.g. seman-
tic relations in WoRDNET) except domain la-
bels. Three systems have been implemented, in-
tegrating knowledge-based and statistical tech-
niques, for the three tasks we participated in,
i.e. English &apos;all words&apos;, English &apos;lexical sample&apos;
and Italian &apos;lexical sample&apos;. The main lexical
resource for domains is &amp;quot;WordNet Domains&amp;quot;,
an extension of English Wordnet 1.6 (Fellbaum,
1998) developed at ITC-irst, where synsets have
been annotated with domain information.
</bodyText>
<sectionHeader confidence="0.966393" genericHeader="method">
2 WordNet Domains
</sectionHeader>
<bodyText confidence="0.99997052">
The basic lexical resource we used in SENSEVAL-
2 is &amp;quot;WordNet Domains&amp;quot;, an extension of
WORDNET 1.6 where each synset has been an-
notated with at least one domain label, se-
lected from a set of about two hundred la-
bels hierarchically organized (see (Magnini and
Cavaglia, 2000) for the annotation methodol-
ogy and for the evaluation of the resource).
The information from the domains that we
added is complementary to what is already in
WORDNET. First of all a domain may in-
clude synsets of different syntactic categories:
for instance MEDICINE groups together senses
from Nouns, such as doctor#1 and hospital#1,
and from Verbs such as operate#7. Sec-
ond, a domain may include senses from dif-
ferent WORDNET sub-hierarchies (i.e. deriv-
ing from different &amp;quot;unique beginners&amp;quot; or from
different &amp;quot;lexicographer files&amp;quot;). For example,
SPORT contains senses such as athlete#1, de-
riving from life_form#1, game_equipment#1
from physical_obj ect#1, sport#1 from act#2,
and playing_f ield#1 from location#1. Fi-
nally, domains may group senses of the same
word into homogeneous clusters, with the side
</bodyText>
<page confidence="0.998048">
111
</page>
<bodyText confidence="0.980556405405406">
effect of reducing word polysemy in WORD NET.
Table 1 shows an example. The word &amp;quot;bank&amp;quot;
has ten different senses in WORD NET 1.6: three
of them (i.e. sense 1, 3 and 6) can be grouped
under the ECONOMY domain, while sense 2 and
7 both belong to GEOGRAPHY and GEOLOGY,
causing the reduction of the polysemy from 10
to 7 senses. For the purposes of SENSEVAL-2
we have considered 41 disjoint labels which al-
low a good level of abstraction without loosing
relevant information (i.e. in the experiments we
have used SPORT in place of VOLLEY or BAS-
KETBALL, which are subsumed by SPORT).
Sense Synset 6 Gloss Domains Senicor
occurr.
#1 depository finan- ECONOMY 20
cial institution,
bank, banking
concern, bank-
ing company (a
financial institu-
tion...)
#2 bank (sloping GEOGRAPHY, 14
land...) GEOLOGY
#3 bank (a supply or ECONOMY
stock held in re-
serve... )
#4 bank, bank ARCHITECTURE, -
building (a build- ECONOMY
ing... )
#5 bank (an arrange- FACTOTUM 1
ment of similar
objects...)
#6 savings bank, ECONOMY
coin bank, money
box, bank (a
container... )
#7 bank (a long GEOGRAPHY, 2
ridge or pile...) GEOLOGY
#8 bank (the funds ECONOMY,
held by a gam- PLAY
bling house...)
#9 bank, cant, cam- ARCHITECTURE -
ber (a slope in the
turn of a road...)
#10 bank (a flight ma- TRANSPORT
neuver... )
Table 1: WORD NET senses, domains and occur-
rences in Semcor for the word &amp;quot;bank&amp;quot;
Two mapping procedures have been imple-
mented for SENSEVAL-2 in order to use do-
main information. For the English tasks a map-
ping from WORDNET 1.6 to the WORDNET
1.7 pre-release made available to participants;
for the Italian task a mapping from WORD-
NET 1.6 to WORDNET 1.5, because the inter-
lingual index of EuroWordNet (Vossen, 1998)
is in that version. The mapping to WORDNET
1.7 is based on a set of heuristics (e.g. corre-
spondences between synonyms, glosses and hy-
pernyms) which discover corresponding synset
pairs. Then, an inheritance algorithm is ap-
plied to WORDNET 1.7 in order to fill unas-
signed synsets with domain labels. As far as
the Italian wordnet is concerned the same pro-
cedure used for the WORD NET 1.7 mapping has
been applied to WORDNET 1.5, resulting in the
annotation of the Interlingual Index. Then the
equivalence links (we excluded eq_hyperonym
and eq_hyphonym) from the ILI to the Italian
synsets were used to bring the domain informa-
tion to Italian words.
There was no time for a complete evaluation
of the quality of the mapping procedures.
</bodyText>
<sectionHeader confidence="0.995055" genericHeader="method">
3 Algorithms
</sectionHeader>
<bodyText confidence="0.999942846153846">
The starting point in the algorithm design was
the previous work in word domain disambigua-
tion reported in (Magnini and Strapparava,
2000). One drawback of that approach is that,
for rather long texts, it does not consider do-
main variations. To overcome this problem we
have introduced contexts within which domains
are calculated. A second direction of work has
been the acquisition of domain information from
annotated texts (i.e. Semcor and the training
data). The following sections presents details of
the disambiguation procedures implemented for
SENSEVAL-2.
</bodyText>
<subsectionHeader confidence="0.993448">
3.1 Linguistic Processing
</subsectionHeader>
<bodyText confidence="0.999981181818182">
XML files made available by the task organizers
have been processed with an XML parser. As
for lemmatization and part-of-speech tagging
the Tree Tagger, developed at the University of
Stuttgart (Schmid, 1994) has been used, both
for English and Italian. The WordNet mor-
phological analyser has also been used in order
to resolve ambiguities and lemmatization mis-
takes. After this process texts are represented
as vectors of triples: word lemma, WORD NET
part of speech and position in the text.
</bodyText>
<subsectionHeader confidence="0.995012">
3.2 Scoring Domains for a Lemma
</subsectionHeader>
<bodyText confidence="0.9832235">
The basic procedure in domain driven disam-
biguation is a function that, given a lemma L,
</bodyText>
<page confidence="0.992707">
112
</page>
<bodyText confidence="0.99618875">
associates a score to each domain defined for
that lemma in Wordnet Domains. Such a score
is the relative frequency of the domain in L,
computed on the basis of the occurrences of the
synsets of L in Semcor. Semcor occurrences for
synsets with multiple domain annotations are
repeated for each domain (e.g. if a synset has 2
occurrences and 2 labels it is counted as having
4 occurrences), while synsets with 0 occurrences
are counted as 0.5. As an example, consider the
lemma &amp;quot;bank&amp;quot; in Table 1. According to our
scoring method, it has 57 total occurrences in
Semcor. The GEOLOGY domain collects contri-
butions from senses 2 and 7, for a total of 16
occurrences in Semcor, which corresponds to a
frequency .28 (i.e. fg[DGeology](bank) = 0.28).
</bodyText>
<subsectionHeader confidence="0.991833">
3.3 Domain Vectors
</subsectionHeader>
<bodyText confidence="0.989422727272727">
The data structure that collects domain infor-
mation is called a Domain Vector (DV). Intu-
itively a DV represents the domains that are
relevant for a certain lemma (or word sense) in
a certain context. We have considered three
kinds of DV&apos;s: a DV for a lemma L within a
context C (DVf), for the case of test data; a
DV for a synset S of a lemma L within a context
C (DVI), for the case of training data; and a
DV for a synset S of a lemma L in WORD NET
(DVs), which is used when no training data are
available.
DV for a lemma in context (DVE). Given
a set of domains D1 ... Dn, a DV for a lemma L
in a position K within a text represents the rele-
vance of those domains for that lemma, i.e. each
component DVL[i] gives the degree of relevance
of the domain Di for the lemma L. Given a con-
text of +C words before and after the lemma L
in the position K, each component of the do-
main vector is defined with the following for-
mula:
</bodyText>
<equation confidence="0.8273115">
Dvf[i]. E Foii(Lo* gauss
k=—C
</equation>
<bodyText confidence="0.959298928571428">
where gauss is the normal distribution cen-
tered on the position K. In the current al-
gorithms C is set to 50 because our experi-
ments with Semcor showed that the precision
decreases below that thresold.
Intuitively, the above formula takes into ac-
count the contribution of the lemmas in the con-
text C to the sense of the target lemma L. In
addition a DV actually selects a set of relevant
domains rather than just one domain.
DV for a synset in context (D11) In case
a training corpus is available where lemmas are
annotated with the correct sense, Domain Vec-
tors are computed with the formula above. In-
stead of considering a lemma in a position K
within a text, we have a sense for that lemma
(i.e. a synset). DVI represents a &amp;quot;typical&amp;quot; vec-
tor for a sense S of a lemma L.
DV for a synset without context (DVs)
When a training corpus is not available (as for
the &apos;all words&apos; task), a simpler way to build a
DV for a certain synset is to compute it with
respect to WordNet Domains. Given a synset S
in WordNet Domains, the domain vector DVs
is a vector that has l&apos;s in the position of its
domain(s) and O&apos;s otherwise. A more accurate
DV could be obtained by considering contextual
information such as the synset gloss.
</bodyText>
<subsectionHeader confidence="0.995631">
3.4 Comparing Domain Vectors
</subsectionHeader>
<bodyText confidence="0.995977916666667">
To disambiguate a lemma L (i.e. the target
lemma) in a text, first its DV f is computed.
The next step consists of comparing the DV
of the target lemma L with the domain vec-
tors for each sense of L derived either from the
training set, when available, or from WordNet
Domains, when training data are not available.
The sense vector DV s which maximizes the sim-
ilarity is selected as the appropriate sense of L
in that text. The similarity between two DV&apos;s
is calculated with the standard scalar product:
DV1 • DV2 =Ei Dvi[i] *
</bodyText>
<sectionHeader confidence="0.996614" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.9850915">
Table 2 presents the results, in terms of pre-
cision and recall, obtained at the SENSEVAL-2
initiative for the three tasks in which we partic-
ipated.
</bodyText>
<table confidence="0.998926166666667">
Task Precision Recall
English All Words (fine g.) .748 .357
English All Words (coarse g.) .748 .357
English Lexical Sample (fine g.) .665 .249
English Lexical Sample (coarse g.) .720 .269
Italian Lexical Sample (fine g.) .375 .371
</table>
<tableCaption confidence="0.8906575">
Table 2: Final results of ITC-irst systems at
SENSEVAL-2
</tableCaption>
<page confidence="0.99824">
113
</page>
<subsectionHeader confidence="0.793518">
4.1 English &apos;All Words&apos;
</subsectionHeader>
<bodyText confidence="0.9999680625">
The &apos;all words&apos; task seems to benefit from the
domain approach. One reason for this is that
texts are enough long to provide art accurate
context (as mentioned in section 3.3, we used
a window of 100 content words around the tar-
get word) within which domains are coherent.
The rather low degree of recall reflects the fact
that few words in a text carry relevant domain
information. Most of the words actually be-
have such as a &amp;quot;factotum&amp;quot; (see (Magnini and
Cavaglia, 2000) for a preliminary discussion on
this problem) that can equally occur in almost
every domain. Some words lie outside the do-
main approach and their senses could be cap-
tured with the integration of local (e.g. syntac-
tic) information.
</bodyText>
<subsectionHeader confidence="0.835796">
4.2 English &apos;Lexical Sample&apos;
</subsectionHeader>
<bodyText confidence="0.999999642857143">
From the point of view of domain driven dis-
ambiguation, the &apos;lexical sample&apos; task was in-
herently more difficult than the &apos;all words&apos; task
for two reasons. First the context provided for
disambiguation was generally shorter than the
100 words we used to build a semantic vector.
Second, the high number of &amp;quot;factotum&amp;quot; words
to be disambiguated resulted in a recall even
lower (i.e. about 0.24) than for the &apos;all words&apos;
task. The improvement of performance from
the fine grained to the coarse grained evalua-
tion seems to confirm that, at least to some de-
gree, domain clustering corresponds to the sense
grouping created by the task organizers.
</bodyText>
<subsectionHeader confidence="0.962044">
4.3 Italian &apos;Lexical Sample&apos;
</subsectionHeader>
<bodyText confidence="0.999945785714286">
The low results obtained for the Italian &apos;lexical
sample&apos; task may have several causes. First of
all, the absence of a training set and the ab-
sence of any tagged text for Italian forced us
to use a similarity function (see 3.4) trained
to an English corpus. This was possible be-
cause we maintained the mappings between the
English and the Italian wordnets. However,
these multiple mappings (i.e. from WORD-
NET1.6 to W0RDNET1.5 and then to the Ital-
ian synsets through the equivalence links) are
another source of possible errors, especially con-
cerning the domain information associated with
Italian synsets.
</bodyText>
<sectionHeader confidence="0.99808" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999977">
We have described an approach to word sense
disambiguation based on domain information.
The underlying assumption is that domains con-
stitute a fundamental feature of text coherence.
As a consequence, word senses occurring in a co-
herent portion of text tend to maximize domain
similarity. Three systems have been imple-
mented, integrating knowledge-based and sta-
tistical techniques, for the three task we partic-
ipated in. As for lexical resources, the systems
make use of WordNet Domains, an extension of
English Wordnet 1.6, where synsets have been
annotated with domain information. The dis-
ambiguation algorithm is based on domain vec-
tors that collect contextual information with re-
spect to the target word. At this moment only
domain information is used in our system. A
promising research direction is the use of local
information (e.g. syntax) to capture word be-
haviors that lie outside the domain approach.
</bodyText>
<sectionHeader confidence="0.996637" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993794142857143">
P. Buitelaar and B. Sacaleanu. 2001. Ranking
and selecting synsets by domain relevance.
In Proc. of NAACL Workshop on WordNet
and Other Lexical Resources: Applications,
Extensions and Customizations, Pittsburgh,
PA, June.
C. Fellbaum. 1998. WordNet. An Electronic
Lexical Database. The MIT Press.
J. Gonzalo, F. Verdejio, C. Peters, and N. Cal-
zolari. 1998. Applying eurowordnet to cross-
language text retrieval. Computers and Hu-
manities, 32(2-3):185-207.
B. Magnini and G. Cavaglia. 2000. Integrat-
ing subject field codes into WordNet. In Pro-
ceedings of LREC-2000, Second International
Conference on Language Resources and Eval-
uation, Athens, Greece, June.
B. Magnini and C. Strapparava. 2000. Exper-
iments in word domain disambiguation for
parallel texts. In Proc. of SIGLEX Workshop
on Word Senses and Multi-linguality, Hong-
Kong, October.
H. Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of
the International Conference on New Meth-
ods in Language Processing.
P. Vossen. 1998. Special issue on eurowordnet.
&apos;Computers and Humanities, 32.
</reference>
<page confidence="0.99864">
114
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.636677">
<title confidence="0.999983">Using Domain Information for Word Sense Disambiguation</title>
<author confidence="0.982167">Bernardo Magnini</author>
<author confidence="0.982167">Carlo Strapparava</author>
<author confidence="0.982167">Giovanni Pezzulo</author>
<author confidence="0.982167">Alfio</author>
<address confidence="0.687778">ITC-irst, Istituto per la Ricerca Scientifica e Tecnologica, 1-38050 Trento,</address>
<email confidence="0.994314">magnini,strappa,pezzulo,gliozzo}©itc.it</email>
<abstract confidence="0.996391">The major goal in ITC-irst&apos;s participation at SENSEVAL-2 was to test the role of domain information in word sense disambiguation. The underlying working hypothesis is that domain labels, such as MEDICINE, ARCHITECTURE and SPORT provide a natural way to establish semantic relations among word senses, which can be profitably used during the disambiguation process. For each task in which we participated (i.e. English all words, English &apos;lexical sample&apos; and Italian &apos;lexical sample&apos;) a different mix of knowledge based and statistical techniques were implemented.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Buitelaar</author>
<author>B Sacaleanu</author>
</authors>
<title>Ranking and selecting synsets by domain relevance.</title>
<date>2001</date>
<booktitle>In Proc. of NAACL Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations,</booktitle>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="1512" citStr="Buitelaar and Sacaleanu, 2001" startWordPosition="220" endWordPosition="223">se Disambiguation (WSD) at ITC-irst focuses on the role of domain information. The hypothesis is that domain labels (such as MEDICINE, ARCHITECTURE and SPORT) provide a natural and powerful way to establish semantic relations among word senses, which can be profitably used during the disambiguation process. In particular, domains constitute a fundamental feature of text coherence, such that word senses occurring in a coherent portion of text tend to maximize domain similarity. The importance of domain information in WSD has been remarked in several works, including (Gonzalo et al., 1998) and (Buitelaar and Sacaleanu, 2001). In (Magnini and Strapparava, 2000) we introduced &amp;quot;Word Domain Disambiguation&amp;quot; (WDD) as a variant of WSD where for each word in a text a domain label (among those allowed by the word) has to be chosen instead of a sense label. We also argued that WDD can be applied to disambiguation tasks that do not require fine grained sense distinctions, such as information retrieval and content-based user modeling. For SENSEVAL2 the goal was to evaluate the role of domain information in WSD: no other syntactic or semantic information has been used (e.g. semantic relations in WoRDNET) except domain labels.</context>
</contexts>
<marker>Buitelaar, Sacaleanu, 2001</marker>
<rawString>P. Buitelaar and B. Sacaleanu. 2001. Ranking and selecting synsets by domain relevance. In Proc. of NAACL Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations, Pittsburgh, PA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet. An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="2439" citStr="Fellbaum, 1998" startWordPosition="374" endWordPosition="375">ine grained sense distinctions, such as information retrieval and content-based user modeling. For SENSEVAL2 the goal was to evaluate the role of domain information in WSD: no other syntactic or semantic information has been used (e.g. semantic relations in WoRDNET) except domain labels. Three systems have been implemented, integrating knowledge-based and statistical techniques, for the three tasks we participated in, i.e. English &apos;all words&apos;, English &apos;lexical sample&apos; and Italian &apos;lexical sample&apos;. The main lexical resource for domains is &amp;quot;WordNet Domains&amp;quot;, an extension of English Wordnet 1.6 (Fellbaum, 1998) developed at ITC-irst, where synsets have been annotated with domain information. 2 WordNet Domains The basic lexical resource we used in SENSEVAL2 is &amp;quot;WordNet Domains&amp;quot;, an extension of WORDNET 1.6 where each synset has been annotated with at least one domain label, selected from a set of about two hundred labels hierarchically organized (see (Magnini and Cavaglia, 2000) for the annotation methodology and for the evaluation of the resource). The information from the domains that we added is complementary to what is already in WORDNET. First of all a domain may include synsets of different syn</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet. An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gonzalo</author>
<author>F Verdejio</author>
<author>C Peters</author>
<author>N Calzolari</author>
</authors>
<title>Applying eurowordnet to crosslanguage text retrieval.</title>
<date>1998</date>
<journal>Computers and Humanities,</journal>
<pages>32--2</pages>
<contexts>
<context position="1476" citStr="Gonzalo et al., 1998" startWordPosition="215" endWordPosition="218">t investigation in Word Sense Disambiguation (WSD) at ITC-irst focuses on the role of domain information. The hypothesis is that domain labels (such as MEDICINE, ARCHITECTURE and SPORT) provide a natural and powerful way to establish semantic relations among word senses, which can be profitably used during the disambiguation process. In particular, domains constitute a fundamental feature of text coherence, such that word senses occurring in a coherent portion of text tend to maximize domain similarity. The importance of domain information in WSD has been remarked in several works, including (Gonzalo et al., 1998) and (Buitelaar and Sacaleanu, 2001). In (Magnini and Strapparava, 2000) we introduced &amp;quot;Word Domain Disambiguation&amp;quot; (WDD) as a variant of WSD where for each word in a text a domain label (among those allowed by the word) has to be chosen instead of a sense label. We also argued that WDD can be applied to disambiguation tasks that do not require fine grained sense distinctions, such as information retrieval and content-based user modeling. For SENSEVAL2 the goal was to evaluate the role of domain information in WSD: no other syntactic or semantic information has been used (e.g. semantic relatio</context>
</contexts>
<marker>Gonzalo, Verdejio, Peters, Calzolari, 1998</marker>
<rawString>J. Gonzalo, F. Verdejio, C. Peters, and N. Calzolari. 1998. Applying eurowordnet to crosslanguage text retrieval. Computers and Humanities, 32(2-3):185-207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>G Cavaglia</author>
</authors>
<title>Integrating subject field codes into WordNet.</title>
<date>2000</date>
<booktitle>In Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation,</booktitle>
<location>Athens, Greece,</location>
<contexts>
<context position="2813" citStr="Magnini and Cavaglia, 2000" startWordPosition="434" endWordPosition="437">istical techniques, for the three tasks we participated in, i.e. English &apos;all words&apos;, English &apos;lexical sample&apos; and Italian &apos;lexical sample&apos;. The main lexical resource for domains is &amp;quot;WordNet Domains&amp;quot;, an extension of English Wordnet 1.6 (Fellbaum, 1998) developed at ITC-irst, where synsets have been annotated with domain information. 2 WordNet Domains The basic lexical resource we used in SENSEVAL2 is &amp;quot;WordNet Domains&amp;quot;, an extension of WORDNET 1.6 where each synset has been annotated with at least one domain label, selected from a set of about two hundred labels hierarchically organized (see (Magnini and Cavaglia, 2000) for the annotation methodology and for the evaluation of the resource). The information from the domains that we added is complementary to what is already in WORDNET. First of all a domain may include synsets of different syntactic categories: for instance MEDICINE groups together senses from Nouns, such as doctor#1 and hospital#1, and from Verbs such as operate#7. Second, a domain may include senses from different WORDNET sub-hierarchies (i.e. deriving from different &amp;quot;unique beginners&amp;quot; or from different &amp;quot;lexicographer files&amp;quot;). For example, SPORT contains senses such as athlete#1, deriving fr</context>
<context position="11725" citStr="Magnini and Cavaglia, 2000" startWordPosition="1999" endWordPosition="2002">ample (coarse g.) .720 .269 Italian Lexical Sample (fine g.) .375 .371 Table 2: Final results of ITC-irst systems at SENSEVAL-2 113 4.1 English &apos;All Words&apos; The &apos;all words&apos; task seems to benefit from the domain approach. One reason for this is that texts are enough long to provide art accurate context (as mentioned in section 3.3, we used a window of 100 content words around the target word) within which domains are coherent. The rather low degree of recall reflects the fact that few words in a text carry relevant domain information. Most of the words actually behave such as a &amp;quot;factotum&amp;quot; (see (Magnini and Cavaglia, 2000) for a preliminary discussion on this problem) that can equally occur in almost every domain. Some words lie outside the domain approach and their senses could be captured with the integration of local (e.g. syntactic) information. 4.2 English &apos;Lexical Sample&apos; From the point of view of domain driven disambiguation, the &apos;lexical sample&apos; task was inherently more difficult than the &apos;all words&apos; task for two reasons. First the context provided for disambiguation was generally shorter than the 100 words we used to build a semantic vector. Second, the high number of &amp;quot;factotum&amp;quot; words to be disambiguat</context>
</contexts>
<marker>Magnini, Cavaglia, 2000</marker>
<rawString>B. Magnini and G. Cavaglia. 2000. Integrating subject field codes into WordNet. In Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation, Athens, Greece, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>C Strapparava</author>
</authors>
<title>Experiments in word domain disambiguation for parallel texts.</title>
<date>2000</date>
<booktitle>In Proc. of SIGLEX Workshop on Word Senses and Multi-linguality, HongKong,</booktitle>
<contexts>
<context position="1548" citStr="Magnini and Strapparava, 2000" startWordPosition="225" endWordPosition="228">focuses on the role of domain information. The hypothesis is that domain labels (such as MEDICINE, ARCHITECTURE and SPORT) provide a natural and powerful way to establish semantic relations among word senses, which can be profitably used during the disambiguation process. In particular, domains constitute a fundamental feature of text coherence, such that word senses occurring in a coherent portion of text tend to maximize domain similarity. The importance of domain information in WSD has been remarked in several works, including (Gonzalo et al., 1998) and (Buitelaar and Sacaleanu, 2001). In (Magnini and Strapparava, 2000) we introduced &amp;quot;Word Domain Disambiguation&amp;quot; (WDD) as a variant of WSD where for each word in a text a domain label (among those allowed by the word) has to be chosen instead of a sense label. We also argued that WDD can be applied to disambiguation tasks that do not require fine grained sense distinctions, such as information retrieval and content-based user modeling. For SENSEVAL2 the goal was to evaluate the role of domain information in WSD: no other syntactic or semantic information has been used (e.g. semantic relations in WoRDNET) except domain labels. Three systems have been implemented</context>
<context position="6204" citStr="Magnini and Strapparava, 2000" startWordPosition="1006" endWordPosition="1009">ill unassigned synsets with domain labels. As far as the Italian wordnet is concerned the same procedure used for the WORD NET 1.7 mapping has been applied to WORDNET 1.5, resulting in the annotation of the Interlingual Index. Then the equivalence links (we excluded eq_hyperonym and eq_hyphonym) from the ILI to the Italian synsets were used to bring the domain information to Italian words. There was no time for a complete evaluation of the quality of the mapping procedures. 3 Algorithms The starting point in the algorithm design was the previous work in word domain disambiguation reported in (Magnini and Strapparava, 2000). One drawback of that approach is that, for rather long texts, it does not consider domain variations. To overcome this problem we have introduced contexts within which domains are calculated. A second direction of work has been the acquisition of domain information from annotated texts (i.e. Semcor and the training data). The following sections presents details of the disambiguation procedures implemented for SENSEVAL-2. 3.1 Linguistic Processing XML files made available by the task organizers have been processed with an XML parser. As for lemmatization and part-of-speech tagging the Tree Ta</context>
</contexts>
<marker>Magnini, Strapparava, 2000</marker>
<rawString>B. Magnini and C. Strapparava. 2000. Experiments in word domain disambiguation for parallel texts. In Proc. of SIGLEX Workshop on Word Senses and Multi-linguality, HongKong, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing.</booktitle>
<contexts>
<context position="6865" citStr="Schmid, 1994" startWordPosition="1107" endWordPosition="1108">her long texts, it does not consider domain variations. To overcome this problem we have introduced contexts within which domains are calculated. A second direction of work has been the acquisition of domain information from annotated texts (i.e. Semcor and the training data). The following sections presents details of the disambiguation procedures implemented for SENSEVAL-2. 3.1 Linguistic Processing XML files made available by the task organizers have been processed with an XML parser. As for lemmatization and part-of-speech tagging the Tree Tagger, developed at the University of Stuttgart (Schmid, 1994) has been used, both for English and Italian. The WordNet morphological analyser has also been used in order to resolve ambiguities and lemmatization mistakes. After this process texts are represented as vectors of triples: word lemma, WORD NET part of speech and position in the text. 3.2 Scoring Domains for a Lemma The basic procedure in domain driven disambiguation is a function that, given a lemma L, 112 associates a score to each domain defined for that lemma in Wordnet Domains. Such a score is the relative frequency of the domain in L, computed on the basis of the occurrences of the synse</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>H. Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International Conference on New Methods in Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<date>1998</date>
<booktitle>Special issue on eurowordnet. &apos;Computers and Humanities,</booktitle>
<pages>32</pages>
<contexts>
<context position="5318" citStr="Vossen, 1998" startWordPosition="859" endWordPosition="860"> pile...) GEOLOGY #8 bank (the funds ECONOMY, held by a gam- PLAY bling house...) #9 bank, cant, cam- ARCHITECTURE - ber (a slope in the turn of a road...) #10 bank (a flight ma- TRANSPORT neuver... ) Table 1: WORD NET senses, domains and occurrences in Semcor for the word &amp;quot;bank&amp;quot; Two mapping procedures have been implemented for SENSEVAL-2 in order to use domain information. For the English tasks a mapping from WORDNET 1.6 to the WORDNET 1.7 pre-release made available to participants; for the Italian task a mapping from WORDNET 1.6 to WORDNET 1.5, because the interlingual index of EuroWordNet (Vossen, 1998) is in that version. The mapping to WORDNET 1.7 is based on a set of heuristics (e.g. correspondences between synonyms, glosses and hypernyms) which discover corresponding synset pairs. Then, an inheritance algorithm is applied to WORDNET 1.7 in order to fill unassigned synsets with domain labels. As far as the Italian wordnet is concerned the same procedure used for the WORD NET 1.7 mapping has been applied to WORDNET 1.5, resulting in the annotation of the Interlingual Index. Then the equivalence links (we excluded eq_hyperonym and eq_hyphonym) from the ILI to the Italian synsets were used t</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>P. Vossen. 1998. Special issue on eurowordnet. &apos;Computers and Humanities, 32.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>