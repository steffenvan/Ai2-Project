<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.510581">
<title confidence="0.987747">
UoM: Using Explicit Semantic Analysis for Classifying Sentiments
</title>
<author confidence="0.994419">
Sapna Negi
</author>
<affiliation confidence="0.998205">
University of Malta
</affiliation>
<address confidence="0.893022">
Msida, MSD2080, MALTA
</address>
<email confidence="0.996781">
sapna.negi13@gmail.com
</email>
<author confidence="0.989221">
Mike Rosner
</author>
<affiliation confidence="0.995899">
University of Malta
</affiliation>
<address confidence="0.892824">
Msida, MSD2080, MALTA
</address>
<email confidence="0.998578">
mike.rosner@um.edu.mt
</email>
<sectionHeader confidence="0.995637" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999404545454545">
In this paper, we describe our system sub-
mitted for the Sentiment Analysis task at Se-
mEval 2013 (Task 2). We implemented a com-
bination of Explicit Semantic Analysis (ESA)
with Naive Bayes classifier. ESA represents
text as a high dimensional vector of explicitly
defined topics, following the distributional se-
mantic model. This approach is novel in the
sense that ESA has not been used for Senti-
ment Analysis in the literature, to the best of
our knowledge.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99991995">
Semantic relatedness measure gives the comparison
of different terms or texts on the basis of their
meaning or the content. For instance, it can be
said that the word ”computer” is semantically
more related to ”laptop” than ”flute”. Sentiment
analysis refers to the task of determining the overall
contextual polarity of the written text. In this paper,
we propose the use of semantic relatedness models,
specifically Explicit Semantic Analysis (ESA),
to identify textual polarity. There are different
approaches to model semantic relatedness like
WordNet based models (Baner ee and Baner ee,
2002), distributional semantic models (DSMs) etc.
DSMs follow the distributional hypothesis, which
says that words occurring in the same contexts tend
to have similar meanings (Harris, 1954). There-
fore, considering sentiment classification problem,
distributional hypothesis suggests that the words or
phrases referring to positive polarity would tend to
co-occur, and similar assumptions can be made for
</bodyText>
<page confidence="0.97502">
535
</page>
<bodyText confidence="0.996577421052632">
the negative terms.
DSMs generally utilize large textual corpora to
extract the distributional information relying on
the co-occurrence information and distribution of
the terms. These models represent the text in the
form of high-dimensional vectors highlighting the
co-occurrence information. Semantic relatedness
between two given texts is calculated by using
these vectors, thus, following that the the semantic
meaning of a text can be inferred from its usage
in different contexts. There are several different
computational models following distributional
semantics hypothesis. Latent Semantic Analysis
(LSA), Latent Dirichlet Allocation (LDA) (Blei et.
al., 2003), Explicit Semantic Analysis (ESA) are
some examples of such models. However, in this
work, we investigated the use of ESA for the given
task of sentiment analysis (SA).
There are two sub-tasks defined in Task 2 at
SemEval 2013 (SemEval, 2013). We participated in
Message Polarity Classification sub-task, where we
are required to automatically classify the sentiment
of a given message into positive, negative, or
neutral. The task deals with the short texts coming
from Twitter and SMS (Short Message Service). We
are provided with 8,000 - 12,000 twitter messages
annotated with their sentiment label for the purpose
of training the models. In this work, we present our
approach for sentiment classification which uses a
combination of ESA and Naive Bayes classifier. The
rest of the paper is structured as follows : Section 2
discusses some related work in this context. Section
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 535–538, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
3 briefly explains ESA. Section 4 describes our
approaches while Section 5 explains the submitted
runs for our system to the task. Section 6 reports the
results, and we conclude in section 7.
</bodyText>
<sectionHeader confidence="0.998368" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999994">
The research in SA initiated with the classical ma-
chine learning algorithms like Naive Bayes, Maxi-
mum Entropy etc. using intuitive features like un-
igrams, bigrams, parts of speech information, posi-
tion of words, adjectives etc. (Pang et. al., 2002).
However, such approaches are heavily dependent
upon the given training data, and therefore can be
very limited for SA due to out of vocabulary words
and phrases, and different meanings of words in
different contexts (Pang and Lee, 2008). Due to
these problems, several methods have been investi-
gated to use some seed words for extracting more
positive and negative terms with the help of lexi-
cal resources like WordNet etc., for instance, Senti-
WordNet, which defines the polarity of the word
along with the intensity. In this paper, we model the
sentiment classification using DSMs based on ex-
plicit topic models (Cimiano et. al., 2009), which
incorporate correlation information from a corpus
like Wikipedia, to generalize from a few known pos-
itive or negative terms. There have been some other
attempts to utilize topic models in this regards, but
they mainly focussed on latent topic models (Lin and
He, 2009) (Maas et. al., 2011). Joint sentiment topic
model introduced LDA based unsupervised topic
models in sentiment analysis by pointing out that
sentiments are often topic dependent because same
word/phrase could represent different sentiments for
different topics (Lin and He, 2009). The recent work
by Maas et. al. (Maas et. al., 2011) on using latent
concept models presented a mixture model of un-
supervised and supervised techniques to learn word
vectors capturing semantic term-document informa-
tion along with the sentiment content.
</bodyText>
<sectionHeader confidence="0.996953" genericHeader="method">
3 Explicit Semantic Analysis
</sectionHeader>
<bodyText confidence="0.998861714285715">
Explicit Semantic Analysis (ESA) is a technique
for computing semantic relatedness between texts
using distributional information (Gabrilovich and
Markovitch, 2007). ESA represents text as vec-
tors of concepts explicitly defined by humans, like
Wikipedia articles. This provides an intuitive and
easily understandable topic space for humans, in
contrast to the latent topic space in latent mod-
els.Input texts are represented as multidimensional
vectors of weighted concepts. The procedure of
computing semantic relatedness involves comparing
the vectors corresponding to the given texts e.g. us-
ing cosine product. The magnitude of each dimen-
sion in the vector is the associativity weight of the
text to that explicit concept/dimension. To quantify
this associativity, the textual content related to the
explicit concept/dimension is utilized. This weight
can be calculated by considering different methods,
for instance, tf-idf score. ESA has been proved to
be a generalized vector space model (Gottron et. al.,
2011).
</bodyText>
<sectionHeader confidence="0.999599" genericHeader="method">
4 Methodology
</sectionHeader>
<bodyText confidence="0.9999889">
We implemented a combination of traditional ma-
chine learning based approach for SA using Naive
Bayes algorithm, and ESA based sentiment identifi-
cation. To perform sentiment classification solely
using ESA, we asses the similarity of a new text
against the text whose sentiment is already known,
using ESA. More similar is a text to a particular sen-
timent annotated text, better are its chances to be-
long to the same sentiment class. On the other hand,
we followed a standard classification approach by
learning Naive Bayes over the given training data.
Finally, we consult both ESA and Naive Bayes for
classifying the text. The overall probability of a text
belonging to a particular sentiment class was deter-
mined by weighted sum of ESA similarity score,
and the scores given by Naive Bayes classifier. The
sentiment class with the highest total score was ac-
cepted as the sentiment of the input text. The indi-
vidual weights of ESA and Naive Bayes were deter-
mined by linear regression for our experiments.
</bodyText>
<sectionHeader confidence="0.994956" genericHeader="method">
5 System Description
</sectionHeader>
<bodyText confidence="0.999762">
We created three bags of words (BOW) correspond-
ing to the different sentiment classes (positive,
negative, and neutral) annotated in the training
data. These BOWs were used as the definition of
the particular sentiment class for making the ESA
comparisons, and for learning Naive Bayes. We
used unigrams and bigrams as features for the Naive
</bodyText>
<page confidence="0.996634">
536
</page>
<table confidence="0.9918545">
Task Approach F score Highest F score Rank
Twitter, with constrained data ESA with Naive Bayes .5182 .6902 24/35
SMS, with constrained data ESA with Naive Bayes .422 .6846 24/28
Twitter, with unconstrained data ESA with Naive Bayes .4507 .6486 16/16
SMS, with unconstrained data ESA with Naive Bayes .3522 .4947 15/15
Twitter, with constrained data ESA .35 .6902 NA
</table>
<tableCaption confidence="0.99987">
Table 1: Results
</tableCaption>
<bodyText confidence="0.996589363636364">
Bayes algorithm. The ESA implementation was
replicated from the version available on Github1,
replacing the Wikipedia dump by the version
released in February 2013.
We submitted two runs each for Twitter and
SMS test data. The first run (constrained) used
only the provided training data for learning while
the second run (unconstrained) used a combination
of external training data coming from the popular
movie review dataset (Pang et. al., 2002), and the
data provided with the task.
</bodyText>
<sectionHeader confidence="0.998642" genericHeader="evaluation">
6 Results and discussion
</sectionHeader>
<bodyText confidence="0.999982384615385">
The first four entries provided in the table 1 corre-
spond to the four runs submitted in SemEval-2013
Task 2. The fifth entry corresponds to the results
of a separate experiment performed by us, to esti-
mate the influence of ESA on SA. According to the
F-scores, ESA is unable to identify the sentiment in
the texts following the mentioned approach. The re-
sults suggest that combining Naive Bayes to the sys-
tem improved the overall scores. However, even the
combined system could not perform well. Also, the
mixing of external data lowered the scores indicat-
ing incompatibility of the external training data with
the provided data.
</bodyText>
<sectionHeader confidence="0.990778" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999710428571429">
We presented an approach of using ESA for senti-
ment classification. The submitted system follow
a combination of standard Naive Bayes model and
ESA based classification. The results of the task
suggests that the approach we used for ESA based
classification is unable to identify the sentiment ac-
curately. As a future step, we plan to investigate
</bodyText>
<footnote confidence="0.901457">
1https://github.com/kasooja/clesa
</footnote>
<bodyText confidence="0.999871">
more on the usability of ESA for sentiment classifi-
cation, for instance, by using suitable features in the
concept definitions, and weighing them according to
the different sentiment classes.
</bodyText>
<sectionHeader confidence="0.998942" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998655">
Maas, A.L., Daly, R.E., Pham, P.T., Huang, D., Ng, A.Y.,
Potts, C.: Learning word vectors for sentiment anal-
ysis. In: Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies - Volume 1. pp. 142–150.
HLT ’11, Association for Computational Linguistics,
Stroudsburg, PA, USA (2011), http://dl.acm.
org/citation.cfm?id=2002472.2002491
Lin, C., He, Y.: Joint sentiment/topic model for sen-
timent analysis. In: Proceedings of the 18th ACM
conference on Information and knowledge manage-
ment. pp. 375–384. CIKM ’09, ACM, New York, NY,
USA (2009), http://doi.acm.org/10.1145/
1645953.1646003
Cimiano, P., Schultz, A., Sizov, S., Sorg, P., Staab,
S.: Explicit versus latent concept models for cross-
language information retrieval. In: Proceedings of
the 21st international jont conference on Artifi-
cal intelligence. pp. 1513–1518. IJCAI’09, Mor-
gan Kaufmann Publishers Inc., San Francisco, CA,
USA (2009), http://dl.acm.org/citation.
cfm?id=1661445.1661688
Pang, B., Lee, L.: Opinion mining and sentiment analy-
sis. Found. Trends Inf. Retr. 2(1-2), 1–135 (Jan 2008),
http://dx.doi.org/10.1561/1500000011
Pang, B., Lee, L., Vaithyanathan, S.: Thumbs up?:
sentiment classification using machine learning tech-
niques. In: Proceedings of the ACL-02 conference
on Empirical methods in natural language process-
ing - Volume 10. pp. 79–86. EMNLP ’02, Associa-
tion for Computational Linguistics, Stroudsburg, PA,
USA (2002), http://dx.doi.org/10.3115/
1118693.1118704
Wilson, T., Kozareva, Z., Nakov, P., Rosenthal, S., Stoy-
anov, V., Ritter, A.: SemEval-2013 task 2: Sentiment
</reference>
<page confidence="0.972622">
537
</page>
<reference confidence="0.999894615384615">
analysis in twitter. In: Proceedings of the International
Workshop on Semantic Evaluation. SemEval ’13 (June
2013)
Banerjee, S., Banerjee, S.: An adapted lesk algorithm for
word sense disambiguation using wordnet. In: In Pro-
ceedings of the Third International Conference on In-
telligent Text Processing and Computational Linguis-
tics. pp. 136–145 (2002)
David M. Blei, Andrew Y. Ng, and Michael I. Jordan. La-
tent dirichlet allocation. J. Mach. Learn. Res., 3:993–
1022, March 2003.
P. W. Foltz, W. Kintsch, and T. K. Landauer. The mea-
surement of textual coherence with latent semantic
analysis. Discourse Processes, 25:285–307, 1998.
Evgeniy Gabrilovich and Shaul Markovitch. Computing
semantic relatedness using wikipedia-based explicit
semantic analysis. In In Proceedings of the 20th In-
ternational Joint Conference on Artificial Intelligence,
pages 1606–1611, 2007.
Thomas Gottron, Maik Anderka, and Benno Stein. In-
sights into explicit semantic analysis. In Proceedings
of the 20th ACM international conference on Informa-
tion and knowledge management, CIKM ’11, pages
1961–1964, New York, NY, USA, 2011. ACM.
Zellig Harris. Distributional structure. Word,
10(23):146–162, 1954.
</reference>
<page confidence="0.996806">
538
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.886747">
<title confidence="0.999806">UoM: Using Explicit Semantic Analysis for Classifying Sentiments</title>
<author confidence="0.968885">Sapna</author>
<affiliation confidence="0.999382">University of</affiliation>
<address confidence="0.957327">Msida, MSD2080,</address>
<email confidence="0.999569">sapna.negi13@gmail.com</email>
<author confidence="0.980215">Mike</author>
<affiliation confidence="0.999845">University of</affiliation>
<address confidence="0.98815">Msida, MSD2080,</address>
<email confidence="0.993292">mike.rosner@um.edu.mt</email>
<abstract confidence="0.999429666666667">In this paper, we describe our system submitted for the Sentiment Analysis task at SemEval 2013 (Task 2). We implemented a combination of Explicit Semantic Analysis (ESA) with Naive Bayes classifier. ESA represents text as a high dimensional vector of explicitly defined topics, following the distributional semantic model. This approach is novel in the sense that ESA has not been used for Sentiment Analysis in the literature, to the best of our knowledge.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A L Maas</author>
<author>R E Daly</author>
<author>P T Pham</author>
<author>D Huang</author>
<author>A Y Ng</author>
<author>C Potts</author>
</authors>
<title>Learning word vectors for sentiment analysis. In:</title>
<date>2011</date>
<booktitle>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies -</booktitle>
<volume>1</volume>
<pages>142--150</pages>
<location>Stroudsburg, PA, USA</location>
<marker>Maas, Daly, Pham, Huang, Ng, Potts, 2011</marker>
<rawString>Maas, A.L., Daly, R.E., Pham, P.T., Huang, D., Ng, A.Y., Potts, C.: Learning word vectors for sentiment analysis. In: Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1. pp. 142–150. HLT ’11, Association for Computational Linguistics, Stroudsburg, PA, USA (2011), http://dl.acm. org/citation.cfm?id=2002472.2002491</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lin</author>
<author>Y He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis. In:</title>
<date>2009</date>
<booktitle>Proceedings of the 18th ACM conference on Information and knowledge management.</booktitle>
<pages>375--384</pages>
<publisher>ACM,</publisher>
<location>New York, NY, USA</location>
<contexts>
<context position="4874" citStr="Lin and He, 2009" startWordPosition="743" endWordPosition="746">ated to use some seed words for extracting more positive and negative terms with the help of lexical resources like WordNet etc., for instance, SentiWordNet, which defines the polarity of the word along with the intensity. In this paper, we model the sentiment classification using DSMs based on explicit topic models (Cimiano et. al., 2009), which incorporate correlation information from a corpus like Wikipedia, to generalize from a few known positive or negative terms. There have been some other attempts to utilize topic models in this regards, but they mainly focussed on latent topic models (Lin and He, 2009) (Maas et. al., 2011). Joint sentiment topic model introduced LDA based unsupervised topic models in sentiment analysis by pointing out that sentiments are often topic dependent because same word/phrase could represent different sentiments for different topics (Lin and He, 2009). The recent work by Maas et. al. (Maas et. al., 2011) on using latent concept models presented a mixture model of unsupervised and supervised techniques to learn word vectors capturing semantic term-document information along with the sentiment content. 3 Explicit Semantic Analysis Explicit Semantic Analysis (ESA) is a</context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Lin, C., He, Y.: Joint sentiment/topic model for sentiment analysis. In: Proceedings of the 18th ACM conference on Information and knowledge management. pp. 375–384. CIKM ’09, ACM, New York, NY, USA (2009), http://doi.acm.org/10.1145/ 1645953.1646003</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>A Schultz</author>
<author>S Sizov</author>
<author>P Sorg</author>
<author>S Staab</author>
</authors>
<title>Explicit versus latent concept models for crosslanguage information retrieval. In:</title>
<date>2009</date>
<booktitle>Proceedings of the 21st international jont conference on Artifical intelligence.</booktitle>
<pages>1513--1518</pages>
<publisher>Morgan Kaufmann Publishers Inc.,</publisher>
<location>San Francisco, CA, USA</location>
<marker>Cimiano, Schultz, Sizov, Sorg, Staab, 2009</marker>
<rawString>Cimiano, P., Schultz, A., Sizov, S., Sorg, P., Staab, S.: Explicit versus latent concept models for crosslanguage information retrieval. In: Proceedings of the 21st international jont conference on Artifical intelligence. pp. 1513–1518. IJCAI’09, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA (2009), http://dl.acm.org/citation. cfm?id=1661445.1661688</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<journal>Found. Trends Inf. Retr.</journal>
<volume>2</volume>
<issue>1</issue>
<pages>1--135</pages>
<contexts>
<context position="4198" citStr="Pang and Lee, 2008" startWordPosition="631" endWordPosition="634"> explains the submitted runs for our system to the task. Section 6 reports the results, and we conclude in section 7. 2 Related Work The research in SA initiated with the classical machine learning algorithms like Naive Bayes, Maximum Entropy etc. using intuitive features like unigrams, bigrams, parts of speech information, position of words, adjectives etc. (Pang et. al., 2002). However, such approaches are heavily dependent upon the given training data, and therefore can be very limited for SA due to out of vocabulary words and phrases, and different meanings of words in different contexts (Pang and Lee, 2008). Due to these problems, several methods have been investigated to use some seed words for extracting more positive and negative terms with the help of lexical resources like WordNet etc., for instance, SentiWordNet, which defines the polarity of the word along with the intensity. In this paper, we model the sentiment classification using DSMs based on explicit topic models (Cimiano et. al., 2009), which incorporate correlation information from a corpus like Wikipedia, to generalize from a few known positive or negative terms. There have been some other attempts to utilize topic models in this</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Pang, B., Lee, L.: Opinion mining and sentiment analysis. Found. Trends Inf. Retr. 2(1-2), 1–135 (Jan 2008), http://dx.doi.org/10.1561/1500000011</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques. In:</title>
<date>2002</date>
<booktitle>Proceedings of the ACL-02 conference on Empirical methods in natural language processing -</booktitle>
<volume>10</volume>
<pages>79--86</pages>
<location>Stroudsburg, PA, USA</location>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Pang, B., Lee, L., Vaithyanathan, S.: Thumbs up?: sentiment classification using machine learning techniques. In: Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10. pp. 79–86. EMNLP ’02, Association for Computational Linguistics, Stroudsburg, PA, USA (2002), http://dx.doi.org/10.3115/ 1118693.1118704</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>Z Kozareva</author>
<author>P Nakov</author>
<author>S Rosenthal</author>
<author>V Stoyanov</author>
<author>Ritter</author>
</authors>
<title>A.: SemEval-2013 task 2: Sentiment analysis in twitter. In:</title>
<date>2013</date>
<booktitle>Proceedings of the International Workshop on Semantic Evaluation. SemEval ’13</booktitle>
<marker>Wilson, Kozareva, Nakov, Rosenthal, Stoyanov, Ritter, 2013</marker>
<rawString>Wilson, T., Kozareva, Z., Nakov, P., Rosenthal, S., Stoyanov, V., Ritter, A.: SemEval-2013 task 2: Sentiment analysis in twitter. In: Proceedings of the International Workshop on Semantic Evaluation. SemEval ’13 (June 2013)</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Banerjee</author>
<author>S Banerjee</author>
</authors>
<title>An adapted lesk algorithm for word sense disambiguation using wordnet. In:</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics.</booktitle>
<pages>136--145</pages>
<marker>Banerjee, Banerjee, 2002</marker>
<rawString>Banerjee, S., Banerjee, S.: An adapted lesk algorithm for word sense disambiguation using wordnet. In: In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics. pp. 136–145 (2002)</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<volume>3</volume>
<pages>1022</pages>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993– 1022, March 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Foltz</author>
<author>W Kintsch</author>
<author>T K Landauer</author>
</authors>
<title>The measurement of textual coherence with latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<pages>25--285</pages>
<marker>Foltz, Kintsch, Landauer, 1998</marker>
<rawString>P. W. Foltz, W. Kintsch, and T. K. Landauer. The measurement of textual coherence with latent semantic analysis. Discourse Processes, 25:285–307, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipedia-based explicit semantic analysis. In</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1606--1611</pages>
<contexts>
<context position="5601" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="847" endWordPosition="850">els in sentiment analysis by pointing out that sentiments are often topic dependent because same word/phrase could represent different sentiments for different topics (Lin and He, 2009). The recent work by Maas et. al. (Maas et. al., 2011) on using latent concept models presented a mixture model of unsupervised and supervised techniques to learn word vectors capturing semantic term-document information along with the sentiment content. 3 Explicit Semantic Analysis Explicit Semantic Analysis (ESA) is a technique for computing semantic relatedness between texts using distributional information (Gabrilovich and Markovitch, 2007). ESA represents text as vectors of concepts explicitly defined by humans, like Wikipedia articles. This provides an intuitive and easily understandable topic space for humans, in contrast to the latent topic space in latent models.Input texts are represented as multidimensional vectors of weighted concepts. The procedure of computing semantic relatedness involves comparing the vectors corresponding to the given texts e.g. using cosine product. The magnitude of each dimension in the vector is the associativity weight of the text to that explicit concept/dimension. To quantify this associativit</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. Computing semantic relatedness using wikipedia-based explicit semantic analysis. In In Proceedings of the 20th International Joint Conference on Artificial Intelligence, pages 1606–1611, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Gottron</author>
<author>Maik Anderka</author>
<author>Benno Stein</author>
</authors>
<title>Insights into explicit semantic analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM ’11,</booktitle>
<pages>1961--1964</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA,</location>
<marker>Gottron, Anderka, Stein, 2011</marker>
<rawString>Thomas Gottron, Maik Anderka, and Benno Stein. Insights into explicit semantic analysis. In Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM ’11, pages 1961–1964, New York, NY, USA, 2011. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Distributional structure.</title>
<date>1954</date>
<journal>Word,</journal>
<volume>10</volume>
<issue>23</issue>
<contexts>
<context position="1483" citStr="Harris, 1954" startWordPosition="223" endWordPosition="224">mputer” is semantically more related to ”laptop” than ”flute”. Sentiment analysis refers to the task of determining the overall contextual polarity of the written text. In this paper, we propose the use of semantic relatedness models, specifically Explicit Semantic Analysis (ESA), to identify textual polarity. There are different approaches to model semantic relatedness like WordNet based models (Baner ee and Baner ee, 2002), distributional semantic models (DSMs) etc. DSMs follow the distributional hypothesis, which says that words occurring in the same contexts tend to have similar meanings (Harris, 1954). Therefore, considering sentiment classification problem, distributional hypothesis suggests that the words or phrases referring to positive polarity would tend to co-occur, and similar assumptions can be made for 535 the negative terms. DSMs generally utilize large textual corpora to extract the distributional information relying on the co-occurrence information and distribution of the terms. These models represent the text in the form of high-dimensional vectors highlighting the co-occurrence information. Semantic relatedness between two given texts is calculated by using these vectors, thu</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig Harris. Distributional structure. Word, 10(23):146–162, 1954.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>