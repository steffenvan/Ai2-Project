<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005599">
<title confidence="0.976666">
Spoken Tutorial Dialogue and the Feeling of Another’s Knowing
</title>
<author confidence="0.998442">
Diane Litman Kate Forbes-Riley
</author>
<affiliation confidence="0.887578">
University of Pittsburgh University of Pittsburgh
Pittsburgh, PA 15260 USA Pittsburgh, PA 15260 USA
</affiliation>
<email confidence="0.999181">
litman@cs.pitt.edu forbesk@cs.pitt.edu
</email>
<sectionHeader confidence="0.997391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999873764705882">
We hypothesize that monitoring the accu-
racy of the “feeling of another’s know-
ing” (FOAK) is a useful predictor of tu-
torial dialogue system performance. We
test this hypothesis in the context of a
wizarded spoken dialogue tutoring system,
where student learning is the primary per-
formance metric. We first present our cor-
pus, which has been annotated with re-
spect to student correctness and uncer-
tainty. We then discuss the derivation of
FOAK measures from these annotations,
for use in building predictive performance
models. Our results show that monitoring
the accuracy of FOAK is indeed predictive
of student learning, both in isolation and in
conjunction with other predictors.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977023255814">
Detecting and exploiting knowledge of a speaker’s
uncertainty has been studied in several research
communities. Spoken language researchers have
identified statistically significant relationships be-
tween speaker uncertainty and linguistic proper-
ties of utterances such as prosody and lexical con-
tent (Liscombe et al., 2005; Dijkstra et al., 2006;
Pon-Barry, 2008). Spoken dialogue researchers
in turn are studying whether responding to user
states such as uncertainty can improve system
performance as measured by usability and effi-
ciency (Tsukahara and Ward, 2001; Pon-Barry et
al., 2006; Forbes-Riley and Litman, 2009a). In
the psycholinguistics community, uncertainty has
been studied in the context of metacognitive abil-
ities, e.g. the ability to monitor the accuracy
of one’s own knowledge (“Feeling of Knowing”
(FOK)), and the ability to monitor the FOK of
someone else (“Feeling of Another’s Knowing”
(FOAK)) (Smith and Clark, 1993; Brennan and
Williams, 1995).
Here we take a spoken dialogue systems per-
spective on FOAK, and investigate whether mon-
itoring the accuracy of FOAK is a useful con-
struct for predictive performance modeling. Our
study uses data previously collected with a wiz-
arded spoken dialogue tutoring system, where stu-
dent learning is the primary performance metric.
Section 2 reviews several relevant constructs and
measures from the area of metacognition. Sec-
tion 3 introduces our dialogue corpus and its user
correctness and uncertainty annotations. Section 4
presents our method for measuring monitoring ac-
curacy of FOAK from these annotations, while
Section 5 shows how we use these measures to
build predictive performance models. Our results
show that monitoring the accuracy of FOAK is in-
deed a significant positive predictor of learning,
both in isolation and over and above other predic-
tors. As discussed in Section 6, increasing mon-
itoring accuracy of FOAK is thus one avenue for
also potentially increasing performance, which we
plan to explore in future versions of our system.
</bodyText>
<subsectionHeader confidence="0.528208">
2 Feeling of Another’s Knowing
</subsectionHeader>
<bodyText confidence="0.9986008">
“Feeling of knowing” (FOK) refers to peoples’
ability to accurately monitor their own knowl-
edge, e.g. to know whether they have answered
a question correctly. Psycholinguistics research
has shown that speakers display FOK in conver-
sation using linguistic cues such as filled pauses
and prosody (Smith and Clark, 1993). Of perhaps
more relevance to dialogue systems, research has
also shown that listeners can use the same cues
to monitor the FOK of someone else, i.e. “feel-
</bodyText>
<subsubsectionHeader confidence="0.642449">
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 286–289,
</subsubsectionHeader>
<affiliation confidence="0.938263">
Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics
</affiliation>
<page confidence="0.999554">
286
</page>
<bodyText confidence="0.9977496875">
ing of another’s knowing” (FORK) (Brennan and
Williams, 1995).
To quantify knowledge monitoring, measures of
monitoring accuracy have been proposed. For ex-
ample, consider an FOK experimental paradigm,
where subjects 1) respond to a set of general
knowledge questions, 2) take a FOK survey, judg-
ing whether or not1 they think they would rec-
ognize the answer to each question in a multiple
choice test, and 3) take such a recognition test. As
shown in Figure 1, such data can be summarized in
an array where each cell represents a mutually ex-
clusive option: the row labels represent the possi-
ble FOK judgments (Y/N), while the columns rep-
resent the possible results of the multiple choice
test (Y/N).
</bodyText>
<figure confidence="0.98991025">
Recognition=Y Recognition=N
Judgment=Y a b
Judgment=N c d
Gamma — (a)(d)−(b)(c) (a)(d)+(b)(c) HC = (a+d)−(b+c) (a+d)+(b+c)
</figure>
<figureCaption confidence="0.999979">
Figure 1: Measuring Monitoring Accuracy.
</figureCaption>
<bodyText confidence="0.999979923076923">
Given such an array, the relationship between
the correctness and the judgment of FOK for an-
swers can be measured using the standard formu-
las in Figure 1: Gamma and the Harmann coef-
ficient (HC) measure relative and absolute knowl-
edge monitoring accuracy, respectively. We use
both metrics in the performance modeling exper-
iments described in Section 5, as both measures
have been well studied and there is a lack of con-
sensus regarding their relative benefits (e.g. (Niet-
feld et al., 2006)). Note that both range in value
from -1 (no monitoring accuracy) to 1 (perfect
monitoring accuracy).
</bodyText>
<sectionHeader confidence="0.996667" genericHeader="introduction">
3 Data
</sectionHeader>
<bodyText confidence="0.999925666666666">
This research uses a corpus of 405 dialogues be-
tween 81 students and ITSPOKE-WOZ. The cor-
pus was collected in an experiment showing that
performance improved when ITSPOKE-WOZ re-
sponded to the uncertainty in student answers,
over and above correctness (Forbes-Riley and Lit-
man, 2009a).
ITSPOKE-WOZ is a semi-automatic version
of ITSPOKE (Intelligent Tutoring SPOKEn di-
alogue system), which is a speech-enhanced ver-
sion of the Why2-Atlas qualitative physics tu-
tor (VanLehn et al., 2002). Recent versions of
</bodyText>
<footnote confidence="0.413292">
1Likert scale rating schemes are also possible.
</footnote>
<bodyText confidence="0.921639307692308">
ITSPOKE have also been enhanced to detect and
respond to student uncertainty, by parameterizing
the dialogue manager so that it can adapt con-
tingently based on student correctness and/or un-
certainty (to test various ways of responding to
uncertainty). In ITSPOKE-WOZ, a few compo-
nents (speech recognition, language understand-
ing, and uncertainty detection) have been replaced
by a human “wizard”, to test the upper-bound per-
formance of adapting to uncertainty in a spoken
dialogue system (i.e. without the noise introduced
by speech and language processing).
The experimental procedure was as follows:
Students (1) read background material, (2) took
a multiple-choice pretest, (3) worked through five
problems with ITSPOKE-WOZ (1 per dialogue),
(4) took a survey, and (5) took a posttest simi-
lar to the pretest. Each student turn in the cor-
pus was annotated2 in real-time by the wizard dur-
ing the experiment, using binary tags representing
student Uncertainty (uncertain (U), nonuncertain
(nonU)) and student Correctness (correct (C), in-
correct (I)). Figure 2 shows an annotated dialogue
excerpt.
ITSPOKE-WOZ6: Now let’s find the forces exerted on the
car in the VERTICAL direction during the collision. First,
what vertical force is always exerted on an object near the
surface of the earth?
USER6: gravity (nonU,C)
ITSPOKE-WOZ7: Fine. In addition to the downward force
of gravity, one other force is exerted on the car in the VER-
TICAL direction during the collision. We haven’t discussed
this force yet, because we only dealt with freefalling objects
before this problem. But you may recall this other vertical
force from the reading. What is it?
USER7: um ... the friction from the air ... or the wind (U,I)
ITSPOKE-WOZs: Great try, but I think you know there’s
a mistake in your answer. Let’s work it out. We know that
gravity can’t be the only vertical force on the car, because ...
</bodyText>
<figureCaption confidence="0.992129">
Figure 2: Annotated Corpus Excerpt.
</figureCaption>
<sectionHeader confidence="0.997572" genericHeader="method">
4 Predictors
</sectionHeader>
<bodyText confidence="0.999391857142857">
To derive our performance models, we use
posttest score as the dependent measure, and in-
clude pretest score among the independent mea-
sures. This allows us to measure learning gain,
not just final test score. We also include addi-
tional independent measures computed from the
wizard’s uncertainty and correctness annotations,
</bodyText>
<footnote confidence="0.97299275">
2In prior ITSPOKE corpora, this wizard displayed in-
terannotator agreement of 0.85 and 0.62 Kappa on correct-
ness and uncertainty, respectively (Forbes-Riley and Litman,
2008).
</footnote>
<page confidence="0.992913">
287
</page>
<bodyText confidence="0.8860475">
as detailed below. Note that all measures are com-
puted on a per student basis (over all 5 dialogues).
Table 1 shows means and standard deviations of
all measures across all 81 students.
</bodyText>
<table confidence="0.999587142857143">
Measure Mean Std. Dev.
pretest .51 .15
posttest .75 .14
%C .79 .09
%U .23 .11
Gamma .77 .17
HC .59 .16
</table>
<tableCaption confidence="0.9996">
Table 1: Descriptive Corpus Statistics.
</tableCaption>
<bodyText confidence="0.99979685">
The percentage of student turns annotated as
correct (%C) and as uncertain (%U) normalize
the raw counts of the wizard’s C and U annota-
tions. Similar measures predict learning in prior
experiments by ourselves and others (e.g (Litman
et al., 2009)) and thus serve as useful baselines.
In our corpus, 79% of a student’s turns are an-
swered correctly on average, while 77% are an-
swered without uncertainty.
The monitoring accuracy measures Gamma
and HC were introduced in Section 2. To con-
struct an array like that shown in Figure 1, we
map the first and second rows to our uncertainty
annotations NonU and U, and map the columns to
our correctness annotations C and I. In (Dijkstra
et al., 2006), high and low FOK/FOAK judgments
are similarly associated with speaker certainty and
uncertainty, respectively. Note that in our annota-
tion scheme, NonU answers are either certain or
neutral.
</bodyText>
<sectionHeader confidence="0.999507" genericHeader="method">
5 Results: Predicting Student Learning
</sectionHeader>
<bodyText confidence="0.999665157894737">
Given the above measures, our first prediction ex-
periment measures the partial Pearson’s correla-
tion between each of the independent measures
and posttest, after first controlling for pretest to
account for learning gain. Our goal here is exam-
ine the predictive utility of the correctness, uncer-
tainty, and monitoring dimensions in isolation.
Table 2 shows the statistically significant results
of the partial correlations. The table shows the in-
dependent measure, the corresponding Pearson’s
Correlation Coefficient (R), and the significance of
the correlation (p). As can be seen, both monitor-
ing measures are positively correlated with learn-
ing, with HC providing better predictive utility
than Gamma. However, %C is even more pre-
dictive of learning than either monitoring measure.
Interestingly, the uncertainty measure %U in and
of itself does not show predictive utility in this
data.
</bodyText>
<table confidence="0.97595225">
Measure R p
%C .52 .00
Gamma .36 .00
HC .42 .00
</table>
<tableCaption confidence="0.8946845">
Table 2: Partial Correlations with Posttest (p &lt;
.05).
</tableCaption>
<bodyText confidence="0.99907055">
Our second prediction experiment uses PAR-
ADISE to build a learning model that can po-
tentially include multiple independent measures.
As in prior PARADISE applications (e.g. (M¨oller,
2005)), we train the models using stepwise mul-
tiple linear regression, which automatically deter-
mines the measures to include in the model. Our
goal here is to explore whether monitoring accu-
racy provides any added value to our correctness
and uncertainty measures.
When all measures are made available for pre-
dicting learning, we see that monitoring accuracy
as measured by HC does add value over and above
correctness: the stepwise procedure includes HC
in the model, as it significantly accounts for more
variance than just including %C and pretest. In
particular, the application of PARADISE shows
that the following performance function provides
the best significant training fit to our data (R2 =
.71, p &lt; .01):
</bodyText>
<equation confidence="0.935667">
postest = .44*%C + .21*pretest + .20*HC
</equation>
<bodyText confidence="0.999984785714286">
The equation shows each selected measure and its
(standardized) weight; larger weights indicate pa-
rameters with greater relative predictive power in
accounting for posttest variance. %C is signifi-
cant at p &lt; .01, while pretest and HC are each
significant at p &lt; .05, with the coefficients all pos-
itive. Like the correlations, our regression demon-
strates the predictive utility of the accuracy and
monitoring measures, but not the uncertainty mea-
sure. The model further shows that while correctly
answering the system’s questions (%C) is predic-
tive of learning, also including FOAK monitoring
accuracy (HC) significantly increases the model’s
predictive power.
</bodyText>
<sectionHeader confidence="0.992015" genericHeader="conclusions">
6 Conclusion and Future Directions
</sectionHeader>
<bodyText confidence="0.998319333333333">
This paper explores whether knowledge monitor-
ing accuracy is a useful construct for understand-
ing dialogue system performance. In particular,
</bodyText>
<page confidence="0.993696">
288
</page>
<bodyText confidence="0.999971161290322">
we demonstrate the utility of combining previ-
ously studied correctness and uncertainty annota-
tions, using a measure of FOAK monitoring ac-
curacy. Our results show that while the correct-
ness of a user’s response predicts learning, the un-
certainty with which a user conveys a response
does not. In contrast, the ability to monitor FOAK
accuracy predicts learning, in isolation and over
and above correctness. We believe that monitor-
ing accuracy will be a relevant construct for other
dialogue applications involving knowledge asym-
metry, such as problem solving, instruction giv-
ing, and trouble shooting (e.g. (Janarthanam and
Lemon, 2008)).
In future work we plan to use our results to in-
form a modification of our system aimed at im-
proving inferred user knowledge monitoring abil-
ities; we will better measure such improvements
by incorporating FOK ratings into our testing. In
addition, we recently found interactions between
learning and both user domain expertise and gen-
der (Forbes-Riley and Litman, 2009b); we will
investigate whether similar interactions extend to
knowledge monitoring metrics. Since our corpus
contains dialogues with both uncertainty-adaptive
and non-adaptive versions of ITSPOKE-WOZ, we
also plan to examine whether differing dialogue
strategies influence the learned predictive models.
Finally, we plan to replicate our analyses in a di-
alogue corpus we recently collected using a fully
automated version of our system.
</bodyText>
<sectionHeader confidence="0.997366" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998739666666667">
NSF #0631930 supports this work. We thank H.
Ai, P. Jordan, and the reviewers for helpful com-
ments.
</bodyText>
<sectionHeader confidence="0.994908" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.979050629032258">
S. E. Brennan and M. Williams. 1995. The feeling
of another’s knowing: Prosody and filled pauses as
cues to listeners about the metacognitive states of
speakers. Journal of Memory and Language.
C. Dijkstra, E. Krahmer, and M. Swerts. 2006. Ma-
nipulating uncertainty: The contribution of different
audiovisual prosodic cues to the perception of confi-
dence. In Proc. Speech Prosody.
K. Forbes-Riley and D. J. Litman. 2008. Analyz-
ing dependencies between student certainness states
and tutor responses in a spoken dialogue corpus. In
L. Dybkjaer and W. Minker, editors, Recent Trends
in Discourse and Dialogue. Springer.
K. Forbes-Riley and D. Litman. 2009a. Adapting to
student uncertainty improves tutoring dialogues. In
Proc. Intl. Conf. on Artificial Intelligence in Educa-
tion.
K. Forbes-Riley and D. Litman. 2009b. A user
modeling-based performance analysis of a wizarded
uncertainty-adaptive dialogue system corpus. In
Proc. Interspeech, Brighton, UK, September.
S. Janarthanam and O. Lemon. 2008. User simulations
for online adaptation and knowledge-alignment in
troubleshooting dialogue systems. In Proc. SEM-
dial.
J. Liscombe, J. Venditti, and J. Hirschberg. 2005. De-
tecting certainness in spoken tutorial dialogues. In
Proc. Interspeech.
D. Litman, J. Moore, M. Dzikovska, and E. Farrow.
2009. Using natural language processing to analyze
tutorial dialogue corpora across domains and modal-
ities. In Proc. Intl. Conf. on Artificial Intelligence in
Education.
S. M¨oller. 2005. Parameters for quantifying the in-
teraction with spoken dialogue telephone services.
In Proc. SIGdial Workshop on Discourse and Dia-
logue.
J. L. Nietfeld, C. K. Enders, and G. Schraw. 2006. A
Monte Carlo comparison of measures of relative and
absolute monitoring accuracy. Educational and Psy-
chological Measurement.
H. Pon-Barry, K. Schultz, E. O. Bratt, B. Clark, and
S. Peters. 2006. Responding to student uncertainty
in spoken tutorial dialogue systems. Intl. Journal of
Artificial Intelligence in Education.
H. Pon-Barry. 2008. Prosodic manifestations of confi-
dence and uncertainty in spoken language. In Proc.
Interspeech.
V. L. Smith and H. H. Clark. 1993. On the course of
answering questions. Journal of Memory and Lan-
guage.
W. Tsukahara and N. Ward. 2001. Responding to sub-
tle, fleeting changes in the user’s internal state. In
Proc. SIG-CHI on Human factors in computing sys-
tems.
K. VanLehn, P. W. Jordan, C. Ros´e, D. Bhembe,
M. B¨ottner, A. Gaydos, M. Makatchev, U. Pap-
puswamy, M. Ringenberg, A. Roque, S. Siler, R. Sri-
vastava, and R. Wilson. 2002. The architecture of
Why2-Atlas: A coach for qualitative physics essay
writing. In Proc. Intl. Conf. on Intelligent Tutoring
Systems.
</reference>
<page confidence="0.998619">
289
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.944576">
<title confidence="0.999052">Spoken Tutorial Dialogue and the Feeling of Another’s Knowing</title>
<author confidence="0.998371">Diane Litman Kate Forbes-Riley</author>
<affiliation confidence="0.999989">University of Pittsburgh University of Pittsburgh</affiliation>
<address confidence="0.974384">Pittsburgh, PA 15260 USA Pittsburgh, PA 15260 USA</address>
<email confidence="0.999815">litman@cs.pitt.eduforbesk@cs.pitt.edu</email>
<abstract confidence="0.998390777777778">We hypothesize that monitoring the accuracy of the “feeling of another’s knowing” (FOAK) is a useful predictor of tutorial dialogue system performance. We test this hypothesis in the context of a wizarded spoken dialogue tutoring system, where student learning is the primary performance metric. We first present our corpus, which has been annotated with respect to student correctness and uncertainty. We then discuss the derivation of FOAK measures from these annotations, for use in building predictive performance models. Our results show that monitoring the accuracy of FOAK is indeed predictive of student learning, both in isolation and in conjunction with other predictors.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S E Brennan</author>
<author>M Williams</author>
</authors>
<title>The feeling of another’s knowing: Prosody and filled pauses as cues to listeners about the metacognitive states of speakers.</title>
<date>1995</date>
<journal>Journal of Memory and Language.</journal>
<contexts>
<context position="1905" citStr="Brennan and Williams, 1995" startWordPosition="278" endWordPosition="281"> 2006; Pon-Barry, 2008). Spoken dialogue researchers in turn are studying whether responding to user states such as uncertainty can improve system performance as measured by usability and efficiency (Tsukahara and Ward, 2001; Pon-Barry et al., 2006; Forbes-Riley and Litman, 2009a). In the psycholinguistics community, uncertainty has been studied in the context of metacognitive abilities, e.g. the ability to monitor the accuracy of one’s own knowledge (“Feeling of Knowing” (FOK)), and the ability to monitor the FOK of someone else (“Feeling of Another’s Knowing” (FOAK)) (Smith and Clark, 1993; Brennan and Williams, 1995). Here we take a spoken dialogue systems perspective on FOAK, and investigate whether monitoring the accuracy of FOAK is a useful construct for predictive performance modeling. Our study uses data previously collected with a wizarded spoken dialogue tutoring system, where student learning is the primary performance metric. Section 2 reviews several relevant constructs and measures from the area of metacognition. Section 3 introduces our dialogue corpus and its user correctness and uncertainty annotations. Section 4 presents our method for measuring monitoring accuracy of FOAK from these annota</context>
<context position="3746" citStr="Brennan and Williams, 1995" startWordPosition="567" endWordPosition="570">ed a question correctly. Psycholinguistics research has shown that speakers display FOK in conversation using linguistic cues such as filled pauses and prosody (Smith and Clark, 1993). Of perhaps more relevance to dialogue systems, research has also shown that listeners can use the same cues to monitor the FOK of someone else, i.e. “feelProceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 286–289, Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics 286 ing of another’s knowing” (FORK) (Brennan and Williams, 1995). To quantify knowledge monitoring, measures of monitoring accuracy have been proposed. For example, consider an FOK experimental paradigm, where subjects 1) respond to a set of general knowledge questions, 2) take a FOK survey, judging whether or not1 they think they would recognize the answer to each question in a multiple choice test, and 3) take such a recognition test. As shown in Figure 1, such data can be summarized in an array where each cell represents a mutually exclusive option: the row labels represent the possible FOK judgments (Y/N), while the columns represent the possible resul</context>
</contexts>
<marker>Brennan, Williams, 1995</marker>
<rawString>S. E. Brennan and M. Williams. 1995. The feeling of another’s knowing: Prosody and filled pauses as cues to listeners about the metacognitive states of speakers. Journal of Memory and Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dijkstra</author>
<author>E Krahmer</author>
<author>M Swerts</author>
</authors>
<title>Manipulating uncertainty: The contribution of different audiovisual prosodic cues to the perception of confidence.</title>
<date>2006</date>
<booktitle>In Proc. Speech Prosody.</booktitle>
<contexts>
<context position="1283" citStr="Dijkstra et al., 2006" startWordPosition="185" endWordPosition="188">e derivation of FOAK measures from these annotations, for use in building predictive performance models. Our results show that monitoring the accuracy of FOAK is indeed predictive of student learning, both in isolation and in conjunction with other predictors. 1 Introduction Detecting and exploiting knowledge of a speaker’s uncertainty has been studied in several research communities. Spoken language researchers have identified statistically significant relationships between speaker uncertainty and linguistic properties of utterances such as prosody and lexical content (Liscombe et al., 2005; Dijkstra et al., 2006; Pon-Barry, 2008). Spoken dialogue researchers in turn are studying whether responding to user states such as uncertainty can improve system performance as measured by usability and efficiency (Tsukahara and Ward, 2001; Pon-Barry et al., 2006; Forbes-Riley and Litman, 2009a). In the psycholinguistics community, uncertainty has been studied in the context of metacognitive abilities, e.g. the ability to monitor the accuracy of one’s own knowledge (“Feeling of Knowing” (FOK)), and the ability to monitor the FOK of someone else (“Feeling of Another’s Knowing” (FOAK)) (Smith and Clark, 1993; Brenn</context>
<context position="9161" citStr="Dijkstra et al., 2006" startWordPosition="1453" endWordPosition="1456">ain (%U) normalize the raw counts of the wizard’s C and U annotations. Similar measures predict learning in prior experiments by ourselves and others (e.g (Litman et al., 2009)) and thus serve as useful baselines. In our corpus, 79% of a student’s turns are answered correctly on average, while 77% are answered without uncertainty. The monitoring accuracy measures Gamma and HC were introduced in Section 2. To construct an array like that shown in Figure 1, we map the first and second rows to our uncertainty annotations NonU and U, and map the columns to our correctness annotations C and I. In (Dijkstra et al., 2006), high and low FOK/FOAK judgments are similarly associated with speaker certainty and uncertainty, respectively. Note that in our annotation scheme, NonU answers are either certain or neutral. 5 Results: Predicting Student Learning Given the above measures, our first prediction experiment measures the partial Pearson’s correlation between each of the independent measures and posttest, after first controlling for pretest to account for learning gain. Our goal here is examine the predictive utility of the correctness, uncertainty, and monitoring dimensions in isolation. Table 2 shows the statist</context>
</contexts>
<marker>Dijkstra, Krahmer, Swerts, 2006</marker>
<rawString>C. Dijkstra, E. Krahmer, and M. Swerts. 2006. Manipulating uncertainty: The contribution of different audiovisual prosodic cues to the perception of confidence. In Proc. Speech Prosody.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Forbes-Riley</author>
<author>D J Litman</author>
</authors>
<title>Analyzing dependencies between student certainness states and tutor responses in a spoken dialogue corpus.</title>
<date>2008</date>
<booktitle>Recent Trends in Discourse and Dialogue.</booktitle>
<editor>In L. Dybkjaer and W. Minker, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="8133" citStr="Forbes-Riley and Litman, 2008" startWordPosition="1271" endWordPosition="1274"> out. We know that gravity can’t be the only vertical force on the car, because ... Figure 2: Annotated Corpus Excerpt. 4 Predictors To derive our performance models, we use posttest score as the dependent measure, and include pretest score among the independent measures. This allows us to measure learning gain, not just final test score. We also include additional independent measures computed from the wizard’s uncertainty and correctness annotations, 2In prior ITSPOKE corpora, this wizard displayed interannotator agreement of 0.85 and 0.62 Kappa on correctness and uncertainty, respectively (Forbes-Riley and Litman, 2008). 287 as detailed below. Note that all measures are computed on a per student basis (over all 5 dialogues). Table 1 shows means and standard deviations of all measures across all 81 students. Measure Mean Std. Dev. pretest .51 .15 posttest .75 .14 %C .79 .09 %U .23 .11 Gamma .77 .17 HC .59 .16 Table 1: Descriptive Corpus Statistics. The percentage of student turns annotated as correct (%C) and as uncertain (%U) normalize the raw counts of the wizard’s C and U annotations. Similar measures predict learning in prior experiments by ourselves and others (e.g (Litman et al., 2009)) and thus serve a</context>
</contexts>
<marker>Forbes-Riley, Litman, 2008</marker>
<rawString>K. Forbes-Riley and D. J. Litman. 2008. Analyzing dependencies between student certainness states and tutor responses in a spoken dialogue corpus. In L. Dybkjaer and W. Minker, editors, Recent Trends in Discourse and Dialogue. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Forbes-Riley</author>
<author>D Litman</author>
</authors>
<title>Adapting to student uncertainty improves tutoring dialogues.</title>
<date>2009</date>
<booktitle>In Proc. Intl. Conf. on Artificial Intelligence in Education.</booktitle>
<contexts>
<context position="1557" citStr="Forbes-Riley and Litman, 2009" startWordPosition="225" endWordPosition="228">roduction Detecting and exploiting knowledge of a speaker’s uncertainty has been studied in several research communities. Spoken language researchers have identified statistically significant relationships between speaker uncertainty and linguistic properties of utterances such as prosody and lexical content (Liscombe et al., 2005; Dijkstra et al., 2006; Pon-Barry, 2008). Spoken dialogue researchers in turn are studying whether responding to user states such as uncertainty can improve system performance as measured by usability and efficiency (Tsukahara and Ward, 2001; Pon-Barry et al., 2006; Forbes-Riley and Litman, 2009a). In the psycholinguistics community, uncertainty has been studied in the context of metacognitive abilities, e.g. the ability to monitor the accuracy of one’s own knowledge (“Feeling of Knowing” (FOK)), and the ability to monitor the FOK of someone else (“Feeling of Another’s Knowing” (FOAK)) (Smith and Clark, 1993; Brennan and Williams, 1995). Here we take a spoken dialogue systems perspective on FOAK, and investigate whether monitoring the accuracy of FOAK is a useful construct for predictive performance modeling. Our study uses data previously collected with a wizarded spoken dialogue tu</context>
<context position="5427" citStr="Forbes-Riley and Litman, 2009" startWordPosition="842" endWordPosition="846">acy, respectively. We use both metrics in the performance modeling experiments described in Section 5, as both measures have been well studied and there is a lack of consensus regarding their relative benefits (e.g. (Nietfeld et al., 2006)). Note that both range in value from -1 (no monitoring accuracy) to 1 (perfect monitoring accuracy). 3 Data This research uses a corpus of 405 dialogues between 81 students and ITSPOKE-WOZ. The corpus was collected in an experiment showing that performance improved when ITSPOKE-WOZ responded to the uncertainty in student answers, over and above correctness (Forbes-Riley and Litman, 2009a). ITSPOKE-WOZ is a semi-automatic version of ITSPOKE (Intelligent Tutoring SPOKEn dialogue system), which is a speech-enhanced version of the Why2-Atlas qualitative physics tutor (VanLehn et al., 2002). Recent versions of 1Likert scale rating schemes are also possible. ITSPOKE have also been enhanced to detect and respond to student uncertainty, by parameterizing the dialogue manager so that it can adapt contingently based on student correctness and/or uncertainty (to test various ways of responding to uncertainty). In ITSPOKE-WOZ, a few components (speech recognition, language understanding</context>
</contexts>
<marker>Forbes-Riley, Litman, 2009</marker>
<rawString>K. Forbes-Riley and D. Litman. 2009a. Adapting to student uncertainty improves tutoring dialogues. In Proc. Intl. Conf. on Artificial Intelligence in Education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Forbes-Riley</author>
<author>D Litman</author>
</authors>
<title>A user modeling-based performance analysis of a wizarded uncertainty-adaptive dialogue system corpus.</title>
<date>2009</date>
<booktitle>In Proc. Interspeech,</booktitle>
<location>Brighton, UK,</location>
<contexts>
<context position="1557" citStr="Forbes-Riley and Litman, 2009" startWordPosition="225" endWordPosition="228">roduction Detecting and exploiting knowledge of a speaker’s uncertainty has been studied in several research communities. Spoken language researchers have identified statistically significant relationships between speaker uncertainty and linguistic properties of utterances such as prosody and lexical content (Liscombe et al., 2005; Dijkstra et al., 2006; Pon-Barry, 2008). Spoken dialogue researchers in turn are studying whether responding to user states such as uncertainty can improve system performance as measured by usability and efficiency (Tsukahara and Ward, 2001; Pon-Barry et al., 2006; Forbes-Riley and Litman, 2009a). In the psycholinguistics community, uncertainty has been studied in the context of metacognitive abilities, e.g. the ability to monitor the accuracy of one’s own knowledge (“Feeling of Knowing” (FOK)), and the ability to monitor the FOK of someone else (“Feeling of Another’s Knowing” (FOAK)) (Smith and Clark, 1993; Brennan and Williams, 1995). Here we take a spoken dialogue systems perspective on FOAK, and investigate whether monitoring the accuracy of FOAK is a useful construct for predictive performance modeling. Our study uses data previously collected with a wizarded spoken dialogue tu</context>
<context position="5427" citStr="Forbes-Riley and Litman, 2009" startWordPosition="842" endWordPosition="846">acy, respectively. We use both metrics in the performance modeling experiments described in Section 5, as both measures have been well studied and there is a lack of consensus regarding their relative benefits (e.g. (Nietfeld et al., 2006)). Note that both range in value from -1 (no monitoring accuracy) to 1 (perfect monitoring accuracy). 3 Data This research uses a corpus of 405 dialogues between 81 students and ITSPOKE-WOZ. The corpus was collected in an experiment showing that performance improved when ITSPOKE-WOZ responded to the uncertainty in student answers, over and above correctness (Forbes-Riley and Litman, 2009a). ITSPOKE-WOZ is a semi-automatic version of ITSPOKE (Intelligent Tutoring SPOKEn dialogue system), which is a speech-enhanced version of the Why2-Atlas qualitative physics tutor (VanLehn et al., 2002). Recent versions of 1Likert scale rating schemes are also possible. ITSPOKE have also been enhanced to detect and respond to student uncertainty, by parameterizing the dialogue manager so that it can adapt contingently based on student correctness and/or uncertainty (to test various ways of responding to uncertainty). In ITSPOKE-WOZ, a few components (speech recognition, language understanding</context>
</contexts>
<marker>Forbes-Riley, Litman, 2009</marker>
<rawString>K. Forbes-Riley and D. Litman. 2009b. A user modeling-based performance analysis of a wizarded uncertainty-adaptive dialogue system corpus. In Proc. Interspeech, Brighton, UK, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Janarthanam</author>
<author>O Lemon</author>
</authors>
<title>User simulations for online adaptation and knowledge-alignment in troubleshooting dialogue systems.</title>
<date>2008</date>
<booktitle>In Proc. SEMdial.</booktitle>
<contexts>
<context position="12804" citStr="Janarthanam and Lemon, 2008" startWordPosition="2018" endWordPosition="2021">nstrate the utility of combining previously studied correctness and uncertainty annotations, using a measure of FOAK monitoring accuracy. Our results show that while the correctness of a user’s response predicts learning, the uncertainty with which a user conveys a response does not. In contrast, the ability to monitor FOAK accuracy predicts learning, in isolation and over and above correctness. We believe that monitoring accuracy will be a relevant construct for other dialogue applications involving knowledge asymmetry, such as problem solving, instruction giving, and trouble shooting (e.g. (Janarthanam and Lemon, 2008)). In future work we plan to use our results to inform a modification of our system aimed at improving inferred user knowledge monitoring abilities; we will better measure such improvements by incorporating FOK ratings into our testing. In addition, we recently found interactions between learning and both user domain expertise and gender (Forbes-Riley and Litman, 2009b); we will investigate whether similar interactions extend to knowledge monitoring metrics. Since our corpus contains dialogues with both uncertainty-adaptive and non-adaptive versions of ITSPOKE-WOZ, we also plan to examine whet</context>
</contexts>
<marker>Janarthanam, Lemon, 2008</marker>
<rawString>S. Janarthanam and O. Lemon. 2008. User simulations for online adaptation and knowledge-alignment in troubleshooting dialogue systems. In Proc. SEMdial.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Liscombe</author>
<author>J Venditti</author>
<author>J Hirschberg</author>
</authors>
<title>Detecting certainness in spoken tutorial dialogues.</title>
<date>2005</date>
<booktitle>In Proc. Interspeech.</booktitle>
<contexts>
<context position="1260" citStr="Liscombe et al., 2005" startWordPosition="181" endWordPosition="184">nty. We then discuss the derivation of FOAK measures from these annotations, for use in building predictive performance models. Our results show that monitoring the accuracy of FOAK is indeed predictive of student learning, both in isolation and in conjunction with other predictors. 1 Introduction Detecting and exploiting knowledge of a speaker’s uncertainty has been studied in several research communities. Spoken language researchers have identified statistically significant relationships between speaker uncertainty and linguistic properties of utterances such as prosody and lexical content (Liscombe et al., 2005; Dijkstra et al., 2006; Pon-Barry, 2008). Spoken dialogue researchers in turn are studying whether responding to user states such as uncertainty can improve system performance as measured by usability and efficiency (Tsukahara and Ward, 2001; Pon-Barry et al., 2006; Forbes-Riley and Litman, 2009a). In the psycholinguistics community, uncertainty has been studied in the context of metacognitive abilities, e.g. the ability to monitor the accuracy of one’s own knowledge (“Feeling of Knowing” (FOK)), and the ability to monitor the FOK of someone else (“Feeling of Another’s Knowing” (FOAK)) (Smith</context>
</contexts>
<marker>Liscombe, Venditti, Hirschberg, 2005</marker>
<rawString>J. Liscombe, J. Venditti, and J. Hirschberg. 2005. Detecting certainness in spoken tutorial dialogues. In Proc. Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Litman</author>
<author>J Moore</author>
<author>M Dzikovska</author>
<author>E Farrow</author>
</authors>
<title>Using natural language processing to analyze tutorial dialogue corpora across domains and modalities.</title>
<date>2009</date>
<booktitle>In Proc. Intl. Conf. on Artificial Intelligence in Education.</booktitle>
<contexts>
<context position="8715" citStr="Litman et al., 2009" startWordPosition="1373" endWordPosition="1376">tively (Forbes-Riley and Litman, 2008). 287 as detailed below. Note that all measures are computed on a per student basis (over all 5 dialogues). Table 1 shows means and standard deviations of all measures across all 81 students. Measure Mean Std. Dev. pretest .51 .15 posttest .75 .14 %C .79 .09 %U .23 .11 Gamma .77 .17 HC .59 .16 Table 1: Descriptive Corpus Statistics. The percentage of student turns annotated as correct (%C) and as uncertain (%U) normalize the raw counts of the wizard’s C and U annotations. Similar measures predict learning in prior experiments by ourselves and others (e.g (Litman et al., 2009)) and thus serve as useful baselines. In our corpus, 79% of a student’s turns are answered correctly on average, while 77% are answered without uncertainty. The monitoring accuracy measures Gamma and HC were introduced in Section 2. To construct an array like that shown in Figure 1, we map the first and second rows to our uncertainty annotations NonU and U, and map the columns to our correctness annotations C and I. In (Dijkstra et al., 2006), high and low FOK/FOAK judgments are similarly associated with speaker certainty and uncertainty, respectively. Note that in our annotation scheme, NonU </context>
</contexts>
<marker>Litman, Moore, Dzikovska, Farrow, 2009</marker>
<rawString>D. Litman, J. Moore, M. Dzikovska, and E. Farrow. 2009. Using natural language processing to analyze tutorial dialogue corpora across domains and modalities. In Proc. Intl. Conf. on Artificial Intelligence in Education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M¨oller</author>
</authors>
<title>Parameters for quantifying the interaction with spoken dialogue telephone services.</title>
<date>2005</date>
<booktitle>In Proc. SIGdial Workshop on Discourse and Dialogue.</booktitle>
<marker>M¨oller, 2005</marker>
<rawString>S. M¨oller. 2005. Parameters for quantifying the interaction with spoken dialogue telephone services. In Proc. SIGdial Workshop on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Nietfeld</author>
<author>C K Enders</author>
<author>G Schraw</author>
</authors>
<title>A Monte Carlo comparison of measures of relative and absolute monitoring accuracy. Educational and Psychological Measurement.</title>
<date>2006</date>
<contexts>
<context position="5037" citStr="Nietfeld et al., 2006" startWordPosition="779" endWordPosition="783">gment=Y a b Judgment=N c d Gamma — (a)(d)−(b)(c) (a)(d)+(b)(c) HC = (a+d)−(b+c) (a+d)+(b+c) Figure 1: Measuring Monitoring Accuracy. Given such an array, the relationship between the correctness and the judgment of FOK for answers can be measured using the standard formulas in Figure 1: Gamma and the Harmann coefficient (HC) measure relative and absolute knowledge monitoring accuracy, respectively. We use both metrics in the performance modeling experiments described in Section 5, as both measures have been well studied and there is a lack of consensus regarding their relative benefits (e.g. (Nietfeld et al., 2006)). Note that both range in value from -1 (no monitoring accuracy) to 1 (perfect monitoring accuracy). 3 Data This research uses a corpus of 405 dialogues between 81 students and ITSPOKE-WOZ. The corpus was collected in an experiment showing that performance improved when ITSPOKE-WOZ responded to the uncertainty in student answers, over and above correctness (Forbes-Riley and Litman, 2009a). ITSPOKE-WOZ is a semi-automatic version of ITSPOKE (Intelligent Tutoring SPOKEn dialogue system), which is a speech-enhanced version of the Why2-Atlas qualitative physics tutor (VanLehn et al., 2002). Recen</context>
</contexts>
<marker>Nietfeld, Enders, Schraw, 2006</marker>
<rawString>J. L. Nietfeld, C. K. Enders, and G. Schraw. 2006. A Monte Carlo comparison of measures of relative and absolute monitoring accuracy. Educational and Psychological Measurement.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Pon-Barry</author>
<author>K Schultz</author>
<author>E O Bratt</author>
<author>B Clark</author>
<author>S Peters</author>
</authors>
<title>Responding to student uncertainty in spoken tutorial dialogue systems.</title>
<date>2006</date>
<journal>Intl. Journal of Artificial Intelligence in Education.</journal>
<contexts>
<context position="1526" citStr="Pon-Barry et al., 2006" startWordPosition="221" endWordPosition="224"> other predictors. 1 Introduction Detecting and exploiting knowledge of a speaker’s uncertainty has been studied in several research communities. Spoken language researchers have identified statistically significant relationships between speaker uncertainty and linguistic properties of utterances such as prosody and lexical content (Liscombe et al., 2005; Dijkstra et al., 2006; Pon-Barry, 2008). Spoken dialogue researchers in turn are studying whether responding to user states such as uncertainty can improve system performance as measured by usability and efficiency (Tsukahara and Ward, 2001; Pon-Barry et al., 2006; Forbes-Riley and Litman, 2009a). In the psycholinguistics community, uncertainty has been studied in the context of metacognitive abilities, e.g. the ability to monitor the accuracy of one’s own knowledge (“Feeling of Knowing” (FOK)), and the ability to monitor the FOK of someone else (“Feeling of Another’s Knowing” (FOAK)) (Smith and Clark, 1993; Brennan and Williams, 1995). Here we take a spoken dialogue systems perspective on FOAK, and investigate whether monitoring the accuracy of FOAK is a useful construct for predictive performance modeling. Our study uses data previously collected wit</context>
</contexts>
<marker>Pon-Barry, Schultz, Bratt, Clark, Peters, 2006</marker>
<rawString>H. Pon-Barry, K. Schultz, E. O. Bratt, B. Clark, and S. Peters. 2006. Responding to student uncertainty in spoken tutorial dialogue systems. Intl. Journal of Artificial Intelligence in Education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Pon-Barry</author>
</authors>
<title>Prosodic manifestations of confidence and uncertainty in spoken language. In</title>
<date>2008</date>
<booktitle>Proc. Interspeech.</booktitle>
<contexts>
<context position="1301" citStr="Pon-Barry, 2008" startWordPosition="189" endWordPosition="190">asures from these annotations, for use in building predictive performance models. Our results show that monitoring the accuracy of FOAK is indeed predictive of student learning, both in isolation and in conjunction with other predictors. 1 Introduction Detecting and exploiting knowledge of a speaker’s uncertainty has been studied in several research communities. Spoken language researchers have identified statistically significant relationships between speaker uncertainty and linguistic properties of utterances such as prosody and lexical content (Liscombe et al., 2005; Dijkstra et al., 2006; Pon-Barry, 2008). Spoken dialogue researchers in turn are studying whether responding to user states such as uncertainty can improve system performance as measured by usability and efficiency (Tsukahara and Ward, 2001; Pon-Barry et al., 2006; Forbes-Riley and Litman, 2009a). In the psycholinguistics community, uncertainty has been studied in the context of metacognitive abilities, e.g. the ability to monitor the accuracy of one’s own knowledge (“Feeling of Knowing” (FOK)), and the ability to monitor the FOK of someone else (“Feeling of Another’s Knowing” (FOAK)) (Smith and Clark, 1993; Brennan and Williams, 1</context>
</contexts>
<marker>Pon-Barry, 2008</marker>
<rawString>H. Pon-Barry. 2008. Prosodic manifestations of confidence and uncertainty in spoken language. In Proc. Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V L Smith</author>
<author>H H Clark</author>
</authors>
<title>On the course of answering questions.</title>
<date>1993</date>
<journal>Journal of Memory and Language.</journal>
<contexts>
<context position="1876" citStr="Smith and Clark, 1993" startWordPosition="274" endWordPosition="277"> 2005; Dijkstra et al., 2006; Pon-Barry, 2008). Spoken dialogue researchers in turn are studying whether responding to user states such as uncertainty can improve system performance as measured by usability and efficiency (Tsukahara and Ward, 2001; Pon-Barry et al., 2006; Forbes-Riley and Litman, 2009a). In the psycholinguistics community, uncertainty has been studied in the context of metacognitive abilities, e.g. the ability to monitor the accuracy of one’s own knowledge (“Feeling of Knowing” (FOK)), and the ability to monitor the FOK of someone else (“Feeling of Another’s Knowing” (FOAK)) (Smith and Clark, 1993; Brennan and Williams, 1995). Here we take a spoken dialogue systems perspective on FOAK, and investigate whether monitoring the accuracy of FOAK is a useful construct for predictive performance modeling. Our study uses data previously collected with a wizarded spoken dialogue tutoring system, where student learning is the primary performance metric. Section 2 reviews several relevant constructs and measures from the area of metacognition. Section 3 introduces our dialogue corpus and its user correctness and uncertainty annotations. Section 4 presents our method for measuring monitoring accur</context>
<context position="3302" citStr="Smith and Clark, 1993" startWordPosition="499" endWordPosition="502">sitive predictor of learning, both in isolation and over and above other predictors. As discussed in Section 6, increasing monitoring accuracy of FOAK is thus one avenue for also potentially increasing performance, which we plan to explore in future versions of our system. 2 Feeling of Another’s Knowing “Feeling of knowing” (FOK) refers to peoples’ ability to accurately monitor their own knowledge, e.g. to know whether they have answered a question correctly. Psycholinguistics research has shown that speakers display FOK in conversation using linguistic cues such as filled pauses and prosody (Smith and Clark, 1993). Of perhaps more relevance to dialogue systems, research has also shown that listeners can use the same cues to monitor the FOK of someone else, i.e. “feelProceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 286–289, Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics 286 ing of another’s knowing” (FORK) (Brennan and Williams, 1995). To quantify knowledge monitoring, measures of monitoring accuracy have been proposed. For example, consider an FOK experimental paradigm, where subjects 1</context>
</contexts>
<marker>Smith, Clark, 1993</marker>
<rawString>V. L. Smith and H. H. Clark. 1993. On the course of answering questions. Journal of Memory and Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Tsukahara</author>
<author>N Ward</author>
</authors>
<title>Responding to subtle, fleeting changes in the user’s internal state.</title>
<date>2001</date>
<booktitle>In Proc. SIG-CHI on Human factors in computing systems.</booktitle>
<contexts>
<context position="1502" citStr="Tsukahara and Ward, 2001" startWordPosition="217" endWordPosition="220">on and in conjunction with other predictors. 1 Introduction Detecting and exploiting knowledge of a speaker’s uncertainty has been studied in several research communities. Spoken language researchers have identified statistically significant relationships between speaker uncertainty and linguistic properties of utterances such as prosody and lexical content (Liscombe et al., 2005; Dijkstra et al., 2006; Pon-Barry, 2008). Spoken dialogue researchers in turn are studying whether responding to user states such as uncertainty can improve system performance as measured by usability and efficiency (Tsukahara and Ward, 2001; Pon-Barry et al., 2006; Forbes-Riley and Litman, 2009a). In the psycholinguistics community, uncertainty has been studied in the context of metacognitive abilities, e.g. the ability to monitor the accuracy of one’s own knowledge (“Feeling of Knowing” (FOK)), and the ability to monitor the FOK of someone else (“Feeling of Another’s Knowing” (FOAK)) (Smith and Clark, 1993; Brennan and Williams, 1995). Here we take a spoken dialogue systems perspective on FOAK, and investigate whether monitoring the accuracy of FOAK is a useful construct for predictive performance modeling. Our study uses data </context>
</contexts>
<marker>Tsukahara, Ward, 2001</marker>
<rawString>W. Tsukahara and N. Ward. 2001. Responding to subtle, fleeting changes in the user’s internal state. In Proc. SIG-CHI on Human factors in computing systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K VanLehn</author>
<author>P W Jordan</author>
<author>C Ros´e</author>
<author>D Bhembe</author>
<author>M B¨ottner</author>
<author>A Gaydos</author>
<author>M Makatchev</author>
<author>U Pappuswamy</author>
<author>M Ringenberg</author>
<author>A Roque</author>
<author>S Siler</author>
<author>R Srivastava</author>
<author>R Wilson</author>
</authors>
<title>The architecture of Why2-Atlas: A coach for qualitative physics essay writing.</title>
<date>2002</date>
<booktitle>In Proc. Intl. Conf. on Intelligent Tutoring Systems.</booktitle>
<marker>VanLehn, Jordan, Ros´e, Bhembe, B¨ottner, Gaydos, Makatchev, Pappuswamy, Ringenberg, Roque, Siler, Srivastava, Wilson, 2002</marker>
<rawString>K. VanLehn, P. W. Jordan, C. Ros´e, D. Bhembe, M. B¨ottner, A. Gaydos, M. Makatchev, U. Pappuswamy, M. Ringenberg, A. Roque, S. Siler, R. Srivastava, and R. Wilson. 2002. The architecture of Why2-Atlas: A coach for qualitative physics essay writing. In Proc. Intl. Conf. on Intelligent Tutoring Systems.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>