<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001664">
<title confidence="0.976748">
Corpus-Based Identification of Non-Anaphoric Noun Phrases
</title>
<author confidence="0.98605">
David L. Bean and Ellen Riloff
</author>
<affiliation confidence="0.977842">
Department of Computer Science
University of Utah
Salt Lake City, Utah 84112
</affiliation>
<email confidence="0.669792">
Ibean,rilofflOcs.utah.edu
</email>
<sectionHeader confidence="0.993755" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999157388888889">
Coreference resolution involves finding antecedents
for anaphoric discourse entities, such as definite
noun phrases. But many definite noun phrases are
not anaphoric because their meaning can be un-
derstood from general world knowledge (e.g., &amp;quot;the
White House&amp;quot; or &amp;quot;the news media&amp;quot;). We have
developed a corpus-based algorithm for automat-
ically identifying definite noun phrases that are
non-anaphoric, which has the potential to improve
the efficiency and accuracy of coreference resolu-
tion systems. Our algorithm generates lists of non-
anaphoric noun phrases and noun phrase patterns
from a training corpus and uses them to recognize
non-anaphoric noun phrases in new texts. Using
1600 MUC-4 terrorism news articles as the training
corpus, our approach achieved 78% recall and 87%
precision at identifying such noun phrases in 50 test
documents.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99695735">
Most automated approaches to coreference res-
olution attempt to locate an antecedent for ev-
ery potentially coreferent discourse entity (DE)
in a text. The problem with this approach is
that a large number of DE&apos;s may not have an-
tecedents. While some discourse entities such
as pronouns are almost always referential, def-
inite descriptions&amp;quot; may not be. Earlier work
found that nearly 50% of definite descriptions
had no prior referents (Vieira and Poesio, 1997),
and we found that number to be even higher,
63%, in our corpus. Some non-anaphoric def-
inite descriptions can be identified by looking
for syntactic clues like attached prepositional
phrases or restrictive relative clauses. But other
definite descriptions are non-anaphoric because
readers understand their meaning due to com-
mon knowledge. For example, readers of this
&apos;In this work, we define a definite description to be a
noun phrase beginning with the.
paper will probably understand the real world
referents of &amp;quot;the F.B.I.,&amp;quot; &amp;quot;the White House,&amp;quot;
and &amp;quot;the Golden Gate Bridge.&amp;quot; These are in-
stances of definite descriptions that a corefer-
ence resolver does not need to resolve because
they each fully specify a cognitive representa-
tion of the entity in the reader&apos;s mind.
One way to address this problem is to cre-
ate a list of all non-anaphoric NPs that could
be used as a filter prior to coreference resolu-
tion, but hand coding such a list is a daunt-
ing and intractable task. We propose a corpus-
based mechanism to identify non-anaphoric NPs
automatically. We will refer to non-anaphoric
definite noun phrases as existential NPs (Allen,
1995). Our algorithm uses statistical methods
to generate lists of existential noun phrases and
noun phrase patterns from a training corpus.
These lists are then used to recognize existen-
tial NPs in new texts.
</bodyText>
<sectionHeader confidence="0.987107" genericHeader="introduction">
2 Prior Research
</sectionHeader>
<bodyText confidence="0.999396611111111">
Computational coreference resolvers fall into
two categories: systems that make no at-
tempt to identify non-anaphoric discourse en-
tities prior to coreference resolution, and those
that apply a filter to discourse entities, identify-
ing a subset of them that are anaphoric. Those
that do not practice filtering include decision
tree models (Aone and Bennett, 1996), (Mc-
Carthy and Lehnert, 1995) that consider all pos-
sible combinations of potential anaphora and
referents. Exhaustively examining all possible
combinations is expensive and, we believe, un-
necessary.
Of those systems that apply filtering prior to
coreference resolution, the nature of the filter-
ing varies. Some systems recognize when an
anaphor and a candidate antecedent are incom-
patible. In SRI&apos;s probabilistic model (Kehler,
</bodyText>
<page confidence="0.998717">
373
</page>
<bodyText confidence="0.960795666666666">
The ARCE battalion command has reported that about 50 peasants of various ages have been
kidnapped by terrorists of the Farabundo Marti National Liberation Front [FMLN] in San
Miguel Department. According to that garrison, the mass kidnapping took place on 30 December
in San Luis de la Reina. The source added that the terrorists forced the individuals, who were
taken to an unknown location, out of their residences, presumably to incorporate them against their
will into clandestine groups.
</bodyText>
<figureCaption confidence="0.999394">
Figure 1: Anaphoric and Non-Anaphoric NPs (definite descriptions highlighted.)
</figureCaption>
<bodyText confidence="0.999700571428571">
1997), a pair of extracted templates may be
removed from consideration because an out-
side knowledge base indicates contradictory fea-
tures. Other systems look for particular con-
structions using certain trigger words. For ex-
ample, pleonastic2 pronouns are identified by
looking for modal adjectives (e.g. &amp;quot;necessary&amp;quot;)
or cognitive verbs (e.g. &amp;quot;It is thought that...&amp;quot;)
in a set of patterned constructions (Lappin and
Leass, 1994), (Kennedy and Boguraev, 1996).
A more recent system (Vieira and Poesio,
1997) recognizes a large percentage of non-
anaphoric definite noun phrases (NPs) during
the coreference resolution process through the
use of syntactic cues and case-sensitive rules.
These methods were successful in many in-
stances, but they could not identify them all.
The existential NPs that were missed were ex-
istential to the reader, not because they were
modified by particular syntactic constructions,
but because they were part of the reader&apos;s gen-
eral world knowledge.
Definite noun phrases that do not need to be
resolved because they are understood through
world knowledge can represent a significant por-
tion of the existential noun phrases in a text. In
our research, we found that existential NPs ac-
count for 63% of all definite NPs, and 24% of
them could not be identified by syntactic or lex-
ical means. This paper details our method for
identifying existential NPs that are understood
through general world knowledge. Our system
requires no hand coded information and can rec-
ognize a larger portion of existential NPs than
Vieira and Poesio&apos;s system.
</bodyText>
<sectionHeader confidence="0.996883" genericHeader="method">
3 Definite NP Taxonomy
</sectionHeader>
<bodyText confidence="0.964738333333333">
To better understand what makes an NP
anaphoric or non-anaphoric, we found it useful
to classify definite NPs into a taxonomy. We
</bodyText>
<footnote confidence="0.9382185">
2Pronouns that are semantically empty, e.g. &amp;quot;It is
clear that....&amp;quot;
</footnote>
<bodyText confidence="0.971089333333333">
first classified definite NPs into two broad cat-
egories, referential NPs, which have prior refer-
ents in the texts, and existential NPs, which do
not. In Figure 1, examples of referential NPs
are &amp;quot;the mass kidnapping,&amp;quot; &amp;quot;the terror-
ists&amp;quot; and &amp;quot;the individuals.&amp;quot;, while examples
of existential NPs are &amp;quot;the ARCE battalion
command&amp;quot; and &amp;quot;the Farabundo Marti Na-
tional Liberation Front.&amp;quot; (The full taxon-
omy can be found in Figure 2.)
We should clarify an important point. When
we say that a definite NP is existential, we say
this because it completely specifies a cognitive
representation of the entity in the reader&apos;s mind.
That is, suppose &amp;quot;the F.B.I.&amp;quot; appears in both
sentence 1 and sentence 7 of a text. Although
there may be a cohesive relationship between
the noun phrases, because they both completely
specify independently, we consider them to be
non-anaphoric.
Definite Noun Phrases
</bodyText>
<listItem confidence="0.943315833333333">
- Referential
- Existential
- Independent
- Syntactic
- Semantic
- Associative
</listItem>
<figureCaption confidence="0.994742">
Figure 2: Definite NP Taxonomy
</figureCaption>
<bodyText confidence="0.999986888888889">
We further classified existential NPs into two
categories, independent and associative, which
are distinguished by their need for context. In-
dependent existentials can be understood in iso-
lation. Associative existentials are inherently
associated with an event, action, object or other
context3. In a text about a basketball game,
for example, we might find &amp;quot;the score,&amp;quot; &amp;quot;the
hoop&amp;quot; and &amp;quot;the bleachers.&amp;quot; Although they may
</bodyText>
<footnote confidence="0.653391">
3Our taxonomy mimics Prince&apos;s (Prince, 1981) in
</footnote>
<bodyText confidence="0.880643">
that our independent existentials roughly equate to her
new class, our associative existentials to her inferable
class, and our referentials to her evoked class.
</bodyText>
<page confidence="0.994685">
374
</page>
<bodyText confidence="0.999986846153846">
not have direct antecedents in the text, we
understand what they mean because they are
all associated with basketball games. In isola-
tion, a reader would not necessarily understand
the meaning of &amp;quot;the score&amp;quot; because context is
needed to disambiguate the intended word sense
and provide a complete specification.
Because associative NPs represent less than
10% of the existential NPs in our corpus, our ef-
forts were directed at automatically identifying
independent existentials. Understanding how
to identify independent existential NPs requires
that we have an understanding of why these
NPs are existential. We classified independent
existentials into two groups, semantic and syn-
tactic. Semantically independent NPs are exis-
tential because they are understood by readers
who share a collective understanding of current
events and world knowledge. For example, we
understand the meaning of &amp;quot;the F.B.I.&amp;quot; without
needing any other information. Syntactically
independent NPs, on the other hand, gain this
quality because they are modified structurally.
For example, in &amp;quot;the man who shot Liberty Va-
lence,&amp;quot; &amp;quot;the man&amp;quot; is existential because the rel-
ative clause uniquely identifies its referent.
</bodyText>
<sectionHeader confidence="0.943416" genericHeader="method">
4 Mining Existential NPs from a
Corpus
</sectionHeader>
<bodyText confidence="0.999982571428571">
Our goal is to build a system that can identify
independent existential noun phrases automati-
cally. In the previous section, we observed that
&amp;quot;existentialism&amp;quot; can be granted to a definite
noun phrase either through syntax or seman-
tics. In this section, we introduce four methods
for recognizing both classes of existentials.
</bodyText>
<subsectionHeader confidence="0.998899">
4.1 Syntactic Heuristics
</subsectionHeader>
<bodyText confidence="0.9998079">
We began by building a set of syntactic heuris-
tics that look for the structural cues of restric-
tive premodification and restrictive postmod-
ification. Restrictive premodification is often
found in noun phrases in which a proper noun
is used as a modifier for a head noun, for ex-
ample, &amp;quot;the U.S. president.&amp;quot; &amp;quot;The president&amp;quot;
itself is ambiguous, but &amp;quot;the U.S. president&amp;quot; is
not. Restrictive postmodification is often rep-
resented by restrictive relative clauses, preposi-
tional phrases, and appositives. For example,
&amp;quot;the president of the United States&amp;quot; and &amp;quot;the
president who governs the U.S.&amp;quot; are existen-
tial due to a prepositional phrase and a relative
clause, respectively.
We also developed syntactic heuristics to rec-
ognize referential NPs. Most NPs of the form
&amp;quot;the &lt;number&gt; &lt;noun&gt;&amp;quot; (e.g., &amp;quot;the 12 men&amp;quot;)
have an antecedent, so we classified them as ref-
erential. Also, if the head noun of the NP ap-
peared earlier in the text, we classified the NP
as referential.
This method, then, consists of two groups of
syntactic heuristics. The first group, which we
refer to as the rule-in heuristics, contains seven
heuristics that identify restrictive premodifica-
tion or postmodification, thus targeting existen-
tial NPs. The second group, referred to as the
rule-out heuristics, contains two heuristics that
identify referential NPs.
</bodyText>
<subsectionHeader confidence="0.987967">
4.2 Sentence One Extractions (Si)
</subsectionHeader>
<bodyText confidence="0.999944727272727">
Most referential NPs have antecedents that pre-
cede them in the text. This observation is the
basis of our first method for identifying seman-
tically independent NPs. If a definite NP occurs
in the first sentence4 of a text, we assume the
NP is existential. Using a training corpus, we
create a list of presumably existential NPs by
collecting the first sentence of every text and
extracting all definite NPs that were not classi-
fied by the syntactic heuristics. We call this list
the 51 extractions.
</bodyText>
<subsectionHeader confidence="0.996002">
4.3 Existential Head Patterns (EHP)
</subsectionHeader>
<bodyText confidence="0.999928142857143">
While examining the Si extractions, we found
many similar NPs, for example &amp;quot;the Salvadoran
Government,&amp;quot; &amp;quot;the Guatemalan Government,&amp;quot;
and &amp;quot;the U.S. Government.&amp;quot; The similarities
indicate that some head nouns, when premod-
ified, represent existential entities. By using
the Si extractions as input to a pattern gen-
eration algorithm, we built a set of Existen-
tial Head Patterns (EHPs) that identify such
constructions. These patterns are of the form
&amp;quot;the &lt;x+&gt;5 &lt;nounl ...nounN&gt;&amp;quot; such as &amp;quot;the
&lt;x+&gt; government&amp;quot; or &amp;quot;the &lt;x+&gt; Salvadoran
government.&amp;quot; Figure 3 shows the algorithm for
creating EHPs.
</bodyText>
<footnote confidence="0.99543925">
4Many of the texts we used were newspaper arti-
cles and all headers, including titles and bylines, were
stripped before processing.
5&lt;x+&gt; = one or more words
</footnote>
<page confidence="0.993745">
375
</page>
<listItem confidence="0.9786736">
1. For each NP of more than two words, build a candidate pattern of the form &amp;quot;the &lt;x+&gt;
headnoun.&amp;quot; Example: if the NP was &amp;quot;the new Salvadoran government,&amp;quot; the candidate pattern
would be &amp;quot;the &lt;x+&gt; government.&amp;quot;
2. Apply that pattern to the corpus, count how many times it matches an NP.
3. If possible, grow the candidate pattern by inserting the word to the left of the headnoun, e.g.
the candidate pattern now becomes &amp;quot;the &lt;x+&gt; Salvadoran government.&amp;quot;
4. Reapply the pattern to the corpus, count how many times it matches an NP. If the new count
is less that the last iteration&apos;s count, stop and return the prior pattern. If the new count is
equal to the last iteration&apos;s count, return to step 3. This iterative process has the effect of
recognizing compound head nouns.
</listItem>
<figureCaption confidence="0.982976">
Figure 3: EHP Algorithm
</figureCaption>
<table confidence="0.995791625">
If the NP was identified via the Si or EHP methods:
Is its definite probability above an upper threshold?
Yes: Classify as existential.
No: Is its definite probability above a lower threshold?
Yes: Is its sentence-number less than or equal to an early allowance threshold?
Yes : Classify as existential.
No: Leave unclassified (allow later methods to apply).
No: Leave unclassified (allow later methods to apply).
</table>
<figureCaption confidence="0.987492">
Figure 4: Vaccine Algorithm
</figureCaption>
<subsectionHeader confidence="0.994271">
4.4 Definite-Only List (DO)
</subsectionHeader>
<bodyText confidence="0.999971769230769">
It also became clear that some existentials
never appear in indefinite constructions. &amp;quot;The
F.B.I.,&amp;quot; &amp;quot;the contrary,&amp;quot; &amp;quot;the National Guard&amp;quot;
are definite NPs which are rarely, if ever, seen
in indefinite constructions. The chances that
a reader will encounter &amp;quot;an F.B.I.&amp;quot; are slim to
none. These NPs appeared to be perfect can-
didates for a corpus-based approach. To locate
&amp;quot;definite-only&amp;quot; NPs we made two passes over
the corpus. The first pass produced a list of ev-
ery definite NP and its frequency. The second
pass counted indefinite uses of all NPs cataloged
during the first pass. Knowing how often an NP
was used in definite and indefinite constructions
allowed us to sort the NPs, first by the probabil-
ity of being used as a definite (its definite prob-
ability), and second by definite-use frequency.
For example, &amp;quot;the contrary&amp;quot; appeared high on
this list because its head noun occurred 15 times
in the training corpus, and every time it was in
a definite construction. From this, we created a
definite-only list by selecting those NPs which
occurred at least 5 times and only in definite
constructions.
Examples from the three methods can be
found in the Appendix.
</bodyText>
<subsectionHeader confidence="0.938234">
4.5 Vaccine
</subsectionHeader>
<bodyText confidence="0.99914275">
Our methods for identifying existential NPs are
all heuristic-based and therefore can be incor-
rect in certain situations. We identified two
types of common errors.
</bodyText>
<listItem confidence="0.971385578947368">
1. An incorrect Si assumption. When the Si as-
sumption fails, i.e. when a definite NP in the
first sentence of a text is truly referential, the
referential NP is added to the Si list. Later, an
Existential Head Pattern may be built from this
NP. In this way, a single misclassified NP may
cause multiple noun phrases to be misclassified
in new texts, acting as an &amp;quot;infection&amp;quot; (Roark
and Charniak, 1998).
2. Occasional existentialism. Sometimes an NP
is existential in one text but referential in an-
other. For example, &amp;quot;the guerrillas&amp;quot; often refers
to a set of counter-government forces that the
reader of an El Salvadoran newspaper would
understand. In some cases, however, a partic-
ular group of guerrillas was mentioned previ-
ously in the text (&amp;quot;A group of FMLN rebels
attacked the capital...&amp;quot;), and later references
to &amp;quot;the guerrillas&amp;quot; referred to this group.
</listItem>
<bodyText confidence="0.999196666666667">
To address these problems, we developed a
vaccine. It was clear that we had a number of in-
fections in our Si list, including &amp;quot;the base,&amp;quot; &amp;quot;the
</bodyText>
<page confidence="0.997932">
376
</page>
<bodyText confidence="0.930746">
For every definite NP in a text
</bodyText>
<listItem confidence="0.996861857142857">
1. Apply syntactic RuleOutHeuristics, if any fired, classify the NP as referential.
2. Look up the NP in the Si list, if found, classify the NP as existential (unless stopped by
vaccine).
3. Look up the NP in the DO list, if found, classify the NP as existential.
4. Apply all EHPs, if any apply, classify the NP as existential (unless stopped by vaccine).
5. Apply syntactic RuleInHeuristics, if any fired, classify the NP as existential.
6. If the NP is not yet classified, classify the NP as referential.
</listItem>
<figureCaption confidence="0.997894">
Figure 5: Existential Identification Algorithm
</figureCaption>
<bodyText confidence="0.999942555555555">
individuals,&amp;quot; &amp;quot;the attack,&amp;quot; and &amp;quot;the banks.&amp;quot;
We noticed, however, that many of these in-
correct NPs also appeared near the bottom of
our definite/indefinite list, indicating that they
were often seen in indefinite constructions. We
used the definite probability measure as a way
of detecting errors in the Si and EHP lists. If
the definite probability of an NP was above an
upper threshold, the NP was allowed to be clas-
sified as existential. If the definite probability of
an NP fell below a lower threshold, it was not al-
lowed to be classified by the Si or EHP method.
Those NPs that fell between the two thresholds
were considered occasionally existential.
Occasionally existential NPs were handled by
observing where the NPs first occurred in the
text. For example, if the first use of &amp;quot;the guer-
rillas&amp;quot; was in the first few sentences of a text,
it was usually an existential use. If the first use
was later, it was usually a referential use be-
cause a prior definition appeared in earlier sen-
tences. We applied an early allowance threshold
of three sentences – occasionally existential NPs
occuring under this threshold were classified as
existential, and those that occurred above were
left unclassified. Figure 4 details the vaccine&apos;s
algorithm.
</bodyText>
<sectionHeader confidence="0.991131" genericHeader="method">
5 Algorithm &amp; Training
</sectionHeader>
<bodyText confidence="0.9999265">
We trained and tested our methods on the
Latin American newswire articles from MUC-
4 (MUC-4 Proceedings, 1992). The training set
contained 1,600 texts and the test set contained
50 texts. All texts were first parsed by SUN-
DANCE, our heuristic-based partial parser de-
veloped at the University of Utah.
We generated the Si extractions by process-
ing the first sentence of all training texts. This
produced 849 definite NPs. Using these NPs as
</bodyText>
<figure confidence="0.889566714285714">
New
Text
EHP
Si
Unresolved Marked
referential existential
definite NPs definite NPs
</figure>
<figureCaption confidence="0.999869">
Figure 6: Recognizing Existential NPs
</figureCaption>
<bodyText confidence="0.999594444444445">
input to the existential head pattern algorithm,
we generated 297 EHPs. The DO list was built
by using only those NPs which appeared at least
5 times in the corpus and 100% of the time as
definites. We generated the DO list in two iter-
ations, once for head nouns alone and once for
full NPs, resulting in a list of 65 head nouns and
321 full NPs6.
Once the methods had been trained, we clas-
sified each definite NP in the test set as referen-
tial or existential using the algorithm in Figure
5. Figure 6 graphically represents the main el-
ements of the algorithm. Note that we applied
vaccines to the Si and EHP lists, but not to the
DO list because gaining entry to the DO list
is much more difficult — an NP must occur at
least 5 times in the training corpus, and every
time it must occur in a definite construction.
</bodyText>
<footnote confidence="0.813922">
6The full NP list showed best performance using pa-
rameters of 5 and 75%, not the 5 and 100% used to create
the head noun only list.
</footnote>
<figure confidence="0.994132125">
DO
Vaccine
Vaccine
Existential
Recognizer
Algorithm
Syntactic
Heuristics
</figure>
<page confidence="0.936669">
377
</page>
<table confidence="0.897091">
Method Tested Recall Precision
0. Baseline 100% 72.2%
</table>
<listItem confidence="0.925344625">
1. Syntactic Heuristics 43.0% 93.1%
2. Syntactic Heuristics + Si 66.3% 84.3%
3. Syntactic Heuristics + EHP 60.7% 87.3%
4. Syntactic Heuristics + DO 69.2% 83.9%
5. Syntactic Heuristics + Si + EHP 79.9% 82.2%
6. Syntactic Heuristics + Si + EHP + DO 81.7% 82.2%
7. Syntactic Heuristics + Si + EHP + DO + V.(70/25) 77.7% 86.6%
8. Syntactic Heuristics + Si + EHP + DO + Vb(50/25) 79.1% 84.5%
</listItem>
<figureCaption confidence="0.999027">
Figure 7: Evaluation Results
</figureCaption>
<bodyText confidence="0.999863692307692">
To evaluate the performance of our algorithm,
we hand-tagged each definite NP in the 50 test
texts as a syntactically independent existential,
a semantically independent existential, an asso-
ciative existential or a referential NP. Figure 8
shows the distribution of definite NP types in
the test texts. Of the 1,001 definite NPs tested,
63% were independent existentials, so removing
these NPs from the coreference resolution pro-
cess could have substantial savings. We mea-
sured the accuracy of our classifications using
recall and precision metrics. Results are shown
in Figure 7.
</bodyText>
<table confidence="0.7600306">
478 Independent existential, syntactic 48%
153 Independent existential, semantic 15%
92 Associative existential 9%
270 Referential 28%
1001 Total
</table>
<figureCaption confidence="0.998182">
Figure 8: NP Distribution
</figureCaption>
<bodyText confidence="0.99855365">
As a baseline measurement, we considered the
accuracy of classifying every definite NP as ex-
istential. Given the distribution of definite NP
types in our test set, this would result in recall
of 100% and precision of 72%. Note that we
are more interested in high measures of preci-
sion than recall because we view this method
to be the precursor to a coreference resolution
algorithm. Incorrectly removing an anaphoric
NP means that the coreference resolver would
never have a chance to resolve it, on the other
hand, non-anaphoric NPs that slip through can
still be ruled as non-anaphoric by the corefer-
ence resolver.
We first evaluated our system using only the
syntactic heuristics, which produced only 43%
recall, but 92% precision. Although the syn-
tactic heuristics are a reliable way to identify
existential definite NPs, they miss 57% of the
true existentials.
</bodyText>
<sectionHeader confidence="0.999604" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999966638888889">
We expected the Si, EHP, and DO methods
to increase coverage. First, we evaluated each
method independently (on top of the syntac-
tic heuristics). The results appear in rows 2-4
of Figure 7. Each method increased recall to
between 61-69%, but decreased precision to 84-
87%. All of these methods produced a substan-
tial gain in recall at some cost in precision.
Next, we tried combining the methods to
make sure that they were not identifying ex-
actly the same set of existential NPs. When
we combined the Si and EHP heuristics, recall
increased to 80% with precision dropping only
slightly to 82%. When we combined all three
methods (Si, EHP, and DO), recall increased
to 82% without any corresponding loss of preci-
sion. These experiments show that these heuris-
tics substantially increase recall and are identi-
fying different sets of existential NPs.
Finally, we tested our vaccine algorithm to
see if it could increase precision without sacri-
ficing much recall. We experimented with two
variations: Va used an upper definite probabil-
ity threshold of 70% and VI, used an upper def-
inite probability threshold of 50%. Both vari-
ations used a lower definite probability thresh-
old of 25%. The results are shown in rows 7-8
of Figure 7. Both vaccine variations increased
precision by several percentage points with only
a slight drop in recall.
In previous work, the system developed by
Vieria &amp; Poesio achieved 74% recall and 85%
precision for identifying &amp;quot;larger situation and
unfamiliar use&amp;quot; NPs. This set of NPs does not
correspond exactly to our definition of existen-
tial NPs because we consider associative NPs
</bodyText>
<page confidence="0.996019">
378
</page>
<bodyText confidence="0.999900625">
to be existential and they do not. Even so, our
results are slightly better than their previous re-
sults. A more equitable comparison is to mea-
sure our system&apos;s performance on only the in-
dependent existential noun phrases. Using this
measure, our algorithm achieved 81.8% recall
with 85.6% precision using Va, and achieved
82.9% recall with 83.5% precision using Vb.
</bodyText>
<sectionHeader confidence="0.999086" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999978176470588">
We have developed several methods for auto--
matically identifying existential noun phrases
using a training corpus. It accomplishes this
task with recall and precision measurements
that exceed those of the earlier Vieira Rz Poesio
system, while not exploiting full parse trees, ap-
positive constructions, hand-coded lists, or case
sensitive text7. In addition, because the sys-
tem is fully automated and corpus-based, it is
suitable for applications that require portabil-
ity across domains. Given the large percentage
of non-anaphoric discourse entities handled by
most coreference resolvers, we believe that us-
ing a system like ours to filter existential NPs
has the potential to reduce processing time and
complexity and improve the accuracy of coref-
erence resolution.
</bodyText>
<sectionHeader confidence="0.999263" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999275111111111">
James Allen. 1995. Natural Language Understand-
ing. Benjamin/Cummings Press, Redwood City,
CA.
Chinatsu Aone and Scott William Bennett. 1996.
Applying Machine Learning to Anaphora Reso-
lution. In Connectionist, Statistical, and Sym-
bolic Approaches to Learning for Natural Lan-
guage Understanding, pages 302-314. Springer-
Verlag, Berlin.
Andrew Kehler. 1997. Probabilistic coreference in
information extraction. In Proceedings of the Sec-
ond Conference on Empirical Methods in Natural
Language Processing (EMNLP-97).
Christopher Kennedy and Branimir Boguraev. 1996.
Anaphor for everyone: Pronomial anaphora reso-
lution without a parser. In Proceedings of the 16th
International Conference on Computational Lin-
guistics (COLING-96).
7Case sensitive text can have a significant positive ef-
fect on performance because it helps to identify proper
nouns. Proper nouns can then be used to look for restric-
tive premodification, something that our system cannot
take advantage of because the MUC-4 corpus is entirely
in uppercase.
Shalom Lappin and Herbert J. Leass. 1994. An al-
gorithm for pronomial anaphora resolution. Com-
putational Linguistics, 20(4):535-561.
Joseph F. McCarthy and Wendy G. Lehnert. 1995.
Using Decision Trees for Coreference Resolution.
In Proceedings of the 14th International Joint
Conference on Artificial Intelligence (IJCAI-95),
pages 1050-1055.
Ellen F. Prince. 1981. Toward a taxonomy of given-
new information. In Peter Cole, editor, Radical
Pragmatics, pages 223-255. Academic Press.
Brian Roark and Eugene Charniak. 1998. Noun-
phrase co-occurence statistics for semi-automatic
semantic lexcon construction. In Proceedings of
the 36th Annual Meeting of the Association for
Computational Linguistics.
R. Vieira and M. Poesio. 1997. Processing defi-
nite descriptions in corpora. In S. Botley and
M. McEnery, editors, Corpus-based and Compu-
tational Approaches to Discourse Anaphora. UCL
Press.
</reference>
<page confidence="0.999628">
379
</page>
<sectionHeader confidence="0.965123" genericHeader="acknowledgments">
Appendix
</sectionHeader>
<bodyText confidence="0.42212">
Examples from the Si, EHP, Sz DO lists.
</bodyText>
<table confidence="0.997032666666667">
Si Extractions Existential Head Patterns Definite-Only NPs
THE PMLN TERRORISTS THE &lt;X-F&gt; NATIONAL CAPITOL THE STATE DEPARTMENT
THE NATIONAL CAPITOL THE &lt;X-F&gt; AFFAIR THE PAST 16 YEARS
THE PMLN REBELS THE &lt;X-F&gt; ATTACKS THE CENTRAL AMERICAN UNIVERSITY
THE NATIONAL REVOLUTIONARY NETWORK THE &lt;X-I-&gt; AUTHORITIES THE MEDIA
THE PAVON PRISON FARM THE &lt;X4-&gt; INSTITUTE THE 6TH INFRANTRY BRIGADE
THE FMLN TERRORIST LEADERS THE &lt;X4-&gt; GOVERNMENT THE PAST FEW HOURS
THE CUSCATLAN RADIO NETWORK THE &lt;X-I-&gt; COMMUNITY THE U.N. SECRETARY GENERAL
THE PAVON REHABILITATION FARM THE &lt;X+&gt; STRUCTURE THE PENTAGON
THE PLO THE &lt;X-I-&gt; PATROL THE CONTRARY
THE TELA AGREEMENTS THE &lt;X-1-&gt; BORDER THE MRTA
THE SALVADORAN ARMY THE &lt;X4-&gt; SQUARE THE CARIBBEAN
THE COLOMBIAN GUERRILLA MOVEMENTS THE &lt;X-F&gt; COMMAND THE USS
THE COLOMBIAN ARMY THE &lt;X-F&gt; SENATE THE DRUG TRAFFICKING MAFIA
THE RELIGIOUS MONTHLY MAGAZINE 30 GIORNI THE &lt;X-1-&gt; NETWORK THE MAQUILIGUAS
THE REVOLUTIONARY LEFT THE &lt;X-1-&gt; LEADERS THE MAYORSHIP
THE PERUVIAN ARMY THE &lt;X4-&gt; RESULT THE SANDINISTS
THE CENTRAL AMERICAN PEOPLES THE &lt;X4-&gt; SECURITY THE LATTER
THE GUATEMALAN ARMY THE &lt;X-F&gt; CRIMINALS THE WOUNDED
THE BUSINESS SECTOR THE &lt;X-1-&gt; HOSPITAL THE SAME
THE HONDURAN ARM THE &lt;X-F&gt; CENTER THE CITIZENRY
THE ANTICOMMUNIST ACTION ALLIANCE THE &lt;X-F&gt; REPORTS THE KREMLIN
THE DEMOCRATIC SYSTEM THE &lt;X4-&gt; ELN THE BEST
THE U.S. THE &lt;X-F&gt; AGREEMENTS THE NEXT
THE BUSH ADMINISTRATION THE &lt;X-F&gt; CONSTITUTION THE MEANTIME
THE CATHOLIC CHURCH THE &lt;X-I-&gt; PEOPLES THE COUNTRYSIDE
THE WAR THE &lt;X-F&gt; EMBASSY THE NAVY
</table>
<page confidence="0.989163">
380
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.909977">
<title confidence="0.999496">Corpus-Based Identification of Non-Anaphoric Noun Phrases</title>
<author confidence="0.999768">L Bean Riloff</author>
<affiliation confidence="0.999951">Department of Computer Science University of Utah</affiliation>
<address confidence="0.982955">Salt Lake City, Utah 84112</address>
<email confidence="0.990178">Ibean,rilofflOcs.utah.edu</email>
<abstract confidence="0.996025">Coreference resolution involves finding antecedents for anaphoric discourse entities, such as definite noun phrases. But many definite noun phrases are not anaphoric because their meaning can be understood from general world knowledge (e.g., &amp;quot;the White House&amp;quot; or &amp;quot;the news media&amp;quot;). We have developed a corpus-based algorithm for automatically identifying definite noun phrases that are non-anaphoric, which has the potential to improve the efficiency and accuracy of coreference resolution systems. Our algorithm generates lists of nonanaphoric noun phrases and noun phrase patterns from a training corpus and uses them to recognize non-anaphoric noun phrases in new texts. Using 1600 MUC-4 terrorism news articles as the training corpus, our approach achieved 78% recall and 87% precision at identifying such noun phrases in 50 test documents.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
</authors>
<title>Natural Language Understanding.</title>
<date>1995</date>
<publisher>Benjamin/Cummings Press,</publisher>
<location>Redwood City, CA.</location>
<contexts>
<context position="2663" citStr="Allen, 1995" startWordPosition="415" endWordPosition="416">&amp;quot;the White House,&amp;quot; and &amp;quot;the Golden Gate Bridge.&amp;quot; These are instances of definite descriptions that a coreference resolver does not need to resolve because they each fully specify a cognitive representation of the entity in the reader&apos;s mind. One way to address this problem is to create a list of all non-anaphoric NPs that could be used as a filter prior to coreference resolution, but hand coding such a list is a daunting and intractable task. We propose a corpusbased mechanism to identify non-anaphoric NPs automatically. We will refer to non-anaphoric definite noun phrases as existential NPs (Allen, 1995). Our algorithm uses statistical methods to generate lists of existential noun phrases and noun phrase patterns from a training corpus. These lists are then used to recognize existential NPs in new texts. 2 Prior Research Computational coreference resolvers fall into two categories: systems that make no attempt to identify non-anaphoric discourse entities prior to coreference resolution, and those that apply a filter to discourse entities, identifying a subset of them that are anaphoric. Those that do not practice filtering include decision tree models (Aone and Bennett, 1996), (McCarthy and L</context>
</contexts>
<marker>Allen, 1995</marker>
<rawString>James Allen. 1995. Natural Language Understanding. Benjamin/Cummings Press, Redwood City, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chinatsu Aone</author>
<author>Scott William Bennett</author>
</authors>
<title>Applying Machine Learning to Anaphora Resolution.</title>
<date>1996</date>
<booktitle>In Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Understanding,</booktitle>
<pages>302--314</pages>
<publisher>SpringerVerlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="3246" citStr="Aone and Bennett, 1996" startWordPosition="504" endWordPosition="507">phrases as existential NPs (Allen, 1995). Our algorithm uses statistical methods to generate lists of existential noun phrases and noun phrase patterns from a training corpus. These lists are then used to recognize existential NPs in new texts. 2 Prior Research Computational coreference resolvers fall into two categories: systems that make no attempt to identify non-anaphoric discourse entities prior to coreference resolution, and those that apply a filter to discourse entities, identifying a subset of them that are anaphoric. Those that do not practice filtering include decision tree models (Aone and Bennett, 1996), (McCarthy and Lehnert, 1995) that consider all possible combinations of potential anaphora and referents. Exhaustively examining all possible combinations is expensive and, we believe, unnecessary. Of those systems that apply filtering prior to coreference resolution, the nature of the filtering varies. Some systems recognize when an anaphor and a candidate antecedent are incompatible. In SRI&apos;s probabilistic model (Kehler, 373 The ARCE battalion command has reported that about 50 peasants of various ages have been kidnapped by terrorists of the Farabundo Marti National Liberation Front [FMLN</context>
</contexts>
<marker>Aone, Bennett, 1996</marker>
<rawString>Chinatsu Aone and Scott William Bennett. 1996. Applying Machine Learning to Anaphora Resolution. In Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Understanding, pages 302-314. SpringerVerlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
</authors>
<title>Probabilistic coreference in information extraction.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing (EMNLP-97).</booktitle>
<marker>Kehler, 1997</marker>
<rawString>Andrew Kehler. 1997. Probabilistic coreference in information extraction. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing (EMNLP-97).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>Branimir Boguraev</author>
</authors>
<title>Anaphor for everyone: Pronomial anaphora resolution without a parser.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96).</booktitle>
<contexts>
<context position="4708" citStr="Kennedy and Boguraev, 1996" startWordPosition="723" endWordPosition="726">heir residences, presumably to incorporate them against their will into clandestine groups. Figure 1: Anaphoric and Non-Anaphoric NPs (definite descriptions highlighted.) 1997), a pair of extracted templates may be removed from consideration because an outside knowledge base indicates contradictory features. Other systems look for particular constructions using certain trigger words. For example, pleonastic2 pronouns are identified by looking for modal adjectives (e.g. &amp;quot;necessary&amp;quot;) or cognitive verbs (e.g. &amp;quot;It is thought that...&amp;quot;) in a set of patterned constructions (Lappin and Leass, 1994), (Kennedy and Boguraev, 1996). A more recent system (Vieira and Poesio, 1997) recognizes a large percentage of nonanaphoric definite noun phrases (NPs) during the coreference resolution process through the use of syntactic cues and case-sensitive rules. These methods were successful in many instances, but they could not identify them all. The existential NPs that were missed were existential to the reader, not because they were modified by particular syntactic constructions, but because they were part of the reader&apos;s general world knowledge. Definite noun phrases that do not need to be resolved because they are understood</context>
</contexts>
<marker>Kennedy, Boguraev, 1996</marker>
<rawString>Christopher Kennedy and Branimir Boguraev. 1996. Anaphor for everyone: Pronomial anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96).</rawString>
</citation>
<citation valid="false">
<title>7Case sensitive text can have a significant positive effect on performance because it helps to identify proper nouns. Proper nouns can then be used to look for restrictive premodification, something that our system cannot take advantage of because the MUC-4 corpus is entirely in uppercase.</title>
<marker></marker>
<rawString>7Case sensitive text can have a significant positive effect on performance because it helps to identify proper nouns. Proper nouns can then be used to look for restrictive premodification, something that our system cannot take advantage of because the MUC-4 corpus is entirely in uppercase.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert J Leass</author>
</authors>
<title>An algorithm for pronomial anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<contexts>
<context position="4678" citStr="Lappin and Leass, 1994" startWordPosition="719" endWordPosition="722">unknown location, out of their residences, presumably to incorporate them against their will into clandestine groups. Figure 1: Anaphoric and Non-Anaphoric NPs (definite descriptions highlighted.) 1997), a pair of extracted templates may be removed from consideration because an outside knowledge base indicates contradictory features. Other systems look for particular constructions using certain trigger words. For example, pleonastic2 pronouns are identified by looking for modal adjectives (e.g. &amp;quot;necessary&amp;quot;) or cognitive verbs (e.g. &amp;quot;It is thought that...&amp;quot;) in a set of patterned constructions (Lappin and Leass, 1994), (Kennedy and Boguraev, 1996). A more recent system (Vieira and Poesio, 1997) recognizes a large percentage of nonanaphoric definite noun phrases (NPs) during the coreference resolution process through the use of syntactic cues and case-sensitive rules. These methods were successful in many instances, but they could not identify them all. The existential NPs that were missed were existential to the reader, not because they were modified by particular syntactic constructions, but because they were part of the reader&apos;s general world knowledge. Definite noun phrases that do not need to be resolv</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Shalom Lappin and Herbert J. Leass. 1994. An algorithm for pronomial anaphora resolution. Computational Linguistics, 20(4):535-561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph F McCarthy</author>
<author>Wendy G Lehnert</author>
</authors>
<title>Using Decision Trees for Coreference Resolution.</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI-95),</booktitle>
<pages>1050--1055</pages>
<contexts>
<context position="3276" citStr="McCarthy and Lehnert, 1995" startWordPosition="508" endWordPosition="512"> (Allen, 1995). Our algorithm uses statistical methods to generate lists of existential noun phrases and noun phrase patterns from a training corpus. These lists are then used to recognize existential NPs in new texts. 2 Prior Research Computational coreference resolvers fall into two categories: systems that make no attempt to identify non-anaphoric discourse entities prior to coreference resolution, and those that apply a filter to discourse entities, identifying a subset of them that are anaphoric. Those that do not practice filtering include decision tree models (Aone and Bennett, 1996), (McCarthy and Lehnert, 1995) that consider all possible combinations of potential anaphora and referents. Exhaustively examining all possible combinations is expensive and, we believe, unnecessary. Of those systems that apply filtering prior to coreference resolution, the nature of the filtering varies. Some systems recognize when an anaphor and a candidate antecedent are incompatible. In SRI&apos;s probabilistic model (Kehler, 373 The ARCE battalion command has reported that about 50 peasants of various ages have been kidnapped by terrorists of the Farabundo Marti National Liberation Front [FMLN] in San Miguel Department. Ac</context>
</contexts>
<marker>McCarthy, Lehnert, 1995</marker>
<rawString>Joseph F. McCarthy and Wendy G. Lehnert. 1995. Using Decision Trees for Coreference Resolution. In Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI-95), pages 1050-1055.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen F Prince</author>
</authors>
<title>Toward a taxonomy of givennew information.</title>
<date>1981</date>
<booktitle>Radical Pragmatics,</booktitle>
<pages>223--255</pages>
<editor>In Peter Cole, editor,</editor>
<publisher>Academic Press.</publisher>
<contexts>
<context position="7494" citStr="Prince, 1981" startWordPosition="1171" endWordPosition="1172"> non-anaphoric. Definite Noun Phrases - Referential - Existential - Independent - Syntactic - Semantic - Associative Figure 2: Definite NP Taxonomy We further classified existential NPs into two categories, independent and associative, which are distinguished by their need for context. Independent existentials can be understood in isolation. Associative existentials are inherently associated with an event, action, object or other context3. In a text about a basketball game, for example, we might find &amp;quot;the score,&amp;quot; &amp;quot;the hoop&amp;quot; and &amp;quot;the bleachers.&amp;quot; Although they may 3Our taxonomy mimics Prince&apos;s (Prince, 1981) in that our independent existentials roughly equate to her new class, our associative existentials to her inferable class, and our referentials to her evoked class. 374 not have direct antecedents in the text, we understand what they mean because they are all associated with basketball games. In isolation, a reader would not necessarily understand the meaning of &amp;quot;the score&amp;quot; because context is needed to disambiguate the intended word sense and provide a complete specification. Because associative NPs represent less than 10% of the existential NPs in our corpus, our efforts were directed at aut</context>
</contexts>
<marker>Prince, 1981</marker>
<rawString>Ellen F. Prince. 1981. Toward a taxonomy of givennew information. In Peter Cole, editor, Radical Pragmatics, pages 223-255. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Eugene Charniak</author>
</authors>
<title>Nounphrase co-occurence statistics for semi-automatic semantic lexcon construction.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="14898" citStr="Roark and Charniak, 1998" startWordPosition="2366" endWordPosition="2369">the three methods can be found in the Appendix. 4.5 Vaccine Our methods for identifying existential NPs are all heuristic-based and therefore can be incorrect in certain situations. We identified two types of common errors. 1. An incorrect Si assumption. When the Si assumption fails, i.e. when a definite NP in the first sentence of a text is truly referential, the referential NP is added to the Si list. Later, an Existential Head Pattern may be built from this NP. In this way, a single misclassified NP may cause multiple noun phrases to be misclassified in new texts, acting as an &amp;quot;infection&amp;quot; (Roark and Charniak, 1998). 2. Occasional existentialism. Sometimes an NP is existential in one text but referential in another. For example, &amp;quot;the guerrillas&amp;quot; often refers to a set of counter-government forces that the reader of an El Salvadoran newspaper would understand. In some cases, however, a particular group of guerrillas was mentioned previously in the text (&amp;quot;A group of FMLN rebels attacked the capital...&amp;quot;), and later references to &amp;quot;the guerrillas&amp;quot; referred to this group. To address these problems, we developed a vaccine. It was clear that we had a number of infections in our Si list, including &amp;quot;the base,&amp;quot; &amp;quot;the</context>
</contexts>
<marker>Roark, Charniak, 1998</marker>
<rawString>Brian Roark and Eugene Charniak. 1998. Nounphrase co-occurence statistics for semi-automatic semantic lexcon construction. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Vieira</author>
<author>M Poesio</author>
</authors>
<title>Processing definite descriptions in corpora.</title>
<date>1997</date>
<booktitle>Corpus-based and Computational Approaches to Discourse Anaphora.</booktitle>
<editor>In S. Botley and M. McEnery, editors,</editor>
<publisher>UCL Press.</publisher>
<contexts>
<context position="1520" citStr="Vieira and Poesio, 1997" startWordPosition="225" endWordPosition="228">orism news articles as the training corpus, our approach achieved 78% recall and 87% precision at identifying such noun phrases in 50 test documents. 1 Introduction Most automated approaches to coreference resolution attempt to locate an antecedent for every potentially coreferent discourse entity (DE) in a text. The problem with this approach is that a large number of DE&apos;s may not have antecedents. While some discourse entities such as pronouns are almost always referential, definite descriptions&amp;quot; may not be. Earlier work found that nearly 50% of definite descriptions had no prior referents (Vieira and Poesio, 1997), and we found that number to be even higher, 63%, in our corpus. Some non-anaphoric definite descriptions can be identified by looking for syntactic clues like attached prepositional phrases or restrictive relative clauses. But other definite descriptions are non-anaphoric because readers understand their meaning due to common knowledge. For example, readers of this &apos;In this work, we define a definite description to be a noun phrase beginning with the. paper will probably understand the real world referents of &amp;quot;the F.B.I.,&amp;quot; &amp;quot;the White House,&amp;quot; and &amp;quot;the Golden Gate Bridge.&amp;quot; These are instances </context>
<context position="4756" citStr="Vieira and Poesio, 1997" startWordPosition="731" endWordPosition="734">inst their will into clandestine groups. Figure 1: Anaphoric and Non-Anaphoric NPs (definite descriptions highlighted.) 1997), a pair of extracted templates may be removed from consideration because an outside knowledge base indicates contradictory features. Other systems look for particular constructions using certain trigger words. For example, pleonastic2 pronouns are identified by looking for modal adjectives (e.g. &amp;quot;necessary&amp;quot;) or cognitive verbs (e.g. &amp;quot;It is thought that...&amp;quot;) in a set of patterned constructions (Lappin and Leass, 1994), (Kennedy and Boguraev, 1996). A more recent system (Vieira and Poesio, 1997) recognizes a large percentage of nonanaphoric definite noun phrases (NPs) during the coreference resolution process through the use of syntactic cues and case-sensitive rules. These methods were successful in many instances, but they could not identify them all. The existential NPs that were missed were existential to the reader, not because they were modified by particular syntactic constructions, but because they were part of the reader&apos;s general world knowledge. Definite noun phrases that do not need to be resolved because they are understood through world knowledge can represent a signifi</context>
</contexts>
<marker>Vieira, Poesio, 1997</marker>
<rawString>R. Vieira and M. Poesio. 1997. Processing definite descriptions in corpora. In S. Botley and M. McEnery, editors, Corpus-based and Computational Approaches to Discourse Anaphora. UCL Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>