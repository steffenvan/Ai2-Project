<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.992802">
Chinese Chunking with another Type of Spec
</title>
<author confidence="0.987282">
Hongqiao Li
</author>
<affiliation confidence="0.732036666666667">
Beijing Institute of
Technology
Beijing 100081 China
</affiliation>
<email confidence="0.974227">
lhqtxm@bit.edu.cn
</email>
<author confidence="0.94123">
Chang-Ning Huang
</author>
<affiliation confidence="0.919644">
Microsoft Research Asia
</affiliation>
<bodyText confidence="0.525086">
Beijing 100080 China
cnhuang@msrchina.
research.microsoft.com
</bodyText>
<author confidence="0.667767">
Jianfeng Gao
</author>
<affiliation confidence="0.5915575">
Microsoft Research Asia
Beijing 100080 China
</affiliation>
<email confidence="0.85951">
jfgao@microsoft.com
</email>
<author confidence="0.761144">
Xiaozhong Fan
</author>
<affiliation confidence="0.559845">
Beijing Institute of
Technology
Beijing 100081 China
</affiliation>
<email confidence="0.937981">
fxz@bit.edu.cn
</email>
<sectionHeader confidence="0.989578" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999925375">
Spec is a critical issue for automatic chunking.
This paper proposes a solution of Chinese
chunking with another type of spec, which is
not derived from a complete syntactic tree but
only based on the un-bracketed, POS tagged
corpus. With this spec, a chunked data is built
and HMM is used to build the chunker. TBL-
based error correction is used to further
improve chunking performance. The average
chunk length is about 1.38 tokens, F measure
of chunking achieves 91.13%, labeling
accuracy alone achieves 99.80% and the ratio
of crossing brackets is 2.87%. We also find
that the hardest point of Chinese chunking is
to identify the chunking boundary inside
noun-noun sequences1.
</bodyText>
<sectionHeader confidence="0.998693" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999748565217391">
Abney (1991) has proposed chunking as a useful
and relative tractable median stage that is to divide
sentences into non-overlapping segments only
based on superficial analysis and local information.
(Ramshaw and Marcus, 1995) represent chunking
as tagging problem and the CoNLL2000 shared
task (Kim Sang and Buchholz, 2000) is now the
standard evaluation task for chunking English.
Their work has inspired many others to study
chunking for other human languages.
Besides the chunking algorithm, spec (the
detailed definitions of all chunk types) is another
critical issue for automatic chunking development.
The well-defined spec can induce the chunker to
perform well. Currently chunking specs are
defined as some rules or one program to extract
phrases from Treebank such as (Li, 2003) and (Li,
2004) in order to save the cost of manual
annotation. We name it as Treebank-derived spec.
However, we find that it is more valuable to
compile another type of chunking spec according
to the observation from un-bracketed corpus
instead of Treebank.
</bodyText>
<footnote confidence="0.9912125">
1 This work was done while Hongqiao Li was visiting
Microsoft Research Asia.
</footnote>
<bodyText confidence="0.999933193548387">
Based on the problems of chunking Chinese that
are found with our observation, we explain the
reason why another type of spec is needed and then
propose our spec in which the shortening and
extending strategies are used to resolve these
problems. We also compare our spec with a
Treebank-derived spec which is derived from
Chinese Treebank (CTB) (Xue and Xia, 2000). An
annotated chunking corpus is built with the spec
and then a chunker is also constructed accordingly.
For annotation, we adopt a two-stage processing,
in which text is first chunked manually and then
the potential inconsistent annotations are checked
semi-automatically with a tool. For the chunker,
we use HMM model and TBL (Transform-based
Learning) (Brill, 1995) based error correction to
further improve chunking performance. With our
spec the overall average length of chunks arrives
1.38 tokens, in open test, the chunking F measure
achieves 91.13% and 95.45% if under-combining
errors are not counted. We also find the hardest
point of Chinese chunking is to identify the
chunking boundary inside a noun-noun sequence.
In the remainder of this paper section 2 describes
some problems in chunking Chinese text, section 3
discusses the reason why another type of spec is
needed and proposes our chunking spec, section 4
discusses the annotation of our chunking corpus,
section 5 describes chunking model, section 6
gives experiment results, section 7, 8 recall some
related work and give our conclusions respectively.
</bodyText>
<sectionHeader confidence="0.57479" genericHeader="introduction">
2 Problems of Chunking Chinese Text
</sectionHeader>
<bodyText confidence="0.9512846">
The purpose of Chinese chunking is to divide
sentence into syntactically correlated parts of
words after word segmentation and part-of-speech
(POS) tagging. For example:
‘solid’ /n ‘traffic’ /n ‘frame’] [VP /d
‘already’ /v ‘achieve considerable
scale ’ /u] ‘Zhuhai has achieved considerable
scale in solid traffic frame.’
According to Abney’s definition, most chunks
are modifier-head structures and non-overlapping.
However, some syntactic structures in Chinese are
very hard to be chunked correctly due to
/ns ‘Zhuhai’] /u ‘of’ [NP
/a
[NP
characteristics of Chinese language, for example,
less using of function words and less inflection
formats. Table 1 shows the most common
structural ambiguities occurred during Chinese
chunking. Their occurrences and distributions of
each possible structure are also reported. As can be
seen in Table 1, only 77% neighboring nouns can
be grouped inside one chunk; if the left word is ‘
/of’ or a verb, this figure will ascend to 80% and
94% respectively; but if the left word is an
adjective or a numeral, it will descend to 70% and
59% respectively; for ‘n_c_n’, only 52% are word
level coordination. In contrast with English
chunking, several hard problems are described in
detail as following.
</bodyText>
<listItem confidence="0.657856">
(1) Noun-noun compounds
</listItem>
<bodyText confidence="0.927039363636364">
Compounds formed by more than two
neighboring nouns are very common in Chinese
and not always all the left nouns modify the head
of the compound. Some compounds consist of
several shorter sub-compounds. For example:
( /younger /volunteer
/science and technology /service team)
‘young volunteer service team of science and
technology’
‘ ’ and ‘ ’ are two sub-
compounds and the former modifies the latter.
But sometimes it is impossible to distinguish the
inner structures, for example:
/world /peace /career
It is impossible to distinguish whether it is {{
} } or { { }}.
English chunking also shows such problem, and
the common solution for English is not to identify
their inner structure and treat them as a flat noun
phrase. Following is an example in CoNLL2000
shared task:
[NP employee assistance program directors]
</bodyText>
<listItem confidence="0.783709">
(2) Coordination
</listItem>
<bodyText confidence="0.998731193548387">
Coordination in all cases can be divided into two
types: with conjunctions and without conjunctions.
The former can be further divided into two
subcategories: word-level and phrase-level
coordinations. For example:
{ /policy /bank /and
/commercial /bank} /of {
/relationship /and /cooperation} ‘the
relationship and cooperation between policy
banks and commercial banks’.
The former coordination is phrase-level and the
latter is word-level. Unfortunately, sometimes it is
difficult or even impossible to distinguish whether
it is word-level or phrase-level at all, for example:
/least /salary /and /living
maintenance ‘the least salary and living
maintenance’
It is impossible to distinguish ‘’ is a shared
modifier or not. English chunking also has such
kind of problems. The solution of CoNLL2000 is
to leave the conjunctions outside chunks for
phrase-level coordinations and to group the
conjunction inside a chunk when it is word-level or
impossibly distinguished phrase-level. For
example:
[NP enough food and water]
In Chinese, some coordinate construction has no
conjunction or punctuation inside, and also could
not be distinguished from a modifier-head
construction with syntactic knowledge only. For
example:
</bodyText>
<table confidence="0.865674">
/order ( /police wagon /caution
light /alarm whistle) ‘Order the police
Pattern1 No.2 Distributions Examples
n_n 951 77% (modifier head) (/society /phenomenon) ‘social phenomena’
7% (coordination)
16% (others)
</table>
<bodyText confidence="0.81474908">
(/language /wordage) ‘language and wordage’
(/capital /art 台/stage) ‘ the stage of capital art’
v nn 154 _ _94 /enter /factory /worker
6% (v_n modify the last noun)
% (others)
‘avoid
/avoid /law /duty legal duties’
n n 98 _ _20% 勤/watch /of /traffic /cop ‘a
80% ( n_n is modifier _head)
(others)
orderly traffic cop’
痪/paralytic /of /body /function
a nn 27 _ _30% /high /technology /company ‘high-tech company’
70% ( a modify the first n)
(others)
‘old
/old /news /worker news worker’
m nn 17 _ _59% /two /nation /people ‘our two peoples’
41% ( m modify the first n) /some /country /area ‘some rural areas’
(others)
n c n 88 _ _48 /economy /and /society ‘economy and society’
52%(word level coordination)
%(others)
/quality /and /technology 求/requirement
n, v, a, d, m, q, p, f , c are the POS tags of noun, verb, adjective, adverb, number, measure, preposition, localizer,
</bodyText>
<footnote confidence="0.9399295">
conjunction respectively, ‘_’ means neighboring, ‘/of’ is a common auxiliary word in Chinese.
2This statistical work is done on our test corpus whose setting is shown in Table 3.
</footnote>
<tableCaption confidence="0.995118">
Table 1: The observation of several common structural ambiguities during Chinese chunking
</tableCaption>
<bodyText confidence="0.9396018">
wagons, caution lights and alarm whistles’
Such problem does not exist in English because
almost all coordinations have certain conjunctions
or punctuations between words or phrases of the
same syntactic categories in formal English.
</bodyText>
<listItem confidence="0.745986">
(3) Structural ambiguities
</listItem>
<bodyText confidence="0.979358625">
In Chinese, some structural ambiguities in
phrase level are impossible or unnecessary to be
distinguished during chunking. There is an
example of ‘a_n_n’:
/a ‘modern’ /n ‘industry’
‘system’
{ { }} or {{ } } are
identically acceptable. English also has such
problem. The solution of CoNLL2000 is not to
distinguish inner structure and group the given
sequence as a single chunk. For example, the inner
structure of ‘[NP heavy truck production]’ is ‘{{heavy
truck} production}’, whereas one reading of ‘[NP
heavy quake damage]’ is ‘{heavy {quake damage}}’.
Besides, ‘a_n_n’, ‘m_n_n’ and ‘m_q_n_n’ also
have the similar problem.
</bodyText>
<sectionHeader confidence="0.980345" genericHeader="method">
3 Chinese Chunking Spec
</sectionHeader>
<bodyText confidence="0.999944466666667">
As a kind of shallow parsing, the principles of
chunking are to make chunking much more
efficient and precise than full parsing. Obviously,
one can shorten the length of chunks to leave
ambiguities outside of chunks. For example, if we
let noun-noun sequences always chunk into single
word, those ambiguities listed in Table 1 would not
be encountered and the performance would be
greatly improved. In fact, there is an implicit
requirement in chunking, no matter which
language it is, the average length of chunks is as
longer as possible without violating the general
principle of chunking. So a trade-off between the
average chunk length and the chunking
performance exists.
</bodyText>
<subsectionHeader confidence="0.999691">
3.1 Why another type of spec is needed
</subsectionHeader>
<bodyText confidence="0.91808824137931">
A convenient spec is to extract the lowest non-
terminal nodes from a Treebank (e.g. CTB) as
Chinese chunked data. But there are some
problems. The trees are designed for full parsing
instead of shallow parsing, thus some of these
problems listed in section 2 could not be resolved
well in chunking. Maybe we can compile some
rules to prune the tree or break some non-terminal
nodes in order to properly resolve these problems
just like CoNLL2000. However, just as (Kim Sang
and Buchholz, 2000) noted: “some trees are very
complex and some annotations are inconsistent”.
So these rules are complex, the extracted data are
inconsistent and manual check is also needed. In
addition, the resource of Chinese Treebank is
limited and the extracted data is not enough for
chunking.
So we compile another type of chunking spec
according to the observation from un-bracket
corpus instead of Treebank. The only shortcoming
is the cost of annotation, but there are some
advantages for us to explore.
1) It coincides with auto chunking procedure,
and we can select proper solutions to these
problems without constraints of the exist Treebank.
The purpose of drafting another type of chunking
spec is to keep chunking consistency as high as
possible without hurting the performance of auto-
chunking in whole.
</bodyText>
<listItem confidence="0.992143625">
2) Through spec drafting and text
annotating most frequent and significant syntactic
ambiguities could be studied, and those
observations are in turn described in the spec
carefully.
3) With a proper spec and certain mechanical
approaches, a large-scale chunked data could be
produced without supporting from the Treebank.
</listItem>
<subsectionHeader confidence="0.999519">
3.2 Our spec
</subsectionHeader>
<bodyText confidence="0.999887111111111">
Our spec and chunking annotation are based on
PK corpus2 (Yu et al. 1996). The PK corpus is un-
bracketed, but in which all words are segmented
and only one POS tag is assigned to each word.
We define 11 chunk types that are similar with
CoNLL2000. They are NP (noun chunk), VP (verb
chunk), ADJP (adjective chunk), ADVP (adverb
chunk), PP (prepositional chunk), CONJP
(conjunction), MP (numerical chunk), TP
(temporal chunk), SP (spatial chunk), INTJP
(interjection) and INDP (independent chunk).
During spec drafting we try to find a proper
chunk spec to solve these problems by two ways:
either merging neighboring chunks into one chunk
or shortening them. Besides those structural
ambiguities, we also extend boundary of the
chunks with minor structural ambiguities in order
to make the chunks close to the constituents.
</bodyText>
<subsectionHeader confidence="0.945478">
3.2.1 Shortening
</subsectionHeader>
<bodyText confidence="0.999864818181818">
The auxiliary ‘/of’ is one of the most frequent
words in Chinese and used to connect a pre-
modifier with its nominal head. However the left
boundary of such a -construction is quite
complicated: almost all kinds of preceding clauses,
phrases and words can be combined with it to form
such a pre-modifier, and even one -construction
can embed into another. So we definitely leave it
outside any chunk. Similarly, conjunctions, ‘
/and’, ‘/or’ and ‘/and’ et al., are also left
outside any chunk no matter they are word-level or
</bodyText>
<footnote confidence="0.560235">
2 Can be downloaded from www.icl.pku.edu.cn
</footnote>
<bodyText confidence="0.732897666666667">
/n
phrase-level coordinations. For instances, the
examples in Section 2 are chunked as ‘[NP
</bodyText>
<listItem confidence="0.5803532">
] [NP ] [NP ] [NP
]’ and ‘[ADJP ] [NP ] [NP
]’
3.2.2 Extending
(1) NP
</listItem>
<bodyText confidence="0.9751058">
Similar with the shared task of CoNLL2000,
we define noun compound that is formed by a
noun-sequence: ‘a_n_n’, ‘m_n_n’ or ‘m_q_n_n’,
as one chunk, even if there are sub-compounds,
sub-phrase or coordination relations inside it. For
</bodyText>
<equation confidence="0.6128955">
instances, ‘[NP ]’
‘[NP ]’, ‘[VP ] [NP
</equation>
<bodyText confidence="0.956321375">
]’, ‘[NP ] and ‘[NP
]’ are grouped into single chunks
respectively.
However, it does not mean that we blindly bind
all neighboring nouns into a flat NP. If those
neighboring nouns are not in one constituent or
cross the phrase boundary, they will be chunked
separately, such as following two examples in
</bodyText>
<tableCaption confidence="0.990617">
Table 1: ‘[VP ] [NP ] [NP ]’ and ‘[ADJP
</tableCaption>
<bodyText confidence="0.909240666666667">
] /u [NP ] [NP ]’. So our solution
does not break the grammatical phrase structure in
a given sentence.
With this chunking strategy, we not only
properly resolved these problems, but also get
longer chunks. Longer chunks can make
successive parsing easier based on chunking. For
example, if we chunked the sentence as:
[NP ] [NP ] [NP ] [VP
] /w
There would be three possible syntactic trees
which are difficult to be distinguished:
</bodyText>
<equation confidence="0.974644666666667">
1a) {{ [NP ] { [NP ] [NP
]}} [VP ]}
1b) {{{ [NP ] [NP ]} [NP
]} [VP ]}
1c) {{ [NP ] [NP ]} { [NP
] [VP ]}}
</equation>
<bodyText confidence="0.800245125">
Whereas with above chunking strategy of our
spec, there is only one syntactic tree remained:
{{[NP ] [NP ]} [VP
]} /w
Another reason of the chunking strategy is that
for some NLP applications such as IR, IE or QA, it
is unnecessary to analyze these ambiguities at the
early stage of text analysis.
</bodyText>
<listItem confidence="0.577632">
(2) PP
</listItem>
<bodyText confidence="0.997716647058824">
Most PP consists of only the preposition itself
because the right boundary of a preposition phrase
is hard to identify or far from the preposition. But
certain prepositional phrases in Chinese are formed
with a frame-like construction, such as [PP /p
‘at’ .../f ‘middle’], [PP /p .../f ‘top’], etc.
Statistics shows that more than 90% of those
frame-like PPs are un-ambiguous, and others
commonly have certain formal features such as an
auxiliary or a conjunction immediately
following the localizer. Table 2 shows the statistic
result. Thus with those observations, those frame-
like constructions could be chunked as PP. The
length of such kind of PP frames is restricted to be
at most two words inside in order to keep the
distribution of chunk length more even and the
chunking annotation more consistent.
</bodyText>
<table confidence="0.9996734">
Pattern1 No.of occurrence Ratio as a chunk
p_*_f 45 93.33%
P_*_*_f 36 97.22%
*_f 40 92.50%
*_*_f 9 77.78%
</table>
<tableCaption confidence="0.689488333333333">
1 This statistical work is also done on our test
corpus and ‘*’ means a wildcard for a POS tag.
Table 2: The ration of grouping these patterns
</tableCaption>
<listItem confidence="0.7806965">
as a chunk without any ambiguity
(3) SP
</listItem>
<bodyText confidence="0.998663">
Most spatial chunks consist of only the
localizer(with POS tag ‘/s’ or ‘/f’). But if the
spatial phrase is in the beginning of a sentence, or
there is a punctuation (except “”) in front of it,
then the localizer and its preceding words could be
chunked as a SP. And the number of words in front
of the localizer is also restricted to at most two for
the same reason.
</bodyText>
<listItem confidence="0.867009">
(4) VP
</listItem>
<bodyText confidence="0.980443684210526">
Commonly, a verb chunk VP is a pre-modifier
verb construction, or a head-verb with its following
verb-particles which form a morphologically
derived word sequence. The pre-modifier is
formed by adverbial phrases and/or auxiliary verbs.
In order to keep the annotation consistent those
verb particles and auxiliary verbs could be found in
a closed list respectively only. Post-modifiers of a
verb such as object and complement should be
excluded in a verb chunk.
We find that although a head verb groups more
than one preceding adverbial phrases, auxiliary
verbs and following verb-particles into one VP, its
chunking performance is still high. For example:
[CONJP /c ‘if’] [VP /d ‘lately’
/d ‘not’ /v ‘can’ /v ‘build’ /v
‘up’] [NP /n ‘diplomat /n ‘relation’]
‘If we could not build up the foreign relations
soon’
</bodyText>
<subsectionHeader confidence="0.994091">
3.3 Spec Comparison
</subsectionHeader>
<bodyText confidence="0.906491142857143">
We compare our spec with the Treebank-derived
spec, named as S1, which is to extract the lowest
non-terminal nodes from CTB as chunks from the
,
aspect of the solutions of these problems in section
2. Noun-noun compound and the coordination
which has no conjunction are chunked identically
in both specs. But for others, there are different. In
S1, the conjunctions of phrase-level coordination
are outside of chunks and the ones of word-level
are inside a chunk, all adjective or numerical
modifiers are separate from noun head. According
to S1, the example in 3.2.1 should be chunked as
following.
</bodyText>
<equation confidence="0.9752485">
[ADJP ] [NP ] [NP ] [NP
] [NP ]
</equation>
<bodyText confidence="0.977548692307692">
But these phrases that are impossible to
distinguish inner structures during the early stage
of text analysis are hard to be chunked and would
cause some inconsistency. ‘[ADJP ] [NP ]
[NP ]’ or ‘[ADJP ] [NP
]’, ‘[ADJP ] [NP ] [NP ]’ or
‘[ADJP ] [NP ]’, are hard to make
decisions with S1.
In addition, with our spec outside words are only
punctuations, structural auxiliary ‘ /of’, or
conjunctions, whereas with S1, outside words are
defined as all left words after lowest non-terminal
extraction.
</bodyText>
<sectionHeader confidence="0.983885" genericHeader="method">
4 Chunking Annotation
</sectionHeader>
<bodyText confidence="0.999959230769231">
Four graduate students of linguistics were
assigned to annotate manually the PK corpus with
the proposed chunking spec. Many discussions
between authors and those annotators were
conducted in order to define a better chunking spec
for Chinese. Through the spec drafting and text
annotating most significant syntactic ambiguities
in Chinese, such as those structural ambiguities
discussed in section 2 and 3, have been studied,
and those observations are carefully described in
the spec in turn.
Consistency control is another important issue
during annotation. Besides the common methods:
manual checking, double annotation, post
annotation checking, we explored a new
consistency measure to help us find the potential
inconsistent annotations, which is hinted by
(Kenneth and Ryszard. 2000), who defined
consistency gain as a measure of a rule in learning
from noisy data.
The consistency of an annotated corpus in whole
could be divided down into consistency of each
chunk. If the same chunks appear in the same
context, they should be identically annotated. So
we define the consistency of one special chunk as
the ratio of identical annotation in the same context.
</bodyText>
<equation confidence="0.9956943">
cons(P, context(P) )
No. of same annotation in context( )
P
= (1)
No. of ( , context( )) in corpus
P
N
1
cons(S) = ∑ cons (Pi , context (Pi)) (2)
N i=1
</equation>
<bodyText confidence="0.998559066666667">
Where P represents a pattern of the chunk (POS
or/and lexical sequence), context(P) represents the
needed context to annotate this chunk, N represents
the number of chunks in the whole corpus S.
In order to improve the efficiency we also
develop a semi-automatic tool that not only check
mechanical errors but also detect those potential
inconsistent annotations. For example, one inputs a
POS pattern: ‘a_n_n’, and an expected annotation
result: ‘B-NP_I-NP_E-NP3’, the tool will list all
the consistent and inconsistent sentences in the
annotated text respectively. Based on the output
one can revise those inconsistent results one by one,
and finally the consistency of the chunked text will
be improved step by step.
</bodyText>
<sectionHeader confidence="0.997507" genericHeader="method">
5 Chunking Model
</sectionHeader>
<bodyText confidence="0.999988260869565">
After annotating the corpus, we could use
various learning algorithms to build the chunking
model. In this paper, HMM is selected because not
only its training speed is fast, but also it has
comparable performance (Xun and Huang, 2000).
Automatic chunking with HMM should conduct
the following two steps. 1) Identify boundaries of
each chunk. It is to assign each word a chunk mark,
named M, which contains 5 classes: B, I, E, S (a
single word chunk) and O (outside all chunks). 2)
Tag the chunk type, named X, which contains 11
types defined in Section 3.
So each word will be tagged with two tags: M
and X (the words excluding from any chunk only
have M). So the result after chunking is a sequence
of triples (t, m, x), where t, m, x represent POS tag,
chunk mark and chunk type respectively. All the
triples of a chunk are combined as an item ni,
which also could be named as a chunk rule. Let W
as the word segmentation result of a given sentence,
T as POS tagging result and C (C= n1 n2...nj) as the
chunking result. The statistical chunking model
could be described as following:
</bodyText>
<equation confidence="0.992216888888889">
C∗ = arg max (  |,
P C W T
C
PW C T P C T P W T
(  |, ) ( , ) / ( , )
C
P W C T P C T
(  |, ) ( , )
C
</equation>
<bodyText confidence="0.6082305">
Independent assumption is used to approximate
P(W|C,T), that is:
</bodyText>
<footnote confidence="0.954296333333333">
3 B, E, I represent the left/right boundary of a chunk
and inside a chunk respectively, B-NP means this word
is the beginning of NP.
</footnote>
<equation confidence="0.961585769230769">
)
= arg max
(3)
= arg max
m (4) TBL based error correction (EC) are done
P W C T respectively.
(  |, ) &apos; ∏ P w i ti mi xi
(  |, , )
i=1
If the triple is unseen, formula 5 is used.
count t m x
( , ,
i i i
</equation>
<bodyText confidence="0.842954">
For P(C, T), tri-grams among chunks and outside
words are used to approximate, that is:
</bodyText>
<equation confidence="0.981458">
/ k
P(C,T)&apos; Pln1)P(n2  |n1)∏ P(ni  |ni−2ni−1)
i=3
</equation>
<bodyText confidence="0.999919833333333">
Smoothing follows the method of (Gao et al.,
2002).
In order to improve the performance we use N-
fold error correction (Wu, 2004) technique to
reduce the error rate and TBL is used to learn the
error correction rules based on the output of HMM.
</bodyText>
<sectionHeader confidence="0.962127" genericHeader="method">
6 Data and Evaluation
</sectionHeader>
<bodyText confidence="0.9999306">
The performance of chunking is commonly
measured with three figures: precision (P), recall
(R) and F measure that are defined in CoNLL2000.
Besides these, we also use two other measurements
to evaluate the performance of bracketing and
labeling respectively: RCB(ratio of crossing
brackets), that is the percentage of the found
brackets which cross the correct brackets;
LA(labeling accuracy), that is the percentage of the
found chunks which have the correct labels.
</bodyText>
<equation confidence="0.669337">
RCB =
</equation>
<bodyText confidence="0.9180015">
No. of the chunks crossed chunk boundaries
No. of chunks in test data
</bodyText>
<equation confidence="0.399947">
LA =
No. of correct chunks
</equation>
<bodyText confidence="0.9555375">
No. of the chunks with correct boundaries
The average length (ALen) of chunks for each
type is the average number of tokens in each chunk
of given type. The overall average length is the
average number of tokens in each chunk. To be
more disinterested, outside tokens (including
outside punctuations) are also concerned and each
of them is counted as one chunk.
</bodyText>
<subsectionHeader confidence="0.998477">
6.1 Chunking performance with our spec
</subsectionHeader>
<bodyText confidence="0.985322666666667">
Training and test was done on the PK corpus.
Table 3 shows the detail information. We use the
uni-gram of chunk POS rules as the baseline.
</bodyText>
<table confidence="0.7703695">
Data No. of No. of No. of ALen
tokens chunks outside (include O)
Train 444,777 229,989 92,839 1.377
Test 28,382 13,879 5,493 1.363
</table>
<tableCaption confidence="0.879868666666667">
Table 3:The information of data set
Table 4 shows the chunking performance of
close test and open test when HMM and ten folds
</tableCaption>
<table confidence="0.9997028">
Close Test (%) Open Test (%)
F RCB LA F RCB LA
Baseline 81.95 6.55 99.46 81.44 6.58 99.47
HMM 94.79 2.62 99.78 88.39 3.18 99.65
HMM+EC 95.11 2.38 99.91 91.13 2.87 99.80
</table>
<tableCaption confidence="0.992742">
Table 4:The overall performance of chunking
</tableCaption>
<bodyText confidence="0.9993714">
As can be seen, the performance of open test
doesn’t drop much. For open test, HMM achieves
6.9% F improvement, 3.4% RCB reduction on
baseline; error correction gets another 2.7% F
improvement, 0.3% RCB reduction. Labeling
accuracy is so high even with the baseline, which
indicates that the hard point of chunking is to
identify the boundaries of each chunk.
Table 5 shows the performance of each type of
chunks respectively. NP and VP amount to
approximately 76% of all chunks, so their
chunking performance dominates the overall
performance. Although we extend VP and PP, their
performances are much better than overall. The
performance of INDP can arrive 99% although it is
much longer than other types. Because its surface
evidences are clear and complete owing to its
definition: the meta-data of a document, all the
descriptions inside a pair of parenthesis, and also
certain fixed phrases which do not act as a
syntactic constituent in a sentence. From the
relative lower performance of NP, but the most
part of all chunks, we can conclude that the hardest
issue of Chinese chunking is to identify boundaries
of NPs.
</bodyText>
<table confidence="0.999246571428572">
Percent ALen P R F
age(%) (tokens) (%) (%) (%)
NP 45.94 1.649 88.82 86.25 87.52
VP 29.82 1.416 96.60 96.49 96.55
PP 6.59 1.221 93.67 93.58 93.63
MP 3.69 1.818 89.51 86.33 87.89
ADJP 3.77 1.308 86.11 89.43 87.74
SP 2.71 1.167 84.70 84.03 84.36
TP 2.59 1.251 93.23 94.30 93.76
CONJP 2.22 1.000 97.20 98.73 97.96
INDP 1.41 4.297 99.06 99.06 99.06
ADVP 1.06 1.117 85.48 85.03 85.25
INTJP 0.23 1.016 68.75 95.65 80.00
ALL 100 1.507 91.70 90.55 91.13
</table>
<tableCaption confidence="0.987665">
Table 5:The result of each type with our spec
</tableCaption>
<bodyText confidence="0.999922">
All the chunking errors could be classified into
four types: wrong labeling, under-combining, over-
combining and overlapping. Table 6 lists the
number and percentage of each type of errors.
Under-combining errors count about a half
number of overall chunking errors, however it is
</bodyText>
<equation confidence="0.4835969">
max( ( ,
count t m
i jj k
,
2
,
))
xk
P(wi  |tomi, xi) =
)
</equation>
<bodyText confidence="0.997395166666667">
not a problem in certain applications because they
does not cross the brackets, thus there are still
opportunities to combine them later with additional
knowledge. If we evaluate the chunking result
without counting those under-combining errors, the
F score of the proposed chunker achieves 95.45%.
</bodyText>
<table confidence="0.9946408">
Error type No.of the Errors Percentage
Wrong labeling 22 2.56%
Under-combine 418 48.71%
Over-combining 339 39.51%
Overlapping 59 6.88%
</table>
<tableCaption confidence="0.99026">
Table 6:The distribution of chunking errors
</tableCaption>
<bodyText confidence="0.999926625">
With comparison we also use some other
learning methods, MBL(Bosch and Buchholz,
2002), SVM(Kudoh and Matsumoto, 2001) and
TBL to build the chunker. The features for MBL
and SVM are the POS of current, left two and right
two words, lexical of current, left one and right one
word. TiMBL4 and SVM-light5 are used as the
tools. For SVM, we convert the chunk marks
BIOES to BI and the binary class SVM is used to
classifier the chunk boundary, then some rules are
used to identify its label. For TBL, the rule
templates are all the possible combinations of the
features and the initial state is that each word is a
chunk. Table 7 shows the result. As seen, without
error correction all these models do not perform
well and our HMM gets the best performance.
</bodyText>
<table confidence="0.9762145">
MBL SVM TBL HMM
F(%) 85.31 86.25 86.92 88.39
</table>
<tableCaption confidence="0.976918">
Table 7:Comparison with different algorithms
</tableCaption>
<subsectionHeader confidence="0.989644">
6.2 Further applications
</subsectionHeader>
<bodyText confidence="0.9990275">
The length of chunks with our spec (AoL is 1.38)
is longer than other Treebank-derived specs (AoL
of S1 is 1.239) and closer to the constituents of
sentence. Thus there are several applications
benefit from the fact, such as:
1) The longest/full noun phrase identification.
According to our statistics, due to including noun-
noun compounds, ‘a_n_n’ and ‘m_n_n’ inside NPs,
65% noun chunks are already the longest/full noun
phrases and other 22% could become the longest
/full noun phrases by only one next combining step.
2) The predicate-verb identification.
By extending the average length of VPs, the main
verb (or predicate-verb, also called tensed verb in
English) of a given sentence could be identified
based on certain surface evidences with a relatively
high accuracy. With certain definition our statistics
based on our test set show that 84.88% of those
main verbs are located in the first longest VPs
among all VPs in a sentence.
</bodyText>
<footnote confidence="0.994989">
4 http://ilk.kub.nl/software.html
5 http://svmlight.joachims.org/
</footnote>
<sectionHeader confidence="0.998642" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999959518518518">
For chunking spec, the CoNLL2000 shared task
defines a program chunklink to extract chunks
from English Treebank. (Li, 2003) defines the
similar Treebank-derived spec for Chinese and she
reports manual check is also needed to make data
consistent. Part of the Sparkle project has
concentrates on a spec based on un-bracketed
corpus of English, Italian, French and
German(Carroll et al., 1997). (Zhou, 2002) defines
base phrase which is similar as chunk for Chinese,
but his annotation and experiment are on his own
corpus.
For chunking algorithm, many machine learning
(ML) methods have been applied and got
promising results after chunking is represented as
tagging problem, such as: SVM (Kudoh and
Matsumoto, 2001), Memory-based (Bosch and
Buchholz, 2002), SNoW (Li and Roth), et al..
Some rule-base chunking (Kinyon, 2003) and
combining rules with learning (Park and Zhang,
2003) are also reported.
For annotation, (Brants, 2000) reports the inter-
annotator agreement of part-of-speech annotations
is 98.57%, the one of structural annotations is
92.43% and some consistency measures. (Xue et
al., 2002) also address some issues related to
building a large-scale Chinese corpus.
</bodyText>
<sectionHeader confidence="0.996652" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999966">
We propose a solution of Chinese chunking with
another type of spec that is based on un-bracketed
corpus rather than derived from a Treebank.
Through spec drafting and annotating, most
significant syntactic ambiguous patterns have been
studied, and those observations in turn have been
described in the spec carefully. The proposed
method of defining a chunking spec helps us find a
proper solution for the hard problems of chunking
Chinese. The experiments show that with our spec,
the overall Chinese chunking F-measure achieves
91.13% and 95.45% if under-combining errors are
not counted.
</bodyText>
<sectionHeader confidence="0.997999" genericHeader="acknowledgments">
9 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999602333333333">
We would like to thank the members of the
Natural Language Computing Group at Microsoft
Research Asia. Especial acknowledgement is to the
anonymous reviewers for their insightful
comments and suggestions. Based on that we have
revised the paper accordingly.
</bodyText>
<sectionHeader confidence="0.996355" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997447371794872">
S. Abney. 1991. Parsing by chunks. In Principle-
Based Parsing. Kluwer Academic Publishers,
Dordrecht: 257–278.
L.A. Ramshaw and M.P. Marcus. 1995. Text
chunkingusing transformation-based learning. In
Proceedings of the 3rd ACL/SIGDAT Workshop,
Cambridge, Massachusetts, USA: 82–94.
E. Tjong Kim Sang and S. Buchholz. 2000.
Introduction to the CoNLL-2000 shared task:
Chunking. In Proceedings of CoNLL-2000 and
LLL-2000, Lisbon, Portugal: 127–132.
Sujian Li, Qun Liu and Zhifeng Yang. 2003.
Chunking based on maximum entropy. Chinese
Journal of Computer, 25(12): 1734–1738.
Heng Li, Jingbo Zhu and Tianshun Yao. 2004.
SVM based Chinese text chunking. Journal of
Chinese Information Processing, 18(2): 1–7.
Nianwen Xue and Fei Xia. 2000. The Bracketing
Guidelines for the Penn Chinese Treebank(3.0).
Technical report ,University of Pennsylvania,
URL http:// www.cis.upenn.edu/~chinese/.
Eric Brill. Transformation-based error-driven
learning and natural language processing: A case
study in part of speech tagging. Computational
Linguistics,21 (4):543–565.
Shiwen Yu, Huiming Duan, Xuefeng Zhu, et al.
2002. The basic processing of contemporary
Chinese corpus at Peking University. Journal of
Chinese Information Processing, 16(6): 58–65.
K.A. Kaufman and R.S. Michalski. 1999. Learning
from inconsistent and noisy data: the AQ18
approach, Proceedings of the Eleventh
International Symposium on Methodologies for
Intelligent Systems, Warsaw: 411–419.
Endong Xun and Changning Huang. 2000. A
unified statistical model for the identification of
English baseNP, In Proceedings of the 38th ACL:
109–117.
Jianfeng Gao, Joshua Goodman, Mingjing Li, Kai-
Fu Lee. Toward a unified approach to statistical
language modeling for Chinese. ACM
Transactions on Asian Language Information
Processing, Vol. 1, No. 1, 2002: 3-33.
Dekai WU, Grace NGAI, Marine CARPUAT. N-
fold Templated Piped Correction. Proceedings of
the First International Joint Conference on
Natural Language Processing, SANYA: 632–
637.
Antal van den Bosch and S. Buchholz. 2002.
Shallow parsing on the basis of words only: a
case study, In Proceedings of the 40th ACL: 433–
440.
Taku Kudo and Yuji Matsumoto. 2000. Use of
support vector learning for chunk identification,
In Proceedings of the 4th CoNLL: 142–144.
J. Carroll, T. Briscoe, G. Carroll et al. 1997.
Phrasal parsing software. Sparkle Work
Package 3, Deliverable D3.2.
Yuqi Zhang and Qiang Zhou. 2002. Automatic
identification of Chinese base phrases. Journal
of Chinese Information Processing, 16(6):1–8.
X. Li and D. Roth. 2001. Exploring evidence for
shallow parsing. In Proceedings of the 5th
CoNLL.
Alexandra Kinyon. 2003. A language-independent
shallow-parser compiler. In Proceedings of 10th
EACL Conference, Toulouse, France: 322-329.
S.-B. Park, B.-T. Zhang. 2003. Text chunking by
combining hand-crafted rules and memory-based,
In Proceedings of the 41th ACL: 497–504.
Thorsten Brants. 2000. Inter-annotator agreement
for a German newspaper corpus, In Second
International Conference on Language
Resources and Evaluation LREC-2000, Athens,
Greece: 69–76.
Nianwen Xue, Fu-Dong Chiou and M. Palmer.
2002. Building a large-scale annotated Chinese
corpus, In Proceedings of COLING.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.395487">
<title confidence="0.99873">Chinese Chunking with another Type of Spec</title>
<author confidence="0.996799">Hongqiao Li</author>
<affiliation confidence="0.984837">Beijing Institute of Technology</affiliation>
<address confidence="0.996729">Beijing 100081 China</address>
<email confidence="0.985812">lhqtxm@bit.edu.cn</email>
<author confidence="0.971035">Chang-Ning Huang</author>
<affiliation confidence="0.999886">Microsoft Research Asia</affiliation>
<address confidence="0.997566">Beijing 100080 China</address>
<email confidence="0.97046">cnhuang@msrchina.research.microsoft.com</email>
<author confidence="0.890024">Jianfeng Gao</author>
<affiliation confidence="0.999856">Microsoft Research Asia</affiliation>
<address confidence="0.991406">Beijing 100080 China</address>
<email confidence="0.999895">jfgao@microsoft.com</email>
<author confidence="0.985051">Xiaozhong Fan</author>
<affiliation confidence="0.9800555">Beijing Institute of Technology</affiliation>
<address confidence="0.995072">Beijing 100081 China</address>
<email confidence="0.994698">fxz@bit.edu.cn</email>
<abstract confidence="0.971326">Spec is a critical issue for automatic chunking. This paper proposes a solution of Chinese chunking with another type of spec, which is not derived from a complete syntactic tree but only based on the un-bracketed, POS tagged corpus. With this spec, a chunked data is built and HMM is used to build the chunker. TBLbased error correction is used to further improve chunking performance. The average chunk length is about 1.38 tokens, F measure of chunking achieves 91.13%, labeling accuracy alone achieves 99.80% and the ratio of crossing brackets is 2.87%. We also find that the hardest point of Chinese chunking is to identify the chunking boundary inside</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Parsing by chunks. In PrincipleBased Parsing.</title>
<date>1991</date>
<pages>257--278</pages>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="1105" citStr="Abney (1991)" startWordPosition="161" endWordPosition="162">king with another type of spec, which is not derived from a complete syntactic tree but only based on the un-bracketed, POS tagged corpus. With this spec, a chunked data is built and HMM is used to build the chunker. TBLbased error correction is used to further improve chunking performance. The average chunk length is about 1.38 tokens, F measure of chunking achieves 91.13%, labeling accuracy alone achieves 99.80% and the ratio of crossing brackets is 2.87%. We also find that the hardest point of Chinese chunking is to identify the chunking boundary inside noun-noun sequences1. 1 Introduction Abney (1991) has proposed chunking as a useful and relative tractable median stage that is to divide sentences into non-overlapping segments only based on superficial analysis and local information. (Ramshaw and Marcus, 1995) represent chunking as tagging problem and the CoNLL2000 shared task (Kim Sang and Buchholz, 2000) is now the standard evaluation task for chunking English. Their work has inspired many others to study chunking for other human languages. Besides the chunking algorithm, spec (the detailed definitions of all chunk types) is another critical issue for automatic chunking development. The </context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>S. Abney. 1991. Parsing by chunks. In PrincipleBased Parsing. Kluwer Academic Publishers, Dordrecht: 257–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M P Marcus</author>
</authors>
<title>Text chunkingusing transformation-based learning.</title>
<date>1995</date>
<booktitle>In Proceedings of the 3rd ACL/SIGDAT Workshop,</booktitle>
<pages>82--94</pages>
<location>Cambridge, Massachusetts, USA:</location>
<contexts>
<context position="1318" citStr="Ramshaw and Marcus, 1995" startWordPosition="190" endWordPosition="193">ild the chunker. TBLbased error correction is used to further improve chunking performance. The average chunk length is about 1.38 tokens, F measure of chunking achieves 91.13%, labeling accuracy alone achieves 99.80% and the ratio of crossing brackets is 2.87%. We also find that the hardest point of Chinese chunking is to identify the chunking boundary inside noun-noun sequences1. 1 Introduction Abney (1991) has proposed chunking as a useful and relative tractable median stage that is to divide sentences into non-overlapping segments only based on superficial analysis and local information. (Ramshaw and Marcus, 1995) represent chunking as tagging problem and the CoNLL2000 shared task (Kim Sang and Buchholz, 2000) is now the standard evaluation task for chunking English. Their work has inspired many others to study chunking for other human languages. Besides the chunking algorithm, spec (the detailed definitions of all chunk types) is another critical issue for automatic chunking development. The well-defined spec can induce the chunker to perform well. Currently chunking specs are defined as some rules or one program to extract phrases from Treebank such as (Li, 2003) and (Li, 2004) in order to save the c</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>L.A. Ramshaw and M.P. Marcus. 1995. Text chunkingusing transformation-based learning. In Proceedings of the 3rd ACL/SIGDAT Workshop, Cambridge, Massachusetts, USA: 82–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Tjong Kim Sang</author>
<author>S Buchholz</author>
</authors>
<title>Introduction to the CoNLL-2000 shared task: Chunking.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000,</booktitle>
<pages>127--132</pages>
<location>Lisbon, Portugal:</location>
<contexts>
<context position="1416" citStr="Sang and Buchholz, 2000" startWordPosition="205" endWordPosition="208">rage chunk length is about 1.38 tokens, F measure of chunking achieves 91.13%, labeling accuracy alone achieves 99.80% and the ratio of crossing brackets is 2.87%. We also find that the hardest point of Chinese chunking is to identify the chunking boundary inside noun-noun sequences1. 1 Introduction Abney (1991) has proposed chunking as a useful and relative tractable median stage that is to divide sentences into non-overlapping segments only based on superficial analysis and local information. (Ramshaw and Marcus, 1995) represent chunking as tagging problem and the CoNLL2000 shared task (Kim Sang and Buchholz, 2000) is now the standard evaluation task for chunking English. Their work has inspired many others to study chunking for other human languages. Besides the chunking algorithm, spec (the detailed definitions of all chunk types) is another critical issue for automatic chunking development. The well-defined spec can induce the chunker to perform well. Currently chunking specs are defined as some rules or one program to extract phrases from Treebank such as (Li, 2003) and (Li, 2004) in order to save the cost of manual annotation. We name it as Treebank-derived spec. However, we find that it is more va</context>
<context position="10536" citStr="Sang and Buchholz, 2000" startWordPosition="1651" endWordPosition="1654">unking. So a trade-off between the average chunk length and the chunking performance exists. 3.1 Why another type of spec is needed A convenient spec is to extract the lowest nonterminal nodes from a Treebank (e.g. CTB) as Chinese chunked data. But there are some problems. The trees are designed for full parsing instead of shallow parsing, thus some of these problems listed in section 2 could not be resolved well in chunking. Maybe we can compile some rules to prune the tree or break some non-terminal nodes in order to properly resolve these problems just like CoNLL2000. However, just as (Kim Sang and Buchholz, 2000) noted: “some trees are very complex and some annotations are inconsistent”. So these rules are complex, the extracted data are inconsistent and manual check is also needed. In addition, the resource of Chinese Treebank is limited and the extracted data is not enough for chunking. So we compile another type of chunking spec according to the observation from un-bracket corpus instead of Treebank. The only shortcoming is the cost of annotation, but there are some advantages for us to explore. 1) It coincides with auto chunking procedure, and we can select proper solutions to these problems witho</context>
</contexts>
<marker>Sang, Buchholz, 2000</marker>
<rawString>E. Tjong Kim Sang and S. Buchholz. 2000. Introduction to the CoNLL-2000 shared task: Chunking. In Proceedings of CoNLL-2000 and LLL-2000, Lisbon, Portugal: 127–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujian Li</author>
<author>Qun Liu</author>
<author>Zhifeng Yang</author>
</authors>
<title>Chunking based on maximum entropy.</title>
<date>2003</date>
<journal>Chinese Journal of Computer,</journal>
<volume>25</volume>
<issue>12</issue>
<pages>1734--1738</pages>
<marker>Li, Liu, Yang, 2003</marker>
<rawString>Sujian Li, Qun Liu and Zhifeng Yang. 2003. Chunking based on maximum entropy. Chinese Journal of Computer, 25(12): 1734–1738.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Li</author>
<author>Jingbo Zhu</author>
<author>Tianshun Yao</author>
</authors>
<title>SVM based Chinese text chunking.</title>
<date>2004</date>
<journal>Journal of Chinese Information Processing,</journal>
<volume>18</volume>
<issue>2</issue>
<pages>1--7</pages>
<marker>Li, Zhu, Yao, 2004</marker>
<rawString>Heng Li, Jingbo Zhu and Tianshun Yao. 2004. SVM based Chinese text chunking. Journal of Chinese Information Processing, 18(2): 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
</authors>
<title>The Bracketing Guidelines for the Penn Chinese Treebank(3.0).</title>
<date>2000</date>
<tech>Technical report</tech>
<institution>University of Pennsylvania, URL</institution>
<note>http:// www.cis.upenn.edu/~chinese/.</note>
<contexts>
<context position="2581" citStr="Xue and Xia, 2000" startWordPosition="395" endWordPosition="398">ank-derived spec. However, we find that it is more valuable to compile another type of chunking spec according to the observation from un-bracketed corpus instead of Treebank. 1 This work was done while Hongqiao Li was visiting Microsoft Research Asia. Based on the problems of chunking Chinese that are found with our observation, we explain the reason why another type of spec is needed and then propose our spec in which the shortening and extending strategies are used to resolve these problems. We also compare our spec with a Treebank-derived spec which is derived from Chinese Treebank (CTB) (Xue and Xia, 2000). An annotated chunking corpus is built with the spec and then a chunker is also constructed accordingly. For annotation, we adopt a two-stage processing, in which text is first chunked manually and then the potential inconsistent annotations are checked semi-automatically with a tool. For the chunker, we use HMM model and TBL (Transform-based Learning) (Brill, 1995) based error correction to further improve chunking performance. With our spec the overall average length of chunks arrives 1.38 tokens, in open test, the chunking F measure achieves 91.13% and 95.45% if under-combining errors are </context>
</contexts>
<marker>Xue, Xia, 2000</marker>
<rawString>Nianwen Xue and Fei Xia. 2000. The Bracketing Guidelines for the Penn Chinese Treebank(3.0). Technical report ,University of Pennsylvania, URL http:// www.cis.upenn.edu/~chinese/.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging.</title>
<booktitle>Computational Linguistics,21</booktitle>
<pages>4--543</pages>
<marker>Brill, </marker>
<rawString>Eric Brill. Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging. Computational Linguistics,21 (4):543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiwen Yu</author>
<author>Huiming Duan</author>
<author>Xuefeng Zhu</author>
</authors>
<title>The basic processing of contemporary Chinese corpus at Peking University.</title>
<date>2002</date>
<journal>Journal of Chinese Information Processing,</journal>
<volume>16</volume>
<issue>6</issue>
<pages>58--65</pages>
<marker>Yu, Duan, Zhu, 2002</marker>
<rawString>Shiwen Yu, Huiming Duan, Xuefeng Zhu, et al. 2002. The basic processing of contemporary Chinese corpus at Peking University. Journal of Chinese Information Processing, 16(6): 58–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K A Kaufman</author>
<author>R S Michalski</author>
</authors>
<title>Learning from inconsistent and noisy data: the AQ18 approach,</title>
<date>1999</date>
<booktitle>Proceedings of the Eleventh International Symposium on Methodologies for Intelligent Systems,</booktitle>
<pages>411--419</pages>
<location>Warsaw:</location>
<marker>Kaufman, Michalski, 1999</marker>
<rawString>K.A. Kaufman and R.S. Michalski. 1999. Learning from inconsistent and noisy data: the AQ18 approach, Proceedings of the Eleventh International Symposium on Methodologies for Intelligent Systems, Warsaw: 411–419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Endong Xun</author>
<author>Changning Huang</author>
</authors>
<title>A unified statistical model for the identification of English baseNP,</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th ACL:</booktitle>
<pages>109--117</pages>
<contexts>
<context position="20453" citStr="Xun and Huang, 2000" startWordPosition="3329" endWordPosition="3332">nnotations. For example, one inputs a POS pattern: ‘a_n_n’, and an expected annotation result: ‘B-NP_I-NP_E-NP3’, the tool will list all the consistent and inconsistent sentences in the annotated text respectively. Based on the output one can revise those inconsistent results one by one, and finally the consistency of the chunked text will be improved step by step. 5 Chunking Model After annotating the corpus, we could use various learning algorithms to build the chunking model. In this paper, HMM is selected because not only its training speed is fast, but also it has comparable performance (Xun and Huang, 2000). Automatic chunking with HMM should conduct the following two steps. 1) Identify boundaries of each chunk. It is to assign each word a chunk mark, named M, which contains 5 classes: B, I, E, S (a single word chunk) and O (outside all chunks). 2) Tag the chunk type, named X, which contains 11 types defined in Section 3. So each word will be tagged with two tags: M and X (the words excluding from any chunk only have M). So the result after chunking is a sequence of triples (t, m, x), where t, m, x represent POS tag, chunk mark and chunk type respectively. All the triples of a chunk are combined</context>
</contexts>
<marker>Xun, Huang, 2000</marker>
<rawString>Endong Xun and Changning Huang. 2000. A unified statistical model for the identification of English baseNP, In Proceedings of the 38th ACL: 109–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Joshua Goodman</author>
<author>Mingjing Li</author>
<author>KaiFu Lee</author>
</authors>
<title>Toward a unified approach to statistical language modeling for Chinese.</title>
<date>2002</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>1</volume>
<pages>3--33</pages>
<contexts>
<context position="21990" citStr="Gao et al., 2002" startWordPosition="3658" endWordPosition="3661">C P W C T P C T ( |, ) ( , ) C Independent assumption is used to approximate P(W|C,T), that is: 3 B, E, I represent the left/right boundary of a chunk and inside a chunk respectively, B-NP means this word is the beginning of NP. ) = arg max (3) = arg max m (4) TBL based error correction (EC) are done P W C T respectively. ( |, ) &apos; ∏ P w i ti mi xi ( |, , ) i=1 If the triple is unseen, formula 5 is used. count t m x ( , , i i i For P(C, T), tri-grams among chunks and outside words are used to approximate, that is: / k P(C,T)&apos; Pln1)P(n2 |n1)∏ P(ni |ni−2ni−1) i=3 Smoothing follows the method of (Gao et al., 2002). In order to improve the performance we use Nfold error correction (Wu, 2004) technique to reduce the error rate and TBL is used to learn the error correction rules based on the output of HMM. 6 Data and Evaluation The performance of chunking is commonly measured with three figures: precision (P), recall (R) and F measure that are defined in CoNLL2000. Besides these, we also use two other measurements to evaluate the performance of bracketing and labeling respectively: RCB(ratio of crossing brackets), that is the percentage of the found brackets which cross the correct brackets; LA(labeling a</context>
</contexts>
<marker>Gao, Goodman, Li, Lee, 2002</marker>
<rawString>Jianfeng Gao, Joshua Goodman, Mingjing Li, KaiFu Lee. Toward a unified approach to statistical language modeling for Chinese. ACM Transactions on Asian Language Information Processing, Vol. 1, No. 1, 2002: 3-33.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Dekai WU</author>
<author>Grace NGAI</author>
<author>Marine CARPUAT</author>
</authors>
<title>Nfold Templated Piped Correction.</title>
<booktitle>Proceedings of the First International Joint Conference on Natural Language Processing,</booktitle>
<pages>632--637</pages>
<location>SANYA:</location>
<marker>WU, NGAI, CARPUAT, </marker>
<rawString>Dekai WU, Grace NGAI, Marine CARPUAT. Nfold Templated Piped Correction. Proceedings of the First International Joint Conference on Natural Language Processing, SANYA: 632– 637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antal van den Bosch</author>
<author>S Buchholz</author>
</authors>
<title>Shallow parsing on the basis of words only: a case study,</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th ACL: 433–</booktitle>
<pages>440</pages>
<marker>van den Bosch, Buchholz, 2002</marker>
<rawString>Antal van den Bosch and S. Buchholz. 2002. Shallow parsing on the basis of words only: a case study, In Proceedings of the 40th ACL: 433– 440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Use of support vector learning for chunk identification,</title>
<date>2000</date>
<booktitle>In Proceedings of the 4th CoNLL:</booktitle>
<pages>142--144</pages>
<marker>Kudo, Matsumoto, 2000</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2000. Use of support vector learning for chunk identification, In Proceedings of the 4th CoNLL: 142–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>T Briscoe</author>
<author>G Carroll</author>
</authors>
<date>1997</date>
<booktitle>Phrasal parsing software. Sparkle Work Package 3, Deliverable D3.2.</booktitle>
<contexts>
<context position="28503" citStr="Carroll et al., 1997" startWordPosition="4755" endWordPosition="4758">inition our statistics based on our test set show that 84.88% of those main verbs are located in the first longest VPs among all VPs in a sentence. 4 http://ilk.kub.nl/software.html 5 http://svmlight.joachims.org/ 7 Related Work For chunking spec, the CoNLL2000 shared task defines a program chunklink to extract chunks from English Treebank. (Li, 2003) defines the similar Treebank-derived spec for Chinese and she reports manual check is also needed to make data consistent. Part of the Sparkle project has concentrates on a spec based on un-bracketed corpus of English, Italian, French and German(Carroll et al., 1997). (Zhou, 2002) defines base phrase which is similar as chunk for Chinese, but his annotation and experiment are on his own corpus. For chunking algorithm, many machine learning (ML) methods have been applied and got promising results after chunking is represented as tagging problem, such as: SVM (Kudoh and Matsumoto, 2001), Memory-based (Bosch and Buchholz, 2002), SNoW (Li and Roth), et al.. Some rule-base chunking (Kinyon, 2003) and combining rules with learning (Park and Zhang, 2003) are also reported. For annotation, (Brants, 2000) reports the interannotator agreement of part-of-speech anno</context>
</contexts>
<marker>Carroll, Briscoe, Carroll, 1997</marker>
<rawString>J. Carroll, T. Briscoe, G. Carroll et al. 1997. Phrasal parsing software. Sparkle Work Package 3, Deliverable D3.2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuqi Zhang</author>
<author>Qiang Zhou</author>
</authors>
<title>Automatic identification of Chinese base phrases.</title>
<date>2002</date>
<journal>Journal of Chinese Information Processing,</journal>
<volume>16</volume>
<issue>6</issue>
<marker>Zhang, Zhou, 2002</marker>
<rawString>Yuqi Zhang and Qiang Zhou. 2002. Automatic identification of Chinese base phrases. Journal of Chinese Information Processing, 16(6):1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>D Roth</author>
</authors>
<title>Exploring evidence for shallow parsing.</title>
<date>2001</date>
<booktitle>In Proceedings of the 5th CoNLL.</booktitle>
<marker>Li, Roth, 2001</marker>
<rawString>X. Li and D. Roth. 2001. Exploring evidence for shallow parsing. In Proceedings of the 5th CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Kinyon</author>
</authors>
<title>A language-independent shallow-parser compiler.</title>
<date>2003</date>
<booktitle>In Proceedings of 10th EACL Conference,</booktitle>
<pages>322--329</pages>
<location>Toulouse, France:</location>
<contexts>
<context position="28936" citStr="Kinyon, 2003" startWordPosition="4824" endWordPosition="4825">lso needed to make data consistent. Part of the Sparkle project has concentrates on a spec based on un-bracketed corpus of English, Italian, French and German(Carroll et al., 1997). (Zhou, 2002) defines base phrase which is similar as chunk for Chinese, but his annotation and experiment are on his own corpus. For chunking algorithm, many machine learning (ML) methods have been applied and got promising results after chunking is represented as tagging problem, such as: SVM (Kudoh and Matsumoto, 2001), Memory-based (Bosch and Buchholz, 2002), SNoW (Li and Roth), et al.. Some rule-base chunking (Kinyon, 2003) and combining rules with learning (Park and Zhang, 2003) are also reported. For annotation, (Brants, 2000) reports the interannotator agreement of part-of-speech annotations is 98.57%, the one of structural annotations is 92.43% and some consistency measures. (Xue et al., 2002) also address some issues related to building a large-scale Chinese corpus. 8 Conclusion We propose a solution of Chinese chunking with another type of spec that is based on un-bracketed corpus rather than derived from a Treebank. Through spec drafting and annotating, most significant syntactic ambiguous patterns have b</context>
</contexts>
<marker>Kinyon, 2003</marker>
<rawString>Alexandra Kinyon. 2003. A language-independent shallow-parser compiler. In Proceedings of 10th EACL Conference, Toulouse, France: 322-329.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-B Park</author>
<author>B-T Zhang</author>
</authors>
<title>Text chunking by combining hand-crafted rules and memory-based,</title>
<date>2003</date>
<booktitle>In Proceedings of the 41th ACL:</booktitle>
<pages>497--504</pages>
<contexts>
<context position="28993" citStr="Park and Zhang, 2003" startWordPosition="4831" endWordPosition="4834">parkle project has concentrates on a spec based on un-bracketed corpus of English, Italian, French and German(Carroll et al., 1997). (Zhou, 2002) defines base phrase which is similar as chunk for Chinese, but his annotation and experiment are on his own corpus. For chunking algorithm, many machine learning (ML) methods have been applied and got promising results after chunking is represented as tagging problem, such as: SVM (Kudoh and Matsumoto, 2001), Memory-based (Bosch and Buchholz, 2002), SNoW (Li and Roth), et al.. Some rule-base chunking (Kinyon, 2003) and combining rules with learning (Park and Zhang, 2003) are also reported. For annotation, (Brants, 2000) reports the interannotator agreement of part-of-speech annotations is 98.57%, the one of structural annotations is 92.43% and some consistency measures. (Xue et al., 2002) also address some issues related to building a large-scale Chinese corpus. 8 Conclusion We propose a solution of Chinese chunking with another type of spec that is based on un-bracketed corpus rather than derived from a Treebank. Through spec drafting and annotating, most significant syntactic ambiguous patterns have been studied, and those observations in turn have been des</context>
</contexts>
<marker>Park, Zhang, 2003</marker>
<rawString>S.-B. Park, B.-T. Zhang. 2003. Text chunking by combining hand-crafted rules and memory-based, In Proceedings of the 41th ACL: 497–504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>Inter-annotator agreement for a German newspaper corpus,</title>
<date>2000</date>
<booktitle>In Second International Conference on Language Resources and Evaluation LREC-2000,</booktitle>
<pages>69--76</pages>
<location>Athens, Greece:</location>
<contexts>
<context position="29043" citStr="Brants, 2000" startWordPosition="4840" endWordPosition="4841">keted corpus of English, Italian, French and German(Carroll et al., 1997). (Zhou, 2002) defines base phrase which is similar as chunk for Chinese, but his annotation and experiment are on his own corpus. For chunking algorithm, many machine learning (ML) methods have been applied and got promising results after chunking is represented as tagging problem, such as: SVM (Kudoh and Matsumoto, 2001), Memory-based (Bosch and Buchholz, 2002), SNoW (Li and Roth), et al.. Some rule-base chunking (Kinyon, 2003) and combining rules with learning (Park and Zhang, 2003) are also reported. For annotation, (Brants, 2000) reports the interannotator agreement of part-of-speech annotations is 98.57%, the one of structural annotations is 92.43% and some consistency measures. (Xue et al., 2002) also address some issues related to building a large-scale Chinese corpus. 8 Conclusion We propose a solution of Chinese chunking with another type of spec that is based on un-bracketed corpus rather than derived from a Treebank. Through spec drafting and annotating, most significant syntactic ambiguous patterns have been studied, and those observations in turn have been described in the spec carefully. The proposed method </context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. Inter-annotator agreement for a German newspaper corpus, In Second International Conference on Language Resources and Evaluation LREC-2000, Athens, Greece: 69–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fu-Dong Chiou</author>
<author>M Palmer</author>
</authors>
<title>Building a large-scale annotated Chinese corpus,</title>
<date>2002</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="29215" citStr="Xue et al., 2002" startWordPosition="4863" endWordPosition="4866">d experiment are on his own corpus. For chunking algorithm, many machine learning (ML) methods have been applied and got promising results after chunking is represented as tagging problem, such as: SVM (Kudoh and Matsumoto, 2001), Memory-based (Bosch and Buchholz, 2002), SNoW (Li and Roth), et al.. Some rule-base chunking (Kinyon, 2003) and combining rules with learning (Park and Zhang, 2003) are also reported. For annotation, (Brants, 2000) reports the interannotator agreement of part-of-speech annotations is 98.57%, the one of structural annotations is 92.43% and some consistency measures. (Xue et al., 2002) also address some issues related to building a large-scale Chinese corpus. 8 Conclusion We propose a solution of Chinese chunking with another type of spec that is based on un-bracketed corpus rather than derived from a Treebank. Through spec drafting and annotating, most significant syntactic ambiguous patterns have been studied, and those observations in turn have been described in the spec carefully. The proposed method of defining a chunking spec helps us find a proper solution for the hard problems of chunking Chinese. The experiments show that with our spec, the overall Chinese chunking</context>
</contexts>
<marker>Xue, Chiou, Palmer, 2002</marker>
<rawString>Nianwen Xue, Fu-Dong Chiou and M. Palmer. 2002. Building a large-scale annotated Chinese corpus, In Proceedings of COLING.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>