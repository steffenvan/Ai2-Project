<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000574">
<title confidence="0.9768335">
SHELLFBK: An Information Retrieval-based System For Multi-Domain
Sentiment Analysis
</title>
<author confidence="0.763139">
Mauro Dragoni
</author>
<affiliation confidence="0.570645">
Fondazione Bruno Kessler
</affiliation>
<address confidence="0.6751525">
Via Sommarive 18
Povo, Trento
</address>
<email confidence="0.995756">
dragoni@fbk.eu
</email>
<sectionHeader confidence="0.995605" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999933454545455">
This paper describes the SHELLFBK system
that participated in SemEval 2015 Tasks 9,
10, and 11. Our system takes a supervised
approach that builds on techniques from in-
formation retrieval. The algorithm populates
an inverted index with pseudo-documents that
encode dependency parse relationships ex-
tracted from the sentences in the training set.
Each record stored in the index is annotated
with the polarity and domain of the sentence
it represents. When the polarity or domain of
a new sentence has to be computed, the new
sentence is converted to a query that is used
to retrieve the most similar sentences from the
training set. The retrieved instances are scored
for relevance to the query. The most rele-
vant training instant is used to assign a polarity
and domain label to the new sentence. While
the results on well-formed sentences are en-
couraging, the performance obtained on short
texts like tweets demonstrate that more work
is needed in this area.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996557534883721">
Sentiment analysis is a natural language processing
task whose aim is to classify documents according to
the opinion (polarity) they express on a given sub-
ject (Pang et al., 2002). Generally speaking, sen-
timent analysis aims at determining the attitude of
a speaker or a writer with respect to a topic or the
overall tonality of a document. This task has created
a considerable interest due to its wide applications.
In recent years, the exponential increase of the Web
for exchanging public opinions about events, facts,
products, etc., has led to an extensive usage of senti-
ment analysis approaches, especially for marketing
purposes.
By formalizing the sentiment analysis problem, a
“sentiment” or “opinion” has been defined by (Liu
and Zhang, 2012) as a quintuple:
(oj, fjk, soijkl, hi, tl), (1)
where oj is a target object, fjk is a feature of the
object oj, soijkl is the sentiment value of the opinion
of the opinion holder hi on feature fjk of object oj
at time tl. The value of soijkl can be positive (by
denoting a state of happiness, bliss, or satisfaction),
negative (by denoting a state of sorrow, dejection,
or disappointment), or neutral (it is not possible to
denote any particular sentiment), or a more granular
rating. The term hi encodes the opinion holder, and
tl is the time when the opinion is expressed.
Such an analysis, may be document-based, where
the positive, negative, or neutral sentiment is as-
signed to the entire document content; or it may be
sentence-based where individual sentences are ana-
lyzed separately and classified according to the dif-
ferent polarity values. In the latter case, it is often
desirable to find with a high precision the entity at-
tributes towards which the detected sentiment is di-
rected.
In the classic sentiment analysis problem, the po-
larity of each term within the document is com-
puted independently of the domain which the doc-
ument’s domain. However, conditioning term po-
larity by domain has been found to improve perfor-
mance (Blitzer et al., 2007). We illustrate the intu-
ition behind domain specific term polarity. Let us
</bodyText>
<page confidence="0.954869">
502
</page>
<note confidence="0.9480525">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 502–509,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.5998845">
consider the following example concerning the ad-
jective “small”:
</bodyText>
<listItem confidence="0.85277125">
1. The sideboard is small and it is not able to con-
tain a lot of stuff.
2. The small dimensions of this decoder allow to
move it easily.
</listItem>
<bodyText confidence="0.999881217391304">
In the first sentence, we considered the Furnishings
domain and, within it, the polarity of the adjective
“small” is, for sure, “negative” because it highlights
an issue of the described item. On the other hand, in
the second sentence, where we considered the Elec-
tronics domain, the polarity of such an adjective may
be considered “positive”.
Unlike the approaches already discussed in the lit-
erature (and presented in Section 2), we address the
multi-domain sentiment analysis problem by apply-
ing Information Retrieval (IR) techniques for repre-
senting information about the linguistic structure of
sentences and by taking into account both their po-
larity and the domain.
The rest of the work is structured as follows. Sec-
tion 2 presents a survey on works about sentiment
analysis. Section 3 provides a description of the
SHELLFBK system by described how information
are stored during the training phase and exploited
during the test one. Section 4 reports the system
evaluation performed on the Tasks 9, 10, and 11 pro-
posed at SemEval 2015 and, finally, Section 5 con-
cludes the paper.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999878634920635">
The topic of sentiment analysis has been studied ex-
tensively in the literature (Pang and Lee, 2008; Liu
and Zhang, 2012), where several techniques have
been proposed and validated.
Machine learning techniques are the most com-
mon approaches used for addressing this problem,
given that any existing supervised methods can be
applied to sentiment classification. For instance,
in (Pang et al., 2002) and (Pang and Lee, 2004), the
authors compared the performance of Naive-Bayes,
Maximum Entropy, and Support Vector Machines in
sentiment analysis on different features like consid-
ering only unigrams, bigrams, combination of both,
incorporating parts of speech and position informa-
tion or by taking only adjectives. Moreover, beside
the use of standard machine learning method, re-
searchers have also proposed several custom tech-
niques specifically for sentiment classification, like
the use of adapted score function based on the eval-
uation of positive or negative words in product re-
views (Dave et al., 2003), as well as by defining
weighting schemata for enhancing classification ac-
curacy (Paltoglou and Thelwall, 2010).
An obstacle to research in this direction is the
need of labeled training data, whose preparation is
a time-consuming activity. Therefore, in order to re-
duce the labeling effort, opinion words have been
used for training procedures. In (Tan et al., 2008)
and (Qiu et al., 2009b), the authors used opinion
words to label portions of informative examples for
training the classifiers. Opinion words have been ex-
ploited also for improving the accuracy of sentiment
classification, as presented in (Melville et al., 2009),
where a framework incorporating lexical knowledge
in supervised learning to enhance accuracy has been
proposed. Opinion words have been used also for
unsupervised learning approaches like the ones pre-
sented in (Taboada et al., 2011) and (Turney, 2002).
Another research direction concerns the exploita-
tion of discourse-analysis techniques. (Somasun-
daran, 2010) and (Asher et al., 2008) discuss some
discourse-based supervised and unsupervised ap-
proaches for opinion analysis; while in (Wang and
Zhou, 2010), the authors present an approach to
identify discourse relations.
The approaches presented above are applied at the
document-level, i.e., the polarity value is assigned
to the entire document content. However, for im-
proving the accuracy of the sentiment classification,
a more fine-grained analysis of the text, i.e., the sen-
timent classification of the single sentences, has to
be performed. In the case of sentence-level senti-
ment classification, two different sub-tasks have to
be addressed: (i) to determine if the sentence is sub-
jective or objective, and (ii) in the case that the sen-
tence is subjective, to determine if the opinion ex-
pressed in the sentence is positive, negative, or neu-
tral. The task of classifying a sentence as subjec-
tive or objective, called “subjectivity classification”,
has been widely discussed in the literature (Riloff et
al., 2006; Wiebe et al., 2004; Wilson et al., 2004;
Wilson et al., 2006; Yu and Hatzivassiloglou, 2003).
Once subjective sentences are identified, the same
</bodyText>
<page confidence="0.997372">
503
</page>
<bodyText confidence="0.99994825">
methods as for sentiment classification may be ap-
plied. For example, in (Hatzivassiloglou and Wiebe,
2000) the authors consider gradable adjectives for
sentiment spotting; while in (Kim and Hovy, 2007)
and (Kim et al., 2006) the authors built models to
identify some specific types of opinions.
The growth of product reviews was the perfect
floor for using sentiment analysis techniques in mar-
keting activities. However, the issue of improving
the ability of detecting the different opinions con-
cerning the same product expressed in the same re-
view became a challenging problem. Such a task
has been faced by introducing “aspect” extraction
approaches that were able to extract, from each
sentence, which is the aspect the opinion refers
to. In the literature, many approaches have been
proposed: conditional random fields (CRF) (Jakob
and Gurevych, 2010; Lafferty et al., 2001), hid-
den Markov models (HMM) (Freitag and McCal-
lum, 2000; Jin and Ho, 2009; Jin et al., 2009), se-
quential rule mining (Liu et al., 2005), dependency
tree kernels (Wu et al., 2009), and clustering (Su et
al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a
method was proposed to extract both opinion words
and aspects simultaneously by exploiting some syn-
tactic relations of opinion words and aspects.
A particular attention should be given also to the
application of sentiment analysis in social networks.
More and more often, people use social networks
for expressing their moods concerning their last pur-
chase or, in general, about new products. Such a
social network environment opened up new chal-
lenges due to the different ways people express their
opinions, as described by (Barbosa and Feng, 2010)
and (Bermingham and Smeaton, 2010), who men-
tion “noisy data” as one of the biggest hurdles in
analyzing social network texts.
One of the first studies on sentiment analysis on
micro-blogging websites has been discussed in (Go
et al., 2009), where the authors present a distant
supervision-based approach for sentiment classifica-
tion.
At the same time, the social dimension of the
Web opens up the opportunity to combine com-
puter science and social sciences to better recognize,
interpret, and process opinions and sentiments ex-
pressed over it. Such multi-disciplinary approach
has been called sentic computing (Cambria and Hus-
sain, 2012b). Application domains where sentic
computing has already shown its potential are the
cognitive-inspired classification of images (Cambria
and Hussain, 2012a), of texts in natural language,
and of handwritten text (Wang et al., 2013).
Finally, an interesting recent research direction is
domain adaptation, as it has been shown that senti-
ment classification is highly sensitive to the domain
from which the training data is extracted. A classi-
fier trained using opinionated documents from one
domain often performs poorly when it is applied or
tested on opinionated documents from another do-
main, as we demonstrated through the example pre-
sented in Section 1. The reason is that words and
even language constructs used in different domains
for expressing opinions can be quite different. To
make matters worse, the same word in one domain
may have positive connotations, but in another do-
main may have negative connotations; therefore, do-
main adaptation is needed. In the literature, dif-
ferent approaches related to the Multi-Domain sen-
timent analysis have been proposed. Briefly, two
main categories may be identified: (i) the transfer
of learned classifiers across different domains (Yang
et al., 2006; Blitzer et al., 2007; Pan et al., 2010;
Bollegala et al., 2013; Xia et al., 2013; Yoshida et
al., 2011), and (ii) the use of propagation of labels
through graph structures (Ponomareva and Thelwall,
2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et
al., 2014). Independently of the kind of approach,
works using concepts rather than terms for repre-
senting different sentiments have been proposed.
</bodyText>
<sectionHeader confidence="0.977915" genericHeader="method">
3 The SHELLFBK System
</sectionHeader>
<bodyText confidence="0.999993">
The proposed system is based on the implementa-
tion of an IR approach for inferring both the polarity
of a sentence and, if requested, the domain to which
the sentence belongs to. The rational behind the us-
age of such an approach is that by using indexes, the
computation of the Retrieval Status Value (RSV) (da
Costa Pereira et al., 2012) of a term or expression,
automatically takes into account which are the ele-
ments that are more significant in each index with
respect to the ones that, instead, are not important
with respect to the index content. In this section, we
present the steps we carried out to implement our IR
based sentiment and theme classification system.
</bodyText>
<page confidence="0.987631">
504
</page>
<subsectionHeader confidence="0.977322">
3.1 Indexes Construction
</subsectionHeader>
<bodyText confidence="0.995396285714286">
The proposed approach, with respect to a classic IR
system, does not use a single index for containing
all information, but a set of indexes are created in
order to facilitate the identification of the correct po-
larity and domain, of a sentence during the valida-
tion phase. In particular, we built the following set
of indexes:
</bodyText>
<listItem confidence="0.999059555555556">
• Polarity Indexes: from the training set, the
positive, negative, and neutral sentences have
been indexed separately.
• Domain Indexes:: a different index has been
built for each domain identified in the training
set. This way, it is possible to store information
about which terms, or expression, are relevant
for each domain.
• Mixed Indexes: by considering the multi-
</listItem>
<bodyText confidence="0.859426117647059">
domain nature of the system, this further set of
indexes allows to have, for each domain, infor-
mation about the correlation between the do-
main and the polarities. This way, we are able
to know if the same term, or expression, has the
same polarity in different domains or not.
For each sentence of the training set, we exploited
the Stanford NLP Library for extracting the depen-
dencies between the terms. Such dependencies are
then used as input for the indexing procedure.
As example, let’s consider the following sentence
extracted from the training set of the Task 9:
“I came here to reflect my happiness by fishing.”
This sentence has a positive polarity and belongs
to the “outdoor activity” domain. By applying the
Stanford parser, the dependencies that are extracted
are the following ones:
</bodyText>
<equation confidence="0.638740555555556">
nsubj(came-2, I-1)
nsubj(reflect-5, I-1)
root(ROOT-0, came-2)
advmod(came-2, here-3)
aux(reflect-5, to-4)
xcomp(came-2, reflect-5)
poss(happiness-7, my-6)
dobj(reflect-5, happiness-7)
prep_by(reflect-5, fishing-9)
</equation>
<bodyText confidence="0.999556125">
Each dependency is composed by three elements:
the name of the “relation” (R), the “governor” (G)
that is the first term of the dependency, and the “de-
pendent” (D) that is the second one. We extract,
from each dependency, the structure “field - content”
shown in Table 1 by using as example the depen-
dency “dobj(reflect-5, happiness-7)”. Such a struc-
ture is then given as input to the index.
</bodyText>
<table confidence="0.999778428571429">
Field Name Content
RGD “dobj-reflect-happiness”
RDG “dobj-happiness-reflect”
GD “reflect-happiness”
DG “happiness-reflect”
G “reflect”
D “happiness”
</table>
<tableCaption confidence="0.9869825">
Table 1: Field structure and corresponding content stored
in the index.
</tableCaption>
<bodyText confidence="0.99977025">
The structure shown in Table 1 is created for each
dependency extracted from the sentence and the ag-
gregation of all structures are stored as final record
in the index.
</bodyText>
<subsectionHeader confidence="0.998745">
3.2 Polarity and Domain Computation
</subsectionHeader>
<bodyText confidence="0.999970307692308">
Once the indexes are built, both the polarity and the
domain of each sentence that need to be evaluated,
are computed by performing a set of queries on the
indexes. In our approach, we implemented a varia-
tion of classic IR scoring formula for our purposes.
In the classical TF-IDF IR model (van Rijsbergen,
1979), the inverse document frequency value is used
for identifying which are the most significant docu-
ments with respect to a particular query. This value
is useful when we want to identify the uniqueness
of a document with respect to a term contained in
a query, with respect to the other documents stored
into the index. In our case, the scenario is different
because if a term, or expression, occurs often in the
index, this aspect has to be emphasized instead of
being discriminated. Therefore, in our scoring for-
mula we consider, as final score of a term or an ex-
pression, the document frequency (DF) value (i.e.,
the inverse of the IDF). This way, we are able to in-
fer if a particular term or expression is significant or
not for a given polarity value or domain.
The queries are built with the same procedure
used for creating the records stored in the indexes.
For each sentence to evaluate, a set of queries, one
for each dependency extracted from the sentence is
performed on the indexes and the results are aggre-
</bodyText>
<page confidence="0.991492">
505
</page>
<bodyText confidence="0.916705909090909">
gated for inferring both the polarity and domain of
the sentence.
As example of how the system works, let’s con-
sider the following sentence:
“I feel good and I feel healthy.”
For simplicity, we only consider the following
two extracted dependencies:
acomp feel-2, good-3)
acomp feel-6, healthy-7)
From these two dependencies, we generate the
following two queries:
</bodyText>
<equation confidence="0.42066825">
Q1: &amp;quot;RGD:&amp;quot;acomp-feel-good&amp;quot;
OR RDG:&amp;quot;acomp-good-feel&amp;quot;
OR GD:&amp;quot;feel-good&amp;quot; OR DG:&amp;quot;good-feel&amp;quot;
OR G:&amp;quot;feel&amp;quot; OR D:&amp;quot;good&amp;quot;
Q2: &amp;quot;RGD:&amp;quot;acomp-feel-healthy&amp;quot;
OR RDG:&amp;quot;acomp-healthy-feel&amp;quot;
OR GD:&amp;quot;feel-healthy&amp;quot; OR DG:&amp;quot;healthy-feel&amp;quot;
OR G:&amp;quot;feel&amp;quot; OR D:&amp;quot;healthy&amp;quot;
</equation>
<bodyText confidence="0.999314333333333">
For computing the polarity of the sentence, the
queries are performed on the three indexes con-
taining polarized records: positive (POS), negative
(NEG), and neutral (NEU). From the computed
ranks, we extract only the DF associated to each
field F contained in the query:
</bodyText>
<equation confidence="0.998914">
DF(F) = 1/IDF(F) (2)
</equation>
<bodyText confidence="0.963124333333333">
where DF is the value extracted.
As a direct consequence, for each index I, the
value representing the RSV of a sentence is:
</bodyText>
<equation confidence="0.9996944">
RSV(I) = DF(RGDQ1) + DF(RDGQ1)+
DF(GDQ1) + DF(DGQ1) + DF(GQ1)+
DF(DQ1) + DF(RGDQ2) + DF(RDGQ2)+
DF(GDQ2) + DF(DGQ2) + DF(GQ2)+
DF(DQ2)
</equation>
<bodyText confidence="0.999446333333333">
Finally, the polarity of the sentence S is inferred
by considering the maximum RSV computed over
the three indexes:
</bodyText>
<equation confidence="0.9912935">
Polarity(S) =
argmaxP∈POS,NEU,NEG RSV(S, P)
</equation>
<bodyText confidence="0.9991485">
In case of domain assignment, given a set D of k
domains, the domain is computed by:
</bodyText>
<equation confidence="0.974589">
Domain(S) = argmax Z∈1...k RSV(S, DZ) (5)
</equation>
<sectionHeader confidence="0.999395" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.957132368421053">
The SHELLFBK system participated in three Se-
mEval 2015 tasks: 9, 10, and 11. All three tasks
were about the sentiment analysis topic with the fol-
lowing differences:
• Task 9 (Russo et al., 2015): this task is based on
a dataset of events annotated as instantiations of
pleasant and unpleasant events previously col-
lected in psychological researches as the ones
on which human judgments converge (Lewin-
sohn and Amenson, 1978),(MacPhillamy. and
Lewinsohn, 1982). Task 9 concerns classifica-
tion of the events that are pleasant or unpleas-
ant for a person writing in first person. This
task was organized around two subtasks: (A)
identification of the polarity value associated
to an event instance, and (B) identification of
both the event instantiations and the associated
polarity values. The SHELLFBK system has
been tested on both tasks.
</bodyText>
<listItem confidence="0.998693333333333">
• Task 10 (Rosenthal et al., 2015): this task
aims to identify sentiment polarities in short
text messages contained in the Twitter micro-
blog. This task contains five subtasks: (A)
expression-level, (B) message-level, (C) topic-
related, (D) trend, and (E) a task on prior polar-
ity of terms. The SHELLFBK has been tested
only on the subtask (B).
• Task 11 (Ghosh et al., 2015): this task consists
</listItem>
<bodyText confidence="0.821912818181818">
in the classification of tweets containing irony
and metaphors. Given a set of tweets that are
rich in metaphor and irony, the goal is to deter-
mine whether the user has expressed a positive,
negative, or neutral sentiment in each, and the
degree to which this sentiment has been com-
municated. With respect to the other tasks, here
the polarity is expressed through a fine-grained
scale in the interval [-5, 5].
In the following subsections, we will briefly re-
port the performance obtained on each task.
</bodyText>
<subsectionHeader confidence="0.98233">
4.1 Task 9
</subsectionHeader>
<bodyText confidence="0.989040333333333">
Table 2 reports the results obtained in Task 9. This
task consisted in the identification of the polarity of
a sentence written in first person (subtask A) and in
</bodyText>
<page confidence="0.995434">
506
</page>
<table confidence="0.999466">
Task Precision Recall F-Measure
Subtask A 0.555 0.384 0.454
Subtask B 0.261 0.155 0.197
</table>
<tableCaption confidence="0.999384">
Table 2: Results obtained by the SHELLFBK system on
Task 9.
</tableCaption>
<bodyText confidence="0.999832555555556">
the identification of both the polarity and the do-
main of the sentence (subtask B). Precision, recall
and F-Measure have been computed. As expected,
the accuracy obtained on the sole prediction of the
sentence polarity is higher with respect to the one
obtained on the subtask combining the inference of
both the domain and the polarity itself. Unfortu-
nately, the recall values obtained on both subtasks
are quite low, especially for the subtask B.
</bodyText>
<subsectionHeader confidence="0.990126">
4.2 Task 10
</subsectionHeader>
<bodyText confidence="0.999997777777778">
Performance obtained by the SHELLFBK system
on Task 10 have been reported in Table 3. For this
task, the SHELLFBK system has been tested only
on the message-level polarity subtask (B). By ob-
serving either the overall f-measure and the ones ob-
tained on the different portions of the dataset, the
performance of the system are too low for consider-
ing it a reliable solution for being used in contexts
where short texts are taken into account.
</bodyText>
<subsectionHeader confidence="0.999109">
4.3 Task 11
</subsectionHeader>
<bodyText confidence="0.9999285625">
Results of the proposed system concerning Task 11
are shown in Table 4. In this task, due to the fine-
grained nature of the polarity predictions, the cosine
similarity and the mean square error with respect to
the gold standard have been computed. In the first
result-line, the values obtained on the four figura-
tive categories are reported, while in the second one,
the overall results. By observing the results, for the
“Sarcasm” and “Irony” topics the obtained results
are acceptable; while, for the “Metaphor” and for
the “Other” category, both the cosine similarity and
the MSE are significantly worse with respect to the
first two. These results, either with the ones obtained
on Task 10, confirm that the analysis of short texts
is the first issue to address for improving the general
quality of the system.
</bodyText>
<sectionHeader confidence="0.989392" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99998">
In this paper, we described the SHELLFBK system
presented at SemEval 2015 that participated in Se-
mEval 2015 Tasks 9, 10, and 11. Our system makes
use of IR techniques to classify sentences by polar-
ity, domain and the joint prediction of polarity and
domain, effectively providing domain specific senti-
ment analysis. The results demonstrated that, while
on well-formed sentences the system obtained good
performance, the method performs less well on short
texts like tweets. Therefore, future work will focus
on the improvement of the system in this direction.
In future work, we intend to explore the integration
of sentiment knowledge bases (Dragoni et al., 2014)
in order to move toward a more cognitive approach.
</bodyText>
<sectionHeader confidence="0.992249" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999923">
We would like to thank the anonymous reviewers for
their helpful suggestions and comments.
</bodyText>
<sectionHeader confidence="0.990291" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995002962962963">
Nicholas Asher, Farah Benamara, and Yvette Yannick
Mathieu. 2008. Distilling opinion in discourse: A
preliminary study. In COLING (Posters), pages 7–10.
Luciano Barbosa and Junlan Feng. 2010. Robust senti-
ment detection on twitter from biased and noisy data.
In COLING (Posters), pages 36–44.
Adam Bermingham and Alan F. Smeaton. 2010. Clas-
sifying sentiment in microblogs: is brevity an advan-
tage? In CIKM, pages 1833–1836.
John Blitzer, Mark Dredze, and Fernando Pereira. 2007.
Biographies, bollywood, boom-boxes and blenders:
Domain adaptation for sentiment classification. In
ACL, pages 187–205.
Danushka Bollegala, David J. Weir, and John A. Carroll.
2013. Cross-domain sentiment classification using a
sentiment sensitive thesaurus. IEEE Trans. Knowl.
Data Eng., 25(8):1719–1731.
Erik Cambria and Amir Hussain. 2012a. Sentic album:
Content-, concept-, and context-based online personal
photo management system. Cognitive Computation,
4(4):477–496.
Erik Cambria and Amir Hussain. 2012b. Sentic Com-
puting: Techniques, Tools, and Applications, volume 2
of SpringerBriefs in Cognitive Computation. Springer,
Dordrecht, Netherlands.
Kushal Dave, Steve Lawrence, and David M. Pennock.
2003. Mining the peanut gallery: opinion extraction
</reference>
<page confidence="0.990747">
507
</page>
<table confidence="0.99786475">
Task Live Journal 2014 SMS 2013 Twitter 2013 Twitter 2014 Twitter 2014 Sarcasm
Progress Test 0.3406 0.2614 0.3214 0.3220 0.3558
Task F-Measure - - - -
Overall 0.3245 - - - -
</table>
<tableCaption confidence="0.996689">
Table 3: Results obtained by the SHELLFBK on Task 10.
</tableCaption>
<table confidence="0.999688">
Sarcasm Mean Square Error Other Sarcasm Cosine Similarity Other
Irony Metaphor Irony Metaphor
Detailed Results 4.375 4.516 9.219 12.16 0.669 0.625 0.35 0.167
MSE Cosine - - - - - -
General Result 7.701 0.431 - - - - - -
</table>
<tableCaption confidence="0.999887">
Table 4: Results obtained by the SHELLFBK on Task 11.
</tableCaption>
<reference confidence="0.990995589041096">
and semantic classification of product reviews. In
WWW, pages 519–528.
Mauro Dragoni, Andrea G.B.Tettamanzi, and C´elia
da Costa Pereira. 2014. Propagating and aggregating
fuzzy polarities for concept-level sentiment analysis.
Cognitive Computation, pages 1–12.
Dayne Freitag and Andrew McCallum. 2000. In-
formation extraction with hmm structures learned by
stochastic optimization. In AAAI/IAAI, pages 584–
589.
Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso,
Ekaterina Shutova, Antonio Reyes, and John Barnden.
2015. SemEval-2015 task 11: Sentiment analysis of
figurative language in twitter. In Proceedings of the
9th International Workshop on Semantic Evaluation,
SemEval ’2015, Denver, Colorado, June.
Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervision.
CS224N Project Report, Standford University.
Vasileios Hatzivassiloglou and Janyce Wiebe. 2000. Ef-
fects of adjective orientation and gradability on sen-
tence subjectivity. In COLING, pages 299–305.
Sheng Huang, Zhendong Niu, and Chongyang Shi.
2014. Automatic construction of domain-specific sen-
timent lexicon based on constrained label propagation.
Knowl.-Based Syst., 56:191–200.
Niklas Jakob and Iryna Gurevych. 2010. Extracting
opinion targets in a single and cross-domain setting
with conditional random fields. In EMNLP, pages
1035–1045.
Wei Jin and Hung Hay Ho. 2009. A novel lexicalized
HMM-based learning framework for web opinion min-
ing. In Proceedings of the 26th Annual International
Conference on Machine Learning, ICML ’09, pages
465–472, New York, NY, USA. ACM.
Wei Jin, Hung Hay Ho, and Rohini K. Srihari. 2009.
Opinionminer: a novel machine learning system for
web opinion mining and extraction. In KDD, pages
1195–1204.
Soo-Min Kim and Eduard H. Hovy. 2007. Crystal: An-
alyzing predictive opinions on the web. In EMNLP-
CoNLL, pages 1056–1064.
Soo-Min Kim, Patrick Pantel, Timothy Chklovski, and
Marco Pennacchiotti. 2006. Automatically assessing
review helpfulness. In EMNLP, pages 423–430.
John D. Lafferty, Andrew McCallum, and Fernando C. N.
Pereira. 2001. Conditional random fields: Probabilis-
tic models for segmenting and labeling sequence data.
In ICML, pages 282–289.
Peter M. Lewinsohn and Christopher S. Amenson.
1978. Some relations between pleasant and unpleas-
ant events and depression. Journal of Abnormal Psy-
chology, 87:644–654.
Bing Liu and Lei Zhang. 2012. A survey of opinion
mining and sentiment analysis. In C. C. Aggarwal and
C. X. Zhai, editors, Mining Text Data, pages 415–463.
Springer.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opinions
on the web. In WWW, pages 342–351.
Douglas MacPhillamy, and Peter M. Lewinsohn. 1982.
The pleasant event schedule: Studies on reliability, va-
lidity, and scale intercorrelation. Journal of Counsel-
ing and Clinical Psychology, 50:363–380.
Prem Melville, Wojciech Gryc, and Richard D.
Lawrence. 2009. Sentiment analysis of blogs by com-
bining lexical knowledge with text classification. In
KDD, pages 1275–1284.
Georgios Paltoglou and Mike Thelwall. 2010. A study of
information retrieval weighting schemes for sentiment
analysis. In ACL, pages 1386–1395.
Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang
Yang, and Zheng Chen. 2010. Cross-domain senti-
</reference>
<page confidence="0.990101">
508
</page>
<reference confidence="0.995833102803738">
ment classification via spectral feature alignment. In
WWW, pages 751–760.
Bo Pang and Lillian Lee. 2004. A sentimental education:
Sentiment analysis using subjectivity summarization
based on minimum cuts. In ACL, pages 271–278.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in Infor-
mation Retrieval, 2(1-2):1–135.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? sentiment classification using ma-
chine learning techniques. In Proceedings of EMNLP
2002, pages 79–86, Philadelphia, July.
Natalia Ponomareva and Mike Thelwall. 2013. Semi-
supervised vs. cross-domain graphs for sentiment anal-
ysis. In RANLP, pages 571–578.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009a.
Expanding domain sentiment lexicon through double
propagation. In IJCAI, pages 1199–1204.
Likun Qiu, Weishi Zhang, Changjian Hu, and Kai Zhao.
2009b. Selc: a self-supervised model for sentiment
classification. In CIKM, pages 929–936.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2011. Opinion word expansion and target extraction
through double propagation. Computational Linguis-
tics, 37(1):9–27.
Ellen Riloff, Siddharth Patwardhan, and Janyce Wiebe.
2006. Feature subsumption for opinion analysis. In
EMNLP, pages 440–448.
Sara Rosenthal, Preslav Nakov, Svetlana Kiritchenko,
Saif M Mohammad, Alan Ritter, and Veselin Stoy-
anov. 2015. SemEval-2015 task 10: Sentiment analy-
sis in twitter. In Proceedings of the 9th International
Workshop on Semantic Evaluation, SemEval ’2015,
Denver, Colorado, June.
Irene Russo, Tommaso Caselli, and Carlo Strapparava.
2015. SemEval-2015 Task 9: CLIPEval Implicit Po-
larity of Events. In Proceedings of the 9th Inter-
national Workshop on Semantic Evaluation, SemEval
’2015, Denver, Colorado, June.
Swapna Somasundaran. 2010. Discourse-level relations
for Opinion Analysis. Ph.D. thesis, University of Pitts-
burgh.
Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu,
Xiaoxun Zhang, Bin Swen, and Zhong Su. 2008. Hid-
den sentiment association in chinese web opinion min-
ing. In WWW, pages 959–968.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly D. Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computational
Linguistics, 37(2):267–307.
Yen-Jen Tai and Hung-Yu Kao. 2013. Automatic
domain-specific sentiment lexicon generation with la-
bel propagation. In iiWAS, pages 53:53–53:62. ACM.
Songbo Tan, Yuefen Wang, and Xueqi Cheng. 2008.
Combining learn-based and lexicon-based techniques
for sentiment detection without using labeled exam-
ples. In SIGIR, pages 743–744.
Angela Charng-Rurng Tsai, Chi-En Wu, Richard Tzong-
Han Tsai, and Jane Yung jen Hsu. 2013. Building a
concept-level sentiment dictionary based on common-
sense knowledge. IEEE Int. Systems, 28(2):22–30.
C´elia da Costa Pereira, Mauro Dragoni, and Gabriella
Pasi 2012. Multidimensional relevance: Prioritized
aggregation in a personalized Information Retrieval
setting. Inf. Process. Manage., 48(2):340–357.
Peter D. Turney. 2002. Thumbs up or thumbs down?
semantic orientation applied to unsupervised classifi-
cation of reviews. In ACL, pages 417–424.
Cornelis Joost van Rijsbergen. 1979. Information Re-
trieval. Butterworth.
Hongling Wang and Guodong Zhou. 2010. Topic-driven
multi-document summarization. In IALP, pages 195–
198.
Qiu Feng Wang, Erik Cambria, Cheng Lin Liu, and Amir
Hussain. 2013. Common sense knowledge for hand-
written chinese recognition. Cognitive Computation,
5(2):234–242.
Janyce Wiebe, Theresa Wilson, Rebecca F. Bruce,
Matthew Bell, and Melanie Martin. 2004. Learn-
ing subjective language. Computational Linguistics,
30(3):277–308.
Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. 2004.
Just how mad are you? finding strong and weak opin-
ion clauses. In AAAI, pages 761–769.
Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. 2006.
Recognizing strong and weak opinion clauses. Com-
putational Intelligence, 22(2):73–99.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion mining.
In EMNLP, pages 1533–1541.
Rui Xia, Chengqing Zong, Xuelei Hu, and Erik Cambria.
2013. Feature ensemble plus sample selection: Do-
main adaptation for sentiment classification. IEEE Int.
Systems, 28(3):10–18.
Hui Yang, Jamie Callan, and Luo Si. 2006. Knowledge
transfer and opinion detection in the TREC 2006 blog
track. In TREC.
Yasuhisa Yoshida, Tsutomu Hirao, Tomoharu Iwata,
Masaaki Nagata, and Yuji Matsumoto. 2011. Trans-
fer learning for multiple-domain sentiment analysis—
identifying domain dependent/independent word po-
larity. In AAAI, pages 1286–1291.
Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards
answering opinion questions: Separating facts from
opinions and identifying the polarity of opinion sen-
tences. In Proceedings of EMNLP 2003, pages 129–
136, Stroudsburg, PA, USA.
</reference>
<page confidence="0.998494">
509
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.228621">
<title confidence="0.999356">An Information Retrieval-based System For Sentiment Analysis</title>
<author confidence="0.750691333333333">Mauro Fondazione Bruno Via Sommarive</author>
<affiliation confidence="0.478186">Povo,</affiliation>
<email confidence="0.993652">dragoni@fbk.eu</email>
<abstract confidence="0.998857434782609">paper describes the that participated in SemEval 2015 Tasks 9, 10, and 11. Our system takes a supervised approach that builds on techniques from information retrieval. The algorithm populates an inverted index with pseudo-documents that encode dependency parse relationships extracted from the sentences in the training set. Each record stored in the index is annotated with the polarity and domain of the sentence it represents. When the polarity or domain of a new sentence has to be computed, the new sentence is converted to a query that is used to retrieve the most similar sentences from the training set. The retrieved instances are scored for relevance to the query. The most relevant training instant is used to assign a polarity and domain label to the new sentence. While the results on well-formed sentences are encouraging, the performance obtained on short texts like tweets demonstrate that more work is needed in this area.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Farah Benamara</author>
<author>Yvette Yannick Mathieu</author>
</authors>
<title>Distilling opinion in discourse: A preliminary study.</title>
<date>2008</date>
<booktitle>In COLING (Posters),</booktitle>
<pages>7--10</pages>
<contexts>
<context position="6752" citStr="Asher et al., 2008" startWordPosition="1081" endWordPosition="1084">uthors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enhance accuracy has been proposed. Opinion words have been used also for unsupervised learning approaches like the ones presented in (Taboada et al., 2011) and (Turney, 2002). Another research direction concerns the exploitation of discourse-analysis techniques. (Somasundaran, 2010) and (Asher et al., 2008) discuss some discourse-based supervised and unsupervised approaches for opinion analysis; while in (Wang and Zhou, 2010), the authors present an approach to identify discourse relations. The approaches presented above are applied at the document-level, i.e., the polarity value is assigned to the entire document content. However, for improving the accuracy of the sentiment classification, a more fine-grained analysis of the text, i.e., the sentiment classification of the single sentences, has to be performed. In the case of sentence-level sentiment classification, two different sub-tasks have </context>
</contexts>
<marker>Asher, Benamara, Mathieu, 2008</marker>
<rawString>Nicholas Asher, Farah Benamara, and Yvette Yannick Mathieu. 2008. Distilling opinion in discourse: A preliminary study. In COLING (Posters), pages 7–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciano Barbosa</author>
<author>Junlan Feng</author>
</authors>
<title>Robust sentiment detection on twitter from biased and noisy data.</title>
<date>2010</date>
<booktitle>In COLING (Posters),</booktitle>
<pages>36--44</pages>
<contexts>
<context position="9575" citStr="Barbosa and Feng, 2010" startWordPosition="1533" endWordPosition="1536">clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened up new challenges due to the different ways people express their opinions, as described by (Barbosa and Feng, 2010) and (Bermingham and Smeaton, 2010), who mention “noisy data” as one of the biggest hurdles in analyzing social network texts. One of the first studies on sentiment analysis on micro-blogging websites has been discussed in (Go et al., 2009), where the authors present a distant supervision-based approach for sentiment classification. At the same time, the social dimension of the Web opens up the opportunity to combine computer science and social sciences to better recognize, interpret, and process opinions and sentiments expressed over it. Such multi-disciplinary approach has been called sentic</context>
</contexts>
<marker>Barbosa, Feng, 2010</marker>
<rawString>Luciano Barbosa and Junlan Feng. 2010. Robust sentiment detection on twitter from biased and noisy data. In COLING (Posters), pages 36–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Bermingham</author>
<author>Alan F Smeaton</author>
</authors>
<title>Classifying sentiment in microblogs: is brevity an advantage? In</title>
<date>2010</date>
<booktitle>CIKM,</booktitle>
<pages>1833--1836</pages>
<contexts>
<context position="9610" citStr="Bermingham and Smeaton, 2010" startWordPosition="1538" endWordPosition="1541"> In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened up new challenges due to the different ways people express their opinions, as described by (Barbosa and Feng, 2010) and (Bermingham and Smeaton, 2010), who mention “noisy data” as one of the biggest hurdles in analyzing social network texts. One of the first studies on sentiment analysis on micro-blogging websites has been discussed in (Go et al., 2009), where the authors present a distant supervision-based approach for sentiment classification. At the same time, the social dimension of the Web opens up the opportunity to combine computer science and social sciences to better recognize, interpret, and process opinions and sentiments expressed over it. Such multi-disciplinary approach has been called sentic computing (Cambria and Hussain, 20</context>
</contexts>
<marker>Bermingham, Smeaton, 2010</marker>
<rawString>Adam Bermingham and Alan F. Smeaton. 2010. Classifying sentiment in microblogs: is brevity an advantage? In CIKM, pages 1833–1836.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Mark Dredze</author>
<author>Fernando Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In</title>
<date>2007</date>
<booktitle>ACL,</booktitle>
<pages>187--205</pages>
<contexts>
<context position="3162" citStr="Blitzer et al., 2007" startWordPosition="516" endWordPosition="519">negative, or neutral sentiment is assigned to the entire document content; or it may be sentence-based where individual sentences are analyzed separately and classified according to the different polarity values. In the latter case, it is often desirable to find with a high precision the entity attributes towards which the detected sentiment is directed. In the classic sentiment analysis problem, the polarity of each term within the document is computed independently of the domain which the document’s domain. However, conditioning term polarity by domain has been found to improve performance (Blitzer et al., 2007). We illustrate the intuition behind domain specific term polarity. Let us 502 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 502–509, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics consider the following example concerning the adjective “small”: 1. The sideboard is small and it is not able to contain a lot of stuff. 2. The small dimensions of this decoder allow to move it easily. In the first sentence, we considered the Furnishings domain and, within it, the polarity of the adjective “small” is, for sure, “negativ</context>
<context position="11438" citStr="Blitzer et al., 2007" startWordPosition="1823" endWordPosition="1826">monstrated through the example presented in Section 1. The reason is that words and even language constructs used in different domains for expressing opinions can be quite different. To make matters worse, the same word in one domain may have positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind </context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In ACL, pages 187–205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danushka Bollegala</author>
<author>David J Weir</author>
<author>John A Carroll</author>
</authors>
<title>Cross-domain sentiment classification using a sentiment sensitive thesaurus.</title>
<date>2013</date>
<journal>IEEE Trans. Knowl. Data Eng.,</journal>
<volume>25</volume>
<issue>8</issue>
<contexts>
<context position="11480" citStr="Bollegala et al., 2013" startWordPosition="1831" endWordPosition="1834"> in Section 1. The reason is that words and even language constructs used in different domains for expressing opinions can be quite different. To make matters worse, the same word in one domain may have positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind the usage of such an approach is that by u</context>
</contexts>
<marker>Bollegala, Weir, Carroll, 2013</marker>
<rawString>Danushka Bollegala, David J. Weir, and John A. Carroll. 2013. Cross-domain sentiment classification using a sentiment sensitive thesaurus. IEEE Trans. Knowl. Data Eng., 25(8):1719–1731.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Cambria</author>
<author>Amir Hussain</author>
</authors>
<title>Sentic album: Content-, concept-, and context-based online personal photo management system.</title>
<date>2012</date>
<journal>Cognitive Computation,</journal>
<volume>4</volume>
<issue>4</issue>
<contexts>
<context position="10212" citStr="Cambria and Hussain, 2012" startWordPosition="1632" endWordPosition="1636">gham and Smeaton, 2010), who mention “noisy data” as one of the biggest hurdles in analyzing social network texts. One of the first studies on sentiment analysis on micro-blogging websites has been discussed in (Go et al., 2009), where the authors present a distant supervision-based approach for sentiment classification. At the same time, the social dimension of the Web opens up the opportunity to combine computer science and social sciences to better recognize, interpret, and process opinions and sentiments expressed over it. Such multi-disciplinary approach has been called sentic computing (Cambria and Hussain, 2012b). Application domains where sentic computing has already shown its potential are the cognitive-inspired classification of images (Cambria and Hussain, 2012a), of texts in natural language, and of handwritten text (Wang et al., 2013). Finally, an interesting recent research direction is domain adaptation, as it has been shown that sentiment classification is highly sensitive to the domain from which the training data is extracted. A classifier trained using opinionated documents from one domain often performs poorly when it is applied or tested on opinionated documents from another domain, as</context>
</contexts>
<marker>Cambria, Hussain, 2012</marker>
<rawString>Erik Cambria and Amir Hussain. 2012a. Sentic album: Content-, concept-, and context-based online personal photo management system. Cognitive Computation, 4(4):477–496.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Erik Cambria</author>
<author>Amir Hussain</author>
</authors>
<booktitle>2012b. Sentic Computing: Techniques, Tools, and Applications,</booktitle>
<volume>2</volume>
<publisher>Springer,</publisher>
<location>Dordrecht, Netherlands.</location>
<marker>Cambria, Hussain, </marker>
<rawString>Erik Cambria and Amir Hussain. 2012b. Sentic Computing: Techniques, Tools, and Applications, volume 2 of SpringerBriefs in Cognitive Computation. Springer, Dordrecht, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kushal Dave</author>
<author>Steve Lawrence</author>
<author>David M Pennock</author>
</authors>
<title>Mining the peanut gallery: opinion extraction and semantic classification of product reviews.</title>
<date>2003</date>
<booktitle>In WWW,</booktitle>
<pages>519--528</pages>
<contexts>
<context position="5734" citStr="Dave et al., 2003" startWordPosition="926" endWordPosition="929">l., 2002) and (Pang and Lee, 2004), the authors compared the performance of Naive-Bayes, Maximum Entropy, and Support Vector Machines in sentiment analysis on different features like considering only unigrams, bigrams, combination of both, incorporating parts of speech and position information or by taking only adjectives. Moreover, beside the use of standard machine learning method, researchers have also proposed several custom techniques specifically for sentiment classification, like the use of adapted score function based on the evaluation of positive or negative words in product reviews (Dave et al., 2003), as well as by defining weighting schemata for enhancing classification accuracy (Paltoglou and Thelwall, 2010). An obstacle to research in this direction is the need of labeled training data, whose preparation is a time-consuming activity. Therefore, in order to reduce the labeling effort, opinion words have been used for training procedures. In (Tan et al., 2008) and (Qiu et al., 2009b), the authors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as prese</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Kushal Dave, Steve Lawrence, and David M. Pennock. 2003. Mining the peanut gallery: opinion extraction and semantic classification of product reviews. In WWW, pages 519–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Dragoni</author>
<author>Andrea G B Tettamanzi</author>
<author>C´elia da Costa Pereira</author>
</authors>
<title>Propagating and aggregating fuzzy polarities for concept-level sentiment analysis. Cognitive Computation,</title>
<date>2014</date>
<pages>1--12</pages>
<marker>Dragoni, Tettamanzi, Pereira, 2014</marker>
<rawString>Mauro Dragoni, Andrea G.B.Tettamanzi, and C´elia da Costa Pereira. 2014. Propagating and aggregating fuzzy polarities for concept-level sentiment analysis. Cognitive Computation, pages 1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
<author>Andrew McCallum</author>
</authors>
<title>Information extraction with hmm structures learned by stochastic optimization.</title>
<date>2000</date>
<booktitle>In AAAI/IAAI,</booktitle>
<pages>584--589</pages>
<contexts>
<context position="8823" citStr="Freitag and McCallum, 2000" startWordPosition="1406" endWordPosition="1410"> product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such</context>
</contexts>
<marker>Freitag, McCallum, 2000</marker>
<rawString>Dayne Freitag and Andrew McCallum. 2000. Information extraction with hmm structures learned by stochastic optimization. In AAAI/IAAI, pages 584– 589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aniruddha Ghosh</author>
<author>Guofu Li</author>
<author>Tony Veale</author>
<author>Paolo Rosso</author>
<author>Ekaterina Shutova</author>
<author>Antonio Reyes</author>
<author>John Barnden</author>
</authors>
<title>SemEval-2015 task 11: Sentiment analysis of figurative language in twitter.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="19071" citStr="Ghosh et al., 2015" startWordPosition="3070" endWordPosition="3073">anized around two subtasks: (A) identification of the polarity value associated to an event instance, and (B) identification of both the event instantiations and the associated polarity values. The SHELLFBK system has been tested on both tasks. • Task 10 (Rosenthal et al., 2015): this task aims to identify sentiment polarities in short text messages contained in the Twitter microblog. This task contains five subtasks: (A) expression-level, (B) message-level, (C) topicrelated, (D) trend, and (E) a task on prior polarity of terms. The SHELLFBK has been tested only on the subtask (B). • Task 11 (Ghosh et al., 2015): this task consists in the classification of tweets containing irony and metaphors. Given a set of tweets that are rich in metaphor and irony, the goal is to determine whether the user has expressed a positive, negative, or neutral sentiment in each, and the degree to which this sentiment has been communicated. With respect to the other tasks, here the polarity is expressed through a fine-grained scale in the interval [-5, 5]. In the following subsections, we will briefly report the performance obtained on each task. 4.1 Task 9 Table 2 reports the results obtained in Task 9. This task consist</context>
</contexts>
<marker>Ghosh, Li, Veale, Rosso, Shutova, Reyes, Barnden, 2015</marker>
<rawString>Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso, Ekaterina Shutova, Antonio Reyes, and John Barnden. 2015. SemEval-2015 task 11: Sentiment analysis of figurative language in twitter. In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015, Denver, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alec Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision.</title>
<date>2009</date>
<tech>CS224N Project Report,</tech>
<institution>Standford University.</institution>
<contexts>
<context position="9815" citStr="Go et al., 2009" startWordPosition="1573" endWordPosition="1576">ld be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened up new challenges due to the different ways people express their opinions, as described by (Barbosa and Feng, 2010) and (Bermingham and Smeaton, 2010), who mention “noisy data” as one of the biggest hurdles in analyzing social network texts. One of the first studies on sentiment analysis on micro-blogging websites has been discussed in (Go et al., 2009), where the authors present a distant supervision-based approach for sentiment classification. At the same time, the social dimension of the Web opens up the opportunity to combine computer science and social sciences to better recognize, interpret, and process opinions and sentiments expressed over it. Such multi-disciplinary approach has been called sentic computing (Cambria and Hussain, 2012b). Application domains where sentic computing has already shown its potential are the cognitive-inspired classification of images (Cambria and Hussain, 2012a), of texts in natural language, and of handw</context>
</contexts>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter sentiment classification using distant supervision. CS224N Project Report, Standford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Janyce Wiebe</author>
</authors>
<title>Effects of adjective orientation and gradability on sentence subjectivity.</title>
<date>2000</date>
<booktitle>In COLING,</booktitle>
<pages>299--305</pages>
<contexts>
<context position="7995" citStr="Hatzivassiloglou and Wiebe, 2000" startWordPosition="1275" endWordPosition="1278">essed: (i) to determine if the sentence is subjective or objective, and (ii) in the case that the sentence is subjective, to determine if the opinion expressed in the sentence is positive, negative, or neutral. The task of classifying a sentence as subjective or objective, called “subjectivity classification”, has been widely discussed in the literature (Riloff et al., 2006; Wiebe et al., 2004; Wilson et al., 2004; Wilson et al., 2006; Yu and Hatzivassiloglou, 2003). Once subjective sentences are identified, the same 503 methods as for sentiment classification may be applied. For example, in (Hatzivassiloglou and Wiebe, 2000) the authors consider gradable adjectives for sentiment spotting; while in (Kim and Hovy, 2007) and (Kim et al., 2006) the authors built models to identify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which i</context>
</contexts>
<marker>Hatzivassiloglou, Wiebe, 2000</marker>
<rawString>Vasileios Hatzivassiloglou and Janyce Wiebe. 2000. Effects of adjective orientation and gradability on sentence subjectivity. In COLING, pages 299–305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheng Huang</author>
<author>Zhendong Niu</author>
<author>Chongyang Shi</author>
</authors>
<title>Automatic construction of domain-specific sentiment lexicon based on constrained label propagation. Knowl.-Based Syst.,</title>
<date>2014</date>
<pages>56--191</pages>
<contexts>
<context position="11679" citStr="Huang et al., 2014" startWordPosition="1866" endWordPosition="1869"> positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind the usage of such an approach is that by using indexes, the computation of the Retrieval Status Value (RSV) (da Costa Pereira et al., 2012) of a term or expression, automatically takes into account which are the elements that are more signif</context>
</contexts>
<marker>Huang, Niu, Shi, 2014</marker>
<rawString>Sheng Huang, Zhendong Niu, and Chongyang Shi. 2014. Automatic construction of domain-specific sentiment lexicon based on constrained label propagation. Knowl.-Based Syst., 56:191–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting opinion targets in a single and cross-domain setting with conditional random fields.</title>
<date>2010</date>
<booktitle>In EMNLP,</booktitle>
<pages>1035--1045</pages>
<contexts>
<context position="8743" citStr="Jakob and Gurevych, 2010" startWordPosition="1393" endWordPosition="1396">uthors built models to identify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing the</context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Niklas Jakob and Iryna Gurevych. 2010. Extracting opinion targets in a single and cross-domain setting with conditional random fields. In EMNLP, pages 1035–1045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
</authors>
<title>A novel lexicalized HMM-based learning framework for web opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th Annual International Conference on Machine Learning, ICML ’09,</booktitle>
<pages>465--472</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="8841" citStr="Jin and Ho, 2009" startWordPosition="1411" endWordPosition="1414">fect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network </context>
</contexts>
<marker>Jin, Ho, 2009</marker>
<rawString>Wei Jin and Hung Hay Ho. 2009. A novel lexicalized HMM-based learning framework for web opinion mining. In Proceedings of the 26th Annual International Conference on Machine Learning, ICML ’09, pages 465–472, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
<author>Rohini K Srihari</author>
</authors>
<title>Opinionminer: a novel machine learning system for web opinion mining and extraction.</title>
<date>2009</date>
<booktitle>In KDD,</booktitle>
<pages>1195--1204</pages>
<contexts>
<context position="8860" citStr="Jin et al., 2009" startWordPosition="1415" endWordPosition="1418">ng sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened </context>
</contexts>
<marker>Jin, Ho, Srihari, 2009</marker>
<rawString>Wei Jin, Hung Hay Ho, and Rohini K. Srihari. 2009. Opinionminer: a novel machine learning system for web opinion mining and extraction. In KDD, pages 1195–1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard H Hovy</author>
</authors>
<title>Crystal: Analyzing predictive opinions on the web. In EMNLPCoNLL,</title>
<date>2007</date>
<pages>1056--1064</pages>
<contexts>
<context position="8090" citStr="Kim and Hovy, 2007" startWordPosition="1289" endWordPosition="1292"> subjective, to determine if the opinion expressed in the sentence is positive, negative, or neutral. The task of classifying a sentence as subjective or objective, called “subjectivity classification”, has been widely discussed in the literature (Riloff et al., 2006; Wiebe et al., 2004; Wilson et al., 2004; Wilson et al., 2006; Yu and Hatzivassiloglou, 2003). Once subjective sentences are identified, the same 503 methods as for sentiment classification may be applied. For example, in (Hatzivassiloglou and Wiebe, 2000) the authors consider gradable adjectives for sentiment spotting; while in (Kim and Hovy, 2007) and (Kim et al., 2006) the authors built models to identify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: cond</context>
</contexts>
<marker>Kim, Hovy, 2007</marker>
<rawString>Soo-Min Kim and Eduard H. Hovy. 2007. Crystal: Analyzing predictive opinions on the web. In EMNLPCoNLL, pages 1056–1064.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Patrick Pantel</author>
<author>Timothy Chklovski</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Automatically assessing review helpfulness.</title>
<date>2006</date>
<booktitle>In EMNLP,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="8113" citStr="Kim et al., 2006" startWordPosition="1294" endWordPosition="1297"> if the opinion expressed in the sentence is positive, negative, or neutral. The task of classifying a sentence as subjective or objective, called “subjectivity classification”, has been widely discussed in the literature (Riloff et al., 2006; Wiebe et al., 2004; Wilson et al., 2004; Wilson et al., 2006; Yu and Hatzivassiloglou, 2003). Once subjective sentences are identified, the same 503 methods as for sentiment classification may be applied. For example, in (Hatzivassiloglou and Wiebe, 2000) the authors consider gradable adjectives for sentiment spotting; while in (Kim and Hovy, 2007) and (Kim et al., 2006) the authors built models to identify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (</context>
</contexts>
<marker>Kim, Pantel, Chklovski, Pennacchiotti, 2006</marker>
<rawString>Soo-Min Kim, Patrick Pantel, Timothy Chklovski, and Marco Pennacchiotti. 2006. Automatically assessing review helpfulness. In EMNLP, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In</title>
<date>2001</date>
<booktitle>ICML,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="8767" citStr="Lafferty et al., 2001" startWordPosition="1397" endWordPosition="1400">ntify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning thei</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter M Lewinsohn</author>
<author>Christopher S Amenson</author>
</authors>
<title>Some relations between pleasant and unpleasant events and depression.</title>
<date>1978</date>
<journal>Journal of Abnormal Psychology,</journal>
<pages>87--644</pages>
<contexts>
<context position="18283" citStr="Lewinsohn and Amenson, 1978" startWordPosition="2940" endWordPosition="2944">ver the three indexes: Polarity(S) = argmaxP∈POS,NEU,NEG RSV(S, P) In case of domain assignment, given a set D of k domains, the domain is computed by: Domain(S) = argmax Z∈1...k RSV(S, DZ) (5) 4 Results The SHELLFBK system participated in three SemEval 2015 tasks: 9, 10, and 11. All three tasks were about the sentiment analysis topic with the following differences: • Task 9 (Russo et al., 2015): this task is based on a dataset of events annotated as instantiations of pleasant and unpleasant events previously collected in psychological researches as the ones on which human judgments converge (Lewinsohn and Amenson, 1978),(MacPhillamy. and Lewinsohn, 1982). Task 9 concerns classification of the events that are pleasant or unpleasant for a person writing in first person. This task was organized around two subtasks: (A) identification of the polarity value associated to an event instance, and (B) identification of both the event instantiations and the associated polarity values. The SHELLFBK system has been tested on both tasks. • Task 10 (Rosenthal et al., 2015): this task aims to identify sentiment polarities in short text messages contained in the Twitter microblog. This task contains five subtasks: (A) expre</context>
</contexts>
<marker>Lewinsohn, Amenson, 1978</marker>
<rawString>Peter M. Lewinsohn and Christopher S. Amenson. 1978. Some relations between pleasant and unpleasant events and depression. Journal of Abnormal Psychology, 87:644–654.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Lei Zhang</author>
</authors>
<title>A survey of opinion mining and sentiment analysis. In</title>
<date>2012</date>
<booktitle>Mining Text Data,</booktitle>
<pages>415--463</pages>
<editor>C. C. Aggarwal and C. X. Zhai, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="1905" citStr="Liu and Zhang, 2012" startWordPosition="299" endWordPosition="302"> express on a given subject (Pang et al., 2002). Generally speaking, sentiment analysis aims at determining the attitude of a speaker or a writer with respect to a topic or the overall tonality of a document. This task has created a considerable interest due to its wide applications. In recent years, the exponential increase of the Web for exchanging public opinions about events, facts, products, etc., has led to an extensive usage of sentiment analysis approaches, especially for marketing purposes. By formalizing the sentiment analysis problem, a “sentiment” or “opinion” has been defined by (Liu and Zhang, 2012) as a quintuple: (oj, fjk, soijkl, hi, tl), (1) where oj is a target object, fjk is a feature of the object oj, soijkl is the sentiment value of the opinion of the opinion holder hi on feature fjk of object oj at time tl. The value of soijkl can be positive (by denoting a state of happiness, bliss, or satisfaction), negative (by denoting a state of sorrow, dejection, or disappointment), or neutral (it is not possible to denote any particular sentiment), or a more granular rating. The term hi encodes the opinion holder, and tl is the time when the opinion is expressed. Such an analysis, may be </context>
<context position="4848" citStr="Liu and Zhang, 2012" startWordPosition="792" endWordPosition="795">ntences and by taking into account both their polarity and the domain. The rest of the work is structured as follows. Section 2 presents a survey on works about sentiment analysis. Section 3 provides a description of the SHELLFBK system by described how information are stored during the training phase and exploited during the test one. Section 4 reports the system evaluation performed on the Tasks 9, 10, and 11 proposed at SemEval 2015 and, finally, Section 5 concludes the paper. 2 Related Work The topic of sentiment analysis has been studied extensively in the literature (Pang and Lee, 2008; Liu and Zhang, 2012), where several techniques have been proposed and validated. Machine learning techniques are the most common approaches used for addressing this problem, given that any existing supervised methods can be applied to sentiment classification. For instance, in (Pang et al., 2002) and (Pang and Lee, 2004), the authors compared the performance of Naive-Bayes, Maximum Entropy, and Support Vector Machines in sentiment analysis on different features like considering only unigrams, bigrams, combination of both, incorporating parts of speech and position information or by taking only adjectives. Moreove</context>
</contexts>
<marker>Liu, Zhang, 2012</marker>
<rawString>Bing Liu and Lei Zhang. 2012. A survey of opinion mining and sentiment analysis. In C. C. Aggarwal and C. X. Zhai, editors, Mining Text Data, pages 415–463. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the web. In</title>
<date>2005</date>
<booktitle>WWW,</booktitle>
<pages>342--351</pages>
<contexts>
<context position="8903" citStr="Liu et al., 2005" startWordPosition="1423" endWordPosition="1426">ng activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened up new challenges due to the different ways</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the web. In WWW, pages 342–351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas MacPhillamy</author>
<author>Peter M Lewinsohn</author>
</authors>
<title>The pleasant event schedule: Studies on reliability, validity, and scale intercorrelation.</title>
<date>1982</date>
<journal>Journal of Counseling and Clinical Psychology,</journal>
<pages>50--363</pages>
<marker>MacPhillamy, Lewinsohn, 1982</marker>
<rawString>Douglas MacPhillamy, and Peter M. Lewinsohn. 1982. The pleasant event schedule: Studies on reliability, validity, and scale intercorrelation. Journal of Counseling and Clinical Psychology, 50:363–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prem Melville</author>
<author>Wojciech Gryc</author>
<author>Richard D Lawrence</author>
</authors>
<title>Sentiment analysis of blogs by combining lexical knowledge with text classification.</title>
<date>2009</date>
<booktitle>In KDD,</booktitle>
<pages>1275--1284</pages>
<contexts>
<context position="6365" citStr="Melville et al., 2009" startWordPosition="1025" endWordPosition="1028"> as by defining weighting schemata for enhancing classification accuracy (Paltoglou and Thelwall, 2010). An obstacle to research in this direction is the need of labeled training data, whose preparation is a time-consuming activity. Therefore, in order to reduce the labeling effort, opinion words have been used for training procedures. In (Tan et al., 2008) and (Qiu et al., 2009b), the authors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enhance accuracy has been proposed. Opinion words have been used also for unsupervised learning approaches like the ones presented in (Taboada et al., 2011) and (Turney, 2002). Another research direction concerns the exploitation of discourse-analysis techniques. (Somasundaran, 2010) and (Asher et al., 2008) discuss some discourse-based supervised and unsupervised approaches for opinion analysis; while in (Wang and Zhou, 2010), the authors present an approach to identify discourse relations. The approaches presented </context>
</contexts>
<marker>Melville, Gryc, Lawrence, 2009</marker>
<rawString>Prem Melville, Wojciech Gryc, and Richard D. Lawrence. 2009. Sentiment analysis of blogs by combining lexical knowledge with text classification. In KDD, pages 1275–1284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgios Paltoglou</author>
<author>Mike Thelwall</author>
</authors>
<title>A study of information retrieval weighting schemes for sentiment analysis.</title>
<date>2010</date>
<booktitle>In ACL,</booktitle>
<pages>1386--1395</pages>
<contexts>
<context position="5846" citStr="Paltoglou and Thelwall, 2010" startWordPosition="942" endWordPosition="945">opy, and Support Vector Machines in sentiment analysis on different features like considering only unigrams, bigrams, combination of both, incorporating parts of speech and position information or by taking only adjectives. Moreover, beside the use of standard machine learning method, researchers have also proposed several custom techniques specifically for sentiment classification, like the use of adapted score function based on the evaluation of positive or negative words in product reviews (Dave et al., 2003), as well as by defining weighting schemata for enhancing classification accuracy (Paltoglou and Thelwall, 2010). An obstacle to research in this direction is the need of labeled training data, whose preparation is a time-consuming activity. Therefore, in order to reduce the labeling effort, opinion words have been used for training procedures. In (Tan et al., 2008) and (Qiu et al., 2009b), the authors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enh</context>
</contexts>
<marker>Paltoglou, Thelwall, 2010</marker>
<rawString>Georgios Paltoglou and Mike Thelwall. 2010. A study of information retrieval weighting schemes for sentiment analysis. In ACL, pages 1386–1395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sinno Jialin Pan</author>
<author>Xiaochuan Ni</author>
<author>Jian-Tao Sun</author>
<author>Qiang Yang</author>
<author>Zheng Chen</author>
</authors>
<title>Cross-domain sentiment classification via spectral feature alignment.</title>
<date>2010</date>
<booktitle>In WWW,</booktitle>
<pages>751--760</pages>
<contexts>
<context position="11456" citStr="Pan et al., 2010" startWordPosition="1827" endWordPosition="1830"> example presented in Section 1. The reason is that words and even language constructs used in different domains for expressing opinions can be quite different. To make matters worse, the same word in one domain may have positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind the usage of such </context>
</contexts>
<marker>Pan, Ni, Sun, Yang, Chen, 2010</marker>
<rawString>Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang Yang, and Zheng Chen. 2010. Cross-domain sentiment classification via spectral feature alignment. In WWW, pages 751–760.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In ACL,</booktitle>
<pages>271--278</pages>
<contexts>
<context position="5150" citStr="Pang and Lee, 2004" startWordPosition="838" endWordPosition="841">and exploited during the test one. Section 4 reports the system evaluation performed on the Tasks 9, 10, and 11 proposed at SemEval 2015 and, finally, Section 5 concludes the paper. 2 Related Work The topic of sentiment analysis has been studied extensively in the literature (Pang and Lee, 2008; Liu and Zhang, 2012), where several techniques have been proposed and validated. Machine learning techniques are the most common approaches used for addressing this problem, given that any existing supervised methods can be applied to sentiment classification. For instance, in (Pang et al., 2002) and (Pang and Lee, 2004), the authors compared the performance of Naive-Bayes, Maximum Entropy, and Support Vector Machines in sentiment analysis on different features like considering only unigrams, bigrams, combination of both, incorporating parts of speech and position information or by taking only adjectives. Moreover, beside the use of standard machine learning method, researchers have also proposed several custom techniques specifically for sentiment classification, like the use of adapted score function based on the evaluation of positive or negative words in product reviews (Dave et al., 2003), as well as by </context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In ACL, pages 271–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="4826" citStr="Pang and Lee, 2008" startWordPosition="788" endWordPosition="791">stic structure of sentences and by taking into account both their polarity and the domain. The rest of the work is structured as follows. Section 2 presents a survey on works about sentiment analysis. Section 3 provides a description of the SHELLFBK system by described how information are stored during the training phase and exploited during the test one. Section 4 reports the system evaluation performed on the Tasks 9, 10, and 11 proposed at SemEval 2015 and, finally, Section 5 concludes the paper. 2 Related Work The topic of sentiment analysis has been studied extensively in the literature (Pang and Lee, 2008; Liu and Zhang, 2012), where several techniques have been proposed and validated. Machine learning techniques are the most common approaches used for addressing this problem, given that any existing supervised methods can be applied to sentiment classification. For instance, in (Pang et al., 2002) and (Pang and Lee, 2004), the authors compared the performance of Naive-Bayes, Maximum Entropy, and Support Vector Machines in sentiment analysis on different features like considering only unigrams, bigrams, combination of both, incorporating parts of speech and position information or by taking on</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP 2002,</booktitle>
<pages>79--86</pages>
<location>Philadelphia,</location>
<contexts>
<context position="1332" citStr="Pang et al., 2002" startWordPosition="208" endWordPosition="211">converted to a query that is used to retrieve the most similar sentences from the training set. The retrieved instances are scored for relevance to the query. The most relevant training instant is used to assign a polarity and domain label to the new sentence. While the results on well-formed sentences are encouraging, the performance obtained on short texts like tweets demonstrate that more work is needed in this area. 1 Introduction Sentiment analysis is a natural language processing task whose aim is to classify documents according to the opinion (polarity) they express on a given subject (Pang et al., 2002). Generally speaking, sentiment analysis aims at determining the attitude of a speaker or a writer with respect to a topic or the overall tonality of a document. This task has created a considerable interest due to its wide applications. In recent years, the exponential increase of the Web for exchanging public opinions about events, facts, products, etc., has led to an extensive usage of sentiment analysis approaches, especially for marketing purposes. By formalizing the sentiment analysis problem, a “sentiment” or “opinion” has been defined by (Liu and Zhang, 2012) as a quintuple: (oj, fjk, </context>
<context position="5125" citStr="Pang et al., 2002" startWordPosition="833" endWordPosition="836">ring the training phase and exploited during the test one. Section 4 reports the system evaluation performed on the Tasks 9, 10, and 11 proposed at SemEval 2015 and, finally, Section 5 concludes the paper. 2 Related Work The topic of sentiment analysis has been studied extensively in the literature (Pang and Lee, 2008; Liu and Zhang, 2012), where several techniques have been proposed and validated. Machine learning techniques are the most common approaches used for addressing this problem, given that any existing supervised methods can be applied to sentiment classification. For instance, in (Pang et al., 2002) and (Pang and Lee, 2004), the authors compared the performance of Naive-Bayes, Maximum Entropy, and Support Vector Machines in sentiment analysis on different features like considering only unigrams, bigrams, combination of both, incorporating parts of speech and position information or by taking only adjectives. Moreover, beside the use of standard machine learning method, researchers have also proposed several custom techniques specifically for sentiment classification, like the use of adapted score function based on the evaluation of positive or negative words in product reviews (Dave et a</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques. In Proceedings of EMNLP 2002, pages 79–86, Philadelphia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalia Ponomareva</author>
<author>Mike Thelwall</author>
</authors>
<title>Semisupervised vs. cross-domain graphs for sentiment analysis.</title>
<date>2013</date>
<booktitle>In RANLP,</booktitle>
<pages>571--578</pages>
<contexts>
<context position="11620" citStr="Ponomareva and Thelwall, 2013" startWordPosition="1854" endWordPosition="1857">ifferent. To make matters worse, the same word in one domain may have positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind the usage of such an approach is that by using indexes, the computation of the Retrieval Status Value (RSV) (da Costa Pereira et al., 2012) of a term or expression, automatically tak</context>
</contexts>
<marker>Ponomareva, Thelwall, 2013</marker>
<rawString>Natalia Ponomareva and Mike Thelwall. 2013. Semisupervised vs. cross-domain graphs for sentiment analysis. In RANLP, pages 571–578.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Expanding domain sentiment lexicon through double propagation.</title>
<date>2009</date>
<booktitle>In IJCAI,</booktitle>
<pages>1199--1204</pages>
<contexts>
<context position="6124" citStr="Qiu et al., 2009" startWordPosition="989" endWordPosition="992">rchers have also proposed several custom techniques specifically for sentiment classification, like the use of adapted score function based on the evaluation of positive or negative words in product reviews (Dave et al., 2003), as well as by defining weighting schemata for enhancing classification accuracy (Paltoglou and Thelwall, 2010). An obstacle to research in this direction is the need of labeled training data, whose preparation is a time-consuming activity. Therefore, in order to reduce the labeling effort, opinion words have been used for training procedures. In (Tan et al., 2008) and (Qiu et al., 2009b), the authors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enhance accuracy has been proposed. Opinion words have been used also for unsupervised learning approaches like the ones presented in (Taboada et al., 2011) and (Turney, 2002). Another research direction concerns the exploitation of discourse-analysis techniques. (Somasundaran, 20</context>
<context position="9002" citStr="Qiu et al., 2009" startWordPosition="1441" endWordPosition="1444">rning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened up new challenges due to the different ways people express their opinions, as described by (Barbosa and Feng, 2010) and (Bermingham and Smeato</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009a. Expanding domain sentiment lexicon through double propagation. In IJCAI, pages 1199–1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Likun Qiu</author>
<author>Weishi Zhang</author>
<author>Changjian Hu</author>
<author>Kai Zhao</author>
</authors>
<title>Selc: a self-supervised model for sentiment classification. In</title>
<date>2009</date>
<booktitle>CIKM,</booktitle>
<pages>929--936</pages>
<contexts>
<context position="6124" citStr="Qiu et al., 2009" startWordPosition="989" endWordPosition="992">rchers have also proposed several custom techniques specifically for sentiment classification, like the use of adapted score function based on the evaluation of positive or negative words in product reviews (Dave et al., 2003), as well as by defining weighting schemata for enhancing classification accuracy (Paltoglou and Thelwall, 2010). An obstacle to research in this direction is the need of labeled training data, whose preparation is a time-consuming activity. Therefore, in order to reduce the labeling effort, opinion words have been used for training procedures. In (Tan et al., 2008) and (Qiu et al., 2009b), the authors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enhance accuracy has been proposed. Opinion words have been used also for unsupervised learning approaches like the ones presented in (Taboada et al., 2011) and (Turney, 2002). Another research direction concerns the exploitation of discourse-analysis techniques. (Somasundaran, 20</context>
<context position="9002" citStr="Qiu et al., 2009" startWordPosition="1441" endWordPosition="1444">rning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened up new challenges due to the different ways people express their opinions, as described by (Barbosa and Feng, 2010) and (Bermingham and Smeato</context>
</contexts>
<marker>Qiu, Zhang, Hu, Zhao, 2009</marker>
<rawString>Likun Qiu, Weishi Zhang, Changjian Hu, and Kai Zhao. 2009b. Selc: a self-supervised model for sentiment classification. In CIKM, pages 929–936.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Opinion word expansion and target extraction through double propagation.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="9022" citStr="Qiu et al., 2011" startWordPosition="1445" endWordPosition="1448">uct expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened up new challenges due to the different ways people express their opinions, as described by (Barbosa and Feng, 2010) and (Bermingham and Smeaton, 2010), who mentio</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2011</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through double propagation. Computational Linguistics, 37(1):9–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Siddharth Patwardhan</author>
<author>Janyce Wiebe</author>
</authors>
<title>Feature subsumption for opinion analysis.</title>
<date>2006</date>
<booktitle>In EMNLP,</booktitle>
<pages>440--448</pages>
<contexts>
<context position="7738" citStr="Riloff et al., 2006" startWordPosition="1235" endWordPosition="1238">entiment classification, a more fine-grained analysis of the text, i.e., the sentiment classification of the single sentences, has to be performed. In the case of sentence-level sentiment classification, two different sub-tasks have to be addressed: (i) to determine if the sentence is subjective or objective, and (ii) in the case that the sentence is subjective, to determine if the opinion expressed in the sentence is positive, negative, or neutral. The task of classifying a sentence as subjective or objective, called “subjectivity classification”, has been widely discussed in the literature (Riloff et al., 2006; Wiebe et al., 2004; Wilson et al., 2004; Wilson et al., 2006; Yu and Hatzivassiloglou, 2003). Once subjective sentences are identified, the same 503 methods as for sentiment classification may be applied. For example, in (Hatzivassiloglou and Wiebe, 2000) the authors consider gradable adjectives for sentiment spotting; while in (Kim and Hovy, 2007) and (Kim et al., 2006) the authors built models to identify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the a</context>
</contexts>
<marker>Riloff, Patwardhan, Wiebe, 2006</marker>
<rawString>Ellen Riloff, Siddharth Patwardhan, and Janyce Wiebe. 2006. Feature subsumption for opinion analysis. In EMNLP, pages 440–448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Rosenthal</author>
<author>Preslav Nakov</author>
<author>Svetlana Kiritchenko</author>
<author>Saif M Mohammad</author>
<author>Alan Ritter</author>
<author>Veselin Stoyanov</author>
</authors>
<title>SemEval-2015 task 10: Sentiment analysis in twitter.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="18731" citStr="Rosenthal et al., 2015" startWordPosition="3012" endWordPosition="3015">s instantiations of pleasant and unpleasant events previously collected in psychological researches as the ones on which human judgments converge (Lewinsohn and Amenson, 1978),(MacPhillamy. and Lewinsohn, 1982). Task 9 concerns classification of the events that are pleasant or unpleasant for a person writing in first person. This task was organized around two subtasks: (A) identification of the polarity value associated to an event instance, and (B) identification of both the event instantiations and the associated polarity values. The SHELLFBK system has been tested on both tasks. • Task 10 (Rosenthal et al., 2015): this task aims to identify sentiment polarities in short text messages contained in the Twitter microblog. This task contains five subtasks: (A) expression-level, (B) message-level, (C) topicrelated, (D) trend, and (E) a task on prior polarity of terms. The SHELLFBK has been tested only on the subtask (B). • Task 11 (Ghosh et al., 2015): this task consists in the classification of tweets containing irony and metaphors. Given a set of tweets that are rich in metaphor and irony, the goal is to determine whether the user has expressed a positive, negative, or neutral sentiment in each, and the </context>
</contexts>
<marker>Rosenthal, Nakov, Kiritchenko, Mohammad, Ritter, Stoyanov, 2015</marker>
<rawString>Sara Rosenthal, Preslav Nakov, Svetlana Kiritchenko, Saif M Mohammad, Alan Ritter, and Veselin Stoyanov. 2015. SemEval-2015 task 10: Sentiment analysis in twitter. In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015, Denver, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Russo</author>
<author>Tommaso Caselli</author>
<author>Carlo Strapparava</author>
</authors>
<title>SemEval-2015 Task 9: CLIPEval Implicit Polarity of Events.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="18053" citStr="Russo et al., 2015" startWordPosition="2905" endWordPosition="2908">= DF(RGDQ1) + DF(RDGQ1)+ DF(GDQ1) + DF(DGQ1) + DF(GQ1)+ DF(DQ1) + DF(RGDQ2) + DF(RDGQ2)+ DF(GDQ2) + DF(DGQ2) + DF(GQ2)+ DF(DQ2) Finally, the polarity of the sentence S is inferred by considering the maximum RSV computed over the three indexes: Polarity(S) = argmaxP∈POS,NEU,NEG RSV(S, P) In case of domain assignment, given a set D of k domains, the domain is computed by: Domain(S) = argmax Z∈1...k RSV(S, DZ) (5) 4 Results The SHELLFBK system participated in three SemEval 2015 tasks: 9, 10, and 11. All three tasks were about the sentiment analysis topic with the following differences: • Task 9 (Russo et al., 2015): this task is based on a dataset of events annotated as instantiations of pleasant and unpleasant events previously collected in psychological researches as the ones on which human judgments converge (Lewinsohn and Amenson, 1978),(MacPhillamy. and Lewinsohn, 1982). Task 9 concerns classification of the events that are pleasant or unpleasant for a person writing in first person. This task was organized around two subtasks: (A) identification of the polarity value associated to an event instance, and (B) identification of both the event instantiations and the associated polarity values. The SHE</context>
</contexts>
<marker>Russo, Caselli, Strapparava, 2015</marker>
<rawString>Irene Russo, Tommaso Caselli, and Carlo Strapparava. 2015. SemEval-2015 Task 9: CLIPEval Implicit Polarity of Events. In Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval ’2015, Denver, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
</authors>
<title>Discourse-level relations for Opinion Analysis.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pittsburgh.</institution>
<contexts>
<context position="6727" citStr="Somasundaran, 2010" startWordPosition="1077" endWordPosition="1079">Qiu et al., 2009b), the authors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enhance accuracy has been proposed. Opinion words have been used also for unsupervised learning approaches like the ones presented in (Taboada et al., 2011) and (Turney, 2002). Another research direction concerns the exploitation of discourse-analysis techniques. (Somasundaran, 2010) and (Asher et al., 2008) discuss some discourse-based supervised and unsupervised approaches for opinion analysis; while in (Wang and Zhou, 2010), the authors present an approach to identify discourse relations. The approaches presented above are applied at the document-level, i.e., the polarity value is assigned to the entire document content. However, for improving the accuracy of the sentiment classification, a more fine-grained analysis of the text, i.e., the sentiment classification of the single sentences, has to be performed. In the case of sentence-level sentiment classification, two </context>
</contexts>
<marker>Somasundaran, 2010</marker>
<rawString>Swapna Somasundaran. 2010. Discourse-level relations for Opinion Analysis. Ph.D. thesis, University of Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Su</author>
<author>Xinying Xu</author>
<author>Honglei Guo</author>
<author>Zhili Guo</author>
<author>Xian Wu</author>
<author>Xiaoxun Zhang</author>
<author>Bin Swen</author>
<author>Zhong Su</author>
</authors>
<title>Hidden sentiment association in chinese web opinion mining.</title>
<date>2008</date>
<booktitle>In WWW,</booktitle>
<pages>959--968</pages>
<contexts>
<context position="8980" citStr="Su et al., 2008" startWordPosition="1436" endWordPosition="1439">fferent opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened up new challenges due to the different ways people express their opinions, as described by (Barbosa and Feng, 2010) and </context>
</contexts>
<marker>Su, Xu, Guo, Guo, Wu, Zhang, Swen, Su, 2008</marker>
<rawString>Qi Su, Xinying Xu, Honglei Guo, Zhili Guo, Xian Wu, Xiaoxun Zhang, Bin Swen, and Zhong Su. 2008. Hidden sentiment association in chinese web opinion mining. In WWW, pages 959–968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly D Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexiconbased methods for sentiment analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="6599" citStr="Taboada et al., 2011" startWordPosition="1060" endWordPosition="1063">erefore, in order to reduce the labeling effort, opinion words have been used for training procedures. In (Tan et al., 2008) and (Qiu et al., 2009b), the authors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enhance accuracy has been proposed. Opinion words have been used also for unsupervised learning approaches like the ones presented in (Taboada et al., 2011) and (Turney, 2002). Another research direction concerns the exploitation of discourse-analysis techniques. (Somasundaran, 2010) and (Asher et al., 2008) discuss some discourse-based supervised and unsupervised approaches for opinion analysis; while in (Wang and Zhou, 2010), the authors present an approach to identify discourse relations. The approaches presented above are applied at the document-level, i.e., the polarity value is assigned to the entire document content. However, for improving the accuracy of the sentiment classification, a more fine-grained analysis of the text, i.e., the sen</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly D. Voll, and Manfred Stede. 2011. Lexiconbased methods for sentiment analysis. Computational Linguistics, 37(2):267–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yen-Jen Tai</author>
<author>Hung-Yu Kao</author>
</authors>
<title>Automatic domain-specific sentiment lexicon generation with label propagation.</title>
<date>2013</date>
<booktitle>In iiWAS,</booktitle>
<pages>53--53</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="11658" citStr="Tai and Kao, 2013" startWordPosition="1862" endWordPosition="1865">one domain may have positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind the usage of such an approach is that by using indexes, the computation of the Retrieval Status Value (RSV) (da Costa Pereira et al., 2012) of a term or expression, automatically takes into account which are the elements</context>
</contexts>
<marker>Tai, Kao, 2013</marker>
<rawString>Yen-Jen Tai and Hung-Yu Kao. 2013. Automatic domain-specific sentiment lexicon generation with label propagation. In iiWAS, pages 53:53–53:62. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Songbo Tan</author>
<author>Yuefen Wang</author>
<author>Xueqi Cheng</author>
</authors>
<title>Combining learn-based and lexicon-based techniques for sentiment detection without using labeled examples.</title>
<date>2008</date>
<booktitle>In SIGIR,</booktitle>
<pages>743--744</pages>
<contexts>
<context position="6102" citStr="Tan et al., 2008" startWordPosition="984" endWordPosition="987"> learning method, researchers have also proposed several custom techniques specifically for sentiment classification, like the use of adapted score function based on the evaluation of positive or negative words in product reviews (Dave et al., 2003), as well as by defining weighting schemata for enhancing classification accuracy (Paltoglou and Thelwall, 2010). An obstacle to research in this direction is the need of labeled training data, whose preparation is a time-consuming activity. Therefore, in order to reduce the labeling effort, opinion words have been used for training procedures. In (Tan et al., 2008) and (Qiu et al., 2009b), the authors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enhance accuracy has been proposed. Opinion words have been used also for unsupervised learning approaches like the ones presented in (Taboada et al., 2011) and (Turney, 2002). Another research direction concerns the exploitation of discourse-analysis techniq</context>
</contexts>
<marker>Tan, Wang, Cheng, 2008</marker>
<rawString>Songbo Tan, Yuefen Wang, and Xueqi Cheng. 2008. Combining learn-based and lexicon-based techniques for sentiment detection without using labeled examples. In SIGIR, pages 743–744.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Charng-Rurng Tsai</author>
<author>Chi-En Wu</author>
<author>Richard TzongHan Tsai</author>
<author>Jane Yung jen Hsu</author>
</authors>
<title>Building a concept-level sentiment dictionary based on commonsense knowledge.</title>
<date>2013</date>
<journal>IEEE Int. Systems,</journal>
<volume>28</volume>
<issue>2</issue>
<contexts>
<context position="11639" citStr="Tsai et al., 2013" startWordPosition="1858" endWordPosition="1861">, the same word in one domain may have positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind the usage of such an approach is that by using indexes, the computation of the Retrieval Status Value (RSV) (da Costa Pereira et al., 2012) of a term or expression, automatically takes into account whi</context>
</contexts>
<marker>Tsai, Wu, Tsai, Hsu, 2013</marker>
<rawString>Angela Charng-Rurng Tsai, Chi-En Wu, Richard TzongHan Tsai, and Jane Yung jen Hsu. 2013. Building a concept-level sentiment dictionary based on commonsense knowledge. IEEE Int. Systems, 28(2):22–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´elia da Costa Pereira</author>
<author>Mauro Dragoni</author>
<author>Gabriella Pasi</author>
</authors>
<title>Multidimensional relevance: Prioritized aggregation in a personalized Information Retrieval setting.</title>
<date>2012</date>
<journal>Inf. Process. Manage.,</journal>
<volume>48</volume>
<issue>2</issue>
<contexts>
<context position="12177" citStr="Pereira et al., 2012" startWordPosition="1951" endWordPosition="1954">f labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind the usage of such an approach is that by using indexes, the computation of the Retrieval Status Value (RSV) (da Costa Pereira et al., 2012) of a term or expression, automatically takes into account which are the elements that are more significant in each index with respect to the ones that, instead, are not important with respect to the index content. In this section, we present the steps we carried out to implement our IR based sentiment and theme classification system. 504 3.1 Indexes Construction The proposed approach, with respect to a classic IR system, does not use a single index for containing all information, but a set of indexes are created in order to facilitate the identification of the correct polarity and domain, of </context>
</contexts>
<marker>Pereira, Dragoni, Pasi, 2012</marker>
<rawString>C´elia da Costa Pereira, Mauro Dragoni, and Gabriella Pasi 2012. Multidimensional relevance: Prioritized aggregation in a personalized Information Retrieval setting. Inf. Process. Manage., 48(2):340–357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In ACL,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="6618" citStr="Turney, 2002" startWordPosition="1065" endWordPosition="1066"> the labeling effort, opinion words have been used for training procedures. In (Tan et al., 2008) and (Qiu et al., 2009b), the authors used opinion words to label portions of informative examples for training the classifiers. Opinion words have been exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enhance accuracy has been proposed. Opinion words have been used also for unsupervised learning approaches like the ones presented in (Taboada et al., 2011) and (Turney, 2002). Another research direction concerns the exploitation of discourse-analysis techniques. (Somasundaran, 2010) and (Asher et al., 2008) discuss some discourse-based supervised and unsupervised approaches for opinion analysis; while in (Wang and Zhou, 2010), the authors present an approach to identify discourse relations. The approaches presented above are applied at the document-level, i.e., the polarity value is assigned to the entire document content. However, for improving the accuracy of the sentiment classification, a more fine-grained analysis of the text, i.e., the sentiment classificati</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In ACL, pages 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cornelis Joost van Rijsbergen</author>
</authors>
<title>Information Retrieval.</title>
<date>1979</date>
<location>Butterworth.</location>
<marker>van Rijsbergen, 1979</marker>
<rawString>Cornelis Joost van Rijsbergen. 1979. Information Retrieval. Butterworth.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongling Wang</author>
<author>Guodong Zhou</author>
</authors>
<title>Topic-driven multi-document summarization.</title>
<date>2010</date>
<booktitle>In IALP,</booktitle>
<pages>195--198</pages>
<contexts>
<context position="6873" citStr="Wang and Zhou, 2010" startWordPosition="1098" endWordPosition="1101">n exploited also for improving the accuracy of sentiment classification, as presented in (Melville et al., 2009), where a framework incorporating lexical knowledge in supervised learning to enhance accuracy has been proposed. Opinion words have been used also for unsupervised learning approaches like the ones presented in (Taboada et al., 2011) and (Turney, 2002). Another research direction concerns the exploitation of discourse-analysis techniques. (Somasundaran, 2010) and (Asher et al., 2008) discuss some discourse-based supervised and unsupervised approaches for opinion analysis; while in (Wang and Zhou, 2010), the authors present an approach to identify discourse relations. The approaches presented above are applied at the document-level, i.e., the polarity value is assigned to the entire document content. However, for improving the accuracy of the sentiment classification, a more fine-grained analysis of the text, i.e., the sentiment classification of the single sentences, has to be performed. In the case of sentence-level sentiment classification, two different sub-tasks have to be addressed: (i) to determine if the sentence is subjective or objective, and (ii) in the case that the sentence is s</context>
</contexts>
<marker>Wang, Zhou, 2010</marker>
<rawString>Hongling Wang and Guodong Zhou. 2010. Topic-driven multi-document summarization. In IALP, pages 195– 198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiu Feng Wang</author>
<author>Erik Cambria</author>
<author>Cheng Lin Liu</author>
<author>Amir Hussain</author>
</authors>
<title>Common sense knowledge for handwritten chinese recognition.</title>
<date>2013</date>
<journal>Cognitive Computation,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="10446" citStr="Wang et al., 2013" startWordPosition="1666" endWordPosition="1669">uthors present a distant supervision-based approach for sentiment classification. At the same time, the social dimension of the Web opens up the opportunity to combine computer science and social sciences to better recognize, interpret, and process opinions and sentiments expressed over it. Such multi-disciplinary approach has been called sentic computing (Cambria and Hussain, 2012b). Application domains where sentic computing has already shown its potential are the cognitive-inspired classification of images (Cambria and Hussain, 2012a), of texts in natural language, and of handwritten text (Wang et al., 2013). Finally, an interesting recent research direction is domain adaptation, as it has been shown that sentiment classification is highly sensitive to the domain from which the training data is extracted. A classifier trained using opinionated documents from one domain often performs poorly when it is applied or tested on opinionated documents from another domain, as we demonstrated through the example presented in Section 1. The reason is that words and even language constructs used in different domains for expressing opinions can be quite different. To make matters worse, the same word in one d</context>
</contexts>
<marker>Wang, Cambria, Liu, Hussain, 2013</marker>
<rawString>Qiu Feng Wang, Erik Cambria, Cheng Lin Liu, and Amir Hussain. 2013. Common sense knowledge for handwritten chinese recognition. Cognitive Computation, 5(2):234–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Rebecca F Bruce</author>
<author>Matthew Bell</author>
<author>Melanie Martin</author>
</authors>
<title>Learning subjective language.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<contexts>
<context position="7758" citStr="Wiebe et al., 2004" startWordPosition="1239" endWordPosition="1242">on, a more fine-grained analysis of the text, i.e., the sentiment classification of the single sentences, has to be performed. In the case of sentence-level sentiment classification, two different sub-tasks have to be addressed: (i) to determine if the sentence is subjective or objective, and (ii) in the case that the sentence is subjective, to determine if the opinion expressed in the sentence is positive, negative, or neutral. The task of classifying a sentence as subjective or objective, called “subjectivity classification”, has been widely discussed in the literature (Riloff et al., 2006; Wiebe et al., 2004; Wilson et al., 2004; Wilson et al., 2006; Yu and Hatzivassiloglou, 2003). Once subjective sentences are identified, the same 503 methods as for sentiment classification may be applied. For example, in (Hatzivassiloglou and Wiebe, 2000) the authors consider gradable adjectives for sentiment spotting; while in (Kim and Hovy, 2007) and (Kim et al., 2006) the authors built models to identify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting </context>
</contexts>
<marker>Wiebe, Wilson, Bruce, Bell, Martin, 2004</marker>
<rawString>Janyce Wiebe, Theresa Wilson, Rebecca F. Bruce, Matthew Bell, and Melanie Martin. 2004. Learning subjective language. Computational Linguistics, 30(3):277–308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Rebecca Hwa</author>
</authors>
<title>Just how mad are you? finding strong and weak opinion clauses.</title>
<date>2004</date>
<booktitle>In AAAI,</booktitle>
<pages>761--769</pages>
<contexts>
<context position="7779" citStr="Wilson et al., 2004" startWordPosition="1243" endWordPosition="1246">ned analysis of the text, i.e., the sentiment classification of the single sentences, has to be performed. In the case of sentence-level sentiment classification, two different sub-tasks have to be addressed: (i) to determine if the sentence is subjective or objective, and (ii) in the case that the sentence is subjective, to determine if the opinion expressed in the sentence is positive, negative, or neutral. The task of classifying a sentence as subjective or objective, called “subjectivity classification”, has been widely discussed in the literature (Riloff et al., 2006; Wiebe et al., 2004; Wilson et al., 2004; Wilson et al., 2006; Yu and Hatzivassiloglou, 2003). Once subjective sentences are identified, the same 503 methods as for sentiment classification may be applied. For example, in (Hatzivassiloglou and Wiebe, 2000) the authors consider gradable adjectives for sentiment spotting; while in (Kim and Hovy, 2007) and (Kim et al., 2006) the authors built models to identify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinion</context>
</contexts>
<marker>Wilson, Wiebe, Hwa, 2004</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. 2004. Just how mad are you? finding strong and weak opinion clauses. In AAAI, pages 761–769.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Rebecca Hwa</author>
</authors>
<title>Recognizing strong and weak opinion clauses.</title>
<date>2006</date>
<journal>Computational Intelligence,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="7800" citStr="Wilson et al., 2006" startWordPosition="1247" endWordPosition="1250">ext, i.e., the sentiment classification of the single sentences, has to be performed. In the case of sentence-level sentiment classification, two different sub-tasks have to be addressed: (i) to determine if the sentence is subjective or objective, and (ii) in the case that the sentence is subjective, to determine if the opinion expressed in the sentence is positive, negative, or neutral. The task of classifying a sentence as subjective or objective, called “subjectivity classification”, has been widely discussed in the literature (Riloff et al., 2006; Wiebe et al., 2004; Wilson et al., 2004; Wilson et al., 2006; Yu and Hatzivassiloglou, 2003). Once subjective sentences are identified, the same 503 methods as for sentiment classification may be applied. For example, in (Hatzivassiloglou and Wiebe, 2000) the authors consider gradable adjectives for sentiment spotting; while in (Kim and Hovy, 2007) and (Kim et al., 2006) the authors built models to identify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same</context>
</contexts>
<marker>Wilson, Wiebe, Hwa, 2006</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. 2006. Recognizing strong and weak opinion clauses. Computational Intelligence, 22(2):73–99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining. In</title>
<date>2009</date>
<booktitle>EMNLP,</booktitle>
<pages>1533--1541</pages>
<contexts>
<context position="8946" citStr="Wu et al., 2009" startWordPosition="1430" endWordPosition="1433">ng the ability of detecting the different opinions concerning the same product expressed in the same review became a challenging problem. Such a task has been faced by introducing “aspect” extraction approaches that were able to extract, from each sentence, which is the aspect the opinion refers to. In the literature, many approaches have been proposed: conditional random fields (CRF) (Jakob and Gurevych, 2010; Lafferty et al., 2001), hidden Markov models (HMM) (Freitag and McCallum, 2000; Jin and Ho, 2009; Jin et al., 2009), sequential rule mining (Liu et al., 2005), dependency tree kernels (Wu et al., 2009), and clustering (Su et al., 2008). In (Qiu et al., 2009a; Qiu et al., 2011), a method was proposed to extract both opinion words and aspects simultaneously by exploiting some syntactic relations of opinion words and aspects. A particular attention should be given also to the application of sentiment analysis in social networks. More and more often, people use social networks for expressing their moods concerning their last purchase or, in general, about new products. Such a social network environment opened up new challenges due to the different ways people express their opinions, as describe</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In EMNLP, pages 1533–1541.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Xia</author>
<author>Chengqing Zong</author>
<author>Xuelei Hu</author>
<author>Erik Cambria</author>
</authors>
<title>Feature ensemble plus sample selection: Domain adaptation for sentiment classification.</title>
<date>2013</date>
<journal>IEEE Int. Systems,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="11498" citStr="Xia et al., 2013" startWordPosition="1835" endWordPosition="1838">n is that words and even language constructs used in different domains for expressing opinions can be quite different. To make matters worse, the same word in one domain may have positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind the usage of such an approach is that by using indexes, the </context>
</contexts>
<marker>Xia, Zong, Hu, Cambria, 2013</marker>
<rawString>Rui Xia, Chengqing Zong, Xuelei Hu, and Erik Cambria. 2013. Feature ensemble plus sample selection: Domain adaptation for sentiment classification. IEEE Int. Systems, 28(3):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Yang</author>
<author>Jamie Callan</author>
<author>Luo Si</author>
</authors>
<title>Knowledge transfer and opinion detection in the TREC</title>
<date>2006</date>
<booktitle>In TREC.</booktitle>
<contexts>
<context position="11416" citStr="Yang et al., 2006" startWordPosition="1819" endWordPosition="1822">er domain, as we demonstrated through the example presented in Section 1. The reason is that words and even language constructs used in different domains for expressing opinions can be quite different. To make matters worse, the same word in one domain may have positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to</context>
</contexts>
<marker>Yang, Callan, Si, 2006</marker>
<rawString>Hui Yang, Jamie Callan, and Luo Si. 2006. Knowledge transfer and opinion detection in the TREC 2006 blog track. In TREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhisa Yoshida</author>
<author>Tsutomu Hirao</author>
<author>Tomoharu Iwata</author>
<author>Masaaki Nagata</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Transfer learning for multiple-domain sentiment analysis— identifying domain dependent/independent word polarity.</title>
<date>2011</date>
<booktitle>In AAAI,</booktitle>
<pages>1286--1291</pages>
<contexts>
<context position="11521" citStr="Yoshida et al., 2011" startWordPosition="1839" endWordPosition="1842">d even language constructs used in different domains for expressing opinions can be quite different. To make matters worse, the same word in one domain may have positive connotations, but in another domain may have negative connotations; therefore, domain adaptation is needed. In the literature, different approaches related to the Multi-Domain sentiment analysis have been proposed. Briefly, two main categories may be identified: (i) the transfer of learned classifiers across different domains (Yang et al., 2006; Blitzer et al., 2007; Pan et al., 2010; Bollegala et al., 2013; Xia et al., 2013; Yoshida et al., 2011), and (ii) the use of propagation of labels through graph structures (Ponomareva and Thelwall, 2013; Tsai et al., 2013; Tai and Kao, 2013; Huang et al., 2014). Independently of the kind of approach, works using concepts rather than terms for representing different sentiments have been proposed. 3 The SHELLFBK System The proposed system is based on the implementation of an IR approach for inferring both the polarity of a sentence and, if requested, the domain to which the sentence belongs to. The rational behind the usage of such an approach is that by using indexes, the computation of the Retr</context>
</contexts>
<marker>Yoshida, Hirao, Iwata, Nagata, Matsumoto, 2011</marker>
<rawString>Yasuhisa Yoshida, Tsutomu Hirao, Tomoharu Iwata, Masaaki Nagata, and Yuji Matsumoto. 2011. Transfer learning for multiple-domain sentiment analysis— identifying domain dependent/independent word polarity. In AAAI, pages 1286–1291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP 2003,</booktitle>
<pages>129--136</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7832" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="1251" endWordPosition="1254">ent classification of the single sentences, has to be performed. In the case of sentence-level sentiment classification, two different sub-tasks have to be addressed: (i) to determine if the sentence is subjective or objective, and (ii) in the case that the sentence is subjective, to determine if the opinion expressed in the sentence is positive, negative, or neutral. The task of classifying a sentence as subjective or objective, called “subjectivity classification”, has been widely discussed in the literature (Riloff et al., 2006; Wiebe et al., 2004; Wilson et al., 2004; Wilson et al., 2006; Yu and Hatzivassiloglou, 2003). Once subjective sentences are identified, the same 503 methods as for sentiment classification may be applied. For example, in (Hatzivassiloglou and Wiebe, 2000) the authors consider gradable adjectives for sentiment spotting; while in (Kim and Hovy, 2007) and (Kim et al., 2006) the authors built models to identify some specific types of opinions. The growth of product reviews was the perfect floor for using sentiment analysis techniques in marketing activities. However, the issue of improving the ability of detecting the different opinions concerning the same product expressed in the same r</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of EMNLP 2003, pages 129– 136, Stroudsburg, PA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>