<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000173">
<title confidence="0.997876">
An Integrated Dialog Simulation Technique for Evaluating Spoken Dialog
Systems
</title>
<author confidence="0.998386">
Sangkeun Jung, Cheongjae Lee, Kyungduk Kim, Gary Geunbae Lee
</author>
<affiliation confidence="0.999971">
Department of Computer Science and Engineering
Pohang University of Computer Science and Technology(POSTECH)
</affiliation>
<address confidence="0.952983">
San 31, Hyoja-Dong, Pohang, 790-784, Korea
</address>
<email confidence="0.991259">
{hugman, lcj80, getta, gblee}@postech.ac.kr
</email>
<sectionHeader confidence="0.99348" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999987769230769">
This paper proposes a novel integrated dialog
simulation technique for evaluating spoken di-
alog systems. Many techniques for simulat-
ing users and errors have been proposed for
use in improving and evaluating spoken dia-
log systems, but most of them are not easily
applied to various dialog systems or domains
because some are limited to specific domains
or others require heuristic rules. In this pa-
per, we propose a highly-portable technique for
simulating user intention, utterance and Au-
tomatic Speech Recognition (ASR) channels.
This technique can be used to rapidly build a
dialog simulation system for evaluating spo-
ken dialog systems. We propose a novel user
intention modeling and generating method that
uses a linear-chain conditional random field, a
data-driven domain specific user utterance sim-
ulation method, and a novel ASR channel sim-
ulation method with adjustable error recogni-
tion rates. Experiments using these techniques
were carried out to evaluate the performance
and behavior of previously developed dialog
systems designed for navigation dialogs, and
it turned out that our approach is easy to set up
and shows the similar tendencies of real users.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999922875">
Evaluation of spoken dialog systems is essential for de-
veloping and improving the systems and for assessing
their performance. Normally, humans are used to eval-
uate the systems, but training and employing human
evaluators is expensive. Furthermore, qualified human
users are not always immediately available. These in-
evitable difficulties of working with human users can
cause huge delay in development and assessment of
</bodyText>
<note confidence="0.723266">
© 2008. Licensed under the Creative Commons
</note>
<footnote confidence="0.967176">
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.999919976744186">
spoken dialog systems. To avoid the problems that re-
sult from using humans to evaluate spoken dialog sys-
tems, developers have widely used dialog simulation,
in which a simulated user interacts with a spoken dia-
log system.
Many techniques for user intention, utterance and er-
ror simulation have been proposed. However, previ-
ously proposed simulation techniques cannot be eas-
ily applied to evaluate various dialog systems, because
some of these techniques are specially designed to work
with their own dialog systems, some require heuristic
rules or flowcharts, and others try to build user side
dialog management systems using specialized dialog
managing methods. These problems motivated us to
develop dialog simulation techniques which allow de-
velopers to build dialog simulation systems rapidly for
use in evaluating various dialog systems.
To be successful, a simulation approach should not
depend on specific domains or rules. Also it should not
be coupled to a specific dialog management method.
Furthermore, successful dialog simulation should fully
support both user simulation and environment simula-
tion. In user simulation, it must be capable of simu-
lating both user intentions and user utterances, because
user utterances are essential for testing the language un-
derstanding component of the dialog system. In addi-
tion to user simulation, environment simulation such as
ASR channel simulation is desirable because it allows
developers to test the dialog system in various acoustic
environments.
In this paper, we propose novel dialog simulation
techniques which satisfy these requirements. We in-
troduce a new user intention simulation method based
on the sequential graphical model, and a user utterance
simulator which can generate diverse natural user utter-
ances. The user intention and utterance simulators are
both fully data-driven approaches; therefore they have
high domain- and language portability. We also propose
a novel Automatic Speech Recognizer (ASR) channel
simulator which allows the developers to set the de-
sired speech recognition performance level. Through
a case study, we showed that our approach is feasible in
successful dialog simulation to evaluate spoken dialog
</bodyText>
<page confidence="0.985531">
9
</page>
<note confidence="0.694612">
Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 9–16
Manchester, August 2008
</note>
<bodyText confidence="0.9968302">
systems.
This paper is structured as follows. We first provide a
brief introduction of other dialog simulation techniques
and their differences from our approach in Section 2.
We then introduce the overall architecture and the de-
tailed methods of intention, utterance and ASR channel
simulation in Section 3. Experiments to test the simula-
tion techniques, and a case study are described in Sec-
tion 4. We conclude with a brief summary and suggest
directions for future work in Section 5.
</bodyText>
<sectionHeader confidence="0.999427" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.99997778125">
Dialog simulation techniques can be classified accord-
ing to the purpose of the simulation. One of the pur-
poses is to support the refinement of dialog strategies.
Some techniques use large amounts of simulated data
for a systematic exploration of the dialog state space
in the framework of reinforcement learning (Schatz-
mann et al., 2005; Schatzmann et al., 2007a). Other
techniques use simulation techniques to investigate and
improve the target dialog strategies by examining the
results heuristically or automatically (Chung, 2004;
Rieser and Lemon, 2006; Torres et al., 2008). A sec-
ond purpose of dialog simulation techniques is to eval-
uate the dialog system itself qualitatively. Eckert et al.,
(1997) and L´opez-C´ozar et., (2003; 2006) used a dialog
simulation to evaluate whole dialog systems.
Dialog simulation techniques can also be classified
according to the layers of the simulation. Typically, di-
alog simulation can be divided into three layers: user
intention, user surface (utterance) and error simulation.
Some studies have focused only on the intention level
simulation (Rieser and Lemon, 2006; Schatzmann et
al., 2007b; Cuayahuitl et al., 2005). The main purpose
of those approaches was to collect and examine inten-
tion level dialog behavior for automatically learning di-
alog strategies. In this case, surface and error simula-
tions were neglected or simply accessed normally.
Another approach is to simulate both user intention
and surface. In this approach, user utterance generation
is designed to express a given intention. Chung (2004)
tried to use the natural language generation module
of (Seneff, 2002) to generate this surface. He used a
speech synthesizer to generate user utterances. L´opez-
C´ozar et., (2003; 2006) collected real human utter-
ances, and selected and played the voice to provide in-
put for the spoken dialog system. Both Chung (2004)
and L´opez-C´ozar et., (2003; 2006) used rule based in-
tention simulation. They used real ASR to recognize
the synthesized or played voice; hence, ASR channel
simulation is not needed in their techniques. Schefier
and Young (2000; 2001) used the lattices which are de-
rived from the grammars used by the recognition en-
gine, but generated user utterances by associating the
lattice edges with intentions. During utterance gener-
ation, they simulated errors in recognition and under-
standing by probabilistic substitution on the selection of
the edge. Schatzmann et al., (2007a; 2007b) proposed a
statistical model for user utterance generation and error
simulation using agenda based intention simulation.
The existing rule-based techniques for simulating in-
tentions or surfaces are not appropriate in the sense of
portability criteria. In addition, specific dialog manag-
ing techniques based user simulators (e.g., (Torres et
al., 2008)) are not desirable because it is not easy to
implement these techniques for other developers. An-
other important criterion for evaluating dialog simula-
tion techniques for use in evaluating spoken dialog sys-
tems is the range of simulation layers. Simulations that
are restricted to only the intention level are not suffi-
cient to evaluate the whole dialog system. Domain and
language independent techniques for simulating both
intentions and utterances are needed, and ASR channel
simulation is desirable for evaluating the spoken dia-
log systems accurately because human-machine dialog
is heavily iniuenced by speech recognition errors.
</bodyText>
<sectionHeader confidence="0.996062" genericHeader="method">
3 Dialog Simulation Architecture for
Dialog System Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999852">
3.1 Overall Architecture
</subsectionHeader>
<bodyText confidence="0.998674771428571">
Typical spoken dialog systems deal with the dialog be-
tween a human user and a machine. Human users ut-
ter spoken language to express their intention, which is
recognized, understood and managed by ASR, Spoken
Language Understanding (SLU) and Dialog Manager
(DM). Conventionally, ASR has been considered to be
a component of dialog systems. However, in this re-
search, we do not include a real ASR module in the di-
alog system component because a real ASR takes only
fixed level of speech as an input. To use real voices,
we must either collect real human speech or generate
voices using a speech synthesizer. However, both ap-
proaches have limitations. When recording and play-
ing real human voices, the cost of data collection is
high and the simulator can simulate only the behav-
ior of the humans who were recorded. When using a
speech synthesizer, the synthesizer can usually generate
the speech of one person, on a limited variety of speech
behaviors; this means that the dialog system cannot be
evaluated under various conditions. Also, in both ap-
proaches, freely adjusting the speech recognition per-
formance level is difficult. In this research, instead of
using real speech we simulate the ASR channel and add
noises to a clean utterance from the user simulator to
mimic the speech recognition result.
The overall architecture of our dialog simulation sep-
arates the user simulator into two levels: user intention
simulator and utterance simulator (Fig. 1). The user
intention simulator accepts the discourse circumstances
with system intention as input and generates the next
user intention. The user utterance simulator constructs
a corresponding user sentence to express the given user
intention. The simulated user sentence is fed to the
ASR channel simulator, which then adds noises to the
utterance. This noisy utterance is passed to a dialog sys-
</bodyText>
<page confidence="0.971938">
10
</page>
<figure confidence="0.996331222222222">
= Simulated User = = System =
User Simulator
User Utterance
Simulator
User Intention
Simulator
Dialog Logs
Evaluator
ASR
Channel
Simulator
Evaluation
Results
Dialog Manager
Dialog System
System
Intention
SLU
</figure>
<figureCaption confidence="0.991130333333333">
Figure 2: Conditional Random Fields for user intention
modeling. UIt: User Intention; DIt: Discourse Infor-
mation for the tth user turn
</figureCaption>
<figure confidence="0.999648111111111">
DI1
UI1
DI2
UI2
...
UIt
DIt
DIt+1
UIt+1
</figure>
<figureCaption confidence="0.999984">
Figure 1: Overall architecture of dialog simulation
</figureCaption>
<bodyText confidence="0.9999874">
tem which consists of a SLU and a DM. The dialog sys-
tem understands the user utterance, manages dialog and
passes the system intention to the user simulator. User
simulator, ASR channel simulator and dialog system re-
peat the conversation until the user simulator generates
an end to the dialog.
After finishing simulating one dialog successfully,
this dialog is stored in Dialog Logs. If the dialog logs
contain enough dialogs, the evaluator uses the logs to
evaluate the performance of the dialog system.
</bodyText>
<subsectionHeader confidence="0.998451">
3.2 User Intention Simulation
</subsectionHeader>
<bodyText confidence="0.999956555555556">
The task of user intention simulation is to generate sub-
sequent user intentions given current discourse circum-
stances. The intention is usually represented as ab-
stracted user’s goals and information on user’s utter-
ance (surface). In other words, generating the user’s
next semantic frame from the current discourse status
constitutes the user intention simulation.
Dialog is basically sequential behavior in which par-
ticipants use language to interact with each other. This
means that intentions of the user or the system are natu-
rally embedded in a sequential structure. Therefore, in
intention modeling we must consider how to model this
sequential property. Also, we must understand that the
user’s intention depends not only on previous n-gram
user and system intentions, but also on diverse dis-
course circumstances, including dialog goal, the num-
ber of items, and the number of filled component slots.
Sophisticated user intention modeling should be able to
reflect the discourse information.
To satisfy the sequential property and use rich
information for user intention modeling, we used
linear-chain Conditional Random Field (CRF) model
(Lafferty et al., 2001) for user intention modeling.
Let Y, X be random vectors, A = {Ak} E RK be a
parameter vector, and {fk(y,y&apos;,xt)}Kk=1 be a set of
real-valued feature functions. Then a linear-chain CRF
is a distribution of p(y|x) that takes the form
</bodyText>
<equation confidence="0.99897775">
K
1
p(y|x) = Z(x) exp { E Akfk(yt, yt−1, xt)} (1)
k=1
</equation>
<bodyText confidence="0.989565447368421">
where Z(x) is an instance-specific normalization func-
tion.
Akfk(yt, yt−1, xt)}
CRF is an undirected graphical model that defines a
single log-linear distribution over the joint probability
of an entire label sequence given a particular observa-
tion sequence. This single distribution removes the per-
state normalization requirement and allows entire state
sequences to be accounted for at once. This property is
well suited to model the entire sequence of intentions in
a dialog. Also, CRF is a conditional model, and not a
joint model (such as the Hidden Markov Model). Arbi-
trary facts can be captured to describe the observation
in the form of indicator functions. This means that CRF
allows us to use rich discourse information to model in-
tentions.
CRF has states and observations in each time line.
We represent the user intention as state and discourse
information as observations in CRF (Fig. 2). We rep-
resent the state as a semantic frame. For example in
the semantic frame representing the user intention for
the utterance ‘I want to go to city hall’ (Fig. 3), dia-
log act is a domain-independent label of an utterance at
the level of illocutionary force (e.g. statement, request,
wh question) and main goal is the domain-specific user
goal of an utterance (e.g. give something, tell purpose).
Component slots represent named entities in the utter-
ance. We use the cartesian product of each slot of se-
mantic frame to represent the state of the utterance in
our CRF model. In this example, the state symbol is
‘requestxsearch locxloc name’.
For the observation, we can use various discourse
events because CRF allows using rich information by
interpreting each event as an indicator function. Be-
cause we pursue the portable dialog simulation tech-
nique, we separated the features of the discourse in-
formation into those that are domain independent and
those that are domain dependent. Domain independent
</bodyText>
<equation confidence="0.994714285714286">
E
Z(x) =
y
K
E
k=1
exp {
</equation>
<page confidence="0.994151">
11
</page>
<table confidence="0.956257846153846">
Semantic Frame for User Inention Simulation
raw user utterance I want to go to city hall.
dialog_act request
main_goal search loc
component.[loc_name] cityhall
Preprocessing Information for User Utterance Simulation
processed utterance I/PRP want/VB to/TO go/VB to/TO floc_name]
/[loc_name]
Structure Tags PRP, VB, TO, VB, TO, floc_name]
Word Vocabulary I, want, to, go, to, floc_name]
Generation Target for User Utterance Simulation
Structure PRP → VB → TO → VB → TO → floc name]
Word Sequence I → want → to → go → to → floc_name]
</table>
<figureCaption confidence="0.977044333333333">
Figure 3: Example of semantic frame for user inten-
tion, and preprocessing and generation target for user
utterance simulation.
</figureCaption>
<bodyText confidence="0.999642390243903">
features include discourse information which is not rel-
evant to the specific dialog domain and system. For ex-
ample, previous system acts in Fig. 4 are not dependent
on specific dialog domain. The actual values of pre-
vious system acts could be dependent on each dialog
domain and system, but the label itself is independent
because every dialog system has system parts and corre-
sponding system acts. In contrast, domain specific dis-
course information exists for each dialog system. For
example, in the navigation domain (Fig. 4), the cur-
rent position of the user or the user’s favorite restau-
rant could be very important for generating the user’s
intention. This information is dependent on the spe-
cific domain and system. We handle these features as
‘OTHER INFO’.
We trained the user intention model using dialog ex-
amples of human-machine. One training example con-
sists of a sequence of user intentions and discourse in-
formation features in a given dialog. We collected train-
ing examples and trained the intention model using a
typical CRF training method, a limited-memory quasi-
Newton code for unconstrained optimization (L-BFGS)
of (Liu and Nocedal, 1989).
To generate user intentions given specific discourse
circumstances, we calculate the probability of a se-
quence of user intentions from the beginning of the
dialog to the corresponding turn. For example, sup-
pose that we need to generate user intention at the
third turn (UI3) (Fig. 2). We have previously sim-
ulated user intentions UI1 and UI2 using DI1 and
DI2. In this case, we calculate the probability of
UI1 → UI2 → UI3 given DI1, DI2 and DI3. No-
tice that DI3 contains discourse information at the third
turn: it includes previous system intention, attributes
and other useful information. Using the algorithm (Fig.
5) we generate the user intention at turn t. The proba-
bility of P(UI1, UI2, ... , UIt|DI1, DI2,... , DIt) is
calculated using the equation (1). In the genera-
tion of user intention at t turn, we do not select the
UIt which has higher probability. Instead, we se-
lect UIt randomly based on the probability distribution
</bodyText>
<table confidence="0.988565428571428">
Domain Independent Features
PREV_1_SYS_ACT previous system action.
PREV_1_SYS_ACT_ATTRIBUTES Ex) PREV_1_SYS_ACT=confirm
PREV_2_SYS_ACT previous system mentioned attributes.
PREV_2_SYS_ACT_ATTRIBUTES Ex) PREV_1_SYS_ACT_attributes=city_name
SYSTEM_HOLDING_COMP_SLOT previous system action.
Ex) PREV_2_SYS_ACT=confirm
previous system mentioned attributes.
Ex) PREV_2_SYS_ACT_attributes=city_name
system recognized component slot.
Ex) SYSTEM_HOLDING_COMP_SLOT=loc_name
Domain Dependent Features
OTHER_INFO other useful domain dependent information
Ex) OTHER_INFO(user_fav_rest)=gajokjung
</table>
<figureCaption confidence="0.945186">
Figure 4: Example feature design for navigation do-
main
</figureCaption>
<figure confidence="0.532386714285714">
UI t ˥ user intention at t turn
S ˥ user intentions set (UI t ଲ S )
UI 1 , UI 2 , ... , UI t-1 ˥ already simulated user intention sequence
DI 1 , DI 2 , ... , DI t ˥ discourse information from 1 to t turn
For each UI t in S
Calculate P( UI 1 , UI 2 , ..., UI t |DI 1 , DI 2 , ..., DI t )
UI t ˥ random user intention from P( UI 1 , UI 2 , ..., UIt |DI 1 , DI 2 , ..., DI t )
</figure>
<figureCaption confidence="0.99183">
Figure 5: User intention generation algorithm
</figureCaption>
<bodyText confidence="0.9979918">
P(UI1, UI2, ... , UIt|DI1, DI2, ... , DIt) because we
want to generate diverse user intention sequence given
the same discourse context. If we select UIt which has
highest probability, user intention simulator always re-
turns the same user intention sequence.
</bodyText>
<subsectionHeader confidence="0.997464">
3.3 User Utterance Simulation
</subsectionHeader>
<bodyText confidence="0.999957695652174">
Utterance simulation generates surface level utterances
which express a given user intention. For example, if
users want to go somewhere and provide place name
information, we need to generate corresponding utter-
ances (e.g. ‘I want to go to [place name] or ‘Let’s go to
[place name]’). We approach the task of user utterance
simulation by assuming that the types of structures and
the vocabulary are limited when we make utterances to
express certain context and intention in a specific do-
main, and that humans express their intentions by re-
combining and re-aligning these structures and vocabu-
laries.
To model this process, we need to collect the types of
structures and vocabularies. For this, we need to define
the context space. We define the structure and vocabu-
lary space as a production of dialog act and main goal.
In an example of semantic frame for the utterance “I
want to go to city hall” (Fig. 3), the structure and vocab-
ulary (SV) space ID is ‘request # search loc’, which is
produced by the dialog act and the main goal. We col-
lect structure tags, which consist of a part of speech
tag, a component slot tag, and a vocabulary that cor-
responds to SV space. For example (Fig. 3), structure
</bodyText>
<page confidence="0.955538">
12
</page>
<figure confidence="0.825797166666667">
First Phase – Generating Structures and Words given SV space
1. Repeat generate S t based on PSV(S t+1 |S t ),
until S T = &lt;setence—end&gt;, where S t ∈ S , t=1,2,3,....T .
2. Generate Wt based on PSV (Wt |S t ), where
t =1,2,3,..,T , Wt ∈ V
3. The generation word sequence W={W1,W2,..,WT} is inserted
into the set of generated utterance U
4. Repeat 1 to 3 for Max—Generation—Number
times, MaxGenerationNumber is given by developers
Second Phase – Selection by measure
1.Rescore the utterance U k in the set of U by the measure
2.Select top n-best
</figure>
<figureCaption confidence="0.999966">
Figure 6: Algorithm of user utterance simulation
</figureCaption>
<bodyText confidence="0.9996404375">
tags include PRP, VB, TO, VB as a part of speech tag
and [loc name] as a component slot tag. The vocab-
ulary includes I, want, to, go, and [loc name]. In the
vocabulary, every named-entity word is replaced with
its category name.
In this way, we can collect the structure tags and vo-
cabulary for each SV space from the dialog logs. For
the given SV space, we estimate probability distribu-
tions for statistical user utterance simulation using a
training process. For each space, we estimate tag tran-
sition probability PSV (St+1|St) and collect structure
tags set SSV and vocabularies VSV .
We devised a two-phase user utterance generation al-
gorithm (Fig. 6). Symbols are as follows. The detail
explanation of Fig. 6 will be followed in the next sub-
sections.
</bodyText>
<listItem confidence="0.999900714285714">
• SSV : structure tag set for given SV
• VSV : vocabularies for given SV
• Si : structure tag, i = 0, ..., T, Si E SSV
• Wi : word, i = 0,..., T, Wi E VSV
• Wseq : generated word sequence. Wseq =
(W1, W2, ..., WT)
• Uk : k-th sampled utterance,
</listItem>
<equation confidence="0.88425">
k = 1, ..., Max Sampling Number, Uk E U
</equation>
<subsectionHeader confidence="0.8584405">
3.3.1 First Phase - Generating Structure and
Word Sequence
</subsectionHeader>
<bodyText confidence="0.993998641509434">
We generate the structure tag S1 based on the prob-
ability of PSV (S1 |&lt; sentence start &gt;) and then
S1 influences the generating of S2 after PSV (S2|S1).
In this way, a structure tag chain is generated sequen-
tially based on the structure tag transition probability
PSV (St+1|St) until the last generated structure tag ST
is &lt; sentence end &gt;. We assume that the current
structure tag has a first order Markov property, which
means that the structure tag is only influenced by the
previous structure tag. After the structure tags are
generated, the emission probability PSV (Wt|St)(w =
1, ... , T) is used to generate the word sequence given
the tag sequence. We iterate the process of generating
structures and word sequences sufficient times to gen-
erate many different structure tags and word sequences
which may occur in real human expressions. Select-
ing natural utterances from the generated utterances re-
quires an automatic evaluation metric.
3.3.2 Second Phase - Selection by the BLEU
measure
To measure the naturalness of the generated utter-
ances, we use the BLEU (Bilingual Evaluation Under-
study) score (Papineni et al., 2001) which is widely
used for automatic evaluation in Statistical Machine
Translation (SMT). In SMT, translated candidate sen-
tences are evaluated by comparing semantically equiv-
alent reference sentences which have been translated
by a human. Evaluation of the user utterance gener-
ation shares the same task of evaluation in SMT. We
can evaluate the naturalness of generated utterances by
comparing semantically equivalent reference utterances
collected by humans. Therefore, the BLEU score can
be adopted successfully to measure the naturalness of
the utterances.
The BLEU score is the geometric mean of the n-gram
precisions with a brevity penalty. The original BLEU
metric is used to evaluate translated sentences by com-
paring them to several reference sentences. We mod-
ified the BLEU metric to compare one generated ut-
terance with several reference utterances. To rescore
the generated utterances, we used the Structure and
Word interpolated BLEU score (SWB). After the first
phase, we obtain generated utterances which have both
structure and word sequence. To measure the natu-
ralness of a generated utterance, we check both struc-
tural and lexical naturalness. We calculated Struc-
ture Sequence BLEU score using the generated struc-
ture tags sequences instead of words sequences with the
reference structure tag sequences of the SV space in the
BLEU calculation process. The Word Sequence BLEU
is calculated by measuring BLEU score using the gener-
ated words sequence with the reference word sequences
of the SV space. SWB is calculated as:
</bodyText>
<equation confidence="0.992918">
SWB = a * Structure Sequence BLEU
+(1 − a) * Word Sequence BLEU
</equation>
<bodyText confidence="0.99979575">
In this study, we set a = 0.5. Using SWB, we select
the top 20-best generated utterances and return a corre-
sponding generated utterance by selecting one of them
randomly.
</bodyText>
<subsectionHeader confidence="0.948137">
3.4 ASR channel Simulation
</subsectionHeader>
<bodyText confidence="0.999963555555556">
ASR channel simulation generates speech recognition
errors which might occur in the real speech recognition
process. In this study, we simulate the ASR channel and
modify the generated clean utterance to a speech rec-
ognized erroneous utterance. Successful ASR channel
simulation techniques should have the following prop-
erties: the developer should be able to set the simu-
lated word error rate (WER) between 0% ˜ 100%; the
simulated errors should be generated based on realistic
</bodyText>
<page confidence="0.997952">
13
</page>
<bodyText confidence="0.999941142857143">
phone-level and word-level confusions; and the tech-
nique should be easily adapted to new tasks, at low cost.
Our ASR channel simulation approach is designed
to satisfy these properties. The proposed ASR channel
simulation method involved four steps: 1) Determining
error position 2) Generating error types on error marked
words. 3) Generating ASR errors such as substitution,
deletion and insertion errors, and 4) Rescoring and se-
lecting simulated erroneous utterances (Fig. 7 for Ko-
rean language example).
In the first step, we used the WER to determine the
positions of erroneous words. For each word, we ran-
domly generate a number between 0 and 1. If this num-
ber is between 0 and WER, we mark the word Error
Word (1); otherwise we mark the word Clean Word (0).
In the second step, we generate ASR error types for the
error marked words based on the error type distribution.
In the third step, we generate various types of ASR er-
ror. In the case of deletion error, we simply delete the
error marked word from the utterance. In the case of
insertion error, we select one word from the pronunci-
ation dictionary randomly, and insert it before the error
marked word. In the case of substitution error, we use a
more complex process to select a substitutable word.
To select a substitutable word, we compare the
marked error word with the words from pronunciation
dictionary which are similar in syllable sequence and
phoneme sequence. First, we convert the final word
sequence from the user simulator into a phoneme se-
quence using a Grapheme-to-Phoneme (G2P) module
(Lee et al., 2006). Then, we extract a part of the
phoneme sequence which is similar to the error marked
word from the entire phoneme sequence of the ut-
terance. The reason for extracting a target phoneme
sequence corresponding to one word from the entire
phoneme sequence is that the G2P results vary between
the boundaries of words. Then, we separate the marked
word into syllables and compare their syllable-level
similarity to other words in the pronunciation dictio-
nary. We calculate a similarity score which interpolates
syllable and phoneme level similarity using following
equations.
</bodyText>
<equation confidence="0.997579">
Similarity = 0 * Syllable Alignment Score
+(1 − 0) * Phone Alignment Score
</equation>
<bodyText confidence="0.987324642857143">
We used the dynamic global alignment algorithm of
(Needleman and Wunsch, 1970) for both syllable and
phoneme sequence alignment. This alignment algo-
rithm requires a weight matrix. As a weight matrix,
we used a vowel confusion matrix which is based on
the manner of articulation. We consider the position
(back/front, high/mid/low) of the tongue and the shape
(round/flat) of the lips. We select candidate words
which have higher similarity than an arbitrary thresh-
old 0 and replace the error marked word with a random
word from this set. We repeat steps 1 to 3 many times
(usually 100) to collect error added utterances.
In the fourth step, we rescore the error added utter-
si-chung e ga go sip eo (I want to go to city hall)
</bodyText>
<figureCaption confidence="0.999349">
Figure 7: Example of ASR channel simulation
</figureCaption>
<bodyText confidence="0.999941166666667">
ances using the language model (LM) score. This LM
is trained using a domain corpus which is usually used
in ASR. We select top n-best erroneous utterances (we
set n=10) and choose one of them randomly. This utter-
ance is the final result of ASR channel simulator, and is
fed into the dialog system.
</bodyText>
<sectionHeader confidence="0.998973" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999894545454546">
We proposed a method that user intention, utterance and
ASR channel simulation to rapidly assemble a simula-
tion system to evaluate dialog systems. We conducted
a case study for the navigation domain Korean spoken
dialog system to test our simulation method and exam-
ine the dialog behaviors using the simulator. We used
100 dialog examples from real user and dialog system
to train user intention and utterance simulator. We used
the SLU method of (Jeong and Lee, 2006), and dia-
log management method of (Kim et al., 2008) to build
the dialog system. After trained user simulator, we per-
form simulation to collect 5000 dialog samples for each
WER settings (WER = 0 ˜ 40 %).
To verify the user intention and utterance simula-
tion quality, we let two human judges to evaluate 200
randomly chosen dialogs and 1031 utterances from the
simulated dialog examples (WER=0%). At first, they
evaluate a dialog with three scale (1: Unnatural, 2: Pos-
sible, 3: Natural), then evaluate the utterances of a dia-
log with three scale (1: Unclear, 2: Understandable, 3:
Natural).
The inter evaluator agreement (kappa) is 0.45 and
0.58 for dialog and utterance evaluation respectively,
which show the moderate agreement (Fig. 8). Both
judges show the positive reactions for the quality of user
intention and utterance, the simulated dialogs can be
possibly occurred, and the quality of utterance is close
to natural human utterance.
We also did regression analysis with the results of
human evaluation and the SWB score to find out the
relationship between SWB and human judgment. Fig.
9 shows the result of polynomial regression (order 3)
result. It shows that ‘Unclear’ utterance might have 0.5
</bodyText>
<figure confidence="0.892270458333333">
Error Generation
Ranking with LM score
4-Step
Selecting Noisy
Utterance
si-cheong gat go seo eo
Generating Error
Types and
Positions
si-cheong e ga go sip eo
0 1 1 0 1 0
- del sub - sub -
si-cheong - geo-gi go si eo
Generating si-cheong - ga-ja go seo eo
Candidate Lists of si-cheong - gat go seu eo
Noisy Utterance
si-cheong - geot go sil eo
1-Step
2-Step
3-Step
14
Human 1 Human 2 Average Kappa
Dialog 2.38 2.22 2.30 0.45
Utterance 2.74 2.67 2.71 0.58
</figure>
<figureCaption confidence="0.8334495">
Figure 8: Human evaluation results on dialog and utter-
ance
</figureCaption>
<figure confidence="0.995702928571429">
0.94
0.84
0.74
0.64
0.54
0.44
0.34
SWB Score
0 5 10 15 20 25 30 35 40
SLU accuracy and TCR
0.90
0.80
0.70
0.60
0.50
1.00
SLU
TCR
Length
9.3
8.9
8.5
8.1
7.7
Avg. Dialog Length (turns)
Word Error Rate (%)
1 1.5 2 2.5 3
Average human evaluation for user utterances
</figure>
<figureCaption confidence="0.9725735">
Figure 9: Relationship between SWB score and human
judgment
</figureCaption>
<bodyText confidence="0.998081888888889">
˜ 0.7 SWB score, ‘Possible’ and ‘Natural’ simulated
utterance might have over 0.75. It means that we can
simulate good user utterance if we constrain the user
simulator with the threshold around 0.75 SWB score.
To assess the ASR channel simulation quality, we
compared how SLU of utterances was affected by
WER. SLU was quantified according to sentence er-
ror rate (SER) and concept error rate (CER). Compared
to WER set by the developer, measured WER was the
same, SER increased more rapidly, and CER increased
more slowly (Fig. 10). This means that our simula-
tion framework models SLU errors effective as well as
speech recognition errors.
Fig. 11 shows the overall dialog system behaviors us-
ing the user simulator and ASR channel simulator. As
the WER rate increased, dialog system performance de-
creased and dialog length increased. This result is sim-
ilar as observed to the dialog behaviors in real human-
</bodyText>
<figureCaption confidence="0.862861">
Figure 10: Relationship between given WER and mea-
sured other error rates. X-axis = WER fixed by ASR
channel(%)
Figure 11: Dialog simulation result on navigation do-
main
</figureCaption>
<bodyText confidence="0.840818">
machine dialog.
</bodyText>
<sectionHeader confidence="0.998905" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999962476190476">
This paper presented novel and easy to build dialog sim-
ulation methods for use in evaluation of spoken dia-
log systems. We proposed methods of simulating utter-
ances and user intentions to replace real human users,
and introduced an ASR channel simulation method that
acts as a real speech recognizer. We introduce a method
of simulating user intentions which is based on the CRF
sequential graphical model, and an utterance simulator
that generates user utterances. Both user intention and
utterance simulators use a fully data-driven approach;
therefore, they have high domain- and language porta-
bility. We also proposed a novel ASR channel sim-
ulator which allows the developers to set the speech
recognition performance level. We applied our meth-
ods to evaluate a navigation domain dialog system; ex-
perimental results show that the simulators successfully
evaluated the dialog system, and that simulated inten-
tion, utterance and errors closely match to those ob-
served in real human-computer dialogs. We will apply
our approach to other dialog systems and bootstrap new
dialog system strategy for the future works.
</bodyText>
<sectionHeader confidence="0.998235" genericHeader="acknowledgments">
6 Acknowledgement
</sectionHeader>
<bodyText confidence="0.997805">
This research was supported by the Intelligent Robotics
Development Program, one of the 21st Century Frontier
R&amp;D Programs funded by the Ministry of Knowledge
Economy of Korea.
</bodyText>
<sectionHeader confidence="0.995185" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.7975202">
Chung, G. 2004. Developing a flexible spoken dialog
system using simulation. Proc. ACL, pages 63–70.
Cuayahuitl, H., S. Renals, O. Lemon, and H. Shi-
modaira. 2005. Human-Computer Dialogue Sim-
ulation Using Hidden Markov Models. Automatic
</reference>
<figure confidence="0.978811085714286">
100
90
80
70
60
50
40
30
20
10
0
WER measured
SER
CER
err rate(%)
1.9087 10.1069
0
0
0
33.28
10
10
18.3183 26.1619
19.71
56.6
20
70.91
30
29
34.4322 41.755
39.06
81.29
40
49.21
50
</figure>
<page confidence="0.792251">
88
15
</page>
<reference confidence="0.999191922077922">
Speech Recognition and Understanding, 2005 IEEE
Workshop on, pages 100–105.
Eckert, W., E. Levin, and R. Pieraccini. 1997. User
modeling for spoken dialogue system evaluation.
Automatic Speech Recognition and Understanding,
1997. Proceedings., 1997 IEEE Workshop on, pages
80–87.
Jeong, M. and G. Lee. 2006. Jointly Predicting
Dialog Act and Named Entity for Statistical Spo-
ken Language Understanding. Proceedings of the
IEEE/ACL 2006 workshop on spoken language tech-
nology (SLT).
Kim, K., C. Lee, S Jung, and G. Lee. 2008. A
frame-based probabilistic framework for spoken di-
alog management using dialog examples. In the 9th
sigdial workshop on discourse and dialog (sigdial
2008), To appear.
Lafferty, J.D., A. McCallum, and F.C.N. Pereira. 2001.
Conditional Random Fields: Probabilistic Models
for Segmenting and Labeling Sequence Data. Pro-
ceedings of the Eighteenth International Conference
on Machine Learning table of contents, pages 282–
289.
Lee, J., S. Kim, and G.G. Lee. 2006. Grapheme-to-
Phoneme Conversion Using Automatically Extracted
Associative Rules for Korean TTS System. In Ninth
International Conference on Spoken Language Pro-
cessing. ISCA.
Liu, D.C. and J. Nocedal. 1989. On the limited
memory BFGS method for large scale optimization.
Mathematical Programming, 45(1):503–528.
L´opez-C´ozar, R., A. De la Torre, JC Segura, and AJ Ru-
bio. 2003. Assessment of dialogue systems by
means of a new simulation technique. Speech Com-
munication, 40(3):387–407.
L´opez-C´ozar, Ram´on, Zoraida Callejas, and Michael
Mctear. 2006. Testing the performance of spoken di-
alogue systems by means of an artificially simulated
user. Artif. Intell. Rev., 26(4):291–323.
Needleman, SB and CD Wunsch. 1970. A general
method applicable to the search for similarities in the
amino acid sequence of two proteins. J Mol Biol,
48(3):443–53.
Papineni, K., S. Roukos, T. Ward, and WJ Zhu.
2001. BLEU: a method for automatic evaluation of
MT. Research Report, Computer Science RC22176
(W0109-022), IBM Research Division, TJ Watson
Research Center, 17.
Rieser, V. and O. Lemon. 2006. Cluster-Based User
Simulations for Learning Dialogue Strategies. In
Ninth International Conference on Spoken Language
Processing. ISCA.
Schatzmann, J., K. Georgila, and S. Young. 2005.
Quantitative Evaluation of User Simulation Tech-
niques for Spoken Dialogue Systems. In 6th SIGdial
Workshop on Discourse and Dialogue. ISCA.
Schatzmann, J., B. Thomson, and S. Young. 2007a.
Error simulation for training statistical dialogue sys-
tems. Automatic Speech Recognition &amp; Understand-
ing, 2007. ASRU. IEEE Workshop on, pages 526–
531.
Schatzmann, J., B. Thomson, and S. Young. 2007b.
Statistical User Simulation with a Hidden Agenda.
Proc. SIGDial, Antwerp, Belgium.
Scheffler, K. and S. Young. 2000. Probabilistic simula-
tion of human-machine dialogues. Proc. ofICASSP,
2:1217–1220.
Scheffler, K. and S. Young. 2001. Corpus-based dia-
logue simulation for automatic strategy learning and
evaluation. Proc. NAACL Workshop on Adaptation
in Dialogue Systems, pages 64–70.
Seneff, S. 2002. Response planning and generation
in the Mercury flight reservation system. Computer
Speech and Language, 16(3):283–312.
Torres, Francisco, Emilio Sanchis, and Encarna
Segarra. 2008. User simulation in a stochastic di-
alog system. Comput. Speech Lang., 22(3):230–255.
</reference>
<page confidence="0.998701">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.912061">
<title confidence="0.99973">An Integrated Dialog Simulation Technique for Evaluating Spoken Dialog Systems</title>
<author confidence="0.999202">Sangkeun Jung</author>
<author confidence="0.999202">Cheongjae Lee</author>
<author confidence="0.999202">Kyungduk Kim</author>
<author confidence="0.999202">Gary Geunbae</author>
<affiliation confidence="0.99993">Department of Computer Science and Pohang University of Computer Science and</affiliation>
<address confidence="0.97283">San 31, Hyoja-Dong, Pohang, 790-784,</address>
<email confidence="0.947204">lcj80,getta,</email>
<abstract confidence="0.999404407407408">This paper proposes a novel integrated dialog simulation technique for evaluating spoken dialog systems. Many techniques for simulating users and errors have been proposed for use in improving and evaluating spoken dialog systems, but most of them are not easily applied to various dialog systems or domains because some are limited to specific domains or others require heuristic rules. In this paper, we propose a highly-portable technique for simulating user intention, utterance and Automatic Speech Recognition (ASR) channels. This technique can be used to rapidly build a dialog simulation system for evaluating spoken dialog systems. We propose a novel user intention modeling and generating method that uses a linear-chain conditional random field, a data-driven domain specific user utterance simulation method, and a novel ASR channel simulation method with adjustable error recognition rates. Experiments using these techniques were carried out to evaluate the performance and behavior of previously developed dialog systems designed for navigation dialogs, and it turned out that our approach is easy to set up and shows the similar tendencies of real users.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Chung</author>
</authors>
<title>Developing a flexible spoken dialog system using simulation.</title>
<date>2004</date>
<booktitle>Proc. ACL,</booktitle>
<pages>63--70</pages>
<contexts>
<context position="5523" citStr="Chung, 2004" startWordPosition="823" endWordPosition="824">f summary and suggest directions for future work in Section 5. 2 Related Works Dialog simulation techniques can be classified according to the purpose of the simulation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divided into three layers: user intention, user surface (utterance) and error simulation. Some studies have focused only on the intention level simulation (Rieser and Lemon, 2006; Schatzmann et al., 2</context>
<context position="6865" citStr="Chung (2004)" startWordPosition="1033" endWordPosition="1034">r automatically learning dialog strategies. In this case, surface and error simulations were neglected or simply accessed normally. Another approach is to simulate both user intention and surface. In this approach, user utterance generation is designed to express a given intention. Chung (2004) tried to use the natural language generation module of (Seneff, 2002) to generate this surface. He used a speech synthesizer to generate user utterances. L´opezC´ozar et., (2003; 2006) collected real human utterances, and selected and played the voice to provide input for the spoken dialog system. Both Chung (2004) and L´opez-C´ozar et., (2003; 2006) used rule based intention simulation. They used real ASR to recognize the synthesized or played voice; hence, ASR channel simulation is not needed in their techniques. Schefier and Young (2000; 2001) used the lattices which are derived from the grammars used by the recognition engine, but generated user utterances by associating the lattice edges with intentions. During utterance generation, they simulated errors in recognition and understanding by probabilistic substitution on the selection of the edge. Schatzmann et al., (2007a; 2007b) proposed a statisti</context>
</contexts>
<marker>Chung, 2004</marker>
<rawString>Chung, G. 2004. Developing a flexible spoken dialog system using simulation. Proc. ACL, pages 63–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cuayahuitl</author>
<author>S Renals</author>
<author>O Lemon</author>
<author>H Shimodaira</author>
</authors>
<title>Human-Computer Dialogue Simulation Using Hidden Markov Models. Automatic Speech Recognition and Understanding,</title>
<date>2005</date>
<journal>IEEE Workshop on,</journal>
<pages>100--105</pages>
<contexts>
<context position="6153" citStr="Cuayahuitl et al., 2005" startWordPosition="918" endWordPosition="921">er and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divided into three layers: user intention, user surface (utterance) and error simulation. Some studies have focused only on the intention level simulation (Rieser and Lemon, 2006; Schatzmann et al., 2007b; Cuayahuitl et al., 2005). The main purpose of those approaches was to collect and examine intention level dialog behavior for automatically learning dialog strategies. In this case, surface and error simulations were neglected or simply accessed normally. Another approach is to simulate both user intention and surface. In this approach, user utterance generation is designed to express a given intention. Chung (2004) tried to use the natural language generation module of (Seneff, 2002) to generate this surface. He used a speech synthesizer to generate user utterances. L´opezC´ozar et., (2003; 2006) collected real huma</context>
</contexts>
<marker>Cuayahuitl, Renals, Lemon, Shimodaira, 2005</marker>
<rawString>Cuayahuitl, H., S. Renals, O. Lemon, and H. Shimodaira. 2005. Human-Computer Dialogue Simulation Using Hidden Markov Models. Automatic Speech Recognition and Understanding, 2005 IEEE Workshop on, pages 100–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Eckert</author>
<author>E Levin</author>
<author>R Pieraccini</author>
</authors>
<title>User modeling for spoken dialogue system evaluation. Automatic Speech Recognition and Understanding,</title>
<date>1997</date>
<booktitle>Proceedings.,</booktitle>
<pages>80--87</pages>
<contexts>
<context position="5696" citStr="Eckert et al., (1997)" startWordPosition="850" endWordPosition="853">ation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divided into three layers: user intention, user surface (utterance) and error simulation. Some studies have focused only on the intention level simulation (Rieser and Lemon, 2006; Schatzmann et al., 2007b; Cuayahuitl et al., 2005). The main purpose of those approaches was to collect and examine intention level dialog behavior for automatically learning dialog strategies.</context>
</contexts>
<marker>Eckert, Levin, Pieraccini, 1997</marker>
<rawString>Eckert, W., E. Levin, and R. Pieraccini. 1997. User modeling for spoken dialogue system evaluation. Automatic Speech Recognition and Understanding, 1997. Proceedings., 1997 IEEE Workshop on, pages 80–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jeong</author>
<author>G Lee</author>
</authors>
<title>Jointly Predicting Dialog Act and Named Entity for Statistical Spoken Language Understanding.</title>
<date>2006</date>
<booktitle>Proceedings of the IEEE/ACL 2006 workshop on spoken language technology (SLT).</booktitle>
<contexts>
<context position="28929" citStr="Jeong and Lee, 2006" startWordPosition="4679" endWordPosition="4682">et n=10) and choose one of them randomly. This utterance is the final result of ASR channel simulator, and is fed into the dialog system. 4 Experiments We proposed a method that user intention, utterance and ASR channel simulation to rapidly assemble a simulation system to evaluate dialog systems. We conducted a case study for the navigation domain Korean spoken dialog system to test our simulation method and examine the dialog behaviors using the simulator. We used 100 dialog examples from real user and dialog system to train user intention and utterance simulator. We used the SLU method of (Jeong and Lee, 2006), and dialog management method of (Kim et al., 2008) to build the dialog system. After trained user simulator, we perform simulation to collect 5000 dialog samples for each WER settings (WER = 0 ˜ 40 %). To verify the user intention and utterance simulation quality, we let two human judges to evaluate 200 randomly chosen dialogs and 1031 utterances from the simulated dialog examples (WER=0%). At first, they evaluate a dialog with three scale (1: Unnatural, 2: Possible, 3: Natural), then evaluate the utterances of a dialog with three scale (1: Unclear, 2: Understandable, 3: Natural). The inter </context>
</contexts>
<marker>Jeong, Lee, 2006</marker>
<rawString>Jeong, M. and G. Lee. 2006. Jointly Predicting Dialog Act and Named Entity for Statistical Spoken Language Understanding. Proceedings of the IEEE/ACL 2006 workshop on spoken language technology (SLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kim</author>
<author>C Lee</author>
<author>S Jung</author>
<author>G Lee</author>
</authors>
<title>A frame-based probabilistic framework for spoken dialog management using dialog examples.</title>
<date>2008</date>
<booktitle>In the 9th sigdial workshop on discourse and dialog (sigdial</booktitle>
<note>To appear.</note>
<contexts>
<context position="28981" citStr="Kim et al., 2008" startWordPosition="4689" endWordPosition="4692">e is the final result of ASR channel simulator, and is fed into the dialog system. 4 Experiments We proposed a method that user intention, utterance and ASR channel simulation to rapidly assemble a simulation system to evaluate dialog systems. We conducted a case study for the navigation domain Korean spoken dialog system to test our simulation method and examine the dialog behaviors using the simulator. We used 100 dialog examples from real user and dialog system to train user intention and utterance simulator. We used the SLU method of (Jeong and Lee, 2006), and dialog management method of (Kim et al., 2008) to build the dialog system. After trained user simulator, we perform simulation to collect 5000 dialog samples for each WER settings (WER = 0 ˜ 40 %). To verify the user intention and utterance simulation quality, we let two human judges to evaluate 200 randomly chosen dialogs and 1031 utterances from the simulated dialog examples (WER=0%). At first, they evaluate a dialog with three scale (1: Unnatural, 2: Possible, 3: Natural), then evaluate the utterances of a dialog with three scale (1: Unclear, 2: Understandable, 3: Natural). The inter evaluator agreement (kappa) is 0.45 and 0.58 for dia</context>
</contexts>
<marker>Kim, Lee, Jung, Lee, 2008</marker>
<rawString>Kim, K., C. Lee, S Jung, and G. Lee. 2008. A frame-based probabilistic framework for spoken dialog management using dialog examples. In the 9th sigdial workshop on discourse and dialog (sigdial 2008), To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Lafferty</author>
<author>A McCallum</author>
<author>F C N Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>Proceedings of the Eighteenth International Conference on Machine Learning table of contents,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="12514" citStr="Lafferty et al., 2001" startWordPosition="1913" endWordPosition="1916">n a sequential structure. Therefore, in intention modeling we must consider how to model this sequential property. Also, we must understand that the user’s intention depends not only on previous n-gram user and system intentions, but also on diverse discourse circumstances, including dialog goal, the number of items, and the number of filled component slots. Sophisticated user intention modeling should be able to reflect the discourse information. To satisfy the sequential property and use rich information for user intention modeling, we used linear-chain Conditional Random Field (CRF) model (Lafferty et al., 2001) for user intention modeling. Let Y, X be random vectors, A = {Ak} E RK be a parameter vector, and {fk(y,y&apos;,xt)}Kk=1 be a set of real-valued feature functions. Then a linear-chain CRF is a distribution of p(y|x) that takes the form K 1 p(y|x) = Z(x) exp { E Akfk(yt, yt−1, xt)} (1) k=1 where Z(x) is an instance-specific normalization function. Akfk(yt, yt−1, xt)} CRF is an undirected graphical model that defines a single log-linear distribution over the joint probability of an entire label sequence given a particular observation sequence. This single distribution removes the perstate normalizat</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J.D., A. McCallum, and F.C.N. Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. Proceedings of the Eighteenth International Conference on Machine Learning table of contents, pages 282– 289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lee</author>
<author>S Kim</author>
<author>G G Lee</author>
</authors>
<title>Grapheme-toPhoneme Conversion Using Automatically Extracted Associative Rules for Korean TTS System. In</title>
<date>2006</date>
<booktitle>Ninth International Conference on Spoken Language Processing. ISCA.</booktitle>
<contexts>
<context position="26731" citStr="Lee et al., 2006" startWordPosition="4308" endWordPosition="4311">, we simply delete the error marked word from the utterance. In the case of insertion error, we select one word from the pronunciation dictionary randomly, and insert it before the error marked word. In the case of substitution error, we use a more complex process to select a substitutable word. To select a substitutable word, we compare the marked error word with the words from pronunciation dictionary which are similar in syllable sequence and phoneme sequence. First, we convert the final word sequence from the user simulator into a phoneme sequence using a Grapheme-to-Phoneme (G2P) module (Lee et al., 2006). Then, we extract a part of the phoneme sequence which is similar to the error marked word from the entire phoneme sequence of the utterance. The reason for extracting a target phoneme sequence corresponding to one word from the entire phoneme sequence is that the G2P results vary between the boundaries of words. Then, we separate the marked word into syllables and compare their syllable-level similarity to other words in the pronunciation dictionary. We calculate a similarity score which interpolates syllable and phoneme level similarity using following equations. Similarity = 0 * Syllable A</context>
</contexts>
<marker>Lee, Kim, Lee, 2006</marker>
<rawString>Lee, J., S. Kim, and G.G. Lee. 2006. Grapheme-toPhoneme Conversion Using Automatically Extracted Associative Rules for Korean TTS System. In Ninth International Conference on Spoken Language Processing. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Liu</author>
<author>J Nocedal</author>
</authors>
<title>On the limited memory BFGS method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical Programming,</booktitle>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="16550" citStr="Liu and Nocedal, 1989" startWordPosition="2583" endWordPosition="2586">rrent position of the user or the user’s favorite restaurant could be very important for generating the user’s intention. This information is dependent on the specific domain and system. We handle these features as ‘OTHER INFO’. We trained the user intention model using dialog examples of human-machine. One training example consists of a sequence of user intentions and discourse information features in a given dialog. We collected training examples and trained the intention model using a typical CRF training method, a limited-memory quasiNewton code for unconstrained optimization (L-BFGS) of (Liu and Nocedal, 1989). To generate user intentions given specific discourse circumstances, we calculate the probability of a sequence of user intentions from the beginning of the dialog to the corresponding turn. For example, suppose that we need to generate user intention at the third turn (UI3) (Fig. 2). We have previously simulated user intentions UI1 and UI2 using DI1 and DI2. In this case, we calculate the probability of UI1 → UI2 → UI3 given DI1, DI2 and DI3. Notice that DI3 contains discourse information at the third turn: it includes previous system intention, attributes and other useful information. Using</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Liu, D.C. and J. Nocedal. 1989. On the limited memory BFGS method for large scale optimization. Mathematical Programming, 45(1):503–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L´opez-C´ozar</author>
<author>A De la Torre</author>
<author>JC Segura</author>
<author>AJ Rubio</author>
</authors>
<title>Assessment of dialogue systems by means of a new simulation technique.</title>
<date>2003</date>
<journal>Speech Communication,</journal>
<volume>40</volume>
<issue>3</issue>
<marker>L´opez-C´ozar, Torre, Segura, Rubio, 2003</marker>
<rawString>L´opez-C´ozar, R., A. De la Torre, JC Segura, and AJ Rubio. 2003. Assessment of dialogue systems by means of a new simulation technique. Speech Communication, 40(3):387–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ram´on L´opez-C´ozar</author>
<author>Zoraida Callejas</author>
<author>Michael Mctear</author>
</authors>
<title>Testing the performance of spoken dialogue systems by means of an artificially simulated user.</title>
<date>2006</date>
<journal>Artif. Intell. Rev.,</journal>
<volume>26</volume>
<issue>4</issue>
<marker>L´opez-C´ozar, Callejas, Mctear, 2006</marker>
<rawString>L´opez-C´ozar, Ram´on, Zoraida Callejas, and Michael Mctear. 2006. Testing the performance of spoken dialogue systems by means of an artificially simulated user. Artif. Intell. Rev., 26(4):291–323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SB Needleman</author>
<author>CD Wunsch</author>
</authors>
<title>A general method applicable to the search for similarities in the amino acid sequence of two proteins.</title>
<date>1970</date>
<journal>J Mol Biol,</journal>
<volume>48</volume>
<issue>3</issue>
<contexts>
<context position="27457" citStr="Needleman and Wunsch, 1970" startWordPosition="4424" endWordPosition="4427">e entire phoneme sequence of the utterance. The reason for extracting a target phoneme sequence corresponding to one word from the entire phoneme sequence is that the G2P results vary between the boundaries of words. Then, we separate the marked word into syllables and compare their syllable-level similarity to other words in the pronunciation dictionary. We calculate a similarity score which interpolates syllable and phoneme level similarity using following equations. Similarity = 0 * Syllable Alignment Score +(1 − 0) * Phone Alignment Score We used the dynamic global alignment algorithm of (Needleman and Wunsch, 1970) for both syllable and phoneme sequence alignment. This alignment algorithm requires a weight matrix. As a weight matrix, we used a vowel confusion matrix which is based on the manner of articulation. We consider the position (back/front, high/mid/low) of the tongue and the shape (round/flat) of the lips. We select candidate words which have higher similarity than an arbitrary threshold 0 and replace the error marked word with a random word from this set. We repeat steps 1 to 3 many times (usually 100) to collect error added utterances. In the fourth step, we rescore the error added uttersi-ch</context>
</contexts>
<marker>Needleman, Wunsch, 1970</marker>
<rawString>Needleman, SB and CD Wunsch. 1970. A general method applicable to the search for similarities in the amino acid sequence of two proteins. J Mol Biol, 48(3):443–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>WJ Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of MT.</title>
<date>2001</date>
<journal>Research Report, Computer Science RC22176 (W0109-022), IBM Research Division, TJ Watson Research Center,</journal>
<volume>17</volume>
<contexts>
<context position="22867" citStr="Papineni et al., 2001" startWordPosition="3676" endWordPosition="3679">he structure tags are generated, the emission probability PSV (Wt|St)(w = 1, ... , T) is used to generate the word sequence given the tag sequence. We iterate the process of generating structures and word sequences sufficient times to generate many different structure tags and word sequences which may occur in real human expressions. Selecting natural utterances from the generated utterances requires an automatic evaluation metric. 3.3.2 Second Phase - Selection by the BLEU measure To measure the naturalness of the generated utterances, we use the BLEU (Bilingual Evaluation Understudy) score (Papineni et al., 2001) which is widely used for automatic evaluation in Statistical Machine Translation (SMT). In SMT, translated candidate sentences are evaluated by comparing semantically equivalent reference sentences which have been translated by a human. Evaluation of the user utterance generation shares the same task of evaluation in SMT. We can evaluate the naturalness of generated utterances by comparing semantically equivalent reference utterances collected by humans. Therefore, the BLEU score can be adopted successfully to measure the naturalness of the utterances. The BLEU score is the geometric mean of </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Papineni, K., S. Roukos, T. Ward, and WJ Zhu. 2001. BLEU: a method for automatic evaluation of MT. Research Report, Computer Science RC22176 (W0109-022), IBM Research Division, TJ Watson Research Center, 17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rieser</author>
<author>O Lemon</author>
</authors>
<title>Cluster-Based User Simulations for Learning Dialogue Strategies.</title>
<date>2006</date>
<booktitle>In Ninth International Conference on Spoken Language Processing. ISCA.</booktitle>
<contexts>
<context position="5547" citStr="Rieser and Lemon, 2006" startWordPosition="825" endWordPosition="828"> suggest directions for future work in Section 5. 2 Related Works Dialog simulation techniques can be classified according to the purpose of the simulation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divided into three layers: user intention, user surface (utterance) and error simulation. Some studies have focused only on the intention level simulation (Rieser and Lemon, 2006; Schatzmann et al., 2007b; Cuayahuitl et al.,</context>
</contexts>
<marker>Rieser, Lemon, 2006</marker>
<rawString>Rieser, V. and O. Lemon. 2006. Cluster-Based User Simulations for Learning Dialogue Strategies. In Ninth International Conference on Spoken Language Processing. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schatzmann</author>
<author>K Georgila</author>
<author>S Young</author>
</authors>
<title>Quantitative Evaluation of User Simulation Techniques for Spoken Dialogue Systems.</title>
<date>2005</date>
<booktitle>In 6th SIGdial Workshop on Discourse and Dialogue. ISCA.</booktitle>
<contexts>
<context position="5327" citStr="Schatzmann et al., 2005" startWordPosition="794" endWordPosition="798">re and the detailed methods of intention, utterance and ASR channel simulation in Section 3. Experiments to test the simulation techniques, and a case study are described in Section 4. We conclude with a brief summary and suggest directions for future work in Section 5. 2 Related Works Dialog simulation techniques can be classified according to the purpose of the simulation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divi</context>
</contexts>
<marker>Schatzmann, Georgila, Young, 2005</marker>
<rawString>Schatzmann, J., K. Georgila, and S. Young. 2005. Quantitative Evaluation of User Simulation Techniques for Spoken Dialogue Systems. In 6th SIGdial Workshop on Discourse and Dialogue. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schatzmann</author>
<author>B Thomson</author>
<author>S Young</author>
</authors>
<title>Error simulation for training statistical dialogue systems. Automatic Speech Recognition &amp; Understanding,</title>
<date>2007</date>
<booktitle>ASRU. IEEE Workshop on,</booktitle>
<pages>526--531</pages>
<contexts>
<context position="5352" citStr="Schatzmann et al., 2007" startWordPosition="799" endWordPosition="802">ds of intention, utterance and ASR channel simulation in Section 3. Experiments to test the simulation techniques, and a case study are described in Section 4. We conclude with a brief summary and suggest directions for future work in Section 5. 2 Related Works Dialog simulation techniques can be classified according to the purpose of the simulation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divided into three layers: us</context>
<context position="7436" citStr="Schatzmann et al., (2007" startWordPosition="1120" endWordPosition="1123">input for the spoken dialog system. Both Chung (2004) and L´opez-C´ozar et., (2003; 2006) used rule based intention simulation. They used real ASR to recognize the synthesized or played voice; hence, ASR channel simulation is not needed in their techniques. Schefier and Young (2000; 2001) used the lattices which are derived from the grammars used by the recognition engine, but generated user utterances by associating the lattice edges with intentions. During utterance generation, they simulated errors in recognition and understanding by probabilistic substitution on the selection of the edge. Schatzmann et al., (2007a; 2007b) proposed a statistical model for user utterance generation and error simulation using agenda based intention simulation. The existing rule-based techniques for simulating intentions or surfaces are not appropriate in the sense of portability criteria. In addition, specific dialog managing techniques based user simulators (e.g., (Torres et al., 2008)) are not desirable because it is not easy to implement these techniques for other developers. Another important criterion for evaluating dialog simulation techniques for use in evaluating spoken dialog systems is the range of simulation l</context>
</contexts>
<marker>Schatzmann, Thomson, Young, 2007</marker>
<rawString>Schatzmann, J., B. Thomson, and S. Young. 2007a. Error simulation for training statistical dialogue systems. Automatic Speech Recognition &amp; Understanding, 2007. ASRU. IEEE Workshop on, pages 526– 531.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schatzmann</author>
<author>B Thomson</author>
<author>S Young</author>
</authors>
<title>Statistical User Simulation with a Hidden Agenda.</title>
<date>2007</date>
<booktitle>Proc. SIGDial,</booktitle>
<location>Antwerp, Belgium.</location>
<contexts>
<context position="5352" citStr="Schatzmann et al., 2007" startWordPosition="799" endWordPosition="802">ds of intention, utterance and ASR channel simulation in Section 3. Experiments to test the simulation techniques, and a case study are described in Section 4. We conclude with a brief summary and suggest directions for future work in Section 5. 2 Related Works Dialog simulation techniques can be classified according to the purpose of the simulation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divided into three layers: us</context>
<context position="7436" citStr="Schatzmann et al., (2007" startWordPosition="1120" endWordPosition="1123">input for the spoken dialog system. Both Chung (2004) and L´opez-C´ozar et., (2003; 2006) used rule based intention simulation. They used real ASR to recognize the synthesized or played voice; hence, ASR channel simulation is not needed in their techniques. Schefier and Young (2000; 2001) used the lattices which are derived from the grammars used by the recognition engine, but generated user utterances by associating the lattice edges with intentions. During utterance generation, they simulated errors in recognition and understanding by probabilistic substitution on the selection of the edge. Schatzmann et al., (2007a; 2007b) proposed a statistical model for user utterance generation and error simulation using agenda based intention simulation. The existing rule-based techniques for simulating intentions or surfaces are not appropriate in the sense of portability criteria. In addition, specific dialog managing techniques based user simulators (e.g., (Torres et al., 2008)) are not desirable because it is not easy to implement these techniques for other developers. Another important criterion for evaluating dialog simulation techniques for use in evaluating spoken dialog systems is the range of simulation l</context>
</contexts>
<marker>Schatzmann, Thomson, Young, 2007</marker>
<rawString>Schatzmann, J., B. Thomson, and S. Young. 2007b. Statistical User Simulation with a Hidden Agenda. Proc. SIGDial, Antwerp, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Scheffler</author>
<author>S Young</author>
</authors>
<title>Probabilistic simulation of human-machine dialogues.</title>
<date>2000</date>
<booktitle>Proc. ofICASSP,</booktitle>
<pages>2--1217</pages>
<marker>Scheffler, Young, 2000</marker>
<rawString>Scheffler, K. and S. Young. 2000. Probabilistic simulation of human-machine dialogues. Proc. ofICASSP, 2:1217–1220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Scheffler</author>
<author>S Young</author>
</authors>
<title>Corpus-based dialogue simulation for automatic strategy learning and evaluation.</title>
<date>2001</date>
<booktitle>Proc. NAACL Workshop on Adaptation in Dialogue Systems,</booktitle>
<pages>64--70</pages>
<marker>Scheffler, Young, 2001</marker>
<rawString>Scheffler, K. and S. Young. 2001. Corpus-based dialogue simulation for automatic strategy learning and evaluation. Proc. NAACL Workshop on Adaptation in Dialogue Systems, pages 64–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Seneff</author>
</authors>
<title>Response planning and generation in the Mercury flight reservation system.</title>
<date>2002</date>
<journal>Computer Speech and Language,</journal>
<volume>16</volume>
<issue>3</issue>
<contexts>
<context position="6618" citStr="Seneff, 2002" startWordPosition="992" endWordPosition="993">lation. Some studies have focused only on the intention level simulation (Rieser and Lemon, 2006; Schatzmann et al., 2007b; Cuayahuitl et al., 2005). The main purpose of those approaches was to collect and examine intention level dialog behavior for automatically learning dialog strategies. In this case, surface and error simulations were neglected or simply accessed normally. Another approach is to simulate both user intention and surface. In this approach, user utterance generation is designed to express a given intention. Chung (2004) tried to use the natural language generation module of (Seneff, 2002) to generate this surface. He used a speech synthesizer to generate user utterances. L´opezC´ozar et., (2003; 2006) collected real human utterances, and selected and played the voice to provide input for the spoken dialog system. Both Chung (2004) and L´opez-C´ozar et., (2003; 2006) used rule based intention simulation. They used real ASR to recognize the synthesized or played voice; hence, ASR channel simulation is not needed in their techniques. Schefier and Young (2000; 2001) used the lattices which are derived from the grammars used by the recognition engine, but generated user utterances </context>
</contexts>
<marker>Seneff, 2002</marker>
<rawString>Seneff, S. 2002. Response planning and generation in the Mercury flight reservation system. Computer Speech and Language, 16(3):283–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco Torres</author>
<author>Emilio Sanchis</author>
<author>Encarna Segarra</author>
</authors>
<title>User simulation in a stochastic dialog system.</title>
<date>2008</date>
<journal>Comput. Speech Lang.,</journal>
<volume>22</volume>
<issue>3</issue>
<contexts>
<context position="5569" citStr="Torres et al., 2008" startWordPosition="829" endWordPosition="832">future work in Section 5. 2 Related Works Dialog simulation techniques can be classified according to the purpose of the simulation. One of the purposes is to support the refinement of dialog strategies. Some techniques use large amounts of simulated data for a systematic exploration of the dialog state space in the framework of reinforcement learning (Schatzmann et al., 2005; Schatzmann et al., 2007a). Other techniques use simulation techniques to investigate and improve the target dialog strategies by examining the results heuristically or automatically (Chung, 2004; Rieser and Lemon, 2006; Torres et al., 2008). A second purpose of dialog simulation techniques is to evaluate the dialog system itself qualitatively. Eckert et al., (1997) and L´opez-C´ozar et., (2003; 2006) used a dialog simulation to evaluate whole dialog systems. Dialog simulation techniques can also be classified according to the layers of the simulation. Typically, dialog simulation can be divided into three layers: user intention, user surface (utterance) and error simulation. Some studies have focused only on the intention level simulation (Rieser and Lemon, 2006; Schatzmann et al., 2007b; Cuayahuitl et al., 2005). The main purpo</context>
<context position="7797" citStr="Torres et al., 2008" startWordPosition="1171" endWordPosition="1174">on engine, but generated user utterances by associating the lattice edges with intentions. During utterance generation, they simulated errors in recognition and understanding by probabilistic substitution on the selection of the edge. Schatzmann et al., (2007a; 2007b) proposed a statistical model for user utterance generation and error simulation using agenda based intention simulation. The existing rule-based techniques for simulating intentions or surfaces are not appropriate in the sense of portability criteria. In addition, specific dialog managing techniques based user simulators (e.g., (Torres et al., 2008)) are not desirable because it is not easy to implement these techniques for other developers. Another important criterion for evaluating dialog simulation techniques for use in evaluating spoken dialog systems is the range of simulation layers. Simulations that are restricted to only the intention level are not sufficient to evaluate the whole dialog system. Domain and language independent techniques for simulating both intentions and utterances are needed, and ASR channel simulation is desirable for evaluating the spoken dialog systems accurately because human-machine dialog is heavily iniue</context>
</contexts>
<marker>Torres, Sanchis, Segarra, 2008</marker>
<rawString>Torres, Francisco, Emilio Sanchis, and Encarna Segarra. 2008. User simulation in a stochastic dialog system. Comput. Speech Lang., 22(3):230–255.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>