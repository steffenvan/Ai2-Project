<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998269">
A Joint Graph Model for Pinyin-to-Chinese Conversion
with Typo Correction*
</title>
<author confidence="0.996909">
Zhongye Jia and Hai Zhao†
</author>
<affiliation confidence="0.998635666666667">
MOE-Microsoft Key Laboratory for Intelligent Computing and Intelligent Systems,
Center for Brain-Like Computing and Machine Intelligence
Department of Computer Science and Engineering, Shanghai Jiao Tong University
</affiliation>
<address confidence="0.982405">
800 Dongchuan Road, Shanghai 200240, China
</address>
<email confidence="0.998886">
jia.zhongye@gmail.com, zhaohai@cs.sjtu.edu.cn
</email>
<sectionHeader confidence="0.980093" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999940928571429">
It is very import for Chinese language pro-
cessing with the aid of an efficient input
method engine (IME), of which pinyin-
to-Chinese (PTC) conversion is the core
part. Meanwhile, though typos are in-
evitable during user pinyin inputting, ex-
isting IMEs paid little attention to such big
inconvenience. In this paper, motivated by
a key equivalence of two decoding algo-
rithms, we propose a joint graph model to
globally optimize PTC and typo correction
for IME. The evaluation results show that
the proposed method outperforms both ex-
isting academic and commercial IMEs.
</bodyText>
<sectionHeader confidence="0.998457" genericHeader="keywords">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.993186">
1.1 Chinese Input Method
</subsectionHeader>
<bodyText confidence="0.999938083333333">
The daily life of Chinese people heavily depends
on Chinese input method engine (IME), no matter
whether one is composing an E-mail, writing an
article, or sending a text message. However, ev-
ery Chinese word inputted into computer or cell-
phone cannot be typed through one-to-one map-
ping of key-to-letter inputting directly, but has to
go through an IME as there are thousands of Chi-
nese characters for inputting while only 26 letter
keys are available in the keyboard. An IME is
an essential software interface that maps Chinese
characters into English letter combinations. An ef-
</bodyText>
<footnote confidence="0.858095">
*This work was partially supported by the National Natu-
ral Science Foundation of China (Grant No.60903119, Grant
No.61170114, and Grant No.61272248), the National Ba-
sic Research Program of China (Grant No.2013CB329401),
the Science and Technology Commission of Shanghai Mu-
nicipality (Grant No.13511500200), and the European Union
Seventh Framework Program (Grant No.247619).
†Corresponding author
</footnote>
<bodyText confidence="0.999694">
ficient IME will largely improve the user experi-
ence of Chinese information processing.
Nowadays most of Chinese IMEs are pinyin
based. Pinyin is originally designed as the pho-
netic symbol of a Chinese character (based on the
standard modern Chinese, mandarin) , using Latin
letters as its syllable notation. For example, the
pinyin of the Chinese character “爱”(love) is “ài”.
Most characters usually have unique pinyin rep-
resentations, while a few Chinese characters may
be pronounced in several different ways, so they
may have multiple pinyin representations. The ad-
vantage of pinyin IME is that it only adopts the
pronunciation perspective of Chinese characters
so that it is simple and easy to learn. But there
are only less than 500 pinyin syllables in stan-
dard modern Chinese, compared with over 6,000
commonly used Chinese characters, which leads
to serious ambiguities for pinyin-to-character map-
ping. Modern pinyin IMEs mostly use a “sentence-
based” decoding technique (Chen and Lee, 2000)
to alleviate the ambiguities. “Sentence based”
means that IME generates a sequence of Chinese
characters upon a sequence of pinyin inputs with
respect to certain statistical criteria.
</bodyText>
<subsectionHeader confidence="0.954589">
1.2 Typos and Chinese Spell Checking
</subsectionHeader>
<bodyText confidence="0.999850363636364">
Written in Chinese characters but not alphabets,
spell checking for Chinese language is quite dif-
ferent from the same task for other languages.
Since Chinese characters are entered via IME,
those user-made typos do not immediately lead to
spelling errors. When a user types a wrong letter,
IME will be very likely to fail to generate the ex-
pected Chinese character sequence. Normally, the
user may immediately notice the inputting error
and then make corrections, which usually means
doing a bunch of extra operations like cursor
</bodyText>
<page confidence="0.952675">
1512
</page>
<note confidence="0.8301675">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1512–1523,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999566606060606">
movement, deletion and re-typing. Thus there are
two separated sub-tasks for Chinese spell check-
ing: 1. typo checking for user typed pinyin se-
quences which should be a built-in module in
IME, and 2. spell checking for Chinese texts in
its narrow sense, which is typically a module of
word processing applications (Yang et al., 2012b).
These two terms are often confused especially in
IME related works such as (Chen and Lee, 2000)
and (Wu et al., 2009).
Pinyin typos have always been a serious prob-
lem for Chinese pinyin IMEs. The user may fail
to input the completely right pinyin simply be-
cause he/she is a dialect speaker and does not know
the exact pronunciation for the expected character.
This may be a very common situation since there
are about seven quite different dialects in Chinese,
among which being spoken languages, six are far
different from the standard modern Chinese, man-
darin. With the boom of smart-phones, pinyin ty-
pos worsen due to the limited size of soft key-
board, and the lack of physical feedback on the
touch screen. However, existing practical IMEs
only provide small patches to deal with typos such
as Fuzzy Pinyin (Wu and Chen, 2004) and other
language specific errors (Zheng et al., 2011b).
Typo checking and correction has an important
impact on IME performance. When IME fails to
correct a typo and generate the expected sentence,
the user will have to take much extra effort to move
the cursor back to the mistyped letter and correct it,
which leads to very poor user experience (Jia and
Zhao, 2013).
</bodyText>
<sectionHeader confidence="0.997113" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.999942315789473">
The very first approach for Chinese input with
typo correction was made by (Chen and Lee,
2000), which was also the initial attempt of
“sentence-based” IME. The idea of “statistical in-
put method” was proposed by modeling PTC con-
version as a hidden Markov model (HMM), and
using Viterbi (Viterbi, 1967) algorithm to decode
the sequence. They solved the typo correction
problem by decomposing the conditional proba-
bility P(HIP) of Chinese character sequence H
given pinyin sequence P into a language model
P(wi|wi_1) and a typing model P(pi|wi). The
typing model that was estimated on real user input
data was for typo correction. However, real user
input data can be very noisy and not very conve-
nient to obtain. As we will propose a joint model
in this paper, such an individual typing model is
not necessarily built in our approach.
(Zheng et al., 2011a) developed an IME sys-
tem with typo correction called CHIME using
noisy channel error model and language-specific
features. However their model depended on a
very strong assumption that input pinyin sequence
should have been segmented into pinyin words by
the user. This assumption does not really hold in
modern “sentence-based” IMEs. We release this
assumption since our model solves segmentation,
typo correction and PTC conversion jointly.
Besides the common HMM approach for PTC
conversion, there are also various methods such as:
support vector machine (Jiang et al., 2007), max-
imum entropy (ME) model (Wang et al., 2006),
conditional random field (CRF) (Li et al., 2009)
and statistical machine translation (SMT) (Yang et
al., 2012a; Wang et al., 2013c; Zhang and Zhao,
2013), etc.
Spell checking or typo checking was first pro-
posed for English (Peterson, 1980). (Mays et al.,
1991) addressed that spell checking should be done
within a context, i.e., a sentence or a long phrase
with a certain meaning, instead of only in one
word. A recent spell correction work is (Li et al.,
2006), where a distributional similarity was intro-
duced for spell correction of web queries.
Early attempts for Chinese spelling checking
could date back to (Chang, 1994) where charac-
ter tables for similar shape, pronunciation, mean-
ing, and input-method-code characters were pro-
posed. More recently, the 7th SIGHAN Workshop
on Chinese Language Processing (Yu et al., 2013)
held a shared task on Chinese spell checking. Var-
ious approaches were made for the task includ-
ing language model (LM) based methods (Chen
et al., 2013), ME model (Han and Chang, 2013),
CRF (Wang et al., 2013d; Wang et al., 2013a),
SMT (Chiu et al., 2013; Liu et al., 2013), and graph
model (Jia et al., 2013), etc.
</bodyText>
<sectionHeader confidence="0.997225" genericHeader="method">
3 Pinyin Input Method Model
</sectionHeader>
<subsectionHeader confidence="0.999805">
3.1 From English Letter to Chinese Sentence
</subsectionHeader>
<bodyText confidence="0.999972857142857">
It is a rather long journey from the first English
letter typed on the keyboard to finally a completed
Chinese sentence generated by IME. We will first
take an overview of the entire process.
The average length of pinyin syllables is about 3
letters. There are about 410 pinyin syllables used
in the current pinyin system. Each pinyin sylla-
</bodyText>
<page confidence="0.975649">
1513
</page>
<bodyText confidence="0.999968578947368">
ble has a bunch of corresponding Chinese char-
acters which share the same pronunciation repre-
sented by the syllable. The number of those homo-
phones ranges from 1 to over 300. Chinese char-
acters then form words. But word in Chinese is
a rather vague concept. Without word delimiters,
linguists have argued on what a Chinese word re-
ally is for a long time and that is why there is al-
ways a primary word segmentation treatment in
most Chinese language processing tasks (Zhao et
al., 2006; Huang and Zhao, 2007; Zhao and Kit,
2008; Zhao et al., 2010; Zhao and Kit, 2011; Zhao
et al., 2013). A Chinese word may contain from
1 to over 10 characters due to different word seg-
mentation conventions. Figure 1 demonstrates the
relationship of pinyin and word, from pinyin letters
“nihao” to the word “你好 (hello)”. Typically, an
IME takes the pinyin input, segments it into sylla-
bles, looks up corresponding words in a dictionary
and generates a sentence with the candidate words.
ble segmentation by using rules. But as the pinyin
input is not segmented, it is nearly impossible to
adopt previous spell checking methods for English
to pinyin typo checking, although techniques for
English spell checking have been well developed.
A bit confusing but interesting, pinyin typo cor-
rection and segmentation come as two sides of one
problem: when a pinyin sequence is mistyped, it
is unlikely to be correctly segmented; when it is
segmented in an awkward way, it is likely to be
mistyped.
Inspired by (Yang et al., 2012b) and (Jia et al.,
2013), we adopt the graph model for Chinese spell
checking for pinyin segmentation and typo correc-
tion, which is based on the shortest path word seg-
mentation algorithm (Casey and Lecolinet, 1996).
The model has two major steps: segmentation and
correction.
</bodyText>
<subsubsectionHeader confidence="0.702007">
3.2.1 Pinyin Segmentation
</subsubsectionHeader>
<bodyText confidence="0.992392">
The shortest path segmentation algorithm is based
on the idea that a reasonable segmentation should
minimize the number of segmented units. For a
pinyin sequence p1pe ... pL, where pi is a letter,
first a directed acyclic graph (DAG) GS = (V, E)
is built for pinyin segmentation step. The vertex
set V consists of the following parts:
</bodyText>
<listItem confidence="0.9981555">
• Virtual start vertex S0 and end vertex SE;
• Possible legal syllables fetched from dictio-
nary Dp according to the input pinyin se-
quence:
</listItem>
<figure confidence="0.992036416666667">
n i h
ni hao
nihao
tid
a o
tido
Pinyin syllables
o Chinese characters
Pinyin characters
Chinese word
Pinyin word
{Si,j|Si,j = pi ... pj E Dp};
</figure>
<figureCaption confidence="0.999953">
Figure 1: Relationship of pinyin and words
</figureCaption>
<subsectionHeader confidence="0.99471">
3.2 Pinyin Segmentation and Typo
Correction
</subsectionHeader>
<bodyText confidence="0.9429331875">
Non-Chinese users may feel confused or even
surprised if they know that when typing pinyin
through an IME, Chinese IME users will never en-
ter delimiters such as “Space” key to segment ei-
ther pinyin syllables or pinyin words, but just in-
put the entire un-segmented pinyin sequence. For
example, if one wants to input “你好世界 (Hello
world)”, he will just type “nihaoshijie” instead of
segmented pinyin sequence “ni hao shi jie”. Nev-
ertheless, pinyin syllable segmentation is a much
easier problem compared to Chinese word seg-
mentation. Since pinyin syllables have a very lim-
ited vocabulary and follow a set of regularities
strictly, it is convenient to perform pinyin sylla-
• The letter itself as a fallback no matter if it is
a legal pinyin syllable or not:
</bodyText>
<equation confidence="0.907123">
{Si|Si = pi}.
</equation>
<bodyText confidence="0.9800715">
The vertex weights wS are all set to 0. The edges
are from a syllable to all syllables next to it:
</bodyText>
<equation confidence="0.998328">
E = {E(Si,j — Sj+1,k)|Si,j, Sj+1,k E V}.
</equation>
<bodyText confidence="0.9999485">
The edge weight the negative logarithm of con-
ditional probability P(Sj+1,k|Si,j) that a syllable
Si,j is followed by Sj+1,k, which is give by a bi-
gram language model of pinyin syllables:
</bodyText>
<equation confidence="0.994296">
WE(Si,j—Sj+1,k) = —logP(Sj+1,k|Si,j)
</equation>
<bodyText confidence="0.854937">
The shortest path P* on the graph is the path P
with the least sum of weights:
</bodyText>
<equation confidence="0.991562">
∑ ∑
P* = arg min wv + WE.
(v,E)EGn(v,E)EP v E
</equation>
<page confidence="0.916729">
1514
</page>
<bodyText confidence="0.999515692307692">
Computing the shortest path from S0 to SE on
GS yields the best segmentation. This is the sin-
gle source shortest path (SSSP) problem on DAG
which has an efficient algorithm by preprocessing
the DAG with topology sort, then traversing ver-
tices and edges in topological order. It has the time
complexity of O(|V |+ |E|). For example, one in-
tends to input “你好世界 (Hello world)” by typ-
ing “nihaoshijie”, but mistyped as “mihaoshijiw”.
The graph for this input is shown in Figure 2. The
shortest path, i.e., the best segmentation is “mi hao
shi ji w”. We will continue to use this example in
the rest of this paper.
</bodyText>
<figureCaption confidence="0.800224">
Figure 2: Graph model for pinyin segmentation
</figureCaption>
<subsectionHeader confidence="0.528309">
3.2.2 Pinyin Typo Correction
</subsectionHeader>
<bodyText confidence="0.99832175">
Next in the correction step, for the segmented
pinyin sequence S1, S2, ... , SM, a graph Gc is
constructed to perform typo correction. The ver-
tex set V consists of the following parts:
</bodyText>
<listItem confidence="0.9974005">
• Virtual start vertex S′0 and end vertex S′E with
vertex weights of 0;
• All possible syllables similar to original syl-
lable in Gs. If the adjacent syllables can be
merged into a legal syllable, the merged syl-
lable is also added into V:
</listItem>
<equation confidence="0.99835">
{S′i,j|S′i,j = S′i ... S′j E Dp,
S′k — Sk, k = i &lt; jJ,
</equation>
<bodyText confidence="0.999652166666667">
where the similarity — is measured in Lev-
enshtein distance (Levenshtein, 1966). Sylla-
bles with Levenshtein distance under a certain
threshold are considered as similar:
Similar to Gs, the edges are from one syllable to all
syllables next to it and edge weights are the condi-
tional probabilities between them. Computing the
shortest path from S′0 to S′E on Gc yields the best
typo correction result. In addition, the result has
been segmented so far. Considering our running
example, the graph Gc is shown in Figure 3, and
the typo correction result is “mi hao shi jie”.
</bodyText>
<figureCaption confidence="0.951966">
Figure 3: Graph model for pinyin typo correction
</figureCaption>
<bodyText confidence="0.999943352941177">
Merely using the above model, the typo cor-
rection result is not satisfying yet, no matter how
much effort is paid. The major reason is that the
basic semantic unit of Chinese language is actu-
ally word (tough vaguely defined) which is usu-
ally composed of several characters. Thus the con-
ditional probability between characters does not
make much sense. In addition, a pinyin syllable
usually maps to dozens or even hundreds of cor-
responding homophonic characters, which makes
the conditional probability between syllables much
more noisy. However, using pinyin words instead
of syllables is not a wise choice because pinyin
word segmentation is not so easy a task as syllable
segmentation. To make typo correction better, we
consider to integrate it with PTC conversion using
a joint model.
</bodyText>
<subsectionHeader confidence="0.9926055">
3.3 Hidden Markov Model for
Pinyin-to-Chinese Conversion
</subsectionHeader>
<bodyText confidence="0.9993596">
PTC conversion has long been viewed as a decod-
ing problem using HMM. We continue to follow
this formalization. The best Chinese character se-
quence W∗ for a given pinyin syllable sequence S
is the one with the highest conditional probability
</bodyText>
<figure confidence="0.989738081632653">
P(W |S) that
m
mi
i
h a
ha
hao
ao
o s
shi
h i j i
ji
w
...
...
...
ti
ni
pao
...
zhi
shuai
ju
e
a
mi hao shi
ji
w
ma
huo
shu
jie
...
hai
sai
jia
... ...
...
L(Si, Sj) &lt; T H Si — Sj. W∗ = arg max P(W |S)
W
P(W)P(S|W)
= arg max
W
The vertex weight is the Levenshtein distance P(S)
multiply by a normalization parameter:
= arg max P(W)P(S|W)
W
wS′i,; = Q ∑ j L(S′k, Sk). = arg max ∏ ∏P(wi|wi−1) P(si|wi)
k−i w1,ww,...,wM wi wi
</figure>
<page confidence="0.961398">
1515
</page>
<bodyText confidence="0.999682259259259">
In the HMM for pinyin IME, observation states are
pinyin syllables, hidden states are Chinese words,
emission probability is P(si|wi), and transition
probability is P(wi|wi−1). Note the transition
probability is the conditional probability between
words instead of characters. PTC conversion is to
decode the Chinese word sequence from the pinyin
sequence. The Viterbi algorithm (Viterbi, 1967) is
used for the decoding.
The shortest path algorithm for typo correction
and Viterbi algorithm for PTC conversion are very
closely related. It has been strictly proven by (For-
ney, 1973) that the sequence decoding problem on
HMM is formally identical to finding a shortest
path on a certain graph, which can be constructed
in the following manner.
Consider a first order HMM with all possi-
ble observations ® = {o1, o2, ... , oM}, hidden
states S = {s1, s2,... , sN}, a special start state
s0, emission probabilities (Esi,ok) = P(ok|si),
transition probabilities (Tsi,sj) = P(sj|si), and
start probabilities (Ssi) = P(si|s0). For an
observation sequence of T time periods Y =
{y1,y2,...,yT|yt ∈ ®,t = 1,...,T}, the de-
coding problem is to find the best corresponding
hidden state sequence X∗ with the highest proba-
bility, i.e.,
</bodyText>
<equation confidence="0.965215">
Ext,ytTxt−1,xt. (1)
</equation>
<bodyText confidence="0.9990565">
Then we will construct a DAG G = (V, E) upon
the HMM. The vertex set V includes:
</bodyText>
<listItem confidence="0.922505888888889">
• Virtual start vertex v0 and end vertex vE with
vertex weight of 0;
• Normal vertices vxt, where t = 1, ... , T, and
∀xt ∈ S. The vertex weight is the negative
logarithm of emission probability:
wvxt = − log Ext,yt.
The edge set E includes:
• Edges from the start vertex E(v0 → vx1) with
edge weight
</listItem>
<equation confidence="0.59163">
WE(v0→vx1) = −log Sx1,
</equation>
<bodyText confidence="0.80815">
where ∀x1 ∈ S;
</bodyText>
<listItem confidence="0.9620035">
• Edges to the end vertex E(vxT → vE) with
vertex weights of 0;
• Edges between adjacent time periods
E(vxt−1 → vxt) with edge weight
</listItem>
<equation confidence="0.996137">
WE(vxt−1→vxt) = −logTxt−1,xt,
</equation>
<bodyText confidence="0.998942666666667">
where t = 2, ... , T, and ∀xt, xt−1 ∈ S.
The shortest path P∗ from v0 to vE is the one with
the least sum of vertex and edge weights, i.e.,
</bodyText>
<equation confidence="0.99957675">
(wvxt + WE(vxt−1→vxt))
{− log Sx1 − log Ex1,y1
(− log Ext,yt − log Txt−1,xt)}
Ext,ytTxt−1,xt. (2)
</equation>
<bodyText confidence="0.999802">
The optimization goal of P∗ in Equation (2) is
identical to that of X∗ in Equation (1).
</bodyText>
<subsectionHeader confidence="0.98107">
3.4 Joint Graph Model For Pinyin IME
</subsectionHeader>
<bodyText confidence="0.999864444444444">
Given HMM decoding problem is identical to
SSSP problem on DAG, we propose a joint graph
model for PTC conversion with typo correction.
The joint graph model aims to find the global op-
timal for both PTC conversion and typo correction
on the entire input pinyin sequence. The graph
G = (V, E) is constructed based on graph Gc for
typo correction in Section 3.2. The vertex set V
consists of the following parts:
</bodyText>
<listItem confidence="0.993511857142857">
• Virtual start vertex V0 and end vertex VE with
vertex weight of 0;
• Adjacent pinyin syllables in Gc are merged
into pinyin words. Corresponding Chinese
words are fetched from a PTC dictionary Dc,
which is a dictionary maps pinyin words to
Chinese words, and added as vertices:
</listItem>
<equation confidence="0.380483">
{Vi,j|∀Vi,j ∈ Dc[S′i ... S′j], i ≤ j};
</equation>
<bodyText confidence="0.999658333333333">
The vertex weight consists of two parts: 1.
the vertex weights of syllables in Gc, and 2.
the emission probability:
</bodyText>
<equation confidence="0.998051555555556">
X∗ = arg max Sx1Ex1,y1 T
x1,xt∈S ∏
t=2
P∗ = arg min
vxt∈V
∑T
t=1
= arg min
vx1,vxt∈V
∑T
+
t=2
= arg max Sx1Ex1,y1 T
vx1,vxt∈V ∏
t=2
wVi,j =β ∑ j L(S′k, Sk)
k=i
− γ log P(S′ i ... S′j|Vi,j);
</equation>
<page confidence="0.770675">
1516
</page>
<bodyText confidence="0.823832">
The edge weights are the negative logarithm of the
transition probabilities:
</bodyText>
<equation confidence="0.598513">
WE(Vz ,→V,+1 k) = — log P(Vj+1,k|Vi,j)
</equation>
<bodyText confidence="0.999932666666667">
Although the model is formulated on first order
HMM, i.e., the LM used for transition probabil-
ity is a bigram one, it is easy to extend the model
to take advantage of higher order n-gram LM, by
tracking longer history while traversing the graph.
Computing the shortest path from V0 to VE on G
yields the best pinyin-to-Chinese conversion with
typo correction result. Considering our running
example, the graph G is shown in Figure 4.
</bodyText>
<figureCaption confidence="0.992449">
Figure 4: Joint graph model
</figureCaption>
<bodyText confidence="0.9993535">
The joint graph is rather huge and density. Ac-
cording to our empirical statistics, when setting
threshold T = 2, for a sentence of M characters,
the joint graph will have |V |= M x 1, 000, and
</bodyText>
<equation confidence="0.703349">
|E |= M x 1, 000, 000.
</equation>
<figureCaption confidence="0.998384">
Figure 6: Filtered graph model
</figureCaption>
<bodyText confidence="0.99988">
backtracking the best paths to current vertex while
traversing. The heap is implemented as a priority
queue of size K sorted according to path length
that should support efficient push and pop opera-
tions. Fibonacci heap (Fredman and Tarjan, 1987)
is adopted for the heap implementation since it has
a push complexity of O(1) which is better than the
O(K) for other heap structures.
Another benefit provided by K-shortest paths
is that it can be used for generating N-best can-
didates of PTC conversion, which may be helpful
for further performance improvement.
</bodyText>
<sectionHeader confidence="0.99941" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999043">
4.1 Corpora, Tools and Experiment Settings
</subsectionHeader>
<bodyText confidence="0.999967333333333">
The corpus for evaluation is the one provided
in (Yang et al., 2012a), which is originally ex-
tracted from the People’s Daily corpus and labeled
with pinyin. The corpus has already been split into
training TRAIN, development DEV and test TEST
sets as shown in Table 1.
</bodyText>
<table confidence="0.468794">
TRAIN DEV TEST
#Sentence 1M 2K 100K
#character 43,679,593 83,765 4,123,184
</table>
<figure confidence="0.99547227027027">
...
或活火
huo
...
还海
ma hai
mi
...
你呢呢
ni
...
米迷
...
ti... pao zhi.
...
好好豪
hao
...
吗嘛妈
mi’huo
ni’hao
... ...
迷惑 至极
zhi&apos;ji
...
你好
束书数
shu
...
赛塞鳃
sai
... ...
世事 及几
shi ji
...
shuai
shi&apos;jie
...
帅甩摔
...
句局
ju
jie
jia
接姐节
...
家加
世界
w
e
a...
...
饿额
...
mi米迷
...
你呢呢
ni
...
迷惑
mi’huo zhi&apos;ji
ni’hao
huo zhi ... ji ...a...
...
shi&apos;jie
...
至极
jie
世界
接姐节
If the corresponding pinyin syllables in Gc have an
edge between them, the vertices in G also have an
edge:
E = {E(Vi,j — Vj+1,k)|E(Si,j — Sj+1,k) E Gc}.
</figure>
<tableCaption confidence="0.994019">
Table 1: Data set size
</tableCaption>
<subsectionHeader confidence="0.706112">
3.5 K-Shortest Paths
</subsectionHeader>
<bodyText confidence="0.999935666666667">
To reduce the scale of graph G, we filter graph Gc
by searching its K-shortest paths first to get G′c and
construct G on top of G′c. Figure 5 shows the 3-
shortest paths filtered graph G′c and Figure 6 shows
the corresponding G for our running example. The
scale of graph may be thus drastically reduced.
</bodyText>
<figureCaption confidence="0.967733">
Figure 5: K-shortest paths in typo correction
</figureCaption>
<bodyText confidence="0.999902266666667">
An efficient heap data structure is required in
K-shortest paths algorithm (Eppstein, 1998) for
SRILM (Stolcke, 2002) is adopted for lan-
guage model training and KenLM (Heafield, 2011;
Heafield et al., 2013) for language model query.
The Chinese part of the corpus is segmented into
words before LM training. Maximum match-
ing word segmentation is used with a large word
vocabulary V extracted from web data provided
by (Wang et al., 2013b). The pinyin part is seg-
mented according to the Chinese part. This vo-
cabulary V also serves as the PTC dictionary. The
original vocabulary is not labeled with pinyin, thus
we use the PTC dictionary of sunpinyin1 which is
an open source Chinese pinyin IME, to label the
</bodyText>
<footnote confidence="0.819707">
1http://code.google.com/p/sunpinyin/
</footnote>
<figure confidence="0.8409806">
mi huo zhi
ni hao shi
ji
jie
a
</figure>
<page confidence="0.969331">
1517
</page>
<bodyText confidence="0.9991455">
vocabulary V with pinyin. The emission proba-
bilities are estimated using the lexical translation
module of MOSES (Koehn et al., 2007) as “trans-
lation probability” from pinyin to Chinese.
</bodyText>
<subsectionHeader confidence="0.935738">
4.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999966095238095">
We will use conventional sequence labeling evalu-
ation metrics such as sequence accuracy and char-
acter accuracy2.
Chinese characters in a sentence may be sepa-
rated by digits, punctuation and alphabets which
are directly inputted without the IME. We fol-
low the so-called term Max Input Unit (MIU), the
longest consecutive Chinese character sequence
proposed by (Jia and Zhao, 2013). We will mainly
consider MIU accuracy (MIU-Acc) which is the
ratio of the number of completely corrected gen-
erated MIUs over the number of all MIUs, and
character accuracy (Ch-Acc), but the sentence ac-
curacy (S-Acc) will also be reported in evaluation
results.
We will also report the conversion error
rate (ConvER) proposed by (Zheng et al., 2011a),
which is the ratio of the number of mistyped pinyin
word that is not converted to the right Chinese
word over the total number of mistyped pinyin
words3.
</bodyText>
<subsectionHeader confidence="0.994893">
4.3 Baseline System without Typo Correction
</subsectionHeader>
<bodyText confidence="0.999987588235294">
Firstly we build a baseline system without typo
correction which is a pipeline of pinyin syllable
segmentation and PTC conversion. The baseline
system takes a pinyin input sequence, segments it
into syllables, and then converts it to Chinese char-
acter sequence.
The pinyin syllable segmentation already has
very high (over 98%) accuracy with a trigram LM
using improved Kneser-Ney smoothing. Accord-
ing to our empirical observation, emission prob-
abilities are mostly 1 since most Chinese words
have unique pronunciation. So in this step we set
-y = 0. We consider different LM smoothing
methods including Kneser-Ney (KN), improved
Kneser-Ney (IKN), and Witten-Bell (WB). All of
the three smoothing methods for bigram and tri-
gram LMs are examined both using back-off mod-
</bodyText>
<footnote confidence="0.917977333333333">
2We only work on the PTC conversion part of IME, thus
we are unable to use existing evaluation systems (Jia and
Zhao, 2013) for full Chinese IME functions.
3Other evaluation metrics are also proposed by (Zheng et
al., 2011a) which is only suitable for their system since our
system uses a joint model
</footnote>
<bodyText confidence="0.997228571428571">
els and interpolated models. The number of N-
best candidates for PTC conversion is set to 10.
The results on DEv are shown in Figure 7 in which
the “-i” suffix indicates using interpolated model.
According to the results, we then choose the tri-
gram LM using Kneser-Ney smoothing with inter-
polation.
</bodyText>
<figure confidence="0.493412">
KNKN-iIKNIKN-iWBWB-i
</figure>
<figureCaption confidence="0.9456455">
Figure 7: MIU-Acc and Ch-Acc with different LM
smoothing
</figureCaption>
<bodyText confidence="0.915532142857143">
The choice of the number of N-best candidates
for PTC conversion also has a strong impact on the
results. Figure 8 shows the results on DEv with dif-
ferent Ns, of which the N axis is drawn in logarith-
mic scale. We can observe that MIU-Acc slightly
decreases while N goes up, but Ch-Acc largely in-
creases. We therefore choose N = 10 as trade-off.
</bodyText>
<figureCaption confidence="0.6574556">
Figure 8: MIU-Acc and Ch-Acc with different Ns
The parameter -y determines emission probabil-
ity. Results with different -y on DEv is shown in
Figure 9, of which the -y axis is drawn in logarith-
mic scale. -y = 0.03 is chosen at last.
</figureCaption>
<bodyText confidence="0.99995975">
We compare our baseline system with several
practical pinyin IMEs including sunpinyin and
Google Input Tools (Online version)4. The results
on DEv are shown in Table 2.
</bodyText>
<footnote confidence="0.675973">
4http://www.google.com/inputtools/try/
</footnote>
<figure confidence="0.990832679245283">
MIU-Acc
0.74
0.72
0.68
0.66
0.64
0.62
0.7
MIU-Acc-bigram
Ch-Acc-bigram
MIU-Acc-trigram
Ch-Acc-trigram
0.964
0.962
0.96
0.958
0.956
0.954
0.952
0.95
0.948
0.946
0.944
Ch-Acc
1 10 100 1000
MIU-Acc
0.7315
0.7305
0.7295
0.7285
0.7275
0.7265
0.732
0.731
0.729
0.728
0.727
0.73
MIU-Acc
Ch-Acc
0.985
0.98
0.975
0.97
0.965
0.96
0.955
0.95
0.945
0.94
0.935
Ch-Acc
1518
</figure>
<figureCaption confidence="0.99971">
Figure 9: MIU-Acc and Ch-Acc with different -y
</figureCaption>
<table confidence="0.999371333333333">
MIU-Acc Ch-Acc S-Acc
Baseline 73.39 96.24 38.00
sunpinyin 52.37 87.51 13.95
Google 74.74 94.81 40.2
Yang-ME - 93.3 30.2
Yang-MT - 95.5 45.4
</table>
<tableCaption confidence="0.959076">
Table 2: Baseline system compared to other
IMEs (%)
</tableCaption>
<subsectionHeader confidence="0.469907">
4.4 PTC Conversion with Typo Correction
</subsectionHeader>
<bodyText confidence="0.9996781">
Based upon the baseline system, we build the joint
system of PTC conversion with typo correction.
We simulate user typos by randomly generating
errors automatically on the corpus. The typo rate
is set according to previous Human-Computer In-
teraction (HCI) studies. Due to few works have
been done on modeling Chinese text entry, we
have to refer to those corresponding results on
English (Wobbrock and Myers, 2006; MacKen-
zie and Soukoreff, 2002; Clarkson et al., 2005),
which show that the average typo rate is about 2%.
(Zheng et al., 2011a) performed an experiment that
2,000 sentences of 11,968 Chinese words were en-
tered by 5 native speakers. The collected data con-
sists of 775 mistyped pinyin words caused by one
edit operation, and 85 caused by two edit opera-
tions. As we observe on TRAIN that the average
pinyin word length is 5.24, then typo rate in the
experiment of (Zheng et al., 2011a) can be roughly
estimated as:
</bodyText>
<equation confidence="0.93937">
775 + 85 x 2
11968 x 5.24
</equation>
<bodyText confidence="0.99169548">
which is similar to the conclusion on English. Thus
we generate corpora from DEV with typo rate of
0% (0-P), 2% (2-P), and 5% (5-P) to evaluate the
system.
According to (Zheng et al., 2011a) most
mistyped pinyin words are caused by one edit op-
eration. Since pinyin syllable is much shorter than
pinyin word, this ratio can be higher for pinyin
syllables. From our statistics on TRAIN, with 2%
randomly generated typos, Pr(G(5′, 5) &lt; 2) =
99.86%. Thus we set the threshold T for G to 2.
We first set K-shortest paths filter to K = 10
and tune Q. Results with different Q are shown
in Figure 10. With Q = 3.5, we select K. Re-
Figure 10: MIU-Acc and Ch-Acc with different Q
sults with different K are shown in Figure 11. We
choose K = 20 since there is no significant im-
provement when K &gt; 20.
The selection of K also directly guarantees the
running time of the joint model. With K = 20,
on a normal PC with Intel Pentium Dual-Core
E6700 CPU, the PTC conversion rate is over 2000
characters-per-minute (cpm), which is much faster
than the normal typing rate of 200 cpm.
With all parameters optimized, results on TEST
</bodyText>
<figure confidence="0.998852471264367">
0.001 0.01 0.1 1
MIU-Acc
0.75
0.65
0.55
0.45
0.7
0.6
0.5
MIU-Acc
Ch-Acc
0.98
0.96
0.94
0.92
0.9
0.88
0.86
0.84
0.82
Ch-Acc
MIU-Acc
Ch-Acc
2.5 3 3.5 4 4.5 5
(a) 0-P
0.946
MIU-Acc
Ch-Acc
0.944
0.942
0.94
0.938
0.936
0.934
0.932
2.5 3 3.5 4 4.5 5
(b) 2-P
0.888
MIU-Acc
Ch-Acc
0.61
0.884
0.605
0.882
0.88
0.878
0.595
0.876
0.59
0.874
0.585 0.872
2 2.5 3 3.5 4 4.5 5
(c) 5-P
MIU-Acc 0.745
MIU-Acc 0.74
0.735
0.73
0.725
0.72
0.715
0.71
0.705
0.7
0.695
0.69
0.685
0.68
0.675
0.67
0.665
0.615
MIU-Acc
0.97
0.968
0.966
0.964
0.962
0.96
0.958
0.956
0.954
0.6
0.886
Ch-Acc
Ch-Acc
Ch-Acc
= 1.51%,
</figure>
<page confidence="0.791329">
1519
</page>
<figureCaption confidence="0.998195">
Figure 11: MIU-Acc and Ch-Acc with different K
</figureCaption>
<bodyText confidence="0.99981508">
using the proposed joint model are shown in Ta-
ble 3 and Table 4. Our results are compared to
the baseline system without typo correction and
Google Input Tool. Since sunpinyin does not have
typo correction module and performs much poorer
than our baseline system, we do not include it in
the comparison. Though no direct proofs can be
found to indicate if Google Input Tool has an in-
dependent typo correction component, its outputs
show that such a component is unlikely available.
Since Google Input Tool has to be accessed
through a web interface and the network connec-
tion cannot be guaranteed. we only take a subset
of 10K sentences of TEST to perform the experi-
ments, and the results are shown in Table 3.
The scores reported in (Zheng et al., 2011a) are
not listed in Table 4 since the data set is differ-
ent. They reported a ConvER of 53.56%, which is
given here for reference.
Additionally, to further inspect the robustness of
our model, performance with typo rate ranges from
0% to 5% is shown in Figure 12. Although the per-
formance decreases while typo rate goes up, it is
still quite satisfying around typo rate of 2% which
is assumed to be the real world situation.
</bodyText>
<table confidence="0.9994529">
MIU-Acc Ch-Acc S-Acc ConvER
Baseline 0-P 79.90 97.47 48.87 -
Baseline 2-P 50.47 90.53 11.12 99.95
Baseline 5-P 30.26 82.83 3.32 99.99
Google 0-P 79.08 95.26 46.83 -
Google 2-P 49.47 61.50 11.08 91.70
Google 5-P 29.18 36.20 3.29 94.64
Joint 0-P 79.90 97.52 49.27 -
Joint 2-P 75.55 95.40 40.69 18.45
Joint 5-P 67.76 90.17 27.86 24.68
</table>
<tableCaption confidence="0.793006">
Table 3: Test results on 10K sentences from TEST
(%)
</tableCaption>
<table confidence="0.999812142857143">
MIU-Acc Ch-Acc S-Acc ConvER
Baseline 0-P 74.46 96.42 40.50 -
Baseline 2-P 47.25 89.50 9.62 99.95
Baseline 5-P 28.28 81.74 2.63 99.98
Joint 2-P 74.22 96.39 40.34 -
Joint 2-P 69.91 94.14 33.11 21.35
Joint 5-P 62.14 88.49 22.62 27.79
</table>
<tableCaption confidence="0.99926">
Table 4: Test results on TEST (%)
</tableCaption>
<figure confidence="0.9966931">
1.2
MIU-Acc
Ch-Acc
1
0.8
0.6
0.4
0.2
0 0
0 1 2 3 4 5
</figure>
<figureCaption confidence="0.9692085">
Figure 12: MIU-Acc and Ch-Acc with different
typo rate (%)
</figureCaption>
<sectionHeader confidence="0.993142" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999894111111111">
In this paper, we have developed a joint graph
model for pinyin-to-Chinese conversion with typo
correction. This model finds a joint global opti-
mal for typo correction and PTC conversion on the
entire input pinyin sequence. The evaluation re-
sults show that our model outperforms both pre-
vious academic systems and existing commercial
products. In addition, the joint model is efficient
enough for practical use.
</bodyText>
<figure confidence="0.999905742857143">
MIU-Acc 0.745
MIU-Acc 0.74
0.735
0.73
0.725
0.72
0.715
0.71
0.705
0.7
0.695
0.69
0.685
0.68
0.675
0.67
0.665
0.66
0.655
MIU-Acc 0.61
0.6
0.59
0.58
0.57
0.56
0.55
0.89 Ch-Acc
0.885
0.88
0.875
0.87
0.865
0.86
0.855
0.85
MIU-Acc
Ch-Acc
0 10 20 30 40 50 60 70 80 90 100
0.968
0.966
0.964
Ch-Acc
0.962
0.96
0.958
0.956
0.954
0.945
0.94
0.935
Ch-Acc
0.93
0.925
0.92
(a) 0-P
MIU-Acc
Ch-Acc
0 10 20 30 40 50 60 70 80 90 100
(b) 2-P
MIU-Acc
Ch-Acc
0 10 20 30 40 50 60 70 80 90 100
(c) 5-P
MIU-Acc 1.2
1
0.8
0.6
0.4
0.2
Ch-Acc
</figure>
<page confidence="0.916798">
1520
</page>
<sectionHeader confidence="0.923372" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998959454545454">
Richard G. Casey and Eric Lecolinet. 1996. A Sur-
vey of Methods and Strategies in Character Segmen-
tation. Pattern Analysis and Machine Intelligence,
IEEE Transactions on, 18(7):690–706.
Chao-Huang Chang. 1994. A Pilot Study on Auto-
matic Chinese Spelling Error Correction. Journal of
Chinese Language and Computing, 4:143–149.
Zheng Chen and Kai-Fu Lee. 2000. A New Statis-
tical Approach To Chinese Pinyin Input. In Pro-
ceedings of the 38th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 241–247,
Hong Kong, October.
Kuan-Yu Chen, Hung-Shin Lee, Chung-Han Lee, Hsin-
Min Wang, and Hsin-Hsi Chen. 2013. A Study
of Language Modeling for Chinese Spelling Check.
In Proceedings of the Seventh SIGHAN Workshop
on Chinese Language Processing, pages 79–83,
Nagoya, Japan, October. Asian Federation of Nat-
ural Language Processing.
Hsun-wen Chiu, Jian-cheng Wu, and Jason S. Chang.
2013. Chinese Spelling Checker Based on Statis-
tical Machine Translation. In Proceedings of the
Seventh SIGHAN Workshop on Chinese Language
Processing, pages 49–53, Nagoya, Japan, October.
Asian Federation of Natural Language Processing.
Edward Clarkson, James Clawson, Kent Lyons, and
Thad Starner. 2005. An Empirical Study of Typ-
ing Rates on mini-QWERTY Keyboards. In CHI ’05
Extended Abstracts on Human Factors in Computing
Systems, CHI EA ’05, pages 1288–1291, New York,
NY, USA. ACM.
David Eppstein. 1998. Finding the K Shortest Paths.
SIAM Journal on computing, 28(2):652–673.
Jr G. David Forney. 1973. The Viterbi Algorithm.
Proceedings of the IEEE, 61(3):268–278.
Michael L. Fredman and Robert Endre Tarjan. 1987.
Fibonacci Heaps and Their Uses in Improved Net-
work Optimization Algorithms. Journal of the ACM
(JACM), 34(3):596–615, July.
Dongxu Han and Baobao Chang. 2013. A Maxi-
mum Entropy Approach to Chinese Spelling Check.
In Proceedings of the Seventh SIGHAN Workshop
on Chinese Language Processing, pages 74–78,
Nagoya, Japan, October. Asian Federation of Nat-
ural Language Processing.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable Modified
Kneser-Ney Language Model Estimation. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 690–696,
Sofia, Bulgaria, August.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
EMNLP 2011 Sixth Workshop on Statistical Ma-
chine Translation, pages 187–197, Edinburgh, Scot-
land, United Kingdom, July.
Changning Huang and Hai Zhao. 2007. Chinese Word
Segmentation: A Decade Review. Journal of Chi-
nese Information Processing, 21(3):8–20.
Zhongye Jia and Hai Zhao. 2013. KySS 1.0: a
Framework for Automatic Evaluation of Chinese In-
put Method Engines. In Proceedings of the Sixth In-
ternational Joint Conference on Natural Language
Processing, pages 1195–1201, Nagoya, Japan, Octo-
ber. Asian Federation of Natural Language Process-
ing.
Zhongye Jia, Peilu Wang, and Hai Zhao. 2013. Graph
Model for Chinese Spell Checking. In Proceedings
of the Seventh SIGHAN Workshop on Chinese Lan-
guage Processing, pages 88–92, Nagoya, Japan, Oc-
tober. Asian Federation of Natural Language Pro-
cessing.
Wei Jiang, Yi Guan, Xiaolong Wang, and BingQuan
Liu. 2007. PinYin-to-Character Conversion Model
based on Support Vector Machines. Journal of Chi-
nese information processing, 21(2):100–105.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open Source Toolkit for Statistical Machine Trans-
lation. In Proceedings of the 45th Annual Meeting of
the Association for Computational Linguistics Com-
panion Volume Proceedings of the Demo and Poster
Sessions, pages 177–180, Prague, Czech Republic,
June. Association for Computational Linguistics.
Vladimir I. Levenshtein. 1966. Binary Codes Capable
of Correcting Deletions, Insertions and Reversals. In
Soviet physics doklady, volume 10, page 707.
Mu Li, Muhua Zhu, Yang Zhang, and Ming Zhou.
2006. Exploring Distributional Similarity Based
Models for Query Spelling Correction. In Proceed-
ings of the 21st International Conference on Compu-
tational Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics, pages
1025–1032, Sydney, Australia, July. Association for
Computational Linguistics.
Lu Li, Xuan Wang, Xiao-Long Wang, and Yan-Bing
Yu. 2009. A Conditional Random Fields Approach
to Chinese Pinyin-to-Character Conversion. Journal
of Communication and Computer, 6(4):25–31.
Xiaodong Liu, Kevin Cheng, Yanyan Luo, Kevin Duh,
and Yuji Matsumoto. 2013. A Hybrid Chinese
Spelling Correction Using Language Model and Sta-
tistical Machine Translation with Reranking. In Pro-
ceedings of the Seventh SIGHAN Workshop on Chi-
nese Language Processing, pages 54–58, Nagoya,
Japan, October. Asian Federation of Natural Lan-
guage Processing.
</reference>
<page confidence="0.809093">
1521
</page>
<reference confidence="0.999932890909091">
I. Scott MacKenzie and R. William Soukoreff. 2002. A
Character-level Error Analysis Technique for Eval-
uating Text Entry Methods. In Proceedings of the
Second Nordic Conference on Human-computer In-
teraction, NordiCHI ’02, pages 243–246, New York,
NY, USA. ACM.
Eric Mays, Fred J Damerau, and Robert L Mercer.
1991. Context Based Spelling Correction. Informa-
tion Processing &amp; Management, 27(5):517–522.
James L. Peterson. 1980. Computer Programs for De-
tecting and Correcting Spelling Errors. Commun.
ACM, 23(12):676–687, December.
Andreas Stolcke. 2002. SRILM-An Extensible Lan-
guage Modeling Toolkit. In Proceedings of the in-
ternational conference on spoken language process-
ing, volume 2, pages 901–904.
Andrew J. Viterbi. 1967. Error Bounds for Con-
volutional Codes and an Asymptotically Optimum
Decoding Algorithm. Information Theory, IEEE
Transactions on, 13(2):260–269.
Xuan Wang, Lu Li, Lin Yao, and Waqas Anwar. 2006.
A Maximum Entropy Approach to Chinese Pin Yin-
To-Character Conversion. In Systems, Man and Cy-
bernetics, 2006. SMC’06. IEEE International Con-
ference on, volume 4, pages 2956–2959. IEEE.
Chun-Hung Wang, Jason S. Chang, and Jian-Cheng
Wu. 2013a. Automatic Chinese Confusion Words
Extraction Using Conditional Random Fields and the
Web. In Proceedings of the Seventh SIGHAN Work-
shop on Chinese Language Processing, pages 64–
68, Nagoya, Japan, October. Asian Federation of
Natural Language Processing.
Peilu Wang, Ruihua Sun, Hai Zhao, and Kai Yu.
2013b. A New Word Language Model Evaluation
Metric for Character Based Languages. In Chinese
Computational Linguistics and Natural Language
Processing Based on Naturally Annotated Big Data,
pages 315–324. Springer.
Rui Wang, Masao Utiyama, Isao Goto, Eiichro Sumita,
Hai Zhao, and Bao-Liang Lu. 2013c. Converting
Continuous-Space Language Models into N-Gram
Language Models for Statistical Machine Transla-
tion. In Proceedings of the 2013 Conference on Em-
pirical Methods in Natural Language Processing,
pages 845–850, Seattle, Washington, USA, October.
Association for Computational Linguistics.
Yih-Ru Wang, Yuan-Fu Liao, Yeh-Kuang Wu, and
Liang-Chun Chang. 2013d. Conditional Random
Field-based Parser and Language Model for Tradi-
tional Chinese Spelling Checker. In Proceedings
of the Seventh SIGHAN Workshop on Chinese Lan-
guage Processing, pages 69–73, Nagoya, Japan, Oc-
tober. Asian Federation of Natural Language Pro-
cessing.
Jacob O. Wobbrock and Brad A. Myers. 2006. Analyz-
ing the Input Stream for Character- Level Errors in
Unconstrained Text Entry Evaluations. ACM Trans.
Comput.-Hum. Interact., 13(4):458–489, December.
Jun Wu and Liren Chen. 2004. Fault-tolerant Roman-
ized Input Method for Non-roman Characters, Au-
gust 25. US Patent App. 10/928,131.
Jun Wu, Hulcan Zhu, and Hongjun Zhu. 2009. Sys-
tems and Methods for Translating Chinese Pinyin
to Chinese Characters, January 13. US Patent
7,478,033.
Shaohua Yang, Hai Zhao, and Bao-liang Lu. 2012a. A
Machine Translation Approach for Chinese Whole-
Sentence Pinyin-to-Character Conversion. In Pro-
ceedings of the 26th Pacific Asia Conference on Lan-
guage, Information, and Computation, pages 333–
342, Bali,Indonesia, November. Faculty of Com-
puter Science, Universitas Indonesia.
Shaohua Yang, Hai Zhao, Xiaolin Wang, and Bao-liang
Lu. 2012b. Spell Checking for Chinese. In Interna-
tional Conference on Language Resources and Eval-
uation, pages 730–736, Istanbul, Turkey, May.
Liang-Chih Yu, Yuen-Hsien Tseng, Jingbo Zhu, and
Fuji Ren, editors. 2013. Proceedings of the Seventh
SIGHAN Workshop on Chinese Language Process-
ing. Asian Federation of Natural Language Process-
ing, Nagoya, Japan, October.
Jingyi Zhang and Hai Zhao. 2013. Improving Func-
tion Word Alignment with Frequency and Syntac-
tic Information. In Proceedings of the Twenty-Third
international joint conference on Artificial Intelli-
gence, pages 2211–2217. AAAI Press.
Hai Zhao and Chunyu Kit. 2008. Exploiting Unlabeled
Text with Different Unsupervised Segmentation Cri-
teria for Chinese Word Segmentation. Research in
Computing Science, 33:93–104.
Hai Zhao and Chunyu Kit. 2011. Integrating Unsu-
pervised and Supervised Word Segmentation: The
Role of Goodness Measures. Information Sciences,
181(1):163–183.
Hai Zhao, Chang-Ning Huang, and Mu Li. 2006. An
Improved Chinese Word Segmentation System with
Conditional Random Field. In Proceedings of the
Fifth SIGHAN Workshop on Chinese Language Pro-
cessing, pages 162–165, Sydney, Australia, July.
Association for Computational Linguistics.
Hai Zhao, Chang-Ning Huang, Mu Li, and Bao-Liang
Lu. 2010. A Unified Character-Based Tagging
Framework for Chinese Word Segmentation. ACM
Transactions on Asian Language Information Pro-
cessing (TALIP), 9(2):5.
Hai Zhao, Masao Utiyama, Eiichiro Sumita, and Bao-
Liang Lu. 2013. An Empirical Study on Word
Segmentation for Chinese Machine Translation. In
Computational Linguistics and Intelligent Text Pro-
cessing, pages 248–263. Springer.
</reference>
<page confidence="0.839497">
1522
</page>
<reference confidence="0.999617785714286">
Yabin Zheng, Chen Li, and Maosong Sun. 2011a.
CHIME: An Efficient Error-tolerant Chinese Pinyin
Input Method. In Proceedings of the Twenty-Second
International Joint Conference on Artificial Intel-
ligence - Volume Volume Three, IJCAI’11, pages
2551–2556. AAAI Press.
Yabin Zheng, Lixing Xie, Zhiyuan Liu, Maosong Sun,
Yang Zhang, and Liyun Ru. 2011b. Why Press
Backspace? Understanding User Input Behaviors in
Chinese Pinyin Input Method. In Proceedings of the
49th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Techologies,
pages 485–490, Portland, Oregon, USA, June. Asso-
ciation for Computational Linguistics.
</reference>
<page confidence="0.957171">
1523
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.426560">
<title confidence="0.88715">A Joint Graph Model for Pinyin-to-Chinese Conversion Typo</title>
<author confidence="0.775565">Jia</author>
<author confidence="0.775565">Hai</author>
<affiliation confidence="0.83751">MOE-Microsoft Key Laboratory for Intelligent Computing and Intelligent Center for Brain-Like Computing and Machine Department of Computer Science and Engineering, Shanghai Jiao Tong</affiliation>
<address confidence="0.996588">800 Dongchuan Road, Shanghai 200240,</address>
<email confidence="0.972509">jia.zhongye@gmail.com,zhaohai@cs.sjtu.edu.cn</email>
<abstract confidence="0.997754266666667">It is very import for Chinese language processing with the aid of an efficient input method engine (IME), of which pinyinto-Chinese (PTC) conversion is the core part. Meanwhile, though typos are inevitable during user pinyin inputting, existing IMEs paid little attention to such big inconvenience. In this paper, motivated by a key equivalence of two decoding algorithms, we propose a joint graph model to globally optimize PTC and typo correction for IME. The evaluation results show that the proposed method outperforms both existing academic and commercial IMEs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Richard G Casey</author>
<author>Eric Lecolinet</author>
</authors>
<date>1996</date>
<booktitle>A Survey of Methods and Strategies in Character Segmentation. Pattern Analysis and Machine Intelligence, IEEE Transactions on,</booktitle>
<pages>18--7</pages>
<contexts>
<context position="10266" citStr="Casey and Lecolinet, 1996" startWordPosition="1669" endWordPosition="1672">checking methods for English to pinyin typo checking, although techniques for English spell checking have been well developed. A bit confusing but interesting, pinyin typo correction and segmentation come as two sides of one problem: when a pinyin sequence is mistyped, it is unlikely to be correctly segmented; when it is segmented in an awkward way, it is likely to be mistyped. Inspired by (Yang et al., 2012b) and (Jia et al., 2013), we adopt the graph model for Chinese spell checking for pinyin segmentation and typo correction, which is based on the shortest path word segmentation algorithm (Casey and Lecolinet, 1996). The model has two major steps: segmentation and correction. 3.2.1 Pinyin Segmentation The shortest path segmentation algorithm is based on the idea that a reasonable segmentation should minimize the number of segmented units. For a pinyin sequence p1pe ... pL, where pi is a letter, first a directed acyclic graph (DAG) GS = (V, E) is built for pinyin segmentation step. The vertex set V consists of the following parts: • Virtual start vertex S0 and end vertex SE; • Possible legal syllables fetched from dictionary Dp according to the input pinyin sequence: n i h ni hao nihao tid a o tido Pinyin</context>
</contexts>
<marker>Casey, Lecolinet, 1996</marker>
<rawString>Richard G. Casey and Eric Lecolinet. 1996. A Survey of Methods and Strategies in Character Segmentation. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 18(7):690–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao-Huang Chang</author>
</authors>
<title>A Pilot Study on Automatic Chinese Spelling Error Correction.</title>
<date>1994</date>
<journal>Journal of Chinese Language and Computing,</journal>
<pages>4--143</pages>
<contexts>
<context position="7613" citStr="Chang, 1994" startWordPosition="1214" endWordPosition="1215">dom field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHAN Workshop on Chinese Language Processing (Yu et al., 2013) held a shared task on Chinese spell checking. Various approaches were made for the task including language model (LM) based methods (Chen et al., 2013), ME model (Han and Chang, 2013), CRF (Wang et al., 2013d; Wang et al., 2013a), SMT (Chiu et al., 2013; Liu et al., 2013), and graph model (Jia et al., 2013), etc. 3 Pinyin Input Method Model 3.1 From English Letter to Chinese Sentence It is a ra</context>
</contexts>
<marker>Chang, 1994</marker>
<rawString>Chao-Huang Chang. 1994. A Pilot Study on Automatic Chinese Spelling Error Correction. Journal of Chinese Language and Computing, 4:143–149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Kai-Fu Lee</author>
</authors>
<title>A New Statistical Approach To Chinese Pinyin Input.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>241--247</pages>
<location>Hong Kong,</location>
<contexts>
<context position="2995" citStr="Chen and Lee, 2000" startWordPosition="452" endWordPosition="455">st characters usually have unique pinyin representations, while a few Chinese characters may be pronounced in several different ways, so they may have multiple pinyin representations. The advantage of pinyin IME is that it only adopts the pronunciation perspective of Chinese characters so that it is simple and easy to learn. But there are only less than 500 pinyin syllables in standard modern Chinese, compared with over 6,000 commonly used Chinese characters, which leads to serious ambiguities for pinyin-to-character mapping. Modern pinyin IMEs mostly use a “sentencebased” decoding technique (Chen and Lee, 2000) to alleviate the ambiguities. “Sentence based” means that IME generates a sequence of Chinese characters upon a sequence of pinyin inputs with respect to certain statistical criteria. 1.2 Typos and Chinese Spell Checking Written in Chinese characters but not alphabets, spell checking for Chinese language is quite different from the same task for other languages. Since Chinese characters are entered via IME, those user-made typos do not immediately lead to spelling errors. When a user types a wrong letter, IME will be very likely to fail to generate the expected Chinese character sequence. Nor</context>
<context position="4380" citStr="Chen and Lee, 2000" startWordPosition="670" endWordPosition="673">gs of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1512–1523, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics movement, deletion and re-typing. Thus there are two separated sub-tasks for Chinese spell checking: 1. typo checking for user typed pinyin sequences which should be a built-in module in IME, and 2. spell checking for Chinese texts in its narrow sense, which is typically a module of word processing applications (Yang et al., 2012b). These two terms are often confused especially in IME related works such as (Chen and Lee, 2000) and (Wu et al., 2009). Pinyin typos have always been a serious problem for Chinese pinyin IMEs. The user may fail to input the completely right pinyin simply because he/she is a dialect speaker and does not know the exact pronunciation for the expected character. This may be a very common situation since there are about seven quite different dialects in Chinese, among which being spoken languages, six are far different from the standard modern Chinese, mandarin. With the boom of smart-phones, pinyin typos worsen due to the limited size of soft keyboard, and the lack of physical feedback on th</context>
</contexts>
<marker>Chen, Lee, 2000</marker>
<rawString>Zheng Chen and Kai-Fu Lee. 2000. A New Statistical Approach To Chinese Pinyin Input. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 241–247, Hong Kong, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuan-Yu Chen</author>
<author>Hung-Shin Lee</author>
<author>Chung-Han Lee</author>
<author>HsinMin Wang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>A Study of Language Modeling for Chinese Spelling Check.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>79--83</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="7967" citStr="Chen et al., 2013" startWordPosition="1269" endWordPosition="1272">a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHAN Workshop on Chinese Language Processing (Yu et al., 2013) held a shared task on Chinese spell checking. Various approaches were made for the task including language model (LM) based methods (Chen et al., 2013), ME model (Han and Chang, 2013), CRF (Wang et al., 2013d; Wang et al., 2013a), SMT (Chiu et al., 2013; Liu et al., 2013), and graph model (Jia et al., 2013), etc. 3 Pinyin Input Method Model 3.1 From English Letter to Chinese Sentence It is a rather long journey from the first English letter typed on the keyboard to finally a completed Chinese sentence generated by IME. We will first take an overview of the entire process. The average length of pinyin syllables is about 3 letters. There are about 410 pinyin syllables used in the current pinyin system. Each pinyin sylla1513 ble has a bunch of </context>
</contexts>
<marker>Chen, Lee, Lee, Wang, Chen, 2013</marker>
<rawString>Kuan-Yu Chen, Hung-Shin Lee, Chung-Han Lee, HsinMin Wang, and Hsin-Hsi Chen. 2013. A Study of Language Modeling for Chinese Spelling Check. In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 79–83, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsun-wen Chiu</author>
<author>Jian-cheng Wu</author>
<author>Jason S Chang</author>
</authors>
<title>Chinese Spelling Checker Based on Statistical Machine Translation.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>49--53</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="8069" citStr="Chiu et al., 2013" startWordPosition="1289" endWordPosition="1292">ere a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHAN Workshop on Chinese Language Processing (Yu et al., 2013) held a shared task on Chinese spell checking. Various approaches were made for the task including language model (LM) based methods (Chen et al., 2013), ME model (Han and Chang, 2013), CRF (Wang et al., 2013d; Wang et al., 2013a), SMT (Chiu et al., 2013; Liu et al., 2013), and graph model (Jia et al., 2013), etc. 3 Pinyin Input Method Model 3.1 From English Letter to Chinese Sentence It is a rather long journey from the first English letter typed on the keyboard to finally a completed Chinese sentence generated by IME. We will first take an overview of the entire process. The average length of pinyin syllables is about 3 letters. There are about 410 pinyin syllables used in the current pinyin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The n</context>
</contexts>
<marker>Chiu, Wu, Chang, 2013</marker>
<rawString>Hsun-wen Chiu, Jian-cheng Wu, and Jason S. Chang. 2013. Chinese Spelling Checker Based on Statistical Machine Translation. In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 49–53, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Clarkson</author>
<author>James Clawson</author>
<author>Kent Lyons</author>
<author>Thad Starner</author>
</authors>
<title>An Empirical Study of Typing Rates on mini-QWERTY Keyboards.</title>
<date>2005</date>
<booktitle>In CHI ’05 Extended Abstracts on Human Factors in Computing Systems, CHI EA ’05,</booktitle>
<pages>1288--1291</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="26783" citStr="Clarkson et al., 2005" startWordPosition="4571" endWordPosition="4574">ogle 74.74 94.81 40.2 Yang-ME - 93.3 30.2 Yang-MT - 95.5 45.4 Table 2: Baseline system compared to other IMEs (%) 4.4 PTC Conversion with Typo Correction Based upon the baseline system, we build the joint system of PTC conversion with typo correction. We simulate user typos by randomly generating errors automatically on the corpus. The typo rate is set according to previous Human-Computer Interaction (HCI) studies. Due to few works have been done on modeling Chinese text entry, we have to refer to those corresponding results on English (Wobbrock and Myers, 2006; MacKenzie and Soukoreff, 2002; Clarkson et al., 2005), which show that the average typo rate is about 2%. (Zheng et al., 2011a) performed an experiment that 2,000 sentences of 11,968 Chinese words were entered by 5 native speakers. The collected data consists of 775 mistyped pinyin words caused by one edit operation, and 85 caused by two edit operations. As we observe on TRAIN that the average pinyin word length is 5.24, then typo rate in the experiment of (Zheng et al., 2011a) can be roughly estimated as: 775 + 85 x 2 11968 x 5.24 which is similar to the conclusion on English. Thus we generate corpora from DEV with typo rate of 0% (0-P), 2% (2-</context>
</contexts>
<marker>Clarkson, Clawson, Lyons, Starner, 2005</marker>
<rawString>Edward Clarkson, James Clawson, Kent Lyons, and Thad Starner. 2005. An Empirical Study of Typing Rates on mini-QWERTY Keyboards. In CHI ’05 Extended Abstracts on Human Factors in Computing Systems, CHI EA ’05, pages 1288–1291, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Eppstein</author>
</authors>
<title>Finding the K Shortest Paths.</title>
<date>1998</date>
<journal>SIAM Journal on computing,</journal>
<pages>28--2</pages>
<contexts>
<context position="21617" citStr="Eppstein, 1998" startWordPosition="3720" endWordPosition="3721">in syllables in Gc have an edge between them, the vertices in G also have an edge: E = {E(Vi,j — Vj+1,k)|E(Si,j — Sj+1,k) E Gc}. Table 1: Data set size 3.5 K-Shortest Paths To reduce the scale of graph G, we filter graph Gc by searching its K-shortest paths first to get G′c and construct G on top of G′c. Figure 5 shows the 3- shortest paths filtered graph G′c and Figure 6 shows the corresponding G for our running example. The scale of graph may be thus drastically reduced. Figure 5: K-shortest paths in typo correction An efficient heap data structure is required in K-shortest paths algorithm (Eppstein, 1998) for SRILM (Stolcke, 2002) is adopted for language model training and KenLM (Heafield, 2011; Heafield et al., 2013) for language model query. The Chinese part of the corpus is segmented into words before LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IM</context>
</contexts>
<marker>Eppstein, 1998</marker>
<rawString>David Eppstein. 1998. Finding the K Shortest Paths. SIAM Journal on computing, 28(2):652–673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jr G David Forney</author>
</authors>
<title>The Viterbi Algorithm.</title>
<date>1973</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<pages>61--3</pages>
<contexts>
<context position="16200" citStr="Forney, 1973" startWordPosition="2719" endWordPosition="2721">wi) k−i w1,ww,...,wM wi wi 1515 In the HMM for pinyin IME, observation states are pinyin syllables, hidden states are Chinese words, emission probability is P(si|wi), and transition probability is P(wi|wi−1). Note the transition probability is the conditional probability between words instead of characters. PTC conversion is to decode the Chinese word sequence from the pinyin sequence. The Viterbi algorithm (Viterbi, 1967) is used for the decoding. The shortest path algorithm for typo correction and Viterbi algorithm for PTC conversion are very closely related. It has been strictly proven by (Forney, 1973) that the sequence decoding problem on HMM is formally identical to finding a shortest path on a certain graph, which can be constructed in the following manner. Consider a first order HMM with all possible observations ® = {o1, o2, ... , oM}, hidden states S = {s1, s2,... , sN}, a special start state s0, emission probabilities (Esi,ok) = P(ok|si), transition probabilities (Tsi,sj) = P(sj|si), and start probabilities (Ssi) = P(si|s0). For an observation sequence of T time periods Y = {y1,y2,...,yT|yt ∈ ®,t = 1,...,T}, the decoding problem is to find the best corresponding hidden state sequence</context>
</contexts>
<marker>Forney, 1973</marker>
<rawString>Jr G. David Forney. 1973. The Viterbi Algorithm. Proceedings of the IEEE, 61(3):268–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael L Fredman</author>
<author>Robert Endre Tarjan</author>
</authors>
<title>Fibonacci Heaps and Their Uses in Improved Network Optimization Algorithms.</title>
<date>1987</date>
<journal>Journal of the ACM (JACM),</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="19919" citStr="Fredman and Tarjan, 1987" startWordPosition="3403" endWordPosition="3406">version with typo correction result. Considering our running example, the graph G is shown in Figure 4. Figure 4: Joint graph model The joint graph is rather huge and density. According to our empirical statistics, when setting threshold T = 2, for a sentence of M characters, the joint graph will have |V |= M x 1, 000, and |E |= M x 1, 000, 000. Figure 6: Filtered graph model backtracking the best paths to current vertex while traversing. The heap is implemented as a priority queue of size K sorted according to path length that should support efficient push and pop operations. Fibonacci heap (Fredman and Tarjan, 1987) is adopted for the heap implementation since it has a push complexity of O(1) which is better than the O(K) for other heap structures. Another benefit provided by K-shortest paths is that it can be used for generating N-best candidates of PTC conversion, which may be helpful for further performance improvement. 4 Experiments 4.1 Corpora, Tools and Experiment Settings The corpus for evaluation is the one provided in (Yang et al., 2012a), which is originally extracted from the People’s Daily corpus and labeled with pinyin. The corpus has already been split into training TRAIN, development DEV a</context>
</contexts>
<marker>Fredman, Tarjan, 1987</marker>
<rawString>Michael L. Fredman and Robert Endre Tarjan. 1987. Fibonacci Heaps and Their Uses in Improved Network Optimization Algorithms. Journal of the ACM (JACM), 34(3):596–615, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dongxu Han</author>
<author>Baobao Chang</author>
</authors>
<title>A Maximum Entropy Approach to Chinese Spelling Check.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>74--78</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="7999" citStr="Han and Chang, 2013" startWordPosition="1275" endWordPosition="1278">only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHAN Workshop on Chinese Language Processing (Yu et al., 2013) held a shared task on Chinese spell checking. Various approaches were made for the task including language model (LM) based methods (Chen et al., 2013), ME model (Han and Chang, 2013), CRF (Wang et al., 2013d; Wang et al., 2013a), SMT (Chiu et al., 2013; Liu et al., 2013), and graph model (Jia et al., 2013), etc. 3 Pinyin Input Method Model 3.1 From English Letter to Chinese Sentence It is a rather long journey from the first English letter typed on the keyboard to finally a completed Chinese sentence generated by IME. We will first take an overview of the entire process. The average length of pinyin syllables is about 3 letters. There are about 410 pinyin syllables used in the current pinyin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters</context>
</contexts>
<marker>Han, Chang, 2013</marker>
<rawString>Dongxu Han and Baobao Chang. 2013. A Maximum Entropy Approach to Chinese Spelling Check. In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 74–78, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Ivan Pouzyrevsky</author>
<author>Jonathan H Clark</author>
<author>Philipp Koehn</author>
</authors>
<title>Scalable Modified Kneser-Ney Language Model Estimation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>690--696</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="21732" citStr="Heafield et al., 2013" startWordPosition="3737" endWordPosition="3740">i,j — Sj+1,k) E Gc}. Table 1: Data set size 3.5 K-Shortest Paths To reduce the scale of graph G, we filter graph Gc by searching its K-shortest paths first to get G′c and construct G on top of G′c. Figure 5 shows the 3- shortest paths filtered graph G′c and Figure 6 shows the corresponding G for our running example. The scale of graph may be thus drastically reduced. Figure 5: K-shortest paths in typo correction An efficient heap data structure is required in K-shortest paths algorithm (Eppstein, 1998) for SRILM (Stolcke, 2002) is adopted for language model training and KenLM (Heafield, 2011; Heafield et al., 2013) for language model query. The Chinese part of the corpus is segmented into words before LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IME, to label the 1http://code.google.com/p/sunpinyin/ mi huo zhi ni hao shi ji jie a 1517 vocabulary V with pinyin. </context>
</contexts>
<marker>Heafield, Pouzyrevsky, Clark, Koehn, 2013</marker>
<rawString>Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H. Clark, and Philipp Koehn. 2013. Scalable Modified Kneser-Ney Language Model Estimation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 690–696, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: Faster and Smaller Language Model Queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>187--197</pages>
<location>Edinburgh, Scotland, United Kingdom,</location>
<contexts>
<context position="21708" citStr="Heafield, 2011" startWordPosition="3735" endWordPosition="3736">,j — Vj+1,k)|E(Si,j — Sj+1,k) E Gc}. Table 1: Data set size 3.5 K-Shortest Paths To reduce the scale of graph G, we filter graph Gc by searching its K-shortest paths first to get G′c and construct G on top of G′c. Figure 5 shows the 3- shortest paths filtered graph G′c and Figure 6 shows the corresponding G for our running example. The scale of graph may be thus drastically reduced. Figure 5: K-shortest paths in typo correction An efficient heap data structure is required in K-shortest paths algorithm (Eppstein, 1998) for SRILM (Stolcke, 2002) is adopted for language model training and KenLM (Heafield, 2011; Heafield et al., 2013) for language model query. The Chinese part of the corpus is segmented into words before LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IME, to label the 1http://code.google.com/p/sunpinyin/ mi huo zhi ni hao shi ji jie a 1517 vo</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: Faster and Smaller Language Model Queries. In Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland, United Kingdom, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changning Huang</author>
<author>Hai Zhao</author>
</authors>
<title>Chinese Word Segmentation: A Decade Review.</title>
<date>2007</date>
<journal>Journal of Chinese Information Processing,</journal>
<volume>21</volume>
<issue>3</issue>
<contexts>
<context position="9053" citStr="Huang and Zhao, 2007" startWordPosition="1464" endWordPosition="1467"> is about 3 letters. There are about 410 pinyin syllables used in the current pinyin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The number of those homophones ranges from 1 to over 300. Chinese characters then form words. But word in Chinese is a rather vague concept. Without word delimiters, linguists have argued on what a Chinese word really is for a long time and that is why there is always a primary word segmentation treatment in most Chinese language processing tasks (Zhao et al., 2006; Huang and Zhao, 2007; Zhao and Kit, 2008; Zhao et al., 2010; Zhao and Kit, 2011; Zhao et al., 2013). A Chinese word may contain from 1 to over 10 characters due to different word segmentation conventions. Figure 1 demonstrates the relationship of pinyin and word, from pinyin letters “nihao” to the word “你好 (hello)”. Typically, an IME takes the pinyin input, segments it into syllables, looks up corresponding words in a dictionary and generates a sentence with the candidate words. ble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previous spell checking meth</context>
</contexts>
<marker>Huang, Zhao, 2007</marker>
<rawString>Changning Huang and Hai Zhao. 2007. Chinese Word Segmentation: A Decade Review. Journal of Chinese Information Processing, 21(3):8–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongye Jia</author>
<author>Hai Zhao</author>
</authors>
<title>KySS 1.0: a Framework for Automatic Evaluation of Chinese Input Method Engines.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>1195--1201</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="5485" citStr="Jia and Zhao, 2013" startWordPosition="862" endWordPosition="865">mart-phones, pinyin typos worsen due to the limited size of soft keyboard, and the lack of physical feedback on the touch screen. However, existing practical IMEs only provide small patches to deal with typos such as Fuzzy Pinyin (Wu and Chen, 2004) and other language specific errors (Zheng et al., 2011b). Typo checking and correction has an important impact on IME performance. When IME fails to correct a typo and generate the expected sentence, the user will have to take much extra effort to move the cursor back to the mistyped letter and correct it, which leads to very poor user experience (Jia and Zhao, 2013). 2 Related Works The very first approach for Chinese input with typo correction was made by (Chen and Lee, 2000), which was also the initial attempt of “sentence-based” IME. The idea of “statistical input method” was proposed by modeling PTC conversion as a hidden Markov model (HMM), and using Viterbi (Viterbi, 1967) algorithm to decode the sequence. They solved the typo correction problem by decomposing the conditional probability P(HIP) of Chinese character sequence H given pinyin sequence P into a language model P(wi|wi_1) and a typing model P(pi|wi). The typing model that was estimated on</context>
<context position="22895" citStr="Jia and Zhao, 2013" startWordPosition="3928" endWordPosition="3931"> zhi ni hao shi ji jie a 1517 vocabulary V with pinyin. The emission probabilities are estimated using the lexical translation module of MOSES (Koehn et al., 2007) as “translation probability” from pinyin to Chinese. 4.2 Evaluation Metrics We will use conventional sequence labeling evaluation metrics such as sequence accuracy and character accuracy2. Chinese characters in a sentence may be separated by digits, punctuation and alphabets which are directly inputted without the IME. We follow the so-called term Max Input Unit (MIU), the longest consecutive Chinese character sequence proposed by (Jia and Zhao, 2013). We will mainly consider MIU accuracy (MIU-Acc) which is the ratio of the number of completely corrected generated MIUs over the number of all MIUs, and character accuracy (Ch-Acc), but the sentence accuracy (S-Acc) will also be reported in evaluation results. We will also report the conversion error rate (ConvER) proposed by (Zheng et al., 2011a), which is the ratio of the number of mistyped pinyin word that is not converted to the right Chinese word over the total number of mistyped pinyin words3. 4.3 Baseline System without Typo Correction Firstly we build a baseline system without typo co</context>
<context position="24336" citStr="Jia and Zhao, 2013" startWordPosition="4164" endWordPosition="4167"> syllable segmentation already has very high (over 98%) accuracy with a trigram LM using improved Kneser-Ney smoothing. According to our empirical observation, emission probabilities are mostly 1 since most Chinese words have unique pronunciation. So in this step we set -y = 0. We consider different LM smoothing methods including Kneser-Ney (KN), improved Kneser-Ney (IKN), and Witten-Bell (WB). All of the three smoothing methods for bigram and trigram LMs are examined both using back-off mod2We only work on the PTC conversion part of IME, thus we are unable to use existing evaluation systems (Jia and Zhao, 2013) for full Chinese IME functions. 3Other evaluation metrics are also proposed by (Zheng et al., 2011a) which is only suitable for their system since our system uses a joint model els and interpolated models. The number of Nbest candidates for PTC conversion is set to 10. The results on DEv are shown in Figure 7 in which the “-i” suffix indicates using interpolated model. According to the results, we then choose the trigram LM using Kneser-Ney smoothing with interpolation. KNKN-iIKNIKN-iWBWB-i Figure 7: MIU-Acc and Ch-Acc with different LM smoothing The choice of the number of N-best candidates </context>
</contexts>
<marker>Jia, Zhao, 2013</marker>
<rawString>Zhongye Jia and Hai Zhao. 2013. KySS 1.0: a Framework for Automatic Evaluation of Chinese Input Method Engines. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 1195–1201, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongye Jia</author>
<author>Peilu Wang</author>
<author>Hai Zhao</author>
</authors>
<title>Graph Model for Chinese Spell Checking.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>88--92</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="8124" citStr="Jia et al., 2013" startWordPosition="1300" endWordPosition="1303">l correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHAN Workshop on Chinese Language Processing (Yu et al., 2013) held a shared task on Chinese spell checking. Various approaches were made for the task including language model (LM) based methods (Chen et al., 2013), ME model (Han and Chang, 2013), CRF (Wang et al., 2013d; Wang et al., 2013a), SMT (Chiu et al., 2013; Liu et al., 2013), and graph model (Jia et al., 2013), etc. 3 Pinyin Input Method Model 3.1 From English Letter to Chinese Sentence It is a rather long journey from the first English letter typed on the keyboard to finally a completed Chinese sentence generated by IME. We will first take an overview of the entire process. The average length of pinyin syllables is about 3 letters. There are about 410 pinyin syllables used in the current pinyin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The number of those homophones ranges from 1 to over 300. Ch</context>
<context position="10076" citStr="Jia et al., 2013" startWordPosition="1638" endWordPosition="1641">ionary and generates a sentence with the candidate words. ble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previous spell checking methods for English to pinyin typo checking, although techniques for English spell checking have been well developed. A bit confusing but interesting, pinyin typo correction and segmentation come as two sides of one problem: when a pinyin sequence is mistyped, it is unlikely to be correctly segmented; when it is segmented in an awkward way, it is likely to be mistyped. Inspired by (Yang et al., 2012b) and (Jia et al., 2013), we adopt the graph model for Chinese spell checking for pinyin segmentation and typo correction, which is based on the shortest path word segmentation algorithm (Casey and Lecolinet, 1996). The model has two major steps: segmentation and correction. 3.2.1 Pinyin Segmentation The shortest path segmentation algorithm is based on the idea that a reasonable segmentation should minimize the number of segmented units. For a pinyin sequence p1pe ... pL, where pi is a letter, first a directed acyclic graph (DAG) GS = (V, E) is built for pinyin segmentation step. The vertex set V consists of the foll</context>
</contexts>
<marker>Jia, Wang, Zhao, 2013</marker>
<rawString>Zhongye Jia, Peilu Wang, and Hai Zhao. 2013. Graph Model for Chinese Spell Checking. In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 88–92, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jiang</author>
<author>Yi Guan</author>
<author>Xiaolong Wang</author>
<author>BingQuan Liu</author>
</authors>
<title>PinYin-to-Character Conversion Model based on Support Vector Machines.</title>
<date>2007</date>
<journal>Journal of Chinese information processing,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="6936" citStr="Jiang et al., 2007" startWordPosition="1098" endWordPosition="1101">lt in our approach. (Zheng et al., 2011a) developed an IME system with typo correction called CHIME using noisy channel error model and language-specific features. However their model depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. </context>
</contexts>
<marker>Jiang, Guan, Wang, Liu, 2007</marker>
<rawString>Wei Jiang, Yi Guan, Xiaolong Wang, and BingQuan Liu. 2007. PinYin-to-Character Conversion Model based on Support Vector Machines. Journal of Chinese information processing, 21(2):100–105.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="22439" citStr="Koehn et al., 2007" startWordPosition="3857" endWordPosition="3860"> LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IME, to label the 1http://code.google.com/p/sunpinyin/ mi huo zhi ni hao shi ji jie a 1517 vocabulary V with pinyin. The emission probabilities are estimated using the lexical translation module of MOSES (Koehn et al., 2007) as “translation probability” from pinyin to Chinese. 4.2 Evaluation Metrics We will use conventional sequence labeling evaluation metrics such as sequence accuracy and character accuracy2. Chinese characters in a sentence may be separated by digits, punctuation and alphabets which are directly inputted without the IME. We follow the so-called term Max Input Unit (MIU), the longest consecutive Chinese character sequence proposed by (Jia and Zhao, 2013). We will mainly consider MIU accuracy (MIU-Acc) which is the ratio of the number of completely corrected generated MIUs over the number of all </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177–180, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Binary Codes Capable of Correcting Deletions, Insertions and Reversals.</title>
<date>1966</date>
<booktitle>In Soviet physics doklady,</booktitle>
<volume>10</volume>
<pages>707</pages>
<contexts>
<context position="13561" citStr="Levenshtein, 1966" startWordPosition="2259" endWordPosition="2260">ph model for pinyin segmentation 3.2.2 Pinyin Typo Correction Next in the correction step, for the segmented pinyin sequence S1, S2, ... , SM, a graph Gc is constructed to perform typo correction. The vertex set V consists of the following parts: • Virtual start vertex S′0 and end vertex S′E with vertex weights of 0; • All possible syllables similar to original syllable in Gs. If the adjacent syllables can be merged into a legal syllable, the merged syllable is also added into V: {S′i,j|S′i,j = S′i ... S′j E Dp, S′k — Sk, k = i &lt; jJ, where the similarity — is measured in Levenshtein distance (Levenshtein, 1966). Syllables with Levenshtein distance under a certain threshold are considered as similar: Similar to Gs, the edges are from one syllable to all syllables next to it and edge weights are the conditional probabilities between them. Computing the shortest path from S′0 to S′E on Gc yields the best typo correction result. In addition, the result has been segmented so far. Considering our running example, the graph Gc is shown in Figure 3, and the typo correction result is “mi hao shi jie”. Figure 3: Graph model for pinyin typo correction Merely using the above model, the typo correction result is</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir I. Levenshtein. 1966. Binary Codes Capable of Correcting Deletions, Insertions and Reversals. In Soviet physics doklady, volume 10, page 707.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mu Li</author>
<author>Muhua Zhu</author>
<author>Yang Zhang</author>
<author>Ming Zhou</author>
</authors>
<title>Exploring Distributional Similarity Based Models for Query Spelling Correction.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1025--1032</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="7448" citStr="Li et al., 2006" startWordPosition="1187" endWordPosition="1190"> for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHAN Workshop on Chinese Language Processing (Yu et al., 2013) held a shared task on Chinese spell checking. Various approaches were made for the task including language model (LM) based methods (Chen et al., 2013), ME model (Han and Chang, 2013), CRF (Wang et al., 2013d; Wang et al., 2013a), S</context>
</contexts>
<marker>Li, Zhu, Zhang, Zhou, 2006</marker>
<rawString>Mu Li, Muhua Zhu, Yang Zhang, and Ming Zhou. 2006. Exploring Distributional Similarity Based Models for Query Spelling Correction. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 1025–1032, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu Li</author>
<author>Xuan Wang</author>
<author>Xiao-Long Wang</author>
<author>Yan-Bing Yu</author>
</authors>
<title>A Conditional Random Fields Approach to Chinese Pinyin-to-Character Conversion.</title>
<date>2009</date>
<journal>Journal of Communication and Computer,</journal>
<volume>6</volume>
<issue>4</issue>
<contexts>
<context position="7034" citStr="Li et al., 2009" startWordPosition="1115" endWordPosition="1118">sing noisy channel error model and language-specific features. However their model depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tabl</context>
</contexts>
<marker>Li, Wang, Wang, Yu, 2009</marker>
<rawString>Lu Li, Xuan Wang, Xiao-Long Wang, and Yan-Bing Yu. 2009. A Conditional Random Fields Approach to Chinese Pinyin-to-Character Conversion. Journal of Communication and Computer, 6(4):25–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodong Liu</author>
<author>Kevin Cheng</author>
<author>Yanyan Luo</author>
<author>Kevin Duh</author>
<author>Yuji Matsumoto</author>
</authors>
<title>A Hybrid Chinese Spelling Correction Using Language Model and Statistical Machine Translation with Reranking.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>54--58</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="8088" citStr="Liu et al., 2013" startWordPosition="1293" endWordPosition="1296">l similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHAN Workshop on Chinese Language Processing (Yu et al., 2013) held a shared task on Chinese spell checking. Various approaches were made for the task including language model (LM) based methods (Chen et al., 2013), ME model (Han and Chang, 2013), CRF (Wang et al., 2013d; Wang et al., 2013a), SMT (Chiu et al., 2013; Liu et al., 2013), and graph model (Jia et al., 2013), etc. 3 Pinyin Input Method Model 3.1 From English Letter to Chinese Sentence It is a rather long journey from the first English letter typed on the keyboard to finally a completed Chinese sentence generated by IME. We will first take an overview of the entire process. The average length of pinyin syllables is about 3 letters. There are about 410 pinyin syllables used in the current pinyin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The number of those homo</context>
</contexts>
<marker>Liu, Cheng, Luo, Duh, Matsumoto, 2013</marker>
<rawString>Xiaodong Liu, Kevin Cheng, Yanyan Luo, Kevin Duh, and Yuji Matsumoto. 2013. A Hybrid Chinese Spelling Correction Using Language Model and Statistical Machine Translation with Reranking. In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 54–58, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Scott MacKenzie</author>
<author>R William Soukoreff</author>
</authors>
<title>A Character-level Error Analysis Technique for Evaluating Text Entry Methods.</title>
<date>2002</date>
<booktitle>In Proceedings of the Second Nordic Conference on Human-computer Interaction, NordiCHI ’02,</booktitle>
<pages>243--246</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="26759" citStr="MacKenzie and Soukoreff, 2002" startWordPosition="4566" endWordPosition="4570"> sunpinyin 52.37 87.51 13.95 Google 74.74 94.81 40.2 Yang-ME - 93.3 30.2 Yang-MT - 95.5 45.4 Table 2: Baseline system compared to other IMEs (%) 4.4 PTC Conversion with Typo Correction Based upon the baseline system, we build the joint system of PTC conversion with typo correction. We simulate user typos by randomly generating errors automatically on the corpus. The typo rate is set according to previous Human-Computer Interaction (HCI) studies. Due to few works have been done on modeling Chinese text entry, we have to refer to those corresponding results on English (Wobbrock and Myers, 2006; MacKenzie and Soukoreff, 2002; Clarkson et al., 2005), which show that the average typo rate is about 2%. (Zheng et al., 2011a) performed an experiment that 2,000 sentences of 11,968 Chinese words were entered by 5 native speakers. The collected data consists of 775 mistyped pinyin words caused by one edit operation, and 85 caused by two edit operations. As we observe on TRAIN that the average pinyin word length is 5.24, then typo rate in the experiment of (Zheng et al., 2011a) can be roughly estimated as: 775 + 85 x 2 11968 x 5.24 which is similar to the conclusion on English. Thus we generate corpora from DEV with typo </context>
</contexts>
<marker>MacKenzie, Soukoreff, 2002</marker>
<rawString>I. Scott MacKenzie and R. William Soukoreff. 2002. A Character-level Error Analysis Technique for Evaluating Text Entry Methods. In Proceedings of the Second Nordic Conference on Human-computer Interaction, NordiCHI ’02, pages 243–246, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Mays</author>
<author>Fred J Damerau</author>
<author>Robert L Mercer</author>
</authors>
<title>Context Based Spelling Correction.</title>
<date>1991</date>
<journal>Information Processing &amp; Management,</journal>
<volume>27</volume>
<issue>5</issue>
<contexts>
<context position="7246" citStr="Mays et al., 1991" startWordPosition="1150" endWordPosition="1153">assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHAN Workshop on Chinese Language Processing (Yu et al., 2013) held a shared task on Chinese </context>
</contexts>
<marker>Mays, Damerau, Mercer, 1991</marker>
<rawString>Eric Mays, Fred J Damerau, and Robert L Mercer. 1991. Context Based Spelling Correction. Information Processing &amp; Management, 27(5):517–522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James L Peterson</author>
</authors>
<title>Computer Programs for Detecting and Correcting Spelling Errors.</title>
<date>1980</date>
<journal>Commun. ACM,</journal>
<volume>23</volume>
<issue>12</issue>
<contexts>
<context position="7225" citStr="Peterson, 1980" startWordPosition="1148" endWordPosition="1149">by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHAN Workshop on Chinese Language Processing (Yu et al., 2013) held a sh</context>
</contexts>
<marker>Peterson, 1980</marker>
<rawString>James L. Peterson. 1980. Computer Programs for Detecting and Correcting Spelling Errors. Commun. ACM, 23(12):676–687, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM-An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the international conference on spoken language processing,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<contexts>
<context position="21643" citStr="Stolcke, 2002" startWordPosition="3724" endWordPosition="3725">edge between them, the vertices in G also have an edge: E = {E(Vi,j — Vj+1,k)|E(Si,j — Sj+1,k) E Gc}. Table 1: Data set size 3.5 K-Shortest Paths To reduce the scale of graph G, we filter graph Gc by searching its K-shortest paths first to get G′c and construct G on top of G′c. Figure 5 shows the 3- shortest paths filtered graph G′c and Figure 6 shows the corresponding G for our running example. The scale of graph may be thus drastically reduced. Figure 5: K-shortest paths in typo correction An efficient heap data structure is required in K-shortest paths algorithm (Eppstein, 1998) for SRILM (Stolcke, 2002) is adopted for language model training and KenLM (Heafield, 2011; Heafield et al., 2013) for language model query. The Chinese part of the corpus is segmented into words before LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IME, to label the 1http://co</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM-An Extensible Language Modeling Toolkit. In Proceedings of the international conference on spoken language processing, volume 2, pages 901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew J Viterbi</author>
</authors>
<title>Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm. Information Theory,</title>
<date>1967</date>
<journal>IEEE Transactions on,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="5804" citStr="Viterbi, 1967" startWordPosition="918" endWordPosition="919">d correction has an important impact on IME performance. When IME fails to correct a typo and generate the expected sentence, the user will have to take much extra effort to move the cursor back to the mistyped letter and correct it, which leads to very poor user experience (Jia and Zhao, 2013). 2 Related Works The very first approach for Chinese input with typo correction was made by (Chen and Lee, 2000), which was also the initial attempt of “sentence-based” IME. The idea of “statistical input method” was proposed by modeling PTC conversion as a hidden Markov model (HMM), and using Viterbi (Viterbi, 1967) algorithm to decode the sequence. They solved the typo correction problem by decomposing the conditional probability P(HIP) of Chinese character sequence H given pinyin sequence P into a language model P(wi|wi_1) and a typing model P(pi|wi). The typing model that was estimated on real user input data was for typo correction. However, real user input data can be very noisy and not very convenient to obtain. As we will propose a joint model in this paper, such an individual typing model is not necessarily built in our approach. (Zheng et al., 2011a) developed an IME system with typo correction </context>
<context position="16013" citStr="Viterbi, 1967" startWordPosition="2689" endWordPosition="2690">P(S|W) = arg max W The vertex weight is the Levenshtein distance P(S) multiply by a normalization parameter: = arg max P(W)P(S|W) W wS′i,; = Q ∑ j L(S′k, Sk). = arg max ∏ ∏P(wi|wi−1) P(si|wi) k−i w1,ww,...,wM wi wi 1515 In the HMM for pinyin IME, observation states are pinyin syllables, hidden states are Chinese words, emission probability is P(si|wi), and transition probability is P(wi|wi−1). Note the transition probability is the conditional probability between words instead of characters. PTC conversion is to decode the Chinese word sequence from the pinyin sequence. The Viterbi algorithm (Viterbi, 1967) is used for the decoding. The shortest path algorithm for typo correction and Viterbi algorithm for PTC conversion are very closely related. It has been strictly proven by (Forney, 1973) that the sequence decoding problem on HMM is formally identical to finding a shortest path on a certain graph, which can be constructed in the following manner. Consider a first order HMM with all possible observations ® = {o1, o2, ... , oM}, hidden states S = {s1, s2,... , sN}, a special start state s0, emission probabilities (Esi,ok) = P(ok|si), transition probabilities (Tsi,sj) = P(sj|si), and start probab</context>
</contexts>
<marker>Viterbi, 1967</marker>
<rawString>Andrew J. Viterbi. 1967. Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm. Information Theory, IEEE Transactions on, 13(2):260–269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuan Wang</author>
<author>Lu Li</author>
<author>Lin Yao</author>
<author>Waqas Anwar</author>
</authors>
<title>A Maximum Entropy Approach to Chinese Pin YinTo-Character Conversion.</title>
<date>2006</date>
<booktitle>In Systems, Man and Cybernetics,</booktitle>
<volume>4</volume>
<pages>2956--2959</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6984" citStr="Wang et al., 2006" startWordPosition="1107" endWordPosition="1110">ed an IME system with typo correction called CHIME using noisy channel error model and language-specific features. However their model depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking cou</context>
</contexts>
<marker>Wang, Li, Yao, Anwar, 2006</marker>
<rawString>Xuan Wang, Lu Li, Lin Yao, and Waqas Anwar. 2006. A Maximum Entropy Approach to Chinese Pin YinTo-Character Conversion. In Systems, Man and Cybernetics, 2006. SMC’06. IEEE International Conference on, volume 4, pages 2956–2959. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chun-Hung Wang</author>
<author>Jason S Chang</author>
<author>Jian-Cheng Wu</author>
</authors>
<title>Automatic Chinese Confusion Words Extraction Using Conditional Random Fields and the Web.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>64--68</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="7115" citStr="Wang et al., 2013" startWordPosition="1128" endWordPosition="1131">el depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters we</context>
<context position="21962" citStr="Wang et al., 2013" startWordPosition="3777" endWordPosition="3780">filtered graph G′c and Figure 6 shows the corresponding G for our running example. The scale of graph may be thus drastically reduced. Figure 5: K-shortest paths in typo correction An efficient heap data structure is required in K-shortest paths algorithm (Eppstein, 1998) for SRILM (Stolcke, 2002) is adopted for language model training and KenLM (Heafield, 2011; Heafield et al., 2013) for language model query. The Chinese part of the corpus is segmented into words before LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IME, to label the 1http://code.google.com/p/sunpinyin/ mi huo zhi ni hao shi ji jie a 1517 vocabulary V with pinyin. The emission probabilities are estimated using the lexical translation module of MOSES (Koehn et al., 2007) as “translation probability” from pinyin to Chinese. 4.2 Evaluation Metrics We will use conventional sequence labeling eva</context>
</contexts>
<marker>Wang, Chang, Wu, 2013</marker>
<rawString>Chun-Hung Wang, Jason S. Chang, and Jian-Cheng Wu. 2013a. Automatic Chinese Confusion Words Extraction Using Conditional Random Fields and the Web. In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 64– 68, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peilu Wang</author>
<author>Ruihua Sun</author>
<author>Hai Zhao</author>
<author>Kai Yu</author>
</authors>
<title>A New Word Language Model Evaluation Metric for Character Based Languages.</title>
<date>2013</date>
<booktitle>In Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data,</booktitle>
<pages>315--324</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="7115" citStr="Wang et al., 2013" startWordPosition="1128" endWordPosition="1131">el depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters we</context>
<context position="21962" citStr="Wang et al., 2013" startWordPosition="3777" endWordPosition="3780">filtered graph G′c and Figure 6 shows the corresponding G for our running example. The scale of graph may be thus drastically reduced. Figure 5: K-shortest paths in typo correction An efficient heap data structure is required in K-shortest paths algorithm (Eppstein, 1998) for SRILM (Stolcke, 2002) is adopted for language model training and KenLM (Heafield, 2011; Heafield et al., 2013) for language model query. The Chinese part of the corpus is segmented into words before LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IME, to label the 1http://code.google.com/p/sunpinyin/ mi huo zhi ni hao shi ji jie a 1517 vocabulary V with pinyin. The emission probabilities are estimated using the lexical translation module of MOSES (Koehn et al., 2007) as “translation probability” from pinyin to Chinese. 4.2 Evaluation Metrics We will use conventional sequence labeling eva</context>
</contexts>
<marker>Wang, Sun, Zhao, Yu, 2013</marker>
<rawString>Peilu Wang, Ruihua Sun, Hai Zhao, and Kai Yu. 2013b. A New Word Language Model Evaluation Metric for Character Based Languages. In Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data, pages 315–324. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Wang</author>
<author>Masao Utiyama</author>
<author>Isao Goto</author>
<author>Eiichro Sumita</author>
<author>Hai Zhao</author>
<author>Bao-Liang Lu</author>
</authors>
<title>Converting Continuous-Space Language Models into N-Gram Language Models for Statistical Machine Translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>845--850</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="7115" citStr="Wang et al., 2013" startWordPosition="1128" endWordPosition="1131">el depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters we</context>
<context position="21962" citStr="Wang et al., 2013" startWordPosition="3777" endWordPosition="3780">filtered graph G′c and Figure 6 shows the corresponding G for our running example. The scale of graph may be thus drastically reduced. Figure 5: K-shortest paths in typo correction An efficient heap data structure is required in K-shortest paths algorithm (Eppstein, 1998) for SRILM (Stolcke, 2002) is adopted for language model training and KenLM (Heafield, 2011; Heafield et al., 2013) for language model query. The Chinese part of the corpus is segmented into words before LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IME, to label the 1http://code.google.com/p/sunpinyin/ mi huo zhi ni hao shi ji jie a 1517 vocabulary V with pinyin. The emission probabilities are estimated using the lexical translation module of MOSES (Koehn et al., 2007) as “translation probability” from pinyin to Chinese. 4.2 Evaluation Metrics We will use conventional sequence labeling eva</context>
</contexts>
<marker>Wang, Utiyama, Goto, Sumita, Zhao, Lu, 2013</marker>
<rawString>Rui Wang, Masao Utiyama, Isao Goto, Eiichro Sumita, Hai Zhao, and Bao-Liang Lu. 2013c. Converting Continuous-Space Language Models into N-Gram Language Models for Statistical Machine Translation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 845–850, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yih-Ru Wang</author>
<author>Yuan-Fu Liao</author>
<author>Yeh-Kuang Wu</author>
<author>Liang-Chun Chang</author>
</authors>
<title>Conditional Random Field-based Parser and Language Model for Traditional Chinese Spelling Checker.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>69--73</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="7115" citStr="Wang et al., 2013" startWordPosition="1128" endWordPosition="1131">el depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters we</context>
<context position="21962" citStr="Wang et al., 2013" startWordPosition="3777" endWordPosition="3780">filtered graph G′c and Figure 6 shows the corresponding G for our running example. The scale of graph may be thus drastically reduced. Figure 5: K-shortest paths in typo correction An efficient heap data structure is required in K-shortest paths algorithm (Eppstein, 1998) for SRILM (Stolcke, 2002) is adopted for language model training and KenLM (Heafield, 2011; Heafield et al., 2013) for language model query. The Chinese part of the corpus is segmented into words before LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IME, to label the 1http://code.google.com/p/sunpinyin/ mi huo zhi ni hao shi ji jie a 1517 vocabulary V with pinyin. The emission probabilities are estimated using the lexical translation module of MOSES (Koehn et al., 2007) as “translation probability” from pinyin to Chinese. 4.2 Evaluation Metrics We will use conventional sequence labeling eva</context>
</contexts>
<marker>Wang, Liao, Wu, Chang, 2013</marker>
<rawString>Yih-Ru Wang, Yuan-Fu Liao, Yeh-Kuang Wu, and Liang-Chun Chang. 2013d. Conditional Random Field-based Parser and Language Model for Traditional Chinese Spelling Checker. In Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 69–73, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob O Wobbrock</author>
<author>Brad A Myers</author>
</authors>
<title>Analyzing the Input Stream for Character- Level Errors in Unconstrained Text Entry Evaluations.</title>
<date>2006</date>
<journal>ACM Trans. Comput.-Hum. Interact.,</journal>
<volume>13</volume>
<issue>4</issue>
<contexts>
<context position="26728" citStr="Wobbrock and Myers, 2006" startWordPosition="4562" endWordPosition="4565">Baseline 73.39 96.24 38.00 sunpinyin 52.37 87.51 13.95 Google 74.74 94.81 40.2 Yang-ME - 93.3 30.2 Yang-MT - 95.5 45.4 Table 2: Baseline system compared to other IMEs (%) 4.4 PTC Conversion with Typo Correction Based upon the baseline system, we build the joint system of PTC conversion with typo correction. We simulate user typos by randomly generating errors automatically on the corpus. The typo rate is set according to previous Human-Computer Interaction (HCI) studies. Due to few works have been done on modeling Chinese text entry, we have to refer to those corresponding results on English (Wobbrock and Myers, 2006; MacKenzie and Soukoreff, 2002; Clarkson et al., 2005), which show that the average typo rate is about 2%. (Zheng et al., 2011a) performed an experiment that 2,000 sentences of 11,968 Chinese words were entered by 5 native speakers. The collected data consists of 775 mistyped pinyin words caused by one edit operation, and 85 caused by two edit operations. As we observe on TRAIN that the average pinyin word length is 5.24, then typo rate in the experiment of (Zheng et al., 2011a) can be roughly estimated as: 775 + 85 x 2 11968 x 5.24 which is similar to the conclusion on English. Thus we gener</context>
</contexts>
<marker>Wobbrock, Myers, 2006</marker>
<rawString>Jacob O. Wobbrock and Brad A. Myers. 2006. Analyzing the Input Stream for Character- Level Errors in Unconstrained Text Entry Evaluations. ACM Trans. Comput.-Hum. Interact., 13(4):458–489, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Wu</author>
<author>Liren Chen</author>
</authors>
<title>Fault-tolerant Romanized Input Method for Non-roman Characters,</title>
<date>2004</date>
<journal>US Patent App.</journal>
<pages>10--928</pages>
<contexts>
<context position="5115" citStr="Wu and Chen, 2004" startWordPosition="798" endWordPosition="801"> input the completely right pinyin simply because he/she is a dialect speaker and does not know the exact pronunciation for the expected character. This may be a very common situation since there are about seven quite different dialects in Chinese, among which being spoken languages, six are far different from the standard modern Chinese, mandarin. With the boom of smart-phones, pinyin typos worsen due to the limited size of soft keyboard, and the lack of physical feedback on the touch screen. However, existing practical IMEs only provide small patches to deal with typos such as Fuzzy Pinyin (Wu and Chen, 2004) and other language specific errors (Zheng et al., 2011b). Typo checking and correction has an important impact on IME performance. When IME fails to correct a typo and generate the expected sentence, the user will have to take much extra effort to move the cursor back to the mistyped letter and correct it, which leads to very poor user experience (Jia and Zhao, 2013). 2 Related Works The very first approach for Chinese input with typo correction was made by (Chen and Lee, 2000), which was also the initial attempt of “sentence-based” IME. The idea of “statistical input method” was proposed by </context>
</contexts>
<marker>Wu, Chen, 2004</marker>
<rawString>Jun Wu and Liren Chen. 2004. Fault-tolerant Romanized Input Method for Non-roman Characters, August 25. US Patent App. 10/928,131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Wu</author>
<author>Hulcan Zhu</author>
<author>Hongjun Zhu</author>
</authors>
<title>Systems and Methods for Translating Chinese Pinyin to Chinese Characters,</title>
<date>2009</date>
<tech>US Patent 7,478,033.</tech>
<contexts>
<context position="4402" citStr="Wu et al., 2009" startWordPosition="675" endWordPosition="678">ting of the Association for Computational Linguistics, pages 1512–1523, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics movement, deletion and re-typing. Thus there are two separated sub-tasks for Chinese spell checking: 1. typo checking for user typed pinyin sequences which should be a built-in module in IME, and 2. spell checking for Chinese texts in its narrow sense, which is typically a module of word processing applications (Yang et al., 2012b). These two terms are often confused especially in IME related works such as (Chen and Lee, 2000) and (Wu et al., 2009). Pinyin typos have always been a serious problem for Chinese pinyin IMEs. The user may fail to input the completely right pinyin simply because he/she is a dialect speaker and does not know the exact pronunciation for the expected character. This may be a very common situation since there are about seven quite different dialects in Chinese, among which being spoken languages, six are far different from the standard modern Chinese, mandarin. With the boom of smart-phones, pinyin typos worsen due to the limited size of soft keyboard, and the lack of physical feedback on the touch screen. Howeve</context>
</contexts>
<marker>Wu, Zhu, Zhu, 2009</marker>
<rawString>Jun Wu, Hulcan Zhu, and Hongjun Zhu. 2009. Systems and Methods for Translating Chinese Pinyin to Chinese Characters, January 13. US Patent 7,478,033.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shaohua Yang</author>
<author>Hai Zhao</author>
<author>Bao-liang Lu</author>
</authors>
<title>A Machine Translation Approach for Chinese WholeSentence Pinyin-to-Character Conversion.</title>
<date>2012</date>
<booktitle>In Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation,</booktitle>
<pages>333--342</pages>
<institution>Faculty of Computer Science, Universitas Indonesia.</institution>
<location>Bali,Indonesia,</location>
<contexts>
<context position="4281" citStr="Yang et al., 2012" startWordPosition="653" endWordPosition="656">ake corrections, which usually means doing a bunch of extra operations like cursor 1512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1512–1523, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics movement, deletion and re-typing. Thus there are two separated sub-tasks for Chinese spell checking: 1. typo checking for user typed pinyin sequences which should be a built-in module in IME, and 2. spell checking for Chinese texts in its narrow sense, which is typically a module of word processing applications (Yang et al., 2012b). These two terms are often confused especially in IME related works such as (Chen and Lee, 2000) and (Wu et al., 2009). Pinyin typos have always been a serious problem for Chinese pinyin IMEs. The user may fail to input the completely right pinyin simply because he/she is a dialect speaker and does not know the exact pronunciation for the expected character. This may be a very common situation since there are about seven quite different dialects in Chinese, among which being spoken languages, six are far different from the standard modern Chinese, mandarin. With the boom of smart-phones, pi</context>
<context position="7095" citStr="Yang et al., 2012" startWordPosition="1124" endWordPosition="1127">s. However their model depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-metho</context>
<context position="10051" citStr="Yang et al., 2012" startWordPosition="1633" endWordPosition="1636">esponding words in a dictionary and generates a sentence with the candidate words. ble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previous spell checking methods for English to pinyin typo checking, although techniques for English spell checking have been well developed. A bit confusing but interesting, pinyin typo correction and segmentation come as two sides of one problem: when a pinyin sequence is mistyped, it is unlikely to be correctly segmented; when it is segmented in an awkward way, it is likely to be mistyped. Inspired by (Yang et al., 2012b) and (Jia et al., 2013), we adopt the graph model for Chinese spell checking for pinyin segmentation and typo correction, which is based on the shortest path word segmentation algorithm (Casey and Lecolinet, 1996). The model has two major steps: segmentation and correction. 3.2.1 Pinyin Segmentation The shortest path segmentation algorithm is based on the idea that a reasonable segmentation should minimize the number of segmented units. For a pinyin sequence p1pe ... pL, where pi is a letter, first a directed acyclic graph (DAG) GS = (V, E) is built for pinyin segmentation step. The vertex s</context>
<context position="20357" citStr="Yang et al., 2012" startWordPosition="3476" endWordPosition="3479"> heap is implemented as a priority queue of size K sorted according to path length that should support efficient push and pop operations. Fibonacci heap (Fredman and Tarjan, 1987) is adopted for the heap implementation since it has a push complexity of O(1) which is better than the O(K) for other heap structures. Another benefit provided by K-shortest paths is that it can be used for generating N-best candidates of PTC conversion, which may be helpful for further performance improvement. 4 Experiments 4.1 Corpora, Tools and Experiment Settings The corpus for evaluation is the one provided in (Yang et al., 2012a), which is originally extracted from the People’s Daily corpus and labeled with pinyin. The corpus has already been split into training TRAIN, development DEV and test TEST sets as shown in Table 1. TRAIN DEV TEST #Sentence 1M 2K 100K #character 43,679,593 83,765 4,123,184 ... 或活火 huo ... 还海 ma hai mi ... 你呢呢 ni ... 米迷 ... ti... pao zhi. ... 好好豪 hao ... 吗嘛妈 mi’huo ni’hao ... ... 迷惑 至极 zhi&apos;ji ... 你好 束书数 shu ... 赛塞鳃 sai ... ... 世事 及几 shi ji ... shuai shi&apos;jie ... 帅甩摔 ... 句局 ju jie jia 接姐节 ... 家加 世界 w e a... ... 饿额 ... mi米迷 ... 你呢呢 ni ... 迷惑 mi’huo zhi&apos;ji ni’hao huo zhi ... ji ...a... ... shi&apos;ji</context>
</contexts>
<marker>Yang, Zhao, Lu, 2012</marker>
<rawString>Shaohua Yang, Hai Zhao, and Bao-liang Lu. 2012a. A Machine Translation Approach for Chinese WholeSentence Pinyin-to-Character Conversion. In Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation, pages 333– 342, Bali,Indonesia, November. Faculty of Computer Science, Universitas Indonesia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shaohua Yang</author>
<author>Hai Zhao</author>
<author>Xiaolin Wang</author>
<author>Bao-liang Lu</author>
</authors>
<title>Spell Checking for Chinese.</title>
<date>2012</date>
<booktitle>In International Conference on Language Resources and Evaluation,</booktitle>
<pages>730--736</pages>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="4281" citStr="Yang et al., 2012" startWordPosition="653" endWordPosition="656">ake corrections, which usually means doing a bunch of extra operations like cursor 1512 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1512–1523, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics movement, deletion and re-typing. Thus there are two separated sub-tasks for Chinese spell checking: 1. typo checking for user typed pinyin sequences which should be a built-in module in IME, and 2. spell checking for Chinese texts in its narrow sense, which is typically a module of word processing applications (Yang et al., 2012b). These two terms are often confused especially in IME related works such as (Chen and Lee, 2000) and (Wu et al., 2009). Pinyin typos have always been a serious problem for Chinese pinyin IMEs. The user may fail to input the completely right pinyin simply because he/she is a dialect speaker and does not know the exact pronunciation for the expected character. This may be a very common situation since there are about seven quite different dialects in Chinese, among which being spoken languages, six are far different from the standard modern Chinese, mandarin. With the boom of smart-phones, pi</context>
<context position="7095" citStr="Yang et al., 2012" startWordPosition="1124" endWordPosition="1127">s. However their model depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-metho</context>
<context position="10051" citStr="Yang et al., 2012" startWordPosition="1633" endWordPosition="1636">esponding words in a dictionary and generates a sentence with the candidate words. ble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previous spell checking methods for English to pinyin typo checking, although techniques for English spell checking have been well developed. A bit confusing but interesting, pinyin typo correction and segmentation come as two sides of one problem: when a pinyin sequence is mistyped, it is unlikely to be correctly segmented; when it is segmented in an awkward way, it is likely to be mistyped. Inspired by (Yang et al., 2012b) and (Jia et al., 2013), we adopt the graph model for Chinese spell checking for pinyin segmentation and typo correction, which is based on the shortest path word segmentation algorithm (Casey and Lecolinet, 1996). The model has two major steps: segmentation and correction. 3.2.1 Pinyin Segmentation The shortest path segmentation algorithm is based on the idea that a reasonable segmentation should minimize the number of segmented units. For a pinyin sequence p1pe ... pL, where pi is a letter, first a directed acyclic graph (DAG) GS = (V, E) is built for pinyin segmentation step. The vertex s</context>
<context position="20357" citStr="Yang et al., 2012" startWordPosition="3476" endWordPosition="3479"> heap is implemented as a priority queue of size K sorted according to path length that should support efficient push and pop operations. Fibonacci heap (Fredman and Tarjan, 1987) is adopted for the heap implementation since it has a push complexity of O(1) which is better than the O(K) for other heap structures. Another benefit provided by K-shortest paths is that it can be used for generating N-best candidates of PTC conversion, which may be helpful for further performance improvement. 4 Experiments 4.1 Corpora, Tools and Experiment Settings The corpus for evaluation is the one provided in (Yang et al., 2012a), which is originally extracted from the People’s Daily corpus and labeled with pinyin. The corpus has already been split into training TRAIN, development DEV and test TEST sets as shown in Table 1. TRAIN DEV TEST #Sentence 1M 2K 100K #character 43,679,593 83,765 4,123,184 ... 或活火 huo ... 还海 ma hai mi ... 你呢呢 ni ... 米迷 ... ti... pao zhi. ... 好好豪 hao ... 吗嘛妈 mi’huo ni’hao ... ... 迷惑 至极 zhi&apos;ji ... 你好 束书数 shu ... 赛塞鳃 sai ... ... 世事 及几 shi ji ... shuai shi&apos;jie ... 帅甩摔 ... 句局 ju jie jia 接姐节 ... 家加 世界 w e a... ... 饿额 ... mi米迷 ... 你呢呢 ni ... 迷惑 mi’huo zhi&apos;ji ni’hao huo zhi ... ji ...a... ... shi&apos;ji</context>
</contexts>
<marker>Yang, Zhao, Wang, Lu, 2012</marker>
<rawString>Shaohua Yang, Hai Zhao, Xiaolin Wang, and Bao-liang Lu. 2012b. Spell Checking for Chinese. In International Conference on Language Resources and Evaluation, pages 730–736, Istanbul, Turkey, May.</rawString>
</citation>
<citation valid="true">
<date>2013</date>
<booktitle>Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing. Asian Federation of Natural Language Processing,</booktitle>
<editor>Liang-Chih Yu, Yuen-Hsien Tseng, Jingbo Zhu, and Fuji Ren, editors.</editor>
<location>Nagoya, Japan,</location>
<marker>2013</marker>
<rawString>Liang-Chih Yu, Yuen-Hsien Tseng, Jingbo Zhu, and Fuji Ren, editors. 2013. Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing. Asian Federation of Natural Language Processing, Nagoya, Japan, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jingyi Zhang</author>
<author>Hai Zhao</author>
</authors>
<title>Improving Function Word Alignment with Frequency and Syntactic Information.</title>
<date>2013</date>
<booktitle>In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence,</booktitle>
<pages>2211--2217</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="7139" citStr="Zhang and Zhao, 2013" startWordPosition="1132" endWordPosition="1135">y strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly. Besides the common HMM approach for PTC conversion, there are also various methods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc. Spell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries. Early attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recent</context>
</contexts>
<marker>Zhang, Zhao, 2013</marker>
<rawString>Jingyi Zhang and Hai Zhao. 2013. Improving Function Word Alignment with Frequency and Syntactic Information. In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, pages 2211–2217. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Chunyu Kit</author>
</authors>
<title>Exploiting Unlabeled Text with Different Unsupervised Segmentation Criteria for Chinese Word Segmentation.</title>
<date>2008</date>
<journal>Research in Computing Science,</journal>
<pages>33--93</pages>
<contexts>
<context position="9073" citStr="Zhao and Kit, 2008" startWordPosition="1468" endWordPosition="1471">here are about 410 pinyin syllables used in the current pinyin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The number of those homophones ranges from 1 to over 300. Chinese characters then form words. But word in Chinese is a rather vague concept. Without word delimiters, linguists have argued on what a Chinese word really is for a long time and that is why there is always a primary word segmentation treatment in most Chinese language processing tasks (Zhao et al., 2006; Huang and Zhao, 2007; Zhao and Kit, 2008; Zhao et al., 2010; Zhao and Kit, 2011; Zhao et al., 2013). A Chinese word may contain from 1 to over 10 characters due to different word segmentation conventions. Figure 1 demonstrates the relationship of pinyin and word, from pinyin letters “nihao” to the word “你好 (hello)”. Typically, an IME takes the pinyin input, segments it into syllables, looks up corresponding words in a dictionary and generates a sentence with the candidate words. ble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previous spell checking methods for English to p</context>
</contexts>
<marker>Zhao, Kit, 2008</marker>
<rawString>Hai Zhao and Chunyu Kit. 2008. Exploiting Unlabeled Text with Different Unsupervised Segmentation Criteria for Chinese Word Segmentation. Research in Computing Science, 33:93–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Chunyu Kit</author>
</authors>
<title>Integrating Unsupervised and Supervised Word Segmentation: The Role of Goodness Measures.</title>
<date>2011</date>
<journal>Information Sciences,</journal>
<volume>181</volume>
<issue>1</issue>
<contexts>
<context position="9112" citStr="Zhao and Kit, 2011" startWordPosition="1476" endWordPosition="1479">d in the current pinyin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The number of those homophones ranges from 1 to over 300. Chinese characters then form words. But word in Chinese is a rather vague concept. Without word delimiters, linguists have argued on what a Chinese word really is for a long time and that is why there is always a primary word segmentation treatment in most Chinese language processing tasks (Zhao et al., 2006; Huang and Zhao, 2007; Zhao and Kit, 2008; Zhao et al., 2010; Zhao and Kit, 2011; Zhao et al., 2013). A Chinese word may contain from 1 to over 10 characters due to different word segmentation conventions. Figure 1 demonstrates the relationship of pinyin and word, from pinyin letters “nihao” to the word “你好 (hello)”. Typically, an IME takes the pinyin input, segments it into syllables, looks up corresponding words in a dictionary and generates a sentence with the candidate words. ble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previous spell checking methods for English to pinyin typo checking, although technique</context>
</contexts>
<marker>Zhao, Kit, 2011</marker>
<rawString>Hai Zhao and Chunyu Kit. 2011. Integrating Unsupervised and Supervised Word Segmentation: The Role of Goodness Measures. Information Sciences, 181(1):163–183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Chang-Ning Huang</author>
<author>Mu Li</author>
</authors>
<title>An Improved Chinese Word Segmentation System with Conditional Random Field.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>162--165</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="9031" citStr="Zhao et al., 2006" startWordPosition="1460" endWordPosition="1463">of pinyin syllables is about 3 letters. There are about 410 pinyin syllables used in the current pinyin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The number of those homophones ranges from 1 to over 300. Chinese characters then form words. But word in Chinese is a rather vague concept. Without word delimiters, linguists have argued on what a Chinese word really is for a long time and that is why there is always a primary word segmentation treatment in most Chinese language processing tasks (Zhao et al., 2006; Huang and Zhao, 2007; Zhao and Kit, 2008; Zhao et al., 2010; Zhao and Kit, 2011; Zhao et al., 2013). A Chinese word may contain from 1 to over 10 characters due to different word segmentation conventions. Figure 1 demonstrates the relationship of pinyin and word, from pinyin letters “nihao” to the word “你好 (hello)”. Typically, an IME takes the pinyin input, segments it into syllables, looks up corresponding words in a dictionary and generates a sentence with the candidate words. ble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previo</context>
</contexts>
<marker>Zhao, Huang, Li, 2006</marker>
<rawString>Hai Zhao, Chang-Ning Huang, and Mu Li. 2006. An Improved Chinese Word Segmentation System with Conditional Random Field. In Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 162–165, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Chang-Ning Huang</author>
<author>Mu Li</author>
<author>Bao-Liang Lu</author>
</authors>
<title>A Unified Character-Based Tagging Framework for Chinese Word Segmentation.</title>
<date>2010</date>
<journal>ACM Transactions on Asian Language Information Processing (TALIP),</journal>
<volume>9</volume>
<issue>2</issue>
<contexts>
<context position="9092" citStr="Zhao et al., 2010" startWordPosition="1472" endWordPosition="1475">inyin syllables used in the current pinyin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The number of those homophones ranges from 1 to over 300. Chinese characters then form words. But word in Chinese is a rather vague concept. Without word delimiters, linguists have argued on what a Chinese word really is for a long time and that is why there is always a primary word segmentation treatment in most Chinese language processing tasks (Zhao et al., 2006; Huang and Zhao, 2007; Zhao and Kit, 2008; Zhao et al., 2010; Zhao and Kit, 2011; Zhao et al., 2013). A Chinese word may contain from 1 to over 10 characters due to different word segmentation conventions. Figure 1 demonstrates the relationship of pinyin and word, from pinyin letters “nihao” to the word “你好 (hello)”. Typically, an IME takes the pinyin input, segments it into syllables, looks up corresponding words in a dictionary and generates a sentence with the candidate words. ble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previous spell checking methods for English to pinyin typo checking</context>
</contexts>
<marker>Zhao, Huang, Li, Lu, 2010</marker>
<rawString>Hai Zhao, Chang-Ning Huang, Mu Li, and Bao-Liang Lu. 2010. A Unified Character-Based Tagging Framework for Chinese Word Segmentation. ACM Transactions on Asian Language Information Processing (TALIP), 9(2):5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Masao Utiyama</author>
<author>Eiichiro Sumita</author>
<author>BaoLiang Lu</author>
</authors>
<title>An Empirical Study on Word Segmentation for Chinese Machine Translation.</title>
<date>2013</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>248--263</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="9132" citStr="Zhao et al., 2013" startWordPosition="1480" endWordPosition="1483">yin system. Each pinyin sylla1513 ble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The number of those homophones ranges from 1 to over 300. Chinese characters then form words. But word in Chinese is a rather vague concept. Without word delimiters, linguists have argued on what a Chinese word really is for a long time and that is why there is always a primary word segmentation treatment in most Chinese language processing tasks (Zhao et al., 2006; Huang and Zhao, 2007; Zhao and Kit, 2008; Zhao et al., 2010; Zhao and Kit, 2011; Zhao et al., 2013). A Chinese word may contain from 1 to over 10 characters due to different word segmentation conventions. Figure 1 demonstrates the relationship of pinyin and word, from pinyin letters “nihao” to the word “你好 (hello)”. Typically, an IME takes the pinyin input, segments it into syllables, looks up corresponding words in a dictionary and generates a sentence with the candidate words. ble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previous spell checking methods for English to pinyin typo checking, although techniques for English spell </context>
</contexts>
<marker>Zhao, Utiyama, Sumita, Lu, 2013</marker>
<rawString>Hai Zhao, Masao Utiyama, Eiichiro Sumita, and BaoLiang Lu. 2013. An Empirical Study on Word Segmentation for Chinese Machine Translation. In Computational Linguistics and Intelligent Text Processing, pages 248–263. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yabin Zheng</author>
<author>Chen Li</author>
<author>Maosong Sun</author>
</authors>
<title>CHIME: An Efficient Error-tolerant Chinese Pinyin Input Method.</title>
<date>2011</date>
<booktitle>In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence - Volume Volume Three, IJCAI’11,</booktitle>
<pages>2551--2556</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="5170" citStr="Zheng et al., 2011" startWordPosition="807" endWordPosition="810">e is a dialect speaker and does not know the exact pronunciation for the expected character. This may be a very common situation since there are about seven quite different dialects in Chinese, among which being spoken languages, six are far different from the standard modern Chinese, mandarin. With the boom of smart-phones, pinyin typos worsen due to the limited size of soft keyboard, and the lack of physical feedback on the touch screen. However, existing practical IMEs only provide small patches to deal with typos such as Fuzzy Pinyin (Wu and Chen, 2004) and other language specific errors (Zheng et al., 2011b). Typo checking and correction has an important impact on IME performance. When IME fails to correct a typo and generate the expected sentence, the user will have to take much extra effort to move the cursor back to the mistyped letter and correct it, which leads to very poor user experience (Jia and Zhao, 2013). 2 Related Works The very first approach for Chinese input with typo correction was made by (Chen and Lee, 2000), which was also the initial attempt of “sentence-based” IME. The idea of “statistical input method” was proposed by modeling PTC conversion as a hidden Markov model (HMM),</context>
<context position="23243" citStr="Zheng et al., 2011" startWordPosition="3986" endWordPosition="3989">y2. Chinese characters in a sentence may be separated by digits, punctuation and alphabets which are directly inputted without the IME. We follow the so-called term Max Input Unit (MIU), the longest consecutive Chinese character sequence proposed by (Jia and Zhao, 2013). We will mainly consider MIU accuracy (MIU-Acc) which is the ratio of the number of completely corrected generated MIUs over the number of all MIUs, and character accuracy (Ch-Acc), but the sentence accuracy (S-Acc) will also be reported in evaluation results. We will also report the conversion error rate (ConvER) proposed by (Zheng et al., 2011a), which is the ratio of the number of mistyped pinyin word that is not converted to the right Chinese word over the total number of mistyped pinyin words3. 4.3 Baseline System without Typo Correction Firstly we build a baseline system without typo correction which is a pipeline of pinyin syllable segmentation and PTC conversion. The baseline system takes a pinyin input sequence, segments it into syllables, and then converts it to Chinese character sequence. The pinyin syllable segmentation already has very high (over 98%) accuracy with a trigram LM using improved Kneser-Ney smoothing. Accord</context>
<context position="26855" citStr="Zheng et al., 2011" startWordPosition="4585" endWordPosition="4588">ine system compared to other IMEs (%) 4.4 PTC Conversion with Typo Correction Based upon the baseline system, we build the joint system of PTC conversion with typo correction. We simulate user typos by randomly generating errors automatically on the corpus. The typo rate is set according to previous Human-Computer Interaction (HCI) studies. Due to few works have been done on modeling Chinese text entry, we have to refer to those corresponding results on English (Wobbrock and Myers, 2006; MacKenzie and Soukoreff, 2002; Clarkson et al., 2005), which show that the average typo rate is about 2%. (Zheng et al., 2011a) performed an experiment that 2,000 sentences of 11,968 Chinese words were entered by 5 native speakers. The collected data consists of 775 mistyped pinyin words caused by one edit operation, and 85 caused by two edit operations. As we observe on TRAIN that the average pinyin word length is 5.24, then typo rate in the experiment of (Zheng et al., 2011a) can be roughly estimated as: 775 + 85 x 2 11968 x 5.24 which is similar to the conclusion on English. Thus we generate corpora from DEV with typo rate of 0% (0-P), 2% (2-P), and 5% (5-P) to evaluate the system. According to (Zheng et al., 201</context>
<context position="29770" citStr="Zheng et al., 2011" startWordPosition="5126" endWordPosition="5129">n and Google Input Tool. Since sunpinyin does not have typo correction module and performs much poorer than our baseline system, we do not include it in the comparison. Though no direct proofs can be found to indicate if Google Input Tool has an independent typo correction component, its outputs show that such a component is unlikely available. Since Google Input Tool has to be accessed through a web interface and the network connection cannot be guaranteed. we only take a subset of 10K sentences of TEST to perform the experiments, and the results are shown in Table 3. The scores reported in (Zheng et al., 2011a) are not listed in Table 4 since the data set is different. They reported a ConvER of 53.56%, which is given here for reference. Additionally, to further inspect the robustness of our model, performance with typo rate ranges from 0% to 5% is shown in Figure 12. Although the performance decreases while typo rate goes up, it is still quite satisfying around typo rate of 2% which is assumed to be the real world situation. MIU-Acc Ch-Acc S-Acc ConvER Baseline 0-P 79.90 97.47 48.87 - Baseline 2-P 50.47 90.53 11.12 99.95 Baseline 5-P 30.26 82.83 3.32 99.99 Google 0-P 79.08 95.26 46.83 - Google 2-P</context>
</contexts>
<marker>Zheng, Li, Sun, 2011</marker>
<rawString>Yabin Zheng, Chen Li, and Maosong Sun. 2011a. CHIME: An Efficient Error-tolerant Chinese Pinyin Input Method. In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence - Volume Volume Three, IJCAI’11, pages 2551–2556. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yabin Zheng</author>
<author>Lixing Xie</author>
<author>Zhiyuan Liu</author>
<author>Maosong Sun</author>
<author>Yang Zhang</author>
<author>Liyun Ru</author>
</authors>
<title>Why Press Backspace? Understanding User Input Behaviors in Chinese Pinyin Input Method.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Techologies,</booktitle>
<pages>485--490</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="5170" citStr="Zheng et al., 2011" startWordPosition="807" endWordPosition="810">e is a dialect speaker and does not know the exact pronunciation for the expected character. This may be a very common situation since there are about seven quite different dialects in Chinese, among which being spoken languages, six are far different from the standard modern Chinese, mandarin. With the boom of smart-phones, pinyin typos worsen due to the limited size of soft keyboard, and the lack of physical feedback on the touch screen. However, existing practical IMEs only provide small patches to deal with typos such as Fuzzy Pinyin (Wu and Chen, 2004) and other language specific errors (Zheng et al., 2011b). Typo checking and correction has an important impact on IME performance. When IME fails to correct a typo and generate the expected sentence, the user will have to take much extra effort to move the cursor back to the mistyped letter and correct it, which leads to very poor user experience (Jia and Zhao, 2013). 2 Related Works The very first approach for Chinese input with typo correction was made by (Chen and Lee, 2000), which was also the initial attempt of “sentence-based” IME. The idea of “statistical input method” was proposed by modeling PTC conversion as a hidden Markov model (HMM),</context>
<context position="23243" citStr="Zheng et al., 2011" startWordPosition="3986" endWordPosition="3989">y2. Chinese characters in a sentence may be separated by digits, punctuation and alphabets which are directly inputted without the IME. We follow the so-called term Max Input Unit (MIU), the longest consecutive Chinese character sequence proposed by (Jia and Zhao, 2013). We will mainly consider MIU accuracy (MIU-Acc) which is the ratio of the number of completely corrected generated MIUs over the number of all MIUs, and character accuracy (Ch-Acc), but the sentence accuracy (S-Acc) will also be reported in evaluation results. We will also report the conversion error rate (ConvER) proposed by (Zheng et al., 2011a), which is the ratio of the number of mistyped pinyin word that is not converted to the right Chinese word over the total number of mistyped pinyin words3. 4.3 Baseline System without Typo Correction Firstly we build a baseline system without typo correction which is a pipeline of pinyin syllable segmentation and PTC conversion. The baseline system takes a pinyin input sequence, segments it into syllables, and then converts it to Chinese character sequence. The pinyin syllable segmentation already has very high (over 98%) accuracy with a trigram LM using improved Kneser-Ney smoothing. Accord</context>
<context position="26855" citStr="Zheng et al., 2011" startWordPosition="4585" endWordPosition="4588">ine system compared to other IMEs (%) 4.4 PTC Conversion with Typo Correction Based upon the baseline system, we build the joint system of PTC conversion with typo correction. We simulate user typos by randomly generating errors automatically on the corpus. The typo rate is set according to previous Human-Computer Interaction (HCI) studies. Due to few works have been done on modeling Chinese text entry, we have to refer to those corresponding results on English (Wobbrock and Myers, 2006; MacKenzie and Soukoreff, 2002; Clarkson et al., 2005), which show that the average typo rate is about 2%. (Zheng et al., 2011a) performed an experiment that 2,000 sentences of 11,968 Chinese words were entered by 5 native speakers. The collected data consists of 775 mistyped pinyin words caused by one edit operation, and 85 caused by two edit operations. As we observe on TRAIN that the average pinyin word length is 5.24, then typo rate in the experiment of (Zheng et al., 2011a) can be roughly estimated as: 775 + 85 x 2 11968 x 5.24 which is similar to the conclusion on English. Thus we generate corpora from DEV with typo rate of 0% (0-P), 2% (2-P), and 5% (5-P) to evaluate the system. According to (Zheng et al., 201</context>
<context position="29770" citStr="Zheng et al., 2011" startWordPosition="5126" endWordPosition="5129">n and Google Input Tool. Since sunpinyin does not have typo correction module and performs much poorer than our baseline system, we do not include it in the comparison. Though no direct proofs can be found to indicate if Google Input Tool has an independent typo correction component, its outputs show that such a component is unlikely available. Since Google Input Tool has to be accessed through a web interface and the network connection cannot be guaranteed. we only take a subset of 10K sentences of TEST to perform the experiments, and the results are shown in Table 3. The scores reported in (Zheng et al., 2011a) are not listed in Table 4 since the data set is different. They reported a ConvER of 53.56%, which is given here for reference. Additionally, to further inspect the robustness of our model, performance with typo rate ranges from 0% to 5% is shown in Figure 12. Although the performance decreases while typo rate goes up, it is still quite satisfying around typo rate of 2% which is assumed to be the real world situation. MIU-Acc Ch-Acc S-Acc ConvER Baseline 0-P 79.90 97.47 48.87 - Baseline 2-P 50.47 90.53 11.12 99.95 Baseline 5-P 30.26 82.83 3.32 99.99 Google 0-P 79.08 95.26 46.83 - Google 2-P</context>
</contexts>
<marker>Zheng, Xie, Liu, Sun, Zhang, Ru, 2011</marker>
<rawString>Yabin Zheng, Lixing Xie, Zhiyuan Liu, Maosong Sun, Yang Zhang, and Liyun Ru. 2011b. Why Press Backspace? Understanding User Input Behaviors in Chinese Pinyin Input Method. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Techologies, pages 485–490, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>