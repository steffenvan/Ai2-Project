<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018565">
<title confidence="0.995891">
Exploiting Rich Features for Detecting Hedges and Their Scope
</title>
<author confidence="0.999587">
Xinxin Li, Jianping Shen, Xiang Gao, Xuan Wang
</author>
<affiliation confidence="0.925959">
Harbin Institute of Technology Shenzhen Graduate School
Shenzhen, Guangdong, China
</affiliation>
<email confidence="0.9415755">
{lixxin2, jpshen2008}@gmail.com,
sky0306201@163.com, wangxuan@insun.hit.edu.cn
</email>
<sectionHeader confidence="0.993306" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999928277777778">
This paper describes our system about
detecting hedges and their scope in natural
language texts for our participation in CoNLL-
2010 shared tasks. We formalize these two
tasks as sequence labeling problems, and
implement them using conditional random
fields (CRFs) model. In the first task, we use a
greedy forward procedure to select features for
the classifier. These features include part-of-
speech tag, word form, lemma, chunk tag of
tokens in the sentence. In the second task, our
system exploits rich syntactic features about
dependency structures and phrase structures,
which achieves a better performance than only
using the flat sequence features. Our system
achieves the third score in biological data set
for the first task, and achieves 0.5265 F1 score
for the second task.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999920558139535">
In recent years, a fair amount of approaches have
been developed on detecting speculative and
negative information from biomedical and
natural language texts, for its benefit to the
applications like information extraction. These
approaches evolve from hand-crafted rule-based
approaches, which use regular expressions to
match the sentences or its grammatical parsing,
such as NegEx (Chapman et al., 2001),
Negfinder (Mutalik et al., 2001), and
NegExpander (Aronow et al., 1999), to machine
learning approaches, including semi-supervised
methods (Medlock and Briscoe, 2007; Szarvas,
2008), and supervised methods (Morante and
Daelemans, 2009).
In this paper, we describe the machine
learning system submitted to CoNLL-2010
Shared task (Farkas et al., 2010). Our system
formalizes these two tasks as consecutive
sequence labeling problems, and learns the
classifiers using conditional random fields
approach. In the first task, a model is trained to
identify the hedge cues in sentences, and in the
second task, another model is used to find the
corresponding scope for each hedge cue
generated in the first task. Our system follows
the study of Morante and Daelemans (2009), but
applies more refined feature selection. In the first
task, we use a greedy forward procedure to select
features for the classifier. In the second task, we
exploit rich syntactic information to improve the
performance of the model, from dependency
structures and phrase structures. A rule-based
post processing procedure is used to eliminate
the errors brought by the classifier for each task.
The remainder of the paper is organized as
follows. In section 2, we briefly describe the task
and the details of our system, including how to
select features for the hedge cue detection
system, and how to find the corresponding scope
for each hedge cue. The experimental results are
discussed in section 3. In section 4 we put
forward some conclusion.
</bodyText>
<sectionHeader confidence="0.987654" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999943272727273">
We model these two tasks for identifying the
hedge cues and finding their scope as two
consecutive sequence labeling problems, such as
chunking, segmentation and named entity
recognition, and train the classifiers using
conditional random fields approach (Lafferty et
al., 2001). For each task, a post-processing
procedure is used to refine the results from the
classifier.
In the first task, we detect the hedge cue by
classifying the tokens of a sentence as being at
the beginning of, inside or outside of the hedge
signal. In the second task, we find the scope of a
hedge cue by classifying the tokens of a sentence
as being the first one of, the last one or neither of
the scope.
A sentence from biological full articles data
set omitting the id number is shown below in
Figure 1. In this sentence, there is only one
hedge cue, the phrase “raises an interesting
question”, and its corresponding scope is the
sequence from token “raises” to token “acid”.
</bodyText>
<page confidence="0.983848">
78
</page>
<note confidence="0.6709995">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 78–83,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<footnote confidence="0.332075">
&lt;sentence&gt;This &lt;xcope&gt;&lt;cue&gt;raises an
interesting question&lt;/cue&gt;: &amp;quot;Is there a 23rd
amino acid&lt;/xcope&gt;?&amp;quot;.&lt;/sentence&gt;
</footnote>
<figureCaption confidence="0.920223">
Figure 1: A sentence with hedge cue and scope
annotation in biological full articles data set
</figureCaption>
<subsectionHeader confidence="0.9939">
2.1 Hedge detection
</subsectionHeader>
<bodyText confidence="0.999884655172414">
Since hedge cues usually consist of one or more
tokens, we predict the tokens in BIO
representation, whether the token is the first
token of a hedge cue (B-cue), inside a hedge cue
(I-cue), or outside of the hedge cue (O-cue). For
the sentence in Figure 1, token “raises” is
denoted as B-cue, tokens “an interesting
question” all as I-cue, and the other tokens in the
sentence as O-cue.
The classifier is trained using conditional
random fields (Lafferty et al., 2001), which
combines the benefits of conditional models with
the global normalization of random field models,
and avoid the label bias problem that exists in
maximum entropy Markov models (MEMMs).
The CRF model we use is implemented as
CRF++ 0.51 1 . The parameters of the CRF
classifier are set as defaults.
We use a greedy forward procedure to select a
better feature sets for the classifier according to
the evaluation results in the development set. We
first start from a basic feature set, and then add
each feature outside the basic set and remove
each feature inside the basic set one by one to
check the effectiveness of each feature by the
performance change in the development set. This
procedure is repeated until no feature is added or
removed or the performance is not improved.
The selected features are listed below:
</bodyText>
<listItem confidence="0.99989025">
• Cn (n=-2,-1, 0, 1, 2)
• CnCn+1 (n=-1,0)
• Cn-1CnCn+1 (n=-1,0,1)
• Cn-2Cn-1CnCn+1 (n=0,1)
</listItem>
<bodyText confidence="0.990592285714286">
Where C denote features of each token,
including FORM, LEMMA, and POS (in Table
1), C0 represents the feature of current token and
Cn(C-n) represents the feature of the token n
positions to the right (left) of current token.
CnCn+1 denote the combination of Cn and Cn+1. So
are Cn-1CnCn+1 and Cn-2Cn-1CnCn+1.
</bodyText>
<footnote confidence="0.954411">
1 http://crfpp.sourceforge.net/
</footnote>
<table confidence="0.99898325">
Feature Description
Name
FORM Word form or punctuation symbol.
LEMMA Lemma or stem of word form.
POS Part-of-speech tag of the token.
CHUNK Chunk tag of the token, e.g. B_NP,
B_ SBAR, and I_NP.
TCHUNK Chunk type of the token, e.g. NP.
</table>
<tableCaption confidence="0.999844">
Table 1: Description of features of each token
</tableCaption>
<bodyText confidence="0.999937583333333">
Although our system is based on token, chunk
features are also important. Analyzing the
training data set, it is shown that if one token in a
chunk is in the hedge cue, the other tokens in the
chunk are usually in the same hedge cue. The
chunk feature can provide more information for
the multiword hedge cues. The LEMMA, POS,
and CHUNK of each token used in our system
are determined using GENIA tagger (Tsuruoka et
al., 2005).
The selected CHUNK features in our system
are listed as follows:
</bodyText>
<listItem confidence="0.99922475">
• Cn (n=-3, -2,-1, 0, 1, 2, 3 )
• CnCn+1 (n=-3, -2,-1, 0, 1, 2, 3 )
• Cn-1CnCn+1 (n=-2,-1,0,1,-2)
• Cn-2Cn-1CnCn+1 (n=-1,0,1,2)
</listItem>
<bodyText confidence="0.999798714285714">
We can obtain the preliminary results using
the CRF model-based classifier, but there are
some missed or incorrectly classified hedge cues
which can be recognized by rule-based patterns.
Through statistical analysis on the training and
development data sets, we obtain some effective
rules for post processing, including:
</bodyText>
<listItem confidence="0.990925666666666">
• If the first token of a NP chunk tag is
annotated as I-cue, the whole NP chunk is
in the hedge cues.
• If the B-VP chunk tag of a token is
followed by a B-SBAR chunk tag, the
token is annotated as B-cue.
• If token “that” follows token “indicate”
and the POS of token “that” is IN, the
chunk tag of token “that” is B-SBAR, then
the “indicate” will be annotated with B-
cue and “that” will be annotated with I-
cue.
• If token “indicate” is followed by token
“an” or token “a”, then the token
“indicate” is annotated as B-cue.
</listItem>
<page confidence="0.987773">
79
</page>
<subsectionHeader confidence="0.996643">
2.2 Scope finding
</subsectionHeader>
<bodyText confidence="0.999951458333333">
In this task, we train a classifier to predict
whether each token in the sentence is in the
scope by classifying them as the first one (F-
scope), the last one (L-scope), or neither
(NONE) of the scope, which is the same as
Morante and Daelemans (2009). For the sentence
in Figure 1, token “raises” is denoted as F-scope,
token “acid” as L-scope, and the other tokens in
the sentence as NONE.
After the classification, a post processing
procedure is used to match the scope to each
hedge, guaranteeing that each hedge has only one
corresponding scope sequence, and must be
inside its scope sequence. There is no cross
between different scope sequences, but inclusion
is allowed. The hedges are selected from the first
task.
The classifier is also implemented using
conditional random fields model, and the
parameters of the CRF classifier are set as
defaults. We first build a set of baseline sequence
features for the classifier, some borrowed from
Morante and Daelemans (2009). The selected
baseline sequence features are:
</bodyText>
<listItem confidence="0.998735129032258">
• Of the token in focus: FORM, POS,
LEMMA, CHUNK, TCHUNK,
combination of FORM and POS; POS,
LEMMA, CHUNK, TCHUNK of two
tokens to the left and three tokens to the
right; first word, last word, chain of
FORM, POS of two chunks to the left and
two chunks to the right; All combination
of POS in the window of length less than 3;
All combination of CHUNK in the
window of length 2.
• Of the left closest hedge: chain of the
FORM, POS, LEMMA, CHUNK, and
TCHUNK; All combination of POS and
FORM in the window of length 2.
• Of the right closest hedge: chain of the
FORM, POS, LEMMA, CHUNK, and
TCHUNK; All combination of POS and
FORM in the window of length 2.
• Of the tokens between the left closest
hedge and the token in focus: chain of
FORM, POS, LEMMA, CHUNK and
TCHUNK; the number.
• Of the tokens between the right closest
hedge and the token in focus: chain of
FORM, POS, LEMMA, CHUNK and
TCHUNK; the number.
• Others: the number of hedge cues in the
sentence; the sequence relation between
the token in focus and hedge cues (LEFT,
RIGHT, MIDDLE, IN, NULL)
</listItem>
<bodyText confidence="0.998320958333333">
Besides the sequence features listed above,
syntactic features between the token in focus and
hedge cues are explored in our classifier. Huang
and Low (2007) notes that structure information
stored in parse trees helps identifying the scope
of negative hedge cues, and Szarvas (2008)
points out that the scope of a keyword can be
determined on the basic of syntax. Thus we
believe that a highly accurate extraction of
syntactic structure would be beneficial for this
task.
For sentences in the dataset, their dependency
structures are extracted using GENIA
Dependency parser (Sagae and Tsujii, 2007), and
phrase structure using Brown self-trained
biomedical parser (McClosky, 2009). Figure 2
shows the corresponding dependency tree and
Figure 3 shows the corresponding phrase
structure tree for the sentence in Figure 1. In the
following part in the section, we will illustrate
these syntactic features and give examples for
their value. We take the token “acid” as the token
in focus, to determine whether it is classified as
F-scope, L-scope or NONE.
</bodyText>
<figureCaption confidence="0.997325">
Figure 2: Dependency tree of the sentence in
Figure 1
</figureCaption>
<bodyText confidence="0.998209833333333">
For the token “acid” in the dependency trees
in Figure 2, its father node is the token “there”,
and the dependency relation between these two
token is “NMOD”.
Dependency features between the token in
focus and the left closest hedge cue are:
</bodyText>
<listItem confidence="0.9155335">
• Dependency relation of the token in
focus to its father, left closest hedge to its
</listItem>
<page confidence="0.958966">
80
</page>
<bodyText confidence="0.876322">
father and the dependency relation pair:
NOMD, ROOT, ROOT+NMOD.
</bodyText>
<listItem confidence="0.999001">
• Chain of POS: -&gt;VBZ&lt;-VBZ&lt;-EX&lt;-NN
• Chain of POS without consecutive
redundant POS: -&gt;VBZ &lt;-EX&lt;-NN
• POS of their nearest co-father: VBZ
• Whether it is a linear relation (self, up ,
down, no): up
• Kinship (grandfather, grandson, father,
son, brother, self, no): no.
• The number of tokens in the chain: 4
</listItem>
<bodyText confidence="0.979124333333333">
Similar features are extracted for dependency
relation between the token in focus and its right
closest hedge cue. There is no right hedge cue for
token “acid”. Thus these features are set as
“NULL”.
This raises an interesting question: &amp;quot; Is there a 23rd amino acid ? &amp;quot; .
</bodyText>
<figureCaption confidence="0.9985405">
Figure 3: Phrase structure tree of the sentence in
Figure 1
</figureCaption>
<bodyText confidence="0.974589">
Phrase structure features between the token in
focus and its left closest hedge cue are:
</bodyText>
<listItem confidence="0.997052222222222">
• Chain of syntactic categories: VBZ-
&gt;VP&lt;- NP &lt;-NP &lt;-S&lt;-VP &lt;-NP&lt;-NN
• syntactic categories without consecutive
redundant ones: VBZ-&gt;VP&lt;-NP&lt;-S&lt;-
VP&lt;- NP&lt;-NN
• Syntactic category of their nearest co-
father: VP
• The number of syntactic categories in the
chain: 8
</listItem>
<bodyText confidence="0.998912">
The phrase structure features between the
token in focus and the nearest right hedge cue are
similar, setting as “NULL”.
Scope finding requires each hedge cue has
only one corresponding scope. A hedge-scope
pair is true positive only if the hedge cue and its
corresponding scope are correctly identified. We
perform the post processing procedure in
sequence:
</bodyText>
<listItem confidence="0.898682208333334">
• For each hedge cue from the beginning
to the end of the sentence, find its left
closest F-scope which has not been
identified by other hedge cues, and
identify it as its F-scope.
• For each hedge cue from the end to the
beginning of the sentence, find its right
closest L-scope which has not been
identified by other hedge cues, and
identify it as its L-scope.
• For each hedge:
• If both its F-scope and L-scope is
identified, then done;
• If only its F-scope is identified, then
its L-scope is set as L-scope of the
last hedge cue in the sentence if it
exists or according to the dictionary
which we build with training data
set;
• If only its L-scope is identified, then
its F-scope is set as its first token;
• If none of its F-scope and L-scope is
identified, then discard the hedge
cue.
</listItem>
<sectionHeader confidence="0.984955" genericHeader="method">
3 Overall Results
</sectionHeader>
<bodyText confidence="0.999989684210526">
In this section we will present our experimental
results for these two tasks. In the first task, the
chief evaluation is carried on sentence level:
whether a sentence contains hedge/weasel cue or
not. Our system compares the performance of
different machine learning algorithm, CRF and
SVM-HMM on hedge cue detection. A post
processing procedure is used to increase the
recall measure for our system.
In the second task, three experiments are
performed. The first experiment is used to
validate the benefit of dependency features and
phrase structure features for scope finding. The
second experiment is designed to evaluate the
effect of abstract dataset on full article dataset.
These two experiments are all performed using
gold hedge cues. The performance of our scope
finding system with predicted hedge cues is
presented in the third experiment.
</bodyText>
<figure confidence="0.997646076923077">
S
S
VP
NP
NP
ADVP NP
ADVP
NP
S
VP
NP
NP
DT VBZ DT JJ NN : NN VBZ RB DT NN NN NN . RB .
</figure>
<page confidence="0.986988">
81
</page>
<subsectionHeader confidence="0.996801">
3.1 Hedge detection
</subsectionHeader>
<bodyText confidence="0.975967">
The first experiment is used to compare two
machine learning algorithms, SVM-HMM and
CRF. We train the classifiers on abstract and full
articles data sets. The results of the classifier on
evaluation data set are shown in Table 2.
</bodyText>
<table confidence="0.999144">
Model Precision Recall F1
SVM-HMM 88.71 81.52 84.96
CRF 90.4 81.01 85.45
</table>
<tableCaption confidence="0.947987">
Table 2: Results of hedge cues detection using
CRF and SVM-HMM
</tableCaption>
<bodyText confidence="0.998112333333333">
From Table 1, it is shown that CRF model
outperforms SVM-HMM model in both
precision and recall measure. The results are
obtained without post processing. The
experimental result with post processing is
shown in Table 3.
</bodyText>
<table confidence="0.999324">
Feature Precision Recall F1
Without Post 90.4 81.01 85.45
processing
Post 90.1 82.05 85.89
processing
</table>
<tableCaption confidence="0.9939275">
Table 3: Result of biological evaluation data set
without/with post processing
</tableCaption>
<bodyText confidence="0.9992555">
By post processing, some mislabeled or
incorrectly classified hedge cues can be
recognized, especially the recall of the I-cue
improved largely, from 55.26% to 68.51%.
Though the precision is a little lower, the F1
measure increases 0.44%.
</bodyText>
<subsectionHeader confidence="0.999789">
3.2 Scope finding
</subsectionHeader>
<bodyText confidence="0.999641388888889">
To measure the benefit of syntactic features on
scope finding task, we perform the experiment
with different features on abstract data set, of
which we split two-thirds as training data, and
the other one third as testing data. The results are
presented in Table 4.
We take the classifier with sequence features
as baseline classifier. From Table 4, it is shown
that adding dependency features achieves a
slightly better performance than the baseline
classifier, and adding phrase structure features
improve much better, about 1.2% F1-score. The
classifier with all syntactic features achieves the
best F1-score, 2.19% higher than baseline
classifier. However, in later experiment on
evaluation dataset after the shared task, we
observed that dependency features actually
harmed the performance for full articles dataset.
</bodyText>
<table confidence="0.9995995">
Feature set Precision Recall F1
Sequence 82.20 81.61 81.90
(Baseline)
Sequence + 82.28 82.09 82.19
Dependency
Sequence 83.14 83.04 83.09
+ Phrase structure
All 84.19 83.99 84.09
</table>
<tableCaption confidence="0.9861785">
Table 4: Results of scope finding system with
different feature sets on abstract data set
</tableCaption>
<bodyText confidence="0.999494454545454">
Three experiments are designed to evaluate
the benefit of abstract dataset for full articles
dataset. The first one is performed on full articles
data set, of which we split two-thirds for training,
and the other one third for testing. The second
experiment is trained on abstract data set, and
evaluated on full articles data set. In the third
experiment, we take abstract data set and one
third of full articles as training data, and evaluate
on the remaining full articles data set. The results
are shown below in Table 5.
</bodyText>
<table confidence="0.9994326">
Training Testing Prec. Recall F1
data data
Part Art. Part Art. 53.14 51.80 52.46
Abs. Full Art. 54.32 54.64 54.48
Mix Part Art. 59.59 59.74 59.66
</table>
<tableCaption confidence="0.954846">
Table 5: Results of scope finding system with
gold-standard hedge cues
</tableCaption>
<bodyText confidence="0.999893578947368">
Results in Table 5 reveal that more abstract
and full article dataset are added to the classifier
as training data, better performance the system
achieve. Thus we use the combination of abstract
and full articles as training data for the final
evaluation.
Table 6 presents the results of our scope
finding system with or without dependency
features, using both gold-standard hedge cues
and predicated hedge cues generated by our
hedge cue finding system.
Comparing the results in Table 4, 5, and 6, we
observe that the performance of scope finding
classifier on full article dataset is much lower
than on abstract dataset, and dependency features
are beneficial for the abstract dataset, but useless
for full article dataset. We ascribe this
phenomenon to the lack of enough full articles
training data and the different properties of
</bodyText>
<page confidence="0.995647">
82
</page>
<bodyText confidence="0.9563605">
abstract and full articles data sets. Deep research
is expected to continue.
</bodyText>
<table confidence="0.9956059">
Hedge Dep. Prec. Recall F1
cues features
Predicted with 57.42 47.92 52.
24
without 58.13 48.11 52.
65
Gold with 59.43 58.28
standard 85
without 60.20 58.86
52
</table>
<tableCaption confidence="0.967872">
Table 6: Results of scope finding system
with/without dependency features using both
gold-standard and predicated hedge cues
</tableCaption>
<sectionHeader confidence="0.998" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999934583333333">
In this paper, we describe a machine learning
system for detecting hedges and their scope in
natural language texts. These two tasks are
formalized as sequence labeling problems, and
implemented using conditional random fields
approach. We use a greedy forward procedure to
select features for the classifier, and exploit rich
syntactic features to achieve a better performance.
In the in-domain evaluation, our system achieves
the third score in biological data set for the first
task, and achieves 0.5265 F1 score for the second
task.
</bodyText>
<sectionHeader confidence="0.997297" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999875">
The authors would like to thank Buzhou Tang for
useful discussions of the paper. This work is
supported by the National High-tech R&amp;D
Program of China (863 Program, No.
2007AA01Z194).
</bodyText>
<sectionHeader confidence="0.999276" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999708215384615">
David B. Aronow, Fangfang Feng, and W. Bruce
Croft. 1999. Ad Hoc Classification of Radiology
Reports. Journal of the American Medical
Informatics Association, 6(5):393–411.
Wendy W. Chapman, Will Bridewell, Paul Hanbury,
Gregory F. Cooper, and Bruce G. Buchanan. 2001.
A Simple Algorithm for Identifying Negated
Findings and Diseases in Discharge Summaries.
Journal of Biomedical Informatics, 34:301–310.
Richárd Farkas, Veronika Vincze, György Móra,
János Csirik, and György Szarvas. 2010. The
CoNLL-2010 Shared Task: Learning to Detect
Hedges and their Scope in Natural Language Text.
In Proceedings of the Fourteenth Conference
on Computational Natural Language Learning
(CoNLL-2010): Shared Task, pages 1–12.
Yang Huang, and Henry J. Lowe. 2007. A novel
hybrid approach to automated negation detection in
clinical radiology reports. Journal of the
American Medical Informatics Association,
14(3):304–311.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling
sequence data. In Proceedings of the Eighteenth
International Conference on Machine
Learning, pages 282–289.
David McClosky. 2009. Any Domain Parsing:
Automatic Domain Adaptation for Natural
Language Parsing. Ph.D. thesis, Department of
Computer Science, Brown University.
Ben Medlock, and Ted Briscoe. 2007. Weakly
supervised learning for hedge classification in
scientific literature. In Proc. of ACL 2007, pages
992–999.
Roser Morante, and Walter Daelemans. 2009.
Learning the scope of hedge cues in biomedical
texts. In Proceedings of the Workshop on
BioNLP, pages 28–36.
Pradeep G. Mutalik, Aniruddha Deshpande, and
Prakash M. Nadkarni. 2001. Use of general-
purpose negation detection to augment concept
indexing of medical documents: a quantitative
study using the UMLS. Journal of the American
Medical Informatics Association, 8(6):598–609.
Kenji Sagae, and Jun’ichi Tsujii. 2007. Dependency
parsing and domain adaptation with LR models
and parser ensembles. In Proceedings of the
CoNLL-2007 Shared Task, pages 82–94
György Szarvas. 2008. Hedge classification in
biomedical texts with a weakly supervised
selection of keywords. In Proc. of ACL 2008,
pages 281–289, Columbus, Ohio, USA. ACL.
György Szarvas, Veronika Vincze, Richárd Farkas,
and János Csirik. 2008. The BioScope corpus:
annotation for negation, uncertainty and their scope
in biomedical texts. In Proc. of BioNLP 2008,
pages 38–45, Columbus, Ohio. ACL.
Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim,
Tomoko Ohta, John McNaught, Sophia Ananiadou,
and Jun&apos;ichi Tsujii. 2005. Developing a Robust
Part-of-Speech Tagger for Biomedical Text.
Advances in Informatics - 10th Panhellenic
Conference on Informatics, LNCS 3746, pages
382–392.
</reference>
<page confidence="0.999308">
83
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.791520">
<title confidence="0.999167">Exploiting Rich Features for Detecting Hedges and Their Scope</title>
<author confidence="0.995919">Xinxin Li</author>
<author confidence="0.995919">Jianping Shen</author>
<author confidence="0.995919">Xiang Gao</author>
<author confidence="0.995919">Xuan</author>
<affiliation confidence="0.999698">Harbin Institute of Technology Shenzhen Graduate</affiliation>
<address confidence="0.986806">Shenzhen, Guangdong, China</address>
<email confidence="0.893343">{lixxin2,sky0306201@163.com,wangxuan@insun.hit.edu.cn</email>
<abstract confidence="0.999168789473684">This paper describes our system about detecting hedges and their scope in natural language texts for our participation in CoNLL- 2010 shared tasks. We formalize these two tasks as sequence labeling problems, and implement them using conditional random fields (CRFs) model. In the first task, we use a greedy forward procedure to select features for the classifier. These features include part-ofspeech tag, word form, lemma, chunk tag of tokens in the sentence. In the second task, our system exploits rich syntactic features about dependency structures and phrase structures, which achieves a better performance than only using the flat sequence features. Our system achieves the third score in biological data set for the first task, and achieves 0.5265 F1 score for the second task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David B Aronow</author>
<author>Fangfang Feng</author>
<author>W Bruce Croft</author>
</authors>
<title>Ad Hoc Classification of Radiology Reports.</title>
<date>1999</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>6</volume>
<issue>5</issue>
<contexts>
<context position="1558" citStr="Aronow et al., 1999" startWordPosition="223" endWordPosition="226"> system achieves the third score in biological data set for the first task, and achieves 0.5265 F1 score for the second task. 1 Introduction In recent years, a fair amount of approaches have been developed on detecting speculative and negative information from biomedical and natural language texts, for its benefit to the applications like information extraction. These approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as NegEx (Chapman et al., 2001), Negfinder (Mutalik et al., 2001), and NegExpander (Aronow et al., 1999), to machine learning approaches, including semi-supervised methods (Medlock and Briscoe, 2007; Szarvas, 2008), and supervised methods (Morante and Daelemans, 2009). In this paper, we describe the machine learning system submitted to CoNLL-2010 Shared task (Farkas et al., 2010). Our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach. In the first task, a model is trained to identify the hedge cues in sentences, and in the second task, another model is used to find the corresponding scope for each hedg</context>
</contexts>
<marker>Aronow, Feng, Croft, 1999</marker>
<rawString>David B. Aronow, Fangfang Feng, and W. Bruce Croft. 1999. Ad Hoc Classification of Radiology Reports. Journal of the American Medical Informatics Association, 6(5):393–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wendy W Chapman</author>
<author>Will Bridewell</author>
<author>Paul Hanbury</author>
<author>Gregory F Cooper</author>
<author>Bruce G Buchanan</author>
</authors>
<title>A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries.</title>
<date>2001</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>34--301</pages>
<contexts>
<context position="1485" citStr="Chapman et al., 2001" startWordPosition="212" endWordPosition="215">ieves a better performance than only using the flat sequence features. Our system achieves the third score in biological data set for the first task, and achieves 0.5265 F1 score for the second task. 1 Introduction In recent years, a fair amount of approaches have been developed on detecting speculative and negative information from biomedical and natural language texts, for its benefit to the applications like information extraction. These approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as NegEx (Chapman et al., 2001), Negfinder (Mutalik et al., 2001), and NegExpander (Aronow et al., 1999), to machine learning approaches, including semi-supervised methods (Medlock and Briscoe, 2007; Szarvas, 2008), and supervised methods (Morante and Daelemans, 2009). In this paper, we describe the machine learning system submitted to CoNLL-2010 Shared task (Farkas et al., 2010). Our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach. In the first task, a model is trained to identify the hedge cues in sentences, and in the second </context>
</contexts>
<marker>Chapman, Bridewell, Hanbury, Cooper, Buchanan, 2001</marker>
<rawString>Wendy W. Chapman, Will Bridewell, Paul Hanbury, Gregory F. Cooper, and Bruce G. Buchanan. 2001. A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries. Journal of Biomedical Informatics, 34:301–310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richárd Farkas</author>
<author>Veronika Vincze</author>
<author>György Móra</author>
<author>János Csirik</author>
<author>György Szarvas</author>
</authors>
<title>The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task,</booktitle>
<pages>1--12</pages>
<contexts>
<context position="1836" citStr="Farkas et al., 2010" startWordPosition="261" endWordPosition="264">tural language texts, for its benefit to the applications like information extraction. These approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as NegEx (Chapman et al., 2001), Negfinder (Mutalik et al., 2001), and NegExpander (Aronow et al., 1999), to machine learning approaches, including semi-supervised methods (Medlock and Briscoe, 2007; Szarvas, 2008), and supervised methods (Morante and Daelemans, 2009). In this paper, we describe the machine learning system submitted to CoNLL-2010 Shared task (Farkas et al., 2010). Our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach. In the first task, a model is trained to identify the hedge cues in sentences, and in the second task, another model is used to find the corresponding scope for each hedge cue generated in the first task. Our system follows the study of Morante and Daelemans (2009), but applies more refined feature selection. In the first task, we use a greedy forward procedure to select features for the classifier. In the second task, we exploit rich syntactic</context>
</contexts>
<marker>Farkas, Vincze, Móra, Csirik, Szarvas, 2010</marker>
<rawString>Richárd Farkas, Veronika Vincze, György Móra, János Csirik, and György Szarvas. 2010. The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task, pages 1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Huang</author>
<author>Henry J Lowe</author>
</authors>
<title>A novel hybrid approach to automated negation detection in clinical radiology reports.</title>
<date>2007</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>14</volume>
<issue>3</issue>
<marker>Huang, Lowe, 2007</marker>
<rawString>Yang Huang, and Henry J. Lowe. 2007. A novel hybrid approach to automated negation detection in clinical radiology reports. Journal of the American Medical Informatics Association, 14(3):304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="3304" citStr="Lafferty et al., 2001" startWordPosition="496" endWordPosition="499">organized as follows. In section 2, we briefly describe the task and the details of our system, including how to select features for the hedge cue detection system, and how to find the corresponding scope for each hedge cue. The experimental results are discussed in section 3. In section 4 we put forward some conclusion. 2 System Description We model these two tasks for identifying the hedge cues and finding their scope as two consecutive sequence labeling problems, such as chunking, segmentation and named entity recognition, and train the classifiers using conditional random fields approach (Lafferty et al., 2001). For each task, a post-processing procedure is used to refine the results from the classifier. In the first task, we detect the hedge cue by classifying the tokens of a sentence as being at the beginning of, inside or outside of the hedge signal. In the second task, we find the scope of a hedge cue by classifying the tokens of a sentence as being the first one of, the last one or neither of the scope. A sentence from biological full articles data set omitting the id number is shown below in Figure 1. In this sentence, there is only one hedge cue, the phrase “raises an interesting question”, a</context>
<context position="4878" citStr="Lafferty et al., 2001" startWordPosition="755" endWordPosition="758">a 23rd amino acid&lt;/xcope&gt;?&amp;quot;.&lt;/sentence&gt; Figure 1: A sentence with hedge cue and scope annotation in biological full articles data set 2.1 Hedge detection Since hedge cues usually consist of one or more tokens, we predict the tokens in BIO representation, whether the token is the first token of a hedge cue (B-cue), inside a hedge cue (I-cue), or outside of the hedge cue (O-cue). For the sentence in Figure 1, token “raises” is denoted as B-cue, tokens “an interesting question” all as I-cue, and the other tokens in the sentence as O-cue. The classifier is trained using conditional random fields (Lafferty et al., 2001), which combines the benefits of conditional models with the global normalization of random field models, and avoid the label bias problem that exists in maximum entropy Markov models (MEMMs). The CRF model we use is implemented as CRF++ 0.51 1 . The parameters of the CRF classifier are set as defaults. We use a greedy forward procedure to select a better feature sets for the classifier according to the evaluation results in the development set. We first start from a basic feature set, and then add each feature outside the basic set and remove each feature inside the basic set one by one to ch</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
</authors>
<title>Any Domain Parsing: Automatic Domain Adaptation for Natural Language Parsing.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Science, Brown University.</institution>
<contexts>
<context position="10674" citStr="McClosky, 2009" startWordPosition="1764" endWordPosition="1765">ween the token in focus and hedge cues are explored in our classifier. Huang and Low (2007) notes that structure information stored in parse trees helps identifying the scope of negative hedge cues, and Szarvas (2008) points out that the scope of a keyword can be determined on the basic of syntax. Thus we believe that a highly accurate extraction of syntactic structure would be beneficial for this task. For sentences in the dataset, their dependency structures are extracted using GENIA Dependency parser (Sagae and Tsujii, 2007), and phrase structure using Brown self-trained biomedical parser (McClosky, 2009). Figure 2 shows the corresponding dependency tree and Figure 3 shows the corresponding phrase structure tree for the sentence in Figure 1. In the following part in the section, we will illustrate these syntactic features and give examples for their value. We take the token “acid” as the token in focus, to determine whether it is classified as F-scope, L-scope or NONE. Figure 2: Dependency tree of the sentence in Figure 1 For the token “acid” in the dependency trees in Figure 2, its father node is the token “there”, and the dependency relation between these two token is “NMOD”. Dependency feat</context>
</contexts>
<marker>McClosky, 2009</marker>
<rawString>David McClosky. 2009. Any Domain Parsing: Automatic Domain Adaptation for Natural Language Parsing. Ph.D. thesis, Department of Computer Science, Brown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Medlock</author>
<author>Ted Briscoe</author>
</authors>
<title>Weakly supervised learning for hedge classification in scientific literature.</title>
<date>2007</date>
<booktitle>In Proc. of ACL</booktitle>
<pages>992--999</pages>
<contexts>
<context position="1652" citStr="Medlock and Briscoe, 2007" startWordPosition="234" endWordPosition="237">0.5265 F1 score for the second task. 1 Introduction In recent years, a fair amount of approaches have been developed on detecting speculative and negative information from biomedical and natural language texts, for its benefit to the applications like information extraction. These approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as NegEx (Chapman et al., 2001), Negfinder (Mutalik et al., 2001), and NegExpander (Aronow et al., 1999), to machine learning approaches, including semi-supervised methods (Medlock and Briscoe, 2007; Szarvas, 2008), and supervised methods (Morante and Daelemans, 2009). In this paper, we describe the machine learning system submitted to CoNLL-2010 Shared task (Farkas et al., 2010). Our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach. In the first task, a model is trained to identify the hedge cues in sentences, and in the second task, another model is used to find the corresponding scope for each hedge cue generated in the first task. Our system follows the study of Morante and Daelemans (2009</context>
</contexts>
<marker>Medlock, Briscoe, 2007</marker>
<rawString>Ben Medlock, and Ted Briscoe. 2007. Weakly supervised learning for hedge classification in scientific literature. In Proc. of ACL 2007, pages 992–999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the scope of hedge cues in biomedical texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on BioNLP,</booktitle>
<pages>28--36</pages>
<contexts>
<context position="1722" citStr="Morante and Daelemans, 2009" startWordPosition="243" endWordPosition="246">, a fair amount of approaches have been developed on detecting speculative and negative information from biomedical and natural language texts, for its benefit to the applications like information extraction. These approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as NegEx (Chapman et al., 2001), Negfinder (Mutalik et al., 2001), and NegExpander (Aronow et al., 1999), to machine learning approaches, including semi-supervised methods (Medlock and Briscoe, 2007; Szarvas, 2008), and supervised methods (Morante and Daelemans, 2009). In this paper, we describe the machine learning system submitted to CoNLL-2010 Shared task (Farkas et al., 2010). Our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach. In the first task, a model is trained to identify the hedge cues in sentences, and in the second task, another model is used to find the corresponding scope for each hedge cue generated in the first task. Our system follows the study of Morante and Daelemans (2009), but applies more refined feature selection. In the first task, we u</context>
<context position="8159" citStr="Morante and Daelemans (2009)" startWordPosition="1331" endWordPosition="1334"> tag, the token is annotated as B-cue. • If token “that” follows token “indicate” and the POS of token “that” is IN, the chunk tag of token “that” is B-SBAR, then the “indicate” will be annotated with Bcue and “that” will be annotated with Icue. • If token “indicate” is followed by token “an” or token “a”, then the token “indicate” is annotated as B-cue. 79 2.2 Scope finding In this task, we train a classifier to predict whether each token in the sentence is in the scope by classifying them as the first one (Fscope), the last one (L-scope), or neither (NONE) of the scope, which is the same as Morante and Daelemans (2009). For the sentence in Figure 1, token “raises” is denoted as F-scope, token “acid” as L-scope, and the other tokens in the sentence as NONE. After the classification, a post processing procedure is used to match the scope to each hedge, guaranteeing that each hedge has only one corresponding scope sequence, and must be inside its scope sequence. There is no cross between different scope sequences, but inclusion is allowed. The hedges are selected from the first task. The classifier is also implemented using conditional random fields model, and the parameters of the CRF classifier are set as de</context>
</contexts>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante, and Walter Daelemans. 2009. Learning the scope of hedge cues in biomedical texts. In Proceedings of the Workshop on BioNLP, pages 28–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pradeep G Mutalik</author>
<author>Aniruddha Deshpande</author>
<author>Prakash M Nadkarni</author>
</authors>
<title>Use of generalpurpose negation detection to augment concept indexing of medical documents: a quantitative study using the UMLS.</title>
<date>2001</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>8</volume>
<issue>6</issue>
<contexts>
<context position="1519" citStr="Mutalik et al., 2001" startWordPosition="217" endWordPosition="220">ly using the flat sequence features. Our system achieves the third score in biological data set for the first task, and achieves 0.5265 F1 score for the second task. 1 Introduction In recent years, a fair amount of approaches have been developed on detecting speculative and negative information from biomedical and natural language texts, for its benefit to the applications like information extraction. These approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as NegEx (Chapman et al., 2001), Negfinder (Mutalik et al., 2001), and NegExpander (Aronow et al., 1999), to machine learning approaches, including semi-supervised methods (Medlock and Briscoe, 2007; Szarvas, 2008), and supervised methods (Morante and Daelemans, 2009). In this paper, we describe the machine learning system submitted to CoNLL-2010 Shared task (Farkas et al., 2010). Our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach. In the first task, a model is trained to identify the hedge cues in sentences, and in the second task, another model is used to fin</context>
</contexts>
<marker>Mutalik, Deshpande, Nadkarni, 2001</marker>
<rawString>Pradeep G. Mutalik, Aniruddha Deshpande, and Prakash M. Nadkarni. 2001. Use of generalpurpose negation detection to augment concept indexing of medical documents: a quantitative study using the UMLS. Journal of the American Medical Informatics Association, 8(6):598–609.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Dependency parsing and domain adaptation with LR models and parser ensembles.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL-2007 Shared Task,</booktitle>
<pages>82--94</pages>
<contexts>
<context position="10592" citStr="Sagae and Tsujii, 2007" startWordPosition="1752" endWordPosition="1755">IGHT, MIDDLE, IN, NULL) Besides the sequence features listed above, syntactic features between the token in focus and hedge cues are explored in our classifier. Huang and Low (2007) notes that structure information stored in parse trees helps identifying the scope of negative hedge cues, and Szarvas (2008) points out that the scope of a keyword can be determined on the basic of syntax. Thus we believe that a highly accurate extraction of syntactic structure would be beneficial for this task. For sentences in the dataset, their dependency structures are extracted using GENIA Dependency parser (Sagae and Tsujii, 2007), and phrase structure using Brown self-trained biomedical parser (McClosky, 2009). Figure 2 shows the corresponding dependency tree and Figure 3 shows the corresponding phrase structure tree for the sentence in Figure 1. In the following part in the section, we will illustrate these syntactic features and give examples for their value. We take the token “acid” as the token in focus, to determine whether it is classified as F-scope, L-scope or NONE. Figure 2: Dependency tree of the sentence in Figure 1 For the token “acid” in the dependency trees in Figure 2, its father node is the token “ther</context>
</contexts>
<marker>Sagae, Tsujii, 2007</marker>
<rawString>Kenji Sagae, and Jun’ichi Tsujii. 2007. Dependency parsing and domain adaptation with LR models and parser ensembles. In Proceedings of the CoNLL-2007 Shared Task, pages 82–94</rawString>
</citation>
<citation valid="true">
<authors>
<author>György Szarvas</author>
</authors>
<title>Hedge classification in biomedical texts with a weakly supervised selection of keywords.</title>
<date>2008</date>
<booktitle>In Proc. of ACL</booktitle>
<pages>281--289</pages>
<publisher>ACL.</publisher>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="1668" citStr="Szarvas, 2008" startWordPosition="238" endWordPosition="239">ond task. 1 Introduction In recent years, a fair amount of approaches have been developed on detecting speculative and negative information from biomedical and natural language texts, for its benefit to the applications like information extraction. These approaches evolve from hand-crafted rule-based approaches, which use regular expressions to match the sentences or its grammatical parsing, such as NegEx (Chapman et al., 2001), Negfinder (Mutalik et al., 2001), and NegExpander (Aronow et al., 1999), to machine learning approaches, including semi-supervised methods (Medlock and Briscoe, 2007; Szarvas, 2008), and supervised methods (Morante and Daelemans, 2009). In this paper, we describe the machine learning system submitted to CoNLL-2010 Shared task (Farkas et al., 2010). Our system formalizes these two tasks as consecutive sequence labeling problems, and learns the classifiers using conditional random fields approach. In the first task, a model is trained to identify the hedge cues in sentences, and in the second task, another model is used to find the corresponding scope for each hedge cue generated in the first task. Our system follows the study of Morante and Daelemans (2009), but applies m</context>
<context position="10276" citStr="Szarvas (2008)" startWordPosition="1703" endWordPosition="1704">in of FORM, POS, LEMMA, CHUNK and TCHUNK; the number. • Of the tokens between the right closest hedge and the token in focus: chain of FORM, POS, LEMMA, CHUNK and TCHUNK; the number. • Others: the number of hedge cues in the sentence; the sequence relation between the token in focus and hedge cues (LEFT, RIGHT, MIDDLE, IN, NULL) Besides the sequence features listed above, syntactic features between the token in focus and hedge cues are explored in our classifier. Huang and Low (2007) notes that structure information stored in parse trees helps identifying the scope of negative hedge cues, and Szarvas (2008) points out that the scope of a keyword can be determined on the basic of syntax. Thus we believe that a highly accurate extraction of syntactic structure would be beneficial for this task. For sentences in the dataset, their dependency structures are extracted using GENIA Dependency parser (Sagae and Tsujii, 2007), and phrase structure using Brown self-trained biomedical parser (McClosky, 2009). Figure 2 shows the corresponding dependency tree and Figure 3 shows the corresponding phrase structure tree for the sentence in Figure 1. In the following part in the section, we will illustrate these</context>
</contexts>
<marker>Szarvas, 2008</marker>
<rawString>György Szarvas. 2008. Hedge classification in biomedical texts with a weakly supervised selection of keywords. In Proc. of ACL 2008, pages 281–289, Columbus, Ohio, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>György Szarvas</author>
<author>Veronika Vincze</author>
<author>Richárd Farkas</author>
<author>János Csirik</author>
</authors>
<title>The BioScope corpus: annotation for negation, uncertainty and their scope in biomedical texts.</title>
<date>2008</date>
<booktitle>In Proc. of BioNLP</booktitle>
<pages>38--45</pages>
<publisher>ACL.</publisher>
<location>Columbus, Ohio.</location>
<marker>Szarvas, Vincze, Farkas, Csirik, 2008</marker>
<rawString>György Szarvas, Veronika Vincze, Richárd Farkas, and János Csirik. 2008. The BioScope corpus: annotation for negation, uncertainty and their scope in biomedical texts. In Proc. of BioNLP 2008, pages 38–45, Columbus, Ohio. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Yuka Tateishi</author>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>John McNaught</author>
<author>Sophia Ananiadou</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Developing a Robust Part-of-Speech Tagger for Biomedical Text.</title>
<date>2005</date>
<booktitle>Advances in Informatics - 10th Panhellenic Conference on Informatics, LNCS 3746,</booktitle>
<pages>382--392</pages>
<contexts>
<context position="6847" citStr="Tsuruoka et al., 2005" startWordPosition="1093" endWordPosition="1096">ord form. POS Part-of-speech tag of the token. CHUNK Chunk tag of the token, e.g. B_NP, B_ SBAR, and I_NP. TCHUNK Chunk type of the token, e.g. NP. Table 1: Description of features of each token Although our system is based on token, chunk features are also important. Analyzing the training data set, it is shown that if one token in a chunk is in the hedge cue, the other tokens in the chunk are usually in the same hedge cue. The chunk feature can provide more information for the multiword hedge cues. The LEMMA, POS, and CHUNK of each token used in our system are determined using GENIA tagger (Tsuruoka et al., 2005). The selected CHUNK features in our system are listed as follows: • Cn (n=-3, -2,-1, 0, 1, 2, 3 ) • CnCn+1 (n=-3, -2,-1, 0, 1, 2, 3 ) • Cn-1CnCn+1 (n=-2,-1,0,1,-2) • Cn-2Cn-1CnCn+1 (n=-1,0,1,2) We can obtain the preliminary results using the CRF model-based classifier, but there are some missed or incorrectly classified hedge cues which can be recognized by rule-based patterns. Through statistical analysis on the training and development data sets, we obtain some effective rules for post processing, including: • If the first token of a NP chunk tag is annotated as I-cue, the whole NP chunk is</context>
</contexts>
<marker>Tsuruoka, Tateishi, Kim, Ohta, McNaught, Ananiadou, Tsujii, 2005</marker>
<rawString>Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim, Tomoko Ohta, John McNaught, Sophia Ananiadou, and Jun&apos;ichi Tsujii. 2005. Developing a Robust Part-of-Speech Tagger for Biomedical Text. Advances in Informatics - 10th Panhellenic Conference on Informatics, LNCS 3746, pages 382–392.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>