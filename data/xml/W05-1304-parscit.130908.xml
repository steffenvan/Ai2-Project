<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998247">
A Machine Learning Approach to Acronym Generation
</title>
<author confidence="0.940491">
Yoshimasa Tsuruoka
</author>
<affiliation confidence="0.663841333333333">
CREST
Japan Science and Technology Agency
Japan
</affiliation>
<author confidence="0.928807">
Sophia Ananiadou
</author>
<affiliation confidence="0.727312666666667">
School of Computing
Salford University
United Kingdom
</affiliation>
<author confidence="0.977374">
Jun’ichi Tsujii
</author>
<affiliation confidence="0.995423">
Department of Computer Science
The University of Tokyo
</affiliation>
<address confidence="0.423122">
Japan
</address>
<email confidence="0.984829666666667">
tsuruoka@is.s.u-tokyo.ac.jp
S.Ananiadou@salford.ac.uk
tsujii@is.s.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.995575" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999915695652174">
This paper presents a machine learning
approach to acronym generation. We for-
malize the generation process as a se-
quence labeling problem on the letters in
the definition (expanded form) so that a
variety of Markov modeling approaches
can be applied to this task. To con-
struct the data for training and testing, we
extracted acronym-definition pairs from
MEDLINE abstracts and manually anno-
tated each pair with positional informa-
tion about the letters in the acronym. We
have built an MEMM-based tagger using
this training data set and evaluated the
performance of acronym generation. Ex-
perimental results show that our machine
learning method gives significantly bet-
ter performance than that achieved by the
standard heuristic rule for acronym gen-
eration and enables us to obtain multi-
ple candidate acronyms together with their
likelihoods represented in probability val-
ues.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99962165">
Technical terms and named-entities play important
roles in knowledge integration and information re-
trieval in the biomedical domain. However, spelling
variations make it difficult to identify the terms con-
veying the same concept because they are written
in different manners. Acronyms constitute a major
part of spelling variations (Nenadic et al., 2002), so
proper management of acronyms leads to improved
performance of the information systems in this do-
main.
As for the methods for recognizing acronym-
definition pairs from running text, there are many
studies reporting high performance (e.g. over 96%
accuracy and 82% recall) (Yoshida et al., 2000; Ne-
nadic et al., 2002; Schwartz and Hearst, 2003; Za-
hariev, 2003; Adar, 2004). However, another aspect
that we have to consider for efficient acronym man-
agement is to generate acronyms from the given def-
inition (expanded form).
One obvious application of acronym generation
is to expand the keywords in information retrieval.
As reported in (Wren et al., 2005), for example,
you can retrieve only 25% of the documents con-
cerning the concept of “JNK” by using the key-
word “c-jun N-terminal kinase”. In more than 33%
of the documents the concept is written with its
acronym “JNK”. To alleviate this problem, some
research efforts have been devoted to constructing
a database containing a large number of acronym-
definition pairs from running text of biomedical doc-
uments (Adar, 2004).
However, the major problem of this database-
building approach is that building the database offer-
ing complete coverage is nearly impossible because
not all the biomedical documents are publicly avail-
able. Although most of the abstracts of biomedical
papers are publicly available on MEDLINE, there
is still a large number of full-papers which are not
available.
In this paper, we propose an alternative approach
</bodyText>
<page confidence="0.971325">
25
</page>
<bodyText confidence="0.93246412">
Proceedings of the ACL-ISMB Workshop on Linking Biolo ical Literature, Ontologies and Databases: Mining
Biological Semantics, pages 25–31, Detroit, June 2005. @0 2005 Association for Computational Linguistics
to providing acronyms from their definitions so
that we can obtain acronyms without consulting
acronym-definition databases.
One of the simplest way to generate acronyms
from definitions would be to choose the letters at the
beginning of each word and capitalize them. How-
ever, there are a lot of exceptions in the acronyms
appearing in biomedical documents. The followings
are some real examples of the definition-acronym
pairs that cannot be created with the simple heuristic
method.
RNA polymerase (RNAP)
antithrombin (AT)
melanoma cell adhesion molecule (Mel-CAM)
the xenoestrogen 4-tert-octylphenol (t-OP)
In this paper we present a machine learning ap-
proach to automatic generation of acronyms in order
to capture a variety of mechanisms of acronym gen-
eration. We formalize this problem as a sequence
labeling task such as part-of-speech tagging, chunk-
ing and other natural language tagging tasks so that
common Markov modeling approaches can be ap-
plied to this task.
</bodyText>
<sectionHeader confidence="0.498901" genericHeader="method">
2 Acronym Generation as a Sequence
</sectionHeader>
<subsectionHeader confidence="0.785112">
Labeling Problem
</subsectionHeader>
<bodyText confidence="0.947986216216216">
Given the definition (expanded form), the mecha-
nism of acronym generation can be regarded as the
task of selecting the appropriate action on each letter
in the definition.
Figure 1 illustrates an example, where the defini-
tion is “Duck interferon gamma” and the generated
acronym is “DuIFN-gamma”. The generation pro-
ceeds as follows:
The acronym generator outputs the first
two letters unchanged and skips the fol-
lowing three letters. Then the generator
capitalizes ‘i’ and skip the following four
letters...
By assuming that an acronym is made up of alpha-
numeric letters, spaces and hyphens, the actions be-
ing taken by the generator are classified into the fol-
lowing five classes.
SKIP
The generator skips the letter.
UPPER
If the target letter is uppercase, the generator
outputs the same letter. If the target letter is
lowercase, the generator coverts the letter into
the corresponding upper letter.
LOWER
If the target letter is lowercase, the generator
outputs the same letter. If the target letter is
uppercase, the generator coverts the letter into
the corresponding lowercase letter.
SPACE
The generator convert the letter into a space.
HYPHEN
The generator convert the letter into a hyphen.
From the probabilistic modeling point of view,
this task is to find the sequence of actions
that maximizes the following probability given the
observation
</bodyText>
<equation confidence="0.952463">
(1)
</equation>
<bodyText confidence="0.947124333333333">
Observations are the letters in the definition and
various types of features derived from them. We de-
compose the probability in a left-to-right manner.
(2)
By making a first-order markov assumption, the
equation becomes
</bodyText>
<equation confidence="0.513141">
(3)
</equation>
<bodyText confidence="0.998888666666667">
If we have the training data containing a large
number of definition-acronym pairs where the defi-
nition is annotated with the labels for actions, we can
estimate the parameters of this probabilistic model
and the best action sequence can be efficiently com-
puted by using a Viterbi decoding algorithm.
In this paper we adopt a maximum entropy model
(Berger et al., 1996) to estimate the local probabili-
ties since it can incorporate diverse types
of features with reasonable computational cost. This
modeling, as a whole, is called Maximum Entropy
Markov Modeling (MEMM).
</bodyText>
<page confidence="0.958038">
26
</page>
<figure confidence="0.999939558823529">
Definition Actions
D UPPER
u LOWER
c SKIP
k SKIP
SKIP
i UPPER
n SKIP
t SKIP
e SKIP
r SKIP
f UPPER
e SKIP
r SKIP
o SKIP
n UPPER
HYPHEN
g LOWER
a LOWER
m LOWER
m LOWER
a LOWER
Acronym
D
u
I
F
N
-
g
a
m
m
a
</figure>
<figureCaption confidence="0.999798">
Figure 1: Acronym generation as a sequence labeling problem. The definition is “Duck interferon gamma”
</figureCaption>
<bodyText confidence="0.968957470588236">
and the acronym is “DuIFN-gamma”. Each letter in the acronym is generated from a letter in the definition
following the action for the letter.
Regularization is important in maximum entropy
modeling to avoid overfitting to the training data.
For this purpose, we use the maximum entropy
modeling with inequality constraints (Kazama and
Tsujii, 2003). The model gives equally good per-
formance as the maximum entropy modeling with
Gaussian priors (Chen and Rosenfeld, 1999), and
the size of the resulting model is much smaller than
that of Gaussian priors because most of the param-
eters become zero. This characteristic enables us
to easily handle the model data and carry out quick
decoding, which is convenient when we repetitively
perform experiments. This modeling has one param-
eter to tune, which is called width factor. We set this
parameter to be 1.0 throughout the experiments.
</bodyText>
<sectionHeader confidence="0.978548" genericHeader="method">
3 The Data for Training and Testing
</sectionHeader>
<bodyText confidence="0.999517384615385">
Since there is no training data available for the ma-
chine learning task described in the previous section,
we manually created the data. First, we extracted
definition-acronym pairs from MEDLINE abstracts
using the acronym acquisition method proposed by
(Schwartz and Hearst, 2003). The abstracts used for
constructing the data were randomly selected from
the abstracts published in the year of 2001. Dupli-
cated pairs were removed from the set.
In acquiring the pairs from the documents, we fo-
cused only on the pairs that appear in the form of
... expanded form (acronym) ...
We then manually removed misrecognized pairs
and annotated each pair with positional informa-
tion. The positional information tells which letter
in the definition should correspond to a letter in the
acronym. Table 1 lists a portion of the data. For
example, the positional information in the first pair
indicates that the first letter ‘i’ in the definition cor-
responds to ‘I’ in the acronym, and the 12th letter
‘m’ corresponds to ‘M’.
With this positional information, we can create
the training data for the sequence labeling task be-
cause there is one-to-one correspondence between
the sequence labels and the data with positional in-
formation. In other words, we can determine the ap-
</bodyText>
<page confidence="0.983845">
27
</page>
<table confidence="0.9999486">
Definition Acronym Positional
Information
intestinal metaplasia IM 1, 12
lactate dehydrogenase LDH 1, 9, 11
cytokeratin CK 1, 5
cytokeratins CKs 1, 5, 12
Epstein-Barr virus EBV 1, 9, 14
30-base pairs bp 4, 9
in-situ hybridization ISH 1, 4, 9
: : :
</table>
<tableCaption confidence="0.921725">
Table 1: Curated data containing definitions, their
acronyms and the positional information.
</tableCaption>
<bodyText confidence="0.996278">
propriate action for each letter in the definition by
comparing the letter with the corresponding letter in
the acronym.
</bodyText>
<sectionHeader confidence="0.999796" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.9924907">
Maximum entropy modeling allows us to incorpo-
rate diverse types of features. In this paper we use
the following types of features in local classification.
As an example, consider the situation where we are
going to determine the action at the letter ‘f’ in the
definition “Duck interferon gamma”.
Letter unigram (UNI)
The unigrams of the neighboring letters. (i.e.
“ r”, “ f”, and “ e”)
Letter bigram (BI)
The bigrams of the neighboring letters. (i.e.
Letter trigram (TRI)
The trigrams of the neighboring letters. (i.e.
erf”, “ rfe”, “ fer”,
and “ ero”)
Action history (HIS)
The preceding action (i.e. SKIP)
Orthographic features (ORT)
Whether the target letter is uppercase or not
(i.e. false)
</bodyText>
<table confidence="0.825656461538462">
Definition Length (LEN)
Rank Probability String
1 0.779 TBI
2 0.062 TUBI
3 0.028 TB
4 0.019 TbI
5 0.015 TB-I
6 0.009 tBI
7 0.008 TI
8 0.007 TBi
9 0.002 TUB
10 0.002 TUbI
ANSWER TBI
</table>
<tableCaption confidence="0.941196">
Table 2: Generated acronyms for “traumatic brain
injury”.
</tableCaption>
<bodyText confidence="0.96092">
The number of the words in the definition (i.e.
“len=3”)
Letter sequence (SEQ)
</bodyText>
<listItem confidence="0.942419461538462">
1. The sequence of the letters ranging from
the beginning of the word to the target let-
ter. (i.e. “ interf”)
2. The sequence of the letters ranging from
the target letter to the end of the word. (i.e.
“ feron”)
3. The word containing the target letter. (i.e.
“ interferon”)
Distance (DIS)
1. The distance between the target letter and
the beginning of the word. (i.e. “
6”)
2. The distance between the target letter and
</listItem>
<bodyText confidence="0.640321">
the tail of the word. (i.e. “ 5”)
</bodyText>
<sectionHeader confidence="0.998382" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999872">
To evaluate the performance of the acronym gener-
ation method presented in the previous section, we
ran five-fold cross validation experiments using the
manually curated data set. The data set consists of
1,901 definition-acronym pairs.
For comparison, we also tested the performance
of the popular heuristics for acronym generation in
which we choose the letters at the beginning of each
word in the definition and capitalize them.
</bodyText>
<equation confidence="0.963424333333333">
er”, “ rf”, “ fe”, and “ er”)
“
“ ter”, “
</equation>
<page confidence="0.993072">
28
</page>
<table confidence="0.869594083333333">
Rank Probability String
1 0.423 ORF1
2 0.096 OR1
3 0.085 ORF-1
4 0.070 RF1
5 0.047 OrF1
6 0.036 OF1
7 0.025 ORf1
8 0.019 OR-1
9 0.016 R1
10 0.014 RF-1
ANSWER ORF-1
</table>
<tableCaption confidence="0.989926">
Table 3: Generated acronyms for “open reading
frame 1”.
</tableCaption>
<figure confidence="0.561704333333333">
Rank Probability String
1 0.163 RNA-P
2 0.147 RP
3 0.118 RNP
4 0.110 RNAP
5 0.064 RA-P
6 0.051 R-P
7 0.043 RAP
8 0.041 RN-P
9 0.034 RNA-PM
10 0.030 RPM
ANSWER RNAP
</figure>
<tableCaption confidence="0.9614655">
Table 4: Generated acronyms for “RNA
polymerase”.
</tableCaption>
<table confidence="0.998398083333333">
Rank Probability String
1 0.405 MCPP
2 0.149 MCP
3 0.056 MCP
4 0.031 MPP
5 0.028 McPP
6 0.024 MchPP
7 0.020 MC
8 0.011 MP
9 0.011 mCPP
10 0.010 MCRPP
ANSWER mCPP
</table>
<tableCaption confidence="0.9623275">
Table 5: Generated acronyms for
“meta-chlorophenylpiperazine”.
</tableCaption>
<table confidence="0.899828333333333">
Rank Probability String
1 0.811 TV
2 0.034 TSV
3 0.030 TCV
4 0.021 Tv
5 0.019 TVs
6 0.013 T-V
7 0.008 TOV
8 0.004 TSCV
9 0.002 T-v
10 0.001 TOSV
ANSWER TOSV
</table>
<tableCaption confidence="0.995164">
Table 6: Generated acronyms for “Toscana virus”.
</tableCaption>
<subsectionHeader confidence="0.981015">
5.1 Generated Acronyms
</subsectionHeader>
<bodyText confidence="0.999985714285714">
Tables 2 to 5 show some examples of generated
acronyms together with their probabilities. They
are sorted with their probabilities and the top ten
acronyms are shown. The correct acronym given in
the training data is described in the bottom row in
each table.
In Table 2, the definition is “traumatic brain in-
jury” and the correct acronym is “TBI”. This is the
simplest case in acronym generation, where the first
letter of each word in the definition is to be capital-
ized. Our acronym generator gives a high probabil-
ity to the correct acronym and it is ranked at the top.
Table 3 shows a slightly more complex case,
where the generator needs to convert the space be-
</bodyText>
<footnote confidence="0.553232666666667">
Rank Coverage (%)
1 55.2
2 65.8
3 70.4
4 73.2
5 75.4
6 76.7
7 78.3
8 79.8
9 81.1
10 82.2
BASELINE 47.3
</footnote>
<tableCaption confidence="0.9137985">
Table 7: Coverage achieved with the Top N Candi-
dates.
</tableCaption>
<page confidence="0.998612">
29
</page>
<bodyText confidence="0.999761470588235">
tween ‘F’ and ‘1’ into a hyphen. The correct answer
is located at the third rank.
The definition in Table 4 is “RNA polymerase”
and the correct acronym is “RNAP”, so the gener-
ator needs to the first three letters unchanged. The
correct answer is located at the fourth rank, and the
probability given the correct answer does not have a
large gap with the top-ranked acronym.
Table 5 shows a more difficult case, where you
need to output the first letter in lowercase and choose
appropriate letters from the string having no delim-
iters (e.g. spaces and hyphens). Our acronym gener-
ator outputs the correct acronym at the nine-th rank
but the probability given this acronym is very low
compared to that given to the top-ranked string.
Table 6 shows a similar case. The probability
given to the correct acronym is very low.
</bodyText>
<subsectionHeader confidence="0.979148">
5.2 Coverage
</subsectionHeader>
<bodyText confidence="0.999786785714286">
Table 7 shows how much percentage of the cor-
rect acronyms are covered if we take top N can-
didates from the outputs of the acronym generator.
The bottom line (BASELINE) shows the coverage
achieved by generating one acronym using the stan-
dard heuristic rule for acronym generation. Note that
the coverage achieved with a single candidate (Rank
1) is better that of BASELINE.
If we take top five candidates, we can have a cov-
erage of 75.4%, which is considerably better than
that achieved by the heuristic rule. This suggests
that the acronym generator could be used to signif-
icantly improve the performance of the systems for
information retrieval and information integration.
</bodyText>
<subsectionHeader confidence="0.831992">
5.3 Features
</subsectionHeader>
<bodyText confidence="0.998996692307692">
To evaluate how much individual types of features
affect the generation performance, we ran experi-
ments using different feature types. Table 8 shows
the results. Overall, the results show that various
types of features have been successfully incorpo-
rated in the MEMM modeling and individual types
of features contribute to improving performance.
The performance achieved with only unigram fea-
tures is almost the same as that achieved by the
heuristic rule. Note that the features on the previous
state improve the performance, which suggests that
our selection of the states in the Markov modeling is
a reasonable choice for this task.
</bodyText>
<figure confidence="0.996648777777778">
100
90
80
70
60
50
40
100 1000
Number of Training Samples
</figure>
<figureCaption confidence="0.999584">
Figure 2: Learning curve.
</figureCaption>
<subsectionHeader confidence="0.986576">
5.4 Learning Curve
</subsectionHeader>
<bodyText confidence="0.9999128">
Figure 2 shows a learning curve of our acronym
generator, which shows the relationship between the
number of the training samples and the performance
of the system. The graph clearly indicates that the
performance consistently improves as the training
data increases and still continues to improve even
when the size of the training data reaches the max-
imum. This suggests that we can achieve improved
performance by increasing the annotated data for
training.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="method">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999970583333333">
We presented a machine learning approach to
acronym generation. In this approach, we regarded
the generation process as a sequence labeling prob-
lem, and we manually created the data for training
and testing.
Experimental results using 1901 definition-
acronym pairs, we achieved a coverage of 55.1%,
which is significantly bettern than that achieved by
the standard heuristic rule for acronym generation.
The algorithm also enables us to have other acronym
candidates together with the probabilities represent-
ing their likelihood.
</bodyText>
<sectionHeader confidence="0.505267" genericHeader="discussions">
6.1 Future work
</sectionHeader>
<bodyText confidence="0.9990582">
In this paper we did not consider the generation
mechanisms where the letters in the acronym appear
in a different order in the definition. Since about 3%
of acronyms reportedly involve this types of gener-
ation mechanism (Schwartz and Hearst, 2003), we
</bodyText>
<figure confidence="0.67754575">
Coverage (%)
Top 1
Top 5
Top 10
</figure>
<page confidence="0.987517">
30
</page>
<table confidence="0.9905673">
Feature Templates Top 1 Top 5 Top 10
Coverage (%) Coverage (%) Coverage (%)
UNI 48.2 66.2 74.2
UNI, BI 50.1 71.2 78.3
UNI, BI, TRI 50.4 72.3 80.1
UNI, BI, TRI, HIS 50.6 73.6 81.2
UNI, BI, TRI, HIS, ORT 51.0 73.9 80.9
UNI, BI, TRI, HIS, ORT, LEN 53.9 74.6 81.3
UNI, BI, TRI, HIS, ORT, LEN, DIS 54.4 75.0 81.8
UNI, BI, TRI, HIS, ORT, LEN, DIS, SEQ 55.1 75.4 82.2
</table>
<tableCaption confidence="0.999854">
Table 8: Performance with Different Feature Sets.
</tableCaption>
<bodyText confidence="0.9886267">
might further improve performance by considering
such permutation of letters.
As the learning curve (Fig 2) suggested, one ob-
vious way to improve the performance is to increase
the training data. The size of the training data used
in the experiments is fairly small compared to those
in other sequence tagging tasks such POS tagging
and chunking. We plan to increase the size of the
training data with a semi-automatic way that could
reduce the human effort for annotation.
</bodyText>
<sectionHeader confidence="0.9991" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99985365625">
Eytan Adar. 2004. Sarad: A simple and robust abbrevia-
tion dictionary. Bioinformatics, 20(4):527–533.
Adam L. Berger, Stephen A. Della Pietra, and Vincent
J. Della Pietra. 1996. A maximum entropy approach
to natural language processing. Computational Lin-
guistics, 22(1):39–71.
Stanley F. Chen and Ronald Rosenfeld. 1999. A gaus-
sian prior for smoothing maximum entropy models.
Technical Report CMUCS -99-108, Carnegie Mellon
University.
Jun’ichi Kazama and Jun’ichi Tsujii. 2003. Evaluation
and extension of maximum entropy models with in-
equality constraints. In Proceedings of EMNLP 2003.
Goran Nenadic, Irena Spasic, and Sophia Ananiadou.
2002. Automatic acronym acquisition and term vari-
ation management within domain-specific texts. In
Proceedings of the LREC-3, pages 2155–2162.
Ariel Schwartz and Marti Hearst. 2003. A simple
algorithm for identifying abbreviation definitions in
biomedical texts,. In Proceedings of the Pacific Sym-
posium on Biocomputing (PSB 2003).
Jonathan D. Wren, Jeffrey T. Chang, James Pustejovsky,
Eytan Adar, Harold R. Garner, and Russ B. Altman.
2005. Biomedical term mapping databases. Nucleic
Acid Research, 33.
M. Yoshida, K. Fukuda, and T. Takagi. 2000. Pnad-css:
a workbench for constructing a protein name abbrevi-
ation dictionary. Bioinformatics, 16(2):169–175.
Manuel Zahariev. 2003. An efficient methodology for
acronym-expansion matching. In Proceedings of the
International Conference on Information and Knowl-
edge Engineering (IKE).
</reference>
<page confidence="0.999913">
31
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.065448">
<title confidence="0.999772">A Machine Learning Approach to Acronym Generation</title>
<author confidence="0.975827">Yoshimasa Tsuruoka</author>
<affiliation confidence="0.7823635">CREST Japan Science and Technology Agency Japan Sophia School of Salford</affiliation>
<address confidence="0.539598">United Kingdom</address>
<author confidence="0.966211">Jun’ichi Tsujii</author>
<affiliation confidence="0.99978">Department of Computer Science The University of Tokyo</affiliation>
<address confidence="0.67285">Japan</address>
<email confidence="0.979163">tsujii@is.s.u-tokyo.ac.jp</email>
<abstract confidence="0.991796833333333">This paper presents a machine learning approach to acronym generation. We formalize the generation process as a sequence labeling problem on the letters in the definition (expanded form) so that a variety of Markov modeling approaches can be applied to this task. To construct the data for training and testing, we extracted acronym-definition pairs from MEDLINE abstracts and manually annotated each pair with positional information about the letters in the acronym. We have built an MEMM-based tagger using this training data set and evaluated the performance of acronym generation. Experimental results show that our machine learning method gives significantly better performance than that achieved by the standard heuristic rule for acronym generation and enables us to obtain multiple candidate acronyms together with their likelihoods represented in probability values.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eytan Adar</author>
</authors>
<title>Sarad: A simple and robust abbreviation dictionary.</title>
<date>2004</date>
<journal>Bioinformatics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="1974" citStr="Adar, 2004" startWordPosition="291" endWordPosition="292">edical domain. However, spelling variations make it difficult to identify the terms conveying the same concept because they are written in different manners. Acronyms constitute a major part of spelling variations (Nenadic et al., 2002), so proper management of acronyms leads to improved performance of the information systems in this domain. As for the methods for recognizing acronymdefinition pairs from running text, there are many studies reporting high performance (e.g. over 96% accuracy and 82% recall) (Yoshida et al., 2000; Nenadic et al., 2002; Schwartz and Hearst, 2003; Zahariev, 2003; Adar, 2004). However, another aspect that we have to consider for efficient acronym management is to generate acronyms from the given definition (expanded form). One obvious application of acronym generation is to expand the keywords in information retrieval. As reported in (Wren et al., 2005), for example, you can retrieve only 25% of the documents concerning the concept of “JNK” by using the keyword “c-jun N-terminal kinase”. In more than 33% of the documents the concept is written with its acronym “JNK”. To alleviate this problem, some research efforts have been devoted to constructing a database cont</context>
</contexts>
<marker>Adar, 2004</marker>
<rawString>Eytan Adar. 2004. Sarad: A simple and robust abbreviation dictionary. Bioinformatics, 20(4):527–533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="6280" citStr="Berger et al., 1996" startWordPosition="969" endWordPosition="972"> given the observation (1) Observations are the letters in the definition and various types of features derived from them. We decompose the probability in a left-to-right manner. (2) By making a first-order markov assumption, the equation becomes (3) If we have the training data containing a large number of definition-acronym pairs where the definition is annotated with the labels for actions, we can estimate the parameters of this probabilistic model and the best action sequence can be efficiently computed by using a Viterbi decoding algorithm. In this paper we adopt a maximum entropy model (Berger et al., 1996) to estimate the local probabilities since it can incorporate diverse types of features with reasonable computational cost. This modeling, as a whole, is called Maximum Entropy Markov Modeling (MEMM). 26 Definition Actions D UPPER u LOWER c SKIP k SKIP SKIP i UPPER n SKIP t SKIP e SKIP r SKIP f UPPER e SKIP r SKIP o SKIP n UPPER HYPHEN g LOWER a LOWER m LOWER m LOWER a LOWER Acronym D u I F N - g a m m a Figure 1: Acronym generation as a sequence labeling problem. The definition is “Duck interferon gamma” and the acronym is “DuIFN-gamma”. Each letter in the acronym is generated from a letter i</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen A. Della Pietra, and Vincent J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Ronald Rosenfeld</author>
</authors>
<title>A gaussian prior for smoothing maximum entropy models.</title>
<date>1999</date>
<tech>Technical Report CMUCS -99-108,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="7262" citStr="Chen and Rosenfeld, 1999" startWordPosition="1142" endWordPosition="1145">OWER m LOWER a LOWER Acronym D u I F N - g a m m a Figure 1: Acronym generation as a sequence labeling problem. The definition is “Duck interferon gamma” and the acronym is “DuIFN-gamma”. Each letter in the acronym is generated from a letter in the definition following the action for the letter. Regularization is important in maximum entropy modeling to avoid overfitting to the training data. For this purpose, we use the maximum entropy modeling with inequality constraints (Kazama and Tsujii, 2003). The model gives equally good performance as the maximum entropy modeling with Gaussian priors (Chen and Rosenfeld, 1999), and the size of the resulting model is much smaller than that of Gaussian priors because most of the parameters become zero. This characteristic enables us to easily handle the model data and carry out quick decoding, which is convenient when we repetitively perform experiments. This modeling has one parameter to tune, which is called width factor. We set this parameter to be 1.0 throughout the experiments. 3 The Data for Training and Testing Since there is no training data available for the machine learning task described in the previous section, we manually created the data. First, we extr</context>
</contexts>
<marker>Chen, Rosenfeld, 1999</marker>
<rawString>Stanley F. Chen and Ronald Rosenfeld. 1999. A gaussian prior for smoothing maximum entropy models. Technical Report CMUCS -99-108, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun’ichi Kazama</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Evaluation and extension of maximum entropy models with inequality constraints.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="7140" citStr="Kazama and Tsujii, 2003" startWordPosition="1123" endWordPosition="1126">ER c SKIP k SKIP SKIP i UPPER n SKIP t SKIP e SKIP r SKIP f UPPER e SKIP r SKIP o SKIP n UPPER HYPHEN g LOWER a LOWER m LOWER m LOWER a LOWER Acronym D u I F N - g a m m a Figure 1: Acronym generation as a sequence labeling problem. The definition is “Duck interferon gamma” and the acronym is “DuIFN-gamma”. Each letter in the acronym is generated from a letter in the definition following the action for the letter. Regularization is important in maximum entropy modeling to avoid overfitting to the training data. For this purpose, we use the maximum entropy modeling with inequality constraints (Kazama and Tsujii, 2003). The model gives equally good performance as the maximum entropy modeling with Gaussian priors (Chen and Rosenfeld, 1999), and the size of the resulting model is much smaller than that of Gaussian priors because most of the parameters become zero. This characteristic enables us to easily handle the model data and carry out quick decoding, which is convenient when we repetitively perform experiments. This modeling has one parameter to tune, which is called width factor. We set this parameter to be 1.0 throughout the experiments. 3 The Data for Training and Testing Since there is no training da</context>
</contexts>
<marker>Kazama, Tsujii, 2003</marker>
<rawString>Jun’ichi Kazama and Jun’ichi Tsujii. 2003. Evaluation and extension of maximum entropy models with inequality constraints. In Proceedings of EMNLP 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Goran Nenadic</author>
<author>Irena Spasic</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Automatic acronym acquisition and term variation management within domain-specific texts.</title>
<date>2002</date>
<booktitle>In Proceedings of the LREC-3,</booktitle>
<pages>2155--2162</pages>
<contexts>
<context position="1599" citStr="Nenadic et al., 2002" startWordPosition="228" endWordPosition="231">ine learning method gives significantly better performance than that achieved by the standard heuristic rule for acronym generation and enables us to obtain multiple candidate acronyms together with their likelihoods represented in probability values. 1 Introduction Technical terms and named-entities play important roles in knowledge integration and information retrieval in the biomedical domain. However, spelling variations make it difficult to identify the terms conveying the same concept because they are written in different manners. Acronyms constitute a major part of spelling variations (Nenadic et al., 2002), so proper management of acronyms leads to improved performance of the information systems in this domain. As for the methods for recognizing acronymdefinition pairs from running text, there are many studies reporting high performance (e.g. over 96% accuracy and 82% recall) (Yoshida et al., 2000; Nenadic et al., 2002; Schwartz and Hearst, 2003; Zahariev, 2003; Adar, 2004). However, another aspect that we have to consider for efficient acronym management is to generate acronyms from the given definition (expanded form). One obvious application of acronym generation is to expand the keywords in</context>
</contexts>
<marker>Nenadic, Spasic, Ananiadou, 2002</marker>
<rawString>Goran Nenadic, Irena Spasic, and Sophia Ananiadou. 2002. Automatic acronym acquisition and term variation management within domain-specific texts. In Proceedings of the LREC-3, pages 2155–2162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariel Schwartz</author>
<author>Marti Hearst</author>
</authors>
<title>A simple algorithm for identifying abbreviation definitions in biomedical texts,.</title>
<date>2003</date>
<booktitle>In Proceedings of the Pacific Symposium on Biocomputing (PSB</booktitle>
<contexts>
<context position="1945" citStr="Schwartz and Hearst, 2003" startWordPosition="284" endWordPosition="287">ation and information retrieval in the biomedical domain. However, spelling variations make it difficult to identify the terms conveying the same concept because they are written in different manners. Acronyms constitute a major part of spelling variations (Nenadic et al., 2002), so proper management of acronyms leads to improved performance of the information systems in this domain. As for the methods for recognizing acronymdefinition pairs from running text, there are many studies reporting high performance (e.g. over 96% accuracy and 82% recall) (Yoshida et al., 2000; Nenadic et al., 2002; Schwartz and Hearst, 2003; Zahariev, 2003; Adar, 2004). However, another aspect that we have to consider for efficient acronym management is to generate acronyms from the given definition (expanded form). One obvious application of acronym generation is to expand the keywords in information retrieval. As reported in (Wren et al., 2005), for example, you can retrieve only 25% of the documents concerning the concept of “JNK” by using the keyword “c-jun N-terminal kinase”. In more than 33% of the documents the concept is written with its acronym “JNK”. To alleviate this problem, some research efforts have been devoted to</context>
<context position="7992" citStr="Schwartz and Hearst, 2003" startWordPosition="1260" endWordPosition="1263">arameters become zero. This characteristic enables us to easily handle the model data and carry out quick decoding, which is convenient when we repetitively perform experiments. This modeling has one parameter to tune, which is called width factor. We set this parameter to be 1.0 throughout the experiments. 3 The Data for Training and Testing Since there is no training data available for the machine learning task described in the previous section, we manually created the data. First, we extracted definition-acronym pairs from MEDLINE abstracts using the acronym acquisition method proposed by (Schwartz and Hearst, 2003). The abstracts used for constructing the data were randomly selected from the abstracts published in the year of 2001. Duplicated pairs were removed from the set. In acquiring the pairs from the documents, we focused only on the pairs that appear in the form of ... expanded form (acronym) ... We then manually removed misrecognized pairs and annotated each pair with positional information. The positional information tells which letter in the definition should correspond to a letter in the acronym. Table 1 lists a portion of the data. For example, the positional information in the first pair in</context>
<context position="16646" citStr="Schwartz and Hearst, 2003" startWordPosition="2750" endWordPosition="2753">eated the data for training and testing. Experimental results using 1901 definitionacronym pairs, we achieved a coverage of 55.1%, which is significantly bettern than that achieved by the standard heuristic rule for acronym generation. The algorithm also enables us to have other acronym candidates together with the probabilities representing their likelihood. 6.1 Future work In this paper we did not consider the generation mechanisms where the letters in the acronym appear in a different order in the definition. Since about 3% of acronyms reportedly involve this types of generation mechanism (Schwartz and Hearst, 2003), we Coverage (%) Top 1 Top 5 Top 10 30 Feature Templates Top 1 Top 5 Top 10 Coverage (%) Coverage (%) Coverage (%) UNI 48.2 66.2 74.2 UNI, BI 50.1 71.2 78.3 UNI, BI, TRI 50.4 72.3 80.1 UNI, BI, TRI, HIS 50.6 73.6 81.2 UNI, BI, TRI, HIS, ORT 51.0 73.9 80.9 UNI, BI, TRI, HIS, ORT, LEN 53.9 74.6 81.3 UNI, BI, TRI, HIS, ORT, LEN, DIS 54.4 75.0 81.8 UNI, BI, TRI, HIS, ORT, LEN, DIS, SEQ 55.1 75.4 82.2 Table 8: Performance with Different Feature Sets. might further improve performance by considering such permutation of letters. As the learning curve (Fig 2) suggested, one obvious way to improve the</context>
</contexts>
<marker>Schwartz, Hearst, 2003</marker>
<rawString>Ariel Schwartz and Marti Hearst. 2003. A simple algorithm for identifying abbreviation definitions in biomedical texts,. In Proceedings of the Pacific Symposium on Biocomputing (PSB 2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan D Wren</author>
<author>Jeffrey T Chang</author>
<author>James Pustejovsky</author>
<author>Eytan Adar</author>
<author>Harold R Garner</author>
<author>Russ B Altman</author>
</authors>
<title>Biomedical term mapping databases.</title>
<date>2005</date>
<journal>Nucleic Acid Research,</journal>
<volume>33</volume>
<contexts>
<context position="2257" citStr="Wren et al., 2005" startWordPosition="334" endWordPosition="337"> to improved performance of the information systems in this domain. As for the methods for recognizing acronymdefinition pairs from running text, there are many studies reporting high performance (e.g. over 96% accuracy and 82% recall) (Yoshida et al., 2000; Nenadic et al., 2002; Schwartz and Hearst, 2003; Zahariev, 2003; Adar, 2004). However, another aspect that we have to consider for efficient acronym management is to generate acronyms from the given definition (expanded form). One obvious application of acronym generation is to expand the keywords in information retrieval. As reported in (Wren et al., 2005), for example, you can retrieve only 25% of the documents concerning the concept of “JNK” by using the keyword “c-jun N-terminal kinase”. In more than 33% of the documents the concept is written with its acronym “JNK”. To alleviate this problem, some research efforts have been devoted to constructing a database containing a large number of acronymdefinition pairs from running text of biomedical documents (Adar, 2004). However, the major problem of this databasebuilding approach is that building the database offering complete coverage is nearly impossible because not all the biomedical document</context>
</contexts>
<marker>Wren, Chang, Pustejovsky, Adar, Garner, Altman, 2005</marker>
<rawString>Jonathan D. Wren, Jeffrey T. Chang, James Pustejovsky, Eytan Adar, Harold R. Garner, and Russ B. Altman. 2005. Biomedical term mapping databases. Nucleic Acid Research, 33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Yoshida</author>
<author>K Fukuda</author>
<author>T Takagi</author>
</authors>
<title>Pnad-css: a workbench for constructing a protein name abbreviation dictionary.</title>
<date>2000</date>
<journal>Bioinformatics,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="1896" citStr="Yoshida et al., 2000" startWordPosition="275" endWordPosition="278">ies play important roles in knowledge integration and information retrieval in the biomedical domain. However, spelling variations make it difficult to identify the terms conveying the same concept because they are written in different manners. Acronyms constitute a major part of spelling variations (Nenadic et al., 2002), so proper management of acronyms leads to improved performance of the information systems in this domain. As for the methods for recognizing acronymdefinition pairs from running text, there are many studies reporting high performance (e.g. over 96% accuracy and 82% recall) (Yoshida et al., 2000; Nenadic et al., 2002; Schwartz and Hearst, 2003; Zahariev, 2003; Adar, 2004). However, another aspect that we have to consider for efficient acronym management is to generate acronyms from the given definition (expanded form). One obvious application of acronym generation is to expand the keywords in information retrieval. As reported in (Wren et al., 2005), for example, you can retrieve only 25% of the documents concerning the concept of “JNK” by using the keyword “c-jun N-terminal kinase”. In more than 33% of the documents the concept is written with its acronym “JNK”. To alleviate this pr</context>
</contexts>
<marker>Yoshida, Fukuda, Takagi, 2000</marker>
<rawString>M. Yoshida, K. Fukuda, and T. Takagi. 2000. Pnad-css: a workbench for constructing a protein name abbreviation dictionary. Bioinformatics, 16(2):169–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuel Zahariev</author>
</authors>
<title>An efficient methodology for acronym-expansion matching.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Information and Knowledge Engineering (IKE).</booktitle>
<contexts>
<context position="1961" citStr="Zahariev, 2003" startWordPosition="288" endWordPosition="290">eval in the biomedical domain. However, spelling variations make it difficult to identify the terms conveying the same concept because they are written in different manners. Acronyms constitute a major part of spelling variations (Nenadic et al., 2002), so proper management of acronyms leads to improved performance of the information systems in this domain. As for the methods for recognizing acronymdefinition pairs from running text, there are many studies reporting high performance (e.g. over 96% accuracy and 82% recall) (Yoshida et al., 2000; Nenadic et al., 2002; Schwartz and Hearst, 2003; Zahariev, 2003; Adar, 2004). However, another aspect that we have to consider for efficient acronym management is to generate acronyms from the given definition (expanded form). One obvious application of acronym generation is to expand the keywords in information retrieval. As reported in (Wren et al., 2005), for example, you can retrieve only 25% of the documents concerning the concept of “JNK” by using the keyword “c-jun N-terminal kinase”. In more than 33% of the documents the concept is written with its acronym “JNK”. To alleviate this problem, some research efforts have been devoted to constructing a </context>
</contexts>
<marker>Zahariev, 2003</marker>
<rawString>Manuel Zahariev. 2003. An efficient methodology for acronym-expansion matching. In Proceedings of the International Conference on Information and Knowledge Engineering (IKE).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>