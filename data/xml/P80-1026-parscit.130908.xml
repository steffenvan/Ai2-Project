<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.67815">
Flexible Parsing
</title>
<author confidence="0.505625">
Phil Hayes and George Mouradian
</author>
<affiliation confidence="0.7522625">
Computer Science Department, Carnegie-Mellon University
Pittsburgh. PA 15213, USA
</affiliation>
<bodyText confidence="0.995858333333333">
communicating via a keyboard and display screen. We then present a
taxonomy of grammatical deviations common in this context, and by
implication a set of parsing flexibilities needed to deal.with them.
</bodyText>
<listItem confidence="0.579164">
2. I. Communication with a Limited-Domain System
</listItem>
<bodyText confidence="0.993226434782609">
In the remainder of this paper, we will focus on a restricted type of
communication situation, that between a limited-domain system and its
user, and on the parsing flexibilities needed by such a system to cope with
the user&apos;s inevitable grammatical deviations. Examples of the type of
system we have in mind are data-base retrieval systems. electronic mail
systems. medical diagnosis systems. or any systems operating in a domain
so restricted that they can completely understand any relevant input a
user might provide. In short, exactly the kind Of system that is normally
used for work in applied natural language processing. There are several
points to be made.
Abstract&apos;
When people use natural language in natural settings, they often
use it ungrammatically, missing out or repeating words.
breaking-off and restarting, speaking in fragments, etc.. Their
human listeners are usually able to cope with these deviations with
little difficulty. If a computer system wishes tc accept natural
language input from its users on a routine basis, it must display a
similar indifference. In this paper, we outline a set of parsing
flexibilities that such a system should provide. We go on to
describe FlexP. a bottom-up pattern-matching parser that we have
designed and implemented to provide these flexibilities for
restricted natural language input to a limited-domain computer
system.
</bodyText>
<sectionHeader confidence="0.460295" genericHeader="method">
1. The Importance of Flexible Parsing
</sectionHeader>
<bodyText confidence="0.996501222222222">
When people use natural language in natural conversation, they often
do not respect grammatical niceties. Instead of speaking sequences of
grammatically well-formed and complete sentences, people often miss out
or repeat words or phrases, break off what they are saying and rephrase
or replace it, speak in fragments, or use otherwise incorrect grammar.
The following example conversation involves a number of these
grammatical deviations:
A: I want ... can you send a memo a message to to Smith
Ci: Is that John or John Smith or Jim Smith.
A: Jim
Instead of being unable or refusing to parse such ungrammaticality,
human listeners are generally unperturbed by it. Neither participant in the
above example, for instance, would have any difficulty in following the
conversation.
If computers are ever to converse naturally with humans, they must be
able to parse their input as flexibly and robustly as humans do. While
considerable advances have been made in recent years in applied natural
language processing, few of the systems that have been constructed have
pakl sufficient attention to the kinds of deviation that will inevitably occur
in their imput if they are used in a natural environment. In many cases, if
the user&apos;s input does not conform to the system&apos;s grammar, an indication
of incomprehension followed by a request to rephrase may be the best he
can expect. We believe that such inflexibility in parsing severely limits the
practicality of natural language computer interlaces, and is a major reason
why natural language has yet to find wide acceptance in such applications
as database retrieval or interactive command languages.
In this paper, we report on a flexible parser, called FlexP, suitable for
use with a restricted natural language interface to a limited-domain
computer system. We describe first the kinds of grammatical deviations
we are trying to deal with, then the basic design decisions for FlexP with
justification for them based on the kinds of problem to be solved, and
finally more details of our parsing system with worked examples of its
operation. These examples,and most of the others in the paper, represent
natural language input to an electronic mail system that we and others [11
are constructing as part of our research on user interfaces. This system
employs FlexP to parse its input.
</bodyText>
<sectionHeader confidence="0.965795" genericHeader="method">
2. Types of Grammatical Deviation
</sectionHeader>
<bodyText confidence="0.9996905">
There are a number of distinct types of grammatical deviation and not
all types are found in all types of communication situation. In this section.
we first define the restricted type ol communication situation that we will
be concerned with, that of a limited-domain computer system and its user
First. although .7.uch systems can be expected to parse and understand
anything relevant to their domain, their users cannot be expected to
confine themselves to relevant input. As Bobrow et. at. 121 note, users
often explain their umferlying motivations or otherwise justify their
ii S in terms quite ii relevant to MO domain of the system. The result
is that such systems cannot expect to parse all tti ii input even with the
use of flexible parsing techniques.
Secondly. a flexible parser is just part of the conversational component
of such a system. .and cannot solve all parsing problems by itself. For
example. if a parser can extract two coherent fragments from an otherwise
incomprehensible input, the decisions about what the system should
next must be made by another component of the system. A decision on
whether to jump to a conclusion about what the user intended, to present
him with a set of alternative interpretations, or to profess total confusion,
can only be made with information about the history of the conversation,
beliefs about the user&apos;s goals. and measures of plausibility for any given
action by the user. See (71 for more discussion of this broader view of
graceful interaction in man-machine communication. Suffice it to say that
we assume a flexible parser is just one component of a larger system, and
that ally incomprehensions or ambiguities that it finds are passed on to
another component of the system with access to higher-level information,
putting it in a better position to decide what to do next.
Finally, we assume that, as usual for such systems, input is typed,
rather than spoken as is normal in human conversations. This simplifies
low-level processing tremendously because key-strokes unlike speech
wave-forms are unambiguous. On the other hand, problems like
misspelling arise, and a flexible parser cannot assume that segmentation
into words by spaces and carriage returns will always be correct.
However, such input is still one side of a conversation, rather than a
polished text in the manner of most written material. As such, it is likely to
contain many of the same type of errors normally found in spoken
conversations.
</bodyText>
<subsectionHeader confidence="0.966026">
2.2. Misspelling
</subsectionHeader>
<bodyText confidence="0.973077">
Misspelling is perhaps the most common form of grammatical deviation
in written language. Accordingly, it is the form of ungrammaticality that
has been dealt with the most by language processing systems. PARRY
1111, Lu-EnI81. ;Ilk I numerous other systems have tried to correct misspelt
input from their users.
letwnucll was by 11■0 A. Unice Office id Scientific Ileseaten under
l:nfIliaitt I 49620 /SC 011a
</bodyText>
<page confidence="0.999066">
97
</page>
<bodyText confidence="0.9999518">
An ability to correct spelling implies the existence of a dictionary of
correctly spelled words An input word not found in the dictionary is
assumed to be misspelt and is compared against each of the dictionary
words. If a dictionary word comes close enough to the input word
according to some criteria of lexical matching, it is used in place of the
input word.
Spelling correction may be attempted in or out of context. For instance.
there is only one reasonable correction for &amp;quot;relavent&amp;quot; or or &amp;quot;seperate&amp;quot;,
but for an meta like &amp;quot;tin&amp;quot; some kind of context is typically necessary as in
&amp;quot;I&apos;ll see you tin April&amp;quot; or &amp;quot;he was shot with the stolen un.&amp;quot; In ellect.
context cart be used to reduce the size of the dictionary to be searched for
correct words. This holli makes the seam cl more efficient and reduces the
possibility ol multiple matches of the input against the dictionary. The
LIFER WI system uses the strong Constraints typically provided by its
semantic el :amnia in this way to reduce the range of possibilities for
spelling correction.
A particularly troublesome kind of spelling error results in a valid word
different from the one intended, as in &amp;quot;show me on of the messages&amp;quot;.
Cloarly. such an error can only he corrected through climparison against
a contextually determined vocabulary.
</bodyText>
<subsectionHeader confidence="0.899414">
2.3. Novel Words
</subsectionHeader>
<bodyText confidence="0.999866583333333">
Even accomplished users of a language will sometimes encounter
words they do not know. Such situations are a test of their language
learning skills. If one didn&apos;t know the word &amp;quot;fawn&amp;quot;, one could at least
decide it was a colour from &amp;quot;a fawn coloured sweater&amp;quot;. If one just knew
the word aS wlef my to a young deer, one ritiulit cunclude that ml was Pesny
used to mean the colour of a young deer. In general. beyond making
direct inferences about the role of unknown words from their immediate
context, vocabulary learning can require arbitrary amounts of real-world
knowledge and inference. and this is certainly beyond the capabilities of
Present day artificial intelligence techniques (though see Carbonell Pit for
work in this direction).
There is. however, a very common special subclass of novel words that
is well within the capabilities of present day systems: unknown proper
names. Given an appropriate context, either sentential or discourse, it is
relatively straightforward to parse unknown words into the names of
People, places. etc. Thus in &amp;quot;send copies to Moledeski Chiselov&amp;quot; it is
reasonable to conclude from the local context that &amp;quot;Molecleski&amp;quot; is a first
name, &amp;quot;Chrselov&amp;quot; is a surname, and together they identify a person (the
intended recipient of the copies). Strategies like this were used in the
POLITICS 1.51. FRUMP 14 and PARRY 11 11 systems.
Since novel words are by definition not in the known vocabulary, how
can a parsing system distinguish them from misspellings? hi most cases,
the novel words will not be close enough to known words to allow
successful correction, as in the above example, but this is not always true:
an unknown first name of &amp;quot;Al&amp;quot; could easily be corrected to &amp;quot;all&amp;quot;.
Conversely, it is not safe to assume that unknown words in contexts which
allow proper names are really proper names as in: &amp;quot;send copies to al
managers&amp;quot;. In this example. &amp;quot;al&amp;quot; probably should be corrected to &amp;quot;all&amp;quot;.
In order to resolve such cases it may be necessary to check against a list
of referents for proper names. if this is known, or otherwise to consider
such factors as whether the initial letters of the words are capitalized.
As far as we know, no systems yet constructed have integrated their
handling of misspelt words and unknown. proper names to the degree
outlined ;Move. I lowever, the COOP 191 system allows systematic access
to a data base t:oritairting proper names without the 111111( I kV Inclusion of
nue words in the system&apos;s parsing vocabulary.
</bodyText>
<subsectionHeader confidence="0.690364">
2.4. Erroneous segmenting markers
</subsectionHeader>
<bodyText confidence="0.999673615384615">
Written text is segmented into words by spaces and new lines, and into
higher level units by commas, periods and other punctuation marks. Both
classes, especially the second, may be omitted or inserted speciously.
Spoken language is also segmented. but by the quite different markers of
stress, interaction and noise words and phrases; we will not consider
those further here.
Incorrect segmentation at the lexical level results in two or more words
being run together, as in &amp;quot;runtogether&amp;quot;. or a single word being split up
into two or more segments. as in &amp;quot;tog ether&amp;quot; or (inconveniently) &amp;quot;to get
her&amp;quot;, or combinations of these effects as in &amp;quot;runt° geth er&amp;quot;. In all cases. it
seems natural to deal with such errors by extending the spelling
correction mechanism to be able to recognize target words as initial
segments 01 unknown words, and vice-versa. As far as we know, no
current systems deal with incorrect segmentation into words.
The other type of segmenting error, incorrect punctuation, has a much
broader impact on parsing methodology. Current parsers typically work
one sentence at a time, and assume that each sentence is terminated by
an explicit end of sentence marker. A flexible parser must be able to deal
with the potential absence of such a marker, and recognize the sentence
boundary regardless. It should also be able to make use of such
Punctuation if it is used correctly, and to ignore it if it is used incorrectly.
Instead of punctuation, many interactive systems use carriage-return to
indicate sentence termination. Missing sentence terminators in this case
correspond to two sentences on one line, or to the typing of a sentence
without the terminating return. while specious terminators correspond to
typing a sentence on more than one line.
</bodyText>
<subsectionHeader confidence="0.712197">
2.5. Lhoken-011 and Restarted Utterances
</subsectionHeader>
<bodyText confidence="0.964422555555556">
In spoken language, it is very common to break off and restart all or part
of an utterance:
I want to — Could you tell me the name?
Was the man --er-- the official here yesterday?
Usually. such restarts are signalled in some way. by &amp;quot;urn&amp;quot; or &amp;quot;er&amp;quot;, or more
explicitly by &amp;quot;let&apos;s back up&amp;quot; or some similar phrase.
In written language. such restarts do not normally occur because they
are erased by the writer before the reader sees them. Interactive
computer systems typically provide facilities for their users to delete the
last character. word, or current mile as though it had never been typed, for
the very purpose of allowing such restarts. Given these signals, the
lest:els are easy to deleCI and interpret. However. sometimes users fail to
make use of these signals. Sometimes. for instance, input not containing
a carriage-return can be spread over several lines by intermixing of input
and output. A flexible parser should be able to make sense out. of
&amp;quot;obvious&amp;quot; restarts that are not signalled, as in:
delete the show me all the messages from Smith
2.8. Fragmentary and Otherwise Elliptical Input
Naturally occuring language often involves utterances that are not
Complete sentences. Often the appropriateness of such fragmentary
utterances depends on conversational or physical context as in:
A: Do you mean Jim Smith or Fred Smith?
8: Jim
A: Send a message to Smith
B: OK
A: with copies to Jones
A flexible parser must be able to parse such fragments given the
appropriate context.
There is a question here of what such fragments should be parsed into.
Parsing systems which have dealt with the problem have typically
assumed II it such inputs are ellipses of complete sentences, and that
their parsing involves finding that complete sentence, and parsing it. Thus
the sentence corresponding to &amp;quot;Jim&amp;quot; in the example above would be &amp;quot;I
mean Jim&amp;quot;. Essentially this view has been taken by the LIFER [81 and
GUS 121 systems. An alternative view is that such fragments are not
ellipses of more complete sentences, but are themselves complete
</bodyText>
<page confidence="0.995024">
98
</page>
<bodyText confidence="0.999963">
utterances given the context in which they occur, and should be parsed as
such. We have taken this view in our approach to flexible parsing, as we
will explain more fully below. Carbonell (personal communication)
suggests a third view appropriate for seine fragments: that of an extended
case frame. In the second example above, for instance. A&apos;s &apos;with copies
to Jones&amp;quot; forms a natural pail ol the case frame established by &amp;quot;soul a
message to Smith&amp;quot; Yet another approach to fragment parsing is taken in
the PLANES system (12j which always parses in terms of major fragments
rather than complete utterances. This technique relies on there being
only one way to combine the fragments thus obtained, which may be a
reasonable assumption for &apos;fairy limited domain systems.
</bodyText>
<subsectionHeader confidence="0.737986">
Ellipses can :ilso occur without regard to context. A type that
</subsectionHeader>
<bodyText confidence="0.993567098360655">
interactive systems are particularly likely to lace is crypticness in which
articles and other non-essential words are 0111100(i as in &amp;quot;show messages
alter June 17&amp;quot; instead of the more complete &amp;quot;show rue all messages dated
after June 17&amp;quot;. Again, there is a question of whether to consider the
cryptic input taunplete, which would mean modifying the system&apos;s
grammar, or whether to consider it elliptical, and complete it by using
flexible techniques to parse it against the complete version as it exists in
Pie standard gr:unmar.
Other coinnton forms of ellipses are associated with conjunction as in:
John got up and [John] brushed his teeth.
Mary saw Bill and Bill [saw&apos; Mary.
Fred recognized [the building] and (Fred( walked towards the building.
Since conjunctions can support such a wide range of ellipsis, it is
generally impractical to recognize such utterances by appropriate
grammar extensions. Efforts to deal with conjunction have therefore
depended on general mechanisms which supplement the basic parsing
strategy, as in the LUNAR system [151, or which modify the grammar
temporarily, as in the work of Kwasny and Sondheimer 1101. We have not
attempted to deal with this type of ellipsis in our parsing system. and will
not discuss further the type of flexibility it requires.
2.7. Interjected Phrases, Omission, and Substitution
Sometimes people interject noise or other qualifying phrases into what
is otherwise a normal grammatical flow as in:
I want the message dated I think June 17
Such interjections can be inserted at almost any point in an utterance, and
so must be dealt with as they arise by flexible techniques.
It is relatively straightforward for a system of limited comprehension to
screen out and ignore standard noise phrases such as &amp;quot;I think&amp;quot; or &amp;quot;as far
as I can tell&amp;quot;. More troublesome are interjections that cannot be
recognized by the system, as might for instance be the case in
Display [just to refresh my memory( the message dated June 17.
I want to see the message [as I forgot what it saidl dated June 17.
where the unrecognized interjections are bracketed. A flexible parser
should be able to ignore such interjections. There is always the chance
that the unrecognized part was an important part of what the user was
trying to say. but clearly, the problem that arise from this cannot be
handled by a parser.
Omissions of words (or phrases) from the input are closely related to
cryptic input as discussed above. and one way of dealing with cryptic
input is to treat it as a set of omissions. However, in cryptic input only
inessential information is missed out. while it is conceivable that one could
also omit essential information as in:
Display the message June 17
Here it is unclear whether the speaker means a message dated on June IT
or before June 17 or after June 17 (we assume that the system addressed
can display things inimmliately. or not at all). If an omission can be
nairowed down ill this way, the parser should he able to geuerate all the
alternatives dor contextual resolution of the ambiguity or for the basis of a
question to the user). It the omission can be narrowed down to one
alternative then the input was merely cm yptic.
Besides omitting words and phrases, people sometimes substitute
incorrect or unintended ones. Often such substitutions are spelling errors
and should be caught by the spelling correction mechanism, but
sometimes they are inadvertent substitutions or uses of equivalent
vocabulary not known to the system. This type of substitution is just like
an omission except that there is an unrecognized word or phrase in the
place where the omitted input should have been. For instance, in &amp;quot;the
message over June 17&amp;quot;, &amp;quot;over&amp;quot; takes the place of &amp;quot;dated&amp;quot; or &amp;quot;sent after&amp;quot;
or whatever else is appropriate at that point. If the substitution is of
vocabulary which is appropriate but unknown to the system, parsing of
substituted words can provide the basis of vocabulary extension.
</bodyText>
<subsectionHeader confidence="0.986588">
2.8. Agreement Failure
</subsectionHeader>
<bodyText confidence="0.9533532">
It is not uncommon for people to fail to make the appropriate agreement
between the various parts of a noun or verb phrase as in:
1 wants to send a messages to Jim Smith.
The appropriate action is to ignore the lack of agreement. and Weischedel
and Black 1131 describe a method for relaxing the predicates in an ATN
which typically check for such agreements. However, it is generally not
possible to conclude locally which value of the marker (number or person)
for which the clash occurs is actually intended. We considered examples
in which the disagreement involves more than inflections (as in &amp;quot;the
message over June 17&amp;quot;) in the section on substitutions.
</bodyText>
<sectionHeader confidence="0.610318" genericHeader="method">
2.9. Idioms
</sectionHeader>
<bodyText confidence="0.961681894736842">
Idioms are phrases whose interpretation is not what would be obtained
by parsing and interpreting them constructively in the normal way. They
may also not adhere to the standard syntactic rules. Idioms must thus be
parsed as a whole in a pattern matching kind of mode. Parsers based
purely oil pattern matching, like that of PARRY I ItJ, thus are able to parse
idioms naturally. while others must either add a preprocessing phrase of
pattern matching as in the LUNAR system (IS), or mix specific patterns in
with more general rules, as in the work of Kwasny and Sondheimer [101.
Semantic grammars (3, 8) provide a relatively natural way of mixing
idiomatic and more general patterns.
2.10. User Supplied Changes
In normal human conversation, once something is said, it is said and
cannot be cliangixi. except indirectly by more words which refer back to
the original ones. In interactively typed input, there is always the
possibility that a user may notice an error lie has made mid go back and
correct it himself, without wailinu or the system to pursue its own,
possibly slow and ineffective. methods of correction. With appropriate
editing facilities. the user may do this without erasing intervening words,
and, if the system is processing his input on a word by word basis. may
</bodyText>
<sectionHeader confidence="0.73241" genericHeader="method">
3. An Approach to Flexible Parsing
</sectionHeader>
<bodyText confidence="0.9993754375">
Most current parsing systems are unable to cope with MOM of the kinds
of grzunrnatical deviation outlined above. This is because typical parsing
systems attempt to apply their grammar to their input in a rigid way, and
since deviant input, by definition. does riot conform to the grammar, they
are unable to produce any kind of parse for it at all. Attempts to parse
more flexibly have typically involved parsing strategies to be used after a
top-down parse using an ATN 114.1 or similar transition net has failed.
Such ef forts include the ellipsis and paraphrase mechanisms of LIFER [81,
the predicate relaxation techniques of Weischedel and Black (13), and
several of the devices for extending ATN&apos;s proposed by Kwasny arid
Sondheimer 1101.
thus alter a word that the system has already processed. A flexible parser
must be able to take advantage of such user provided corrections to
unknown words, and to prefer thein over its own corrections. It must also
be prepared to change its parse if the user changes a valid word to
another different but equally valid word.
</bodyText>
<page confidence="0.993917">
99
</page>
<bodyText confidence="0.999967076923077">
We have constructed a parser, FlexP, which can apply its grammar to
its input flexibly, and thus deal with the grammatical deviations discussed
in the previous section. We should emphasize, however. that FlexP is
designed to be used in the interlace to a restricted-domain system. As
such, it is intended to work Poen a domain-specific semantic grammar,
rather than one suitable for broader classes of input. FlexP thus does not
embody a solution for flexible parsing of natural language in general. In
describing FlexP. we will note those of its techniques that seem unlikely to
scale up to use with more complex grammars with wider coverage.
We have adopted in FlexP an approach to flexible parsing based not on
ATN&apos;s. but closer to the pattern-matching parser of the PARRY system
1111. possibly the most robust parser yet constructed. Our approach is
based on several design decisions:
</bodyText>
<listItem confidence="0.926901777777778">
• bottom up rather than top-down parsing: This aids in the
parsing of fragmentary utterances, and in the rerogiation of
interjections and restarts.
• pattern matching: 1 his is essential for idioms, and also aids
in the iletection of omissions and substitutions in
non-idioinatic phrases.
• parse suspension and continuation: The ability to
suspend a parse and later resume its processing is important
for interjections. restarts, and non-explicit terminations.
</listItem>
<bodyText confidence="0.996043">
In the remainder of this section we examine and justify these design
decisions in more detail.
</bodyText>
<subsectionHeader confidence="0.914217">
3.1. Bottom-Up Parsing
</subsectionHeader>
<bodyText confidence="0.999968387096774">
Our choice of a bottom-up strategy is based on our need to recognize
isolated sentence fragments. If an utterance which would normally be
considered only a fragment of a complete sentence is to be recognized
top-down, there are two approaches to take. First, the grammar can be
altered so that the fragment is recognized as a complete utterance in its
own right. This is undesirable because it can cause enormous expansion
Of the grammar, and because it becomes difficult to decide whether a
fragment appears in isolation or as part of a larger utterance. especially if
the possibility of missing end of sentence markers also exists. The second
option is for the parser to infer from the conversational context what
grammatical sub-category (or sequence of sub-categories) the fragment
might fit into, and then to do a top-down parse from that sub-category.
This essentially is the tactic used in the GUS 121 and LIFER 1171) systems.
This strategy is clearly better than the first one, but has two problems; first
of predicting all possible sub-categories which might come next, and
secondly, of inefficiency if a large number are predicted. Kwashy and
Sondheimer 1101 use a combination of the two strategies by temporarily
modifying an ATN grammar to accept fragment categories as complete
utterances at the times they are contextually predicted.
Gottoin-up parsing avoids the problem of predicting what
sub-categories may occur. If a fragment fitting a given sub-category does
occur, it is parsed as such whatever the context. However, if a given input
Can be parsed as more than one sub-category, the bottom-up approach
would have to produce them all, even if only one would be predicted
top-down. In a system of limited comprehension, fragmentary recognition
is sometimes necessary because not all of an input can be recognized,
rather than because of intentional ellipsis. Here, ills probably impossible
to make predictions and bottom-up parsing is the only method that is likely
to work. As described below, bottom-up strategies, coupled with
suspended parses, are also helpful in recognizing interjections and
restarts.
</bodyText>
<subsectionHeader confidence="0.85203">
3.2. Pattern Matching
</subsectionHeader>
<bodyText confidence="0.999962282051282">
We have chosen to use a grammar of linear patterns rather than a
If:amnion network because palteni-matching meshes well with bottom-up
parsing. because it facilitates recognition (if utielances with omissions
and substitutions, and because itis necessary anyway [Ur the fecoynition
of idiomatic phrases.
The grammar ol the parser is a set of rewrite or production rules whose
telt hand ax le is a lineal pattern of cow:animas (lexical ni Mello level) and
whose right hand side defines a rfnult constituent. Elements of the
pattern may be labelled optional or allow for repeated matches. We make
the assumption, certainly true for the grammar we are presently working
with, that the grammar will be semantic rather than syntactic, with patterns
corresponding to idiomatic phrases or to oblect and event descriptions
meaningful in some limited domain, rather than to general syntactic
structures.
Linear patterns fit well with bottom-up parsing because they can be
indexed by any of their components, and becauSe, once indexed, it is
straightforward to confirm whether a pattern matches input already
processed in a way consistent with the way the pattern was indexed.
Patterns help with the detection of omissions and substitutions because
in either case the relevant pattern can still be indexed by the remaining
elements that appear correctly in the input, and thus the pattern as a
whole can be recognized even it some of its elements are missing or
incorrect. In the case of substitutions. such a technique can actually help
locus the spelling correction, proper name recognition. or vocabulary
learning techniques, whichever is appropriate, by isolating the substituted
input and the pattern constituent which it should have matched. In effect.
this allows the normally bottom-up parsing strategy to go top-down to
resolve such substitutions.
In normal left to right processing, it is not necessary to activate all the
Patterns indexed by every new word as it is considered. If a new word is
accounted or by a Pattern that has already been partially matched by
previous input, it is likely that no other patterns need to be indexed and
matched for that input. This heuristic alows FlexP&apos;s parsing algorithm to
limit the number of patterns it Ines to match. We should emphasize,
however, that it is a heuristic, and while it has caused us no trouble with
the limited-domain grammar we have been using, it is unclear how well it
would transfer to a more complex grammar. FlexP&apos;s algorithm does,
however. carry along multiple partial parses in other ambiguous cases.
removing the need for any backtracking.
</bodyText>
<subsectionHeader confidence="0.969629">
3.3. Parse Suspension and Continuation
</subsectionHeader>
<bodyText confidence="0.999864090909091">
FlexP employs the technique of suspending a parse with the possibility
of later continuation to help with the recognition of interjections. restarts.
and implicit terininations. The parsing algorithm works left to right in a
breadth-first manner. It maintains a set of partial parses, each at which
accounts for the input already processed but riot yet accounted for by a
completed parse. The parser attempts to incorporate each new input into
each of the partial parses. If this is successful, the partial parses are
extended and may increase Or decrease in number. If no partial parse can
be extended, the entire set is saved as a suspended parse.
There are several possible explanations for input mismatch, i.e. the
failure of Me next input to extend sparse.
</bodyText>
<listItem confidence="0.980344333333333">
• The input could be an implicit termination. i.e. the start of a
new top-level utterance, and the previous utterance should be
assumed complete.
• t he input could be a restart, in which case ti.e active parse
should be abandoned and a new parse started from that point.
• The input could be the start of an interjection, in which case
</listItem>
<bodyText confidence="0.8640244">
the active parse should be temporarily suspended, and a new
Parse started for the intenection.
It is not possible, in general, to distinguish between these cases at the
time the mismatch occurs. It the active parse is not at a possible
terniination point, then input mismatch cannot indicate implicit
</bodyText>
<page confidence="0.982107">
100
</page>
<bodyText confidence="0.999945454545454">
termination, but may indicate either restart or interjection. It is necessary
to suspend the active parse and wait to see if it is continued at the next
input mismatch. On the other hand, if the active parse is at a possible
termination point, input mismatch does not rule out interjection or even
restart. In this situation, our algorithm tentatively assumes that there has
been an implicit termination, but suspends the active parse anyway for
subsequent potential continuation.
Note also that the possibility of implicit termination provides justification
for the strategy of interpreting each input immediately it is received. lithe
input signals an implicit termination, then the user may well expect the
system to respond immediately to the input thus terminated.
</bodyText>
<sectionHeader confidence="0.677189" genericHeader="method">
4. Details of FlexP
</sectionHeader>
<bodyText confidence="0.96642785">
This section describes how FlexP achieves the flexibilities discussed
earlier. The implementation described is being used as the parser for an
intelligent interface lo a multi-media message system II]. The intelligence
in this interface is concentrated in a llser AUVIll which inediates between
the user and the underlying tool system. The Agent ensures that the
interaction goes smoothly by, among other things, checking that the user
specifies the operations he wants performed and their parameters
correctly and unambiguously. conducting a dialogue with the user if
problems arise. The role of FlexP. as the Agent&apos;s parser is to transform the
user&apos;s input into the internal representations employed by the Agent.
Usually this input is a request for action by the tool or a description of
objects known to the tool. Our examples are drawn from that context.
4.1. Preliminary Example
Suppose the user types
display new messages
Interpretation begins as soon as any input is available. The first word is
used as an index into the store of rewrite rules. Each rule gives a pattern
and a structure to be past mod .when ilie pattern is matched. The
components of the structure are built from the structures or words which
match the elements of the pattern. The word &amp;quot;display&amp;quot; indexes the rule:
</bodyText>
<table confidence="0.840858428571429">
(pattern: (Display Message Description)
result: [Structurelype: Operationdeguest
Operation: Display
Message: (Filler MessageOescription)]
Using this rule time parser constructs the partial parse tree
(Display MessageOescription)
display
</table>
<bodyText confidence="0.942511">
We call the partially-instantiated pattern which labels the upper node a
hypothesis. It represents a possible interpretation for a segment of input.
The next word &amp;quot;new&amp;quot; does riot directly match the hypothesis, but since
&amp;quot;new&amp;quot; is a MsgAdj (an adjective which can modify a description of a
message), it indexes the rule:
Here. &amp;quot;?&amp;quot; means optional, and &amp;quot;&amp;quot; means repeatable. For the sake of
clarity, we have omitted other prefixes which distinguish between terminal
and non-terminal pattern elements. The result of this rule fits the current
hypothesis. so extends the parse as follows:
(Display MessageDescriplion)
</bodyText>
<page confidence="0.640233">
1
</page>
<bodyText confidence="0.9646201">
(Met •MsgAdj Msgliead •MsgCase)
display new
lhe hypothesis is not yet fully confirmed even though all the elements are
&apos;notched. Its second i t, silent malches amities. lower level hypothesis
which is only iecompletely matched. This lower pattern becomes the
cirrwrif frYvothetas because it pm edicts what should conic next in the input
stream.
The third input matches the category Msollead (head noun of a
message description) and so fits the current hypothesis. This match fills
the last non-oplional slot in that pattern. By doing so it makes the current
hypothesis and its parent pattern potentially complete. When the parser
finds a potentially complete phrase whose result is of interest to the Agent
(and the parent phrase in this example is in that category), the result is
constructed and sent. However, since the parser has not seen a
termination signal, this parse is kept tic.live. I lie iiiput see,&apos; SO far inay be
only a prefix for some longer utterance such as &amp;quot;display new messages
about ADA&amp;quot;. In this case &amp;quot;about ADA&amp;quot; would be recognized as a match
for MsgCase (a prepositional phrase that can be part of a message
description), the parse would be extended, and a revision of the previous
structure sent to the Agent.
</bodyText>
<subsectionHeader confidence="0.873918">
4.2. Unrecognized Words
</subsectionHeader>
<bodyText confidence="0.995841466666667">
When an input word cannot be found in the dictionary, spelling
correction is attempted in a background process which runs at lower
priority than the parser. The input word and a list of possibilities derived
from the current hypothesis are passed as arguments. For example:
display the new messaegs
produces the partial parse
(Display MessageDescription)
(Met •MsgAdj MsgHead •MsgCase)
display the new
The lower pattern is the current hypothesis and has two elements eligible
to match the next input. Another MsgAdj could be matched. A match for
MsgHead would also fit. Both elements have associated lists of keywords
known to occur in phrases which match them. The one for MsgHead
includes the word &amp;quot;messages&amp;quot;. and the spelling corrector passes this
back to the parser as the most likely interpretation.
In some cases the spelling corrector produces several likely
alternatives. The parser handles such ambiguous words using the same
mechanisms which accommodate phrases with ambiguous interpretations
That is, alternative interpretations are carried along until there is enough
input to discriminate those which are plausible from those which are not.
I he details are given in the next section.
The user inay also correct the input text himself. These changes are
handled in much the same way as those proposed by the spelling
corrector. Ot course, these user-supplied changes are given priority, and
11:1130S built using the forme, version must he nnxlilietl or discarded.
Spelling correction is nal as a separate, lower priority process because
a reasonable parse may be produced even without a proper interpretation
for the unknown word. Since spelling correction can involve rather
time-consuming searches, this work is best done when the parser has.no
better alternatives to explore.
</bodyText>
<subsectionHeader confidence="0.955688">
4.3. Ambiguous Input
</subsectionHeader>
<bodyText confidence="0.9999065">
In the first example there was only one hypothesis about the structure
of the input. More generally, there may be several hypotheses which
provide competing interpretations about what has already been seen and
what will appear next. Until these partial parses are found to be
inconsistent with the actual input, they are carried along as part of the
active parse. Therefore the active parse is a set of partial parse trees each
</bodyText>
<figure confidence="0.966418833333333">
(pattern:
result:
(Met •MsgAdj Msgllead •MsgCase)
IStruclurelype: MessageDescription
Components:
1)
</figure>
<page confidence="0.99244">
101
</page>
<bodyText confidence="0.9975126">
efficiency required for real-time response. but could conceivably fail to
find appropriate parses. We have not encountered such circumstances
with the small domain-specific semantic grammar we have been using.
other hand. once Msgl lead has been matched only the last element is
eligible under the strict interpretation of the pattern.
</bodyText>
<subsectionHeader confidence="0.907958">
4.4. Flexible Matching
</subsectionHeader>
<bodyText confidence="0.944507555555556">
rhe only flexibility described so far is that allowed by the optional
elements of patterns. It omissions can he anticipated, allowances may be
built isile the grammar. In this section we show how other omissions may
he handled and othei flexibilities achieved by allownin additional freedom
in the way an item is allowed to match a pattern. I-here are two ways in
with a top-level hypothesis about the overall structure of the input so far
and a current hypothesis concerning the next iflout. The actual
implementation allows sharing of common structure among competing
hypotheses and so is more efficient than this description suggests.
The input
were there any messages on
could be completed by giving a date (&amp;quot;...on Tuesday&amp;quot;) or a topic (&amp;quot;...on
ADA&amp;quot;). Consequently, the sub-phrase &amp;quot;any messages on&amp;quot; results in two
partial parses:
Consider the input
display new alinia ADA
The hist two words parse normally to produce
(Display MessageDescription)
</bodyText>
<subsectionHeader confidence="0.183266">
(Wet •MsgAdj Msgliead •MsgCase)
</subsectionHeader>
<bodyText confidence="0.951433769230769">
display new
The next word does not fit that hypothesis. The two eligible elements
predict either another message adjective or a MsgHead. The word
&amp;quot;about&amp;quot; does not match either of these, nor can the parser construct any
path to them using intermediate hypotheses. Since there are no other
partial parses available to account for this input, and since normal
matching fails, flexible matching is tried.
and (Wel •Msgfldj Msgllead •MsgCase) First. previously skipped elements are compared to the input. In this
any messages (On Dale) example, the element ?Det is considered but does not match. Next,
on elements to the right of the eligible elements are considered. Thus
MsgCase is considered even though the non-optional element MsgHead
has not been matched. This succeeds and allows the partial parse to be
extended to
</bodyText>
<figure confidence="0.894895">
(Display MessageDescription)
(net &apos;MsgAdj Msgllead •MsgCase)
new (About Lop ic
about
display
on
</figure>
<bodyText confidence="0.9966466">
It the next input were &amp;quot;Tuesday&amp;quot; it would be consistent with the first parse,
tail not the rA1C011(i. Since one of the alternatives does account for the
input. those that do not may be discarded. On the other hand, if all the
partial muses fail to matcli the input, other action Is glkell. We consider
III the SOCII011 un suspended parses.
As a general strategy, we carry sevei al possible interpretations only as
long as It is no clear best alternative. In particular no flexible parsing
techniques are used to support parses lor which there are plausible
alternatives under normal parsing. This heuristic helps achieve the
which the matching criteria inay be relaxed. namely
</bodyText>
<listItem confidence="0.9968155">
• relax consistency constraints, e.g. number agreement
• allow out of order matches
</listItem>
<bodyText confidence="0.984480166666667">
Consistency constraints are predicates which are attached to rules.
They assert relationships which must hold among the items which fill the
pattern. Mese constraints allow context-sensitive constructions in the
grammar. Such predicates are commonly used for similar purposes by
ATN parsers 1141 and the flexibility achieved by relaxing these constraints
has been explored before )t31. The technique fits smoothly into FlexP but
has not actually been needed or used in our current application.
On the other hand. out of order matching is essential for the parser&apos;s
approach to errors of omission, transposition, and substitution. Even
WI en strictly &apos;mei ineled. several elements of a pattern may he eligible to
match the next input item. For example. in the pattern for a
MessageDescription
( ?Del. •MsgAdj Msollead •MsgCase)
each of the lirst three elements is initially eligible but the last is not. On the
which correctly predicts the final input item.
Unrecognizable substitutions are also handled by this mechanism. In
the phrase
display the new stuff about ADA
the word &amp;quot;Stuff&amp;quot; is not found in the dictionary so spelling correction is
tried but does not produce any plausible alternatives. While spelling
correction is underway, the remaining inputs can be parsed by senelY
omitting &amp;quot;stuff&amp;quot; and using the flexible matching procedure.
Transpositions are handled through one application of Ilexible matching if
the element of the transposed pair is optional, two applications if not.
</bodyText>
<subsectionHeader confidence="0.775267">
4.5. Suspended Parses
</subsectionHeader>
<bodyText confidence="0.999508230769231">
Interjections are Imre comMon in spoken than in wi :en language but
do occur in typed input sometimes. To deal with such input. Ou«lesign
allows for blocked parses to be suspended rather than merely discarded.
Users, especially novices, may embellish their input with words and
phrases that do rnt provide essential information and cannot be
specifically anticipalet. Consider t examples:
display please messages dated June 17
display for me messages dated June 17
In the first case, the interjected word &amp;quot;please&amp;quot; could be recognized as a
cnnunnn noise phrase which means nothing to the Agent except possibly
to suggest that the user is a novice. The second example is more difficult.
Both words of the interjected phrase can appear in a number of legitimate
mid meaningful constriliannis: they cannot be ignored so easily.
</bodyText>
<figure confidence="0.9190565">
( Wet •MsgAdj Msollead •MsgCase)
any messages (On Topic)
</figure>
<page confidence="0.991145">
102
</page>
<bodyText confidence="0.9889039375">
For the latter example. parse suspension works as follows. After the
first word, the active parse contains a single partial parse:
(Display MessageDescription)
display
The next word does not fit this hypothesis, so it is suspended. In its place,
a new active parse is constructed. It contains several partial parses
including
(for Person) and (for TimeInterval)
1
for for
The next word confirms the first of these, Ind the fourth word
&amp;quot;messages&amp;quot; does not. When the parser finds that it cannot extend the
active parse, it considers the suspended parse. Since &amp;quot;messages&amp;quot; fits,
the active and suspended parses are exchanged and the remainder of the
input processed normally, so that the parser recognizes &amp;quot;display
messages dated June 17&amp;quot; as if it had never contained &amp;quot;for me&amp;quot;.
</bodyText>
<sectionHeader confidence="0.999064" genericHeader="conclusions">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999821166666667">
When people use language naturally, they mike mistakes and employ
economies of expression that. often result in language which is
ungrammatical by strict standards. In particular, such grammatical
deviations will inevitably occur in the input of a computer system which
allows its user lo employ natural language. Such a computer system must.
therefore, be prepared to parse its inind flexibly, if il is avoid frustration for
its user.
In this paper, we have attempted to outline the main kinds of flexibility a
natural language parser intended for natural use should provide. We also
described a bottom-up pattern-matching parser. FlexP, which exhibits
these Ilexibilities, and which is suitable for restricted natural language
input to a limited-domain system.
</bodyText>
<sectionHeader confidence="0.999264" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99992930952381">
1. Ball, J. E. and Hayes, P. J. Representation of Task-Independent
Knowledge in a Gracefully Interacting User Interface. Tech. Rept,,
Carnegie-Mellon University Computer Science Department, 1980.
2. Bobrow, D. G., Kaplan, R. M., Kay, M., Norman D. A., Thompson, H.,
and Winograd. T. &amp;quot;GUS: a Frame-Driven Dialogue System.&amp;quot; Artificial
Intelligence 8(1977), 155-173.
3. Burton, R. R. Semantic Grammar: An Engineering Technique for
Constructing Natural Language Understanding Systems. BBN Report
3453, Bolt, Beranek. and Newman, Inc., December, 1976.
4. Carbonell. J. G. Towards a Self-Extending Parser. Proc. of 17th
Annual Meeting of the Assoc. for Commit. Ling., La Jolla, Ca.,
August, 1979, pp. 3-7.
5, Carbonell, J. G. Subjective Understanding: Computer Models of
Belief Systems. Ph.D. Th., Yale University, 1979,
6. DeJong, G. Skimming Stories in Real-Time. Ph.D. Th., Computer
Science Dept., Yale University, 1979.
7. Hayes, P. J.. and Fleddy, R. Graceful Interaction in Man-Machine
Communication. Proc. Sixth Int. Jt. Conf. on Artificial Intelligence, Tokyo,
1979, pp. 372-374.
8. Hendrix, G. G. Human Engineering for Applied Natural Language
Processing. Proc. Filth Int. Jt. Cont. on Artificial Intelligence, MIT, 1977,
pp. 183-191.
9. Kaplan, S. J. Cooperative Responses from a Portable Natural
latiumitte Data Bata! Query System. Ph.D. Th.. Dept. of Computer and
Information Science. University of Pennsylvania. Philadelphia, 1979.
10, Kwasny. S. C. and Sondheimer, N. K. Ungrammaticality and
Extra-Grammaticality in Natural Language Understanding Systems. Proc.
of 17111 Annual Meeting of the Assoc. for Comput. Ling., La Jolla, Ca.,
August. 1979, pp. 19-23.
11. Parkison. R. C., Colby, K. M., and Faught. W. S. • &amp;quot;Conversational
Language Comprehension Using Integrated Pattern-Matching and
Parsing.&amp;quot; Attatcial Intelligeticy 9 (1977). 111-134.
12. Waltz. D. L. &amp;quot;An English Language Question Answering System for
a Large Relational Data Base.&amp;quot; Comm. ACM 2 1,7 (1978), 526-539.
3. Weischedel, R. M. and Black. J. Responding to Potentially
Unpzuseable Sentences. Tech. Rept. 79/3. Dept. of Computer and
Information Sciences, University of Delaware, 1979.
14. Woods, W. A. &amp;quot;Transition Network Grammars for Natural Language
Analysis.&amp;quot; Comm. ACM 13, 10 (October 1970), 591-606.
15. Woods, W. A.. Kaplan, R. M., and Nash-Webber, B. The Lunar
Science!: t Final Report. Tech. Rept. 2378, Bolt,
Beranek, and Newman, Inc., 1972.
</reference>
<page confidence="0.999298">
103
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002779">
<title confidence="0.999921">Flexible Parsing</title>
<author confidence="0.999885">Phil Hayes</author>
<author confidence="0.999885">George Mouradian</author>
<affiliation confidence="0.999987">Computer Science Department, Carnegie-Mellon University</affiliation>
<address confidence="0.998444">Pittsburgh. PA 15213, USA</address>
<abstract confidence="0.98447076170213">communicating via a keyboard and display screen. We then present a taxonomy of grammatical deviations common in this context, and by implication a set of parsing flexibilities needed to deal.with them. I. Communication Limited-Domain System In the remainder of this paper, we will focus on a restricted type of communication situation, that between a limited-domain system and its user, and on the parsing flexibilities needed by such a system to cope with the user&apos;s inevitable grammatical deviations. Examples of the type of we have mind are retrieval systems. electronic mail systems. medical diagnosis systems. or any systems operating in a domain so restricted that they can completely understand any relevant input a user might provide. In short, exactly the kind Of system that is normally used for work in applied natural language processing. There are several points to be made. Abstract&apos; When people use natural language in natural settings, they often use it ungrammatically, missing out or repeating words. breaking-off and restarting, speaking in fragments, etc.. Their human listeners are usually able to cope with these deviations with little difficulty. If a computer system wishes tc accept natural language input from its users on a routine basis, it must display a similar indifference. In this paper, we outline a set of parsing flexibilities that such a system should provide. We go on to describe FlexP. a bottom-up pattern-matching parser that we have designed and implemented to provide these flexibilities for restricted natural language input to a limited-domain computer system. 1. The Importance of Flexible Parsing When people use natural language in natural conversation, they often do not respect grammatical niceties. Instead of speaking sequences of grammatically well-formed and complete sentences, people often miss out or repeat words or phrases, break off what they are saying and rephrase or replace it, speak in fragments, or use otherwise incorrect grammar. The following example conversation involves a number of these grammatical deviations: A: I want ... can you send a memo a message to to Smith Is that John or John Smith or Jim A: Jim Instead of being unable or refusing to parse such ungrammaticality, human listeners are generally unperturbed by it. Neither participant in the above example, for instance, would have any difficulty in following the conversation. If computers are ever to converse naturally with humans, they must be to their input as flexibly as humans While considerable advances have been made in recent years in applied natural language processing, few of the systems that have been constructed have sufficient attention to of deviation that will their imput if used in a natural environment. In many cases, if the user&apos;s input does not conform to the system&apos;s grammar, an indication by a request to rephrase may be the best he We believe that such in parsing severely limits the practicality of natural language computer interlaces, and is a major reason why natural language has yet to find wide acceptance in such applications as database retrieval or interactive command languages. In this paper, we report on a flexible parser, called FlexP, suitable for use with a restricted natural language interface to a limited-domain computer system. We describe first the kinds of grammatical deviations we are trying to deal with, then the basic design decisions for FlexP with justification for them based on the kinds of problem to be solved, and finally more details of our parsing system with worked examples of its operation. These examples,and most of the others in the paper, represent natural language input to an electronic mail system that we and others [11 are constructing as part of our research on user interfaces. This system employs FlexP to parse its input. 2. Types of Grammatical Deviation There are a number of distinct types of grammatical deviation and not types found in types of communication situation. In section. first define restricted type ol communication situation that we will be concerned with, that of a limited-domain computer system and its user First. although .7.uch systems can be expected to parse and understand anything relevant to their domain, their users cannot be expected to confine themselves to relevant input. As Bobrow et. at. 121 note, users their umferlying motivations otherwise justify their terms quite ii relevant to MO domain of the system. The result such cannot expect to parse all tti ii input even with the use of flexible parsing techniques. Secondly. a flexible parser is just part of the conversational component of such a system. .and cannot solve all parsing problems by itself. For example. if a parser can extract two coherent fragments from an otherwise incomprehensible input, the decisions about what the system should next must be made by another component of the system. A decision on whether to jump to a conclusion about what the user intended, to present him with a set of alternative interpretations, or to profess total confusion, can only be made with information about the history of the conversation, beliefs about the user&apos;s goals. and measures of plausibility for any given action by the user. See (71 for more discussion of this broader view of graceful interaction in man-machine communication. Suffice it to say that we assume a flexible parser is just one component of a larger system, and ally incomprehensions or ambiguities that it finds are passed component of the system access to higher-level information, putting it in a better position to decide what to do next. Finally, we assume that, as usual for such systems, input is typed, rather than spoken as is normal in human conversations. This simplifies low-level processing tremendously because key-strokes unlike speech wave-forms are unambiguous. On the other hand, problems like arise, and parser cannot assume that segmentation into words by spaces and carriage returns will always be correct. However, such input is still one side of a conversation, rather than a polished text in the manner of most written material. As such, it is likely to contain many of the same type of errors normally found in spoken conversations. 2.2. Misspelling Misspelling is perhaps the most common form of grammatical deviation in written language. Accordingly, it is the form of ungrammaticality that has been dealt with the most by language processing systems. PARRY ;Ilk numerous other systems have tried to correct misspelt input from their users. letwnucll was by 11■0 A. Unice Office id Scientific Ileseaten under l:nfIliaitt I 49620 /SC 011a 97 An ability to correct spelling implies the existence of a dictionary of correctly spelled words An input word not found in the dictionary is assumed to be misspelt and is compared against each of the dictionary words. If a dictionary word comes close enough to the input word according to some criteria of lexical matching, it is used in place of the input word. Spelling correction may be attempted in or out of context. For instance. there is only one reasonable correction for &amp;quot;relavent&amp;quot; or or &amp;quot;seperate&amp;quot;, but for an meta like &amp;quot;tin&amp;quot; some kind of context is typically necessary as in &amp;quot;I&apos;ll see you tin April&amp;quot; or &amp;quot;he was shot with the stolen un.&amp;quot; In ellect. context cart be used to reduce the size of the dictionary to be searched for correct words. This holli makes the seam cl more efficient and reduces the possibility ol multiple matches of the input against the dictionary. The LIFER WI system uses the strong Constraints typically provided by its semantic el :amnia in this way to reduce the range of possibilities for spelling correction. troublesome kind of spelling error results in a valid word different from the one intended, as in &amp;quot;show me on of the messages&amp;quot;. an error can only through against a contextually determined vocabulary. 2.3. Novel Words Even accomplished users of a language will sometimes encounter they do not know. Such situations are test of skills. If know &amp;quot;fawn&amp;quot;, one could at least it was a colour from &amp;quot;a fawn coloured sweater&amp;quot;. If one just word my to a young deer, one ritiulit cunclude that ml was Pesny to mean the colour of a young deer. general. beyond making direct inferences about the role of unknown words from their immediate context, vocabulary learning can require arbitrary amounts of real-world and this is certainly beyond the capabilities of Present day artificial intelligence techniques (though see Carbonell Pit for work in this direction). is. however, a very common special subclass of words that well within capabilities of present day systems: proper Given an appropriate context, either sentential discourse, it is straightforward parse unknown words into the names of People, places. etc. Thus in &amp;quot;send copies to Moledeski Chiselov&amp;quot; it is reasonable to conclude from the local context that &amp;quot;Molecleski&amp;quot; is a first name, &amp;quot;Chrselov&amp;quot; is a surname, and together they identify a person (the intended recipient of the copies). Strategies like this were used in the and PARRY 11 11 systems. novel words are by definition not in the known how a parsing system distinguish from misspellings? hi most the novel words will not be close enough to known words to allow successful correction, as in the above example, but this is not always true: an unknown first name of &amp;quot;Al&amp;quot; could easily be corrected to &amp;quot;all&amp;quot;. Conversely, it is not safe to assume that unknown words in contexts which allow proper names are really proper names as in: &amp;quot;send copies to al In this example. &amp;quot;al&amp;quot; probably should corrected to &amp;quot;all&amp;quot;. In order to resolve such cases it may be necessary to check against a list of referents for proper names. if this is known, or otherwise to consider such factors as whether the initial letters of the words are capitalized. As far as we know, no systems yet constructed have integrated their handling of misspelt words and unknown. proper names to the degree outlined ;Move. I lowever, the COOP 191 system allows systematic access a data base t:oritairting proper names without the I kV Inclusion nue words in the system&apos;s parsing vocabulary. 2.4. Erroneous segmenting markers Written text is segmented into words by spaces and new lines, and into higher level units by commas, periods and other punctuation marks. Both classes, especially the second, may be omitted or inserted speciously. Spoken language is also segmented. but by the quite different markers of stress, interaction and noise words and phrases; we will not consider those further here. at the lexical level results in two or more words being run together, as in &amp;quot;runtogether&amp;quot;. or a single word being split up into two or more segments. as in &amp;quot;tog ether&amp;quot; or (inconveniently) &amp;quot;to get her&amp;quot;, or combinations of these effects as in &amp;quot;runt° geth er&amp;quot;. In all cases. it seems natural to deal with such errors by extending the spelling correction mechanism to be able to recognize target words as initial segments 01 unknown words, and vice-versa. As far as we know, no current systems deal with incorrect segmentation into words. The other type of segmenting error, incorrect punctuation, has a much broader impact on parsing methodology. Current parsers typically work one sentence at a time, and assume that each sentence is terminated by explicit end sentence A flexible parser must be able to deal with the potential absence of such a marker, and recognize the sentence boundary regardless. It should also be able to make use of such if it is used correctly, and to ignore it if it is incorrectly. of many interactive systems use carriage-return to sentence termination. Missing sentence terminators in this to sentences on one line, or to the typing of a sentence without the terminating return. while specious terminators correspond to a sentence on more than Lhoken-011 and Restarted spoken language, it is very to break off and restart all or part of an utterance: want to — Could you tell me name? man --er-the official here yesterday? Usually. such restarts are signalled in some way. by &amp;quot;urn&amp;quot; or &amp;quot;er&amp;quot;, or more explicitly by &amp;quot;let&apos;s back up&amp;quot; or some similar phrase. In written language. such restarts do not normally occur because they are erased by the writer before the reader sees them. Interactive systems typically provide for their to delete the character. or current mile as though it never been typed, for very purpose such restarts. Given these signals, the lest:els are easy to deleCI and interpret. However. sometimes users fail to make use of these signals. Sometimes. for instance, input not containing carriage-return can be spread over lines by intermixing input output. A flexible should be able to make sense out. of &amp;quot;obvious&amp;quot; restarts that are not signalled, as in: delete the show me all the messages from Smith and Otherwise Elliptical Input language often involves utterances that are not Often the appropriateness of such fragmentary depends on conversational or physical context as Do you mean Jim Smith or Smith? A: Send a message to Smith B: OK A: with copies to Jones A flexible parser must be able to parse such fragments given the appropriate context. There is a question here of what such fragments should be parsed into. Parsing systems which have dealt with the problem have typically assumed II it such inputs are ellipses of complete sentences, and that their parsing involves finding that complete sentence, and parsing it. Thus the sentence corresponding to &amp;quot;Jim&amp;quot; in the example above would be &amp;quot;I Jim&amp;quot;. Essentially this view has been taken by the LIFER and 121 systems. An view is that such fragments are not ellipses of more complete sentences, but are themselves complete 98 utterances given the context in which they occur, and should be parsed as such. We have taken this view in our approach to flexible parsing, as we will explain more fully below. Carbonell (personal communication) suggests a third view appropriate for seine fragments: that of an extended case frame. In the second example above, for instance. A&apos;s &apos;with copies to Jones&amp;quot; forms a natural pail ol the case frame established by &amp;quot;soul a message to Smith&amp;quot; Yet another approach to fragment parsing is taken in the PLANES system (12j which always parses in terms of major fragments rather than complete utterances. This technique relies on there being only one way to combine the fragments thus obtained, which may be a reasonable assumption for &apos;fairy limited domain systems. Ellipses can :ilso occur without regard to context. A type that interactive systems are particularly likely to lace is crypticness in which and non-essential words 0111100(i in &amp;quot;show messages alter June 17&amp;quot; instead of the more complete &amp;quot;show rue all messages dated after June 17&amp;quot;. Again, there is a question of whether to consider the cryptic input taunplete, which would mean modifying the system&apos;s grammar, or whether to consider it elliptical, and complete it by using flexible techniques to parse it against the complete version as it exists in Pie standard gr:unmar. Other coinnton forms of ellipses are associated with conjunction as in: John got up and [John] brushed his teeth. Mary saw Bill and Bill [saw&apos; Mary. Fred recognized [the building] and (Fred( walked towards the building. Since conjunctions can support such a wide range of ellipsis, it is generally impractical to recognize such utterances by appropriate grammar extensions. Efforts to deal with conjunction have therefore depended on general mechanisms which supplement the basic parsing strategy, as in the LUNAR system [151, or which modify the grammar temporarily, as in the work of Kwasny and Sondheimer 1101. We have not attempted to deal with this type of ellipsis in our parsing system. and will not discuss further the type of flexibility it requires. 2.7. Interjected Phrases, Omission, and Substitution Sometimes people interject noise or other qualifying phrases into what is otherwise a normal grammatical flow as in: I want the message dated I think June 17 interjections can at almost any point in an utterance, and so must be dealt with as they arise by flexible techniques. It is relatively straightforward for a system of limited comprehension to screen out and ignore standard noise phrases such as &amp;quot;I think&amp;quot; or &amp;quot;as far as I can tell&amp;quot;. More troublesome are interjections that cannot be recognized by the system, as might for instance be the case in Display [just to refresh my memory( the message dated June 17. I want to see the message [as I forgot what it saidl dated June 17. where the unrecognized interjections are bracketed. A flexible parser should be able to ignore such interjections. There is always the chance that the unrecognized part was an important part of what the user was trying to say. but clearly, the problem that arise from this cannot be handled by a parser. Omissions of words (or phrases) from the input are closely related to cryptic input as discussed above. and one way of dealing with cryptic input is to treat it as a set of omissions. However, in cryptic input only inessential information is missed out. while it is conceivable that one could also omit essential information as in: Display the message June 17 it is unclear whether the speaker means a message dated on June or before June 17 or after June 17 (we assume that the system addressed can display things inimmliately. or not at all). If an omission can be nairowed down ill this way, the parser should he able to geuerate all the alternatives dor contextual resolution of the ambiguity or for the basis of a question to the user). It the omission can be narrowed down to one alternative then the input was merely cm yptic. Besides omitting words and phrases, people sometimes substitute incorrect or unintended ones. Often such substitutions are spelling errors and should be caught by the spelling correction mechanism, but sometimes they are inadvertent substitutions or uses of equivalent vocabulary not known to the system. This type of substitution is just like an omission except that there is an unrecognized word or phrase in the place where the omitted input should have been. For instance, in &amp;quot;the message over June 17&amp;quot;, &amp;quot;over&amp;quot; takes the place of &amp;quot;dated&amp;quot; or &amp;quot;sent after&amp;quot; or whatever else is appropriate at that point. If the substitution is of vocabulary which is appropriate but unknown to the system, parsing of substituted words can provide the basis of vocabulary extension. 2.8. Agreement Failure It is not uncommon for people to fail to make the appropriate agreement between the various parts of a noun or verb phrase as in: 1 wants to send a messages to Jim Smith. The appropriate action is to ignore the lack of agreement. and Weischedel and Black 1131 describe a method for relaxing the predicates in an ATN which typically check for such agreements. However, it is generally not possible to conclude locally which value of the marker (number or person) for which the clash occurs is actually intended. We considered examples in which the disagreement involves more than inflections (as in &amp;quot;the message over June 17&amp;quot;) in the section on substitutions. 2.9. Idioms Idioms are phrases whose interpretation is not what would be obtained by parsing and interpreting them constructively in the normal way. They may also not adhere to the standard syntactic rules. Idioms must thus be parsed as a whole in a pattern matching kind of mode. Parsers based purely oil pattern matching, like that of PARRY I ItJ, thus are able to parse idioms naturally. while others must either add a preprocessing phrase of pattern matching as in the LUNAR system (IS), or mix specific patterns in with more general rules, as in the work of Kwasny and Sondheimer [101. Semantic grammars (3, 8) provide a relatively natural way of mixing idiomatic and more general patterns. 2.10. User Supplied Changes In normal human conversation, once something is said, it is said and cannot be cliangixi. except indirectly by more words which refer back to the original ones. In interactively typed input, there is always the that a user may notice an error lie has made mid go back it himself, without wailinu the system to pursue its own, possibly slow and ineffective. methods of correction. With appropriate editing facilities. the user may do this without erasing intervening words, and, if the system is processing his input on a word by word basis. may 3. An Approach to Flexible Parsing current parsing systems are unable to cope with the kinds of grzunrnatical deviation outlined above. This is because typical parsing systems attempt to apply their grammar to their input in a rigid way, and since deviant input, by definition. does riot conform to the grammar, they are unable to produce any kind of parse for it at all. Attempts to parse more flexibly have typically involved parsing strategies to be used after a parse using an ATN or similar transition net has failed. Such ef forts include the ellipsis and paraphrase mechanisms of LIFER [81, the predicate relaxation techniques of Weischedel and Black (13), and several of the devices for extending ATN&apos;s proposed by Kwasny arid Sondheimer 1101. thus alter a word that the system has already processed. A flexible parser must be able to take advantage of such user provided corrections to unknown words, and to prefer thein over its own corrections. It must also be prepared to change its parse if the user changes a valid word to another different but equally valid word. 99 We have constructed a parser, FlexP, which can apply its grammar to its input flexibly, and thus deal with the grammatical deviations discussed in the previous section. We should emphasize, however. that FlexP is designed to be used in the interlace to a restricted-domain system. As such, it is intended to work Poen a domain-specific semantic grammar, rather than one suitable for broader classes of input. FlexP thus does not embody a solution for flexible parsing of natural language in general. In describing FlexP. we will note those of its techniques that seem unlikely to scale up to use with more complex grammars with wider coverage. We have adopted in FlexP an approach to flexible parsing based not on ATN&apos;s. but closer to the pattern-matching parser of the PARRY system 1111. possibly the most robust parser yet constructed. Our approach is based on several design decisions: • bottom up rather than top-down parsing: This aids in the parsing of fragmentary utterances, and in the rerogiation of interjections and restarts. • pattern matching: 1 his is essential for idioms, and also aids in the iletection of omissions and substitutions in non-idioinatic phrases. • parse suspension and continuation: The ability to suspend a parse and later resume its processing is important for interjections. restarts, and non-explicit terminations. In the remainder of this section we examine and justify these design decisions in more detail. 3.1. Bottom-Up Parsing Our choice of a bottom-up strategy is based on our need to recognize isolated sentence fragments. If an utterance which would normally be considered only a fragment of a complete sentence is to be recognized top-down, there are two approaches to take. First, the grammar can be altered so that the fragment is recognized as a complete utterance in its own right. This is undesirable because it can cause enormous expansion Of the grammar, and because it becomes difficult to decide whether a fragment appears in isolation or as part of a larger utterance. especially if the possibility of missing end of sentence markers also exists. The second option is for the parser to infer from the conversational context what grammatical sub-category (or sequence of sub-categories) the fragment might fit into, and then to do a top-down parse from that sub-category. This essentially is the tactic used in the GUS 121 and LIFER 1171) systems. This strategy is clearly better than the first one, but has two problems; first of predicting all possible sub-categories which might come next, and secondly, of inefficiency if a large number are predicted. Kwashy and Sondheimer 1101 use a combination of the two strategies by temporarily modifying an ATN grammar to accept fragment categories as complete utterances at the times they are contextually predicted. Gottoin-up parsing avoids the problem of predicting what sub-categories may occur. If a fragment fitting a given sub-category does occur, it is parsed as such whatever the context. However, if a given input Can be parsed as more than one sub-category, the bottom-up approach would have to produce them all, even if only one would be predicted top-down. In a system of limited comprehension, fragmentary recognition is sometimes necessary because not all of an input can be recognized, rather than because of intentional ellipsis. Here, ills probably impossible to make predictions and bottom-up parsing is the only method that is likely to work. As described below, bottom-up strategies, coupled with suspended parses, are also helpful in recognizing interjections and restarts. 3.2. Pattern Matching We have chosen to use a grammar of linear patterns rather than a If:amnion network because palteni-matching meshes well with bottom-up parsing. because it facilitates recognition (if utielances with omissions and substitutions, and because itis necessary anyway [Ur the fecoynition of idiomatic phrases. The grammar ol the parser is a set of rewrite or production rules whose hand ax le is a lineal pattern of cow:animas (lexical level) and whose right hand side defines a rfnult constituent. Elements of the pattern may be labelled optional or allow for repeated matches. We make assumption, certainly true for the grammar we working with, that the grammar will be semantic rather than syntactic, with patterns corresponding to idiomatic phrases or to oblect and event descriptions meaningful in some limited domain, rather than to general syntactic structures. Linear patterns fit well with bottom-up parsing because they can be indexed by any of their components, and becauSe, once indexed, it is straightforward to confirm whether a pattern matches input already processed in a way consistent with the way the pattern was indexed. Patterns help with the detection of omissions and substitutions because in either case the relevant pattern can still be indexed by the remaining elements that appear correctly in the input, and thus the pattern as a recognized even it some of its elements are missing or incorrect. In the case of substitutions. such a technique can actually help locus the spelling correction, proper name recognition. or vocabulary learning techniques, whichever is appropriate, by isolating the substituted input and the pattern constituent which it should have matched. In effect. this allows the normally bottom-up parsing strategy to go top-down to resolve such substitutions. In normal left to right processing, it is not necessary to activate all the Patterns indexed by every new word as it is considered. If a new word is accounted or by a Pattern that has already been partially matched by previous input, it is likely that no other patterns need to be indexed and matched for that input. This heuristic alows FlexP&apos;s parsing algorithm to limit the number of patterns it Ines to match. We should emphasize, that it heuristic, and while it has caused us no trouble with the limited-domain grammar we have been using, it is unclear how well it would transfer to a more complex grammar. FlexP&apos;s algorithm does, however. carry along multiple partial parses in other ambiguous cases. removing the need for any backtracking. 3.3. Parse Suspension and Continuation FlexP employs the technique of suspending a parse with the possibility of later continuation to help with the recognition of interjections. restarts. terininations. The parsing algorithm works left to right in a breadth-first manner. It maintains a set of partial parses, each at which accounts for the input already processed but riot yet accounted for by a completed parse. The parser attempts to incorporate each new input into each of the partial parses. If this is successful, the partial parses are and may increase Or decrease in number. If no partial parse be extended, the entire set is saved as a suspended parse. There are several possible explanations for input mismatch, i.e. the of Me next input to • The input could be an implicit termination. i.e. the start of a new top-level utterance, and the previous utterance should be assumed complete. t he input could be a restart, case ti.e active parse should be abandoned and a new parse started from that point. • The input could be the start of an interjection, in which case the active parse should be temporarily suspended, and a new Parse started for the intenection. It is not possible, in general, to distinguish between these cases at the time the mismatch occurs. It the active parse is not at a possible terniination point, then input mismatch cannot indicate implicit 100 termination, but may indicate either restart or interjection. It is necessary to suspend the active parse and wait to see if it is continued at the next input mismatch. On the other hand, if the active parse is at a possible termination point, input mismatch does not rule out interjection or even restart. In this situation, our algorithm tentatively assumes that there has been an implicit termination, but suspends the active parse anyway for subsequent potential continuation. Note also that the possibility of implicit termination provides justification for the strategy of interpreting each input immediately it is received. lithe input signals an implicit termination, then the user may well expect the system to respond immediately to the input thus terminated. 4. Details of FlexP This section describes how FlexP achieves the flexibilities discussed earlier. The implementation described is being used as the parser for an intelligent interface lo a multi-media message system II]. The intelligence this interface is concentrated in a between the user and the underlying tool system. The Agent ensures that the interaction goes smoothly by, among other things, checking that the user specifies the operations he wants performed and their parameters correctly and unambiguously. conducting a dialogue with the user if arise. The role of as the Agent&apos;s parser is to transform the user&apos;s input into the internal representations employed by the Agent. Usually this input is a request for action by the tool or a description of objects known to the tool. Our examples are drawn from that context. Suppose the user types new Interpretation begins as soon as any input is available. The first word is as an index into the store of rules. rule gives a pattern a structure to be past mod ilie pattern is matched. The components of the structure are built from the structures or words which match the elements of the pattern. The word &amp;quot;display&amp;quot; indexes the rule: (pattern: (Display Message Description) result: [Structurelype: Operationdeguest Operation: Display (Filler Using this rule time parser constructs the partial parse tree display We call the partially-instantiated pattern which labels the upper node a represents a possible interpretation for a segment of input. The next word &amp;quot;new&amp;quot; does riot directly match the hypothesis, but since &amp;quot;new&amp;quot; is a MsgAdj (an adjective which can modify a description of a message), it indexes the rule: Here. &amp;quot;?&amp;quot; means optional, and &amp;quot;&amp;quot; means repeatable. For the sake of clarity, we have omitted other prefixes which distinguish between terminal and non-terminal pattern elements. The result of this rule fits the current hypothesis. so extends the parse as follows: (Display MessageDescriplion) 1 (Met •MsgAdj Msgliead •MsgCase) display new lhe hypothesis is not yet fully confirmed even though all the elements are Its second i t, lower level hypothesis which is only iecompletely matched. This lower pattern becomes the because it pm edicts what should conic next in stream. The third input matches the category Msollead (head noun of a message description) and so fits the current hypothesis. This match fills the last non-oplional slot in that pattern. By doing so it makes the current and its parent pattern complete. the parser finds a potentially complete phrase whose result is of interest to the Agent (and the parent phrase in this example is in that category), the result is constructed and sent. However, since the parser has not seen a termination signal, this parse is kept tic.live. I lie iiiput see,&apos; SO far inay be only a prefix for some longer utterance such as &amp;quot;display new messages about ADA&amp;quot;. In this case &amp;quot;about ADA&amp;quot; would be recognized as a match for MsgCase (a prepositional phrase that can be part of a message description), the parse would be extended, and a revision of the previous structure sent to the Agent. Words When an input word cannot be found in the dictionary, spelling correction is attempted in a background process which runs at lower priority than the parser. The input word and a list of possibilities derived from the current hypothesis are passed as arguments. For example: display the new messaegs produces the partial parse (Display MessageDescription) (Met •MsgAdj MsgHead •MsgCase) display the The lower pattern is the current hypothesis and has two elements eligible to match the next input. Another MsgAdj could be matched. A match for MsgHead would also fit. Both elements have associated lists of keywords known to occur in phrases which match them. The one for MsgHead includes the word &amp;quot;messages&amp;quot;. and the spelling corrector passes this back to the parser as the most likely interpretation. In some cases the spelling corrector produces several likely alternatives. The parser handles such ambiguous words using the same mechanisms which accommodate phrases with ambiguous interpretations That is, alternative interpretations are carried along until there is enough discriminate those which are plausible from those which are not. details are given in the next section. The user inay also correct the input text himself. These changes are handled in much the same way as those proposed by the spelling corrector. Ot course, these user-supplied changes are given priority, and using the forme, he nnxlilietl discarded. Spelling correction is nal as a separate, lower priority process because a reasonable parse may be produced even without a proper interpretation for the unknown word. Since spelling correction can involve rather time-consuming searches, this work is best done when the parser has.no better alternatives to explore. 4.3. Ambiguous Input In the first example there was only one hypothesis about the structure of the input. More generally, there may be several hypotheses which provide competing interpretations about what has already been seen and what will appear next. Until these partial parses are found to be inconsistent with the actual input, they are carried along as part of the Therefore the active parse is a set of partial parse trees each (pattern: result: (Met •MsgAdj Msgllead •MsgCase) IStruclurelype: MessageDescription Components: 101 efficiency required for real-time response. but could conceivably fail to find appropriate parses. We have not encountered such circumstances with the small domain-specific semantic grammar we have been using. other hand. once Msgl lead has been matched only the last element is under interpretation of the pattern. 4.4. Flexible Matching rhe only flexibility described so far is that allowed by the optional elements of patterns. It omissions can he anticipated, allowances may be built isile the grammar. In this section we show how other omissions may he handled and othei flexibilities achieved by allownin additional freedom the way an item is allowed to match a pattern. are two ways in with a top-level hypothesis about the overall structure of the input so far and a current hypothesis concerning the next iflout. The actual implementation allows sharing of common structure among competing hypotheses and so is more efficient than this description suggests. The input were there any messages on be completed by giving a (&amp;quot;...on Tuesday&amp;quot;) a topic (&amp;quot;...on Consequently, the sub-phrase &amp;quot;any messages on&amp;quot; in partial parses: Consider the input display new alinia ADA hist two words parse produce (Display MessageDescription) (Wet •MsgAdj Msgliead •MsgCase) display new next word does not fit that hypothesis. two eligible elements predict either another message adjective or a MsgHead. The word &amp;quot;about&amp;quot; does not match either of these, nor can the parser construct any path to them using intermediate hypotheses. Since there are no other partial parses available to account for this input, and since normal matching fails, flexible matching is tried. and (Wel •Msgfldj Msgllead messages •MsgCase) (On Dale) on First. previously skipped elements are compared to the input. In this example, the element ?Det is considered but does not match. Next, elements to the right of the eligible elements are considered. Thus MsgCase is considered even though the non-optional element MsgHead not been matched. This succeeds and allows partial parse to be extended to any (net &apos;MsgAdj new (About Lop ic about display on the next were it would be consistent with the first parse, not the rA1C011(i. Since one the alternatives does account for the those that do may be discarded. On the other hand, if all the muses fail to matcli the input, other action glkell. We consider the SOCII011 suspended general strategy, carry al possible only as It is clear alternative. particular no flexible parsing techniques are used to support parses lor which there are plausible under normal parsing. This heuristic helps achieve which the matching criteria inay be relaxed. namely • relax consistency constraints, e.g. number agreement • allow out of order matches Consistency constraints are predicates which are attached to rules. They assert relationships which must hold among the items which fill the pattern. Mese constraints allow context-sensitive constructions in the grammar. Such predicates are commonly used for similar purposes by parsers 1141 the flexibility achieved by relaxing these constraints explored before )t31. The technique fits smoothly into FlexP but has not actually been needed or used in our current application. the other hand. out of order is for the parser&apos;s to errors of omission, transposition, and substitution. WI en strictly &apos;mei ineled. several elements of a pattern may he eligible to next input item. For example. in the pattern for a MessageDescription ( ?Del. •MsgAdj Msollead •MsgCase) of the lirst three elements initially but the last is not. On the which correctly predicts the final input item. are also handled by this mechanism. In the phrase display the new stuff about ADA the word &amp;quot;Stuff&amp;quot; is not found in the dictionary so spelling correction is tried but does not produce any plausible alternatives. While spelling the remaining inputs can be parsed by senelY &amp;quot;stuff&amp;quot; and using matching procedure. Transpositions are handled through one application of Ilexible matching if element of the is optional, two applications if not. 4.5. Suspended Parses are Imre comMon spoken in wi :en language but occur in typed input sometimes. To with such Ou«lesign for blocked parses be suspended rather than merely discarded. especially novices, may their input with words that do essential information and cannot be anticipalet. Consider t display please messages dated June 17 display for me messages dated June 17 the first case, the interjected word &amp;quot;please&amp;quot; be recognized as a noise phrase which nothing to the Agent except possibly suggest that the user is a novice. example is more difficult. Both words of the interjected phrase can appear in a number of legitimate meaningful constriliannis: cannot be ignored so Wet •MsgAdj •MsgCase) any messages (On Topic) 102 For the latter example. parse suspension works as follows. After the first word, the active parse contains a single partial parse: (Display MessageDescription) display The next word does not fit this hypothesis, so it is suspended. In its place, a new active parse is constructed. It contains several partial parses including Person) (for TimeInterval) 1 for for next confirms the first of these, Ind the fourth word &amp;quot;messages&amp;quot; does not. When the parser finds that it cannot extend the active parse, it considers the suspended parse. Since &amp;quot;messages&amp;quot; fits, the active and suspended parses are exchanged and the remainder of the input processed normally, so that the parser recognizes &amp;quot;display messages dated June 17&amp;quot; as if it had never contained &amp;quot;for me&amp;quot;. 5. Conclusion When people use language naturally, they mike mistakes and employ economies of expression that. often result in language which is ungrammatical by strict standards. In particular, such grammatical deviations will inevitably occur in the input of a computer system which allows its user lo employ natural language. Such a computer system must. therefore, be prepared to parse its inind flexibly, if il is avoid frustration for its user. In this paper, we have attempted to outline the main kinds of flexibility a natural language parser intended for natural use should provide. We also described a bottom-up pattern-matching parser. FlexP, which exhibits these Ilexibilities, and which is suitable for restricted natural language input to a limited-domain system.</abstract>
<note confidence="0.963780604651163">References 1. Ball, J. E. and Hayes, P. J. Representation of Task-Independent Knowledge in a Gracefully Interacting User Interface. Tech. Rept,, Carnegie-Mellon University Computer Science Department, 1980. Bobrow, D. G., Kaplan, R. M., Kay, D. A., Thompson, H., Winograd. T. &amp;quot;GUS: a Frame-Driven Dialogue System.&amp;quot; 3. Burton, R. R. Semantic Grammar: An Engineering Technique for Constructing Natural Language Understanding Systems. BBN Report 3453, Bolt, Beranek. and Newman, Inc., December, 1976. 4. Carbonell. J. G. Towards a Self-Extending Parser. Proc. of 17th Annual Meeting of the Assoc. for Commit. Ling., La Jolla, Ca., August, 1979, pp. 3-7. Carbonell, J. G. Understanding: Computer Models of Systems. Th., Yale University, 1979, DeJong, G. Stories in Real-Time. Th., Computer Science Dept., Yale University, 1979. 7. Hayes, P. J.. and Fleddy, R. Graceful Interaction in Man-Machine Communication. Proc. Sixth Int. Jt. Conf. on Artificial Intelligence, Tokyo, 1979, pp. 372-374. G. G. Human Engineering for Applied Natural Language Processing. Proc. Filth Int. Jt. Cont. on Artificial Intelligence, MIT, 1977, pp. 183-191. Kaplan, S. J. Responses from a Portable Natural Data Bata! Query System. Th.. Dept. of Computer and Information Science. University of Pennsylvania. Philadelphia, 1979. 10, Kwasny. S. C. and Sondheimer, N. K. Ungrammaticality and Extra-Grammaticality in Natural Language Understanding Systems. Proc. of 17111 Annual Meeting of the Assoc. for Comput. Ling., La Jolla, Ca., August. 1979, pp. 19-23. 11. Parkison. R. C., Colby, K. M., and Faught. W. S. • &amp;quot;Conversational Language Comprehension Using Integrated Pattern-Matching and Intelligeticy 9 (1977). 12. Waltz. D. L. &amp;quot;An English Language Question Answering System for Large Relational Data Base.&amp;quot; ACM 2 1,7 (1978), 3. Weischedel, R. M. and Black. J. Responding to Potentially Unpzuseable Sentences. Tech. Rept. 79/3. Dept. of Computer and Information Sciences, University of Delaware, 1979. 14. Woods, W. A. &amp;quot;Transition Network Grammars for Natural Language ACM 13, (October 1970), 591-606. 15. Woods, W. A.. Kaplan, R. M., and Nash-Webber, B. The Lunar t Report. Tech. Rept. 2378, Bolt, Beranek, and Newman, Inc., 1972. 103</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J E Ball</author>
<author>P J Hayes</author>
</authors>
<title>Representation of Task-Independent Knowledge in a Gracefully Interacting User Interface.</title>
<date>1980</date>
<tech>Tech. Rept,,</tech>
<institution>Carnegie-Mellon University Computer Science Department,</institution>
<marker>1.</marker>
<rawString>Ball, J. E. and Hayes, P. J. Representation of Task-Independent Knowledge in a Gracefully Interacting User Interface. Tech. Rept,, Carnegie-Mellon University Computer Science Department, 1980.</rawString>
</citation>
<citation valid="false">
<authors>
<author>T</author>
</authors>
<title>GUS: a Frame-Driven Dialogue System.&amp;quot;</title>
<journal>Artificial Intelligence</journal>
<volume>8</volume>
<issue>1977</issue>
<pages>155--173</pages>
<marker>2.</marker>
<rawString>Bobrow, D. G., Kaplan, R. M., Kay, M., Norman D. A., Thompson, H., and Winograd. T. &amp;quot;GUS: a Frame-Driven Dialogue System.&amp;quot; Artificial Intelligence 8(1977), 155-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R R Burton</author>
</authors>
<title>Semantic Grammar: An Engineering Technique for Constructing Natural Language Understanding Systems.</title>
<date>1976</date>
<tech>BBN Report 3453,</tech>
<contexts>
<context position="20858" citStr="(3, 8)" startWordPosition="3439" endWordPosition="3440">ms Idioms are phrases whose interpretation is not what would be obtained by parsing and interpreting them constructively in the normal way. They may also not adhere to the standard syntactic rules. Idioms must thus be parsed as a whole in a pattern matching kind of mode. Parsers based purely oil pattern matching, like that of PARRY I ItJ, thus are able to parse idioms naturally. while others must either add a preprocessing phrase of pattern matching as in the LUNAR system (IS), or mix specific patterns in with more general rules, as in the work of Kwasny and Sondheimer [101. Semantic grammars (3, 8) provide a relatively natural way of mixing idiomatic and more general patterns. 2.10. User Supplied Changes In normal human conversation, once something is said, it is said and cannot be cliangixi. except indirectly by more words which refer back to the original ones. In interactively typed input, there is always the possibility that a user may notice an error lie has made mid go back and correct it himself, without wailinu or the system to pursue its own, possibly slow and ineffective. methods of correction. With appropriate editing facilities. the user may do this without erasing intervenin</context>
</contexts>
<marker>3.</marker>
<rawString>Burton, R. R. Semantic Grammar: An Engineering Technique for Constructing Natural Language Understanding Systems. BBN Report 3453, Bolt, Beranek. and Newman, Inc., December, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G</author>
</authors>
<title>Towards a Self-Extending Parser.</title>
<date>1979</date>
<booktitle>Proc. of 17th Annual Meeting of the Assoc. for Commit.</booktitle>
<tech>Ph.D. Th.,</tech>
<pages>3--7</pages>
<institution>Yale University,</institution>
<location>Ling., La Jolla, Ca.,</location>
<marker>4.</marker>
<rawString>Carbonell. J. G. Towards a Self-Extending Parser. Proc. of 17th Annual Meeting of the Assoc. for Commit. Ling., La Jolla, Ca., August, 1979, pp. 3-7. 5, Carbonell, J. G. Subjective Understanding: Computer Models of Belief Systems. Ph.D. Th., Yale University, 1979,</rawString>
</citation>
<citation valid="true">
<authors>
<author>G DeJong</author>
</authors>
<title>Skimming Stories in Real-Time.</title>
<date>1979</date>
<tech>Ph.D. Th.,</tech>
<institution>Computer Science Dept., Yale University,</institution>
<marker>6.</marker>
<rawString>DeJong, G. Skimming Stories in Real-Time. Ph.D. Th., Computer Science Dept., Yale University, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Hayes</author>
<author>R Fleddy</author>
</authors>
<title>Graceful Interaction in Man-Machine Communication.</title>
<date>1979</date>
<booktitle>Proc. Sixth Int. Jt. Conf. on Artificial Intelligence,</booktitle>
<pages>372--374</pages>
<location>Tokyo,</location>
<marker>7.</marker>
<rawString>Hayes, P. J.. and Fleddy, R. Graceful Interaction in Man-Machine Communication. Proc. Sixth Int. Jt. Conf. on Artificial Intelligence, Tokyo, 1979, pp. 372-374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G G Hendrix</author>
</authors>
<title>Human Engineering for Applied Natural Language Processing.</title>
<date>1977</date>
<booktitle>Proc. Filth Int. Jt. Cont. on Artificial Intelligence,</booktitle>
<pages>183--191</pages>
<location>MIT,</location>
<contexts>
<context position="20858" citStr="(3, 8)" startWordPosition="3439" endWordPosition="3440">ms Idioms are phrases whose interpretation is not what would be obtained by parsing and interpreting them constructively in the normal way. They may also not adhere to the standard syntactic rules. Idioms must thus be parsed as a whole in a pattern matching kind of mode. Parsers based purely oil pattern matching, like that of PARRY I ItJ, thus are able to parse idioms naturally. while others must either add a preprocessing phrase of pattern matching as in the LUNAR system (IS), or mix specific patterns in with more general rules, as in the work of Kwasny and Sondheimer [101. Semantic grammars (3, 8) provide a relatively natural way of mixing idiomatic and more general patterns. 2.10. User Supplied Changes In normal human conversation, once something is said, it is said and cannot be cliangixi. except indirectly by more words which refer back to the original ones. In interactively typed input, there is always the possibility that a user may notice an error lie has made mid go back and correct it himself, without wailinu or the system to pursue its own, possibly slow and ineffective. methods of correction. With appropriate editing facilities. the user may do this without erasing intervenin</context>
</contexts>
<marker>8.</marker>
<rawString>Hendrix, G. G. Human Engineering for Applied Natural Language Processing. Proc. Filth Int. Jt. Cont. on Artificial Intelligence, MIT, 1977, pp. 183-191.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S J Kaplan</author>
</authors>
<title>Cooperative Responses from a Portable Natural latiumitte Data Bata! Query System.</title>
<date>1979</date>
<booktitle>Proc. of 17111 Annual Meeting of the Assoc. for Comput.</booktitle>
<tech>Ph.D. Th..</tech>
<volume>10</volume>
<pages>pp.</pages>
<institution>Dept. of Computer and Information Science. University of Pennsylvania.</institution>
<location>Philadelphia,</location>
<marker>9.</marker>
<rawString>Kaplan, S. J. Cooperative Responses from a Portable Natural latiumitte Data Bata! Query System. Ph.D. Th.. Dept. of Computer and Information Science. University of Pennsylvania. Philadelphia, 1979. 10, Kwasny. S. C. and Sondheimer, N. K. Ungrammaticality and Extra-Grammaticality in Natural Language Understanding Systems. Proc. of 17111 Annual Meeting of the Assoc. for Comput. Ling., La Jolla, Ca., August. 1979, pp. 19-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C</author>
<author>K M Colby</author>
<author>W S Faught</author>
</authors>
<title>Conversational Language Comprehension Using Integrated Pattern-Matching and Parsing.&amp;quot;</title>
<date>1977</date>
<journal>Attatcial Intelligeticy</journal>
<volume>9</volume>
<pages>111--134</pages>
<marker>11.</marker>
<rawString>Parkison. R. C., Colby, K. M., and Faught. W. S. • &amp;quot;Conversational Language Comprehension Using Integrated Pattern-Matching and Parsing.&amp;quot; Attatcial Intelligeticy 9 (1977). 111-134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L</author>
</authors>
<title>An English Language Question Answering System for a Large Relational Data Base.&amp;quot;</title>
<date>1978</date>
<journal>Comm. ACM</journal>
<volume>2</volume>
<pages>526--539</pages>
<marker>12.</marker>
<rawString>Waltz. D. L. &amp;quot;An English Language Question Answering System for a Large Relational Data Base.&amp;quot; Comm. ACM 2 1,7 (1978), 526-539.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J</author>
</authors>
<title>Responding to Potentially Unpzuseable Sentences.</title>
<date>1979</date>
<tech>Tech. Rept. 79/3.</tech>
<institution>Dept. of Computer and Information Sciences, University of Delaware,</institution>
<contexts>
<context position="20858" citStr="(3, 8)" startWordPosition="3439" endWordPosition="3440">ms Idioms are phrases whose interpretation is not what would be obtained by parsing and interpreting them constructively in the normal way. They may also not adhere to the standard syntactic rules. Idioms must thus be parsed as a whole in a pattern matching kind of mode. Parsers based purely oil pattern matching, like that of PARRY I ItJ, thus are able to parse idioms naturally. while others must either add a preprocessing phrase of pattern matching as in the LUNAR system (IS), or mix specific patterns in with more general rules, as in the work of Kwasny and Sondheimer [101. Semantic grammars (3, 8) provide a relatively natural way of mixing idiomatic and more general patterns. 2.10. User Supplied Changes In normal human conversation, once something is said, it is said and cannot be cliangixi. except indirectly by more words which refer back to the original ones. In interactively typed input, there is always the possibility that a user may notice an error lie has made mid go back and correct it himself, without wailinu or the system to pursue its own, possibly slow and ineffective. methods of correction. With appropriate editing facilities. the user may do this without erasing intervenin</context>
</contexts>
<marker>3.</marker>
<rawString>Weischedel, R. M. and Black. J. Responding to Potentially Unpzuseable Sentences. Tech. Rept. 79/3. Dept. of Computer and Information Sciences, University of Delaware, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Transition Network Grammars for Natural Language Analysis.&amp;quot;</title>
<date>1970</date>
<journal>Comm. ACM</journal>
<volume>13</volume>
<pages>10</pages>
<marker>14.</marker>
<rawString>Woods, W. A. &amp;quot;Transition Network Grammars for Natural Language Analysis.&amp;quot; Comm. ACM 13, 10 (October 1970), 591-606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Kaplan Woods</author>
<author>R M</author>
<author>B Nash-Webber</author>
</authors>
<title>The Lunar Science!: t Final Report.</title>
<date>1972</date>
<tech>Tech. Rept. 2378,</tech>
<location>Bolt, Beranek, and Newman, Inc.,</location>
<marker>15.</marker>
<rawString>Woods, W. A.. Kaplan, R. M., and Nash-Webber, B. The Lunar Science!: t Final Report. Tech. Rept. 2378, Bolt, Beranek, and Newman, Inc., 1972.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>