<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000221">
<title confidence="0.989391">
From Descriptive Annotation to Grammar Specification
</title>
<author confidence="0.954427">
Lars Hellan
</author>
<affiliation confidence="0.7957405">
NTNU
Trondheim, Norway
</affiliation>
<email confidence="0.95093">
lars.hellan@hf.ntnu.no
</email>
<sectionHeader confidence="0.996924" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999668714285714">
The paper presents an architecture for connecting
annotated linguistic data with a computational gram-
mar system. Pivotal to the architecture is an annota-
tional interlingua – called the Construction Labeling
system (CL) - which is notationally very simple, de-
scriptively finegrained, cross-typologically applica-
ble, and formally well-defined enough to map to a
state-of-the-art computational model of grammar. In
the present instantiation of the architecture, the com-
putational grammar is an HPSG-based system called
TypeGram. Underlying the architecture is a research
program of enhancing the interconnectivity between
linguistic analytic subsystems such as grammar for-
malisms and text annotation systems.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999985119047619">
This paper advocates the view that all aspects of
descriptive, theoretical, typological, and compu-
tational linguistics should hang together in over-
all precisely defined networks of terminologies
and formalisms, but flexibly so such that each
field can choose suitable formats, and different
traditions can maintain their preferred terminol-
ogies and formalisms. Terms and symbols used
for linguistic annotation are central in this enter-
prise, and the paper describes an algorithm by
which a code suitable for sentence level annota-
tion can be aligned with a system of attribute-
value matrix (AVM) representations. An aim for
further development is a similar alignment for
PoS/morpheme annotation symbols.
The alignment described has as its theoretical
and computational reference point an HPSG-
based system, where, aside from AVMs, types
play a crucial role. Most likely, alignment archi-
tectures with similar capacities to the one here
described can have other formal frameworks in-
tegrated. For such alternatives the present system
may serve as a roadmap, and hopefully more: the
architecture is sought to be modular such that
parts of it – such as the formal framework, or an
annotation tag system - can be replaced while
keeping other parts constant. At the present
point, however, this is a demonstration tied to
unique choices for each module in the architec-
ture. It serves as a feasibility demonstration of
the design as such, and equally much to motivate
the specific annotation code presented, which is
pivotal to the system as a whole.
This paper has two parts. The first part presents
the sentence-level annotation code. It consists of
strings of labels (connected by hyphens) where
each label represents a possible property of a
sentential sign, such as, e.g., ‘has Argument
structure X’, ‘has Aspect Y’, ‘has a Subject with
properties Z’, ‘expresses situation type S’, etc.
The construction type specification in (1) is a
first illustration of the code:
</bodyText>
<equation confidence="0.9162175">
(1) v-tr-suAg_obAffincrem-
COMPLETED_MONODEVMNT
</equation>
<bodyText confidence="0.9835028">
(Ex.: English: the boy ate the cake)
This reads: the sign is headed by verb; its syntac-
tic frame is transitive; it has a Subject (su) whose
thematic role is agent, and an Object (ob) whose
thematic role is incrementally affected; its aspec-
tual type is characterized as a combination of
completed and monotonic development.
Expressions like that in (1), characterizing a
sentence from its ‘global’ perspective, are re-
ferred to as templates. The code is flexible in
having no upward bound on the number of labels
used in a template, and expressive in that each
label represents a statement about some part or
aspect of the sign. The code as such will be re-
ferred to as the Construction Labeling (CL)
system; see section 2.
The circumstance that each individual label has
the logic of a statement, is essential to the trans-
parency of the code. This propositional character
of a label also opens for the alignment of CL
with a formal grammar system, which is ad-
dressed in the second part of the paper. Here we
show how templates can be linked to AVMs, like
the template in (1) to an AVM like (2) (in mixed
HPSG/LFG style),
</bodyText>
<page confidence="0.970128">
172
</page>
<note confidence="0.41134">
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 172–176,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<equation confidence="0.997903904761905">
⎡HEAD verb ⎤
⎢ ⎥
⎢⎡ SUBJ INDX 1 ROLE agent
⎡ [ ]⎤ ⎤
⎢ ⎣ ⎦ ⎥
⎢ GF ⎥ ⎥
⎢ ⎢ OBJ INDX 2 ROLE aff-increm
⎡ [ ]⎤ ⎥ ⎥
⎢ ⎣ ⎣ ⎦ ⎥
⎢ ⎦ ⎥
⎢ INDX ref-index ⎥
⎢ ⎥
⎢ ASPECT completed ⎥
⎢ ⎥
⎡ ACT1 1 ⎤
⎢ ACTNTS ⎥
⎢ ⎥
⎢ ACT2 2 ⎥
⎢ ⎣ ⎥ ⎦
⎢ ⎥
⎣ ⎢ SIT-TYPE monotonic_development ⎥
</equation>
<bodyText confidence="0.80151625">
and in such a way that each individual label in the
template can be seen as inducing its specific part
of the AVM, as informally and partially indicated
in (3):
</bodyText>
<equation confidence="0.999708190476191">
v - - - [ HEAD verb]
tr - - - ⎡⎡ S U B J IN D X 1
⎡ ⎤ ⎤ ⎤
⎢ ⎢ ⎣ ⎦ ⎥ ⎥
G F
⎢ ⎢ ⎤ ⎥ ⎥
O B J IN D X 2
⎡
⎢ ⎢ ⎣ ⎣ ⎦ ⎥
⎥ ⎦
⎢ ⎥
⎢⎡ A C T 1 1 ⎤ ⎥
A C T N T S
⎢ ⎢ ⎥ ⎥
⎣ ⎢ ⎣ A C T 2 2 ⎥ ⎦ ⎦
suAg - - - ⎡ GF SUBJ INDX [ ROLE agent]
⎡ ⎡ ⎤ ⎤ ⎤ ⎦
⎣ ⎣ ⎣ ⎦ ⎦
obAffincrem - - - ⎡GF OBJ INDX [ ROLE aff-increm ]
⎡ ⎡ ⎤⎤⎤ ⎦
⎣ ⎣ ⎣ ⎦ ⎦
</equation>
<bodyText confidence="0.999989875">
Thus, while the labels have a descriptive trans-
parency essential to the descriptive functionality
of the over-all code, this transparency can be
‘cashed out’ also in the definition of a linking
between CL and grammar formalisms like that
illustrated in (2) and (3). Section 3 describes a
possible architecture for achieving this, centered
around the computational grammar TypeGram.
</bodyText>
<sectionHeader confidence="0.742193" genericHeader="method">
2 Construction Labeling
</sectionHeader>
<bodyText confidence="0.999947620689655">
In its first development, the coding system has
been based on two typologically very diverse
languages: Norwegian, and the West African lan-
guage Ga. An overview of the system is given in
(Hellan and Dakubu 2010). The end product of
its application to a language is called a construc-
tion profile of the language, abbreviated its c-
profile. This is an assembly of between 150 and
250 templates encoding the span of variation of-
fered by the language in a fixed number of re-
spects, in a code immediately comparable to c-
profiles of other languages. A c-profile for both
Ga and Norwegian is given in (Hellan and Da-
kubu op. cit.); see also (Hellan and Dakubu 2009,
Dakubu 2008, Hellan 2008).
The typical method of establishing c-profiles is
through paradigm building, where, based on one
sentence of the language, one establishes the
various paradigms relative to which the sentence
instantiates choices, and supplements these para-
digms with paradigms spun out of other sen-
tences or constructions, ultimately establishing a
full network of construction types for the lan-
guage relative to the discriminants selected.
(‘Construction’ is here used in a theory neutral
way.)
The creation of c-profiles is obviously an in-
cremental process, both in the building of tem-
plates instantiating possibilities defined by the
range of discriminants recognized at any point,
and in extending this range reflecting new phe-
nomena and new languages investigated. Thus,
while the stage referred to above reflects in depth
work on Germanic and Kwa, significant en-
hancements are currently made through work on
Ethio-semitic (especially through the study
(Wakjira, to appear) on Kistaninya), Bantu,
Indic, and other language groups, mostly not yet
having achieved full c-profiles.
Although presentable as networks, in normal
displays c-profiles are given as lists, with strict
principles of ordering. Some c-profiles are also
entered in the TypeCraft database
(http://www.typecraft.org/), where one can
search according to any labels serving as con-
stituents of templates. At present, the number of
labels employed in the code is about 40 for va-
lence types, 90 for specifications relating to the
syntactic form of specific constituents, 40 for
thematic roles of specific constituents, 20 for
aspect and Aktionsart values, and 60 for situation
types. For valence and grammatical functions,
language and framework independence in the
code is made possible due to considerable agree-
ment across traditions, whereas for participant
roles and situation types, there is much less of a
consolidated basis, and in these areas code de-
velopment and evaluation is still a primary issue.
</bodyText>
<sectionHeader confidence="0.999173" genericHeader="method">
3 TypeGram
</sectionHeader>
<bodyText confidence="0.999794727272727">
TypeGram is in most respects a normal HPSG-
based computational grammar built on the LKB
platform (Copestake 2002). Crucial to the pre-
sent discussion, it has some components de-
signed for linking it up with the CL code, which
makes it possible for it to
- provide an AVM display of any CL template
(like (2) above, for (1));
- provide a basis for a rapid development of a
parsing grammar for any language for which a
c-profile has been created;
</bodyText>
<page confidence="0.995494">
173
</page>
<bodyText confidence="0.999903133333333">
- provide an intermediate parsing facility for
sentences of any language even when no gram-
mar specific to the language has been created, as
long as the language has been assigned a c-
profile.
We will refer to the ‘basic’ part of TypeGram
as its Core. Relative to current grammar formal-
isms using AVMs, such as LFG and HPSG (cf.
Bresnan 2001, Butt et al. 1999, Pollard and Sag
1994), the TypeGram Core borrows from LFG
an inventory of grammatical functions, and from
HPSG the use of types, and a design by which
all components of a grammar are encoded in
AVMs. Unlike most computational grammars,
the Core defines analyses for phenomena not
restricted to one language, but for the union of
all languages for which c-profiles have been de-
fined. (In this respect it resembles the HPSG
Grammar Matrix (‘the Matrix’ - see Bender et.
al, and http://www.delph-in.net/matrix/ ); we
comment on its relationship to this system be-
low.) The mediation between the Core and the c-
profiles is induced by special type files:
- one file for each c-profile (of which there are
currently three, for Ga, Norwegian and Kistan-
inya)
- one general file, called Labeltypes, for defin-
ing CL labels as types in terms of the Core types.
This architecture can be summed up as follows
(with ‘Ga c-types’ meaning ‘types correspond-
ing to the templates constituting the c-profile for
Ga’, and items in boldface being items defined
inside the TypeGram system):
Thus, what communicates between the Core and
the construction specifications in the CL code is
Labeltypes, which in turn feeds into the lan-
guage specific template definition files. The lat-
ter files build only on Labeltypes, which in turn
builds only on the Core. This allows for modu-
larity: the content of the Core can be changed,
e.g., to the system of the Matrix (or even an
LFG-based system), without affecting the c-
profiles or the c-type inventories.
We now describe possibilities offered by the
architecture.
</bodyText>
<subsectionHeader confidence="0.999354">
3.1 Providing AVM displays of templates
</subsectionHeader>
<bodyText confidence="0.996284333333333">
In exemplifying this function, we use a template
from Ga, along with a glossed example to illus-
trate the construction type:
</bodyText>
<figure confidence="0.9536444">
(5) v-ditr-obPostp-
suAg_obEndpt_ob2Mover-PLACEMENT
Ame-wo tsone le mli yele
3P.AOR-put vehicle DEF inside yam
V N Art N N
</figure>
<figureCaption confidence="0.3900495">
‘They put [vehicle’s inside] [yam]’ = ‘They
put yams in the lorry.’
</figureCaption>
<bodyText confidence="0.9196898">
Here the two objects represent a Mover (the
yam) and where the Mover is finally placed (the
lorry’s inside). This Endpoint is characterized as
the inside of something, where the expression of
this inside is structurally like a possessive NP
construction.
In the type-file ‘Ga c-types’, the template in
(5) is turned into a grammatical type by the type
definition (6) (where ‘:=’ means ‘is a subtype
of’ and ‘&amp;’ is the operation of unification):
</bodyText>
<equation confidence="0.519185">
v-ditr-obPostp-suAg_obEndpt_ob2Th-
PLACEMENT :=
v &amp; ditr &amp; obPostp &amp; suAg &amp; obEndpt &amp; ob2Th
&amp; PLACEMENT.
</equation>
<bodyText confidence="0.999904533333333">
The way in which the individual types v, ditr,
obPostp, etc., are here unified to constitute a
definition of the type corresponding to the full
template, corresponds to the way in which, in
(3), the constituent labels of the template (1) are
portrayed as contributing to its full AVM.
The defining types in (6) are in turn defined in
labeltypes, by definitions whose defining terms
are in turn defined in the Core.
With such type definitions in the background,
the template v-ditr-obPostp-
suAg_obEndpt_ob2Th-PLACEMENT is a type
recognized in the grammar. Using the view type
definition offered in a standard LKB interface,
one sees the AVM assigned to this template.
</bodyText>
<subsectionHeader confidence="0.999961">
3.2 Developing a parsing grammar
</subsectionHeader>
<bodyText confidence="0.999502">
Suppose that we want to develop a grammar
of Ga – GaGram -, taking advantage of the type
apparatus already described. (For Ga, the lexi-
con (Dakubu 2009) is partly informed by the c-
profile and is a resource in building the lexicon
of the grammar.) What is missing is defining a
lexicon, inflectional rules, derivational rules and
</bodyText>
<figure confidence="0.643161666666667">
(4)
c-profile of Ga Ga c-types
c-profile of
Norwegian Norw.c-typ Labeltypes
c-profile of
Kistaninya Kistane c-types Core
</figure>
<page confidence="0.996458">
174
</page>
<bodyText confidence="0.9999451">
syntactic combinatorial rules. The latter is partly
deducible from the constructional templates, and
for templates which reflect verb subcategoriza-
tion frames, lexical frame types are fairly di-
rectly derivable from the templates. What needs
to be done in addition is specifying the lexical
root items of Ga, and the inflectional and deriva-
tional formatives used in the language.
This ‘grammar construction kit’ offered by
TypeGram clearly resembles the HPSG Gram-
mar Matrix (‘Matrix’; cf. Bender et al. 2002). It
differs from the Matrix most essentially through
the way in which the grammar internal specifica-
tions are ‘semi-automatically’ updated as the c-
profile grows. This systematic linkage between a
cross-linguistic descriptive classification code
and a computational grammar code is not yet
available in the Matrix. Nothing, though, pre-
cludes introducing the TypeGram architecture
also there, in this respect.
</bodyText>
<subsectionHeader confidence="0.9979">
3.3 An intermediate parsing facility
</subsectionHeader>
<bodyText confidence="0.998158">
TypeGram has specifications which, in addition
to the above, in principle enable it to parse the
Ga string in (5) – viz.,
</bodyText>
<listItem confidence="0.533812">
(7) AmE-wo tsone lE mli yElE
</listItem>
<bodyText confidence="0.534428">
as a structure like (8) (AVM not shown):
</bodyText>
<subsectionHeader confidence="0.449084">
V3PputAor Nvehicle ArtDEF Ninside Nyam
</subsectionHeader>
<bodyText confidence="0.999450555555556">
We may informally refer to (8) as an ‘x-ray’ of
(7). As terminal nodes in the parse tree, it has
the English glosses corresponding to the Ga
roots, and functional morph glosses for the ac-
tual formatives of the Ga string. This is achieved
through having as input to the parser not the
string (7) itself, but the standard gloss associated
with the string – (9a) – suitably modified to stan-
dard LKB parse input format:
</bodyText>
<figure confidence="0.682275">
(9)
3P.AOR-put vehicle DEF inside yam
V N Art N N
b. V3PputAor Nvehicle ArtDEF Ninside Nyam
</figure>
<bodyText confidence="0.9998805">
This is achieved by having the TypeGram lexi-
con contain all those English roots which ever
appear in the glosses of Ga sentences (obviously
relative to a limited, but in principle expandable
corpus), and having these roots be associated
with exactly the frame types which the corre-
sponding Ga roots have relative to Ga. Thus, to
produce (8), this lexicon would have to include
an entry like (10) (using LKB style format),
‘put’ being the counterpart to wo in this context:
</bodyText>
<equation confidence="0.845941">
(10)
put := v-ditr-obPostp-suAg_obEndpt_ob2Th-
PLACEMENT &amp; [ ORTH &lt;“put“&gt;,
ACTANTS.PRED put_rel ].
</equation>
<bodyText confidence="0.999826941176471">
What this facility amounts to is a parser dis-
playing the structure of sentences of a language
for which one has designed a c-profile, but not
yet a parsing grammar. It would be useful as a
tool for typological comparison. To work, such a
system would require a highly disciplined set of
conventions for ‘standard’ glossing, and an in-
terface in addition to LKB where such a glossing
would be ‘read in’ as a string-to-parse; the latter
is a facility not yet implemented (the only exist-
ing candidate interface for this purpose, to our
knowledge, would be TypeCraft (cf. Beermann
and Mihaylov 2009), while the development of
the former (presumably with reference to exist-
ing glossing conventions such as the Leipzig
Glossing rules, see References) would be part of
the over-all initiative described at the outset.
</bodyText>
<sectionHeader confidence="0.999613" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.99995795">
With the Construction Labeling code and its de-
ployment across languages as a basis, we have
shown how this code can be mapped to a gram-
mar formalism, both formally and computation-
ally. We are thereby able to, at one and the same
time, develop descriptive sentence level annota-
tions across typologically diverse languages with
a unitary code, and derive from these annota-
tions facilities for automatic display of AVMs
for any coded annotation, for rapid grammar de-
velopment for the language concerned, and – so
far less robustly - for intermediate ‘gloss’-
reflecting parsing.
We have thereby provided a system where de-
scriptive, theoretical, typological, and computa-
tional concerns are brought together in an over-
all precisely defined network of terminologies
and formalisms, and flexibly so such that each
field – here annotation and grammar develop-
ment – have their respective suitable formats.
</bodyText>
<figure confidence="0.9930235">
(8) VP
V NP NP
NP N
N Art
</figure>
<page confidence="0.991843">
175
</page>
<sectionHeader confidence="0.99586" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996077813559322">
Dorothee Beermann and Pavel Mihaylov 2009. Type-
Craft – Glossing and Databasing for Linguists.
Proceedings of the 23rd Scandinavian Conference
of Linguistics, Uppsala, Sweden, October 2008.
Emily M Bender, Dan Flickinger, and Stephan Oepen.
2002. The Grammar Matrix: An open-source
starter kit for the rapid development of cross-
linguistically consistent broad-coverage precision
grammars. In Proceedings of the Workshop on
Grammar Engineering and Evaluation, COLING
2002, Taipei.
Joan Bresnan. 2001. Lexical Functional Grammar.
Oxford: Blackwell.
Miriam Butt, Tracy Holloway King, Maria-Eugenia
Nini and Frederique Segond. 1999. A Grammar-
writer&apos;s Cookbook. Stanford: CSLI Publications.
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI Publications.
Mary Esther Kropp Dakubu,. 2008. The Construction
label project: a tool for typological study. Pre-
sented at West African Languages Congress
(WALC), Winneba, July 2008.
Mary Esther Kropp Dakubu. 2009. Ga-English Dic-
tionary. Accra.
Lars Hellan. 2008. Enumerating Verb Constructions
Cross-linguistically. COLING Workshop on Gram-
mar Engineering Across frameworks. Manchester.
http://www.aclweb.org/anthology-
new/W/W08/#1700
Lars Hellan and Mary Esther Kropp Dakubu. 2009:
A methodology for enhancing argument structure
specification. In: Proceedings from the 4th Lan-
guage Technology Conference (LTC 2009),
Poznan.
Lars Hellan and Mary Esther Kropp Dakubu. 2010.
Identifying Verb Constructions Cross-
linguistically. SLAVOB series, Univ. of Ghana
(http://www.typecraft.org/w/images/d/db/1_Introla
bels_SLAVOB-final.pdf,
http://www.typecraft.org/w/images/a/a0/2_Ga_app
endix_SLAVOB-final.pdf,
http://www.typecraft.org/w/images/b/bd/3_Norweg
ian_Appendix_plus_3_SLAVOB-final.pdf )
Carl Pollard and Ivan Sag. 1994. Head-Driven Phrase
Structure Grammar. Chicago University Press.
Bedilu Debela Wakjira. To appear. Kistaninya Verb
Morphology and Verb Constructions. PhD disserta-
tion. NTNU.
Some web sites:
Leipzig glossing rules:
http://www.eva.mpg.de/lingua/resources/glossing-
rules.php
TypeGram:
http://www.typecraft.org/tc2wiki/TypeGram
TypeCraft:
http://www.typecraft.org/
Construction Labeling site:
http://www.typecraft.org/research/projects/Verbconstr
uctions/
</reference>
<page confidence="0.997995">
176
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.655216">
<title confidence="0.995345">From Descriptive Annotation to Grammar Specification</title>
<author confidence="0.746361">Lars</author>
<affiliation confidence="0.778099">Trondheim,</affiliation>
<email confidence="0.995685">lars.hellan@hf.ntnu.no</email>
<abstract confidence="0.999465933333333">The paper presents an architecture for connecting annotated linguistic data with a computational grammar system. Pivotal to the architecture is an annotacalled the Labeling system (CL) which is notationally very simple, descriptively finegrained, cross-typologically applicable, and formally well-defined enough to map to a state-of-the-art computational model of grammar. In the present instantiation of the architecture, the computational grammar is an HPSG-based system called Underlying the architecture is a research program of enhancing the interconnectivity between linguistic analytic subsystems such as grammar formalisms and text annotation systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dorothee Beermann</author>
<author>Pavel Mihaylov</author>
</authors>
<title>TypeCraft – Glossing and Databasing for Linguists.</title>
<date>2009</date>
<booktitle>Proceedings of the 23rd Scandinavian Conference of Linguistics,</booktitle>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="15228" citStr="Beermann and Mihaylov 2009" startWordPosition="2588" endWordPosition="2591">&lt;“put“&gt;, ACTANTS.PRED put_rel ]. What this facility amounts to is a parser displaying the structure of sentences of a language for which one has designed a c-profile, but not yet a parsing grammar. It would be useful as a tool for typological comparison. To work, such a system would require a highly disciplined set of conventions for ‘standard’ glossing, and an interface in addition to LKB where such a glossing would be ‘read in’ as a string-to-parse; the latter is a facility not yet implemented (the only existing candidate interface for this purpose, to our knowledge, would be TypeCraft (cf. Beermann and Mihaylov 2009), while the development of the former (presumably with reference to existing glossing conventions such as the Leipzig Glossing rules, see References) would be part of the over-all initiative described at the outset. 4 Conclusion With the Construction Labeling code and its deployment across languages as a basis, we have shown how this code can be mapped to a grammar formalism, both formally and computationally. We are thereby able to, at one and the same time, develop descriptive sentence level annotations across typologically diverse languages with a unitary code, and derive from these annotat</context>
</contexts>
<marker>Beermann, Mihaylov, 2009</marker>
<rawString>Dorothee Beermann and Pavel Mihaylov 2009. TypeCraft – Glossing and Databasing for Linguists. Proceedings of the 23rd Scandinavian Conference of Linguistics, Uppsala, Sweden, October 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily M Bender</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<title>The Grammar Matrix: An open-source starter kit for the rapid development of crosslinguistically consistent broad-coverage precision grammars.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Grammar Engineering and Evaluation, COLING 2002,</booktitle>
<location>Taipei.</location>
<contexts>
<context position="12879" citStr="Bender et al. 2002" startWordPosition="2194" endWordPosition="2197"> of Ga Ga c-types c-profile of Norwegian Norw.c-typ Labeltypes c-profile of Kistaninya Kistane c-types Core 174 syntactic combinatorial rules. The latter is partly deducible from the constructional templates, and for templates which reflect verb subcategorization frames, lexical frame types are fairly directly derivable from the templates. What needs to be done in addition is specifying the lexical root items of Ga, and the inflectional and derivational formatives used in the language. This ‘grammar construction kit’ offered by TypeGram clearly resembles the HPSG Grammar Matrix (‘Matrix’; cf. Bender et al. 2002). It differs from the Matrix most essentially through the way in which the grammar internal specifications are ‘semi-automatically’ updated as the cprofile grows. This systematic linkage between a cross-linguistic descriptive classification code and a computational grammar code is not yet available in the Matrix. Nothing, though, precludes introducing the TypeGram architecture also there, in this respect. 3.3 An intermediate parsing facility TypeGram has specifications which, in addition to the above, in principle enable it to parse the Ga string in (5) – viz., (7) AmE-wo tsone lE mli yElE as </context>
</contexts>
<marker>Bender, Flickinger, Oepen, 2002</marker>
<rawString>Emily M Bender, Dan Flickinger, and Stephan Oepen. 2002. The Grammar Matrix: An open-source starter kit for the rapid development of crosslinguistically consistent broad-coverage precision grammars. In Proceedings of the Workshop on Grammar Engineering and Evaluation, COLING 2002, Taipei.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
</authors>
<title>Lexical Functional Grammar.</title>
<date>2001</date>
<publisher>Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="8718" citStr="Bresnan 2001" startWordPosition="1510" endWordPosition="1511">esigned for linking it up with the CL code, which makes it possible for it to - provide an AVM display of any CL template (like (2) above, for (1)); - provide a basis for a rapid development of a parsing grammar for any language for which a c-profile has been created; 173 - provide an intermediate parsing facility for sentences of any language even when no grammar specific to the language has been created, as long as the language has been assigned a cprofile. We will refer to the ‘basic’ part of TypeGram as its Core. Relative to current grammar formalisms using AVMs, such as LFG and HPSG (cf. Bresnan 2001, Butt et al. 1999, Pollard and Sag 1994), the TypeGram Core borrows from LFG an inventory of grammatical functions, and from HPSG the use of types, and a design by which all components of a grammar are encoded in AVMs. Unlike most computational grammars, the Core defines analyses for phenomena not restricted to one language, but for the union of all languages for which c-profiles have been defined. (In this respect it resembles the HPSG Grammar Matrix (‘the Matrix’ - see Bender et. al, and http://www.delph-in.net/matrix/ ); we comment on its relationship to this system below.) The mediation b</context>
</contexts>
<marker>Bresnan, 2001</marker>
<rawString>Joan Bresnan. 2001. Lexical Functional Grammar. Oxford: Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Tracy Holloway King</author>
<author>Maria-Eugenia Nini</author>
<author>Frederique Segond</author>
</authors>
<title>A Grammarwriter&apos;s Cookbook.</title>
<date>1999</date>
<publisher>CSLI Publications.</publisher>
<location>Stanford:</location>
<contexts>
<context position="8736" citStr="Butt et al. 1999" startWordPosition="1512" endWordPosition="1515">nking it up with the CL code, which makes it possible for it to - provide an AVM display of any CL template (like (2) above, for (1)); - provide a basis for a rapid development of a parsing grammar for any language for which a c-profile has been created; 173 - provide an intermediate parsing facility for sentences of any language even when no grammar specific to the language has been created, as long as the language has been assigned a cprofile. We will refer to the ‘basic’ part of TypeGram as its Core. Relative to current grammar formalisms using AVMs, such as LFG and HPSG (cf. Bresnan 2001, Butt et al. 1999, Pollard and Sag 1994), the TypeGram Core borrows from LFG an inventory of grammatical functions, and from HPSG the use of types, and a design by which all components of a grammar are encoded in AVMs. Unlike most computational grammars, the Core defines analyses for phenomena not restricted to one language, but for the union of all languages for which c-profiles have been defined. (In this respect it resembles the HPSG Grammar Matrix (‘the Matrix’ - see Bender et. al, and http://www.delph-in.net/matrix/ ); we comment on its relationship to this system below.) The mediation between the Core an</context>
</contexts>
<marker>Butt, King, Nini, Segond, 1999</marker>
<rawString>Miriam Butt, Tracy Holloway King, Maria-Eugenia Nini and Frederique Segond. 1999. A Grammarwriter&apos;s Cookbook. Stanford: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars.</title>
<date>2002</date>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="8045" citStr="Copestake 2002" startWordPosition="1384" endWordPosition="1385">ating to the syntactic form of specific constituents, 40 for thematic roles of specific constituents, 20 for aspect and Aktionsart values, and 60 for situation types. For valence and grammatical functions, language and framework independence in the code is made possible due to considerable agreement across traditions, whereas for participant roles and situation types, there is much less of a consolidated basis, and in these areas code development and evaluation is still a primary issue. 3 TypeGram TypeGram is in most respects a normal HPSGbased computational grammar built on the LKB platform (Copestake 2002). Crucial to the present discussion, it has some components designed for linking it up with the CL code, which makes it possible for it to - provide an AVM display of any CL template (like (2) above, for (1)); - provide a basis for a rapid development of a parsing grammar for any language for which a c-profile has been created; 173 - provide an intermediate parsing facility for sentences of any language even when no grammar specific to the language has been created, as long as the language has been assigned a cprofile. We will refer to the ‘basic’ part of TypeGram as its Core. Relative to curr</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Ann Copestake. 2002. Implementing Typed Feature Structure Grammars. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Esther Kropp Dakubu</author>
</authors>
<title>The Construction label project: a tool for typological study. Presented at West African Languages Congress (WALC),</title>
<date>2008</date>
<location>Winneba,</location>
<contexts>
<context position="5946" citStr="Dakubu 2008" startWordPosition="1064" endWordPosition="1065">d on two typologically very diverse languages: Norwegian, and the West African language Ga. An overview of the system is given in (Hellan and Dakubu 2010). The end product of its application to a language is called a construction profile of the language, abbreviated its cprofile. This is an assembly of between 150 and 250 templates encoding the span of variation offered by the language in a fixed number of respects, in a code immediately comparable to cprofiles of other languages. A c-profile for both Ga and Norwegian is given in (Hellan and Dakubu op. cit.); see also (Hellan and Dakubu 2009, Dakubu 2008, Hellan 2008). The typical method of establishing c-profiles is through paradigm building, where, based on one sentence of the language, one establishes the various paradigms relative to which the sentence instantiates choices, and supplements these paradigms with paradigms spun out of other sentences or constructions, ultimately establishing a full network of construction types for the language relative to the discriminants selected. (‘Construction’ is here used in a theory neutral way.) The creation of c-profiles is obviously an incremental process, both in the building of templates instant</context>
</contexts>
<marker>Dakubu, 2008</marker>
<rawString>Mary Esther Kropp Dakubu,. 2008. The Construction label project: a tool for typological study. Presented at West African Languages Congress (WALC), Winneba, July 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Esther Kropp Dakubu</author>
</authors>
<title>Ga-English Dictionary.</title>
<date>2009</date>
<location>Accra.</location>
<contexts>
<context position="5933" citStr="Dakubu 2009" startWordPosition="1062" endWordPosition="1063">has been based on two typologically very diverse languages: Norwegian, and the West African language Ga. An overview of the system is given in (Hellan and Dakubu 2010). The end product of its application to a language is called a construction profile of the language, abbreviated its cprofile. This is an assembly of between 150 and 250 templates encoding the span of variation offered by the language in a fixed number of respects, in a code immediately comparable to cprofiles of other languages. A c-profile for both Ga and Norwegian is given in (Hellan and Dakubu op. cit.); see also (Hellan and Dakubu 2009, Dakubu 2008, Hellan 2008). The typical method of establishing c-profiles is through paradigm building, where, based on one sentence of the language, one establishes the various paradigms relative to which the sentence instantiates choices, and supplements these paradigms with paradigms spun out of other sentences or constructions, ultimately establishing a full network of construction types for the language relative to the discriminants selected. (‘Construction’ is here used in a theory neutral way.) The creation of c-profiles is obviously an incremental process, both in the building of temp</context>
<context position="12070" citStr="Dakubu 2009" startWordPosition="2070" endWordPosition="2071">re portrayed as contributing to its full AVM. The defining types in (6) are in turn defined in labeltypes, by definitions whose defining terms are in turn defined in the Core. With such type definitions in the background, the template v-ditr-obPostpsuAg_obEndpt_ob2Th-PLACEMENT is a type recognized in the grammar. Using the view type definition offered in a standard LKB interface, one sees the AVM assigned to this template. 3.2 Developing a parsing grammar Suppose that we want to develop a grammar of Ga – GaGram -, taking advantage of the type apparatus already described. (For Ga, the lexicon (Dakubu 2009) is partly informed by the cprofile and is a resource in building the lexicon of the grammar.) What is missing is defining a lexicon, inflectional rules, derivational rules and (4) c-profile of Ga Ga c-types c-profile of Norwegian Norw.c-typ Labeltypes c-profile of Kistaninya Kistane c-types Core 174 syntactic combinatorial rules. The latter is partly deducible from the constructional templates, and for templates which reflect verb subcategorization frames, lexical frame types are fairly directly derivable from the templates. What needs to be done in addition is specifying the lexical root ite</context>
</contexts>
<marker>Dakubu, 2009</marker>
<rawString>Mary Esther Kropp Dakubu. 2009. Ga-English Dictionary. Accra.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Hellan</author>
</authors>
<title>Enumerating Verb Constructions Cross-linguistically. COLING Workshop on Grammar Engineering Across frameworks.</title>
<date>2008</date>
<location>Manchester. http://www.aclweb.org/anthologynew/W/W08/#1700</location>
<contexts>
<context position="5960" citStr="Hellan 2008" startWordPosition="1066" endWordPosition="1067">logically very diverse languages: Norwegian, and the West African language Ga. An overview of the system is given in (Hellan and Dakubu 2010). The end product of its application to a language is called a construction profile of the language, abbreviated its cprofile. This is an assembly of between 150 and 250 templates encoding the span of variation offered by the language in a fixed number of respects, in a code immediately comparable to cprofiles of other languages. A c-profile for both Ga and Norwegian is given in (Hellan and Dakubu op. cit.); see also (Hellan and Dakubu 2009, Dakubu 2008, Hellan 2008). The typical method of establishing c-profiles is through paradigm building, where, based on one sentence of the language, one establishes the various paradigms relative to which the sentence instantiates choices, and supplements these paradigms with paradigms spun out of other sentences or constructions, ultimately establishing a full network of construction types for the language relative to the discriminants selected. (‘Construction’ is here used in a theory neutral way.) The creation of c-profiles is obviously an incremental process, both in the building of templates instantiating possibi</context>
</contexts>
<marker>Hellan, 2008</marker>
<rawString>Lars Hellan. 2008. Enumerating Verb Constructions Cross-linguistically. COLING Workshop on Grammar Engineering Across frameworks. Manchester. http://www.aclweb.org/anthologynew/W/W08/#1700</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Hellan</author>
<author>Mary Esther Kropp Dakubu</author>
</authors>
<title>A methodology for enhancing argument structure specification. In:</title>
<date>2009</date>
<booktitle>Proceedings from the 4th Language Technology Conference (LTC 2009),</booktitle>
<location>Poznan.</location>
<contexts>
<context position="5933" citStr="Hellan and Dakubu 2009" startWordPosition="1060" endWordPosition="1063">ing system has been based on two typologically very diverse languages: Norwegian, and the West African language Ga. An overview of the system is given in (Hellan and Dakubu 2010). The end product of its application to a language is called a construction profile of the language, abbreviated its cprofile. This is an assembly of between 150 and 250 templates encoding the span of variation offered by the language in a fixed number of respects, in a code immediately comparable to cprofiles of other languages. A c-profile for both Ga and Norwegian is given in (Hellan and Dakubu op. cit.); see also (Hellan and Dakubu 2009, Dakubu 2008, Hellan 2008). The typical method of establishing c-profiles is through paradigm building, where, based on one sentence of the language, one establishes the various paradigms relative to which the sentence instantiates choices, and supplements these paradigms with paradigms spun out of other sentences or constructions, ultimately establishing a full network of construction types for the language relative to the discriminants selected. (‘Construction’ is here used in a theory neutral way.) The creation of c-profiles is obviously an incremental process, both in the building of temp</context>
</contexts>
<marker>Hellan, Dakubu, 2009</marker>
<rawString>Lars Hellan and Mary Esther Kropp Dakubu. 2009: A methodology for enhancing argument structure specification. In: Proceedings from the 4th Language Technology Conference (LTC 2009), Poznan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Hellan</author>
<author>Mary Esther Kropp Dakubu</author>
</authors>
<title>Identifying Verb Constructions Crosslinguistically.</title>
<date>2010</date>
<booktitle>SLAVOB series, Univ. of Ghana (http://www.typecraft.org/w/images/d/db/1_Introla bels_SLAVOB-final.pdf, ian_Appendix_plus_3_SLAVOB-final.pdf )</booktitle>
<contexts>
<context position="5489" citStr="Hellan and Dakubu 2010" startWordPosition="978" endWordPosition="981">⎣ ⎦ ⎦ Thus, while the labels have a descriptive transparency essential to the descriptive functionality of the over-all code, this transparency can be ‘cashed out’ also in the definition of a linking between CL and grammar formalisms like that illustrated in (2) and (3). Section 3 describes a possible architecture for achieving this, centered around the computational grammar TypeGram. 2 Construction Labeling In its first development, the coding system has been based on two typologically very diverse languages: Norwegian, and the West African language Ga. An overview of the system is given in (Hellan and Dakubu 2010). The end product of its application to a language is called a construction profile of the language, abbreviated its cprofile. This is an assembly of between 150 and 250 templates encoding the span of variation offered by the language in a fixed number of respects, in a code immediately comparable to cprofiles of other languages. A c-profile for both Ga and Norwegian is given in (Hellan and Dakubu op. cit.); see also (Hellan and Dakubu 2009, Dakubu 2008, Hellan 2008). The typical method of establishing c-profiles is through paradigm building, where, based on one sentence of the language, one e</context>
</contexts>
<marker>Hellan, Dakubu, 2010</marker>
<rawString>Lars Hellan and Mary Esther Kropp Dakubu. 2010. Identifying Verb Constructions Crosslinguistically. SLAVOB series, Univ. of Ghana (http://www.typecraft.org/w/images/d/db/1_Introla bels_SLAVOB-final.pdf, ian_Appendix_plus_3_SLAVOB-final.pdf )</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>Chicago University Press.</publisher>
<contexts>
<context position="8759" citStr="Pollard and Sag 1994" startWordPosition="1516" endWordPosition="1519">he CL code, which makes it possible for it to - provide an AVM display of any CL template (like (2) above, for (1)); - provide a basis for a rapid development of a parsing grammar for any language for which a c-profile has been created; 173 - provide an intermediate parsing facility for sentences of any language even when no grammar specific to the language has been created, as long as the language has been assigned a cprofile. We will refer to the ‘basic’ part of TypeGram as its Core. Relative to current grammar formalisms using AVMs, such as LFG and HPSG (cf. Bresnan 2001, Butt et al. 1999, Pollard and Sag 1994), the TypeGram Core borrows from LFG an inventory of grammatical functions, and from HPSG the use of types, and a design by which all components of a grammar are encoded in AVMs. Unlike most computational grammars, the Core defines analyses for phenomena not restricted to one language, but for the union of all languages for which c-profiles have been defined. (In this respect it resembles the HPSG Grammar Matrix (‘the Matrix’ - see Bender et. al, and http://www.delph-in.net/matrix/ ); we comment on its relationship to this system below.) The mediation between the Core and the cprofiles is indu</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan Sag. 1994. Head-Driven Phrase Structure Grammar. Chicago University Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bedilu Debela Wakjira</author>
</authors>
<title>To appear. Kistaninya Verb Morphology and Verb Constructions. PhD dissertation.</title>
<publisher>NTNU.</publisher>
<marker>Wakjira, </marker>
<rawString>Bedilu Debela Wakjira. To appear. Kistaninya Verb Morphology and Verb Constructions. PhD dissertation. NTNU.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Some web</author>
</authors>
<title>sites: Leipzig glossing rules: http://www.eva.mpg.de/lingua/resources/glossingrules.php Construction Labeling site: http://www.typecraft.org/research/projects/Verbconstr uctions/</title>
<marker>web, </marker>
<rawString>Some web sites: Leipzig glossing rules: http://www.eva.mpg.de/lingua/resources/glossingrules.php Construction Labeling site: http://www.typecraft.org/research/projects/Verbconstr uctions/</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>