<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007793">
<title confidence="0.9894625">
Automatic Indexing of Specialized Documents:
Using Generic vs. Domain-Specific Document Representations
</title>
<note confidence="0.890875">
Aurélie Névéol James G. Mork Alan R. Aronson
{neveola,mork,alan}@nlm.nih.gov
National Library of Medicine
8600 Rockville Pike
Bethesda, MD 20894
USA
</note>
<sectionHeader confidence="0.987501" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999976333333333">
The shift from paper to electronic docu-
ments has caused the curation of informa-
tion sources in large electronic databases
to become more generalized. In the bio-
medical domain, continuing efforts aim at
refining indexing tools to assist with the
update and maintenance of databases such
as MEDLINE®. In this paper, we evaluate
two statistical methods of producing
MeSH® indexing recommendations for
the genetics literature, including recom-
mendations involving subheadings, which
is a novel application for the methods. We
show that a generic representation of the
documents yields both better precision
and recall. We also find that a domain-
specific representation of the documents
can contribute to enhancing recall.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999936285714286">
There are two major approaches for the automatic
indexing of text documents: statistical approaches
that rely on various word counting techniques [su-
ch as vector space models (Salton, 1989), Latent
Semantic Indexing (Deerwester et al., 1990) or
probabilistic models (Sparck-Jones et al., 2000)]
and linguistic approaches that involve syntactical
and lexical analysis [see for example term extrac-
tion and term variation recognition in systems such
as MetaMap (Aronson, 2001), FASTR (Jacquemin
and Tzoukermann, 1999) or IndDoc (Nazarenko
and Ait El Mekki, 2005)]. In many cases, the com-
bination of these approaches has been shown to
improve the performance of a single approach both
for controlled indexing (Aronson et al., 2004) and
free text indexing (Byrne and Klein, 2003).
Recently, Névéol et al. (2007) presented lin-
guistic approaches for the indexing of documents
in the field of genetics. In this paper, we explore a
statistical approach of indexing for text documents
also in the field of genetics. This approach was
previously used successfully to produce Medical
Subject Headings (MeSH) main heading recom-
mendations. Our goal in this experiment is two-
fold: first, extending an existing method to the pro-
duction of recommendations involving subhead-
ings and second, assessing the possible benefit of
using a domain-specific variant of the method.
</bodyText>
<sectionHeader confidence="0.989946" genericHeader="introduction">
2 A k-Nearest-Neighbors approach for
indexing
</sectionHeader>
<subsectionHeader confidence="0.983597">
2.1 Principle
</subsectionHeader>
<bodyText confidence="0.975629444444444">
The k-Nearest-Neighbors (k-NN) approach views
indexing as a multi-class classification problem
where a document may be assigned several
“classes” in the form of indexing terms. It requires
a large set of labeled data composed of previously
indexed documents. k-NN relies on the assumption
that similar documents should be classified in a
similar way. The algorithm consists of two steps:
1/documents that are most “similar” to the query
document must be retrieved from the set of labeled
documents. They are considered as “neighbors” for
the query document; 2/an indexing set must be
produced from these and assigned to the query
document.
Finding similar documents
All documents are represented using a vector of
distinctive features within the representation space.
Based on this representation, labeled documents
</bodyText>
<page confidence="0.988062">
183
</page>
<note confidence="0.742086">
BioNLP 2007: Biological, translational, and clinical language processing, pages 183–190,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999500125">
may be ranked according to their similarity to the
query document using usual similarity measures
such as cosine or Dice. The challenge in this step is
to define an appropriate representation space for
the documents and to select optimal features for
each document. Another issue is the number (k) of
neighbors that should be selected to use in the next
step.
</bodyText>
<subsectionHeader confidence="0.855737">
Producing an indexing set
</subsectionHeader>
<bodyText confidence="0.9999845">
When applied to a single-class classification prob-
lem, the class that is the most frequent among the k
neighbors is usually assigned to the query docu-
ment. Indexing is a multi-class problem for which
the number of classes a document should be as-
signed is not known, as it may vary from one
document to another. Therefore, indexing terms
from the neighbor documents are all taken into
account and ranked according to the number of
neighbors that were labeled with them. The more
neighbors labeled with a given indexing term, the
higher the confidence that it will be a relevant in-
dexing term for the query document. This resulting
indexing set may then be filtered to select only the
terms that were obtained from a defined minimum
number of neighbors.
</bodyText>
<subsectionHeader confidence="0.9992945">
2.2 Document representation
Generic representation
</subsectionHeader>
<bodyText confidence="0.999155263157895">
A generic representation of documents is obtained
from the text formed by the title and abstract. This
text is processed so that punctuation is removed,
stop-words from a pre-defined list (of 310 words)
are removed, remaining words are switched to
lower case and a minimal amount of stemming is
applied. As described by Salton (1989) words
should be weighted according to the number of
times they occur in the query document and the
number of times they occur in the whole collection
(here, MEDLINE). Moreover, words from the title
are given an additional weight compared to words
from the abstract. Further adjustments relative to
document length and local weighting according to
the Poisson distribution are detailed in (Aronson et
al, 2000; Kim et al., 2001) where the PubMed Re-
lated Citations (PRC) algorithm is discussed. Fur-
ther experiments showed that the best results were
obtained by using the ten nearest neighbors.
</bodyText>
<subsectionHeader confidence="0.837902">
Domain-specific representation
</subsectionHeader>
<bodyText confidence="0.999962954545454">
In specialized domains, documents from the litera-
ture may be represented with concepts or objects
commonly used or studied in the field. For exam-
ple, (Rhodes et al., 2007) meet specific chemistry
oriented search needs by representing US patents
and patent applications with molecular information
in the form of chemical terms and structures. A
similar representation is used for PubChem
(http://pubchem.ncbi.nlm.nih.gov/) records. In the
genetics domain, genes are among the most com-
monly discussed or manipulated concepts. There-
fore, genes should provide a relevant domain-
specific description of documents from the genet-
ics literature.
The second indexing algorithm that we describe
in this paper, know as the Gene Reference Into
Function (GeneRIF) Related Citations (GRC) algo-
rithm, uses “GeneRIF” links (defined in the para-
graph below) to retrieve neighbors for a query
document.
To form a specific representation of the docu-
ment, gene names are retrieved by ABGene1 (Ta-
nabe and Wilbur, 2002) and mapped to Entrez
Gene2 unique identifiers. The mapping was per-
formed with a version of SemRep (Rindflesch and
Fiszman, 2003) restricted to human genes. It con-
sists in normalizing the gene name (switch to lower
case, remove spaces and hyphens) and matching
the resulting string to one of the gene names or
aliases listed in Entrez Gene.
For each gene, the GeneRIF links supply a sub-
set of MEDLINE citations manually selected by
NLM indexers for describing the functions associ-
ated with the gene. These sets were used in two
ways:
To complete the document representation. If a
citation was included in the GeneRIF of a
given gene, the gene was given an additional
weight in the document representation.
To limit the set of possible neighbors. In the
generic representation, all MEDLINE cita-
tions contain the representation features,
words. Therefore, they all have to be con-
sidered as potential neighbors. However,
</bodyText>
<footnote confidence="0.99292625">
1 Software downloaded January 17, 2007, from
http://www.ncbi.nlm.nih.gov/staff/lsmith/MedPost.html
2 Retrieved January 17, 2007, from:
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene
</footnote>
<page confidence="0.997664">
184
</page>
<bodyText confidence="0.999794111111111">
only a subset of citations actually contains
genes. Therefore, only those citations need
to be considered as potential neighbors. This
observation enables us to limit the specific
processing to relevant citations. Possible
neighbors for a query document consist of
the union of the GeneRIF citations corre-
sponding to each gene in the document rep-
resentation.
</bodyText>
<tableCaption confidence="0.9961855">
Table 1: Gene description of a sample MEDLINE
document and its two nearest neighbors
</tableCaption>
<table confidence="0.998011272727273">
PubMed IDs ABGene Entrez Gene IDs
15645653 abcc6 368
mrp6 368; 6283
ldl-r 3949
pxe 368; 5823
fh 2271
10835643 mrp6 368; 6283
pxe 368; 5823
16392638 abcc6 368
mrp6 368; 6283
pxe 368; 5823
</table>
<bodyText confidence="0.997608">
For each query document, the set of possible
neighbors was processed and ranked according to
gene similarity using a cosine measure. Table 1
shows the description of a sample MEDLINE cita-
tion and its two nearest neighbors.
Based on experiments with the PubMed Related
Citations algorithm, ten neighbors were retained to
form a candidate set of indexing terms.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="method">
3 Experiment
</sectionHeader>
<subsectionHeader confidence="0.999971">
3.1 Application to MeSH indexing
</subsectionHeader>
<bodyText confidence="0.999990923076923">
In the MEDLINE database, publications of the bio-
medical domain are indexed with Medical Subject
Headings, or MeSH descriptors. MeSH contains
about 24,000 main headings denoting medical con-
cepts such as foot, bone neoplasm or appendec-
tomy. MeSH also contains 83 subheadings such as
genetics, metabolism or surgery that can be associ-
ated with the main headings in order to refer to a
specific aspect of the concept. Moreover, each de-
scriptor (a main heading alone or associated with
one or more subheadings) is assigned a “minor” or
“major” weight depending on how substantially the
concept it denotes is discussed in the article. “Ma-
jor” descriptors are marked with a star.
In order to form a candidate indexing set to be
assigned to a query document, the descriptors as-
signed to each of the neighbors were broken down
into a set of main headings and pairs (i.e. a main
heading associated with a single subheading). For
this experiment, indications of major terms were
ignored.
For example, the MeSH descriptor
*Myocardium/cytology/metabolism would gener-
ate the main heading Myocardium and the two
pairs Myocardium/cytology and Myocar-
dium/metabolism.
</bodyText>
<subsectionHeader confidence="0.9998">
3.2 Test Corpus
</subsectionHeader>
<bodyText confidence="0.999993833333333">
Both methods were tested on a corpus composed of
a selection of the 49,863 citations entered into
MEDLINE in January 2005. The 2006 version of
MeSH was used for the indexing in these citations.
About one fifth of the citations (10,161) are con-
sidered to be genetics-related, as determined by
Journal Descriptor Indexing (Humphrey, 1999).
Our test corpus was composed of genetics-related
citations from which Entrez Gene IDs could be
extracted – about 40% of the cases. The final test
corpus size was 3,962. Appendix A shows a sam-
ple citation from the corpus.
</bodyText>
<subsectionHeader confidence="0.991837">
3.3 Protocol
</subsectionHeader>
<bodyText confidence="0.999894157894737">
Figure 1 shows the setting of our experiment.
Documents from the test corpus described above
were processed to obtain both a generic and spe-
cific representation as described in section 2.2. The
corresponding ten nearest neighbors were retrieved
using the PRC and GRC algorithms. All the
neighbors’ MeSH descriptors were pooled to form
candidate indexing sets of descriptors that were
evaluated using precision and recall measures. Pre-
cision was the number of candidate descriptors that
were selected as indexing terms by NLM indexers
(according to reference MEDLINE indexing) over
the total number of candidate descriptors. Recall
was the number of candidate descriptors that were
selected as indexing terms by NLM indexers over
the total number of indexing terms expected (ac-
cording to reference MEDLINE indexing). For
better comparison between the methods, we also
computed F-measure giving equal weight to preci-
</bodyText>
<page confidence="0.995539">
185
</page>
<bodyText confidence="0.9960064">
sion and recall - F1=2*PR/(P+R) and giving a
higher weight to recall - F3=10*PR/(9P+R).
Four different categories of descriptors were
considered in the evaluation:
MH: MeSH main headings (regardless of
whether subheadings were attached in the
reference indexing)
SH: stand-alone subheadings (regardless of the
main heading(s) they were attached to in the
reference indexing)
MH/SH: main heading/subheading pairs
DESC: MeSH descriptors, i.e. main headings
and main heading/subheading pairs
Similarly, four different candidate indexing sets
were considered: the indexing set resulting from
PRC, the indexing set resulting from GRC, the in-
dexing set resulting from the pooling of PRC and
GRC sets and finally the indexing set resulting
from the intersection of PRC and GRC indexing
sets (common index terms).
</bodyText>
<figureCaption confidence="0.9628775">
Figure 1: Producing candidate indexing sets with
generic and domain-specific representations.
</figureCaption>
<sectionHeader confidence="0.999838" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.999931090909091">
Appendix B shows the indexing sets obtained from
the GRC and PRC algorithms for a sample citation
from the test corpus. Table 2 presents the results of
our experiments. For each category of descriptors,
the best performance was bolded. It can be ob-
served that in general, the best precision and F1
scores are obtained with the common indexing set,
the best recall is obtained with the pooling of in-
dexing sets and the best F3 score is obtained with
PRC algorithm, the pooling of indexing sets being
a close second.
</bodyText>
<sectionHeader confidence="0.999951" genericHeader="method">
5 Discussion
</sectionHeader>
<subsectionHeader confidence="0.99851">
5.1 Performance of the methods
</subsectionHeader>
<bodyText confidence="0.999913696969697">
As can be seen from the bolded figures in table 2,
the best performance is obtained either from the
PRC algorithm, or from a combination of PRC and
GRC. When indexing methods are combined, it is
usually expected that statistical methods will pro-
vide the best recall whereas linguistic methods will
provide the best precision. Combining complemen-
tary methods is then expected to provide the best
overall performance. In this context, it seems that
the option of pooling the indexing sets should be
retained for further experiments. The most signifi-
cant result of this study is that the pooling of meth-
ods achieves a recall of 92% for stand-alone
subheading retrieval. While the precision is only
19%, the selection of stand-alone subheadings of-
fered by our methods is nearly exhaustive and it
reduces by 70% the size of the list of allowable
subheadings that could potentially be used. NLM
indexers have declared this could prove very useful
to enhance their indexing practice.
In order to qualify the added value of the spe-
cific description, we looked at the descriptors that
were correctly recommended by GRC and not rec-
ommended by PRC. Check Tags (descriptors used
to denote the species, age and gender of the sub-
jects discussed in an article) seemed prominent, but
only Human was significantly recommended cor-
rectly more often than it was recommended incor-
rectly (~2.2 times more correct than incorrect
recommendations – 2,712 correct vs. 1,250 incor-
rect). No other descriptor could be identified as
being consistently recommended either correctly or
incorrectly.
</bodyText>
<figure confidence="0.998229956521739">
Generic
representation
Text Words
MEDLINE document
Specific
representation
Genes
GRC
indexing set
PRC
indexing set
PubMed
Related Citations
(PRC)
1- Find similar
documents
2- Use index terms
in similar
documents as
indexing candidates
GeneRIFs
Related Citations
(GRC)
</figure>
<page confidence="0.995694">
186
</page>
<bodyText confidence="0.999874714285714">
For both methods, filtering the indexing sets
according to the number of neighbors that lead to
include the indexing terms results in an increase of
precision and a loss of recall. The best trade-off
(measured by F1) is obtained when indexing terms
come from at least three neighbors (data not
shown).
</bodyText>
<subsectionHeader confidence="0.996403">
5.2 A scale of indexing performance
</subsectionHeader>
<bodyText confidence="0.9995934">
The problem with evaluating indexing is that,
although inter-indexer variability is reduced when
a controlled vocabulary is used, indexing is an
open cognitive task for which there is no unique
“right” solution.
</bodyText>
<tableCaption confidence="0.997332">
Table 2: performance of the indexing methods on the four categories of descriptors
</tableCaption>
<table confidence="0.999481166666667">
SH MH SH/MH DESC
P R F1 F3 P R F1 F3 P R F1 F3 P R F1 F3
GRC 21 72 32 58 8 49 14 32 3 23 6 14 6 38 10 25
PRC 27 88 41 72 13 61 22 45 8 56 15 36 11 59 18 41
Pool 19 92 32 67 9 82 16 44 5 62 9 29 7 74 13 38
Common 36 68 47 62 22 27 24 27 18 17 17 17 21 23 22 23
</table>
<bodyText confidence="0.999924163265306">
In practice, this means that there is no ideal
unique set of descriptors to use for the indexing
of a particular document. Therefore, when com-
paring an indexing set obtained automatically
(e.g. here with the PRC or GRC methods) to a
“gold standard” indexing set produced by a
trained indexer (e.g. here, NLM indexers) the
difference observed can be due to erroneous de-
scriptors produced by the automatic methods.
But it is also likely that the automatic methods
will produce terms that are semantically close to
what the human indexer selected or even rele-
vant terms that the human indexer considered or
forgot to select. While evaluation methods to
assess the semantic similarity between indexing
sets are investigated (Névéol et al. 2006), a con-
sistency study by Funk et al. (1983) can shade
some light on inter-indexer consistency in
MEDLINE and what range of performance may
be expected from automatic systems. In this
study, Hooper’s consistency (the average pro-
portion of terms in agreement between two in-
dexers) for stand-alone subheadings (SH) was
48.7%. It was 33.8% for pairs (MH/SH) and
48.2% for main headings (MH). In light of these
figures, although no direct comparison with the
results of our experiment is possible, the preci-
sion obtained from the common recommenda-
tions (especially for stand-alone subheadings,
36%) seems reasonably useful. Further more,
when informally presenting the indexers sample
recommendations obtained with these methods,
they expressed their interest in the high recall as
reviewing a larger selection of potentially useful
terms might help them track important descrip-
tors they may not have thought of using other-
wise.
In comparison with other research, the results
are also encouraging: the recall resulting from
either PRC or pooling the indexing sets is sig-
nificantly better than that obtained by Névéol et
al. (2007) on a larger set of MEDLINE 2005
citations – 20% at best for main head-
ing/subheading pairs with a dictionary-based
method which consisted in extracting main head-
ing and subheading separately from the citations
(using MTI and string matching dictionary en-
tries) before forming all the allowable pairs as
recommendations.
</bodyText>
<subsectionHeader confidence="0.999513">
5.3 Limitations of the experiment
</subsectionHeader>
<bodyText confidence="0.999802375">
In the specific description, the mapping between
gene names and Entrez Gene IDs only takes hu-
man genes into account, which potentially limits
the scope of the method, since many more or-
ganisms and their genes may be discussed in the
literature. In some cases, this limitation can lead
to confusion with other organisms. For example,
the gene EPO “erythropoietin” is listed in Entrez
Gene for 11 organisms including Homo Sapiens.
With our current algorithm, this gene will be
assumed to be a human gene. In the case of
PMID 15213094 in our test corpus, the organism
discussed in the paper was in fact Mus Musculus
(common mouse). In this particular case, the
check tag Humans, which was erroneous, could
be found in the candidate indexing set. However,
</bodyText>
<page confidence="0.995577">
187
</page>
<bodyText confidence="0.999662">
correct indexing terms could still be retrieved
due to the fact that both the human and mouse
gene share common functions.
Another limitation is the size of the test cor-
pus, which was limited to less than 4,000 docu-
ments.
</bodyText>
<subsectionHeader confidence="0.983189">
5.4 Mining the biomedical literature for
gene-concept links
</subsectionHeader>
<bodyText confidence="0.999938846153846">
Other approaches to gene-keyword mapping ex-
ploit the links between genes and diseases or
proteins as they are described either in the re-
cords of databases such as OMIM or more for-
mally expressed as in the GeneRIF. Substantial
work has addressed linking DNA microarray
data to keywords in controlled vocabulary such
as MeSH (Masys et al. 2001) or characterizing
gene clusters with text words from the literature
(Liu et al. 2004). However, no normalized “se-
mantic fingerprinting” has been yet produced
between controlled sets such as Entrez Gene and
MeSH terms.
</bodyText>
<sectionHeader confidence="0.97239" genericHeader="conclusions">
6 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999976863636364">
In this paper, we applied a statistical method for
indexing documents from the genetics literature.
We presented two different document represen-
tations, one generic and one specific to the ge-
netics domain. The results bear out our
expectations that such statistical methods can
also be used successfully to produce recommen-
dations involving subheadings. Furthermore,
they yield higher recall than other more linguis-
tic-based methods. In terms of recall, the best
results are obtained when the indexing sets from
both the specific and generic representations are
pooled.
In future work, we plan to refine the algorithm
based on the specific method by expending its
scope to other organisms than Homo Sapiens
and to take the gene frequency in the title and
abstract of documents into account for the repre-
sentation. Then, we shall conduct further evalua-
tions in order to observe the impact of these
changes, and to verify that similar results can be
obtained on a larger corpus.
</bodyText>
<sectionHeader confidence="0.992927" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999540818181818">
This research was supported in part by an ap-
pointment of A. Névéol to the Lister Hill Center
Fellows Program sponsored by the National Li-
brary of Medicine and administered by the Oak
Ridge Institute for Science and Education. The
authors would like to thank Halil Kilicoglu for
his help with obtaining Entrez Gene IDs from
the ABgene output. We also thank Susanne
Humphrey and Sonya Shooshan for their in-
sightful comments on the preparation and edit-
ing of this manuscript.
</bodyText>
<sectionHeader confidence="0.998518" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998932578947368">
Alan R. Aronson, Olivier Bodenreider, H. Florence
Chang, Susanne M. Humphrey, James G. Mork,
Stuart J. Nelson, Thomas C. Rindflesch and W.
John Wilbur. 2000. The NLM Indexing Initiative.
Proceedings of the Annual American Medical In-
formatics Association Symposium. (AMIA 2000):
17-21.
Alan R. Aronson. 2001. Effective mapping of bio-
medical text to the UMLS Metathesaurus: the
MetaMap program. Proceedings of the Annual
AMIA Symposium. (AMIA 2001):17-21.
Alan R. Aronson, James G. Mork, Cliff W. Gay, Su-
sanne M. Humphrey and William J. Rogers. 2004.
The NLM Indexing Initiative&apos;s Medical Text In-
dexer. Proceedings of Medinfo 2004: 268-72.
Kate Byrne and Ewan Klein. 2003. Image Retrieval
using Natural Language and Content-Based tech-
niques. In Arjen P. de Vries, ed. Proceedings of
the 4th Dutch-Belgian Information Retrieval
Workshop (DIR 2003):57-62.
Scott Deerwester, Susan Dumais, Georges Furnas,
Thomas Landauer and Richard Harshman. 1990.
Indexing by latent semantic analysis. Journal of
American Society for Information Science, 6
(41):391-407.
Mark E. Funk, Carolyn A. Reid and Leon S.
McGoogan. 1983. Indexing consistency in
MEDLINE. Bull. Med. Libr. Assoc. 71(2):176-
183.
Susanne M. Humphrey. 1999. Automatic indexing of
documents from journal descriptors: a preliminary
investigation. J Am Soc Inf Sci Technol. 50(8):661-
674
Christian Jacquemin and Evelyne Tzoukermann.
1999. NLP for term variant extraction: Synergy of
morphology, lexicon, and syntax. In T.
Strzalkowski (Ed.), Natural language information
retrieval (p. 25-74). Boston, MA: Kluwer.
</reference>
<page confidence="0.992223">
188
</page>
<reference confidence="0.997446229166667">
Won Kim, Alan R. Aronson and W. John Wilbur.
2001. Automatic MeSH term assignment and qual-
ity assessment. Proceedings of the Annual AMIA
Symposium: 319-23.
Ying Liu, Martin Brandon, Shamkant Navathe, Ray
Dingledine and Brian J. Ciliax. 2004. Text mining
functional keywords associated with genes. Pro-
ceedings of MEDINFO 2004: 292-296
Daniel R. Masys, John B. Welsh, J. Lynn Fink, Mi-
chael Gribskov, Igor Klacansky and Jacques Cor-
beil. 2001. Use of keyword hierarchies to interpret
gene expression patterns. In: Bioinformatics
17(4):319-326
Adeline Nazarenko and Touria Ait El Mekki 2005.
Building back-of-the-book indexes. In: Terminol-
ogy 11(1):199–224
Aurélie Névéol, Kelly Zeng, Olivier Bodenreider.
2006. Besides precision &amp; recall: Exploring alter-
native approaches to evaluating an automatic in-
dexing tool for MEDLINE. Proceedings of the
Annual AMIA Symposium: 589-93.
Aurélie Névéol, Sonya E. Shooshan, Susanne M.
Humphrey, Thomas C. Rindflesch and Alan R
Aronson. 2007. Multiple approaches to fine-
grained indexing of the biomedical literature. Pro-
ceedings of the 12th Pacific Symposium on Bio-
computing. 12:292-303
James Rhodes, Stephen Boyer, Jeffrey Kreulen, Ying
Chen, Patricia Ordonez. 2007. Mining Patents Us-
ing Molecular Similarity Search. Proceedings of
the 12th Pacific Symposium on Biocomputing.
12:304-315
Thomas C. Rindflesch and Marcelo Fiszman. 2003.
The interaction of domain knowledge and linguis-
tic structure in natural language processing: inter-
preting hypernymic propositions in biomedical
text. J Biomed Inform. 36(6), 462-77
Gerald Salton. 1989. Automatic text processing : The
transformation, analysis, and retrieval of informa-
tion by computer. Reading, MA : Addison-Wesley.
Karen Sparck-Jones, Steve Walker and Stephen E.
Robertson. 2000. A probalistic model of informa-
tion retrieval: development and comparative ex-
periments (part 1). Information Processing and
Management, 36(3):779-808.
Lorraine Tanabe and W. John Wilbur. 2002. Tagging
gene and protein names in biomedical text. Bioin-
formatics. 2002 Aug;18(8):1124-32.
</reference>
<sectionHeader confidence="0.910834" genericHeader="conclusions">
Appendix A: Title, abstract and reference indexing set for a sample citation
</sectionHeader>
<bodyText confidence="0.992641533333333">
PubMed ID 15645653
Title Identification of two novel missense mutations (p.R1221C and p.R1357W) in the ABCC6 (MRP6)
gene in a Japanese patient with pseudoxanthoma elasticum (PXE).
Abstract Pseudoxanthoma elasticum (PXE) is a rare, inherited, systemic disease of elastic tissue that in par-
ticular affects the skin, eyes, and cardiovascular system. Recently, the ABCC6 (MRP6) gene was
found to cause PXE. A defective type of ABCC6 gene (16pl3.1) was determined in two Japanese
patients with PXE. In order to determine whether these patients have a defect in ABCC6 gene, we
examined each of 31 exons and flanking intron sequences by PCR methods (SSCP screening and
direct sequencing). We found two novel missense variants in exon 26 and 29 in a compound het-
erozygous state in the first patient. One is a missense mutation (c.3661C&gt;T; p.R1221C) in exon 26
and the other is a missense mutation (c.4069C&gt;T; p.R1357W) in exon 29. These mutations have
not been detected in our control panel of 200 alleles. To our knowledge, this is the first report of
mutation identification in the ABCC6 gene in Japanese PXE patients. The second patient was ho-
mozygous for 2542_2543delG in ABCC6 gene and heterozygous for 6 kb deletion of LDL-R gene.
This case is the first report of a genetically confirmed case of double mutations both in PXE and
</bodyText>
<table confidence="0.8815266">
FH loci.
MeSH Adult
reference Aged
indexing set Female
Humans
Japan
Multidrug Resistance-Associated Proteins/*genetics
*Mutation, Missense
Pedigree
Pseudoxanthoma Elasticum/*genetics
</table>
<page confidence="0.938274">
189
</page>
<tableCaption confidence="0.44791">
Appendix B: Sample indexing sets obtained from the GRC and PRC algorithms for
a sample citation
</tableCaption>
<table confidence="0.810884878787879">
PubMed ID 15645653
GRC indexing Humans (10)
set* (top 15 terms)
Multidrug Resistance-Associated Proteins (9)
Mutation (8)
Male (7)
Female (7)
Multidrug Resistance-Associated Proteins/genetics (7)
Pseudoxanthoma Elasticum (6)
Pseudoxanthoma Elasticum/genetics (6)
Pedigree (5)
Exons (4)
DNA Mutational Analysis (4)
Mutation/genetics (4)
Adult (4)
Introns (3)
Aged (3)
PRC indexing Multidrug Resistance-Associated Proteins (10)
set* (top 15 terms)
Multidrug Resistance-Associated Proteins /genetics (10)
Pseudoxanthoma Elasticum (10)
Pseudoxanthoma Elasticum/genetics (10)
Mutation (7)
DNA Mutational Analysis (6)
Pedigree (5)
Genotype (4)
Polymorphism, Genetic (4)
Alleles (4)
Mutation/genetics (3)
Haplotypes (3)
Models, Genetic (3)
Gene Deletion (3)
Exons (3)
</table>
<footnote confidence="0.9607295">
* Terms appearing in the reference set are underlined; the number of neighbors – out of the 10 nearest neighbors –
labeled with each term is shown between brackets after the term.
</footnote>
<page confidence="0.991186">
190
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.901969">
<title confidence="0.99861">Automatic Indexing of Specialized Documents: Generic Document Representations</title>
<author confidence="0.993355">Aurélie Névéol James G Mork Alan R Aronson</author>
<email confidence="0.969438">neveola@nlm.nih.gov</email>
<email confidence="0.969438">mork@nlm.nih.gov</email>
<email confidence="0.969438">alan@nlm.nih.gov</email>
<affiliation confidence="0.960086">National Library of</affiliation>
<address confidence="0.996203333333333">8600 Rockville Bethesda, MD USA</address>
<abstract confidence="0.999297736842105">The shift from paper to electronic documents has caused the curation of information sources in large electronic databases to become more generalized. In the biomedical domain, continuing efforts aim at refining indexing tools to assist with the update and maintenance of databases such In this paper, we evaluate two statistical methods of producing indexing recommendations for the genetics literature, including recommendations involving subheadings, which is a novel application for the methods. We show that a generic representation of the documents yields both better precision and recall. We also find that a domainspecific representation of the documents can contribute to enhancing recall.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alan R Aronson</author>
<author>Olivier Bodenreider</author>
<author>H Florence Chang</author>
<author>Susanne M Humphrey</author>
<author>James G Mork</author>
<author>Stuart J Nelson</author>
<author>Thomas C Rindflesch</author>
<author>W John Wilbur</author>
</authors>
<date>2000</date>
<booktitle>The NLM Indexing Initiative. Proceedings of the Annual American Medical Informatics Association Symposium. (AMIA</booktitle>
<pages>17--21</pages>
<contexts>
<context position="5316" citStr="Aronson et al, 2000" startWordPosition="818" endWordPosition="821"> that punctuation is removed, stop-words from a pre-defined list (of 310 words) are removed, remaining words are switched to lower case and a minimal amount of stemming is applied. As described by Salton (1989) words should be weighted according to the number of times they occur in the query document and the number of times they occur in the whole collection (here, MEDLINE). Moreover, words from the title are given an additional weight compared to words from the abstract. Further adjustments relative to document length and local weighting according to the Poisson distribution are detailed in (Aronson et al, 2000; Kim et al., 2001) where the PubMed Related Citations (PRC) algorithm is discussed. Further experiments showed that the best results were obtained by using the ten nearest neighbors. Domain-specific representation In specialized domains, documents from the literature may be represented with concepts or objects commonly used or studied in the field. For example, (Rhodes et al., 2007) meet specific chemistry oriented search needs by representing US patents and patent applications with molecular information in the form of chemical terms and structures. A similar representation is used for PubChe</context>
</contexts>
<marker>Aronson, Bodenreider, Chang, Humphrey, Mork, Nelson, Rindflesch, Wilbur, 2000</marker>
<rawString>Alan R. Aronson, Olivier Bodenreider, H. Florence Chang, Susanne M. Humphrey, James G. Mork, Stuart J. Nelson, Thomas C. Rindflesch and W. John Wilbur. 2000. The NLM Indexing Initiative. Proceedings of the Annual American Medical Informatics Association Symposium. (AMIA 2000): 17-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan R Aronson</author>
</authors>
<title>Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program.</title>
<date>2001</date>
<booktitle>Proceedings of the Annual AMIA Symposium. (AMIA</booktitle>
<pages>2001--17</pages>
<contexts>
<context position="1467" citStr="Aronson, 2001" startWordPosition="210" endWordPosition="211"> precision and recall. We also find that a domainspecific representation of the documents can contribute to enhancing recall. 1 Introduction There are two major approaches for the automatic indexing of text documents: statistical approaches that rely on various word counting techniques [such as vector space models (Salton, 1989), Latent Semantic Indexing (Deerwester et al., 1990) or probabilistic models (Sparck-Jones et al., 2000)] and linguistic approaches that involve syntactical and lexical analysis [see for example term extraction and term variation recognition in systems such as MetaMap (Aronson, 2001), FASTR (Jacquemin and Tzoukermann, 1999) or IndDoc (Nazarenko and Ait El Mekki, 2005)]. In many cases, the combination of these approaches has been shown to improve the performance of a single approach both for controlled indexing (Aronson et al., 2004) and free text indexing (Byrne and Klein, 2003). Recently, Névéol et al. (2007) presented linguistic approaches for the indexing of documents in the field of genetics. In this paper, we explore a statistical approach of indexing for text documents also in the field of genetics. This approach was previously used successfully to produce Medical S</context>
</contexts>
<marker>Aronson, 2001</marker>
<rawString>Alan R. Aronson. 2001. Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program. Proceedings of the Annual AMIA Symposium. (AMIA 2001):17-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan R Aronson</author>
<author>James G Mork</author>
<author>Cliff W Gay</author>
<author>Susanne M Humphrey</author>
<author>William J Rogers</author>
</authors>
<title>The NLM Indexing Initiative&apos;s Medical Text Indexer.</title>
<date>2004</date>
<booktitle>Proceedings of Medinfo</booktitle>
<pages>268--72</pages>
<contexts>
<context position="1721" citStr="Aronson et al., 2004" startWordPosition="249" endWordPosition="252">ely on various word counting techniques [such as vector space models (Salton, 1989), Latent Semantic Indexing (Deerwester et al., 1990) or probabilistic models (Sparck-Jones et al., 2000)] and linguistic approaches that involve syntactical and lexical analysis [see for example term extraction and term variation recognition in systems such as MetaMap (Aronson, 2001), FASTR (Jacquemin and Tzoukermann, 1999) or IndDoc (Nazarenko and Ait El Mekki, 2005)]. In many cases, the combination of these approaches has been shown to improve the performance of a single approach both for controlled indexing (Aronson et al., 2004) and free text indexing (Byrne and Klein, 2003). Recently, Névéol et al. (2007) presented linguistic approaches for the indexing of documents in the field of genetics. In this paper, we explore a statistical approach of indexing for text documents also in the field of genetics. This approach was previously used successfully to produce Medical Subject Headings (MeSH) main heading recommendations. Our goal in this experiment is twofold: first, extending an existing method to the production of recommendations involving subheadings and second, assessing the possible benefit of using a domain-speci</context>
</contexts>
<marker>Aronson, Mork, Gay, Humphrey, Rogers, 2004</marker>
<rawString>Alan R. Aronson, James G. Mork, Cliff W. Gay, Susanne M. Humphrey and William J. Rogers. 2004. The NLM Indexing Initiative&apos;s Medical Text Indexer. Proceedings of Medinfo 2004: 268-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kate Byrne</author>
<author>Ewan Klein</author>
</authors>
<title>Image Retrieval using Natural Language and Content-Based techniques.</title>
<date>2003</date>
<booktitle>In Arjen P. de Vries, ed. Proceedings of the 4th Dutch-Belgian Information Retrieval Workshop (DIR</booktitle>
<pages>2003--57</pages>
<contexts>
<context position="1768" citStr="Byrne and Klein, 2003" startWordPosition="257" endWordPosition="260">as vector space models (Salton, 1989), Latent Semantic Indexing (Deerwester et al., 1990) or probabilistic models (Sparck-Jones et al., 2000)] and linguistic approaches that involve syntactical and lexical analysis [see for example term extraction and term variation recognition in systems such as MetaMap (Aronson, 2001), FASTR (Jacquemin and Tzoukermann, 1999) or IndDoc (Nazarenko and Ait El Mekki, 2005)]. In many cases, the combination of these approaches has been shown to improve the performance of a single approach both for controlled indexing (Aronson et al., 2004) and free text indexing (Byrne and Klein, 2003). Recently, Névéol et al. (2007) presented linguistic approaches for the indexing of documents in the field of genetics. In this paper, we explore a statistical approach of indexing for text documents also in the field of genetics. This approach was previously used successfully to produce Medical Subject Headings (MeSH) main heading recommendations. Our goal in this experiment is twofold: first, extending an existing method to the production of recommendations involving subheadings and second, assessing the possible benefit of using a domain-specific variant of the method. 2 A k-Nearest-Neighb</context>
</contexts>
<marker>Byrne, Klein, 2003</marker>
<rawString>Kate Byrne and Ewan Klein. 2003. Image Retrieval using Natural Language and Content-Based techniques. In Arjen P. de Vries, ed. Proceedings of the 4th Dutch-Belgian Information Retrieval Workshop (DIR 2003):57-62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan Dumais</author>
<author>Georges Furnas</author>
<author>Thomas Landauer</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of American Society for Information Science,</journal>
<volume>6</volume>
<pages>41--391</pages>
<contexts>
<context position="1235" citStr="Deerwester et al., 1990" startWordPosition="175" endWordPosition="178"> of producing MeSH® indexing recommendations for the genetics literature, including recommendations involving subheadings, which is a novel application for the methods. We show that a generic representation of the documents yields both better precision and recall. We also find that a domainspecific representation of the documents can contribute to enhancing recall. 1 Introduction There are two major approaches for the automatic indexing of text documents: statistical approaches that rely on various word counting techniques [such as vector space models (Salton, 1989), Latent Semantic Indexing (Deerwester et al., 1990) or probabilistic models (Sparck-Jones et al., 2000)] and linguistic approaches that involve syntactical and lexical analysis [see for example term extraction and term variation recognition in systems such as MetaMap (Aronson, 2001), FASTR (Jacquemin and Tzoukermann, 1999) or IndDoc (Nazarenko and Ait El Mekki, 2005)]. In many cases, the combination of these approaches has been shown to improve the performance of a single approach both for controlled indexing (Aronson et al., 2004) and free text indexing (Byrne and Klein, 2003). Recently, Névéol et al. (2007) presented linguistic approaches fo</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Scott Deerwester, Susan Dumais, Georges Furnas, Thomas Landauer and Richard Harshman. 1990. Indexing by latent semantic analysis. Journal of American Society for Information Science, 6 (41):391-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark E Funk</author>
<author>Carolyn A Reid</author>
<author>Leon S McGoogan</author>
</authors>
<date>1983</date>
<journal>Indexing consistency in MEDLINE. Bull. Med. Libr. Assoc.</journal>
<pages>71--2</pages>
<contexts>
<context position="16314" citStr="Funk et al. (1983)" startWordPosition="2610" endWordPosition="2613">obtained automatically (e.g. here with the PRC or GRC methods) to a “gold standard” indexing set produced by a trained indexer (e.g. here, NLM indexers) the difference observed can be due to erroneous descriptors produced by the automatic methods. But it is also likely that the automatic methods will produce terms that are semantically close to what the human indexer selected or even relevant terms that the human indexer considered or forgot to select. While evaluation methods to assess the semantic similarity between indexing sets are investigated (Névéol et al. 2006), a consistency study by Funk et al. (1983) can shade some light on inter-indexer consistency in MEDLINE and what range of performance may be expected from automatic systems. In this study, Hooper’s consistency (the average proportion of terms in agreement between two indexers) for stand-alone subheadings (SH) was 48.7%. It was 33.8% for pairs (MH/SH) and 48.2% for main headings (MH). In light of these figures, although no direct comparison with the results of our experiment is possible, the precision obtained from the common recommendations (especially for stand-alone subheadings, 36%) seems reasonably useful. Further more, when infor</context>
</contexts>
<marker>Funk, Reid, McGoogan, 1983</marker>
<rawString>Mark E. Funk, Carolyn A. Reid and Leon S. McGoogan. 1983. Indexing consistency in MEDLINE. Bull. Med. Libr. Assoc. 71(2):176-183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susanne M Humphrey</author>
</authors>
<title>Automatic indexing of documents from journal descriptors: a preliminary investigation.</title>
<date>1999</date>
<journal>J Am Soc Inf Sci Technol.</journal>
<pages>50--8</pages>
<contexts>
<context position="10176" citStr="Humphrey, 1999" startWordPosition="1585" endWordPosition="1586"> with a single subheading). For this experiment, indications of major terms were ignored. For example, the MeSH descriptor *Myocardium/cytology/metabolism would generate the main heading Myocardium and the two pairs Myocardium/cytology and Myocardium/metabolism. 3.2 Test Corpus Both methods were tested on a corpus composed of a selection of the 49,863 citations entered into MEDLINE in January 2005. The 2006 version of MeSH was used for the indexing in these citations. About one fifth of the citations (10,161) are considered to be genetics-related, as determined by Journal Descriptor Indexing (Humphrey, 1999). Our test corpus was composed of genetics-related citations from which Entrez Gene IDs could be extracted – about 40% of the cases. The final test corpus size was 3,962. Appendix A shows a sample citation from the corpus. 3.3 Protocol Figure 1 shows the setting of our experiment. Documents from the test corpus described above were processed to obtain both a generic and specific representation as described in section 2.2. The corresponding ten nearest neighbors were retrieved using the PRC and GRC algorithms. All the neighbors’ MeSH descriptors were pooled to form candidate indexing sets of de</context>
</contexts>
<marker>Humphrey, 1999</marker>
<rawString>Susanne M. Humphrey. 1999. Automatic indexing of documents from journal descriptors: a preliminary investigation. J Am Soc Inf Sci Technol. 50(8):661-674</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
<author>Evelyne Tzoukermann</author>
</authors>
<title>NLP for term variant extraction: Synergy of morphology, lexicon, and syntax.</title>
<date>1999</date>
<booktitle>In T. Strzalkowski (Ed.), Natural language information retrieval (p.</booktitle>
<pages>25--74</pages>
<publisher>Kluwer.</publisher>
<location>Boston, MA:</location>
<contexts>
<context position="1508" citStr="Jacquemin and Tzoukermann, 1999" startWordPosition="213" endWordPosition="216">We also find that a domainspecific representation of the documents can contribute to enhancing recall. 1 Introduction There are two major approaches for the automatic indexing of text documents: statistical approaches that rely on various word counting techniques [such as vector space models (Salton, 1989), Latent Semantic Indexing (Deerwester et al., 1990) or probabilistic models (Sparck-Jones et al., 2000)] and linguistic approaches that involve syntactical and lexical analysis [see for example term extraction and term variation recognition in systems such as MetaMap (Aronson, 2001), FASTR (Jacquemin and Tzoukermann, 1999) or IndDoc (Nazarenko and Ait El Mekki, 2005)]. In many cases, the combination of these approaches has been shown to improve the performance of a single approach both for controlled indexing (Aronson et al., 2004) and free text indexing (Byrne and Klein, 2003). Recently, Névéol et al. (2007) presented linguistic approaches for the indexing of documents in the field of genetics. In this paper, we explore a statistical approach of indexing for text documents also in the field of genetics. This approach was previously used successfully to produce Medical Subject Headings (MeSH) main heading recom</context>
</contexts>
<marker>Jacquemin, Tzoukermann, 1999</marker>
<rawString>Christian Jacquemin and Evelyne Tzoukermann. 1999. NLP for term variant extraction: Synergy of morphology, lexicon, and syntax. In T. Strzalkowski (Ed.), Natural language information retrieval (p. 25-74). Boston, MA: Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Won Kim</author>
<author>Alan R Aronson</author>
<author>W John Wilbur</author>
</authors>
<title>Automatic MeSH term assignment and quality assessment.</title>
<date>2001</date>
<booktitle>Proceedings of the Annual AMIA Symposium:</booktitle>
<pages>319--23</pages>
<contexts>
<context position="5335" citStr="Kim et al., 2001" startWordPosition="822" endWordPosition="825">removed, stop-words from a pre-defined list (of 310 words) are removed, remaining words are switched to lower case and a minimal amount of stemming is applied. As described by Salton (1989) words should be weighted according to the number of times they occur in the query document and the number of times they occur in the whole collection (here, MEDLINE). Moreover, words from the title are given an additional weight compared to words from the abstract. Further adjustments relative to document length and local weighting according to the Poisson distribution are detailed in (Aronson et al, 2000; Kim et al., 2001) where the PubMed Related Citations (PRC) algorithm is discussed. Further experiments showed that the best results were obtained by using the ten nearest neighbors. Domain-specific representation In specialized domains, documents from the literature may be represented with concepts or objects commonly used or studied in the field. For example, (Rhodes et al., 2007) meet specific chemistry oriented search needs by representing US patents and patent applications with molecular information in the form of chemical terms and structures. A similar representation is used for PubChem (http://pubchem.n</context>
</contexts>
<marker>Kim, Aronson, Wilbur, 2001</marker>
<rawString>Won Kim, Alan R. Aronson and W. John Wilbur. 2001. Automatic MeSH term assignment and quality assessment. Proceedings of the Annual AMIA Symposium: 319-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Liu</author>
<author>Martin Brandon</author>
<author>Shamkant Navathe</author>
<author>Ray Dingledine</author>
<author>Brian J Ciliax</author>
</authors>
<title>Text mining functional keywords associated with genes.</title>
<date>2004</date>
<booktitle>Proceedings of MEDINFO</booktitle>
<pages>292--296</pages>
<contexts>
<context position="19216" citStr="Liu et al. 2004" startWordPosition="3082" endWordPosition="3085">gene share common functions. Another limitation is the size of the test corpus, which was limited to less than 4,000 documents. 5.4 Mining the biomedical literature for gene-concept links Other approaches to gene-keyword mapping exploit the links between genes and diseases or proteins as they are described either in the records of databases such as OMIM or more formally expressed as in the GeneRIF. Substantial work has addressed linking DNA microarray data to keywords in controlled vocabulary such as MeSH (Masys et al. 2001) or characterizing gene clusters with text words from the literature (Liu et al. 2004). However, no normalized “semantic fingerprinting” has been yet produced between controlled sets such as Entrez Gene and MeSH terms. 6 Conclusion and future work In this paper, we applied a statistical method for indexing documents from the genetics literature. We presented two different document representations, one generic and one specific to the genetics domain. The results bear out our expectations that such statistical methods can also be used successfully to produce recommendations involving subheadings. Furthermore, they yield higher recall than other more linguistic-based methods. In t</context>
</contexts>
<marker>Liu, Brandon, Navathe, Dingledine, Ciliax, 2004</marker>
<rawString>Ying Liu, Martin Brandon, Shamkant Navathe, Ray Dingledine and Brian J. Ciliax. 2004. Text mining functional keywords associated with genes. Proceedings of MEDINFO 2004: 292-296</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel R Masys</author>
<author>John B Welsh</author>
<author>J Lynn Fink</author>
<author>Michael Gribskov</author>
<author>Igor Klacansky</author>
<author>Jacques Corbeil</author>
</authors>
<title>Use of keyword hierarchies to interpret gene expression patterns. In:</title>
<date>2001</date>
<journal>Bioinformatics</journal>
<pages>17--4</pages>
<contexts>
<context position="19130" citStr="Masys et al. 2001" startWordPosition="3068" endWordPosition="3071">t indexing terms could still be retrieved due to the fact that both the human and mouse gene share common functions. Another limitation is the size of the test corpus, which was limited to less than 4,000 documents. 5.4 Mining the biomedical literature for gene-concept links Other approaches to gene-keyword mapping exploit the links between genes and diseases or proteins as they are described either in the records of databases such as OMIM or more formally expressed as in the GeneRIF. Substantial work has addressed linking DNA microarray data to keywords in controlled vocabulary such as MeSH (Masys et al. 2001) or characterizing gene clusters with text words from the literature (Liu et al. 2004). However, no normalized “semantic fingerprinting” has been yet produced between controlled sets such as Entrez Gene and MeSH terms. 6 Conclusion and future work In this paper, we applied a statistical method for indexing documents from the genetics literature. We presented two different document representations, one generic and one specific to the genetics domain. The results bear out our expectations that such statistical methods can also be used successfully to produce recommendations involving subheadings</context>
</contexts>
<marker>Masys, Welsh, Fink, Gribskov, Klacansky, Corbeil, 2001</marker>
<rawString>Daniel R. Masys, John B. Welsh, J. Lynn Fink, Michael Gribskov, Igor Klacansky and Jacques Corbeil. 2001. Use of keyword hierarchies to interpret gene expression patterns. In: Bioinformatics 17(4):319-326</rawString>
</citation>
<citation valid="true">
<title>Adeline Nazarenko and Touria Ait El Mekki</title>
<date>2005</date>
<journal>In: Terminology</journal>
<volume>11</volume>
<issue>1</issue>
<marker>2005</marker>
<rawString>Adeline Nazarenko and Touria Ait El Mekki 2005. Building back-of-the-book indexes. In: Terminology 11(1):199–224</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aurélie Névéol</author>
<author>Kelly Zeng</author>
<author>Olivier Bodenreider</author>
</authors>
<title>Besides precision &amp; recall: Exploring alternative approaches to evaluating an automatic indexing tool for MEDLINE.</title>
<date>2006</date>
<booktitle>Proceedings of the Annual AMIA Symposium:</booktitle>
<pages>589--93</pages>
<contexts>
<context position="16271" citStr="Névéol et al. 2006" startWordPosition="2601" endWordPosition="2604">. Therefore, when comparing an indexing set obtained automatically (e.g. here with the PRC or GRC methods) to a “gold standard” indexing set produced by a trained indexer (e.g. here, NLM indexers) the difference observed can be due to erroneous descriptors produced by the automatic methods. But it is also likely that the automatic methods will produce terms that are semantically close to what the human indexer selected or even relevant terms that the human indexer considered or forgot to select. While evaluation methods to assess the semantic similarity between indexing sets are investigated (Névéol et al. 2006), a consistency study by Funk et al. (1983) can shade some light on inter-indexer consistency in MEDLINE and what range of performance may be expected from automatic systems. In this study, Hooper’s consistency (the average proportion of terms in agreement between two indexers) for stand-alone subheadings (SH) was 48.7%. It was 33.8% for pairs (MH/SH) and 48.2% for main headings (MH). In light of these figures, although no direct comparison with the results of our experiment is possible, the precision obtained from the common recommendations (especially for stand-alone subheadings, 36%) seems </context>
</contexts>
<marker>Névéol, Zeng, Bodenreider, 2006</marker>
<rawString>Aurélie Névéol, Kelly Zeng, Olivier Bodenreider. 2006. Besides precision &amp; recall: Exploring alternative approaches to evaluating an automatic indexing tool for MEDLINE. Proceedings of the Annual AMIA Symposium: 589-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aurélie Névéol</author>
<author>Sonya E Shooshan</author>
<author>Susanne M Humphrey</author>
<author>Thomas C Rindflesch</author>
<author>Alan R Aronson</author>
</authors>
<title>Multiple approaches to finegrained indexing of the biomedical literature.</title>
<date>2007</date>
<booktitle>Proceedings of the 12th Pacific Symposium on Biocomputing.</booktitle>
<pages>12--292</pages>
<contexts>
<context position="1800" citStr="Névéol et al. (2007)" startWordPosition="262" endWordPosition="265">89), Latent Semantic Indexing (Deerwester et al., 1990) or probabilistic models (Sparck-Jones et al., 2000)] and linguistic approaches that involve syntactical and lexical analysis [see for example term extraction and term variation recognition in systems such as MetaMap (Aronson, 2001), FASTR (Jacquemin and Tzoukermann, 1999) or IndDoc (Nazarenko and Ait El Mekki, 2005)]. In many cases, the combination of these approaches has been shown to improve the performance of a single approach both for controlled indexing (Aronson et al., 2004) and free text indexing (Byrne and Klein, 2003). Recently, Névéol et al. (2007) presented linguistic approaches for the indexing of documents in the field of genetics. In this paper, we explore a statistical approach of indexing for text documents also in the field of genetics. This approach was previously used successfully to produce Medical Subject Headings (MeSH) main heading recommendations. Our goal in this experiment is twofold: first, extending an existing method to the production of recommendations involving subheadings and second, assessing the possible benefit of using a domain-specific variant of the method. 2 A k-Nearest-Neighbors approach for indexing 2.1 Pr</context>
<context position="17396" citStr="Névéol et al. (2007)" startWordPosition="2778" endWordPosition="2781">n obtained from the common recommendations (especially for stand-alone subheadings, 36%) seems reasonably useful. Further more, when informally presenting the indexers sample recommendations obtained with these methods, they expressed their interest in the high recall as reviewing a larger selection of potentially useful terms might help them track important descriptors they may not have thought of using otherwise. In comparison with other research, the results are also encouraging: the recall resulting from either PRC or pooling the indexing sets is significantly better than that obtained by Névéol et al. (2007) on a larger set of MEDLINE 2005 citations – 20% at best for main heading/subheading pairs with a dictionary-based method which consisted in extracting main heading and subheading separately from the citations (using MTI and string matching dictionary entries) before forming all the allowable pairs as recommendations. 5.3 Limitations of the experiment In the specific description, the mapping between gene names and Entrez Gene IDs only takes human genes into account, which potentially limits the scope of the method, since many more organisms and their genes may be discussed in the literature. I</context>
</contexts>
<marker>Névéol, Shooshan, Humphrey, Rindflesch, Aronson, 2007</marker>
<rawString>Aurélie Névéol, Sonya E. Shooshan, Susanne M. Humphrey, Thomas C. Rindflesch and Alan R Aronson. 2007. Multiple approaches to finegrained indexing of the biomedical literature. Proceedings of the 12th Pacific Symposium on Biocomputing. 12:292-303</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Rhodes</author>
<author>Stephen Boyer</author>
<author>Jeffrey Kreulen</author>
<author>Ying Chen</author>
<author>Patricia Ordonez</author>
</authors>
<title>Mining Patents Using Molecular Similarity Search.</title>
<date>2007</date>
<booktitle>Proceedings of the 12th Pacific Symposium on Biocomputing.</booktitle>
<pages>12--304</pages>
<contexts>
<context position="5702" citStr="Rhodes et al., 2007" startWordPosition="879" endWordPosition="882">r, words from the title are given an additional weight compared to words from the abstract. Further adjustments relative to document length and local weighting according to the Poisson distribution are detailed in (Aronson et al, 2000; Kim et al., 2001) where the PubMed Related Citations (PRC) algorithm is discussed. Further experiments showed that the best results were obtained by using the ten nearest neighbors. Domain-specific representation In specialized domains, documents from the literature may be represented with concepts or objects commonly used or studied in the field. For example, (Rhodes et al., 2007) meet specific chemistry oriented search needs by representing US patents and patent applications with molecular information in the form of chemical terms and structures. A similar representation is used for PubChem (http://pubchem.ncbi.nlm.nih.gov/) records. In the genetics domain, genes are among the most commonly discussed or manipulated concepts. Therefore, genes should provide a relevant domainspecific description of documents from the genetics literature. The second indexing algorithm that we describe in this paper, know as the Gene Reference Into Function (GeneRIF) Related Citations (GR</context>
</contexts>
<marker>Rhodes, Boyer, Kreulen, Chen, Ordonez, 2007</marker>
<rawString>James Rhodes, Stephen Boyer, Jeffrey Kreulen, Ying Chen, Patricia Ordonez. 2007. Mining Patents Using Molecular Similarity Search. Proceedings of the 12th Pacific Symposium on Biocomputing. 12:304-315</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas C Rindflesch</author>
<author>Marcelo Fiszman</author>
</authors>
<title>The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text.</title>
<date>2003</date>
<journal>J Biomed Inform.</journal>
<volume>36</volume>
<issue>6</issue>
<pages>462--77</pages>
<contexts>
<context position="6655" citStr="Rindflesch and Fiszman, 2003" startWordPosition="1024" endWordPosition="1027">sed or manipulated concepts. Therefore, genes should provide a relevant domainspecific description of documents from the genetics literature. The second indexing algorithm that we describe in this paper, know as the Gene Reference Into Function (GeneRIF) Related Citations (GRC) algorithm, uses “GeneRIF” links (defined in the paragraph below) to retrieve neighbors for a query document. To form a specific representation of the document, gene names are retrieved by ABGene1 (Tanabe and Wilbur, 2002) and mapped to Entrez Gene2 unique identifiers. The mapping was performed with a version of SemRep (Rindflesch and Fiszman, 2003) restricted to human genes. It consists in normalizing the gene name (switch to lower case, remove spaces and hyphens) and matching the resulting string to one of the gene names or aliases listed in Entrez Gene. For each gene, the GeneRIF links supply a subset of MEDLINE citations manually selected by NLM indexers for describing the functions associated with the gene. These sets were used in two ways: To complete the document representation. If a citation was included in the GeneRIF of a given gene, the gene was given an additional weight in the document representation. To limit the set of pos</context>
</contexts>
<marker>Rindflesch, Fiszman, 2003</marker>
<rawString>Thomas C. Rindflesch and Marcelo Fiszman. 2003. The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text. J Biomed Inform. 36(6), 462-77</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Salton</author>
</authors>
<title>Automatic text processing : The transformation, analysis, and retrieval of information by computer.</title>
<date>1989</date>
<publisher>Addison-Wesley.</publisher>
<location>Reading, MA :</location>
<contexts>
<context position="1183" citStr="Salton, 1989" startWordPosition="170" endWordPosition="171">aper, we evaluate two statistical methods of producing MeSH® indexing recommendations for the genetics literature, including recommendations involving subheadings, which is a novel application for the methods. We show that a generic representation of the documents yields both better precision and recall. We also find that a domainspecific representation of the documents can contribute to enhancing recall. 1 Introduction There are two major approaches for the automatic indexing of text documents: statistical approaches that rely on various word counting techniques [such as vector space models (Salton, 1989), Latent Semantic Indexing (Deerwester et al., 1990) or probabilistic models (Sparck-Jones et al., 2000)] and linguistic approaches that involve syntactical and lexical analysis [see for example term extraction and term variation recognition in systems such as MetaMap (Aronson, 2001), FASTR (Jacquemin and Tzoukermann, 1999) or IndDoc (Nazarenko and Ait El Mekki, 2005)]. In many cases, the combination of these approaches has been shown to improve the performance of a single approach both for controlled indexing (Aronson et al., 2004) and free text indexing (Byrne and Klein, 2003). Recently, Név</context>
<context position="4907" citStr="Salton (1989)" startWordPosition="754" endWordPosition="755"> the higher the confidence that it will be a relevant indexing term for the query document. This resulting indexing set may then be filtered to select only the terms that were obtained from a defined minimum number of neighbors. 2.2 Document representation Generic representation A generic representation of documents is obtained from the text formed by the title and abstract. This text is processed so that punctuation is removed, stop-words from a pre-defined list (of 310 words) are removed, remaining words are switched to lower case and a minimal amount of stemming is applied. As described by Salton (1989) words should be weighted according to the number of times they occur in the query document and the number of times they occur in the whole collection (here, MEDLINE). Moreover, words from the title are given an additional weight compared to words from the abstract. Further adjustments relative to document length and local weighting according to the Poisson distribution are detailed in (Aronson et al, 2000; Kim et al., 2001) where the PubMed Related Citations (PRC) algorithm is discussed. Further experiments showed that the best results were obtained by using the ten nearest neighbors. Domain-</context>
</contexts>
<marker>Salton, 1989</marker>
<rawString>Gerald Salton. 1989. Automatic text processing : The transformation, analysis, and retrieval of information by computer. Reading, MA : Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Sparck-Jones</author>
<author>Steve Walker</author>
<author>Stephen E Robertson</author>
</authors>
<title>A probalistic model of information retrieval: development and comparative experiments (part 1).</title>
<date>2000</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>36--3</pages>
<contexts>
<context position="1287" citStr="Sparck-Jones et al., 2000" startWordPosition="182" endWordPosition="185">he genetics literature, including recommendations involving subheadings, which is a novel application for the methods. We show that a generic representation of the documents yields both better precision and recall. We also find that a domainspecific representation of the documents can contribute to enhancing recall. 1 Introduction There are two major approaches for the automatic indexing of text documents: statistical approaches that rely on various word counting techniques [such as vector space models (Salton, 1989), Latent Semantic Indexing (Deerwester et al., 1990) or probabilistic models (Sparck-Jones et al., 2000)] and linguistic approaches that involve syntactical and lexical analysis [see for example term extraction and term variation recognition in systems such as MetaMap (Aronson, 2001), FASTR (Jacquemin and Tzoukermann, 1999) or IndDoc (Nazarenko and Ait El Mekki, 2005)]. In many cases, the combination of these approaches has been shown to improve the performance of a single approach both for controlled indexing (Aronson et al., 2004) and free text indexing (Byrne and Klein, 2003). Recently, Névéol et al. (2007) presented linguistic approaches for the indexing of documents in the field of genetics</context>
</contexts>
<marker>Sparck-Jones, Walker, Robertson, 2000</marker>
<rawString>Karen Sparck-Jones, Steve Walker and Stephen E. Robertson. 2000. A probalistic model of information retrieval: development and comparative experiments (part 1). Information Processing and Management, 36(3):779-808.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorraine Tanabe</author>
<author>W John Wilbur</author>
</authors>
<title>Tagging gene and protein names in biomedical text. Bioinformatics.</title>
<date>2002</date>
<pages>18--8</pages>
<contexts>
<context position="6526" citStr="Tanabe and Wilbur, 2002" startWordPosition="1002" endWordPosition="1006">sed for PubChem (http://pubchem.ncbi.nlm.nih.gov/) records. In the genetics domain, genes are among the most commonly discussed or manipulated concepts. Therefore, genes should provide a relevant domainspecific description of documents from the genetics literature. The second indexing algorithm that we describe in this paper, know as the Gene Reference Into Function (GeneRIF) Related Citations (GRC) algorithm, uses “GeneRIF” links (defined in the paragraph below) to retrieve neighbors for a query document. To form a specific representation of the document, gene names are retrieved by ABGene1 (Tanabe and Wilbur, 2002) and mapped to Entrez Gene2 unique identifiers. The mapping was performed with a version of SemRep (Rindflesch and Fiszman, 2003) restricted to human genes. It consists in normalizing the gene name (switch to lower case, remove spaces and hyphens) and matching the resulting string to one of the gene names or aliases listed in Entrez Gene. For each gene, the GeneRIF links supply a subset of MEDLINE citations manually selected by NLM indexers for describing the functions associated with the gene. These sets were used in two ways: To complete the document representation. If a citation was include</context>
</contexts>
<marker>Tanabe, Wilbur, 2002</marker>
<rawString>Lorraine Tanabe and W. John Wilbur. 2002. Tagging gene and protein names in biomedical text. Bioinformatics. 2002 Aug;18(8):1124-32.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>