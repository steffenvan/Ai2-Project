<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.062527">
<title confidence="0.99778">
Towards a Flexible Semantics:
Colour Terms in Collaborative Reference Tasks
</title>
<author confidence="0.998752">
Bert Baumgaertner Raquel Fern´andez Matthew Stone
</author>
<affiliation confidence="0.999658">
University of California, Davis University of Amsterdam Rutgers University
</affiliation>
<email confidence="0.997917">
bbaum@ucdavis.edu raquel.fernandez@uva.nl matthew.stone@rutgers.edu
</email>
<sectionHeader confidence="0.993883" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99988675">
We report ongoing work on the development
of agents that can implicitly coordinate with
their partners in referential tasks, taking as a
case study colour terms. We describe algo-
rithms for generation and resolution of colour
descriptions and report results of experiments
on how humans use colour terms for reference
in production and comprehension.
</bodyText>
<sectionHeader confidence="0.998788" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999886609756097">
Speakers do not always share identical semantic rep-
resentations nor identical lexicons. For instance, a
subject may refer to a shape as a diamond while
another subject may call that same shape a square
(which just happens to be tilted sidewise); or some-
one may refer to a particular colour with ‘light pink’
while a different speaker may refer to it as ‘salmon’.
Regardless of these differences, which seem com-
mon place, speakers in dialogue are able to com-
municate successfully most of the time. Success-
ful communication exploits interlocutors’ abilities to
negotiate referring expressions interactively through
grounding (Clark and Wilkes-Gibbs, 1986; Clark
and Schaefer, 1989), but in many cases interlocutors
can already make a good guess at their partners’ in-
tentions by relaxing the interpretation of their utter-
ances and looking for the referent that best matches
this looser interpretation. We are interested in mod-
elling this second kind of behaviour computation-
ally, to get a better understanding of it and to con-
tribute to the development of dialogue systems that
are able to better coordinate with their human part-
ners.
In this paper we focus on collaborative referen-
tial tasks (akin to the classic matching tasks intro-
duced by Krauss and Weinheimer (1966) and Clark
and Wilkes-Gibbs (1986)) and take as a case study
colour terms. Our focus here is not on the explicit
joint negotiation of effective terms, but rather on the
deployment of flexible semantic representations that
can adapt to the constraints imposed by the context
and to the dialogue partner’s language use.
We start by describing our algorithms for genera-
tion and resolution of colour descriptions in the next
section. In sections 3 and 4, we present results of
experiments that investigate how humans use colour
terms for reference in production and comprehen-
sion. Section 5 compares our model against the ex-
perimental data we have collected so far and dis-
cusses some directions for future work. We end with
a short conclusion in section 6.
</bodyText>
<sectionHeader confidence="0.67137" genericHeader="method">
2 Reference to Colours: Our Model
</sectionHeader>
<bodyText confidence="0.999824">
Our view of how colour terms are used in referential
tasks follows the basic tenets of Gricean pragmat-
ics (Grice, 1975) and collaborative reference theo-
ries (Clark and Wilkes-Gibbs, 1986), according to
which speakers and addressees tend to maximize the
success of their joint task while minimizing costs.
In the domain of colour terms, we take this to
mean that speakers tend use a basic colour term (e.g.,
‘red’ or ‘blue’) whenever this is enough to iden-
tify the target object and resort to an alternative,
more specific or complex term (e.g., ‘bordeaux’ or
‘navy blue’) in other contexts where the basic term
is deemed insufficient. Non-basic terms can be con-
sidered more costly because they are less frequent
and thus more difficult to retrieve.
Similar ideas are at the core of models for the
generation of referring expressions that build on the
seminal work of Dale and Reiter (1995). These ap-
</bodyText>
<page confidence="0.970176">
80
</page>
<note confidence="0.5231865">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 80–84,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999176">
proaches, however, rely on a lexicon or database
where the properties of potential target objects are
associated with specific, predefined terms.1 Our aim
is to develop dialogue agents that employ more flex-
ible semantic representations, allowing them to (a)
refer to target colours with different terms in differ-
ent contexts, and (b) resolve the reference of colour
terms produced by the dialogue partner by picking
up targets that are not rigidly linked to the term in
the agent’s lexicon.
</bodyText>
<subsectionHeader confidence="0.980796">
2.1 Algorithms
</subsectionHeader>
<bodyText confidence="0.99980964516129">
Data. To develop the generation and resolution al-
gorithms of our agent, we used a publicly avail-
able database of RGB codes and colour terms gen-
erated from a colour naming survey created by Ran-
dall Monroe (author of the webcomic xkcd.com)
and taken by around two hundred thousand par-
ticipants.2 This database contains a total of 954
colour terms (corresponding to the colour terms
most frequently used by the participants) paired with
a unique RGB code corresponding to the location in
the RGB colour space which was most frequently
named with the colour term in question.
We use this database as the default lexicon of our
agent. Amongst the colour terms in the lexicon,
we distinguish between basic and non-basic colours.
We selected the following as our basic colours: red,
purple, pink, magenta, brown, orange, yellow, green,
teal, blue, and grey. This selection takes into account
the high frequency of these terms in English and is in
line with the literature on basic colour terms (Berlin
and Kay, 1967; Berlin and Kay, 1991).
Resolution Algorithm. ALIN (ALgorithm for IN-
terpretation) is given as input a scene of coloured
squares and a colour term. Its output is the square it
takes to be the intended target, generated as follows.
Assuming the input term is in the lexicon, ALIN
compares every colour in the scene to the RGB value
of the input (the anchor). ALIN considers a colour
c the intended target if, (a) c is nearest the anchor
within a certain distance threshold, and (b) for any
other colour c&apos; in the scene within the given distance
</bodyText>
<footnote confidence="0.7993985">
1See, however, van Deemter (2006) for an attempt to deal
with vague properties such as size within this framework.
2For further details visit http://blog.xkcd.com/
2010/05/03/color-survey-results/.
</footnote>
<figureCaption confidence="0.906536">
Figure 1: Two scenes with the brown square (top left in
both scenes) as the target; no competitors (left scene) and
one potential competitor (right scene).
</figureCaption>
<bodyText confidence="0.998138034482759">
threshold of the anchor, c&apos; is far enough away from
both the anchor and c. We say more about distance
thresholds below.
Generation Algorithm. Unless there are competi-
tors (colours relatively close to the target), GENA
(GENeration Algorithm) is disposed to output a ba-
sic colour term if the target is acceptably close to a
basic colour (if not, it selects the default term asso-
ciated with the RGB code in the lexicon). In case
there are competitor colours in the scene, if the tar-
get is a basic colour, GENA will attempt to select a
non-basic colour term closest to the target but still
further away from the competitor(s). If the target is
not a basic colour, GENA simply selects the default
term in the lexicon.
Measuring Colour Distance. We treat colours
in our model as points in a conceptual space
(G¨ardenfors, 2000; J¨ager, 2009). As a first approx-
imation, we measure colour proximity in terms of
Euclidean distances between RGB values.3 Three
variables were used to set the thresholds required by
ALIN and GENA: i) bc is the maximum range to
search for basic colours; ii) min is the minimum dis-
tance required between two colours to be considered
minimally different; and iii) max is the maximum
range of allowable search for alternative colours. We
conducted two pilot studies to establish reasonable
values for these variables, which we then set as: bc
= 100; min = 25; max = 75.4
</bodyText>
<sectionHeader confidence="0.998076" genericHeader="method">
3 Experimental Methodology
</sectionHeader>
<bodyText confidence="0.999697333333333">
We conducted two small experiments to collect data
about how speakers and addressees use colour terms
in referential tasks.
</bodyText>
<footnote confidence="0.963713">
3We recognize Euclidean distances between RGB values as-
sumes colour space is uniform, which is not the case in human
vision (Wyszecki and Stiles, 2000). See section 5.
4RGB codes scaled at 0–255.
</footnote>
<page confidence="0.994635">
81
</page>
<figure confidence="0.999474410958904">
basic colour w/o competitors basic colour with competitors
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.5
0.4
0.3
0.2
0.1
0.0
brown
chocolate brown
dark brown
earthy brown
poop brown
same as mud
blueberry
brown
chocolate brown
colour of mud
dark brown
non-basic colour w/o competitors
non-basic colour with competitors
0.5
0.4
0.3
0.2
0.1
0.0
rose
rose pink
salmon
salmon pink
dark pink
dusty rose
magenta
mauve
pink
red
bright pink
dull light fuchsia
dull salmon pink
dusty rose
light mauve
light pink
light red
light salmon
lightish pink
magenta
mauve
medium pink
orangish pink
pastel pink
pink
red
rose
rose pink
salmon
salmon pink
terra cotta
</figure>
<figureCaption confidence="0.999932">
Figure 2: Sample of results from ExpA, for a basic and a non-basic colour.
</figureCaption>
<bodyText confidence="0.980871103448276">
Materials &amp; Setup. We created 12 different
scenes, each consisting of four solid coloured
squares, one of them the target (see Figure 1 for
sample scenes). Scenes were designed to take into
account two parameters: basic and non-basic target
colours, and without or with a competitor – a colour
at a distance threshold from the target.5 The target
basic colours used were ‘brown’ and ‘magenta’ and
the non-basic ones, ‘rose’ and ‘sea blue’.6 Each tar-
get colour appeared at least in one scene where there
were no competitors.
We run a generation experiment (ExpA) and a res-
olution experiment (ExpB). In ExpA, participants
were shown our 12 scenes and were asked to refer
to the target with a colour term that would allow a
potential addressee to identify it in the current con-
text, but without reference to the other colours in
the scene (to avoid comparatives such as ‘the bluer
square’). In ExpB, participants were shown a scene
and a colour term and were asked to pick up the in-
tended referent. The colour terms used in this sec-
ond experiment were selected from those produced
in ExpA – 29 scene-term pairs in total. Each scene
appeared at least twice, once with a term with high
occurrence frequency in ExpA, and once or twice
with one or two terms that had been produced with
low frequency. To minimize chances that subjects
recognize the same scene more than once, we ro-
tated and dispersed them evenly throughout.
</bodyText>
<footnote confidence="0.8106796">
5Any colour within a Euclidean distance of 125 from the
target was considered a competitor.
6Compositional phrases may introduce more sophisticated
effects. However, the data on which our lexicon is based ab-
stracted away from such details, treating them as simples.
</footnote>
<bodyText confidence="0.9909372">
Participants. A total of 36 native-English partici-
pants took part in the experiments: 19 in ExpA and
17 in ExpB. Subjects for both experiments included
undergraduate students, graduates students, and uni-
versity faculty. Both experiments were run online.
</bodyText>
<sectionHeader confidence="0.992088" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999841">
ExpA Generation. ExpA revealed there is high
variability in the terms produced to refer to a sin-
gle colour. As expected, variability of terms gener-
ated for non-basic colours was higher than for ba-
sic colours. For non-basic colours, variability of
terms in scenes with competitors was higher. Fig-
ure 2 shows the different terms produced for a basic
colour (‘brown’) and a non-basic colour (‘rose’) in
scenes without and with competitors, together with
the proportional frequency of each term.
For the brown square target in a scene with-
out competitors, the basic-colour term ‘brown’ was
used with high frequency (72% of the time) while
any other terms were used 1 or 2 times only. In
scenes with competitors, ‘dark brown’ had high-
est frequency with ‘brown’ almost as much (43%
vs. 40%). For the rose square target in a scene with-
out competitors, there was also one term that stood
out as the most frequent, ‘pink’, although its fre-
quency (30%) is substantially lower to that of the
basic-colour ‘brown’. In scenes with competitors
there is an explosion in variation, with ‘pink’ still
standing out but only with a proportional frequency
of 21%.
Overall, ExpA showed that speakers attempt to
adapt their colour descriptions to the context and that
</bodyText>
<page confidence="0.996937">
82
</page>
<bodyText confidence="0.999853523809524">
there is high variability in the terms they choose to
do this.
ExpB: Resolution. ExpB showed that reference
resolution is almost always successful despite the
variation in colour terms observed in ExpA. For the
basic colours in scenes with no competitors, partici-
pants successfully identified the targets in all cases,
while in scenes with competitors they did so 98%
of the time. This was the case for both terms with
proportionally high and low frequency.
For the non-basic colours in scenes with no com-
petitors, the success rate in identifying the target
was again 100% for both high and low frequency
terms. For scenes with competitors, there were dif-
ferences depending on the frequency of the terms
used: for high frequency terms there were once more
no resolution errors, while the resolution success
rate dropped to 78% where we used terms with low
proportional frequency scores. A summary of these
results is shown in Table 1, together with the success
rate of our resolution algorithm ALIN.
</bodyText>
<table confidence="0.930168">
Basic Colours low freq. Non-basic Colours
high freq. nc c high freq. low freq.
nc c nc c nc c
ExpB 1 0.98 1 0.98 1 1 1 0.78
ALIN 1 0.71 1 0.71 0.5 1 0.75 0.71
</table>
<tableCaption confidence="0.9701205">
Table 1: Resolution success rate by human participants
and ALIN in scenes without and with competitors (nc/c).
</tableCaption>
<sectionHeader confidence="0.999138" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999992818181818">
The data we collected allows us to make informa-
tive comparisons between humans and our model in
collaborative reference tasks. Although we do not
believe the data is sufficient for an evaluation, the
comparison illuminates how the model can be re-
fined and the setup required for a proper evaluation.
Regarding resolution, we note that an algorithm
that rigidly associates colours and terms would have
successfully resolved only 4 of the 29 cases, 3 of
which were basic colours with no distractors – a
7.25% success rate. In our scenarios with four po-
tential targets, a random algorithm would have an
average success rate of 25%. ALIN is closer to our
human data (see Table 1), though anomalies exist.
One problem is the lack of compositional semantics
in our current model. ALIN failed to resolve com-
plex phrases like ‘dull salmon pink’ and ‘deep gray
blue’, which were terms produced by humans for
non-basic colours with competitors, simply because
the terms were not in the agent’s lexicon. Other
anomalies seem to be consequences of taking Eu-
clidean distances over RGB values, which may be
too crude. In the future, our intent is to convert RGB
values to Lab values and then use Delta-E values to
measure distances. First, however, we need a more
sophisticated analysis of the thresholds that we used
for ALIN and GENA.
As for generation, given the amount of variation
observed in the terms produced by our subjects, it is
not clear how human performance ought to be com-
pared to GENA’s. For instance, in scenes with com-
petitors, GENA produced ‘reddish brown’ for the
basic colour ‘brown’ and ‘coral’ for the non-basic
colour ‘rose’. These did not appear in our human-
generated data but still seem to our lights reasonable
descriptions. GENA also produced ‘gray’ to refer to
‘rose’ in a different scene, which seems less appro-
priate and may be due to our current way of calcu-
lating colour distances and setting up the thresholds.
We believe that instead of comparing GENA’s
output to human output, it makes more sense to eval-
uate GENA by testing how well humans can resolve
terms produced by it. We intend to carry out this
evaluation in the future.
</bodyText>
<sectionHeader confidence="0.999784" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999954111111111">
We have focused on the specific case of colours
where speakers differ in the referring expressions
they generate, but addressees are nevertheless able
to relax the interpretations of the expressions in or-
der to coordinate. We believe this implicit adapt-
ability is part of our semantic representation more
broadly. The case of colour provides us with a start-
ing point for studying and modelling computation-
ally this flexibility we possess.
</bodyText>
<sectionHeader confidence="0.996934" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99468225">
This work has been partially supported by grant
632.002.001 from the Netherlands Organisation for
Scientic Research (NWO) and by grant IIS-1017811
from the National Science Foundation (NSF).
</bodyText>
<page confidence="0.998425">
83
</page>
<sectionHeader confidence="0.995894" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999778285714286">
Brent Berlin and Paul Kay. 1967. Universality and evo-
lution of basic color terms. Laboratory for Language-
Behavior Research.
Brent Berlin and Paul Kay. 1991. Basic color terms:
Their universality and evolution. Univ of California
Pr.
Herbert H. Clark and Edward F. Schaefer. 1989. Con-
tributing to discourse. Cognitive Science, 13(2):259–
294.
Herbert H. Clark and Donna Wilkes-Gibbs. 1986. Refer-
ring as a collaborative process. Cognition, 22:1–39.
Robert Dale and Ehud Reiter. 1995. Computational in-
terpretations of the Gricean Maxims in the Generation
of Referring Expressions. Cognitive Science, 18:233–
266.
Peter G¨ardenfors. 2000. Conceptual Spaces. MIT Press,
Cambridge.
Paul Grice. 1975. Logic and conversation. In D. David-
son and G. Harman, editors, The Logic of Grammar,
pages 64–75. Dickenson, Encino, California.
Gerhard J¨ager. 2009. Natural color categories are convex
sets. In Logic, Language and Meaning: 17th Amster-
dam Colloquium, Amsterdam, The Netherlands, De-
cember 16-18, 2009, Revised Selected Papers, pages
11–20. Springer.
Robert Krauss and Sidney Weinheimer. 1966. Concur-
rent feedback, confirmation, and the encoding of refer-
ents in verbal communication. Journal of Personality
and Social Psychology, 4(3):343–346.
Kees van Deemter. 2006. Generating referring expres-
sions that involve gradable properties. Computational
Lingustics, 32(2):195–222.
G¨unter Wyszecki and Walter S. Stiles. 2000. Color sci-
ence: concepts and methods, quantitative data and
formulae. Wiley Classics Library.
</reference>
<page confidence="0.999244">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.977409">
<title confidence="0.9993695">Towards a Flexible Semantics: Colour Terms in Collaborative Reference Tasks</title>
<author confidence="0.999961">Bert Baumgaertner Raquel Fern´andez Matthew Stone</author>
<affiliation confidence="0.99999">University of California, Davis University of Amsterdam Rutgers University</affiliation>
<email confidence="0.994723">bbaum@ucdavis.eduraquel.fernandez@uva.nlmatthew.stone@rutgers.edu</email>
<abstract confidence="0.998178222222222">We report ongoing work on the development of agents that can implicitly coordinate with their partners in referential tasks, taking as a case study colour terms. We describe algorithms for generation and resolution of colour descriptions and report results of experiments on how humans use colour terms for reference in production and comprehension.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Brent Berlin</author>
<author>Paul Kay</author>
</authors>
<title>Universality and evolution of basic color terms. Laboratory for LanguageBehavior Research.</title>
<date>1967</date>
<contexts>
<context position="5281" citStr="Berlin and Kay, 1967" startWordPosition="843" endWordPosition="846">quently used by the participants) paired with a unique RGB code corresponding to the location in the RGB colour space which was most frequently named with the colour term in question. We use this database as the default lexicon of our agent. Amongst the colour terms in the lexicon, we distinguish between basic and non-basic colours. We selected the following as our basic colours: red, purple, pink, magenta, brown, orange, yellow, green, teal, blue, and grey. This selection takes into account the high frequency of these terms in English and is in line with the literature on basic colour terms (Berlin and Kay, 1967; Berlin and Kay, 1991). Resolution Algorithm. ALIN (ALgorithm for INterpretation) is given as input a scene of coloured squares and a colour term. Its output is the square it takes to be the intended target, generated as follows. Assuming the input term is in the lexicon, ALIN compares every colour in the scene to the RGB value of the input (the anchor). ALIN considers a colour c the intended target if, (a) c is nearest the anchor within a certain distance threshold, and (b) for any other colour c&apos; in the scene within the given distance 1See, however, van Deemter (2006) for an attempt to deal</context>
</contexts>
<marker>Berlin, Kay, 1967</marker>
<rawString>Brent Berlin and Paul Kay. 1967. Universality and evolution of basic color terms. Laboratory for LanguageBehavior Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brent Berlin</author>
<author>Paul Kay</author>
</authors>
<title>Basic color terms: Their universality and evolution. Univ of California Pr.</title>
<date>1991</date>
<contexts>
<context position="5304" citStr="Berlin and Kay, 1991" startWordPosition="847" endWordPosition="850">rticipants) paired with a unique RGB code corresponding to the location in the RGB colour space which was most frequently named with the colour term in question. We use this database as the default lexicon of our agent. Amongst the colour terms in the lexicon, we distinguish between basic and non-basic colours. We selected the following as our basic colours: red, purple, pink, magenta, brown, orange, yellow, green, teal, blue, and grey. This selection takes into account the high frequency of these terms in English and is in line with the literature on basic colour terms (Berlin and Kay, 1967; Berlin and Kay, 1991). Resolution Algorithm. ALIN (ALgorithm for INterpretation) is given as input a scene of coloured squares and a colour term. Its output is the square it takes to be the intended target, generated as follows. Assuming the input term is in the lexicon, ALIN compares every colour in the scene to the RGB value of the input (the anchor). ALIN considers a colour c the intended target if, (a) c is nearest the anchor within a certain distance threshold, and (b) for any other colour c&apos; in the scene within the given distance 1See, however, van Deemter (2006) for an attempt to deal with vague properties </context>
</contexts>
<marker>Berlin, Kay, 1991</marker>
<rawString>Brent Berlin and Paul Kay. 1991. Basic color terms: Their universality and evolution. Univ of California Pr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Edward F Schaefer</author>
</authors>
<title>Contributing to discourse.</title>
<date>1989</date>
<journal>Cognitive Science,</journal>
<volume>13</volume>
<issue>2</issue>
<pages>294</pages>
<contexts>
<context position="1322" citStr="Clark and Schaefer, 1989" startWordPosition="187" endWordPosition="190">entations nor identical lexicons. For instance, a subject may refer to a shape as a diamond while another subject may call that same shape a square (which just happens to be tilted sidewise); or someone may refer to a particular colour with ‘light pink’ while a different speaker may refer to it as ‘salmon’. Regardless of these differences, which seem common place, speakers in dialogue are able to communicate successfully most of the time. Successful communication exploits interlocutors’ abilities to negotiate referring expressions interactively through grounding (Clark and Wilkes-Gibbs, 1986; Clark and Schaefer, 1989), but in many cases interlocutors can already make a good guess at their partners’ intentions by relaxing the interpretation of their utterances and looking for the referent that best matches this looser interpretation. We are interested in modelling this second kind of behaviour computationally, to get a better understanding of it and to contribute to the development of dialogue systems that are able to better coordinate with their human partners. In this paper we focus on collaborative referential tasks (akin to the classic matching tasks introduced by Krauss and Weinheimer (1966) and Clark </context>
</contexts>
<marker>Clark, Schaefer, 1989</marker>
<rawString>Herbert H. Clark and Edward F. Schaefer. 1989. Contributing to discourse. Cognitive Science, 13(2):259– 294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Donna Wilkes-Gibbs</author>
</authors>
<title>Referring as a collaborative process.</title>
<date>1986</date>
<journal>Cognition,</journal>
<pages>22--1</pages>
<contexts>
<context position="1295" citStr="Clark and Wilkes-Gibbs, 1986" startWordPosition="183" endWordPosition="186">hare identical semantic representations nor identical lexicons. For instance, a subject may refer to a shape as a diamond while another subject may call that same shape a square (which just happens to be tilted sidewise); or someone may refer to a particular colour with ‘light pink’ while a different speaker may refer to it as ‘salmon’. Regardless of these differences, which seem common place, speakers in dialogue are able to communicate successfully most of the time. Successful communication exploits interlocutors’ abilities to negotiate referring expressions interactively through grounding (Clark and Wilkes-Gibbs, 1986; Clark and Schaefer, 1989), but in many cases interlocutors can already make a good guess at their partners’ intentions by relaxing the interpretation of their utterances and looking for the referent that best matches this looser interpretation. We are interested in modelling this second kind of behaviour computationally, to get a better understanding of it and to contribute to the development of dialogue systems that are able to better coordinate with their human partners. In this paper we focus on collaborative referential tasks (akin to the classic matching tasks introduced by Krauss and W</context>
<context position="2885" citStr="Clark and Wilkes-Gibbs, 1986" startWordPosition="448" endWordPosition="451">algorithms for generation and resolution of colour descriptions in the next section. In sections 3 and 4, we present results of experiments that investigate how humans use colour terms for reference in production and comprehension. Section 5 compares our model against the experimental data we have collected so far and discusses some directions for future work. We end with a short conclusion in section 6. 2 Reference to Colours: Our Model Our view of how colour terms are used in referential tasks follows the basic tenets of Gricean pragmatics (Grice, 1975) and collaborative reference theories (Clark and Wilkes-Gibbs, 1986), according to which speakers and addressees tend to maximize the success of their joint task while minimizing costs. In the domain of colour terms, we take this to mean that speakers tend use a basic colour term (e.g., ‘red’ or ‘blue’) whenever this is enough to identify the target object and resort to an alternative, more specific or complex term (e.g., ‘bordeaux’ or ‘navy blue’) in other contexts where the basic term is deemed insufficient. Non-basic terms can be considered more costly because they are less frequent and thus more difficult to retrieve. Similar ideas are at the core of model</context>
</contexts>
<marker>Clark, Wilkes-Gibbs, 1986</marker>
<rawString>Herbert H. Clark and Donna Wilkes-Gibbs. 1986. Referring as a collaborative process. Cognition, 22:1–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
<author>Ehud Reiter</author>
</authors>
<title>Computational interpretations of the Gricean Maxims in the Generation of Referring Expressions.</title>
<date>1995</date>
<journal>Cognitive Science,</journal>
<volume>18</volume>
<pages>266</pages>
<contexts>
<context position="3587" citStr="Dale and Reiter (1995)" startWordPosition="568" endWordPosition="571">ir joint task while minimizing costs. In the domain of colour terms, we take this to mean that speakers tend use a basic colour term (e.g., ‘red’ or ‘blue’) whenever this is enough to identify the target object and resort to an alternative, more specific or complex term (e.g., ‘bordeaux’ or ‘navy blue’) in other contexts where the basic term is deemed insufficient. Non-basic terms can be considered more costly because they are less frequent and thus more difficult to retrieve. Similar ideas are at the core of models for the generation of referring expressions that build on the seminal work of Dale and Reiter (1995). These ap80 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 80–84, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics proaches, however, rely on a lexicon or database where the properties of potential target objects are associated with specific, predefined terms.1 Our aim is to develop dialogue agents that employ more flexible semantic representations, allowing them to (a) refer to target colours with different terms in different contexts, and (b) resolve the reference of colour terms produced by the dialogue partner by picking up t</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>Robert Dale and Ehud Reiter. 1995. Computational interpretations of the Gricean Maxims in the Generation of Referring Expressions. Cognitive Science, 18:233– 266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter G¨ardenfors</author>
</authors>
<title>Conceptual Spaces.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<marker>G¨ardenfors, 2000</marker>
<rawString>Peter G¨ardenfors. 2000. Conceptual Spaces. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Grice</author>
</authors>
<title>Logic and conversation.</title>
<date>1975</date>
<booktitle>The Logic of Grammar,</booktitle>
<pages>64--75</pages>
<editor>In D. Davidson and G. Harman, editors,</editor>
<location>Dickenson, Encino, California.</location>
<contexts>
<context position="2817" citStr="Grice, 1975" startWordPosition="441" endWordPosition="442">partner’s language use. We start by describing our algorithms for generation and resolution of colour descriptions in the next section. In sections 3 and 4, we present results of experiments that investigate how humans use colour terms for reference in production and comprehension. Section 5 compares our model against the experimental data we have collected so far and discusses some directions for future work. We end with a short conclusion in section 6. 2 Reference to Colours: Our Model Our view of how colour terms are used in referential tasks follows the basic tenets of Gricean pragmatics (Grice, 1975) and collaborative reference theories (Clark and Wilkes-Gibbs, 1986), according to which speakers and addressees tend to maximize the success of their joint task while minimizing costs. In the domain of colour terms, we take this to mean that speakers tend use a basic colour term (e.g., ‘red’ or ‘blue’) whenever this is enough to identify the target object and resort to an alternative, more specific or complex term (e.g., ‘bordeaux’ or ‘navy blue’) in other contexts where the basic term is deemed insufficient. Non-basic terms can be considered more costly because they are less frequent and thu</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>Paul Grice. 1975. Logic and conversation. In D. Davidson and G. Harman, editors, The Logic of Grammar, pages 64–75. Dickenson, Encino, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard J¨ager</author>
</authors>
<title>Natural color categories are convex sets.</title>
<date>2009</date>
<booktitle>In Logic, Language and Meaning: 17th Amsterdam Colloquium,</booktitle>
<pages>11--20</pages>
<publisher>Springer.</publisher>
<location>Amsterdam, The Netherlands,</location>
<marker>J¨ager, 2009</marker>
<rawString>Gerhard J¨ager. 2009. Natural color categories are convex sets. In Logic, Language and Meaning: 17th Amsterdam Colloquium, Amsterdam, The Netherlands, December 16-18, 2009, Revised Selected Papers, pages 11–20. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Krauss</author>
<author>Sidney Weinheimer</author>
</authors>
<title>Concurrent feedback, confirmation, and the encoding of referents in verbal communication.</title>
<date>1966</date>
<journal>Journal of Personality and Social Psychology,</journal>
<volume>4</volume>
<issue>3</issue>
<contexts>
<context position="1911" citStr="Krauss and Weinheimer (1966)" startWordPosition="286" endWordPosition="289">-Gibbs, 1986; Clark and Schaefer, 1989), but in many cases interlocutors can already make a good guess at their partners’ intentions by relaxing the interpretation of their utterances and looking for the referent that best matches this looser interpretation. We are interested in modelling this second kind of behaviour computationally, to get a better understanding of it and to contribute to the development of dialogue systems that are able to better coordinate with their human partners. In this paper we focus on collaborative referential tasks (akin to the classic matching tasks introduced by Krauss and Weinheimer (1966) and Clark and Wilkes-Gibbs (1986)) and take as a case study colour terms. Our focus here is not on the explicit joint negotiation of effective terms, but rather on the deployment of flexible semantic representations that can adapt to the constraints imposed by the context and to the dialogue partner’s language use. We start by describing our algorithms for generation and resolution of colour descriptions in the next section. In sections 3 and 4, we present results of experiments that investigate how humans use colour terms for reference in production and comprehension. Section 5 compares our </context>
</contexts>
<marker>Krauss, Weinheimer, 1966</marker>
<rawString>Robert Krauss and Sidney Weinheimer. 1966. Concurrent feedback, confirmation, and the encoding of referents in verbal communication. Journal of Personality and Social Psychology, 4(3):343–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
</authors>
<title>Generating referring expressions that involve gradable properties.</title>
<date>2006</date>
<journal>Computational Lingustics,</journal>
<volume>32</volume>
<issue>2</issue>
<marker>van Deemter, 2006</marker>
<rawString>Kees van Deemter. 2006. Generating referring expressions that involve gradable properties. Computational Lingustics, 32(2):195–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unter Wyszecki</author>
<author>Walter S Stiles</author>
</authors>
<title>Color science: concepts and methods, quantitative data and formulae.</title>
<date>2000</date>
<publisher>Wiley Classics Library.</publisher>
<contexts>
<context position="7870" citStr="Wyszecki and Stiles, 2000" startWordPosition="1280" endWordPosition="1283"> colours; ii) min is the minimum distance required between two colours to be considered minimally different; and iii) max is the maximum range of allowable search for alternative colours. We conducted two pilot studies to establish reasonable values for these variables, which we then set as: bc = 100; min = 25; max = 75.4 3 Experimental Methodology We conducted two small experiments to collect data about how speakers and addressees use colour terms in referential tasks. 3We recognize Euclidean distances between RGB values assumes colour space is uniform, which is not the case in human vision (Wyszecki and Stiles, 2000). See section 5. 4RGB codes scaled at 0–255. 81 basic colour w/o competitors basic colour with competitors 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 0.5 0.4 0.3 0.2 0.1 0.0 brown chocolate brown dark brown earthy brown poop brown same as mud blueberry brown chocolate brown colour of mud dark brown non-basic colour w/o competitors non-basic colour with competitors 0.5 0.4 0.3 0.2 0.1 0.0 rose rose pink salmon salmon pink dark pink dusty rose magenta mauve pink red bright pink dull light fuchsia dull salmon pink dusty rose light mauve light pink light red light salmon light</context>
</contexts>
<marker>Wyszecki, Stiles, 2000</marker>
<rawString>G¨unter Wyszecki and Walter S. Stiles. 2000. Color science: concepts and methods, quantitative data and formulae. Wiley Classics Library.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>