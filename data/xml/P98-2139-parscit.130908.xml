<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000100">
<title confidence="0.948548">
Deriving Transfer Rules from Dominance-Preserving Alignments
</title>
<author confidence="0.8235055">
Adam Meyers, Roman Yangarber, Ralph Grishman,
Catherine Macleod, Antonio Moreno—Sandovalt
</author>
<note confidence="0.5441755">
New York University
715 Broadway, 7th Floor, NY, NY 10003, USA
tUniversidad AutOnoma de Madrid
Cantoblanco, 28049-Madrid, SPAIN
</note>
<bodyText confidence="0.5325975">
meyers/roman/grishman/macleodOcs.nyu.edu
sandova101ola.111f.uam.es
</bodyText>
<sectionHeader confidence="0.999314" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999666878787879">
Automatic acquisition of translation rules from
parallel sentence-aligned text takes a variety of
forms. Some machine translation (MT) systems
treat aligned sentences as unstructured word se-
quences. Other systems, including our own ((Gr-
ishman, 1994) and (Meyers et al., 1996)), syn-
tactically analyze sentences (parse) before ac-
quiring transfer rules (cf. (Kaji et al., 1992),
(Matsumoto et al., 1993), and (Kitamura and
Matsumoto, 1995)). This has the advantage of
acquiring structural as well as lexical correspon-
dences. A syntactically analyzed, aligned cor-
pus may serve as an example base for a form of
example-based MT (cf. (Sato and Nagao, 1990),
(Kaji et al., 1992), and (Furuse and Iida. 1994)).
This paperl describes: (1) an efficient algo-
rithm for aligning a pair of source/target lan-
guage parse trees; and (2) a procedure for de-
riving transfer rules from this alignment. Each
transfer rule consists of a pair of tree fragments
derived by &amp;quot;cutting up&amp;quot; the source and target
trees. A set of transfer rules whose left-hand
sides match a source language parse tree is used
to generate a target language parse tree from
their set of right-hand sides. which is a transla-
tion of the source tree. This technique resembles
work on MT using synchronous Tree-Adjoining
Grammars (cf. (Abeille et al.. 1990)).
The Proteus translation system learns transfer
rules from pairs of aligned source and target reg-
ularized parses, Proteus&apos;s representation of pred-
icate argument structure (cf. Figure 1).2 Then
it uses these transfer rules to map source Ian-
</bodyText>
<footnote confidence="0.943848333333333">
We thank Cristina Olmeda Moreno for work on pars-
ing our Spanish text. This research was supported by
National Science Foundation Grant IRI-9303013.
2Regularized parses (henceforth, &amp;quot;parse trees&amp;quot;) are
like F-structures of Lexical Function Grammar (LFG),
except that a dependency structure is used.&amp;quot;
</footnote>
<bodyText confidence="0.99910995">
guage regularized parses generated by our source
language parser into target language regularized
parses. Finally a generator converts target reg-
ularized parses into target language sentences.
An alignment f is a 1-to-1 partial mapping
from source nodes to target nodes. We con-
sider only alignments which preserve the dom-
inance relationship: If node a dominates node
b in the source tree. then 1(a) dominates f (b)
in the target tree. In Figure 1. source nodes .4.
B, C and D map to the corresponding target
nodes. marked with a prime, e.g., f (A) = .4&apos;.
The alignment may be represented by the set
{(A, A&apos;), (B, B&apos;), (C. C&apos;). (D. D&apos;)} . We can as-
sign a score to each alignment f based on the
(weighted) number of pairs in f; finding the best
alignment translates into finding the alignment
with the highest score. Our algorithms are based
on (Farach et al., 1995) and related work.
We needed efficient alignment algorithms be-
cause: (1) Corpus-based training requires pro-
cessing a lot of text; and (2) An exhaustive
search of all alignments is too computationally
expensive for realistically sized parse trees.
Eliminating dominance violations greatly re-
duced our search space. Similar work (e.g.,
(Matsumoto et al., 1993)) considers all possible
matches. Although. our system cannot account
for actual dominance violations in a given bi-
text, there are no such violations in our corpus
and many hypothetical cases can be avoided by
adopting the appropriate grammar. Cases of ad-
juncts aligning with heads and vice versa are not
dominance violations if we replace our depen-
dency analysis with one in which internal nodes
have category labels and the head constituents
are marked by HEAD arcs and we assume the
following Categorial Grammar (CG) style anal-
yses. Suppose that verb (V1) maps to adverb
(A&apos;1) and adverb (A2) maps to verb (V&apos;2), where
</bodyText>
<page confidence="0.999282">
843
</page>
<figureCaption confidence="0.999797">
Figure 1: A Pair of Aligned Trees
</figureCaption>
<figure confidence="0.988595428571429">
Subj
Source Tree
D = volver
a E = calcular
Obj
en
. .....................
C = libro
....
\de
........................
D&apos; = recalculate
C&apos; = workbook
F = traba*
Excel vuelve a cakular valores en libro de trabajo
• • ................... . - -
Excel recalculates values in workbook
A = Excel
.........................
Target Tree
.................... .
</figure>
<bodyText confidence="0.99392975">
A2 modifies V1 and A&apos;1 modifies V&apos;2. We as-
sume the following structures: [VP [VP1 V1
A2] and [VP [VP2 V*2 All No dominance
violation exists because no dominance relation
holds between VI and A2 or V*2 and A&apos;1. Y.
Matsumoto (p.c.) notes that the subordinate
clause of a source sentence may align with the
main clause of a target language and vice versa,
e.g.. X after Y aligns with Y&apos; before X&apos;. where
X. X&apos;, Y and Y are all clauses. Assuming a CG
style analysis, [S X [after Y.]] aligns with [S Y.
[before X&apos;]] with no dominance violations.
</bodyText>
<sectionHeader confidence="0.955083" genericHeader="keywords">
2 The Least-Common-Ancestor
Constraint
</sectionHeader>
<bodyText confidence="0.99985446875">
Our earlier tree alignment algorithms (cf. (Mey-
ers et al.. 1996)) were designed to produce align-
ments which preserve the least common ancestor
relationship: If nodes a and b map into nodes
a&apos; = f (a) and b&apos; = f (b), then f (LC A(a,b)) =
LC A( f (a). f (b)) = LC A(a&apos;,b&apos;). The least com-
mon ancestor (LCA) of a and b is the lowest node
in the tree dominating both a and b. The LCA-
preserving approach imposes limitations on the
quality of the resulting alignments. In Figure 1.
the LCA-preserving algorithm will match node
E with node D&apos; and report that as the best match
overall. The score S(D. D&apos;) would take into ac-
count only the match (E, D&apos;), which in turn in-
cludes (B, B&apos;) and (C. C&apos;). (S (D. D&apos;) would be
penalized for collapsing the arc from D to E.)
We seek a better alignment scheme, in which
the score S(D, D&apos;) could benefit from S (A, A&apos;).
We are willing to pay a small penalty to collapse
the path from D to E, and align the resulting
structure. This leads to new algorithms where
the LCA-preserving restriction is replaced by the
weaker, dominance-preserving constraint. The
rationale behind allowing an edge, say (v, u) to
be collapsed when matching two nodes v and v&apos;.
is that we may find some children of u which cor-
respond well to some children of v&apos;. while other
children of v correspond well to other children of
v&apos;. (This is not possible if LCA.s are preserved.)
The algorithm relies on the assumption that two
different children of v will not match well with
the same child of v&apos;.
</bodyText>
<sectionHeader confidence="0.993102" genericHeader="method">
3 The Dominance-Preserving
Algorithm
</sectionHeader>
<bodyText confidence="0.999849192307692">
Let T and T&apos; be the source and the target trees.
We use a dynamic programming algorithm to
compute, in a bottom-up fashion, the scores for
matching each node in T against each node in T&apos;.
There are 0(n2) such scores, n = max(ITI,
is number of nodes in the trees. Let the d(v) be
the degree of a node v. We denote children of v
by vi, i = 1, ..., d(v), and arc (v, vi) by
For all pairs of nodes v E T and v&apos; E T&apos;, the
algorithm computes the score function S(v,
S(v, v&apos;) corresponds to the best match found be-
tween the subtrees rooted at v in T and at v&apos; in
T&apos;. The values of S are stored in a IT! x IT&apos;I ma-
trix, also denoted by S. Initially, we fill the ma-
trix S with undefined values, and invoke the pro-
cedure SCOREdom, described below, to com-
pute S(root(T),root(T&apos;)), the score for matching
the root nodes of the trees. During the compu-
tation of the score for the roots, the procedure
recursively finds the best-scoring matches for all
the nodes in the trees. This yields the best align-
ment of the entire trees.
Table 1(a) shows the values of S for the trees
in Figure 1. Whenever we compute a score for
internal nodes, we also record the best way of
pairing up their children in Table 1(b).3 The
</bodyText>
<footnote confidence="0.819348">
3 Children pairings include child/child pairs and par-
ent/child pairs: (D.D&apos;)&apos;s pairing is {(.4, A&apos;), (E, D&apos;)}.
</footnote>
<page confidence="0.995906">
844
</page>
<bodyText confidence="0.999074">
alignment, implicit in these children pairings, is
used in a later phase (Section 4) to recover the
alignment for the entire trees.
Procedure SCOREdom: For a pair of nodes,
(v, v&apos;), recursively compute the score S(v, v&apos;):
Construct an intermediate child-scoring ma-
trix M = M(v, v&apos;), for the children of v and v&apos;;
the dimensions of M are (d(v) + 1) x (d(v&apos;) + 1).
That is, the number of rows in M is one more
than the number of children of v, and the number
of columns is one more than number of children
of v&apos;. We label row d(v) + 1 and column d(v&apos;) + 1
with a &amp;quot;*&amp;quot;. Fill the matrix M:
</bodyText>
<listItem confidence="0.995465">
1. Vi, j, where 1 &lt; &lt; d(v), 1 &lt; j &lt; d(v&apos;)
compute the corresponding entry in Mii:
= S(v, v/j) + Lexarc(7i, 5.1j)
</listItem>
<bodyText confidence="0.878413285714286">
The function Lexn„,d,(v, v&apos;) &gt; 0 (used be-
low) is the quality of translation, i.e. the
measure of how closely the label (word) at
source node v corresponds to the label at
target node v&apos; in the bilingual dictionary,
and Lexarc(fi, &gt; 0 is the corresponding
measure for arc labels.
</bodyText>
<listItem confidence="0.998728333333333">
2. Fill the last column as follows: Vi, where
1 &lt; i &lt; d(v) compute the entries:
= S(v, v&apos;) — Pen(iii)
</listItem>
<bodyText confidence="0.571559">
Pen(77i) &gt; 0 is the penalty for collapsing the
edge 7i, which depends on the value of the
label of that edge.
</bodyText>
<listItem confidence="0.99059725">
3. Symmetrically, Vj s.t. 1 &lt; j &lt;
d(v&apos;) fill the last row with the entries:
= S(v, — Pen()
4. The entry M— is disfavored: M_ = —Do
</listItem>
<bodyText confidence="0.998833727272727">
For example, during the calculation of the
scores S(D,D&apos;) and S(E. D&apos;) from Table 1, the
corresponding matrices M (D, D&apos;) and M (E, D&apos;)
are filled in as in Table 2. The proper values for
the parameter functions used above, such. as the
penalty function Pen and the translation mea-
sures, are chosen empirically, and constitute the
tunable parameters of the procedure. Normally,
we will expect that the values of Lexnode will be
much larger than the values of Lex,, and Pen.
In the example we used the following settings:
</bodyText>
<listItem confidence="0.99976825">
1. Lex„de = 100 for an exact translation, as for
(A, A&apos;), (B, if) and (C, C&apos;), and 0 otherwise.
2. all values of Lex,, are set to zero
3. all penalties Pen are set to 1
</listItem>
<bodyText confidence="0.9973605">
Now, using the values in M, compute the score
for matching v and v&apos;:
</bodyText>
<equation confidence="0.992386">
S(v, vi) = Leznode(v, vi) + max E mi, (1)
PE CP (i,j)EP
</equation>
<bodyText confidence="0.96956225">
Here P is a legitimate pairing of v and its chil-
dren against v&apos; and its children. A legitimate
pairing P is a set of elements of the matrix M.
that conform to the following conditions:
</bodyText>
<listItem confidence="0.967373111111111">
1. each row and each column of M may con-
tribute at most one element to P. except
that the row and the column labeled * may
contribute more than one element to P
2. if P contains an element Mii correspond-
ing to the node pair (w. w&apos;), and some child
node u appears in the Children-Pairing for
(w, w&apos;), then the row or column of a may
not contribute any elements to P.
</listItem>
<bodyText confidence="0.999113739130435">
We use CP = GP (v .v&apos;) to denote the set of all
legitimate pairings. There are 0(d!) such pair-
ings, where d is the greater of the degrees of v
and v&apos;. The summation in (1) ranges over all
the pairs (i, j) that appear in a legitimate pair-
ing P E ,CP(v, v&apos;). We evaluate this summation
for all 0(d!) legitimate pairings in LP and then
select the pairing Pb&amp;quot;t with the maximum score.
Pbest is then stored in the Children-Pairing ma-
trix entry for (v, v&apos;).
Table 2 shows how scores are calculated. The
best score for S(E, D&apos;) is 200, the sum of the
scores for (B, B&apos;) and (C. C&apos;). S(D. D&apos;) =
299 = S (A, A&apos;) + S(E. D&apos;) — 1, a penalty of 1
for collapsing the edge from D to E.
We can reduce the computation time of the
max term in (1), if we do not consider all 0(d!)
pairings of the children of v and v&apos;. Instead
of exhaustively computing the maximal-scoring
pairingPbest in (1), we can build it in a greedy
fashion: successively choos the d highest-scoring,
mutually disjoint pairs from the 0(e) possible
pairs of children of v and v&apos;.
</bodyText>
<listItem confidence="0.988896833333333">
1. Initialize the set of highest scoring pairs
Pbest
2. Pbest PbestU {(i, j)} where Mij is the next
largest entry in the matrix, which that sat-
isfies both conditions 1 and 2 of legitimate
pairings
</listItem>
<page confidence="0.996045">
845
</page>
<table confidence="0.903706052631579">
Target Nodes Target Nodes
Source
Nodes
Source
Nodes
A&apos; B&apos; C&apos; D&apos;
A 100 0 0 0
B 0 100 0 0
C 0 0 100 0
D 0 0 0 299
E 0 0 0 200
F 0 0 0 0
A&apos; B&apos; C&apos; D&apos;
A - - - -
B - - - -
C - - - -
D - - - (A. A&apos;)(E , D&apos;)
E - - - (B. B1)(C.C&apos;)
F - - - -
</table>
<tableCaption confidence="0.999513">
Table 1: (a) A Final Score Matrix: (b) Children-Pairing Matrix
</tableCaption>
<table confidence="0.943668823529412">
Target Children
1: A&apos; 2: B&apos; 3: C&apos; *: D&apos;
1:B 0 100 0 99
2:C 0 0 100 99
*: E 0 99 99 —
Target Children
1: .4&apos; 2: B&apos; 3: C&apos; *: D&apos;
LA 100 0 0 99
2:E 0 99 99 199
*: D 99 98 98 --,x
Source
Chil-
dren
Source
Chil-
dren
The Score S(E, D&apos;) = 100 + 100 = 200 The Score S D D = 199+ 100 = 299
</table>
<tableCaption confidence="0.962693">
Table 2: Computing Child-Scoring Matrices
</tableCaption>
<listItem confidence="0.73655975">
3. Repeat the above step until no more pairs
can be added to Pbest at most d times.
where d = min(d(v), d(v/)).
4. Compute the result:
</listItem>
<equation confidence="0.601017">
S (v, = Lexnode (v, + E(i.J)Ep..„
</equation>
<bodyText confidence="0.996827">
The greedy algorithm aligns trees with 71
nodes and maximal degree d in 0(n2d2) time.
</bodyText>
<sectionHeader confidence="0.833784" genericHeader="method">
4 Acquiring Transfer Rules
</sectionHeader>
<bodyText confidence="0.969649578947368">
This section describes the procedure for deriving
transfer rules from aligned parse trees.
First, the best-scoring alignment is recovered
from the Children-Pairing matrix, (Table 1(b)).4
Start by including the root node-pair in the
alignment, (here (D. D&apos;)). Then, for each pair
(v, v&apos;) already in the alignment, repeat the fol-
lowing steps, until no more pairs can be added to
the alignment: (1) look up the Children-Pairing
for (v. v&apos;); (2) for each pair in the children-
pairing, if it does not include either v or v&apos;, add
the pair to the alignment, (e.g. (A, A&apos;), etc.).
&apos;When sentences in the bitext have multiple parses,
we align structure sharing forests of trees. If one pair
of trees has the highest scoring alignment, we acquire
transfer rules from that alignment. When more than one
pair of trees tie for the highest score, we acquire transfer
rules from the set of pairs of aligned subtrees which are
shared by each of these high scoring alignments.
In the running example, the final align-
ment (F.4) is {(D, D&apos;), (A, A&apos;), (B, B&apos;), (C,C&apos;)}.
Based on this alignment we can &amp;quot;chop up&amp;quot; the
trees into fragments, or substructures ((Mat-
sumoto et al., 1993)), where each substructure
of a tree is a connected group of nodes in the
tree, together with their joining arcs. In Fig-
ure 1, dashed arrows connect aligned pairs of
source and target substructures. These corre-
spondences become our transfer rules.
For each pair of aligned nodes (v. v&apos;) in F.4,
there is a pair of substructures in Figure 1 such
that v and v&apos; are the roots of the source and tar-
get substructures. These substructures include
all unaligned source and target nodes v,, and
v&apos;u. below v and v&apos;, which have no intervening
aligned nodes y or y&apos; dominating vu, or v.
The transfer rules derived from Figure 1 may
be written as follows:
</bodyText>
<reference confidence="0.543925666666667">
1. &lt; root: Excel &gt; &lt; root : Excel &gt;
2. &lt; root : valores &gt; &lt; root : values &gt;
3. &lt; root : libro, de : trabajo &gt; &lt; root :
workbook &gt;
4. &lt; •root : volver, subj : x1. a :&lt; root :
calcular, obj : x2, en: x3 &gt;&gt;
&lt; root : recalculate, subj : Tr(xi),obj :
Tr(x2), in :Tr(x3) &gt;
Each substructure is represented as a list con-
</reference>
<page confidence="0.997408">
846
</page>
<bodyText confidence="0.999835909090909">
taming a root lexical item, and a set of arc-
value pairs. An arc (role) al with head (value)
h is written as al : h, where h is a fixed la-
bel (word), a substructure or a variable. If the
source substructure has n of the leaves labeled
with variables xl, xn, the target will have
n of the leaves labeled with Tr (xi) ,
where Tr(x) is the lexical translation function.
This general structure allows us to capture re-
lations between multi-word expressions in the
source and target languages.
</bodyText>
<sectionHeader confidence="0.998135" genericHeader="method">
5 Translation
</sectionHeader>
<bodyText confidence="0.999982086956522">
The described procedure for acquisition of trans-
fer rules from corpora is the basis for our trans-
lation system. A large collection of transfer rules
are collected from a training corpus. When new
text is to be translated, it is first parsed. The
source tree is matched against the left hand sides
of the transfer rules which have been collected.
If a set of transfer rules whose left-hand sides
match the parse tree is found. the corresponding
target structure is generated from the right hand
sides of these transfer rules. Typically, several
sets of transfer rules meet this criterion. They
are ranked by their frequency in the training cor-
pus. Once a target tree has been produced. it is
converted to a word sequence by a target lan-
guage generator. We have applied this approach
to the translation of Microsoft Help files in En-
glish and Spanish. The sentences are moderately
simple and quite parallel in structure. which has
made the corpus suitable for our initial system
development. To date, we have been using a
training corpus of about 1,000 sentences, and a
test corpus of about 100 sentences.
</bodyText>
<sectionHeader confidence="0.999468" genericHeader="conclusions">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.99986796969697">
Real evaluation of performance of MT systems
is time consuming and subjective. Neverthe-
less, some evaluation system is needed to insure
that incremental changes are for the better, or
at least, are not detrimental. We measured the
success of our translation by how closely we re-
produced Microsoft&apos;s English (target language)
text. Our evaluation procedure computes the
ratio between (a) the complement of the inter-
section set of words in our translation and the
actual Microsoft sentence; and (b) the combined
lengths of these two sentences. An exact trans-
lation gives a score of 0. If the system generates
the sentence &amp;quot;A B C D E&amp;quot; and the actual sen-
tence is &amp;quot;A B C F&amp;quot;, the score is 3/9 (the length
of D E F divided by the combined lengths of
ABCDEandABCF.) The dominance-
preserving version of the program produced out-
put for 88 out of 91 test sentences. The average
score for these 88 sentences was 0.29: 0.21 due
to incorrect word matches and 0.08 due to failure
to translate because insufficient confidence levels
were reached. The LCA-preserving version pro-
duced output for only 83 sentences with an aver-
age score of over 0.30: about 0.23 due to incor-
rect word matches and about 0.08 due to insuffi-
cient confidence levels. This crude scoring tech-
nique suggests that the dominance-preserving al-
gorithm improved our results: more sentences
were translated with higher quality. One limita-
tion of this scoring technique is that paraphrases
are penalized. An imperfect score (even .20)
may signify an adequate translation.
</bodyText>
<sectionHeader confidence="0.999116" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999858034482758">
A. Abeille, Y. Schabes. and A. K. Joshi. 1990.
Using Lexicalized Tags for Machine Transla-
tion. In COLING90.
M. Farad&apos;, T. M. Przytycka, and M. Thorup.
1995. On the agreement of many trees. Infor-
mation Processing Letters, 55:297-301.
0. Furuse and H. Iida. 1994. Constituent
Boundary Parsing for Example-Based Ma-
chine Translation. In COLING94.
R. Grishman. 1994. Iterative Alignment of Syn-
tactic Structures for a Bilingual Corpus.. In
Proceedings of the Second Annual Workshop
for Very Large Corpora, Tokyo.
H. Kaji, Y. Kida, and Y. Morimoto. 1992.
Learning Translation Templates from Bilin-
anal Text. In COLING92.
M. Kitamura and Y. Matsumoto. 1995. A Ma-
chine Translation System based on Transla-
tion Rules Acquired from Parallel Corpora. In
RANLP95.
Y. Matsumoto, H. Ishimoto. T. Utsuro, and
M. Nagao. 1993. Structural Matching of Par-
allel Texts. In ACL93.
A. Meyers, R. Yangarber, and R. Grishman.
1996. Alignment of Shared Forests for Bilin-
gual Corpora. In COLING96, pages 460-465.
S. Sato and M. Nagao. 1990. Toward Memory-
based Translation. In COLING90, volume 3.
pages 247-252.
</reference>
<page confidence="0.998227">
847
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.719227">
<title confidence="0.999944">Deriving Transfer Rules from Dominance-Preserving Alignments</title>
<author confidence="0.9968465">Adam Meyers</author>
<author confidence="0.9968465">Roman Yangarber</author>
<author confidence="0.9968465">Ralph Grishman</author>
<author confidence="0.9968465">Catherine Macleod</author>
<author confidence="0.9968465">Antonio Moreno—Sandovalt</author>
<affiliation confidence="0.999767">New York University</affiliation>
<address confidence="0.999973">715 Broadway, 7th Floor, NY, NY 10003, USA</address>
<affiliation confidence="0.844589">tUniversidad AutOnoma de Madrid</affiliation>
<address confidence="0.973985">Cantoblanco, 28049-Madrid, SPAIN</address>
<email confidence="0.998515">meyers/roman/grishman/macleodOcs.nyu.edu</email>
<intro confidence="0.861081">sandova101ola.111f.uam.es</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>root</author>
</authors>
<booktitle>Excel &gt; &lt; root : Excel &gt;</booktitle>
<contexts>
<context position="1090" citStr="(1)" startWordPosition="150" endWordPosition="150">ion (MT) systems treat aligned sentences as unstructured word sequences. Other systems, including our own ((Grishman, 1994) and (Meyers et al., 1996)), syntactically analyze sentences (parse) before acquiring transfer rules (cf. (Kaji et al., 1992), (Matsumoto et al., 1993), and (Kitamura and Matsumoto, 1995)). This has the advantage of acquiring structural as well as lexical correspondences. A syntactically analyzed, aligned corpus may serve as an example base for a form of example-based MT (cf. (Sato and Nagao, 1990), (Kaji et al., 1992), and (Furuse and Iida. 1994)). This paperl describes: (1) an efficient algorithm for aligning a pair of source/target language parse trees; and (2) a procedure for deriving transfer rules from this alignment. Each transfer rule consists of a pair of tree fragments derived by &amp;quot;cutting up&amp;quot; the source and target trees. A set of transfer rules whose left-hand sides match a source language parse tree is used to generate a target language parse tree from their set of right-hand sides. which is a translation of the source tree. This technique resembles work on MT using synchronous Tree-Adjoining Grammars (cf. (Abeille et al.. 1990)). The Proteus translatio</context>
<context position="3140" citStr="(1)" startWordPosition="492" endWordPosition="492">ionship: If node a dominates node b in the source tree. then 1(a) dominates f (b) in the target tree. In Figure 1. source nodes .4. B, C and D map to the corresponding target nodes. marked with a prime, e.g., f (A) = .4&apos;. The alignment may be represented by the set {(A, A&apos;), (B, B&apos;), (C. C&apos;). (D. D&apos;)} . We can assign a score to each alignment f based on the (weighted) number of pairs in f; finding the best alignment translates into finding the alignment with the highest score. Our algorithms are based on (Farach et al., 1995) and related work. We needed efficient alignment algorithms because: (1) Corpus-based training requires processing a lot of text; and (2) An exhaustive search of all alignments is too computationally expensive for realistically sized parse trees. Eliminating dominance violations greatly reduced our search space. Similar work (e.g., (Matsumoto et al., 1993)) considers all possible matches. Although. our system cannot account for actual dominance violations in a given bitext, there are no such violations in our corpus and many hypothetical cases can be avoided by adopting the appropriate grammar. Cases of adjuncts aligning with heads and vice versa are not dominance</context>
<context position="9985" citStr="(1)" startWordPosition="1767" endWordPosition="1767">eter functions used above, such. as the penalty function Pen and the translation measures, are chosen empirically, and constitute the tunable parameters of the procedure. Normally, we will expect that the values of Lexnode will be much larger than the values of Lex,, and Pen. In the example we used the following settings: 1. Lex„de = 100 for an exact translation, as for (A, A&apos;), (B, if) and (C, C&apos;), and 0 otherwise. 2. all values of Lex,, are set to zero 3. all penalties Pen are set to 1 Now, using the values in M, compute the score for matching v and v&apos;: S(v, vi) = Leznode(v, vi) + max E mi, (1) PE CP (i,j)EP Here P is a legitimate pairing of v and its children against v&apos; and its children. A legitimate pairing P is a set of elements of the matrix M. that conform to the following conditions: 1. each row and each column of M may contribute at most one element to P. except that the row and the column labeled * may contribute more than one element to P 2. if P contains an element Mii corresponding to the node pair (w. w&apos;), and some child node u appears in the Children-Pairing for (w, w&apos;), then the row or column of a may not contribute any elements to P. We use CP = GP (v .v&apos;) to denote t</context>
<context position="11279" citStr="(1)" startWordPosition="2033" endWordPosition="2033"> the degrees of v and v&apos;. The summation in (1) ranges over all the pairs (i, j) that appear in a legitimate pairing P E ,CP(v, v&apos;). We evaluate this summation for all 0(d!) legitimate pairings in LP and then select the pairing Pb&amp;quot;t with the maximum score. Pbest is then stored in the Children-Pairing matrix entry for (v, v&apos;). Table 2 shows how scores are calculated. The best score for S(E, D&apos;) is 200, the sum of the scores for (B, B&apos;) and (C. C&apos;). S(D. D&apos;) = 299 = S (A, A&apos;) + S(E. D&apos;) — 1, a penalty of 1 for collapsing the edge from D to E. We can reduce the computation time of the max term in (1), if we do not consider all 0(d!) pairings of the children of v and v&apos;. Instead of exhaustively computing the maximal-scoring pairingPbest in (1), we can build it in a greedy fashion: successively choos the d highest-scoring, mutually disjoint pairs from the 0(e) possible pairs of children of v and v&apos;. 1. Initialize the set of highest scoring pairs Pbest 2. Pbest PbestU {(i, j)} where Mij is the next largest entry in the matrix, which that satisfies both conditions 1 and 2 of legitimate pairings 845 Target Nodes Target Nodes Source Nodes Source Nodes A&apos; B&apos; C&apos; D&apos; A 100 0 0 0 B 0 100 0 0 C 0 0 1</context>
<context position="13075" citStr="(1)" startWordPosition="2410" endWordPosition="2410"> d times. where d = min(d(v), d(v/)). 4. Compute the result: S (v, = Lexnode (v, + E(i.J)Ep..„ The greedy algorithm aligns trees with 71 nodes and maximal degree d in 0(n2d2) time. 4 Acquiring Transfer Rules This section describes the procedure for deriving transfer rules from aligned parse trees. First, the best-scoring alignment is recovered from the Children-Pairing matrix, (Table 1(b)).4 Start by including the root node-pair in the alignment, (here (D. D&apos;)). Then, for each pair (v, v&apos;) already in the alignment, repeat the following steps, until no more pairs can be added to the alignment: (1) look up the Children-Pairing for (v. v&apos;); (2) for each pair in the childrenpairing, if it does not include either v or v&apos;, add the pair to the alignment, (e.g. (A, A&apos;), etc.). &apos;When sentences in the bitext have multiple parses, we align structure sharing forests of trees. If one pair of trees has the highest scoring alignment, we acquire transfer rules from that alignment. When more than one pair of trees tie for the highest score, we acquire transfer rules from the set of pairs of aligned subtrees which are shared by each of these high scoring alignments. In the running example, the final al</context>
</contexts>
<marker>1.</marker>
<rawString>&lt; root: Excel &gt; &lt; root : Excel &gt;</rawString>
</citation>
<citation valid="false">
<authors>
<author>root</author>
</authors>
<title>valores &gt; &lt; root : values &gt;</title>
<contexts>
<context position="1180" citStr="(2)" startWordPosition="166" endWordPosition="166">cluding our own ((Grishman, 1994) and (Meyers et al., 1996)), syntactically analyze sentences (parse) before acquiring transfer rules (cf. (Kaji et al., 1992), (Matsumoto et al., 1993), and (Kitamura and Matsumoto, 1995)). This has the advantage of acquiring structural as well as lexical correspondences. A syntactically analyzed, aligned corpus may serve as an example base for a form of example-based MT (cf. (Sato and Nagao, 1990), (Kaji et al., 1992), and (Furuse and Iida. 1994)). This paperl describes: (1) an efficient algorithm for aligning a pair of source/target language parse trees; and (2) a procedure for deriving transfer rules from this alignment. Each transfer rule consists of a pair of tree fragments derived by &amp;quot;cutting up&amp;quot; the source and target trees. A set of transfer rules whose left-hand sides match a source language parse tree is used to generate a target language parse tree from their set of right-hand sides. which is a translation of the source tree. This technique resembles work on MT using synchronous Tree-Adjoining Grammars (cf. (Abeille et al.. 1990)). The Proteus translation system learns transfer rules from pairs of aligned source and target regularized parses,</context>
<context position="3205" citStr="(2)" startWordPosition="503" endWordPosition="503"> dominates f (b) in the target tree. In Figure 1. source nodes .4. B, C and D map to the corresponding target nodes. marked with a prime, e.g., f (A) = .4&apos;. The alignment may be represented by the set {(A, A&apos;), (B, B&apos;), (C. C&apos;). (D. D&apos;)} . We can assign a score to each alignment f based on the (weighted) number of pairs in f; finding the best alignment translates into finding the alignment with the highest score. Our algorithms are based on (Farach et al., 1995) and related work. We needed efficient alignment algorithms because: (1) Corpus-based training requires processing a lot of text; and (2) An exhaustive search of all alignments is too computationally expensive for realistically sized parse trees. Eliminating dominance violations greatly reduced our search space. Similar work (e.g., (Matsumoto et al., 1993)) considers all possible matches. Although. our system cannot account for actual dominance violations in a given bitext, there are no such violations in our corpus and many hypothetical cases can be avoided by adopting the appropriate grammar. Cases of adjuncts aligning with heads and vice versa are not dominance violations if we replace our dependency analysis with one in whi</context>
<context position="13121" citStr="(2)" startWordPosition="2418" endWordPosition="2418">te the result: S (v, = Lexnode (v, + E(i.J)Ep..„ The greedy algorithm aligns trees with 71 nodes and maximal degree d in 0(n2d2) time. 4 Acquiring Transfer Rules This section describes the procedure for deriving transfer rules from aligned parse trees. First, the best-scoring alignment is recovered from the Children-Pairing matrix, (Table 1(b)).4 Start by including the root node-pair in the alignment, (here (D. D&apos;)). Then, for each pair (v, v&apos;) already in the alignment, repeat the following steps, until no more pairs can be added to the alignment: (1) look up the Children-Pairing for (v. v&apos;); (2) for each pair in the childrenpairing, if it does not include either v or v&apos;, add the pair to the alignment, (e.g. (A, A&apos;), etc.). &apos;When sentences in the bitext have multiple parses, we align structure sharing forests of trees. If one pair of trees has the highest scoring alignment, we acquire transfer rules from that alignment. When more than one pair of trees tie for the highest score, we acquire transfer rules from the set of pairs of aligned subtrees which are shared by each of these high scoring alignments. In the running example, the final alignment (F.4) is {(D, D&apos;), (A, A&apos;), (B, B&apos;), (</context>
</contexts>
<marker>2.</marker>
<rawString>&lt; root : valores &gt; &lt; root : values &gt;</rawString>
</citation>
<citation valid="false">
<authors>
<author>root</author>
</authors>
<title>libro, de : trabajo &gt; &lt; root : workbook &gt;</title>
<marker>3.</marker>
<rawString>&lt; root : libro, de : trabajo &gt; &lt; root : workbook &gt;</rawString>
</citation>
<citation valid="true">
<authors>
<author>•root</author>
</authors>
<title>volver, subj : x1. a :&lt; root : calcular, obj : x2, en:</title>
<date>1990</date>
<booktitle>x3 &gt;&gt; &lt; root : recalculate, subj : Tr(xi),obj : Tr(x2), in :Tr(x3) &gt; Each substructure is represented as a list</booktitle>
<marker>4.</marker>
<rawString>&lt; •root : volver, subj : x1. a :&lt; root : calcular, obj : x2, en: x3 &gt;&gt; &lt; root : recalculate, subj : Tr(xi),obj : Tr(x2), in :Tr(x3) &gt; Each substructure is represented as a list conA. Abeille, Y. Schabes. and A. K. Joshi. 1990. Using Lexicalized Tags for Machine Translation. In COLING90. M. Farad&apos;, T. M. Przytycka, and M. Thorup.</rawString>
</citation>
<citation valid="false">
<title>On the agreement of many trees.</title>
<journal>Information Processing Letters,</journal>
<pages>55--297</pages>
<marker>1995.</marker>
<rawString>On the agreement of many trees. Information Processing Letters, 55:297-301.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Furuse</author>
<author>H Iida</author>
</authors>
<title>Constituent Boundary Parsing for Example-Based Machine Translation. In</title>
<date>1994</date>
<booktitle>In Proceedings of the Second Annual Workshop for Very Large Corpora,</booktitle>
<location>Tokyo.</location>
<marker>0.</marker>
<rawString>Furuse and H. Iida. 1994. Constituent Boundary Parsing for Example-Based Machine Translation. In COLING94. R. Grishman. 1994. Iterative Alignment of Syntactic Structures for a Bilingual Corpus.. In Proceedings of the Second Annual Workshop for Very Large Corpora, Tokyo. H. Kaji, Y. Kida, and Y. Morimoto. 1992. Learning Translation Templates from Bilinanal Text. In COLING92. M. Kitamura and Y. Matsumoto. 1995. A Machine Translation System based on Translation Rules Acquired from Parallel Corpora. In RANLP95. Y. Matsumoto, H. Ishimoto. T. Utsuro, and M. Nagao. 1993. Structural Matching of Parallel Texts. In ACL93. A. Meyers, R. Yangarber, and R. Grishman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sato</author>
<author>M Nagao</author>
</authors>
<title>Alignment of Shared Forests for Bilingual Corpora. In</title>
<date>1990</date>
<booktitle>COLING96,</booktitle>
<volume>3</volume>
<pages>460--465</pages>
<marker>1996.</marker>
<rawString>Alignment of Shared Forests for Bilingual Corpora. In COLING96, pages 460-465. S. Sato and M. Nagao. 1990. Toward Memorybased Translation. In COLING90, volume 3. pages 247-252.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>