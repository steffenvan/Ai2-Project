<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011005">
<title confidence="0.999377">
Predicting Power Relations between Participants
in Written Dialog from a Single Thread
</title>
<author confidence="0.996372">
Vinodkumar Prabhakaran
</author>
<affiliation confidence="0.987866">
Dept. of Computer Science
Columbia University, New York, NY
</affiliation>
<email confidence="0.998281">
vinod@cs.columbia.edu
</email>
<sectionHeader confidence="0.993892" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999968125">
We introduce the problem of predicting
who has power over whom in pairs of peo-
ple based on a single written dialog. We
propose a new set of structural features.
We build a supervised learning system to
predict the direction of power; our new
features significantly improve the results
over using previously proposed features.
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999787896551724">
Computationally analyzing the social context in
which language is used has gathered great interest
within the NLP community recently. One of the
areas that has generated substantial research is the
study of how social power relations between peo-
ple affect and/or are revealed in their interactions
with one another. Researchers have proposed sys-
tems to detect social power relations between par-
ticipants of organizational email threads (Bramsen
et al., 2011; Gilbert, 2012; Prabhakaran and Ram-
bow, 2013), online forums (Danescu-Niculescu-
Mizil et al., 2012; Biran et al., 2012; Danescu-
Niculescu-Mizil et al., 2013), chats (Strzalkowski
et al., 2012), and off-line interactions such as pres-
idential debates (Prabhakaran et al., 2013; Nguyen
et al., 2013). Automatically identifying power and
influence from interactions can have many prac-
tical applications ranging from law enforcement
and intelligence to online marketing.
A significant number of these studies are per-
formed in the domain of organizational email
where there is a well defined notion of power (or-
ganizational hierarchy). Bramsen et al. (2011) and
Gilbert (2012) predict hierarchical power relations
between people in the Enron email corpus using
lexical features extracted from all the messages
exchanged between them. However, their ap-
proaches primarily apply to situations where large
collections of messages exchanged between pairs
</bodyText>
<author confidence="0.447269">
Owen Rambow
</author>
<affiliation confidence="0.466933">
Cntr. for Comp. Learning Systems
Columbia University, New York, NY
</affiliation>
<email confidence="0.901861">
rambow@ccls.columbia.edu
</email>
<bodyText confidence="0.999913428571429">
of people are available. In (Prabhakaran and Ram-
bow, 2013), we introduced the problem of detect-
ing whether a participant of an email thread has
power over someone else in the thread and estab-
lished the importance of dialog structure in that
task. However, in that work we did not detect over
whom that person has power.
In this paper, we introduce a new problem for-
mulation. We predict the hierarchical power rela-
tion between pairs of participants in an email in-
teraction thread based solely on features extracted
from that thread. As a second major contribution,
we introduce a new set of features to capture as-
pects of participant behavior such as responsive-
ness, and we show that these features are signifi-
cantly correlated with the direction of power. We
present a fully automatic system for this task ob-
taining an accuracy of 73.0%, an improvement of
6.9% over 68.3% by a system using only lexical
features. This best-performing system uses our
new feature set.
</bodyText>
<sectionHeader confidence="0.989085" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.999932333333333">
Early NLP-based approaches such as Bramsen et
al. (2011) and Gilbert (2012) built systems to pre-
dict hierarchical power relations between people
in the Enron email corpus using lexical features
from all the messages exchanged between them.
One limitation of this approach is that it relies
solely on lexical cues and hence works best when
large collections of messages exchanged between
the pairs of people are available. For example,
Bramsen et al. (2011) excluded sender-recipient
pairs who exchanged fewer than 500 words from
their evaluation set, since they found smaller text
samples are harder to classify. By taking the mes-
sage out of the context of the interaction in which
it was exchanged, they fail to utilize cues from the
structure of interactions, which complements the
lexical cues in detecting power relations, as we
showed in (Prabhakaran and Rambow, 2013).
</bodyText>
<page confidence="0.988167">
339
</page>
<bodyText confidence="0.991255707317073">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 339–344,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
We modeled the problem of detecting power re-
lationships differently in (Prabhakaran and Ram-
bow, 2013): we predicted whether a participant
in an email thread has a certain type of power
or not. However, in that work we did not pre-
dict over whom he/she has that power. This
may result in noisy features; consider a thread in
which participant X has power over participant
Y, who has power over participant Z. By ag-
gregating features over all messages sent by Y,
features salient to a subordinate-superior interac-
tion are incorrectly conflated with those salient to
superior-subordinate interaction. Another limita-
tion of (Prabhakaran and Rambow, 2013) is that
we used manual annotations for many of our fea-
tures such as dialog acts and overt displays of
power. Relying on manual annotations for features
limited our analysis to a small subset of the Enron
corpus, which has only 18 instances of hierarchi-
cal power. Consequently, our findings with respect
to hierarchical power were weak in terms of both
correlations of features and system performance.
In this paper, we introduce the problem of pre-
dicting who has power over whom in pairs of inter-
acting participants based on a single thread of in-
teractions. From (Bramsen et al., 2011) we retain
the idea that we want to predict the power relation
between pairs of people. But in contrast to their
formulation, we retain the goal from (Prabhakaran
and Rambow, 2013) that we want to study com-
munication in the context of an interaction, and
that we want to be able to make predictions us-
ing only the emails exchanged in a single thread.
Like (Prabhakaran and Rambow, 2013), we use
features to capture the dialog structure, but we use
automatic taggers to generate them and assume no
manual annotation at all at training or test time.
This allows us to use the entire Enron email cor-
pus for this study.
</bodyText>
<sectionHeader confidence="0.99638" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999955">
In this work, we use the version of Enron email
corpus by Yeh and Harnly (2006) which captures
the thread structure of email exchanges. The cor-
pus contains 36,615 email threads. We excluded a
small subset of 419 threads that was used for pre-
vious manual annotation efforts, part of which was
also used to train the DA and ODP taggers (Sec-
tion 5) that generate features for our system. The
average number of email messages per thread was
around 3. We divided the remaining threads into
train (50%), dev (25%) and test (25%) sets by ran-
dom sampling. We then applied various basic NLP
preprocessing steps such as tokenization, POS tag-
ging and lemmatization to the body of email mes-
sages. We use the Enron gold organizational hier-
archy released by Agarwal et al. (2012) to model
hierarchical power. Their corpus was manually
built using information from Enron organizational
charts. It includes relations of 1,518 employees
and captures dominance relations between 13,724
pairs of them. Theirs is the largest such data set
available to the best of our knowledge.
</bodyText>
<sectionHeader confidence="0.979756" genericHeader="method">
4 Problem Formulation
</sectionHeader>
<bodyText confidence="0.998996296296296">
Let t denote an email thread and Mt denote the
set of all messages in t. Also, let Pt be the set
of all participants in t, i.e., the union of senders
and recipients (To and CC) of all messages in
Mt. We are interested in detecting power rela-
tions between pairs of participants who interact
within a given email thread. Not every pair of par-
ticipants (p1i p2) E Pt x Pt interact with one an-
other within t. Let IMt(p1i p2) denote the set of
Interaction Messages — non-empty messages in
t in which either pi is the sender and p2 is one
of the recipients or vice versa. We call the set of
(p1i p2) such that |IMt(p1i p2) |&gt; 0 the interact-
ing participant pairs of t (IPPt).
We focus on the manifestations of power in in-
teractions between people across different levels
of hierarchy. For every (p1i p2) E IPPt, we query
the set of dominance relations in the gold hierar-
chy to determine their hierarchical power relation
(HP(p1i p2)). We exclude pairs that do not exist
in the gold hierarchy from our analysis and denote
the remaining set of related interacting participant
pairs as RIPPt. We assign HP(p1i p2) to be su-
perior if p1 dominates p2, and subordinate if p2
dominates p1. Table 1 shows the total number of
pairs in IPPt and RIPPt from all the threads in
our corpus and across train, dev and test sets.
</bodyText>
<table confidence="0.9360125">
Description Total Train Dev Test
# of threads 36,196 18,079 8,973 9,144
Et JIPPtj 355,797 174,892 91,898 89,007
Et IRIPPtl 15,048 7,510 3,578 3,960
</table>
<tableCaption confidence="0.982151">
Table 1: Data Statistics
</tableCaption>
<bodyText confidence="0.63617075">
Row 1 presents the total number of threads in different
subsets of the corpus. Row 2 and 3 present the number of
interacting participant pairs (IPP) and related interacting
participant pairs (RIPP) in those subsets.
</bodyText>
<page confidence="0.987797">
340
</page>
<bodyText confidence="0.999223071428571">
Given a thread t and a pair of participants
(p1, p2) ∈ RIPPt, we want to automatically de-
tect HP(p1 , p2). This problem formulation is
similar to the ones in (Bramsen et al., 2011) and
(Gilbert, 2012). However, the difference is that for
us an instance is a pair of participants in a single
thread of interaction (which may or may not in-
clude other people), whereas for them an instance
constitutes all messages exchanged between a pair
of people in the entire corpus. Our formula-
tion also differs from (Prabhakaran and Rambow,
2013) in that we detect power relations between
pairs of participants, instead of just whether a par-
ticipant had power over anyone in the thread.
</bodyText>
<sectionHeader confidence="0.982609" genericHeader="method">
5 Structural Analysis
</sectionHeader>
<bodyText confidence="0.995760875000001">
In this section we analyze various features that
capture the structure of interaction between the
pairs of participants in a thread. Each feature f
is extracted with respect to a person p over a ref-
erence set of messages M (denoted fpM). For a
pair (p1 , p2), we extract 4 versions of each fea-
ture f : fp1
IMt(p1,p2), fp2
IMt(p1,p2), fMt p1 and fMtp2. The
first two capture behavior of the pair among them-
selves, while the third and fourth capture their
overall behavior in the entire thread. We group our
features into three categories — THRNew, THRPR
and DIAPR. THRNew is a set of new features we
propose, while THRPR and DIAPR incorporate fea-
tures we proposed in (Prabhakaran and Rambow,
2013). THRNew and THRPR capture the structure
of message exchanges without looking at the con-
tent of the emails (e.g., how many emails did a per-
son send), while DIAPR captures the pragmatics of
the dialog and requires an analysis of the content
of the emails (e.g., did they issue any requests).
THRNew: This is a new set of features we in-
troduce in this paper. It includes the average num-
ber of recipients (AvgRecipients) and To recipients
(AvgToRecipients) in emails sent by p, the per-
centage of emails p received in which he/she was
in the To list (InToList%), boolean features de-
noting whether p added or removed people when
responding to a message (AddPerson and Re-
movePerson), average number of replies received
per message sent by p (ReplyRate) and average
number of replies received from the other person
of the pair to messages where he/she was a To re-
cipient (ReplyRateWithinPair). ReplyRateWithin-
Pair applies only to IMt(p1 , p2).
THRPR: This feature set includes two meta-
data based feature sets — positional and verbosity.
Positional features include a boolean feature to de-
note whether p sent the first message (Initiate),
and relative positions of p’s first and last messages
(FirstMsgPos and LastMsgPos) in M. Verbosity
features include p’s message count (MsgCount),
message ratio (MsgRatio), token count (Token-
Count), token ratio (TokenRato) and tokens per
message (TokenPerMsg), all calculated over M.
DIAPR: In (Prabhakaran and Rambow, 2013),
we used dialog features derived from manual an-
notations — dialog acts (DA) and overt displays
of power (ODP) — to model the structure of inter-
actions within the message content. In this work,
we obtain DA and ODP tags on the entire cor-
pus using automatic taggers trained on those man-
ual annotations. The DA tagger (Omuya et al.,
2013) obtained an accuracy of 92%. The ODP
tagger (Prabhakaran et al., 2012) obtained an ac-
curacy of 96% and F-measure of 54%. The DA
tagger labels each sentence to be one of the 4
dialog acts: Request Action, Request Informa-
tion, Inform, and Conventional. The ODP Tag-
ger identifies sentences (mostly requests) that ex-
press additional constraints on its response, be-
yond those introduced by the dialog act. We use
5 features: ReqAction%, ReqInform%, Inform%,
Conventional%, and ODP% to capture the per-
centage of sentences in messages sent by p that has
each of these labels. We also use a feature to cap-
ture the number of p’s messages with a request that
did not get a reply, i.e., dangling requests (Dan-
glingReq%), over all messages sent by p.
We perform an unpaired two-sample two-tailed
Student’s t-Test comparing mean values of each
feature for subordinates vs. superiors. For our
analysis, a data point is a related interacting pair,
and not a message. Hence, a message with mul-
tiple recipients who have a superior/subordinate
relation with the sender will contribute to features
for multiple data points. We limit our analysis to
the related interacting pairs from only our train
set. Table 2 presents mean values of features for
subordinates and superiors at the interaction level.
Thread level versions of these features also ob-
tained similar results overall in terms of direction
of difference and significance. We denote three
significance levels — * (p &lt; .05), ** (p &lt; .01),
and *** (p &lt; .001). To control false discovery
rates in multiple testing, we adjusted the p-values
(Benjamini and Hochberg, 1995). We summarize
</bodyText>
<page confidence="0.985401">
341
</page>
<table confidence="0.999794538461538">
Feature Name Mean(f sub Mean(f sup
��� ) ��� )
THRNew
AvgRecipients*** 21.14 43.10
AvgToRecipients*** 18.19 38.94
InToList% 0.82 0.80
ReplyRate*** 0.86 1.23
ReplyRateWithinPair*** 0.16 0.10
AddPerson 0.48 0.47
RemovePerson*** 0.41 0.37
THRPR
Initiate*** 0.45 0.56
FirstMsgPos 0.04 0.03
LastMsgPos*** 0.15 0.11
MsgCount*** 0.64 0.70
MsgRatio*** 0.44 0.56
TokenCount 91.22 83.26
TokenRatio*** 0.45 0.55
TokenPerMsg* 140.60 120.87
DIAPR
Conventional%*** 0.15 0.17
Inform%*** 0.78 0.72
ReqAction%*** 0.02 0.04
ReqInform%*** 0.05 0.06
DanglingReq%*** 0.12 0.15
ODP%*** 0.03 0.06
</table>
<tableCaption confidence="0.97049475">
Table 2: Student’s t-Test Results of fpIMt.
THRNew: new meta-data features; THRPR, DIAPR: meta-data
and dialog-act features from previous studies;
* (p &lt; .05); ** (p &lt; .01); *** (p &lt; .001)
</tableCaption>
<bodyText confidence="0.890774">
the main findings on the significant features below.
</bodyText>
<listItem confidence="0.9931729375">
1. Superiors send messages addressed to more
people (AvgRecipients and AvgToRecipi-
ents). Consequently, they get more replies to
their messages (ReplyRate). However, con-
sidering messages where the other person of
the pair is addressed in the To list (ReplyRate-
WithinPair), subordinates get more replies.
2. Superiors issue more requests (ReqAction%
and ReqInform%) and overt displays of
power (ODP%). Subordinates issue more
informs (Inform%) and, surprisingly, have
fewer unanswered requests (DanglingReq%).
3. Superiors initiate the interactions more often
than subordinates (Initiate). They also leave
interactions earlier (LastMsgPos).
4. Superiors send shorter messages (Token-
</listItem>
<bodyText confidence="0.952487558823529">
PerMsg). They also send more messages
(MsgCount &amp; MsgRatio) and even contribute
a higher ratio of tokens in the thread (Token-
Ratio) despite sending shorter messages.
Finding 1 goes in line with findings from stud-
ies analyzing social networks that superiors have
higher connectivity in the networks that they are
part of (Rowe et al., 2007). Intuitively, those who
have higher connectivity also send emails to larger
number of people, and hence our result. Since su-
periors address more people in their emails, they
also have a higher chance of getting replies. Find-
ing 2 also aligns with the general intuition about
how superiors and subordinates behave within in-
teractions (e.g., superiors exhibit more overt dis-
plays of power than subordinates).
Findings 3 &amp; 4 are interesting since they re-
veal special characteristics of threads involving hi-
erarchically related participants. In (Prabhakaran
and Rambow, 2013), we had found that persons
with hierarchical power rarely initiated threads
and contributed less within the threads. But that
problem formulation was different — we were
identifying whether a person in a given thread had
hierarchical power over someone else or not. The
data points in that formulation included partici-
pants from threads that did not have any hierar-
chically related people, whereas our current for-
mulation do not. These findings suggest that if a
person starts an email thread, he’s likely not to be
the one who has power, but if a thread includes a
pair of people who are hierarchically related, then
it is likely to be initiated by the superior and he/she
tends to contribute more in such threads.
</bodyText>
<sectionHeader confidence="0.957979" genericHeader="method">
6 Predicting Direction of Power
</sectionHeader>
<bodyText confidence="0.999994894736842">
We build an SVM-based supervised learning sys-
tem that can predict HP(p1, p2) to be either su-
perior or subordinate based on the interaction
within a thread t for any pair of participants
(p1 , p2) ∈ RIPPt. We deterministically fix the
order of participants in (p1, p2) such that p1 is the
sender of the first message in IMt(p1 , p2 ). We
use the ClearTK (Ogren et al., 2008) wrapper for
SVMLight (Joachims, 1999) in our experiments.
We use the related interacting participant pairs in
threads from the train set to train our models and
optimize our performance on those from the dev
set. We report results obtained on dev and test sets.
In our formulation, values of many features are
undefined for some instances (e.g., Inform% is un-
defined when MsgCount = 0). Handling of unde-
fined values for features in SVM is not straight-
forward. Most SVM implementations assume the
value of 0 by default in such cases, conflating them
</bodyText>
<page confidence="0.993426">
342
</page>
<table confidence="0.999939875">
Description Accuracy
Baseline (Always Superior) 52.54
Baseline (Word Unigrams + Bigrams) 68.56
THRNew 55.90
THRPR 54.30
DIAPR 54.05
THRPR + THRNew 61.49
DIAPR + THRPR + THRNew 62.47
LEX 70.74
LEX + DIAPR + THRPR 67.44
LEX + DIAPR + THRPR + THRNew 68.56
BEST (= LEX + THRNew) 73.03
BEST (Using p1 features only) 72.08
BEST (Using IMt features only) 72.11
BEST (Using Mt only) 71.27
BEST (No Indicator Variables) 72.44
</table>
<tableCaption confidence="0.85324925">
Table 3: Accuracies on feature subsets (dev set).
THRNew: new meta-data features; THRPR, DIAPR: meta-data
and dialog-act features from previous studies; LEX: ngrams;
BEST: best subset; IMt stands for IMt(p1, p2)
</tableCaption>
<bodyText confidence="0.999952387096774">
with cases where Inform% is truly 0. In order to
mitigate this issue, we use an indicator feature for
each structural feature to denote whether or not it
is valid. Since we use a quadratic kernel, we ex-
pect the SVM to pick up the interaction between
each feature and its indicator feature.
Lexical features have already been shown to be
valuable in predicting power relations (Bramsen
et al., 2011; Gilbert, 2012). We use another fea-
ture set LEX to capture word ngrams, POS (part
of speech) ngrams and mixed ngrams. A mixed
ngram (Prabhakaran et al., 2012) is a special case
of word ngram where words belonging to open
classes are replaced with their POS tags. We found
the best setting to be using both unigrams and bi-
grams for all three types of ngrams, by tuning in
our dev set. We then performed experiments using
all subsets of {LEX, THRNew, THRPR, DIAPR }.
Table 3 presents the results obtained using var-
ious feature subsets. We use a majority class
baseline assigning HP(p1i p2) to be always su-
perior, which obtains 52.5% accuracy. We also
use a stronger baseline using word unigrams and
bigrams as features, which obtained an accuracy
of 68.6%. The performance of the system using
each structural feature class on its own is very
low. Combining all three of them improves the
accuracy to 62.5%. The highest performance ob-
tained without using any message content is for
THRPR and THRNew (61.5%). LEX features by
itself obtain a very high accuracy of 70.7%, con-
firming the importance of lexical patterns in this
task. Perplexingly, adding all structural features to
LEX reduces the accuracy by around 2.2 percent-
age points. The best performing system (BEST)
uses LEX and THRNew features and obtains an
accuracy of 73.0%, a statistically significant im-
provement over the LEX-only system (McNemar).
We also performed an ablation study to under-
stand the importance of different slices of our fea-
ture sets. If we remove all feature versions with
respect to the second person, the accuracy drops
to 72.1%. This suggests that features about the
other person’s behavior also help the prediction
task. If we remove either the thread level versions
of features or interaction level versions of features,
the accuracy again drops, suggesting that both the
pair’s behavior among themselves, and their over-
all behavior in the thread add value to the predic-
tion task. Removing the indicator feature denot-
ing the structural features’ validity also reduces
the performance of the system.
We now discuss evaluation on our blind test set.
The majority baseline (Always Superior) for ac-
curacy is 55.0%. The word unigrams and bigrams
baseline obtains an accuracy of 68.3%. The LEX
system (using other forms of ngrams as well) ob-
tains a slightly lower accuracy of 68.1%. Our
BEST system using LEX and THRNew features
obtains an accuracy of 73.0% (coincidentally the
same as on the dev set), an improvement of 6.9%
over the system using only lexical features.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999982111111111">
We introduced the problem of predicting who has
power over whom based on a single thread of writ-
ten interactions. We introduced a new set of fea-
tures which describe the structure of the dialog.
Using this feature set, we obtain an accuracy of
73.0% on a blind test. In future work, we will
tackle the problem of three-way classification of
pairs of participants, which will cover cases in
which they are not in a power relation at all.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999833166666667">
This paper is based upon work supported by the
DARPA DEFT Program. The views expressed are
those of the authors and do not reflect the official
policy or position of the Department of Defense
or the U.S. Government. We also thank several
anonymous reviewers for their feedback.
</bodyText>
<page confidence="0.998748">
343
</page>
<sectionHeader confidence="0.982813" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998154718446602">
Apoorv Agarwal, Adinoyi Omuya, Aaron Harnly, and
Owen Rambow. 2012. A Comprehensive Gold
Standard for the Enron Organizational Hierarchy. In
Proceedings of the 50th Annual Meeting of the ACL
(Short Papers), pages 161–165, Jeju Island, Korea,
July. Association for Computational Linguistics.
Yoav Benjamini and Yosef Hochberg. 1995. Control-
ling the false discovery rate: a practical and pow-
erful approach to multiple testing. Journal of the
Royal Statistical Society. Series B (Methodological),
pages 289–300.
Or Biran, Sara Rosenthal, Jacob Andreas, Kathleen
McKeown, and Owen Rambow. 2012. Detecting
influencers in written online conversations. In Pro-
ceedings of the Second Workshop on Language in
Social Media, pages 37–45, Montr´eal, Canada, June.
Association for Computational Linguistics.
Philip Bramsen, Martha Escobar-Molano, Ami Patel,
and Rafael Alonso. 2011. Extracting social power
relationships from natural language. In Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 773–782, Portland, Oregon, USA,
June. Association for Computational Linguistics.
Cristian Danescu-Niculescu-Mizil, Lillian Lee,
Bo Pang, and Jon Kleinberg. 2012. Echoes of
power: language effects and power differences in
social interaction. In Proceedings of the 21st in-
ternational conference on World Wide Web, WWW
’12, New York, NY, USA. ACM.
Cristian Danescu-Niculescu-Mizil, Moritz Sudhof,
Dan Jurafsky, Jure Leskovec, and Christopher Potts.
2013. A computational approach to politeness with
application to social factors. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
250–259, Sofia, Bulgaria, August. Association for
Computational Linguistics.
Eric Gilbert. 2012. Phrases that signal workplace hier-
archy. In Proceedings of the ACM 2012 conference
on Computer Supported Cooperative Work, CSCW
’12, pages 1037–1046, New York, NY, USA. ACM.
Thorsten Joachims. 1999. Making Large-Scale SVM
Learning Practical. In Bernhard Sch¨olkopf, Christo-
pher J.C. Burges, and A. Smola, editors, Advances
in Kernel Methods - Support Vector Learning, Cam-
bridge, MA, USA. MIT Press.
Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik,
Deborah A. Cai, Jennifer E. Midberry, and Yuanxin
Wang. 2013. Modeling topic control to detect in-
fluence in conversations using nonparametric topic
models. Machine Learning, pages 1–41.
Philip V. Ogren, Philipp G. Wetzler, and Steven
Bethard. 2008. ClearTK: A UIMA toolkit for sta-
tistical natural language processing. In Towards
Enhanced Interoperability for Large HLT Systems:
UIMA for NLP workshop at Language Resources
and Evaluation Conference (LREC).
Adinoyi Omuya, Vinodkumar Prabhakaran, and Owen
Rambow. 2013. Improving the quality of minor-
ity class identification in dialog act tagging. In Pro-
ceedings of the 2013 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
802–807, Atlanta, Georgia, June. Association for
Computational Linguistics.
Vinodkumar Prabhakaran and Owen Rambow. 2013.
Written dialog and social power: Manifestations of
different types of power in dialog behavior. In Pro-
ceedings of the IJCNLP, pages 216–224, Nagoya,
Japan, October. Asian Federation of Natural Lan-
guage Processing.
Vinodkumar Prabhakaran, Owen Rambow, and Mona
Diab. 2012. Predicting Overt Display of Power in
Written Dialogs. In Human Language Technolo-
gies: The 2012 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, Montreal, Canada, June. Associ-
ation for Computational Linguistics.
Vinodkumar Prabhakaran, Ajita John, and Dor´ee D.
Seligmann. 2013. Who had the upper hand? rank-
ing participants of interactions based on their rela-
tive power. In Proceedings of the IJCNLP, pages
365–373, Nagoya, Japan, October. Asian Federation
of Natural Language Processing.
Ryan Rowe, German Creamer, Shlomo Hershkop, and
Salvatore J. Stolfo. 2007. Automated social hier-
archy detection through email network analysis. In
Proceedings of the 9th WebKDD and 1st SNA-KDD
2007 workshop on Web Mining and Social Network
Anal. ACM.
Tomek Strzalkowski, Samira Shaikh, Ting Liu,
George Aaron Broadwell, Jenny Stromer-Galley,
Sarah Taylor, Umit Boz, Veena Ravishankar, and
Xiaoai Ren. 2012. Modeling leadership and influ-
ence in multi-party online discourse. In Proceedings
of COLING, pages 2535–2552, Mumbai, India, De-
cember. The COLING 2012 Organizing Committee.
Jen-Yuan Yeh and Aaron Harnly. 2006. Email thread
reassembly using similarity matching. In CEAS
2006 - The Third Conference on Email and Anti-
Spam, July 27-28, 2006, Mountain View, California,
USA, Mountain View, California, USA, July.
</reference>
<page confidence="0.999003">
344
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.799855">
<title confidence="0.987694">Predicting Power Relations between in Written Dialog from a Single Thread</title>
<author confidence="0.814369">Vinodkumar</author>
<affiliation confidence="0.998773">Dept. of Computer Columbia University, New York,</affiliation>
<email confidence="0.999848">vinod@cs.columbia.edu</email>
<abstract confidence="0.999622777777778">We introduce the problem of predicting who has power over whom in pairs of people based on a single written dialog. We propose a new set of structural features. We build a supervised learning system to predict the direction of power; our new features significantly improve the results over using previously proposed features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Adinoyi Omuya</author>
<author>Aaron Harnly</author>
<author>Owen Rambow</author>
</authors>
<title>A Comprehensive Gold Standard for the Enron Organizational Hierarchy.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the ACL (Short Papers),</booktitle>
<pages>161--165</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="6739" citStr="Agarwal et al. (2012)" startWordPosition="1090" endWordPosition="1093">us contains 36,615 email threads. We excluded a small subset of 419 threads that was used for previous manual annotation efforts, part of which was also used to train the DA and ODP taggers (Section 5) that generate features for our system. The average number of email messages per thread was around 3. We divided the remaining threads into train (50%), dev (25%) and test (25%) sets by random sampling. We then applied various basic NLP preprocessing steps such as tokenization, POS tagging and lemmatization to the body of email messages. We use the Enron gold organizational hierarchy released by Agarwal et al. (2012) to model hierarchical power. Their corpus was manually built using information from Enron organizational charts. It includes relations of 1,518 employees and captures dominance relations between 13,724 pairs of them. Theirs is the largest such data set available to the best of our knowledge. 4 Problem Formulation Let t denote an email thread and Mt denote the set of all messages in t. Also, let Pt be the set of all participants in t, i.e., the union of senders and recipients (To and CC) of all messages in Mt. We are interested in detecting power relations between pairs of participants who int</context>
</contexts>
<marker>Agarwal, Omuya, Harnly, Rambow, 2012</marker>
<rawString>Apoorv Agarwal, Adinoyi Omuya, Aaron Harnly, and Owen Rambow. 2012. A Comprehensive Gold Standard for the Enron Organizational Hierarchy. In Proceedings of the 50th Annual Meeting of the ACL (Short Papers), pages 161–165, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Benjamini</author>
<author>Yosef Hochberg</author>
</authors>
<title>Controlling the false discovery rate: a practical and powerful approach to multiple testing.</title>
<date>1995</date>
<journal>Journal of the Royal Statistical Society. Series B (Methodological),</journal>
<pages>289--300</pages>
<contexts>
<context position="13545" citStr="Benjamini and Hochberg, 1995" startWordPosition="2260" endWordPosition="2263">le recipients who have a superior/subordinate relation with the sender will contribute to features for multiple data points. We limit our analysis to the related interacting pairs from only our train set. Table 2 presents mean values of features for subordinates and superiors at the interaction level. Thread level versions of these features also obtained similar results overall in terms of direction of difference and significance. We denote three significance levels — * (p &lt; .05), ** (p &lt; .01), and *** (p &lt; .001). To control false discovery rates in multiple testing, we adjusted the p-values (Benjamini and Hochberg, 1995). We summarize 341 Feature Name Mean(f sub Mean(f sup ��� ) ��� ) THRNew AvgRecipients*** 21.14 43.10 AvgToRecipients*** 18.19 38.94 InToList% 0.82 0.80 ReplyRate*** 0.86 1.23 ReplyRateWithinPair*** 0.16 0.10 AddPerson 0.48 0.47 RemovePerson*** 0.41 0.37 THRPR Initiate*** 0.45 0.56 FirstMsgPos 0.04 0.03 LastMsgPos*** 0.15 0.11 MsgCount*** 0.64 0.70 MsgRatio*** 0.44 0.56 TokenCount 91.22 83.26 TokenRatio*** 0.45 0.55 TokenPerMsg* 140.60 120.87 DIAPR Conventional%*** 0.15 0.17 Inform%*** 0.78 0.72 ReqAction%*** 0.02 0.04 ReqInform%*** 0.05 0.06 DanglingReq%*** 0.12 0.15 ODP%*** 0.03 0.06 Table 2</context>
</contexts>
<marker>Benjamini, Hochberg, 1995</marker>
<rawString>Yoav Benjamini and Yosef Hochberg. 1995. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society. Series B (Methodological), pages 289–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Or Biran</author>
<author>Sara Rosenthal</author>
<author>Jacob Andreas</author>
<author>Kathleen McKeown</author>
<author>Owen Rambow</author>
</authors>
<title>Detecting influencers in written online conversations.</title>
<date>2012</date>
<booktitle>In Proceedings of the Second Workshop on Language in Social Media,</booktitle>
<pages>37--45</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="1117" citStr="Biran et al., 2012" startWordPosition="165" endWordPosition="168">eviously proposed features. 1 Introduction Computationally analyzing the social context in which language is used has gathered great interest within the NLP community recently. One of the areas that has generated substantial research is the study of how social power relations between people affect and/or are revealed in their interactions with one another. Researchers have proposed systems to detect social power relations between participants of organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013), online forums (Danescu-NiculescuMizil et al., 2012; Biran et al., 2012; DanescuNiculescu-Mizil et al., 2013), chats (Strzalkowski et al., 2012), and off-line interactions such as presidential debates (Prabhakaran et al., 2013; Nguyen et al., 2013). Automatically identifying power and influence from interactions can have many practical applications ranging from law enforcement and intelligence to online marketing. A significant number of these studies are performed in the domain of organizational email where there is a well defined notion of power (organizational hierarchy). Bramsen et al. (2011) and Gilbert (2012) predict hierarchical power relations between peo</context>
</contexts>
<marker>Biran, Rosenthal, Andreas, McKeown, Rambow, 2012</marker>
<rawString>Or Biran, Sara Rosenthal, Jacob Andreas, Kathleen McKeown, and Owen Rambow. 2012. Detecting influencers in written online conversations. In Proceedings of the Second Workshop on Language in Social Media, pages 37–45, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Bramsen</author>
<author>Martha Escobar-Molano</author>
<author>Ami Patel</author>
<author>Rafael Alonso</author>
</authors>
<title>Extracting social power relationships from natural language.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>773--782</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="999" citStr="Bramsen et al., 2011" startWordPosition="147" endWordPosition="150">ised learning system to predict the direction of power; our new features significantly improve the results over using previously proposed features. 1 Introduction Computationally analyzing the social context in which language is used has gathered great interest within the NLP community recently. One of the areas that has generated substantial research is the study of how social power relations between people affect and/or are revealed in their interactions with one another. Researchers have proposed systems to detect social power relations between participants of organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013), online forums (Danescu-NiculescuMizil et al., 2012; Biran et al., 2012; DanescuNiculescu-Mizil et al., 2013), chats (Strzalkowski et al., 2012), and off-line interactions such as presidential debates (Prabhakaran et al., 2013; Nguyen et al., 2013). Automatically identifying power and influence from interactions can have many practical applications ranging from law enforcement and intelligence to online marketing. A significant number of these studies are performed in the domain of organizational email where there is a well defined notion of power</context>
<context position="3082" citStr="Bramsen et al. (2011)" startWordPosition="475" endWordPosition="478">on between pairs of participants in an email interaction thread based solely on features extracted from that thread. As a second major contribution, we introduce a new set of features to capture aspects of participant behavior such as responsiveness, and we show that these features are significantly correlated with the direction of power. We present a fully automatic system for this task obtaining an accuracy of 73.0%, an improvement of 6.9% over 68.3% by a system using only lexical features. This best-performing system uses our new feature set. 2 Motivation Early NLP-based approaches such as Bramsen et al. (2011) and Gilbert (2012) built systems to predict hierarchical power relations between people in the Enron email corpus using lexical features from all the messages exchanged between them. One limitation of this approach is that it relies solely on lexical cues and hence works best when large collections of messages exchanged between the pairs of people are available. For example, Bramsen et al. (2011) excluded sender-recipient pairs who exchanged fewer than 500 words from their evaluation set, since they found smaller text samples are harder to classify. By taking the message out of the context of</context>
<context position="5351" citStr="Bramsen et al., 2011" startWordPosition="841" endWordPosition="844">n of (Prabhakaran and Rambow, 2013) is that we used manual annotations for many of our features such as dialog acts and overt displays of power. Relying on manual annotations for features limited our analysis to a small subset of the Enron corpus, which has only 18 instances of hierarchical power. Consequently, our findings with respect to hierarchical power were weak in terms of both correlations of features and system performance. In this paper, we introduce the problem of predicting who has power over whom in pairs of interacting participants based on a single thread of interactions. From (Bramsen et al., 2011) we retain the idea that we want to predict the power relation between pairs of people. But in contrast to their formulation, we retain the goal from (Prabhakaran and Rambow, 2013) that we want to study communication in the context of an interaction, and that we want to be able to make predictions using only the emails exchanged in a single thread. Like (Prabhakaran and Rambow, 2013), we use features to capture the dialog structure, but we use automatic taggers to generate them and assume no manual annotation at all at training or test time. This allows us to use the entire Enron email corpus </context>
<context position="8933" citStr="Bramsen et al., 2011" startWordPosition="1481" endWordPosition="1484">our corpus and across train, dev and test sets. Description Total Train Dev Test # of threads 36,196 18,079 8,973 9,144 Et JIPPtj 355,797 174,892 91,898 89,007 Et IRIPPtl 15,048 7,510 3,578 3,960 Table 1: Data Statistics Row 1 presents the total number of threads in different subsets of the corpus. Row 2 and 3 present the number of interacting participant pairs (IPP) and related interacting participant pairs (RIPP) in those subsets. 340 Given a thread t and a pair of participants (p1, p2) ∈ RIPPt, we want to automatically detect HP(p1 , p2). This problem formulation is similar to the ones in (Bramsen et al., 2011) and (Gilbert, 2012). However, the difference is that for us an instance is a pair of participants in a single thread of interaction (which may or may not include other people), whereas for them an instance constitutes all messages exchanged between a pair of people in the entire corpus. Our formulation also differs from (Prabhakaran and Rambow, 2013) in that we detect power relations between pairs of participants, instead of just whether a participant had power over anyone in the thread. 5 Structural Analysis In this section we analyze various features that capture the structure of interactio</context>
<context position="18673" citStr="Bramsen et al., 2011" startWordPosition="3081" endWordPosition="3084">les) 72.44 Table 3: Accuracies on feature subsets (dev set). THRNew: new meta-data features; THRPR, DIAPR: meta-data and dialog-act features from previous studies; LEX: ngrams; BEST: best subset; IMt stands for IMt(p1, p2) with cases where Inform% is truly 0. In order to mitigate this issue, we use an indicator feature for each structural feature to denote whether or not it is valid. Since we use a quadratic kernel, we expect the SVM to pick up the interaction between each feature and its indicator feature. Lexical features have already been shown to be valuable in predicting power relations (Bramsen et al., 2011; Gilbert, 2012). We use another feature set LEX to capture word ngrams, POS (part of speech) ngrams and mixed ngrams. A mixed ngram (Prabhakaran et al., 2012) is a special case of word ngram where words belonging to open classes are replaced with their POS tags. We found the best setting to be using both unigrams and bigrams for all three types of ngrams, by tuning in our dev set. We then performed experiments using all subsets of {LEX, THRNew, THRPR, DIAPR }. Table 3 presents the results obtained using various feature subsets. We use a majority class baseline assigning HP(p1i p2) to be alway</context>
</contexts>
<marker>Bramsen, Escobar-Molano, Patel, Alonso, 2011</marker>
<rawString>Philip Bramsen, Martha Escobar-Molano, Ami Patel, and Rafael Alonso. 2011. Extracting social power relationships from natural language. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 773–782, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristian Danescu-Niculescu-Mizil</author>
<author>Lillian Lee</author>
<author>Bo Pang</author>
<author>Jon Kleinberg</author>
</authors>
<title>Echoes of power: language effects and power differences in social interaction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web, WWW ’12,</booktitle>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Danescu-Niculescu-Mizil, Lee, Pang, Kleinberg, 2012</marker>
<rawString>Cristian Danescu-Niculescu-Mizil, Lillian Lee, Bo Pang, and Jon Kleinberg. 2012. Echoes of power: language effects and power differences in social interaction. In Proceedings of the 21st international conference on World Wide Web, WWW ’12, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristian Danescu-Niculescu-Mizil</author>
<author>Moritz Sudhof</author>
<author>Dan Jurafsky</author>
<author>Jure Leskovec</author>
<author>Christopher Potts</author>
</authors>
<title>A computational approach to politeness with application to social factors.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>250--259</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<marker>Danescu-Niculescu-Mizil, Sudhof, Jurafsky, Leskovec, Potts, 2013</marker>
<rawString>Cristian Danescu-Niculescu-Mizil, Moritz Sudhof, Dan Jurafsky, Jure Leskovec, and Christopher Potts. 2013. A computational approach to politeness with application to social factors. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 250–259, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Gilbert</author>
</authors>
<title>Phrases that signal workplace hierarchy.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, CSCW ’12,</booktitle>
<pages>1037--1046</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1014" citStr="Gilbert, 2012" startWordPosition="151" endWordPosition="152">o predict the direction of power; our new features significantly improve the results over using previously proposed features. 1 Introduction Computationally analyzing the social context in which language is used has gathered great interest within the NLP community recently. One of the areas that has generated substantial research is the study of how social power relations between people affect and/or are revealed in their interactions with one another. Researchers have proposed systems to detect social power relations between participants of organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013), online forums (Danescu-NiculescuMizil et al., 2012; Biran et al., 2012; DanescuNiculescu-Mizil et al., 2013), chats (Strzalkowski et al., 2012), and off-line interactions such as presidential debates (Prabhakaran et al., 2013; Nguyen et al., 2013). Automatically identifying power and influence from interactions can have many practical applications ranging from law enforcement and intelligence to online marketing. A significant number of these studies are performed in the domain of organizational email where there is a well defined notion of power (organizationa</context>
<context position="3101" citStr="Gilbert (2012)" startWordPosition="480" endWordPosition="481">ipants in an email interaction thread based solely on features extracted from that thread. As a second major contribution, we introduce a new set of features to capture aspects of participant behavior such as responsiveness, and we show that these features are significantly correlated with the direction of power. We present a fully automatic system for this task obtaining an accuracy of 73.0%, an improvement of 6.9% over 68.3% by a system using only lexical features. This best-performing system uses our new feature set. 2 Motivation Early NLP-based approaches such as Bramsen et al. (2011) and Gilbert (2012) built systems to predict hierarchical power relations between people in the Enron email corpus using lexical features from all the messages exchanged between them. One limitation of this approach is that it relies solely on lexical cues and hence works best when large collections of messages exchanged between the pairs of people are available. For example, Bramsen et al. (2011) excluded sender-recipient pairs who exchanged fewer than 500 words from their evaluation set, since they found smaller text samples are harder to classify. By taking the message out of the context of the interaction in</context>
<context position="8953" citStr="Gilbert, 2012" startWordPosition="1486" endWordPosition="1487">, dev and test sets. Description Total Train Dev Test # of threads 36,196 18,079 8,973 9,144 Et JIPPtj 355,797 174,892 91,898 89,007 Et IRIPPtl 15,048 7,510 3,578 3,960 Table 1: Data Statistics Row 1 presents the total number of threads in different subsets of the corpus. Row 2 and 3 present the number of interacting participant pairs (IPP) and related interacting participant pairs (RIPP) in those subsets. 340 Given a thread t and a pair of participants (p1, p2) ∈ RIPPt, we want to automatically detect HP(p1 , p2). This problem formulation is similar to the ones in (Bramsen et al., 2011) and (Gilbert, 2012). However, the difference is that for us an instance is a pair of participants in a single thread of interaction (which may or may not include other people), whereas for them an instance constitutes all messages exchanged between a pair of people in the entire corpus. Our formulation also differs from (Prabhakaran and Rambow, 2013) in that we detect power relations between pairs of participants, instead of just whether a participant had power over anyone in the thread. 5 Structural Analysis In this section we analyze various features that capture the structure of interaction between the pairs </context>
<context position="18689" citStr="Gilbert, 2012" startWordPosition="3085" endWordPosition="3086">curacies on feature subsets (dev set). THRNew: new meta-data features; THRPR, DIAPR: meta-data and dialog-act features from previous studies; LEX: ngrams; BEST: best subset; IMt stands for IMt(p1, p2) with cases where Inform% is truly 0. In order to mitigate this issue, we use an indicator feature for each structural feature to denote whether or not it is valid. Since we use a quadratic kernel, we expect the SVM to pick up the interaction between each feature and its indicator feature. Lexical features have already been shown to be valuable in predicting power relations (Bramsen et al., 2011; Gilbert, 2012). We use another feature set LEX to capture word ngrams, POS (part of speech) ngrams and mixed ngrams. A mixed ngram (Prabhakaran et al., 2012) is a special case of word ngram where words belonging to open classes are replaced with their POS tags. We found the best setting to be using both unigrams and bigrams for all three types of ngrams, by tuning in our dev set. We then performed experiments using all subsets of {LEX, THRNew, THRPR, DIAPR }. Table 3 presents the results obtained using various feature subsets. We use a majority class baseline assigning HP(p1i p2) to be always superior, whic</context>
</contexts>
<marker>Gilbert, 2012</marker>
<rawString>Eric Gilbert. 2012. Phrases that signal workplace hierarchy. In Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, CSCW ’12, pages 1037–1046, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making Large-Scale SVM Learning Practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods - Support Vector Learning,</booktitle>
<editor>In Bernhard Sch¨olkopf, Christopher J.C. Burges, and A. Smola, editors,</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="17131" citStr="Joachims, 1999" startWordPosition="2821" endWordPosition="2822">f a thread includes a pair of people who are hierarchically related, then it is likely to be initiated by the superior and he/she tends to contribute more in such threads. 6 Predicting Direction of Power We build an SVM-based supervised learning system that can predict HP(p1, p2) to be either superior or subordinate based on the interaction within a thread t for any pair of participants (p1 , p2) ∈ RIPPt. We deterministically fix the order of participants in (p1, p2) such that p1 is the sender of the first message in IMt(p1 , p2 ). We use the ClearTK (Ogren et al., 2008) wrapper for SVMLight (Joachims, 1999) in our experiments. We use the related interacting participant pairs in threads from the train set to train our models and optimize our performance on those from the dev set. We report results obtained on dev and test sets. In our formulation, values of many features are undefined for some instances (e.g., Inform% is undefined when MsgCount = 0). Handling of undefined values for features in SVM is not straightforward. Most SVM implementations assume the value of 0 by default in such cases, conflating them 342 Description Accuracy Baseline (Always Superior) 52.54 Baseline (Word Unigrams + Bigr</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making Large-Scale SVM Learning Practical. In Bernhard Sch¨olkopf, Christopher J.C. Burges, and A. Smola, editors, Advances in Kernel Methods - Support Vector Learning, Cambridge, MA, USA. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viet-An Nguyen</author>
<author>Jordan Boyd-Graber</author>
<author>Philip Resnik</author>
<author>Deborah A Cai</author>
<author>Jennifer E Midberry</author>
<author>Yuanxin Wang</author>
</authors>
<title>Modeling topic control to detect influence in conversations using nonparametric topic models.</title>
<date>2013</date>
<booktitle>Machine Learning,</booktitle>
<pages>1--41</pages>
<contexts>
<context position="1294" citStr="Nguyen et al., 2013" startWordPosition="191" endWordPosition="194">. One of the areas that has generated substantial research is the study of how social power relations between people affect and/or are revealed in their interactions with one another. Researchers have proposed systems to detect social power relations between participants of organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013), online forums (Danescu-NiculescuMizil et al., 2012; Biran et al., 2012; DanescuNiculescu-Mizil et al., 2013), chats (Strzalkowski et al., 2012), and off-line interactions such as presidential debates (Prabhakaran et al., 2013; Nguyen et al., 2013). Automatically identifying power and influence from interactions can have many practical applications ranging from law enforcement and intelligence to online marketing. A significant number of these studies are performed in the domain of organizational email where there is a well defined notion of power (organizational hierarchy). Bramsen et al. (2011) and Gilbert (2012) predict hierarchical power relations between people in the Enron email corpus using lexical features extracted from all the messages exchanged between them. However, their approaches primarily apply to situations where large </context>
</contexts>
<marker>Nguyen, Boyd-Graber, Resnik, Cai, Midberry, Wang, 2013</marker>
<rawString>Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik, Deborah A. Cai, Jennifer E. Midberry, and Yuanxin Wang. 2013. Modeling topic control to detect influence in conversations using nonparametric topic models. Machine Learning, pages 1–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip V Ogren</author>
<author>Philipp G Wetzler</author>
<author>Steven Bethard</author>
</authors>
<title>ClearTK: A UIMA toolkit for statistical natural language processing.</title>
<date>2008</date>
<booktitle>In Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP workshop at Language Resources and Evaluation Conference (LREC).</booktitle>
<contexts>
<context position="17093" citStr="Ogren et al., 2008" startWordPosition="2814" endWordPosition="2817">ely not to be the one who has power, but if a thread includes a pair of people who are hierarchically related, then it is likely to be initiated by the superior and he/she tends to contribute more in such threads. 6 Predicting Direction of Power We build an SVM-based supervised learning system that can predict HP(p1, p2) to be either superior or subordinate based on the interaction within a thread t for any pair of participants (p1 , p2) ∈ RIPPt. We deterministically fix the order of participants in (p1, p2) such that p1 is the sender of the first message in IMt(p1 , p2 ). We use the ClearTK (Ogren et al., 2008) wrapper for SVMLight (Joachims, 1999) in our experiments. We use the related interacting participant pairs in threads from the train set to train our models and optimize our performance on those from the dev set. We report results obtained on dev and test sets. In our formulation, values of many features are undefined for some instances (e.g., Inform% is undefined when MsgCount = 0). Handling of undefined values for features in SVM is not straightforward. Most SVM implementations assume the value of 0 by default in such cases, conflating them 342 Description Accuracy Baseline (Always Superior</context>
</contexts>
<marker>Ogren, Wetzler, Bethard, 2008</marker>
<rawString>Philip V. Ogren, Philipp G. Wetzler, and Steven Bethard. 2008. ClearTK: A UIMA toolkit for statistical natural language processing. In Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP workshop at Language Resources and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adinoyi Omuya</author>
<author>Vinodkumar Prabhakaran</author>
<author>Owen Rambow</author>
</authors>
<title>Improving the quality of minority class identification in dialog act tagging.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>802--807</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="11935" citStr="Omuya et al., 2013" startWordPosition="1991" endWordPosition="1994">last messages (FirstMsgPos and LastMsgPos) in M. Verbosity features include p’s message count (MsgCount), message ratio (MsgRatio), token count (TokenCount), token ratio (TokenRato) and tokens per message (TokenPerMsg), all calculated over M. DIAPR: In (Prabhakaran and Rambow, 2013), we used dialog features derived from manual annotations — dialog acts (DA) and overt displays of power (ODP) — to model the structure of interactions within the message content. In this work, we obtain DA and ODP tags on the entire corpus using automatic taggers trained on those manual annotations. The DA tagger (Omuya et al., 2013) obtained an accuracy of 92%. The ODP tagger (Prabhakaran et al., 2012) obtained an accuracy of 96% and F-measure of 54%. The DA tagger labels each sentence to be one of the 4 dialog acts: Request Action, Request Information, Inform, and Conventional. The ODP Tagger identifies sentences (mostly requests) that express additional constraints on its response, beyond those introduced by the dialog act. We use 5 features: ReqAction%, ReqInform%, Inform%, Conventional%, and ODP% to capture the percentage of sentences in messages sent by p that has each of these labels. We also use a feature to captu</context>
</contexts>
<marker>Omuya, Prabhakaran, Rambow, 2013</marker>
<rawString>Adinoyi Omuya, Vinodkumar Prabhakaran, and Owen Rambow. 2013. Improving the quality of minority class identification in dialog act tagging. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 802–807, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinodkumar Prabhakaran</author>
<author>Owen Rambow</author>
</authors>
<title>Written dialog and social power: Manifestations of different types of power in dialog behavior.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the IJCNLP,</booktitle>
<pages>216--224</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="1045" citStr="Prabhakaran and Rambow, 2013" startWordPosition="153" endWordPosition="157">irection of power; our new features significantly improve the results over using previously proposed features. 1 Introduction Computationally analyzing the social context in which language is used has gathered great interest within the NLP community recently. One of the areas that has generated substantial research is the study of how social power relations between people affect and/or are revealed in their interactions with one another. Researchers have proposed systems to detect social power relations between participants of organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013), online forums (Danescu-NiculescuMizil et al., 2012; Biran et al., 2012; DanescuNiculescu-Mizil et al., 2013), chats (Strzalkowski et al., 2012), and off-line interactions such as presidential debates (Prabhakaran et al., 2013; Nguyen et al., 2013). Automatically identifying power and influence from interactions can have many practical applications ranging from law enforcement and intelligence to online marketing. A significant number of these studies are performed in the domain of organizational email where there is a well defined notion of power (organizational hierarchy). Bramsen et al. (2</context>
<context position="3899" citStr="Prabhakaran and Rambow, 2013" startWordPosition="606" endWordPosition="609">limitation of this approach is that it relies solely on lexical cues and hence works best when large collections of messages exchanged between the pairs of people are available. For example, Bramsen et al. (2011) excluded sender-recipient pairs who exchanged fewer than 500 words from their evaluation set, since they found smaller text samples are harder to classify. By taking the message out of the context of the interaction in which it was exchanged, they fail to utilize cues from the structure of interactions, which complements the lexical cues in detecting power relations, as we showed in (Prabhakaran and Rambow, 2013). 339 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 339–344, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics We modeled the problem of detecting power relationships differently in (Prabhakaran and Rambow, 2013): we predicted whether a participant in an email thread has a certain type of power or not. However, in that work we did not predict over whom he/she has that power. This may result in noisy features; consider a thread in which participant X has power over participant Y, who has po</context>
<context position="5531" citStr="Prabhakaran and Rambow, 2013" startWordPosition="872" endWordPosition="875">ns for features limited our analysis to a small subset of the Enron corpus, which has only 18 instances of hierarchical power. Consequently, our findings with respect to hierarchical power were weak in terms of both correlations of features and system performance. In this paper, we introduce the problem of predicting who has power over whom in pairs of interacting participants based on a single thread of interactions. From (Bramsen et al., 2011) we retain the idea that we want to predict the power relation between pairs of people. But in contrast to their formulation, we retain the goal from (Prabhakaran and Rambow, 2013) that we want to study communication in the context of an interaction, and that we want to be able to make predictions using only the emails exchanged in a single thread. Like (Prabhakaran and Rambow, 2013), we use features to capture the dialog structure, but we use automatic taggers to generate them and assume no manual annotation at all at training or test time. This allows us to use the entire Enron email corpus for this study. 3 Data In this work, we use the version of Enron email corpus by Yeh and Harnly (2006) which captures the thread structure of email exchanges. The corpus contains 3</context>
<context position="9286" citStr="Prabhakaran and Rambow, 2013" startWordPosition="1541" endWordPosition="1544"> participant pairs (IPP) and related interacting participant pairs (RIPP) in those subsets. 340 Given a thread t and a pair of participants (p1, p2) ∈ RIPPt, we want to automatically detect HP(p1 , p2). This problem formulation is similar to the ones in (Bramsen et al., 2011) and (Gilbert, 2012). However, the difference is that for us an instance is a pair of participants in a single thread of interaction (which may or may not include other people), whereas for them an instance constitutes all messages exchanged between a pair of people in the entire corpus. Our formulation also differs from (Prabhakaran and Rambow, 2013) in that we detect power relations between pairs of participants, instead of just whether a participant had power over anyone in the thread. 5 Structural Analysis In this section we analyze various features that capture the structure of interaction between the pairs of participants in a thread. Each feature f is extracted with respect to a person p over a reference set of messages M (denoted fpM). For a pair (p1 , p2), we extract 4 versions of each feature f : fp1 IMt(p1,p2), fp2 IMt(p1,p2), fMt p1 and fMtp2. The first two capture behavior of the pair among themselves, while the third and four</context>
<context position="11599" citStr="Prabhakaran and Rambow, 2013" startWordPosition="1930" endWordPosition="1933">ssages where he/she was a To recipient (ReplyRateWithinPair). ReplyRateWithinPair applies only to IMt(p1 , p2). THRPR: This feature set includes two metadata based feature sets — positional and verbosity. Positional features include a boolean feature to denote whether p sent the first message (Initiate), and relative positions of p’s first and last messages (FirstMsgPos and LastMsgPos) in M. Verbosity features include p’s message count (MsgCount), message ratio (MsgRatio), token count (TokenCount), token ratio (TokenRato) and tokens per message (TokenPerMsg), all calculated over M. DIAPR: In (Prabhakaran and Rambow, 2013), we used dialog features derived from manual annotations — dialog acts (DA) and overt displays of power (ODP) — to model the structure of interactions within the message content. In this work, we obtain DA and ODP tags on the entire corpus using automatic taggers trained on those manual annotations. The DA tagger (Omuya et al., 2013) obtained an accuracy of 92%. The ODP tagger (Prabhakaran et al., 2012) obtained an accuracy of 96% and F-measure of 54%. The DA tagger labels each sentence to be one of the 4 dialog acts: Request Action, Request Information, Inform, and Conventional. The ODP Tagg</context>
<context position="15971" citStr="Prabhakaran and Rambow, 2013" startWordPosition="2616" endWordPosition="2619">in the networks that they are part of (Rowe et al., 2007). Intuitively, those who have higher connectivity also send emails to larger number of people, and hence our result. Since superiors address more people in their emails, they also have a higher chance of getting replies. Finding 2 also aligns with the general intuition about how superiors and subordinates behave within interactions (e.g., superiors exhibit more overt displays of power than subordinates). Findings 3 &amp; 4 are interesting since they reveal special characteristics of threads involving hierarchically related participants. In (Prabhakaran and Rambow, 2013), we had found that persons with hierarchical power rarely initiated threads and contributed less within the threads. But that problem formulation was different — we were identifying whether a person in a given thread had hierarchical power over someone else or not. The data points in that formulation included participants from threads that did not have any hierarchically related people, whereas our current formulation do not. These findings suggest that if a person starts an email thread, he’s likely not to be the one who has power, but if a thread includes a pair of people who are hierarchic</context>
</contexts>
<marker>Prabhakaran, Rambow, 2013</marker>
<rawString>Vinodkumar Prabhakaran and Owen Rambow. 2013. Written dialog and social power: Manifestations of different types of power in dialog behavior. In Proceedings of the IJCNLP, pages 216–224, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinodkumar Prabhakaran</author>
<author>Owen Rambow</author>
<author>Mona Diab</author>
</authors>
<title>Predicting Overt Display of Power in Written Dialogs.</title>
<date>2012</date>
<booktitle>In Human Language Technologies: The 2012 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montreal, Canada,</location>
<contexts>
<context position="12006" citStr="Prabhakaran et al., 2012" startWordPosition="2003" endWordPosition="2006">es include p’s message count (MsgCount), message ratio (MsgRatio), token count (TokenCount), token ratio (TokenRato) and tokens per message (TokenPerMsg), all calculated over M. DIAPR: In (Prabhakaran and Rambow, 2013), we used dialog features derived from manual annotations — dialog acts (DA) and overt displays of power (ODP) — to model the structure of interactions within the message content. In this work, we obtain DA and ODP tags on the entire corpus using automatic taggers trained on those manual annotations. The DA tagger (Omuya et al., 2013) obtained an accuracy of 92%. The ODP tagger (Prabhakaran et al., 2012) obtained an accuracy of 96% and F-measure of 54%. The DA tagger labels each sentence to be one of the 4 dialog acts: Request Action, Request Information, Inform, and Conventional. The ODP Tagger identifies sentences (mostly requests) that express additional constraints on its response, beyond those introduced by the dialog act. We use 5 features: ReqAction%, ReqInform%, Inform%, Conventional%, and ODP% to capture the percentage of sentences in messages sent by p that has each of these labels. We also use a feature to capture the number of p’s messages with a request that did not get a reply, </context>
<context position="18832" citStr="Prabhakaran et al., 2012" startWordPosition="3109" endWordPosition="3112"> studies; LEX: ngrams; BEST: best subset; IMt stands for IMt(p1, p2) with cases where Inform% is truly 0. In order to mitigate this issue, we use an indicator feature for each structural feature to denote whether or not it is valid. Since we use a quadratic kernel, we expect the SVM to pick up the interaction between each feature and its indicator feature. Lexical features have already been shown to be valuable in predicting power relations (Bramsen et al., 2011; Gilbert, 2012). We use another feature set LEX to capture word ngrams, POS (part of speech) ngrams and mixed ngrams. A mixed ngram (Prabhakaran et al., 2012) is a special case of word ngram where words belonging to open classes are replaced with their POS tags. We found the best setting to be using both unigrams and bigrams for all three types of ngrams, by tuning in our dev set. We then performed experiments using all subsets of {LEX, THRNew, THRPR, DIAPR }. Table 3 presents the results obtained using various feature subsets. We use a majority class baseline assigning HP(p1i p2) to be always superior, which obtains 52.5% accuracy. We also use a stronger baseline using word unigrams and bigrams as features, which obtained an accuracy of 68.6%. The</context>
</contexts>
<marker>Prabhakaran, Rambow, Diab, 2012</marker>
<rawString>Vinodkumar Prabhakaran, Owen Rambow, and Mona Diab. 2012. Predicting Overt Display of Power in Written Dialogs. In Human Language Technologies: The 2012 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Montreal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinodkumar Prabhakaran</author>
<author>Ajita John</author>
<author>Dor´ee D Seligmann</author>
</authors>
<title>Who had the upper hand? ranking participants of interactions based on their relative power.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the IJCNLP,</booktitle>
<pages>365--373</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="1272" citStr="Prabhakaran et al., 2013" startWordPosition="187" endWordPosition="190">the NLP community recently. One of the areas that has generated substantial research is the study of how social power relations between people affect and/or are revealed in their interactions with one another. Researchers have proposed systems to detect social power relations between participants of organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013), online forums (Danescu-NiculescuMizil et al., 2012; Biran et al., 2012; DanescuNiculescu-Mizil et al., 2013), chats (Strzalkowski et al., 2012), and off-line interactions such as presidential debates (Prabhakaran et al., 2013; Nguyen et al., 2013). Automatically identifying power and influence from interactions can have many practical applications ranging from law enforcement and intelligence to online marketing. A significant number of these studies are performed in the domain of organizational email where there is a well defined notion of power (organizational hierarchy). Bramsen et al. (2011) and Gilbert (2012) predict hierarchical power relations between people in the Enron email corpus using lexical features extracted from all the messages exchanged between them. However, their approaches primarily apply to s</context>
</contexts>
<marker>Prabhakaran, John, Seligmann, 2013</marker>
<rawString>Vinodkumar Prabhakaran, Ajita John, and Dor´ee D. Seligmann. 2013. Who had the upper hand? ranking participants of interactions based on their relative power. In Proceedings of the IJCNLP, pages 365–373, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Rowe</author>
<author>German Creamer</author>
<author>Shlomo Hershkop</author>
<author>Salvatore J Stolfo</author>
</authors>
<title>Automated social hierarchy detection through email network analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the 9th WebKDD and 1st SNA-KDD</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="15399" citStr="Rowe et al., 2007" startWordPosition="2527" endWordPosition="2530">ubordinates issue more informs (Inform%) and, surprisingly, have fewer unanswered requests (DanglingReq%). 3. Superiors initiate the interactions more often than subordinates (Initiate). They also leave interactions earlier (LastMsgPos). 4. Superiors send shorter messages (TokenPerMsg). They also send more messages (MsgCount &amp; MsgRatio) and even contribute a higher ratio of tokens in the thread (TokenRatio) despite sending shorter messages. Finding 1 goes in line with findings from studies analyzing social networks that superiors have higher connectivity in the networks that they are part of (Rowe et al., 2007). Intuitively, those who have higher connectivity also send emails to larger number of people, and hence our result. Since superiors address more people in their emails, they also have a higher chance of getting replies. Finding 2 also aligns with the general intuition about how superiors and subordinates behave within interactions (e.g., superiors exhibit more overt displays of power than subordinates). Findings 3 &amp; 4 are interesting since they reveal special characteristics of threads involving hierarchically related participants. In (Prabhakaran and Rambow, 2013), we had found that persons </context>
</contexts>
<marker>Rowe, Creamer, Hershkop, Stolfo, 2007</marker>
<rawString>Ryan Rowe, German Creamer, Shlomo Hershkop, and Salvatore J. Stolfo. 2007. Automated social hierarchy detection through email network analysis. In Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 workshop on Web Mining and Social Network Anal. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
<author>Samira Shaikh</author>
<author>Ting Liu</author>
<author>George Aaron Broadwell</author>
<author>Jenny Stromer-Galley</author>
<author>Sarah Taylor</author>
<author>Umit Boz</author>
<author>Veena Ravishankar</author>
<author>Xiaoai Ren</author>
</authors>
<title>Modeling leadership and influence in multi-party online discourse.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>2535--2552</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="1190" citStr="Strzalkowski et al., 2012" startWordPosition="175" endWordPosition="178">ing the social context in which language is used has gathered great interest within the NLP community recently. One of the areas that has generated substantial research is the study of how social power relations between people affect and/or are revealed in their interactions with one another. Researchers have proposed systems to detect social power relations between participants of organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013), online forums (Danescu-NiculescuMizil et al., 2012; Biran et al., 2012; DanescuNiculescu-Mizil et al., 2013), chats (Strzalkowski et al., 2012), and off-line interactions such as presidential debates (Prabhakaran et al., 2013; Nguyen et al., 2013). Automatically identifying power and influence from interactions can have many practical applications ranging from law enforcement and intelligence to online marketing. A significant number of these studies are performed in the domain of organizational email where there is a well defined notion of power (organizational hierarchy). Bramsen et al. (2011) and Gilbert (2012) predict hierarchical power relations between people in the Enron email corpus using lexical features extracted from all t</context>
</contexts>
<marker>Strzalkowski, Shaikh, Liu, Broadwell, Stromer-Galley, Taylor, Boz, Ravishankar, Ren, 2012</marker>
<rawString>Tomek Strzalkowski, Samira Shaikh, Ting Liu, George Aaron Broadwell, Jenny Stromer-Galley, Sarah Taylor, Umit Boz, Veena Ravishankar, and Xiaoai Ren. 2012. Modeling leadership and influence in multi-party online discourse. In Proceedings of COLING, pages 2535–2552, Mumbai, India, December. The COLING 2012 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jen-Yuan Yeh</author>
<author>Aaron Harnly</author>
</authors>
<title>Email thread reassembly using similarity matching.</title>
<date>2006</date>
<booktitle>In CEAS 2006 - The Third Conference on Email and AntiSpam,</booktitle>
<location>Mountain View, California, USA, Mountain View, California, USA,</location>
<contexts>
<context position="6053" citStr="Yeh and Harnly (2006)" startWordPosition="970" endWordPosition="973">eople. But in contrast to their formulation, we retain the goal from (Prabhakaran and Rambow, 2013) that we want to study communication in the context of an interaction, and that we want to be able to make predictions using only the emails exchanged in a single thread. Like (Prabhakaran and Rambow, 2013), we use features to capture the dialog structure, but we use automatic taggers to generate them and assume no manual annotation at all at training or test time. This allows us to use the entire Enron email corpus for this study. 3 Data In this work, we use the version of Enron email corpus by Yeh and Harnly (2006) which captures the thread structure of email exchanges. The corpus contains 36,615 email threads. We excluded a small subset of 419 threads that was used for previous manual annotation efforts, part of which was also used to train the DA and ODP taggers (Section 5) that generate features for our system. The average number of email messages per thread was around 3. We divided the remaining threads into train (50%), dev (25%) and test (25%) sets by random sampling. We then applied various basic NLP preprocessing steps such as tokenization, POS tagging and lemmatization to the body of email mess</context>
</contexts>
<marker>Yeh, Harnly, 2006</marker>
<rawString>Jen-Yuan Yeh and Aaron Harnly. 2006. Email thread reassembly using similarity matching. In CEAS 2006 - The Third Conference on Email and AntiSpam, July 27-28, 2006, Mountain View, California, USA, Mountain View, California, USA, July.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>