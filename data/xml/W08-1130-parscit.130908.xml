<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011715">
<title confidence="0.9977935">
OSU-2: Generating Referring Expressions
with a Maximum Entropy Classifier
</title>
<author confidence="0.996653">
Emily Jamison
</author>
<affiliation confidence="0.995467">
Department of Linguistics
The Ohio State University
</affiliation>
<address confidence="0.595438">
Columbus, OH 43210, USA
</address>
<email confidence="0.998453">
jamison@ling.osu.edu
</email>
<author confidence="0.992903">
Dennis Mehay
</author>
<affiliation confidence="0.9954465">
Department of Linguistics
The Ohio State University
</affiliation>
<address confidence="0.595794">
Columbus, OH 43210, USA
</address>
<email confidence="0.999191">
mehay@ling.osu.edu
</email>
<sectionHeader confidence="0.995659" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999398333333333">
Selection of natural-sounding referring ex-
pressions is useful in text generation and in-
formation summarization (Kan et al., 2001).
We use discourse-level feature predicates in
a maximum entropy classifier (Berger et al.,
1996) with binary and n-class classification to
select referring expressions from a list. We
find that while mention-type n-class classifi-
cation produces higher accuracy of type, bi-
nary classification of individual referring ex-
pressions helps to avoid use of awkward refer-
ring expressions.
</bodyText>
<sectionHeader confidence="0.998037" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998854">
Referring expression generation is the task of insert-
ing noun phrases that refer to a mentioned extra-
linguistic entity into a text. REG is helpful for tasks
such as text generation and information summariza-
tion (Kan et al., 2001).
</bodyText>
<sectionHeader confidence="0.976104" genericHeader="method">
2 Task Description
</sectionHeader>
<bodyText confidence="0.994764">
The Referring Expressions Generation Chal-
lenge (Belz and Gatt, 2008) includes a task based
on the GREC corpus, a collection of introductory
texts from Wikipedia that includes articles about
cities, countries, rivers, people, and mountains.
In this corpus, the main topic of each text (MSR)
has been replaced with a list of possible referring
expressions (REs). The objective of the task is to
identify the most appropriate referring expression
from the list for each mention of the MSR, given
the surrounding text and annotated syntactic and
semantic information.
</bodyText>
<sectionHeader confidence="0.997759" genericHeader="method">
3 Predicates
</sectionHeader>
<bodyText confidence="0.999984111111111">
We created 13 predicates, in addition to the six pred-
icates available with the corpus. All predicates can
be used with the binary classification method; only
non-RE-level predicates can be used with the n-class
classification method. Predicates describe: string
similarity of the RE and the title of the article, the
mention’s order in the article, distance between pre-
vious mention and current mention, and detection of
a contrastive discourse entity in the text.1
</bodyText>
<sectionHeader confidence="0.984208" genericHeader="method">
4 Maximum Entropy Classifier
</sectionHeader>
<bodyText confidence="0.9997545">
We defined indicator feature functions for a number
of contextual predicates, each describing a pairing of
some potential property of the syntactico-semantic
and discourse context of a RE (a ‘predicate’) and a
label. These feature functions fi were used to train
a maximum entropy classifier (Berger et al., 1996)
(Le, 2004) that assigns a probability to a RE re given
context cx as follows:
</bodyText>
<equation confidence="0.987212333333333">
n
p(re |cx) = Z(cx) exp Aifi(cx, re)
i=1
</equation>
<bodyText confidence="0.999872285714286">
where Z(cx) is a normalizing sum and the Ai are the
parameters (feature weights) learned. Two classifi-
cation systems were used: binary and n-class. With
the binary method, the classifier estimates the like-
lihood of a possible referring expression’s correct
insertion into the text, and inserts the RE with the
highest ’yes’ probability. With the n-class method,
</bodyText>
<footnote confidence="0.996811">
1More details at http://www.ling.ohio-state.edu/˜jamison
</footnote>
<page confidence="0.976806">
196
</page>
<table confidence="0.9996608">
Predicates Used Single Combinations
GREC predicates 40.40% 50.91%
all predicates 50.30% 58.54%
no contrasting entities 50.30% 59.30%
all non-RE-level preds 44.82% 51.07%
</table>
<tableCaption confidence="0.999527">
Table 1: Results with binary classification.
</tableCaption>
<table confidence="0.9965785">
Predicates Used Single Combinations
all non-RE-level preds 61.13% 62.50%
</table>
<tableCaption confidence="0.999877">
Table 2: Results with n-class classification.
</tableCaption>
<bodyText confidence="0.9998274">
the mention is classified according to type of refer-
ring expression (proper name, common noun, pro-
noun, empty) and a RE of the proper type is chosen.
A predicate combinator was implemented to cre-
ate pairs of predicates for the classifier.
</bodyText>
<sectionHeader confidence="0.99992" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999971636363636">
Our results are shown in tables 1 and 2; table 3
shows further per-category results. N-class classi-
fication has a higher type accuracy than the binary
method(single: 61.13% versus 44.82%). Added
predicates made a notable difference (single, orig-
inal predicates: 40.40%; with added predicates:
50.30%). However, the predicates that detected con-
trasting discourse entities proved not to be helpful
(combinations: 59.30% declined to 58.54%). Fi-
nally, the predicate combinator improved all results
(binary, all predicates: 50.30% to 58.54%).
</bodyText>
<sectionHeader confidence="0.998902" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<subsectionHeader confidence="0.459211">
References
</subsectionHeader>
<bodyText confidence="0.929517826086956">
Example 1: Albania
The Republic of Albania itself is a
Balkan country in Southeastern Europe.
Which itself borders Montenegro to the
north, the Serbian province of Kosovo to
the northeast, the Republic of Macedonia
in the east, and Greece in the south.
In example 1, both mentions are matched with an RE
that is the proper type (proper name and pronoun,
respectively), yet the result is undesireable.
A different example typical of the binary classifi-
cation method is shown in example 2.
Example 2: Alfred Nobel
Alfred Nobel was a Swedish chemist,
engineer, innovator, armaments manufac-
turer and the inventor of dynamite. [...] In
his last will, Alfred Nobel used his enor-
mous fortune to institute the Nobel Prizes.
In example 2, the use of predicates specific to each
RE besides the type causes use of the RE ”Alfred
Nobel” as a subject, and the RE ”his” as a posses-
sive pronoun. The text, if mildly repetitive, is still
comprehensible.
</bodyText>
<sectionHeader confidence="0.98127" genericHeader="references">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.918725533333333">
In this study, we used discourse-level predicates and
binary and n-class maximum entropy classifiers to
select referring expressions. Eventually, we plan
to combine these two approaches, first selecting all
REs of the appropriate type and then ranking them.
The n-class method does not evaluate characteristics
of each individual referring expression. However,
the accuracy measure is designed to judge appro-
priateness of a referring expression based only on
whether its type is correct. A typical high-accuracy
n-class result is shown in example 1.
System City Ctry Mnt River Pple
b-all 53.54 57.61 49.58 75.00 65.85
b-nonRE 51.52 53.26 45.83 40.00 57.07
n-nonRE 53.54 63.04 61.67 65.00 67.32
</bodyText>
<tableCaption confidence="0.989332">
Table 3: Challenge-submitted results by category.
</tableCaption>
<reference confidence="0.961881785714286">
Anya Belz and Albert Gatt. 2008. REG
Challenge 2008: Participants Pack.
http://www.nltg.brighton.ac.uk/research/reg08/.
A. L. Berger, S. D. Pietra, and V. D. Pietra. 1996. A
maximum entropy approach to natural language pro-
cessing. Computational Linguistcs, 22(1):39–71.
Min-Yen Kan, Kathleen R. McKeown, and Judith L. Kla-
vans. 2001. Applying natural language generation to
indicative summarization. EWNLG ’01: Proceedings
of the 8th European workshop on Natural Language
Generation.
Zhang Le. 2004. Maximum Entropy
Modeling Toolkit for Python and C++.
http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.
</reference>
<page confidence="0.996583">
197
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.948135">
<title confidence="0.998142">OSU-2: Generating Referring with a Maximum Entropy Classifier</title>
<author confidence="0.999943">Emily Jamison</author>
<affiliation confidence="0.999798">Department of Linguistics The Ohio State University</affiliation>
<address confidence="0.999994">Columbus, OH 43210, USA</address>
<email confidence="0.999878">jamison@ling.osu.edu</email>
<author confidence="0.994967">Dennis Mehay</author>
<affiliation confidence="0.999755">Department of Linguistics The Ohio State University</affiliation>
<address confidence="0.999975">Columbus, OH 43210, USA</address>
<email confidence="0.999803">mehay@ling.osu.edu</email>
<abstract confidence="0.996668307692308">Selection of natural-sounding referring expressions is useful in text generation and information summarization (Kan et al., 2001). We use discourse-level feature predicates in a maximum entropy classifier (Berger et al., 1996) with binary and n-class classification to select referring expressions from a list. We find that while mention-type n-class classification produces higher accuracy of type, binary classification of individual referring expressions helps to avoid use of awkward referring expressions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anya Belz</author>
<author>Albert Gatt</author>
</authors>
<date>2008</date>
<journal>REG Challenge</journal>
<note>Participants Pack. http://www.nltg.brighton.ac.uk/research/reg08/.</note>
<contexts>
<context position="1146" citStr="Belz and Gatt, 2008" startWordPosition="163" endWordPosition="166">6) with binary and n-class classification to select referring expressions from a list. We find that while mention-type n-class classification produces higher accuracy of type, binary classification of individual referring expressions helps to avoid use of awkward referring expressions. 1 Introduction Referring expression generation is the task of inserting noun phrases that refer to a mentioned extralinguistic entity into a text. REG is helpful for tasks such as text generation and information summarization (Kan et al., 2001). 2 Task Description The Referring Expressions Generation Challenge (Belz and Gatt, 2008) includes a task based on the GREC corpus, a collection of introductory texts from Wikipedia that includes articles about cities, countries, rivers, people, and mountains. In this corpus, the main topic of each text (MSR) has been replaced with a list of possible referring expressions (REs). The objective of the task is to identify the most appropriate referring expression from the list for each mention of the MSR, given the surrounding text and annotated syntactic and semantic information. 3 Predicates We created 13 predicates, in addition to the six predicates available with the corpus. All </context>
</contexts>
<marker>Belz, Gatt, 2008</marker>
<rawString>Anya Belz and Albert Gatt. 2008. REG Challenge 2008: Participants Pack. http://www.nltg.brighton.ac.uk/research/reg08/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>S D Pietra</author>
<author>V D Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistcs,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="2463" citStr="Berger et al., 1996" startWordPosition="369" endWordPosition="372"> used with the n-class classification method. Predicates describe: string similarity of the RE and the title of the article, the mention’s order in the article, distance between previous mention and current mention, and detection of a contrastive discourse entity in the text.1 4 Maximum Entropy Classifier We defined indicator feature functions for a number of contextual predicates, each describing a pairing of some potential property of the syntactico-semantic and discourse context of a RE (a ‘predicate’) and a label. These feature functions fi were used to train a maximum entropy classifier (Berger et al., 1996) (Le, 2004) that assigns a probability to a RE re given context cx as follows: n p(re |cx) = Z(cx) exp Aifi(cx, re) i=1 where Z(cx) is a normalizing sum and the Ai are the parameters (feature weights) learned. Two classification systems were used: binary and n-class. With the binary method, the classifier estimates the likelihood of a possible referring expression’s correct insertion into the text, and inserts the RE with the highest ’yes’ probability. With the n-class method, 1More details at http://www.ling.ohio-state.edu/˜jamison 196 Predicates Used Single Combinations GREC predicates 40.40</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. L. Berger, S. D. Pietra, and V. D. Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistcs, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min-Yen Kan</author>
<author>Kathleen R McKeown</author>
<author>Judith L Klavans</author>
</authors>
<title>Applying natural language generation to indicative summarization.</title>
<date>2001</date>
<booktitle>EWNLG ’01: Proceedings of the 8th European workshop on Natural Language Generation.</booktitle>
<contexts>
<context position="1057" citStr="Kan et al., 2001" startWordPosition="150" endWordPosition="153">discourse-level feature predicates in a maximum entropy classifier (Berger et al., 1996) with binary and n-class classification to select referring expressions from a list. We find that while mention-type n-class classification produces higher accuracy of type, binary classification of individual referring expressions helps to avoid use of awkward referring expressions. 1 Introduction Referring expression generation is the task of inserting noun phrases that refer to a mentioned extralinguistic entity into a text. REG is helpful for tasks such as text generation and information summarization (Kan et al., 2001). 2 Task Description The Referring Expressions Generation Challenge (Belz and Gatt, 2008) includes a task based on the GREC corpus, a collection of introductory texts from Wikipedia that includes articles about cities, countries, rivers, people, and mountains. In this corpus, the main topic of each text (MSR) has been replaced with a list of possible referring expressions (REs). The objective of the task is to identify the most appropriate referring expression from the list for each mention of the MSR, given the surrounding text and annotated syntactic and semantic information. 3 Predicates We</context>
</contexts>
<marker>Kan, McKeown, Klavans, 2001</marker>
<rawString>Min-Yen Kan, Kathleen R. McKeown, and Judith L. Klavans. 2001. Applying natural language generation to indicative summarization. EWNLG ’01: Proceedings of the 8th European workshop on Natural Language Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhang Le</author>
</authors>
<date>2004</date>
<booktitle>Maximum Entropy Modeling Toolkit for Python and C++. http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.</booktitle>
<contexts>
<context position="2474" citStr="Le, 2004" startWordPosition="373" endWordPosition="374"> classification method. Predicates describe: string similarity of the RE and the title of the article, the mention’s order in the article, distance between previous mention and current mention, and detection of a contrastive discourse entity in the text.1 4 Maximum Entropy Classifier We defined indicator feature functions for a number of contextual predicates, each describing a pairing of some potential property of the syntactico-semantic and discourse context of a RE (a ‘predicate’) and a label. These feature functions fi were used to train a maximum entropy classifier (Berger et al., 1996) (Le, 2004) that assigns a probability to a RE re given context cx as follows: n p(re |cx) = Z(cx) exp Aifi(cx, re) i=1 where Z(cx) is a normalizing sum and the Ai are the parameters (feature weights) learned. Two classification systems were used: binary and n-class. With the binary method, the classifier estimates the likelihood of a possible referring expression’s correct insertion into the text, and inserts the RE with the highest ’yes’ probability. With the n-class method, 1More details at http://www.ling.ohio-state.edu/˜jamison 196 Predicates Used Single Combinations GREC predicates 40.40% 50.91% al</context>
</contexts>
<marker>Le, 2004</marker>
<rawString>Zhang Le. 2004. Maximum Entropy Modeling Toolkit for Python and C++. http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>