<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000431">
<title confidence="0.9946285">
Teaching NLP to Computer Science Majors via Applications and
Experiments
</title>
<author confidence="0.992657">
Reva Freedman
</author>
<affiliation confidence="0.9851235">
Department of Computer Science
Northern Illinois University
</affiliation>
<address confidence="0.878139">
DeKalb, IL 60115
</address>
<email confidence="0.995366">
rfreedman@niu.edu
</email>
<sectionHeader confidence="0.993827" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999098058823529">
Most computer science majors at Northern
Illinois University, whether at the B.S. or M.S.
level, are professionally oriented. However,
some of the best students are willing to try
something completely different. NLP is a
challenge for them because most have no
background in linguistics or artificial
intelligence, have little experience in reading
traditional academic prose, and are unused to
open-ended assignments with gray areas. In
this paper I describe a syllabus for Introduction
to NLP that concentrates on applications and
motivates concepts through student
experiments. Core materials include an
introductory linguistics textbook, the Jurafsky
and Martin textbook, the NLTK book, and a
Python textbook.
</bodyText>
<sectionHeader confidence="0.998949" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999525684210526">
Northern Illinois University is a large public
university (25,000 students) located about 60 miles
west of Chicago. Most computer science majors
come from the suburbs and exurbs of Chicago or
small towns near the university. Their preferred
career path is generally to obtain a programming
job in local industry, preferably in a hi-tech area.
Most students take the Introduction to NLP course
out of a desire to do something different from their
required courses.
In this paper I describe the issues I have found in
teaching NLP to this population, and the syllabus I
have developed as a result. Since the students
enjoy programming and see system development
as the core issue of computer science, I concentrate
on applications and their structure. I motivate
many of the issues involved using data and systems
from the web and in-class experiments. I explicitly
teach the linguistics background that they need.
</bodyText>
<sectionHeader confidence="0.948346" genericHeader="introduction">
2 Student background
</sectionHeader>
<bodyText confidence="0.9989765">
I started from the following assumptions derived
from several years of teaching Introduction to
Artificial Intelligence and Introduction to NLP at
NIU.
</bodyText>
<listItem confidence="0.987536923076923">
Linguistic background:
1. Students have never studied linguistics.
2. Students are not familiar with the common
syntactic constructions of English taught in
traditional English grammar, and are often unsure
about parts of speech.
3. Students have little experience with languages
other than English.
Programming:
4. Students are not familiar with programming
languages other than conventional imperative
languages such as C++, Java, and .NET.
5. Students like to program and to build working
systems.
6. Students expect to have programming
languages explicitly taught in class.
Academic approach:
7. Students live on the web and are
uncomfortable having to use offline reference
materials.
8. Students are not comfortable with or
interested in traditional academic prose or research
papers.
9. Students are taking the course for fun and to
do something different. They are unlikely to need
specific NLP content in their future careers.
</listItem>
<page confidence="0.971638">
114
</page>
<note confidence="0.389547">
Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics (TeachCL-08), pages 114–119,
</note>
<page confidence="0.460147">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.963911">
10. Students taking NLP are unlikely to have
time in their program to take another artificial
intelligence course (although there are exceptions).
</bodyText>
<sectionHeader confidence="0.956936" genericHeader="method">
3 Course goals
</sectionHeader>
<bodyText confidence="0.997518">
From these presuppositions I have developed the
following general principles to provide a positive
experience for both students and teacher:
</bodyText>
<listItem confidence="0.97659725">
1. Teach the linguistic content explicitly, at a
level suitable for beginners.
2. Concentrate on applications, using them to
motivate algorithms.
3. Concentrate on student involvement at all
levels: in-class experiments, take-home
experiments to be discussed in class, and practical
programming projects.
4. Concentrate on a few basic principles that are
repeated in many contexts, such as rule-based vs.
Bayesian approaches and the role of world
knowledge in working systems.
</listItem>
<bodyText confidence="0.860239142857143">
From these presuppositions I have developed a
syllabus that maintains student interest, provides
students a basic background in NLP, and also
provides them with useful skills and knowledge
that they may not otherwise encounter in their
program of study.
The course has three goals:
</bodyText>
<listItem confidence="0.999842733333333">
1. Give students a general background in the
issues involved in handling both speech and
written text, some of the most common
applications, and some of the most widely used
algorithms.
2. Provide students with a productive experience
in a modern programming language.
3. Teach students a number of useful concepts
that they might not otherwise come across in their
course of study. These topics include:
• Bayes’ Law
• Dynamic programming
• Hidden Markov models
• Regular expressions and finite-state machines
• Context-free grammars
</listItem>
<bodyText confidence="0.98888375">
The following sections of the paper describe the
most important units of the course, showing how
they use the principles stated above to contribute to
these goals.
</bodyText>
<sectionHeader confidence="0.997057" genericHeader="method">
4 Introducing NLP
</sectionHeader>
<bodyText confidence="0.9999895">
The first goal of the course is to define the NLP
task and explain why it is harder and less
determinate than many of the problems they have
studied in their other courses.
I start by encouraging students to list all the
meanings they can for “I made her duck”, based on
the five meanings given by Jurafsky and Martin
(2000, section 1.2). For a view of a system that can
deal with such issues, I then introduce Figure 1.1
of Bird, Klein, and Loper (2008, henceforce
referred to as the NLTK textbook), which shows a
pipeline architecture for a spoken dialogue system.
I use this opportunity to discuss each component
and possible data representations.
</bodyText>
<sectionHeader confidence="0.879792" genericHeader="method">
5 Providing linguistic background
</sectionHeader>
<bodyText confidence="0.997427333333333">
I introduce three kinds of background knowledge,
related to speech, words and sentences, and human
factors issues.
</bodyText>
<subsectionHeader confidence="0.955229">
5.1 Background for speech processing
</subsectionHeader>
<bodyText confidence="0.999756857142857">
To provide essential background for discussing
speech processing, I introduce the concepts of
phone and phoneme. I also teach give a brief
introduction to the IPA so that I can use it in
examples. I use the following sections from
Stewart and Vaillette (2001), a textbook for
introductory linguistics classes:
</bodyText>
<construct confidence="0.4643992">
File 3.1: International Phonetic Alphabet (IPA)
File 3.2: English consonants
File 3.3: English vowels
File 3.5: English transcription exercises
File 4.1: Phones vs. phonemes
</construct>
<bodyText confidence="0.9034263">
These sections were chosen to provide the
background students need while providing
maximum opportunities for interaction. Students
have found this approach more accessible than the
rather terse treatment in Jurafsky and Martin
(2000, ch. 4). I do the following activities, familiar
to teachers of introductory linguistics classes, in
class:
• Putting one’s fingers on the glottis to experience
the difference between voiced and unvoiced
</bodyText>
<page confidence="0.995284">
115
</page>
<bodyText confidence="0.969088">
recur frequently during the semester. This is a
good place to discuss the importance of separating
training data and test data.
</bodyText>
<figure confidence="0.881613333333333">
6 Python
consonants
• Putting one’s hand in front of one’s mouth to
experience the difference between aspirated and
unaspirated consonants
• Reading IPA transcription in pairs
</figure>
<bodyText confidence="0.984648571428571">
I also introduce students to the idea that both
pronunciation and other areas of human language
generation are affected by context. For example,
using Figure 5.7 of Jurafsky and Martin (2000) as
a guide, I try to generate as many as possible of the
sixteen most common pronunciations of because
shown in that figure.
</bodyText>
<subsectionHeader confidence="0.97878">
5.2 Background for text processing
</subsectionHeader>
<bodyText confidence="0.99998025">
As background for the text processing section, I
lecture on a few core aspects of syntax and related
topics that will be needed during the semester.
These topics include the following:
</bodyText>
<listItem confidence="0.9945315">
• What is a word?
• How many parts of speech are there?
• Lexical ambiguity
• Syntactic ambiguity, including PP attachment,
attachment of gerunds, and coordination
ambiguity
• Difference between syntactic structure and
intention
</listItem>
<subsectionHeader confidence="0.987751">
5.3 Background in human factors issues
</subsectionHeader>
<bodyText confidence="0.99991135">
This section includes several topics that experience
has shown will be needed during the semester.
The first is the difference between descriptive
and prescriptive linguistics. I take class polls on
various sociolinguistic issues, including
pronunciation, word choice and sentence structure,
using File 10.10: Language variation from Stewart
and Vaillette (2001) as a basis.
I take a poll on the pronunciation of the word
office, choosing that word since the distribution of
its first vowel is sensitive both to geography and
speaker age. The poll gives me an opportunity to
introduce some of the human factors issues related
to corpus collection and the issue of statistical
significance. We also examine some data
collection tasks found on the Internet, using them
to discuss experimental design and how it relates to
the data collected.
Finally, I begin a discussion on the difference
between rule-based and statistical systems that will
</bodyText>
<subsectionHeader confidence="0.998266">
6.1 Basic Python
</subsectionHeader>
<bodyText confidence="0.9972408">
The next step is to teach basic Python so that there
will be time for some practice programs before the
first major programming project. As computer
science majors, the students tend to find that the
treatment in the NLTK textbook does not answer
enough of their technical questions, such as issues
on argument handling and copying of objects
vs. references to them.
I give several lectures on Python, including the
following topics:
</bodyText>
<listItem confidence="0.9999664">
• Basic data structures
• Basic control structures
• Functions and modules
• Objects
• File handling
</listItem>
<bodyText confidence="0.7468195">
I have found Lutz (2008) to be the most readable
introductory textbook. I use Chun (2007) as a
reference for topics not covered by Lutz, such as
regular expressions and some of the I/O options.
</bodyText>
<subsectionHeader confidence="0.998859">
6.2 Using Python for basic language
</subsectionHeader>
<bodyText confidence="0.988212277777778">
handling
This unit basically covers the material in chapters
2, 3, and 6 of the NLTK textbook. The goal is to
show students how easily some of these problems
can be handled with an appropriate programming
language. Many of them are quite uncomfortable
with the idea of a list not implemented with
pointers, but in the end they cope well with a
language that does not have all the baggage of
C++.
I give a simple assignment that involves finding
the most common words in a corpus. A secondary
purpose of this assignment is to reinforce the
earlier lecture on the difficulty of defining a word.
I lard the input text for the assignment with
problematic cases such as hyphenated multiword
expressions, e.g., “the orange-juice based
confection.”
</bodyText>
<page confidence="0.999101">
116
</page>
<sectionHeader confidence="0.971917" genericHeader="method">
7 Rule-based dialogue systems using
</sectionHeader>
<subsectionHeader confidence="0.631827">
regular expressions
</subsectionHeader>
<bodyText confidence="0.999902777777777">
Since later in the course we will be comparing
rule-based systems to statistics-based systems, this
is an appropriate time to introduce rule based
systems. We experiment in class with Eliza, trying
both to make it work and make it fail. I give out a
list of versions available on the web, and students
can easily find more. In class I often use the emacs
built-in version.
I then give out copies of the original Eliza paper
(Weizenbaum, 1966), which contains the original
script in an appendix. If time permits, I also
discuss PARRY (Parkison, Colby and Faught,
1977), which has a much more linguistically
sophisticated design but there is no simulator
available for it.
I introduce regular expressions at this point for
two reasons. In addition to being required for
continued use of the NLTK textbook, regular
expressions are an important idea that is not
otherwise included in our curriculum. We
experiment with Rocky Ross’ interactive web site
(Pascoe, 2005) and occasionally with other
simulators. I also assign a simple homework using
regular expressions in Python.
The first major project in the course is to write
an shallow interactive written dialogue system, i.e.,
an Eliza-type program. Students have the choice of
choosing a more realistic, limited domain, such as
a database front-end, or of picking a specific case
(e.g., a linguistic issue) that they would like Eliza
to handle. This project is implemented in Python as
a rule-based system with heavy use of regular
expressions. Before they write their code, students
do a five-minute presentation of their domain,
including a sample conversation. After the projects
are due, they present their results to the class.
</bodyText>
<subsectionHeader confidence="0.499426">
8 Spelling correction and Bayes’ Law
</subsectionHeader>
<bodyText confidence="0.99982375862069">
Bayes’ Law is another core topic that students are
generally unfamiliar with, even though statistics is
required in our program. To provide a contrast to
rule-based systems, and to introduce this core
topic, I present Kernighan, Church and Gale’s
(1990) Bayesian approach to spelling correction, as
explained by Jurafsky and Martin (2000, section
5.5).
Kernighan et al. choose as the preferred
correction the one that maximizes P(t|c)P(c), where
t is the typo and c is a candidate correction. In a
previous paper (Freedman, 2005), I discuss in
detail an assignment where students choose a
corpus and replicate Kernighan’s calculations.
They then compare their results to results from
their favorite word processor.
Students are generally surprised at how similar
the results are from what they originally see as an
unmotivated calculation. They are always surprised
to learn that spelling correction is generally not
done by a lookup process. They are also surprised
to learn that learn that results were largely
independent of the corpus chosen.
I also demonstrate approximating word
frequencies by page counts in Google, along with a
discussion of the advantages and disadvantages of
doing so. In general, students prefer to use one of
the NLTK corpora or a corpus obtained from the
web.
</bodyText>
<sectionHeader confidence="0.93443" genericHeader="method">
9 Machine translation: rule-based and
</sectionHeader>
<subsectionHeader confidence="0.911557">
statistical models
</subsectionHeader>
<bodyText confidence="0.998564444444444">
This unit has several purposes. In addition to
showing students how the same problem can be
attacked in remarkably different ways, including
multiple levels of rule-based and statistically-based
systems, machine translation gives students a look
at a fielded application that is good enough to be
viable but sill obviously needs improvement.
To the extent that information is publicly
available, I discuss the architecture of one of the
oldest machine translation systems, Systran
(Babelfish), and one of the newest, Microsoft Live
Translator. The latter uses components from
MindNet, Microsoft’s knowledge representation
project, which provides another opportunity to
reinforce the importance of world knowledge in
artificial intelligence and NLP in particular. It also
provides an initial opportunity to discuss the
concept of machine learning as opposed to hand-
crafting rules or databases.
As the assignment for this unit, students choose
a short text in a foreign language. They use
multiple web-based translation systems to translate
it into English, and analyze the results. In addition
to the systems mentioned above, the Reverso
system has done well in these experiments.
Popular inputs include administrative text (e.g.,
citizenship rules) from a bilingual country and
</bodyText>
<page confidence="0.995114">
117
</page>
<bodyText confidence="0.999670285714286">
chapter 1 of Genesis. One student started with a
French version of the Tolkien poem “... one ring to
rule them all...” Although translation of poetry
obviously poses different issues than technical text,
a fruitful discussion emerged from the fact that two
of the systems misparsed one or more of the lines
of the poem.
</bodyText>
<sectionHeader confidence="0.974725" genericHeader="method">
10 POS identification, parsing and
</sectionHeader>
<subsectionHeader confidence="0.701996">
author identification
</subsectionHeader>
<bodyText confidence="0.99997582051282">
This unit of the course covers key sections of
chapters 4, 7, 8 and 9 of the NLTK textbook.
Although one student originally stated that “I
really don’t care about parts of speech,” students
find this material more interesting after seeing how
many of the machine translation errors are caused
by parsing errors. Still, I only cover POS
assignment enough to use it for chunking and
parsing.
The application chosen for this unit involves
author identification. I introduce students to the
basics of the Federalist Papers controversy. Then I
discuss the approach of Mosteller and Wallace
(1984), which depends largely on words used
much more frequently by one author than the
other, such as while and whilst.
I suggest to students that more interesting results
could perhaps be obtained if data about items such
as part of speech use and use of specific
constructions of English were added to the input.
As an alternative assignment, I give students
transcripts of tutoring by two different professors
and invite them to identify the authors of
additional transcripts from a test set. A secondary
goal of this assignment is for students to see the
level of cleanup that live data can require.
This assignment also shows students the relative
difficulty level of chunking vs. parsing better than
any lecture could. This is useful because students
otherwise tend to find chunking too ad hoc for
their taste.
I do teach several approaches to parsing since
many students will not otherwise see context-free
grammars in their studies. Having had the
experiences with machine translation systems helps
prevent the reaction of a previous class to Earley’s
algorithm: “we understand it; it’s just not
interesting.” I also frame Earley’s algorithm as
another example of dynamic programming.
</bodyText>
<sectionHeader confidence="0.648033" genericHeader="method">
11 Speech understanding
</sectionHeader>
<bodyText confidence="0.99999104">
Students generally find speech a much more
compelling application than written text. In this
unit I discuss how basic speech processing works.
This unit provides a nice review of the basics of
phonology taught at the beginning of the semester.
It also provides a nice review of Bayes’ Law
because the approach used, based on Jurafsky and
Martin (2000, ch. 5.7–5.9) uses Bayes’ Law in a
fashion similar to spelling correction.
The assignment for this unit involves
experimenting with publicly available speech
understanding systems to see how well they work.
The assignment involves comparing two automated
411 systems, Google’s new system
(1-800-GOOG411), which was built specifically
for data collection, and Jingle (1-800-FREE411),
which is advertising-supported. I also encourage
students to report on their own experiments with
bank, airline, and other systems.
I give at least one anonymous questionnaire
every semester. Students generally report that the
level of detail is appropriate. They generally vote
for more topics as opposed to more depth, and they
always vote for more programming assignments
and real systems rather than theory.
</bodyText>
<sectionHeader confidence="0.994444" genericHeader="method">
12 Future work
</sectionHeader>
<bodyText confidence="0.999651076923077">
I am considering replacing author identification by
question answering, both because it is an important
and practical topic and because I think it would
provide better motivation for teaching chunking. I
am also considering keeping author identification
and adding the use of a machine learning package
to that unit, since I believe that machine learning is
rapidly becoming a concept that all students should
be exposed to before they graduate.
My long-term goal is to have students build an
end-to-end system. A short-term goal in service of
this objective would be to add a unit on text-to-
speech systems.
</bodyText>
<sectionHeader confidence="0.990717" genericHeader="conclusions">
13 Conclusions
</sectionHeader>
<bodyText confidence="0.9998556">
This paper described a syllabus for teaching NLP
to computer science majors with no background in
the topic. Students enjoyed the course more and
were more apt to participate when the course was
oriented toward applications such as dialogue
</bodyText>
<page confidence="0.994645">
118
</page>
<bodyText confidence="0.999880142857143">
systems, machine translation, spelling correction
and author identification. Students also learned
about the architecture of these systems and the
algorithms underlying them. Students implemented
versions of some of the smaller applications and
experimented with web versions of large fielded
systems such as machine translation systems.
</bodyText>
<sectionHeader confidence="0.998278" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99996">
I thank the authors of Jurafsky and Martin (2000)
and Bird, Klein and Loper (2008), whose extensive
labor has made it possible to teach this course. I
would also like to thank the anonymous reviewers
for their suggestions.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999668225">
Steven Bird, Ewan Klein, and Edward Loper. (2008).
Natural Language Processing in Python. Available
on the web at http://nltk.org/index.php/Book.
Wesley J. Chun. (2007). Core Python Programming,
2/e. Upper Saddle River, NJ: Prentice-Hall.
Reva Freedman. (2005). Concrete Assignments for
Teaching NLP in an M.S. Program. In Second
Workshop on Effective Tools and Methodologies for
Teaching NLP and CL, 43rd Annual Meeting of the
ACL.
Daniel Jurafsky and James H. Martin. (2000). Speech
and Language Processing. Upper Saddle River, NJ:
Prentice-Hall.
Mark Lutz. (2008). Learning Python, 3/e. Sebastopol,
CA: O’Reilly.
Mark D. Kernighan, Kenneth W. Church, and William
A. Gale. (1990). A spelling correction program based
on a noisy channel model. In COLING ’90
(Helsinki), v. 2, pp. 205–211.
Frederick and Mosteller and David L. Wallace. (1984).
Applied Bayesian and Classical Inference: The Case
of The Federalist Papers. New York: Springer.
Originally published in 1964 as Inference and
Disputed Authorship: The Federalist.
Brad Pascoe (2005). Webworks FSA applet. Available
at http://www.cs.montana.edu/webworks/projects/
theoryportal/models/fsa-exercise/appletCode/
fsa_applet.html.
Roger C. Parkison, Kenneth Mark Colby, and William
S. Faught. (1977). Conversational Language
Comprehension Using Integrated Pattern-Matching
and Parsing. Artificial Intelligence 9: 111–134.
Thomas W. Stewart, Jr. and Nathan Vaillette. (2001).
Language Files: Materials for an Introduction to
Language and Linguistics, 8/e. Columbus: Ohio
State University Press.
Joseph Weizenbaum. (1966). Eliza—A Computer
Program for the Study of Natural Language
Computation between Man and Machine.
Communications of the ACM 9(1): 36–45.
</reference>
<page confidence="0.999092">
119
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.157092">
<title confidence="0.996265">Teaching NLP to Computer Science Majors via Applications and Experiments</title>
<author confidence="0.906515">Reva</author>
<affiliation confidence="0.8461685">Department of Computer Northern Illinois</affiliation>
<address confidence="0.75447">DeKalb, IL</address>
<email confidence="0.999052">rfreedman@niu.edu</email>
<abstract confidence="0.997387">Most computer science majors at Northern Illinois University, whether at the B.S. or M.S. level, are professionally oriented. However, some of the best students are willing to try something completely different. NLP is a challenge for them because most have no background in linguistics or artificial intelligence, have little experience in reading traditional academic prose, and are unused to</abstract>
<note confidence="0.363221">open-ended assignments with gray areas. In</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Ewan Klein</author>
<author>Edward Loper</author>
</authors>
<title>Natural Language Processing in Python. Available on the web at http://nltk.org/index.php/Book.</title>
<date>2008</date>
<marker>Bird, Klein, Loper, 2008</marker>
<rawString>Steven Bird, Ewan Klein, and Edward Loper. (2008). Natural Language Processing in Python. Available on the web at http://nltk.org/index.php/Book.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wesley J Chun</author>
</authors>
<date>2007</date>
<booktitle>Core Python Programming, 2/e. Upper Saddle</booktitle>
<publisher>Prentice-Hall.</publisher>
<location>River, NJ:</location>
<contexts>
<context position="9370" citStr="Chun (2007)" startWordPosition="1454" endWordPosition="1455"> is to teach basic Python so that there will be time for some practice programs before the first major programming project. As computer science majors, the students tend to find that the treatment in the NLTK textbook does not answer enough of their technical questions, such as issues on argument handling and copying of objects vs. references to them. I give several lectures on Python, including the following topics: • Basic data structures • Basic control structures • Functions and modules • Objects • File handling I have found Lutz (2008) to be the most readable introductory textbook. I use Chun (2007) as a reference for topics not covered by Lutz, such as regular expressions and some of the I/O options. 6.2 Using Python for basic language handling This unit basically covers the material in chapters 2, 3, and 6 of the NLTK textbook. The goal is to show students how easily some of these problems can be handled with an appropriate programming language. Many of them are quite uncomfortable with the idea of a list not implemented with pointers, but in the end they cope well with a language that does not have all the baggage of C++. I give a simple assignment that involves finding the most commo</context>
</contexts>
<marker>Chun, 2007</marker>
<rawString>Wesley J. Chun. (2007). Core Python Programming, 2/e. Upper Saddle River, NJ: Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reva Freedman</author>
</authors>
<title>Concrete Assignments for Teaching NLP in an M.S.</title>
<date>2005</date>
<booktitle>Program. In Second Workshop on Effective Tools and Methodologies for Teaching NLP and CL, 43rd Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="12562" citStr="Freedman, 2005" startWordPosition="1978" endWordPosition="1979">re due, they present their results to the class. 8 Spelling correction and Bayes’ Law Bayes’ Law is another core topic that students are generally unfamiliar with, even though statistics is required in our program. To provide a contrast to rule-based systems, and to introduce this core topic, I present Kernighan, Church and Gale’s (1990) Bayesian approach to spelling correction, as explained by Jurafsky and Martin (2000, section 5.5). Kernighan et al. choose as the preferred correction the one that maximizes P(t|c)P(c), where t is the typo and c is a candidate correction. In a previous paper (Freedman, 2005), I discuss in detail an assignment where students choose a corpus and replicate Kernighan’s calculations. They then compare their results to results from their favorite word processor. Students are generally surprised at how similar the results are from what they originally see as an unmotivated calculation. They are always surprised to learn that spelling correction is generally not done by a lookup process. They are also surprised to learn that learn that results were largely independent of the corpus chosen. I also demonstrate approximating word frequencies by page counts in Google, along </context>
</contexts>
<marker>Freedman, 2005</marker>
<rawString>Reva Freedman. (2005). Concrete Assignments for Teaching NLP in an M.S. Program. In Second Workshop on Effective Tools and Methodologies for Teaching NLP and CL, 43rd Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing. Upper Saddle River,</title>
<date>2000</date>
<publisher>Prentice-Hall.</publisher>
<location>NJ:</location>
<contexts>
<context position="5240" citStr="Jurafsky and Martin (2000" startWordPosition="800" endWordPosition="803">aw • Dynamic programming • Hidden Markov models • Regular expressions and finite-state machines • Context-free grammars The following sections of the paper describe the most important units of the course, showing how they use the principles stated above to contribute to these goals. 4 Introducing NLP The first goal of the course is to define the NLP task and explain why it is harder and less determinate than many of the problems they have studied in their other courses. I start by encouraging students to list all the meanings they can for “I made her duck”, based on the five meanings given by Jurafsky and Martin (2000, section 1.2). For a view of a system that can deal with such issues, I then introduce Figure 1.1 of Bird, Klein, and Loper (2008, henceforce referred to as the NLTK textbook), which shows a pipeline architecture for a spoken dialogue system. I use this opportunity to discuss each component and possible data representations. 5 Providing linguistic background I introduce three kinds of background knowledge, related to speech, words and sentences, and human factors issues. 5.1 Background for speech processing To provide essential background for discussing speech processing, I introduce the conc</context>
<context position="6470" citStr="Jurafsky and Martin (2000" startWordPosition="987" endWordPosition="990">of phone and phoneme. I also teach give a brief introduction to the IPA so that I can use it in examples. I use the following sections from Stewart and Vaillette (2001), a textbook for introductory linguistics classes: File 3.1: International Phonetic Alphabet (IPA) File 3.2: English consonants File 3.3: English vowels File 3.5: English transcription exercises File 4.1: Phones vs. phonemes These sections were chosen to provide the background students need while providing maximum opportunities for interaction. Students have found this approach more accessible than the rather terse treatment in Jurafsky and Martin (2000, ch. 4). I do the following activities, familiar to teachers of introductory linguistics classes, in class: • Putting one’s fingers on the glottis to experience the difference between voiced and unvoiced 115 recur frequently during the semester. This is a good place to discuss the importance of separating training data and test data. 6 Python consonants • Putting one’s hand in front of one’s mouth to experience the difference between aspirated and unaspirated consonants • Reading IPA transcription in pairs I also introduce students to the idea that both pronunciation and other areas of human </context>
<context position="12370" citStr="Jurafsky and Martin (2000" startWordPosition="1944" endWordPosition="1947"> as a rule-based system with heavy use of regular expressions. Before they write their code, students do a five-minute presentation of their domain, including a sample conversation. After the projects are due, they present their results to the class. 8 Spelling correction and Bayes’ Law Bayes’ Law is another core topic that students are generally unfamiliar with, even though statistics is required in our program. To provide a contrast to rule-based systems, and to introduce this core topic, I present Kernighan, Church and Gale’s (1990) Bayesian approach to spelling correction, as explained by Jurafsky and Martin (2000, section 5.5). Kernighan et al. choose as the preferred correction the one that maximizes P(t|c)P(c), where t is the typo and c is a candidate correction. In a previous paper (Freedman, 2005), I discuss in detail an assignment where students choose a corpus and replicate Kernighan’s calculations. They then compare their results to results from their favorite word processor. Students are generally surprised at how similar the results are from what they originally see as an unmotivated calculation. They are always surprised to learn that spelling correction is generally not done by a lookup pro</context>
<context position="17192" citStr="Jurafsky and Martin (2000" startWordPosition="2707" endWordPosition="2710">aving had the experiences with machine translation systems helps prevent the reaction of a previous class to Earley’s algorithm: “we understand it; it’s just not interesting.” I also frame Earley’s algorithm as another example of dynamic programming. 11 Speech understanding Students generally find speech a much more compelling application than written text. In this unit I discuss how basic speech processing works. This unit provides a nice review of the basics of phonology taught at the beginning of the semester. It also provides a nice review of Bayes’ Law because the approach used, based on Jurafsky and Martin (2000, ch. 5.7–5.9) uses Bayes’ Law in a fashion similar to spelling correction. The assignment for this unit involves experimenting with publicly available speech understanding systems to see how well they work. The assignment involves comparing two automated 411 systems, Google’s new system (1-800-GOOG411), which was built specifically for data collection, and Jingle (1-800-FREE411), which is advertising-supported. I also encourage students to report on their own experiments with bank, airline, and other systems. I give at least one anonymous questionnaire every semester. Students generally repor</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Daniel Jurafsky and James H. Martin. (2000). Speech and Language Processing. Upper Saddle River, NJ: Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Lutz</author>
</authors>
<date>2008</date>
<booktitle>Learning Python, 3/e.</booktitle>
<location>Sebastopol, CA: O’Reilly.</location>
<contexts>
<context position="9305" citStr="Lutz (2008)" startWordPosition="1443" endWordPosition="1444"> and statistical systems that will 6.1 Basic Python The next step is to teach basic Python so that there will be time for some practice programs before the first major programming project. As computer science majors, the students tend to find that the treatment in the NLTK textbook does not answer enough of their technical questions, such as issues on argument handling and copying of objects vs. references to them. I give several lectures on Python, including the following topics: • Basic data structures • Basic control structures • Functions and modules • Objects • File handling I have found Lutz (2008) to be the most readable introductory textbook. I use Chun (2007) as a reference for topics not covered by Lutz, such as regular expressions and some of the I/O options. 6.2 Using Python for basic language handling This unit basically covers the material in chapters 2, 3, and 6 of the NLTK textbook. The goal is to show students how easily some of these problems can be handled with an appropriate programming language. Many of them are quite uncomfortable with the idea of a list not implemented with pointers, but in the end they cope well with a language that does not have all the baggage of C++</context>
</contexts>
<marker>Lutz, 2008</marker>
<rawString>Mark Lutz. (2008). Learning Python, 3/e. Sebastopol, CA: O’Reilly.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark D Kernighan</author>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>A spelling correction program based on a noisy channel model.</title>
<date>1990</date>
<booktitle>In COLING ’90 (Helsinki),</booktitle>
<volume>2</volume>
<pages>205--211</pages>
<marker>Kernighan, Church, Gale, 1990</marker>
<rawString>Mark D. Kernighan, Kenneth W. Church, and William A. Gale. (1990). A spelling correction program based on a noisy channel model. In COLING ’90 (Helsinki), v. 2, pp. 205–211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick</author>
<author>Mosteller</author>
<author>David L Wallace</author>
</authors>
<title>Applied Bayesian and Classical Inference: The Case of The Federalist Papers.</title>
<date>1984</date>
<publisher>Springer.</publisher>
<location>New York:</location>
<note>Originally published in</note>
<marker>Frederick, Mosteller, Wallace, 1984</marker>
<rawString>Frederick and Mosteller and David L. Wallace. (1984). Applied Bayesian and Classical Inference: The Case of The Federalist Papers. New York: Springer. Originally published in 1964 as Inference and Disputed Authorship: The Federalist.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brad Pascoe</author>
</authors>
<title>Webworks FSA applet.</title>
<date>2005</date>
<note>Available at http://www.cs.montana.edu/webworks/projects/ theoryportal/models/fsa-exercise/appletCode/ fsa_applet.html.</note>
<contexts>
<context position="11275" citStr="Pascoe, 2005" startWordPosition="1774" endWordPosition="1775">emacs built-in version. I then give out copies of the original Eliza paper (Weizenbaum, 1966), which contains the original script in an appendix. If time permits, I also discuss PARRY (Parkison, Colby and Faught, 1977), which has a much more linguistically sophisticated design but there is no simulator available for it. I introduce regular expressions at this point for two reasons. In addition to being required for continued use of the NLTK textbook, regular expressions are an important idea that is not otherwise included in our curriculum. We experiment with Rocky Ross’ interactive web site (Pascoe, 2005) and occasionally with other simulators. I also assign a simple homework using regular expressions in Python. The first major project in the course is to write an shallow interactive written dialogue system, i.e., an Eliza-type program. Students have the choice of choosing a more realistic, limited domain, such as a database front-end, or of picking a specific case (e.g., a linguistic issue) that they would like Eliza to handle. This project is implemented in Python as a rule-based system with heavy use of regular expressions. Before they write their code, students do a five-minute presentatio</context>
</contexts>
<marker>Pascoe, 2005</marker>
<rawString>Brad Pascoe (2005). Webworks FSA applet. Available at http://www.cs.montana.edu/webworks/projects/ theoryportal/models/fsa-exercise/appletCode/ fsa_applet.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Parkison</author>
<author>Kenneth Mark Colby</author>
<author>William S Faught</author>
</authors>
<title>Conversational Language Comprehension Using Integrated Pattern-Matching and Parsing.</title>
<date>1977</date>
<journal>Artificial Intelligence</journal>
<volume>9</volume>
<pages>111--134</pages>
<marker>Parkison, Colby, Faught, 1977</marker>
<rawString>Roger C. Parkison, Kenneth Mark Colby, and William S. Faught. (1977). Conversational Language Comprehension Using Integrated Pattern-Matching and Parsing. Artificial Intelligence 9: 111–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathan Vaillette</author>
</authors>
<title>Language Files: Materials for an Introduction to Language and Linguistics, 8/e. Columbus: Ohio State</title>
<date>2001</date>
<publisher>University Press.</publisher>
<contexts>
<context position="6013" citStr="Vaillette (2001)" startWordPosition="926" endWordPosition="927"> the NLTK textbook), which shows a pipeline architecture for a spoken dialogue system. I use this opportunity to discuss each component and possible data representations. 5 Providing linguistic background I introduce three kinds of background knowledge, related to speech, words and sentences, and human factors issues. 5.1 Background for speech processing To provide essential background for discussing speech processing, I introduce the concepts of phone and phoneme. I also teach give a brief introduction to the IPA so that I can use it in examples. I use the following sections from Stewart and Vaillette (2001), a textbook for introductory linguistics classes: File 3.1: International Phonetic Alphabet (IPA) File 3.2: English consonants File 3.3: English vowels File 3.5: English transcription exercises File 4.1: Phones vs. phonemes These sections were chosen to provide the background students need while providing maximum opportunities for interaction. Students have found this approach more accessible than the rather terse treatment in Jurafsky and Martin (2000, ch. 4). I do the following activities, familiar to teachers of introductory linguistics classes, in class: • Putting one’s fingers on the glo</context>
<context position="8150" citStr="Vaillette (2001)" startWordPosition="1250" endWordPosition="1251">rd? • How many parts of speech are there? • Lexical ambiguity • Syntactic ambiguity, including PP attachment, attachment of gerunds, and coordination ambiguity • Difference between syntactic structure and intention 5.3 Background in human factors issues This section includes several topics that experience has shown will be needed during the semester. The first is the difference between descriptive and prescriptive linguistics. I take class polls on various sociolinguistic issues, including pronunciation, word choice and sentence structure, using File 10.10: Language variation from Stewart and Vaillette (2001) as a basis. I take a poll on the pronunciation of the word office, choosing that word since the distribution of its first vowel is sensitive both to geography and speaker age. The poll gives me an opportunity to introduce some of the human factors issues related to corpus collection and the issue of statistical significance. We also examine some data collection tasks found on the Internet, using them to discuss experimental design and how it relates to the data collected. Finally, I begin a discussion on the difference between rule-based and statistical systems that will 6.1 Basic Python The </context>
</contexts>
<marker>Vaillette, 2001</marker>
<rawString>Thomas W. Stewart, Jr. and Nathan Vaillette. (2001). Language Files: Materials for an Introduction to Language and Linguistics, 8/e. Columbus: Ohio State University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Weizenbaum</author>
</authors>
<title>Eliza—A Computer Program for the Study of Natural Language Computation between Man and Machine.</title>
<date>1966</date>
<journal>Communications of the ACM</journal>
<volume>9</volume>
<issue>1</issue>
<pages>36--45</pages>
<contexts>
<context position="10755" citStr="Weizenbaum, 1966" startWordPosition="1692" endWordPosition="1693">gnment with problematic cases such as hyphenated multiword expressions, e.g., “the orange-juice based confection.” 116 7 Rule-based dialogue systems using regular expressions Since later in the course we will be comparing rule-based systems to statistics-based systems, this is an appropriate time to introduce rule based systems. We experiment in class with Eliza, trying both to make it work and make it fail. I give out a list of versions available on the web, and students can easily find more. In class I often use the emacs built-in version. I then give out copies of the original Eliza paper (Weizenbaum, 1966), which contains the original script in an appendix. If time permits, I also discuss PARRY (Parkison, Colby and Faught, 1977), which has a much more linguistically sophisticated design but there is no simulator available for it. I introduce regular expressions at this point for two reasons. In addition to being required for continued use of the NLTK textbook, regular expressions are an important idea that is not otherwise included in our curriculum. We experiment with Rocky Ross’ interactive web site (Pascoe, 2005) and occasionally with other simulators. I also assign a simple homework using r</context>
</contexts>
<marker>Weizenbaum, 1966</marker>
<rawString>Joseph Weizenbaum. (1966). Eliza—A Computer Program for the Study of Natural Language Computation between Man and Machine. Communications of the ACM 9(1): 36–45.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>