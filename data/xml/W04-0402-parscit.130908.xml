<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.988531">
Second ACL Workshop on Multiword Expressions: Integrating Processing, July 2004, pp. 9-16
</note>
<title confidence="0.9983885">
Paraphrasing of Japanese Light-verb Constructions
Based on Lexical Conceptual Structure
</title>
<author confidence="0.979353">
Atsushi Fujita† Kentaro Furihata† Kentaro Inui† Yuji Matsumoto† Koichi Takeuchi$
</author>
<affiliation confidence="0.976571">
†Graduate School of Information Science,
Nara Institute of Science and Technology
</affiliation>
<email confidence="0.986683">
{atsush-f,kenta-f,inui,matsu}@is.naist.jp
</email>
<affiliation confidence="0.9971295">
$Department of Information Technology,
Okayama University
</affiliation>
<email confidence="0.997941">
koichi@it.okayama-u.ac.jp
</email>
<sectionHeader confidence="0.993885" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99987425">
Some particular classes of lexical paraphrases such
as verb alteration and compound noun decomposi-
tion can be handled by a handful of general rules
and lexical semantic knowledge. In this paper, we
attempt to capture the regularity underlying these
classes of paraphrases, focusing on the paraphras-
ing of Japanese light-verb constructions (LVCs).
We propose a paraphrasing model for LVCs that
is based on transforming the Lexical Conceptual
Structures (LCSs) of verbal elements. We also pro-
pose a refinement of an existing LCS dictionary. Ex-
perimental results show that our LCS-based para-
phrasing model characterizes some of the semantic
features of those verbs required for generating para-
phrases, such as the direction of an action and the
relationship between arguments and surface cases.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932130434783">
Automatic paraphrase generation technology offers
the potential to bridge gaps between the authors and
readers of documents. For example, a system that
is capable of simplifying a given text, or showing
the user several alternative expressions conveying
the same content, would be useful for assisting a
reader (Carroll et al., 1999; Inui et al., 2003).
In Japanese, like other languages, there are sev-
eral classes of paraphrasing that exhibit a degree
of regularity that allows them to be explained by
a handful of sophisticated general rules and lexical
semantic knowledge. For example, paraphrases as-
sociated with voice alteration, verb/case alteration,
compounds, and lexical derivations all fall into such
classes. In this paper, we focus our discussion on
another useful class of paraphrases, namely, the
paraphrasing of light-verb constructions (LVCs),
and propose a computational model for generating
paraphrases of this class.
Sentence (1s) is an example of an LVC1. An LVC
is a verb phrase (“kandou-o ataeta (made an impres-
sion)” in (1s)) that consists of a light-verb (“ataeta
(give-PAST)”) that grammatically governs a nomi-
</bodyText>
<footnote confidence="0.989305">
1For each example, s denotes an input and t denotes its para-
phrase.
</footnote>
<figureCaption confidence="0.814805833333333">
nalized verb (“kandou (an impression)”) (also see
Figure 1 in Section 2.2). A paraphrase of (1s) is sen-
tence (1t), in which the nominalized verb functions
as the main verb with its verbal form (“kandou-s-as
e-ta (be impressed-CAU, PAST)”).
(1) s. Eiga-ga kare-ni kandou-o ataeta.
</figureCaption>
<bodyText confidence="0.98345556097561">
film-NOM him-DAT impression-ACC give-PAST
The film made an impression on him.
t. Eiga-ga kare-o kandou-s-ase-ta.
film-NOM him-ACC be impressed-CAUSATIVE, PAST
The film impressed him.
To generate this type of paraphrase, we need a com-
putational model that is capable of the following
two classes of choice (also see Section 2.2):
Selection of the voice: The model needs to be able
to choose the voice of the target sentence from
active, passive, causative, etc. In example (1),
the causative voice is chosen, which is indi-
cated by the auxiliary verb “ase (causative)”.
Reassignment of the cases: The model needs to
be able to reassign a case marker to each ar-
gument of the main verb. In (1), the gram-
matical case of “kare (him),” which was orig-
inally assigned the dative case, is changed to
accusative.
The task is not as simple as it may seem, because
both decisions depend not only on the syntactic and
semantic attributes of the light-verb, but also on
those of the nominalized verb (Muraki, 1991).
In this paper, we propose a novel lexical
semantics-based account of the LVC paraphrasing,
which uses the theory of Lexical Conceptual Struc-
ture (LCS) of Japanese verbs (Kageyama, 1996;
Takeuchi et al., 2001). The theory of LCS offers
an advantage as the basis of lexical resources for
paraphrasing, because it has been developed to ex-
plain varieties of linguistic phenomena including
lexical derivations, the construction of compounds,
and verb alteration (Levin, 1993; Dorr et al., 1995;
Kageyama, 1996; Takeuchi et al., 2001), all of
which are associated with the systematic paraphras-
ing we mentioned above.
The paraphrasing associated with LVCs is not id-
iosyncratic to Japanese but also appears commonly
in other languages such as English (Mel’ˇcuk and
Polgu`ere, 1987; Iordanskaja et al., 1991; Dras,
1999, etc.), as indicated by the following examples.
</bodyText>
<listItem confidence="0.998963">
(2) s. Steven made an attempt to stop playing.
t. Steven attempted to stop playing.
(3) s. It had a noticeable effect on the trade.
t. It noticeably affected the trade.
</listItem>
<bodyText confidence="0.999966466666667">
Our approach raises the interesting issue of whether
the paraphrasing of LVCs can be modeled in an
analogous way across languages.
Our aim in this paper are: (i) exploring the reg-
ularity of the LVC paraphrasing based a lexical
semantics-based account, and (ii) assessing the im-
mature Japanese semantic typology through a prac-
tical task.
The following sections describe our motiva-
tion, target, and related work on LVC paraphras-
ing (Section 2), the basics of LCS and the refine-
ments we made (Section 3), our paraphrasing model
(Section 4), and our experiments (Section 5). Fi-
nally, we conclude this paper with a brief of descrip-
tion of work to be done in the future (Section 6).
</bodyText>
<subsectionHeader confidence="0.708815">
2 Motivation, target, and related work
2.1 Motivation
</subsectionHeader>
<bodyText confidence="0.99978168">
One of the critical issues that we face in para-
phrase generation is how to develop and maintain
knowledge resources that covers a sufficiently wide
range of paraphrasing patterns such as those in-
dicating that “to make an attempt” can be para-
phrased into “to attempt,” and that “potential” can
be paraphrased into “possibility.” Several attempts
have been made to develop such resources manually
(Sato, 1999; Dras, 1999; Inui and Nogami, 2001);
those work have, however, tended to restrict their
scope to specific classes of paraphrases, and cannot
be used to construct a sufficiently comprehensive re-
source for practical applications.
There is another trend in the research in this field,
namely, the automatic acquisition of paraphrase pat-
terns from parallel or comparable corpora (Barzilay
and McKeown, 2001; Lin and Pantel, 2001; Pang et
al., 2003; Shinyama and Sekine, 2003, etc.). This
type of approach may be able to reduce the cost
of resource development. There are problems that
must be overcome, however, before they can work
practically. First, automatically acquired patterns
tend to be complex. For example, from the para-
phrase of (4s) into (4t), we can naively obtain the
pattern: “X is purchased by Y ⇒ Y buys X.”
</bodyText>
<listItem confidence="0.9458995">
(4) s. This car was purchased by him.
t. He bought this car.
</listItem>
<bodyText confidence="0.979540333333333">
This could also, however, be regarded as a combi-
nation of a simpler pattern of lexical paraphrasing
(“purchase ⇒ buy”) and a voice activization (“X
</bodyText>
<figureCaption confidence="0.965266">
Figure 1: Dependency structure showing the range
which the LVC paraphrasing affects.
</figureCaption>
<bodyText confidence="0.999849705882353">
be VERB-PP by Y ⇒ Y VERB X”). If we were to
use an acquisition scheme that is not capable of de-
composing such complex paraphrases correctly, we
would have to collect a combinatorial number of
paraphrases to gain the required coverage. Second,
the results of automatic acquisition would likely in-
clude many inappropriate patterns, which would re-
quire manual correction. Manual correction, how-
ever, would be impractical if we were collecting a
combinatorial number of patterns.
Our approach to this dilemma is as follows: first,
we manually develop the resources needed to cover
those paraphrases that appear regularly, and then de-
compose and automatically refine the acquired para-
phrasing patterns using those resources. The work
reported in this paper is aimed at this resource de-
velopment.
</bodyText>
<subsectionHeader confidence="0.999924">
2.2 Target structure and required operations
</subsectionHeader>
<bodyText confidence="0.99982516">
Figure 1 shows the range which the LVC para-
phrasing affects, where the solid boxes denote
Japanese base-chunk so-called “bunsetsu.”2 Being
involved in the paraphrasing, the modifiers of the
LVC need the following operations:
Change of the dependence: The dependences of
the elements (a) and (b) need to be changed
because the original modifiee, the light-verb,
is eliminated by the paraphrasing.
Re-conjugation: The conjugation form of the ele-
ments (d), (e), and occasionally (c) need to be
changed according to the category change of
their modifiee, the nominalized verb.
Reassignment of the cases: As described in the
previous section, the case markers of the ele-
ments (b) and often (c) need to be reassigned.
Selection of the voice: The voice of the nominal-
ized verb needs to be chosen according to the
combination of the nominalized verb, the light-
verb, and the original voice.
The first two operations are trivial in the field of
text generation. Moreover, they can be done inde-
pendently of the LVC paraphrasing. The most deli-
cate operation is for the element (c) because it acts
either as an adverb or as a case, relying on the con-
</bodyText>
<footnote confidence="0.966768">
2The modifiee of the LVC is not affected because the part-
of-speech of the light-verb and main verb are the same.
</footnote>
<figure confidence="0.997453142857143">
Target of this paper
(b)
(c)
Noun + Case particle&amp;quot;no&amp;quot;(GEN)
Noun + Case Particle
(a)
Adverb
(d)
Nominalized verb + Case particle
Embedded clause
LVC
(e)
Adjective
Light-verb (+suffixes)
</figure>
<tableCaption confidence="0.972433">
Table 1: Examples of LCS
</tableCaption>
<bodyText confidence="0.771459545454546">
Verb LCS for verb Verb phrase
move [y MOVE TO z] My sister (Theme) moves to a neighboring town (Goal).
transmit [x CONTROL [y MOVE TO z]] The enzyme (Agent) transmits messages (Theme) to the muscles (Goal).
locate [y BE AT z] The school (Theme) locates near the river (Goal).
maintain [x CONTROL [y BE AT z]] He (Agent) maintains a machine (Theme) in good condition (Goal).
text. In the former case, it needs the second opera-
tion. In the latter case, it needs the third operation
as well as the element (b).
In this paper, we take into account only the ele-
ment (b), namely, the sibling cases of the nominal-
ized verb.
</bodyText>
<sectionHeader confidence="0.731552" genericHeader="introduction">
2.3 Related work
</sectionHeader>
<bodyText confidence="0.999666217391304">
Based on the Meaning-Text Theory (Mel’ˇcuk and
Polgu`ere, 1987), Iordanskaja et al. (1991) pro-
poses a set of paraphrasing rules including one for
LVC paraphrasing. Their rule heavily relies on what
are called lexical functions, by which they virtually
specify all the choices relevant to LVC paraphras-
ing for every combination of nominalized verb and
light-verb individually. Our approach is to employ
lexical semantics to provide a general account of
those classes of choices.
On the other hand, Kaji and Kurohashi (2004)
proposes a paraphrasing model which bases on an
ordinary dictionary. Given an input LVC, their
model paraphrases it using the gloss of both the
nominalized verb and the light-verb with the seman-
tic feature of the light-verb. Their model looks ro-
bust because of the availability of an ordinary dic-
tionary. However, their model fails to explain the
difference in the voice selection between examples
(5) and (6) since it selects the voice based only
on the light-verb — in their approach, the light-
verb “ukeru (to receive)” always maps to the passive
voice irrespective of the nominalized verb.
</bodyText>
<listItem confidence="0.758619">
(5) s. Enkai-eno shoutai-o uketa.
</listItem>
<equation confidence="0.947798769230769">
party-GEN invitation-ACC receive-PAST
I received an invitation to the party.
t. Enkai-ni shoutai-s-are-ta.
party-DAT invite-PAS, PAST
I was invited to the party.
(6) s. Kare-no hanashi-ni
his-GEN talk-DAT
kandou-o uketa.
impression-ACC receive-PAST
I was given a good impression by his talk.
t. Kare-no hanashi-ni kandou-shi-ta.
his-GEN talk-DAT be impressed-ACT, PAST
I was impressed by his talk.
</equation>
<bodyText confidence="0.786784">
In (Kaji and Kurohashi, 2004), the target expres-
sion is restricted only to the LVC itself (also see
Figure 1). Hence, their model is unable to reassign
the cases as we saw in example (1).
</bodyText>
<sectionHeader confidence="0.972792" genericHeader="method">
3 Lexical Conceptual Structure
</sectionHeader>
<subsectionHeader confidence="0.996132">
3.1 Basic framework of LCS
</subsectionHeader>
<bodyText confidence="0.999886333333333">
The theory of Lexical Conceptual Structure
(LCS) associates a verb with a semantic struc-
ture as exemplified by Table 1. An LCS consists
of semantic predicates (“CONTROL,” “BE AT,”
etc.) and their argument slots (x, y, z). Argument
slots x, y, and z correspond to the semantic roles
“Agent,” “Theme,” and “Goal,” respectively. Tak-
ing the LCS of the verb “transmit” as an example,
[y MOVE TO z] denotes the state of affairs that the
state of the “Theme” changes to the “Goal,” and
[x CONTROL ...] denotes that the “Agent” causes the
state change.
</bodyText>
<subsectionHeader confidence="0.995767">
3.2 Refinements
</subsectionHeader>
<bodyText confidence="0.997554">
We make use of the TLCS dictionary, a Japanese
verb LCS dictionary developed by Takeuchi et al.
(2001), because it offers the following advantages:
</bodyText>
<listItem confidence="0.9953454">
• It is based on solid linguistic work, as in
(Kageyama, 1996).
• Its scale is considerably larger than any other
existing collections of verb LCS entries.
• It provides a set of concrete rules for LCS as-
</listItem>
<bodyText confidence="0.959186166666667">
signment, which ensures the reliability of the
dictionary.
In spite of these advantages, our preliminary ex-
amination of the dictionary revealed that further re-
finements were needed. To refine the typology of
TLCS, we collected the following sets of words:
Nominalized verbs: We regard “sahen-nouns”4
and nominal forms of verbs as nominalized
verbs. We retrieved 1,210 nominalized verbs
from the TLCS dictionary.
Light-verbs: Since a verb takes different meanings
when it is a part of LVCs with different case
particles, we collected pairs (c, v) of case par-
ticle c and verb v in the following way:
Step 1. We collected 876,101 types of triplets
(n, c, v) of nominalized verb n, case par-
ticle c, and base form of verb v from the
parsed5 sentences of newspaper articles6.
</bodyText>
<footnote confidence="0.875060875">
4A sahen-noun is a verbal noun in Japanese, which acts as
a verb in the form of “sahen-noun + suru”.
5We used the statistical Japanese dependency parser
CaboCha (Kudo and Matsumoto, 2002) for parsing.
http://chasen.naist.jp/˜taku/software/cabocha/
6Excerpts from 9 years of the Mainichi Shinbun and 10
years of the Nihon Keizai Shinbun, giving a total of 25,061,504
sentences, were used.
</footnote>
<tableCaption confidence="0.98816">
Table 2: Extensions of LCS
</tableCaption>
<table confidence="0.602998571428571">
Verb Verb phrase and its LCS representation
Ext.1 hankou-suru [[Ken]y BE AGAINST [parents]z]
(resist) Ken-ga oya-ni hankou-suru.
Ken-NOM parents-DAT resist-PRES (Ken resists his parents.)
Ext.2 ukeru [BECOME [[salesclerk]z BE WITH [[complaint]y MOVE FROM [customer]x TO [salesclerk]z]]]
(receive) Ten’in-ga kyaku-kara kujo-o ukeru.
salesclerk-NOM customer-ABL complaint-ACC receive-PRES
(The salesclerk receives a complaint from a customer.)
Ext.3 motomeru [[Ken]x CONTROL [[apology]y MOVE FROM [George]z TO [FILLED]]]3
(ask) Ken-ga George-ni shazai-o motomeru.
Ken-NOM George-DAT apology-ACC ask-PRES (Ken asks George for an apology.)
Ext.4 kandou-suru [BECOME [[Ken]z BE WITH [[FILLED]y MOVE FROM [music]x TO [Ken]z]]]
(be impressed) Ken-ga ongaku-ni kandou-suru.
Ken-NOM music-DAT be impressed-PRES (Ken is impressed by the music.)
</table>
<bodyText confidence="0.986920771428571">
Step 2. For each of the 50 most frequent (c, v)
tuples, we extracted the 10 most frequent
(n, c, v).
Step 3. Each (n, c, v) was manually evaluated
to determine whether it was an LVC. If
any of 10 triplets was determined to be
an LVC, (c, v) was merged into the list of
light-verbs. As a result, we collected 40
types of (c, v) for light-verbs.
Through investigating the above 1,210 nominal-
ized verbs and 40 light-verbs, we extended the ty-
pology of TLCS as shown below (also see Table 2).
Ext. 1. Treatment of “Partner”: The dative case
of “hankou-suru (resist)” and “eikyo-suru (af-
fect)” does not indicate the “Goal” of the ac-
tion but the “Partner.”
Ext. 2. Verbs of obtaining (Levin, 1993): In con-
trast with “ataeru (give),” the nominative case
of “ukeru (receive)” and “eru (acquire)” is the
“Goal” of the “Theme,” while the ablative case
indicates “Source.”
Ext. 3. Require verb: “motomeru (ask)” and
“yokyu-suru (require)” denote the existence of
the external “Agent” who controls the action of
the other “Agent” or “Theme.”
Ext. 4. Verbs of psychological state (Levin,
1993): “kandou-suru (be impressed)” and “os-
oreru (fear)” indicate the change of psycholog-
ical state of the “Agent.” The ascriptive part of
the change has to be described.
Consequently, we defined a new LCS typology
consisting of 16 types. Note that more than one LCS
can be assigned to a verb if it has a polysemy. For
convenience, we refer to the extended dictionary as
the LCSdic7.
</bodyText>
<footnote confidence="0.959693428571429">
6The predicate “FILLED” represents an implicit argument
of the verb and the verb assigned this LCS cannot take this
argument. Taking the LCS of the verb “sign” as an example,
“FILLED” in [x CONTROL [BECOME [[FILLED]y BE AT
z]]] denotes the name of “Agent.”
7The latest version of the LCSdic is available from
http://cl.it.okayama-u.ac.jp/rsc/lcs/
</footnote>
<sectionHeader confidence="0.991233" genericHeader="method">
4 Paraphrasing model
</sectionHeader>
<bodyText confidence="0.993879">
In this section, we describe how we generate para-
phrases of LVCs. Figure 2 illustrates how our model
paraphrases the LVC of example (7).
</bodyText>
<table confidence="0.6008995">
(7) s. Ken-ga eiga-ni shigeki-o uketa.
Ken-NOM film-DAT inspiration-ACC receive-PAST
Ken received inspiration from the film.
t. Ken-ga eiga-ni shigeki-s-are-ta.
Ken-NOM film-DAT inspire-PAS, PAST
Ken was inspired by the film.
</table>
<bodyText confidence="0.998566923076923">
The idea is to exploit the LCS representation as a
semantic representation and to model the LVC para-
phrasing by the transformation of the LCS represen-
tation. The process consists of the following three
steps:
Step 1. Semantic analysis: The model first ana-
lyzes a given input sentence including an LVC
to obtain its semantic structure in terms of the
LCS representation. In Figure 2, this step pro-
duces LCSV 1.
Step 2. Semantic transformation (LCS transfor-
mation): The model then transfers the ob-
tained semantic structure to another semantic
structure so that the target structure consists of
the LCS of the nominalized verb of the input.
In our example, this step generates LCSN1 to-
gether with the supplement [BECOME [...]].
Step 3. Surface generation: Having obtained the
target LCS representation, the model finally
lexicalizes it to generate the output sentence.
So, the key issue is how to control the second step,
namely, the transformation of the LCS representa-
tion.
The rest of this section elaborates on each step,
using different symbols to denote arguments; x, y,
and z for LCSV , and x’, y’, and z’ for LCSN.
</bodyText>
<subsectionHeader confidence="0.998923">
4.1 Semantic analysis
</subsectionHeader>
<bodyText confidence="0.99937375">
Given an input sentence, which we assume to be a
simple clause with an LVC, we first look up the LCS
template LCSV 0 for the given light-verb, and then
apply the case assignment rule, below (Takeuchi et
</bodyText>
<figure confidence="0.68830075">
(10) Surface generation
Paraphrased sentence
Ken-ga (Ken-NOM) eiga-ni (film-DAT)
shigeki-s-are-ta (inspire-PAS, PAST).
</figure>
<figureCaption confidence="0.999251">
Figure 2: The LCS-based paraphrasing model.
</figureCaption>
<bodyText confidence="0.8358025">
al., 2001), to obtain its LCS representation LCSV1:
Case assignment rule:
</bodyText>
<listItem confidence="0.769861">
• In the case of the LCSV 0 having argument x,
fill the leftmost argument of the LCSV 0 with
</listItem>
<bodyText confidence="0.8703337">
the nominative case of the input, the second
leftmost with the accusative, and the rest with
the dative.
• Otherwise, fill arguments y and z of the LCSV0
with the nominative and the dative, respec-
tively.
In the example shown in Figure 2, the nominative
“Ken” fills the leftmost argument z. Accordingly,
the accusative “shigeki (inspiration)” and the dative
“eiga (film)” fill y and x, respectively.
</bodyText>
<listItem confidence="0.491774">
(8) s. Ken-ga eiga-ni shigeki-o uketa.
</listItem>
<table confidence="0.329777">
Ken-NOM film-DAT inspiration-ACC receive-PAST
Ken received inspiration from the film.
LCSV0 [BECOME [z BE WITH [y MOVE FROM x
TO z]]]
LCSV1 [BECOME [[Ken]z BE WITH [[inspiration]y
MOVE FROM [film]x TO [Ken]z]]]
</table>
<subsectionHeader confidence="0.97984">
4.2 LCS transformation
</subsectionHeader>
<bodyText confidence="0.9999865">
The second step of our paraphrasing model
matches the resultant LCS representation (LCSV 1
in Figure 2) with the LCS of the nominalized verb
(LCSN0) to generate the target LCS representation
(LCSN1). Figure 3 shows a more detailed view of
this process for the example shown in Figure 2.
</bodyText>
<subsubsectionHeader confidence="0.721404">
4.2.1 Predicate matching
</subsubsectionHeader>
<bodyText confidence="0.9996594">
The first step is to determine the predicate in
LCSV 1 that should be matched with the predicate
in LCSN0. Assuming that only the agentivity is rel-
evant to the selection of the voice in the paraphras-
ing of LVC, which is our primary concern, we clas-
sify the semantic predicates into the following two
classes:
Agentive predicates: “CONTROL,” “ACT ON,”
“ACT,” “BE AGAINST,” and “MOVE FROM
TO.”
</bodyText>
<figureCaption confidence="0.999212">
Figure 3: LCS transformation.
</figureCaption>
<bodyText confidence="0.991991454545455">
State of affair predicates: “MOVE TO,” “BE
AT,” and “BE WITH.”
Aspectual predicates: “BECOME.”
We also assume that any pair of predicates of
the same class is allowed to match, and that the
aspectual predicates are ignored. In our example,
“MOVE FROM TO” matches “ACT ON,” as shown
in Figure 3.
LCS representations have right-branching (or
right-embedding) structures. Since inner-embedded
predicates denote the state of affairs, they take pri-
ority in the matching. In other words, the matching
proceeds from the rightmost inner predicates to the
outer predicates.
Having matched the predicates, we then fill each
argument slot in LCSN0 with its corresponding ar-
gument in LCSV1. In Figure 3, argument z is
matched with y’, and x with x’. As a result, “Ken”
comes to the y’ slot and “eiga (film)” comes to the
x’ slot8.
This process is repeated until the leftmost predi-
cate in LCSN0 or that in LCSV 1 is matched.
</bodyText>
<subsectionHeader confidence="0.900183">
4.2.2 Treatment of non-transfered predicates
</subsectionHeader>
<bodyText confidence="0.9999872">
If LCSV 1 has any non-transfered predicates when
the predicate matching has been completed, they
represent the semantic content that is not covered by
LCSN1 and which needs to be lexicalized by aux-
iliary linguistic devices such as voice auxiliaries.
In the case of Figure 3, [BECOME [[Ken]z BE WITH]]
in LCSV 1 remains non-transfered. In such a case,
we attach the non-transfered predicates to LCSN0,
which are then lexicalized by auxiliaries in the next
step, the surface generation.
</bodyText>
<subsectionHeader confidence="0.998818">
4.3 Surface generation
</subsectionHeader>
<bodyText confidence="0.999916666666667">
We again apply the aforementioned case assignment
rule to generate a sentence from the resultant LCS
representation. In this process, the model makes the
final decisions on the selection of the voice and the
reassignment of the cases, according to the follow-
ing decision list:
</bodyText>
<footnote confidence="0.848556857142857">
8When an argument is filled with another LCS, arguments
within the inner LCS are also matched. Likewise, with regard
to an assumption that the input sentences are periphrastic, we
introduced some exceptional rules. That is, arguments filled
with the implicit filler represented by “FILLED” or the target
nominalized verb N are never matched, and “Goal” in LCSV 1
can be matched to “Theme” in LCSN0.
</footnote>
<figure confidence="0.985031884615384">
[BECOME [z BE WITH [y MOVE FROM x TO z]]]
ukeru (receive) LCSV0 (1) Semantic analysis
LCSV1 [BECOME [[Ken]z BE WITH
[[inspiration]y MOVE FROM [film]x TO [Ken]z]]]
shigeki-suru (inspire)
[x’ ACT ON y’]
(2) LCS transformation
LCSN0
[BECOME [[Ken]z BE WITH]] +
[[film]x’ ACT ON [Ken]y’]
LCSN1
Input sentence
Ken-ga (Ken-NOM) eiga-ni (film-DAT)
shigeki-o (inspiration-ACC) uketa (receive-PAST).
LCS dictionary
LCSV1
[BECOME [[Ken]z BE WITH
[[inspiration]y MOVE FROM [film]x TO [Ken]z]]]
(b) Argument matching
LCSN0
[x’ ACT ON y’]
(c) Attaching the remaining structure
LCSN1
[BECOME [[Ken]z BE WITH]] +
[[film]x’ ACT ON [Ken]y’]
(a) Predicate matching
</figure>
<listItem confidence="0.96441935">
1. If the attached predicate is filled with the same
argument as the leftmost argument in LCSN1,
the “active” voice is selected and the case
structure is left as is.
2. If the argument of the attached predicate has
the same value as either z’ or y’ in LCSN1,
lexicalization is performed to make the argu-
ment a subject. Therefore, the “passive” voice
is selected and case alternation (passivization)
is applied.
3. If the attached predicate is “BE WITH” and its
argument has the same value as x’ in LCSN1,
the “causative” voice is selected and case alter-
nation (causativizaton) is applied.
4. If the attached predicate is an agentive predi-
cate, and its argument is filled with a value dif-
ferent from those of the other arguments, then
the “causative” voice is selected and case alter-
nation (causativization) is applied.
5. Otherwise, no modification is applied.
</listItem>
<bodyText confidence="0.94216975">
Since the example in Figure 2 satisfies the second
condition, the model chooses “s-are-ru (passive)”
and passivizes the sentence so that “Ken” fills the
nominative case.
</bodyText>
<listItem confidence="0.439424">
(9) LCSN1 [BECOME [[Ken]z BE WITH]]
+ [[film]x’ ACT ON [Ken]y’]
t. Ken-ga eiga-ni shigeki-s-are-ta.
</listItem>
<bodyText confidence="0.555071">
Ken-NOM film-DAT inspire-PAS, PAST
Ken was inspired by the film.
</bodyText>
<sectionHeader confidence="0.998579" genericHeader="evaluation">
5 Experiment
</sectionHeader>
<subsectionHeader confidence="0.999874">
5.1 Paraphrase generation and evaluation
</subsectionHeader>
<bodyText confidence="0.999942916666667">
To empirically evaluate our paraphrasing model and
the LCSdic, and to clarify the remaining problems,
we analyzed a set of automatically generated para-
phrase candidates. The sentences used in the exper-
iment were collected in the following way:
Step 1. From the 876,101 types of triplet (n, c, v)
collected in Section 3.2, 23,608 types of
(n, c, v) were extracted, whose components, n
and (c, v), are listed in the LCSdic.
Step 2. For each of the 245 most frequent (n, c, v),
the 3 most frequent simple clauses includ-
ing the (n, c, v) were extracted from the cor-
pus from which (n, c, v) s were extracted in
Section 3.2. As a result, we collected 735 sen-
tences.
Step 3. We input these 735 sentences into our para-
phrasing model, and then automatically gener-
ated paraphrase candidates. When more than
one LCS is assigned to a verb in the LCSdic
due to its polysemy or ergative verb such as
“kaifuku-suru (recover),” our model generates
all the possible paraphrase candidates. As a re-
sult, 825 paraphrase candidates, that is, at least
one for each input, were generated.
</bodyText>
<tableCaption confidence="0.995725">
Table 3: Error sources
</tableCaption>
<table confidence="0.998698666666667">
Correct candidates 621 (75.8%)
Erroneous candidates 198 (24.2%)
Definition of LCS 30
LCS for light-verb 24
LCS for nominalized verb 6
Paraphrasing model 61
LCS transformation algorithm 59
Treatment of “suru (to do)” 2
Ambiguity 107
Ambiguous thematic role of dative 78
Recognition of LVC 24
Selection of transitive/intransitive 5
</table>
<bodyText confidence="0.9995774">
We manually classified the resultant 825 para-
phrase candidates into 621 correct and 198 erro-
neous candidates. The remaining 6 candidates were
not classified. The precision of the paraphrase gen-
eration was 75.8% (621 / 819).
</bodyText>
<subsectionHeader confidence="0.998239">
5.2 Error analysis
</subsectionHeader>
<bodyText confidence="0.999961333333333">
To clarify the cause of the erroneous paraphrases,
we manually classified 198 erroneous paraphrase
candidates. Table 3 lists the error sources.
</bodyText>
<subsectionHeader confidence="0.741804">
5.2.1 LCS transformation algorithm
</subsectionHeader>
<bodyText confidence="0.999475461538462">
The experiment came close to confirming that the
right-first matching algorithm in our paraphrasing
model operates correctly. Unfortunately, the match-
ing rules produced some erroneous paraphrases in
LCS transformation.
Errors in predicate matching: To paraphrase
(10s) below, “CONTROL” in LCSV 1 must be
matched with “CONTROL” in LCSN0, and x to x’.
However, our model first matched “CONTROL” in
LCSV1 with “MOVE FROM TO” in LCSN0. Thus,
x was incorrectly matched with z’ and x’ remained
empty. The desired form of LCSN1 is shown in
(11).
</bodyText>
<equation confidence="0.923197">
(10) s. kacho-ga buka-ni
section-chief-NOM subordinate-DAT
shiji-o dasu.
order-ACC issue-PRES
</equation>
<bodyText confidence="0.353441">
The section chief issues orders to his subordinates.
(N=“order”, V =“issue”)
</bodyText>
<footnote confidence="0.30477325">
LCSV1 [[chief]x CONTROL [BECOME [[order]y
BE AT [subordinate]z]]]
LCSN0 [x’ CONTROL [y’ MOVE FROM z’ TO
[FILLED]]]
LCSN1∗[x’ CONTROL [[subordinate]y’ MOVE
FROM [chief]z’ TO [FILLED]]]
(11) LCSN1 [[chief]x’ CONTROL [y’ MOVE FROM
[subordinate] TO [FILLED]]]
</footnote>
<bodyText confidence="0.977503">
This error was caused by the mis-matching of
“CONTROL” with “MOVE FROM TO.” Although
we regard some predicates as being in the same
classes as those described in Section 4.2.1, these
need to be considered carefully. In particular
“MOVE FROM TO” needs further investigation be-
cause it causes many errors whenever it has the
“FILLED” argument.
Errors in argument matching: Even if all the
predicates are matched properly, there would still
be a chance of errors being caused by incorrect ar-
gument matching. With the present algorithm, z
can be matched with y’ if and only if z’ contains
“FILLED.” In the case of (12), however, z has to
be matched with y’, even though z’ is empty. The
desired form of LCSN1 is shown in (13).
</bodyText>
<figure confidence="0.9255436">
(12) s. Jikan-ni seigen-ga aru.
time-DAT limitation-NOM exist-PRES
There is a time limitation.
(N=“limitation”, V =“exist”)
LCSV 1 [BECOME [[limitation]y BE AT [time]z]]
LCSN0 [x’ CONTROL [BECOME [y’ BE AT z’]]]
LCSN1*[x’ CONTROL [BECOME [y’ BE AT
[time]z’]]]
(13) LCSN1 [x’ CONTROL [BECOME [[timey]y’ BEAT
z’]]]
</figure>
<subsectionHeader confidence="0.433234">
5.2.2 Ambiguous thematic role of dative
</subsectionHeader>
<bodyText confidence="0.999874636363636">
In contrast to dative cases in English, in Japanese,
the dative case has ambiguity. That is, it can be a
complement to the verb or an adjunct9. However,
since LCS is not capable of determining whether the
case is a complement or an adjunct, z is occasion-
ally incorrectly filled with an adjunct. For exam-
ple, “medo-ni” in (14s) should not fill z, because it
acts as an adverb, even though it consists of a noun,
“medo (prospect)” and a case particle for the dative.
We found that 78 erroneous candidates constitute
this most dominant type of errors.
</bodyText>
<figure confidence="0.509772142857143">
(14) s. Kin’you-o medo-ni sagyo-o susumeru.
Friday-NOM by-DAT work-ACC carry on-PRES
I plan to finish the work by Friday.
(N=“work”, V =“carry”)
LCSV0 [x CONTROL [BECOME [y BE AT z]]]
LCSV 1*[x CONTROL [BECOME [[work]y BE AT
[by]z]]]
</figure>
<bodyText confidence="0.996162933333334">
The ambiguity of dative cases in Japanese has
been discussed in the literature of linguistics and
some natural language processing tasks (Muraki,
1991). To date, however, a practical compli-
ment/adjunct classifier has not been established. We
plan to address this topic in our future research.
Preliminary investigation revealed that only cer-
tain groups of nouns can constitute both compli-
ments and adjuncts according to the governing verb.
Therefore, generally whether a word acts as a com-
plement is determined without combining it with the
verb.
9(Muraki, 1991) classifies dative cases into 11 thematic
roles that can be regarded as complements. In contrast, there
is no typology of dative cases that act as adjuncts.
</bodyText>
<subsectionHeader confidence="0.969624">
5.2.3 Recognition of LVC
</subsectionHeader>
<bodyText confidence="0.999626818181818">
In our model, we assume that a triplet (n, c, v) con-
sisting of a nominalized verb n and a light-verb tu-
ple (c, v) from our vocabulary lists (see Section 3.2)
always act as an LVC. However, not only the triplet
itself but also its context sometimes affects whether
the given triplet can be paraphrased. For exam-
ple, we regard “imi-ga aru” as an LVC, because the
nominalized verb “imi” and the tuple (“ga”, “aru”)
appear in the vocabulary lists. However, the (n, c, v)
in (15s) does not act as an LVC, while the same
triplet in (16s) does.
</bodyText>
<figure confidence="0.692037166666667">
(15) s. Sanka-suru-koto-ni imi-ga aru.
to participate-DAT meaning-NOM exist-PRES
There is meaning in participating.
t.*Sanka-suru-koto-o imi-suru.
to participate-ACC mean-ACT, PRES
∗It means to participate in it.
(16) s. “kennel”-niwa inugoya-toiu
“kennel”-TOP doghouse-OF
imi-ga aru.
meaning-NOM exist-PRES
“kennel” has the meaning of doghouse.
t. “kennel”-wa inugoya-o imi-suru.
</figure>
<figureCaption confidence="0.1455795">
“kennel”-TOP doghouse-ACC mean-ACT, PRES
“kennel” means doghouse.
</figureCaption>
<bodyText confidence="0.9999824">
The above difference is caused by the polysemy
of the nominalized verb “imi” that denotes “worth”
in the context of (15s), but “meaning” in (16s).
Although incorporating word sense disambiguation
using contextual clues complicates our model, in
fact only a limited number of nominalized verbs are
polysemous. We therefore expect that we can list
them up and use this as a trigger for making a deci-
sion as to whether we need to take the context into
account. Namely, given a (n, c, v), we would be
able to classify it into (a) a main verb phrase, (b) a
delicate case in terms of the dependence of its con-
text, and (c) an LVC.
We can adopt a different approach to avoiding
incorrect paraphrase generation. As described in
Section 5.1, our model generates all the possible
paraphrase candidates when more than one LCS is
assigned to a verb. Similarly, our approach can be
extended to (i) over-generate paraphrase candidates
by considering the polysemy of not only assigned
LCS types, but also that of nominalized verbs (see
(15s) and (16s)) and whether the given (n, c, v) is
an LVC, and (ii) revise or reject the incorrect candi-
dates by using handcrafted solid rules or statistical
language models.
</bodyText>
<sectionHeader confidence="0.978345" genericHeader="conclusions">
6 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.99984296">
In this paper, we presented an LCS-based para-
phrasing model for LVCs and an extension of an ex-
isting LCS dictionary. Our model achieved an accu-
racy of 75.8% in selecting the voice and reassigning
the cases.
To make our paraphrasing model more accurate,
further analysis is needed, especially for the LCS
transformation stage described in Section 4.2. Sim-
ilarly, several levels of disambiguation should also
be solved. The Japanese LCS typology has to be
refined from the theoretical point of view. For ex-
ample, since extensions are no more than human in-
tuition, we must discuss how we can assign LCSs
for given verbs based on explicit language tests, as
described in (Takeuchi et al., 2001).
In future research, we will also extend our LCS-
based approach to other classes of paraphrases that
exhibit some regularity, such as verb alteration and
compound noun decomposition as shown in (17)
and (18), below. LCS has been discussed as a
means of explaining the difference between transi-
tive/intransitive verbs, and the construction of com-
pounds. Therefore, our next goal is to show the ap-
plicability of LCS through practical tasks, namely,
paraphrasing.
</bodyText>
<equation confidence="0.49713">
(17) s. Jishin-ga building-o kowashita.
earthquake-NOM building-DAT destroy-PAST
</equation>
<bodyText confidence="0.74686425">
The earthquake destroyed the building.
t. Jishin-de building-ga kowareta.
earthquake-LOC building-NOM be destroyed-PAST
The building was destroyed in the earthquake.
</bodyText>
<equation confidence="0.507347428571429">
(18) s. Kare-wa kikai
he-TOP machine-
sousa-ga jouzu-da.
operation-NOM good-COPULA
He is good at operating the machine.
t. Kare-wa kikai-o jouzu-ni sousa-suru.
he-TOP machine-DAT well-ADV operate-PRES
</equation>
<bodyText confidence="0.750321">
He operates machines well.
</bodyText>
<sectionHeader confidence="0.995728" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999764486486486">
R. Barzilay and K. R. McKeown. 2001. Extracting para-
phrases from a parallel corpus. In Proceedings of the
39th Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 50–57.
J. Carroll, G. Minnen, D. Pearce, Y. Canning, S. De-
vlin, and J. Tait. 1999. Simplifying text for language-
impaired readers. In Proceedings of the 9th Confer-
ence of the European Chapter of the Association for
Computational Linguistics (EACL), pages 269–270.
B. J. Dorr, J. Garman, and A. Weinberg. 1995. From
syntactic encodings to thematic roles: building lexi-
cal entries for interlingual MT. Machine Translation,
9(3):71–100.
M. Dras. 1999. Tree adjoining grammar and the reluc-
tant paraphrasing of text. Ph.D. thesis, Department of
Computing, Macquarie University.
K. Inui and M. Nogami. 2001. A paraphrase-based
exploration of cohesiveness criteria. In Proceedings
of the 8th European Workshop on Natulal Language
Generation (EWNLG), pages 101–110.
K. Inui, A. Fujita, T. Takahashi, R. Iida, and T. Iwakura.
2003. Text simplification for reading assistance: a
project note. In Proceedings of the 2nd International
Workshop on Paraphrasing: Paraphrase Acquisition
and Applications (IWP), pages 9–16.
L. Iordanskaja, R. Kittredge, and A. Polgu`ere. 1991.
Lexical selection and paraphrase in a meaning-text
generation model. In Paris et al. (Eds.) Natural Lan-
guage Generation in Artificial Intelligence and Com-
putational Linguistics, pages 293–312. Kluwer Aca-
demic Publishers.
T. Kageyama, editor. 1996. Verb semantics. Kuroshio
Publishers. (in Japanese).
N. Kaji and S. Kurohashi. 2004. Recognition and para-
phrasing of periphrastic and overlapping verb phrases.
In Proceedings of the 4th International Conference on
Language Resources and Evaluation (LREC) Work-
shop on Methodologies and Evaluation of Multiword
Units in Real-world Application.
T. Kudo and Y. Matsumoto. 2002. Japanese depen-
dency analysis using cascaded chunking. In Proceed-
ings of 6th Conference on Natural Language Learning
(CoNLL), pages 63–69.
B. Levin. 1993. English verb classes and alternations:
a preliminary investigation. Chicago Press.
D. Lin and P. Pantel. 2001. Discovery of inference rules
for question answering. Natural Language Engineer-
ing, 7(4):343–360.
I. Mel’ˇcuk and A. Polgu`ere. 1987. A formal lexicon in
meaning-text theory (or how to do lexica with words).
Computational Linguistics, 13(3-4):261–275.
S. Muraki. 1991. Various aspects of Japanese verbs.
Hitsuji Syobo. (in Japanese).
B. Pang, K. Knight, and D. Marcu. 2003. Syntax-based
alignment of multiple translations: extracting para-
phrases and generating new sentences. In Proceed-
ings of the 2003 Human Language Technology Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics (HLT-NAACL),
pages 102–109.
S. Sato. 1999. Automatic paraphrase of technical pa-
pers’ titles. Journal ofInformation Processing Society
ofJapan, 40(7):2937–2945. (in Japanese).
Y. Shinyama and S. Sekine. 2003. Paraphrase acquisi-
tion for information extraction. In Proceedings of the
2nd International Workshop on Paraphrasing: Para-
phrase Acquisition and Applications (IWP), pages 65–
71.
K. Takeuchi, K. Uchiyama, S. Yoshioka, K. Kageura,
and T. Koyama. 2001. Categorising deverbal nouns
based on lexical conceptual structure for analysing
Japanese compounds. In Proceedings of IEEE Sys-
tem, Man, and Cybernetics Conference, pages 904–
909.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.453126">
<note confidence="0.939631">Second ACL Workshop on Multiword Expressions: Integrating Processing, July 2004, pp. 9-16</note>
<title confidence="0.8060415">Paraphrasing of Japanese Light-verb Based on Lexical Conceptual Structure</title>
<affiliation confidence="0.993214">School of Information Nara Institute of Science and of Information</affiliation>
<address confidence="0.787379">Okayama</address>
<email confidence="0.989089">koichi@it.okayama-u.ac.jp</email>
<abstract confidence="0.999811588235294">Some particular classes of lexical paraphrases such as verb alteration and compound noun decomposition can be handled by a handful of general rules and lexical semantic knowledge. In this paper, we attempt to capture the regularity underlying these classes of paraphrases, focusing on the paraphrasing of Japanese light-verb constructions (LVCs). We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements. We also propose a refinement of an existing LCS dictionary. Experimental results show that our LCS-based paraphrasing model characterizes some of the semantic features of those verbs required for generating paraphrases, such as the direction of an action and the relationship between arguments and surface cases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>K R McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>50--57</pages>
<contexts>
<context position="6335" citStr="Barzilay and McKeown, 2001" startWordPosition="989" endWordPosition="992"> as those indicating that “to make an attempt” can be paraphrased into “to attempt,” and that “potential” can be paraphrased into “possibility.” Several attempts have been made to develop such resources manually (Sato, 1999; Dras, 1999; Inui and Nogami, 2001); those work have, however, tended to restrict their scope to specific classes of paraphrases, and cannot be used to construct a sufficiently comprehensive resource for practical applications. There is another trend in the research in this field, namely, the automatic acquisition of paraphrase patterns from parallel or comparable corpora (Barzilay and McKeown, 2001; Lin and Pantel, 2001; Pang et al., 2003; Shinyama and Sekine, 2003, etc.). This type of approach may be able to reduce the cost of resource development. There are problems that must be overcome, however, before they can work practically. First, automatically acquired patterns tend to be complex. For example, from the paraphrase of (4s) into (4t), we can naively obtain the pattern: “X is purchased by Y ⇒ Y buys X.” (4) s. This car was purchased by him. t. He bought this car. This could also, however, be regarded as a combination of a simpler pattern of lexical paraphrasing (“purchase ⇒ buy”) </context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>R. Barzilay and K. R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL), pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>G Minnen</author>
<author>D Pearce</author>
<author>Y Canning</author>
<author>S Devlin</author>
<author>J Tait</author>
</authors>
<title>Simplifying text for languageimpaired readers.</title>
<date>1999</date>
<booktitle>In Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>269--270</pages>
<contexts>
<context position="1615" citStr="Carroll et al., 1999" startWordPosition="223" endWordPosition="226">ing LCS dictionary. Experimental results show that our LCS-based paraphrasing model characterizes some of the semantic features of those verbs required for generating paraphrases, such as the direction of an action and the relationship between arguments and surface cases. 1 Introduction Automatic paraphrase generation technology offers the potential to bridge gaps between the authors and readers of documents. For example, a system that is capable of simplifying a given text, or showing the user several alternative expressions conveying the same content, would be useful for assisting a reader (Carroll et al., 1999; Inui et al., 2003). In Japanese, like other languages, there are several classes of paraphrasing that exhibit a degree of regularity that allows them to be explained by a handful of sophisticated general rules and lexical semantic knowledge. For example, paraphrases associated with voice alteration, verb/case alteration, compounds, and lexical derivations all fall into such classes. In this paper, we focus our discussion on another useful class of paraphrases, namely, the paraphrasing of light-verb constructions (LVCs), and propose a computational model for generating paraphrases of this cla</context>
</contexts>
<marker>Carroll, Minnen, Pearce, Canning, Devlin, Tait, 1999</marker>
<rawString>J. Carroll, G. Minnen, D. Pearce, Y. Canning, S. Devlin, and J. Tait. 1999. Simplifying text for languageimpaired readers. In Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 269–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Dorr</author>
<author>J Garman</author>
<author>A Weinberg</author>
</authors>
<title>From syntactic encodings to thematic roles: building lexical entries for interlingual MT.</title>
<date>1995</date>
<journal>Machine Translation,</journal>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="4255" citStr="Dorr et al., 1995" startWordPosition="650" endWordPosition="653">d not only on the syntactic and semantic attributes of the light-verb, but also on those of the nominalized verb (Muraki, 1991). In this paper, we propose a novel lexical semantics-based account of the LVC paraphrasing, which uses the theory of Lexical Conceptual Structure (LCS) of Japanese verbs (Kageyama, 1996; Takeuchi et al., 2001). The theory of LCS offers an advantage as the basis of lexical resources for paraphrasing, because it has been developed to explain varieties of linguistic phenomena including lexical derivations, the construction of compounds, and verb alteration (Levin, 1993; Dorr et al., 1995; Kageyama, 1996; Takeuchi et al., 2001), all of which are associated with the systematic paraphrasing we mentioned above. The paraphrasing associated with LVCs is not idiosyncratic to Japanese but also appears commonly in other languages such as English (Mel’ˇcuk and Polgu`ere, 1987; Iordanskaja et al., 1991; Dras, 1999, etc.), as indicated by the following examples. (2) s. Steven made an attempt to stop playing. t. Steven attempted to stop playing. (3) s. It had a noticeable effect on the trade. t. It noticeably affected the trade. Our approach raises the interesting issue of whether the par</context>
</contexts>
<marker>Dorr, Garman, Weinberg, 1995</marker>
<rawString>B. J. Dorr, J. Garman, and A. Weinberg. 1995. From syntactic encodings to thematic roles: building lexical entries for interlingual MT. Machine Translation, 9(3):71–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dras</author>
</authors>
<title>Tree adjoining grammar and the reluctant paraphrasing of text.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computing, Macquarie University.</institution>
<contexts>
<context position="4577" citStr="Dras, 1999" startWordPosition="702" endWordPosition="703">., 2001). The theory of LCS offers an advantage as the basis of lexical resources for paraphrasing, because it has been developed to explain varieties of linguistic phenomena including lexical derivations, the construction of compounds, and verb alteration (Levin, 1993; Dorr et al., 1995; Kageyama, 1996; Takeuchi et al., 2001), all of which are associated with the systematic paraphrasing we mentioned above. The paraphrasing associated with LVCs is not idiosyncratic to Japanese but also appears commonly in other languages such as English (Mel’ˇcuk and Polgu`ere, 1987; Iordanskaja et al., 1991; Dras, 1999, etc.), as indicated by the following examples. (2) s. Steven made an attempt to stop playing. t. Steven attempted to stop playing. (3) s. It had a noticeable effect on the trade. t. It noticeably affected the trade. Our approach raises the interesting issue of whether the paraphrasing of LVCs can be modeled in an analogous way across languages. Our aim in this paper are: (i) exploring the regularity of the LVC paraphrasing based a lexical semantics-based account, and (ii) assessing the immature Japanese semantic typology through a practical task. The following sections describe our motivatio</context>
<context position="5944" citStr="Dras, 1999" startWordPosition="932" endWordPosition="933">nd our experiments (Section 5). Finally, we conclude this paper with a brief of description of work to be done in the future (Section 6). 2 Motivation, target, and related work 2.1 Motivation One of the critical issues that we face in paraphrase generation is how to develop and maintain knowledge resources that covers a sufficiently wide range of paraphrasing patterns such as those indicating that “to make an attempt” can be paraphrased into “to attempt,” and that “potential” can be paraphrased into “possibility.” Several attempts have been made to develop such resources manually (Sato, 1999; Dras, 1999; Inui and Nogami, 2001); those work have, however, tended to restrict their scope to specific classes of paraphrases, and cannot be used to construct a sufficiently comprehensive resource for practical applications. There is another trend in the research in this field, namely, the automatic acquisition of paraphrase patterns from parallel or comparable corpora (Barzilay and McKeown, 2001; Lin and Pantel, 2001; Pang et al., 2003; Shinyama and Sekine, 2003, etc.). This type of approach may be able to reduce the cost of resource development. There are problems that must be overcome, however, bef</context>
</contexts>
<marker>Dras, 1999</marker>
<rawString>M. Dras. 1999. Tree adjoining grammar and the reluctant paraphrasing of text. Ph.D. thesis, Department of Computing, Macquarie University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Inui</author>
<author>M Nogami</author>
</authors>
<title>A paraphrase-based exploration of cohesiveness criteria.</title>
<date>2001</date>
<booktitle>In Proceedings of the 8th European Workshop on Natulal Language Generation (EWNLG),</booktitle>
<pages>101--110</pages>
<contexts>
<context position="5968" citStr="Inui and Nogami, 2001" startWordPosition="934" endWordPosition="937">iments (Section 5). Finally, we conclude this paper with a brief of description of work to be done in the future (Section 6). 2 Motivation, target, and related work 2.1 Motivation One of the critical issues that we face in paraphrase generation is how to develop and maintain knowledge resources that covers a sufficiently wide range of paraphrasing patterns such as those indicating that “to make an attempt” can be paraphrased into “to attempt,” and that “potential” can be paraphrased into “possibility.” Several attempts have been made to develop such resources manually (Sato, 1999; Dras, 1999; Inui and Nogami, 2001); those work have, however, tended to restrict their scope to specific classes of paraphrases, and cannot be used to construct a sufficiently comprehensive resource for practical applications. There is another trend in the research in this field, namely, the automatic acquisition of paraphrase patterns from parallel or comparable corpora (Barzilay and McKeown, 2001; Lin and Pantel, 2001; Pang et al., 2003; Shinyama and Sekine, 2003, etc.). This type of approach may be able to reduce the cost of resource development. There are problems that must be overcome, however, before they can work practi</context>
</contexts>
<marker>Inui, Nogami, 2001</marker>
<rawString>K. Inui and M. Nogami. 2001. A paraphrase-based exploration of cohesiveness criteria. In Proceedings of the 8th European Workshop on Natulal Language Generation (EWNLG), pages 101–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Inui</author>
<author>A Fujita</author>
<author>T Takahashi</author>
<author>R Iida</author>
<author>T Iwakura</author>
</authors>
<title>Text simplification for reading assistance: a project note.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2nd International Workshop on Paraphrasing: Paraphrase Acquisition and Applications (IWP),</booktitle>
<pages>9--16</pages>
<contexts>
<context position="1635" citStr="Inui et al., 2003" startWordPosition="227" endWordPosition="230">perimental results show that our LCS-based paraphrasing model characterizes some of the semantic features of those verbs required for generating paraphrases, such as the direction of an action and the relationship between arguments and surface cases. 1 Introduction Automatic paraphrase generation technology offers the potential to bridge gaps between the authors and readers of documents. For example, a system that is capable of simplifying a given text, or showing the user several alternative expressions conveying the same content, would be useful for assisting a reader (Carroll et al., 1999; Inui et al., 2003). In Japanese, like other languages, there are several classes of paraphrasing that exhibit a degree of regularity that allows them to be explained by a handful of sophisticated general rules and lexical semantic knowledge. For example, paraphrases associated with voice alteration, verb/case alteration, compounds, and lexical derivations all fall into such classes. In this paper, we focus our discussion on another useful class of paraphrases, namely, the paraphrasing of light-verb constructions (LVCs), and propose a computational model for generating paraphrases of this class. Sentence (1s) is</context>
</contexts>
<marker>Inui, Fujita, Takahashi, Iida, Iwakura, 2003</marker>
<rawString>K. Inui, A. Fujita, T. Takahashi, R. Iida, and T. Iwakura. 2003. Text simplification for reading assistance: a project note. In Proceedings of the 2nd International Workshop on Paraphrasing: Paraphrase Acquisition and Applications (IWP), pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Iordanskaja</author>
<author>R Kittredge</author>
<author>A Polgu`ere</author>
</authors>
<title>Lexical selection and paraphrase in a meaning-text generation model.</title>
<date>1991</date>
<booktitle>In Paris et al. (Eds.) Natural Language Generation in Artificial Intelligence and Computational Linguistics,</booktitle>
<pages>293--312</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Iordanskaja, Kittredge, Polgu`ere, 1991</marker>
<rawString>L. Iordanskaja, R. Kittredge, and A. Polgu`ere. 1991. Lexical selection and paraphrase in a meaning-text generation model. In Paris et al. (Eds.) Natural Language Generation in Artificial Intelligence and Computational Linguistics, pages 293–312. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<title>Verb semantics. Kuroshio Publishers.</title>
<date>1996</date>
<editor>T. Kageyama, editor.</editor>
<note>(in Japanese).</note>
<marker>1996</marker>
<rawString>T. Kageyama, editor. 1996. Verb semantics. Kuroshio Publishers. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kaji</author>
<author>S Kurohashi</author>
</authors>
<title>Recognition and paraphrasing of periphrastic and overlapping verb phrases.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC) Workshop on Methodologies and Evaluation of Multiword Units in Real-world Application.</booktitle>
<contexts>
<context position="10501" citStr="Kaji and Kurohashi (2004)" startWordPosition="1691" endWordPosition="1694">into account only the element (b), namely, the sibling cases of the nominalized verb. 2.3 Related work Based on the Meaning-Text Theory (Mel’ˇcuk and Polgu`ere, 1987), Iordanskaja et al. (1991) proposes a set of paraphrasing rules including one for LVC paraphrasing. Their rule heavily relies on what are called lexical functions, by which they virtually specify all the choices relevant to LVC paraphrasing for every combination of nominalized verb and light-verb individually. Our approach is to employ lexical semantics to provide a general account of those classes of choices. On the other hand, Kaji and Kurohashi (2004) proposes a paraphrasing model which bases on an ordinary dictionary. Given an input LVC, their model paraphrases it using the gloss of both the nominalized verb and the light-verb with the semantic feature of the light-verb. Their model looks robust because of the availability of an ordinary dictionary. However, their model fails to explain the difference in the voice selection between examples (5) and (6) since it selects the voice based only on the light-verb — in their approach, the lightverb “ukeru (to receive)” always maps to the passive voice irrespective of the nominalized verb. (5) s.</context>
</contexts>
<marker>Kaji, Kurohashi, 2004</marker>
<rawString>N. Kaji and S. Kurohashi. 2004. Recognition and paraphrasing of periphrastic and overlapping verb phrases. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC) Workshop on Methodologies and Evaluation of Multiword Units in Real-world Application.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Japanese dependency analysis using cascaded chunking.</title>
<date>2002</date>
<booktitle>In Proceedings of 6th Conference on Natural Language Learning (CoNLL),</booktitle>
<pages>63--69</pages>
<contexts>
<context position="13643" citStr="Kudo and Matsumoto, 2002" startWordPosition="2215" endWordPosition="2218">minalized verbs. We retrieved 1,210 nominalized verbs from the TLCS dictionary. Light-verbs: Since a verb takes different meanings when it is a part of LVCs with different case particles, we collected pairs (c, v) of case particle c and verb v in the following way: Step 1. We collected 876,101 types of triplets (n, c, v) of nominalized verb n, case particle c, and base form of verb v from the parsed5 sentences of newspaper articles6. 4A sahen-noun is a verbal noun in Japanese, which acts as a verb in the form of “sahen-noun + suru”. 5We used the statistical Japanese dependency parser CaboCha (Kudo and Matsumoto, 2002) for parsing. http://chasen.naist.jp/˜taku/software/cabocha/ 6Excerpts from 9 years of the Mainichi Shinbun and 10 years of the Nihon Keizai Shinbun, giving a total of 25,061,504 sentences, were used. Table 2: Extensions of LCS Verb Verb phrase and its LCS representation Ext.1 hankou-suru [[Ken]y BE AGAINST [parents]z] (resist) Ken-ga oya-ni hankou-suru. Ken-NOM parents-DAT resist-PRES (Ken resists his parents.) Ext.2 ukeru [BECOME [[salesclerk]z BE WITH [[complaint]y MOVE FROM [customer]x TO [salesclerk]z]]] (receive) Ten’in-ga kyaku-kara kujo-o ukeru. salesclerk-NOM customer-ABL complaint-AC</context>
</contexts>
<marker>Kudo, Matsumoto, 2002</marker>
<rawString>T. Kudo and Y. Matsumoto. 2002. Japanese dependency analysis using cascaded chunking. In Proceedings of 6th Conference on Natural Language Learning (CoNLL), pages 63–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>English verb classes and alternations: a preliminary investigation.</title>
<date>1993</date>
<publisher>Chicago Press.</publisher>
<contexts>
<context position="4236" citStr="Levin, 1993" startWordPosition="648" endWordPosition="649">cisions depend not only on the syntactic and semantic attributes of the light-verb, but also on those of the nominalized verb (Muraki, 1991). In this paper, we propose a novel lexical semantics-based account of the LVC paraphrasing, which uses the theory of Lexical Conceptual Structure (LCS) of Japanese verbs (Kageyama, 1996; Takeuchi et al., 2001). The theory of LCS offers an advantage as the basis of lexical resources for paraphrasing, because it has been developed to explain varieties of linguistic phenomena including lexical derivations, the construction of compounds, and verb alteration (Levin, 1993; Dorr et al., 1995; Kageyama, 1996; Takeuchi et al., 2001), all of which are associated with the systematic paraphrasing we mentioned above. The paraphrasing associated with LVCs is not idiosyncratic to Japanese but also appears commonly in other languages such as English (Mel’ˇcuk and Polgu`ere, 1987; Iordanskaja et al., 1991; Dras, 1999, etc.), as indicated by the following examples. (2) s. Steven made an attempt to stop playing. t. Steven attempted to stop playing. (3) s. It had a noticeable effect on the trade. t. It noticeably affected the trade. Our approach raises the interesting issue</context>
<context position="15396" citStr="Levin, 1993" startWordPosition="2482" endWordPosition="2483">st frequent (n, c, v). Step 3. Each (n, c, v) was manually evaluated to determine whether it was an LVC. If any of 10 triplets was determined to be an LVC, (c, v) was merged into the list of light-verbs. As a result, we collected 40 types of (c, v) for light-verbs. Through investigating the above 1,210 nominalized verbs and 40 light-verbs, we extended the typology of TLCS as shown below (also see Table 2). Ext. 1. Treatment of “Partner”: The dative case of “hankou-suru (resist)” and “eikyo-suru (affect)” does not indicate the “Goal” of the action but the “Partner.” Ext. 2. Verbs of obtaining (Levin, 1993): In contrast with “ataeru (give),” the nominative case of “ukeru (receive)” and “eru (acquire)” is the “Goal” of the “Theme,” while the ablative case indicates “Source.” Ext. 3. Require verb: “motomeru (ask)” and “yokyu-suru (require)” denote the existence of the external “Agent” who controls the action of the other “Agent” or “Theme.” Ext. 4. Verbs of psychological state (Levin, 1993): “kandou-suru (be impressed)” and “osoreru (fear)” indicate the change of psychological state of the “Agent.” The ascriptive part of the change has to be described. Consequently, we defined a new LCS typology c</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>B. Levin. 1993. English verb classes and alternations: a preliminary investigation. Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="6357" citStr="Lin and Pantel, 2001" startWordPosition="993" endWordPosition="996">o make an attempt” can be paraphrased into “to attempt,” and that “potential” can be paraphrased into “possibility.” Several attempts have been made to develop such resources manually (Sato, 1999; Dras, 1999; Inui and Nogami, 2001); those work have, however, tended to restrict their scope to specific classes of paraphrases, and cannot be used to construct a sufficiently comprehensive resource for practical applications. There is another trend in the research in this field, namely, the automatic acquisition of paraphrase patterns from parallel or comparable corpora (Barzilay and McKeown, 2001; Lin and Pantel, 2001; Pang et al., 2003; Shinyama and Sekine, 2003, etc.). This type of approach may be able to reduce the cost of resource development. There are problems that must be overcome, however, before they can work practically. First, automatically acquired patterns tend to be complex. For example, from the paraphrase of (4s) into (4t), we can naively obtain the pattern: “X is purchased by Y ⇒ Y buys X.” (4) s. This car was purchased by him. t. He bought this car. This could also, however, be regarded as a combination of a simpler pattern of lexical paraphrasing (“purchase ⇒ buy”) and a voice activizati</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>D. Lin and P. Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mel’ˇcuk</author>
<author>A Polgu`ere</author>
</authors>
<title>A formal lexicon in meaning-text theory (or how to do lexica with words).</title>
<date>1987</date>
<journal>Computational Linguistics,</journal>
<pages>13--3</pages>
<marker>Mel’ˇcuk, Polgu`ere, 1987</marker>
<rawString>I. Mel’ˇcuk and A. Polgu`ere. 1987. A formal lexicon in meaning-text theory (or how to do lexica with words). Computational Linguistics, 13(3-4):261–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Muraki</author>
</authors>
<title>Various aspects of Japanese verbs. Hitsuji Syobo.</title>
<date>1991</date>
<note>(in Japanese).</note>
<contexts>
<context position="3765" citStr="Muraki, 1991" startWordPosition="576" endWordPosition="577">ose the voice of the target sentence from active, passive, causative, etc. In example (1), the causative voice is chosen, which is indicated by the auxiliary verb “ase (causative)”. Reassignment of the cases: The model needs to be able to reassign a case marker to each argument of the main verb. In (1), the grammatical case of “kare (him),” which was originally assigned the dative case, is changed to accusative. The task is not as simple as it may seem, because both decisions depend not only on the syntactic and semantic attributes of the light-verb, but also on those of the nominalized verb (Muraki, 1991). In this paper, we propose a novel lexical semantics-based account of the LVC paraphrasing, which uses the theory of Lexical Conceptual Structure (LCS) of Japanese verbs (Kageyama, 1996; Takeuchi et al., 2001). The theory of LCS offers an advantage as the basis of lexical resources for paraphrasing, because it has been developed to explain varieties of linguistic phenomena including lexical derivations, the construction of compounds, and verb alteration (Levin, 1993; Dorr et al., 1995; Kageyama, 1996; Takeuchi et al., 2001), all of which are associated with the systematic paraphrasing we ment</context>
<context position="28831" citStr="Muraki, 1991" startWordPosition="4670" endWordPosition="4671">(14s) should not fill z, because it acts as an adverb, even though it consists of a noun, “medo (prospect)” and a case particle for the dative. We found that 78 erroneous candidates constitute this most dominant type of errors. (14) s. Kin’you-o medo-ni sagyo-o susumeru. Friday-NOM by-DAT work-ACC carry on-PRES I plan to finish the work by Friday. (N=“work”, V =“carry”) LCSV0 [x CONTROL [BECOME [y BE AT z]]] LCSV 1*[x CONTROL [BECOME [[work]y BE AT [by]z]]] The ambiguity of dative cases in Japanese has been discussed in the literature of linguistics and some natural language processing tasks (Muraki, 1991). To date, however, a practical compliment/adjunct classifier has not been established. We plan to address this topic in our future research. Preliminary investigation revealed that only certain groups of nouns can constitute both compliments and adjuncts according to the governing verb. Therefore, generally whether a word acts as a complement is determined without combining it with the verb. 9(Muraki, 1991) classifies dative cases into 11 thematic roles that can be regarded as complements. In contrast, there is no typology of dative cases that act as adjuncts. 5.2.3 Recognition of LVC In our </context>
</contexts>
<marker>Muraki, 1991</marker>
<rawString>S. Muraki. 1991. Various aspects of Japanese verbs. Hitsuji Syobo. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>Syntax-based alignment of multiple translations: extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL),</booktitle>
<pages>102--109</pages>
<contexts>
<context position="6376" citStr="Pang et al., 2003" startWordPosition="997" endWordPosition="1000"> be paraphrased into “to attempt,” and that “potential” can be paraphrased into “possibility.” Several attempts have been made to develop such resources manually (Sato, 1999; Dras, 1999; Inui and Nogami, 2001); those work have, however, tended to restrict their scope to specific classes of paraphrases, and cannot be used to construct a sufficiently comprehensive resource for practical applications. There is another trend in the research in this field, namely, the automatic acquisition of paraphrase patterns from parallel or comparable corpora (Barzilay and McKeown, 2001; Lin and Pantel, 2001; Pang et al., 2003; Shinyama and Sekine, 2003, etc.). This type of approach may be able to reduce the cost of resource development. There are problems that must be overcome, however, before they can work practically. First, automatically acquired patterns tend to be complex. For example, from the paraphrase of (4s) into (4t), we can naively obtain the pattern: “X is purchased by Y ⇒ Y buys X.” (4) s. This car was purchased by him. t. He bought this car. This could also, however, be regarded as a combination of a simpler pattern of lexical paraphrasing (“purchase ⇒ buy”) and a voice activization (“X Figure 1: De</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>B. Pang, K. Knight, and D. Marcu. 2003. Syntax-based alignment of multiple translations: extracting paraphrases and generating new sentences. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL), pages 102–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sato</author>
</authors>
<title>Automatic paraphrase of technical papers’ titles.</title>
<date>1999</date>
<journal>Journal ofInformation Processing Society ofJapan,</journal>
<volume>40</volume>
<issue>7</issue>
<note>(in Japanese).</note>
<contexts>
<context position="5932" citStr="Sato, 1999" startWordPosition="930" endWordPosition="931">ection 4), and our experiments (Section 5). Finally, we conclude this paper with a brief of description of work to be done in the future (Section 6). 2 Motivation, target, and related work 2.1 Motivation One of the critical issues that we face in paraphrase generation is how to develop and maintain knowledge resources that covers a sufficiently wide range of paraphrasing patterns such as those indicating that “to make an attempt” can be paraphrased into “to attempt,” and that “potential” can be paraphrased into “possibility.” Several attempts have been made to develop such resources manually (Sato, 1999; Dras, 1999; Inui and Nogami, 2001); those work have, however, tended to restrict their scope to specific classes of paraphrases, and cannot be used to construct a sufficiently comprehensive resource for practical applications. There is another trend in the research in this field, namely, the automatic acquisition of paraphrase patterns from parallel or comparable corpora (Barzilay and McKeown, 2001; Lin and Pantel, 2001; Pang et al., 2003; Shinyama and Sekine, 2003, etc.). This type of approach may be able to reduce the cost of resource development. There are problems that must be overcome, </context>
</contexts>
<marker>Sato, 1999</marker>
<rawString>S. Sato. 1999. Automatic paraphrase of technical papers’ titles. Journal ofInformation Processing Society ofJapan, 40(7):2937–2945. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Shinyama</author>
<author>S Sekine</author>
</authors>
<title>Paraphrase acquisition for information extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2nd International Workshop on Paraphrasing: Paraphrase Acquisition and Applications (IWP),</booktitle>
<pages>65--71</pages>
<contexts>
<context position="6403" citStr="Shinyama and Sekine, 2003" startWordPosition="1001" endWordPosition="1004">o “to attempt,” and that “potential” can be paraphrased into “possibility.” Several attempts have been made to develop such resources manually (Sato, 1999; Dras, 1999; Inui and Nogami, 2001); those work have, however, tended to restrict their scope to specific classes of paraphrases, and cannot be used to construct a sufficiently comprehensive resource for practical applications. There is another trend in the research in this field, namely, the automatic acquisition of paraphrase patterns from parallel or comparable corpora (Barzilay and McKeown, 2001; Lin and Pantel, 2001; Pang et al., 2003; Shinyama and Sekine, 2003, etc.). This type of approach may be able to reduce the cost of resource development. There are problems that must be overcome, however, before they can work practically. First, automatically acquired patterns tend to be complex. For example, from the paraphrase of (4s) into (4t), we can naively obtain the pattern: “X is purchased by Y ⇒ Y buys X.” (4) s. This car was purchased by him. t. He bought this car. This could also, however, be regarded as a combination of a simpler pattern of lexical paraphrasing (“purchase ⇒ buy”) and a voice activization (“X Figure 1: Dependency structure showing </context>
</contexts>
<marker>Shinyama, Sekine, 2003</marker>
<rawString>Y. Shinyama and S. Sekine. 2003. Paraphrase acquisition for information extraction. In Proceedings of the 2nd International Workshop on Paraphrasing: Paraphrase Acquisition and Applications (IWP), pages 65– 71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Takeuchi</author>
<author>K Uchiyama</author>
<author>S Yoshioka</author>
<author>K Kageura</author>
<author>T Koyama</author>
</authors>
<title>Categorising deverbal nouns based on lexical conceptual structure for analysing Japanese compounds.</title>
<date>2001</date>
<booktitle>In Proceedings of IEEE System, Man, and Cybernetics Conference,</booktitle>
<pages>904--909</pages>
<contexts>
<context position="3975" citStr="Takeuchi et al., 2001" startWordPosition="607" endWordPosition="610"> cases: The model needs to be able to reassign a case marker to each argument of the main verb. In (1), the grammatical case of “kare (him),” which was originally assigned the dative case, is changed to accusative. The task is not as simple as it may seem, because both decisions depend not only on the syntactic and semantic attributes of the light-verb, but also on those of the nominalized verb (Muraki, 1991). In this paper, we propose a novel lexical semantics-based account of the LVC paraphrasing, which uses the theory of Lexical Conceptual Structure (LCS) of Japanese verbs (Kageyama, 1996; Takeuchi et al., 2001). The theory of LCS offers an advantage as the basis of lexical resources for paraphrasing, because it has been developed to explain varieties of linguistic phenomena including lexical derivations, the construction of compounds, and verb alteration (Levin, 1993; Dorr et al., 1995; Kageyama, 1996; Takeuchi et al., 2001), all of which are associated with the systematic paraphrasing we mentioned above. The paraphrasing associated with LVCs is not idiosyncratic to Japanese but also appears commonly in other languages such as English (Mel’ˇcuk and Polgu`ere, 1987; Iordanskaja et al., 1991; Dras, 19</context>
<context position="12436" citStr="Takeuchi et al. (2001)" startWordPosition="2010" endWordPosition="2013">e (LCS) associates a verb with a semantic structure as exemplified by Table 1. An LCS consists of semantic predicates (“CONTROL,” “BE AT,” etc.) and their argument slots (x, y, z). Argument slots x, y, and z correspond to the semantic roles “Agent,” “Theme,” and “Goal,” respectively. Taking the LCS of the verb “transmit” as an example, [y MOVE TO z] denotes the state of affairs that the state of the “Theme” changes to the “Goal,” and [x CONTROL ...] denotes that the “Agent” causes the state change. 3.2 Refinements We make use of the TLCS dictionary, a Japanese verb LCS dictionary developed by Takeuchi et al. (2001), because it offers the following advantages: • It is based on solid linguistic work, as in (Kageyama, 1996). • Its scale is considerably larger than any other existing collections of verb LCS entries. • It provides a set of concrete rules for LCS assignment, which ensures the reliability of the dictionary. In spite of these advantages, our preliminary examination of the dictionary revealed that further refinements were needed. To refine the typology of TLCS, we collected the following sets of words: Nominalized verbs: We regard “sahen-nouns”4 and nominal forms of verbs as nominalized verbs. W</context>
<context position="32325" citStr="Takeuchi et al., 2001" startWordPosition="5245" endWordPosition="5248"> and an extension of an existing LCS dictionary. Our model achieved an accuracy of 75.8% in selecting the voice and reassigning the cases. To make our paraphrasing model more accurate, further analysis is needed, especially for the LCS transformation stage described in Section 4.2. Similarly, several levels of disambiguation should also be solved. The Japanese LCS typology has to be refined from the theoretical point of view. For example, since extensions are no more than human intuition, we must discuss how we can assign LCSs for given verbs based on explicit language tests, as described in (Takeuchi et al., 2001). In future research, we will also extend our LCSbased approach to other classes of paraphrases that exhibit some regularity, such as verb alteration and compound noun decomposition as shown in (17) and (18), below. LCS has been discussed as a means of explaining the difference between transitive/intransitive verbs, and the construction of compounds. Therefore, our next goal is to show the applicability of LCS through practical tasks, namely, paraphrasing. (17) s. Jishin-ga building-o kowashita. earthquake-NOM building-DAT destroy-PAST The earthquake destroyed the building. t. Jishin-de buildi</context>
</contexts>
<marker>Takeuchi, Uchiyama, Yoshioka, Kageura, Koyama, 2001</marker>
<rawString>K. Takeuchi, K. Uchiyama, S. Yoshioka, K. Kageura, and T. Koyama. 2001. Categorising deverbal nouns based on lexical conceptual structure for analysing Japanese compounds. In Proceedings of IEEE System, Man, and Cybernetics Conference, pages 904– 909.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>