<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000441">
<title confidence="0.933142">
An Empirical Study of Chinese Name Matching and Applications
</title>
<author confidence="0.980037">
Nanyun Peng&apos; and Mo Yu2 and Mark Dredze&apos;
</author>
<affiliation confidence="0.9943734">
&apos;Human Language Technology Center of Excellence
Center for Language and Speech Processing
Johns Hopkins University, Baltimore, MD, 21218
2Machine Intelligence and Translation Lab
Harbin Institute of Technology, Harbin, China
</affiliation>
<email confidence="0.993617">
npeng1@jhu.edu, gflfof@gmail.com, mdredze@cs.jhu.edu
</email>
<sectionHeader confidence="0.997353" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999929">
Methods for name matching, an important
component to support downstream tasks
such as entity linking and entity clustering,
have focused on alphabetic languages, pri-
marily English. In contrast, logogram lan-
guages such as Chinese remain untested.
We evaluate methods for name matching
in Chinese, including both string match-
ing and learning approaches. Our ap-
proach, based on new representations for
Chinese, improves both name matching
and a downstream entity clustering task.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976277777778">
A key technique in entity disambiguation is name
matching: determining if two mention strings
could refer to the same entity. The challenge
of name matching lies in name variation, which
can be attributed to many factors: nicknames,
aliases, acronyms, and differences in translitera-
tion, among others. In light of these issues, exact
string match can lead to poor results. Numerous
downstream tasks benefit from improved name
matching: entity coreference (Strube et al., 2002),
name transliteration (Knight and Graehl, 1998),
identifying names for mining paraphrases (Barzi-
lay and Lee, 2003), entity linking (Rao et al.,
2013) and entity clustering (Green et al., 2012).
As a result, there have been numerous proposed
name matching methods (Cohen et al., 2003), with
a focus on person names. Despite extensive explo-
ration of this task, most work has focused on Indo-
European languages in general and English in par-
ticular. These languages use alphabets as repre-
sentations of written language. In contrast, other
languages use logograms, which represent a word
or morpheme, the most popular being Chinese
which uses hanzi ({A). This presents challenges
for name matching: a small number of hanzi repre-
sent an entire name and there are tens of thousands
of hanzi in use. Current methods remain largely
untested in this setting, despite downstream tasks
in Chinese that rely on name matching (Chen et
al., 2010; Cassidy et al., 2011). Martschat et al.
(2012) point out errors in coreference resolution
due to Chinese name matching errors, which sug-
gests that downstream tasks can benefit from im-
provements in Chinese name matching techniques.
This paper presents an analysis of new and ex-
isting approaches to name matching in Chinese.
The goal is to determine whether two Chinese
strings can refer to the same entity (person, orga-
nization, location) based on the strings alone. The
more general task of entity coreference (Soon et
al., 2001), or entity clustering, includes the con-
text of the mentions in determining coreference. In
contrast, standalone name matching modules are
context independent (Andrews et al., 2012; Green
et al., 2012). In addition to showing name match-
ing improvements on newly developed datasets of
matched Chinese name pairs, we show improve-
ments in a downstream Chinese entity clustering
task by using our improved name matching sys-
tem. We call our name matching tool Mingpipe, a
Python package that can be used as a standalone
tool or integrated within a larger system. We re-
lease Mingpipe as well as several datasets to sup-
port further work on this task.1
</bodyText>
<sectionHeader confidence="0.989781" genericHeader="method">
2 Name Matching Methods
</sectionHeader>
<bodyText confidence="0.838767">
Name matching originated as part of research into
record linkage in databases. Initial work focused
</bodyText>
<footnote confidence="0.9954555">
1The code and data for this paper are available at:
https://github.com/hltcoe/mingpipe
</footnote>
<page confidence="0.767885">
377
</page>
<bodyText confidence="0.968290313725491">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 377–383,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
on string matching techniques. This work can
be organized into three major categories: 1) Pho-
netic matching methods, e.g. Soundex (Holmes
and McCabe, 2002), double Metaphone (Philips,
2000) etc.; 2) Edit-distance based measures, e.g.
Levenshtein distance (Levenshtein, 1966), Jaro-
Winkler (Porter et al., 1997; Winkler, 1999),
and 3) Token-based similarity, e.g. soft TF-IDF
(Bilenko et al., 2003). Analyses comparing these
approaches have not found consistent improve-
ments of one method over another (Cohen et al.,
2003; Christen, 2006). More recent work has
focused on learning a string matching model on
name pairs, such as probabilistic noisy channel
models (Sukharev et al., 2014; Bilenko et al.,
2003). The advantage of trained models is that,
with sufficient training data, they can be tuned for
specific tasks.
While many NLP tasks rely on name matching,
research on name matching techniques themselves
has not been a major focus within the NLP com-
munity. Most downstream NLP systems have sim-
ply employed a static edit distance module to de-
cide whether two names can be matched (Chen et
al., 2010; Cassidy et al., 2011; Martschat et al.,
2012). An exception is work on training finite
state transducers for edit distance metrics (Ristad
and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008;
Dreyer et al., 2008; Cotterell et al., 2014). More
recently, Andrews et al. (2012) presented a phylo-
genetic model of string variation using transducers
that applies to pairs of names string (supervised)
and unpaired collections (unsupervised).
Beyond name matching in a single language,
several papers have considered cross lingual name
matching, where name strings are drawn from
two different languages, such as matching Arabic
names (El-Shishtawy, 2013) with English (Free-
man et al., 2006; Green et al., 2012). Addition-
ally, name matching has been used as a component
in cross language entity linking (McNamee et al.,
2011a; McNamee et al., 2011b) and cross lingual
entity clustering (Green et al., 2012). However,
little work has focused on logograms, with the ex-
ception of Cheng et al. (2011). As we will demon-
strate in § 3, there are special challenges caused by
the logogram nature of Chinese. We believe this is
the first evaluation of Chinese name matching.
</bodyText>
<sectionHeader confidence="0.998444" genericHeader="method">
3 Challenges
</sectionHeader>
<bodyText confidence="0.9960645">
Numerous factors cause name variations, includ-
ing abbreviations, morphological derivations, his-
</bodyText>
<subsectionHeader confidence="0.93966">
Examples Notes
</subsectionHeader>
<bodyText confidence="0.65226">
i*VJ_V v.s. 1w2 simplified v.s. traditional
</bodyText>
<listItem confidence="0.383413">
*9 v.s. Abbreviation and traditional
</listItem>
<equation confidence="0.978593">
�f!�Q*09 v.s. simplified
�nWT�AE v.s. Transliteration of Addis Ababa
t ftXT_t AE in Mainland and Taiwan. Dif-
/ iA·ti·s1·iA·bei·bA / ferent hanzi, similar pronuncia-
v.s. / A·ti·s1·A·bei·bA / tions.
svf&apos; p v.s. 9WR Transliteration of Florence in
/ fo·luo·lu@n·sA / Mainland and Hong Kong. Dif-
v.s. / fei·lEN·tsh8v / ferent writing and dialects.
fffAWT·�AA v.s. 4000 Transliteration of Humphrey
/ lu·fu·siu·xan·fu·laI / Rufus in Mainland and Hong
v.s. / xan·lu·fu / Kong. The first uses a literal
</equation>
<bodyText confidence="0.5899264">
transliteration, while the second
does not. Both reverse the name
order (consistent with Chinese
names) and change the surname
to sound Chinese.
</bodyText>
<tableCaption confidence="0.993292">
Table 1: Challenges in Chinese name matching.
</tableCaption>
<bodyText confidence="0.5874594">
torical sound or spelling change, loanword for-
mation, translation, transliteration, or transcription
error (Andrews et al., 2012). In addition to all the
above factors, Chinese name matching presents
unique challenges (Table 1):
</bodyText>
<listItem confidence="0.994224157894737">
• There are more than 50k Chinese characters.
This can create a large number of parameters
in character edit models, which can compli-
cate parameter estimation.
• Chinese characters represent morphemes, not
sounds. Many characters can share a sin-
gle pronunciation2, and many characters have
similar sounds3. This causes typos (mistak-
ing characters with the same pronunciation)
and introduces variability in transliteration
(different characters chosen to represent the
same sound).
• Chinese has two writing systems (simplified,
traditional) and two major dialects (Man-
darin, Cantonese), with different pairings in
different regions (see Table 2 for the three
dominant regional combinations.) This has a
significant impact on loanwords and translit-
erations.
</listItem>
<bodyText confidence="0.463192">
2486 characters are pronounced / tpi / (regardless of tone).
3e.g. E� and IK (different orthography) are pronounced
similar (/tùuAN/ and /tùAN /).
</bodyText>
<page confidence="0.993639">
378
</page>
<table confidence="0.47718775">
Region Writing System Dialect
Hong Kong Traditional Cantonese
Mainland Simplified Mandarin
Taiwan Traditional Mandarin
</table>
<tableCaption confidence="0.834091">
Table 2: Regional variations for Chinese writing
and dialect.
</tableCaption>
<sectionHeader confidence="0.997173" genericHeader="method">
4 Methods
</sectionHeader>
<bodyText confidence="0.999977916666667">
We evaluate several name matching methods,
representative of the major approaches to name
matching described above.
String Matching We consider two common
string matching algorithms: Levenshtein and Jaro-
Winkler. However, because of the issues men-
tioned above we expect these to perform poorly
when applied to Chinese strings. We consider sev-
eral transformations to improve these methods.
First, we map all strings to a single writing sys-
tem: simplified. This is straightforward since tra-
ditional Chinese characters have a many-to-one
mapping to simplified characters. Second, we con-
sider a pronunciation based representation. We
convert characters to pinyin4, the official pho-
netic system (and ISO standard) for transcribing
Mandarin pronunciations into the Latin alphabet.
While pinyin is a common representation used in
Chinese entity disambiguation work (Feng et al.,
2004; Jiang et al., 2007), the pinyin for an en-
tire entity is typically concatenated and treated
as a single string (“string-pinyin”). However, the
pinyin string itself has internal structure that may
be useful for name matching. We consider two
new pinyin representations. Since each Chinese
character corresponds to a pinyin, we take each
pinyin as a token corresponding to the Chinese
character. We call this “character-pinyin”. Addi-
tionally, every Mandarin syllable (represented by
a pinyin) can be spelled with a combination of an
initial and a final segment. Therefore, we split
each pinyin token further into the initial and final
segment. We call this “segmented-pinyin”5.
Transducers We next consider methods that can
be trained on available Chinese name pairs. Trans-
ducers are common choices for learning edit dis-
</bodyText>
<footnote confidence="0.9174124">
4Hong Kong has a romanization scheme more suitable for
Cantonese, but we found no improvements over using pinyin.
Therefore, for simplicity we use pinyin throughout.
5For example, the pinyin for 4K is segmented into / zh /
and / ang /.
</footnote>
<bodyText confidence="0.9998865625">
tance metrics for strings, and they perform bet-
ter than string similarity (Ristad and Yianilos,
1998; Andrews et al., 2012; Cotterell et al., 2014).
We use the probabilistic transducer of Cotterell
et al. (2014) to learn a stochastic edit distance.
The model represent the conditional probability
p(ylx; 0), where y is a generated string based on
editing x according to parameters 0. At each
position xi, one of four actions (copy, substi-
tute, insert, delete) are taken to generate charac-
ter yj. The probability of each action depends
on the string to the left of xi (x(i_N1):i), the
string to the right of xi (xi:(i+N2)), and gener-
ated string to the left of yj (y(j_N3):j). The vari-
ables N1, N2, N3 are the context size. Note that
characters to the right of yj are excluded as they
are not yet generated. Training maximizes the
observed data log-likelihood and EM is used to
marginalize over the latent edit actions. Since the
large number of Chinese characters make param-
eter estimation prohibitive, we only train trans-
ducers on the three pinyin representations: string-
pinyin (28 characters), character-pinyin (384 char-
acters), segmented-pinyin (59 characters).
Name Matching as Classification An alternate
learning formulation considers name matching as
a classification task (Mayfield et al., 2009; Zhang
et al., 2010; Green et al., 2012). Each string pair
is an instance: a positive classification means that
two strings can refer to the same name. This al-
lows for arbitrary and global features of the two
strings. We use an SVM with a linear kernel.
To learn possible edit rules for Chinese names
we add features for pairs of n-grams. For each
string, we extract all n-grams (n=1,2,3) and align
n-grams between strings using the Hungarian al-
gorithm.6 Features correspond to the aligned n-
gram pairs, as well as the unaligned n-grams.
To reduce the number of parameters, we only
include features which appear in positive train-
ing examples. These features are generated for
two string representations: the simplified Chinese
string (simplified n-grams) and a pinyin repre-
sentation (pinyin n-grams), so that we can in-
corporate both orthographic features and phonetic
features. We separately select the best perform-
ing pinyin representation (string-pinyin, character-
pinyin, segmented-pinyin) on development data
</bodyText>
<footnote confidence="0.770070333333333">
6We found this performed much better than directly align-
ing characters or tokens. We also tried n-gram TF-IDF cosine
similarity, but it degraded results (Cohen et al., 2003).
</footnote>
<page confidence="0.978019">
379
</page>
<table confidence="0.999771428571428">
Feature Type Number of Features
Simplified n-grams —10k
Pinyin n-grams —9k
Jaccard similarity 6 × 10
TF-IDF similarity 2 × 10
Levenshtein distance 2 × 10
Other 7
</table>
<tableCaption confidence="0.896579">
Table 3: Features for SVM learning.
</tableCaption>
<bodyText confidence="0.994142571428572">
for each dataset.
We measure Jaccard similarity between the
two strings separately for 1,2,3-grams for each
string representation. An additional feature in-
dicates no n-gram overlap. The best performing
Levenshtein distance metric is included as a fea-
ture. Finally, we include other features for several
name properties: the difference in character length
and two indicators as to whether the first character
of the two strings match and if its a common Chi-
nese last name. Real valued features are binarized.
Table 3 lists the feature templates we used in
our SVM model and the corresponding number of
features.
</bodyText>
<sectionHeader confidence="0.999651" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.755357">
5.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999752090909091">
We constructed two datasets from Wikipedia.
REDIRECT: We extracted webpage redirects
from Chinese Wikipedia pages that correspond to
entities (person, organization, location); the page
type is indicated in the page’s metadata. Redi-
rect links indicate queries that all lead to the
same page, such as “Barack Hussein Obama” and
“Barack Obama”. To remove redirects that are not
entities (e.g. “44th president”) we removed entries
that contain numerals and Latin characters, as well
as names that contain certain keywords.7 The fi-
nal dataset contains 13,730 pairs of person names,
10,686 organizations and 5,152 locations, divided
into s train, s development and s test.
NAME GROUPS: Chinese Wikipedia contains a
handcrafted mapping between the entity name and
various transliterations,8 including for Mainland,
Hong Kong and Taiwan. We created two datasets:
Mainland-Hong Kong (1288 people pairs, 357 lo-
cations, 177 organizations), and Mainland-Taiwan
(1500 people, 439 locations, 112 organizations).
Data proportions are split as in REDIRECT.
</bodyText>
<footnote confidence="0.998890666666667">
7Entries that contain 34JA(list), ã*_(representative) , L4
J (movement), P19 (issue) and * (wikipedia).
8http://zh.wikipedia.org/wiki/Template:CGroup
</footnote>
<table confidence="0.999923272727273">
Method Character prec@1 prec@3 MRR
original 0.773 0.838 0.821
Levenshtein simplified 0.816 0.872 0.856
string-pinyin 0.743 0.844 0.811
character-pinyin 0.824 0.885 0.866
segment-pinyin 0.797 0.877 0.849
original 0.690 0.792 0.767
Jaro-Winkler simplified 0.741 0.821 0.803
string-pinyin 0.741 0.818 0.800
character-pinyin 0.751 0.831 0.813
segment-pinyin 0.753 0.821 0.808
</table>
<tableCaption confidence="0.999908">
Table 4: String matching on development data.
</tableCaption>
<subsectionHeader confidence="0.982882">
5.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999925230769231">
We evaluated performance on a ranking task (the
setting of Andrews et al. (2012)). In each instance,
the algorithm was given a query and a set of 11
names from which to select the best match. The
11 names included a matching name as well as 10
other names with some character overlap with the
query that are randomly chose from the same data
split. We evaluate using precision@1,3 and mean
reciprocal rank (MRR). Classifiers were trained
on the true pairs (positive) and negative examples
constructed by pairing a name with 10 other names
that have some character overlap with it. The two
SVM parameters (the regularizer co-efficient C
and the instance weight w for positive examples),
as well as the best pinyin representation, were se-
lected using grid search on dev data.
Results For string matching methods, simplified
characters improve over the original characters for
both Levenshtein and Jaro-Winkler (Table 4). Sur-
prisingly, pinyin does not help over the simpli-
fied characters. Segmented pinyin improved over
pinyin but did not do as well as the simplified char-
acters. Our method of character pinyin performed
the best overall, because it utilizes the phonetic
information the pinyin encodes: all the different
characters that have the same pronunciation are
reduced to the same pinyin representation. Over
all the representations, Levenshtein outperformed
Jaro-Winkler, consistent with previous work (Co-
hen et al., 2003).
Compared to the best string matching method
(Levenshtein over pinyin characters), the trans-
ducer improves for the two name group datasets
but does worse on REDIRECT (Table 5). The
heterogeneous nature of REDIRECT, including
variation from aliases, nicknames, and long-
distance re-ordering, may confuse the trans-
ducer. The SVM does best overall, improv-
ing for all datasets over string matching and
</bodyText>
<page confidence="0.994294">
380
</page>
<table confidence="0.9999563">
Method Dataset prec@1 prec@3 MRR
REDIRECT 0.820 0.868 0.859
Levenshtein Mainland-Taiwan 0.867 0.903 0.897
Mainland-Hong Kong 0.873 0.937 0.911
REDIRECT 0.767 0.873 0.833
Transducer Mainland-Taiwan 0.889 0.938 0.921
Mainland-Hong Kong 0.925(∗) 0.989(∗) 0.954(∗)
REDIRECT 0.888(∗∗) 0.948(∗∗) 0.924(∗∗)
SVM Mainland-Taiwan 0.926 0.966(∗∗) 0.951(∗)
Mainland-Hong Kongs 0.882 0.972 0.928
</table>
<tableCaption confidence="0.847265">
Table 5: Results on test data. * better than
Levenshtein; ** better than all other methods
</tableCaption>
<table confidence="0.949556555555556">
(p = 0.05)
Features Datasets
REDIRECT Name Groups
ALL 0.921 0.966
- Jaccard similariy 0.908 0.929
- Levenshtein 0.919 0.956
- Simplified pairs 0.918 0.965
- Pinyin pairs 0.920 0.960
- Others 0.921 0.962
</table>
<tableCaption confidence="0.999406">
Table 6: Ablation experiments on SVM features
</tableCaption>
<bodyText confidence="0.994353714285715">
tying or beating the transducer. Different
pinyin representations (combined with the sim-
plified representation) worked best on differ-
ent datasets: character-pinyin for REDIRECT,
segmented-pinyin for Mainland-Hongkong and
string-pinyin for Mainland-Taiwan. To understand
how the features for SVM affect the final results,
we conduct ablation tests for different group of
features when trained on person names (only) for
each dataset (Table 6). Overall, Jaccard features
are the most effective.
Error Analysis We annotated 100 randomly
sampled REDIRECT development pairs incorrectly
classified by the SVM. We found three major types
of errors. 1) Matches requiring external knowl-
edge (43% of errors), where there were nicknames
or aliases. In these cases, the given name strings
are insufficient for determining the correct an-
swer. These types of errors are typically han-
dled using alias lists. 2) Transliteration confusions
(13%) resulting from different dialects, transliter-
ation versus translation, or only part of a name be-
ing transliterated. 3) Noisy data (19%): Wikipedia
redirects include names in other languages (e.g.
Japanese, Korean) or orthographically identical
strings for different entities. Finally, 25% of the
time the system simply got the wrong answer,
Many of these cases are acronyms.
</bodyText>
<subsectionHeader confidence="0.989222">
5.3 Entity Clustering
</subsectionHeader>
<bodyText confidence="0.997239">
We evaluate the impact of our improved name
matching on a downstream task: entity clustering
</bodyText>
<table confidence="0.999191285714286">
Method Dev Test
Precision Recall F1 Precision Recall F1
Exact match 84.55 57.46 68.42 63.95 65.44 64.69
Jaro-winkler 84.87 58.35 69.15 70.79 66.21 68.42
Levenshtein 83.16 61.13 70.46 69.56 67.27 68.40
Transducer 90.33 74.92 81.90 73.59 63.70 68.29
SVM 90.05 63.90 74.75 74.33 67.60 70.81
</table>
<tableCaption confidence="0.999803">
Table 7: Results on Chinese entity clustering.
</tableCaption>
<bodyText confidence="0.999660555555556">
(cross document coreference resolution), where
the goal is identify co-referent named mentions
across documents. Only a few studies have con-
sidered Chinese entity clustering (Chen and Mar-
tin, 2007), including the TAC KBP shared task,
which has included clustering Chinese NIL men-
tions (Ji et al., 2011). We construct an entity clus-
tering dataset from the TAC KBP entity linking
data. All of the 2012 Chinese data is used as de-
velopment, and the 2013 data as test. We use the
system of Green et al. (2012), which allows for
the inclusion of arbitrary name matching metrics.
We follow their setup for training and evaluation
(B3) and use TF-IDF context features. We tune
the clustering cutoff for their hierarchical model,
as well as the name matching threshold on the de-
velopment data. For the trainable name matching
methods (transducer, SVM) we train the methods
on the development data using cross-validation, as
well as tuning the representations and model pa-
rameters. We include an exact match baseline.
Table 7 shows that on test data, our best method
(SVM) improves over all previous methods by
over 2 points. The transducer makes strong gains
on dev but not test, suggesting that parameter tun-
ing overfit. These results demonstrate the down-
stream benefits of improved name matching.
</bodyText>
<sectionHeader confidence="0.995661" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998795307692308">
Our results suggest several research directions.
The remaining errors could be addressed with ad-
ditional resources. Alias lists could be learned
from data or derived from existing resources.
Since the best pinyin representation varies by
dataset, work could automatically determine the
most effective representation, which may include
determining the type of variation present in the
proposed pair, as well as the associated dialect.
Our name matching tool, Mingpipe, is imple-
mented as a Python library. We make Mingpipe
and our datasets available to aid future research on
this topic.9
</bodyText>
<footnote confidence="0.970846">
9https://github.com/hltcoe/mingpipe
</footnote>
<page confidence="0.996992">
381
</page>
<sectionHeader confidence="0.996227" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999756558558558">
Nicholas Andrews, Jason Eisner, and Mark Dredze.
2012. Name phylogeny: A generative model of
string variation. In Empirical Methods in Natural
Language Processing (EMNLP), pages 344–355.
Regina Barzilay and Lillian Lee. 2003. Learning
to paraphrase: An unsupervised approach using
multiple-sequence alignment. In North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (NAACL-
HLT), pages 16–23.
Mikhail Bilenko, Raymond Mooney, William Cohen,
Pradeep Ravikumar, and Stephen Fienberg. 2003.
Adaptive name matching in information integration.
IEEE Intelligent Systems, 18(5):16–23.
Alexandre Bouchard-Cˆot´e, Percy Liang, Dan Klein,
and Thomas L Griffiths. 2008. A probabilistic ap-
proach to language change. In Advances in Neural
Information Processing Systems (NIPS), pages 169–
176.
Taylor Cassidy, Zheng Chen, Javier Artiles, Heng Ji,
Hongbo Deng, Lev-Arie Ratinov, Jing Zheng, Ji-
awei Han, and Dan Roth. 2011. Cuny-uiuc-sri tac-
kbp2011 entity linking system description. In Text
Analysis Conference (TAC).
Ying Chen and James Martin. 2007. Towards ro-
bust unsupervised personal name disambiguation.
In Empirical Methods in Natural Language Process-
ing (EMNLP), pages 190–198.
Ying Chen, Peng Jin, Wenjie Li, and Chu-Ren Huang.
2010. The chinese persons name disambiguation
evaluation: Exploration of personal name disam-
biguation in chinese news. In CIPS-SIGHAN Joint
Conference on Chinese Language Processing.
Gang Cheng, Fei Wang, Haiyang Lv, and Yinling
Zhang. 2011. Anew matching algorithm for chi-
nese place names. In International Conference on
Geoinformatics, pages 1–4. IEEE.
Peter Christen. 2006. A comparison of personal
name matching: Techniques and practical issues.
In IEEE International Conference on Data Mining
Workshops, pages 290–294.
William Cohen, Pradeep Ravikumar, and Stephen Fien-
berg. 2003. A comparison of string metrics for
matching names and records. In KDD Workshop on
Data Cleaning and Object Consolidation, pages 73–
78.
Ryan Cotterell, Nanyun Peng, and Jason Eisner. 2014.
Stochastic contextual edit distance and probabilistic
fsts. In Association for Computational Linguistics
(ACL), pages 625–630.
Markus Dreyer, Jason R Smith, and Jason Eisner.
2008. Latent-variable modeling of string transduc-
tions with finite-state methods. In Empirical Meth-
ods in Natural Language Processing (EMNLP),
pages 1080–1089.
Tarek El-Shishtawy. 2013. A hybrid algo-
rithm for matching arabic names. arXiv preprint
arXiv:1309.5657.
Donghui Feng, Yajuan L¨u, and Ming Zhou. 2004.
A new approach for english-chinese named entity
alignment. In Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 372–379.
Andrew T Freeman, Sherri L Condon, and Christo-
pher M Ackerman. 2006. Cross linguistic name
matching in english and arabic: a one to many map-
ping extension of the levenshtein edit distance algo-
rithm. In North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies (NAACL-HLT), pages 471–478.
Spence Green, Nicholas Andrews, Matthew R. Gorm-
ley, Mark Dredze, and Christopher D. Manning.
2012. Entity clustering across languages. In North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(NAACL-HLT), pages 60–69.
David Holmes and M Catherine McCabe. 2002. Im-
proving precision and recall for soundex retrieval.
In International Conference on Information Tech-
nology: Coding and Computing, pages 22–26.
Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011.
Overview of the tac 2011 knowledge base popula-
tion track. In Text Analytics Conference.
Long Jiang, Ming Zhou, Lee-Feng Chien, and Cheng
Niu. 2007. Named entity translation with web
mining and transliteration. In International Joint
Conference on Artificial Intelligence (IJCAI), pages
1629–1634.
Kevin Knight and Jonathan Graehl. 1998. Ma-
chine transliteration. Computational Linguistics,
24(4):599–612.
A Levenshtein. 1966. Binary codes capable of cor-
recting deletions, insertions and reversals. Soviet
Physics Doklady, 10(8):707–710.
Sebastian Martschat, Jie Cai, Samuel Broscheit, ´Eva
M´ujdricza-Maydt, and Michael Strube. 2012. A
multigraph model for coreference resolution. In
Empirical Methods in Natural Language Processing
(EMNLP) and the Conference on Natural Language
Learning (CONLL), pages 100–106.
James Mayfield, David Alexander, Bonnie J Dorr, Ja-
son Eisner, Tamer Elsayed, Tim Finin, Clayton Fink,
Marjorie Freedman, Nikesh Garera, Paul McNamee,
et al. 2009. Cross-document coreference resolu-
tion: A key technology for learning by reading. In
AAAI Spring Symposium: Learning by Reading and
Learning to Read, pages 65–70.
Paul McNamee, James Mayfield, Dawn Lawrie, Dou-
glas W Oard, and David S Doermann. 2011a.
Cross-language entity linking. In International Joint
Conference on Natural Language Processing (IJC-
NLP), pages 255–263.
</reference>
<page confidence="0.979034">
382
</page>
<reference confidence="0.999645641025641">
Paul McNamee, James Mayfield, Douglas W Oard,
Tan Xu, Ke Wu, Veselin Stoyanov, and David Do-
ermann. 2011b. Cross-language entity linking in
maryland during a hurricane. In Empirical Methods
in Natural Language Processing (EMNLP).
L Philips. 2000. The double metaphone search algo-
rithm. C/C++ Users Journal, 18(6).
Edward H Porter, William E Winkler, et al. 1997. Ap-
proximate string comparison and its effect on an ad-
vanced record linkage system. In Advanced record
linkage system. US Bureau of the Census, Research
Report.
Delip Rao, Paul McNamee, and Mark Dredze. 2013.
Entity linking: Finding extracted entities in a knowl-
edge base. In Multi-source, Multilingual Informa-
tion Extraction and Summarization, pages 93–115.
Springer.
Eric Sven Ristad and Peter N Yianilos. 1998. Learning
string-edit distance. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 20(5):522–532.
Wee Meng Soon, Hwee Tou Ng, and Daniel
Chung Yong Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrases.
Computational linguistics, 27(4):521–544.
Michael Strube, Stefan Rapp, and Christoph M¨uller.
2002. The influence of minimum edit distance on
reference resolution. In Empirical Methods in Natu-
ral Language Processing (EMNLP), pages 312–319.
Jeffrey Sukharev, Leonid Zhukov, and Alexandrin
Popescul. 2014. Learning alternative name
spellings. arXiv preprint arXiv:1405.2048.
William E Winkler. 1999. The state of record link-
age and current research problems. In Statistical Re-
search Division, US Census Bureau.
Wei Zhang, Jian Su, Chew Lim Tan, and Wen Ting
Wang. 2010. Entity linking leveraging: Automat-
ically generated annotation. In International Con-
ference on Computational Linguistics (COLING),
pages 1290–1298.
</reference>
<page confidence="0.999358">
383
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.384708">
<title confidence="0.946424">An Empirical Study of Chinese Name Matching and Applications</title>
<affiliation confidence="0.705397">Language Technology Center of Center for Language and Speech Johns Hopkins University, Baltimore, MD, Intelligence and Translation Harbin Institute of Technology, Harbin,</affiliation>
<email confidence="0.996923">npeng1@jhu.edu,gflfof@gmail.com,mdredze@cs.jhu.edu</email>
<abstract confidence="0.999537692307692">Methods for name matching, an important component to support downstream tasks such as entity linking and entity clustering, have focused on alphabetic languages, primarily English. In contrast, logogram languages such as Chinese remain untested. We evaluate methods for name matching in Chinese, including both string matching and learning approaches. Our approach, based on new representations for Chinese, improves both name matching and a downstream entity clustering task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Andrews</author>
<author>Jason Eisner</author>
<author>Mark Dredze</author>
</authors>
<title>Name phylogeny: A generative model of string variation.</title>
<date>2012</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>344--355</pages>
<contexts>
<context position="2998" citStr="Andrews et al., 2012" startWordPosition="456" endWordPosition="459"> due to Chinese name matching errors, which suggests that downstream tasks can benefit from improvements in Chinese name matching techniques. This paper presents an analysis of new and existing approaches to name matching in Chinese. The goal is to determine whether two Chinese strings can refer to the same entity (person, organization, location) based on the strings alone. The more general task of entity coreference (Soon et al., 2001), or entity clustering, includes the context of the mentions in determining coreference. In contrast, standalone name matching modules are context independent (Andrews et al., 2012; Green et al., 2012). In addition to showing name matching improvements on newly developed datasets of matched Chinese name pairs, we show improvements in a downstream Chinese entity clustering task by using our improved name matching system. We call our name matching tool Mingpipe, a Python package that can be used as a standalone tool or integrated within a larger system. We release Mingpipe as well as several datasets to support further work on this task.1 2 Name Matching Methods Name matching originated as part of research into record linkage in databases. Initial work focused 1The code a</context>
<context position="5330" citStr="Andrews et al. (2012)" startWordPosition="822" endWordPosition="825">ufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have simply employed a static edit distance module to decide whether two names can be matched (Chen et al., 2010; Cassidy et al., 2011; Martschat et al., 2012). An exception is work on training finite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008; Dreyer et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a component in cross language entity linking (McNamee et al., 2011a; McNamee et al., 2011b) and cross lingual entity cluste</context>
<context position="7230" citStr="Andrews et al., 2012" startWordPosition="1113" endWordPosition="1116">ons. svf&apos; p v.s. 9WR Transliteration of Florence in / fo·luo·lu@n·sA / Mainland and Hong Kong. Difv.s. / fei·lEN·tsh8v / ferent writing and dialects. fffAWT·�AA v.s. 4000 Transliteration of Humphrey / lu·fu·siu·xan·fu·laI / Rufus in Mainland and Hong v.s. / xan·lu·fu / Kong. The first uses a literal transliteration, while the second does not. Both reverse the name order (consistent with Chinese names) and change the surname to sound Chinese. Table 1: Challenges in Chinese name matching. torical sound or spelling change, loanword formation, translation, transliteration, or transcription error (Andrews et al., 2012). In addition to all the above factors, Chinese name matching presents unique challenges (Table 1): • There are more than 50k Chinese characters. This can create a large number of parameters in character edit models, which can complicate parameter estimation. • Chinese characters represent morphemes, not sounds. Many characters can share a single pronunciation2, and many characters have similar sounds3. This causes typos (mistaking characters with the same pronunciation) and introduces variability in transliteration (different characters chosen to represent the same sound). • Chinese has two w</context>
<context position="10481" citStr="Andrews et al., 2012" startWordPosition="1605" endWordPosition="1608">nt. Therefore, we split each pinyin token further into the initial and final segment. We call this “segmented-pinyin”5. Transducers We next consider methods that can be trained on available Chinese name pairs. Transducers are common choices for learning edit dis4Hong Kong has a romanization scheme more suitable for Cantonese, but we found no improvements over using pinyin. Therefore, for simplicity we use pinyin throughout. 5For example, the pinyin for 4K is segmented into / zh / and / ang /. tance metrics for strings, and they perform better than string similarity (Ristad and Yianilos, 1998; Andrews et al., 2012; Cotterell et al., 2014). We use the probabilistic transducer of Cotterell et al. (2014) to learn a stochastic edit distance. The model represent the conditional probability p(ylx; 0), where y is a generated string based on editing x according to parameters 0. At each position xi, one of four actions (copy, substitute, insert, delete) are taken to generate character yj. The probability of each action depends on the string to the left of xi (x(i_N1):i), the string to the right of xi (xi:(i+N2)), and generated string to the left of yj (y(j_N3):j). The variables N1, N2, N3 are the context size. </context>
<context position="15390" citStr="Andrews et al. (2012)" startWordPosition="2358" endWordPosition="2361">esentative) , L4 J (movement), P19 (issue) and * (wikipedia). 8http://zh.wikipedia.org/wiki/Template:CGroup Method Character prec@1 prec@3 MRR original 0.773 0.838 0.821 Levenshtein simplified 0.816 0.872 0.856 string-pinyin 0.743 0.844 0.811 character-pinyin 0.824 0.885 0.866 segment-pinyin 0.797 0.877 0.849 original 0.690 0.792 0.767 Jaro-Winkler simplified 0.741 0.821 0.803 string-pinyin 0.741 0.818 0.800 character-pinyin 0.751 0.831 0.813 segment-pinyin 0.753 0.821 0.808 Table 4: String matching on development data. 5.2 Evaluation We evaluated performance on a ranking task (the setting of Andrews et al. (2012)). In each instance, the algorithm was given a query and a set of 11 names from which to select the best match. The 11 names included a matching name as well as 10 other names with some character overlap with the query that are randomly chose from the same data split. We evaluate using precision@1,3 and mean reciprocal rank (MRR). Classifiers were trained on the true pairs (positive) and negative examples constructed by pairing a name with 10 other names that have some character overlap with it. The two SVM parameters (the regularizer co-efficient C and the instance weight w for positive examp</context>
</contexts>
<marker>Andrews, Eisner, Dredze, 2012</marker>
<rawString>Nicholas Andrews, Jason Eisner, and Mark Dredze. 2012. Name phylogeny: A generative model of string variation. In Empirical Methods in Natural Language Processing (EMNLP), pages 344–355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT),</booktitle>
<pages>16--23</pages>
<contexts>
<context position="1472" citStr="Barzilay and Lee, 2003" startWordPosition="207" endWordPosition="211">clustering task. 1 Introduction A key technique in entity disambiguation is name matching: determining if two mention strings could refer to the same entity. The challenge of name matching lies in name variation, which can be attributed to many factors: nicknames, aliases, acronyms, and differences in transliteration, among others. In light of these issues, exact string match can lead to poor results. Numerous downstream tasks benefit from improved name matching: entity coreference (Strube et al., 2002), name transliteration (Knight and Graehl, 1998), identifying names for mining paraphrases (Barzilay and Lee, 2003), entity linking (Rao et al., 2013) and entity clustering (Green et al., 2012). As a result, there have been numerous proposed name matching methods (Cohen et al., 2003), with a focus on person names. Despite extensive exploration of this task, most work has focused on IndoEuropean languages in general and English in particular. These languages use alphabets as representations of written language. In contrast, other languages use logograms, which represent a word or morpheme, the most popular being Chinese which uses hanzi ({A). This presents challenges for name matching: a small number of han</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: An unsupervised approach using multiple-sequence alignment. In North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT), pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Bilenko</author>
<author>Raymond Mooney</author>
<author>William Cohen</author>
<author>Pradeep Ravikumar</author>
<author>Stephen Fienberg</author>
</authors>
<title>Adaptive name matching in information integration.</title>
<date>2003</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="4350" citStr="Bilenko et al., 2003" startWordPosition="661" endWordPosition="664">iation for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 377–383, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics on string matching techniques. This work can be organized into three major categories: 1) Phonetic matching methods, e.g. Soundex (Holmes and McCabe, 2002), double Metaphone (Philips, 2000) etc.; 2) Edit-distance based measures, e.g. Levenshtein distance (Levenshtein, 1966), JaroWinkler (Porter et al., 1997; Winkler, 1999), and 3) Token-based similarity, e.g. soft TF-IDF (Bilenko et al., 2003). Analyses comparing these approaches have not found consistent improvements of one method over another (Cohen et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have </context>
</contexts>
<marker>Bilenko, Mooney, Cohen, Ravikumar, Fienberg, 2003</marker>
<rawString>Mikhail Bilenko, Raymond Mooney, William Cohen, Pradeep Ravikumar, and Stephen Fienberg. 2003. Adaptive name matching in information integration. IEEE Intelligent Systems, 18(5):16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Bouchard-Cˆot´e</author>
<author>Percy Liang</author>
<author>Dan Klein</author>
<author>Thomas L Griffiths</author>
</authors>
<title>A probabilistic approach to language change.</title>
<date>2008</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS),</booktitle>
<pages>169--176</pages>
<marker>Bouchard-Cˆot´e, Liang, Klein, Griffiths, 2008</marker>
<rawString>Alexandre Bouchard-Cˆot´e, Percy Liang, Dan Klein, and Thomas L Griffiths. 2008. A probabilistic approach to language change. In Advances in Neural Information Processing Systems (NIPS), pages 169– 176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Cassidy</author>
<author>Zheng Chen</author>
<author>Javier Artiles</author>
<author>Heng Ji</author>
<author>Hongbo Deng</author>
<author>Lev-Arie Ratinov</author>
<author>Jing Zheng</author>
<author>Jiawei Han</author>
<author>Dan Roth</author>
</authors>
<title>Cuny-uiuc-sri tackbp2011 entity linking system description.</title>
<date>2011</date>
<booktitle>In Text Analysis Conference (TAC).</booktitle>
<contexts>
<context position="2310" citStr="Cassidy et al., 2011" startWordPosition="347" endWordPosition="350">e exploration of this task, most work has focused on IndoEuropean languages in general and English in particular. These languages use alphabets as representations of written language. In contrast, other languages use logograms, which represent a word or morpheme, the most popular being Chinese which uses hanzi ({A). This presents challenges for name matching: a small number of hanzi represent an entire name and there are tens of thousands of hanzi in use. Current methods remain largely untested in this setting, despite downstream tasks in Chinese that rely on name matching (Chen et al., 2010; Cassidy et al., 2011). Martschat et al. (2012) point out errors in coreference resolution due to Chinese name matching errors, which suggests that downstream tasks can benefit from improvements in Chinese name matching techniques. This paper presents an analysis of new and existing approaches to name matching in Chinese. The goal is to determine whether two Chinese strings can refer to the same entity (person, organization, location) based on the strings alone. The more general task of entity coreference (Soon et al., 2001), or entity clustering, includes the context of the mentions in determining coreference. In </context>
<context position="5079" citStr="Cassidy et al., 2011" startWordPosition="783" endWordPosition="786">n et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have simply employed a static edit distance module to decide whether two names can be matched (Chen et al., 2010; Cassidy et al., 2011; Martschat et al., 2012). An exception is work on training finite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008; Dreyer et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic n</context>
</contexts>
<marker>Cassidy, Chen, Artiles, Ji, Deng, Ratinov, Zheng, Han, Roth, 2011</marker>
<rawString>Taylor Cassidy, Zheng Chen, Javier Artiles, Heng Ji, Hongbo Deng, Lev-Arie Ratinov, Jing Zheng, Jiawei Han, and Dan Roth. 2011. Cuny-uiuc-sri tackbp2011 entity linking system description. In Text Analysis Conference (TAC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Chen</author>
<author>James Martin</author>
</authors>
<title>Towards robust unsupervised personal name disambiguation.</title>
<date>2007</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>190--198</pages>
<contexts>
<context position="19815" citStr="Chen and Martin, 2007" startWordPosition="3028" endWordPosition="3032">evaluate the impact of our improved name matching on a downstream task: entity clustering Method Dev Test Precision Recall F1 Precision Recall F1 Exact match 84.55 57.46 68.42 63.95 65.44 64.69 Jaro-winkler 84.87 58.35 69.15 70.79 66.21 68.42 Levenshtein 83.16 61.13 70.46 69.56 67.27 68.40 Transducer 90.33 74.92 81.90 73.59 63.70 68.29 SVM 90.05 63.90 74.75 74.33 67.60 70.81 Table 7: Results on Chinese entity clustering. (cross document coreference resolution), where the goal is identify co-referent named mentions across documents. Only a few studies have considered Chinese entity clustering (Chen and Martin, 2007), including the TAC KBP shared task, which has included clustering Chinese NIL mentions (Ji et al., 2011). We construct an entity clustering dataset from the TAC KBP entity linking data. All of the 2012 Chinese data is used as development, and the 2013 data as test. We use the system of Green et al. (2012), which allows for the inclusion of arbitrary name matching metrics. We follow their setup for training and evaluation (B3) and use TF-IDF context features. We tune the clustering cutoff for their hierarchical model, as well as the name matching threshold on the development data. For the trai</context>
</contexts>
<marker>Chen, Martin, 2007</marker>
<rawString>Ying Chen and James Martin. 2007. Towards robust unsupervised personal name disambiguation. In Empirical Methods in Natural Language Processing (EMNLP), pages 190–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Chen</author>
<author>Peng Jin</author>
<author>Wenjie Li</author>
<author>Chu-Ren Huang</author>
</authors>
<title>The chinese persons name disambiguation evaluation: Exploration of personal name disambiguation in chinese news.</title>
<date>2010</date>
<booktitle>In CIPS-SIGHAN Joint Conference on Chinese Language Processing.</booktitle>
<contexts>
<context position="2287" citStr="Chen et al., 2010" startWordPosition="343" endWordPosition="346">s. Despite extensive exploration of this task, most work has focused on IndoEuropean languages in general and English in particular. These languages use alphabets as representations of written language. In contrast, other languages use logograms, which represent a word or morpheme, the most popular being Chinese which uses hanzi ({A). This presents challenges for name matching: a small number of hanzi represent an entire name and there are tens of thousands of hanzi in use. Current methods remain largely untested in this setting, despite downstream tasks in Chinese that rely on name matching (Chen et al., 2010; Cassidy et al., 2011). Martschat et al. (2012) point out errors in coreference resolution due to Chinese name matching errors, which suggests that downstream tasks can benefit from improvements in Chinese name matching techniques. This paper presents an analysis of new and existing approaches to name matching in Chinese. The goal is to determine whether two Chinese strings can refer to the same entity (person, organization, location) based on the strings alone. The more general task of entity coreference (Soon et al., 2001), or entity clustering, includes the context of the mentions in deter</context>
<context position="5057" citStr="Chen et al., 2010" startWordPosition="779" endWordPosition="782"> over another (Cohen et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have simply employed a static edit distance module to decide whether two names can be matched (Chen et al., 2010; Cassidy et al., 2011; Martschat et al., 2012). An exception is work on training finite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008; Dreyer et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, suc</context>
</contexts>
<marker>Chen, Jin, Li, Huang, 2010</marker>
<rawString>Ying Chen, Peng Jin, Wenjie Li, and Chu-Ren Huang. 2010. The chinese persons name disambiguation evaluation: Exploration of personal name disambiguation in chinese news. In CIPS-SIGHAN Joint Conference on Chinese Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gang Cheng</author>
<author>Fei Wang</author>
<author>Haiyang Lv</author>
<author>Yinling Zhang</author>
</authors>
<title>Anew matching algorithm for chinese place names.</title>
<date>2011</date>
<booktitle>In International Conference on Geoinformatics,</booktitle>
<pages>1--4</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6045" citStr="Cheng et al. (2011)" startWordPosition="934" endWordPosition="937">ames string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a component in cross language entity linking (McNamee et al., 2011a; McNamee et al., 2011b) and cross lingual entity clustering (Green et al., 2012). However, little work has focused on logograms, with the exception of Cheng et al. (2011). As we will demonstrate in § 3, there are special challenges caused by the logogram nature of Chinese. We believe this is the first evaluation of Chinese name matching. 3 Challenges Numerous factors cause name variations, including abbreviations, morphological derivations, hisExamples Notes i*VJ_V v.s. 1w2 simplified v.s. traditional *9 v.s. Abbreviation and traditional �f!�Q*09 v.s. simplified �nWT�AE v.s. Transliteration of Addis Ababa t ftXT_t AE in Mainland and Taiwan. Dif/ iA·ti·s1·iA·bei·bA / ferent hanzi, similar pronunciav.s. / A·ti·s1·A·bei·bA / tions. svf&apos; p v.s. 9WR Transliteration</context>
</contexts>
<marker>Cheng, Wang, Lv, Zhang, 2011</marker>
<rawString>Gang Cheng, Fei Wang, Haiyang Lv, and Yinling Zhang. 2011. Anew matching algorithm for chinese place names. In International Conference on Geoinformatics, pages 1–4. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Christen</author>
</authors>
<title>A comparison of personal name matching: Techniques and practical issues.</title>
<date>2006</date>
<booktitle>In IEEE International Conference on Data Mining Workshops,</booktitle>
<pages>290--294</pages>
<contexts>
<context position="4490" citStr="Christen, 2006" startWordPosition="684" endWordPosition="685">ing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics on string matching techniques. This work can be organized into three major categories: 1) Phonetic matching methods, e.g. Soundex (Holmes and McCabe, 2002), double Metaphone (Philips, 2000) etc.; 2) Edit-distance based measures, e.g. Levenshtein distance (Levenshtein, 1966), JaroWinkler (Porter et al., 1997; Winkler, 1999), and 3) Token-based similarity, e.g. soft TF-IDF (Bilenko et al., 2003). Analyses comparing these approaches have not found consistent improvements of one method over another (Cohen et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have simply employed a static edit distance module to decide whether two names can be matched (Chen et al., 2010; Cassidy et al., 2011; Martschat</context>
</contexts>
<marker>Christen, 2006</marker>
<rawString>Peter Christen. 2006. A comparison of personal name matching: Techniques and practical issues. In IEEE International Conference on Data Mining Workshops, pages 290–294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Cohen</author>
<author>Pradeep Ravikumar</author>
<author>Stephen Fienberg</author>
</authors>
<title>A comparison of string metrics for matching names and records.</title>
<date>2003</date>
<booktitle>In KDD Workshop on Data Cleaning and Object Consolidation,</booktitle>
<pages>73--78</pages>
<contexts>
<context position="1641" citStr="Cohen et al., 2003" startWordPosition="236" endWordPosition="239">f name matching lies in name variation, which can be attributed to many factors: nicknames, aliases, acronyms, and differences in transliteration, among others. In light of these issues, exact string match can lead to poor results. Numerous downstream tasks benefit from improved name matching: entity coreference (Strube et al., 2002), name transliteration (Knight and Graehl, 1998), identifying names for mining paraphrases (Barzilay and Lee, 2003), entity linking (Rao et al., 2013) and entity clustering (Green et al., 2012). As a result, there have been numerous proposed name matching methods (Cohen et al., 2003), with a focus on person names. Despite extensive exploration of this task, most work has focused on IndoEuropean languages in general and English in particular. These languages use alphabets as representations of written language. In contrast, other languages use logograms, which represent a word or morpheme, the most popular being Chinese which uses hanzi ({A). This presents challenges for name matching: a small number of hanzi represent an entire name and there are tens of thousands of hanzi in use. Current methods remain largely untested in this setting, despite downstream tasks in Chinese</context>
<context position="4473" citStr="Cohen et al., 2003" startWordPosition="680" endWordPosition="683"> pages 377–383, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics on string matching techniques. This work can be organized into three major categories: 1) Phonetic matching methods, e.g. Soundex (Holmes and McCabe, 2002), double Metaphone (Philips, 2000) etc.; 2) Edit-distance based measures, e.g. Levenshtein distance (Levenshtein, 1966), JaroWinkler (Porter et al., 1997; Winkler, 1999), and 3) Token-based similarity, e.g. soft TF-IDF (Bilenko et al., 2003). Analyses comparing these approaches have not found consistent improvements of one method over another (Cohen et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have simply employed a static edit distance module to decide whether two names can be matched (Chen et al., 2010; Cassidy et al.</context>
<context position="12845" citStr="Cohen et al., 2003" startWordPosition="1983" endWordPosition="1986">meters, we only include features which appear in positive training examples. These features are generated for two string representations: the simplified Chinese string (simplified n-grams) and a pinyin representation (pinyin n-grams), so that we can incorporate both orthographic features and phonetic features. We separately select the best performing pinyin representation (string-pinyin, characterpinyin, segmented-pinyin) on development data 6We found this performed much better than directly aligning characters or tokens. We also tried n-gram TF-IDF cosine similarity, but it degraded results (Cohen et al., 2003). 379 Feature Type Number of Features Simplified n-grams —10k Pinyin n-grams —9k Jaccard similarity 6 × 10 TF-IDF similarity 2 × 10 Levenshtein distance 2 × 10 Other 7 Table 3: Features for SVM learning. for each dataset. We measure Jaccard similarity between the two strings separately for 1,2,3-grams for each string representation. An additional feature indicates no n-gram overlap. The best performing Levenshtein distance metric is included as a feature. Finally, we include other features for several name properties: the difference in character length and two indicators as to whether the firs</context>
<context position="16739" citStr="Cohen et al., 2003" startWordPosition="2572" endWordPosition="2576"> simplified characters improve over the original characters for both Levenshtein and Jaro-Winkler (Table 4). Surprisingly, pinyin does not help over the simplified characters. Segmented pinyin improved over pinyin but did not do as well as the simplified characters. Our method of character pinyin performed the best overall, because it utilizes the phonetic information the pinyin encodes: all the different characters that have the same pronunciation are reduced to the same pinyin representation. Over all the representations, Levenshtein outperformed Jaro-Winkler, consistent with previous work (Cohen et al., 2003). Compared to the best string matching method (Levenshtein over pinyin characters), the transducer improves for the two name group datasets but does worse on REDIRECT (Table 5). The heterogeneous nature of REDIRECT, including variation from aliases, nicknames, and longdistance re-ordering, may confuse the transducer. The SVM does best overall, improving for all datasets over string matching and 380 Method Dataset prec@1 prec@3 MRR REDIRECT 0.820 0.868 0.859 Levenshtein Mainland-Taiwan 0.867 0.903 0.897 Mainland-Hong Kong 0.873 0.937 0.911 REDIRECT 0.767 0.873 0.833 Transducer Mainland-Taiwan 0</context>
</contexts>
<marker>Cohen, Ravikumar, Fienberg, 2003</marker>
<rawString>William Cohen, Pradeep Ravikumar, and Stephen Fienberg. 2003. A comparison of string metrics for matching names and records. In KDD Workshop on Data Cleaning and Object Consolidation, pages 73– 78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Cotterell</author>
<author>Nanyun Peng</author>
<author>Jason Eisner</author>
</authors>
<title>Stochastic contextual edit distance and probabilistic fsts.</title>
<date>2014</date>
<booktitle>In Association for Computational Linguistics (ACL),</booktitle>
<pages>625--630</pages>
<contexts>
<context position="5292" citStr="Cotterell et al., 2014" startWordPosition="816" endWordPosition="819">antage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have simply employed a static edit distance module to decide whether two names can be matched (Chen et al., 2010; Cassidy et al., 2011; Martschat et al., 2012). An exception is work on training finite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008; Dreyer et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a component in cross language entity linking (McNamee et al., 2011a; McNamee et al., </context>
<context position="10506" citStr="Cotterell et al., 2014" startWordPosition="1609" endWordPosition="1612">t each pinyin token further into the initial and final segment. We call this “segmented-pinyin”5. Transducers We next consider methods that can be trained on available Chinese name pairs. Transducers are common choices for learning edit dis4Hong Kong has a romanization scheme more suitable for Cantonese, but we found no improvements over using pinyin. Therefore, for simplicity we use pinyin throughout. 5For example, the pinyin for 4K is segmented into / zh / and / ang /. tance metrics for strings, and they perform better than string similarity (Ristad and Yianilos, 1998; Andrews et al., 2012; Cotterell et al., 2014). We use the probabilistic transducer of Cotterell et al. (2014) to learn a stochastic edit distance. The model represent the conditional probability p(ylx; 0), where y is a generated string based on editing x according to parameters 0. At each position xi, one of four actions (copy, substitute, insert, delete) are taken to generate character yj. The probability of each action depends on the string to the left of xi (x(i_N1):i), the string to the right of xi (xi:(i+N2)), and generated string to the left of yj (y(j_N3):j). The variables N1, N2, N3 are the context size. Note that characters to t</context>
</contexts>
<marker>Cotterell, Peng, Eisner, 2014</marker>
<rawString>Ryan Cotterell, Nanyun Peng, and Jason Eisner. 2014. Stochastic contextual edit distance and probabilistic fsts. In Association for Computational Linguistics (ACL), pages 625–630.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dreyer</author>
<author>Jason R Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Latent-variable modeling of string transductions with finite-state methods.</title>
<date>2008</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1080--1089</pages>
<contexts>
<context position="5267" citStr="Dreyer et al., 2008" startWordPosition="812" endWordPosition="815">t al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have simply employed a static edit distance module to decide whether two names can be matched (Chen et al., 2010; Cassidy et al., 2011; Martschat et al., 2012). An exception is work on training finite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008; Dreyer et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a component in cross language entity linking (McNamee et al.</context>
</contexts>
<marker>Dreyer, Smith, Eisner, 2008</marker>
<rawString>Markus Dreyer, Jason R Smith, and Jason Eisner. 2008. Latent-variable modeling of string transductions with finite-state methods. In Empirical Methods in Natural Language Processing (EMNLP), pages 1080–1089.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tarek El-Shishtawy</author>
</authors>
<title>A hybrid algorithm for matching arabic names. arXiv preprint arXiv:1309.5657.</title>
<date>2013</date>
<contexts>
<context position="5704" citStr="El-Shishtawy, 2013" startWordPosition="877" endWordPosition="878">schat et al., 2012). An exception is work on training finite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008; Dreyer et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a component in cross language entity linking (McNamee et al., 2011a; McNamee et al., 2011b) and cross lingual entity clustering (Green et al., 2012). However, little work has focused on logograms, with the exception of Cheng et al. (2011). As we will demonstrate in § 3, there are special challenges caused by the logogram nature of Chinese. We believe this is the first evaluation of Chinese name matching. 3 Challenges Numerous factors cause name variations, including abbreviations, morphologic</context>
</contexts>
<marker>El-Shishtawy, 2013</marker>
<rawString>Tarek El-Shishtawy. 2013. A hybrid algorithm for matching arabic names. arXiv preprint arXiv:1309.5657.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donghui Feng</author>
<author>Yajuan L¨u</author>
<author>Ming Zhou</author>
</authors>
<title>A new approach for english-chinese named entity alignment.</title>
<date>2004</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>372--379</pages>
<marker>Feng, L¨u, Zhou, 2004</marker>
<rawString>Donghui Feng, Yajuan L¨u, and Ming Zhou. 2004. A new approach for english-chinese named entity alignment. In Empirical Methods in Natural Language Processing (EMNLP), pages 372–379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew T Freeman</author>
<author>Sherri L Condon</author>
<author>Christopher M Ackerman</author>
</authors>
<title>Cross linguistic name matching in english and arabic: a one to many mapping extension of the levenshtein edit distance algorithm.</title>
<date>2006</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<pages>471--478</pages>
<contexts>
<context position="5739" citStr="Freeman et al., 2006" startWordPosition="881" endWordPosition="885">is work on training finite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008; Dreyer et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a component in cross language entity linking (McNamee et al., 2011a; McNamee et al., 2011b) and cross lingual entity clustering (Green et al., 2012). However, little work has focused on logograms, with the exception of Cheng et al. (2011). As we will demonstrate in § 3, there are special challenges caused by the logogram nature of Chinese. We believe this is the first evaluation of Chinese name matching. 3 Challenges Numerous factors cause name variations, including abbreviations, morphological derivations, hisExamples Notes i</context>
</contexts>
<marker>Freeman, Condon, Ackerman, 2006</marker>
<rawString>Andrew T Freeman, Sherri L Condon, and Christopher M Ackerman. 2006. Cross linguistic name matching in english and arabic: a one to many mapping extension of the levenshtein edit distance algorithm. In North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 471–478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Nicholas Andrews</author>
<author>Matthew R Gormley</author>
<author>Mark Dredze</author>
<author>Christopher D Manning</author>
</authors>
<title>Entity clustering across languages. In North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</title>
<date>2012</date>
<pages>60--69</pages>
<contexts>
<context position="1550" citStr="Green et al., 2012" startWordPosition="221" endWordPosition="224">atching: determining if two mention strings could refer to the same entity. The challenge of name matching lies in name variation, which can be attributed to many factors: nicknames, aliases, acronyms, and differences in transliteration, among others. In light of these issues, exact string match can lead to poor results. Numerous downstream tasks benefit from improved name matching: entity coreference (Strube et al., 2002), name transliteration (Knight and Graehl, 1998), identifying names for mining paraphrases (Barzilay and Lee, 2003), entity linking (Rao et al., 2013) and entity clustering (Green et al., 2012). As a result, there have been numerous proposed name matching methods (Cohen et al., 2003), with a focus on person names. Despite extensive exploration of this task, most work has focused on IndoEuropean languages in general and English in particular. These languages use alphabets as representations of written language. In contrast, other languages use logograms, which represent a word or morpheme, the most popular being Chinese which uses hanzi ({A). This presents challenges for name matching: a small number of hanzi represent an entire name and there are tens of thousands of hanzi in use. C</context>
<context position="3019" citStr="Green et al., 2012" startWordPosition="460" endWordPosition="463">atching errors, which suggests that downstream tasks can benefit from improvements in Chinese name matching techniques. This paper presents an analysis of new and existing approaches to name matching in Chinese. The goal is to determine whether two Chinese strings can refer to the same entity (person, organization, location) based on the strings alone. The more general task of entity coreference (Soon et al., 2001), or entity clustering, includes the context of the mentions in determining coreference. In contrast, standalone name matching modules are context independent (Andrews et al., 2012; Green et al., 2012). In addition to showing name matching improvements on newly developed datasets of matched Chinese name pairs, we show improvements in a downstream Chinese entity clustering task by using our improved name matching system. We call our name matching tool Mingpipe, a Python package that can be used as a standalone tool or integrated within a larger system. We release Mingpipe as well as several datasets to support further work on this task.1 2 Name Matching Methods Name matching originated as part of research into record linkage in databases. Initial work focused 1The code and data for this pape</context>
<context position="5760" citStr="Green et al., 2012" startWordPosition="886" endWordPosition="889">nite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008; Dreyer et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a component in cross language entity linking (McNamee et al., 2011a; McNamee et al., 2011b) and cross lingual entity clustering (Green et al., 2012). However, little work has focused on logograms, with the exception of Cheng et al. (2011). As we will demonstrate in § 3, there are special challenges caused by the logogram nature of Chinese. We believe this is the first evaluation of Chinese name matching. 3 Challenges Numerous factors cause name variations, including abbreviations, morphological derivations, hisExamples Notes i*VJ_V v.s. 1w2 simpli</context>
<context position="11701" citStr="Green et al., 2012" startWordPosition="1803" endWordPosition="1806">ote that characters to the right of yj are excluded as they are not yet generated. Training maximizes the observed data log-likelihood and EM is used to marginalize over the latent edit actions. Since the large number of Chinese characters make parameter estimation prohibitive, we only train transducers on the three pinyin representations: stringpinyin (28 characters), character-pinyin (384 characters), segmented-pinyin (59 characters). Name Matching as Classification An alternate learning formulation considers name matching as a classification task (Mayfield et al., 2009; Zhang et al., 2010; Green et al., 2012). Each string pair is an instance: a positive classification means that two strings can refer to the same name. This allows for arbitrary and global features of the two strings. We use an SVM with a linear kernel. To learn possible edit rules for Chinese names we add features for pairs of n-grams. For each string, we extract all n-grams (n=1,2,3) and align n-grams between strings using the Hungarian algorithm.6 Features correspond to the aligned ngram pairs, as well as the unaligned n-grams. To reduce the number of parameters, we only include features which appear in positive training examples</context>
<context position="20122" citStr="Green et al. (2012)" startWordPosition="3087" endWordPosition="3090">.92 81.90 73.59 63.70 68.29 SVM 90.05 63.90 74.75 74.33 67.60 70.81 Table 7: Results on Chinese entity clustering. (cross document coreference resolution), where the goal is identify co-referent named mentions across documents. Only a few studies have considered Chinese entity clustering (Chen and Martin, 2007), including the TAC KBP shared task, which has included clustering Chinese NIL mentions (Ji et al., 2011). We construct an entity clustering dataset from the TAC KBP entity linking data. All of the 2012 Chinese data is used as development, and the 2013 data as test. We use the system of Green et al. (2012), which allows for the inclusion of arbitrary name matching metrics. We follow their setup for training and evaluation (B3) and use TF-IDF context features. We tune the clustering cutoff for their hierarchical model, as well as the name matching threshold on the development data. For the trainable name matching methods (transducer, SVM) we train the methods on the development data using cross-validation, as well as tuning the representations and model parameters. We include an exact match baseline. Table 7 shows that on test data, our best method (SVM) improves over all previous methods by ove</context>
</contexts>
<marker>Green, Andrews, Gormley, Dredze, Manning, 2012</marker>
<rawString>Spence Green, Nicholas Andrews, Matthew R. Gormley, Mark Dredze, and Christopher D. Manning. 2012. Entity clustering across languages. In North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 60–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Holmes</author>
<author>M Catherine McCabe</author>
</authors>
<title>Improving precision and recall for soundex retrieval.</title>
<date>2002</date>
<booktitle>In International Conference on Information Technology: Coding and Computing,</booktitle>
<pages>22--26</pages>
<contexts>
<context position="4109" citStr="Holmes and McCabe, 2002" startWordPosition="628" endWordPosition="631">s Name matching originated as part of research into record linkage in databases. Initial work focused 1The code and data for this paper are available at: https://github.com/hltcoe/mingpipe 377 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 377–383, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics on string matching techniques. This work can be organized into three major categories: 1) Phonetic matching methods, e.g. Soundex (Holmes and McCabe, 2002), double Metaphone (Philips, 2000) etc.; 2) Edit-distance based measures, e.g. Levenshtein distance (Levenshtein, 1966), JaroWinkler (Porter et al., 1997; Winkler, 1999), and 3) Token-based similarity, e.g. soft TF-IDF (Bilenko et al., 2003). Analyses comparing these approaches have not found consistent improvements of one method over another (Cohen et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with s</context>
</contexts>
<marker>Holmes, McCabe, 2002</marker>
<rawString>David Holmes and M Catherine McCabe. 2002. Improving precision and recall for soundex retrieval. In International Conference on Information Technology: Coding and Computing, pages 22–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of the tac 2011 knowledge base population track.</title>
<date>2011</date>
<booktitle>In Text Analytics Conference.</booktitle>
<contexts>
<context position="19920" citStr="Ji et al., 2011" startWordPosition="3047" endWordPosition="3050">sion Recall F1 Precision Recall F1 Exact match 84.55 57.46 68.42 63.95 65.44 64.69 Jaro-winkler 84.87 58.35 69.15 70.79 66.21 68.42 Levenshtein 83.16 61.13 70.46 69.56 67.27 68.40 Transducer 90.33 74.92 81.90 73.59 63.70 68.29 SVM 90.05 63.90 74.75 74.33 67.60 70.81 Table 7: Results on Chinese entity clustering. (cross document coreference resolution), where the goal is identify co-referent named mentions across documents. Only a few studies have considered Chinese entity clustering (Chen and Martin, 2007), including the TAC KBP shared task, which has included clustering Chinese NIL mentions (Ji et al., 2011). We construct an entity clustering dataset from the TAC KBP entity linking data. All of the 2012 Chinese data is used as development, and the 2013 data as test. We use the system of Green et al. (2012), which allows for the inclusion of arbitrary name matching metrics. We follow their setup for training and evaluation (B3) and use TF-IDF context features. We tune the clustering cutoff for their hierarchical model, as well as the name matching threshold on the development data. For the trainable name matching methods (transducer, SVM) we train the methods on the development data using cross-va</context>
</contexts>
<marker>Ji, Grishman, Dang, 2011</marker>
<rawString>Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011. Overview of the tac 2011 knowledge base population track. In Text Analytics Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Ming Zhou</author>
<author>Lee-Feng Chien</author>
<author>Cheng Niu</author>
</authors>
<title>Named entity translation with web mining and transliteration.</title>
<date>2007</date>
<booktitle>In International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<pages>1629--1634</pages>
<contexts>
<context position="9325" citStr="Jiang et al., 2007" startWordPosition="1420" endWordPosition="1423"> perform poorly when applied to Chinese strings. We consider several transformations to improve these methods. First, we map all strings to a single writing system: simplified. This is straightforward since traditional Chinese characters have a many-to-one mapping to simplified characters. Second, we consider a pronunciation based representation. We convert characters to pinyin4, the official phonetic system (and ISO standard) for transcribing Mandarin pronunciations into the Latin alphabet. While pinyin is a common representation used in Chinese entity disambiguation work (Feng et al., 2004; Jiang et al., 2007), the pinyin for an entire entity is typically concatenated and treated as a single string (“string-pinyin”). However, the pinyin string itself has internal structure that may be useful for name matching. We consider two new pinyin representations. Since each Chinese character corresponds to a pinyin, we take each pinyin as a token corresponding to the Chinese character. We call this “character-pinyin”. Additionally, every Mandarin syllable (represented by a pinyin) can be spelled with a combination of an initial and a final segment. Therefore, we split each pinyin token further into the initi</context>
</contexts>
<marker>Jiang, Zhou, Chien, Niu, 2007</marker>
<rawString>Long Jiang, Ming Zhou, Lee-Feng Chien, and Cheng Niu. 2007. Named entity translation with web mining and transliteration. In International Joint Conference on Artificial Intelligence (IJCAI), pages 1629–1634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<pages>24--4</pages>
<contexts>
<context position="1405" citStr="Knight and Graehl, 1998" startWordPosition="198" endWordPosition="201">ns for Chinese, improves both name matching and a downstream entity clustering task. 1 Introduction A key technique in entity disambiguation is name matching: determining if two mention strings could refer to the same entity. The challenge of name matching lies in name variation, which can be attributed to many factors: nicknames, aliases, acronyms, and differences in transliteration, among others. In light of these issues, exact string match can lead to poor results. Numerous downstream tasks benefit from improved name matching: entity coreference (Strube et al., 2002), name transliteration (Knight and Graehl, 1998), identifying names for mining paraphrases (Barzilay and Lee, 2003), entity linking (Rao et al., 2013) and entity clustering (Green et al., 2012). As a result, there have been numerous proposed name matching methods (Cohen et al., 2003), with a focus on person names. Despite extensive exploration of this task, most work has focused on IndoEuropean languages in general and English in particular. These languages use alphabets as representations of written language. In contrast, other languages use logograms, which represent a word or morpheme, the most popular being Chinese which uses hanzi ({A)</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4):599–612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions and reversals.</title>
<date>1966</date>
<journal>Soviet Physics Doklady,</journal>
<volume>10</volume>
<issue>8</issue>
<contexts>
<context position="4228" citStr="Levenshtein, 1966" startWordPosition="644" endWordPosition="645">this paper are available at: https://github.com/hltcoe/mingpipe 377 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 377–383, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics on string matching techniques. This work can be organized into three major categories: 1) Phonetic matching methods, e.g. Soundex (Holmes and McCabe, 2002), double Metaphone (Philips, 2000) etc.; 2) Edit-distance based measures, e.g. Levenshtein distance (Levenshtein, 1966), JaroWinkler (Porter et al., 1997; Winkler, 1999), and 3) Token-based similarity, e.g. soft TF-IDF (Bilenko et al., 2003). Analyses comparing these approaches have not found consistent improvements of one method over another (Cohen et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on </context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>A Levenshtein. 1966. Binary codes capable of correcting deletions, insertions and reversals. Soviet Physics Doklady, 10(8):707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Martschat</author>
<author>Jie Cai</author>
<author>Samuel Broscheit</author>
<author>´Eva M´ujdricza-Maydt</author>
<author>Michael Strube</author>
</authors>
<title>A multigraph model for coreference resolution.</title>
<date>2012</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP) and the Conference on Natural Language Learning (CONLL),</booktitle>
<pages>100--106</pages>
<marker>Martschat, Cai, Broscheit, M´ujdricza-Maydt, Strube, 2012</marker>
<rawString>Sebastian Martschat, Jie Cai, Samuel Broscheit, ´Eva M´ujdricza-Maydt, and Michael Strube. 2012. A multigraph model for coreference resolution. In Empirical Methods in Natural Language Processing (EMNLP) and the Conference on Natural Language Learning (CONLL), pages 100–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Mayfield</author>
<author>David Alexander</author>
<author>Bonnie J Dorr</author>
<author>Jason Eisner</author>
<author>Tamer Elsayed</author>
<author>Tim Finin</author>
<author>Clayton Fink</author>
<author>Marjorie Freedman</author>
<author>Nikesh Garera</author>
<author>Paul McNamee</author>
</authors>
<title>Cross-document coreference resolution: A key technology for learning by reading. In AAAI Spring Symposium: Learning by Reading and Learning to Read,</title>
<date>2009</date>
<pages>65--70</pages>
<contexts>
<context position="11660" citStr="Mayfield et al., 2009" startWordPosition="1795" endWordPosition="1798">ariables N1, N2, N3 are the context size. Note that characters to the right of yj are excluded as they are not yet generated. Training maximizes the observed data log-likelihood and EM is used to marginalize over the latent edit actions. Since the large number of Chinese characters make parameter estimation prohibitive, we only train transducers on the three pinyin representations: stringpinyin (28 characters), character-pinyin (384 characters), segmented-pinyin (59 characters). Name Matching as Classification An alternate learning formulation considers name matching as a classification task (Mayfield et al., 2009; Zhang et al., 2010; Green et al., 2012). Each string pair is an instance: a positive classification means that two strings can refer to the same name. This allows for arbitrary and global features of the two strings. We use an SVM with a linear kernel. To learn possible edit rules for Chinese names we add features for pairs of n-grams. For each string, we extract all n-grams (n=1,2,3) and align n-grams between strings using the Hungarian algorithm.6 Features correspond to the aligned ngram pairs, as well as the unaligned n-grams. To reduce the number of parameters, we only include features w</context>
</contexts>
<marker>Mayfield, Alexander, Dorr, Eisner, Elsayed, Finin, Fink, Freedman, Garera, McNamee, 2009</marker>
<rawString>James Mayfield, David Alexander, Bonnie J Dorr, Jason Eisner, Tamer Elsayed, Tim Finin, Clayton Fink, Marjorie Freedman, Nikesh Garera, Paul McNamee, et al. 2009. Cross-document coreference resolution: A key technology for learning by reading. In AAAI Spring Symposium: Learning by Reading and Learning to Read, pages 65–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>James Mayfield</author>
<author>Dawn Lawrie</author>
<author>Douglas W Oard</author>
<author>David S Doermann</author>
</authors>
<title>Cross-language entity linking.</title>
<date>2011</date>
<booktitle>In International Joint Conference on Natural Language Processing (IJCNLP),</booktitle>
<pages>255--263</pages>
<contexts>
<context position="5873" citStr="McNamee et al., 2011" startWordPosition="905" endWordPosition="908">r et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a component in cross language entity linking (McNamee et al., 2011a; McNamee et al., 2011b) and cross lingual entity clustering (Green et al., 2012). However, little work has focused on logograms, with the exception of Cheng et al. (2011). As we will demonstrate in § 3, there are special challenges caused by the logogram nature of Chinese. We believe this is the first evaluation of Chinese name matching. 3 Challenges Numerous factors cause name variations, including abbreviations, morphological derivations, hisExamples Notes i*VJ_V v.s. 1w2 simplified v.s. traditional *9 v.s. Abbreviation and traditional �f!�Q*09 v.s. simplified �nWT�AE v.s. Transliteration </context>
</contexts>
<marker>McNamee, Mayfield, Lawrie, Oard, Doermann, 2011</marker>
<rawString>Paul McNamee, James Mayfield, Dawn Lawrie, Douglas W Oard, and David S Doermann. 2011a. Cross-language entity linking. In International Joint Conference on Natural Language Processing (IJCNLP), pages 255–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>James Mayfield</author>
<author>Douglas W Oard</author>
<author>Tan Xu</author>
<author>Ke Wu</author>
<author>Veselin Stoyanov</author>
<author>David Doermann</author>
</authors>
<title>Cross-language entity linking in maryland during a hurricane.</title>
<date>2011</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="5873" citStr="McNamee et al., 2011" startWordPosition="905" endWordPosition="908">r et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a component in cross language entity linking (McNamee et al., 2011a; McNamee et al., 2011b) and cross lingual entity clustering (Green et al., 2012). However, little work has focused on logograms, with the exception of Cheng et al. (2011). As we will demonstrate in § 3, there are special challenges caused by the logogram nature of Chinese. We believe this is the first evaluation of Chinese name matching. 3 Challenges Numerous factors cause name variations, including abbreviations, morphological derivations, hisExamples Notes i*VJ_V v.s. 1w2 simplified v.s. traditional *9 v.s. Abbreviation and traditional �f!�Q*09 v.s. simplified �nWT�AE v.s. Transliteration </context>
</contexts>
<marker>McNamee, Mayfield, Oard, Xu, Wu, Stoyanov, Doermann, 2011</marker>
<rawString>Paul McNamee, James Mayfield, Douglas W Oard, Tan Xu, Ke Wu, Veselin Stoyanov, and David Doermann. 2011b. Cross-language entity linking in maryland during a hurricane. In Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Philips</author>
</authors>
<title>The double metaphone search algorithm.</title>
<date>2000</date>
<journal>C/C++ Users Journal,</journal>
<volume>18</volume>
<issue>6</issue>
<contexts>
<context position="4143" citStr="Philips, 2000" startWordPosition="634" endWordPosition="635">ch into record linkage in databases. Initial work focused 1The code and data for this paper are available at: https://github.com/hltcoe/mingpipe 377 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 377–383, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics on string matching techniques. This work can be organized into three major categories: 1) Phonetic matching methods, e.g. Soundex (Holmes and McCabe, 2002), double Metaphone (Philips, 2000) etc.; 2) Edit-distance based measures, e.g. Levenshtein distance (Levenshtein, 1966), JaroWinkler (Porter et al., 1997; Winkler, 1999), and 3) Token-based similarity, e.g. soft TF-IDF (Bilenko et al., 2003). Analyses comparing these approaches have not found consistent improvements of one method over another (Cohen et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can </context>
</contexts>
<marker>Philips, 2000</marker>
<rawString>L Philips. 2000. The double metaphone search algorithm. C/C++ Users Journal, 18(6).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward H Porter</author>
<author>William E Winkler</author>
</authors>
<title>Approximate string comparison and its effect on an advanced record linkage system.</title>
<date>1997</date>
<booktitle>In Advanced record linkage system. US Bureau of the Census, Research Report.</booktitle>
<marker>Porter, Winkler, 1997</marker>
<rawString>Edward H Porter, William E Winkler, et al. 1997. Approximate string comparison and its effect on an advanced record linkage system. In Advanced record linkage system. US Bureau of the Census, Research Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Paul McNamee</author>
<author>Mark Dredze</author>
</authors>
<title>Entity linking: Finding extracted entities in a knowledge base.</title>
<date>2013</date>
<booktitle>In Multi-source, Multilingual Information Extraction and Summarization,</booktitle>
<pages>93--115</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1507" citStr="Rao et al., 2013" startWordPosition="214" endWordPosition="217">hnique in entity disambiguation is name matching: determining if two mention strings could refer to the same entity. The challenge of name matching lies in name variation, which can be attributed to many factors: nicknames, aliases, acronyms, and differences in transliteration, among others. In light of these issues, exact string match can lead to poor results. Numerous downstream tasks benefit from improved name matching: entity coreference (Strube et al., 2002), name transliteration (Knight and Graehl, 1998), identifying names for mining paraphrases (Barzilay and Lee, 2003), entity linking (Rao et al., 2013) and entity clustering (Green et al., 2012). As a result, there have been numerous proposed name matching methods (Cohen et al., 2003), with a focus on person names. Despite extensive exploration of this task, most work has focused on IndoEuropean languages in general and English in particular. These languages use alphabets as representations of written language. In contrast, other languages use logograms, which represent a word or morpheme, the most popular being Chinese which uses hanzi ({A). This presents challenges for name matching: a small number of hanzi represent an entire name and the</context>
</contexts>
<marker>Rao, McNamee, Dredze, 2013</marker>
<rawString>Delip Rao, Paul McNamee, and Mark Dredze. 2013. Entity linking: Finding extracted entities in a knowledge base. In Multi-source, Multilingual Information Extraction and Summarization, pages 93–115. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Sven Ristad</author>
<author>Peter N Yianilos</author>
</authors>
<title>Learning string-edit distance.</title>
<date>1998</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="5216" citStr="Ristad and Yianilos, 1998" startWordPosition="804" endWordPosition="807">ic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have simply employed a static edit distance module to decide whether two names can be matched (Chen et al., 2010; Cassidy et al., 2011; Martschat et al., 2012). An exception is work on training finite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et al., 2008; Dreyer et al., 2008; Cotterell et al., 2014). More recently, Andrews et al. (2012) presented a phylogenetic model of string variation using transducers that applies to pairs of names string (supervised) and unpaired collections (unsupervised). Beyond name matching in a single language, several papers have considered cross lingual name matching, where name strings are drawn from two different languages, such as matching Arabic names (El-Shishtawy, 2013) with English (Freeman et al., 2006; Green et al., 2012). Additionally, name matching has been used as a compone</context>
<context position="10459" citStr="Ristad and Yianilos, 1998" startWordPosition="1601" endWordPosition="1604">n initial and a final segment. Therefore, we split each pinyin token further into the initial and final segment. We call this “segmented-pinyin”5. Transducers We next consider methods that can be trained on available Chinese name pairs. Transducers are common choices for learning edit dis4Hong Kong has a romanization scheme more suitable for Cantonese, but we found no improvements over using pinyin. Therefore, for simplicity we use pinyin throughout. 5For example, the pinyin for 4K is segmented into / zh / and / ang /. tance metrics for strings, and they perform better than string similarity (Ristad and Yianilos, 1998; Andrews et al., 2012; Cotterell et al., 2014). We use the probabilistic transducer of Cotterell et al. (2014) to learn a stochastic edit distance. The model represent the conditional probability p(ylx; 0), where y is a generated string based on editing x according to parameters 0. At each position xi, one of four actions (copy, substitute, insert, delete) are taken to generate character yj. The probability of each action depends on the string to the left of xi (x(i_N1):i), the string to the right of xi (xi:(i+N2)), and generated string to the left of yj (y(j_N3):j). The variables N1, N2, N3 </context>
</contexts>
<marker>Ristad, Yianilos, 1998</marker>
<rawString>Eric Sven Ristad and Peter N Yianilos. 1998. Learning string-edit distance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(5):522–532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational linguistics,</journal>
<pages>27--4</pages>
<contexts>
<context position="2818" citStr="Soon et al., 2001" startWordPosition="430" endWordPosition="433">ting, despite downstream tasks in Chinese that rely on name matching (Chen et al., 2010; Cassidy et al., 2011). Martschat et al. (2012) point out errors in coreference resolution due to Chinese name matching errors, which suggests that downstream tasks can benefit from improvements in Chinese name matching techniques. This paper presents an analysis of new and existing approaches to name matching in Chinese. The goal is to determine whether two Chinese strings can refer to the same entity (person, organization, location) based on the strings alone. The more general task of entity coreference (Soon et al., 2001), or entity clustering, includes the context of the mentions in determining coreference. In contrast, standalone name matching modules are context independent (Andrews et al., 2012; Green et al., 2012). In addition to showing name matching improvements on newly developed datasets of matched Chinese name pairs, we show improvements in a downstream Chinese entity clustering task by using our improved name matching system. We call our name matching tool Mingpipe, a Python package that can be used as a standalone tool or integrated within a larger system. We release Mingpipe as well as several dat</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Stefan Rapp</author>
<author>Christoph M¨uller</author>
</authors>
<title>The influence of minimum edit distance on reference resolution.</title>
<date>2002</date>
<booktitle>In Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>312--319</pages>
<marker>Strube, Rapp, M¨uller, 2002</marker>
<rawString>Michael Strube, Stefan Rapp, and Christoph M¨uller. 2002. The influence of minimum edit distance on reference resolution. In Empirical Methods in Natural Language Processing (EMNLP), pages 312–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Sukharev</author>
<author>Leonid Zhukov</author>
<author>Alexandrin Popescul</author>
</authors>
<title>Learning alternative name spellings. arXiv preprint arXiv:1405.2048.</title>
<date>2014</date>
<contexts>
<context position="4637" citStr="Sukharev et al., 2014" startWordPosition="706" endWordPosition="709"> three major categories: 1) Phonetic matching methods, e.g. Soundex (Holmes and McCabe, 2002), double Metaphone (Philips, 2000) etc.; 2) Edit-distance based measures, e.g. Levenshtein distance (Levenshtein, 1966), JaroWinkler (Porter et al., 1997; Winkler, 1999), and 3) Token-based similarity, e.g. soft TF-IDF (Bilenko et al., 2003). Analyses comparing these approaches have not found consistent improvements of one method over another (Cohen et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a major focus within the NLP community. Most downstream NLP systems have simply employed a static edit distance module to decide whether two names can be matched (Chen et al., 2010; Cassidy et al., 2011; Martschat et al., 2012). An exception is work on training finite state transducers for edit distance metrics (Ristad and Yianilos, 1998; Bouchard-Cˆot´e et </context>
</contexts>
<marker>Sukharev, Zhukov, Popescul, 2014</marker>
<rawString>Jeffrey Sukharev, Leonid Zhukov, and Alexandrin Popescul. 2014. Learning alternative name spellings. arXiv preprint arXiv:1405.2048.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William E Winkler</author>
</authors>
<title>The state of record linkage and current research problems.</title>
<date>1999</date>
<booktitle>In Statistical Research Division, US Census Bureau.</booktitle>
<contexts>
<context position="4278" citStr="Winkler, 1999" startWordPosition="652" endWordPosition="653">/mingpipe 377 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 377–383, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics on string matching techniques. This work can be organized into three major categories: 1) Phonetic matching methods, e.g. Soundex (Holmes and McCabe, 2002), double Metaphone (Philips, 2000) etc.; 2) Edit-distance based measures, e.g. Levenshtein distance (Levenshtein, 1966), JaroWinkler (Porter et al., 1997; Winkler, 1999), and 3) Token-based similarity, e.g. soft TF-IDF (Bilenko et al., 2003). Analyses comparing these approaches have not found consistent improvements of one method over another (Cohen et al., 2003; Christen, 2006). More recent work has focused on learning a string matching model on name pairs, such as probabilistic noisy channel models (Sukharev et al., 2014; Bilenko et al., 2003). The advantage of trained models is that, with sufficient training data, they can be tuned for specific tasks. While many NLP tasks rely on name matching, research on name matching techniques themselves has not been a</context>
</contexts>
<marker>Winkler, 1999</marker>
<rawString>William E Winkler. 1999. The state of record linkage and current research problems. In Statistical Research Division, US Census Bureau.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Zhang</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
<author>Wen Ting Wang</author>
</authors>
<title>Entity linking leveraging: Automatically generated annotation.</title>
<date>2010</date>
<booktitle>In International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1290--1298</pages>
<contexts>
<context position="11680" citStr="Zhang et al., 2010" startWordPosition="1799" endWordPosition="1802"> the context size. Note that characters to the right of yj are excluded as they are not yet generated. Training maximizes the observed data log-likelihood and EM is used to marginalize over the latent edit actions. Since the large number of Chinese characters make parameter estimation prohibitive, we only train transducers on the three pinyin representations: stringpinyin (28 characters), character-pinyin (384 characters), segmented-pinyin (59 characters). Name Matching as Classification An alternate learning formulation considers name matching as a classification task (Mayfield et al., 2009; Zhang et al., 2010; Green et al., 2012). Each string pair is an instance: a positive classification means that two strings can refer to the same name. This allows for arbitrary and global features of the two strings. We use an SVM with a linear kernel. To learn possible edit rules for Chinese names we add features for pairs of n-grams. For each string, we extract all n-grams (n=1,2,3) and align n-grams between strings using the Hungarian algorithm.6 Features correspond to the aligned ngram pairs, as well as the unaligned n-grams. To reduce the number of parameters, we only include features which appear in posit</context>
</contexts>
<marker>Zhang, Su, Tan, Wang, 2010</marker>
<rawString>Wei Zhang, Jian Su, Chew Lim Tan, and Wen Ting Wang. 2010. Entity linking leveraging: Automatically generated annotation. In International Conference on Computational Linguistics (COLING), pages 1290–1298.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>