<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011107">
<title confidence="0.9960125">
Introduction to CKIP Chinese Word Segmentation System for the First
International Chinese Word Segmentation Bakeoff
</title>
<author confidence="0.995866">
Wei-Yun Ma Keh-Jiann Chen
</author>
<affiliation confidence="0.816752">
Institute of Information science, Institute of Information science,
Academia Sinica Academia Sinica
</affiliation>
<email confidence="0.996881">
ma@iis.sinica.edu.tw kchen@iis.sinica.edu.tw
</email>
<sectionHeader confidence="0.995607" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999957230769231">
In this paper, we roughly described the
procedures of our segmentation system,
including the methods for resolving seg-
mentation ambiguities and identifying un-
known words. The CKIP group of
Academia Sinica participated in testing on
open and closed tracks of Beijing Univer-
sity (PK) and Hong Kong Cityu (HK).
The evaluation results show our system
performs very well in either HK open
track or HK closed track and just accept-
able in PK tracks. Some explanations and
analysis are presented in this paper.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999947739130435">
At the first international Chinese Word
Segmentation Bakeoff, Academia Sinica
participated in testing on open and closed tracks of
Beijing University (PK) and Hong Kong Cityu
(HK). The same segmentation algorithm was
applied to process these two corpora, except that
character code conversion from GB to BIG5 for
PK corpus and few modifications due to different
segmentation standards had been made. The
difference between open and closed tracks is that
while processing the open track, besides of the
lexicon trained from the specific corpus, we also
consulted the Academia Sinica lexicon to enhance
the word collection.
It is well known that there are two major
difficulties in Chinese word segmentation. One is
resolving the ambiguous segmentation, and the
other is identifying unknown words.
Our earlier work mainly focused on the
resolving of segmentation ambiguities and using
regular expressions to handle the determinant-
measure and reduplication compounds (Chen &amp;
Liu 1992, Chen 1999). We adopt a variation of the
longest matching algorithm with several heuristic
rules to resolve the ambiguities and achieve
99.77% of the success rate without counting the
mistakes occurred due to the existence of unknown
words. After that, we were paying more attention
on the problems of extracting and identifying
unknown words (Chen et.al 1997, Chen &amp; Bai
1998, Chen &amp; Ma 2002, Tseng &amp; Chen 2002, Ma
&amp; Chen 2003). The process of unknown word
extraction could be roughly divided into two steps,
i.e. detection process and extraction process. The
detection process detects possible occurrences of
unknown words (Chen &amp; Bai 1998), so that deeper
morphological analysis is carried out only at the
places where unknown word morphemes were
detected (Chen &amp; Ma 2002). A bottom-up merging
algorithm was proposed in (Ma &amp; Chen 2003),
which utilizes hybrid statistical and linguistic
information to extract unknown words effectively.
In addition to the bakeoff results evaluated by
SIGHAN, we also present some other relevant
experiment results and provide analysis on the
system performance in the following sections.
</bodyText>
<sectionHeader confidence="0.957791" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.975916756756756">
Figure 1 illustrates the block diagram of our
segmentation system used in this contest. The first
two steps of word segmentation algorithm are
word matching and resolution for ambiguous
matches. These two processes were performed in
parallel. The algorithm reads the input sentences
from left to right and matches the input character
string with lexemes. In (Chen &amp; Liu 1992), if an
ambiguous segmentation does occur, the matching
algorithm looks ahead two more words, and the
disambiguation rules for those three word chunks
is applied afterward. For instance, in (1), the first
matched word could be &apos; &apos; or &apos; &apos;. Then the
algorithm will look ahead to take all of the possible
combinations of three word chunks, as shown in
(2), into consideration.
The disambiguation algorithm will select the
first word of the most plausible chunks as the
solution according to heuristic rules. The first
heuristic rule is:
Longest Matching Rule: The most plausible seg-
mentation is the three word sequence with the
longest length.
In the above example, the longest matched
three-word chunk is (1). Therefore the first seg-
mented word is &apos; &apos;. This heuristic rules
achieves as high as 99.69% accuracy and a high
applicability of 93.21%, i.e. the 93.21% of the am-
biguities were resolved by this rule. However there
are still about 6.79% of ambiguities, i.e. the three
word chunks with the same length but with differ-
ent segmentations, which cannot be resolved by the
maximal matching rule. The following heuristic
rules were used for further resolution.
Word Length Rule: Pick the three-word chunk
that has the smallest standard deviation in length of
the three words.
</bodyText>
<subsectionHeader confidence="0.695651">
Morphemic Rules:
</subsectionHeader>
<bodyText confidence="0.780527666666667">
(a). Pick the chunk with fewer bound morphemes.
(b). Pick the chunk with fewer characters in com-
pound words.
</bodyText>
<subsectionHeader confidence="0.48562">
Probability Rule:
</subsectionHeader>
<bodyText confidence="0.934086176470588">
(a). Pick the chunk with the high frequency mono-
syllabic words.
(b). Pick the chunk with the highest probability
value.
After disambiguation process, an input sentence
is segmented into a word sequence. Then for the
needs of the following unknown word extraction, a
Pos bi-gram tagging model is applied to tag Pos of
words.
It is clear that unknown words in the input text
will be segmented into several adjacent tokens
(known words or monosyllabic morphemes). Then
at unknown word detection stage, every
monosyllable is decided whether it is a word or an
unknown word morpheme by a set of syntactic
discriminators, which are trained from a word
segmented corpus.
</bodyText>
<figureCaption confidence="0.999457">
Figure 1. Flowchart of the system
</figureCaption>
<figure confidence="0.9948044">
(1)
complete authenticate report
&amp;quot;complete the report about authenticating&amp;quot;
(2)
(3)
</figure>
<bodyText confidence="0.88304125">
if can increase gross profit rate
&amp;quot;if gross profit rate can be increased...&amp;quot;
(4) after first step word segmentation:
For example, the correct segmentation of (3) is
shown, but the unknown word ” ” is
segmented into three monosyllabic words after the
first step of word segmentation process. In (4), The
unknown word detection process will mark the
sentence as “ () ()
where (?) denotes the detected monosyllabic
unknown word morpheme and () denotes common
words. During extracting process, the rule
matching process focuses on the morphemes
marked with (?) only and tries to combine them
with left/right neighbors according to the rules for
unknown words. After that the unknown word “
” is extracted.
We adopt a bottom-up merging algorithm (Ma &amp;
Chen 2003), which utilizes hybrid statistical and
linguistic information, to extract unknown words.
</bodyText>
<sectionHeader confidence="0.999572" genericHeader="method">
3 Adaptation for Different Tracks
</sectionHeader>
<bodyText confidence="0.99959776">
It is known that different segmentation standards
could affect the performance of segmentation
significantly. In this contest, due to limited
preparing time, we mainly focused on adjusting the
regular expressions for determinant-measure
compounds according to the HK and PK
segmentation standards.
While processing the PK track, a shortcut
method of converting GB codes to BIG5 codes was
adopted to cope with the problem of character
coding difference. Instead of re-design or re-
implement the GB segmentation system, we
convert the codes of training and testing PK
corpora into BIG5 versions and perform the
segmentation under the BIG5 environment. The
segmented results are then translated back to GB
code as the final outputs. In contrast, processing of
HK corpus is easier for us, because our system was
designed for the BIG5 environment.
As for the lexicons, for closed test, both PK and
HK lexicons are derived from the word sets of
each respective training corpus. For the open test,
each lexicon was enhanced by adding the lexical
entries in the CKIP lexicon. The sizes of lexicons
are shown in table1.
</bodyText>
<table confidence="0.9907834">
HK PK
# of lexical entries (HK/PK)for 22K 50K
closed test
# of lexical entries (HK/PK join 140K 156
CKIP) for open test K
</table>
<tableCaption confidence="0.9866475">
Note: # lexicon of (CKIP) is 133K
Table 1. The sizes of lexicons
</tableCaption>
<bodyText confidence="0.999733875">
Syntactic categories of a words were utilized in
unknown word detection and extraction processes.
We don’t have syntactic categories for words
which are not in the CKIP lexicon. Therefore, we
(Chen et.al 1997, Tseng &amp; Chen 2002) use
association strength between morphemes and
syntactic categories to predict the category of a
new word. The accuracy rate is about 80%.
</bodyText>
<sectionHeader confidence="0.984035" genericHeader="evaluation">
4 Evaluation Results
</sectionHeader>
<bodyText confidence="0.999854625">
There are several evaluation indexes provided
by SIGHAN, i.e. test recall (R), test precision (P),
F score2, the out-of-vocabulary (OOV) rate for the
test corpus, the recall on OOV words (Roov), and
the recall on in-vocabulary (Riv) words.
Tables 2 shows the evaluation results of our sys-
tem in HK closed and open tracks. For both tracks,
our system achieved the top ranks on F scores.
</bodyText>
<note confidence="0.603586">
Note: The word count of testing corpus is 34955
</note>
<tableCaption confidence="0.958138">
Table 2. Scores for HK
</tableCaption>
<bodyText confidence="0.998885">
The evaluations of our system in PK closed and
open tracks are shown in table 3. For PK closed
track, our system ranks 6th among 10 systems. And
for PK open track, our system ranks 3rd among 8
systems.
</bodyText>
<table confidence="0.879913363636364">
after unknown word detection:
(?) (?) (?)
after unknown word extraction:
() (?) (?) (?)”,
R P F OOV Roov Riv
Closed 0.947 0.934 0.940 0.071 0.625 0.972
Open 0.958 0.954 0.956 0.071 0.788 0.971
R P F OOV Roov Riv
Closed 0.939 0.934 0.936 0.069 0.642 0.961
Open 0.939 0.938 0.938 0.069 0.675 0.959
Note: The word count of testing corpus is 34955
</table>
<tableCaption confidence="0.964804">
Table 3. Scores for PK
</tableCaption>
<bodyText confidence="0.9962345">
Because Academia Sinica corpora (AS) are
provided by us, we are not allowed to participate
any AS track at this contest. Therefore, in this
report, we still show the performance of our
system evaluating AS closed track in table 4. Our
system would have the top rank if the result was
compared with the other 6 participants of AS
closed track.
</bodyText>
<table confidence="0.980988333333333">
R P F OOV Roov Riv
0.968 0.966 0.967 0.022 0.657 0.975
Note: The word count of testing corpus is 11985
</table>
<tableCaption confidence="0.98976">
Table 4. Scores for AS closed
</tableCaption>
<sectionHeader confidence="0.98524" genericHeader="conclusions">
5 Discussions and Conclusions
</sectionHeader>
<bodyText confidence="0.999957828571429">
The evaluation results show that our system
performs very well in either HK closed track or
HK open track. We think the key to the success is
our unknown word extraction performs better than
other participants. This could be observed by the
results of HK closed track, the 2th and 3th system,
which have better performance in Riv but worse
Roov than our system, performs worse than our
system in f score. Furthermore to have better
performance, high precision for unknown word
extraction is necessary, since one identification
error may cause at least two segmentation errors.
The performance in PK tracks are not as well as
HK. An important reason is that coding
conversion may cause errors. For instance, in the
conversion of the GB code of “ ” (the capital
of Brazil) to its BIG5 codes, Since GB code to
BIG5 conversion is a one-to-many mapping, the
above example is wrongly converted to “ ”.
This kind of errors do affect accuracy of the
segmentation significantly, especially for the
unkown word processes. To solve this problem, we
think the best and direct solution is to re-
implement the GB segmentation version without
any code conversion.
Variation on the word segmentation standards is
another reason of causing segmentation errors.
Some of the standards were even not available to
the public. It is better to propose a uniform word
segmentation standard in the future.
Regarding evaluation index, we suggest that an
error type of crossing error should be take into
consideration, since noncrossing errors are more or
less related to segmentation standards and crossing
errors are more severe.
</bodyText>
<sectionHeader confidence="0.999727" genericHeader="references">
6 References
</sectionHeader>
<reference confidence="0.99998372">
[1] Chen, K.J. &amp; S.H. Liu, 1992,&amp;quot;Word Identification
for Mandarin Chinese Sentences,&amp;quot; Proceedings of
14th Coling, pp. 101-107
[2] Chen, C. J., M.H. Bai, &amp; K.J. Chen, 1997,” Cate-
gory Guessing for Chinese Unknown Words,” Pro-
ceedings of the Natural Language Processing
Pacific Rim Symposium, 35-40, Thailand.
[3] Chen, K.J. &amp; Ming-Hong Bai, 1998, “Unknown
Word Detection for Chinese by a Corpus-based
Learning Method,” international Journal of Com-
putational linguistics and Chinese Language
Processing, Vol.3, #1, pp.27-44
[4] Chen, Keh-jiann,1999,”Lexical Analysis for Chi-
nese- Difficulties and Possible Solutions”, Journal
of Chinese Institute of Engineers, Vol. 22. #5, pp.
561-571.
[5] Chen, K.J. &amp; Wei-Yun Ma, 2002. Unknown Word
Extraction for Chinese Documents. In Proceedings
of COLING 2002, pages 169-175
[6] Tseng, H.H. &amp; K.J. Chen, 2002. Design of Chinese
Morphological Analyzer. In Proceedings of
SIGHAN, pages 49-55
[7] Ma Wei-Yun &amp; K.J. Chen, 2003. A bottom-up
Merging Algorithm for Chinese Unknown Word
Extraction. In Proceedings of SIGHAN
</reference>
</variant>
</algorithm>

<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K J Chen</author>
<author>S H Liu</author>
</authors>
<title>Identification for Mandarin Chinese Sentences,&amp;quot;</title>
<date>1992</date>
<booktitle>Proceedings of 14th Coling,</booktitle>
<pages>101--107</pages>
<marker>[1]</marker>
<rawString>Chen, K.J. &amp; S.H. Liu, 1992,&amp;quot;Word Identification for Mandarin Chinese Sentences,&amp;quot; Proceedings of 14th Coling, pp. 101-107</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Chen</author>
<author>M H Bai</author>
<author>K J Chen</author>
</authors>
<title>Category Guessing for Chinese Unknown Words,”</title>
<date>1997</date>
<booktitle>Proceedings of the Natural Language Processing Pacific Rim Symposium,</booktitle>
<pages>35--40</pages>
<marker>[2]</marker>
<rawString>Chen, C. J., M.H. Bai, &amp; K.J. Chen, 1997,” Category Guessing for Chinese Unknown Words,” Proceedings of the Natural Language Processing Pacific Rim Symposium, 35-40, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Chen</author>
<author>Ming-Hong Bai</author>
</authors>
<title>Unknown Word Detection for Chinese by a Corpus-based Learning</title>
<date>1998</date>
<booktitle>Method,” international Journal of Computational linguistics and Chinese Language Processing, Vol.3,</booktitle>
<volume>1</volume>
<pages>27--44</pages>
<marker>[3]</marker>
<rawString>Chen, K.J. &amp; Ming-Hong Bai, 1998, “Unknown Word Detection for Chinese by a Corpus-based Learning Method,” international Journal of Computational linguistics and Chinese Language Processing, Vol.3, #1, pp.27-44</rawString>
</citation>
<citation valid="false">
<authors>
<author>Chen</author>
</authors>
<title>Keh-jiann,1999,”Lexical Analysis for Chinese- Difficulties and Possible Solutions”,</title>
<journal>Journal of Chinese Institute of Engineers,</journal>
<volume>22</volume>
<pages>561--571</pages>
<marker>[4]</marker>
<rawString>Chen, Keh-jiann,1999,”Lexical Analysis for Chinese- Difficulties and Possible Solutions”, Journal of Chinese Institute of Engineers, Vol. 22. #5, pp. 561-571.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Chen</author>
<author>Wei-Yun Ma</author>
</authors>
<title>Unknown Word Extraction for Chinese Documents.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>169--175</pages>
<marker>[5]</marker>
<rawString>Chen, K.J. &amp; Wei-Yun Ma, 2002. Unknown Word Extraction for Chinese Documents. In Proceedings of COLING 2002, pages 169-175</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Tseng</author>
<author>K J Chen</author>
</authors>
<title>Design of Chinese Morphological Analyzer.</title>
<date>2002</date>
<booktitle>In Proceedings of SIGHAN,</booktitle>
<pages>49--55</pages>
<marker>[6]</marker>
<rawString>Tseng, H.H. &amp; K.J. Chen, 2002. Design of Chinese Morphological Analyzer. In Proceedings of SIGHAN, pages 49-55</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ma Wei-Yun</author>
<author>K J Chen</author>
</authors>
<title>A bottom-up Merging Algorithm for Chinese Unknown Word Extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of SIGHAN</booktitle>
<marker>[7]</marker>
<rawString>Ma Wei-Yun &amp; K.J. Chen, 2003. A bottom-up Merging Algorithm for Chinese Unknown Word Extraction. In Proceedings of SIGHAN</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>