<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005043">
<title confidence="0.9988725">
Annotating text using the Linguistic Description Scheme of MPEG-7:
The DIRECT-INFO Scenario
</title>
<author confidence="0.986047">
Thierry Declerck, Stephan Busemann
</author>
<affiliation confidence="0.85694">
Language Technology Lab
DFKI GmbH
</affiliation>
<address confidence="0.581639">
Saarbrücken, Germany
</address>
<email confidence="0.998148">
{declerck|busemann}@dfki.de
</email>
<author confidence="0.972645">
Herwig Rehatschek, Gert Kienast
</author>
<affiliation confidence="0.972516">
Institute for Information Systems &amp;
</affiliation>
<address confidence="0.570114666666667">
Information Management,
JRS GmbH
Graz, Austria
</address>
<email confidence="0.998825">
{rehatschek|kienast}@joanneum.at
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999677666666667">
We describe the way we adapted a text
analysis tool for annotating with the Lin-
guistic Description Scheme of MPEG-7
text related to and extracted from multi-
media content. Practically applied in the
DIRECT-INFO EC R&amp;D project we
show how such linguistic annotation con-
tributes to semantic annotation of multi-
modal analysis systems, demonstrating
also the use of the XML schema of
MPEG-7 for supporting cross-media se-
mantic content annotation.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989393259259259">
In the R&amp;D project DIRECT-INFO the concrete
business case of sponsorship tracking was tar-
geted. The scenario investigated within the pro-
ject was that sponsors want to know how often
their brands are mentioned in connection with
the sponsored company. The visual detection of a
brand (e.g. in videos) is not sufficient to meet the
requirements of this business case. Multimodal
analysis and fusion – as implemented within DI-
RECT-INFO – is needed in order to fulfill these
requirements (Rehatschek, 2004).
Within this context text analysis has been ap-
plied to documents reporting on entities, like
football teams, that have close relations to large
sponsoring companies. In the text analysis com-
ponent of the system we had to detect if an entity
was mentioned positively, negatively or neu-
trally. Besides all the processing and annotation
issues to positive or negative mentions, we had
to make our results available to a global MPEG-7
document, which is encoding the annotation re-
sults of various analysis of the modalities in-
volved (logo detection, speech recognition, text
analysis etc.). This global MPEG-7 document
was the input for a fusion component.
In the next sections we describe the Text
Analysis (TA) component of DIRECT-INFO.
We then briefly describe the linguistic descrip-
tion scheme (LDS) of MPEG-7 and show the
annotation generated by the TA. Finally we
briefly discuss the role the LDS, and generally
speaking MPEG-7, can play in supporting an
interoperable cross-media annotation strategy. It
seems to us, that LDS is offering a good mean
for adding semantic metadata to image/video, but
not for a real semantic integration of text and
media content annotation, which in the case of
DIRECT-INFO was performed by an additional
fusion component.
2 The detection of positive/negative
mentioning
Our work in DIRECT-INFO has been dedicated
in enhancing an already existing tool for linguis-
tic annotation. This tool, called SCHUG (Shal-
low and CHunk-based Unification Grammar
tool), is annotating texts considering both lin-
guistic constituency and dependency structures
(T. Declerck, M. Vela 2005).
A first development step was dedicated in cre-
ating specialized lexicons for various types of
lexical categories (like nouns, adjectives and
verbs) that can bear the property of being intrin-
sically positive or negative in a specific domain,
as can be seen just below in the case of soccer:
</bodyText>
<equation confidence="0.964843">
command =&gt; {POS =&gt; Noun, INT =&gt; &amp;quot;positive&amp;quot;}
dominate =&gt; {POS =&gt; Verb, INT =&gt; &amp;quot;positive&amp;quot;}
weak =&gt; {POS =&gt; Adj, INT =&gt; &amp;quot;negative&amp;quot;}
</equation>
<bodyText confidence="0.9610935">
Considering a sentence like “ManU takes the
command in the game against the weak Spanish
</bodyText>
<page confidence="0.997872">
53
</page>
<bodyText confidence="0.999992111111111">
team”, the head-noun of the direct object (lin-
guistically speaking) “the command” gets from
the access to the specialized DIRECT-INFO
lexicon a tag “INTERPRETATION” with value
“positive”. Whereas the adjective “weak” in the
PP-adjunct “in the game against the weak Span-
ish team” gets an “INTERPRETATION” tag
with value “negative”.
Once the words in the sentence have been
lexically tagged with respect to their interpreta-
tion, the computing of the pos./neg. interpreta-
tion at the level of linguistic fragments and then
at the level of the sentences can start. For this we
have defined heuristics along the lines of the de-
pendency structures delivered by the linguistic
analysis. So in the case of the NP “the weak
Spanish team”, the head noun “team”, as such a
neutral expression, is getting the “INTERPRE-
TATION” tag with the value “negative”, since it
is modified by a “negative” adjective. In case the
reference resolution algorithm of the linguistic
tools has been able to specify that the “Spanish
team” is in fact “Real Madrid” this entity gets a
negative “INTERPRETATION” tag.
The head noun of the NP realizing the subject
of the sentence, “ManU” gets a positive mention
tag, since it is the subject of a positive verb and
direct object combination (the NP “the com-
mand” having a positive reading, whereas the
verb “takes” has a neutral reading).
A last aspect to be mentioned here concerns
the treatment of the so-called polarity items.
Specific words in natural language intrinsically
carry a negation or position force (or scope). So
the words not, none or no have an intrinsic nega-
tion force and negate the words and fragments in
the context in which those specific words are
occurring. The context that is negated by such
words can be also called the “scope” (or the
range) of the negation. Consider for example the
sentence: “I would definitely pay £15 million to
get Owen, not even a decent striker, instead...”
Our tools are able to detect that the NP “decent
striker” is negated, and therefore the positive
reading of “decent striker” is being ruled out.
</bodyText>
<sectionHeader confidence="0.990539" genericHeader="method">
3 Metadata Description
</sectionHeader>
<bodyText confidence="0.999982571428571">
The different content analysis modules of the
DIRECT-INFO system extract different types of
metadata, ranging from low-level audiovisual
feature descriptions to semantic metadata. The
global metadata description must be rich and has
to clearly interrelate the various analysis results,
as it is the input of the fusion component.
</bodyText>
<subsectionHeader confidence="0.99533">
4.1 Using MPEG-7 for Detailed Description of
Audiovisual Content
</subsectionHeader>
<bodyText confidence="0.99968008">
In DIRECT-INFO the MPEG-7 standard is used
for metadata description. It is an excellent choice
for describing audiovisual content because of its
comprehensiveness and flexibility. The compre-
hensiveness results from the fact that the stan-
dard has been designed for a broad range of ap-
plications and thus employs very general and
widely applicable concepts. The standard con-
tains a large set of tools for diverse types of an-
notations on different semantic levels. The flexi-
bility of MPEG-7, which is provided by a high
level of generality, makes it usable for a broad
application area without imposing strict con-
straints on the metadata models of these applica-
tions. The flexibility is very much based on the
structuring tools and allows the description to be
modular and on different levels of abstraction.
MPEG-7 supports fine grained description, and it
is possible to attach descriptors to arbitrary seg-
ments on any level of detail of the description.
Among the descriptive tools developed within
the MPEG-7 framework, one is concerned with
the use of natural language for adding metadata
to the content description of image and video: the
so-called Linguistic Description Scheme (LDS).
</bodyText>
<subsectionHeader confidence="0.962398">
4.2 MPEG-7: The Linguistic Description
Scheme (LDS)
</subsectionHeader>
<bodyText confidence="0.862322466666667">
MPEG-7 foresees four kinds of textual annota-
tion that can be attached as metadata to some
audio-video content. The natural language ex-
pression used here is “Spain scores a goal against
Sweden. The scoring player is Morientes”.
Free Text Annotation: Here only tags are put
around the text:
&lt;TextAnnotation&gt;
&lt;FreeTextAnnotation xml:lang=&amp;quot;en&amp;quot;&gt;
Spain scores a goal against Sweden.
The scoring player is Morientes.
&lt;/FreeTextAnnotation&gt;
&lt;/TextAnnotation&gt;
Key Word Annotation: Key Words are ex-
tracted from text and correspondingly annotated:
</bodyText>
<figure confidence="0.993311266666667">
&lt;TextAnnotation&gt;
&lt;KeywordAnnotation&gt;
&lt;Keyword&gt;score&lt;/Keyword&gt;
&lt;Keyword&gt;Sweden&lt;/Keyword&gt;
&lt;Keyword&gt;Spain&lt;/Keyword&gt;
&lt;Keyword&gt;Morientes&lt;/Keyword&gt;
&lt;/KeywordAnnotation&gt;
&lt;/TextAnnotation&gt;
54
Structured Annotation: Question/Answering
like semantics is associated to the text:
&lt;TextAnnotation&gt;
&lt;StructuredAnnotation&gt;
&lt;Who&gt;&lt;Name&gt;Spain&lt;/Name&gt;&lt;/Who&gt;
&lt;WhatAction&gt;&lt;Name&gt;score
goal&lt;/Name&gt;&lt;/WhatAction&gt;
&lt;Where&gt;&lt;Name&gt;A Coruña,
Spain&lt;/Name&gt;&lt;/Where&gt;
&lt;When&gt;&lt;Name&gt;March 25,
1998&lt;Name&gt;&lt;/When&gt;
&lt;/StructuredAnnotation&gt;
&lt;/TextAnnotation&gt;
Dependency Structure: Here the full linguis-
tic apparatus is used for annotating the text:
&lt;TextAnnotation&gt;
&lt;DependencyStructure&gt;
&lt;Sentence&gt;
&lt;Phrase operator=&amp;quot;subject&amp;quot;&gt;
&lt;Head type=&amp;quot;noun&amp;quot;&gt;Spain&lt;/Head&gt;
&lt;/Phrase&gt;
&lt;Head type=&amp;quot;verb&amp;quot; base-
Form=&amp;quot;score&amp;quot;&gt;scored&lt;/Head&gt;
&lt;Phrase operator=&amp;quot;object&amp;quot;&gt;
&lt;Head type=&amp;quot;article noun&amp;quot;&gt;a
goal&lt;/Head&gt;
&lt;/Phrase&gt;
&lt;Phrase&gt;
&lt;Head
type=&amp;quot;preposition&amp;quot;&gt;against&lt;/Head&gt;
&lt;Phrase&gt;
&lt;Head&gt;Sweden&lt;/Head&gt;&lt;/Phrase&gt;
&lt;/Phrase&gt;
&lt;/Sentence&gt;
&lt;/DependencyStructure&gt;
&lt;/TextAnnotation&gt;1
</figure>
<sectionHeader confidence="0.353554" genericHeader="method">
4 MPEG-7 Format of the Text Analysis
component in DIRECT-INFO
</sectionHeader>
<bodyText confidence="0.989480933333333">
On the base of the linguistic analysis of our de-
pendency parser, we generate the “structured
annotation” of the MPEG-7 Linguistic Descrip-
tion Scheme. We think that this kind of annota-
tion is the most practical of LDS for adding se-
mantics to multimedia content, since it is proba-
bly more intuitive for the media expert as the
underlying linguistic dependency structure. At
the same time it seems also straightforward to
go first for a (internal) dependency analysis,
since it is then relatively easy to map automati-
cally dependency units to the “Who”, “WhatAc-
tion” and other tags of LDS.
The MPEG-7 output of the TA module of DI-
RECT-INFO looks like:
</bodyText>
<figure confidence="0.99845421875">
&lt;MediaInformation&gt;
&lt;MediaProfile&gt;
&lt;MediaFormat&gt;
&lt;Content href=&amp;quot;http://www.direct-
info.net/mpeg7/cs/ContentCS.2004.xml/di.
content.writtenText&amp;quot;&gt;
&lt;Name&gt;Written text&lt;/Name&gt;
1 These examples are taken from a former and excellent
online tutorial on MPEG-7 by Philippe Salembier.
&lt;/Content&gt;
&lt;/MediaFormat&gt;
&lt;MediaInstance&gt;
&lt;InstanceIdentifier/&gt;
&lt;MediaLocator&gt;
&lt;!-- essence id--&gt;
&lt;MediaUri&gt;5543&lt;/MediaUri&gt;
&lt;/MediaLocator&gt;
&lt;/MediaInstance&gt;
&lt;/MediaProfile&gt;
&lt;/MediaInformation&gt;
&lt;StructuralUnit href=&amp;quot;http://www.direct-
info.net/mpeg7/cs/StructuralUnitCS.2004.
xml/di.vis.pdf&amp;quot;&gt;
&lt;Name&gt;PDF&lt;/Name&gt;
&lt;/StructuralUnit&gt;
&lt;!-- more than one page can be stored
within a file --&gt;
&lt;SpatialDecomposition criteria=&amp;quot;Page&amp;quot;&gt;
&lt;StillRegion id=&amp;quot;TA_PAGE1&amp;quot;&gt;
&lt;StructuralUnit
href=&amp;quot;http://www.direct-
info.net/mpeg7/cs/StructuralUnitCS.2004.
xml/di.vis.page&amp;quot;&gt;
&lt;Name&gt;Page&lt;/Name&gt;
&lt;/StructuralUnit&gt;
&lt;SpatialDecomposition crite-
ria=&amp;quot;TextAnalysis&amp;quot; gap=&amp;quot;true&amp;quot; over-
lap=&amp;quot;false&amp;quot;&gt;
&lt;StillRegion&gt;
&lt;StructuralUnit
href=&amp;quot;http://www.direct-
info.net/mpeg7/cs/StructuralUnitCS.2004.
xml/di.vis.textAnal ysisAnnotation&amp;quot;&gt;
&lt;Name&gt;Text analysis annota-
tion&lt;/Name&gt;
&lt;/StructuralUnit&gt;
&lt;TextAnnotation&gt;
&lt;StructuredAnnotation&gt;
&lt;WhatObject
href=&amp;quot;http://www.direct-
info.net/mpeg7/cs/LogoCS.2004.xml/di.ta.
object.juventus&amp;quot;&gt;
&lt;Name
xml:lang=&amp;quot;it&amp;quot;&gt;Juventus&lt;/Name&gt;
&lt;/WhatObject
&lt;WhatAction
href=&amp;quot;http://www.direct-
info.net/mpeg7/cs/TextAnalysisCS.2004.xm
l/di.ta.action.teamMentioned&amp;quot;&gt;
&lt;Name xml:lang=&amp;quot;it&amp;quot;&gt;mentioning of
team&lt;/Name&gt;
&lt;/WhatAction&gt;
&lt;Why&gt;
&lt;Name xml:lang=&amp;quot;it&amp;quot;&gt;
</figure>
<figureCaption confidence="0.8019112">
295 771120 Con DVD Auto da Sogno Porsche
e 10, con calendario ufficiale 2006 Ju-
ventus o Milan&amp;quot; o Inter o Palermo o
Fiorentina o Totti&amp;quot; o Wrestling&amp;quot; e 6, 9
Euro 1, Poste Italiane Sped . in A.P
</figureCaption>
<figure confidence="0.9961499">
&lt;/Name&gt;
&lt;/Why&gt;
&lt;How href=&amp;quot;http://www.direct-
info.net/mpeg7/cs/TextAnalysisCS.2004.xm
l/di.ta.mentioning.neut&amp;quot;&gt;
&lt;Name xml:lang=&amp;quot;it&amp;quot;&gt;neut&lt;/Name&gt;
&lt;/How&gt;
&lt;/StructuredAnnotation&gt;
&lt;/TextAnnotation&gt;
&lt;/StillRegion&gt;
</figure>
<bodyText confidence="0.96709375">
Without going into too much detail here, it is
enough to stress that in the first part of the anno-
tation, the link to the general multimedia and
multimodal repository is ensured. We have to
</bodyText>
<page confidence="0.995179">
55
</page>
<bodyText confidence="0.9999465">
deal with a PDF document that should be proc-
essed by a Text Analysis tool. The “essence” ID
is giving information about the location where
the application relevant data is stored and where
the results of the Text Analysis should be stored.
All this metadata is ensuring the combination of
the results of the analysis of various modalities
dealing with one application relevant dataset (for
example the combination of the logo detection of
a brand and the related positive or negative men-
tioning of a team sponsored by this brand). For
reason of place, we can not show and comment
here the complete (and multimodal) MPEG-7
annotation, but details are given in (G. Kienast,
2005).
The second part of the annotation gives the re-
sults of the combined linguistic and “structured”
analysis we are dealing with. As mentioned
above, in the case of DIRECT-INFO, results of
text analysis are accessed via the structured an-
notation of the Linguistic Description Schema of
MPEG-7.
</bodyText>
<sectionHeader confidence="0.993927" genericHeader="conclusions">
5 Conclusions and future Work
</sectionHeader>
<bodyText confidence="0.999994595238095">
In the DIRECT-INFO project we managed to
include results of text analysis in an automated
fashion into a MPEG-7 description, which was
dealing with the XML representation of the
analysis of various modalities. Using correspond-
ing metadata, it was possible to ensure the en-
coding/annotation of the related results in one
file and to facilitate the access to the separated
annotation using XPath. As such the DIRECT-
INFO MPEG-7 annotation schema is offering a
practicable multi-dimensional annotation
scheme, if we consider a “dimensions” as being
the output of the analysis of various modalities.
MPEG-7 proved to be generic and flexible
enough for combining, saving and accessing
various types of annotation.
Limitations of MPEG-7 were encountered
when the task was about fusion or merging of
information encoded in the various descriptors
(or features), and this task was addressed in a
posterior step, whereas the encoding scheme of
MPEG-7 was not longer helpful, in defining for
example relations between the annotation result-
ing from the different modules or for defining
constraints between those annotation. There
seems to be a need for a higher level of represen-
tation for annotation resulting from the analysis
of distinct media, being low-level features for
images or high-level semantic features for texts.
The need of an “ontologization” of multime-
dia features has been already recognized and pro-
jects are already dealing with this, like AceMe-
dia. Initial work in relating multimodal annota-
tion in DIRECT-INFO will be further developed
in K-Space, a new Network of Excellence, which
goal is to provide for support in semantic infer-
ence for both automatic and semi-automatic an-
notation and retrieval of multimedia content. K-
Space aims at closing the “semantic gap” be-
tween the low-level content descriptions and the
richness and subjectivity of semantics in high-
level human interpretations of audiovisual media.
</bodyText>
<sectionHeader confidence="0.999383" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999898555555556">
The R&amp;D work presented in this paper was par-
tially conducted within the DIRECT-INFO pro-
ject, funded under the 6th Framework Programme
of the European Community within the strategic
objective &amp;quot;Semantic-based knowledge manage-
ment systems&amp;quot; (IST FP6-506898). Actual work
on interoperability of media, language and se-
mantic annotation is being funded by the Net-
work of Excellence K-Space (IST FP6-027026).
</bodyText>
<sectionHeader confidence="0.999105" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999919636363636">
T. Declerck, J. Kuper, H. Saggion, A. Samiotou, P.
Wittenburg, J. Contreras. Contribution of NLP to
the Content Indexing of Multimedia Documents. In
Lecture Notes in Computer Science Volume 3115 / 2004
Pages 610-618,Springer-Verlag Heidelberg, 6 2004.
T. Declerck, M. Vela, “Linguistic Dependencies as a
Basis for the Extraction of Semantic Relations”, in
Proceedings of the ECCB&apos;05 Workshop on Bio-
medical Ontologies and Text Processing, Madrid
(2005)
G. Kienast, A. Horti, András, H. Rehatschek, S.
Busemann, T. Declerck, V. Hahn and R. Cavet.
“DIRECT INFO: A Media Monitoring System for
Sponsorship Tracking.” In Proceedings of the
ACM SIGIR Workshop on Multimedia Information
Retrieval. 2005.
H. Rehatschek: &amp;quot;DIRECT-INFO: Media monitoring
and multimodal analysis for time critical deci-
sions&amp;quot;. Proceedings of the 5th International Work-
shop on Image Analysis for Multimedia Interactive
Services (WIAMIS), ISBN-972-98115-7-1, Lis-
bon, April 2004.
</reference>
<footnote confidence="0.98625675">
AceMedia project: http://www.acemedia.org/aceMedia
DIRECT-INFO project: http://www.direct-info.net/
K-Space project: http://kspace.qmul.net/
MPEG-7: http://www.chiariglione.org/mpeg/
</footnote>
<page confidence="0.996432">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.453144">
<title confidence="0.9059155">Annotating text using the Linguistic Description Scheme of MPEG-7: The DIRECT-INFO Scenario</title>
<author confidence="0.990442">Thierry Declerck</author>
<author confidence="0.990442">Stephan</author>
<affiliation confidence="0.9187835">Language Technology DFKI</affiliation>
<address confidence="0.96536">Saarbrücken, Germany</address>
<email confidence="0.99701">{declerck|busemann}@dfki.de</email>
<author confidence="0.771829">Herwig Rehatschek</author>
<author confidence="0.771829">Gert</author>
<affiliation confidence="0.918186333333333">Institute for Information Systems Information JRS</affiliation>
<address confidence="0.992064">Graz, Austria</address>
<email confidence="0.995717">{rehatschek|kienast}@joanneum.at</email>
<abstract confidence="0.998035230769231">We describe the way we adapted a text analysis tool for annotating with the Linguistic Description Scheme of MPEG-7 text related to and extracted from multimedia content. Practically applied in the DIRECT-INFO EC R&amp;D project we show how such linguistic annotation contributes to semantic annotation of multimodal analysis systems, demonstrating also the use of the XML schema of MPEG-7 for supporting cross-media semantic content annotation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Declerck</author>
<author>J Kuper</author>
<author>H Saggion</author>
<author>A Samiotou</author>
<author>P Wittenburg</author>
<author>J Contreras</author>
</authors>
<title>Contribution of NLP to the Content Indexing of Multimedia Documents.</title>
<date>2004</date>
<booktitle>In Lecture Notes in Computer Science Volume 3115 /</booktitle>
<pages>610--618</pages>
<location>Heidelberg, 6</location>
<marker>Declerck, Kuper, Saggion, Samiotou, Wittenburg, Contreras, 2004</marker>
<rawString>T. Declerck, J. Kuper, H. Saggion, A. Samiotou, P. Wittenburg, J. Contreras. Contribution of NLP to the Content Indexing of Multimedia Documents. In Lecture Notes in Computer Science Volume 3115 / 2004 Pages 610-618,Springer-Verlag Heidelberg, 6 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Declerck</author>
<author>M Vela</author>
</authors>
<title>Linguistic Dependencies as a Basis for the Extraction of Semantic Relations”,</title>
<date>2005</date>
<booktitle>in Proceedings of the ECCB&apos;05 Workshop on Biomedical Ontologies and Text Processing,</booktitle>
<location>Madrid</location>
<marker>Declerck, Vela, 2005</marker>
<rawString>T. Declerck, M. Vela, “Linguistic Dependencies as a Basis for the Extraction of Semantic Relations”, in Proceedings of the ECCB&apos;05 Workshop on Biomedical Ontologies and Text Processing, Madrid (2005)</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kienast</author>
<author>A Horti</author>
<author>H Rehatschek András</author>
<author>S Busemann</author>
<author>T Declerck</author>
<author>V Hahn</author>
<author>R Cavet</author>
</authors>
<title>DIRECT INFO: A Media Monitoring System for Sponsorship Tracking.”</title>
<date>2005</date>
<booktitle>In Proceedings of the ACM SIGIR Workshop on Multimedia Information Retrieval.</booktitle>
<marker>Kienast, Horti, András, Busemann, Declerck, Hahn, Cavet, 2005</marker>
<rawString>G. Kienast, A. Horti, András, H. Rehatschek, S. Busemann, T. Declerck, V. Hahn and R. Cavet. “DIRECT INFO: A Media Monitoring System for Sponsorship Tracking.” In Proceedings of the ACM SIGIR Workshop on Multimedia Information Retrieval. 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Rehatschek</author>
</authors>
<title>DIRECT-INFO: Media monitoring and multimodal analysis for time critical decisions&amp;quot;.</title>
<date>2004</date>
<booktitle>Proceedings of the 5th International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS),</booktitle>
<pages>972--98115</pages>
<location>Lisbon,</location>
<contexts>
<context position="1326" citStr="Rehatschek, 2004" startWordPosition="192" endWordPosition="193">ng also the use of the XML schema of MPEG-7 for supporting cross-media semantic content annotation. 1 Introduction In the R&amp;D project DIRECT-INFO the concrete business case of sponsorship tracking was targeted. The scenario investigated within the project was that sponsors want to know how often their brands are mentioned in connection with the sponsored company. The visual detection of a brand (e.g. in videos) is not sufficient to meet the requirements of this business case. Multimodal analysis and fusion – as implemented within DIRECT-INFO – is needed in order to fulfill these requirements (Rehatschek, 2004). Within this context text analysis has been applied to documents reporting on entities, like football teams, that have close relations to large sponsoring companies. In the text analysis component of the system we had to detect if an entity was mentioned positively, negatively or neutrally. Besides all the processing and annotation issues to positive or negative mentions, we had to make our results available to a global MPEG-7 document, which is encoding the annotation results of various analysis of the modalities involved (logo detection, speech recognition, text analysis etc.). This global </context>
</contexts>
<marker>Rehatschek, 2004</marker>
<rawString>H. Rehatschek: &amp;quot;DIRECT-INFO: Media monitoring and multimodal analysis for time critical decisions&amp;quot;. Proceedings of the 5th International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), ISBN-972-98115-7-1, Lisbon, April 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>