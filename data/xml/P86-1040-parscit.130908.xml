<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.211302">
<title confidence="0.967419">
FORUM ON MACHINE TRANSLATION
Machine Translation will not Work
</title>
<author confidence="0.639183">
Martin Kay
</author>
<note confidence="0.673157">
Xerox Palo Alto Research Center
3333 Coyote Hill Road
Palo Alto, CA 94304
</note>
<sectionHeader confidence="0.917338" genericHeader="abstract">
PANELIST STATEMENT
</sectionHeader>
<bodyText confidence="0.999362">
Large expenditures on fundamental scientific research are
usually limited to the hard sciences. It is therefore entirely
reasonable to suppose that, if large sums of money are spent
on machine translations, it will be with the clear expectation
that what is being purchased is principally development and
engineering, and that the result will contribute substantially
to the solution of some pressing problem.
Anyone who accepts large (or small) sums on this under-
standing is either technically naive or dangerously cynical. It
may certainly be that
</bodyText>
<listItem confidence="0.9848227">
1. machine translation could provide a valuable
framework for fundamental research;
2. texts in highly restricted subsets of natural lan-
guage could be devised for particular puposes and
texts in translated automatically;
3. computers have an important role to fill in
making translations;
4. translations of extremely low quality may be ac-
ceptible on occasions.
However,
1. the fundamental research is so far from ap-
plicability,
2. the language subsets are so restricted,
3. the useful computer technologies are so different
from machine translation,
4. the quality of the translations that can be
produced of natural texts by automatic means is
so low, and
5. the occasions on which those translations could
be useful are so rare,
</listItem>
<bodyText confidence="0.998679433333333">
that the use of the term in these cases can only result in con-
fusion if not deception.
A determined attempt was made to bring machine trans-
lation to the point of usability in the sixties. It has become
fashionable to deride these as &amp;quot;first generation&amp;quot; systems and
to refer to what is being done now as belonging to the second
or third generation. It should surely be possible for those
who think that the newer systems can succeed where the ear-
lier ones failed, to point to problems that have been solved
since the sixties that are so crucial as substantially to change
our assessment of what can be achieved. We know a good
deal more about programming techniques and have larger
machines to work with; we have more elegant theories of
syntax and what modern linguists are pleased to call seman-
tics; and there has been some exploratory work on anaphora.
But, we still have little idea how to translate into a closely
related language like French or German, English sentences
containing such words as &amp;quot;he&amp;quot;, &amp;quot;she&amp;quot;, &amp;quot;it&amp;quot;, &amp;quot;not&amp;quot;, &amp;quot;and&amp;quot;,
and &amp;quot;of&amp;quot;. Furthermore, such work as has been done on these
problems has been studiously ignored by all those currently
involved in developing systems.
Unfortunately, the sums that are being spent on MT in
Europe and Japan are large enough to make virtually in-
evitable the production of a second ALPAC report sometime
in the next few years. This will inevitably have a devastat-
ing effect on the whole field of computational linguistics,
everywhere in the world. The report will be the more devas-
tating for the fact that much of the money has in fact been
spent frivolously, and much of the work has been incom-
petent, even by today&apos;s limited standards.
</bodyText>
<page confidence="0.995555">
268
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.382698">
<title confidence="0.9923005">FORUM ON MACHINE TRANSLATION Machine Translation will not Work</title>
<author confidence="0.999915">Martin Kay</author>
<affiliation confidence="0.997744">Xerox Palo Alto Research Center</affiliation>
<address confidence="0.999471">3333 Coyote Hill Road Palo Alto, CA 94304</address>
<affiliation confidence="0.513759">PANELIST STATEMENT</affiliation>
<abstract confidence="0.998882583333333">Large expenditures on fundamental scientific research are usually limited to the hard sciences. It is therefore entirely reasonable to suppose that, if large sums of money are spent on machine translations, it will be with the clear expectation that what is being purchased is principally development and engineering, and that the result will contribute substantially to the solution of some pressing problem. Anyone who accepts large (or small) sums on this understanding is either technically naive or dangerously cynical. It may certainly be that 1. machine translation could provide a valuable framework for fundamental research; 2. texts in highly restricted subsets of natural language could be devised for particular puposes and texts in translated automatically; 3. computers have an important role to fill in making translations; 4. translations of extremely low quality may be acceptible on occasions. However, 1. the fundamental research is so far from applicability, 2. the language subsets are so restricted, 3. the useful computer technologies are so different from machine translation, 4. the quality of the translations that can be produced of natural texts by automatic means is so low, and 5. the occasions on which those translations could be useful are so rare, that the use of the term in these cases can only result in confusion if not deception. A determined attempt was made to bring machine translation to the point of usability in the sixties. It has become fashionable to deride these as &amp;quot;first generation&amp;quot; systems and to refer to what is being done now as belonging to the second or third generation. It should surely be possible for those who think that the newer systems can succeed where the earlier ones failed, to point to problems that have been solved since the sixties that are so crucial as substantially to change our assessment of what can be achieved. We know a good deal more about programming techniques and have larger machines to work with; we have more elegant theories of syntax and what modern linguists are pleased to call semantics; and there has been some exploratory work on anaphora. But, we still have little idea how to translate into a closely related language like French or German, English sentences containing such words as &amp;quot;he&amp;quot;, &amp;quot;she&amp;quot;, &amp;quot;it&amp;quot;, &amp;quot;not&amp;quot;, &amp;quot;and&amp;quot;, and &amp;quot;of&amp;quot;. Furthermore, such work as has been done on these problems has been studiously ignored by all those currently involved in developing systems. Unfortunately, the sums that are being spent on MT in Europe and Japan are large enough to make virtually inevitable the production of a second ALPAC report sometime in the next few years. This will inevitably have a devastating effect on the whole field of computational linguistics, everywhere in the world. The report will be the more devastating for the fact that much of the money has in fact been spent frivolously, and much of the work has been incomeven today&apos;s limited standards.</abstract>
<intro confidence="0.818543">268</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>