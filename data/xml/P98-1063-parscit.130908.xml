<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000172">
<title confidence="0.9942145">
Combining Stochastic and Rule-Based Methods for Disambiguation
in Agglutinative Languages
</title>
<note confidence="0.955411333333333">
Ezeiza N., Alegria I., Arriola J.M., Urizar R.
Informatika Falcultatea
649 P.K Donostia E-20080
</note>
<email confidence="0.850601">
jibecran@si.ehu.es
http://ixa.si.ehu.es
</email>
<sectionHeader confidence="0.98909" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999537827586207">
In this paper we present the results of the
combination of stochastic and rule-based
disambiguation methods applied to Basque
languagel . The methods we have used in
disambiguation are Constraint Grammar
formalism and an H1VIM based tagger
developed within the MULTEXT project.
As Basque is an agglutinative language, a
morphological analyser is needed to attach
all possible readings to each word. Then,
CG rules are applied using all the
morphological features and this process
decreases morphological ambiguity of
texts. Finally, we use the MULTEXT
project tools to select just one from the
possible remaining tags.
Using only the stochastic method the error
rate is about 14%, but the accuracy may be
increased by about 2% enriching the lexi-
con with the unknown words. When both
methods are combined, the error rate of the
whole process is 3.5%. Considering that
the training corpus is quite small, that the
FEMM model is a first order one and that
Constraint Grammar of Basque language is
still in progress, we think that this com-
bined method can achieve good results,
and it would be appropriate for other
agglutinative languages.
</bodyText>
<sectionHeader confidence="0.960887" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.998067857142857">
Based on the results of the combination of
stochastic and rule-based disambiguation
methods applied to Basque language, we will
show that the results of the combination are
significantly better than the ones obtained
applying the methods separately.
As Basque is an agglutinative and highly in-
</bodyText>
<note confidence="0.625570625">
This research has been supported by the Education
Department of the Government of the Basque
Country and the Interministerial Commision for
Science and Technology.
Aduriz I.
UZEI
Aldapeta, 20.
Donostia E-20009
</note>
<email confidence="0.779528">
uzei@sarenet.es
</email>
<bodyText confidence="0.9999036">
flected language, a morphological analyser is
needed to attach all possible interpretations to
each word. This process, which may not be
necessary in other languages such as English,
makes the tagging task more complex. We use
MORFEUS, a robust morphological analyser
for Basque developed at the University of the
Basque Country (Alegria et al., 1996). We
present it briefly in section 1, in the overview
of the whole system, the lemmatiser/tagger for
Basque EUSLEM.
We have added to MORFEUS a lemma dis-
ambiguation process, described in section 2,
which discards some of the analyses of the
word based on statistical measures.
Another important issue concerning a tagger is
the tagset itself. We discuss the design of the
tagset in section 3.
In section 4, we present the results of the ap-
plication of rule-based and stochastic disambi-
guation methods to Basque.
These results are deeply improved by combin-
ing both methods as explained in section 5.
Finally, we discuss some possible improve-
ments of the system and future research.
</bodyText>
<sectionHeader confidence="0.57653" genericHeader="method">
1 Overview of the system
</sectionHeader>
<bodyText confidence="0.99745125">
The disambiguation system is integrated in
EUSLEM, a lemmatiser/tagger for Basque
(Aduriz etal., 1996). EUSLEM has three main
modules:
</bodyText>
<listItem confidence="0.976344384615385">
• MORFEUS, the morphological analyser
based on the two-level formalism. It is a ro-
bust and wide coverage analyser for Basque.
• the module that treats multiword lexical
units. It has not been used in the experiments
in order to simplify the process.
• the disambiguation module, which will be
described in sections 5 and 6.
MORFEUS plays an important role in the
lemmatiser/tagger, because it assigns every to-
ken all the morphological features. The most
important functions are:
• incremental analysis, which is divided in
</listItem>
<page confidence="0.996316">
380
</page>
<bodyText confidence="0.999918125">
three phases, using the two level formalism
in all of them: 1) the standard analyser pro-
cesses words according to the standard lexi-
con and standard rules of the language; 2)
the analyser of linguistic variants analyses
dialectal variants and competence errors2;
and 3) the analyser of unknown words or
guesser processes the remaining words.
</bodyText>
<listItem confidence="0.93812">
• lemma disambiguation, presented below.
</listItem>
<sectionHeader confidence="0.830819" genericHeader="method">
2 Lemma disambiguation
</sectionHeader>
<bodyText confidence="0.987002">
The lemma disambiguation has been added to
the previously developed analyser for two main
reasons:
</bodyText>
<listItem confidence="0.99495425">
• the average number of interpretations in un-
known words is significantly higher than in
standard words.
• there could be more than one lemma per tag.
</listItem>
<bodyText confidence="0.924178">
Since the disambiguation module won&apos;t deal
with this kind of ambiguity, it has to be
solved to lemmatise the text.
We use different methods for the disambigua-
tion of linguistic variants and unknown words.
In the case of linguistic variants we try to select
the lemma that is &amp;quot;nearest&amp;quot; to the standard one
according to the number of non-standard mor-
phemes and rules. We choose the interpretation
that has less non-standard uses.
</bodyText>
<tableCaption confidence="0.903553">
Table 1- Number of readings.
</tableCaption>
<bodyText confidence="0.990907">
In the case of unknown words, the procedure
uses the following criteria:
</bodyText>
<listItem confidence="0.985659875">
• for each category and subcategory pair, leave
at least one interpretation.
• assign a weight to each lemma according to
the final trigram and the category and subca-
tegory pair.
• select the lemma according to its length and
weight —best combination of high weight and
short lemma.
</listItem>
<bodyText confidence="0.9999528">
These procedures have been tested with a small
corpus and the produced error-rate is 0.2%.
This is insignificant considering that the avera-
ge number of interpretations of unknown
words decreases by 7, as shown in table 1.
</bodyText>
<sectionHeader confidence="0.987105" genericHeader="method">
3 Designing the tagset
</sectionHeader>
<bodyText confidence="0.994819818181818">
The choice of a tagset is a critical aspect when
designing a tagger. Before defining the tagset
2 This module is very useful since Basque is still in
normalisation process.
we have had to take some aspects into account:
there was not any exhaustive tagset for auto-
matic use, and the output of the morphological
analyser is too rich and does not offer a directly
applicable tagset.
While designing the general tagset, we tried to
meet the following requirements:
</bodyText>
<listItem confidence="0.995581833333333">
• it had to take into account all the problems
concerning ellipsis, derivation and composi-
tion (Aduriz etal., 1995).
• in addition, it had to be general, far from ad
hoc tagsets.
• it had to be coherent with the information
provided by the morphological analyser.
Bearing all these considerations in mind, the
tagset has been structured in four levels:
• in the first level, general categories are inclu-
ded (noun, verb, etc.). There are 20 tags.
• in the second level each category tag is fur-
ther refined by subcategory tags. There are
48 tags.
• the third level includes other interesting in-
formation, as declension case, verb tense,
etc. There are 318 tags in the training cor-
pus, but using a larger corpus we found 185
new tags.
• the output of the morphological analysis
constitutes the last level of tagging. There are
2,943 different interpretations in this training
corpus, but we have found more than 9,000
in a lar er cornus.
</listItem>
<table confidence="0.619941333333333">
ambiguity rate tags/token
first 35.11% 1.48
second 40.68% 1.57
third 62.24% &apos; 2.20
fourth &apos; 3.48
64.42%
</table>
<tableCaption confidence="0.9459">
Table 2- Ambiguity of each eve .
</tableCaption>
<bodyText confidence="0.999703">
The morphological ambiguity will differ de-
pending on the level of tagging used in each
case, as shown in table 2.
</bodyText>
<sectionHeader confidence="0.994442" genericHeader="method">
4 Morphological Disambiguation
</sectionHeader>
<bodyText confidence="0.999947909090909">
There are two kinds of methods for morpho-
logical disambiguation: on one hand, statistical
methods need little effort and obtain very good
results (Church, 1988; Cutting etal., 1992), at
least when applied to English, but when we try
to apply them to Basque we encounter addi-
tional problems; on the other hand, some
rule-based systems (Brill, 1992; Voutilainen et
al., 1992) are at least as good as statistical
systems and are better adapted to free-order
languages and agglutinative languages. So, we
</bodyText>
<figure confidence="0.9852415">
variants
before
2.58
after
2.52
unknown
13.1
6.21
</figure>
<page confidence="0.990067">
381
</page>
<bodyText confidence="0.998744125">
have selected one of each group: Constraint
Grammar formalism (Karlsson et al., 1995)
and the HMM based TATOO tagger
(Armstrong et al., 1995), which has been de-
signed to be applied it to the output of a mor-
phological analyser and the tagset can be
switched easily without changing the input
text.
</bodyText>
<figureCaption confidence="0.749114">
Figure 1- Initial ambiguity3.
</figureCaption>
<bodyText confidence="0.9983462">
We have used the second and third levels
tagsets for the experiments and a small corpus
—28,300 words— divided in a training corpus of
27,000 words and a text of 1,300 words for
testing.
</bodyText>
<figureCaption confidence="0.789346">
Figure 2- Number of tags per token.
</figureCaption>
<bodyText confidence="0.999648153846154">
The initial ambiguity of the training corpus is
relatively high, as shown infig. I, and the ave-
rage number of tags per token is also higher
than in other languages —see fig. 2. The num-
ber of ambiguity classes is also high —290 and
1138 respectively— and some of the classes in
the test corpus aren&apos;t in the training corpus,
specially in the 3rd level tagset. This means
that the training corpus doesn&apos;t cover all the
phenomena of the language, so we would need
a larger corpus to assure that it is general and
representative of the language.
We tried both supervised and unsupervised4
</bodyText>
<footnote confidence="0.8551866">
3 These measures are taken after the process denoted
in each column: M morphological analysis; M*
—) morphological analysis with enriched lexicon;
CG —) Contraint Grammar.
4 Even if we used the same corpus for both training
</footnote>
<bodyText confidence="0.909488">
training using the 2nd level tagset and only su-
pervised training using the third level tagset.
The results are shown infig. 3(S). Accuracy is
below 90% and 75% respectively. Using un-
known words to enrich the lexicon, the results
are improved —see fig 3(S*)—, but are still far
from the accuracy of other systems.
We have also written some biases —to be exact
11— to correct the most evident errors in the
2nd level. We didn&apos;t write more biases for the
following reasons:
</bodyText>
<listItem confidence="0.964767285714286">
• They can use just the previous tag to change
the probabilities, and in some cases we need
a wider context to the left and/or to the right.
• They can&apos;t use the lemma or the word.
• From the beginning of this research, our in-
tention was to combine this method with
Constraint Grammar.
</listItem>
<bodyText confidence="0.91803225">
Using these biases, the error rate decreases by
5% in supervised training and by 7% in unsu-
pervised one —fig 3(S+B).
We also used biases5 with the enriched lexicon
and the accuracy increases by less than 2% in
both experiments —fig 3(S+B*). This is not a
great improvement when trying to decrease an
error rate greater than 10%, but the enrichment
of the lexicon may be a good way to improve
the system.
The logical conclusions of these experiments
are:
</bodyText>
<listItem confidence="0.959715714285714">
• the statistical approach might not be a good
approach for agglutinative and free-order
languages —as pointed out by Oflazer and
Kuril&amp; (1994).
• writing good disambiguation rules may real-
ly improve the accuracy of the disambigua-
tion task.
</listItem>
<bodyText confidence="0.999881857142857">
As we mentioned above, it is difficult to define
accurate rules using stochastic models, so we
use the Constraint Grammar for Basque6
(Aduriz etal., 1997) for this purpose.
The morphological disambiguator uses around
800 constraint rules that discard illegitimate
analyses on the basis of local or global context
</bodyText>
<footnote confidence="0.884562">
methods to compare the results, the latter
performed better using a larger corpus.
5 These biases were written taking into account the
errors made in the first experiment.
6 The rules were designed having syntactic analysis
as the main goal.
</footnote>
<figure confidence="0.987456923076923">
70
• second ES third
65
N
50
45
40
25
20
38
18
•
•
• Nom
• rom, Nom .&amp;quot;■.„);
• •
M M* M+CG M*+CG
• second CI third
r—
E
M* M+CG M*±CG
2
1.5
1
0.5
0
</figure>
<page confidence="0.994004">
382
</page>
<bodyText confidence="0.992228625">
conditions. The application of CG formalism7
is quite satisfactory, obtaining a recall of
99,8% but there are still 2.16 readings per to-
ken. The ambiguity rate after applying CG of
Basque drop from 41% to 12% using 2nd level
tagset and 64% to 22% using 3rd level tagset
—fig. 2— and the error rate in terms of the
tagsets is approximately 1%.
</bodyText>
<figureCaption confidence="0.997656">
Figure 3- Accuracy of the experiments8.
</figureCaption>
<sectionHeader confidence="0.99925" genericHeader="method">
5 Combining methods
</sectionHeader>
<bodyText confidence="0.972303961538461">
There have been some approaches to the com-
bination of statistical and linguistic methods
applied to POS disambiguation (Leech et al.,
1994; Tapanainen and Voutilainen, 1994;
Oflazer and Mr, 1997) to improve the accuracy
of the systems.
Oflazer and Tiir (1997) use simple statistical in-
formation and constraint rules. They include a
constraint application paradigm to make the
disambiguation independent of the rule se-
quence.
The approach of Tapanainen and Voutilainen
(1994) disambiguates the text using XT and
ENGCG independently; then the ambiguities
remaining in ENGCG are solved using the re-
sults of XT.
We propose a similar combination, applying
both disambiguation methods one after the
other, but training the stochastic tagger on the
output of the CG disambiguator.
Since in the output of CG of Basque the avera-
7 These results were obtained using the CG-2 parser,
which allows grouping the rules in different ordered
subgranunars depending on their accuracy. This
morphological disam-biguator uses only the first
two subgrammars.
</bodyText>
<equation confidence="0.7993235">
8 S stochastic; * with enriched lexicon;
B with biases; CG Constraint Grammar.
</equation>
<bodyText confidence="0.99994002">
ge number of possible tags is still high —1.13-
1.14 for 2nd level tagset and 1.29-1.3 for 3rd
level tagset— and the stochastic tagger produces
relatively high error rate —around 15% in 2nd
level and almost 30% in 3rd level—, we first
apply constraint rules and then train the
stochastic tagger on the output of the rule-
based disambiguator.
Fig. 1(CG) shows the ambiguity left by
Basque CG in terms of the tagsets. Although
the ambiguity rate is significantly lower than in
previous experiments, the remaining ambigui-
ties are hard to solve even using all the linguis-
tic information available.
We have also experimented with the enriched
lexicon and the results are very encouraging, as
shown in fig.3(CG+S*). Considering that the
number of ambiguity classes is still high
—around 240 in the 2nd level and more than
1000 in the 3rd level—, we think that the results
are very good.
For the 2nd level tagging, the error rate after
combining both methods is less than 3.5%,
half of it comes from MORFEUS and Basque
CG and the rest is made by the stochastic dis-
ambiguation. This is due to the fact that gene-
rally the types of ambiguity remaining after CG
is applied are hard to solve.
Examining the errors, we find that half of them
are made in unknown words trying to distin-
guish between proper names of persons and
places. We use two different tags because it is
interesting for some applications and the tagset
was defined based on morphological features.
This kind of ambiguity is very hard to solve
and in some applications this distinction is not
important. So in this case the accuracy of the
tagger would be 98%.
The accuracy in the third level tagset is around
91% using the combined method, which is not
too bad bearing in mind the number of tags
—310—, the precision of the input —1.29
tags/token— and that the training corpus does
not cover all the phenomena of the language9.
We want to point out that the experiments with
the 3rd level tagset show even clearer that the
combined method performs much better than
the stochastic. Moreover, we think that CG
disambiguation is even convenient at this level
because of the initial ambiguity —63%.
</bodyText>
<footnote confidence="0.733491">
9 In a corpus of around 900,000 words we found 185
new tags and more than 1700 new classes.
</footnote>
<figure confidence="0.993058260869565">
1
1
1
1
:111111111111
• supervised 0 unsupervised 19 third level
100
97.5
95
92.5
90
87.5
85
82.5
80
7.5
75
72.5
70
67.5
65
62.5
60
</figure>
<page confidence="0.996348">
383
</page>
<sectionHeader confidence="0.934574" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.94806848">
We have presented the results of applying
different disambiguation methods to an agglu-
tinative and highly inflected language with a
relatively free order in sentences.
On one hand, this latter characteristic of
Basque makes it difficult to learn appropriate
probabilities, particularly first order stochastic
models. We solve this problem in part with CG
for Basque, which uses a larger context and
can tackle the free word-order problem.
However, it is a very hard work to write a full
grammar and disambiguate texts completely
using CO formalism, so we have complemen-
ted this method with a stochastic disambigua-
tion process and the results are quite
encouraging.
Comparing the results of Tapanainen and
Voutilainen (1994) with ours, we see that they
achieve 98.5% recall combining 1.02-1.04
readings from ENGCG and 96% accuracy in
XT, while we begin with 1.13-1.14 readings,
the quality of our stochastic tagger is less than
90% and our result is better than 96%.
Unlike Tapanainen and Voutilainen (1994), we
think that training on the output of the CG the
statistical disambiguation works quite betterlo,
at least using such a small training corpus. In
the future we will compile a larger corpus and
to decrease the number of readings left by CG.
On the other hand, we think that the informa-
tion given by the second level tag is not suffi-
cient to decide which of the choices is the
correct one, but the training corpus is quite
small. However, translating the results of the
3rd level to the 2nd one we obtain around 97%
of accuracy. So, we think that improving the
3rd level tagging would improve the 2nd level
tagging too. We also want to experiment unsu-
pervised learning in the 3rd level tagging with a
large training corpus.
Along with this, the future research will focus
on the following processes:
• morphosyntactic treatment for the elaboration
of morphological information (nominalisa-
tion, ellipsis, etc.).
• treatment of multiword lexical units
(MV/LU). We are planning to integrate this
module to process unambiguous MWLU, to
decreases the ambiguity rate and to make the
input of the disambiguation more precise.
</bodyText>
<page confidence="0.587782">
10 With their method accuracy is 2% lower.
</page>
<sectionHeader confidence="0.950575" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9909504">
We are in debt with the research-team of the
General Linguistics Department of the
University of Helsinki for giving us
permission to use CO Parser. We also want to
thank Gilbert Robert for tuning TATOO.
</bodyText>
<sectionHeader confidence="0.998539" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999592673913043">
Aduriz I., Aldezabal I., Alegria I., Artola X.,
Ezeiza N., Urizar R. (1996) EUSLEM: A
lemmatiser/tagger for Basque. EURALEX.
Aduriz I., Alegria I., Arriola J.M., Artola X.,
Diaz de Ilarraza A., Ezeiza N., Gojenola K.,
Maritxalar M. (1995) Different issues in the
design of a lemmatizer/tagger for Basque.
&amp;quot;From text to tag&amp;quot; SIGDAT, EACL
Workshop.
Aduriz, I., Arriola, J.M., Artola, X., Diaz de
Illarraza, A., Gojenola, K., Maritxalar, M.
(1997) Morphosyntactic Disambiguation for
Basque based on the Constraint Grammar
Formalism. RANLP, Bulgaria.
Alegria, I., Sarasola, K., Urkia, M. (1996)
Automatic morphological analysis of Basque.
Literary and Linguistic Computing Vol 11, N.
4.
Armstrong S., Russel G., Petitpierre D., Robert
G. (1995) An open architecture for
Multilingual Text Processing. EACL&apos;95. vol 1,
101-106.
Brill E. (1992) A simple rule-based part of
speech tagger. ANLP, 152-155.
Church K. W. (1988) A stochastic parts pro-
gram and phrase parser for unrestricted text.
ANLP, 136-143.
Cutting D., Kupiec J., Pedersen J., Sibun P.
(1992) A practical part-of-speech tagger.
ANLP, 133-140.
Karlsson F., Voutilainen A., Heikkila J., Anttila
A. (1995) Constraint Grammar: Language-in-
dependent System for Parsing Unrestricted
Text. Mouton de Gruyter.
Leech G., Garside R., Bryan M. (1994)
CLAWS4: The tagging of the British National
Corpus. COLING, 622-628.
Oflazer K., Kunitiz I. (1994) Tagging and
Morphological Disambiguation of Turkish
Text. ANLP, 144-149.
Oflazer K., Tiir G. (1997) Morphological
Disambiguation by Voting Constraints. ACL-
EACL, 222-229.
Tapanainen P., Voutilainen A. (1994) Tagging
Accurately - Don&apos;t guess if you know. ANLP,
47-52.
</reference>
<page confidence="0.998969">
384
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.287869">
<title confidence="0.895165">Combining Stochastic and Rule-Based Methods for Disambiguation in Agglutinative Languages N., Alegria J.M., Urizar R.</title>
<author confidence="0.357681">Informatika Falcultatea</author>
<address confidence="0.905472">649 P.K Donostia E-20080</address>
<email confidence="0.974446">jibecran@si.ehu.es</email>
<web confidence="0.997355">http://ixa.si.ehu.es</web>
<abstract confidence="0.999670233333333">In this paper we present the results of the combination of stochastic and rule-based disambiguation methods applied to Basque languagel . The methods we have used in disambiguation are Constraint Grammar formalism and an H1VIM based tagger developed within the MULTEXT project. As Basque is an agglutinative language, a morphological analyser is needed to attach all possible readings to each word. Then, CG rules are applied using all the morphological features and this process decreases morphological ambiguity of texts. Finally, we use the MULTEXT project tools to select just one from the possible remaining tags. Using only the stochastic method the error rate is about 14%, but the accuracy may be increased by about 2% enriching the lexicon with the unknown words. When both methods are combined, the error rate of the whole process is 3.5%. Considering that the training corpus is quite small, that the FEMM model is a first order one and that Constraint Grammar of Basque language is still in progress, we think that this combined method can achieve good results, and it would be appropriate for other agglutinative languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Aduriz</author>
<author>I Aldezabal</author>
<author>I Alegria</author>
<author>X Artola</author>
<author>N Ezeiza</author>
<author>R Urizar</author>
</authors>
<title>EUSLEM: A lemmatiser/tagger for Basque.</title>
<date>1996</date>
<publisher>EURALEX.</publisher>
<marker>Aduriz, Aldezabal, Alegria, Artola, Ezeiza, Urizar, 1996</marker>
<rawString>Aduriz I., Aldezabal I., Alegria I., Artola X., Ezeiza N., Urizar R. (1996) EUSLEM: A lemmatiser/tagger for Basque. EURALEX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Aduriz</author>
<author>I Alegria</author>
<author>J M Arriola</author>
<author>X Artola</author>
<author>Diaz de Ilarraza A</author>
<author>N Ezeiza</author>
<author>K Gojenola</author>
<author>M Maritxalar</author>
</authors>
<title>Different issues in the design of a lemmatizer/tagger for Basque. &amp;quot;From text to tag&amp;quot;</title>
<date>1995</date>
<journal>SIGDAT, EACL Workshop.</journal>
<marker>Aduriz, Alegria, Arriola, Artola, A, Ezeiza, Gojenola, Maritxalar, 1995</marker>
<rawString>Aduriz I., Alegria I., Arriola J.M., Artola X., Diaz de Ilarraza A., Ezeiza N., Gojenola K., Maritxalar M. (1995) Different issues in the design of a lemmatizer/tagger for Basque. &amp;quot;From text to tag&amp;quot; SIGDAT, EACL Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Aduriz</author>
<author>J M Arriola</author>
<author>X Artola</author>
<author>Diaz de Illarraza</author>
<author>A Gojenola</author>
<author>K Maritxalar</author>
<author>M</author>
</authors>
<title>Morphosyntactic Disambiguation for Basque based on the Constraint Grammar Formalism.</title>
<date>1997</date>
<location>RANLP,</location>
<marker>Aduriz, Arriola, Artola, de Illarraza, Gojenola, Maritxalar, M, 1997</marker>
<rawString>Aduriz, I., Arriola, J.M., Artola, X., Diaz de Illarraza, A., Gojenola, K., Maritxalar, M. (1997) Morphosyntactic Disambiguation for Basque based on the Constraint Grammar Formalism. RANLP, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Alegria</author>
<author>K Sarasola</author>
<author>M Urkia</author>
</authors>
<title>Automatic morphological analysis of Basque.</title>
<date>1996</date>
<journal>Literary and Linguistic Computing Vol</journal>
<volume>11</volume>
<contexts>
<context position="2255" citStr="Alegria et al., 1996" startWordPosition="341" endWordPosition="344"> As Basque is an agglutinative and highly inThis research has been supported by the Education Department of the Government of the Basque Country and the Interministerial Commision for Science and Technology. Aduriz I. UZEI Aldapeta, 20. Donostia E-20009 uzei@sarenet.es flected language, a morphological analyser is needed to attach all possible interpretations to each word. This process, which may not be necessary in other languages such as English, makes the tagging task more complex. We use MORFEUS, a robust morphological analyser for Basque developed at the University of the Basque Country (Alegria et al., 1996). We present it briefly in section 1, in the overview of the whole system, the lemmatiser/tagger for Basque EUSLEM. We have added to MORFEUS a lemma disambiguation process, described in section 2, which discards some of the analyses of the word based on statistical measures. Another important issue concerning a tagger is the tagset itself. We discuss the design of the tagset in section 3. In section 4, we present the results of the application of rule-based and stochastic disambiguation methods to Basque. These results are deeply improved by combining both methods as explained in section 5. Fi</context>
</contexts>
<marker>Alegria, Sarasola, Urkia, 1996</marker>
<rawString>Alegria, I., Sarasola, K., Urkia, M. (1996) Automatic morphological analysis of Basque. Literary and Linguistic Computing Vol 11, N. 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Armstrong</author>
<author>G Russel</author>
<author>D Petitpierre</author>
<author>G Robert</author>
</authors>
<title>An open architecture for Multilingual Text Processing.</title>
<date>1995</date>
<booktitle>EACL&apos;95.</booktitle>
<volume>1</volume>
<pages>101--106</pages>
<contexts>
<context position="7710" citStr="Armstrong et al., 1995" startWordPosition="1254" endWordPosition="1257">and, statistical methods need little effort and obtain very good results (Church, 1988; Cutting etal., 1992), at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule-based systems (Brill, 1992; Voutilainen et al., 1992) are at least as good as statistical systems and are better adapted to free-order languages and agglutinative languages. So, we variants before 2.58 after 2.52 unknown 13.1 6.21 381 have selected one of each group: Constraint Grammar formalism (Karlsson et al., 1995) and the HMM based TATOO tagger (Armstrong et al., 1995), which has been designed to be applied it to the output of a morphological analyser and the tagset can be switched easily without changing the input text. Figure 1- Initial ambiguity3. We have used the second and third levels tagsets for the experiments and a small corpus —28,300 words— divided in a training corpus of 27,000 words and a text of 1,300 words for testing. Figure 2- Number of tags per token. The initial ambiguity of the training corpus is relatively high, as shown infig. I, and the average number of tags per token is also higher than in other languages —see fig. 2. The number of </context>
</contexts>
<marker>Armstrong, Russel, Petitpierre, Robert, 1995</marker>
<rawString>Armstrong S., Russel G., Petitpierre D., Robert G. (1995) An open architecture for Multilingual Text Processing. EACL&apos;95. vol 1, 101-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<journal>ANLP,</journal>
<pages>152--155</pages>
<contexts>
<context position="7360" citStr="Brill, 1992" startWordPosition="1200" endWordPosition="1201">gs/token first 35.11% 1.48 second 40.68% 1.57 third 62.24% &apos; 2.20 fourth &apos; 3.48 64.42% Table 2- Ambiguity of each eve . The morphological ambiguity will differ depending on the level of tagging used in each case, as shown in table 2. 4 Morphological Disambiguation There are two kinds of methods for morphological disambiguation: on one hand, statistical methods need little effort and obtain very good results (Church, 1988; Cutting etal., 1992), at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule-based systems (Brill, 1992; Voutilainen et al., 1992) are at least as good as statistical systems and are better adapted to free-order languages and agglutinative languages. So, we variants before 2.58 after 2.52 unknown 13.1 6.21 381 have selected one of each group: Constraint Grammar formalism (Karlsson et al., 1995) and the HMM based TATOO tagger (Armstrong et al., 1995), which has been designed to be applied it to the output of a morphological analyser and the tagset can be switched easily without changing the input text. Figure 1- Initial ambiguity3. We have used the second and third levels tagsets for the experim</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Brill E. (1992) A simple rule-based part of speech tagger. ANLP, 152-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
</authors>
<title>A stochastic parts program and phrase parser for unrestricted text.</title>
<date>1988</date>
<journal>ANLP,</journal>
<pages>136--143</pages>
<contexts>
<context position="7173" citStr="Church, 1988" startWordPosition="1168" endWordPosition="1169">l analysis constitutes the last level of tagging. There are 2,943 different interpretations in this training corpus, but we have found more than 9,000 in a lar er cornus. ambiguity rate tags/token first 35.11% 1.48 second 40.68% 1.57 third 62.24% &apos; 2.20 fourth &apos; 3.48 64.42% Table 2- Ambiguity of each eve . The morphological ambiguity will differ depending on the level of tagging used in each case, as shown in table 2. 4 Morphological Disambiguation There are two kinds of methods for morphological disambiguation: on one hand, statistical methods need little effort and obtain very good results (Church, 1988; Cutting etal., 1992), at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule-based systems (Brill, 1992; Voutilainen et al., 1992) are at least as good as statistical systems and are better adapted to free-order languages and agglutinative languages. So, we variants before 2.58 after 2.52 unknown 13.1 6.21 381 have selected one of each group: Constraint Grammar formalism (Karlsson et al., 1995) and the HMM based TATOO tagger (Armstrong et al., 1995), which has been designed to be applied it to the output of a m</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Church K. W. (1988) A stochastic parts program and phrase parser for unrestricted text. ANLP, 136-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cutting</author>
<author>J Kupiec</author>
<author>J Pedersen</author>
<author>P Sibun</author>
</authors>
<title>A practical part-of-speech tagger.</title>
<date>1992</date>
<journal>ANLP,</journal>
<pages>133--140</pages>
<marker>Cutting, Kupiec, Pedersen, Sibun, 1992</marker>
<rawString>Cutting D., Kupiec J., Pedersen J., Sibun P. (1992) A practical part-of-speech tagger. ANLP, 133-140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Karlsson</author>
<author>A Voutilainen</author>
<author>J Heikkila</author>
<author>A Anttila</author>
</authors>
<title>Constraint Grammar: Language-independent System for Parsing Unrestricted Text. Mouton de Gruyter.</title>
<date>1995</date>
<contexts>
<context position="7654" citStr="Karlsson et al., 1995" startWordPosition="1244" endWordPosition="1247">s of methods for morphological disambiguation: on one hand, statistical methods need little effort and obtain very good results (Church, 1988; Cutting etal., 1992), at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule-based systems (Brill, 1992; Voutilainen et al., 1992) are at least as good as statistical systems and are better adapted to free-order languages and agglutinative languages. So, we variants before 2.58 after 2.52 unknown 13.1 6.21 381 have selected one of each group: Constraint Grammar formalism (Karlsson et al., 1995) and the HMM based TATOO tagger (Armstrong et al., 1995), which has been designed to be applied it to the output of a morphological analyser and the tagset can be switched easily without changing the input text. Figure 1- Initial ambiguity3. We have used the second and third levels tagsets for the experiments and a small corpus —28,300 words— divided in a training corpus of 27,000 words and a text of 1,300 words for testing. Figure 2- Number of tags per token. The initial ambiguity of the training corpus is relatively high, as shown infig. I, and the average number of tags per token is also hi</context>
</contexts>
<marker>Karlsson, Voutilainen, Heikkila, Anttila, 1995</marker>
<rawString>Karlsson F., Voutilainen A., Heikkila J., Anttila A. (1995) Constraint Grammar: Language-independent System for Parsing Unrestricted Text. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
<author>R Garside</author>
<author>M Bryan</author>
</authors>
<date>1994</date>
<booktitle>CLAWS4: The tagging of the British National Corpus. COLING,</booktitle>
<pages>622--628</pages>
<contexts>
<context position="11627" citStr="Leech et al., 1994" startWordPosition="1950" endWordPosition="1953">; • • M M* M+CG M*+CG • second CI third r— E M* M+CG M*±CG 2 1.5 1 0.5 0 382 conditions. The application of CG formalism7 is quite satisfactory, obtaining a recall of 99,8% but there are still 2.16 readings per token. The ambiguity rate after applying CG of Basque drop from 41% to 12% using 2nd level tagset and 64% to 22% using 3rd level tagset —fig. 2— and the error rate in terms of the tagsets is approximately 1%. Figure 3- Accuracy of the experiments8. 5 Combining methods There have been some approaches to the combination of statistical and linguistic methods applied to POS disambiguation (Leech et al., 1994; Tapanainen and Voutilainen, 1994; Oflazer and Mr, 1997) to improve the accuracy of the systems. Oflazer and Tiir (1997) use simple statistical information and constraint rules. They include a constraint application paradigm to make the disambiguation independent of the rule sequence. The approach of Tapanainen and Voutilainen (1994) disambiguates the text using XT and ENGCG independently; then the ambiguities remaining in ENGCG are solved using the results of XT. We propose a similar combination, applying both disambiguation methods one after the other, but training the stochastic tagger on </context>
</contexts>
<marker>Leech, Garside, Bryan, 1994</marker>
<rawString>Leech G., Garside R., Bryan M. (1994) CLAWS4: The tagging of the British National Corpus. COLING, 622-628.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Oflazer</author>
<author>I Kunitiz</author>
</authors>
<title>Tagging and Morphological Disambiguation of Turkish Text.</title>
<date>1994</date>
<pages>144--149</pages>
<publisher>ANLP,</publisher>
<marker>Oflazer, Kunitiz, 1994</marker>
<rawString>Oflazer K., Kunitiz I. (1994) Tagging and Morphological Disambiguation of Turkish Text. ANLP, 144-149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Oflazer</author>
<author>G Tiir</author>
</authors>
<title>Morphological Disambiguation by Voting Constraints.</title>
<date>1997</date>
<pages>222--229</pages>
<publisher>ACLEACL,</publisher>
<contexts>
<context position="11748" citStr="Oflazer and Tiir (1997)" startWordPosition="1969" endWordPosition="1972">lism7 is quite satisfactory, obtaining a recall of 99,8% but there are still 2.16 readings per token. The ambiguity rate after applying CG of Basque drop from 41% to 12% using 2nd level tagset and 64% to 22% using 3rd level tagset —fig. 2— and the error rate in terms of the tagsets is approximately 1%. Figure 3- Accuracy of the experiments8. 5 Combining methods There have been some approaches to the combination of statistical and linguistic methods applied to POS disambiguation (Leech et al., 1994; Tapanainen and Voutilainen, 1994; Oflazer and Mr, 1997) to improve the accuracy of the systems. Oflazer and Tiir (1997) use simple statistical information and constraint rules. They include a constraint application paradigm to make the disambiguation independent of the rule sequence. The approach of Tapanainen and Voutilainen (1994) disambiguates the text using XT and ENGCG independently; then the ambiguities remaining in ENGCG are solved using the results of XT. We propose a similar combination, applying both disambiguation methods one after the other, but training the stochastic tagger on the output of the CG disambiguator. Since in the output of CG of Basque the avera7 These results were obtained using the </context>
</contexts>
<marker>Oflazer, Tiir, 1997</marker>
<rawString>Oflazer K., Tiir G. (1997) Morphological Disambiguation by Voting Constraints. ACLEACL, 222-229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
<author>A Voutilainen</author>
</authors>
<title>Tagging Accurately - Don&apos;t guess if you know.</title>
<date>1994</date>
<journal>ANLP,</journal>
<pages>47--52</pages>
<contexts>
<context position="11661" citStr="Tapanainen and Voutilainen, 1994" startWordPosition="1954" endWordPosition="1957">G • second CI third r— E M* M+CG M*±CG 2 1.5 1 0.5 0 382 conditions. The application of CG formalism7 is quite satisfactory, obtaining a recall of 99,8% but there are still 2.16 readings per token. The ambiguity rate after applying CG of Basque drop from 41% to 12% using 2nd level tagset and 64% to 22% using 3rd level tagset —fig. 2— and the error rate in terms of the tagsets is approximately 1%. Figure 3- Accuracy of the experiments8. 5 Combining methods There have been some approaches to the combination of statistical and linguistic methods applied to POS disambiguation (Leech et al., 1994; Tapanainen and Voutilainen, 1994; Oflazer and Mr, 1997) to improve the accuracy of the systems. Oflazer and Tiir (1997) use simple statistical information and constraint rules. They include a constraint application paradigm to make the disambiguation independent of the rule sequence. The approach of Tapanainen and Voutilainen (1994) disambiguates the text using XT and ENGCG independently; then the ambiguities remaining in ENGCG are solved using the results of XT. We propose a similar combination, applying both disambiguation methods one after the other, but training the stochastic tagger on the output of the CG disambiguator</context>
<context position="15719" citStr="Tapanainen and Voutilainen (1994)" startWordPosition="2639" endWordPosition="2642">tive and highly inflected language with a relatively free order in sentences. On one hand, this latter characteristic of Basque makes it difficult to learn appropriate probabilities, particularly first order stochastic models. We solve this problem in part with CG for Basque, which uses a larger context and can tackle the free word-order problem. However, it is a very hard work to write a full grammar and disambiguate texts completely using CO formalism, so we have complemented this method with a stochastic disambiguation process and the results are quite encouraging. Comparing the results of Tapanainen and Voutilainen (1994) with ours, we see that they achieve 98.5% recall combining 1.02-1.04 readings from ENGCG and 96% accuracy in XT, while we begin with 1.13-1.14 readings, the quality of our stochastic tagger is less than 90% and our result is better than 96%. Unlike Tapanainen and Voutilainen (1994), we think that training on the output of the CG the statistical disambiguation works quite betterlo, at least using such a small training corpus. In the future we will compile a larger corpus and to decrease the number of readings left by CG. On the other hand, we think that the information given by the second leve</context>
</contexts>
<marker>Tapanainen, Voutilainen, 1994</marker>
<rawString>Tapanainen P., Voutilainen A. (1994) Tagging Accurately - Don&apos;t guess if you know. ANLP, 47-52.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>