<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999077">
Acquisition of English-Chinese Transliterated Word Pairs from Parallel-
Aligned Texts using a Statistical Machine Transliteration Model
</title>
<author confidence="0.983703">
Chun-Jen Lee1, 2
</author>
<affiliation confidence="0.832940666666667">
1 Telecommunication Labs.
Chunghwa Telecom Co., Ltd.
Chungli, Taiwan, R.O.C.
</affiliation>
<email confidence="0.992004">
cjlee@cht.com.tw
</email>
<sectionHeader confidence="0.997326" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99995105882353">
This paper presents a framework for extract-
ing English and Chinese transliterated word
pairs from parallel texts. The approach is
based on the statistical machine transliteration
model to exploit the phonetic similarities be-
tween English words and corresponding Chi-
nese transliterations. For a given proper noun
in English, the proposed method extracts the
corresponding transliterated word from the
aligned text in Chinese. Under the proposed
approach, the parameters of the model are
automatically learned from a bilingual proper
name list. Experimental results show that the
average rates of word and character precision
are 86.0% and 94.4%, respectively. The rates
can be further improved with the addition of
simple linguistic processing.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99951">
Automatic bilingual lexicon construction based on bi-
lingual corpora has become an important first step for
many studies and applications of natural language proc-
essing (NLP), such as machine translation (MT), cross-
language information retrieval (CLIR), and bilingual
text alignment. As noted in Tsuji (2002), many previous
methods (Dagan et al., 1993; Kupiec, 1993; Wu and Xia,
1994; Melamed, 1996; Smadja et al., 1996) deal with
this problem based on frequency of words appearing in
the corpora, which can not be effectively applied to low-
frequency words, such as transliterated words. These
transliterated words are often domain-specific and cre-
ated frequently. Many of them are not found in existing
bilingual dictionaries. Thus, it is difficult to handle
transliteration only via simple dictionary lookup. For
CLIR, the accuracy of transliteration highly affects the
performance of retrieval.
In this paper, we present a framework of acquisition
for English and Chinese transliterated word pairs based
on the proposed statistical machine transliteration model.
</bodyText>
<affiliation confidence="0.79623">
Jason S. Chang2
2 Department of Computer Science
National Tsing Hua University
Hsinchu, Taiwan, R.O.C.
</affiliation>
<email confidence="0.982014">
jschang@cs.nthu.edu.tw
</email>
<bodyText confidence="0.999976833333333">
Recently, much research has been done on machine
transliteration for many language pairs, such as Eng-
lish/Arabic (Al-Onaizan and Knight, 2002), Eng-
lish/Chinese (Chen et al., 1998; Lin and Chen, 2002;
Wan and Verspoor, 1998), English/Japanese (Knight
and Graehl, 1998), and English/Korean (Lee and Choi,
1997; Oh and Choi, 2002). Most previous approaches to
machine transliteration have focused on the use of a
pronunciation dictionary for converting source words
into phonetic symbols, a manually assigned scoring
matrix for measuring phonetic similarities between
source and target words, or a method based on heuristic
rules for source-to-target word transliteration. However,
words with unknown pronunciations may cause prob-
lems for transliteration. In addition, using either a lan-
guage-dependent penalty function to measure the
similarity between bilingual word pairs, or handcrafted
heuristic mapping rules for transliteration may lead to
problems when porting to other language pairs.
The proposed method in this paper requires no con-
version of source words into phonetic symbols. The
model is trained automatically on a bilingual proper
name list via unsupervised learning.
The remainder of the paper is organized as follows:
Section 2 gives an overview of machine transliteration
and describes the proposed model. Section 3 describes
how to apply the model for extraction of transliterated
target words from parallel texts. Experimental setup and
quantitative assessment of performance are presented in
Section 4. Concluding remarks are made in Section 5.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="method">
2 Statistical Machine Transliteration
Model
</sectionHeader>
<subsectionHeader confidence="0.997995">
2.1 Overview of the Noisy Channel Model
</subsectionHeader>
<bodyText confidence="0.95536325">
Machine transliteration can be regarded as a noisy
channel, as illustrated in Figure 1. Briefly, the language
model generates a source word E and the transliteration
model converts the word E to a target transliteration C.
Then, the channel decoder is used to find the word Ê
that is the most likely to the word E that gives rise to the
transliteration C.
Under the noisy channel model, the back-
transliteration problem is to find out the most probable
word E, given transliteration C. Letting P(E) be the
probability of a word E, then for a given transliteration
C, the back-transliteration probability of a word E can
be written as P(E|C). By Bayes’ rule, the transliteration
problem can be written as follows:
Since P(C) is constant for the given C, we can rewrite
Eq. (1) as follows:
</bodyText>
<equation confidence="0.92613125">
ˆ
E = arg max P(E)P(C  |E
E
(2)
</equation>
<bodyText confidence="0.994264">
The first term, P(E), in Eq. (2) is the language model,
the probability of E. The second term, P(C|E), in Eq. (2)
is the transliteration model, the probability of the trans-
literation C conditioned on E.
Below, we assume that E is written in English, while
C is written in Chinese. Since Chinese and English are
not in the same language family, there is no simple or
direct way of mapping and comparison. One feasible
solution is to adopt a Chinese romanization system1 to
represent the pronunciation of each Chinese character.
Among the many romanization systems for Chinese,
Wade-Giles and Pinyin are the most widely used. The
Wade-Giles system is commonly used in Taiwan today
and has traditionally been popular among Western
scholars. For this reason, we use the Wade-Giles system
to romanize Chinese characters. However, the proposed
approach is equally applicable to other romanization
systems.
The language model gives the prior probability P(E)
which can be modeled using maximum likelihood esti-
mation. As for the transliteration model P(C|E), we can
approximate it using the transliteration unit (TU), which
is a decomposition of E and C. TU is defined as a se-
</bodyText>
<footnote confidence="0.9703425">
1 Ref. sites: “http://www.romanization.com/index.html” and
“http://www.edepot.com/taoroman.html”.
</footnote>
<bodyText confidence="0.981609727272727">
quence of characters transliterated as a base unit. For
English, a TU can be a monograph, a digraph, or a tri-
graph (Wells, 2001). For Chinese, a TU can be a sylla-
ble initial, a syllable final, or a syllable (Chao, 1968)
represented by corresponding romanized characters. To
illustrate how this approach works, take the example of
an English name, “Smith”, which can be segmented into
four TUs and aligned with the romanized transliteration.
Assuming that the word is segmented into “S-m-i-th”,
then a possible alignment with the Chinese translitera-
tion “史密斯 (Shihmissu)” is depicted in Figure 2.
</bodyText>
<figureCaption confidence="0.9886205">
Figure 2. TU alignment between English and
Chinese romanized character sequences.
</figureCaption>
<subsectionHeader confidence="0.864535">
2.2 Formal Description: Statistical Translitera-
tion Model (STM)
</subsectionHeader>
<bodyText confidence="0.999185">
A word E with l characters and a romanized word C
with n characters are denoted by l
</bodyText>
<equation confidence="0.568949">
e1 and n
c1 , respec-
</equation>
<bodyText confidence="0.996613428571429">
tively. Assume that the number of aligned TUs for (E,
C) is N, and let M = {m1 , m2,..., mN } be an alignment
candidate, where mj is the match type of the j-th TU.
The match type is defined as a pair of TU lengths for the
two languages. For instance, in the case of (Smith,
Shihmissu), N is 4, and M is {1-4, 1-1, 1-1, 2-3}. We
write E and C as follows:
</bodyText>
<equation confidence="0.9987276">
= = =
l N ,
 E e u u u
1 1 1 2
 C c v v v
N
= = =
n ,
1 1 1 2
(3)
</equation>
<bodyText confidence="0.99783225">
where ui and vj are the i-th TU of E and the j-th TU of
C, respectively.
Then the probability of C given E, P(C|E), is formulated
as follows:
</bodyText>
<equation confidence="0.99893025">
P C E P C M E P C M E P M E
(  |) ( ,  |) (  |, ) (  |)
=∑ =∑
M M
</equation>
<bodyText confidence="0.97694175">
To reduce computational complexity, one alternative
approach is to modify the summation criterion in Eq. (4)
into maximization. Therefore, we can approximate
P(C|E) as follows:
</bodyText>
<equation confidence="0.986624">
P C E
(  |) max (  |, ) (  |)
≈ P C M E P M E
M
≈ maxP(C  |M,E)P(M) . (5)
M
ˆ
E = arg max (  |)
P E C =
P E P C
( ) ( |
P(C)
</equation>
<figure confidence="0.895019388888889">
argmax
E) . (1)
E E
S m i th
Shih m i ssu
史 密 斯
Language
Model
P(E)
Transli-
Teration
Model
P(C|E)
Channel
Decoder
P(E|C)
argmax
E
</figure>
<figureCaption confidence="0.9883565">
Figure 1. The noisy channel model in ma-
chine transliteration.
</figureCaption>
<equation confidence="0.662004">
ˆ
E
E
C
),

,...,
u
N ,
vN
,...,
. (4)
We approximate P(C |M,E)P(M) as follows:
P C M E P M = P v N u N P m m m
(  |, ) ( ) (  |) ( , ,...,
1 1 1 2 N
</equation>
<bodyText confidence="0.994885714285714">
Let S(i, j) be the maximum accumulated log prob-
ability between the first i characters of E and the first j
characters of C. Then, logP(C  |E) = S(l, n) , the maxi-
mum accumulated log probability among all possible
alignment paths of E with length l and C with length n,
can be computed using a dynamic programming (DP)
strategy, as shown in the following:
</bodyText>
<equation confidence="0.880349">
Step 1 (Initialization):
S(0,0) = 0
Step 2 (Recursion):
S(i, j)= max S(i − h, j − k)
h,k
</equation>
<bodyText confidence="0.9958615">
Therefore, the translation probability P(vj  |ui) can be
approximated as follows:
The probability of the match type, P(h, k) , can be es-
timated as follows:
</bodyText>
<equation confidence="0.9292925">
count h k
( , )
P h k
( , ) ∑∑
=
i j
</equation>
<bodyText confidence="0.91138">
For the reason that count(ui,vj) is unknown in the
beginning , a reasonable initial estimate of the parame-
ters of the translation model is to constrain the TU
alignments of a word pair (E, C) within a position dis-
</bodyText>
<equation confidence="0.729264868421053">
p h
+ − 1
tance δ (Lee and Choi, 1997). Assume that ui e p
=
q k
+ −1
and vj c q , and dδ (ui, vj) is the allowable posi-
=
tion distance within δ for the aligned pair (ui, vi).
dδ (ui, vj) is defined as follows:
≈∏ P(vi  |ui)P(mi). (6)
Therefore, we have
N
N
i=1
log (  |E) max ∑= (logP(vi  |ui)+logP(mi))
P C ≈ i 1
M
P(vj  |ui) =
count(u)
i
count
(ui , vj ) .
)
.
( , )
i j
count
q
−
p
δ,
× l
&lt;
and
,
(
+k−
1)×l
q
&lt;
+
δ
(p
h 1)
− −
n
log (  |) log ( , )
P c e
j i
+ + P h k
j k
− i h
−
0≤i≤l, 0≤ j≤ n.
(9)
Step 3 (Termination):
dδ(ui,vj)= n (13)






S l n
( , ) max
= S(l − h, n − k)
h,k
log (  |) log ( , )
P c e
n l
+ + P h k
n k
− l h
−
(10)
</equation>
<bodyText confidence="0.999308">
where P(h,k) is defined as the probability of the match
type “h-k”.
</bodyText>
<subsectionHeader confidence="0.998918">
2.3 Estimation of Model Parameters
</subsectionHeader>
<bodyText confidence="0.977943481481482">
To describe the iterative procedure for re-estimation of
probabilities of P(vj  |ui) and P(mi) , we first define
the following functions:
count(ui,vj) = the number of occurrences of
aligned pair ui and vi in the training
set.
count(ui) = the number of occurrences of ui in
the training set.
count(h, k) = the total number of occurrences
of ui with length h aligned with vj
with length k in the training set.
where l and n are the length of the source word E and
the target word C, respectively.
To accelerate the convergence of EM training and
reduce the noisy TU aligned pairs (ui, vj), we restrict the
combination of TU pairs to limited patterns. Consonant
TU pairs only with same or similar phonemes are al-
lowed to be matched together. An English consonant is
also allowed to matching with a Chinese syllable begin-
ning with same or similar phonemes. An English semi-
vowel TU can either be matched with a Chinese
consonant or a vowel with same or similar phonemes, or
be matched with a Chinese syllable beginning with
same or similar phonemes.
As for the probability of match type, P(h, k) , it is
set to uniform distribution in the initialization phase,
shown as follows:
</bodyText>
<equation confidence="0.996961">
1
P h k =
( , ) ,(14)
T
</equation>
<bodyText confidence="0.959363">
where T is the total number of match types allowed.
Based on the Expectation Maximization (EM) algo-
rithm (Dempster et al., 1977) with Viterbi decoding
(Forney, 1973), the iterative parameter estimation pro-
cedure is described as follows:
Step 1 (Initialization):
Use Eq. (13) to generate likely TU alignment
pairs. Calculate the initial model parameters,
</bodyText>
<equation confidence="0.724914">
P(vj  |ui) and P(h, k) , using Eq. (11) and Eq.
(12).
</equation>
<bodyText confidence="0.952800307692308">
Step 2 (Expection):
Based on current model parameters, find the
best Viterbi path for each E and C word pair in
the training set.
Step 3 (Maximization):
Based on all the TU alignment pairs obtained
from Step 2, calculate the new model parame-
ters using Eqs. (11) and (12). Replace the
model parameters with the new model parame-
ters. If it reaches a stopping criterion or a pre-
defined iteration numbers, then stop the
training procedure. Otherwise, go back to Step
2.
</bodyText>
<sectionHeader confidence="0.9688295" genericHeader="method">
3 Extraction of Transliteration from Par-
allel Text
</sectionHeader>
<bodyText confidence="0.9998475">
The task of machine transliteration is useful for many
NLP applications, and one interesting related problem is
how to find the corresponding transliteration for a given
source word in a parallel corpus. We will describe how
to apply the proposed model for such a task.
For that purpose, a sentence alignment procedure is
applied first to align parallel texts at the sentence level.
Then, we use a tagger to identify proper nouns in the
source text. After that, the model is applied to isolate the
transliteration in the target text. In general, the pro-
posed transliteration model could be further augmented
with linguistic processing, which will be described in
more details in the next subsection. The overall process
is summarized in Figure 3.
</bodyText>
<subsectionHeader confidence="0.555397">
Bilingual corpus
Proper names:
Source &amp; Target words
</subsectionHeader>
<figureCaption confidence="0.972954">
Figure 3. The overall process for the extrac-
</figureCaption>
<bodyText confidence="0.813477333333333">
tion of transliteration from parallel text.
An excerpt from the magazine Scientific American
(Cibelli et al., 2002) is illustrated as follows:
</bodyText>
<subsectionHeader confidence="0.729329">
Source sentence:
</subsectionHeader>
<bodyText confidence="0.95268825">
“Rudolf Jaenisch, a cloning expert at the
Whitehead Institute for Biomedical Re-
search at the Massachusetts Institute of
Technology, concurred:”
</bodyText>
<subsectionHeader confidence="0.459054">
Target sentence:
</subsectionHeader>
<bodyText confidence="0.960959375">
“麻省理工學院懷海德生物醫學研究院的複製
專家傑尼西說:”
In the above excerpt, three English proper nouns “Jae-
nisch”, “Whitehead”, and “Massachusetts” are identi-
fied by a tagger. Utilizing Eqs. (7) and the DP approach
formulated by Eqs. (8)-(10), we found the target word
“huaihaite ( 懷 海 德 )” most likely corresponding to
“Whitehead”. In order to retrieve the transliteration for a
given proper noun, we need to keep track of the optimal
TU decoding sequence associated with the given Chi-
nese term for each word pair under the proposed
method. The aligned TUs can be easily obtained via
backtracking the best Viterbi path (Manning and
Schutze, 1999). For the example mentioned above, the
alignments of the TU matching pairs via the Viterbi
backtracking path are illustrated in Figure 4.
</bodyText>
<figureCaption confidence="0.989017">
Figure 4. The alignments of the TU matching pairs
via the Viterbi backtracking path.
</figureCaption>
<figure confidence="0.644989076923077">
Linguistic
processing
Transli-
terator
Prepro-
cessing
Proper names:
Word extraction
Source word
Source
sentence
Sentence alignment
Target
sentence
Match Type TU Pair
:
0 - 1 , -- y
0 - 1 , -- u
0 - 1 , -- a
0 - 1 , -- n
2 - 2 , Wh--hu
1 - 1 , i -- a
1 - 0 , t --
1 - 1 , e -- i
1 - 1 , h -- h
0 - 1 , -- a
2 - 1 , ea -- i
1 - 2 , d -- te
0 - 1 , -- s
0 - 1 , -- h
0 - 1 , -- e
0 - 1 , -- n
0 - 1 , -- g
:
院
懷
海
德
生
</figure>
<subsectionHeader confidence="0.991143">
3.1 Linguistic Processing
</subsectionHeader>
<bodyText confidence="0.968659928571429">
Some language-dependent knowledge can be integrated
to further improve the performance, especially when we
focus on specific language pairs.
Linguistic Processing Rule 1 (R1):
Some source words have both transliteration and trans-
lation, which are equally acceptable and can be used
interchangeably. For example, the source word “Eng-
land” is translated into “英國 (Yingkou)” and transliter-
ated into “英格蘭 (Yingkolan)”, respectively, as shown
in Figure 5. Since the proposed model is designed spe-
cifically for transliteration, such cases may cause prob-
lems. One way to overcome this limitation is to handle
those cases by using a list of commonly used proper
names and translations.
</bodyText>
<figure confidence="0.902226375">
England vs. 英國
The Spanish Armada sailed to England in
1588.
西班牙無敵艦隊於一五八八年出征英國。
England vs.英格蘭
England is the only country coterminous
with Wales.
英格蘭是唯一與威爾斯毗連的國家。
</figure>
<figureCaption confidence="0.998281">
Figure 5. Examples of mixed usages of
translation and transliteration.
</figureCaption>
<bodyText confidence="0.955936">
Linguistic Processing Rule 2 (R2):
From error analysis of the aligned results of the training
set, the proposed approach suffers from the fluid TUs,
such as “t”, “d”, “tt”, “dd”, “te”, and “de”. Sometimes
they are omitted in transliteration, and sometimes they
are transliterated as a Chinese character. For instance,
“d” is usually transliterated into “特”, “得”, or “德”
corresponding to Chinese TU of “te”. The English TU
“d” is transliterated as “德” in (Clifford, 克利福德), but
</bodyText>
<figureCaption confidence="0.823815">
left out in (Radford, 雷德福). In the example shown in
Figure 6, “David (大衛)” is mistakenly matched up with
“大衛的”.
Figure 6. Example of the transliterated
word extraction for “David”.
</figureCaption>
<bodyText confidence="0.999590428571429">
However, that problem caused by fluid TUs
can be partly overcome by adding more linguistic
constraints in the post-processing phase. We calcu-
late the Chinese character distributions of proper
nouns from a bilingual proper name list. A small
set of Chinese characters is often used for translit-
eration. Therefore, it is possible to improve the
performance by pruning extra tailing characters,
which do not belong to the transliterated character
set, from the transliteration candidates. For in-
stance, the probability of “的, 去, 說, 是, 有” being
used in transliteration is very low. So correct trans-
literation “ 大 衛 ” for the source word “David”
could be extracted by removing the character “的”.
</bodyText>
<subsectionHeader confidence="0.9987615">
3.2 Working Flow by Integrating Linguistic and
Statistical Information
</subsectionHeader>
<bodyText confidence="0.99930965">
Combining the linguistic processing and transliteration
model, we present the algorithm for transliteration ex-
traction as follows:
Step 1: Look up the translation list as stated in
R1. If the translation of a source word
appears in both the entry of the transla-
tion list and the aligned target sentence
(or paragraph), then pick the translation
as the target word. Otherwise, go to Step
2.
Step 2: Pass the source word and its aligned tar-
get sentence (or paragraph) through the
proposed model to extract the target
word.
Step 3: Apply linguistic processing R2 to re-
move superfluous tailing characters in
the target word.
After the above processing, the performance of
source-target word extraction is significantly improved
over the previous experiment.
</bodyText>
<equation confidence="0.731045">
(A boy by the name of David.)
名叫 大 衛 的 一個男孩。
</equation>
<bodyText confidence="0.962019">
...... Ta Wei Te .........
......... David.
</bodyText>
<sectionHeader confidence="0.99737" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9986255">
In this section, we focus on the setup of experiments
and performance evaluation for the proposed model.
</bodyText>
<subsectionHeader confidence="0.993929">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999898866666667">
The corpus T0 for training consists of 2,430 pairs of
English names together with their Chinese translitera-
tions. Two experiments are conducted. In the first ex-
periment, we analyze the convergence characteristics of
this model training based on a similarity-based frame-
work (Chen et al., 1998; Lin and Chen, 2002). A valida-
tion set T1, consisting of 150 unseen person name pairs,
was collected from Sinorama Magazine (Sinorama,
2002). For each transliterated word in T1, a set of 1,557
proper names is used as potential answers. In the second
experiment, a parallel corpus T2 was prepared to evalu-
ate the performance of proposed methods. T2 consists of
500 bilingual examples from the English-Chinese ver-
sion of the Longman Dictionary of Contempory English
(LDOCE) (Proctor, 1988).
</bodyText>
<subsectionHeader confidence="0.993583">
4.2 Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.99978975">
In the first experiment, a set of source words was com-
pared with a given target word, and then was ranked by
similarity scores. The source word with the highest
similarity score is chosen as the answer to the back-
transliteration problem. The performance is evaluated
by rates of the Average Rank (AR) and the Average
Reciprocal Rank (ARR) following Voorhees and Tice
(2000).
</bodyText>
<equation confidence="0.791968">
(16)
</equation>
<bodyText confidence="0.998895">
where N is the number of testing data, and R(i) is the
rank of the i-th testing data. Higher values of ARR indi-
cate better performance.
</bodyText>
<figureCaption confidence="0.9621035">
Figure 7. Performance at each iteration on
the validation set T1.
</figureCaption>
<bodyText confidence="0.998147666666667">
In Figure 7, we show the rates of AR and ARR for the
validation set T1 by varying the number of iterations of
the EM training algorithm from 1 to 6. We note that the
rates become saturated at the 2nd iteration, which indi-
cates the efficiency of the proposed training approach.
As for the second experiment, performance on the
extraction of transliterations is evaluated based on pre-
cision and recall rates on the word and character level.
Since we consider exact one proper name in the source
language and one transliteration in the target language at
a time. The word recall rates are same as word precision
rates:
</bodyText>
<figure confidence="0.9559236">
Word Precision (WP
number of correctly extracted words .(17)
number of correct words
The character level recall and precision are as follows:
Character precision (CP
number of correctly extracted characters (18)
,
Character Recall (CR) =
number of correctly extracted characters .(19)
number of correct characters
</figure>
<bodyText confidence="0.999554136363636">
For the purpose of easier evaluation, T2 was de-
signed to contain exact one proper name in the source
language and one transliteration in the target language
for each bilingual example. Therefore, if more than one
proper name occurs in a bilingual example, we separate
them into several testing examples. We also separate a
compound proper name in one example into individual
names to form multiple examples. For example, in the
first case, two proper names “Tchaikovsky” and “Stra-
vinsky” were found in the testing sample “Tchaikovsky
and Stravinsky each wrote several famous ballets”. In
the second case, a compound proper name “Cyril
Tourneur” was found in “No one knows who wrote that
play, but it is usually ascribed to Cyril Tourneur”. How-
ever, in the third case, “New York” is transliterated as a
whole Chinese word “紐約”, so it can not be separated
into two words. Therefore, the testing data for the above
examples will be semi-automatically constructed. For
simplicity, we considered each proper name in the
source sentence in turn and determined its correspond-
ing transliteration independently. Table 1 shows some
examples of the testing set T2.
</bodyText>
<figure confidence="0.924528086956522">
N
∑=
N i 1
AR
=
1
R(i)
(15)
N
∑=
i 1
1
1
N
R(i)
=
ARR
Rate of AR
2.5
3.5
0.5
1.5
2
3
0
1
1 2 3 4 5
Iteration number
0.84
0.82
0.8
0.78
0.76
0.74
0.72
Rate of ARR
AR
ARR
)
=
)
=
number of correct characters
He is a (second) Caesar in speech and leader-
ship.
他在演說及領導方面0才能有如凱撒再世.
</figure>
<table confidence="0.9937479">
Can you adduce any reason at all for his
strange behaviour, Holmes?
福爾摩斯, 你能否舉出什麼理由解釋他0古
怪行為?
They appointed him to catch all the rats in
/Hy�a�gmge{lliin. /y� .J�.�.}
�L!511 JTp//ICIL!5�/�** 區 有0老鼠.
Drink nRoo Rossignol,ssiigmol, the aristocrat of table wines!
喝羅 ++
這是餐酒中0上品!
Cleopatra was bitten by an asp.
克利XIA特拉女王是被小毒蛇咬死0.
Schoenberg used atonality in the music of his
middle period.
桑伯格在中期用無調性方式作曲.
Now that this painting has been authenticated
as a Rembrandt, it&apos;s worth 10 times as much
as I paid for it!
由於這幅畫已證實是倫布朗真蹟, 它0時價
是我當初買下來時0十fAR!
</table>
<tableCaption confidence="0.999782">
Table 1. Part of bilingual examples of the test-
</tableCaption>
<bodyText confidence="0.981345428571428">
ing set T2.
In the experiment of transliterated word extraction,
the proposed method achieves on average 86.0% word
accuracy rate, 94.4% character precision rate, and
96.3% character recall rate, as shown in row 1 of Table
2. The performance can be further improved with a sim-
ple statistical and linguistic processing, as shown in
</bodyText>
<tableCaption confidence="0.969336">
Table 2.
</tableCaption>
<table confidence="0.9990316">
Methods WP CP CR
Baseline 86.0% 94.4% 96.3%
Baseline+R1 88.6% 95.4% 97.7%
Baseline+R2 90.8% 97.4% 95.9%
Baseline+R1+R2 94.2% 98.3% 97.7%
</table>
<tableCaption confidence="0.977503">
Table 2. The experimental results of transliter-
ated word extraction for T2.
</tableCaption>
<bodyText confidence="0.99827">
In the baseline model, we find that there are some
errors caused by translations which are not strictly trans-
literated; and there are some source words transferred
into target words by means of transliteration and transla-
tion mutually. Therefore, R1 can be viewed as the pre-
processing to extract transliterated words. Some errors
are further eliminated by R2 which considers the usage
of the transliterated characters in the target language. In
this experiment, we use a transliterated character set of
735 Chinese characters.
</bodyText>
<sectionHeader confidence="0.999253" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99996">
In this paper, we describe a framework to deal with the
problem of acquiring English-Chinese bilingual translit-
erated word pairs from parallel-aligned texts. An unsu-
pervised learning approach to the proposed machine
transliteration model is also presented. The proposed
approach automatically learned the parameters of the
model from a bilingual proper name list. It is not re-
stricted to the availability of pronunciation dictionary in
the source language. From the experimental results, it
indicates that our methods achieve excellent perform-
ance. With the statistical-based characteristic of the pro-
posed model, we plan to extend the experiments to bi-
directional transliteration and other different corpora.
</bodyText>
<sectionHeader confidence="0.998972" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997828433333334">
Yaser Al-Onaizan and Kevin Knight. 2002. Translating
named entities using monolingual and bilingual re-
sources. In Proceedings of the 40th Annual Meeting
of the Association for Computational Linguistics
(ACL), pages 400-408.
Hsin-Hsi Chen, Sheng-Jie Huang, Yung-Wei Ding, and
Shih-Chung Tsai. 1998. Proper name translation in
cross-language information retrieval. In Proceedings
of 17th COLING and 36th ACL, pages 232-236.
Yuen Ren Chao. 1968. A Grammar of spoken Chinese.
Berkeley, University of California Press.
Dagan, I., Church, K. W., and Gale, W. A. 1993. Robust
bilingual word alignment for machine aided transla-
tion. In Proceedings of the Workshop on Very Large
Corpora: Academic and Industrial Perspectives,
pages 1-8, Columbus Ohio.
Jose B. Cibelli, Robert P. Lanza, Michael D. West, and
Carol Ezzell. 2002. What Clones? Scientific Ameri-
can, Inc., New York, January.
http://www.sciam.com.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Maximum likelihood from incomplete data via the
EM algorithm. Journal of the Royal Statistical Soci-
ety, 39(1):1-38.
G. D. Forney. 1973. The Viterbi algorithm. Proceedings
of IEEE, 61:268-278, March.
Kevin Knight and Jonathan Graehl. 1998. Machine
transliteration. Computational Linguistics,
24(4):599-612.
Julian Kupiec. 1993. An algorithm for finding noun
phrase correspondences in bilingual corpora. In Pro-
ceedings of the 40th Annual Conference of the
Machine Translation in the Americas, pages 206–
213.
Association for Computational Linguistics (ACL),
pages 17-22, Columbus, Ohio.
Jae Sung Lee and Key-Sun Choi. 1997. A statistical
method to generate various foreign word translitera-
tions in multilingual information retrieval system. In
Proceedings of the 2nd International Workshop on
Information Retrieval with Asian Languages
(IRAL&apos;97), pages 123-128, Tsukuba, Japan.
Wei-Hao Lin and Hsin-Hsi Chen. 2002. Backward
transliteration by learning phonetic similarity. In
CoNLL-2002, Sixth Conference on Natural Lan-
guage Learning, Taipei, Taiwan.
Christopher D. Manning and Hinrich Schutze. 1999.
Foundations of Statistical Natural Language Proc-
essing, MIT Press; 1st edition.
I Dan Melamed. 1996. Automatic construction of clean
broad coverage translation lexicons. In Proceedings
of the 2nd Conference of the Association for Ma-
chine Translation in the Americas (AMTA&apos;96),
Montreal, Canada.
Jong-Hoon Oh and Key-Sun Choi. 2002. An English-
Korean transliteration model using pronunciation
and contextual rules. In Proceedings of the 19th In-
ternational Conference on Computational Linguis-
tics (COLING), Taipei, Taiwan.
P. Proctor, 1988. Longman English-Chinese Dictionary
of Contemporary English, Longman Group (Far
East) Ltd., Hong Kong.
Sinorama. 2002. Sinorama Magazine.
http://www.greatman.com.tw/sinorama.htm.
Bonnie Glover Stalls and Kevin Knight. 1998. Translat-
ing names and technical terms in Arabic text. In
Proceedings of the COLING/ACL Workshop on
Computational Approaches to Semitic Languages.
Frank Z. Smadja, Kathleen McKeown, and Vasileios
Hatzivassiloglou. 1996. Translating collocations for
bilingual lexicons: a statistical approach. Computa-
tional Linguistics, 22(1):1-38.
Keita Tsuji. 2002. Automatic extraction of translational
Japanese-KATAKANA and English word pairs
from bilingual corpora. International Journal of
Computer Processing of Oriental Languages,
15(3):261-279.
Ellen M. Voorhees and Dawn M. Tice. 2000. The trec-8
question answering track report. In English Text Re-
trieval Conference (TREC-B).
Stephen Wan and Cornelia Maria Verspoor. 1998.
Automatic English-Chinese name transliteration for
development of multilingual resources. In Proceed-
ings of 17th COLING and 36th ACL, pages 1352-
1356.
J. C. Wells. 2001. Longman Pronunciation Dictionary
(New Edition), Addison Wesley Longman, Inc.
Dekai Wu and Xuanyin Xia. 1994. Learning an English-
Chinese lexicon from a parallel corpus. In Proceed-
ings of the First Conference of the Association for
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.404593">
<title confidence="0.985887">Acquisition of English-Chinese Transliterated Word Pairs from Parallel-</title>
<author confidence="0.426367">Aligned Texts using a Statistical Machine Transliteration Model</author>
<affiliation confidence="0.879662">Chunghwa Telecom Co.,</affiliation>
<address confidence="0.949821">Chungli, Taiwan,</address>
<email confidence="0.994554">cjlee@cht.com.tw</email>
<abstract confidence="0.999829222222222">This paper presents a framework for extracting English and Chinese transliterated word pairs from parallel texts. The approach is based on the statistical machine transliteration model to exploit the phonetic similarities between English words and corresponding Chinese transliterations. For a given proper noun in English, the proposed method extracts the corresponding transliterated word from the aligned text in Chinese. Under the proposed approach, the parameters of the model are automatically learned from a bilingual proper name list. Experimental results show that the average rates of word and character precision are 86.0% and 94.4%, respectively. The rates can be further improved with the addition of simple linguistic processing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Translating named entities using monolingual and bilingual resources.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>400--408</pages>
<contexts>
<context position="2346" citStr="Al-Onaizan and Knight, 2002" startWordPosition="335" endWordPosition="338">lingual dictionaries. Thus, it is difficult to handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transl</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yaser Al-Onaizan and Kevin Knight. 2002. Translating named entities using monolingual and bilingual resources. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 400-408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsin-Hsi Chen</author>
<author>Sheng-Jie Huang</author>
<author>Yung-Wei Ding</author>
<author>Shih-Chung Tsai</author>
</authors>
<title>Proper name translation in cross-language information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of 17th COLING and 36th ACL,</booktitle>
<pages>232--236</pages>
<contexts>
<context position="2382" citStr="Chen et al., 1998" startWordPosition="341" endWordPosition="344">handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either</context>
<context position="17825" citStr="Chen et al., 1998" startWordPosition="3154" endWordPosition="3157">ance of source-target word extraction is significantly improved over the previous experiment. (A boy by the name of David.) 名叫 大 衛 的 一個男孩。 ...... Ta Wei Te ......... ......... David. 4 Experiments In this section, we focus on the setup of experiments and performance evaluation for the proposed model. 4.1 Experimental Setup The corpus T0 for training consists of 2,430 pairs of English names together with their Chinese transliterations. Two experiments are conducted. In the first experiment, we analyze the convergence characteristics of this model training based on a similarity-based framework (Chen et al., 1998; Lin and Chen, 2002). A validation set T1, consisting of 150 unseen person name pairs, was collected from Sinorama Magazine (Sinorama, 2002). For each transliterated word in T1, a set of 1,557 proper names is used as potential answers. In the second experiment, a parallel corpus T2 was prepared to evaluate the performance of proposed methods. T2 consists of 500 bilingual examples from the English-Chinese version of the Longman Dictionary of Contempory English (LDOCE) (Proctor, 1988). 4.2 Evaluation Metric In the first experiment, a set of source words was compared with a given target word, an</context>
</contexts>
<marker>Chen, Huang, Ding, Tsai, 1998</marker>
<rawString>Hsin-Hsi Chen, Sheng-Jie Huang, Yung-Wei Ding, and Shih-Chung Tsai. 1998. Proper name translation in cross-language information retrieval. In Proceedings of 17th COLING and 36th ACL, pages 232-236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuen Ren Chao</author>
</authors>
<title>A Grammar of spoken Chinese.</title>
<date>1968</date>
<publisher>Berkeley, University of California Press.</publisher>
<contexts>
<context position="6155" citStr="Chao, 1968" startWordPosition="944" endWordPosition="945">her romanization systems. The language model gives the prior probability P(E) which can be modeled using maximum likelihood estimation. As for the transliteration model P(C|E), we can approximate it using the transliteration unit (TU), which is a decomposition of E and C. TU is defined as a se1 Ref. sites: “http://www.romanization.com/index.html” and “http://www.edepot.com/taoroman.html”. quence of characters transliterated as a base unit. For English, a TU can be a monograph, a digraph, or a trigraph (Wells, 2001). For Chinese, a TU can be a syllable initial, a syllable final, or a syllable (Chao, 1968) represented by corresponding romanized characters. To illustrate how this approach works, take the example of an English name, “Smith”, which can be segmented into four TUs and aligned with the romanized transliteration. Assuming that the word is segmented into “S-m-i-th”, then a possible alignment with the Chinese transliteration “史密斯 (Shihmissu)” is depicted in Figure 2. Figure 2. TU alignment between English and Chinese romanized character sequences. 2.2 Formal Description: Statistical Transliteration Model (STM) A word E with l characters and a romanized word C with n characters are denot</context>
</contexts>
<marker>Chao, 1968</marker>
<rawString>Yuen Ren Chao. 1968. A Grammar of spoken Chinese. Berkeley, University of California Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>K W Church</author>
<author>W A Gale</author>
</authors>
<title>Robust bilingual word alignment for machine aided translation.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives,</booktitle>
<pages>1--8</pages>
<location>Columbus Ohio.</location>
<contexts>
<context position="1363" citStr="Dagan et al., 1993" startWordPosition="191" endWordPosition="194">atically learned from a bilingual proper name list. Experimental results show that the average rates of word and character precision are 86.0% and 94.4%, respectively. The rates can be further improved with the addition of simple linguistic processing. 1 Introduction Automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (NLP), such as machine translation (MT), crosslanguage information retrieval (CLIR), and bilingual text alignment. As noted in Tsuji (2002), many previous methods (Dagan et al., 1993; Kupiec, 1993; Wu and Xia, 1994; Melamed, 1996; Smadja et al., 1996) deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to lowfrequency words, such as transliterated words. These transliterated words are often domain-specific and created frequently. Many of them are not found in existing bilingual dictionaries. Thus, it is difficult to handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition </context>
</contexts>
<marker>Dagan, Church, Gale, 1993</marker>
<rawString>Dagan, I., Church, K. W., and Gale, W. A. 1993. Robust bilingual word alignment for machine aided translation. In Proceedings of the Workshop on Very Large Corpora: Academic and Industrial Perspectives, pages 1-8, Columbus Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jose B Cibelli</author>
<author>Robert P Lanza</author>
<author>Michael D West</author>
<author>Carol Ezzell</author>
</authors>
<title>What Clones?</title>
<date>2002</date>
<publisher>Scientific American, Inc.,</publisher>
<location>New York, January. http://www.sciam.com.</location>
<contexts>
<context position="12726" citStr="Cibelli et al., 2002" startWordPosition="2276" endWordPosition="2279"> align parallel texts at the sentence level. Then, we use a tagger to identify proper nouns in the source text. After that, the model is applied to isolate the transliteration in the target text. In general, the proposed transliteration model could be further augmented with linguistic processing, which will be described in more details in the next subsection. The overall process is summarized in Figure 3. Bilingual corpus Proper names: Source &amp; Target words Figure 3. The overall process for the extraction of transliteration from parallel text. An excerpt from the magazine Scientific American (Cibelli et al., 2002) is illustrated as follows: Source sentence: “Rudolf Jaenisch, a cloning expert at the Whitehead Institute for Biomedical Research at the Massachusetts Institute of Technology, concurred:” Target sentence: “麻省理工學院懷海德生物醫學研究院的複製 專家傑尼西說:” In the above excerpt, three English proper nouns “Jaenisch”, “Whitehead”, and “Massachusetts” are identified by a tagger. Utilizing Eqs. (7) and the DP approach formulated by Eqs. (8)-(10), we found the target word “huaihaite ( 懷 海 德 )” most likely corresponding to “Whitehead”. In order to retrieve the transliteration for a given proper noun, we need to keep tra</context>
</contexts>
<marker>Cibelli, Lanza, West, Ezzell, 2002</marker>
<rawString>Jose B. Cibelli, Robert P. Lanza, Michael D. West, and Carol Ezzell. 2002. What Clones? Scientific American, Inc., New York, January. http://www.sciam.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society,</journal>
<pages>39--1</pages>
<contexts>
<context position="10971" citStr="Dempster et al., 1977" startWordPosition="1986" endWordPosition="1989">re allowed to be matched together. An English consonant is also allowed to matching with a Chinese syllable beginning with same or similar phonemes. An English semivowel TU can either be matched with a Chinese consonant or a vowel with same or similar phonemes, or be matched with a Chinese syllable beginning with same or similar phonemes. As for the probability of match type, P(h, k) , it is set to uniform distribution in the initialization phase, shown as follows: 1 P h k = ( , ) ,(14) T where T is the total number of match types allowed. Based on the Expectation Maximization (EM) algorithm (Dempster et al., 1977) with Viterbi decoding (Forney, 1973), the iterative parameter estimation procedure is described as follows: Step 1 (Initialization): Use Eq. (13) to generate likely TU alignment pairs. Calculate the initial model parameters, P(vj |ui) and P(h, k) , using Eq. (11) and Eq. (12). Step 2 (Expection): Based on current model parameters, find the best Viterbi path for each E and C word pair in the training set. Step 3 (Maximization): Based on all the TU alignment pairs obtained from Step 2, calculate the new model parameters using Eqs. (11) and (12). Replace the model parameters with the new model p</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, 39(1):1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G D Forney</author>
</authors>
<title>The Viterbi algorithm.</title>
<date>1973</date>
<booktitle>Proceedings of IEEE,</booktitle>
<pages>61--268</pages>
<contexts>
<context position="11008" citStr="Forney, 1973" startWordPosition="1993" endWordPosition="1994">consonant is also allowed to matching with a Chinese syllable beginning with same or similar phonemes. An English semivowel TU can either be matched with a Chinese consonant or a vowel with same or similar phonemes, or be matched with a Chinese syllable beginning with same or similar phonemes. As for the probability of match type, P(h, k) , it is set to uniform distribution in the initialization phase, shown as follows: 1 P h k = ( , ) ,(14) T where T is the total number of match types allowed. Based on the Expectation Maximization (EM) algorithm (Dempster et al., 1977) with Viterbi decoding (Forney, 1973), the iterative parameter estimation procedure is described as follows: Step 1 (Initialization): Use Eq. (13) to generate likely TU alignment pairs. Calculate the initial model parameters, P(vj |ui) and P(h, k) , using Eq. (11) and Eq. (12). Step 2 (Expection): Based on current model parameters, find the best Viterbi path for each E and C word pair in the training set. Step 3 (Maximization): Based on all the TU alignment pairs obtained from Step 2, calculate the new model parameters using Eqs. (11) and (12). Replace the model parameters with the new model parameters. If it reaches a stopping c</context>
</contexts>
<marker>Forney, 1973</marker>
<rawString>G. D. Forney. 1973. The Viterbi algorithm. Proceedings of IEEE, 61:268-278, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<pages>24--4</pages>
<contexts>
<context position="2471" citStr="Knight and Graehl, 1998" startWordPosition="354" endWordPosition="357">f transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either a language-dependent penalty function to measure the similarity between bilingual word p</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4):599-612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Kupiec</author>
</authors>
<title>An algorithm for finding noun phrase correspondences in bilingual corpora.</title>
<date>1993</date>
<booktitle>In Proceedings of the 40th Annual Conference of the Machine Translation in the Americas,</booktitle>
<pages>206--213</pages>
<contexts>
<context position="1377" citStr="Kupiec, 1993" startWordPosition="195" endWordPosition="196">m a bilingual proper name list. Experimental results show that the average rates of word and character precision are 86.0% and 94.4%, respectively. The rates can be further improved with the addition of simple linguistic processing. 1 Introduction Automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (NLP), such as machine translation (MT), crosslanguage information retrieval (CLIR), and bilingual text alignment. As noted in Tsuji (2002), many previous methods (Dagan et al., 1993; Kupiec, 1993; Wu and Xia, 1994; Melamed, 1996; Smadja et al., 1996) deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to lowfrequency words, such as transliterated words. These transliterated words are often domain-specific and created frequently. Many of them are not found in existing bilingual dictionaries. Thus, it is difficult to handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English an</context>
</contexts>
<marker>Kupiec, 1993</marker>
<rawString>Julian Kupiec. 1993. An algorithm for finding noun phrase correspondences in bilingual corpora. In Proceedings of the 40th Annual Conference of the Machine Translation in the Americas, pages 206– 213.</rawString>
</citation>
<citation valid="false">
<title>Association for Computational Linguistics (ACL),</title>
<pages>17--22</pages>
<location>Columbus, Ohio.</location>
<marker></marker>
<rawString>Association for Computational Linguistics (ACL), pages 17-22, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jae Sung Lee</author>
<author>Key-Sun Choi</author>
</authors>
<title>A statistical method to generate various foreign word transliterations in multilingual information retrieval system.</title>
<date>1997</date>
<booktitle>In Proceedings of the 2nd International Workshop on Information Retrieval with Asian Languages (IRAL&apos;97),</booktitle>
<pages>123--128</pages>
<location>Tsukuba, Japan.</location>
<contexts>
<context position="2511" citStr="Lee and Choi, 1997" startWordPosition="360" endWordPosition="363">ce of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either a language-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping r</context>
<context position="8934" citStr="Lee and Choi, 1997" startWordPosition="1545" endWordPosition="1548"> can be computed using a dynamic programming (DP) strategy, as shown in the following: Step 1 (Initialization): S(0,0) = 0 Step 2 (Recursion): S(i, j)= max S(i − h, j − k) h,k Therefore, the translation probability P(vj |ui) can be approximated as follows: The probability of the match type, P(h, k) , can be estimated as follows: count h k ( , ) P h k ( , ) ∑∑ = i j For the reason that count(ui,vj) is unknown in the beginning , a reasonable initial estimate of the parameters of the translation model is to constrain the TU alignments of a word pair (E, C) within a position disp h + − 1 tance δ (Lee and Choi, 1997). Assume that ui e p = q k + −1 and vj c q , and dδ (ui, vj) is the allowable posi= tion distance within δ for the aligned pair (ui, vi). dδ (ui, vj) is defined as follows: ≈∏ P(vi |ui)P(mi). (6) Therefore, we have N N i=1 log ( |E) max ∑= (logP(vi |ui)+logP(mi)) P C ≈ i 1 M P(vj |ui) = count(u) i count (ui , vj ) . ) . ( , ) i j count q − p δ, × l &lt; and , ( +k− 1)×l q &lt; + δ (p h 1) − − n log ( |) log ( , ) P c e j i + + P h k j k − i h − 0≤i≤l, 0≤ j≤ n. (9) Step 3 (Termination): dδ(ui,vj)= n (13)       S l n ( , ) max = S(l − h, n − k) h,k log ( |) log ( , ) P c e n l + + P h k n k − l </context>
</contexts>
<marker>Lee, Choi, 1997</marker>
<rawString>Jae Sung Lee and Key-Sun Choi. 1997. A statistical method to generate various foreign word transliterations in multilingual information retrieval system. In Proceedings of the 2nd International Workshop on Information Retrieval with Asian Languages (IRAL&apos;97), pages 123-128, Tsukuba, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei-Hao Lin</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Backward transliteration by learning phonetic similarity.</title>
<date>2002</date>
<booktitle>In CoNLL-2002, Sixth Conference on Natural Language Learning,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="2402" citStr="Lin and Chen, 2002" startWordPosition="345" endWordPosition="348">ion only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either a language-dependen</context>
<context position="17846" citStr="Lin and Chen, 2002" startWordPosition="3158" endWordPosition="3161">et word extraction is significantly improved over the previous experiment. (A boy by the name of David.) 名叫 大 衛 的 一個男孩。 ...... Ta Wei Te ......... ......... David. 4 Experiments In this section, we focus on the setup of experiments and performance evaluation for the proposed model. 4.1 Experimental Setup The corpus T0 for training consists of 2,430 pairs of English names together with their Chinese transliterations. Two experiments are conducted. In the first experiment, we analyze the convergence characteristics of this model training based on a similarity-based framework (Chen et al., 1998; Lin and Chen, 2002). A validation set T1, consisting of 150 unseen person name pairs, was collected from Sinorama Magazine (Sinorama, 2002). For each transliterated word in T1, a set of 1,557 proper names is used as potential answers. In the second experiment, a parallel corpus T2 was prepared to evaluate the performance of proposed methods. T2 consists of 500 bilingual examples from the English-Chinese version of the Longman Dictionary of Contempory English (LDOCE) (Proctor, 1988). 4.2 Evaluation Metric In the first experiment, a set of source words was compared with a given target word, and then was ranked by </context>
</contexts>
<marker>Lin, Chen, 2002</marker>
<rawString>Wei-Hao Lin and Hsin-Hsi Chen. 2002. Backward transliteration by learning phonetic similarity. In CoNLL-2002, Sixth Conference on Natural Language Learning, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schutze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing,</booktitle>
<publisher>MIT Press;</publisher>
<note>1st edition.</note>
<contexts>
<context position="13555" citStr="Manning and Schutze, 1999" startWordPosition="2406" endWordPosition="2409">e: “麻省理工學院懷海德生物醫學研究院的複製 專家傑尼西說:” In the above excerpt, three English proper nouns “Jaenisch”, “Whitehead”, and “Massachusetts” are identified by a tagger. Utilizing Eqs. (7) and the DP approach formulated by Eqs. (8)-(10), we found the target word “huaihaite ( 懷 海 德 )” most likely corresponding to “Whitehead”. In order to retrieve the transliteration for a given proper noun, we need to keep track of the optimal TU decoding sequence associated with the given Chinese term for each word pair under the proposed method. The aligned TUs can be easily obtained via backtracking the best Viterbi path (Manning and Schutze, 1999). For the example mentioned above, the alignments of the TU matching pairs via the Viterbi backtracking path are illustrated in Figure 4. Figure 4. The alignments of the TU matching pairs via the Viterbi backtracking path. Linguistic processing Transliterator Preprocessing Proper names: Word extraction Source word Source sentence Sentence alignment Target sentence Match Type TU Pair : 0 - 1 , -- y 0 - 1 , -- u 0 - 1 , -- a 0 - 1 , -- n 2 - 2 , Wh--hu 1 - 1 , i -- a 1 - 0 , t -- 1 - 1 , e -- i 1 - 1 , h -- h 0 - 1 , -- a 2 - 1 , ea -- i 1 - 2 , d -- te 0 - 1 , -- s 0 - 1 , -- h 0 - 1 , -- e 0 -</context>
</contexts>
<marker>Manning, Schutze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Schutze. 1999. Foundations of Statistical Natural Language Processing, MIT Press; 1st edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic construction of clean broad coverage translation lexicons.</title>
<date>1996</date>
<booktitle>In Proceedings of the 2nd Conference of the Association for Machine Translation in the Americas (AMTA&apos;96),</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="1410" citStr="Melamed, 1996" startWordPosition="201" endWordPosition="202">Experimental results show that the average rates of word and character precision are 86.0% and 94.4%, respectively. The rates can be further improved with the addition of simple linguistic processing. 1 Introduction Automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (NLP), such as machine translation (MT), crosslanguage information retrieval (CLIR), and bilingual text alignment. As noted in Tsuji (2002), many previous methods (Dagan et al., 1993; Kupiec, 1993; Wu and Xia, 1994; Melamed, 1996; Smadja et al., 1996) deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to lowfrequency words, such as transliterated words. These transliterated words are often domain-specific and created frequently. Many of them are not found in existing bilingual dictionaries. Thus, it is difficult to handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pai</context>
</contexts>
<marker>Melamed, 1996</marker>
<rawString>I Dan Melamed. 1996. Automatic construction of clean broad coverage translation lexicons. In Proceedings of the 2nd Conference of the Association for Machine Translation in the Americas (AMTA&apos;96), Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Key-Sun Choi</author>
</authors>
<title>An EnglishKorean transliteration model using pronunciation and contextual rules.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING),</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="2531" citStr="Oh and Choi, 2002" startWordPosition="364" endWordPosition="367">this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either a language-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping rules for translitera</context>
</contexts>
<marker>Oh, Choi, 2002</marker>
<rawString>Jong-Hoon Oh and Key-Sun Choi. 2002. An EnglishKorean transliteration model using pronunciation and contextual rules. In Proceedings of the 19th International Conference on Computational Linguistics (COLING), Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Proctor</author>
</authors>
<title>Longman English-Chinese Dictionary of Contemporary English,</title>
<date>1988</date>
<institution>Longman Group (Far East) Ltd., Hong Kong.</institution>
<contexts>
<context position="18313" citStr="Proctor, 1988" startWordPosition="3235" endWordPosition="3236">nt, we analyze the convergence characteristics of this model training based on a similarity-based framework (Chen et al., 1998; Lin and Chen, 2002). A validation set T1, consisting of 150 unseen person name pairs, was collected from Sinorama Magazine (Sinorama, 2002). For each transliterated word in T1, a set of 1,557 proper names is used as potential answers. In the second experiment, a parallel corpus T2 was prepared to evaluate the performance of proposed methods. T2 consists of 500 bilingual examples from the English-Chinese version of the Longman Dictionary of Contempory English (LDOCE) (Proctor, 1988). 4.2 Evaluation Metric In the first experiment, a set of source words was compared with a given target word, and then was ranked by similarity scores. The source word with the highest similarity score is chosen as the answer to the backtransliteration problem. The performance is evaluated by rates of the Average Rank (AR) and the Average Reciprocal Rank (ARR) following Voorhees and Tice (2000). (16) where N is the number of testing data, and R(i) is the rank of the i-th testing data. Higher values of ARR indicate better performance. Figure 7. Performance at each iteration on the validation se</context>
</contexts>
<marker>Proctor, 1988</marker>
<rawString>P. Proctor, 1988. Longman English-Chinese Dictionary of Contemporary English, Longman Group (Far East) Ltd., Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sinorama</author>
</authors>
<date>2002</date>
<note>Sinorama Magazine. http://www.greatman.com.tw/sinorama.htm.</note>
<contexts>
<context position="17966" citStr="Sinorama, 2002" startWordPosition="3179" endWordPosition="3180">.. Ta Wei Te ......... ......... David. 4 Experiments In this section, we focus on the setup of experiments and performance evaluation for the proposed model. 4.1 Experimental Setup The corpus T0 for training consists of 2,430 pairs of English names together with their Chinese transliterations. Two experiments are conducted. In the first experiment, we analyze the convergence characteristics of this model training based on a similarity-based framework (Chen et al., 1998; Lin and Chen, 2002). A validation set T1, consisting of 150 unseen person name pairs, was collected from Sinorama Magazine (Sinorama, 2002). For each transliterated word in T1, a set of 1,557 proper names is used as potential answers. In the second experiment, a parallel corpus T2 was prepared to evaluate the performance of proposed methods. T2 consists of 500 bilingual examples from the English-Chinese version of the Longman Dictionary of Contempory English (LDOCE) (Proctor, 1988). 4.2 Evaluation Metric In the first experiment, a set of source words was compared with a given target word, and then was ranked by similarity scores. The source word with the highest similarity score is chosen as the answer to the backtransliteration </context>
</contexts>
<marker>Sinorama, 2002</marker>
<rawString>Sinorama. 2002. Sinorama Magazine. http://www.greatman.com.tw/sinorama.htm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Glover Stalls</author>
<author>Kevin Knight</author>
</authors>
<title>Translating names and technical terms in Arabic text.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages.</booktitle>
<marker>Stalls, Knight, 1998</marker>
<rawString>Bonnie Glover Stalls and Kevin Knight. 1998. Translating names and technical terms in Arabic text. In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Z Smadja</author>
<author>Kathleen McKeown</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Translating collocations for bilingual lexicons: a statistical approach.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="1432" citStr="Smadja et al., 1996" startWordPosition="203" endWordPosition="206">sults show that the average rates of word and character precision are 86.0% and 94.4%, respectively. The rates can be further improved with the addition of simple linguistic processing. 1 Introduction Automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (NLP), such as machine translation (MT), crosslanguage information retrieval (CLIR), and bilingual text alignment. As noted in Tsuji (2002), many previous methods (Dagan et al., 1993; Kupiec, 1993; Wu and Xia, 1994; Melamed, 1996; Smadja et al., 1996) deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to lowfrequency words, such as transliterated words. These transliterated words are often domain-specific and created frequently. Many of them are not found in existing bilingual dictionaries. Thus, it is difficult to handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the propos</context>
</contexts>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>Frank Z. Smadja, Kathleen McKeown, and Vasileios Hatzivassiloglou. 1996. Translating collocations for bilingual lexicons: a statistical approach. Computational Linguistics, 22(1):1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keita Tsuji</author>
</authors>
<title>Automatic extraction of translational Japanese-KATAKANA and English word pairs from bilingual corpora.</title>
<date>2002</date>
<journal>International Journal of Computer Processing of Oriental Languages,</journal>
<pages>15--3</pages>
<contexts>
<context position="1320" citStr="Tsuji (2002)" startWordPosition="186" endWordPosition="187">the parameters of the model are automatically learned from a bilingual proper name list. Experimental results show that the average rates of word and character precision are 86.0% and 94.4%, respectively. The rates can be further improved with the addition of simple linguistic processing. 1 Introduction Automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (NLP), such as machine translation (MT), crosslanguage information retrieval (CLIR), and bilingual text alignment. As noted in Tsuji (2002), many previous methods (Dagan et al., 1993; Kupiec, 1993; Wu and Xia, 1994; Melamed, 1996; Smadja et al., 1996) deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to lowfrequency words, such as transliterated words. These transliterated words are often domain-specific and created frequently. Many of them are not found in existing bilingual dictionaries. Thus, it is difficult to handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this pa</context>
</contexts>
<marker>Tsuji, 2002</marker>
<rawString>Keita Tsuji. 2002. Automatic extraction of translational Japanese-KATAKANA and English word pairs from bilingual corpora. International Journal of Computer Processing of Oriental Languages, 15(3):261-279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
<author>Dawn M Tice</author>
</authors>
<title>The trec-8 question answering track report.</title>
<date>2000</date>
<booktitle>In English Text Retrieval Conference (TREC-B).</booktitle>
<contexts>
<context position="18710" citStr="Voorhees and Tice (2000)" startWordPosition="3300" endWordPosition="3303">, a parallel corpus T2 was prepared to evaluate the performance of proposed methods. T2 consists of 500 bilingual examples from the English-Chinese version of the Longman Dictionary of Contempory English (LDOCE) (Proctor, 1988). 4.2 Evaluation Metric In the first experiment, a set of source words was compared with a given target word, and then was ranked by similarity scores. The source word with the highest similarity score is chosen as the answer to the backtransliteration problem. The performance is evaluated by rates of the Average Rank (AR) and the Average Reciprocal Rank (ARR) following Voorhees and Tice (2000). (16) where N is the number of testing data, and R(i) is the rank of the i-th testing data. Higher values of ARR indicate better performance. Figure 7. Performance at each iteration on the validation set T1. In Figure 7, we show the rates of AR and ARR for the validation set T1 by varying the number of iterations of the EM training algorithm from 1 to 6. We note that the rates become saturated at the 2nd iteration, which indicates the efficiency of the proposed training approach. As for the second experiment, performance on the extraction of transliterations is evaluated based on precision an</context>
</contexts>
<marker>Voorhees, Tice, 2000</marker>
<rawString>Ellen M. Voorhees and Dawn M. Tice. 2000. The trec-8 question answering track report. In English Text Retrieval Conference (TREC-B).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Wan</author>
<author>Cornelia Maria Verspoor</author>
</authors>
<title>Automatic English-Chinese name transliteration for development of multilingual resources.</title>
<date>1998</date>
<booktitle>In Proceedings of 17th COLING and 36th ACL,</booktitle>
<pages>1352--1356</pages>
<contexts>
<context position="2427" citStr="Wan and Verspoor, 1998" startWordPosition="349" endWordPosition="352">dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model. Jason S. Chang2 2 Department of Computer Science National Tsing Hua University Hsinchu, Taiwan, R.O.C. jschang@cs.nthu.edu.tw Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic (Al-Onaizan and Knight, 2002), English/Chinese (Chen et al., 1998; Lin and Chen, 2002; Wan and Verspoor, 1998), English/Japanese (Knight and Graehl, 1998), and English/Korean (Lee and Choi, 1997; Oh and Choi, 2002). Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration. However, words with unknown pronunciations may cause problems for transliteration. In addition, using either a language-dependent penalty function to mea</context>
</contexts>
<marker>Wan, Verspoor, 1998</marker>
<rawString>Stephen Wan and Cornelia Maria Verspoor. 1998. Automatic English-Chinese name transliteration for development of multilingual resources. In Proceedings of 17th COLING and 36th ACL, pages 1352-1356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Wells</author>
</authors>
<title>Longman Pronunciation Dictionary (New Edition),</title>
<date>2001</date>
<publisher>Addison Wesley Longman, Inc.</publisher>
<contexts>
<context position="6064" citStr="Wells, 2001" startWordPosition="926" endWordPosition="927">m to romanize Chinese characters. However, the proposed approach is equally applicable to other romanization systems. The language model gives the prior probability P(E) which can be modeled using maximum likelihood estimation. As for the transliteration model P(C|E), we can approximate it using the transliteration unit (TU), which is a decomposition of E and C. TU is defined as a se1 Ref. sites: “http://www.romanization.com/index.html” and “http://www.edepot.com/taoroman.html”. quence of characters transliterated as a base unit. For English, a TU can be a monograph, a digraph, or a trigraph (Wells, 2001). For Chinese, a TU can be a syllable initial, a syllable final, or a syllable (Chao, 1968) represented by corresponding romanized characters. To illustrate how this approach works, take the example of an English name, “Smith”, which can be segmented into four TUs and aligned with the romanized transliteration. Assuming that the word is segmented into “S-m-i-th”, then a possible alignment with the Chinese transliteration “史密斯 (Shihmissu)” is depicted in Figure 2. Figure 2. TU alignment between English and Chinese romanized character sequences. 2.2 Formal Description: Statistical Transliteratio</context>
</contexts>
<marker>Wells, 2001</marker>
<rawString>J. C. Wells. 2001. Longman Pronunciation Dictionary (New Edition), Addison Wesley Longman, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Xuanyin Xia</author>
</authors>
<title>Learning an EnglishChinese lexicon from a parallel corpus.</title>
<date>1994</date>
<booktitle>In Proceedings of the First Conference of the Association</booktitle>
<publisher>for</publisher>
<contexts>
<context position="1395" citStr="Wu and Xia, 1994" startWordPosition="197" endWordPosition="200">proper name list. Experimental results show that the average rates of word and character precision are 86.0% and 94.4%, respectively. The rates can be further improved with the addition of simple linguistic processing. 1 Introduction Automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (NLP), such as machine translation (MT), crosslanguage information retrieval (CLIR), and bilingual text alignment. As noted in Tsuji (2002), many previous methods (Dagan et al., 1993; Kupiec, 1993; Wu and Xia, 1994; Melamed, 1996; Smadja et al., 1996) deal with this problem based on frequency of words appearing in the corpora, which can not be effectively applied to lowfrequency words, such as transliterated words. These transliterated words are often domain-specific and created frequently. Many of them are not found in existing bilingual dictionaries. Thus, it is difficult to handle transliteration only via simple dictionary lookup. For CLIR, the accuracy of transliteration highly affects the performance of retrieval. In this paper, we present a framework of acquisition for English and Chinese translit</context>
</contexts>
<marker>Wu, Xia, 1994</marker>
<rawString>Dekai Wu and Xuanyin Xia. 1994. Learning an EnglishChinese lexicon from a parallel corpus. In Proceedings of the First Conference of the Association for</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>