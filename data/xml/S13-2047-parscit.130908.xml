<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000029">
<title confidence="0.7310005">
SOFTCARDINALITY: Hierarchical Text Overlap
for Student Response Analysis
</title>
<author confidence="0.735052">
Sergio Jimenez, Claudia Becerra
</author>
<affiliation confidence="0.654354">
Universidad Nacional de Colombia
</affiliation>
<address confidence="0.753342">
Ciudad Universitaria,
edificio 453, oficina 114
Bogotá, Colombia
</address>
<email confidence="0.988105">
sgjimenezv@unal.edu.co
cjbecerrac@unal.edu.co
</email>
<sectionHeader confidence="0.996639" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996542476190476">
In this paper we describe our system used to
participate in the Student-Response-Analysis
task-7 at SemEval 2013. This system is based
on text overlap through the soft cardinality and
a new mechanism for weight propagation. Al-
though there are several official performance
measures, taking into account the overall ac-
curacy throughout the two availabe data sets
(Beetle and SciEntsBank), our system ranked
first in the 2 way classification task and sec-
ond in the others. Furthermore, our sys-
tem performs particularly well with “unseen-
domains” instances, which was the more chal-
lenging test set. This paper also describes an-
other system that integrates this method with
the lexical-overlap baseline provided by the
task organizers obtaining better results than
the best official results. We concluded that the
soft cardinality method is a very competitive
baseline for the automatic evaluation of stu-
dent responses.
</bodyText>
<sectionHeader confidence="0.998881" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997489">
The Student-Response-Analysis (SRA) task consist
in provide assessments of the correctness of student
answers (A), considering their corresponding ques-
tions (Q) and reference answers (RA) (Dzikovska
et al., 2012). SRA is the task-7 in the SemEval
2013 evaluation campaign (Dzikovska et al., 2013).
The method used in our participation was basically
text overlap based on the soft cardinality (Jimenez
et al., 2010) plus a machine learning classifier. This
method did not use any information external to the
</bodyText>
<note confidence="0.8532002">
Alexander Gelbukh
CIC-IPN
Av. Juan Dios Bátiz, Av. Mendizábal,
Col. Nueva Industrial Vallejo
CP 07738, DF, México
</note>
<email confidence="0.968368">
gelbukh@gelbukh.com
</email>
<bodyText confidence="0.999896617647059">
data sets except for a stemmer and a list of stop
words.
The soft cardinality is a general model for object
comparison that has been tested at text applications.
Particularly, this text overlap approach has provided
strong baselines for several applications, i.e. entity
resolution (Jimenez et al., 2010), semantic textual
similarity (Jimenez et al., 2012a), cross-lingual tex-
tual entailment (Jimenez et al., 2012b), information
retrieval, textual entailment and paraphrase detec-
tion (Jimenez and Gelbukh, 2012). A brief descrip-
tion of the soft cardinality is presented in the next
section.
The data for SRA consist of two data sets Bee-
tle (5,199 instances) and SciEntsBank (10,804 in-
stances) divided into training and test sets (76%-
24% for Beetle and 46%-54% SciEntsBank). In ad-
dition, the test part of Beetle data set was divided
into two test sets: “unseen answers” (35%) and “un-
seen questions” (65%). Similarity, SciEntsBank test
part is divided into “unseen answers” (9%), “unseen
questions” (13%) and “unseen domains” (78%). All
texts are in English.
The challenge consists in predicting for each in-
stance triple (Q, A, RA) an assessment of correct-
ness for the student’s answer. Three levels of detail
are considered for this assessment: 2 way (correct
and incorrect), 3 way (correct, contradictory and in-
correct) and 5 way (correct, incomplete, contradic-
tory, irrelevant and non-in-the-domain).
Section 3 presents the method used for the extrac-
tion of features from texts using the soft cardinal-
ity to provide a vector representation. In Section 4,
the details of the system used to produce our predic-
</bodyText>
<page confidence="0.901747">
280
</page>
<bodyText confidence="0.988326846153846">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 280–284, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
tions are presented. Besides, in that section a system
that integrates our system with the lexical-overlap
baseline proposed by the task organizers is also pre-
sented. This combined system was motivated by the
observation that our system performed well in the
SciEntsBank data set but poorly in Beetle in compar-
ison with the lexical-overlap baseline. The results
obtained by both systems are also presented in that
section.
Finally in Section 5 the conclusions of our partic-
ipation in this evaluation campaign are presented.
</bodyText>
<sectionHeader confidence="0.889597" genericHeader="introduction">
2 Soft Cardinality
</sectionHeader>
<bodyText confidence="0.986751">
The soft cardinality (Jimenez et al., 2010) of a col-
lection of elements S is calculated with the follow-
ing expression:
</bodyText>
<equation confidence="0.971259375">
Having
={s1,
... ,
0; p
0;
1 &gt; sim(x, y)
0, x
y; and sim(x, x) = 1.
</equation>
<bodyText confidence="0.951847818181818">
The parameter p controls the degree of &amp;quot;softness&amp;quot;
of the cardinality (the larger the
In fact,
the soft cardinality is equivalent to
classical set cardinality. The default value for this
parameter is p = 1. The coefficients
are weights
associated with each element, which can represent
the importance or informative character of each ele-
ment. The function sim is a similarity function that
compares pairs of elements in the collection S.
</bodyText>
<equation confidence="0.897980888888889">
S
s2,
sn};wi≥
≥
≥
=6
“harder”).
→∞
wi
</equation>
<bodyText confidence="0.937944037037037">
281 approaches. First, using the information retrieval ap-
proach, the document is considered like a very long
sentence and the comparison is then straight for-
ward. Another approach is to make pairwise com-
parisons between the sentence and each sentence in
the document. Then, the similarity scores of these
comparisons can be aggregated in a single score
using average, max or min functions. These ap-
proaches have issues, the former ignores the sen-
tence subdivision of the document and the later ig-
nores the similarities among the sentences in the
document.
In the task at hand, each instance is composed of
a question Q, a student answer A, which are sen-
tences, and a collection of reference answers RA,
which could be considered as amulti-sentence doc-
ument. The soft cardinality can be used to provide
values for
and
The intersections that involve RA require
sues.
as
. Similarly, a combined representation us-
ing a range of q-grams of different length can be
denoted as
For instance, if
then
</bodyText>
<equation confidence="0.962387083333333">
|Q|0,|A|0,|RA|0,|Q∩A|0,|A∩RA|0
|Q∩RA|0.
Let’s
t1
t[q]i
t[q1:q2]
i .
t1=“home”
t[2:3]
1 ={“ho”,“om”,“me”,“hom”,“ome”}.
t[q1:q2] and t[q1:q2] representations can be com-
1 2
</equation>
<bodyText confidence="0.971539">
pared using the Dice’s coefficient to build aword-
similarity function:
</bodyText>
<equation confidence="0.9936176">
⎛
Xn
wi · ⎝sim(si, sj)p
|S|0 =
Xn
i=1
j=1
ties
Two words (or terms)
simwords(t1,t2) =
</equation>
<bodyText confidence="0.8837015">
a special treatment to tackle the aforementioned is-
start defining aword-similarity function.
</bodyText>
<equation confidence="0.9273945">
�����
�t[q1:q2]
2 · 1 ∩ t[q1:q2]
2
</equation>
<bodyText confidence="0.996156">
and t2 can be compared di-
viding them into character q-grams (Kukich, 1992).
The representation in q-grams of ti can be denoted
</bodyText>
<equation confidence="0.965267">
~(2)
����t[q1:q2]
�t[q1:q2] ��� + ���
1 1
Thus,
</equation>
<bodyText confidence="0.896872888888889">
means classical cardinality and
soft
cardinality.
The function
can be plugged in
to
obtain the soft cardinality of a sentence
(using uni-
tary weights
</bodyText>
<equation confidence="0.943786428571429">
= 1 an
|x|
|x|0
simwords
eq.1
S
wi
</equation>
<bodyText confidence="0.94143">
d p = 1):
tence and a document can |S|0 = X |S |⎛ simword(ti, tj) ⎞ −1
be obtained with different i=1 X|S |⎠ (1)
⎝j=1 when p
3 Features from Cardinali
It is commonly accepted that it is possible to make
a fair comparison of two objects if they are of the
same nature. If the objects are instances of a com-
positional hierarchy, they should belong to the same
class to be comparable. Clearly, a house is compa-
rable with another house, a wall with another wall
and a brick with another brick, but walls and bricks
are not comparable (at least not directly). Similarly,
in text applications documents should be compared
with documents, sentences with sentences, words
with words, and so on.
However, a comparison measure between a sen-
</bodyText>
<table confidence="0.904748375">
Note that in eq. 2 the classical set cardinality was
used, i.e
⎞ −1
⎠ (3)
|X ||Y  ||X U Y |
|Q|0 BF2: |A|0 BF3: |Q U A|0
|A|0 |RA|00 BF5: |RA U A|00
BF1: |Q|0 BF4: |RA|00 BF6: |RA U Q|00
</table>
<tableCaption confidence="0.99955">
Table 1: Basic feature set
</tableCaption>
<bodyText confidence="0.9945736">
Where ti are the words in the sentence S .
The sentence-soft-cardinality function can be
used to build a sentence-similarity function to com-
pare two sentences S1 and S2 using again the Dice’s
coefficient:
</bodyText>
<table confidence="0.991129692307692">
EF1: |X n Y  |EF2: |X \ Y |
EF3: |Y \ X |EF4: |X∩Y |
|X|
EF5: |X∩Y  |EF6: |X∩Y |
|Y  ||X∪Y |
EF7: 2·|X∩Y  |EF8: |X∩Y |
|X|+|Y  |&apos;|X|·|Y |
EF9: X∩ |EF10: X∩|
mil(|XY|Y |) |(|XI,|Y
m |)
EF11: |·(|X|+|Y |) EF12: |X ∪ Y  |− |X ∩ Y |
|X∩2·|X
|·|Y|
</table>
<tableCaption confidence="0.999463">
Table 2: Extended feature set
</tableCaption>
<bodyText confidence="0.989438666666667">
Y |. Consequently, the total number of features is 6
basic features plus 12 extended features multiplied
by 3, i.e. 42 features.
</bodyText>
<equation confidence="0.8913945">
sim����.(S1,S2) = |S1 |+ |S2|
4 Systems Description
2 · (|S1|0 + |S2|0 − |S1 U S2|0)
(4)
</equation>
<bodyText confidence="0.9984752">
In this formulation S1 US2 is the concatenation of
both sentences.
The eq. 4 can be plugged again into eq. 1 to obtain
the soft cardinality of a “document” RA, which is a
collection of sentences RA = {S1, S2.... , S|RA|}:
</bodyText>
<equation confidence="0.994054">
⎛ ⎞−1
|RA|
X
|Si|0 · ⎝ sim(Si, Sj) ⎠(5)
j=1
</equation>
<bodyText confidence="0.983734476190476">
Note that the soft cardinalities of the sentences
|Si|0 were re-used as importance weights wi in eq.
1. These weights are propagations of the unitary
weights assigned to the words, which in turn were
aggregated by the soft cardinality at sentence level
(eq. 3). This soft cardinality is denoted with double
apostrophe because is a function recursively based
in the single-apostrophized soft cardinality.
The proposed soft cardinality expressions are
used to obtain the basic feature set presented in Ta-
ble 1. The soft cardinalities of |Q|0, |A|0 and |QUA|0
are calculated with eq. 3. The soft cardinalities
|RA|00, |RAUA|00 and |RAUQ|00 are calculated with
eq. 5. Recall that Q U A is the concatenation of the
question and answer sentences. Similarly, RA U A
and RA U Q are the collection of reference answers
adding A xor Q .
Starting from the basic feature set, an extended
set, showed in Table 2, can be obtained from each
one of the three rows in Table 1. Recall that |X n
Y  |= |X|+|Y |−|XUY  |and |X\Y  |= |X|−|Xn
</bodyText>
<subsectionHeader confidence="0.994219">
4.1 Submitted System
</subsectionHeader>
<bodyText confidence="0.999747631578947">
First, each text in the SRA data was preprocessed by
tokenizing, lowercasing, stop-words1 removing and
stemming with the Porter’s algorithm (Porter, 1980).
Second, each stemmed word t was represented in
q-grams: t[3:4] for Beetle and t[4] for SciEntsBank.
These representations obtained the best accuracies
in the training data sets.
Two vector data sets were obtained extracting the
42 features–described in Section 3–for each instance
in Beetle and SciEntsBank separately. Then, three
classification models (2 way, 3way and 5 way) were
learned from the training partitions on each vector
data set using a J48 graft tree (Webb, 1999). All
6 resulting classification models were boosted with
15 iterations of bagging (Breiman, 1996). The used
implementation of this classifier was that included
in WEKA v.3.6.9 (Hall et al., 2009). The results
obtained by this system are shown in Table 3 in the
rows labeled with “Soft Cardinality-run1”.
</bodyText>
<subsectionHeader confidence="0.999713">
4.2 An Improved System
</subsectionHeader>
<bodyText confidence="0.999857428571429">
At the time when the official results were released,
we observed that our submitted system performed
pretty well in SciEntsBank but poorly in Beetle.
Moreover, the lexical-overlap baseline outperformed
our system in Beetle. Firstly, we decided to include
in our feature set the 8 features of the lexical over-
lap baseline described by Dzikovska et al. (2012)
</bodyText>
<footnote confidence="0.848577">
1those provided by nltk.org
</footnote>
<equation confidence="0.95245375">
|RA|
X
i=1
|RA|00 =
</equation>
<page confidence="0.991842">
282
</page>
<table confidence="0.984219684210526">
Beetle SciEntsBank
Task System UA1 UQ2 All UA1 UQ2 UD3 All All Rank
2 way Soft Cardinality-unofficial 0.797 0.725 0.750 0.717 0.733 0.726 0.726 0.730 -
Soft Cardinality-run1 0.781 0.667 0.707 0.724 0.745 0.711 0.716 0.715 1
ETS-run1 0.811 0.741 0.765 0.722 0.711 0.698 0.702 0.713 2
CU-run1 0.786 0.718 0.742 0.656 0.674 0.693 0.687 0.697 3
Lexical overlap baseline 0.797 0.740 0.760 0.661 0.674 0.676 0.674 0.690 6
3 way Soft Cardinality-unofficial 0.608 0.532 0.559 0.656 0.671 0.646 0.650 0.634 -
ETS-run1 0.633 0.551 0.580 0.626 0.663 0.632 0.635 0.625 1
Soft Cardinality-run1 0.624 0.453 0.513 0.659 0.652 0.637 0.641 0.618 2
CoMeT-run1 0.731 0.518 0.592 0.713 0.546 0.579 0.587 0.588 3
Lexical overlap baseline 0.595 0.512 0.541 0.556 0.540 0.577 0.570 0.565 8
5way Soft Cardinality-unofficial 0.572 0.476 0.510 0.552 0.520 0.534 0.534 0.530 -
ETS-run1 0.574 0.560 0.565 0.543 0.532 0.501 0.509 0.519 1
Soft Cardinality-run1 0.576 0.451 0.495 0.544 0.525 0.512 0.517 0.513 2
ETS-run2 0.715 0.621 0.654 0.631 0.401 0.476 0.481 0.512 3
Lexical overlap baseline 0.519 0.480 0.494 0.437 0.413 0.415 0.417 0.430 11
Total number of test instances 439 819 1,258 540 733 4,562 5,835 7,093
TEST SETS: unseen answers1, unseen questions2, unseen domains3.
</table>
<tableCaption confidence="0.986796">
Table 3: Official results for the top-3 performing systems (among 15), the lexical overlap baseline in the SRA task
SemEval 2013 and unofficial results of the soft cardinality system combined with the lexical overlap (in italics).
Performance measure used: overall accuracy.
</tableCaption>
<bodyText confidence="0.968055076923077">
(see Text::Similarity::Overlaps2 package for more
details).
Secondly, the lexical overlap baseline aggregates
the pairwise scores between each reference answer
and the student answer by taking the maximum
value of the pairwise scores. So, we decided to use
this aggregation mechanism instead of the aggrega-
tion proposed through eq. 3.
Thirdly, only at that time we realized that, unlike
Beetle, in SciEntsBank all instances have only one
reference answer. Consequently, the only effect of
eq. 5 in SciEntsBank was in the calculation of |RA∪
A|&apos;&apos; (and |RA∪Q|&apos;&apos;) by |X∪Y |&apos;&apos; = |X|1+|Y |1
</bodyText>
<equation confidence="0.725165">
1+simsent.(X,Y ).
</equation>
<bodyText confidence="0.998334875">
As a result, this transformation induced a boosting
effect in X ∩Y making |X ∩Y |&apos;&apos; ≥ |X ∩Y |&apos; for any
X, Y . We decided to use this intersection-boosting
effect not only in RA ∩ A, RA ∩ Q, but in Q ∩
A. This intersecton boosting effect works similarly
to the Lesk’s measure (Lesk, 1986) included in the
lexical overlap baseline.
The individual effect in the performance of each
</bodyText>
<footnote confidence="0.540718">
2http://search.cpan.org/dist/Text-
Similarity/lib/Text/Similarity/Overlaps.pm
</footnote>
<bodyText confidence="0.999889333333333">
of the previous decisions was positive in all three
cases. The results obtained using an improved
system that implemented those three decisions are
shown in Table 3–in italics. This system would have
obtained the best general overall accuracy in the of-
ficial ranking.
</bodyText>
<sectionHeader confidence="0.999429" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999911230769231">
We participated in the Student-Response-Analysis
task-7 in SemEval 2013 with a text overlap system
based on the soft cardinality. This system obtained
places 1st (2 way task) and 2nd (3 way and 5 way)
considering the overall accuracy across all data sets
and test sets. Particularly, our system was the best
in the largest and more challenging test set, namely
“unseen domains”. Moreover, we integrated the lex-
ical overlap baseline to our system obtaining even
better results.
As a conclusion, the text overlap method based on
the soft cardinality is very challenging base line for
the SRA task.
</bodyText>
<page confidence="0.99771">
283
</page>
<sectionHeader confidence="0.998182" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999874642857143">
This research was funded in part by the Systems
and Industrial Engineering Department, the Office
of Student Welfare of the National University of
Colombia, Bogotá, and through a grant from the
Colombian Department for Science, Technology
and Innovation, Colciencias, proj. 1101-521-28465
with funding from “El Patrimonio Autónomo Fondo
Nacional de Financiamiento para la Ciencia, la Tec-
nología y la Innovación, Francisco José de Caldas.”
The third author recognizes the support from Mexi-
can Government (SNI, COFAA-IPN, SIP 20131702,
CONACYT 50206-H) and CONACYT–DST India
(proj. 122030 “Answer Validation through Textual
Entailment”).
</bodyText>
<sectionHeader confidence="0.998309" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999472305084746">
Leo Breiman. 1996. Bagging predictors. Machine
Learning, 24(2):123–140.
Myroslava O. Dzikovska, Rodney D. Nielsen, and Chris
Brew. 2012. Towards effective tutorial feedback for
explanation questions: a dataset and baselines. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, NAACL
HLT ’12, page 200–210, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Myroslava O. Dzikovska, Rodney D. Nielsen, Chris
Brew, Claudia Leacock, Danilo Giampiccolo, Luisa
Bentivogli, Peter Clark, Ido Dagan, and Hoa Trang
Dang. 2013. SemEval-2013 task 7: The joint stu-
dent response analysis and 8th recognizing textual en-
tailment challenge. In Proceedings of the 7th Inter-
national Workshop on Semantic Evaluation (SemEval
2013), in conjunction with the Second Joint Confer-
ence on Lexical and Computational Semantcis (*SEM
2013), Atlanta, Georgia, USA, June. Association for
Computational Linguistics.
Mark Hall, Frank Eibe, Geoffrey Holmes, and Bernhard
Pfahringer. 2009. The WEKA data mining software:
An update. SIGKDD Explorations, 11(1):10–18.
Sergio Jimenez and Alexander Gelbukh. 2012. Baselines
for natural language processing tasks. Appl. Comput.
Math., 11(2):180–199.
Sergio Jimenez, Fabio Gonzalez, and Alexander Gel-
bukh. 2010. Text comparison using soft cardinality.
In Edgar Chavez and Stefano Lonardi, editors, String
Processing and Information Retrieval, volume 6393 of
LNCS, pages 297–302. Springer, Berlin, Heidelberg.
Sergio Jimenez, Claudia Becerra, and Alexander Gel-
bukh. 2012a. Soft cardinality: A parameterized simi-
larity function for text comparison. In Proceedings of
the 6th International Workshop on Semantic Evalua-
tion (SemEval, *SEM 2012), Montreal, Canada.
Sergio Jimenez, Claudia Becerra, and Alexander Gel-
bukh. 2012b. Soft cardinality+ ML: learning adaptive
similarity functions for cross-lingual textual entail-
ment. In Proceedings of the 6th International Work-
shop on Semantic Evaluation (SemEval, *SEM 2012),
Montreal, Canada. ACL.
Karen Kukich. 1992. Techniques for automatically
correcting words in text. ACM Computing Surveys,
24:377–439, December.
Michael Lesk. 1986. Automatic sense disambiguation
using machine readable dictionaries: how to tell a pine
cone from an ice cream cone. In Proceedings of the
5th annual international conference on Systems docu-
mentation, SIGDOC ’86, page 24–26, New York, NY,
USA. ACM.
Martin Porter. 1980. An algorithm for suffix stripping.
Program, 3(14):130–137, October.
Geoffrey I. Webb. 1999. Decision tree grafting from the
all-tests-but-one partition. In Proceedings of the 16th
international joint conference on Artificial intelligence
- Volume 2, IJCAI’99, pages 702–707, San Francisco,
CA, USA. Morgan Kaufmann Publishers Inc.
</reference>
<page confidence="0.998373">
284
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.467906">
<title confidence="0.9991185">SOFTCARDINALITY: Hierarchical Text Overlap for Student Response Analysis</title>
<author confidence="0.970157">Sergio Jimenez</author>
<author confidence="0.970157">Claudia</author>
<affiliation confidence="0.707007">Universidad Nacional de Ciudad</affiliation>
<address confidence="0.7620245">edificio 453, oficina Bogotá,</address>
<email confidence="0.987341">cjbecerrac@unal.edu.co</email>
<abstract confidence="0.998162227272727">In this paper we describe our system used to participate in the Student-Response-Analysis task-7 at SemEval 2013. This system is based on text overlap through the soft cardinality and a new mechanism for weight propagation. Although there are several official performance measures, taking into account the overall accuracy throughout the two availabe data sets (Beetle and SciEntsBank), our system ranked in the way task and second in the others. Furthermore, our system performs particularly well with “unseendomains” instances, which was the more challenging test set. This paper also describes another system that integrates this method with the lexical-overlap baseline provided by the task organizers obtaining better results than the best official results. We concluded that the soft cardinality method is a very competitive baseline for the automatic evaluation of student responses.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
</authors>
<title>Bagging predictors.</title>
<date>1996</date>
<booktitle>Machine Learning,</booktitle>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="10372" citStr="Breiman, 1996" startWordPosition="1719" endWordPosition="1720">he Porter’s algorithm (Porter, 1980). Second, each stemmed word t was represented in q-grams: t[3:4] for Beetle and t[4] for SciEntsBank. These representations obtained the best accuracies in the training data sets. Two vector data sets were obtained extracting the 42 features–described in Section 3–for each instance in Beetle and SciEntsBank separately. Then, three classification models (2 way, 3way and 5 way) were learned from the training partitions on each vector data set using a J48 graft tree (Webb, 1999). All 6 resulting classification models were boosted with 15 iterations of bagging (Breiman, 1996). The used implementation of this classifier was that included in WEKA v.3.6.9 (Hall et al., 2009). The results obtained by this system are shown in Table 3 in the rows labeled with “Soft Cardinality-run1”. 4.2 An Improved System At the time when the official results were released, we observed that our submitted system performed pretty well in SciEntsBank but poorly in Beetle. Moreover, the lexical-overlap baseline outperformed our system in Beetle. Firstly, we decided to include in our feature set the 8 features of the lexical overlap baseline described by Dzikovska et al. (2012) 1those provi</context>
</contexts>
<marker>Breiman, 1996</marker>
<rawString>Leo Breiman. 1996. Bagging predictors. Machine Learning, 24(2):123–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myroslava O Dzikovska</author>
<author>Rodney D Nielsen</author>
<author>Chris Brew</author>
</authors>
<title>Towards effective tutorial feedback for explanation questions: a dataset and baselines.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12,</booktitle>
<pages>200--210</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1399" citStr="Dzikovska et al., 2012" startWordPosition="196" endWordPosition="199">ll with “unseendomains” instances, which was the more challenging test set. This paper also describes another system that integrates this method with the lexical-overlap baseline provided by the task organizers obtaining better results than the best official results. We concluded that the soft cardinality method is a very competitive baseline for the automatic evaluation of student responses. 1 Introduction The Student-Response-Analysis (SRA) task consist in provide assessments of the correctness of student answers (A), considering their corresponding questions (Q) and reference answers (RA) (Dzikovska et al., 2012). SRA is the task-7 in the SemEval 2013 evaluation campaign (Dzikovska et al., 2013). The method used in our participation was basically text overlap based on the soft cardinality (Jimenez et al., 2010) plus a machine learning classifier. This method did not use any information external to the Alexander Gelbukh CIC-IPN Av. Juan Dios Bátiz, Av. Mendizábal, Col. Nueva Industrial Vallejo CP 07738, DF, México gelbukh@gelbukh.com data sets except for a stemmer and a list of stop words. The soft cardinality is a general model for object comparison that has been tested at text applications. Particula</context>
<context position="10959" citStr="Dzikovska et al. (2012)" startWordPosition="1812" endWordPosition="1815">terations of bagging (Breiman, 1996). The used implementation of this classifier was that included in WEKA v.3.6.9 (Hall et al., 2009). The results obtained by this system are shown in Table 3 in the rows labeled with “Soft Cardinality-run1”. 4.2 An Improved System At the time when the official results were released, we observed that our submitted system performed pretty well in SciEntsBank but poorly in Beetle. Moreover, the lexical-overlap baseline outperformed our system in Beetle. Firstly, we decided to include in our feature set the 8 features of the lexical overlap baseline described by Dzikovska et al. (2012) 1those provided by nltk.org |RA| X i=1 |RA|00 = 282 Beetle SciEntsBank Task System UA1 UQ2 All UA1 UQ2 UD3 All All Rank 2 way Soft Cardinality-unofficial 0.797 0.725 0.750 0.717 0.733 0.726 0.726 0.730 - Soft Cardinality-run1 0.781 0.667 0.707 0.724 0.745 0.711 0.716 0.715 1 ETS-run1 0.811 0.741 0.765 0.722 0.711 0.698 0.702 0.713 2 CU-run1 0.786 0.718 0.742 0.656 0.674 0.693 0.687 0.697 3 Lexical overlap baseline 0.797 0.740 0.760 0.661 0.674 0.676 0.674 0.690 6 3 way Soft Cardinality-unofficial 0.608 0.532 0.559 0.656 0.671 0.646 0.650 0.634 - ETS-run1 0.633 0.551 0.580 0.626 0.663 0.632 0.</context>
</contexts>
<marker>Dzikovska, Nielsen, Brew, 2012</marker>
<rawString>Myroslava O. Dzikovska, Rodney D. Nielsen, and Chris Brew. 2012. Towards effective tutorial feedback for explanation questions: a dataset and baselines. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12, page 200–210, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Myroslava O Dzikovska</author>
<author>Rodney D Nielsen</author>
<author>Chris Brew</author>
<author>Claudia Leacock</author>
<author>Danilo Giampiccolo</author>
<author>Luisa Bentivogli</author>
<author>Peter Clark</author>
<author>Ido Dagan</author>
<author>Hoa Trang Dang</author>
</authors>
<title>SemEval-2013 task 7: The joint student response analysis and 8th recognizing textual entailment challenge.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantcis (*SEM 2013),</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="1483" citStr="Dzikovska et al., 2013" startWordPosition="210" endWordPosition="213">er also describes another system that integrates this method with the lexical-overlap baseline provided by the task organizers obtaining better results than the best official results. We concluded that the soft cardinality method is a very competitive baseline for the automatic evaluation of student responses. 1 Introduction The Student-Response-Analysis (SRA) task consist in provide assessments of the correctness of student answers (A), considering their corresponding questions (Q) and reference answers (RA) (Dzikovska et al., 2012). SRA is the task-7 in the SemEval 2013 evaluation campaign (Dzikovska et al., 2013). The method used in our participation was basically text overlap based on the soft cardinality (Jimenez et al., 2010) plus a machine learning classifier. This method did not use any information external to the Alexander Gelbukh CIC-IPN Av. Juan Dios Bátiz, Av. Mendizábal, Col. Nueva Industrial Vallejo CP 07738, DF, México gelbukh@gelbukh.com data sets except for a stemmer and a list of stop words. The soft cardinality is a general model for object comparison that has been tested at text applications. Particularly, this text overlap approach has provided strong baselines for several applicatio</context>
</contexts>
<marker>Dzikovska, Nielsen, Brew, Leacock, Giampiccolo, Bentivogli, Clark, Dagan, Dang, 2013</marker>
<rawString>Myroslava O. Dzikovska, Rodney D. Nielsen, Chris Brew, Claudia Leacock, Danilo Giampiccolo, Luisa Bentivogli, Peter Clark, Ido Dagan, and Hoa Trang Dang. 2013. SemEval-2013 task 7: The joint student response analysis and 8th recognizing textual entailment challenge. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantcis (*SEM 2013), Atlanta, Georgia, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Frank Eibe</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
</authors>
<title>The WEKA data mining software: An update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="10470" citStr="Hall et al., 2009" startWordPosition="1733" endWordPosition="1736">t[3:4] for Beetle and t[4] for SciEntsBank. These representations obtained the best accuracies in the training data sets. Two vector data sets were obtained extracting the 42 features–described in Section 3–for each instance in Beetle and SciEntsBank separately. Then, three classification models (2 way, 3way and 5 way) were learned from the training partitions on each vector data set using a J48 graft tree (Webb, 1999). All 6 resulting classification models were boosted with 15 iterations of bagging (Breiman, 1996). The used implementation of this classifier was that included in WEKA v.3.6.9 (Hall et al., 2009). The results obtained by this system are shown in Table 3 in the rows labeled with “Soft Cardinality-run1”. 4.2 An Improved System At the time when the official results were released, we observed that our submitted system performed pretty well in SciEntsBank but poorly in Beetle. Moreover, the lexical-overlap baseline outperformed our system in Beetle. Firstly, we decided to include in our feature set the 8 features of the lexical overlap baseline described by Dzikovska et al. (2012) 1those provided by nltk.org |RA| X i=1 |RA|00 = 282 Beetle SciEntsBank Task System UA1 UQ2 All UA1 UQ2 UD3 All</context>
</contexts>
<marker>Hall, Eibe, Holmes, Pfahringer, 2009</marker>
<rawString>Mark Hall, Frank Eibe, Geoffrey Holmes, and Bernhard Pfahringer. 2009. The WEKA data mining software: An update. SIGKDD Explorations, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Baselines for natural language processing tasks.</title>
<date>2012</date>
<journal>Appl. Comput. Math.,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="2339" citStr="Jimenez and Gelbukh, 2012" startWordPosition="337" endWordPosition="340">IC-IPN Av. Juan Dios Bátiz, Av. Mendizábal, Col. Nueva Industrial Vallejo CP 07738, DF, México gelbukh@gelbukh.com data sets except for a stemmer and a list of stop words. The soft cardinality is a general model for object comparison that has been tested at text applications. Particularly, this text overlap approach has provided strong baselines for several applications, i.e. entity resolution (Jimenez et al., 2010), semantic textual similarity (Jimenez et al., 2012a), cross-lingual textual entailment (Jimenez et al., 2012b), information retrieval, textual entailment and paraphrase detection (Jimenez and Gelbukh, 2012). A brief description of the soft cardinality is presented in the next section. The data for SRA consist of two data sets Beetle (5,199 instances) and SciEntsBank (10,804 instances) divided into training and test sets (76%- 24% for Beetle and 46%-54% SciEntsBank). In addition, the test part of Beetle data set was divided into two test sets: “unseen answers” (35%) and “unseen questions” (65%). Similarity, SciEntsBank test part is divided into “unseen answers” (9%), “unseen questions” (13%) and “unseen domains” (78%). All texts are in English. The challenge consists in predicting for each instan</context>
</contexts>
<marker>Jimenez, Gelbukh, 2012</marker>
<rawString>Sergio Jimenez and Alexander Gelbukh. 2012. Baselines for natural language processing tasks. Appl. Comput. Math., 11(2):180–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Fabio Gonzalez</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Text comparison using soft cardinality.</title>
<date>2010</date>
<booktitle>String Processing and Information Retrieval,</booktitle>
<volume>6393</volume>
<pages>297--302</pages>
<editor>In Edgar Chavez and Stefano Lonardi, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="1601" citStr="Jimenez et al., 2010" startWordPosition="229" endWordPosition="232">nizers obtaining better results than the best official results. We concluded that the soft cardinality method is a very competitive baseline for the automatic evaluation of student responses. 1 Introduction The Student-Response-Analysis (SRA) task consist in provide assessments of the correctness of student answers (A), considering their corresponding questions (Q) and reference answers (RA) (Dzikovska et al., 2012). SRA is the task-7 in the SemEval 2013 evaluation campaign (Dzikovska et al., 2013). The method used in our participation was basically text overlap based on the soft cardinality (Jimenez et al., 2010) plus a machine learning classifier. This method did not use any information external to the Alexander Gelbukh CIC-IPN Av. Juan Dios Bátiz, Av. Mendizábal, Col. Nueva Industrial Vallejo CP 07738, DF, México gelbukh@gelbukh.com data sets except for a stemmer and a list of stop words. The soft cardinality is a general model for object comparison that has been tested at text applications. Particularly, this text overlap approach has provided strong baselines for several applications, i.e. entity resolution (Jimenez et al., 2010), semantic textual similarity (Jimenez et al., 2012a), cross-lingual </context>
<context position="4279" citStr="Jimenez et al., 2010" startWordPosition="643" endWordPosition="646">tion for Computational Linguistics tions are presented. Besides, in that section a system that integrates our system with the lexical-overlap baseline proposed by the task organizers is also presented. This combined system was motivated by the observation that our system performed well in the SciEntsBank data set but poorly in Beetle in comparison with the lexical-overlap baseline. The results obtained by both systems are also presented in that section. Finally in Section 5 the conclusions of our participation in this evaluation campaign are presented. 2 Soft Cardinality The soft cardinality (Jimenez et al., 2010) of a collection of elements S is calculated with the following expression: Having ={s1, ... , 0; p 0; 1 &gt; sim(x, y) 0, x y; and sim(x, x) = 1. The parameter p controls the degree of &amp;quot;softness&amp;quot; of the cardinality (the larger the In fact, the soft cardinality is equivalent to classical set cardinality. The default value for this parameter is p = 1. The coefficients are weights associated with each element, which can represent the importance or informative character of each element. The function sim is a similarity function that compares pairs of elements in the collection S. S s2, sn};wi≥ ≥ ≥ =</context>
</contexts>
<marker>Jimenez, Gonzalez, Gelbukh, 2010</marker>
<rawString>Sergio Jimenez, Fabio Gonzalez, and Alexander Gelbukh. 2010. Text comparison using soft cardinality. In Edgar Chavez and Stefano Lonardi, editors, String Processing and Information Retrieval, volume 6393 of LNCS, pages 297–302. Springer, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Claudia Becerra</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Soft cardinality: A parameterized similarity function for text comparison.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval, *SEM 2012),</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="2183" citStr="Jimenez et al., 2012" startWordPosition="317" endWordPosition="320">oft cardinality (Jimenez et al., 2010) plus a machine learning classifier. This method did not use any information external to the Alexander Gelbukh CIC-IPN Av. Juan Dios Bátiz, Av. Mendizábal, Col. Nueva Industrial Vallejo CP 07738, DF, México gelbukh@gelbukh.com data sets except for a stemmer and a list of stop words. The soft cardinality is a general model for object comparison that has been tested at text applications. Particularly, this text overlap approach has provided strong baselines for several applications, i.e. entity resolution (Jimenez et al., 2010), semantic textual similarity (Jimenez et al., 2012a), cross-lingual textual entailment (Jimenez et al., 2012b), information retrieval, textual entailment and paraphrase detection (Jimenez and Gelbukh, 2012). A brief description of the soft cardinality is presented in the next section. The data for SRA consist of two data sets Beetle (5,199 instances) and SciEntsBank (10,804 instances) divided into training and test sets (76%- 24% for Beetle and 46%-54% SciEntsBank). In addition, the test part of Beetle data set was divided into two test sets: “unseen answers” (35%) and “unseen questions” (65%). Similarity, SciEntsBank test part is divided int</context>
</contexts>
<marker>Jimenez, Becerra, Gelbukh, 2012</marker>
<rawString>Sergio Jimenez, Claudia Becerra, and Alexander Gelbukh. 2012a. Soft cardinality: A parameterized similarity function for text comparison. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval, *SEM 2012), Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Claudia Becerra</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Soft cardinality+ ML: learning adaptive similarity functions for cross-lingual textual entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval, *SEM 2012),</booktitle>
<publisher>ACL.</publisher>
<location>Montreal, Canada.</location>
<contexts>
<context position="2183" citStr="Jimenez et al., 2012" startWordPosition="317" endWordPosition="320">oft cardinality (Jimenez et al., 2010) plus a machine learning classifier. This method did not use any information external to the Alexander Gelbukh CIC-IPN Av. Juan Dios Bátiz, Av. Mendizábal, Col. Nueva Industrial Vallejo CP 07738, DF, México gelbukh@gelbukh.com data sets except for a stemmer and a list of stop words. The soft cardinality is a general model for object comparison that has been tested at text applications. Particularly, this text overlap approach has provided strong baselines for several applications, i.e. entity resolution (Jimenez et al., 2010), semantic textual similarity (Jimenez et al., 2012a), cross-lingual textual entailment (Jimenez et al., 2012b), information retrieval, textual entailment and paraphrase detection (Jimenez and Gelbukh, 2012). A brief description of the soft cardinality is presented in the next section. The data for SRA consist of two data sets Beetle (5,199 instances) and SciEntsBank (10,804 instances) divided into training and test sets (76%- 24% for Beetle and 46%-54% SciEntsBank). In addition, the test part of Beetle data set was divided into two test sets: “unseen answers” (35%) and “unseen questions” (65%). Similarity, SciEntsBank test part is divided int</context>
</contexts>
<marker>Jimenez, Becerra, Gelbukh, 2012</marker>
<rawString>Sergio Jimenez, Claudia Becerra, and Alexander Gelbukh. 2012b. Soft cardinality+ ML: learning adaptive similarity functions for cross-lingual textual entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval, *SEM 2012), Montreal, Canada. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Kukich</author>
</authors>
<title>Techniques for automatically correcting words in text.</title>
<date>1992</date>
<journal>ACM Computing Surveys,</journal>
<pages>24--377</pages>
<contexts>
<context position="6418" citStr="Kukich, 1992" startWordPosition="1008" endWordPosition="1009">using a range of q-grams of different length can be denoted as For instance, if then |Q|0,|A|0,|RA|0,|Q∩A|0,|A∩RA|0 |Q∩RA|0. Let’s t1 t[q]i t[q1:q2] i . t1=“home” t[2:3] 1 ={“ho”,“om”,“me”,“hom”,“ome”}. t[q1:q2] and t[q1:q2] representations can be com1 2 pared using the Dice’s coefficient to build awordsimilarity function: ⎛ Xn wi · ⎝sim(si, sj)p |S|0 = Xn i=1 j=1 ties Two words (or terms) simwords(t1,t2) = a special treatment to tackle the aforementioned isstart defining aword-similarity function. ����� �t[q1:q2] 2 · 1 ∩ t[q1:q2] 2 and t2 can be compared dividing them into character q-grams (Kukich, 1992). The representation in q-grams of ti can be denoted ~(2) ����t[q1:q2] �t[q1:q2] ��� + ��� 1 1 Thus, means classical cardinality and soft cardinality. The function can be plugged in to obtain the soft cardinality of a sentence (using unitary weights = 1 an |x| |x|0 simwords eq.1 S wi d p = 1): tence and a document can |S|0 = X |S |⎛ simword(ti, tj) ⎞ −1 be obtained with different i=1 X|S |⎠ (1) ⎝j=1 when p 3 Features from Cardinali It is commonly accepted that it is possible to make a fair comparison of two objects if they are of the same nature. If the objects are instances of a compositional</context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Karen Kukich. 1992. Techniques for automatically correcting words in text. ACM Computing Surveys, 24:377–439, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proceedings of the 5th annual international conference on Systems documentation, SIGDOC ’86,</booktitle>
<pages>24--26</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="13429" citStr="Lesk, 1986" startWordPosition="2218" endWordPosition="2219">ism instead of the aggregation proposed through eq. 3. Thirdly, only at that time we realized that, unlike Beetle, in SciEntsBank all instances have only one reference answer. Consequently, the only effect of eq. 5 in SciEntsBank was in the calculation of |RA∪ A|&apos;&apos; (and |RA∪Q|&apos;&apos;) by |X∪Y |&apos;&apos; = |X|1+|Y |1 1+simsent.(X,Y ). As a result, this transformation induced a boosting effect in X ∩Y making |X ∩Y |&apos;&apos; ≥ |X ∩Y |&apos; for any X, Y . We decided to use this intersection-boosting effect not only in RA ∩ A, RA ∩ Q, but in Q ∩ A. This intersecton boosting effect works similarly to the Lesk’s measure (Lesk, 1986) included in the lexical overlap baseline. The individual effect in the performance of each 2http://search.cpan.org/dist/TextSimilarity/lib/Text/Similarity/Overlaps.pm of the previous decisions was positive in all three cases. The results obtained using an improved system that implemented those three decisions are shown in Table 3–in italics. This system would have obtained the best general overall accuracy in the official ranking. 5 Conclusions We participated in the Student-Response-Analysis task-7 in SemEval 2013 with a text overlap system based on the soft cardinality. This system obtained</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Michael Lesk. 1986. Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone. In Proceedings of the 5th annual international conference on Systems documentation, SIGDOC ’86, page 24–26, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>3</volume>
<issue>14</issue>
<contexts>
<context position="9794" citStr="Porter, 1980" startWordPosition="1630" endWordPosition="1631">. 3. The soft cardinalities |RA|00, |RAUA|00 and |RAUQ|00 are calculated with eq. 5. Recall that Q U A is the concatenation of the question and answer sentences. Similarly, RA U A and RA U Q are the collection of reference answers adding A xor Q . Starting from the basic feature set, an extended set, showed in Table 2, can be obtained from each one of the three rows in Table 1. Recall that |X n Y |= |X|+|Y |−|XUY |and |X\Y |= |X|−|Xn 4.1 Submitted System First, each text in the SRA data was preprocessed by tokenizing, lowercasing, stop-words1 removing and stemming with the Porter’s algorithm (Porter, 1980). Second, each stemmed word t was represented in q-grams: t[3:4] for Beetle and t[4] for SciEntsBank. These representations obtained the best accuracies in the training data sets. Two vector data sets were obtained extracting the 42 features–described in Section 3–for each instance in Beetle and SciEntsBank separately. Then, three classification models (2 way, 3way and 5 way) were learned from the training partitions on each vector data set using a J48 graft tree (Webb, 1999). All 6 resulting classification models were boosted with 15 iterations of bagging (Breiman, 1996). The used implementat</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Martin Porter. 1980. An algorithm for suffix stripping. Program, 3(14):130–137, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey I Webb</author>
</authors>
<title>Decision tree grafting from the all-tests-but-one partition.</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th international joint conference on Artificial intelligence - Volume 2, IJCAI’99,</booktitle>
<pages>702--707</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="10274" citStr="Webb, 1999" startWordPosition="1705" endWordPosition="1706"> SRA data was preprocessed by tokenizing, lowercasing, stop-words1 removing and stemming with the Porter’s algorithm (Porter, 1980). Second, each stemmed word t was represented in q-grams: t[3:4] for Beetle and t[4] for SciEntsBank. These representations obtained the best accuracies in the training data sets. Two vector data sets were obtained extracting the 42 features–described in Section 3–for each instance in Beetle and SciEntsBank separately. Then, three classification models (2 way, 3way and 5 way) were learned from the training partitions on each vector data set using a J48 graft tree (Webb, 1999). All 6 resulting classification models were boosted with 15 iterations of bagging (Breiman, 1996). The used implementation of this classifier was that included in WEKA v.3.6.9 (Hall et al., 2009). The results obtained by this system are shown in Table 3 in the rows labeled with “Soft Cardinality-run1”. 4.2 An Improved System At the time when the official results were released, we observed that our submitted system performed pretty well in SciEntsBank but poorly in Beetle. Moreover, the lexical-overlap baseline outperformed our system in Beetle. Firstly, we decided to include in our feature se</context>
</contexts>
<marker>Webb, 1999</marker>
<rawString>Geoffrey I. Webb. 1999. Decision tree grafting from the all-tests-but-one partition. In Proceedings of the 16th international joint conference on Artificial intelligence - Volume 2, IJCAI’99, pages 702–707, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>