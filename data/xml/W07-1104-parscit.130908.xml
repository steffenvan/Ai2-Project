<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000124">
<title confidence="0.986198">
Semantics-based Multiword Expression Extraction
</title>
<author confidence="0.991157">
Tim Van de Cruys and Begofna Villada Moir´on
</author>
<affiliation confidence="0.990499">
Alfa Informatica, University of Groningen
</affiliation>
<address confidence="0.7317375">
Oude Kijk in ’t Jatstraat 26
9712 EK Groningen, The Netherlands
</address>
<email confidence="0.999498">
{T.Van.de.Cruys|M.B.Villada.Moiron}@rug.nl
</email>
<sectionHeader confidence="0.998604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999741823529412">
This paper describes a fully unsupervised
and automated method for large-scale ex-
traction of multiword expressions (MWEs)
from large corpora. The method aims at cap-
turing the non-compositionality of MWEs;
the intuition is that a noun within a MWE
cannot easily be replaced by a semanti-
cally similar noun. To implement this intu-
ition, a noun clustering is automatically ex-
tracted (using distributional similarity mea-
sures), which gives us clusters of semanti-
cally related nouns. Next, a number of statis-
tical measures – based on selectional prefer-
ences – is developed that formalize the intu-
ition of non-compositionality. Our approach
has been tested on Dutch, and automatically
evaluated using Dutch lexical resources.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998135631578947">
MWEs are expressions whose linguistic behaviour is
not predictable from the linguistic behaviour of their
component words. Baldwin (2006) characterizes the
idiosyncratic behavior of MWEs as “a lack of com-
positionality manifest at different levels of analysis,
namely, lexical, morphological, syntactic, seman-
tic, pragmatic and statistical”. Some MWEs show
productive morphology and/or syntactic flexibility.
Therefore, these two aspects are not sufficient con-
ditions to discriminate actual MWEs from productive
expressions. Nonetheless, the mentioned character-
istics are useful indicators to distinguish literal and
idiomatic expressions (Fazly and Stevenson, 2006).
One property that seems to affect MWEs the most
is semantic non-compositionality. MWEs are typi-
cally non-compositional. As a consequence, it is not
possible to replace the noun of a MWE by semanti-
cally related nouns. Take for example the expres-
sions in (1) and (2):
</bodyText>
<listItem confidence="0.984566833333333">
(1) a. break the vase
b. break the cup
c. break the dish
(2) a. break the ice
b. *break the snow
c. *break the hail
</listItem>
<bodyText confidence="0.999697352941177">
Expression (1-a) is fully compositional. Therefore,
vase can easily be replaced with semantically re-
lated nouns such as cup and dish. Expression (2-a),
on the contrary, is non-compositional; ice cannot be
replaced with semantically related words, such as
snow and hail without loss of the original meaning.
Due to the idiosyncratic behavior, current propos-
als argue that MWEs need to be described in the lexi-
con (Sag et al., 2002). In most languages, electronic
lexical resources (such as dictionaries, thesauri, on-
tologies) suffer from a limited coverage of MWEs.
To facilitate the update and expansion of language
resources, the NLP community would clearly bene-
fit from automated methods that extract MWEs from
large text collections. This is the main motivation to
pursue an automated and fully unsupervised MWE
extraction method.
</bodyText>
<page confidence="0.982936">
25
</page>
<note confidence="0.9206">
Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.989535" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999933839506173">
Recent proposals that attempt to capture seman-
tic compositionality (or lack thereof) employ vari-
ous strategies. Approaches evaluated so far make
use of dictionaries with semantic annotation (Piao
et al., 2006), WordNet (Pearce, 2001), automati-
cally generated thesauri (Lin, 1999; McCarthy et
al., 2003; Fazly and Stevenson, 2006), vector-based
methods that measure semantic distance (Baldwin et
al., 2003; Katz and Giesbrecht, 2006), translations
extracted from parallel corpora (Villada Moir´on
and Tiedemann, 2006) or hybrid methods that use
machine learning techniques informed by features
coded using some of the above methods (Venkata-
pathy and Joshi, 2005).
Pearce (2001) describes a method to extract collo-
cations from corpora by measuring semantic compo-
sitionality. The underlying assumption is that a fully
compositional expression allows synonym replace-
ment of its component words, whereas a collocation
does not. Pearce measures to what degree a collo-
cation candidate allows synonym replacement. The
measurement is used to rank candidates relative to
their compositionality.
Building on Lin (1998), McCarthy et al. (2003)
measure the semantic similarity between expres-
sions (verb particles) as a whole and their compo-
nent words (verb). They exploit contextual features
and frequency information in order to assess mean-
ing overlap. They established that human composi-
tionality judgements correlate well with those mea-
sures that take into account the semantics of the par-
ticle. Contrary to these measures, standard associ-
ation measures poorly correlate with human judge-
ments.
A different approach proposed by Villada Moir´on
and Tiedemann (2006) measures translational en-
tropy as a sign of meaning predictability, and there-
fore non-compositionality. The entropy observed
among word alignments of a potential MWE varies:
highly predictable alignments show less entropy and
probably correspond to compositional expressions.
Data sparseness and polysemy pose problems be-
cause the entropy cannot be accurately calculated.
Fazly and Stevenson (2006) use lexical and
syntactic fixedness as partial indicators of non-
compositionality. Their method uses Lin’s (1998)
automatically generated thesaurus to compute a met-
ric of lexical fixedness. Lexical fixedness mea-
sures the deviation between the pointwise mutual
information of a verb-object phrase and the aver-
age pointwise mutual information of the expres-
sions resulting from substituting the noun by its
synonyms in the original phrase. This measure is
similar to Lin’s (1999) proposal for finding non-
compositional phrases. Separately, a syntactic flexi-
bility score measures the probability of seeing a can-
didate in a set of pre-selected syntactic patterns. The
assumption is that non-compositional expressions
score high in idiomaticity, that is, a score resulting
from the combination of lexical fixedness and syn-
tactic flexibility. The authors report an 80% accu-
racy in distinguishing literal from idiomatic expres-
sions in a test set of 200 expressions. The perfor-
mance of both metrics is stable across all frequency
ranges.
In this study, we are interested in establishing
whether a fully unsupervised method can capture
the (partial or) non-compositionality of MWEs. The
method should not depend on the existence of large
(open domain) parallel corpora or sense tagged cor-
pora. Also, the method should not require numer-
ous adjustments when applied to new subclasses
of MWEs, for instance, when coding empirical at-
tributes of the candidates. Similar to Lin (1999),
McCarthy et al. (2003) and Fazly and Stevenson
(2006), our method makes use of automatically gen-
erated thesauri; the technique used to compile the
thesauri differs from previous work. Aiming at find-
ing a method of general applicability, the measures
to capture non-compositionality differ from those
employed in earlier work.
</bodyText>
<sectionHeader confidence="0.99807" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.9978229">
In the description and evaluation of our algorithm,
we focus on the extraction of verbal MWEs that con-
tain prepositional complements, although we believe
the method can be easily generalized to other kinds
of MWEs.
In our semantics-based approach, we want to for-
malize the intuition of non-compositionality, so that
MWE extraction can be done in a fully automated
way. A number of statistical measures are developed
that try to capture the MWE’s non-compositional
</bodyText>
<page confidence="0.992265">
26
</page>
<bodyText confidence="0.999052">
bond between a verb-preposition combination and
its noun by comparing the particular noun of a MWE
candidate to other semantically related nouns.
</bodyText>
<subsectionHeader confidence="0.992159">
3.1 Data extraction
</subsectionHeader>
<bodyText confidence="0.999964">
can only be assigned to one cluster. This may pose a
problem for polysemous nouns. On the other hand,
this makes the computation of our metrics straight-
forward, since we do not have to decide among var-
ious senses of a word.
The MWE candidates (verb + prepositional phrase)
are automatically extracted from the Twente Nieuws
Corpus (Ordelman, 2002), a large corpus of Dutch
newspaper texts (500 million words), which has
been automatically parsed by the Dutch dependency
parser Alpino (van Noord, 2006). Next, a matrix is
created of the 5,000 most frequent verb-preposition
combinations by the 10,000 most frequent nouns,
containing the frequency of each MWE candidate.1
To this matrix, a number of statistical measures are
applied to determine the non-compositionality of the
candidate MWEs. These statistical measures are ex-
plained in 3.3.
</bodyText>
<subsectionHeader confidence="0.999023">
3.2 Clustering
</subsectionHeader>
<bodyText confidence="0.999992913043478">
In order to compare a noun to its semantically re-
lated nouns, a noun clustering is created. These
clusters are automatically extracted using standard
distributional similarity techniques (Weeds, 2003;
van der Plas and Bouma, 2005). First, depen-
dency triples are extracted from the Twente Nieuws
Corpus. Next, feature vectors are created for each
noun, containing the frequency of the dependency
relations in which the noun occurs.2 This way, a
frequency matrix of 10K nouns by 100K depen-
dency relations is constructed. The cell frequencies
are replaced by pointwise mutual information scores
(Church et al., 1991), so that more informative fea-
tures get a higher weight. The noun vectors are then
clustered into 1,000 clusters using a simple K-means
clustering algorithm (MacQueen, 1967) with cosine
similarity. During development, several other clus-
tering algorithms and parameters have been tested,
but the settings described above gave us the best
EuroWordNet similarity score (using Wu and Palmer
(1994)).
Note that our clustering algorithm is a hard clus-
tering algorithm, which means that a certain noun
</bodyText>
<footnote confidence="0.685301">
1The lowest frequency verb-preposition combination (with
regard to the 10,000 nouns) appears 3 times.
2e.g. dependency relations that qualify apple might be ‘ob-
ject of eat’ and ‘adjective red’. This gives us dependency triples
like &lt; apple, obj, eat &gt;.
</footnote>
<subsectionHeader confidence="0.994272">
3.3 Measures
</subsectionHeader>
<bodyText confidence="0.966465241379311">
The measures used to find MWEs are inspired by
Resnik’s method to find selectional preferences
(Resnik, 1993; Resnik, 1996). Resnik uses a number
of measures based on the Kullback-Leibler diver-
gence, to measure the difference between the prior
probability of a noun class p(c) and the probabil-
ity of the class given a verb p(clv). We adopt the
method for particular nouns, and add a measure for
determining the ‘unique preference’ of a noun given
other nouns in the cluster, which, we claim, yields
a measure of non-compositionality. In total, 4 mea-
sures are used, the latter two being the symmetric
counterpart of the former two.
The first two measures, Av→n (equation 2) and
Rv→n (equation 3), formalize the unique prefer-
ence of the verb3 for the noun. Equation 1 gives
the Kullback-Leibler divergence between the overall
probability distribution of the nouns and the proba-
bility distribution of the nouns given a verb; it is used
as a normalization constant in equation 2. Equa-
tion 2 models the actual preference of the verb for
the noun.
(2)
Sv
When p(nlv) is 0, Av→n is undefined. In this
case, we assign a score of 0.
Equation 3 gives the ratio of the verb preference
for a particular noun, compared to the other nouns
that are present in the cluster.
</bodyText>
<equation confidence="0.981765">
Av→n (3 )
Rv→n =
En′ǫC Av→n′
</equation>
<bodyText confidence="0.8433265">
When Rv→n is more or less equally divided
among the different nouns in the cluster, there is no
3We will use ‘verb’ to designate a prepositional verb, i.e. a
combination of a verb and a preposition.
</bodyText>
<equation confidence="0.9989886">
�Sv = p(n I v) log p(n I v) (1)
n p(n)
Av→n =
p(n I v) logp(n|v)
p(n)
</equation>
<page confidence="0.983627">
27
</page>
<bodyText confidence="0.999982">
preference of the verb for a particular noun in the
cluster, whereas scores close to 1 indicate a ‘unique’
preference of the verb for a particular noun in the
cluster. Candidates whose Rv→n value approaches
1 are likely to be non-compositional expressions.
In the latter two measures, An→v and Rn→v, the
direction of preference is changed: equations 4 and 5
are the symmetric counterparts of equations 2 and 3.
Instead of the preference of the verb for the noun,
the preference of the noun for the verb is modelled.
Except for the change of preference direction, the
characteristics of the former and the latter two mea-
sures are the same.
</bodyText>
<equation confidence="0.9984965">
An→v = p(v I n) logp(v|n)
Sn p(v) (4)
Rn→v = En′ǫC An′→v
An→v (5)
</equation>
<bodyText confidence="0.999987875">
Note that, despite their symmetry, the measures
for verb preference and the measures for noun pref-
erence are different in nature. It is possible that
a certain verb only selects a restricted number of
nouns, while the nouns themselves can co-occur
with many different verbs. This brings about differ-
ent probability distributions. In our evaluation, we
want to investigate the impact of both preferences.
</bodyText>
<subsectionHeader confidence="0.758701">
3.4 Example
</subsectionHeader>
<bodyText confidence="0.994330666666667">
In this section, an elaborated example is presented,
to show how our method works. Take for example
the two MWE candidates in (3):
</bodyText>
<figure confidence="0.4971448">
a. in
in
to be appreciated
b. in
in
</figure>
<bodyText confidence="0.961437652173913">
to fall down the well
In the first expression, smaak cannot be replaced
with other semantically similar nouns, such as geur
‘smell’ and zicht ‘sight’, whereas in the second ex-
pression, put can easily be replaced with other se-
mantically similar words, such as kuil ‘hole’ and
krater ‘crater’.
The first step in the formalization of this intuition,
is the extraction of the clusters in which the words
smaak and put appear from our clustering database.
This gives us the clusters in (4).
(4) a. smaak: aroma ‘aroma’, gehoor ‘hear-
ing’, geur ‘smell’, gezichtsvermogen
‘sight’, reuk ‘smell’, spraak ‘speech’,
zicht ‘sight’
b. put: afgrond ‘abyss’, bouwput ‘build-
ing excavation’, gaatje ‘hole’, gat
‘hole’, hiaat ‘gap’, hol ‘cave’, kloof
‘gap’, krater ‘crater’, kuil ‘hole’, lacune
‘lacuna’, leemte ‘gap’, valkuil ‘pitfall’
Next, the various measures described in section 3.3
are applied. Resulting scores are given in tables 1
and 2.
</bodyText>
<table confidence="0.99933825">
MWE candidate Av→n Rv→n An→v Rn→v
val#in smaak .12 1.00 .04 1.00
val#in geur .00 .00 .00 .00
val#in zicht .00 .00 .00 .00
</table>
<tableCaption confidence="0.847134">
Table 1: Scores for MWE candidate in de smaak
vallen and other nouns in the same cluster.
Table 1 gives the scores for the MWE in de smaak
</tableCaption>
<bodyText confidence="0.978192166666667">
vallen, together with some other nouns that are
present in the same cluster. Av→n shows that there
is a clear preference (.12) of the verb val in for the
noun smaak. Rv→n shows that there is a unique
preference of the verb for the particular noun smaak.
For the other nouns (geur, zicht, ... ), the verb has no
preference whatsoever. Therefore, the ratio of verb
preference for smaak compared to the other nouns
in the cluster is 1.00.
An→v and Rn→v show similar behaviour. There
is a preference (.04) of the noun smaak for the verb
val in, and this preference is unique (1.00).
</bodyText>
<table confidence="0.9996196">
Av→n Rv→n An→v Rn→v
.00 .05 .00 .05
.01 .11 .02 .37
.00 .02 .00 .03
.04 .71 .01 .24
</table>
<tableCaption confidence="0.9948765">
Table 2: Scores for MWE candidate in de put vallen
and other nouns in same cluster.
</tableCaption>
<figure confidence="0.998916388888889">
(3)
de
the
smaak
taste
vallen
fall
de
the
vallen
fall
put
well
MWE candidate
val#in put
val#in kuil
val#in kloof
val#in gat
</figure>
<page confidence="0.995581">
28
</page>
<bodyText confidence="0.999738">
Table 2 gives the scores for the instance in de put
vallen – which is not a MWE – together with other
nouns from the same cluster. The results are quite
different from the ones in table 1. Av→n – the pref-
erence of the verb for the noun – is quite low in most
cases, the highest score being a score of .04 for gat.
Furthermore, Rv→n does not show a unique pref-
erence of val in for put (a low ratio score of .05).
Instead, the preference mass is divided among the
various nouns in the cluster, the highest preference
of val in being assigned to the noun gat (.71).4
The other two scores show again a similar ten-
dency; An→v – the preference of the noun for the
verb – is low in all cases, and when all nouns in the
cluster are considered (Rn→v), there is no ‘unique’
preference of one noun for the verb val in. Instead,
the preference mass is divided among all nouns in
the cluster.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="evaluation">
4 Results &amp; Evaluation
</sectionHeader>
<subsectionHeader confidence="0.993112">
4.1 Quantitative evaluation
</subsectionHeader>
<bodyText confidence="0.999993136363636">
In this section, we quantitatively evaluate our
method, and compare it to the lexical and syntactic
fixedness measures proposed by Fazly and Steven-
son (2006). More information about Fazly and
Stevenson’s measures can be found in their paper.
The potential MWEs that are extracted with the
fully unsupervised method described above and with
Fazly and Stevenson’s (2006) method (FS from here
onwards) are automatically evaluated by compar-
ing the extracted list to handcrafted MWE databases.
Since we have extracted Dutch MWEs, we are us-
ing the two Dutch resources available: the Refer-
entie Bestand Nederlands (RBN, Martin and Maks
(2005)) and the Van Dale Lexicographical Informa-
tion System (VLIS) database. Evaluation scores are
calculated with regard to the MWEs that are present
in our evaluation resources. Among the MWEs in our
reference data, we consider only those expressions
that are present in our frequency matrix: if the verb
is not among the 5,000 most frequent verbs, or the
noun is not among the 10,000 most frequent nouns,
the frequency information is not present in our input
</bodyText>
<footnote confidence="0.65227175">
4The expression is ambiguous: it can be used in a lit-
eral sense (in een gat vallen, ‘to fall down a hole’) and in a
metaphorical sense (in een zwart gat vallen, ‘to get depressed
after a joyful or busy period’).
</footnote>
<bodyText confidence="0.999964177777778">
data. Consequently, our algorithm would never be
able to find those MWEs.
The first six rows of table 3 show precision, re-
call and f-measure for various parameter thresholds
with regard to the measures Av→n, Rv→n, An→v
and Rn→v, together with the number of candidates
found (n). The last 3 rows show the highest val-
ues we were able to reach by using FS’s fixedness
scores.
Using only two parameters – Av→n and Rv→n –
gives the highest f-measure (f 14%), with a pre-
cision and recall of about 17% and about 12% re-
spectively. Adding parameter Rn→v increases preci-
sion but degrades recall, and this tendency continues
when adding both parameters An→v and Rn→v. In
all cases, a higher threshold increases precision but
degrades recall. When using a high threshold for all
parameters, the algorithm is able to reach a precision
of f 38%, but recall is low (f 4%).
Lexical fixedness reaches an f-measure of f 12%
(threshold of 3.00). These scores show the best per-
formance that we reached using lexical fixedness.
Following FS, we evaluated the syntactic fixedness
scores of expressions falling above a frequency cut-
off. Since our corpus is much larger than that used
by FS, a frequency cutoff of 50 was chosen. The pre-
cision, recall and f-measure of the syntactic fixed-
ness measure (shown on table 3) are f 10%, 41%
and 16% respectively, showing worse precision than
our method but much better recall and f-measure.
As shown by FS, syntactic fixedness performs better
than lexical fixedness; Fixednessoverall improves
on the syntactic fixedness results and also reaches
better overall performance than our method.
The compared methods show a different behav-
ior. FS’s method favours high recall whereas our
method prefers the best trade-off between precision
and recall. We wish to highlight that our method
reaches better precision than FS’s method while han-
dling many low frequency candidates (minimum fre-
quency is 3); this makes our method preferable in
some NLP tasks. It is possible that the two methods
are capturing different properties of MWEs; in future
work, we want to analyse whether the expressions
extracted by the two methods differ.
</bodyText>
<page confidence="0.997043">
29
</page>
<table confidence="0.999878363636364">
parameters precision recall f-measure
Av→n Rv→n An→v Rn→v n (%) (%) (%)
.10 .80 – 3175 16.09 13.11 14.45
.10 .90 – 2655 17.59 11.98 14.25
.10 .80 – .80 2225 19.19 10.95 13.95
.10 .90 – .90 1870 20.70 9.93 13.42
.10 .80 .01 .80 1859 20.33 9.69 13.13
.20 .99 .05 .99 404 38.12 3.95 7.16
Fixednesslex(v, n) 3.00 3899 15.14 9.92 11.99
Fixednesssyn(v, n) 50 15,630 10.20 40.90 16.33
Fixednessoverall(v, n) 50 7819 13.73 27.54 18.33
</table>
<tableCaption confidence="0.99983">
Table 3: Evaluation results compared to RBN &amp; VLIS
</tableCaption>
<subsectionHeader confidence="0.99511">
4.2 Qualitative evaluation
</subsectionHeader>
<bodyText confidence="0.998503545454545">
Next, we elaborate upon advantages and disadvan-
tages of our semantics-based MWE extraction algo-
rithm by examining the output of the procedure, and
looking at the characteristics of the MWEs found and
the errors made by the algorithm.
First of all, our algorithm is able to filter out gram-
matical collocations that cause problems in tradi-
tional MWE extraction paradigms. An example is
given in (5).
filter out non-MWEs like the expressions b in (6)
and (7).
</bodyText>
<listItem confidence="0.936826444444444">
(6) a. verschijnen op toneel
appear on stage
to appear
b. zingen op toneel
sing on stage
to sing on the stage
(7) a. lig in geheugen
lie in memory
be in memory
</listItem>
<figure confidence="0.950874272727273">
voorwaarden
conditions
aan
to
b. lig
lie
eisen,
demands,
(5) voldoen
meet
meet the {demands, conditions}
</figure>
<bodyText confidence="0.993843405405406">
in ziekenhuis
in hospital
lie in the hospital
In traditional MWE extraction algorithms, based on
collocations, highly frequent expressions like the
ones in (5) often get classified as a MWE, even
though they are fully compositional. Such algo-
rithms correctly identify a strong lexical affinity be-
tween two component words (voldoen, aan), which
make up a grammatical collocation; however, they
fail to capture the fact that the noun may be filled in
by a semantic class of nouns. Our algorithm filters
out those expressions, because semantic similarity
between nouns that fill in the object slot is taken into
account.
Our quantitative evaluation shows that the algo-
rithm reaches the best results (i.e. the highest f-
measures) when using only two parameters (Av→n
and Rv→n). Upon closer inspection of the output,
we noticed that An→v and Rn→v are often able to
It is only when the two other measures (a unique
preference of the noun for the verb) are taken into
account that the b expressions are filtered out – ei-
ther because the noun preference for the verb is very
low, or because it is more evenly distributed among
the cluster. The b expressions, which are non-MWEs,
result from the combination of a verb with a highly
frequent PP. These PPs are typically locative, direc-
tional or predicative PPs, that may combine with nu-
merous verbs.
Also, expressions like the ones in (8), where the
fixedness of the expression lies not so much in the
verb-noun combination, but more in the noun part
(naar school, naar huis) are filtered out by the lat-
ter two measures. These preposition-noun combina-
tions seem to be institutionalized PPs, so-called de-
terminerless PPs.
</bodyText>
<page confidence="0.989465">
30
</page>
<figure confidence="0.608784833333333">
(8) a. naar school willen
to school want
want to go to school
b. naar
to
want to go home
</figure>
<bodyText confidence="0.999938461538462">
We will now look at some errors made by our algo-
rithm. First of all, our algorithm highly depends on
the quality of the noun clustering. If a noun appears
in a cluster with unrelated words, the measures will
overrate the semantic uniqueness of the expressions
in which the noun appears.
Secondly, syntax might play an important role.
Sometimes, there are syntactic restrictions between
the preposition and the noun. A noun like pagina
‘page’ can only appear with the preposition op ‘on’,
as in lees op pagina ‘read on page’. Other, semanti-
cally related nouns, such as hoofdstuk ‘chapter’, pre-
fer in ‘in’. Due to these restrictions, the measures
will again overrate the semantic uniqueness of the
noun (pagina in the example).
Finally, our hard clustering method does not take
polysemous nouns into account. A noun may only
occur in one cluster, ignoring other possible mean-
ings. Schaal, for example, means ‘dish’ as well as
‘scale’. In our clustering, it only appears in a cluster
of dish-related nouns. Therefore, expressions like
maak gebruik op [grote] schaal ‘make use of [sth.]
on a [large] scale’, receive again overrated measures
of semantic uniqueness, because the ‘scale’ sense of
the noun is compared to nouns related to the ‘dish’
sense.
</bodyText>
<sectionHeader confidence="0.995537" genericHeader="conclusions">
5 Conclusions and further work
</sectionHeader>
<bodyText confidence="0.999940557377049">
Our algorithm based on non-compositionality ex-
plores a new approach aimed at large-scale MWE
extraction. Using only two parameters, Av,n and
Rv,n, yields the highest f-measure. Using the two
other parameters, An,v and Rn,v, increases preci-
sion but degrades recall. Due to the formalization of
the intuition of non-compositionality (using an auto-
matic noun clustering), our algorithm is able to rule
out various expressions that are coined MWEs by tra-
ditional algorithms.
Note that our algorithm has taken on a purely
semantics-based approach. ‘Syntactic fixedness’ of
the expressions is not taken into account. Combin-
ing our semantics-based approach with other extrac-
tion techniques such as the syntactic fixedness mea-
sure proposed by Fazly and Stevenson (2006) might
improve the results significantly.
We conclude with some issues saved for future
work. First of all, we would like to combine our
semantics-based method with other methods that are
used to find MWEs (especially syntax-based meth-
ods), and implement the method in general classifi-
cation models (decision tree classifier and maximum
entropy model). This includes the use of a more
principled (machine learning) framework in order to
establish the optimal threshold values.
Next, we would like to investigate a number of
topics to improve on our semantics-based method.
First of all, using the top k similar nouns for a certain
noun – instead of the cluster in which a noun appears
– might be more beneficial to get a grasp of the com-
positionality of MWE candidates. Also, making use
of a verb clustering in addition to the noun clustering
might help in determining the non-compositionality
of expressions. Disambiguating among the various
senses of nouns should also be a useful improve-
ment. Furthermore, we would like to generalize our
method to other syntactic patterns (e.g. verb object
combinations), and test the approach for English.
One final issue is the realization of a manual eval-
uation of our semantics-based algorithm, by hav-
ing human judges decide whether a MWE candidate
found by our algorithm is an actual MWE. Our au-
tomated evaluation framework is error-prone due to
mistakes and incompleteness of our resources. Dur-
ing qualitative evaluation, we found many actual
MWEs found by our algorithm, that were not con-
sidered correct by our resources (e.g. [iemand] in
de gordijnen jagen ‘to drive s.o. mad’, op het [ver-
keerde] paard gokken ‘back the wrong horse’, [de
kat] uit de boom kijken ‘wait to see which way the
wind blows’, uit het [goede] hout gesneden ‘be a
trustworthy person’). Conversely, there were also
questionable MWE candidates that were described
as actual MWEs in our evaluation resources (val op
woensdag ‘fall on a wednesday’, neem als voorzitter
‘take as chairperson’, ruik naar haring ‘smell like
herring’, ben voor [...] procent ‘to be ...percent’).
A manual evaluation could overcome these difficul-
ties.
We believe that our method provides a genuine
</bodyText>
<figure confidence="0.89592025">
huis
home
willen
want
</figure>
<page confidence="0.999703">
31
</page>
<bodyText confidence="0.999965571428571">
and successful approach to get a grasp of the non-
compositionality of MWEs in a fully automated way.
We also believe that it is one of the first methods
able to extract MWEs based on non-compositionality
on a large scale, and that traditional MWE extrac-
tion algorithms will benefit from taking this non-
compositionality into account.
</bodyText>
<sectionHeader confidence="0.996406" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9985398">
This research was carried out as part of the research
program IRME STEVIN project. We would also like
to thank Gertjan van Noord and the two anonymous
reviewers for their helpful comments on an earlier
version of this paper.
</bodyText>
<sectionHeader confidence="0.999677" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9995002">
T. Baldwin, C. Bannard, T. Tanaka, and D. Widdows. 2003. An
Empirical Model of Multiword Expressions Decomposabil-
ity. In Proc. of the ACL-2003 Workshop on Multiword Ex-
pressions: Analysis, Acquisition and Treatment, pages 89–
96, Sapporo, Japan.
T. Baldwin. 2006. Compositionality and Multiword Expres-
sions: Six of One, Half a Dozen of the Other? Invited talk
given at the COLING/ACL’06 Workshop on Multiword Ex-
pressions: Identifying and Exploiting Underlying Properties,
July.
K. Church, W. Gale, P. Hanks, and D. Hindle. 1991. Using
statistics in lexical analysis. In Uri Zernik, editor, Lexical
Acquisition: Exploiting On-line resources to build a lexicon,
pages 115–164. Lawrence Erlbaum Associates, New Jersey.
A. Fazly and S. Stevenson. 2006. Automatically constructing
a lexicon of verb phrase idiomatic combinations. In Pro-
ceedings of the 11th Conference of the European Chapter of
the Association for Computational Linguistics (EACL-2006),
Trento, Italy.
G. Katz and E. Giesbrecht. 2006. Automatic identification of
non-compositional multi-word expressions using Latent Se-
mantic Analysis. In Proc. of the COLING/ACL’06 Work-
shop on Multiword Expressions: Identifying and Exploiting
Underlying Properties, pages 12–19, Sydney, Australia.
D. Lin. 1998. Automatic retrieval and clustering of simi-
lar words. In Proceedings of COLING/ACL 98, Montreal,
Canada.
D. Lin. 1999. Automatic identification of non-compositional
phrases. In Proceedings ofACL-99, pages 317–324. Univer-
sity of Maryland.
J. B. MacQueen. 1967. Some methods for classification and
analysis of multivariate observations. In Proceedings of 5-th
Berkeley Symposium on Mathematical Statistics and Prob-
ability, volume 1, pages 281–297, Berkeley. University of
California Press.
W. Martin and I. Maks, 2005. Referentie Bestand Nederlands.
Documentatie, April.
D. McCarthy, B. Keller, and J. Carroll. 2003. Detecting a Con-
tinuum of Compositionality in Phrasal Verbs. In Proc. of
the ACL-2003 Workshop on Multiword Expressions: Analy-
sis, Acquisition and Treatment, Sapporo, Japan.
R.J.F. Ordelman. 2002. Twente Nieuws Corpus (TwNC), Au-
gust. Parlevink Language Techonology Group. University of
Twente.
D. Pearce. 2001. Synonymy in collocation extraction. In Word-
Net and Other lexical resources: applications, extensions
&amp; customizations (NAACL 2001), pages 41–46, Pittsburgh.
Carnegie Mellon University.
S. Piao, P. Rayson, O. Mudraya, A. Wilson, and R. Garside.
2006. Measuring mwe compositionality using semantic an-
notation. In Proceedings of the Workshop on Multiword
Expressions: Identifying and Exploiting Underlying Prop-
erties, pages 2–11, Sydney, Australia. Association for Com-
putational Linguistics.
P. Resnik. 1993. Selection and Information: A Class-Based
Approach to Lexical Relationships. PhD Thesis, University
of Pennsylvania.
P. Resnik. 1996. Selectional constraints: An information-
theoretic model and its computational realization. Cogni-
tion, 61:127–159.
I. Sag, T. Baldwin, F. Bond, A. Copestake, and D. Flickinger.
2002. Multiword Expressions: a pain in the neck for NLP.
In Proceedings of the Third International Conference on
Intelligent Text Processing and Computational Linguistics,
pages 1–15, Mexico City, Mexico.
L. van der Plas and G. Bouma. 2005. Syntactic contexts for
finding semantically similar words. Computational Linguis-
tics in the Netherlands 2004. Selected Papers from the Fif-
teenth CLINMeeting, pages 173–184.
G. van Noord. 2006. At Last Parsing Is Now Operational.
In P. Mertens, C. Fairon, A. Dister, and P. Watrin, editors,
TALN06. Verbum Ex Machina. Actes de la 13e conference
sur le traitement automatique des langues naturelles, pages
20–42, Leuven.
S. Venkatapathy and A. Joshi. 2005. Measuring the relative
compositionality of verb-noun collocations by integrating
features. In Proceedings of the Human Language Technol-
ogy Conference and Conference on Empirical Methods in
Natural Language Processing, pages 899–906, Vancouver.
B. Villada Moir´on and J. Tiedemann. 2006. Identifying id-
iomatic expressions using automatic word-alignment. In
Proceedings of the EACL 2006 Workshop on Multi-word-
expressions in a multilingual context”, pages 33–40, Trento,
Italy.
J. Weeds. 2003. Measures and Applications of Lexical Distri-
butional Similarity. PhD Thesis, University of Sussex.
Z. Wu and M. Palmer. 1994. Verb semantics and lexical selec-
tion. In 32nd. Annual Meeting of the Association for Com-
putational Linguistics, pages 133–138, New Mexico State
University, Las Cruces, New Mexico.
</reference>
<page confidence="0.999305">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.827424">
<title confidence="0.999894">Semantics-based Multiword Expression Extraction</title>
<author confidence="0.999792">Tim Van_de_Cruys</author>
<author confidence="0.999792">Begofna Villada</author>
<affiliation confidence="0.9051925">Alfa Informatica, University of Oude Kijk in ’t Jatstraat</affiliation>
<address confidence="0.950927">9712 EK Groningen, The</address>
<abstract confidence="0.999248055555556">This paper describes a fully unsupervised and automated method for large-scale exof multiword expressions from large corpora. The method aims at capthe non-compositionality of intuition is that a noun within a cannot easily be replaced by a semantically similar noun. To implement this intuition, a noun clustering is automatically extracted (using distributional similarity measures), which gives us clusters of semantically related nouns. Next, a number of statistical measures – based on selectional preferences – is developed that formalize the intuition of non-compositionality. Our approach has been tested on Dutch, and automatically evaluated using Dutch lexical resources.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Baldwin</author>
<author>C Bannard</author>
<author>T Tanaka</author>
<author>D Widdows</author>
</authors>
<title>An Empirical Model of Multiword Expressions Decomposability.</title>
<date>2003</date>
<booktitle>In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>89--96</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="3451" citStr="Baldwin et al., 2003" startWordPosition="513" endWordPosition="516"> unsupervised MWE extraction method. 25 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Previous Work Recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies. Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al., 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al., 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al., 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moir´on and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). Pearce (2001) describes a method to extract collocations from corpora by measuring semantic compositionality. The underlying assumption is that a fully compositional expression allows synonym replacement of its component words, whereas a collocation does not. Pearce measures to what degree a collocation candidate allows synonym replacement</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>T. Baldwin, C. Bannard, T. Tanaka, and D. Widdows. 2003. An Empirical Model of Multiword Expressions Decomposability. In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 89– 96, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
</authors>
<title>Compositionality and Multiword Expressions: Six of One, Half a Dozen of the Other? Invited talk given at the COLING/ACL’06 Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,</title>
<date>2006</date>
<contexts>
<context position="1122" citStr="Baldwin (2006)" startWordPosition="161" endWordPosition="162">ily be replaced by a semantically similar noun. To implement this intuition, a noun clustering is automatically extracted (using distributional similarity measures), which gives us clusters of semantically related nouns. Next, a number of statistical measures – based on selectional preferences – is developed that formalize the intuition of non-compositionality. Our approach has been tested on Dutch, and automatically evaluated using Dutch lexical resources. 1 Introduction MWEs are expressions whose linguistic behaviour is not predictable from the linguistic behaviour of their component words. Baldwin (2006) characterizes the idiosyncratic behavior of MWEs as “a lack of compositionality manifest at different levels of analysis, namely, lexical, morphological, syntactic, semantic, pragmatic and statistical”. Some MWEs show productive morphology and/or syntactic flexibility. Therefore, these two aspects are not sufficient conditions to discriminate actual MWEs from productive expressions. Nonetheless, the mentioned characteristics are useful indicators to distinguish literal and idiomatic expressions (Fazly and Stevenson, 2006). One property that seems to affect MWEs the most is semantic non-compos</context>
</contexts>
<marker>Baldwin, 2006</marker>
<rawString>T. Baldwin. 2006. Compositionality and Multiword Expressions: Six of One, Half a Dozen of the Other? Invited talk given at the COLING/ACL’06 Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>W Gale</author>
<author>P Hanks</author>
<author>D Hindle</author>
</authors>
<title>Using statistics in lexical analysis.</title>
<date>1991</date>
<editor>In Uri Zernik, editor, Lexical</editor>
<location>New Jersey.</location>
<contexts>
<context position="9010" citStr="Church et al., 1991" startWordPosition="1363" endWordPosition="1366">tering In order to compare a noun to its semantically related nouns, a noun clustering is created. These clusters are automatically extracted using standard distributional similarity techniques (Weeds, 2003; van der Plas and Bouma, 2005). First, dependency triples are extracted from the Twente Nieuws Corpus. Next, feature vectors are created for each noun, containing the frequency of the dependency relations in which the noun occurs.2 This way, a frequency matrix of 10K nouns by 100K dependency relations is constructed. The cell frequencies are replaced by pointwise mutual information scores (Church et al., 1991), so that more informative features get a higher weight. The noun vectors are then clustered into 1,000 clusters using a simple K-means clustering algorithm (MacQueen, 1967) with cosine similarity. During development, several other clustering algorithms and parameters have been tested, but the settings described above gave us the best EuroWordNet similarity score (using Wu and Palmer (1994)). Note that our clustering algorithm is a hard clustering algorithm, which means that a certain noun 1The lowest frequency verb-preposition combination (with regard to the 10,000 nouns) appears 3 times. 2e.</context>
</contexts>
<marker>Church, Gale, Hanks, Hindle, 1991</marker>
<rawString>K. Church, W. Gale, P. Hanks, and D. Hindle. 1991. Using statistics in lexical analysis. In Uri Zernik, editor, Lexical Acquisition: Exploiting On-line resources to build a lexicon, pages 115–164. Lawrence Erlbaum Associates, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fazly</author>
<author>S Stevenson</author>
</authors>
<title>Automatically constructing a lexicon of verb phrase idiomatic combinations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2006),</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="1650" citStr="Fazly and Stevenson, 2006" startWordPosition="228" endWordPosition="231">ehaviour is not predictable from the linguistic behaviour of their component words. Baldwin (2006) characterizes the idiosyncratic behavior of MWEs as “a lack of compositionality manifest at different levels of analysis, namely, lexical, morphological, syntactic, semantic, pragmatic and statistical”. Some MWEs show productive morphology and/or syntactic flexibility. Therefore, these two aspects are not sufficient conditions to discriminate actual MWEs from productive expressions. Nonetheless, the mentioned characteristics are useful indicators to distinguish literal and idiomatic expressions (Fazly and Stevenson, 2006). One property that seems to affect MWEs the most is semantic non-compositionality. MWEs are typically non-compositional. As a consequence, it is not possible to replace the noun of a MWE by semantically related nouns. Take for example the expressions in (1) and (2): (1) a. break the vase b. break the cup c. break the dish (2) a. break the ice b. *break the snow c. *break the hail Expression (1-a) is fully compositional. Therefore, vase can easily be replaced with semantically related nouns such as cup and dish. Expression (2-a), on the contrary, is non-compositional; ice cannot be replaced wi</context>
<context position="3376" citStr="Fazly and Stevenson, 2006" startWordPosition="503" endWordPosition="506">ge text collections. This is the main motivation to pursue an automated and fully unsupervised MWE extraction method. 25 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Previous Work Recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies. Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al., 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al., 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al., 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moir´on and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). Pearce (2001) describes a method to extract collocations from corpora by measuring semantic compositionality. The underlying assumption is that a fully compositional expression allows synonym replacement of its component words, whereas a collocation does not. Pearce</context>
<context position="5099" citStr="Fazly and Stevenson (2006)" startWordPosition="753" endWordPosition="756">sures that take into account the semantics of the particle. Contrary to these measures, standard association measures poorly correlate with human judgements. A different approach proposed by Villada Moir´on and Tiedemann (2006) measures translational entropy as a sign of meaning predictability, and therefore non-compositionality. The entropy observed among word alignments of a potential MWE varies: highly predictable alignments show less entropy and probably correspond to compositional expressions. Data sparseness and polysemy pose problems because the entropy cannot be accurately calculated. Fazly and Stevenson (2006) use lexical and syntactic fixedness as partial indicators of noncompositionality. Their method uses Lin’s (1998) automatically generated thesaurus to compute a metric of lexical fixedness. Lexical fixedness measures the deviation between the pointwise mutual information of a verb-object phrase and the average pointwise mutual information of the expressions resulting from substituting the noun by its synonyms in the original phrase. This measure is similar to Lin’s (1999) proposal for finding noncompositional phrases. Separately, a syntactic flexibility score measures the probability of seeing</context>
<context position="6621" citStr="Fazly and Stevenson (2006)" startWordPosition="989" endWordPosition="992">from idiomatic expressions in a test set of 200 expressions. The performance of both metrics is stable across all frequency ranges. In this study, we are interested in establishing whether a fully unsupervised method can capture the (partial or) non-compositionality of MWEs. The method should not depend on the existence of large (open domain) parallel corpora or sense tagged corpora. Also, the method should not require numerous adjustments when applied to new subclasses of MWEs, for instance, when coding empirical attributes of the candidates. Similar to Lin (1999), McCarthy et al. (2003) and Fazly and Stevenson (2006), our method makes use of automatically generated thesauri; the technique used to compile the thesauri differs from previous work. Aiming at finding a method of general applicability, the measures to capture non-compositionality differ from those employed in earlier work. 3 Methodology In the description and evaluation of our algorithm, we focus on the extraction of verbal MWEs that contain prepositional complements, although we believe the method can be easily generalized to other kinds of MWEs. In our semantics-based approach, we want to formalize the intuition of non-compositionality, so th</context>
<context position="15770" citStr="Fazly and Stevenson (2006)" startWordPosition="2554" endWordPosition="2558">various nouns in the cluster, the highest preference of val in being assigned to the noun gat (.71).4 The other two scores show again a similar tendency; An→v – the preference of the noun for the verb – is low in all cases, and when all nouns in the cluster are considered (Rn→v), there is no ‘unique’ preference of one noun for the verb val in. Instead, the preference mass is divided among all nouns in the cluster. 4 Results &amp; Evaluation 4.1 Quantitative evaluation In this section, we quantitatively evaluate our method, and compare it to the lexical and syntactic fixedness measures proposed by Fazly and Stevenson (2006). More information about Fazly and Stevenson’s measures can be found in their paper. The potential MWEs that are extracted with the fully unsupervised method described above and with Fazly and Stevenson’s (2006) method (FS from here onwards) are automatically evaluated by comparing the extracted list to handcrafted MWE databases. Since we have extracted Dutch MWEs, we are using the two Dutch resources available: the Referentie Bestand Nederlands (RBN, Martin and Maks (2005)) and the Van Dale Lexicographical Information System (VLIS) database. Evaluation scores are calculated with regard to the</context>
<context position="24081" citStr="Fazly and Stevenson (2006)" startWordPosition="3951" endWordPosition="3954">n and Rv,n, yields the highest f-measure. Using the two other parameters, An,v and Rn,v, increases precision but degrades recall. Due to the formalization of the intuition of non-compositionality (using an automatic noun clustering), our algorithm is able to rule out various expressions that are coined MWEs by traditional algorithms. Note that our algorithm has taken on a purely semantics-based approach. ‘Syntactic fixedness’ of the expressions is not taken into account. Combining our semantics-based approach with other extraction techniques such as the syntactic fixedness measure proposed by Fazly and Stevenson (2006) might improve the results significantly. We conclude with some issues saved for future work. First of all, we would like to combine our semantics-based method with other methods that are used to find MWEs (especially syntax-based methods), and implement the method in general classification models (decision tree classifier and maximum entropy model). This includes the use of a more principled (machine learning) framework in order to establish the optimal threshold values. Next, we would like to investigate a number of topics to improve on our semantics-based method. First of all, using the top</context>
</contexts>
<marker>Fazly, Stevenson, 2006</marker>
<rawString>A. Fazly and S. Stevenson. 2006. Automatically constructing a lexicon of verb phrase idiomatic combinations. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2006), Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Katz</author>
<author>E Giesbrecht</author>
</authors>
<title>Automatic identification of non-compositional multi-word expressions using Latent Semantic Analysis.</title>
<date>2006</date>
<booktitle>In Proc. of the COLING/ACL’06 Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,</booktitle>
<pages>12--19</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="3479" citStr="Katz and Giesbrecht, 2006" startWordPosition="517" endWordPosition="520">action method. 25 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Previous Work Recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies. Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al., 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al., 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al., 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moir´on and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). Pearce (2001) describes a method to extract collocations from corpora by measuring semantic compositionality. The underlying assumption is that a fully compositional expression allows synonym replacement of its component words, whereas a collocation does not. Pearce measures to what degree a collocation candidate allows synonym replacement. The measurement is used to</context>
</contexts>
<marker>Katz, Giesbrecht, 2006</marker>
<rawString>G. Katz and E. Giesbrecht. 2006. Automatic identification of non-compositional multi-word expressions using Latent Semantic Analysis. In Proc. of the COLING/ACL’06 Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, pages 12–19, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING/ACL 98,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="4154" citStr="Lin (1998)" startWordPosition="617" endWordPosition="618">nd Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). Pearce (2001) describes a method to extract collocations from corpora by measuring semantic compositionality. The underlying assumption is that a fully compositional expression allows synonym replacement of its component words, whereas a collocation does not. Pearce measures to what degree a collocation candidate allows synonym replacement. The measurement is used to rank candidates relative to their compositionality. Building on Lin (1998), McCarthy et al. (2003) measure the semantic similarity between expressions (verb particles) as a whole and their component words (verb). They exploit contextual features and frequency information in order to assess meaning overlap. They established that human compositionality judgements correlate well with those measures that take into account the semantics of the particle. Contrary to these measures, standard association measures poorly correlate with human judgements. A different approach proposed by Villada Moir´on and Tiedemann (2006) measures translational entropy as a sign of meaning p</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of COLING/ACL 98, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic identification of non-compositional phrases.</title>
<date>1999</date>
<booktitle>In Proceedings ofACL-99,</booktitle>
<pages>317--324</pages>
<institution>University of Maryland.</institution>
<contexts>
<context position="3325" citStr="Lin, 1999" startWordPosition="497" endWordPosition="498">methods that extract MWEs from large text collections. This is the main motivation to pursue an automated and fully unsupervised MWE extraction method. 25 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Previous Work Recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies. Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al., 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al., 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al., 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moir´on and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). Pearce (2001) describes a method to extract collocations from corpora by measuring semantic compositionality. The underlying assumption is that a fully compositional expression allows synonym replacement of its comp</context>
<context position="6566" citStr="Lin (1999)" startWordPosition="982" endWordPosition="983">80% accuracy in distinguishing literal from idiomatic expressions in a test set of 200 expressions. The performance of both metrics is stable across all frequency ranges. In this study, we are interested in establishing whether a fully unsupervised method can capture the (partial or) non-compositionality of MWEs. The method should not depend on the existence of large (open domain) parallel corpora or sense tagged corpora. Also, the method should not require numerous adjustments when applied to new subclasses of MWEs, for instance, when coding empirical attributes of the candidates. Similar to Lin (1999), McCarthy et al. (2003) and Fazly and Stevenson (2006), our method makes use of automatically generated thesauri; the technique used to compile the thesauri differs from previous work. Aiming at finding a method of general applicability, the measures to capture non-compositionality differ from those employed in earlier work. 3 Methodology In the description and evaluation of our algorithm, we focus on the extraction of verbal MWEs that contain prepositional complements, although we believe the method can be easily generalized to other kinds of MWEs. In our semantics-based approach, we want to</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>D. Lin. 1999. Automatic identification of non-compositional phrases. In Proceedings ofACL-99, pages 317–324. University of Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B MacQueen</author>
</authors>
<title>Some methods for classification and analysis of multivariate observations.</title>
<date>1967</date>
<booktitle>In Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability,</booktitle>
<volume>1</volume>
<pages>281--297</pages>
<institution>Berkeley. University of California Press.</institution>
<contexts>
<context position="9183" citStr="MacQueen, 1967" startWordPosition="1392" endWordPosition="1393">rity techniques (Weeds, 2003; van der Plas and Bouma, 2005). First, dependency triples are extracted from the Twente Nieuws Corpus. Next, feature vectors are created for each noun, containing the frequency of the dependency relations in which the noun occurs.2 This way, a frequency matrix of 10K nouns by 100K dependency relations is constructed. The cell frequencies are replaced by pointwise mutual information scores (Church et al., 1991), so that more informative features get a higher weight. The noun vectors are then clustered into 1,000 clusters using a simple K-means clustering algorithm (MacQueen, 1967) with cosine similarity. During development, several other clustering algorithms and parameters have been tested, but the settings described above gave us the best EuroWordNet similarity score (using Wu and Palmer (1994)). Note that our clustering algorithm is a hard clustering algorithm, which means that a certain noun 1The lowest frequency verb-preposition combination (with regard to the 10,000 nouns) appears 3 times. 2e.g. dependency relations that qualify apple might be ‘object of eat’ and ‘adjective red’. This gives us dependency triples like &lt; apple, obj, eat &gt;. 3.3 Measures The measures</context>
</contexts>
<marker>MacQueen, 1967</marker>
<rawString>J. B. MacQueen. 1967. Some methods for classification and analysis of multivariate observations. In Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability, volume 1, pages 281–297, Berkeley. University of California Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Martin</author>
<author>I Maks</author>
</authors>
<title>Referentie Bestand Nederlands.</title>
<date>2005</date>
<location>Documentatie,</location>
<contexts>
<context position="16248" citStr="Martin and Maks (2005)" startWordPosition="2630" endWordPosition="2633">on, we quantitatively evaluate our method, and compare it to the lexical and syntactic fixedness measures proposed by Fazly and Stevenson (2006). More information about Fazly and Stevenson’s measures can be found in their paper. The potential MWEs that are extracted with the fully unsupervised method described above and with Fazly and Stevenson’s (2006) method (FS from here onwards) are automatically evaluated by comparing the extracted list to handcrafted MWE databases. Since we have extracted Dutch MWEs, we are using the two Dutch resources available: the Referentie Bestand Nederlands (RBN, Martin and Maks (2005)) and the Van Dale Lexicographical Information System (VLIS) database. Evaluation scores are calculated with regard to the MWEs that are present in our evaluation resources. Among the MWEs in our reference data, we consider only those expressions that are present in our frequency matrix: if the verb is not among the 5,000 most frequent verbs, or the noun is not among the 10,000 most frequent nouns, the frequency information is not present in our input 4The expression is ambiguous: it can be used in a literal sense (in een gat vallen, ‘to fall down a hole’) and in a metaphorical sense (in een z</context>
</contexts>
<marker>Martin, Maks, 2005</marker>
<rawString>W. Martin and I. Maks, 2005. Referentie Bestand Nederlands. Documentatie, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>B Keller</author>
<author>J Carroll</author>
</authors>
<title>Detecting a Continuum of Compositionality in Phrasal Verbs.</title>
<date>2003</date>
<booktitle>In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="3348" citStr="McCarthy et al., 2003" startWordPosition="499" endWordPosition="502">t extract MWEs from large text collections. This is the main motivation to pursue an automated and fully unsupervised MWE extraction method. 25 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Previous Work Recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies. Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al., 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al., 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al., 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moir´on and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). Pearce (2001) describes a method to extract collocations from corpora by measuring semantic compositionality. The underlying assumption is that a fully compositional expression allows synonym replacement of its component words, whereas a </context>
<context position="6590" citStr="McCarthy et al. (2003)" startWordPosition="984" endWordPosition="987"> in distinguishing literal from idiomatic expressions in a test set of 200 expressions. The performance of both metrics is stable across all frequency ranges. In this study, we are interested in establishing whether a fully unsupervised method can capture the (partial or) non-compositionality of MWEs. The method should not depend on the existence of large (open domain) parallel corpora or sense tagged corpora. Also, the method should not require numerous adjustments when applied to new subclasses of MWEs, for instance, when coding empirical attributes of the candidates. Similar to Lin (1999), McCarthy et al. (2003) and Fazly and Stevenson (2006), our method makes use of automatically generated thesauri; the technique used to compile the thesauri differs from previous work. Aiming at finding a method of general applicability, the measures to capture non-compositionality differ from those employed in earlier work. 3 Methodology In the description and evaluation of our algorithm, we focus on the extraction of verbal MWEs that contain prepositional complements, although we believe the method can be easily generalized to other kinds of MWEs. In our semantics-based approach, we want to formalize the intuition</context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>D. McCarthy, B. Keller, and J. Carroll. 2003. Detecting a Continuum of Compositionality in Phrasal Verbs. In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J F Ordelman</author>
</authors>
<date>2002</date>
<institution>Twente Nieuws Corpus (TwNC), August. Parlevink Language Techonology Group. University of Twente.</institution>
<contexts>
<context position="7888" citStr="Ordelman, 2002" startWordPosition="1193" endWordPosition="1194">ay. A number of statistical measures are developed that try to capture the MWE’s non-compositional 26 bond between a verb-preposition combination and its noun by comparing the particular noun of a MWE candidate to other semantically related nouns. 3.1 Data extraction can only be assigned to one cluster. This may pose a problem for polysemous nouns. On the other hand, this makes the computation of our metrics straightforward, since we do not have to decide among various senses of a word. The MWE candidates (verb + prepositional phrase) are automatically extracted from the Twente Nieuws Corpus (Ordelman, 2002), a large corpus of Dutch newspaper texts (500 million words), which has been automatically parsed by the Dutch dependency parser Alpino (van Noord, 2006). Next, a matrix is created of the 5,000 most frequent verb-preposition combinations by the 10,000 most frequent nouns, containing the frequency of each MWE candidate.1 To this matrix, a number of statistical measures are applied to determine the non-compositionality of the candidate MWEs. These statistical measures are explained in 3.3. 3.2 Clustering In order to compare a noun to its semantically related nouns, a noun clustering is created.</context>
</contexts>
<marker>Ordelman, 2002</marker>
<rawString>R.J.F. Ordelman. 2002. Twente Nieuws Corpus (TwNC), August. Parlevink Language Techonology Group. University of Twente.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pearce</author>
</authors>
<title>Synonymy in collocation extraction.</title>
<date>2001</date>
<booktitle>In WordNet and Other lexical resources: applications, extensions &amp; customizations (NAACL</booktitle>
<pages>41--46</pages>
<institution>Pittsburgh. Carnegie Mellon University.</institution>
<contexts>
<context position="3280" citStr="Pearce, 2001" startWordPosition="491" endWordPosition="492">P community would clearly benefit from automated methods that extract MWEs from large text collections. This is the main motivation to pursue an automated and fully unsupervised MWE extraction method. 25 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Previous Work Recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies. Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al., 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al., 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al., 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moir´on and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). Pearce (2001) describes a method to extract collocations from corpora by measuring semantic compositionality. The underlying assumption is that a fully compositional expr</context>
</contexts>
<marker>Pearce, 2001</marker>
<rawString>D. Pearce. 2001. Synonymy in collocation extraction. In WordNet and Other lexical resources: applications, extensions &amp; customizations (NAACL 2001), pages 41–46, Pittsburgh. Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Piao</author>
<author>P Rayson</author>
<author>O Mudraya</author>
<author>A Wilson</author>
<author>R Garside</author>
</authors>
<title>Measuring mwe compositionality using semantic annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,</booktitle>
<pages>2--11</pages>
<institution>Sydney, Australia. Association for Computational Linguistics.</institution>
<contexts>
<context position="3256" citStr="Piao et al., 2006" startWordPosition="486" endWordPosition="489">of language resources, the NLP community would clearly benefit from automated methods that extract MWEs from large text collections. This is the main motivation to pursue an automated and fully unsupervised MWE extraction method. 25 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Previous Work Recent proposals that attempt to capture semantic compositionality (or lack thereof) employ various strategies. Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al., 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al., 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al., 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moir´on and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). Pearce (2001) describes a method to extract collocations from corpora by measuring semantic compositionality. The underlying assumption is that a </context>
</contexts>
<marker>Piao, Rayson, Mudraya, Wilson, Garside, 2006</marker>
<rawString>S. Piao, P. Rayson, O. Mudraya, A. Wilson, and R. Garside. 2006. Measuring mwe compositionality using semantic annotation. In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, pages 2–11, Sydney, Australia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Selection and Information: A Class-Based Approach to Lexical Relationships.</title>
<date>1993</date>
<tech>PhD Thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="9879" citStr="Resnik, 1993" startWordPosition="1500" endWordPosition="1501"> parameters have been tested, but the settings described above gave us the best EuroWordNet similarity score (using Wu and Palmer (1994)). Note that our clustering algorithm is a hard clustering algorithm, which means that a certain noun 1The lowest frequency verb-preposition combination (with regard to the 10,000 nouns) appears 3 times. 2e.g. dependency relations that qualify apple might be ‘object of eat’ and ‘adjective red’. This gives us dependency triples like &lt; apple, obj, eat &gt;. 3.3 Measures The measures used to find MWEs are inspired by Resnik’s method to find selectional preferences (Resnik, 1993; Resnik, 1996). Resnik uses a number of measures based on the Kullback-Leibler divergence, to measure the difference between the prior probability of a noun class p(c) and the probability of the class given a verb p(clv). We adopt the method for particular nouns, and add a measure for determining the ‘unique preference’ of a noun given other nouns in the cluster, which, we claim, yields a measure of non-compositionality. In total, 4 measures are used, the latter two being the symmetric counterpart of the former two. The first two measures, Av→n (equation 2) and Rv→n (equation 3), formalize th</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>P. Resnik. 1993. Selection and Information: A Class-Based Approach to Lexical Relationships. PhD Thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Selectional constraints: An informationtheoretic model and its computational realization.</title>
<date>1996</date>
<journal>Cognition,</journal>
<pages>61--127</pages>
<contexts>
<context position="9894" citStr="Resnik, 1996" startWordPosition="1502" endWordPosition="1503">ve been tested, but the settings described above gave us the best EuroWordNet similarity score (using Wu and Palmer (1994)). Note that our clustering algorithm is a hard clustering algorithm, which means that a certain noun 1The lowest frequency verb-preposition combination (with regard to the 10,000 nouns) appears 3 times. 2e.g. dependency relations that qualify apple might be ‘object of eat’ and ‘adjective red’. This gives us dependency triples like &lt; apple, obj, eat &gt;. 3.3 Measures The measures used to find MWEs are inspired by Resnik’s method to find selectional preferences (Resnik, 1993; Resnik, 1996). Resnik uses a number of measures based on the Kullback-Leibler divergence, to measure the difference between the prior probability of a noun class p(c) and the probability of the class given a verb p(clv). We adopt the method for particular nouns, and add a measure for determining the ‘unique preference’ of a noun given other nouns in the cluster, which, we claim, yields a measure of non-compositionality. In total, 4 measures are used, the latter two being the symmetric counterpart of the former two. The first two measures, Av→n (equation 2) and Rv→n (equation 3), formalize the unique prefer</context>
</contexts>
<marker>Resnik, 1996</marker>
<rawString>P. Resnik. 1996. Selectional constraints: An informationtheoretic model and its computational realization. Cognition, 61:127–159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Sag</author>
<author>T Baldwin</author>
<author>F Bond</author>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>Multiword Expressions: a pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<pages>1--15</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="2464" citStr="Sag et al., 2002" startWordPosition="370" endWordPosition="373">ically related nouns. Take for example the expressions in (1) and (2): (1) a. break the vase b. break the cup c. break the dish (2) a. break the ice b. *break the snow c. *break the hail Expression (1-a) is fully compositional. Therefore, vase can easily be replaced with semantically related nouns such as cup and dish. Expression (2-a), on the contrary, is non-compositional; ice cannot be replaced with semantically related words, such as snow and hail without loss of the original meaning. Due to the idiosyncratic behavior, current proposals argue that MWEs need to be described in the lexicon (Sag et al., 2002). In most languages, electronic lexical resources (such as dictionaries, thesauri, ontologies) suffer from a limited coverage of MWEs. To facilitate the update and expansion of language resources, the NLP community would clearly benefit from automated methods that extract MWEs from large text collections. This is the main motivation to pursue an automated and fully unsupervised MWE extraction method. 25 Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 25–32, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Previous Work Recent proposals </context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>I. Sag, T. Baldwin, F. Bond, A. Copestake, and D. Flickinger. 2002. Multiword Expressions: a pain in the neck for NLP. In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics, pages 1–15, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L van der Plas</author>
<author>G Bouma</author>
</authors>
<title>Syntactic contexts for finding semantically similar words.</title>
<date>2005</date>
<booktitle>Computational Linguistics in the Netherlands 2004. Selected Papers from the Fifteenth CLINMeeting,</booktitle>
<pages>173--184</pages>
<marker>van der Plas, Bouma, 2005</marker>
<rawString>L. van der Plas and G. Bouma. 2005. Syntactic contexts for finding semantically similar words. Computational Linguistics in the Netherlands 2004. Selected Papers from the Fifteenth CLINMeeting, pages 173–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G van Noord</author>
</authors>
<title>At Last Parsing Is Now Operational. In</title>
<date>2006</date>
<booktitle>TALN06. Verbum Ex Machina. Actes de la 13e conference sur le traitement automatique des langues naturelles,</booktitle>
<pages>20--42</pages>
<editor>P. Mertens, C. Fairon, A. Dister, and P. Watrin, editors,</editor>
<location>Leuven.</location>
<marker>van Noord, 2006</marker>
<rawString>G. van Noord. 2006. At Last Parsing Is Now Operational. In P. Mertens, C. Fairon, A. Dister, and P. Watrin, editors, TALN06. Verbum Ex Machina. Actes de la 13e conference sur le traitement automatique des langues naturelles, pages 20–42, Leuven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Venkatapathy</author>
<author>A Joshi</author>
</authors>
<title>Measuring the relative compositionality of verb-noun collocations by integrating features.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>899--906</pages>
<location>Vancouver.</location>
<contexts>
<context position="3708" citStr="Venkatapathy and Joshi, 2005" startWordPosition="549" endWordPosition="553"> capture semantic compositionality (or lack thereof) employ various strategies. Approaches evaluated so far make use of dictionaries with semantic annotation (Piao et al., 2006), WordNet (Pearce, 2001), automatically generated thesauri (Lin, 1999; McCarthy et al., 2003; Fazly and Stevenson, 2006), vector-based methods that measure semantic distance (Baldwin et al., 2003; Katz and Giesbrecht, 2006), translations extracted from parallel corpora (Villada Moir´on and Tiedemann, 2006) or hybrid methods that use machine learning techniques informed by features coded using some of the above methods (Venkatapathy and Joshi, 2005). Pearce (2001) describes a method to extract collocations from corpora by measuring semantic compositionality. The underlying assumption is that a fully compositional expression allows synonym replacement of its component words, whereas a collocation does not. Pearce measures to what degree a collocation candidate allows synonym replacement. The measurement is used to rank candidates relative to their compositionality. Building on Lin (1998), McCarthy et al. (2003) measure the semantic similarity between expressions (verb particles) as a whole and their component words (verb). They exploit co</context>
</contexts>
<marker>Venkatapathy, Joshi, 2005</marker>
<rawString>S. Venkatapathy and A. Joshi. 2005. Measuring the relative compositionality of verb-noun collocations by integrating features. In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 899–906, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Villada Moir´on</author>
<author>J Tiedemann</author>
</authors>
<title>Identifying idiomatic expressions using automatic word-alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the EACL 2006 Workshop on Multi-wordexpressions in a multilingual context”,</booktitle>
<pages>33--40</pages>
<location>Trento, Italy.</location>
<marker>Moir´on, Tiedemann, 2006</marker>
<rawString>B. Villada Moir´on and J. Tiedemann. 2006. Identifying idiomatic expressions using automatic word-alignment. In Proceedings of the EACL 2006 Workshop on Multi-wordexpressions in a multilingual context”, pages 33–40, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Weeds</author>
</authors>
<title>Measures and Applications of Lexical Distributional Similarity.</title>
<date>2003</date>
<tech>PhD Thesis,</tech>
<institution>University of Sussex.</institution>
<contexts>
<context position="8596" citStr="Weeds, 2003" startWordPosition="1299" endWordPosition="1300">d by the Dutch dependency parser Alpino (van Noord, 2006). Next, a matrix is created of the 5,000 most frequent verb-preposition combinations by the 10,000 most frequent nouns, containing the frequency of each MWE candidate.1 To this matrix, a number of statistical measures are applied to determine the non-compositionality of the candidate MWEs. These statistical measures are explained in 3.3. 3.2 Clustering In order to compare a noun to its semantically related nouns, a noun clustering is created. These clusters are automatically extracted using standard distributional similarity techniques (Weeds, 2003; van der Plas and Bouma, 2005). First, dependency triples are extracted from the Twente Nieuws Corpus. Next, feature vectors are created for each noun, containing the frequency of the dependency relations in which the noun occurs.2 This way, a frequency matrix of 10K nouns by 100K dependency relations is constructed. The cell frequencies are replaced by pointwise mutual information scores (Church et al., 1991), so that more informative features get a higher weight. The noun vectors are then clustered into 1,000 clusters using a simple K-means clustering algorithm (MacQueen, 1967) with cosine </context>
</contexts>
<marker>Weeds, 2003</marker>
<rawString>J. Weeds. 2003. Measures and Applications of Lexical Distributional Similarity. PhD Thesis, University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wu</author>
<author>M Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In 32nd. Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<institution>Mexico State University, Las Cruces,</institution>
<location>New</location>
<contexts>
<context position="9403" citStr="Wu and Palmer (1994)" startWordPosition="1422" endWordPosition="1425">pendency relations in which the noun occurs.2 This way, a frequency matrix of 10K nouns by 100K dependency relations is constructed. The cell frequencies are replaced by pointwise mutual information scores (Church et al., 1991), so that more informative features get a higher weight. The noun vectors are then clustered into 1,000 clusters using a simple K-means clustering algorithm (MacQueen, 1967) with cosine similarity. During development, several other clustering algorithms and parameters have been tested, but the settings described above gave us the best EuroWordNet similarity score (using Wu and Palmer (1994)). Note that our clustering algorithm is a hard clustering algorithm, which means that a certain noun 1The lowest frequency verb-preposition combination (with regard to the 10,000 nouns) appears 3 times. 2e.g. dependency relations that qualify apple might be ‘object of eat’ and ‘adjective red’. This gives us dependency triples like &lt; apple, obj, eat &gt;. 3.3 Measures The measures used to find MWEs are inspired by Resnik’s method to find selectional preferences (Resnik, 1993; Resnik, 1996). Resnik uses a number of measures based on the Kullback-Leibler divergence, to measure the difference betwee</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Z. Wu and M. Palmer. 1994. Verb semantics and lexical selection. In 32nd. Annual Meeting of the Association for Computational Linguistics, pages 133–138, New Mexico State University, Las Cruces, New Mexico.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>