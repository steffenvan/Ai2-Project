<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<bodyText confidence="0.1556564">
The Relationship Between Tree Adjoining Grammars And Head Grammarst
D.J. Weir K.Vijay-Shanker A.K. Joshi
Department of Computer and Information Science
University of Pennsylvania
Philadelphia, PA 19104
</bodyText>
<sectionHeader confidence="0.877452" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999967">
We examine the relationship between the two grammatical
formalisms: Tree Adjoining Grammars and Head Gram-
mars. We briefly investigate the weak equivalence of the
two formalisms. We then turn to a discussion comparing
the linguistic expressiveness of the two formalisms.
</bodyText>
<sectionHeader confidence="0.999061" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978540540541">
Recent work [9,3] has revealed a very close formal rela-
tionship between the grammatical formalisms of Tree Ad-
joining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s).
In this paper we examine whether they have the same
power of linguistic description. TAG&apos;s were first intro-
duced in 1975 by Joshi, Levy and Takahashi[1] and inves-
tigated further in [2,4,8]. HG&apos;s were first introduced by
Pollard[5]. TAG&apos;s and HG&apos;s were introduced to capture
certain structural properties of natural languages. These
formalisms were developed independently and are nota-
tionally quite different. TAG&apos;s deal with a set of elemen-
tary trees composed by means of an operation called ad-
joining. HG&apos;s maintain the essential character of context-
free string rewriting rules, except for the fact that besides
concatenation of strings, string wrapping operations are
permitted. Observations of similarities between proper-
ties of the two formalisms led us to study the formal rela-
tionship between these two formalisms and the results of
this investigation are presented in detail in [9,3]. We will
briefly describe the formal relationship established in [9,3],
showing TAG&apos;s to be equivalent to a variant of HG&apos;s. We
argue that the relationship between HG&apos;s and this variant
of HG&apos;s called Modified Head Grammars (MHG&apos;s) is very
close.
Having discussed the question of the weak equivalence
of TAG&apos;s and HG&apos;s, we explore, in Sections 4 and 5, what
might be loosely described as their strong equivalence. Sec-
tion 4 discusses consequences of the substantial notational
differences between the two formalisms. In Section 5, with
the use of several examples of analyses (that can not be
t This work was partially supported by the NSF grants
MCS-82-19116-CER, MCS-82-07294 and DCR-84-10413.
We are grateful to Tony Kroch and Carl Pollard, both
of whom have made valuable contributions to this work.
given by CFG&apos;s), we attempt to give cases in which they
have the ability to make similar analyses as well as situa-
tions in which they differ in their descriptive power.
</bodyText>
<subsectionHeader confidence="0.934192">
1.1 Definitions
</subsectionHeader>
<bodyText confidence="0.998779">
In this section, we shall briefly define the three formalisms:
TAG&apos;s, HG&apos;s, and MHG&apos;s.
</bodyText>
<subsubsectionHeader confidence="0.728224">
1.1.1 Tree Adjoining Grammars
</subsubsectionHeader>
<bodyText confidence="0.997802590909091">
Tree Adjoining Grammars differs from string rewriting sys-
tems such as Context Free Grammars in that they generate
trees. These trees are generated from a finite set of so-
called elementary trees using the operation of tree ad-
junction. There are two types of elementary trees: initial
and auxiliary. Linguistically, initial trees correspond to
phrase structure trees for basic sentential forms, whereas
auxiliary trees correspond to modifying structures.
The nodes in the frontier of elementary trees are la-
belled by terminal symbols except for one node in the fron-
tier of each auxiliary tree, the foot node, which is labelled
by the same nonterminal symbol as the root. Since initial
trees are sentential, their root is always labelled by the
nonterminal S.
We now describe the adjoining operation. Suppose we
adjoin an auxiliary tree into a sentential tree -y. The
label of the node at which the adjoining operation takes
place must be the same as the label of the root (and foot)
of #. The subtree under this node is excised from -y, the
auxiliary tree 13 is inserted in its place and the excised
subtree replaces the foot of fl. Thus the tree obtained
after adjoining 13 is as shown below.
</bodyText>
<page confidence="0.998998">
67
</page>
<bodyText confidence="0.997988176470588">
The definition of adjunction allows for more complex
constraints to be placed on adjoining. Associated with
each node is a selective adjoining (SA) constraint spec-
ifying that subset of the auxiliary tree which can be ad-
joined at this node. If the SA constraint specifies an empty
subset of trees, then we call this constraint the Null Ad-
joining (NA) constraint. If the SA constraint specifies
the entire set of auxiliary tree whose root is labelled with
the appropriate nonterminal, then by convention we will
not specify the SA constraint. We also allow obligatory
adjoining(0A) constraints at nodes, to ensure that an ad-
junction is obligatorily performed at these nodes. When
we adjoin an auxiliary tree /3 in a tree those nodes in the
resulting tree that do not correspond to nodes of /3, retain
those constraints appearing in The remaining nodes
have the same constraints as those for the corresponding
nodes of )6.
</bodyText>
<subsectionHeader confidence="0.881946">
1.1.2 Head Grammars
</subsectionHeader>
<bodyText confidence="0.9999118125">
Head Grammars are string rewriting systems like CFG&apos;s,
but differ in that each string has a distinguished symbol
corresponding to the head of the string. These are there-
fore called headed strings. The formalism allows not only
concatenation of headed strings but also so-called head
wrapping operations which split a string on one side of
the head and place another string between the two sub-
strings. We use one of two notations to denote headed
strings: when we wish to explicitly mention the head we
use the representation w1Ttw2; alternatively, we simply de-
note a headed string by 1.17. Productions in a HG are of the
form A f (al, • • • , an) or A ai where: A is a nonter-
minal; a4 is either a nonterminal or a headed string; and
f is either a concatenation or a head wrapping operation.
Roach[61 has shown that there is a normal form for Head
Grammars which uses only the following operations.
</bodyText>
<equation confidence="0.9984605">
LC1(uia7u2, vi-4v2) = u1a1u2v1a2v2
LC2(uoiu2,via2v2) = u1a1u2v1v2
LL1(uicu2,vic-v2) = uftri v a2v2u2
L L2(111-diu2 , v Cciiv 2) = u1a1v1ciiv2u2
LR1(11107u2,v1iv2) = u1v1a2v2a1u2
LR2(ufaTu2, = uiv1a2v2a1u2
</equation>
<subsectionHeader confidence="0.891154">
1.1.3 Modified Head Grammars
</subsectionHeader>
<bodyText confidence="0.977092777777778">
Pollard&apos;s definition of headed strings includes the headed
empty string (T). However the term f , kr) , .
is undefined whent-W = A. This nonuniformity has led to
difficulties in proving certain formal properties of HG&apos;s[6].
MHG&apos;s were considered to overcome these problems. Later
in this paper we shall argue that MHG&apos;s are not only close
to HG&apos;s formally, but also that they can be given a linguis-
tic interpretation which retains the essential characteristics
of HG&apos;s. It is worth noting that the definition of MHG&apos;s
given here coincides with the definition of HG&apos;s given in
[71.
Instead of headed strings, MHG&apos;s use so-called split
strings. Unlike a headed string which has a distinguished
symbol, a split string has a distinguished position about
which it may be split. In MHG&apos;s, there are 3 operations
on split strings: W, Cl, and C2. The operations Cl and
C2 correspond to the operations LC1 and LC2 in HG&apos;s.
They are defined as follows:
</bodyText>
<equation confidence="0.998573">
Cl(tu11w2,u11u2) = w11w2u1u2
C2(w11w2, uitu2) = w1w2u11u2
</equation>
<bodyText confidence="0.999561">
Since the split point is not a symbol (which can be split
either to its left or right) but a position between strings,
separate left and right wrapping operations are not needed.
The wrapping operation, W, in MHG is defined as follows:
</bodyText>
<equation confidence="0.605321">
W (wit tv2, u u2) = wiui1u2w2
</equation>
<bodyText confidence="0.9718735">
We could have defined two operations W1 and W2 as in
HG. But since W1 can very easily be simulated with other
operations, we require only W2, renamed simply W.
2 MHG&apos;s and TAG&apos;s
In this section, we discuss the weak equivalence of TAG&apos;s
and MHG&apos;s. We will first consider the relationship between
the wrapping operation W of MHG&apos;s and the adjoining
operation of TAG&apos;s.
</bodyText>
<subsectionHeader confidence="0.99035">
2.1 Wrapping and Adjoining
</subsectionHeader>
<bodyText confidence="0.927241307692308">
The weak equivalence of MHG&apos;s and TAG&apos;s is a conse-
quence of the similarities between the operations of wrap-
ping and adjoining. It is the roles played by the split point
and the foot node that underlies this relationship. When a
tree is used for adjunction, its foot node determines where
the excised subtree is reinserted. The strings in the fron-
tier to the left and right of the foot node appear on the
left and right of the frontier of the excised subtree. As
shown in the figure below, the foot node can be thought
of as a position in the frontier of a tree, determining how
the string in the frontier is split.
V, lk Vz
foot
</bodyText>
<page confidence="0.995255">
68
</page>
<bodyText confidence="0.9999172">
Adjoining in this case, corresponds to wrapping w11w2
around the split string v11v2. Thus, the split point and
the foot node perform the same role. The proofs show-
ing the equivalence of TAG&apos;s and MHG&apos;s is based on this
correspondence.
</bodyText>
<subsectionHeader confidence="0.996854">
2.2 Inclusion of TAL in MHL
</subsectionHeader>
<bodyText confidence="0.999647684210526">
We shall now briefly present a scheme for transforming a
given TAG to an equivalent MHG. We associate with each
auxiliary tree a set of productions such that each tree gen-
erated from this elementary tree with frontier w1Xw2 has
an associated derivation in the MHG, using these produc-
tions, of the split string uhttv2. The use of this tree for
adjunction at some node labelled X can be mimicked with
a single additonal production which uses the wrapping op-
eration.
For each elementary tree we return a sequence of pro-
ductions capturing the structure of the tree in the following
way. We use nonterminals that are named by the nodes of
elementary trees rather than the labels of the nodes. For
each node ti in an elementary tree, we have two nontermi-
nal X„ and Y„: Xe derives the strings appearing on the
frontier of trees derived from the subtree rooted at 17; Y„
derives the concatenation of the strings derived under each
daughter of If n has daughters th, , n, then we have
the production:
</bodyText>
<equation confidence="0.971773857142857">
&apos;Cr!
Yni —&gt; C2(a, X„),
X„
X„ —■ W (X,Y„),
X„
Y„ C2(1), X„,c)
Xns -4 17&apos;73
</equation>
<listItem confidence="0.969051">
• A
</listItem>
<bodyText confidence="0.903884">
where Ai, , g„ are the roots of the auxiliary trees adjoin-
able at Th.
</bodyText>
<subsectionHeader confidence="0.99943">
2.3 Inclusion of MHL in TAL
</subsectionHeader>
<bodyText confidence="0.998443352941176">
In this construction we use elementary trees to directly
simulate the use of productions in MHG to rewrite nonter-
minals. Generation of a derivation tree in string-rewriting
systems involves the substitution of nonterminal nodes, ap-
pearing in the frontier of the unfinished derivation tree, by
trees corresponding to productions for that nonterminal.
From the point of view of the string languages obtained,
tree adjunction can be used to simulate substitution, as
illustrated in the following example.
Y,, —0 Ci(X„„ , X„)
where the node dominates the foot node (by convention,
we let i = 1 if ti does not dominate the foot node). Adjunc-
tion at 77, is simulated by use of the following production:
X„ W (X,, Y,,)
where i is the root of some auxiliary tree which can be
adjoined at 17. If adjunction is optional at n then we include
the production:
</bodyText>
<subsubsectionHeader confidence="0.462886">
Xe—*.
</subsubsectionHeader>
<bodyText confidence="0.999817">
Notice that when ti has an NA or OA constraint we omit
the second or third of the above productions, respectively.
Rather than present the full details (which can be found
in [9,3]) we illustrate the construction with an example
showing a single auxiliary tree and the corresponding MHG
productions.
</bodyText>
<equation confidence="0.982993">
X if
/ IL
a, A
1/1 D G
)73 X %
</equation>
<bodyText confidence="0.97979725">
Notice that although the node where adjoining occurs does
not appear in the frontier of the tree, the presence of the
node labelled by the empty string does not effect the string
language.
For each production in the MHG we have an auxiliary
tree. A production in an MHG can use one of the three
operations: Cl, C2, and W. Correspondingly we have
three types of trees, shown below.
</bodyText>
<figure confidence="0.9522565">
A -4 cl(B,C)
Aø
13 OA
C OA
Aø
A W (8,0 A a C. 2 (a)
</figure>
<page confidence="0.993414">
69
</page>
<bodyText confidence="0.999939454545455">
Drawing the analogy with string-rewriting systems: NA
constraints at each root have the effect of ensuring that a
nonterminal is rewritten only once; NA constraints at the
foot node ensures that, like the nodes labelled by A, they
do not contribute to the strings derived; OA constraints
are used to ensure that every nonterminal introduced is
rewritten at least once.
The two trees mimicking the concatenation operations
differ only in the position of their foot node. This node
is positioned in order to satisfy the following requirement:
for every derivation in the MHG there must be a derived
tree in the TAG for the same string, in which the foot is
positioned at the split point.
The tree associated with the wrapping operation is
quite different. The foot node appears below the two nodes
to be expanded because the wrapping operation of MHG&apos;s
corresponds to the LL2 operation of HG&apos;s in which the
head (split point) of the second argument becomes the new
head (split point). Placement of the nonterminal, which is
to be wrapped, above the other nonterminal achieves the
desired effect as described earlier.
While straightforward, this construction does not cap-
ture the linguistic motivation underlying TAG&apos;s. The aux-
iliary trees directly reflect the use of the concatenation
and the wrapping operations. As we discuss in more detail
in Section 4, elementary trees for natural languages TAG&apos;s
are constrained to capture meaningful linguistic structures.
In the TAG&apos;s generated in the above construction, the el-
ementary trees are incomplete in this respect: as reflected
by the extensive use of the OA constraints. Since HG&apos;s
and MHG&apos;s do not explicitly give minimal linguistic struc-
tures, it is not surprising that such a direct mapping from
MHG&apos;s to TAG&apos;s does not recover this information.
</bodyText>
<sectionHeader confidence="0.985377" genericHeader="introduction">
3 HG&apos;s and MHG&apos;s
</sectionHeader>
<bodyText confidence="0.99983225">
In this section, we will discuss the relationship between
HG&apos;s and MHG&apos;s. First, we outline a construction show-
ing that HL&apos;s are included in MHL&apos;s. Problems arise in
showing the inclusion in the other direction because of the
nonuniform way in which HG&apos;s treat the empty headed
string. In the final part of this section, we argue that
MHG&apos;s can be given a meaningful linguistic interpretation,
and may be considered essentially the same as HG&apos;s.
</bodyText>
<subsectionHeader confidence="0.997757">
3.1 HL&apos;s and MHL&apos;s
</subsectionHeader>
<bodyText confidence="0.995827414634146">
The inclusion of HL&apos;s in MHL&apos;s can be shown by con-
structing for every HG, G, an equivalent MHG, G&apos;. We
now present a short description of how this construction
proceeds.
Suppose a nonterminal X derives the headed string
w1hw2. Depending on whether the left or right wrapping
operation is used, this headed string can be split on ei-
ther side of the head. In fact, a headed string can be split
first to the right of its head and then the resulting string
can be split to the left of the same head. Since in MHG&apos;s
we can only split a string in one place, we introduce non-
terminals XV&apos;, that derive split strings of the form w11w2
whenever X derives w1hw2 in the HG. The missing head
can be reintroduced with the following productions:
W(Xth, ht) and X&apos; --■W(X1h,
Thus, the two nonterminals, Xi and Xr derive wihtw2 and
withw2 respectively. Complete details of this proof are
given in [31.
We are unable to give a general proof showing the in-
clusion of MHL&apos;s in HL&apos;s. Although Pollard[5] allows the
use of the empty headed string, mathematically, it does not
have the same status as other headed strings. For exam-
ple, LC1(A-, Tv) is undefined. Although we have not found
any way of getting around this in a systematic manner,
we feel that the problem of the empty headed string in the
HG formalism does not result from an important difference
between the formalisms.
For any particular natural language, Head Grammars
for that language appear to use either only the left wrap-
ping operations LLi, or only the right wrapping operations
LRi. Based on this observation, we suggest that for any
HG for a natural language, there will be a corresponding
MHG which can be given a linguistic interpretation. Since
headed strings will always be split on the same side of the
head, we can think of the split point in a split string as
determining the head position. For example, split strings
generated by a MHG for a natural language that uses only
the left wrapping operations have their split points imme-
diately to the right of the actual head. Thus a split point
in a phrase not only defines where the phrase can be split,
but also the head of the string.
</bodyText>
<sectionHeader confidence="0.9922705" genericHeader="method">
4 Notational Differences between
TAG&apos;s and HG&apos;s
</sectionHeader>
<bodyText confidence="0.999502111111111">
TAG&apos;s and HG&apos;s are notationally very different, and this
has a number of consequences that influence the way in
which the formalisms can be used to express various as-
pects of language structure. The principal differences de-
rive from the fact that TAG&apos;s are a tree-rewriting system
unlike HG&apos;s which manipulate strings.
The elementary trees in a TAG, in order to be linguisti-
cally meaningful, must conform to certain constraints that
are not explicitly specified in the definition of the formal-
</bodyText>
<page confidence="0.995363">
70
</page>
<bodyText confidence="0.999481727272728">
ism. In particular, each elementary tree must constitute
a minimal linguistic structure. Initial trees have essen-
tially the structure of simple sentences; auxiliary trees cor-
respond to minimal recursive constructions and generally
constitute structures that act as modifiers of the category
appearing at their root and foot nodes.
A hypothesis that underlies the linguistic intuitions of
TAG&apos;s is that all dependencies are captured within elemen-
tary trees. This is based on the assumption that elemen-
tary trees are the appropriate domain upon which to define
dependencies, rather than, for example, productions in a
Context-free Grammar. Since in string-rewriting systems,
dependent lexical items can not always appear in the same
production, the formalism does not prevent the possibility
that it may be necessary to perform an unbounded amount
of computation in order to check that two dependent lex-
ical items agree in certain features. However, since in
TAG&apos;s dependencies are captured by bounded structures,
we expect that the complexity of this computation does
not depend on the derivation. Features such as agreement
may be checked within the elementary trees (instantiated
up to lexical items) without need to percolate information
up the derivation tree in an unbounded way. Some check-
ing is necessary between an elementary tree and an auxil-
iary tree adjoined to it at some node, but this checking is
still local and unbounded. Similarly, elementary trees, be-
ing minimal linguistic structures, should capture all of the
sub-categorization information, simplifying the processing
required during parsing. Further work (especially empiri-
cal) is necessary to confirm the above hypothesis before we
can conclude that elementary trees can in fact capture all
the necessary information or whether we must draw upon
more complex machinery. These issues will be discussed in
detail in a later paper.
Another important feature of TAG&apos;s that differentiates
them from HG&apos;s is that TAG&apos;s generate phrase-structure
trees. As a result, the elementary trees must conform to
certain constraints such as left-to-right ordering and lin-
guistically meaningful dominance relations. Unlike other
string-rewriting systems that use only the operation of con-
catenation, HG&apos;s do not associate a phrase-structure tree
with a derivation: wrapping, unlike concatenation, does
not preserve the word order of its arguments. In the Sec-
tion 5, we will present an example illustrating the impor-
tance of this difference between the two formalisms.
It is still possible to associate a phrase-structure with
a derivation in HG&apos;s that indicates the constituents and
we use this structure when comparing the analyses made
by the two systems. These trees are not really phrase-
structure trees but rather trees with annotations which
indicate how the constituents will be wrapped (or concate-
nated). It is thus a derivation structure, recording the his-
tory of the derivation. With an example we now illustrate
how a constituent analysis is produced by a derivation in
a HG.
</bodyText>
<equation confidence="0.9026732">
VP REI
V S LC 2
I /
scuo NP VP
frla,j swim
</equation>
<sectionHeader confidence="0.959945" genericHeader="method">
5 Towards &amp;quot;Strong&amp;quot; equivalence
</sectionHeader>
<bodyText confidence="0.999927">
In Section 2 we considered the weak equivalence of the two
formalisms. In this section, we will consider three exam-
ples in order to compare the linguistic analyses that can
be given by the two formalisms. We begin with an ex-
ample (Example 1) which illustrates that the construction
given in Section 2 for converting a TAG into an MHG gives
similar structures. We then consider an example (Exam-
ple 2) which demonstrates that the construction does not
always preserve the structure. However, there is an al-
ternate way of viewing the relationship between wrapping
and adjoining, which, for the same example, does preserve
the structure.
Although the usual notion of strong equivalence (i.e.,
equivalence under identity of structural descriptions) can
not be used in comparing TAG and HG (as we have already
indicated in Section 4), we will describe informally what
the notion of &amp;quot;strong&amp;quot; equivalence should be in this case.
We then illustrate by means of an example (Example 3),
how the two systems differ in this respect.
</bodyText>
<subsectionHeader confidence="0.994066">
5.1 Example 1
</subsectionHeader>
<bodyText confidence="0.999307666666667">
Pollard[5] has suggested that HG can be used to provide
an appropriate analysis for easy problems to solve. He does
not provide a detailed analysis but it is roughly as follows.
</bodyText>
<figure confidence="0.3758945">
NP LL 2
N
AP ILI NP
5
easy
-1. Sol Vt.
</figure>
<page confidence="0.998445">
71
</page>
<bodyText confidence="0.9941548">
This analysis can not be provided by CFG&apos;s since in de-
riving easy to solve we can not obtain easy to solve and
problems as intermediate phrases. The appropriate ele-
mentary tree for a TAG giving the same analysis would
be:
</bodyText>
<figure confidence="0.8184155">
NP
/
AP NP 5
\
to sok.
easy
</figure>
<bodyText confidence="0.999889833333333">
Note that the phrase easy to solve wraps around problems
by splitting about the head and the foot node in both
the grammars. Since the conversion of this TAG would
result in the HG given above, this example shows that the
construction captures the correct correspondence between
the two formalisms.
</bodyText>
<subsectionHeader confidence="0.993461">
5.2 Example 2
</subsectionHeader>
<bodyText confidence="0.999991">
We now present an example demonstrating that the con-
struction does not always preserve the details of the lin-
guistic analysis. This example concerns cross-serial depen-
dencies, for example, dependencies between NP&apos;s and V&apos;s
in subordinate clauses in Dutch (cited frequently as an
example of a non-context-free construction). For example,
the Dutch equivalent of John saw Mary swim is John Mary
saw swim. Although these dependencies can involve an ar-
bitrary number of verbs, for our purposes it is sufficient to
consider this simple case. The elementary trees used in a
TAG, GTAG, generating this sentence are given below.
</bodyText>
<equation confidence="0.863616875">
/5\
5 VP
/\
NP VP ,V
I I.
N Swan
I I
Mani e
</equation>
<bodyText confidence="0.999743333333333">
The HG given in [5] (GH) assigns the following deriva-
tion structure (an annotated phrase-structure recording
the history of the derivation) for this sentence.
</bodyText>
<figure confidence="0.758852666666667">
S l-c2
NP VP IV&apos;
IV V S
I I /N
folln Saw NP
flary
</figure>
<bodyText confidence="0.991566">
If we use the construction in Section 2 on the elemen-
tary trees for the TAG shown above, we would generate
an HG, GIHG, that produces the following analysis of this
sentence.
</bodyText>
<equation confidence="0.631449727272727">
3 1.c
?Ml vP
/°\
NP Lcz
I.
N NP VP sage,
I I I
N V
ALT
I \
scuA)
</equation>
<bodyText confidence="0.999906428571429">
This does not give the same analysis as GHG: both GHG
and GTAG give intermediate structures in which the predi-
cate help(Mary swim) is formed. This then combines with
the noun phrase John giving the resulting sentence. In the
HG GIHG John is first combined with Mary swim: this is
not an acceptable linguistic structure. G1HG corresponds
in this sense to the following unacceptable TAG, G1TAG.
</bodyText>
<figure confidence="0.95177264">
vs
\y
NP e
I\IN
N
\ ti/
Mara NP VP &amp;
J I I
1//
1
5 WW1
VP
/5\
NP VP
/
N S V
fohn e
/
NP VP
\
S V
A I
Lim &amp;quot;Ait9 VP t
C S
SaW
</figure>
<page confidence="0.991562">
72
</page>
<bodyText confidence="0.999879793103449">
Not only does the Construction map the acceptable
TAG to the unacceptable HG; but it can also be shown
that the unacceptable TAG is converted into the accept-
able HG. This suggests that our construction does not al-
ways preserve linguistic analyses. This arises because the
use of wrapping operation does not correspond to the way
in which the foot node splits the auxiliary tree in this case.
However, there is an alternate way of viewing the manner
in which wrapping and adjoining can be related. Consider
the following tree.
Instead of wrapping w1w2 around ui and then concate-
nating u2; while deriving the string w1thw2u2 we could
derive the string by wrapping u1u2 around w2 and then
concatenating w1. This can not be done in the general
case (for example, when the string u is nonempty).
The two grammars GHG and GTAG can be related in
this manner since GTAG satisfies the required conditions.
This approach may be interpreted as combining the phrase
u1u2 with w2 to form the phrase u1w2u2. Relating the
above tree to Example 2, u1 and u2 correspond to Mary
and swim respectively and w2 corresponds to saw. Thus,
Mary swim wraps around saw to produce the verb phrase
Mary saw swim as in the TAG GTAG and the HG GHG•
As the previous two examples illustrate, there are two
ways of drawing a correspondence between wrapping and
adjoining,both of which can be applicable. However, only
one of them is general enough to cover all situations, and
is the one used in Sections 2 and 3 in discussing the weak
equivalence.
</bodyText>
<subsectionHeader confidence="0.971911">
5.3 Example 3
</subsectionHeader>
<bodyText confidence="0.999944695652174">
The normal notion of strong equivalence can not be used to
discuss the relationship between the two formalisms, since
HG&apos;s do not generate the standard phrase structure trees
(from the derivation structure). However, it is possible to
relate the analyses given by the two systems. This can be
done in terms of the intermediate constituent structures.
So far, in Examples 1 and 2 considered above we showed
that the same analyses can be given in both the formalisms.
We now present an example suggesting that this is not al-
ways the case. There are certain constraints placed on ele-
mentary trees: that they use meaningful elementary trees
corresponding to minimal linguistic structures (for exam-
ple, the verb and all its complements, including the subject
complement are in the same elementary tree); and that
the final tree must be a phrase-structure tree. As a result,
TAG&apos;s can not give certain analyses which the HG&apos;s can
provide, as evidenced in the following example.
The example we use concerns analyses of John per-
suaded Bill to leave. We will discuss two analyses both
of which have been proposed in the literature and have
been independently justified. First, we present an analysis
that can be expressed in both formalisms. The TAG has
the following two elementary trees.
</bodyText>
<figure confidence="0.558207583333333">
NP VP
Al V NP 5
3orI I
1,01(1(44 N
&amp;Lit
The derivation structure corresponding to this analysis
that HG&apos;s can give is as follows.
S 4c2
NP VP Lc/
V iv P 5
I
persuacha Ni to leave,
</figure>
<bodyText confidence="0.9255605">
However, Pollard[5] gives another analysis which has the
following derivation structure.
</bodyText>
<figure confidence="0.849233444444444">
P V P
1 to leave,
73
LC2
NP VP Li-I
N
VP i ct WP
3-ohn If/ \5
/\
</figure>
<figureCaption confidence="0.938106">
pus...Jed t. Leave Sat
</figureCaption>
<bodyText confidence="0.999971105263158">
In this analysis the predicate persuade to leave is formed as
an intermediate phrase. Wrapping is then used to derive
the phrase persuade Bill to leave. To provide such an anal-
ysis with TAG&apos;s, the phrase persuade to leave must appear
in the same elementary tree. Bill must either appear in
an another elementary tree or must be above the phrase
persuade to leave if it appears in the same elementary tree
(so that the phrase persuade to leave is formed first). It
can not appear above the phrase persuade to leave since
then the word order will not be correct. Alternatively, it
can not appear in a separate elementary tree since no mat-
ter which correspondence we make between wrapping and
adjoining, we can not get a TAG which has meaningful el-
ementary trees providing the same analysis. Thus the only
appropriate TAG for this example is as shown above.
The significance of this constraint that TAG&apos;s appear
to have (illustrated by Example 3) can not be assessed until
a wider range of examples are evaluated from this point of
view.
</bodyText>
<sectionHeader confidence="0.999429" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999976727272727">
This paper focusses on the linguistic aspects of the re-
lationship between Head Grammars and Tree Adjoining
Grammars. With the use of examples, we not only illus-
trate cases where the two formalisms make similar analy-
ses, but also discuss differences in their descriptive power.
Further empirical study is required before we can deter-
mine the significance of these differences. We have also
briefly studied the consequences of the notational differ-
ences between the formalisms. A more detailed analysis
of the linguistic and computational aspects of these differ-
ences is currently being pursued.
</bodyText>
<sectionHeader confidence="0.994354" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999856648648649">
[1] Joshi, A. K., Levy, L. S., and Takahashi, M. Tree
Adjunct Grammars. Journal of Computer and System
Sciences 10(1), March, 1975.
[2] Joshi, A. K. How Much Context-Sensitivity is Neces-
sary for Characterizing Structural descriptions - Tree
Adjoining Grammars. In D. Dowty, L. Karttunen and
Zwicky, A. (editors), Natural Language Processing -
Theoretical, Computational and Psychological Perspec-
tive. Cambridge University Press, New York, 1985.
originally presented in 1983.
[3] Joshi, A. K., Vijay-Shanker, K., and Weir, D.J. Tree
Adjoining Grammars and Head Grammars. Techni-
cal Report MS-CIS-86-1, Department of Computer
and Information Science, University of Pennsylvania,
Philadelphia, January, 1986.
[4] Kroch, A. and Joshi, A. K. Linguistic Relevance of Tree
Adjoining Grammars. Technical Report MS-CIS-85-
18, Department of Computer and Information Science,
University of Pennsylvania, Philadelphia, April, 1985.
also to appear in Linguistics and Philosophy, 1986.
[5] Pollard, C. Generalized Phrase Structure Grammars,
Head Grammars and Natural Language. PhD thesis,
Stanford University, August, 1984.
[6] Roach, K. Formal Properties of Head Grammars.
1985. Presented at Mathematics of Language workshop
at the University of Michigan, Ann Arbor.
[7] Rounds, W. C. LFP: A Logic for Linguistic Descrip-
tions and an Analysis of its Complexity. September,
1985. University of Michigan.
[8] Vijay-Shanker, K. and Joshi, A. K. Some Compu-
tational Properties of Tree Adjoining Grammars. In
23rd meeting of Assoc. of Computational Linguistics,
pages 82-93. July, 1985.
[9] Vijay-Shanker, K., Weir, D. J., and Joshi, A. K. Tree
Adjoining and Head Wrapping. In 1104 International
Conference on Computational Linguistics. August,
1986.
</reference>
<page confidence="0.99913">
74
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.990629">
<title confidence="0.999676">The Relationship Between Tree Adjoining Grammars And Head Grammarst</title>
<author confidence="0.999739">D J Weir K Vijay-Shanker A K Joshi</author>
<affiliation confidence="0.999908">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.999626">Philadelphia, PA 19104</address>
<abstract confidence="0.998601833333333">We examine the relationship between the two grammatical formalisms: Tree Adjoining Grammars and Head Grammars. We briefly investigate the weak equivalence of the two formalisms. We then turn to a discussion comparing the linguistic expressiveness of the two formalisms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>L S Levy</author>
<author>M Takahashi</author>
</authors>
<title>Tree Adjunct Grammars.</title>
<date>1975</date>
<journal>Journal of Computer and System Sciences</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="808" citStr="[1]" startWordPosition="119" endWordPosition="119">tract We examine the relationship between the two grammatical formalisms: Tree Adjoining Grammars and Head Grammars. We briefly investigate the weak equivalence of the two formalisms. We then turn to a discussion comparing the linguistic expressiveness of the two formalisms. 1 Introduction Recent work [9,3] has revealed a very close formal relationship between the grammatical formalisms of Tree Adjoining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s). In this paper we examine whether they have the same power of linguistic description. TAG&apos;s were first introduced in 1975 by Joshi, Levy and Takahashi[1] and investigated further in [2,4,8]. HG&apos;s were first introduced by Pollard[5]. TAG&apos;s and HG&apos;s were introduced to capture certain structural properties of natural languages. These formalisms were developed independently and are notationally quite different. TAG&apos;s deal with a set of elementary trees composed by means of an operation called adjoining. HG&apos;s maintain the essential character of contextfree string rewriting rules, except for the fact that besides concatenation of strings, string wrapping operations are permitted. Observations of similarities between properties of the two formalisms </context>
</contexts>
<marker>[1]</marker>
<rawString>Joshi, A. K., Levy, L. S., and Takahashi, M. Tree Adjunct Grammars. Journal of Computer and System Sciences 10(1), March, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>How Much Context-Sensitivity is Necessary for Characterizing Structural descriptions - Tree Adjoining Grammars. In</title>
<date>1985</date>
<booktitle>Natural Language Processing -Theoretical, Computational and Psychological Perspective.</booktitle>
<editor>D. Dowty, L. Karttunen and Zwicky, A. (editors),</editor>
<publisher>Cambridge University Press,</publisher>
<location>New York,</location>
<note>originally presented in</note>
<contexts>
<context position="844" citStr="[2,4,8]" startWordPosition="125" endWordPosition="125">p between the two grammatical formalisms: Tree Adjoining Grammars and Head Grammars. We briefly investigate the weak equivalence of the two formalisms. We then turn to a discussion comparing the linguistic expressiveness of the two formalisms. 1 Introduction Recent work [9,3] has revealed a very close formal relationship between the grammatical formalisms of Tree Adjoining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s). In this paper we examine whether they have the same power of linguistic description. TAG&apos;s were first introduced in 1975 by Joshi, Levy and Takahashi[1] and investigated further in [2,4,8]. HG&apos;s were first introduced by Pollard[5]. TAG&apos;s and HG&apos;s were introduced to capture certain structural properties of natural languages. These formalisms were developed independently and are notationally quite different. TAG&apos;s deal with a set of elementary trees composed by means of an operation called adjoining. HG&apos;s maintain the essential character of contextfree string rewriting rules, except for the fact that besides concatenation of strings, string wrapping operations are permitted. Observations of similarities between properties of the two formalisms led us to study the formal relations</context>
</contexts>
<marker>[2]</marker>
<rawString>Joshi, A. K. How Much Context-Sensitivity is Necessary for Characterizing Structural descriptions - Tree Adjoining Grammars. In D. Dowty, L. Karttunen and Zwicky, A. (editors), Natural Language Processing -Theoretical, Computational and Psychological Perspective. Cambridge University Press, New York, 1985. originally presented in 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>K Vijay-Shanker</author>
<author>D J Weir</author>
</authors>
<title>Tree Adjoining Grammars and Head Grammars.</title>
<date>1986</date>
<tech>Technical Report MS-CIS-86-1,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania,</institution>
<location>Philadelphia,</location>
<contexts>
<context position="1547" citStr="[9,3]" startWordPosition="232" endWordPosition="232">ctural properties of natural languages. These formalisms were developed independently and are notationally quite different. TAG&apos;s deal with a set of elementary trees composed by means of an operation called adjoining. HG&apos;s maintain the essential character of contextfree string rewriting rules, except for the fact that besides concatenation of strings, string wrapping operations are permitted. Observations of similarities between properties of the two formalisms led us to study the formal relationship between these two formalisms and the results of this investigation are presented in detail in [9,3]. We will briefly describe the formal relationship established in [9,3], showing TAG&apos;s to be equivalent to a variant of HG&apos;s. We argue that the relationship between HG&apos;s and this variant of HG&apos;s called Modified Head Grammars (MHG&apos;s) is very close. Having discussed the question of the weak equivalence of TAG&apos;s and HG&apos;s, we explore, in Sections 4 and 5, what might be loosely described as their strong equivalence. Section 4 discusses consequences of the substantial notational differences between the two formalisms. In Section 5, with the use of several examples of analyses (that can not be t This</context>
<context position="10678" citStr="[9,3]" startWordPosition="1815" endWordPosition="1815">e used to simulate substitution, as illustrated in the following example. Y,, —0 Ci(X„„ , X„) where the node dominates the foot node (by convention, we let i = 1 if ti does not dominate the foot node). Adjunction at 77, is simulated by use of the following production: X„ W (X,, Y,,) where i is the root of some auxiliary tree which can be adjoined at 17. If adjunction is optional at n then we include the production: Xe—*. Notice that when ti has an NA or OA constraint we omit the second or third of the above productions, respectively. Rather than present the full details (which can be found in [9,3]) we illustrate the construction with an example showing a single auxiliary tree and the corresponding MHG productions. X if / IL a, A 1/1 D G )73 X % Notice that although the node where adjoining occurs does not appear in the frontier of the tree, the presence of the node labelled by the empty string does not effect the string language. For each production in the MHG we have an auxiliary tree. A production in an MHG can use one of the three operations: Cl, C2, and W. Correspondingly we have three types of trees, shown below. A -4 cl(B,C) Aø 13 OA C OA Aø A W (8,0 A a C. 2 (a) 69 Drawing the a</context>
</contexts>
<marker>[3]</marker>
<rawString>Joshi, A. K., Vijay-Shanker, K., and Weir, D.J. Tree Adjoining Grammars and Head Grammars. Technical Report MS-CIS-86-1, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, January, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kroch</author>
<author>A K Joshi</author>
</authors>
<title>Linguistic Relevance of Tree Adjoining Grammars.</title>
<date>1985</date>
<tech>Technical Report MS-CIS-85-18,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania,</institution>
<location>Philadelphia,</location>
<contexts>
<context position="844" citStr="[2,4,8]" startWordPosition="125" endWordPosition="125">p between the two grammatical formalisms: Tree Adjoining Grammars and Head Grammars. We briefly investigate the weak equivalence of the two formalisms. We then turn to a discussion comparing the linguistic expressiveness of the two formalisms. 1 Introduction Recent work [9,3] has revealed a very close formal relationship between the grammatical formalisms of Tree Adjoining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s). In this paper we examine whether they have the same power of linguistic description. TAG&apos;s were first introduced in 1975 by Joshi, Levy and Takahashi[1] and investigated further in [2,4,8]. HG&apos;s were first introduced by Pollard[5]. TAG&apos;s and HG&apos;s were introduced to capture certain structural properties of natural languages. These formalisms were developed independently and are notationally quite different. TAG&apos;s deal with a set of elementary trees composed by means of an operation called adjoining. HG&apos;s maintain the essential character of contextfree string rewriting rules, except for the fact that besides concatenation of strings, string wrapping operations are permitted. Observations of similarities between properties of the two formalisms led us to study the formal relations</context>
</contexts>
<marker>[4]</marker>
<rawString>Kroch, A. and Joshi, A. K. Linguistic Relevance of Tree Adjoining Grammars. Technical Report MS-CIS-85-18, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, April, 1985. also to appear in Linguistics and Philosophy, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
</authors>
<title>Generalized Phrase Structure Grammars, Head Grammars and Natural Language. PhD thesis,</title>
<date>1984</date>
<institution>Stanford University,</institution>
<contexts>
<context position="886" citStr="[5]" startWordPosition="131" endWordPosition="131"> Adjoining Grammars and Head Grammars. We briefly investigate the weak equivalence of the two formalisms. We then turn to a discussion comparing the linguistic expressiveness of the two formalisms. 1 Introduction Recent work [9,3] has revealed a very close formal relationship between the grammatical formalisms of Tree Adjoining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s). In this paper we examine whether they have the same power of linguistic description. TAG&apos;s were first introduced in 1975 by Joshi, Levy and Takahashi[1] and investigated further in [2,4,8]. HG&apos;s were first introduced by Pollard[5]. TAG&apos;s and HG&apos;s were introduced to capture certain structural properties of natural languages. These formalisms were developed independently and are notationally quite different. TAG&apos;s deal with a set of elementary trees composed by means of an operation called adjoining. HG&apos;s maintain the essential character of contextfree string rewriting rules, except for the fact that besides concatenation of strings, string wrapping operations are permitted. Observations of similarities between properties of the two formalisms led us to study the formal relationship between these two formalisms and the r</context>
<context position="14529" citStr="[5]" startWordPosition="2487" endWordPosition="2487">an be split first to the right of its head and then the resulting string can be split to the left of the same head. Since in MHG&apos;s we can only split a string in one place, we introduce nonterminals XV&apos;, that derive split strings of the form w11w2 whenever X derives w1hw2 in the HG. The missing head can be reintroduced with the following productions: W(Xth, ht) and X&apos; --■W(X1h, Thus, the two nonterminals, Xi and Xr derive wihtw2 and withw2 respectively. Complete details of this proof are given in [31. We are unable to give a general proof showing the inclusion of MHL&apos;s in HL&apos;s. Although Pollard[5] allows the use of the empty headed string, mathematically, it does not have the same status as other headed strings. For example, LC1(A-, Tv) is undefined. Although we have not found any way of getting around this in a systematic manner, we feel that the problem of the empty headed string in the HG formalism does not result from an important difference between the formalisms. For any particular natural language, Head Grammars for that language appear to use either only the left wrapping operations LLi, or only the right wrapping operations LRi. Based on this observation, we suggest that for a</context>
<context position="20393" citStr="[5]" startWordPosition="3443" endWordPosition="3443">does not always preserve the structure. However, there is an alternate way of viewing the relationship between wrapping and adjoining, which, for the same example, does preserve the structure. Although the usual notion of strong equivalence (i.e., equivalence under identity of structural descriptions) can not be used in comparing TAG and HG (as we have already indicated in Section 4), we will describe informally what the notion of &amp;quot;strong&amp;quot; equivalence should be in this case. We then illustrate by means of an example (Example 3), how the two systems differ in this respect. 5.1 Example 1 Pollard[5] has suggested that HG can be used to provide an appropriate analysis for easy problems to solve. He does not provide a detailed analysis but it is roughly as follows. NP LL 2 N AP ILI NP 5 easy -1. Sol Vt. 71 This analysis can not be provided by CFG&apos;s since in deriving easy to solve we can not obtain easy to solve and problems as intermediate phrases. The appropriate elementary tree for a TAG giving the same analysis would be: NP / AP NP 5 \ to sok. easy Note that the phrase easy to solve wraps around problems by splitting about the head and the foot node in both the grammars. Since the conve</context>
<context position="21850" citStr="[5]" startWordPosition="3708" endWordPosition="3708">serve the details of the linguistic analysis. This example concerns cross-serial dependencies, for example, dependencies between NP&apos;s and V&apos;s in subordinate clauses in Dutch (cited frequently as an example of a non-context-free construction). For example, the Dutch equivalent of John saw Mary swim is John Mary saw swim. Although these dependencies can involve an arbitrary number of verbs, for our purposes it is sufficient to consider this simple case. The elementary trees used in a TAG, GTAG, generating this sentence are given below. /5\ 5 VP /\ NP VP ,V I I. N Swan I I Mani e The HG given in [5] (GH) assigns the following derivation structure (an annotated phrase-structure recording the history of the derivation) for this sentence. S l-c2 NP VP IV&apos; IV V S I I /N folln Saw NP flary If we use the construction in Section 2 on the elementary trees for the TAG shown above, we would generate an HG, GIHG, that produces the following analysis of this sentence. 3 1.c ?Ml vP /°\ NP Lcz I. N NP VP sage, I I I N V ALT I \ scuA) This does not give the same analysis as GHG: both GHG and GTAG give intermediate structures in which the predicate help(Mary swim) is formed. This then combines with the </context>
<context position="25810" citStr="[5]" startWordPosition="4429" endWordPosition="4429">n not give certain analyses which the HG&apos;s can provide, as evidenced in the following example. The example we use concerns analyses of John persuaded Bill to leave. We will discuss two analyses both of which have been proposed in the literature and have been independently justified. First, we present an analysis that can be expressed in both formalisms. The TAG has the following two elementary trees. NP VP Al V NP 5 3orI I 1,01(1(44 N &amp;Lit The derivation structure corresponding to this analysis that HG&apos;s can give is as follows. S 4c2 NP VP Lc/ V iv P 5 I persuacha Ni to leave, However, Pollard[5] gives another analysis which has the following derivation structure. P V P 1 to leave, 73 LC2 NP VP Li-I N VP i ct WP 3-ohn If/ \5 /\ pus...Jed t. Leave Sat In this analysis the predicate persuade to leave is formed as an intermediate phrase. Wrapping is then used to derive the phrase persuade Bill to leave. To provide such an analysis with TAG&apos;s, the phrase persuade to leave must appear in the same elementary tree. Bill must either appear in an another elementary tree or must be above the phrase persuade to leave if it appears in the same elementary tree (so that the phrase persuade to leave</context>
</contexts>
<marker>[5]</marker>
<rawString>Pollard, C. Generalized Phrase Structure Grammars, Head Grammars and Natural Language. PhD thesis, Stanford University, August, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Roach</author>
</authors>
<title>Formal Properties of Head Grammars.</title>
<date>1985</date>
<institution>University of Michigan,</institution>
<location>Ann Arbor.</location>
<contexts>
<context position="6143" citStr="[6]" startWordPosition="1003" endWordPosition="1003">atenation or a head wrapping operation. Roach[61 has shown that there is a normal form for Head Grammars which uses only the following operations. LC1(uia7u2, vi-4v2) = u1a1u2v1a2v2 LC2(uoiu2,via2v2) = u1a1u2v1v2 LL1(uicu2,vic-v2) = uftri v a2v2u2 L L2(111-diu2 , v Cciiv 2) = u1a1v1ciiv2u2 LR1(11107u2,v1iv2) = u1v1a2v2a1u2 LR2(ufaTu2, = uiv1a2v2a1u2 1.1.3 Modified Head Grammars Pollard&apos;s definition of headed strings includes the headed empty string (T). However the term f , kr) , . is undefined whent-W = A. This nonuniformity has led to difficulties in proving certain formal properties of HG&apos;s[6]. MHG&apos;s were considered to overcome these problems. Later in this paper we shall argue that MHG&apos;s are not only close to HG&apos;s formally, but also that they can be given a linguistic interpretation which retains the essential characteristics of HG&apos;s. It is worth noting that the definition of MHG&apos;s given here coincides with the definition of HG&apos;s given in [71. Instead of headed strings, MHG&apos;s use so-called split strings. Unlike a headed string which has a distinguished symbol, a split string has a distinguished position about which it may be split. In MHG&apos;s, there are 3 operations on split strings</context>
</contexts>
<marker>[6]</marker>
<rawString>Roach, K. Formal Properties of Head Grammars. 1985. Presented at Mathematics of Language workshop at the University of Michigan, Ann Arbor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Rounds</author>
</authors>
<title>LFP: A Logic for Linguistic Descriptions and an Analysis of its Complexity.</title>
<date>1985</date>
<institution>University of Michigan.</institution>
<marker>[7]</marker>
<rawString>Rounds, W. C. LFP: A Logic for Linguistic Descriptions and an Analysis of its Complexity. September, 1985. University of Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>A K Joshi</author>
</authors>
<title>Some Computational Properties of Tree Adjoining Grammars.</title>
<date>1985</date>
<booktitle>In 23rd meeting of Assoc. of Computational Linguistics,</booktitle>
<pages>82--93</pages>
<contexts>
<context position="844" citStr="[2,4,8]" startWordPosition="125" endWordPosition="125">p between the two grammatical formalisms: Tree Adjoining Grammars and Head Grammars. We briefly investigate the weak equivalence of the two formalisms. We then turn to a discussion comparing the linguistic expressiveness of the two formalisms. 1 Introduction Recent work [9,3] has revealed a very close formal relationship between the grammatical formalisms of Tree Adjoining Grammars (TAG&apos;s) and Head Grammars (HG&apos;s). In this paper we examine whether they have the same power of linguistic description. TAG&apos;s were first introduced in 1975 by Joshi, Levy and Takahashi[1] and investigated further in [2,4,8]. HG&apos;s were first introduced by Pollard[5]. TAG&apos;s and HG&apos;s were introduced to capture certain structural properties of natural languages. These formalisms were developed independently and are notationally quite different. TAG&apos;s deal with a set of elementary trees composed by means of an operation called adjoining. HG&apos;s maintain the essential character of contextfree string rewriting rules, except for the fact that besides concatenation of strings, string wrapping operations are permitted. Observations of similarities between properties of the two formalisms led us to study the formal relations</context>
</contexts>
<marker>[8]</marker>
<rawString>Vijay-Shanker, K. and Joshi, A. K. Some Computational Properties of Tree Adjoining Grammars. In 23rd meeting of Assoc. of Computational Linguistics, pages 82-93. July, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>D J Weir</author>
<author>A K Joshi</author>
</authors>
<title>Tree Adjoining and Head Wrapping.</title>
<date>1986</date>
<booktitle>In 1104 International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="1547" citStr="[9,3]" startWordPosition="232" endWordPosition="232">ctural properties of natural languages. These formalisms were developed independently and are notationally quite different. TAG&apos;s deal with a set of elementary trees composed by means of an operation called adjoining. HG&apos;s maintain the essential character of contextfree string rewriting rules, except for the fact that besides concatenation of strings, string wrapping operations are permitted. Observations of similarities between properties of the two formalisms led us to study the formal relationship between these two formalisms and the results of this investigation are presented in detail in [9,3]. We will briefly describe the formal relationship established in [9,3], showing TAG&apos;s to be equivalent to a variant of HG&apos;s. We argue that the relationship between HG&apos;s and this variant of HG&apos;s called Modified Head Grammars (MHG&apos;s) is very close. Having discussed the question of the weak equivalence of TAG&apos;s and HG&apos;s, we explore, in Sections 4 and 5, what might be loosely described as their strong equivalence. Section 4 discusses consequences of the substantial notational differences between the two formalisms. In Section 5, with the use of several examples of analyses (that can not be t This</context>
<context position="10678" citStr="[9,3]" startWordPosition="1815" endWordPosition="1815">e used to simulate substitution, as illustrated in the following example. Y,, —0 Ci(X„„ , X„) where the node dominates the foot node (by convention, we let i = 1 if ti does not dominate the foot node). Adjunction at 77, is simulated by use of the following production: X„ W (X,, Y,,) where i is the root of some auxiliary tree which can be adjoined at 17. If adjunction is optional at n then we include the production: Xe—*. Notice that when ti has an NA or OA constraint we omit the second or third of the above productions, respectively. Rather than present the full details (which can be found in [9,3]) we illustrate the construction with an example showing a single auxiliary tree and the corresponding MHG productions. X if / IL a, A 1/1 D G )73 X % Notice that although the node where adjoining occurs does not appear in the frontier of the tree, the presence of the node labelled by the empty string does not effect the string language. For each production in the MHG we have an auxiliary tree. A production in an MHG can use one of the three operations: Cl, C2, and W. Correspondingly we have three types of trees, shown below. A -4 cl(B,C) Aø 13 OA C OA Aø A W (8,0 A a C. 2 (a) 69 Drawing the a</context>
</contexts>
<marker>[9]</marker>
<rawString>Vijay-Shanker, K., Weir, D. J., and Joshi, A. K. Tree Adjoining and Head Wrapping. In 1104 International Conference on Computational Linguistics. August, 1986.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>