<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.953185">
Unification-Based Semantic Interpretation
</title>
<note confidence="0.3485045">
Robert C. Moore
Artificial Intelligence Center
SRI International
Menlo Park, CA 94025
</note>
<sectionHeader confidence="0.963953" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999976125">
We show how unification can be used to spec-
ify the semantic interpretation of natural-language
expressions, including problematical constructions
involving long-distance dependencies. We also
sketch a theoretical foundation for unification-
based semantic interpretation, and compare the
unification-based approach with more conven-
tional techniques based on the lambda calculus.
</bodyText>
<sectionHeader confidence="0.999341" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994872">
Over the past several years, unification-based for-
malisms (Shieber, 1986) have come to be widely
used for specifying the syntax of natural lan-
guages, particularly among computational lin-
guists. It is less widely realized by computa-
tional linguists that unification can also be a pow-
erful tool for specifying the semantic interpreta-
tion of natural languages. While many of the
techniques described in this paper are fairly well
known among natural-language researchers work-
ing with logic grammars, they have not been ex-
tensively discussed in the literature, perhaps the
only systematic presentation being that of Pereira
and Shieber (1987). This paper goes into many is-
sues in greater detail than do Pereira and Shieber,
however, and sketches what may be the first the-
oretical analysis of unification-based semantic in-
terpretation.
We begin by reviewing the basic ideas behind
unification-based grammar formalisms, which will
also serve to introduce the style of notation to be
used throughout the paper. The notation is that
used in the Core Language Engine (CLE) devel-
oped by SRI&apos;s Cambridge Computer Science Re-
search Center in Cambridge, England, a system
whose semantic-interpretation component makes
use of many of the ideas presented here.
Fundamentally, unification grammar is a gener-
alization of context-free phrase structure grammar
in which grammatical-category expressions are not
simply atomic symbols, but have sets of features
with constraints on their values. Such constraints
are commonly specified using sets of equations.
Our notation uses equations of a very simple
format—just eature=value—and permits only
one equation per feature per constituent, but we
can indicate constraints that would be expressed
in other formalisms using more complex equations
by letting the value of a feature contain a variable
that appears in more than one equation. The CLE
is written in Prolog, to take advantage of the effi-
ciency of Prolog unification in implementing cate-
gory unification, so our grammar rules are written
as Prolog assertions, and we follow Prolog con-
ventions in that constants, such as category and
feature names, start with lowercase letters, and
variables start with uppercase letters. As an ex-
ample, a simplified version of the rule for the basic
subject-predicate sentence form might be written
in our notation as
</bodyText>
<equation confidence="0.429288">
(1) syn(s_np_vp
</equation>
<bodyText confidence="0.905552592592593">
Cs: Ctype=tens ed] ,
up: Cperson=P ,num=2,1] ,
vp : [type=tensed,
person=P num=11]] ) .
The predicate syn indicates that this is a syntax
rule, and the first argument s_np_vp is a rule iden-
tifier that lets us key the semantic-interpretation
rules to the syntax rules. The second argu-
ment of syn is a list of category expressions that
make up the content of the rule, the first speci-
fying the category of the mother constituent and
the rest specifying the categories of the daugh-
ter constituents. This rule, then, says that a
tensed sentence (a: Etype=tensed) ) can consist
of a noun phrase (up) followed by a verb phrase
(vp), with the restrictions that the verb phrase
must be tensed (type=tensed), and that the noun
phrase and verb phrase must agree in person and
number—that is, the person and num features of
the noun phrase must have the same respective
values as the person and num features of the verb
phrase.
These constraints are checked in the process of
parsing a sentence by unifying the values of fea-
tures specified in the rule with the values of fea-
tures in the constituents found in the input. Sup-
pose, for instance, that we are parsing the sentence
</bodyText>
<page confidence="0.997068">
33
</page>
<note confidence="0.7931185">
2 Functional Application vs.
Unification
</note>
<bodyText confidence="0.981898988636364">
Mary runs using a left-corner parser. If Mary is
parsed as a constituent of category
np: [per son=3rd,munr-sing3 ,
then unifying this category expression with
np: Cperson=P,num=t1]
in applying the sentence rule above will force the
variables P and N to take on the values 3rd and
sing, respectively. Thus when we try to parse
the verb phrase, we know that it must be of the
category
vp:Etype=tensed,person=3rd,num=sing].
Our notation for semantic-interpretation rules
is a slight generalization of the notation for syn-
tax rules. The only change is that in each position
where a syntax rule would have a category expres-
sion, a semantic rule has a pair consisting of a
&amp;quot;logical-form&amp;quot; expression and a category expres-
sion, where the logical-form expression specifies
the semantic interpretation of the corresponding
constituent. A semantic-interpretation rule cor-
responding to syntax rule (1) might look like the
following:
(2) sem(s_np_vp,
C(apply(Vp,Np) ,s:0),
(Np,np: )
(Vp.vp: 0)3).
The predicate sem means that this is a semantic-
interpretation rule, and the rule identifier s_np_vp
indicates that this rule applies to structures built
by the syntax rule with the same identifier. The
list of pairs of logical-form expressions and cate-
gory expressions specifies the logical form of the
mother constituent in terms of the logical forms
and feature values of the daughter constituents.
In this case the rule says that the logical form of
a sentence generated by the s_np_vp rule is an ap-
plicative expression with the logical form of the
verb phrase as the functor and the logical form of
the noun phrase as the argument. (The dummy
functor apply is introduced because Prolog syntax
does not allow variables in functor position.) Note
that there are no feature restrictions on any of the
category expressions occurring in the rule. They
are unnecessary in this case because the semantic
rule applies only to structures built by the s_np_vp
syntax rule, and thus inherits all the restrictions
applied by that rule.
Example (2) is typical of the kind of semantic rules
used in the standard approach to semantic inter-
pretation in the tradition established by Richard
Montague (1974) (Dowty, Wall, and Peters, 1981).
In this approach, the interpretation of a complex
constituent is the result of the functional applica-
tion of the interpretation of one of the daughter
constituents to the interpretation of the others.
A problem with this approach is that if, in a
rule like (2), the verb phrase itself is semanti-
cally complex, as it usually is, a lambda expres-
sion has to be used to express the verb-phrase in-
terpretation, and then a lambda reduction must
be applied to express the sentence interpretation
in its simplest form (Dowty, Wall, and Peters,
1981, pp. 98-111). To use (2) to specify the in-
terpretation of the sentence John likes Mary, the
logical form for John could simply be john, but
the logical form for likes Mary would have to be
something like X \like(X,mary). [The notation
Var \Body for lambda expressions is borrowed from
Lambda Prolog (Miller and Nadathur, 1986).] The
logical form for the whole sentence would then
be apply (X \like (X ,mary) , john), which must
be reduced to yield the simplified logical form
like( john,mary).
Moreover, lambda expressions and the ensuing
reductions would have to be introduced at many
intermediate stages if we wanted to produce sim-
plified logical forms for the interpretations of com-
plex constituents such as verb phrases. If we want
to accommodate modal auxiliaries, as in John
might like Mary, we have to make sure that the
verb phrase might like Mary receives the same
type of interpretation as like(s) Mary in order to
combine properly with the interpretation of the
subject. If we try to maintain functional applica-
tion as the only method of semantic composition,
then it seems that the simplest logical form we can
come up with for might like Mary is produced by
the following rule:
</bodyText>
<equation confidence="0.6202506">
(3) sem(vp_aux_vp,
[(X \apply (Aux , apply (Vp , X)) ,
vp: 0).
(Aux,aux: 0),
(Vp,vp:C3)]). •
</equation>
<bodyText confidence="0.998490666666667">
Applying this rule to the simplest plausible logical
forms for might and like Mary would produce the
following logical form for might like Mary:
</bodyText>
<page confidence="0.9584">
314
</page>
<equation confidence="0.9915735">
X \ apply (might ,
(apply(Y \ like (Y ,mary) , X) ) )
</equation>
<bodyText confidence="0.820941050847458">
which must be reduced to obtain the simpler ex-
pression X \might (like (X ,mary) ) . When this ex-
pression is used in the sentence-level rule, another
reduction is required to eliminate the remaining
lambda expression. The part of the reduction step
that gets rid of the apply functors is to some ex-
tent an artifact of the way we have chosen to en-
code these expressions as Prolog terms, but the
lambda reductions are not. They are inherent in
the approach, and normally each rule will intro-
duce at least one lambda expression that needs to
be reduced away.
It is, of course, possible to add a lambda-
reduction step to the interpreter for the semantic
rules, but it is both simpler and more efficient to
use the feature system and unification to do ex-
plicitly what lambda expressions and lambda re-
duction do implicitly—assign a value to a variable
embedded in a logical-form expression. According
to this approach, instead of the logical form for
a verb phrase being a logical predicate, it is the
same as the logical form of an entire sentence, but
with a variable as the subject argument of the verb
and a feature on the verb phrase having that same
variable as its value. The sentence interpretation
rule can thus be expressed as
(4) sem(s_np_vp,
[(Vp,s: 0),
(Np,np ),
(Vp,vp: Csubjval=Np])]) ,
which says that the logical form of the sentence is
just the logical form of the verb phrase with the
subject argument of the verb phrase unified with
the logical form of the subject noun phrase. If
the verb phrase likes Mary is assigned the logical-
form/category-expression pair
(like (X ,mary) ,vp: Csubj va1=X] ),
then the application of this rule will unify the log-
ical form of the subject noun phrase, say john,
directly with the variable X in like (X,mary) to
immediately produce a sentence constituent with
the logical form like ( j ohn, mary).
Modal auxiliaries can be handled equally easily
by a rule such as
(5) sem(vp_aux_vp,
((Aux, vp : [subjval=SJ),
(Aux , aux: Eargva1=Vp]) ,
(Vp,vp: Csubjval=S] )]) .
If might is assigned the logical-form/category-
expression pair
(might (A) , aux : Cargval=A] ),
then applying this rule to interpret the verb phrase
might like Mary will unify A in might (A) with
like(X ,mary) to produce a constituent with the
logical-form/category-expression pair
(might (like , X , mary) ,vp: Esubjva1=X] ).
which functions in the sentence-interpretation
rule in exactly the same way as the logical-
form/category-expression pair for like Mary.
</bodyText>
<sectionHeader confidence="0.814584" genericHeader="introduction">
3 Are Lambda Expressions
Ever Necessary?
</sectionHeader>
<bodyText confidence="0.98783164516129">
The approach presented above for eliminating the
explicit use of lambda expressions and lambda re-
ductions is quite general, but it does not replace
all possible uses of lambda expressions in seman-
tic interpretation. Consider the sentence John and
Bill like Mary. The simplest logical form for the
distributive reading of this sentence would be
and(like(john,mary) ,like(bill,mary)).
If the verb phrase is assigned the logical-
form/category-expression pair
(like (X , mary) ,vp: [subjva1=X] ),
as we have suggested, then we have a problem:
Only one of john or bill can be directly unified
with X, but to produce the desired logical form,
we seem to need two instances of lik e (X , mary) ,
with two different instantiations of X.
Another problem arises when a constituent that
normally functions as a predicate is used as an
argument instead. Common nouns, for example,
are normally used to make direct predications, so
a noun like senator might be assigned the logical-
form/category-expression pair
(s enator (X) ,nbar: Cargva1=X] )
according to the pattern we have been following.
(Note that we do not have &amp;quot;noun&amp;quot; as a syntactic
category; rather, a common noun is simply treated
as a lexical &amp;quot;n-bar.&amp;quot;) It is widely recognized, how-
ever, that there are &amp;quot;intensional&amp;quot; adjectives and
adjective phrases, such as former, that need to be
treated as higher-level predicates or operators on
predicates, so that in an expression like former
</bodyText>
<page confidence="0.995954">
35
</page>
<bodyText confidence="0.999619">
senator, the noun senator is not involved in di-
rectly making a predication, but instead functions
as an argument to former. We can see that this
must be the case, from the observation that a for-
mer senator is no longer a senator. The logical
form we have assigned to senator, however, is not
literally that of a predicate, however, but rather of
a complete formula with a free variable. We there-
fore need some means to transform this formula
with its free variable into an explicit predicate to
be an argument of former. The introduction of
lambda expressions provides the solution to this
problem, because the transformation we require is
exactly what is accomplished by lambda abstrac-
tion. The following rule shows how this can be
carried out in practice:
</bodyText>
<figure confidence="0.708295333333333">
(6) sem(nbar_adj_nbar,
C(Adjp,nbar: Cargval=A3 ),
(Adjp,adjp: Ctype=intensional,
argval1=X\Nbar,
argval2=A3),
(Nbaranbar: Cargva1=X3 )3 ) .
</figure>
<bodyText confidence="0.972434875">
This rule requires the logical-form/category-
expression pair assigned to an intensional adjec-
tive phrase to be something like
(1 ormer (P ,Y) ,
adjp: Ctype=intensional,
argval1=P,argval2=Y3),
where t ormer(P ,Y) means that Y is a former P.
The daughter nbar is required to be as previously
supposed. The rule creates a lambda expression,
by unifying the bound variable with the argument
of the daughter nbar and making the logical form
of the daughter nbar the body of the lambda ex-
pression, and unifies the lambda expression with
the first argument of the adjp. The second ar-
gument of the adjp becomes- the argument of the
mother nbar. Applying this rule to former senator
will thus produce a constituent with the logical-
form/category-expression pair
(former(X\senator(X),Y),
nbar:Eargva1=Y3).
This solution to the second problem also solves
the first problem. Even in the standard lambda-
calculus-based approach, the only way in which
multiple instances of a predicate expression ap-
plied to different arguments can arise from a sin-
gle source is for the predicate expression to ap-
pear as an argument to some other expression
that contains multiple instances of that argument.
Since our approach requires turning a predicate
into an explicit lambda expression if it is used
as an argument, by the time we need multiple
instances of the predicate, it is already_ in the
form of a lambda expression. We can show how
this works by encoding a Montagovian (Dowty,
Wall, Peters, 1981) treatment of conjoined sub-
ject noun phrases within our approach. The ma-
jor feature of this treatment is that noun phrases
act as higher-order predicates of verb phrases,
rather than the other way around as in the sim-
pler rules presented in Sections 1 and 2. In
the Montagovian treatment, a proper noun such
as John is given an interpretation equivalent to
P\P(john), so that when we apply it to a pred-
icate like run in interpreting John runs we get
something like apply (P \P ( j ohn) ,run) which re-
duces to run( john). With this in mind, consider
the following two rules for the interpretation of
sentences with conjoined subjects:
</bodyText>
<figure confidence="0.7291219">
(7) sem(np_np_conj_np
C(Conj,np: Cargval=P3),
(Npl,np: Cargval=P3),
(Conj,conj: Cargval1=Np1,
argval2=Np23),
(Np2,np: Cargval=P3 )3).
(8) sem(s_np_vp,
[(lip&apos;s: 0),
(Npanp: Cargva1=X\Vp3),
(Vp,vp: Csubjva1=X3 )3).
</figure>
<bodyText confidence="0.917968263157894">
The first of these rules gives a Montagovian
treatment of conjoined noun phrases, and the
second gives a Montagovian treatment of simple
declarative sentences. Both of these rules assume
that a proper noun such as John would have a
logical-form/category-expression pair like
(apply(P,john),np: Cargval=P3).
In (7) it is assumed that the conjunction and
would have a logical-form/category-expression
pair like
(and(P1,P2),
conj : Cargval1=P1 , argval2=P23 ) .
In (7) the logical forms of the two conjoined daugh-
ter nps are unified with the two arguments of the
conjunction, and the arguments of the daughter
nps are unified with each other and with the sin-
gle argument of the mother np. Thus applying
(7) to interpret John and Bill yields a constituent
with the logical-form/category-expression pair
</bodyText>
<page confidence="0.991634">
36
</page>
<bodyText confidence="0.981424615384615">
(and(apply(P,john),apply(P,bill)),
np:[argval=PJ).
In (8) an explicit lambda expression is constructed
out of the logical form of the vp daughter in the
same way a lambda expression was constructed in
(6), and this lambda expression is unified with the
argument of the subject np. For the sentence John
and Bill like Mary, this would produce the logical
form
and (apply (X \ like (X ,mary), john),
apply (X \ like (X ,mary) ,bill)) ,
which can be reduced to
and (like ( j ohn mary) , like (bill ,mary) ).
</bodyText>
<sectionHeader confidence="0.996609666666667" genericHeader="method">
4 Theoretical Foundations of
Unification-Based Seman-
tics
</sectionHeader>
<bodyText confidence="0.981697743902439">
The examples presented above ought to be con-
vincing that a unification-based formalism can be
a powerful tool for specifying the interpretation of
natural-language expressions. What may not be
clear is whether there is any reasonable theoretical
foundation for this approach, or whether it is just
so much unprincipled &amp;quot;feature hacking.&amp;quot; The in-
formal explanations we have provided of how par-
ticular rules work, stated in terms of unifying the
logical form for constituent X with the appropriate
variable in the logical form for constituent Y, may
suggest that the latter is the case. If no constraints
are placed on how such a formalism is used, it is
certainly possible to apply it in ways that have no
basis in any well-founded semantic theory. Never-
theless, it is possible to place restrictions on the
formalism to ensure that the rules we write have a
sound theoretical basis, while still permitting the
sorts of rules that seem to be needed to specify the
semantic interpretation of natural languages.
The main question that arises in this regard is
whether the semantic rules specify the interpreta-
tion of a natural-language expression in a compo-
sitional fashion. That is, does every rule assign
to a mother constituent a well-defined interpreta-
tion that depends solely on the interpretations of
the daughter constituents? If the interpretation
of a constituent is taken to be just the interpre-
tation of its logical-form expression, the answer is
clearly &amp;quot;no.&amp;quot; In our formalism the logical-form
expression assigned to a mother constituent de-
pends on both the logical-form expressions and
the category expressions assigned to its daughters.
As long as both category expressions and logical-
form expressions have a theoretically sound basis,
however, there is no reason that both should not
be taken into account in a semantic theory; so,
we will define the interpretation of a constituent
based on both its category and its logical form.
Taking the notion of interpretation in this way,
we will explain how our approach can be made
to preserve compositionality. First, we will show
how to give a well-defined interpretation to every
constituent; then, we will sketch the sort of re-
strictions on the formalism one needs to guarantee
that any interpretation-preserving substitution for
a daughter constituent also preserves the interpre-
tation of the mother constituent.
The main problem in giving a well-defined inter-
pretation to every constituent is how to interpret a
constituent whose logical-form expression contains
free variables that also appear in feature values in
the constituent&apos;s category expression. Recall the
rule we gave for combining auxiliaries with verb
phrases:
(5) sem(vp_aux_vp,
[(Aux, vp: EsubjvalaZ) ) ,
(Aux, aux : Cargval=Vp3 ) ,
(Vp,vp: Csubj val=S7 )7 ) •
This rule accepts daughter constituents having
logical-form/category-expression pairs such as
(might (A) , aux : Cargvalr-A] )
and
(like (X , mary) , vp: Csubjva1=X7 )
to produce a mother constituent having the
logical-form/category-expression pair
(might(like,X,mary),vp:[subjval.X].
Each of these pairs has a logical-form expression
containing a free variable that also occurs as a fea-
ture value in its category expression. The simplest
way to deal with logical-form/category-expression
pairs such as these is to regard them in the way
that syntactic-category expressions in unification
grammar can be regarded—as abbreviations for
the set of all their well-formed fully instantiated
substitution instances.
To establish some terminology, we will say that
a logical-form/category-expression pair containing
no free-variable occurrences has a &amp;quot;basic interpre-
tation,&amp;quot; which is simply the ordered pair consist-
ing of the interpretation of the logical-form ex-
pression and the interpretation of the category
</bodyText>
<page confidence="0.99868">
37
</page>
<bodyText confidence="0.988885578431373">
expression. Since there are no free variables in-
volved, basic interpretations should be unprob-
lematic. The logical-form expression will simply
be a closed well-formed expression of some ordi-
nary logical language, and its interpretation will
be whatever the usual interpretation of that ex-
pression is in the relevant logic. The category ex-
pression can be taken to denote a fully instantiated
grammatical category of the sort typically found
in unification grammars. The only unusual prop-
erty of this category is that some of its features
may have logical-form interpretations as values,
but, as these will always be interpretations of ex-
pressions containing no free-variable occurrences,
they will always be well defined.
Next, we define the interpretation of an arbi-
trary logical-form/category-expression pair to be
the set of basic interpretations of all its well-
formed substitution instances that contain no
free-variable occurrences. For example, the in-
terpretation of a constituent with the logical-
form/category-expression pair
(might (like , X ,mary) ,vp: Csubj va1=X] )
would consist of a set containing the basic inter-
pretations of such pairs as
(might (like , john,mary) ,
vp: [subj val=j ohn] ) ,
(might (like ,bill ,mary) .
VP: Csubjval=bill3) ,
and so forth.
This provides well-defined interpretation for ev-
ery constituent, so we can now consider what re-
strictions we can place on the formalism to guaran-
tee that any interpretation-preserving substitution
for a daughter constituent also preserves the inter-
pretation of its mother constituent. The first re-
striction we need rules out constituents that would
have degenerate interpretations: No semantic rule
or semantic lexical specification may contain both
free and bound occurrences of the same variable
in a logical-form/category-expression pair.
To see why this restriction is needed, consider
the logical-form/category-expression pair
(every(X,man(X) ,die(X)) ,
np: [boundvar=X, bodyval=die (X)] ) ,
which might be the substitution instance of a
daughter constituent that would be selected in
a rule that combines noun phrases with verb
phrases. The problem with such a pair is
that it does not have any well-formed substi-
tution instances that contain no free-variable
occurrences. The variable X must be left
uninstantiated in order for the logical-form ex-
pression every(X,man(X) ,die(X)) to be well
formed, but this requires a free occurrence of X
in np: [boundvar=X , bodyval=die (X)] . Thus this
pair will be assigned the empty set as its in-
terpretation. Since any logical-form/category-
expression pair that contains both free and bound
occurrences of the same variable will receive this
degenerate interpretation, any other such pair
could be substituted for this one without alter-
ing the interpretations of the daughter constituent
substitution instances that determine the inter-
pretation of the mother constituent. It is clear
that this would normally lead to gross violations of
compositionality, since the daughter substitution
instances selected for the noun phrases every man,
no woman, and some dog would all receive the
same degenerate interpretation under this scheme.
This restriction may appear to be so constrain-
ing as to rule out certain potentially useful ways
of writing semantic rules, but in fact it is gener-
ally possible to rewrite such rules in ways that do
not violate the restiction. For example, in place of
the sort of logical-form/category-expression pair
we have just ruled out, we can fairly easily rewrite
the relevant rules to select daughter substitution
instances such as
(every(X,man(X),die(X)),
np: [bodypred=X\die(X)] ) ,
which does not violate the constraint and has a
completely straightforward interpretation.
Having ruled out constituents with degenerate
interpretations, the principal remaining problem
is how to exclude rules that depend on properties
of logical-form expressions over and above their in-
terpretations. For example, suppose that the or-
der of conjuncts does not affect the interpretation
of a logical conjunction, according to the inter-
pretation of the logical-form language. That is,
and(p,q) would have the same interpretation as
and(q,p). The potential problem that this raises
is that we might write a semantic rule that con-
tains both a logical-form expression like and(P ,Q)
in the specification of a daughter constituent and
the variable P in the logical form of the mother
constituent. This would be a violation of composi-
tionality, because the interpretation of the mother
would depend on the interpretation of the left con-
junct of a conjunction, even though, according
to the semantics of the logical-form language, it
</bodyText>
<page confidence="0.997968">
38
</page>
<bodyText confidence="0.999982318181818">
makes no sense to distinguish the left and right
conjuncts. If order of conjunction does not af-
fect meaning, we ought to be able to substitute
a daughter with the logical form and(q,p) for
one with the logical form and(p,q) without af-
fecting the interpretation assigned to the mother,
but clearly, in this case, the interpretation of the
mother would be affected.
It is not clear that there is any uniquely optimal
set of restrictions that guarantees that such viola-
tions of compositionality cannot occur. Indeed,
since unification formalisms in general have Tur-
ing machine power, it is quite likely that there is
no computable characterization of all and only the
sets of semantic rules that are compositional. Nev-
ertheless, one can describe sets of restrictions that
do guarantee compositionality, and which seem
to provide enough power to express the sorts of
semantic rules we need to use to specify the se-
mantics of natural languages. One fairly natu-
ral way of restricting the formalism to guarantee
compositionality is to set things up so that unifi-
cations involving logical-form expressions are gen-
erally made against variables, so that it is possible
neither to extract subparts of logical-form expres-
sions nor to filter on the syntactic form of logical-
form expressions. The only exception to this re-
striction that seems to be required in practice is
to allow for rules that assemble and disassemble
lambda expressions with respect to their bodies
and bound variables. So long as no extraction
from inside the body of a lambda expression is
allowed, however, compositionality is preserved.
It is possible to define a set of restrictions on
the form of semantic rules that guarantee that
no rule extracts subparts (other than the body
or bound variable of a lambda expression) of a
logical-form expression or filters on the syntactic
form of a logical-form expression. The statement
of these restrictions is straightforward, but rather
long and tedious, so we omit the details here. We
will simply note that none of the sample rules pre-
sented in this paper involve any such extraction or
filtering.
</bodyText>
<sectionHeader confidence="0.98045" genericHeader="method">
5 The Semantics of Long-
Distance Dependencies
</sectionHeader>
<bodyText confidence="0.976694228070175">
The main difficulty that arises in formulating
semantic-interpretation rules is that constituents
frequently appear syntactically in places that do
not directly reflect their semantic role. Semanti-
cally, the subject of a sentence is one of the argu-
ments of the verb, so it would be much easier to
produce logical forms for sentences if the subject
were part of the verb phrase. The use of features
such as subjval, in effect, provides a mechanism
for taking the interpretation of the subject from
the place where it occurs and inserting it into the
verb phrase interpretation where it &amp;quot;logically&amp;quot; be-
longs.
The way features can be manipulated to accom-
plish this is particularly striking in the case of the
long-distance dependencies, such as those in WH-
questions. For the sentence Which girl might John
like?, the simplest plausible logical form would be
something like
which(X,girl(X),might(like(john,X)),
where the question-forming operator which is
treated as a generalized quantifier whose &amp;quot;argu-
ments&amp;quot; consist of a bound variable, a restriction,
and a body.
The problem is how to get the variable X to
link the part of the logical form that comes from
the fronted interrogative noun phrase with the
argument of like that corresponds to the noun
phrase gap at the end of the verb phrase. To solve
this problem, we can use a technique called &amp;quot;gap-
threading.&amp;quot; This technique was introduced in uni-
fication grammar to describe the syntax of con-
structions with long-distance dependencies (Kart-
tunnen, 1986) (Pereira and Sheiber, 1987, pp. 125-
129), but it works equally well for specifying their
semantics. The basic idea is to use a pair of fea-
tures, gapvals in and gapvalsout, to encode a list
of semantic &amp;quot;gap fillers&amp;quot; to be used as the seman-
tic interpretations of syntactic gaps, and to thread
that list along to the points where the gaps occur.
These gap fillers are often just the bound variables
introduced by the constructions that permit gaps
to occur.
The following semantic rules illustrate how this
mechanism works:
(9) sem(whq_ynq_np_gap,
[(Np , s : Cgapvalsin= 0 .
gapvalsout=0:1),
(Np ,np : [type=interrog,
bodypred=A \Ynq] ) ,
(Ynq, s : Cgapvalsin= [A] ,
gapvalsout= )3 ) .
This is the semantic-interpretation rule for a WH-
question with a long-distance dependency. The
syntactic form of such a sentence is an interrog-
ative noun phrase followed by a yes/no question
with a noun phrase gap. This rule expects the
</bodyText>
<page confidence="0.775898">
3 9
</page>
<bodyText confidence="0.9943335">
interrogative noun phrase which girl to have a
logical-form/category-expression pair such as
</bodyText>
<equation confidence="0.919209333333333">
(which( X , girl (X) , Bodyval) ,
np : [type=interrog ,
bodypred=X \ Bodyval] ) .
</equation>
<bodyText confidence="0.999937266666667">
The feature bodypred holds a lambda expression
whose body and bound variable are unified respec-
tively with the body and the bound variable of the
which expression. In (9) the body of this lambda
expression is unified with the logical form of the
embedded yes/no question, and the gapvals in
feature is set to be a list containing the bound vari-
able of the lambda expression. This list is actually
used as a stack, to accomodate multiply nested
filler-gap dependencies. Since this form of ques-
tion cannot be embedded in other constructions,
however, we know that in this case there will be
no other gap-fillers already on the list.
This is the rule that provides the logical form
for empty noun phrases:
</bodyText>
<figure confidence="0.215581333333333">
(10) sem(empty_np ,
[(Val ,np : [gapvalsin= [Vail ValRest] ,
gapvalsout=ValRest] )] ) .
</figure>
<bodyText confidence="0.994868390243902">
Notice that it has a mother category, but no
daughter categories. The rule simply says that
the logical form of an empty np is the first ele-
ment on its list of semantic gap-fillers, and that
this element is &amp;quot;popped&amp;quot; from the gap-filler list.
That is, the gapvalsout feature takes as its value
the tail of the value of the gapvals in feature.
We now show two rules that illustrate how a list
of gap-fillers is passed along to the points where
the gaps they fill occur.
(11) sem(vp_aux_vp,
[(Aux,vp:[subjval=S,gapvalsin=In,
gapvalsout=Out] ) ,
(Aux,aux:Cargval=Vp]).
(Vp,vp:[subjval=S,gapva].sin=In,
gapvalsout=Out])]).
This semantic rule for verb phrases formed by an
auxilliary followed by a verb phrase illustrates the
typical use of the gap features to &amp;quot;thread&amp;quot; the list
of gap fillers through the syntactic structure of the
sentence to the points where they are needed. An
auxiliary verb cannot be or contain a WH-type
gap, so there are no gap features on the category
aux. Thus the gap features on the mother vp are
simply unified with the corresponding features on
the daughter vp.
A more complex case is illustrated by the fol-
lowing rule:
(12) sem(vp_vp_pp ,
[(Pp,vp:[subjval=Spgapvalsin=In,
gapvalsout=Out]),
(Vp,vp:[subjval=S,gapvalsin=In,
gapvalsout=Thru]),
(Pp,pp:Eargval=Vp,gapvalsin=Thru,
gapvalsout=out3 )3) .
This is a semantic rule for verb phrases that con-
sist of a verb phrase and a prepositional phrase.
Since WH-gaps can occur in either verb phrases
or prepositional phrases, the rule threads the list
carried by the gapvalsin feature of the mother vp
first through the daughter vp and then through the
daughter pp. This is done by unifying the mother
vp&apos;s gapvalsin feature with the daughter vp&apos;s
gapvalsin feature, the daughter vp&apos;s gapvalsout
feature with the daughter pp&apos;s gapvals in feature,
and finally the daughter pp&apos;s gapvalsout feature
with the mother vp&apos;s gapvalsout feature. Since
a gap-filler is removed from the list once it has
been &amp;quot;consumed&amp;quot; by a gap, this way of threading
ensures that fillers and gaps will be matched in
a last-in-first-out fashion, which seems to be the
general pattern for English sentences with multi-
ple filler-gap dependencies. (This does not handle
&amp;quot;parasitic gap&amp;quot; constructions, but these are very
rare and at present there seems to be no really
convincing linguistic account of when such con-
structions can be used.)
Taken altogether, these rules push the quan-
tified variable of the interrogative noun phrase
onto the list of gap values encoded in the fea-
ture gapvalsin on the embedded yes/no question.
The list of gap values gets passed along by the
gap-threading mechanism, until the empty-noun-
phrase rule pops the variable off the gap values list
and uses it as the logical form of the noun phrase
gap. Then the entire logical form for the embed-
ded yes/no question is unified with the body of
the logical form for the interrogative noun phrase,
producing the desired logical form for the whole
sentence.
This treatment of the semantics of long-distance
dependencies provides us with an answer to the
question of the relative expressive power of our
approach compared with the conventional lambda-
calculus-based approach. We know that the
unification-based approach is at least as power-
ful as the conventional approach, because the
the conventional approach can be embedded di-
rectly in it, as illustrated by the examples in
Section 3. What about the other way around?
Many unification-based rules have direct lambda-
calculus-based counterparts; for example (2) is
</bodyText>
<page confidence="0.901297">
4O
</page>
<bodyText confidence="0.999967894736842">
a counterpart of (4), and (3) is the counterpart
of (5). Once we introduce gap-threading, how-
ever, the correspondence breaks down. In the
conventional approach, each rule applies only to
constituents whose semantic interpretation is of
some particular single semantic type, say, func-
tions from individuals to propositions. If every
free variable in our approach is treated as a lambda
variable in the conventional approach, then no
one rule can cover two expressions whose inter-
pretation essentially involves different numbers of
variables, since these would be of different seman-
tic types. Hence, rules like (11) and (12), which
cover constituents containing any number of gaps,
would have to be replaced in the conventional ap-
proach by a separate rule for each possible number
of gaps. Thus, our formalism enables us to write
more general rules than is possible taking the con-
ventional approach.
</bodyText>
<sectionHeader confidence="0.999849" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999767882352941">
In this paper we have tried to show that a
unification-based approach can provide powerful
tools for specifying the semantic interpretation
of natural-language expressions, while being just
as well founded theoretically as the conventional
lambda-calculus-based approach. Although the
unification-based approach does not provide a sub-
stitute for all uses of lambda expressions in se-
mantic interpretation, we have shown that lambda
expressions can be introduced very easily where
they are needed. Finally, the unification-based ap-
proach provides for a simpler statement of many
semantic-interpretation rules, it eliminates many
of the lambda reductions needed to express seman-
tic interpretations in their simplest form, and in
some cases it allows more general rules than can
be stated taking the conventional approach.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999849571428572">
The research reported in this paper was begun
at SRI International&apos;s Cambridge Computer Sci-
ence Research Centre in Cambridge, England, sup-
ported by a grant from the Alvey Directorate
of the U.K. Department of Trade and Indus-
try and by the members of the NATTIE consor-
tium (British Aerospace, British Telecom, Hewlett
Packard, ICL, Olivetti, Philips, Shell Research,
and SRI). The work was continued at the SRI Ar-
tificial Intelligence Center and the Center for the
Study of Language and Information, supported
in part by a gift from the Systems Development
Foundation and in part by a contract with the
Nippon Telegraph and Telephone Corporation.
</bodyText>
<sectionHeader confidence="0.996456" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999825076923077">
Dowty, David R., Robert Wall, and Stanley Pe-
ters (1981) Introduction to Montague Semantics
(D. Reidel, Dordrecht, Holland).
Karttunnen, Lauri (1986) &amp;quot;D-PATR: A De-
velopment Environment for Unification-Based
Grammars,&amp;quot; Proceedings of the 11th Interna-
tional Conference on Computational Linguis-
tics, Bonn, West Germany, pp. 74-80.
Miller, Dale A., and Gopalan Nadathur (1986)
&amp;quot;Higher-Order Logic Programming,&amp;quot; in E.
Shapiro (ed.), Third International Conference
on Logic Programming, pp. 448-462 (Springer-
Verlag, Berlin, West Germany).
Montague, Richard (1974) Formal Philosophy
(Yale University Press, New Haven, Connecti-
cut).
Pereira, Fernando C.N., and Stuart M. Shieber
(1987) Prolog and Natural-Language Analysis,
CSLI Lecture Notes Number 10, Center for the
Study of Language and Information, Stanford
University, Stanford, California.
Shieber, Stuart M. (1986) An Introduction to
Unification-Based Approaches to Grammar,
CSLI Lecture Notes Number 4, Center for the
Study of Language and Information, Stanford
University, Stanford, California.
</reference>
<page confidence="0.999447">
41
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.974190">
<title confidence="0.999821">Unification-Based Semantic Interpretation</title>
<author confidence="0.999954">Robert C Moore</author>
<affiliation confidence="0.99964">Artificial Intelligence Center SRI International</affiliation>
<address confidence="0.999916">Menlo Park, CA 94025</address>
<abstract confidence="0.997168111111111">We show how unification can be used to specify the semantic interpretation of natural-language expressions, including problematical constructions involving long-distance dependencies. We also sketch a theoretical foundation for unificationbased semantic interpretation, and compare the unification-based approach with more conventional techniques based on the lambda calculus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David R Dowty</author>
<author>Robert Wall</author>
<author>Stanley Peters</author>
</authors>
<title>Introduction to Montague Semantics (D. Reidel,</title>
<date>1981</date>
<location>Dordrecht, Holland).</location>
<contexts>
<context position="6301" citStr="Dowty, Wall, and Peters, 1981" startWordPosition="996" endWordPosition="1000">form of the noun phrase as the argument. (The dummy functor apply is introduced because Prolog syntax does not allow variables in functor position.) Note that there are no feature restrictions on any of the category expressions occurring in the rule. They are unnecessary in this case because the semantic rule applies only to structures built by the s_np_vp syntax rule, and thus inherits all the restrictions applied by that rule. Example (2) is typical of the kind of semantic rules used in the standard approach to semantic interpretation in the tradition established by Richard Montague (1974) (Dowty, Wall, and Peters, 1981). In this approach, the interpretation of a complex constituent is the result of the functional application of the interpretation of one of the daughter constituents to the interpretation of the others. A problem with this approach is that if, in a rule like (2), the verb phrase itself is semantically complex, as it usually is, a lambda expression has to be used to express the verb-phrase interpretation, and then a lambda reduction must be applied to express the sentence interpretation in its simplest form (Dowty, Wall, and Peters, 1981, pp. 98-111). To use (2) to specify the interpretation o</context>
</contexts>
<marker>Dowty, Wall, Peters, 1981</marker>
<rawString>Dowty, David R., Robert Wall, and Stanley Peters (1981) Introduction to Montague Semantics (D. Reidel, Dordrecht, Holland).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunnen</author>
</authors>
<title>D-PATR: A Development Environment for Unification-Based Grammars,&amp;quot;</title>
<date>1986</date>
<booktitle>Proceedings of the 11th International Conference on Computational Linguistics,</booktitle>
<pages>74--80</pages>
<location>Bonn, West</location>
<contexts>
<context position="28962" citStr="Karttunnen, 1986" startWordPosition="4666" endWordPosition="4668">might(like(john,X)), where the question-forming operator which is treated as a generalized quantifier whose &amp;quot;arguments&amp;quot; consist of a bound variable, a restriction, and a body. The problem is how to get the variable X to link the part of the logical form that comes from the fronted interrogative noun phrase with the argument of like that corresponds to the noun phrase gap at the end of the verb phrase. To solve this problem, we can use a technique called &amp;quot;gapthreading.&amp;quot; This technique was introduced in unification grammar to describe the syntax of constructions with long-distance dependencies (Karttunnen, 1986) (Pereira and Sheiber, 1987, pp. 125- 129), but it works equally well for specifying their semantics. The basic idea is to use a pair of features, gapvals in and gapvalsout, to encode a list of semantic &amp;quot;gap fillers&amp;quot; to be used as the semantic interpretations of syntactic gaps, and to thread that list along to the points where the gaps occur. These gap fillers are often just the bound variables introduced by the constructions that permit gaps to occur. The following semantic rules illustrate how this mechanism works: (9) sem(whq_ynq_np_gap, [(Np , s : Cgapvalsin= 0 . gapvalsout=0:1), (Np ,np :</context>
</contexts>
<marker>Karttunnen, 1986</marker>
<rawString>Karttunnen, Lauri (1986) &amp;quot;D-PATR: A Development Environment for Unification-Based Grammars,&amp;quot; Proceedings of the 11th International Conference on Computational Linguistics, Bonn, West Germany, pp. 74-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dale A Miller</author>
<author>Gopalan Nadathur</author>
</authors>
<title>Higher-Order Logic Programming,&amp;quot;</title>
<date>1986</date>
<booktitle>Third International Conference on Logic Programming,</booktitle>
<pages>448--462</pages>
<editor>in E. Shapiro (ed.),</editor>
<location>(SpringerVerlag, Berlin, West Germany).</location>
<contexts>
<context position="7171" citStr="Miller and Nadathur, 1986" startWordPosition="1146" endWordPosition="1149"> in a rule like (2), the verb phrase itself is semantically complex, as it usually is, a lambda expression has to be used to express the verb-phrase interpretation, and then a lambda reduction must be applied to express the sentence interpretation in its simplest form (Dowty, Wall, and Peters, 1981, pp. 98-111). To use (2) to specify the interpretation of the sentence John likes Mary, the logical form for John could simply be john, but the logical form for likes Mary would have to be something like X \like(X,mary). [The notation Var \Body for lambda expressions is borrowed from Lambda Prolog (Miller and Nadathur, 1986).] The logical form for the whole sentence would then be apply (X \like (X ,mary) , john), which must be reduced to yield the simplified logical form like( john,mary). Moreover, lambda expressions and the ensuing reductions would have to be introduced at many intermediate stages if we wanted to produce simplified logical forms for the interpretations of complex constituents such as verb phrases. If we want to accommodate modal auxiliaries, as in John might like Mary, we have to make sure that the verb phrase might like Mary receives the same type of interpretation as like(s) Mary in order to c</context>
</contexts>
<marker>Miller, Nadathur, 1986</marker>
<rawString>Miller, Dale A., and Gopalan Nadathur (1986) &amp;quot;Higher-Order Logic Programming,&amp;quot; in E. Shapiro (ed.), Third International Conference on Logic Programming, pp. 448-462 (SpringerVerlag, Berlin, West Germany).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<title>Formal Philosophy</title>
<date>1974</date>
<publisher>Yale University Press,</publisher>
<location>New Haven, Connecticut).</location>
<contexts>
<context position="6270" citStr="Montague (1974)" startWordPosition="994" endWordPosition="995"> and the logical form of the noun phrase as the argument. (The dummy functor apply is introduced because Prolog syntax does not allow variables in functor position.) Note that there are no feature restrictions on any of the category expressions occurring in the rule. They are unnecessary in this case because the semantic rule applies only to structures built by the s_np_vp syntax rule, and thus inherits all the restrictions applied by that rule. Example (2) is typical of the kind of semantic rules used in the standard approach to semantic interpretation in the tradition established by Richard Montague (1974) (Dowty, Wall, and Peters, 1981). In this approach, the interpretation of a complex constituent is the result of the functional application of the interpretation of one of the daughter constituents to the interpretation of the others. A problem with this approach is that if, in a rule like (2), the verb phrase itself is semantically complex, as it usually is, a lambda expression has to be used to express the verb-phrase interpretation, and then a lambda reduction must be applied to express the sentence interpretation in its simplest form (Dowty, Wall, and Peters, 1981, pp. 98-111). To use (2) </context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>Montague, Richard (1974) Formal Philosophy (Yale University Press, New Haven, Connecticut).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Stuart M Shieber</author>
</authors>
<title>Prolog and Natural-Language Analysis,</title>
<date>1987</date>
<booktitle>CSLI Lecture Notes Number 10, Center for the Study of Language and Information,</booktitle>
<location>Stanford University, Stanford, California.</location>
<contexts>
<context position="1167" citStr="Pereira and Shieber (1987)" startWordPosition="161" endWordPosition="164">t several years, unification-based formalisms (Shieber, 1986) have come to be widely used for specifying the syntax of natural languages, particularly among computational linguists. It is less widely realized by computational linguists that unification can also be a powerful tool for specifying the semantic interpretation of natural languages. While many of the techniques described in this paper are fairly well known among natural-language researchers working with logic grammars, they have not been extensively discussed in the literature, perhaps the only systematic presentation being that of Pereira and Shieber (1987). This paper goes into many issues in greater detail than do Pereira and Shieber, however, and sketches what may be the first theoretical analysis of unification-based semantic interpretation. We begin by reviewing the basic ideas behind unification-based grammar formalisms, which will also serve to introduce the style of notation to be used throughout the paper. The notation is that used in the Core Language Engine (CLE) developed by SRI&apos;s Cambridge Computer Science Research Center in Cambridge, England, a system whose semantic-interpretation component makes use of many of the ideas presented</context>
</contexts>
<marker>Pereira, Shieber, 1987</marker>
<rawString>Pereira, Fernando C.N., and Stuart M. Shieber (1987) Prolog and Natural-Language Analysis, CSLI Lecture Notes Number 10, Center for the Study of Language and Information, Stanford University, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar,</title>
<date>1986</date>
<booktitle>CSLI Lecture Notes Number 4, Center for the Study of Language and Information,</booktitle>
<location>Stanford University, Stanford, California.</location>
<marker>Shieber, 1986</marker>
<rawString>Shieber, Stuart M. (1986) An Introduction to Unification-Based Approaches to Grammar, CSLI Lecture Notes Number 4, Center for the Study of Language and Information, Stanford University, Stanford, California.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>