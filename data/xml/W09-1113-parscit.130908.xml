<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004846">
<title confidence="0.96185">
Learning Where to Look: Modeling Eye Movements in Reading
</title>
<author confidence="0.979386">
Mattias Nilsson Joakim Nivre
</author>
<affiliation confidence="0.9903765">
Department of Linguistics and Philology Department of Linguistics and Philology
Uppsala University Uppsala University
</affiliation>
<email confidence="0.994942">
mattias.nilsson@lingfil.uu.se joakim.nivre@lingfil.uu.se
</email>
<sectionHeader confidence="0.995598" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999115">
We propose a novel machine learning task that
consists in learning to predict which words in
a text are fixated by a reader. In a first pilot
experiment, we show that it is possible to out-
perform a majority baseline using a transition-
based model with a logistic regression classi-
fier and a very limited set of features. We also
show that the model is capable of capturing
frequency effects on eye movements observed
in human readers.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999900672727273">
Any person engaged in normal skilled reading pro-
duces an alternating series of rapid eye movements
and brief fixations that forms a rich and detailed be-
havioral record of the reading process. In the last
few decades a great deal of experimental evidence
has accumulated to suggest that the eye movements
of readers are reflective of ongoing language pro-
cessing and thus provide a useful source of infor-
mation for making inferences about the linguistic
processes involved in reading (Clifton et al., 2007).
In psycholinguistic research, eye movement data is
now commonly used to study how experimental ma-
nipulations of linguistic stimuli manifest themselves
in the eye movement record.
Another related strand of research primarily at-
tempts to understand what determines when and
where the eyes move during reading. This line of
research has led to mathematically well specified ac-
counts of eye movement control in reading being
instantiated as computational models (Legge et al.,
1997; Reichle et al., 1998; Salvucci, 2001; Engbert
et al., 2002; McDonald et al., 2005; Feng, 2006;
Reilly and Radach, 2006; Yang, 2006). (For a re-
cent overview, see (Reichle, 2006).) These models
receive text as input and produce predictions for the
location and duration of eye fixations, in approxima-
tion to human reading behavior. Although there are
substantial differences between the various models,
they typically combine both mechanisms of visuo-
motor control and linguistic processing. Two impor-
tant points of divergence concern the extent to which
language processing influences eye movements and
whether readers process information from more than
one word at a time (Starr and Rayner, 2001). More
generally, the models that have emerged to date are
based on different sets of assumptions about the un-
derlying perceptual and cognitive mechanisms that
control eye movements. The most influential model
so far, the E-Z Reader model (Reichle et al., 1998;
Reichle et al., 2003; Pollatsek et al., 2006), rests on
the assumptions that cognitive /lexical processing is
the engine that drives the eyes through the text and
that words are identified serially, one at a time.
Although eye movement models typically have
parameters that are fitted to empirical data sets, they
are not based on machine learning in the standard
sense and their predictions are hardly ever tested on
unseen data. Moreover, their predictions are nor-
mally averaged over a whole group of readers or
words belonging to a given frequency class. In this
study, however, we investigate whether saccadic eye
movements during reading can be modeled using
machine learning. The task we propose is to learn
to predict the eye movements of an individual reader
reading a specific text, using as training data the eye
</bodyText>
<page confidence="0.984661">
93
</page>
<note confidence="0.9899">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 93–101,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999968458333334">
movements recorded for the same person reading
other texts.
Predicting the eye movements of an individual
reader on new texts is arguably a hard problem, and
we therefore restrict the task to predicting word-
based fixations (but not the duration of these fixa-
tions) and focus on a first pilot experiment inves-
tigating whether we can outperform a reasonable
baseline on this task. More precisely, we present ex-
perimental results for a transition-based model, us-
ing a log-linear classifier, and show that the model
significantly outperforms the baseline of always pre-
dicting the most frequent saccade. In addition, we
show that even this simple model is able to capture
frequency effects on eye movements observed in hu-
man readers.
We want to emphasize that the motivation for this
modeling experiment is not to advance the state of
the art in computational modeling of eye movements
during reading. For this our model is far too crude
and limited in scope. The goal is rather to propose a
novel approach to the construction and evaluation of
such models, based on machine learning and model
assessment on unseen data. In doing this, we want
to establish a reasonable baseline for future research
by evaluating a simple model with a restricted set
of features. In future studies, we intend to inves-
tigate how results can be improved by introducing
more complex models as well as a richer feature
space. More generally, the machine learning ap-
proach explored here places emphasis on modeling
eye movement behavior with few a priori assump-
tions about underlying cognitive and physiological
mechanisms.
The rest of the paper is structured as follows. Sec-
tion 2 provides a brief background on basic charac-
teristics of eye movements in reading. The emphasis
is on saccadic eye movements rather than on tempo-
ral aspects of fixations. Section 3 defines the novel
task of learning to predict fixations during reading
and discusses different evaluation metrics for this
task. Section 4 presents a transition-based model
for solving this task, using a log-linear classifier to
predict the most probable transition after each fixa-
tion. Section 5 presents experimental results for the
model using data from the Dundee corpus (Kennedy
and Pynte, 2005), and Section 6 contains conclu-
sions and suggestions for future research.
</bodyText>
<sectionHeader confidence="0.729571" genericHeader="method">
2 Eye Movements in Reading
</sectionHeader>
<bodyText confidence="0.999964260869565">
Perhaps contrary to intuition, the eyes of readers do
not move smoothly across a line or page of text. It is
a salient fact in reading research that the eyes make
a series of very rapid ballistic movements (called
saccades) from one location to another. In between
saccades, the eyes remain relatively stationary for
brief periods of time (fixations). Most fixations last
about 200-300 ms but there is considerable variabil-
ity, both between and within readers. Thus, some
fixations last under 100 ms while others last over
500 ms (Rayner, 1998). Much of the variability in
fixation durations appears associated to processing
ease or difficulty.
The number of characters that is within the re-
gion of effective vision on any fixation is known as
the perceptual span. For English readers, the per-
ceptual span extends approximately four characters
to the left and fifteen characters to the right of the
fixation. Although readers fixate most words in a
text, many words are also skipped. Approximately
85% of the content words are fixated and 35% of
the function words (Carpenter and Just, 1983). Vari-
ables known to influence the likelihood of skipping
a word are word length, frequency and predictabil-
ity. Thus, more frequent words in the language are
skipped more often than less frequent words. This is
true also when word length is controlled for. Simi-
larly, words that occur in constrained contexts (and
are thus more predictable) are skipped more often
than words in less constrained contexts.
Although the majority of saccades in reading is
relatively local, i.e., target nearby words, more dis-
tant saccades also occur. Most saccades move the
eyes forward approximately 7–9 character spaces.
Approximately 15% of the saccades, however, are
regressions, in which the eyes move back to earlier
parts of the text (Rayner, 1998). It has long been
established that the length of saccades is influenced
by both the length of the fixated word and the word
to the right of the fixation (O’Regan, 1979). Re-
gressions often go back one or two words, but occa-
sionally they stretch further back. Such backward
movements are often thought to reflect linguistic
processing difficulty, e.g., because of syntactic pars-
ing problems. Readers, however, are often unaware
of making regressions, especially shorter ones.
</bodyText>
<page confidence="0.999609">
94
</page>
<sectionHeader confidence="0.991953" genericHeader="method">
3 The Learning Task
</sectionHeader>
<bodyText confidence="0.999254727272727">
We define a text T as a sequence of word tokens
(w1, ... , wn), and we define a fixation sequence
F for T as a sequence of token positions in T
(i1, ... , im) (1 &lt; ik &lt; n). The fixation set S(F)
corresponding to F is the set of token positions that
occur in F. For example, the text Mary had a lit-
tle lamb is represented by T = (Mary, had, a, little,
lamb); a reading of this text where the sequence of
fixations is Mary – little – Mary – lamb is repre-
sented by F = (1, 4, 1, 5); and the corresponding
fixation set is S(F) = f1, 4, 5g.
The task we now want to consider is the one
of predicting the fixation sequence F for a spe-
cific reading event E involving person P reading
text T. The training data consist of fixation se-
quences F1, ... , Fk for reading events distinct from
E involving the same person P but different texts
T1, ... , Tk. The performance of a model M is eval-
uated by comparing the predicted fixation sequence
FM to the fixation sequence FO observed in a read-
ing experiment involving P and T. Here are some
of the conceivable metrics for this evaluation:
</bodyText>
<listItem confidence="0.992055944444445">
1. Fixation sequence similarity: How similar
are the sequences FM and FO, as measured, for
example, by some string similarity metric?
2. Fixation accuracy: How large is the agree-
ment between the sets S(FM) and S(FO), as
measured by 0-1-loss over the entire text, i.e.,
how large is the proportion of positions that are
either in both S(FM) and S(FO) (fixated to-
kens) or in neither (skipped tokens). This can
also be broken down into precision and recall
for fixated and skipped tokens, respectively.
3. Fixation distributions: Does the model pre-
dict the correct proportion of fixated and
skipped tokens, as measured by the difference
between |S(FM)|/|T |and |S(FO)|/|T|? This
can also be broken down by frequency classes
of words, to see if the model captures frequency
effects reported in the literature.
</listItem>
<bodyText confidence="0.999701944444445">
These evaluation metrics are ordered by an implica-
tional scale from hardest to easiest. Thus, a model
that correctly predicts the exact fixation sequence
also makes correct predictions with respect to the
set of words fixated and the number of words fixated
(but not vice versa). In the same fashion, a model
that correctly predicts which words are fixated (but
not the exact sequence) also correctly predicts the
number of words fixated.
In the experiments reported in Section 5, we will
use variants of the latter two metrics and compare
the performance of our model to the baseline of al-
ways predicting the most frequent type of saccade
for the reader in question. We will report results
both for individual readers and mean scores over all
readers in the test set. The evaluation of fixation se-
quence similarity (the first type of metric) will be
left for future work.
</bodyText>
<sectionHeader confidence="0.995026" genericHeader="method">
4 A Transition-Based Model
</sectionHeader>
<bodyText confidence="0.999990296296296">
When exploring a new task, we first have to decide
what kind of model to use. As stated in the introduc-
tion, we regard this as a pilot experiment to establish
the feasibility of the task and have therefore chosen
to start with one of the simplest models possible and
see whether we can beat the baseline of always pre-
dicting the most frequent saccade. Since the task
consists in predicting a sequence of different actions,
it is very natural to use a transition-based model,
with configurations representing fixation states and
transitions representing saccadic movements. Given
such a system, we can train a classifier to predict the
next transition given the information in the current
configuration. In order to derive a complete tran-
sition sequence, we start in an initial configuration,
representing the reader’s state before the first fixa-
tion, and repeatedly apply the transition predicted by
the classifier until we reach a terminal state, repre-
senting the reader’s state after having read the entire
text. At an abstract level, this is essentially the same
idea as in transition-based dependency parsing (Ya-
mada and Matsumoto, 2003; Nivre, 2006; Attardi,
2006). In the following subsections, we discuss the
different components of the model in turn, including
the transition system, the classifier used, the features
used to represent data, and the search algorithm used
to derive complete transition sequences.
</bodyText>
<subsectionHeader confidence="0.996606">
4.1 Transition System
</subsectionHeader>
<bodyText confidence="0.9998205">
A transition system is an abstract machine consist-
ing of a set of configurations and transitions between
</bodyText>
<page confidence="0.987692">
95
</page>
<listItem confidence="0.910302777777778">
configurations. A configuration in the current sys-
tem is a triple C = (L, R, F), where
1. L is a list of tokens representing the left con-
text, including the currently fixated token and
all preceding tokens in the text.
2. R is a list of tokens representing the right con-
text, including all tokens following the cur-
rently fixated token in the text.
3. F is a list of token positions, representing the
</listItem>
<bodyText confidence="0.931183666666667">
fixation sequence so far, including the currently
fixated token.
For example, if the text to be read is Mary had a
little lamb, then the configuration
([Mary,had,a,little], [lamb], [1,4])
represents the state of a reader fixating the word little
after first having fixated the word Mary.
For any text T = w1 ... wn, we define initial and
terminal configurations as follows:
</bodyText>
<listItem confidence="0.881825">
1. Initial: C = ([], [w1,...,wn], [])
2. Terminal: C = ([w1, ... , wn], [ ], F)
(for any F)
</listItem>
<bodyText confidence="0.89087">
We then define the following transitions:1
</bodyText>
<listItem confidence="0.995614">
1. Progress(n):
</listItem>
<bodyText confidence="0.75064">
([λ|wi], [wi+1, ... , wi+n|ρ], [φ|i]) ⇒
([λ|wi, wi+1, ... ,wi+n], ρ, [φ|i, i+n])
</bodyText>
<listItem confidence="0.62018875">
2. Regress(n):
([λ|wi−n, ... , wi−1, wi], ρ, [φ|i]) ⇒
([λ|wi−n], [wi−n+1, ... , wi|ρ], [φ|i, i−n])
3. Refixate:
</listItem>
<equation confidence="0.662572">
([λ|wi], ρ, [φ|i]) ⇒ ([λ|wi], ρ, [φ|i, i])
</equation>
<bodyText confidence="0.9999165">
The transition Progress(n) models progressive sac-
cades of length n, which means that the next fixated
word is n positions forward with respect to the cur-
rently fixated word (i.e., n−1 words are skipped).
In a similar fashion, the transition Regress(n) mod-
els regressive saccades of length n. If the parameter
</bodyText>
<footnote confidence="0.555357666666667">
1We use the variables A, p and φ for arbitrary sublists of L,
R and F, respectively, and we write the L and F lists with their
tails to the right, to maintain the natural order of words.
</footnote>
<bodyText confidence="0.999504538461538">
n of either Progress(n) or Regress(n) is greater than
the number of words remaining in the relevant di-
rection, then the longest possible movement is made
instead, in which case Regress(n) leads to a terminal
configuration while Progress(n) leads to a configu-
ration that is similar to the initial configuration in
that it has an empty L list. The transition Refixate,
finally, models refixations, that is, cases where the
next word fixated is the same as the current.
To illustrate how this system works, we may con-
sider the transition sequence corresponding to the
reading of the text Mary had a little lamb used as
an example in Section 3:2
</bodyText>
<equation confidence="0.993921">
Init ⇒ ([ ], [Mary, ... , lamb], [ ])
P(1) ⇒ ([Mary], [had, ..., lamb], [1])
P(3) ⇒ ([Mary, ..., little], [lamb], [1,4])
R(3) ⇒ ([Mary], [had, ..., lamb], [1,4,1])
P(4) ⇒ ([Mary,..., lamb],[], [1,4,1,5])
</equation>
<subsectionHeader confidence="0.994663">
4.2 Learning Transitions
</subsectionHeader>
<bodyText confidence="0.999820666666666">
The transition system defined in the previous section
specifies the set of possible saccade transitions that
can be executed during the reading of a text, but it
does not say anything about the probability of dif-
ferent transitions in a given configuration, nor does
it guarantee that a terminal configuration will ever
be reached. The question is now whether we can
learn to predict the most probable transition in such
a way that the generated transition sequences model
the behavior of a given reader. To do this we need
to train a classifier that predicts the next transition
for any configuration, using as training data the ob-
served fixation sequences of a given reader. Before
that, however, we need to decide on a feature repre-
sentation for configurations.
Features used in this study are listed in Table 1.
We use the notation L[i] to refer to the ith token
in the list L and similarly for R and F. The first
two features refer to properties of the currently fix-
ated token. Length is simply the character length
of the word, while frequency class is an index of
the word’s frequency of occurrence in representative
text. Word frequencies are based on occurrences in
the Bristish National Corpus (BNC) and divided into
</bodyText>
<footnote confidence="0.9597575">
2We abbreviate Progress(n) and Regress(n) to P(n) and
R(n), respectively.
</footnote>
<page confidence="0.98019">
96
</page>
<table confidence="0.984793777777778">
Feature Description
CURRENT.LENGTH The length of the token L[1]
CURRENT.FREQUENCYCLASS The frequency class of the token L[1]
NEXT.LENGTH The length of the token R[1]
NEXT.FREQUENCYCLASS The frequency class of the token R[1]
NEXTPLUSONE.LENGTH The length of the token R[2]
NEXTPLUSTWO.LENGTH The length of the token R[3]
DISTANCE.ONETOTWO The distance, in tokens, between F[1] and F[2]
DISTANCE.TWOTOTHREE The distance, in tokens, between F[2] and F[3]
</table>
<tableCaption confidence="0.999678">
Table 1: Features defined over fixation configurations. The notation L[i] is used to denote the ith element of list L.
</tableCaption>
<bodyText confidence="0.999710139534884">
five classes. Frequencies were computed per million
words in the ranges 1–10, 11–100, 101–1000, 1001–
10000, and more than 10000.
The next four features define features of tokens
to the right of the current fixation. For the to-
ken immediately to the right, both length and fre-
quency are recorded whereas only length is con-
sidered for the two following tokens. The last
two features are defined over tokens in the fixa-
tion sequence built thus far and record the history
of the two most recent saccade actions. The first
of these (DISTANCE.ONETOTWO) defines the sac-
cade distance, in number of tokens, that led up
to the token currently being fixated. The second
(DISTANCE.TWOTOTHREE), defines the next most
recent saccade distance, that led up to the previous
fixation. For these two features the following holds.
If the distance is positive, the saccade is progressive,
if the distance is negative, the saccade is regressive,
and if the distance amounts to zero, the saccade is a
refixation.
The small set of features used in the current model
were chosen to reflect experimental evidence on eye
movements in reading. Thus, for example, as noted
in section 2, it is a well-documented fact that short,
frequent and predictable words tend to be skipped.
The last two features are included in the hope of
capturing some of the dynamics in eye movement
behavior, for example, if regressions are more likely
to occur after longer progressive saccades, or if the
next word is skipped more often if the current word
is refixated. Still, it is clear that this is only a tiny
subset of the feature space that might be considered,
and it remains an important topic for future research
to further explore this space and to study the impact
of different features.
Given our feature representation, and given some
training data derived from reading experiments, it
is straightforward to train a classifier for predicting
the most probable transition out of any configura-
tion. There are many learning algorithms that could
be used for this purpose, but in the pilot experiments
we only make use of logistic regression.
</bodyText>
<subsectionHeader confidence="0.999425">
4.3 Search Algorithm
</subsectionHeader>
<bodyText confidence="0.9997474">
Once we have trained a classifier f that predicts the
next transition f(C) out of any configuration C, we
can simulate the eye movement behavior of a person
reading the text T = (wi, ... , wn) using the follow-
ing simple search algorithm:
</bodyText>
<listItem confidence="0.997552666666667">
1. Initialize C to ([ ], [wi, ... , wn], []).
2. While C is not terminal, apply f(C) to C.
3. Return F of C.
</listItem>
<bodyText confidence="0.999568444444444">
It is worth noting that search will always terminate
once a terminal configuration has been reached, even
though there is nothing in the transition system that
forbids transitions out of terminal configurations. In
other words, while the model itself allows regres-
sions and refixations after the last word of the text
has been fixated, the search algorithm does not. This
seems like a reasonable approximation for this pilot
study.
</bodyText>
<sectionHeader confidence="0.999893" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.986238">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999609">
The experiments we report are based on data from
the English section of the Dundee corpus. This sec-
</bodyText>
<page confidence="0.99903">
97
</page>
<table confidence="0.99836">
Reader # sentences Fixation Accuracy Fixations Prec Skips F1
Baseline Model Prec Rec F1 Rec
a 136 53.3 70.0 69.9 73.8 71.8 69.0 65.8 67.4
b 156 55.7 66.5 65.2 85.8 74.1 70.3 80.4 75.0
c 151 59.9 70.9 72.5 82.8 77.3 67.4 53.1 59.4
d 162 69.0 78.9 84.7 84.8 84.7 66.0 65.8 65.9
e 182 51.7 71.8 69.1 78.4 73.5 75.3 65.2 69.9
f 157 63.5 67.9 70.9 83.7 76.8 58.7 40.2 47.7
g 129 43.3 56.6 49.9 80.8 61.7 72.2 38.1 49.9
h 143 57.6 66.9 69.4 76.3 72.7 62.8 54.3 58.2
i 196 56.4 69.1 69.6 80.3 74.6 68.2 54.7 60.7
j 166 66.1 76.3 82.2 81.9 82.0 65.0 65.4 65.2
Average 157.8 57.7 69.5 70.3 80.9 75.2 67.5 58.3 62.6
</table>
<tableCaption confidence="0.999508">
Table 2: Fixation and skipping accuracy on test data; Prec = precision, Rec = recall, F1 = balanced F measure.
</tableCaption>
<bodyText confidence="0.999989327586207">
tion contains the eye tracking record of ten partici-
pants reading editorial texts from The Independent
newspaper. The corpus contains 20 texts, each of
which were read by all participants. Participants also
answered a set of multiple-choice comprehension
questions after having finished reading each text.
The corpus consists of 2379 sentences, 56212 tokens
and 9776 types. The data was recorded using a Dr.
Bouis Oculometer Eyetracker, sampling the position
of the right eye every millisecond (see Kennedy and
Pynte, 2005, for further details).
For the experiments reported here, the corpus was
divided into three data sets: texts 1-16 for training
(1911 sentences), texts 17-18 for development and
validation (237 sentences), and the last two texts 19-
20 for testing (231 sentences).
Since we want to learn to predict the observed
saccade transition for any fixation configuration,
where configurations are represented as feature vec-
tors, it is not possible to use the eye tracking data
directly as training and test data. Instead, we simu-
late the search algorithm on the corpus data of each
reader in order to derive, for each sentence, the fea-
ture vectors over the configurations and the tran-
sitions corresponding to the observed fixation se-
quence. The instances to be classified then consist of
feature representations of configurations while the
classes are the possible transitions.
To somewhat simplify the learning task in this
first study, we removed all instances of non-local
saccades prior to training. Progressions stretching
further than five words ahead of the current fixation
were removed, as were regressions stretching further
back than two words. Refixations were not removed.
Thus we reduced the number of prediction classes to
eight. Removal of the non-local saccade instances
resulted in a 1.72% loss over the total number of in-
stances in the training data for all readers.
We trained one classifier for each reader using lo-
gistic regression, as implemented in Weka (Witten
and Eibe, 2005) and default options. In addition, we
trained majority baseline classifiers for all readers.
These models always predict the most frequent sac-
cadic eye movement for a given reader.
The classifiers were evaluated with respect to the
accuracy achieved when reading previously unseen
text using the search algorithm in 4.3. To ensure
that test data were consistent with training data, sen-
tences including any saccade outside of the local
range were removed prior to test. This resulted
in removal of 18.9% of the total number of sen-
tences in the test data for all readers. Accuracy was
measured in three different ways. First, we com-
puted the fixation accuracy, that is, the proportion
of words that were correctly fixated or skipped by
the model, which we also broke down into precision
and recall for fixations and skips separately.3 Sec-
ondly, we compared the predicted fixation distribu-
</bodyText>
<footnote confidence="0.9943118">
3Fixation/skip precision is the proportion of tokens fix-
ated/skipped by the model that were also fixated/skipped by
the reader; fixation/skip recall is the proportion of tokens fix-
ated/skipped by the reader that were also fixated/skipped by the
model.
</footnote>
<page confidence="0.982373">
98
</page>
<bodyText confidence="0.999920333333333">
tions to the observed fixation distributions, both over
all words and broken down into the same five fre-
quency classes that were used as features (see Sec-
tion 4). The latter statistics, averaged over all read-
ers, allow us to see whether the model correctly pre-
dicts the frequency effect discussed in section 2.
</bodyText>
<subsectionHeader confidence="0.981719">
5.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999969328358209">
Table 2 shows the fixation accuracy, and precision,
recall and F1 for fixations and skips, for each of the
ten different models and the average across all mod-
els (bottom row). Fixation accuracy is compared to
the baseline of always predicting the most frequent
saccade type (Progress(2) for readers a and e, and
Progress(1) for the rest).
If we consider the fixation accuracy, we see that
all models improve substantially on the baseline
models. The mean difference between models and
baselines is highly significant (p &lt; .001, paired t-
test). The relative improvement ranges from 4.4 per-
centage points in the worst case (model of reader f)
to 20.1 percentage points in the best case (model of
reader e). The highest scoring model, the model of
reader d, has an accuracy of 78.9%. The lowest scor-
ing model, the model of reader g, has an accuracy
of 56.6%. This is also the reader for whom there
is the smallest number of sentences in the test data
(129), which means that a large number of sentences
were removed prior to testing because of the greater
number of non-local saccades made by this reader.
Thus, this reader has an unusually varied saccadic
behaviour which is particularly hard to model.
Comparing the precision and recall for fixation
and skips, we see that while precision tends to be
about the same for both categories (with a few no-
table exceptions), recall is consistently higher for
fixations than for skips. We believe that this is due
to a tendency of the model to overpredict fixations,
especially for low-frequency words. This has a great
impact on the F1 measure (unweighted harmonic
mean of precision and recall), which is considerably
higher for fixations than for skips.
Figure 1 shows the distributions of fixations
grouped by reader and model. The models appear
reasonably good at adapting to the empirical fixa-
tion distribution of individual readers. However, the
models typically tend to look at more words than the
readers, as noted above. This suggests that the mod-
els lack sufficient information to learn to skip words
more often. This might be overcome by introducing
features that further encourage skipping of words. In
addition to word length and word frequency, that are
already accounted for, n-gram probability could be
included as a measure of predictability, for example.
We also note that there is a strong linear relation
between the capability of fitting the empirical dis-
tribution well and achieving high fixation accuracy
(Pearson’s r: -0.91, as measured by taking the dif-
ferences of each pair of distributions and correlating
them with the fixation accuracy of the models).
Figure 2 shows the mean observed and predicted
fixation and skipping probability as a function of
word frequency class, averaged over all readers. As
seen here, model prediction is responsive to fre-
quency class in a fashion comparable to the read-
ers, although the predictions typically tend to exag-
gerate the observed frequency effect. In the lower
to medium classes (1–3), almost every word is fix-
ated. Then there is a clear drop in fixation proba-
bility for words in frequency class 4 which fits well
with the observed fixation probability. Finally there
is another drop in fixation probability for the most
frequent words (5). The skipping probabilities for
the different classes show the corresponding reverse
trend.
</bodyText>
<sectionHeader confidence="0.99936" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999676666666667">
In this paper we have defined a new machine learn-
ing task where the goal is to learn the saccadic eye
movement behavior of individual readers in order
to predict the sequence of word fixations for novel
reading events. We have discussed different evalua-
tion metrics for this task, and we have established a
first benchmark by training and evaluating a simple
transition-based model using a log-linear classifier
to predict the next transition. The evaluation shows
that even this simple model, with features limited to
a few relevant properties in a small context window,
outperforms a majority baseline and captures some
of the word frequency effects on eye movements ob-
served in human readers.
This pilot study opens up a number of direc-
tions for future research. With respect to mod-
eling, we need to explore more complex models,
richer feature spaces, and alternative learning algo-
</bodyText>
<page confidence="0.977621">
99
</page>
<figure confidence="0.9989344">
Proportion
0.0 0.2 0.4 0.6 0.8
Reader
Model
a b c d e f g h i j
</figure>
<figureCaption confidence="0.999921">
Figure 1: Proportion of fixated tokens grouped by reader and model
</figureCaption>
<figure confidence="0.68873">
Frequency class
</figure>
<figureCaption confidence="0.974975">
Figure 2: Mean observed and predicted fixation and skipping probability for five frequency classes of words
</figureCaption>
<figure confidence="0.99906436">
1 2 3 4 5
Fixation probability
0.0 0.2 0.4 0.6 0.8 1.0
S S
S
F
F F
S
F
S
S
F
F
F Fixation - Observed
F Fixation - Predicted
S Skipping - Observed
S Skipping - Predicted
S
S
F
F
S
S
F
F
</figure>
<bodyText confidence="0.999873125">
rithms. For example, given the sequential nature
of the task, it seems natural to explore probabilistic
sequence models such as HMMs (see for example
Feng (2006)). With respect to evaluation, we need
to develop metrics that are sensitive to the sequential
behavior of models, such as the fixation sequence
similarity measure discussed in Section 3, and in-
vestigate to what extent results can be generalized
across readers. With respect to the task itself, we
need to introduce additional aspects of the reading
process, in particular the duration of fixations. By
pursuing these lines of research, we should be able
to gain a better understanding of how machine learn-
ing methods in eye movement modeling can inform
and advance current theories and models in reading
and psycholinguistic research.
</bodyText>
<page confidence="0.988853">
100
</page>
<sectionHeader confidence="0.995793" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999646643835616">
Giuseppe Attardi. 2006. Experiments with a multilan-
guage non-projective dependency parser. In Proceed-
ings of the 10th Conference on Computational Natural
Language Learning (CoNLL), pages 166–170.
Patricia A. Carpenter and Marcel A. Just. 1983. What
your eyes do while your mind is reading. In Keith
Rayner, editor, Eye movements in reading: Perceptual
and language processes, pages 275–307. New York:
Academic Press.
Charles Clifton, Adrian Staub, and Keith Rayner. 2007.
Eye movements in reading words and sentences. In
Roger van Gompel, editor, Eye movements: A window
on mind and brain, pages 341–372. Amsterdam: Else-
vier.
Ralf Engbert, André Longtin, and Reinhold Kliegl. 2002.
A dynamical model of saccade generation in reading
based on spatially distributed lexical processing. Vi-
sion Research, 42:621–636.
Gary Feng. 2006. Eye movements as time-series random
variables: A stochastic model of eye movement con-
trol in reading. Cognitive Systems Research, 7:70–95.
Alan Kennedy and Joël Pynte. 2005. Parafoveal-on-
foveal effects in normal reading. Vision research,
45:153–168.
Gordon E. Legge, Timothy S. Klitz, and Bosco S. Tjan.
1997. Mr. Chips: An ideal-observer model of reading.
Psychological Review, 104:524–553.
Scott A. McDonald, R.H.S. Carpenter, and Richard C.
Schillcock. 2005. An anatomically-constrained,
stochastic model of eye movement control in reading.
Psychological Review, 112:814–840.
Joakim Nivre. 2006. Inductive Dependency Parsing.
Springer.
J. Kevin O’Regan. 1979. Eye guidance in reading: Evi-
dence for the linguistic control hypothesis. Perception
&amp; Psychophysics, 25:501–509.
Alexander Pollatsek, Erik Reichle, and Keith Rayner.
2006. Tests of the E-Z Reader model: Exploring the
interface between cognition and eye movements.
Keith Rayner. 1998. Eye movements in reading and in-
formation processing: 20 years of research. Psycho-
logical Bulletin, 124:372–422.
Erik Reichle, Alexander Pollatsek, Donald Fisher, and
Keith Rayner. 1998. Toward a model of eye
movement control in reading. Psychological Review,
105:125–157.
Erik Reichle, Keith Rayner, and Alexander Pollatsek.
2003. The E-Z Reader model of eye-movement con-
trol in reading: Comparisons to other models. Behav-
ioral and Brain Sciences, 26:445–476.
Eric Reichle, editor. 2006. Cognitive Systems Research.
7:1–96. Special issue on models of eye-movement
control in reading.
Ronan Reilly and Ralph Radach. 2006. Some empirical
tests of an interactive activation model of eye move-
ment control in reading. Cognitive Systems Research,
7:34–55.
Dario D. Salvucci. 2001. An integrated model of eye
movements and visual encoding. Cognitive Systems
Research, 1:201–220.
Matthew Starr and Keith Rayner. 2001. Eye movements
during reading: some current controversies. Trends in
Cognitive Sciences, 5:156–163.
Ian H. Witten and Frank Eibe. 2005. Data Mining: Prac-
tical machine learning tools and techniques. Morgan
Kaufmann.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statisti-
cal dependency analysis with support vector machines.
In Proceedings of the 8th International Workshop on
Parsing Technologies (IWPT), pages 195–206.
Shun-nan Yang. 2006. A oculomotor-based model of
eye movements in reading: The competition/activation
model. Cognitive Systems Research, 7:56–69.
</reference>
<page confidence="0.998604">
101
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.662311">
<title confidence="0.999987">Learning Where to Look: Modeling Eye Movements in Reading</title>
<author confidence="0.999715">Mattias Nilsson Joakim Nivre</author>
<affiliation confidence="0.9992065">Department of Linguistics and Philology Department of Linguistics and Philology Uppsala University Uppsala</affiliation>
<email confidence="0.66882">mattias.nilsson@lingfil.uu.sejoakim.nivre@lingfil.uu.se</email>
<abstract confidence="0.999297272727273">We propose a novel machine learning task that consists in learning to predict which words in a text are fixated by a reader. In a first pilot experiment, we show that it is possible to outperform a majority baseline using a transitionbased model with a logistic regression classifier and a very limited set of features. We also show that the model is capable of capturing frequency effects on eye movements observed in human readers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Giuseppe Attardi</author>
</authors>
<title>Experiments with a multilanguage non-projective dependency parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>166--170</pages>
<contexts>
<context position="12284" citStr="Attardi, 2006" startWordPosition="2026" endWordPosition="2027">ccadic movements. Given such a system, we can train a classifier to predict the next transition given the information in the current configuration. In order to derive a complete transition sequence, we start in an initial configuration, representing the reader’s state before the first fixation, and repeatedly apply the transition predicted by the classifier until we reach a terminal state, representing the reader’s state after having read the entire text. At an abstract level, this is essentially the same idea as in transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2006; Attardi, 2006). In the following subsections, we discuss the different components of the model in turn, including the transition system, the classifier used, the features used to represent data, and the search algorithm used to derive complete transition sequences. 4.1 Transition System A transition system is an abstract machine consisting of a set of configurations and transitions between 95 configurations. A configuration in the current system is a triple C = (L, R, F), where 1. L is a list of tokens representing the left context, including the currently fixated token and all preceding tokens in the text.</context>
</contexts>
<marker>Attardi, 2006</marker>
<rawString>Giuseppe Attardi. 2006. Experiments with a multilanguage non-projective dependency parser. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL), pages 166–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patricia A Carpenter</author>
<author>Marcel A Just</author>
</authors>
<title>What your eyes do while your mind is reading.</title>
<date>1983</date>
<booktitle>Eye movements in reading: Perceptual and language processes,</booktitle>
<pages>275--307</pages>
<editor>In Keith Rayner, editor,</editor>
<publisher>Academic Press.</publisher>
<location>New York:</location>
<contexts>
<context position="7101" citStr="Carpenter and Just, 1983" startWordPosition="1133" endWordPosition="1136"> some fixations last under 100 ms while others last over 500 ms (Rayner, 1998). Much of the variability in fixation durations appears associated to processing ease or difficulty. The number of characters that is within the region of effective vision on any fixation is known as the perceptual span. For English readers, the perceptual span extends approximately four characters to the left and fifteen characters to the right of the fixation. Although readers fixate most words in a text, many words are also skipped. Approximately 85% of the content words are fixated and 35% of the function words (Carpenter and Just, 1983). Variables known to influence the likelihood of skipping a word are word length, frequency and predictability. Thus, more frequent words in the language are skipped more often than less frequent words. This is true also when word length is controlled for. Similarly, words that occur in constrained contexts (and are thus more predictable) are skipped more often than words in less constrained contexts. Although the majority of saccades in reading is relatively local, i.e., target nearby words, more distant saccades also occur. Most saccades move the eyes forward approximately 7–9 character spac</context>
</contexts>
<marker>Carpenter, Just, 1983</marker>
<rawString>Patricia A. Carpenter and Marcel A. Just. 1983. What your eyes do while your mind is reading. In Keith Rayner, editor, Eye movements in reading: Perceptual and language processes, pages 275–307. New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Clifton</author>
<author>Adrian Staub</author>
<author>Keith Rayner</author>
</authors>
<title>Eye movements in reading words and sentences.</title>
<date>2007</date>
<booktitle>Eye movements: A window on mind and brain,</booktitle>
<pages>341--372</pages>
<editor>In Roger van Gompel, editor,</editor>
<publisher>Elsevier.</publisher>
<location>Amsterdam:</location>
<contexts>
<context position="1224" citStr="Clifton et al., 2007" startWordPosition="188" endWordPosition="191"> that the model is capable of capturing frequency effects on eye movements observed in human readers. 1 Introduction Any person engaged in normal skilled reading produces an alternating series of rapid eye movements and brief fixations that forms a rich and detailed behavioral record of the reading process. In the last few decades a great deal of experimental evidence has accumulated to suggest that the eye movements of readers are reflective of ongoing language processing and thus provide a useful source of information for making inferences about the linguistic processes involved in reading (Clifton et al., 2007). In psycholinguistic research, eye movement data is now commonly used to study how experimental manipulations of linguistic stimuli manifest themselves in the eye movement record. Another related strand of research primarily attempts to understand what determines when and where the eyes move during reading. This line of research has led to mathematically well specified accounts of eye movement control in reading being instantiated as computational models (Legge et al., 1997; Reichle et al., 1998; Salvucci, 2001; Engbert et al., 2002; McDonald et al., 2005; Feng, 2006; Reilly and Radach, 2006;</context>
</contexts>
<marker>Clifton, Staub, Rayner, 2007</marker>
<rawString>Charles Clifton, Adrian Staub, and Keith Rayner. 2007. Eye movements in reading words and sentences. In Roger van Gompel, editor, Eye movements: A window on mind and brain, pages 341–372. Amsterdam: Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Engbert</author>
<author>André Longtin</author>
<author>Reinhold Kliegl</author>
</authors>
<title>A dynamical model of saccade generation in reading based on spatially distributed lexical processing.</title>
<date>2002</date>
<journal>Vision Research,</journal>
<pages>42--621</pages>
<contexts>
<context position="1763" citStr="Engbert et al., 2002" startWordPosition="271" endWordPosition="274">erences about the linguistic processes involved in reading (Clifton et al., 2007). In psycholinguistic research, eye movement data is now commonly used to study how experimental manipulations of linguistic stimuli manifest themselves in the eye movement record. Another related strand of research primarily attempts to understand what determines when and where the eyes move during reading. This line of research has led to mathematically well specified accounts of eye movement control in reading being instantiated as computational models (Legge et al., 1997; Reichle et al., 1998; Salvucci, 2001; Engbert et al., 2002; McDonald et al., 2005; Feng, 2006; Reilly and Radach, 2006; Yang, 2006). (For a recent overview, see (Reichle, 2006).) These models receive text as input and produce predictions for the location and duration of eye fixations, in approximation to human reading behavior. Although there are substantial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers process information from more than one wo</context>
</contexts>
<marker>Engbert, Longtin, Kliegl, 2002</marker>
<rawString>Ralf Engbert, André Longtin, and Reinhold Kliegl. 2002. A dynamical model of saccade generation in reading based on spatially distributed lexical processing. Vision Research, 42:621–636.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary Feng</author>
</authors>
<title>Eye movements as time-series random variables: A stochastic model of eye movement control in reading.</title>
<date>2006</date>
<booktitle>Cognitive Systems Research,</booktitle>
<pages>7--70</pages>
<contexts>
<context position="1798" citStr="Feng, 2006" startWordPosition="279" endWordPosition="280">ed in reading (Clifton et al., 2007). In psycholinguistic research, eye movement data is now commonly used to study how experimental manipulations of linguistic stimuli manifest themselves in the eye movement record. Another related strand of research primarily attempts to understand what determines when and where the eyes move during reading. This line of research has led to mathematically well specified accounts of eye movement control in reading being instantiated as computational models (Legge et al., 1997; Reichle et al., 1998; Salvucci, 2001; Engbert et al., 2002; McDonald et al., 2005; Feng, 2006; Reilly and Radach, 2006; Yang, 2006). (For a recent overview, see (Reichle, 2006).) These models receive text as input and produce predictions for the location and duration of eye fixations, in approximation to human reading behavior. Although there are substantial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers process information from more than one word at a time (Starr and Rayner, 200</context>
<context position="29164" citStr="Feng (2006)" startWordPosition="4883" endWordPosition="4884">ng algo99 Proportion 0.0 0.2 0.4 0.6 0.8 Reader Model a b c d e f g h i j Figure 1: Proportion of fixated tokens grouped by reader and model Frequency class Figure 2: Mean observed and predicted fixation and skipping probability for five frequency classes of words 1 2 3 4 5 Fixation probability 0.0 0.2 0.4 0.6 0.8 1.0 S S S F F F S F S S F F F Fixation - Observed F Fixation - Predicted S Skipping - Observed S Skipping - Predicted S S F F S S F F rithms. For example, given the sequential nature of the task, it seems natural to explore probabilistic sequence models such as HMMs (see for example Feng (2006)). With respect to evaluation, we need to develop metrics that are sensitive to the sequential behavior of models, such as the fixation sequence similarity measure discussed in Section 3, and investigate to what extent results can be generalized across readers. With respect to the task itself, we need to introduce additional aspects of the reading process, in particular the duration of fixations. By pursuing these lines of research, we should be able to gain a better understanding of how machine learning methods in eye movement modeling can inform and advance current theories and models in rea</context>
</contexts>
<marker>Feng, 2006</marker>
<rawString>Gary Feng. 2006. Eye movements as time-series random variables: A stochastic model of eye movement control in reading. Cognitive Systems Research, 7:70–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Kennedy</author>
<author>Joël Pynte</author>
</authors>
<title>Parafoveal-onfoveal effects in normal reading. Vision research,</title>
<date>2005</date>
<pages>45--153</pages>
<contexts>
<context position="5909" citStr="Kennedy and Pynte, 2005" startWordPosition="936" endWordPosition="939">e paper is structured as follows. Section 2 provides a brief background on basic characteristics of eye movements in reading. The emphasis is on saccadic eye movements rather than on temporal aspects of fixations. Section 3 defines the novel task of learning to predict fixations during reading and discusses different evaluation metrics for this task. Section 4 presents a transition-based model for solving this task, using a log-linear classifier to predict the most probable transition after each fixation. Section 5 presents experimental results for the model using data from the Dundee corpus (Kennedy and Pynte, 2005), and Section 6 contains conclusions and suggestions for future research. 2 Eye Movements in Reading Perhaps contrary to intuition, the eyes of readers do not move smoothly across a line or page of text. It is a salient fact in reading research that the eyes make a series of very rapid ballistic movements (called saccades) from one location to another. In between saccades, the eyes remain relatively stationary for brief periods of time (fixations). Most fixations last about 200-300 ms but there is considerable variability, both between and within readers. Thus, some fixations last under 100 ms</context>
<context position="21350" citStr="Kennedy and Pynte, 2005" startWordPosition="3576" endWordPosition="3579">ixation and skipping accuracy on test data; Prec = precision, Rec = recall, F1 = balanced F measure. tion contains the eye tracking record of ten participants reading editorial texts from The Independent newspaper. The corpus contains 20 texts, each of which were read by all participants. Participants also answered a set of multiple-choice comprehension questions after having finished reading each text. The corpus consists of 2379 sentences, 56212 tokens and 9776 types. The data was recorded using a Dr. Bouis Oculometer Eyetracker, sampling the position of the right eye every millisecond (see Kennedy and Pynte, 2005, for further details). For the experiments reported here, the corpus was divided into three data sets: texts 1-16 for training (1911 sentences), texts 17-18 for development and validation (237 sentences), and the last two texts 19- 20 for testing (231 sentences). Since we want to learn to predict the observed saccade transition for any fixation configuration, where configurations are represented as feature vectors, it is not possible to use the eye tracking data directly as training and test data. Instead, we simulate the search algorithm on the corpus data of each reader in order to derive, </context>
</contexts>
<marker>Kennedy, Pynte, 2005</marker>
<rawString>Alan Kennedy and Joël Pynte. 2005. Parafoveal-onfoveal effects in normal reading. Vision research, 45:153–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gordon E Legge</author>
<author>Timothy S Klitz</author>
<author>Bosco S Tjan</author>
</authors>
<title>Mr. Chips: An ideal-observer model of reading.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<pages>104--524</pages>
<contexts>
<context position="1703" citStr="Legge et al., 1997" startWordPosition="261" endWordPosition="264">thus provide a useful source of information for making inferences about the linguistic processes involved in reading (Clifton et al., 2007). In psycholinguistic research, eye movement data is now commonly used to study how experimental manipulations of linguistic stimuli manifest themselves in the eye movement record. Another related strand of research primarily attempts to understand what determines when and where the eyes move during reading. This line of research has led to mathematically well specified accounts of eye movement control in reading being instantiated as computational models (Legge et al., 1997; Reichle et al., 1998; Salvucci, 2001; Engbert et al., 2002; McDonald et al., 2005; Feng, 2006; Reilly and Radach, 2006; Yang, 2006). (For a recent overview, see (Reichle, 2006).) These models receive text as input and produce predictions for the location and duration of eye fixations, in approximation to human reading behavior. Although there are substantial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements a</context>
</contexts>
<marker>Legge, Klitz, Tjan, 1997</marker>
<rawString>Gordon E. Legge, Timothy S. Klitz, and Bosco S. Tjan. 1997. Mr. Chips: An ideal-observer model of reading. Psychological Review, 104:524–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott A McDonald</author>
<author>R H S Carpenter</author>
<author>Richard C Schillcock</author>
</authors>
<title>An anatomically-constrained, stochastic model of eye movement control in reading.</title>
<date>2005</date>
<journal>Psychological Review,</journal>
<pages>112--814</pages>
<contexts>
<context position="1786" citStr="McDonald et al., 2005" startWordPosition="275" endWordPosition="278">uistic processes involved in reading (Clifton et al., 2007). In psycholinguistic research, eye movement data is now commonly used to study how experimental manipulations of linguistic stimuli manifest themselves in the eye movement record. Another related strand of research primarily attempts to understand what determines when and where the eyes move during reading. This line of research has led to mathematically well specified accounts of eye movement control in reading being instantiated as computational models (Legge et al., 1997; Reichle et al., 1998; Salvucci, 2001; Engbert et al., 2002; McDonald et al., 2005; Feng, 2006; Reilly and Radach, 2006; Yang, 2006). (For a recent overview, see (Reichle, 2006).) These models receive text as input and produce predictions for the location and duration of eye fixations, in approximation to human reading behavior. Although there are substantial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers process information from more than one word at a time (Starr and</context>
</contexts>
<marker>McDonald, Carpenter, Schillcock, 2005</marker>
<rawString>Scott A. McDonald, R.H.S. Carpenter, and Richard C. Schillcock. 2005. An anatomically-constrained, stochastic model of eye movement control in reading. Psychological Review, 112:814–840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Inductive Dependency Parsing.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<contexts>
<context position="12268" citStr="Nivre, 2006" startWordPosition="2024" endWordPosition="2025">presenting saccadic movements. Given such a system, we can train a classifier to predict the next transition given the information in the current configuration. In order to derive a complete transition sequence, we start in an initial configuration, representing the reader’s state before the first fixation, and repeatedly apply the transition predicted by the classifier until we reach a terminal state, representing the reader’s state after having read the entire text. At an abstract level, this is essentially the same idea as in transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2006; Attardi, 2006). In the following subsections, we discuss the different components of the model in turn, including the transition system, the classifier used, the features used to represent data, and the search algorithm used to derive complete transition sequences. 4.1 Transition System A transition system is an abstract machine consisting of a set of configurations and transitions between 95 configurations. A configuration in the current system is a triple C = (L, R, F), where 1. L is a list of tokens representing the left context, including the currently fixated token and all preceding tok</context>
</contexts>
<marker>Nivre, 2006</marker>
<rawString>Joakim Nivre. 2006. Inductive Dependency Parsing. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kevin O’Regan</author>
</authors>
<title>Eye guidance in reading: Evidence for the linguistic control hypothesis.</title>
<date>1979</date>
<journal>Perception &amp; Psychophysics,</journal>
<pages>25--501</pages>
<marker>O’Regan, 1979</marker>
<rawString>J. Kevin O’Regan. 1979. Eye guidance in reading: Evidence for the linguistic control hypothesis. Perception &amp; Psychophysics, 25:501–509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Pollatsek</author>
<author>Erik Reichle</author>
<author>Keith Rayner</author>
</authors>
<title>Tests of the E-Z Reader model: Exploring the interface between cognition and eye movements.</title>
<date>2006</date>
<contexts>
<context position="2707" citStr="Pollatsek et al., 2006" startWordPosition="419" endWordPosition="422">n the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers process information from more than one word at a time (Starr and Rayner, 2001). More generally, the models that have emerged to date are based on different sets of assumptions about the underlying perceptual and cognitive mechanisms that control eye movements. The most influential model so far, the E-Z Reader model (Reichle et al., 1998; Reichle et al., 2003; Pollatsek et al., 2006), rests on the assumptions that cognitive /lexical processing is the engine that drives the eyes through the text and that words are identified serially, one at a time. Although eye movement models typically have parameters that are fitted to empirical data sets, they are not based on machine learning in the standard sense and their predictions are hardly ever tested on unseen data. Moreover, their predictions are normally averaged over a whole group of readers or words belonging to a given frequency class. In this study, however, we investigate whether saccadic eye movements during reading ca</context>
</contexts>
<marker>Pollatsek, Reichle, Rayner, 2006</marker>
<rawString>Alexander Pollatsek, Erik Reichle, and Keith Rayner. 2006. Tests of the E-Z Reader model: Exploring the interface between cognition and eye movements.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Rayner</author>
</authors>
<title>Eye movements in reading and information processing: 20 years of research.</title>
<date>1998</date>
<journal>Psychological Bulletin,</journal>
<pages>124--372</pages>
<contexts>
<context position="6554" citStr="Rayner, 1998" startWordPosition="1045" endWordPosition="1046">ions and suggestions for future research. 2 Eye Movements in Reading Perhaps contrary to intuition, the eyes of readers do not move smoothly across a line or page of text. It is a salient fact in reading research that the eyes make a series of very rapid ballistic movements (called saccades) from one location to another. In between saccades, the eyes remain relatively stationary for brief periods of time (fixations). Most fixations last about 200-300 ms but there is considerable variability, both between and within readers. Thus, some fixations last under 100 ms while others last over 500 ms (Rayner, 1998). Much of the variability in fixation durations appears associated to processing ease or difficulty. The number of characters that is within the region of effective vision on any fixation is known as the perceptual span. For English readers, the perceptual span extends approximately four characters to the left and fifteen characters to the right of the fixation. Although readers fixate most words in a text, many words are also skipped. Approximately 85% of the content words are fixated and 35% of the function words (Carpenter and Just, 1983). Variables known to influence the likelihood of skip</context>
<context position="7837" citStr="Rayner, 1998" startWordPosition="1253" endWordPosition="1254">frequent words in the language are skipped more often than less frequent words. This is true also when word length is controlled for. Similarly, words that occur in constrained contexts (and are thus more predictable) are skipped more often than words in less constrained contexts. Although the majority of saccades in reading is relatively local, i.e., target nearby words, more distant saccades also occur. Most saccades move the eyes forward approximately 7–9 character spaces. Approximately 15% of the saccades, however, are regressions, in which the eyes move back to earlier parts of the text (Rayner, 1998). It has long been established that the length of saccades is influenced by both the length of the fixated word and the word to the right of the fixation (O’Regan, 1979). Regressions often go back one or two words, but occasionally they stretch further back. Such backward movements are often thought to reflect linguistic processing difficulty, e.g., because of syntactic parsing problems. Readers, however, are often unaware of making regressions, especially shorter ones. 94 3 The Learning Task We define a text T as a sequence of word tokens (w1, ... , wn), and we define a fixation sequence F fo</context>
</contexts>
<marker>Rayner, 1998</marker>
<rawString>Keith Rayner. 1998. Eye movements in reading and information processing: 20 years of research. Psychological Bulletin, 124:372–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Reichle</author>
<author>Alexander Pollatsek</author>
<author>Donald Fisher</author>
<author>Keith Rayner</author>
</authors>
<title>Toward a model of eye movement control in reading.</title>
<date>1998</date>
<journal>Psychological Review,</journal>
<pages>105--125</pages>
<contexts>
<context position="1725" citStr="Reichle et al., 1998" startWordPosition="265" endWordPosition="268">l source of information for making inferences about the linguistic processes involved in reading (Clifton et al., 2007). In psycholinguistic research, eye movement data is now commonly used to study how experimental manipulations of linguistic stimuli manifest themselves in the eye movement record. Another related strand of research primarily attempts to understand what determines when and where the eyes move during reading. This line of research has led to mathematically well specified accounts of eye movement control in reading being instantiated as computational models (Legge et al., 1997; Reichle et al., 1998; Salvucci, 2001; Engbert et al., 2002; McDonald et al., 2005; Feng, 2006; Reilly and Radach, 2006; Yang, 2006). (For a recent overview, see (Reichle, 2006).) These models receive text as input and produce predictions for the location and duration of eye fixations, in approximation to human reading behavior. Although there are substantial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers pro</context>
</contexts>
<marker>Reichle, Pollatsek, Fisher, Rayner, 1998</marker>
<rawString>Erik Reichle, Alexander Pollatsek, Donald Fisher, and Keith Rayner. 1998. Toward a model of eye movement control in reading. Psychological Review, 105:125–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Reichle</author>
<author>Keith Rayner</author>
<author>Alexander Pollatsek</author>
</authors>
<title>The E-Z Reader model of eye-movement control in reading: Comparisons to other models. Behavioral and Brain Sciences,</title>
<date>2003</date>
<pages>26--445</pages>
<contexts>
<context position="2682" citStr="Reichle et al., 2003" startWordPosition="415" endWordPosition="418">ial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers process information from more than one word at a time (Starr and Rayner, 2001). More generally, the models that have emerged to date are based on different sets of assumptions about the underlying perceptual and cognitive mechanisms that control eye movements. The most influential model so far, the E-Z Reader model (Reichle et al., 1998; Reichle et al., 2003; Pollatsek et al., 2006), rests on the assumptions that cognitive /lexical processing is the engine that drives the eyes through the text and that words are identified serially, one at a time. Although eye movement models typically have parameters that are fitted to empirical data sets, they are not based on machine learning in the standard sense and their predictions are hardly ever tested on unseen data. Moreover, their predictions are normally averaged over a whole group of readers or words belonging to a given frequency class. In this study, however, we investigate whether saccadic eye mo</context>
</contexts>
<marker>Reichle, Rayner, Pollatsek, 2003</marker>
<rawString>Erik Reichle, Keith Rayner, and Alexander Pollatsek. 2003. The E-Z Reader model of eye-movement control in reading: Comparisons to other models. Behavioral and Brain Sciences, 26:445–476.</rawString>
</citation>
<citation valid="true">
<date>2006</date>
<booktitle>Cognitive Systems Research. 7:1–96. Special issue on models of eye-movement control in reading.</booktitle>
<editor>Eric Reichle, editor.</editor>
<contexts>
<context position="29164" citStr="(2006)" startWordPosition="4884" endWordPosition="4884">go99 Proportion 0.0 0.2 0.4 0.6 0.8 Reader Model a b c d e f g h i j Figure 1: Proportion of fixated tokens grouped by reader and model Frequency class Figure 2: Mean observed and predicted fixation and skipping probability for five frequency classes of words 1 2 3 4 5 Fixation probability 0.0 0.2 0.4 0.6 0.8 1.0 S S S F F F S F S S F F F Fixation - Observed F Fixation - Predicted S Skipping - Observed S Skipping - Predicted S S F F S S F F rithms. For example, given the sequential nature of the task, it seems natural to explore probabilistic sequence models such as HMMs (see for example Feng (2006)). With respect to evaluation, we need to develop metrics that are sensitive to the sequential behavior of models, such as the fixation sequence similarity measure discussed in Section 3, and investigate to what extent results can be generalized across readers. With respect to the task itself, we need to introduce additional aspects of the reading process, in particular the duration of fixations. By pursuing these lines of research, we should be able to gain a better understanding of how machine learning methods in eye movement modeling can inform and advance current theories and models in rea</context>
</contexts>
<marker>2006</marker>
<rawString>Eric Reichle, editor. 2006. Cognitive Systems Research. 7:1–96. Special issue on models of eye-movement control in reading.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Reilly</author>
<author>Ralph Radach</author>
</authors>
<title>Some empirical tests of an interactive activation model of eye movement control in reading.</title>
<date>2006</date>
<booktitle>Cognitive Systems Research,</booktitle>
<pages>7--34</pages>
<contexts>
<context position="1823" citStr="Reilly and Radach, 2006" startWordPosition="281" endWordPosition="284">g (Clifton et al., 2007). In psycholinguistic research, eye movement data is now commonly used to study how experimental manipulations of linguistic stimuli manifest themselves in the eye movement record. Another related strand of research primarily attempts to understand what determines when and where the eyes move during reading. This line of research has led to mathematically well specified accounts of eye movement control in reading being instantiated as computational models (Legge et al., 1997; Reichle et al., 1998; Salvucci, 2001; Engbert et al., 2002; McDonald et al., 2005; Feng, 2006; Reilly and Radach, 2006; Yang, 2006). (For a recent overview, see (Reichle, 2006).) These models receive text as input and produce predictions for the location and duration of eye fixations, in approximation to human reading behavior. Although there are substantial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers process information from more than one word at a time (Starr and Rayner, 2001). More generally, the m</context>
</contexts>
<marker>Reilly, Radach, 2006</marker>
<rawString>Ronan Reilly and Ralph Radach. 2006. Some empirical tests of an interactive activation model of eye movement control in reading. Cognitive Systems Research, 7:34–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dario D Salvucci</author>
</authors>
<title>An integrated model of eye movements and visual encoding.</title>
<date>2001</date>
<booktitle>Cognitive Systems Research,</booktitle>
<pages>1--201</pages>
<contexts>
<context position="1741" citStr="Salvucci, 2001" startWordPosition="269" endWordPosition="270">n for making inferences about the linguistic processes involved in reading (Clifton et al., 2007). In psycholinguistic research, eye movement data is now commonly used to study how experimental manipulations of linguistic stimuli manifest themselves in the eye movement record. Another related strand of research primarily attempts to understand what determines when and where the eyes move during reading. This line of research has led to mathematically well specified accounts of eye movement control in reading being instantiated as computational models (Legge et al., 1997; Reichle et al., 1998; Salvucci, 2001; Engbert et al., 2002; McDonald et al., 2005; Feng, 2006; Reilly and Radach, 2006; Yang, 2006). (For a recent overview, see (Reichle, 2006).) These models receive text as input and produce predictions for the location and duration of eye fixations, in approximation to human reading behavior. Although there are substantial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers process information</context>
</contexts>
<marker>Salvucci, 2001</marker>
<rawString>Dario D. Salvucci. 2001. An integrated model of eye movements and visual encoding. Cognitive Systems Research, 1:201–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Starr</author>
<author>Keith Rayner</author>
</authors>
<title>Eye movements during reading: some current controversies.</title>
<date>2001</date>
<booktitle>Trends in Cognitive Sciences,</booktitle>
<pages>5--156</pages>
<contexts>
<context position="2400" citStr="Starr and Rayner, 2001" startWordPosition="369" endWordPosition="372">al., 2005; Feng, 2006; Reilly and Radach, 2006; Yang, 2006). (For a recent overview, see (Reichle, 2006).) These models receive text as input and produce predictions for the location and duration of eye fixations, in approximation to human reading behavior. Although there are substantial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers process information from more than one word at a time (Starr and Rayner, 2001). More generally, the models that have emerged to date are based on different sets of assumptions about the underlying perceptual and cognitive mechanisms that control eye movements. The most influential model so far, the E-Z Reader model (Reichle et al., 1998; Reichle et al., 2003; Pollatsek et al., 2006), rests on the assumptions that cognitive /lexical processing is the engine that drives the eyes through the text and that words are identified serially, one at a time. Although eye movement models typically have parameters that are fitted to empirical data sets, they are not based on machine</context>
</contexts>
<marker>Starr, Rayner, 2001</marker>
<rawString>Matthew Starr and Keith Rayner. 2001. Eye movements during reading: some current controversies. Trends in Cognitive Sciences, 5:156–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Frank Eibe</author>
</authors>
<title>Data Mining: Practical machine learning tools and techniques.</title>
<date>2005</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="22842" citStr="Witten and Eibe, 2005" startWordPosition="3814" endWordPosition="3817">o somewhat simplify the learning task in this first study, we removed all instances of non-local saccades prior to training. Progressions stretching further than five words ahead of the current fixation were removed, as were regressions stretching further back than two words. Refixations were not removed. Thus we reduced the number of prediction classes to eight. Removal of the non-local saccade instances resulted in a 1.72% loss over the total number of instances in the training data for all readers. We trained one classifier for each reader using logistic regression, as implemented in Weka (Witten and Eibe, 2005) and default options. In addition, we trained majority baseline classifiers for all readers. These models always predict the most frequent saccadic eye movement for a given reader. The classifiers were evaluated with respect to the accuracy achieved when reading previously unseen text using the search algorithm in 4.3. To ensure that test data were consistent with training data, sentences including any saccade outside of the local range were removed prior to test. This resulted in removal of 18.9% of the total number of sentences in the test data for all readers. Accuracy was measured in three</context>
</contexts>
<marker>Witten, Eibe, 2005</marker>
<rawString>Ian H. Witten and Frank Eibe. 2005. Data Mining: Practical machine learning tools and techniques. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>195--206</pages>
<contexts>
<context position="12255" citStr="Yamada and Matsumoto, 2003" startWordPosition="2019" endWordPosition="2023">on states and transitions representing saccadic movements. Given such a system, we can train a classifier to predict the next transition given the information in the current configuration. In order to derive a complete transition sequence, we start in an initial configuration, representing the reader’s state before the first fixation, and repeatedly apply the transition predicted by the classifier until we reach a terminal state, representing the reader’s state after having read the entire text. At an abstract level, this is essentially the same idea as in transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2006; Attardi, 2006). In the following subsections, we discuss the different components of the model in turn, including the transition system, the classifier used, the features used to represent data, and the search algorithm used to derive complete transition sequences. 4.1 Transition System A transition system is an abstract machine consisting of a set of configurations and transitions between 95 configurations. A configuration in the current system is a triple C = (L, R, F), where 1. L is a list of tokens representing the left context, including the currently fixated token and all </context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT), pages 195–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shun-nan Yang</author>
</authors>
<title>A oculomotor-based model of eye movements in reading: The competition/activation model.</title>
<date>2006</date>
<booktitle>Cognitive Systems Research,</booktitle>
<pages>7--56</pages>
<contexts>
<context position="1836" citStr="Yang, 2006" startWordPosition="285" endWordPosition="286"> In psycholinguistic research, eye movement data is now commonly used to study how experimental manipulations of linguistic stimuli manifest themselves in the eye movement record. Another related strand of research primarily attempts to understand what determines when and where the eyes move during reading. This line of research has led to mathematically well specified accounts of eye movement control in reading being instantiated as computational models (Legge et al., 1997; Reichle et al., 1998; Salvucci, 2001; Engbert et al., 2002; McDonald et al., 2005; Feng, 2006; Reilly and Radach, 2006; Yang, 2006). (For a recent overview, see (Reichle, 2006).) These models receive text as input and produce predictions for the location and duration of eye fixations, in approximation to human reading behavior. Although there are substantial differences between the various models, they typically combine both mechanisms of visuomotor control and linguistic processing. Two important points of divergence concern the extent to which language processing influences eye movements and whether readers process information from more than one word at a time (Starr and Rayner, 2001). More generally, the models that ha</context>
</contexts>
<marker>Yang, 2006</marker>
<rawString>Shun-nan Yang. 2006. A oculomotor-based model of eye movements in reading: The competition/activation model. Cognitive Systems Research, 7:56–69.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>