<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011751">
<title confidence="0.999248">
A Dual-Layer Semantic Role Labeling System
</title>
<author confidence="0.997758">
Lun-Wei Ku
</author>
<affiliation confidence="0.801396">
Institute of Information Science
Academia Sinica, Taiwan
</affiliation>
<email confidence="0.993684">
lwku@iis.sinica.edu.tw
</email>
<author confidence="0.963775">
Shafqat Mumtaz Virk
</author>
<affiliation confidence="0.7989115">
Institute of Information Science
Academia Sinica, Taiwan
</affiliation>
<email confidence="0.9945">
virk.shafqat@gmail.com
</email>
<author confidence="0.97696">
Yann-Huei Lee
</author>
<affiliation confidence="0.807628">
Institute of Information Science
Academia Sinica, Taiwan
</affiliation>
<email confidence="0.795834">
andycyrus.gmail.com
</email>
<sectionHeader confidence="0.995545" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999844318181818">
We describe a well-performed semantic role
labeling system that further extracts concepts
(smaller semantic expressions) from unstruc-
tured natural language sentences language in-
dependently. A dual-layer semantic role
labeling (SRL) system is built using Chinese
Treebank and Propbank data. Contextual in-
formation is incorporated while labeling the
predicate arguments to achieve better perfor-
mance. Experimental results show that the
proposed approach is superior to CoNLL 2009
best systems and comparable to the state of
the art with the advantage that it requires no
feature engineering process. Concepts are fur-
ther extracted according to templates formu-
lated by the labeled semantic roles to serve as
features in other NLP tasks to provide seman-
tically related cues and potentially help in re-
lated research problems. We also show that it
is easy to generate a different language ver-
sion of this system by actually building an
English system which performs satisfactory.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999795810810811">
Semantic roles are utilized to find concepts au-
tomatically and assure their meaningfulness. Se-
mantic role labeling is a research problem which
finds in a given sentence the predicates and their
arguments (identification), and further labels the
semantic relationship between predicates and ar-
guments, that is, their semantic roles (classifica-
tion). There are several labeling sets. Researchers
have widely adopted the semantic role labels de-
fined in Propbank (Bonial et al., 2010) like predi-
cate (PRED), numbered arguments 0 to 5 (ARG0,
ARG1, ARG2, ARG3, ARG4, ARG5), or modifier
arguments (ARGM-X); finer labels are those de-
fined in Sinica Treebank (Huang et al., 2000) like
agent, theme, target, which are labeled on each
node of the parse tree; those defined in FrameNet
(Ruppenhofer et al., 2006) are the finest but most
expressive. Each set provides semantic information.
As long as the semantic relationship between terms
derives from their semantic role labels, we are able
to determine whether they should be extracted
from the current sentence to construct a concept.
The word concept usually refers to an abstract or
general idea inferred or derived from specific in-
stances. Therefore, the extraction of concepts from
text is often defined as extracting terms that are in
some way related to one another. These terms
could be predefined by people in resources such as
ontologies, or they could be typical words in texts.
In this paper, we view concepts as the continuous
or discontinuous meaningful units in a sentence
and hence they are tightly related to semantic roles.
We propose a dual-layer semantic role labeling
system which provides extracted concepts accord-
ing to the reported labels, and then demonstrate the
functions of this system. Experimental results will
show the merit of the proposed framework.
</bodyText>
<sectionHeader confidence="0.999893" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999834882352941">
Previous studies related to this work can be divided
into two groups: semantic role labeling and con-
cept extraction. Semantic role labeling (SRL) has
sparked much interest in NLP (Shen and Lapata,
2007; Liu and Gildea, 2010). The first automatic
SRL systems were reported by Gildea and Jurafsky
in 2002 (Gildea and Jurafsky 2002); since then,
their ideas have dominated the field. In their ap-
proach, they emphasize the selection of appropriate
lexical and syntactical features for SRL, the use of
statistical classifiers and their combinations, and
ways to handle data sparseness. Many researchers
have tried to build on their work by augmenting
and/or altering the feature set (Xue 2004), by ex-
perimenting with various classification approaches
(Pradhan et al. 2004; Park and Rim 2005), and by
attempting different ways to handle data sparseness
</bodyText>
<page confidence="0.995268">
49
</page>
<note confidence="0.696458">
Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 49–54,
Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP
</note>
<bodyText confidence="0.990338285714286">
(Zapirain, Agirre, and Màrquez 2007). Moreover,
some researchers have tried to extend it in novel
ways. For example, Ding and Chang (2008) used a
hierarchical feature selection strategy, while Jiang,
Li, and Ng (2005) proposed exploiting argument
interdependence, that is, the fact that the semantic
role of one argument can depend on the semantic
roles of other arguments.
Many researchers have tried to extract concepts
from texts (Gelfand et al., 1998; Hovy et al., 2009;
Villalon and Calvo, 2009; Dinh and Tamine, 2011;
Torii et al., 2011). Hovy narrowed the domain of
interest into concepts “below” a given seed term.
Villalon and Calvo extract concepts from student
essays for concept map mining, which generates a
directed relational graph of the extracted concepts
in an essay. For specific domains, biological or
medical concepts are of greatest interest to re-
searchers (Jonnalagadda et al., 2011). Two rela-
tively new and related approaches are the Concept
parser (Rajagopal et al. 2013), a part of the
SenticNet project (Cambria, Olsher, and Rajagopal
2014) and ConceptNet (Liu and Singh 2004). The
former is a tool to decompose unrestricted natural
language text to a bag of concepts, which is similar
to our work. However, in the final phase a seman-
tic knowledge base is used to express a concept in
all its different forms and their concept-parser does
not use any semantic knowledge during decompo-
sition. The latter is a semantic network based on
the Open Mind Common Sense (OMCS)
knowledge base. As it is a knowledge base, its
construction process is quite different from the
work described here of automatically extracting
concepts from sentences.
</bodyText>
<figure confidence="0.8264515">
Output:
Concepts
</figure>
<figureCaption confidence="0.999763">
Figure 1: System Framework.
</figureCaption>
<figure confidence="0.999719818181818">
Input:
Sentence
Syntactic Parsing
Semantic Role
Labeling
Prop-
Bank
Concept
Templates
Concept
Extraction
</figure>
<figureCaption confidence="0.988498">
Figure 2: System Interface (Chinese example sentence: In 2010, Google company negotiated with the China gov-
ernment on the issue of results censoring, and eventually shut down the web search service.)
</figureCaption>
<page confidence="0.987894">
50
</page>
<sectionHeader confidence="0.995517" genericHeader="method">
3 System
</sectionHeader>
<bodyText confidence="0.999988266666667">
The proposed system includes three major com-
ponents: a syntactic parser, a semantic role la-
beler, and a concept formulation component. The
framework is shown in Figure 1. The input sen-
tence is first transformed into a syntactic parse
tree through a syntactical analysis step that al-
most all automatic semantic role labeling sys-
tems require (Johansson and Nugues 2008). Here
the Stanford parser (Klein and Manning 2003) is
utilized. Figure 2 shows the system interface.
The left part is the English system and the right
part is the Chinese system. After users input a
sentence, the system will automatically parse,
label semantic roles and report the related con-
cepts for it.
</bodyText>
<subsectionHeader confidence="0.998968">
3.1 Semantic Role Labeling
</subsectionHeader>
<bodyText confidence="0.999965696969697">
To develop a SRL system, a total of 33 features
including features related to the head word relat-
ed features, target word related features, gram-
mar related features, and semantic type related
features, are collected from related work (Xue,
2008; Ding and Chang, 2008; Sun and Jurafsky
2004; Gildea and Jurafsky 2002). Then the base-
line maximum entropy system is developed using
these features (Manning and Schutze, 1999).
Two sets of data – Chinese Treebank 5.0 together
with Propbank 1.0 and Chinese Treebank 6.0
with Propbank 2.0 – are separated into the train-
ing and testing sets, and are then used to build
models to identify and classify semantic labels,
and also to evaluate the performance, respective-
ly. As Chinese data was selected for experiments,
the hypernyms of words from E-Hownet1, a Chi-
nese word ontology, are utilized as the semantic
type of words. When applying the whole system
on data in other languages, for major languages it
is not difficult to find resources to obtain hyper-
nyms. For minor languages, it is fine to just ig-
nore these features. According to our experience,
this will yield F-Score reductions of only 1% to
2%.
We further exploit argument interdependence
to enhance performance by the dual-layer
framework shown in Figure 2. Suppose for any
given predicate P in a sentence, the system has
identified the three potential arguments A1, A2,
and A3 of the predicate. Next, to predict the se-
mantic role labels of those three arguments, a
critical observation made by (Jiang, Li, and Ng
</bodyText>
<footnote confidence="0.806337">
1 http://ckip.iis.sinica.edu.tw/CKIP/conceptnet.htm
</footnote>
<bodyText confidence="0.963937629629629">
2005) is that the semantic roles of arguments
may depend on each other; this phenomenon is
known as argument interdependence. A common
way to escape argument interdependence is to
adopt sequence labeling, and use the features
extracted from the arguments around the current
argument together with the features of the current
one to predict the label for the current argument.
For example, while predicting the label of argu-
ment A2, features extracted from arguments A1
and A3 are also used. Although window sizes
can be used to set the scope of this interdepend-
ence, the window-size strategy has some practi-
cal limits: the typically large feature set
necessitates the use of smaller window sizes (a
window size of [-1,1] is common). However,
small window sizes can make it impossible to
capture long dependency phenomena.
To overcome the limitations of the window-
size strategy, we use all the surrounding argu-
ments’ predicted labels – window size [-∞,∞],
as opposed to their features – to predict the label
of the current node. This also conforms to the
rule that when a role is taken by the other argu-
ment, it is less likely that the current argument is
of the same role. We implement this idea using
the dual-layer classification framework shown in
</bodyText>
<figureCaption confidence="0.975725">
Figure 3.
Figure 3: SRL classification framework.
</figureCaption>
<bodyText confidence="0.9998734">
In layer 1 the baseline system is used to pre-
dict the labels for identified nodes. Then in layer
2, these predicted labels of all surrounding argu-
ments (in this example, A1 and A3) together with
other features of the current node (A2) are used
</bodyText>
<figure confidence="0.996689692307692">
Layer 1
Layer 2
Label
prediction
Features
A1 A2 A3
Features +
predicted labels
Predicted label
Features
Label
prediction
Features
</figure>
<page confidence="0.992258">
51
</page>
<bodyText confidence="0.998129333333333">
to predict the label of the current node. Note as
this approach is under no window size limitation,
the labels of all arguments under the same predi-
cate are taken into account. Experimental resu lts
show that this strategy works better than the
window-size strategy. Table 1 shows the system
accuracies for the single- and dual-layer frame-
works. The predicted dual-layer framework uti-
lized the SRL labels predicted in layer 1, while
the gold dual-layer framework used as features
the gold SRL labels of the surrounding argu-
ments.
</bodyText>
<table confidence="0.998353">
System Accuracy
Ding and Chang, 2008 (state of the art) 94.68
Single-layer framework 94.60
Dual-layer framework (predicted) 94.86
Dual-layer framework (gold) 95.40
</table>
<tableCaption confidence="0.999923">
Table 1. Accuracy of SRL classification phase.
</tableCaption>
<bodyText confidence="0.998696333333333">
To further evaluate the performance of the
proposed system and offer comparisons, we ap-
plied it on Chinese Treebank 6.0 with Propbank
2.0 in the same way as in the CoNLL 2009 SRL-
only task data according to the information pro-
vided by the CoNLL organizers. Table 2 shows
the results of the proposed system. Table 3 fur-
ther shows the performance of the best systems
in CoNLL 2009.
</bodyText>
<table confidence="0.9969418">
Identification Classification SRL
Precision 94.38 90.22 86.89
Recall 96.24 80.11
F-Score 95.30 83.36
Accuracy 97.92 96.25
</table>
<tableCaption confidence="0.994246">
Table 2. SRL results on Propbank 2.0.
</tableCaption>
<table confidence="0.9999264">
System name Type Score
Nugus (Björkelund Closed chal- 78.50
et al., 2009) lenge, SRL-only (F-Score)
Meza-Ruiz Closed chal- 82.66
(Meza-Ruiz and lenge, SRL-only (Precision)
Riedel, 2009)
Täckström Closed chal- 79.31
(Täckström, 2009) lenge, SRL-only (Recall)
Che Open challenge, 76.42
(Che et al., 2009) Joint Task (F-Score)
</table>
<tableCaption confidence="0.999449">
Table 3. CoNLL 2009 SRL performance2.
</tableCaption>
<bodyText confidence="0.99992556">
The CoNLL 2009 task builds dependency-
based SRL systems, while the proposed system
works on the constituent-based parsing trees.
Also the settings of the proposed system are not
all the same as the CoNLL 2009 SRL systems. In
CoNLL 2009, as noted in Table 5, participants
can participate in open or closed challenges, and
can choose whether they want to attempt both
syntactic and semantic labeling tasks (joint task)
or only to attempt the SRL task. The setting of
the proposed system is open challenge, SRL-only,
while researchers working on the Chinese data
selected only two other different settings: closed
challenge, SRL only and open challenge, joint
task. However, Table 5 shows that the proposed
system outperforms the CoNLL 2009 best sys-
tems in terms of precision (86.89 vs. 82.66), re-
call (80.11 vs. 79.31), and f-score (83.36 vs.
78.50). Moreover, lately, dependency-based SRL
has shown advantages over constituent-based
SRL (Johansson and Nugues, 2008); thus we ex-
pect to show better results if working on depend-
ency-based parsed data. Therefore, we believe
the proposed system is comparable or even supe-
rior to other systems.
</bodyText>
<subsectionHeader confidence="0.999477">
3.2 Concept-Formulations
</subsectionHeader>
<bodyText confidence="0.99978948">
Once the sentence has been annotated seman-
tically, the concepts are formulated by concept
templates designed according to Propbank SRL
labels. Propbank provides semantic role labels of
two types. One type is numbered arguments
Arg0, Arg1, and so on until Arg5; the other type
is modifiers with function tags, which give addi-
tional information about when, where, or how the
event occurred. Tables 4 and 5 list the descrip-
tions of the Propbank arguments utilized for the
concept template generation. Table 6 then lists
the generated concept templates.
As shown in Table 6, the predicate and its ar-
guments are placed in various orders to build a
list of concepts according to their semantic roles.
These role combinations serve as templates
which can capture a complete and important
piece of information described in one sentence to
form a concept. Additionally, the arguments (i.e.,
the subjects and objects of the predicate) in
themselves can represent useful concepts, and for
this reason, the arguments alone are also includ-
ed in extracted concepts. For comparison, in Ta-
ble 7 the extracted concepts are listed with those
from the SenticNet concept parser.
</bodyText>
<footnote confidence="0.946588">
2 http://ufal.mff.cuni.cz/conll2009-st/results/results.php
</footnote>
<page confidence="0.99261">
52
</page>
<table confidence="0.9989135">
Numbered Description
Argument
Arg0 agent, causer, experiencer
Arg1 theme, patient
Arg2 instrument, benefactive, attribute
Arg3 starting point, benefactive, attribute
Arg4 ending point
Arg5 Direction
</table>
<tableCaption confidence="0.996414">
Table 4. Propbank numbered arguments.
</tableCaption>
<table confidence="0.999940454545455">
Modifier Desc Modifier Desc
ArgM- Location ArgM-COM Comitative
LOC
ArgM- Time ArgM-DIR Direction
TMP
ArgM- Goal ArgM-EXT Extent
GOL
ArgM- Manner ArgM-NEG Negation
MNR
ArgM- Cause ArgM-PRP Purpose
CAU
</table>
<tableCaption confidence="0.983708">
Table 5. Propbank modifier auguments.
</tableCaption>
<table confidence="0.999670473684211">
# Concept Template
1 ARG0 Pred
2 Pred ARG1
3 Pred_ARG1_ARG2
4 Pred_ARG1_ARG2_ARG3
5 Pred_ARG1_ARG2_ARG3_ARG4
6 Pred_ARG1_ARG2_ARG3_ARG4_ARG5
7 Pred_with_ARGM-COM
8 Pred_in_ARGM-LOC
9 Pred in order to ARGM-PRP
10 Pred in the direction ARGM-DIR
11 Pred because ARGM-CAU
12 Pred when ARGM-TMP
13 Pred ARGM-GOL
14 Pred by ARGM-EXT
15 Pred_ARGM-MNR
16 Pred_ARGM-NEG
17 ARGX’s
18 ARGM’s
</table>
<tableCaption confidence="0.712086">
Table 6. Concept templates.
</tableCaption>
<table confidence="0.999083333333333">
Proposed System
a_birthday_cake, bought_Super_Market,
bought_a_birthday_cake, Super_Market, celebrat-
ed_David’s_birthday, We_bought, David’s_birthday,
We celebrated
SenticNet Concept Parser
birthday_cake, birthday_from_market,
buy_birthday_cake, birthday_cake, birthday_david,
buy from market, super market, celebrate david
</table>
<tableCaption confidence="0.946033">
Table 7. Concepts generated by the proposed system
and the SenticNet Concept Parser.
</tableCaption>
<sectionHeader confidence="0.977894" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999967578947368">
We have presented a system to decompose a sen-
tence into a set of concepts through the proposed
well-performed semantic role labeling system
(http://doraemon.iis.sinica.edu.tw/srl-concept/),
which differs from previous related attempts. We
demonstrated that this dual-layer semantic role
labeling framework that exploits argument inter-
dependence performs slightly better than the
state of the art, and that it is relatively simple as
no feature selection or engineering processes are
required. We easily generated another English
system under the same framework, which show-
cased the language independency of the system.
In addition, it reached an F-Score 0.84, which
was considered satisfactory. In the future, we
plan to investigate how to further represent and
utilize these extracted concepts efficiently in
more NLP tasks which call for deep language
understanding.
</bodyText>
<sectionHeader confidence="0.979284" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.966143">
Research of this paper was partially supported by
National Science Council, Taiwan, under the
contract NSC101-2628-E-224-001-MY3.
</bodyText>
<sectionHeader confidence="0.997285" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99717348">
Björkelund, A., Hafdell, L., &amp; Nugues, P. 2009. Mul-
tilingual semantic role labeling. In Proceedings of
the Thirteenth Conference on Computational Natu-
ral Language Learning: Shared Task, 43-48.
Bonial, C.; Babko-Malaya, O.; Choi, J. D.; Hwang, J.;
and Palmer, M. 2010. Propbank annotation guide-
lines. Center for Computational Language and
Edu-cation Research Institute of Cognitive Science
Uni-versity of Colorad at Boulder.
Cambria, E.; Olsher, D.; and Rajagopal, D. 2014.
Senticnet 3: A common and common-sense
knowledge base for cognition-driven sentiment
anal-ysis. In Proceedings of AAAI, 1515–1521.
Che, W., Li, Z., Li, Y., Guo, Y., Qin, B., &amp; Liu, T.
2009. Multilingual dependency-based syntactic and
semantic parsing. In Proceedings of the Thirteenth
Conference on Computational Natural Language
Learning: Shared Task, 49-54.
Dinh, D., &amp; Tamine, L. 2011. Biomedical concept
extraction based on combining the content-based
and word order similarities. In Proceedings of the
2011 ACM Symposium on Applied Computing,
1159-1163. ACM.
Gelfand, B., Wulfekuler, M., &amp; Punch, W. F. 1998.
Automated concept extraction from plain text.
</reference>
<page confidence="0.994841">
53
</page>
<reference confidence="0.999101386138614">
In AAAI 1998 Workshop on Text Categoriza-
tion, 13-17.
Gildea, D., and Jurafsky, D. 2002. Automatic labeling
of semantic roles. Comput. Linguist. 28(3):245–
288.
Hovy, E., Kozareva, Z., &amp; Riloff, E. 2009. Toward
completeness in concept extraction and classifica-
tion. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Pro-
cessing: Volume 2-Volume 2, 948-957.
Huang, C. R., Chen, F. Y., Chen, K. J., Gao, Z. M., &amp;
Chen, K. Y. (2000, October). Sinica Treebank: de-
sign criteria, annotation guidelines, and on-line in-
terface. In Proceedings of the second workshop on
Chinese language processing: held in conjunction
with the 38th Annual Meeting of the Association
for Computational Linguistics-Volume 12, 29-37.
Jiang, Z. P.; Li, J.; and Ng, H. T. 2005. Semantic ar-
gu-ment classification exploiting argument inter-
depend-ence. In Proceedings of the 19th
International Joint Conference on Artificial Intelli-
gence, IJCAI’05, 1067–1072.
Johansson, R., &amp; Nugues, P. 2008. The effect of syn-
tactic representation on semantic role labeling. In
Proceedings of the 22nd International Conference
on Computational Linguistics-Volume 1, 393-400.
R. Johansson and P. Nugues. 2008. Dependency-
based semantic role labeling of PropBank. In Pro-
ceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing.
Jonnalagadda, S., Cohen, T., Wu, S., &amp; Gonzalez, G.
2012. Enhancing clinical concept extraction with
distributional semantics. Journal of biomedical in-
formatics, 45(1), 129-140.
Klein, D., and Manning, C. D. 2003. Accurate unlexi-
cal-ized parsing. In Proceedings of the 41st Annual
Meeting on Association for Computational Lin-
guis-tics - Volume 1, ACL ’03, 423–430.
D. Liu and D. Gildea. 2010. Semantic role features for
machine translation. In Proceedings of the 23rd In-
ternational Conference on Computational Linguis-
tics.
Liu, H., and Singh, P. 2004. Conceptnet: A practical
commonsense reasoning toolkit. BT
TECHNOLOGY JOURNAL 22:211–226.
Manning, Christopher D. and Schutze, Hinrich. 1999.
Foundations of statistical natural language pro-
cessing, Cambridge, Mass.: MIT Press.
Meza-Ruiz, I., &amp; Riedel, S. 2009. Multilingual se-
mantic role labelling with markov logic.
In Proceedings of the Thirteenth Conference on
Computational Natural Language Learning: Shared
Task, 85-90.
Park, K.-M., and Rim, H.-C. 2005. Maximum entropy
based semantic role labeling. In Proceedings of the
Ninth Conference on Computational Natural Lan-
guage Learning, CONLL ’05, 209–212.
Pradhan, S.; Ward, W.; Hacioglu, K.; and Martin, J. H.
2004. Shallow semantic parsing using support vec-
tor machines. In Proceedings of the Conference on
the Human Language Technologies and North
American Association for Computational Linguis-
tics (HLT-NAACL 2004), 233–240.
Rajagopal, D.; Cambria, E.; Olsher, D.; and Kwok, K.
2013. A graph-based approach to commonsense
concept extrac- tion and semantic similarity detec-
tion. In Proceedings of the 22Nd International Con-
ference on World Wide Web Companion,
WWW ’13 Companion, 565–570.
Ruppenhofer, J., Ellsworth, M., Petruck, M. R., John-
son, C. R., &amp; Scheffczyk, J. (2006). FrameNet II:
Extended theory and practice.
D. Shen and M. Lapata. 2007. Using semantic roles to
improve question answering. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing and on Computational Natural
Language Learning.
Täckström, O. 2009. Multilingual semantic parsing
with a pipeline of linear classifiers. In Proceedings
of the Thirteenth Conference on Computational
Natural Language Learning: Shared Task, 103-108.
Torii, M., Wagholikar, K., &amp; Liu, H. 2011. Using
machine learning for concept extraction on clinical
documents from multiple data sources. Journal of
the American Medical Informatics Association,
amiajnl-2011.
Villalon, J., &amp; Calvo, R. A. 2009. Concept extraction
from student essays, towards concept map mining.
In Proceedings of Ninth IEEE International Con-
ference on Advanced Learning Technologies, 221-
225.
Xue, N. 2004. Calibrating features for semantic role
labeling. In Proceedings of EMNLP 2004, 88–94.
Xue, N. 2008. Labeling chinese predicates with
seman-tic roles. Comput. Linguist. 34(2):225–255.
Zapirain, B.; Agirre, E.; and Màrquez, L. 2007. Ub-
cupc: Sequential srl using selectional preferences:
An approach with maximum entropy markov mod-
els. In Proceedings of the 4th International Work-
shop on Semantic Evaluations, SemEval ’07, 354–
357.
</reference>
<page confidence="0.999014">
54
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.082132">
<title confidence="0.999968">A Dual-Layer Semantic Role Labeling System</title>
<author confidence="0.999549">Lun-Wei Ku</author>
<affiliation confidence="0.998838">Institute of Information</affiliation>
<address confidence="0.498502">Academia Sinica, Taiwan</address>
<email confidence="0.974061">lwku@iis.sinica.edu.tw</email>
<author confidence="0.65584">Shafqat Mumtaz</author>
<affiliation confidence="0.7949665">Institute of Information Academia Sinica, Taiwan</affiliation>
<email confidence="0.998702">virk.shafqat@gmail.com</email>
<author confidence="0.834757">Yann-Huei</author>
<affiliation confidence="0.758308">Institute of Information Academia Sinica, Taiwan</affiliation>
<email confidence="0.998822">andycyrus.gmail.com</email>
<abstract confidence="0.996609130434783">We describe a well-performed semantic role labeling system that further extracts concepts (smaller semantic expressions) from unstructured natural language sentences language independently. A dual-layer semantic role labeling (SRL) system is built using Chinese Treebank and Propbank data. Contextual information is incorporated while labeling the predicate arguments to achieve better performance. Experimental results show that the proposed approach is superior to CoNLL 2009 best systems and comparable to the state of the art with the advantage that it requires no feature engineering process. Concepts are further extracted according to templates formulated by the labeled semantic roles to serve as features in other NLP tasks to provide semantically related cues and potentially help in related research problems. We also show that it is easy to generate a different language version of this system by actually building an English system which performs satisfactory.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Björkelund</author>
<author>L Hafdell</author>
<author>P Nugues</author>
</authors>
<title>Multilingual semantic role labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>43--48</pages>
<marker>Björkelund, Hafdell, Nugues, 2009</marker>
<rawString>Björkelund, A., Hafdell, L., &amp; Nugues, P. 2009. Multilingual semantic role labeling. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, 43-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bonial</author>
<author>O Babko-Malaya</author>
<author>J D Choi</author>
<author>J Hwang</author>
<author>M Palmer</author>
</authors>
<title>Propbank annotation guidelines.</title>
<date>2010</date>
<institution>Center for Computational Language and Edu-cation Research Institute of Cognitive Science Uni-versity of Colorad at Boulder.</institution>
<contexts>
<context position="1803" citStr="Bonial et al., 2010" startWordPosition="257" endWordPosition="260"> to generate a different language version of this system by actually building an English system which performs satisfactory. 1 Introduction Semantic roles are utilized to find concepts automatically and assure their meaningfulness. Semantic role labeling is a research problem which finds in a given sentence the predicates and their arguments (identification), and further labels the semantic relationship between predicates and arguments, that is, their semantic roles (classification). There are several labeling sets. Researchers have widely adopted the semantic role labels defined in Propbank (Bonial et al., 2010) like predicate (PRED), numbered arguments 0 to 5 (ARG0, ARG1, ARG2, ARG3, ARG4, ARG5), or modifier arguments (ARGM-X); finer labels are those defined in Sinica Treebank (Huang et al., 2000) like agent, theme, target, which are labeled on each node of the parse tree; those defined in FrameNet (Ruppenhofer et al., 2006) are the finest but most expressive. Each set provides semantic information. As long as the semantic relationship between terms derives from their semantic role labels, we are able to determine whether they should be extracted from the current sentence to construct a concept. The</context>
</contexts>
<marker>Bonial, Babko-Malaya, Choi, Hwang, Palmer, 2010</marker>
<rawString>Bonial, C.; Babko-Malaya, O.; Choi, J. D.; Hwang, J.; and Palmer, M. 2010. Propbank annotation guidelines. Center for Computational Language and Edu-cation Research Institute of Cognitive Science Uni-versity of Colorad at Boulder.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Cambria</author>
<author>D Olsher</author>
<author>D Rajagopal</author>
</authors>
<title>Senticnet 3: A common and common-sense knowledge base for cognition-driven sentiment anal-ysis.</title>
<date>2014</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>1515--1521</pages>
<marker>Cambria, Olsher, Rajagopal, 2014</marker>
<rawString>Cambria, E.; Olsher, D.; and Rajagopal, D. 2014. Senticnet 3: A common and common-sense knowledge base for cognition-driven sentiment anal-ysis. In Proceedings of AAAI, 1515–1521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Che</author>
<author>Z Li</author>
<author>Y Li</author>
<author>Y Guo</author>
<author>B Qin</author>
<author>T Liu</author>
</authors>
<title>Multilingual dependency-based syntactic and semantic parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="11691" citStr="Che et al., 2009" startWordPosition="1861" endWordPosition="1864">ovided by the CoNLL organizers. Table 2 shows the results of the proposed system. Table 3 further shows the performance of the best systems in CoNLL 2009. Identification Classification SRL Precision 94.38 90.22 86.89 Recall 96.24 80.11 F-Score 95.30 83.36 Accuracy 97.92 96.25 Table 2. SRL results on Propbank 2.0. System name Type Score Nugus (Björkelund Closed chal- 78.50 et al., 2009) lenge, SRL-only (F-Score) Meza-Ruiz Closed chal- 82.66 (Meza-Ruiz and lenge, SRL-only (Precision) Riedel, 2009) Täckström Closed chal- 79.31 (Täckström, 2009) lenge, SRL-only (Recall) Che Open challenge, 76.42 (Che et al., 2009) Joint Task (F-Score) Table 3. CoNLL 2009 SRL performance2. The CoNLL 2009 task builds dependencybased SRL systems, while the proposed system works on the constituent-based parsing trees. Also the settings of the proposed system are not all the same as the CoNLL 2009 SRL systems. In CoNLL 2009, as noted in Table 5, participants can participate in open or closed challenges, and can choose whether they want to attempt both syntactic and semantic labeling tasks (joint task) or only to attempt the SRL task. The setting of the proposed system is open challenge, SRL-only, while researchers working o</context>
</contexts>
<marker>Che, Li, Li, Guo, Qin, Liu, 2009</marker>
<rawString>Che, W., Li, Z., Li, Y., Guo, Y., Qin, B., &amp; Liu, T. 2009. Multilingual dependency-based syntactic and semantic parsing. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, 49-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Dinh</author>
<author>L Tamine</author>
</authors>
<title>Biomedical concept extraction based on combining the content-based and word order similarities.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 ACM Symposium on Applied Computing,</booktitle>
<pages>1159--1163</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="4656" citStr="Dinh and Tamine, 2011" startWordPosition="713" endWordPosition="716">LP 2015 System Demonstrations, pages 49–54, Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP (Zapirain, Agirre, and Màrquez 2007). Moreover, some researchers have tried to extend it in novel ways. For example, Ding and Chang (2008) used a hierarchical feature selection strategy, while Jiang, Li, and Ng (2005) proposed exploiting argument interdependence, that is, the fact that the semantic role of one argument can depend on the semantic roles of other arguments. Many researchers have tried to extract concepts from texts (Gelfand et al., 1998; Hovy et al., 2009; Villalon and Calvo, 2009; Dinh and Tamine, 2011; Torii et al., 2011). Hovy narrowed the domain of interest into concepts “below” a given seed term. Villalon and Calvo extract concepts from student essays for concept map mining, which generates a directed relational graph of the extracted concepts in an essay. For specific domains, biological or medical concepts are of greatest interest to researchers (Jonnalagadda et al., 2011). Two relatively new and related approaches are the Concept parser (Rajagopal et al. 2013), a part of the SenticNet project (Cambria, Olsher, and Rajagopal 2014) and ConceptNet (Liu and Singh 2004). The former is a t</context>
</contexts>
<marker>Dinh, Tamine, 2011</marker>
<rawString>Dinh, D., &amp; Tamine, L. 2011. Biomedical concept extraction based on combining the content-based and word order similarities. In Proceedings of the 2011 ACM Symposium on Applied Computing, 1159-1163. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Gelfand</author>
<author>M Wulfekuler</author>
<author>W F Punch</author>
</authors>
<title>Automated concept extraction from plain text.</title>
<date>1998</date>
<contexts>
<context position="4588" citStr="Gelfand et al., 1998" startWordPosition="701" endWordPosition="704">different ways to handle data sparseness 49 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 49–54, Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP (Zapirain, Agirre, and Màrquez 2007). Moreover, some researchers have tried to extend it in novel ways. For example, Ding and Chang (2008) used a hierarchical feature selection strategy, while Jiang, Li, and Ng (2005) proposed exploiting argument interdependence, that is, the fact that the semantic role of one argument can depend on the semantic roles of other arguments. Many researchers have tried to extract concepts from texts (Gelfand et al., 1998; Hovy et al., 2009; Villalon and Calvo, 2009; Dinh and Tamine, 2011; Torii et al., 2011). Hovy narrowed the domain of interest into concepts “below” a given seed term. Villalon and Calvo extract concepts from student essays for concept map mining, which generates a directed relational graph of the extracted concepts in an essay. For specific domains, biological or medical concepts are of greatest interest to researchers (Jonnalagadda et al., 2011). Two relatively new and related approaches are the Concept parser (Rajagopal et al. 2013), a part of the SenticNet project (Cambria, Olsher, and Ra</context>
</contexts>
<marker>Gelfand, Wulfekuler, Punch, 1998</marker>
<rawString>Gelfand, B., Wulfekuler, M., &amp; Punch, W. F. 1998. Automated concept extraction from plain text.</rawString>
</citation>
<citation valid="false">
<booktitle>In AAAI 1998 Workshop on Text Categorization,</booktitle>
<pages>13--17</pages>
<marker></marker>
<rawString>In AAAI 1998 Workshop on Text Categorization, 13-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Comput. Linguist.</journal>
<volume>28</volume>
<issue>3</issue>
<pages>288</pages>
<contexts>
<context position="3491" citStr="Gildea and Jurafsky 2002" startWordPosition="532" endWordPosition="535"> are tightly related to semantic roles. We propose a dual-layer semantic role labeling system which provides extracted concepts according to the reported labels, and then demonstrate the functions of this system. Experimental results will show the merit of the proposed framework. 2 Related Work Previous studies related to this work can be divided into two groups: semantic role labeling and concept extraction. Semantic role labeling (SRL) has sparked much interest in NLP (Shen and Lapata, 2007; Liu and Gildea, 2010). The first automatic SRL systems were reported by Gildea and Jurafsky in 2002 (Gildea and Jurafsky 2002); since then, their ideas have dominated the field. In their approach, they emphasize the selection of appropriate lexical and syntactical features for SRL, the use of statistical classifiers and their combinations, and ways to handle data sparseness. Many researchers have tried to build on their work by augmenting and/or altering the feature set (Xue 2004), by experimenting with various classification approaches (Pradhan et al. 2004; Park and Rim 2005), and by attempting different ways to handle data sparseness 49 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 49–54, Beijing, Chi</context>
<context position="7176" citStr="Gildea and Jurafsky 2002" startWordPosition="1120" endWordPosition="1123"> (Klein and Manning 2003) is utilized. Figure 2 shows the system interface. The left part is the English system and the right part is the Chinese system. After users input a sentence, the system will automatically parse, label semantic roles and report the related concepts for it. 3.1 Semantic Role Labeling To develop a SRL system, a total of 33 features including features related to the head word related features, target word related features, grammar related features, and semantic type related features, are collected from related work (Xue, 2008; Ding and Chang, 2008; Sun and Jurafsky 2004; Gildea and Jurafsky 2002). Then the baseline maximum entropy system is developed using these features (Manning and Schutze, 1999). Two sets of data – Chinese Treebank 5.0 together with Propbank 1.0 and Chinese Treebank 6.0 with Propbank 2.0 – are separated into the training and testing sets, and are then used to build models to identify and classify semantic labels, and also to evaluate the performance, respectively. As Chinese data was selected for experiments, the hypernyms of words from E-Hownet1, a Chinese word ontology, are utilized as the semantic type of words. When applying the whole system on data in other la</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Gildea, D., and Jurafsky, D. 2002. Automatic labeling of semantic roles. Comput. Linguist. 28(3):245– 288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
<author>Z Kozareva</author>
<author>E Riloff</author>
</authors>
<title>Toward completeness in concept extraction and classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>948--957</pages>
<contexts>
<context position="4607" citStr="Hovy et al., 2009" startWordPosition="705" endWordPosition="708">le data sparseness 49 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 49–54, Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP (Zapirain, Agirre, and Màrquez 2007). Moreover, some researchers have tried to extend it in novel ways. For example, Ding and Chang (2008) used a hierarchical feature selection strategy, while Jiang, Li, and Ng (2005) proposed exploiting argument interdependence, that is, the fact that the semantic role of one argument can depend on the semantic roles of other arguments. Many researchers have tried to extract concepts from texts (Gelfand et al., 1998; Hovy et al., 2009; Villalon and Calvo, 2009; Dinh and Tamine, 2011; Torii et al., 2011). Hovy narrowed the domain of interest into concepts “below” a given seed term. Villalon and Calvo extract concepts from student essays for concept map mining, which generates a directed relational graph of the extracted concepts in an essay. For specific domains, biological or medical concepts are of greatest interest to researchers (Jonnalagadda et al., 2011). Two relatively new and related approaches are the Concept parser (Rajagopal et al. 2013), a part of the SenticNet project (Cambria, Olsher, and Rajagopal 2014) and C</context>
</contexts>
<marker>Hovy, Kozareva, Riloff, 2009</marker>
<rawString>Hovy, E., Kozareva, Z., &amp; Riloff, E. 2009. Toward completeness in concept extraction and classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2, 948-957.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Huang</author>
<author>F Y Chen</author>
<author>K J Chen</author>
<author>Z M Gao</author>
<author>K Y Chen</author>
</authors>
<title>Sinica Treebank: design criteria, annotation guidelines, and on-line interface.</title>
<date>2000</date>
<booktitle>In Proceedings of the second workshop on Chinese language processing: held in conjunction with the 38th Annual Meeting of the Association for Computational Linguistics-Volume</booktitle>
<volume>12</volume>
<pages>29--37</pages>
<contexts>
<context position="1993" citStr="Huang et al., 2000" startWordPosition="289" endWordPosition="292">tically and assure their meaningfulness. Semantic role labeling is a research problem which finds in a given sentence the predicates and their arguments (identification), and further labels the semantic relationship between predicates and arguments, that is, their semantic roles (classification). There are several labeling sets. Researchers have widely adopted the semantic role labels defined in Propbank (Bonial et al., 2010) like predicate (PRED), numbered arguments 0 to 5 (ARG0, ARG1, ARG2, ARG3, ARG4, ARG5), or modifier arguments (ARGM-X); finer labels are those defined in Sinica Treebank (Huang et al., 2000) like agent, theme, target, which are labeled on each node of the parse tree; those defined in FrameNet (Ruppenhofer et al., 2006) are the finest but most expressive. Each set provides semantic information. As long as the semantic relationship between terms derives from their semantic role labels, we are able to determine whether they should be extracted from the current sentence to construct a concept. The word concept usually refers to an abstract or general idea inferred or derived from specific instances. Therefore, the extraction of concepts from text is often defined as extracting terms </context>
</contexts>
<marker>Huang, Chen, Chen, Gao, Chen, 2000</marker>
<rawString>Huang, C. R., Chen, F. Y., Chen, K. J., Gao, Z. M., &amp; Chen, K. Y. (2000, October). Sinica Treebank: design criteria, annotation guidelines, and on-line interface. In Proceedings of the second workshop on Chinese language processing: held in conjunction with the 38th Annual Meeting of the Association for Computational Linguistics-Volume 12, 29-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z P Jiang</author>
<author>J Li</author>
<author>H T Ng</author>
</authors>
<title>Semantic argu-ment classification exploiting argument interdepend-ence.</title>
<date>2005</date>
<booktitle>In Proceedings of the 19th International Joint Conference on Artificial Intelligence, IJCAI’05,</booktitle>
<pages>1067--1072</pages>
<marker>Jiang, Li, Ng, 2005</marker>
<rawString>Jiang, Z. P.; Li, J.; and Ng, H. T. 2005. Semantic argu-ment classification exploiting argument interdepend-ence. In Proceedings of the 19th International Joint Conference on Artificial Intelligence, IJCAI’05, 1067–1072.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Johansson</author>
<author>P Nugues</author>
</authors>
<title>The effect of syntactic representation on semantic role labeling.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics-Volume</booktitle>
<volume>1</volume>
<pages>393--400</pages>
<contexts>
<context position="6525" citStr="Johansson and Nugues 2008" startWordPosition="1012" endWordPosition="1015"> PropBank Concept Templates Concept Extraction Figure 2: System Interface (Chinese example sentence: In 2010, Google company negotiated with the China government on the issue of results censoring, and eventually shut down the web search service.) 50 3 System The proposed system includes three major components: a syntactic parser, a semantic role labeler, and a concept formulation component. The framework is shown in Figure 1. The input sentence is first transformed into a syntactic parse tree through a syntactical analysis step that almost all automatic semantic role labeling systems require (Johansson and Nugues 2008). Here the Stanford parser (Klein and Manning 2003) is utilized. Figure 2 shows the system interface. The left part is the English system and the right part is the Chinese system. After users input a sentence, the system will automatically parse, label semantic roles and report the related concepts for it. 3.1 Semantic Role Labeling To develop a SRL system, a total of 33 features including features related to the head word related features, target word related features, grammar related features, and semantic type related features, are collected from related work (Xue, 2008; Ding and Chang, 200</context>
<context position="12714" citStr="Johansson and Nugues, 2008" startWordPosition="2024" endWordPosition="2027">er they want to attempt both syntactic and semantic labeling tasks (joint task) or only to attempt the SRL task. The setting of the proposed system is open challenge, SRL-only, while researchers working on the Chinese data selected only two other different settings: closed challenge, SRL only and open challenge, joint task. However, Table 5 shows that the proposed system outperforms the CoNLL 2009 best systems in terms of precision (86.89 vs. 82.66), recall (80.11 vs. 79.31), and f-score (83.36 vs. 78.50). Moreover, lately, dependency-based SRL has shown advantages over constituent-based SRL (Johansson and Nugues, 2008); thus we expect to show better results if working on dependency-based parsed data. Therefore, we believe the proposed system is comparable or even superior to other systems. 3.2 Concept-Formulations Once the sentence has been annotated semantically, the concepts are formulated by concept templates designed according to Propbank SRL labels. Propbank provides semantic role labels of two types. One type is numbered arguments Arg0, Arg1, and so on until Arg5; the other type is modifiers with function tags, which give additional information about when, where, or how the event occurred. Tables 4 an</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Johansson, R., &amp; Nugues, P. 2008. The effect of syntactic representation on semantic role labeling. In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1, 393-400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Johansson</author>
<author>P Nugues</author>
</authors>
<title>Dependencybased semantic role labeling of PropBank.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="6525" citStr="Johansson and Nugues 2008" startWordPosition="1012" endWordPosition="1015"> PropBank Concept Templates Concept Extraction Figure 2: System Interface (Chinese example sentence: In 2010, Google company negotiated with the China government on the issue of results censoring, and eventually shut down the web search service.) 50 3 System The proposed system includes three major components: a syntactic parser, a semantic role labeler, and a concept formulation component. The framework is shown in Figure 1. The input sentence is first transformed into a syntactic parse tree through a syntactical analysis step that almost all automatic semantic role labeling systems require (Johansson and Nugues 2008). Here the Stanford parser (Klein and Manning 2003) is utilized. Figure 2 shows the system interface. The left part is the English system and the right part is the Chinese system. After users input a sentence, the system will automatically parse, label semantic roles and report the related concepts for it. 3.1 Semantic Role Labeling To develop a SRL system, a total of 33 features including features related to the head word related features, target word related features, grammar related features, and semantic type related features, are collected from related work (Xue, 2008; Ding and Chang, 200</context>
<context position="12714" citStr="Johansson and Nugues, 2008" startWordPosition="2024" endWordPosition="2027">er they want to attempt both syntactic and semantic labeling tasks (joint task) or only to attempt the SRL task. The setting of the proposed system is open challenge, SRL-only, while researchers working on the Chinese data selected only two other different settings: closed challenge, SRL only and open challenge, joint task. However, Table 5 shows that the proposed system outperforms the CoNLL 2009 best systems in terms of precision (86.89 vs. 82.66), recall (80.11 vs. 79.31), and f-score (83.36 vs. 78.50). Moreover, lately, dependency-based SRL has shown advantages over constituent-based SRL (Johansson and Nugues, 2008); thus we expect to show better results if working on dependency-based parsed data. Therefore, we believe the proposed system is comparable or even superior to other systems. 3.2 Concept-Formulations Once the sentence has been annotated semantically, the concepts are formulated by concept templates designed according to Propbank SRL labels. Propbank provides semantic role labels of two types. One type is numbered arguments Arg0, Arg1, and so on until Arg5; the other type is modifiers with function tags, which give additional information about when, where, or how the event occurred. Tables 4 an</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>R. Johansson and P. Nugues. 2008. Dependencybased semantic role labeling of PropBank. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Jonnalagadda</author>
<author>T Cohen</author>
<author>S Wu</author>
<author>G Gonzalez</author>
</authors>
<title>Enhancing clinical concept extraction with distributional semantics.</title>
<date>2012</date>
<journal>Journal of biomedical informatics,</journal>
<volume>45</volume>
<issue>1</issue>
<pages>129--140</pages>
<marker>Jonnalagadda, Cohen, Wu, Gonzalez, 2012</marker>
<rawString>Jonnalagadda, S., Cohen, T., Wu, S., &amp; Gonzalez, G. 2012. Enhancing clinical concept extraction with distributional semantics. Journal of biomedical informatics, 45(1), 129-140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Accurate unlexical-ized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguis-tics - Volume 1, ACL ’03,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="6576" citStr="Klein and Manning 2003" startWordPosition="1020" endWordPosition="1023">2: System Interface (Chinese example sentence: In 2010, Google company negotiated with the China government on the issue of results censoring, and eventually shut down the web search service.) 50 3 System The proposed system includes three major components: a syntactic parser, a semantic role labeler, and a concept formulation component. The framework is shown in Figure 1. The input sentence is first transformed into a syntactic parse tree through a syntactical analysis step that almost all automatic semantic role labeling systems require (Johansson and Nugues 2008). Here the Stanford parser (Klein and Manning 2003) is utilized. Figure 2 shows the system interface. The left part is the English system and the right part is the Chinese system. After users input a sentence, the system will automatically parse, label semantic roles and report the related concepts for it. 3.1 Semantic Role Labeling To develop a SRL system, a total of 33 features including features related to the head word related features, target word related features, grammar related features, and semantic type related features, are collected from related work (Xue, 2008; Ding and Chang, 2008; Sun and Jurafsky 2004; Gildea and Jurafsky 2002)</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, D., and Manning, C. D. 2003. Accurate unlexical-ized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguis-tics - Volume 1, ACL ’03, 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Liu</author>
<author>D Gildea</author>
</authors>
<title>Semantic role features for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="3386" citStr="Liu and Gildea, 2010" startWordPosition="515" endWordPosition="518">er, we view concepts as the continuous or discontinuous meaningful units in a sentence and hence they are tightly related to semantic roles. We propose a dual-layer semantic role labeling system which provides extracted concepts according to the reported labels, and then demonstrate the functions of this system. Experimental results will show the merit of the proposed framework. 2 Related Work Previous studies related to this work can be divided into two groups: semantic role labeling and concept extraction. Semantic role labeling (SRL) has sparked much interest in NLP (Shen and Lapata, 2007; Liu and Gildea, 2010). The first automatic SRL systems were reported by Gildea and Jurafsky in 2002 (Gildea and Jurafsky 2002); since then, their ideas have dominated the field. In their approach, they emphasize the selection of appropriate lexical and syntactical features for SRL, the use of statistical classifiers and their combinations, and ways to handle data sparseness. Many researchers have tried to build on their work by augmenting and/or altering the feature set (Xue 2004), by experimenting with various classification approaches (Pradhan et al. 2004; Park and Rim 2005), and by attempting different ways to </context>
</contexts>
<marker>Liu, Gildea, 2010</marker>
<rawString>D. Liu and D. Gildea. 2010. Semantic role features for machine translation. In Proceedings of the 23rd International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>P Singh</author>
</authors>
<title>Conceptnet: A practical commonsense reasoning toolkit.</title>
<date>2004</date>
<journal>BT TECHNOLOGY JOURNAL</journal>
<pages>22--211</pages>
<contexts>
<context position="5237" citStr="Liu and Singh 2004" startWordPosition="805" endWordPosition="808">and Calvo, 2009; Dinh and Tamine, 2011; Torii et al., 2011). Hovy narrowed the domain of interest into concepts “below” a given seed term. Villalon and Calvo extract concepts from student essays for concept map mining, which generates a directed relational graph of the extracted concepts in an essay. For specific domains, biological or medical concepts are of greatest interest to researchers (Jonnalagadda et al., 2011). Two relatively new and related approaches are the Concept parser (Rajagopal et al. 2013), a part of the SenticNet project (Cambria, Olsher, and Rajagopal 2014) and ConceptNet (Liu and Singh 2004). The former is a tool to decompose unrestricted natural language text to a bag of concepts, which is similar to our work. However, in the final phase a semantic knowledge base is used to express a concept in all its different forms and their concept-parser does not use any semantic knowledge during decomposition. The latter is a semantic network based on the Open Mind Common Sense (OMCS) knowledge base. As it is a knowledge base, its construction process is quite different from the work described here of automatically extracting concepts from sentences. Output: Concepts Figure 1: System Frame</context>
</contexts>
<marker>Liu, Singh, 2004</marker>
<rawString>Liu, H., and Singh, P. 2004. Conceptnet: A practical commonsense reasoning toolkit. BT TECHNOLOGY JOURNAL 22:211–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schutze</author>
</authors>
<title>Foundations of statistical natural language processing,</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="7280" citStr="Manning and Schutze, 1999" startWordPosition="1136" endWordPosition="1139">h system and the right part is the Chinese system. After users input a sentence, the system will automatically parse, label semantic roles and report the related concepts for it. 3.1 Semantic Role Labeling To develop a SRL system, a total of 33 features including features related to the head word related features, target word related features, grammar related features, and semantic type related features, are collected from related work (Xue, 2008; Ding and Chang, 2008; Sun and Jurafsky 2004; Gildea and Jurafsky 2002). Then the baseline maximum entropy system is developed using these features (Manning and Schutze, 1999). Two sets of data – Chinese Treebank 5.0 together with Propbank 1.0 and Chinese Treebank 6.0 with Propbank 2.0 – are separated into the training and testing sets, and are then used to build models to identify and classify semantic labels, and also to evaluate the performance, respectively. As Chinese data was selected for experiments, the hypernyms of words from E-Hownet1, a Chinese word ontology, are utilized as the semantic type of words. When applying the whole system on data in other languages, for major languages it is not difficult to find resources to obtain hypernyms. For minor langua</context>
</contexts>
<marker>Manning, Schutze, 1999</marker>
<rawString>Manning, Christopher D. and Schutze, Hinrich. 1999. Foundations of statistical natural language processing, Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Meza-Ruiz</author>
<author>S Riedel</author>
</authors>
<title>Multilingual semantic role labelling with markov logic.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>85--90</pages>
<marker>Meza-Ruiz, Riedel, 2009</marker>
<rawString>Meza-Ruiz, I., &amp; Riedel, S. 2009. Multilingual semantic role labelling with markov logic. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, 85-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-M Park</author>
<author>H-C Rim</author>
</authors>
<title>Maximum entropy based semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning, CONLL ’05,</booktitle>
<pages>209--212</pages>
<contexts>
<context position="3948" citStr="Park and Rim 2005" startWordPosition="603" endWordPosition="606">est in NLP (Shen and Lapata, 2007; Liu and Gildea, 2010). The first automatic SRL systems were reported by Gildea and Jurafsky in 2002 (Gildea and Jurafsky 2002); since then, their ideas have dominated the field. In their approach, they emphasize the selection of appropriate lexical and syntactical features for SRL, the use of statistical classifiers and their combinations, and ways to handle data sparseness. Many researchers have tried to build on their work by augmenting and/or altering the feature set (Xue 2004), by experimenting with various classification approaches (Pradhan et al. 2004; Park and Rim 2005), and by attempting different ways to handle data sparseness 49 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 49–54, Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP (Zapirain, Agirre, and Màrquez 2007). Moreover, some researchers have tried to extend it in novel ways. For example, Ding and Chang (2008) used a hierarchical feature selection strategy, while Jiang, Li, and Ng (2005) proposed exploiting argument interdependence, that is, the fact that the semantic role of one argument can depend on the semantic roles of other arguments. Many researchers have tried to extract c</context>
</contexts>
<marker>Park, Rim, 2005</marker>
<rawString>Park, K.-M., and Rim, H.-C. 2005. Maximum entropy based semantic role labeling. In Proceedings of the Ninth Conference on Computational Natural Language Learning, CONLL ’05, 209–212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>W Ward</author>
<author>K Hacioglu</author>
<author>J H Martin</author>
</authors>
<title>Shallow semantic parsing using support vector machines.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on the Human Language Technologies and North American Association for Computational Linguistics (HLT-NAACL 2004),</booktitle>
<pages>233--240</pages>
<contexts>
<context position="3928" citStr="Pradhan et al. 2004" startWordPosition="599" endWordPosition="602">as sparked much interest in NLP (Shen and Lapata, 2007; Liu and Gildea, 2010). The first automatic SRL systems were reported by Gildea and Jurafsky in 2002 (Gildea and Jurafsky 2002); since then, their ideas have dominated the field. In their approach, they emphasize the selection of appropriate lexical and syntactical features for SRL, the use of statistical classifiers and their combinations, and ways to handle data sparseness. Many researchers have tried to build on their work by augmenting and/or altering the feature set (Xue 2004), by experimenting with various classification approaches (Pradhan et al. 2004; Park and Rim 2005), and by attempting different ways to handle data sparseness 49 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 49–54, Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP (Zapirain, Agirre, and Màrquez 2007). Moreover, some researchers have tried to extend it in novel ways. For example, Ding and Chang (2008) used a hierarchical feature selection strategy, while Jiang, Li, and Ng (2005) proposed exploiting argument interdependence, that is, the fact that the semantic role of one argument can depend on the semantic roles of other arguments. Many researchers hav</context>
</contexts>
<marker>Pradhan, Ward, Hacioglu, Martin, 2004</marker>
<rawString>Pradhan, S.; Ward, W.; Hacioglu, K.; and Martin, J. H. 2004. Shallow semantic parsing using support vector machines. In Proceedings of the Conference on the Human Language Technologies and North American Association for Computational Linguistics (HLT-NAACL 2004), 233–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Rajagopal</author>
<author>E Cambria</author>
<author>D Olsher</author>
<author>K Kwok</author>
</authors>
<title>A graph-based approach to commonsense concept extrac- tion and semantic similarity detection.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22Nd International Conference on World Wide Web Companion, WWW ’13 Companion,</booktitle>
<pages>565--570</pages>
<contexts>
<context position="5130" citStr="Rajagopal et al. 2013" startWordPosition="788" endWordPosition="791">Many researchers have tried to extract concepts from texts (Gelfand et al., 1998; Hovy et al., 2009; Villalon and Calvo, 2009; Dinh and Tamine, 2011; Torii et al., 2011). Hovy narrowed the domain of interest into concepts “below” a given seed term. Villalon and Calvo extract concepts from student essays for concept map mining, which generates a directed relational graph of the extracted concepts in an essay. For specific domains, biological or medical concepts are of greatest interest to researchers (Jonnalagadda et al., 2011). Two relatively new and related approaches are the Concept parser (Rajagopal et al. 2013), a part of the SenticNet project (Cambria, Olsher, and Rajagopal 2014) and ConceptNet (Liu and Singh 2004). The former is a tool to decompose unrestricted natural language text to a bag of concepts, which is similar to our work. However, in the final phase a semantic knowledge base is used to express a concept in all its different forms and their concept-parser does not use any semantic knowledge during decomposition. The latter is a semantic network based on the Open Mind Common Sense (OMCS) knowledge base. As it is a knowledge base, its construction process is quite different from the work </context>
</contexts>
<marker>Rajagopal, Cambria, Olsher, Kwok, 2013</marker>
<rawString>Rajagopal, D.; Cambria, E.; Olsher, D.; and Kwok, K. 2013. A graph-based approach to commonsense concept extrac- tion and semantic similarity detection. In Proceedings of the 22Nd International Conference on World Wide Web Companion, WWW ’13 Companion, 565–570.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ruppenhofer</author>
<author>M Ellsworth</author>
<author>M R Petruck</author>
<author>C R Johnson</author>
<author>J Scheffczyk</author>
</authors>
<title>FrameNet II: Extended theory and practice.</title>
<date>2006</date>
<contexts>
<context position="2123" citStr="Ruppenhofer et al., 2006" startWordPosition="311" endWordPosition="314">edicates and their arguments (identification), and further labels the semantic relationship between predicates and arguments, that is, their semantic roles (classification). There are several labeling sets. Researchers have widely adopted the semantic role labels defined in Propbank (Bonial et al., 2010) like predicate (PRED), numbered arguments 0 to 5 (ARG0, ARG1, ARG2, ARG3, ARG4, ARG5), or modifier arguments (ARGM-X); finer labels are those defined in Sinica Treebank (Huang et al., 2000) like agent, theme, target, which are labeled on each node of the parse tree; those defined in FrameNet (Ruppenhofer et al., 2006) are the finest but most expressive. Each set provides semantic information. As long as the semantic relationship between terms derives from their semantic role labels, we are able to determine whether they should be extracted from the current sentence to construct a concept. The word concept usually refers to an abstract or general idea inferred or derived from specific instances. Therefore, the extraction of concepts from text is often defined as extracting terms that are in some way related to one another. These terms could be predefined by people in resources such as ontologies, or they co</context>
</contexts>
<marker>Ruppenhofer, Ellsworth, Petruck, Johnson, Scheffczyk, 2006</marker>
<rawString>Ruppenhofer, J., Ellsworth, M., Petruck, M. R., Johnson, C. R., &amp; Scheffczyk, J. (2006). FrameNet II: Extended theory and practice.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Shen</author>
<author>M Lapata</author>
</authors>
<title>Using semantic roles to improve question answering.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing and on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="3363" citStr="Shen and Lapata, 2007" startWordPosition="511" endWordPosition="514">s in texts. In this paper, we view concepts as the continuous or discontinuous meaningful units in a sentence and hence they are tightly related to semantic roles. We propose a dual-layer semantic role labeling system which provides extracted concepts according to the reported labels, and then demonstrate the functions of this system. Experimental results will show the merit of the proposed framework. 2 Related Work Previous studies related to this work can be divided into two groups: semantic role labeling and concept extraction. Semantic role labeling (SRL) has sparked much interest in NLP (Shen and Lapata, 2007; Liu and Gildea, 2010). The first automatic SRL systems were reported by Gildea and Jurafsky in 2002 (Gildea and Jurafsky 2002); since then, their ideas have dominated the field. In their approach, they emphasize the selection of appropriate lexical and syntactical features for SRL, the use of statistical classifiers and their combinations, and ways to handle data sparseness. Many researchers have tried to build on their work by augmenting and/or altering the feature set (Xue 2004), by experimenting with various classification approaches (Pradhan et al. 2004; Park and Rim 2005), and by attemp</context>
</contexts>
<marker>Shen, Lapata, 2007</marker>
<rawString>D. Shen and M. Lapata. 2007. Using semantic roles to improve question answering. In Proceedings of the Conference on Empirical Methods in Natural Language Processing and on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Täckström</author>
</authors>
<title>Multilingual semantic parsing with a pipeline of linear classifiers.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>103--108</pages>
<contexts>
<context position="11621" citStr="Täckström, 2009" startWordPosition="1852" endWordPosition="1853">s in the CoNLL 2009 SRLonly task data according to the information provided by the CoNLL organizers. Table 2 shows the results of the proposed system. Table 3 further shows the performance of the best systems in CoNLL 2009. Identification Classification SRL Precision 94.38 90.22 86.89 Recall 96.24 80.11 F-Score 95.30 83.36 Accuracy 97.92 96.25 Table 2. SRL results on Propbank 2.0. System name Type Score Nugus (Björkelund Closed chal- 78.50 et al., 2009) lenge, SRL-only (F-Score) Meza-Ruiz Closed chal- 82.66 (Meza-Ruiz and lenge, SRL-only (Precision) Riedel, 2009) Täckström Closed chal- 79.31 (Täckström, 2009) lenge, SRL-only (Recall) Che Open challenge, 76.42 (Che et al., 2009) Joint Task (F-Score) Table 3. CoNLL 2009 SRL performance2. The CoNLL 2009 task builds dependencybased SRL systems, while the proposed system works on the constituent-based parsing trees. Also the settings of the proposed system are not all the same as the CoNLL 2009 SRL systems. In CoNLL 2009, as noted in Table 5, participants can participate in open or closed challenges, and can choose whether they want to attempt both syntactic and semantic labeling tasks (joint task) or only to attempt the SRL task. The setting of the pr</context>
</contexts>
<marker>Täckström, 2009</marker>
<rawString>Täckström, O. 2009. Multilingual semantic parsing with a pipeline of linear classifiers. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, 103-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Torii</author>
<author>K Wagholikar</author>
<author>H Liu</author>
</authors>
<title>Using machine learning for concept extraction on clinical documents from multiple data sources.</title>
<date>2011</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<pages>2011</pages>
<contexts>
<context position="4677" citStr="Torii et al., 2011" startWordPosition="717" endWordPosition="720">ations, pages 49–54, Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP (Zapirain, Agirre, and Màrquez 2007). Moreover, some researchers have tried to extend it in novel ways. For example, Ding and Chang (2008) used a hierarchical feature selection strategy, while Jiang, Li, and Ng (2005) proposed exploiting argument interdependence, that is, the fact that the semantic role of one argument can depend on the semantic roles of other arguments. Many researchers have tried to extract concepts from texts (Gelfand et al., 1998; Hovy et al., 2009; Villalon and Calvo, 2009; Dinh and Tamine, 2011; Torii et al., 2011). Hovy narrowed the domain of interest into concepts “below” a given seed term. Villalon and Calvo extract concepts from student essays for concept map mining, which generates a directed relational graph of the extracted concepts in an essay. For specific domains, biological or medical concepts are of greatest interest to researchers (Jonnalagadda et al., 2011). Two relatively new and related approaches are the Concept parser (Rajagopal et al. 2013), a part of the SenticNet project (Cambria, Olsher, and Rajagopal 2014) and ConceptNet (Liu and Singh 2004). The former is a tool to decompose unre</context>
</contexts>
<marker>Torii, Wagholikar, Liu, 2011</marker>
<rawString>Torii, M., Wagholikar, K., &amp; Liu, H. 2011. Using machine learning for concept extraction on clinical documents from multiple data sources. Journal of the American Medical Informatics Association, amiajnl-2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Villalon</author>
<author>R A Calvo</author>
</authors>
<title>Concept extraction from student essays, towards concept map mining.</title>
<date>2009</date>
<booktitle>In Proceedings of Ninth IEEE International Conference on Advanced Learning Technologies,</booktitle>
<pages>221--225</pages>
<contexts>
<context position="4633" citStr="Villalon and Calvo, 2009" startWordPosition="709" endWordPosition="712">49 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 49–54, Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP (Zapirain, Agirre, and Màrquez 2007). Moreover, some researchers have tried to extend it in novel ways. For example, Ding and Chang (2008) used a hierarchical feature selection strategy, while Jiang, Li, and Ng (2005) proposed exploiting argument interdependence, that is, the fact that the semantic role of one argument can depend on the semantic roles of other arguments. Many researchers have tried to extract concepts from texts (Gelfand et al., 1998; Hovy et al., 2009; Villalon and Calvo, 2009; Dinh and Tamine, 2011; Torii et al., 2011). Hovy narrowed the domain of interest into concepts “below” a given seed term. Villalon and Calvo extract concepts from student essays for concept map mining, which generates a directed relational graph of the extracted concepts in an essay. For specific domains, biological or medical concepts are of greatest interest to researchers (Jonnalagadda et al., 2011). Two relatively new and related approaches are the Concept parser (Rajagopal et al. 2013), a part of the SenticNet project (Cambria, Olsher, and Rajagopal 2014) and ConceptNet (Liu and Singh 2</context>
</contexts>
<marker>Villalon, Calvo, 2009</marker>
<rawString>Villalon, J., &amp; Calvo, R. A. 2009. Concept extraction from student essays, towards concept map mining. In Proceedings of Ninth IEEE International Conference on Advanced Learning Technologies, 221-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
</authors>
<title>Calibrating features for semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP 2004,</booktitle>
<pages>88--94</pages>
<contexts>
<context position="3850" citStr="Xue 2004" startWordPosition="590" endWordPosition="591">role labeling and concept extraction. Semantic role labeling (SRL) has sparked much interest in NLP (Shen and Lapata, 2007; Liu and Gildea, 2010). The first automatic SRL systems were reported by Gildea and Jurafsky in 2002 (Gildea and Jurafsky 2002); since then, their ideas have dominated the field. In their approach, they emphasize the selection of appropriate lexical and syntactical features for SRL, the use of statistical classifiers and their combinations, and ways to handle data sparseness. Many researchers have tried to build on their work by augmenting and/or altering the feature set (Xue 2004), by experimenting with various classification approaches (Pradhan et al. 2004; Park and Rim 2005), and by attempting different ways to handle data sparseness 49 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 49–54, Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP (Zapirain, Agirre, and Màrquez 2007). Moreover, some researchers have tried to extend it in novel ways. For example, Ding and Chang (2008) used a hierarchical feature selection strategy, while Jiang, Li, and Ng (2005) proposed exploiting argument interdependence, that is, the fact that the semantic role of one argu</context>
</contexts>
<marker>Xue, 2004</marker>
<rawString>Xue, N. 2004. Calibrating features for semantic role labeling. In Proceedings of EMNLP 2004, 88–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
</authors>
<title>Labeling chinese predicates with seman-tic roles.</title>
<date>2008</date>
<journal>Comput. Linguist.</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="7104" citStr="Xue, 2008" startWordPosition="1110" endWordPosition="1111">re (Johansson and Nugues 2008). Here the Stanford parser (Klein and Manning 2003) is utilized. Figure 2 shows the system interface. The left part is the English system and the right part is the Chinese system. After users input a sentence, the system will automatically parse, label semantic roles and report the related concepts for it. 3.1 Semantic Role Labeling To develop a SRL system, a total of 33 features including features related to the head word related features, target word related features, grammar related features, and semantic type related features, are collected from related work (Xue, 2008; Ding and Chang, 2008; Sun and Jurafsky 2004; Gildea and Jurafsky 2002). Then the baseline maximum entropy system is developed using these features (Manning and Schutze, 1999). Two sets of data – Chinese Treebank 5.0 together with Propbank 1.0 and Chinese Treebank 6.0 with Propbank 2.0 – are separated into the training and testing sets, and are then used to build models to identify and classify semantic labels, and also to evaluate the performance, respectively. As Chinese data was selected for experiments, the hypernyms of words from E-Hownet1, a Chinese word ontology, are utilized as the se</context>
</contexts>
<marker>Xue, 2008</marker>
<rawString>Xue, N. 2008. Labeling chinese predicates with seman-tic roles. Comput. Linguist. 34(2):225–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Zapirain</author>
<author>E Agirre</author>
<author>L Màrquez</author>
</authors>
<title>Ubcupc: Sequential srl using selectional preferences: An approach with maximum entropy markov models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07,</booktitle>
<pages>354--357</pages>
<marker>Zapirain, Agirre, Màrquez, 2007</marker>
<rawString>Zapirain, B.; Agirre, E.; and Màrquez, L. 2007. Ubcupc: Sequential srl using selectional preferences: An approach with maximum entropy markov models. In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07, 354– 357.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>