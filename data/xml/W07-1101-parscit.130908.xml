<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002039">
<title confidence="0.9995805">
A Measure of Syntactic Flexibility for Automatically Identifying Multiword
Expressions in Corpora
</title>
<author confidence="0.985576">
Colin Bannard
</author>
<affiliation confidence="0.883784">
Department of Developmental and Comparative Psychology
Max Planck Institute for Evolutionary Anthropology
</affiliation>
<address confidence="0.6050415">
Deutscher Platz 6
D-04103 Leipzig
</address>
<email confidence="0.975003">
colin.bannard@eva.mpg.de
</email>
<sectionHeader confidence="0.981823" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99992725">
Natural languages contain many multi-word
sequences that do not display the variety of
syntactic processes we would expect given
their phrase type, and consequently must be
included in the lexicon as multiword units.
This paper describes a method for identify-
ing such items in corpora, focussing on En-
glish verb-noun combinations. In an eval-
uation using a set of dictionary-published
MWEs we show that our method achieves
greater accuracy than existing MWE extrac-
tion methods based on lexical association.
</bodyText>
<sectionHeader confidence="0.995155" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981673076923">
A multi-word expression (henceforth MWE) is usu-
ally taken to be any word combination (adjacent or
otherwise) that has some feature (syntactic, semantic
or purely statistical) that cannot be predicted on the
basis of its component words and/or the combinato-
rial processes of the language. Such units need to be
included in any language description that hopes to
account for actual usage. Lexicographers (for both
printed dictionaries and NLP systems) therefore re-
quire well-motivated ways of automatically identi-
fying units of interest. The work described in this
paper is a contribution to this task.
Many linguists have offered classification
schemes for MWEs. While these accounts vary in
their terminology, they mostly focus on three differ-
ent phenomena: collocation, non-compositionality
and syntactic fixedness. In computational linguis-
tics, a great deal of work has been done on the
extraction of collocations in the last decade and
a half (see Pecina (2005) for a survey). There
have also been a number of papers focusing on the
detection of semantic non-compositional items in
recent years beginning with the work of Schone
and Jurafsky (2001). The task of identifying
syntactically-fixed phrases, however, has been much
less explored. This third variety is the focus of
the present paper. Languages contain many word
combinations that do not allow the variation we
would expect based solely on their grammatical
form. In the most extreme case there are many
phrases which seem to allow no syntactic variation
whatsoever. These include phrases such as by
and large and in short, which do not allow any
morphological variation (*in shortest) or internal
modification (*by and pretty large). We focus here
on phrases that allow some syntactic variation, but
do not allow other kinds.
The small amount of previous work on the iden-
tification of syntactic fixedness (Wermter and Hahn
(2004), Fazly and Stevenson (2006)) has either fo-
cused on a single variation variety, or has only been
evaluated for combinations of a small preselected
list of words, presumably due to noise. In this pa-
per we employ a syntactic parser, thus allowing us
to include a wider range of syntactic features in our
model. Furthermore we describe a statistical mea-
sure of variation that is robust enough to be freely
evaluated over the full set of possible word combi-
nations found in the corpus.
The remainder of our paper will be structured as
follows. Section 2 will discuss the kinds of fixedness
that we observe in our target phrase variety. Sec-
</bodyText>
<note confidence="0.828355333333333">
1
Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 1–8,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999515">
tion 3 will describe our model. Section 4 will eval-
uate the performance of the method and compare it
to some other methods that have been described in
the literature. Section 5 will describe some previous
work on the problem, and section 6 will review our
findings.
</bodyText>
<sectionHeader confidence="0.6069985" genericHeader="method">
2 Syntactic Fixedness in English Verb
Phrases
</sectionHeader>
<bodyText confidence="0.999307823529412">
The experiments described here deal with one par-
ticular variety of phrase: English verb phrases of the
form verb plus noun (e.g. walk the dog, pull teeth,
take a leaflet). In a survey of the idiomatic phrases
listed in the Collins Cobuild Dictionary of Idioms,
Villavicencio and Copestake (2002) found this kind
of idiom to account for more of the entries than any
other. Riehemann (2001) performed a manual cor-
pus analysis of verb and noun phrase idioms found
in the Collins Cobuild Dictionary of Idioms. She
found considerable fixedness with some phrases al-
lowing no variation at all.
Based on this literature we identified three im-
portant kinds of non-morphological variation that
such phrases can undergo, and which crucially have
been observed to be restricted for particular combi-
nations. These are as follows:
</bodyText>
<listItem confidence="0.998877916666666">
• Variation, addition or dropping of a determiner
so that, for example, run the show becomes run
their show, make waves becomes make more
waves, or strike a chord becomes strike chord
respectively.
• Modification of the noun phrase so that, for ex-
ample, break the ice becomes break the diplo-
matic ice. We refer to this as internal modifica-
tion.
• The verb phrase passivises so that, for example,
call the shots is realised as the shots were called
by.
</listItem>
<sectionHeader confidence="0.995586" genericHeader="method">
3 Our Model
</sectionHeader>
<bodyText confidence="0.999976226415095">
We use the written component of the BNC to make
observations about the extent to which these varia-
tions are permitted by particular verb-noun combi-
nations. In order to do this we need some way to
a) identify such combinations, and b) identify when
they are displaying a syntactic variation. In order to
do both of these we utilise a syntactic parser.
We parse our corpus using the RASP system
(Briscoe and Carroll, 2002). The system contains
a LR probabilistic parser, based on a tag-sequence
grammar. It is particularly suited to this task be-
cause unlike many contemporary parsers, it makes
use of no significant information about the probabil-
ity of seeing relationships between particular lexical
items. Since we are looking here for cases where
the syntactic behaviour of particular word combina-
tions deviates from general grammatical patterns, it
is desirable that the analysis we use has not already
factored in lexical information. Example output can
be seen in figure 1. We extract all verb and nouns
pairs connected by an object relation in the parsed
corpus. We are interested here in the object relation-
ship between buy and apartment, and we can use the
output to identify the variations that this phrase dis-
plays.
The first thing to note is that the phrase is pas-
sivised. Apartment is described as an object of buy
by the “obj” relation that appears at the end of the
line. Because of the passivisation, apartment is also
described as a non-clausal subject of buy by the “nc-
mod” relation that appears at the beginning of the
line. This presence of a semantic object that appears
as a surface subject tells us that we are a dealing
with a passive. The “ncmod” relation tells us that
the adjective largest is a modifier of apartment. And
finally, the “detmod” relation tells us that the is a de-
terminer attached to apartment. We make a count
over the whole corpus of the number of times each
verb-object pair occurs, and the number of times it
occurs with each relation of interest.
For passivisation and internal modification, a vari-
ation is simply the presence of a particular grammat-
ical relation. The addition, dropping or variation of
a determiner is not so straightforward. We are inter-
ested in the frequency with which each phrase varies
from its dominant determiner status. We need there-
fore to determine what this dominant status is for
each item. A verb and noun object pair where the
noun has no determiner relation is recorded as hav-
ing no determiner. This is one potential determiner
status. The other varieties of status are defined by
the kind of determiner that is appended. The RASP
parser uses the very rich CLAWS-2 tagset. We con-
</bodyText>
<equation confidence="0.993125444444444">
2
(|ncsubj ||buy+ed:6_VVN ||apartment:3_NN1 ||obj|)
(|arg_mod ||by:7_II ||buy+ed:6_VVN ||couple:10_NN1 ||subj|)
(|ncmod |_ |apartment:3_NN1 ||largest:2_JJT|)
(|detmod |_ |apartment:3_NN1 ||The:1_AT|)
(|ncmod |_ |couple:10_NN1 ||Swedish:9_JJ|)
(|detmod |_ |couple:10_NN1 ||a:8_AT1|)
(|mod |_ |buy+ed:6_VVN ||immediately:5_RR|)
(|aux |_ |buy+ed:6_VVN ||be+ed:4_VBDZ|)
</equation>
<figureCaption confidence="0.985588">
Figure 1: RASP parse of sentence The largest apartment was immediately bought by a Swedish couple.
</figureCaption>
<bodyText confidence="0.999912">
sider each of these tags as a different determiner sta-
tus. Once the determiner status of all occurrences
has been recorded, the dominant status for each item
is taken to be the status that occurs most frequently.
The number of variations is taken to be the number
of times that the phrase occurs with any other status.
</bodyText>
<subsectionHeader confidence="0.99982">
3.1 Quantifying variation
</subsectionHeader>
<bodyText confidence="0.999695580645162">
We are interested here in measuring the degree of
syntactic variation allowed by each verb-object pair
found in our corpus. Firstly we use the counts that
we extracted above to estimate the probability of
each variation for each combination, employing a
Laplace estimator to deal with zero counts.
A straightforward product of these probabilities
would give us the probability of free variation for a
given verb-object pair. We need, however, to con-
sider the fact that each phrase has a prior probability
of variation derived from the probability of variation
of the component words. Take passivisation for ex-
ample. Some verbs are more prone to passivisation
than others. The degree of passivisation of a phrase
will therefore depend to a large extent upon the pas-
sivisation habits of the component verb.
What we want is an estimate of the extent to
which the probability of variation for that combi-
nation deviates from the variation we would expect
based on the variation we observe for its component
words. For this we use conditional pointwise mu-
tual information. Each kind of variation is associ-
ated with a single component word. Passivisation is
associated with the verb. Internal modification and
determiner variation are associated with the object.
We calculate the mutual information of the syntactic
variation x and the word y given the word z, as seen
in equation 1. In the case of passivisation z will be
the verb and y will be the object. In the case of inter-
nal modification and determiner variation z will be
the object.
</bodyText>
<equation confidence="0.9983684">
I(x; y|z) = H(x|z) − H(x|y, z) (1)
= − lo92 p(x|z) − [−1o92 p(x|y, z)1
= − lo92 p(x|z) + 1o92 p(x|y,z)
= lo92p(x|y, z)
p(x|z)
</equation>
<bodyText confidence="0.9999937">
Conditional pointwise mutual information tells us
the amount of information in bits that y provides
about x (and vice versa) given z (see e.g. MacKay
(2003)). If a variation occurs for a given word pair
with greater likelihood than we would expect based
on the frequency of seeing that same variation with
the relevant component word, then the mutual infor-
mation will be high. We want to find the informa-
tion that is gained about all the syntactic variations
by a particular verb and object combination. We
therefore calculate the information gained about all
the verb-relevant syntactic variations (passivisation)
by the addition of the object, and the information
gained about all the object relevant variations (inter-
nal modification and determiner dropping, variation
or addition) by the addition of the verb. Summing
these, as in equation 2 then gives us the total infor-
mation gained about syntactic variation for the word
pair W, and we take this as our measure of the degree
of syntactic flexibility for this pair.
</bodyText>
<equation confidence="0.919097428571429">
n
SynV ar(W)= I(V erbV ari; Obj|V erb) (2)
i
n
+ I(ObjV arj;V erb|Obj)
j
3
</equation>
<sectionHeader confidence="0.994909" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999884709090909">
This paper aims to provide a method for highlight-
ing those verb plus noun phrases that are syntacti-
cally fixed and consequently need to be included in
the lexicon. This is intended as a tool for lexicog-
raphers. We hypothesize that in a list that has been
inversely ranked with the variability measure valid
MWEs will occur at the top.
The evaluation procedure used here (first sug-
gested by Evert and Krenn (2001) for evaluating
measures of lexical association) involves producing
and evaluating just such a ranking. The RASP parser
identifies 979,156 unique verb-noun pairs in the
BNC. The measure of syntactic flexibility was used
to inverse rank these items (the most fixed first).1
This ranking was then evaluated using a list of id-
ioms taken from published dictionaries, by observ-
ing how many of the gold standard items were found
in each top n, and calculating the accuracy score.
2 By reason of the diverse nature of MWEs, these
lists can be expected to contain many MWEs that are
not syntactically fixed, giving us a very low upper
bound. However this seems to us the evaluation that
best reflects the application for which the measure is
designed. The list of gold standard idioms we used
were taken from the Longman Dictionary of English
idioms (Long and Summers, 1979) and the SAID
Syntactically Annotated Idiom Dataset (Kuiper et
al., 2003). Combining the two dictionaries gave us
a list of 1109 unique verb-noun pairs, 914 of which
were identified in the BNC.
In order to evaluate the performance of our tech-
nique it will be useful to compare its results with the
ranks of scores that can be obtained by other means.
A simple method of sorting items available to the
corpus lexicographer that might expected to give
reasonable performance is item frequency. We take
this as our baseline. In the introduction we referred
to multiple varieties of MWE. One such variety is
the collocation. Although the collocation is a dif-
ferent variety of MWE, any dictionary will contain
collocations as well as syntactically fixed phrases.
1Any ties were dealt with by generating a random number
for each item and ranking the drawn items using this.
2Note that because the number of candidate items in each
sample is fixed, the relative performance of any two methods
will be the same for recall as it is for precision. In such circum-
stances the term accuracy is preferred.
The collocation has received more attention than
any other variety of MWE and it will therefore be
useful to compare our measure with these methods
as state-of-the-art extraction techniques. We report
the performance obtained when we rank our candi-
date items using all four collocation extraction tech-
niques described in Manning and Schutze (1999) :
t-score, mutual information, log likelihood and x2.
</bodyText>
<subsectionHeader confidence="0.504149">
4.1 Results
</subsectionHeader>
<bodyText confidence="0.999906052631579">
Figure 2 provides a plot of the accuracy score each
sample obtains when evaluated using the superset of
the two dictionaries for all samples from n = 1 to n
= 5,000.
Included in figure 2 are the scores obtained when
we inverse ranked using the variation score for each
individual feature, calculated with equation 1. There
is notable divergence in the performance of the dif-
ferent features. The best performing feature is pas-
sivisation, followed by internal modification. Deter-
miner variation performs notably worse for all val-
ues of n.
We next wanted to look at combinations of these
features using equation 2. We saw that the various
syntactic variations achieved very different scores
when used in isolation, and it was by no means cer-
tain that combining all features would the best ap-
proach. Nonetheless we found that the best scores
were achieved by combining all three - an accuracy
of 18%, 14.2 and 5.86% for n of 100, 1000 and 5000
respectively. This can be see in figure 2. The results
achieved with frequency ranking can also be seen in
the plot.
The accuracy achieved by the four collocation
measures can be seen plotted in figure 3. The best
performers are the t-score and the log-likelihood ra-
tio, with MI and x-squared performing much worse.
The best score for low values of n is t-score, with
log-likelihood overtaking for larger values. The best
performing collocation measures often give a perfor-
mance that is only equal to and often worse than raw
frequency. This is consistent with results reported
by Evert and Krenn (2001). Our best syntactic vari-
ation method outperforms all the collocation extrac-
tion techniques.
We can see, then, that our method is outperform-
ing frequency ranking and the various collocation
measures in terms of accuracy. A major claim we
</bodyText>
<figure confidence="0.990290625">
4
25
20
15
10
5
0
0 1000
</figure>
<figureCaption confidence="0.999547">
Figure 2: Accuracy by sample size for syntactic variation measures
</figureCaption>
<bodyText confidence="0.999917704545454">
are making for the method however is that it ex-
tracts a different kind of phrase. A close examina-
tion tells us that this is the case. Table 1 lists the
top 25 verb-noun combinations extracted using our
best performing combination of features, and those
extracted using frequency ranking. As can be see
there is no overlap between these lists. In the top 50
items there is an overlap of 3 between the two lists.
Over the top 100 items of the two lists there is only
an overlap of 6 items and over the top 1000 there is
an overlap of only 98.
This small overlap compares favourably with that
found for the collocation scores. While they pro-
duce ranks that are different from pure frequency,
the collocation measures are still based on relative
frequencies. The two high-performing collocation
measures, t-score and log-likelihood have overlap
with frequency of 795 and 624 out of 1000 respec-
tively. This tells us that the collocation measures
are significantly duplicating the information avail-
able from frequency ranking. The item overlap be-
tween t-score items and those extracted using the
the best-performing syntactic variation measure is
116. The overlap between syntactic variation and
log-likelihood items is 108. This smallCoverlap tells
us that our measure is extracting very different items
from the collocation measures.
Given that our measure appears to be pinpoint-
ing a different selection of items from those high-
lighted by frequency ranking or lexical association,
we next want looked at combining the two sources
of information. We test this by ranking our candi-
date list using frequency and using the most consis-
tently well-performing syntactic variation measure
in two separate runs, and then adding together the
two ranks achieved using the two methods for each
item. The items are then reranked using the result-
ing sums. When this ranking is evaluated against the
dictionaries it gives the scores plotted in figure 3 - a
clearly better performance than syntactic fixedness
or frequency alone for samples of 1000 and above.
Having reported all scores we now want to mea-
sure whether any of them are beating frequency
ranking at a level that is statistically significant.
</bodyText>
<figure confidence="0.9974787">
Y
5
25
20
15
10
5
0
&amp;quot;
0 2000
</figure>
<figureCaption confidence="0.999813">
Figure 3: Accuracy by sample size for lexical association measures
</figureCaption>
<bodyText confidence="0.999939744186046">
In order to do this we pick three values of n
(100,1000 and 5000) and examine whether the ac-
curacy achieved by our method are greater than
those achieved with frequency ranking at a level
that is significantly greater than chance. Conven-
tional significance testing is problematic for this
task. Rather than using a significance test that relies
upon an assumed distribution, then, we will use a
computationally-intensive randomization test of sig-
nificance called stratified shuffling. This technique
works by estimating the difference that might occur
between scores by chance through a simulation (see
(Cohen, 1995) for details). As is standard we per-
form 10,000 shuffle iterations.
The results for our three chosen values of n can
be seen in table 2. We accept any result of p &lt; 0.05
as significant, and scores that achieve this level of
significance are shown in bold. As an additional
check on performance we also extend our evalua-
tion. In any evaluation against a gold standard re-
source, there is a risk that the performance of a tech-
nique is particular to the lexical resource used and
will not generalise. For this reason we will here re-
port results achieved using not only the combined set
but also each dictionary in isolation. If the technique
is effective then we would expect it to perform well
for both resources.
We can see that our syntactic variation measures
perform equal to or better than frequency over both
dictionaries in isolation for samples of 1000 and
5000. The good performance against two data sets
tells us that the performance does generalise beyond
a single resource. For the Longman dictionary, the
accuracy achieved by the syntactic variation mea-
sure employing the three best performing features
(“P, I and D”) is significantly higher (at a level of p
&lt; 0.05) than that achieved when ranking with fre-
quency for sample sizes of 1000 and 5000. The
ranking achieved using the combination of syntac-
tic fixedness and frequency information produces a
result that is significant over all items for samples of
1000 and 5000. By contrast, none of the collocation
scores perform significantly better than frequency. 3
</bodyText>
<footnote confidence="0.352756">
3As very low frequency items have been observed to cause
</footnote>
<table confidence="0.92502775">
h
6
Syntactic Variation Collocation
DICTIONARY Freq P,I &amp;D P,I,D &amp;Freq t MI LLR x2
Top 100 items
LONGMANS 14 21 15 16 0 13 0
SAID 21 17 17 23 0 17 0
BOTH 28 18 25 32 0 25 0
Top 1000 items
LONGMANS 6.6 10.4 10.2 6.3 0 6.5 0.3
SAID 9.1 9 9.9 9 0 8.1 0.2
BOTH 12.2 14.2 15.2 12 0 11.4 0.4
Top 5000 items
LONGMANS 3.24 4.28 4.84 3.12 0.06 3.44 0.58
SAID 3.86 3.56 4.54 3.68 0.04 3.86 0.54
BOTH 5.56 5.86 7.68 5.34 0.04 5.66 0.88
</table>
<tableCaption confidence="0.992126">
Table 2: Accuracy for top 100, 1000 and 5000 items (scores beating frequency at p &lt; 0.05 are in bold)
</tableCaption>
<bodyText confidence="0.9999375">
An important issue for future research is how
much the performance of our measure is affected
by the technology used. In an evalutaion of RASP,
Preiss (2003) reports an precision of 85.83 and recall
of 78.48 for the direct object relation, 69.45/57.72
for the “ncmod” relation, and 91.15/98.77 for the
“detmod” relation. There is clearly some variance
here, but it is not easy to see any straightforward re-
lationship with our results. The highest performance
relation (“detmod”) was our least informative fea-
ture. Meanwhile our other two features both rely on
the ”ncmod” relation. One way to address this issue
in future research will be to replicate using multiple
parsers.
</bodyText>
<sectionHeader confidence="0.999282" genericHeader="method">
5 Previous work
</sectionHeader>
<bodyText confidence="0.999835452380952">
Wermter and Hahn (2004) explore one kind of
syntactic fixedness: the (non-)modifiability of
preposition-noun-verb combinations in German.
They extract all preposition-noun-verb combina-
tions from a corpus of German news text, and iden-
tify all the supplementary lexical information that
occurs between the preposition and the verb. For
each phrase they calculate the probability of seeing
each piece of supplementary material, and take this
as its degree of fixedness. A final score is then cal-
culated by taking the product of this score and the
problems for collocation measures, we experimented with vari-
ous cutoffs up to an occurence rate of 5. We found that this did
not lead to any significant difference from frequency.
probability of occurrence of the phrase. They then
manually evaluated how many true MWEs occurred
in the top n items at various values of n. Like us
they report that their measure outperformed t-score,
log likelihood ratio and frequency.
Fazly and Stevenson (2006) propose a measure
for detecting the syntactic fixedness of English verb
phrases of the same variety as us. They use a set of
regular patterns to identify, for particular word com-
binations (including one of a chosen set of 28 fre-
quent ”basic” verbs), the probability of occurrence
in passive voice, with particular determiners and in
plural form. They then calculate the relative en-
tropy of this probability distribution for the particu-
lar word pair and the probabilities observed over all
the word combinations. As we pointed out in section
3.1 a comparison with all verbs is problematic as
each verb will have its own probability of variation,
and this perhaps explains their focus on a small set
of verbs. They use a development set to establish a
threshold on what constitutes relative fixedness and
calculate the accuracy. This threshhold gives over
the set of 200 items, half of which were found in
a dictionary and hence considered MWEs and half
weren’t. They report an accuracy of 70%, against a
50% baseline. While this is promising, their use of a
small selection of items of a particular kind in their
evaluation makes it somewhat difficult to assess.
</bodyText>
<page confidence="0.946427">
7
</page>
<table confidence="0.999780038461539">
FREQUENCY P,I &amp; D
1 take place follow suit
2 have effect draw level
3 shake head give rise
4 have time part company
5 take part see chapter
6 do thing give moment
7 make decision open fire
8 have idea run counter
9 play role take refuge
10 play part clear throat
11 open door speak volume
12 do job please contact
13 do work leave net
14 make sense give way
15 have chance see page
16 make use catch sight
17 ask question cite argument
18 spend time see table
19 take care check watch
20 have problem list engagement
21 take step go bust
22 take time change subject
23 take action change hand
24 find way keep pace
25 have power see paragraph
</table>
<tableCaption confidence="0.999741">
Table 1: Top 25 phrases
</tableCaption>
<sectionHeader confidence="0.997065" genericHeader="discussions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999911333333333">
Any lexicon must contain multiword units as well
as individual words. The linguistic literature con-
tains claims for the inclusion of multiword items
in the lexicon on the basis of a number of linguis-
tic dimensions. One of these is syntactic fixedness.
This paper has shown that by quantifying the syntac-
tic fixedness of verb-noun phrases we can identify a
gold standard set of dictionary MWEs with a greater
accuracy than the lexical association measures that
have hitherto dominated the literature, and that, per-
haps more crucially, we can identify a different set of
expressions, not available using existing techniques.
</bodyText>
<sectionHeader confidence="0.998176" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<reference confidence="0.8197526">
Thanks to Tim Baldwin, Francis Bond, Ted Briscoe,
Chris Callison-Burch, Mirella Lapata, Alex Las-
carides, Andrew Smith, Takaaki Tanaka and two
anonymous reviewers for helpful ideas and com-
ments.
</reference>
<sectionHeader confidence="0.827949" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999859210526316">
Ted Briscoe and John Carroll. 2002. Robust accurate
statistical annotation of general text. In Proceedings
of LREC-2003.
P. Cohen. 1995. Empirical Methods forArtificial Intelli-
gence. MIT Press.
Stefan Evert and Brigitte Krenn. 2001. Methods for the
qualitative evaluation of lexical association measures.
In Proceedings of ACL-2001.
Afsaneh Fazly and Suzanne Stevenson. 2006. Automat-
ically constructing a lexicon of verb phrase idiomatic
combinations. In Proceedings of EACL-2006.
Koenraad Kuiper, Heather McCann, and Heidi Quinn.
2003. A syntactically annotated idiom database (said),
v,1.
Thomas H. Long and Della Summers. 1979. Longman
Dictionary of English Idioms. Longman Dictionaries.
David J.C. MacKay. 2003. Information Theory, Infer-
ence and Learning Algorithms. Cambridge University
Press.
C. Manning and H. Schutze. 1999. Foundations of
Statistical Natural Language Processing. MIT Press,
Cambridge, USA.
Pavel Pecina. 2005. An extensive empirical study of
collocation extraction methods. In Proceedings of the
ACL-2005 Student Research Workshop.
Judita Preiss. 2003. Using grammatical relations to com-
pare parsers. In Proceedings of EACL-03.
Suzanne Riehemann. 2001. A Constructional Approach
to Idioms and Word Formation. Ph.D. thesis, Stanford
University.
Patrick Schone and Dan Jurafsky. 2001. Is knowledge-
free induction of multiword unit dictionary headwords
a solved problem? In Proceedings of EMNLP-2001.
Aline Villavicencio and Ann Copestake. 2002. On the
nature of idioms. LinGO Working Paper No. 2002-04.
Joachim Wermter and Udo Hahn. 2004. Collocation ex-
traction based on modifiability statistics. In Proceed-
ings of COLING-2004.
</reference>
<page confidence="0.929598">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.289766">
<title confidence="0.9930885">A Measure of Syntactic Flexibility for Automatically Identifying Multiword Expressions in Corpora</title>
<author confidence="0.904494">Colin</author>
<affiliation confidence="0.896197">Department of Developmental and Comparative</affiliation>
<author confidence="0.8605765">Max Planck Institute for Evolutionary Deutscher Platz</author>
<address confidence="0.497549">D-04103</address>
<email confidence="0.989128">colin.bannard@eva.mpg.de</email>
<abstract confidence="0.997544076923077">Natural languages contain many multi-word sequences that do not display the variety of syntactic processes we would expect given their phrase type, and consequently must be included in the lexicon as multiword units. This paper describes a method for identifying such items in corpora, focussing on English verb-noun combinations. In an evaluation using a set of dictionary-published MWEs we show that our method achieves greater accuracy than existing MWE extraction methods based on lexical association.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Thanks to Tim Baldwin</author>
<author>Francis Bond</author>
<author>Ted Briscoe</author>
</authors>
<institution>Chris Callison-Burch, Mirella Lapata, Alex Las-</institution>
<marker>Baldwin, Bond, Briscoe, </marker>
<rawString>Thanks to Tim Baldwin, Francis Bond, Ted Briscoe, Chris Callison-Burch, Mirella Lapata, Alex Las-</rawString>
</citation>
<citation valid="false">
<authors>
<author>Andrew Smith carides</author>
</authors>
<title>Takaaki Tanaka and two anonymous reviewers for helpful ideas and comments.</title>
<marker>carides, </marker>
<rawString>carides, Andrew Smith, Takaaki Tanaka and two anonymous reviewers for helpful ideas and comments.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Robust accurate statistical annotation of general text.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC-2003.</booktitle>
<contexts>
<context position="5508" citStr="Briscoe and Carroll, 2002" startWordPosition="888" endWordPosition="891">k the ice becomes break the diplomatic ice. We refer to this as internal modification. • The verb phrase passivises so that, for example, call the shots is realised as the shots were called by. 3 Our Model We use the written component of the BNC to make observations about the extent to which these variations are permitted by particular verb-noun combinations. In order to do this we need some way to a) identify such combinations, and b) identify when they are displaying a syntactic variation. In order to do both of these we utilise a syntactic parser. We parse our corpus using the RASP system (Briscoe and Carroll, 2002). The system contains a LR probabilistic parser, based on a tag-sequence grammar. It is particularly suited to this task because unlike many contemporary parsers, it makes use of no significant information about the probability of seeing relationships between particular lexical items. Since we are looking here for cases where the syntactic behaviour of particular word combinations deviates from general grammatical patterns, it is desirable that the analysis we use has not already factored in lexical information. Example output can be seen in figure 1. We extract all verb and nouns pairs connec</context>
</contexts>
<marker>Briscoe, Carroll, 2002</marker>
<rawString>Ted Briscoe and John Carroll. 2002. Robust accurate statistical annotation of general text. In Proceedings of LREC-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cohen</author>
</authors>
<title>Empirical Methods forArtificial Intelligence.</title>
<date>1995</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="18882" citStr="Cohen, 1995" startWordPosition="3127" endWordPosition="3128">rder to do this we pick three values of n (100,1000 and 5000) and examine whether the accuracy achieved by our method are greater than those achieved with frequency ranking at a level that is significantly greater than chance. Conventional significance testing is problematic for this task. Rather than using a significance test that relies upon an assumed distribution, then, we will use a computationally-intensive randomization test of significance called stratified shuffling. This technique works by estimating the difference that might occur between scores by chance through a simulation (see (Cohen, 1995) for details). As is standard we perform 10,000 shuffle iterations. The results for our three chosen values of n can be seen in table 2. We accept any result of p &lt; 0.05 as significant, and scores that achieve this level of significance are shown in bold. As an additional check on performance we also extend our evaluation. In any evaluation against a gold standard resource, there is a risk that the performance of a technique is particular to the lexical resource used and will not generalise. For this reason we will here report results achieved using not only the combined set but also each dict</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>P. Cohen. 1995. Empirical Methods forArtificial Intelligence. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Brigitte Krenn</author>
</authors>
<title>Methods for the qualitative evaluation of lexical association measures.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL-2001.</booktitle>
<contexts>
<context position="11738" citStr="Evert and Krenn (2001)" startWordPosition="1927" endWordPosition="1930">ctic variation for the word pair W, and we take this as our measure of the degree of syntactic flexibility for this pair. n SynV ar(W)= I(V erbV ari; Obj|V erb) (2) i n + I(ObjV arj;V erb|Obj) j 3 4 Evaluation This paper aims to provide a method for highlighting those verb plus noun phrases that are syntactically fixed and consequently need to be included in the lexicon. This is intended as a tool for lexicographers. We hypothesize that in a list that has been inversely ranked with the variability measure valid MWEs will occur at the top. The evaluation procedure used here (first suggested by Evert and Krenn (2001) for evaluating measures of lexical association) involves producing and evaluating just such a ranking. The RASP parser identifies 979,156 unique verb-noun pairs in the BNC. The measure of syntactic flexibility was used to inverse rank these items (the most fixed first).1 This ranking was then evaluated using a list of idioms taken from published dictionaries, by observing how many of the gold standard items were found in each top n, and calculating the accuracy score. 2 By reason of the diverse nature of MWEs, these lists can be expected to contain many MWEs that are not syntactically fixed, </context>
<context position="15653" citStr="Evert and Krenn (2001)" startWordPosition="2589" endWordPosition="2592">100, 1000 and 5000 respectively. This can be see in figure 2. The results achieved with frequency ranking can also be seen in the plot. The accuracy achieved by the four collocation measures can be seen plotted in figure 3. The best performers are the t-score and the log-likelihood ratio, with MI and x-squared performing much worse. The best score for low values of n is t-score, with log-likelihood overtaking for larger values. The best performing collocation measures often give a performance that is only equal to and often worse than raw frequency. This is consistent with results reported by Evert and Krenn (2001). Our best syntactic variation method outperforms all the collocation extraction techniques. We can see, then, that our method is outperforming frequency ranking and the various collocation measures in terms of accuracy. A major claim we 4 25 20 15 10 5 0 0 1000 Figure 2: Accuracy by sample size for syntactic variation measures are making for the method however is that it extracts a different kind of phrase. A close examination tells us that this is the case. Table 1 lists the top 25 verb-noun combinations extracted using our best performing combination of features, and those extracted using f</context>
</contexts>
<marker>Evert, Krenn, 2001</marker>
<rawString>Stefan Evert and Brigitte Krenn. 2001. Methods for the qualitative evaluation of lexical association measures. In Proceedings of ACL-2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatically constructing a lexicon of verb phrase idiomatic combinations.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL-2006.</booktitle>
<contexts>
<context position="2728" citStr="Fazly and Stevenson (2006)" startWordPosition="413" endWordPosition="416">r. Languages contain many word combinations that do not allow the variation we would expect based solely on their grammatical form. In the most extreme case there are many phrases which seem to allow no syntactic variation whatsoever. These include phrases such as by and large and in short, which do not allow any morphological variation (*in shortest) or internal modification (*by and pretty large). We focus here on phrases that allow some syntactic variation, but do not allow other kinds. The small amount of previous work on the identification of syntactic fixedness (Wermter and Hahn (2004), Fazly and Stevenson (2006)) has either focused on a single variation variety, or has only been evaluated for combinations of a small preselected list of words, presumably due to noise. In this paper we employ a syntactic parser, thus allowing us to include a wider range of syntactic features in our model. Furthermore we describe a statistical measure of variation that is robust enough to be freely evaluated over the full set of possible word combinations found in the corpus. The remainder of our paper will be structured as follows. Section 2 will discuss the kinds of fixedness that we observe in our target phrase varie</context>
<context position="22671" citStr="Fazly and Stevenson (2006)" startWordPosition="3783" endWordPosition="3786">he probability of seeing each piece of supplementary material, and take this as its degree of fixedness. A final score is then calculated by taking the product of this score and the problems for collocation measures, we experimented with various cutoffs up to an occurence rate of 5. We found that this did not lead to any significant difference from frequency. probability of occurrence of the phrase. They then manually evaluated how many true MWEs occurred in the top n items at various values of n. Like us they report that their measure outperformed t-score, log likelihood ratio and frequency. Fazly and Stevenson (2006) propose a measure for detecting the syntactic fixedness of English verb phrases of the same variety as us. They use a set of regular patterns to identify, for particular word combinations (including one of a chosen set of 28 frequent ”basic” verbs), the probability of occurrence in passive voice, with particular determiners and in plural form. They then calculate the relative entropy of this probability distribution for the particular word pair and the probabilities observed over all the word combinations. As we pointed out in section 3.1 a comparison with all verbs is problematic as each ver</context>
</contexts>
<marker>Fazly, Stevenson, 2006</marker>
<rawString>Afsaneh Fazly and Suzanne Stevenson. 2006. Automatically constructing a lexicon of verb phrase idiomatic combinations. In Proceedings of EACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koenraad Kuiper</author>
<author>Heather McCann</author>
<author>Heidi Quinn</author>
</authors>
<title>A syntactically annotated idiom database (said),</title>
<date>2003</date>
<pages>1</pages>
<contexts>
<context position="12677" citStr="Kuiper et al., 2003" startWordPosition="2084" endWordPosition="2087">f idioms taken from published dictionaries, by observing how many of the gold standard items were found in each top n, and calculating the accuracy score. 2 By reason of the diverse nature of MWEs, these lists can be expected to contain many MWEs that are not syntactically fixed, giving us a very low upper bound. However this seems to us the evaluation that best reflects the application for which the measure is designed. The list of gold standard idioms we used were taken from the Longman Dictionary of English idioms (Long and Summers, 1979) and the SAID Syntactically Annotated Idiom Dataset (Kuiper et al., 2003). Combining the two dictionaries gave us a list of 1109 unique verb-noun pairs, 914 of which were identified in the BNC. In order to evaluate the performance of our technique it will be useful to compare its results with the ranks of scores that can be obtained by other means. A simple method of sorting items available to the corpus lexicographer that might expected to give reasonable performance is item frequency. We take this as our baseline. In the introduction we referred to multiple varieties of MWE. One such variety is the collocation. Although the collocation is a different variety of M</context>
</contexts>
<marker>Kuiper, McCann, Quinn, 2003</marker>
<rawString>Koenraad Kuiper, Heather McCann, and Heidi Quinn. 2003. A syntactically annotated idiom database (said), v,1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas H Long</author>
<author>Della Summers</author>
</authors>
<title>Longman Dictionary of English Idioms. Longman Dictionaries.</title>
<date>1979</date>
<contexts>
<context position="12604" citStr="Long and Summers, 1979" startWordPosition="2073" endWordPosition="2076">tems (the most fixed first).1 This ranking was then evaluated using a list of idioms taken from published dictionaries, by observing how many of the gold standard items were found in each top n, and calculating the accuracy score. 2 By reason of the diverse nature of MWEs, these lists can be expected to contain many MWEs that are not syntactically fixed, giving us a very low upper bound. However this seems to us the evaluation that best reflects the application for which the measure is designed. The list of gold standard idioms we used were taken from the Longman Dictionary of English idioms (Long and Summers, 1979) and the SAID Syntactically Annotated Idiom Dataset (Kuiper et al., 2003). Combining the two dictionaries gave us a list of 1109 unique verb-noun pairs, 914 of which were identified in the BNC. In order to evaluate the performance of our technique it will be useful to compare its results with the ranks of scores that can be obtained by other means. A simple method of sorting items available to the corpus lexicographer that might expected to give reasonable performance is item frequency. We take this as our baseline. In the introduction we referred to multiple varieties of MWE. One such variety</context>
</contexts>
<marker>Long, Summers, 1979</marker>
<rawString>Thomas H. Long and Della Summers. 1979. Longman Dictionary of English Idioms. Longman Dictionaries.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J C MacKay</author>
</authors>
<title>Information Theory, Inference and Learning Algorithms.</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="10372" citStr="MacKay (2003)" startWordPosition="1695" endWordPosition="1696">eterminer variation are associated with the object. We calculate the mutual information of the syntactic variation x and the word y given the word z, as seen in equation 1. In the case of passivisation z will be the verb and y will be the object. In the case of internal modification and determiner variation z will be the object. I(x; y|z) = H(x|z) − H(x|y, z) (1) = − lo92 p(x|z) − [−1o92 p(x|y, z)1 = − lo92 p(x|z) + 1o92 p(x|y,z) = lo92p(x|y, z) p(x|z) Conditional pointwise mutual information tells us the amount of information in bits that y provides about x (and vice versa) given z (see e.g. MacKay (2003)). If a variation occurs for a given word pair with greater likelihood than we would expect based on the frequency of seeing that same variation with the relevant component word, then the mutual information will be high. We want to find the information that is gained about all the syntactic variations by a particular verb and object combination. We therefore calculate the information gained about all the verb-relevant syntactic variations (passivisation) by the addition of the object, and the information gained about all the object relevant variations (internal modification and determiner drop</context>
</contexts>
<marker>MacKay, 2003</marker>
<rawString>David J.C. MacKay. 2003. Information Theory, Inference and Learning Algorithms. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Manning</author>
<author>H Schutze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, USA.</location>
<contexts>
<context position="14043" citStr="Manning and Schutze (1999)" startWordPosition="2313" endWordPosition="2316"> for each item and ranking the drawn items using this. 2Note that because the number of candidate items in each sample is fixed, the relative performance of any two methods will be the same for recall as it is for precision. In such circumstances the term accuracy is preferred. The collocation has received more attention than any other variety of MWE and it will therefore be useful to compare our measure with these methods as state-of-the-art extraction techniques. We report the performance obtained when we rank our candidate items using all four collocation extraction techniques described in Manning and Schutze (1999) : t-score, mutual information, log likelihood and x2. 4.1 Results Figure 2 provides a plot of the accuracy score each sample obtains when evaluated using the superset of the two dictionaries for all samples from n = 1 to n = 5,000. Included in figure 2 are the scores obtained when we inverse ranked using the variation score for each individual feature, calculated with equation 1. There is notable divergence in the performance of the different features. The best performing feature is passivisation, followed by internal modification. Determiner variation performs notably worse for all values of</context>
</contexts>
<marker>Manning, Schutze, 1999</marker>
<rawString>C. Manning and H. Schutze. 1999. Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Pecina</author>
</authors>
<title>An extensive empirical study of collocation extraction methods.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL-2005 Student Research Workshop.</booktitle>
<contexts>
<context position="1771" citStr="Pecina (2005)" startWordPosition="261" endWordPosition="262"> hopes to account for actual usage. Lexicographers (for both printed dictionaries and NLP systems) therefore require well-motivated ways of automatically identifying units of interest. The work described in this paper is a contribution to this task. Many linguists have offered classification schemes for MWEs. While these accounts vary in their terminology, they mostly focus on three different phenomena: collocation, non-compositionality and syntactic fixedness. In computational linguistics, a great deal of work has been done on the extraction of collocations in the last decade and a half (see Pecina (2005) for a survey). There have also been a number of papers focusing on the detection of semantic non-compositional items in recent years beginning with the work of Schone and Jurafsky (2001). The task of identifying syntactically-fixed phrases, however, has been much less explored. This third variety is the focus of the present paper. Languages contain many word combinations that do not allow the variation we would expect based solely on their grammatical form. In the most extreme case there are many phrases which seem to allow no syntactic variation whatsoever. These include phrases such as by a</context>
</contexts>
<marker>Pecina, 2005</marker>
<rawString>Pavel Pecina. 2005. An extensive empirical study of collocation extraction methods. In Proceedings of the ACL-2005 Student Research Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judita Preiss</author>
</authors>
<title>Using grammatical relations to compare parsers.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL-03.</booktitle>
<contexts>
<context position="21148" citStr="Preiss (2003)" startWordPosition="3542" endWordPosition="3543">t MI LLR x2 Top 100 items LONGMANS 14 21 15 16 0 13 0 SAID 21 17 17 23 0 17 0 BOTH 28 18 25 32 0 25 0 Top 1000 items LONGMANS 6.6 10.4 10.2 6.3 0 6.5 0.3 SAID 9.1 9 9.9 9 0 8.1 0.2 BOTH 12.2 14.2 15.2 12 0 11.4 0.4 Top 5000 items LONGMANS 3.24 4.28 4.84 3.12 0.06 3.44 0.58 SAID 3.86 3.56 4.54 3.68 0.04 3.86 0.54 BOTH 5.56 5.86 7.68 5.34 0.04 5.66 0.88 Table 2: Accuracy for top 100, 1000 and 5000 items (scores beating frequency at p &lt; 0.05 are in bold) An important issue for future research is how much the performance of our measure is affected by the technology used. In an evalutaion of RASP, Preiss (2003) reports an precision of 85.83 and recall of 78.48 for the direct object relation, 69.45/57.72 for the “ncmod” relation, and 91.15/98.77 for the “detmod” relation. There is clearly some variance here, but it is not easy to see any straightforward relationship with our results. The highest performance relation (“detmod”) was our least informative feature. Meanwhile our other two features both rely on the ”ncmod” relation. One way to address this issue in future research will be to replicate using multiple parsers. 5 Previous work Wermter and Hahn (2004) explore one kind of syntactic fixedness: </context>
</contexts>
<marker>Preiss, 2003</marker>
<rawString>Judita Preiss. 2003. Using grammatical relations to compare parsers. In Proceedings of EACL-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzanne Riehemann</author>
</authors>
<title>A Constructional Approach to Idioms and Word Formation.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="4195" citStr="Riehemann (2001)" startWordPosition="664" endWordPosition="665">d and compare it to some other methods that have been described in the literature. Section 5 will describe some previous work on the problem, and section 6 will review our findings. 2 Syntactic Fixedness in English Verb Phrases The experiments described here deal with one particular variety of phrase: English verb phrases of the form verb plus noun (e.g. walk the dog, pull teeth, take a leaflet). In a survey of the idiomatic phrases listed in the Collins Cobuild Dictionary of Idioms, Villavicencio and Copestake (2002) found this kind of idiom to account for more of the entries than any other. Riehemann (2001) performed a manual corpus analysis of verb and noun phrase idioms found in the Collins Cobuild Dictionary of Idioms. She found considerable fixedness with some phrases allowing no variation at all. Based on this literature we identified three important kinds of non-morphological variation that such phrases can undergo, and which crucially have been observed to be restricted for particular combinations. These are as follows: • Variation, addition or dropping of a determiner so that, for example, run the show becomes run their show, make waves becomes make more waves, or strike a chord becomes </context>
</contexts>
<marker>Riehemann, 2001</marker>
<rawString>Suzanne Riehemann. 2001. A Constructional Approach to Idioms and Word Formation. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Schone</author>
<author>Dan Jurafsky</author>
</authors>
<title>Is knowledgefree induction of multiword unit dictionary headwords a solved problem?</title>
<date>2001</date>
<booktitle>In Proceedings of EMNLP-2001.</booktitle>
<contexts>
<context position="1958" citStr="Schone and Jurafsky (2001)" startWordPosition="290" endWordPosition="293"> interest. The work described in this paper is a contribution to this task. Many linguists have offered classification schemes for MWEs. While these accounts vary in their terminology, they mostly focus on three different phenomena: collocation, non-compositionality and syntactic fixedness. In computational linguistics, a great deal of work has been done on the extraction of collocations in the last decade and a half (see Pecina (2005) for a survey). There have also been a number of papers focusing on the detection of semantic non-compositional items in recent years beginning with the work of Schone and Jurafsky (2001). The task of identifying syntactically-fixed phrases, however, has been much less explored. This third variety is the focus of the present paper. Languages contain many word combinations that do not allow the variation we would expect based solely on their grammatical form. In the most extreme case there are many phrases which seem to allow no syntactic variation whatsoever. These include phrases such as by and large and in short, which do not allow any morphological variation (*in shortest) or internal modification (*by and pretty large). We focus here on phrases that allow some syntactic va</context>
</contexts>
<marker>Schone, Jurafsky, 2001</marker>
<rawString>Patrick Schone and Dan Jurafsky. 2001. Is knowledgefree induction of multiword unit dictionary headwords a solved problem? In Proceedings of EMNLP-2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aline Villavicencio</author>
<author>Ann Copestake</author>
</authors>
<title>On the nature of idioms.</title>
<date>2002</date>
<journal>LinGO Working Paper</journal>
<volume>No.</volume>
<pages>2002--04</pages>
<contexts>
<context position="4102" citStr="Villavicencio and Copestake (2002)" startWordPosition="645" endWordPosition="648"> Computational Linguistics tion 3 will describe our model. Section 4 will evaluate the performance of the method and compare it to some other methods that have been described in the literature. Section 5 will describe some previous work on the problem, and section 6 will review our findings. 2 Syntactic Fixedness in English Verb Phrases The experiments described here deal with one particular variety of phrase: English verb phrases of the form verb plus noun (e.g. walk the dog, pull teeth, take a leaflet). In a survey of the idiomatic phrases listed in the Collins Cobuild Dictionary of Idioms, Villavicencio and Copestake (2002) found this kind of idiom to account for more of the entries than any other. Riehemann (2001) performed a manual corpus analysis of verb and noun phrase idioms found in the Collins Cobuild Dictionary of Idioms. She found considerable fixedness with some phrases allowing no variation at all. Based on this literature we identified three important kinds of non-morphological variation that such phrases can undergo, and which crucially have been observed to be restricted for particular combinations. These are as follows: • Variation, addition or dropping of a determiner so that, for example, run th</context>
</contexts>
<marker>Villavicencio, Copestake, 2002</marker>
<rawString>Aline Villavicencio and Ann Copestake. 2002. On the nature of idioms. LinGO Working Paper No. 2002-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Wermter</author>
<author>Udo Hahn</author>
</authors>
<title>Collocation extraction based on modifiability statistics.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING-2004.</booktitle>
<contexts>
<context position="2700" citStr="Wermter and Hahn (2004)" startWordPosition="409" endWordPosition="412">focus of the present paper. Languages contain many word combinations that do not allow the variation we would expect based solely on their grammatical form. In the most extreme case there are many phrases which seem to allow no syntactic variation whatsoever. These include phrases such as by and large and in short, which do not allow any morphological variation (*in shortest) or internal modification (*by and pretty large). We focus here on phrases that allow some syntactic variation, but do not allow other kinds. The small amount of previous work on the identification of syntactic fixedness (Wermter and Hahn (2004), Fazly and Stevenson (2006)) has either focused on a single variation variety, or has only been evaluated for combinations of a small preselected list of words, presumably due to noise. In this paper we employ a syntactic parser, thus allowing us to include a wider range of syntactic features in our model. Furthermore we describe a statistical measure of variation that is robust enough to be freely evaluated over the full set of possible word combinations found in the corpus. The remainder of our paper will be structured as follows. Section 2 will discuss the kinds of fixedness that we observ</context>
<context position="21706" citStr="Wermter and Hahn (2004)" startWordPosition="3630" endWordPosition="3633">d by the technology used. In an evalutaion of RASP, Preiss (2003) reports an precision of 85.83 and recall of 78.48 for the direct object relation, 69.45/57.72 for the “ncmod” relation, and 91.15/98.77 for the “detmod” relation. There is clearly some variance here, but it is not easy to see any straightforward relationship with our results. The highest performance relation (“detmod”) was our least informative feature. Meanwhile our other two features both rely on the ”ncmod” relation. One way to address this issue in future research will be to replicate using multiple parsers. 5 Previous work Wermter and Hahn (2004) explore one kind of syntactic fixedness: the (non-)modifiability of preposition-noun-verb combinations in German. They extract all preposition-noun-verb combinations from a corpus of German news text, and identify all the supplementary lexical information that occurs between the preposition and the verb. For each phrase they calculate the probability of seeing each piece of supplementary material, and take this as its degree of fixedness. A final score is then calculated by taking the product of this score and the problems for collocation measures, we experimented with various cutoffs up to a</context>
</contexts>
<marker>Wermter, Hahn, 2004</marker>
<rawString>Joachim Wermter and Udo Hahn. 2004. Collocation extraction based on modifiability statistics. In Proceedings of COLING-2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>