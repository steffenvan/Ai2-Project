<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.835806666666667">
PHRAN - A Knowledge-Based Natural Language Understander
Robert Wilensky and Yigal Arens
University of California at Berkeley
</title>
<sectionHeader confidence="0.789944" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999544761904762">
We have developed an approach to natural language
processing in which the natural language processor is
viewed as a knowledge-based system whose knowledge is
about the meanings of the utterances of its language.
The approach is oriented around the phrase rather than
the word as the basic unit. We believe that this
paradigm for language processing not only extends the
capabilities of other natural language systems, but
handles those tasks that previous systems could perform
in a more systematic and extensible manner.
We have constructed a natural language analysis program
called PHRAN (PHRasal ANalyzer) based in this approach.
This model has a number of advantages over existing
systems, including the ability to understand a wider
variety of language utterances, increased processing
speed in some cases, a clear separation of control
structure from data structure, a knowledge base that
could be shared by a language production mechanism,
greater ease of extensibility, and the ability to store
some useful forms of knowledge that cannot readily be
added to other systems.
</bodyText>
<sectionHeader confidence="0.875932" genericHeader="introduction">
1.0 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.9999663">
The problem of constructing a natural language processing
system may be viewed as a problem of constructing a
knowledge-based system. From this orientation, the
questions to ask are the following: What sort of
knowledge does a system need about a language in order to
understand the meaning of an utterance or to produce an
utterance in that language? How can this knowledge about
one&apos;s language best be represented, organized and
utilized? Can these tasks be achieved so that the
resulting system is easy to add to and modify? Moreover,
can the system be made to emulate a human language user?
Existing natural language processing systems vary
considerably in the kinds of knowledge about language
they possess, as well as in how this knowledge is
represented, organized and utilized. However, most of
these systems are based on ideas about language that do
not come to grips with the fact that a natural language
processor needs a great deal of knowledge about the
meaning of its languages utterances.
Part of the problem is that most current natural language
systems assume that the meaning of a natural language
utterance can be computed as a function of the
constituents of the utterance. The basic constituents of
utterances are assumed to be words, and all the knowledge
the system has about the semantics of its language is
stored at the word level (Birnbaum et al, 1979) (Riesbeck
et al, 1075) (Wilks, 1973) (Woods, 1970). However, many
natural language utterances have interpretations that
cannot be found by examining their components. Idioms,
canned phrases, lexical collocations, and structural
formulas are instances of large classes of language
utterances whose interpretation require knowledge about
the entire phrase independent of its individual words
(Becker, 1975) (Mitchell, 1971).
We propose as an alternative a model of language use that
comes from viewing language processing systems as
knowledge-based systems that require the representation
and organization of large amounts of knowledge about what
the utterances of a language mean. This model has the
following properties:
</bodyText>
<listItem confidence="0.898591">
1. It has knowledge about the meaning of the words
of the language, but in addition, much of the
system&apos;s knowledge is about the meaning of
larger forms of utterances.
2. This knowledge is stored in the form of
pattern-concept pairs. A pattern is a phrasal
</listItem>
<bodyText confidence="0.819823277777778">
construct ox varying degrees of specificity. A
concept is a notation that represents the
meaning of the phrase. Together, this pair
associates different forms of utterances with
their meanings.
3. The knowledge about language contained in the
system is kept separate from the processing
strategies that apply this knowledge to the
understanding and production tasks.
4. The understanding component matches incoming
utterances against known patterns, and then uses
the concepts associated with the matched
patterns to represent the utterance&apos;s meaning.
5. The production component expresses itself by
looking for concepts in the data base that match
the concept it wishes to express. The phrasal
patterns associated with these concepts are used
to generate the natural language utterance.
6. The data-base of pattern-concept pairs is shared
by both the understanding mechanism and the
mechanism of language production.
7. Other associations besides meanings may be kept
along with a phrase. For example, a description
of the contexts in which the phrase is an
appropriate way to express its meaning may be
stored. A person or situation strongly
associated with the phrase may also be tied to
it.
PHRAN (PHRasal ANalyzer) is a natural language
understanding system based on this view of language use.
PHRAN reads English text and produces structures .that
represent its meaning. As it reads an utterance, PHRAN
searches its knowledge base of pattern-concept pairs for
patterns that best interpret the text. The concept
portion of these pairs is then used to produce the
meaning representation for the utterance.
</bodyText>
<listItem confidence="0.89632575">
PHRAN has a number of advantages over previous systems:
1. The system is able to handle phrasal language
units that are awkwardly handled by previous
systems but which are found with great frequency
in ordinary speech and common natural language
texts.
2. It is simpler to add new information to the
system because control and representation are
kept separate. To extend the system, new
pattern-concept pairs are simply added to the
data-base.
3. The knowledge base used by PHRAN is declarative,
and is in principle sharable by a system for
language productiop (Such a mechanism is now
under construction). Thus adding information to
the base should extend the capabilities of both
mechanisms.
4. Because associations other than meanings can be
stored along with phrasal units, the
identification of a phrase can provide
contextual clues not otherwise available to
subsequent processing mechanisms.
5. The model seems to more adequately reflect the
psychological reality of human language use.
</listItem>
<sectionHeader confidence="0.548648" genericHeader="method">
2.0 PHRASAL LANGUAGE CONSTRUCTS
</sectionHeader>
<bodyText confidence="0.99987476">
By the term &amp;quot;phrasal language constructs&amp;quot; we refer to
those language units of which the language user has
specific knowledge. We cannot present our entire
classification of these constructs here. However, our
phrasal constructs range greatly. in flexibility. For
example, fixed exprespions like by and large , the Big
Apple (meaning N.Y.C.), and lexical collocations such as
&amp;quot;eye dropper&amp;quot; and &amp;quot;weak safety&amp;quot; allow little or no
modification idioms like &amp;quot;kick the bucket&amp;quot; and &amp;quot;bury
A
the hatchet allow the verb in them to appear in various
forms; discontinuous dependencies like look ... up&amp;quot;
permit varying positional relationships of their
constituents. All these constructs are phrasal in that
the language user must know the meaning of the construct
as a whole in order to use it correctly.
In the most general case, a phrase may express the usage
of a word sense. For example, to express one usage of
the verb kick, the phrase &amp;quot;&lt;person&gt; &lt;kick-form&gt; &lt;object&gt;&amp;quot;
is used.---This denotes a person followed by some verb
form involving kick (e.g., kick, kicked, would have
kicked&amp;quot;) follower—Bp some utterance denoting an object.
Our notion of a phrasal language construct is similar to
a structural formula (Fillmore, 1979). However, our
eft-m.1=115r delermiffing whether a set of forms should
</bodyText>
<page confidence="0.99656">
117
</page>
<bodyText confidence="0.999933142857143">
be accomodated by the same phrasal pattern is essentially
a conceptual one. Since each phrasal pattern in MAN is
associated with a concept, if the meanings of phrases are
different, they should be matched by different patterns.
If the surface structure of the phrases is similar and
they seem to mean the same thing, then they should be
accomodated by one pattern.
</bodyText>
<sectionHeader confidence="0.667595" genericHeader="method">
3.0 PHRAN
</sectionHeader>
<bodyText confidence="0.994880666666667">
PHRAN (PHRasal ANalyzer) is an English language
understanding system which integrates both generative and
non-productive language abilities to provide a relatively
flexible and extensible natural language understanding
facility. While PHRAN does have knowledge about
individual words, it is not limited to such knowledge,
nor is its processing capability constrained by a
word-based bias.
Here are some examples of sentences PHRAN can understand:
</bodyText>
<listItem confidence="0.984289">
• Oilmen are encouraged by the amount of oil discovered
</listItem>
<bodyText confidence="0.870964">
in the Baltimore Canyon, an undersea trough 100 miles
off the shore of New Jersey. (Newsweek, Feb 1980)
</bodyText>
<listItem confidence="0.97456725">
• The young man was told to drive quickly over to
Berkeley.
• If John gives Bill the big apple then Pill won&apos;t be
hungry.
* Willa will drive Bill to The Big Apple if she is
given twenty five dollars.
• If Mary brings John we&apos;ll go to a Chinese restaurant.
• Willa gives me a headache.
</listItem>
<bodyText confidence="0.997613555555555">
(The previous sentences are analyzed by an uncompiled
version of PHRAN on the DEC-20/40 system at UC Berkeley
in from 2 to 9 seconds of CPU time).
At the center of PHRAN is a knowledge base of phrasal
patterns. These include literal strings such as &amp;quot;so &apos;s
your old man&amp;quot;; patterns such as &amp;quot;&lt;nationality&gt;
restaurant&amp;quot;, and very general phrases such as &amp;quot;(person&gt;
&lt;give&gt; &lt;person&gt; &lt;object&gt; .
Associated with each phrasal pattern is a conceptual
template. A conceptual template is a piece o. meaning
representation with possible references to pieces of the
associated phrasal pattern. For example, associated with
the phrasal pattern &amp;quot;&lt;nationality&gt; restaurant&amp;quot; is the
conceptual template denoting a restaurant that serves
&lt;nationality&gt; type food; associated with the phrasal
pattern &amp;quot;&lt;person1&gt; &lt;give&gt; &lt;person2&gt; Cobject&gt;&amp;quot; is the
conceptual template that denotes a transfer of possession
by &lt;person1&gt; of &lt;object&gt; to &lt;person2&gt; from &lt;person1&gt;.
</bodyText>
<subsectionHeader confidence="0.4150395">
4.0 HOW PHRAN WORKS
4.1 Overall Algorithm
</subsectionHeader>
<bodyText confidence="0.9837708">
PHRAN is made up of three parts - a database of
pattern-concept pairs, a set of comprehension routines,
and a routine which suggests appropriate pattern, concept
pairs. PHRAN takes as input an English sentence, and as
it reads it from left to right, PHRAN compares the
sentence against patterns from the database. Whenever a
matching pattern is found, PHRAN interprets that part of
the sentence that matched the pattern as describing the
concept associated with the pattern in the
pattern-concept pair.
</bodyText>
<subsubsectionHeader confidence="0.729123">
4.1.1 Overview. Of Processing -
</subsubsectionHeader>
<bodyText confidence="0.999586875">
When PHAN analyzes a sentence, it reads the words one at
a time, from left to right. It does just enough
morphological analysis to recognize contractions and
&apos;s s. The pattern suggesting routine determines if any
new patterns should be tried, and PHRAN checks all the
new patterns to see if they agree with that part of the
sentence already analyzed, discarding those that don&apos;t.
A word&apos;s meaning is determined simply by its matching a
pattern consisting of that literal word. Then a term is
formed with the properties specified in the concept
associated with the word, and this term is added to a
list PHRAN maintains. PHRAN checks if the term it just
added the list completes or extends patterns that had
alread5 been partially matched by the previous terms. If
a pattern is completely matched, the terms matching tha-
pattern are removed and a new term, specified by thy
concept part of the nattern-concept pair, is formed ane
replaces the terms the pattern matched.
When PHRAN finishes processing one word it reads the
next, iterating this procedure until it reaches the end
of a sentence. At this point, it should end up with a
single term on its list. This term contains the
conceptualization representing the meaning of the whole
sentence.
</bodyText>
<subsubsectionHeader confidence="0.8935">
4.1.2 Overview Of PHRAN Patterns -
</subsubsectionHeader>
<bodyText confidence="0.880428684210526">
A pattern-concept pair consists of a specification of the
phrasal unit, an associated concept, and some additional
information about how the two are related. When PHRAN
instantiates a concept, it creates an item called a term
that includes the concept as well as some additirETT
information.
A pattern is a sequence of conditions that must hold true
for a sequence of terms. A pattern may specify optional
terms tog, the place where these may appear, and what
effect (if any) their appearance will have on the
properties of the term formed if the pattern is matched.
For example, consider the following informal description
of one of the patterns suggested by the mention of the
verb &apos;to eat in certain contexts.
1 pattern to recognize -
1&lt;first term: represents a person&gt;
&apos; &lt;second term: is an active form of EAT&gt; ,
&lt;OPTIONAL third term: represents food,&apos;
term to form -
</bodyText>
<equation confidence="0.79427">
(INGEST ACTOR &lt;first term&gt;)
OBJECT (third term, if present,
else FOOD&gt;))
</equation>
<bodyText confidence="0.999805666666667">
Notice that the third term is marked as optional. If it
is not present in the text, PHRAN will fill-the OBJECT
slot with a default representing generic food.
</bodyText>
<subsubsectionHeader confidence="0.682155">
4.1.3 Simple Example -
</subsubsectionHeader>
<bodyText confidence="0.9936025625">
The following is a highly simplified example of how PHRAN
processes the sentence John dropped out of school&amp;quot;:
First the word &amp;quot;John&amp;quot; is read. &amp;quot;John&amp;quot; matches the
pattern consisting of the literal &amp;quot;John , and the concept
associated with this pattern causes a term to be formed
that represents a noun phrase and a particular male
person named John. No other patterns were suggested.
This term is added on to *CONCEPT*, the list of terms
PHRAN keeps and which will eventually contain the meaning
of the sentence. Thus *CONCEPT* looks like
&lt; rJOHN1 - person, mol &gt;
&amp;quot;Dropped&amp;quot; is read next. It matches the literal
&amp;quot;dropped&amp;quot;, and an appropriate term is formed. The
pattern suggesting routine instructs PHRAN to consider
the &apos;basic pattern associated with the verb &apos;to drop&apos;,
which is:
</bodyText>
<equation confidence="0.483778">
I r&lt;person&gt; &lt;DROP&gt; &lt;object&gt;) r 1
</equation>
<bodyText confidence="0.99291071875">
Its initial coLdition is found to be satisfied by the
first term in *CONCEPT* -- this fact is stored under that
term so that succeeding ones will be checked to see if
this partial match continues. The term that was formed
after reading &apos;dropped&amp;quot; is now added to the list.
*CONCEPT* is now
&lt; IJOHN1 - person, NP) , rDROP - verb] &gt;
PHRAN now checks to see if the pattern stored under the
first term matches the term just added to *CONCEPT* too,
and it does. This new fact is now stored under the last
term.
Next the word &amp;quot;out&amp;quot; is read. The pattern suggestion
mechanism is alerted by the occurence of the verb &apos;drop&apos;
followed by the word &apos;out&apos;, and at this point it
instructs PHRAN to consi :r the pattern
f r&lt;person&gt; &lt;DROP&gt; &amp;quot;out&amp;quot; &amp;quot;of&amp;quot; &lt;school&gt;1 I ... !
The list in *CONCEPT* is checked against this pattern to
see if it matches its first two terms, and since that is
the case, this fact is stored under the accord term. A
term associated with out&apos; is now added to *CONCEPT*:
&lt; 1JOHN1 - person, NP) , [DROP - verb) , [OUT1 &gt;
The two patterns that have matched up to DROP are checked
to see if the new term extends them. This is true only
for the second pattern, apd this fact is stored under the
next term. The pattern 1&lt;person&gt; &lt;DROP&gt; &lt;object&gt;1 is
discarded.
Now the word &amp;quot;of&amp;quot; is read. A term is formed and added to
*CONCEPT*. The pattern that matched up to OUT is
extended by OF so the pattern is moved to the next term.
The word &amp;quot;high&amp;quot; is read and a term is formed and added to
*CONCEPT*. Nov the pattern under OF is compared against
HIGH. It doesn&apos;t satisfy the next condition. PHRAN
</bodyText>
<page confidence="0.993693">
118
</page>
<bodyText confidence="0.933649733333333">
reads &amp;quot;school&amp;quot;, and the pattern suggestion routine
presents PHRAN with two patterns:
&amp;quot;high&amp;quot; &amp;quot;school&amp;quot; r represention denoting a
school for 10th through 12th
graders!
2. r&lt;adjective&gt; &lt;noun&gt;1 r representation denoting ,
noun modified by adjectivel I
Both patterns are satisfied by the previous term and this
fact is stored under it. The new term is added to
*CONCEPT*, now:
&lt; [3OLIN1 , person, W ,,gDROP - verbl , rOUT1„
. FOF! , IH/GH - adjj., [ CHOOL - school, noun) &gt;
The two patterns are compared against the last term, and
both are matched. The last two terms aee removed from
*CONCEPT*, and the patterns under OF are checked to
determine which of the two possible meanings we have
should be chosen. Patterns are suggested such that the
more specific ones appear first, so that the more
specific interpretation will be chosen if all patterns
match equally well. Only if the second meaning (i.e. a
school that is high) were explicitly specified by a
previous pattern, would it have been chosen.
A term is formed and added to *CONCEPT*, which now
contains
&lt; IJOHN1 - person, NP) hDROP - verbl , FOUT1
LOFI , FRIG -SCHOOL1 - School, NPI &gt;
The pattern under OF is checked against the last term in
*CONCEPT*. PHRAN finds a complete match, so all the
matched terms are removed and replaced by the concept
associated with this pattern.
</bodyText>
<table confidence="0.6259066">
*CONCEPT* now contains this concept as the final result:
&lt; I (SSCHOOLING STUDENT JOHN1)
SCHOOL HIGH-SCHOOL1)
TERMINATION PREMATURE)) ] &gt;
4.2 Pattern-Concept Pairs In More Detail
</table>
<subsubsectionHeader confidence="0.934446">
4.2.1 The Pattern -
</subsubsectionHeader>
<bodyText confidence="0.993837333333333">
The pattern portion of a pattern-concept pair consists of
a sequence of predicates. These may take one of several
forms:
</bodyText>
<listItem confidence="0.899706111111111">
1. A word; which will match only a term
representing this exact word.
2. A class name (in parentheses); will match any
term representing a member of this class (e.g.
&amp;quot;(FOOD)&amp;quot; or &amp;quot;(PHYSICAL-OBJECT)&amp;quot;).
3. A pair, the first element of which is a property
name and the second is a value; will match any
term havtng the required value of the property
(e.g. &amp;quot;(Part-Of-Speech VERB)&amp;quot;).
</listItem>
<bodyText confidence="0.970852826086956">
In addition, we may negate a condition or specify that a
conjunction or disjunction of several must hold.
The following is one of the patterns which may be
suggested by the occurrence of the verb give in an
utterance:
r(PERSON) (ROOT GIVE) (PERSON) (PHYSOB)1
4.2.1.1 Optional Parts -
To indicate the presence of optional terms, a list of
pattern concept-pairs is inserted into the pattern at the
appropriate place. These pairs have as their first
element a sub-pattern that will match the optional terms.
The second part describes how the new term to be formed
if the main pattern is found should be modified to
reflect the existence of the optional sub-pattern.
The concept corresponding to the optional part of a
pattern is treated in a form slightly different from the
way we treat regular concept parts of pattern-concept
pairs. As usual, it consists of pairs of expressions.
The first of each pair will be placed as is at the end of
the properties of the term to be formed, and the second
will be evaluated first and then placed on that list.
For example, another pattern suggested when &apos;give&apos; is
seen is the following:
</bodyText>
<equation confidence="0.720665333333333">
((PERSON) (ROOT (PHYSOB)
EVE) (PERSON))
TO (OPT-VAL 2 CD-FORM))1)1
</equation>
<bodyText confidence="0.999877647058823">
The terms of this pattern describe a person, the verb
give, and then some physical object. The last term
describes the optional terms, consisting of the word to
followed by a person description. Associated with thrg
pattern is a concept part that specifies what to do with
the optional part if it is there. Here it specifies that
the second term in the optional pattern should fill in
the TO slot in the conceptualization associated with the
whole pattern.
This particular pattern need not be a separate pattern in
PHRAN from the one that looks for the verb followed by
the recipient followed by the object transferred. We
often show patterns without all the alternatives that are
possible for expositional purposes. Sometimes it is
simpler to write the actual patterns separately, although
we attach no theoretical significance to this
disposition.
</bodyText>
<subsubsectionHeader confidence="0.993383">
4.2.2 The Concept -
</subsubsectionHeader>
<bodyText confidence="0.974462714285714">
When a pattern is matched, PHRAN removes the terms that
match it from *CONCEPT* and replaces them with a new
term, as defined by the second part of the
pattern-concept pair. For example, here is a
pattern-concept pair that may be suggested when the verb
&apos;eat&apos; is encountered:
([(PERSON) (ROOT EAn (g((FOOD))
</bodyText>
<sectionHeader confidence="0.95512175" genericHeader="method">
[P-O-S &apos;SENTENCE
CD-FORM (INGEST (ACTOR ?ACTOR) (OBJECT ?FOOD))
ACTOR (VALE 1 CD-FORM)
FOOD &apos;FOOD)
</sectionHeader>
<bodyText confidence="0.996458807692308">
The concept portion of this pair describes a term
covering an entire sentence, and whose meaning is the
action of INGESTing some food (Schenk, 1975). The next
two descriptors specify how to fill in variable parts of
this action. The expression (VALUE n prop) specifies tne
prop property of the n&apos;th term in the matc ed sequence
of the pattern (not including optional terms). OPT-VAL
does the same thing with regards to a matched optional
sub-pattern. Thus the concept description above
specifies that the actor of the action is to be the term
matching the first condition. The object eaten will be
either the default concept food, or, if the optional
sub-pattern was found, the term corresponding to this
sub-pattern.
Sometimes a slot in the conceptualization can be filled
by a term in a higher level pattern of which this one is
an element. For example, when analyzing &apos;John wanted to
eat a cupcake a slight modification of the previous
pattern is used to find the meaning of &amp;quot;to eat a
cupcake&amp;quot;. Since no subject appears in this form, the
higher level pattern specifies where it may find it.
That is, a pattern associated with want&amp;quot; looks like the
following:
[&lt;person&gt; &lt;WANT&gt; &lt;infinitive&gt;1
This specifies that the subject of the clause following
want is the same as the subject of want.
</bodyText>
<subsectionHeader confidence="0.668186">
4.3 Pattern Manipulation In More Detail
4.3.1 Reading A Word -
</subsectionHeader>
<bodyText confidence="0.999972">
When a word is read PHRAN compares the patterns offered
by the pattern suggesting routine with the list *CONCEPT*
in the manner described in the example in section 4.1.3.
It discards patterns that conflict with *CONCEPT* and
retains the rest. Then PHRAN tries to determine which
meaning of the word to choose, using the &amp;quot;active&amp;quot;
patterns (those that have matched up to the point where
PHRAN has read). It checks if there is a particular
meaning that will match the next slot in some pattern or,
if no such definition exists, if there is a meaning that
might be the beginning of a sequence of terms whose
meaning, as determined via a pattern-concept pair, will
satisfy the next slot in one of the active patterns. If
this is the case, that meaning of the word is chosen.
Otherwise PHRAN defaults to the first of the meanings of
the word.
A new term is formed and if it satisfies the next
condition in one of these patterns, the appropriate
pattern is moved to the pattern-list of the new term. If
the next condition in the pattern indicates that the term
specified is optional, then PHRAN checks for these
optional terms, and if it is convinced that they are not
present, it checks to see if the new term satisfies the
condition following the optional ones in the pattern.
</bodyText>
<equation confidence="0.931957">
(F00 ( PT-VAL 1 CD-FORM))1)]
infinitive-subjel TALUE 1 CD-FORM)
</equation>
<page confidence="0.665508">
119
4.3.2 A Pattern Is Matched -
</page>
<bodyText confidence="0.999017777777778">
When a pattern has been matched completely, PHRAN
continues checking all the other patterns on the
pattern-list. When it has finished, PHRAN will take the
longest pattern that was matched and will consider the
concept of its pattern-concept pair to be the meaning of
the sequence. If there are several patterns of the same
length that were matched PHRAN will group all their
meanings together.
New patterns are suggested and a disambiguation process
follows, exactly as in the case of a new word being read.
For example, the words &amp;quot;the big apple&amp;quot;, when recognized,
will have two possible meanings; one being a large
fruit, the other being New York City. PHRAN will check
the patterns active at that time to determine if one of
these two meanings satisfies the next condition in one of
the patterns. If so, then that meaning will be chosen.
Otherwise a large fruit&apos; will be the default, as it is
the first in the list of possible meanings.
</bodyText>
<subsectionHeader confidence="0.996276">
4.4 Adverbs And Adverbial Phrases
</subsectionHeader>
<bodyText confidence="0.999199807692308">
In certain cases there is need for slightly modified
notions of pattern and concept, the most prominent
examples being adverbs and adverbial phrases. Such
phrases are also recognized through the use of patterns.
However, upon recognizing an adverb, PHRAN searches
within the active patterns for an action that it can
modify. When such an action is found the concept part of
the pair associated with the adverb is used to modify the
concept of the original action.
Adverbs such as &amp;quot;quickly&amp;quot; and &amp;quot;slowly&amp;quot; are currently
defined end can be used to modify conceptualizations
containing various actions. Thus PHRAN can handle
constructs like:
John ate slowly.
Quickly, John left the house.
John left the house quickly.
John slowly ate the apple.
John wanted slowly to eat the apple.
Some special cases of negation are handled by specific
patterns. For example, the negation of the verb want
usually is interpreted as meaning &amp;quot;want not - &amp;quot;Nrry
didn&apos;t want to go to school&amp;quot; means the same thing as
&amp;quot;Mary wanted not to go to school&amp;quot;. Thus PHRAN contains
the specific pattern t&lt;person&gt; &lt;do&gt; &amp;quot;not&amp;quot; &lt;want&gt;
&lt;inf-phrase) I which is associated with this
interpretation.
</bodyText>
<subsectionHeader confidence="0.980937">
4.5 Indexing And Pattern Suggestion
</subsectionHeader>
<bodyText confidence="0.998403875">
Retrieving the phrasal pattern matching a particular
utterance from PHRAN&apos;s knowledge base is an important
problem that we have not yet solved to our complete
satisfaction. We find some consolation in the fact that
the problem of indexing a large data base is a neccesary
and familiar problem for all knowledge based systems.
We have tried two pattern suggestion mechanisms with
PHRAN:
</bodyText>
<listItem confidence="0.9835312">
1. Keying patterns off individual words or
previously matched patterns.
2. Indexing patterns under ordered sequences of
cues gotten from the sentence —mat--prrasyr
Trnerns recognized in it.
</listItem>
<bodyText confidence="0.999766459459459">
The first indexing mechanism works but it requires that
any pattern used to recognize a phrasal expressions be
suggested by some word in it. This is unacceptable
because it will cause the pattern to be suggested
whenever the word it is triggered by is mentioned. The
difficulties inherent in such an indexing scheme can be
appreciated by considering which word in the phrase &amp;quot;by
and large&amp;quot; should be used to trigger it. Any choice we
make will cause the pattern to be suggested very often in
contexts when it is not appropriate. In this form,
PHRAN&apos;s processing roughly resembles ELI&apos;s (Riesbeck et
al, 1975).
We therefore developed the second mechanism. The
patterns-concept pairs of the database are indexed in a
tree. As words are read, the pattern suggesting
mechanism travels down this tree, choosing branches
according to the meanings of the words. It suggests to
PHRAN the patterns found at the nodes it has arrived at.
The list of nodes is remembered, and when the next word
is read the routine continues to branch from them, in
addition to starting from the root. In practice, the
number of nodes in the list is rather small.
For example, whenever a noun-phrase is followed by an
active form of some verb, the suggesting routine
instructs MAW to consider the simple declarative forma
of the verb. When a noun-phrase is followed by the verb
&apos;to be followed by the perfective form of some verb, the
routine instructs PHRAN to consider the passive uses of
the last verb. The phrasal pattern that will recognize
the expression &apos;by and large is found at the node
reached only after seeing those three words
consecutively. In this manner this pattern will be
suggested only when neccessary.
The main problem with this scheme is that it does not
lend itself well to allowing contextual cues to influence
the choice of patterns FRAN should try. This is one
area where future research will be concentrated.
</bodyText>
<sectionHeader confidence="0.875922" genericHeader="conclusions">
5.0 COMPARISON TO OTHER SYSTEMS
</sectionHeader>
<bodyText confidence="0.99989470886076">
There are a number of other natural language processing
systems that either use some notion of patterns or
produce meaning structures as output. We contrast PHRAN
with some of these.
An example of a natural language understanding system
that produces declarative meaning representations is
Riesbeck&apos;s conceptual analyzer (Riesbeck, 1974).
Riesbeck&apos;s system (and the various systems that have
descended from it) works by attaching routines to
individual words. These routines are generally
responsible for building pieces of a meaning
representation. When a word is reed by the system, the
routines associated with that word are used to build up a
meaning structure that eventually denotes the meaning of
the entire utterance.
While our aims are much in the spirit of Riesbeck&apos;s
analyzer, we believe there are both practical and
theoretical difficulties inherent in his approach. For
example, in Riesbeck&apos;s conceptual analyzer, specific
understanding routines are needed for each word known to
the system. Thus extending the system&apos;s vocabulary
requires the creation and debugging of new code. In
addition, these routines function only in the
understanding process. The knowledge they embody is
inaccessible to other mechanisms, in particular, to
production procedures.
Moreover, because Riesbeck&apos;s approach is word-oriented,
it is difficult to incorporate phrasal structures into
his model. Some word of the phrase must have a routine
associated with it that checks for that phrase. At best,
this implementation is awkward.
One of the earliest langusge understanding systems to
incorporate phrasal patterns is Colby &apos;s PARRY. PARRY is
a simulation of a paranoid mental patient that contains a
natural languege front end (Parkinson et a), 1077). It
receives a sentence as input and analyzes it in several
separate &amp;quot;steges . In effect, PARRY replaces the input
with sentences of successively simpler form. In the
simplified sentence PARRY searches for patterns, of which
there are two basic types: patterns used to interpret
the whole eentence, and those used only to interpret
parts of it (relative clauses, for example).
For PARRY, the purpose of the natural language analyzer
is only to translate the input into a simplified form
that a model of a paranoid person may use to determine an
appropriate response. No attempt is made to model the
anelyzer itself after a human language user, as we are
doing, nor are claims made to this effect. A system
attempting to model human language analysis could not
permit several unrelated passes, the use of a transition
network grammar to interpret only certain sub-strings in
the input, or a rule permitting it to simply ignore parts
of the input.
This theoretical shortcoming of PARRY - having separate
grammar rules for the complete sentence and for sub-parts
o it - is shared by Hendrix&apos;s LIFER (Hendrix, 1077).
LIFER is designed to enable a database to be queried
using a subset of the English languege. As is the cape
for PARRY, the natural language analysis done by LIFER is
not meant to model humans. Rather, its function is to
translate the input into instructions and produce a reply
as efficiently as poesible, and nothing resembling a
representation of the meaning of the input is ever
iormed. course. the purpose of LIFER is not to be the
. .
front end of a system that understands coherent texts
and which must therefore perform subsequent inference
processes. While LIFER provides a workable solution to
the nature] language problem in a limited context, many
general problems of language analysis are not addressed
in that context.
SOPHIE (Burton, 1976) was designed to assist students in
learning about simple electronic circuits. It can
conduct a dialogue with the user in a restricted subset
of the English language, and it uses knowledge about
patterns of speech to interpret the input. SOPHIE
accepts only certain questions and instructions
concerning a few tasks. As is the case with LITER, the
language utterances acceptable to the system are
</bodyText>
<page confidence="0.982729">
120
</page>
<bodyText confidence="0.999977509803922">
restricted to such an extent that many natural language
processing problems need not be dealt with and other
problems have solutions appropriate only to this context.
In addition, SOPHIE does not produce any representation
of the meaning of the input, and it makes more than one
pass on the input ignoring unknown words, practices that
have already been criticized.
The augmented finite state transition network (ATN) has
been used by a number of researchers to aid in the
analysis of natural language sentences for example, see
Woods 1970). However, most systems that use ATM&apos;s
incorporate one feature which we find objectionable on
both theoretical and practical grounds. This is the
separation of analysis into syntactic and semantic
phases. The efficacy and psychological validity of the
separation of syntactic and semantic processing has been
argued at length elsewhere (see Scha 1975 for example).
In addition, most ATN based systems for oxample Woods&apos;
LUNAR program) do not produce representations, but
rather, run queries of a data base.
In contrast to the systems just described, Wilks&apos;
English-French machine ranslator does not share several
of their shortcomings Wilks, 1973). It produces a
representation of the meaning of an utterance, and it
attempts to deal with unrestricted natural language. The
main difference between Wilk&apos;s system and system we
describe is that Wilks&apos; patterns are matched against
concepts mentioned in a sentence. To recognize these
concepts he attaches representations to words in a
dictionary.
The problem is that this presupposes that there is a
simple correspondence between the form of a concept and
the form of a language utterance. However, it is the
fact that this correspondence is not simple that leads to
the difficulties we are addressing in our work. In fact,
since the correspondence of words to meanings is complex,
it would appear that a program like Wilks&apos; translator
will eventually need the kind of knowledge embodied in
PHRAN to complete its analysis.
One recent attempt at natural language analysis that
radically departs from pattern-based approaches is Rieger
and Small&apos;s system (Small, 1978). This system uses word
experts rather than patterns as its basic mechanrelF7
Their system acknowledges the enormity of the knowledge
base required for language understanding, and proposes a
way of addressing the relevant issues. However, the idea
of putting as much information as possible under
individual words is about as far from our conception of
language analysis as one can get, and we would argue,
would exemplify all the problems we have described in
word-based systems.
</bodyText>
<sectionHeader confidence="0.989877" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999678976190476">
Becker, Joseph D. (1975). The phrasal lexicon. In
Theoretical Issues in Natural Language Processing. R.
henanx ana aa.Nr-Veoper (eds.). Camoriage, Mass.
Birnbaum, L. and Selfridge, M. (1979). Problems in
conceptual analysis of nature]. language. Yale University
Department of Computer Science Research Report 168.
Burton., Richard R. (1476). Semantic Grammar: An
Engineering Technique for Constructing Natural Language
Understanding Systems. BEN Report No. 3453, Dec 1975.
Fillmore, C.J. (1979). Innocence: A Ser.ond
Idealization for Linguistics. In Proceedings of the
Fifth Berkeley Language Symposium, Berkeley; CatiT7Thia.
Hendrix, Gary G. (1977). The Lifer Manual: A Guide to
Building Practical Natural Language Interfaces. SRI
International: Al Center Technical Note 138, Feb 1977.
Mitchell, T. F. (1971). Linguistic &amp;quot;Goings On&amp;quot;:
Collocations and Other Matters Arising on the Syntactic
Record. Archivum Linguisticum 2 (new series) 35-69.
Parkinson, R.C., Colby, K.M., and Fought, W.S. (1977).
Conversational Language Comprehension Using Integrated
Pattern-Matching and Parsing. Artificial Intelligence 9,
111-134.
Riesbeck, C. K. (1975). Conceptual analysis. In R. C.
Schenk Conceptual Information Processing. American
Elsevier ruolisPing uompany, inc., New lork.
Riesbeck. C. K. and Schenk, R. C. (1975).
Comprehension by computer: expectation-based analysis of
sentences in context. Yale University Research Report
78.
Schenk. R. C. (1975). Conceptual Information
Processing. American Elsevier Puolisning uompany, Inc.,
sew ioric.
Small, S. (1978). Conceptual language analysis for
story comprehension. Technical Report No. 663, Dept.
of Computer Science, University of Maryland, College
Park, Maryland.
Wilke, Yorick (1973). An Al Approach to Machine
Translation. In Computer Models of Thought and Language,
R.C. Schenk and K.M: uoloy (eas77, W.H. Freeman and
Co., San Francisco, 1973.
Woods, W. A. (1970). Transition Network Grammars for
Natural Language Analysis. CACM 13, 591-606.
</reference>
<page confidence="0.99789">
121
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.988057">
<title confidence="0.999149">PHRAN - A Knowledge-Based Natural Language Understander</title>
<author confidence="0.999355">Robert Wilensky</author>
<author confidence="0.999355">Yigal Arens</author>
<affiliation confidence="0.999903">University of California at Berkeley</affiliation>
<abstract confidence="0.999518818181818">We have developed an approach to natural language processing in which the natural language processor is viewed as a knowledge-based system whose knowledge is about the meanings of the utterances of its language. The approach is oriented around the phrase rather than the word as the basic unit. We believe that this paradigm for language processing not only extends the capabilities of other natural language systems, but handles those tasks that previous systems could perform in a more systematic and extensible manner. We have constructed a natural language analysis program called PHRAN (PHRasal ANalyzer) based in this approach. This model has a number of advantages over existing systems, including the ability to understand a wider variety of language utterances, increased processing speed in some cases, a clear separation of control structure from data structure, a knowledge base that could be shared by a language production mechanism, greater ease of extensibility, and the ability to store some useful forms of knowledge that cannot readily be added to other systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Joseph D Becker</author>
</authors>
<title>The phrasal lexicon.</title>
<date>1975</date>
<booktitle>In Theoretical Issues in Natural Language Processing.</booktitle>
<editor>R. henanx ana aa.Nr-Veoper (eds.). Camoriage,</editor>
<location>Mass.</location>
<contexts>
<context position="3017" citStr="Becker, 1975" startWordPosition="471" endWordPosition="472">ents of the utterance. The basic constituents of utterances are assumed to be words, and all the knowledge the system has about the semantics of its language is stored at the word level (Birnbaum et al, 1979) (Riesbeck et al, 1075) (Wilks, 1973) (Woods, 1970). However, many natural language utterances have interpretations that cannot be found by examining their components. Idioms, canned phrases, lexical collocations, and structural formulas are instances of large classes of language utterances whose interpretation require knowledge about the entire phrase independent of its individual words (Becker, 1975) (Mitchell, 1971). We propose as an alternative a model of language use that comes from viewing language processing systems as knowledge-based systems that require the representation and organization of large amounts of knowledge about what the utterances of a language mean. This model has the following properties: 1. It has knowledge about the meaning of the words of the language, but in addition, much of the system&apos;s knowledge is about the meaning of larger forms of utterances. 2. This knowledge is stored in the form of pattern-concept pairs. A pattern is a phrasal construct ox varying degre</context>
</contexts>
<marker>Becker, 1975</marker>
<rawString>Becker, Joseph D. (1975). The phrasal lexicon. In Theoretical Issues in Natural Language Processing. R. henanx ana aa.Nr-Veoper (eds.). Camoriage, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Birnbaum</author>
<author>M Selfridge</author>
</authors>
<title>Problems in conceptual analysis of nature]. language.</title>
<date>1979</date>
<tech>Research Report 168.</tech>
<institution>Yale University Department of Computer Science</institution>
<marker>Birnbaum, Selfridge, 1979</marker>
<rawString>Birnbaum, L. and Selfridge, M. (1979). Problems in conceptual analysis of nature]. language. Yale University Department of Computer Science Research Report 168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard R Burton</author>
</authors>
<title>Semantic Grammar: An Engineering Technique for Constructing Natural Language Understanding Systems.</title>
<date>1476</date>
<tech>BEN Report No. 3453,</tech>
<marker>Burton, 1476</marker>
<rawString>Burton., Richard R. (1476). Semantic Grammar: An Engineering Technique for Constructing Natural Language Understanding Systems. BEN Report No. 3453, Dec 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
</authors>
<title>Innocence: A Ser.ond Idealization for Linguistics.</title>
<date>1979</date>
<booktitle>In Proceedings of the Fifth Berkeley Language Symposium,</booktitle>
<location>Berkeley; CatiT7Thia.</location>
<contexts>
<context position="7444" citStr="Fillmore, 1979" startWordPosition="1168" endWordPosition="1169">g positional relationships of their constituents. All these constructs are phrasal in that the language user must know the meaning of the construct as a whole in order to use it correctly. In the most general case, a phrase may express the usage of a word sense. For example, to express one usage of the verb kick, the phrase &amp;quot;&lt;person&gt; &lt;kick-form&gt; &lt;object&gt;&amp;quot; is used.---This denotes a person followed by some verb form involving kick (e.g., kick, kicked, would have kicked&amp;quot;) follower—Bp some utterance denoting an object. Our notion of a phrasal language construct is similar to a structural formula (Fillmore, 1979). However, our eft-m.1=115r delermiffing whether a set of forms should 117 be accomodated by the same phrasal pattern is essentially a conceptual one. Since each phrasal pattern in MAN is associated with a concept, if the meanings of phrases are different, they should be matched by different patterns. If the surface structure of the phrases is similar and they seem to mean the same thing, then they should be accomodated by one pattern. 3.0 PHRAN PHRAN (PHRasal ANalyzer) is an English language understanding system which integrates both generative and non-productive language abilities to provide</context>
</contexts>
<marker>Fillmore, 1979</marker>
<rawString>Fillmore, C.J. (1979). Innocence: A Ser.ond Idealization for Linguistics. In Proceedings of the Fifth Berkeley Language Symposium, Berkeley; CatiT7Thia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary G Hendrix</author>
</authors>
<title>The Lifer Manual: A Guide to Building Practical Natural Language Interfaces.</title>
<date>1977</date>
<booktitle>SRI International: Al Center Technical Note 138,</booktitle>
<marker>Hendrix, 1977</marker>
<rawString>Hendrix, Gary G. (1977). The Lifer Manual: A Guide to Building Practical Natural Language Interfaces. SRI International: Al Center Technical Note 138, Feb 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T F Mitchell</author>
</authors>
<title>Linguistic &amp;quot;Goings On&amp;quot;: Collocations and Other Matters Arising on the Syntactic Record.</title>
<date>1971</date>
<journal>Archivum Linguisticum</journal>
<volume>2</volume>
<pages>35--69</pages>
<contexts>
<context position="3034" citStr="Mitchell, 1971" startWordPosition="473" endWordPosition="474">erance. The basic constituents of utterances are assumed to be words, and all the knowledge the system has about the semantics of its language is stored at the word level (Birnbaum et al, 1979) (Riesbeck et al, 1075) (Wilks, 1973) (Woods, 1970). However, many natural language utterances have interpretations that cannot be found by examining their components. Idioms, canned phrases, lexical collocations, and structural formulas are instances of large classes of language utterances whose interpretation require knowledge about the entire phrase independent of its individual words (Becker, 1975) (Mitchell, 1971). We propose as an alternative a model of language use that comes from viewing language processing systems as knowledge-based systems that require the representation and organization of large amounts of knowledge about what the utterances of a language mean. This model has the following properties: 1. It has knowledge about the meaning of the words of the language, but in addition, much of the system&apos;s knowledge is about the meaning of larger forms of utterances. 2. This knowledge is stored in the form of pattern-concept pairs. A pattern is a phrasal construct ox varying degrees of specificity</context>
</contexts>
<marker>Mitchell, 1971</marker>
<rawString>Mitchell, T. F. (1971). Linguistic &amp;quot;Goings On&amp;quot;: Collocations and Other Matters Arising on the Syntactic Record. Archivum Linguisticum 2 (new series) 35-69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Parkinson</author>
<author>K M Colby</author>
<author>W S Fought</author>
</authors>
<title>Conversational Language Comprehension Using Integrated Pattern-Matching and Parsing.</title>
<date>1977</date>
<journal>Artificial Intelligence</journal>
<volume>9</volume>
<pages>111--134</pages>
<marker>Parkinson, Colby, Fought, 1977</marker>
<rawString>Parkinson, R.C., Colby, K.M., and Fought, W.S. (1977). Conversational Language Comprehension Using Integrated Pattern-Matching and Parsing. Artificial Intelligence 9, 111-134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C K Riesbeck</author>
</authors>
<title>Conceptual analysis. In</title>
<date>1975</date>
<location>New lork.</location>
<marker>Riesbeck, 1975</marker>
<rawString>Riesbeck, C. K. (1975). Conceptual analysis. In R. C. Schenk Conceptual Information Processing. American Elsevier ruolisPing uompany, inc., New lork.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C K</author>
<author>R C Schenk</author>
</authors>
<title>Comprehension by computer: expectation-based analysis of sentences in context.</title>
<date>1975</date>
<journal>Yale University Research Report</journal>
<volume>78</volume>
<marker>K, Schenk, 1975</marker>
<rawString>Riesbeck. C. K. and Schenk, R. C. (1975). Comprehension by computer: expectation-based analysis of sentences in context. Yale University Research Report 78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C</author>
</authors>
<title>Conceptual Information Processing.</title>
<date>1975</date>
<publisher>American Elsevier</publisher>
<note>Puolisning uompany, Inc., sew ioric.</note>
<marker>C, 1975</marker>
<rawString>Schenk. R. C. (1975). Conceptual Information Processing. American Elsevier Puolisning uompany, Inc., sew ioric.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Small</author>
</authors>
<title>Conceptual language analysis for story comprehension.</title>
<date>1978</date>
<tech>Technical Report No. 663,</tech>
<institution>Dept. of Computer Science, University of Maryland, College Park,</institution>
<location>Maryland.</location>
<marker>Small, 1978</marker>
<rawString>Small, S. (1978). Conceptual language analysis for story comprehension. Technical Report No. 663, Dept. of Computer Science, University of Maryland, College Park, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilke</author>
</authors>
<title>An Al Approach to Machine Translation.</title>
<date>1973</date>
<booktitle>In Computer Models of Thought and Language, R.C. Schenk and K.M: uoloy (eas77, W.H. Freeman and Co.,</booktitle>
<location>San Francisco,</location>
<marker>Wilke, 1973</marker>
<rawString>Wilke, Yorick (1973). An Al Approach to Machine Translation. In Computer Models of Thought and Language, R.C. Schenk and K.M: uoloy (eas77, W.H. Freeman and Co., San Francisco, 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Transition Network Grammars for Natural Language Analysis.</title>
<date>1970</date>
<journal>CACM</journal>
<volume>13</volume>
<pages>591--606</pages>
<contexts>
<context position="2663" citStr="Woods, 1970" startWordPosition="425" endWordPosition="426">re based on ideas about language that do not come to grips with the fact that a natural language processor needs a great deal of knowledge about the meaning of its languages utterances. Part of the problem is that most current natural language systems assume that the meaning of a natural language utterance can be computed as a function of the constituents of the utterance. The basic constituents of utterances are assumed to be words, and all the knowledge the system has about the semantics of its language is stored at the word level (Birnbaum et al, 1979) (Riesbeck et al, 1075) (Wilks, 1973) (Woods, 1970). However, many natural language utterances have interpretations that cannot be found by examining their components. Idioms, canned phrases, lexical collocations, and structural formulas are instances of large classes of language utterances whose interpretation require knowledge about the entire phrase independent of its individual words (Becker, 1975) (Mitchell, 1971). We propose as an alternative a model of language use that comes from viewing language processing systems as knowledge-based systems that require the representation and organization of large amounts of knowledge about what the u</context>
<context position="31548" citStr="Woods 1970" startWordPosition="5228" endWordPosition="5229">e with LITER, the language utterances acceptable to the system are 120 restricted to such an extent that many natural language processing problems need not be dealt with and other problems have solutions appropriate only to this context. In addition, SOPHIE does not produce any representation of the meaning of the input, and it makes more than one pass on the input ignoring unknown words, practices that have already been criticized. The augmented finite state transition network (ATN) has been used by a number of researchers to aid in the analysis of natural language sentences for example, see Woods 1970). However, most systems that use ATM&apos;s incorporate one feature which we find objectionable on both theoretical and practical grounds. This is the separation of analysis into syntactic and semantic phases. The efficacy and psychological validity of the separation of syntactic and semantic processing has been argued at length elsewhere (see Scha 1975 for example). In addition, most ATN based systems for oxample Woods&apos; LUNAR program) do not produce representations, but rather, run queries of a data base. In contrast to the systems just described, Wilks&apos; English-French machine ranslator does not s</context>
</contexts>
<marker>Woods, 1970</marker>
<rawString>Woods, W. A. (1970). Transition Network Grammars for Natural Language Analysis. CACM 13, 591-606.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>