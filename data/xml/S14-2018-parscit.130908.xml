<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000780">
<title confidence="0.9908455">
Biocom Usp: Tweet Sentiment Analysis with Adaptive Boosting
Ensemble
</title>
<author confidence="0.988003">
N´adia F. F. Silva, Eduardo R. Hruschka
</author>
<affiliation confidence="0.993647">
University of S˜ao Paulo, USP
</affiliation>
<address confidence="0.95356">
S˜ao Carlos, SP, Brazil
</address>
<email confidence="0.984586">
nadia, erh@icmc.usp.br
</email>
<author confidence="0.99033">
Estevam Rafael Hruschka Jr.
</author>
<affiliation confidence="0.9984505">
Department of Computer Science
Federal University of Sao Carlos.
</affiliation>
<address confidence="0.959186">
S˜ao Carlos, SP, Brazil
</address>
<email confidence="0.998197">
estevam@dc.ufscar.br
</email>
<sectionHeader confidence="0.993881" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998728777777778">
We describe our approach for the
SemEval-2014 task 9: Sentiment Analy-
sis in Twitter. We make use of an en-
semble learning method for sentiment
classification of tweets that relies on
varied features such as feature hash-
ing, part-of-speech, and lexical fea-
tures. Our system was evaluated in
the Twitter message-level task.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.968460298245614">
The sentiment analysis is a field of study that
investigates feelings present in texts. This
field of study has become important, espe-
cially due to the internet growth, the content
generated by its users, and the emergence of
the social networks. In the social networks
such as Twitter people post their opinions in a
colloquial and compact language, and it is be-
coming a large dataset, which can be used as
a source of information for various automatic
tools of sentiment inference. There is an enor-
mous interest in sentiment analysis of Twit-
ter messages, known as tweets, with applica-
tions in several segments, such as (i) directing
marketing campaigns, extracting consumer re-
views of services and products (Jansen et al.,
2009); (ii) identifying manifestations of bully-
ing (Xu et al., 2012); (iii) predicting to fore-
cast box-office revenues for movies (Asur and
Huberman, 2010); and (iv) predicting accep-
tance or rejection of presidential candidates
(Diakopoulos and Shamma, 2010; O’Connor
et al., 2010).
This work is licensed under a Creative
Commons Attribution 4.0 International Li-
cence. Page numbers and proceedings footer
are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
One of the problems encountered by re-
searchers in tweet sentiment analysis is the
scarcity of public datasets. Although Twit-
ter sentiment datasets have already been cre-
ated, they are either small — such as Obama-
McCain Debate corpus (Shamma et al., 2009)
and Health Care Reform corpus (Speriosu et
al., 2011) or big and proprietary such as in
(Lin and Kolcz, 2012). Others rely on noisy
labels obtained from emoticons and hashtags
(Go et al., 2009). The SemEval-2014 task 9: Sen-
timent Analysis in Twitter (Nakov et al., 2013)
provides a public dataset to be used to com-
pare the accuracy of different approaches.
In this paper, we propose to analyse tweet
sentiment with the use of Adaptive Boost-
ing (Freund and Schapire, 1997), making
use of the well-known Multinomial Classi-
fier. Boosting is an approach to machine
learning that is based on the idea of creat-
ing a highly accurate prediction rule by com-
bining many relatively weak and inaccurate
rules. The AdaBoost algorithm (Freund and
Schapire, 1997) was the first practical boost-
ing algorithm, and remains one of the most
widely used and studied, with applications in
numerous fields. Therefore, it has potential to
be very useful for tweet sentiment analysis, as
we address in this paper.
</bodyText>
<sectionHeader confidence="0.999765" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9997949">
Classifier ensembles for tweet sentiment anal-
ysis have been underexplored in the literature
— a few exceptions are (Lin and Kolcz, 2012;
Clark and Wicentwoski, 2013; Rodriguez et
al., 2013; Hassan et al., 2013).
Lin and Kolcz (2012) used logistic regres-
sion classifiers learned from hashed byte 4-
grams as features – The feature extractor con-
siders the tweet as a raw byte array. It moves
a four-byte sliding window along the array,
</bodyText>
<page confidence="0.991632">
129
</page>
<note confidence="0.7309995">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 129–134,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999983081081081">
and hashes the contents of the bytes, the value
of which was taken as the feature id. Here the
4-grams refers to four characters (and not to
four words). They made no attempt to per-
form any linguistic processing, not even word
tokenization. For each of the (proprietary)
datasets, they experimented with ensembles
of different sizes. The ensembles were formed
by different models, obtained from different
training sets, but with the same learning algo-
rithm (logistic regression). Their results show
that the ensembles lead to more accurate clas-
sifiers.
Rodr´ıgues et al. (2013) and Clark et al.
(2013) proposed the use of classifier ensem-
bles at the expression-level, which is related
to Contextual Polarity Disambiguation. In this
perspective, the sentiment label (positive,
negative, or neutral) is applied to a specific
phrase or word within the tweet and does not
necessarily match the sentiment of the entire
tweet.
Finally, another type of ensemble frame-
work has been recently proposed by Hassan
et al. (2013), who deal with class imbalance,
sparsity, and representational issues. The au-
thors propose to enrich the corpus using mul-
tiple additional datasets related to the task of
sentiment classification. Differently from pre-
vious works, the authors use a combination of
unigrams and bigrams of simple words, part-
of-speech, and semantic features.
None of the previous works used AdaBoost
(Freund and Schapire, 1996). Also, lexicons
and/or part-of-speech in combination with
feature hashing, like in (Lin and Kolcz, 2012)
have not been addressed in the literature.
</bodyText>
<sectionHeader confidence="0.953125" genericHeader="method">
3 AdaBoost Ensemble
</sectionHeader>
<bodyText confidence="0.999751380952381">
Boosting is a relatively young, yet extremely
powerful, machine learning technique. The
main idea behind boosting algorithms is to
combine multiple weak learners – classifi-
cation algorithms that perform only slightly
better than random guessing – into a power-
ful composite classifier. Our focus is on the
well known AdaBoost algorithm (Freund and
Schapire, 1997) based on Multinomial Naive
Bayes as base classifiers (Figure 1).
AdaBoost and its variants have been ap-
plied to diverse domains with great success,
owing to their solid theoretical foundation,
accurate prediction, and great simplicity (Fre-
und and Schapire, 1997). For example, Viola
and Jones (2001) used AdaBoost to face de-
tection, Hao and Luo (2006) dealt with im-
age segmentation, recognition of handwritten
digits, and outdoor scene classification prob-
lems. In (Bloehdorn and Hotho, 2004) text
classification is explored.
</bodyText>
<figureCaption confidence="0.998563">
Figure 1: AdaBoost Approach
</figureCaption>
<sectionHeader confidence="0.967262" genericHeader="method">
4 Feature Engineering
</sectionHeader>
<bodyText confidence="0.9999969">
The most commonly used text representation
method adopted in the literature is known as
Bag of Words (BOW) technique, where a doc-
ument is considered as a BOW, and is repre-
sented by a feature vector containing all the
words appearing in the corpus. In spite of
BOW being simple and very effective in text
classification, a large amount of information
from the original document is not considered,
word order is ruptured, and syntactic struc-
tures are broken. Therefore, sophisticated fea-
ture extraction methods with a deeper under-
standing of the documents are required for
sentiment classification tasks. Instead of us-
ing only BOW, alternative ways to represent
text, including Part of Speech (PoS) based fea-
tures, feature hashing, and lexicons have been
addressed in the literature.
We implemented an ensemble of classifiers
that receive as input data a combination of
three features sets: i) lexicon features that cap-
tures the semantic aspect of a tweet; ii) fea-
ture hashing that captures the surface-form as
abbreviations, slang terms from this type of
social network, elongated words (for exam-
ple, loveeeee), sentences with words without
a space between them (for instance, Ilovveap-
ple!), and so on; iii) and a specific syntactic fea-
tures for tweets. Technical details of each fea-
ture set are provided in the sequel.
</bodyText>
<subsectionHeader confidence="0.929215">
Lexicon Features
</subsectionHeader>
<bodyText confidence="0.999718666666667">
We use the sentimental lexicon provided by
(Thelwall et al., 2010) and (Hu and Liu, 2004).
The former is known as SentiStrength and
</bodyText>
<page confidence="0.981962">
130
</page>
<bodyText confidence="0.999840810810811">
provides: an emotion vocabulary, an emoti-
cons list (with positive, negative, and neutral
icons), a negation list, and a booster word list.
We use the negative list in cases where the
next term in a sentence is an opinion word
(either positive or negative). In such cases
we have polarity inversion. For example, in
the sentence “The house is not beautiful”, the
negative word “not” invert the polarity of the
opinion word beautiful. The booster word list
is composed by adverbs that suggest more or
less emphasis in the sentiment. For exam-
ple, in the sentence “He was incredibly rude.”
the term “incredibly” is an adverb that lay em-
phasis on the opinion word “rude”. Besides
using SentiStrength, we use the lexicon ap-
proach proposed by (Hu and Liu, 2004). In
their approach, a list of words and associa-
tions with positive and negative sentiments
has been provided that are very useful for
sentiment analysis.
These two lexicons were used to build the
first feature set according to Table 1, where it
is presented an example of tweet representa-
tion for the tweet1: “The soccer team didn’t
play extremely bad last Wednesday.” The
word “bad” exists in the lexicon list of (Hu
and Liu, 2004), and it is a negative word.
The word “bad” also exists in the negation
list provided by (Thelwall et al., 2010). The
term “didn’t” is a negative word according to
SentiStrength (Thelwall et al., 2010) and there
is a polarity inversion of the opinion words
ahead. Finally, the term “extremely” belongs
the booster word list and this word suggests
more emphasis to the opinion words existing
ahead.
</bodyText>
<table confidence="0.957378">
positive negative neutral class
tweet1 3 0 0 positive
</table>
<tableCaption confidence="0.8491425">
Table 1: Representing Twitter messages with
lexicons.
</tableCaption>
<bodyText confidence="0.99996695">
as input to a learning algorithm. The origi-
nal high-dimensional space is “reduced” by
hashing the features into a lower-dimensional
space, i.e., mapping features to hash keys.
Thus, multiple features can be mapped to the
same hash key, thereby “aggregating” their
counts.
We used the MurmurHash3 function
(SMHasher, 2010), that is a non-cryptographic
hash function suitable for general hash-based
lookup tables. It has been used for many
purposes, and a recent approach that has
emerged is its use for feature hashing or
hashing trick. Instead of building and storing
an explicit traditional bag-of-words with
n-grams, the feature hashing uses a hash
function to reduce the dimensionality of the
output space and the length of this space
(features) is explicitly fixed in advance. For
this paper, we used this code (in Python):
</bodyText>
<equation confidence="0.894985666666667">
Code Listing 1: Murmurhash:
from sklearn.utils.murmurhash
import murmurhash3_bytes_u32
for w in &amp;quot;i loveee apple&amp;quot;.split():
print(&amp;quot;{0} =&gt; {1}&amp;quot;.format(
w,murmurhash3_bytes_u32(w,0)%2**10))
</equation>
<bodyText confidence="0.99975">
The dimensionality is 2 ∗ ∗10, i.e 210 fea-
tures. In this code the output is a hash code
for each word “w” in the phrase “i loveee
apple”, i.e. i =&gt; 43, loveee =&gt; 381 and
apple =&gt; 144. Table 2 shows an example of
feature hashing representation.
</bodyText>
<table confidence="0.998648142857143">
1 2 3 4 ··· 1024 class
tweet1 0 0 1 1 ··· 0 positive
tweet2 0 1 0 3 ··· 0 negative
tweet3 2 0 0 0 ··· 0 positive
. .. .. .. ....... · · · ... .
.. .
tweetn 0 0 2 1 ··· 0 neutral
</table>
<tableCaption confidence="0.9799835">
Table 2: Representing Twitter messages with
feature hashing.
</tableCaption>
<subsectionHeader confidence="0.902429">
Feature hashing
</subsectionHeader>
<bodyText confidence="0.999988">
Feature hashing has been introduced for text
classification in (Shi et al., 2009), (Wein-
berger et al., 2009), (Forman and Kirshen-
baum, 2008), (Langford et al., 2007), (Caragea
et al., 2011). In the context of tweet classi-
fication, feature hashing offers an approach
to reducing the number of features provided
</bodyText>
<subsectionHeader confidence="0.946735">
Specific syntactic (PoS) features
</subsectionHeader>
<bodyText confidence="0.999988285714286">
We used the Part of Speech (PoS) tagged for
tweets with the Twitter NLP tool (Gimpel et
al., 2011). It encompasses 25 tags including
Nominal, Nominal plus Verbal, Other open-
class words like adjectives, adverbs and in-
terjection, Twitter specific tags such as hash-
tags, mention, discourse marker, just to name
</bodyText>
<page confidence="0.998976">
131
</page>
<tableCaption confidence="0.8406555">
a few. Table 3 shows an example of syntactic
features representation.
</tableCaption>
<table confidence="0.974100857142857">
tag, tag2 tag3 tag4 · · · tag25 class
tweet, 0 0 3 1 ··· 0 positive
tweet2 0 2 0 1 ··· 0 negative
tweet3 1 0 0 0 ··· 0 positive
. .. .. .. ....... · · · ... .
.. .
tweetn 0 0 1 1 ··· 0 neutral
</table>
<tableCaption confidence="0.9777265">
Table 3: Representing Twitter messages with
syntactic features.
</tableCaption>
<bodyText confidence="0.9982844">
A combination of lexicons, feature hashing,
and part-of-speech is used to train the ensem-
ble classifiers, thereby resulting in 1024 fea-
tures from feature hashing, 3 features from
lexicons, and 25 features from PoS.
</bodyText>
<sectionHeader confidence="0.991568" genericHeader="method">
5 Experimental Setup and Results
</sectionHeader>
<bodyText confidence="0.998605375">
We conducted experiments by using the
WEKA platform1. Table 4 shows the class dis-
tributions in training, development, and test-
ing sets. Table 5 presents the results for posi-
tive and negative classes with the classifiers
used in training set, and Table 6 shows the
computed results by SemEval organizers in
the test sets.
</bodyText>
<table confidence="0.998946076923077">
Training Set
Set Positive Negative Neutral Total
Train 3,640 (37%) 1,458 (15%) 4,586 (48%) 9,684
Development Set
Set Positive Negative Neutral Total
Dev 575 (35%) 340(20%) 739 (45%) 1,654
Testing Sets
Set Positive Negative Neutral Total
LiveJournal 427 (37%) 304 (27%) 411 (36%) 1,142
SMS2013 492 (23%) 394(19%) 1,207 (58%) 2,093
Twitter2013 1,572 (41%) 601 (16%) 1,640 (43%) 3,813
Twitter2014 982 (53%) 202 (11%) 669 (36%) 1,853
Twitter2014Sar 33 (38%) 40 (47%) 13 (15%) 86
</table>
<tableCaption confidence="0.708183">
Table 4: Class distributions in the training set
(Train), development set (Dev) and testing set
(Test).
</tableCaption>
<sectionHeader confidence="0.979649" genericHeader="method">
6 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999253">
From our results, we conclude that the use of
AdaBoost provides good performance in the
sentiment analysis (message-level subtask).
In the cross-validation process, Multinomial
Naive Bayes (MNB) has shown better results
than Support Vector Machines (SVM) as a
component for AdaBoost. However, we feel
</bodyText>
<footnote confidence="0.980414">
1http://www.cs.waikato.ac.nz/ml/weka/
</footnote>
<table confidence="0.999760166666667">
Set Algorithm F-Measure F-Measure Average
Positive Negative
Train MNB 63.40 49.40 56.40
Train SVM 64.00 44.50 54.20
Train AdaBoost w/ SVM 62.50 44.50 53.50
Train AdaBoost w/ MNB 65.10 49.60 57.35
</table>
<tableCaption confidence="0.995522">
Table 5: Results from 10-fold cross validation
</tableCaption>
<bodyText confidence="0.5817015">
in the training set with default parameters of
Weka. MNB and SVM stand for Multinomial
Naive Bayes and Support Vector Machine, re-
spectively.
</bodyText>
<table confidence="0.999738692307693">
Scoring LiveJournal2014
class precision recall F-measure
positive 69.79 64.92 67.27
negative 76.64 61.64 68.33
neutral 51.82 69.84 59.50
overall score: 67.80
Scoring SMS2013
positive 61.99 46.78 53.32
negative 72.34 42.86 53.82
neutral 53.85 83.76 65.56
overall score: 53.57
Scoring Twitter2013
positive 68.07 66.13 67.08
negative 48.09 50.00 49.02
neutral 67.20 68.15 67.67
overall score: 58.05
Scoring Twitter2014
positive 65.17 70.48 67.72
negative 53.47 48.21 50.70
neutral 59.94 55.62 57.70
overall score: 59.21
Scoring Twitter2014Sarcasm
positive 63.64 44.68 52.50
negative 22.50 75.00, 34.62
neutral 76.92 37.04 50.00
overall score: 43.56
</table>
<tableCaption confidence="0.996752">
Table 6: Results in the test sets — AdaBoost
</tableCaption>
<bodyText confidence="0.913478666666667">
plus Multinomial Naive Bayes, which was the
best algorithm in cross validation.
that further investigations are necessary be-
fore making strong claims about this result.
Overall, the SemEval Tasks have make evi-
dent the usual challenges when mining opin-
ions from Social Media channels: noisy text,
irregular grammar and orthography, highly
specific lingo, and others. Moreover, tempo-
ral dependencies can affect the performance if
the training and test data have been gathered
at different.
</bodyText>
<sectionHeader confidence="0.980162" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999738666666667">
The authors would like to thank the Re-
search Agencies CAPES, FAPESP, and CNPq
for their financial support.
</bodyText>
<sectionHeader confidence="0.87798" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.542515333333333">
Sitaram Asur and Bernardo A. Huberman. 2010.
Predicting the future with social media. In Pro-
ceedings of the 2010 International Conference on
</bodyText>
<page confidence="0.99202">
132
</page>
<reference confidence="0.962708728070176">
Web Intelligence and Intelligent Agent Technology
- Volume 01, WI-IAT ’10, pages 492–499, Wash-
ington, DC, USA. IEEE Computer Society.
Stephan Bloehdorn and Andreas Hotho. 2004.
Text classification by boosting weak learners
based on terms and concepts. In Proceedings of
the Fourth IEEE International Conference on Data
Mining, pages 331–334. IEEE Computer Society
Press, November.
Cornelia Caragea, Adrian Silvescu, and Prasen-
jit Mitra. 2011. Protein sequence classifica-
tion using feature hashing. In Fang-Xiang Wu,
Mohammed Javeed Zaki, Shinichi Morishita,
Yi Pan, Stephen Wong, Anastasia Christianson,
and Xiaohua Hu, editors, BIBM, pages 538–543.
IEEE.
Sam Clark and Rich Wicentwoski. 2013. Swatcs:
Combining simple classifiers with estimated
accuracy. In Second Joint Conference on Lexical
and Computational Semantics (*SEM), Volume 2:
Proceedings of the Seventh International Workshop
on Semantic Evaluation (SemEval 2013), pages
425–429, Atlanta, Georgia, USA, June.
Nicholas A. Diakopoulos and David A. Shamma.
2010. Characterizing debate performance via
aggregated twitter sentiment. In Proceedings of
the SIGCHI Conference on Human Factors in Com-
puting Systems, CHI ’10, pages 1195–1198, New
York, NY, USA. ACM.
George Forman and Evan Kirshenbaum. 2008.
Extremely fast text feature extraction for clas-
sification and indexing. In CIKM ’08: Proceed-
ing of the 17th ACM conference on Information and
knowledge management, pages 1221–1230, New
York, NY, USA. ACM.
Yoav Freund and Robert E. Schapire. 1996. Ex-
periments with a new boosting algorithm. In
Thirteenth International Conference on Machine
Learning, pages 148–156, San Francisco. Morgan
Kaufmann.
Yoav Freund and Robert E Schapire. 1997.
A decision-theoretic generalization of on-line
learning and an application to boosting. Jour-
nal of Computer and System Sciences, 55(1):119 –
139.
Kevin Gimpel, Nathan Schneider, Brendan
O’Connor, Dipanjan Das, Daniel Mills, Jacob
Eisenstein, Michael Heilman, Dani Yogatama,
Jeffrey Flanigan, and Noah A. Smith. 2011.
Part-of-speech tagging for twitter: Annotation,
features, and experiments. In Proceedings of
the 49th Annual Meeting of the Association for
Computational Linguistics – Short Papers - Volume
2, HLT ’11, pages 42–47, Stroudsburg, PA, USA.
Alec Go, Richa Bhayani, and Lei Huang. 2009.
Twitter sentiment classification using distant
supervision. Processing, pages 1–6.
Wei Hao and Jiebo Luo. 2006. Generalized
Multiclass AdaBoost and Its Applications to
Multimedia Classification. In Computer Vision
and Pattern Recognition Workshop, 2006. CVPRW
&apos;06. Conference on, page 113, Washington,
DC, USA, June. IEEE.
Ammar Hassan, Ahmed Abbasi, and Daniel
Zeng. 2013. Twitter sentiment analysis: A
bootstrap ensemble framework. In SocialCom,
pages 357–364. IEEE.
Minqing Hu and Bing Liu. 2004. Mining and
summarizing customer reviews. In Proceed-
ings of the tenth ACM SIGKDD international con-
ference on Knowledge discovery and data mining,
KDD ’04, pages 168–177, New York, NY, USA.
ACM.
Bernard J. Jansen, Mimi Zhang, Kate Sobel, and
Abdur Chowdury. 2009. Twitter power:
Tweets as electronic word of mouth. J. Am. Soc.
Inf. Sci. Technol., 60(11):2169–2188, nov.
John Langford, Alex Strehl, and Lihong Li. 2007.
Vowpal wabbit online learning project. http:
//mloss.org/software/view/53/.
Jimmy Lin and Alek Kolcz. 2012. Large-scale ma-
chine learning at twitter. In Proceedings of the
2012 ACM SIGMOD International Conference on
Management of Data, SIGMOD ’12, pages 793–
804, New York, NY, USA. ACM.
Preslav Nakov, Sara Rosenthal, Zornitsa
Kozareva, Veselin Stoyanov, Alan Ritter,
and Theresa Wilson. 2013. Semeval-2013 task
2: Sentiment analysis in twitter. In Second
Joint Conference on Lexical and Computational
Semantics (*SEM), Volume 2: Proceedings of the
Seventh International Workshop on Semantic Eval-
uation (SemEval 2013), pages 312–320, Atlanta,
Georgia, USA, June.
Brendan O’Connor, Ramnath Balasubramanyan,
Bryan R. Routledge, and Noah A. Smith. 2010.
From tweets to polls: Linking text sentiment to
public opinion time series. In ICWSM’10, pages
1–1.
Penagos Carlos Rodriguez, Jordi Atserias, Joan
Codina-Filba, David Garcıa-Narbona, Jens
Grivolla, Patrik Lambert, and Roser Saurı.
2013. Fbm: Combining lexicon-based ml and
heuristics for social media polarities. In Pro-
ceedings of SemEval-2013 – International Work-
shop on Semantic Evaluation Co-located with *Sem
and NAACL, Atlanta, Georgia. Url date at 2013-
10-10.
David A. Shamma, Lyndon Kennedy, and Eliz-
abeth F. Churchill. 2009. Tweet the debates:
Understanding community annotation of un-
collected sources. In In WSM ?09: Proceedings
of the international workshop on Workshop on So-
cial.
</reference>
<page confidence="0.989215">
133
</page>
<reference confidence="0.999645903225806">
Qinfeng Shi, James Petterson, Gideon Dror,
John Langford, Alex Smola, and S.V.N. Vish-
wanathan. 2009. Hash kernels for structured
data. J. Mach. Learn. Res., 10:2615–2637.
SMHasher. 2010. The murmurhash family of
hash functions.
Michael Speriosu, Nikita Sudan, Sid Upadhyay,
and Jason Baldridge. 2011. Twitter polarity
classification with label propagation over lexi-
cal links and the follower graph. In Proceedings
of the First Workshop on Unsupervised Learning in
NLP, pages 53–63, Stroudsburg, PA, USA.
Mike Thelwall, Kevan Buckley, Georgios Pal-
toglou, Di Cai, and Arvid Kappas. 2010. Senti-
ment in short strength detection informal text.
J. Am. Soc. Inf. Sci. Technol., 61(12):2544–2558,
December.
Paul Viola and Michael Jones. 2001. Robust real-
time object detection. In International Journal of
Computer Vision.
Kilian Q. Weinberger, Anirban Dasgupta, John
Langford, Alexander J. Smola, and Josh Atten-
berg. 2009. Feature hashing for large scale mul-
titask learning. In Andrea Pohoreckyj Dany-
luk, L Bottou, and Michael L. Littman, editors,
ICML, volume 382 of ACM International Confer-
ence Proceeding Series, page 140. ACM.
Jun-Ming Xu, Kwang-Sung Jun, Xiaojin Zhu, and
Amy Bellmore. 2012. Learning from bullying
traces in social media. In HLT-NAACL, pages
656–666.
</reference>
<page confidence="0.998631">
134
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.513900">
<title confidence="0.988229">Biocom Usp: Tweet Sentiment Analysis with Adaptive Boosting Ensemble</title>
<author confidence="0.993061">N´adia F F Silva</author>
<author confidence="0.993061">R Eduardo</author>
<affiliation confidence="0.82683">of Paulo,</affiliation>
<address confidence="0.727089">Carlos, SP,</address>
<email confidence="0.910453">nadia,erh@icmc.usp.br</email>
<author confidence="0.997097">Estevam Rafael Hruschka</author>
<affiliation confidence="0.9958385">Department of Computer Federal University of Sao</affiliation>
<address confidence="0.823338">Carlos, SP,</address>
<email confidence="0.991256">estevam@dc.ufscar.br</email>
<abstract confidence="0.994765">We describe our approach for the SemEval-2014 task 9: Sentiment Analyin We make use of an ensemble learning method for sentiment classification of tweets that relies on varied features such as feature hashing, part-of-speech, and lexical features. Our system was evaluated in the Twitter message-level task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Web</author>
</authors>
<title>Intelligence and Intelligent Agent Technology - Volume 01,</title>
<journal>WI-IAT</journal>
<volume>10</volume>
<pages>492--499</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<marker>Web, </marker>
<rawString>Web Intelligence and Intelligent Agent Technology - Volume 01, WI-IAT ’10, pages 492–499, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Andreas Hotho</author>
</authors>
<title>Text classification by boosting weak learners based on terms and concepts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth IEEE International Conference on Data Mining,</booktitle>
<pages>331--334</pages>
<publisher>IEEE Computer Society Press,</publisher>
<contexts>
<context position="6167" citStr="Bloehdorn and Hotho, 2004" startWordPosition="971" endWordPosition="974"> random guessing – into a powerful composite classifier. Our focus is on the well known AdaBoost algorithm (Freund and Schapire, 1997) based on Multinomial Naive Bayes as base classifiers (Figure 1). AdaBoost and its variants have been applied to diverse domains with great success, owing to their solid theoretical foundation, accurate prediction, and great simplicity (Freund and Schapire, 1997). For example, Viola and Jones (2001) used AdaBoost to face detection, Hao and Luo (2006) dealt with image segmentation, recognition of handwritten digits, and outdoor scene classification problems. In (Bloehdorn and Hotho, 2004) text classification is explored. Figure 1: AdaBoost Approach 4 Feature Engineering The most commonly used text representation method adopted in the literature is known as Bag of Words (BOW) technique, where a document is considered as a BOW, and is represented by a feature vector containing all the words appearing in the corpus. In spite of BOW being simple and very effective in text classification, a large amount of information from the original document is not considered, word order is ruptured, and syntactic structures are broken. Therefore, sophisticated feature extraction methods with a </context>
</contexts>
<marker>Bloehdorn, Hotho, 2004</marker>
<rawString>Stephan Bloehdorn and Andreas Hotho. 2004. Text classification by boosting weak learners based on terms and concepts. In Proceedings of the Fourth IEEE International Conference on Data Mining, pages 331–334. IEEE Computer Society Press, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cornelia Caragea</author>
<author>Adrian Silvescu</author>
<author>Prasenjit Mitra</author>
</authors>
<title>Protein sequence classification using feature hashing.</title>
<date>2011</date>
<pages>538--543</pages>
<editor>In Fang-Xiang Wu, Mohammed Javeed Zaki, Shinichi Morishita, Yi Pan, Stephen Wong, Anastasia Christianson, and Xiaohua Hu, editors, BIBM,</editor>
<publisher>IEEE.</publisher>
<contexts>
<context position="11118" citStr="Caragea et al., 2011" startWordPosition="1802" endWordPosition="1805">utput is a hash code for each word “w” in the phrase “i loveee apple”, i.e. i =&gt; 43, loveee =&gt; 381 and apple =&gt; 144. Table 2 shows an example of feature hashing representation. 1 2 3 4 ··· 1024 class tweet1 0 0 1 1 ··· 0 positive tweet2 0 1 0 3 ··· 0 negative tweet3 2 0 0 0 ··· 0 positive . .. .. .. ....... · · · ... . .. . tweetn 0 0 2 1 ··· 0 neutral Table 2: Representing Twitter messages with feature hashing. Feature hashing Feature hashing has been introduced for text classification in (Shi et al., 2009), (Weinberger et al., 2009), (Forman and Kirshenbaum, 2008), (Langford et al., 2007), (Caragea et al., 2011). In the context of tweet classification, feature hashing offers an approach to reducing the number of features provided Specific syntactic (PoS) features We used the Part of Speech (PoS) tagged for tweets with the Twitter NLP tool (Gimpel et al., 2011). It encompasses 25 tags including Nominal, Nominal plus Verbal, Other openclass words like adjectives, adverbs and interjection, Twitter specific tags such as hashtags, mention, discourse marker, just to name 131 a few. Table 3 shows an example of syntactic features representation. tag, tag2 tag3 tag4 · · · tag25 class tweet, 0 0 3 1 ··· 0 posi</context>
</contexts>
<marker>Caragea, Silvescu, Mitra, 2011</marker>
<rawString>Cornelia Caragea, Adrian Silvescu, and Prasenjit Mitra. 2011. Protein sequence classification using feature hashing. In Fang-Xiang Wu, Mohammed Javeed Zaki, Shinichi Morishita, Yi Pan, Stephen Wong, Anastasia Christianson, and Xiaohua Hu, editors, BIBM, pages 538–543. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sam Clark</author>
<author>Rich Wicentwoski</author>
</authors>
<title>Swatcs: Combining simple classifiers with estimated accuracy.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>425--429</pages>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="3311" citStr="Clark and Wicentwoski, 2013" startWordPosition="524" endWordPosition="527">approach to machine learning that is based on the idea of creating a highly accurate prediction rule by combining many relatively weak and inaccurate rules. The AdaBoost algorithm (Freund and Schapire, 1997) was the first practical boosting algorithm, and remains one of the most widely used and studied, with applications in numerous fields. Therefore, it has potential to be very useful for tweet sentiment analysis, as we address in this paper. 2 Related Work Classifier ensembles for tweet sentiment analysis have been underexplored in the literature — a few exceptions are (Lin and Kolcz, 2012; Clark and Wicentwoski, 2013; Rodriguez et al., 2013; Hassan et al., 2013). Lin and Kolcz (2012) used logistic regression classifiers learned from hashed byte 4- grams as features – The feature extractor considers the tweet as a raw byte array. It moves a four-byte sliding window along the array, 129 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 129–134, Dublin, Ireland, August 23-24, 2014. and hashes the contents of the bytes, the value of which was taken as the feature id. Here the 4-grams refers to four characters (and not to four words). They made no attempt to perform any</context>
</contexts>
<marker>Clark, Wicentwoski, 2013</marker>
<rawString>Sam Clark and Rich Wicentwoski. 2013. Swatcs: Combining simple classifiers with estimated accuracy. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 425–429, Atlanta, Georgia, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas A Diakopoulos</author>
<author>David A Shamma</author>
</authors>
<title>Characterizing debate performance via aggregated twitter sentiment.</title>
<date>2010</date>
<booktitle>In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI ’10,</booktitle>
<pages>1195--1198</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1651" citStr="Diakopoulos and Shamma, 2010" startWordPosition="255" endWordPosition="258"> it is becoming a large dataset, which can be used as a source of information for various automatic tools of sentiment inference. There is an enormous interest in sentiment analysis of Twitter messages, known as tweets, with applications in several segments, such as (i) directing marketing campaigns, extracting consumer reviews of services and products (Jansen et al., 2009); (ii) identifying manifestations of bullying (Xu et al., 2012); (iii) predicting to forecast box-office revenues for movies (Asur and Huberman, 2010); and (iv) predicting acceptance or rejection of presidential candidates (Diakopoulos and Shamma, 2010; O’Connor et al., 2010). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ One of the problems encountered by researchers in tweet sentiment analysis is the scarcity of public datasets. Although Twitter sentiment datasets have already been created, they are either small — such as ObamaMcCain Debate corpus (Shamma et al., 2009) and Health Care Reform corpus (Speriosu et al., 2011) or big and proprietary such as in (Lin and Kolcz, 2012</context>
</contexts>
<marker>Diakopoulos, Shamma, 2010</marker>
<rawString>Nicholas A. Diakopoulos and David A. Shamma. 2010. Characterizing debate performance via aggregated twitter sentiment. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI ’10, pages 1195–1198, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Forman</author>
<author>Evan Kirshenbaum</author>
</authors>
<title>Extremely fast text feature extraction for classification and indexing.</title>
<date>2008</date>
<booktitle>In CIKM ’08: Proceeding of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>1221--1230</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="11069" citStr="Forman and Kirshenbaum, 2008" startWordPosition="1793" endWordPosition="1797">ionality is 2 ∗ ∗10, i.e 210 features. In this code the output is a hash code for each word “w” in the phrase “i loveee apple”, i.e. i =&gt; 43, loveee =&gt; 381 and apple =&gt; 144. Table 2 shows an example of feature hashing representation. 1 2 3 4 ··· 1024 class tweet1 0 0 1 1 ··· 0 positive tweet2 0 1 0 3 ··· 0 negative tweet3 2 0 0 0 ··· 0 positive . .. .. .. ....... · · · ... . .. . tweetn 0 0 2 1 ··· 0 neutral Table 2: Representing Twitter messages with feature hashing. Feature hashing Feature hashing has been introduced for text classification in (Shi et al., 2009), (Weinberger et al., 2009), (Forman and Kirshenbaum, 2008), (Langford et al., 2007), (Caragea et al., 2011). In the context of tweet classification, feature hashing offers an approach to reducing the number of features provided Specific syntactic (PoS) features We used the Part of Speech (PoS) tagged for tweets with the Twitter NLP tool (Gimpel et al., 2011). It encompasses 25 tags including Nominal, Nominal plus Verbal, Other openclass words like adjectives, adverbs and interjection, Twitter specific tags such as hashtags, mention, discourse marker, just to name 131 a few. Table 3 shows an example of syntactic features representation. tag, tag2 tag3</context>
</contexts>
<marker>Forman, Kirshenbaum, 2008</marker>
<rawString>George Forman and Evan Kirshenbaum. 2008. Extremely fast text feature extraction for classification and indexing. In CIKM ’08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 1221–1230, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Robert E Schapire</author>
</authors>
<title>Experiments with a new boosting algorithm.</title>
<date>1996</date>
<booktitle>In Thirteenth International Conference on Machine Learning,</booktitle>
<pages>148--156</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>San Francisco.</location>
<contexts>
<context position="5144" citStr="Freund and Schapire, 1996" startWordPosition="815" endWordPosition="818">) is applied to a specific phrase or word within the tweet and does not necessarily match the sentiment of the entire tweet. Finally, another type of ensemble framework has been recently proposed by Hassan et al. (2013), who deal with class imbalance, sparsity, and representational issues. The authors propose to enrich the corpus using multiple additional datasets related to the task of sentiment classification. Differently from previous works, the authors use a combination of unigrams and bigrams of simple words, partof-speech, and semantic features. None of the previous works used AdaBoost (Freund and Schapire, 1996). Also, lexicons and/or part-of-speech in combination with feature hashing, like in (Lin and Kolcz, 2012) have not been addressed in the literature. 3 AdaBoost Ensemble Boosting is a relatively young, yet extremely powerful, machine learning technique. The main idea behind boosting algorithms is to combine multiple weak learners – classification algorithms that perform only slightly better than random guessing – into a powerful composite classifier. Our focus is on the well known AdaBoost algorithm (Freund and Schapire, 1997) based on Multinomial Naive Bayes as base classifiers (Figure 1). Ada</context>
</contexts>
<marker>Freund, Schapire, 1996</marker>
<rawString>Yoav Freund and Robert E. Schapire. 1996. Experiments with a new boosting algorithm. In Thirteenth International Conference on Machine Learning, pages 148–156, San Francisco. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Robert E Schapire</author>
</authors>
<title>A decision-theoretic generalization of on-line learning and an application to boosting.</title>
<date>1997</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>55</volume>
<issue>1</issue>
<pages>139</pages>
<contexts>
<context position="2614" citStr="Freund and Schapire, 1997" startWordPosition="410" endWordPosition="413">c datasets. Although Twitter sentiment datasets have already been created, they are either small — such as ObamaMcCain Debate corpus (Shamma et al., 2009) and Health Care Reform corpus (Speriosu et al., 2011) or big and proprietary such as in (Lin and Kolcz, 2012). Others rely on noisy labels obtained from emoticons and hashtags (Go et al., 2009). The SemEval-2014 task 9: Sentiment Analysis in Twitter (Nakov et al., 2013) provides a public dataset to be used to compare the accuracy of different approaches. In this paper, we propose to analyse tweet sentiment with the use of Adaptive Boosting (Freund and Schapire, 1997), making use of the well-known Multinomial Classifier. Boosting is an approach to machine learning that is based on the idea of creating a highly accurate prediction rule by combining many relatively weak and inaccurate rules. The AdaBoost algorithm (Freund and Schapire, 1997) was the first practical boosting algorithm, and remains one of the most widely used and studied, with applications in numerous fields. Therefore, it has potential to be very useful for tweet sentiment analysis, as we address in this paper. 2 Related Work Classifier ensembles for tweet sentiment analysis have been underex</context>
<context position="5675" citStr="Freund and Schapire, 1997" startWordPosition="895" endWordPosition="898">ch, and semantic features. None of the previous works used AdaBoost (Freund and Schapire, 1996). Also, lexicons and/or part-of-speech in combination with feature hashing, like in (Lin and Kolcz, 2012) have not been addressed in the literature. 3 AdaBoost Ensemble Boosting is a relatively young, yet extremely powerful, machine learning technique. The main idea behind boosting algorithms is to combine multiple weak learners – classification algorithms that perform only slightly better than random guessing – into a powerful composite classifier. Our focus is on the well known AdaBoost algorithm (Freund and Schapire, 1997) based on Multinomial Naive Bayes as base classifiers (Figure 1). AdaBoost and its variants have been applied to diverse domains with great success, owing to their solid theoretical foundation, accurate prediction, and great simplicity (Freund and Schapire, 1997). For example, Viola and Jones (2001) used AdaBoost to face detection, Hao and Luo (2006) dealt with image segmentation, recognition of handwritten digits, and outdoor scene classification problems. In (Bloehdorn and Hotho, 2004) text classification is explored. Figure 1: AdaBoost Approach 4 Feature Engineering The most commonly used t</context>
</contexts>
<marker>Freund, Schapire, 1997</marker>
<rawString>Yoav Freund and Robert E Schapire. 1997. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119 – 139.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: Annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics – Short Papers - Volume 2, HLT ’11,</booktitle>
<pages>42--47</pages>
<location>Stroudsburg, PA, USA.</location>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics – Short Papers - Volume 2, HLT ’11, pages 42–47, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alec Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision.</title>
<date>2009</date>
<booktitle>Processing,</booktitle>
<pages>1--6</pages>
<contexts>
<context position="2336" citStr="Go et al., 2009" startWordPosition="362" endWordPosition="365">ons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ One of the problems encountered by researchers in tweet sentiment analysis is the scarcity of public datasets. Although Twitter sentiment datasets have already been created, they are either small — such as ObamaMcCain Debate corpus (Shamma et al., 2009) and Health Care Reform corpus (Speriosu et al., 2011) or big and proprietary such as in (Lin and Kolcz, 2012). Others rely on noisy labels obtained from emoticons and hashtags (Go et al., 2009). The SemEval-2014 task 9: Sentiment Analysis in Twitter (Nakov et al., 2013) provides a public dataset to be used to compare the accuracy of different approaches. In this paper, we propose to analyse tweet sentiment with the use of Adaptive Boosting (Freund and Schapire, 1997), making use of the well-known Multinomial Classifier. Boosting is an approach to machine learning that is based on the idea of creating a highly accurate prediction rule by combining many relatively weak and inaccurate rules. The AdaBoost algorithm (Freund and Schapire, 1997) was the first practical boosting algorithm, </context>
</contexts>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter sentiment classification using distant supervision. Processing, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Hao</author>
<author>Jiebo Luo</author>
</authors>
<title>Generalized Multiclass AdaBoost and Its Applications to Multimedia Classification.</title>
<date>2006</date>
<booktitle>In Computer Vision and Pattern Recognition Workshop,</booktitle>
<pages>113</pages>
<publisher>IEEE.</publisher>
<location>Washington, DC, USA,</location>
<contexts>
<context position="6027" citStr="Hao and Luo (2006)" startWordPosition="951" endWordPosition="954">a behind boosting algorithms is to combine multiple weak learners – classification algorithms that perform only slightly better than random guessing – into a powerful composite classifier. Our focus is on the well known AdaBoost algorithm (Freund and Schapire, 1997) based on Multinomial Naive Bayes as base classifiers (Figure 1). AdaBoost and its variants have been applied to diverse domains with great success, owing to their solid theoretical foundation, accurate prediction, and great simplicity (Freund and Schapire, 1997). For example, Viola and Jones (2001) used AdaBoost to face detection, Hao and Luo (2006) dealt with image segmentation, recognition of handwritten digits, and outdoor scene classification problems. In (Bloehdorn and Hotho, 2004) text classification is explored. Figure 1: AdaBoost Approach 4 Feature Engineering The most commonly used text representation method adopted in the literature is known as Bag of Words (BOW) technique, where a document is considered as a BOW, and is represented by a feature vector containing all the words appearing in the corpus. In spite of BOW being simple and very effective in text classification, a large amount of information from the original document</context>
</contexts>
<marker>Hao, Luo, 2006</marker>
<rawString>Wei Hao and Jiebo Luo. 2006. Generalized Multiclass AdaBoost and Its Applications to Multimedia Classification. In Computer Vision and Pattern Recognition Workshop, 2006. CVPRW &amp;#039;06. Conference on, page 113, Washington, DC, USA, June. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ammar Hassan</author>
<author>Ahmed Abbasi</author>
<author>Daniel Zeng</author>
</authors>
<title>Twitter sentiment analysis: A bootstrap ensemble framework.</title>
<date>2013</date>
<booktitle>In SocialCom,</booktitle>
<pages>357--364</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="3357" citStr="Hassan et al., 2013" startWordPosition="532" endWordPosition="535">a of creating a highly accurate prediction rule by combining many relatively weak and inaccurate rules. The AdaBoost algorithm (Freund and Schapire, 1997) was the first practical boosting algorithm, and remains one of the most widely used and studied, with applications in numerous fields. Therefore, it has potential to be very useful for tweet sentiment analysis, as we address in this paper. 2 Related Work Classifier ensembles for tweet sentiment analysis have been underexplored in the literature — a few exceptions are (Lin and Kolcz, 2012; Clark and Wicentwoski, 2013; Rodriguez et al., 2013; Hassan et al., 2013). Lin and Kolcz (2012) used logistic regression classifiers learned from hashed byte 4- grams as features – The feature extractor considers the tweet as a raw byte array. It moves a four-byte sliding window along the array, 129 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 129–134, Dublin, Ireland, August 23-24, 2014. and hashes the contents of the bytes, the value of which was taken as the feature id. Here the 4-grams refers to four characters (and not to four words). They made no attempt to perform any linguistic processing, not even word tokeniza</context>
<context position="4737" citStr="Hassan et al. (2013)" startWordPosition="753" endWordPosition="756">different training sets, but with the same learning algorithm (logistic regression). Their results show that the ensembles lead to more accurate classifiers. Rodr´ıgues et al. (2013) and Clark et al. (2013) proposed the use of classifier ensembles at the expression-level, which is related to Contextual Polarity Disambiguation. In this perspective, the sentiment label (positive, negative, or neutral) is applied to a specific phrase or word within the tweet and does not necessarily match the sentiment of the entire tweet. Finally, another type of ensemble framework has been recently proposed by Hassan et al. (2013), who deal with class imbalance, sparsity, and representational issues. The authors propose to enrich the corpus using multiple additional datasets related to the task of sentiment classification. Differently from previous works, the authors use a combination of unigrams and bigrams of simple words, partof-speech, and semantic features. None of the previous works used AdaBoost (Freund and Schapire, 1996). Also, lexicons and/or part-of-speech in combination with feature hashing, like in (Lin and Kolcz, 2012) have not been addressed in the literature. 3 AdaBoost Ensemble Boosting is a relatively</context>
</contexts>
<marker>Hassan, Abbasi, Zeng, 2013</marker>
<rawString>Ammar Hassan, Ahmed Abbasi, and Daniel Zeng. 2013. Twitter sentiment analysis: A bootstrap ensemble framework. In SocialCom, pages 357–364. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7676" citStr="Hu and Liu, 2004" startWordPosition="1216" endWordPosition="1219"> of classifiers that receive as input data a combination of three features sets: i) lexicon features that captures the semantic aspect of a tweet; ii) feature hashing that captures the surface-form as abbreviations, slang terms from this type of social network, elongated words (for example, loveeeee), sentences with words without a space between them (for instance, Ilovveapple!), and so on; iii) and a specific syntactic features for tweets. Technical details of each feature set are provided in the sequel. Lexicon Features We use the sentimental lexicon provided by (Thelwall et al., 2010) and (Hu and Liu, 2004). The former is known as SentiStrength and 130 provides: an emotion vocabulary, an emoticons list (with positive, negative, and neutral icons), a negation list, and a booster word list. We use the negative list in cases where the next term in a sentence is an opinion word (either positive or negative). In such cases we have polarity inversion. For example, in the sentence “The house is not beautiful”, the negative word “not” invert the polarity of the opinion word beautiful. The booster word list is composed by adverbs that suggest more or less emphasis in the sentiment. For example, in the se</context>
<context position="8910" citStr="Hu and Liu, 2004" startWordPosition="1429" endWordPosition="1432">credibly rude.” the term “incredibly” is an adverb that lay emphasis on the opinion word “rude”. Besides using SentiStrength, we use the lexicon approach proposed by (Hu and Liu, 2004). In their approach, a list of words and associations with positive and negative sentiments has been provided that are very useful for sentiment analysis. These two lexicons were used to build the first feature set according to Table 1, where it is presented an example of tweet representation for the tweet1: “The soccer team didn’t play extremely bad last Wednesday.” The word “bad” exists in the lexicon list of (Hu and Liu, 2004), and it is a negative word. The word “bad” also exists in the negation list provided by (Thelwall et al., 2010). The term “didn’t” is a negative word according to SentiStrength (Thelwall et al., 2010) and there is a polarity inversion of the opinion words ahead. Finally, the term “extremely” belongs the booster word list and this word suggests more emphasis to the opinion words existing ahead. positive negative neutral class tweet1 3 0 0 positive Table 1: Representing Twitter messages with lexicons. as input to a learning algorithm. The original high-dimensional space is “reduced” by hashing </context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04, pages 168–177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard J Jansen</author>
<author>Mimi Zhang</author>
<author>Kate Sobel</author>
<author>Abdur Chowdury</author>
</authors>
<title>Twitter power: Tweets as electronic word of mouth.</title>
<date>2009</date>
<journal>J. Am. Soc. Inf. Sci. Technol.,</journal>
<volume>60</volume>
<issue>11</issue>
<contexts>
<context position="1399" citStr="Jansen et al., 2009" startWordPosition="218" endWordPosition="221">s become important, especially due to the internet growth, the content generated by its users, and the emergence of the social networks. In the social networks such as Twitter people post their opinions in a colloquial and compact language, and it is becoming a large dataset, which can be used as a source of information for various automatic tools of sentiment inference. There is an enormous interest in sentiment analysis of Twitter messages, known as tweets, with applications in several segments, such as (i) directing marketing campaigns, extracting consumer reviews of services and products (Jansen et al., 2009); (ii) identifying manifestations of bullying (Xu et al., 2012); (iii) predicting to forecast box-office revenues for movies (Asur and Huberman, 2010); and (iv) predicting acceptance or rejection of presidential candidates (Diakopoulos and Shamma, 2010; O’Connor et al., 2010). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ One of the problems encountered by researchers in tweet sentiment analysis is the scarcity of public datasets.</context>
</contexts>
<marker>Jansen, Zhang, Sobel, Chowdury, 2009</marker>
<rawString>Bernard J. Jansen, Mimi Zhang, Kate Sobel, and Abdur Chowdury. 2009. Twitter power: Tweets as electronic word of mouth. J. Am. Soc. Inf. Sci. Technol., 60(11):2169–2188, nov.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Langford</author>
<author>Alex Strehl</author>
<author>Lihong Li</author>
</authors>
<title>Vowpal wabbit online learning project.</title>
<date>2007</date>
<note>http: //mloss.org/software/view/53/.</note>
<contexts>
<context position="11094" citStr="Langford et al., 2007" startWordPosition="1798" endWordPosition="1801">tures. In this code the output is a hash code for each word “w” in the phrase “i loveee apple”, i.e. i =&gt; 43, loveee =&gt; 381 and apple =&gt; 144. Table 2 shows an example of feature hashing representation. 1 2 3 4 ··· 1024 class tweet1 0 0 1 1 ··· 0 positive tweet2 0 1 0 3 ··· 0 negative tweet3 2 0 0 0 ··· 0 positive . .. .. .. ....... · · · ... . .. . tweetn 0 0 2 1 ··· 0 neutral Table 2: Representing Twitter messages with feature hashing. Feature hashing Feature hashing has been introduced for text classification in (Shi et al., 2009), (Weinberger et al., 2009), (Forman and Kirshenbaum, 2008), (Langford et al., 2007), (Caragea et al., 2011). In the context of tweet classification, feature hashing offers an approach to reducing the number of features provided Specific syntactic (PoS) features We used the Part of Speech (PoS) tagged for tweets with the Twitter NLP tool (Gimpel et al., 2011). It encompasses 25 tags including Nominal, Nominal plus Verbal, Other openclass words like adjectives, adverbs and interjection, Twitter specific tags such as hashtags, mention, discourse marker, just to name 131 a few. Table 3 shows an example of syntactic features representation. tag, tag2 tag3 tag4 · · · tag25 class t</context>
</contexts>
<marker>Langford, Strehl, Li, 2007</marker>
<rawString>John Langford, Alex Strehl, and Lihong Li. 2007. Vowpal wabbit online learning project. http: //mloss.org/software/view/53/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jimmy Lin</author>
<author>Alek Kolcz</author>
</authors>
<title>Large-scale machine learning at twitter.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, SIGMOD ’12,</booktitle>
<pages>793--804</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2252" citStr="Lin and Kolcz, 2012" startWordPosition="348" endWordPosition="351">os and Shamma, 2010; O’Connor et al., 2010). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ One of the problems encountered by researchers in tweet sentiment analysis is the scarcity of public datasets. Although Twitter sentiment datasets have already been created, they are either small — such as ObamaMcCain Debate corpus (Shamma et al., 2009) and Health Care Reform corpus (Speriosu et al., 2011) or big and proprietary such as in (Lin and Kolcz, 2012). Others rely on noisy labels obtained from emoticons and hashtags (Go et al., 2009). The SemEval-2014 task 9: Sentiment Analysis in Twitter (Nakov et al., 2013) provides a public dataset to be used to compare the accuracy of different approaches. In this paper, we propose to analyse tweet sentiment with the use of Adaptive Boosting (Freund and Schapire, 1997), making use of the well-known Multinomial Classifier. Boosting is an approach to machine learning that is based on the idea of creating a highly accurate prediction rule by combining many relatively weak and inaccurate rules. The AdaBoos</context>
<context position="5249" citStr="Lin and Kolcz, 2012" startWordPosition="830" endWordPosition="833">entire tweet. Finally, another type of ensemble framework has been recently proposed by Hassan et al. (2013), who deal with class imbalance, sparsity, and representational issues. The authors propose to enrich the corpus using multiple additional datasets related to the task of sentiment classification. Differently from previous works, the authors use a combination of unigrams and bigrams of simple words, partof-speech, and semantic features. None of the previous works used AdaBoost (Freund and Schapire, 1996). Also, lexicons and/or part-of-speech in combination with feature hashing, like in (Lin and Kolcz, 2012) have not been addressed in the literature. 3 AdaBoost Ensemble Boosting is a relatively young, yet extremely powerful, machine learning technique. The main idea behind boosting algorithms is to combine multiple weak learners – classification algorithms that perform only slightly better than random guessing – into a powerful composite classifier. Our focus is on the well known AdaBoost algorithm (Freund and Schapire, 1997) based on Multinomial Naive Bayes as base classifiers (Figure 1). AdaBoost and its variants have been applied to diverse domains with great success, owing to their solid theo</context>
</contexts>
<marker>Lin, Kolcz, 2012</marker>
<rawString>Jimmy Lin and Alek Kolcz. 2012. Large-scale machine learning at twitter. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, SIGMOD ’12, pages 793– 804, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Sara Rosenthal</author>
<author>Zornitsa Kozareva</author>
<author>Veselin Stoyanov</author>
<author>Alan Ritter</author>
<author>Theresa Wilson</author>
</authors>
<title>Semeval-2013 task 2: Sentiment analysis in twitter.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>312--320</pages>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="2413" citStr="Nakov et al., 2013" startWordPosition="375" endWordPosition="378">oter are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ One of the problems encountered by researchers in tweet sentiment analysis is the scarcity of public datasets. Although Twitter sentiment datasets have already been created, they are either small — such as ObamaMcCain Debate corpus (Shamma et al., 2009) and Health Care Reform corpus (Speriosu et al., 2011) or big and proprietary such as in (Lin and Kolcz, 2012). Others rely on noisy labels obtained from emoticons and hashtags (Go et al., 2009). The SemEval-2014 task 9: Sentiment Analysis in Twitter (Nakov et al., 2013) provides a public dataset to be used to compare the accuracy of different approaches. In this paper, we propose to analyse tweet sentiment with the use of Adaptive Boosting (Freund and Schapire, 1997), making use of the well-known Multinomial Classifier. Boosting is an approach to machine learning that is based on the idea of creating a highly accurate prediction rule by combining many relatively weak and inaccurate rules. The AdaBoost algorithm (Freund and Schapire, 1997) was the first practical boosting algorithm, and remains one of the most widely used and studied, with applications in num</context>
</contexts>
<marker>Nakov, Rosenthal, Kozareva, Stoyanov, Ritter, Wilson, 2013</marker>
<rawString>Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva, Veselin Stoyanov, Alan Ritter, and Theresa Wilson. 2013. Semeval-2013 task 2: Sentiment analysis in twitter. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 312–320, Atlanta, Georgia, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>Ramnath Balasubramanyan</author>
<author>Bryan R Routledge</author>
<author>Noah A Smith</author>
</authors>
<title>From tweets to polls: Linking text sentiment to public opinion time series.</title>
<date>2010</date>
<booktitle>In ICWSM’10,</booktitle>
<pages>1--1</pages>
<marker>O’Connor, Balasubramanyan, Routledge, Smith, 2010</marker>
<rawString>Brendan O’Connor, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. 2010. From tweets to polls: Linking text sentiment to public opinion time series. In ICWSM’10, pages 1–1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Penagos Carlos Rodriguez</author>
<author>Jordi Atserias</author>
<author>Joan Codina-Filba</author>
<author>David Garcıa-Narbona</author>
<author>Jens Grivolla</author>
<author>Patrik Lambert</author>
<author>Roser Saurı</author>
</authors>
<title>Fbm: Combining lexicon-based ml and heuristics for social media polarities.</title>
<date>2013</date>
<booktitle>In Proceedings of SemEval-2013 – International Workshop on Semantic Evaluation Co-located with *Sem</booktitle>
<pages>2013--10</pages>
<contexts>
<context position="3335" citStr="Rodriguez et al., 2013" startWordPosition="528" endWordPosition="531">that is based on the idea of creating a highly accurate prediction rule by combining many relatively weak and inaccurate rules. The AdaBoost algorithm (Freund and Schapire, 1997) was the first practical boosting algorithm, and remains one of the most widely used and studied, with applications in numerous fields. Therefore, it has potential to be very useful for tweet sentiment analysis, as we address in this paper. 2 Related Work Classifier ensembles for tweet sentiment analysis have been underexplored in the literature — a few exceptions are (Lin and Kolcz, 2012; Clark and Wicentwoski, 2013; Rodriguez et al., 2013; Hassan et al., 2013). Lin and Kolcz (2012) used logistic regression classifiers learned from hashed byte 4- grams as features – The feature extractor considers the tweet as a raw byte array. It moves a four-byte sliding window along the array, 129 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 129–134, Dublin, Ireland, August 23-24, 2014. and hashes the contents of the bytes, the value of which was taken as the feature id. Here the 4-grams refers to four characters (and not to four words). They made no attempt to perform any linguistic processing, </context>
</contexts>
<marker>Rodriguez, Atserias, Codina-Filba, Garcıa-Narbona, Grivolla, Lambert, Saurı, 2013</marker>
<rawString>Penagos Carlos Rodriguez, Jordi Atserias, Joan Codina-Filba, David Garcıa-Narbona, Jens Grivolla, Patrik Lambert, and Roser Saurı. 2013. Fbm: Combining lexicon-based ml and heuristics for social media polarities. In Proceedings of SemEval-2013 – International Workshop on Semantic Evaluation Co-located with *Sem and NAACL, Atlanta, Georgia. Url date at 2013-10-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Shamma</author>
<author>Lyndon Kennedy</author>
<author>Elizabeth F Churchill</author>
</authors>
<title>Tweet the debates: Understanding community annotation of uncollected sources.</title>
<date>2009</date>
<booktitle>In In WSM ?09: Proceedings of the international workshop on Workshop on Social.</booktitle>
<contexts>
<context position="2142" citStr="Shamma et al., 2009" startWordPosition="328" endWordPosition="331">s (Asur and Huberman, 2010); and (iv) predicting acceptance or rejection of presidential candidates (Diakopoulos and Shamma, 2010; O’Connor et al., 2010). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ One of the problems encountered by researchers in tweet sentiment analysis is the scarcity of public datasets. Although Twitter sentiment datasets have already been created, they are either small — such as ObamaMcCain Debate corpus (Shamma et al., 2009) and Health Care Reform corpus (Speriosu et al., 2011) or big and proprietary such as in (Lin and Kolcz, 2012). Others rely on noisy labels obtained from emoticons and hashtags (Go et al., 2009). The SemEval-2014 task 9: Sentiment Analysis in Twitter (Nakov et al., 2013) provides a public dataset to be used to compare the accuracy of different approaches. In this paper, we propose to analyse tweet sentiment with the use of Adaptive Boosting (Freund and Schapire, 1997), making use of the well-known Multinomial Classifier. Boosting is an approach to machine learning that is based on the idea of </context>
</contexts>
<marker>Shamma, Kennedy, Churchill, 2009</marker>
<rawString>David A. Shamma, Lyndon Kennedy, and Elizabeth F. Churchill. 2009. Tweet the debates: Understanding community annotation of uncollected sources. In In WSM ?09: Proceedings of the international workshop on Workshop on Social.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qinfeng Shi</author>
<author>James Petterson</author>
<author>Gideon Dror</author>
<author>John Langford</author>
<author>Alex Smola</author>
<author>S V N Vishwanathan</author>
</authors>
<title>Hash kernels for structured data.</title>
<date>2009</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>10--2615</pages>
<contexts>
<context position="11010" citStr="Shi et al., 2009" startWordPosition="1784" endWordPosition="1787">w,murmurhash3_bytes_u32(w,0)%2**10)) The dimensionality is 2 ∗ ∗10, i.e 210 features. In this code the output is a hash code for each word “w” in the phrase “i loveee apple”, i.e. i =&gt; 43, loveee =&gt; 381 and apple =&gt; 144. Table 2 shows an example of feature hashing representation. 1 2 3 4 ··· 1024 class tweet1 0 0 1 1 ··· 0 positive tweet2 0 1 0 3 ··· 0 negative tweet3 2 0 0 0 ··· 0 positive . .. .. .. ....... · · · ... . .. . tweetn 0 0 2 1 ··· 0 neutral Table 2: Representing Twitter messages with feature hashing. Feature hashing Feature hashing has been introduced for text classification in (Shi et al., 2009), (Weinberger et al., 2009), (Forman and Kirshenbaum, 2008), (Langford et al., 2007), (Caragea et al., 2011). In the context of tweet classification, feature hashing offers an approach to reducing the number of features provided Specific syntactic (PoS) features We used the Part of Speech (PoS) tagged for tweets with the Twitter NLP tool (Gimpel et al., 2011). It encompasses 25 tags including Nominal, Nominal plus Verbal, Other openclass words like adjectives, adverbs and interjection, Twitter specific tags such as hashtags, mention, discourse marker, just to name 131 a few. Table 3 shows an e</context>
</contexts>
<marker>Shi, Petterson, Dror, Langford, Smola, Vishwanathan, 2009</marker>
<rawString>Qinfeng Shi, James Petterson, Gideon Dror, John Langford, Alex Smola, and S.V.N. Vishwanathan. 2009. Hash kernels for structured data. J. Mach. Learn. Res., 10:2615–2637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SMHasher</author>
</authors>
<title>The murmurhash family of hash functions.</title>
<date>2010</date>
<contexts>
<context position="9737" citStr="SMHasher, 2010" startWordPosition="1563" endWordPosition="1564">is a polarity inversion of the opinion words ahead. Finally, the term “extremely” belongs the booster word list and this word suggests more emphasis to the opinion words existing ahead. positive negative neutral class tweet1 3 0 0 positive Table 1: Representing Twitter messages with lexicons. as input to a learning algorithm. The original high-dimensional space is “reduced” by hashing the features into a lower-dimensional space, i.e., mapping features to hash keys. Thus, multiple features can be mapped to the same hash key, thereby “aggregating” their counts. We used the MurmurHash3 function (SMHasher, 2010), that is a non-cryptographic hash function suitable for general hash-based lookup tables. It has been used for many purposes, and a recent approach that has emerged is its use for feature hashing or hashing trick. Instead of building and storing an explicit traditional bag-of-words with n-grams, the feature hashing uses a hash function to reduce the dimensionality of the output space and the length of this space (features) is explicitly fixed in advance. For this paper, we used this code (in Python): Code Listing 1: Murmurhash: from sklearn.utils.murmurhash import murmurhash3_bytes_u32 for w </context>
</contexts>
<marker>SMHasher, 2010</marker>
<rawString>SMHasher. 2010. The murmurhash family of hash functions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Speriosu</author>
<author>Nikita Sudan</author>
<author>Sid Upadhyay</author>
<author>Jason Baldridge</author>
</authors>
<title>Twitter polarity classification with label propagation over lexical links and the follower graph.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Unsupervised Learning in NLP,</booktitle>
<pages>53--63</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2196" citStr="Speriosu et al., 2011" startWordPosition="337" endWordPosition="340">eptance or rejection of presidential candidates (Diakopoulos and Shamma, 2010; O’Connor et al., 2010). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ One of the problems encountered by researchers in tweet sentiment analysis is the scarcity of public datasets. Although Twitter sentiment datasets have already been created, they are either small — such as ObamaMcCain Debate corpus (Shamma et al., 2009) and Health Care Reform corpus (Speriosu et al., 2011) or big and proprietary such as in (Lin and Kolcz, 2012). Others rely on noisy labels obtained from emoticons and hashtags (Go et al., 2009). The SemEval-2014 task 9: Sentiment Analysis in Twitter (Nakov et al., 2013) provides a public dataset to be used to compare the accuracy of different approaches. In this paper, we propose to analyse tweet sentiment with the use of Adaptive Boosting (Freund and Schapire, 1997), making use of the well-known Multinomial Classifier. Boosting is an approach to machine learning that is based on the idea of creating a highly accurate prediction rule by combinin</context>
</contexts>
<marker>Speriosu, Sudan, Upadhyay, Baldridge, 2011</marker>
<rawString>Michael Speriosu, Nikita Sudan, Sid Upadhyay, and Jason Baldridge. 2011. Twitter polarity classification with label propagation over lexical links and the follower graph. In Proceedings of the First Workshop on Unsupervised Learning in NLP, pages 53–63, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Thelwall</author>
<author>Kevan Buckley</author>
<author>Georgios Paltoglou</author>
<author>Di Cai</author>
<author>Arvid Kappas</author>
</authors>
<title>Sentiment in short strength detection informal text.</title>
<date>2010</date>
<journal>J. Am. Soc. Inf. Sci. Technol.,</journal>
<volume>61</volume>
<issue>12</issue>
<marker>Thelwall, Buckley, Paltoglou, Di Cai, Kappas, 2010</marker>
<rawString>Mike Thelwall, Kevan Buckley, Georgios Paltoglou, Di Cai, and Arvid Kappas. 2010. Sentiment in short strength detection informal text. J. Am. Soc. Inf. Sci. Technol., 61(12):2544–2558, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Viola</author>
<author>Michael Jones</author>
</authors>
<title>Robust realtime object detection.</title>
<date>2001</date>
<journal>In International Journal of Computer Vision.</journal>
<contexts>
<context position="5975" citStr="Viola and Jones (2001)" startWordPosition="941" endWordPosition="944">emely powerful, machine learning technique. The main idea behind boosting algorithms is to combine multiple weak learners – classification algorithms that perform only slightly better than random guessing – into a powerful composite classifier. Our focus is on the well known AdaBoost algorithm (Freund and Schapire, 1997) based on Multinomial Naive Bayes as base classifiers (Figure 1). AdaBoost and its variants have been applied to diverse domains with great success, owing to their solid theoretical foundation, accurate prediction, and great simplicity (Freund and Schapire, 1997). For example, Viola and Jones (2001) used AdaBoost to face detection, Hao and Luo (2006) dealt with image segmentation, recognition of handwritten digits, and outdoor scene classification problems. In (Bloehdorn and Hotho, 2004) text classification is explored. Figure 1: AdaBoost Approach 4 Feature Engineering The most commonly used text representation method adopted in the literature is known as Bag of Words (BOW) technique, where a document is considered as a BOW, and is represented by a feature vector containing all the words appearing in the corpus. In spite of BOW being simple and very effective in text classification, a la</context>
</contexts>
<marker>Viola, Jones, 2001</marker>
<rawString>Paul Viola and Michael Jones. 2001. Robust realtime object detection. In International Journal of Computer Vision.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian Q Weinberger</author>
<author>Anirban Dasgupta</author>
<author>John Langford</author>
<author>Alexander J Smola</author>
<author>Josh Attenberg</author>
</authors>
<title>Feature hashing for large scale multitask learning.</title>
<date>2009</date>
<booktitle>of ACM International Conference Proceeding Series,</booktitle>
<volume>382</volume>
<pages>140</pages>
<editor>In Andrea Pohoreckyj Danyluk, L Bottou, and Michael L. Littman, editors, ICML,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="11037" citStr="Weinberger et al., 2009" startWordPosition="1788" endWordPosition="1792">u32(w,0)%2**10)) The dimensionality is 2 ∗ ∗10, i.e 210 features. In this code the output is a hash code for each word “w” in the phrase “i loveee apple”, i.e. i =&gt; 43, loveee =&gt; 381 and apple =&gt; 144. Table 2 shows an example of feature hashing representation. 1 2 3 4 ··· 1024 class tweet1 0 0 1 1 ··· 0 positive tweet2 0 1 0 3 ··· 0 negative tweet3 2 0 0 0 ··· 0 positive . .. .. .. ....... · · · ... . .. . tweetn 0 0 2 1 ··· 0 neutral Table 2: Representing Twitter messages with feature hashing. Feature hashing Feature hashing has been introduced for text classification in (Shi et al., 2009), (Weinberger et al., 2009), (Forman and Kirshenbaum, 2008), (Langford et al., 2007), (Caragea et al., 2011). In the context of tweet classification, feature hashing offers an approach to reducing the number of features provided Specific syntactic (PoS) features We used the Part of Speech (PoS) tagged for tweets with the Twitter NLP tool (Gimpel et al., 2011). It encompasses 25 tags including Nominal, Nominal plus Verbal, Other openclass words like adjectives, adverbs and interjection, Twitter specific tags such as hashtags, mention, discourse marker, just to name 131 a few. Table 3 shows an example of syntactic feature</context>
</contexts>
<marker>Weinberger, Dasgupta, Langford, Smola, Attenberg, 2009</marker>
<rawString>Kilian Q. Weinberger, Anirban Dasgupta, John Langford, Alexander J. Smola, and Josh Attenberg. 2009. Feature hashing for large scale multitask learning. In Andrea Pohoreckyj Danyluk, L Bottou, and Michael L. Littman, editors, ICML, volume 382 of ACM International Conference Proceeding Series, page 140. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun-Ming Xu</author>
<author>Kwang-Sung Jun</author>
<author>Xiaojin Zhu</author>
<author>Amy Bellmore</author>
</authors>
<title>Learning from bullying traces in social media.</title>
<date>2012</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>656--666</pages>
<contexts>
<context position="1462" citStr="Xu et al., 2012" startWordPosition="228" endWordPosition="231">ent generated by its users, and the emergence of the social networks. In the social networks such as Twitter people post their opinions in a colloquial and compact language, and it is becoming a large dataset, which can be used as a source of information for various automatic tools of sentiment inference. There is an enormous interest in sentiment analysis of Twitter messages, known as tweets, with applications in several segments, such as (i) directing marketing campaigns, extracting consumer reviews of services and products (Jansen et al., 2009); (ii) identifying manifestations of bullying (Xu et al., 2012); (iii) predicting to forecast box-office revenues for movies (Asur and Huberman, 2010); and (iv) predicting acceptance or rejection of presidential candidates (Diakopoulos and Shamma, 2010; O’Connor et al., 2010). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ One of the problems encountered by researchers in tweet sentiment analysis is the scarcity of public datasets. Although Twitter sentiment datasets have already been created,</context>
</contexts>
<marker>Xu, Jun, Zhu, Bellmore, 2012</marker>
<rawString>Jun-Ming Xu, Kwang-Sung Jun, Xiaojin Zhu, and Amy Bellmore. 2012. Learning from bullying traces in social media. In HLT-NAACL, pages 656–666.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>