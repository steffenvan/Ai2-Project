<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.021566">
<title confidence="0.998838">
What causes a causal relation?
Detecting Causal Triggers in Biomedical Scientific Discourse
</title>
<author confidence="0.981062">
Claudiu Mih˘ail˘a and Sophia Ananiadou
</author>
<affiliation confidence="0.992455666666667">
The National Centre for Text Mining,
School of Computer Science,
The University of Manchester,
</affiliation>
<address confidence="0.814514">
131 Princess Street, Manchester M1 7DN, UK
</address>
<email confidence="0.9929155">
claudiu.mihaila@manchester.ac.uk
sophia.ananiadou@manchester.ac.uk
</email>
<sectionHeader confidence="0.993773" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999899761904762">
Current domain-specific information extrac-
tion systems represent an important resource
for biomedical researchers, who need to pro-
cess vaster amounts of knowledge in short
times. Automatic discourse causality recog-
nition can further improve their workload by
suggesting possible causal connections and
aiding in the curation of pathway models. We
here describe an approach to the automatic
identification of discourse causality triggers in
the biomedical domain using machine learn-
ing. We create several baselines and experi-
ment with various parameter settings for three
algorithms, i.e., Conditional Random Fields
(CRF), Support Vector Machines (SVM) and
Random Forests (RF). Also, we evaluate the
impact of lexical, syntactic and semantic fea-
tures on each of the algorithms and look at er-
rors. The best performance of 79.35% F-score
is achieved by CRFs when using all three fea-
ture types.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99992811627907">
The need to provide automated, efficient and accu-
rate means of retrieving and extracting user-oriented
biomedical knowledge has significantly increased
according to the ever-increasing amount of knowl-
edge pusblished daily in the form of research ar-
ticles (Ananiadou and McNaught, 2006; Cohen
and Hunter, 2008). Biomedical text mining has
seen significant recent advancements in recent years
(Zweigenbaum et al., 2007), including named en-
tity recognition (Fukuda et al., 1998), coreference
resolution (Batista-Navarro and Ananiadou, 2011;
Savova et al., 2011) and relation (Miwa et al., 2009;
Pyysalo et al., 2009) and event extraction (Miwa
et al., 2012b; Miwa et al., 2012a). Using biomed-
ical text mining technology, text can now be en-
riched via the addition of semantic metadata and
thus can support tasks such as analysing molecu-
lar pathways (Rzhetsky et al., 2004) and semantic
searching (Miyao et al., 2006).
However, more complex tasks, such as question
answering and automatic summarisation, require the
extraction of information that spans across several
sentences, together with the recognition of relations
that exist across sentence boundaries, in order to
achieve high levels of performance.
The notion of discourse can be defined as a co-
herent sequence of clauses and sentences. These
are connected in a logical manner by discourse re-
lations, such as causal, temporal and conditional,
which characterise how facts in text are related. In
turn, these help readers infer deeper, more com-
plex knowledge about the facts mentioned in the
discourse. These relations can be either explicit
or implicit, depending whether or not they are ex-
pressed in text using overt discourse connectives
(also known as triggers). Take, for instance, the case
in example (1), where the trigger Therefore signals
a justification between the two sentences: because
“a normal response to mild acid pH from PmrB re-
quires both a periplasmic histidine and several glu-
tamic acid residues”, the authors believe that the
“regulation of PmrB activity could involve protona-
tion of some amino acids”.
</bodyText>
<listItem confidence="0.6496115">
(1) In the case of PmrB, a normal response to mild
acid pH requires not only a periplasmic histidine
</listItem>
<page confidence="0.976648">
38
</page>
<note confidence="0.6554575">
Proceedings of the ACL Student Research Workshop, pages 38–45,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.994776066666667">
but also several glutamic acid residues.
Therefore, regulation of PmrB activity may in-
volve protonation of one or more of these amino
acids.
Thus, by identifying this causal relation, search
engines become able to discover relations between
biomedical entities and events or between experi-
mental evidence and associated conclusions. How-
ever, phrases acting as causal triggers in certain con-
texts may not denote causality in all cases. There-
fore, a dictionary-based approach is likely to pro-
duce a very high number of false positives. In
this paper, we explore several supervised machine-
learning approaches to the automatic identification
of triggers that actually denote causality.
</bodyText>
<sectionHeader confidence="0.999918" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999915179487179">
A large amount of work related to discourse pars-
ing and discourse relation identification exists in the
general domain, where researchers have not only
identified discourse connectives, but also developed
end-to-end discourse parsers (Pitler and Nenkova,
2009; Lin et al., 2012). Most work is based on
the Penn Discourse Treebank (PDTB) (Prasad et al.,
2008), a corpus of lexically-grounded annotations of
discourse relations.
Until now, comparatively little work has been car-
ried out on causal discourse relations in the biomed-
ical domain, although causal associations between
biological entities, events and processes are central
to most claims of interest (Kleinberg and Hripcsak,
2011). The equivalent of the PDTB for the biomed-
ical domain is the BioDRB corpus (Prasad et al.,
2011), containing 16 types of discourse relations,
e.g., temporal, causal and conditional. The number
of purely causal relations annotated in this corpus is
542. There are another 23 relations which are a mix-
ture between causality and one of either background,
temporal, conjunction or reinforcement relations. A
slightly larger corpus is the BioCause (Mih˘ail˘a et
al., 2013), containing over 850 manually annotated
causal discourse relations in 19 full-text open-access
journal articles from the infectious diseases domain.
Using the BioDRB corpus as data, some re-
searchers explored the identification of discourse
connectives (Ramesh et al., 2012). However, they
do not distinguish between the types of discourse
relations. They obtain the best F-score of 75.7% us-
ing CRF, with SVM reaching only 65.7%. These
results were obtained by using only syntactic fea-
tures, as sematic features were shown to lower the
performance. Also, they prove that there exist dif-
ferences in discourse triggers between the biomedi-
cal and general domains by training a model on the
BioDRB and evaluating it against PDTB and vice-
versa.
</bodyText>
<sectionHeader confidence="0.998009" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.992624">
In this section, we describe our data and the features
of causal triggers. We also explain our evaluation
methodology.
</bodyText>
<subsectionHeader confidence="0.99658">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.999854545454545">
The data for the experiments comes from the Bio-
Cause corpus. BioCause is a collection of 19 open-
access full-text journal articles pertaining to the
biomedical subdomain of infectious diseases, manu-
ally annotated with causal relationships. Two types
of spans of text are marked in the text, namely causal
triggers and causal arguments. Each causal relation
is composed of three text-bound annotations: a trig-
ger, a cause or evidence argument and an effect argu-
ment. Some causal relations have implicit triggers,
so these are excluded from the current research.
Figure 1 shows an example of discourse causality
from BioCause, marking the causal trigger and the
two arguments with their respective relation. Named
entities are also marked in this example.
BioCause contains 381 unique explicit triggers in
the corpus, each being used, on average, only 2.10
times. The number decreases to 347 unique triggers
when they are lemmatised, corresponding to an av-
erage usage of 2.30 times per trigger. Both count
settings show the diversity of causality-triggering
phrases that are used in the biomedical domain.
</bodyText>
<subsectionHeader confidence="0.994056">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.9999265">
Three types of features have been employed in the
development of this causality trigger model, i.e., lex-
ical, syntactic and semantic. These features are cat-
egorised and described below.
</bodyText>
<subsectionHeader confidence="0.820222">
3.2.1 Lexical features
</subsectionHeader>
<bodyText confidence="0.986968">
The lexical features are built from the actual to-
kens present in text. Tokenisation is performed by
</bodyText>
<page confidence="0.998856">
39
</page>
<figureCaption confidence="0.999576">
Figure 1: Causal relation in the BioCause.
</figureCaption>
<bodyText confidence="0.998695533333333">
the GENIA tagger (Tsuruoka et al., 2005) using the
biomedical model. The first two features represent
the token’s surface expression and its base form.
Neighbouring tokens have also been considered.
We included the token immediately to the left and
the one immediately to the right of the current to-
ken. This decision is based on two observations.
Firstly, in the case of tokens to the left, most trig-
gers are found either at the beginning of the sentence
(311 instances) or are preceded by a comma (238 in-
stances). These two left contexts represent 69% of
all triggers. Secondly, for the tokens to the right, al-
most 45% of triggers are followed by a determiner,
such as the, a or an, (281 instances) or a comma (71
instances).
</bodyText>
<subsectionHeader confidence="0.576445">
3.2.2 Syntactic features
</subsectionHeader>
<bodyText confidence="0.999960272727273">
The syntax, dependency and predicate argument
structure are produced by the Enju parser (Miyao
and Tsujii, 2008). Figure 2 depicts a partial lexical
parse tree of a sentence which starts with a causal
trigger, namely Our results suggest that. From the
lexical parse trees, several types of features have
been generated.
The first two features represent the part-of-speech
and syntactic category of a token. For instance,
the figure shows that the token that has the part-of-
speech IN. These features are included due to the
fact that either many triggers are lexicalised as an
adverb or conjunction, or are part of a verb phrase.
For the same reason, the syntactical category path
from the root of the lexical parse tree to the token is
also included. The path also encodes, for each par-
ent constituent, the position of the token in its sub-
tree, i.e., beginning (B), inside (I) or end (E); if the
token is the only leaf node of the constituent, this is
marked differently, using a C. Thus, the path of that,
highlighted in the figure, is I-S/I-VP/B-CP/C-CX.
Secondly, for each token, we extracted the pred-
</bodyText>
<figureCaption confidence="0.993782">
Figure 2: Partial lexical parse tree of a sentence starting
with a causal trigger.
</figureCaption>
<bodyText confidence="0.999905333333333">
icate argument structure and checked whether a re-
lation exista between the token and the previous and
following tokens. The values for this feature repre-
sent the argument number as allocated by Enju.
Thirdly, the ancestors of each token to the third
degree are instantiated as three different features. In
the case that such ancestors do not exist (i.e., the
root of the lexical parse tree is less than three nodes
away), a ”none” value is given. For instance, the
token that in Figure 2 has as its first three ancestors
the constituents marked with CX, CP and VP.
Finally, the lowest common ancestor in the lexi-
cal parse tree between the current token and its left
neighbour has been included. In the example, the
lowest common ancestor for that and suggest is VP.
These last two feature types have been produced
on the observation that the lowest common ancestor
for all tokens in a causal trigger is S or VP in over
70% of instances. Furthermore, the percentage of
cases of triggers with V or ADV as lowest common
ancestor is almost 9% in each case. Also, the aver-
</bodyText>
<page confidence="0.990431">
40
</page>
<bodyText confidence="0.962674">
age distance to the lowest common ancestor is 3.
</bodyText>
<subsectionHeader confidence="0.686323">
3.2.3 Semantic features
</subsectionHeader>
<bodyText confidence="0.999958515151515">
We have exploited several semantic knowledge
sources to identify causal triggers more accurately,
as a mapping to concepts and named entities acts as
a back-off smoothing, thus increasing performance.
One semantic knowledge source is the BioCause
corpus itself. All documents annotated for causal-
ity in BioCause had been previously manually an-
notated with biomedical named entity and event in-
formation. This was performed in the context of var-
ious shared tasks, such as the BioNLP 2011 Shared
Task on Infectious Diseases (Pyysalo et al., 2011).
We therefore leverage this existing information to
add another semantic layer to the model. More-
over, another advantage of having a gold standard
annotation is the fact that it is now possible to sepa-
rate the task of automatic causal trigger recognition
from automatic named entity recognition and event
extraction. The named entity and event annotation
in the BioCause corpus is used to extract informa-
tion about whether a token is part of a named entity
or event trigger. Furthermore, the type of the named
entity or event is included as a separate feature.
The second semantic knowledge source is Word-
Net (Fellbaum, 1998). Using this resource, the hy-
pernym of every token in the text has been included
as a feature. Only the first sense of every token has
been considered, as no sense disambiguation tech-
nique has been employed.
Finally, tokens have been linked to the Unified
Medical Language System (UMLS) (Bodenreider,
2004) semantic types. Thus, we included a feature
to say whether a token is part of a UMLS type and
another for its semantic type if the previous is true.
</bodyText>
<subsectionHeader confidence="0.996847">
3.3 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999633625">
We explored with various machine learning algo-
rithms and various settings for the task of identifying
causal triggers.
On the one hand, we experimented with CRF
(Lafferty et al., 2001), a probabilistic modelling
framework commonly used for sequence labelling
tasks. In this work, we employed the CRFSuite im-
plementation1.
</bodyText>
<footnote confidence="0.8981935">
1http://www.chokkan.org/software/
crfsuite
</footnote>
<bodyText confidence="0.996401166666667">
On the other hand, we modelled trigger detection
as a classification task, using Support Vector Ma-
chines and Random Forests. More specifically, we
employed the implementation in Weka (Hall et al.,
2009; Witten and Frank, 2005) for RFs, and Lib-
SVM (Chang and Lin, 2011) for SVMs.
</bodyText>
<sectionHeader confidence="0.999522" genericHeader="evaluation">
4 Results and discussion
</sectionHeader>
<bodyText confidence="0.998683">
Several models have been developed and 10-fold
cross-evaluated to examine the complexity of the
task, the impact of various feature types (lexical,
syntactic, semantic). Table 1 shows the performance
evaluation of baseline systems and other classifiers.
These are described in the following subsections. It
should be noted that the dataset is highly skewed,
with a ratio of positive examples to negative exam-
ples of approximately 1:52.
</bodyText>
<table confidence="0.9999533">
Classifier P R Fl
Baseline Dict 8.36 100 15.43
Dep 7.51 76.66 13.68
Dict+Dep 14.30 75.33 24.03
2-way CRF 89.29 73.53 79.35
SVM 81.62 61.05 69.85
RandFor 78.16 66.96 72.13
3-way CRF 89.13 64.04 72.87
SVM 74.21 56.82 64.36
RandFor 73.80 60.95 66.76
</table>
<tableCaption confidence="0.9976475">
Table 1: Performance of various classifiers in identifying
causal connectives
</tableCaption>
<subsectionHeader confidence="0.954022">
4.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999915428571429">
Several baselines have been devised. The first base-
line is a dictionary-based heuristic, named Dict. A
lexicon is populated with all annotated causal trig-
gers and then this is used to tag all instances of its
entries in the text as connectives. The precision of
this heuristic is very low, 8.36%, which leads to an
F-score of 15.43%, considering the recall is 100%.
This is mainly due to triggers which are rarely used
as causal triggers, such as and, by and that.
Building on the previously mentioned observation
about the lowest common ancestor for all tokens in a
causal trigger, we built a baseline system that checks
all constituent nodes in the lexical parse tree for the
S, V, VP and ADV tags and marks them as causal
</bodyText>
<page confidence="0.998728">
41
</page>
<bodyText confidence="0.999906769230769">
triggers. The name of this system is Dep. Not only
does Dep obtain a lower precision than Dict, but it
also performs worse in terms of recall. The F-score
is 13.68%, largely due to the high number of inter-
mediate nodes in the lexical parse tree that have VP
as their category.
The third baseline is a combination of Dict and
Dep: we consider only constituents that have the
necessary category (S, V, VP or ADV) and include
a trigger from the dictionary. Although the recall
decreases slightly, the precision increases to almost
twice that of both Dict and Dep. This produces a
much better F-score of 24.03%.
</bodyText>
<subsectionHeader confidence="0.998169">
4.2 Sequence labelling task
</subsectionHeader>
<bodyText confidence="0.999993303030303">
As a sequence labelling task, we have modelled
causal trigger detection as two separate tasks.
Firstly, each trigger is represented in the B-I-O for-
mat (further mentioned as the 3-way model). Thus,
the first word of every trigger is tagged as B (be-
gin), whilst the following words in the trigger are
tagged as I (inside). Non-trigger words are tagged
as O (outside).
The second model is a simpler version of the pre-
vious one: it does not distinguish between the first
and the following words in the trigger. In other
words, each word is tagged either as being part of
or outside the trigger, further known as the 2-way
model. Hence, a sequence of contiguous tokens
marked as part of a trigger form one trigger.
CRF performs reasonably well in detecting causal
triggers. In the 3-way model, it obtains an F-score of
almost 73%, much better than the other algorithms.
It also obtains the highest precision (89%) and recall
(64%). However, in the 2-way model, CRF’s perfor-
mance is slightly lower than that of Random Forests,
achieving only 79.35%. Its precision, on the other
hand, is the highest in this model. The results from
both models were obtained by combining features
from all three feature categories.
Table 2 show the effect of feature types on both
models of CRFs. As can be observed, the best per-
formances, in terms of F-score, including the previ-
ously mentioned ones, are obtained when combin-
ing all three types of features, i.e., lexical, syntactic
and semantic. The best precision and recall, how-
ever, are not necessarily achieved by using all three
feature types. In the two-way model, the best preci-
</bodyText>
<table confidence="0.999951666666667">
Features P R Fl
2-way Lex 88.99 67.09 73.59
Syn 92.20 68.68 75.72
Sem 87.20 63.30 69.36
Lex-Syn 87.76 73.29 78.73
Lex+Sem 89.54 69.10 75.61
Syn+Sem 87.48 72.62 78.13
Lex-Syn-Sem 89.29 73.53 79.35
3-way Lex 85.87 56.34 65.18
Syn 87.62 61.44 70.22
Sem 80.78 51.43 59.39
Lex+Syn 87.80 63.04 72.59
Lex+Sem 85.50 58.11 66.80
Syn+Sem 84.83 64.94 72.41
Lex-Syn-Sem 89.13 64.04 72.87
</table>
<tableCaption confidence="0.9976765">
Table 2: Effect of feature types on the sequence labelling
task, given in percentages.
</tableCaption>
<bodyText confidence="0.9999205">
sion is obtained by using the syntactic features only,
reaching over 92%, almost 3% higher than when all
three feature types are used. In the three-way model,
syntactic and semantic features produce the best re-
call (almost 65%), which is just under 1% higher
than the recall when all features are used.
</bodyText>
<subsectionHeader confidence="0.999356">
4.3 Classification task
</subsectionHeader>
<bodyText confidence="0.999990142857143">
As a classification task, an algorithm has to decide
whether a token is part of a trigger or not, similarly
to the previous two-way subtask in the case of CRF.
Firstly, we have used RF for the classification
task. Various parameter settings regarding the num-
ber of constructed trees and the number of random
features have been explored.
The effect of feature types on the performance of
RF is shown in Table 3. As can be observed, the
best performance is obtained when combining lexi-
cal and semantic features. Due to the fact that causal
triggers do not have a semantic mapping to concepts
in the named entity and UMLS annotations, the trees
in the random forest classifier can easily produce
rules that distinguish triggers from non-triggers. As
such, the use of semantic features alone produce a
very good precision of 84.34%. Also, in all cases
where semantic features are combined with other
feature types, the precision increases by 0.5% in the
case of lexical features and 3.5% in the case of syn-
tactic features. However, the recall of semantic fea-
</bodyText>
<page confidence="0.997776">
42
</page>
<bodyText confidence="0.6567745">
tures alone is the lowest. The best recall is obtained
when using only lexical features.
</bodyText>
<table confidence="0.99994325">
Features P R F1
Lex 78.47 68.30 73.03
Syn 68.19 62.36 65.15
Sem 84.34 56.83 67.91
Lex+Syn 77.11 65.92 71.09
Lex+Sem 79.10 67.91 73.08
Syn+Sem 71.83 64.45 67.94
Lex+Syn+Sem 77.98 67.31 72.25
</table>
<tableCaption confidence="0.999923">
Table 3: Effect of feature types on Random Forests.
</tableCaption>
<bodyText confidence="0.9997746875">
Secondly, we explored the performance of SVMs
in detecting causal triggers. We have experimented
with two kernels, namely polynomial (second de-
gree) and radial basis function (RBF) kernels. For
each of these two kernels, we have evaluated vari-
ous combinations of parameter values for cost and
weight. Both these kernels achieved similar results,
indicating that the feature space is not linearly sepa-
rable and that the problem is highly complex.
The effect of feature types on the performance of
SVMs is shown in Table 4. As can be observed,
the best performance is obtained when combining
the lexical and semantic feature types (69.85% F-
score). The combination of all features produces the
best precision, whilst the best recall is obtained by
combining lexical and semantic features.
</bodyText>
<table confidence="0.99978925">
Features P R F1
Lex 80.80 60.94 69.47
Syn 82.94 55.60 66.57
Sem 85.07 56.51 67.91
Lex+Syn 86.49 53.63 66.81
Lex+Sem 81.62 61.05 69.85
Syn+Sem 84.49 55.31 66.85
Lex+Syn+Sem 87.70 53.96 66.81
</table>
<tableCaption confidence="0.999641">
Table 4: Effect of feature types on SVM.
</tableCaption>
<subsectionHeader confidence="0.998596">
4.4 Error analysis
</subsectionHeader>
<bodyText confidence="0.999734052631579">
As we expected, the majority of errors arise from se-
quences of tokens which are only used infrequently
as non-causal triggers. This applies to 107 trigger
types, whose number of false positives (FP) is higher
than the number of true positives (TP). In fact, 64
trigger types occur only once as a causal instance,
whilst the average number of FPs for these types is
14.25. One such example is and, for which the num-
ber of non-causal instances (2305) is much greater
than that of causal instances (1). Other examples
of trigger types more commonly used as causal trig-
gers, are suggesting (9 TP, 54 FP), indicating (8 TP,
41 FP) and resulting in (6 TP, 14 FP). For instance,
example (2) contains two mentions of indicating, but
neither of them implies causality.
(2) Buffer treated control cells showed intense
green staining with syto9 (indicating viabil-
ity) and a lack of PI staining (indicating no
dead/dying cells or DNA release).
</bodyText>
<sectionHeader confidence="0.995981" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999962620689655">
We have presented an approach to the automatic
identification of triggers of causal discourse rela-
tions in biomedical scientific text. The task has
proven to be a highly complex one, posing many
challenges. Shallow approaches, such as dictionary
matching and lexical parse tree matching, perform
very poorly, due to the high ambiguity of causal
triggers (with F-scores of approximately 15% each
and 24% when combined). We have explored vari-
ous machine learning algorithms that automatically
classify tokens into triggers or non-triggers and we
have evaluated the impact of multiple lexical, syn-
tactic and semantic features. The performance of
SVMs prove that the task of identifying causal trig-
gers is indeed complex. The best performing classi-
fier is CRF-based and combines lexical, syntactical
and semantical features in order to obtain an F-score
of 79.35%.
As future work, integrating the causal relations in
the BioDRB corpus is necessary to check whether a
data insufficiency problem exists and, if so, estimate
the optimal amount of necessary data. Furthermore,
evaluations against the general domain need to be
performed, in order to establish any differences in
expressing causality in the biomedical domain. One
possible source for this is the PDTB corpus. A more
difficult task that needs attention is that of identify-
ing implicit triggers. Finally, our system needs to be
extended in order to identify the two arguments of
</bodyText>
<page confidence="0.999249">
43
</page>
<bodyText confidence="0.999749">
causal relations, the cause and effect, thus allowing
the creation of a complete discourse causality parser.
</bodyText>
<sectionHeader confidence="0.995577" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999949">
This work was partially funded by the Engineer-
ing and Physical Sciences Research Council [grant
number EP/P505631/1].
</bodyText>
<sectionHeader confidence="0.99836" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997416177083333">
Sophia Ananiadou and John McNaught, editors. 2006.
Text Mining for Biology And Biomedicine. Artech
House, Inc.
Riza Theresa B. Batista-Navarro and Sophia Anani-
adou. 2011. Building a coreference-annotated corpus
from the domain of biochemistry. In Proceedings of
BioNLP 2011, pages 83–91.
Olivier Bodenreider. 2004. The unified medical lan-
guage system (UMLS): integrating biomedical termi-
nology. Nucleic Acids Research, 32(suppl 1):D267–
D270.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM:
A library for support vector machines. ACM Transac-
tions on Intelligent Systems and Technology, 2:27:1–
27:27. Software available at http://www.csie.
ntu.edu.tw/˜cjlin/libsvm.
Kevin Bretonnel Cohen and Lawrence Hunter. 2008.
Getting started in text mining. PLoS Computational
Biology, 4(1):e20, 01.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge, MA.
Ken-ichiro Fukuda, Tatsuhiko Tsunoda, Ayuchi Tamura,
and Toshihisa Takagi. 1998. Toward information ex-
traction: Identifying protein names from biological pa-
pers. In Proceedings of the Pacific Symposium on Bio-
computing, volume 707, pages 707–718.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: an update.
SIGKDD Explor. Newsl., 11:10–18, November.
Samantha Kleinberg and George Hripcsak. 2011. A re-
view of causal inference for biomedical informatics.
Journal ofBiomedical Informatics, 44(6):1102 – 1112.
John D. Lafferty, Andrew McCallum, and Fernando C. N.
Pereira. 2001. Conditional random fields: Proba-
bilistic models for segmenting and labeling sequence
data. In Proceedings of the Eighteenth International
Conference on Machine Learning, ICML ’01, pages
282–289, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2012. A
pdtb-styled end-to-end discourse parser. Natural Lan-
guage Engineering, FirstView:1–34, 10.
Claudiu Mih˘ail˘a, Tomoko Ohta, Sampo Pyysalo, and
Sophia Ananiadou. 2013. BioCause: Annotating and
analysing causality in the biomedical domain. BMC
Bioinformatics, 14(1):2, January.
Makoto Miwa, Rune Sastre, Yusuke Miyao, and Jun’ichi
Tsujii. 2009. Protein-protein interaction extraction by
leveraging multiple kernels and parsers. International
Journal ofMedical Informatics, 78(12):e39–e46, June.
Makoto Miwa, Paul Thompson, and Sophia Ananiadou.
2012a. Boosting automatic event extraction from the
literature using domain adaptation and coreference
resolution. Bioinformatics, 28(13):1759–1765.
Makoto Miwa, Paul Thompson, John McNaught, Dou-
glas B. Kell, and Sophia Ananiadou. 2012b. Extract-
ing semantically enriched events from biomedical lit-
erature. BMC Bioinformatics, 13:108.
Yusuke Miyao and Jun’ichi Tsujii. 2008. Feature for-
est models for probabilistic HPSG parsing. Computa-
tional Linguistics, 34(1):3580, March.
Yusuke Miyao, Tomoko Ohta, Katsuya Masuda, Yoshi-
masa Tsuruoka, Kazuhiro Yoshida, Takashi Ninomiya,
and Jun’ichi Tsujii. 2006. Semantic retrieval for the
accurate identification of relational concepts in mas-
sive textbases. In ACL.
Emily Pitler and Ani Nenkova. 2009. Using syntax to
disambiguate explicit discourse connectives in text. In
ACL/AFNLP (Short Papers), pages 13–16.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The Penn Discourse TreeBank 2.0.
In Nicoletta Calzolari, Khalid Choukri, Bente Mae-
gaard, Joseph Mariani, Jan Odjik, Stelios Piperidis,
and Daniel Tapias, editors, In Proceedings of the 6th
International Conference on language Resources and
Evaluation (LREC), pages 2961–2968.
Rashmi Prasad, Susan McRoy, Nadya Frid, Aravind
Joshi, and Hong Yu. 2011. The biomedical discourse
relation bank. BMC Bioinformatics, 12(1):188.
Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and
Jun’ichi Tsujii. 2009. Static relations: a piece in the
biomedical information extraction puzzle. In Proceed-
ings of the Workshop on Current Trends in Biomedical
Natural Language Processing, BioNLP ’09, pages 1–
9, Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Jun’ichi Tsujii, and Sophia Ananiadou. 2011.
Overview of the infectious diseases (ID) task of
BioNLP shared task 2011. In Proceedings of the
BioNLP Shared Task 2011 Workshop, pages 26–35,
Portland, Oregon, USA, June. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.979546">
44
</page>
<reference confidence="0.999636161290323">
Polepalli Balaji Ramesh, Rashmi Prasad, Tim Miller,
Brian Harrington, and Hong Yu. 2012. Automatic dis-
course connective detection in biomedical text. Jour-
nal of the American Medical Informatics Association.
Andrey Rzhetsky, Ivan Iossifov, Tomohiro Koike,
Michael Krauthammer, Pauline Kra, Mitzi Morris,
Hong Yu, Ariel Pablo Dubou´e, Wubin Weng, W.John
Wilbur, Vasileios Hatzivassiloglou, and Carol Fried-
man. 2004. Geneways: a system for extracting, ana-
lyzing, visualizing, and integrating molecular pathway
data. Journal of Biomedical Informatics, 37(1):43 –
53.
Guergana K Savova, Wendy W Chapman, Jiaping Zheng,
and Rebecca S Crowley. 2011. Anaphoric rela-
tions in the clinical narrative: corpus creation. Jour-
nal of the American Medical Informatics Association,
18(4):459–465.
Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim,
Tomoko Ohta, John McNaught, Sophia Ananiadou,
and Jun’ichi Tsujii. 2005. Developing a robust part-
of-speech tagger for biomedical text. In Advances
in Informatics - 10th Panhellenic Conference on In-
formatics, volume 3746 of LNCS, pages 382–392.
Springer-Verlag, Volos, Greece, November.
Ian Witten and Eibe Frank. 2005. Data Mining: Prac-
tical Machine Learning Tools and Techniques (Second
Edition). Morgan Kaufmann.
Pierre Zweigenbaum, Dina Demner-Fushman, Hong Yu,
and Kevin B. Cohen. 2007. Frontiers of biomedical
text mining: current progress. Briefings in Bioinfor-
matics, 8(5):358–375.
</reference>
<page confidence="0.99939">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.306989">
<title confidence="0.9895405">What causes a causal relation? Detecting Causal Triggers in Biomedical Scientific Discourse</title>
<author confidence="0.631197">Claudiu Mih˘ail˘a</author>
<author confidence="0.631197">Sophia</author>
<affiliation confidence="0.816339333333333">The National Centre for Text School of Computer The University of</affiliation>
<address confidence="0.752985">131 Princess Street, Manchester M1 7DN,</address>
<email confidence="0.997253">sophia.ananiadou@manchester.ac.uk</email>
<abstract confidence="0.997935636363636">Current domain-specific information extraction systems represent an important resource for biomedical researchers, who need to process vaster amounts of knowledge in short times. Automatic discourse causality recognition can further improve their workload by suggesting possible causal connections and aiding in the curation of pathway models. We here describe an approach to the automatic identification of discourse causality triggers in the biomedical domain using machine learning. We create several baselines and experiment with various parameter settings for three algorithms, i.e., Conditional Random Fields (CRF), Support Vector Machines (SVM) and Random Forests (RF). Also, we evaluate the impact of lexical, syntactic and semantic features on each of the algorithms and look at errors. The best performance of 79.35% F-score is achieved by CRFs when using all three feature types.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sophia Ananiadou</author>
<author>John McNaught</author>
<author>editors</author>
</authors>
<title>Text Mining for Biology And Biomedicine.</title>
<date>2006</date>
<publisher>Artech House, Inc.</publisher>
<marker>Ananiadou, McNaught, editors, 2006</marker>
<rawString>Sophia Ananiadou and John McNaught, editors. 2006. Text Mining for Biology And Biomedicine. Artech House, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Riza Theresa B Batista-Navarro</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Building a coreference-annotated corpus from the domain of biochemistry.</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP</booktitle>
<pages>83--91</pages>
<contexts>
<context position="1787" citStr="Batista-Navarro and Ananiadou, 2011" startWordPosition="249" endWordPosition="252">rformance of 79.35% F-score is achieved by CRFs when using all three feature types. 1 Introduction The need to provide automated, efficient and accurate means of retrieving and extracting user-oriented biomedical knowledge has significantly increased according to the ever-increasing amount of knowledge pusblished daily in the form of research articles (Ananiadou and McNaught, 2006; Cohen and Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 2006). However, more complex tasks, such as question answering and automatic summarisation, require the extraction of information that spans across several sentences, together with the recognition of relations that exist across s</context>
</contexts>
<marker>Batista-Navarro, Ananiadou, 2011</marker>
<rawString>Riza Theresa B. Batista-Navarro and Sophia Ananiadou. 2011. Building a coreference-annotated corpus from the domain of biochemistry. In Proceedings of BioNLP 2011, pages 83–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Bodenreider</author>
</authors>
<title>The unified medical language system (UMLS): integrating biomedical terminology.</title>
<date>2004</date>
<booktitle>Nucleic Acids Research, 32(suppl 1):D267– D270.</booktitle>
<contexts>
<context position="12345" citStr="Bodenreider, 2004" startWordPosition="1970" endWordPosition="1971">on. The named entity and event annotation in the BioCause corpus is used to extract information about whether a token is part of a named entity or event trigger. Furthermore, the type of the named entity or event is included as a separate feature. The second semantic knowledge source is WordNet (Fellbaum, 1998). Using this resource, the hypernym of every token in the text has been included as a feature. Only the first sense of every token has been considered, as no sense disambiguation technique has been employed. Finally, tokens have been linked to the Unified Medical Language System (UMLS) (Bodenreider, 2004) semantic types. Thus, we included a feature to say whether a token is part of a UMLS type and another for its semantic type if the previous is true. 3.3 Experimental setup We explored with various machine learning algorithms and various settings for the task of identifying causal triggers. On the one hand, we experimented with CRF (Lafferty et al., 2001), a probabilistic modelling framework commonly used for sequence labelling tasks. In this work, we employed the CRFSuite implementation1. 1http://www.chokkan.org/software/ crfsuite On the other hand, we modelled trigger detection as a classifi</context>
</contexts>
<marker>Bodenreider, 2004</marker>
<rawString>Olivier Bodenreider. 2004. The unified medical language system (UMLS): integrating biomedical terminology. Nucleic Acids Research, 32(suppl 1):D267– D270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<volume>2</volume>
<pages>27--27</pages>
<note>Software available at http://www.csie. ntu.edu.tw/˜cjlin/libsvm.</note>
<contexts>
<context position="13151" citStr="Chang and Lin, 2011" startWordPosition="2096" endWordPosition="2099">ith various machine learning algorithms and various settings for the task of identifying causal triggers. On the one hand, we experimented with CRF (Lafferty et al., 2001), a probabilistic modelling framework commonly used for sequence labelling tasks. In this work, we employed the CRFSuite implementation1. 1http://www.chokkan.org/software/ crfsuite On the other hand, we modelled trigger detection as a classification task, using Support Vector Machines and Random Forests. More specifically, we employed the implementation in Weka (Hall et al., 2009; Witten and Frank, 2005) for RFs, and LibSVM (Chang and Lin, 2011) for SVMs. 4 Results and discussion Several models have been developed and 10-fold cross-evaluated to examine the complexity of the task, the impact of various feature types (lexical, syntactic, semantic). Table 1 shows the performance evaluation of baseline systems and other classifiers. These are described in the following subsections. It should be noted that the dataset is highly skewed, with a ratio of positive examples to negative examples of approximately 1:52. Classifier P R Fl Baseline Dict 8.36 100 15.43 Dep 7.51 76.66 13.68 Dict+Dep 14.30 75.33 24.03 2-way CRF 89.29 73.53 79.35 SVM 8</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1– 27:27. Software available at http://www.csie. ntu.edu.tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Bretonnel Cohen</author>
<author>Lawrence Hunter</author>
</authors>
<title>Getting started in text mining.</title>
<date>2008</date>
<journal>PLoS Computational Biology,</journal>
<volume>4</volume>
<issue>1</issue>
<pages>01</pages>
<contexts>
<context position="1560" citStr="Cohen and Hunter, 2008" startWordPosition="219" endWordPosition="222">ditional Random Fields (CRF), Support Vector Machines (SVM) and Random Forests (RF). Also, we evaluate the impact of lexical, syntactic and semantic features on each of the algorithms and look at errors. The best performance of 79.35% F-score is achieved by CRFs when using all three feature types. 1 Introduction The need to provide automated, efficient and accurate means of retrieving and extracting user-oriented biomedical knowledge has significantly increased according to the ever-increasing amount of knowledge pusblished daily in the form of research articles (Ananiadou and McNaught, 2006; Cohen and Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 20</context>
</contexts>
<marker>Cohen, Hunter, 2008</marker>
<rawString>Kevin Bretonnel Cohen and Lawrence Hunter. 2008. Getting started in text mining. PLoS Computational Biology, 4(1):e20, 01.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken-ichiro Fukuda</author>
<author>Tatsuhiko Tsunoda</author>
<author>Ayuchi Tamura</author>
<author>Toshihisa Takagi</author>
</authors>
<title>Toward information extraction: Identifying protein names from biological papers.</title>
<date>1998</date>
<booktitle>In Proceedings of the Pacific Symposium on Biocomputing,</booktitle>
<volume>707</volume>
<pages>707--718</pages>
<contexts>
<context position="1726" citStr="Fukuda et al., 1998" startWordPosition="243" endWordPosition="246">the algorithms and look at errors. The best performance of 79.35% F-score is achieved by CRFs when using all three feature types. 1 Introduction The need to provide automated, efficient and accurate means of retrieving and extracting user-oriented biomedical knowledge has significantly increased according to the ever-increasing amount of knowledge pusblished daily in the form of research articles (Ananiadou and McNaught, 2006; Cohen and Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 2006). However, more complex tasks, such as question answering and automatic summarisation, require the extraction of information that spans across several sentences, t</context>
</contexts>
<marker>Fukuda, Tsunoda, Tamura, Takagi, 1998</marker>
<rawString>Ken-ichiro Fukuda, Tatsuhiko Tsunoda, Ayuchi Tamura, and Toshihisa Takagi. 1998. Toward information extraction: Identifying protein names from biological papers. In Proceedings of the Pacific Symposium on Biocomputing, volume 707, pages 707–718.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA data mining software: an update.</title>
<date>2009</date>
<journal>SIGKDD Explor. Newsl.,</journal>
<pages>11--10</pages>
<contexts>
<context position="13084" citStr="Hall et al., 2009" startWordPosition="2083" endWordPosition="2086">pe if the previous is true. 3.3 Experimental setup We explored with various machine learning algorithms and various settings for the task of identifying causal triggers. On the one hand, we experimented with CRF (Lafferty et al., 2001), a probabilistic modelling framework commonly used for sequence labelling tasks. In this work, we employed the CRFSuite implementation1. 1http://www.chokkan.org/software/ crfsuite On the other hand, we modelled trigger detection as a classification task, using Support Vector Machines and Random Forests. More specifically, we employed the implementation in Weka (Hall et al., 2009; Witten and Frank, 2005) for RFs, and LibSVM (Chang and Lin, 2011) for SVMs. 4 Results and discussion Several models have been developed and 10-fold cross-evaluated to examine the complexity of the task, the impact of various feature types (lexical, syntactic, semantic). Table 1 shows the performance evaluation of baseline systems and other classifiers. These are described in the following subsections. It should be noted that the dataset is highly skewed, with a ratio of positive examples to negative examples of approximately 1:52. Classifier P R Fl Baseline Dict 8.36 100 15.43 Dep 7.51 76.66</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: an update. SIGKDD Explor. Newsl., 11:10–18, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samantha Kleinberg</author>
<author>George Hripcsak</author>
</authors>
<title>A review of causal inference for biomedical informatics.</title>
<date>2011</date>
<journal>Journal ofBiomedical Informatics,</journal>
<volume>44</volume>
<issue>6</issue>
<pages>1112</pages>
<contexts>
<context position="4966" citStr="Kleinberg and Hripcsak, 2011" startWordPosition="745" endWordPosition="748">ourse relation identification exists in the general domain, where researchers have not only identified discourse connectives, but also developed end-to-end discourse parsers (Pitler and Nenkova, 2009; Lin et al., 2012). Most work is based on the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), a corpus of lexically-grounded annotations of discourse relations. Until now, comparatively little work has been carried out on causal discourse relations in the biomedical domain, although causal associations between biological entities, events and processes are central to most claims of interest (Kleinberg and Hripcsak, 2011). The equivalent of the PDTB for the biomedical domain is the BioDRB corpus (Prasad et al., 2011), containing 16 types of discourse relations, e.g., temporal, causal and conditional. The number of purely causal relations annotated in this corpus is 542. There are another 23 relations which are a mixture between causality and one of either background, temporal, conjunction or reinforcement relations. A slightly larger corpus is the BioCause (Mih˘ail˘a et al., 2013), containing over 850 manually annotated causal discourse relations in 19 full-text open-access journal articles from the infectious</context>
</contexts>
<marker>Kleinberg, Hripcsak, 2011</marker>
<rawString>Samantha Kleinberg and George Hripcsak. 2011. A review of causal inference for biomedical informatics. Journal ofBiomedical Informatics, 44(6):1102 – 1112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="12702" citStr="Lafferty et al., 2001" startWordPosition="2030" endWordPosition="2033">ery token in the text has been included as a feature. Only the first sense of every token has been considered, as no sense disambiguation technique has been employed. Finally, tokens have been linked to the Unified Medical Language System (UMLS) (Bodenreider, 2004) semantic types. Thus, we included a feature to say whether a token is part of a UMLS type and another for its semantic type if the previous is true. 3.3 Experimental setup We explored with various machine learning algorithms and various settings for the task of identifying causal triggers. On the one hand, we experimented with CRF (Lafferty et al., 2001), a probabilistic modelling framework commonly used for sequence labelling tasks. In this work, we employed the CRFSuite implementation1. 1http://www.chokkan.org/software/ crfsuite On the other hand, we modelled trigger detection as a classification task, using Support Vector Machines and Random Forests. More specifically, we employed the implementation in Weka (Hall et al., 2009; Witten and Frank, 2005) for RFs, and LibSVM (Chang and Lin, 2011) for SVMs. 4 Results and discussion Several models have been developed and 10-fold cross-evaluated to examine the complexity of the task, the impact of</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01, pages 282–289, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ziheng Lin</author>
<author>Hwee Tou Ng</author>
<author>Min-Yen Kan</author>
</authors>
<title>A pdtb-styled end-to-end discourse parser.</title>
<date>2012</date>
<journal>Natural Language Engineering, FirstView:1–34,</journal>
<volume>10</volume>
<contexts>
<context position="4555" citStr="Lin et al., 2012" startWordPosition="684" endWordPosition="687">s causal triggers in certain contexts may not denote causality in all cases. Therefore, a dictionary-based approach is likely to produce a very high number of false positives. In this paper, we explore several supervised machinelearning approaches to the automatic identification of triggers that actually denote causality. 2 Related Work A large amount of work related to discourse parsing and discourse relation identification exists in the general domain, where researchers have not only identified discourse connectives, but also developed end-to-end discourse parsers (Pitler and Nenkova, 2009; Lin et al., 2012). Most work is based on the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), a corpus of lexically-grounded annotations of discourse relations. Until now, comparatively little work has been carried out on causal discourse relations in the biomedical domain, although causal associations between biological entities, events and processes are central to most claims of interest (Kleinberg and Hripcsak, 2011). The equivalent of the PDTB for the biomedical domain is the BioDRB corpus (Prasad et al., 2011), containing 16 types of discourse relations, e.g., temporal, causal and conditional. The nu</context>
</contexts>
<marker>Lin, Ng, Kan, 2012</marker>
<rawString>Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2012. A pdtb-styled end-to-end discourse parser. Natural Language Engineering, FirstView:1–34, 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudiu Mih˘ail˘a</author>
<author>Tomoko Ohta</author>
<author>Sampo Pyysalo</author>
<author>Sophia Ananiadou</author>
</authors>
<title>BioCause: Annotating and analysing causality in the biomedical domain.</title>
<date>2013</date>
<journal>BMC Bioinformatics,</journal>
<volume>14</volume>
<issue>1</issue>
<marker>Mih˘ail˘a, Ohta, Pyysalo, Ananiadou, 2013</marker>
<rawString>Claudiu Mih˘ail˘a, Tomoko Ohta, Sampo Pyysalo, and Sophia Ananiadou. 2013. BioCause: Annotating and analysing causality in the biomedical domain. BMC Bioinformatics, 14(1):2, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Miwa</author>
<author>Rune Sastre</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Protein-protein interaction extraction by leveraging multiple kernels and parsers.</title>
<date>2009</date>
<journal>International Journal ofMedical Informatics,</journal>
<volume>78</volume>
<issue>12</issue>
<contexts>
<context position="1841" citStr="Miwa et al., 2009" startWordPosition="259" endWordPosition="262">ture types. 1 Introduction The need to provide automated, efficient and accurate means of retrieving and extracting user-oriented biomedical knowledge has significantly increased according to the ever-increasing amount of knowledge pusblished daily in the form of research articles (Ananiadou and McNaught, 2006; Cohen and Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 2006). However, more complex tasks, such as question answering and automatic summarisation, require the extraction of information that spans across several sentences, together with the recognition of relations that exist across sentence boundaries, in order to achieve high levels of</context>
</contexts>
<marker>Miwa, Sastre, Miyao, Tsujii, 2009</marker>
<rawString>Makoto Miwa, Rune Sastre, Yusuke Miyao, and Jun’ichi Tsujii. 2009. Protein-protein interaction extraction by leveraging multiple kernels and parsers. International Journal ofMedical Informatics, 78(12):e39–e46, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Miwa</author>
<author>Paul Thompson</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Boosting automatic event extraction from the literature using domain adaptation and coreference resolution.</title>
<date>2012</date>
<journal>Bioinformatics,</journal>
<volume>28</volume>
<issue>13</issue>
<contexts>
<context position="1904" citStr="Miwa et al., 2012" startWordPosition="270" endWordPosition="273">ient and accurate means of retrieving and extracting user-oriented biomedical knowledge has significantly increased according to the ever-increasing amount of knowledge pusblished daily in the form of research articles (Ananiadou and McNaught, 2006; Cohen and Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 2006). However, more complex tasks, such as question answering and automatic summarisation, require the extraction of information that spans across several sentences, together with the recognition of relations that exist across sentence boundaries, in order to achieve high levels of performance. The notion of discourse can be defined as a coher</context>
</contexts>
<marker>Miwa, Thompson, Ananiadou, 2012</marker>
<rawString>Makoto Miwa, Paul Thompson, and Sophia Ananiadou. 2012a. Boosting automatic event extraction from the literature using domain adaptation and coreference resolution. Bioinformatics, 28(13):1759–1765.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Miwa</author>
<author>Paul Thompson</author>
<author>John McNaught</author>
<author>Douglas B Kell</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Extracting semantically enriched events from biomedical literature.</title>
<date>2012</date>
<journal>BMC Bioinformatics,</journal>
<pages>13--108</pages>
<contexts>
<context position="1904" citStr="Miwa et al., 2012" startWordPosition="270" endWordPosition="273">ient and accurate means of retrieving and extracting user-oriented biomedical knowledge has significantly increased according to the ever-increasing amount of knowledge pusblished daily in the form of research articles (Ananiadou and McNaught, 2006; Cohen and Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 2006). However, more complex tasks, such as question answering and automatic summarisation, require the extraction of information that spans across several sentences, together with the recognition of relations that exist across sentence boundaries, in order to achieve high levels of performance. The notion of discourse can be defined as a coher</context>
</contexts>
<marker>Miwa, Thompson, McNaught, Kell, Ananiadou, 2012</marker>
<rawString>Makoto Miwa, Paul Thompson, John McNaught, Douglas B. Kell, and Sophia Ananiadou. 2012b. Extracting semantically enriched events from biomedical literature. BMC Bioinformatics, 13:108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Feature forest models for probabilistic HPSG parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="8652" citStr="Miyao and Tsujii, 2008" startWordPosition="1339" endWordPosition="1342">ft and the one immediately to the right of the current token. This decision is based on two observations. Firstly, in the case of tokens to the left, most triggers are found either at the beginning of the sentence (311 instances) or are preceded by a comma (238 instances). These two left contexts represent 69% of all triggers. Secondly, for the tokens to the right, almost 45% of triggers are followed by a determiner, such as the, a or an, (281 instances) or a comma (71 instances). 3.2.2 Syntactic features The syntax, dependency and predicate argument structure are produced by the Enju parser (Miyao and Tsujii, 2008). Figure 2 depicts a partial lexical parse tree of a sentence which starts with a causal trigger, namely Our results suggest that. From the lexical parse trees, several types of features have been generated. The first two features represent the part-of-speech and syntactic category of a token. For instance, the figure shows that the token that has the part-ofspeech IN. These features are included due to the fact that either many triggers are lexicalised as an adverb or conjunction, or are part of a verb phrase. For the same reason, the syntactical category path from the root of the lexical par</context>
</contexts>
<marker>Miyao, Tsujii, 2008</marker>
<rawString>Yusuke Miyao and Jun’ichi Tsujii. 2008. Feature forest models for probabilistic HPSG parsing. Computational Linguistics, 34(1):3580, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Tomoko Ohta</author>
<author>Katsuya Masuda</author>
</authors>
<title>Semantic retrieval for the accurate identification of relational concepts in massive textbases.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<location>Yoshimasa Tsuruoka, Kazuhiro Yoshida, Takashi Ninomiya, and</location>
<contexts>
<context position="2163" citStr="Miyao et al., 2006" startWordPosition="314" endWordPosition="317">nd Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 2006). However, more complex tasks, such as question answering and automatic summarisation, require the extraction of information that spans across several sentences, together with the recognition of relations that exist across sentence boundaries, in order to achieve high levels of performance. The notion of discourse can be defined as a coherent sequence of clauses and sentences. These are connected in a logical manner by discourse relations, such as causal, temporal and conditional, which characterise how facts in text are related. In turn, these help readers infer deeper, more complex knowledge</context>
</contexts>
<marker>Miyao, Ohta, Masuda, 2006</marker>
<rawString>Yusuke Miyao, Tomoko Ohta, Katsuya Masuda, Yoshimasa Tsuruoka, Kazuhiro Yoshida, Takashi Ninomiya, and Jun’ichi Tsujii. 2006. Semantic retrieval for the accurate identification of relational concepts in massive textbases. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Ani Nenkova</author>
</authors>
<title>Using syntax to disambiguate explicit discourse connectives in text.</title>
<date>2009</date>
<booktitle>In ACL/AFNLP (Short Papers),</booktitle>
<pages>13--16</pages>
<contexts>
<context position="4536" citStr="Pitler and Nenkova, 2009" startWordPosition="680" endWordPosition="683"> However, phrases acting as causal triggers in certain contexts may not denote causality in all cases. Therefore, a dictionary-based approach is likely to produce a very high number of false positives. In this paper, we explore several supervised machinelearning approaches to the automatic identification of triggers that actually denote causality. 2 Related Work A large amount of work related to discourse parsing and discourse relation identification exists in the general domain, where researchers have not only identified discourse connectives, but also developed end-to-end discourse parsers (Pitler and Nenkova, 2009; Lin et al., 2012). Most work is based on the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), a corpus of lexically-grounded annotations of discourse relations. Until now, comparatively little work has been carried out on causal discourse relations in the biomedical domain, although causal associations between biological entities, events and processes are central to most claims of interest (Kleinberg and Hripcsak, 2011). The equivalent of the PDTB for the biomedical domain is the BioDRB corpus (Prasad et al., 2011), containing 16 types of discourse relations, e.g., temporal, causal and </context>
</contexts>
<marker>Pitler, Nenkova, 2009</marker>
<rawString>Emily Pitler and Ani Nenkova. 2009. Using syntax to disambiguate explicit discourse connectives in text. In ACL/AFNLP (Short Papers), pages 13–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>The Penn Discourse TreeBank 2.0.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on language Resources and Evaluation (LREC),</booktitle>
<pages>2961--2968</pages>
<editor>In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odjik, Stelios Piperidis, and Daniel Tapias, editors,</editor>
<contexts>
<context position="4635" citStr="Prasad et al., 2008" startWordPosition="698" endWordPosition="701">Therefore, a dictionary-based approach is likely to produce a very high number of false positives. In this paper, we explore several supervised machinelearning approaches to the automatic identification of triggers that actually denote causality. 2 Related Work A large amount of work related to discourse parsing and discourse relation identification exists in the general domain, where researchers have not only identified discourse connectives, but also developed end-to-end discourse parsers (Pitler and Nenkova, 2009; Lin et al., 2012). Most work is based on the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), a corpus of lexically-grounded annotations of discourse relations. Until now, comparatively little work has been carried out on causal discourse relations in the biomedical domain, although causal associations between biological entities, events and processes are central to most claims of interest (Kleinberg and Hripcsak, 2011). The equivalent of the PDTB for the biomedical domain is the BioDRB corpus (Prasad et al., 2011), containing 16 types of discourse relations, e.g., temporal, causal and conditional. The number of purely causal relations annotated in this corpus is 542. There are anoth</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse TreeBank 2.0. In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odjik, Stelios Piperidis, and Daniel Tapias, editors, In Proceedings of the 6th International Conference on language Resources and Evaluation (LREC), pages 2961–2968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Susan McRoy</author>
<author>Nadya Frid</author>
<author>Aravind Joshi</author>
<author>Hong Yu</author>
</authors>
<title>The biomedical discourse relation bank.</title>
<date>2011</date>
<journal>BMC Bioinformatics,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="5063" citStr="Prasad et al., 2011" startWordPosition="763" endWordPosition="766">course connectives, but also developed end-to-end discourse parsers (Pitler and Nenkova, 2009; Lin et al., 2012). Most work is based on the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), a corpus of lexically-grounded annotations of discourse relations. Until now, comparatively little work has been carried out on causal discourse relations in the biomedical domain, although causal associations between biological entities, events and processes are central to most claims of interest (Kleinberg and Hripcsak, 2011). The equivalent of the PDTB for the biomedical domain is the BioDRB corpus (Prasad et al., 2011), containing 16 types of discourse relations, e.g., temporal, causal and conditional. The number of purely causal relations annotated in this corpus is 542. There are another 23 relations which are a mixture between causality and one of either background, temporal, conjunction or reinforcement relations. A slightly larger corpus is the BioCause (Mih˘ail˘a et al., 2013), containing over 850 manually annotated causal discourse relations in 19 full-text open-access journal articles from the infectious diseases domain. Using the BioDRB corpus as data, some researchers explored the identification o</context>
</contexts>
<marker>Prasad, McRoy, Frid, Joshi, Yu, 2011</marker>
<rawString>Rashmi Prasad, Susan McRoy, Nadya Frid, Aravind Joshi, and Hong Yu. 2011. The biomedical discourse relation bank. BMC Bioinformatics, 12(1):188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Tomoko Ohta</author>
<author>Jin-Dong Kim</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Static relations: a piece in the biomedical information extraction puzzle.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing, BioNLP ’09,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1864" citStr="Pyysalo et al., 2009" startWordPosition="263" endWordPosition="266">duction The need to provide automated, efficient and accurate means of retrieving and extracting user-oriented biomedical knowledge has significantly increased according to the ever-increasing amount of knowledge pusblished daily in the form of research articles (Ananiadou and McNaught, 2006; Cohen and Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 2006). However, more complex tasks, such as question answering and automatic summarisation, require the extraction of information that spans across several sentences, together with the recognition of relations that exist across sentence boundaries, in order to achieve high levels of performance. The notio</context>
</contexts>
<marker>Pyysalo, Ohta, Kim, Tsujii, 2009</marker>
<rawString>Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and Jun’ichi Tsujii. 2009. Static relations: a piece in the biomedical information extraction puzzle. In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing, BioNLP ’09, pages 1– 9, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Tomoko Ohta</author>
<author>Rafal Rak</author>
<author>Dan Sullivan</author>
<author>Chunhong Mao</author>
<author>Chunxia Wang</author>
<author>Bruno Sobral</author>
<author>Jun’ichi Tsujii</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Overview of the infectious diseases (ID) task of BioNLP shared task</title>
<date>2011</date>
<booktitle>In Proceedings of the BioNLP Shared Task 2011 Workshop,</booktitle>
<pages>26--35</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="11413" citStr="Pyysalo et al., 2011" startWordPosition="1813" endWordPosition="1816">er40 age distance to the lowest common ancestor is 3. 3.2.3 Semantic features We have exploited several semantic knowledge sources to identify causal triggers more accurately, as a mapping to concepts and named entities acts as a back-off smoothing, thus increasing performance. One semantic knowledge source is the BioCause corpus itself. All documents annotated for causality in BioCause had been previously manually annotated with biomedical named entity and event information. This was performed in the context of various shared tasks, such as the BioNLP 2011 Shared Task on Infectious Diseases (Pyysalo et al., 2011). We therefore leverage this existing information to add another semantic layer to the model. Moreover, another advantage of having a gold standard annotation is the fact that it is now possible to separate the task of automatic causal trigger recognition from automatic named entity recognition and event extraction. The named entity and event annotation in the BioCause corpus is used to extract information about whether a token is part of a named entity or event trigger. Furthermore, the type of the named entity or event is included as a separate feature. The second semantic knowledge source i</context>
</contexts>
<marker>Pyysalo, Ohta, Rak, Sullivan, Mao, Wang, Sobral, Tsujii, Ananiadou, 2011</marker>
<rawString>Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sullivan, Chunhong Mao, Chunxia Wang, Bruno Sobral, Jun’ichi Tsujii, and Sophia Ananiadou. 2011. Overview of the infectious diseases (ID) task of BioNLP shared task 2011. In Proceedings of the BioNLP Shared Task 2011 Workshop, pages 26–35, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Polepalli Balaji Ramesh</author>
<author>Rashmi Prasad</author>
<author>Tim Miller</author>
<author>Brian Harrington</author>
<author>Hong Yu</author>
</authors>
<title>Automatic discourse connective detection in biomedical text.</title>
<date>2012</date>
<journal>Journal of the American Medical Informatics Association.</journal>
<contexts>
<context position="5708" citStr="Ramesh et al., 2012" startWordPosition="857" endWordPosition="860">discourse relations, e.g., temporal, causal and conditional. The number of purely causal relations annotated in this corpus is 542. There are another 23 relations which are a mixture between causality and one of either background, temporal, conjunction or reinforcement relations. A slightly larger corpus is the BioCause (Mih˘ail˘a et al., 2013), containing over 850 manually annotated causal discourse relations in 19 full-text open-access journal articles from the infectious diseases domain. Using the BioDRB corpus as data, some researchers explored the identification of discourse connectives (Ramesh et al., 2012). However, they do not distinguish between the types of discourse relations. They obtain the best F-score of 75.7% using CRF, with SVM reaching only 65.7%. These results were obtained by using only syntactic features, as sematic features were shown to lower the performance. Also, they prove that there exist differences in discourse triggers between the biomedical and general domains by training a model on the BioDRB and evaluating it against PDTB and viceversa. 3 Methodology In this section, we describe our data and the features of causal triggers. We also explain our evaluation methodology. 3</context>
</contexts>
<marker>Ramesh, Prasad, Miller, Harrington, Yu, 2012</marker>
<rawString>Polepalli Balaji Ramesh, Rashmi Prasad, Tim Miller, Brian Harrington, and Hong Yu. 2012. Automatic discourse connective detection in biomedical text. Journal of the American Medical Informatics Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrey Rzhetsky</author>
<author>Ivan Iossifov</author>
<author>Tomohiro Koike</author>
<author>Michael Krauthammer</author>
<author>Pauline Kra</author>
<author>Mitzi Morris</author>
<author>Hong Yu</author>
<author>Ariel Pablo Dubou´e</author>
<author>Wubin Weng</author>
<author>W John Wilbur</author>
<author>Vasileios Hatzivassiloglou</author>
<author>Carol Friedman</author>
</authors>
<title>Geneways: a system for extracting, analyzing, visualizing, and integrating molecular pathway data.</title>
<date>2004</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>37</volume>
<issue>1</issue>
<marker>Rzhetsky, Iossifov, Koike, Krauthammer, Kra, Morris, Yu, Dubou´e, Weng, Wilbur, Hatzivassiloglou, Friedman, 2004</marker>
<rawString>Andrey Rzhetsky, Ivan Iossifov, Tomohiro Koike, Michael Krauthammer, Pauline Kra, Mitzi Morris, Hong Yu, Ariel Pablo Dubou´e, Wubin Weng, W.John Wilbur, Vasileios Hatzivassiloglou, and Carol Friedman. 2004. Geneways: a system for extracting, analyzing, visualizing, and integrating molecular pathway data. Journal of Biomedical Informatics, 37(1):43 – 53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guergana K Savova</author>
<author>Wendy W Chapman</author>
<author>Jiaping Zheng</author>
<author>Rebecca S Crowley</author>
</authors>
<title>Anaphoric relations in the clinical narrative: corpus creation.</title>
<date>2011</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="1809" citStr="Savova et al., 2011" startWordPosition="253" endWordPosition="256">ed by CRFs when using all three feature types. 1 Introduction The need to provide automated, efficient and accurate means of retrieving and extracting user-oriented biomedical knowledge has significantly increased according to the ever-increasing amount of knowledge pusblished daily in the form of research articles (Ananiadou and McNaught, 2006; Cohen and Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 2006). However, more complex tasks, such as question answering and automatic summarisation, require the extraction of information that spans across several sentences, together with the recognition of relations that exist across sentence boundaries, in</context>
</contexts>
<marker>Savova, Chapman, Zheng, Crowley, 2011</marker>
<rawString>Guergana K Savova, Wendy W Chapman, Jiaping Zheng, and Rebecca S Crowley. 2011. Anaphoric relations in the clinical narrative: corpus creation. Journal of the American Medical Informatics Association, 18(4):459–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Yuka Tateishi</author>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>John McNaught</author>
<author>Sophia Ananiadou</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Developing a robust partof-speech tagger for biomedical text.</title>
<date>2005</date>
<booktitle>In Advances in Informatics - 10th Panhellenic Conference on Informatics,</booktitle>
<volume>3746</volume>
<pages>382--392</pages>
<publisher>Springer-Verlag,</publisher>
<location>Volos, Greece,</location>
<contexts>
<context position="7827" citStr="Tsuruoka et al., 2005" startWordPosition="1198" endWordPosition="1201">unique triggers when they are lemmatised, corresponding to an average usage of 2.30 times per trigger. Both count settings show the diversity of causality-triggering phrases that are used in the biomedical domain. 3.2 Features Three types of features have been employed in the development of this causality trigger model, i.e., lexical, syntactic and semantic. These features are categorised and described below. 3.2.1 Lexical features The lexical features are built from the actual tokens present in text. Tokenisation is performed by 39 Figure 1: Causal relation in the BioCause. the GENIA tagger (Tsuruoka et al., 2005) using the biomedical model. The first two features represent the token’s surface expression and its base form. Neighbouring tokens have also been considered. We included the token immediately to the left and the one immediately to the right of the current token. This decision is based on two observations. Firstly, in the case of tokens to the left, most triggers are found either at the beginning of the sentence (311 instances) or are preceded by a comma (238 instances). These two left contexts represent 69% of all triggers. Secondly, for the tokens to the right, almost 45% of triggers are fol</context>
</contexts>
<marker>Tsuruoka, Tateishi, Kim, Ohta, McNaught, Ananiadou, Tsujii, 2005</marker>
<rawString>Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim, Tomoko Ohta, John McNaught, Sophia Ananiadou, and Jun’ichi Tsujii. 2005. Developing a robust partof-speech tagger for biomedical text. In Advances in Informatics - 10th Panhellenic Conference on Informatics, volume 3746 of LNCS, pages 382–392. Springer-Verlag, Volos, Greece, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2005</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques (Second Edition).</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="13109" citStr="Witten and Frank, 2005" startWordPosition="2087" endWordPosition="2090">is true. 3.3 Experimental setup We explored with various machine learning algorithms and various settings for the task of identifying causal triggers. On the one hand, we experimented with CRF (Lafferty et al., 2001), a probabilistic modelling framework commonly used for sequence labelling tasks. In this work, we employed the CRFSuite implementation1. 1http://www.chokkan.org/software/ crfsuite On the other hand, we modelled trigger detection as a classification task, using Support Vector Machines and Random Forests. More specifically, we employed the implementation in Weka (Hall et al., 2009; Witten and Frank, 2005) for RFs, and LibSVM (Chang and Lin, 2011) for SVMs. 4 Results and discussion Several models have been developed and 10-fold cross-evaluated to examine the complexity of the task, the impact of various feature types (lexical, syntactic, semantic). Table 1 shows the performance evaluation of baseline systems and other classifiers. These are described in the following subsections. It should be noted that the dataset is highly skewed, with a ratio of positive examples to negative examples of approximately 1:52. Classifier P R Fl Baseline Dict 8.36 100 15.43 Dep 7.51 76.66 13.68 Dict+Dep 14.30 75.</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Ian Witten and Eibe Frank. 2005. Data Mining: Practical Machine Learning Tools and Techniques (Second Edition). Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Zweigenbaum</author>
<author>Dina Demner-Fushman</author>
<author>Hong Yu</author>
<author>Kevin B Cohen</author>
</authors>
<title>Frontiers of biomedical text mining: current progress.</title>
<date>2007</date>
<journal>Briefings in Bioinformatics,</journal>
<volume>8</volume>
<issue>5</issue>
<contexts>
<context position="1668" citStr="Zweigenbaum et al., 2007" startWordPosition="234" endWordPosition="237"> impact of lexical, syntactic and semantic features on each of the algorithms and look at errors. The best performance of 79.35% F-score is achieved by CRFs when using all three feature types. 1 Introduction The need to provide automated, efficient and accurate means of retrieving and extracting user-oriented biomedical knowledge has significantly increased according to the ever-increasing amount of knowledge pusblished daily in the form of research articles (Ananiadou and McNaught, 2006; Cohen and Hunter, 2008). Biomedical text mining has seen significant recent advancements in recent years (Zweigenbaum et al., 2007), including named entity recognition (Fukuda et al., 1998), coreference resolution (Batista-Navarro and Ananiadou, 2011; Savova et al., 2011) and relation (Miwa et al., 2009; Pyysalo et al., 2009) and event extraction (Miwa et al., 2012b; Miwa et al., 2012a). Using biomedical text mining technology, text can now be enriched via the addition of semantic metadata and thus can support tasks such as analysing molecular pathways (Rzhetsky et al., 2004) and semantic searching (Miyao et al., 2006). However, more complex tasks, such as question answering and automatic summarisation, require the extrac</context>
</contexts>
<marker>Zweigenbaum, Demner-Fushman, Yu, Cohen, 2007</marker>
<rawString>Pierre Zweigenbaum, Dina Demner-Fushman, Hong Yu, and Kevin B. Cohen. 2007. Frontiers of biomedical text mining: current progress. Briefings in Bioinformatics, 8(5):358–375.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>