<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002438">
<title confidence="0.998287">
Towards a Discourse Relation-aware Approach
for Chinese-English Machine Translation
</title>
<author confidence="0.995639">
Frances Yung
</author>
<affiliation confidence="0.999774">
Nara Institute of Science and Technology
</affiliation>
<address confidence="0.686819">
8916-5 Takayama, Ikoma, Nara, 630-0192 Japan
</address>
<email confidence="0.998714">
pikyufrances-y@is.naist.jp
</email>
<sectionHeader confidence="0.997388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999399">
Translation of discourse relations is one
of the recent efforts of incorporating dis-
course information to statistical machine
translation (SMT). While existing works
focus on disambiguation of ambiguous
discourse connectives, or transformation
of discourse trees, only explicit discourse
relations are tackled. A greater challenge
exists in machine translation of Chinese,
since implicit discourse relations are abun-
dant and occur both inside and outside a
sentence. This thesis proposal describes
ongoing work on bilingual discourse anno-
tation and plans towards incorporating dis-
course relation knowledge to a Chinese-
English SMT system with consideration of
implicit discourse relations. The final goal
is a discourse-unit-based translation model
unbounded by the traditional assumption
of sentence-to-sentence translation.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999951431372549">
Human translation is created at document level,
suggesting that translation of a particular sentence
depends also on the ‘discourse structure’. Re-
cently, some MT researchers have started to ex-
plore the possibility to incorporate linguistic in-
formation outside the sentence boundary for MT,
such as topical structure, coreference chains, and
lexical coherence. Among various discourse struc-
tures, discourse relations, also known as coher-
ence relations, are meaningful relations connect-
ing text segments and are crucial to the human
cognitive processing as well as memory of texts
(Sanders and Noordman, 2000). These relations
can be explicitly marked in a text by signaling
phrases or implicitly implied. Even when they
are explicit, some markers are ambiguous and
do not always signal the same relation. In ad-
dition, strategies to represent discourse relations
vary across languages. It is thus a challenging task
to correctly translate discourse relations.
This thesis proposal presents my plan to-
wards building a discourse-relation-aware ma-
chine translation system translating from Chinese
to English. In particular, I would like to focus on
modeling the translation of implicit discourse re-
lations, which has not yet been exploited to date
to my knowledge, but is yet a noticeable problem
since implicit discourse relations are abundant in
Chinese. According to the statistics of the bilin-
gual discourse annotation in progress, about 1/4 of
the Chinese implicit DCs are translated to explicit
DCs in English.
A reasonable initial attempt to learn discourse-
relation-aware translation rules is a knowledge-
based approach based on an annotated corpus.
This proposal describes my ongoing work on an-
notating and cross-lingually aligning discourse re-
lations in a Chinese-English translation corpus, as
well as my plans to incorporate the resulting lin-
guistic markup into an SMT system. Motivated by
the characteristics of long Chinese sentences with
multiple discourse segments, a further direction of
the research is to translate in units of discourse
segments instead of sentences.
Section 2 gives an overview of existing litera-
ture. Section 3 explains the motivations behind my
research on discourse relations for MT. Section 4
describes my ongoing work of bilingual discourse
annotation, followed by statistics to date . Section
5 present my plans for next steps. Finally, a con-
clusion is drawn in Section 6.
</bodyText>
<sectionHeader confidence="0.999367" genericHeader="introduction">
2 Survey
</sectionHeader>
<subsectionHeader confidence="0.980278">
2.1 English discourse processing
</subsectionHeader>
<bodyText confidence="0.95770125">
There are a number of discourse-annotated En-
glish resources, including the ‘RST Treebank’
(Carlson et al., 2001) and the ‘Discourse Graph-
Bank’ (Wolf and Gibson, 2005), which consist
</bodyText>
<page confidence="0.988478">
18
</page>
<note confidence="0.854447">
Proceedings of the ACL 2014 Student Research Workshop, pages 18–25,
</note>
<affiliation confidence="0.274114">
Baltimore, Maryland USA, June 22-27 2014. c�2014 Association for Computational Linguistics
</affiliation>
<bodyText confidence="0.9999626">
of 385 and 135 articles respectively. Recent dis-
course research often make use of the large-scaled
Penn Discourse Treebank (PDTB) (Prasad et
al., 2008). Departed from annotation using pre-
defined discourse relations, such as ‘Rhetorical
Structure Theory’ (Mann and Thompson, 1988),
PDTB introduces a lexically-ground formalism
to annotate discourse relations by identifying
the discourse connectives (DCs). An example is
shown in the following.
</bodyText>
<subsectionHeader confidence="0.550908">
Example 1: Since McDonald’s menu prices
</subsectionHeader>
<bodyText confidence="0.999497260869565">
rose this year, the actual decline may have been
more. (PDTB 1280)
‘Since’ is an explicit DC taking the italic seg-
ment as the first argument (Arg1), and the bolded
segment as the second argument (Arg2), which is
syntactically attached to the DC. Implicit DCs are
inserted by annotators between adjacent sentences
of the same paragraph to represent inferred dis-
course relations. Each DC is annotated with de-
fined senses classified into 3 levels of granularity.
PDTB allows evaluation of English discourse
parsing tasks and disambiguation tasks (Pitler and
Nenkova, 2009; Lin et al., 2010), which reveal
that implicit discourse relations are much harder to
learn than explicit discourse relations (Pitler et al.,
2009; Zhou et al., 2010). For example, classifica-
tion of the 4 main relation senses (temporal, con-
tingency, comparison, expansion) reaches 94% ac-
curacy for explicit relations (Pitler and Nenkova,
2009), but only range from F-scores of 20% for
‘temporal’ to 76% for ‘expansion’ relations, pos-
sibly due to unbalanced number of training in-
stances (Pitler et al., 2009; Zhou et al., 2010).
</bodyText>
<subsectionHeader confidence="0.998504">
2.2 Chinese discourse processing
</subsectionHeader>
<bodyText confidence="0.999843611111111">
Schemes for Chinese discourse annotation have
been proposed in the existing literature (Xue,
2005; Zhou and Xue, 2012) but the corresponding
resource is not yet available. Zhou et al. (2012)
proposed to project English discourse annotation
and classification algorithms to Chinese data, but
the transfer was based on automatic word align-
ment and machine translation results. Works in
Chinese discourse parsing report F-scores of 64%
in classification of inter-sentence discourse rela-
tions and 71% in 2-way classification of intra-
sentence contingency and comparison relations
(Huang and Chen, 2011; Huang and Chen, 2012),
training on a moderately sized (81 articles) corpus
and considering explicit and implicit relations col-
lectively. Corelation between discourse relation
and sentiment was also explored based on anno-
tated data (Huang et al., 2013).
</bodyText>
<subsectionHeader confidence="0.999403">
2.3 Discourse relations in SMT
</subsectionHeader>
<bodyText confidence="0.999975157894737">
Earlier studies of discourse relations in MT in-
cludes Marcu et al. (2000), which proposed a
discourse transfer model to re-construct the tar-
get discourse tree from the source discourse tree,
parsed by the (RST). However, incorporation to
an SMT system was not discussed in the work.
Recent works focus on the translation of ambigu-
ous DCs, such as ‘since’ in the temporal sense vs.
‘since’ in the reason sense. This is achieved by
annotating the DCs in the training data by ‘trans-
lation spotting’, which is to manually align the
DCs of the source text to their translation in the
target text, either occurring as DCs or other ex-
pressions (Meyer et al., 2011; Popescu-Belis et al.,
2012; Meyer et al., 2012; Meyer and Polakova,
2013; Cartoni et al., 2013). Experiments of these
works have been conducted in English-to-French,
Czech and German translation and only explicit
DCs were considered.
Tu et al. (2013) proposed a framework for
Chinese-to-English translation, in which the
source text is automatically parsed by an RST
parser and translation rules are extracted from
the source discourse trees aligned with the target
strings. An improvement of 1.16 BLEU point is
reported, considering only intra-sentential explicit
relations.
Meyer et al. (2012) found that the translation of
DC improves by up to 10% disregarded of BLEU,
which stays around the baseline system score.
To detect the improvement, they used a metric
known as ACT (Accuracy of Connective Transla-
tion) (Hajlaoui and Popescu-Belis, 2012; Hajlaoui
and Popescu-Belis, 2013), which relies on bilin-
gual word alignment and a dictionary of DCs. In
the setting, missing/additional DC (i.e. potential
implicitation/explicitation of discourse relations)
are to be checked manually for the validity.
</bodyText>
<sectionHeader confidence="0.995179" genericHeader="method">
3 Motivation
</sectionHeader>
<bodyText confidence="0.9999615">
The motivation behind a discourse-relation-aware
translation model for Chinese is two-fold. First
of all, on top of ambiguous discourse connectives
as in other languages, Chinese documents contain
</bodyText>
<page confidence="0.995409">
19
</page>
<bodyText confidence="0.9994228">
abundant implicit connectives (Xue, 2005). In par-
ticular, complex sentences often occur in the form
of ‘running sentences’, in which loose clauses run
in a sequence separated by commas yet without
explicit connectives. Such sentence structures are
used to represent the temporal or reasoning or-
der or related events, or simply to achieve con-
sistent rhythmic patterns. In contrast, syntactical
constraint is prominent in English and this kind
of ‘paratactic’ structures only occur as occasional
rhetorical measures. In other cases, relations be-
tween clauses within a sentence are marked by co-
ordinating or subordinating conjunctions in order
to maintain an intact sentence structure.
Another motivation is that translation in
units of sentences is not always preferable in
Chinese-English translation. In fact, each comma-
separated segment of a ‘running sentence’ can
be considered as an elementary discourse units
(EDU) (Yang and Xue, 2012; Zhou and Xue,
2012) and aligned across the two languages.
In current SMT models, sentence splitting is
the result of the language model or translation
rules containing periods or sentence initial
markers. A long Chinese ‘running sentence’
is typically translated to one English sentence
with ‘comma splices’ (ungrammatical commas
between complete sentences without connecting
by conjunctions). On the other hand, discourse
structure provides clues to split the source sen-
tence. It is because some DCs only relate EDUs
within the same sentences (e.g. ’but’, ‘because’)
while some only relate with the previous sentence
(e.g. ‘however’, ‘in addition’)(Stepanov and
Riccardi, 2013).
Example 2 shows two versions of English trans-
lation of a Chinese sentence as output by Google
Translate. Note that in the original Chinese
sentence, all the DCs are omitted to achieve a
quadruplet pattern. Implicit DCs, represented by
glossed words in brackets, can be inserted to each
comma-separated clause to signal the discourse
relations. Without explicit DCs, the MT output
(MT original) results in a sequence of broken
clauses, whereas with inserted DCs (MT w/DC),
the clauses are joined by the translated DCs to
a complete sentence. In addition, the dropped
pronoun ‘you’ is properly generated, potentially
due to improvement in syntactical parsing of the
source sentence.
</bodyText>
<equation confidence="0.644851">
Example 2
Source: (如果-if)交納稅款有困難的 &apos; (便-
then)可暫緩積欠&apos;(但是-but)新稅不欠&apos;(而且-
furthermore)掛稅免罰 &apos; (並-and) 逐年繳清
</equation>
<bodyText confidence="0.99173425">
MT original: Difficult to pay taxes, may suspend
arrears, the new tex is not owed, penalties linked
tax free, paid annually.
MT w/DC: If you have difficulty to pay taxes, you
can suspend the arrears, but the new tax is not
owed and taxes linked to impunity and paid an-
nually.
Ref: Those having difficulty paying taxes can tem-
porarily postponing old debt but not owing on new
taxes, and suspending taxes and waiving fines,
and paying off year by year.
(adapted from Chinese Tree Bank Art.89)
</bodyText>
<sectionHeader confidence="0.62724" genericHeader="method">
4 Work in progress: Cross-lingual
</sectionHeader>
<subsectionHeader confidence="0.362869">
annotation of discourse relations
</subsectionHeader>
<bodyText confidence="0.999941423076923">
Towards building a statistical machine translation
system that tackles discourse relations specifically,
I started manually annotating a Chinese-English
translation corpus with discourse relations. The
purpose of annotation is not only to create data but
also to understand the problems in Chinese dis-
course processing and translation. The completed
annotation is planned to be released.
Comparing with representation of discourse re-
lations by analytical definitions, the PDTB-styled
association of discourse relations to lexical con-
nectives is more compatible to the procedures
of statistical machine translation. Therefore, the
PDTB convention is adopted for the annotation of
connectives on both sides of the parallel corpus.
Instead of sense annotation, the DCs are aligned
in similar manner as the ‘translation spotting’ ap-
proach (Meyer et al., 2011; Popescu-Belis et al.,
2012; Cartoni et al., 2013). In other words, the
‘senses’ are disambiguated by the translation of
the DCs. The data used is the English Chinese
Translation Treebank (Bies et al., 2007), which
consists of 325 Chinese news stories translated
into 146,300 words of English. Adaptations made
to capture the cross-lingual difference in discourse
relations are explained in the following.
</bodyText>
<subsectionHeader confidence="0.951055">
4.1 EDU segmented by punctuations
</subsectionHeader>
<bodyText confidence="0.997936">
In the PDTB, the span of each EDU (Arg1 or
Arg2), which can range from a single noun to mul-
tiple sentences, are manually annotated. While
</bodyText>
<page confidence="0.973761">
20
</page>
<bodyText confidence="0.9998741875">
each WSJ paragraph1 contains three sentences on
average, the typical ‘running sentences’ in Chi-
nese are exceptionally long. It is hard for an-
notators to agree on an EDU span, and neither
does it have direct effect on the DC translation.
Therefore, I follow previous works (Yang and
Xue, 2012; Zhou and Xue, 2012) and consider a
segment separated by Chinese punctuations, espe-
cially commas, as the span of an EDU.
Nonetheless, there are exceptions since Chinese
commas are used arbitrarily to signify ’pauses’ in
the sentence. Three original tags are defined to an-
notate the exceptions: ‘ATTribution’ , ‘initialized
ADVerbial’, and ‘OPTional comma’ (refer to Ta-
ble 1). These are designed for training of auto-
matic EDU segmentation.
</bodyText>
<subsectionHeader confidence="0.937515">
4.2 Explicit DCs
</subsectionHeader>
<bodyText confidence="0.999956222222222">
After recognizing a valid EDU on the source
text, explicit DC(s) in the EDU are tagged ‘EXP’
and aligned to their translation on the target side,
which are not necessarily explicit DCs. In con-
trast with the defined list of subordinating con-
junctions, coordinating conjunctions and adver-
bials, DCs are not limited to any syntactical cat-
egories in this scheme so as to improve the cover-
age of cross-lingual annotation. For example, ‘at
the same time’ and ‘in spite of the fact that’ are an-
notated as DC instances, since they function as the
DCs ‘simultaneously’ and ‘although’ respectively,
independent of context.
In addition, conjunctions between VP construc-
tions, which are not annotated in the PDTB, are
also annotated as explicit DCs. It is because sub-
jects are often dropped in Chinese and many EDUs
will be ignored if VP constructions are excluded.
</bodyText>
<subsectionHeader confidence="0.991384">
4.3 Discourse markers alternative to DCs
</subsectionHeader>
<bodyText confidence="0.999950666666667">
Discourse relations can be explicitly marked by
non-DC expressions that are context dependent.
Following the PDTB scheme, the ‘ALTLex’ tag
is used to annotate such alternative lexicalization
of discourse relations. However, with a loose defi-
nition of DC, few alternative expressions are iden-
tified. Therefore, the ‘ALT’ tag is defined only
on the English side, which particularly serves to
mark non-DC translation of Chinese DCs. Typi-
cally, English prepositions are tagged ‘ALT’ and
aligned to Chinese DCs that do not correspond
with any English DCs. For example, ‘ 透過’ is
</bodyText>
<footnote confidence="0.969018">
1A paragraph is considered an independent document in
the PDTB. This annotation scheme follows this assumption.
</footnote>
<bodyText confidence="0.996999333333333">
a common DC for the ‘method’ relation, yet there
is not a DC for this relation in English and thus it
is often translated to ‘by’ or ‘through’.
</bodyText>
<subsectionHeader confidence="0.998307">
4.4 Categorization of DCs
</subsectionHeader>
<bodyText confidence="0.999895">
It is observed that subtly different DCs need not
be distinguished for translation, thus they are an-
notated as variations of a same DC. For exam-
ple, explicit occurrences of ‘in addition’, ‘addi-
tionally’, ‘moreover’, ‘furthermore’ and ‘besides’,
all listed as distinct DCs in PDTB, are annotated
as instances of ‘in addition’, and ‘ 但是’, ‘ 可是’,
‘ 然而’, ‘ 不過’as instances of ‘ 但是’ (literally
‘but’). An unambiguous DC is used to represent
the DC type, such as ‘since’ as an instance of ‘be-
cause’ but not the reverse.
Assigning DCs variations to an unambiguous
type can serve as sense annotation without an ab-
stract taxonomy of senses. External DC lexicon
can also be flexibly added by registering new DC
entries to existing categories. On the other hand,
DCs that are not interchangeable in the syntactical
context, such as ‘but’ and ‘however’, are treated as
distinct DC types in order to deduce discriminative
translation rules.
</bodyText>
<subsectionHeader confidence="0.984485">
4.5 Implicit DCs
</subsectionHeader>
<bodyText confidence="0.999974846153846">
In order to produce translation rules for all dis-
course relations, including the unmarked ones, im-
plicit DCs (IMP) are inserted after all explicit DCs
are identified in the Chinese EDU. A correspond-
ing implicit DC is also inserted, if possible, as
translation of a Chinese DC (explicit or implicit)
when explicit translation is not identified. Note
that implicit DCs are always annotated by a DC
type instead of a variation to avoid ambiguity.
The IMP tag is used to annotate parallel DC
structures in Chinese. Most Chinese discourse re-
lations are marked by ‘parallel DCs’, which are
similar to English patterns such as ‘either...or’,
’if...then’, ‘not only...but also’. However, one or
both DCs in the parallel structure can be dropped
in Chinese. The dropped DCs are inserted as IMP
and aligned to the English side.
After the first round of the annotation, another
annotator is to repeat the annotation with the set of
DCs recognized by the first annotator. Since im-
plicit discourse relations lack lexical signals, the
annotator agreement is lower (72% for English
(Miltsakaki et al., 2004)). I plan to include im-
plicit DC annotations of both annotators as multi-
ple readings or coexisting DCs of the implicit re-
lations, thus multiplying the training instances.
</bodyText>
<page confidence="0.998014">
21
</page>
<subsectionHeader confidence="0.816746">
4.6 Redundancy
</subsectionHeader>
<bodyText confidence="0.9996866">
Usually, two EDUs are related by one DC in En-
glish, thus only one of the Chinese parallel DCs
is translated to explicitly. To learn this transla-
tion rule, the untranslated DC is thus aligned to
a‘REDundant’ tag attached to the corresponding
English EDU. To mark Chinese DCs that always
occur independently rather than in parallel struc-
ture, the EDU without a DC is also annotated as
‘RED’. The various types of tags for DC annota-
tion are summarized in Table 1.
</bodyText>
<table confidence="0.9667427">
Tags for aligned ‘DC’
Chinese English
EXP EXP explicit DC identified
IMP IMP implicit DC insertable
- ALT expressions alternative to DC
RED RED ungrammatical to insert DC
Tags for Non-EDU Chinese segments
ATT source of attribution
ADV adverbial initialized
OPT optional comma for a rhythmic pause
</table>
<tableCaption confidence="0.953353">
Table 1: Tags for Chi-Eng DC annotations
</tableCaption>
<subsectionHeader confidence="0.993307">
4.7 Primary analysis of the annotation
</subsectionHeader>
<bodyText confidence="0.994053714285714">
To date, 82 articles (about 33000 English words,
about 1/3 of the complete dataset) have been an-
notated, giving rise to 2050 aligned discourse rela-
tions. In addition, 486 punctuation-separated seg-
ments on the Chinese side have been identified as
non-EDU segments. 59 DC types for Chinese and
47 for English have been identified.
</bodyText>
<table confidence="0.993292888888889">
Chi -/- Eng EXP. ALT. IMP. RED. Total
EXP. 291 68 23 49 431
IMP. 396 144 770 261 1561
RED. 6 0 0 52 58
Total 693 212 783 362 2050
attribute - - - - 211
optional - - - - 89
adverbial - - - - 186
Total - - - - 486
</table>
<tableCaption confidence="0.893419">
Table 2: Distribution of alignment between differ-
ent ‘DC’ types
</tableCaption>
<bodyText confidence="0.99697309375">
The distribution of alignments between these
types is shown in Table 2. Although the statis-
tics are not directly comparable to other existing
data due to difference in definitions, it agrees with
previous findings that implicit DCs are abundant
in Chinese (Zhou and Xue, 2012). According to
the present data, about 1/4 of the implicit DCs are
translated to explicit DCs in English. However,
more than half are not explicitly translated (im-
plicit or redundant). This suggests that implicit
DC recovery can be focused on the those that are
likely to be translated explicitly.
It is also observable that explicit Chinese DCs
are mostly translated to an explicit DC in English,
while about 1/6 of them are translated to non-
DC expressions. As mentioned, these are mostly
prepositions corresponding to discourse relations
that are not defined by any DCs in English. This
suggests that bilingual discourse annotation can
recover a larger variation of universal discourse
relations than monolingual annotation. Further ex-
ploratory analysis will be conducted to investigate
the tendency in discourse relation markedness and
alignment, so as to define informative linguistic
features for model training.
Currently, I am using the MAE annotation
tool(Stubbs, 2011). The annotation effort can be
lightened by developing an interface that assists
the multilingual annotation task by, for example,
automatic EDU segmentation (to be reviewed by
annotators) and automatic identification and pre-
alignment of DCs based on a DC dictionary.
</bodyText>
<sectionHeader confidence="0.974952" genericHeader="method">
5 Future plans
</sectionHeader>
<bodyText confidence="0.9999216">
The key of this research is to integrate the an-
notated discourse knowledge into an SMT sys-
tem. Integration of document level parse to MT,
as described in Marcu et al. (2000) for Japanese-
to-English translation, is complicated. In addi-
tion, comparing with Japanese, the word order in
Chinese and English are not drastically different.
Therefore, I plan to make use of information from
DC-based shallow discourse parse. My main tasks
towards this system include:
</bodyText>
<listItem confidence="0.9994136">
1. Cross-lingual DC annotation
2. EDU segmentation
3. Prediction of source implicit DCs
4. Integration to SMT system
5. DC-aware MT evaluation
</listItem>
<bodyText confidence="0.994766">
A flowchart of these tasks is shown in Figure 1 and
explained in the following.
</bodyText>
<subsectionHeader confidence="0.96756">
5.1 EDU segmentation
</subsectionHeader>
<bodyText confidence="0.9961745">
Discourse parsing can be divided to the tasks
of DC identification and argument identification,
</bodyText>
<page confidence="0.998581">
22
</page>
<figureCaption confidence="0.999725">
Figure 1: Main tasks for proposed DC-aware SMT system.
</figureCaption>
<bodyText confidence="0.999928833333333">
where the latter can be further divided into argu-
ment position and argument span identification. In
Chinese, a punctuation-separated segment is ba-
sically considered an EDU, so the span is fixed.
The exceptional cases of commas not segmenting
an EDU are annotated in the dataset and can be
predicted in a binary classification task using lex-
ical and syntactical features, as in Yang and Xue
(2012). On the other hand, a text segment can
contain more than one EDU when there are mul-
tiple DCs, thus further segmentation is necessary
depending on DC identification.
</bodyText>
<subsectionHeader confidence="0.999886">
5.2 Prediction of source implicit DCs
</subsectionHeader>
<bodyText confidence="0.9999743125">
One focus of this research is to explicitize implicit
Chinese DCs when translating to English. I plan to
construct a model to predict implicit discourse re-
lations in the Chinese source text. Previous works
on Chinese discourse relation recognitions (Yue,
2006; Huang and Chen, 2011) provide insights on
the prediction task and the DC annotated corpus
provides data for supervised training. Although
state-of-the-art implicit discourse parsing is still
of low accuracy, the preciseness can be adjusted
to suit the goal of machine translation. As in other
joint tasks with MT, such as Bouamor et al. (2013),
features of whether the implicit DC can be trans-
lated explicitly, or correctly, can in incorporated
to the prediction task, so as to predict translatable
implicit DCs in particular.
</bodyText>
<subsectionHeader confidence="0.996469">
5.3 Integration to SMT system
</subsectionHeader>
<bodyText confidence="0.999874">
One way to exploit discourse knowledge into an
SMT system is to incorporate the predicted dis-
course features, such as implicit DC, DC sequence
or DC type, into a factored translation model
(Koehn and Hoang, 2007). Another approach is to
decorate identified and predicted DCs in a syntac-
tical parsed tree, so as to enrich the tree-to-string
rules with DC markedness features. Moreover,
when a source DC is translated to a sentence initial
DC, a source sentence is potentially split to mul-
tiple target sentences. A document level decoder
(Hardmeier et al., 2012) that searches beyond the
sentence boundary is thus preferred.
</bodyText>
<subsectionHeader confidence="0.984346">
5.4 DC-aware MT evaluation
</subsectionHeader>
<bodyText confidence="0.9999676">
Comparable evaluation is essential for MT re-
search, yet conventional MT metrics, such as
BLEU, is not effective in detecting improvement
in discourse relation translation (Meyer et al.,
2012). One direction is to extend the ACT metrics
(Hajlaoui and Popescu-Belis, 2013) to access also
translation of implicit DCs. Another direction is to
define a measure that is not reference-dependent,
since implicit relations can be translated in various
ways. Moreover, conventional MT metrics, which
compare a candidate with the reference sentence-
by-sentence, have to be modified when used to ac-
cess the overall MT performance of the proposed
system, since the output sentences may not align
with the reference sentences one-by-one.
</bodyText>
<sectionHeader confidence="0.999383" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999456">
In this thesis proposal, ongoing work and future
plans have been presented towards a discourse-
relation-aware SMT system. The research can
serve as basis for the goal of a document-level MT
system that considers various discourse structures.
</bodyText>
<sectionHeader confidence="0.972888" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9807235">
I would like to thank Baidu for travel and confer-
ence support for this paper.
</bodyText>
<page confidence="0.997495">
23
</page>
<sectionHeader confidence="0.996304" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.979584398148148">
Ann Bies, Martha Palmer, Justin Mott, and Colin
Warner. 2007. English chinese translation treebank
v 1.0. Linguistic Data Consortium LDC2007T02,
January.
Houda Bouamor, Behrang Mohit, and Kemal Oflazer.
2013. Sumt: A framework of summarization and
mt. Proceedings of the International Conference on
Natural Language Processing.
Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski. 2001. Building a discourse-tagged cor-
pus in the framework of rhetorical structure theory.
Proceedings of the SIGdial Workshop on Discourse
and Dialogue.
Bruno Cartoni, Sandrine Zufferey, and Thomas Meyer.
2013. Annotating the meaning of discourse connec-
tives by looking at their translation: The translation-
spotting technique. Dialogue and Discourse, 4(2).
Najeh Hajlaoui and Andrei Popescu-Belis. 2012.
Translating english discourse connectives into ara-
bic: a corpus-based analysis and an evaluation met-
ric. Proceedings of the Workshop on Computational
Approaches to Arabic Script-based Languages.
Najeh Hajlaoui and Andrei Popescu-Belis. 2013. As-
sessing the accuracy of discourse connective trans-
lations: Validation of an automatic metric. Compu-
tational LInguistics and Intelligent Text Processing,
7617.
Christian Hardmeier, Joakim Nivre, and J¨org Tiede-
mann. 2012. Document-wide decoding for phrase-
based statistical machine translation. Proceedings of
the Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Nat-
ural Language Learning.
Hen-Hsen Huang and Hsin-Hsi Chen. 2011. Chinese
discourse relation recognition. Proceedings of the
International Conference on Natural Language Pro-
cessing.
Hen-Hsen Huang and Hsin-Hsi Chen. 2012. Contin-
gency and comparison relation labelling and struc-
ture prediction in chinese sentences. Proceedings of
the Annual Meeting of the Special Interest Group on
Discourse and Dialogue.
Hen-Hsen Huang, Chi-Hsin Yu, Tai-Wei Chang, Cong-
Kai lin, and Hsin-Hsi Chen. 2013. Analyses of
the association between discourse relation and sen-
timent polarity with a chinese human-annotated cor-
pus. Proceedings of the Linguistic Annotation Work-
shop and Interperability with Discourse.
Philipp Koehn and Hieu Hoang. 2007. Factored trans-
lation models. Proceedings of the Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning.
Ziheng Lin, Hwee Tou Ng, and Min Yen Kan. 2010. A
pdtb-styled end-to-end discourse parser. Technical
report, National University of Singapore.
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text.
Daniel Marcu, Lynn Carlson, and Maki Watanabe.
2000. The automatic translation of discourse struc-
tures. Proceedings of the North American Chapter
of the Association for Computational Linguistics.
Thomas Meyer and Lucie Polakova. 2013. Machine
translation with many manually labeled discourse
connectives. Proceedings of the Discourse in Ma-
chine Translation Workshop.
Thomas Meyer, Andrei Popescu-Belis, Sandrine Zuf-
ferey, and Bruno Cartoni. 2011. Multilingual anno-
tation and disambiguation of discourse connectives
for machine translation. Proceedings of the Annual
Meeting of the Special Interest Group on Discourse
and Dialogue.
Thomas Meyer, Andrei Popescu-Belis, and Najeh Ha-
jlaoui. 2012. Machine translation of labeled dis-
course connectives. Proceedings of the Biennial
Conference of the Association for Machine Trans-
lation in the Americas.
Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and
Bonnie Webber. 2004. Annotating discourse con-
nectives and their arguments. Proceedings of the
Workshop on Frontiers in Corpus Annotations.
Emily Pitler and Ani Nenkova. 2009. Using syntax to
disambiguate explicit discourse connectives in text.
Proceedings of the Annual Meeting of the Associa-
tion for Computational Linguistics and the Interna-
tional Joint Conference on Natural Language Pro-
cessing.
Emily Pitler, Annie Louis, and Ani Nenkova. 2009.
Automatic sense prediction for implicit discourse re-
lations in text. Proceedings of the Annual Meeting of
the Association for Computational Linguistics and
the International Joint Conference on Natural Lan-
guage Processing.
Andrei Popescu-Belis, Thomas Meyer, Jeevanthi
Liyanapathirana, Bruno Cartoni, and Sandrine Zuf-
ferey. 2012. Discourse-level annotation over eu-
roparl for machine translation: Connectives and pro-
nouns. Proceedings of the Language Resource and
Evaluation Conference.
Rashmi Prasad, Nikhit Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The penn discourse treebank 2.0.
Proceedings of the Language Resource and Evalua-
tion Conference.
Ted Sanders and Leo Noordman. 2000. The role of
coherence relations and their linguistic markers in
text processing. Discourse Processes, 1.
</reference>
<page confidence="0.974956">
24
</page>
<reference confidence="0.999122731707317">
Evgeny A. Stepanov and Giuseppe Riccardi. 2013.
Comparative evaluation of argument extraction al-
gorithms in discourse relation parsing. Proceedings
of the International Conference on Parsing Tech-
nologies.
Amber Stubbs. 2011. Mae and mai: lightweight an-
notation and adjudication tools. Proceedings of the
Linguistic Annotation Workshop.
Mei Tu, Yu Zhou, and Chengqing Zong. 2013. A novel
translation framework based on rhetorical structure
theory. Proceedings of the Annual Meeting of the
Association for Computational Linguistics.
Florian Wolf and Edward Gibson. 2005. Representing
discourse coherence: a corpus-based analysis. Com-
putational Linguistics.
Nianwen Xue. 2005. Annotating discourse connec-
tives in the chinese treebank. Proceedings of the
Workshop on Frontiers in Corpus Annotations.
Yaqin Yang and Nianwen Xue. 2012. Chinese comma
disambiguation for discourse analysis. Proceedings
of the Annual Meeting of the Association for Com-
putational Linguistics.
Ming Yue. 2006. Discursive usage of six chinese punc-
tuation marks. Proceedings of the Annual Meet-
ing of the Association for Computational Linguis-
tics and International Conference on Computational
Linguistics.
Yuping Zhou and Nianwen Xue. 2012. Pdtb-style dis-
course annotation of chinese text. Proceedings of
the Annual Meeting of the Association for Computa-
tional Linguistics.
Zhi-Min Zhou, Yu Xu, Zheng-Yu Niu, Man Lan, Jian
Su, and Chew Lim Tan. 2010. Predicting discourse
connectives for implicit discourse relation recogni-
tion. Proceedings of the International Conference
on Computational Linguistics.
Lan Jun Zhou, Wei Gao, Binyang Li, Zhongyu Wei,
and Kam-Fat Wong. 2012. Cross-lingual iden-
tification of ambiguous discourse connectives for
resource-poor language. Proceedings of the Inter-
national Conference on Computational Linguistics.
</reference>
<page confidence="0.998726">
25
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.468396">
<title confidence="0.998499">Towards a Discourse Relation-aware for Chinese-English Machine Translation</title>
<author confidence="0.493519">Frances</author>
<affiliation confidence="0.996255">Nara Institute of Science and</affiliation>
<address confidence="0.983902">8916-5 Takayama, Ikoma, Nara, 630-0192</address>
<email confidence="0.976958">pikyufrances-y@is.naist.jp</email>
<abstract confidence="0.999324761904762">Translation of discourse relations is one of the recent efforts of incorporating discourse information to statistical machine translation (SMT). While existing works focus on disambiguation of ambiguous discourse connectives, or transformation of discourse trees, only explicit discourse relations are tackled. A greater challenge exists in machine translation of Chinese, since implicit discourse relations are abundant and occur both inside and outside a sentence. This thesis proposal describes ongoing work on bilingual discourse annotation and plans towards incorporating discourse relation knowledge to a Chinese- English SMT system with consideration of implicit discourse relations. The final goal is a discourse-unit-based translation model unbounded by the traditional assumption of sentence-to-sentence translation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Martha Palmer</author>
<author>Justin Mott</author>
<author>Colin Warner</author>
</authors>
<title>English chinese translation treebank v 1.0. Linguistic Data Consortium</title>
<date>2007</date>
<booktitle>LDC2007T02,</booktitle>
<contexts>
<context position="12345" citStr="Bies et al., 2007" startWordPosition="1866" endWordPosition="1869">analytical definitions, the PDTB-styled association of discourse relations to lexical connectives is more compatible to the procedures of statistical machine translation. Therefore, the PDTB convention is adopted for the annotation of connectives on both sides of the parallel corpus. Instead of sense annotation, the DCs are aligned in similar manner as the ‘translation spotting’ approach (Meyer et al., 2011; Popescu-Belis et al., 2012; Cartoni et al., 2013). In other words, the ‘senses’ are disambiguated by the translation of the DCs. The data used is the English Chinese Translation Treebank (Bies et al., 2007), which consists of 325 Chinese news stories translated into 146,300 words of English. Adaptations made to capture the cross-lingual difference in discourse relations are explained in the following. 4.1 EDU segmented by punctuations In the PDTB, the span of each EDU (Arg1 or Arg2), which can range from a single noun to multiple sentences, are manually annotated. While 20 each WSJ paragraph1 contains three sentences on average, the typical ‘running sentences’ in Chinese are exceptionally long. It is hard for annotators to agree on an EDU span, and neither does it have direct effect on the DC tr</context>
</contexts>
<marker>Bies, Palmer, Mott, Warner, 2007</marker>
<rawString>Ann Bies, Martha Palmer, Justin Mott, and Colin Warner. 2007. English chinese translation treebank v 1.0. Linguistic Data Consortium LDC2007T02, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Houda Bouamor</author>
<author>Behrang Mohit</author>
<author>Kemal Oflazer</author>
</authors>
<title>Sumt: A framework of summarization and mt.</title>
<date>2013</date>
<booktitle>Proceedings of the International Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="22484" citStr="Bouamor et al. (2013)" startWordPosition="3540" endWordPosition="3543">rce implicit DCs One focus of this research is to explicitize implicit Chinese DCs when translating to English. I plan to construct a model to predict implicit discourse relations in the Chinese source text. Previous works on Chinese discourse relation recognitions (Yue, 2006; Huang and Chen, 2011) provide insights on the prediction task and the DC annotated corpus provides data for supervised training. Although state-of-the-art implicit discourse parsing is still of low accuracy, the preciseness can be adjusted to suit the goal of machine translation. As in other joint tasks with MT, such as Bouamor et al. (2013), features of whether the implicit DC can be translated explicitly, or correctly, can in incorporated to the prediction task, so as to predict translatable implicit DCs in particular. 5.3 Integration to SMT system One way to exploit discourse knowledge into an SMT system is to incorporate the predicted discourse features, such as implicit DC, DC sequence or DC type, into a factored translation model (Koehn and Hoang, 2007). Another approach is to decorate identified and predicted DCs in a syntactical parsed tree, so as to enrich the tree-to-string rules with DC markedness features. Moreover, w</context>
</contexts>
<marker>Bouamor, Mohit, Oflazer, 2013</marker>
<rawString>Houda Bouamor, Behrang Mohit, and Kemal Oflazer. 2013. Sumt: A framework of summarization and mt. Proceedings of the International Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Carlson</author>
<author>Daniel Marcu</author>
<author>Mary Ellen Okurowski</author>
</authors>
<title>Building a discourse-tagged corpus in the framework of rhetorical structure theory.</title>
<date>2001</date>
<booktitle>Proceedings of the SIGdial Workshop on Discourse and Dialogue.</booktitle>
<contexts>
<context position="3622" citStr="Carlson et al., 2001" startWordPosition="529" endWordPosition="532">ith multiple discourse segments, a further direction of the research is to translate in units of discourse segments instead of sentences. Section 2 gives an overview of existing literature. Section 3 explains the motivations behind my research on discourse relations for MT. Section 4 describes my ongoing work of bilingual discourse annotation, followed by statistics to date . Section 5 present my plans for next steps. Finally, a conclusion is drawn in Section 6. 2 Survey 2.1 English discourse processing There are a number of discourse-annotated English resources, including the ‘RST Treebank’ (Carlson et al., 2001) and the ‘Discourse GraphBank’ (Wolf and Gibson, 2005), which consist 18 Proceedings of the ACL 2014 Student Research Workshop, pages 18–25, Baltimore, Maryland USA, June 22-27 2014. c�2014 Association for Computational Linguistics of 385 and 135 articles respectively. Recent discourse research often make use of the large-scaled Penn Discourse Treebank (PDTB) (Prasad et al., 2008). Departed from annotation using predefined discourse relations, such as ‘Rhetorical Structure Theory’ (Mann and Thompson, 1988), PDTB introduces a lexically-ground formalism to annotate discourse relations by identif</context>
</contexts>
<marker>Carlson, Marcu, Okurowski, 2001</marker>
<rawString>Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski. 2001. Building a discourse-tagged corpus in the framework of rhetorical structure theory. Proceedings of the SIGdial Workshop on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Cartoni</author>
<author>Sandrine Zufferey</author>
<author>Thomas Meyer</author>
</authors>
<title>Annotating the meaning of discourse connectives by looking at their translation: The translationspotting technique. Dialogue and Discourse,</title>
<date>2013</date>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="7103" citStr="Cartoni et al., 2013" startWordPosition="1073" endWordPosition="1076"> the target discourse tree from the source discourse tree, parsed by the (RST). However, incorporation to an SMT system was not discussed in the work. Recent works focus on the translation of ambiguous DCs, such as ‘since’ in the temporal sense vs. ‘since’ in the reason sense. This is achieved by annotating the DCs in the training data by ‘translation spotting’, which is to manually align the DCs of the source text to their translation in the target text, either occurring as DCs or other expressions (Meyer et al., 2011; Popescu-Belis et al., 2012; Meyer et al., 2012; Meyer and Polakova, 2013; Cartoni et al., 2013). Experiments of these works have been conducted in English-to-French, Czech and German translation and only explicit DCs were considered. Tu et al. (2013) proposed a framework for Chinese-to-English translation, in which the source text is automatically parsed by an RST parser and translation rules are extracted from the source discourse trees aligned with the target strings. An improvement of 1.16 BLEU point is reported, considering only intra-sentential explicit relations. Meyer et al. (2012) found that the translation of DC improves by up to 10% disregarded of BLEU, which stays around the </context>
<context position="12188" citStr="Cartoni et al., 2013" startWordPosition="1840" endWordPosition="1843">ms in Chinese discourse processing and translation. The completed annotation is planned to be released. Comparing with representation of discourse relations by analytical definitions, the PDTB-styled association of discourse relations to lexical connectives is more compatible to the procedures of statistical machine translation. Therefore, the PDTB convention is adopted for the annotation of connectives on both sides of the parallel corpus. Instead of sense annotation, the DCs are aligned in similar manner as the ‘translation spotting’ approach (Meyer et al., 2011; Popescu-Belis et al., 2012; Cartoni et al., 2013). In other words, the ‘senses’ are disambiguated by the translation of the DCs. The data used is the English Chinese Translation Treebank (Bies et al., 2007), which consists of 325 Chinese news stories translated into 146,300 words of English. Adaptations made to capture the cross-lingual difference in discourse relations are explained in the following. 4.1 EDU segmented by punctuations In the PDTB, the span of each EDU (Arg1 or Arg2), which can range from a single noun to multiple sentences, are manually annotated. While 20 each WSJ paragraph1 contains three sentences on average, the typical </context>
</contexts>
<marker>Cartoni, Zufferey, Meyer, 2013</marker>
<rawString>Bruno Cartoni, Sandrine Zufferey, and Thomas Meyer. 2013. Annotating the meaning of discourse connectives by looking at their translation: The translationspotting technique. Dialogue and Discourse, 4(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Najeh Hajlaoui</author>
<author>Andrei Popescu-Belis</author>
</authors>
<title>Translating english discourse connectives into arabic: a corpus-based analysis and an evaluation metric.</title>
<date>2012</date>
<booktitle>Proceedings of the Workshop on Computational Approaches to Arabic Script-based Languages.</booktitle>
<contexts>
<context position="7855" citStr="Hajlaoui and Popescu-Belis, 2012" startWordPosition="1187" endWordPosition="1190">s were considered. Tu et al. (2013) proposed a framework for Chinese-to-English translation, in which the source text is automatically parsed by an RST parser and translation rules are extracted from the source discourse trees aligned with the target strings. An improvement of 1.16 BLEU point is reported, considering only intra-sentential explicit relations. Meyer et al. (2012) found that the translation of DC improves by up to 10% disregarded of BLEU, which stays around the baseline system score. To detect the improvement, they used a metric known as ACT (Accuracy of Connective Translation) (Hajlaoui and Popescu-Belis, 2012; Hajlaoui and Popescu-Belis, 2013), which relies on bilingual word alignment and a dictionary of DCs. In the setting, missing/additional DC (i.e. potential implicitation/explicitation of discourse relations) are to be checked manually for the validity. 3 Motivation The motivation behind a discourse-relation-aware translation model for Chinese is two-fold. First of all, on top of ambiguous discourse connectives as in other languages, Chinese documents contain 19 abundant implicit connectives (Xue, 2005). In particular, complex sentences often occur in the form of ‘running sentences’, in which </context>
</contexts>
<marker>Hajlaoui, Popescu-Belis, 2012</marker>
<rawString>Najeh Hajlaoui and Andrei Popescu-Belis. 2012. Translating english discourse connectives into arabic: a corpus-based analysis and an evaluation metric. Proceedings of the Workshop on Computational Approaches to Arabic Script-based Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Najeh Hajlaoui</author>
<author>Andrei Popescu-Belis</author>
</authors>
<title>Assessing the accuracy of discourse connective translations: Validation of an automatic metric.</title>
<date>2013</date>
<booktitle>Computational LInguistics and Intelligent Text Processing,</booktitle>
<pages>7617</pages>
<contexts>
<context position="7890" citStr="Hajlaoui and Popescu-Belis, 2013" startWordPosition="1191" endWordPosition="1194">) proposed a framework for Chinese-to-English translation, in which the source text is automatically parsed by an RST parser and translation rules are extracted from the source discourse trees aligned with the target strings. An improvement of 1.16 BLEU point is reported, considering only intra-sentential explicit relations. Meyer et al. (2012) found that the translation of DC improves by up to 10% disregarded of BLEU, which stays around the baseline system score. To detect the improvement, they used a metric known as ACT (Accuracy of Connective Translation) (Hajlaoui and Popescu-Belis, 2012; Hajlaoui and Popescu-Belis, 2013), which relies on bilingual word alignment and a dictionary of DCs. In the setting, missing/additional DC (i.e. potential implicitation/explicitation of discourse relations) are to be checked manually for the validity. 3 Motivation The motivation behind a discourse-relation-aware translation model for Chinese is two-fold. First of all, on top of ambiguous discourse connectives as in other languages, Chinese documents contain 19 abundant implicit connectives (Xue, 2005). In particular, complex sentences often occur in the form of ‘running sentences’, in which loose clauses run in a sequence sep</context>
<context position="23618" citStr="Hajlaoui and Popescu-Belis, 2013" startWordPosition="3721" endWordPosition="3724">ical parsed tree, so as to enrich the tree-to-string rules with DC markedness features. Moreover, when a source DC is translated to a sentence initial DC, a source sentence is potentially split to multiple target sentences. A document level decoder (Hardmeier et al., 2012) that searches beyond the sentence boundary is thus preferred. 5.4 DC-aware MT evaluation Comparable evaluation is essential for MT research, yet conventional MT metrics, such as BLEU, is not effective in detecting improvement in discourse relation translation (Meyer et al., 2012). One direction is to extend the ACT metrics (Hajlaoui and Popescu-Belis, 2013) to access also translation of implicit DCs. Another direction is to define a measure that is not reference-dependent, since implicit relations can be translated in various ways. Moreover, conventional MT metrics, which compare a candidate with the reference sentenceby-sentence, have to be modified when used to access the overall MT performance of the proposed system, since the output sentences may not align with the reference sentences one-by-one. 6 Conclusion In this thesis proposal, ongoing work and future plans have been presented towards a discourserelation-aware SMT system. The research </context>
</contexts>
<marker>Hajlaoui, Popescu-Belis, 2013</marker>
<rawString>Najeh Hajlaoui and Andrei Popescu-Belis. 2013. Assessing the accuracy of discourse connective translations: Validation of an automatic metric. Computational LInguistics and Intelligent Text Processing, 7617.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Hardmeier</author>
<author>Joakim Nivre</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Document-wide decoding for phrasebased statistical machine translation.</title>
<date>2012</date>
<booktitle>Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="23258" citStr="Hardmeier et al., 2012" startWordPosition="3667" endWordPosition="3670">able implicit DCs in particular. 5.3 Integration to SMT system One way to exploit discourse knowledge into an SMT system is to incorporate the predicted discourse features, such as implicit DC, DC sequence or DC type, into a factored translation model (Koehn and Hoang, 2007). Another approach is to decorate identified and predicted DCs in a syntactical parsed tree, so as to enrich the tree-to-string rules with DC markedness features. Moreover, when a source DC is translated to a sentence initial DC, a source sentence is potentially split to multiple target sentences. A document level decoder (Hardmeier et al., 2012) that searches beyond the sentence boundary is thus preferred. 5.4 DC-aware MT evaluation Comparable evaluation is essential for MT research, yet conventional MT metrics, such as BLEU, is not effective in detecting improvement in discourse relation translation (Meyer et al., 2012). One direction is to extend the ACT metrics (Hajlaoui and Popescu-Belis, 2013) to access also translation of implicit DCs. Another direction is to define a measure that is not reference-dependent, since implicit relations can be translated in various ways. Moreover, conventional MT metrics, which compare a candidate </context>
</contexts>
<marker>Hardmeier, Nivre, Tiedemann, 2012</marker>
<rawString>Christian Hardmeier, Joakim Nivre, and J¨org Tiedemann. 2012. Document-wide decoding for phrasebased statistical machine translation. Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hen-Hsen Huang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Chinese discourse relation recognition.</title>
<date>2011</date>
<booktitle>Proceedings of the International Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="6064" citStr="Huang and Chen, 2011" startWordPosition="899" endWordPosition="902">se discourse processing Schemes for Chinese discourse annotation have been proposed in the existing literature (Xue, 2005; Zhou and Xue, 2012) but the corresponding resource is not yet available. Zhou et al. (2012) proposed to project English discourse annotation and classification algorithms to Chinese data, but the transfer was based on automatic word alignment and machine translation results. Works in Chinese discourse parsing report F-scores of 64% in classification of inter-sentence discourse relations and 71% in 2-way classification of intrasentence contingency and comparison relations (Huang and Chen, 2011; Huang and Chen, 2012), training on a moderately sized (81 articles) corpus and considering explicit and implicit relations collectively. Corelation between discourse relation and sentiment was also explored based on annotated data (Huang et al., 2013). 2.3 Discourse relations in SMT Earlier studies of discourse relations in MT includes Marcu et al. (2000), which proposed a discourse transfer model to re-construct the target discourse tree from the source discourse tree, parsed by the (RST). However, incorporation to an SMT system was not discussed in the work. Recent works focus on the trans</context>
<context position="22162" citStr="Huang and Chen, 2011" startWordPosition="3489" endWordPosition="3492">d in the dataset and can be predicted in a binary classification task using lexical and syntactical features, as in Yang and Xue (2012). On the other hand, a text segment can contain more than one EDU when there are multiple DCs, thus further segmentation is necessary depending on DC identification. 5.2 Prediction of source implicit DCs One focus of this research is to explicitize implicit Chinese DCs when translating to English. I plan to construct a model to predict implicit discourse relations in the Chinese source text. Previous works on Chinese discourse relation recognitions (Yue, 2006; Huang and Chen, 2011) provide insights on the prediction task and the DC annotated corpus provides data for supervised training. Although state-of-the-art implicit discourse parsing is still of low accuracy, the preciseness can be adjusted to suit the goal of machine translation. As in other joint tasks with MT, such as Bouamor et al. (2013), features of whether the implicit DC can be translated explicitly, or correctly, can in incorporated to the prediction task, so as to predict translatable implicit DCs in particular. 5.3 Integration to SMT system One way to exploit discourse knowledge into an SMT system is to </context>
</contexts>
<marker>Huang, Chen, 2011</marker>
<rawString>Hen-Hsen Huang and Hsin-Hsi Chen. 2011. Chinese discourse relation recognition. Proceedings of the International Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hen-Hsen Huang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Contingency and comparison relation labelling and structure prediction in chinese sentences.</title>
<date>2012</date>
<booktitle>Proceedings of the Annual Meeting of the Special Interest Group on Discourse and Dialogue.</booktitle>
<contexts>
<context position="6087" citStr="Huang and Chen, 2012" startWordPosition="903" endWordPosition="906">g Schemes for Chinese discourse annotation have been proposed in the existing literature (Xue, 2005; Zhou and Xue, 2012) but the corresponding resource is not yet available. Zhou et al. (2012) proposed to project English discourse annotation and classification algorithms to Chinese data, but the transfer was based on automatic word alignment and machine translation results. Works in Chinese discourse parsing report F-scores of 64% in classification of inter-sentence discourse relations and 71% in 2-way classification of intrasentence contingency and comparison relations (Huang and Chen, 2011; Huang and Chen, 2012), training on a moderately sized (81 articles) corpus and considering explicit and implicit relations collectively. Corelation between discourse relation and sentiment was also explored based on annotated data (Huang et al., 2013). 2.3 Discourse relations in SMT Earlier studies of discourse relations in MT includes Marcu et al. (2000), which proposed a discourse transfer model to re-construct the target discourse tree from the source discourse tree, parsed by the (RST). However, incorporation to an SMT system was not discussed in the work. Recent works focus on the translation of ambiguous DCs</context>
</contexts>
<marker>Huang, Chen, 2012</marker>
<rawString>Hen-Hsen Huang and Hsin-Hsi Chen. 2012. Contingency and comparison relation labelling and structure prediction in chinese sentences. Proceedings of the Annual Meeting of the Special Interest Group on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hen-Hsen Huang</author>
<author>Chi-Hsin Yu</author>
<author>Tai-Wei Chang</author>
<author>CongKai lin</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Analyses of the association between discourse relation and sentiment polarity with a chinese human-annotated corpus.</title>
<date>2013</date>
<booktitle>Proceedings of the Linguistic Annotation Workshop and Interperability with Discourse.</booktitle>
<contexts>
<context position="6317" citStr="Huang et al., 2013" startWordPosition="937" endWordPosition="940">nnotation and classification algorithms to Chinese data, but the transfer was based on automatic word alignment and machine translation results. Works in Chinese discourse parsing report F-scores of 64% in classification of inter-sentence discourse relations and 71% in 2-way classification of intrasentence contingency and comparison relations (Huang and Chen, 2011; Huang and Chen, 2012), training on a moderately sized (81 articles) corpus and considering explicit and implicit relations collectively. Corelation between discourse relation and sentiment was also explored based on annotated data (Huang et al., 2013). 2.3 Discourse relations in SMT Earlier studies of discourse relations in MT includes Marcu et al. (2000), which proposed a discourse transfer model to re-construct the target discourse tree from the source discourse tree, parsed by the (RST). However, incorporation to an SMT system was not discussed in the work. Recent works focus on the translation of ambiguous DCs, such as ‘since’ in the temporal sense vs. ‘since’ in the reason sense. This is achieved by annotating the DCs in the training data by ‘translation spotting’, which is to manually align the DCs of the source text to their transla</context>
</contexts>
<marker>Huang, Yu, Chang, lin, Chen, 2013</marker>
<rawString>Hen-Hsen Huang, Chi-Hsin Yu, Tai-Wei Chang, CongKai lin, and Hsin-Hsi Chen. 2013. Analyses of the association between discourse relation and sentiment polarity with a chinese human-annotated corpus. Proceedings of the Linguistic Annotation Workshop and Interperability with Discourse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="22910" citStr="Koehn and Hoang, 2007" startWordPosition="3610" endWordPosition="3613">the-art implicit discourse parsing is still of low accuracy, the preciseness can be adjusted to suit the goal of machine translation. As in other joint tasks with MT, such as Bouamor et al. (2013), features of whether the implicit DC can be translated explicitly, or correctly, can in incorporated to the prediction task, so as to predict translatable implicit DCs in particular. 5.3 Integration to SMT system One way to exploit discourse knowledge into an SMT system is to incorporate the predicted discourse features, such as implicit DC, DC sequence or DC type, into a factored translation model (Koehn and Hoang, 2007). Another approach is to decorate identified and predicted DCs in a syntactical parsed tree, so as to enrich the tree-to-string rules with DC markedness features. Moreover, when a source DC is translated to a sentence initial DC, a source sentence is potentially split to multiple target sentences. A document level decoder (Hardmeier et al., 2012) that searches beyond the sentence boundary is thus preferred. 5.4 DC-aware MT evaluation Comparable evaluation is essential for MT research, yet conventional MT metrics, such as BLEU, is not effective in detecting improvement in discourse relation tra</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Philipp Koehn and Hieu Hoang. 2007. Factored translation models. Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ziheng Lin</author>
<author>Hwee Tou Ng</author>
<author>Min Yen Kan</author>
</authors>
<title>A pdtb-styled end-to-end discourse parser.</title>
<date>2010</date>
<tech>Technical report,</tech>
<institution>National University of Singapore.</institution>
<contexts>
<context position="4925" citStr="Lin et al., 2010" startWordPosition="726" endWordPosition="729"> Since McDonald’s menu prices rose this year, the actual decline may have been more. (PDTB 1280) ‘Since’ is an explicit DC taking the italic segment as the first argument (Arg1), and the bolded segment as the second argument (Arg2), which is syntactically attached to the DC. Implicit DCs are inserted by annotators between adjacent sentences of the same paragraph to represent inferred discourse relations. Each DC is annotated with defined senses classified into 3 levels of granularity. PDTB allows evaluation of English discourse parsing tasks and disambiguation tasks (Pitler and Nenkova, 2009; Lin et al., 2010), which reveal that implicit discourse relations are much harder to learn than explicit discourse relations (Pitler et al., 2009; Zhou et al., 2010). For example, classification of the 4 main relation senses (temporal, contingency, comparison, expansion) reaches 94% accuracy for explicit relations (Pitler and Nenkova, 2009), but only range from F-scores of 20% for ‘temporal’ to 76% for ‘expansion’ relations, possibly due to unbalanced number of training instances (Pitler et al., 2009; Zhou et al., 2010). 2.2 Chinese discourse processing Schemes for Chinese discourse annotation have been propos</context>
</contexts>
<marker>Lin, Ng, Kan, 2010</marker>
<rawString>Ziheng Lin, Hwee Tou Ng, and Min Yen Kan. 2010. A pdtb-styled end-to-end discourse parser. Technical report, National University of Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text.</tech>
<contexts>
<context position="4133" citStr="Mann and Thompson, 1988" startWordPosition="603" endWordPosition="606"> There are a number of discourse-annotated English resources, including the ‘RST Treebank’ (Carlson et al., 2001) and the ‘Discourse GraphBank’ (Wolf and Gibson, 2005), which consist 18 Proceedings of the ACL 2014 Student Research Workshop, pages 18–25, Baltimore, Maryland USA, June 22-27 2014. c�2014 Association for Computational Linguistics of 385 and 135 articles respectively. Recent discourse research often make use of the large-scaled Penn Discourse Treebank (PDTB) (Prasad et al., 2008). Departed from annotation using predefined discourse relations, such as ‘Rhetorical Structure Theory’ (Mann and Thompson, 1988), PDTB introduces a lexically-ground formalism to annotate discourse relations by identifying the discourse connectives (DCs). An example is shown in the following. Example 1: Since McDonald’s menu prices rose this year, the actual decline may have been more. (PDTB 1280) ‘Since’ is an explicit DC taking the italic segment as the first argument (Arg1), and the bolded segment as the second argument (Arg2), which is syntactically attached to the DC. Implicit DCs are inserted by annotators between adjacent sentences of the same paragraph to represent inferred discourse relations. Each DC is annota</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Lynn Carlson</author>
<author>Maki Watanabe</author>
</authors>
<title>The automatic translation of discourse structures.</title>
<date>2000</date>
<booktitle>Proceedings of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6423" citStr="Marcu et al. (2000)" startWordPosition="955" endWordPosition="958">nment and machine translation results. Works in Chinese discourse parsing report F-scores of 64% in classification of inter-sentence discourse relations and 71% in 2-way classification of intrasentence contingency and comparison relations (Huang and Chen, 2011; Huang and Chen, 2012), training on a moderately sized (81 articles) corpus and considering explicit and implicit relations collectively. Corelation between discourse relation and sentiment was also explored based on annotated data (Huang et al., 2013). 2.3 Discourse relations in SMT Earlier studies of discourse relations in MT includes Marcu et al. (2000), which proposed a discourse transfer model to re-construct the target discourse tree from the source discourse tree, parsed by the (RST). However, incorporation to an SMT system was not discussed in the work. Recent works focus on the translation of ambiguous DCs, such as ‘since’ in the temporal sense vs. ‘since’ in the reason sense. This is achieved by annotating the DCs in the training data by ‘translation spotting’, which is to manually align the DCs of the source text to their translation in the target text, either occurring as DCs or other expressions (Meyer et al., 2011; Popescu-Belis e</context>
<context position="20595" citStr="Marcu et al. (2000)" startWordPosition="3237" endWordPosition="3240"> relation markedness and alignment, so as to define informative linguistic features for model training. Currently, I am using the MAE annotation tool(Stubbs, 2011). The annotation effort can be lightened by developing an interface that assists the multilingual annotation task by, for example, automatic EDU segmentation (to be reviewed by annotators) and automatic identification and prealignment of DCs based on a DC dictionary. 5 Future plans The key of this research is to integrate the annotated discourse knowledge into an SMT system. Integration of document level parse to MT, as described in Marcu et al. (2000) for Japaneseto-English translation, is complicated. In addition, comparing with Japanese, the word order in Chinese and English are not drastically different. Therefore, I plan to make use of information from DC-based shallow discourse parse. My main tasks towards this system include: 1. Cross-lingual DC annotation 2. EDU segmentation 3. Prediction of source implicit DCs 4. Integration to SMT system 5. DC-aware MT evaluation A flowchart of these tasks is shown in Figure 1 and explained in the following. 5.1 EDU segmentation Discourse parsing can be divided to the tasks of DC identification an</context>
</contexts>
<marker>Marcu, Carlson, Watanabe, 2000</marker>
<rawString>Daniel Marcu, Lynn Carlson, and Maki Watanabe. 2000. The automatic translation of discourse structures. Proceedings of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Meyer</author>
<author>Lucie Polakova</author>
</authors>
<title>Machine translation with many manually labeled discourse connectives.</title>
<date>2013</date>
<booktitle>Proceedings of the Discourse in Machine Translation Workshop.</booktitle>
<contexts>
<context position="7080" citStr="Meyer and Polakova, 2013" startWordPosition="1069" endWordPosition="1072">sfer model to re-construct the target discourse tree from the source discourse tree, parsed by the (RST). However, incorporation to an SMT system was not discussed in the work. Recent works focus on the translation of ambiguous DCs, such as ‘since’ in the temporal sense vs. ‘since’ in the reason sense. This is achieved by annotating the DCs in the training data by ‘translation spotting’, which is to manually align the DCs of the source text to their translation in the target text, either occurring as DCs or other expressions (Meyer et al., 2011; Popescu-Belis et al., 2012; Meyer et al., 2012; Meyer and Polakova, 2013; Cartoni et al., 2013). Experiments of these works have been conducted in English-to-French, Czech and German translation and only explicit DCs were considered. Tu et al. (2013) proposed a framework for Chinese-to-English translation, in which the source text is automatically parsed by an RST parser and translation rules are extracted from the source discourse trees aligned with the target strings. An improvement of 1.16 BLEU point is reported, considering only intra-sentential explicit relations. Meyer et al. (2012) found that the translation of DC improves by up to 10% disregarded of BLEU, </context>
</contexts>
<marker>Meyer, Polakova, 2013</marker>
<rawString>Thomas Meyer and Lucie Polakova. 2013. Machine translation with many manually labeled discourse connectives. Proceedings of the Discourse in Machine Translation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Meyer</author>
<author>Andrei Popescu-Belis</author>
<author>Sandrine Zufferey</author>
<author>Bruno Cartoni</author>
</authors>
<title>Multilingual annotation and disambiguation of discourse connectives for machine translation.</title>
<date>2011</date>
<booktitle>Proceedings of the Annual Meeting of the Special Interest Group on Discourse and Dialogue.</booktitle>
<contexts>
<context position="7006" citStr="Meyer et al., 2011" startWordPosition="1057" endWordPosition="1060"> in MT includes Marcu et al. (2000), which proposed a discourse transfer model to re-construct the target discourse tree from the source discourse tree, parsed by the (RST). However, incorporation to an SMT system was not discussed in the work. Recent works focus on the translation of ambiguous DCs, such as ‘since’ in the temporal sense vs. ‘since’ in the reason sense. This is achieved by annotating the DCs in the training data by ‘translation spotting’, which is to manually align the DCs of the source text to their translation in the target text, either occurring as DCs or other expressions (Meyer et al., 2011; Popescu-Belis et al., 2012; Meyer et al., 2012; Meyer and Polakova, 2013; Cartoni et al., 2013). Experiments of these works have been conducted in English-to-French, Czech and German translation and only explicit DCs were considered. Tu et al. (2013) proposed a framework for Chinese-to-English translation, in which the source text is automatically parsed by an RST parser and translation rules are extracted from the source discourse trees aligned with the target strings. An improvement of 1.16 BLEU point is reported, considering only intra-sentential explicit relations. Meyer et al. (2012) fo</context>
<context position="12137" citStr="Meyer et al., 2011" startWordPosition="1832" endWordPosition="1835">to create data but also to understand the problems in Chinese discourse processing and translation. The completed annotation is planned to be released. Comparing with representation of discourse relations by analytical definitions, the PDTB-styled association of discourse relations to lexical connectives is more compatible to the procedures of statistical machine translation. Therefore, the PDTB convention is adopted for the annotation of connectives on both sides of the parallel corpus. Instead of sense annotation, the DCs are aligned in similar manner as the ‘translation spotting’ approach (Meyer et al., 2011; Popescu-Belis et al., 2012; Cartoni et al., 2013). In other words, the ‘senses’ are disambiguated by the translation of the DCs. The data used is the English Chinese Translation Treebank (Bies et al., 2007), which consists of 325 Chinese news stories translated into 146,300 words of English. Adaptations made to capture the cross-lingual difference in discourse relations are explained in the following. 4.1 EDU segmented by punctuations In the PDTB, the span of each EDU (Arg1 or Arg2), which can range from a single noun to multiple sentences, are manually annotated. While 20 each WSJ paragraph</context>
</contexts>
<marker>Meyer, Popescu-Belis, Zufferey, Cartoni, 2011</marker>
<rawString>Thomas Meyer, Andrei Popescu-Belis, Sandrine Zufferey, and Bruno Cartoni. 2011. Multilingual annotation and disambiguation of discourse connectives for machine translation. Proceedings of the Annual Meeting of the Special Interest Group on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Meyer</author>
<author>Andrei Popescu-Belis</author>
<author>Najeh Hajlaoui</author>
</authors>
<title>Machine translation of labeled discourse connectives.</title>
<date>2012</date>
<booktitle>Proceedings of the Biennial Conference of the Association for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="7054" citStr="Meyer et al., 2012" startWordPosition="1065" endWordPosition="1068">sed a discourse transfer model to re-construct the target discourse tree from the source discourse tree, parsed by the (RST). However, incorporation to an SMT system was not discussed in the work. Recent works focus on the translation of ambiguous DCs, such as ‘since’ in the temporal sense vs. ‘since’ in the reason sense. This is achieved by annotating the DCs in the training data by ‘translation spotting’, which is to manually align the DCs of the source text to their translation in the target text, either occurring as DCs or other expressions (Meyer et al., 2011; Popescu-Belis et al., 2012; Meyer et al., 2012; Meyer and Polakova, 2013; Cartoni et al., 2013). Experiments of these works have been conducted in English-to-French, Czech and German translation and only explicit DCs were considered. Tu et al. (2013) proposed a framework for Chinese-to-English translation, in which the source text is automatically parsed by an RST parser and translation rules are extracted from the source discourse trees aligned with the target strings. An improvement of 1.16 BLEU point is reported, considering only intra-sentential explicit relations. Meyer et al. (2012) found that the translation of DC improves by up to</context>
<context position="23539" citStr="Meyer et al., 2012" startWordPosition="3709" endWordPosition="3712">approach is to decorate identified and predicted DCs in a syntactical parsed tree, so as to enrich the tree-to-string rules with DC markedness features. Moreover, when a source DC is translated to a sentence initial DC, a source sentence is potentially split to multiple target sentences. A document level decoder (Hardmeier et al., 2012) that searches beyond the sentence boundary is thus preferred. 5.4 DC-aware MT evaluation Comparable evaluation is essential for MT research, yet conventional MT metrics, such as BLEU, is not effective in detecting improvement in discourse relation translation (Meyer et al., 2012). One direction is to extend the ACT metrics (Hajlaoui and Popescu-Belis, 2013) to access also translation of implicit DCs. Another direction is to define a measure that is not reference-dependent, since implicit relations can be translated in various ways. Moreover, conventional MT metrics, which compare a candidate with the reference sentenceby-sentence, have to be modified when used to access the overall MT performance of the proposed system, since the output sentences may not align with the reference sentences one-by-one. 6 Conclusion In this thesis proposal, ongoing work and future plans </context>
</contexts>
<marker>Meyer, Popescu-Belis, Hajlaoui, 2012</marker>
<rawString>Thomas Meyer, Andrei Popescu-Belis, and Najeh Hajlaoui. 2012. Machine translation of labeled discourse connectives. Proceedings of the Biennial Conference of the Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleni Miltsakaki</author>
<author>Rashmi Prasad</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>Annotating discourse connectives and their arguments.</title>
<date>2004</date>
<booktitle>Proceedings of the Workshop on Frontiers in Corpus Annotations.</booktitle>
<contexts>
<context position="17254" citStr="Miltsakaki et al., 2004" startWordPosition="2674" endWordPosition="2677">nnotate parallel DC structures in Chinese. Most Chinese discourse relations are marked by ‘parallel DCs’, which are similar to English patterns such as ‘either...or’, ’if...then’, ‘not only...but also’. However, one or both DCs in the parallel structure can be dropped in Chinese. The dropped DCs are inserted as IMP and aligned to the English side. After the first round of the annotation, another annotator is to repeat the annotation with the set of DCs recognized by the first annotator. Since implicit discourse relations lack lexical signals, the annotator agreement is lower (72% for English (Miltsakaki et al., 2004)). I plan to include implicit DC annotations of both annotators as multiple readings or coexisting DCs of the implicit relations, thus multiplying the training instances. 21 4.6 Redundancy Usually, two EDUs are related by one DC in English, thus only one of the Chinese parallel DCs is translated to explicitly. To learn this translation rule, the untranslated DC is thus aligned to a‘REDundant’ tag attached to the corresponding English EDU. To mark Chinese DCs that always occur independently rather than in parallel structure, the EDU without a DC is also annotated as ‘RED’. The various types of </context>
</contexts>
<marker>Miltsakaki, Prasad, Joshi, Webber, 2004</marker>
<rawString>Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and Bonnie Webber. 2004. Annotating discourse connectives and their arguments. Proceedings of the Workshop on Frontiers in Corpus Annotations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Ani Nenkova</author>
</authors>
<title>Using syntax to disambiguate explicit discourse connectives in text.</title>
<date>2009</date>
<booktitle>Proceedings of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="4906" citStr="Pitler and Nenkova, 2009" startWordPosition="722" endWordPosition="725"> the following. Example 1: Since McDonald’s menu prices rose this year, the actual decline may have been more. (PDTB 1280) ‘Since’ is an explicit DC taking the italic segment as the first argument (Arg1), and the bolded segment as the second argument (Arg2), which is syntactically attached to the DC. Implicit DCs are inserted by annotators between adjacent sentences of the same paragraph to represent inferred discourse relations. Each DC is annotated with defined senses classified into 3 levels of granularity. PDTB allows evaluation of English discourse parsing tasks and disambiguation tasks (Pitler and Nenkova, 2009; Lin et al., 2010), which reveal that implicit discourse relations are much harder to learn than explicit discourse relations (Pitler et al., 2009; Zhou et al., 2010). For example, classification of the 4 main relation senses (temporal, contingency, comparison, expansion) reaches 94% accuracy for explicit relations (Pitler and Nenkova, 2009), but only range from F-scores of 20% for ‘temporal’ to 76% for ‘expansion’ relations, possibly due to unbalanced number of training instances (Pitler et al., 2009; Zhou et al., 2010). 2.2 Chinese discourse processing Schemes for Chinese discourse annotati</context>
</contexts>
<marker>Pitler, Nenkova, 2009</marker>
<rawString>Emily Pitler and Ani Nenkova. 2009. Using syntax to disambiguate explicit discourse connectives in text. Proceedings of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Annie Louis</author>
<author>Ani Nenkova</author>
</authors>
<title>Automatic sense prediction for implicit discourse relations in text.</title>
<date>2009</date>
<booktitle>Proceedings of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="5053" citStr="Pitler et al., 2009" startWordPosition="745" endWordPosition="748">ing the italic segment as the first argument (Arg1), and the bolded segment as the second argument (Arg2), which is syntactically attached to the DC. Implicit DCs are inserted by annotators between adjacent sentences of the same paragraph to represent inferred discourse relations. Each DC is annotated with defined senses classified into 3 levels of granularity. PDTB allows evaluation of English discourse parsing tasks and disambiguation tasks (Pitler and Nenkova, 2009; Lin et al., 2010), which reveal that implicit discourse relations are much harder to learn than explicit discourse relations (Pitler et al., 2009; Zhou et al., 2010). For example, classification of the 4 main relation senses (temporal, contingency, comparison, expansion) reaches 94% accuracy for explicit relations (Pitler and Nenkova, 2009), but only range from F-scores of 20% for ‘temporal’ to 76% for ‘expansion’ relations, possibly due to unbalanced number of training instances (Pitler et al., 2009; Zhou et al., 2010). 2.2 Chinese discourse processing Schemes for Chinese discourse annotation have been proposed in the existing literature (Xue, 2005; Zhou and Xue, 2012) but the corresponding resource is not yet available. Zhou et al. (</context>
</contexts>
<marker>Pitler, Louis, Nenkova, 2009</marker>
<rawString>Emily Pitler, Annie Louis, and Ani Nenkova. 2009. Automatic sense prediction for implicit discourse relations in text. Proceedings of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrei Popescu-Belis</author>
<author>Thomas Meyer</author>
<author>Jeevanthi Liyanapathirana</author>
<author>Bruno Cartoni</author>
<author>Sandrine Zufferey</author>
</authors>
<title>Discourse-level annotation over europarl for machine translation: Connectives and pronouns.</title>
<date>2012</date>
<booktitle>Proceedings of the Language Resource and Evaluation Conference.</booktitle>
<contexts>
<context position="7034" citStr="Popescu-Belis et al., 2012" startWordPosition="1061" endWordPosition="1064">u et al. (2000), which proposed a discourse transfer model to re-construct the target discourse tree from the source discourse tree, parsed by the (RST). However, incorporation to an SMT system was not discussed in the work. Recent works focus on the translation of ambiguous DCs, such as ‘since’ in the temporal sense vs. ‘since’ in the reason sense. This is achieved by annotating the DCs in the training data by ‘translation spotting’, which is to manually align the DCs of the source text to their translation in the target text, either occurring as DCs or other expressions (Meyer et al., 2011; Popescu-Belis et al., 2012; Meyer et al., 2012; Meyer and Polakova, 2013; Cartoni et al., 2013). Experiments of these works have been conducted in English-to-French, Czech and German translation and only explicit DCs were considered. Tu et al. (2013) proposed a framework for Chinese-to-English translation, in which the source text is automatically parsed by an RST parser and translation rules are extracted from the source discourse trees aligned with the target strings. An improvement of 1.16 BLEU point is reported, considering only intra-sentential explicit relations. Meyer et al. (2012) found that the translation of </context>
<context position="12165" citStr="Popescu-Belis et al., 2012" startWordPosition="1836" endWordPosition="1839">lso to understand the problems in Chinese discourse processing and translation. The completed annotation is planned to be released. Comparing with representation of discourse relations by analytical definitions, the PDTB-styled association of discourse relations to lexical connectives is more compatible to the procedures of statistical machine translation. Therefore, the PDTB convention is adopted for the annotation of connectives on both sides of the parallel corpus. Instead of sense annotation, the DCs are aligned in similar manner as the ‘translation spotting’ approach (Meyer et al., 2011; Popescu-Belis et al., 2012; Cartoni et al., 2013). In other words, the ‘senses’ are disambiguated by the translation of the DCs. The data used is the English Chinese Translation Treebank (Bies et al., 2007), which consists of 325 Chinese news stories translated into 146,300 words of English. Adaptations made to capture the cross-lingual difference in discourse relations are explained in the following. 4.1 EDU segmented by punctuations In the PDTB, the span of each EDU (Arg1 or Arg2), which can range from a single noun to multiple sentences, are manually annotated. While 20 each WSJ paragraph1 contains three sentences o</context>
</contexts>
<marker>Popescu-Belis, Meyer, Liyanapathirana, Cartoni, Zufferey, 2012</marker>
<rawString>Andrei Popescu-Belis, Thomas Meyer, Jeevanthi Liyanapathirana, Bruno Cartoni, and Sandrine Zufferey. 2012. Discourse-level annotation over europarl for machine translation: Connectives and pronouns. Proceedings of the Language Resource and Evaluation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhit Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>The penn discourse treebank 2.0.</title>
<date>2008</date>
<booktitle>Proceedings of the Language Resource and Evaluation Conference.</booktitle>
<contexts>
<context position="4005" citStr="Prasad et al., 2008" startWordPosition="586" endWordPosition="589">on 5 present my plans for next steps. Finally, a conclusion is drawn in Section 6. 2 Survey 2.1 English discourse processing There are a number of discourse-annotated English resources, including the ‘RST Treebank’ (Carlson et al., 2001) and the ‘Discourse GraphBank’ (Wolf and Gibson, 2005), which consist 18 Proceedings of the ACL 2014 Student Research Workshop, pages 18–25, Baltimore, Maryland USA, June 22-27 2014. c�2014 Association for Computational Linguistics of 385 and 135 articles respectively. Recent discourse research often make use of the large-scaled Penn Discourse Treebank (PDTB) (Prasad et al., 2008). Departed from annotation using predefined discourse relations, such as ‘Rhetorical Structure Theory’ (Mann and Thompson, 1988), PDTB introduces a lexically-ground formalism to annotate discourse relations by identifying the discourse connectives (DCs). An example is shown in the following. Example 1: Since McDonald’s menu prices rose this year, the actual decline may have been more. (PDTB 1280) ‘Since’ is an explicit DC taking the italic segment as the first argument (Arg1), and the bolded segment as the second argument (Arg2), which is syntactically attached to the DC. Implicit DCs are inse</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhit Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The penn discourse treebank 2.0. Proceedings of the Language Resource and Evaluation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Sanders</author>
<author>Leo Noordman</author>
</authors>
<title>The role of coherence relations and their linguistic markers in text processing.</title>
<date>2000</date>
<booktitle>Discourse Processes,</booktitle>
<volume>1</volume>
<contexts>
<context position="1666" citStr="Sanders and Noordman, 2000" startWordPosition="225" endWordPosition="228">ion. 1 Introduction Human translation is created at document level, suggesting that translation of a particular sentence depends also on the ‘discourse structure’. Recently, some MT researchers have started to explore the possibility to incorporate linguistic information outside the sentence boundary for MT, such as topical structure, coreference chains, and lexical coherence. Among various discourse structures, discourse relations, also known as coherence relations, are meaningful relations connecting text segments and are crucial to the human cognitive processing as well as memory of texts (Sanders and Noordman, 2000). These relations can be explicitly marked in a text by signaling phrases or implicitly implied. Even when they are explicit, some markers are ambiguous and do not always signal the same relation. In addition, strategies to represent discourse relations vary across languages. It is thus a challenging task to correctly translate discourse relations. This thesis proposal presents my plan towards building a discourse-relation-aware machine translation system translating from Chinese to English. In particular, I would like to focus on modeling the translation of implicit discourse relations, which</context>
</contexts>
<marker>Sanders, Noordman, 2000</marker>
<rawString>Ted Sanders and Leo Noordman. 2000. The role of coherence relations and their linguistic markers in text processing. Discourse Processes, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny A Stepanov</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Comparative evaluation of argument extraction algorithms in discourse relation parsing.</title>
<date>2013</date>
<booktitle>Proceedings of the International Conference on Parsing Technologies.</booktitle>
<contexts>
<context position="9940" citStr="Stepanov and Riccardi, 2013" startWordPosition="1494" endWordPosition="1497">guages. In current SMT models, sentence splitting is the result of the language model or translation rules containing periods or sentence initial markers. A long Chinese ‘running sentence’ is typically translated to one English sentence with ‘comma splices’ (ungrammatical commas between complete sentences without connecting by conjunctions). On the other hand, discourse structure provides clues to split the source sentence. It is because some DCs only relate EDUs within the same sentences (e.g. ’but’, ‘because’) while some only relate with the previous sentence (e.g. ‘however’, ‘in addition’)(Stepanov and Riccardi, 2013). Example 2 shows two versions of English translation of a Chinese sentence as output by Google Translate. Note that in the original Chinese sentence, all the DCs are omitted to achieve a quadruplet pattern. Implicit DCs, represented by glossed words in brackets, can be inserted to each comma-separated clause to signal the discourse relations. Without explicit DCs, the MT output (MT original) results in a sequence of broken clauses, whereas with inserted DCs (MT w/DC), the clauses are joined by the translated DCs to a complete sentence. In addition, the dropped pronoun ‘you’ is properly genera</context>
</contexts>
<marker>Stepanov, Riccardi, 2013</marker>
<rawString>Evgeny A. Stepanov and Giuseppe Riccardi. 2013. Comparative evaluation of argument extraction algorithms in discourse relation parsing. Proceedings of the International Conference on Parsing Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amber Stubbs</author>
</authors>
<title>Mae and mai: lightweight annotation and adjudication tools.</title>
<date>2011</date>
<booktitle>Proceedings of the Linguistic Annotation Workshop.</booktitle>
<contexts>
<context position="20139" citStr="Stubbs, 2011" startWordPosition="3164" endWordPosition="3165">ted to an explicit DC in English, while about 1/6 of them are translated to nonDC expressions. As mentioned, these are mostly prepositions corresponding to discourse relations that are not defined by any DCs in English. This suggests that bilingual discourse annotation can recover a larger variation of universal discourse relations than monolingual annotation. Further exploratory analysis will be conducted to investigate the tendency in discourse relation markedness and alignment, so as to define informative linguistic features for model training. Currently, I am using the MAE annotation tool(Stubbs, 2011). The annotation effort can be lightened by developing an interface that assists the multilingual annotation task by, for example, automatic EDU segmentation (to be reviewed by annotators) and automatic identification and prealignment of DCs based on a DC dictionary. 5 Future plans The key of this research is to integrate the annotated discourse knowledge into an SMT system. Integration of document level parse to MT, as described in Marcu et al. (2000) for Japaneseto-English translation, is complicated. In addition, comparing with Japanese, the word order in Chinese and English are not drastic</context>
</contexts>
<marker>Stubbs, 2011</marker>
<rawString>Amber Stubbs. 2011. Mae and mai: lightweight annotation and adjudication tools. Proceedings of the Linguistic Annotation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mei Tu</author>
<author>Yu Zhou</author>
<author>Chengqing Zong</author>
</authors>
<title>A novel translation framework based on rhetorical structure theory.</title>
<date>2013</date>
<booktitle>Proceedings of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7258" citStr="Tu et al. (2013)" startWordPosition="1096" endWordPosition="1099">rks focus on the translation of ambiguous DCs, such as ‘since’ in the temporal sense vs. ‘since’ in the reason sense. This is achieved by annotating the DCs in the training data by ‘translation spotting’, which is to manually align the DCs of the source text to their translation in the target text, either occurring as DCs or other expressions (Meyer et al., 2011; Popescu-Belis et al., 2012; Meyer et al., 2012; Meyer and Polakova, 2013; Cartoni et al., 2013). Experiments of these works have been conducted in English-to-French, Czech and German translation and only explicit DCs were considered. Tu et al. (2013) proposed a framework for Chinese-to-English translation, in which the source text is automatically parsed by an RST parser and translation rules are extracted from the source discourse trees aligned with the target strings. An improvement of 1.16 BLEU point is reported, considering only intra-sentential explicit relations. Meyer et al. (2012) found that the translation of DC improves by up to 10% disregarded of BLEU, which stays around the baseline system score. To detect the improvement, they used a metric known as ACT (Accuracy of Connective Translation) (Hajlaoui and Popescu-Belis, 2012; H</context>
</contexts>
<marker>Tu, Zhou, Zong, 2013</marker>
<rawString>Mei Tu, Yu Zhou, and Chengqing Zong. 2013. A novel translation framework based on rhetorical structure theory. Proceedings of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Wolf</author>
<author>Edward Gibson</author>
</authors>
<title>Representing discourse coherence: a corpus-based analysis. Computational Linguistics.</title>
<date>2005</date>
<contexts>
<context position="3676" citStr="Wolf and Gibson, 2005" startWordPosition="538" endWordPosition="541">of the research is to translate in units of discourse segments instead of sentences. Section 2 gives an overview of existing literature. Section 3 explains the motivations behind my research on discourse relations for MT. Section 4 describes my ongoing work of bilingual discourse annotation, followed by statistics to date . Section 5 present my plans for next steps. Finally, a conclusion is drawn in Section 6. 2 Survey 2.1 English discourse processing There are a number of discourse-annotated English resources, including the ‘RST Treebank’ (Carlson et al., 2001) and the ‘Discourse GraphBank’ (Wolf and Gibson, 2005), which consist 18 Proceedings of the ACL 2014 Student Research Workshop, pages 18–25, Baltimore, Maryland USA, June 22-27 2014. c�2014 Association for Computational Linguistics of 385 and 135 articles respectively. Recent discourse research often make use of the large-scaled Penn Discourse Treebank (PDTB) (Prasad et al., 2008). Departed from annotation using predefined discourse relations, such as ‘Rhetorical Structure Theory’ (Mann and Thompson, 1988), PDTB introduces a lexically-ground formalism to annotate discourse relations by identifying the discourse connectives (DCs). An example is sh</context>
</contexts>
<marker>Wolf, Gibson, 2005</marker>
<rawString>Florian Wolf and Edward Gibson. 2005. Representing discourse coherence: a corpus-based analysis. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Annotating discourse connectives in the chinese treebank.</title>
<date>2005</date>
<booktitle>Proceedings of the Workshop on Frontiers in Corpus Annotations.</booktitle>
<contexts>
<context position="5565" citStr="Xue, 2005" startWordPosition="827" endWordPosition="828">scourse relations are much harder to learn than explicit discourse relations (Pitler et al., 2009; Zhou et al., 2010). For example, classification of the 4 main relation senses (temporal, contingency, comparison, expansion) reaches 94% accuracy for explicit relations (Pitler and Nenkova, 2009), but only range from F-scores of 20% for ‘temporal’ to 76% for ‘expansion’ relations, possibly due to unbalanced number of training instances (Pitler et al., 2009; Zhou et al., 2010). 2.2 Chinese discourse processing Schemes for Chinese discourse annotation have been proposed in the existing literature (Xue, 2005; Zhou and Xue, 2012) but the corresponding resource is not yet available. Zhou et al. (2012) proposed to project English discourse annotation and classification algorithms to Chinese data, but the transfer was based on automatic word alignment and machine translation results. Works in Chinese discourse parsing report F-scores of 64% in classification of inter-sentence discourse relations and 71% in 2-way classification of intrasentence contingency and comparison relations (Huang and Chen, 2011; Huang and Chen, 2012), training on a moderately sized (81 articles) corpus and considering explicit</context>
<context position="8363" citStr="Xue, 2005" startWordPosition="1259" endWordPosition="1260">they used a metric known as ACT (Accuracy of Connective Translation) (Hajlaoui and Popescu-Belis, 2012; Hajlaoui and Popescu-Belis, 2013), which relies on bilingual word alignment and a dictionary of DCs. In the setting, missing/additional DC (i.e. potential implicitation/explicitation of discourse relations) are to be checked manually for the validity. 3 Motivation The motivation behind a discourse-relation-aware translation model for Chinese is two-fold. First of all, on top of ambiguous discourse connectives as in other languages, Chinese documents contain 19 abundant implicit connectives (Xue, 2005). In particular, complex sentences often occur in the form of ‘running sentences’, in which loose clauses run in a sequence separated by commas yet without explicit connectives. Such sentence structures are used to represent the temporal or reasoning order or related events, or simply to achieve consistent rhythmic patterns. In contrast, syntactical constraint is prominent in English and this kind of ‘paratactic’ structures only occur as occasional rhetorical measures. In other cases, relations between clauses within a sentence are marked by coordinating or subordinating conjunctions in order </context>
</contexts>
<marker>Xue, 2005</marker>
<rawString>Nianwen Xue. 2005. Annotating discourse connectives in the chinese treebank. Proceedings of the Workshop on Frontiers in Corpus Annotations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaqin Yang</author>
<author>Nianwen Xue</author>
</authors>
<title>Chinese comma disambiguation for discourse analysis.</title>
<date>2012</date>
<booktitle>Proceedings of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9260" citStr="Yang and Xue, 2012" startWordPosition="1394" endWordPosition="1397">simply to achieve consistent rhythmic patterns. In contrast, syntactical constraint is prominent in English and this kind of ‘paratactic’ structures only occur as occasional rhetorical measures. In other cases, relations between clauses within a sentence are marked by coordinating or subordinating conjunctions in order to maintain an intact sentence structure. Another motivation is that translation in units of sentences is not always preferable in Chinese-English translation. In fact, each commaseparated segment of a ‘running sentence’ can be considered as an elementary discourse units (EDU) (Yang and Xue, 2012; Zhou and Xue, 2012) and aligned across the two languages. In current SMT models, sentence splitting is the result of the language model or translation rules containing periods or sentence initial markers. A long Chinese ‘running sentence’ is typically translated to one English sentence with ‘comma splices’ (ungrammatical commas between complete sentences without connecting by conjunctions). On the other hand, discourse structure provides clues to split the source sentence. It is because some DCs only relate EDUs within the same sentences (e.g. ’but’, ‘because’) while some only relate with th</context>
<context position="13010" citStr="Yang and Xue, 2012" startWordPosition="1976" endWordPosition="1979">anslated into 146,300 words of English. Adaptations made to capture the cross-lingual difference in discourse relations are explained in the following. 4.1 EDU segmented by punctuations In the PDTB, the span of each EDU (Arg1 or Arg2), which can range from a single noun to multiple sentences, are manually annotated. While 20 each WSJ paragraph1 contains three sentences on average, the typical ‘running sentences’ in Chinese are exceptionally long. It is hard for annotators to agree on an EDU span, and neither does it have direct effect on the DC translation. Therefore, I follow previous works (Yang and Xue, 2012; Zhou and Xue, 2012) and consider a segment separated by Chinese punctuations, especially commas, as the span of an EDU. Nonetheless, there are exceptions since Chinese commas are used arbitrarily to signify ’pauses’ in the sentence. Three original tags are defined to annotate the exceptions: ‘ATTribution’ , ‘initialized ADVerbial’, and ‘OPTional comma’ (refer to Table 1). These are designed for training of automatic EDU segmentation. 4.2 Explicit DCs After recognizing a valid EDU on the source text, explicit DC(s) in the EDU are tagged ‘EXP’ and aligned to their translation on the target sid</context>
<context position="21676" citStr="Yang and Xue (2012)" startWordPosition="3410" endWordPosition="3413">own in Figure 1 and explained in the following. 5.1 EDU segmentation Discourse parsing can be divided to the tasks of DC identification and argument identification, 22 Figure 1: Main tasks for proposed DC-aware SMT system. where the latter can be further divided into argument position and argument span identification. In Chinese, a punctuation-separated segment is basically considered an EDU, so the span is fixed. The exceptional cases of commas not segmenting an EDU are annotated in the dataset and can be predicted in a binary classification task using lexical and syntactical features, as in Yang and Xue (2012). On the other hand, a text segment can contain more than one EDU when there are multiple DCs, thus further segmentation is necessary depending on DC identification. 5.2 Prediction of source implicit DCs One focus of this research is to explicitize implicit Chinese DCs when translating to English. I plan to construct a model to predict implicit discourse relations in the Chinese source text. Previous works on Chinese discourse relation recognitions (Yue, 2006; Huang and Chen, 2011) provide insights on the prediction task and the DC annotated corpus provides data for supervised training. Althou</context>
</contexts>
<marker>Yang, Xue, 2012</marker>
<rawString>Yaqin Yang and Nianwen Xue. 2012. Chinese comma disambiguation for discourse analysis. Proceedings of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming Yue</author>
</authors>
<title>Discursive usage of six chinese punctuation marks.</title>
<date>2006</date>
<booktitle>Proceedings of the Annual Meeting of the Association for Computational Linguistics and International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="22139" citStr="Yue, 2006" startWordPosition="3487" endWordPosition="3488">re annotated in the dataset and can be predicted in a binary classification task using lexical and syntactical features, as in Yang and Xue (2012). On the other hand, a text segment can contain more than one EDU when there are multiple DCs, thus further segmentation is necessary depending on DC identification. 5.2 Prediction of source implicit DCs One focus of this research is to explicitize implicit Chinese DCs when translating to English. I plan to construct a model to predict implicit discourse relations in the Chinese source text. Previous works on Chinese discourse relation recognitions (Yue, 2006; Huang and Chen, 2011) provide insights on the prediction task and the DC annotated corpus provides data for supervised training. Although state-of-the-art implicit discourse parsing is still of low accuracy, the preciseness can be adjusted to suit the goal of machine translation. As in other joint tasks with MT, such as Bouamor et al. (2013), features of whether the implicit DC can be translated explicitly, or correctly, can in incorporated to the prediction task, so as to predict translatable implicit DCs in particular. 5.3 Integration to SMT system One way to exploit discourse knowledge in</context>
</contexts>
<marker>Yue, 2006</marker>
<rawString>Ming Yue. 2006. Discursive usage of six chinese punctuation marks. Proceedings of the Annual Meeting of the Association for Computational Linguistics and International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuping Zhou</author>
<author>Nianwen Xue</author>
</authors>
<title>Pdtb-style discourse annotation of chinese text.</title>
<date>2012</date>
<booktitle>Proceedings of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5586" citStr="Zhou and Xue, 2012" startWordPosition="829" endWordPosition="832">ations are much harder to learn than explicit discourse relations (Pitler et al., 2009; Zhou et al., 2010). For example, classification of the 4 main relation senses (temporal, contingency, comparison, expansion) reaches 94% accuracy for explicit relations (Pitler and Nenkova, 2009), but only range from F-scores of 20% for ‘temporal’ to 76% for ‘expansion’ relations, possibly due to unbalanced number of training instances (Pitler et al., 2009; Zhou et al., 2010). 2.2 Chinese discourse processing Schemes for Chinese discourse annotation have been proposed in the existing literature (Xue, 2005; Zhou and Xue, 2012) but the corresponding resource is not yet available. Zhou et al. (2012) proposed to project English discourse annotation and classification algorithms to Chinese data, but the transfer was based on automatic word alignment and machine translation results. Works in Chinese discourse parsing report F-scores of 64% in classification of inter-sentence discourse relations and 71% in 2-way classification of intrasentence contingency and comparison relations (Huang and Chen, 2011; Huang and Chen, 2012), training on a moderately sized (81 articles) corpus and considering explicit and implicit relatio</context>
<context position="9281" citStr="Zhou and Xue, 2012" startWordPosition="1398" endWordPosition="1401">nsistent rhythmic patterns. In contrast, syntactical constraint is prominent in English and this kind of ‘paratactic’ structures only occur as occasional rhetorical measures. In other cases, relations between clauses within a sentence are marked by coordinating or subordinating conjunctions in order to maintain an intact sentence structure. Another motivation is that translation in units of sentences is not always preferable in Chinese-English translation. In fact, each commaseparated segment of a ‘running sentence’ can be considered as an elementary discourse units (EDU) (Yang and Xue, 2012; Zhou and Xue, 2012) and aligned across the two languages. In current SMT models, sentence splitting is the result of the language model or translation rules containing periods or sentence initial markers. A long Chinese ‘running sentence’ is typically translated to one English sentence with ‘comma splices’ (ungrammatical commas between complete sentences without connecting by conjunctions). On the other hand, discourse structure provides clues to split the source sentence. It is because some DCs only relate EDUs within the same sentences (e.g. ’but’, ‘because’) while some only relate with the previous sentence (</context>
<context position="13031" citStr="Zhou and Xue, 2012" startWordPosition="1980" endWordPosition="1983">0 words of English. Adaptations made to capture the cross-lingual difference in discourse relations are explained in the following. 4.1 EDU segmented by punctuations In the PDTB, the span of each EDU (Arg1 or Arg2), which can range from a single noun to multiple sentences, are manually annotated. While 20 each WSJ paragraph1 contains three sentences on average, the typical ‘running sentences’ in Chinese are exceptionally long. It is hard for annotators to agree on an EDU span, and neither does it have direct effect on the DC translation. Therefore, I follow previous works (Yang and Xue, 2012; Zhou and Xue, 2012) and consider a segment separated by Chinese punctuations, especially commas, as the span of an EDU. Nonetheless, there are exceptions since Chinese commas are used arbitrarily to signify ’pauses’ in the sentence. Three original tags are defined to annotate the exceptions: ‘ATTribution’ , ‘initialized ADVerbial’, and ‘OPTional comma’ (refer to Table 1). These are designed for training of automatic EDU segmentation. 4.2 Explicit DCs After recognizing a valid EDU on the source text, explicit DC(s) in the EDU are tagged ‘EXP’ and aligned to their translation on the target side, which are not nece</context>
<context position="19162" citStr="Zhou and Xue, 2012" startWordPosition="3012" endWordPosition="3015">. 59 DC types for Chinese and 47 for English have been identified. Chi -/- Eng EXP. ALT. IMP. RED. Total EXP. 291 68 23 49 431 IMP. 396 144 770 261 1561 RED. 6 0 0 52 58 Total 693 212 783 362 2050 attribute - - - - 211 optional - - - - 89 adverbial - - - - 186 Total - - - - 486 Table 2: Distribution of alignment between different ‘DC’ types The distribution of alignments between these types is shown in Table 2. Although the statistics are not directly comparable to other existing data due to difference in definitions, it agrees with previous findings that implicit DCs are abundant in Chinese (Zhou and Xue, 2012). According to the present data, about 1/4 of the implicit DCs are translated to explicit DCs in English. However, more than half are not explicitly translated (implicit or redundant). This suggests that implicit DC recovery can be focused on the those that are likely to be translated explicitly. It is also observable that explicit Chinese DCs are mostly translated to an explicit DC in English, while about 1/6 of them are translated to nonDC expressions. As mentioned, these are mostly prepositions corresponding to discourse relations that are not defined by any DCs in English. This suggests th</context>
</contexts>
<marker>Zhou, Xue, 2012</marker>
<rawString>Yuping Zhou and Nianwen Xue. 2012. Pdtb-style discourse annotation of chinese text. Proceedings of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi-Min Zhou</author>
<author>Yu Xu</author>
<author>Zheng-Yu Niu</author>
<author>Man Lan</author>
<author>Jian Su</author>
<author>Chew Lim Tan</author>
</authors>
<title>Predicting discourse connectives for implicit discourse relation recognition.</title>
<date>2010</date>
<booktitle>Proceedings of the International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="5073" citStr="Zhou et al., 2010" startWordPosition="749" endWordPosition="752">t as the first argument (Arg1), and the bolded segment as the second argument (Arg2), which is syntactically attached to the DC. Implicit DCs are inserted by annotators between adjacent sentences of the same paragraph to represent inferred discourse relations. Each DC is annotated with defined senses classified into 3 levels of granularity. PDTB allows evaluation of English discourse parsing tasks and disambiguation tasks (Pitler and Nenkova, 2009; Lin et al., 2010), which reveal that implicit discourse relations are much harder to learn than explicit discourse relations (Pitler et al., 2009; Zhou et al., 2010). For example, classification of the 4 main relation senses (temporal, contingency, comparison, expansion) reaches 94% accuracy for explicit relations (Pitler and Nenkova, 2009), but only range from F-scores of 20% for ‘temporal’ to 76% for ‘expansion’ relations, possibly due to unbalanced number of training instances (Pitler et al., 2009; Zhou et al., 2010). 2.2 Chinese discourse processing Schemes for Chinese discourse annotation have been proposed in the existing literature (Xue, 2005; Zhou and Xue, 2012) but the corresponding resource is not yet available. Zhou et al. (2012) proposed to pr</context>
</contexts>
<marker>Zhou, Xu, Niu, Lan, Su, Tan, 2010</marker>
<rawString>Zhi-Min Zhou, Yu Xu, Zheng-Yu Niu, Man Lan, Jian Su, and Chew Lim Tan. 2010. Predicting discourse connectives for implicit discourse relation recognition. Proceedings of the International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lan Jun Zhou</author>
<author>Wei Gao</author>
<author>Binyang Li</author>
<author>Zhongyu Wei</author>
<author>Kam-Fat Wong</author>
</authors>
<title>Cross-lingual identification of ambiguous discourse connectives for resource-poor language.</title>
<date>2012</date>
<booktitle>Proceedings of the International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="5658" citStr="Zhou et al. (2012)" startWordPosition="841" endWordPosition="844"> et al., 2009; Zhou et al., 2010). For example, classification of the 4 main relation senses (temporal, contingency, comparison, expansion) reaches 94% accuracy for explicit relations (Pitler and Nenkova, 2009), but only range from F-scores of 20% for ‘temporal’ to 76% for ‘expansion’ relations, possibly due to unbalanced number of training instances (Pitler et al., 2009; Zhou et al., 2010). 2.2 Chinese discourse processing Schemes for Chinese discourse annotation have been proposed in the existing literature (Xue, 2005; Zhou and Xue, 2012) but the corresponding resource is not yet available. Zhou et al. (2012) proposed to project English discourse annotation and classification algorithms to Chinese data, but the transfer was based on automatic word alignment and machine translation results. Works in Chinese discourse parsing report F-scores of 64% in classification of inter-sentence discourse relations and 71% in 2-way classification of intrasentence contingency and comparison relations (Huang and Chen, 2011; Huang and Chen, 2012), training on a moderately sized (81 articles) corpus and considering explicit and implicit relations collectively. Corelation between discourse relation and sentiment was</context>
</contexts>
<marker>Zhou, Gao, Li, Wei, Wong, 2012</marker>
<rawString>Lan Jun Zhou, Wei Gao, Binyang Li, Zhongyu Wei, and Kam-Fat Wong. 2012. Cross-lingual identification of ambiguous discourse connectives for resource-poor language. Proceedings of the International Conference on Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>