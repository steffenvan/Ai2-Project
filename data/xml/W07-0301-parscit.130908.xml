<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.986304">
Applying POMDPs to Dialog Systems in the Troubleshooting Domain
</title>
<author confidence="0.882487">
Jason D. Williams
</author>
<affiliation confidence="0.706286">
AT&amp;T Labs – Research
</affiliation>
<address confidence="0.930384">
180 Park Ave, Building 103
Florham Park, NJ 07932
</address>
<email confidence="0.997603">
jdw@research.att.com
</email>
<sectionHeader confidence="0.993869" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999840333333333">
This paper reports on progress applying
partially observable Markov decision pro-
cesses (POMDPs) to a commercial dia-
log domain: troubleshooting. In the trou-
bleshooting domain, a spoken dialog sys-
tem helps a user to fix a product such as
a failed DSL connection. Past work has
argued that a POMDP is a principled ap-
proach to building spoken dialog systems
in the simpler slot-filling domain; this pa-
per explains how the POMDPs formula-
tion can be extended to the more complex
troubleshooting domain. Results from di-
alog simulation verify that a POMDP out-
performs a handcrafted baseline.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999924555555556">
In the troubleshooting domain, a spoken dialog sys-
tem (SDS) helps a user to restore a malfunction-
ing product such as a DSL connection to a work-
ing state. Building dialog systems for this domain
presents several new challenges. First, the user may
make mistakes such as misinterpreting the meaning
of a status light or pressing the wrong button, so even
if no speech recognition errors are made, the user’s
response may be misleading. Next, in addition to the
speech recognizer, input is also received from run-
ning network tests such as pinging the user’s DSL
modem. Input from both sources may contain er-
rors, and a dialog system must cope with conflict-
ing information from two channels. In sum, the dia-
log system never knows the true state of the product
nor the user’s true actions, yet must still instruct the
user to successfully restore the product to a working
state.
</bodyText>
<page confidence="0.949106">
1
</page>
<bodyText confidence="0.999950382352941">
Dialog models which explicitly model uncertainty
have been shown to significantly outperform base-
line models which do not, primarily because they
cope better with conflicting evidence introduced by
speech recognition errors (Roy et al., 2000; Zhang
et al., 2001; Williams and Young, 2007). However,
past work has been confined to slot-filling tasks and
has not tackled the troubleshooting domain. Con-
versely, dialog systems for troubleshooting in the
literature have not attempted to model uncertainty
directly (Grosz and Sidner, 1986; Lochbaum, 1998).
The contribution of this paper is to show how
to model a troubleshooting spoken dialog system
as a partially observable Markov decision process
(POMDP). We argue that past work in the gen-
eral troubleshooting literature represents simplifica-
tions or special cases of a POMDP, then we show
how a troubleshooting POMDP can be combined
with a dialog system POMDP to create a unified
framework that admits global optimization. Exper-
iments with simulated users show how the POMDP
formulation effectively balances diagnostic actions
(such as a network test) with communicative ac-
tions (such as giving the user instructions), and how
the POMDP formulation outperforms a hand-crafted
baseline both in terms of efficiency and task comple-
tion.
This paper is organized as follows. Section 2 re-
views POMDPs, the general troubleshooting prob-
lem, and POMDP-based spoken dialog systems;
section 3 explains how these two POMDPs can be
combined to model a troubleshooting spoken dialog
system; sections 4-5 present results from simulation;
and section 6 concludes.
</bodyText>
<sectionHeader confidence="0.982539" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.9899975">
A POMDP is a model for control when there is un-
certainty in the effects of actions and in the state
</bodyText>
<note confidence="0.5194695">
Bridging the Gap: Academic and Industrial Research in Dialog Technologies Workshop Proceedings, pages 1–8,
NAACL-HLT, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999794041666667">
of the environment. Formally, a POMDP q3 is de-
fined as a tuple q3 = (S, A, T, R, ®, Z, -y, b0) where
S is a set of states s describing the environment with
s E S; A is a set of actions a E A which operate
on the environment; T defines a transition proba-
bility P(s0|s, a); R defines the expected (immedi-
ate, real-valued) reward r(s, a) E fit; ® is a set
of observations o E ® which describe the state of
the environment; Z defines an observation proba-
bility P(o0|s0, a); -y is a geometric discount factor
0 &lt; -y &lt; 1; and b0 is an initial belief state, defined
below.
The POMDP operates as follows. At each time-
step, the environment is in some unobserved state
s. Since s is not known exactly, a distribution over
possible states called a belief state b is maintained
where b(s) indicates the probability of being in a
particular state s, with b0 denoting the initial belief
state. Based on b, a control algorithm (also called a
policy) selects an action a, receives a reward r, and
the environment transitions to (unobserved) state s0,
where s0 depends only on s and a. The environment
then generates an observation o0 which is dependent
on s0 and a. At each time-step, b is updated as
</bodyText>
<equation confidence="0.9097645">
�b0(s0) = q · P(o0|s0, a) P(s0|s, a)b(s) (1)
8
</equation>
<bodyText confidence="0.999951090909091">
where q is a normalization constant (Kaelbling et
al., 1998). The process of maintaining b at each
time step is called belief monitoring. The cumula-
tive, infinite-horizon, discounted reward is called the
return and written V = E∞t°0 -ytr(st, at), where st
and at indicate the state of the environment and the
action taken at time t, respectively. The goal of the
control algorithm is to choose actions that maximize
the expected return E[V ] given b and the POMDP
parameters q3, and the process of searching for such
a control algorithm is called optimization.
</bodyText>
<subsectionHeader confidence="0.997831">
2.1 Troubleshooting as a POMDP
</subsectionHeader>
<bodyText confidence="0.998624714285714">
The goal of the general (non-dialog) problem of au-
tomated troubleshooting is for a control algorithm to
fix a product by taking a sequence of diagnosis and
repair actions. Different actions have different relia-
bilities and different costs, and the aim is to find the
sequence that minimizes the total cost. Since the ac-
tions are not completely reliable, the true state of the
</bodyText>
<figureCaption confidence="0.964539166666667">
Figure 1: Influence diagram depiction of automated
troubleshooting. Round nodes represent random
variables, shaded nodes are unobservable and clear
nodes are observable. Arcs show conditional depen-
dence. Squares indicate actions, selected by the pol-
icy. Diamonds indicate real-valued rewards.
</figureCaption>
<bodyText confidence="0.999714666666667">
product can’t be known with certainty: for example,
an instrument may provide a faulty reading.
Formalizing this, a product has some hidden state
x, which is usually decomposed into components
x = (x1, x2, ... , xn). A control algorithm takes
action am, which changes the state of x according
to P(x0|x, am). The product then produces an ob-
servation y according to P(y0|x0, am). Replacing
cost with reward, the control algorithm receives re-
ward r(x, am) and the goal is to find the sequence
of actions which maximizes the cumulative sum of
reward. When viewed in this way, automated trou-
bleshooting can be readily viewed as a POMDP
(Shakeri et al., 1997). Figure 1 shows the automated
troubleshooting task as an influence diagram.
Although POMDPs are an elegant model for trou-
bleshooting, they are also notoriously difficult to
optimize and much of the troubleshooting litera-
ture seeks appropriate constraints which render the
optimization tractable, such as assuming that each
action affects at most one product state compo-
nent, that actions have deterministic effects, and that
there is only fault present (Heckerman et al., 1995).
More recently, advances in the POMDP literature
have radically increased the scalability of optimiza-
tion algorithms: for example, Poupart optimizes a
substantial network troubleshooting problem cast as
a generic POMDP (Poupart and Boutilier, 2004).
Viewing troubleshooting as a generic POMDP in-
creases the scope of admissible troubleshooting
tasks, and as will be discussed in section 3, this view
also allows the uncertainty in the product state to be
explicitly modelled in a spoken dialog system.
</bodyText>
<figure confidence="0.676186666666667">
r
r&apos;
x
x&apos;
am&apos;
Timestep n Timestep n+1
y
am
y&apos;
</figure>
<page confidence="0.98978">
2
</page>
<subsectionHeader confidence="0.987505">
2.2 Spoken dialog as a POMDP
</subsectionHeader>
<bodyText confidence="0.999985827586207">
Past work has argued that POMDPs represent a prin-
cipled approach to modelling (non-troubleshooting)
spoken dialog systems (Roy et al., 2000; Zhang et
al., 2001; Williams and Young, 2007). The intu-
ition is that a user’s goals and actions form the un-
observed state and the (possibly erroneous) ASR
result forms the observation. The SDS-POMDP
model (Williams and Young, 2007) formalizes this
by decomposing the POMDP state variable s into
three components, s = (su, au, d). The component
su gives the user’s goal, such as a complete travel
itinerary in a travel reservation task. The component
au gives the most recent user action (communicative
intent), such as stating a place the user would like to
travel to. Finally the component d records relevant
dialog history, such as the grounding status of a slot.
None of these components is observable directly by
the dialog system and the SDS-POMDP belief state
is formed of a distribution over these components
b(su, au, d). The POMDP action a corresponds to
the dialog system action am, such as asking the user
where they want to go to. Finally, the POMDP ob-
servation o is set to (au, c), where iiu is the hypoth-
esis of the user’s action (communicative intent) pro-
vided by the speech recognition and understanding
process, and c is the confidence score. Figure 2
shows the SDS-POMDP model as an influence di-
agram, and also shows the conditional dependencies
assumed in the SDS-POMDP model.
</bodyText>
<sectionHeader confidence="0.985256" genericHeader="method">
3 Troubleshooting SDS-POMDP model
</sectionHeader>
<bodyText confidence="0.975760733333333">
In this section, we develop a statistical model of a
troubleshooting dialog system. The formulation be-
gins by taking the union of the state spaces of the
dialog POMDP and the troubleshooting POMDP,
(su, au, d, x), and making two modifications. First,
it is assumed that the user’s goal su is known and
constant (i.e., to fix the product), and as such does
not need to be included. Second, the user’s action
au is decomposed into two components: ats u denotes
troubleshooting actions that are directed toward the
product, such as turning a modem on or off, entering
a user name or just observing the status lights; and
acom
u denotes communicative actions to the dialog
system such as saying “green” or “yes”. Reorder-
</bodyText>
<figureCaption confidence="0.980851">
Figure 2: SDS-POMDP model shown as an influ-
ence diagram. The dotted box refers to all of the
(hidden) POMDP state components.
</figureCaption>
<bodyText confidence="0.548945">
ing, the combined POMDP state has components:
</bodyText>
<equation confidence="0.929227">
s = (atsu , x, acom
u , d). (2)
</equation>
<bodyText confidence="0.994488">
Next, the combined observation is formed of the
union of the observations from the dialog and trou-
bleshooting POMDPs:
</bodyText>
<equation confidence="0.9717705">
o = (acom
u , c, y). (3)
</equation>
<bodyText confidence="0.931712705882353">
Finally, since the POMDP may choose only one ac-
tion at each time-step, the POMDP action is simply
am.
Substituting eq. 2 into the POMDP
transition function
0 and am. Further, the user’s communicative
action acom 0 depends only on the most recent user’s
u
troubleshooting action atsu 0, product state x0, dialog
history d and system action am. Finally, the dialog
history component d0 is a function of the previous
dialog history d and the most recent user and dialog
system actions atsu 0, acom
u 0, and am. With these
assumptions, the combined transition function is:
P(ats 0, x0, acom0, d0|ats u , x, acom
u , d, am) ≈
</bodyText>
<construct confidence="0.4313356">
u u
P(atsu 0|x, d, am) · P(x0|x, am, atsu 0)·
P(acom
u 0|d, am, ats u 0, x0)·
P (d0|d, am,
</construct>
<figure confidence="0.942677823529412">
&apos;
am
r
r&apos;
su
su
&apos;
d
d&apos;
c, au ~
Timestep n &apos; &apos; Timestep n+1
au
~
c, au
am
au&apos;
P(s0|s, a) yields
</figure>
<figureCaption confidence="0.350695">
P(ats 0, x0, acom0, d0|ats u , x, acom
</figureCaption>
<bodyText confidence="0.951063111111111">
u , d, am) and is
u u
decomposed as follows. First, it is assumed that
the user’s troubleshooting action atsu 0 depends only
on the system’s action am, the previous product
state x and the dialog history d. Next, it is as-
sumed that the product state x0 depends only on
the previous product state x, and the most recent
user’s and dialog system’s troubleshooting actions
</bodyText>
<figure confidence="0.623460166666667">
ats
u
(4)
ats u 0, x0, acom
u 0)
3
</figure>
<figureCaption confidence="0.976264">
Figure 3: Influence diagram of a troubleshooting
spoken dialog system.
</figureCaption>
<bodyText confidence="0.81369175">
Substituting eq. 3 into the POMDP
observation function P(o0|s0, a) yields
P(�acom
u 0, c0, y0|atsu 0, x0, acom
u 0, d0, am). It is assumed
that the ASR hypothesis Wom
u 0 and confidence score
c0 depend only on the user’s speech in acom
u 0 and
that the result of the troubleshooting test (conducted
by the dialog system) y0 depends only on the state
of the product x0 and the dialog system’s action am:
</bodyText>
<equation confidence="0.98824">
P acom0 C&apos; ats&apos; x&apos; acom0 d&apos; a
(�u , &gt; y u , &gt; ((u , &gt; m) (5)
P(acomu0, c0|acomu0) - P(y|am, x0)
</equation>
<bodyText confidence="0.999567428571429">
An influence diagram of the model is shown in Fig-
ure 3.
At runtime, a belief state (i.e., distribution)
is maintained over the POMDP state variables,
b(atsu , x, acom
u , d). Based on this belief state the pol-
icy chooses an action am and receives observation
</bodyText>
<equation confidence="0.8873655">
(a&amp;quot;com/ 0,
u ,c,
</equation>
<bodyText confidence="0.985491230769231">
ing Eq 1, and the cycle repeats.
(aP The user action models P(atsu0|x, d, am) and
com 0|d, am, ats 0, x0) indicate how users are
u u
likely to respond in troubleshooting dialogs and can
be estimated from annotated dialog data. The prod-
uct models P(x0|x, am, atsu 0) and P(y0|am, x0) in-
dicate how user and dialog system actions change
the state of the product and the reliability of tests,
and these can be estimated by interviewing domain
experts or by examining logs of product perfor-
mance. As in the SDS-POMDP model, the di-
alog history model P(d0|d, am, acom 0, x0, ats0) can
</bodyText>
<subsectionHeader confidence="0.479834">
u u
</subsectionHeader>
<bodyText confidence="0.99933275">
be handcrafted so as to incorporate features from
the dialog history which the dialog designer be-
lieves are important, such as appropriateness or no-
tions of grounding. The ASR confusion model
</bodyText>
<equation confidence="0.862217">
P(a �, c
</equation>
<bodyText confidence="0.998593166666667">
m00|a �om0) can be estimated from speech
recognition data or derived analytically. The re-
ward function can include distinct costs for differ-
ent diagnostic tests, dialog actions, and for success-
ful/unsuccessful task completion. It is not specified
explicitly here since it depends on the application.
</bodyText>
<sectionHeader confidence="0.998662" genericHeader="method">
4 Illustration: DSL-1
</sectionHeader>
<bodyText confidence="0.999904717948718">
To illustrate the general framework, we first created
a very simple troubleshooting spoken dialog system
called DSL-1. Table 1 shows the values for all of
the variables. In DSL-1, the are just 2 possible prob-
lems: no-power and no-network.
The conditional probability tables composing the
model were handcrafted based on conversations
with troubleshooting experts and past experience
with spoken dialog systems. For example, the model
of user’s troubleshooting action assumes that the
user performs the correct action with p = 0.9,
doesn’t understand with p = 0.05, and performs an
incorrect action with p = 0.05. The model of the
user’s communicative action assumes that the user
provides correct (but possibly incomplete) informa-
tion with p = 0.9, and remains silent with p = 0.1.
The model of the product was designed such that
the user’s check-power and check-network actions
are always effective, but if power is restored there
may still be no-network with p = 0.2.
The model of the speech recognition and under-
standing process uses a concept error rate of 30%,
where errors are uniformly distributed, and no con-
fidence scores are used. For example, when the
user expresses the concept all-ok, it will be recog-
nized correctly 70% of the time, and will be mis-
recognized as no-power 5% of the time, as no-
network 5% of the time, etc. The model for y in-
dicates how reliable the ping action is, set with a
parameter perr: for example if perr = 0.1, the result
of a ping test will be incorrect 10% of the time. In
the experiments below, the value of perr is varied to
explore how the POMDP policy trades off between
the ping action and communicative actions.
The reward function provides +100 for taking
the end-call action when the connection is working,
−100 for taking the done action when the connec-
tion isn’t working, and −1 for any communicative
or test action. The dialog continues until the dialog
</bodyText>
<figure confidence="0.960007357142857">
r
r&apos;
x
x&apos;
d d&apos;
am&apos;
am
atsacomats&apos;
u u
au com&apos;
y
c,acom
u
y&apos;
c,aom
u~c
Timestep n Timestep n+1
The belief state is updated by apply-
4
Variable Values
atsu {check-power, check-network, observe, do-nothing, dont-understand}
State x {all-ok, no-power, no-network}
Components d {start, not-done, done}
acom {no-power, no-network, power-ok, all-ok, silent, didnt-understand}
u
Observation ii mom (same set as a xom
Components y {ping-ok, no-response}
Action am {ping, ask-working-ok, req-check-power, req-check-network, end-call}
</figure>
<tableCaption confidence="0.996506">
Table 1: Variable values in the DSL-1 simple troubleshooting example.
</tableCaption>
<bodyText confidence="0.986704">
system takes the done action, at which point the di-
alog is over.
</bodyText>
<sectionHeader confidence="0.699087" genericHeader="method">
4.1 Results
</sectionHeader>
<bodyText confidence="0.999969848484848">
The POMDP was optimized using a standard algo-
rithm from the literature (Spaan and Vlassis, 2005).
This algorithm optimizes the policy at a discrete set
of belief points; as more points are added, the qual-
ity of the resulting policy improves at the expense
of more computation. We found that 300 belief
points achieved asymptotic performance. A model
was constructed for values of perr ranging from 0.0
to 0.5; each model was optimized and then evaluated
using 5000 simulated dialogs.
Results are shown in Figures 4 and 5. In each
figure the x-axis is the accuracy of the ping action:
perr = 0% indicates that the ping action is entirely
reliable and perr = 50% indicates that the ping ac-
tion returns useless noise. In Figure 4, the y-axis
shows average return, and in Figure 5, the solid line
shows the task completion rate and the dotted line
shows the average dialog length. The error bars in-
dicate the 95% confidence interval.
As the error rate for the ping action increases from
0% to 20%, the average dialog length increases from
5.1 turns to 6.5 turns, and the successful task com-
pletion rate falls from 100.0% to 98.9%. These fig-
ures then remain broadly constant from 20% to 50%.
In other words, as errors in the ping action increase,
dialogs become longer and occasionally the system
fails to fix the connection. Inspecting the dialog
transcripts showed that at perr = 0%, the policy
relies on the ping action to judge whether the con-
nection is working. As perr increases, the policy
decreasingly employs the ping diagnostic action in
favor of the ask-working-ok communicative action
until perr = 20%, at which point the ping action is
</bodyText>
<figure confidence="0.95698725">
Average return 94
93
92
91
90
89
88
87
86
85
84
perr (ping error rate)
</figure>
<figureCaption confidence="0.98613">
Figure 4: Error rate of the ping action vs. reward
</figureCaption>
<bodyText confidence="0.992537681818182">
gained per dialog. As the error rate of the ping ac-
tion is increased, performance declines until the er-
ror rate reaches 20%, at which point the system no
longer uses the ping action.
not used at all. At this point the planning process has
determined that the ping action doesn’t help produce
better dialogs than just interacting with the caller,
and the performance from 20% to 50% is constant.1
These experiments confirm that, for a very sim-
ple troubleshooting dialog system in simulation, the
POMDP approach is able to synthesize noisy infor-
mation gained from communicative and test actions
into one unified belief while the underlying, hidden
product state is changing. This is an important re-
sult because past work that has applied POMDPs
to dialog systems has employed a single modality
(communicative actions), and have largely had fixed
persistent state. Even so, this illustration is much
too small to be of practical use, and relies entirely
on hand-crafted models of the dynamics. In the next
section a model of realistic scale is presented with
transition dynamics estimated from real conversa-
</bodyText>
<footnote confidence="0.9964425">
1The variations in performance between 20% and 50% are
due to sampling in the optimization algorithm.
</footnote>
<page confidence="0.968362">
5
</page>
<figure confidence="0.695393625">
Task copmletion rate (%) 99.9% 7 Average dialog length
99.5% 6.6 (turns)
99.1% 6.2
98.7% 5.8
98.3% 5.4
5
p err (ping error rate)
Task completion rate Average dialog length
</figure>
<figureCaption confidence="0.909643">
Figure 5: Error rate of the ping action vs. success-
</figureCaption>
<bodyText confidence="0.9213552">
ful task completion rate and average dialog length.
The left y axis and the solid line show the task com-
pletion rate, and the right y axis and the dotted line
show the average dialog length in number of turns.
tional data.
</bodyText>
<sectionHeader confidence="0.99632" genericHeader="method">
5 Illustration: DSL-2
</sectionHeader>
<bodyText confidence="0.999813512820513">
In this section we present a second POMDP-based
troubleshooting dialog system called DSL-2 which
captures many of the properties of a real-world
DSL troubleshooting task. Approximately 100 tele-
phone calls between (human) DSL support agents
and customers were monitored, and the observations
of these conversations guided creation of the dia-
log system, including typical problems, agent in-
structions, and user responses. The product state X
was decomposed into 19 components which track,
for example, whether there are any outages re-
ported, whether the DSL modem is switched on, and
whether the username has been entered correctly in
the DSL configuration. Seven of these components
can cause the connection to fail: (1) router pow-
ered off or crashed, (2) an upstream network crash,
(3) a service outage, (4-6) a wrong username, pass-
word, or connection type entered in the DSL modem
configuration, and (7) an unknown root cause which
can’t be fixed by the dialog system. Some of the
problems can only be identified or fixed by the dia-
log system (such as a service outage or an upstream
network crash), and the rest only by the user (such as
a router being off or wrong username entered). The
problems may occur in any combination: for exam-
ple, there may be a service outage while the user’s
password is entered incorrectly. The system action
set (Am) consisted of 18 actions such as asking the
user to turn the modem on, providing the correct
username, checking whether any outages have been
reported, and rebooting the upstream network inter-
face. The user’s troubleshooting action set A&amp;quot; � con-
sisted of 12 actions such as turning the modem on
or off, opening the DSL configuration screen, enter-
ing a password, and attempting to surf to a website.
The user’s communicative action set A� m
� consisted
of 11 actions such as saying the color of a light (e.g.,
“red” or “green”), yes and no, back-channel, silence,
and an “out-of-grammar” action which accounts for
user speech which cannot be recognized.
The conditional probability tables for each of the
product components were handcrafted based on in-
terviews with DSL technicians and are almost all
deterministic. For example, if the DSL modem
is powered on, the power light will always be on.
Next a subset of the agent/user telephone calls were
transcribed and annotated with simple dialog acts,
and from these the two user models were estimated.
Smoothing was applied so that the models allow for
the user to take any action at any point in the dia-
log. Concept recognition errors were generated with
p = 0.30, and confidence scores were drawn from
an exponential distribution such that (at an equal er-
ror rate confidence threshold) about half of the con-
cept errors could be identified. The reward func-
tion provides +100 for ending the dialog having cor-
rectly identified (and if possible resolved) the root
causes, −100 for ending the dialog with unidenti-
fied or unresolved root causes, and −1 for any other
action. If a dialog ran for more than 100 turns, it was
considered a failure and terminated.
We created a state-based dialog manager by hand
(called HC) which broadly reflects the agents’ trou-
bleshooting practices and which serves as our base-
line. HC consisted of 19 dialog states, where each
state specified an action am to take (for example to
ask the user to turn the modem on), and observations
from the speech recognizer �a� m
� or troubleshooting
tests y may cause transitions between dialog states.
HC first asks the user to power cycle the modem,
then checks for outages and “resets” the upstream
network interface, then verifies that the username,
password, and network type are configured correctly
on the router. After each step HC checks if the con-
nection is working by asking if the network light
is green, pinging the modem, then asking the user
</bodyText>
<page confidence="0.999001">
6
</page>
<table confidence="0.9993805">
POMDP HC HC(0)
CER 30% 30% 0%
N 500 500 500
TCR 96.1% 78.0% 88.6%
Length 19.9 76.5 48.5
Return 73.3 8.13 48.8
</table>
<tableCaption confidence="0.973838">
Table 2: Results for the POMDP and hand-crafted
</tableCaption>
<bodyText confidence="0.97967775">
dialog managers. CER is concept error rate; TCR is
task completion rate; Length is measured in turns.
to open a web browser; if any one of these tests
fails, troubleshooting resumes, and if they all suc-
ceed then HC ends the dialog. If an outage is de-
tected, HC says this and exits, and if the connection
still isn’t working at the end of the dialog then HC
escalates the call to a (human) technician. In general
when HC receives an unexpected answer or confi-
dence score below the equal-error rate threshold, it
treats this as a likely speech recognition error and
remains in the same dialog state.
Next, optimization was performed as described in
(Williams et al., 2005). This technique takes as in-
put a POMDP model and a state-based dialog con-
troller, and produces an improved dialog controller.
Space limitations prevent a full description here; the
intuition is that the algorithm uses the POMDP be-
lief state at runtime to “rewire” the dialog controller
to achieve an improvement in reward. Because this
optimization algorithm improves a standard state-
based dialog controller (in this case the HC base-
line), it provides an indication of the value of adding
the POMDP machinery.
</bodyText>
<subsectionHeader confidence="0.652297">
5.1 Results and discussion
</subsectionHeader>
<bodyText confidence="0.999992098039216">
First, 500 simulated dialogs were run with the
POMDP, and then 500 simulated dialogs were run
with the HC baseline controller. Finally, as a fur-
ther comparison, the ASR simulation was changed
so that no ASR errors were made, and HC was
run for 500 dialogs in this configuration, which we
call HC(0). Results are shown in Table 2. All of
the observed differences are statistically significant
(p « 0.01).
In the presence of speech recognition errors, the
POMDP produces dialogs which are significantly
shorter and more successful than HC. Moreover, the
POMDP, which faced ASR errors, also outperforms
HC(0), which did not. Examination of the dialog
transcripts found that the main source of failure for
HC(0) was exceeding 100 turns. In other words,
quantitatively, the POMDP is both more robust to
ASR errors and (independent of ASR errors) more
efficient.
The dialog transcripts were inspected to deter-
mine qualitatively how the POMDP attained better
performance. An example is shown in Table 3. At
the start of the conversation, the belief (probability)
that the connection is working p(allOk) is 56% and
the belief that the power to the DSL modem is on
p(pwrOn) is 98.0% (these are 2 of the 19 compo-
nents in the product state x). As the dialog pro-
gresses, belief monitoring updates these to account
for the evidence received. For example, the unsuc-
cessful ping in S1 causes p(allOk) to drop from 56%
to 14%. The belief monitoring process also natu-
rally makes use of indirect evidence – for example,
in U14 the user indicates the network light is “red”:
since the network light will only be on if the power
to the DSL modem is on, this causes an increase in
the belief that the power is on, from 99.1% to 99.8%.
The key benefit of the POMDP approach is that
the dialog manager can exploit the belief state to
make better progress in the face of low-confidence
or even nonsensical replies, without sacrificing over-
all task completion. For example, in S1 through S9
the POMDP policy differs from the baseline con-
troller: the baseline controller would have ignored
the lower-confidence recognitions in U4 and U8, but
the POMDP policy moves ahead. When the policy
receives a nonsensical reply, for example in U6, it
reverts back to an earlier stage of the troubleshoot-
ing procedure it had previously skipped. This latter
behavior ensures that omitting steps to move faster
through the procedure doesn’t ultimately sacrifice
task completion.
</bodyText>
<sectionHeader confidence="0.99981" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999970214285714">
This paper has shown how a spoken dialog system
for troubleshooting can be cast as a POMDP. The
troubleshooting domain has important differences to
past applications of the POMDP approach and the
two illustrations provided in this paper support our
claim that, at least in dialog simulation, the advan-
tages of POMDPs apply to this domain.
After finishing simulation experiments, we in-
stalled DSL-2 into a real dialog system, and found
that belief monitoring runs slower than real-time.
We subsequently developed a method to address
this, which we will report on separately in the fu-
ture, and are now preparing for a pilot study with
real users.
</bodyText>
<sectionHeader confidence="0.999031" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.957326192982456">
BJ Grosz and CL Sidner. 1986. Attention, intentions,
and the structure of discourse. Computational Lin-
guistics, 12(3):175–204.
D Heckerman, JS Breese, and K Rommelse. 1995.
Decision-theoretic troubleshooting. Communications
of the ACM, 38(3):49–57.
L Kaelbling, ML Littman, and AR Cassandra. 1998.
Planning and acting in partially observable stochastic
domains. Artificial Intelligence, 101.
KE Lochbaum. 1998. A collaborative planning model
of intentional structure. Computational Linguistics,
24(4):525–572.
P Poupart and C Boutilier. 2004. VDCBPI: an ap-
proximate scalable algorithm for large scale POMDPs.
In Proc Advances in Neural Information Processing
Systems 17 (NIPS), Vancouver, Canada, pages 1081–
1088.
N Roy, J Pineau, and S Thrun. 2000. Spoken dialog
management for robots. In Proc Association for Com-
putational Linguistics (ACL), Hong Kong.
M Shakeri, KR Pattipati, V Raghavan, A Patterson-Hine,
and DL Iverson. 1997. Multiple fault isolation in
redundant systems. Technical Report NCC2-5123,
NASA Ames.
MTJ Spaan and N Vlassis. 2005. Perseus: randomized
point-based value iteration for POMDPs. Journal of
Artificial Intelligence Research, 24:195–220.
JD Williams and SJ Young. 2007. Partially observable
markov decision processes for spoken dialog systems.
Computer Speech and Language, 21(2):393–422.
JD Williams, P Poupart, and SJ Young. 2005. Partially
observable Markov decision processes with continu-
ous observations for dialogue management. In Proc
SIGdial Workshop on Discourse and Dialogue, Lis-
bon.
B Zhang, Q Cai, J Mao, and B Guo. 2001. Planning
and acting under uncertainty: A new model for spoken
dialogue system. In Proc Conf on Uncertainty in Ar-
tificial Intelligence (UAI), Seattle, Washington, pages
572–579.
ID p(allOk) p(pwrOn) Transcript
*S1 56% 98.0% I’m going to try pinging your DSL modem from here.
S2 - - There was no response so it seems your connection isn’t working yet.
*S3 14% 96.1% Please turn the DSL modem on.
U4 - - ok [ok, 0.004]
*S5 30% 96.4% What color is the network light on the DSL modem?
U6 - - dontunderstand [no, 0.052]
*S7 30% 93.8% Please turn the DSL modem on.
U8 - - dontunderstand [ok, 0.454]
*S9 31% 99.1% I’m going to check if there are any outages reported, just a moment.
S10 - - There are no outages reported.
S11 39% 99.1% I’m going to try resetting your connection from here, just a moment.
S12 - - Ok, that has been done.
S13 48% 99.1% What color is the network light on the DSL modem?
U14 - - red [red, 0.678]
S15 3% 99.8% Please open the DSL configuration screen.
... ... ... ...
</reference>
<tableCaption confidence="0.654743">
Table 3: Fragment of a conversation with the POMDP dialog manager. Asterisks (*) indicate transitions
</tableCaption>
<bodyText confidence="0.98287575">
not in the baseline dialog manager. p(allOk) shows the probability that DSL connectivity is working and
p(pwrOn) shows the probability that the power to the DSL modem is on, according to the POMDP belief
state. The simulated user’s communicative actions are shown in italics, followed by the [concept,
confidence score] produced by the ASR simulation.
</bodyText>
<page confidence="0.996591">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.969852">
<title confidence="0.99986">Applying POMDPs to Dialog Systems in the Troubleshooting Domain</title>
<author confidence="0.999982">Jason D Williams</author>
<affiliation confidence="0.998834">AT&amp;T Labs – Research</affiliation>
<address confidence="0.997039">180 Park Ave, Building 103 Florham Park, NJ 07932</address>
<email confidence="0.999863">jdw@research.att.com</email>
<abstract confidence="0.998492875">This paper reports on progress applying partially observable Markov decision processes (POMDPs) to a commercial dialog domain: troubleshooting. In the troubleshooting domain, a spoken dialog system helps a user to fix a product such as a failed DSL connection. Past work has argued that a POMDP is a principled approach to building spoken dialog systems in the simpler slot-filling domain; this paper explains how the POMDPs formulation can be extended to the more complex troubleshooting domain. Results from dialog simulation verify that a POMDP outperforms a handcrafted baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>BJ Grosz</author>
<author>CL Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="2192" citStr="Grosz and Sidner, 1986" startWordPosition="354" endWordPosition="357"> must still instruct the user to successfully restore the product to a working state. 1 Dialog models which explicitly model uncertainty have been shown to significantly outperform baseline models which do not, primarily because they cope better with conflicting evidence introduced by speech recognition errors (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007). However, past work has been confined to slot-filling tasks and has not tackled the troubleshooting domain. Conversely, dialog systems for troubleshooting in the literature have not attempted to model uncertainty directly (Grosz and Sidner, 1986; Lochbaum, 1998). The contribution of this paper is to show how to model a troubleshooting spoken dialog system as a partially observable Markov decision process (POMDP). We argue that past work in the general troubleshooting literature represents simplifications or special cases of a POMDP, then we show how a troubleshooting POMDP can be combined with a dialog system POMDP to create a unified framework that admits global optimization. Experiments with simulated users show how the POMDP formulation effectively balances diagnostic actions (such as a network test) with communicative actions (su</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>BJ Grosz and CL Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Heckerman</author>
<author>JS Breese</author>
<author>K Rommelse</author>
</authors>
<title>Decision-theoretic troubleshooting.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>3</issue>
<contexts>
<context position="7190" citStr="Heckerman et al., 1995" startWordPosition="1189" endWordPosition="1192">aximizes the cumulative sum of reward. When viewed in this way, automated troubleshooting can be readily viewed as a POMDP (Shakeri et al., 1997). Figure 1 shows the automated troubleshooting task as an influence diagram. Although POMDPs are an elegant model for troubleshooting, they are also notoriously difficult to optimize and much of the troubleshooting literature seeks appropriate constraints which render the optimization tractable, such as assuming that each action affects at most one product state component, that actions have deterministic effects, and that there is only fault present (Heckerman et al., 1995). More recently, advances in the POMDP literature have radically increased the scalability of optimization algorithms: for example, Poupart optimizes a substantial network troubleshooting problem cast as a generic POMDP (Poupart and Boutilier, 2004). Viewing troubleshooting as a generic POMDP increases the scope of admissible troubleshooting tasks, and as will be discussed in section 3, this view also allows the uncertainty in the product state to be explicitly modelled in a spoken dialog system. r r&apos; x x&apos; am&apos; Timestep n Timestep n+1 y am y&apos; 2 2.2 Spoken dialog as a POMDP Past work has argued </context>
</contexts>
<marker>Heckerman, Breese, Rommelse, 1995</marker>
<rawString>D Heckerman, JS Breese, and K Rommelse. 1995. Decision-theoretic troubleshooting. Communications of the ACM, 38(3):49–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kaelbling</author>
<author>ML Littman</author>
<author>AR Cassandra</author>
</authors>
<title>Planning and acting in partially observable stochastic domains.</title>
<date>1998</date>
<journal>Artificial Intelligence,</journal>
<volume>101</volume>
<contexts>
<context position="4857" citStr="Kaelbling et al., 1998" startWordPosition="811" endWordPosition="814"> is not known exactly, a distribution over possible states called a belief state b is maintained where b(s) indicates the probability of being in a particular state s, with b0 denoting the initial belief state. Based on b, a control algorithm (also called a policy) selects an action a, receives a reward r, and the environment transitions to (unobserved) state s0, where s0 depends only on s and a. The environment then generates an observation o0 which is dependent on s0 and a. At each time-step, b is updated as �b0(s0) = q · P(o0|s0, a) P(s0|s, a)b(s) (1) 8 where q is a normalization constant (Kaelbling et al., 1998). The process of maintaining b at each time step is called belief monitoring. The cumulative, infinite-horizon, discounted reward is called the return and written V = E∞t°0 -ytr(st, at), where st and at indicate the state of the environment and the action taken at time t, respectively. The goal of the control algorithm is to choose actions that maximize the expected return E[V ] given b and the POMDP parameters q3, and the process of searching for such a control algorithm is called optimization. 2.1 Troubleshooting as a POMDP The goal of the general (non-dialog) problem of automated troublesho</context>
</contexts>
<marker>Kaelbling, Littman, Cassandra, 1998</marker>
<rawString>L Kaelbling, ML Littman, and AR Cassandra. 1998. Planning and acting in partially observable stochastic domains. Artificial Intelligence, 101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>KE Lochbaum</author>
</authors>
<title>A collaborative planning model of intentional structure.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="2209" citStr="Lochbaum, 1998" startWordPosition="358" endWordPosition="359"> user to successfully restore the product to a working state. 1 Dialog models which explicitly model uncertainty have been shown to significantly outperform baseline models which do not, primarily because they cope better with conflicting evidence introduced by speech recognition errors (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007). However, past work has been confined to slot-filling tasks and has not tackled the troubleshooting domain. Conversely, dialog systems for troubleshooting in the literature have not attempted to model uncertainty directly (Grosz and Sidner, 1986; Lochbaum, 1998). The contribution of this paper is to show how to model a troubleshooting spoken dialog system as a partially observable Markov decision process (POMDP). We argue that past work in the general troubleshooting literature represents simplifications or special cases of a POMDP, then we show how a troubleshooting POMDP can be combined with a dialog system POMDP to create a unified framework that admits global optimization. Experiments with simulated users show how the POMDP formulation effectively balances diagnostic actions (such as a network test) with communicative actions (such as giving the </context>
</contexts>
<marker>Lochbaum, 1998</marker>
<rawString>KE Lochbaum. 1998. A collaborative planning model of intentional structure. Computational Linguistics, 24(4):525–572.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Poupart</author>
<author>C Boutilier</author>
</authors>
<title>VDCBPI: an approximate scalable algorithm for large scale POMDPs.</title>
<date>2004</date>
<booktitle>In Proc Advances in Neural Information Processing Systems 17 (NIPS),</booktitle>
<pages>1081--1088</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="7439" citStr="Poupart and Boutilier, 2004" startWordPosition="1223" endWordPosition="1226"> elegant model for troubleshooting, they are also notoriously difficult to optimize and much of the troubleshooting literature seeks appropriate constraints which render the optimization tractable, such as assuming that each action affects at most one product state component, that actions have deterministic effects, and that there is only fault present (Heckerman et al., 1995). More recently, advances in the POMDP literature have radically increased the scalability of optimization algorithms: for example, Poupart optimizes a substantial network troubleshooting problem cast as a generic POMDP (Poupart and Boutilier, 2004). Viewing troubleshooting as a generic POMDP increases the scope of admissible troubleshooting tasks, and as will be discussed in section 3, this view also allows the uncertainty in the product state to be explicitly modelled in a spoken dialog system. r r&apos; x x&apos; am&apos; Timestep n Timestep n+1 y am y&apos; 2 2.2 Spoken dialog as a POMDP Past work has argued that POMDPs represent a principled approach to modelling (non-troubleshooting) spoken dialog systems (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007). The intuition is that a user’s goals and actions form the unobserved state and the</context>
</contexts>
<marker>Poupart, Boutilier, 2004</marker>
<rawString>P Poupart and C Boutilier. 2004. VDCBPI: an approximate scalable algorithm for large scale POMDPs. In Proc Advances in Neural Information Processing Systems 17 (NIPS), Vancouver, Canada, pages 1081– 1088.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Roy</author>
<author>J Pineau</author>
<author>S Thrun</author>
</authors>
<title>Spoken dialog management for robots.</title>
<date>2000</date>
<booktitle>In Proc Association for Computational Linguistics (ACL), Hong Kong.</booktitle>
<contexts>
<context position="1899" citStr="Roy et al., 2000" startWordPosition="310" endWordPosition="313">from running network tests such as pinging the user’s DSL modem. Input from both sources may contain errors, and a dialog system must cope with conflicting information from two channels. In sum, the dialog system never knows the true state of the product nor the user’s true actions, yet must still instruct the user to successfully restore the product to a working state. 1 Dialog models which explicitly model uncertainty have been shown to significantly outperform baseline models which do not, primarily because they cope better with conflicting evidence introduced by speech recognition errors (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007). However, past work has been confined to slot-filling tasks and has not tackled the troubleshooting domain. Conversely, dialog systems for troubleshooting in the literature have not attempted to model uncertainty directly (Grosz and Sidner, 1986; Lochbaum, 1998). The contribution of this paper is to show how to model a troubleshooting spoken dialog system as a partially observable Markov decision process (POMDP). We argue that past work in the general troubleshooting literature represents simplifications or special cases of a POMDP, then we show </context>
<context position="7908" citStr="Roy et al., 2000" startWordPosition="1304" endWordPosition="1307">tion algorithms: for example, Poupart optimizes a substantial network troubleshooting problem cast as a generic POMDP (Poupart and Boutilier, 2004). Viewing troubleshooting as a generic POMDP increases the scope of admissible troubleshooting tasks, and as will be discussed in section 3, this view also allows the uncertainty in the product state to be explicitly modelled in a spoken dialog system. r r&apos; x x&apos; am&apos; Timestep n Timestep n+1 y am y&apos; 2 2.2 Spoken dialog as a POMDP Past work has argued that POMDPs represent a principled approach to modelling (non-troubleshooting) spoken dialog systems (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007). The intuition is that a user’s goals and actions form the unobserved state and the (possibly erroneous) ASR result forms the observation. The SDS-POMDP model (Williams and Young, 2007) formalizes this by decomposing the POMDP state variable s into three components, s = (su, au, d). The component su gives the user’s goal, such as a complete travel itinerary in a travel reservation task. The component au gives the most recent user action (communicative intent), such as stating a place the user would like to travel to. Finally the component d recor</context>
</contexts>
<marker>Roy, Pineau, Thrun, 2000</marker>
<rawString>N Roy, J Pineau, and S Thrun. 2000. Spoken dialog management for robots. In Proc Association for Computational Linguistics (ACL), Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Shakeri</author>
<author>KR Pattipati</author>
<author>V Raghavan</author>
<author>A Patterson-Hine</author>
<author>DL Iverson</author>
</authors>
<title>Multiple fault isolation in redundant systems.</title>
<date>1997</date>
<tech>Technical Report NCC2-5123,</tech>
<location>NASA Ames.</location>
<contexts>
<context position="6712" citStr="Shakeri et al., 1997" startWordPosition="1117" endWordPosition="1120">inty: for example, an instrument may provide a faulty reading. Formalizing this, a product has some hidden state x, which is usually decomposed into components x = (x1, x2, ... , xn). A control algorithm takes action am, which changes the state of x according to P(x0|x, am). The product then produces an observation y according to P(y0|x0, am). Replacing cost with reward, the control algorithm receives reward r(x, am) and the goal is to find the sequence of actions which maximizes the cumulative sum of reward. When viewed in this way, automated troubleshooting can be readily viewed as a POMDP (Shakeri et al., 1997). Figure 1 shows the automated troubleshooting task as an influence diagram. Although POMDPs are an elegant model for troubleshooting, they are also notoriously difficult to optimize and much of the troubleshooting literature seeks appropriate constraints which render the optimization tractable, such as assuming that each action affects at most one product state component, that actions have deterministic effects, and that there is only fault present (Heckerman et al., 1995). More recently, advances in the POMDP literature have radically increased the scalability of optimization algorithms: for</context>
</contexts>
<marker>Shakeri, Pattipati, Raghavan, Patterson-Hine, Iverson, 1997</marker>
<rawString>M Shakeri, KR Pattipati, V Raghavan, A Patterson-Hine, and DL Iverson. 1997. Multiple fault isolation in redundant systems. Technical Report NCC2-5123, NASA Ames.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MTJ Spaan</author>
<author>N Vlassis</author>
</authors>
<title>Perseus: randomized point-based value iteration for POMDPs.</title>
<date>2005</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>24--195</pages>
<contexts>
<context position="16175" citStr="Spaan and Vlassis, 2005" startWordPosition="2764" endWordPosition="2767">alues atsu {check-power, check-network, observe, do-nothing, dont-understand} State x {all-ok, no-power, no-network} Components d {start, not-done, done} acom {no-power, no-network, power-ok, all-ok, silent, didnt-understand} u Observation ii mom (same set as a xom Components y {ping-ok, no-response} Action am {ping, ask-working-ok, req-check-power, req-check-network, end-call} Table 1: Variable values in the DSL-1 simple troubleshooting example. system takes the done action, at which point the dialog is over. 4.1 Results The POMDP was optimized using a standard algorithm from the literature (Spaan and Vlassis, 2005). This algorithm optimizes the policy at a discrete set of belief points; as more points are added, the quality of the resulting policy improves at the expense of more computation. We found that 300 belief points achieved asymptotic performance. A model was constructed for values of perr ranging from 0.0 to 0.5; each model was optimized and then evaluated using 5000 simulated dialogs. Results are shown in Figures 4 and 5. In each figure the x-axis is the accuracy of the ping action: perr = 0% indicates that the ping action is entirely reliable and perr = 50% indicates that the ping action retu</context>
</contexts>
<marker>Spaan, Vlassis, 2005</marker>
<rawString>MTJ Spaan and N Vlassis. 2005. Perseus: randomized point-based value iteration for POMDPs. Journal of Artificial Intelligence Research, 24:195–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JD Williams</author>
<author>SJ Young</author>
</authors>
<title>Partially observable markov decision processes for spoken dialog systems.</title>
<date>2007</date>
<journal>Computer Speech and Language,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="1946" citStr="Williams and Young, 2007" startWordPosition="318" endWordPosition="321">ging the user’s DSL modem. Input from both sources may contain errors, and a dialog system must cope with conflicting information from two channels. In sum, the dialog system never knows the true state of the product nor the user’s true actions, yet must still instruct the user to successfully restore the product to a working state. 1 Dialog models which explicitly model uncertainty have been shown to significantly outperform baseline models which do not, primarily because they cope better with conflicting evidence introduced by speech recognition errors (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007). However, past work has been confined to slot-filling tasks and has not tackled the troubleshooting domain. Conversely, dialog systems for troubleshooting in the literature have not attempted to model uncertainty directly (Grosz and Sidner, 1986; Lochbaum, 1998). The contribution of this paper is to show how to model a troubleshooting spoken dialog system as a partially observable Markov decision process (POMDP). We argue that past work in the general troubleshooting literature represents simplifications or special cases of a POMDP, then we show how a troubleshooting POMDP can be combined wit</context>
<context position="7955" citStr="Williams and Young, 2007" startWordPosition="1312" endWordPosition="1315">optimizes a substantial network troubleshooting problem cast as a generic POMDP (Poupart and Boutilier, 2004). Viewing troubleshooting as a generic POMDP increases the scope of admissible troubleshooting tasks, and as will be discussed in section 3, this view also allows the uncertainty in the product state to be explicitly modelled in a spoken dialog system. r r&apos; x x&apos; am&apos; Timestep n Timestep n+1 y am y&apos; 2 2.2 Spoken dialog as a POMDP Past work has argued that POMDPs represent a principled approach to modelling (non-troubleshooting) spoken dialog systems (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007). The intuition is that a user’s goals and actions form the unobserved state and the (possibly erroneous) ASR result forms the observation. The SDS-POMDP model (Williams and Young, 2007) formalizes this by decomposing the POMDP state variable s into three components, s = (su, au, d). The component su gives the user’s goal, such as a complete travel itinerary in a travel reservation task. The component au gives the most recent user action (communicative intent), such as stating a place the user would like to travel to. Finally the component d records relevant dialog history, such as the groundi</context>
</contexts>
<marker>Williams, Young, 2007</marker>
<rawString>JD Williams and SJ Young. 2007. Partially observable markov decision processes for spoken dialog systems. Computer Speech and Language, 21(2):393–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JD Williams</author>
<author>P Poupart</author>
<author>SJ Young</author>
</authors>
<title>Partially observable Markov decision processes with continuous observations for dialogue management.</title>
<date>2005</date>
<booktitle>In Proc SIGdial Workshop on Discourse and Dialogue,</booktitle>
<location>Lisbon.</location>
<contexts>
<context position="24170" citStr="Williams et al., 2005" startWordPosition="4141" endWordPosition="4144">is task completion rate; Length is measured in turns. to open a web browser; if any one of these tests fails, troubleshooting resumes, and if they all succeed then HC ends the dialog. If an outage is detected, HC says this and exits, and if the connection still isn’t working at the end of the dialog then HC escalates the call to a (human) technician. In general when HC receives an unexpected answer or confidence score below the equal-error rate threshold, it treats this as a likely speech recognition error and remains in the same dialog state. Next, optimization was performed as described in (Williams et al., 2005). This technique takes as input a POMDP model and a state-based dialog controller, and produces an improved dialog controller. Space limitations prevent a full description here; the intuition is that the algorithm uses the POMDP belief state at runtime to “rewire” the dialog controller to achieve an improvement in reward. Because this optimization algorithm improves a standard statebased dialog controller (in this case the HC baseline), it provides an indication of the value of adding the POMDP machinery. 5.1 Results and discussion First, 500 simulated dialogs were run with the POMDP, and then</context>
</contexts>
<marker>Williams, Poupart, Young, 2005</marker>
<rawString>JD Williams, P Poupart, and SJ Young. 2005. Partially observable Markov decision processes with continuous observations for dialogue management. In Proc SIGdial Workshop on Discourse and Dialogue, Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Zhang</author>
<author>Q Cai</author>
<author>J Mao</author>
<author>B Guo</author>
</authors>
<title>Planning and acting under uncertainty: A new model for spoken dialogue system.</title>
<date>2001</date>
<booktitle>In Proc Conf on Uncertainty in Artificial Intelligence (UAI),</booktitle>
<pages>572--579</pages>
<location>Seattle, Washington,</location>
<contexts>
<context position="1919" citStr="Zhang et al., 2001" startWordPosition="314" endWordPosition="317">rk tests such as pinging the user’s DSL modem. Input from both sources may contain errors, and a dialog system must cope with conflicting information from two channels. In sum, the dialog system never knows the true state of the product nor the user’s true actions, yet must still instruct the user to successfully restore the product to a working state. 1 Dialog models which explicitly model uncertainty have been shown to significantly outperform baseline models which do not, primarily because they cope better with conflicting evidence introduced by speech recognition errors (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007). However, past work has been confined to slot-filling tasks and has not tackled the troubleshooting domain. Conversely, dialog systems for troubleshooting in the literature have not attempted to model uncertainty directly (Grosz and Sidner, 1986; Lochbaum, 1998). The contribution of this paper is to show how to model a troubleshooting spoken dialog system as a partially observable Markov decision process (POMDP). We argue that past work in the general troubleshooting literature represents simplifications or special cases of a POMDP, then we show how a troubleshootin</context>
<context position="7928" citStr="Zhang et al., 2001" startWordPosition="1308" endWordPosition="1311">or example, Poupart optimizes a substantial network troubleshooting problem cast as a generic POMDP (Poupart and Boutilier, 2004). Viewing troubleshooting as a generic POMDP increases the scope of admissible troubleshooting tasks, and as will be discussed in section 3, this view also allows the uncertainty in the product state to be explicitly modelled in a spoken dialog system. r r&apos; x x&apos; am&apos; Timestep n Timestep n+1 y am y&apos; 2 2.2 Spoken dialog as a POMDP Past work has argued that POMDPs represent a principled approach to modelling (non-troubleshooting) spoken dialog systems (Roy et al., 2000; Zhang et al., 2001; Williams and Young, 2007). The intuition is that a user’s goals and actions form the unobserved state and the (possibly erroneous) ASR result forms the observation. The SDS-POMDP model (Williams and Young, 2007) formalizes this by decomposing the POMDP state variable s into three components, s = (su, au, d). The component su gives the user’s goal, such as a complete travel itinerary in a travel reservation task. The component au gives the most recent user action (communicative intent), such as stating a place the user would like to travel to. Finally the component d records relevant dialog h</context>
</contexts>
<marker>Zhang, Cai, Mao, Guo, 2001</marker>
<rawString>B Zhang, Q Cai, J Mao, and B Guo. 2001. Planning and acting under uncertainty: A new model for spoken dialogue system. In Proc Conf on Uncertainty in Artificial Intelligence (UAI), Seattle, Washington, pages 572–579.</rawString>
</citation>
<citation valid="false">
<title>ID p(allOk) p(pwrOn) Transcript *S1 56% 98.0% I’m going to try pinging your DSL modem from here. S2 - - There was no response so it seems your connection isn’t working yet. *S3 14% 96.1% Please turn the DSL modem on. U4 - - ok [ok, 0.004] *S5 30% 96.4% What color is the network light on the DSL modem? U6 - - dontunderstand [no, 0.052] *S7 30% 93.8% Please turn the DSL modem on. U8 - - dontunderstand [ok, 0.454] *S9 31% 99.1% I’m going to check if there are any outages reported, just a moment. S10 - - There are no outages reported. S11 39% 99.1% I’m going to try resetting your connection from here, just a moment. S12 - - Ok, that has been done. S13 48% 99.1% What color is the network light on the DSL modem? U14 - - red [red,</title>
<booktitle>0.678] S15 3% 99.8% Please open the DSL configuration</booktitle>
<marker></marker>
<rawString>ID p(allOk) p(pwrOn) Transcript *S1 56% 98.0% I’m going to try pinging your DSL modem from here. S2 - - There was no response so it seems your connection isn’t working yet. *S3 14% 96.1% Please turn the DSL modem on. U4 - - ok [ok, 0.004] *S5 30% 96.4% What color is the network light on the DSL modem? U6 - - dontunderstand [no, 0.052] *S7 30% 93.8% Please turn the DSL modem on. U8 - - dontunderstand [ok, 0.454] *S9 31% 99.1% I’m going to check if there are any outages reported, just a moment. S10 - - There are no outages reported. S11 39% 99.1% I’m going to try resetting your connection from here, just a moment. S12 - - Ok, that has been done. S13 48% 99.1% What color is the network light on the DSL modem? U14 - - red [red, 0.678] S15 3% 99.8% Please open the DSL configuration screen. ... ... ... ...</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>