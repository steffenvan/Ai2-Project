<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.991338">
Dialogue Helpsystem based on Flexible Matching of
User Query with Natural Language Knowledge Base
</title>
<author confidence="0.986357">
Sadao Kurohashi and Wataru Higasa
</author>
<affiliation confidence="0.9876355">
Graduate School of Informatics
Kyoto University
</affiliation>
<address confidence="0.86547">
Yoshida-honmachi, Sakyo, Kyoto, 606-8501 Japan
</address>
<email confidence="0.998528">
kuro@i.kyoto-u.ac.jp, higasa@pine.kuee.kyoto-u.ac.jp
</email>
<sectionHeader confidence="0.994791" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998934">
This paper describes a dialog help-
system which advises users in us-
ing computer facilities and software
applications provided by the Cen-
ter for Information and Multime-
dia Studies, Kyoto University. The
system employs a knowledge base
written in natural language and re-
trieves a proper knowledge unit by
flexible matching of user query with
the knowledge base. The system
is running since July 1999, received
about 2,000 queries for the first
seven months, and answered about
40% of them satisfactory.
</bodyText>
<sectionHeader confidence="0.99878" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979366666667">
One of the ultimate goals of Natural Lan-
guage Processing is to realize a dialogue sys-
tem which can communicate with human be-
ings in a natural way (Wilks, 1999). How-
ever, no effective real world dialogue applica-
tion exists so far, not only in spoken language
for which speech recognition is still a big ob-
stacle, but also in typing language.
The most serious problem is knowledge. It
is obvious that without sufficient knowledge a
dialogue system cannot talk with people sat-
isfactorily. Classical dialogue systems like UC
(Wilensky et al., 1984) utilized a formal lan-
guage to represent knowledge, which requires
the heavy cost of construction and mainte-
nance and makes the scaling up quite difficult.
In contrast, along with the improvement
of NLP, research activities which utilize nat-
ural language text as a knowledge base be-
come popular, such as START (Katz, 1990),
FAQ Finder (Cooper, 1996), and QA Track
in TREC 8 (NIST and DARPA, 2000). These
systems, however, basically produce one time
response, and do not have a conversation with
users.
This paper proposes a dialogue helpsystem
in which natural language knowledge base is
not only used for one time response, but also
for conducting a conversation. To put it con-
cretely, the system can
</bodyText>
<listItem confidence="0.998019666666667">
• ask the user back if there is an unknown
word in the user utterance,
• interpret the user utterance contextually,
and
• ask the user back when the user utter-
ance is not clear.
</listItem>
<bodyText confidence="0.999950611111111">
In order to achieve these functions, a mild
restriction is imposed on the knowledge base;
it is compiled in a dictionary-like structure
(entry and its description) and the descrip-
tion is written in an if-then format (though
several expressions can be used to show if-
then relation).
The dialogue helpsystem reported in this
paper advises faculties and students in us-
ing the computer facilities and software ap-
plications of a university. The computer
facilities of Kyoto University, about 1,200
computers (PCs and WSs) in several rooms
and modem connections are administrated
by the Center for Information and Multime-
dia Studies (CIMS; http://www.media.kyoto-
u.ac.jp/). The situation at CIMS is that
many people are using computers, teaching
</bodyText>
<page confidence="0.997235">
141
</page>
<bodyText confidence="0.999716222222222">
assistants (TAs) help the users, but are not al-
ways available, and certain fundamental ques-
tions are asked frequently. Considering this,
we assumed that it is a very promising domain
for an experimental dialogue system.
The system started its service on July 1999,
received about 2,000 queries for the first seven
months, and answered about 40% of them sat-
isfactorily.
</bodyText>
<sectionHeader confidence="0.995433" genericHeader="introduction">
2 Examples
</sectionHeader>
<bodyText confidence="0.859844954545455">
The following examples (real logs of the ser-
vice) are illustrative of the breadth of dia-
logues in which the system aims to partic-
ipate. The system is capable of generating
the answers shown below in response to most
forms of the request users might supply&apos;.
&lt;1999 Jul 08 19:31:49&gt;
Ul: Method to invoke a screen save in
UNIX?
Si: What is &amp;quot;screen save&amp;quot;?
U2: screen saver.
S2: Type &amp;quot;-xlock&amp;quot; in the command line.
&lt;1999 Aug 19 21:20:52&gt;
Ul: Please tell me how can 1 read emails in
Emacs.
Si: Select mail software from &amp;quot;mh-e&amp;quot;,
&amp;quot;mew&amp;quot;.
U2: I try mh-e.
S2: Type &amp;quot;M-x mh-rmail&amp;quot; on Emacs. Type
&amp;quot;1&amp;quot; to get unread emails and type &amp;quot;.&amp;quot;
after you move the cursor on the line
you want to read.
</bodyText>
<equation confidence="0.4676525">
&lt;1999 Sep 16 22:32:20&gt;
Ul: How can I use Mew in UNIX?
</equation>
<bodyText confidence="0.8933521">
Si: After invoking Emacs, type &amp;quot;M-x
mew&amp;quot;. See http://w-ww.mew.org/ for
details.
U2: How can I delete emails?
S2: Type &amp;quot;d&amp;quot; in the Summary Mode and
then type &amp;quot;x&amp;quot; for execution.
&apos;Although our system is a Japanese dialogue sys-
tem, in this paper we use their English translations
for the explanation.
&lt;1999 Oct 25 12:42:28&gt;
Ul: Tell me how to use Netscape.
Si: On the [Start Menu], click [program]
and then click [Netscape Navigator].
U2: What&apos;s start menu?
S2: [Start Menu] is a pull-down menu sum-
marizing Windows applications, which
appears when you click [Start] icon on
the left bottom of the desktop screen.
U3: What is click?
S3: I cannot explain &amp;quot;click&amp;quot; in detail.
</bodyText>
<sectionHeader confidence="0.793296" genericHeader="method">
3 Types of user utterances
</sectionHeader>
<bodyText confidence="0.994926">
We observed the conversations of users and
TAs in the CIMS computer rooms by record-
ing and transcription (20 hours observation;
1.5 hours recording).
From this study, we discovered that user
utterances can be classified as follows:
</bodyText>
<listItem confidence="0.6714726">
What type: The user asks some fact.
ex. What is Emacs?
Ex-plain Emacs.
How type: The user asks how to do some-
thing.
</listItem>
<bodyText confidence="0.835435823529412">
ex. How can I input Japanese characters
in Emacs?
I want to input Japanese characters
in Emacs.
Symptom type: The user shows some
symptom since he/she want to know
how to cope with it.
ex. I cannot access my private folder.
The screen is white.
Request type: The user requests something
to CIMS.
ex. Please install Visual-C.
Please make my disk quota bigger.
Addition type: The user adds or modifies
the previous question.
ex. How about WindowsNT?
In the case of reply?
</bodyText>
<page confidence="0.990692">
142
</page>
<figure confidence="0.993101">
User
Input: How can I send emails by Mew?
User Interface
(WWW browser)
Email Sender
Knowledge
Base
&lt;TITLE&gt;Mew&lt;IIITLE&gt;
&lt;SYN&gt;mew, MEW, MIYUUSYN&gt;
&lt;BT&gt;Mail software&lt;/BT&gt;
&lt;DEF&gt;A kind of mail software working on Emacs ./DEF&gt;
&lt;DESCRIPTION&gt;
•-•&lt;KU&gt;In order to invoke Mew,
type &amp;quot;M-x mew&amp;quot; on Emacs.&lt;/KU&gt;
%%certainty score.. &lt;KU4If you want to send emails by Mew on EmI
..
.............type 7C4-
c-c&apos; when you finish writing a maiik&apos;KU&gt;
. •••&lt;KU&gt;If you want to receive emails by Mew on Emacs,
type &amp;quot;i&amp;quot;.&lt;/KU&gt;
•••&lt;KU&gt;If you want to reply emails by Mew on Emacs,
&lt;/KU&gt;
&lt;/DESCRIPTION&gt;
........
Input Analyzer
(KNP)
Type &amp;quot;C-cC-c&amp;quot; when you
a
,
emails 4&amp;quot;
Isend
Utterance content Utterance type
Flexible Mathing
--------
The best
•••• ......
&lt;TITLE&gt;Mh-e&lt;/TITLE&gt;
&lt;SYN&gt;rnh-e&lt;/SYN&gt;
&lt;BT&gt;Mail software&lt;/BT&gt;
</figure>
<figureCaption confidence="0.999998">
Figure 1: The outline of the helpsystem.
</figureCaption>
<bodyText confidence="0.969055222222222">
Answer type: The user answers the system
question.
ex. WINDOWS.
The compression type is zip.
The helpsystem reported in the paper an-
swers what, how and symptom questions. In
addition, it can interpret addition and answer
utterances contextually. The request utter-
ances are out of the system scope currently.
</bodyText>
<sectionHeader confidence="0.974669" genericHeader="method">
4 Outline of the helpsystem
</sectionHeader>
<bodyText confidence="0.998872782608696">
The system is comprised of the following com-
ponents (Figure 1):
User Interface: Users access to the helpsys-
tern via a WWW browser by using CGI
based HTML forms. The helpsystem is
actually running on a workstation in our
lab.
Input Analyzer: The user utterance is
transformed into a dependency structure
by a robust parser, KNP (Kurohashi
and Nagao, 1994; Kurohashi and Na-
gao, 1998), and utterance-pattern rules
are applied to extract the utterance type
and the utterance content.
Japanese is head-final and the final ex-
pression shows an utterance type. There-
fore, the longest matching of utterance-
pattern rules form the end of the utter-
ance can detect the utterance type in
most cases. For example, if the final ex-
pression is &amp;quot;niha doushitara ii desu ka
(How can I -)&amp;quot;, how type is assigned; if
&amp;quot;no baai ha (In case - -)&amp;quot;, addition type.
</bodyText>
<page confidence="0.995149">
143
</page>
<bodyText confidence="0.99790380952381">
Knowledge base: The knowledge base is
written in a natural language, in a
dictionary-like structure.
Dialogue Manager: The core process of
the dialogue manager is to match the
user utterance with the knowledge base
in order to find the most appropriate de-
scription. It also handles contextual in-
terpretation of the user utterance and
question to the user.
Email Sender: The user can send his/her
input-log to the CIMS staff via email if
the automatic response is not satisfac-
tory. So, the user does not have to in-
put his questions a second time. This
option surely contributes to the popular-
ity of the system.
In the following sections, we discuss the
knowledge base and the dialogue manager,
since we consider these components as the
core of the system.
</bodyText>
<sectionHeader confidence="0.960976" genericHeader="method">
5 Knowledge base
</sectionHeader>
<subsectionHeader confidence="0.998605">
5.1 The outline
</subsectionHeader>
<bodyText confidence="0.999812793103449">
The knowledge base has a dictionary-like
structure, in which each entry describes a
concept/issue in the domain. It was com-
piled manually by referring to the real QAs in
CIMS rooms, the FAQ page of CIMS (about
100 items), and question emails sent to CIMS
(about 150 emails). Currently, it contains
about 250 entries.
Each entry consists of a headword
(&lt;TITLE&gt; t ag) , synonyms ( &lt;sYN&gt; tag),
an upper word (&lt;BT&gt; tag), a definition
of the headword (&lt;DEF&gt; tag) and sev-
eral descriptions concerning the headword
(&lt;DESCRLPTION&gt; tag; see Figure 1). All
content words in the knowledge base were
registered to the system database, which is
used to see whether a user input word is
known or unknown to the system (Section
6.1).
In addition, by collecting the headword
and its upper word pairs from the knowl-
edge base, the domain ontology (concept tax-
onomy) is constructed automatically. The
top categories of the current ontology are
software, hardware, computer term (different
to soft/hardware), action term, and general
term. The domain ontology is used by the di-
alogue manager in several ways (Section 6.2,
6.3).
</bodyText>
<subsectionHeader confidence="0.997912">
5.2 Natural language representation
</subsectionHeader>
<bodyText confidence="0.985602727272727">
In the knowledge base, the definition and sev-
eral descriptions for the headword are written
in natural language, which provides both high
power of expression and high extensibility.
The definition of the headword is used for
what questions; the descriptions are used for
how and symptom questions. Each descrip-
tion, called knowledge unit (abbreviated to
KU), is written in the following style:
&lt;KU&gt; if a case, then what/how to do. &lt;/KU&gt;
In Japanese, there are many sentential pat-
terns to express if-then relation. Authors of
the knowledge base can use several expres-
sions like &amp;quot;- • - deareba • (if - • - • -)&amp;quot;, &amp;quot;. • - no
baai ha • •• (in case that • • •
The basic form of the how and symp-
tom question is &amp;quot;in some case, what/how
can I do?&amp;quot;. Therefore, the system can an-
swer the question by finding the most similar
KU case part and showing the corresponding
what/how to do part to the user (see Figure
1).
</bodyText>
<subsectionHeader confidence="0.9945765">
5.3 Matching of user question and
knowledge unit
</subsectionHeader>
<bodyText confidence="0.778162666666667">
Matching of the user question and a knowl-
edge unit (KU) is done by comparing their
dependency trees whose nodes are phrases.
Their similarity is calculated as follows (Fig-
ure 2):
1. For each phrase in the user question, the
most similar phrase in the KU case part
is looked for based on the following cri-
teria:
</bodyText>
<listItem confidence="0.878551">
• Matching of content words : 3 points
• The second or more matching
of content words (when the
phrase contains two or more
content words) : 1 point
</listItem>
<page confidence="0.948964">
144
</page>
<table confidence="0.944584916666667">
3+0+1+1=5 on Emacs
3+0+1+1=5
3+0+1+1=5
by .Me*
by Mew
: . emails
F.;;TTATTI
send
The user question A knowledge unit
(The maximum matching score: 15) (The maximum matching score : 20)
The certainty score = (5+5+5)2 x 100 = 75 (%)
15 x 20
</table>
<figureCaption confidence="0.981213">
Figure 2: Matching of the user question and a knowledge unit.
</figureCaption>
<listItem confidence="0.995933833333333">
• Matching of the depth of the
phrases in parse trees : 1 point
• Matching of the type of the
phrases (phrase types differ
depending on surface cases
and verb conjugations, etc) : 1 point
</listItem>
<bodyText confidence="0.908420210526316">
2. The similarity scores of phrases in the
user question are summed up and nor-
malized by the maximum matching score
(MMS) as follows (the MMS is the simi-
larity score with the same sentence):
(The sum of scores Of) 2
phrase similarities )
( The MMS of (The MMS
the user question) the KU case)
The above score is given to the KU as its
certainty score.
The above algorithm cares for the struc-
tures of sentences to some extent by giving
phrase depth scores and phrase type scores,
but not in a strict way. This leads to a flex-
ible matching for handling a variety of natu-
ral language sentences and some parse errors.
For the present, the parameters were given
empirically.
</bodyText>
<sectionHeader confidence="0.987355" genericHeader="method">
6 Dialogue manager
</sectionHeader>
<bodyText confidence="0.978016222222222">
Figure 1 showed the simplest case of a QA. In
some cases, however, the user and the system
have to take more turns until the user obtains
a satisfactory answer. Such a turn-taking is
an essential point of a conversation.
To conduct a conversation, that is, to per-
form a proper turn-taking, the participant
have to be able to do the following functions
at least:
</bodyText>
<listItem confidence="0.999221">
• ask the opponent back if there is an un-
known word in the opponent&apos;s utterance,
• interpret the opponent&apos;s utterance con-
textually, and
• ask the opponent back when the oppo-
nent&apos;s utterance is not clear.
</listItem>
<bodyText confidence="0.9996964">
Our dialogue helpsystem can perform the
basic level of the above functions by referring
to natural language knowledge base. In the
following subsections, we explain each of these
functions in detail.
</bodyText>
<subsectionHeader confidence="0.999657">
6.1 Asking back of an unknown word
</subsectionHeader>
<bodyText confidence="0.999661">
Given the user utterance, the system first
checks whether each content word in it is reg-
istered in the system database or not. If the
word is not registered, it means that the word
is an unknown word to the system. An un-
known word appears in the following cases:
</bodyText>
<listItem confidence="0.99818075">
1. Technical term not covered by the knowl-
edge base.
ex. shell script, clone
2. Technical term whose synonym or related
term is covered by the knowledge base.
ex. Mozaic, Mozilla
3. Misspell of the user.
ex. Internetmai, Windo
</listItem>
<page confidence="0.999494">
145
</page>
<tableCaption confidence="0.999304">
Table 1: Patterns of the system responses.
</tableCaption>
<figure confidence="0.958254761904762">
The best
certainty score
one
many
# of the candidate KUs
(one difference)
Select &lt;upper concept&gt; from &lt;list
of the difference&gt;.
(two or more differences)
Your question is not clear. Select
&lt;list of the candidate KU cases&gt;.
Your question is not clear. Select
&lt;list of the candidate KU cases&gt;
100-60%
60-30%
30-0%
&lt;what/how to do&gt;
(of the KU)
I cannot answer your question.
4. General term.
ex. name, summer vacation
</figure>
<bodyText confidence="0.9965924375">
The system decision, whether the unknown
word is general term or not, is taken accord-
ing to whether it is an entry of a children&apos;s
dictionary or not (Tadika, 1997).
If the unknown word is not a general term,
the system asks the user back in the form
&amp;quot;what is &apos;unknown word&apos;?&amp;quot;. If the system
asks &amp;quot;what is Internetmai?&amp;quot;, the user prob-
ably notices his/her misspell and re-input
it correctly. If the system asks &amp;quot;what is
Mozilla?&amp;quot;, the user might paraphrase it like
&amp;quot;It means Netscape&amp;quot;.
If the unknown word is a general word, it
does not make sense to ask the user back, like
&amp;quot;what is name?&amp;quot;. Therefore, the system just
overlooks it.
</bodyText>
<subsectionHeader confidence="0.9625375">
6.2 Contextual interpretation of user
questions
</subsectionHeader>
<bodyText confidence="0.994831666666667">
The user question may be related to its pre-
ceding utterances, modifying or supplement-
ing them. As an example, consider the fol-
lowing dialogue:
Ul: How can I send emails by Mew?
Type &amp;quot;C-c C-c&amp;quot; when you finish writing
a mail.
U2: In case to reply.
S2: Move the cursor on the message to
which you want to reply and type &amp;quot;A&amp;quot;.
In this dialogue, the user utterance U2 is a
modification of U1, indicating &amp;quot;How can I re-
ply emails by Mew?&amp;quot;.
In order to interpret such a context depen-
dent utterance properly, the dialogue man-
ager attempt to merge the user&apos;s new utter-
ance onto the previous one. For each word of
the user&apos;s new utterance, wnew, if the previ-
ous utterance contains the word of the same
category, Wold, tvi,„,, is overwritten on Wold.
If not, wn,„ is added to the previous utter-
ance. Two words are considered to be in the
same category if they belong to the same top
category of the domain ontology described in
Section 4.1. Then, the system looks up the
knowledge base by the merged utterance.
In the above example, &amp;quot;reply&amp;quot; of U2 is over-
written on &amp;quot;send&amp;quot; of Ul, since they belong
to the same category, action term. Then the
system attempts to match the combined ut-
terance &amp;quot;How can I reply emails by Mew?&amp;quot;
with the knowledge base, and as a final re-
sult, it can response as S2 2.
In the above example, since U2 is an addi-
tion utterance, the system does not need to
interpret U2 as a new, context independent
question. However, if the user utterance has
a different type, it is not possible to decide
whether it is context dependent or indepen-
</bodyText>
<footnote confidence="0.520964666666667">
2Note that the system keeps the resultant interpre-
tation of the user query, which means that the system
can keep more than one user utterances practically.
For example, if the user asks &amp;quot;In case to forward&amp;quot; af-
ter S2 in the above example, the system can interpret
it as &amp;quot;How can I forward emails by Mew&amp;quot;.
</footnote>
<page confidence="0.996731">
146
</page>
<figureCaption confidence="0.994528">
Figure 3: An example of handling many candidate KUs.
</figureCaption>
<figure confidence="0.974495388888889">
66%
66%
uncompress
Candidate KUs
LNy..•■■■■••••••■•..&amp;quot;
Difference : lzh file, zip file
Upper concept : compressed file
uncompress I
Ul : I would like to uncompress a file.
Si : Select compressed file from &amp;quot;lzh file&amp;quot;
and &amp;quot;zip file&amp;quot;.
U2 : lzh file.
-6-
S2 : Invoke LHA Utility 32 and select
uncompress wizard from [File] menu.
by LHA Utility
by LHA Utility
ziff:file
</figure>
<bodyText confidence="0.98680603125">
dent by seeing the new utterance alone.
To decide this, the dialogue manager re-
gards the certainty score between the utter-
ance and the most similar KU as an appropri-
ateness measure of the interpretation. That
is, we calculate both the certainty score be-
tween the merged utterance (contextual inter-
pretation) and the knowledge base, and that
between the new utterance as it is and the
knowledge base. Then, we choose the inter-
pretation which obtained the KU with the
bigger certainty score.
For example, in the following dialogue, U2
is interpreted as &amp;quot;How to invoke Mew?&amp;quot;, since
this combined interpretation has the bigger
certainty score rather than U2 itself.
Ul: What is Mew?
Si: A kind of mail software working on
Emacs.
U2: How to invoke?
S2: Type &apos;M-x mew&amp;quot; on Emacs.
On the other hand, in the next example, U2
is interpreted as it is, since U2 has the big-
ger certainty score rather than the combined,
somehow strange interpretation of &amp;quot;How to
uncompress zip files by Outlook on Unix?&amp;quot;.
Ul: I want to send an email by Outlook.
Si: Invoke OutlookExpress, write your
email, and select &amp;quot;Send/Get&amp;quot; button.
U2: How to uncompress zip files on UNIX.
S2: Type &amp;quot;unzip [zip filename]&amp;quot; in the com-
mand line.
</bodyText>
<subsectionHeader confidence="0.897006">
6.3 Asking back for an unclear
question
</subsectionHeader>
<bodyText confidence="0.999987444444444">
As mentioned so far, the system retrieves
proper KUs which are similar to the user
question. The KU with the best certainty
score and the KUs with the 90% or larger cer-
tainty score are called candidate KUs. The di-
alogue manager performs differently depend-
ing on the best certainty score and the num-
ber of candidate KUs, as shown in Table 1.
If the certainty score is 60% or higher and
the number of the candidate KUs are two or
more, the dialogue manager detects the dif-
ference between their cases and ask the user
to make his/her question more specific.
Figure 3 shows an example of such a dia-
logue. The two candidate KUs are detected
for Ul and their cases have only one differ-
ence: &amp;quot;lzh file&amp;quot; and &amp;quot;zip file&amp;quot;. Then, the sys-
tem detects their common upper concept in
the domain ontology and ask the user in the
form &amp;quot;Select &lt;upper concept&gt; from &lt;list of
the difference &gt;&amp;quot; as shown in Figure 3.
If the candidate KUs contain two or more
differences, it is hard to edit them in a neat
way. Therefore, the system shows the candi-
date KUs&apos; cases as they are. If the certainty
score is less than 60% and larger than 30%,
the system responses in the same way.
</bodyText>
<page confidence="0.996644">
147
</page>
<figureCaption confidence="0.999933">
Figure 4: Evaluation of the helpsystem.
</figureCaption>
<figure confidence="0.999734614035087">
180
160
140
120
100
80
60
40
20
MRenews
CIOut of scope
Failure:Difficult
I Faure:Knowledge
• FeitureZialeg Manager
11Faurein pat Meow&apos;
D Success
II
Nov22-Nov28
Oct18-0ct22
Nov29-Dec05
Doc27-Jan02
Dec20-Dec28
Doc13-Dec 19
Dec08-Dec12
Oct04-Oct I 0
Nov08-Nov14
• 4
✓ 3
CO I,
0 Z
CO
CO
0
CO
00
8
00
7a
Ts
Co
0
4
76&apos;
0
0
Co
7
0
Co
(.,
a
.1
CO
a,
CO
0
0▪ 4
</figure>
<sectionHeader confidence="0.966262" genericHeader="evaluation">
7 Evaluation
</sectionHeader>
<bodyText confidence="0.9986395">
The helpsystem started its service on July
1999 as past of the CIMS web service. All
conversation logs between users and the sys-
tem have been stored as a dialogue database.
In the dialogue database, each dialogue be-
tween a user and the system is segmented into
task units manually. We call this unit a ses-
sion. Figure 4 shows the number of sessions
and their evaluation of each week from July
5th to January 30th. On average, there are
70 sessions in a week; a dialogue with a user
and the system consists of 2.1 sessions, which
means a user asks 2.1 topics in one dialogue;
one session consists of 3.2 turns.
The evaluation of sessions is based on the
following criteria.
Success: The system could return a satisfac-
tory answer.
</bodyText>
<subsectionHeader confidence="0.833687">
Failure:Input Analyzer: The system
</subsectionHeader>
<bodyText confidence="0.9987298">
could not response properly because of
the input analysis error, mostly the lack
of utterance-pattern rules. Utterance-
pattern rules are added whenever the
lack is found.
</bodyText>
<subsectionHeader confidence="0.670039">
Failure:Dialog Manager: The system
</subsectionHeader>
<bodyText confidence="0.9998236875">
could not response properly because
of the dialogue manager error. Dia-
logue manager error comes both from
simple bugs of the system and from
unnoticed patterns of the user response.
For example, when the system asks
&amp;quot;select from A and B&amp;quot; expecting the
answer &amp;quot;A&amp;quot; or &amp;quot;B&amp;quot;, a user might answer
&amp;quot;the latter&amp;quot;. The system is modified
whenever necessary.
Failure:Knowledge: The system could not
answer the question because of the lack
of knowledge. This is the major rea-
son of the failure as shown in Figure 4.
Though the knowledge base is being ex-
tended step by step, the range of the user
</bodyText>
<page confidence="0.993868">
148
</page>
<bodyText confidence="0.999952035714285">
query is unlimited, including troubles in
using PCs and advanced settings of soft-
ware/hardware.
Failure:Difficult: Current system architec-
ture could not handle the question. For
example, a user sometimes asks &amp;quot;what is
the difference between A and B&amp;quot;, or when
the system asks &amp;quot;select from A and B&amp;quot;, a
user answers &amp;quot;I don&apos;t know&amp;quot;. In order to
handle such utterances, we are planning
to improve the system to exploit defini-
tions of &amp;quot;A&amp;quot; and &amp;quot;B&amp;quot;.
Out of scope: Out of the system domain,
such as questions about telephone
charges in using PPP or the Y2K prob-
lem.
Miscellaneous: Such as &amp;quot;hello&amp;quot;, &amp;quot;this is a
test&amp;quot; or just a simple typo like &amp;quot;a&amp;quot;.
The success ratio, that is, the ratio of Suc-
cess over Success plus Failure, of the whole
period is 37%. The system became stable
around October 1999, and the success ratio
after that (14 weeks) is 39%. Considering rel-
atively wide domain the system have to cover,
we feel the success ratio is reasonable, and the
system is contributing to CIMS to some ex-
tent by handling simple FAQs like &amp;quot;how to
change my password&amp;quot;.
</bodyText>
<sectionHeader confidence="0.994198" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999982137931034">
This paper described the dialogue helpsys-
tern, which has been working in practice with
real users.
Construction of natural language knowl-
edge base needs some cost, though it is much
easier than that of formal language knowl-
edge base. However, providing a high-quality
service needs cost; good manuals and FAQs
are important for any products, and a large
amount of materials are prepared for cus-
tomer service operators. With that in mind,
we can say preparing a good document is a
universal problem, not just to a dialogue sys-
tem.
By running the system, the real dialogue
database can be accumulated. Based on this
database, we would like to study the phenom-
ena of man-machine conversation and to ex-
tend our work to user modeling, user intention
estimation, and other interesting dialogue re-
search areas.
The system is designed to be domain-
independent and can be ported to a new do-
main by preparing a domain knowledge base.
Exploiting this merit, we are planning to con-
struct the automatic reference service system
of Kyoto University Library, which certainly
provides us with a wider breadth of dialogue
data.
</bodyText>
<sectionHeader confidence="0.999316" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999862655172414">
Edwin Cooper. 1996. Improving FAQ Finder&apos;s
performance: Setting parameters by getetic
programming. In Working Notes of the AAAI
Spring Symposium on Machine Learning in In-
formation Access.
B Katz. 1990. Using english for indexing and
retrieving. In Artificial Intelligence at MIT.
Vol.1, MIT Press, pages 134-165.
Sadao Kurohashi and Makoto Nagao. 1994. A
syntactic analysis method of long Japanese sen-
tences based on the detection of conjunctive
structures. Computational Linguistics, 20(4).
Sadao Kurohashi and Makoto Nagao. 1998.
Building a Japanese parsed corpus while im-
proving the parsing system. In Proceedings of
the First International Conference on Language
Resources &amp; Evaluation, pages 719-724.
NIST and DARPA. 2000. The Eighth Text RE-
trieval Conference (TREC-8). NIST Special
Publication.
Jyunichi Tadika, editor. 1997. Reika Shougaku
Kokugojiten (Japanese dictionary for children).
Sanseido.
Robert Wilensky, Yiga1 Arens, and David Chin.
1984. Talking to unix in English: An oveview of
UC. Communications of the ACM, 27(6):574-
593.
Yorick Wilks, editor. 1999. Machine Conversa-
tions. Kluwer Academic Publishers.
</reference>
<page confidence="0.998976">
149
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.223761">
<title confidence="0.759146">Dialogue Helpsystem based on Flexible Matching User Query with Natural Language Knowledge Base</title>
<author confidence="0.780992">Sadao Kurohashi</author>
<author confidence="0.780992">Wataru</author>
<affiliation confidence="0.628935">Graduate School of Kyoto</affiliation>
<address confidence="0.728892">Yoshida-honmachi, Sakyo, Kyoto, 606-8501</address>
<abstract confidence="0.9981185625">This paper describes a dialog helpsystem which advises users in using computer facilities and software applications provided by the Center for Information and Multimedia Studies, Kyoto University. The system employs a knowledge base written in natural language and retrieves a proper knowledge unit by flexible matching of user query with the knowledge base. The system is running since July 1999, received about 2,000 queries for the first seven months, and answered about 40% of them satisfactory.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Edwin Cooper</author>
</authors>
<title>Improving FAQ Finder&apos;s performance: Setting parameters by getetic programming.</title>
<date>1996</date>
<booktitle>In Working Notes of the AAAI Spring Symposium on Machine Learning in Information Access.</booktitle>
<contexts>
<context position="1697" citStr="Cooper, 1996" startWordPosition="264" endWordPosition="265">nition is still a big obstacle, but also in typing language. The most serious problem is knowledge. It is obvious that without sufficient knowledge a dialogue system cannot talk with people satisfactorily. Classical dialogue systems like UC (Wilensky et al., 1984) utilized a formal language to represent knowledge, which requires the heavy cost of construction and maintenance and makes the scaling up quite difficult. In contrast, along with the improvement of NLP, research activities which utilize natural language text as a knowledge base become popular, such as START (Katz, 1990), FAQ Finder (Cooper, 1996), and QA Track in TREC 8 (NIST and DARPA, 2000). These systems, however, basically produce one time response, and do not have a conversation with users. This paper proposes a dialogue helpsystem in which natural language knowledge base is not only used for one time response, but also for conducting a conversation. To put it concretely, the system can • ask the user back if there is an unknown word in the user utterance, • interpret the user utterance contextually, and • ask the user back when the user utterance is not clear. In order to achieve these functions, a mild restriction is imposed on</context>
</contexts>
<marker>Cooper, 1996</marker>
<rawString>Edwin Cooper. 1996. Improving FAQ Finder&apos;s performance: Setting parameters by getetic programming. In Working Notes of the AAAI Spring Symposium on Machine Learning in Information Access.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Katz</author>
</authors>
<title>Using english for indexing and retrieving.</title>
<date>1990</date>
<booktitle>In Artificial Intelligence at MIT. Vol.1,</booktitle>
<pages>134--165</pages>
<publisher>MIT Press,</publisher>
<contexts>
<context position="1670" citStr="Katz, 1990" startWordPosition="260" endWordPosition="261">ge for which speech recognition is still a big obstacle, but also in typing language. The most serious problem is knowledge. It is obvious that without sufficient knowledge a dialogue system cannot talk with people satisfactorily. Classical dialogue systems like UC (Wilensky et al., 1984) utilized a formal language to represent knowledge, which requires the heavy cost of construction and maintenance and makes the scaling up quite difficult. In contrast, along with the improvement of NLP, research activities which utilize natural language text as a knowledge base become popular, such as START (Katz, 1990), FAQ Finder (Cooper, 1996), and QA Track in TREC 8 (NIST and DARPA, 2000). These systems, however, basically produce one time response, and do not have a conversation with users. This paper proposes a dialogue helpsystem in which natural language knowledge base is not only used for one time response, but also for conducting a conversation. To put it concretely, the system can • ask the user back if there is an unknown word in the user utterance, • interpret the user utterance contextually, and • ask the user back when the user utterance is not clear. In order to achieve these functions, a mil</context>
</contexts>
<marker>Katz, 1990</marker>
<rawString>B Katz. 1990. Using english for indexing and retrieving. In Artificial Intelligence at MIT. Vol.1, MIT Press, pages 134-165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>A syntactic analysis method of long Japanese sentences based on the detection of conjunctive structures.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="7111" citStr="Kurohashi and Nagao, 1994" startWordPosition="1175" endWordPosition="1178">The compression type is zip. The helpsystem reported in the paper answers what, how and symptom questions. In addition, it can interpret addition and answer utterances contextually. The request utterances are out of the system scope currently. 4 Outline of the helpsystem The system is comprised of the following components (Figure 1): User Interface: Users access to the helpsystern via a WWW browser by using CGI based HTML forms. The helpsystem is actually running on a workstation in our lab. Input Analyzer: The user utterance is transformed into a dependency structure by a robust parser, KNP (Kurohashi and Nagao, 1994; Kurohashi and Nagao, 1998), and utterance-pattern rules are applied to extract the utterance type and the utterance content. Japanese is head-final and the final expression shows an utterance type. Therefore, the longest matching of utterancepattern rules form the end of the utterance can detect the utterance type in most cases. For example, if the final expression is &amp;quot;niha doushitara ii desu ka (How can I -)&amp;quot;, how type is assigned; if &amp;quot;no baai ha (In case - -)&amp;quot;, addition type. 143 Knowledge base: The knowledge base is written in a natural language, in a dictionary-like structure. Dialogue M</context>
</contexts>
<marker>Kurohashi, Nagao, 1994</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 1994. A syntactic analysis method of long Japanese sentences based on the detection of conjunctive structures. Computational Linguistics, 20(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>Building a Japanese parsed corpus while improving the parsing system.</title>
<date>1998</date>
<booktitle>In Proceedings of the First International Conference on Language Resources &amp; Evaluation,</booktitle>
<pages>719--724</pages>
<contexts>
<context position="7139" citStr="Kurohashi and Nagao, 1998" startWordPosition="1179" endWordPosition="1183">. The helpsystem reported in the paper answers what, how and symptom questions. In addition, it can interpret addition and answer utterances contextually. The request utterances are out of the system scope currently. 4 Outline of the helpsystem The system is comprised of the following components (Figure 1): User Interface: Users access to the helpsystern via a WWW browser by using CGI based HTML forms. The helpsystem is actually running on a workstation in our lab. Input Analyzer: The user utterance is transformed into a dependency structure by a robust parser, KNP (Kurohashi and Nagao, 1994; Kurohashi and Nagao, 1998), and utterance-pattern rules are applied to extract the utterance type and the utterance content. Japanese is head-final and the final expression shows an utterance type. Therefore, the longest matching of utterancepattern rules form the end of the utterance can detect the utterance type in most cases. For example, if the final expression is &amp;quot;niha doushitara ii desu ka (How can I -)&amp;quot;, how type is assigned; if &amp;quot;no baai ha (In case - -)&amp;quot;, addition type. 143 Knowledge base: The knowledge base is written in a natural language, in a dictionary-like structure. Dialogue Manager: The core process of </context>
</contexts>
<marker>Kurohashi, Nagao, 1998</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 1998. Building a Japanese parsed corpus while improving the parsing system. In Proceedings of the First International Conference on Language Resources &amp; Evaluation, pages 719-724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
<author>DARPA</author>
</authors>
<date>2000</date>
<booktitle>The Eighth Text REtrieval Conference (TREC-8). NIST Special Publication.</booktitle>
<contexts>
<context position="1744" citStr="NIST and DARPA, 2000" startWordPosition="272" endWordPosition="275">o in typing language. The most serious problem is knowledge. It is obvious that without sufficient knowledge a dialogue system cannot talk with people satisfactorily. Classical dialogue systems like UC (Wilensky et al., 1984) utilized a formal language to represent knowledge, which requires the heavy cost of construction and maintenance and makes the scaling up quite difficult. In contrast, along with the improvement of NLP, research activities which utilize natural language text as a knowledge base become popular, such as START (Katz, 1990), FAQ Finder (Cooper, 1996), and QA Track in TREC 8 (NIST and DARPA, 2000). These systems, however, basically produce one time response, and do not have a conversation with users. This paper proposes a dialogue helpsystem in which natural language knowledge base is not only used for one time response, but also for conducting a conversation. To put it concretely, the system can • ask the user back if there is an unknown word in the user utterance, • interpret the user utterance contextually, and • ask the user back when the user utterance is not clear. In order to achieve these functions, a mild restriction is imposed on the knowledge base; it is compiled in a dictio</context>
</contexts>
<marker>NIST, DARPA, 2000</marker>
<rawString>NIST and DARPA. 2000. The Eighth Text REtrieval Conference (TREC-8). NIST Special Publication.</rawString>
</citation>
<citation valid="true">
<title>Reika Shougaku Kokugojiten (Japanese dictionary for children).</title>
<date>1997</date>
<editor>Jyunichi Tadika, editor.</editor>
<publisher>Sanseido.</publisher>
<marker>1997</marker>
<rawString>Jyunichi Tadika, editor. 1997. Reika Shougaku Kokugojiten (Japanese dictionary for children). Sanseido.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Wilensky</author>
<author>Yiga1 Arens</author>
<author>David Chin</author>
</authors>
<title>Talking to unix in English: An oveview of UC.</title>
<date>1984</date>
<journal>Communications of the ACM,</journal>
<pages>27--6</pages>
<contexts>
<context position="1348" citStr="Wilensky et al., 1984" startWordPosition="205" endWordPosition="208">rst seven months, and answered about 40% of them satisfactory. 1 Introduction One of the ultimate goals of Natural Language Processing is to realize a dialogue system which can communicate with human beings in a natural way (Wilks, 1999). However, no effective real world dialogue application exists so far, not only in spoken language for which speech recognition is still a big obstacle, but also in typing language. The most serious problem is knowledge. It is obvious that without sufficient knowledge a dialogue system cannot talk with people satisfactorily. Classical dialogue systems like UC (Wilensky et al., 1984) utilized a formal language to represent knowledge, which requires the heavy cost of construction and maintenance and makes the scaling up quite difficult. In contrast, along with the improvement of NLP, research activities which utilize natural language text as a knowledge base become popular, such as START (Katz, 1990), FAQ Finder (Cooper, 1996), and QA Track in TREC 8 (NIST and DARPA, 2000). These systems, however, basically produce one time response, and do not have a conversation with users. This paper proposes a dialogue helpsystem in which natural language knowledge base is not only use</context>
</contexts>
<marker>Wilensky, Arens, Chin, 1984</marker>
<rawString>Robert Wilensky, Yiga1 Arens, and David Chin. 1984. Talking to unix in English: An oveview of UC. Communications of the ACM, 27(6):574-593.</rawString>
</citation>
<citation valid="true">
<title>Machine Conversations.</title>
<date>1999</date>
<editor>Yorick Wilks, editor.</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>1999</marker>
<rawString>Yorick Wilks, editor. 1999. Machine Conversations. Kluwer Academic Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>