<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000022">
<title confidence="0.988791">
Towards Debugging Sentiment Lexicons
</title>
<author confidence="0.997182">
Andrew Schneider
</author>
<affiliation confidence="0.994234">
Computer and Information Sciences
Temple University
</affiliation>
<email confidence="0.98412">
atschneider@temple.edu
</email>
<author confidence="0.983257">
Eduard Dragut
</author>
<affiliation confidence="0.989942">
Computer and Information Sciences
Temple University
</affiliation>
<email confidence="0.995594">
edragut@temple.edu
</email>
<sectionHeader confidence="0.99735" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999840695652174">
Central to many sentiment analysis tasks
are sentiment lexicons (SLs). SLs exhibit
polarity inconsistencies. Previous work
studied the problem of checking the con-
sistency of an SL for the case when the en-
tries have categorical labels (positive, neg-
ative or neutral) and showed that it is NP-
hard. In this paper, we address the more
general problem, in which polarity tags
take the form of a continuous distribution
in the interval [0, 1]. We show that this
problem is polynomial. We develop a gen-
eral framework for addressing the consis-
tency problem using linear programming
(LP) theory. LP tools allow us to uncover
inconsistencies efficiently, paving the way
to building SL debugging tools. We show
that previous work corresponds to 0-1 inte-
ger programming, a particular case of LP.
Our experimental studies show a strong
correlation between polarity consistency
in SLs and the accuracy of sentiment tag-
ging in practice.
</bodyText>
<sectionHeader confidence="0.999479" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997435538461538">
Many sentiment analysis algorithms rely on sen-
timent lexicons (SLs), where word forms or word
senses1 are tagged as conveying positive, negative
or neutral sentiments. SLs are constructed by one
of three methods (Liu, 2012; Feldman, 2013): (1)
Manual tagging by human annotators is gener-
ally reliable, but because it is labor-intensive, slow,
and costly, this method has produced small-sized
SLs comprising a few thousand words, e.g., Opin-
ion Finder (OF) (Wilson et al., 2005), Appraisal
Lexicon (AL) (Taboada and Grieve, 2004), Gen-
eral Inquirer (GI) (Stone et al., 1966), and Micro-
WNOp (Cerini et al., 2007). (2) Dictionary-
</bodyText>
<footnote confidence="0.587115">
1We refer to a string of letters or sounds as a word form &amp;
to a pairing of a word form with a meaning as a word sense.
</footnote>
<bodyText confidence="0.999467365853658">
based acquisition relies on a set of seed words
to expand its coverage to similar words. There
are over thirty dictionary-based techniques (An-
dreevskaia and Bergler, 2006; Blum et al., 2004;
Chen and Skiena, 2014; Choi and Wiebe, 2014;
Esuli and Sebastiani, 2006; Feng et al., 2013; Has-
san and Radev, 2010; Kamps et al., 2004; Moham-
mad et al., 2009; Takamura et al., 2005; Turney,
2002; Williams and Anand, 2009), most of them
based on WordNet (Fellbaum, 1998), such as Sen-
tiWordNet (SWN)(Baccianella et al., 2010) and
Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano,
2010). (3) Corpus-based acquisition expands a
set of seed words with the use of a large docu-
ment corpus (Breck et al., 2007; Bross and Ehrig,
2013; Choi and Cardie, 2009; Ding et al., 2008;
Du et al., 2010; Hatzivassiloglou and McKeown,
1997; Jijkoun et al., 2010; Kaji and Kitsuregawa,
2007; Klebanov et al., 2013; Lu et al., 2011; Peng
and Park, 2011; Tang et al., 2014; Wu and Wen,
2010). Method (1) generally produces the most
reliable annotations, however the considerable ef-
fort required to yield substantial lexicons makes
it less useful in practice. The appeals of (2) and
(3) lie in the formalism of their models and their
capability of producing large-sized SLs. SLs are
either word or sense/synset oriented. We refer to
the former as Sentiment Word Lexicons (SWLs),
e.g., GI, OF, and AL, and to the latter as Senti-
ment Sense Lexions (SSLs), e.g., SWN, QWN,
and Micro-WNOp. Besides the method of compi-
lation, SLs may also vary with regard to sentiment
annotation.
Polarity disagreements are noted across SLs
that do (SWN, Q-WordNet) and do not (AL, GI)
reference WordNet. For instance, the adjectives
panicky and terrified, have negative and
positive polarities in OF, respectively. They each
have only one synset which they share in Word-
Net: “thrown into a state of intense fear or des-
peration”. Assuming that there is an intrinsic re-
</bodyText>
<page confidence="0.96691">
1024
</page>
<note confidence="0.977398666666667">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1024–1034,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.99989084375">
lationship between the sentiments of a word and
its meanings, a single synset polarity assignment
to this synset cannot agree with both positive and
negative at the word level. If the information given
in WordNet is accurate (the Oxford and Cam-
bridge dictionaries give only this meaning for both
words) then there must be an annotation inconsis-
tency in OF, called a polarity inconsistency. While
some inconsistencies are easy to detect, manual
consistency checking of an entire SL is an imprac-
tical endeavor, primarily because of the sheer size
(SWN has over 206,000 word-sense pairs). Ad-
ditionally, WordNet’s complex network structure
renders manual checking virtually impossible; an
instance of a polarity inconsistency may entail an
entire sub-network of words and senses. In this
paper we develop a rigorous formal method based
on linear programming (LP)(Schrijver, 1986) for
polarity consistency checking of SLs with accom-
panying methods to unearth mislabeled words and
synsets when consistency is not satisfied.
We translate the polarity consistency problem
(PCP) into a form of the LP problem, suitable
as the input to a standard LP solver, and utilize
the functionality available in modern LP software
(e.g., identifying an irreducible infeasible subset)
to pinpoint the sources of inconsistencies when
they occur. In our experimentation we are able to
quickly uncover numerous intra- and inter-lexicon
inconsistencies in all of the input SLs tested and to
suggest lexicon entries for a linguist to focus on in
“debugging” the lexicon.
</bodyText>
<sectionHeader confidence="0.579551" genericHeader="introduction">
Background and Previous Work
</sectionHeader>
<bodyText confidence="0.999925222222222">
Sentiment resources have taken two basic ap-
proaches to polarity annotation: discrete and frac-
tional. In the discrete approach, polarity is defined
to be one of the discrete values positive, negative,
or neutral. A word or a synset takes exactly one
of the three values. QWN, AL, GI, and OF follow
the discrete polarity annotation. In the fractional
approach, polarity is defined as a 3-tuple of non-
negative real numbers that sum to 1, correspond-
ing to the positive, negative, and neutral values re-
spectively. SWN, Micro-WNOp, and Hassan and
Radev (2010) employ a fractional polarity anno-
tation. For example, the single synset of the ad-
jective admissible in WordNet has the senti-
ment tags positive in QWN and (.25, .625, .125)
in SWN, so here SWN gives a primarily negative
polarity with some positive and less neutral polar-
ity. We denote by PCP-D and PCP-F the polarity
</bodyText>
<figureCaption confidence="0.756191">
Figure 1: Discrete vs. fractional polarity consis-
tency. Example taken from Dragut et al. (2012).
</figureCaption>
<bodyText confidence="0.999226136363636">
consistency problem for the discrete and fractional
polarity annotations, respectively.
Dragut et al. (2012) introduces the PCP for do-
main independent SLs and gives a solution to a
particular form of the PCP-D, but that method
cannot solve PCP-F. For example, they show
that the adjectives laughable, comic, and
risible (Figure 1) constitute an inconsistency
in the discrete case. AL gives positive polarity for
laughable and OF gives negative for comic.
If s2 is not positive then laughable is not pos-
itive and if s2 is not negative then comic is not
negative, so there is no assignment of s2 that satis-
fies the whole system. Hence there is an incon-
sistency. However, the following fractional po-
larity tags do satisfy the system: s1 : (1, 0, 0),
s2 : (.66, .34, 0), s3 : (0, 1, 0), where the meaning
of the second tag, for instance, is that s2 is .66 pos-
itive, .34 negative, and 0 neutral. We thus see that
the discrete polarity annotation is rigid and leads
to more inconsistencies, whereas the fractional an-
notation captures more naturally the polarity spec-
trum of a word or synset. In this paper we give
a solution to the PCP-F. The differences between
our solution and that of Dragut et al. (2012) give
some insight into the general differences between
the fractional and discrete problems. First, the
discrete case is intractable, i.e., computationally
NP-complete (Dragut et al., 2012); we show in
this paper (Section 3.2) that the fractional case is
tractable (solvable in polynomial time). Second,
the PCP-D is solved in Dragut et al. (2012) by
translation to the Boolean satisfiability problem
(SAT) (Schaefer, 1978); here we recast the PCP-
F in terms of LP theory. Third, we show that the
LP framework is a natural setting for the PCP as
a whole, and that the PCP-D corresponds to the 0-
1 integer LP problem (Section 3.2), a classic NP-
complete problem (Karp, 2010).
Our experiments (Section 5.4) show that cor-
recting even a small number of inconsistencies can
greatly improve the accuracy of sentiment annota-
tion tasks. We implement our algorithm as a versa-
tile tool for debugging SLs, which helps locate the
</bodyText>
<equation confidence="0.79676425">
laughable :
positive
risible : ?
comic :
negative
1
0.5 0.5 0.6 0.4
s1 : “so unrea-
</equation>
<bodyText confidence="0.5334475">
sonable as to
invite derision”
s2 : “of or relating
to or characteristic
of comedy”
s3 : “arousing
or provoking
laughter”
</bodyText>
<page confidence="0.967341">
1025
</page>
<bodyText confidence="0.9966115">
sources of error in SLs. We apply our algorithm to
both SWLs and SSLs and demonstrate the useful-
ness of our approach to improving SLs.
The main contributions of this paper are:
</bodyText>
<listItem confidence="0.998833">
• solve the PCP-F;
• show that the PCP-F is tractable;
• show that the PCP is an instance of LP;
• develop a technique for identifying inconsis-
tencies in SLs of various types;
• implement our algorithm as a prototype SL
debugger;
• show that there is a strong correlation be-
tween polarity inconsistency in SLs and the
performance of sentiment tagging tools de-
veloped on them.
</listItem>
<sectionHeader confidence="0.942112" genericHeader="method">
2 Problem Definition
</sectionHeader>
<bodyText confidence="0.9987508">
In this section we give a formal characterization
of the polarity assignment of words and synsets in
SLs using WordNet. We use −, +, 0 to denote
negative, positive, and neutral polarities, respec-
tively, throughout the paper.
</bodyText>
<subsectionHeader confidence="0.996312">
2.1 Polarity Representation
</subsectionHeader>
<bodyText confidence="0.9993549375">
We define the polarity of a synset or word
r in WordNet to be a discrete probabil-
ity distribution, called a polarity distribution:
P+(r), P_(r), P0(r) &gt; 0 with P+(r) + P_(r) +
P0(r) = 1. P+(r), P_(r) and P0(r) represent
the “likelihoods” that r is positive, negative or
neutral, respectively. For instance, the WordNet
synset “worthy of reliance or trust” of the adjec-
tive reliable is given the polarity distribution
P+ = .375, P_ = .0 and P0 = .625 in Senti-
WordNet. We may drop r from the notation if the
meaning is clear from context. The use of a polar-
ity distribution to describe the polarity of a word
or synset is shared with many previous works (An-
dreevskaia and Bergler, 2006; Baccianella et al.,
2010; Kim and Hovy, 2006).
</bodyText>
<subsectionHeader confidence="0.993881">
2.2 WordNet
</subsectionHeader>
<bodyText confidence="0.997896">
A word-synset network N is a 4-tuple (W, S, £,
f) where W is a finite set of words, S is a finite
set of synsets, £ C_ W x S and f is a function
assigning a positive integer to each element in £.
For any word w and synset s, s is a synset of w if
(w, s) E £. For a pair (w, s) E £, f(w, s) is called
the frequency of use of w in the sense given by
s. For a word w, we let freq(w) denote the sum
of all f(w, s) such that (w, s) E £. We define
the relative frequency of w with s by rf(w, s) =
f(w,s) If f (w, s) = 0, the frequency of each
freq(w).
synset of w is increased by a small constant E. We
use E = .1 in our prototype.
</bodyText>
<subsectionHeader confidence="0.99942">
2.3 Word Polarities
</subsectionHeader>
<bodyText confidence="0.999984">
We contend that there exists a relation between the
sentiment orientation of a word and the polarities
of its related senses (synsets), and we make the as-
sumption that this relation takes the form of a lin-
ear function. Thus, for w E W and p E {+, −, 0},
the polarity distribution of w is defined as:
</bodyText>
<equation confidence="0.9442155">
�Pp(w) = g(w, s) · Pp(s), (1)
sESw
</equation>
<bodyText confidence="0.9981899375">
where Pp(s) is the polarity value of synset s
with polarity p and g(w, s) is a rational num-
ber. For example, g can be the relative frequency
of s with respect to w in WordNet: g(w, s) =
rf(w, s); bw E W, s E S. Alternatively, for each
word w we can draw g(w, ·) from a Zipfian dis-
tribution, following the observation that the distri-
bution of word senses roughly follows a Zipfian
power-law (Kilgarriff, 2004; Sanderson, 1999). In
this paper, we will assume g(w, s) = rf(w, s).
For example, the three synsets of the adjec-
tive reliable with relative frequencies 911, 111,
and 111, respectively, are given the distributions
(.375, 0, .625), (.5, 0, .5), and (.625, 0, .375) in
SentiWordNet. So for reliable we have P+ =
110.375 + 1
</bodyText>
<equation confidence="0.9904125">
9 110.5 + 1110.625 Pz� 0.41, P_ = 0, and
P0 = 9110.625 + 1110.5 + 1110.375 Pz� 0.59.
</equation>
<subsectionHeader confidence="0.99818">
2.4 Modeling Sentiment Orientation in SLs
</subsectionHeader>
<bodyText confidence="0.999969722222222">
Words and synsets have unique polarities in some
SLs, e.g., AL and OF. For instance, reliable
has positive polarity in AL, GI, and OF. The
question is: what does a discrete annotation of
reliable tell us about its polarity distribution?
One might take it to mean that the polarity distri-
bution is simply (1, 0, 0). This contradicts the in-
formation in SWN, which gives some neutral po-
larity for all of the synsets of reliable. So a
better polarity distribution would allow P0 &gt; 0.
Furthermore, given that (.41, 0, .59), (.40, 0, .60),
and (.45, 0, .55) give virtually identical informa-
tion to a sentiment analyst, it seems unreasonable
to expect exactly one to be the correct polarity
tag for reliable and the other two incorrect.
Therefore, instead of claiming to pinpoint an ex-
act polarity distribution for a word, we propose to
set a boundary on its variation. This establishes a
</bodyText>
<page confidence="0.971396">
1026
</page>
<bodyText confidence="0.994974">
range of values, instead of a single point, in which
SLs can be said to agree.
Thus, for a word w, we can define
</bodyText>
<equation confidence="0.980342666666667">
� + if P+ &gt; P−
polarity(w) = − (2)
if P− &gt; P+
</equation>
<bodyText confidence="0.999258166666667">
which we refer to as MAX POL. This model is
adopted either explicitly or implicitly by numer-
ous works (Hassan and Radev, 2010; Kim and
Hovy, 2004; Kim and Hovy, 2006; Qiu et al.,
2009). Another model is the majority sense model,
called MAJORITY, (Dragut et al., 2012), where
</bodyText>
<equation confidence="0.945410666666667">
polarity(w)
+ if P+ &gt; P− + P0
= Sl − if P− &gt; P+ + P0 (3)
Another polarity model, MAX, is defined as
� + if P+ &gt;P− &amp; P+ &gt;P0
polarity(w)= − if P−&gt;P+ &amp;P−&gt;P0 (4)
</equation>
<bodyText confidence="0.998693111111111">
For instance, reliable conveys positive po-
larity according to MAX POL, since P+ &gt; P−,
but neutral according to MAJORITY. When the
condition of being neither positive nor negative
can be phrased as a conjunction of linear in-
equalities, as is the case with MAJORITY and
MAX POL, then we define neutral as not positive
and not negative. These model definitions can be
applied to synsets as well.
</bodyText>
<subsectionHeader confidence="0.996704">
2.5 Polarity Consistency Definition
</subsectionHeader>
<bodyText confidence="0.9999857">
Instead of defining consistency for SLs dependent
on a choice of model, we develop a generic defi-
nition applicable to a wide variety of models, in-
cluding all of those discussed above. We require
that the polarity of a word or synset in the network
N be characterized by a set of linear inequalities
(constraints) with rational coefficients. Formally,
for each word w ∈ W, the knowledge that w has
a discrete polarity p ∈ {+, −, 0} is characterized
by a set of linear inequalities:
</bodyText>
<equation confidence="0.879029">
ψ(w,p) = {ai,0P++ai,1P−+ai,2P0 :� bi}, (5)
</equation>
<bodyText confidence="0.9982406">
where --&lt;∈ {≤, &lt;} and ai,0, ai,1, ai,2, bi ∈ Q,
i = 0, 1, ... , m. For instance, if the MAX model
is used, for w = worship whose polarity is pos-
itive in OF, we get the following set of inequali-
ties: ψ(w,+) = {P+−P− &gt; 0,P+−P0 &gt; 0} =
{(−1)P++1P−+0P0 &lt;0, (−1)P++0P−+1P0 &lt;0}.
Let L be an SL. We denote the system of in-
equalities introduced by all words and synsets
in L with known polarities in the network N
by Ψ0(N, L). The variables in Ψ0(N, L) are
</bodyText>
<figureCaption confidence="0.997516">
Figure 2: A network of 4 words and 3 synsets
</figureCaption>
<bodyText confidence="0.998849">
P+(r), P−(r) and P0(r), r ∈ W ∪ S. Denote by
T0(N, L) the set of constraints implied by the po-
larity distributions for all r ∈ L: P+(r)+P−(r)+
P0(r) = 1 and Pp∈{+,−,0}(r) ≥ 0,∀r ∈ W ∪ S.
Let Φ0(N, L) = Ψ0(N, L) ∪ T0(N, L).
</bodyText>
<construct confidence="0.739987">
Example 1. Let w1, w2, w3, and w4 be
the nouns perseverance, persistence,
pertinacity, and tenacity, respectively,
which are in OF with polarities +, 0, −,
and +, respectively (Figure 2). Assuming the
</construct>
<equation confidence="0.9323403">
MAJORITY model, ψ(w1,+) = {P+(w1) &gt;
P−(w1) + P0(w1)} = {P+(w1) &gt; 1 −
P+(w1)} = {−P+(w1) &lt; −12}, and ψ(w2, 0) =
{P+(w2) ≤ P−(w2) + P0(w2),P−(w2) ≤
P+(w2) + P0(w2)} = {P+(w2) ≤ 12, P−(w2)≤
2}. Similarly, ψ(w3, −) = {−P−(w3) &lt; −1
1 2}
and ψ(w4, −) = {−P+(w4) &lt; −12}.
Definition 1. A sentiment lexicon L is consistent if
the system Φ0(N, L) is feasible, i.e., has a solution.
</equation>
<bodyText confidence="0.999586588235294">
The PCP is then the problem of deciding if a
given SL L is consistent. In general, PCP can be
stated as follows: Given an assignment of polar-
ities to the words, does there exist an assignment
ofpolarities to the synsets that agrees with that of
the words? If the polarity annotation is discrete,
we have the PCP-D; if the polarity is fractional,
we have PCP-F. Our focus is PCP-F in this paper.
The benefits of a generic problem model are at
least two-fold. First, different linguists may have
different views about the kinds of inequalities one
should use to express the probability distribution
of a word with a unique polarity in some SL. The
new model can accommodate divergent views as
long as they are expressed as linear constraints.
Second, the results proven for the generic model
will hold for any particular instance of the model.
</bodyText>
<sectionHeader confidence="0.98505" genericHeader="method">
3 Polarity Consistency: an LP Approach
</sectionHeader>
<bodyText confidence="0.9995164">
A careful analysis of the proposed formulation
of the problem of SL consistency checking re-
veals that this can be naturally translated into an
LP problem. The goal of LP is the optimiza-
tion of a linear objective function, subject to lin-
</bodyText>
<equation confidence="0.948125">
perseverance
w1 : +
persistence
w2 : 0
pertinacity
w3 : −
tenacity
w4 : +
</equation>
<figure confidence="0.5402515">
0.5 0.29
0.5 0.01
0.7
1 1
s2 : “the act
of persisting or
persevering”
s3 : “the property
of a continuous
period of time”
s1 : “persistent
determination”
</figure>
<page confidence="0.982127">
1027
</page>
<bodyText confidence="0.992192157142857">
ear (in)equality constraints. LP problems are ex-
pressed in standard form as follows:
x represents the
vector of variables
(to be determined),
c and b are vec-
tors of (known) co-
efficients, A is a (known) matrix of coefficients,
and (·)T is the matrix transpose. An LP algorithm
finds a point in the feasible region where cTx has
the smallest value, if such a point exists. The feasi-
ble region is the set of x that satisfy the constraints
Ax ≤ b and x ≥ 0.
There are several non-trivial challenges that
need to be addressed in transforming our prob-
lem (i.e., the system Φ0(N, L)) into an LP prob-
lem. For instance, we have both strict and weak
inequalities in our model, whereas standard LP
does not include strict inequalities. We describe
the steps of this transformation next.
12},
Equality. The system Φ0(N, L) contains con-
straints of the form P+(s)+P−(s)+P0(s)=1 for
each s ∈ S, but observe that there are no equal-
ity constraints in the standard LP form (Equation
6). The usual conversion procedure is to replace a
given equality constraint: aTx = b, with: aTx ≤ b
and −aTx ≤ −b. However, this procedure in-
creases the number of constraints in Φ0(N, L) lin-
early. This can have a significant computation im-
pact since Φ0(N, L) may have thousands of con-
straints (see discussion in Section 5.3). Instead,
we can show that the system F obtained by per-
forming the following two-step transformation is
equivalent to Φ0(N, L), in the sense that F is fea-
sible iff Φ0(N, L) is feasible. For every s ∈ S,
(Step 1) we convert each P+(s)+P−(s)+P0(s)=1
to P+(s)+P−(s)≤1, and (Step 2) we replace ev-
ery P0(s) in Φ0(N, L) with 1 −P+(s) −P−(s).
Strict Inequalities. Strict inequalities are not
allowed in LP and their presence in inequality sys-
tems in general poses difficulties to inequality sys-
tem solvers (Goberna et al., 2003; Goberna and
Rodriguez, 2006; Ghaoui et al., 1994). Fortu-
nately results developed by the LP community al-
low us to overcome this obstacle and maintain the
flexibility of our proposed model. We introduce
a new variable y ≥ 0, and for every strict con-
straint of the form aTx &lt; b, we rewrite the in-
equality as aTx + y ≤ b. Let Φ00(N, L) be this
new system of constraints. We modify the objec-
tive function (previously null) to maximize y (i.e.,
minimize −y). Denote by F0 the LP that maxi-
mizes y subject to Φ00(N, L). We can show that
Φ0(N, L) is feasible iff F0 is feasible and y =6 0.
A sketch of the proof is as follows: if y &gt; 0 then
aTx + y ≤ b implies aTx &lt; b. Conversely, if
aTx &lt; b then ∃y &gt; 0 such that aTx + y ≤ b,
and maximizing for y will yield a y &gt; 0 iff one is
feasible. This step is omitted if we have no strict
constraints in Φ0(N, L).
Example (continued). The formulations of
ψ(w1, +), ψ(w3, −), and ψ(w4, +) involve strict
inequalities, so they are rewritten in Φ00(N, L),
e.g., ψ00(w4, +) = {−P+(s1) + y ≤ −12}.
We denote by Φ(N, L) the standard form of
Φ0(N, L) obtained by applying the above steps.
This is the input to an LP solver.
Theorem 1. Sentiment lexicon L is polarity con-
sistent iff Φ(N, L) is feasible.
</bodyText>
<subsectionHeader confidence="0.999148">
3.2 Time Complexity
</subsectionHeader>
<bodyText confidence="0.999932066666667">
For the network N and an SL L, the above trans-
lation algorithm converts the PCP into an LP
problem on the order of O(|E|), a polynomial
time conversion. The general class of linear pro-
gramming problems includes subclasses that are
NP-hard, such as the integer linear programming
(ILP) problems, as well as polynomial solvable
subclasses. We observe that our problem is rep-
resented by a system of rational linear inequali-
ties. This class of LP problems is solvable in poly-
nomial time (Khachiyan, 1980; G´acs and Lov´asz,
1981). This (informally) proves that the PCP-F is
solvable in polynomial time. PCP is NP-complete
in the discrete case (Dragut et al., 2012). This is
not surprising since in our LP formulation of the
</bodyText>
<figure confidence="0.954886">
minimize cTx
subject to Ax ≤ b (6)
and x ≥ 0
3.1 Translation to LP
</figure>
<bodyText confidence="0.5609735">
In our problem, x is the concatenation of all the
triplets hP+(r), P−(r), P0(r)i for all r ∈ W ∪ S.
Eliminate Word Related Variables. For each
word w ∈ L we replace P+(w), P−(w) and P0(w)
with their corresponding expressions according to
Equation 1; then the linear system Φ0(N, L) has
only the synset variables P+(s), P−(s) and P0(s)
for s ∈ S.
Example (continued). Using the relative fre-
quencies of Figure 2 in Equation 1 we get:
</bodyText>
<equation confidence="0.9903154">
ψ(w1,+)= {−.5P+(s1) − .5P+(s2) &lt; −12},
ψ(w2,0)={.29P+(s1)+.01P+(s2)+.7P+(s3)≤ 12,
.29P−(s1) + .01P−(s2) + .7P−(s3) ≤
ψ(w3,−)= {−P−(s1) &lt; − 1 2}, and
ψ(w4,+)= {−P+(s1) &lt; −1 2}.
</equation>
<page confidence="0.967585">
1028
</page>
<bodyText confidence="0.99968725">
PCP, the discrete case corresponds to the 0-1 in-
teger programming (BIP) subclass. (Recall that in
the discrete case each synset has a unique polar-
ity.) BIP is the special case of integer program-
ming where variables are required to be 0 or 1. BIP
is a classic NP-hard problem (Garey and Johnson,
1990). We summarize these statements in the fol-
lowing theorem.
</bodyText>
<figureCaption confidence="0.6542015">
Theorem 2. The PCP-F problem is P and the
PCP-D is NP-complete.
</figureCaption>
<bodyText confidence="0.999995166666667">
We proved a more general and more compre-
hensive result than Dragut et al. (2012). The PCP
solved by Dragut et al. (2012) is a particular case
of PCP-D: it can be obtained by instantiating our
framework with the MAJORITY model (Equation
3) and requiring each synset to take a unique polar-
ity. We believe that the ability to encompass both
fractional and discrete cases within one frame-
work, that of LP, is an important contribution, be-
cause it helps to give structure to the general prob-
lem of polarity consistency and to contextualize
the difference between the approaches.
</bodyText>
<sectionHeader confidence="0.98523" genericHeader="method">
4 Towards Debugging SLs
</sectionHeader>
<bodyText confidence="0.981909390243902">
Simply stating that an SL is inconsistent is of lit-
tle practical use unless accompanying assistance
in diagnosing and repairing inconsistencies is pro-
vided. Automated assistance is necessary in the
face of the scale and complexity of modern SLs:
e.g., AL has close to 7,000 entries, SWN annotates
the entirety of WordNet, over 206,000 word-sense
pairs. There are unique and interesting problems
associated with inconsistent SLs, among them: (1)
isolate a (small) subset of words/synsets that is po-
larity inconsistent, but becomes consistent if one
of them is removed; we call this an Irreducible
Polarity Inconsistent Subset (IPIS); (2) return an
IPIS with smallest cardinality (intuitively, such a
set is easiest to repair); (3) find all IPISs, and (4)
find the largest polarity consistent subset of an in-
consistent SL. In the framework of linear systems
of constraints, the problems (1) - (4) correspond
to (i) the identification of an Irreducible Infeasi-
ble Subset (IIS) of constraints within Φ(N, L), (ii)
finding IIS of minimum cardinality, (iii) finding all
IISs and (iv) finding the largest set of constraints
in Φ(N, L) that is feasible, respectively. An IIS
is an infeasible subset of constraints that becomes
feasible if any single constraint is removed. Prob-
lems (ii) - (iv) are NP-hard and some may even be
difficult to approximate (Amaldi and Kann, 1998;
Chinneck, 2008; Chakravarti, 1994; Tamiz et al.,
1996). We focus on problem (1) in this paper,
which we solve via IIS discovery. We keep a bi-
jective mapping from words and synsets to con-
straints such that for any given constraint, we can
uniquely identify the word or synset in Φ(N, L)
from which it was introduced. Hence, once an IIS
is isolated, we know the corresponding words or
synsets. Modern LP solvers typically can give an
IIS when a system is found to be infeasible, but
none give all IISs or the IIS of minimum size.
Example (continued). The polarity assignments
of w1, w2, w3, and w4, are consistent iff there exist
polarity distributions (P+(sz), P−(si), P0(si)) for
</bodyText>
<equation confidence="0.980530714285714">
i = 1, 2, 3, such that: y &gt; 0
ψ(w1, +): −.5P+(s1) + .5P+(s2) + y &lt; −12,
ψ(w2,0):.29P+(s1) + .01P+(s2) + .7P+(s3)&lt;21
AND .29P−(s1) + .01P−(s2) +.7P−(s3)&lt; 12,
ψ(w3, −) : −P−(s1) + y &lt; −1,
&lt;
ψ(w4, +) : −P+(s1) + y —211,
υ(s1):P+(s1)+P−(s1)&lt; 1AND P+(s1), P−(s1)&gt;0,
υ(s2):P+(s2)+P−(s2)&lt; 1AND P+(s2), P−(s2)&gt;0,
υ(s3):P+(s3)+P−(s3)&lt; 1AND P+(s3), P−(s3)&gt;0.
Upon examination, if y &gt; 0, then ψ(w3, −) im-
plies P−(s1) &gt; 21 and ψ(w4, +) implies P+(s1) &gt;
2. Then P+(s1) + P−(s1) &gt; 1, contradicting
1
</equation>
<bodyText confidence="0.991131307692308">
υ(s1). Hence, this LP system is infeasible. More-
over {ψ(w3,−), ψ(w4, +), υ(s1)1 is an IIS. Trac-
ing back we get that the set of words {w3, w41 is
inconsistent. Therefore it is an IPIS.
Isolating IPISs helps focus SL diagnosis and re-
pair efforts. Fixing SLs via IIS isolation proceeds
iteratively: (1) isolate an IIS, (2) determine a re-
pair for this IIS, (3) if the model is still infeasi-
ble, go to step (1). This approach is well sum-
marized by Greenberg’s aphorism: “diagnosis =
isolation + explanation” (Greenberg, 1993). The
proposed use requires human interaction to effect
the changes to the lexicon. One might ask if this
involvement is strictly necessary; in response we
draw a parallel between our SL debugger and a
software debugger. A software debugger can iden-
tify a known programming error, say the use of
an undefined variable. It informs the program-
mer, but it does not assign a value to the vari-
able itself. It requires the user to make the de-
sired assignment. Similarly, our debugger can
deterministically identify an inconsistent compo-
nent, but it cannot deterministically decide which
elements to adjust. In most cases, this is simply
not an objective decision. To illustrate this point,
from our example, we know that minimally one
</bodyText>
<page confidence="0.985319">
1029
</page>
<table confidence="0.961099235294118">
SL adj. adv. noun verb total
UN 3,084 940 2,340 1,812 8,176
AL 1,486 377 2 0 1,865
GI 1,337 121 1,474 1,050 3,982
OF 2,608 775 1,907 1,501 6,791
SWN 18,156 3,621 82,115 13,767 117,659
QWN 4,060 40 7,404 4,006 15,510
MWN 255 30 487 283 1,055
adj. adv. noun verb total
UN 8 14 5 8 35
AL 0 0 0 - 0
GI 2 0 0 0 2
OF 7 15 4 9 35
Table 2: SWL-Internal Inconsistencies
Inconsistency Ratios
SWLs
SSLs
</table>
<tableCaption confidence="0.99657">
Table 1: Counts of words/synsets in each SL
</tableCaption>
<bodyText confidence="0.999647166666667">
of pertinacity(−) and tenacity(+) must
be adjusted, but the determination as to which re-
quires the subjective analysis of a domain expert.
In this paper, we do not repair any of the dis-
covered inconsistencies. We focus on isolating as
many IPISs as possible.
</bodyText>
<sectionHeader confidence="0.999793" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.979333210526316">
The purpose of our experimental work is manifold,
we show that: (1) inconsistencies exist in and be-
tween SLs, (2) our algorithm is effective at uncov-
ering them in the various types of SLs proposed
in the literature, (3) fractional polarity representa-
tion is more flexible than discrete, giving orders
of magnitude fewer inconsistencies, and (4) senti-
ment analysis is significantly improved when the
inconsistencies of a basis SL are corrected.
Experiment Setup: We use four SWLs: GI,
AL, OF and their union, denoted UN, and three
SSLs: QWN, SWN and MicroWN-Op. The dis-
tribution of their entries is given in Table 1. The
MAJORITY model (Equation 3) is used in all tri-
als. This allows for direct comparison with Dragut
et al. (2012). We implemented our algorithm in
Java interfacing with the GUROBI LP solver2, and
ran the tests on a 4 x 1.70GHz core computer with
6GB of main memory.
</bodyText>
<subsectionHeader confidence="0.992551">
5.1 Inconsistencies in SWLs
</subsectionHeader>
<bodyText confidence="0.993293538461538">
In this set of experiments, we apply our algorithm
to GI, AL, OF and UN. We find no inconsisten-
cies in AL, only 2 in GI, and 35 in both UN and
OF (Table 2). (Recall that an inconsistency is a
set of words whose polarities cannot be concomi-
tantly satisfied.) These numbers do not represent
all possible inconsistencies (See discussion in Sec-
tion 4). In general, the number of IISs for an infea-
sible system can be exponential in the size of the
system Φ(N, L) (Chakravarti, 1994), however our
results suggest that in practice this does not occur.
Compared with Dragut et al. (2012), we see a
marked decrease in the number of inconsistencies.
</bodyText>
<footnote confidence="0.989688">
2www.gurobi.com
</footnote>
<table confidence="0.9989668">
SWL adj. adv. noun verb total
UN 0.67 0.89 0.85 0.81 0.78
AL 0.63 0.8 1 - 0.66
GI 0.6 0.41 0.87 0.91 0.78
OF 0.66 0.87 0.82 0.77 0.76
</table>
<tableCaption confidence="0.99996">
Table 3: SentiWordNet paired with SWLs
</tableCaption>
<bodyText confidence="0.999703833333333">
They found 249, 2, 14, and 240 inconsistencies in
UN, AL, GI, and OF, respectively. These incon-
sistencies are obtained in the first iteration of their
SAT-Solver. This shows that about 86% of incon-
sistent words in a discrete framework can be made
consistent in a fractional system.
</bodyText>
<subsectionHeader confidence="0.995862">
5.2 Inconsistencies in SSLs
</subsectionHeader>
<bodyText confidence="0.9964383125">
In this set of experiments we check the polarity
inconsistencies between SWLs and SSLs. We pair
each SSL with each of the SWLs.
SentiWordNet. SWN is an automatically gen-
erated SL with a fractional polarity annotation of
every synset in WordNet. Since SWN annotates
every synset in WordNet, there are no free vari-
ables in this trial. Each variable PP∈{+,−,0}(s)
for s E S is fully determined by SWN, so this
amounts to a constant on the left hand side of each
inequality. Our task is to simply check whether the
inequality holds between the constant on the left
and that on the right. Table 3 gives the proportion
of words from each SWL that is inconsistent with
SWN. We see there is substantial disagreement be-
tween SWN and all of the SWLs, in most cases
more than 70% disagreement. For example, 5,260
of the 6,921 words in OF do not agree with the
polarities assigned to their senses in SWN. This
outcome is deeply surprising given that all these
SLs are domain independent – no step in their
construction processes hints to a specific domain
knowledge. This opens up the door to future anal-
ysis of SL acquisition. For instance, examining
the impact that model choice (e.g., MAJORITY
vs. MAX) has on inter-lexicon agreement.
Q-WordNet. QWN gives a discrete polarity for
15,510 WordNet synsets. When a synset is an-
notated in QWN, its variables, PP∈{+,−,0}(s), are
assigned the QWN values in Φ; a feasible assign-
ment is sought for the remaining free variables. An
inconsistency may occur among a set of words, or
</bodyText>
<page confidence="0.955371">
1030
</page>
<table confidence="0.987177">
UN AL GI OF
total 345 34 139 325
</table>
<tableCaption confidence="0.999823">
Table 4: Q-WordNet paired with SWLs.
</tableCaption>
<bodyText confidence="0.999016767441861">
a set of words and synsets. Table 4 depicts the
outcome of this study. We obtain 345 inconsis-
tencies between QWN and UN. The reduced num-
ber of inconsistencies with AL (34) is explained by
their limited “overlay” (QWN has only 40 adverb
synsets). Dragut et al. (2012) reports 455 incon-
sistencies between QWN and UN, 110 more than
we found here. Again, this difference is due to the
rigidity of the discrete case, which leads to more
inconsistencies in general.
Micro-WNOp. This is a fractional SSL of
1,105 synsets from WordNet manually annotated
by five annotators. The synsets are divided into
three groups: 110 annotated by the consensus
of the annotators, 496 annotated individually by
three annotators, and 499 annotated individually
by two annotators. We take the average polarities
of groups 2 and 3 and include this data as two ad-
ditional sets of values. Table 5 gives the inconsis-
tencies per user in each group. For Groups 2 and
3, we give the average number of inconsistencies
among the users (Avg. Incons. in Table 5) as well
as the inconsistencies of the averaged annotations
(Avg. User in Table 5).
Micro-WNOp gives us an opportunity to an-
alyze the robustness of our method by compar-
ing the number of inconsistencies of the individ-
ual users to that of the averaged annotation. Intu-
itively, we expect that the average number of in-
consistencies in a group of users to be close to the
number of inconsistencies for the user averaged
annotations. This is clearly apparent from Table
5, when comparing Lines 4 and 5 in Group 2 and
Lines 3 and 4 in Group 3. For example, Group 2
has an average of 68 inconsistencies for OF, which
is very close to the number of inconsistencies, 63,
obtained for the group averaged annotations. This
study suggests a potential application of our al-
gorithm: to estimate the confidence weight (trust)
of a user’s polarity annotation. A user with good
polarity consistency receives a higher weight than
one with poor polarity consistency. This can be
applied in a multi-annotator SL scenario.
</bodyText>
<subsectionHeader confidence="0.99657">
5.3 Computation
</subsectionHeader>
<bodyText confidence="0.9994065">
We provide information about the runtime execu-
tion of our method in this section. Over all of our
experiments, the resulting systems of constraints
can be as small as 2 constraints with 2 variables
</bodyText>
<table confidence="0.999484727272727">
UN AL GI OF
Common 45 3 13 43
Group 2 User 1 88 10 59 75
User 2 50 8 24 48
User 3 97 12 64 82
Avg.Incons. 78 10 49 68
Avg. User 1,2,3 69 8 40 63
Group 3 User 4 72 9 46 60
User 5 70 8 46 59
Avg.Incons. 71 9 46 60
Avg. User 4,5 68 8 42 57
</table>
<tableCaption confidence="0.999597">
Table 5: Micro-WNOp – SWD Inconsistencies
</tableCaption>
<bodyText confidence="0.999953222222222">
and as large as 3,330 constraints with 4,946 vari-
ables. We achieve very good overall execution
times, 68 sec. on average. At its peak, our algo-
rithm requires 770MB of memory. Compared to
the SAT approach by Dragut et al. (2012), which
takes about 10 min. and requires about 10GB of
memory, our method is several orders of magni-
tude more efficient and more practical, paving the
way to building practical SL debugging tools.
</bodyText>
<subsectionHeader confidence="0.583331">
5.4 Inconsistency &amp; Sentiment Annotation
</subsectionHeader>
<bodyText confidence="0.999995838709677">
This experiment has two objectives: (1) show that
two inconsistent SLs give very different results
when applied to sentiment analysis tasks and (2)
given an inconsistent SL D, and D&apos; an improved
version of D with fewer inconsistencies, show that
D&apos; gives better results than D in sentiment anal-
ysis tasks. We use a third-party sentiment anno-
tation tool that utilizes SLs, Opinion Parser (Liu,
2012). We give the instantiations of D below.
In (1), we use the dataset aclImdb (Maas et al.,
2011), which consists of 50,000 reviews, and the
SLs UN and SWN. Let UN&apos; and SWN&apos; be the sub-
sets of UN and SWN, respectively, with the prop-
erty that they have the same set of (word, pos)
pair entries and word appears in aclImdb. UN&apos;
and SWN&apos; have 6,003 entries. We select from
aclImdb the reviews with the property that they
contain at least 50 words in SWN&apos; and UN&apos;. This
gives 516 negative and 567 positive reviews, a to-
tal of 1,083 reviews containing a total of 31,701
sentences. Opinion Parser is run on these sen-
tences using SWN&apos; and UN&apos;. We obtain that
16,741 (52.8%) sentences acquire different polar-
ities between the two SLs.
In (2), we use 110 randomly selected sentences
from aclImdb, which we manually tagged with
their overall polarities. We use OF and OF&apos;, where
OF&apos; is the version of OF after just six inconsisten-
cies are manually fixed. We run Opinion Parser on
these sentences using OF and OF&apos;. We obtain an
accuracy of 42% with OF and 47% with OF&apos;, an
</bodyText>
<page confidence="0.981005">
1031
</page>
<bodyText confidence="0.9997574">
improvement of 8.5% for just a small fraction of
corrected inconsistencies.
These two experiments show a strong correla-
tion between polarity inconsistency in SLs and its
effect on sentiment tagging in practice.
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999861833333333">
Resolving polarity inconsistencies helps to im-
prove the accuracy of sentiment analysis tasks. We
show that LP theory provides a natural framework
for the polarity consistency problem. We give a
polynomial time algorithm for deciding whether
an SL is polarity consistent. If an SL is found to
be inconsistent, we provide an efficient method to
uncover sets of words or word senses that are in-
consistent and require linguists’ attention. Effec-
tive SL debugging tools such as this will help in
the development of improved SLs for use in senti-
ment analysis tasks.
</bodyText>
<sectionHeader confidence="0.99951" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999984142857143">
We would like to thank Bing Liu for running
the experiments of Section 5.4 on his commercial
tool Opinion Parser, Christiane Fellbaum for the
discussions on polarity inconsistency, and Prasad
Sistla for the discussions on linear programming.
We would also like to thank the reviewers for their
time, effort, and insightful feedback.
</bodyText>
<sectionHeader confidence="0.998951" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999042444444444">
Rodrigo Agerri and Ana Garc´ıa-Serrano. 2010. Q-
wordnet: Extracting polarity from wordnet senses.
In LREC.
Edoardo Amaldi and Viggo Kann. 1998. On the ap-
proximability of minimizing nonzero variables or
unsatisfied relations in linear systems. Theoretical
Computer Science, 209.
A. Andreevskaia and S. Bergler. 2006. Mining word-
net for fuzzy sentiment: Sentiment tag extraction
from wordnet glosses. In EACL.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. SentiWordNet 3.0: An Enhanced Lex-
ical Resource for Sentiment Analysis and Opinion
Mining. In LREC.
Avrim Blum, John Lafferty, Mugizi Robert Rweban-
gira, and Rajashekar Reddy. 2004. Semi-supervised
learning using randomized mincuts. In ICML.
Eric Breck, Yejin Choi, and Claire Cardie. 2007. Iden-
tifying expressions of opinion in context. In IJCAI.
Juergen Bross and Heiko Ehrig. 2013. Automatic con-
struction of domain and aspect specific sentiment
lexicons for customer review mining. In CIKM.
S. Cerini, V. Compagnoni, A. Demontis, M. For-
mentelli, and G. Gandini, 2007. Language re-
sources and linguistic theory: Typology, second
language acquisition, English linguistics., chapter
Micro-WNOp: A gold standard for the evaluation of
automatically compiled lexical resources for opinion
mining. Franco Angeli Editore, Milano, IT.
Nilotpal Chakravarti. 1994. Some results concerning
post-infeasibility analysis. European Journal of Op-
erational Research, 73(1).
Yanqing Chen and Steven Skiena. 2014. Building sen-
timent lexicons for all major languages. In ACL.
John W Chinneck. 2008. Feasibility and infea-
sibility in optimization: algorithms and computa-
tional methods. International Series in Operations
Research and Management Science. Springer, Dor-
drecht.
Yejin Choi and Claire Cardie. 2009. Adapting a
polarity lexicon using integer linear programming
for domain-specific sentiment classification. In
EMNLP.
Yoonjung Choi and Janyce Wiebe. 2014. +/-
effectwordnet: Sense-level lexicon acquisition for
opinion inference. In EMNLP.
Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A
holistic lexicon-based approach to opinion mining.
In WSDM.
Eduard C. Dragut, Hong Wang, Clement Yu, Prasad
Sistla, and Weiyi Meng. 2012. Polarity consistency
checking for sentiment dictionaries. In ACL.
Weifu Du, Songbo Tan, Xueqi Cheng, and Xi-
aochun Yun. 2010. Adapting information bottle-
neck method for automatic construction of domain-
oriented sentiment lexicon. In WSDM.
A. Esuli and F. Sebastiani. 2006. Determining term
subjectivity and term orientation for opinion mining.
In EACL.
Ronen Feldman. 2013. Techniques and applications
for sentiment analysis. Commun. ACM, 56(4).
C. Fellbaum. 1998. WordNet: An On-Line Lexical
Database and Some of its Applications. MIT Press,
Cambridge, MA.
Song Feng, Jun Sak Kang, Polina Kuznetsova, and
Yejin Choi. 2013. Connotation lexicon: A dash of
sentiment beneath the surface meaning. In ACL.
Peter G´acs and Laszlo Lov´asz. 1981. Khachiyans al-
gorithm for linear programming. In Mathematical
Programming at Oberwolfach, volume 14 of Mathe-
matical Programming Studies. Springer Berlin Hei-
delberg.
</reference>
<page confidence="0.845149">
1032
</page>
<reference confidence="0.999815745098039">
Michael R. Garey and David S. Johnson. 1990. Com-
puters and Intractability; A Guide to the Theory of
NP-Completeness. W. H. Freeman &amp; Co.
Laurent E. Ghaoui, Eric Feron, and Vendataramanan
Balakrishnan. 1994. Linear Matrix Inequalities in
System &amp; Control Theory (Studies in Applied Math-
ematics), volume 15. SIAM.
Miguel A. Goberna and Margarita M. L. Rodriguez.
2006. Analyzing linear systems containing strict in-
equalities via evenly convex hulls. European Jour-
nal of Operational Research, 169(3).
Miguel A. Goberna, Valentin Jornet, and Mar-
garita M.L. Rodriguez. 2003. On linear systems
containing strict inequalities. Linear Algebra and
its Applications, 360(0).
Harvey J. Greenberg. 1993. How to analyze the results
of linear programspart 3: Infeasibility diagnosis. In-
terfaces, 23(6).
Ahmed Hassan and Dragomir Radev. 2010. Identify-
ing text polarity using random walks. In ACL.
Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In ACL.
Valentin Jijkoun, Maarten de Rijke, and Wouter
Weerkamp. 2010. Generating focused topic-
specific sentiment lexicons. In ACL.
Nobuhiro Kaji and Masaru Kitsuregawa. 2007. Build-
ing lexicon for sentiment analysis from massive col-
lection of html documents. In EMNLP-CoNLL.
J. Kamps, M. Marx, R. Mokken, and M. de Rijke.
2004. Using wordnet to measure semantic orienta-
tion of adjectives. In LREC.
Richard M. Karp. 2010. Reducibility among combina-
torial problems. In 50 Years ofInteger Programming
1958-2008 - From the Early Years to the State-of-
the-Art. Springer Berlin Heidelberg.
L. G. Khachiyan. 1980. Polynomial algorithms in lin-
ear programming. Zh. Vychisl. Mat. Mat. Fiz., 20(1).
Adam Kilgarriff. 2004. How dominant is the common-
est sense of a word? In Text, Speech, and Dialogue,
volume 3206 of Lecture Notes in Artificial Intelli-
gence.
M. Kim and E. Hovy. 2004. Determining the senti-
ment of opinions. In COLING.
Soo-Min Kim and Eduard Hovy. 2006. Identifying and
analyzing judgment opinions. In HLT-NAACL.
Beata Beigman Klebanov, Nitin Madnani, and Jill
Burstein. 2013. Using pivot-based paraphrasing
and sentiment profiles to improve a subjectivity lex-
icon for essay data. In ACL.
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Synthesis Lectures on Human Language Tech-
nologies. Morgan &amp; Claypool Publishers.
Yue Lu, Malu Castellanos, Umeshwar Dayal, and
ChengXiang Zhai. 2011. Automatic construction of
a context-aware sentiment lexicon: an optimization
approach. In WWW.
Andrew L. Maas, Raymond E. Daly, Peter Pham, Dan
Huang, Andrew Ng, and Christopher Potts. 2011.
Learning word vectors for sentiment analysis. In
ACL.
Saif Mohammad, Cody Dunne, and Bonnie Dorr.
2009. Generating high-coverage semantic orienta-
tion lexicons from overtly marked words and a the-
saurus. In EMNLP.
Wei Peng and Dae Hoon Park. 2011. Generate adjec-
tive sentiment dictionary for social media sentiment
analysis using constrained nonnegative matrix fac-
torization. In ICWSM.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009. Expanding domain sentiment lexicon through
double propagation. In IJCAI.
Mark Sanderson. 1999. The impact on retrieval ef-
fectiveness of skewed frequency distributions. ACM
Transactions on Information Systems, 17(4).
Thomas J. Schaefer. 1978. The complexity of satisfia-
bility problems. In STOC.
Alexander Schrijver. 1986. Theory of linear and in-
teger programming. John Wiley &amp; Sons, Inc., New
York, NY, USA.
P. Stone, D. Dunphy, M. Smith, and J. Ogilvie. 1966.
The General Inquirer: A computer approach to con-
tent analysis. MIT Press.
M. Taboada and J. Grieve. 2004. Analyzing appraisal
automatically. In AAAI Spring Symposium.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientations of words us-
ing spin model. In ACL.
M. Tamiz, S. J. Mardle, and D. F. Jones. 1996. De-
tecting IIS in infeasible linear programmes using
techniques from goal programming. Comput. Oper.
Res., 23(2).
Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and Ting
Liu. 2014. Building large-scale twitter-specific sen-
timent lexicon: A representation learning approach.
In COLING.
P. Turney. 2002. Thumbs up or thumbs down? seman-
tic orientation applied to unsupervised classification
of reviews. In ACL.
Gbolahan K. Williams and Sarabjot Singh Anand.
2009. Predicting the polarity strength of adjectives
using wordnet. In ICWSM.
</reference>
<page confidence="0.554076">
1033
</page>
<reference confidence="0.981011166666667">
T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recog-
nizing contextual polarity in phrase-level sentiment
analysis. In HLT/EMNLP.
Yunfang Wu and Miaomiao Wen. 2010. Disambiguat-
ing dynamic sentiment ambiguous adjectives. In
COLING.
</reference>
<page confidence="0.995236">
1034
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.094225">
<title confidence="0.684909666666667">Towards Debugging Sentiment Lexicons Andrew Computer and Information</title>
<author confidence="0.811666">Temple</author>
<email confidence="0.999403">atschneider@temple.edu</email>
<note confidence="0.282595">Eduard</note>
<title confidence="0.777786">Computer and Information</title>
<author confidence="0.877754">Temple</author>
<email confidence="0.999896">edragut@temple.edu</email>
<abstract confidence="0.9984845">Central to many sentiment analysis tasks are sentiment lexicons (SLs). SLs exhibit polarity inconsistencies. Previous work studied the problem of checking the consistency of an SL for the case when the entries have categorical labels (positive, negative or neutral) and showed that it is NPhard. In this paper, we address the more general problem, in which polarity tags take the form of a continuous distribution in the interval [0, 1]. We show that this problem is polynomial. We develop a general framework for addressing the consistency problem using linear programming (LP) theory. LP tools allow us to uncover inconsistencies efficiently, paving the way to building SL debugging tools. We show that previous work corresponds to 0-1 integer programming, a particular case of LP. Our experimental studies show a strong correlation between polarity consistency in SLs and the accuracy of sentiment tagging in practice.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rodrigo Agerri</author>
<author>Ana Garc´ıa-Serrano</author>
</authors>
<title>Qwordnet: Extracting polarity from wordnet senses.</title>
<date>2010</date>
<booktitle>In LREC.</booktitle>
<marker>Agerri, Garc´ıa-Serrano, 2010</marker>
<rawString>Rodrigo Agerri and Ana Garc´ıa-Serrano. 2010. Qwordnet: Extracting polarity from wordnet senses. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edoardo Amaldi</author>
<author>Viggo Kann</author>
</authors>
<title>On the approximability of minimizing nonzero variables or unsatisfied relations in linear systems.</title>
<date>1998</date>
<journal>Theoretical Computer Science,</journal>
<volume>209</volume>
<contexts>
<context position="24276" citStr="Amaldi and Kann, 1998" startWordPosition="4285" endWordPosition="4288"> and (4) find the largest polarity consistent subset of an inconsistent SL. In the framework of linear systems of constraints, the problems (1) - (4) correspond to (i) the identification of an Irreducible Infeasible Subset (IIS) of constraints within Φ(N, L), (ii) finding IIS of minimum cardinality, (iii) finding all IISs and (iv) finding the largest set of constraints in Φ(N, L) that is feasible, respectively. An IIS is an infeasible subset of constraints that becomes feasible if any single constraint is removed. Problems (ii) - (iv) are NP-hard and some may even be difficult to approximate (Amaldi and Kann, 1998; Chinneck, 2008; Chakravarti, 1994; Tamiz et al., 1996). We focus on problem (1) in this paper, which we solve via IIS discovery. We keep a bijective mapping from words and synsets to constraints such that for any given constraint, we can uniquely identify the word or synset in Φ(N, L) from which it was introduced. Hence, once an IIS is isolated, we know the corresponding words or synsets. Modern LP solvers typically can give an IIS when a system is found to be infeasible, but none give all IISs or the IIS of minimum size. Example (continued). The polarity assignments of w1, w2, w3, and w4, a</context>
</contexts>
<marker>Amaldi, Kann, 1998</marker>
<rawString>Edoardo Amaldi and Viggo Kann. 1998. On the approximability of minimizing nonzero variables or unsatisfied relations in linear systems. Theoretical Computer Science, 209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Andreevskaia</author>
<author>S Bergler</author>
</authors>
<title>Mining wordnet for fuzzy sentiment: Sentiment tag extraction from wordnet glosses.</title>
<date>2006</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="2074" citStr="Andreevskaia and Bergler, 2006" startWordPosition="325" endWordPosition="329">nerally reliable, but because it is labor-intensive, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010;</context>
<context position="10460" citStr="Andreevskaia and Bergler, 2006" startWordPosition="1734" endWordPosition="1738">et to be a discrete probability distribution, called a polarity distribution: P+(r), P_(r), P0(r) &gt; 0 with P+(r) + P_(r) + P0(r) = 1. P+(r), P_(r) and P0(r) represent the “likelihoods” that r is positive, negative or neutral, respectively. For instance, the WordNet synset “worthy of reliance or trust” of the adjective reliable is given the polarity distribution P+ = .375, P_ = .0 and P0 = .625 in SentiWordNet. We may drop r from the notation if the meaning is clear from context. The use of a polarity distribution to describe the polarity of a word or synset is shared with many previous works (Andreevskaia and Bergler, 2006; Baccianella et al., 2010; Kim and Hovy, 2006). 2.2 WordNet A word-synset network N is a 4-tuple (W, S, £, f) where W is a finite set of words, S is a finite set of synsets, £ C_ W x S and f is a function assigning a positive integer to each element in £. For any word w and synset s, s is a synset of w if (w, s) E £. For a pair (w, s) E £, f(w, s) is called the frequency of use of w in the sense given by s. For a word w, we let freq(w) denote the sum of all f(w, s) such that (w, s) E £. We define the relative frequency of w with s by rf(w, s) = f(w,s) If f (w, s) = 0, the frequency of each fr</context>
</contexts>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>A. Andreevskaia and S. Bergler. 2006. Mining wordnet for fuzzy sentiment: Sentiment tag extraction from wordnet glosses. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining.</title>
<date>2010</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="2418" citStr="Baccianella et al., 2010" startWordPosition="386" endWordPosition="389"> to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in pr</context>
<context position="10486" citStr="Baccianella et al., 2010" startWordPosition="1739" endWordPosition="1742">distribution, called a polarity distribution: P+(r), P_(r), P0(r) &gt; 0 with P+(r) + P_(r) + P0(r) = 1. P+(r), P_(r) and P0(r) represent the “likelihoods” that r is positive, negative or neutral, respectively. For instance, the WordNet synset “worthy of reliance or trust” of the adjective reliable is given the polarity distribution P+ = .375, P_ = .0 and P0 = .625 in SentiWordNet. We may drop r from the notation if the meaning is clear from context. The use of a polarity distribution to describe the polarity of a word or synset is shared with many previous works (Andreevskaia and Bergler, 2006; Baccianella et al., 2010; Kim and Hovy, 2006). 2.2 WordNet A word-synset network N is a 4-tuple (W, S, £, f) where W is a finite set of words, S is a finite set of synsets, £ C_ W x S and f is a function assigning a positive integer to each element in £. For any word w and synset s, s is a synset of w if (w, s) E £. For a pair (w, s) E £, f(w, s) is called the frequency of use of w in the sense given by s. For a word w, we let freq(w) denote the sum of all f(w, s) such that (w, s) E £. We define the relative frequency of w with s by rf(w, s) = f(w,s) If f (w, s) = 0, the frequency of each freq(w). synset of w is incr</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>John Lafferty</author>
<author>Mugizi Robert Rwebangira</author>
<author>Rajashekar Reddy</author>
</authors>
<title>Semi-supervised learning using randomized mincuts.</title>
<date>2004</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="2093" citStr="Blum et al., 2004" startWordPosition="330" endWordPosition="333"> is labor-intensive, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou a</context>
</contexts>
<marker>Blum, Lafferty, Rwebangira, Reddy, 2004</marker>
<rawString>Avrim Blum, John Lafferty, Mugizi Robert Rwebangira, and Rajashekar Reddy. 2004. Semi-supervised learning using randomized mincuts. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Breck</author>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Identifying expressions of opinion in context.</title>
<date>2007</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="2591" citStr="Breck et al., 2007" startWordPosition="415" endWordPosition="418">e to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We r</context>
</contexts>
<marker>Breck, Choi, Cardie, 2007</marker>
<rawString>Eric Breck, Yejin Choi, and Claire Cardie. 2007. Identifying expressions of opinion in context. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juergen Bross</author>
<author>Heiko Ehrig</author>
</authors>
<title>Automatic construction of domain and aspect specific sentiment lexicons for customer review mining.</title>
<date>2013</date>
<booktitle>In CIKM.</booktitle>
<contexts>
<context position="2614" citStr="Bross and Ehrig, 2013" startWordPosition="419" endWordPosition="422">There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as S</context>
</contexts>
<marker>Bross, Ehrig, 2013</marker>
<rawString>Juergen Bross and Heiko Ehrig. 2013. Automatic construction of domain and aspect specific sentiment lexicons for customer review mining. In CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cerini</author>
<author>V Compagnoni</author>
<author>A Demontis</author>
<author>M Formentelli</author>
<author>G Gandini</author>
</authors>
<title>Language resources and linguistic theory: Typology, second language acquisition, English linguistics., chapter Micro-WNOp: A gold standard for the evaluation of automatically compiled lexical resources for opinion mining. Franco Angeli Editore,</title>
<date>2007</date>
<location>Milano, IT.</location>
<contexts>
<context position="1768" citStr="Cerini et al., 2007" startWordPosition="269" endWordPosition="272">ntroduction Many sentiment analysis algorithms rely on sentiment lexicons (SLs), where word forms or word senses1 are tagged as conveying positive, negative or neutral sentiments. SLs are constructed by one of three methods (Liu, 2012; Feldman, 2013): (1) Manual tagging by human annotators is generally reliable, but because it is labor-intensive, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), su</context>
</contexts>
<marker>Cerini, Compagnoni, Demontis, Formentelli, Gandini, 2007</marker>
<rawString>S. Cerini, V. Compagnoni, A. Demontis, M. Formentelli, and G. Gandini, 2007. Language resources and linguistic theory: Typology, second language acquisition, English linguistics., chapter Micro-WNOp: A gold standard for the evaluation of automatically compiled lexical resources for opinion mining. Franco Angeli Editore, Milano, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nilotpal Chakravarti</author>
</authors>
<title>Some results concerning post-infeasibility analysis.</title>
<date>1994</date>
<journal>European Journal of Operational Research,</journal>
<volume>73</volume>
<issue>1</issue>
<contexts>
<context position="24311" citStr="Chakravarti, 1994" startWordPosition="4291" endWordPosition="4292">istent subset of an inconsistent SL. In the framework of linear systems of constraints, the problems (1) - (4) correspond to (i) the identification of an Irreducible Infeasible Subset (IIS) of constraints within Φ(N, L), (ii) finding IIS of minimum cardinality, (iii) finding all IISs and (iv) finding the largest set of constraints in Φ(N, L) that is feasible, respectively. An IIS is an infeasible subset of constraints that becomes feasible if any single constraint is removed. Problems (ii) - (iv) are NP-hard and some may even be difficult to approximate (Amaldi and Kann, 1998; Chinneck, 2008; Chakravarti, 1994; Tamiz et al., 1996). We focus on problem (1) in this paper, which we solve via IIS discovery. We keep a bijective mapping from words and synsets to constraints such that for any given constraint, we can uniquely identify the word or synset in Φ(N, L) from which it was introduced. Hence, once an IIS is isolated, we know the corresponding words or synsets. Modern LP solvers typically can give an IIS when a system is found to be infeasible, but none give all IISs or the IIS of minimum size. Example (continued). The polarity assignments of w1, w2, w3, and w4, are consistent iff there exist polar</context>
<context position="28795" citStr="Chakravarti, 1994" startWordPosition="5091" endWordPosition="5092">nterfacing with the GUROBI LP solver2, and ran the tests on a 4 x 1.70GHz core computer with 6GB of main memory. 5.1 Inconsistencies in SWLs In this set of experiments, we apply our algorithm to GI, AL, OF and UN. We find no inconsistencies in AL, only 2 in GI, and 35 in both UN and OF (Table 2). (Recall that an inconsistency is a set of words whose polarities cannot be concomitantly satisfied.) These numbers do not represent all possible inconsistencies (See discussion in Section 4). In general, the number of IISs for an infeasible system can be exponential in the size of the system Φ(N, L) (Chakravarti, 1994), however our results suggest that in practice this does not occur. Compared with Dragut et al. (2012), we see a marked decrease in the number of inconsistencies. 2www.gurobi.com SWL adj. adv. noun verb total UN 0.67 0.89 0.85 0.81 0.78 AL 0.63 0.8 1 - 0.66 GI 0.6 0.41 0.87 0.91 0.78 OF 0.66 0.87 0.82 0.77 0.76 Table 3: SentiWordNet paired with SWLs They found 249, 2, 14, and 240 inconsistencies in UN, AL, GI, and OF, respectively. These inconsistencies are obtained in the first iteration of their SAT-Solver. This shows that about 86% of inconsistent words in a discrete framework can be made c</context>
</contexts>
<marker>Chakravarti, 1994</marker>
<rawString>Nilotpal Chakravarti. 1994. Some results concerning post-infeasibility analysis. European Journal of Operational Research, 73(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanqing Chen</author>
<author>Steven Skiena</author>
</authors>
<title>Building sentiment lexicons for all major languages.</title>
<date>2014</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2116" citStr="Chen and Skiena, 2014" startWordPosition="334" endWordPosition="337">, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijko</context>
</contexts>
<marker>Chen, Skiena, 2014</marker>
<rawString>Yanqing Chen and Steven Skiena. 2014. Building sentiment lexicons for all major languages. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John W Chinneck</author>
</authors>
<title>Feasibility and infeasibility in optimization: algorithms and computational methods.</title>
<date>2008</date>
<booktitle>International Series in Operations Research and Management Science.</booktitle>
<publisher>Springer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="24292" citStr="Chinneck, 2008" startWordPosition="4289" endWordPosition="4290">st polarity consistent subset of an inconsistent SL. In the framework of linear systems of constraints, the problems (1) - (4) correspond to (i) the identification of an Irreducible Infeasible Subset (IIS) of constraints within Φ(N, L), (ii) finding IIS of minimum cardinality, (iii) finding all IISs and (iv) finding the largest set of constraints in Φ(N, L) that is feasible, respectively. An IIS is an infeasible subset of constraints that becomes feasible if any single constraint is removed. Problems (ii) - (iv) are NP-hard and some may even be difficult to approximate (Amaldi and Kann, 1998; Chinneck, 2008; Chakravarti, 1994; Tamiz et al., 1996). We focus on problem (1) in this paper, which we solve via IIS discovery. We keep a bijective mapping from words and synsets to constraints such that for any given constraint, we can uniquely identify the word or synset in Φ(N, L) from which it was introduced. Hence, once an IIS is isolated, we know the corresponding words or synsets. Modern LP solvers typically can give an IIS when a system is found to be infeasible, but none give all IISs or the IIS of minimum size. Example (continued). The polarity assignments of w1, w2, w3, and w4, are consistent if</context>
</contexts>
<marker>Chinneck, 2008</marker>
<rawString>John W Chinneck. 2008. Feasibility and infeasibility in optimization: algorithms and computational methods. International Series in Operations Research and Management Science. Springer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification.</title>
<date>2009</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="2637" citStr="Choi and Cardie, 2009" startWordPosition="423" endWordPosition="426">ictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons </context>
</contexts>
<marker>Choi, Cardie, 2009</marker>
<rawString>Yejin Choi and Claire Cardie. 2009. Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoonjung Choi</author>
<author>Janyce Wiebe</author>
</authors>
<title>effectwordnet: Sense-level lexicon acquisition for opinion inference.</title>
<date>2014</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="2138" citStr="Choi and Wiebe, 2014" startWordPosition="338" endWordPosition="341">s method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji </context>
</contexts>
<marker>Choi, Wiebe, 2014</marker>
<rawString>Yoonjung Choi and Janyce Wiebe. 2014. +/-effectwordnet: Sense-level lexicon acquisition for opinion inference. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In WSDM.</booktitle>
<contexts>
<context position="2656" citStr="Ding et al., 2008" startWordPosition="427" endWordPosition="430">ues (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, O</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. In WSDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard C Dragut</author>
<author>Hong Wang</author>
<author>Clement Yu</author>
<author>Prasad Sistla</author>
<author>Weiyi Meng</author>
</authors>
<title>Polarity consistency checking for sentiment dictionaries.</title>
<date>2012</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="6619" citStr="Dragut et al. (2012)" startWordPosition="1062" endWordPosition="1065">nal approach, polarity is defined as a 3-tuple of nonnegative real numbers that sum to 1, corresponding to the positive, negative, and neutral values respectively. SWN, Micro-WNOp, and Hassan and Radev (2010) employ a fractional polarity annotation. For example, the single synset of the adjective admissible in WordNet has the sentiment tags positive in QWN and (.25, .625, .125) in SWN, so here SWN gives a primarily negative polarity with some positive and less neutral polarity. We denote by PCP-D and PCP-F the polarity Figure 1: Discrete vs. fractional polarity consistency. Example taken from Dragut et al. (2012). consistency problem for the discrete and fractional polarity annotations, respectively. Dragut et al. (2012) introduces the PCP for domain independent SLs and gives a solution to a particular form of the PCP-D, but that method cannot solve PCP-F. For example, they show that the adjectives laughable, comic, and risible (Figure 1) constitute an inconsistency in the discrete case. AL gives positive polarity for laughable and OF gives negative for comic. If s2 is not positive then laughable is not positive and if s2 is not negative then comic is not negative, so there is no assignment of s2 that</context>
<context position="8013" citStr="Dragut et al., 2012" startWordPosition="1301" endWordPosition="1304">(0, 1, 0), where the meaning of the second tag, for instance, is that s2 is .66 positive, .34 negative, and 0 neutral. We thus see that the discrete polarity annotation is rigid and leads to more inconsistencies, whereas the fractional annotation captures more naturally the polarity spectrum of a word or synset. In this paper we give a solution to the PCP-F. The differences between our solution and that of Dragut et al. (2012) give some insight into the general differences between the fractional and discrete problems. First, the discrete case is intractable, i.e., computationally NP-complete (Dragut et al., 2012); we show in this paper (Section 3.2) that the fractional case is tractable (solvable in polynomial time). Second, the PCP-D is solved in Dragut et al. (2012) by translation to the Boolean satisfiability problem (SAT) (Schaefer, 1978); here we recast the PCPF in terms of LP theory. Third, we show that the LP framework is a natural setting for the PCP as a whole, and that the PCP-D corresponds to the 0- 1 integer LP problem (Section 3.2), a classic NPcomplete problem (Karp, 2010). Our experiments (Section 5.4) show that correcting even a small number of inconsistencies can greatly improve the a</context>
<context position="13671" citStr="Dragut et al., 2012" startWordPosition="2365" endWordPosition="2368">eliable and the other two incorrect. Therefore, instead of claiming to pinpoint an exact polarity distribution for a word, we propose to set a boundary on its variation. This establishes a 1026 range of values, instead of a single point, in which SLs can be said to agree. Thus, for a word w, we can define � + if P+ &gt; P− polarity(w) = − (2) if P− &gt; P+ which we refer to as MAX POL. This model is adopted either explicitly or implicitly by numerous works (Hassan and Radev, 2010; Kim and Hovy, 2004; Kim and Hovy, 2006; Qiu et al., 2009). Another model is the majority sense model, called MAJORITY, (Dragut et al., 2012), where polarity(w) + if P+ &gt; P− + P0 = Sl − if P− &gt; P+ + P0 (3) Another polarity model, MAX, is defined as � + if P+ &gt;P− &amp; P+ &gt;P0 polarity(w)= − if P−&gt;P+ &amp;P−&gt;P0 (4) For instance, reliable conveys positive polarity according to MAX POL, since P+ &gt; P−, but neutral according to MAJORITY. When the condition of being neither positive nor negative can be phrased as a conjunction of linear inequalities, as is the case with MAJORITY and MAX POL, then we define neutral as not positive and not negative. These model definitions can be applied to synsets as well. 2.5 Polarity Consistency Definition Inste</context>
<context position="21150" citStr="Dragut et al., 2012" startWordPosition="3753" endWordPosition="3756"> translation algorithm converts the PCP into an LP problem on the order of O(|E|), a polynomial time conversion. The general class of linear programming problems includes subclasses that are NP-hard, such as the integer linear programming (ILP) problems, as well as polynomial solvable subclasses. We observe that our problem is represented by a system of rational linear inequalities. This class of LP problems is solvable in polynomial time (Khachiyan, 1980; G´acs and Lov´asz, 1981). This (informally) proves that the PCP-F is solvable in polynomial time. PCP is NP-complete in the discrete case (Dragut et al., 2012). This is not surprising since in our LP formulation of the minimize cTx subject to Ax ≤ b (6) and x ≥ 0 3.1 Translation to LP In our problem, x is the concatenation of all the triplets hP+(r), P−(r), P0(r)i for all r ∈ W ∪ S. Eliminate Word Related Variables. For each word w ∈ L we replace P+(w), P−(w) and P0(w) with their corresponding expressions according to Equation 1; then the linear system Φ0(N, L) has only the synset variables P+(s), P−(s) and P0(s) for s ∈ S. Example (continued). Using the relative frequencies of Figure 2 in Equation 1 we get: ψ(w1,+)= {−.5P+(s1) − .5P+(s2) &lt; −12}, ψ(</context>
<context position="22392" citStr="Dragut et al. (2012)" startWordPosition="3976" endWordPosition="3979">(s2)+.7P+(s3)≤ 12, .29P−(s1) + .01P−(s2) + .7P−(s3) ≤ ψ(w3,−)= {−P−(s1) &lt; − 1 2}, and ψ(w4,+)= {−P+(s1) &lt; −1 2}. 1028 PCP, the discrete case corresponds to the 0-1 integer programming (BIP) subclass. (Recall that in the discrete case each synset has a unique polarity.) BIP is the special case of integer programming where variables are required to be 0 or 1. BIP is a classic NP-hard problem (Garey and Johnson, 1990). We summarize these statements in the following theorem. Theorem 2. The PCP-F problem is P and the PCP-D is NP-complete. We proved a more general and more comprehensive result than Dragut et al. (2012). The PCP solved by Dragut et al. (2012) is a particular case of PCP-D: it can be obtained by instantiating our framework with the MAJORITY model (Equation 3) and requiring each synset to take a unique polarity. We believe that the ability to encompass both fractional and discrete cases within one framework, that of LP, is an important contribution, because it helps to give structure to the general problem of polarity consistency and to contextualize the difference between the approaches. 4 Towards Debugging SLs Simply stating that an SL is inconsistent is of little practical use unless accomp</context>
<context position="28137" citStr="Dragut et al. (2012)" startWordPosition="4968" endWordPosition="4971">(2) our algorithm is effective at uncovering them in the various types of SLs proposed in the literature, (3) fractional polarity representation is more flexible than discrete, giving orders of magnitude fewer inconsistencies, and (4) sentiment analysis is significantly improved when the inconsistencies of a basis SL are corrected. Experiment Setup: We use four SWLs: GI, AL, OF and their union, denoted UN, and three SSLs: QWN, SWN and MicroWN-Op. The distribution of their entries is given in Table 1. The MAJORITY model (Equation 3) is used in all trials. This allows for direct comparison with Dragut et al. (2012). We implemented our algorithm in Java interfacing with the GUROBI LP solver2, and ran the tests on a 4 x 1.70GHz core computer with 6GB of main memory. 5.1 Inconsistencies in SWLs In this set of experiments, we apply our algorithm to GI, AL, OF and UN. We find no inconsistencies in AL, only 2 in GI, and 35 in both UN and OF (Table 2). (Recall that an inconsistency is a set of words whose polarities cannot be concomitantly satisfied.) These numbers do not represent all possible inconsistencies (See discussion in Section 4). In general, the number of IISs for an infeasible system can be exponen</context>
<context position="31310" citStr="Dragut et al. (2012)" startWordPosition="5533" endWordPosition="5536">et. QWN gives a discrete polarity for 15,510 WordNet synsets. When a synset is annotated in QWN, its variables, PP∈{+,−,0}(s), are assigned the QWN values in Φ; a feasible assignment is sought for the remaining free variables. An inconsistency may occur among a set of words, or 1030 UN AL GI OF total 345 34 139 325 Table 4: Q-WordNet paired with SWLs. a set of words and synsets. Table 4 depicts the outcome of this study. We obtain 345 inconsistencies between QWN and UN. The reduced number of inconsistencies with AL (34) is explained by their limited “overlay” (QWN has only 40 adverb synsets). Dragut et al. (2012) reports 455 inconsistencies between QWN and UN, 110 more than we found here. Again, this difference is due to the rigidity of the discrete case, which leads to more inconsistencies in general. Micro-WNOp. This is a fractional SSL of 1,105 synsets from WordNet manually annotated by five annotators. The synsets are divided into three groups: 110 annotated by the consensus of the annotators, 496 annotated individually by three annotators, and 499 annotated individually by two annotators. We take the average polarities of groups 2 and 3 and include this data as two additional sets of values. Tabl</context>
<context position="33792" citStr="Dragut et al. (2012)" startWordPosition="5984" endWordPosition="5987">er all of our experiments, the resulting systems of constraints can be as small as 2 constraints with 2 variables UN AL GI OF Common 45 3 13 43 Group 2 User 1 88 10 59 75 User 2 50 8 24 48 User 3 97 12 64 82 Avg.Incons. 78 10 49 68 Avg. User 1,2,3 69 8 40 63 Group 3 User 4 72 9 46 60 User 5 70 8 46 59 Avg.Incons. 71 9 46 60 Avg. User 4,5 68 8 42 57 Table 5: Micro-WNOp – SWD Inconsistencies and as large as 3,330 constraints with 4,946 variables. We achieve very good overall execution times, 68 sec. on average. At its peak, our algorithm requires 770MB of memory. Compared to the SAT approach by Dragut et al. (2012), which takes about 10 min. and requires about 10GB of memory, our method is several orders of magnitude more efficient and more practical, paving the way to building practical SL debugging tools. 5.4 Inconsistency &amp; Sentiment Annotation This experiment has two objectives: (1) show that two inconsistent SLs give very different results when applied to sentiment analysis tasks and (2) given an inconsistent SL D, and D&apos; an improved version of D with fewer inconsistencies, show that D&apos; gives better results than D in sentiment analysis tasks. We use a third-party sentiment annotation tool that util</context>
</contexts>
<marker>Dragut, Wang, Yu, Sistla, Meng, 2012</marker>
<rawString>Eduard C. Dragut, Hong Wang, Clement Yu, Prasad Sistla, and Weiyi Meng. 2012. Polarity consistency checking for sentiment dictionaries. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weifu Du</author>
<author>Songbo Tan</author>
<author>Xueqi Cheng</author>
<author>Xiaochun Yun</author>
</authors>
<title>Adapting information bottleneck method for automatic construction of domainoriented sentiment lexicon.</title>
<date>2010</date>
<booktitle>In WSDM.</booktitle>
<contexts>
<context position="2673" citStr="Du et al., 2010" startWordPosition="431" endWordPosition="434">nd Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, OF, and AL, and to</context>
</contexts>
<marker>Du, Tan, Cheng, Yun, 2010</marker>
<rawString>Weifu Du, Songbo Tan, Xueqi Cheng, and Xiaochun Yun. 2010. Adapting information bottleneck method for automatic construction of domainoriented sentiment lexicon. In WSDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Esuli</author>
<author>F Sebastiani</author>
</authors>
<title>Determining term subjectivity and term orientation for opinion mining.</title>
<date>2006</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="2166" citStr="Esuli and Sebastiani, 2006" startWordPosition="342" endWordPosition="345">small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Kleba</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>A. Esuli and F. Sebastiani. 2006. Determining term subjectivity and term orientation for opinion mining. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
</authors>
<title>Techniques and applications for sentiment analysis.</title>
<date>2013</date>
<journal>Commun. ACM,</journal>
<volume>56</volume>
<issue>4</issue>
<contexts>
<context position="1398" citStr="Feldman, 2013" startWordPosition="211" endWordPosition="212"> programming (LP) theory. LP tools allow us to uncover inconsistencies efficiently, paving the way to building SL debugging tools. We show that previous work corresponds to 0-1 integer programming, a particular case of LP. Our experimental studies show a strong correlation between polarity consistency in SLs and the accuracy of sentiment tagging in practice. 1 Introduction Many sentiment analysis algorithms rely on sentiment lexicons (SLs), where word forms or word senses1 are tagged as conveying positive, negative or neutral sentiments. SLs are constructed by one of three methods (Liu, 2012; Feldman, 2013): (1) Manual tagging by human annotators is generally reliable, but because it is labor-intensive, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There</context>
</contexts>
<marker>Feldman, 2013</marker>
<rawString>Ronen Feldman. 2013. Techniques and applications for sentiment analysis. Commun. ACM, 56(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An On-Line Lexical Database and Some of its Applications.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2364" citStr="Fellbaum, 1998" startWordPosition="380" endWordPosition="381">erini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An On-Line Lexical Database and Some of its Applications. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Jun Sak Kang</author>
<author>Polina Kuznetsova</author>
<author>Yejin Choi</author>
</authors>
<title>Connotation lexicon: A dash of sentiment beneath the surface meaning.</title>
<date>2013</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2185" citStr="Feng et al., 2013" startWordPosition="346" endWordPosition="349"> few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; L</context>
</contexts>
<marker>Feng, Kang, Kuznetsova, Choi, 2013</marker>
<rawString>Song Feng, Jun Sak Kang, Polina Kuznetsova, and Yejin Choi. 2013. Connotation lexicon: A dash of sentiment beneath the surface meaning. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter G´acs</author>
<author>Laszlo Lov´asz</author>
</authors>
<title>Khachiyans algorithm for linear programming.</title>
<date>1981</date>
<booktitle>In Mathematical Programming at Oberwolfach,</booktitle>
<volume>14</volume>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>G´acs, Lov´asz, 1981</marker>
<rawString>Peter G´acs and Laszlo Lov´asz. 1981. Khachiyans algorithm for linear programming. In Mathematical Programming at Oberwolfach, volume 14 of Mathematical Programming Studies. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Garey</author>
<author>David S Johnson</author>
</authors>
<title>Computers and Intractability; A Guide to the Theory of NP-Completeness.</title>
<date>1990</date>
<contexts>
<context position="22190" citStr="Garey and Johnson, 1990" startWordPosition="3940" endWordPosition="3943">y the synset variables P+(s), P−(s) and P0(s) for s ∈ S. Example (continued). Using the relative frequencies of Figure 2 in Equation 1 we get: ψ(w1,+)= {−.5P+(s1) − .5P+(s2) &lt; −12}, ψ(w2,0)={.29P+(s1)+.01P+(s2)+.7P+(s3)≤ 12, .29P−(s1) + .01P−(s2) + .7P−(s3) ≤ ψ(w3,−)= {−P−(s1) &lt; − 1 2}, and ψ(w4,+)= {−P+(s1) &lt; −1 2}. 1028 PCP, the discrete case corresponds to the 0-1 integer programming (BIP) subclass. (Recall that in the discrete case each synset has a unique polarity.) BIP is the special case of integer programming where variables are required to be 0 or 1. BIP is a classic NP-hard problem (Garey and Johnson, 1990). We summarize these statements in the following theorem. Theorem 2. The PCP-F problem is P and the PCP-D is NP-complete. We proved a more general and more comprehensive result than Dragut et al. (2012). The PCP solved by Dragut et al. (2012) is a particular case of PCP-D: it can be obtained by instantiating our framework with the MAJORITY model (Equation 3) and requiring each synset to take a unique polarity. We believe that the ability to encompass both fractional and discrete cases within one framework, that of LP, is an important contribution, because it helps to give structure to the gene</context>
</contexts>
<marker>Garey, Johnson, 1990</marker>
<rawString>Michael R. Garey and David S. Johnson. 1990. Computers and Intractability; A Guide to the Theory of NP-Completeness. W. H. Freeman &amp; Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurent E Ghaoui</author>
<author>Eric Feron</author>
<author>Vendataramanan Balakrishnan</author>
</authors>
<date>1994</date>
<booktitle>Linear Matrix Inequalities in System &amp; Control Theory (Studies in Applied Mathematics),</booktitle>
<volume>15</volume>
<publisher>SIAM.</publisher>
<contexts>
<context position="19290" citStr="Ghaoui et al., 1994" startWordPosition="3398" endWordPosition="3401">s of constraints (see discussion in Section 5.3). Instead, we can show that the system F obtained by performing the following two-step transformation is equivalent to Φ0(N, L), in the sense that F is feasible iff Φ0(N, L) is feasible. For every s ∈ S, (Step 1) we convert each P+(s)+P−(s)+P0(s)=1 to P+(s)+P−(s)≤1, and (Step 2) we replace every P0(s) in Φ0(N, L) with 1 −P+(s) −P−(s). Strict Inequalities. Strict inequalities are not allowed in LP and their presence in inequality systems in general poses difficulties to inequality system solvers (Goberna et al., 2003; Goberna and Rodriguez, 2006; Ghaoui et al., 1994). Fortunately results developed by the LP community allow us to overcome this obstacle and maintain the flexibility of our proposed model. We introduce a new variable y ≥ 0, and for every strict constraint of the form aTx &lt; b, we rewrite the inequality as aTx + y ≤ b. Let Φ00(N, L) be this new system of constraints. We modify the objective function (previously null) to maximize y (i.e., minimize −y). Denote by F0 the LP that maximizes y subject to Φ00(N, L). We can show that Φ0(N, L) is feasible iff F0 is feasible and y =6 0. A sketch of the proof is as follows: if y &gt; 0 then aTx + y ≤ b impli</context>
</contexts>
<marker>Ghaoui, Feron, Balakrishnan, 1994</marker>
<rawString>Laurent E. Ghaoui, Eric Feron, and Vendataramanan Balakrishnan. 1994. Linear Matrix Inequalities in System &amp; Control Theory (Studies in Applied Mathematics), volume 15. SIAM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miguel A Goberna</author>
<author>Margarita M L Rodriguez</author>
</authors>
<title>Analyzing linear systems containing strict inequalities via evenly convex hulls.</title>
<date>2006</date>
<journal>European Journal of Operational Research,</journal>
<volume>169</volume>
<issue>3</issue>
<contexts>
<context position="19268" citStr="Goberna and Rodriguez, 2006" startWordPosition="3394" endWordPosition="3397">ce Φ0(N, L) may have thousands of constraints (see discussion in Section 5.3). Instead, we can show that the system F obtained by performing the following two-step transformation is equivalent to Φ0(N, L), in the sense that F is feasible iff Φ0(N, L) is feasible. For every s ∈ S, (Step 1) we convert each P+(s)+P−(s)+P0(s)=1 to P+(s)+P−(s)≤1, and (Step 2) we replace every P0(s) in Φ0(N, L) with 1 −P+(s) −P−(s). Strict Inequalities. Strict inequalities are not allowed in LP and their presence in inequality systems in general poses difficulties to inequality system solvers (Goberna et al., 2003; Goberna and Rodriguez, 2006; Ghaoui et al., 1994). Fortunately results developed by the LP community allow us to overcome this obstacle and maintain the flexibility of our proposed model. We introduce a new variable y ≥ 0, and for every strict constraint of the form aTx &lt; b, we rewrite the inequality as aTx + y ≤ b. Let Φ00(N, L) be this new system of constraints. We modify the objective function (previously null) to maximize y (i.e., minimize −y). Denote by F0 the LP that maximizes y subject to Φ00(N, L). We can show that Φ0(N, L) is feasible iff F0 is feasible and y =6 0. A sketch of the proof is as follows: if y &gt; 0 </context>
</contexts>
<marker>Goberna, Rodriguez, 2006</marker>
<rawString>Miguel A. Goberna and Margarita M. L. Rodriguez. 2006. Analyzing linear systems containing strict inequalities via evenly convex hulls. European Journal of Operational Research, 169(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miguel A Goberna</author>
<author>Valentin Jornet</author>
<author>Margarita M L Rodriguez</author>
</authors>
<title>On linear systems containing strict inequalities. Linear Algebra and its Applications,</title>
<date>2003</date>
<volume>360</volume>
<issue>0</issue>
<contexts>
<context position="19239" citStr="Goberna et al., 2003" startWordPosition="3390" endWordPosition="3393">computation impact since Φ0(N, L) may have thousands of constraints (see discussion in Section 5.3). Instead, we can show that the system F obtained by performing the following two-step transformation is equivalent to Φ0(N, L), in the sense that F is feasible iff Φ0(N, L) is feasible. For every s ∈ S, (Step 1) we convert each P+(s)+P−(s)+P0(s)=1 to P+(s)+P−(s)≤1, and (Step 2) we replace every P0(s) in Φ0(N, L) with 1 −P+(s) −P−(s). Strict Inequalities. Strict inequalities are not allowed in LP and their presence in inequality systems in general poses difficulties to inequality system solvers (Goberna et al., 2003; Goberna and Rodriguez, 2006; Ghaoui et al., 1994). Fortunately results developed by the LP community allow us to overcome this obstacle and maintain the flexibility of our proposed model. We introduce a new variable y ≥ 0, and for every strict constraint of the form aTx &lt; b, we rewrite the inequality as aTx + y ≤ b. Let Φ00(N, L) be this new system of constraints. We modify the objective function (previously null) to maximize y (i.e., minimize −y). Denote by F0 the LP that maximizes y subject to Φ00(N, L). We can show that Φ0(N, L) is feasible iff F0 is feasible and y =6 0. A sketch of the p</context>
</contexts>
<marker>Goberna, Jornet, Rodriguez, 2003</marker>
<rawString>Miguel A. Goberna, Valentin Jornet, and Margarita M.L. Rodriguez. 2003. On linear systems containing strict inequalities. Linear Algebra and its Applications, 360(0).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harvey J Greenberg</author>
</authors>
<title>How to analyze the results of linear programspart 3: Infeasibility diagnosis.</title>
<date>1993</date>
<journal>Interfaces,</journal>
<volume>23</volume>
<issue>6</issue>
<contexts>
<context position="25964" citStr="Greenberg, 1993" startWordPosition="4585" endWordPosition="4586"> implies P−(s1) &gt; 21 and ψ(w4, +) implies P+(s1) &gt; 2. Then P+(s1) + P−(s1) &gt; 1, contradicting 1 υ(s1). Hence, this LP system is infeasible. Moreover {ψ(w3,−), ψ(w4, +), υ(s1)1 is an IIS. Tracing back we get that the set of words {w3, w41 is inconsistent. Therefore it is an IPIS. Isolating IPISs helps focus SL diagnosis and repair efforts. Fixing SLs via IIS isolation proceeds iteratively: (1) isolate an IIS, (2) determine a repair for this IIS, (3) if the model is still infeasible, go to step (1). This approach is well summarized by Greenberg’s aphorism: “diagnosis = isolation + explanation” (Greenberg, 1993). The proposed use requires human interaction to effect the changes to the lexicon. One might ask if this involvement is strictly necessary; in response we draw a parallel between our SL debugger and a software debugger. A software debugger can identify a known programming error, say the use of an undefined variable. It informs the programmer, but it does not assign a value to the variable itself. It requires the user to make the desired assignment. Similarly, our debugger can deterministically identify an inconsistent component, but it cannot deterministically decide which elements to adjust.</context>
</contexts>
<marker>Greenberg, 1993</marker>
<rawString>Harvey J. Greenberg. 1993. How to analyze the results of linear programspart 3: Infeasibility diagnosis. Interfaces, 23(6).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Dragomir Radev</author>
</authors>
<title>Identifying text polarity using random walks.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2209" citStr="Hassan and Radev, 2010" startWordPosition="350" endWordPosition="354">, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and</context>
<context position="6207" citStr="Hassan and Radev (2010)" startWordPosition="991" endWordPosition="994"> to focus on in “debugging” the lexicon. Background and Previous Work Sentiment resources have taken two basic approaches to polarity annotation: discrete and fractional. In the discrete approach, polarity is defined to be one of the discrete values positive, negative, or neutral. A word or a synset takes exactly one of the three values. QWN, AL, GI, and OF follow the discrete polarity annotation. In the fractional approach, polarity is defined as a 3-tuple of nonnegative real numbers that sum to 1, corresponding to the positive, negative, and neutral values respectively. SWN, Micro-WNOp, and Hassan and Radev (2010) employ a fractional polarity annotation. For example, the single synset of the adjective admissible in WordNet has the sentiment tags positive in QWN and (.25, .625, .125) in SWN, so here SWN gives a primarily negative polarity with some positive and less neutral polarity. We denote by PCP-D and PCP-F the polarity Figure 1: Discrete vs. fractional polarity consistency. Example taken from Dragut et al. (2012). consistency problem for the discrete and fractional polarity annotations, respectively. Dragut et al. (2012) introduces the PCP for domain independent SLs and gives a solution to a parti</context>
<context position="13529" citStr="Hassan and Radev, 2010" startWordPosition="2340" endWordPosition="2343">5) give virtually identical information to a sentiment analyst, it seems unreasonable to expect exactly one to be the correct polarity tag for reliable and the other two incorrect. Therefore, instead of claiming to pinpoint an exact polarity distribution for a word, we propose to set a boundary on its variation. This establishes a 1026 range of values, instead of a single point, in which SLs can be said to agree. Thus, for a word w, we can define � + if P+ &gt; P− polarity(w) = − (2) if P− &gt; P+ which we refer to as MAX POL. This model is adopted either explicitly or implicitly by numerous works (Hassan and Radev, 2010; Kim and Hovy, 2004; Kim and Hovy, 2006; Qiu et al., 2009). Another model is the majority sense model, called MAJORITY, (Dragut et al., 2012), where polarity(w) + if P+ &gt; P− + P0 = Sl − if P− &gt; P+ + P0 (3) Another polarity model, MAX, is defined as � + if P+ &gt;P− &amp; P+ &gt;P0 polarity(w)= − if P−&gt;P+ &amp;P−&gt;P0 (4) For instance, reliable conveys positive polarity according to MAX POL, since P+ &gt; P−, but neutral according to MAJORITY. When the condition of being neither positive nor negative can be phrased as a conjunction of linear inequalities, as is the case with MAJORITY and MAX POL, then we define </context>
</contexts>
<marker>Hassan, Radev, 2010</marker>
<rawString>Ahmed Hassan and Dragomir Radev. 2010. Identifying text polarity using random walks. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2709" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="435" endWordPosition="438"> Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, OF, and AL, and to the latter as Sentiment Sense Lexio</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the semantic orientation of adjectives. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
<author>Maarten de Rijke</author>
<author>Wouter Weerkamp</author>
</authors>
<title>Generating focused topicspecific sentiment lexicons.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<marker>Jijkoun, de Rijke, Weerkamp, 2010</marker>
<rawString>Valentin Jijkoun, Maarten de Rijke, and Wouter Weerkamp. 2010. Generating focused topicspecific sentiment lexicons. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuhiro Kaji</author>
<author>Masaru Kitsuregawa</author>
</authors>
<title>Building lexicon for sentiment analysis from massive collection of html documents.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL.</booktitle>
<contexts>
<context position="2759" citStr="Kaji and Kitsuregawa, 2007" startWordPosition="443" endWordPosition="446"> 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, OF, and AL, and to the latter as Sentiment Sense Lexions (SSLs), e.g., SWN, QWN, and Micro-WNOp. Besides</context>
</contexts>
<marker>Kaji, Kitsuregawa, 2007</marker>
<rawString>Nobuhiro Kaji and Masaru Kitsuregawa. 2007. Building lexicon for sentiment analysis from massive collection of html documents. In EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kamps</author>
<author>M Marx</author>
<author>R Mokken</author>
<author>M de Rijke</author>
</authors>
<title>Using wordnet to measure semantic orientation of adjectives.</title>
<date>2004</date>
<booktitle>In LREC.</booktitle>
<marker>Kamps, Marx, Mokken, de Rijke, 2004</marker>
<rawString>J. Kamps, M. Marx, R. Mokken, and M. de Rijke. 2004. Using wordnet to measure semantic orientation of adjectives. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard M Karp</author>
</authors>
<title>Reducibility among combinatorial problems.</title>
<date>2010</date>
<booktitle>In 50 Years ofInteger Programming 1958-2008 - From the Early Years to the State-ofthe-Art.</booktitle>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="8496" citStr="Karp, 2010" startWordPosition="1389" endWordPosition="1390">actional and discrete problems. First, the discrete case is intractable, i.e., computationally NP-complete (Dragut et al., 2012); we show in this paper (Section 3.2) that the fractional case is tractable (solvable in polynomial time). Second, the PCP-D is solved in Dragut et al. (2012) by translation to the Boolean satisfiability problem (SAT) (Schaefer, 1978); here we recast the PCPF in terms of LP theory. Third, we show that the LP framework is a natural setting for the PCP as a whole, and that the PCP-D corresponds to the 0- 1 integer LP problem (Section 3.2), a classic NPcomplete problem (Karp, 2010). Our experiments (Section 5.4) show that correcting even a small number of inconsistencies can greatly improve the accuracy of sentiment annotation tasks. We implement our algorithm as a versatile tool for debugging SLs, which helps locate the laughable : positive risible : ? comic : negative 1 0.5 0.5 0.6 0.4 s1 : “so unreasonable as to invite derision” s2 : “of or relating to or characteristic of comedy” s3 : “arousing or provoking laughter” 1025 sources of error in SLs. We apply our algorithm to both SWLs and SSLs and demonstrate the usefulness of our approach to improving SLs. The main co</context>
</contexts>
<marker>Karp, 2010</marker>
<rawString>Richard M. Karp. 2010. Reducibility among combinatorial problems. In 50 Years ofInteger Programming 1958-2008 - From the Early Years to the State-ofthe-Art. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L G Khachiyan</author>
</authors>
<title>Polynomial algorithms in linear programming.</title>
<date>1980</date>
<journal>Zh. Vychisl. Mat. Mat. Fiz.,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="20989" citStr="Khachiyan, 1980" startWordPosition="3729" endWordPosition="3730">to an LP solver. Theorem 1. Sentiment lexicon L is polarity consistent iff Φ(N, L) is feasible. 3.2 Time Complexity For the network N and an SL L, the above translation algorithm converts the PCP into an LP problem on the order of O(|E|), a polynomial time conversion. The general class of linear programming problems includes subclasses that are NP-hard, such as the integer linear programming (ILP) problems, as well as polynomial solvable subclasses. We observe that our problem is represented by a system of rational linear inequalities. This class of LP problems is solvable in polynomial time (Khachiyan, 1980; G´acs and Lov´asz, 1981). This (informally) proves that the PCP-F is solvable in polynomial time. PCP is NP-complete in the discrete case (Dragut et al., 2012). This is not surprising since in our LP formulation of the minimize cTx subject to Ax ≤ b (6) and x ≥ 0 3.1 Translation to LP In our problem, x is the concatenation of all the triplets hP+(r), P−(r), P0(r)i for all r ∈ W ∪ S. Eliminate Word Related Variables. For each word w ∈ L we replace P+(w), P−(w) and P0(w) with their corresponding expressions according to Equation 1; then the linear system Φ0(N, L) has only the synset variables </context>
</contexts>
<marker>Khachiyan, 1980</marker>
<rawString>L. G. Khachiyan. 1980. Polynomial algorithms in linear programming. Zh. Vychisl. Mat. Mat. Fiz., 20(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>How dominant is the commonest sense of a word?</title>
<date>2004</date>
<booktitle>In Text, Speech, and Dialogue,</booktitle>
<volume>3206</volume>
<contexts>
<context position="11909" citStr="Kilgarriff, 2004" startWordPosition="2044" endWordPosition="2045">synsets), and we make the assumption that this relation takes the form of a linear function. Thus, for w E W and p E {+, −, 0}, the polarity distribution of w is defined as: �Pp(w) = g(w, s) · Pp(s), (1) sESw where Pp(s) is the polarity value of synset s with polarity p and g(w, s) is a rational number. For example, g can be the relative frequency of s with respect to w in WordNet: g(w, s) = rf(w, s); bw E W, s E S. Alternatively, for each word w we can draw g(w, ·) from a Zipfian distribution, following the observation that the distribution of word senses roughly follows a Zipfian power-law (Kilgarriff, 2004; Sanderson, 1999). In this paper, we will assume g(w, s) = rf(w, s). For example, the three synsets of the adjective reliable with relative frequencies 911, 111, and 111, respectively, are given the distributions (.375, 0, .625), (.5, 0, .5), and (.625, 0, .375) in SentiWordNet. So for reliable we have P+ = 110.375 + 1 9 110.5 + 1110.625 Pz� 0.41, P_ = 0, and P0 = 9110.625 + 1110.5 + 1110.375 Pz� 0.59. 2.4 Modeling Sentiment Orientation in SLs Words and synsets have unique polarities in some SLs, e.g., AL and OF. For instance, reliable has positive polarity in AL, GI, and OF. The question is:</context>
</contexts>
<marker>Kilgarriff, 2004</marker>
<rawString>Adam Kilgarriff. 2004. How dominant is the commonest sense of a word? In Text, Speech, and Dialogue, volume 3206 of Lecture Notes in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kim</author>
<author>E Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="13549" citStr="Kim and Hovy, 2004" startWordPosition="2344" endWordPosition="2347">cal information to a sentiment analyst, it seems unreasonable to expect exactly one to be the correct polarity tag for reliable and the other two incorrect. Therefore, instead of claiming to pinpoint an exact polarity distribution for a word, we propose to set a boundary on its variation. This establishes a 1026 range of values, instead of a single point, in which SLs can be said to agree. Thus, for a word w, we can define � + if P+ &gt; P− polarity(w) = − (2) if P− &gt; P+ which we refer to as MAX POL. This model is adopted either explicitly or implicitly by numerous works (Hassan and Radev, 2010; Kim and Hovy, 2004; Kim and Hovy, 2006; Qiu et al., 2009). Another model is the majority sense model, called MAJORITY, (Dragut et al., 2012), where polarity(w) + if P+ &gt; P− + P0 = Sl − if P− &gt; P+ + P0 (3) Another polarity model, MAX, is defined as � + if P+ &gt;P− &amp; P+ &gt;P0 polarity(w)= − if P−&gt;P+ &amp;P−&gt;P0 (4) For instance, reliable conveys positive polarity according to MAX POL, since P+ &gt; P−, but neutral according to MAJORITY. When the condition of being neither positive nor negative can be phrased as a conjunction of linear inequalities, as is the case with MAJORITY and MAX POL, then we define neutral as not posit</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>M. Kim and E. Hovy. 2004. Determining the sentiment of opinions. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Identifying and analyzing judgment opinions.</title>
<date>2006</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="10507" citStr="Kim and Hovy, 2006" startWordPosition="1743" endWordPosition="1746">arity distribution: P+(r), P_(r), P0(r) &gt; 0 with P+(r) + P_(r) + P0(r) = 1. P+(r), P_(r) and P0(r) represent the “likelihoods” that r is positive, negative or neutral, respectively. For instance, the WordNet synset “worthy of reliance or trust” of the adjective reliable is given the polarity distribution P+ = .375, P_ = .0 and P0 = .625 in SentiWordNet. We may drop r from the notation if the meaning is clear from context. The use of a polarity distribution to describe the polarity of a word or synset is shared with many previous works (Andreevskaia and Bergler, 2006; Baccianella et al., 2010; Kim and Hovy, 2006). 2.2 WordNet A word-synset network N is a 4-tuple (W, S, £, f) where W is a finite set of words, S is a finite set of synsets, £ C_ W x S and f is a function assigning a positive integer to each element in £. For any word w and synset s, s is a synset of w if (w, s) E £. For a pair (w, s) E £, f(w, s) is called the frequency of use of w in the sense given by s. For a word w, we let freq(w) denote the sum of all f(w, s) such that (w, s) E £. We define the relative frequency of w with s by rf(w, s) = f(w,s) If f (w, s) = 0, the frequency of each freq(w). synset of w is increased by a small cons</context>
<context position="13569" citStr="Kim and Hovy, 2006" startWordPosition="2348" endWordPosition="2351"> sentiment analyst, it seems unreasonable to expect exactly one to be the correct polarity tag for reliable and the other two incorrect. Therefore, instead of claiming to pinpoint an exact polarity distribution for a word, we propose to set a boundary on its variation. This establishes a 1026 range of values, instead of a single point, in which SLs can be said to agree. Thus, for a word w, we can define � + if P+ &gt; P− polarity(w) = − (2) if P− &gt; P+ which we refer to as MAX POL. This model is adopted either explicitly or implicitly by numerous works (Hassan and Radev, 2010; Kim and Hovy, 2004; Kim and Hovy, 2006; Qiu et al., 2009). Another model is the majority sense model, called MAJORITY, (Dragut et al., 2012), where polarity(w) + if P+ &gt; P− + P0 = Sl − if P− &gt; P+ + P0 (3) Another polarity model, MAX, is defined as � + if P+ &gt;P− &amp; P+ &gt;P0 polarity(w)= − if P−&gt;P+ &amp;P−&gt;P0 (4) For instance, reliable conveys positive polarity according to MAX POL, since P+ &gt; P−, but neutral according to MAJORITY. When the condition of being neither positive nor negative can be phrased as a conjunction of linear inequalities, as is the case with MAJORITY and MAX POL, then we define neutral as not positive and not negative</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2006. Identifying and analyzing judgment opinions. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beata Beigman Klebanov</author>
<author>Nitin Madnani</author>
<author>Jill Burstein</author>
</authors>
<title>Using pivot-based paraphrasing and sentiment profiles to improve a subjectivity lexicon for essay data. In ACL.</title>
<date>2013</date>
<contexts>
<context position="2782" citStr="Klebanov et al., 2013" startWordPosition="447" endWordPosition="450"> 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, OF, and AL, and to the latter as Sentiment Sense Lexions (SSLs), e.g., SWN, QWN, and Micro-WNOp. Besides the method of compilat</context>
</contexts>
<marker>Klebanov, Madnani, Burstein, 2013</marker>
<rawString>Beata Beigman Klebanov, Nitin Madnani, and Jill Burstein. 2013. Using pivot-based paraphrasing and sentiment profiles to improve a subjectivity lexicon for essay data. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="1382" citStr="Liu, 2012" startWordPosition="209" endWordPosition="210">sing linear programming (LP) theory. LP tools allow us to uncover inconsistencies efficiently, paving the way to building SL debugging tools. We show that previous work corresponds to 0-1 integer programming, a particular case of LP. Our experimental studies show a strong correlation between polarity consistency in SLs and the accuracy of sentiment tagging in practice. 1 Introduction Many sentiment analysis algorithms rely on sentiment lexicons (SLs), where word forms or word senses1 are tagged as conveying positive, negative or neutral sentiments. SLs are constructed by one of three methods (Liu, 2012; Feldman, 2013): (1) Manual tagging by human annotators is generally reliable, but because it is labor-intensive, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to simi</context>
<context position="34428" citStr="Liu, 2012" startWordPosition="6090" endWordPosition="6091">. and requires about 10GB of memory, our method is several orders of magnitude more efficient and more practical, paving the way to building practical SL debugging tools. 5.4 Inconsistency &amp; Sentiment Annotation This experiment has two objectives: (1) show that two inconsistent SLs give very different results when applied to sentiment analysis tasks and (2) given an inconsistent SL D, and D&apos; an improved version of D with fewer inconsistencies, show that D&apos; gives better results than D in sentiment analysis tasks. We use a third-party sentiment annotation tool that utilizes SLs, Opinion Parser (Liu, 2012). We give the instantiations of D below. In (1), we use the dataset aclImdb (Maas et al., 2011), which consists of 50,000 reviews, and the SLs UN and SWN. Let UN&apos; and SWN&apos; be the subsets of UN and SWN, respectively, with the property that they have the same set of (word, pos) pair entries and word appears in aclImdb. UN&apos; and SWN&apos; have 6,003 entries. We select from aclImdb the reviews with the property that they contain at least 50 words in SWN&apos; and UN&apos;. This gives 516 negative and 567 positive reviews, a total of 1,083 reviews containing a total of 31,701 sentences. Opinion Parser is run on th</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Malu Castellanos</author>
<author>Umeshwar Dayal</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Automatic construction of a context-aware sentiment lexicon: an optimization approach.</title>
<date>2011</date>
<booktitle>In WWW.</booktitle>
<contexts>
<context position="2799" citStr="Lu et al., 2011" startWordPosition="451" endWordPosition="454">3; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, OF, and AL, and to the latter as Sentiment Sense Lexions (SSLs), e.g., SWN, QWN, and Micro-WNOp. Besides the method of compilation, SLs may also</context>
</contexts>
<marker>Lu, Castellanos, Dayal, Zhai, 2011</marker>
<rawString>Yue Lu, Malu Castellanos, Umeshwar Dayal, and ChengXiang Zhai. 2011. Automatic construction of a context-aware sentiment lexicon: an optimization approach. In WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew L Maas</author>
<author>Raymond E Daly</author>
<author>Peter Pham</author>
<author>Dan Huang</author>
<author>Andrew Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Learning word vectors for sentiment analysis.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="34523" citStr="Maas et al., 2011" startWordPosition="6106" endWordPosition="6109">icient and more practical, paving the way to building practical SL debugging tools. 5.4 Inconsistency &amp; Sentiment Annotation This experiment has two objectives: (1) show that two inconsistent SLs give very different results when applied to sentiment analysis tasks and (2) given an inconsistent SL D, and D&apos; an improved version of D with fewer inconsistencies, show that D&apos; gives better results than D in sentiment analysis tasks. We use a third-party sentiment annotation tool that utilizes SLs, Opinion Parser (Liu, 2012). We give the instantiations of D below. In (1), we use the dataset aclImdb (Maas et al., 2011), which consists of 50,000 reviews, and the SLs UN and SWN. Let UN&apos; and SWN&apos; be the subsets of UN and SWN, respectively, with the property that they have the same set of (word, pos) pair entries and word appears in aclImdb. UN&apos; and SWN&apos; have 6,003 entries. We select from aclImdb the reviews with the property that they contain at least 50 words in SWN&apos; and UN&apos;. This gives 516 negative and 567 positive reviews, a total of 1,083 reviews containing a total of 31,701 sentences. Opinion Parser is run on these sentences using SWN&apos; and UN&apos;. We obtain that 16,741 (52.8%) sentences acquire different pol</context>
</contexts>
<marker>Maas, Daly, Pham, Huang, Ng, Potts, 2011</marker>
<rawString>Andrew L. Maas, Raymond E. Daly, Peter Pham, Dan Huang, Andrew Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Cody Dunne</author>
<author>Bonnie Dorr</author>
</authors>
<title>Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus.</title>
<date>2009</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="2252" citStr="Mohammad et al., 2009" startWordPosition="359" endWordPosition="363">2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen,</context>
</contexts>
<marker>Mohammad, Dunne, Dorr, 2009</marker>
<rawString>Saif Mohammad, Cody Dunne, and Bonnie Dorr. 2009. Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Peng</author>
<author>Dae Hoon Park</author>
</authors>
<title>Generate adjective sentiment dictionary for social media sentiment analysis using constrained nonnegative matrix factorization.</title>
<date>2011</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="2820" citStr="Peng and Park, 2011" startWordPosition="455" endWordPosition="458">ev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, OF, and AL, and to the latter as Sentiment Sense Lexions (SSLs), e.g., SWN, QWN, and Micro-WNOp. Besides the method of compilation, SLs may also vary with regard to </context>
</contexts>
<marker>Peng, Park, 2011</marker>
<rawString>Wei Peng and Dae Hoon Park. 2011. Generate adjective sentiment dictionary for social media sentiment analysis using constrained nonnegative matrix factorization. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Expanding domain sentiment lexicon through double propagation.</title>
<date>2009</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="13588" citStr="Qiu et al., 2009" startWordPosition="2352" endWordPosition="2355">it seems unreasonable to expect exactly one to be the correct polarity tag for reliable and the other two incorrect. Therefore, instead of claiming to pinpoint an exact polarity distribution for a word, we propose to set a boundary on its variation. This establishes a 1026 range of values, instead of a single point, in which SLs can be said to agree. Thus, for a word w, we can define � + if P+ &gt; P− polarity(w) = − (2) if P− &gt; P+ which we refer to as MAX POL. This model is adopted either explicitly or implicitly by numerous works (Hassan and Radev, 2010; Kim and Hovy, 2004; Kim and Hovy, 2006; Qiu et al., 2009). Another model is the majority sense model, called MAJORITY, (Dragut et al., 2012), where polarity(w) + if P+ &gt; P− + P0 = Sl − if P− &gt; P+ + P0 (3) Another polarity model, MAX, is defined as � + if P+ &gt;P− &amp; P+ &gt;P0 polarity(w)= − if P−&gt;P+ &amp;P−&gt;P0 (4) For instance, reliable conveys positive polarity according to MAX POL, since P+ &gt; P−, but neutral according to MAJORITY. When the condition of being neither positive nor negative can be phrased as a conjunction of linear inequalities, as is the case with MAJORITY and MAX POL, then we define neutral as not positive and not negative. These model defin</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding domain sentiment lexicon through double propagation. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Sanderson</author>
</authors>
<title>The impact on retrieval effectiveness of skewed frequency distributions.</title>
<date>1999</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>17</volume>
<issue>4</issue>
<contexts>
<context position="11927" citStr="Sanderson, 1999" startWordPosition="2046" endWordPosition="2047">ake the assumption that this relation takes the form of a linear function. Thus, for w E W and p E {+, −, 0}, the polarity distribution of w is defined as: �Pp(w) = g(w, s) · Pp(s), (1) sESw where Pp(s) is the polarity value of synset s with polarity p and g(w, s) is a rational number. For example, g can be the relative frequency of s with respect to w in WordNet: g(w, s) = rf(w, s); bw E W, s E S. Alternatively, for each word w we can draw g(w, ·) from a Zipfian distribution, following the observation that the distribution of word senses roughly follows a Zipfian power-law (Kilgarriff, 2004; Sanderson, 1999). In this paper, we will assume g(w, s) = rf(w, s). For example, the three synsets of the adjective reliable with relative frequencies 911, 111, and 111, respectively, are given the distributions (.375, 0, .625), (.5, 0, .5), and (.625, 0, .375) in SentiWordNet. So for reliable we have P+ = 110.375 + 1 9 110.5 + 1110.625 Pz� 0.41, P_ = 0, and P0 = 9110.625 + 1110.5 + 1110.375 Pz� 0.59. 2.4 Modeling Sentiment Orientation in SLs Words and synsets have unique polarities in some SLs, e.g., AL and OF. For instance, reliable has positive polarity in AL, GI, and OF. The question is: what does a discr</context>
</contexts>
<marker>Sanderson, 1999</marker>
<rawString>Mark Sanderson. 1999. The impact on retrieval effectiveness of skewed frequency distributions. ACM Transactions on Information Systems, 17(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas J Schaefer</author>
</authors>
<title>The complexity of satisfiability problems.</title>
<date>1978</date>
<booktitle>In STOC.</booktitle>
<contexts>
<context position="8247" citStr="Schaefer, 1978" startWordPosition="1340" endWordPosition="1341">otation captures more naturally the polarity spectrum of a word or synset. In this paper we give a solution to the PCP-F. The differences between our solution and that of Dragut et al. (2012) give some insight into the general differences between the fractional and discrete problems. First, the discrete case is intractable, i.e., computationally NP-complete (Dragut et al., 2012); we show in this paper (Section 3.2) that the fractional case is tractable (solvable in polynomial time). Second, the PCP-D is solved in Dragut et al. (2012) by translation to the Boolean satisfiability problem (SAT) (Schaefer, 1978); here we recast the PCPF in terms of LP theory. Third, we show that the LP framework is a natural setting for the PCP as a whole, and that the PCP-D corresponds to the 0- 1 integer LP problem (Section 3.2), a classic NPcomplete problem (Karp, 2010). Our experiments (Section 5.4) show that correcting even a small number of inconsistencies can greatly improve the accuracy of sentiment annotation tasks. We implement our algorithm as a versatile tool for debugging SLs, which helps locate the laughable : positive risible : ? comic : negative 1 0.5 0.5 0.6 0.4 s1 : “so unreasonable as to invite der</context>
</contexts>
<marker>Schaefer, 1978</marker>
<rawString>Thomas J. Schaefer. 1978. The complexity of satisfiability problems. In STOC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Schrijver</author>
</authors>
<title>Theory of linear and integer programming.</title>
<date>1986</date>
<publisher>John Wiley &amp; Sons, Inc.,</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4956" citStr="Schrijver, 1986" startWordPosition="793" endWordPosition="794">ries give only this meaning for both words) then there must be an annotation inconsistency in OF, called a polarity inconsistency. While some inconsistencies are easy to detect, manual consistency checking of an entire SL is an impractical endeavor, primarily because of the sheer size (SWN has over 206,000 word-sense pairs). Additionally, WordNet’s complex network structure renders manual checking virtually impossible; an instance of a polarity inconsistency may entail an entire sub-network of words and senses. In this paper we develop a rigorous formal method based on linear programming (LP)(Schrijver, 1986) for polarity consistency checking of SLs with accompanying methods to unearth mislabeled words and synsets when consistency is not satisfied. We translate the polarity consistency problem (PCP) into a form of the LP problem, suitable as the input to a standard LP solver, and utilize the functionality available in modern LP software (e.g., identifying an irreducible infeasible subset) to pinpoint the sources of inconsistencies when they occur. In our experimentation we are able to quickly uncover numerous intra- and inter-lexicon inconsistencies in all of the input SLs tested and to suggest le</context>
</contexts>
<marker>Schrijver, 1986</marker>
<rawString>Alexander Schrijver. 1986. Theory of linear and integer programming. John Wiley &amp; Sons, Inc., New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Stone</author>
<author>D Dunphy</author>
<author>M Smith</author>
<author>J Ogilvie</author>
</authors>
<title>The General Inquirer: A computer approach to content analysis.</title>
<date>1966</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1731" citStr="Stone et al., 1966" startWordPosition="262" endWordPosition="265">f sentiment tagging in practice. 1 Introduction Many sentiment analysis algorithms rely on sentiment lexicons (SLs), where word forms or word senses1 are tagged as conveying positive, negative or neutral sentiments. SLs are constructed by one of three methods (Liu, 2012; Feldman, 2013): (1) Manual tagging by human annotators is generally reliable, but because it is labor-intensive, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them </context>
</contexts>
<marker>Stone, Dunphy, Smith, Ogilvie, 1966</marker>
<rawString>P. Stone, D. Dunphy, M. Smith, and J. Ogilvie. 1966. The General Inquirer: A computer approach to content analysis. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Taboada</author>
<author>J Grieve</author>
</authors>
<title>Analyzing appraisal automatically. In</title>
<date>2004</date>
<publisher>AAAI Spring Symposium.</publisher>
<contexts>
<context position="1687" citStr="Taboada and Grieve, 2004" startWordPosition="254" endWordPosition="257">een polarity consistency in SLs and the accuracy of sentiment tagging in practice. 1 Introduction Many sentiment analysis algorithms rely on sentiment lexicons (SLs), where word forms or word senses1 are tagged as conveying positive, negative or neutral sentiments. SLs are constructed by one of three methods (Liu, 2012; Feldman, 2013): (1) Manual tagging by human annotators is generally reliable, but because it is labor-intensive, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 20</context>
</contexts>
<marker>Taboada, Grieve, 2004</marker>
<rawString>M. Taboada and J. Grieve. 2004. Analyzing appraisal automatically. In AAAI Spring Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientations of words using spin model.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2275" citStr="Takamura et al., 2005" startWordPosition="364" endWordPosition="367">n (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) gene</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientations of words using spin model. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tamiz</author>
<author>S J Mardle</author>
<author>D F Jones</author>
</authors>
<title>Detecting IIS in infeasible linear programmes using techniques from goal programming.</title>
<date>1996</date>
<journal>Comput. Oper. Res.,</journal>
<volume>23</volume>
<issue>2</issue>
<contexts>
<context position="24332" citStr="Tamiz et al., 1996" startWordPosition="4293" endWordPosition="4296"> inconsistent SL. In the framework of linear systems of constraints, the problems (1) - (4) correspond to (i) the identification of an Irreducible Infeasible Subset (IIS) of constraints within Φ(N, L), (ii) finding IIS of minimum cardinality, (iii) finding all IISs and (iv) finding the largest set of constraints in Φ(N, L) that is feasible, respectively. An IIS is an infeasible subset of constraints that becomes feasible if any single constraint is removed. Problems (ii) - (iv) are NP-hard and some may even be difficult to approximate (Amaldi and Kann, 1998; Chinneck, 2008; Chakravarti, 1994; Tamiz et al., 1996). We focus on problem (1) in this paper, which we solve via IIS discovery. We keep a bijective mapping from words and synsets to constraints such that for any given constraint, we can uniquely identify the word or synset in Φ(N, L) from which it was introduced. Hence, once an IIS is isolated, we know the corresponding words or synsets. Modern LP solvers typically can give an IIS when a system is found to be infeasible, but none give all IISs or the IIS of minimum size. Example (continued). The polarity assignments of w1, w2, w3, and w4, are consistent iff there exist polarity distributions (P+</context>
</contexts>
<marker>Tamiz, Mardle, Jones, 1996</marker>
<rawString>M. Tamiz, S. J. Mardle, and D. F. Jones. 1996. Detecting IIS in infeasible linear programmes using techniques from goal programming. Comput. Oper. Res., 23(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duyu Tang</author>
<author>Furu Wei</author>
<author>Bing Qin</author>
<author>Ming Zhou</author>
<author>Ting Liu</author>
</authors>
<title>Building large-scale twitter-specific sentiment lexicon: A representation learning approach.</title>
<date>2014</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="2839" citStr="Tang et al., 2014" startWordPosition="459" endWordPosition="462">., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, OF, and AL, and to the latter as Sentiment Sense Lexions (SSLs), e.g., SWN, QWN, and Micro-WNOp. Besides the method of compilation, SLs may also vary with regard to sentiment annotatio</context>
</contexts>
<marker>Tang, Wei, Qin, Zhou, Liu, 2014</marker>
<rawString>Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, and Ting Liu. 2014. Building large-scale twitter-specific sentiment lexicon: A representation learning approach. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2289" citStr="Turney, 2002" startWordPosition="368" endWordPosition="369">eve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P. Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gbolahan K Williams</author>
<author>Sarabjot Singh Anand</author>
</authors>
<title>Predicting the polarity strength of adjectives using wordnet.</title>
<date>2009</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="2316" citStr="Williams and Anand, 2009" startWordPosition="370" endWordPosition="373">neral Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Mohammad et al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotati</context>
</contexts>
<marker>Williams, Anand, 2009</marker>
<rawString>Gbolahan K. Williams and Sarabjot Singh Anand. 2009. Predicting the polarity strength of adjectives using wordnet. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP.</booktitle>
<contexts>
<context position="1636" citStr="Wilson et al., 2005" startWordPosition="247" endWordPosition="250">imental studies show a strong correlation between polarity consistency in SLs and the accuracy of sentiment tagging in practice. 1 Introduction Many sentiment analysis algorithms rely on sentiment lexicons (SLs), where word forms or word senses1 are tagged as conveying positive, negative or neutral sentiments. SLs are constructed by one of three methods (Liu, 2012; Feldman, 2013): (1) Manual tagging by human annotators is generally reliable, but because it is labor-intensive, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (Wilson et al., 2005), Appraisal Lexicon (AL) (Taboada and Grieve, 2004), General Inquirer (GI) (Stone et al., 1966), and MicroWNOp (Cerini et al., 2007). (2) Dictionary1We refer to a string of letters or sounds as a word form &amp; to a pairing of a word form with a meaning as a word sense. based acquisition relies on a set of seed words to expand its coverage to similar words. There are over thirty dictionary-based techniques (Andreevskaia and Bergler, 2006; Blum et al., 2004; Chen and Skiena, 2014; Choi and Wiebe, 2014; Esuli and Sebastiani, 2006; Feng et al., 2013; Hassan and Radev, 2010; Kamps et al., 2004; Moham</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunfang Wu</author>
<author>Miaomiao Wen</author>
</authors>
<title>Disambiguating dynamic sentiment ambiguous adjectives.</title>
<date>2010</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="2858" citStr="Wu and Wen, 2010" startWordPosition="463" endWordPosition="466">t al., 2009; Takamura et al., 2005; Turney, 2002; Williams and Anand, 2009), most of them based on WordNet (Fellbaum, 1998), such as SentiWordNet (SWN)(Baccianella et al., 2010) and Q-WordNet (QWN) (Agerri and Garc´ıa-Serrano, 2010). (3) Corpus-based acquisition expands a set of seed words with the use of a large document corpus (Breck et al., 2007; Bross and Ehrig, 2013; Choi and Cardie, 2009; Ding et al., 2008; Du et al., 2010; Hatzivassiloglou and McKeown, 1997; Jijkoun et al., 2010; Kaji and Kitsuregawa, 2007; Klebanov et al., 2013; Lu et al., 2011; Peng and Park, 2011; Tang et al., 2014; Wu and Wen, 2010). Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice. The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs. SLs are either word or sense/synset oriented. We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, OF, and AL, and to the latter as Sentiment Sense Lexions (SSLs), e.g., SWN, QWN, and Micro-WNOp. Besides the method of compilation, SLs may also vary with regard to sentiment annotation. Polarity disagre</context>
</contexts>
<marker>Wu, Wen, 2010</marker>
<rawString>Yunfang Wu and Miaomiao Wen. 2010. Disambiguating dynamic sentiment ambiguous adjectives. In COLING.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>