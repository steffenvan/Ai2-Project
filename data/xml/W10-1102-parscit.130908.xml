<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.999385">
Extracting Information for Generating A Diabetes Report Card from
Free Text in Physicians Notes
</title>
<author confidence="0.960433">
Ramanjot S Bhatia
</author>
<affiliation confidence="0.6984155">
University of Ottawa Heart
Institute
Ottawa, Ontario.
Rbhatia
</affiliation>
<email confidence="0.978607">
@ottawaheart.ca
</email>
<author confidence="0.998205">
Susan McClinton
</author>
<affiliation confidence="0.772399">
University of Ottawa Heart
Institute
Ottawa, Ontario.
SMcClinton
</affiliation>
<email confidence="0.921033">
@ottawaheart.ca
</email>
<author confidence="0.89098">
Amber Graystone
</author>
<affiliation confidence="0.867726">
McMaster University
</affiliation>
<address confidence="0.311756">
Hamilton, Ontario.
</address>
<email confidence="0.6514285">
amber.graystone
@medportal.ca
</email>
<author confidence="0.9985">
Jason Morin
</author>
<affiliation confidence="0.7882392">
National Research Council
Canada
Ottawa, Ontario.
jason.morin
@nrc-cnrc.gc.ca
</affiliation>
<author confidence="0.871219">
Ross A Davies
</author>
<affiliation confidence="0.9313395">
University of Ottawa Heart
Institute
</affiliation>
<address confidence="0.3708835">
Ottawa, Ontario.
RADavies
</address>
<email confidence="0.984239">
@ottawaheart.ca
</email>
<author confidence="0.984037">
Richard F Davies
</author>
<affiliation confidence="0.938370333333333">
University of Ottawa Heart
Institute
Ottawa, Ontario.
</affiliation>
<sectionHeader confidence="0.35997" genericHeader="abstract">
RFDavies
</sectionHeader>
<email confidence="0.938843">
@ottawaheart.ca
</email>
<sectionHeader confidence="0.999306" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998362962963">
A standard practice for care providers is to record
patient consults using voice dictation. The voice
dictation record is transcribed into free text and
stored electronically. The nature of this text is
narrative with a possibility of containing headings
marking the boundaries of the paragraphs. This
remains the medium of choice for storing key pa-
tient information as opposed to structured tables
due to time constraints, uncertainty about the use
of codes, classification limitations, and difficulty
with the use of computer systems. The information
being stored in machine readable format is not
amenable to any form of statistical analysis or re-
view as it exists (Mcdonald 1997, Lovis et al.
2000). The usefulness of mining information from
this text has been stressed by many including
Heinze et al. (2001) and Hripcsak et al. (1995).
The information unlocked from the free text could
be used for facilitating patient management, re-
searching disease symptoms, analyzing diagnoses,
epidemiological research, book keeping, etc. The
free text in these documents has been shown to be
less ambiguous than text in general unrestricted
documents (Ruch et al. 2001) making it feasible to
successfully apply extraction techniques using
tools from IE and NLP. Natural language
processing has been used to analyze free text in
</bodyText>
<sectionHeader confidence="0.517272" genericHeader="introduction">
Abstract
</sectionHeader>
<bodyText confidence="0.999903666666667">
Achieving guideline-based targets in patients
with diabetes is crucial for improving clinical
outcomes and preventing long-term complica-
tions. Using electronic heath records (EHRs) to
identify high-risk patients for further interven-
tion by screening large populations is limited be-
cause many EHRs store clinical information as
dictated and transcribed free text notes that are
not amenable to statistical analysis. This paper
presents the process of extracting elements
needed for generating a diabetes report card from
free text notes written in English. Numerical
measurements, representing lab values and phys-
ical examinations results are extracted from free
text documents and then stored in a structured
database. Extracting diagnosis information and
medication lists are work in progress. The com-
plete dataset for this project is comprised of
81,932 documents from 30,459 patients collected
over a period of 5 years. The patient population
is considered high risk for diabetes as they have
existing cardiovascular complications. Experi-
mental results validate our method, demonstrat-
ing high precision (88.8-100%).
</bodyText>
<page confidence="0.973218">
8
</page>
<note confidence="0.7528555">
Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 8–14,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.996636921568628">
medical domain for decision support (Chapman et
al. 2005), classifying medical problem lists
(Meystre and Haug 2005), extracting disease re-
lated information (Xu et al. 2004), building dy-
namic medications lists (Pakhomov et al. 2002),
building applications for better data management,
and for diagnosis detection. (Friedman et al. 2004,
Roberts et al. 2008, Liu and Friedman 2004).
Our goal is to automatically generate diabetes
report cards from the free text in physicians&apos; letters.
The report card can be used to detect populations
at risk for diabetes mellitus and track their vital
information over a period of time. Previous work
in similar area has seen Turchin et al. (2005) iden-
tify patients with diabetes from the text of physi-
cian notes by looking for mention of diabetes and
predefined list of medication names. They use a
manually created list of negation tokens to detect
false examples. They compare the process to ma-
nual chart review and billing notes and show the
automatic system performs at par with manual re-
view with the advantage of it being highly effi-
cient.
In Turchin et al. (2006) the authors use regular
expressions to extract blood pressure values and
change of treatment for hypertension. They use a
set of regular expressions to detect the presence of
a blood pressure related tag, which predicts that the
sentence is likely to contain a blood pressure value.
The value itself is then extracted using regular ex-
pressions. They identify the strength of the process
in it being relatively simple, efficient and quick to
setup, while its weakness is its lack of generaliza-
tion. Voorham and Denig (2007) solve a similar
problem as in here and extract information regard-
ing diabetes from free text notes using a number
centric approach. They identify all positive numer-
ical values and then attach respective labels to the
values. They use a keyword based approach with a
four word token window and apply a character se-
quence algorithm to check for spelling errors.
Extracting relevant information from free text
represents a challenging problem since the task can
be considered to be a form of reverse engineering
and is above the mere presence of keywords or
patterns. It is necessary to generate semantic repre-
sentations to understand the text. The free text
document may contain multiple values for the
same label, and it&apos;s important to be able to distin-
guish and choose the correct value. These values
could be:
</bodyText>
<listItem confidence="0.99696">
• multiple readings (in which case a prede-
fined rule may be enough, e.g. choosing the
smallest mean arterial blood pressure value)
• potential target values (which may or may
not be important)
• values taken over a period of time
• values taken at different locations
• values reflecting family history
• change in a value and not the actual value
• values influenced by some external reasons
(e.g. take medication if the weight is above
a certain value).
</listItem>
<bodyText confidence="0.999673818181818">
Friedman and Hripcsak (1999) discuss some of
the many problems of dealing with free text in
medical domain. One method to resolve these
problems is to build a full grammar tree and assign
semantic roles to accurately interpret the text.
However, generating full parse trees for medical
text requires specialized parsers developed for the
clinical domain (Freidman, 2005). It has been
shown that shallow syntactic approaches can yield
similar results to the ones using full syntactic de-
tails (Gildea &amp; Palmer, 2002).
In this work we use shallow syntactic and se-
mantic features (manually created concept list and
WordNet, Miller 1995) to tag information relating
to the numerical values extracted from the text. We
use machine learning tool WEKA (Hall et al.
2009) to build binary classifiers that pick positive
values from the list of values extracted from the
document. Our method allows us to build a robust
and extendible system which should be easily port-
able to texts from different institutions and other
medical domains.
</bodyText>
<sectionHeader confidence="0.928848" genericHeader="method">
2 Method
</sectionHeader>
<bodyText confidence="0.999972083333333">
Our method extends Voorham&apos;s work in using the
numeric value centered approach while developing
a robust way to disambiguate between multiple
values in the same document. The information ex-
tracted for the report card is divided into four cate-
gories: demographic information, numerical
measurement values, medication list, and diagnos-
es. We currently have access to only one source of
information, the free text in physicians&apos; notes,
hence all of the information needed for the report
card is extracted from these notes. The extraction
of demographic information is achieved using reg-
</bodyText>
<page confidence="0.989577">
9
</page>
<bodyText confidence="0.999390408163265">
ular expressions/pattern matching based tech-
niques. The demographic information extracted is
year of birth, date of encounter and gender. The
gender information is determined using a heuristic,
which counts the number of third person masculine
and feminine pronouns present in the text. Numeri-
cal measurement values extracted include blood
pressure (systolic and diastolic), LDL, HDL,
HbA1C, weight, total cholesterol, fasting glucose,
glucose (unspecified) and creatinine. The medica-
tion list extraction process uses a manually created
database of applicable medications. The diagnosis
detection involves negation detection in the sen-
tences that mention diabetes using the NegEx algo-
rithm (Chapman et al. 2001).
In this study we use shallow syntactic and se-
mantic attributes to build a system that extracts the
physical examination and laboratory results data.
The values are extracted as numeric value-label
pairs. The system is divided into three main parts
(Figure 1): preprocessing stage, extraction of the
numeric value-label pairs, and testing the validity
of the extracted pairs.
Preprocessing: The documents were originally
stored in Microsoft Word format (WordML). They
are converted to XML using XSLT transformation.
All formatting information is stripped except for
bold and italic font information and paragraph
boundaries
The paragraphs in the document are further
broken down into sentences and tokens. We use
OPENNLP Maxent1 library to do sentence boun-
dary detection and tokenization. OPENNLP Max-
ent is based on maximum entropy algorithms
described in Ratnaparkhi (1998) and Berger et al.
(1996). The OPENNLP statistical tagger is used to
assign syntactic tags to the tokens.
Data Extraction: In this phase the system extracts
all potential numerical values and assigns them
labels. The system loops through all of the tokens
in the document, testing for numerical values. It
tests each numerical token against a set of regular
expressions and assigns them a list of potential
labels based on the regular expression it matches.
The system takes into account the presence of a
measurement unit and revises the potential list of
labels based on the unit. For each potential label,
using a knowledge base, the system looks for con-
cepts that validate the labels. The closest possible
</bodyText>
<footnote confidence="0.833996">
1 http://opennlp.sourceforge.net/
</footnote>
<bodyText confidence="0.9841518">
validation is accepted as pairing. The Edit distance
algorithm is used to test for matching concepts in
order to account for any spelling errors. The con-
cepts are searched within the constraints of the sen-
tence.
</bodyText>
<figureCaption confidence="0.7844115">
Figure 1 Process Flow diagram for the extraction
process
</figureCaption>
<bodyText confidence="0.999861052631579">
In case multiple labels are validated because of the
presence of multiple concepts in the same sen-
tence, the label indicated by the closest concept is
selected. For each pair, the system extracts a list of
features which help to resolve for positive values.
One exception to the sentence level boundary rule
is: if no concepts are found in the sentence, and the
sentence contains a third person singular inanimate
pronoun, the search is extended to the previous
sentence.
Testing Validity: The previous step extracts all
possible label-numeric value pairs. As discussed
earlier not all values are valid or of interest. In or-
der to select positive values, binary classifiers were
built for each label. The dataset used for training
consisted of 900 documents (210 patients). The
J48 (decision trees 4.5) and NBTree (Naïve Bayes
decision trees) algorithms in WEKA were used to
generate the machine learning classifiers.
</bodyText>
<page confidence="0.996799">
10
</page>
<bodyText confidence="0.9968945">
Features: The following is the list of features ex-
tracted for each pair.
</bodyText>
<listItem confidence="0.965731535714286">
a) Absolute distance between the label and the
numerical value.
b) Label shared (Yes/No): Yes, if the same con-
cept label is attached to another numerical val-
ue in the same document.
c) Closest verb token appearing left of the numer-
ical value.
d) Presence of a modal verb (Yes/No)
e) Distance of numerical value from the modal
verb (a positive value is assigned for the modal
verb if it occurs before the numeric token, and
a negative value when it appears after).
f) Conjunction present (Yes/No): If there is con-
junction present between the label and numeri-
cal value or not.
g) Coreference present (Yes/No): If third person
singular inanimate pronoun is present or not.
h) Negation concept present (Yes/No): True if
there is any negation concept present in the vi-
cinity of the numerical value/label. The nega-
tion concepts include not just negative
statement markers, but also false cognates and
other concepts collected by the domain ex-
perts. (e.g. systolic murmur or systolic volume
do not indicate systolic pressure).
i) Locational Information token: The stemmed
token is stored if it is recognized as a location-
al information token. The location information
</listItem>
<bodyText confidence="0.859677954545454">
is deduced by generalizing each token and
checking to see whether it resolves to one of
many Locational cues in WordNet. The list of
location indicators is presented in Figure 2.
The cues are resolved against the WordNet
hypernym definitions for that token.
j) Distance of numerical value from Locational
token.
k) Temporal information token: Similar to (i), the
stemmed token indicating temporal informa-
tion. The temporal information token includes
any tokens that indicate date or time. The list
of temporal indicator cues in WordNet is
shown in Figure 2.
l) Distance of the numerical value from the tem-
poral token.
For features (c), (i) and (k) the tokens are stored in
their uninflected form, achieved using Porter
Stemmer. For the report card, in case of multiple
positive values for the same label, the smallest val-
ue is selected. In the case of blood pressure, the
smallest mean arterial pressure is selected.
</bodyText>
<figureCaption confidence="0.9026195">
Figure 2 WordNet hypernym based generalization cues
for location and time indicators
</figureCaption>
<sectionHeader confidence="0.996212" genericHeader="method">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.998448533333333">
Evaluation was done using a test set consisting of
804 documents from 260 patients (50 percent had
positive diagnosis for diabetes). The test set was
created by a first year student at Michael G De-
groote School of Medicine at McMaster Universi-
ty. The reviewer manually analyzed the notes and
extracted final values that would appear on the re-
port card along with a time stamp for each value to
indicate the source document. The human reviewer
took approximately 10 minutes per patient; in
comparison the computer analyzed the data at 6.43
patients per minute.
Evaluation results testing the performance of
the system using the manually coded test set are
shown in Table 1 below.
</bodyText>
<table confidence="0.99983375">
Value Preci- Recall F-
sion measure
1 Blood 98.2 96.9 97.8
Pressure
2 LDL 96.4 94.2 95.3
3 HDL 100 98.3 99.1
4 Creatinine 97.2 92.1 94.5
5 Weight 95.6 92.9 94.2
6 TC 93.1 98.1 95.5
7 Glucose 90.7 85.7 87.7
8 F Glucose 88.8 80.0 84.2
9 HbA1C 90.9 86.9 88.8
</table>
<tableCaption confidence="0.982347">
Table 1 Precision/Recall for numerical values
</tableCaption>
<page confidence="0.99941">
11
</page>
<sectionHeader confidence="0.998699" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999792466666666">
The precision, recall and f-measure for all nine
label values extracted for the system along with the
recall values for the human reviewer are listed in
Table 1. The system demonstrates high precision in
extracting and selecting positive numeric value-
label pairs. Blood pressure is extracted with a pre-
cision of 98.2% and recall 96.9%. HDL and LDL
values are easy to spot and extract as they usually
occur without description. At the lower end of pre-
cision are fasting glucose, glucose and HbA1C
where precision results are in the range of 88-90%.
The majority of errors for all categories occurred
due to problems in identifying numeric values be-
cause of typing errors.
Figure 3 shows an example of the level of com-
plexity resolved using the algorithm developed
here. The clinical documents frequently have mul-
tiple values for weight and blood pressure in a sin-
gle document. The lab values do not have the same
level of multiplicity but it can occur. In this exam-
ple, the extraction step extracts all five values, and
the classifier successfully rejects values #3 and #5.
To comply with the report card’s output require-
ments the lowest mean arterial pressure of the re-
maining three values is adopted, which is the
correct response. This approach is extendible to
build a slot-filler system for the values, which
would allow the system to reason on its choice.
In previous work, the disambiguation of the
values is only based on the presence of negation
concepts within a pre-specified boundary. We ex-
tend this to include a simple need based co-
reference, location and temporal information, and a
heuristic approach to include the head verb (it only
takes into account the closest verb, which may or
may not be the governing verb). The system can
successfully detect negative values such as target
values, previous values, change in value or values
measured elsewhere.
The information extracted is stored in a struc-
tured MySQL database. The system allows mul-
tiple views on this information. Figure 4 shows the
output for blood pressure and creatinine for a pa-
tient that was created from the information ex-
tracted from the free text.
</bodyText>
<figureCaption confidence="0.572941">
Figure 3 Example 1
</figureCaption>
<bodyText confidence="0.99992425">
At this time we have not evaluated the contribu-
tion of each feature individually, as this requires
building a comprehensive test set; it remains as
future work.
</bodyText>
<sectionHeader confidence="0.998835" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999960444444445">
Our preliminary results demonstrate that the sys-
tem performs with high precision and recall at the
task of extracting numerical values. It also shows
the ability to build a patient-chart abstractor within
the restricted domain. The use of semantic and
syntactic features enables the system to tag the
values which permit the overall extraction process
to generate more informative numeric value-label
pairs. The use of machine learning algorithms
coupled with a large enough learning dataset pro-
duces a robust system that should work reliably on
similar data from any source. We plan to test the
system on a dataset obtained from the free text
notes of endocrinologists at a different health insti-
tution to validate the generalization of the algo-
rithm. The next step for the Diabetes Report Card
is to extract the list of medications and track any
changes in medication, dosage and frequency.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999809666666667">
A special thanks to Michael Domenic Corbo for
doing the manual review and creating the gold
standard dataset.
</bodyText>
<page confidence="0.995749">
12
</page>
<figureCaption confidence="0.992395">
Figure 4 System Output: Automatically generated graphs for blood pressure and creatinine values for a patient
</figureCaption>
<sectionHeader confidence="0.99787" genericHeader="references">
6 References
</sectionHeader>
<reference confidence="0.999688157142857">
Berger, A. L., Pietra, V. J., &amp; Pietra, S. A. (1996). A
maximum entropy approach to natural language
processing. Computational Linguistics , 39-71.
Chapman, W. W., Christensenb, L. M., Wagnera, M.
M., Haugb, P. J., Ivanova, O., Dowlinga, J. N., et al.
(2005). Classifying free-text triage chief complaints into
syndromic categories with natural languages processing.
Artificial Intelligence in Medicine , 31-40.
Chapman, W., Bridewell, W., Hanbury, P., Cooper, G.,
&amp; Buchanan, B. (2001). Evaluation of negation phrases
in narrative clinical reports. Proc AMIA Symp , 105-114.
Freidman, C. (2005). Semantic Text Parsing for Patient
Records. In Medical Informatics (pp. 423-448).
Springer US.
Friedman, C., &amp; Hripcsak, G. (1999). Natural Language
Processing and Its Future in Medicine. Acad Med , 890-
895.
Friedman, C., Shagina, L., Lussier, Y., &amp; Hripcsak, G.
(2004). Automated Encoding of Clinical Documents
based on Natural Language Processing. Journal of
American Medical Informatics Association .
Gildea, D., &amp; Palmer, M. (2002). The Necessity of
Syntactic Parsing for Predicate Argument Recognition.
Association for Computational Linguistics, (pp. 239-
246).
Hall, M., Frank, E., Holmes, G., Pfahringer, B.,
Reutemann, P., &amp; Witten, I. H. (2009). The WEKA
Data Mining Software: An Update. SIGKDD
Explorations .
Heinze, D. T., Morsch, M. L., &amp; Holbrook, J. (2001).
Mining free-text medical records. AMIA, (pp. 254-258).
Hripcsak, G., Friedman, C., Alderson, P., DuMouchel,
W., Johnson, S., &amp; Clayton, P. (1995). Unlocking
clinical data from narrative reports: a study of natural
language processing. Ann Intern Med , 681-689.
Liu, H., &amp; Friedman, C. (2004). CliniViewer: a tool for
viewing electronic medical records based on natural
language processing and XML. MedInfo , 639-643.
Lovis, C., Baud, R. H., &amp; Plancheb, P. (2000). Power of
expression in the electronic patient record: structured
data or narrative text? International Journal of Medical
Informatics , 101-110.
Mcdonald, C. J. (1997). The Barriers to Electronic
Medical Record Systems and How to Overcome Them.
Journal of the American Medical Informatics
Association , 213-221.
Meystre, S., &amp; Haug, P. J. (2005). Automation of a
problem list using natural language processing. BMC
Medical Informatics and Decision Making , 5-30.
Miller, G. A. (1995). WordNet: A Lexical Database for
English. Communications of the ACM , 38, 39-41.
Pakhomov, S. V., Ruggieri, A., &amp; Chute, C. G. (2002).
Maximum entropy modeling for mining patient
medication status from free text. Proceedings of the
American Medical Informatics, (pp. 587–591).
Ratnaparkhi, A. (1998). Maximum Entropy Models for
Natural Language Ambiguity Resolution. Phd Thesis.
Roberts, A., Gaizauskas, R., Hepple, M., &amp; Guo, Y.
(2008). Mining clinical relationships from patient
narratives. Natural Language Processing in
Biomedicine (BioNLP) ACL Workshop.
Ruch, P., Baud, R., Geissbuhler, A., &amp; Rassinoux, A.-
M. (2001). Comparing general and medical texts for
information retreival based on natural language
processing: An inquiry into lexical disambiguation., (pp.
261-266).
Turchin, A., Kohane, I., &amp; Pendergrass, M. (2005).
Identification of patients with diabetes from the text of
physician notes in the electronic medical record.
Diabetes Care , 1794-1795.
</reference>
<page confidence="0.987753">
13
</page>
<reference confidence="0.999762857142857">
Turchin, A., Kolatkar, N., Grant, R. W., Makhni, E. C.,
Pendergrass, M. L., &amp; Einbinder, J. S. (2006). Using
regular expressions to abstract blood pressure and
treatment intensification information from the text of
physician notes. Journal of the American Medical
Informatics Association , 691-696.
Voorham, J., &amp; Denig, P. (2007). Computerized
Extraction of Information on the Quality of Diabetes
Care from Free Text in Electronic Patient Records of
General Practitioners. The Journal of the American
Medical Informatics Association , 349-354.
Xu, H., Anderson, K., Grann, V. R., &amp; Friedman, C.
(2004). Facilitating Research in Pathology using Natural
Language Processing. Proc AMIA Symp, (p. 1057).
</reference>
<page confidence="0.99927">
14
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.046890">
<title confidence="0.8362145">Extracting Information for Generating A Diabetes Report Card from Free Text in Physicians Notes</title>
<author confidence="0.498899">S Ramanjot</author>
<affiliation confidence="0.999938">University of Ottawa</affiliation>
<address confidence="0.800726">Ottawa,</address>
<email confidence="0.987141">@ottawaheart.ca</email>
<author confidence="0.962578">Susan</author>
<affiliation confidence="0.999939">University of Ottawa</affiliation>
<address confidence="0.801871">Ottawa,</address>
<email confidence="0.989338">@ottawaheart.ca</email>
<author confidence="0.898218">Amber Graystone</author>
<affiliation confidence="0.458577">McMaster</affiliation>
<address confidence="0.982723">Hamilton, Ontario.</address>
<email confidence="0.997985">@medportal.ca</email>
<author confidence="0.926914">Jason</author>
<affiliation confidence="0.999535">National Research</affiliation>
<address confidence="0.732766">Ottawa,</address>
<email confidence="0.997256">@nrc-cnrc.gc.ca</email>
<author confidence="0.938066">A Ross</author>
<affiliation confidence="0.999971">University of Ottawa</affiliation>
<address confidence="0.803344">Ottawa,</address>
<email confidence="0.997147">@ottawaheart.ca</email>
<author confidence="0.963044">F Richard</author>
<affiliation confidence="0.999956">University of Ottawa</affiliation>
<address confidence="0.787516">Ottawa,</address>
<email confidence="0.902694">@ottawaheart.ca</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>V J Pietra</author>
<author>S A Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<booktitle>Computational Linguistics ,</booktitle>
<pages>39--71</pages>
<contexts>
<context position="9446" citStr="Berger et al. (1996)" startWordPosition="1457" endWordPosition="1460">e, extraction of the numeric value-label pairs, and testing the validity of the extracted pairs. Preprocessing: The documents were originally stored in Microsoft Word format (WordML). They are converted to XML using XSLT transformation. All formatting information is stripped except for bold and italic font information and paragraph boundaries The paragraphs in the document are further broken down into sentences and tokens. We use OPENNLP Maxent1 library to do sentence boundary detection and tokenization. OPENNLP Maxent is based on maximum entropy algorithms described in Ratnaparkhi (1998) and Berger et al. (1996). The OPENNLP statistical tagger is used to assign syntactic tags to the tokens. Data Extraction: In this phase the system extracts all potential numerical values and assigns them labels. The system loops through all of the tokens in the document, testing for numerical values. It tests each numerical token against a set of regular expressions and assigns them a list of potential labels based on the regular expression it matches. The system takes into account the presence of a measurement unit and revises the potential list of labels based on the unit. For each potential label, using a knowledg</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, A. L., Pietra, V. J., &amp; Pietra, S. A. (1996). A maximum entropy approach to natural language processing. Computational Linguistics , 39-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W W Chapman</author>
<author>L M Christensenb</author>
<author>M M Wagnera</author>
<author>P J Haugb</author>
<author>O Ivanova</author>
<author>J N Dowlinga</author>
</authors>
<title>Classifying free-text triage chief complaints into syndromic categories with natural languages processing.</title>
<date>2005</date>
<booktitle>Artificial Intelligence in Medicine ,</booktitle>
<pages>31--40</pages>
<contexts>
<context position="3375" citStr="Chapman et al. 2005" startWordPosition="485" endWordPosition="488">medication lists are work in progress. The complete dataset for this project is comprised of 81,932 documents from 30,459 patients collected over a period of 5 years. The patient population is considered high risk for diabetes as they have existing cardiovascular complications. Experimental results validate our method, demonstrating high precision (88.8-100%). 8 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 8–14, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics medical domain for decision support (Chapman et al. 2005), classifying medical problem lists (Meystre and Haug 2005), extracting disease related information (Xu et al. 2004), building dynamic medications lists (Pakhomov et al. 2002), building applications for better data management, and for diagnosis detection. (Friedman et al. 2004, Roberts et al. 2008, Liu and Friedman 2004). Our goal is to automatically generate diabetes report cards from the free text in physicians&apos; letters. The report card can be used to detect populations at risk for diabetes mellitus and track their vital information over a period of time. Previous work in similar area has se</context>
</contexts>
<marker>Chapman, Christensenb, Wagnera, Haugb, Ivanova, Dowlinga, 2005</marker>
<rawString>Chapman, W. W., Christensenb, L. M., Wagnera, M. M., Haugb, P. J., Ivanova, O., Dowlinga, J. N., et al. (2005). Classifying free-text triage chief complaints into syndromic categories with natural languages processing. Artificial Intelligence in Medicine , 31-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Chapman</author>
<author>W Bridewell</author>
<author>P Hanbury</author>
<author>G Cooper</author>
<author>B Buchanan</author>
</authors>
<title>Evaluation of negation phrases in narrative clinical reports.</title>
<date>2001</date>
<booktitle>Proc AMIA Symp ,</booktitle>
<pages>105--114</pages>
<contexts>
<context position="8546" citStr="Chapman et al. 2001" startWordPosition="1321" endWordPosition="1324">s year of birth, date of encounter and gender. The gender information is determined using a heuristic, which counts the number of third person masculine and feminine pronouns present in the text. Numerical measurement values extracted include blood pressure (systolic and diastolic), LDL, HDL, HbA1C, weight, total cholesterol, fasting glucose, glucose (unspecified) and creatinine. The medication list extraction process uses a manually created database of applicable medications. The diagnosis detection involves negation detection in the sentences that mention diabetes using the NegEx algorithm (Chapman et al. 2001). In this study we use shallow syntactic and semantic attributes to build a system that extracts the physical examination and laboratory results data. The values are extracted as numeric value-label pairs. The system is divided into three main parts (Figure 1): preprocessing stage, extraction of the numeric value-label pairs, and testing the validity of the extracted pairs. Preprocessing: The documents were originally stored in Microsoft Word format (WordML). They are converted to XML using XSLT transformation. All formatting information is stripped except for bold and italic font information </context>
</contexts>
<marker>Chapman, Bridewell, Hanbury, Cooper, Buchanan, 2001</marker>
<rawString>Chapman, W., Bridewell, W., Hanbury, P., Cooper, G., &amp; Buchanan, B. (2001). Evaluation of negation phrases in narrative clinical reports. Proc AMIA Symp , 105-114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Freidman</author>
</authors>
<title>Semantic Text Parsing for Patient Records.</title>
<date>2005</date>
<booktitle>In Medical Informatics</booktitle>
<pages>423--448</pages>
<publisher>Springer US.</publisher>
<contexts>
<context position="6584" citStr="Freidman, 2005" startWordPosition="1021" endWordPosition="1022">r a period of time • values taken at different locations • values reflecting family history • change in a value and not the actual value • values influenced by some external reasons (e.g. take medication if the weight is above a certain value). Friedman and Hripcsak (1999) discuss some of the many problems of dealing with free text in medical domain. One method to resolve these problems is to build a full grammar tree and assign semantic roles to accurately interpret the text. However, generating full parse trees for medical text requires specialized parsers developed for the clinical domain (Freidman, 2005). It has been shown that shallow syntactic approaches can yield similar results to the ones using full syntactic details (Gildea &amp; Palmer, 2002). In this work we use shallow syntactic and semantic features (manually created concept list and WordNet, Miller 1995) to tag information relating to the numerical values extracted from the text. We use machine learning tool WEKA (Hall et al. 2009) to build binary classifiers that pick positive values from the list of values extracted from the document. Our method allows us to build a robust and extendible system which should be easily portable to text</context>
</contexts>
<marker>Freidman, 2005</marker>
<rawString>Freidman, C. (2005). Semantic Text Parsing for Patient Records. In Medical Informatics (pp. 423-448). Springer US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
<author>G Hripcsak</author>
</authors>
<date>1999</date>
<booktitle>Natural Language Processing and Its Future in Medicine. Acad Med ,</booktitle>
<pages>890--895</pages>
<contexts>
<context position="6242" citStr="Friedman and Hripcsak (1999)" startWordPosition="965" endWordPosition="968">y contain multiple values for the same label, and it&apos;s important to be able to distinguish and choose the correct value. These values could be: • multiple readings (in which case a predefined rule may be enough, e.g. choosing the smallest mean arterial blood pressure value) • potential target values (which may or may not be important) • values taken over a period of time • values taken at different locations • values reflecting family history • change in a value and not the actual value • values influenced by some external reasons (e.g. take medication if the weight is above a certain value). Friedman and Hripcsak (1999) discuss some of the many problems of dealing with free text in medical domain. One method to resolve these problems is to build a full grammar tree and assign semantic roles to accurately interpret the text. However, generating full parse trees for medical text requires specialized parsers developed for the clinical domain (Freidman, 2005). It has been shown that shallow syntactic approaches can yield similar results to the ones using full syntactic details (Gildea &amp; Palmer, 2002). In this work we use shallow syntactic and semantic features (manually created concept list and WordNet, Miller 1</context>
</contexts>
<marker>Friedman, Hripcsak, 1999</marker>
<rawString>Friedman, C., &amp; Hripcsak, G. (1999). Natural Language Processing and Its Future in Medicine. Acad Med , 890-895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
<author>L Shagina</author>
<author>Y Lussier</author>
<author>G Hripcsak</author>
</authors>
<title>Automated Encoding of Clinical Documents based on Natural Language Processing.</title>
<date>2004</date>
<journal>Journal of American Medical Informatics Association .</journal>
<contexts>
<context position="3652" citStr="Friedman et al. 2004" startWordPosition="525" endWordPosition="528">. Experimental results validate our method, demonstrating high precision (88.8-100%). 8 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 8–14, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics medical domain for decision support (Chapman et al. 2005), classifying medical problem lists (Meystre and Haug 2005), extracting disease related information (Xu et al. 2004), building dynamic medications lists (Pakhomov et al. 2002), building applications for better data management, and for diagnosis detection. (Friedman et al. 2004, Roberts et al. 2008, Liu and Friedman 2004). Our goal is to automatically generate diabetes report cards from the free text in physicians&apos; letters. The report card can be used to detect populations at risk for diabetes mellitus and track their vital information over a period of time. Previous work in similar area has seen Turchin et al. (2005) identify patients with diabetes from the text of physician notes by looking for mention of diabetes and predefined list of medication names. They use a manually created list of negation tokens to detect false examples. They compare the process to manua</context>
</contexts>
<marker>Friedman, Shagina, Lussier, Hripcsak, 2004</marker>
<rawString>Friedman, C., Shagina, L., Lussier, Y., &amp; Hripcsak, G. (2004). Automated Encoding of Clinical Documents based on Natural Language Processing. Journal of American Medical Informatics Association .</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>M Palmer</author>
</authors>
<title>The Necessity of Syntactic Parsing for Predicate Argument Recognition. Association for Computational Linguistics,</title>
<date>2002</date>
<pages>239--246</pages>
<contexts>
<context position="6728" citStr="Gildea &amp; Palmer, 2002" startWordPosition="1043" endWordPosition="1046">• values influenced by some external reasons (e.g. take medication if the weight is above a certain value). Friedman and Hripcsak (1999) discuss some of the many problems of dealing with free text in medical domain. One method to resolve these problems is to build a full grammar tree and assign semantic roles to accurately interpret the text. However, generating full parse trees for medical text requires specialized parsers developed for the clinical domain (Freidman, 2005). It has been shown that shallow syntactic approaches can yield similar results to the ones using full syntactic details (Gildea &amp; Palmer, 2002). In this work we use shallow syntactic and semantic features (manually created concept list and WordNet, Miller 1995) to tag information relating to the numerical values extracted from the text. We use machine learning tool WEKA (Hall et al. 2009) to build binary classifiers that pick positive values from the list of values extracted from the document. Our method allows us to build a robust and extendible system which should be easily portable to texts from different institutions and other medical domains. 2 Method Our method extends Voorham&apos;s work in using the numeric value centered approach</context>
</contexts>
<marker>Gildea, Palmer, 2002</marker>
<rawString>Gildea, D., &amp; Palmer, M. (2002). The Necessity of Syntactic Parsing for Predicate Argument Recognition. Association for Computational Linguistics, (pp. 239-246).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hall</author>
<author>E Frank</author>
<author>G Holmes</author>
<author>B Pfahringer</author>
<author>P Reutemann</author>
<author>I H Witten</author>
</authors>
<title>The WEKA Data Mining Software: An Update. SIGKDD Explorations .</title>
<date>2009</date>
<contexts>
<context position="6976" citStr="Hall et al. 2009" startWordPosition="1084" endWordPosition="1087">is to build a full grammar tree and assign semantic roles to accurately interpret the text. However, generating full parse trees for medical text requires specialized parsers developed for the clinical domain (Freidman, 2005). It has been shown that shallow syntactic approaches can yield similar results to the ones using full syntactic details (Gildea &amp; Palmer, 2002). In this work we use shallow syntactic and semantic features (manually created concept list and WordNet, Miller 1995) to tag information relating to the numerical values extracted from the text. We use machine learning tool WEKA (Hall et al. 2009) to build binary classifiers that pick positive values from the list of values extracted from the document. Our method allows us to build a robust and extendible system which should be easily portable to texts from different institutions and other medical domains. 2 Method Our method extends Voorham&apos;s work in using the numeric value centered approach while developing a robust way to disambiguate between multiple values in the same document. The information extracted for the report card is divided into four categories: demographic information, numerical measurement values, medication list, and </context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., &amp; Witten, I. H. (2009). The WEKA Data Mining Software: An Update. SIGKDD Explorations .</rawString>
</citation>
<citation valid="true">
<authors>
<author>D T Heinze</author>
<author>M L Morsch</author>
<author>J Holbrook</author>
</authors>
<title>Mining free-text medical records. AMIA,</title>
<date>2001</date>
<pages>254--258</pages>
<contexts>
<context position="1480" citStr="Heinze et al. (2001)" startWordPosition="206" endWordPosition="209">is text is narrative with a possibility of containing headings marking the boundaries of the paragraphs. This remains the medium of choice for storing key patient information as opposed to structured tables due to time constraints, uncertainty about the use of codes, classification limitations, and difficulty with the use of computer systems. The information being stored in machine readable format is not amenable to any form of statistical analysis or review as it exists (Mcdonald 1997, Lovis et al. 2000). The usefulness of mining information from this text has been stressed by many including Heinze et al. (2001) and Hripcsak et al. (1995). The information unlocked from the free text could be used for facilitating patient management, researching disease symptoms, analyzing diagnoses, epidemiological research, book keeping, etc. The free text in these documents has been shown to be less ambiguous than text in general unrestricted documents (Ruch et al. 2001) making it feasible to successfully apply extraction techniques using tools from IE and NLP. Natural language processing has been used to analyze free text in Abstract Achieving guideline-based targets in patients with diabetes is crucial for improv</context>
</contexts>
<marker>Heinze, Morsch, Holbrook, 2001</marker>
<rawString>Heinze, D. T., Morsch, M. L., &amp; Holbrook, J. (2001). Mining free-text medical records. AMIA, (pp. 254-258).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hripcsak</author>
<author>C Friedman</author>
<author>P Alderson</author>
<author>W DuMouchel</author>
<author>S Johnson</author>
<author>P Clayton</author>
</authors>
<title>Unlocking clinical data from narrative reports: a study of natural language processing.</title>
<date>1995</date>
<journal>Ann Intern Med ,</journal>
<pages>681--689</pages>
<contexts>
<context position="1507" citStr="Hripcsak et al. (1995)" startWordPosition="211" endWordPosition="214"> a possibility of containing headings marking the boundaries of the paragraphs. This remains the medium of choice for storing key patient information as opposed to structured tables due to time constraints, uncertainty about the use of codes, classification limitations, and difficulty with the use of computer systems. The information being stored in machine readable format is not amenable to any form of statistical analysis or review as it exists (Mcdonald 1997, Lovis et al. 2000). The usefulness of mining information from this text has been stressed by many including Heinze et al. (2001) and Hripcsak et al. (1995). The information unlocked from the free text could be used for facilitating patient management, researching disease symptoms, analyzing diagnoses, epidemiological research, book keeping, etc. The free text in these documents has been shown to be less ambiguous than text in general unrestricted documents (Ruch et al. 2001) making it feasible to successfully apply extraction techniques using tools from IE and NLP. Natural language processing has been used to analyze free text in Abstract Achieving guideline-based targets in patients with diabetes is crucial for improving clinical outcomes and p</context>
</contexts>
<marker>Hripcsak, Friedman, Alderson, DuMouchel, Johnson, Clayton, 1995</marker>
<rawString>Hripcsak, G., Friedman, C., Alderson, P., DuMouchel, W., Johnson, S., &amp; Clayton, P. (1995). Unlocking clinical data from narrative reports: a study of natural language processing. Ann Intern Med , 681-689.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>C Friedman</author>
</authors>
<title>CliniViewer: a tool for viewing electronic medical records based on natural language processing and XML.</title>
<date>2004</date>
<booktitle>MedInfo ,</booktitle>
<pages>639--643</pages>
<contexts>
<context position="3697" citStr="Liu and Friedman 2004" startWordPosition="533" endWordPosition="536"> demonstrating high precision (88.8-100%). 8 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 8–14, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics medical domain for decision support (Chapman et al. 2005), classifying medical problem lists (Meystre and Haug 2005), extracting disease related information (Xu et al. 2004), building dynamic medications lists (Pakhomov et al. 2002), building applications for better data management, and for diagnosis detection. (Friedman et al. 2004, Roberts et al. 2008, Liu and Friedman 2004). Our goal is to automatically generate diabetes report cards from the free text in physicians&apos; letters. The report card can be used to detect populations at risk for diabetes mellitus and track their vital information over a period of time. Previous work in similar area has seen Turchin et al. (2005) identify patients with diabetes from the text of physician notes by looking for mention of diabetes and predefined list of medication names. They use a manually created list of negation tokens to detect false examples. They compare the process to manual chart review and billing notes and show the</context>
</contexts>
<marker>Liu, Friedman, 2004</marker>
<rawString>Liu, H., &amp; Friedman, C. (2004). CliniViewer: a tool for viewing electronic medical records based on natural language processing and XML. MedInfo , 639-643.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lovis</author>
<author>R H Baud</author>
<author>P Plancheb</author>
</authors>
<title>Power of expression in the electronic patient record: structured data or narrative text?</title>
<date>2000</date>
<journal>International Journal of Medical Informatics ,</journal>
<pages>101--110</pages>
<contexts>
<context position="1370" citStr="Lovis et al. 2000" startWordPosition="188" endWordPosition="191">tation. The voice dictation record is transcribed into free text and stored electronically. The nature of this text is narrative with a possibility of containing headings marking the boundaries of the paragraphs. This remains the medium of choice for storing key patient information as opposed to structured tables due to time constraints, uncertainty about the use of codes, classification limitations, and difficulty with the use of computer systems. The information being stored in machine readable format is not amenable to any form of statistical analysis or review as it exists (Mcdonald 1997, Lovis et al. 2000). The usefulness of mining information from this text has been stressed by many including Heinze et al. (2001) and Hripcsak et al. (1995). The information unlocked from the free text could be used for facilitating patient management, researching disease symptoms, analyzing diagnoses, epidemiological research, book keeping, etc. The free text in these documents has been shown to be less ambiguous than text in general unrestricted documents (Ruch et al. 2001) making it feasible to successfully apply extraction techniques using tools from IE and NLP. Natural language processing has been used to a</context>
</contexts>
<marker>Lovis, Baud, Plancheb, 2000</marker>
<rawString>Lovis, C., Baud, R. H., &amp; Plancheb, P. (2000). Power of expression in the electronic patient record: structured data or narrative text? International Journal of Medical Informatics , 101-110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Mcdonald</author>
</authors>
<title>The Barriers to Electronic Medical Record Systems and How to Overcome Them.</title>
<date>1997</date>
<journal>Journal of the American Medical Informatics Association ,</journal>
<pages>213--221</pages>
<contexts>
<context position="1350" citStr="Mcdonald 1997" startWordPosition="186" endWordPosition="187">using voice dictation. The voice dictation record is transcribed into free text and stored electronically. The nature of this text is narrative with a possibility of containing headings marking the boundaries of the paragraphs. This remains the medium of choice for storing key patient information as opposed to structured tables due to time constraints, uncertainty about the use of codes, classification limitations, and difficulty with the use of computer systems. The information being stored in machine readable format is not amenable to any form of statistical analysis or review as it exists (Mcdonald 1997, Lovis et al. 2000). The usefulness of mining information from this text has been stressed by many including Heinze et al. (2001) and Hripcsak et al. (1995). The information unlocked from the free text could be used for facilitating patient management, researching disease symptoms, analyzing diagnoses, epidemiological research, book keeping, etc. The free text in these documents has been shown to be less ambiguous than text in general unrestricted documents (Ruch et al. 2001) making it feasible to successfully apply extraction techniques using tools from IE and NLP. Natural language processin</context>
</contexts>
<marker>Mcdonald, 1997</marker>
<rawString>Mcdonald, C. J. (1997). The Barriers to Electronic Medical Record Systems and How to Overcome Them. Journal of the American Medical Informatics Association , 213-221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Meystre</author>
<author>P J Haug</author>
</authors>
<title>Automation of a problem list using natural language processing.</title>
<date>2005</date>
<booktitle>BMC Medical Informatics and Decision Making ,</booktitle>
<pages>5--30</pages>
<contexts>
<context position="3434" citStr="Meystre and Haug 2005" startWordPosition="493" endWordPosition="496">et for this project is comprised of 81,932 documents from 30,459 patients collected over a period of 5 years. The patient population is considered high risk for diabetes as they have existing cardiovascular complications. Experimental results validate our method, demonstrating high precision (88.8-100%). 8 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 8–14, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics medical domain for decision support (Chapman et al. 2005), classifying medical problem lists (Meystre and Haug 2005), extracting disease related information (Xu et al. 2004), building dynamic medications lists (Pakhomov et al. 2002), building applications for better data management, and for diagnosis detection. (Friedman et al. 2004, Roberts et al. 2008, Liu and Friedman 2004). Our goal is to automatically generate diabetes report cards from the free text in physicians&apos; letters. The report card can be used to detect populations at risk for diabetes mellitus and track their vital information over a period of time. Previous work in similar area has seen Turchin et al. (2005) identify patients with diabetes fr</context>
</contexts>
<marker>Meystre, Haug, 2005</marker>
<rawString>Meystre, S., &amp; Haug, P. J. (2005). Automation of a problem list using natural language processing. BMC Medical Informatics and Decision Making , 5-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>WordNet: A Lexical Database for English.</title>
<date>1995</date>
<journal>Communications of the ACM ,</journal>
<volume>38</volume>
<pages>39--41</pages>
<contexts>
<context position="6846" citStr="Miller 1995" startWordPosition="1064" endWordPosition="1065">k (1999) discuss some of the many problems of dealing with free text in medical domain. One method to resolve these problems is to build a full grammar tree and assign semantic roles to accurately interpret the text. However, generating full parse trees for medical text requires specialized parsers developed for the clinical domain (Freidman, 2005). It has been shown that shallow syntactic approaches can yield similar results to the ones using full syntactic details (Gildea &amp; Palmer, 2002). In this work we use shallow syntactic and semantic features (manually created concept list and WordNet, Miller 1995) to tag information relating to the numerical values extracted from the text. We use machine learning tool WEKA (Hall et al. 2009) to build binary classifiers that pick positive values from the list of values extracted from the document. Our method allows us to build a robust and extendible system which should be easily portable to texts from different institutions and other medical domains. 2 Method Our method extends Voorham&apos;s work in using the numeric value centered approach while developing a robust way to disambiguate between multiple values in the same document. The information extracted</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>Miller, G. A. (1995). WordNet: A Lexical Database for English. Communications of the ACM , 38, 39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S V Pakhomov</author>
<author>A Ruggieri</author>
<author>C G Chute</author>
</authors>
<title>Maximum entropy modeling for mining patient medication status from free text.</title>
<date>2002</date>
<booktitle>Proceedings of the American Medical Informatics,</booktitle>
<pages>587--591</pages>
<contexts>
<context position="3550" citStr="Pakhomov et al. 2002" startWordPosition="511" endWordPosition="514">ient population is considered high risk for diabetes as they have existing cardiovascular complications. Experimental results validate our method, demonstrating high precision (88.8-100%). 8 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 8–14, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics medical domain for decision support (Chapman et al. 2005), classifying medical problem lists (Meystre and Haug 2005), extracting disease related information (Xu et al. 2004), building dynamic medications lists (Pakhomov et al. 2002), building applications for better data management, and for diagnosis detection. (Friedman et al. 2004, Roberts et al. 2008, Liu and Friedman 2004). Our goal is to automatically generate diabetes report cards from the free text in physicians&apos; letters. The report card can be used to detect populations at risk for diabetes mellitus and track their vital information over a period of time. Previous work in similar area has seen Turchin et al. (2005) identify patients with diabetes from the text of physician notes by looking for mention of diabetes and predefined list of medication names. They use </context>
</contexts>
<marker>Pakhomov, Ruggieri, Chute, 2002</marker>
<rawString>Pakhomov, S. V., Ruggieri, A., &amp; Chute, C. G. (2002). Maximum entropy modeling for mining patient medication status from free text. Proceedings of the American Medical Informatics, (pp. 587–591).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>Maximum Entropy Models for Natural Language Ambiguity Resolution. Phd Thesis.</title>
<date>1998</date>
<contexts>
<context position="9421" citStr="Ratnaparkhi (1998)" startWordPosition="1454" endWordPosition="1455"> 1): preprocessing stage, extraction of the numeric value-label pairs, and testing the validity of the extracted pairs. Preprocessing: The documents were originally stored in Microsoft Word format (WordML). They are converted to XML using XSLT transformation. All formatting information is stripped except for bold and italic font information and paragraph boundaries The paragraphs in the document are further broken down into sentences and tokens. We use OPENNLP Maxent1 library to do sentence boundary detection and tokenization. OPENNLP Maxent is based on maximum entropy algorithms described in Ratnaparkhi (1998) and Berger et al. (1996). The OPENNLP statistical tagger is used to assign syntactic tags to the tokens. Data Extraction: In this phase the system extracts all potential numerical values and assigns them labels. The system loops through all of the tokens in the document, testing for numerical values. It tests each numerical token against a set of regular expressions and assigns them a list of potential labels based on the regular expression it matches. The system takes into account the presence of a measurement unit and revises the potential list of labels based on the unit. For each potentia</context>
</contexts>
<marker>Ratnaparkhi, 1998</marker>
<rawString>Ratnaparkhi, A. (1998). Maximum Entropy Models for Natural Language Ambiguity Resolution. Phd Thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Roberts</author>
<author>R Gaizauskas</author>
<author>M Hepple</author>
<author>Y Guo</author>
</authors>
<title>Mining clinical relationships from patient narratives.</title>
<date>2008</date>
<booktitle>Natural Language Processing in Biomedicine (BioNLP) ACL Workshop.</booktitle>
<contexts>
<context position="3673" citStr="Roberts et al. 2008" startWordPosition="529" endWordPosition="532"> validate our method, demonstrating high precision (88.8-100%). 8 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 8–14, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics medical domain for decision support (Chapman et al. 2005), classifying medical problem lists (Meystre and Haug 2005), extracting disease related information (Xu et al. 2004), building dynamic medications lists (Pakhomov et al. 2002), building applications for better data management, and for diagnosis detection. (Friedman et al. 2004, Roberts et al. 2008, Liu and Friedman 2004). Our goal is to automatically generate diabetes report cards from the free text in physicians&apos; letters. The report card can be used to detect populations at risk for diabetes mellitus and track their vital information over a period of time. Previous work in similar area has seen Turchin et al. (2005) identify patients with diabetes from the text of physician notes by looking for mention of diabetes and predefined list of medication names. They use a manually created list of negation tokens to detect false examples. They compare the process to manual chart review and bi</context>
</contexts>
<marker>Roberts, Gaizauskas, Hepple, Guo, 2008</marker>
<rawString>Roberts, A., Gaizauskas, R., Hepple, M., &amp; Guo, Y. (2008). Mining clinical relationships from patient narratives. Natural Language Processing in Biomedicine (BioNLP) ACL Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ruch</author>
<author>R Baud</author>
<author>A Geissbuhler</author>
<author>A-M Rassinoux</author>
</authors>
<title>Comparing general and medical texts for information retreival based on natural language processing: An inquiry into lexical disambiguation.,</title>
<date>2001</date>
<pages>261--266</pages>
<contexts>
<context position="1831" citStr="Ruch et al. 2001" startWordPosition="259" endWordPosition="262">mation being stored in machine readable format is not amenable to any form of statistical analysis or review as it exists (Mcdonald 1997, Lovis et al. 2000). The usefulness of mining information from this text has been stressed by many including Heinze et al. (2001) and Hripcsak et al. (1995). The information unlocked from the free text could be used for facilitating patient management, researching disease symptoms, analyzing diagnoses, epidemiological research, book keeping, etc. The free text in these documents has been shown to be less ambiguous than text in general unrestricted documents (Ruch et al. 2001) making it feasible to successfully apply extraction techniques using tools from IE and NLP. Natural language processing has been used to analyze free text in Abstract Achieving guideline-based targets in patients with diabetes is crucial for improving clinical outcomes and preventing long-term complications. Using electronic heath records (EHRs) to identify high-risk patients for further intervention by screening large populations is limited because many EHRs store clinical information as dictated and transcribed free text notes that are not amenable to statistical analysis. This paper presen</context>
</contexts>
<marker>Ruch, Baud, Geissbuhler, Rassinoux, 2001</marker>
<rawString>Ruch, P., Baud, R., Geissbuhler, A., &amp; Rassinoux, A.-M. (2001). Comparing general and medical texts for information retreival based on natural language processing: An inquiry into lexical disambiguation., (pp. 261-266).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Turchin</author>
<author>I Kohane</author>
<author>M Pendergrass</author>
</authors>
<title>Identification of patients with diabetes from the text of physician notes in the electronic medical record. Diabetes Care ,</title>
<date>2005</date>
<pages>1794--1795</pages>
<contexts>
<context position="3999" citStr="Turchin et al. (2005)" startWordPosition="584" endWordPosition="587">lassifying medical problem lists (Meystre and Haug 2005), extracting disease related information (Xu et al. 2004), building dynamic medications lists (Pakhomov et al. 2002), building applications for better data management, and for diagnosis detection. (Friedman et al. 2004, Roberts et al. 2008, Liu and Friedman 2004). Our goal is to automatically generate diabetes report cards from the free text in physicians&apos; letters. The report card can be used to detect populations at risk for diabetes mellitus and track their vital information over a period of time. Previous work in similar area has seen Turchin et al. (2005) identify patients with diabetes from the text of physician notes by looking for mention of diabetes and predefined list of medication names. They use a manually created list of negation tokens to detect false examples. They compare the process to manual chart review and billing notes and show the automatic system performs at par with manual review with the advantage of it being highly efficient. In Turchin et al. (2006) the authors use regular expressions to extract blood pressure values and change of treatment for hypertension. They use a set of regular expressions to detect the presence of </context>
</contexts>
<marker>Turchin, Kohane, Pendergrass, 2005</marker>
<rawString>Turchin, A., Kohane, I., &amp; Pendergrass, M. (2005). Identification of patients with diabetes from the text of physician notes in the electronic medical record. Diabetes Care , 1794-1795.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Turchin</author>
<author>N Kolatkar</author>
<author>R W Grant</author>
<author>E C Makhni</author>
<author>M L Pendergrass</author>
<author>J S Einbinder</author>
</authors>
<title>Using regular expressions to abstract blood pressure and treatment intensification information from the text of physician notes.</title>
<date>2006</date>
<journal>Journal of the American Medical Informatics Association ,</journal>
<pages>691--696</pages>
<contexts>
<context position="4423" citStr="Turchin et al. (2006)" startWordPosition="659" endWordPosition="662">The report card can be used to detect populations at risk for diabetes mellitus and track their vital information over a period of time. Previous work in similar area has seen Turchin et al. (2005) identify patients with diabetes from the text of physician notes by looking for mention of diabetes and predefined list of medication names. They use a manually created list of negation tokens to detect false examples. They compare the process to manual chart review and billing notes and show the automatic system performs at par with manual review with the advantage of it being highly efficient. In Turchin et al. (2006) the authors use regular expressions to extract blood pressure values and change of treatment for hypertension. They use a set of regular expressions to detect the presence of a blood pressure related tag, which predicts that the sentence is likely to contain a blood pressure value. The value itself is then extracted using regular expressions. They identify the strength of the process in it being relatively simple, efficient and quick to setup, while its weakness is its lack of generalization. Voorham and Denig (2007) solve a similar problem as in here and extract information regarding diabete</context>
</contexts>
<marker>Turchin, Kolatkar, Grant, Makhni, Pendergrass, Einbinder, 2006</marker>
<rawString>Turchin, A., Kolatkar, N., Grant, R. W., Makhni, E. C., Pendergrass, M. L., &amp; Einbinder, J. S. (2006). Using regular expressions to abstract blood pressure and treatment intensification information from the text of physician notes. Journal of the American Medical Informatics Association , 691-696.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Voorham</author>
<author>P Denig</author>
</authors>
<title>Computerized Extraction of Information on the Quality of Diabetes Care from Free Text in Electronic Patient Records of General Practitioners.</title>
<date>2007</date>
<journal>The Journal of the American Medical Informatics Association ,</journal>
<pages>349--354</pages>
<contexts>
<context position="4946" citStr="Voorham and Denig (2007)" startWordPosition="745" endWordPosition="748">s at par with manual review with the advantage of it being highly efficient. In Turchin et al. (2006) the authors use regular expressions to extract blood pressure values and change of treatment for hypertension. They use a set of regular expressions to detect the presence of a blood pressure related tag, which predicts that the sentence is likely to contain a blood pressure value. The value itself is then extracted using regular expressions. They identify the strength of the process in it being relatively simple, efficient and quick to setup, while its weakness is its lack of generalization. Voorham and Denig (2007) solve a similar problem as in here and extract information regarding diabetes from free text notes using a number centric approach. They identify all positive numerical values and then attach respective labels to the values. They use a keyword based approach with a four word token window and apply a character sequence algorithm to check for spelling errors. Extracting relevant information from free text represents a challenging problem since the task can be considered to be a form of reverse engineering and is above the mere presence of keywords or patterns. It is necessary to generate semant</context>
</contexts>
<marker>Voorham, Denig, 2007</marker>
<rawString>Voorham, J., &amp; Denig, P. (2007). Computerized Extraction of Information on the Quality of Diabetes Care from Free Text in Electronic Patient Records of General Practitioners. The Journal of the American Medical Informatics Association , 349-354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Xu</author>
<author>K Anderson</author>
<author>V R Grann</author>
<author>C Friedman</author>
</authors>
<date>2004</date>
<booktitle>Facilitating Research in Pathology using Natural Language Processing. Proc AMIA Symp,</booktitle>
<pages>1057</pages>
<contexts>
<context position="3491" citStr="Xu et al. 2004" startWordPosition="502" endWordPosition="505"> patients collected over a period of 5 years. The patient population is considered high risk for diabetes as they have existing cardiovascular complications. Experimental results validate our method, demonstrating high precision (88.8-100%). 8 Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 8–14, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics medical domain for decision support (Chapman et al. 2005), classifying medical problem lists (Meystre and Haug 2005), extracting disease related information (Xu et al. 2004), building dynamic medications lists (Pakhomov et al. 2002), building applications for better data management, and for diagnosis detection. (Friedman et al. 2004, Roberts et al. 2008, Liu and Friedman 2004). Our goal is to automatically generate diabetes report cards from the free text in physicians&apos; letters. The report card can be used to detect populations at risk for diabetes mellitus and track their vital information over a period of time. Previous work in similar area has seen Turchin et al. (2005) identify patients with diabetes from the text of physician notes by looking for mention of </context>
</contexts>
<marker>Xu, Anderson, Grann, Friedman, 2004</marker>
<rawString>Xu, H., Anderson, K., Grann, V. R., &amp; Friedman, C. (2004). Facilitating Research in Pathology using Natural Language Processing. Proc AMIA Symp, (p. 1057).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>