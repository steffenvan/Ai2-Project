<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<note confidence="0.7257615">
The Computer Generation of Speech with
Discoursally and Semantically Motivated Intonation
</note>
<author confidence="0.920327">
Robin P. Fawcett
</author>
<affiliation confidence="0.8840795">
Computational Linguistics Unit
University of Wales College of Cardiff
</affiliation>
<note confidence="0.4696175">
Cardiff CF1 3EU
UK
</note>
<sectionHeader confidence="0.830109" genericHeader="abstract">
AbstraCt
</sectionHeader>
<bodyText confidence="0.99994256">
The paper shows how it is possible, in the framework of a
systemic functional grammar (SFG) approach to the
semantics of natural language, to generate an output with
intonation that is motivated semantically and discoursally.
Most of the work =ported has already been successfully
implemented in GENESYS (tlic very large generator of the
COMMUNAL Project see Appendix 1). A major feature
is that it does not first generate a syntax tree and words, and
then impose intonational contours on them (as is a common
approach in modelling intonation); rather, it generates the
various intonational features directly, as it is generating richly
labelled structures (as are typical in SFG), and the associated
hems. The claim is not that the model proposed here solves
all the problems of generating intonation, but that it points
a way forward that makes natural links with semantics and
discourse. A secondary purpose of this paper is to
demonstrate, for one of many possible areas of NLG that
could have been chosen, that there is stilt much important
work to be done in &apos;sentence generation&apos;. I do this in order
to refute the suggestion, Occasionally heard at recent
conferences, that the major work in &apos;sentence generation&apos; has
already been done, and that the main (only?) area of
significance in NLG is in higher level planning. In my
experience the two are interdependent, and we should expect
significant developments at every level in the years to come.
</bodyText>
<sectionHeader confidence="0.822897" genericHeader="categories and subject descriptors">
1. Purpose and Scope
</sectionHeader>
<bodyText confidence="0.978160947368421">
The aspect of Natural Language Generation
(NLG) to be described here is the generation of
spoken text that has Intonation, where that
intonation is motivated both semantically (i.e. in
terms of the semantics - in a broad sense of the
term to be clarified soon - of sentences) and
discoursally (i.e. in terms of what the discourse
pinnning component specifies).1 Any specification
of intonation requires, of course, to be integrated
with an adapted version of a speech synthesizer
(e.g. one that draws on one of the currently
available systems that attempts - inevitably with
Appendix 1 for a brief overview of the project).
1. As will be clear from what follows, the model presented
here owes a great deal to two people in particular: Michael
Halliday and Paul Teach. Through them, I am well aware,
there is a debt to many others, too numerous to mention,
who have worked in the difficult field of intonation in
English. I am grateful too for early encouragement in this
area from Gillian Brown (whose work is drawn on also by
Paul Tench), and for the regular, ongoing stimulus of many
good explorations of ideas in this and other areas with my
colleague Gordon Tucker. But none of these should be
blamed for the inevitable crudities, infelicities and no doubt
errors in the model described here; these are mine.
The approach is very different from that in
MITalk (Allen 1986), which is essentially a text-
to-speech system. So far as I am aware, the only
generative model prior to ours that attempts to
generate intonation that is motivated semantically
and discoursally is the impressive work of Isard,
Houghton, Pearson and their colleagues at Sussex
(Houghton and Isard 1987) and Houghton and
Pearson 1988). Its limitation is the very small size
of its syntax, lexis, semantics and working domain.
We see our work in the COMMUNAL Project as
being to build on their important achievement.
(But see Appendix 2 for what we do not attempt.)
</bodyText>
<sectionHeader confidence="0.839926" genericHeader="method">
2. The Relevant Components of the
Communal Model
</sectionHeader>
<bodyText confidence="0.999893285714286">
The major components of the overall model that
will be referred to below are as follows. We
assume an interactive system, rather than one that
is merely monologue. We shall ignore here the
components related to parsing, interpretation and
inputting to the belief system and planner. The
components relevant to generation are:
</bodyText>
<listItem confidence="0.8648222">
1. The belief system, which includes general and
specific beliefs about (&apos;knowledge of) situations
and things in some domain; specific beliefs about
the content of the preceding discourse, about
various aspects of the current social situation,
about the addressee and his beliefs of all types,
his attitudes, his goals and plans.
2. A planner, which makes general plans, drawing
on knowledge of
3. genres (scripts, schemas, etc), introducing
</listItem>
<bodyText confidence="0.925752111111111">
where appropriate sub-units such as transactions
(see below) and more detailed plans, using ...
4, the local discourse grammar, which is
modelled as a &apos;systemic flowchart&apos; (i.e. a flowchart
containing many small system networks at the
choice points, and which generates exchanges and
their structure),
5. the ledcogrammar, i.e. the sentence generator,
consisting of:
</bodyText>
<page confidence="0.997247">
164
</page>
<figureCaption confidence="0.964631066666666">
a. the system networks of semantic features for 165 in the SEG metaphor, above them). These
a wide variety of types of meaning related to semantic features are then realized in the purely
situations and realized in the clause, including intonational contrasts of TONE, TONICITY and
theme and information structure as well as TONALITY.
transitivity, mood, negativity, modalit/, affective The accounts of the various aspects of intonation
meaning and logical relationships, and equivalent in what follows will inevitably be introductory, and
system networks for things and qualities, and may to the specialist appear simplistic. A
b. the realization rules which turn the selection somewhat fuller treatment is given in Tench and
expressions of features that are the output from Fawcett 1988, and a very full treatment is given in
passes through the system networks into syntactic Tench 1987, which includes summaries of relevant
structures with items (grammatical and lexical) work by other intonation specialists
and markers of punctuation or intonation as their (I omit here, for reasons of space, a specification
terminal nodes. of bow one might model the way in which the
3. Modelling Intonation position in a transaction and an exchange affects
3.1. An Overview of the Generation of Intonation intonation.)
</figureCaption>
<bodyText confidence="0.996889721518988">
Let us imagine that Ivy (the &apos;person&apos; of whose Let us assume, then, that Ivy is preparing a
mind GENESYS models a part) is about to response to the Personnel Officer&apos;s question,
generate a sentence. Let us suppose that she is using the information that, while Mr Peter Piper&apos;s
being consulted by the Personnel Officer of a address is currently 11 Romilly Crescent, Canton,
large institution, who draws regularly on her Cardiff, he is moving from there after one month.
specialist knowledge and advice, and that he has In discourse planning terms, she chooses that her
just asked her &amp;quot;Where does Peter Piper live?&amp;quot;. move will be a &apos;support&apos; for a &apos;solicit information&apos;,
(We shall come later to how intonation is and that the act at the head of the move is a &apos;give
represented.) Like most human users of new content&apos; (see Fawcett, van der Mije and van
language, Ivy makes reasonable assumptions about Wissen 1988). As we shall see, these choices pre-
(loosely, she &apos;knows&apos;) where she is in any current select in the MOOD network of the
transaction (e.g. at the start, in the middle or at leidcogrammar the features [information] and
the end), and where she is in the current [giver]. But first there is a more basic system to
exchange. This affects the pitch level of what she consider.
says. She needs to choose a tone (the change in 3.2. The MODE System
pitch marked by a stepping or a slide on the tonic The initial rule of the semantics of the lesico-
syllable) which will express the MOOD of the grammar to be considered here is:
final matrix clause of her sentence. (&apos;Matrix here situation -&gt;
means &apos;at the top layer of structure&apos;.) She needs &apos;MODE&apos; &amp; &apos;TENOR&apos; &amp; &apos;CONGRUENCE SIT&apos;.
to locate that tone on an item which will be Thus means that, for any &apos;situation&apos; ( roughly
thereby marked as new Information. She needs to &apos;proposition&apos;) that you are generating, you must
decide if it is to be presented simply as &apos;new&apos;, or make choices in all three of the systems named.
as &apos;contrastively new&apos; (in the terms used here). (Notice, then, that &apos;parallelism&apos; lies at the heart of
And she needs to decide on the information the grammar.) Here we shall be concerned only
status of any chunks of information that are to be with the MODE system. (It is from CONGR-
presented as separate from the main information UENCE_SIT that the main part of the network
unit of the clause. (The information that guides is entered, to generate configurations of
these choices comes from various aspects of the participant roles, such as Agent and Affected, and
higher belief system, which there is unfortunately choices in MOOD, such as &apos;information seeker&apos;,
no space to discuss here.) and very many others.) The MODE system is
As we shall see, these various components of the very simple:
semantic level of intonation account, in a different &apos;MODE&apos; -&gt; 70% spoken / 30% written.
way from the usual approach in British intonation This means: &apos;In the MODE system, you must
studies, for Halliday&apos;s well-known triad of TONE, choose between generating a spoken output (for
TONALITY and TONICITY. While it is which under random generation there is a 70%
perfectly possible to talk about the contrasts in probability) and generating a written output
intonational form to which these three refer as (which carries a 30% probability). Clearly, since
&apos;systems&apos;, I suggest that it is more insightful to
take, as the level of contrasts to be modelled in
system networks, the meanings that lie behind (or,
Ivy is in a spoken interaction, she will be strongly
disposed to select [spoken] - but in principle she
need not. We shall not discuss here the
interesting reasons for and against introducing this
system to the lexica-grammar itself, except to
point to two significant advantages that it brings.
Nor, unfortunately, is there space to discuss the
roles of the probabilities and the ways in which
they are assigned (sometimes simply a guess at
the overall pattern for central types of text;
sometimes based on textual studies).
(The next few lines presuppose some familiarity
with systemic grammars; for those without this
knowledge it may be advisable to re-read this
section after seeing the working of the examples.)
What is the role of this system? First, it enables
the grammar-builder to refer, at any point on this
initial pass through the system network, to
whichever feature in this system has been chosen
as an entry condition to a later system. In other
words, where there is greater richness of choice in
meaning in the spoken mode (as is typically the
case with meanings realized in intonation, as
against those realized in punctuation), we can
ensure that those systems are only entered when
the feature [spoken] has been chosen. We shall
shortly see the great value of this. Second, the
&apos;MODE&apos; system enables us to refer, at any point
in a realization rule, on this or any subsequent
pass through the network, to this feature as a
conditional feature for the realization of some
other feature, In other words, we can ensure that
if [spoken] has been chosen the realization will
take the form of intonation, and if [written] has
been chosen it is expressed in punctuation. Both
of these facilities contribute greatly to the elegant
operation of the lexicogrammar as a whole, both
in meanings realized in intonation and in many
other ways.
</bodyText>
<subsectionHeader confidence="0.715936">
33. The Sentence Generator MOOD
</subsectionHeader>
<bodyText confidence="0.941514529411765">
The unmarked choice in the &apos;CONGRUENCE
SIT&apos; system is, unsurprisingly, frongruent_siit
This is the choice that opens up the whole array
of meanings associated with realization in a
clause, and many parallel systems follow. Among
these is the MOOD network This is a fairly
large and complex network of meanings, and
these are realized partly in syntax, partly in items
(such as &amp;quot;please&amp;quot;), and partly in tone ( = variation
in pitch). The network is too large and complex
to present here, but we shall trace a route through
it that shows why it is central to an understanding
of intonation. The first options in the current
GENESYS network are shown below:
congruent sit &gt;
&apos;TRANSITIVITY* &amp; &apos;MOOD (&amp; OTHERS).
&apos;MOOD(A)&apos; &gt; 90% information / 10% directive.
</bodyText>
<equation confidence="0.75530925">
information -&gt; &apos;MOOD(8)&apos; &amp;
&apos;TIME_REFERENCE_POINT (&amp; OTHERS).
&apos;MOOD(B)&apos; -&gt;
70% giver (1.2) / 30% seeker (16).
</equation>
<bodyText confidence="0.999511">
The second line reads: &apos;In the MOOD(A) system
you must choose between the feature
[information], which overall has a 90% probability
of being selected, and [directive], which has only
a 10% probability. As so often, the choice of a
single feature leads to further parallel systems,
one of which continues the MOOD network itself.
The last line in the above rules exemplifies the
use of numbers in brackets after the features; it is
the number of the realization rule for the feature
concerned. What will this look like?
Here is a slightly simplified version of the
realization rule for [giver]:
</bodyText>
<subsectionHeader confidence="0.856827">
1.2 : giver:
</subsectionHeader>
<bodyText confidence="0.9928975">
if fills &apos;Z&apos; and (simplex sit or
final co ordinated situation)
then if on first_pass written then &apos;E&apos; &lt;&apos;.&amp;quot;,
if on —first_pass spoken then &apos;E&apos; &lt; &amp;quot;I&amp;quot;).
The effect of this rule is on the &apos;Ender&apos; (i.e. &apos;E&apos;,
the last element in the structure of the clause). If
[written] is chosen in the &apos;MODE&apos; system it is
expounded by a full stop (Br. E. for &apos;period&apos;), but
if the choice is [spoken] it is expounded by a final
intonation unit boundary, i.e. j. However, says the
rule, neither realization will occur unless the
clause (1) directly fills the element &apos;Sentence&apos;
(represented by &apos;Z&apos; as an approximation to sigma)
and (2) is &apos;simplex&apos;, i.e. is not co-ordinated with
one or more other clauses or, if it is, is the final
clause.
This may seem a surprisingly complex rule to
those in NLP used to working with mini-
grammars. But this is typical of the working level
of complexity in a natural language, and those
who are used to working with the problems of
building broad coverage grammars will appreciate
that this is not a particularly complex rule. In the
case of our example the effect is to give to Ivy&apos;s
output a final intonation unit boundary.
We come next to an example of the value of being
able to use of the feature [spoken] as an entry
condition to a system. This is necessary because
the MOOD network also builds in variables in
&apos;key&apos; (in the sense of Halliday 1970), i.e. finer
choices within the MOOD options. These
correspond to what Tench treats separately as
variations in attitude. While accepting the view
that these more delicate choices can be seen as
</bodyText>
<page confidence="0.997996">
166
</page>
<bodyText confidence="0.984772311926606">
serving a separate function from the function of
the basic tone, the fact is that in any systemic
computational implementation the way in which
they enter the choice system is simply as more
delicate choices that are directly dependent on the
broad choice of meaning realized in the broad
tone. The range of such delicate variations
appears to be potentially different for the various
meanings (see further below). In the systems
given below, note the high probability of choosing
[assertive] followed by [neutral].
giver &amp; spoken -&gt;
70% assertive / 15% deferring (1.21) /
15% with_reservation (1.22).
assertive - &gt; 2% very strong (1.23) / 8% strong
(1.24) / 60% neutral (1.25) / 30% mild (1.26).
In an intermediate level model (such as Prototype
Generator 2 (PG2), which is the most advanced
version of GENESYS currently implemented) we
need only relatively simple rules such as the
following:
1.21 : deferring:
if fills &apos;Z&apos; and on first_pass spoken and
(simplex sit orlinal_co_ordinated_situation)
then &apos;2-&apos; by &apos;NT&apos;.
(&apos;NT&apos; = &apos;Nuclear Tonic&apos;; see 3.4.3.)
1.22 : with reservation
if fills and on first_pass spoken and
(simplex sit or falai co_ordinated_situation)
then &apos;12rby Isrr.
And so on, for [very strong] (realized by &apos;21&apos;),
[strong] (realized by &apos;1+ &apos;), [neutral] (realized by
&apos;1&apos;) and [mild] (realized by &apos;1-&apos;).
Here we are using a numerical notation for tones
that goes back to an earlier tradition even than
Halliday&apos;s description (1967, 1970), though it has
much in common with Halliday&apos;s. (Readers from
the American tradition used to an iconic
representation may have some adjustments to
make in interpreting the notation. But there
should be no fundamental difficulty; Halliday&apos;s
description has been widely used (and indeed
tested) on American and Canadian English.)
I give next a brief summary of the differences
between the scheme for tones used here and
Halliday&apos;s well-known scheme (1967, 1970).
Tench&apos;s (and so my) numbers &apos;1&apos; and &apos;2&apos;
correspond to Halliday&apos;s usage, as do the use of
&apos;+&apos; and &apos;-&apos;. But Halliday&apos;s &apos;Tone 3&apos; is seen as a
variant of our Tone 2; Halliday&apos;s Tone 4 (a fall-
rise) is represented by &apos;12&apos;; and his &apos;Tone 5 (a
rise-fall) is shown as &apos;21&apos;. Tench&apos;s general
descriptions of the tones in words (1987) imply
four pitch levels, and I therefore use the following
labels for the model implemented: base, low, mid
and high. The four levels in turn provide a
framework for describing three types of pitch
change. It will be helpful for what follows to set
them out as three &apos;scales&apos;: these descriptions of
the tones are in effect source material for writing
realization rules. (I have given these scales
informal semantic labels; these are not intended
to correspond directly to the features in the
MOOD network encountered so far, but to evoke
features from various parts of the network,
including the many options dependent on
[directly*. Finally, let me remind you that we
are not at this point trying to account for all
tones, but only for those that carry the MOOD of
a matrix simplex Of final clause. This clear
separation of the ways in which tones are
generated is a key feature of the present
proposals. We shall come shortly to some of the
ways of generating appropriate tones for some of
the other positions in which tones occur.
The &apos;assertive&apos; scale (Tones 21 and 1):
Tone 21: rise-fall (rise to high plus fall to base)
Tone 1+: high-fall (fall from high to base)
Tone 1: mid-fall (fall from mid to base)
Tone 1-: (fall from low to base)
Also (see below):
Tone 21.: low rise-fall (lower version of Tone
21)*
The &apos;deferring&apos; scale (Tone 2):
Tone 2+: high-rise (rise from base to high)
Tone 2: mid-rise (rise from base to mid)
Tone 2-: low-rise (rise from base to low)
The &apos;implication&apos; scale (Tone 12):
Tone 12: fall-rise
Also (see below):
Tone 12-: low fall-rise (lower version of 12)k
* Tench suggests that these are variants of Tone
21 and 12 that additionally signal &apos;emotional
involvement&apos;.
As will be clear, Tench and I propose a
modification to Halliday&apos;s basic set of contrasts
in TONE, such that Halliday&apos;s Tone 5 is seen as
an extreme form of Tone 1. This fits naturally
with the semantics of these tones. In a somewhat
similar way, Tench treats Halliday&apos;s Tone 3 (a low
rise) as a variant of Halliday&apos;s Tone 2, under the
rubric of &apos;deference to the listener&apos;, and we adopt
this too in COMMUNAL But note that, while
that kind of semantic description holds good for
Tone 2s (Halliday&apos;s Tone 3s) in the sentence-final
position, I shall suggest other means of generating
them in non-final positions. In the present system
there are no &apos;double tone groups&apos;, such as
Halliday&apos;s Tone 13 (i.e. a Tone 1 to res lin; the
</bodyText>
<page confidence="0.988052">
167
</page>
<bodyText confidence="0.999939882352941">
main MOOD meaning, followed by a Tone 3
(here 2) for &apos;supplementary information&apos;.) Such
final Tone 2s will be generated in a similar way to
that to be illustrated in section 33 below for
initial Tone 3s (and, as we shall see, 12s). Finally,
note that I include here one option that Tench
includes under &apos;status of information&apos;. This is his
&apos;implication&apos;, realized in Tone 12, i.e. a fall-rise.
This is Halliday&apos;s Tone 4, which he characterizes
as (among other descriptions) &apos;with reservation&apos;.
This tone occurs both as a carrier of MOOD and
otherwise; it is with the former that we are
concerned here. It seems plausible to treat it as
a variant that can be chosen as an alternative to
the basic falling and rising tones recognized by
both Halliday and Tench, and I have therefore
incorporated it in the overall MOOD network.
</bodyText>
<subsectionHeader confidence="0.9347765">
3.4. Focus of Information
3.4.1. The Line of Approach to the Problem
</subsectionHeader>
<bodyText confidence="0.999949636363636">
I shall present here a somewhat novel approach to
the relationship between the two sets of
phenomena described by both Halliday and Tench
as TONALITY and TONICITY. TONALITY is
typically thought of as &apos;cutting up a Wing of
words into intonation units&apos; (Tenth&apos;s term;
Halliday&apos;s is &apos;tone groups), with each intonation
unit realizing one Information unit. The
problem, when one is approaching the question
from the angle of generation, is that there is no
string of words to cut up - not, that is, until the
sentence has been generated. We therefore need
to Look for a semantic approach to the problem.
My proposal is that it is helpful to start not with
TONALITY but TONICITY.
TONICITY is the placing of the tonic on a
syllable. The item so marked is shown to be
being presented as new information - and this is
a semantic concept. (&apos;New&apos; information is
information presented as &apos;not recoverable?) But
a further problem arises, in that linguists
recognize both &apos;marked&apos; and &apos;unmarked&apos; tonicity.
</bodyText>
<subsectionHeader confidence="0.6628">
3.4.2. Generating Marked Tonicity
</subsectionHeader>
<bodyText confidence="0.997154875">
Marked tonicity occurs when the item containing
the tonic syllable is presented by the speaker as
&apos;contrastively new&apos;. Unmarked tonicity occurs
when there is no marked tonicity (which is by far
the most usual case); we shall return to this
shortly. Marked tonicity is handled in GENESYS
in the following way. In principle, any pathway
through the system network that results in the
generation of a formai item will lead to a system
of the following form (where &apos;x&apos; is the current
terminal feature):
x &gt; not_contrastively new / contrastively new.
The realization of [contrastively new] is that a
contrastive tonic is conflated witg the element of
structure that the item expounds. The simple
version implemented in PG2 is as follows:
</bodyText>
<figure confidence="0.386859857142857">
&apos;INFORMATION FOCUS&apos; -&gt;
99% no_element Marked_as_contrastively new /
1% element_mariced_as_contrastively new.
element_marked_as_contrastively new -&gt;
50% contrastive_newnesson_polarity (18.1) /
50% contrastive_newness_on_process (18.2) /
0% other.
</figure>
<bodyText confidence="0.97750075">
Realization rule 18.1 states the complex set of
conditions for conflating a contrastive tonic (CT&apos;)
with the appropriate element; for the POLARITY
system (&apos;positive&apos; vs. &apos;negative&apos;) this is typically the
Operator (which may have to be supplied by a
&apos;do-support&apos; rule) but it may be any one of several
others, depending on whether or not the clause is
moodless and, if not, whether a directive, and if
not, what auxiliaries are realized, etc. The rule
for presenting the &apos;process&apos; (realized in the Main
verb) as &apos;contrastively_new&apos; is however extremely
simple:
18.2: contrastive newness_on_process :
&apos;Cr, by qv% —
In the case of our example, the choice is not to
present any element as contrastively new.
</bodyText>
<subsectionHeader confidence="0.68036">
3.4.3. Generating Unmarked Tonicity
</subsectionHeader>
<bodyText confidence="0.999937875">
How, then, should we generate unmarked
tonicity? The answer is simple: as the default -
i.e. when there is no contrastive tonic. In other
words, I want to suggest that unmarked tonicity is
a formal phenomenon of intonation that does not
express an active choice in meaning. The relevant
facts are well known, i.e., roughly, that what we
here term a nuclear tonic (NT&apos;) fang on the last
lexical item in the information unit. The question
is: &apos;How can we define the intonation unit, in
semantic terms?&apos; The only contender as a
semantic unit, in the GENESYS framework, is the
situation, i.e. the semantic unit typically realized
in the clause. The actual decision as to which
item the unmarked tonic shall be assigned to gets
made relatively late in the generation process. In
GENESYS we simply have a list of the few dozen
items generated by the lexicogrammar that cannot
carry the unmarked tonic: roughly, the
&apos;grammatical items&apos; of English. Essentially, then,
this default rule will insert one, and only one,
nuclear tonic in each sentence. This will hold
even when there are two or more co-ordinated
clauses in that sentence, and/or one or more
</bodyText>
<page confidence="0.9944">
168
</page>
<tableCaption confidence="0.340887">
embedded clauses.
3.5. Status of Information
33.1. The Importance of this Category
</tableCaption>
<bodyText confidence="0.995489471698114">
This is a concept not distinguished as a separate
phenomenon in Hallidays treatment of intonation,
but which Tench does treat separately. This clear
separation of two semantically distinct phenomena
was a significant help in developing the generative
model proposed here. However the concept of
&apos;status of information&apos; is quite highly generalised,
in the sense that it is not manifested in just one
part of the overall network (as for example
MOOD is). Specifically, we find this option at
many of the points where a unit is generated that
Is not the final matrix clause in the sentence.
Many of these (though by no means all) have
already been implemented in GENESYS, and the
following are a representative sample.
33.2. The Co-ordination of Situations and Things
One major source of multiple intonation units is
co-ordination. Thus, when GENESYS generates
co-ordinated clauses (realizing co-ordinated
situations) such as &amp;quot;Either Ivy kW= Ike, or she
loves Fred, or she doesn&apos;t love anybody.&amp;quot;, she first
recognizes at an abstract level that separate
information units are being assigned and then
inserts, depending on whether the output is to be
spoken or written, either (1) commas or (2)
intonation unit boundaries and an appropriate
tone such as Tone 2. We shall not reproduce
here the surprisingly large system network and
realization rules for this area of the grammar,
which merit a paper to themselves. Ail that needs
to be said is that to develop a model of clause co-
ordination that incorporates most of the
phenomena of naturally occurring texts is a major
task, and that it took several months of work to
build our current system. In terms of the above
example, it generates, if [spoken] has been
selected:
I either Ivy loves Ike/NT/2 I
or she loves Fred/NT/2 I
or she doesn&apos;t love anybody/NT/1 I
While the patterns of the networks and their
realizations are different for the co-ordination of
nominal groups, they are handled in a similar way.
The system accommodates the perhaps surprising
fact that, in the case of nominal groups, there is
typically one more intonation unit than there
would be commas. As in the MOOD network,
there is a greater number of delicate choices
realized in intonation than there is in punctuation.
So the feature [spoken] is again used as an entry
condition to the system in the
&apos;CO ORDINATION SIT&apos; network, to ensure that
the system is not entered unless [spoken] has been
chosen. Here the speaker chooses in the system of
runmarked_co ordination spoken] vs.
[co ordination vvilla reservation]: The first is
reased by a fone base-to-mid rise; Halliday&apos;s
Tone 3), and the second by a Tone 12 (fall-rise;
Hallidays Tone 4).
33.3. Thematized Circumstances: Situations,
Things, Qualities
Another major source of additional intonation
units is the thematization of time and
circumstance. These meanings are realized in
Adjuncts of various types. They may occur in
various places in the clause, and here we shall
consider just those that appear at the beginning of
a clause. So far GENESYS includes eleven types,
each of which may be realized by either a clause
or a group (three different classes of groups being
recognized: nominal, prepositional and quantity-
quality groups). Note, then, that we have now
identified a second major source of what has been
termed &apos;clause combining&apos;. A similar approach is
needed for &apos;clause final&apos; clauses, i.e. clauses that
fill any of the eleven types of Adjunct built into
GENESYS so far, and that come late in the
clause. (This is a different approach to clause-
combining from that in Halliday 1985 and so from
that in the Nigel grammar at ISI; here such
clauses are simply treated as embedded - so far
with gains in generalizations rather than losses.)
Let us take as an example the concept of time
position, which is one of five types of
&apos;circumstance of time&apos; recognized in GENESYS -
the others being repetition, duration, periodic
frequency, and usuality. While GENESYS will
happily generate clauses such as &amp;quot;until he leaves
the company&apos; to specify a time position, in the
case of our example Ivy has chosen the simpler
structure of the prepositional group, i.e. &amp;quot;until next
month&amp;quot;. The first system to consider is:
&apos;TIME POSITION TFIEM.ATIZATION&apos; -&gt;
99%—unthematize-1_time_position (202) /
1% thematized_time_position (203).
Because the answer modifies the presuppositions
that the Personnel Officer brought to his question
(i.e. that Peter Piper had a fixed address), Ivy
decides to thematize the part of her reply that
expresses this, i.e. her specification of the &apos;time
position&apos;. This is realized by placing the &apos;time
position Adjunct&apos; at an early place in the clause.
(Note that this is not a &apos;movement rule&apos;; there are
no such rules in this generator, and no element is
located until it can be located in its correct place.)
The next two systems are:
</bodyText>
<page confidence="0.995361">
169
</page>
<bodyText confidence="0.956358088888889">
thematized_timeiposition -&gt;
80% time_position_as_separate
information unit /
20% time...position as_part_of main_
information unit.
spoken &amp; time_position_as_separate_
information unit -&gt;
20% highliglted thematized time _position /
80% neutral theTnatized tim—e_position.
The first of the two systems applies whether or
not the MODE is spoken or written (the written
realization being a comma). But the writing
system cannot make the distinction offered in the
second, so that here again the feature [spoken]
from the original MODE system is used as an
entry condition. In our example Ivy chooses to
present the specification of the time position
(&amp;quot;until last week&apos;) as a separate information unit,
and furthermore to highlight it (by using a Tone
12 (a fall-rise).
But you may have noticed that these features have
no realization rules. How, then, do these choices
get realized? The answer is that these features
act as conditional features on the realization rules
for the units that are generated, after re-entry to
the overall network, on a subsequent pass though
it. The reason for including the system at the
rank of situation is that in this way we can capture
the generalisation that these options are relevant
whatever the unit - a clause or some kind of
group - that fills the Adjunct.
In our case the sub-network that we find ourselves
in on re-entry is the network for
&apos;MINIMAL RELA&apos;TIONSHIP_PLUS_THING&apos;,
i.e. the network from which prepositional groups
are generated. Here we enter the following
system (where the suffix &apos;mrpt&apos; echoes the name
of the overall system):
location_mrpt -&gt;
place_mrpt (90.001) / time _mrpt (90.002).
Here (time mrpt) will be pre-selected by the
choice at file higher rank. The part of its
realization rule concerned with intonation may
appear, once again, somewhat complex, but once
again it seems to correspond to the relative (but
always limited) complexity of the facts of how
English works:
90.002: time_mrpt :
if (on_previous_pass
time_position_as separate_information_unit
and on first_pass spoken)
then (if current unit pgp then e &lt;
if on_previous_pass
highlighted_tmatized_time_position
then &apos;12&apos; by yr,
if on_previous_pass &apos;
neutral thematized_time_position
len &apos;2&apos; by T.
As you will see, these rules insert appropriate
intonation boundaries and tones. The tonic (&apos;r)
is already waiting in the starting structure of the
prepositional group, so that the rule simply
conflates the actual tone with it. Let us assume
that Ivy, in order to highlight still further the
thematization of the words 6 month&amp;quot;, selects the
highlighting rather than the neutral option. (The
nominal group &amp;quot;next month&amp;quot; is generated by a
further re-entry.) Finally, the system supplies the
initial intonation unit boundary for any unit
without one. If we assume that the rest of items
generated (in components not considered in this
paper) are &amp;quot;he will be living at eleven Romilly
Crescent, Canton&amp;quot; the full output for our example
is:
I until next month/T/12 I he will be living at
eleven Romilly Crescent/T/2 I Canton/NT/1 I
33.4. Other Sources of Intonation
Other sources of intonation occur in specialist
mini-grammars such as those for dates and
addresses. These can be quite complex, and may
insert several tonics, each with an appropriate
tone. Our worked example illustrates one such
case: note the Tone 2 on &amp;quot;Crescent&amp;quot;. Yet other
types will be included in the next version of
GENESYS, including (1) Adjuncts (which may be
filled by clauses or groups) that are placed after
the nuclear tonic of a clause and which carry
&apos;supplementary information&apos;, and (2) &apos;non-
restrictive relative clauses&apos; (i.e. ones that carry,
once again, &apos;supplementary information?),
</bodyText>
<subsectionHeader confidence="0.9751">
3.6. Summary of the lexicogrammatical
</subsectionHeader>
<bodyText confidence="0.990975058823529">
generation of intonation
We have now completed a fairly full specification
of the major aspects of intonation included at the
present stage of the development of the
GENESYS model.
To summarize: GENESYS offers the choice, on
entering the first system that results in the
generation of a sentence, between [written] and
[spoken]. The importance of this apparently
trivial system is that the choice made in it
determines whether or not one can go on to enter
quite a number of more &apos;delicate&apos; systems whose
choices are realized in intonation. Its features
also act as conditions on the realization of
features chosen in the same network, or in one
entered on a subsequent pass. The result is that
the realization at the level of form will be in
</bodyText>
<page confidence="0.991218">
170
</page>
<bodyText confidence="0.999977475">
terms of either intonation or punctuation. We
have seen how choices in MOOD, in
INFORMATION FOCUS and in various types of
&apos;status of informalion&apos; contribute together to the
specification of intonation, and we have seen some
of the details of how this can be implemented.
The result is an integrated model that avoids the
psychologically implausible approach whereby one
first generates a syntax tree and a string of words
at its leaves, and then &apos;adds on&apos; the intonation.
Instead, it treats intonation as one of three modes
of realization (the other two being syntax and
items), generating the various aspects of
intonation at appropriate points in the generation
of syntax and items.
It may be helpful to conclude by specifying
explicitly the final stages of this process. First the
generator looks for a contrastive tonic (ar) with
which to conflate the tone, and then, if there Isn&apos;t
one, it provides as a default a nuclear tonic (&apos;NT&apos;)
for the final matrix clause, i.e. the intonational
element of structure with which the tone realizing
the meaning of MOOD is conflated. The other
intonation units specified by various types of
Information status are fitted around this central
framework, receiving tones appropriate to their
status. Where they are clauses these tones will be
conflated with a nuclear tonic (unless, of course,
there is a contrastive tonic), and where they are
groups the tones will be conflated with a simple
tonic. A nuclear tonic is thus one that is
potentially capable of receiving the type of tone
that realizes a MOOD option. It should be made
clear that, in every case of the location of a
nuclear tonic or a simple tonic, the element with
which it is conflated must be out that is not
expounded by an item from the list of inherently
weak items. (Any such item may of course still
receive a tonic by being contrastively stressed, as
in I he has/CT/1+ eaten it I.)
</bodyText>
<sectionHeader confidence="0.997949" genericHeader="method">
4. Conclusions
</sectionHeader>
<subsectionHeader confidence="0.973317">
4.14 Overall Summary
</subsectionHeader>
<bodyText confidence="0.999987727272727">
The COMMUNAL project began with a hope
that it would be possible to take the insights from
a Hallidayan-Tenchian view of intonation, and to
develop a computational adaptation and
implementation of them. A promising overall
approach to the problem has indeed been
developed; much of the resulting model has been
worked out in considerable detail; and many large
and significant portions have been implemented
computationally. The framework has proved itself
to be adaptable when modifications are indicated,
and there is good reason to hope that aspects not
as yet worked out explicitly will prove to be
solvable in the framework of the present model.
There is, therefore, the exciting prospect that,
when our sister project gets under way and
provides the necessary complementary
components (no doubt with some requirements on
us to adapt our outputs to their needs) we shall
be in a position to offer a relatively full model of
speech with discoursally and semantically
motivated intonation. It will, moreover, be a
principled model, and we hope that it will be
capable of further extension and of tine-tuning.
We feel that the use of SFG, and specifically of
the type that separates clearly system networks
and realization rules (as in GENBSYS), gives us
a facility that is sensitive to the need for both
extension and fine-tuning. Above all, the
centrality in the model of choice between
semantic features makes it a natural formalism
for relating the &apos;sentence grammar&apos; to higher
components in the overall model.
</bodyText>
<subsectionHeader confidence="0.97941">
4.2. The General Prospect in NW
</subsectionHeader>
<bodyText confidence="0.999956162162162">
Finally, let me turn to a more general point. It
appears that, increasingly over the last few years,
the focus of interest for many researchers in NW
has switched from what we might term sentence
generation to higher level planning (which 1 term
discourse generation). It is here, one sometimes
hears it said, that &apos;all the really interesting work&apos;
is being done. Going implicitly with this claim is
the assumption, which I have occasionally heard
expressed quite explicitly, that the major problems
of sentence generation have been solved.
But is this really so? While a lot of very
impressive work has been done, and while some
quite large generators have been built (e.g. as
reported in McDonald 1985, Mann and
Mathiessen 1985, Fawcett 1990), very many major
problems remain unresolved. Specifically, many
important aspects of &apos;sentence grammar&apos; remain
outside the scope of current generators. Where,
for example, will we find a full description of a
semantically and/or pragmatically motivated
model of even such a well-known syntactic
phenomenon as the relative clause? And what
about comparative constructions (where even the
Linguistics literature is weak)? And there are
many, many more areas of the semantics and
syntax of sentences where our models are still far
from adequate. There are also many issues of
model construction regarding, for example, the
optimal division of labour between components,
the outlining of which deserves a separate paper
(or book). And, even if we had models that
covered all these and the many other areas
competently, we have hardly begun the process of
developing adequate methods for the comparison
and evaluation of models. Thus there is still an
enormous amount of challenging and fascinating
</bodyText>
<page confidence="0.994411">
171
</page>
<bodyText confidence="0.999934842105263">
work to do before we can say with any confidence
that we have anything like adequate sentence
generators. (A senior figure in German MP
circles suggested at COLING &apos;88 that one can buy
good sentence generators off the shelf. It depends
how good &apos;good&apos; is!)
In this paper I have illustrated two crucial points:
(1) that there are indeed significant areas of
language not yet adequately covered in current
generators, and (less clearly because I have had to
omit the relevant section for reasons of space) (2)
that the development of an adequate model of
these depends on the concurrent development of
discourse and sentence generators.
Clearly, while there are in existence a number of
fairly large sentence generators, we have in no
way reached a situation where no further work
needs to be done. I am aware, as the director of
a project that seeks to provide rich coverage for
as much of English as possible, that we have a
great deal of work still to do, and that this holds
for the sentence generator component as well as
for the discourse planning systems. GENESYS
already has 50% more systems than the NIG.EL
(in the long established Penman Project; see
Appendix 1), but our rough estimate is that we
need to make it at least as large again before we
have anything approaching full grammatical
coverage. And, of course, as everyone who has
wrestled seriously with genuine natural language
knows, many tricky problems will remain even
then. Finding anything like the &apos;right&apos; solution to
many of these will require, I claim, models that
have developed, in dose interaction with each
other, their discourse planning and their sentence
generation components - and their belief
representation, including beliefs about the
addressee.
</bodyText>
<sectionHeader confidence="0.99493" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999407">
The research reported here was supported by
grants from R.SRE Malvern under contract no.
ER1/9/4/2181/23, by the University Research
Council of International Computers Ltd, and by
Longman.
</bodyText>
<sectionHeader confidence="0.977098" genericHeader="method">
Appendix 1
</sectionHeader>
<bodyText confidence="0.999712149253732">
COMMUNAL is a major research project that
applies and develops Systemic Functional
Grammar (SFG) in a very large, fully working
computer program. The acronym COMMUNAL
stands for COnviviai Man-Machine
Understanding through NAtural Language. The
principles underlying the project are set out in
Fawcett 1988, and an illustration of a generation
is presented in Tucker 1989. A fuller (but fairly
informal) overall description, including some
comparison with other projects, is given in
Fawcett 1990. See also Fawcett (to appear). The
project is planned to last 5 years, with around 6
researchers working on it. We finiqhe.d the
successful Phase 1 in 1989, and now (May 1990)
are getting under way on Phase 2 The central
component of the overall system is the generator,
built at Cardiff. This is called GENESYS
(because it GENErates SYStemically).
Contributions from the University of Leeds in
Phase 1 were to build (1) a derived probabilistic
purser, called the RAP (for Realistic Annealing
Parser, which devetops earlier work at Leeds),
and (2) the interpreter (called REVELATION,
because it reveals the &apos;meaning&apos; from the
&apos;wording). Each of these is a major development
in its field. But because both build directly on the
relevant aspects of GENESYS, we can
characterise the coverage of the COMMUNAL
system as a whole in terms of the size of
GENESYS.
Here is a quotation and a few facts to give you a
perspective on COMMUNAL at the end of Phase
1, McDonald, Vaughan and Pustejovsky
(1987:179), in referring to the Penman project at
the University of S. California, say: &apos;Nigel,
Penman&apos;s grammar .... is the largest systemic
grammar and possibly the largest machine
grammar of any kind.&apos; Although the
COMMUNAL team developed GENESYS
completely independently, starting from scratch
with new system networks and handling
realization in a rather different way, GENESYS
already has many more systems than Nigel. (This
is not a criticism of Nigel; the research team have
been working on other components of Penman).
A major theoretical difference between the two is
that the networks in GENESYS are more
explicitly oriented to semantics than in Nigel. We
make the assumption that the system networks in
the lexicogrammar are the semantic options.
GENESYS has around 600 semantic systems
realized In grammar (syntax and morphology, and
also intonation and punctuation (see below), while
Nigel has about 400 grammatical systems. But
GENESYS additionally does something that the
builders of Nigel would have liked to do, but from
which they have so far been prevented (by the
requirement of a sponsor): it integrates system
networks for vocabulary with the networks
realized grammatically. GENESYS is still
growing, so that in Phase 2 we estimate that it will
more than double the number of systems realized
in syntax and grammatical items. This should
enable it to handle something approaching
unrestricted syntax. COMMUNAL&apos;s first major
achievement is therefore the size and scope of
</bodyText>
<page confidence="0.993005">
172
</page>
<bodyText confidence="0.9997618">
GENESYS. The second must be seen in the
wider framework of the model as a whole. It has
been a long-standing goal of NLP to build a large
scale system that uses the same grammar to
either generate or interpret a sentence. (Many
current systems use a different grammar for each
process.) The second major achievement is to
have performed this task with a very large
grammar - a Systemic Functional Grammar, in
this ease. (This will be the subject of a separate
paper in the future.) A third achievement
(though one less relevant in the present context)
has been the development of a probabilistic
parser by the Leeds part of the COMMUNAL
team.
</bodyText>
<sectionHeader confidence="0.976131" genericHeader="conclusions">
Appendix 2
</sectionHeader>
<bodyText confidence="0.995254603773585">
&apos;Intonation&apos; is a term susceptible to a wide range
of interpretations. It may therefore be useful to
list some major aspects of die complex task of
generating natural intonation that will not be
discussed here. The first four are not covered
because they lie outside the current goals of the
COMMUNAL project, while the last two are
omitted because they will be implemented (we
expect) by a sister project, support for which is
currently being negotiated.
1. We shall not be concerned with the high level
planning that will tailor the text to the needs of
the addressee as affected by the channel (e.g. to
build in greater redundancy, in the form of
repetition of subject matter in planning what to
express overtly, act by act). (For the general
notion of tailoring, see Paris 1988.)
2. We shall not discuss variation in intonational
characteristics of the sort that distinguish between
speakers of different dialects (geographical, social
class, age, etc).
3. The same goes for individual variation, i.e.
intonational idiolect.
4. We shall ignore the code of tone of voice
(&apos;angry&apos;, &apos;conciliatory&apos;, &apos;delighted&apos;, etc). At the
same time we recognize that it is an important
semiotic system in its own right, and that in the
longer run the way in which it is, as it were,
superimposed on the intonation system itself must
be modelled. We recognize too the problems of
drawing a firm line between tone of voice and
some of the quite delicate distinctions that we
shall recognise in the MOOD system (c.f.
Halliday&apos;s 1970 term &apos;key).
5. We shall ignore any aspect of intonational
variation that does not realize meaning. For
example, it may be that speakers introduce
semantically unmotivated variation into the pre-
tonic segment of an intonation unit, in order to
avoid monotony (cf. House and Johnson 1987).
(An alternative hypothesis, of course, might be
that such variation is in fact semantically
motivated, but that we have not yet discovered
what aspects of meaning it correlates with and
how best to refer to it; this is a characteristic of
much interpersonal meaning.)
6. We shall not be concerned here with the
physical implementation of the output, but simply
(if only it were simple!) with providing a written
text output marked appropriately for input to the
system which will integrate it with the speech
synthesis representation of the segmental
phonology.
</bodyText>
<sectionHeader confidence="0.999376" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.894215566666667">
Allen, I. (ed.) From Tert to Speech: the MITalk
System. Cambridge: Cambridge University Press.
Benson, JD., and Greaves, W.S., (eds.) 1985.
Systemic perspectives on discourse, Vol 1: Selected
theoretical papers from the Ninth International
Systemic Workshop. Norwood, NJ., Ablex.
Brady, M., and Berwick, LC. (eds), 1983.
Computational models of discourse. Cambridge,
Mass: MIT Press.
Fawcett, R.P., 1980. Cognitive linguistics and
social interaction: towards an integrated model of a
systemic functional grammar and the other
components of an interacting mind. Heidelberg:
Julius Groos and Exeter University.
Fawcett, R.P., 1988. &apos;Language generation as
choice in social interaction&apos;. In Zock and Sabah
(eds) 1988b, 27-49.
Fawcett, R.P., 1990. &apos;The COMMUNAL Project:
two years old and going well&apos;. In Network No. 13.
Fawcett, LP., (to appear). &apos;A systemic functional
approach to selectional restrictions, roles and
semantic preferences&apos;. Accepted for Machine
Translation.
Fawcett, R.P., van der Mije, A., and van Wissen,
C., 1988. &apos;Towards a systemic flowchart model for
local discourse structure&apos;, in Fawcett and Young
1988, pp. 116-43.
Fawcett, LP., and Young, DJ., (eds.) 1988. New
developments in systemic linguistics, Vol 2: Theory
and application. London: Pinter.
</reference>
<page confidence="0.990288">
173
</page>
<reference confidence="0.999080703703704">
Halliday, MA.K., 1967. Intonation and grammar
in British English. The Hague: Mouton.
MA.K., 1970. A course in spoken
English: intonation. London: Oxford University
Press.
Halliday, M.A.K., 1985. An introduction to
functional grammar. London: Arnold.
Houghton, G. and Isard, S.D.,1987. &apos;Why to speak,
what to say and how to say it: modelling language
production in discourse&apos;. In Morris 1987, pp. 112-
30.
Houghton, G., and Pearson, M., 1988. &apos;The
production of spoken dialogue. In Zock and
Sabah 1988a, pp. 112-30.
House, J. &amp; Johnson, M. (1987) Enlivening the
intonation in Text-to-Speech Synthesis: an
&apos;Accent-Unit&apos; Model&apos;, Procs 11th ICPhS, Tallinn.
Kempen, Gerard, (ed) 1987. Natural language
generation. Dordrecht Martinus Nijhoff.
Kobsa, A., and Wahlster, W. (eds.) User Models in
Dialogue Systems. Berlin: Springer.
Mann, W.C., and Matthiessen, 1983/85.
&apos;A demonstration of the Nigel text generation
computer program&apos;. In Mann and Matthiessen
1983 and in Benson and Greaves 1985, pp.50-83.
McDonald, D., 1983. &apos;Natural language
generation as a computational problem&apos;. In Brady
and Berwick 1983, pp209-65.
McDonald, D.D., Vaughan, M.M., and
Pustejovsky, J.D., 198&apos;7. &apos;Factors contributing to
efficiency in natural language generation&apos;. In
Kempen 1987, pp. 159-181.
Morris, P., (ed.) 1987. Modelling cognition.
Chichester: Wiley.
Paris, C.L. &apos;Tailoring object descriptions to a
user&apos;s expertise&apos;. In 1Cobsa and Wahlster 1988.
Tench, P., 1987. The roles of intonation in English
discourse. PhD thesis, University of Wales.
Tench, P., and Fawcett, R.P, 1988. Specification
of intonation for Prototype Generator 2.
(COMMUNAL Report No 6) Cardiff:
Computational Linguistics Unit, University of
Wales College of Cardiff.
Tucker, GIL, 1989. &apos;Natural language generation
with a systemic functional grammar&apos;. In
Laboratorio degli studi linguistici 1989/1.
Camerino: Italy: Universita degli Studi di
Camerino (pp.7-27).
Zock, M., and Sabah, G., (eds) 1988a. Advances
in natural language generation Vol 1. London:
Pinter.
Zock, M., and Sabah, G., (eds) 198811 Advances
in natural language generation Vol 2. London:
Pinter.
</reference>
<page confidence="0.673025">
173a
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001531">
<title confidence="0.995591">The Computer Generation of Speech with Discoursally and Semantically Motivated Intonation</title>
<note confidence="0.4895816">P. Computational Linguistics University of Wales College of Cardiff CF1 UK</note>
<abstract confidence="0.996814854671281">The paper shows how it is possible, in the framework of a systemic functional grammar (SFG) approach to the semantics of natural language, to generate an output with intonation that is motivated semantically and discoursally. of the work =ported been successfully implemented in GENESYS (tlic very large generator of the COMMUNAL Project see Appendix 1). A major feature that it does a syntax and words, and then impose intonational contours on them (as is a common approach in modelling intonation); rather, it generates the various intonational features directly, as it is generating richly labelled structures (as are typical in SFG), and the associated hems. The claim is not that the model proposed here solves all the problems of generating intonation, but that it points a way forward that makes natural links with semantics and discourse. A secondary purpose of this paper is to demonstrate, for one of many possible areas of NLG that could have been chosen, that there is stilt much important work to be done in &apos;sentence generation&apos;. I do this in order refute the suggestion, Occasionally heard at that the work in &apos;sentence generation&apos; has already been done, and that the main (only?) area of significance in NLG is in higher level planning. In my are and we should expect significant developments at every level in the years to come. 1. Purpose and Scope The aspect of Natural Language Generation (NLG) to be described here is the generation of spoken text that has Intonation, where that intonation is motivated both semantically (i.e. in terms of the semantics in a broad sense of the term to be clarified soon of sentences) and discoursally (i.e. in terms of what the discourse component Any specification of intonation requires, of course, to be integrated with an adapted version of a speech synthesizer (e.g. one that draws on one of the currently available systems that attempts inevitably with Appendix 1 for a brief overview of the project). As be clear from what follows, the model presented owes a great deal to two in particular: Michael and Paul Teach. Through them, am well aware, a debt to many others, too numerous to mention, have worked in difficult field of intonation in I am grateful too early encouragement in this from Gillian Brown (whose work is drawn on by for the regular, ongoing stimulus of many explorations of this and other areas with my Gordon Tucker. But none of these should for the inevitable crudities, and doubt model here; these are mine. The approach is very different from that in MITalk (Allen 1986), which is essentially a textto-speech system. So far as I am aware, the only generative model prior to ours that attempts to generate intonation that is motivated semantically and discoursally is the impressive work of Isard, Houghton, Pearson and their colleagues at Sussex (Houghton and Isard 1987) and Houghton and Pearson 1988). Its limitation is the very small size of its syntax, lexis, semantics and working domain. We see our work in the COMMUNAL Project as being to build on their important achievement. see Appendix 2 for what we do 2. The Relevant Components of the Communal Model The major components of the overall model that will be referred to below are as follows. We interactive system, rather than one that is merely monologue. We shall ignore here the components related to parsing, interpretation and to the system and planner. The components relevant to generation are: 1. The belief system, which includes general and specific beliefs about (&apos;knowledge of) situations things in some domain; specific about the content of the preceding discourse, about various aspects of the current social situation, about the addressee and his beliefs of all types, his attitudes, his goals and plans. A planner, makes general plans, drawing on knowledge of 3. genres (scripts, schemas, etc), introducing where appropriate sub-units such as transactions (see below) and more detailed plans, using ... the discourse grammar, which is modelled as a &apos;systemic flowchart&apos; (i.e. a flowchart containing many small system networks at the and which generates exchanges and their structure), the ledcogrammar, i.e. the generator, consisting of: 164 a. the system networks of semantic features for a wide variety of types of meaning related to situations and realized in the clause, including theme and information structure as well as transitivity, mood, negativity, modalit/, affective meaning and logical relationships, and equivalent system networks for things and qualities, and 165 in the SEG metaphor, above them). These semantic features are then realized in the purely intonational contrasts of TONE, TONICITY and TONALITY. b. the realization rules which turn the selection expressions of features that are the output from passes through the system networks into syntactic structures with items (grammatical and lexical) and markers of punctuation or intonation as their terminal nodes. The accounts of the various aspects of intonation in what follows will inevitably be introductory, and may to the specialist appear simplistic. A somewhat fuller treatment is given in Tench and Fawcett 1988, and a very full treatment is given in Tench 1987, which includes summaries of relevant work by other intonation specialists 3. Modelling Intonation (I omit here, for reasons of space, a specification of bow one might model the way in which the position in a transaction and an exchange affects intonation.) 3.1. An Overview of the Generation of Intonation Let us assume, then, that Ivy is preparing a response to the Personnel Officer&apos;s question, using the information that, while Mr Peter Piper&apos;s address is currently 11 Romilly Crescent, Canton, Cardiff, he is moving from there after one month. In discourse planning terms, she chooses that her move will be a &apos;support&apos; for a &apos;solicit information&apos;, and that the act at the head of the move is a &apos;give new content&apos; (see Fawcett, van der Mije and van Wissen 1988). As we shall see, these choices pre-select in the MOOD network of the leidcogrammar the features [information] and first there a more basic system to consider. Let us imagine that Ivy (the &apos;person&apos; of whose mind GENESYS models a part) is about to generate a sentence. Let us suppose that she is being consulted by the Personnel Officer of a large institution, who draws regularly on her specialist knowledge and advice, and that he has just asked her &amp;quot;Where does Peter Piper live?&amp;quot;. (We shall come later to how intonation is represented.) Like most human users of language, Ivy makes reasonable assumptions about (loosely, she &apos;knows&apos;) where she is in any current transaction (e.g. at the start, in the middle or at the end), and where she is in the current exchange. This affects the pitch level of what she says. She needs to choose a tone (the change in pitch marked by a stepping or a slide on the tonic syllable) which will express the MOOD of the final matrix clause of her sentence. (&apos;Matrix here means &apos;at the top layer of structure&apos;.) She needs to locate that tone on an item which will be thereby marked as new Information. She needs to decide if it is to be presented simply as &apos;new&apos;, or as &apos;contrastively new&apos; (in the terms used here). And she needs to decide on the information status of any chunks of information that are to be presented as separate from the main information unit of the clause. (The information that guides these choices comes from various aspects of the higher belief system, which there is unfortunately no space to discuss here.) 3.2. The MODE System As we shall see, these various components of the semantic level of intonation account, in a different from the usual approach in studies, for Halliday&apos;s well-known triad of TONE, TONALITY and TONICITY. While it is perfectly possible to talk about the contrasts in intonational form to which these three refer as I suggest that it is insightful take, as the level of contrasts to be modelled in system networks, the meanings that lie behind (or, The initial rule of the semantics of the lesico-grammar to be considered here is: situation -&gt; &apos;MODE&apos; &amp; &apos;TENOR&apos; &amp; &apos;CONGRUENCE SIT&apos;. Thus means that, for any &apos;situation&apos; ( roughly &apos;proposition&apos;) that you are generating, you must make choices in all three of the systems named. (Notice, then, that &apos;parallelism&apos; lies at the heart of the grammar.) Here we shall be concerned only with the MODE system. (It is from CONGR-UENCE_SIT that the main part of the network is entered, to generate configurations of roles, such as Agent and and in MOOD, such &apos;information seeker&apos;, and very many others.) The MODE system is very simple: -&gt; / This means: &apos;In the MODE system, you must choose between generating a spoken output (for under random generation there is a probability) and generating a written output carries a Clearly, since Ivy is in a spoken interaction, she will be strongly disposed to select [spoken] but in principle she need not. We shall not discuss here the interesting reasons for and against introducing this system to the lexica-grammar itself, except to point to two significant advantages that it brings. Nor, unfortunately, is there space to discuss the roles of the probabilities and the ways in which they are assigned (sometimes simply a guess at the overall pattern for central types of text; sometimes based on textual studies). (The next few lines presuppose some familiarity with systemic grammars; for those without this knowledge it may be advisable to re-read this section after seeing the working of the examples.) What is the role of this system? First, it enables the grammar-builder to refer, at any point on this pass through the system to whichever feature in this system has been chosen an condition to later system. In other where there is greater richness of choice meaning in the spoken mode (as is typically the case with meanings realized in intonation, as against those realized in punctuation), we can ensure that those systems are only entered when the feature [spoken] has been chosen. We shall shortly see the great value of this. Second, the &apos;MODE&apos; system enables us to refer, at any point realization rule, on this or any subsequent pass through the network, to this feature as a conditional feature for the realization of some other feature, In other words, we can ensure that if [spoken] has been chosen the realization will the of and if [written] has been chosen it is expressed in punctuation. Both of these facilities contribute greatly to the elegant operation of the lexicogrammar as a whole, both in meanings realized in intonation and in many other ways. The Generator The unmarked choice in the &apos;CONGRUENCE SIT&apos; system is, unsurprisingly, frongruent_siit This is the choice that opens up the whole array of meanings associated with realization in a clause, and many parallel systems follow. Among these is the MOOD network This is a fairly large and complex network of meanings, and are realized partly in syntax, partly in (such as &amp;quot;please&amp;quot;), and partly in tone ( = variation in pitch). The network is too large and complex to present here, but we shall trace a route through that shows why it is central to an understanding intonation. The first options current GENESYS network are shown below: congruent sit &gt; &apos;TRANSITIVITY* &amp; &apos;MOOD (&amp; OTHERS). &apos;MOOD(A)&apos; &gt; 90% information / 10% directive. information -&gt; &apos;MOOD(8)&apos; &amp; &apos;TIME_REFERENCE_POINT (&amp; OTHERS). &apos;MOOD(B)&apos; -&gt; 70% giver (1.2) / 30% seeker (16). The second line reads: &apos;In the MOOD(A) system you must choose between the feature which a 90% probability of being selected, and [directive], which has only a 10% probability. As so often, the choice of a single feature leads to further parallel systems, one of which continues the MOOD network itself. The last line in the above rules exemplifies the use of numbers in brackets after the features; it is number of realization rule for feature concerned. What will this look like? Here is a slightly simplified version of the realization rule for [giver]: 1.2 : giver: if fills &apos;Z&apos; and (simplex sit or situation) then if on first_pass written then &apos;E&apos; &lt;&apos;.&amp;quot;, on spoken then &apos;E&apos; &lt; &amp;quot;I&amp;quot;). The effect of this rule is on the &apos;Ender&apos; (i.e. &apos;E&apos;, last element in the structure of the clause). [written] is chosen in the &apos;MODE&apos; system it is expounded by a full stop (Br. E. for &apos;period&apos;), but if the choice is [spoken] it is expounded by a final unit i.e. j. However, says the rule, neither realization will occur unless the clause (1) directly fills the element &apos;Sentence&apos; (represented by &apos;Z&apos; as an approximation to sigma) and (2) is &apos;simplex&apos;, i.e. is not co-ordinated with one or more other clauses or, if it is, is the final clause. This may seem a surprisingly complex rule to those in NLP used to working with minigrammars. But this is typical of the working level of complexity in a natural language, and those who are used to working with the problems of building broad coverage grammars will appreciate that this is not a particularly complex rule. In the of our example the is give to Ivy&apos;s a intonation unit boundary. We come next to an example of the value of being to use of the feature an entry to a This is necessary because the MOOD network also builds in variables in &apos;key&apos; (in the sense of Halliday 1970), i.e. finer choices within the MOOD options. These correspond to what Tench treats separately as in attitude. While accepting the that these more delicate choices can be seen as 166 serving a separate function from the function of the basic tone, the fact is that in any systemic computational implementation the way in which they enter the choice system is simply as more delicate choices that are directly dependent on the broad choice of meaning realized in the broad tone. The range of such delicate variations appears to be potentially different for the various meanings (see further below). In the systems given below, note the high probability of choosing [assertive] followed by [neutral]. giver &amp; spoken -&gt; 70% assertive / 15% deferring (1.21) / 15% with_reservation (1.22). assertive - &gt; 2% very strong (1.23) / 8% strong (1.24) / 60% neutral (1.25) / 30% mild (1.26). In an intermediate level model (such as Prototype Generator 2 (PG2), which is the most advanced version of GENESYS currently implemented) we need only relatively simple rules such as the following: 1.21 : deferring: if fills &apos;Z&apos; and on first_pass spoken and (simplex sit orlinal_co_ordinated_situation) then &apos;2-&apos; by &apos;NT&apos;. (&apos;NT&apos; = &apos;Nuclear Tonic&apos;; see 3.4.3.) 1.22 : with reservation if fills and on first_pass spoken (simplex sit or falai co_ordinated_situation) And so on, for [very strong] (realized by &apos;21&apos;), [strong] (realized by &apos;1+ &apos;), [neutral] (realized by &apos;1&apos;) and [mild] (realized by &apos;1-&apos;). Here we are using a numerical notation for tones that goes back to an earlier tradition even than Halliday&apos;s description (1967, 1970), though it has much in common with Halliday&apos;s. (Readers from the American tradition used to an iconic representation may have some adjustments to make in interpreting the notation. But there should be no fundamental difficulty; Halliday&apos;s description has been widely used (and indeed tested) on American and Canadian English.) I give next a brief summary of the differences the tones used here and Halliday&apos;s well-known scheme (1967, 1970). Tench&apos;s (and so my) numbers &apos;1&apos; and &apos;2&apos; correspond to Halliday&apos;s usage, as do the use of &apos;+&apos; and &apos;-&apos;. But Halliday&apos;s &apos;Tone 3&apos; is seen as a of our Tone 2; Halliday&apos;s Tone fallrise) is represented by &apos;12&apos;; and his &apos;Tone 5 (a rise-fall) is shown as &apos;21&apos;. Tench&apos;s general of the tones (1987) imply pitch levels, and I therefore following labels for the model implemented: base, low, mid and high. The four levels in turn provide a framework for describing three types of pitch change. It will be helpful for what follows to set them out as three &apos;scales&apos;: these descriptions of the tones are in effect source material for writing realization rules. (I have given these scales informal semantic labels; these are not intended to correspond directly to the features in the MOOD network encountered so far, but to evoke features from various parts of the network, including the many options dependent on [directly*. Finally, let me remind you that we are not at this point trying to account for all tones, but only for those that carry the MOOD of matrix simplex clause. This clear separation of the ways in which tones are generated is a key feature of the present proposals. We shall come shortly to some of the ways of generating appropriate tones for some of the other positions in which tones occur.</abstract>
<note confidence="0.981242529411765">The &apos;assertive&apos; scale (Tones 21 and 1): 21: rise-fall (rise to high fall base) Tone 1+: high-fall (fall from high to base) Tone 1: mid-fall (fall from mid to base) Tone 1-: (fall from low to Also (see below): Tone 21.: low rise-fall (lower version of Tone 21)* The &apos;deferring&apos; scale (Tone 2): 2+: high-rise high) Tone 2: mid-rise (rise from base to mid) Tone 2-: low-rise (rise from base to low) The &apos;implication&apos; scale (Tone 12): Tone 12: fall-rise Also (see below): Tone 12-: low fall-rise (lower version of 12)k * Tench suggests that these are variants of Tone</note>
<abstract confidence="0.994071846464648">21 and 12 that additionally signal &apos;emotional involvement&apos;. As will be clear, Tench and I propose a modification to Halliday&apos;s basic set of contrasts TONE, Halliday&apos;s Tone 5 is seen form of Tone 1. This fits naturally with the semantics of these tones. In a somewhat similar way, Tench treats Halliday&apos;s Tone 3 (a low rise) as a variant of Halliday&apos;s Tone 2, under the rubric of &apos;deference to the listener&apos;, and we adopt this too in COMMUNAL But note that, while that kind of semantic description holds good for 2s (Halliday&apos;s Tone 3s) sentence-final position, I shall suggest other means of generating them in non-final positions. In the present system there are no &apos;double tone groups&apos;, such as Tone 13 (i.e. a Tone 1 to reslin;the 167 meaning, followed by a Tone for &apos;supplementary information&apos;.) Such final Tone 2s will be generated in a similar way to to illustrated section 33 for initial Tone 3s (and, as we shall see, 12s). Finally, that I here one option that Tench includes under &apos;status of information&apos;. This is his &apos;implication&apos;, realized in Tone 12, i.e. a fall-rise. This is Halliday&apos;s Tone 4, which he characterizes descriptions) &apos;with reservation&apos;. tone occurs both a carrier MOOD and it is with the former that we concerned here. It seems plausible to treat it as a variant that can be chosen as an alternative to basic falling and rising tones by both Halliday and Tench, and I have therefore incorporated it in the overall MOOD network. 3.4. Focus of Information 3.4.1. The Line of Approach to the Problem I shall present here a somewhat novel approach to the relationship between the two sets of phenomena described by both Halliday and Tench and TONALITY is of up a Wing of into intonation units&apos; (Tenth&apos;s is &apos;tone groups), with intonation realizing Information unit. problem, when one is approaching the question the angle of generation, is there of words cut up that until the has generated. We need Look semantic to the problem. My proposal is that it is helpful to start not with TONALITY but TONICITY. TONICITY is the placing of the tonic on a syllable. The item so marked is shown to be presented new information and this concept. (&apos;New&apos; information is presented as recoverable?) But further problem arises, in linguists recognize both &apos;marked&apos; and &apos;unmarked&apos; tonicity. 3.4.2. Generating Marked Tonicity Marked tonicity occurs when the item containing the tonic syllable is presented by the speaker as Unmarked tonicity occurs there is no marked tonicity (which is by the most usual case); we shall return to this shortly. Marked tonicity is handled in GENESYS in the following way. In principle, any pathway through the system network that results in the of formai will lead to a system of the following form (where &apos;x&apos; is the current terminal feature): not_contrastively new / contrastively new. realization [contrastively new] is that a tonic is witg element of that the item The simple version implemented in PG2 is as follows: &apos;INFORMATION FOCUS&apos; -&gt; 99% no_element Marked_as_contrastively new / 1% element_mariced_as_contrastively new. new 50% contrastive_newnesson_polarity (18.1) / 50% contrastive_newness_on_process (18.2) / 0% other. Realization rule 18.1 states the complex set of conditions for conflating a contrastive tonic (CT&apos;) with the appropriate element; for the POLARITY system (&apos;positive&apos; vs. &apos;negative&apos;) this is typically the Operator (which may have to be supplied by a &apos;do-support&apos; rule) but it may be any one of several others, depending on whether or not the clause is moodless and, if not, whether a directive, and if not, what auxiliaries are realized, etc. The rule for presenting the &apos;process&apos; (realized in the Main as &apos;contrastively_new&apos; extremely simple: 18.2: contrastive newness_on_process : — the our example, the choice is not to any new. 3.4.3. Generating Unmarked Tonicity then, should we generate The answer is simple: as the default when there is contrastive tonic. In other I want to suggest that unmarked is formal phenomenon of that not active choice in meaning. The are well known, roughly, that what we here term a nuclear tonic (NT&apos;) fang on the last item in the information unit. question &apos;How we define the intonation unit, in terms?&apos; The only as a unit, in the GENESYS framework, is the semantic unit typically realized in the clause. The actual decision as to which item the unmarked tonic shall be assigned to gets relatively in the generation process. In we have a list of the few dozen generated by lexicogrammar that cannot carry the unmarked tonic: roughly, the &apos;grammatical items&apos; of English. Essentially, then, will one, and only tonic sentence. will when there are two or more in that and/or one or more 168 embedded clauses. 3.5. Status of Information 33.1. The Importance of this Category This is a concept not distinguished as a separate phenomenon in Hallidays treatment of intonation, but which Tench does treat separately. This clear separation of two semantically distinct phenomena was a significant help in developing the generative model proposed here. However the concept of &apos;status of information&apos; is quite highly generalised, in the sense that it is not manifested in just one part of the overall network (as for example MOOD is). Specifically, we find this option at of the points a unit is generated that Is not the final matrix clause in the sentence. Many of these (though by no means all) have in GENESYS, and the following are a representative sample. 33.2. The Co-ordination of Situations and Things One major source of multiple intonation units is co-ordination. Thus, when GENESYS generates co-ordinated clauses (realizing co-ordinated situations) such as &amp;quot;Either Ivy kW= Ike, or she loves Fred, or she doesn&apos;t love anybody.&amp;quot;, she first recognizes at an abstract level that separate information units are being assigned and then inserts, depending on whether the output is to be spoken or written, either (1) commas or (2) intonation unit boundaries and an appropriate tone such as Tone 2. We shall not reproduce here the surprisingly large system network and rules this of the grammar, which merit a paper to themselves. Ail that needs to be said is that to develop a model of clause coordination that incorporates most of the phenomena of naturally occurring texts is a major task, and that it took several months of work to build our current system. In terms of the above example, it generates, if [spoken] has been selected: I either Ivy loves Ike/NT/2 I or she loves Fred/NT/2 I or she doesn&apos;t love anybody/NT/1 I While the patterns of the networks and their realizations are different for the co-ordination of nominal groups, they are handled in a similar way. The system accommodates the perhaps surprising fact that, in the case of nominal groups, there is typically one more intonation unit than there would be commas. As in the MOOD network, there is a greater number of delicate choices realized in intonation than there is in punctuation. So the feature [spoken] is again used as an entry condition to the system in the &apos;CO ORDINATION SIT&apos; network, to ensure that the system is not entered unless [spoken] has been chosen. Here the speaker chooses in the system of runmarked_co ordination spoken] vs. [co ordination vvilla reservation]: The first is by a rise; Halliday&apos;s Tone 3), and the second by a Tone 12 (fall-rise; Hallidays Tone 4). 33.3. Thematized Circumstances: Situations, Things, Qualities Another major source of additional intonation is the of time and meanings are realized in Adjuncts of various types. They may occur in various places in the clause, and here we shall consider just those that appear at the beginning of a clause. So far GENESYS includes eleven types, of which may be realized by clause or a group (three different classes of groups being and quantityquality groups). Note, then, that we have now identified a second major source of what has been termed &apos;clause combining&apos;. A similar approach is needed for &apos;clause final&apos; clauses, i.e. clauses that any of the of Adjunct built into GENESYS so far, and that come late in the clause. (This is a different approach to clausecombining from that in Halliday 1985 and so from Nigel grammar at ISI; here such clauses are simply treated as embedded so far with gains in generalizations rather than losses.) Let us take as an example the concept of time which is one five types of &apos;circumstance of time&apos; recognized in GENESYS the others being repetition, duration, periodic frequency, and usuality. While GENESYS will happily generate clauses such as &amp;quot;until he leaves the company&apos; to specify a time position, in the case of our example Ivy has chosen the simpler structure of the prepositional group, i.e. &amp;quot;until next month&amp;quot;. The first system to consider is: &apos;TIME POSITION TFIEM.ATIZATION&apos; -&gt; (202) / 1% thematized_time_position (203). Because the answer modifies the presuppositions that the Personnel Officer brought to his question (i.e. that Peter Piper had a fixed address), Ivy decides to thematize the part of her reply that expresses this, i.e. her specification of the &apos;time position&apos;. This is realized by placing the &apos;time position Adjunct&apos; at an early place in the clause. (Note that this is not a &apos;movement rule&apos;; there are no such rules in this generator, and no element is located until it can be located in its correct place.) The next two systems are: 169 -&gt; 80% time_position_as_separate information unit / as_part_of main_ information unit. spoken &amp; time_position_as_separate_ information unit -&gt; 20% highliglted thematized time _position / neutral theTnatized The first of the two systems applies whether or not the MODE is spoken or written (the written realization being a comma). But the writing system cannot make the distinction offered in the second, so that here again the feature [spoken] from the original MODE system is used as an entry condition. In our example Ivy chooses to present the specification of the time position (&amp;quot;until last week&apos;) as a separate information unit, and furthermore to highlight it (by using a Tone 12 (a fall-rise). But you may have noticed that these features have no realization rules. How, then, do these choices get realized? The answer is that these features act as conditional features on the realization rules the units that are generated, re-entry the overall network, on a subsequent pass though The including the system at the of situation is that this we can capture the generalisation that these options are relevant the unit a clause or some kind of that fills the In our case the sub-network that we find ourselves in on re-entry is the network for &apos;MINIMAL RELA&apos;TIONSHIP_PLUS_THING&apos;, i.e. the network from which prepositional groups are generated. Here we enter the following system (where the suffix &apos;mrpt&apos; echoes the name of the overall system): location_mrpt -&gt; place_mrpt (90.001) / time _mrpt (90.002). Here (time mrpt) will be pre-selected by the at rank. The part of its realization rule concerned with intonation may appear, once again, somewhat complex, but once again it seems to correspond to the relative (but always limited) complexity of the facts of how English works: 90.002: time_mrpt : if (on_previous_pass time_position_as separate_information_unit and on first_pass spoken) then (if current unit pgp then e &lt; highlighted_tmatized_time_position &apos;12&apos; by if on_previous_pass neutral thematized_time_position &apos;2&apos; by As you will see, these rules insert appropriate boundaries and tones. The tonic already waiting in the structure the prepositional group, so that the rule simply conflates the actual tone with it. Let us assume that Ivy, in order to highlight still further the of the words 6month&amp;quot;, selects the highlighting rather than the neutral option. (The nominal group &amp;quot;next month&amp;quot; is generated by a further re-entry.) Finally, the system supplies the initial intonation unit boundary for any unit without one. If we assume that the rest of items generated (in components not considered in this paper) are &amp;quot;he will be living at eleven Romilly Crescent, Canton&amp;quot; the full output for our example is: I until next month/T/12 I he will be living at eleven Romilly Crescent/T/2 I Canton/NT/1 I 33.4. Other Sources of Intonation Other sources of intonation occur in specialist mini-grammars such as those for dates and addresses. These can be quite complex, and may several tonics, with appropriate tone. Our worked example illustrates one such case: note the Tone 2 on &amp;quot;Crescent&amp;quot;. Yet other types will be included in the next version of GENESYS, including (1) Adjuncts (which may be filled by clauses or groups) that are placed after of a clause and which carry &apos;supplementary information&apos;, and (2) &apos;nonrestrictive relative clauses&apos; (i.e. ones that carry, again, information?), of the lexicogrammatical generation of intonation We have now completed a fairly full specification of the major aspects of intonation included at the of development of the GENESYS model. summarize: offers choice, on entering the first system that results in the of a [written] and [spoken]. The importance of this apparently trivial system is that the choice made in it not one can go on to enter quite a number of more &apos;delicate&apos; systems whose are realized Its features act on features chosen in the same network, or in one entered on a subsequent pass. The result is that realization at the level form will be in 170 terms of either intonation or punctuation. We have seen how choices in MOOD, in INFORMATION FOCUS and in various types of &apos;status of informalion&apos; contribute together to the specification of intonation, and we have seen some of the details of how this can be implemented. The result is an integrated model that avoids the psychologically implausible approach whereby one first generates a syntax tree and a string of words its leaves, and on&apos; the intonation. Instead, it treats intonation as one of three modes of realization (the other two being syntax and items), generating the various aspects of at appropriate in the of syntax and items. It may be helpful to conclude by specifying the final stages of this process. the looks for a tonic to conflate the tone, and if there one, it provides as a default a nuclear tonic (&apos;NT&apos;) for the final matrix clause, i.e. the intonational element of structure with which the tone realizing the meaning of MOOD is conflated. The other intonation units specified by various types of status fitted around this central framework, receiving tones appropriate to their are clauses these tones will be conflated with a nuclear tonic (unless, of course, there is a contrastive tonic), and where they are groups the tones will be conflated with a simple tonic. A nuclear tonic is thus one that is potentially capable of receiving the type of tone that realizes a MOOD option. It should be made clear that, in every case of the location of a nuclear tonic or a simple tonic, the element with which it is conflated must be out that is not expounded by an item from the list of inherently weak items. (Any such item may of course still receive a tonic by being contrastively stressed, as in I he has/CT/1+ eaten it I.) 4. Conclusions 4.14 Overall Summary COMMUNAL began with a hope that it would be possible to take the insights from Hallidayan-Tenchian view of and to develop a computational adaptation and implementation of them. A promising overall approach to the problem has indeed been much of the resulting model been out considerable detail; and many large and significant portions have been implemented computationally. The framework has proved itself to be adaptable when modifications are indicated, and there is good reason to hope that aspects not as yet worked out explicitly will prove to be solvable in the framework of the present model. There is, therefore, the exciting prospect that, when our sister project gets under way and provides the necessary complementary components (no doubt with some requirements on us to adapt our outputs to their needs) we shall be in a position to offer a relatively full model of with and semantically intonation. It will, be and we hope that it will be capable of further extension and of tine-tuning. We feel that the use of SFG, and specifically of the type that separates clearly system networks and realization rules (as in GENBSYS), gives us a facility that is sensitive to the need for both extension and fine-tuning. Above all, the centrality in the model of choice between features it a natural formalism for relating the &apos;sentence grammar&apos; to higher components in the overall model. The General Prospect in Finally, let me turn to a more general point. It appears that, increasingly over the last few years, the focus of interest for many researchers in NW switched from what we might sentence higher level planning (which 1 term discourse generation). It is here, one sometimes hears it said, that &apos;all the really interesting work&apos; is being done. Going implicitly with this claim is the assumption, which I have occasionally heard expressed quite explicitly, that the major problems of sentence generation have been solved. is really so? a lot of very impressive work has been done, and while some quite large generators have been built (e.g. as reported in McDonald 1985, Mann and Mathiessen 1985, Fawcett 1990), very many major problems remain unresolved. Specifically, many aspects of remain outside the scope of current generators. Where, for example, will we find a full description of a semantically and/or pragmatically motivated model of even such a well-known syntactic phenomenon as the relative clause? And what about comparative constructions (where even the literature is weak)? there are many, many more areas of the semantics and syntax of sentences where our models are still far There are also many issues model construction regarding, for example, the division labour between components, the outlining of which deserves a separate paper book). even if we had models covered all these and the many other areas competently, we have hardly begun the process of adequate methods for the evaluation of models. Thus there is still enormous amount of challenging and fascinating 171 work to do before we can say with any confidence that we have anything like adequate sentence generators. (A senior figure in German MP circles suggested at COLING &apos;88 that one can buy good sentence generators off the shelf. It depends how good &apos;good&apos; is!) In this paper I have illustrated two crucial points: (1) that there are indeed significant areas of language not yet adequately covered in current generators, and (less clearly because I have had to omit the relevant section for reasons of space) (2) that the development of an adequate model of these depends on the concurrent development of discourse and sentence generators. Clearly, while there are in existence a number of fairly large sentence generators, we have in no way reached a situation where no further work needs to be done. I am aware, as the director of a project that seeks to provide rich coverage for as much of English as possible, that we have a great deal of work still to do, and that this holds for the sentence generator component as well as for the discourse planning systems. GENESYS already has 50% more systems than the NIG.EL (in the long established Penman Project; see Appendix 1), but our rough estimate is that we need to make it at least as large again before we have anything approaching full grammatical coverage. And, of course, as everyone who has wrestled seriously with genuine natural language knows, many tricky problems will remain even then. Finding anything like the &apos;right&apos; solution to many of these will require, I claim, models that have developed, in dose interaction with each other, their discourse planning and their sentence generation components and their belief representation, including beliefs about the addressee.</abstract>
<note confidence="0.989548285714286">Acknowledgements The research reported here was supported by grants from R.SRE Malvern under contract no. ER1/9/4/2181/23, by the University Research Council of International Computers Ltd, and by Longman. Appendix 1</note>
<abstract confidence="0.995615291970803">COMMUNAL is a major research project that applies and develops Systemic Functional Grammar (SFG) in a very large, fully working computer program. The acronym COMMUNAL stands for COnviviai Man-Machine Understanding through NAtural Language. The principles underlying the project are set out in Fawcett 1988, and an illustration of a generation is presented in Tucker 1989. A fuller (but fairly informal) overall description, including some comparison with other projects, is given in Fawcett 1990. See also Fawcett (to appear). The project is planned to last 5 years, with around 6 researchers working on it. We finiqhe.d the successful Phase 1 in 1989, and now (May 1990) are getting under way on Phase 2 The central component of the overall system is the generator, built at Cardiff. This is called GENESYS (because it GENErates SYStemically). Contributions from the University of Leeds in Phase 1 were to build (1) a derived probabilistic purser, called the RAP (for Realistic Annealing Parser, which devetops earlier work at Leeds), (2) the REVELATION, because it reveals the &apos;meaning&apos; from the &apos;wording). Each of these is a major development in its field. But because both build directly on the relevant aspects of GENESYS, we can characterise the coverage of the COMMUNAL system as a whole in terms of the size of GENESYS. Here is a quotation and a few facts to give you a perspective on COMMUNAL at the end of Phase 1, McDonald, Vaughan and (1987:179), in referring to the Penman project at the University of S. California, say: &apos;Nigel, Penman&apos;s grammar .... is the largest systemic grammar and possibly the largest machine grammar of any kind.&apos; Although COMMUNAL team developed GENESYS completely independently, starting from scratch with new system networks and handling realization in a rather different way, GENESYS already has many more systems than Nigel. (This is not a criticism of Nigel; the research team have been working on other components of Penman). A major theoretical difference between the two is that the networks in GENESYS are more explicitly oriented to semantics than in Nigel. We make the assumption that the system networks in the lexicogrammar are the semantic options. GENESYS has around 600 semantic systems In grammar and morphology, and also intonation and punctuation (see below), while Nigel has about 400 grammatical systems. But GENESYS additionally does something that the builders of Nigel would have liked to do, but from which they have so far been prevented (by the of a sponsor): it integrates for vocabulary the networks realized grammatically. GENESYS is growing, so that in Phase 2 we estimate that it will more than double the number of systems realized in syntax and grammatical items. This should enable it to handle something approaching unrestricted syntax. COMMUNAL&apos;s first major achievement is therefore the size and scope of 172 GENESYS. The second must be seen in the wider framework of the model as a whole. It has been a long-standing goal of NLP to build a large scale system that uses the same grammar to either generate or interpret a sentence. (Many systems use a different grammar for process.) The second major achievement is to have performed this task with a very large grammar a Systemic Functional Grammar, in this ease. (This will be the subject of a separate paper in the future.) A third (though one less relevant in the present context) has been the development of a probabilistic parser by the Leeds part of the COMMUNAL team. Appendix 2 &apos;Intonation&apos; is a term susceptible to a wide range of interpretations. It may therefore be useful to list some major aspects of die complex task of generating natural intonation that will not be discussed here. The first four are not covered because they lie outside the current goals of the COMMUNAL project, while the last two are omitted because they will be implemented (we expect) by a sister project, support for which is currently being negotiated. 1. We shall not be concerned with the high level planning that will tailor the text to the needs of the addressee as affected by the channel (e.g. to build in greater redundancy, in the form of repetition of subject matter in planning what to express overtly, act by act). (For the general notion of tailoring, see Paris 1988.) 2. We shall not discuss variation in intonational characteristics of the sort that distinguish between speakers of different dialects (geographical, social class, age, etc). 3. The same goes for individual variation, i.e. intonational idiolect. 4. We shall ignore the code of tone of voice (&apos;angry&apos;, &apos;conciliatory&apos;, &apos;delighted&apos;, etc). At the same time we recognize that it is an important semiotic system in its own right, and that in the longer run the way in which it is, as it were, superimposed on the intonation system itself must be modelled. We recognize too the problems of drawing a firm line between tone of voice and some of the quite delicate distinctions that we recognise MOOD system (c.f. Halliday&apos;s 1970 term &apos;key). 5. We shall ignore any aspect of intonational variation that does not realize meaning. For example, it may be that speakers introduce semantically unmotivated variation into the pretonic segment of an intonation unit, in order to avoid monotony (cf. House and Johnson 1987). (An alternative hypothesis, of course, might be that such variation is in fact semantically motivated, but that we have not yet discovered what aspects of meaning it correlates with and best to refer to it; a characteristic of much interpersonal meaning.) 6. We shall not be concerned here with the physical implementation of the output, but simply (if only it were simple!) with providing a written text output marked appropriately for input to the system which will integrate it with the speech synthesis representation of the segmental phonology.</abstract>
<title confidence="0.674843">References</title>
<author confidence="0.682611">I Tert to Speech the MITalk</author>
<affiliation confidence="0.787845">Cambridge University Press.</affiliation>
<note confidence="0.9665968">Benson, JD., and Greaves, W.S., (eds.) 1985. Systemic perspectives on discourse, Vol 1: Selected theoretical papers from the Ninth International Workshop. NJ., Ablex. Brady, M., and Berwick, LC. (eds), 1983.</note>
<abstract confidence="0.9615745">models of discourse. Mass: MIT Press. R.P., linguistics and social interaction: towards an integrated model of a systemic functional grammar and the other of an interacting mind.</abstract>
<note confidence="0.891094434782609">Julius Groos and Exeter University. Fawcett, R.P., 1988. &apos;Language generation as choice in social interaction&apos;. In Zock and Sabah 27-49. &apos;The COMMUNAL Project: years old and going well&apos;. In No. 13. Fawcett, LP., (to appear). &apos;A systemic functional approach to selectional restrictions, roles and preferences&apos;. Accepted for Translation. Fawcett, R.P., van der Mije, A., and van Wissen, C., 1988. &apos;Towards a systemic flowchart model for discourse structure&apos;, in Fawcett Young 1988, pp. 116-43. LP., and Young, DJ., (eds.) 1988. developments in systemic linguistics, Vol 2: Theory application. Pinter. 173 MA.K., 1967. and grammar British English. Hague: Mouton. 1970. course in spoken intonation. Oxford University Press.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>I Allen</author>
</authors>
<title>From Tert to Speech: the MITalk System. Cambridge:</title>
<publisher>Cambridge University Press.</publisher>
<marker>Allen, </marker>
<rawString>Allen, I. (ed.) From Tert to Speech: the MITalk System. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JD Benson</author>
<author>W S Greaves</author>
</authors>
<date>1985</date>
<booktitle>Systemic perspectives on discourse, Vol 1: Selected theoretical papers from the Ninth International Systemic Workshop.</booktitle>
<location>Norwood, NJ., Ablex.</location>
<marker>Benson, Greaves, 1985</marker>
<rawString>Benson, JD., and Greaves, W.S., (eds.) 1985. Systemic perspectives on discourse, Vol 1: Selected theoretical papers from the Ninth International Systemic Workshop. Norwood, NJ., Ablex.</rawString>
</citation>
<citation valid="true">
<title>Computational models of discourse.</title>
<date>1983</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass:</location>
<marker>1983</marker>
<rawString>Brady, M., and Berwick, LC. (eds), 1983. Computational models of discourse. Cambridge, Mass: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R P Fawcett</author>
</authors>
<title>Cognitive linguistics and social interaction: towards an integrated model of a systemic functional grammar and the other components of an interacting mind.</title>
<date>1980</date>
<institution>Julius Groos and Exeter University.</institution>
<location>Heidelberg:</location>
<marker>Fawcett, 1980</marker>
<rawString>Fawcett, R.P., 1980. Cognitive linguistics and social interaction: towards an integrated model of a systemic functional grammar and the other components of an interacting mind. Heidelberg: Julius Groos and Exeter University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R P Fawcett</author>
</authors>
<title>Language generation as choice in social interaction&apos;.</title>
<date>1988</date>
<booktitle>In Zock and Sabah (eds) 1988b,</booktitle>
<pages>27--49</pages>
<contexts>
<context position="5595" citStr="Fawcett 1988" startWordPosition="903" endWordPosition="904"> the purely situations and realized in the clause, including intonational contrasts of TONE, TONICITY and theme and information structure as well as TONALITY. transitivity, mood, negativity, modalit/, affective The accounts of the various aspects of intonation meaning and logical relationships, and equivalent in what follows will inevitably be introductory, and system networks for things and qualities, and may to the specialist appear simplistic. A b. the realization rules which turn the selection somewhat fuller treatment is given in Tench and expressions of features that are the output from Fawcett 1988, and a very full treatment is given in passes through the system networks into syntactic Tench 1987, which includes summaries of relevant structures with items (grammatical and lexical) work by other intonation specialists and markers of punctuation or intonation as their (I omit here, for reasons of space, a specification terminal nodes. of bow one might model the way in which the 3. Modelling Intonation position in a transaction and an exchange affects 3.1. An Overview of the Generation of Intonation intonation.) Let us imagine that Ivy (the &apos;person&apos; of whose Let us assume, then, that Ivy i</context>
<context position="40826" citStr="Fawcett 1988" startWordPosition="6761" endWordPosition="6762">tion components - and their belief representation, including beliefs about the addressee. Acknowledgements The research reported here was supported by grants from R.SRE Malvern under contract no. ER1/9/4/2181/23, by the University Research Council of International Computers Ltd, and by Longman. Appendix 1 COMMUNAL is a major research project that applies and develops Systemic Functional Grammar (SFG) in a very large, fully working computer program. The acronym COMMUNAL stands for COnviviai Man-Machine Understanding through NAtural Language. The principles underlying the project are set out in Fawcett 1988, and an illustration of a generation is presented in Tucker 1989. A fuller (but fairly informal) overall description, including some comparison with other projects, is given in Fawcett 1990. See also Fawcett (to appear). The project is planned to last 5 years, with around 6 researchers working on it. We finiqhe.d the successful Phase 1 in 1989, and now (May 1990) are getting under way on Phase 2 The central component of the overall system is the generator, built at Cardiff. This is called GENESYS (because it GENErates SYStemically). Contributions from the University of Leeds in Phase 1 were t</context>
</contexts>
<marker>Fawcett, 1988</marker>
<rawString>Fawcett, R.P., 1988. &apos;Language generation as choice in social interaction&apos;. In Zock and Sabah (eds) 1988b, 27-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R P Fawcett</author>
</authors>
<title>The COMMUNAL Project: two years old and going well&apos;.</title>
<date>1990</date>
<booktitle>In Network No. 13.</booktitle>
<contexts>
<context position="37572" citStr="Fawcett 1990" startWordPosition="6243" endWordPosition="6244"> researchers in NW has switched from what we might term sentence generation to higher level planning (which 1 term discourse generation). It is here, one sometimes hears it said, that &apos;all the really interesting work&apos; is being done. Going implicitly with this claim is the assumption, which I have occasionally heard expressed quite explicitly, that the major problems of sentence generation have been solved. But is this really so? While a lot of very impressive work has been done, and while some quite large generators have been built (e.g. as reported in McDonald 1985, Mann and Mathiessen 1985, Fawcett 1990), very many major problems remain unresolved. Specifically, many important aspects of &apos;sentence grammar&apos; remain outside the scope of current generators. Where, for example, will we find a full description of a semantically and/or pragmatically motivated model of even such a well-known syntactic phenomenon as the relative clause? And what about comparative constructions (where even the Linguistics literature is weak)? And there are many, many more areas of the semantics and syntax of sentences where our models are still far from adequate. There are also many issues of model construction regardi</context>
<context position="41016" citStr="Fawcett 1990" startWordPosition="6790" endWordPosition="6791">t no. ER1/9/4/2181/23, by the University Research Council of International Computers Ltd, and by Longman. Appendix 1 COMMUNAL is a major research project that applies and develops Systemic Functional Grammar (SFG) in a very large, fully working computer program. The acronym COMMUNAL stands for COnviviai Man-Machine Understanding through NAtural Language. The principles underlying the project are set out in Fawcett 1988, and an illustration of a generation is presented in Tucker 1989. A fuller (but fairly informal) overall description, including some comparison with other projects, is given in Fawcett 1990. See also Fawcett (to appear). The project is planned to last 5 years, with around 6 researchers working on it. We finiqhe.d the successful Phase 1 in 1989, and now (May 1990) are getting under way on Phase 2 The central component of the overall system is the generator, built at Cardiff. This is called GENESYS (because it GENErates SYStemically). Contributions from the University of Leeds in Phase 1 were to build (1) a derived probabilistic purser, called the RAP (for Realistic Annealing Parser, which devetops earlier work at Leeds), and (2) the interpreter (called REVELATION, because it reve</context>
</contexts>
<marker>Fawcett, 1990</marker>
<rawString>Fawcett, R.P., 1990. &apos;The COMMUNAL Project: two years old and going well&apos;. In Network No. 13.</rawString>
</citation>
<citation valid="false">
<authors>
<author>LP Fawcett</author>
</authors>
<title>(to appear). &apos;A systemic functional approach to selectional restrictions, roles and semantic preferences&apos;. Accepted for Machine Translation.</title>
<marker>Fawcett, </marker>
<rawString>Fawcett, LP., (to appear). &apos;A systemic functional approach to selectional restrictions, roles and semantic preferences&apos;. Accepted for Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R P Fawcett</author>
<author>A van der Mije</author>
<author>C van Wissen</author>
</authors>
<title>Towards a systemic flowchart model for local discourse structure&apos;,</title>
<date>1988</date>
<booktitle>in Fawcett and</booktitle>
<pages>116--43</pages>
<location>Young</location>
<marker>Fawcett, van der Mije, van Wissen, 1988</marker>
<rawString>Fawcett, R.P., van der Mije, A., and van Wissen, C., 1988. &apos;Towards a systemic flowchart model for local discourse structure&apos;, in Fawcett and Young 1988, pp. 116-43.</rawString>
</citation>
<citation valid="true">
<title>New developments in systemic linguistics, Vol 2: Theory and application.</title>
<date>1988</date>
<editor>Fawcett, LP., and Young, DJ., (eds.)</editor>
<location>London: Pinter.</location>
<marker>1988</marker>
<rawString>Fawcett, LP., and Young, DJ., (eds.) 1988. New developments in systemic linguistics, Vol 2: Theory and application. London: Pinter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MA K Halliday</author>
</authors>
<title>Intonation and grammar in British English.</title>
<date>1967</date>
<publisher>The Hague: Mouton.</publisher>
<marker>Halliday, 1967</marker>
<rawString>Halliday, MA.K., 1967. Intonation and grammar in British English. The Hague: Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K MA</author>
</authors>
<title>A course in spoken English: intonation. London:</title>
<date>1970</date>
<publisher>Oxford University Press.</publisher>
<marker>MA, 1970</marker>
<rawString>MA.K., 1970. A course in spoken English: intonation. London: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>An introduction to functional grammar.</title>
<date>1985</date>
<location>London: Arnold.</location>
<contexts>
<context position="27613" citStr="Halliday 1985" startWordPosition="4616" endWordPosition="4617">just those that appear at the beginning of a clause. So far GENESYS includes eleven types, each of which may be realized by either a clause or a group (three different classes of groups being recognized: nominal, prepositional and quantityquality groups). Note, then, that we have now identified a second major source of what has been termed &apos;clause combining&apos;. A similar approach is needed for &apos;clause final&apos; clauses, i.e. clauses that fill any of the eleven types of Adjunct built into GENESYS so far, and that come late in the clause. (This is a different approach to clausecombining from that in Halliday 1985 and so from that in the Nigel grammar at ISI; here such clauses are simply treated as embedded - so far with gains in generalizations rather than losses.) Let us take as an example the concept of time position, which is one of five types of &apos;circumstance of time&apos; recognized in GENESYS - the others being repetition, duration, periodic frequency, and usuality. While GENESYS will happily generate clauses such as &amp;quot;until he leaves the company&apos; to specify a time position, in the case of our example Ivy has chosen the simpler structure of the prepositional group, i.e. &amp;quot;until next month&amp;quot;. The first s</context>
</contexts>
<marker>Halliday, 1985</marker>
<rawString>Halliday, M.A.K., 1985. An introduction to functional grammar. London: Arnold.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Houghton</author>
<author>S D Isard</author>
</authors>
<title>Why to speak, what to say and how to say it: modelling language production in discourse&apos;.</title>
<date>1987</date>
<booktitle>In</booktitle>
<pages>112--30</pages>
<location>Morris</location>
<contexts>
<context position="3357" citStr="Houghton and Isard 1987" startWordPosition="551" endWordPosition="554">egular, ongoing stimulus of many good explorations of ideas in this and other areas with my colleague Gordon Tucker. But none of these should be blamed for the inevitable crudities, infelicities and no doubt errors in the model described here; these are mine. The approach is very different from that in MITalk (Allen 1986), which is essentially a textto-speech system. So far as I am aware, the only generative model prior to ours that attempts to generate intonation that is motivated semantically and discoursally is the impressive work of Isard, Houghton, Pearson and their colleagues at Sussex (Houghton and Isard 1987) and Houghton and Pearson 1988). Its limitation is the very small size of its syntax, lexis, semantics and working domain. We see our work in the COMMUNAL Project as being to build on their important achievement. (But see Appendix 2 for what we do not attempt.) 2. The Relevant Components of the Communal Model The major components of the overall model that will be referred to below are as follows. We assume an interactive system, rather than one that is merely monologue. We shall ignore here the components related to parsing, interpretation and inputting to the belief system and planner. The co</context>
</contexts>
<marker>Houghton, Isard, 1987</marker>
<rawString>Houghton, G. and Isard, S.D.,1987. &apos;Why to speak, what to say and how to say it: modelling language production in discourse&apos;. In Morris 1987, pp. 112-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Houghton</author>
<author>M Pearson</author>
</authors>
<title>The production of spoken dialogue.</title>
<date>1988</date>
<booktitle>In Zock and Sabah 1988a,</booktitle>
<pages>112--30</pages>
<contexts>
<context position="3388" citStr="Houghton and Pearson 1988" startWordPosition="556" endWordPosition="559">any good explorations of ideas in this and other areas with my colleague Gordon Tucker. But none of these should be blamed for the inevitable crudities, infelicities and no doubt errors in the model described here; these are mine. The approach is very different from that in MITalk (Allen 1986), which is essentially a textto-speech system. So far as I am aware, the only generative model prior to ours that attempts to generate intonation that is motivated semantically and discoursally is the impressive work of Isard, Houghton, Pearson and their colleagues at Sussex (Houghton and Isard 1987) and Houghton and Pearson 1988). Its limitation is the very small size of its syntax, lexis, semantics and working domain. We see our work in the COMMUNAL Project as being to build on their important achievement. (But see Appendix 2 for what we do not attempt.) 2. The Relevant Components of the Communal Model The major components of the overall model that will be referred to below are as follows. We assume an interactive system, rather than one that is merely monologue. We shall ignore here the components related to parsing, interpretation and inputting to the belief system and planner. The components relevant to generation</context>
</contexts>
<marker>Houghton, Pearson, 1988</marker>
<rawString>Houghton, G., and Pearson, M., 1988. &apos;The production of spoken dialogue. In Zock and Sabah 1988a, pp. 112-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J House</author>
<author>M Johnson</author>
</authors>
<title>Enlivening the intonation in Text-to-Speech Synthesis: an &apos;Accent-Unit&apos; Model&apos;,</title>
<date>1987</date>
<booktitle>Procs 11th ICPhS,</booktitle>
<location>Tallinn.</location>
<marker>House, Johnson, 1987</marker>
<rawString>House, J. &amp; Johnson, M. (1987) Enlivening the intonation in Text-to-Speech Synthesis: an &apos;Accent-Unit&apos; Model&apos;, Procs 11th ICPhS, Tallinn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Kempen</author>
</authors>
<title>Natural language generation. Dordrecht Martinus Nijhoff.</title>
<date>1987</date>
<marker>Kempen, 1987</marker>
<rawString>Kempen, Gerard, (ed) 1987. Natural language generation. Dordrecht Martinus Nijhoff.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Kobsa</author>
<author>W Wahlster</author>
</authors>
<title>(eds.) User Models in Dialogue Systems.</title>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<marker>Kobsa, Wahlster, </marker>
<rawString>Kobsa, A., and Wahlster, W. (eds.) User Models in Dialogue Systems. Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>Matthiessen</author>
</authors>
<title>A demonstration of the Nigel text generation computer program&apos;.</title>
<date>1985</date>
<booktitle>In Mann and Matthiessen 1983 and in Benson and Greaves</booktitle>
<pages>50--83</pages>
<marker>Mann, Matthiessen, 1985</marker>
<rawString>Mann, W.C., and Matthiessen, 1983/85. &apos;A demonstration of the Nigel text generation computer program&apos;. In Mann and Matthiessen 1983 and in Benson and Greaves 1985, pp.50-83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McDonald</author>
</authors>
<title>Natural language generation as a computational problem&apos;.</title>
<date>1983</date>
<booktitle>In Brady and</booktitle>
<pages>209--65</pages>
<location>Berwick</location>
<marker>McDonald, 1983</marker>
<rawString>McDonald, D., 1983. &apos;Natural language generation as a computational problem&apos;. In Brady and Berwick 1983, pp209-65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D McDonald</author>
<author>M M Vaughan</author>
<author>J D Pustejovsky</author>
</authors>
<title>Factors contributing to efficiency in natural language generation&apos;.</title>
<date></date>
<booktitle>In</booktitle>
<pages>159--181</pages>
<location>Kempen</location>
<marker>McDonald, Vaughan, Pustejovsky, </marker>
<rawString>McDonald, D.D., Vaughan, M.M., and Pustejovsky, J.D., 198&apos;7. &apos;Factors contributing to efficiency in natural language generation&apos;. In Kempen 1987, pp. 159-181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Morris</author>
</authors>
<title>Modelling cognition.</title>
<date>1987</date>
<publisher>Chichester: Wiley.</publisher>
<marker>Morris, 1987</marker>
<rawString>Morris, P., (ed.) 1987. Modelling cognition. Chichester: Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Paris</author>
</authors>
<title>Tailoring object descriptions to a user&apos;s expertise&apos;.</title>
<date>1988</date>
<booktitle>In 1Cobsa and Wahlster</booktitle>
<contexts>
<context position="44938" citStr="Paris 1988" startWordPosition="7444" endWordPosition="7445">nation that will not be discussed here. The first four are not covered because they lie outside the current goals of the COMMUNAL project, while the last two are omitted because they will be implemented (we expect) by a sister project, support for which is currently being negotiated. 1. We shall not be concerned with the high level planning that will tailor the text to the needs of the addressee as affected by the channel (e.g. to build in greater redundancy, in the form of repetition of subject matter in planning what to express overtly, act by act). (For the general notion of tailoring, see Paris 1988.) 2. We shall not discuss variation in intonational characteristics of the sort that distinguish between speakers of different dialects (geographical, social class, age, etc). 3. The same goes for individual variation, i.e. intonational idiolect. 4. We shall ignore the code of tone of voice (&apos;angry&apos;, &apos;conciliatory&apos;, &apos;delighted&apos;, etc). At the same time we recognize that it is an important semiotic system in its own right, and that in the longer run the way in which it is, as it were, superimposed on the intonation system itself must be modelled. We recognize too the problems of drawing a firm </context>
</contexts>
<marker>Paris, 1988</marker>
<rawString>Paris, C.L. &apos;Tailoring object descriptions to a user&apos;s expertise&apos;. In 1Cobsa and Wahlster 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tench</author>
</authors>
<title>The roles of intonation in English discourse.</title>
<date>1987</date>
<tech>PhD thesis,</tech>
<institution>University of Wales.</institution>
<contexts>
<context position="5695" citStr="Tench 1987" startWordPosition="920" endWordPosition="921">and theme and information structure as well as TONALITY. transitivity, mood, negativity, modalit/, affective The accounts of the various aspects of intonation meaning and logical relationships, and equivalent in what follows will inevitably be introductory, and system networks for things and qualities, and may to the specialist appear simplistic. A b. the realization rules which turn the selection somewhat fuller treatment is given in Tench and expressions of features that are the output from Fawcett 1988, and a very full treatment is given in passes through the system networks into syntactic Tench 1987, which includes summaries of relevant structures with items (grammatical and lexical) work by other intonation specialists and markers of punctuation or intonation as their (I omit here, for reasons of space, a specification terminal nodes. of bow one might model the way in which the 3. Modelling Intonation position in a transaction and an exchange affects 3.1. An Overview of the Generation of Intonation intonation.) Let us imagine that Ivy (the &apos;person&apos; of whose Let us assume, then, that Ivy is preparing a mind GENESYS models a part) is about to response to the Personnel Officer&apos;s question, </context>
</contexts>
<marker>Tench, 1987</marker>
<rawString>Tench, P., 1987. The roles of intonation in English discourse. PhD thesis, University of Wales.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tench</author>
<author>R P Fawcett</author>
</authors>
<title>Specification of intonation for Prototype Generator 2.</title>
<date>1988</date>
<marker>Tench, Fawcett, 1988</marker>
<rawString>Tench, P., and Fawcett, R.P, 1988. Specification of intonation for Prototype Generator 2.</rawString>
</citation>
<citation valid="false">
<tech>(COMMUNAL Report No 6)</tech>
<institution>Cardiff: Computational Linguistics Unit, University of Wales College of Cardiff.</institution>
<marker></marker>
<rawString>(COMMUNAL Report No 6) Cardiff: Computational Linguistics Unit, University of Wales College of Cardiff.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GIL Tucker</author>
</authors>
<title>Natural language generation with a systemic functional grammar&apos;.</title>
<date>1989</date>
<booktitle>In Laboratorio degli studi linguistici 1989/1. Camerino: Italy: Universita degli Studi di Camerino</booktitle>
<pages>7--27</pages>
<contexts>
<context position="40891" citStr="Tucker 1989" startWordPosition="6772" endWordPosition="6773">fs about the addressee. Acknowledgements The research reported here was supported by grants from R.SRE Malvern under contract no. ER1/9/4/2181/23, by the University Research Council of International Computers Ltd, and by Longman. Appendix 1 COMMUNAL is a major research project that applies and develops Systemic Functional Grammar (SFG) in a very large, fully working computer program. The acronym COMMUNAL stands for COnviviai Man-Machine Understanding through NAtural Language. The principles underlying the project are set out in Fawcett 1988, and an illustration of a generation is presented in Tucker 1989. A fuller (but fairly informal) overall description, including some comparison with other projects, is given in Fawcett 1990. See also Fawcett (to appear). The project is planned to last 5 years, with around 6 researchers working on it. We finiqhe.d the successful Phase 1 in 1989, and now (May 1990) are getting under way on Phase 2 The central component of the overall system is the generator, built at Cardiff. This is called GENESYS (because it GENErates SYStemically). Contributions from the University of Leeds in Phase 1 were to build (1) a derived probabilistic purser, called the RAP (for R</context>
</contexts>
<marker>Tucker, 1989</marker>
<rawString>Tucker, GIL, 1989. &apos;Natural language generation with a systemic functional grammar&apos;. In Laboratorio degli studi linguistici 1989/1. Camerino: Italy: Universita degli Studi di Camerino (pp.7-27).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zock</author>
<author>G Sabah</author>
</authors>
<date></date>
<booktitle>1988a. Advances in natural language generation Vol 1.</booktitle>
<location>London: Pinter.</location>
<marker>Zock, Sabah, </marker>
<rawString>Zock, M., and Sabah, G., (eds) 1988a. Advances in natural language generation Vol 1. London: Pinter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zock</author>
<author>G Sabah</author>
</authors>
<date></date>
<booktitle>198811 Advances in natural language generation Vol 2.</booktitle>
<location>London: Pinter.</location>
<marker>Zock, Sabah, </marker>
<rawString>Zock, M., and Sabah, G., (eds) 198811 Advances in natural language generation Vol 2. London: Pinter.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>