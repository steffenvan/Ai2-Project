<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.420636">
EFFICIENT PARSING FOR FRENCH*
</title>
<author confidence="0.662475">
Claire Gardent
</author>
<affiliation confidence="0.94813975">
University Blaise Pascal — Clermont II and University of Edinburgh, Centre for Cognitive Science,
2 Buccleuch Place, Edinburgh EH89LW, SCOTLAND, UK
Gabriel G. Bes, Pierre-Francois Ririe and Karine Baschung,
Universite Blaise Pascal — Clermont II, Formation Doctorale Linguistique et Informatique,
</affiliation>
<address confidence="0.715671">
34, Ave. Carnot, 63037 Clermont-Ferrand Cedex, FRANCE
</address>
<sectionHeader confidence="0.64104" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.991252375">
Parsing with categorial grammars often leads to
problems such as proliferating lexical ambiguity, spu-
rious parses and overgeneration. This paper presents a
parser for French developed on an unification based
categorial grammar (FG) which avoids these pro-
blems. This parser is a bottom-up chart parser augmen-
ted with a heuristic eliminating spurious parses. The
unicity and completeness of parsing are proved.
</bodyText>
<sectionHeader confidence="0.998112" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.99988">
Our aim is twofold. First to provide a linguistical-
ly well motivated categorial grammar for French
(henceforth, FG) which accounts for word order varia-
tions without overgenerating and without unnecessary
lexical ambiguities. Second, to enhance parsing effi-
ciency by eliminating spurious parses, i.e. parses with
different derivation trees but equivalent semantics.
The two goals are related in that the parsing strategy
relies on properties of the grammar which are indepen-
dently motivated by the linguistic data. Nevertheless,
the knowledge embodied in the grammar is kept inde-
pendent from the processing phase.
</bodyText>
<sectionHeader confidence="0.998072" genericHeader="method">
1. LINGUISTIC THEORIES AND
WORD ORDER
</sectionHeader>
<footnote confidence="0.8112861">
Word order remains a pervasive issue for most
linguistic analyses. Among the theories most closely
related to FG, Unification Categorial Grammar
(UCG: Zeevat et al. 1987), Combinatory Categorial
Grammar (CCG: Steedman 1985, Steedman 1988),
Categorial Unification Grammar (CUG: Karttunen
1986) and Head-driven Phrase Structure Grammar
(HPSG: Pollard &amp; Sag 1988) all present inconvenien-
ces in their way of dealing with word order as regards
parsing efficiency and/or linguistic data.
</footnote>
<note confidence="0.709985">
* The work reported here was carried out in the ESPRIT Project 393
ACORD, «The Construction and Interrogation of Knowledge
Bases using Natural Language Text and Graphics.
</note>
<bodyText confidence="0.995097677419355">
In UCG and in CCG, the verb typically encodes the
notion of a canonical ordering of the verb arguments.
Word order variations are then handled by resorting to
lexical ambiguity and jump rules&apos; (UCG) or to new
combinators (CCG). As a result, the number of lexical
and/or phrasal edges increases rapidly thus affecting
parsing efficiency. Moreover, empirical evidence does
not support the notion of a canonical order for French
(cf. Bes &amp; Gardent 1989).
In contrast, CUG, GPSG (Gazdar et al. 1985) and
HPSG do not assume any canonical order and subcate-
gorisation information is dissociated from surface
word order. Constraints on word order are enforced by
features and graph unification (CUG) or by Linear Pre-
cedence (LP) statements (HPSG, GPSG). The pro-
blems with CUG are that on the computational side,
graph-unification is costly and less efficient in a Prolog
environment than term unification while from the
linguistic point of view (a) NP&apos;s must be assumed
unambiguous with respect to case which is not true for
- at least - French and (b) clitic doubling cannot be ac-
counted for as a result of using graph unification
between the argument feature structure and the functor
syntax value-set. In HPSG and GPSG (cf. also Uszko-
reit 1987), the problem is that somehow, LP statements
must be made to interact with the corresponding rule
schemas. That is, either rule schemas and LP state-
ments are precompiled before parsing and the number
of rules increases rapidly or LP statements are checked
on the fly during parsing thus slowing down proces-
sing.
</bodyText>
<sectionHeader confidence="0.999342" genericHeader="method">
2. THE GRAMMAR
</sectionHeader>
<bodyText confidence="0.880287571428571">
The formal characteristics of FG underlying the
parsing heuristic are presented in §4. The characteris-
tics of FG necessary to understand the grammar are re-
sumed here (see (Bes &amp;Gardent 89) for a more detailed
presentation).
A jump rule of the fonn X/Y, YIZ —&gt;X/Z where X/Y is a type raised
NP and Y/Z is a verb.
</bodyText>
<page confidence="0.991926">
280
</page>
<bodyText confidence="0.998885884615384">
FG accounts for French linearity phenomena, em-
bedded sentences and unbounded dependencies. It is
derived from UCG and conserves most of the basic
characteristics of the model: monostratality, lexica-
lism, unification-based formalism and binary combi-
natory rules restricted to adjacent signs. Furthermore,
FG, as UCG, analyses NP&apos;s as type-raised categories.
FG departs from UCG in that (i) linguistic entities
such as verbs and nouns, sub-categorize for a set
— rather than a list — of valencies ; (ii) a feature system
is introduced which embodies the interaction of the
different elements conditioning word order; (iii) FG
semantics, though derived directly from MI.:, leave the
scope of scoping operators undefined.
The FG sign presents four types of information re-
levant to the discussion of this paper : (a) Category, (b)
Valency set; (c) Features; (d) Semantics. Only two
combinatory rules —forward and backward concatena-
tion — are used, together with a deletion rule.
A Category can be basic or complex. A basic ca-
tegory is of the form Head, where Head is an atomic
symbol (n(oun),np or s(entence)). Complex categories
are of the form C/Sign, where C is either atomic or
complex, and Sign is a sign called the active sign.
With regard to the Category information, the FG
typology of signs is reduced to the following.
</bodyText>
<listItem confidence="0.9319365">
(1)Type Category Linguistic entities
10 Head verb, noun
fl Head/fl) NP, PP, adjective, adverb,
auxiliary, negative particles
12 (f1)/sign,
(a) sign, = ID Determiner, complementi-
zer, relative pronoun
(b) sign, = fl Preposition
</listItem>
<bodyText confidence="0.987294754716981">
Thus, the result of the concatenation of a NP (f1)
with a verb (M) is a verbal sign (M). Wrt the concate-
nation rules, M signs are arguments; fl signs are either
functors of M signs, or arguments of 12 signs. Signs of
type 12 are leaves and functors.
Valencies in the Valency Set are signs which ex-
press sub-categorisation. The semantics of a M sign is
a predicate with an argumental list. Variables shared by
the semantics of each valency and by the predicate list,
relate the semantics of the valency with the semantics
of the predicate. Nouns and verbs sub-categorize not
only for &amp;quot;normal&amp;quot; valencies such as nom(inative),
dat(ive), etc, but also for a mod(ifier) valency, which is
consumed and recursively reintroduced by modifiers
(adjectives, PP&apos;s and adverbs). Thus, in FG the corn-
InL (Indexed Language) is the semantics incorporated to UCG ; it
derives from Kamp&apos;s DRT. From hereafter we refer to FG semantics
as Int:.
plete combinatorial potential of a predicate is incorpo-
rated into its valency set and a unified treatment of
nominal and verbal modifiers is proposed. The active
sign of a fl functor indicates the valency — if any —
which the functor consumes.
No order value (or directional slash) is associated
with valencies. Instead, Features express adjacent and
non-adjacent constraints on constituent ordering,
which are enforced by the unification-based combina-
tory rules. Constraints can be stated not only between
the active sign of a functor and its argument, but also
between a valency, of a sign,, the signs and the active
sign of the fl functor consuming valency, while con-
catenating with signs. As a result, the valency of a verb
or of a noun imposes constraints not only on the functor
which consumes it, but also on subsequent concatena-
tions. The feature percolation system underlies the
partial associativity property of the grammar (cf. §4).
As mentioned above, the Semantics part of the sign
contains an InL&apos; formula. In FG different derivations of
a string may yield sentence signs whose InL&apos; formulae
are formally different, in that the order of their sub-for-
mulae are different, but the set of their sub-formulae
are equal. Furthermore, sub-formulae are so built that
formulae differing in the ordering of their sub-formu-
lae can in principle be translated to a semantically equi-
valent representation in a first order predicate logic.
This is because : (i) in InL&apos;, the scope of scoping
operators is left undefined; (ii) shared variables ex-
press the relation between determiner and restrictor,
and between scoping operators and their semantic
arguments; (iii) the grammar places constants (i.e.
proper names) in the specified place of the argumental
list of the predicate. For instance, FG associates to (2)
the InL&apos; formulae in (3a) and (3b) :
</bodyText>
<listItem confidence="0.983309">
(2) Un garcon presente Marie a une fille
(3) (a) [E] [ind(X) &amp; garcon(X) &amp; ind(Y) &amp; fille(Y) &amp;
presenter (E,X,marie,Y)]
(b) [E] [ind(Y) &amp; fille(Y) &amp; ind(X) &amp; garcon(X) &amp;
presenter (E,X,marie,Y)]
</listItem>
<bodyText confidence="0.991031857142857">
While a scoping operator of a sentence constituent
is related to its argument by the index of a noun (as in
the above (3)), the relation between the argument of a
scoping operator and the verbal unit is expressed by the
index of the verb. For instance, the negative version of
(2) will incorporate the sub-formula neg (E).
In InL&apos; formulae, determiners (which are leaves
and 12 signs, cf. above), immediately precede their res-
trictors. In formally different InL&apos; formulae, only the
ordering of scoping operators sub-formulae can differ,
but this can be shown to be irrelevant with regard to the
semantics. In French, scope ambiguity is the same for
members of each of the following pairs, while the
ordering of their corresponding semantic sub-forrnu-
</bodyText>
<page confidence="0.995069">
281
</page>
<bodyText confidence="0.975222">
lae, thanks to concatenation of adjacent signs, is ines-
capably different.
</bodyText>
<listItem confidence="0.87806475">
(4) (a) Jacques avait donne un livre (a) a tousles itu-
diants (b).
(a&apos;) Jacques avait donne dtous les itudiants(b) un
livre (a).
(b) Un livre a ea commande par chaque etudiant
(a) a une librairie (b).
(b&apos;) Un livre a ete commanded une librairie ( b) par
chaque itudiant (a).
</listItem>
<bodyText confidence="0.999749052631579">
At the grammatical level (i.e. leaving aside prag-
matic considerations),the translation of an InL&apos; formu-
la to a scoped logical formula can be determined by the
specific scoping operator involved (indicated in the
sub-formula) and by its relation to its semantic argu-
ment (indicated by shared variables). This translation
must introduce the adequate quantifiers, determine
their scope and interpret the &apos;&amp;&apos; separator as either A or
as well as introduce in negative forms. For ins-
tance, the InL&apos; formulae in (Y) translate&apos; to:
(5) 3E, 3X, 3Y (garcon(X) A fille(Y) A presenter
(E,X,marie,Y)).
We assume here the possibility of this translation
without saying any more on it. Since this translation
procedure cannot be defined on the basis of the order of
the sub-formulae corresponding to the scoping opera-
tors, MI.: formulae which differ only wrt the order of
their sub-formulae are said to be semantically equiva-
lent.
</bodyText>
<sectionHeader confidence="0.995867" genericHeader="method">
3. THE PARSER
</sectionHeader>
<bodyText confidence="0.999459452830189">
Because the subcategorisation information is re-
presented as a set rather than as a list, there is no
constraint on the order in which each valency is
consumed. This raises a problem with respect to par-
sing which is that for any triplet X,Y,Z where Y is a
verb and X and Z are arguments to this verb, there will
often be two possible derivations i.e., (XY)Z and
X(YZ).
The problem of spurious parses is a well-known
one in extensions of pure categorial grammar. It deri-
ves either from using other rules or combinators for de-
rivation than just functional application (Pareschi and
Steedman 1987, Wittenburg 1987, Moortgat 1987,
Morrill 1988) or from having unordered set valencies
(ICarttunen 1986), the latter case being that of FG.
Various solutions have been proposed in relation to
this problem. Karttunen&apos;s solution is to check that for
any potential edge, no equivalent analysis is already
In (5) BE can be paraphrased as &amp;quot;There exists an event&amp;quot;.
stored in the chart for the same string of words. Howe-
ver as explained above, two semantically equivalent
formulae of InL&apos; need not be syntactically identical.
Reducing two formulae to a normal form to check their
equivalence or alternatively reducing one to the other
might require 2n permutations with n the number of
predicates occuring in the formulae. Given that the test
must occur each time that two edges stretch over the
same region and given that it requires exponential time,
this solution was disguarded as computationally inef-
ficient.
Pareschi&apos;s lazy parsing algorithm (Pareschi, 1987)
has been shown (Hepple, 1987) to be incomplete.
Wittenburg&apos;s predictive combinators avoid the parsing
problem by advocating grammar compilation which is
not our concern here. Morill&apos;s proposal of defining
equivalence classes on derivations cannot be transpo-
sed to FG since the equivalence class that would be of
relevance to our problem i.e., ((X,Z)Y, X(ZY)) is not
an equivalence class due to our analysis of modifiers.
Finally, Moortgat&apos;s solution is not possible since it
relies on the fact that the grammar is structurally com-
plete&apos; which FG is not.
The solution we offer is to augment a shift-reduce
parser with a heuristic whose essential content is that
no same functor may consume twice the same valency.
This ensures that for all semantically unambiguous
sentences, only one parse is output. To ensure that a
parse is always output whenever there is one, that is to
ensure that the parser is complete, the heuristic only
applies to a restricted set of edge pairs and the chart is
organized as a queue. Coupled with the partial-associa-
tivity of FG, this strategy guarantees that the parser is
complete (cf. §4).
</bodyText>
<subsectionHeader confidence="0.979086">
3.1 THE HEURISTIC
</subsectionHeader>
<bodyText confidence="0.991913583333333">
The heuristic constrains the combination of edges
in the following way2.
Let el be an edge stretching from Si to El labelled
with the type JV, a predicate identifier pl and a sign
Signl , let e2 be an edge stretching from El to S2
labelled with type f/ and a sign Sign2, then e2 will
reduce with el by consuming the valency Val of pl if
e2 has not already reduced with an edge el &apos;by consu-
ming the valency Valofpl where el &apos;stretches from Si&apos;
to El and Si&apos; Si.
In the rest of this section, examples illustrate how
A structurally complete grammar is one such that:
</bodyText>
<footnote confidence="0.97738">
If a sequence of categories X1 Xn reduces to Y, there is a reduction
to Y for any bracketing of X1 Xn into constituents (Moortgat,
1987).
2 A more complete difinition is given in the description of the
parsing algorithm below.
</footnote>
<page confidence="0.991838">
282
</page>
<bodyText confidence="0.9360635">
this heuristic eliminates spurious parses, while allo-
wing for real ambiguities.
Avoiding spurious parses
Consider the derivation in (6)
</bodyText>
<figure confidence="0.9616877">
(6) Jean aime Marie Ed4 = Ed 1 (Ed2,p1,subj)
0 - Ell - 1 - Ed2 - 2 - Ed3-- 3 *Ed5 = Ed&apos; (Ed2,p1,obj)
0 Ed4 ------- 2
Ed5 ------- 2
1 - Ed6 3 Ed6 = Ed3(Ed2,p1,obj)
1 Ed7 3 Ed7 = Ed3(E42,p1,subj)
0 - -Ed8 3 Ed8 = Ed 1(Ed6,p1,subj)
0 - Ed9 3 *Ed9 = Ed3(Ed4,p1,obj)
0 3 *Ed 10 = Ed 1(Ed7,p1,obj)
Ed10
</figure>
<bodyText confidence="0.996438944444444">
where Ed4 = Edl(Ed2,p1,subj) indicates that the edge
Ed! reduces with Ed2 by consuming the subject valen-
cy of the edge Ed2 with predicate pl.
Ed5 and Ed10 are ruled out by the grammar since
in French no lexical (as opposed to clitics and wh-NP)
object NP may appear to the left of the verb. Ed9 is
ruled out by the heuristic since Ed3 has already consu-
med the object valency of the predicate pl thus yiel-
ding Ed6. Note also that Edi may consume twice the
subject valency of pl thus yielding Ed4 and Ed8 since
the heuristic does not apply to pairs of edges labelled
with signs of type fl and 10 respectively.
Producing as many parses as there are readings
The proviso that a functor edge cannot combine
with two different edges by consuming twice the same
valency on the same predicate ensures that PP attach-
ment ambiguities are preserved. Consider (7) for ins-
tance&apos;.
</bodyText>
<equation confidence="0.928209166666667">
(7) Regarde le chien dans la rue
0 --Edl --- 1 ---Ed2 - 2 - Ed3 ---- 3 --- Ed4 4
1 Ed5 3
0 Ed6 3
2 Ed7 4
1 Ed8 4
0 Ed9 4
0 Ed10 4
with Ed7 = Ed4(Ed3,p2,mod)
Ed8 = Ed2(Ed7)
Ed9 = Ed8(Ed 1 ,p 1 ,obj)
Ed 10 = Ed4(Ed6,p1,mod)
</equation>
<bodyText confidence="0.726682625">
where pl and p2 are the predicate identifiers labelling
the edges Ed! and Ed3 respectively.
The above heuristic allows a functor to concatenate
twice by consuming two different valencies. This case
&apos;For the sake of clarity, all irelevant edges have been omitted. This
practice will hold throughout the sequel.
of real ambiguity is illustrated in (8).
(8) Quel homme prdsente Marie a Rose?
</bodyText>
<equation confidence="0.4586006">
0 ---- Edl ---- 1 --- Ed2 -- 2 -- Ed3--- 3 -- Ed4--- 4
1 Ed4 3
1 Ed5 3
3
3
</equation>
<bodyText confidence="0.9995985">
Thus, only edges of the same length correspond to
two different readings. This is the reason why the
heuristic allows a functor to consume twice the same
valency on the same predicate ill it combines with two
edges E and E&apos; that stretch over the same region. A case
in point is illustrated in (9)
</bodyText>
<table confidence="0.97923975">
(9) Quel homme presente Marie a Rose?
0---- Ed1---- 1 --- Ed2 --2-- Ed3---3 -- Ed4--- 4
1 3
Ed5
1 3
Ed6
1 4
Ed7
1 4
Ed8
0 - Ed9 4
---- Ed10 4
</table>
<bodyText confidence="0.9729505">
where a Rose concatenates twice by consuming twice
the same — dative — valency of the same predicate.
</bodyText>
<subsectionHeader confidence="0.930657">
3.2 THE PARSING ALGORITHM
</subsectionHeader>
<bodyText confidence="0.991821153846154">
The parser is a shift-reduce parser integrating a
chart and augmented with the heuristic.
An edge in the chart contains the following infor-
mation:
edge [Name, Type, Heur, S,E, Sign]
where Name is the name of the edge, S and E identifies
the starting and the ending vertex and Sign is the sign
labelling the edge. Type and Heur contain the infor-
mation used by the heuristic. Type is either M, fl and
f2 while the content of Hew depends on the type of the
edge and on whether or not the edge has already
combined with some other edge(s).
Heur
pX where X is an integer.
pX identifies the predicate associated with any
edge.
type M
fl before combination: Var
where Var is the anonymous variable. This indica-
tes that there is as yet no information available that
could violate the heuristic.
after combination: Heur-List
where Hew-List is a list of triplets of the form
[Edge,pX,Val] and Edge indicates an argument
edge with which the functor edge has combined by
consuming valency Val of the predicate pX label-
</bodyText>
<figure confidence="0.717599">
0 Ed6
0 Ed7
where Ed4 = (Ed3,p1,nom)
and Ed5 = (Ed.3,p1,obj)
</figure>
<page confidence="0.980398">
283
</page>
<bodyText confidence="0.938745">
ling Edge.
f2 nil
The basic parsing algorithm is that of a normal
shift-reduce parser integrating a chart rather than a
stack i.e.,
</bodyText>
<listItem confidence="0.9989108">
1. Starting from the beginning of the sentence, for
each word W either shift or reduce,
2. Stop when there is no more word to shift and no
more reduce to perforni,
3. Accept or reject.
</listItem>
<bodyText confidence="0.999684333333334">
Shifting a word W consists in adding to the chart as
many lexical edges as there are lexical entries associa-
ted with Win the lexicon. Reducing an edge E consists
in trying to reduce E with any adjacent edge E&apos; already
stored in the chart. The operation applies recursively in
that whenever a new edge E&amp;quot; is created it is immedia-
tely added to the chart and tried for reduction. The
order in which edges tried for reduction are retrieved
from the chart corresponds to organising the chart as a
queue i.e., first-in-first-ouL Step 3 consists in checking
the chart for an edge stretching from the beginning to
the end of the chart and labelled with a sign of category
s(entence). If there is such an edge, the string is
accepted – else it is rejected.
The heuristic is integrated in the reduce procedure
which can be defined as follows.
Two edges Edgel and Edge2 will reduce to a new
edge Edge3 iff
</bodyText>
<listItem confidence="0.986735578947369">
Either (a)
1. Edge! = [el ,Type 1 ,H I ,E2,S ign 1] and
2. Edge2 = [e2,Type2,H2,E2,Sign2] and
&lt;Type 1 ,Type2&gt; &lt; f0,f I &gt; and
3. apply(S ign 1,S ign2,S ign3) and
4. Edge3 = [e3,Type3,H3,E3,Sign31 and
&lt;S3,E3&gt; = &lt;S1,E2&gt;
Or (b)
1. Edgel = [el,f0,p1,S1,E1,Signl] and
2. Edge2 = [e2,f1,H2,S2,E2,Sign2] and
El = S2 and
3. bapply(Signl,Sign2,Sign3) by consuming the
valency Val and
4. H2 does not contain a triplet of the form
[e l&apos;,p 1 ,Val] where Edge 1&apos; = [e 1 &apos;,f0,p 1,S&apos;l ,S2]
and S&apos;1=S1
5. Edge3 = [e3,f0,p 1,S 1,E2,Sign3]
6. The heuristic information H2 in Edge2 is upda-
ted to [e 1,p 1 ,Val]+H2
</listItem>
<bodyText confidence="0.999068083333333">
where &apos;+ &apos;indicates list concatenation and under the
proviso that the triplet does not already belong to H2.
Where apply(Sign1 ,Sign2,Sign3)meansthat Sign 1
can combine with Sign2 to yield Sign3 by one of the
two combinatory rules of FG and bapply indicates the
backward combinatory rule.
This algorithm is best illustrated by a short exam-
ple. Consider for instance, the parsing of the sentence
Pierre aime Marie. Stepl shifts Pierre thus adding
Edgel to the chart. Because the grammar is designed
to avoid spurious lexical ambiguity, only one edge is
created.
</bodyText>
<equation confidence="0.767719">
Edgel = [el,f1,_,0,1,Sign 1]
</equation>
<bodyText confidence="0.846386333333333">
Since there is no adjacent edge with which Edgel
could be reduced, the next word is shifted i.e., aime
thus yielding Edge2 that is also added to the chart.
</bodyText>
<equation confidence="0.989385">
Edge2 = [e2,f0,p 1 ,1 ,2,S ign21
</equation>
<bodyText confidence="0.9781696">
Edge2 can reduce with Edge! since Sign 1 can
combine with Sign2 to yield Sign3 by consuming the
subject valency of the predicate p1. The resulting edge
Edge3 is added to the chart while the heuristic infor-
mation of the functor edge Edgel is updated:
</bodyText>
<equation confidence="0.9788915">
Edge3 = [e3,f0,p 1,0,2,S ign3]
Edgel = [e 1,f1 ,[[e3,p 1,subj]] ,O, 1 ,S ign 1]
</equation>
<bodyText confidence="0.575327">
No more reduction can occur so that the last word
Marie is shifted thus adding Edge4 to the chart.
</bodyText>
<equation confidence="0.9868">
Edge4 = [e4,f1,_,2,3,Sig4]
</equation>
<bodyText confidence="0.9960985">
Edg4 first reduces with Edeg2 by consuming the sub-
ject valency of pl thus creating Edge5. It also reduces
with Edge2 by consuming the object valency of pl to
yield Edge6.
</bodyText>
<equation confidence="0.9994975">
Edge5 = [e5,f0,p 1,1,3,S ign5]
Edge6 = [e6,f0,p 1,1 ,3,S ign6]
Edge4 is updated as follows.
Edge4 = [e4,f1 ,[[e2,p 1 ,subj] , [e2,p 1 ,obj]] ,2,3,Sign4]
</equation>
<bodyText confidence="0.698372">
At this stage, the chart contains the following edges.
Pierre aime Marie
</bodyText>
<equation confidence="0.998840666666667">
0 e3 3
1 e5-3
1 e6-3
</equation>
<bodyText confidence="0.9539655">
Now Edgel can reduce with Edge6 by consuming
the subject valency of p1 thus yielding Edge7 . Howe-
ver, the heuristic forbids Edge4 to consume the object
valency of pl on Edge3 since Edge4 has already
consumed the object valency of p1 when combining
with Edge2 . In this way, the spurious parse Edge8 is
avoided.
The final chart is as follows.
Pierre aime Marie
0—e1-1—e2-2—e4-3
</bodyText>
<equation confidence="0.9971153">
0 e3 3
1 e5-3
1 e6-3
0 e7 3
*0— e8 3
28L1
with
Edge7 = [e7,f0,p1,0,3,Sign7]
Edge4 = [e4,f1,[[e2,p1,subj],[e2,p 1,obj]],2,3,S ign4]
Edge! = [el ,f1 ge2,p 1 ,subB ,0,1 ,S ign 1
</equation>
<sectionHeader confidence="0.887307" genericHeader="method">
4. UNICITY AND COMPLETNESS
OF THE PARSING
DEFINITIONS
</sectionHeader>
<listItem confidence="0.948332">
1. An indexed lexical f0 is a pair &lt;X,i&gt; where X is a
lexical sign of f0 type (c.f. 2) and i is an integer.
2. PARSE denotes the free algebra recursively defined
by the following conditions.
2.1 Every lexical sign of type fl or 12, and every
indexed lexical 10 is a member of PARSE.
2.2 If P and Q are elements of PARSE, i is an integer,
and k is a name of a valency then (P+LkQ) is a
member of PARSE.
2.3 If P and Q are elements of PARSE, (P+0Q) is a
member of PARSE, where a) is a new symbol.1
3. For each member, P, of PARSE, the string of the
leaves of P is defined recursively as usual:
3.1 If P is a lexical functor or a lexical indexed argu-
ment, L(P) is the string reduced to P.
3.2 L(P+ikQ) is the string obtained by concatenation of
L(P) and L(Q).
4. A member P of PARSE, is called a well indexed
parse (WP) if two indexed leaves which have different
ranges in L(P), have different indicies.
5. The partial function, S(P), from the set of WP to the
set of signs, is defined recursively by the following
conditions:
</listItem>
<subsectionHeader confidence="0.927587">
5.1 If P is a leave S(P) = P
5.2 S(F+ikA) = Z [resp. S(A+ikF) = Z] (k )
</subsectionHeader>
<bodyText confidence="0.903552">
If S(F) is a functor of type fl, S(A) is an argument and
Z is the result sign by the FC rule [resp. BC rule]
when S(F) consumes the valency named k in the
leave of S(A) indexed by i.
5.3 S(F+k3A) = Z [res. S(AtatF) = Z] if S(F) is a functor
of type fl or 12, S(A) is an argument sign and Z is
the result sign by the FC rule [resp. BC rule].
</bodyText>
<listItem confidence="0.863996421052632">
6. For each pair of signs X and Y we denote X Y if X
and Y are such that their non semantic parts are formal-
ly equal and their semantic part is semantically equiva-
lent.
I In 2.3 the index i is just introduced for notational convenience and
will not be used; will denote a valency name or the symbol CD.
7. If P and Q are WP
P Q iff
7.1 S(P) and S(Q) are defined
7.2 S(P) S(Q) and
7.3 L(P) = L(Q)
8. A WP is called accepted if it is accepted by the parser
augmented with the heuristic described in §3.
THEOREM
1. (Unicity) If P and Q are accepted WP&apos;s and if P .2.-- Q,
then P and Q are formally equal.
2. (Completeness) If P is a WP which is accepted by the
grammar, and S(P) is a sign corresponding to a gram-
matical sentence, then there exists a WP Q such that:
</listItem>
<equation confidence="0.879246333333333">
a) Q is accepted, and
b) P z. Q.
NOTATIONAL CONVENTION
</equation>
<bodyText confidence="0.9365792">
F, F... (resp. A,A,...) will denote WP&apos;s such that S(F),
S(F&apos;).. .are functors of type fl (resp. S(A), S(A&apos;)..., are
arguments of type 10).
The proof of the theorem is based on the following
properties 1 to 3 of the grammar. Property 1 follows
directly from the grammar itself. (cf. §2) ; the other two
are strong conjectures which we expect to prove in a
near future.
PROPERTY 111 S(K) is defined and L(K) is not a
lexical leaf, then:
</bodyText>
<equation confidence="0.804013285714286">
a) If K is of type fO, there exist i,k,F and A such that:
K = F+ A or K = A+ F
b) If K is of type fl, there exist Fu of type 12 and Ar of
type 10 or of type fl such that:
K = FutarAr
c) K is not of type f2.
PROPERTY 2 (Decomposition unicity) :
</equation>
<construct confidence="0.89219725">
For every i and k
if F+ikA F+j,kA&apos;, or Al-ikF A&apos;+i,kF
then i= k= k, A s A&apos; and FF&apos;
PROPERTY 3 (Partial associativity) :
</construct>
<bodyText confidence="0.884546333333333">
For every F,A,F such that L(F) L(A) L(F) is a sub-
string of a string of lexical entries which is accepted by
the grammar as a grammatical sentence,
</bodyText>
<reference confidence="0.462444">
a) If S[F+ik(A+ilF)] and S[(F+ikA)+ilF] are defined,
then F+ik(A+,) (F+ikA)-f-iiF
b) If S[A+ilF] and S[(F+ikA)+ilF] are defined,
then S[F+ik(A+f)] is also defined.
</reference>
<page confidence="0.990885">
285
</page>
<figure confidence="0.8711581">
LEMMA 1
If F-FikA
then A&apos;A-uF is not accepted.
Proof: L(F) is a proper substring of L(A), so there
exists A&amp;quot; such that:
a) S(A&amp;quot;+&amp;quot;) is defined, and
b) L(A&amp;quot;) is a substring of L(A)
But A&apos; begins by F and F is not contained in A&amp;quot;, so A&amp;quot;
is an edge shorter than A&apos;. Thus A&apos;+F is not accepted.
LEMMA 2
If S[(A+F)+f] is defined and
Ag-ikF is accepted, then
(A+u,F)+uF is also accepted.
Proof: Suppose, a contrario, that (A+F)+,,F is not
accepted. Then there must exist an edge
A&apos; = A&amp;quot;+ikF such that:
a) S(A&apos;+uF) is defined, and
b) A&apos; is shorter than A+LkF
This implies that A&amp;quot; is shorter than A.
Therefore Atk. F would not be accepted.
</figure>
<sectionHeader confidence="0.636531" genericHeader="method">
PROOF OF THE PART 1 OF THE THEOREM
</sectionHeader>
<bodyText confidence="0.994906875">
The proof is by induction on the lengh, lg(P), of
L(P). So we suppose a) and b) :
a) (induction hypothesis). For everyr and Q&apos; such that
P&apos; and Q&apos; are accepted, if P&apos; s Q&apos;, and
Ig(P&apos;) &lt; n, then P. =.Q&apos;
b) P and Q are accepted, P s Q and
1g(P) = n
and we have to prove that
</bodyText>
<equation confidence="0.981663">
c) P = Q.
First cas : if 1g(P) = 1, then we have
P = L(P) = L(Q) = Q.
Second cas : if lg(P) &gt; 1, then we have
1g(Q) &gt; 1 since L(P) = L(0). Thus there exist P&apos;1,
Q1, Q2, i, k, j, 1, such that
P = P&apos;,+,kP&apos;, and Q =
</equation>
<bodyText confidence="0.97019125">
By the Lemma 1 P&apos;, and must be both functors
or both arguments. And if P&apos;, and Q&apos;, are functors (res.
arguments) then P&apos;2 and Q&apos;2 arearguments (resp. func-
tors). So by Property 2, we have:
</bodyText>
<equation confidence="0.550945">
i = k = k&apos;, P&apos;, _a Q&apos;1, and
</equation>
<bodyText confidence="0.9816665">
Then the induction hypothesis implies that P&apos;, = Q&apos;, and
that IY2 = Q&apos;2. Thus we have proved that P = Q.
</bodyText>
<sectionHeader confidence="0.692756" genericHeader="method">
PROOF OF THE PART 2 OF THE THEOREM
</sectionHeader>
<bodyText confidence="0.92687575">
Let P be a WP such that S(P) is define and corms-
ponds to a grammatical sentence. We will prove, by
induction on the lengh of L(K), that for all the subtrees
K of P, there exists K&apos; such that:
</bodyText>
<figure confidence="0.474859307692308">
a) K&apos; is accepted, and
b)Ks-K&apos;.
We consider the following cases (Property 1)
1. If K is a leaf then K&apos; = K
2. If K = F+ikA, then by the induction hypothesis
there exist F and A&apos; such that:
(i) F and A&apos; are accepted, and
(ii) F a F, A E A&apos;.
Then F+A&apos; is also accepted. So that K&apos; can be choose(&apos;
as F&apos;+A&apos;.
3. If K = A+ikF, we define F, A&apos; as in (2) and we
consider the following subcases :
3.1 If A&apos; is a leaf or if A&apos;.= F1+ uAl where S(AltkF)
</figure>
<construct confidence="0.3780955">
is not defined, then A&apos;+,17 is accepted, and we can
take it as K.
</construct>
<subsectionHeader confidence="0.760251">
3.2 If A&apos; = A1-1-uF1, then by the Lemma 2 A&apos;tkF is
</subsectionHeader>
<bodyText confidence="0.9558765">
accepted. Thus we can define K&apos; as A&apos;+±F.
3.3 If A&apos; = Fl+uAl and S(Al+aF) is defined.
Let A2 = Al+ikF.
By the Property 3 S(F1+uA2) is defined
and K A&apos;+ikF s
Thus this case reduces to case 2.
4. If K = Futa,Ar, where Fu is of type 12 and Ar is of
type f0 or fl, then by induction hypothesis there exists
Ar&apos; such that Ar At&apos; and Ar&apos; is accepted. Then K can
be defined as Fu+koAr&apos;.
</bodyText>
<sectionHeader confidence="0.9997965" genericHeader="method">
5. IMPLEMENTATION AND COVE-
RAGE
</sectionHeader>
<bodyText confidence="0.997428764705882">
FG is implemented in PIMPLE, a PROLOG term
unification implementation of PATR II (cf. Calder
1987) developed at Edinburgh University (Centre for
Cognitive Studies). Modifications to the parsing algo-
rithm have been introduced at the &amp;quot;Universite Blaise
Pascal&amp;quot;, Clermont-Ferrand. The system runs on a SUN
M 3/50 and is being extensively tested. It covers at
present: declarative, interrogative and negative sen-
tences in all moods, with simple and complex verb
forms. This includes yes/no questions, constituent
questions, negative sentences, linearity phenomena
introduced by interrogative inversions, semi free cons-
tituent order, elides (including reflexives), agreement
phenomena (including gender and number agreement
between obj NP to the left of the verb and participles),
passives, embedded sentences and unbounded depen-
dencies.
</bodyText>
<page confidence="0.996678">
286
</page>
<sectionHeader confidence="0.997744" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999646633802817">
Bes, G.G. and C. Gardent (1989) French Order without
Order. To appear in the Proceedings of the Fourth
European ACL Conference (UMIST, Manchester,
10-12 April 1989), 249-255.
Calder, J. (1987) PIMPLE ; A PROLOG Implementa-
tion of the PATR-II Linguistic Environment. Edin-
burgh, Centre for Cognitive Science.
Gazdar, G., Klein, E., Pullum, G., and Sag., I. (1985)
GeneralizedP lzrase Structure Grammar. London:
Basil Blackwell.
Kamp, H. (1981) A Theory of Truth and Semantic
Representation. In Groenendijk, J. A. G., Janssen,
T. M. V. and Stokhof, M. B. J. (eds.) Formal
Methods in the Study of Language, Volume 136,
277-322. Amsterdam : Mathematical Centre
Tracts.
ICarttunen, L. (1986) Radical Lexicalism. Report No.
CSLI-86-68, Center for the Study of Language and
Information, Paper presented at the Conference on
Alternative Conceptions of Phrase Structure, July
1986, New York.
Morrill, G. (1988) Extraction and Coordination in
Phrase Structure Grammar and Cate gorial Gram-
mar. PhD Thesis, Centre for Cognitive Science,
University of Edinburgh.
Pareschi, R. (1987) Combinatory Grammar, Logic
Programming, and Natural Language. In Haddock,
N. J., Klein, E. and Morill, G. (eds.) Edinburgh
Working Papers in Cognitive Science, Volume I;
Categorial Grammar, Unification Grammar and
Parsing.
Pareschi, R. and Steedman, M. J. (1987) A Lazy Way
to Chart-Parse with Extended Categorial Gram-
mars. In Proceedings of the 25 th Annual Meeting of
the Association for Computational Linguistics,
Stanford University, Stanford, Ca., 6-9 July, 1987.
Pollard, C. J. (1984) Generalized Phrase Structure
Grammars, Head Grammars, and Natural Lan-
guages. PhD Thesis, Stanford University.
Pollard, C. J. and Sag, I. (1988)An Information-Based
Approach to Syntax and Semantics : Volume 1
Fundamentals. Stanford, Ca. : Center for the Study
of Language and Information.
Steedman, M.(1985) Dependency and Coordination in
the Grammar of Dutch and English. Language, 61,
523-568.
Steedman, M. (1988) Combinators and Grammars. In
Oehrle,R., Bach, E. and Wheeler, D. (eds.) Cate go-
rial Grammars and Natural Language Structures,
Dordrecht, 1988.
Uszkoreit, H. (1987) Word Order and Constituent
Structure in German. Stanford, CSLI.
Wittenburg, K. (1987) Predictive Combinators : a
Method for Efficient Processing of Combinatory
Categorial Grammar. In Proceedings of the 25th
Annual Meeting of the Association for Computatio-
nal Linguistics, Stanford University, Stanford, Ca.,
6-9 July, 1987.
Zeevat, H. (1986) A Specification of InL. Internal
ACORD Report. Edinburgh, Centre for Cognitive
Science.
Zeevat, H. (1988) Combining Categorial Grammar
and Unification. In Reyle, U. and Rohrer, C. (eds.)
Natural Language Parsing and Linguistic Theo-
ries, 202-229. Dordrecht: D. Reidel.
Zeevat, H., Klein, E. and Calder, J. (1987) An Introduc-
tion to Unification Categorial Grammar. In Had-
dock, N. J., Klein, E. and Morrill, G. (eds.) Edin-
burgh Working Papers in Cognitive Science, Vo-
lume 1: Categorial Grammar, Unification Gram-
mar and Parsing
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.676435">
<title confidence="0.995215">EFFICIENT PARSING FOR FRENCH*</title>
<author confidence="0.998848">Claire Gardent</author>
<affiliation confidence="0.999447">University Blaise Pascal — Clermont II and University of Edinburgh, Centre for Cognitive Science,</affiliation>
<address confidence="0.773321">2 Buccleuch Place, Edinburgh EH89LW, SCOTLAND, UK</address>
<author confidence="0.775801">Gabriel G Bes</author>
<author confidence="0.775801">Pierre-Francois Ririe</author>
<author confidence="0.775801">Karine Baschung</author>
<affiliation confidence="0.999039">Universite Blaise Pascal — Clermont II, Formation Doctorale Linguistique et Informatique,</affiliation>
<address confidence="0.999916">34, Ave. Carnot, 63037 Clermont-Ferrand Cedex, FRANCE</address>
<abstract confidence="0.995137">Parsing with categorial grammars often leads to problems such as proliferating lexical ambiguity, spurious parses and overgeneration. This paper presents a parser for French developed on an unification based categorial grammar (FG) which avoids these problems. This parser is a bottom-up chart parser augmented with a heuristic eliminating spurious parses. The unicity and completeness of parsing are proved.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>a) If S[F+ik(A+ilF)] and S[(F+ikA)+ilF] are defined,</title>
<journal>then F+ik(A+,) (F+ikA)-f-iiF</journal>
<marker></marker>
<rawString>a) If S[F+ik(A+ilF)] and S[(F+ikA)+ilF] are defined, then F+ik(A+,) (F+ikA)-f-iiF</rawString>
</citation>
<citation valid="false">
<title>b) If S[A+ilF] and S[(F+ikA)+ilF] are defined, then S[F+ik(A+f)] is also defined.</title>
<marker></marker>
<rawString>b) If S[A+ilF] and S[(F+ikA)+ilF] are defined, then S[F+ik(A+f)] is also defined.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G G Bes</author>
<author>C Gardent</author>
</authors>
<title>French Order without Order.</title>
<date>1989</date>
<booktitle>the Proceedings of the Fourth European ACL Conference (UMIST,</booktitle>
<pages>249--255</pages>
<location>Manchester,</location>
<note>To appear in</note>
<contexts>
<context position="2581" citStr="Bes &amp; Gardent 1989" startWordPosition="379" endWordPosition="382">The work reported here was carried out in the ESPRIT Project 393 ACORD, «The Construction and Interrogation of Knowledge Bases using Natural Language Text and Graphics. In UCG and in CCG, the verb typically encodes the notion of a canonical ordering of the verb arguments. Word order variations are then handled by resorting to lexical ambiguity and jump rules&apos; (UCG) or to new combinators (CCG). As a result, the number of lexical and/or phrasal edges increases rapidly thus affecting parsing efficiency. Moreover, empirical evidence does not support the notion of a canonical order for French (cf. Bes &amp; Gardent 1989). In contrast, CUG, GPSG (Gazdar et al. 1985) and HPSG do not assume any canonical order and subcategorisation information is dissociated from surface word order. Constraints on word order are enforced by features and graph unification (CUG) or by Linear Precedence (LP) statements (HPSG, GPSG). The problems with CUG are that on the computational side, graph-unification is costly and less efficient in a Prolog environment than term unification while from the linguistic point of view (a) NP&apos;s must be assumed unambiguous with respect to case which is not true for - at least - French and (b) cliti</context>
</contexts>
<marker>Bes, Gardent, 1989</marker>
<rawString>Bes, G.G. and C. Gardent (1989) French Order without Order. To appear in the Proceedings of the Fourth European ACL Conference (UMIST, Manchester, 10-12 April 1989), 249-255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Calder</author>
</authors>
<title>PIMPLE ; A PROLOG Implementation of the PATR-II Linguistic Environment.</title>
<date>1987</date>
<institution>for Cognitive Science.</institution>
<location>Edinburgh, Centre</location>
<marker>Calder, 1987</marker>
<rawString>Calder, J. (1987) PIMPLE ; A PROLOG Implementation of the PATR-II Linguistic Environment. Edinburgh, Centre for Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>G Pullum</author>
<author>I Sag</author>
</authors>
<date>1985</date>
<booktitle>GeneralizedP lzrase Structure Grammar.</booktitle>
<publisher>Basil Blackwell.</publisher>
<location>London:</location>
<contexts>
<context position="2626" citStr="Gazdar et al. 1985" startWordPosition="387" endWordPosition="390"> ESPRIT Project 393 ACORD, «The Construction and Interrogation of Knowledge Bases using Natural Language Text and Graphics. In UCG and in CCG, the verb typically encodes the notion of a canonical ordering of the verb arguments. Word order variations are then handled by resorting to lexical ambiguity and jump rules&apos; (UCG) or to new combinators (CCG). As a result, the number of lexical and/or phrasal edges increases rapidly thus affecting parsing efficiency. Moreover, empirical evidence does not support the notion of a canonical order for French (cf. Bes &amp; Gardent 1989). In contrast, CUG, GPSG (Gazdar et al. 1985) and HPSG do not assume any canonical order and subcategorisation information is dissociated from surface word order. Constraints on word order are enforced by features and graph unification (CUG) or by Linear Precedence (LP) statements (HPSG, GPSG). The problems with CUG are that on the computational side, graph-unification is costly and less efficient in a Prolog environment than term unification while from the linguistic point of view (a) NP&apos;s must be assumed unambiguous with respect to case which is not true for - at least - French and (b) clitic doubling cannot be accounted for as a resul</context>
</contexts>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, G., Klein, E., Pullum, G., and Sag., I. (1985) GeneralizedP lzrase Structure Grammar. London: Basil Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kamp</author>
</authors>
<title>A Theory of Truth and Semantic Representation.</title>
<date>1981</date>
<booktitle>Formal Methods in the Study of Language, Volume 136,</booktitle>
<pages>277--322</pages>
<editor>In Groenendijk, J. A. G., Janssen, T. M. V. and Stokhof, M. B. J. (eds.)</editor>
<institution>Mathematical Centre Tracts.</institution>
<location>Amsterdam :</location>
<marker>Kamp, 1981</marker>
<rawString>Kamp, H. (1981) A Theory of Truth and Semantic Representation. In Groenendijk, J. A. G., Janssen, T. M. V. and Stokhof, M. B. J. (eds.) Formal Methods in the Study of Language, Volume 136, 277-322. Amsterdam : Mathematical Centre Tracts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L ICarttunen</author>
</authors>
<title>Radical Lexicalism. Report No. CSLI-86-68, Center for the Study of Language and Information,</title>
<date>1986</date>
<booktitle>Paper presented at the Conference on Alternative Conceptions of Phrase Structure,</booktitle>
<location>New York.</location>
<contexts>
<context position="11261" citStr="ICarttunen 1986" startWordPosition="1826" endWordPosition="1827"> a list, there is no constraint on the order in which each valency is consumed. This raises a problem with respect to parsing which is that for any triplet X,Y,Z where Y is a verb and X and Z are arguments to this verb, there will often be two possible derivations i.e., (XY)Z and X(YZ). The problem of spurious parses is a well-known one in extensions of pure categorial grammar. It derives either from using other rules or combinators for derivation than just functional application (Pareschi and Steedman 1987, Wittenburg 1987, Moortgat 1987, Morrill 1988) or from having unordered set valencies (ICarttunen 1986), the latter case being that of FG. Various solutions have been proposed in relation to this problem. Karttunen&apos;s solution is to check that for any potential edge, no equivalent analysis is already In (5) BE can be paraphrased as &amp;quot;There exists an event&amp;quot;. stored in the chart for the same string of words. However as explained above, two semantically equivalent formulae of InL&apos; need not be syntactically identical. Reducing two formulae to a normal form to check their equivalence or alternatively reducing one to the other might require 2n permutations with n the number of predicates occuring in th</context>
</contexts>
<marker>ICarttunen, 1986</marker>
<rawString>ICarttunen, L. (1986) Radical Lexicalism. Report No. CSLI-86-68, Center for the Study of Language and Information, Paper presented at the Conference on Alternative Conceptions of Phrase Structure, July 1986, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Morrill</author>
</authors>
<title>Extraction and Coordination in Phrase Structure Grammar and Cate gorial Grammar.</title>
<date>1988</date>
<tech>PhD Thesis,</tech>
<institution>Centre for Cognitive Science, University of Edinburgh.</institution>
<contexts>
<context position="11204" citStr="Morrill 1988" startWordPosition="1818" endWordPosition="1819">ion information is represented as a set rather than as a list, there is no constraint on the order in which each valency is consumed. This raises a problem with respect to parsing which is that for any triplet X,Y,Z where Y is a verb and X and Z are arguments to this verb, there will often be two possible derivations i.e., (XY)Z and X(YZ). The problem of spurious parses is a well-known one in extensions of pure categorial grammar. It derives either from using other rules or combinators for derivation than just functional application (Pareschi and Steedman 1987, Wittenburg 1987, Moortgat 1987, Morrill 1988) or from having unordered set valencies (ICarttunen 1986), the latter case being that of FG. Various solutions have been proposed in relation to this problem. Karttunen&apos;s solution is to check that for any potential edge, no equivalent analysis is already In (5) BE can be paraphrased as &amp;quot;There exists an event&amp;quot;. stored in the chart for the same string of words. However as explained above, two semantically equivalent formulae of InL&apos; need not be syntactically identical. Reducing two formulae to a normal form to check their equivalence or alternatively reducing one to the other might require 2n pe</context>
</contexts>
<marker>Morrill, 1988</marker>
<rawString>Morrill, G. (1988) Extraction and Coordination in Phrase Structure Grammar and Cate gorial Grammar. PhD Thesis, Centre for Cognitive Science, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Pareschi</author>
</authors>
<title>Combinatory Grammar, Logic Programming, and Natural Language.</title>
<date>1987</date>
<booktitle>Edinburgh Working Papers in Cognitive Science, Volume I; Categorial Grammar, Unification Grammar and Parsing.</booktitle>
<editor>In Haddock, N. J., Klein, E. and Morill, G. (eds.)</editor>
<contexts>
<context position="12114" citStr="Pareschi, 1987" startWordPosition="1964" endWordPosition="1965">xists an event&amp;quot;. stored in the chart for the same string of words. However as explained above, two semantically equivalent formulae of InL&apos; need not be syntactically identical. Reducing two formulae to a normal form to check their equivalence or alternatively reducing one to the other might require 2n permutations with n the number of predicates occuring in the formulae. Given that the test must occur each time that two edges stretch over the same region and given that it requires exponential time, this solution was disguarded as computationally inefficient. Pareschi&apos;s lazy parsing algorithm (Pareschi, 1987) has been shown (Hepple, 1987) to be incomplete. Wittenburg&apos;s predictive combinators avoid the parsing problem by advocating grammar compilation which is not our concern here. Morill&apos;s proposal of defining equivalence classes on derivations cannot be transposed to FG since the equivalence class that would be of relevance to our problem i.e., ((X,Z)Y, X(ZY)) is not an equivalence class due to our analysis of modifiers. Finally, Moortgat&apos;s solution is not possible since it relies on the fact that the grammar is structurally complete&apos; which FG is not. The solution we offer is to augment a shift-r</context>
</contexts>
<marker>Pareschi, 1987</marker>
<rawString>Pareschi, R. (1987) Combinatory Grammar, Logic Programming, and Natural Language. In Haddock, N. J., Klein, E. and Morill, G. (eds.) Edinburgh Working Papers in Cognitive Science, Volume I; Categorial Grammar, Unification Grammar and Parsing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Pareschi</author>
<author>M J Steedman</author>
</authors>
<title>A Lazy Way to Chart-Parse with Extended Categorial Grammars.</title>
<date>1987</date>
<booktitle>In Proceedings of the 25 th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>6--9</pages>
<location>Stanford University, Stanford, Ca.,</location>
<contexts>
<context position="11157" citStr="Pareschi and Steedman 1987" startWordPosition="1810" endWordPosition="1813">tically equivalent. 3. THE PARSER Because the subcategorisation information is represented as a set rather than as a list, there is no constraint on the order in which each valency is consumed. This raises a problem with respect to parsing which is that for any triplet X,Y,Z where Y is a verb and X and Z are arguments to this verb, there will often be two possible derivations i.e., (XY)Z and X(YZ). The problem of spurious parses is a well-known one in extensions of pure categorial grammar. It derives either from using other rules or combinators for derivation than just functional application (Pareschi and Steedman 1987, Wittenburg 1987, Moortgat 1987, Morrill 1988) or from having unordered set valencies (ICarttunen 1986), the latter case being that of FG. Various solutions have been proposed in relation to this problem. Karttunen&apos;s solution is to check that for any potential edge, no equivalent analysis is already In (5) BE can be paraphrased as &amp;quot;There exists an event&amp;quot;. stored in the chart for the same string of words. However as explained above, two semantically equivalent formulae of InL&apos; need not be syntactically identical. Reducing two formulae to a normal form to check their equivalence or alternativel</context>
</contexts>
<marker>Pareschi, Steedman, 1987</marker>
<rawString>Pareschi, R. and Steedman, M. J. (1987) A Lazy Way to Chart-Parse with Extended Categorial Grammars. In Proceedings of the 25 th Annual Meeting of the Association for Computational Linguistics, Stanford University, Stanford, Ca., 6-9 July, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Pollard</author>
</authors>
<title>Generalized Phrase Structure Grammars, Head Grammars, and Natural Languages. PhD Thesis,</title>
<date>1984</date>
<institution>Stanford University.</institution>
<marker>Pollard, 1984</marker>
<rawString>Pollard, C. J. (1984) Generalized Phrase Structure Grammars, Head Grammars, and Natural Languages. PhD Thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Pollard</author>
<author>I Sag</author>
</authors>
<title>Information-Based Approach to Syntax and Semantics : Volume 1 Fundamentals. Stanford, Ca. : Center for the Study of Language and Information.</title>
<date>1988</date>
<contexts>
<context position="1838" citStr="Pollard &amp; Sag 1988" startWordPosition="259" endWordPosition="262">n that the parsing strategy relies on properties of the grammar which are independently motivated by the linguistic data. Nevertheless, the knowledge embodied in the grammar is kept independent from the processing phase. 1. LINGUISTIC THEORIES AND WORD ORDER Word order remains a pervasive issue for most linguistic analyses. Among the theories most closely related to FG, Unification Categorial Grammar (UCG: Zeevat et al. 1987), Combinatory Categorial Grammar (CCG: Steedman 1985, Steedman 1988), Categorial Unification Grammar (CUG: Karttunen 1986) and Head-driven Phrase Structure Grammar (HPSG: Pollard &amp; Sag 1988) all present inconveniences in their way of dealing with word order as regards parsing efficiency and/or linguistic data. * The work reported here was carried out in the ESPRIT Project 393 ACORD, «The Construction and Interrogation of Knowledge Bases using Natural Language Text and Graphics. In UCG and in CCG, the verb typically encodes the notion of a canonical ordering of the verb arguments. Word order variations are then handled by resorting to lexical ambiguity and jump rules&apos; (UCG) or to new combinators (CCG). As a result, the number of lexical and/or phrasal edges increases rapidly thus </context>
</contexts>
<marker>Pollard, Sag, 1988</marker>
<rawString>Pollard, C. J. and Sag, I. (1988)An Information-Based Approach to Syntax and Semantics : Volume 1 Fundamentals. Stanford, Ca. : Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Steedman</author>
</authors>
<booktitle>M.(1985) Dependency and Coordination in the Grammar of Dutch and English. Language,</booktitle>
<volume>61</volume>
<pages>523--568</pages>
<marker>Steedman, </marker>
<rawString>Steedman, M.(1985) Dependency and Coordination in the Grammar of Dutch and English. Language, 61, 523-568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Combinators and Grammars.</title>
<date>1988</date>
<booktitle>Cate gorial Grammars and Natural Language Structures,</booktitle>
<editor>In Oehrle,R., Bach, E. and Wheeler, D. (eds.)</editor>
<location>Dordrecht,</location>
<contexts>
<context position="1716" citStr="Steedman 1988" startWordPosition="245" endWordPosition="246">ng spurious parses, i.e. parses with different derivation trees but equivalent semantics. The two goals are related in that the parsing strategy relies on properties of the grammar which are independently motivated by the linguistic data. Nevertheless, the knowledge embodied in the grammar is kept independent from the processing phase. 1. LINGUISTIC THEORIES AND WORD ORDER Word order remains a pervasive issue for most linguistic analyses. Among the theories most closely related to FG, Unification Categorial Grammar (UCG: Zeevat et al. 1987), Combinatory Categorial Grammar (CCG: Steedman 1985, Steedman 1988), Categorial Unification Grammar (CUG: Karttunen 1986) and Head-driven Phrase Structure Grammar (HPSG: Pollard &amp; Sag 1988) all present inconveniences in their way of dealing with word order as regards parsing efficiency and/or linguistic data. * The work reported here was carried out in the ESPRIT Project 393 ACORD, «The Construction and Interrogation of Knowledge Bases using Natural Language Text and Graphics. In UCG and in CCG, the verb typically encodes the notion of a canonical ordering of the verb arguments. Word order variations are then handled by resorting to lexical ambiguity and jump</context>
</contexts>
<marker>Steedman, 1988</marker>
<rawString>Steedman, M. (1988) Combinators and Grammars. In Oehrle,R., Bach, E. and Wheeler, D. (eds.) Cate gorial Grammars and Natural Language Structures, Dordrecht, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Uszkoreit</author>
</authors>
<title>Word Order and Constituent Structure in German.</title>
<date>1987</date>
<location>Stanford, CSLI.</location>
<contexts>
<context position="3370" citStr="Uszkoreit 1987" startWordPosition="513" endWordPosition="515"> on word order are enforced by features and graph unification (CUG) or by Linear Precedence (LP) statements (HPSG, GPSG). The problems with CUG are that on the computational side, graph-unification is costly and less efficient in a Prolog environment than term unification while from the linguistic point of view (a) NP&apos;s must be assumed unambiguous with respect to case which is not true for - at least - French and (b) clitic doubling cannot be accounted for as a result of using graph unification between the argument feature structure and the functor syntax value-set. In HPSG and GPSG (cf. also Uszkoreit 1987), the problem is that somehow, LP statements must be made to interact with the corresponding rule schemas. That is, either rule schemas and LP statements are precompiled before parsing and the number of rules increases rapidly or LP statements are checked on the fly during parsing thus slowing down processing. 2. THE GRAMMAR The formal characteristics of FG underlying the parsing heuristic are presented in §4. The characteristics of FG necessary to understand the grammar are resumed here (see (Bes &amp;Gardent 89) for a more detailed presentation). A jump rule of the fonn X/Y, YIZ —&gt;X/Z where X/Y </context>
</contexts>
<marker>Uszkoreit, 1987</marker>
<rawString>Uszkoreit, H. (1987) Word Order and Constituent Structure in German. Stanford, CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Wittenburg</author>
</authors>
<title>Predictive Combinators : a Method for Efficient Processing of Combinatory Categorial Grammar.</title>
<date>1987</date>
<booktitle>In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>6--9</pages>
<location>Stanford University, Stanford, Ca.,</location>
<contexts>
<context position="11174" citStr="Wittenburg 1987" startWordPosition="1814" endWordPosition="1815">ARSER Because the subcategorisation information is represented as a set rather than as a list, there is no constraint on the order in which each valency is consumed. This raises a problem with respect to parsing which is that for any triplet X,Y,Z where Y is a verb and X and Z are arguments to this verb, there will often be two possible derivations i.e., (XY)Z and X(YZ). The problem of spurious parses is a well-known one in extensions of pure categorial grammar. It derives either from using other rules or combinators for derivation than just functional application (Pareschi and Steedman 1987, Wittenburg 1987, Moortgat 1987, Morrill 1988) or from having unordered set valencies (ICarttunen 1986), the latter case being that of FG. Various solutions have been proposed in relation to this problem. Karttunen&apos;s solution is to check that for any potential edge, no equivalent analysis is already In (5) BE can be paraphrased as &amp;quot;There exists an event&amp;quot;. stored in the chart for the same string of words. However as explained above, two semantically equivalent formulae of InL&apos; need not be syntactically identical. Reducing two formulae to a normal form to check their equivalence or alternatively reducing one to</context>
</contexts>
<marker>Wittenburg, 1987</marker>
<rawString>Wittenburg, K. (1987) Predictive Combinators : a Method for Efficient Processing of Combinatory Categorial Grammar. In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics, Stanford University, Stanford, Ca., 6-9 July, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zeevat</author>
</authors>
<title>A Specification of InL. Internal</title>
<date>1986</date>
<tech>ACORD Report. Edinburgh,</tech>
<institution>Centre for Cognitive Science.</institution>
<marker>Zeevat, 1986</marker>
<rawString>Zeevat, H. (1986) A Specification of InL. Internal ACORD Report. Edinburgh, Centre for Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zeevat</author>
</authors>
<title>Combining Categorial Grammar and Unification.</title>
<date>1988</date>
<booktitle>Natural Language Parsing and Linguistic Theories,</booktitle>
<pages>202--229</pages>
<editor>In Reyle, U. and Rohrer, C. (eds.)</editor>
<location>Dordrecht:</location>
<marker>Zeevat, 1988</marker>
<rawString>Zeevat, H. (1988) Combining Categorial Grammar and Unification. In Reyle, U. and Rohrer, C. (eds.) Natural Language Parsing and Linguistic Theories, 202-229. Dordrecht: D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zeevat</author>
<author>E Klein</author>
<author>J Calder</author>
</authors>
<title>An Introduction to Unification Categorial Grammar.</title>
<date>1987</date>
<booktitle>Edinburgh Working Papers in Cognitive Science, Volume 1: Categorial Grammar, Unification Grammar and Parsing</booktitle>
<editor>In Haddock, N. J., Klein, E. and Morrill, G. (eds.)</editor>
<contexts>
<context position="1648" citStr="Zeevat et al. 1987" startWordPosition="235" endWordPosition="238">y lexical ambiguities. Second, to enhance parsing efficiency by eliminating spurious parses, i.e. parses with different derivation trees but equivalent semantics. The two goals are related in that the parsing strategy relies on properties of the grammar which are independently motivated by the linguistic data. Nevertheless, the knowledge embodied in the grammar is kept independent from the processing phase. 1. LINGUISTIC THEORIES AND WORD ORDER Word order remains a pervasive issue for most linguistic analyses. Among the theories most closely related to FG, Unification Categorial Grammar (UCG: Zeevat et al. 1987), Combinatory Categorial Grammar (CCG: Steedman 1985, Steedman 1988), Categorial Unification Grammar (CUG: Karttunen 1986) and Head-driven Phrase Structure Grammar (HPSG: Pollard &amp; Sag 1988) all present inconveniences in their way of dealing with word order as regards parsing efficiency and/or linguistic data. * The work reported here was carried out in the ESPRIT Project 393 ACORD, «The Construction and Interrogation of Knowledge Bases using Natural Language Text and Graphics. In UCG and in CCG, the verb typically encodes the notion of a canonical ordering of the verb arguments. Word order va</context>
</contexts>
<marker>Zeevat, Klein, Calder, 1987</marker>
<rawString>Zeevat, H., Klein, E. and Calder, J. (1987) An Introduction to Unification Categorial Grammar. In Haddock, N. J., Klein, E. and Morrill, G. (eds.) Edinburgh Working Papers in Cognitive Science, Volume 1: Categorial Grammar, Unification Grammar and Parsing</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>