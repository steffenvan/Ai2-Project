<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.995754">
Efficient Construction of Underspecified Semantics under
Massive Ambiguity
</title>
<author confidence="0.981123">
Jochen Dorre*
</author>
<affiliation confidence="0.9757875">
Institut fiir maschinelle Sprachverarbeitung
University of Stuttgart
</affiliation>
<sectionHeader confidence="0.989227" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998468">
We investigate the problem of determin-
ing a compact underspecified semantical
representation for sentences that may be
highly ambiguous. Due to combinatorial
explosion, the naive method of building se-
mantics for the different syntactic readings
independently is prohibitive. We present
a method that takes as input a syntac-
tic parse forest with associated constraint-
based semantic construction rules and di-
rectly builds a packed semantic structure.
The algorithm is fully implemented and
runs in 0(n4log(n)) in sentence length, if
the grammar meets some reasonable &apos;nor-
mality&apos; restrictions.
</bodyText>
<sectionHeader confidence="0.993455" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.98926430882353">
One of the most central problems that any NL sys-
tem must face is the ubiquitous phenomenon of am-
biguity. In the last few years a whole new branch de-
veloped in semantics that investigates underspecified
semantic representations in order to cope with this
phenomenon. Such representations do not stand for
the real or intended meaning of sentences, but rather
for the possible options of interpretation. Quanti-
fier scope ambiguities are a semantic variety of am-
biguity that is handled especially well by this ap-
proach. Pioneering work in that direction has been
(Alshawi 92) and (Reyle 93).
More recently there has been growing interest in
developing the underspecification approach to also
cover syntactic ambiguities (cf. (Pinlcal 95; EggLe-
beth 95; Schiehlen 96)). Schiehlen&apos;s approach is out-
standing in that he fully takes into account syntactic
*This research has been carried out while the au-
thor visited the Programming Systems Lab of Prof.
Gert Smolka at the University of Saarland, Saarbriicken.
Thanks to John Maxwell, Martin Muller, Joachim
Niehren, Michael Schiehlen, and an anonymous reviewer
for valuable feedback and to all at PS Lab for their help-
ful support with the OZ system.
constraints. In (Schiehlen 96) he presents an algo-
rithm which directly constructs a single underspec-
ified semantic structure from the ideal &amp;quot;underspeci-
fied&amp;quot; syntactic structure, a parse forest.
On the other hand, a method for producing
&amp;quot;packed semantic structures&amp;quot;, in that case &amp;quot;packed
quasi-logical forms&amp;quot;, has already been used in the
Core Language Engine, informally described in (Al-
shawl 92, Chap. 7). However, this method only pro-
duces a structure that is virtually isomorphic to
the parse forest, since it simply replaces parse for-
est nodes by their corresponding semantic oper-
ators. No attempt is made to actually apply se-
mantic operators in the phase where those &amp;quot;packed
QLFs&amp;quot; are constructed. Moreover, the packing of
the QLFs seems to serve no purpose in the process-
ing phases following semantic analysis. Already the
immediately succeeding phase &amp;quot;sortal filtering&amp;quot; re-
quires QLFs to be unpacked, i.e. enumerated.
Contrary to the CLE method, Schiehlen&apos;s method
actively packs semantic structures, even when they
result from distinct syntactic structures, extracting
common parts. His method, however, may take time
exponential w.r.t. sentence length. Already the se-
mantic representations it produces can be exponen-
tially large, because they grow linear with the num-
ber of (syntactic) readings and that can be exponen-
tial, e.g., for sentences that exhibit the well-known
attachment ambiguity of prepositional phrases. It is
therefore an interesting question to ask, whether we
can compute compact semantic representations from
parse forests without falling prey to exponential ex-
plosion.
The purpose of the present paper is to show that
construction of compact semantic representations
like in Schiehlen&apos;s approach from parse forests is not
only possible, but also cheap, i.e., can be done in
polynomial time.
To illustrate our method we use a simple DCG
grammar for PP-attachment ambiguities, adapted
from (Schiehlen 96), that yields semantic represen-
tations (called UDRSs) according to the Underspec-
ified Discourse Representation Theory (Reyle 93;
KampReyle 93). The grammar is shown in Fig. 1.
</bodyText>
<page confidence="0.978356">
386
</page>
<equation confidence="0.99325028">
start(DRS) --&gt; s( [_,_, ltop] , [] , DRS) . vt([Ev,X,Y,L,_DomL],DRS_i,DRS) [saw],
(DRS.[L:see(Ev,X,Y)IDRS_i]).
s([Event,VerbL,DomL],DRS_i,DRS_0) --&gt;
np([X,VerbL,DomL],DRS_i,DRS1), det([X,Lab,VerbL,_],DRS_i,DRS)
vp([Event,X,VerbL,DomL],DRS1,DRS_o). [a],
(DRS.11t(Lab,ltop),1t(VerbL,Lab),
s([Event,VerbL,DomL],DRS_i,DRS_0) --&gt; Lab:XIDRS_i),
s([Event,VerbL,Dom1.],DRS_LDRS1), gensym(1,Lab),gensym(x,X)).
pp([Event,VerbL,DomLI,DRS1,DRS_o).
det([X,ResL,VbL,DomL],DRS_i,DRS) --&gt;
vp([Ev,X,VerbL,DomL],DRS_i,DRS_0) --&gt; [every],
vt([Ev,X,Y,VerbL,DomL],DRS_i,DRS1), [DRS.[1t(L,DomL),1t(VbL,ScpL),ResL:X,
np([Y,VerbL,DomL],DRS1,DRS_o). L:every(ResL,ScpL)IDRS_il,
gensym(1,L),gensym(1,ResL),
np([X,VbL,DomL],DRS_i,DRS_o) --&gt; gensym(1,ScpL),gensym(x,X)).
det([X,Nol....L,VhL,DomL],DRS_i,DRS1),
n([X,NounL,DomL],DRS1,DRS_o). np([X,_,_],DRS_i,DRS) --&gt; [i],
[DRS=[1top:X,anchor(X,speaker)IDRS_i],
n([X,NounL,DomL],DRS_i,DRS_o) --&gt; gensym(x,X)).
n([X,NounL,DomL],DRS_i,DRS1),
pp([X,NounL,DomL],DRS1,DRS_o). n([X,L,_],DRS,[1,:man(X)IDRS]) --&gt; [man].
n([X,L,_],DRS,[L:hill(X)IDRS]) --&gt; [hill].
pp([X,L,DomL],DRS_i,DRS_o) --&gt;
prep(Cond,X,Y), prep(on(X,Y),X,Y) --&gt; [on].
npf[Y,L,DomL],[L:CondIDRS_i],DRS_o). prep(with(X,Y),X,Y) --&gt; [with].
</equation>
<figureCaption confidence="0.999041">
Figure 1: Example DCG
</figureCaption>
<bodyText confidence="0.926743166666667">
The UDRSs constructed by the grammar are flat
lists of the UDRS-constraints 1 &lt; (subordination
(partial) ordering between labels; Prolog represen-
tation: lt (/ , /&apos;)), 1 : Cond (condition introduction
in subUDRS labeled 1), 1 : X (referent introduc-
tion in 1), 1 : GenQuant(1&apos;,1&amp;quot;) (generalised quan-
tifier) and an anchoring function. The meaning of a
UDRS as a set of denoted DRSs can be explained
as follows.1 All conditions with the same label form
a subUDRS and labels occurring in subUDRSs de-
note locations (holes) where other subUDRSs can
be plugged into. The whole UDRS denotes the set
of well-formed DRSs that can be formed by some
plugging of the subUDRSs that does not violate the
ordering ‹. Scope of quantifiers can be underspec-
ified in UDRSs, because subordination can be left
partial.
In our example grammar every nonterminal has
three arguments. The 2nd and the 3rd argument rep-
resent a UDRS list as a difference list, i.e., the UDRS
is &amp;quot;threaded through&amp;quot;. The first argument is a list of
objects occurring in the UDRS that play a specific
role in syntactic combinations of the current node.2
An example of a UDRS, however a packed UDRS, is
shown later on in §5.
To avoid the dependence on a particular grammar
formalism we present our method for a constraint-
based grammar abstractly from the actual constraint
&apos;Readers unfamiliar with DRT should think of these
structures as some Prolog terms, representing semantics,
built by unifications according to the semantic rules. It is
only important to notice how we extract common parts
of those structures, irrespective of the structures&apos; mean-
ings.
2E.g., for an NP its referent, as well as the upper and
lower label for the current clause and the top label.
</bodyText>
<construct confidence="0.794279285714286">
system employed. We only require that semantic
rules relate the semantic &apos;objects&apos; or structures that
are associated with the nodes of a local tree by em-
ploying constraints. E.g., we can view the DCG rule
s --+ np vp as a relation between three &apos;seman-
tic construction terms&apos; or variables SemS , SemNP,
SemVP equivalent to the constraints
</construct>
<equation confidence="0.999573666666667">
SemS = (CEvent,VerbL,DomL,TopLLDRS_i,DRS_o]
SemNP = [(X,VerbL,DomL,Toplj,DRS_i,DRS1]
SemVP = [EEvent,X,VerbL,DomL,TopLLDRS1,DRS_o]
</equation>
<bodyText confidence="0.989892857142857">
Here is an overview of the paper. §2 gives the pre-
liminaries and assumptions needed to precisely state
the problem we want to solve. §3 presents the ab-
stract algorithm. Complexity considerations follow
in §4. Finally, we consider implementation issues,
present results of an experiment in §5, and close with
a discussion.
</bodyText>
<sectionHeader confidence="0.958816" genericHeader="introduction">
2 The Problem
</sectionHeader>
<bodyText confidence="0.998538705882353">
As mentioned already, we aim at calculating from
given parse forests the same compact semantic struc-
tures that have been proposed by (Schiehlen 96),
i.e. structures that make explicit the common parts
of different syntactic readings, so that subsequent
semantic processes can use this generalised infor-
mation. As he does, we assume a constraint-based
grammar, e.g. a DCG (PereiraWarren 80) or HPSG
(PollardSag 94) , in which syntactic constraints and
constraints that determine a resulting semantic rep-
resentation can be seperated and parsing can be per-
formed using the syntactic constraints only.
Second, we assume that the set of syntax trees
can be compactly represented as a parse forest
(cf. (Earley 70; BillotLang 89; Tomita 86)). Parse
forests are rooted labeled directed acyclic graphs
with AND-nodes (standing for context-free branch-
</bodyText>
<page confidence="0.96275">
387
</page>
<figure confidence="0.995507142857143">
np
23 24
saw
25 26 27
a man on
28 29 30 31 32
the hill with the tele
</figure>
<figureCaption confidence="0.999986">
Figure 2: Example of a parse forest
</figureCaption>
<bodyText confidence="0.999861333333333">
ing) and OR-nodes (standing for alternative sub-
trees), that can be characterised as follows (cf. Fig. 2
for an example) .3
</bodyText>
<listItem confidence="0.78702825">
1. The terminal yield as well as the label of two
AND-nodes are identical, if and only if they
both are children of one OR-node.
2. Every tree reading is a valid parse tree.
</listItem>
<bodyText confidence="0.997557333333333">
Tree readings of such graphs are obtained by replac-
ing any OR-node by one of its children. Parse forests
can represent an exponential number of phrase
structure alternatives in o(n3) space, where n is the
length of the sentence. The example uses the 3 OR-
nodes (A, B, C) and the AND-nodes 1 through 32
to represent 5 complete parse trees, that would use
5 x 19 nodes.
Third, we assume the rule-to-rule hypothesis, i.e.,
</bodyText>
<footnote confidence="0.5848985">
3The graphical representation of an OR-node is a box
surrounding its children, i.e. the AND-OR-graph struc-
</footnote>
<bodyText confidence="0.9456744">
ture of
that the grammar associates with each local tree a
&apos;semantic rule&apos; that specifies how to construct the
mother node&apos;s semantics from those of its children.
Hence, input to the algorithm is
</bodyText>
<listItem confidence="0.9980628">
• a parse forest
• an associated semantic rule for every local tree
(AND-node together with its children) therein
• and a semantic representation for each leaf
(coming from a semantic lexicon).
</listItem>
<bodyText confidence="0.999910909090909">
To be more precise, we assume a constraint lan-
guage C over a denumerable set of variables X,
that is a sublanguage of Predicate Logic with equal-
ity and is closed under conjunction, disjunction,
and variable renaming. Small greek letters 0, will
henceforth denote constraints (open formulae) and
letters X, Y, Z (possibly with indeces) will denote
variables. Writing 0(Xi, , Xk) shall indicate that
X1,... , Xk are the free variables in the constraint p5.
Frequently used examples for constraint languages
are the language of equations over first-order terms
</bodyText>
<page confidence="0.958956">
is
388
</page>
<bodyText confidence="0.999959692307692">
for DCGs,4 PATR-style feature-path equations, or
typed feature structure description languages (like
the constraint languages of ALE (Carpenter 92) or
CUF (DorreDorna 93)) for HPSG-style grammars.
Together with the constraint language we require
a constraint solver, that checks constraints for satis-
fiability, usually by transforming them into a normal
form (also called &apos;solved form&apos;). Constraint solving
in the DCG case is simply unification of terms.
The semantic representations mentioned before
are actually not given directly, but rather as a con-
straint on some variable, thus allowing for partiality
in the struct7.1ral description. To that end we assume
that every node in the parse forest ii has associated
with it a variable X1, that is used for constraining the
(partial) semantic structure of v. The semantics of
a leaf node p is hence given as a constraint OA (Xj.,
called a leaf constraint.
A final assumption that we adopt concerns the na-
ture of the &apos;semantic rules&apos;. The process of semantics
construction shall be a completely monotonous pro-
cess of gathering constraints that never leads to fail-
ure. We assume that any associated (instantiated)
semantic rule r(v) of a local tree (AND-branching)
uk) determines v&apos;s semantics E(v) as fol-
lows from those of its children:
</bodyText>
<equation confidence="0.772843">
E(v) = 3X„, 3X (X„, X„„ ,X,,j A
</equation>
<bodyText confidence="0.998044681818182">
The constraint Or(„)(X,,, X„„ , X„k ) is called the
rule constraint for v. It is required to only depend
on the variables X,,, X„,, , X. Note that if the
same rule is to be applied at another node, we have
a different rule constraint.
Note that any E(v) depends only on X,, and can
be thought of as a unary predicate. Now, let us con-
sider semantics construction for a single parse tree
for the moment. The leaf constraints together with
the rules define a semantics constraint E(v) for ev-
ery node v, and the semantics of the full sentence
is described by the E-constraint of the root node,
E(root). In the E-constraints, we actually can sup-
press the existential quantifiers by adopting the con-
vention that any variable other than the one of the
current node is implicitly existentially bound on the
formula toplevel. Name conflicts, that would force
variable renaming, cannot occur. Therefore E(root)
is (equivalent to) just a big conjunction of all rule
constraints for the inner nodes and all leaf con-
straints.
Moving to parse forests, the semantics of an OR-
</bodyText>
<equation confidence="0.830607666666667">
node v(vi, , uk) is to be defined as
E(v) = 3X„, 3X„,,(E(vi) A X,,=X,,, V...
V E(i/k) A Xv=Xvk ),
</equation>
<bodyText confidence="0.867852416666667">
4DCG shall refer in this paper to a logically pure ver-
sion, Definite Clause Grammars based on pure PROLOG,
involving no nonlogical devices like Cut, var/l, etc.
specifying that the set of possible (partial) semantic
representations for v is the union of those of v&apos;s chil-
dren. However, we can simplify this formula once and
for all by assuming that for every OR-node there is
only one variable X, that is associated with it and all
of its children. Using the same variable for vi vk
is unproblematic, because no two of these nodes can
ever occur in a tree reading. Hence, the definition we
get is
</bodyText>
<equation confidence="0.749998">
E(v) = E(vi) V ... V E(vk).
</equation>
<bodyText confidence="0.999984081081081">
Now, in the same way as in the single-tree case, we
can directly &amp;quot;read off&amp;quot; the E-constraint for the whole
parse forest representing the semantics of all read-
ings. Although this constraint is only half the way
to the packed semantic representation we are aim-
ing at, it is nevertheless worthwhile to consider its
structure a little more closely. Fig. 3 shows the struc-
ture of the E-constraint for the OR-node B in the
example parse forest.
In a way the structure of this constraint directly
mirrors the structure of the parse forest. However,
by writing out the constraint, we loose the sharings
present in the forest. A subformula coming from a
shared subtree (as E(18) in Fig. 3) has to be stated
as many times as the subtree appears in an unfolding
of the forest graph. In our PP-attachment example
the blowup caused by this is in fact exponential.
On the other hand, looking at a E-constraint as a
piece of syntax, we can represent this piece of syntax
in the same manner in which trees are represented in
the parse forest, i.e. we can have a representation of
E(root) with a structure isomorphic to the forest&apos;s
graph structure.5 In practice this difference becomes
a question of whether we have full control over the
representations the constraint solver employs (or any
other process that receives this constraint as input).
If not, we cannot contend ourselves with the possi-
bility of compact representation of constraints, but
rather need a means to enforce this compactness on
the constraint level. This means that we have to in-
troduce some form of functional abstraction into the
constraint language (or anything equivalent that al-
lows giving names to complex constraints and refer-
encing to them via their names). Therefore we en-
hance the constraint language as follows. We allow
to our disposition a second set of variables, called
names, and two special forms of constraints
</bodyText>
<listItem confidence="0.753168">
1. def (&lt;name&gt;, &lt;constraint&gt;)
name definition
2. &lt;name&gt; name use
with the requirements, that a name may only be
used, if it is defined and that its definition is unique.
Thus, the constraint E(B) above can be written as
(Or(S) A ... A 026 A N
V 0,(7) A ... A 4)26 A N)
</listItem>
<bodyText confidence="0.519402">
A def (N, 0,(18) A 027 A 0r(21) A 028 A 029)
</bodyText>
<footnote confidence="0.9829445">
5The packed QLFs in the Core Language Engine (Al-
shawl 92) are an example of such a representation.
</footnote>
<page confidence="0.97582">
389
</page>
<equation confidence="0.994970142857143">
Or(6) A 023 A d9r(1O) A 024 A 07.(12) A 025 A Or(15) A 026 A 0r(18) A 627 A 0r(21) A 028 A 029
E(18)
E(6)
V
Or(7) A 0r(14) A 023 A Or(17) A (i)24 A 0r(20) A 025 A 026 A 07.(18) A d)27 A 6r(21) A 4)28 A (t)29
E(l8)
E(7)
</equation>
<figureCaption confidence="0.988091">
Figure 3: Constraint E(B) of example parse forest
</figureCaption>
<bodyText confidence="0.999340689189189">
The packed semantic representation as con-
structed by the method described so far still calls
for an obvious improvement. Very often the dif-
ferent branches of disjunctions contain constraints
that have large parts in common. However, although
these overlaps are efficiently handled on the rep-
resentational level, they are invisible at the logical
level. Hence, what we need is an algorithm that fac-
tores out common parts of the constraints on the
logical level, pushing disjunctions down.&apos; There are
two routes that we can take to do this efficiently.
In the first we consider only the structure of the
parse forest, however ignore the content of (rule or
leaf) constraints. I.e. we explore the fact that the
parts of the E-constraints in a disjunction that stem
from nodes shared by all disjuncts must be identical,
and hence can be factored out.&apos; More precisely, we
can compute for every node v the set must-occur(v)
of nodes (transitively) dominated by v that must oc-
cur in a tree of the forest, whenever v occurs. We can
then use this information, when building the disjunc-
tion E(v) to factor out the constraints introduced
by nodes in must-occur(v), i.e., we build the fac-
tor =A,,,Emust-oc cur( v) E (vi) and a &apos;remainder&apos;
constraint E(vi)VI, for each disjunct.
The other route goes one step further and takes
into account the content of rule and leaf constraints.
For it we need an operation generalise that can be
characterised informally as follows.
For two satisfiable constraints 0 and 0,
genera1ise(0, 7,G) yields the triple
such that e contains the common part&apos; of
0 and f and 0&apos; represents the &apos;remainder&apos;
0\e and likewise 14,1 represents W\e.
&apos;Actually, in the E(B) example such a factoring
makes the use of the name N superfluous. In general,
however, use of names is actually necessary to avoid ex-
ponentially large constraints. Subtrees may be shared
by quite different parts of the structure, not only by dis-
juncts of the same disjunction. In the PP-attachment ex-
ample, a compression of the E-constraint to polynomial
size cannot be achieved with factoring alone.
7(Maxwell IIIKaplan 93) exploit the same idea for
efficiently solving the functional constraints that an LFG
grammar associates with a parse forest.
The exact definition of what the &apos;common part&apos; or
the &apos;remainder&apos; shall be, naturally depends on the
actual constraint system chosen. For our purpose it
is sufficient to require the following properties:
If generalise(0. W) (e, , V), then d 1-
e and th I-e and t eAo, and w
We shall call such a generalisation operation sim-
plifying if the normal form of e is not larger than
any of the input constraints&apos; normal form.
Example: An example for such a generalisa-
tion operation for PROLOG&apos;s constraint system
(equations over first-order terms) is the so-called
anti-unify operation, the dual of unification, that
some PROLOG implementations provide as a library
predicate.&apos; Two terms Ti and T2 &apos;anti-unify&apos; to T,
if T is the (unique) most specific term that sub-
sumes both Ti and T2. The &apos;remainder constraints&apos;
in this case are the residual substitutions al and o-2
that transform T into Ti or T2, respectively.
Let us now state the method informally. We use
generalise to factor out the common parts of dis-
junctions. This is, however, not as trivial as it might
appear at first sight. Generalise should operate
on solved forms, but when we try to eliminate the
names introduced for subtree constraints in order
to solve the corresponding constraints, we end up
with constraints that are exponential in size. In the
following section we describe an algorithm that cir-
cumvents this problem.
</bodyText>
<sectionHeader confidence="0.993509" genericHeader="method">
3 The Algorithm
</sectionHeader>
<bodyText confidence="0.9970745">
We call an order &lt; on the nodes of a directed
acyclic graph G --= (N, E) with nodes N and edges E
bottom-up, if whenever (i, j) E E (&amp;quot;i is a predecessor
to j&amp;quot;), then j &lt; i.
For the sake of simplicity let us assume that
any nonterminal node in the parse forest is binary
branching. Furthermore, we leave implicit, when
conjunctions of constraints are normalised by the
constraint solver. Recall that for the generalisation
operation it is usually meaningful to operate on
</bodyText>
<footnote confidence="0.7820655">
antLunify in Quintus Prolog , term_subsumer in
Sicstus Prolog.
</footnote>
<page confidence="0.996755">
390
</page>
<bodyText confidence="0.907235">
Input: • parse forest, leaf and rule constraints as described above
</bodyText>
<listItem confidence="0.984693666666667">
• array of variables X,, indexed by node s.t. if v is a child of OR-node v 1, then X, =
Data structures: • an array SEM of constraints and an array D of names, both indexed by node
• a stack ENV of def constraints
</listItem>
<bodyText confidence="0.428941">
Output: a constraint representing a packed semantic representation
</bodyText>
<equation confidence="0.7958783">
Method: ENV := nil
process nodes in a bottom-up order
doing with node v:
if v is a leaf then
SEM[v] :=
D[v] := true
elseif v is AND(vi, v2) then
SEM[v] := (/),(„) A SEM[vi] A SEM[v2]
if D[vi] = true then D[v] := D[v2]
elseif D[v2] = true then Did := D[14]
else D[v] := newname
push def(Divb D[vi] A D[v2]) onto ENV
end
elseif v is OR(vi , v2) then
let GEN, REM1, REM2 such that
generalise(SEM[vd, SEM[v2]) (GEN, REM1, REM2)
SEM[v] := GEN
D[v] := newname
push def(D[v], REM1 A D[v1] V REM2 A D[v2]) onto ENV
end return SEM[root] A D[root] A ENV
</equation>
<figureCaption confidence="0.998019">
Figure 4: Packed Semantics Construction Algorithm
</figureCaption>
<bodyText confidence="0.9909238">
solved forms. However, at least the simplifications
true A (/) and A true should be assumed.
The Packed Semantics Construction Algorithm is
given in Fig. 4. It enforces the following invariants,
which can easily be shown by induction.
</bodyText>
<listItem confidence="0.967422777777778">
1. Every name used has a unique definition.
2. For any node v we have the equivalence E(v) E-_--
SEM[v] A [D[u]J, where ID[v]]] shall denote the
constraint obtained from D[v] when recursively
replacing names by the constraints they are
bound to in ENV.
3. For any node v the constraint SEM[v] is never
larger than the E-constraint of any single tree
in the forest originating in v.
</listItem>
<bodyText confidence="0.9382475">
Hence, the returned constraint correctly represents
the semantic representation for all readings.
</bodyText>
<sectionHeader confidence="0.993251" genericHeader="method">
4 Complexity
</sectionHeader>
<bodyText confidence="0.999832818181818">
The complexity of this abstract algorithm depends
primarily on the actual constraint system and gen-
eralisation operation employed. But note also that
the influence of the actual semantic operations pre-
scribed by the grammar can be vast, even for the
simplest constraint systems. E.g., we can write a
DCGs that produce abnormal large &amp;quot;semantic struc-
tures&amp;quot; of sizes growing exponentially with sentence
length (for a single reading). For meaningful gram-
mars we expect this size function to be linear. There-
fore, let us abstract away this size by employing
a function fG(n) that bounds the size of semantic
structures (respectively the size of its describing con-
straint system in normal form) that grammar G as-
signs to sentences of length n.
Finally, we want to assume that generalisation is
simplifying and can be performed within a bound of
g(m) steps, where m is the total size of the input
constraint systems.
With these assumptions in place, the time com-
plexity for the algorithm can be estimated to be (n
= sentence length, N = number of forest nodes)
</bodyText>
<equation confidence="0.940023">
0(g(fG(n)) • N) &lt; 0(9(fG(n)) • n3),
</equation>
<bodyText confidence="0.997659461538462">
since every program step other than the generali-
sation operation can be done in constant time per
node. Observe that because of Invariant 3. the input
constraints to generalise are bounded by fG as any
constraint in SEM.
In the case of a DCG the generalisation oper-
ation is anti_unif y, which can be performed in
o(n • log(n)) time and space (for acyclic struc-
tures). Hence, together with the assumption that
the semantic structures the DCG computes can
be bounded linearly in sentence length (and are
acyclic), we obtain a 0(n • log(n)• N) &lt; 0(n4log(n))
total time complexity.
</bodyText>
<page confidence="0.973599">
391
</page>
<bodyText confidence="0.552167">
SEM[top]:
</bodyText>
<equation confidence="0.947991363636364">
(1top xl,
anchor(xl,&apos;Speaker&apos;),
11 : see(el,x1,x2),
lt(12,1top),
lt(11,12),
12 : x2,
12 : man(x2),
A : on(B,x3),
1t(13,1top),
lt(A,15),
14 : x3,
13 : every(14,15),
14 : hill(x3),
C : with(D,x4),
lt(16,1top),
lt(C,16),
16 : x4,
16 : tele(x4)]
D[top] (a Prolog goal):
dEnv(509,1,[12.,A,D,C1))
ENV (as Prolog predicates):
dEnv(506, 1, A) :-
</equation>
<table confidence="0.7449831875">
( A=tel,11]
; A=[x2,12]
dEnv(339, 1, A) :-
( A=(C,B,C,S)
; A=(x3,14,_,_)
).
dEnv(509, 2, A) :-
( A=(e1,11,x3,14)
A=.(x2,12,C,B],
dEnv(339, 1, (C,E,x2,12])
&gt;.
dEnv(509, 1, A) :-
( A.-(G,F,e1,11),
dEnv(506, 1, (G,F])
A.[E,D,C,B],
dEnv(509, 2, [E,D,C,B])
</table>
<figureCaption confidence="0.993784">
Figure 5: Packed UDRS: conjunctive part (left column) and disjunctive binding environment
</figureCaption>
<sectionHeader confidence="0.9996755" genericHeader="method">
5 Implementation and Experimental
Results
</sectionHeader>
<bodyText confidence="0.96960485">
The algorithm has been implemented for the PRO-
LOG (or DCG) constraint system, i.e., constraints
are equations over first-order terms. Two implemen-
tations have been done. One in the concurrent con-
straint language OZ (SmolkaTreinen 96) and one in
Sicstus Prolog.&apos; The following results relate to the
Prolog implementation.&apos;
Fig. 5 shows the resulting packed UDRS for the
example forest in Fig. 2. Fig. 6 displays the SEM
part as a graph. The disjunctive binding environ-
ment only encodes what the variable referents B and
D (in conjunction with the corresponding labels A
and C) may be bound to to: one of el, x2, or x3 (and
likewise the corresponding label). Executing the goal
dEnv (509 , 1 , [B , A ,D ,C] ) yields the five solutions:
A = 11, B = el, C = 11, D = el ? ;
A = 12, B = x2, C = 11, D = el ? ;
A = B = el, C = 14, D = x3 ? ;
A = B = x2, C = 12, D = x2 ? ;
A = 12, B = x2, C = 14, D = x3 ? ;
</bodyText>
<equation confidence="0.6606585">
no
I ?-
</equation>
<bodyText confidence="0.989135333333333">
Table 1 gives execution times used for semantics
construction of sentences of the form I saw a man
(on a hill) for different n. The machine used for
9The OZ implementation has the advantage that fea-
ture structure constraint solving is built-in. Our imple-
mentation actually represents the DCG terms as a fea-
ture structures. Unfortunately it is an order of magni-
tude slower than the Prolog version. The reason for this
presumably lies in the fact that meta-logical operations
the algorithm needs, like generalise and copy_term
have been modeled in OZ and not on the logical level
were they properly belong, namely the constraint solver.
</bodyText>
<footnote confidence="0.5519295">
19This implementation is available from
http://www.ims.uni-stuttgart.derjochen/CBSem.
</footnote>
<table confidence="0.861806933333333">
hop
anchor(xl,&apos;Speaker&apos;)
12 13
x2 14 15 x4
man(x2) x3 tele(x4)
hill(x3)
n Readings AND- + OR-nodes Time
2 5 35 4 msec
4 42 91 16 msec
6 429 183 48 msec
8 4862 319 114 msec
10 58786 507 220 msec
12 742900 755 430 msec
14 9694845 1071 730 msec
16 129 Mio. 1463 1140 msec
</table>
<tableCaption confidence="0.999867">
Table 1: Execution times
</tableCaption>
<bodyText confidence="0.999001">
the experiment was a Sun Ultra-2 (168MHz), run-
ning Sicstus 3.0#3. In a further experiment an n-ary
ant i_unif y operation was implemented, which im-
proved execution times for the larger sentences, e.g.,
the 16 PP sentence took 750 msec. These results ap-
proximately fit the expectations from the theoretical
complexity bound.
</bodyText>
<figure confidence="0.9816348">
11
see(e 1 ,x 1 ,x2)
A
on(B,x3)
with(D,x4)
</figure>
<figureCaption confidence="0.999055">
Figure 6: Conjunctive part of UDRS, graphically
</figureCaption>
<page confidence="0.994058">
392
</page>
<sectionHeader confidence="0.999177" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999983379310345">
Our algorithm and its implementation show that it
is not only possible in theory, but also feasible in
practice to construct packed semantical representa-
tions directly from parse forests for sentence that ex-
hibit massive syntactic ambiguity. The algorithm is
both in asymptotic complexity and in real numbers
dramatically faster than an earlier approach, that
also tries to provide an underspecified semantics for
syntactic ambiguities. The algorithm has been pre-
sented abstractly from the actual constraint system
and can be :-,dapted to any constraint-based gram-
mar formalism.
A critical assumption for the method has been
that semantic rules never fail, i.e., no search is in-
volved in semantics construction. This is required
to guarantee that the resulting constraint is a kind
of &apos;solved form&apos; actually representing so-to-speak the
free combination of choices it contains. Nevertheless,
our method (modulo small changes to handle failure)
may still prove useful, when this restriction is not
fulfilled, since it focuses on computing the common
information of disjunctive branches. The conjunctive
part of the output constraint of the algorithm can
then be seen as an approximation of the actual re-
sult, if the output constraint is satisfiable. Moreover,
the disjunctive parts are reduced, so that a subse-
quent full-fledged search will have considerably less
work than when directly trying to solve the original
constraint system.
</bodyText>
<sectionHeader confidence="0.999096" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999267123076923">
H. Alshawi (Ed.). The Core Language Engine.
ACL-MIT Press Series in Natural Languages Pro-
cessing. MIT Press, Cambridge, Mass., 1992.
S. Billot and B. Lang. The Structure of Shared
Forests in Ambiguous Parsing. In Proceedings of
the 27th Annual Meeting of the ACL, University of
British Columbia, pp. 143-151, Vancouver, B.C.,
Canada, 1989.
B. Carpenter. ALE: The Attribute Logic Engine
User&apos;s Guide. Laboratory for Computational Lin-
guistics, Philosophy Department, Carnegie Mellon
University, Pittsburgh PA 15213, December 1992.
J. Dorre and M. Dorna. CUF — A Formalism for
Linguistic Knowledge Representation. In J. Dorre
(Ed.), Computational Aspects of Constraint-Based
Linguistic Description I, DYANA-2 deliverable
R1.2.A. ESPRIT, Basic Research Project 6852,
July 1993.
J. Earley. An Efficient Context-Free Parsing Algo-
rithm. Communications of the ACM, 13(2):94-
102, 1970.
M. Egg and K. Lebeth. Semantic Underspeci-
fication and Modifier Attachment Ambiguities.
In J. Kilbury and R. Wiese (Eds.), Integra-
tive Ansiitze in der Computerlinguistik. Beitriige
zur 5. Fachtagung der Sektion Computerlinguis-
tik der Deutschen Gesellschaft fiir Sprachwis-
senschaft (DGfS), pp. 19-24. Düsseldorf, Ger-
many, 1995.
H. Kamp and U. Reyle. From Discourse to Logic. In-
troduction to Modeltheoretic Semantics of Natural
Language, Formal Logic and Discourse Represen-
tation Theory. Studies in Linguistics and Philoso-
phy 42. Kluwer Academic Publishers, Dordrecht,
The Netherlands, 1993.
J. T. Maxwell III and R. M. Kaplan. The Inter-
face between Phrasal and Functional Constraints.
Computational Linguistics, 19(4):571-590, 1993.
F. C. Pereira and D. H. Warren. Definite Clause
Grammars for Language Analysis—A Survey of
the Formalism and a Comparison with Aug-
mented Transition Networks. Artificial Intelli-
gence, 13:231-278, 1980.
M. Pinkal. Radical Underspecification. In Pro-
ceedings of the 10th Amsterdam Colloquium, pp.
587-606, Amsterdam, Holland, December 1995.
ILLC/Department of Philosophy, University of
Amsterdam.
C. Pollard and I. A. Sag. Head Driven Phrase
Structure Grammar. University of Chicago Press,
Chicago, 1994.
U. Reyle. Dealing with Ambiguities by Underspecifi-
cation: Construction, Representation, and Deduc-
tion. Journal of Semantics, 10(2):123-179, 1993.
M. Schiehlen. Semantic Construction from Parse
Forests. In Proceedings of the 16th International
Conference on Computational Linguistics, Copen-
hagen, Denmark, 1996.
G. Smolka and R. Treinen (Eds.). DFKI Oz Doc-
umentation Series. German Research Center
for Artificial Intelligence (DFKI), Stuhlsatzen-
hausweg 3, D-66123 Saarbrficken, Germany, 1996.
http://www.ps.uni-sb.de/oz.
M. Tomita. Efficient Parsing for Natural Languages.
Kluwer Academic Publishers, Boston, 1986.
</reference>
<page confidence="0.999374">
393
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.089178">
<title confidence="0.9812875">Efficient Construction of Underspecified Semantics under Massive Ambiguity</title>
<author confidence="0.979534">Jochen Dorre</author>
<affiliation confidence="0.9961155">Institut fiir maschinelle Sprachverarbeitung University of Stuttgart</affiliation>
<abstract confidence="0.998214617647059">We investigate the problem of determining a compact underspecified semantical representation for sentences that may be highly ambiguous. Due to combinatorial explosion, the naive method of building semantics for the different syntactic readings independently is prohibitive. We present a method that takes as input a syntactic parse forest with associated constraintbased semantic construction rules and dibuilds a packed The algorithm is fully implemented and in sentence length, if the grammar meets some reasonable &apos;normality&apos; restrictions. 1 Background One of the most central problems that any NL system must face is the ubiquitous phenomenon of ambiguity. In the last few years a whole new branch dein semantics that investigates semantic representations in order to cope with this phenomenon. Such representations do not stand for the real or intended meaning of sentences, but rather for the possible options of interpretation. Quantifier scope ambiguities are a semantic variety of ambiguity that is handled especially well by this approach. Pioneering work in that direction has been (Alshawi 92) and (Reyle 93). More recently there has been growing interest in developing the underspecification approach to also cover syntactic ambiguities (cf. (Pinlcal 95; EggLebeth 95; Schiehlen 96)). Schiehlen&apos;s approach is outstanding in that he fully takes into account syntactic</abstract>
<note confidence="0.7350185">This research has been carried out while the author visited the Programming Systems Lab of Prof. Gert Smolka at the University of Saarland, Saarbriicken. Thanks to John Maxwell, Martin Muller, Joachim</note>
<abstract confidence="0.951083285714285">Niehren, Michael Schiehlen, and an anonymous reviewer for valuable feedback and to all at PS Lab for their helpful support with the OZ system. constraints. In (Schiehlen 96) he presents an algorithm which directly constructs a single underspecified semantic structure from the ideal &amp;quot;underspecified&amp;quot; syntactic structure, a parse forest. On the other hand, a method for producing &amp;quot;packed semantic structures&amp;quot;, in that case &amp;quot;packed quasi-logical forms&amp;quot;, has already been used in the Core Language Engine, informally described in (Alshawl 92, Chap. 7). However, this method only produces a structure that is virtually isomorphic to the parse forest, since it simply replaces parse forest nodes by their corresponding semantic operators. No attempt is made to actually apply semantic operators in the phase where those &amp;quot;packed QLFs&amp;quot; are constructed. Moreover, the packing of the QLFs seems to serve no purpose in the processing phases following semantic analysis. Already the immediately succeeding phase &amp;quot;sortal filtering&amp;quot; requires QLFs to be unpacked, i.e. enumerated. Contrary to the CLE method, Schiehlen&apos;s method actively packs semantic structures, even when they result from distinct syntactic structures, extracting common parts. His method, however, may take time exponential w.r.t. sentence length. Already the semantic representations it produces can be exponentially large, because they grow linear with the number of (syntactic) readings and that can be exponential, e.g., for sentences that exhibit the well-known attachment ambiguity of prepositional phrases. It is therefore an interesting question to ask, whether we can compute compact semantic representations from parse forests without falling prey to exponential explosion. purpose of present paper is show that construction of compact semantic representations like in Schiehlen&apos;s approach from parse forests is not only possible, but also cheap, i.e., can be done in polynomial time. To illustrate our method we use a simple DCG grammar for PP-attachment ambiguities, adapted from (Schiehlen 96), that yields semantic representations (called UDRSs) according to the Underspecified Discourse Representation Theory (Reyle 93; KampReyle 93). The grammar is shown in Fig. 1. 386 start(DRS) --&gt; s( [_,_, ltop] , [] , DRS) . vt([Ev,X,Y,L,_DomL],DRS_i,DRS) [saw], (DRS.[L:see(Ev,X,Y)IDRS_i]). s([Event,VerbL,DomL],DRS_i,DRS_0) --&gt; np([X,VerbL,DomL],DRS_i,DRS1), det([X,Lab,VerbL,_],DRS_i,DRS) vp([Event,X,VerbL,DomL],DRS1,DRS_o). [a], (DRS.11t(Lab,ltop),1t(VerbL,Lab), s([Event,VerbL,DomL],DRS_i,DRS_0) --&gt; Lab:XIDRS_i), s([Event,VerbL,Dom1.],DRS_LDRS1), gensym(1,Lab),gensym(x,X)). pp([Event,VerbL,DomLI,DRS1,DRS_o). det([X,ResL,VbL,DomL],DRS_i,DRS) --&gt; vp([Ev,X,VerbL,DomL],DRS_i,DRS_0) --&gt; [every], vt([Ev,X,Y,VerbL,DomL],DRS_i,DRS1), [DRS.[1t(L,DomL),1t(VbL,ScpL),ResL:X, np([Y,VerbL,DomL],DRS1,DRS_o). L:every(ResL,ScpL)IDRS_il, gensym(1,L),gensym(1,ResL), np([X,VbL,DomL],DRS_i,DRS_o) --&gt; gensym(1,ScpL),gensym(x,X)). det([X,Nol....L,VhL,DomL],DRS_i,DRS1), n([X,NounL,DomL],DRS1,DRS_o). np([X,_,_],DRS_i,DRS) --&gt; [i], [DRS=[1top:X,anchor(X,speaker)IDRS_i], n([X,NounL,DomL],DRS_i,DRS_o) --&gt; gensym(x,X)). n([X,NounL,DomL],DRS_i,DRS1), pp([X,NounL,DomL],DRS1,DRS_o). n([X,L,_],DRS,[1,:man(X)IDRS]) --&gt; [man]. n([X,L,_],DRS,[L:hill(X)IDRS]) --&gt; [hill]. pp([X,L,DomL],DRS_i,DRS_o) --&gt; prep(Cond,X,Y), prep(on(X,Y),X,Y) --&gt; [on]. npf[Y,L,DomL],[L:CondIDRS_i],DRS_o). prep(with(X,Y),X,Y) --&gt; [with]. Figure 1: Example DCG The UDRSs constructed by the grammar are flat of the UDRS-constraints &lt; (partial) ordering between labels; Prolog represen-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Alshawi</author>
</authors>
<title>The Core Language Engine.</title>
<date>1992</date>
<booktitle>Series in Natural Languages Processing.</booktitle>
<publisher>ACL-MIT Press</publisher>
<location>Cambridge, Mass.,</location>
<marker>Alshawi, 1992</marker>
<rawString>H. Alshawi (Ed.). The Core Language Engine. ACL-MIT Press Series in Natural Languages Processing. MIT Press, Cambridge, Mass., 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Billot</author>
<author>B Lang</author>
</authors>
<title>The Structure of Shared Forests in Ambiguous Parsing.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Meeting of the ACL, University of British Columbia,</booktitle>
<pages>143--151</pages>
<location>Vancouver, B.C., Canada,</location>
<marker>Billot, Lang, 1989</marker>
<rawString>S. Billot and B. Lang. The Structure of Shared Forests in Ambiguous Parsing. In Proceedings of the 27th Annual Meeting of the ACL, University of British Columbia, pp. 143-151, Vancouver, B.C., Canada, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Carpenter</author>
</authors>
<title>ALE: The Attribute Logic Engine User&apos;s Guide.</title>
<date>1992</date>
<pages>15213</pages>
<institution>Laboratory for Computational Linguistics, Philosophy Department, Carnegie Mellon University,</institution>
<location>Pittsburgh PA</location>
<marker>Carpenter, 1992</marker>
<rawString>B. Carpenter. ALE: The Attribute Logic Engine User&apos;s Guide. Laboratory for Computational Linguistics, Philosophy Department, Carnegie Mellon University, Pittsburgh PA 15213, December 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dorre</author>
<author>M Dorna</author>
</authors>
<title>CUF — A Formalism for Linguistic Knowledge Representation. In</title>
<date>1993</date>
<booktitle>Computational Aspects of Constraint-Based Linguistic Description I, DYANA-2 deliverable R1.2.A. ESPRIT, Basic Research Project 6852,</booktitle>
<editor>J. Dorre (Ed.),</editor>
<marker>Dorre, Dorna, 1993</marker>
<rawString>J. Dorre and M. Dorna. CUF — A Formalism for Linguistic Knowledge Representation. In J. Dorre (Ed.), Computational Aspects of Constraint-Based Linguistic Description I, DYANA-2 deliverable R1.2.A. ESPRIT, Basic Research Project 6852, July 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An Efficient Context-Free Parsing Algorithm.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<pages>13--2</pages>
<marker>Earley, 1970</marker>
<rawString>J. Earley. An Efficient Context-Free Parsing Algorithm. Communications of the ACM, 13(2):94-102, 1970.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Egg</author>
<author>K Lebeth</author>
</authors>
<title>Semantic Underspecification and Modifier Attachment Ambiguities.</title>
<marker>Egg, Lebeth, </marker>
<rawString>M. Egg and K. Lebeth. Semantic Underspecification and Modifier Attachment Ambiguities.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In J Kilbury</author>
<author>R Wiese</author>
</authors>
<title>Integrative Ansiitze</title>
<date></date>
<booktitle>in der Computerlinguistik. Beitriige zur 5. Fachtagung der Sektion Computerlinguistik der Deutschen Gesellschaft fiir Sprachwissenschaft (DGfS),</booktitle>
<pages>pp.</pages>
<location>Düsseldorf, Germany,</location>
<marker>Kilbury, Wiese, </marker>
<rawString>In J. Kilbury and R. Wiese (Eds.), Integrative Ansiitze in der Computerlinguistik. Beitriige zur 5. Fachtagung der Sektion Computerlinguistik der Deutschen Gesellschaft fiir Sprachwissenschaft (DGfS), pp. 19-24. Düsseldorf, Germany, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kamp</author>
<author>U Reyle</author>
</authors>
<title>From Discourse to Logic. Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory.</title>
<date>1993</date>
<booktitle>Studies in Linguistics and Philosophy 42.</booktitle>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht, The Netherlands,</location>
<marker>Kamp, Reyle, 1993</marker>
<rawString>H. Kamp and U. Reyle. From Discourse to Logic. Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory. Studies in Linguistics and Philosophy 42. Kluwer Academic Publishers, Dordrecht, The Netherlands, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J T Maxwell</author>
<author>R M Kaplan</author>
</authors>
<title>The Interface between Phrasal and Functional Constraints. Computational Linguistics,</title>
<date>1993</date>
<marker>Maxwell, Kaplan, 1993</marker>
<rawString>J. T. Maxwell III and R. M. Kaplan. The Interface between Phrasal and Functional Constraints. Computational Linguistics, 19(4):571-590, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C Pereira</author>
<author>D H Warren</author>
</authors>
<title>Definite Clause Grammars for Language Analysis—A Survey of the Formalism and a Comparison with Augmented Transition Networks.</title>
<date>1980</date>
<journal>Artificial Intelligence,</journal>
<pages>13--231</pages>
<marker>Pereira, Warren, 1980</marker>
<rawString>F. C. Pereira and D. H. Warren. Definite Clause Grammars for Language Analysis—A Survey of the Formalism and a Comparison with Augmented Transition Networks. Artificial Intelligence, 13:231-278, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pinkal</author>
</authors>
<title>Radical Underspecification.</title>
<date>1995</date>
<booktitle>In Proceedings of the 10th Amsterdam Colloquium,</booktitle>
<pages>587--606</pages>
<institution>ILLC/Department of Philosophy, University of Amsterdam.</institution>
<location>Amsterdam, Holland,</location>
<marker>Pinkal, 1995</marker>
<rawString>M. Pinkal. Radical Underspecification. In Proceedings of the 10th Amsterdam Colloquium, pp. 587-606, Amsterdam, Holland, December 1995. ILLC/Department of Philosophy, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>Head Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago,</location>
<marker>Pollard, Sag, 1994</marker>
<rawString>C. Pollard and I. A. Sag. Head Driven Phrase Structure Grammar. University of Chicago Press, Chicago, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Reyle</author>
</authors>
<title>Dealing with Ambiguities by Underspecification: Construction, Representation, and Deduction.</title>
<date>1993</date>
<journal>Journal of Semantics,</journal>
<pages>10--2</pages>
<marker>Reyle, 1993</marker>
<rawString>U. Reyle. Dealing with Ambiguities by Underspecification: Construction, Representation, and Deduction. Journal of Semantics, 10(2):123-179, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Schiehlen</author>
</authors>
<title>Semantic Construction from Parse Forests.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<location>Copenhagen,</location>
<marker>Schiehlen, 1996</marker>
<rawString>M. Schiehlen. Semantic Construction from Parse Forests. In Proceedings of the 16th International Conference on Computational Linguistics, Copenhagen, Denmark, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Smolka</author>
<author>R Treinen</author>
</authors>
<date>1996</date>
<booktitle>DFKI Oz Documentation Series. German Research Center for Artificial Intelligence (DFKI), Stuhlsatzenhausweg 3, D-66123 Saarbrficken,</booktitle>
<note>http://www.ps.uni-sb.de/oz.</note>
<marker>Smolka, Treinen, 1996</marker>
<rawString>G. Smolka and R. Treinen (Eds.). DFKI Oz Documentation Series. German Research Center for Artificial Intelligence (DFKI), Stuhlsatzenhausweg 3, D-66123 Saarbrficken, Germany, 1996. http://www.ps.uni-sb.de/oz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Efficient Parsing for Natural Languages.</title>
<date>1986</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston,</location>
<marker>Tomita, 1986</marker>
<rawString>M. Tomita. Efficient Parsing for Natural Languages. Kluwer Academic Publishers, Boston, 1986.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>