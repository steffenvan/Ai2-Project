<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000333">
<title confidence="0.990121">
Automatic prediction of aspectual class of verbs in context
</title>
<author confidence="0.982052">
Annemarie Friedrich and Alexis Palmer
</author>
<affiliation confidence="0.947793">
Department of Computational Linguistics
Saarland University, Saarbr¨ucken, Germany
</affiliation>
<email confidence="0.992036">
{afried,apalmer}@coli.uni-saarland.de
</email>
<sectionHeader confidence="0.997295" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999963">
This paper describes a new approach to
predicting the aspectual class of verbs in
context, i.e., whether a verb is used in a
stative or dynamic sense. We identify two
challenging cases of this problem: when
the verb is unseen in training data, and
when the verb is ambiguous for aspec-
tual class. A semi-supervised approach us-
ing linguistically-motivated features and a
novel set of distributional features based
on representative verb types allows us to
predict classes accurately, even for unseen
verbs. Many frequent verbs can be either
stative or dynamic in different contexts,
which has not been modeled by previous
work; we use contextual features to re-
solve this ambiguity. In addition, we intro-
duce two new datasets of clauses marked
for aspectual class.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991956947368421">
In this work, we focus on the automatic prediction
of whether a verb in context is used in a stative or
in a dynamic sense, the most fundamental distinc-
tion in all taxonomies of aspectual class. The as-
pectual class of a discourse’s finite verbs is an im-
portant factor in conveying and interpreting tem-
poral structure (Moens and Steedman, 1988; Dorr,
1992; Klavans and Chodorow, 1992); others are
tense, grammatical aspect, mood and whether the
utterance represents an event as completed. More
accurate temporal information processing is ex-
pected to be beneficial for a variety of natural lan-
guage processing tasks (Costa and Branco, 2012;
UzZaman et al., 2013).
While most verbs have one predominant inter-
pretation, others are more flexible for aspectual
class and can occur as either stative (1) or dynamic
(2) depending on the context. There are also cases
that allow for both readings, such as (3).
</bodyText>
<listItem confidence="0.97729025">
(1) The liquid fills the container. (stative)
(2) The pool slowly filled with water. (dynamic)
(3) Your soul was made to be filled with God
Himself. (both) (Brown corpus, religion)
</listItem>
<bodyText confidence="0.999929571428572">
Cases like (3) do not imply that there is a third
class, but rather that two interpretations are avail-
able for the sentence, of which usually one will be
chosen by a reader.
Following Siegel and McKeown (2000), we aim
to automatically classify clauses for fundamental
aspectual class, a function of the main verb and
a select group of complements, which may dif-
fer per verb (Siegel and McKeown, 2000; Siegel,
1998b). This corresponds to the aspectual class
of the clause’s main verb when ignoring any as-
pectual markers or transformations. For exam-
ple, English sentences with perfect tense are usu-
ally considered to introduce states to the discourse
(Smith, 1991; Katz, 2003), but we are interested in
the aspectual class before this transformation takes
place. The clause John has kissed Mary introduces
a state, but the fundamental aspectual class of the
‘tenseless’ clause John kiss Mary is dynamic.
In contrast to Siegel and McKeown (2000), we
do not conduct the task of predicting aspectual
class solely at the type level, as such an approach
ignores the minority class of ambiguous verbs. In-
stead we predict the aspectual class of verbs in
the context of their arguments and modifiers. We
show that this method works better than using only
type-based features, especially for verbs with am-
biguous aspectual class. In addition, we show
that type-based features, including novel distribu-
tional features based on representative verbs, accu-
rately predict predominant aspectual class for un-
seen verb types. Our work differs from prior work
in that we treat the problem as a three-way clas-
sification task, predicting DYNAMIC, STATIVE or
BOTH as the aspectual class of a verb in context.
</bodyText>
<page confidence="0.947531">
517
</page>
<bodyText confidence="0.551131">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 517–523,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.999609" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999973617021277">
Aspectual class is well treated in the linguistic lit-
erature (Vendler, 1957; Dowty, 1979; Smith, 1991,
for example). Our notion of the stative/dynamic
distinction corresponds to Bach’s (1986) distinc-
tion between states and non-states; to states ver-
sus occurrences (events and processes) according
to Mourelatos (1978); and to Vendler’s (1957) dis-
tinction between states and the other three classes
(activities, achievements, accomplishments).
Early studies on the computational modeling
of aspectual class (Nakhimovsky, 1988; Passon-
neau, 1988; Brent, 1991; Klavans and Chodorow,
1992) laid foundations for a cluster of papers pub-
lished over a decade ago (Siegel and McKeown,
2000; Siegel, 1998b; Siegel, 1998a). Since then,
it has mostly been treated as a subtask within
temporal reasoning, such as in efforts related to
TimeBank (Pustejovsky et al., 2003) and the Tem-
pEval challenges (Verhagen et al., 2007; Verha-
gen et al., 2010; UzZaman et al., 2013), where
top-performing systems (Jung and Stent, 2013;
Bethard, 2013; Chambers, 2013) use corpus-based
features, WordNet synsets, parse paths and fea-
tures from typed dependencies to classify events
as a joint task with determining the event’s span.
Costa and Branco (2012) explore the usefulness of
a wider range of explicitly aspectual features for
temporal relation classification.
Siegel and McKeown (2000) present the most
extensive study of predicting aspectual class,
which is the main inspiration for this work. While
all of their linguistically motivated features (see
section 4.1) are type-based, they train on and eval-
uate over labeled verbs in context. Their data
set taken from medical discharge summaries com-
prises 1500 clauses containing main verbs other
than be and have which are marked for aspectual
class. Their model fails to outperform a baseline
of memorizing the most frequent class of a verb
type, and they present an experiment testing on un-
seen verb types only for the related task of classi-
fying completedness of events. We replicate their
method using publicly available software, create
a similar but larger corpus,1 and show that it is
indeed possible to predict the aspectual class of
unseen verbs. Siegel (1998a) investigates a classi-
fication method for the verb have in context; in-
</bodyText>
<footnote confidence="0.977485666666667">
1Direct comparison on their data is not possible; feature
values for the verbs studied are available, but full texts and
the English Slot Grammar parser (McCord, 1990) are not.
</footnote>
<table confidence="0.997876666666667">
COMPLETE W/O have/be/none
genre clauses κ clauses κ
jokes 3462 0.85 2660 0.77
letters 1848 0.71 1444 0.62
news 2565 0.79 2075 0.69
all 7875 0.80 6161 0.70
</table>
<tableCaption confidence="0.995485">
Table 1: Asp-MASC: Cohen’s observed un-
weighted κ.
</tableCaption>
<table confidence="0.9994395">
DYNAMIC STATIVE BOTH
DYNAMIC 4464 164 9
STATIVE 434 1056 29
BOTH 5 0 0
</table>
<tableCaption confidence="0.9645565">
Table 2: Asp-MASC: confusion matrix for two
annotators, without have/be/none clauses, κ is 0.7.
</tableCaption>
<bodyText confidence="0.9861665">
spired by this work, our present work goes one
step further and uses a larger set of instance-based
contextual features to perform experiments on a
set of 20 verbs. To the best of our knowledge, there
is no previous work comprehensively addressing
aspectual classification of verbs in context.
</bodyText>
<sectionHeader confidence="0.997295" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.99729028">
Verb type seed sets Using the LCS Database
(Dorr, 2001), we identify sets of verb types whose
senses are only stative (188 verbs, e.g. belong,
cost, possess), only dynamic (3760 verbs, e.g. al-
ter, knock, resign), or mixed (215 verbs, e.g. fill,
stand, take), following a procedure described by
Dorr and Olsen (1997).
Asp-MASC The Asp-MASC corpus consists of
7875 clauses from the letters, news and jokes sec-
tions of MASC (Ide et al., 2010), each labeled
by two annotators for the aspectual class of the
main verb.2 Texts were segmented into clauses us-
ing SPADE (Soricut and Marcu, 2003) with some
heuristic post-processing. We parse the corpus us-
ing the Stanford dependency parser (De Marneffe
et al., 2006) and extract the main verb of each seg-
ment. We use 6161 clauses for the classification
task, omitting clauses with have or be as the main
verb and those where no main verb could be iden-
tified due to parsing errors (none). Table 1 shows
inter-annotator agreement; Table 2 shows the con-
fusion matrix for the two annotators. Our two an-
notators exhibit different preferences on the 598
cases where they disagree between DYNAMIC and
STATIVE. Such differences in annotation prefer-
</bodyText>
<footnote confidence="0.9783845">
2Corpus freely available from
www.coli.uni-saarland.de/˜afried.
</footnote>
<page confidence="0.975062">
518
</page>
<table confidence="0.99379025">
DYNAMIC STATIVE BOTH
DYNAMIC 1444 201 54
STATIVE 168 697 20
BOTH 44 31 8
</table>
<tableCaption confidence="0.932799">
Table 3: Asp-Ambig: confusion matrix for two
annotators. Cohen’s κ is 0.6.
</tableCaption>
<bodyText confidence="0.97924424137931">
ences are not uncommon (Beigman Klebanov et
al., 2008). We observe higher agreement in the
jokes and news subcorpora than for letters; texts
in the letters subcorpora are largely argumentative
and thus have a different rhetorical style than the
more straightforward narratives and reports found
in jokes. Overall, we find substantial agreement.
The data for our experiments uses the label DY-
NAMIC or STATIVE whenever annotators agree,
and BOTH whenever they disagree or when at least
one annotator marked the clause as BOTH, assum-
ing that both readings are possible in such cases.
Because we don’t want to model the authors’ per-
sonal view of the theory, we refrain from applying
an adjudication step and model the data as is.
Asp-Ambig: (Brown) In order to facilitate a
first study on ambiguous verbs, we select 20 fre-
quent verbs from the list of ‘mixed’ verbs (see
section 3) and for each mark 138 sentences. Sen-
tences are extracted randomly from the Brown cor-
pus, such that the distribution of stative/dynamic
usages is expected to be natural. We present
entire sentences to the annotators who mark the
aspectual class of the verb in question as high-
lighted in the sentence. The data is processed in
the same way as Asp-MASC, discarding instances
with parsing problems. This results in 2667 in-
stances. κ is 0.6, the confusion matrix is shown in
Table 3. Details are listed in Table 10.
</bodyText>
<sectionHeader confidence="0.959771" genericHeader="method">
4 Model and Features
</sectionHeader>
<bodyText confidence="0.999947333333334">
For predicting the aspectual class of verbs in con-
text (STATIVE, DYNAMIC, BOTH), we assume a
supervised learning setting and explore features
mined from a large background corpus, distribu-
tional features, and instance-based features. If not
indicated otherwise, experiments use a Random
Forest classifier (Breiman, 2001) trained with the
implementation and standard parameter settings
from Weka (Hall et al., 2009).
</bodyText>
<subsectionHeader confidence="0.98468">
4.1 Linguistic indicator features (LingInd)
</subsectionHeader>
<bodyText confidence="0.614085307692308">
This set of corpus-based features is a reimple-
mentation of the linguistic indicators of Siegel
FEATURE EXAMPLE
continuous continually
adverb endlessly
evaluation better
adverb horribly
manner furiously
adverb patiently
temporal again
adverb finally
in-PP in an hour
for-PP for an hour
</bodyText>
<tableCaption confidence="0.9956965">
Table 4: LingInd feature set and examples for lex-
ical items associated with each indicator.
</tableCaption>
<table confidence="0.999508">
FEATURE VALUES
part-of-speech tag of the verb VB, VBG, VBN, ...
tense present, past, future
progressive true/false
perfect true/false
voice active/passive
grammatical dependents WordNet lexname/POS
</table>
<tableCaption confidence="0.999017">
Table 5: Instance-based (Inst) features
</tableCaption>
<bodyText confidence="0.99725">
and McKeown (2000), who show that (some of)
these features correlate with either stative or dy-
namic verb types. We parse the AFE and XIE sec-
tions of Gigaword (Graff and Cieri, 2003) with
the Stanford dependency parser. For each verb
type, we obtain a normalized count showing how
often it occurs with each of the indicators in Ta-
ble 4, resulting in one value per feature per verb.
For example, for the verb fill, the value of the
feature temporal-adverb is 0.0085, meaning
that 0.85% of the occurrences of fill in the corpus
are modified by one of the temporal adverbs on the
list compiled by Siegel (1998b). Tense, progres-
sive, perfect and voice are extracted using a set of
rules following Loaiciga et al. (2014).3
</bodyText>
<subsectionHeader confidence="0.951056">
4.2 Distributional Features (Dist)
</subsectionHeader>
<bodyText confidence="0.999823538461539">
We aim to leverage existing, possibly noisy sets
of representative stative, dynamic or mixed verb
types extracted from LCS (see section 3), mak-
ing up for unseen verbs and noise by averaging
over distributional similarities. Using an exist-
ing large distributional model (Thater et al., 2011)
estimated over the set of Gigaword documents
marked as stories, for each verb type, we build
a syntactically informed vector representing the
contexts in which the verb occurs. We compute
three numeric feature values per verb type, which
correspond to the average cosine similarities with
the verb types in each of the three seed sets.
</bodyText>
<footnote confidence="0.918606">
3We thank the authors for providing us their code.
</footnote>
<table confidence="0.953105777777778">
FEATURE EXAMPLE
frequency -
present says
past said
future will say
perfect had won
progressive is winning
negated not/never
particle up/in/...
no subject -
519
FEATURES ACCURACY (%)
Baseline (Lemma) 83.6
LingInd 83.8
Inst 70.8
Inst+Lemma 83.7
Dist 83.4
LingInd+Inst+Dist+Lemma 84.1
</table>
<tableCaption confidence="0.904239666666667">
Table 6: Experiment 1: SEEN verbs, using Asp-
MASC. Baseline memorizes most frequent class
per verb type in training folds.
</tableCaption>
<subsectionHeader confidence="0.955252">
4.3 Instance-based features (Inst)
</subsectionHeader>
<bodyText confidence="0.99887155">
Table 5 shows our set of instance-based syntac-
tic and semantic features. In contrast to the above
described type-based features, these features do
not rely on a background corpus, but are ex-
tracted from the clause being classified. Tense,
progressive, perfect and voice are extracted from
dependency parses as described above. For fea-
tures encoding grammatical dependents, we focus
on a subset of grammatical relations. The fea-
ture value is either the WordNet lexical filename
(e.g. noun.person) of the given relation’s argu-
ment or its POS tag, if the former is not avail-
able. We simply use the most frequent sense for
the dependent’s lemma. We also include features
that indicate, if there are any, the particle of the
verb and its prepositional dependents. For the
sentence A little girl had just finished her first
week of school, the instance-based feature values
would include tense:past, subj:noun.person,
dobj:noun.time or particle:none.
</bodyText>
<sectionHeader confidence="0.999704" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999940857142857">
The experiments presented in this section aim to
evaluate the effectiveness of the feature sets de-
scribed in the previous section, focusing on the
challenging cases of verb types unseen in the train-
ing data and highly ambiguous verbs. The feature
Lemma indicates that the verb’s lemma is used as
an additional feature.
</bodyText>
<subsectionHeader confidence="0.441631">
Experiment 1: SEEN verbs
</subsectionHeader>
<bodyText confidence="0.999556833333333">
The setting of our first experiment follows Siegel
and McKeown (2000). Table 6 reports results for
10-fold cross-validation, with occurrences of all
verbs distributed evenly over the folds. No feature
combination significantly4 outperforms the base-
line of simply memorizing the most frequent class
</bodyText>
<footnote confidence="0.880453">
4According to McNemar’s test with Yates’ correction for
</footnote>
<table confidence="0.963438666666667">
continuity, P &lt; 0.01.
FEATURES ACCURACY (%)
1 Baseline 72.5
2 Dist 78.3*
3 LingInd 80.4*
4 LingInd+Dist 81.9*†
</table>
<tableCaption confidence="0.8510468">
Table 7: Experiment 2: UNSEEN verb types, Lo-
gistic regression, Asp-MASC. Baseline labels ev-
erything with the most frequent class in the train-
ing set (DYNAMIC). *Significantly4 different from
line 1. †Significantly4 different from line 3.
</tableCaption>
<table confidence="0.999946647058824">
DATA FEATURES ACC. (%)
one-label Baseline 92.8
verbs
(1966 inst.)
LingInd 92.8
Dist 92.6
Inst+Lemma 91.4*
LingInd+Inst+Lemma 92.4
multi-label Baseline 78.9
verbs
(4195 inst.)
LingInd 79.0
Dist 79.0
Inst 67.4*
Inst+Lemma 79.9
LingInd+Inst+Lemma 80.9*
LingInd+Inst+Lemma+Dist 80.2*
</table>
<tableCaption confidence="0.68760425">
Table 8: Experiment 3: ‘ONE- VS. MULTI-
LABEL’ verbs, Asp-MASC. Baseline as in Table
6. *Indicates that result is significantly4 different
from the respective baseline.
</tableCaption>
<bodyText confidence="0.990953611111111">
of a verb type in the respective training folds.
Experiment 2: UNSEEN verbs
This experiment shows a successful case of semi-
supervised learning: while type-based feature val-
ues can be estimated from large corpora in an un-
supervised way, some labeled training data is nec-
essary to learn their best combination. This exper-
iment specifically examines performance on verbs
not seen in labeled training data. We use 10-fold
cross validation but ensure that all occurrences of
a verb type appear in the same fold: verb types
in each test fold have not been seen in the re-
spective training data, ruling out the Lemma fea-
ture. A Logistic regression classifier (Hall et al.,
2009) works better here (using only numeric fea-
tures), and we present results in Table 7. Both the
LingInd and Dist features generalize across verb
types, and their combination works best.
</bodyText>
<subsectionHeader confidence="0.243546">
Experiment 3: ONE- vs. MULTI-LABEL verbs
</subsectionHeader>
<bodyText confidence="0.991760333333333">
For this experiment, we compute results sepa-
rately for one-label verbs (those for which all in-
stances in Asp-MASC have the same label) and
</bodyText>
<page confidence="0.991012">
520
</page>
<table confidence="0.997637666666667">
SYSTEM CLASS ACC. P R F
baseline micro-avg. 78.9 0.75 0.79 0.76
LingInd DYNAMIC 0.84 0.95 0.89
+Inst STATIVE 0.76 0.69 0.72
+Lemma BOTH 0.51 0.24 0.33
micro-avg. 80.9* 0.78 0.81 0.79
</table>
<tableCaption confidence="0.990354">
Table 9: Experiment 3: ‘MULTI-LABEL’, preci-
</tableCaption>
<bodyText confidence="0.995528888888889">
sion, recall and F-measure, detailed class statistics
for the best-performing system from Table 8.
for multi-label verbs (instances have differing la-
bels in Asp-MASC). We expect one-label verbs
to have a strong predominant aspectual class, and
multi-label verbs to be more flexible. Otherwise,
the experimental setup is as in experiment 1. Re-
sults appear in Table 8. In each case, the linguistic
indicator features again perform on par with the
baseline. For multi-label verbs, the feature combi-
nation Lemma+LingInd+Inst leads to significant4
improvement of 2% gain in accuracy over the
baseline; Table 9 reports detailed class statistics
and reveals a gain in F-measure of 3 points over
the baseline. To sum up, Inst features are essential
for classifying multi-label verbs, and the LingInd
features provide some useful prior. These results
motivate the need for an instance-based approach.
</bodyText>
<subsectionHeader confidence="0.850993">
Experiment 4: INSTANCE-BASED classification
</subsectionHeader>
<bodyText confidence="0.9456235">
For verbs with ambiguous aspectual class, type-
based classification is not sufficient, as this ap-
proach selects a dominant sense for any given verb
and then always assigns that. Therefore we pro-
pose handling ambiguous verbs separately. As
Asp-MASC contains only few instances of each of
the ambiguous verbs, we turn to the Asp-Ambig
dataset. We perform a Leave-One-Out (LOO)
cross validation evaluation, with results reported
in Table 10.5 Using the Inst features alone (not
shown in Table 10) results in a micro-average ac-
curacy of only 58.1%: these features are only use-
ful when combined with the feature Lemma. For
classifying verbs whose most frequent class oc-
curs less than 56% of the time, Lemma+Inst fea-
tures are essential. Whether or not performance
is improved by adding LingInd/Dist features, with
their bias towards one aspectual class, depends
on the verb type. It is an open research question
which verb types should be treated in which way.
5 The third column also shows the outcome of using ei-
ther only the Lemma, only LingInd or only Dist in LOO; all
have almost the same outcome as using the majority class,
numbers differ only after the decimal point.
</bodyText>
<table confidence="0.99959868">
VERB # OF MAJORITY Inst Inst
INST. CLASS5 +Lemma +Lemma
+LingInd
+Dist
feel 128 96.1 STAT 93.0 93.8
say 138 94.9 DYN 93.5 93.5
make 136 91.9 DYN 91.9 91.2
come 133 88.0 DYN 87.2 87.2
take 137 85.4 DYN 85.4 85.4
meet 130 83.9 DYN 86.2 87.7
stand 130 80.0 STAT 79.2 83.1
find 137 74.5 DYN 69.3 68.8
accept 134 70.9 DYN 64.9 65.7
hold 134 56.0 BOTH 43.3 49.3
carry 136 55.9 DYN 55.9 58.1
look 138 55.8 DYN 72.5 74.6
show 133 54.9 DYN 69.2 68.4
appear 136 52.2 STAT 64.7 61.0
follow 122 51.6 BOTH 69.7 65.6
consider 138 50.7 DYN 61.6 70.3
cover 123 50.4 STAT 46.3 54.5
fill 134 47.8 DYN 66.4 62.7
bear 135 47.4 DYN 70.4 67.4
allow 135 37.8 DYN 48.9 51.9
micro-avg. 2667 66.3 71.0* 72.0*
</table>
<tableCaption confidence="0.860788333333333">
Table 10: Experiment 4: INSTANCE-BASED.
Accuracy (in %) on Asp-Ambig. *Differs
significantly4 from the majority class baseline.
</tableCaption>
<sectionHeader confidence="0.977577" genericHeader="conclusions">
6 Discussion and conclusions
</sectionHeader>
<bodyText confidence="0.99988504">
We have described a new, context-aware approach
to automatically predicting aspectual class, includ-
ing a new set of distributional features. We have
also introduced two new data sets of clauses la-
beled for aspectual class. Our experiments show
that in any setting where labeled training data
is available, improvement over the most frequent
class baseline can only be reached by integrating
instance-based features, though type-based fea-
tures (LingInd, Dist) may provide useful priors
for some verbs and successfully predict predom-
inant aspectual class for unseen verb types. In or-
der to arrive at a globally well-performing system,
we envision a multi-stage approach, treating verbs
differently according to whether training data is
available and whether or not the verb’s aspectual
class distribution is highly skewed.
Acknowledgments We thank the anonymous
reviewers, Omri Abend, Mike Lewis, Manfred
Pinkal, Mark Steedman, Stefan Thater and Bonnie
Webber for helpful comments, and our annotators
A. Kirkland and R. K¨uhn. This research was sup-
ported in part by the MMCI Cluster of Excellence,
and the first author is supported by an IBM PhD
Fellowship.
</bodyText>
<page confidence="0.996634">
521
</page>
<sectionHeader confidence="0.996366" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99962318627451">
Emmon Bach. 1986. The algebra of events. Linguis-
tics and philosophy, 9(1):5–16.
Beata Beigman Klebanov, Eyal Beigman, and Daniel
Diermeier. 2008. Analyzing disagreements. In Pro-
ceedings of the Workshop on Human Judgements in
Computational Linguistics, pages 2–7. Association
for Computational Linguistics.
Steven Bethard. 2013. ClearTK-TimeML: A minimal-
ist approach to TempEval 2013. In Second Joint
Conference on Lexical and Computational Seman-
tics (* SEM), volume 2, pages 10–14.
Leo Breiman. 2001. Random forests. Machine Learn-
ing, 45(1):5–32.
Michael R. Brent. 1991. Automatic semantic classifi-
cation of verbs from their syntactic contexts: an im-
plemented classifier for stativity. In Proceedings of
the fifth conference on European chapter of the As-
sociation for Computational Linguistics, pages 222–
226. Association for Computational Linguistics.
Nathanael Chambers. 2013. Navytime: Event and
time ordering from raw text. In Second Joint Con-
ference on Lexical and Computational Semantics (*
SEM), volume 2, pages 73–77.
Francisco Costa and Ant´onio Branco. 2012. Aspec-
tual type and temporal relation classification. In
Proceedings of the 13th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 266–275. Association for Computa-
tional Linguistics.
Marie-Catherine De Marneffe, Bill MacCartney,
Christopher D Manning, et al. 2006. Generat-
ing typed dependency parses from phrase structure
parses. In Proceedings of LREC, volume 6, pages
449–454.
Bonnie J. Dorr and Mari Broman Olsen. 1997. De-
riving verbal and compositional lexical aspect for
NLP applications. In Proceedings of the eighth con-
ference on European chapter of the Association for
Computational Linguistics, pages 151–158. Associ-
ation for Computational Linguistics.
Bonnie J. Dorr. 1992. A two-level knowledge repre-
sentation for machine translation: lexical semantics
and tense/aspect. In Lexical Semantics and Knowl-
edge Representation, pages 269–287. Springer.
Bonnie J. Dorr. 2001. LCS verb database. Online
software database of Lexical Conceptual Structures,
University of Maryland, College Park, MD.
David Dowty. 1979. Word Meaning and Montague
Grammar. Reidel, Dordrecht.
David Graff and Christopher Cieri. 2003. English gi-
gaword.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The weka data mining software: an update.
ACM SIGKDD explorations newsletter, 11(1):10–
18.
Nancy Ide, Christiane Fellbaum, Collin Baker, and Re-
becca Passonneau. 2010. The manually annotated
sub-corpus: a community resource for and by the
people. In Proceedings of the ACL 2010 Conference
Short Papers, pages 68–73. Association for Compu-
tational Linguistics.
Hyuckchul Jung and Amanda Stent. 2013. ATT1:
Temporal annotation using big windows and rich
syntactic and semantic features. In Second Joint
Conference on Lexical and Computational Seman-
tics (* SEM), volume 2, pages 20–24.
Graham Katz. 2003. On the stativity of the english
perfect. Perfect explorations, pages 205–234.
Judith L. Klavans and Martin Chodorow. 1992. De-
grees of stativity: the lexical representation of verb
aspect. In Proceedings of the 14th conference on
Computational Linguistics, pages 1126–1131. Asso-
ciation for Computational Linguistics.
Sharid Loaiciga, Thomas Meyer, and Andrei Popescu-
Belis. 2014. English-French Verb Phrase Align-
ment in Europarl for Tense Translation Modeling.
In Language Resources and Evaluation Conference
(LREC), Reykjavik, Iceland.
Michael C. McCord. 1990. Slot Grammar. Springer.
Marc Moens and Mark J. Steedman. 1988. Tempo-
ral ontology and temporal reference. Computational
Linguistics, 14(2):15–28.
Alexander P.D. Mourelatos. 1978. Events, processes,
and states. Linguistics and philosophy, 2(3):415–
434.
Alexander Nakhimovsky. 1988. Aspect, aspectual
class, and the temporal structure of narrative. Com-
putational Linguistics, 14(2):29–43.
Rebecca Passonneau. 1988. A computational model
of the semantics of tense and aspect. Computational
Linguistics, Spring 1988.
James Pustejovsky, Patrick Hanks, Roser Sauri, An-
drew See, Robert Gaizauskas, Andrea Setzer,
Dragomir Radev, Beth Sundheim, David Day, Lisa
Ferro, et al. 2003. The timebank corpus. In Corpus
linguistics, volume 2003, page 40.
Eric V. Siegel and Kathleen R. McKeown. 2000.
Learning methods to combine linguistic indica-
tors: Improving aspectual classification and reveal-
ing linguistic insights. Computational Linguistics,
26(4):595–628.
</reference>
<page confidence="0.971086">
522
</page>
<reference confidence="0.999815318181818">
Eric V. Siegel. 1998a. Disambiguating verbs with the
WordNet category of the direct object. In Proceed-
ings of Workshop on Usage of WordNet in Natural
Language Processing Systems, Universite de Mon-
treal.
Eric V. Siegel. 1998b. Linguistic Indicators for
Language Understanding: Using machine learn-
ing methods to combine corpus-based indicators for
aspectual classification of clauses. Ph.D. thesis,
Columbia University.
Carlota S. Smith. 1991. The Parameter of Aspect.
Kluwer, Dordrecht.
Radu Soricut and Daniel Marcu. 2003. Sentence level
discourse parsing using syntactic and lexical infor-
mation. In Proceedings of the 2003 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology-Volume 1, pages 149–156. Association
for Computational Linguistics.
Stefan Thater, Hagen F¨urstenau, and Manfred Pinkal.
2011. Word meaning in context: A simple and ef-
fective vector model. In IJCNLP, pages 1134–1143.
Naushad UzZaman, Hector Llorens, Leon Derczyn-
ski, Marc Verhagen, James Allen, and James Puste-
jovsky. 2013. Semeval-2013 task 1: Tempeval-3:
Evaluating time expressions, events, and temporal
relations. In Second joint conference on lexical and
computational semantics (* SEM), volume 2, pages
1–9.
Zeno Vendler, 1957. Linguistics in Philosophy, chapter
Verbs and Times, pages 97–121. Cornell University
Press, Ithaca, New York.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. Semeval-2007 task 15: Tempeval temporal
relation identification. In Proceedings of the 4th
International Workshop on Semantic Evaluations,
pages 75–80. Association for Computational Lin-
guistics.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. SemEval-2010 task 13:
TempEval-2. In Proceedings of the 5th Interna-
tional Workshop on Semantic Evaluation, pages 57–
62. Association for Computational Linguistics.
</reference>
<page confidence="0.99893">
523
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.864268">
<title confidence="0.988795">Automatic prediction of aspectual class of verbs in context</title>
<author confidence="0.968828">Annemarie Friedrich</author>
<author confidence="0.968828">Alexis</author>
<affiliation confidence="0.9988905">Department of Computational Saarland University, Saarbr¨ucken,</affiliation>
<abstract confidence="0.9939206">This paper describes a new approach to predicting the aspectual class of verbs in context, i.e., whether a verb is used in a stative or dynamic sense. We identify two challenging cases of this problem: when the verb is unseen in training data, and when the verb is ambiguous for aspectual class. A semi-supervised approach using linguistically-motivated features and a novel set of distributional features based on representative verb types allows us to predict classes accurately, even for unseen verbs. Many frequent verbs can be either stative or dynamic in different contexts, which has not been modeled by previous work; we use contextual features to resolve this ambiguity. In addition, we introduce two new datasets of clauses marked for aspectual class.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Emmon Bach</author>
</authors>
<title>The algebra of events. Linguistics and philosophy,</title>
<date>1986</date>
<pages>9--1</pages>
<marker>Bach, 1986</marker>
<rawString>Emmon Bach. 1986. The algebra of events. Linguistics and philosophy, 9(1):5–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beata Beigman Klebanov</author>
<author>Eyal Beigman</author>
<author>Daniel Diermeier</author>
</authors>
<title>Analyzing disagreements.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Human Judgements in Computational Linguistics,</booktitle>
<pages>2--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8570" citStr="Klebanov et al., 2008" startWordPosition="1375" endWordPosition="1378"> be as the main verb and those where no main verb could be identified due to parsing errors (none). Table 1 shows inter-annotator agreement; Table 2 shows the confusion matrix for the two annotators. Our two annotators exhibit different preferences on the 598 cases where they disagree between DYNAMIC and STATIVE. Such differences in annotation prefer2Corpus freely available from www.coli.uni-saarland.de/˜afried. 518 DYNAMIC STATIVE BOTH DYNAMIC 1444 201 54 STATIVE 168 697 20 BOTH 44 31 8 Table 3: Asp-Ambig: confusion matrix for two annotators. Cohen’s κ is 0.6. ences are not uncommon (Beigman Klebanov et al., 2008). We observe higher agreement in the jokes and news subcorpora than for letters; texts in the letters subcorpora are largely argumentative and thus have a different rhetorical style than the more straightforward narratives and reports found in jokes. Overall, we find substantial agreement. The data for our experiments uses the label DYNAMIC or STATIVE whenever annotators agree, and BOTH whenever they disagree or when at least one annotator marked the clause as BOTH, assuming that both readings are possible in such cases. Because we don’t want to model the authors’ personal view of the theory, </context>
</contexts>
<marker>Klebanov, Beigman, Diermeier, 2008</marker>
<rawString>Beata Beigman Klebanov, Eyal Beigman, and Daniel Diermeier. 2008. Analyzing disagreements. In Proceedings of the Workshop on Human Judgements in Computational Linguistics, pages 2–7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
</authors>
<title>ClearTK-TimeML: A minimalist approach to TempEval</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (* SEM),</booktitle>
<volume>2</volume>
<pages>10--14</pages>
<contexts>
<context position="5024" citStr="Bethard, 2013" startWordPosition="793" endWordPosition="794">es, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual features for temporal relation classification. Siegel and McKeown (2000) present the most extensive study of predicting aspectual class, which is the main inspiration for this work. While all of their linguistically motivated features (see section 4.1) are type-based, they train on and evaluate over labeled verbs in context. Thei</context>
</contexts>
<marker>Bethard, 2013</marker>
<rawString>Steven Bethard. 2013. ClearTK-TimeML: A minimalist approach to TempEval 2013. In Second Joint Conference on Lexical and Computational Semantics (* SEM), volume 2, pages 10–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
</authors>
<title>Random forests.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="10245" citStr="Breiman, 2001" startWordPosition="1654" endWordPosition="1655">class of the verb in question as highlighted in the sentence. The data is processed in the same way as Asp-MASC, discarding instances with parsing problems. This results in 2667 instances. κ is 0.6, the confusion matrix is shown in Table 3. Details are listed in Table 10. 4 Model and Features For predicting the aspectual class of verbs in context (STATIVE, DYNAMIC, BOTH), we assume a supervised learning setting and explore features mined from a large background corpus, distributional features, and instance-based features. If not indicated otherwise, experiments use a Random Forest classifier (Breiman, 2001) trained with the implementation and standard parameter settings from Weka (Hall et al., 2009). 4.1 Linguistic indicator features (LingInd) This set of corpus-based features is a reimplementation of the linguistic indicators of Siegel FEATURE EXAMPLE continuous continually adverb endlessly evaluation better adverb horribly manner furiously adverb patiently temporal again adverb finally in-PP in an hour for-PP for an hour Table 4: LingInd feature set and examples for lexical items associated with each indicator. FEATURE VALUES part-of-speech tag of the verb VB, VBG, VBN, ... tense present, past</context>
</contexts>
<marker>Breiman, 2001</marker>
<rawString>Leo Breiman. 2001. Random forests. Machine Learning, 45(1):5–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
</authors>
<title>Automatic semantic classification of verbs from their syntactic contexts: an implemented classifier for stativity.</title>
<date>1991</date>
<booktitle>In Proceedings of the fifth conference on European chapter of the Association for Computational Linguistics,</booktitle>
<pages>222--226</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4559" citStr="Brent, 1991" startWordPosition="717" endWordPosition="718">ssociation for Computational Linguistics 2 Related work Aspectual class is well treated in the linguistic literature (Vendler, 1957; Dowty, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a </context>
</contexts>
<marker>Brent, 1991</marker>
<rawString>Michael R. Brent. 1991. Automatic semantic classification of verbs from their syntactic contexts: an implemented classifier for stativity. In Proceedings of the fifth conference on European chapter of the Association for Computational Linguistics, pages 222– 226. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
</authors>
<title>Navytime: Event and time ordering from raw text.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (* SEM),</booktitle>
<volume>2</volume>
<pages>73--77</pages>
<contexts>
<context position="5041" citStr="Chambers, 2013" startWordPosition="795" endWordPosition="796">s, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual features for temporal relation classification. Siegel and McKeown (2000) present the most extensive study of predicting aspectual class, which is the main inspiration for this work. While all of their linguistically motivated features (see section 4.1) are type-based, they train on and evaluate over labeled verbs in context. Their data set taken </context>
</contexts>
<marker>Chambers, 2013</marker>
<rawString>Nathanael Chambers. 2013. Navytime: Event and time ordering from raw text. In Second Joint Conference on Lexical and Computational Semantics (* SEM), volume 2, pages 73–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco Costa</author>
<author>Ant´onio Branco</author>
</authors>
<title>Aspectual type and temporal relation classification.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>266--275</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1642" citStr="Costa and Branco, 2012" startWordPosition="253" endWordPosition="256">e focus on the automatic prediction of whether a verb in context is used in a stative or in a dynamic sense, the most fundamental distinction in all taxonomies of aspectual class. The aspectual class of a discourse’s finite verbs is an important factor in conveying and interpreting temporal structure (Moens and Steedman, 1988; Dorr, 1992; Klavans and Chodorow, 1992); others are tense, grammatical aspect, mood and whether the utterance represents an event as completed. More accurate temporal information processing is expected to be beneficial for a variety of natural language processing tasks (Costa and Branco, 2012; UzZaman et al., 2013). While most verbs have one predominant interpretation, others are more flexible for aspectual class and can occur as either stative (1) or dynamic (2) depending on the context. There are also cases that allow for both readings, such as (3). (1) The liquid fills the container. (stative) (2) The pool slowly filled with water. (dynamic) (3) Your soul was made to be filled with God Himself. (both) (Brown corpus, religion) Cases like (3) do not imply that there is a third class, but rather that two interpretations are available for the sentence, of which usually one will be </context>
<context position="5228" citStr="Costa and Branco (2012)" startWordPosition="822" endWordPosition="825"> for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual features for temporal relation classification. Siegel and McKeown (2000) present the most extensive study of predicting aspectual class, which is the main inspiration for this work. While all of their linguistically motivated features (see section 4.1) are type-based, they train on and evaluate over labeled verbs in context. Their data set taken from medical discharge summaries comprises 1500 clauses containing main verbs other than be and have which are marked for aspectual class. Their model fails to outperform a baseline of me</context>
</contexts>
<marker>Costa, Branco, 2012</marker>
<rawString>Francisco Costa and Ant´onio Branco. 2012. Aspectual type and temporal relation classification. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 266–275. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>449--454</pages>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine De Marneffe, Bill MacCartney, Christopher D Manning, et al. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC, volume 6, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Mari Broman Olsen</author>
</authors>
<title>Deriving verbal and compositional lexical aspect for NLP applications.</title>
<date>1997</date>
<booktitle>In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics,</booktitle>
<pages>151--158</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7434" citStr="Dorr and Olsen (1997)" startWordPosition="1186" endWordPosition="1189">0.7. spired by this work, our present work goes one step further and uses a larger set of instance-based contextual features to perform experiments on a set of 20 verbs. To the best of our knowledge, there is no previous work comprehensively addressing aspectual classification of verbs in context. 3 Data Verb type seed sets Using the LCS Database (Dorr, 2001), we identify sets of verb types whose senses are only stative (188 verbs, e.g. belong, cost, possess), only dynamic (3760 verbs, e.g. alter, knock, resign), or mixed (215 verbs, e.g. fill, stand, take), following a procedure described by Dorr and Olsen (1997). Asp-MASC The Asp-MASC corpus consists of 7875 clauses from the letters, news and jokes sections of MASC (Ide et al., 2010), each labeled by two annotators for the aspectual class of the main verb.2 Texts were segmented into clauses using SPADE (Soricut and Marcu, 2003) with some heuristic post-processing. We parse the corpus using the Stanford dependency parser (De Marneffe et al., 2006) and extract the main verb of each segment. We use 6161 clauses for the classification task, omitting clauses with have or be as the main verb and those where no main verb could be identified due to parsing e</context>
</contexts>
<marker>Dorr, Olsen, 1997</marker>
<rawString>Bonnie J. Dorr and Mari Broman Olsen. 1997. Deriving verbal and compositional lexical aspect for NLP applications. In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics, pages 151–158. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>A two-level knowledge representation for machine translation: lexical semantics and tense/aspect.</title>
<date>1992</date>
<booktitle>In Lexical Semantics and Knowledge Representation,</booktitle>
<pages>269--287</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1359" citStr="Dorr, 1992" startWordPosition="212" endWordPosition="213">rbs can be either stative or dynamic in different contexts, which has not been modeled by previous work; we use contextual features to resolve this ambiguity. In addition, we introduce two new datasets of clauses marked for aspectual class. 1 Introduction In this work, we focus on the automatic prediction of whether a verb in context is used in a stative or in a dynamic sense, the most fundamental distinction in all taxonomies of aspectual class. The aspectual class of a discourse’s finite verbs is an important factor in conveying and interpreting temporal structure (Moens and Steedman, 1988; Dorr, 1992; Klavans and Chodorow, 1992); others are tense, grammatical aspect, mood and whether the utterance represents an event as completed. More accurate temporal information processing is expected to be beneficial for a variety of natural language processing tasks (Costa and Branco, 2012; UzZaman et al., 2013). While most verbs have one predominant interpretation, others are more flexible for aspectual class and can occur as either stative (1) or dynamic (2) depending on the context. There are also cases that allow for both readings, such as (3). (1) The liquid fills the container. (stative) (2) Th</context>
</contexts>
<marker>Dorr, 1992</marker>
<rawString>Bonnie J. Dorr. 1992. A two-level knowledge representation for machine translation: lexical semantics and tense/aspect. In Lexical Semantics and Knowledge Representation, pages 269–287. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>LCS verb database. Online software database of Lexical Conceptual Structures,</title>
<date>2001</date>
<institution>University of Maryland, College Park, MD.</institution>
<contexts>
<context position="7174" citStr="Dorr, 2001" startWordPosition="1145" endWordPosition="1146">.79 2075 0.69 all 7875 0.80 6161 0.70 Table 1: Asp-MASC: Cohen’s observed unweighted κ. DYNAMIC STATIVE BOTH DYNAMIC 4464 164 9 STATIVE 434 1056 29 BOTH 5 0 0 Table 2: Asp-MASC: confusion matrix for two annotators, without have/be/none clauses, κ is 0.7. spired by this work, our present work goes one step further and uses a larger set of instance-based contextual features to perform experiments on a set of 20 verbs. To the best of our knowledge, there is no previous work comprehensively addressing aspectual classification of verbs in context. 3 Data Verb type seed sets Using the LCS Database (Dorr, 2001), we identify sets of verb types whose senses are only stative (188 verbs, e.g. belong, cost, possess), only dynamic (3760 verbs, e.g. alter, knock, resign), or mixed (215 verbs, e.g. fill, stand, take), following a procedure described by Dorr and Olsen (1997). Asp-MASC The Asp-MASC corpus consists of 7875 clauses from the letters, news and jokes sections of MASC (Ide et al., 2010), each labeled by two annotators for the aspectual class of the main verb.2 Texts were segmented into clauses using SPADE (Soricut and Marcu, 2003) with some heuristic post-processing. We parse the corpus using the S</context>
</contexts>
<marker>Dorr, 2001</marker>
<rawString>Bonnie J. Dorr. 2001. LCS verb database. Online software database of Lexical Conceptual Structures, University of Maryland, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>Word Meaning and Montague Grammar.</title>
<date>1979</date>
<location>Reidel, Dordrecht.</location>
<contexts>
<context position="4092" citStr="Dowty, 1979" startWordPosition="653" endWordPosition="654">nal features based on representative verbs, accurately predict predominant aspectual class for unseen verb types. Our work differs from prior work in that we treat the problem as a three-way classification task, predicting DYNAMIC, STATIVE or BOTH as the aspectual class of a verb in context. 517 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 517–523, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related work Aspectual class is well treated in the linguistic literature (Vendler, 1957; Dowty, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel,</context>
</contexts>
<marker>Dowty, 1979</marker>
<rawString>David Dowty. 1979. Word Meaning and Montague Grammar. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
<author>Christopher Cieri</author>
</authors>
<date>2003</date>
<note>English gigaword.</note>
<contexts>
<context position="11181" citStr="Graff and Cieri, 2003" startWordPosition="1790" endWordPosition="1793">b horribly manner furiously adverb patiently temporal again adverb finally in-PP in an hour for-PP for an hour Table 4: LingInd feature set and examples for lexical items associated with each indicator. FEATURE VALUES part-of-speech tag of the verb VB, VBG, VBN, ... tense present, past, future progressive true/false perfect true/false voice active/passive grammatical dependents WordNet lexname/POS Table 5: Instance-based (Inst) features and McKeown (2000), who show that (some of) these features correlate with either stative or dynamic verb types. We parse the AFE and XIE sections of Gigaword (Graff and Cieri, 2003) with the Stanford dependency parser. For each verb type, we obtain a normalized count showing how often it occurs with each of the indicators in Table 4, resulting in one value per feature per verb. For example, for the verb fill, the value of the feature temporal-adverb is 0.0085, meaning that 0.85% of the occurrences of fill in the corpus are modified by one of the temporal adverbs on the list compiled by Siegel (1998b). Tense, progressive, perfect and voice are extracted using a set of rules following Loaiciga et al. (2014).3 4.2 Distributional Features (Dist) We aim to leverage existing, </context>
</contexts>
<marker>Graff, Cieri, 2003</marker>
<rawString>David Graff and Christopher Cieri. 2003. English gigaword.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: an update.</title>
<date>2009</date>
<journal>ACM SIGKDD explorations newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<pages>18</pages>
<contexts>
<context position="10339" citStr="Hall et al., 2009" startWordPosition="1666" endWordPosition="1669"> same way as Asp-MASC, discarding instances with parsing problems. This results in 2667 instances. κ is 0.6, the confusion matrix is shown in Table 3. Details are listed in Table 10. 4 Model and Features For predicting the aspectual class of verbs in context (STATIVE, DYNAMIC, BOTH), we assume a supervised learning setting and explore features mined from a large background corpus, distributional features, and instance-based features. If not indicated otherwise, experiments use a Random Forest classifier (Breiman, 2001) trained with the implementation and standard parameter settings from Weka (Hall et al., 2009). 4.1 Linguistic indicator features (LingInd) This set of corpus-based features is a reimplementation of the linguistic indicators of Siegel FEATURE EXAMPLE continuous continually adverb endlessly evaluation better adverb horribly manner furiously adverb patiently temporal again adverb finally in-PP in an hour for-PP for an hour Table 4: LingInd feature set and examples for lexical items associated with each indicator. FEATURE VALUES part-of-speech tag of the verb VB, VBG, VBN, ... tense present, past, future progressive true/false perfect true/false voice active/passive grammatical dependents</context>
<context position="15992" citStr="Hall et al., 2009" startWordPosition="2552" endWordPosition="2555">eriment 2: UNSEEN verbs This experiment shows a successful case of semisupervised learning: while type-based feature values can be estimated from large corpora in an unsupervised way, some labeled training data is necessary to learn their best combination. This experiment specifically examines performance on verbs not seen in labeled training data. We use 10-fold cross validation but ensure that all occurrences of a verb type appear in the same fold: verb types in each test fold have not been seen in the respective training data, ruling out the Lemma feature. A Logistic regression classifier (Hall et al., 2009) works better here (using only numeric features), and we present results in Table 7. Both the LingInd and Dist features generalize across verb types, and their combination works best. Experiment 3: ONE- vs. MULTI-LABEL verbs For this experiment, we compute results separately for one-label verbs (those for which all instances in Asp-MASC have the same label) and 520 SYSTEM CLASS ACC. P R F baseline micro-avg. 78.9 0.75 0.79 0.76 LingInd DYNAMIC 0.84 0.95 0.89 +Inst STATIVE 0.76 0.69 0.72 +Lemma BOTH 0.51 0.24 0.33 micro-avg. 80.9* 0.78 0.81 0.79 Table 9: Experiment 3: ‘MULTI-LABEL’, precision, </context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The weka data mining software: an update. ACM SIGKDD explorations newsletter, 11(1):10– 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Christiane Fellbaum</author>
<author>Collin Baker</author>
<author>Rebecca Passonneau</author>
</authors>
<title>The manually annotated sub-corpus: a community resource for and by the people.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers,</booktitle>
<pages>68--73</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7558" citStr="Ide et al., 2010" startWordPosition="1208" endWordPosition="1211">perform experiments on a set of 20 verbs. To the best of our knowledge, there is no previous work comprehensively addressing aspectual classification of verbs in context. 3 Data Verb type seed sets Using the LCS Database (Dorr, 2001), we identify sets of verb types whose senses are only stative (188 verbs, e.g. belong, cost, possess), only dynamic (3760 verbs, e.g. alter, knock, resign), or mixed (215 verbs, e.g. fill, stand, take), following a procedure described by Dorr and Olsen (1997). Asp-MASC The Asp-MASC corpus consists of 7875 clauses from the letters, news and jokes sections of MASC (Ide et al., 2010), each labeled by two annotators for the aspectual class of the main verb.2 Texts were segmented into clauses using SPADE (Soricut and Marcu, 2003) with some heuristic post-processing. We parse the corpus using the Stanford dependency parser (De Marneffe et al., 2006) and extract the main verb of each segment. We use 6161 clauses for the classification task, omitting clauses with have or be as the main verb and those where no main verb could be identified due to parsing errors (none). Table 1 shows inter-annotator agreement; Table 2 shows the confusion matrix for the two annotators. Our two an</context>
</contexts>
<marker>Ide, Fellbaum, Baker, Passonneau, 2010</marker>
<rawString>Nancy Ide, Christiane Fellbaum, Collin Baker, and Rebecca Passonneau. 2010. The manually annotated sub-corpus: a community resource for and by the people. In Proceedings of the ACL 2010 Conference Short Papers, pages 68–73. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyuckchul Jung</author>
<author>Amanda Stent</author>
</authors>
<title>ATT1: Temporal annotation using big windows and rich syntactic and semantic features.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (* SEM),</booktitle>
<volume>2</volume>
<pages>20--24</pages>
<contexts>
<context position="5009" citStr="Jung and Stent, 2013" startWordPosition="789" endWordPosition="792">hree classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual features for temporal relation classification. Siegel and McKeown (2000) present the most extensive study of predicting aspectual class, which is the main inspiration for this work. While all of their linguistically motivated features (see section 4.1) are type-based, they train on and evaluate over labeled verbs i</context>
</contexts>
<marker>Jung, Stent, 2013</marker>
<rawString>Hyuckchul Jung and Amanda Stent. 2013. ATT1: Temporal annotation using big windows and rich syntactic and semantic features. In Second Joint Conference on Lexical and Computational Semantics (* SEM), volume 2, pages 20–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Katz</author>
</authors>
<title>On the stativity of the english perfect. Perfect explorations,</title>
<date>2003</date>
<pages>205--234</pages>
<contexts>
<context position="2762" citStr="Katz, 2003" startWordPosition="443" endWordPosition="444">ther that two interpretations are available for the sentence, of which usually one will be chosen by a reader. Following Siegel and McKeown (2000), we aim to automatically classify clauses for fundamental aspectual class, a function of the main verb and a select group of complements, which may differ per verb (Siegel and McKeown, 2000; Siegel, 1998b). This corresponds to the aspectual class of the clause’s main verb when ignoring any aspectual markers or transformations. For example, English sentences with perfect tense are usually considered to introduce states to the discourse (Smith, 1991; Katz, 2003), but we are interested in the aspectual class before this transformation takes place. The clause John has kissed Mary introduces a state, but the fundamental aspectual class of the ‘tenseless’ clause John kiss Mary is dynamic. In contrast to Siegel and McKeown (2000), we do not conduct the task of predicting aspectual class solely at the type level, as such an approach ignores the minority class of ambiguous verbs. Instead we predict the aspectual class of verbs in the context of their arguments and modifiers. We show that this method works better than using only type-based features, especial</context>
</contexts>
<marker>Katz, 2003</marker>
<rawString>Graham Katz. 2003. On the stativity of the english perfect. Perfect explorations, pages 205–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith L Klavans</author>
<author>Martin Chodorow</author>
</authors>
<title>Degrees of stativity: the lexical representation of verb aspect.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th conference on Computational Linguistics,</booktitle>
<pages>1126--1131</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1388" citStr="Klavans and Chodorow, 1992" startWordPosition="214" endWordPosition="217">ither stative or dynamic in different contexts, which has not been modeled by previous work; we use contextual features to resolve this ambiguity. In addition, we introduce two new datasets of clauses marked for aspectual class. 1 Introduction In this work, we focus on the automatic prediction of whether a verb in context is used in a stative or in a dynamic sense, the most fundamental distinction in all taxonomies of aspectual class. The aspectual class of a discourse’s finite verbs is an important factor in conveying and interpreting temporal structure (Moens and Steedman, 1988; Dorr, 1992; Klavans and Chodorow, 1992); others are tense, grammatical aspect, mood and whether the utterance represents an event as completed. More accurate temporal information processing is expected to be beneficial for a variety of natural language processing tasks (Costa and Branco, 2012; UzZaman et al., 2013). While most verbs have one predominant interpretation, others are more flexible for aspectual class and can occur as either stative (1) or dynamic (2) depending on the context. There are also cases that allow for both readings, such as (3). (1) The liquid fills the container. (stative) (2) The pool slowly filled with wat</context>
<context position="4588" citStr="Klavans and Chodorow, 1992" startWordPosition="719" endWordPosition="722">r Computational Linguistics 2 Related work Aspectual class is well treated in the linguistic literature (Vendler, 1957; Dowty, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining t</context>
</contexts>
<marker>Klavans, Chodorow, 1992</marker>
<rawString>Judith L. Klavans and Martin Chodorow. 1992. Degrees of stativity: the lexical representation of verb aspect. In Proceedings of the 14th conference on Computational Linguistics, pages 1126–1131. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharid Loaiciga</author>
<author>Thomas Meyer</author>
<author>Andrei PopescuBelis</author>
</authors>
<title>English-French Verb Phrase Alignment in Europarl for Tense Translation Modeling.</title>
<date>2014</date>
<booktitle>In Language Resources and Evaluation Conference (LREC), Reykjavik,</booktitle>
<contexts>
<context position="11714" citStr="Loaiciga et al. (2014)" startWordPosition="1884" endWordPosition="1887">dynamic verb types. We parse the AFE and XIE sections of Gigaword (Graff and Cieri, 2003) with the Stanford dependency parser. For each verb type, we obtain a normalized count showing how often it occurs with each of the indicators in Table 4, resulting in one value per feature per verb. For example, for the verb fill, the value of the feature temporal-adverb is 0.0085, meaning that 0.85% of the occurrences of fill in the corpus are modified by one of the temporal adverbs on the list compiled by Siegel (1998b). Tense, progressive, perfect and voice are extracted using a set of rules following Loaiciga et al. (2014).3 4.2 Distributional Features (Dist) We aim to leverage existing, possibly noisy sets of representative stative, dynamic or mixed verb types extracted from LCS (see section 3), making up for unseen verbs and noise by averaging over distributional similarities. Using an existing large distributional model (Thater et al., 2011) estimated over the set of Gigaword documents marked as stories, for each verb type, we build a syntactically informed vector representing the contexts in which the verb occurs. We compute three numeric feature values per verb type, which correspond to the average cosine </context>
</contexts>
<marker>Loaiciga, Meyer, PopescuBelis, 2014</marker>
<rawString>Sharid Loaiciga, Thomas Meyer, and Andrei PopescuBelis. 2014. English-French Verb Phrase Alignment in Europarl for Tense Translation Modeling. In Language Resources and Evaluation Conference (LREC), Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C McCord</author>
</authors>
<date>1990</date>
<publisher>Slot Grammar. Springer.</publisher>
<contexts>
<context position="6436" citStr="McCord, 1990" startWordPosition="1018" endWordPosition="1019">of memorizing the most frequent class of a verb type, and they present an experiment testing on unseen verb types only for the related task of classifying completedness of events. We replicate their method using publicly available software, create a similar but larger corpus,1 and show that it is indeed possible to predict the aspectual class of unseen verbs. Siegel (1998a) investigates a classification method for the verb have in context; in1Direct comparison on their data is not possible; feature values for the verbs studied are available, but full texts and the English Slot Grammar parser (McCord, 1990) are not. COMPLETE W/O have/be/none genre clauses κ clauses κ jokes 3462 0.85 2660 0.77 letters 1848 0.71 1444 0.62 news 2565 0.79 2075 0.69 all 7875 0.80 6161 0.70 Table 1: Asp-MASC: Cohen’s observed unweighted κ. DYNAMIC STATIVE BOTH DYNAMIC 4464 164 9 STATIVE 434 1056 29 BOTH 5 0 0 Table 2: Asp-MASC: confusion matrix for two annotators, without have/be/none clauses, κ is 0.7. spired by this work, our present work goes one step further and uses a larger set of instance-based contextual features to perform experiments on a set of 20 verbs. To the best of our knowledge, there is no previous wo</context>
</contexts>
<marker>McCord, 1990</marker>
<rawString>Michael C. McCord. 1990. Slot Grammar. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Moens</author>
<author>Mark J Steedman</author>
</authors>
<title>Temporal ontology and temporal reference.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="1347" citStr="Moens and Steedman, 1988" startWordPosition="208" endWordPosition="211">en verbs. Many frequent verbs can be either stative or dynamic in different contexts, which has not been modeled by previous work; we use contextual features to resolve this ambiguity. In addition, we introduce two new datasets of clauses marked for aspectual class. 1 Introduction In this work, we focus on the automatic prediction of whether a verb in context is used in a stative or in a dynamic sense, the most fundamental distinction in all taxonomies of aspectual class. The aspectual class of a discourse’s finite verbs is an important factor in conveying and interpreting temporal structure (Moens and Steedman, 1988; Dorr, 1992; Klavans and Chodorow, 1992); others are tense, grammatical aspect, mood and whether the utterance represents an event as completed. More accurate temporal information processing is expected to be beneficial for a variety of natural language processing tasks (Costa and Branco, 2012; UzZaman et al., 2013). While most verbs have one predominant interpretation, others are more flexible for aspectual class and can occur as either stative (1) or dynamic (2) depending on the context. There are also cases that allow for both readings, such as (3). (1) The liquid fills the container. (sta</context>
</contexts>
<marker>Moens, Steedman, 1988</marker>
<rawString>Marc Moens and Mark J. Steedman. 1988. Temporal ontology and temporal reference. Computational Linguistics, 14(2):15–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander P D Mourelatos</author>
</authors>
<title>Events, processes, and states. Linguistics and philosophy,</title>
<date>1978</date>
<volume>2</volume>
<issue>3</issue>
<pages>434</pages>
<contexts>
<context position="4321" citStr="Mourelatos (1978)" startWordPosition="685" endWordPosition="686">DYNAMIC, STATIVE or BOTH as the aspectual class of a verb in context. 517 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 517–523, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related work Aspectual class is well treated in the linguistic literature (Vendler, 1957; Dowty, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen</context>
</contexts>
<marker>Mourelatos, 1978</marker>
<rawString>Alexander P.D. Mourelatos. 1978. Events, processes, and states. Linguistics and philosophy, 2(3):415– 434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Nakhimovsky</author>
</authors>
<title>Aspect, aspectual class, and the temporal structure of narrative.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="4528" citStr="Nakhimovsky, 1988" startWordPosition="712" endWordPosition="713">yland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related work Aspectual class is well treated in the linguistic literature (Vendler, 1957; Dowty, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed depend</context>
</contexts>
<marker>Nakhimovsky, 1988</marker>
<rawString>Alexander Nakhimovsky. 1988. Aspect, aspectual class, and the temporal structure of narrative. Computational Linguistics, 14(2):29–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Passonneau</author>
</authors>
<title>A computational model of the semantics of tense and aspect. Computational Linguistics,</title>
<date>1988</date>
<location>Spring</location>
<contexts>
<context position="4546" citStr="Passonneau, 1988" startWordPosition="714" endWordPosition="716">-25 2014. c�2014 Association for Computational Linguistics 2 Related work Aspectual class is well treated in the linguistic literature (Vendler, 1957; Dowty, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify</context>
</contexts>
<marker>Passonneau, 1988</marker>
<rawString>Rebecca Passonneau. 1988. A computational model of the semantics of tense and aspect. Computational Linguistics, Spring 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Patrick Hanks</author>
<author>Roser Sauri</author>
<author>Andrew See</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Dragomir Radev</author>
<author>Beth Sundheim</author>
<author>David Day</author>
<author>Lisa Ferro</author>
</authors>
<title>The timebank corpus.</title>
<date>2003</date>
<booktitle>In Corpus linguistics,</booktitle>
<volume>volume</volume>
<pages>40</pages>
<contexts>
<context position="4860" citStr="Pustejovsky et al., 2003" startWordPosition="764" endWordPosition="767">es; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual features for temporal relation classification. Siegel and McKeown (2000) present the most extensive study of predicting aspectual class, which is the main inspiration </context>
</contexts>
<marker>Pustejovsky, Hanks, Sauri, See, Gaizauskas, Setzer, Radev, Sundheim, Day, Ferro, 2003</marker>
<rawString>James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew See, Robert Gaizauskas, Andrea Setzer, Dragomir Radev, Beth Sundheim, David Day, Lisa Ferro, et al. 2003. The timebank corpus. In Corpus linguistics, volume 2003, page 40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric V Siegel</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Learning methods to combine linguistic indicators: Improving aspectual classification and revealing linguistic insights.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<contexts>
<context position="2297" citStr="Siegel and McKeown (2000)" startWordPosition="366" endWordPosition="369"> most verbs have one predominant interpretation, others are more flexible for aspectual class and can occur as either stative (1) or dynamic (2) depending on the context. There are also cases that allow for both readings, such as (3). (1) The liquid fills the container. (stative) (2) The pool slowly filled with water. (dynamic) (3) Your soul was made to be filled with God Himself. (both) (Brown corpus, religion) Cases like (3) do not imply that there is a third class, but rather that two interpretations are available for the sentence, of which usually one will be chosen by a reader. Following Siegel and McKeown (2000), we aim to automatically classify clauses for fundamental aspectual class, a function of the main verb and a select group of complements, which may differ per verb (Siegel and McKeown, 2000; Siegel, 1998b). This corresponds to the aspectual class of the clause’s main verb when ignoring any aspectual markers or transformations. For example, English sentences with perfect tense are usually considered to introduce states to the discourse (Smith, 1991; Katz, 2003), but we are interested in the aspectual class before this transformation takes place. The clause John has kissed Mary introduces a sta</context>
<context position="4683" citStr="Siegel and McKeown, 2000" startWordPosition="736" endWordPosition="739">ature (Vendler, 1957; Dowty, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly </context>
<context position="14241" citStr="Siegel and McKeown (2000)" startWordPosition="2282" endWordPosition="2285">dependents. For the sentence A little girl had just finished her first week of school, the instance-based feature values would include tense:past, subj:noun.person, dobj:noun.time or particle:none. 5 Experiments The experiments presented in this section aim to evaluate the effectiveness of the feature sets described in the previous section, focusing on the challenging cases of verb types unseen in the training data and highly ambiguous verbs. The feature Lemma indicates that the verb’s lemma is used as an additional feature. Experiment 1: SEEN verbs The setting of our first experiment follows Siegel and McKeown (2000). Table 6 reports results for 10-fold cross-validation, with occurrences of all verbs distributed evenly over the folds. No feature combination significantly4 outperforms the baseline of simply memorizing the most frequent class 4According to McNemar’s test with Yates’ correction for continuity, P &lt; 0.01. FEATURES ACCURACY (%) 1 Baseline 72.5 2 Dist 78.3* 3 LingInd 80.4* 4 LingInd+Dist 81.9*† Table 7: Experiment 2: UNSEEN verb types, Logistic regression, Asp-MASC. Baseline labels everything with the most frequent class in the training set (DYNAMIC). *Significantly4 different from line 1. †Sign</context>
</contexts>
<marker>Siegel, McKeown, 2000</marker>
<rawString>Eric V. Siegel and Kathleen R. McKeown. 2000. Learning methods to combine linguistic indicators: Improving aspectual classification and revealing linguistic insights. Computational Linguistics, 26(4):595–628.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric V Siegel</author>
</authors>
<title>Disambiguating verbs with the WordNet category of the direct object.</title>
<date>1998</date>
<booktitle>In Proceedings of Workshop on Usage of WordNet in Natural Language Processing Systems, Universite de</booktitle>
<location>Montreal.</location>
<contexts>
<context position="2501" citStr="Siegel, 1998" startWordPosition="402" endWordPosition="403">ngs, such as (3). (1) The liquid fills the container. (stative) (2) The pool slowly filled with water. (dynamic) (3) Your soul was made to be filled with God Himself. (both) (Brown corpus, religion) Cases like (3) do not imply that there is a third class, but rather that two interpretations are available for the sentence, of which usually one will be chosen by a reader. Following Siegel and McKeown (2000), we aim to automatically classify clauses for fundamental aspectual class, a function of the main verb and a select group of complements, which may differ per verb (Siegel and McKeown, 2000; Siegel, 1998b). This corresponds to the aspectual class of the clause’s main verb when ignoring any aspectual markers or transformations. For example, English sentences with perfect tense are usually considered to introduce states to the discourse (Smith, 1991; Katz, 2003), but we are interested in the aspectual class before this transformation takes place. The clause John has kissed Mary introduces a state, but the fundamental aspectual class of the ‘tenseless’ clause John kiss Mary is dynamic. In contrast to Siegel and McKeown (2000), we do not conduct the task of predicting aspectual class solely at th</context>
<context position="4697" citStr="Siegel, 1998" startWordPosition="740" endWordPosition="741">y, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual feat</context>
<context position="6197" citStr="Siegel (1998" startWordPosition="979" endWordPosition="980">ate over labeled verbs in context. Their data set taken from medical discharge summaries comprises 1500 clauses containing main verbs other than be and have which are marked for aspectual class. Their model fails to outperform a baseline of memorizing the most frequent class of a verb type, and they present an experiment testing on unseen verb types only for the related task of classifying completedness of events. We replicate their method using publicly available software, create a similar but larger corpus,1 and show that it is indeed possible to predict the aspectual class of unseen verbs. Siegel (1998a) investigates a classification method for the verb have in context; in1Direct comparison on their data is not possible; feature values for the verbs studied are available, but full texts and the English Slot Grammar parser (McCord, 1990) are not. COMPLETE W/O have/be/none genre clauses κ clauses κ jokes 3462 0.85 2660 0.77 letters 1848 0.71 1444 0.62 news 2565 0.79 2075 0.69 all 7875 0.80 6161 0.70 Table 1: Asp-MASC: Cohen’s observed unweighted κ. DYNAMIC STATIVE BOTH DYNAMIC 4464 164 9 STATIVE 434 1056 29 BOTH 5 0 0 Table 2: Asp-MASC: confusion matrix for two annotators, without have/be/non</context>
<context position="11605" citStr="Siegel (1998" startWordPosition="1868" endWordPosition="1869">atures and McKeown (2000), who show that (some of) these features correlate with either stative or dynamic verb types. We parse the AFE and XIE sections of Gigaword (Graff and Cieri, 2003) with the Stanford dependency parser. For each verb type, we obtain a normalized count showing how often it occurs with each of the indicators in Table 4, resulting in one value per feature per verb. For example, for the verb fill, the value of the feature temporal-adverb is 0.0085, meaning that 0.85% of the occurrences of fill in the corpus are modified by one of the temporal adverbs on the list compiled by Siegel (1998b). Tense, progressive, perfect and voice are extracted using a set of rules following Loaiciga et al. (2014).3 4.2 Distributional Features (Dist) We aim to leverage existing, possibly noisy sets of representative stative, dynamic or mixed verb types extracted from LCS (see section 3), making up for unseen verbs and noise by averaging over distributional similarities. Using an existing large distributional model (Thater et al., 2011) estimated over the set of Gigaword documents marked as stories, for each verb type, we build a syntactically informed vector representing the contexts in which th</context>
</contexts>
<marker>Siegel, 1998</marker>
<rawString>Eric V. Siegel. 1998a. Disambiguating verbs with the WordNet category of the direct object. In Proceedings of Workshop on Usage of WordNet in Natural Language Processing Systems, Universite de Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric V Siegel</author>
</authors>
<title>Linguistic Indicators for Language Understanding: Using machine learning methods to combine corpus-based indicators for aspectual classification of clauses.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>Columbia University.</institution>
<contexts>
<context position="2501" citStr="Siegel, 1998" startWordPosition="402" endWordPosition="403">ngs, such as (3). (1) The liquid fills the container. (stative) (2) The pool slowly filled with water. (dynamic) (3) Your soul was made to be filled with God Himself. (both) (Brown corpus, religion) Cases like (3) do not imply that there is a third class, but rather that two interpretations are available for the sentence, of which usually one will be chosen by a reader. Following Siegel and McKeown (2000), we aim to automatically classify clauses for fundamental aspectual class, a function of the main verb and a select group of complements, which may differ per verb (Siegel and McKeown, 2000; Siegel, 1998b). This corresponds to the aspectual class of the clause’s main verb when ignoring any aspectual markers or transformations. For example, English sentences with perfect tense are usually considered to introduce states to the discourse (Smith, 1991; Katz, 2003), but we are interested in the aspectual class before this transformation takes place. The clause John has kissed Mary introduces a state, but the fundamental aspectual class of the ‘tenseless’ clause John kiss Mary is dynamic. In contrast to Siegel and McKeown (2000), we do not conduct the task of predicting aspectual class solely at th</context>
<context position="4697" citStr="Siegel, 1998" startWordPosition="740" endWordPosition="741">y, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual feat</context>
<context position="6197" citStr="Siegel (1998" startWordPosition="979" endWordPosition="980">ate over labeled verbs in context. Their data set taken from medical discharge summaries comprises 1500 clauses containing main verbs other than be and have which are marked for aspectual class. Their model fails to outperform a baseline of memorizing the most frequent class of a verb type, and they present an experiment testing on unseen verb types only for the related task of classifying completedness of events. We replicate their method using publicly available software, create a similar but larger corpus,1 and show that it is indeed possible to predict the aspectual class of unseen verbs. Siegel (1998a) investigates a classification method for the verb have in context; in1Direct comparison on their data is not possible; feature values for the verbs studied are available, but full texts and the English Slot Grammar parser (McCord, 1990) are not. COMPLETE W/O have/be/none genre clauses κ clauses κ jokes 3462 0.85 2660 0.77 letters 1848 0.71 1444 0.62 news 2565 0.79 2075 0.69 all 7875 0.80 6161 0.70 Table 1: Asp-MASC: Cohen’s observed unweighted κ. DYNAMIC STATIVE BOTH DYNAMIC 4464 164 9 STATIVE 434 1056 29 BOTH 5 0 0 Table 2: Asp-MASC: confusion matrix for two annotators, without have/be/non</context>
<context position="11605" citStr="Siegel (1998" startWordPosition="1868" endWordPosition="1869">atures and McKeown (2000), who show that (some of) these features correlate with either stative or dynamic verb types. We parse the AFE and XIE sections of Gigaword (Graff and Cieri, 2003) with the Stanford dependency parser. For each verb type, we obtain a normalized count showing how often it occurs with each of the indicators in Table 4, resulting in one value per feature per verb. For example, for the verb fill, the value of the feature temporal-adverb is 0.0085, meaning that 0.85% of the occurrences of fill in the corpus are modified by one of the temporal adverbs on the list compiled by Siegel (1998b). Tense, progressive, perfect and voice are extracted using a set of rules following Loaiciga et al. (2014).3 4.2 Distributional Features (Dist) We aim to leverage existing, possibly noisy sets of representative stative, dynamic or mixed verb types extracted from LCS (see section 3), making up for unseen verbs and noise by averaging over distributional similarities. Using an existing large distributional model (Thater et al., 2011) estimated over the set of Gigaword documents marked as stories, for each verb type, we build a syntactically informed vector representing the contexts in which th</context>
</contexts>
<marker>Siegel, 1998</marker>
<rawString>Eric V. Siegel. 1998b. Linguistic Indicators for Language Understanding: Using machine learning methods to combine corpus-based indicators for aspectual classification of clauses. Ph.D. thesis, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlota S Smith</author>
</authors>
<title>The Parameter of Aspect.</title>
<date>1991</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="2749" citStr="Smith, 1991" startWordPosition="441" endWordPosition="442">class, but rather that two interpretations are available for the sentence, of which usually one will be chosen by a reader. Following Siegel and McKeown (2000), we aim to automatically classify clauses for fundamental aspectual class, a function of the main verb and a select group of complements, which may differ per verb (Siegel and McKeown, 2000; Siegel, 1998b). This corresponds to the aspectual class of the clause’s main verb when ignoring any aspectual markers or transformations. For example, English sentences with perfect tense are usually considered to introduce states to the discourse (Smith, 1991; Katz, 2003), but we are interested in the aspectual class before this transformation takes place. The clause John has kissed Mary introduces a state, but the fundamental aspectual class of the ‘tenseless’ clause John kiss Mary is dynamic. In contrast to Siegel and McKeown (2000), we do not conduct the task of predicting aspectual class solely at the type level, as such an approach ignores the minority class of ambiguous verbs. Instead we predict the aspectual class of verbs in the context of their arguments and modifiers. We show that this method works better than using only type-based featu</context>
<context position="4105" citStr="Smith, 1991" startWordPosition="655" endWordPosition="656">based on representative verbs, accurately predict predominant aspectual class for unseen verb types. Our work differs from prior work in that we treat the problem as a three-way classification task, predicting DYNAMIC, STATIVE or BOTH as the aspectual class of a verb in context. 517 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 517–523, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related work Aspectual class is well treated in the linguistic literature (Vendler, 1957; Dowty, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siege</context>
</contexts>
<marker>Smith, 1991</marker>
<rawString>Carlota S. Smith. 1991. The Parameter of Aspect. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1,</booktitle>
<pages>149--156</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7705" citStr="Soricut and Marcu, 2003" startWordPosition="1233" endWordPosition="1236">ification of verbs in context. 3 Data Verb type seed sets Using the LCS Database (Dorr, 2001), we identify sets of verb types whose senses are only stative (188 verbs, e.g. belong, cost, possess), only dynamic (3760 verbs, e.g. alter, knock, resign), or mixed (215 verbs, e.g. fill, stand, take), following a procedure described by Dorr and Olsen (1997). Asp-MASC The Asp-MASC corpus consists of 7875 clauses from the letters, news and jokes sections of MASC (Ide et al., 2010), each labeled by two annotators for the aspectual class of the main verb.2 Texts were segmented into clauses using SPADE (Soricut and Marcu, 2003) with some heuristic post-processing. We parse the corpus using the Stanford dependency parser (De Marneffe et al., 2006) and extract the main verb of each segment. We use 6161 clauses for the classification task, omitting clauses with have or be as the main verb and those where no main verb could be identified due to parsing errors (none). Table 1 shows inter-annotator agreement; Table 2 shows the confusion matrix for the two annotators. Our two annotators exhibit different preferences on the 598 cases where they disagree between DYNAMIC and STATIVE. Such differences in annotation prefer2Corp</context>
</contexts>
<marker>Soricut, Marcu, 2003</marker>
<rawString>Radu Soricut and Daniel Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, pages 149–156. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Thater</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
</authors>
<title>Word meaning in context: A simple and effective vector model.</title>
<date>2011</date>
<booktitle>In IJCNLP,</booktitle>
<pages>1134--1143</pages>
<marker>Thater, F¨urstenau, Pinkal, 2011</marker>
<rawString>Stefan Thater, Hagen F¨urstenau, and Manfred Pinkal. 2011. Word meaning in context: A simple and effective vector model. In IJCNLP, pages 1134–1143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naushad UzZaman</author>
<author>Hector Llorens</author>
<author>Leon Derczynski</author>
<author>Marc Verhagen</author>
<author>James Allen</author>
<author>James Pustejovsky</author>
</authors>
<title>Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations.</title>
<date>2013</date>
<booktitle>In Second joint conference on lexical and computational semantics (* SEM),</booktitle>
<volume>2</volume>
<pages>1--9</pages>
<contexts>
<context position="1665" citStr="UzZaman et al., 2013" startWordPosition="257" endWordPosition="260"> prediction of whether a verb in context is used in a stative or in a dynamic sense, the most fundamental distinction in all taxonomies of aspectual class. The aspectual class of a discourse’s finite verbs is an important factor in conveying and interpreting temporal structure (Moens and Steedman, 1988; Dorr, 1992; Klavans and Chodorow, 1992); others are tense, grammatical aspect, mood and whether the utterance represents an event as completed. More accurate temporal information processing is expected to be beneficial for a variety of natural language processing tasks (Costa and Branco, 2012; UzZaman et al., 2013). While most verbs have one predominant interpretation, others are more flexible for aspectual class and can occur as either stative (1) or dynamic (2) depending on the context. There are also cases that allow for both readings, such as (3). (1) The liquid fills the container. (stative) (2) The pool slowly filled with water. (dynamic) (3) Your soul was made to be filled with God Himself. (both) (Brown corpus, religion) Cases like (3) do not imply that there is a third class, but rather that two interpretations are available for the sentence, of which usually one will be chosen by a reader. Fol</context>
<context position="4957" citStr="UzZaman et al., 2013" startWordPosition="782" endWordPosition="785">r’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual features for temporal relation classification. Siegel and McKeown (2000) present the most extensive study of predicting aspectual class, which is the main inspiration for this work. While all of their linguistically motivated features (see section 4.1) are type-ba</context>
</contexts>
<marker>UzZaman, Llorens, Derczynski, Verhagen, Allen, Pustejovsky, 2013</marker>
<rawString>Naushad UzZaman, Hector Llorens, Leon Derczynski, Marc Verhagen, James Allen, and James Pustejovsky. 2013. Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations. In Second joint conference on lexical and computational semantics (* SEM), volume 2, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeno Vendler</author>
</authors>
<title>Linguistics in Philosophy, chapter Verbs and Times,</title>
<date>1957</date>
<pages>97--121</pages>
<publisher>Cornell University Press,</publisher>
<location>Ithaca, New York.</location>
<contexts>
<context position="4079" citStr="Vendler, 1957" startWordPosition="651" endWordPosition="652">vel distributional features based on representative verbs, accurately predict predominant aspectual class for unseen verb types. Our work differs from prior work in that we treat the problem as a three-way classification task, predicting DYNAMIC, STATIVE or BOTH as the aspectual class of a verb in context. 517 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 517–523, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related work Aspectual class is well treated in the linguistic literature (Vendler, 1957; Dowty, 1979; Smith, 1991, for example). Our notion of the stative/dynamic distinction corresponds to Bach’s (1986) distinction between states and non-states; to states versus occurrences (events and processes) according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, </context>
</contexts>
<marker>Vendler, 1957</marker>
<rawString>Zeno Vendler, 1957. Linguistics in Philosophy, chapter Verbs and Times, pages 97–121. Cornell University Press, Ithaca, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>Semeval-2007 task 15: Tempeval temporal relation identification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>75--80</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4911" citStr="Verhagen et al., 2007" startWordPosition="773" endWordPosition="776"> according to Mourelatos (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual features for temporal relation classification. Siegel and McKeown (2000) present the most extensive study of predicting aspectual class, which is the main inspiration for this work. While all of their linguistically mo</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and James Pustejovsky. 2007. Semeval-2007 task 15: Tempeval temporal relation identification. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 75–80. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<title>57– 62. Association for Computational Linguistics.</title>
<date>2010</date>
<booktitle>SemEval-2010 task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>pages</pages>
<contexts>
<context position="4934" citStr="Verhagen et al., 2010" startWordPosition="777" endWordPosition="781">s (1978); and to Vendler’s (1957) distinction between states and the other three classes (activities, achievements, accomplishments). Early studies on the computational modeling of aspectual class (Nakhimovsky, 1988; Passonneau, 1988; Brent, 1991; Klavans and Chodorow, 1992) laid foundations for a cluster of papers published over a decade ago (Siegel and McKeown, 2000; Siegel, 1998b; Siegel, 1998a). Since then, it has mostly been treated as a subtask within temporal reasoning, such as in efforts related to TimeBank (Pustejovsky et al., 2003) and the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), where top-performing systems (Jung and Stent, 2013; Bethard, 2013; Chambers, 2013) use corpus-based features, WordNet synsets, parse paths and features from typed dependencies to classify events as a joint task with determining the event’s span. Costa and Branco (2012) explore the usefulness of a wider range of explicitly aspectual features for temporal relation classification. Siegel and McKeown (2000) present the most extensive study of predicting aspectual class, which is the main inspiration for this work. While all of their linguistically motivated features (see s</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. SemEval-2010 task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 57– 62. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>