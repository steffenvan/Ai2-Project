<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.981192">
Leveraging Linguistic Structure For Open Domain Information
Extraction
</title>
<author confidence="0.998666">
Gabor Angeli Melvin Johnson Premkumar Christopher D. Manning
</author>
<affiliation confidence="0.988322">
Department of Computer Science
Stanford University
</affiliation>
<email confidence="0.989165">
{angeli, melvinj, manning}@cs.stanford.edu
</email>
<sectionHeader confidence="0.997364" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99639135">
Relation triples produced by open domain
information extraction (open IE) systems
are useful for question answering, infer-
ence, and other IE tasks. Traditionally
these are extracted using a large set of pat-
terns; however, this approach is brittle on
out-of-domain text and long-range depen-
dencies, and gives no insight into the sub-
structure of the arguments. We replace this
large pattern set with a few patterns for
canonically structured sentences, and shift
the focus to a classifier which learns to
extract self-contained clauses from longer
sentences. We then run natural logic infer-
ence over these short clauses to determine
the maximally specific arguments for each
candidate triple. We show that our ap-
proach outperforms a state-of-the-art open
IE system on the end-to-end TAC-KBP
2013 Slot Filling task.
</bodyText>
<sectionHeader confidence="0.999514" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999861764705882">
Open information extraction (open IE) has been
shown to be useful in a number of NLP tasks, such
as question answering (Fader et al., 2014), rela-
tion extraction (Soderland et al., 2010), and infor-
mation retrieval (Etzioni, 2011). Conventionally,
open IE systems search a collection of patterns
over either the surface form or dependency tree
of a sentence. Although a small set of patterns
covers most simple sentences (e.g., subject verb
object constructions), relevant relations are often
spread across clauses (see Figure 1) or presented
in a non-canonical form.
Systems like Ollie (Mausam et al., 2012) ap-
proach this problem by using a bootstrapping
method to create a large corpus of broad-coverage
partially lexicalized patterns. Although this is
effective at capturing many of these patterns, it
</bodyText>
<note confidence="0.472024">
Born in Honolulu, Hawaii, Obama is a US Citizen.
</note>
<author confidence="0.48982">
Our System Ollie
</author>
<affiliation confidence="0.35586675">
(Obama; is; US citizen) (Obama; is; a US citizen)
(Obama; born in; (Obama; be born in; Honolulu)
Honolulu, Hawaii) (Honolulu; be born in; Hawaii)
(Obama; is citizen of; US)
</affiliation>
<figure confidence="0.1066494">
Friends give true praise.
Enemies give fake praise.
Our System Ollie
(friends; give; true praise) (friends; give; true praise)
(friends; give; praise)
(enemies; give; fake praise) (enemies; give; fake praise)
Heinz Fischer of Austria visits the US
Our System Ollie
(Heinz Fischer; visits; US) (Heinz Fischer of Austria;
visits; the US)
</figure>
<figureCaption confidence="0.6734888">
Figure 1: Open IE extractions produced by
the system, alongside extractions from the state-
of-the-art Ollie system. Generating coherent
clauses before applying patterns helps reduce false
matches such as (Honolulu; be born in; Hawaii).
</figureCaption>
<bodyText confidence="0.993779">
Inference over the sub-structure of arguments, in
turn, allows us to drop unnecessary information
(e.g., of Austria), but only when it is warranted
(e.g., keep fake in fake praise).
can lead to unintuitive behavior on out-of-domain
text. For instance, while Obama is president is
extracted correctly by Ollie as (Obama; is; pres-
ident), replacing is with are in cats are felines
produces no extractions. Furthermore, existing
systems struggle at producing canonical argument
forms – for example, in Figure 1 the argument
Heinz Fischer of Austria is likely less useful for
downstream applications than Heinz Fischer.
In this paper, we shift the burden of extracting
informative and broad coverage triples away from
this large pattern set. Rather, we first pre-process
the sentence in linguistically motivated ways to
produce coherent clauses which are (1) logically
</bodyText>
<page confidence="0.979571">
344
</page>
<note confidence="0.978246666666667">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 344–354,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999713392156863">
entailed by the original sentence, and (2) easy to
segment into open IE triples. Our approach con-
sists of two stages: we first learn a classifier for
splitting a sentence into shorter utterances (Sec-
tion 3), and then appeal to natural logic (S´anchez
Valencia, 1991) to maximally shorten these utter-
ances while maintaining necessary context (Sec-
tion 4.1). A small set of 14 hand-crafted patterns
can then be used to segment an utterance into an
open IE triple.
We treat the first stage as a greedy search prob-
lem: we traverse a dependency parse tree recur-
sively, at each step predicting whether an edge
should yield an independent clause. Importantly,
in many cases naively yielding a clause on a de-
pendency edge produces an incomplete utterance
(e.g., Born in Honolulu, Hawaii, from Figure 1).
These are often attributable to control relation-
ships, where either the subject or object of the
governing clause controls the subject of the sub-
ordinate clause. We therefore allow the produced
clause to sometimes inherit the subject or object
of its governor. This allows us to capture a large
variety of long range dependencies with a concise
classifier.
From these independent clauses, we then extract
shorter sentences, which will produce shorter ar-
guments more likely to be useful for downstream
applications. A natural framework for solving this
problem is natural logic – a proof system built on
the syntax of human language (see Section 4.1).
We can then observe that Heinz Fischer of Aus-
tria visits China entails that Heinz Fischer visits
China. On the other hand, we respect situations
where it is incorrect to shorten an argument. For
example, No house cats have rabies should not en-
tail that cats have rabies, or even that house cats
have rabies.
When careful attention to logical validity is nec-
essary – such as textual entailment – this approach
captures even more subtle phenomena. For exam-
ple, whereas all rabbits eat fresh vegetables yields
(rabbits; eat; vegetables), the apparently similar
sentence all young rabbits drink milk does not
yield (rabbits; drink; milk).
We show that our new system performs well on
a real world evaluation – the TAC KBP Slot Filling
challenge (Surdeanu, 2013). We outperform both
an official submission on open IE, and a baseline
of replacing our extractor with Ollie, a state-of-
the-art open IE systems.
</bodyText>
<sectionHeader confidence="0.999786" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99997838">
There is a large body of work on open information
extraction. One line of work begins with Text-
Runner (Yates et al., 2007) and ReVerb (Fader
et al., 2011), which make use of computation-
ally efficient surface patterns over tokens. With
the introduction of fast dependency parsers, Ol-
lie (Mausam et al., 2012) continues in the same
spirit but with learned dependency patterns, im-
proving on the earlier WOE system (Wu and Weld,
2010). The Never Ending Language Learning
project (Carlson et al., 2010) has a similar aim,
iteratively learning more facts from the internet
from a seed set of examples. Exemplar (Mesquita
et al., 2013) adapts the open IE framework to n-
ary relationships similar to semantic role labeling,
but without the expensive machinery.
Open IE triples have been used in a number
of applications – for example, learning entail-
ment graphs for new triples (Berant et al., 2011),
and matrix factorization for unifying open IE and
structured relations (Yao et al., 2012; Riedel et
al., 2013). In each of these cases, the concise ex-
tractions provided by open IE allow for efficient
symbolic methods for entailment, such as Markov
logic networks or matrix factorization.
Prior work on the KBP challenge can be cate-
gorized into a number of approaches. The most
common of these are distantly supervised relation
extractors (Craven and Kumlien, 1999; Wu and
Weld, 2007; Mintz et al., 2009; Sun et al., 2011),
and rule based systems (Soderland, 1997; Grish-
man and Min, 2010; Chen et al., 2010). However,
both of these approaches require careful tuning to
the task, and need to be trained explicitly on the
KBP relation schema. Soderland et al. (2013) sub-
mitted a system to KBP making use of open IE re-
lations and an easily constructed mapping to KBP
relations; we use this as a baseline for our empiri-
cal evaluation.
Prior work has used natural logic for RTE-style
textual entailment, as a formalism well-suited for
formal semantics in neural networks, and as a
framework for common-sense reasoning (Mac-
Cartney and Manning, 2009; Watanabe et al.,
2012; Bowman et al., 2014; Angeli and Manning,
2013). We adopt the precise semantics of Icard
and Moss (2014). Our approach of finding short
entailments from a longer utterance is similar in
spirit to work on textual entailment for informa-
tion extraction (Romano et al., 2006).
</bodyText>
<page confidence="0.997407">
345
</page>
<figure confidence="0.895787041666667">
vmod
Born in a small town, she took the midnight train going anywhere.
she Born in a small town
dobj
prep in
vmod dobj
det
amod
nsubj
det
nn
nsubj
det
amod
prep in
(input) (extracted clause)
↓ ↓
she took the midnight train going anywhere she took the midnight train she Born in small town
Born in a small town, she took the midnight train she took midnight train she Born in a town
Born in a town, she took the midnight train ... she Born in town
↓ ↓
(she; born in; small town)
(she; took; midnight train)
(she; born in; town)
</figure>
<figureCaption confidence="0.8772165">
Figure 2: An illustration of our approach. From left to right, a sentence yields a number of independent
clauses (e.g., she Born in a small town – see Section 3). From top to bottom, each clause produces a set
of entailed shorter utterances, and segments the ones which match an atomic pattern into a relation triple
(see Section 4.1).
</figureCaption>
<sectionHeader confidence="0.996003" genericHeader="method">
3 Inter-Clause Open IE
</sectionHeader>
<bodyText confidence="0.999955666666667">
In the first stage of our method, we produce a set
of self-contained clauses from a longer utterance.
Our objective is to produce a set of clauses which
can stand on their own syntactically and seman-
tically, and are entailed by the original sentence
(see Figure 2). Note that this task is not specific to
extracting open IE triples. Conventional relation
extractors, entailment systems, and other NLP ap-
plications may also benefit from such a system.
We frame this task as a search problem. At a
given node in the parse tree, we classify each out-
going arc e = p →−l c, from the governor p to a de-
pendent c with [collapsed] Stanford Dependency
label l, into an action to perform on that arc. Once
we have chosen an action to take on that arc, we
can recurse on the dependent node. We decom-
pose the action into two parts: (1) the action to
take on the outgoing edge e, and (2) the action
to take on the governor p. For example, in our
motivating example, we are considering the arc:
e = took vmod −−−→ born. In this case, the correct
action is to (1) yield a new clause rooted at born,
and (2) interpret the subject of born as the subject
of took.
We proceed to describe this action space in
more detail, followed by an explanation of our
training data, and finally our classifier.
</bodyText>
<subsectionHeader confidence="0.99949">
3.1 Action Space
</subsectionHeader>
<bodyText confidence="0.92006772">
The three actions we can perform on a dependency
edge are:
Yield Yields a new clause on this depen-
dency arc. A canonical case of this action is
the arc suggest ccomp
−−−−→ brush in Dentists suggest
that you should brush your teeth, yielding you
should brush your teeth.
Recurse Recurse on this dependency arc, but
do not yield it as a new clause. For example,
in the sentence faeries are dancing in the field
where I lost my bike, we must recurse through
the intermediate constituent the field where I lost
my bike – which itself is not relevant – to get to
the clause of interest: I lost my bike.
Stop Do not recurse on this arc, as the subtree
under this arc is not entailed by the parent sen-
tence. This is the case, for example, for most
leaf nodes (furry cats are cute should not entail
the clause furry), and is an important action for
the efficiency of the algorithm.
With these three actions, a search path through
the tree becomes a sequence of Recurse and
Yield actions, terminated by a Stop action (or leaf
node). For example, a search sequence A Recurse −−−−−→
</bodyText>
<figure confidence="0.79521625">
B Yield −−−→ C Stop
−−−→ D would yield a clause rooted
at C. A sequence A Yield −−−→ B Yield −−−→ C Stop
−−−→ D
</figure>
<bodyText confidence="0.999483333333333">
would yield clauses rooted at both B and C. Find-
ing all such sequences is in general exponential in
the size of the tree. In practice, during training we
run breadth first search to collect the first 10 000
sequences. During inference we run uniform cost
search until our classifier predictions fall below a
</bodyText>
<page confidence="0.994971">
346
</page>
<bodyText confidence="0.998581666666667">
given threshold.
For the Stop action, we do not need to further
specify an action to take on the parent node. How-
ever, for both of the other actions, it is often the
case that we would like to capture a controller in
the higher clause. We define three such common
actions:
Subject Controller If the arc we are consider-
ing is not already a subject arc, we can copy the
subject of the parent node and attach it as a sub-
ject of the child node. This is the action taken in
the example Born in a small town, she took the
midnight train.
Object Controller Analogous to the subject
controller action above, but taking the object in-
stead. This is the intended action for examples
like I persuaded Fred to leave the room.1
Parent Subject If the arc we are taking is the
only outgoing arc from a node, we take the par-
ent node as the (passive) subject of the child.
This is the action taken in the example Obama,
our 44th president to yield a clause with the se-
mantics of Obama [is] our 44th president.
Although additional actions are easy to imagine,
we found empirically that these cover a wide range
of applicable cases. We turn our attention to the
training data for learning these actions.
</bodyText>
<subsectionHeader confidence="0.998629">
3.2 Training
</subsectionHeader>
<bodyText confidence="0.999960684210526">
We collect a noisy dataset to train our clause gen-
eration model. We leverage the distant supervision
assumption for relation extraction, which creates a
noisy corpus of sentences annotated with relation
mentions (subject and object spans in the sentence
with a known relation). Then, we take this anno-
tation as itself distant supervision for a correct se-
quence of actions to take: any sequence which re-
covers the known relation is correct.
We use a small subset of the KBP source doc-
uments for 2010 (Ji et al., 2010) and 2013 (Sur-
deanu, 2013) as our distantly supervised corpus.
To try to maximize the density of known relations
in the training sentences, we take all sentences
which have at least one known relation for ev-
ery 10 tokens in the sentence, resulting in 43155
sentences. In addition, we incorporate the 23 725
manually annotated examples from Angeli et al.
(2014).
</bodyText>
<footnote confidence="0.725491">
1The system currently misses most most such cases due
to insufficient support in the training data.
</footnote>
<bodyText confidence="0.999985837837838">
Once we are given a collection of labeled sen-
tences, we assume that a sequence of actions
which leads to a correct extraction of a known
relation is a positive sequence. A correct ex-
traction is any extraction we produce from our
model (see Section 4) which has the same argu-
ments as the known relation. For instance, if we
know that Obama was born in Hawaii from the
sentence Born in Hawaii, Obama ..., and an ac-
tion sequence produces the triple (Obama, born in,
Hawaii), then we take that action sequence as a
positive sequence.
Any sequence of actions which results in a
clause which produces no relations is in turn con-
sidered a negative sequence. The third case to con-
sider is a sequence of actions which produces a
relation, but it is not one of the annotated rela-
tions. This arises from the incomplete negatives
problem in distantly supervised relation extraction
(Min et al., 2013): since our knowledge base is
not exhaustive, we cannot be sure if an extracted
relation is incorrect or correct but previously un-
known. Although many of these unmatched re-
lations are indeed incorrect, the dataset is suffi-
ciently biased towards the STOP action that the
occasional false negative hurts end-to-end perfor-
mance. Therefore, we simply discard such se-
quences.
Given a set of noisy positive and negative se-
quences, we construct training data for our action
classifier. All but the last action in a positive se-
quence are added to the training set with the label
Recurse; the last action is added with the label
Split. Only the last action in a negative sequence
is added with the label Stop. We partition the fea-
ture space of our dataset according to the action
applied to the parent node.
</bodyText>
<subsectionHeader confidence="0.954936">
3.3 Inference
</subsectionHeader>
<bodyText confidence="0.999750166666667">
We train a multinomial logistic regression classi-
fier on our noisy training data, using the features
in Table 1. The most salient features are the label
of the edge being taken, the incoming edge to the
parent of the edge being taken, neighboring edges
for both the parent and child of the edge, and the
part of speech tag of the endpoints of the edge.
The dataset is weighted to give 3× weight to ex-
amples in the Recurse class, as precision errors
in this class are relatively harmless for accuracy,
while recall errors are directly harmful to recall.
Inference now reduces to a search problem. Be-
</bodyText>
<page confidence="0.989889">
347
</page>
<subsectionHeader confidence="0.723884">
Feature Class Feature Templates
</subsectionHeader>
<bodyText confidence="0.863893">
Edge taken {l, short name(l)}
Last edge taken {incoming edge(p)}
Neighbors of parent {nbr(p), (p, nbr(p))}
</bodyText>
<equation confidence="0.80350625">
Grandchild edges {out edge(c),
(e, out edge(c))}
Grandchild count {count (nbr(echild))
(e, count (nbr(echild)))}
Has subject/object ∀eCJe,echild}∀lCJsubj,obj}
✶(l ∈ nbr(e))
POS tag signature {pos(p), pos(c),
(pos(p), pos(c))}
</equation>
<table confidence="0.427297">
Features at root {✶(p = root), POS(p)}
</table>
<tableCaption confidence="0.964987">
Table 1: Features for the clause splitter model, de-
</tableCaption>
<bodyText confidence="0.99990576">
ciding to split on the arc e = p l → c. The fea-
ture class is a high level description of features;
the feature templates are the particular templates
used. For instance, the POS signature contains the
tag of the parent, the tag of the child, and both tags
joined in a single feature. Note that all features are
joined with the action to be taken on the parent.
ginning at the root of the tree, we consider every
outgoing edge. For every possible action to be
performed on the parent (i.e., clone subject, clone
root, no action), we apply our trained classifier to
determine whether we (1) split the edge off as a
clause, and recurse; (2) do not split the edge, and
recurse; or (3) do not recurse. In the first two
cases, we recurse on the child of the arc, and con-
tinue until either all arcs have been exhausted, or
all remaining candidate arcs have been marked as
not recursable.
We will use the scores from this classifier to
inform the score assigned to our generated open
IE extractions (Section 4). The score of a clause
is the product of the scores of actions taken to
reach the clause. The score of an extraction will
be this score multiplied by the score of the extrac-
tion given the clause.
</bodyText>
<sectionHeader confidence="0.999089" genericHeader="method">
4 Intra-Clause Open IE
</sectionHeader>
<bodyText confidence="0.999989769230769">
We now turn to the task of generating a maximally
compact sentence which retains the core seman-
tics of the original utterance, and parsing the sen-
tence into a conventional open IE subject verb ob-
ject triple. This is often a key component in down-
stream applications, where extractions need to be
not only correct, but also informative. Whereas
an argument like Heinz Fischer of Austria is often
correct, a downstream application must apply fur-
ther processing to recover information about either
Heinz Fischer, or Austria. Moreover, it must do so
without the ability to appeal to the larger context
of the sentence.
</bodyText>
<subsectionHeader confidence="0.989753">
4.1 Validating Deletions with Natural Logic
</subsectionHeader>
<bodyText confidence="0.993644195121951">
We adopt a subset of natural logic semantics dic-
tating contexts in which lexical items can be re-
moved. Natural logic as a formalism captures
common logical inferences appealing directly to
the form of language, rather than parsing to a spe-
cialized logical syntax. It provides a proof theory
for lexical mutations to a sentence which either
preserve or negate the truth of the premise.
For instance, if all rabbits eat vegetables then
all cute rabbits eat vegetables, since we are al-
lowed to mutate the lexical item rabbit to cute
rabbit. This is done by observing that rabbit is
in scope of the first argument to the operator all.
Since all induces a downward polarity environ-
ment for its first argument, we are allowed to re-
place rabbit with an item which is more specific –
in this case cute rabbit. To contrast, the operator
some induces an upward polarity environment for
its first argument, and therefore we may derive the
inference from cute rabbit to rabbit in: some cute
rabbits are small therefore some rabbits are small.
For a more comprehensive introduction to natural
logic, see van Benthem (2008).
We mark the scopes of all operators (all, no,
many, etc.) in a sentence, and from this deter-
mine whether every lexical item can be replaced
by something more general (has upward polarity),
more specific (downward polarity), or neither. In
the absence of operators, all items have upwards
polarity.
Each dependency arc is then classified into
whether deleting the dependent of that arc makes
the governing constituent at that node more
general, more specific (a rare case), or nei-
ther.2 For example, removing the amod edge in
cute ←−−− rabbit yields the more general lexical
amod
item rabbit. However, removing the nsubj edge in
Fidonsubj ←−−− runs would yield the unentailed (and
nonsensical) phrase runs. The last, rare, case is
an edge that causes the resulting item to be more
</bodyText>
<equation confidence="0.7915425">
specific – e.g., quantmod: aboutquantmod
←−−−−−− 200 is
</equation>
<bodyText confidence="0.717286">
more general than 200.
</bodyText>
<footnote confidence="0.934128">
2We use the Stanford Dependencies representation (de
Marneffe and Manning, 2008).
</footnote>
<page confidence="0.994784">
348
</page>
<bodyText confidence="0.968665297297297">
For most dependencies, this semantics can be
hard-coded with high accuracy. However, there
are at least two cases where more attention is war-
ranted. The first of these concerns non-subsective
adjectives: for example a fake gun is not a gun. For
this case, we make use of the list of non-subsective
adjectives collected in Nayak et al. (2014), and
prohibit their deletion as a hard constraint.
The second concern is with prepositional at-
tachment, and direct object edges. For example,
whereas Alice went to the playground prep with
−−−−−−→
Bob entails that Alice went to the playground, it
is not meaningful to infer that Alice is friends
prep with
−−−−−−→ Bob entails Alice is friends. Analo-
gously, Alice played dobj −−→ baseball on Sunday en-
tails that Alice played on Sunday; but, Obama
signed dobj −−→ the bill on Sunday should not entail
the awkward phrase *Obama signed on Sunday.
We learn these attachment affinities empirically
from the syntactic n-grams corpus of Goldberg
and Orwant (2013). This gives us counts for how
often object and preposition edges occur in the
context of the governing verb and relevant neigh-
boring edges. We hypothesize that edges which
are frequently seen to co-occur are likely to be
essential to the meaning of the sentence. To this
end, we compute the probability of seeing an arc
of a given type, conditioned on the most specific
context we have statistics for. These contexts, and
the order we back off to more general contexts, is
given in Figure 3.
To compute a score s of deleting the edge from
the affinity probability p collected from the syn-
tactic n-grams, we simply cap the affinity and sub-
tract it from 1:
</bodyText>
<equation confidence="0.769853">
s= 1−min(1, pK)
</equation>
<bodyText confidence="0.999941142857143">
where K is a hyperparameter denoting the mini-
mum fraction of the time an edge should occur in
a context to be considered entirely unremovable.
In our experiments, we set K = 13.
The score of an extraction, then, is the product
of the scores of each deletion multiplied by the
score from the clause splitting step in Section 3.
</bodyText>
<subsectionHeader confidence="0.991029">
4.2 Atomic Patterns
</subsectionHeader>
<bodyText confidence="0.9808378">
Once a set of short entailed sentences is produced,
it becomes straightforward to segment them into
conventional open IE triples. We employ 6 sim-
ple dependency patterns, given in Table 2, which
Obama signed the bill into law on Friday
</bodyText>
<figure confidence="0.61200325">
� nsubj dobj �
{ p prep on  |Obama signed bill
� nsubj prep into �
p prep on  |Obama signed law
� nsubj �
p prep on  |Obama signed
� �
p prep on  |signed
�� nsubj dobj �
p dobj  |Obama signed bill
� �
p dobj  |signed
</figure>
<figureCaption confidence="0.986701">
Figure 3: The ordered list of backoff probabilities
</figureCaption>
<bodyText confidence="0.913759142857143">
when deciding to drop a prepositional phrase or di-
rect object. The most specific context is chosen for
which an empirical probability exists; if no con-
text is found then we allow dropping prepositional
phrases and disallow dropping direct objects. Note
that this backoff arbitrarily orders contexts of the
same size.
</bodyText>
<subsectionHeader confidence="0.532384">
Input Extraction
</subsectionHeader>
<equation confidence="0.5849315">
(cats; play with; yarn)
(fish; like to; swim)
(cats; have; tails)
(cats; are; cute)
</equation>
<tableCaption confidence="0.8422005">
Tom and Jerry are fighting
There are cats with tails
Table 2: The six dependency patterns used to seg-
ment an atomic sentence into an open IE triple.
</tableCaption>
<bodyText confidence="0.990739230769231">
cover the majority of atomic relations we are in-
terested in.
When information is available to disambiguate
the substructure of compound nouns (e.g., named
entity segmentation), we extract additional re-
lations with 5 dependency and 3 TokensRegex
(Chang and Manning, 2014) surface form patterns.
These are given in Table 3; we refer to these
as nominal relations. Note that the constraint of
named entity information is by no means required
for the system. In other applications – for exam-
ple, applications in vision – the otherwise trivial
nominal relations could be quite useful.
</bodyText>
<figure confidence="0.997050714285714">
prep on
prep into
dobj
nsubj
det
prep backoff
dobj backoff
</figure>
<figureCaption confidence="0.965482833333334">
cats play with yarn
fish like to swim
cats have tails
cats are cute
(Tom; fighting; Jerry)
(cats; have; tails)
</figureCaption>
<page confidence="0.929655">
349
</page>
<figure confidence="0.956943428571429">
KBP Relation
Org:Founded
Org:Dissolved
Org:LOC Of HQ
Org:Member Of
Org:Parents
Org:Founded By
</figure>
<table confidence="0.989345807692308">
Open IE Relation PMI2
found in 1.17
be found in 1.15
*buy Chrysler in 0.95
*membership in 0.60
in 2.12
base in 1.82
*tough away game in 1.80
*away game in 1.80
’s bank 1.65
*also add to 1.52
invest fund of 1.48
own stake besides 1.18
KBP Relation Open IE Relation PMI2
Per:Date Of Birth be bear on 1.83
bear on 1.28
Per:Date Of Death die on 0.70
be assassinate on 0.65
Per:LOC Of Birth be bear in 1.21
Per:LOC Of Death *elect president of 2.89
Per:Religion speak about 0.67
popular for 0.60
Per:Parents daughter of 0.54
son of 1.52
Per:LOC Residence of 1.48
*independent from 1.18
</table>
<tableCaption confidence="0.876079333333333">
Table 4: A selection of the mapping from KBP to lemmatized open IE relations, conditioned on the types
of the arguments being correct. The top one or two relations are shown for 7 person and 6 organization
relations. Incorrect or dubious mappings are marked with an asterisk.
</tableCaption>
<figure confidence="0.683644">
Input Extraction
</figure>
<figureCaption confidence="0.87202875">
(Durin; is son of; Thorin)
(Thorin; ’s son; Durin)
(Rometty; is CEO of; IBM)
(Obama; is; President)
(Fischer; is of; Austria)
(IBM; ’s; research group)
(Obama; president of; US)
(Our president; be; Obama)
</figureCaption>
<tableCaption confidence="0.761563">
Table 3: The eight patterns used to segment a noun
</tableCaption>
<bodyText confidence="0.897890666666667">
phrase into an open IE triple. The first five are de-
pendency patterns; the last three are surface pat-
terns.
</bodyText>
<sectionHeader confidence="0.951276" genericHeader="method">
5 Mapping OpenIE to a Known Relation
Schema
</sectionHeader>
<bodyText confidence="0.99993575">
A common use case for open IE systems is to map
them to a known relation schema. This can either
be done manually with minimal annotation effort,
or automatically from available training data. We
use both methods in our TAC-KBP evaluation. A
collection of relation mappings was constructed
by a single annotator in approximately a day,3 and
a relation mapping was learned using the proce-
dure described in this section.
We map open IE relations to the KBP schema
by searching for co-occurring relations in a large
distantly-labeled corpus, and marking open IE and
</bodyText>
<footnote confidence="0.5427595">
3The official submission we compare against claimed two
weeks for constructing their manual mapping, although a ver-
sion of their system constructed in only 3 hours performs
nearly as well.
</footnote>
<bodyText confidence="0.998844181818182">
KBP relation pairs which have a high PMI2 value
(B´eatrice, 1994; Evert, 2005) conditioned on their
type signatures matching. To compute PMI2, we
collect probabilities for the open IE and KBP re-
lation co-occurring, the probability of the open IE
relation occurring, and the probability of the KBP
relation occurring. Each of these probabilities is
conditioned on the type signature of the relation.
For example, the joint probability of KBP relation
rk and open IE relation ro, given a type signature
of t1, t2, would be
</bodyText>
<equation confidence="0.989953">
count(rk, ro, t1, t2)
p(rk, ro  |t1, t2) =
r�k,r�o
count(rk, ro, t1, t2)
</equation>
<bodyText confidence="0.99993825">
Omitting the conditioning on the type signature
for notational convenience, and defining p(rk) and
p(ro) analogously, we can then compute The PMI2
value between the two relations:
</bodyText>
<equation confidence="0.986173333333333">
PMI2
( p(rk, 2 l
(rk, ro) = log \p( rk) ? p(ro) /
</equation>
<bodyText confidence="0.999541416666667">
Note that in addition to being a measure
related to PMI, this captures a notion simi-
lar to alignment by agreement (Liang et al.,
2006); the formula can be equivalently written
as log [p(rk  |ro)p(ro  |rk)]. It is also function-
ally the same as the JC WordNet distance measure
(Jiang and Conrath, 1997).
Some sample type checked relation mappings
are given in Table 4. In addition to intuitive map-
pings (e.g., found in → Org:Founded), we can note
some rare, but high precision pairs (e.g., invest
fund of → Org:Founded By). We can also see
</bodyText>
<table confidence="0.36459625">
Durin, son of Thorin
Thorin’s son, Durin
IBM CEO Rometty
President Obama
Fischer of Austria
IBM’s research group
US president Obama
Our president, Obama,
</table>
<page confidence="0.987738">
350
</page>
<bodyText confidence="0.97998975">
the noise in distant supervision occasionally per-
meate the mapping, e.g., with elect president of →
Per:LOC Of Death – a president is likely to die in
his own country.
</bodyText>
<sectionHeader confidence="0.995844" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.99998695">
We evaluate our approach in the context of a real-
world end-to-end relation extraction task – the
TAC KBP Slot Filling challenge. In Slot Filling,
we are given a large unlabeled corpus of text, a
fixed schema of relations (see Section 5), and a
set of query entities. The task is to find all rela-
tion triples in the corpus that have as a subject the
query entity, and as a relation one of the defined
relations. This can be viewed intuitively as popu-
lating Wikipedia Infoboxes from a large unstruc-
tured corpus of text.
We compare our approach to the University
of Washington submission to TAC-KBP 2013
(Soderland et al., 2013). Their system used
OpenIE v4.0 (a successor to Ollie) run over the
KBP corpus and then they generated a mapping
from the extracted relations to the fixed schema.
Unlike our system, Open IE v4.0 employs a se-
mantic role component extracting structured SRL
frames, alongside a conventional open IE system.
Furthermore, the UW submission allows for ex-
tracting relations and entities from substrings of
an open IE triple argument. For example, from
the triple (Smith; was appointed; acting director of
Acme Corporation), they extract that Smith is em-
ployed by Acme Corporation. We disallow such
extractions, passing the burden of finding correct
precise extractions to the open IE system itself (see
Section 4).
For entity linking, the UW submission uses Tom
Lin’s entity linker (Lin et al., 2012); our sub-
mission uses the Illinois Wikifier (Ratinov et al.,
2011) without the relational inference component,
for efficiency. For coreference, UW uses the Stan-
ford coreference system (Lee et al., 2011); we em-
ploy a variant of the simple coref system described
in (Pink et al., 2014).
We report our results in Table 5.4 UW Offi-
cial refers to the official submission in the 2013
challenge; we show a 3.1 F1 improvement (to 22.7
</bodyText>
<footnote confidence="0.997527166666667">
4All results are reported with the anydoc flag set to true
in the evaluation script, meaning that only the truth of the
extracted knowledge base entry and not the associated prove-
nance is scored. In absence of human evaluators, this is in
order to not penalize our system unfairly for extracting a new
correct provenance.
</footnote>
<table confidence="0.999954777777778">
System P R F1
UW Official* 69.8 11.4 19.6
Ollie† 57.4 4.8 8.9
+ Nominal Rels* 57.7 11.8 19.6
Our System
- Nominal Rels† 64.3 8.6 15.2
+ Nominal Rels* 61.9 13.9 22.7
+ Alt. Name 57.8 17.8 27.1
+ Alt. Name + Website 58.6 18.6 28.3
</table>
<tableCaption confidence="0.996572">
Table 5: A summary of our results on the end-
</tableCaption>
<bodyText confidence="0.986258361111111">
to-end KBP Slot Filling task. UW official is the
submission made to the 2013 challenge. The sec-
ond row is the accuracy of Ollie embedded in
our framework, and of Ollie evaluated with nom-
inal relations from our system. Lastly, we report
our system, our system with nominal relations re-
moved, and our system combined with an alternate
names detector and rule-based website detector.
Comparable systems are marked with a dagger† or
asterisk*.
F1) over this submission, evaluated using a com-
parable approach. A common technique in KBP
systems but not employed by the official UW sub-
mission in 2013 is to add alternate names based
on entity linking and coreference. Additionally,
websites are often extracted using heuristic name-
matching as they are hard to capture with tradi-
tional relation extraction techniques. If we make
use of both of these, our end-to-end accuracy be-
comes 28.2 F1.
We attempt to remove the variance in scores
from the influence of other components in an end-
to-end KBP system. We ran the Ollie open IE sys-
tem (Mausam et al., 2012) in an identical frame-
work to ours, and report accuracy in Table 5. Note
that when an argument to an Ollie extraction con-
tains a named entity, we take the argument to be
that named entity. The low performance of this
system can be partially attributed to its inability to
extract nominal relations. To normalize for this,
we report results when the Ollie extractions are
supplemented with the nominal relations produced
by our system (Ollie + Nominal Rels in Table 5).
Conversely, we can remove the nominal relation
extractions from our system; in both cases we out-
perform Ollie on the task.
</bodyText>
<page confidence="0.989169">
351
</page>
<figure confidence="0.9983635">
0.8
0.6
0.4
0.2
0.00.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14
Recall
</figure>
<figureCaption confidence="0.868422">
Figure 4: A precision/recall curve for Ollie and
our system (without nominals). For clarity, recall
is plotted on a range from 0 to 0.15.
</figureCaption>
<subsectionHeader confidence="0.90834">
6.1 Discussion
</subsectionHeader>
<bodyText confidence="0.999988537037037">
We plot a precision/recall curve of our extractions
in Figure 4 in order to get an informal sense of
the calibration of our confidence estimates. Since
confidences only apply to standard extractions, we
plot the curves without including any of the nom-
inal relations. The confidence of a KBP extrac-
tion in our system is calculated as the sum of the
confidences of the open IE extractions that support
it. So, for instance, if we find (Obama; be bear
in; Hawaii) n times with confidences ci ... cn,
the confidence of the KBP extraction would be
Eni=0 ci. It is therefore important to note that
the curve in Figure 4 necessarily conflates the
confidences of individual extractions, and the fre-
quency of an extraction.
With this in mind, the curves lend some inter-
esting insights. Although our system is very high
precision on the most confident extractions, it has
a large dip in precision early in the curve. This
suggests that the model is extracting multiple in-
stances of a bad relation. Systematic errors in
the clause splitter are the likely cause of these er-
rors. While the approach of splitting sentences
into clauses generalizes better to out-of-domain
text, it is reasonable that the errors made in the
clause splitter manifest across a range of sentences
more often than the fine-grained patterns of Ollie
would.
On the right half of the PR curve, however, our
system achieves both higher precision and extends
to a higher recall than Ollie. Furthermore, the
curve is relatively smooth near the tail, suggesting
that indeed we are learning a reasonable estimate
of confidence for extractions that have only one
supporting instance in the text – empirically, 46%
of our extractions.
In total, we extract 42 662 862 open IE triples
which link to a pair of entities in the corpus
(i.e., are candidate KBP extractions), covering
1180 770 relation types. 202 797 of these rela-
tion types appear in more than 10 extraction in-
stances; 28 782 in more than 100 instances, and
4079 in more than 1000 instances. 308 293 rela-
tion types appear only once. Note that our system
over-produces extractions when both a general and
specific extraction are warranted; therefore these
numbers are an overestimate of the number of se-
mantically meaningful facts.
For comparison, Ollie extracted 12 274 319
triples, covering 2 873 239 relation types.
1983 300 of these appeared only once; 69 010
appeared in more than 10 instances, 7951 in more
than 100 instances, and 870 in more than 1000
instances.
</bodyText>
<sectionHeader confidence="0.99901" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999978">
We have presented a system for extracting open
domain relation triples by breaking a long sen-
tence into short, coherent clauses, and then find-
ing the maximally simple relation triples which are
warranted given each of these clauses. This allows
the system to have a greater awareness of the con-
text of each extraction, and to provide informative
triples to downstream applications. We show that
our approach performs well on one such down-
stream application: the KBP Slot Filling task.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999565230769231">
We thank the anonymous reviewers for their
thoughtful feedback. Stanford University grate-
fully acknowledges the support of a Natural Lan-
guage Understanding-focused gift from Google
Inc. and the Defense Advanced Research Projects
Agency (DARPA) Deep Exploration and Filter-
ing of Text (DEFT) Program under Air Force Re-
search Laboratory (AFRL) contract no. FA8750-
13-2-0040. Any opinions, findings, and conclu-
sion or recommendations expressed in this mate-
rial are those of the authors and do not necessarily
reflect the view of the DARPA, AFRL, or the US
government.
</bodyText>
<figure confidence="0.9754745">
Ollie
Our System (without nominals)
Precision
1.0
</figure>
<page confidence="0.991258">
352
</page>
<sectionHeader confidence="0.995665" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999691441176471">
Gabor Angeli and Christopher D. Manning. 2013.
Philosophers are mortal: Inferring the truth of un-
seen facts. In CoNLL.
Gabor Angeli, Julie Tibshirani, Jean Y. Wu, and
Christopher D. Manning. 2014. Combining dis-
tant and partial supervision for relation extraction.
In EMNLP.
DAILLE B´eatrice. 1994. Approche mixte pour
l’extraction automatique de terminologie: statis-
tique lexicale et filtres linguistiques. Ph.D. thesis,
Th`ese de Doctorat. Universit´e de Paris VII.
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2011. Global learning of typed entailment rules. In
Proceedings of ACL, Portland, OR.
Samuel R. Bowman, Christopher Potts, and Christo-
pher D. Manning. 2014. Recursive neural
networks can learn logical semantics. CoRR,
(arXiv:1406.1827).
Andrew Carlson, Justin Betteridge, Bryan Kisiel,
Burr Settles, Estevam R Hruschka Jr, and Tom M
Mitchell. 2010. Toward an architecture for never-
ending language learning. In AAAI.
Angel X. Chang and Christopher D. Manning. 2014.
TokensRegex: Defining cascaded regular expres-
sions over tokens. Technical Report CSTR 2014-02,
Department of Computer Science, Stanford Univer-
sity.
Zheng Chen, Suzanne Tamang, Adam Lee, Xiang
Li, Wen-Pin Lin, Matthew Snover, Javier Artiles,
Marissa Passantino, and Heng Ji. 2010. CUNY-
BLENDER. In TAC-KBP.
Mark Craven and Johan Kumlien. 1999. Constructing
biological knowledge bases by extracting informa-
tion from text sources. In AAAI.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. The Stanford typed dependencies rep-
resentation. In Coling 2008: Proceedings of the
workshop on Cross-Framework and Cross-Domain
Parser Evaluation.
Oren Etzioni. 2011. Search needs a shake-up. Nature,
476(7358):25–26.
Stefan Evert. 2005. The statistics of word cooccur-
rences: word pairs and collocations. Ph.D. thesis,
Universit at Stuttgart.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In EMNLP.
Anthony Fader, Luke Zettlemoyer, and Oren Etzioni.
2014. Open question answering over curated and
extracted knowledge bases. In KDD.
Yoav Goldberg and Jon Orwant. 2013. A dataset of
syntactic-ngrams over time from a very large corpus
of english books. In *SEM.
Ralph Grishman and Bonan Min. 2010. New York
University KBP 2010 slot-filling system. In Proc.
TAC 2010 Workshop.
Thomas Icard, III and Lawrence Moss. 2014. Recent
progress on monotonicity. Linguistic Issues in Lan-
guage Technology.
Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2010. Overview of the tac 2010
knowledge base population track. In Third Text
Analysis Conference.
Jay J Jiang and David W Conrath. 1997. Semantic
similarity based on corpus statistics and lexical tax-
onomy. Proceedings of the 10th International Con-
ference on Research on Computational Linguistics.
Heeyoung Lee, Yves Peirsman, Angel Chang,
Nathanael Chambers, Mihai Surdeanu, and Dan Ju-
rafsky. 2011. Stanford’s multi-pass sieve corefer-
ence resolution system at the conll-2011 shared task.
In CoNLL Shared Task.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In NAACL-HLT.
Thomas Lin, Mausam, and Oren Etzioni. 2012. No
noun phrase left behind: detecting and typing un-
linkable entities. In EMNLP-CoNLL.
Bill MacCartney and Christopher D Manning. 2009.
An extended model of natural logic. In Proceedings
of the eighth international conference on computa-
tional semantics.
Mausam, Michael Schmitz, Robert Bart, Stephen
Soderland, and Oren Etzioni. 2012. Open language
learning for information extraction. In EMNLP.
Filipe Mesquita, Jordan Schmidek, and Denilson Bar-
bosa. 2013. Effectiveness and efficiency of open
relation extraction. In EMNLP.
Bonan Min, Ralph Grishman, Li Wan, Chang Wang,
and David Gondek. 2013. Distant supervision for
relation extraction with an incomplete knowledge
base. In NAACL-HLT.
Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extrac-
tion without labeled data. In ACL.
Neha Nayak, Mark Kowarsky, Gabor Angeli, and
Christopher D. Manning. 2014. A dictionary of
nonsubsective adjectives. Technical Report CSTR
2014-04, Department of Computer Science, Stan-
ford University, October.
Glen Pink, Joel Nothman, and R. James Curran. 2014.
Analysing recall loss in named entity slot filling. In
EMNLP.
</reference>
<page confidence="0.998219">
353
</page>
<note confidence="0.821375428571429">
Lev Ratinov, Dan Roth, Doug Downey, and Mike An-
derson. 2011. Local and global algorithms for dis-
ambiguation to wikipedia. In ACL.
Alexander Yates, Michael Cafarella, Michele Banko,
Oren Etzioni, Matthew Broadhead, and Stephen
Soderland. 2007. TextRunner: Open information
extraction on the web. In ACL-HLT.
</note>
<reference confidence="0.999812795918367">
Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M Marlin. 2013. Relation extraction
with matrix factorization and universal schemas. In
NAACL-HLT.
Lorenza Romano, Milen Kouylekov, Idan Szpektor,
Ido Dagan, and Alberto Lavelli. 2006. Investigat-
ing a generic paraphrase-based approach for relation
extraction. EACL.
V´ıctor Manuel S´anchez S´anchez Valencia. 1991. Stud-
ies on natural logic and categorial grammar. Ph.D.
thesis, University of Amsterdam.
Stephen Soderland, Brendan Roof, Bo Qin, Shi Xu,
Mausam, and Oren Etzioni. 2010. Adapting open
information extraction to domain-specific relations.
AI Magazine, 31(3):93–102.
Stephen Soderland, John Gilmer, Robert Bart, Oren Et-
zioni, and Daniel S. Weld. 2013. Open information
extraction to KBP relations in 3 hours. In Text Anal-
ysis Conference.
Stephen G Soderland. 1997. Learning text analysis
rules for domain-specific natural language process-
ing. Ph.D. thesis, University of Massachusetts.
Ang Sun, Ralph Grishman, Wei Xu, and Bonan Min.
2011. New York University 2011 system for KBP
slot filling. In Proceedings of the Text Analytics
Conference.
Mihai Surdeanu. 2013. Overview of the tac2013
knowledge base population evaluation: English slot
filling and temporal slot filling. In Sixth Text Analy-
sis Conference.
Johan van Benthem. 2008. A brief history of natural
logic. Technical Report PP-2008-05, University of
Amsterdam.
Yotaro Watanabe, Junta Mizuno, Eric Nichols, Naoaki
Okazaki, and Kentaro Inui. 2012. A latent discrim-
inative model for compositional entailment relation
recognition using natural logic. In COLING.
Fei Wu and Daniel S Weld. 2007. Autonomously se-
mantifying wikipedia. In Proceedings of the six-
teenth ACM conference on information and knowl-
edge management. ACM.
Fei Wu and Daniel S Weld. 2010. Open information
extraction using wikipedia. In ACL. Association for
Computational Linguistics.
Limin Yao, Sebastian Riedel, and Andrew McCal-
lum. 2012. Probabilistic databases of universal
schema. In Proceedings of the Joint Workshop on
Automatic Knowledge Base Construction and Web-
scale Knowledge Extraction.
</reference>
<page confidence="0.999146">
354
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.557312">
<title confidence="0.997016">Leveraging Linguistic Structure For Open Domain Information Extraction</title>
<author confidence="0.999834">Gabor Angeli Melvin Johnson Premkumar Christopher D Manning</author>
<affiliation confidence="0.9999415">Department of Computer Stanford University</affiliation>
<email confidence="0.922106">melvinj,</email>
<abstract confidence="0.979789857142857">Relation triples produced by open domain information extraction (open IE) systems are useful for question answering, inference, and other IE tasks. Traditionally these are extracted using a large set of patterns; however, this approach is brittle on out-of-domain text and long-range dependencies, and gives no insight into the substructure of the arguments. We replace this large pattern set with a few patterns for canonically structured sentences, and shift the focus to a classifier which learns to extract self-contained clauses from longer sentences. We then run natural logic inference over these short clauses to determine the maximally specific arguments for each candidate triple. We show that our approach outperforms a state-of-the-art open IE system on the end-to-end TAC-KBP 2013 Slot Filling task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gabor Angeli</author>
<author>Christopher D Manning</author>
</authors>
<title>Philosophers are mortal: Inferring the truth of unseen facts.</title>
<date>2013</date>
<booktitle>In CoNLL.</booktitle>
<contexts>
<context position="8272" citStr="Angeli and Manning, 2013" startWordPosition="1318" endWordPosition="1321"> Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 2012; Bowman et al., 2014; Angeli and Manning, 2013). We adopt the precise semantics of Icard and Moss (2014). Our approach of finding short entailments from a longer utterance is similar in spirit to work on textual entailment for information extraction (Romano et al., 2006). 345 vmod Born in a small town, she took the midnight train going anywhere. she Born in a small town dobj prep in vmod dobj det amod nsubj det nn nsubj det amod prep in (input) (extracted clause) ↓ ↓ she took the midnight train going anywhere she took the midnight train she Born in small town Born in a small town, she took the midnight train she took midnight train she Bor</context>
</contexts>
<marker>Angeli, Manning, 2013</marker>
<rawString>Gabor Angeli and Christopher D. Manning. 2013. Philosophers are mortal: Inferring the truth of unseen facts. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabor Angeli</author>
<author>Julie Tibshirani</author>
<author>Jean Y Wu</author>
<author>Christopher D Manning</author>
</authors>
<title>Combining distant and partial supervision for relation extraction.</title>
<date>2014</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="14254" citStr="Angeli et al. (2014)" startWordPosition="2417" endWordPosition="2420">th a known relation). Then, we take this annotation as itself distant supervision for a correct sequence of actions to take: any sequence which recovers the known relation is correct. We use a small subset of the KBP source documents for 2010 (Ji et al., 2010) and 2013 (Surdeanu, 2013) as our distantly supervised corpus. To try to maximize the density of known relations in the training sentences, we take all sentences which have at least one known relation for every 10 tokens in the sentence, resulting in 43155 sentences. In addition, we incorporate the 23 725 manually annotated examples from Angeli et al. (2014). 1The system currently misses most most such cases due to insufficient support in the training data. Once we are given a collection of labeled sentences, we assume that a sequence of actions which leads to a correct extraction of a known relation is a positive sequence. A correct extraction is any extraction we produce from our model (see Section 4) which has the same arguments as the known relation. For instance, if we know that Obama was born in Hawaii from the sentence Born in Hawaii, Obama ..., and an action sequence produces the triple (Obama, born in, Hawaii), then we take that action s</context>
</contexts>
<marker>Angeli, Tibshirani, Wu, Manning, 2014</marker>
<rawString>Gabor Angeli, Julie Tibshirani, Jean Y. Wu, and Christopher D. Manning. 2014. Combining distant and partial supervision for relation extraction. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DAILLE B´eatrice</author>
</authors>
<title>Approche mixte pour l’extraction automatique de terminologie: statistique lexicale et filtres linguistiques.</title>
<date>1994</date>
<booktitle>Ph.D. thesis, Th`ese de Doctorat. Universit´e de Paris VII.</booktitle>
<marker>B´eatrice, 1994</marker>
<rawString>DAILLE B´eatrice. 1994. Approche mixte pour l’extraction automatique de terminologie: statistique lexicale et filtres linguistiques. Ph.D. thesis, Th`ese de Doctorat. Universit´e de Paris VII.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Global learning of typed entailment rules.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Portland, OR.</location>
<contexts>
<context position="7058" citStr="Berant et al., 2011" startWordPosition="1114" endWordPosition="1117"> parsers, Ollie (Mausam et al., 2012) continues in the same spirit but with learned dependency patterns, improving on the earlier WOE system (Wu and Weld, 2010). The Never Ending Language Learning project (Carlson et al., 2010) has a similar aim, iteratively learning more facts from the internet from a seed set of examples. Exemplar (Mesquita et al., 2013) adapts the open IE framework to nary relationships similar to semantic role labeling, but without the expensive machinery. Open IE triples have been used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al</context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2011</marker>
<rawString>Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2011. Global learning of typed entailment rules. In Proceedings of ACL, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel R Bowman</author>
<author>Christopher Potts</author>
<author>Christopher D Manning</author>
</authors>
<title>Recursive neural networks can learn logical semantics.</title>
<date>2014</date>
<location>CoRR,</location>
<contexts>
<context position="8245" citStr="Bowman et al., 2014" startWordPosition="1314" endWordPosition="1317">ishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 2012; Bowman et al., 2014; Angeli and Manning, 2013). We adopt the precise semantics of Icard and Moss (2014). Our approach of finding short entailments from a longer utterance is similar in spirit to work on textual entailment for information extraction (Romano et al., 2006). 345 vmod Born in a small town, she took the midnight train going anywhere. she Born in a small town dobj prep in vmod dobj det amod nsubj det nn nsubj det amod prep in (input) (extracted clause) ↓ ↓ she took the midnight train going anywhere she took the midnight train she Born in small town Born in a small town, she took the midnight train she </context>
</contexts>
<marker>Bowman, Potts, Manning, 2014</marker>
<rawString>Samuel R. Bowman, Christopher Potts, and Christopher D. Manning. 2014. Recursive neural networks can learn logical semantics. CoRR, (arXiv:1406.1827).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Bryan Kisiel</author>
<author>Burr Settles</author>
<author>Estevam R Hruschka Jr</author>
<author>Tom M Mitchell</author>
</authors>
<title>Toward an architecture for neverending language learning.</title>
<date>2010</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="6665" citStr="Carlson et al., 2010" startWordPosition="1048" endWordPosition="1051">mission on open IE, and a baseline of replacing our extractor with Ollie, a state-ofthe-art open IE systems. 2 Related Work There is a large body of work on open information extraction. One line of work begins with TextRunner (Yates et al., 2007) and ReVerb (Fader et al., 2011), which make use of computationally efficient surface patterns over tokens. With the introduction of fast dependency parsers, Ollie (Mausam et al., 2012) continues in the same spirit but with learned dependency patterns, improving on the earlier WOE system (Wu and Weld, 2010). The Never Ending Language Learning project (Carlson et al., 2010) has a similar aim, iteratively learning more facts from the internet from a seed set of examples. Exemplar (Mesquita et al., 2013) adapts the open IE framework to nary relationships similar to semantic role labeling, but without the expensive machinery. Open IE triples have been used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbo</context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, Settles, Jr, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R Hruschka Jr, and Tom M Mitchell. 2010. Toward an architecture for neverending language learning. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angel X Chang</author>
<author>Christopher D Manning</author>
</authors>
<title>TokensRegex: Defining cascaded regular expressions over tokens.</title>
<date>2014</date>
<tech>Technical Report CSTR 2014-02,</tech>
<institution>Department of Computer Science, Stanford University.</institution>
<contexts>
<context position="24401" citStr="Chang and Manning, 2014" startWordPosition="4169" endWordPosition="4172"> disallow dropping direct objects. Note that this backoff arbitrarily orders contexts of the same size. Input Extraction (cats; play with; yarn) (fish; like to; swim) (cats; have; tails) (cats; are; cute) Tom and Jerry are fighting There are cats with tails Table 2: The six dependency patterns used to segment an atomic sentence into an open IE triple. cover the majority of atomic relations we are interested in. When information is available to disambiguate the substructure of compound nouns (e.g., named entity segmentation), we extract additional relations with 5 dependency and 3 TokensRegex (Chang and Manning, 2014) surface form patterns. These are given in Table 3; we refer to these as nominal relations. Note that the constraint of named entity information is by no means required for the system. In other applications – for example, applications in vision – the otherwise trivial nominal relations could be quite useful. prep on prep into dobj nsubj det prep backoff dobj backoff cats play with yarn fish like to swim cats have tails cats are cute (Tom; fighting; Jerry) (cats; have; tails) 349 KBP Relation Org:Founded Org:Dissolved Org:LOC Of HQ Org:Member Of Org:Parents Org:Founded By Open IE Relation PMI2 </context>
</contexts>
<marker>Chang, Manning, 2014</marker>
<rawString>Angel X. Chang and Christopher D. Manning. 2014. TokensRegex: Defining cascaded regular expressions over tokens. Technical Report CSTR 2014-02, Department of Computer Science, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Suzanne Tamang</author>
<author>Adam Lee</author>
<author>Xiang Li</author>
<author>Wen-Pin Lin</author>
<author>Matthew Snover</author>
<author>Javier Artiles</author>
<author>Marissa Passantino</author>
<author>Heng Ji</author>
</authors>
<date>2010</date>
<booktitle>CUNYBLENDER. In TAC-KBP.</booktitle>
<contexts>
<context position="7666" citStr="Chen et al., 2010" startWordPosition="1216" endWordPosition="1219">al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 2012; Bowman et al., 2014; Angeli and Manning,</context>
</contexts>
<marker>Chen, Tamang, Lee, Li, Lin, Snover, Artiles, Passantino, Ji, 2010</marker>
<rawString>Zheng Chen, Suzanne Tamang, Adam Lee, Xiang Li, Wen-Pin Lin, Matthew Snover, Javier Artiles, Marissa Passantino, and Heng Ji. 2010. CUNYBLENDER. In TAC-KBP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
<author>Johan Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="7523" citStr="Craven and Kumlien, 1999" startWordPosition="1189" endWordPosition="1192">expensive machinery. Open IE triples have been used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural network</context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>The Stanford typed dependencies representation.</title>
<date>2008</date>
<booktitle>In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation.</booktitle>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The Stanford typed dependencies representation. In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
</authors>
<title>Search needs a shake-up.</title>
<date>2011</date>
<journal>Nature,</journal>
<volume>476</volume>
<issue>7358</issue>
<contexts>
<context position="1291" citStr="Etzioni, 2011" startWordPosition="191" endWordPosition="192">ntences, and shift the focus to a classifier which learns to extract self-contained clauses from longer sentences. We then run natural logic inference over these short clauses to determine the maximally specific arguments for each candidate triple. We show that our approach outperforms a state-of-the-art open IE system on the end-to-end TAC-KBP 2013 Slot Filling task. 1 Introduction Open information extraction (open IE) has been shown to be useful in a number of NLP tasks, such as question answering (Fader et al., 2014), relation extraction (Soderland et al., 2010), and information retrieval (Etzioni, 2011). Conventionally, open IE systems search a collection of patterns over either the surface form or dependency tree of a sentence. Although a small set of patterns covers most simple sentences (e.g., subject verb object constructions), relevant relations are often spread across clauses (see Figure 1) or presented in a non-canonical form. Systems like Ollie (Mausam et al., 2012) approach this problem by using a bootstrapping method to create a large corpus of broad-coverage partially lexicalized patterns. Although this is effective at capturing many of these patterns, it Born in Honolulu, Hawaii,</context>
</contexts>
<marker>Etzioni, 2011</marker>
<rawString>Oren Etzioni. 2011. Search needs a shake-up. Nature, 476(7358):25–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>The statistics of word cooccurrences: word pairs and collocations.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit at Stuttgart.</institution>
<contexts>
<context position="27091" citStr="Evert, 2005" startWordPosition="4632" endWordPosition="4633">r TAC-KBP evaluation. A collection of relation mappings was constructed by a single annotator in approximately a day,3 and a relation mapping was learned using the procedure described in this section. We map open IE relations to the KBP schema by searching for co-occurring relations in a large distantly-labeled corpus, and marking open IE and 3The official submission we compare against claimed two weeks for constructing their manual mapping, although a version of their system constructed in only 3 hours performs nearly as well. KBP relation pairs which have a high PMI2 value (B´eatrice, 1994; Evert, 2005) conditioned on their type signatures matching. To compute PMI2, we collect probabilities for the open IE and KBP relation co-occurring, the probability of the open IE relation occurring, and the probability of the KBP relation occurring. Each of these probabilities is conditioned on the type signature of the relation. For example, the joint probability of KBP relation rk and open IE relation ro, given a type signature of t1, t2, would be count(rk, ro, t1, t2) p(rk, ro |t1, t2) = r�k,r�o count(rk, ro, t1, t2) Omitting the conditioning on the type signature for notational convenience, and defin</context>
</contexts>
<marker>Evert, 2005</marker>
<rawString>Stefan Evert. 2005. The statistics of word cooccurrences: word pairs and collocations. Ph.D. thesis, Universit at Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="6322" citStr="Fader et al., 2011" startWordPosition="993" endWordPosition="996">ample, whereas all rabbits eat fresh vegetables yields (rabbits; eat; vegetables), the apparently similar sentence all young rabbits drink milk does not yield (rabbits; drink; milk). We show that our new system performs well on a real world evaluation – the TAC KBP Slot Filling challenge (Surdeanu, 2013). We outperform both an official submission on open IE, and a baseline of replacing our extractor with Ollie, a state-ofthe-art open IE systems. 2 Related Work There is a large body of work on open information extraction. One line of work begins with TextRunner (Yates et al., 2007) and ReVerb (Fader et al., 2011), which make use of computationally efficient surface patterns over tokens. With the introduction of fast dependency parsers, Ollie (Mausam et al., 2012) continues in the same spirit but with learned dependency patterns, improving on the earlier WOE system (Wu and Weld, 2010). The Never Ending Language Learning project (Carlson et al., 2010) has a similar aim, iteratively learning more facts from the internet from a seed set of examples. Exemplar (Mesquita et al., 2013) adapts the open IE framework to nary relationships similar to semantic role labeling, but without the expensive machinery. Op</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Luke Zettlemoyer</author>
<author>Oren Etzioni</author>
</authors>
<title>Open question answering over curated and extracted knowledge bases.</title>
<date>2014</date>
<booktitle>In KDD.</booktitle>
<contexts>
<context position="1202" citStr="Fader et al., 2014" startWordPosition="176" endWordPosition="179">arguments. We replace this large pattern set with a few patterns for canonically structured sentences, and shift the focus to a classifier which learns to extract self-contained clauses from longer sentences. We then run natural logic inference over these short clauses to determine the maximally specific arguments for each candidate triple. We show that our approach outperforms a state-of-the-art open IE system on the end-to-end TAC-KBP 2013 Slot Filling task. 1 Introduction Open information extraction (open IE) has been shown to be useful in a number of NLP tasks, such as question answering (Fader et al., 2014), relation extraction (Soderland et al., 2010), and information retrieval (Etzioni, 2011). Conventionally, open IE systems search a collection of patterns over either the surface form or dependency tree of a sentence. Although a small set of patterns covers most simple sentences (e.g., subject verb object constructions), relevant relations are often spread across clauses (see Figure 1) or presented in a non-canonical form. Systems like Ollie (Mausam et al., 2012) approach this problem by using a bootstrapping method to create a large corpus of broad-coverage partially lexicalized patterns. Alt</context>
</contexts>
<marker>Fader, Zettlemoyer, Etzioni, 2014</marker>
<rawString>Anthony Fader, Luke Zettlemoyer, and Oren Etzioni. 2014. Open question answering over curated and extracted knowledge bases. In KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Jon Orwant</author>
</authors>
<title>A dataset of syntactic-ngrams over time from a very large corpus of english books.</title>
<date>2013</date>
<booktitle>In *SEM.</booktitle>
<contexts>
<context position="22047" citStr="Goldberg and Orwant (2013)" startWordPosition="3751" endWordPosition="3754">as a hard constraint. The second concern is with prepositional attachment, and direct object edges. For example, whereas Alice went to the playground prep with −−−−−−→ Bob entails that Alice went to the playground, it is not meaningful to infer that Alice is friends prep with −−−−−−→ Bob entails Alice is friends. Analogously, Alice played dobj −−→ baseball on Sunday entails that Alice played on Sunday; but, Obama signed dobj −−→ the bill on Sunday should not entail the awkward phrase *Obama signed on Sunday. We learn these attachment affinities empirically from the syntactic n-grams corpus of Goldberg and Orwant (2013). This gives us counts for how often object and preposition edges occur in the context of the governing verb and relevant neighboring edges. We hypothesize that edges which are frequently seen to co-occur are likely to be essential to the meaning of the sentence. To this end, we compute the probability of seeing an arc of a given type, conditioned on the most specific context we have statistics for. These contexts, and the order we back off to more general contexts, is given in Figure 3. To compute a score s of deleting the edge from the affinity probability p collected from the syntactic n-gr</context>
</contexts>
<marker>Goldberg, Orwant, 2013</marker>
<rawString>Yoav Goldberg and Jon Orwant. 2013. A dataset of syntactic-ngrams over time from a very large corpus of english books. In *SEM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>Bonan Min</author>
</authors>
<title>slot-filling system.</title>
<date>2010</date>
<booktitle>In Proc. TAC 2010 Workshop.</booktitle>
<location>New York University KBP</location>
<contexts>
<context position="7646" citStr="Grishman and Min, 2010" startWordPosition="1211" endWordPosition="1215"> new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 2012; Bowman et al., 2014;</context>
</contexts>
<marker>Grishman, Min, 2010</marker>
<rawString>Ralph Grishman and Bonan Min. 2010. New York University KBP 2010 slot-filling system. In Proc. TAC 2010 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Icard</author>
<author>Lawrence Moss</author>
</authors>
<title>Recent progress on monotonicity. Linguistic Issues in Language Technology.</title>
<date>2014</date>
<contexts>
<context position="8329" citStr="Icard and Moss (2014)" startWordPosition="1328" endWordPosition="1331">e careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 2012; Bowman et al., 2014; Angeli and Manning, 2013). We adopt the precise semantics of Icard and Moss (2014). Our approach of finding short entailments from a longer utterance is similar in spirit to work on textual entailment for information extraction (Romano et al., 2006). 345 vmod Born in a small town, she took the midnight train going anywhere. she Born in a small town dobj prep in vmod dobj det amod nsubj det nn nsubj det amod prep in (input) (extracted clause) ↓ ↓ she took the midnight train going anywhere she took the midnight train she Born in small town Born in a small town, she took the midnight train she took midnight train she Born in a town Born in a town, she took the midnight train .</context>
</contexts>
<marker>Icard, Moss, 2014</marker>
<rawString>Thomas Icard, III and Lawrence Moss. 2014. Recent progress on monotonicity. Linguistic Issues in Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
<author>Kira Griffitt</author>
<author>Joe Ellis</author>
</authors>
<title>Overview of the tac 2010 knowledge base population track.</title>
<date>2010</date>
<booktitle>In Third Text Analysis Conference.</booktitle>
<contexts>
<context position="13894" citStr="Ji et al., 2010" startWordPosition="2356" endWordPosition="2359">plicable cases. We turn our attention to the training data for learning these actions. 3.2 Training We collect a noisy dataset to train our clause generation model. We leverage the distant supervision assumption for relation extraction, which creates a noisy corpus of sentences annotated with relation mentions (subject and object spans in the sentence with a known relation). Then, we take this annotation as itself distant supervision for a correct sequence of actions to take: any sequence which recovers the known relation is correct. We use a small subset of the KBP source documents for 2010 (Ji et al., 2010) and 2013 (Surdeanu, 2013) as our distantly supervised corpus. To try to maximize the density of known relations in the training sentences, we take all sentences which have at least one known relation for every 10 tokens in the sentence, resulting in 43155 sentences. In addition, we incorporate the 23 725 manually annotated examples from Angeli et al. (2014). 1The system currently misses most most such cases due to insufficient support in the training data. Once we are given a collection of labeled sentences, we assume that a sequence of actions which leads to a correct extraction of a known r</context>
</contexts>
<marker>Ji, Grishman, Dang, Griffitt, Ellis, 2010</marker>
<rawString>Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Griffitt, and Joe Ellis. 2010. Overview of the tac 2010 knowledge base population track. In Third Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>Proceedings of the 10th International Conference on Research on Computational Linguistics.</booktitle>
<contexts>
<context position="28134" citStr="Jiang and Conrath, 1997" startWordPosition="4811" endWordPosition="4814">ure of t1, t2, would be count(rk, ro, t1, t2) p(rk, ro |t1, t2) = r�k,r�o count(rk, ro, t1, t2) Omitting the conditioning on the type signature for notational convenience, and defining p(rk) and p(ro) analogously, we can then compute The PMI2 value between the two relations: PMI2 ( p(rk, 2 l (rk, ro) = log \p( rk) ? p(ro) / Note that in addition to being a measure related to PMI, this captures a notion similar to alignment by agreement (Liang et al., 2006); the formula can be equivalently written as log [p(rk |ro)p(ro |rk)]. It is also functionally the same as the JC WordNet distance measure (Jiang and Conrath, 1997). Some sample type checked relation mappings are given in Table 4. In addition to intuitive mappings (e.g., found in → Org:Founded), we can note some rare, but high precision pairs (e.g., invest fund of → Org:Founded By). We can also see Durin, son of Thorin Thorin’s son, Durin IBM CEO Rometty President Obama Fischer of Austria IBM’s research group US president Obama Our president, Obama, 350 the noise in distant supervision occasionally permeate the mapping, e.g., with elect president of → Per:LOC Of Death – a president is likely to die in his own country. 6 Evaluation We evaluate our approac</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay J Jiang and David W Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. Proceedings of the 10th International Conference on Research on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Yves Peirsman</author>
<author>Angel Chang</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Stanford’s multi-pass sieve coreference resolution system at the conll-2011 shared task.</title>
<date>2011</date>
<booktitle>In CoNLL Shared Task.</booktitle>
<contexts>
<context position="30331" citStr="Lee et al., 2011" startWordPosition="5181" endWordPosition="5184">s from substrings of an open IE triple argument. For example, from the triple (Smith; was appointed; acting director of Acme Corporation), they extract that Smith is employed by Acme Corporation. We disallow such extractions, passing the burden of finding correct precise extractions to the open IE system itself (see Section 4). For entity linking, the UW submission uses Tom Lin’s entity linker (Lin et al., 2012); our submission uses the Illinois Wikifier (Ratinov et al., 2011) without the relational inference component, for efficiency. For coreference, UW uses the Stanford coreference system (Lee et al., 2011); we employ a variant of the simple coref system described in (Pink et al., 2014). We report our results in Table 5.4 UW Official refers to the official submission in the 2013 challenge; we show a 3.1 F1 improvement (to 22.7 4All results are reported with the anydoc flag set to true in the evaluation script, meaning that only the truth of the extracted knowledge base entry and not the associated provenance is scored. In absence of human evaluators, this is in order to not penalize our system unfairly for extracting a new correct provenance. System P R F1 UW Official* 69.8 11.4 19.6 Ollie† 57.4</context>
</contexts>
<marker>Lee, Peirsman, Chang, Chambers, Surdeanu, Jurafsky, 2011</marker>
<rawString>Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011. Stanford’s multi-pass sieve coreference resolution system at the conll-2011 shared task. In CoNLL Shared Task.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In NAACL-HLT.</booktitle>
<contexts>
<context position="27970" citStr="Liang et al., 2006" startWordPosition="4783" endWordPosition="4786">lities is conditioned on the type signature of the relation. For example, the joint probability of KBP relation rk and open IE relation ro, given a type signature of t1, t2, would be count(rk, ro, t1, t2) p(rk, ro |t1, t2) = r�k,r�o count(rk, ro, t1, t2) Omitting the conditioning on the type signature for notational convenience, and defining p(rk) and p(ro) analogously, we can then compute The PMI2 value between the two relations: PMI2 ( p(rk, 2 l (rk, ro) = log \p( rk) ? p(ro) / Note that in addition to being a measure related to PMI, this captures a notion similar to alignment by agreement (Liang et al., 2006); the formula can be equivalently written as log [p(rk |ro)p(ro |rk)]. It is also functionally the same as the JC WordNet distance measure (Jiang and Conrath, 1997). Some sample type checked relation mappings are given in Table 4. In addition to intuitive mappings (e.g., found in → Org:Founded), we can note some rare, but high precision pairs (e.g., invest fund of → Org:Founded By). We can also see Durin, son of Thorin Thorin’s son, Durin IBM CEO Rometty President Obama Fischer of Austria IBM’s research group US president Obama Our president, Obama, 350 the noise in distant supervision occasio</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lin</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>No noun phrase left behind: detecting and typing unlinkable entities.</title>
<date>2012</date>
<booktitle>In EMNLP-CoNLL.</booktitle>
<contexts>
<context position="30129" citStr="Lin et al., 2012" startWordPosition="5150" endWordPosition="5153">stem, Open IE v4.0 employs a semantic role component extracting structured SRL frames, alongside a conventional open IE system. Furthermore, the UW submission allows for extracting relations and entities from substrings of an open IE triple argument. For example, from the triple (Smith; was appointed; acting director of Acme Corporation), they extract that Smith is employed by Acme Corporation. We disallow such extractions, passing the burden of finding correct precise extractions to the open IE system itself (see Section 4). For entity linking, the UW submission uses Tom Lin’s entity linker (Lin et al., 2012); our submission uses the Illinois Wikifier (Ratinov et al., 2011) without the relational inference component, for efficiency. For coreference, UW uses the Stanford coreference system (Lee et al., 2011); we employ a variant of the simple coref system described in (Pink et al., 2014). We report our results in Table 5.4 UW Official refers to the official submission in the 2013 challenge; we show a 3.1 F1 improvement (to 22.7 4All results are reported with the anydoc flag set to true in the evaluation script, meaning that only the truth of the extracted knowledge base entry and not the associated</context>
</contexts>
<marker>Lin, Mausam, Etzioni, 2012</marker>
<rawString>Thomas Lin, Mausam, and Oren Etzioni. 2012. No noun phrase left behind: detecting and typing unlinkable entities. In EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>An extended model of natural logic.</title>
<date>2009</date>
<booktitle>In Proceedings of the eighth international conference on computational semantics.</booktitle>
<contexts>
<context position="8201" citStr="MacCartney and Manning, 2009" startWordPosition="1305" endWordPosition="1309">., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 2012; Bowman et al., 2014; Angeli and Manning, 2013). We adopt the precise semantics of Icard and Moss (2014). Our approach of finding short entailments from a longer utterance is similar in spirit to work on textual entailment for information extraction (Romano et al., 2006). 345 vmod Born in a small town, she took the midnight train going anywhere. she Born in a small town dobj prep in vmod dobj det amod nsubj det nn nsubj det amod prep in (input) (extracted clause) ↓ ↓ she took the midnight train going anywhere she took the midnight train she Born in small town Born in a </context>
</contexts>
<marker>MacCartney, Manning, 2009</marker>
<rawString>Bill MacCartney and Christopher D Manning. 2009. An extended model of natural logic. In Proceedings of the eighth international conference on computational semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Schmitz Mausam</author>
<author>Robert Bart</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Open language learning for information extraction.</title>
<date>2012</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1669" citStr="Mausam et al., 2012" startWordPosition="247" endWordPosition="250"> Introduction Open information extraction (open IE) has been shown to be useful in a number of NLP tasks, such as question answering (Fader et al., 2014), relation extraction (Soderland et al., 2010), and information retrieval (Etzioni, 2011). Conventionally, open IE systems search a collection of patterns over either the surface form or dependency tree of a sentence. Although a small set of patterns covers most simple sentences (e.g., subject verb object constructions), relevant relations are often spread across clauses (see Figure 1) or presented in a non-canonical form. Systems like Ollie (Mausam et al., 2012) approach this problem by using a bootstrapping method to create a large corpus of broad-coverage partially lexicalized patterns. Although this is effective at capturing many of these patterns, it Born in Honolulu, Hawaii, Obama is a US Citizen. Our System Ollie (Obama; is; US citizen) (Obama; is; a US citizen) (Obama; born in; (Obama; be born in; Honolulu) Honolulu, Hawaii) (Honolulu; be born in; Hawaii) (Obama; is citizen of; US) Friends give true praise. Enemies give fake praise. Our System Ollie (friends; give; true praise) (friends; give; true praise) (friends; give; praise) (enemies; giv</context>
<context position="6475" citStr="Mausam et al., 2012" startWordPosition="1017" endWordPosition="1020"> yield (rabbits; drink; milk). We show that our new system performs well on a real world evaluation – the TAC KBP Slot Filling challenge (Surdeanu, 2013). We outperform both an official submission on open IE, and a baseline of replacing our extractor with Ollie, a state-ofthe-art open IE systems. 2 Related Work There is a large body of work on open information extraction. One line of work begins with TextRunner (Yates et al., 2007) and ReVerb (Fader et al., 2011), which make use of computationally efficient surface patterns over tokens. With the introduction of fast dependency parsers, Ollie (Mausam et al., 2012) continues in the same spirit but with learned dependency patterns, improving on the earlier WOE system (Wu and Weld, 2010). The Never Ending Language Learning project (Carlson et al., 2010) has a similar aim, iteratively learning more facts from the internet from a seed set of examples. Exemplar (Mesquita et al., 2013) adapts the open IE framework to nary relationships similar to semantic role labeling, but without the expensive machinery. Open IE triples have been used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix fact</context>
<context position="32199" citStr="Mausam et al., 2012" startWordPosition="5515" endWordPosition="5518"> asterisk*. F1) over this submission, evaluated using a comparable approach. A common technique in KBP systems but not employed by the official UW submission in 2013 is to add alternate names based on entity linking and coreference. Additionally, websites are often extracted using heuristic namematching as they are hard to capture with traditional relation extraction techniques. If we make use of both of these, our end-to-end accuracy becomes 28.2 F1. We attempt to remove the variance in scores from the influence of other components in an endto-end KBP system. We ran the Ollie open IE system (Mausam et al., 2012) in an identical framework to ours, and report accuracy in Table 5. Note that when an argument to an Ollie extraction contains a named entity, we take the argument to be that named entity. The low performance of this system can be partially attributed to its inability to extract nominal relations. To normalize for this, we report results when the Ollie extractions are supplemented with the nominal relations produced by our system (Ollie + Nominal Rels in Table 5). Conversely, we can remove the nominal relation extractions from our system; in both cases we outperform Ollie on the task. 351 0.8 </context>
</contexts>
<marker>Mausam, Bart, Soderland, Etzioni, 2012</marker>
<rawString>Mausam, Michael Schmitz, Robert Bart, Stephen Soderland, and Oren Etzioni. 2012. Open language learning for information extraction. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Filipe Mesquita</author>
<author>Jordan Schmidek</author>
<author>Denilson Barbosa</author>
</authors>
<title>Effectiveness and efficiency of open relation extraction.</title>
<date>2013</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="6796" citStr="Mesquita et al., 2013" startWordPosition="1070" endWordPosition="1073">is a large body of work on open information extraction. One line of work begins with TextRunner (Yates et al., 2007) and ReVerb (Fader et al., 2011), which make use of computationally efficient surface patterns over tokens. With the introduction of fast dependency parsers, Ollie (Mausam et al., 2012) continues in the same spirit but with learned dependency patterns, improving on the earlier WOE system (Wu and Weld, 2010). The Never Ending Language Learning project (Carlson et al., 2010) has a similar aim, iteratively learning more facts from the internet from a seed set of examples. Exemplar (Mesquita et al., 2013) adapts the open IE framework to nary relationships similar to semantic role labeling, but without the expensive machinery. Open IE triples have been used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categoriz</context>
</contexts>
<marker>Mesquita, Schmidek, Barbosa, 2013</marker>
<rawString>Filipe Mesquita, Jordan Schmidek, and Denilson Barbosa. 2013. Effectiveness and efficiency of open relation extraction. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonan Min</author>
<author>Ralph Grishman</author>
<author>Li Wan</author>
<author>Chang Wang</author>
<author>David Gondek</author>
</authors>
<title>Distant supervision for relation extraction with an incomplete knowledge base.</title>
<date>2013</date>
<booktitle>In NAACL-HLT.</booktitle>
<contexts>
<context position="15244" citStr="Min et al., 2013" startWordPosition="2592" endWordPosition="2595">rguments as the known relation. For instance, if we know that Obama was born in Hawaii from the sentence Born in Hawaii, Obama ..., and an action sequence produces the triple (Obama, born in, Hawaii), then we take that action sequence as a positive sequence. Any sequence of actions which results in a clause which produces no relations is in turn considered a negative sequence. The third case to consider is a sequence of actions which produces a relation, but it is not one of the annotated relations. This arises from the incomplete negatives problem in distantly supervised relation extraction (Min et al., 2013): since our knowledge base is not exhaustive, we cannot be sure if an extracted relation is incorrect or correct but previously unknown. Although many of these unmatched relations are indeed incorrect, the dataset is sufficiently biased towards the STOP action that the occasional false negative hurts end-to-end performance. Therefore, we simply discard such sequences. Given a set of noisy positive and negative sequences, we construct training data for our action classifier. All but the last action in a positive sequence are added to the training set with the label Recurse; the last action is a</context>
</contexts>
<marker>Min, Grishman, Wan, Wang, Gondek, 2013</marker>
<rawString>Bonan Min, Ralph Grishman, Li Wan, Chang Wang, and David Gondek. 2013. Distant supervision for relation extraction with an incomplete knowledge base. In NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="7562" citStr="Mintz et al., 2009" startWordPosition="1197" endWordPosition="1200">n used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense </context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neha Nayak</author>
<author>Mark Kowarsky</author>
<author>Gabor Angeli</author>
<author>Christopher D Manning</author>
</authors>
<title>A dictionary of nonsubsective adjectives.</title>
<date>2014</date>
<tech>Technical Report CSTR 2014-04,</tech>
<institution>Department of Computer Science, Stanford University,</institution>
<contexts>
<context position="21391" citStr="Nayak et al. (2014)" startWordPosition="3643" endWordPosition="3646">ntailed (and nonsensical) phrase runs. The last, rare, case is an edge that causes the resulting item to be more specific – e.g., quantmod: aboutquantmod ←−−−−−− 200 is more general than 200. 2We use the Stanford Dependencies representation (de Marneffe and Manning, 2008). 348 For most dependencies, this semantics can be hard-coded with high accuracy. However, there are at least two cases where more attention is warranted. The first of these concerns non-subsective adjectives: for example a fake gun is not a gun. For this case, we make use of the list of non-subsective adjectives collected in Nayak et al. (2014), and prohibit their deletion as a hard constraint. The second concern is with prepositional attachment, and direct object edges. For example, whereas Alice went to the playground prep with −−−−−−→ Bob entails that Alice went to the playground, it is not meaningful to infer that Alice is friends prep with −−−−−−→ Bob entails Alice is friends. Analogously, Alice played dobj −−→ baseball on Sunday entails that Alice played on Sunday; but, Obama signed dobj −−→ the bill on Sunday should not entail the awkward phrase *Obama signed on Sunday. We learn these attachment affinities empirically from th</context>
</contexts>
<marker>Nayak, Kowarsky, Angeli, Manning, 2014</marker>
<rawString>Neha Nayak, Mark Kowarsky, Gabor Angeli, and Christopher D. Manning. 2014. A dictionary of nonsubsective adjectives. Technical Report CSTR 2014-04, Department of Computer Science, Stanford University, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glen Pink</author>
<author>Joel Nothman</author>
<author>R James Curran</author>
</authors>
<title>Analysing recall loss in named entity slot filling.</title>
<date>2014</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="30412" citStr="Pink et al., 2014" startWordPosition="5197" endWordPosition="5200">mith; was appointed; acting director of Acme Corporation), they extract that Smith is employed by Acme Corporation. We disallow such extractions, passing the burden of finding correct precise extractions to the open IE system itself (see Section 4). For entity linking, the UW submission uses Tom Lin’s entity linker (Lin et al., 2012); our submission uses the Illinois Wikifier (Ratinov et al., 2011) without the relational inference component, for efficiency. For coreference, UW uses the Stanford coreference system (Lee et al., 2011); we employ a variant of the simple coref system described in (Pink et al., 2014). We report our results in Table 5.4 UW Official refers to the official submission in the 2013 challenge; we show a 3.1 F1 improvement (to 22.7 4All results are reported with the anydoc flag set to true in the evaluation script, meaning that only the truth of the extracted knowledge base entry and not the associated provenance is scored. In absence of human evaluators, this is in order to not penalize our system unfairly for extracting a new correct provenance. System P R F1 UW Official* 69.8 11.4 19.6 Ollie† 57.4 4.8 8.9 + Nominal Rels* 57.7 11.8 19.6 Our System - Nominal Rels† 64.3 8.6 15.2 </context>
</contexts>
<marker>Pink, Nothman, Curran, 2014</marker>
<rawString>Glen Pink, Joel Nothman, and R. James Curran. 2014. Analysing recall loss in named entity slot filling. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
<author>Benjamin M Marlin</author>
</authors>
<title>Relation extraction with matrix factorization and universal schemas.</title>
<date>2013</date>
<booktitle>In NAACL-HLT.</booktitle>
<contexts>
<context position="7170" citStr="Riedel et al., 2013" startWordPosition="1132" endWordPosition="1135">ng on the earlier WOE system (Wu and Weld, 2010). The Never Ending Language Learning project (Carlson et al., 2010) has a similar aim, iteratively learning more facts from the internet from a seed set of examples. Exemplar (Mesquita et al., 2013) adapts the open IE framework to nary relationships similar to semantic role labeling, but without the expensive machinery. Open IE triples have been used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitl</context>
</contexts>
<marker>Riedel, Yao, McCallum, Marlin, 2013</marker>
<rawString>Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. 2013. Relation extraction with matrix factorization and universal schemas. In NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorenza Romano</author>
<author>Milen Kouylekov</author>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
<author>Alberto Lavelli</author>
</authors>
<title>Investigating a generic paraphrase-based approach for relation extraction.</title>
<date>2006</date>
<publisher>EACL.</publisher>
<contexts>
<context position="8496" citStr="Romano et al., 2006" startWordPosition="1355" endWordPosition="1358">tions and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 2012; Bowman et al., 2014; Angeli and Manning, 2013). We adopt the precise semantics of Icard and Moss (2014). Our approach of finding short entailments from a longer utterance is similar in spirit to work on textual entailment for information extraction (Romano et al., 2006). 345 vmod Born in a small town, she took the midnight train going anywhere. she Born in a small town dobj prep in vmod dobj det amod nsubj det nn nsubj det amod prep in (input) (extracted clause) ↓ ↓ she took the midnight train going anywhere she took the midnight train she Born in small town Born in a small town, she took the midnight train she took midnight train she Born in a town Born in a town, she took the midnight train ... she Born in town ↓ ↓ (she; born in; small town) (she; took; midnight train) (she; born in; town) Figure 2: An illustration of our approach. From left to right, a se</context>
</contexts>
<marker>Romano, Kouylekov, Szpektor, Dagan, Lavelli, 2006</marker>
<rawString>Lorenza Romano, Milen Kouylekov, Idan Szpektor, Ido Dagan, and Alberto Lavelli. 2006. Investigating a generic paraphrase-based approach for relation extraction. EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V´ıctor Manuel S´anchez S´anchez Valencia</author>
</authors>
<title>Studies on natural logic and categorial grammar.</title>
<date>1991</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="4071" citStr="Valencia, 1991" startWordPosition="618" endWordPosition="619">n linguistically motivated ways to produce coherent clauses which are (1) logically 344 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 344–354, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics entailed by the original sentence, and (2) easy to segment into open IE triples. Our approach consists of two stages: we first learn a classifier for splitting a sentence into shorter utterances (Section 3), and then appeal to natural logic (S´anchez Valencia, 1991) to maximally shorten these utterances while maintaining necessary context (Section 4.1). A small set of 14 hand-crafted patterns can then be used to segment an utterance into an open IE triple. We treat the first stage as a greedy search problem: we traverse a dependency parse tree recursively, at each step predicting whether an edge should yield an independent clause. Importantly, in many cases naively yielding a clause on a dependency edge produces an incomplete utterance (e.g., Born in Honolulu, Hawaii, from Figure 1). These are often attributable to control relationships, where either the</context>
</contexts>
<marker>Valencia, 1991</marker>
<rawString>V´ıctor Manuel S´anchez S´anchez Valencia. 1991. Studies on natural logic and categorial grammar. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Soderland</author>
<author>Brendan Roof</author>
<author>Bo Qin</author>
<author>Shi Xu</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Adapting open information extraction to domain-specific relations.</title>
<date>2010</date>
<journal>AI Magazine,</journal>
<volume>31</volume>
<issue>3</issue>
<contexts>
<context position="1248" citStr="Soderland et al., 2010" startWordPosition="183" endWordPosition="186">et with a few patterns for canonically structured sentences, and shift the focus to a classifier which learns to extract self-contained clauses from longer sentences. We then run natural logic inference over these short clauses to determine the maximally specific arguments for each candidate triple. We show that our approach outperforms a state-of-the-art open IE system on the end-to-end TAC-KBP 2013 Slot Filling task. 1 Introduction Open information extraction (open IE) has been shown to be useful in a number of NLP tasks, such as question answering (Fader et al., 2014), relation extraction (Soderland et al., 2010), and information retrieval (Etzioni, 2011). Conventionally, open IE systems search a collection of patterns over either the surface form or dependency tree of a sentence. Although a small set of patterns covers most simple sentences (e.g., subject verb object constructions), relevant relations are often spread across clauses (see Figure 1) or presented in a non-canonical form. Systems like Ollie (Mausam et al., 2012) approach this problem by using a bootstrapping method to create a large corpus of broad-coverage partially lexicalized patterns. Although this is effective at capturing many of t</context>
</contexts>
<marker>Soderland, Roof, Qin, Xu, Mausam, Etzioni, 2010</marker>
<rawString>Stephen Soderland, Brendan Roof, Bo Qin, Shi Xu, Mausam, and Oren Etzioni. 2010. Adapting open information extraction to domain-specific relations. AI Magazine, 31(3):93–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Soderland</author>
<author>John Gilmer</author>
<author>Robert Bart</author>
<author>Oren Etzioni</author>
<author>Daniel S Weld</author>
</authors>
<title>Open information extraction to KBP relations in 3 hours.</title>
<date>2013</date>
<booktitle>In Text Analysis Conference.</booktitle>
<contexts>
<context position="7823" citStr="Soderland et al. (2013)" startWordPosition="1242" endWordPosition="1245">concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 2012; Bowman et al., 2014; Angeli and Manning, 2013). We adopt the precise semantics of Icard and Moss (2014). Our approach of finding short entailments from a longer utterance is similar in spirit to wo</context>
<context position="29336" citStr="Soderland et al., 2013" startWordPosition="5022" endWordPosition="5025"> evaluate our approach in the context of a realworld end-to-end relation extraction task – the TAC KBP Slot Filling challenge. In Slot Filling, we are given a large unlabeled corpus of text, a fixed schema of relations (see Section 5), and a set of query entities. The task is to find all relation triples in the corpus that have as a subject the query entity, and as a relation one of the defined relations. This can be viewed intuitively as populating Wikipedia Infoboxes from a large unstructured corpus of text. We compare our approach to the University of Washington submission to TAC-KBP 2013 (Soderland et al., 2013). Their system used OpenIE v4.0 (a successor to Ollie) run over the KBP corpus and then they generated a mapping from the extracted relations to the fixed schema. Unlike our system, Open IE v4.0 employs a semantic role component extracting structured SRL frames, alongside a conventional open IE system. Furthermore, the UW submission allows for extracting relations and entities from substrings of an open IE triple argument. For example, from the triple (Smith; was appointed; acting director of Acme Corporation), they extract that Smith is employed by Acme Corporation. We disallow such extractio</context>
</contexts>
<marker>Soderland, Gilmer, Bart, Etzioni, Weld, 2013</marker>
<rawString>Stephen Soderland, John Gilmer, Robert Bart, Oren Etzioni, and Daniel S. Weld. 2013. Open information extraction to KBP relations in 3 hours. In Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Soderland</author>
</authors>
<title>Learning text analysis rules for domain-specific natural language processing.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Massachusetts.</institution>
<contexts>
<context position="7622" citStr="Soderland, 1997" startWordPosition="1209" endWordPosition="1210">ilment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 20</context>
</contexts>
<marker>Soderland, 1997</marker>
<rawString>Stephen G Soderland. 1997. Learning text analysis rules for domain-specific natural language processing. Ph.D. thesis, University of Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ang Sun</author>
<author>Ralph Grishman</author>
<author>Wei Xu</author>
<author>Bonan Min</author>
</authors>
<title>system for KBP slot filling.</title>
<date>2011</date>
<booktitle>In Proceedings of the Text Analytics Conference.</booktitle>
<location>New York University</location>
<contexts>
<context position="7581" citStr="Sun et al., 2011" startWordPosition="1201" endWordPosition="1204">f applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartn</context>
</contexts>
<marker>Sun, Grishman, Xu, Min, 2011</marker>
<rawString>Ang Sun, Ralph Grishman, Wei Xu, and Bonan Min. 2011. New York University 2011 system for KBP slot filling. In Proceedings of the Text Analytics Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
</authors>
<title>Overview of the tac2013 knowledge base population evaluation: English slot filling and temporal slot filling.</title>
<date>2013</date>
<booktitle>In Sixth Text Analysis Conference.</booktitle>
<contexts>
<context position="6008" citStr="Surdeanu, 2013" startWordPosition="939" endWordPosition="940">ns where it is incorrect to shorten an argument. For example, No house cats have rabies should not entail that cats have rabies, or even that house cats have rabies. When careful attention to logical validity is necessary – such as textual entailment – this approach captures even more subtle phenomena. For example, whereas all rabbits eat fresh vegetables yields (rabbits; eat; vegetables), the apparently similar sentence all young rabbits drink milk does not yield (rabbits; drink; milk). We show that our new system performs well on a real world evaluation – the TAC KBP Slot Filling challenge (Surdeanu, 2013). We outperform both an official submission on open IE, and a baseline of replacing our extractor with Ollie, a state-ofthe-art open IE systems. 2 Related Work There is a large body of work on open information extraction. One line of work begins with TextRunner (Yates et al., 2007) and ReVerb (Fader et al., 2011), which make use of computationally efficient surface patterns over tokens. With the introduction of fast dependency parsers, Ollie (Mausam et al., 2012) continues in the same spirit but with learned dependency patterns, improving on the earlier WOE system (Wu and Weld, 2010). The Neve</context>
<context position="13920" citStr="Surdeanu, 2013" startWordPosition="2362" endWordPosition="2364"> attention to the training data for learning these actions. 3.2 Training We collect a noisy dataset to train our clause generation model. We leverage the distant supervision assumption for relation extraction, which creates a noisy corpus of sentences annotated with relation mentions (subject and object spans in the sentence with a known relation). Then, we take this annotation as itself distant supervision for a correct sequence of actions to take: any sequence which recovers the known relation is correct. We use a small subset of the KBP source documents for 2010 (Ji et al., 2010) and 2013 (Surdeanu, 2013) as our distantly supervised corpus. To try to maximize the density of known relations in the training sentences, we take all sentences which have at least one known relation for every 10 tokens in the sentence, resulting in 43155 sentences. In addition, we incorporate the 23 725 manually annotated examples from Angeli et al. (2014). 1The system currently misses most most such cases due to insufficient support in the training data. Once we are given a collection of labeled sentences, we assume that a sequence of actions which leads to a correct extraction of a known relation is a positive sequ</context>
</contexts>
<marker>Surdeanu, 2013</marker>
<rawString>Mihai Surdeanu. 2013. Overview of the tac2013 knowledge base population evaluation: English slot filling and temporal slot filling. In Sixth Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan van Benthem</author>
</authors>
<title>A brief history of natural logic.</title>
<date>2008</date>
<tech>Technical Report PP-2008-05,</tech>
<institution>University of Amsterdam.</institution>
<marker>van Benthem, 2008</marker>
<rawString>Johan van Benthem. 2008. A brief history of natural logic. Technical Report PP-2008-05, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yotaro Watanabe</author>
<author>Junta Mizuno</author>
<author>Eric Nichols</author>
<author>Naoaki Okazaki</author>
<author>Kentaro Inui</author>
</authors>
<title>A latent discriminative model for compositional entailment relation recognition using natural logic.</title>
<date>2012</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="8224" citStr="Watanabe et al., 2012" startWordPosition="1310" endWordPosition="1313">ms (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framework for common-sense reasoning (MacCartney and Manning, 2009; Watanabe et al., 2012; Bowman et al., 2014; Angeli and Manning, 2013). We adopt the precise semantics of Icard and Moss (2014). Our approach of finding short entailments from a longer utterance is similar in spirit to work on textual entailment for information extraction (Romano et al., 2006). 345 vmod Born in a small town, she took the midnight train going anywhere. she Born in a small town dobj prep in vmod dobj det amod nsubj det nn nsubj det amod prep in (input) (extracted clause) ↓ ↓ she took the midnight train going anywhere she took the midnight train she Born in small town Born in a small town, she took th</context>
</contexts>
<marker>Watanabe, Mizuno, Nichols, Okazaki, Inui, 2012</marker>
<rawString>Yotaro Watanabe, Junta Mizuno, Eric Nichols, Naoaki Okazaki, and Kentaro Inui. 2012. A latent discriminative model for compositional entailment relation recognition using natural logic. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Autonomously semantifying wikipedia.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM conference on information and knowledge management.</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="7542" citStr="Wu and Weld, 2007" startWordPosition="1193" endWordPosition="1196">IE triples have been used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need to be trained explicitly on the KBP relation schema. Soderland et al. (2013) submitted a system to KBP making use of open IE relations and an easily constructed mapping to KBP relations; we use this as a baseline for our empirical evaluation. Prior work has used natural logic for RTE-style textual entailment, as a formalism well-suited for formal semantics in neural networks, and as a framewo</context>
</contexts>
<marker>Wu, Weld, 2007</marker>
<rawString>Fei Wu and Daniel S Weld. 2007. Autonomously semantifying wikipedia. In Proceedings of the sixteenth ACM conference on information and knowledge management. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Open information extraction using wikipedia.</title>
<date>2010</date>
<booktitle>In ACL. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6598" citStr="Wu and Weld, 2010" startWordPosition="1038" endWordPosition="1041">g challenge (Surdeanu, 2013). We outperform both an official submission on open IE, and a baseline of replacing our extractor with Ollie, a state-ofthe-art open IE systems. 2 Related Work There is a large body of work on open information extraction. One line of work begins with TextRunner (Yates et al., 2007) and ReVerb (Fader et al., 2011), which make use of computationally efficient surface patterns over tokens. With the introduction of fast dependency parsers, Ollie (Mausam et al., 2012) continues in the same spirit but with learned dependency patterns, improving on the earlier WOE system (Wu and Weld, 2010). The Never Ending Language Learning project (Carlson et al., 2010) has a similar aim, iteratively learning more facts from the internet from a seed set of examples. Exemplar (Mesquita et al., 2013) adapts the open IE framework to nary relationships similar to semantic role labeling, but without the expensive machinery. Open IE triples have been used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, th</context>
</contexts>
<marker>Wu, Weld, 2010</marker>
<rawString>Fei Wu and Daniel S Weld. 2010. Open information extraction using wikipedia. In ACL. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Probabilistic databases of universal schema.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Webscale Knowledge Extraction.</booktitle>
<contexts>
<context position="7148" citStr="Yao et al., 2012" startWordPosition="1128" endWordPosition="1131"> patterns, improving on the earlier WOE system (Wu and Weld, 2010). The Never Ending Language Learning project (Carlson et al., 2010) has a similar aim, iteratively learning more facts from the internet from a seed set of examples. Exemplar (Mesquita et al., 2013) adapts the open IE framework to nary relationships similar to semantic role labeling, but without the expensive machinery. Open IE triples have been used in a number of applications – for example, learning entailment graphs for new triples (Berant et al., 2011), and matrix factorization for unifying open IE and structured relations (Yao et al., 2012; Riedel et al., 2013). In each of these cases, the concise extractions provided by open IE allow for efficient symbolic methods for entailment, such as Markov logic networks or matrix factorization. Prior work on the KBP challenge can be categorized into a number of approaches. The most common of these are distantly supervised relation extractors (Craven and Kumlien, 1999; Wu and Weld, 2007; Mintz et al., 2009; Sun et al., 2011), and rule based systems (Soderland, 1997; Grishman and Min, 2010; Chen et al., 2010). However, both of these approaches require careful tuning to the task, and need t</context>
</contexts>
<marker>Yao, Riedel, McCallum, 2012</marker>
<rawString>Limin Yao, Sebastian Riedel, and Andrew McCallum. 2012. Probabilistic databases of universal schema. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Webscale Knowledge Extraction.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>