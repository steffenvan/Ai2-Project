<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.740145">
TAG&apos;s as a Grammadcal
Formalism for Generation
</note>
<author confidence="0.485446">
David D. McDonald and James D. Pustejovsky
</author>
<affiliation confidence="0.451348">
Department of Computer and Information Science
Univ ersity of Massachusetts at Amherst
</affiliation>
<sectionHeader confidence="0.919706" genericHeader="abstract">
1. Abstract
</sectionHeader>
<bodyText confidence="0.986254352941176">
Tree Adjoining Grammars, or &amp;quot;TAG&apos;s&amp;quot;, (Joshi, Levy &amp;
Takahashi 1975; Joshi 1983; ICroch &amp; Joshi 1985) were
developed as an alternative to the standard syntactic
formalisms that are used in theoretical analyses of language.
They are attractive because they may provide just the
aspects of context sensitive expressive power that actually
appear in human languages while otherwise remaining
context free.
This paper describes how we have applied the theory of
Tree Adjoining Grammars to natural language generation.
We have been attracted to TAG&apos;s because their central
operation—the extension of an Initial&amp;quot; phrase structure tree
through the inclusion, at very specifically constrained
locations, of one or more &amp;quot;auxiliary&amp;quot; trees—corresponds
directly to certain central operatic= of our own,
performance-oriented theory.
We begin by briefly describing TAG&apos;s as a formalism
for phrase structure in a competence theory, and summarize
the points in the theory of TAG&apos;s that are germaine to our
own theory. We then consider generally the position of a
grammar within the generation process, introducing our use
of TAG&apos;s through a contrast with how others have used
systemic grammars. This takes us to the core results of
our paper: using examples from our research with
well-written texts from newspapers, we walk through our
TAG inspired treatments cZ raising and wh-movement, and
show the cant:spondaic: of the TAG &amp;quot;adjunction&amp;quot; operation
and our &amp;quot;attachment&amp;quot; process.
In the final section we discuss extensions to the theory,
motivated by the way we use the operation corresponding
to TAG&apos;s&amp;quot; adjunction in performance. This suggests that the
competence theory of TAG&apos;s can be profitably projected to
structures at the morphological levet as well as the present
syntactic level.
</bodyText>
<sectionHeader confidence="0.976157" genericHeader="keywords">
2. Tree Adjunction Grammars
</sectionHeader>
<bodyText confidence="0.990840236842105">
The theoretical apparatus of a TAG consists of a
primitively defined set of &amp;quot;elementary&amp;quot; phrase structure
trees, a linking&amp;quot; relation that can be used to define
dependency relations between two nodes within an
elementary tree, and an &amp;quot;adjunction&amp;quot; operation that
combines trees under specifiable constraints. The elementary
trees are divided into two sets: initial and auxiliary. Initial
trees have only terminals at their leaves. Auxiliary trees are
distinguished by having one non-terminal among their
leaves; the category of this node must be the same as the
category of the root. Ali elemental trees are &amp;quot;minimal&amp;quot; in
the sense that they do not recurs: on any non-terminal.
A node NI in an elementary tree may be linked
(co-indexed) to a second node N2 in the same tree
provided Ni c-commands N2. Linking is used to indicate
grammatically defined dependencies between nodes such as
subcategorization relationships or filler-gap dependencies.
Links are preserved (though &amp;quot;stretched our) when their tree
is extended through adjunction; this is the mechanism
TAG&apos;s use to represent unbounded dependencies.
Sentence ciertYatioas start with an initial tree, and
continue via the adjunction of an arbitrary number of
auxiliary trees. To adjoin an auxiliary tree A with root
category X to a initial (or derived) tree T, we fiat select
some node of category X within T to be the point at
which the adjunction is to occur. Then (1) the subtree of
T dominated by that instance of X (call it X&apos;) is removed
from T, (2) the auxiliary tree A is knit into T at the
position where X&apos; had been located, and (3) the subtree
dominated by X&apos; is knit into A to replace the second
occurenas of the category X at T&apos;s frontier. The two trees
have now been merged by &amp;quot;splicing&amp;quot; A into T, displacing
the sulxree of T at the point of the adjunction to the
frontier of A.
For example we could take the initial tree:
(s. When does (s John like ei ] I
(the subscript &amp;quot;i&amp;quot; indicates that the &apos;who&amp;quot; and the trace
are linked) and adjoin to it the auxiliary tree:
</bodyText>
<subsectionHeader confidence="0.653042">
Ls Bill believes S]
</subsectionHeader>
<bodyText confidence="0.9266545">
to produce the derived tree:
Es- Whoi does (s Bill believe (s John likes ei ] ]
</bodyText>
<page confidence="0.998655">
94
</page>
<bodyText confidence="0.9896514">
Adjunction may be &amp;quot;constrained&amp;quot;. The grammar writer
may specify which specific trees may be adjoined to a given
node in an elementary tree; if no specification is given the
default is that there is no constraint and that any auxiliary
tree may be adjoined to the node.
</bodyText>
<subsectionHeader confidence="0.974472">
2.1 Key features of the theory of TAG&apos;.
</subsectionHeader>
<bodyText confidence="0.998855763636364">
A TAG specifies surface structure. There is no notion
of derivation from deep structure in the theory of
TAG &apos;s—the primitive trees are not transformed or otherwise
changed once they are introduced into a text, only
combined with other primitive trees. As 1Croch and loshi
point out, this means that a TAG is incomplete as an
account of the structure of a natural language, e.g. a TAG
grammar will contain both an active and a passive form of
the same verbal subcategorization pattern, without an
thr)ry-mediated description of the very close relationship
between them.
To our minds this is by no means a deficit. The
procedural machinery that generative grammars have
traditionally carried with them to characterize relations like
that of active to passive has only gotten in the way of
employing those characterizations in processing models of
generation. This is because a generation model, like any
theory of performance, has a procedural structure of its
own and cannot coexist with an incompatible one, at least
not while still operating efficiently or while retaining a
simple mapping from its actual machine to the virtual
machine that its authors put forward as their account of
psycholinguistic data.
Our own generator uses surface structure as its only
explicitly represented linguistic level. Thus grammatical
formalisms that dwell on the rules governing surface form
are more useful to us than those that hide those rules in a
deep to surface transformational process.
A TAG Involves the manipulation of very small
elementary structures. This is because of the stipulation
that elementary trees may not include recursive nodes. It
implies that the sentences one sees in everyday usage, e.g.
newpaper texts, are the result of many sucessive ad junctions.
This melds nicely with a move that we have made in
recent years to view the conceptual representation from
which generation proceeds as consisting of a heap of very
small, redundantly related information units that have been
deliberately selected by a text planning process from the
total state of the knowledge base at the time of utterance;
each such unit will correspond in the final text to a head
lexical item plus selected thematic arguments—a linguistic
entity that is easily projected onto the elementary trees of a
TAG.
TAG theory includes only one operation, atikmedon,
and otherwise makes no changes to the elementary trees
that go Into • test. This comports well with the indelibility
stipulation in our model of generation, since selected text
fragments can be used directly as specified by the grammar
without the need for any later transformation. The
composition options delimited by the constraints on
adjunction given with a TAG define a space of alternative
text forms which can correspond directly in generation to
alternative conceptual relations among information units,
alternatives in rhetorical intent, and alternatives in prose
style.
</bodyText>
<sectionHeader confidence="0.543957" genericHeader="introduction">
3. Adapting TAG&apos;s to Generation
</sectionHeader>
<bodyText confidence="0.98682316">
The mapping from TAG &apos;s as a formalism for
competence theories of language to our formalism for
generation is strikingly direct. As we described in Section 5
their ad junction operation corresponds to our attachment
process; their constraints on adjunction correspond to our
attachment points; their surface structure trees correspond to
our surface structure trees.1 We further hypothesize that
two quite strong correspondence claims can be made,
though considerably more experimentation and theorizing
will have to be done with both formalisms before these
claims can be confirmed.
1. The primitive information units in realization
specifications can be realized exclusively as one or
another elementary tree as defined by a suitable
TAG, i.e. linguistic criteria can be used in
determining the proper modularity of the
conceptual structure.2
2. Conversely, for any textual relationship which our
generator would derive by the attachment of
multiple information units into a single package,
there is a corresponding rule of adjunction. Since
we use attachment in the realization of nominal
compounds like &amp;quot;oil tanker&amp;quot;, this has the force of
extending the domain of TAG analyses into
morphology. (See section 7).
</bodyText>
<sectionHeader confidence="0.97996" genericHeader="method">
4. The Place of Grammar in a Theory of
Generation
</sectionHeader>
<bodyText confidence="0.990847705882353">
To understand why we are looking at TA G &apos;s rather
than some other formalism, one must first understand the
role of grammar within our processing model. The following
is a brief summary of the model; a more complete
description can be found in McDonald &amp; Pustepvsky
(19854
1 Out model of generation does not employ the simple trees of
labeled nodes that appear in mon theoretical linguc analyses. Our
surface structure incorporates the semantic proverb= of trees, but it
abo includes reifications of constituent positions like nibnct&amp;quot; or
&apos;sentence&amp;quot; and is better characterized overall as an &apos;executable
segue= of labeled positions&apos;. We discus this further in section 5.1.
2 u this hypothesis ecenful. it has very consequential
bnplications foe the &apos;kW of the information units that the text
planner comiructing the realization specification can use, e.g. they
would not be realized as texts that include rectenve nodes. We win
discus thin and other implications in a later paper.
</bodyText>
<page confidence="0.998019">
95
</page>
<bodyText confidence="0.99998187804878">
We have always had two complementary goals in our
research: on the one hand our generation program has had
to be of practical utility to the knoviedge based expert
systems that use it as part of a natural language interface.
This means that architecturally our generator has always
been designed to produce text from conceptual
specifications, &amp;quot;pians&amp;quot;, developed by another program and
consequently has had to be sensitive to the limitations and
varying approaches of the present state of the art in
conceptual representation.
At the same time, we want the architecture of the
virtual machine that we abstract out of our program to be
effective as a source of psycholinguistic hypotheses about
the actual generation process that humans use; it should,
for example, provide the basis for predictive accounts of
human speech error behavior and apparent planning
limitations. To achieve this, we have restricted ourselves to
a highly constrained set of representations and operations,
and have adopted strong and suggestive stipulations on our
design such as high locality, information encapsulation,
online quasi-realtime runtime performance, and indelibility.3
This restricts us as programmers, but disciplines us as
theorists.
We see the process of generation as involving three
temporally intermingled activities: (1) determining what goals
the utterance is to achieve, (2) planning what information
content and rhetorical force will best meet those goals given
the context, and (3) realizing the specified information and
rhetorical intent as a grammatical text. Our linguistic
component (henceforth LC), the Zetalisp program MUMBLE,
handles the third of them activities, taking a &amp;quot;realization
specification&amp;quot; as input, and producing a stream of
morphologically specialized words $ as output.
As described in (McDonald 1984 LC is a
&amp;quot;desaiption-directed&amp;quot; process: it uses the structure of the
realization specification it is given, plus the syntactic surface
structure of the tett in progress (which it extends
incrementally as the specification is realized) to directly
control its actions, interpreting them as though they were
sequential computer programs This technique imposes
strong demands on the descriptive formalism used for
</bodyText>
<construct confidence="0.777754142857143">
3 .Indelibility in a computation requiem that no action of a
proem (making deciamm constructing repremesurn changing stow
etc.) can be transparently undone once it has been performed. Many
nonbacktracking, amperage&apos; program designs have the property: it e
our term for what Marcie [19001 refemed te m the property at being
&apos;ruict/y detensinimie.
4 A mikados specificities can informally be takes to correspond
to what many racarchera, putiodarly psychologists, think at as the
&apos;merge lever representation of • test.
&apos;3 Which is to say that it preeently produces written rather than
spokes tests. We espies to .or with speech output shanty,
however. and the need to &apos;uppers the reprematatiosal basis of as
intonational cootour is begMeing to inflame our deigns foe
connitueney patterns in wsrfaas structure.
</construct>
<bodyText confidence="0.9993218">
representing surface structure. For example, nodes and
category labels now designate actions the generator is to
take (e.g. imposing scoping relations or constraining
embedded decisions) and dictate the inclusion of function
words and morphological specializations.
</bodyText>
<subsectionHeader confidence="0.997843">
4.1 Unbundling Systemic Grammars
</subsectionHeader>
<bodyText confidence="0.999750306122449">
Of the established linguistic formalisms, systemic
grammar [Halliday 19761 has always been the most
important to Al researchers on generation. Two of the
most important generation systems that have been
developed, PROTEUS (Davey 19741 and NIGEL (Mann &amp;
Matthiessen 19831, use systemic grammar, and others,
including ourselves, have been strongly influenced by it.
The reasons for this enthusiasm are central to the special
concerns of generation. Systemic grammars employ a
functional vocabulary: they emphasize the uses to which
language can be put—how languages achieve their speakers&apos;
goals—rather than its formal structure. Since the generation
process begins with goals, unlike the comprehension process
which begins with structure, this orientation makes systemic
grammars more immediately useful than, for example,
transformational generativ• grammars or even procedurally
oriented Al formalisms for language such as ATN&apos;s.
The generation researcher&apos;s primary question is why use
one construction rather than another—active instead of
passive, &amp;quot;the&amp;quot; instead of &amp;quot;a&amp;quot;. The principle device of a
systemic grammar, the &amp;quot;choice system&amp;quot;, supports this
question by highlighting how the constructions of the
language are grouped into sets of alternatives Choice
systems pnrowle an anchoring point for the rules of a
theory of language use ince it is natural to associate the
various semantic, discourse, or rhetorical criteria that bear
on the selection of a given construction or feature with the
choice system to which the construction belongs, thus
providing the basis of a decision-procedure for selecting
from its listed alternatives; the NIGEL system does precisely
this in its &amp;quot;chooser&amp;quot; procedures.
In our formalism we make use of the scone information
as a systemic granunar captures. however we have choasen to
bundle it guise differently. The underlying reason for this is
that our concern for psycholinguistic modeling and efficient
processing takes precedence in our design decisions about
how the facts of language and language use should be
represented in a generator. It is thus instructive to look at
the different kinds of linguistic information that a network
of choice systems carry. In our system we distribute these
to separate computational devices.
o Dependencies among structural features: A generator
must respect the constraints that dependencies impose
and appreciate the impact they have on its
realization options: for example that some
subordinate clauses can not express tense or modality
while main dauses are required to; or that a
pronominal direct object forces particle movement
while a lexical objects leaves it optional.
</bodyText>
<page confidence="0.946518">
96
</page>
<bodyText confidence="0.997576055555556">
o Usage criteria. The decision procedures associated
with each choice system are not a part of the
grammar per se, although they are naturally
associated with it and organized by it. Also most
systemic grammars include very abstract features such
as &amp;quot;generic reference&amp;quot; or &amp;quot;completed action&amp;quot;, which
cross-correlate the language&apos;s surface features, and
thus are more controllen of why a construct is used
rather than constructs themselves.
o Coordinated structural alternatives. A sentence may
be either active or passive, either a question or a
statement. By grouping these alternatives into
systems and using these systems exclusively when
constructing a text, one is guaranteed not to
combine inconsistent structural features.
o Efficient ordering of choices. The network that
connects choice systems provides a natural path
between decisions, which if followed strictly
guarentees that a choice will not be made unless it
is required, and that it will not be made before any
of the choices that it is itself dependent upon,
insuring that it can be made indelibly.
o Typology of surface structure. Almost by accident
(since its specification is distributed throughout all of
the systems implicitly), the grammar determines the
pattern of dominance and constituency relationships
of the text. While not a principle of the theory,
the trees of clauses, NPs, etc. in systemic grammars
tend to be shallow and broad.
We believe, but have not yet established, that
equivalence transformations can be defined that would take
a systemic grammar as a specification to construct the
alternative devices that we use in our generator (or
augment devices that derive from other sources, e.g. a
TAG) by decomposing the information in the systemic
grammar along the lines just listed and redistributing it.
</bodyText>
<sectionHeader confidence="0.983411" genericHeader="method">
5. Example Analyses
</sectionHeader>
<bodyText confidence="0.924279821428571">
One of the task domains we are currently developing
involves newspaper reports of current events. We are
&apos;reverse engineering&apos; leading paragraphs from actual
newspaper articles to produce narrow but complex
conceptual representation, and then designing realization
specifications—plans—that will lead our LC to reconstruct
the original text or motivated variations on it. We have
adopted this domain because the news reporting task, with
its requirement of communicating what is new and
significant in an event as well as the event itself, appears
to impose exceptionally rich constraints on the selection of
what conceptual information to report and on what
syntactic constructions to use in reporting it (see discusdon
in Clippinger &amp; McDonald [19P31. We expect to find out
how much complexity a realization specification requires in
order to motivate such carefully composed texts; this will
later guide us in designing a ten planner with sufficient
capabilities to construct such specifications on its own.
Our examples are drawn from the tett fragment below
(Associated Press, 12(23/84); the realization specification we
use to reproduce the text follows.
&amp;quot;LONDON - Two oil tankers, ffte Nonveglan-owned
Thorahayat and a Llborian-reglstarad vassal, were
rated to have bean hit by MISSileS Friday In the
Guff.
The Thorshavat wee ablaze aid under tow to
Bahrain, officials in Oslo said. Lloyds reported that
two crewman were !lured cri the Liberian alVp.&amp;quot;
</bodyText>
<figure confidence="0.931765444444444">
(lherday&apos;s-evarna-in-the-GUI-tanker-war
avants-requIrecartlficatIon-as-to-sofice
(main-evara rii&lt;sarrorevant-typs_vary112-Oafirof
#Chft-by-missilas Thorshaval&gt;
#Chlt-by-missfles Liberian»
irssual #&lt;runber-of-ships-ha 2&gt;
identify-the-ships )
(particslars 0&lt;darnagerraport Thonshavet Oslo-officials&gt;
0&lt;damage-report Uberian Lloyds&gt; ))
</figure>
<figureCaption confidence="0.645689">
Flgure 1
</figureCaption>
<bodyText confidence="0.996212542857143">
This realization specification represents the structured
object which gives the toplevel plan for this utterance.
Symbols preceded by colons indicate particular features of
the utterance. The two expressions in parentheses are the
content items of the specification and are restricted to
appear in the utterance in that order. The first symbol in
each expression is a label indicating the function of that
item within the plan; embedded items appearing in angle
brackets are information units from the current-events
knowledge base.
Obviously this plan must be considerably refined before
it could serve as a proximal source for the text; that is
why we point out that it is a &amp;quot;topievel&amp;quot; pian. It is a
specification for the general outline of the utterance which
must be fleshed out by recursive planning once its
realization has begun and the LC can supply a linguistic
contact to further constrain the choices for the units and
the rhetorical features.
For present purposes, the key fact to appreciate about
this realization specification is how different it is in form
from the surface structure. One cannot produce the ,ted
text simply by traversing and &apos;reading out&amp;quot; the elements of
the specification as though one were doing direct
production. Structural rearrangements are required, and
these must be done under the control of constraints which
can only be stated in linguistic vocabulary with terms like
&amp;quot;subject&amp;quot; or &amp;quot;raising&apos;.
The fust unit in the specification, 0&lt;aameenrent-type_&gt;,
is a relation over two other units. It indicates that a
commonality between the two has been noticed and deemed
significant in the underlying representation of the event.
The present LC always realizes such relations by merging
the realizations of the two units. If nothing else occurred,
this would give us the text &amp;quot;Two oil tankers were kis by
missiles&amp;quot;.
</bodyText>
<page confidence="0.998083">
97
</page>
<bodyText confidence="0.99906694117647">
As it happens, however, a pending rhetorical constraint
from the realization specification,
aventsrequirscerUfleatIon-asto-soirce
will force the addition of yet another information unit,6 the
reporting event by the news service that announced the
aledged event (e.g. a press release from Iraq, Reuters, etc.).
In this case the &amp;quot;content&amp;quot; of the reporting event is the two
damage-reports which have already been planned for
inclusion in the utterance as part of the &apos;particulars&amp;quot; part
of the specification. Let us look closely at how that
reportiing event unit is folded into surface structure.
When not itself the focus of attention, a reporting
event is typically realized as &amp;quot;so-and-so said X&amp;quot;, that is, the
content of the report is more important than the report
itself; whatever significance the report or its source has as
news will be indicated subtlly through which of the
alternative realizations below is selected for it.7
</bodyText>
<table confidence="0.939311777777778">
(deline-restmilon-dass believe-verbs
: parameters (agent proposition verb)
:choices
(( (AGENT-VERBe-that-PROP agent verb prop)
clause focus(agent) ernphasize(seff) )
; e.g. &amp;quot;Lloyds reports Iraq kit two tankers.&amp;quot;
; encompasses variations with and without that, and
; also ceaseless complements like &amp;quot;John believes him
; to be a fool.&amp;quot;
((raise-VERB-Into-PROP (passivize verb) prop)
clause focus((agent prop)) menUoned-eisewhere(agent) )
; &amp;quot;Two tankers were reported to have been hit&amp;quot;
( Ot-VERB-PROP verb prop)
clause Irderable(agent) )
; e.g. &amp;quot;It is reported that 2 tankers were hit.&amp;quot;
( (leit-dIalocated-PROP agent verb prop)
clause dwernphasizeOself) )
; &amp;quot;Two tankers were his. Gulf sources said.&amp;quot;
</table>
<figureCaption confidence="0.417319">
Figure 3 Realization class assigned to reponarecOR...)
</figureCaption>
<figure confidence="0.6523714">
Desired characteristic Resulting text
de-emphasize report Two tankers were hit, Gulf
shipping sources said.
source is given elsewhere Two tankers were reported his.
emphasize report Iraq reported it hit two tankers.
</figure>
<figureCaption confidence="0.8377815">
Figure 2 Possibilities for expresdng report(searce, info) in
newpapu. prose
</figureCaption>
<bodyText confidence="0.9988838">
In our LC, these alternative &amp;quot;choices&amp;quot; are grouped
together into a &amp;quot;realization class&amp;quot; as shown in Figure 3.
Our realization classes have their historic origins in the
choice systems of systemic grammar, though they are very
different in almost every concrete detail. The most
important difference of interest theoretically is that while
systemic choice systems select among single alternative
features (e.g. passive, gerundive), realization classes select
among entire surface structure fragments at a time (which
might be seen as prespecified realizations of bundles of
features). That is, our approach to generation calls for us
to organize our decision procedures so as to select the
values for a number of linguistic features simultaneously in
one choice where a systemic grammar would make the
selection incrementally.8
</bodyText>
<sectionHeader confidence="0.759595" genericHeader="method">
6 We will not disci= the mechanism by which features in the
</sectionHeader>
<bodyText confidence="0.970801170212766">
specification influence realization. Realization speeifiottions of the
complexity of this example are still very new in our research and we
are unsure whether the process is better organized at the conceptual
level directing a composition proem within the netting component
(during one of the immune invocations) or within the LC mediating
a selection between anticipated alternatives. At this point our design
experiments are inconcluieve.
7 These sentence are artificial; actual once would be considerably
longer. Interestingly, certain other syntactically permeable versions
such u MIS reported that&apos; do not mak in any of the tests we
have examined. Perhaps the lead to- paten is too important to
wane on • pronoun.
Returning to our example, we are now faced now with
the need to incorporate a unit denoting the report of the
Iraqi attacks into the utterance to act as a certification of
the 0&lt;M-by-missies&gt; events. This will be done using the
realization class belleve-verbs; the class is applicable to any
information unit of the form reporlisoorce, Info) (and
others). It determines the realization of such units 121tA
when they appear in issolation and, as in the present case,
when they are to augment an utterance corresponding to
one of their arguments.
From this realization class the choice
raise-VERB-Into-PROP will be selected since (1) the fact that
two ships were hit is most significant, meaning that the
focus will be on the information and not the source (n.b.
when the class executes the source Iraq will be bound to its
parameter and the information about the missile hits to the
proposition parameter); (2) there is no rhetorical motivation
for us to occupy space in the first sentence with the
sources of the report since they have already been planned
to follow. These conditions are sensed by attached
procedures associated with the characteristics that annotate
the choice (i.e. focus and mentionedebewbere).
8 mu technique of using choke systems to control the active
selection of utterance features is employed by the mom well-known
applications of rystensic gammen to generation (i.e. the work of
Davey (1974) and Mann and Mathieu= [1983D. However very raze
work with systemic grammars at Edinburgh by Patten [19851 departs
from de technique. Patten uses a semantic-level planning component
to directly select grouts of features at the rightward. &apos;output&amp;quot;. Ode of
a systemic netsiork, and then works backwards through the network to
determine what other, not sanaiically specified features must be added
to the WU for it to be grammatical; control is thus =Ode the
grammar proper, with grammar mks reiepted to constraint
specification only. We are intrigued by this technique and look
forward &apos;i its further development.
</bodyText>
<page confidence="0.995251">
98
</page>
<bodyText confidence="0.991192857142857">
Since the PROP is already in place in the surface
structure tree, the LC will be interpreting
ralooVEREI-Into-PROP as a specification of how it may fold
the auxiliary tree for reported into the tree for TWO oil
tankers were his by missiles Friday in the Gulf. This
corresponds to the TAG analysis in Figure 4 [Kroch &amp;
Joshi 19851.
</bodyText>
<figure confidence="0.975349666666667">
Initial Tree. Awaliary Tree:
INFL
NP INFL INFL VP
two tankers / be reported INFL
INFL VP
be rut by missiles
</figure>
<figureCaption confidence="0.998288">
Figure 4 Inidal and anxilliary trees for Raising-te-subject
</figureCaption>
<bodyText confidence="0.955852">
The initial tree for Two oil tankers were his by missiles, h,
may be extended at its NFL&amp;quot; node as indicated by the
constraint given in parenthesis by that node. Figure 5
shows the tree after the auxiliary tree A2, named by that
constraint has been adjoined. Notice that the original
INFL&amp;quot; of Figure 4 is now in the complement position of
report, giving us the sentence Two oil tankers were reported
hit by missiles.
</bodyText>
<figure confidence="0.7269018">
NP INFL
two num:ilea INFL VP
he reported INTL
INFL VP
be tdt by aussiles
</figure>
<figureCaption confidence="0.863083">
Figure 5 After embedding report
</figureCaption>
<subsectionHeader confidence="0.965463">
5.1 Path Notation
</subsectionHeader>
<bodyText confidence="0.9998765">
As readers of any of our earlier papers are aware, we
do not employ a conventional tree notation in our LC. A
generation model places its own kinds of demands on the
representation of surface structure, and these lead to
principled departures from the conventions adopted by
theoretical linguists. Figure 6 shows the surface saucture as
our LC would actually represent it just before the moment
when the adjunction is made.
</bodyText>
<figure confidence="0.9518406">
. --&gt; [SENTENCE! ---.
[SUBJECT&apos; [PkEDICATE1
0-Attach-
Raising-
*4%0 - by -arise i los -&gt; predicate
</figure>
<figureCaption confidence="0.998928">
Figure 6 Surface stricture In path notation
</figureCaption>
<bodyText confidence="0.998886928571429">
We call this representation path notation because it
defines the path that our LC. Formally the structure is
not a tree but a uni-directional linked list whose formation
rules obey the axioms of a tree (e.g. any path &amp;quot;down&amp;quot;
through a given node must eventually pass back &amp;quot;up&amp;quot;
through that same node). The path consists of a stream of
entitics representing phrasal nodes, constituent positions
(indicated by square brackets), instances of information units
(in boldface), instant= of words, and activated attachment
points (the labeled circle under the predicate; tee next
section). The various symbols in the figure (e.g. sentence,
predicate, etc.) have attached procedures that are activated
as the point of speech moves along the path, a process we
call &amp;quot;phrase structure execution&amp;quot;. Phrase structure execution
is the means by which grammatical constraints are imposed
on embedded decisions and function words and grammatical
morphemes are produced (For discussion see McDonald
[1984D.
Once one has begun to think of surface structure as a
traversal path, it is a short step to imagining being able to
cut the path and &amp;quot;splice in&amp;quot; additional position sequences.9
This splicing operation inherits a natural set of constraints
on the kinds of distortions that it can perform, since, by
the indelibility stipulation, existing position sequences can
not be destroyed or rethreaded. It is our impression that
these constraints will turn out to be formally the same as
those of a TAG, but we have not yet carried out the
detailed analyses to confirm this.
</bodyText>
<tableCaption confidence="0.637640666666667">
9 The posobility of cutting the airfare structure and inserting new
sequences that change the linguistic coats of positions already in
place has been in our theory of generation Mace WM when we used
it to implement raking verbs whose rhetorical force was the same as
&apos;hedging&amp;quot; adverbs tike possibly. Our present, much more ettensive
use of this device as the core of a distinct attachment proms dates
from the summer of 19114.
10 Constraints of this sort are an inovatios introduced in 1Crocit &amp;
Joeld (19n5j. Previous maims of TAO them allowed &apos;contest
aensieber constraint speeificatioes that in fats were newer exploited.
The present constraints are more attractive formally since they must
be stated locay to a single tree.
</tableCaption>
<figure confidence="0.927738">
NP (plural)
[quant! ---&gt; [head1
[premol.---&gt; [head]
oil tanker
</figure>
<page confidence="0.980012">
99
</page>
<subsectionHeader confidence="0.999243">
3.2 Attachment Points
</subsectionHeader>
<bodyText confidence="0.999949875">
The TAG formalism allows a grammar writer to define
&amp;quot;constraints&amp;quot; by annotating the nodes of elementary trees
with lists indicating what auxiliary trees may be adjoined to
them (including &amp;quot;any&amp;quot; or &amp;quot;none&amp;quot;).1° In a similar manner
the &amp;quot;choices&amp;quot; in our realization classes—which by our
hypothesis can be taken to always =respond to TAG
elementary trees—include specifications of the attachment
points at which new information units can be incorporated
into the surface structure path they define. Rather than
being constraints on an otherwise freely applying operation,
as in a TAG, attachment points are actual objscts
interposed in the path notation of the surface structure. A
list of the attachment points active at any moment is
maintained by the attachment process and consulted
whenever an information unit needs to be added. Most
units could be attached at any of several points, with the
decision being made on the basis of what would be most
consistent with the desired prose style (d. McDonald and
Pustejovsky [1983aD. When one of the points is selected it is
Instantiated, usually splicing in new surface structure in the
process, and the new unit added at a designated position
within the new structure. Figure 7 shows our present
definition of the attachment point that ultimately leads to
the addition of &amp;quot;was reported&amp;quot;.
</bodyText>
<figure confidence="0.913330375">
(dethe-attechment-point attadwaiaimtpreciatte
relsraneports
(preseireiuSrecklvtitracteristies.(0-predcate slot-conts.feemareate Omen)
( raisavvern-with-complement(present-predeate) )
position-of-attachment-point
((al-slot &amp;quot;predicate phrase)
attach-order )
navs-phrese-structtse
(mbenergeiodsOnycontentwintrenew-etrucare
(vp-inftnitIvecomplernent) ; specification of new phrase
vent ; where the unit being attached goes
inanitive•cornoiement) ; where the existing contents go
sitect-cmother-pardnp.attactment-poinus
none
diolees.that-Iniroduce4
nholcalepaseiniktest (nciudes-slot &amp;quot;pnelloate))
</figure>
<figureCaption confidence="0.981298">
Fixers 7 The attachment-paint used by was reported
</figureCaption>
<bodyText confidence="0.986091444444444">
This attachment point goes with any choice (elementary
tree) that includes a constituent position labeled predicate.
It is placed in the position path immediately after (or
&amp;quot;under&amp;quot;) that position (see Figure 6), where it is available
to any new unit that passes the indicated requirements.
When this attachment is =Meted, it builds a new VP
node that has the old VP as one of its constituents, then
splices this new node into the path in its place as shown in
Figure 7.
The unit being attached, e.g. the report of the attack
on the two oil tankers, is made the verb of the new VP.
Later, once the phrase structure execution process has
walked into the new VP and reached that verb position,
the unit&apos;s realization dam (belief-verbs) will be consulted
and a choice selected that is consistent with the
grammatical constraints of being a verb (i.e. a conventional
variant on the raise-VERB-Into-PROP choice), giving us &amp;quot;was
reported&amp;quot;.
</bodyText>
<figure confidence="0.896832166666667">
--) [SENTENCE]
(PREDICATE]
VP (posseive&gt;
(verb] ---&gt; tint -
• complement]
immit -by -missiles ..,&gt;
</figure>
<figureCaption confidence="0.831992">
Fiore 8 The path after attadsment
</figureCaption>
<bodyText confidence="0.999960466666667">
From this discussion one can see that our treatment of
attachment uses two structures, an attachment point and a
choice, where a TAG would only use one structure, an
auxiliary tree. This is • consequence of the fact that we
are working with a performance model of generation that
must show explicitly how conceptual information units are
rendered into tests as part of a psycholinguistically plausible
psocees, while a TAG is a formalism for competence
theories that only need to specify the syntactic structure of
the grammatical strings of a language. This is a significant
difference, but not one that should stand in our way in
compering what the two theories have to offer each other.
Consequently in the .rest of this paper we will omit the
details of the path notation and attachment point definitions
to facilitate the comparison of theoretical issues.
</bodyText>
<sectionHeader confidence="0.838551" genericHeader="method">
6. Generating questions using a TAG version of
</sectionHeader>
<subsectionHeader confidence="0.626098">
wiz-movement
</subsectionHeader>
<bodyText confidence="0.99981885">
Earlier we illustrated the TAG concept of linking&amp;quot; by
Mowing how one would start with an initial tree consisting
of the innermost clause of a question phis the fronted
wit-phrase and then build outward by successively adjoining
the desired auxiliary phrases to the S node that intervenes
between the wit-phrase and the clause. Wh-questions are
thus built front the bottom up, as in fact is gnx sentence
involving verbs taking sentential complements.
This analysis has the desirable property of allowing one
to state the dependencies between the Wh-phrase and the
gap as a local relation on a single elementary one,
eliminating the need to include any machinery for
movement in the theory. All unbounded dependencies now
derive from adjunction: (which, as far as the grammar is
concerned, can be made without limit), rather than to the
explicit migration of a constituent across clauses.
We also find this locality property to be desirable, and
use an analogous procedure in our production of questions
and other kinds of Whquestions and unbounded dependency
constructions.
</bodyText>
<figure confidence="0.957538666666667">
[SUBJECT]
NP
two oil tankers
</figure>
<page confidence="0.934854">
100
</page>
<bodyText confidence="0.997181970588235">
This &amp;quot;bottom-up&amp;quot; design has consequences for how the
realization soxifications for these constructions must be
organized. In particular, the logician&apos;s usual representation
of sentential complement verbs as higher operators is not
tenable in that role. For example we cannot have the
source of, say. How many ships did Reuters report that Iraq
had said it module be the expression:
Landida(quendty-et-ablps). report
(Renters,sayaraq,altack(Iraq,quantitre(•ehips)))
Such an expression defines a natural sequence of exposure
when used as realization specification, =nay that one
realize the Lambda operator first, the report operator
second, the say third, and so on. A local TAG analysis of
Wit-movement requires us to have the Lambda and the
expression containing its matrix once, attach, be present in
a single layer&amp;quot; of the specification, otherwise we would be
forced to violate one of the strong principles of our theory
of generation. namely that the characteristics in a
realization class may &amp;quot;see&amp;quot; only the immediate arguments of
the unit being realiz&apos; ed; they may not look &amp;quot;inside&amp;quot; those
arguments to subsequent levels of conceptual structure.
This principle has served us well, and we are
disinclined to give it up without a very compelling reason.
We elected instead to give up the internal representation of
sentential complement verb texts as single expressions. This
move was easy for us to make since such expressions are
awkward to manipulate in the &apos;East Coast&amp;quot; style frame
knowledge bases that we use in our own reasoning
programs, and we have preferred a represesitatMnal nyie
with redundant, smaller sized conceptual units for quite
some time.
The representation we use instead amounts to breaking
up the logical expression into individual units and allowing
them to include references to each other.
</bodyText>
<equation confidence="0.941426333333333">
lambda(quantity-of.ships) . attack(Iraq,quantity-of-ships)
t-r2 saY(Ir213, U1)
U3 reoornReuters, U2)
</equation>
<bodyText confidence="0.999955515151515">
Given such a network as the realization specification,
the LC must have some principle by which to judge where
to start: which unit should form the basis of the surface
structure to which the others are then attached? A natural
principle to adopt is to begin with the &amp;quot;bans&amp;quot; unit, i.e. the
one that does cot mention any other units in its definition.
We are considering adopting the policy that such units
should be allowed only realizations as initial trees while
units whose definition involves &amp;quot;pointing to&amp;quot; (naming) other
units should be allowed only realizations as auxiliary trees.
We have not, however, worked through all of the
ramifications such a policy might have on other parts of
our generation model; without yet knowing whether it
would improve or degrade the other parts of our theory,
we are reluctant to assert it as one of our hypotheses
relating our generation model to TAG&apos;s.
Given that three part source, the realization of the
question is fairly straightforward (See Figure 9). The
Lambda expression is assigned a realization ciass for ciausal
Wit constructions, whereupon the extracted argument
quantity-el-sides is placed in COMP, and the body of the
expression is pieced in the HEAD position. At the same
time, the two instances of quandty-et-sidm are specially
marked. The one in COMP is assigned to the realization
clam for Wit phrases appropriate to quantity (e.g. it will
have the choice how natty X and possibly related choices
such as &lt;quantity&gt; of which and other variants appropriate
to relative clauses or other positions where Wit caastructioas
can be used). Simultaneously the instance of
quantity-et-Alps in the argument position of the head frame
attack is assigned to the realization class for Wit-trace.
These two specializations are the equivalent, in our model,
of the TAG linking relation.
</bodyText>
<figure confidence="0.624656">
Rutrs Nope:.r?,s
N / Iraq say
comp S
WH(ships)
Iraq attacx
</figure>
<figureCaption confidence="0.339009">
Flom 9 Question formation with senundai compiement
verbs
</figureCaption>
<bodyText confidence="0.926991684210526">
The two pending units, U2 and U3, are then attached
to this matrix, submerging fust the attach unit and then U2
into complement positions.
7. Extensions to the Theory of TAG
Context-free grammars are able to express the word
formation processes that seem to exist for natural languages
(cf. Williams (19811, Selkirk (19132D. A TAG analysis of such
a grammar seems like a natural application to the current
version of the theory (d. Pustejovsky (in preparation)). To
illustrate our point. consider compounding rules in English.
We can say that for a context-free grammar for word
formation. Gw, there is a TAG. Tw, that is equivalent to
Gw (d. Figures 10 and 11). Consider a fragment of Gw
beiow.11
11 Whether the word formation component should in faa have the
power of a TAG or CFO is an opal questions. Langendoen (191111
diatoms the pombility that a Einius state ratamar might be suaktem
Cot Ms generative capaOrr of natural language word Commas
components.
</bodyText>
<page confidence="0.998512">
101
</page>
<sectionHeader confidence="0.98971" genericHeader="method">
N-&gt;NIAIVIP N
A-&gt;NIAIP A
</sectionHeader>
<figure confidence="0.755104333333333">
V -&gt; P V
Figaro 10 CFG Fragment for Word Formates
The corresponding G, fragment would be:
A
comp N comp A
AUXILIARY TREES
oi 1
tanker
INITIAL TREES
</figure>
<figureCaption confidence="0.997218">
Figure 11 TAG Fragment for Word Formation
</figureCaption>
<bodyText confidence="0.985242428571429">
Now consider the compound , &amp;quot;di tanker ternand, taken
from the newspaper reporting domain, and its derivation in
TAG theory, shown in Figure 12.
the penibility of expressing U2 prenominally. One of the
choices associated with this unit is a compound
structure—expressed in terms of an auxiliary tree. A
snapshot at this point in the derivation shows the following
StrUCtille.
5,4 [cam U2] U1]
The next unit opened up in this structure is U3, which also
allows for attachment prenotninally. Thus an auxiliary tree
corresponding to 1.14 is introduced, giving us the snucture
bedew:
rgf :wTv (C0n U4] U311 U1]
The seiectional constraints imposed by the strucrural
positioning of information unit U4 allows only a
compounding choice. Had these been no word-level
compound realization option, we would have worked our
way into a corner without expressing the relation between
*Coil&gt; and /0&lt;tanker&gt;. Because of this it may be better
to view units such as U4 as being associated direcdy with a
lexical compounded form, i.e. oil tanker. This partial
solution, however, would not speak to the problem of active
word formation in the language. Furthermore, it would be
interesting to compare the strategic decisions made by a
generation system with those planning mistakes made by
humans when speaking. This is an aspect of generation that
merits much further research.
</bodyText>
<figure confidence="0.978508166666667">
P V
I -
terminal
Acr-N N
Comp N C4‘ N
oll oil/ ianki
</figure>
<figureCaption confidence="0.996152">
Figure 12 TAG Derivation at oil tanker terminal
</figureCaption>
<bodyText confidence="0.877320785714286">
Let us compare this derivation to the process used by
the LC. The underlying information units from which this
compound is derived in our system ate shown below. The
planner has decided that the units below need to be
communicated in order to adequately express the concept.
The top4evei unit in this bundle is sr.:terminal&gt;.
U1 o&lt;ierniali&gt;
U2 eie.dnekeet U1 U3&gt;
U3 ili&lt;lanker&gt;
U4 .1 0&lt;carries U3 U3&gt;
U5
The run unit to be positioned in the surfaces structure is
1-11, and appears as the head of an NP. There is an
attachment point on this position, however, which allows for
</bodyText>
<page confidence="0.998412">
102
</page>
<sectionHeader confidence="0.983332" genericHeader="conclusions">
8. Acknowledgements
</sectionHeader>
<bodyText confidence="0.8583085">
This research has been supterminaled in part by
contract N0014-85-K-0017 from the Defense Advanced
Research Projects Agency. We would like to thank Marie
Vaughan for help in the preparation of this text.
</bodyText>
<sectionHeader confidence="0.926172" genericHeader="references">
9. References
</sectionHeader>
<reference confidence="0.999757840909091">
Clippinger, &amp; McDonald (1983) &apos;Why Good Writing is
Easier to Understand&amp;quot;, Proc. UCAI-83, pp. 730-732.
Davey (1974) Dbeourse Production, PhD. Dissertation,
FAinburgh University; published in 1979 by Edinburgh
University Press.
Halliday (1976) System and Function in Language, Oxford
University Press.
Joshi (1983) &amp;quot;How Much Context-Sensitivity is Required to
Provide Reasonable Structural Descriptions: Tree
Adjoining Grammars&amp;quot;, preprint to appear in Dowty,
Karttunen, &amp; Zwicky (eds.) Natural Language
Processing: Psycholinguistic, Computational, and
Theoretical Perspectives, Cambridge University Press.
Kroch, T. and A. Joshi (1985) &apos;Ile Linguistic Relevance of
Tree Adjoining Grammar&amp;quot;, University of Pennsylvania,
Dept. of Computer and Information Science.
Langendoen, D.T. (1981) &amp;quot;The Generative Capacity of
Word-Formation Components&amp;quot;, Linguistic Inquiry,
Volume 12.2
Mann &amp; Matthiessen (1983) Nigel: A Systemic Grammar for
Test Generation, in Freedle (ed.) Systemic Perspectives
on Discourse, Abler.
Marcus (1980) A Theory of Syntactic Recognition for Natural
Language, MIT Press.
McDonald (1984) &amp;quot;Description Directed Control: Its
Implications for Natural Language Generation&amp;quot;, in
Cercone (ed.) Computational Linguistics, Pergamon
Press.
McDonald &amp; Pustejovsky (1985a) &amp;quot;SAMSON: a
computational theory of prose style in generation&amp;quot;,
Proceedings of the 1985 meeting of the European
Association for Computational Linguistics.
(1985b) &amp;quot;Description-Directed Natural
Language Generation&amp;quot;, Proceedings of UCAI-85,
W.1Caufmann Inc., Los Altos CA.
Patten T. (1985) &amp;quot;A Problem Solving Approach to
Generating Text from Systemic Grammars&amp;quot;, Proceedings
of the 1985 meeting of the European Association for
Computational Linguistics.
Pustejovsky, J. (In Preparation) &amp;quot;Word Formation in Tree
Adjoining Grammars&amp;quot;
Selkirk (1902) The Syntax of Words, MTT Press.
Williams (1981) &amp;quot;Argument Structure and Morphology&amp;quot; The
Linguistic Review, 1, 81-114.
</reference>
<page confidence="0.999299">
103
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000015">
<title confidence="0.9882775">TAG&apos;s as a Grammadcal Formalism for Generation</title>
<author confidence="0.99997">David D McDonald</author>
<author confidence="0.99997">James D Pustejovsky</author>
<affiliation confidence="0.958088">Department of Computer and Information Science Univ ersity of Massachusetts at Amherst</affiliation>
<abstract confidence="0.999373203883496">1. Abstract Tree Adjoining Grammars, or &amp;quot;TAG&apos;s&amp;quot;, (Joshi, Levy &amp; Takahashi 1975; Joshi 1983; ICroch &amp; Joshi 1985) were developed as an alternative to the standard syntactic formalisms that are used in theoretical analyses of language. They are attractive because they may provide just the aspects of context sensitive expressive power that actually appear in human languages while otherwise remaining context free. This paper describes how we have applied the theory of Tree Adjoining Grammars to natural language generation. We have been attracted to TAG&apos;s because their central operation—the extension of an Initial&amp;quot; phrase structure tree through the inclusion, at very specifically constrained locations, of one or more &amp;quot;auxiliary&amp;quot; trees—corresponds directly to certain central operatic= of our own, performance-oriented theory. We begin by briefly describing TAG&apos;s as a formalism for phrase structure in a competence theory, and summarize the points in the theory of TAG&apos;s that are germaine to our own theory. We then consider generally the position of a grammar within the generation process, introducing our use of TAG&apos;s through a contrast with how others have used systemic grammars. This takes us to the core results of our paper: using examples from our research with well-written texts from newspapers, we walk through our TAG inspired treatments cZ raising and wh-movement, and show the cant:spondaic: of the TAG &amp;quot;adjunction&amp;quot; operation and our &amp;quot;attachment&amp;quot; process. In the final section we discuss extensions to the theory, motivated by the way we use the operation corresponding to TAG&apos;s&amp;quot; adjunction in performance. This suggests that the competence theory of TAG&apos;s can be profitably projected to structures at the morphological levet as well as the present syntactic level. 2. Tree Adjunction Grammars The theoretical apparatus of a TAG consists of a primitively defined set of &amp;quot;elementary&amp;quot; phrase structure trees, a linking&amp;quot; relation that can be used to define dependency relations between two nodes within an elementary tree, and an &amp;quot;adjunction&amp;quot; operation that combines trees under specifiable constraints. The elementary are divided into two sets: initial and auxiliary. only terminals at their leaves. trees distinguished by having one non-terminal among their leaves; the category of this node must be the same as the category of the root. Ali elemental trees are &amp;quot;minimal&amp;quot; in the sense that they do not recurs: on any non-terminal. A node NI in an elementary tree may be linked (co-indexed) to a second node N2 in the same tree provided Ni c-commands N2. Linking is used to indicate grammatically defined dependencies between nodes such as subcategorization relationships or filler-gap dependencies. Links are preserved (though &amp;quot;stretched our) when their tree is extended through adjunction; this is the mechanism TAG&apos;s use to represent unbounded dependencies. Sentence ciertYatioas start with an initial tree, and continue via the adjunction of an arbitrary number of auxiliary trees. To adjoin an auxiliary tree A with root category X to a initial (or derived) tree T, we fiat select some node of category X within T to be the point at which the adjunction is to occur. Then (1) the subtree of T dominated by that instance of X (call it X&apos;) is removed from T, (2) the auxiliary tree A is knit into T at the position where X&apos; had been located, and (3) the subtree dominated by X&apos; is knit into A to replace the second occurenas of the category X at T&apos;s frontier. The two trees have now been merged by &amp;quot;splicing&amp;quot; A into T, displacing the sulxree of T at the point of the adjunction to the frontier of A. For example we could take the initial tree: When does (s John like ei ] I (the subscript &amp;quot;i&amp;quot; indicates that the &apos;who&amp;quot; and the trace are linked) and adjoin to it the auxiliary tree: Ls Bill believes S] to produce the derived tree: Es- Whoi does (s Bill believe (s John likes ei ] ] 94 Adjunction may be &amp;quot;constrained&amp;quot;. The grammar writer may specify which specific trees may be adjoined to a given node in an elementary tree; if no specification is given the default is that there is no constraint and that any auxiliary tree may be adjoined to the node. 2.1 Key features of the theory of TAG&apos;. A TAG specifies surface structure. There is no notion of derivation from deep structure in the theory of TAG &apos;s—the primitive trees are not transformed or otherwise changed once they are introduced into a text, only combined with other primitive trees. As 1Croch and loshi point out, this means that a TAG is incomplete as an account of the structure of a natural language, e.g. a TAG grammar will contain both an active and a passive form of the same verbal subcategorization pattern, without an thr)ry-mediated description of the very close relationship between them. To our minds this is by no means a deficit. The procedural machinery that generative grammars have traditionally carried with them to characterize relations like that of active to passive has only gotten in the way of employing those characterizations in processing models of generation. This is because a generation model, like any theory of performance, has a procedural structure of its own and cannot coexist with an incompatible one, at least not while still operating efficiently or while retaining a simple mapping from its actual machine to the virtual machine that its authors put forward as their account of psycholinguistic data. Our own generator uses surface structure as its only explicitly represented linguistic level. Thus grammatical formalisms that dwell on the rules governing surface form are more useful to us than those that hide those rules in a deep to surface transformational process. A TAG Involves the manipulation of very small elementary structures. This is because of the stipulation that elementary trees may not include recursive nodes. It implies that the sentences one sees in everyday usage, e.g. newpaper texts, are the result of many sucessive ad junctions. This melds nicely with a move that we have made in recent years to view the conceptual representation from which generation proceeds as consisting of a heap of very small, redundantly related information units that have been deliberately selected by a text planning process from the total state of the knowledge base at the time of utterance; such unit will correspond in the final text a lexical item plus selected thematic arguments—a linguistic entity that is easily projected onto the elementary trees of a TAG. includes only one operation, atikmedon, and otherwise makes no changes to the elementary trees go Into • This comports well with the indelibility stipulation in our model of generation, since selected text fragments can be used directly as specified by the grammar without the need for any later transformation. The composition options delimited by the constraints on adjunction given with a TAG define a space of alternative text forms which can correspond directly in generation to alternative conceptual relations among information units, alternatives in rhetorical intent, and alternatives in prose style. 3. Adapting TAG&apos;s to Generation The mapping from TAG &apos;s as a formalism for competence theories of language to our formalism for generation is strikingly direct. As we described in Section 5 their ad junction operation corresponds to our attachment process; their constraints on adjunction correspond to our attachment points; their surface structure trees correspond to surface structure We further hypothesize that two quite strong correspondence claims can be made, though considerably more experimentation and theorizing will have to be done with both formalisms before these claims can be confirmed. 1. The primitive information units in realization specifications can be realized exclusively as one or another elementary tree as defined by a suitable TAG, i.e. linguistic criteria can be used in determining the proper modularity of the Conversely, for relationship which our generator would derive by the attachment of multiple information units into a single package, there is a corresponding rule of adjunction. Since we use attachment in the realization of nominal like tanker&amp;quot;, has the force of extending the domain of TAG analyses into morphology. (See section 7). 4. The Place of Grammar in a Theory of Generation To understand why we are looking at TA G &apos;s rather than some other formalism, one must first understand the role of grammar within our processing model. The following is a brief summary of the model; a more complete description can be found in McDonald &amp; Pustepvsky (19854 Out model does not employ the simple trees of labeled nodes that appear in mon theoretical linguc analyses. Our surface structure incorporates the semantic proverb= of trees, but it abo includes reifications of constituent positions like nibnct&amp;quot; or &apos;sentence&amp;quot; and is better characterized overall as an &apos;executable positions&apos;. We discus this further in section 5.1. hypothesis ecenful. it has very consequential bnplications foe the &apos;kW of the information units that the text realization specification can use, e.g. they would not be realized as texts that include rectenve nodes. We win discus thin and other implications in a later paper. 95 We have always had two complementary goals in our research: on the one hand our generation program has had to be of practical utility to the knoviedge based expert systems that use it as part of a natural language interface. This means that architecturally our generator has always been designed to produce text from conceptual specifications, &amp;quot;pians&amp;quot;, developed by another program and consequently has had to be sensitive to the limitations and varying approaches of the present state of the art in conceptual representation. At the same time, we want the architecture of the virtual machine that we abstract out of our program to be effective as a source of psycholinguistic hypotheses about the actual generation process that humans use; it should, for example, provide the basis for predictive accounts of human speech error behavior and apparent planning limitations. To achieve this, we have restricted ourselves to a highly constrained set of representations and operations, and have adopted strong and suggestive stipulations on our design such as high locality, information encapsulation, quasi-realtime runtime performance, and This restricts us as programmers, but disciplines us as theorists. We see the process of generation as involving three temporally intermingled activities: (1) determining what goals the utterance is to achieve, (2) planning what information content and rhetorical force will best meet those goals given the context, and (3) realizing the specified information and intent as a grammatical text. Our linguistic LC), the Zetalisp program MUMBLE, handles the third of them activities, taking a &amp;quot;realization specification&amp;quot; as input, and producing a stream of morphologically specialized words $ as output. As described in (McDonald 1984 LC is a &amp;quot;desaiption-directed&amp;quot; process: it uses the structure of the realization specification it is given, plus the syntactic surface structure of the tett in progress (which it extends incrementally as the specification is realized) to directly control its actions, interpreting them as though they were sequential computer programs This technique imposes strong demands on the descriptive formalism used for in a computation requiem that no action of a (making deciamm constructing repremesurn changing etc.) can be transparently undone once it has been performed. Many nonbacktracking, amperage&apos; program designs have the property: it e our term for what Marcie [19001 refemed te m the property at being &apos;ruict/y detensinimie. mikados specificities be takes to correspond to what many racarchera, putiodarly psychologists, think at as the &apos;merge lever representation of • test. Which is to say that it preeently produces written rather than spokes tests. We espies to .or with speech output shanty, however. and the need to &apos;uppers the reprematatiosal basis of as intonational cootour is begMeing to inflame our deigns foe connitueney patterns in wsrfaas structure. representing surface structure. For example, nodes and category labels now designate actions the generator is to take (e.g. imposing scoping relations or constraining embedded decisions) and dictate the inclusion of function words and morphological specializations. 4.1 Unbundling Systemic Grammars Of the established linguistic formalisms, systemic grammar [Halliday 19761 has always been the most important to Al researchers on generation. Two of the most important generation systems that have been developed, PROTEUS (Davey 19741 and NIGEL (Mann &amp; Matthiessen 19831, use systemic grammar, and others, including ourselves, have been strongly influenced by it. The reasons for this enthusiasm are central to the special concerns of generation. Systemic grammars employ a functional vocabulary: they emphasize the uses to which language can be put—how languages achieve their speakers&apos; goals—rather than its formal structure. Since the generation process begins with goals, unlike the comprehension process which begins with structure, this orientation makes systemic grammars more immediately useful than, for example, transformational generativ• grammars or even procedurally oriented Al formalisms for language such as ATN&apos;s. The generation researcher&apos;s primary question is why use one construction rather than another—active instead of passive, &amp;quot;the&amp;quot; instead of &amp;quot;a&amp;quot;. The principle device of a systemic grammar, the &amp;quot;choice system&amp;quot;, supports this question by highlighting how the constructions of the language are grouped into sets of alternatives Choice systems pnrowle an anchoring point for the rules of a theory of language use ince it is natural to associate the various semantic, discourse, or rhetorical criteria that bear the selection of a given construction or choice system to which the construction belongs, thus providing the basis of a decision-procedure for selecting from its listed alternatives; the NIGEL system does precisely this in its &amp;quot;chooser&amp;quot; procedures. In our formalism we make use of the scone information as a systemic granunar captures. however we have choasen to it guise differently. underlying reason for this is that our concern for psycholinguistic modeling and efficient processing takes precedence in our design decisions about how the facts of language and language use should be represented in a generator. It is thus instructive to look at the different kinds of linguistic information that a network of choice systems carry. In our system we distribute these to separate computational devices. o Dependencies among structural features: A generator must respect the constraints that dependencies impose and appreciate the impact they have on its realization options: for example that some clauses express tense or modality while main dauses are required to; or that a pronominal direct object forces particle movement while a lexical objects leaves it optional. 96 o Usage criteria. The decision procedures associated with each choice system are not a part of the grammar per se, although they are naturally associated with it and organized by it. Also most systemic grammars include very abstract features such as &amp;quot;generic reference&amp;quot; or &amp;quot;completed action&amp;quot;, which cross-correlate the language&apos;s surface features, and thus are more controllen of why a construct is used rather than constructs themselves. o Coordinated structural alternatives. A sentence may be either active or passive, either a question or a statement. By grouping these alternatives into systems and using these systems exclusively when constructing a text, one is guaranteed not to combine inconsistent structural features. o Efficient ordering of choices. The network that connects choice systems provides a natural path between decisions, which if followed strictly guarentees that a choice will not be made unless it is required, and that it will not be made before any of the choices that it is itself dependent upon, insuring that it can be made indelibly. o Typology of surface structure. Almost by accident (since its specification is distributed throughout all of the systems implicitly), the grammar determines the pattern of dominance and constituency relationships of the text. While not a principle of the theory, the trees of clauses, NPs, etc. in systemic grammars tend to be shallow and broad. We believe, but have not yet established, that equivalence transformations can be defined that would take a systemic grammar as a specification to construct the alternative devices that we use in our generator (or augment devices that derive from other sources, e.g. a TAG) by decomposing the information in the systemic grammar along the lines just listed and redistributing it. 5. Example Analyses One of the task domains we are currently developing involves newspaper reports of current events. We are &apos;reverse engineering&apos; leading paragraphs from actual newspaper articles to produce narrow but complex conceptual representation, and then designing realization specifications—plans—that will lead our LC to reconstruct the original text or motivated variations on it. We have adopted this domain because the news reporting task, with its requirement of communicating what is new and significant in an event as well as the event itself, appears to impose exceptionally rich constraints on the selection of what conceptual information to report and on what syntactic constructions to use in reporting it (see discusdon in Clippinger &amp; McDonald [19P31. We expect to find out how much complexity a realization specification requires in order to motivate such carefully composed texts; this will later guide us in designing a ten planner with sufficient capabilities to construct such specifications on its own. Our examples are drawn from the tett fragment below (Associated Press, 12(23/84); the realization specification we use to reproduce the text follows. &amp;quot;LONDON - Two oil tankers, ffte Nonveglan-owned vassal, rated to have bean hit by MISSileS Friday In the Guff. Thorshavat wee ablaze tow to Bahrain, officials in Oslo said. Lloyds reported that crewman cri the Liberian alVp.&amp;quot; (lherday&apos;s-evarna-in-the-GUI-tanker-war avants-requIrecartlficatIon-as-to-sofice (main-evara rii&lt;sarrorevant-typs_vary112-Oafirof irssual #&lt;runber-of-ships-ha 2&gt; identify-the-ships ) (particslars 0&lt;darnagerraport Thonshavet Oslo-officials&gt; 0&lt;damage-report Uberian Lloyds&gt; )) Flgure 1 This realization specification represents the structured object which gives the toplevel plan for this utterance. Symbols preceded by colons indicate particular features of the utterance. The two expressions in parentheses are the content items of the specification and are restricted to appear in the utterance in that order. The first symbol in each expression is a label indicating the function of that item within the plan; embedded items appearing in angle brackets are information units from the current-events knowledge base. Obviously this plan must be considerably refined before it could serve as a proximal source for the text; that is why we point out that it is a &amp;quot;topievel&amp;quot; pian. It is a specification for the general outline of the utterance which must be fleshed out by recursive planning once its realization has begun and the LC can supply a linguistic contact to further constrain the choices for the units and the rhetorical features. For present purposes, the key fact to appreciate about this realization specification is how different it is in form from the surface structure. One cannot produce the ,ted text simply by traversing and &apos;reading out&amp;quot; the elements of the specification as though one were doing direct production. Structural rearrangements are required, and these must be done under the control of constraints which can only be stated in linguistic vocabulary with terms like &amp;quot;subject&amp;quot; or &amp;quot;raising&apos;. The fust unit in the specification, 0&lt;aameenrent-type_&gt;, is a relation over two other units. It indicates that a commonality between the two has been noticed and deemed significant in the underlying representation of the event. The present LC always realizes such relations by merging the realizations of the two units. If nothing else occurred, would give us the text oil tankers were kis by missiles&amp;quot;. 97 As it happens, however, a pending rhetorical constraint from the realization specification, aventsrequirscerUfleatIon-asto-soirce force the addition of yet another information the reporting event by the news service that announced the aledged event (e.g. a press release from Iraq, Reuters, etc.). In this case the &amp;quot;content&amp;quot; of the reporting event is the two damage-reports which have already been planned for inclusion in the utterance as part of the &apos;particulars&amp;quot; part of the specification. Let us look closely at how that reportiing event unit is folded into surface structure. When not itself the focus of attention, a reporting event is typically realized as &amp;quot;so-and-so said X&amp;quot;, that is, the content of the report is more important than the report itself; whatever significance the report or its source has as news will be indicated subtlly through which of the realizations below is selected for (deline-restmilon-dass believe-verbs : parameters (agent proposition verb) :choices (( (AGENT-VERBe-that-PROP agent verb prop) ernphasize(seff) ) e.g. reports Iraq kit two tankers.&amp;quot; encompasses variations with and without also ceaseless complements believes him ; to be a fool.&amp;quot; (passivize verb) clause focus((agent prop)) menUoned-eisewhere(agent) ) ; &amp;quot;Two tankers were reported to have been hit&amp;quot; ( Ot-VERB-PROP verb prop) clause Irderable(agent) ) e.g. is reported that 2 tankers were hit.&amp;quot; agent verb clause dwernphasizeOself) ) ; &amp;quot;Two tankers were his. Gulf sources said.&amp;quot; 3 Realization class assigned to Desired characteristic Resulting text report tankers were hit, Gulf shipping sources said. is given elsewhere tankers were reported his. report reported it hit two tankers. Figure 2 Possibilities for expresdng report(searce, info) in newpapu. prose In our LC, these alternative &amp;quot;choices&amp;quot; are grouped together into a &amp;quot;realization class&amp;quot; as shown in Figure 3. Our realization classes have their historic origins in the choice systems of systemic grammar, though they are very different in almost every concrete detail. The most important difference of interest theoretically is that while systemic choice systems select among single alternative features (e.g. passive, gerundive), realization classes select among entire surface structure fragments at a time (which might be seen as prespecified realizations of bundles of features). That is, our approach to generation calls for us to organize our decision procedures so as to select the values for a number of linguistic features simultaneously in one choice where a systemic grammar would make the will not disci= the mechanism by which features in the specification influence realization. Realization speeifiottions of the complexity of this example are still very new in our research and we are unsure whether the process is better organized at the conceptual level directing a composition proem within the netting component (during one of the immune invocations) or within the LC mediating a selection between anticipated alternatives. At this point our design experiments are inconcluieve. 7 These sentence are artificial; actual once would be considerably longer. Interestingly, certain other syntactically permeable versions u MIS that&apos; not any of the tests we examined. Perhaps the lead is too important to wane on • pronoun. Returning to our example, we are now faced now with need to incorporate a denoting the report of the Iraqi attacks into the utterance to act as a certification of the 0&lt;M-by-missies&gt; events. This will be done using the realization class belleve-verbs; the class is applicable to any information unit of the form reporlisoorce, Info) (and others). It determines the realization of such units 121tA when they appear in issolation and, as in the present case, when they are to augment an utterance corresponding to one of their arguments. From this realization class the choice raise-VERB-Into-PROP will be selected since (1) the fact that two ships were hit is most significant, meaning that the focus will be on the information and not the source (n.b. when the class executes the source Iraq will be bound to its parameter and the information about the missile hits to the proposition parameter); (2) there is no rhetorical motivation for us to occupy space in the first sentence with the sources of the report since they have already been planned to follow. These conditions are sensed by attached procedures associated with the characteristics that annotate choice (i.e. of using choke systems to control the active selection of utterance features is employed by the mom well-known applications of rystensic gammen to generation (i.e. the work of Davey (1974) and Mann and Mathieu= [1983D. However very raze work with systemic grammars at Edinburgh by Patten [19851 departs from de technique. Patten uses a semantic-level planning component to directly select grouts of features at the rightward. &apos;output&amp;quot;. Ode of a systemic netsiork, and then works backwards through the network to determine what other, not sanaiically specified features must be added to the WU for it to be grammatical; control is thus =Ode the grammar proper, with grammar mks reiepted to constraint specification only. We are intrigued by this technique and look forward &apos;i its further development. 98 Since the PROP is already in place in the surface structure tree, the LC will be interpreting ralooVEREI-Into-PROP as a specification of how it may fold auxiliary tree for the tree for were his by missiles Friday in the Gulf.</abstract>
<note confidence="0.829298">corresponds to the TAG analysis in Figure 4 [Kroch &amp; Joshi 19851.</note>
<title confidence="0.531897666666667">Initial Tree. Awaliary Tree: INFL NP INFL INFL VP</title>
<abstract confidence="0.996878876811594">be reported INFL be rut by missiles Figure 4 Inidal and anxilliary trees for Raising-te-subject initial tree for oil were his by missiles, may be extended at its NFL&amp;quot; node as indicated by the constraint given in parenthesis by that node. Figure 5 shows the tree after the auxiliary tree A2, named by that constraint has been adjoined. Notice that the original INFL&amp;quot; of Figure 4 is now in the complement position of giving us the sentence oil were reported hit by missiles. NP INFL num:ilea VP he reported INTL INFL VP be tdt by aussiles 5 After embedding Notation As readers of any of our earlier papers are aware, we do not employ a conventional tree notation in our LC. A generation model places its own kinds of demands on the of surface structure, lead to principled departures from the conventions adopted by theoretical linguists. Figure 6 shows the surface saucture as our LC would actually represent it just before the moment when the adjunction is made. . --&gt; [SENTENCE! ---. [SUBJECT&apos; [PkEDICATE1 0-Attach- Raising- by -arise i los -&gt; 6 Surface path notation call this representation notation it defines the path that our LC. Formally the structure is not a tree but a uni-directional linked list whose formation rules obey the axioms of a tree (e.g. any path &amp;quot;down&amp;quot; through a given node must eventually pass back &amp;quot;up&amp;quot; through that same node). The path consists of a stream of entitics representing phrasal nodes, constituent positions (indicated by square brackets), instances of information units (in boldface), instant= of words, and activated attachment points (the labeled circle under the predicate; tee next section). The various symbols in the figure (e.g. sentence, predicate, etc.) have attached procedures that are activated as the point of speech moves along the path, a process we call &amp;quot;phrase structure execution&amp;quot;. Phrase structure execution is the means by which grammatical constraints are imposed on embedded decisions and function words and grammatical morphemes are produced (For discussion see McDonald [1984D. Once one has begun to think of surface structure as a traversal path, it is a short step to imagining being able to the path and &amp;quot;splice in&amp;quot; additional position This splicing operation inherits a natural set of constraints on the kinds of distortions that it can perform, since, by the indelibility stipulation, existing position sequences can not be destroyed or rethreaded. It is our impression that these constraints will turn out to be formally the same as those of a TAG, but we have not yet carried out the detailed analyses to confirm this. posobility of cutting the airfare structure and inserting new sequences that change the linguistic coats of positions already in place has been in our theory of generation Mace WM when we used it to implement raking verbs whose rhetorical force was the same as adverbs tike present, much more ettensive use of this device as the core of a distinct attachment proms dates from the summer of 19114. 10 Constraints of this sort are an inovatios introduced in 1Crocit &amp; Joeld (19n5j. Previous maims of TAO them allowed &apos;contest aensieber constraint speeificatioes that in fats were newer exploited. The present constraints are more attractive formally since they must be stated locay to a single tree. ---&gt; [head] oil tanker 99 3.2 Attachment Points The TAG formalism allows a grammar writer to define &amp;quot;constraints&amp;quot; by annotating the nodes of elementary trees with lists indicating what auxiliary trees may be adjoined to (including &amp;quot;any&amp;quot; or In a similar manner the &amp;quot;choices&amp;quot; in our realization classes—which by our hypothesis can be taken to always =respond to TAG trees—include specifications of the which new information units can be incorporated into the surface structure path they define. Rather than being constraints on an otherwise freely applying operation, as in a TAG, attachment points are actual objscts interposed in the path notation of the surface structure. A list of the attachment points active at any moment is maintained by the attachment process and consulted whenever an information unit needs to be added. Most units could be attached at any of several points, with the decision being made on the basis of what would be most consistent with the desired prose style (d. McDonald and Pustejovsky [1983aD. When one of the points is selected it is Instantiated, usually splicing in new surface structure in the process, and the new unit added at a designated position within the new structure. Figure 7 shows our present definition of the attachment point that ultimately leads to the addition of &amp;quot;was reported&amp;quot;. (dethe-attechment-point attadwaiaimtpreciatte relsraneports Omen) ( raisavvern-with-complement(present-predeate) ) position-of-attachment-point ((al-slot &amp;quot;predicate phrase) attach-order ) navs-phrese-structtse (mbenergeiodsOnycontentwintrenew-etrucare ; of new phrase vent ; where the unit being attached goes inanitive•cornoiement) ; where the existing contents go sitect-cmother-pardnp.attactment-poinus none diolees.that-Iniroduce4 nholcalepaseiniktest (nciudes-slot &amp;quot;pnelloate)) 7 The attachment-paint used by was This attachment point goes with any choice (elementary tree) that includes a constituent position labeled predicate. It is placed in the position path immediately after (or &amp;quot;under&amp;quot;) that position (see Figure 6), where it is available to any new unit that passes the indicated requirements. When this attachment is =Meted, it builds a new VP node that has the old VP as one of its constituents, then splices this new node into the path in its place as shown in Figure 7. The unit being attached, e.g. the report of the attack on the two oil tankers, is made the verb of the new VP. Later, once the phrase structure execution process has walked into the new VP and reached that verb position, the unit&apos;s realization dam (belief-verbs) will be consulted and a choice selected that is consistent with the grammatical constraints of being a verb (i.e. a conventional variant on the raise-VERB-Into-PROP choice), giving us &amp;quot;was reported&amp;quot;. --) [SENTENCE] (PREDICATE] (verb] ---&gt; tint - • complement] ..,&gt; Fiore 8 The path after attadsment From this discussion one can see that our treatment of attachment uses two structures, an attachment point and a choice, where a TAG would only use one structure, an auxiliary tree. This is • consequence of the fact that we are working with a performance model of generation that must show explicitly how conceptual information units are rendered into tests as part of a psycholinguistically plausible psocees, while a TAG is a formalism for competence theories that only need to specify the syntactic structure of the grammatical strings of a language. This is a significant difference, but not one that should stand in our way in compering what the two theories have to offer each other. Consequently in the .rest of this paper we will omit the details of the path notation and attachment point definitions to facilitate the comparison of theoretical issues. 6. Generating questions using a TAG version of wiz-movement Earlier we illustrated the TAG concept of linking&amp;quot; by Mowing how one would start with an initial tree consisting of the innermost clause of a question phis the fronted wit-phrase and then build outward by successively adjoining the desired auxiliary phrases to the S node that intervenes between the wit-phrase and the clause. Wh-questions are thus built front the bottom up, as in fact is gnx sentence involving verbs taking sentential complements. This analysis has the desirable property of allowing one to state the dependencies between the Wh-phrase and the gap as a local relation on a single elementary one, eliminating the need to include any machinery for movement in the theory. All unbounded dependencies now from adjunction: far as the grammar is concerned, can be made without limit), rather than to the explicit migration of a constituent across clauses. We also find this locality property to be desirable, and use an analogous procedure in our production of questions and other kinds of Whquestions and unbounded dependency constructions. [SUBJECT] NP oil 100 This &amp;quot;bottom-up&amp;quot; design has consequences for how the realization soxifications for these constructions must be organized. In particular, the logician&apos;s usual representation of sentential complement verbs as higher operators is not tenable in that role. For example we cannot have the of, say. many ships did Reuters report that Iraq said it module the expression: Landida(quendty-et-ablps). report (Renters,sayaraq,altack(Iraq,quantitre(•ehips))) an expression defines a natural of exposure when used as realization specification, =nay that one realize the Lambda operator first, the report operator second, the say third, and so on. A local TAG analysis of Wit-movement requires us to have the Lambda and the expression containing its matrix once, attach, be present in a single layer&amp;quot; of the specification, otherwise we would be forced to violate one of the strong principles of our theory of generation. namely that the characteristics in a realization class may &amp;quot;see&amp;quot; only the immediate arguments of the unit being realiz&apos; ed; they may not look &amp;quot;inside&amp;quot; those arguments to subsequent levels of conceptual structure. This principle has served us well, and we are disinclined to give it up without a very compelling reason. We elected instead to give up the internal representation of sentential complement verb texts as single expressions. This move was easy for us to make since such expressions are awkward to manipulate in the &apos;East Coast&amp;quot; style frame knowledge bases that we use in our own reasoning programs, and we have preferred a represesitatMnal nyie with redundant, smaller sized conceptual units for quite some time. The representation we use instead amounts to breaking up the logical expression into individual units and allowing them to include references to each other. lambda(quantity-of.ships) . attack(Iraq,quantity-of-ships) U1) U3 reoornReuters, U2) Given such a network as the realization specification, the LC must have some principle by which to judge where to start: which unit should form the basis of the surface structure to which the others are then attached? A natural principle to adopt is to begin with the &amp;quot;bans&amp;quot; unit, i.e. the one that does cot mention any other units in its definition. We are considering adopting the policy that such units should be allowed only realizations as initial trees while units whose definition involves &amp;quot;pointing to&amp;quot; (naming) other units should be allowed only realizations as auxiliary trees. We have not, however, worked through all of the ramifications such a policy might have on other parts of our generation model; without yet knowing whether it would improve or degrade the other parts of our theory, we are reluctant to assert it as one of our hypotheses relating our generation model to TAG&apos;s. Given that three part source, the realization of the question is fairly straightforward (See Figure 9). The Lambda expression is assigned a realization ciass for ciausal Wit constructions, whereupon the extracted argument quantity-el-sides is placed in COMP, and the body of the expression is pieced in the HEAD position. At the same time, the two instances of quandty-et-sidm are specially marked. The one in COMP is assigned to the realization clam for Wit phrases appropriate to quantity (e.g. it will the choice natty X possibly related choices as &lt;quantity&gt; other variants appropriate to relative clauses or other positions where Wit caastructioas can be used). Simultaneously the instance of quantity-et-Alps in the argument position of the head frame attack is assigned to the realization class for Wit-trace. These two specializations are the equivalent, in our model, of the TAG linking relation. comp S WH(ships) Iraq attacx Flom 9 Question formation with senundai compiement verbs The two pending units, U2 and U3, are then attached to this matrix, submerging fust the attach unit and then U2 into complement positions. 7. Extensions to the Theory of TAG Context-free grammars are able to express the word formation processes that seem to exist for natural languages (cf. Williams (19811, Selkirk (19132D. A TAG analysis of such a grammar seems like a natural application to the current version of the theory (d. Pustejovsky (in preparation)). To illustrate our point. consider compounding rules in English. We can say that for a context-free grammar for word is a TAG. that is equivalent to (d. 10 and 11). Consider a fragment of 11 Whether the word formation component should in faa have the of a CFO is an opal questions. Langendoen (191111 diatoms the pombility that a Einius state ratamar might be suaktem Cot Ms generative capaOrr of natural language word Commas components.</abstract>
<note confidence="0.399788">101</note>
<title confidence="0.628867375">N-&gt;NIAIVIP N A-&gt;NIAIP A V -&gt; P V Figaro 10 CFG Fragment for Word Formates corresponding would be: A comp N comp A AUXILIARY TREES</title>
<abstract confidence="0.975876781818182">oi 1 tanker INITIAL TREES Figure 11 TAG Fragment for Word Formation consider the compound , ternand, from the newspaper reporting domain, and its derivation in TAG theory, shown in Figure 12. the penibility of expressing U2 prenominally. One of the choices associated with this unit is a compound structure—expressed in terms of an auxiliary tree. A snapshot at this point in the derivation shows the following StrUCtille. U2] U1] The next unit opened up in this structure is U3, which also allows for attachment prenotninally. Thus an auxiliary tree corresponding to 1.14 is introduced, giving us the snucture bedew: :wTv U311 The seiectional constraints imposed by the strucrural positioning of information unit U4 allows only a compounding choice. Had these been no word-level compound realization option, we would have worked our way into a corner without expressing the relation between *Coil&gt; and /0&lt;tanker&gt;. Because of this it may be better to view units such as U4 as being associated direcdy with a compounded form, i.e. tanker. partial solution, however, would not speak to the problem of active word formation in the language. Furthermore, it would be interesting to compare the strategic decisions made by a generation system with those planning mistakes made by humans when speaking. This is an aspect of generation that merits much further research. P V I terminal Comp N N oll C4‘ N ianki 12 TAG Derivation at tanker terminal Let us compare this derivation to the process used by the LC. The underlying information units from which this compound is derived in our system ate shown below. The planner has decided that the units below need to be communicated in order to adequately express the concept. The top4evei unit in this bundle is sr.:terminal&gt;. o&lt;ierniali&gt; eie.dnekeet U3 ili&lt;lanker&gt; .10&lt;carries U3&gt; U5 The run unit to be positioned in the surfaces structure is and appears as the head of an NP. There is an attachment point on this position, however, which allows for 102 8. Acknowledgements</abstract>
<note confidence="0.703729384615385">This research has been supterminaled in part by contract N0014-85-K-0017 from the Defense Advanced Research Projects Agency. We would like to thank Marie Vaughan for help in the preparation of this text. 9. References Clippinger, &amp; McDonald (1983) &apos;Why Good Writing is Easier to Understand&amp;quot;, Proc. UCAI-83, pp. 730-732. Davey (1974) Dbeourse Production, PhD. Dissertation, FAinburgh University; published in 1979 by Edinburgh University Press. Halliday (1976) System and Function in Language, Oxford University Press. Joshi (1983) &amp;quot;How Much Context-Sensitivity is Required to</note>
<title confidence="0.655936">Provide Reasonable Structural Descriptions: Tree</title>
<author confidence="0.250798">preprint to appear in Grammars</author>
<affiliation confidence="0.459563333333333">Karttunen, &amp; Zwicky (eds.) Natural Language Processing: Psycholinguistic, Computational, and Theoretical Perspectives, Cambridge University Press.</affiliation>
<address confidence="0.559494">Kroch, T. and A. Joshi (1985) &apos;Ile Linguistic Relevance of</address>
<affiliation confidence="0.9348285">Tree Adjoining Grammar&amp;quot;, University of Pennsylvania, Dept. of Computer and Information Science.</affiliation>
<address confidence="0.829615">Langendoen, D.T. (1981) &amp;quot;The Generative Capacity of</address>
<affiliation confidence="0.611984">Word-Formation Components&amp;quot;, Linguistic Inquiry,</affiliation>
<address confidence="0.61863">Volume 12.2</address>
<title confidence="0.8593185">amp; Matthiessen (1983) A Systemic Grammar for Generation, Freedle (ed.) Systemic Perspectives</title>
<note confidence="0.957081625">on Discourse, Abler. (1980) Theory of Syntactic Recognition for Natural Press. McDonald (1984) &amp;quot;Description Directed Control: Its Implications for Natural Language Generation&amp;quot;, in Cercone (ed.) Computational Linguistics, Pergamon Press. McDonald &amp; Pustejovsky (1985a) &amp;quot;SAMSON: a computational theory of prose style in generation&amp;quot;, Proceedings of the 1985 meeting of the European Association for Computational Linguistics. (1985b) &amp;quot;Description-Directed Natural Language Generation&amp;quot;, Proceedings of UCAI-85, W.1Caufmann Inc., Los Altos CA. Patten T. (1985) &amp;quot;A Problem Solving Approach to Generating Text from Systemic Grammars&amp;quot;, Proceedings of the 1985 meeting of the European Association for Computational Linguistics. Pustejovsky, J. (In Preparation) &amp;quot;Word Formation in Tree Adjoining Grammars&amp;quot; Selkirk (1902) The Syntax of Words, MTT Press. (1981) &amp;quot;Argument Structure and Morphology&amp;quot; Review, 81-114. 103</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Clippinger</author>
<author>McDonald</author>
</authors>
<title>Why Good Writing is Easier to Understand&amp;quot;,</title>
<date>1983</date>
<booktitle>Proc. UCAI-83,</booktitle>
<pages>730--732</pages>
<marker>Clippinger, McDonald, 1983</marker>
<rawString>Clippinger, &amp; McDonald (1983) &apos;Why Good Writing is Easier to Understand&amp;quot;, Proc. UCAI-83, pp. 730-732.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Davey</author>
</authors>
<title>Dbeourse Production, PhD. Dissertation, FAinburgh University; published in 1979 by Edinburgh</title>
<date>1974</date>
<publisher>University Press.</publisher>
<contexts>
<context position="13215" citStr="Davey 1974" startWordPosition="2086" endWordPosition="2087">begMeing to inflame our deigns foe connitueney patterns in wsrfaas structure. representing surface structure. For example, nodes and category labels now designate actions the generator is to take (e.g. imposing scoping relations or constraining embedded decisions) and dictate the inclusion of function words and morphological specializations. 4.1 Unbundling Systemic Grammars Of the established linguistic formalisms, systemic grammar [Halliday 19761 has always been the most important to Al researchers on generation. Two of the most important generation systems that have been developed, PROTEUS (Davey 19741 and NIGEL (Mann &amp; Matthiessen 19831, use systemic grammar, and others, including ourselves, have been strongly influenced by it. The reasons for this enthusiasm are central to the special concerns of generation. Systemic grammars employ a functional vocabulary: they emphasize the uses to which language can be put—how languages achieve their speakers&apos; goals—rather than its formal structure. Since the generation process begins with goals, unlike the comprehension process which begins with structure, this orientation makes systemic grammars more immediately useful than, for example, transformat</context>
<context position="26109" citStr="Davey (1974)" startWordPosition="4044" endWordPosition="4045">e bound to its parameter and the information about the missile hits to the proposition parameter); (2) there is no rhetorical motivation for us to occupy space in the first sentence with the sources of the report since they have already been planned to follow. These conditions are sensed by attached procedures associated with the characteristics that annotate the choice (i.e. focus and mentionedebewbere). 8 mu technique of using choke systems to control the active selection of utterance features is employed by the mom well-known applications of rystensic gammen to generation (i.e. the work of Davey (1974) and Mann and Mathieu= [1983D. However very raze work with systemic grammars at Edinburgh by Patten [19851 departs from de technique. Patten uses a semantic-level planning component to directly select grouts of features at the rightward. &apos;output&amp;quot;. Ode of a systemic netsiork, and then works backwards through the network to determine what other, not sanaiically specified features must be added to the WU for it to be grammatical; control is thus =Ode the grammar proper, with grammar mks reiepted to constraint specification only. We are intrigued by this technique and look forward &apos;i its further d</context>
</contexts>
<marker>Davey, 1974</marker>
<rawString>Davey (1974) Dbeourse Production, PhD. Dissertation, FAinburgh University; published in 1979 by Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Halliday</author>
</authors>
<title>System and Function in Language,</title>
<date>1976</date>
<publisher>University Press.</publisher>
<location>Oxford</location>
<contexts>
<context position="13055" citStr="Halliday 1976" startWordPosition="2061" endWordPosition="2062">ten rather than spokes tests. We espies to .or with speech output shanty, however. and the need to &apos;uppers the reprematatiosal basis of as intonational cootour is begMeing to inflame our deigns foe connitueney patterns in wsrfaas structure. representing surface structure. For example, nodes and category labels now designate actions the generator is to take (e.g. imposing scoping relations or constraining embedded decisions) and dictate the inclusion of function words and morphological specializations. 4.1 Unbundling Systemic Grammars Of the established linguistic formalisms, systemic grammar [Halliday 19761 has always been the most important to Al researchers on generation. Two of the most important generation systems that have been developed, PROTEUS (Davey 19741 and NIGEL (Mann &amp; Matthiessen 19831, use systemic grammar, and others, including ourselves, have been strongly influenced by it. The reasons for this enthusiasm are central to the special concerns of generation. Systemic grammars employ a functional vocabulary: they emphasize the uses to which language can be put—how languages achieve their speakers&apos; goals—rather than its formal structure. Since the generation process begins with goal</context>
</contexts>
<marker>Halliday, 1976</marker>
<rawString>Halliday (1976) System and Function in Language, Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshi</author>
</authors>
<title>How Much Context-Sensitivity is Required to Provide Reasonable Structural Descriptions: Tree Adjoining Grammars&amp;quot;, preprint to appear</title>
<date>1983</date>
<booktitle>Natural Language Processing: Psycholinguistic, Computational, and Theoretical Perspectives,</booktitle>
<editor>in Dowty, Karttunen, &amp; Zwicky (eds.)</editor>
<publisher>Cambridge University Press.</publisher>
<marker>Joshi, 1983</marker>
<rawString>Joshi (1983) &amp;quot;How Much Context-Sensitivity is Required to Provide Reasonable Structural Descriptions: Tree Adjoining Grammars&amp;quot;, preprint to appear in Dowty, Karttunen, &amp; Zwicky (eds.) Natural Language Processing: Psycholinguistic, Computational, and Theoretical Perspectives, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kroch</author>
<author>A Joshi</author>
</authors>
<title>Ile Linguistic Relevance of Tree Adjoining Grammar&amp;quot;,</title>
<date>1985</date>
<institution>University of Pennsylvania, Dept. of Computer and Information Science.</institution>
<contexts>
<context position="27052" citStr="Kroch &amp; Joshi 1985" startWordPosition="4198" endWordPosition="4201">etermine what other, not sanaiically specified features must be added to the WU for it to be grammatical; control is thus =Ode the grammar proper, with grammar mks reiepted to constraint specification only. We are intrigued by this technique and look forward &apos;i its further development. 98 Since the PROP is already in place in the surface structure tree, the LC will be interpreting ralooVEREI-Into-PROP as a specification of how it may fold the auxiliary tree for reported into the tree for TWO oil tankers were his by missiles Friday in the Gulf. This corresponds to the TAG analysis in Figure 4 [Kroch &amp; Joshi 19851. Initial Tree. Awaliary Tree: INFL NP INFL INFL VP two tankers / be reported INFL INFL VP be rut by missiles Figure 4 Inidal and anxilliary trees for Raising-te-subject The initial tree for Two oil tankers were his by missiles, h, may be extended at its NFL&amp;quot; node as indicated by the constraint given in parenthesis by that node. Figure 5 shows the tree after the auxiliary tree A2, named by that constraint has been adjoined. Notice that the original INFL&amp;quot; of Figure 4 is now in the complement position of report, giving us the sentence Two oil tankers were reported hit by missiles. NP INFL two n</context>
</contexts>
<marker>Kroch, Joshi, 1985</marker>
<rawString>Kroch, T. and A. Joshi (1985) &apos;Ile Linguistic Relevance of Tree Adjoining Grammar&amp;quot;, University of Pennsylvania, Dept. of Computer and Information Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D T Langendoen</author>
</authors>
<title>The Generative Capacity of Word-Formation Components&amp;quot;,</title>
<date>1981</date>
<journal>Linguistic Inquiry, Volume</journal>
<volume>12</volume>
<marker>Langendoen, 1981</marker>
<rawString>Langendoen, D.T. (1981) &amp;quot;The Generative Capacity of Word-Formation Components&amp;quot;, Linguistic Inquiry, Volume 12.2</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mann</author>
<author>Matthiessen</author>
</authors>
<title>Nigel: A Systemic Grammar for Test Generation,</title>
<date>1983</date>
<booktitle>Systemic Perspectives on Discourse,</booktitle>
<editor>in Freedle (ed.)</editor>
<location>Abler.</location>
<contexts>
<context position="13251" citStr="Mann &amp; Matthiessen 1983" startWordPosition="2090" endWordPosition="2093"> deigns foe connitueney patterns in wsrfaas structure. representing surface structure. For example, nodes and category labels now designate actions the generator is to take (e.g. imposing scoping relations or constraining embedded decisions) and dictate the inclusion of function words and morphological specializations. 4.1 Unbundling Systemic Grammars Of the established linguistic formalisms, systemic grammar [Halliday 19761 has always been the most important to Al researchers on generation. Two of the most important generation systems that have been developed, PROTEUS (Davey 19741 and NIGEL (Mann &amp; Matthiessen 19831, use systemic grammar, and others, including ourselves, have been strongly influenced by it. The reasons for this enthusiasm are central to the special concerns of generation. Systemic grammars employ a functional vocabulary: they emphasize the uses to which language can be put—how languages achieve their speakers&apos; goals—rather than its formal structure. Since the generation process begins with goals, unlike the comprehension process which begins with structure, this orientation makes systemic grammars more immediately useful than, for example, transformational generativ• grammars or even pr</context>
</contexts>
<marker>Mann, Matthiessen, 1983</marker>
<rawString>Mann &amp; Matthiessen (1983) Nigel: A Systemic Grammar for Test Generation, in Freedle (ed.) Systemic Perspectives on Discourse, Abler.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcus</author>
</authors>
<title>A Theory of Syntactic Recognition for Natural Language,</title>
<date>1980</date>
<publisher>MIT Press.</publisher>
<marker>Marcus, 1980</marker>
<rawString>Marcus (1980) A Theory of Syntactic Recognition for Natural Language, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>McDonald</author>
</authors>
<title>Description Directed Control: Its Implications for Natural Language Generation&amp;quot;,</title>
<date>1984</date>
<booktitle>Computational Linguistics,</booktitle>
<editor>in Cercone (ed.)</editor>
<publisher>Pergamon Press.</publisher>
<contexts>
<context position="11465" citStr="McDonald 1984" startWordPosition="1827" endWordPosition="1828">s as theorists. We see the process of generation as involving three temporally intermingled activities: (1) determining what goals the utterance is to achieve, (2) planning what information content and rhetorical force will best meet those goals given the context, and (3) realizing the specified information and rhetorical intent as a grammatical text. Our linguistic component (henceforth LC), the Zetalisp program MUMBLE, handles the third of them activities, taking a &amp;quot;realization specification&amp;quot; as input, and producing a stream of morphologically specialized words $ as output. As described in (McDonald 1984 LC is a &amp;quot;desaiption-directed&amp;quot; process: it uses the structure of the realization specification it is given, plus the syntactic surface structure of the tett in progress (which it extends incrementally as the specification is realized) to directly control its actions, interpreting them as though they were sequential computer programs This technique imposes strong demands on the descriptive formalism used for 3 .Indelibility in a computation requiem that no action of a proem (making deciamm constructing repremesurn changing stow etc.) can be transparently undone once it has been performed. Many </context>
</contexts>
<marker>McDonald, 1984</marker>
<rawString>McDonald (1984) &amp;quot;Description Directed Control: Its Implications for Natural Language Generation&amp;quot;, in Cercone (ed.) Computational Linguistics, Pergamon Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>McDonald</author>
<author>Pustejovsky</author>
</authors>
<title>SAMSON: a computational theory of prose style in generation&amp;quot;,</title>
<date>1985</date>
<booktitle>Proceedings of the</booktitle>
<marker>McDonald, Pustejovsky, 1985</marker>
<rawString>McDonald &amp; Pustejovsky (1985a) &amp;quot;SAMSON: a computational theory of prose style in generation&amp;quot;, Proceedings of the 1985 meeting of the European Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<title>Description-Directed Natural Language Generation&amp;quot;,</title>
<date>1985</date>
<booktitle>Proceedings of UCAI-85, W.1Caufmann Inc.,</booktitle>
<location>Los Altos CA.</location>
<marker>1985</marker>
<rawString>(1985b) &amp;quot;Description-Directed Natural Language Generation&amp;quot;, Proceedings of UCAI-85, W.1Caufmann Inc., Los Altos CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Patten</author>
</authors>
<title>A Problem Solving Approach to Generating Text from Systemic Grammars&amp;quot;,</title>
<date>1985</date>
<booktitle>Proceedings of the</booktitle>
<marker>Patten, 1985</marker>
<rawString>Patten T. (1985) &amp;quot;A Problem Solving Approach to Generating Text from Systemic Grammars&amp;quot;, Proceedings of the 1985 meeting of the European Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>(In Preparation) &amp;quot;Word Formation in Tree Adjoining Grammars&amp;quot;</title>
<date>1902</date>
<publisher>MTT Press.</publisher>
<location>Selkirk</location>
<marker>Pustejovsky, 1902</marker>
<rawString>Pustejovsky, J. (In Preparation) &amp;quot;Word Formation in Tree Adjoining Grammars&amp;quot; Selkirk (1902) The Syntax of Words, MTT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Williams</author>
</authors>
<title>Argument Structure and Morphology&amp;quot;</title>
<date>1981</date>
<journal>The Linguistic Review,</journal>
<volume>1</volume>
<pages>81--114</pages>
<contexts>
<context position="39937" citStr="Williams (1981" startWordPosition="6235" endWordPosition="6236">s in the argument position of the head frame attack is assigned to the realization class for Wit-trace. These two specializations are the equivalent, in our model, of the TAG linking relation. Rutrs Nope:.r?,s N / Iraq say comp S WH(ships) Iraq attacx Flom 9 Question formation with senundai compiement verbs The two pending units, U2 and U3, are then attached to this matrix, submerging fust the attach unit and then U2 into complement positions. 7. Extensions to the Theory of TAG Context-free grammars are able to express the word formation processes that seem to exist for natural languages (cf. Williams (19811, Selkirk (19132D. A TAG analysis of such a grammar seems like a natural application to the current version of the theory (d. Pustejovsky (in preparation)). To illustrate our point. consider compounding rules in English. We can say that for a context-free grammar for word formation. Gw, there is a TAG. Tw, that is equivalent to Gw (d. Figures 10 and 11). Consider a fragment of Gw beiow.11 11 Whether the word formation component should in faa have the power of a TAG or CFO is an opal questions. Langendoen (191111 diatoms the pombility that a Einius state ratamar might be suaktem Cot Ms generat</context>
</contexts>
<marker>Williams, 1981</marker>
<rawString>Williams (1981) &amp;quot;Argument Structure and Morphology&amp;quot; The Linguistic Review, 1, 81-114.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>