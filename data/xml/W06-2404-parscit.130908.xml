<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.9986515">
Chunking Japanese Compound Functional Expressions
by Machine Learning
</title>
<author confidence="0.868702">
Masatoshi Tsuchiya† and Takao Shime‡ and Toshihiro Takagi‡
Takehito Utsuro†† and Kiyotaka Uchimoto†‡ and Suguru Matsuyoshi‡
Satoshi Sato‡‡ and Seiichi Nakagawa‡††Computer Center / $†Department of Information and Computer Sciences,
</author>
<affiliation confidence="0.810013625">
Toyohashi University of Technology, Tenpaku-cho, Toyohashi, 441–8580, JAPAN
$Graduate School of Informatics, Kyoto University, Sakyo-ku, Kyoto, 606–8501, JAPAN
††Graduate School of Systems and Information Engineering, University of Tsukuba,
1-1-1, Tennodai, Tsukuba, 305-8573, JAPAN
†$National Institute of Information and Communications Technology,
3–5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619–0289 JAPAN
$$Graduate School of Engineering, Nagoya University,
Furo-cho, Chikusa-ku, Nagoya, 464–8603, JAPAN
</affiliation>
<sectionHeader confidence="0.981073" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999956785714286">
The Japanese language has various types
of compound functional expressions,
which are very important for recogniz-
ing the syntactic structures of Japanese
sentences and for understanding their
semantic contents. In this paper, we
formalize the task of identifying Japanese
compound functional expressions in a
text as a chunking problem. We apply a
machine learning technique to this task,
where we employ that of Support Vector
Machines (SVMs). We show that the pro-
posed method significantly outperforms
existing Japanese text processing tools.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963428571429">
As in the case of other languages, the Japanese
language has various types of functional words
such as post-positional particles and auxiliary
verbs. In addition to those functional words,
the Japanese language has much more compound
functional expressions which consist of more than
one words including both content words and func-
tional words. Those single functional words as
well as compound functional expressions are very
important for recognizing the syntactic structures
of Japanese sentences and for understanding their
semantic contents. Recognition and understanding
of them are also very important for various kinds
of NLP applications such as dialogue systems, ma-
chine translation, and question answering. How-
ever, recognition and semantic interpretation of
compound functional expressions are especially
difficult because it often happens that one com-
pound expression may have both a literal (in other
words, compositional) content word usage and
a non-literal (in other words, non-compositional)
functional usage.
For example, Table 1 shows two example sen-
tences of a compound expression “に (ni) ついて
(tsuite)”, which consists of a post-positional par-
ticle “に (ni)”, and a conjugated form “ついて
(tsuite)” of a verb “つく (tsuku)”. In the sentence
(A), the compound expression functions as a case-
marking particle and has a non-compositional
functional meaning “about”. On the other hand,
in the sentence (B), the expression simply corre-
sponds to a literal concatenation of the usages of
the constituents: the post-positional particle “に
(ni)” and the verb “ついて (tsuite)”, and has a
content word meaning “follow”. Therefore, when
considering machine translation of those Japanese
sentences into English, it is necessary to precisely
judge the usage of the compound expression “に
(ni) ついて (tsuite)”, as shown in the English trans-
lation of the two sentences in Table 1.
There exist widely-used Japanese text process-
ing tools, i.e., pairs of a morphological analysis
tool and a subsequent parsing tool, such as JU-
MAN1+ KNP2 and ChaSen3+ CaboCha4. How-
ever, they process those compound expressions
only partially, in that their morphological analy-
sis dictionaries list only limited number of com-
pound expressions. Furthermore, even if certain
expressions are listed in a morphological analysis
</bodyText>
<footnote confidence="0.992254428571429">
1http://www.kc.t.u-tokyo.ac.jp/
nl-resource/juman-e.html
2http://www.kc.t.u-tokyo.ac.jp/
nl-resource/knp-e.html
3http://chasen.naist.jp/hiki/ChaSen/
4http://chasen.org/˜taku/software/
cabocha/
</footnote>
<page confidence="0.998153">
25
</page>
<tableCaption confidence="0.999404">
Table 1: Translation Selection of a Japanese Compound Expression “に (ni) ついて (tsuite)”
</tableCaption>
<table confidence="0.998795833333333">
私 (watashi) は (ha) 彼 (kare) に (ni) ついて (tsuite) 話した (hanashita)
(I) (TOP) (he) (about) (talked)
(I talked about him.)
私 (watashi) は (ha) 彼 (kare) に (ni) ついて (tsuite) 走った (hashitta)
(I) (TOP) (he) (ACC) (follow) (ran)
(I ran following him.)
</table>
<tableCaption confidence="0.995565">
Table 2: Classification of Functional Expressions based on Grammatical Function
</tableCaption>
<bodyText confidence="0.908488813953488">
Grammatical Function Type # of major # of Example
expressions variants
post-positional subsequent to predicate 36 67 となると
particle / modifying predicate (to-naru-to)
type
subsequent to nominal 45 121 にかけては
/ modifying predicate (ni-kakete-ha)
subsequent to predicate, nominal 2 3 という
/ modifying nominal (to-iu)
auxiliary verb type 42 146 ていい (te-ii)
total 125 337 —
dictionary, those existing tools often fail in resolv-
ing the ambiguities of their usages, such as those
in Table 1. This is mainly because the frame-
work of those existing tools is not designed so as
to resolve such ambiguities of compound (possi-
bly functional) expressions by carefully consider-
ing the context of those expressions.
Considering such a situation, it is necessary
to develop a tool which properly recognizes and
semantically interprets Japanese compound func-
tional expressions. In this paper, we apply a ma-
chine learning technique to the task of identify-
ing Japanese compound functional expressions in
a text. We formalize this identification task as a
chunking problem. We employ the technique of
Support Vector Machines (SVMs) (Vapnik, 1998)
as the machine learning technique, which has been
successfully applied to various natural language
processing tasks including chunking tasks such
as phrase chunking (Kudo and Matsumoto, 2001)
and named entity chunking (Mayfield et al., 2003).
In the preliminary experimental evaluation, we fo-
cus on 52 expressions that have balanced distribu-
tion of their usages in the newspaper text corpus
and are among the most difficult ones in terms of
their identification in a text. We show that the pro-
posed method significantly outperforms existing
Japanese text processing tools as well as another
tool based on hand-crafted rules. We further show
that, in the proposed SVMs based framework, it is
sufficient to collect and manually annotate about
50 training examples per expression.
</bodyText>
<sectionHeader confidence="0.977855333333333" genericHeader="method">
2 Japanese Compound Functional
Expressions and their Example
Database
</sectionHeader>
<subsectionHeader confidence="0.992706">
2.1 Japanese Compound Functional
Expressions
</subsectionHeader>
<bodyText confidence="0.999854285714286">
There exist several collections which list Japanese
functional expressions and examine their usages.
For example, (Morita and Matsuki, 1989) examine
450 functional expressions and (Group Jamashii,
1998) also lists 965 expressions and their exam-
ple sentences. Compared with those two collec-
tions, Gendaigo Hukugouji Youreishu (National
Language Research Institute, 2001) (henceforth,
denoted as GHY) concentrates on 125 major func-
tional expressions which have non-compositional
usages, as well as their variants5 (337 expressions
in total), and collects example sentences of those
expressions. As a first step of developing a tool for
identifying Japanese compound functional expres-
sions, we start with those 125 major functional ex-
pressions and their variants. In this paper, we take
an approach of regarding each of those variants as
a fixed expression, rather than a semi-fixed expres-
sion or a syntactically-flexible expression (Sag et
al., 2002). Then, we focus on evaluating the ef-
fectiveness of straightforwardly applying a stan-
</bodyText>
<footnote confidence="0.73283">
5For each of those 125 major expressions, the differences
between it and its variants are summarized as below: i) in-
sertion/deletion/alternation of certain particles, ii) alternation
of synonymous words, iii) normal/honorific/conversational
forms, iv) base/adnominal/negative forms.
</footnote>
<page confidence="0.999215">
26
</page>
<tableCaption confidence="0.999753">
Table 3: Examples of Classifying Functional/Content Usages
</tableCaption>
<table confidence="0.833476763157895">
Expression Example sentence (English translation) Usage
となると しかしこの病気に効果がない となると functional
(to-naru-to) (となると (to-naru-to) = if)
事は重大だ。
(The situation is serious if it is not effec-
tive against this disease.)
となると 彼 が 社 長 に な る た め の 条 件 の 一 つ content
(to-naru-to) (∼ となると (to-naru-to)
= that (something) becomes ∼)
となると 考えられている。
(They think that it will become a require-
ment for him to be the president.)
にかけては お金を儲けること にかけては 素晴らし functional
(ni-kakete-ha) (∼ にかけては (ni-kakete-ha)
= for ∼)
い才能をもっている。
(He has a great talent for earning money.)
にかけては あまり気 にかけては いない。 content
(ni-kakete-ha) ( (∼ を) 気にかけては
((∼)-wo-ki-ni-kakete-ha)
= worry about ∼)
(I do not worry about it.)
という 彼は生きている という 知らせを聞い functional
(to-iu) (∼という (to-iu) = that ∼)
た。
(I heard that he is alive.)
という 「遊びに来て下さい」という 人もいる。 content
(to-iu) (∼ という (to-iu)
= say (that) ∼)
(Somebody says “Please visit us.”.)
ていい この議論が終ったら休憩し ていい 。 functional
(te-ii) (∼ ていい (te-ii) = may ∼)
(You may have a break after we finish this
discussion.)
ていい このかばんは大きく ていい 。 content
(te-ii) (∼ ていい (te-ii)
= nice because ∼)
(This bag is nice because it is big.)
</table>
<bodyText confidence="0.999967863636364">
dard chunking technique to the task of identifying
Japanese compound functional expressions.
As in Table 2, according to their grammat-
ical functions, those 337 expressions in total
are roughly classified into post-positional particle
type, and auxiliary verb type. Functional expres-
sions of post-positional particle type are further
classified into three subtypes: i) those subsequent
to a predicate and modifying a predicate, which
mainly function as conjunctive particles and are
used for constructing subordinate clauses, ii) those
subsequent to a nominal, and modifying a predi-
cate, which mainly function as case-marking parti-
cles, iii) those subsequent to a nominal, and modi-
fying a nominal, which mainly function as adnom-
inal particles and are used for constructing adnom-
inal clauses. For each of those types, Table 2 also
shows the number of major expressions as well as
that of their variants listed in GHY, and an exam-
ple expression. Furthermore, Table 3 gives exam-
ple sentences of those example expressions as well
as the description of their usages.
</bodyText>
<subsectionHeader confidence="0.995596">
2.2 Issues on Identifying Compound
Functional Expressions in a Text
</subsectionHeader>
<bodyText confidence="0.999908428571428">
The task of identifying Japanese compound func-
tional expressions roughly consists of detecting
candidates of compound functional expressions in
a text and of judging the usages of those can-
didate expressions. The class of Japanese com-
pound functional expressions can be regarded as
closed and their number is at most a few thousand.
</bodyText>
<page confidence="0.999083">
27
</page>
<tableCaption confidence="0.997166">
Table 4: Examples of Detecting more than one Candidate Expression
</tableCaption>
<bodyText confidence="0.951049642857143">
Expression Example sentence (English translation) Usage
という それが試合 という ものの難しさだ。 functional
(to-iu) (NP1 という (to-iu)NP2
= NP2 called as NP1)
(That’s why a match is not so easy.)
というものの 勝った というものの 、スコアは悪い。 functional
(to-iu-mono-no) (— というものの
(to-iu-mono-no)
= although —)
(Although he won, the score is bad.)
Therefore, it is easy to enumerate all the com-
pound functional expressions and their morpheme
sequences. Then, in the process of detecting can-
didates of compound functional expressions in a
text, the text are matched against the morpheme
sequences of the compound functional expressions
considered.
Here, most of the 125 major functional expres-
sions we consider in this paper are compound ex-
pressions which consist of one or more content
words as well as functional words. As we intro-
duced with the examples of Table 1, it is often
the case that they have both a compositional con-
tent word usage as well as a non-compositional
functional usage. For example, in Table 3, the
expression “となると (to-naru-to)” in the sen-
tence (2) has the meaning “ that (something) be-
comes —”, which corresponds to a literal concate-
nation of the usages of the constituents: the post-
positional particle “と”, the verb “なる”, and the
post-positional particle “と”, and can be regarded
as a content word usage. On the other hand, in
the case of the sentence (1), the expression “とな
ると (to-naru-to)” has a non-compositional func-
tional meaning “if”. Based on this discussion, we
classify the usages of those expressions into two
classes: functional and content. Here, functional
usages include both non-compositional and com-
positional functional usages, although most of the
functional usages of those 125 major expressions
can be regarded as non-compositional. On the
other hand, content usages include compositional
content word usages only.
More practically, in the process of detecting
candidates of compound functional expressions in
a text, it can happen that more than one can-
didate expression is detected. For example, in
Table 4, both of the candidate compound func-
tional expressions “という (to-iu)” and “という
ものの (to-iu-mono-no)” are detected in the sen-
tence (9). This is because the sequence of the two
morphemes “と (to)” and “いう (iu)” constituting
the candidate expression “という (to-iu)” is a sub-
sequence of the four morphemes constituting the
candidate expression “というものの (to-iu-mono-
no)” as below:
</bodyText>
<equation confidence="0.863948166666667">
Morpheme sequence
と (to) いう (iu) もの (mono) の (no)
Candidate expression という (to-iu)
と (to) いう (iu) もの (mono) の (no)
Candidate expression というものの (to-iu-mono-no)
と (to) いう (iu) もの (mono) の (no)
</equation>
<bodyText confidence="0.995520703703704">
This is also the case with the sentence (10).
Here, however, as indicated in Table 4, the sen-
tence (9) is an example of the functional usage of
the compound functional expression “という (to-
iu)”, where the sequence of the two morphemes “
と (to)” and “いう (iu)” should be identified and
chunked into a compound functional expression.
On the other hand, the sentence (10) is an ex-
ample of the functional usage of the compound
functional expression “というものの (to-iu-mono-
no)”, where the sequence of the four morphemes “
と (to)”, “いう (iu)”, “もの (mono)”, and “の (no)”
should be identified and chunked into a compound
functional expression. Actually, in the result of
our preliminary corpus study, at least in about 20%
of the occurrences of Japanese compound func-
tional expressions, more than one candidate ex-
pression can be detected. This result indicates that
it is necessary to consider more than one candidate
expression in the task of identifying a Japanese
compound functional expression, and also in the
task of classifying the functional/content usage of
a candidate expression. Thus, in this paper, based
on this observation, we formalize the task of iden-
tifying Japanese compound functional expressions
as a chunking problem, rather than a classification
problem.
</bodyText>
<page confidence="0.998516">
28
</page>
<tableCaption confidence="0.987082">
Table 5: Number of Sentences collected from
</tableCaption>
<table confidence="0.909427166666667">
1995 Mainichi Newspaper Texts (for 337 Expres-
sions)
# of expressions
50 &lt; # of sentences 187 (55%)
0 &lt; # of sentences &lt; 50 117 (35%)
# of sentences = 0 33 (10%)
</table>
<subsectionHeader confidence="0.996674">
2.3 Developing an Example Database
</subsectionHeader>
<bodyText confidence="0.999982">
We developed an example database of Japanese
compound functional expressions, which is used
for training/testing a chunker of Japanese com-
pound functional expressions (Tsuchiya et al.,
2005). The corpus from which we collect example
sentences is 1995 Mainichi newspaper text corpus
(1,294,794 sentences, 47,355,330 bytes). For each
of the 337 expressions, 50 sentences are collected
and chunk labels are annotated according to the
following procedure.
</bodyText>
<listItem confidence="0.9251476">
1. The expression is morphologically analyzed
by ChaSen, and its morpheme sequence6 is
obtained.
2. The corpus is morphologically analyzed by
ChaSen, and 50 sentences which include the
morpheme sequence of the expression are
collected.
3. For each sentence, every occurrence of the
337 expressions is annotated with one of the
usages functional/content by an annotator7.
</listItem>
<bodyText confidence="0.999941666666667">
Table 5 classifies the 337 expressions accord-
ing to the number of sentences collected from the
1995 Mainichi newspaper text corpus. For more
than half of the 337 expressions, more than 50 sen-
tences are collected, although about 10% of the
377 expressions do not appear in the whole cor-
pus. Out of those 187 expressions with more than
50 sentences, 52 are those with balanced distribu-
tion of the functional/content usages in the news-
paper text corpus. Those 52 expressions can be re-
garded as among the most difficult ones in the task
of identifying and classifying functional/content
</bodyText>
<footnote confidence="0.943316181818182">
6For those expressions whose constituent has conjugation
and the conjugated form also has the same usage as the ex-
pression with the original form, the morpheme sequence is
expanded so that the expanded morpheme sequences include
those with conjugated forms.
7For the most frequent 184 expressions, on the average,
the agreement rate between two human annotators is 0.93 and
the Kappa value is 0.73, which means allowing tentative con-
clusions to be drawn (Carletta, 1996; Ng et al., 1999). For
65% of the 184 expressions, the Kappa value is above 0.8,
which means good reliability.
</footnote>
<bodyText confidence="0.999618909090909">
usages. Thus, this paper focuses on those 52 ex-
pressions in the training/testing of chunking com-
pound functional expressions. We extract 2,600
sentences (= 52 expressions x 50 sentences) from
the whole example database and use them for
training/testing the chunker. The number of the
morphemes for the 2,600 sentences is 92,899. We
ignore the chunk labels for the expressions other
than the 52 expressions, resulting in 2,482/701
chunk labels for the functional/content usages, re-
spectively.
</bodyText>
<sectionHeader confidence="0.7668405" genericHeader="method">
3 Chunking Japanese Compound
Functional Expressions with SVMs
</sectionHeader>
<subsectionHeader confidence="0.999852">
3.1 Support Vector Machines
</subsectionHeader>
<bodyText confidence="0.999984181818182">
The principle idea of SVMs is to find a separate
hyperplane that maximizes the margin between
two classes (Vapnik, 1998). If the classes are not
separated by a hyperplane in the original input
space, the samples are transformed in a higher di-
mensional features space.
Giving x is the context (a set of features) of
an input example; xi and yi(i = 1, ..., l, xi E
Rn, yi E11, −1}) indicate the context of the train-
ing data and its category, respectively; The deci-
sion function f in SVM framework is defined as:
</bodyText>
<equation confidence="0.997439333333333">
l l
Ax) = sgn(i=1
E αiyiK(xi, x) + b I (1)
</equation>
<bodyText confidence="0.999015666666667">
where K is a kernel function, b E R is a thresh-
old, and αi are weights. Besides, the weights αi
satisfy the following constraints:
</bodyText>
<equation confidence="0.9996165">
0 &lt; αi &lt; C (i = 1, ...,l) (2)
Eli=1 αiyi = 0 (3)
</equation>
<bodyText confidence="0.9924693">
where C is a misclassification cost. The xi with
non-zero αi are called support vectors. To train
an SVM is to find the αi and the b by solving the
optimization problem; maximizing the following
under the constraints of (2) and (3):
αiαjyiyjK(xi, xj) (4)
The kernel function K is used to transform the
samples in a higher dimensional features space.
Among many kinds of kernel functions available,
we focus on the d-th polynomial kernel:
</bodyText>
<equation confidence="0.999744666666667">
K(x, y) = (x · y + 1)d (5)
L(α) = �l αi − 1 �l
i=1 2 i,j=1
</equation>
<page confidence="0.993806">
29
</page>
<bodyText confidence="0.99978475">
Through experimental evaluation on chunking
Japanese compound functional expressions, we
compared polynomial kernels with d = 1, 2, and
3. Kernels with d = 2 and 3 perform best, while
the kernel with d = 3 requires much more compu-
tational cost than that with d = 2. Thus, through-
out the paper, we show results with the quadratic
kernel (d = 2).
</bodyText>
<subsectionHeader confidence="0.999976">
3.2 Chunking with SVMs
</subsectionHeader>
<bodyText confidence="0.9999787">
This section describes details of formalizing the
chunking task using SVMs. In this paper, we use
an SVMs-based chunking tool YamCha8 (Kudo
and Matsumoto, 2001). In the SVMs-based
chunking framework, SVMs are used as classi-
fiers for assigning labels for representing chunks
to each token. In our task of chunking Japanese
compound functional expressions, each sentence
is represented as a sequence of morphemes, where
a morpheme is regarded as a token.
</bodyText>
<subsectionHeader confidence="0.882088">
3.2.1 Chunk Representation
</subsectionHeader>
<bodyText confidence="0.997827592592592">
For representing proper chunks, we employ
IOB2 representation, one of those which have
been studied well in various chunking tasks of nat-
ural language processing (Tjong Kim Sang, 1999;
Kudo and Matsumoto, 2001). This method uses
the following set of three labels for representing
proper chunks.
I Current token is a middle or the end of a
chunk consisting of more than one token.
O Current token is outside of any chunk.
B Current token is the beginning of a chunk.
As we described in section 2.2, given a candi-
date expression, we classify the usages of the ex-
pression into two classes: functional and content.
Accordingly, we distinguish the chunks of the two
types: the functional type chunk and the content
type chunk. In total, we have the following five la-
bels for representing those chunks: B-functional,
I-functional, B-content, I-content, and O. Ta-
ble 6 gives examples of those chunk labels rep-
resenting chunks.
Finally, as for exending SVMs to multi-class
classifiers, we experimentally compare the pair-
wise method and the one vs. rest method, where
the pairwise method slightly outperformed the one
vs. rest method. Throughout the paper, we show
results with the pairwise method.
</bodyText>
<footnote confidence="0.9932525">
8http://chasen.org/˜taku/software/
yamcha/
</footnote>
<subsectionHeader confidence="0.373277">
3.2.2 Features
</subsectionHeader>
<bodyText confidence="0.999765666666667">
For the feature sets for training/testing of
SVMs, we use the information available in the sur-
rounding context, such as the morphemes, their
parts-of-speech tags, as well as the chunk labels.
More precisely, suppose that we identify the chunk
label ci for the i-th morpheme:
</bodyText>
<table confidence="0.8069492">
−→ Parsing Direction −→
Morpheme mi−2 mi−1 mi mi+1 mi+2
Feature set Fi−2 Fi−1 Fi Fi+1 Fi+2
at a position
Chunk label ci−2 ci−1
</table>
<bodyText confidence="0.987680257142857">
Here, mi is the morpheme appearing at i-th po-
sition, Fi is the feature set at i-th position, and ci
is the chunk label for i-th morpheme. Roughly
speaking, when identifying the chunk label ci for
the i-th morpheme, we use the feature sets Fi−2,
Fi−1, Fi, Fi+1, Fi+2 at the positions i − 2, i − 1,
i, i + 1, i + 2, as well as the preceding two chunk
labels ci−2 and ci−1.
The detailed definition of the feature set Fi at i-
th position is given below. The feature set Fi is de-
fined as a tuple of the morpheme feature MF(mi)
of the i-th morpheme mi, the chunk candidate fea-
ture CF(i) at i-th position, and the chunk context
feature OF(i) at i-th position.
Fi = (MF(mi), CF(i), OF(i) )
The morpheme feature MF(mi) consists of the
lexical form, part-of-speech, conjugation type and
form, base form, and pronunciation of mi.
The chunk candidate feature CF(i) and the
chunk context feature OF(i) are defined consid-
ering the candidate compound functional expres-
sion, which is a sequence of morphemes includ-
ing the morpheme mi at the current position i. As
we described in section 2, the class of Japanese
compound functional expressions can be regarded
as closed and their number is at most a few thou-
sand. Therefore, it is easy to enumerate all the
compound functional expressions and their mor-
pheme sequences. Chunk labels other than O
should be assigned to a morpheme only when it
constitutes at least one of those enumerated com-
pound functional expressions. Suppose that a se-
quence of morphemes mj ... mi ... mk including
mi at the current position i constitutes a candidate
functional expression E as below:
</bodyText>
<equation confidence="0.550207">
mj−2 mj−1 mj ... mi ... mk mk+1 mk+2
</equation>
<bodyText confidence="0.838583727272727">
candidate E of
a compound
functional expression
where the morphemes mj−2, mj−1, mk+1, and
mk+2 are at immediate left/right contexts of E.
Then, the chunk candidate feature CF(i) at i-th
position is defined as a tuple of the number of mor-
phemes constituting E and the position of mi in
E. The chunk context feature OF(i) at i-th posi-
tion is defined as a tuple of the morpheme features
ci
</bodyText>
<page confidence="0.995017">
30
</page>
<tableCaption confidence="0.997396">
Table 6: Examples of Chunk Representation and Chunk Candidate/Context Features
</tableCaption>
<table confidence="0.993270869565217">
(a) Sentence (7) of Table 3
Morpheme (English Chunk label Chunk candidate Chunk context
translation) feature feature
この (kono) (this) O 0 0
議論 (giron) (discussion) O 0 0
が (ga) (NOM) O 0 0
終わっ(owatt) (finish) O 0 0
たら (tara) (after) O 0 0
休憩 (kyuukei) (break) O 0 0
し (shi) (have) O 0 0
て (te) B-functional (2,1) ( MF(休憩 (kyuukei)), 0, MF( し (shi)), 0,
(ii) (may) I-functional (2,2) MF(。(period)), 0, 0, 0 )
。(period) (period) O 0 0
(b) Sentence (8) of Table 3
Morpheme (English Chunk label Chunk candidate Chunk context
translation) feature feature
この (kono) (this) O 0 0
かばん (bag) (discussion) O 0 0
は (ha) (TOP) O 0 0
大きく (ookiku) (big) O 0 0
て (te) (because) B-content (2,1) ( MF(は (ha)), 0, MF(大きく (ookiku)), 0,
いい (ii) (nice) I-content (2,2) MF(。(period)), 0, 0, 0 )
。(period) (period) O 0 0
</table>
<bodyText confidence="0.9972585">
as well as the chunk candidate features at immedi-
ate left/right contexts of E.
</bodyText>
<equation confidence="0.9976762">
CF(i) = ( length of E, position of mi in E )
OF(i) = ( MF(mj−2), CF(j − 2),
MF(mj−1), CF(j − 1),
MF(mk+1), CF(k + 1),
MF(mk+2), CF(k + 2) )
</equation>
<bodyText confidence="0.997358777777778">
Table 6 gives examples of chunk candidate fea-
tures and chunk context features
It can happen that the morpheme at the cur-
rent position i constitutes more than one candidate
compound functional expression. For example,
in the example below, the morpheme sequences
mi−1mimi+1, mi−1mi, and mimi+1mi+2 consti-
tute candidate expressions E1, E2, and E3, respec-
tively.
</bodyText>
<table confidence="0.86678">
Morpheme sequence mi−1 mi mi+1 mi+2
Candidate E1 mi−1 mi mi+1
Candidate E2 mi−1 mi
Candidate E3 mi mi+1 mi+2
</table>
<bodyText confidence="0.998236857142857">
In such cases, we prefer the one starting with the
leftmost morpheme. If more than one candidate
expression starts with the leftmost morpheme, we
prefer the longest one. In the example above, we
prefer the candidate E1 and construct the chunk
candidate features and chunk context features con-
sidering E1 only.
</bodyText>
<sectionHeader confidence="0.999278" genericHeader="evaluation">
4 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.999964740740741">
The detail of the data set we use in the experimen-
tal evaluation was presented in section 2.3. As we
show in Table 7, performance of our SVMs-based
chunkers as well as several baselines including ex-
isting Japanese text processing tools is evaluated
in terms of precision/recall/Fβ=1 of identifying
functional chunks. Performance is evaluated also
in terms of accuracy of classifying detected can-
didate expressions into functional/content chunks.
Among those baselines, “majority ( = functional)”
always assigns functional usage to the detected
candidate expressions. “Hand-crafted rules” are
manually created 145 rules each of which has con-
ditions on morphemes constituting a compound
functional expression as well as those at immedi-
ate left/right contexts. Performance of our SVMs-
based chunkers is measured through 10-fold cross
validation.
As shown in Table 7, our SVMs-based chunkers
significantly outperform those baselines both in
Fβ=1 and classification accuracy9. We also evalu-
ate the effectiveness of each feature set, i.e., the
morpheme feature, the chunk candidate feature,
and the chunk context feature. The results in the
table show that the chunker with the chunk candi-
date feature performs almost best even without the
chunk context feature10.
</bodyText>
<footnote confidence="0.631628625">
9Recall of existing Japanese text processing tools is low,
because those tools can process only 50-60% of the whole
52 compound functional expressions, and for the remaining
40-50% expressions, they fail in identifying all of the occur-
rences of functional usages.
10It is also worthwhile to note that training the SVMs-
based chunker with the full set of features requires computa-
tional cost three times as much as training without the chunk
</footnote>
<page confidence="0.99993">
31
</page>
<tableCaption confidence="0.998938">
Table 7: Evaluation Results (%)
</tableCaption>
<table confidence="0.988061">
Identifying Acc. of classifying
functional chunks functional/content
chunks
Prec. Rec. Fβ=1
majority ( =functional) 78.0 100 87.6 78.0
Baselines Juman/KNP 89.2 49.3 63.5 55.8
ChaSen/CaboCha 89.0 45.6 60.3 53.2
hand-crafted rules 90.7 81.6 85.9 79.1
SVM morpheme 88.0 91.0 89.4 86.5
(feature morpheme + chunk-candidate 91.0 93.2 92.1 89.0
set) morpheme + chunk-candidate/context 91.1 93.6 92.3 89.2
</table>
<figureCaption confidence="0.981621">
Figure 1: Change of Fβ=1 with Different Number
of Training Instances
</figureCaption>
<bodyText confidence="0.999217555555556">
For the SVMs-based chunker with the chunk
candidate feature with/without the chunk context
feature, Figure 1 plots the change of Fβ=1 when
training with different number of labeled chunks
as training instances. With this result, the increase
in Fβ=1 seems to stop with the maximum num-
ber of training instances, which supports the claim
that it is sufficient to collect and manually annotate
about 50 training examples per expression.
</bodyText>
<sectionHeader confidence="0.991499" genericHeader="conclusions">
5 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.998024380952381">
The Japanese language has various types of com-
pound functional expressions, which are very im-
portant for recognizing the syntactic structures of
Japanese sentences and for understanding their se-
mantic contents. In this paper, we formalized
the task of identifying Japanese compound func-
tional expressions in a text as a chunking prob-
lem. We applied a machine learning technique
to this task, where we employed that of Sup-
port Vector Machines (SVMs). We showed that
the proposed method significantly outperforms ex-
isting Japanese text processing tools. The pro-
context feature.
posed framework has advantages over an approach
based on manually created rules such as the one in
(Shudo et al., 2004), in that it requires human cost
to manually create and maintain those rules. On
the other hand, in our framework based on the ma-
chine learning technique, it is sufficient to collect
and manually annotate about 50 training examples
per expression.
</bodyText>
<sectionHeader confidence="0.999107" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999849333333333">
J. Carletta. 1996. Assessing agreement on classification
tasks: the Kappa statistic. Computational Linguistics,
22(2):249–254.
Group Jamashii, editor. 1998. Nihongo Bunkei Jiten.
Kuroshio Publisher. (in Japanese).
T. Kudo and Y. Matsumoto. 2001. Chunking with support
vector machines. In Proc. 2nd NAACL, pages 192–199.
J. Mayfield, P. McNamee, and C. Piatko. 2003. Named entity
recognition using hundreds of thousands of features. In
Proc. 7th CoNLL, pages 184–187.
Y. Morita and M. Matsuki. 1989. Nihongo Hyougen Bunkei,
volume 5 of NAFL Sensho. ALC. (in Japanese).
National Language Research Institute. 2001. Gendaigo
Hukugouji Youreishu. (in Japanese).
H. T. Ng, C. Y. Lim, and S. K. Foo. 1999. A case study on
inter-annotator agreement for word sense disambiguation.
In Proc. ACL SIGLEX Workshop on Standardizing Lexical
Resources, pages 9–13.
I. Sag, T. Baldwin, F. Bond, A. Copestake, and D. Flickinger.
2002. Multiword expressions: A pain in the neck for NLP.
In Proc. 3rd CICLING, pages 1–15.
K. Shudo, T. Tanabe, M. Takahashi, and K. Yoshimura. 2004.
MWEs as non-propositional content indicators. In Proc.
2nd ACL Workshop on Multiword Expressions: Integrat-
ing Processing, pages 32–39.
E. Tjong Kim Sang. 1999. Representing text chunks. In
Proc. 9th EACL, pages 173–179.
M. Tsuchiya, T. Utsuro, S. Matsuyoshi, S. Sato, and S. Nak-
agawa. 2005. A corpus for classifying usages of Japanese
compound functional expressions. In Proc. PACLING,
pages 345–350.
V. N. Vapnik. 1998. Statistical Learning Theory. Wiley-
Interscience.
</reference>
<page confidence="0.999298">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.269108">
<title confidence="0.994804">Chunking Japanese Compound Functional</title>
<author confidence="0.822708">by Machine Learning</author>
<affiliation confidence="0.83508625">Center / of Information and Computer Toyohashi University of Technology, Tenpaku-cho, Toyohashi, 441–8580, School of Informatics, Kyoto University, Sakyo-ku, Kyoto, 606–8501, School of Systems and Information Engineering, University of</affiliation>
<address confidence="0.71053">1-1-1, Tennodai, Tsukuba, 305-8573,</address>
<affiliation confidence="0.97588">Institute of Information and Communications</affiliation>
<address confidence="0.967015">3–5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619–0289</address>
<affiliation confidence="0.919423">School of Engineering, Nagoya</affiliation>
<address confidence="0.987854">Furo-cho, Chikusa-ku, Nagoya, 464–8603, JAPAN</address>
<abstract confidence="0.999527333333333">The Japanese language has various types of compound functional expressions, which are very important for recognizing the syntactic structures of Japanese sentences and for understanding their semantic contents. In this paper, we formalize the task of identifying Japanese compound functional expressions in a text as a chunking problem. We apply a machine learning technique to this task, where we employ that of Support Vector Machines (SVMs). We show that the proposed method significantly outperforms existing Japanese text processing tools.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: the Kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="16267" citStr="Carletta, 1996" startWordPosition="2502" endWordPosition="2503">text corpus. Those 52 expressions can be regarded as among the most difficult ones in the task of identifying and classifying functional/content 6For those expressions whose constituent has conjugation and the conjugated form also has the same usage as the expression with the original form, the morpheme sequence is expanded so that the expanded morpheme sequences include those with conjugated forms. 7For the most frequent 184 expressions, on the average, the agreement rate between two human annotators is 0.93 and the Kappa value is 0.73, which means allowing tentative conclusions to be drawn (Carletta, 1996; Ng et al., 1999). For 65% of the 184 expressions, the Kappa value is above 0.8, which means good reliability. usages. Thus, this paper focuses on those 52 expressions in the training/testing of chunking compound functional expressions. We extract 2,600 sentences (= 52 expressions x 50 sentences) from the whole example database and use them for training/testing the chunker. The number of the morphemes for the 2,600 sentences is 92,899. We ignore the chunk labels for the expressions other than the 52 expressions, resulting in 2,482/701 chunk labels for the functional/content usages, respective</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>J. Carletta. 1996. Assessing agreement on classification tasks: the Kappa statistic. Computational Linguistics, 22(2):249–254.</rawString>
</citation>
<citation valid="true">
<title>Nihongo Bunkei Jiten. Kuroshio Publisher.</title>
<date>1998</date>
<editor>Group Jamashii, editor.</editor>
<note>(in Japanese).</note>
<marker>1998</marker>
<rawString>Group Jamashii, editor. 1998. Nihongo Bunkei Jiten. Kuroshio Publisher. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In Proc. 2nd NAACL,</booktitle>
<pages>192--199</pages>
<contexts>
<context position="5595" citStr="Kudo and Matsumoto, 2001" startWordPosition="801" endWordPosition="804">ssions. Considering such a situation, it is necessary to develop a tool which properly recognizes and semantically interprets Japanese compound functional expressions. In this paper, we apply a machine learning technique to the task of identifying Japanese compound functional expressions in a text. We formalize this identification task as a chunking problem. We employ the technique of Support Vector Machines (SVMs) (Vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking (Kudo and Matsumoto, 2001) and named entity chunking (Mayfield et al., 2003). In the preliminary experimental evaluation, we focus on 52 expressions that have balanced distribution of their usages in the newspaper text corpus and are among the most difficult ones in terms of their identification in a text. We show that the proposed method significantly outperforms existing Japanese text processing tools as well as another tool based on hand-crafted rules. We further show that, in the proposed SVMs based framework, it is sufficient to collect and manually annotate about 50 training examples per expression. 2 Japanese Co</context>
<context position="18722" citStr="Kudo and Matsumoto, 2001" startWordPosition="2941" endWordPosition="2944">cus on the d-th polynomial kernel: K(x, y) = (x · y + 1)d (5) L(α) = �l αi − 1 �l i=1 2 i,j=1 29 Through experimental evaluation on chunking Japanese compound functional expressions, we compared polynomial kernels with d = 1, 2, and 3. Kernels with d = 2 and 3 perform best, while the kernel with d = 3 requires much more computational cost than that with d = 2. Thus, throughout the paper, we show results with the quadratic kernel (d = 2). 3.2 Chunking with SVMs This section describes details of formalizing the chunking task using SVMs. In this paper, we use an SVMs-based chunking tool YamCha8 (Kudo and Matsumoto, 2001). In the SVMs-based chunking framework, SVMs are used as classifiers for assigning labels for representing chunks to each token. In our task of chunking Japanese compound functional expressions, each sentence is represented as a sequence of morphemes, where a morpheme is regarded as a token. 3.2.1 Chunk Representation For representing proper chunks, we employ IOB2 representation, one of those which have been studied well in various chunking tasks of natural language processing (Tjong Kim Sang, 1999; Kudo and Matsumoto, 2001). This method uses the following set of three labels for representing </context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>T. Kudo and Y. Matsumoto. 2001. Chunking with support vector machines. In Proc. 2nd NAACL, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mayfield</author>
<author>P McNamee</author>
<author>C Piatko</author>
</authors>
<title>Named entity recognition using hundreds of thousands of features.</title>
<date>2003</date>
<booktitle>In Proc. 7th CoNLL,</booktitle>
<pages>184--187</pages>
<contexts>
<context position="5645" citStr="Mayfield et al., 2003" startWordPosition="809" endWordPosition="812"> to develop a tool which properly recognizes and semantically interprets Japanese compound functional expressions. In this paper, we apply a machine learning technique to the task of identifying Japanese compound functional expressions in a text. We formalize this identification task as a chunking problem. We employ the technique of Support Vector Machines (SVMs) (Vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking (Kudo and Matsumoto, 2001) and named entity chunking (Mayfield et al., 2003). In the preliminary experimental evaluation, we focus on 52 expressions that have balanced distribution of their usages in the newspaper text corpus and are among the most difficult ones in terms of their identification in a text. We show that the proposed method significantly outperforms existing Japanese text processing tools as well as another tool based on hand-crafted rules. We further show that, in the proposed SVMs based framework, it is sufficient to collect and manually annotate about 50 training examples per expression. 2 Japanese Compound Functional Expressions and their Example Da</context>
</contexts>
<marker>Mayfield, McNamee, Piatko, 2003</marker>
<rawString>J. Mayfield, P. McNamee, and C. Piatko. 2003. Named entity recognition using hundreds of thousands of features. In Proc. 7th CoNLL, pages 184–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Morita</author>
<author>M Matsuki</author>
</authors>
<title>Nihongo Hyougen Bunkei,</title>
<date>1989</date>
<volume>5</volume>
<note>of NAFL Sensho. ALC. (in Japanese).</note>
<contexts>
<context position="6437" citStr="Morita and Matsuki, 1989" startWordPosition="928" endWordPosition="931"> most difficult ones in terms of their identification in a text. We show that the proposed method significantly outperforms existing Japanese text processing tools as well as another tool based on hand-crafted rules. We further show that, in the proposed SVMs based framework, it is sufficient to collect and manually annotate about 50 training examples per expression. 2 Japanese Compound Functional Expressions and their Example Database 2.1 Japanese Compound Functional Expressions There exist several collections which list Japanese functional expressions and examine their usages. For example, (Morita and Matsuki, 1989) examine 450 functional expressions and (Group Jamashii, 1998) also lists 965 expressions and their example sentences. Compared with those two collections, Gendaigo Hukugouji Youreishu (National Language Research Institute, 2001) (henceforth, denoted as GHY) concentrates on 125 major functional expressions which have non-compositional usages, as well as their variants5 (337 expressions in total), and collects example sentences of those expressions. As a first step of developing a tool for identifying Japanese compound functional expressions, we start with those 125 major functional expressions</context>
</contexts>
<marker>Morita, Matsuki, 1989</marker>
<rawString>Y. Morita and M. Matsuki. 1989. Nihongo Hyougen Bunkei, volume 5 of NAFL Sensho. ALC. (in Japanese).</rawString>
</citation>
<citation valid="true">
<title>Gendaigo Hukugouji Youreishu.</title>
<date>2001</date>
<institution>National Language Research Institute.</institution>
<note>(in Japanese).</note>
<marker>2001</marker>
<rawString>National Language Research Institute. 2001. Gendaigo Hukugouji Youreishu. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>C Y Lim</author>
<author>S K Foo</author>
</authors>
<title>A case study on inter-annotator agreement for word sense disambiguation.</title>
<date>1999</date>
<booktitle>In Proc. ACL SIGLEX Workshop on Standardizing Lexical Resources,</booktitle>
<pages>9--13</pages>
<contexts>
<context position="16285" citStr="Ng et al., 1999" startWordPosition="2504" endWordPosition="2507">se 52 expressions can be regarded as among the most difficult ones in the task of identifying and classifying functional/content 6For those expressions whose constituent has conjugation and the conjugated form also has the same usage as the expression with the original form, the morpheme sequence is expanded so that the expanded morpheme sequences include those with conjugated forms. 7For the most frequent 184 expressions, on the average, the agreement rate between two human annotators is 0.93 and the Kappa value is 0.73, which means allowing tentative conclusions to be drawn (Carletta, 1996; Ng et al., 1999). For 65% of the 184 expressions, the Kappa value is above 0.8, which means good reliability. usages. Thus, this paper focuses on those 52 expressions in the training/testing of chunking compound functional expressions. We extract 2,600 sentences (= 52 expressions x 50 sentences) from the whole example database and use them for training/testing the chunker. The number of the morphemes for the 2,600 sentences is 92,899. We ignore the chunk labels for the expressions other than the 52 expressions, resulting in 2,482/701 chunk labels for the functional/content usages, respectively. 3 Chunking Jap</context>
</contexts>
<marker>Ng, Lim, Foo, 1999</marker>
<rawString>H. T. Ng, C. Y. Lim, and S. K. Foo. 1999. A case study on inter-annotator agreement for word sense disambiguation. In Proc. ACL SIGLEX Workshop on Standardizing Lexical Resources, pages 9–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Sag</author>
<author>T Baldwin</author>
<author>F Bond</author>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proc. 3rd CICLING,</booktitle>
<pages>1--15</pages>
<contexts>
<context position="7245" citStr="Sag et al., 2002" startWordPosition="1048" endWordPosition="1051">nal Language Research Institute, 2001) (henceforth, denoted as GHY) concentrates on 125 major functional expressions which have non-compositional usages, as well as their variants5 (337 expressions in total), and collects example sentences of those expressions. As a first step of developing a tool for identifying Japanese compound functional expressions, we start with those 125 major functional expressions and their variants. In this paper, we take an approach of regarding each of those variants as a fixed expression, rather than a semi-fixed expression or a syntactically-flexible expression (Sag et al., 2002). Then, we focus on evaluating the effectiveness of straightforwardly applying a stan5For each of those 125 major expressions, the differences between it and its variants are summarized as below: i) insertion/deletion/alternation of certain particles, ii) alternation of synonymous words, iii) normal/honorific/conversational forms, iv) base/adnominal/negative forms. 26 Table 3: Examples of Classifying Functional/Content Usages Expression Example sentence (English translation) Usage となると しかしこの病気に効果がない となると functional (to-naru-to) (となると (to-naru-to) = if) 事は重大だ。 (The situation is serious if it is</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>I. Sag, T. Baldwin, F. Bond, A. Copestake, and D. Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proc. 3rd CICLING, pages 1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Shudo</author>
<author>T Tanabe</author>
<author>M Takahashi</author>
<author>K Yoshimura</author>
</authors>
<title>MWEs as non-propositional content indicators.</title>
<date>2004</date>
<booktitle>In Proc. 2nd ACL Workshop on Multiword Expressions: Integrating Processing,</booktitle>
<pages>32--39</pages>
<marker>Shudo, Tanabe, Takahashi, Yoshimura, 2004</marker>
<rawString>K. Shudo, T. Tanabe, M. Takahashi, and K. Yoshimura. 2004. MWEs as non-propositional content indicators. In Proc. 2nd ACL Workshop on Multiword Expressions: Integrating Processing, pages 32–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Tjong Kim Sang</author>
</authors>
<title>Representing text chunks.</title>
<date>1999</date>
<booktitle>In Proc. 9th EACL,</booktitle>
<pages>173--179</pages>
<contexts>
<context position="19225" citStr="Sang, 1999" startWordPosition="3021" endWordPosition="3022">nking task using SVMs. In this paper, we use an SVMs-based chunking tool YamCha8 (Kudo and Matsumoto, 2001). In the SVMs-based chunking framework, SVMs are used as classifiers for assigning labels for representing chunks to each token. In our task of chunking Japanese compound functional expressions, each sentence is represented as a sequence of morphemes, where a morpheme is regarded as a token. 3.2.1 Chunk Representation For representing proper chunks, we employ IOB2 representation, one of those which have been studied well in various chunking tasks of natural language processing (Tjong Kim Sang, 1999; Kudo and Matsumoto, 2001). This method uses the following set of three labels for representing proper chunks. I Current token is a middle or the end of a chunk consisting of more than one token. O Current token is outside of any chunk. B Current token is the beginning of a chunk. As we described in section 2.2, given a candidate expression, we classify the usages of the expression into two classes: functional and content. Accordingly, we distinguish the chunks of the two types: the functional type chunk and the content type chunk. In total, we have the following five labels for representing </context>
</contexts>
<marker>Sang, 1999</marker>
<rawString>E. Tjong Kim Sang. 1999. Representing text chunks. In Proc. 9th EACL, pages 173–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tsuchiya</author>
<author>T Utsuro</author>
<author>S Matsuyoshi</author>
<author>S Sato</author>
<author>S Nakagawa</author>
</authors>
<title>A corpus for classifying usages of Japanese compound functional expressions.</title>
<date>2005</date>
<booktitle>In Proc. PACLING,</booktitle>
<pages>345--350</pages>
<contexts>
<context position="14582" citStr="Tsuchiya et al., 2005" startWordPosition="2232" endWordPosition="2235">. Thus, in this paper, based on this observation, we formalize the task of identifying Japanese compound functional expressions as a chunking problem, rather than a classification problem. 28 Table 5: Number of Sentences collected from 1995 Mainichi Newspaper Texts (for 337 Expressions) # of expressions 50 &lt; # of sentences 187 (55%) 0 &lt; # of sentences &lt; 50 117 (35%) # of sentences = 0 33 (10%) 2.3 Developing an Example Database We developed an example database of Japanese compound functional expressions, which is used for training/testing a chunker of Japanese compound functional expressions (Tsuchiya et al., 2005). The corpus from which we collect example sentences is 1995 Mainichi newspaper text corpus (1,294,794 sentences, 47,355,330 bytes). For each of the 337 expressions, 50 sentences are collected and chunk labels are annotated according to the following procedure. 1. The expression is morphologically analyzed by ChaSen, and its morpheme sequence6 is obtained. 2. The corpus is morphologically analyzed by ChaSen, and 50 sentences which include the morpheme sequence of the expression are collected. 3. For each sentence, every occurrence of the 337 expressions is annotated with one of the usages func</context>
</contexts>
<marker>Tsuchiya, Utsuro, Matsuyoshi, Sato, Nakagawa, 2005</marker>
<rawString>M. Tsuchiya, T. Utsuro, S. Matsuyoshi, S. Sato, and S. Nakagawa. 2005. A corpus for classifying usages of Japanese compound functional expressions. In Proc. PACLING, pages 345–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>WileyInterscience.</publisher>
<contexts>
<context position="5403" citStr="Vapnik, 1998" startWordPosition="776" endWordPosition="777">ramework of those existing tools is not designed so as to resolve such ambiguities of compound (possibly functional) expressions by carefully considering the context of those expressions. Considering such a situation, it is necessary to develop a tool which properly recognizes and semantically interprets Japanese compound functional expressions. In this paper, we apply a machine learning technique to the task of identifying Japanese compound functional expressions in a text. We formalize this identification task as a chunking problem. We employ the technique of Support Vector Machines (SVMs) (Vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking (Kudo and Matsumoto, 2001) and named entity chunking (Mayfield et al., 2003). In the preliminary experimental evaluation, we focus on 52 expressions that have balanced distribution of their usages in the newspaper text corpus and are among the most difficult ones in terms of their identification in a text. We show that the proposed method significantly outperforms existing Japanese text processing tools as well as another tool bas</context>
<context position="17081" citStr="Vapnik, 1998" startWordPosition="2630" endWordPosition="2631">ing compound functional expressions. We extract 2,600 sentences (= 52 expressions x 50 sentences) from the whole example database and use them for training/testing the chunker. The number of the morphemes for the 2,600 sentences is 92,899. We ignore the chunk labels for the expressions other than the 52 expressions, resulting in 2,482/701 chunk labels for the functional/content usages, respectively. 3 Chunking Japanese Compound Functional Expressions with SVMs 3.1 Support Vector Machines The principle idea of SVMs is to find a separate hyperplane that maximizes the margin between two classes (Vapnik, 1998). If the classes are not separated by a hyperplane in the original input space, the samples are transformed in a higher dimensional features space. Giving x is the context (a set of features) of an input example; xi and yi(i = 1, ..., l, xi E Rn, yi E11, −1}) indicate the context of the training data and its category, respectively; The decision function f in SVM framework is defined as: l l Ax) = sgn(i=1 E αiyiK(xi, x) + b I (1) where K is a kernel function, b E R is a threshold, and αi are weights. Besides, the weights αi satisfy the following constraints: 0 &lt; αi &lt; C (i = 1, ...,l) (2) Eli=1 </context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>V. N. Vapnik. 1998. Statistical Learning Theory. WileyInterscience.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>