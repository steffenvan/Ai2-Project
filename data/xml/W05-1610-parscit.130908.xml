<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.996782">
Narratological Knowledge for Natural Language Generation
</title>
<author confidence="0.901271">
Birte Lönneker
</author>
<affiliation confidence="0.7779975">
Narratology Research Group Hamburg
Institut für Germanistik II, University of Hamburg
</affiliation>
<address confidence="0.718683">
Von-Melle-Park 6, D-20146 Hamburg
</address>
<email confidence="0.730538">
birte.loenneker@uni-hamburg.de
</email>
<sectionHeader confidence="0.98823" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999164">
The paper proposes an architecture for advanced
NLG systems that handle narratives. Special
attention is paid to document planning. Domain
modelling and meta-knowledge modelling for a
narratological structurer are exemplified.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999458117647059">
Natural Language Generation (NLG) systems usually focus
on descriptive text types. Narrative structures are under-
represented in NLG. However, they are encountered in
many naturally occurring texts, and not only in fiction.
Often, texts are composed of segments with different
prevailing functions: some are descriptive, some argumenta-
tive, others narrative. Therefore, knowledge about narratives
can be useful also for NLG systems that deal with “classi-
cal” NLG tasks. For example, a system that is expected to
describe and compare objects in a museum could include
narrative passages about their use, history or discovery.
The discipline concerned with the structure of narrative
[Barthes, 1966] and narrative discourse [Genette, 1980] is
called narratology. Narratologists distinguish between two
main representational domains of narratives: 1. the story
(histoire) as the totality of the narrated events, abstracted
from their disposition in the text; and 2. the discourse
(récit) that narrates them [Genette, 1988:13].
Narratology has identified a number of descriptive
parameters. As can be seen from the explanations in Table 1
(see Appendix), many parameters describe phenomena that
relate discourse to story in a specific way.
This paper envisages an NLG system with improved
abilities to deal with narrative discourse. Section 2 summa-
rises the relation between Story Generation and NLG. In
Section 3, an architecture for a narratologically enhanced
NLG system is proposed. Section 4 outlines one of the de-
scriptive parameters, illustrating the kind of knowledge that
can be acquired from narratology. Section 5 exemplifies the
domain modelling, a prerequisite for modelling narratologi-
cal knowledge. Section 6 formalises the selected narra-
tological parameter, discusses its mapping onto discourse
graphs used in NLG, and exemplifies its use in a system.
Section 7 concludes the paper and mentions future work.
</bodyText>
<sectionHeader confidence="0.796193" genericHeader="introduction">
2 Story Generation and NLG
</sectionHeader>
<bodyText confidence="0.999946125">
This section gives a brief overview of the relationship
between Story Generation (SG) and NLG. Subsection 2.1
describes the architectural gap between SG and NLG.
Subsection 2.2 discusses the contribution of an existing
system to fill that gap. An extended account of work in SG
cannot be provided here. Pérez y Pérez and Sharples [2004]
compare and evaluate three recent SG systems. For a
discussion of earlier systems, see [Ryan, 1991:233–248].
</bodyText>
<subsectionHeader confidence="0.981371">
2.1 The Story Generation-NLG Gap
</subsectionHeader>
<bodyText confidence="0.956714388888889">
Story Generators aim to produce interesting, understand-
able, artistic, and creative stories [Turner, 1994:15]. In
doing so, they focus on the story (histoire) representational
domain. For example, the generator MINSTREL [Turner,
1994] achieves not only thematic and consistency goals, but
also “dramatic” and “presentational” goals solely by adding
or transforming story events and background information.
The story content is directly mapped onto the output text.
SG faces the difficult problem of finding an interesting
and logically coherent event sequence (story). Less energy
is spent on other tasks, especially at discourse and surface
level. In fact, most implemented SG systems use templates
of different varieties for NLG. Document structuring and
microplanning as NLG processing stages [Reiter, 1994;
Reiter and Dale, 2000:60] are usually skipped in SG, so that
SG and NLG architectures can be confronted as in Figure 1.
Implicit goal: Write coherent narrative
of given genre
</bodyText>
<figure confidence="0.9956391875">
Determine content (story), directly
associated with structure (discourse)
(Abstract) content specification
Template filling
Surface narrative
Traditional SG
Communicative goal
Surface realizer
Surface text
Document planner
(Abstract) text specification
Microplanner
Document plan
Content det.
Doc. structuring
General NLG
</figure>
<figureCaption confidence="0.999766">
Figure 1: Story Generation and Natural Language Generation
</figureCaption>
<subsectionHeader confidence="0.935675">
2.2 STORYBOOK
</subsectionHeader>
<bodyText confidence="0.9986608">
The existence of a gap between SG and NLG has also been
discussed by Callaway and Lester [2002]. To remedy the
situation, they implemented STORYBOOK, an “architecture
for narrative prose generation” [2002:228]. The input to
STORYBOOK must be a “narrative stream that reflects the
orderly progression of events, descriptions and states”
[Callaway and Lester, 2002:231], produced by a hypotheti-
cal Story Generator. STORYBOOK expects this input stream
to contain so-called narrative primitives that specify scene
changes and other aspects such as:
</bodyText>
<listItem confidence="0.9972015">
• narrative person and focalization (“person, omnis-
cience” [Callaway and Lester, 2002:221]);
• details about dialogue realization (e.g. whether an
inquit phrase such as “he said” should precede, follow
or interrupt direct speech, or whether it should be
omitted altogether [Callaway and Lester, 2002:225]).
</listItem>
<bodyText confidence="0.9971392">
Person and focalization are classical narratological pa-
rameters [Genette, 1980]. It is not clear from Callaway and
Lester [2002] how many different values STORYBOOK actu-
ally implements for these parameters; their example tale is
invariably rendered by a “third person disembodied” narra-
tor [2002:230]. — The question of whether or not a charac-
ter utterance is to be provided with an inquit phrase is
sometimes subsumed under the narrative distance parameter
(cf. Table 1): Direct speech framed by inquit phrases is defi-
nitely considered as imitating, but the highest level of imita-
tion is achieved by the reproduction of unframed direct
speech [Fludernik, 2005; Genette, 1988:56].
In STORYBOOK, many decisions concerning discourse
still lie with the Story Generator that is supposed to produce
a stream with narrative primitives. STORYBOOK itself nei-
ther decides about narrative person, focalization, or distance
for any given passage, nor is it concerned with any other
narratological parameters listed in Table 1. Rather,
STORYBOOK focuses on microplanning and surface phe-
nomena with special attention to features particular to nar-
rative. The architectural contribution of STORYBOOK can
thus be seen as reducing the gap between SG and NLG to
approximately the microplanner level, where STORYBOOK,
as a specialized NLG system, takes over from a hypothetical
Story Generator (see Figure 2).
</bodyText>
<footnote confidence="0.27947">
Surface text
</footnote>
<figureCaption confidence="0.976898">
Figure 2: Story Generation and STORYBOOK
</figureCaption>
<sectionHeader confidence="0.993733" genericHeader="method">
3 Narratology for NLG
</sectionHeader>
<bodyText confidence="0.999933888888889">
Narratological aspects influence on all architectural modules
[Reiter, 1994] or representation levels [Cahill et al., 2000]
of NLG. The most important decisions of a narratologically
enhanced system concern the document planner with its
content determination and document structuring sub-
tasks (Subsections 3.1–3.2). Microplanning and surface
realization (Subsection 3.3) are supposed to resemble classi-
cal NLG processes. As further explained below, the archi-
tecture of the envisaged system corresponds to Figure 3.
</bodyText>
<figureCaption confidence="0.988516">
Figure 3: Narratologically enhanced Story Generation-NLG system
</figureCaption>
<subsectionHeader confidence="0.999733">
3.1 Content Determination
</subsectionHeader>
<bodyText confidence="0.999272333333333">
In a narratologically enriched NLG system, a “narrative
content determination module” might be implemented as a
Story Generator. The Story Generator decides
</bodyText>
<listItem confidence="0.9917075">
• what it considers to be a minimal story [Prince, 1973],
• what it considers a good story (cf. Subsection 2.1),
• how to select the content that represents the story:
events, participants, and their relations.
</listItem>
<bodyText confidence="0.999973294117647">
However, if narratological discourse parameters are to be
applied, certain story events or participants are required. For
example, the narrative levels parameter presupposes the
existence of at least one NARRATING action among the story
events of the (first) narrative (see Sections 4–6).
This means that an entirely data-driven, pipelined process
where content determination precedes document structuring
[Reiter and Dale, 2000:111] will not use the full potential of
a narratologically enhanced document planner. Rather, the
content determination module (the Story Generator) should
be able to satisfy constraints issued by the document
structurer. These constraints might well take the form of
modification requests after a first output attempt of the Story
Generator. Therefore, a hypothesis-driven architecture in
which the system switches back and forth between content
determination and document structuring seems well suited
for the task at hand (see the double arrow in Figure 3).
</bodyText>
<subsectionHeader confidence="0.999794">
3.2 Document Structuring
</subsectionHeader>
<bodyText confidence="0.999788833333333">
In the envisaged architecture, the document structurer
receives the narrative content representation from the Story
Generator. In its simplest form, this input is a sequence of
events together with their participants. The structurer shares
a domain model with the Story Generator, where the
semantics of events and participants are represented.
</bodyText>
<figure confidence="0.974597034482759">
Determine content (story), decide about
person, focalization, speech reproduction
Hypothetical SG
Narrative stream
Microplanner
(Abstract) text specification
Surface realizer
StoryBook
Narratological structurer
Story Generator
NLG
Document plan
Microplanner
(Abstract) text specification
Determine content
(story) and
part of structure
(esp. causality)
Vary (order, person,
point of view,...);
create discourse
representation
Abstract
content
repre−
sentation
Goal: Write coherent narrative
Surface realizer
Surface text
</figure>
<figureCaption confidence="0.724698666666667">
of given genre
Implicit goal: Write coherent narrative
of genre: fairy tale
</figureCaption>
<bodyText confidence="0.9853916">
By default, the incoming event sequence is considered as
corresponding to a discourse related by the NarrativeSe-
quence discourse relation1 (for discourse relations, cf. Sub-
section 6.3). The sequence might have additional internal
structure, because most Story Generators represent conse-
quences of events and/or episodes, and therefore some kind
of causality [e.g. Gervás et al., 2004; Pérez y Pérez and
Sharples, 2004; Turner, 1994].
Combining this information with information from the
ontology and with narratological knowledge, the narra-
tological document structurer creates variation in discourse.
Most narrative parameters presented in Table 1 influence on
this representational domain. Amongst others, the Narra-
tological Structurer can perform the following tasks, some
of them in interaction with the Story Generator:
</bodyText>
<listItem confidence="0.979240727272727">
• modify the order of events or episodes, tag the shifted
elements as flashbacks or flashforwards, and accord-
ingly modify the discourse relations (a Cause relation
might become an Explanation relation because of the
inverted event order);
• create ellipsis by suppressing events or episodes that
the reader might as well infer;
• add or remove narrative levels (Sections 4–6);
• decide about point of view and focalization for the
entire narrative or, rather, for certain episodes, and ac-
cordingly present or suppress events and relations.
</listItem>
<bodyText confidence="0.999982333333333">
The produced document plan contains discourse relations
and narratological information for nodes and leaves, which
can be further used in microplanning and surface realization.
</bodyText>
<subsectionHeader confidence="0.999918">
3.3 Microplanning and Surface Realization
</subsectionHeader>
<bodyText confidence="0.999991076923077">
The microplanner performs lexicalisation and aggregation
and generates referring expressions. Besides the usual
constraints, it respects narratological contraints. For exam-
ple, certain values of focalization and point of view can
cause “unusual” referring expressions: personal pronouns
might be used for initial reference [Harweg, 1968: 163–
166], or indefinite referring expressions for subsequent
reference [Ushie, 1986; Wiebe and Rapaport, 1988]. The
choice of vocabulary, tense, and syntactic complexity can as
well depend on narratological factors.
The surface realizer turns the microplanner output into
natural language text. See [Callaway and Lester, 2002:224]
for narrative-related issues in surface realization.
</bodyText>
<sectionHeader confidence="0.978283" genericHeader="method">
4 The Narrative Levels Parameter
</sectionHeader>
<bodyText confidence="0.998850666666667">
The narrative levels parameter will be used to illustrate the
kind of knowledge that can be acquired from narratology for
integration into a narratologically enhanced NLG system.
Narratives can consist of different levels: There are “tales
within tales within tales” [Barth, 1984]. Genette [1988:85]
illustrates this phenomenon by a figure similar to Figure 4,
</bodyText>
<footnote confidence="0.8061115">
1 Similar to the relations Narration [Asher and Lascarides,
2003:162–165] or Occasion [Hobbs, 1990:86–89].
</footnote>
<figureCaption confidence="0.998858">
Figure 4: Narrative levels
</figureCaption>
<bodyText confidence="0.999784086956522">
in which person i produces an utterance a that contains the
production of another utterance b by person j. Talking about
narratives, the “persons” in Genette’s drawing correspond to
narrative instances (narrators). Narrative instance i might
not be identified by any referring expression throughout the
utterances produced by i (and j): i can be “absent from the
story” or heterodiegetic [Genette, 1980:244–245]. Narrative
instance j, on the other hand, necessarily has to be identical
to a character in story a. Finally, j might be absent (or not)
from the “inner” narration b that he himself produces (see
Table 1 on Person).
The generation of a narration within a narration presup-
poses the existence of a NARRATING action in the “outer”
narration: in Figure 4, a NARRATING action (where j tells b)
occurs within outer narration a.2 Therefore, before narrative
levels will be modelled in detail (Section 6), Section 5 will
be concerned with a definition of NARRATING.
Genette’s [1980:244] considerations suggest that narra-
tive levels is one of the simpler narratological parameters.
For example, he claims that any narrative can be converted
into an inner narration by adding “presentational” outer nar-
rations [Genette, 1988:95]. It should thus be possible to
enable a generation system to create narrativel levels.
</bodyText>
<sectionHeader confidence="0.988398" genericHeader="method">
5 NARRATING and Related Frames
</sectionHeader>
<bodyText confidence="0.9999648125">
This section proposes representation structures for
NARRATING (Subsection 5.1) and related frames, especially
the NARRATED frame (Subsection 5.2). A frame is consid-
ered to represent structured knowledge about a given con-
cept. In terms of NLG tasks, this modelling corresponds to
setting up part of a domain model for content determination
[Reiter and Dale, 2000:86–89].
The modelling is supported by concordances from the
German DWDS corpus.3 Contexts of verb forms of erzählen
(‘tell; narrate’) were investigated, because they “evoke” the
target frame NARRATING. As DWDS texts are of several
types, the results reflect general (not only literary) language
use. The analysed corpus material stems from texts pub-
lished between 1990 and 1999. The modelling is also partly
inspired by the SUMO4 upper ontology [Niles and Pease,
2001]. SUMO does not yet include the NARRATING concept.
</bodyText>
<subsectionHeader confidence="0.983252">
5.1 The NARRATING Frame
</subsectionHeader>
<bodyText confidence="0.999663">
The NARRATING frame is an indirect subframe of ACTION.
Narratological theories [Chatman, 1978:44–45] agree with
</bodyText>
<footnote confidence="0.8540455">
2 “Inside” vs. “outside” narrations [Barth, 1984:233] are also
called “framed” vs. “framing” or “embedded” vs. “embedding”.
3 http://www.dwds.de [Query date: 24 January, 2005].
4 http://ontology.teknowledge.com/ [10 March, 2005].
</footnote>
<figure confidence="0.777171">
i
a b
j
</figure>
<bodyText confidence="0.99985244">
current ontologies like SUMO on the fact that an action is
performed intentionally by a cognitive agent. The NARRAT-
ING frame thus inherits an Agent slot which I relabel
NarrativeInstance for better orientation (cf. Table 5).
The NARRATING frame is related to other frames sub-
sumed under the superframe COMMUNICATION_ACTION.
That superframe represents an action in which typically at
least two participants exchange messages. In the present
investigation, NARRATING actions are assumed to express
this content linguistically; therefore, NARRATING is here also
a subframe of LINGUISTIC_COMMUNICATION (cf. Figure 5).
In the NARRATING frame, the content is represented as
complex filler of the Narrated slot; a more detailed
modelling of the NARRATED frame follows in Subsection
5.2. NARRATING is a special subframe of COMMUNICA-
TION_ACTION insofar as it usually restricts the direction of
the information flow between the participants: One of them
is the (main) producer, the other one the (main) recipient of
NARRATED. The respective participant slots are the above
mentioned NarrativeInstance, and the Addressee. Typical-
ly, the Addressee or “narratee” [Genette, 1980] is a cogni-
tive agent different from NarrativeInstance. Nevertheless,
the current model also allows the same individual to act
simultaneously as both NarrativeInstance and Addressee:
cognitive agents may “tell a story to themselves”.
Comments and questions produced by the Addressee,
concerning the Narrated, deserve some attention. The pre-
sent conceptualization considers that even if comments and
questions interrupt of the flow of Narrated, they do not
necessarily mark the end of a NARRATING action (see also
Subsection 5.2).
Some other slots of NARRATING are inherited from the
ACTION or EVENT frames. In the DWDS corpus material (cf.
Table 2, Appendix), examples of fillers of Motivation,
Consequence/Aim, ParallelEvent, Time, Place, and Man-
ner are encountered. Typically, one of the Consequences of
NARRATING is a change of the Addressee’s mental state: the
Narrated is added to her or his knowledge. This conse-
quence seems to belong to the lexico-semantic knowledge
about NARRATING or, probably, COMMUNICATION_ACTIONS
in general, and is rarely mentioned explicitly in texts.
Table 3 gives an overview of the NARRATING frame. It
also maps slot names on binary relation labels and formu-
lates restrictions for the fillers. However, as a representation
of a conceptual entity, it does not specify linguistic restric-
tions such as “addressee-oriented, non-message-oriented”
which are considered to hold language-specifically for indi-
vidual verbs [Bateman et al., 1994]. For the use in a specific
NLG system, the frame and its slots thus need to be mapped
onto the lexicon used by that system during lexicalisation.
</bodyText>
<subsectionHeader confidence="0.995183">
5.2 The NARRATED Frame
</subsectionHeader>
<bodyText confidence="0.9999695">
A text can refer to different aspects of what is narrated in a
NARRATING action. Hence, instead of introducing further
slots within the NARRATING frame, the filler of Narrated
will itself be represented as a frame (cf. Table 4, Appendix).
One way of referring to the NARRATED_LINGUISTIC_MES-
SAGE, abbreviated as NARRATED, is to mention the Text-
</bodyText>
<figure confidence="0.712001">
Event (Process)
</figure>
<figureCaption confidence="0.994182">
Figure 5: Frame hierarchy containing NARRATING
</figureCaption>
<table confidence="0.999404545454545">
NARRATING
Slot Relation Filler Restriction
NarrativeInstance isCausedBy CognitiveAgent (&gt; 0)
Narrated produces Narrated (1)
Addressee isAddressedTo CognitiveAgent (&gt;= 0)
Motivation isMotivatedBy AbstractEntity (&gt;= 0)
Consequence/Aim causes Event (&gt; 0)
ParallelEvent overlapsWith Event (&gt;= 0)
Time happensAtTime TimePosition (&gt; 0)
Place locatedAt PhysicalEntity (&gt; 0)
Manner is Attribute (&gt;= 0)
</table>
<tableCaption confidence="0.999775">
Table 3: The NARRATING frame
</tableCaption>
<bodyText confidence="0.99992075">
Type of the narrated material. Typically, this is a literary
genre, or one of its parts. Further, the NARRATED uses a
MessageSupport, which might be written (e.g. book, let-
ter), spoken (e.g. speech, song) or thought (e.g. dream).
Thought seems to lend itself to somewhat problematic sub-
divisions; see e.g. [Genette, 1980:231] on “retrospections”.
The abstract content of NARRATED is represented linguis-
tically through a LinguisticSurfaceForm. As can be seen
from the DWDS corpus, the LinguisticSurfaceForm oc-
curs as a new sentence or clause, and can be more or less
“direct”. Research on the reproduction of speech is an area
of both narratology and linguistics. Usually, the forms direct
speech (D in Table 4), free indirect speech and indirect
speech (I in Table 4) are distinguished in increasing order of
narrative distance (see Table 1) [Fludernik, 2005].
Comments and questions produced by the Addressee of a
NARRATING action, concerning the Narrated, should also be
part of the LinguisticSurfaceForm: Metaphorically speak-
ing, they might be seen as discursive catalysts or parasites of
that surface form.
Finally, the Topic slot of the NARRATED frame is typical-
ly filled by sentence constituents like objects or preposi-
tional phrases. Since these constituents can themselves be
complex, the topic might be quite detailed, taking the form
of a summary. Still, it does not provide access to the
“original” linguistic surface form. With respect to narrative,
this category is also referred to as narrative report of
discourse or content summary [Fludernik, 2005].
</bodyText>
<figureCaption confidence="0.503991">
Figure 6 illustrates the knowledge modelled by
NARRATED and related frames.
</figureCaption>
<figure confidence="0.998997117647059">
Experiencing
...
...
...
CommunicationAction
...
Happening
Action
produces(LinguisticMessage)
Reporting
produces(NarratedLinguisticMessage)
Narrating
LinguisticCommunication
Committing
Directing
...
...
</figure>
<figureCaption confidence="0.999995">
Figure 6: The NARRATED_LINGUISTIC_MESSAGE frame
</figureCaption>
<bodyText confidence="0.999883846153846">
At a meta-level, the NARRATED frame can be mapped
onto representation structures of the envisaged system that
combines SG and NLG (cf. Figure 3 above). The TextType
is implicitly given in the goal of the Story Generator; also
the Topic or a topic restriction is often given at this stage.
The Support is, depending on the stage of processing, some
digital entity, written (printed), or possibly speech. The Ab-
stractContent is the “abstract” output of a Story Generator
(the product of content determination). The LinguisticSur-
faceForm corresponds to the final NLG output based on
this abstract content. Using knowledge and reasoning proce-
dures, a system might additionally or alternatively summa-
rise AbstractContent into a phrase that represents Topic.
</bodyText>
<sectionHeader confidence="0.982285" genericHeader="method">
6 Representing Narrative Levels
</sectionHeader>
<bodyText confidence="0.999241666666667">
This section is concerned with describing a formalism that
should enable a discourse planner to handle narrative levels
(see Section 4). Via the formalism, the system can be told
</bodyText>
<listItem confidence="0.9776162">
• how many levels a generated narrative should have,
• which narrative instance should be the “direct”
mediator to the reader, and
• how outer and inner narrations, or parts thereof,
should follow each other in discourse.
</listItem>
<bodyText confidence="0.9998524">
The basic ingredients for the formalism (Subsection 6.1)
are applied to a description of example constellations (Sub-
section 6.2) and mapped onto discourse relations (Subsec-
tion 6.3). Subsection 6.4 briefly exemplifies the cooperation
between Story Generator and Narratological Structurer.
</bodyText>
<subsectionHeader confidence="0.998149">
6.1 Basic Ingredients: Classes and Relations
</subsectionHeader>
<bodyText confidence="0.999322">
Three classes and two relations need to be modelled to
represent possible structures of global narratives with
respect to their levels.
</bodyText>
<sectionHeader confidence="0.971747" genericHeader="method">
NARRATION
</sectionHeader>
<bodyText confidence="0.988254333333333">
An instance of NARRATED is a NARRATION if its Linguistic-
SurfaceForm is of the subtype DirectLinguisticSurface-
Form (and is, as such, explicitly present in the output text).
This narratological constraint correctly excludes from
opening a new narrative level such NARRATING actions
which are merely mentioned, or whose NARRATED is
reproduced indirectly.
NARRATIVE_INSTANCE
A NARRATIVE_INSTANCE is a cognitive agent that occupies
the agent role (NarrativeInstance slot) of a NARRATING
action. Neither the instance itself nor the action needs to be
referred to directly in the surface form of any NARRATION.
For example, if i isA NARRATIVE_INSTANCE, the variable
i is not necessarily “resolved” against a character name.
toldBy(NARRATION, NARRATIVE_INSTANCE)
The relation toldBy(a,i) holds if there is a NARRATING action
x, a NARRATION a and a NARRATIVE_INSTANCE i such that
both isCausedBy(x,i) and produces(x,a) are true (Table 3).
</bodyText>
<sectionHeader confidence="0.504349" genericHeader="method">
toldIn(NARRATION, NARRATION)
</sectionHeader>
<bodyText confidence="0.935284">
ToldIn(b,a) or “b is told in a” holds if there is a NARRATION
b, a NARRATION a, and a NARRATING action x such that:
</bodyText>
<listItem confidence="0.999853">
• a is not b;
• a is an event sequence such that one of its events is x;
• produces(x,b).
</listItem>
<sectionHeader confidence="0.325551" genericHeader="method">
DISCOURSE_SEQUENCE
</sectionHeader>
<bodyText confidence="0.99985325">
A DISCOURSE_SEQUENCE is an ordered list of variables
standing for different NARRATIONS, as they sequentially oc-
cur within the discourse of a global narrative. In a DIS-
COURSE_SEQUENCE, the same variable may appear more
than once: for example, an outer narration can frame an
inner narration at the start and the end of a discourse.
Variables for separated parts of the same narration receive
numbered subscripts (see a1 and a2 in Figure 7 below).
</bodyText>
<subsectionHeader confidence="0.986127">
6.2 Example Constellations
</subsectionHeader>
<bodyText confidence="0.9588816">
Type 0: Zero-Instantiation
Zero instantiation of the narrative levels parameter occurs if
there is no change in level. There is only one narration, told
by a narrative instance. An example of this type is the fable
The Fox and the Crow by Aesop, because neither the fox
nor the crow produce any narrations. The instantiation of the
classes and relations corresponds to the scenario in Table 5.
I am not aware of any Story Generator (cf. Section 2) that
exceeds the zero instantiation. This would mean that con-
temporary Story Generators ignore narrative levels.
</bodyText>
<subsectionHeader confidence="0.799232">
Type 1: Outer and one Inner Narration
</subsectionHeader>
<bodyText confidence="0.999379375">
A typical pattern of Type 1 is as follows: An outer narration
contains a NARRATING action whose agent is a narrative
instance different from that of the outer narration. The NAR-
RATED of this action is the inner narration. After the NAR-
RATING action, the rest of the outer narration is told (Table 6).
An example is Heart of Darkness (1902) by Joseph
Conrad. A homodiegetic narrative instance i (= “I&apos;) tells
outer narration a, while j (= “Marlow&apos;) tells inner b:
</bodyText>
<figureCaption confidence="0.999566">
Figure 7: Narrative levels and discourse sequence
</figureCaption>
<figure confidence="0.956372210526316">
NarratedLinguisticMessage
MsgSupport
Relation Filler Restriction
Written
isOjTextType TextType
uses MessageSupport
Spoken
hasForm LinguisticSurfaceForm
isAbout Topic
Thought
LinguisticSurfaceForm represents(AbstractContent)
DirectLSF FreeIndirectLSF IndirectLSF
b
a1
a2
j
b
i
a
</figure>
<table confidence="0.848132">
Classes and Relations Instantiation
Narration a
NarrativeInstance i
Attribution of NarrativeInstance toldBy(a,i)
Attribution of Narration --
Sequence discourse_sequence=[a]
</table>
<tableCaption confidence="0.975419">
Table 5: Zero-Instantiation of Narrative Levels
</tableCaption>
<table confidence="0.9992895">
Classes and Relations Instantiation
Narration a,b
NarrativeInstance ij
Attribution of NarrativeInstance toldBy(a,i), toldBy(bj)
Attribution of Narration toldIn(b,a)
Sequence discourse_sequence=[a1,b,a2]
</table>
<tableCaption confidence="0.997397">
Table 6: One Inner Narration; Framing Outer Narration
</tableCaption>
<construct confidence="0.920890363636364">
[a1 toldBy i] – there was nothing else to do till the end of
the flood; [...] we knew we were fated [...] to hear about one
of Marlow&apos;s inconclusive experiences.
“[b toldBy j] I don&apos;t want to bother you much with what
happened to me personally,” [comment by i] he began,
showing in this remark the weakness of many tellers of tales
[...]; “[b toldBy j] yet to understand the effect of it on me
you ought to know how I got out there, [...], how I went up
that river to the place where I first met the poor chap. [...]
“[b toldBy j] I had then, as you remember, just returned
to London [...].”5
</construct>
<bodyText confidence="0.986078884615385">
The “implicit inquit” phrase he began [...] is a comment
by i concerning the Manner of NARRATING. It is not mod-
elled in the discourse_sequence (see also Subsections 5.1–
5.2 on comments). — The closing part of outer narrative a in
Heart of Darkness is very short (cf. Figure 8, Appendix).
Type 1 has some variants. For instance, an outer narration
might not be resumed at the end of the discourse (Table 7,
Appendix), as in Abbé Prévost’s Manon Lescaut (1731). In
contrast, an outer narration (here: b) might manifest itself in
discourse only after the NARRATED (here: a) produced in the
NARRATING action it contains (Table 8, Appendix). Philip
Roth’s novel Portnoy&apos;s Complaint (1969) shows this pattern.
Yet another variant occurs when the narrative instances of
outer and inner narration are identical (Table 9, Appendix).
An example is Balzac’s Sarrasine (1831), where a homo-
diegetic narrator (i) tells a first narration (a) to an “un-
known” addressee (the “reader”). In the course of a, a NAR-
RATING action is performed by i himself, but with a different
addressee, namely a character in a (cf. Figure 9, Appendix).
Other Types: More Than Two Narrations
More than two NARRATIONS can easily be combined
extending the patterns presented above.
Common “outward” extensions of levels include explicit
introductory or closing NARRATING actions, often produced
on written support by (fictional) editors, translators or
“discoverers” of the inner narration. An example is the
</bodyText>
<footnote confidence="0.9635375">
5 http://www.online-literature.com/conrad/heart_of_darkness/
[10 March, 2005].
</footnote>
<bodyText confidence="0.8715311875">
novel Der goldne Spiegel (‘The golden mirror’, 1772) by
Christoph Martin Wieland, for which a structure with three
opening narrations “leading to” the innermost narration d,
has been identified6 (cf. Table 10, Appendix).
At least equally common are “inward” extensions of the
levels. While several NARRATING actions within one and the
same outer narration are considered to produce parallel
inner narrations at the same level, further levels are added
when a narration is produced within an inner narration. In
The 1001 Nights, Scheherazade entertains King Shahryar
with parallel inner narrations. In these narrations, the char-
acters sometimes tell one another stories, which are inner
narrations at the next level. Table 11 (Appendix) shows a
simplified version of The 1001 Nights, in which Sche-
herazade (j) tells only three stories (b,c,d). The third level is
added by narration e, told by a character (k) of narration d.
</bodyText>
<subsectionHeader confidence="0.996844">
6.3 Discourse Graphs
</subsectionHeader>
<bodyText confidence="0.9999874">
The basic assumption underlying discourse graphs is that
discourse relations (e.g. [Mann and Thompson, 1988;
Hobbs, 1990:83–111; Asher and Lascarides, 2003]) exist
between discourse segments, where a segment is either a
proposition or a graph consisting of already related proposi-
tions. Most theories assume that a limited set of discourse
relations covers all semantic links that might exist between
discourse segments.
Based on the status of segments they relate, multinuclear
and nucleus-satellite discourse relations can be distin-
guished. The definition of nuclearity by Mann and Thomp-
son [1988:266] is centered around the notions of compre-
hensibility (a text is less understandable if a nucleus is
deleted), substitutability (satellites can more easily be
replaced) and writer&apos;s purpose (nuclei are more essential).
Similarly, Hobbs [1990:104] subdivides discourse relations
into coordinating and subordinating.
There are correspondences to narratological theory (e.g.
[Barthes, 1966; Pavel, 1985; Chatman, 1978]). Chatman
subdivides events, as constituting elements of story, into
kernels and satellites. Kernels cannot be deleted without
disturbing the logic of the plot. Satellites contribute first of
all aesthetically, so that their deletion is logically possible.
A difference lies in the size of the analysed segments.
Linguistically inspired theories include propositions
(clauses) as basic level, but descriptions using these theories
often stop at the level of one or several paragraphs (an ex-
ception is [Longacre, 2003]). Narratological analyses usu-
ally concentrate on larger segments, represented by para-
phrases of their propositions [Chatman, 1978:54].
</bodyText>
<sectionHeader confidence="0.51721" genericHeader="method">
Discourse Graphs for Type 1 Narrative Levels
</sectionHeader>
<bodyText confidence="0.999697666666667">
To a certain degree, the narratological description of narra-
tive levels constrains which relations might hold between
narrations of a “levelled” global narrative. Still, it does not
completely disambiguate the global discourse structure.
In fact, in a typical Type 1 narrative (Table 6), the inner
narration b might be related in two competing ways to nar-
</bodyText>
<page confidence="0.590005">
6 By Jörg Schönert in FGN Forum Narratologie
</page>
<note confidence="0.595341">
(http://www.narrport.uni-hamburg.de/) on 21 December, 2004.
</note>
<bodyText confidence="0.9996478">
ration a. The first analysis relates a and b based on a local,
lexical consideration: a NARRATION is regarded as an argu-
ment of the verb phrase that evokes NARRATING. This is
illustrated by Example (1). If NARRATED TextType filler
(e.g. “a story”) is present in a sentence, the English verb tell
allows an implicit LinguisticSurfaceRealization (1a). This
– initially underspecified – argument of tell might then be
realized in a subsequent sentence (1b), so that an Elabora-
tion relation holds between (1a) and (1b). In nucleus-satel-
lite terms, (1a) is a nucleus elaborated by (1b).
</bodyText>
<listItem confidence="0.954416">
(1) a. [a toldBy i] John told a story to Mary. b. “[b
toldBy j] I was seventeen years old, and [...].”
</listItem>
<bodyText confidence="0.973550666666667">
The proposed analysis is in line with Asher and
Lascarides [2003:285], who identify an Elaboration relation
between the propositions (2a) and (2b) of Example (2).
(2) a. John made a promise to Mary. b. He would
phone her.
The possibility that the resulting discourse graph (Figure
10) indeed holds for a global narrative increases if the
NarrativeSequence representing narration b is relatively
short. This also confirms that in these cases, the DirectLin-
guisticSurfaceRepresentation of the content of b is an
aesthetical choice rather than a “plot-logical” necessity.
The presented analysis based on local features does not
always seem globally appropriate as well. Outer narrations
often set the background for a (longer) inner narration at the
start of the discourse_sequence, and draw conclusions,
interpret or evaluate it at the end. Figure 11 shows the
corresponding graph, in which the segment representing
narration b is nucleus of two relations.7 This corresponds to
a “schema” identified by Mann and Thompson [1988:247].
Danlos [2004:130] presents similar double-nuclear struc-
tures (“factorized” nuclei) at the sentence level.
Both presented graphs are plausible. The final choice for
a given global narrative depends not on narratological dis-
course description alone, but on story contents as well.
</bodyText>
<subsectionHeader confidence="0.999818">
6.4 Processing Examples
</subsectionHeader>
<bodyText confidence="0.99974975">
This subsection briefly sketches two examples of how the
Story Generator and the Narratological Structurer (cf. Fig-
ure 3) could cooperate during the creation of typical Type 1
narrative levels (cf. Subsection 6.2).
</bodyText>
<subsectionHeader confidence="0.940659">
Adding an Outer Narration
</subsectionHeader>
<bodyText confidence="0.999795">
The Story Generator creates Story A. Respecting the condi-
tions for a Type 1 narrative, the Narratological Structurer
requests an additional Story B, with some restrictions:
</bodyText>
<listItem confidence="0.9990775">
• B is shorter than A;
• B contains a NARRATING event.
</listItem>
<bodyText confidence="0.99071025">
The Story Generator generates Story B. This might be a
minimal story consisting of the events MEETING (of char-
acters c1 and c2), NARRATING (of a story by c1), REACTION
(of c2). Upon receipt of B, the Narratological Structurer fills
</bodyText>
<footnote confidence="0.958315666666667">
7 At a global level, the Background relation can be compared
only in a very abstract way to the definitions given by Asher and
Lascarides [2003:165–168] or Mann and Thompson [1988:273].
</footnote>
<figure confidence="0.934620777777778">
&amp;quot;Outer Narration&amp;quot; a
NarrativeSequence
a1
NarrativeSequence
Satellite
&amp;quot;Inner Narration&amp;quot; b
NarrativeSequence
Nucleus
[1−30] [31]John told: [32] [33] [34]
</figure>
<figureCaption confidence="0.930686">
Figure 10: Discourse Graph 1 for Type 1, Framing Outer Narration
</figureCaption>
<figure confidence="0.964974">
Satellite Nucleus Nucleus Satellite
[4−12] [13−15]
</figure>
<figureCaption confidence="0.999706">
Figure 11: Discourse Graph 2 for Type 1, Framing Outer Narration
</figureCaption>
<bodyText confidence="0.9998928">
Story A into the Narrated slot of the NARRATING event in
B, tags it as direct speech for the subsequent processing
modules, and arranges all contents into a discourse tree
corresponding to Figure 11. Story A has become an inner
narration and a nucleus, Story B is the outer narration.
</bodyText>
<subsectionHeader confidence="0.897998">
Adding an Inner Narration
</subsectionHeader>
<bodyText confidence="0.994034666666667">
The Story Generator creates Story A which contains a
NARRATING event. The Narratological Structurer requests an
additional Story B, with the following restrictions:
</bodyText>
<listItem confidence="0.9899435">
• B is shorter than A;
• the contents of B illustrate a part of A, for example an
event present in A, or a character trait of the Narra-
tiveInstance of the NARRATING event.
</listItem>
<bodyText confidence="0.997046777777778">
The Story Generator generates Story B. For instance, the
illustration of A might be achieved by similarity: if Story A
contains a CRIME event (e.g. KIDNAPPING), Story B can con-
tain a CRIME event as well (e.g. ROBBERY). The Narratologi-
cal Structurer now fills the new Story B into the Narrated
slot of the NARRATING event in A, tags it as direct speech,
and arranges all contents into a discourse tree, this time
corresponding to Figure 10. Story A has become an outer
narration, Story B is the inner narration and a satellite.
</bodyText>
<sectionHeader confidence="0.987798" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999685363636364">
The proposed system architecture combines Story Genera-
tion, narratological structuring and traditional NLG compo-
nents into an advanced NLG system for the production of
narratives. Starting with the narrative levels parameter, do-
main modelling and meta-knowledge modelling for the
Narratological Structurer were exemplified. Future work
will include comments by narrators, some of which can be
compared to “global level” discourse markers.
Further narratological parameters will be modelled, and
constraints will be formulated for their accumulation. A
cognitive approach might work out their aesthetical effects.
</bodyText>
<figure confidence="0.99728575">
Elaboration
a2
NarrativeSequence
[35−40]
Background
Interpretation/
Evaluation/...
&amp;quot;Outer Narration&amp;quot; a
NarrativeSequence
a1
NarrativeSequence
[1−3]
&amp;quot;Inner Narration&amp;quot; b
NarrativeSequence
a2
NarrativeSequence
</figure>
<bodyText confidence="0.998744166666667">
For example, certain receptional states or strategies could be
identified as “prototypically” activated, enabled, or blocked
by a given combination of narratological parameter instan-
tiations. Finally, content-related studies will lead to concrete
proposals for the interaction between a Narratological Struc-
turer and one of the existing Story Generators.
</bodyText>
<sectionHeader confidence="0.997393" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996038">
This research is supported by DFG (German Research
Foundation) grant ME 1546/2-1. Thanks go to all members
of the Narratology Research Group Hamburg, especially to
Rolf Krause, Jan Christoph Meister and Stefanie Thiedig, as
well as to three anonymous reviewers for their comments.
</bodyText>
<sectionHeader confidence="0.998908" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999098211111111">
[Asher and Lascarides, 2003] Nicholas Asher and Alex Las-
carides. Logics of Conversation. Cambridge University
Press, Cambridge and New York, 2003.
[Barth, 1984] John Barth. The Friday Book, chapter Tales
Within Tales Within Tales, pages 213–252. John
Hopkins University Press, Baltimore and London, 1984.
[Barthes, 1966] Roland Barthes. Introduction à l&apos;analyse
structurale du récit. Communications, 8:1–27, 1966.
[Bateman et al., 1994] John Bateman, Bernardo Magnini
and Fabio Rinaldi. The Generalized {Italian, German,
English} Upper Model. In Proceedings of the ECAI-94
Workshop on Implemented Ontologies, pages 35–45,
Amsterdam, August 1994.
[Cahill et al., 2000] L. Cahill, C. Doran, R. Evans, R. Kib-
ble, C. Mellish, D. Paiva, M. Reape, D. Scott, and N.
Tipper. Enabling Resource Sharing in Language Gen-
eration: An Abstract Reference Architecture. Technical
Paper, MITRE, 2000.
[Callaway and Lester, 2002] Charles B. Callaway and James
C. Lester. Narrative Prose Generation. Artificial Intelli-
gence, 139(2):213–252, August 2002.
[Chatman, 1978] Seymour B. Chatman. Story and Dis-
course. Narrative Structure in Fiction and Film. Cornell
University Press, Ithaca, NY, 1978.
[Danlos, 2004] Laurence Danlos. Discourse Dependency
Structures as constrained DAGs. In Proceedings of the
5th SIGDIAL Workshop on Discourse and Dialogue,
pages 127–135, Cambridge, MA, April 2004.
[Fludernik, 2005] Monika Fludernik. Speech Representa-
tion. In David Herman, Manfred Jahn and Marie-Laure
Ryan, editors, Routledge Encyclopedia of Narrative
Theory, pages 558–563. Routledge, London, 2005.
[Genette, 1980] Gérard Genette. Narrative Discourse. An Es-
say in Method. Cornell University Press, Ithaca, NY, 1980.
[Genette, 1988] Gérard Genette. Narrative Discourse Revis-
ited. Cornell University Press, Ithaca, NY, 1988.
[Gervás et al., 2004] Pablo Gervás, Belén Díaz-Agudo, Fe-
derico Peinado, and Raquel Hervás. Story Plot Genera-
tion based on CBR. In Applications and Innovations in
Intelligent Systems XII (at AI-2004), pages 33–46,
Cambridge, UK, December 2004.
[Harweg, 1968] Roland Harweg. Pronomina und Text-
konstitution. Fink, München, 1968.
[Hobbs, 1990] Jerry R. Hobbs. Literature and Cognition.
CSLI, Stanford, CA, 1990.
[Longacre, 2003] Robert E. Longacre. Holistic Textlinguis-
tics. Electronic working paper, SIL International, 2003.
[Mann and Thompson, 1988] William C. Mann and Sandra
A. Thompson. Rhetorical Structure Theory. Toward a
Functional Theory of Text Organisation. Text, 8(3):243–
281, 1988.
[Niles and Pease, 2001] Ian Niles and Adam Pease. Towards
a Standard Upper Ontology. In Proceedings of the 2nd
International Conference on Formal Ontology in Informa-
tion Systems, pages 2–9, Ogunquit, ME, October 2001.
[Pavel, 1985] Thomas G. Pavel. The Poetics of Plot. The
Case of English Renaissance Drama. Manchester Uni-
versity Press, Manchester, 1985.
[Pérez y Pérez and Sharples, 2004] Rafael Pérez y Pérez and
Mike Sharples. Three computer-based models of story-
telling: BRUTUS, MINSTREL and MEXICA. Knowl-
edge-Based Systems, 17:15–29, 2004.
[Prince, 1973] Gerald Prince. A Grammar of Stories. An
Introduction. Mouton, The Hague and Paris, 1973.
[Reiter, 1994] Ehud Reiter. Has a Consensus NL Generation
Architecture Appeared, and is it Psycholinguistically Plau-
sible? In Proceedings of the 7th International Workshop
on Natural Language Generation, pages 163–170, Ken-
nebunkport, ME, June 1994.
[Reiter and Dale, 2000] Ehud Reiter and Robert Dale. Build-
ing Natural Language Generation Systems. Cambridge
University Press, Cambridge, 2000.
[Rumelhart, 1975] David Rumelhart. Notes on a Schema for
Stories. In Daniel G. Bobrow, editor, Representation and
Understanding. Studies in Cognitive Science, pages 211–
236. Academic Press, New York et al., 1975.
[Ryan, 1991] Marie-Laure Ryan. Possible Worlds, Artificial
Intelligence, and Narrative Theory. Indiana University
Press, Bloomington and Indianapolis, 1991.
[Turner, 1994] Scott R. Turner. The Creative Process: A
Computer Model of Storytelling. Lawrence Erlbaum,
Hillsdale, 1994.
[Ushie, 1988] Yukiko Ushie. ‘Corepresentation’. A Textual
Function of the Indefinite Expression. Text, 6(4):427–
446, 1986.
[Wiebe and Rapaport, 1988] Janyce M. Wiebe and William
J. Rapaport. A Computational Theory of Perspective and
Reference in Narrative. In Proceedings of the 26th
Annual Meeting of the Association for Computational
Linguistics, pages 131–138, Buffalo, NY, June 1988.
</reference>
<table confidence="0.930688041666667">
A Appendix
Parameter Explanation
Time: Order Sequence in which events are told, in comparison with the sequence in which they “actually happened”. In
synchrony, the event sequence in discourse corresponds to the sequence of the story. Anachronies can take the
form of flashbacks (retrospectives) or flashforwards (anticipations).
Time: Speed Relation between story time and discourse time. Congruence exists probably only in single scenes; otherwise
timelapses (accelerations), time jumps (ellipsis), time expansions (decelerations), or pauses are used to achieve
different degrees of expliciteness and emphasis.
Time: Frequence Relation between the number of times a (similar) event happened, and the number of times an event is told. The
following realizations are distinguished: singulative (one-to-one relation), repetitive (“recount several times what
happened once”), and iterative (“recount once what happened several times”).
Mood: Distance Combination of amount of information conveyed and narrator intrusion. Stereotypically, detailed information and
low narrator participation indicate imitation or “direct” dramatic mode, as opposed to a “distant”, mediated
narrative mode. This parameter also affects the way in which speech is reproduced.
Mood: Focalisation Accessibility of knowledge needed to select story events for presentation in discourse. If a narrative instance
disposes of unrestricted knowledge of the story world, it uses external focalization; if the knowledge is restricted to
a character&apos;s field of perception, focalization is internal.
Mood: Spatial, temporal, and ideological points of view from which events are described. Events can be described from
Point of view the point of view of different characters. This parameter covers more aspects than focalization.
Voice: Time relation of the narrating action to the story event. Events can be told while they are happening (concurrently),
Time of narration retrospectively, or prospectively.
Voice: Person Narrator participation. A homodiegetic narrative instance is a character of the current narration (grammatical
realization typically in the first person), while a heterodiegetic narrative instance is “absent” from the current
narrative and not referred to. In a second-person narrative, the protagonist is the reader.
</table>
<tableCaption confidence="0.99362">
Table 1: Selected Narratological Parameters in Discourse Domain
</tableCaption>
<table confidence="0.752542">
NARRATING
Narrative das groje brasilianische Mddchen ‘the tall
Instance Brasilian girl’
ein Beobachter ‘an observer’
metonymic eine Legende ‘a legend’
die Briefe ‘the letters’
die Orte ‘the locations’
</table>
<bodyText confidence="0.983439909090909">
Addressee jedem, der mich danach fragt ‘everyone who
asks me about it’
den Eltern ‘to the parents’
Motivation Die Impulse, aus denen heraus [erzdhlt wird],
sind unterschiedlich ‘The impulses why
something [is told] are different’
Consequence/ [Ich erzdhle dir das] deshalb, damit du heute
Aim schon weijt, daj alles seinen Preis hat. ‘[I tell
you this] so that you already today know that
everything has its price.’
Wir haben uns bepijt vor Lachen[, als Kai
erzdhlte,...] ‘We pissed ourself laughing [when
Kai told...]’
ParallelEvent Wdhrend sie ajen, [erzdhlte er von seinen
Brüdern.] ‘While they were eating, [he was
talking about his brothers.]’
Time nach zwei Schlucken Bier ‘after two sips of beer’
am Abend ‘in the evening’
Place in der Schule ‘at school’; zu Hause ‘at home’
Manner mit fast kindlicher Begeisterung ‘with almost
childlike enthusiasm’
geheimnisvoll tuend ‘with mysterious ado’
</bodyText>
<tableCaption confidence="0.985724">
Table 2: Fillers of the NARRATING frame in DWDS corpus
</tableCaption>
<bodyText confidence="0.668139465116279">
NARRATED_LINGUISTIC_MESSAGE
TextType Geschichte ‘story’
Lügengeschichten ‘cock and bull stories’
Anekdoten ‘anecdotes’
Mdrchen ‘fairy tales’
Trdume ‘dreams’
Witze ‘jokes’
Episoden aus der Geschichte ‘story episodes’
Support in seinem Buch ‘in his book’
Topic von ihrem eigenen Leben ‘about her own life’
von seinem Ausreiseantrag ‘about his emigra-
tion application [from Eastern Germany]’
[die Geschichte] eines Gastarbeiters ‘[the
story] of a foreign worker’
[Geschichten] von den Reihern ‘[stories]
about the herons’
Frauen[geschichten] ‘women [stories]’
mehr oder weniger spannende Kriegsaben-
teuer ‘more or less thrilling war adventures’
was über ihre anderen Hamster ‘something
about her other hamsters’
Linguistic D „Von Kreta aus“[, erzdhlte er weiter,]
Surface „sind wir nach Rhodos gefahren.“
Realization ‘“From Crete“[, he went ahead telling,]
“we went to Rhodos.”’
[erzdhlte er:] „Sie waren Zwillinge.
[...]“ ‘[he told:] “They were twins. [...]”’
— continued on the next page —
NARRATED_LINGUISTIC_MESSAGE (ctd.)
Linguistic I [Dieser Mann hat uns gerade erzählt,]
Surface daß vor seinen Augen ein Toter
Realization wiederauferstanden ist ‘[This man has
(continued) just told us] that someone rose from the
dead right before his eyes’
[Runge erzählt,] er habe gelegentlich
eines Aufenthaltes in Kopenhagen zwei
Männer karikiert, die später, von der
Polizei gesucht, anhand seiner Zeichnung
ausfindig gemacht werden konnten.
‘[Runge tells] he had caricatured two
men during a stay in Copenhagen, who
later on, being searched for by the police,
could be found with his drawing.’
</bodyText>
<tableCaption confidence="0.996956">
Table 4: Fillers of the NARRATED frame in DWDS corpus
</tableCaption>
<table confidence="0.9975445">
Classes and Relations Instantiation
Narration a,b
NarrativeInstance i,j
Attribution of NarrativeInstance toldBy(a,i), toldBy(b,j)
Attribution of Narration toldIn(b,a)
Sequence discourse sequence=[a,b]
</table>
<tableCaption confidence="0.987862">
Table 7: One Inner Narration; Opening Outer Narration only
</tableCaption>
<table confidence="0.997264833333333">
Classes and Relations Instantiation
Narration a,b
NarrativeInstance i,j
Attribution of NarrativeInstance toldBy(a,i), toldBy(b,j)
Attribution of Narration toldIn(a,b)
Sequence discourse_sequence=[a,b]
</table>
<tableCaption confidence="0.992723">
Table 8: One Inner Narration; Closing Outer Narration only
</tableCaption>
<table confidence="0.998827555555555">
Classes and Relations Instantiation
Narration a,b,c,d,e
NarrativeInstance i,j,k
Attribution of toldBy(a,i), toldBy(b,j), toldBy(c,j),
NarrativeInstance toldBy(d,j), toldBy(e,k)
Attribution of Narration toldIn(b,a), toldIn(c,a), toldIn(d,a),
toldIn(e,d)
Sequence discourse-
sequence=[a1,b,a2,c,a3,d1,e,d2,a4]
</table>
<tableCaption confidence="0.999003">
Table 11: Parallel Inner Narrations; Third Level
</tableCaption>
<bodyText confidence="0.869970857142857">
[a2 toldBy i] Marlow ceased, and sat apart [...] in the pose of a
meditating Buddha. Nobody moved [...]. “We have lost the first of
the ebb,” said the Director suddenly. I raised my head. The offing
was barred by a black bank of clouds, and the tranquil waterway
leading to the uttermost ends of the earth flowed sombre under an
overcast sky– seemed to lead into the heart of an immense
darkness.
</bodyText>
<figureCaption confidence="0.771157666666667">
Figure 8: The closing part of narration a in Heart of Darkness
[a1 toldBy i] The next evening we were seated [...] in a dainty
little salon, she on a couch, I on cushions [...].
</figureCaption>
<figure confidence="0.917699625">
“Go on,” she said. “I am listening.”
“But I dare not begin. [...].”
“Speak.”
“I obey.
“[b toldBy i] Ernest-Jean Sarrasine was the only son of a
prosecuting attorney of Franche-Comte,” [comment by i] I began
[...]. “[b toldBy i] His father had [...] amassed a fortune [...], then
[...].”
</figure>
<figureCaption confidence="0.989207">
Figure 9: The same narrative instance tells two narrations (from
Sarrasine by Honoré de Balzac8)
</figureCaption>
<table confidence="0.993219333333333">
Classes and Relations Instantiation
Narration a,b
NarrativeInstance i
Attribution of NarrativeInstanc toldBy(a,i), toldBy(b,i)
Attribution of Narration toldIn(b,a)
Sequence discourse-sequence=[a1,b,a2]
</table>
<tableCaption confidence="0.989425">
Table 9: One Inner Narration with Constant NarrativeInstance
</tableCaption>
<table confidence="0.990642">
Classes and Relations Instantiation
Narration a,b,c,d
NarrativeInstance i,j,k,l
Attribution of toldBy(a,i), toldBy(b,j), toldBy(c,k),
NarrativeInstance toldBy(d,l)
Attribution of Narration toldIn(b,a), toldIn(c,b), toldIn(d,c)
Sequence discourse-sequence=[a,b,c,d]
</table>
<tableCaption confidence="0.99903">
Table 10: Three Opening Narrations; Fourth Level
</tableCaption>
<footnote confidence="0.853019">
8 http://www.gutenberg.org/etext/1826 [10 March, 2005].
</footnote>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.284094">
<title confidence="0.996685">Narratological Knowledge for Natural Language Generation</title>
<author confidence="0.601031">Birte</author>
<affiliation confidence="0.9636035">Narratology Research Group Institut für Germanistik II, University of</affiliation>
<phone confidence="0.478688">Von-Melle-Park 6, D-20146</phone>
<email confidence="0.9901">birte.loenneker@uni-hamburg.de</email>
<abstract confidence="0.998978">The paper proposes an architecture for advanced NLG systems that handle narratives. Special attention is paid to document planning. Domain modelling and meta-knowledge modelling for a narratological structurer are exemplified.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Alex Lascarides</author>
</authors>
<title>Logics of Conversation.</title>
<date>2003</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge and New York,</location>
<marker>[Asher and Lascarides, 2003]</marker>
<rawString>Nicholas Asher and Alex Lascarides. Logics of Conversation. Cambridge University Press, Cambridge and New York, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Barth</author>
</authors>
<title>The Friday Book, chapter Tales Within Tales Within Tales,</title>
<date>1984</date>
<pages>213--252</pages>
<publisher>John Hopkins University Press,</publisher>
<location>Baltimore and London,</location>
<marker>[Barth, 1984]</marker>
<rawString>John Barth. The Friday Book, chapter Tales Within Tales Within Tales, pages 213–252. John Hopkins University Press, Baltimore and London, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roland Barthes</author>
</authors>
<title>Introduction à l&apos;analyse structurale du récit.</title>
<date>1966</date>
<journal>Communications,</journal>
<volume>8</volume>
<marker>[Barthes, 1966]</marker>
<rawString>Roland Barthes. Introduction à l&apos;analyse structurale du récit. Communications, 8:1–27, 1966.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Bateman</author>
<author>Bernardo Magnini</author>
<author>Fabio Rinaldi</author>
</authors>
<title>The Generalized {Italian, German, English} Upper Model.</title>
<date>1994</date>
<booktitle>In Proceedings of the ECAI-94 Workshop on Implemented Ontologies,</booktitle>
<pages>35--45</pages>
<location>Amsterdam,</location>
<marker>[Bateman et al., 1994]</marker>
<rawString>John Bateman, Bernardo Magnini and Fabio Rinaldi. The Generalized {Italian, German, English} Upper Model. In Proceedings of the ECAI-94 Workshop on Implemented Ontologies, pages 35–45, Amsterdam, August 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Cahill</author>
<author>C Doran</author>
<author>R Evans</author>
<author>R Kibble</author>
<author>C Mellish</author>
<author>D Paiva</author>
<author>M Reape</author>
<author>D Scott</author>
<author>N Tipper</author>
</authors>
<title>Enabling Resource Sharing in Language Generation: An Abstract Reference Architecture.</title>
<date>2000</date>
<tech>Technical Paper, MITRE,</tech>
<marker>[Cahill et al., 2000]</marker>
<rawString>L. Cahill, C. Doran, R. Evans, R. Kibble, C. Mellish, D. Paiva, M. Reape, D. Scott, and N. Tipper. Enabling Resource Sharing in Language Generation: An Abstract Reference Architecture. Technical Paper, MITRE, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>James C Lester</author>
</authors>
<title>Narrative Prose Generation.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<volume>139</volume>
<issue>2</issue>
<marker>[Callaway and Lester, 2002]</marker>
<rawString>Charles B. Callaway and James C. Lester. Narrative Prose Generation. Artificial Intelligence, 139(2):213–252, August 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seymour B Chatman</author>
</authors>
<title>Story and Discourse. Narrative Structure in Fiction and Film.</title>
<date>1978</date>
<publisher>Cornell University Press,</publisher>
<location>Ithaca, NY,</location>
<marker>[Chatman, 1978]</marker>
<rawString>Seymour B. Chatman. Story and Discourse. Narrative Structure in Fiction and Film. Cornell University Press, Ithaca, NY, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence Danlos</author>
</authors>
<title>Discourse Dependency Structures as constrained DAGs.</title>
<date>2004</date>
<booktitle>In Proceedings of the 5th SIGDIAL Workshop on Discourse and Dialogue,</booktitle>
<pages>127--135</pages>
<location>Cambridge, MA,</location>
<marker>[Danlos, 2004]</marker>
<rawString>Laurence Danlos. Discourse Dependency Structures as constrained DAGs. In Proceedings of the 5th SIGDIAL Workshop on Discourse and Dialogue, pages 127–135, Cambridge, MA, April 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monika Fludernik</author>
</authors>
<title>Speech Representation. In</title>
<date>2005</date>
<booktitle>Routledge Encyclopedia of Narrative Theory,</booktitle>
<pages>558--563</pages>
<editor>David Herman, Manfred Jahn and Marie-Laure Ryan, editors,</editor>
<publisher>Routledge,</publisher>
<location>London,</location>
<marker>[Fludernik, 2005]</marker>
<rawString>Monika Fludernik. Speech Representation. In David Herman, Manfred Jahn and Marie-Laure Ryan, editors, Routledge Encyclopedia of Narrative Theory, pages 558–563. Routledge, London, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gérard Genette</author>
</authors>
<title>Narrative Discourse. An Essay in Method.</title>
<date>1980</date>
<publisher>Cornell University Press,</publisher>
<location>Ithaca, NY,</location>
<marker>[Genette, 1980]</marker>
<rawString>Gérard Genette. Narrative Discourse. An Essay in Method. Cornell University Press, Ithaca, NY, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gérard Genette</author>
</authors>
<title>Narrative Discourse Revisited.</title>
<date>1988</date>
<publisher>Cornell University Press,</publisher>
<location>Ithaca, NY,</location>
<marker>[Genette, 1988]</marker>
<rawString>Gérard Genette. Narrative Discourse Revisited. Cornell University Press, Ithaca, NY, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo Gervás</author>
<author>Belén Díaz-Agudo</author>
<author>Federico Peinado</author>
<author>Raquel Hervás</author>
</authors>
<title>Story Plot Generation based on CBR.</title>
<date>2004</date>
<booktitle>In Applications and Innovations in Intelligent Systems XII (at AI-2004),</booktitle>
<pages>33--46</pages>
<location>Cambridge, UK,</location>
<marker>[Gervás et al., 2004]</marker>
<rawString>Pablo Gervás, Belén Díaz-Agudo, Federico Peinado, and Raquel Hervás. Story Plot Generation based on CBR. In Applications and Innovations in Intelligent Systems XII (at AI-2004), pages 33–46, Cambridge, UK, December 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roland Harweg</author>
</authors>
<title>Pronomina und Textkonstitution.</title>
<date>1968</date>
<location>Fink, München,</location>
<marker>[Harweg, 1968]</marker>
<rawString>Roland Harweg. Pronomina und Textkonstitution. Fink, München, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Literature and Cognition.</title>
<date>1990</date>
<location>CSLI, Stanford, CA,</location>
<marker>[Hobbs, 1990]</marker>
<rawString>Jerry R. Hobbs. Literature and Cognition. CSLI, Stanford, CA, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert E Longacre</author>
</authors>
<title>Holistic Textlinguistics. Electronic working paper,</title>
<date>2003</date>
<publisher>SIL International,</publisher>
<marker>[Longacre, 2003]</marker>
<rawString>Robert E. Longacre. Holistic Textlinguistics. Electronic working paper, SIL International, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical Structure Theory. Toward a Functional Theory of Text Organisation.</title>
<date>1988</date>
<journal>Text,</journal>
<volume>8</volume>
<issue>3</issue>
<pages>281</pages>
<marker>[Mann and Thompson, 1988]</marker>
<rawString>William C. Mann and Sandra A. Thompson. Rhetorical Structure Theory. Toward a Functional Theory of Text Organisation. Text, 8(3):243– 281, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Niles</author>
<author>Adam Pease</author>
</authors>
<title>Towards a Standard Upper Ontology.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd International Conference on Formal Ontology in Information Systems,</booktitle>
<pages>2--9</pages>
<location>Ogunquit, ME,</location>
<marker>[Niles and Pease, 2001]</marker>
<rawString>Ian Niles and Adam Pease. Towards a Standard Upper Ontology. In Proceedings of the 2nd International Conference on Formal Ontology in Information Systems, pages 2–9, Ogunquit, ME, October 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Pavel</author>
</authors>
<title>The Poetics of Plot. The Case of English Renaissance Drama.</title>
<date>1985</date>
<publisher>Manchester University Press,</publisher>
<location>Manchester,</location>
<marker>[Pavel, 1985]</marker>
<rawString>Thomas G. Pavel. The Poetics of Plot. The Case of English Renaissance Drama. Manchester University Press, Manchester, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rafael</author>
</authors>
<title>Pérez y Pérez and Mike Sharples. Three computer-based models of storytelling:</title>
<date>2004</date>
<journal>BRUTUS, MINSTREL and MEXICA. Knowledge-Based Systems,</journal>
<volume>17</volume>
<marker>[Pérez y Pérez and Sharples, 2004]</marker>
<rawString>Rafael Pérez y Pérez and Mike Sharples. Three computer-based models of storytelling: BRUTUS, MINSTREL and MEXICA. Knowledge-Based Systems, 17:15–29, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Prince</author>
</authors>
<title>A Grammar of Stories. An Introduction. Mouton, The Hague and Paris,</title>
<date>1973</date>
<marker>[Prince, 1973]</marker>
<rawString>Gerald Prince. A Grammar of Stories. An Introduction. Mouton, The Hague and Paris, 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>Has a Consensus NL Generation Architecture Appeared, and is it Psycholinguistically Plausible?</title>
<date>1994</date>
<booktitle>In Proceedings of the 7th International Workshop on Natural Language Generation,</booktitle>
<pages>163--170</pages>
<location>Kennebunkport, ME,</location>
<marker>[Reiter, 1994]</marker>
<rawString>Ehud Reiter. Has a Consensus NL Generation Architecture Appeared, and is it Psycholinguistically Plausible? In Proceedings of the 7th International Workshop on Natural Language Generation, pages 163–170, Kennebunkport, ME, June 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>2000</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge,</location>
<marker>[Reiter and Dale, 2000]</marker>
<rawString>Ehud Reiter and Robert Dale. Building Natural Language Generation Systems. Cambridge University Press, Cambridge, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Rumelhart</author>
</authors>
<title>Notes on a Schema for Stories.</title>
<date>1975</date>
<booktitle>Representation and Understanding. Studies in Cognitive Science,</booktitle>
<pages>211--236</pages>
<editor>In Daniel G. Bobrow, editor,</editor>
<publisher>Academic Press,</publisher>
<location>New York</location>
<marker>[Rumelhart, 1975]</marker>
<rawString>David Rumelhart. Notes on a Schema for Stories. In Daniel G. Bobrow, editor, Representation and Understanding. Studies in Cognitive Science, pages 211– 236. Academic Press, New York et al., 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Laure Ryan</author>
</authors>
<title>Possible Worlds, Artificial Intelligence, and Narrative Theory.</title>
<date>1991</date>
<publisher>Indiana University Press,</publisher>
<location>Bloomington and Indianapolis,</location>
<marker>[Ryan, 1991]</marker>
<rawString>Marie-Laure Ryan. Possible Worlds, Artificial Intelligence, and Narrative Theory. Indiana University Press, Bloomington and Indianapolis, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott R Turner</author>
</authors>
<title>The Creative Process: A Computer Model of Storytelling. Lawrence Erlbaum,</title>
<date>1994</date>
<location>Hillsdale,</location>
<marker>[Turner, 1994]</marker>
<rawString>Scott R. Turner. The Creative Process: A Computer Model of Storytelling. Lawrence Erlbaum, Hillsdale, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>‘Corepresentation’</author>
</authors>
<title>A Textual Function of the Indefinite Expression.</title>
<date>1986</date>
<journal>Text,</journal>
<volume>6</volume>
<issue>4</issue>
<pages>446</pages>
<marker>[Ushie, 1988]</marker>
<rawString>Yukiko Ushie. ‘Corepresentation’. A Textual Function of the Indefinite Expression. Text, 6(4):427– 446, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce M Wiebe</author>
<author>William J Rapaport</author>
</authors>
<title>A Computational Theory of Perspective and Reference in Narrative.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>131--138</pages>
<location>Buffalo, NY,</location>
<marker>[Wiebe and Rapaport, 1988]</marker>
<rawString>Janyce M. Wiebe and William J. Rapaport. A Computational Theory of Perspective and Reference in Narrative. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 131–138, Buffalo, NY, June 1988.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>