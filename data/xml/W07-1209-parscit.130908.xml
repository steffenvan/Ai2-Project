<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018096">
<title confidence="0.9975135">
Pruning the Search Space of a Hand-Crafted Parsing System with a
Probabilistic Parser
</title>
<author confidence="0.982924">
Aoife Cahill Tracy Holloway King John T. Maxwell III
</author>
<affiliation confidence="0.978766">
Dublin City University PARC PARC
</affiliation>
<email confidence="0.987227">
acahill@computing.dcu.ie thking@parc.com maxwell@parc.com
</email>
<sectionHeader confidence="0.995541" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999953">
The demand for deep linguistic analysis
for huge volumes of data means that it is
increasingly important that the time taken
to parse such data is minimized. In the
XLE parsing model which is a hand-crafted,
unification-based parsing system, most of
the time is spent on unification, searching
for valid f-structures (dependency attribute-
value matrices) within the space of the many
valid c-structures (phrase structure trees).
We carried out an experiment to determine
whether pruning the search space at an ear-
lier stage of the parsing process results in
an improvement in the overall time taken to
parse, while maintaining the quality of the
f-structures produced. We retrained a state-
of-the-art probabilistic parser and used it to
pre-bracket input to the XLE, constraining
the valid c-structure space for each sentence.
We evaluated against the PARC 700 Depen-
dency Bank and show that it is possible to
decrease the time taken to parse by —18%
while maintaining accuracy.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992879394736842">
When deep linguistic analysis of massive data is re-
quired (e.g. processing Wikipedia), it is crucial that
the parsing time be minimized. The XLE English
parsing system is a large-scale, hand-crafted, deep,
unification-based system that processes raw text
and produces both constituent-structures (phrase
structure trees) and feature-structures (dependency
attribute-value matrices). A typical breakdown of
parsing time of XLE components is Morphology
(1.6%), Chart (5.8%) and Unifier (92.6%).
The unification process is the bottleneck in the
XLE parsing system. The grammar generates many
valid c-structure trees for a particular sentence: the
Unifier then processes all of these trees (as packed
structures), and a log-linear disambiguation module
can choose the most probable f-structure from the
resulting valid f-structures. For example, the sen-
tence “Growth is slower.” has 84 valid c-structure
trees according to the current English grammar;1
however once the Unifier has processed all of these
trees (in a packed form), only one c-structure and
f-structure pair is valid (see Figure 1). In this in-
stance, the log-linear disambiguation does not need
to choose the most probable result.
The research question we pose is whether the
search space can be pruned earlier before unifi-
cation takes place. Bangalore and Joshi (1999),
Clark and Curran (2004) and Matsuzaki et al. (2007)
show that by using a super tagger before (CCG and
HPSG) parsing, the space required for discrimini-
tive training is drastically reduced. Supertagging
is not widely used within the LFG framework, al-
though there has been some work on using hypertags
(Kinyon, 2000). Ninomiya et al. (2006) propose a
method for faster HPSG parsing while maintaining
accuracy by only using the probabilities of lexical
entry selections (i.e. the supertags) in their discrim-
initive model. In the work presented here, we con-
</bodyText>
<footnote confidence="0.993787333333333">
1For example, is can be a copula, a progressive auxiliary or
a passive auxiliary, while slower can either be an adjective or an
adverb.
</footnote>
<page confidence="0.995304">
65
</page>
<note confidence="0.931117">
Proceedings of the ACL 2007 Workshop on Deep Linguistic Processing, pages 65–72,
Prague, Czech Republic, June, 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999964854166666">
centrate on reducing the number of c-structure trees
that the Unifier has to process, ideally to one tree.
The hope was that this would speed up the parsing
process, but how would it affect the quality of the f-
structures? This is similar to the approach taken by
Cahill et al. (2005) who do not use a hand-crafted
complete unification system (rather an automatically
acquired probabilistic approximation). They parse
raw text into LFG f-structures by first parsing with a
probabilistic CFG parser to choose the most proba-
ble c-structure. This is then passed to an automatic
f-structure annotation algorithm which deterministi-
cally generates one f-structure for that tree.
The most compact way of doing this would be to
integrate a statistical component to the parser that
could rank the c-structure trees and only pass the
most likely forward to the unification process. How-
ever, this would require a large rewrite of the sys-
tem. So, we first wanted to investigate a “cheaper”
alternative to determine the viability of the pruning
strategy; this is the experiment reported in this pa-
per. This is implemented by stipulating constituent
boundaries in the input string, so that any c-structure
that is incompatible with these constraints is invalid
and will not be processed by the Unifier. This was
done to some extent in Riezler et al. (2002) to au-
tomatically generate training data for the log-linear
disambiguation component of XLE. Previous work
obtained the constituent constraints (i.e. brackets)
from the gold-standard trees in the Penn-II Tree-
bank. However, to parse novel text, gold-standard
trees are unavailable.
We used a state-of-the-art probabilistic parser to
provide the bracketing constraints to XLE. These
parsers are accurate (achieving accuracy of over
90% on Section 23 WSJ text), fast, and robust.
The idea is that pre-parsing of the input text by a
fast and accurate parser can prune the c-structure
search space, reducing the amount of work done by
the Unifier, speed up parsing and maintain the high
quality of the f-structures produced.
The structure of this paper is as follows: Section
2 introduces the XLE parsing system. Section 3 de-
scribes a baseline experiment and based on the re-
sults suggests retraining the Bikel parser to improve
results (Section 4). Section 5 describes experiments
on the development set, from which we evaluate the
most successful system against the PARC 700 test
</bodyText>
<equation confidence="0.94430725">
CS 1: ROOT
Sadj[fin] PERIOD
S[fin] .
VPall[fin]
VPcop[fin]
Vcop[fin]
is
&amp;quot;Growth is slower.&amp;quot;
</equation>
<figureCaption confidence="0.997276">
Figure 1: C- and F-Structure for “Growth is slower.”
</figureCaption>
<bodyText confidence="0.846844">
set (Section 6). Finally, Section 7 concludes.
</bodyText>
<sectionHeader confidence="0.863973" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999844666666667">
In this section we introduce Lexical Functional
Grammar, the grammar formalism underlying the
XLE, and briefly describe the XLE parsing system.
</bodyText>
<subsectionHeader confidence="0.995764">
2.1 Lexical Functional Grammar
</subsectionHeader>
<bodyText confidence="0.9998083125">
Lexical Functional Grammar (LFG) (Kaplan and
Bresnan, 1982) is a constraint-based theory of gram-
mar. It (minimally) posits two levels of repre-
sentation, c(onstituent)-structure and f(unctional)-
structure. C-structure is represented by context-
free phrase-structure trees, and captures surface
grammatical configurations such as word order.
The nodes in the trees are annotated with func-
tional equations (attribute-value structure con-
straints) which are resolved to produce an f-
structure. F-structures are recursive attribute-value
matrices, representing abstract syntactic functions.
F-structures approximate basic predicate-argument-
adjunct structures or dependency relations. Fig-
ure 1 shows the c- and f-structure for the sentence
“Growth is slower.”.
</bodyText>
<page confidence="0.603887">
47
</page>
<figure confidence="0.966790238095238">
PRED &apos;be&lt;[68:slow]&gt;[23:growth]&apos;
SUBJ 23
XCOMP
68
PRED &apos;more&apos;
PRED &apos;growth&apos;
PRED &apos;slow&lt;[23:growth]&gt;&apos;
SUBJ [23:growth]
ADJUNCT -1
NP
NPadj
NPzero
N
^ growth
AP[pred]
A
slower
66
Parser Output: (S1 (S (NP (NN Growth)) (VP (AUX is) (ADJP (JJR slower))) (. .)))
Labeled: \[S1 \[S Growth \[VP is \[ADJP slower\] \].\] \]
Unlabeled:\[ \[ Growth \[ is \[ slower\] \].\] \]
</figure>
<figureCaption confidence="0.999659">
Figure 2: Example of retained brackets from parser output to constrain the XLE parser
</figureCaption>
<subsectionHeader confidence="0.993365">
2.2 The XLE Parsing System
</subsectionHeader>
<bodyText confidence="0.999987641025641">
The XLE parsing system is a deep-grammar-based
parsing system. The experiments reported in this
paper use the English LFG grammar constructed
as part of the ParGram project (Butt et al., 2002).
This system incorporates sophisticated ambiguity-
management technology so that all possible syn-
tactic analyses of a sentence are computed in
an efficient, packed representation (Maxwell and
Kaplan, 1993). In accordance with LFG the-
ory, the output includes not only standard context-
free phrase-structure trees (c-structures) but also
attribute-value matrices (f-structures) that explic-
itly encode predicate-argument relations and other
meaningful properties. The f-structures can be de-
terministically mapped to dependency triples with-
out any loss of information, using the built-in or-
dered rewrite system (Crouch et al., 2002). XLE se-
lects the most probable analysis from the potentially
large candidate set by means of a stochastic disam-
biguation component based on a log-linear proba-
bility model (Riezler et al., 2002) that works on the
packed representations. The underlying parsing sys-
tem also has built-in robustness mechanisms that al-
low it to parse strings that are outside the scope of
the grammar as a list of fewest well-formed “frag-
ments”. Furthermore, performance parameters that
bound parsing and disambiguation can be tuned for
efficient but accurate operation. These parameters
include at which point to timeout and return an error,
the amount of stack memory to allocate, the num-
ber of new edges to add to the chart and at which
point to start skimming (a process that guarantees
XLE will finish processing a sentence in polynomial
time by only carrying out a bounded amount of work
on each remaining constituent after a time threshold
has passed). For the experiments reported here, we
did not fine-tune these parameters due to time con-
straints; so default values were arbitrarily set and the
same values used for all parsing experiments.
</bodyText>
<sectionHeader confidence="0.981871" genericHeader="method">
3 Baseline experiments
</sectionHeader>
<bodyText confidence="0.99999095">
We carried out a baseline experiment with two
state-of-the-art parsers to establish what effect pre-
bracketing the input to the XLE system has on the
quality and number of the solutions produced. We
used the Bikel () multi-threaded, head-driven chart-
parsing engine developed at the University of Penn-
sylvania. The second parser is that described in
Charniak and Johnson (2005). This parser uses a
discriminative reranker that selects the most proba-
ble parse from the 50-best parses returned by a gen-
erative parser based on Charniak (2000).
We evaluated against the PARC 700 Dependency
Bank (King et al., 2003) which provides gold-
standard analyses for 700 sentences chosen at ran-
dom from Section 23 of the Penn-II Treebank. The
Dependency Bank was bootstrapped by parsing the
700 sentences with the XLE English grammar, and
then manually correcting the output. The data is di-
vided into two sets, a 140-sentence development set
and a test set of 560 sentences (Kaplan et al., 2004).
We took the raw strings from the 140-sentence
development set and parsed them with each of the
state-of-the-art probabilistic parsers. As an upper
bound for the baseline experiment, we use the brack-
ets in the original Penn-II treebank trees for the 140
development set.
We then used the brackets from each parser out-
put (or original treebank trees) to constrain the XLE
parser. If the input to the XLE parser is bracketed,
the parser will only generate c-structures that respect
these brackets (i.e., only c-structures with brackets
that are compatible with the input brackets are con-
sidered during the unification stage). Figure 2 gives
an example of retained brackets from the parser out-
put. We do not retain brackets around PRN (paren-
thetical phrase) or NP nodes as their structure often
differed too much from XLE analyses of the same
phrases. We passed pre-bracketed strings to the XLE
and evaluated the output f-structures in terms of de-
pendency triples against the 140-sentence subset of
</bodyText>
<page confidence="0.998208">
67
</page>
<table confidence="0.999412333333333">
Non-Fragment Fragment
Penn-XLE Penn-XLE Penn-XLE Penn-XLE
(lab.) (unlab.) (lab.) (unlab.)
Total XLE parses (/140) 0 89 140 140
F-Score of subset 0 84.11 53.92 74.87
Overall F-Score 0 58.91 53.92 74.87
</table>
<tableCaption confidence="0.978105">
Table 1: Upper-bound results for original Penn-II trees
</tableCaption>
<table confidence="0.999915181818182">
Non-Fragment Fragment
XLE Bikel-XLE Bikel-XLE XLE Bikel-XLE Bikel-XLE
(lab.) (unlab.) (lab.) (unlab.)
Total XLE Parses (/140) 119 0 84 135 140 140
F-Score of Subset 81.57 0 84.23 78.72 54.37 73.71
Overall F-Score 72.01 0 55.06 76.13 54.37 *73.71
XLE CJ-XLE CJ-XLE XLE CJ-XLE CJ-XLE
(lab.) (unlab.) (lab.) (unlab.)
Total XLE Parses (/140) 119 0 86 135 139 139
F-Score of Subset 81.57 0 86.57 78.72 53.96 75.64
Overall F-Score 72.01 0 58.04 76.13 53.48 *74.98
</table>
<tableCaption confidence="0.996276">
Table 2: Bikel (2002) and Charniak and Johnson (2005) out-of-the-box baseline results
</tableCaption>
<bodyText confidence="0.994161229166667">
the PARC 700 Dependency Bank.
The results of the baseline experiments are given
in Tables 1 and 2. Table 1 gives the upper bound
results if we use the gold standard Penn treebank
to bracket the input to XLE. Table 2 compares the
XLE (fragment and non-fragment) grammar to the
system where the input is pre-parsed by each parser.
XLE fragment grammars provide a back-off when
parsing fails: the grammar is relaxed and the parser
builds a fragment parse of the well-formed chunks.
We compare the parsers in terms of total number
of parses (out of 140) and the f-score of the sub-
set of sentences successfully parsed. We also com-
bine these scores to give an overall f-score, where
the system scores 0 for each sentence it could not
parse. When testing for statistical significance be-
tween systems, we compare the overall f-score val-
ues. Figures marked with an asterisk are not statisti-
cally significantly different at the 95% level.2
The results show that using unlabeled brackets
achieves reasonable f-scores with the non-fragment
grammar. Using the labeled bracketing from the out-
put of both parsers causes XLE to always fail when
parsing. This is because the labels in the output of
parsers trained on the Penn-II treebank differ con-
siderably from the labels on c-structure trees pro-
2We use the approximate randomization test (Noreen, 1989)
to test for significance.
duced by XLE. Interestingly, the f-scores for both
the CJ-XLE and Bikel-XLE systems are very sim-
ilar to the upper bounds. The gold standard upper
bound is not as high as expected because the Penn
trees used to produce the gold bracketed input are
not always compatible with the XLE-style trees. As
a simple example, the tree in Figure 1 differs from
the parse tree for the same sentence in the Penn
Treebank (Figure 3). The most obvious difference
is the labels on the nodes. However, even in this
small example, there are structural differences, e.g.
the position of the period. In general, the larger the
tree, the greater the difference in both labeling and
structure between the Penn trees and the XLE-style
trees. Therefore, the next step was to retrain a parser
to produce trees with structures the same as XLE-
style trees and with XLE English grammar labels on
the nodes. For this experiment we use the Bikel ()
parser, as it is more suited to being retrained on a
new treebank annotation scheme.
</bodyText>
<sectionHeader confidence="0.994132" genericHeader="method">
4 Retraining the Bikel parser
</sectionHeader>
<bodyText confidence="0.997626333333333">
We retrained the Bikel parser so that it produces
trees like those outputted by the XLE parsing sys-
tem (e.g. Figure 1). To do this, we first created a
training corpus, and then modified the parser to deal
with this new data.
Since there is no manually-created treebank of
</bodyText>
<page confidence="0.987257">
68
</page>
<figure confidence="0.945963">
S
NP VP �
</figure>
<figureCaption confidence="0.999728">
Figure 3: Penn Treebank tree for “Growth is slower.”
</figureCaption>
<bodyText confidence="0.999201928571429">
XLE-style trees, we created one automatically from
sections 02-21 of the Penn-II Treebank. We took the
raw strings from those sections and marked up NP
and SBAR constituents using the brackets from the
gold standard Penn treebank. The NP constituents
are labeled, and the SBAR unlabeled (i.e. the SBAR
constituents are forced to exist in the XLE parse, but
the label on them is not constrained to be SBAR).
We also tagged verbs, adjectives and nouns, based
on the gold standard POS tags.
We parsed the 39,832 marked-up sentences in the
standard training corpus and used the XLE disam-
biguation module to choose the most probable c-
and f-structure pair for each sentence. Ideally we
would have had an expert choose these. We au-
tomatically extracted the c-structure trees produced
by the XLE and performed some automatic post-
processing.3 This resulted in an automatically cre-
ated training corpus of 27,873 XLE-style trees. The
11,959 missing trees were mainly due to the XLE
parses not being compatible with the bracketed in-
put, but sometimes due to time and memory con-
straints.
Using the automatically-created training corpus
of XLE-style trees, we retrained the Bikel parser on
this data. This required adding a new language mod-
ule (“XLE-English”) to the Bikel parser, and regen-
erating head-finding rules for the XLE-style trees.
</bodyText>
<sectionHeader confidence="0.999605" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.99847375">
Once we had a retrained version of the Bikel parser
that parses novel text into XLE-style trees, we car-
ried out a number of experiments on our develop-
ment set in order to establish the optimum settings
</bodyText>
<footnote confidence="0.941298">
3The postprocessing included removing morphological in-
formation and the brackets from the original markup.
</footnote>
<table confidence="0.999903846153846">
All Sentences
XLE Bikel-XLE
Non-fragment grammar
Labeled brackets
Total Parsing Time 964 336
Total XLE Parses (/140) 119 77
F-Score of Subset 81.57 86.11
Overall F-Score 72.01 52.84
Non-fragment grammar
Unlabeled brackets
Total Parsing Time 964 380
Total XLE Parses (/140) 119 89
F-Score of Subset 81.57 85.62
Overall F-Score 72.01 59.34
Fragment grammar
Labeled brackets
Total Parsing Time 1143 390
Total XLE Parses (/140) 135 140
F-Score of Subset 78.72 71.86
Overall F-Score 76.13 71.86
Fragment grammar
Unlabeled brackets
Total Parsing Time 1143 423
Total XLE Parses (/140) 135 140
F-Score of Subset 78.72 74.51
Overall F-Score 76.13 *74.51
</table>
<tableCaption confidence="0.997666">
Table 3: Bikel-XLE Initial Experiments
</tableCaption>
<bodyText confidence="0.687163">
for the evaluation against the PARC 700 test set.
</bodyText>
<subsectionHeader confidence="0.989956">
5.1 Pre-bracketing
</subsectionHeader>
<bodyText confidence="0.990185714285714">
We automatically pre-processed the raw strings from
the 140-sentence development set. This made sys-
tematic changes to the tokens so that the retrained
Bikel parser can parse them. The changes included
removing quotes, converting a and an to a, con-
verting n’t to not, etc. We parsed the pre-processed
strings with the new Bikel parser.
We carried out four initial experiments, experi-
menting with both labeled and unlabeled brackets
and XLE fragment and non-fragment grammars. Ta-
ble 3 gives the results for these experiments. We
compare the parsers in terms of time, total number
of parses (out of 140), the f-score of the subset of
sentences successfully parsed and the overall f-score
if the system achieves a score of 0 for all sentences
it does not parse. The time taken for the Bikel-XLE
system includes the time taken for the Bikel parser
to parse the sentences, as well as the time taken for
XLE to process the bracketed input.
Table 3 shows that using the non-fragment gram-
mar, the Bikel-XLE system performs better on the
</bodyText>
<figure confidence="0.996446">
ADJP-PRD
JJR
slower
NN
VBZ
�
is
Growth
</figure>
<page confidence="0.99647">
69
</page>
<bodyText confidence="0.999953272727273">
subset of sentences parsed than XLE system alone,
though the results are not statistically significantly
better overall, since the coverage is much lower. The
number of bracketed sentences that can be parsed
by XLE increases if the brackets are unlabeled.
The table also shows that the XLE system performs
much better than Bikel-XLE when using the frag-
ment grammars. Although the Bikel-XLE system is
quite a bit faster, there is a drop in f-score; however
this is not statistically significant when the brackets
are unlabeled.
</bodyText>
<subsectionHeader confidence="0.999929">
5.2 Pre-tagging
</subsectionHeader>
<bodyText confidence="0.999862727272727">
We performed some error analysis on the output of
the Bikel-XLE system and noticed that a consider-
able number of errors were due to mis-tagging. So,
we pre-tagged the input to the Bikel parser using the
MXPOST tagger (Ratnaparkhi, 1996). The results
for the non-fragment grammars are presented in Ta-
ble 4. Pre-tagging with MXPOST, however, does
not result in a statistically significantly higher re-
sult than parsing untagged input, although more sen-
tences can be parsed by both systems. Pre-tagging
also adds an extra time overhead cost.
</bodyText>
<table confidence="0.999635833333334">
No pretags MXPOST tags
XLE Bikel-XLE Bikel-XLE
Unlabeled
Total Parsing Time 964 380 493
# XLE Parses (/140) 119 89 92
F-Score of Subset 81.57 85.62 84.98
Overall F-Score 72.01 59.34 *61.11
Labeled
Total Parsing Time 964 336 407
# XLE Parses (/140) 119 77 80
F-Score of Subset 81.57 86.11 85.87
Overall F-Score 72.01 52.84 *54.91
</table>
<tableCaption confidence="0.933064">
Table 4: MXPOST pre-tagged, Non-fragment gram-
mar
</tableCaption>
<subsectionHeader confidence="0.998021">
5.3 Pruning
</subsectionHeader>
<bodyText confidence="0.999756">
The Bikel parser can be customized to allow differ-
ent levels of pruning. The above experiments were
carried out using the default level. We carried out
experiments with three levels of pruning.4 The re-
</bodyText>
<footnote confidence="0.710318333333333">
4The default level of pruning starts at 3.5, has a maximum of
4 and relaxes constraints when parsing fails. Level 1 pruning is
the same as the default except the constraints are never relaxed.
</footnote>
<bodyText confidence="0.994041153846154">
Level 2 pruning has a start value of 3.5 and a maximum value
of 3.5. Level 3 pruning has a start and maximum value of 3.
sults are given in Table 5 for the experiment with
labeled brackets and the non-fragment XLE gram-
mar. More pruning generally results in fewer and
lower-quality parses. The biggest gain is with prun-
ing level 1, where the number and quality of brack-
eted sentences that can be parsed with XLE remains
the same as with the default level. This is because
Bikel with pruning level 1 does not relax the con-
straints when parsing fails and does not waste time
parsing sentences that cannot be parsed in bracketed
form by XLE.
</bodyText>
<tableCaption confidence="0.9182235">
Table 5: Pruning with Non-fragment grammar, La-
beled brackets, Levels default-3
</tableCaption>
<subsectionHeader confidence="0.997089">
5.4 Hybrid systems
</subsectionHeader>
<bodyText confidence="0.997529346153846">
Although pre-parsing with Bikel results in faster
XLE parsing time and high-quality f-structures
(when examining only the quality of the sentences
that can be parsed by the Bikel-XLE system), the
coverage of this system remains poor, therefore the
overall f-score remains poor. One solution is to build
a hybrid two-pass system. During the first pass all
sentences are pre-parsed by Bikel and the bracketed
output is parsed by the XLE non-fragment gram-
mar. In the second pass, the sentences that were
not parsed during the first pass are parsed with the
XLE fragment grammar. We carried out a number
of experiments with hybrid systems and the results
are given in Table 6.
The results show that again labeled brackets re-
sult in a statistically significant increase in f-score,
although the time taken is almost the same as the
XLE fragment grammar alone. Coverage increases
by 1 sentence. Using unlabeled brackets results in
3 additional sentences receiving parses, and parsing
time is improved by —12%; however the increase in
f-score is not statistically significant.
Table 7 gives the results for hybrid systems with
pruning using labeled brackets. The more pruning
that the Bikel parser does, the faster the system,
but the quality of the f-structures begins to deteri-
</bodyText>
<table confidence="0.987456833333333">
Default L1 L2 L3
Total Parsing Time 336 137 137 106
# XLE Parses (/140) 77 77 76 75
F-Score of Subset 86.11 86.11 86.04 85.87
Overall F-Score 52.84 *52.84 *52.43 *52.36
70
XLE Bikel-XLE hybrid Bikel-XLE hybrid
(frag) (labeled) (unlabeled)
Total Parsing Time 1143 1121 1001
Total XLE Parses (/140) 135 136 138
F-Score of Subset 78.72 79.85 79.51
Overall F-Score 76.13 77.61 *78.28
</table>
<tableCaption confidence="0.938696">
Table 6: Hybrid systems compared to the XLE fragment grammar alone
</tableCaption>
<table confidence="0.999945833333333">
XLE Bikel-XLE hybrid Bikel-XLE hybrid Bikel-XLE hybrid
(frag) (level 1) (level 2) (level 3)
Total Parsing Time 1143 918 920 885
Total XLE Parses (/140) 135 136 136 136
F-Score of Subset 78.72 79.85 79.79 79.76
Overall F-Score 76.13 77.61 77.55 77.53
</table>
<tableCaption confidence="0.999723">
Table 7: Hybrid systems with pruning compared to the XLE fragment grammar alone
</tableCaption>
<bodyText confidence="0.999420625">
orate. The best system is the Bikel-XLE hybrid sys-
tem with labeled brackets and pruning level 1. This
system achieves a statistically significant increase in
f-score over the XLE fragment grammar alone, de-
creases the time taken to parse by almost 20% and
increases coverage by 1 sentence. Therefore, we
chose this system to perform our final evaluation
against the PARC 700 Dependency Bank.
</bodyText>
<sectionHeader confidence="0.983274" genericHeader="evaluation">
6 Evaluation against the PARC 700
</sectionHeader>
<bodyText confidence="0.998781857142857">
We evaluated the system that performs best on the
development set against the 560-sentence test set of
the PARC 700 Dependency Bank. The results are
given in Table 8. The hybrid system achieves an
18% decrease in parsing time, a slight improvement
in coverage of 0.9%, and a 1.12% improvement in
overall f-structure quality.
</bodyText>
<table confidence="0.999007666666667">
XLE Bikel-XLE hybrid
(frag) (labeled, prune 1)
Total Parsing Time 4967 4077
Total XLE Parses (/560) 537 542
F-Score of Subset 80.13 80.63
Overall F-Score 77.04 78.16
</table>
<tableCaption confidence="0.949437">
Table 8: PARC 700 evaluation of the Hybrid system
compared to the XLE fragment grammar alone
</tableCaption>
<sectionHeader confidence="0.998709" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.99994606060606">
We successfully used a state-of-the-art probabilistic
parser in combination with a hand-crafted system to
improve parsing time while maintaining the quality
of the output produced. Our hybrid system consists
of two phases. During phase one, pre-processed, to-
kenized text is parsed with a retrained Bikel parser.
We use the labeled brackets in the output to constrain
the c-structures generated by the XLE parsing sys-
tem. In the second phase, we use the XLE fragment
grammar to parse any remaining sentences that have
not received a parse in the first phase.
Given the slight increase in overall f-score per-
formance, the speed up in parsing time (—18%) can
justify more complicated processing architecture for
some applications.5 The main disadvantage of the
current system is that the input to the Bikel parser
needs to be tokenized, whereas XLE processes raw
text. One solution to this is to use a state-of-the-art
probabilistic parser that accepts untokenized input
(such as Charniak and Johnson, 2005) and retrain it
as described in Section 4.
Kaplan et al. (2004) compared time and accuracy
of a version of the Collins parser tuned to maximize
speed and accuracy to an earlier version of the XLE
parser. Although the XLE parser was more accu-
rate, the parsing time was a factor of 1.49 slower
(time converting Collins trees to dependencies was
not counted in the parse time; time to produce f-
structures from c-structures was counted in the XLE
parse time). The hybrid system here narrows the
speed gap while maintaining greater accuracy.
The original hope behind using the brackets to
constrain the XLE c-structure generation was that
</bodyText>
<footnote confidence="0.968701333333333">
5For example, in massive data applications, if the parsing
task takes 30 days, reducing this by 18% saves more than 5
days.
</footnote>
<page confidence="0.998458">
71
</page>
<bodyText confidence="0.999981736842105">
the brackets would force the XLE to choose only
one tree. However, the brackets were sometimes
ambiguous, and sometimes more than one valid tree
was found. In the final evaluation against the PARC
700 test set, the average number of optimal solutions
was 4.05; so the log-linear disambiguation mod-
ule still had to chose the most probable f-structure.
However, this is considerably less to choose from
than the average of 341 optimal solutions produced
by the XLE fragment grammar for the same sen-
tences when unbracketed.
Based on the results of this experiment we have
integrated a statistical component into the XLE
parser itself. With this architecture the packed c-
structure trees are pruned before unification with-
out needing to preprocess the input text. The XLE
c-structure pruning results in a —30% reduction in
parse time on the Wikipedia with little loss in preci-
sion. We hope to report on this in the near future.
</bodyText>
<sectionHeader confidence="0.998593" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.723428">
The research in this paper was partly funded by Sci-
ence Foundation Ireland grant 04/BR/CS0370.
</bodyText>
<sectionHeader confidence="0.99763" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999886972972973">
Srinivas Bangalore and Aravind K. Joshi. 1999. Su-
pertagging: An approach to alsmost parsing. Com-
putational Linguistics, 25(2):237–265.
Dan Bikel. Design of a Multi-lingual, Parallel-processing
Statistical Parsing Engine. In Proceedings of HLT,
YEAR= 2002, pages= 24–27, address= San Diego,
CA,.
Miriam Butt, Helge Dyvik, Tracy Holloway King, Hi-
roshi Masuichi, and Christian Rohrer. 2002. The Par-
allel Grammar Project. In Proceedings of Workshop
on Grammar Engineering and Evaluation, pages 1–7,
Taiwan.
Aoife Cahill, Martin Forst, Michael Burke, Mairead Mc-
Carthy, Ruth O’Donovan, Christian Rohrer, Josef van
Genabith, and Andy Way. 2005. Treebank-based
acquisition of multilingual unification grammar re-
sources. Journal of Research on Language and Com-
putation, pages 247–279.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of ACL, pages 173–180,
Ann Arbor, Michigan.
Eugene Charniak. 2000. A maximum entropy inspired
parser. In Proceedings of NAACL, pages 132–139,
Seattle, WA.
Stephen Clark and James R. Curran. 2004. The Impor-
tance of Supertagging for Wide-Coverage CCG Pars-
ing . In Proceedings of COLING, pages 282–288,
Geneva, Switzerland, Aug 23–Aug 27. COLING.
Richard Crouch, Ron Kaplan, Tracy Holloway King, and
Stefan Riezler. 2002. A comparison of evaluation
metrics for a broad coverage parser. In Proceedings of
the LREC Workshop: Beyond PARSEVAL, pages 67–
74, Las Palmas, Canary Islands, Spain.
Ron Kaplan and Joan Bresnan. 1982. Lexical Functional
Grammar, a Formal System for Grammatical Repre-
sentation. In Joan Bresnan, editor, The Mental Repre-
sentation of Grammatical Relations, pages 173–281.
MIT Press, Cambridge, MA.
Ron Kaplan, Stefan Riezler, Tracy Holloway King,
John T. Maxwell, Alexander Vasserman, and Richard
Crouch. 2004. Speed and Accuracy in Shallow and
Deep Stochastic Parsing. In Proceedings of HLT-
NAACL, pages 97–104, Boston, MA.
Tracy Holloway King, Richard Crouch, Stefan Riezler,
Mary Dalrymple, and Ron Kaplan. 2003. The PARC
700 dependency bank. In Proceedings ofLINC, pages
1–8, Budapest, Hungary.
Alexandra Kinyon. 2000. Hypertags. In Proceedings of
COLING, pages 446–452, Saarbr¨ucken.
Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii.
2007. Efficient HPSG Parsing with Supertagging and
CFG-filtering. In Proceedings of IJCAI, pages 1671–
1676, India.
John T. Maxwell and Ronald M. Kaplan. 1993. The
interface between phrasal and functional constraints.
Computational Linguistics, 19(4):571–590.
Takashi Ninomiya, Takuya Matsuzaki, Yoshimasa Tsu-
ruoka, Yusuke Miyao, and Jun’ichi Tsujii. 2006.
Extremely Lexicalized Models for Accurate and Fast
HPSG Parsing. In Proceedings of EMNLP, pages
155–163, Australia.
Eric W. Noreen. 1989. Computer Intensive Methods
for Testing Hypotheses: An Introduction. Wiley, New
York.
Adwait Ratnaparkhi. 1996. A Maximum Entropy Part-
Of-Speech Tagger. In Proceedings of EMNLP, pages
133–142, Philadelphia, PA.
Stefan Riezler, Tracy King, Ronald Kaplan, Richard
Crouch, John T. Maxwell, and Mark Johnson. 2002.
Parsing the Wall Street Journal using a Lexical-
Functional Grammar and Discriminative Estimation
Techniques. In Proceedings of ACL, pages 271–278,
Philadelphia, PA.
</reference>
<page confidence="0.998724">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.452305">
<title confidence="0.9893805">Pruning the Search Space of a Hand-Crafted Parsing System with a Probabilistic Parser</title>
<author confidence="0.734544">Aoife Cahill Tracy Holloway King John T Maxwell</author>
<affiliation confidence="0.520812">Dublin City University PARC PARC</affiliation>
<email confidence="0.958172">acahill@computing.dcu.iethking@parc.commaxwell@parc.com</email>
<abstract confidence="0.998737916666667">The demand for deep linguistic analysis for huge volumes of data means that it is increasingly important that the time taken to parse such data is minimized. In the XLE parsing model which is a hand-crafted, unification-based parsing system, most of the time is spent on unification, searching for valid f-structures (dependency attributevalue matrices) within the space of the many valid c-structures (phrase structure trees). We carried out an experiment to determine whether pruning the search space at an earlier stage of the parsing process results in an improvement in the overall time taken to parse, while maintaining the quality of the f-structures produced. We retrained a stateof-the-art probabilistic parser and used it to pre-bracket input to the XLE, constraining the valid c-structure space for each sentence. We evaluated against the PARC 700 Dependency Bank and show that it is possible to the time taken to parse by while maintaining accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Aravind K Joshi</author>
</authors>
<title>Supertagging: An approach to alsmost parsing.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="2560" citStr="Bangalore and Joshi (1999)" startWordPosition="385" endWordPosition="388">res), and a log-linear disambiguation module can choose the most probable f-structure from the resulting valid f-structures. For example, the sentence “Growth is slower.” has 84 valid c-structure trees according to the current English grammar;1 however once the Unifier has processed all of these trees (in a packed form), only one c-structure and f-structure pair is valid (see Figure 1). In this instance, the log-linear disambiguation does not need to choose the most probable result. The research question we pose is whether the search space can be pruned earlier before unification takes place. Bangalore and Joshi (1999), Clark and Curran (2004) and Matsuzaki et al. (2007) show that by using a super tagger before (CCG and HPSG) parsing, the space required for discriminitive training is drastically reduced. Supertagging is not widely used within the LFG framework, although there has been some work on using hypertags (Kinyon, 2000). Ninomiya et al. (2006) propose a method for faster HPSG parsing while maintaining accuracy by only using the probabilities of lexical entry selections (i.e. the supertags) in their discriminitive model. In the work presented here, we con1For example, is can be a copula, a progressiv</context>
</contexts>
<marker>Bangalore, Joshi, 1999</marker>
<rawString>Srinivas Bangalore and Aravind K. Joshi. 1999. Supertagging: An approach to alsmost parsing. Computational Linguistics, 25(2):237–265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Bikel</author>
</authors>
<title>Design of a Multi-lingual, Parallel-processing Statistical Parsing Engine.</title>
<date>2002</date>
<booktitle>In Proceedings of HLT, YEAR=</booktitle>
<pages>24--27</pages>
<location>San Diego, CA,.</location>
<contexts>
<context position="12135" citStr="Bikel (2002)" startWordPosition="1906" endWordPosition="1907">40 F-Score of subset 0 84.11 53.92 74.87 Overall F-Score 0 58.91 53.92 74.87 Table 1: Upper-bound results for original Penn-II trees Non-Fragment Fragment XLE Bikel-XLE Bikel-XLE XLE Bikel-XLE Bikel-XLE (lab.) (unlab.) (lab.) (unlab.) Total XLE Parses (/140) 119 0 84 135 140 140 F-Score of Subset 81.57 0 84.23 78.72 54.37 73.71 Overall F-Score 72.01 0 55.06 76.13 54.37 *73.71 XLE CJ-XLE CJ-XLE XLE CJ-XLE CJ-XLE (lab.) (unlab.) (lab.) (unlab.) Total XLE Parses (/140) 119 0 86 135 139 139 F-Score of Subset 81.57 0 86.57 78.72 53.96 75.64 Overall F-Score 72.01 0 58.04 76.13 53.48 *74.98 Table 2: Bikel (2002) and Charniak and Johnson (2005) out-of-the-box baseline results the PARC 700 Dependency Bank. The results of the baseline experiments are given in Tables 1 and 2. Table 1 gives the upper bound results if we use the gold standard Penn treebank to bracket the input to XLE. Table 2 compares the XLE (fragment and non-fragment) grammar to the system where the input is pre-parsed by each parser. XLE fragment grammars provide a back-off when parsing fails: the grammar is relaxed and the parser builds a fragment parse of the well-formed chunks. We compare the parsers in terms of total number of parse</context>
</contexts>
<marker>Bikel, 2002</marker>
<rawString>Dan Bikel. Design of a Multi-lingual, Parallel-processing Statistical Parsing Engine. In Proceedings of HLT, YEAR= 2002, pages= 24–27, address= San Diego, CA,.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Helge Dyvik</author>
<author>Tracy Holloway King</author>
<author>Hiroshi Masuichi</author>
<author>Christian Rohrer</author>
</authors>
<title>The Parallel Grammar Project.</title>
<date>2002</date>
<booktitle>In Proceedings of Workshop on Grammar Engineering and Evaluation,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="7642" citStr="Butt et al., 2002" startWordPosition="1181" endWordPosition="1184">D &apos;more&apos; PRED &apos;growth&apos; PRED &apos;slow&lt;[23:growth]&gt;&apos; SUBJ [23:growth] ADJUNCT -1 NP NPadj NPzero N ^ growth AP[pred] A slower 66 Parser Output: (S1 (S (NP (NN Growth)) (VP (AUX is) (ADJP (JJR slower))) (. .))) Labeled: \[S1 \[S Growth \[VP is \[ADJP slower\] \].\] \] Unlabeled:\[ \[ Growth \[ is \[ slower\] \].\] \] Figure 2: Example of retained brackets from parser output to constrain the XLE parser 2.2 The XLE Parsing System The XLE parsing system is a deep-grammar-based parsing system. The experiments reported in this paper use the English LFG grammar constructed as part of the ParGram project (Butt et al., 2002). This system incorporates sophisticated ambiguitymanagement technology so that all possible syntactic analyses of a sentence are computed in an efficient, packed representation (Maxwell and Kaplan, 1993). In accordance with LFG theory, the output includes not only standard contextfree phrase-structure trees (c-structures) but also attribute-value matrices (f-structures) that explicitly encode predicate-argument relations and other meaningful properties. The f-structures can be deterministically mapped to dependency triples without any loss of information, using the built-in ordered rewrite sy</context>
</contexts>
<marker>Butt, Dyvik, King, Masuichi, Rohrer, 2002</marker>
<rawString>Miriam Butt, Helge Dyvik, Tracy Holloway King, Hiroshi Masuichi, and Christian Rohrer. 2002. The Parallel Grammar Project. In Proceedings of Workshop on Grammar Engineering and Evaluation, pages 1–7, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Martin Forst</author>
<author>Michael Burke</author>
<author>Mairead McCarthy</author>
<author>Ruth O’Donovan</author>
<author>Christian Rohrer</author>
<author>Josef van Genabith</author>
<author>Andy Way</author>
</authors>
<title>Treebank-based acquisition of multilingual unification grammar resources.</title>
<date>2005</date>
<journal>Journal of Research on Language and Computation,</journal>
<pages>247--279</pages>
<marker>Cahill, Forst, Burke, McCarthy, O’Donovan, Rohrer, van Genabith, Way, 2005</marker>
<rawString>Aoife Cahill, Martin Forst, Michael Burke, Mairead McCarthy, Ruth O’Donovan, Christian Rohrer, Josef van Genabith, and Andy Way. 2005. Treebank-based acquisition of multilingual unification grammar resources. Journal of Research on Language and Computation, pages 247–279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>173--180</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="9796" citStr="Charniak and Johnson (2005)" startWordPosition="1518" endWordPosition="1521">t after a time threshold has passed). For the experiments reported here, we did not fine-tune these parameters due to time constraints; so default values were arbitrarily set and the same values used for all parsing experiments. 3 Baseline experiments We carried out a baseline experiment with two state-of-the-art parsers to establish what effect prebracketing the input to the XLE system has on the quality and number of the solutions produced. We used the Bikel () multi-threaded, head-driven chartparsing engine developed at the University of Pennsylvania. The second parser is that described in Charniak and Johnson (2005). This parser uses a discriminative reranker that selects the most probable parse from the 50-best parses returned by a generative parser based on Charniak (2000). We evaluated against the PARC 700 Dependency Bank (King et al., 2003) which provides goldstandard analyses for 700 sentences chosen at random from Section 23 of the Penn-II Treebank. The Dependency Bank was bootstrapped by parsing the 700 sentences with the XLE English grammar, and then manually correcting the output. The data is divided into two sets, a 140-sentence development set and a test set of 560 sentences (Kaplan et al., 20</context>
<context position="12167" citStr="Charniak and Johnson (2005)" startWordPosition="1909" endWordPosition="1912">set 0 84.11 53.92 74.87 Overall F-Score 0 58.91 53.92 74.87 Table 1: Upper-bound results for original Penn-II trees Non-Fragment Fragment XLE Bikel-XLE Bikel-XLE XLE Bikel-XLE Bikel-XLE (lab.) (unlab.) (lab.) (unlab.) Total XLE Parses (/140) 119 0 84 135 140 140 F-Score of Subset 81.57 0 84.23 78.72 54.37 73.71 Overall F-Score 72.01 0 55.06 76.13 54.37 *73.71 XLE CJ-XLE CJ-XLE XLE CJ-XLE CJ-XLE (lab.) (unlab.) (lab.) (unlab.) Total XLE Parses (/140) 119 0 86 135 139 139 F-Score of Subset 81.57 0 86.57 78.72 53.96 75.64 Overall F-Score 72.01 0 58.04 76.13 53.48 *74.98 Table 2: Bikel (2002) and Charniak and Johnson (2005) out-of-the-box baseline results the PARC 700 Dependency Bank. The results of the baseline experiments are given in Tables 1 and 2. Table 1 gives the upper bound results if we use the gold standard Penn treebank to bracket the input to XLE. Table 2 compares the XLE (fragment and non-fragment) grammar to the system where the input is pre-parsed by each parser. XLE fragment grammars provide a back-off when parsing fails: the grammar is relaxed and the parser builds a fragment parse of the well-formed chunks. We compare the parsers in terms of total number of parses (out of 140) and the f-score o</context>
<context position="25088" citStr="Charniak and Johnson, 2005" startWordPosition="4065" endWordPosition="4068">ctures generated by the XLE parsing system. In the second phase, we use the XLE fragment grammar to parse any remaining sentences that have not received a parse in the first phase. Given the slight increase in overall f-score performance, the speed up in parsing time (—18%) can justify more complicated processing architecture for some applications.5 The main disadvantage of the current system is that the input to the Bikel parser needs to be tokenized, whereas XLE processes raw text. One solution to this is to use a state-of-the-art probabilistic parser that accepts untokenized input (such as Charniak and Johnson, 2005) and retrain it as described in Section 4. Kaplan et al. (2004) compared time and accuracy of a version of the Collins parser tuned to maximize speed and accuracy to an earlier version of the XLE parser. Although the XLE parser was more accurate, the parsing time was a factor of 1.49 slower (time converting Collins trees to dependencies was not counted in the parse time; time to produce fstructures from c-structures was counted in the XLE parse time). The hybrid system here narrows the speed gap while maintaining greater accuracy. The original hope behind using the brackets to constrain the XL</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking. In Proceedings of ACL, pages 173–180, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum entropy inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>132--139</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="9958" citStr="Charniak (2000)" startWordPosition="1547" endWordPosition="1548"> and the same values used for all parsing experiments. 3 Baseline experiments We carried out a baseline experiment with two state-of-the-art parsers to establish what effect prebracketing the input to the XLE system has on the quality and number of the solutions produced. We used the Bikel () multi-threaded, head-driven chartparsing engine developed at the University of Pennsylvania. The second parser is that described in Charniak and Johnson (2005). This parser uses a discriminative reranker that selects the most probable parse from the 50-best parses returned by a generative parser based on Charniak (2000). We evaluated against the PARC 700 Dependency Bank (King et al., 2003) which provides goldstandard analyses for 700 sentences chosen at random from Section 23 of the Penn-II Treebank. The Dependency Bank was bootstrapped by parsing the 700 sentences with the XLE English grammar, and then manually correcting the output. The data is divided into two sets, a 140-sentence development set and a test set of 560 sentences (Kaplan et al., 2004). We took the raw strings from the 140-sentence development set and parsed them with each of the state-of-the-art probabilistic parsers. As an upper bound for </context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum entropy inspired parser. In Proceedings of NAACL, pages 132–139, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>The Importance of Supertagging for Wide-Coverage CCG Parsing .</title>
<date>2004</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>282--288</pages>
<publisher>COLING.</publisher>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="2585" citStr="Clark and Curran (2004)" startWordPosition="389" endWordPosition="392">biguation module can choose the most probable f-structure from the resulting valid f-structures. For example, the sentence “Growth is slower.” has 84 valid c-structure trees according to the current English grammar;1 however once the Unifier has processed all of these trees (in a packed form), only one c-structure and f-structure pair is valid (see Figure 1). In this instance, the log-linear disambiguation does not need to choose the most probable result. The research question we pose is whether the search space can be pruned earlier before unification takes place. Bangalore and Joshi (1999), Clark and Curran (2004) and Matsuzaki et al. (2007) show that by using a super tagger before (CCG and HPSG) parsing, the space required for discriminitive training is drastically reduced. Supertagging is not widely used within the LFG framework, although there has been some work on using hypertags (Kinyon, 2000). Ninomiya et al. (2006) propose a method for faster HPSG parsing while maintaining accuracy by only using the probabilities of lexical entry selections (i.e. the supertags) in their discriminitive model. In the work presented here, we con1For example, is can be a copula, a progressive auxiliary or a passive </context>
</contexts>
<marker>Clark, Curran, 2004</marker>
<rawString>Stephen Clark and James R. Curran. 2004. The Importance of Supertagging for Wide-Coverage CCG Parsing . In Proceedings of COLING, pages 282–288, Geneva, Switzerland, Aug 23–Aug 27. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Crouch</author>
<author>Ron Kaplan</author>
<author>Tracy Holloway King</author>
<author>Stefan Riezler</author>
</authors>
<title>A comparison of evaluation metrics for a broad coverage parser.</title>
<date>2002</date>
<booktitle>In Proceedings of the LREC Workshop: Beyond PARSEVAL,</booktitle>
<pages>pages</pages>
<contexts>
<context position="8268" citStr="Crouch et al., 2002" startWordPosition="1268" endWordPosition="1271"> system incorporates sophisticated ambiguitymanagement technology so that all possible syntactic analyses of a sentence are computed in an efficient, packed representation (Maxwell and Kaplan, 1993). In accordance with LFG theory, the output includes not only standard contextfree phrase-structure trees (c-structures) but also attribute-value matrices (f-structures) that explicitly encode predicate-argument relations and other meaningful properties. The f-structures can be deterministically mapped to dependency triples without any loss of information, using the built-in ordered rewrite system (Crouch et al., 2002). XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear probability model (Riezler et al., 2002) that works on the packed representations. The underlying parsing system also has built-in robustness mechanisms that allow it to parse strings that are outside the scope of the grammar as a list of fewest well-formed “fragments”. Furthermore, performance parameters that bound parsing and disambiguation can be tuned for efficient but accurate operation. These parameters include at which point to timeout</context>
</contexts>
<marker>Crouch, Kaplan, King, Riezler, 2002</marker>
<rawString>Richard Crouch, Ron Kaplan, Tracy Holloway King, and Stefan Riezler. 2002. A comparison of evaluation metrics for a broad coverage parser. In Proceedings of the LREC Workshop: Beyond PARSEVAL, pages 67– 74, Las Palmas, Canary Islands, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Kaplan</author>
<author>Joan Bresnan</author>
</authors>
<title>Lexical Functional Grammar, a Formal System for Grammatical Representation.</title>
<date>1982</date>
<booktitle>The Mental Representation of Grammatical Relations,</booktitle>
<pages>173--281</pages>
<editor>In Joan Bresnan, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="6275" citStr="Kaplan and Bresnan, 1982" startWordPosition="979" endWordPosition="982">ning the Bikel parser to improve results (Section 4). Section 5 describes experiments on the development set, from which we evaluate the most successful system against the PARC 700 test CS 1: ROOT Sadj[fin] PERIOD S[fin] . VPall[fin] VPcop[fin] Vcop[fin] is &amp;quot;Growth is slower.&amp;quot; Figure 1: C- and F-Structure for “Growth is slower.” set (Section 6). Finally, Section 7 concludes. 2 Background In this section we introduce Lexical Functional Grammar, the grammar formalism underlying the XLE, and briefly describe the XLE parsing system. 2.1 Lexical Functional Grammar Lexical Functional Grammar (LFG) (Kaplan and Bresnan, 1982) is a constraint-based theory of grammar. It (minimally) posits two levels of representation, c(onstituent)-structure and f(unctional)- structure. C-structure is represented by contextfree phrase-structure trees, and captures surface grammatical configurations such as word order. The nodes in the trees are annotated with functional equations (attribute-value structure constraints) which are resolved to produce an fstructure. F-structures are recursive attribute-value matrices, representing abstract syntactic functions. F-structures approximate basic predicate-argumentadjunct structures or depe</context>
</contexts>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>Ron Kaplan and Joan Bresnan. 1982. Lexical Functional Grammar, a Formal System for Grammatical Representation. In Joan Bresnan, editor, The Mental Representation of Grammatical Relations, pages 173–281. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Kaplan</author>
<author>Stefan Riezler</author>
<author>Tracy Holloway King</author>
<author>John T Maxwell</author>
<author>Alexander Vasserman</author>
<author>Richard Crouch</author>
</authors>
<title>Speed and Accuracy in Shallow and Deep Stochastic Parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of HLTNAACL,</booktitle>
<pages>97--104</pages>
<location>Boston, MA.</location>
<contexts>
<context position="10399" citStr="Kaplan et al., 2004" startWordPosition="1620" endWordPosition="1623">nd Johnson (2005). This parser uses a discriminative reranker that selects the most probable parse from the 50-best parses returned by a generative parser based on Charniak (2000). We evaluated against the PARC 700 Dependency Bank (King et al., 2003) which provides goldstandard analyses for 700 sentences chosen at random from Section 23 of the Penn-II Treebank. The Dependency Bank was bootstrapped by parsing the 700 sentences with the XLE English grammar, and then manually correcting the output. The data is divided into two sets, a 140-sentence development set and a test set of 560 sentences (Kaplan et al., 2004). We took the raw strings from the 140-sentence development set and parsed them with each of the state-of-the-art probabilistic parsers. As an upper bound for the baseline experiment, we use the brackets in the original Penn-II treebank trees for the 140 development set. We then used the brackets from each parser output (or original treebank trees) to constrain the XLE parser. If the input to the XLE parser is bracketed, the parser will only generate c-structures that respect these brackets (i.e., only c-structures with brackets that are compatible with the input brackets are considered during</context>
<context position="25151" citStr="Kaplan et al. (2004)" startWordPosition="4077" endWordPosition="4080">e the XLE fragment grammar to parse any remaining sentences that have not received a parse in the first phase. Given the slight increase in overall f-score performance, the speed up in parsing time (—18%) can justify more complicated processing architecture for some applications.5 The main disadvantage of the current system is that the input to the Bikel parser needs to be tokenized, whereas XLE processes raw text. One solution to this is to use a state-of-the-art probabilistic parser that accepts untokenized input (such as Charniak and Johnson, 2005) and retrain it as described in Section 4. Kaplan et al. (2004) compared time and accuracy of a version of the Collins parser tuned to maximize speed and accuracy to an earlier version of the XLE parser. Although the XLE parser was more accurate, the parsing time was a factor of 1.49 slower (time converting Collins trees to dependencies was not counted in the parse time; time to produce fstructures from c-structures was counted in the XLE parse time). The hybrid system here narrows the speed gap while maintaining greater accuracy. The original hope behind using the brackets to constrain the XLE c-structure generation was that 5For example, in massive data</context>
</contexts>
<marker>Kaplan, Riezler, King, Maxwell, Vasserman, Crouch, 2004</marker>
<rawString>Ron Kaplan, Stefan Riezler, Tracy Holloway King, John T. Maxwell, Alexander Vasserman, and Richard Crouch. 2004. Speed and Accuracy in Shallow and Deep Stochastic Parsing. In Proceedings of HLTNAACL, pages 97–104, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy Holloway King</author>
<author>Richard Crouch</author>
<author>Stefan Riezler</author>
<author>Mary Dalrymple</author>
<author>Ron Kaplan</author>
</authors>
<title>The PARC 700 dependency bank.</title>
<date>2003</date>
<booktitle>In Proceedings ofLINC,</booktitle>
<pages>1--8</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="10029" citStr="King et al., 2003" startWordPosition="1557" endWordPosition="1560">periments We carried out a baseline experiment with two state-of-the-art parsers to establish what effect prebracketing the input to the XLE system has on the quality and number of the solutions produced. We used the Bikel () multi-threaded, head-driven chartparsing engine developed at the University of Pennsylvania. The second parser is that described in Charniak and Johnson (2005). This parser uses a discriminative reranker that selects the most probable parse from the 50-best parses returned by a generative parser based on Charniak (2000). We evaluated against the PARC 700 Dependency Bank (King et al., 2003) which provides goldstandard analyses for 700 sentences chosen at random from Section 23 of the Penn-II Treebank. The Dependency Bank was bootstrapped by parsing the 700 sentences with the XLE English grammar, and then manually correcting the output. The data is divided into two sets, a 140-sentence development set and a test set of 560 sentences (Kaplan et al., 2004). We took the raw strings from the 140-sentence development set and parsed them with each of the state-of-the-art probabilistic parsers. As an upper bound for the baseline experiment, we use the brackets in the original Penn-II tr</context>
</contexts>
<marker>King, Crouch, Riezler, Dalrymple, Kaplan, 2003</marker>
<rawString>Tracy Holloway King, Richard Crouch, Stefan Riezler, Mary Dalrymple, and Ron Kaplan. 2003. The PARC 700 dependency bank. In Proceedings ofLINC, pages 1–8, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Kinyon</author>
</authors>
<title>Hypertags.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>446--452</pages>
<contexts>
<context position="2875" citStr="Kinyon, 2000" startWordPosition="439" endWordPosition="440">one c-structure and f-structure pair is valid (see Figure 1). In this instance, the log-linear disambiguation does not need to choose the most probable result. The research question we pose is whether the search space can be pruned earlier before unification takes place. Bangalore and Joshi (1999), Clark and Curran (2004) and Matsuzaki et al. (2007) show that by using a super tagger before (CCG and HPSG) parsing, the space required for discriminitive training is drastically reduced. Supertagging is not widely used within the LFG framework, although there has been some work on using hypertags (Kinyon, 2000). Ninomiya et al. (2006) propose a method for faster HPSG parsing while maintaining accuracy by only using the probabilities of lexical entry selections (i.e. the supertags) in their discriminitive model. In the work presented here, we con1For example, is can be a copula, a progressive auxiliary or a passive auxiliary, while slower can either be an adjective or an adverb. 65 Proceedings of the ACL 2007 Workshop on Deep Linguistic Processing, pages 65–72, Prague, Czech Republic, June, 2007. c�2007 Association for Computational Linguistics centrate on reducing the number of c-structure trees tha</context>
</contexts>
<marker>Kinyon, 2000</marker>
<rawString>Alexandra Kinyon. 2000. Hypertags. In Proceedings of COLING, pages 446–452, Saarbr¨ucken.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takuya Matsuzaki</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Efficient HPSG Parsing with Supertagging and CFG-filtering.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>1671--1676</pages>
<contexts>
<context position="2613" citStr="Matsuzaki et al. (2007)" startWordPosition="394" endWordPosition="397">the most probable f-structure from the resulting valid f-structures. For example, the sentence “Growth is slower.” has 84 valid c-structure trees according to the current English grammar;1 however once the Unifier has processed all of these trees (in a packed form), only one c-structure and f-structure pair is valid (see Figure 1). In this instance, the log-linear disambiguation does not need to choose the most probable result. The research question we pose is whether the search space can be pruned earlier before unification takes place. Bangalore and Joshi (1999), Clark and Curran (2004) and Matsuzaki et al. (2007) show that by using a super tagger before (CCG and HPSG) parsing, the space required for discriminitive training is drastically reduced. Supertagging is not widely used within the LFG framework, although there has been some work on using hypertags (Kinyon, 2000). Ninomiya et al. (2006) propose a method for faster HPSG parsing while maintaining accuracy by only using the probabilities of lexical entry selections (i.e. the supertags) in their discriminitive model. In the work presented here, we con1For example, is can be a copula, a progressive auxiliary or a passive auxiliary, while slower can </context>
</contexts>
<marker>Matsuzaki, Miyao, Tsujii, 2007</marker>
<rawString>Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2007. Efficient HPSG Parsing with Supertagging and CFG-filtering. In Proceedings of IJCAI, pages 1671– 1676, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John T Maxwell</author>
<author>Ronald M Kaplan</author>
</authors>
<title>The interface between phrasal and functional constraints.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="7846" citStr="Maxwell and Kaplan, 1993" startWordPosition="1209" endWordPosition="1212">(. .))) Labeled: \[S1 \[S Growth \[VP is \[ADJP slower\] \].\] \] Unlabeled:\[ \[ Growth \[ is \[ slower\] \].\] \] Figure 2: Example of retained brackets from parser output to constrain the XLE parser 2.2 The XLE Parsing System The XLE parsing system is a deep-grammar-based parsing system. The experiments reported in this paper use the English LFG grammar constructed as part of the ParGram project (Butt et al., 2002). This system incorporates sophisticated ambiguitymanagement technology so that all possible syntactic analyses of a sentence are computed in an efficient, packed representation (Maxwell and Kaplan, 1993). In accordance with LFG theory, the output includes not only standard contextfree phrase-structure trees (c-structures) but also attribute-value matrices (f-structures) that explicitly encode predicate-argument relations and other meaningful properties. The f-structures can be deterministically mapped to dependency triples without any loss of information, using the built-in ordered rewrite system (Crouch et al., 2002). XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear probability model (Riezl</context>
</contexts>
<marker>Maxwell, Kaplan, 1993</marker>
<rawString>John T. Maxwell and Ronald M. Kaplan. 1993. The interface between phrasal and functional constraints. Computational Linguistics, 19(4):571–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takashi Ninomiya</author>
<author>Takuya Matsuzaki</author>
<author>Yoshimasa Tsuruoka</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Extremely Lexicalized Models for Accurate and Fast HPSG Parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>155--163</pages>
<contexts>
<context position="2899" citStr="Ninomiya et al. (2006)" startWordPosition="441" endWordPosition="444"> and f-structure pair is valid (see Figure 1). In this instance, the log-linear disambiguation does not need to choose the most probable result. The research question we pose is whether the search space can be pruned earlier before unification takes place. Bangalore and Joshi (1999), Clark and Curran (2004) and Matsuzaki et al. (2007) show that by using a super tagger before (CCG and HPSG) parsing, the space required for discriminitive training is drastically reduced. Supertagging is not widely used within the LFG framework, although there has been some work on using hypertags (Kinyon, 2000). Ninomiya et al. (2006) propose a method for faster HPSG parsing while maintaining accuracy by only using the probabilities of lexical entry selections (i.e. the supertags) in their discriminitive model. In the work presented here, we con1For example, is can be a copula, a progressive auxiliary or a passive auxiliary, while slower can either be an adjective or an adverb. 65 Proceedings of the ACL 2007 Workshop on Deep Linguistic Processing, pages 65–72, Prague, Czech Republic, June, 2007. c�2007 Association for Computational Linguistics centrate on reducing the number of c-structure trees that the Unifier has to pro</context>
</contexts>
<marker>Ninomiya, Matsuzaki, Tsuruoka, Miyao, Tsujii, 2006</marker>
<rawString>Takashi Ninomiya, Takuya Matsuzaki, Yoshimasa Tsuruoka, Yusuke Miyao, and Jun’ichi Tsujii. 2006. Extremely Lexicalized Models for Accurate and Fast HPSG Parsing. In Proceedings of EMNLP, pages 155–163, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric W Noreen</author>
</authors>
<title>Computer Intensive Methods for Testing Hypotheses: An Introduction.</title>
<date>1989</date>
<publisher>Wiley,</publisher>
<location>New York.</location>
<contexts>
<context position="13539" citStr="Noreen, 1989" startWordPosition="2140" endWordPosition="2141">t parse. When testing for statistical significance between systems, we compare the overall f-score values. Figures marked with an asterisk are not statistically significantly different at the 95% level.2 The results show that using unlabeled brackets achieves reasonable f-scores with the non-fragment grammar. Using the labeled bracketing from the output of both parsers causes XLE to always fail when parsing. This is because the labels in the output of parsers trained on the Penn-II treebank differ considerably from the labels on c-structure trees pro2We use the approximate randomization test (Noreen, 1989) to test for significance. duced by XLE. Interestingly, the f-scores for both the CJ-XLE and Bikel-XLE systems are very similar to the upper bounds. The gold standard upper bound is not as high as expected because the Penn trees used to produce the gold bracketed input are not always compatible with the XLE-style trees. As a simple example, the tree in Figure 1 differs from the parse tree for the same sentence in the Penn Treebank (Figure 3). The most obvious difference is the labels on the nodes. However, even in this small example, there are structural differences, e.g. the position of the p</context>
</contexts>
<marker>Noreen, 1989</marker>
<rawString>Eric W. Noreen. 1989. Computer Intensive Methods for Testing Hypotheses: An Introduction. Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A Maximum Entropy PartOf-Speech Tagger.</title>
<date>1996</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>133--142</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="19190" citStr="Ratnaparkhi, 1996" startWordPosition="3086" endWordPosition="3087">mber of bracketed sentences that can be parsed by XLE increases if the brackets are unlabeled. The table also shows that the XLE system performs much better than Bikel-XLE when using the fragment grammars. Although the Bikel-XLE system is quite a bit faster, there is a drop in f-score; however this is not statistically significant when the brackets are unlabeled. 5.2 Pre-tagging We performed some error analysis on the output of the Bikel-XLE system and noticed that a considerable number of errors were due to mis-tagging. So, we pre-tagged the input to the Bikel parser using the MXPOST tagger (Ratnaparkhi, 1996). The results for the non-fragment grammars are presented in Table 4. Pre-tagging with MXPOST, however, does not result in a statistically significantly higher result than parsing untagged input, although more sentences can be parsed by both systems. Pre-tagging also adds an extra time overhead cost. No pretags MXPOST tags XLE Bikel-XLE Bikel-XLE Unlabeled Total Parsing Time 964 380 493 # XLE Parses (/140) 119 89 92 F-Score of Subset 81.57 85.62 84.98 Overall F-Score 72.01 59.34 *61.11 Labeled Total Parsing Time 964 336 407 # XLE Parses (/140) 119 77 80 F-Score of Subset 81.57 86.11 85.87 Over</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A Maximum Entropy PartOf-Speech Tagger. In Proceedings of EMNLP, pages 133–142, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy King</author>
<author>Ronald Kaplan</author>
<author>Richard Crouch</author>
<author>John T Maxwell</author>
<author>Mark Johnson</author>
</authors>
<title>Parsing the Wall Street Journal using a LexicalFunctional Grammar and Discriminative Estimation Techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>271--278</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="4760" citStr="Riezler et al. (2002)" startWordPosition="744" endWordPosition="747">ntegrate a statistical component to the parser that could rank the c-structure trees and only pass the most likely forward to the unification process. However, this would require a large rewrite of the system. So, we first wanted to investigate a “cheaper” alternative to determine the viability of the pruning strategy; this is the experiment reported in this paper. This is implemented by stipulating constituent boundaries in the input string, so that any c-structure that is incompatible with these constraints is invalid and will not be processed by the Unifier. This was done to some extent in Riezler et al. (2002) to automatically generate training data for the log-linear disambiguation component of XLE. Previous work obtained the constituent constraints (i.e. brackets) from the gold-standard trees in the Penn-II Treebank. However, to parse novel text, gold-standard trees are unavailable. We used a state-of-the-art probabilistic parser to provide the bracketing constraints to XLE. These parsers are accurate (achieving accuracy of over 90% on Section 23 WSJ text), fast, and robust. The idea is that pre-parsing of the input text by a fast and accurate parser can prune the c-structure search space, reduci</context>
<context position="8462" citStr="Riezler et al., 2002" startWordPosition="1300" endWordPosition="1303">1993). In accordance with LFG theory, the output includes not only standard contextfree phrase-structure trees (c-structures) but also attribute-value matrices (f-structures) that explicitly encode predicate-argument relations and other meaningful properties. The f-structures can be deterministically mapped to dependency triples without any loss of information, using the built-in ordered rewrite system (Crouch et al., 2002). XLE selects the most probable analysis from the potentially large candidate set by means of a stochastic disambiguation component based on a log-linear probability model (Riezler et al., 2002) that works on the packed representations. The underlying parsing system also has built-in robustness mechanisms that allow it to parse strings that are outside the scope of the grammar as a list of fewest well-formed “fragments”. Furthermore, performance parameters that bound parsing and disambiguation can be tuned for efficient but accurate operation. These parameters include at which point to timeout and return an error, the amount of stack memory to allocate, the number of new edges to add to the chart and at which point to start skimming (a process that guarantees XLE will finish processi</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>Stefan Riezler, Tracy King, Ronald Kaplan, Richard Crouch, John T. Maxwell, and Mark Johnson. 2002. Parsing the Wall Street Journal using a LexicalFunctional Grammar and Discriminative Estimation Techniques. In Proceedings of ACL, pages 271–278, Philadelphia, PA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>