<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002029">
<title confidence="0.99537">
Multi-word Term Extraction for Bulgarian
</title>
<author confidence="0.994603">
Svetla Koeva
</author>
<affiliation confidence="0.964174">
Department of Computational Linguistics – IBL
Bulgarian Academy of Sciences
</affiliation>
<address confidence="0.957598">
52 Shipchenski prohod Blv. Sofia 1113, Bulgaria
</address>
<email confidence="0.999123">
svetla@ibl.bas.bg
</email>
<sectionHeader confidence="0.995641" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99998">
The goal of this paper is to compile a
method for multi-word term extraction,
taking into account both the linguistic
properties of Bulgarian terms and their
statistical rates. The method relies on the
extraction of term candidates matching
given syntactic patterns followed by statis-
tical (by means of Log-likelihood ratio)
and linguistically (by means of inflec-
tional clustering) based filtering aimed at
improving the coverage and the precision
of multi-word term extraction.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999991642857143">
The goal of this paper is to compile a method for
multi-word term extraction, taking into account
both the linguistic properties of Bulgarian terms
and their statistical rates. Term extraction exploits
well-established techniques that seem difficult to
improve significantly. As in many other areas of
computational linguistics, term extraction has been
approached generally with three different strategies
– linguistic techniques, statistical techniques and a
combination of both (Bourigault et al., 2001; Jac-
quemin &amp; Bourigault, 2000). The linguistically
based techniques exploit the morpho-syntactic
structure of terms that usually differ from one lan-
guage to another (for example in Bulgarian and in
English the most frequent syntactic structure repre-
senting terms is the noun phrase, but the two lan-
guages significantly differ in their constituent
structure and agreement properties). The automatic
extraction of term morpho-syntactic patterns, being
in most cases language-dependent, requires spe-
cific language processing – Part-of-speech (POS)
tagging, lemmatization, syntactic parsing, etc. The
statistical techniques, on the other hand, rely on the
different statistical features of terms compared to
other words in the text and are usually based on the
detection of words and expressions with a fre-
quency value higher than a given limit. Some of
the statistical approaches focus on the association
measures between the components of the multi-
word terms. Hybrid approaches, combining lin-
guistic and statistical techniques, are also applied,
mainly in two manners: statistical proceeding is
used to filter the term candidates obtained through
linguistic techniques, and, vice versa, some lin-
guistic filters are exploited after statistical process-
ing, in order to extract the statistically significant
word combinations that match some given syntac-
tic patterns.
The method for automatic multi-word term ex-
traction, presented in this paper, also relies both on
linguistic knowledge and on statistical processing.
The research aims are to:
</bodyText>
<listItem confidence="0.995859">
• Apply syntactic patterns of Bulgarian
terms directed to multi-word term extraction;
• Use well-known statistical methods (asso-
ciation measures) to eliminate some of the irrele-
vant multi-word terms;
• Further limit the number of invalid terms
by clustering term candidates around their lem-
mas;
• Test the performance of such a method
over the manually annotated corpus.
</listItem>
<page confidence="0.97261">
59
</page>
<subsubsectionHeader confidence="0.675945">
Balto-Slavonic Natural Language Processing 2007, June 29, 2007, pages 59–66,
</subsubsectionHeader>
<bodyText confidence="0.995575777777778">
Prague, June 2007. c�2007 Association for Computational Linguistics
Most of the current methods for automatic term
extraction are developed for English, and thus they
are not appropriate for direct adaptation to Bulgar-
ian, due to the morpho-syntactic differences be-
tween the two languages. Bulgarian is a language
with a rich inflectional system. That is to say, a
noun lemma can appear in six forms if it is mascu-
line and in four forms if it is feminine or neuter.
Besides, noun phrase structure and agreement
properties in Bulgarian differ in some aspects from
other languages such as English, Therefore, a lan-
guage-specific approach is needed if we want to
utilise the morpho-syntactical information for term
extraction. To the best of our knowledge there is
no report of an extensive work directed towards
Bulgarian term extraction.
The structure of our paper outlines the three
steps involved in our approach. In the following
section we present a short linguistic analysis of
Bulgarian terms. In the third section, we describe
the identification of the candidate terms. The
fourth section explains how we applied a list of
terms to the filters. We then evaluate our results on
a corpus that was set up by manual annotation. Fi-
nally, we discuss some peculiarities of the pre-
sented study and propose future works to be done.
</bodyText>
<subsectionHeader confidence="0.784991">
2 Linguistic analysis of Bulgarian terms
2.1. Compilation of a term annotated corpus
</subsectionHeader>
<bodyText confidence="0.999906555555556">
We share the views that larger corpora not only
give statistically more reliable counts, but also re-
veal phenomena that are completely lacking in
smaller samples. The Acquis Communautaire
(AC)1 – the European Union legislation, which
consists of approximately eight thousand docu-
ments containing approximately 40 million words
(to be more specific, its Bulgarian subpart) – is
targeted as the most appropriate resource for our
research: because of its size, and because of the
number of languages included in it. (The proposed
method can be further transformed and/or evalu-
ated to deal with the rest of the languages repre-
sented in the parallel corpus.)
The AC contains documents from several do-
mains, which are divided into chapters: Agricul-
ture, Fisheries, Transport Policy, Taxation,
Economic and Monetary Union, Statistics, Social
</bodyText>
<footnote confidence="0.83809">
1 There has been some experience of exploiting the AC as a
multilingual corpus (Steinberger at al., 2006).
</footnote>
<bodyText confidence="0.9944458">
Policy and Employment, Energy, Industrial Policy,
Education and Training, Telecommunication and
Information Technologies, Culture and Audio-
visual Policy, etc. This annotated subpart of the
Bulgarian AC is developed as a test corpus and
contains 10,521 words from randomly selected text
samples representing the domains of Agriculture
(AGR), Energy (ENR) and Education and Training
(EDC).
Some criteria for the manual annotation of Bul-
garian terms were defined, the notion of term
among others. As with most linguistic concepts, a
term is defined in various ways. For example, as “a
word or expression that has a precise meaning in
some uses or is peculiar to a science, art, profes-
sion” (Webster, 2002), or as “a word or expression
used for some particular thing”2, or generally as
words or phrases that denote specific concepts in a
given subject domain. For the purposes of this in-
vestigation we defined a term as
An open class word or expression that is peculiar
to a specific domain of human activities and occurs
with a determinate (in some limits) frequency in
that domain.
The annotation of terms in the Bulgarian AC
subpart is also based on both the maximum and
minimum length term selection. That is, in the case
of a multi-word term which constituents are also
terms, the longest term (as well as all shorter
terms) is selected. It should be pointed out, how-
ever, that the term annotated corpus is still small
enough to be representative of the word frequency
and is a sample of translated texts that might mani-
fest different tendencies for a term’s distribution
from those in the original texts.
</bodyText>
<subsectionHeader confidence="0.992254">
2.2. Single-word terms vs. multi-word terms
</subsectionHeader>
<bodyText confidence="0.996764">
The general impression is that the most of the pa-
pers dealing with automatic term extraction (espe-
cially the statistically based ones) are focused on
multi-word terms. This can be explained by the
fact that for English a bigger percentage of multi-
word terms comparing to single-word terms is re-
ported. To show the tendency for the correlation
between single-word and multi-word terms in Bul-
garian texts, the manually annotated subpart of the
Bulgarian AC has been studied. We found out (Ta-
ble 1.) that the proportion of single-word terms
</bodyText>
<footnote confidence="0.921791">
2 http://wordnet.princeton.edu
</footnote>
<page confidence="0.997441">
60
</page>
<bodyText confidence="0.999212375">
varies from about 2.5% to 3% depending on the
subject domain.
The results show that the use of single-word
terms in Bulgarian technical documents is also not
very frequent and the tendency is that multi-word
terms are preferred to single-word ones. Following
these observations, first we will concentrate on the
extraction of the Bulgarian multi-word terms.
</bodyText>
<table confidence="0.999439857142857">
Domain AGR ENR EDC Total
#Words 4423 3002 3096 10521
#Terms (T) 344 297 254 895
#Multi-word T 266 165 171 602
#Single-word T 111 89 93 293
% Terms 7,77 9,89 8,2 8,5
% Single-word T 2,5 2,96 3 2,78
</table>
<tableCaption confidence="0.999201">
Table 1. Distribution of single-word terms
</tableCaption>
<subsectionHeader confidence="0.988921">
2.3 Syntactic structures of Bulgarian terms
</subsectionHeader>
<bodyText confidence="0.995798441176471">
The starting point for the linguistically motivated
part of the automatic term extraction is to describe
the syntactic structure of Bulgarian terms. There
are several Bulgarian terminological dictionaries
published and some terminological databases
available on the internet – all recourses are taken
into consideration in the analysis without providing
exact calculations. The collection of Bulgarian
terms, obtained by the annotated subpart of the
Bulgarian AC, is used as a source for the determi-
nation of the most frequent syntactic structures of
Bulgarian terms.
It is claimed that NPs constitute about 80-99 %
of whole terms in an English text, with the varying
percentage depending on the text types (Arppe,
1995). The same statement is roughly true for Bul-
garian; although there are some adjectives and
verbs that can be regarded as terms in a certain
domain (only three verbs and one adjective are de-
tected in the annotated corpus). In this study we
have concentrated on the NPs’ term extraction,
which comprises the focus of interest in several
studies (Jacquemin, 2001; Justeson &amp; Katz, 1995;
Voutanen, 1993).
In order to obtain the statistics, the annotated part
of Bulgarian AC is pre-processing. This allows the
consequences of the categories constituting Bul-
garian terms to be extracted and their frequency to
be calculated. As a result, 16 different sequences of
categories are obtained, among them 5 with a rate
higher than 11 %. In the next examples the most
frequent syntactic patterns of the Bulgarian multi-
word terms are listed following their frequency
rate:
</bodyText>
<listItem confidence="0.929963666666667">
• AN —&gt; riboloven sezon (fishing season),
iglolistno darvo (conifer), zemedelski ceni (firm
prices), termalna energiya (thermal energy), kli-
matichna instalaciya (air-conditioning);
• NpN —&gt; obogatyavane na gorivo (fuel en-
richment), podobryavane na pochvata (soil im-
provement), prava na deteto (children&apos;s rights),
svoboda na pechata (freedom of the press);
• NpAN —&gt; opazvane na okolnata sreda
(environmental protection), nomenklatura na
zemedelskite produkti (agricultural product no-
menclature), izpolzvane na slanchevata energiya
(solar energy end-use applications), sredstva za
masova informaciya (media);
• AAN —&gt; semeyno zemedelsko stopanstwo
(family farming), evropeyska parichna sistema
(European Monetary System), inteligentna
transportna sistema (intelligent transport sys-
tem), magniten informacionen nositel (magnetic
medium);
• ANpN —&gt; elektronen transfer na fondove
(electronic funds transfer), optichesko raz-
poznavane na simvoli (Optical Character Recog-
nition), pravna uredba na telekomunikaciite
(regulation of telecommunications), izbiratelno
razprostranenie na informaciya (selective dis-
semination of information).
</listItem>
<bodyText confidence="0.999894529411765">
Among the five types, the AN structure was
the most frequent one, although the exact percent-
age still remains to be calculated over the bigger
corpus.
The main differences observed concerning these
five Bulgarian structures and their English equiva-
lents are the regular agreement between the adjec-
tival modifier and the head noun in Bulgarian and
the prepositional phrase in Bulgarian instead the
noun modifier in English. The adjective-noun
agreement in Bulgarian noun phrases is partially
exploited in the presented piece of work, but it
might be extensively considered in further im-
provements of the method.
In the case of NpN, NpAN and ANpN structures,
we found out that most of the terms corresponding
to these patterns are built up with the Bulgarian
</bodyText>
<page confidence="0.996645">
61
</page>
<bodyText confidence="0.999923285714286">
preposition na (of). This may be explained by the
fact that these PPs usually correspond to the Eng-
lish NPs with a noun modifier denoting more spe-
cific concepts. The possible strings of categories
that might constitute the Bulgarian terms are ex-
ploited due to the fact that Bulgarian terms usually
do not allow other constituents among their parts.
</bodyText>
<subsectionHeader confidence="0.97955">
2.4 Term variations
</subsectionHeader>
<bodyText confidence="0.977956897959184">
Some authors have pointed out the discrepancy
between term representation in dictionaries, and
the term forms used in real texts (Daille, 2003). It
is well known that the same concept can be formu-
lated in different ways and the automatic term ex-
traction should be able to recognize and link those
different linguistic forms or expressions. Different
kinds of term variants are distinguished in the lit-
erature: orthographic variants (capitalization), in-
flectional variants (word forms), morpho-syntactic
variants (derivation), syntactic variants (word or-
der differences) and semantic variants (syno-
nyms).
In this study only the orthographic and inflec-
tional variants are taken into consideration. It
should be pointed out that compared to lemmas
the multi-word terms have their own inflective
rules. The POS of the head word determines the
clustering of the term into grammatical classes,
such as noun, adjective, and so on, which define
the possible slots in the paradigm.
The significant grammatical categories inherent
to the lemma of the head word (such as gender for
nouns), the number and POS of the remaining
constituents and the options for inserting some
words (such as particles) in the multi-word term
structure all show the grouping of multi-word
terms’ grammatical subclasses and define which
slots of the paradigm are realized in the language.
And finally, the formation of word forms of each
component of a multi-word term and the type of
agreement dependencies between components
show the classification of multi-word terms into
grammatical types that describe the real word
paradigm belonging to a particular term (Koeva,
2005).
For instance, the Bulgarian term klimatichna in-
stalaciya (air-conditioning) is a noun phrase; the
members of the paradigm are determined by the
head feminine noun. The inflection type is deter-
mined by the inflectional alternations of each
member (the adjective and the noun):
klimatichna instalaciya – singular, indefinite
klimatichnata instalaciya – singular, definite
klimatichni instalaciii – plural, indefinite
klimatichnite instalaciii – plural, definite
There are agreement dependencies between
adjective and head noun and no other words’ in-
tervention or word order changes are allowed.
</bodyText>
<sectionHeader confidence="0.996029" genericHeader="method">
3 Automatic term extraction
</sectionHeader>
<subsectionHeader confidence="0.999969">
3.1 Pre-processing of the Bulgarian AC
</subsectionHeader>
<bodyText confidence="0.999993973684211">
It is common practice to extract candidate terms
using a part-of-speech (POS) tagger and an
automaton (a program extracting word sequences
corresponding to predefined POS patterns). The
part-of-speech tagging is the process of automati-
cally identifying the words in a text as correspond-
ing to a particular part of speech. The part-of-
speech tagger used in this study is developed utiliz-
ing a large manually annotated corpus consisting
of 197,000 tokens (150,000 words) randomly ex-
tracted from the Bulgarian Brawn corpus
(1,000,000 words) (Koeva et al., 2006). The tagger
has been developed as a modified version of the
Brill tagger (Brill, 1994). The Brill tagger was
trained for Bulgarian using a part of the tagged
corpus. We applied a rule-based approach leading
to 98.3% precision. A sophisticated tokenizer that
recognizes sentence boundaries and categorizes
tokens as words, abbreviations, punctuation, nu-
merical expressions, hours, dates and URLs has
been built as a part of the tagger. For each word in
the text the initial (most probable) part of speech
among the ambiguity set is assigned from a large
inflectional dictionary (Koeva, 1998).
The words that are not recognized by the dic-
tionary are handled by the guesser analyzing the
suffixes of the unrecognized words and assigning
the initial part of speech among the ambiguity set.
The part-of-speech ambiguity ratio calculated over
the annotated corpus is 1.51 tags per word, which
means that on average every second word is am-
biguous. For solving the ambiguity, 144 contextual
rules are implemented, utilizing the part of speech
and dictionary information on the context, Some
additional techniques for the optimizations are im-
plemented – the application of dictionaries of ab-
breviations, proper nouns, grammatically unambi-
guous words, etc. After POS tagging the text re-
</bodyText>
<page confidence="0.998263">
62
</page>
<bodyText confidence="0.999903611111111">
mains unchanged and the additional information is
added in an xml format.
Lemmatization is the process of automatic de-
termining the lemma for a given word. Since the
lemmatization involves fixing the part of speech of
a word, it requires the running of a tagger. Lemma-
tization is closely related to stemming. The differ-
ence is that a stemmer operates on a single word
without explicit knowledge of its identity as a part
of speech, its lemma or its inflectional properties.
For Bulgarian a large inflectional dictionary is
used both for lemmatization and stemming.
The tag sets differ both in how the words are di-
vided into categories, and in how their categories
are defined. For the purposes of this investigation
the grammatical information characterizing the
forms is also assigned to nouns and adjectives, be-
cause the adjective-noun agreement is exploited.
</bodyText>
<subsectionHeader confidence="0.999832">
3.2 Extraction of term candidates
</subsectionHeader>
<bodyText confidence="0.989877190476191">
Following the frequency analysis of the constituent
structure of the Bulgarian multi-word terms, the
targeted syntactic patterns will be recognized by
the following regular expression:
[(A+N(pA*N)?)(NpA*N)]
The strings of categories bellow will be matched;
those with more than two adjectives are either rare,
or not observed in the language:
AN, AAN, NpN, NpAN, ANpN, ANpAN,
NpAAN, ANpAAN, AANpAAN, ...
The regular expression does not match the single
Ns as well as the NPs with low frequently – only
the five syntactic patterns with the highest fre-
quency rate are targeted for the term extraction.
Moreover, the agreement features of the Bulgarian
NP structures are exploited considering the unifica-
tion of grammatical features between the preceding
adjective and the immediate following adjective or
noun. Based on patterns’ matching, the term can-
didates corresponding to the above regular expres-
sions are extracted:
</bodyText>
<listItem confidence="0.921580416666667">
• AN —&gt; osnovno obrazovanie (basic educa-
tion),
• AAN —&gt; novi obrazovatelni metodi (new
educational methods), evropeyska audiovi-
zualna zona (European audiovisual area),
• NpN —&gt; ezik za programirane
(programming language),
• NpAN —&gt; planirane na uchebnata godina
(planning of the school year), elekronna
obrabotka na danni (electronic data
processing), potrebitel na ingormacionna
tehnologiya (information technology user), etc.
</listItem>
<bodyText confidence="0.737937">
On the other hand, the following phrases (which
are annotated as terms) are not recognized:
</bodyText>
<listItem confidence="0.999953333333333">
• NpVpN —&gt; aparat za vazproizwodstvo na
zvuk (sound reproduction equipment),
• AcAN —&gt; poshtenski i telekomunikacionni
uslugi (postal and telecommunications ser-
vices),
• NpNpNN —&gt; sistema za upravlenie na
</listItem>
<bodyText confidence="0.99938">
baza danni (database management system), etc.
A deficiency of the approach based on the syntac-
tic patterns is also the fact that any NP that
matches the patterns will be selected as a term
candidate, as is shown in the following examples:
</bodyText>
<listItem confidence="0.8685694">
• AN —&gt; novi metodi (new methods),
ogranicheno dvizhenie (limited circulation),
• NpN —&gt; analiz na informaciya (informa-
tion analysis), broy na uchenicite (number of
pupils), etc.
</listItem>
<bodyText confidence="0.999409571428571">
Some of the noun phrases are wrongly extracted,
although in this case this is concerned with a com-
positional building of structures that cannot be
considered as that of multi-word terms. Some term
candidates with a preposition cannot be treated
even as phrases, because their parts belong to dif-
ferent sentence constituents. The identification of
the sub-phrases that are themselves also terms
should also be taken into account. In the following
example, sistema za upravlenie na baza ot danni
(database management system), the phrases sis-
tema za uprawlenie (management system), uprav-
lenie na baza ot danni (database management) and
baza ot danni (database) are also terms.
</bodyText>
<table confidence="0.988229333333333">
Domain AGR ENG EDC Total
#Words 4,423 3,002 3,096 10,521
#Term candidates 901 778 712 2,391
</table>
<tableCaption confidence="0.999286">
Table 2. Number of term candidates
</tableCaption>
<bodyText confidence="0.993872">
The number of extracted term candidates de-
pends on the structure of the sentences that occur
in the selected domains. Table 2 shows the ex-
tracted term candidates from a Bulgarian AC sub-
</bodyText>
<page confidence="0.998654">
63
</page>
<bodyText confidence="0.898818">
part representing texts from the Agriculture, En-
ergy and Education domains.
</bodyText>
<sectionHeader confidence="0.551889" genericHeader="method">
4 Filtering of term candidates
</sectionHeader>
<bodyText confidence="0.9999326">
As a filtering mechanism we adopted the calculat-
ing of the associativity between words, which is
often used to identify word collocations, and the
term clustering according to the inflexional para-
digms.
</bodyText>
<subsectionHeader confidence="0.999395">
4.1 Statistical filtering
</subsectionHeader>
<bodyText confidence="0.9995621875">
The frequency-based techniques applied to term
filtering assign a numerical value to sets of words
to rank term candidates and exclude those term
candidates below a certain threshold. The state-
ment that the more frequently a lexical unit appears
in a given document the more likely it is that this
unit has a terminological function can be applied to
certain genres of texts. Alone, frequency is not a
robust metric for assessing the terminological
property of a candidate.
In our case, we want to measure the cohesion of
a multi-word candidate term by verifying if its
words occur together as a coincidence or not. As-
sociation measures are often used to rate the corre-
lation of word pairs (Daille, 1995; Daille et al.,
1998).
</bodyText>
<table confidence="0.99123925">
B !B
A Nii Nij N1p
!A Nji Njj N2p
Np1 Np2 Npp
</table>
<tableCaption confidence="0.999353">
Table 3. The contingency table
</tableCaption>
<bodyText confidence="0.996290333333333">
These measures can be derived from the contin-
gency table (Table 3.) of the word pair (A,B) con-
taining the observed frequencies of (A,B), as fol-
lows:
Nii = the joint frequency of word A and word B;
Nij = the frequency word A occurs and word B
does not;
Nji = the frequency word B occurs and word A
does not;
Njj = the frequency word A and word B do not oc-
cur;
Npp = the total number of ngrams;
Np1, Np2, N1p, N2p are the marginal counts.
The lexical association measures are formulas
that relate the observed frequencies to the expected
frequency (Mij = (Np1 * N1p) / Npp) under the
assumption that A and B are independent. For the
current work, the Log-likelihood coefficient has
been employed (Dunning, 1993), as it is reported
to perform well among other scoring methods
(Daille, 1995).
</bodyText>
<equation confidence="0.950705">
Log-likelihood = 2 * ∑ ( Nij * log( Nij / Mij) )
</equation>
<bodyText confidence="0.999949333333333">
This calculation over the text serves as an impor-
tant technique in identifying term candidates. The
larger the value of Log-likelihood is, the stronger
is the association between the two pairs of the
string; consequently the string is the most probable
candidate. Statistic filtering is applied only to those
term candidates extracted by the linguistic compo-
nent. For the calculation, the Ngram Statistics
Package (NSP), programs that aids in analyzing
ngrams, is executed (Banerjee &amp; Pedersen, 2003).
The NSP takes text files (in our case Cyrillic letters
are transliterated into Latin) as input and generates
a list of bigrams along with their frequencies as
outputs. Over the list of bigrams obtained, the Log-
likelihood is run to compute a ratio for each ngram.
The bigrams are targeted because some of the term
candidates initially extracted are long ones contain-
ing sub-phrases that are likely to function as term
candidates. In order to avoid potential term candi-
dates being included in other longer phrases, the
term candidates are split and the constituting bi-
grams are generated.
As a result of statistical filtering, the initially se-
lected term candidates are assigned different values
according to their word association. The Log-
likelihood coefficient computed for each bigram is
used to decide whether or not there is enough evi-
dence to reject or accept a bigram - there is a clear
opposition between small and big values. Below
the first five ranked candidates are listed.
</bodyText>
<listItem confidence="0.9806256">
1. evropeyskata obshtnost (European community)
2. atomna energiya (nuclear energy)
3. detska gradina (kindergarten)
4. Darzhaven vestnik (government newspaper)
5. obrazovatelna sistema (educational system)
</listItem>
<subsectionHeader confidence="0.984055">
4.2 Linguistic filtering
</subsectionHeader>
<bodyText confidence="0.999891333333333">
The linguistic filtering aims at linking the different
variations of the same basic term. The list of the
automatically extracted terms was reviewed by
</bodyText>
<page confidence="0.997932">
64
</page>
<bodyText confidence="0.999926125">
means of lemmatization in order to refine it and to
increase the score of some terms. Until this stage
the different word forms of a term were calculated
separately. Bulgarian is a highly inflected language
– the forms of the head noun can vary from one to
seven depending of the gender, number and refer-
ences to a person. The sequences of lemmas be-
longing to the term candidates are processed and
the frequency values are recalculated according to
the grouping of terms in one inflectional cluster
with respect to the common canonical form.
Through this technique morphologically-related
occurrences, such as iglolistno darvo (a conifer),
iglolistnoto darvo (the conifer), iglolistni darveta
(conifers) and iglolistnite darveta (the conifers) are
treated as one term.
</bodyText>
<sectionHeader confidence="0.999371" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.99998025">
The presented method of identifying Bulgarian
multi-word terms was applied on the manually an-
notated corpus. First the texts were pre-processed
by means of POS tagging and lemmatization, then
the target syntactic patterns were extracted, and the
rates of the related bigrams were calculated by
means of Log-likelihood association, and finally
additional reordering of term candidates was per-
formed by means of inflectional clustering. As a
result, 430 (from 539) correctly extracted multi-
word terms are obtained – the precision of 79.96%
is registered.
</bodyText>
<sectionHeader confidence="0.996461" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999991454545455">
We have presented a method aimed at extracting
Bulgarian multi-word terms, which relies on the
extraction of syntactic patterns from text and on
the statistical and linguistically based filtering
aimed at improving the coverage and the precision
of multi-word collocation extraction. We have ap-
plied Log-likelihood ratio statistical filtering to the
extracted multi-word terms. All extracted term
candidates are grammatically correct, due to the
syntactically based pattern matching. Further de-
velopments of the method include:
</bodyText>
<listItem confidence="0.994543166666667">
• Statistical determination of single-word
terms;
• Coverage of long-distance occurrence and
rare syntactic structures of multi-word terms;
• Analyzing the embedded terms.
• Using &apos;stop lists&apos; of open and closed class
</listItem>
<bodyText confidence="0.954248333333333">
words that are hardly to be found in the multi-
word terms.
Some other experiments will be made using
other well-known techniques of association meas-
ure. For the evaluation purposes the test corpus
will be extended. A bigger homogeneous corpus
would undoubtedly result in an increase in terms
with more representative frequencies, and, there-
fore, in an improvement in statistical estimation of
terms. The results can be exploited in the multilin-
gual term extraction, due to the fact that the AC
represents the biggest multilingual parallel corpus.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999682133333333">
A. Aprre 1995. Term Extraction from Unrestricted Text:
10th Nordic Conference of Computational Linguistics
(NoDaLiDa), Helsinki.
S. Banerjee and T. Pedersen 2003. The Design, Imple-
mentation, and Use of the Ngram Statistics Package,
Proceedings of the Fourth International Conference
on Intelligent Text Processing and Computational
Linguistics, Mexico City.
D. Bourigault, C. Jacquemin, and M.-C. L&apos;Homme
2001. Recent Advances in Computational Terminol-
ogy, volume 2 of Natural Language Processing, John
Benjamins.
E. Brill 1994. Some Advances In Rule-Based Part of
Speech Tagging AAAI, Seattle, Washington
B. Daille 1995. Combined approach for terminology
extraction: lexical statistics and linguistic filtering.
Technical paper. UCREL, Lancaster University.
B. Daille 2003. Conceptual structuring through term
variations, Proceedings of the ACL Workshop on Mul-
tiword Expressions: Analysis, Acquisition and Treat-
ment.
B. Daille, E. Gaussier, and J.-M. Lange 1998. An
Evaluation of Statistical Scores for Word Association,
in J. Ginzburg, Z. Khasidashvili, C. Vogel, J.-J. Levy,
and E. Vallduvi (eds), The Tbilisi Symposium on
Logic, Language and Computation: Selected Papers,
CSLI Publications, p. 177-188.
T. Dunning 1993. Accurate methods for thestatistics of
surprise and coincidence,. Computational Linguistics,
19(1):61–74.
</reference>
<page confidence="0.990353">
65
</page>
<reference confidence="0.999751064516129">
C. Jacquemin 2001. Spotting and Discovering Terms
through Natural Language Processing. MIT Press.
C. Jacquemin and D. Bouricault 2000. Chapter 19 Term
Extraction and Automatic Indexing, Handbook of
Computational Linguistics (R. Mitkov (ed.)), Oxford
University Press, Oxford.
J. S. Justeson and S. M. Katz 1995. Technical Termi-
nology: Some Linguistic Properties and an Algorithm
for Identification in Text, Natural Language Engi-
neering. 1(1):9-27.
S. Koeva 1998. Bulgarian Grammatical dictionary. Or-
ganization of the language data, Bulgarian language,
vol. 6: 49-58.
S. Koeva 2005. Inflection Morphology of Bulgarian
Multiword Expressions, Computer Applications in
Slavic Studies – Proceedings of Azbuki@net, Interna-
tional Conference and Workshop, Sofia, 201-216.
S. Koeva, S. Leseva, I. Stoyanova, E. Tarpomanova,
and M. Todorova 2006. Bulgarian Tagged Corpora,
Proceedings of the Fifth International Conference
Formal Approaches to South Slavic and Balkan Lan-
guages, Sofia, 78-86.
R. Steinberger, B. Pouliquen, A. Widiger, C. Ignat, T.
Erjavec, D. Tufiş, and D. Varga 2006. The JRC-
Acquis: A multilingual aligned parallel corpus with
20+ languages, Proceedings of the 5th International
Conference on Language Resources and Evaluation
(LREC&apos;2006), Genoa.
A. Voutilainen. 1993. NPtool. A detector of English
noun phrases, Proceedings of the Workshop on Very
Large Corpora, Columbus, Ohio.
</reference>
<page confidence="0.988982">
66
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.484816">
<title confidence="0.998895">Multi-word Term Extraction for Bulgarian</title>
<author confidence="0.952536">Svetla</author>
<affiliation confidence="0.758108">Department of Computational Linguistics – Bulgarian Academy of</affiliation>
<address confidence="0.970791">52 Shipchenski prohod Blv. Sofia 1113, Bulgaria</address>
<email confidence="0.988648">svetla@ibl.bas.bg</email>
<abstract confidence="0.998932153846154">The goal of this paper is to compile a method for multi-word term extraction, taking into account both the linguistic properties of Bulgarian terms and their statistical rates. The method relies on the extraction of term candidates matching given syntactic patterns followed by statistical (by means of Log-likelihood ratio) and linguistically (by means of inflectional clustering) based filtering aimed at improving the coverage and the precision of multi-word term extraction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Aprre</author>
</authors>
<title>Term Extraction from Unrestricted Text:</title>
<date>1995</date>
<booktitle>10th Nordic Conference of Computational Linguistics (NoDaLiDa),</booktitle>
<location>Helsinki.</location>
<marker>Aprre, 1995</marker>
<rawString>A. Aprre 1995. Term Extraction from Unrestricted Text: 10th Nordic Conference of Computational Linguistics (NoDaLiDa), Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Banerjee</author>
<author>T Pedersen</author>
</authors>
<title>The Design, Implementation, and Use of the Ngram Statistics Package,</title>
<date>2003</date>
<booktitle>Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<location>Mexico City.</location>
<contexts>
<context position="22825" citStr="Banerjee &amp; Pedersen, 2003" startWordPosition="3586" endWordPosition="3589">s it is reported to perform well among other scoring methods (Daille, 1995). Log-likelihood = 2 * ∑ ( Nij * log( Nij / Mij) ) This calculation over the text serves as an important technique in identifying term candidates. The larger the value of Log-likelihood is, the stronger is the association between the two pairs of the string; consequently the string is the most probable candidate. Statistic filtering is applied only to those term candidates extracted by the linguistic component. For the calculation, the Ngram Statistics Package (NSP), programs that aids in analyzing ngrams, is executed (Banerjee &amp; Pedersen, 2003). The NSP takes text files (in our case Cyrillic letters are transliterated into Latin) as input and generates a list of bigrams along with their frequencies as outputs. Over the list of bigrams obtained, the Loglikelihood is run to compute a ratio for each ngram. The bigrams are targeted because some of the term candidates initially extracted are long ones containing sub-phrases that are likely to function as term candidates. In order to avoid potential term candidates being included in other longer phrases, the term candidates are split and the constituting bigrams are generated. As a result</context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>S. Banerjee and T. Pedersen 2003. The Design, Implementation, and Use of the Ngram Statistics Package, Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics, Mexico City.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bourigault</author>
<author>C Jacquemin</author>
<author>M-C L&apos;Homme</author>
</authors>
<date>2001</date>
<booktitle>Recent Advances in Computational Terminology,</booktitle>
<volume>2</volume>
<location>John Benjamins.</location>
<contexts>
<context position="1204" citStr="Bourigault et al., 2001" startWordPosition="167" endWordPosition="170">ring) based filtering aimed at improving the coverage and the precision of multi-word term extraction. 1 Introduction The goal of this paper is to compile a method for multi-word term extraction, taking into account both the linguistic properties of Bulgarian terms and their statistical rates. Term extraction exploits well-established techniques that seem difficult to improve significantly. As in many other areas of computational linguistics, term extraction has been approached generally with three different strategies – linguistic techniques, statistical techniques and a combination of both (Bourigault et al., 2001; Jacquemin &amp; Bourigault, 2000). The linguistically based techniques exploit the morpho-syntactic structure of terms that usually differ from one language to another (for example in Bulgarian and in English the most frequent syntactic structure representing terms is the noun phrase, but the two languages significantly differ in their constituent structure and agreement properties). The automatic extraction of term morpho-syntactic patterns, being in most cases language-dependent, requires specific language processing – Part-of-speech (POS) tagging, lemmatization, syntactic parsing, etc. The st</context>
</contexts>
<marker>Bourigault, Jacquemin, L&apos;Homme, 2001</marker>
<rawString>D. Bourigault, C. Jacquemin, and M.-C. L&apos;Homme 2001. Recent Advances in Computational Terminology, volume 2 of Natural Language Processing, John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Some Advances In Rule-Based Part of Speech Tagging AAAI,</title>
<date>1994</date>
<tech>Technical paper. UCREL,</tech>
<institution>Lancaster University.</institution>
<location>Seattle, Washington</location>
<contexts>
<context position="15206" citStr="Brill, 1994" startWordPosition="2350" endWordPosition="2351"> candidate terms using a part-of-speech (POS) tagger and an automaton (a program extracting word sequences corresponding to predefined POS patterns). The part-of-speech tagging is the process of automatically identifying the words in a text as corresponding to a particular part of speech. The part-ofspeech tagger used in this study is developed utilizing a large manually annotated corpus consisting of 197,000 tokens (150,000 words) randomly extracted from the Bulgarian Brawn corpus (1,000,000 words) (Koeva et al., 2006). The tagger has been developed as a modified version of the Brill tagger (Brill, 1994). The Brill tagger was trained for Bulgarian using a part of the tagged corpus. We applied a rule-based approach leading to 98.3% precision. A sophisticated tokenizer that recognizes sentence boundaries and categorizes tokens as words, abbreviations, punctuation, numerical expressions, hours, dates and URLs has been built as a part of the tagger. For each word in the text the initial (most probable) part of speech among the ambiguity set is assigned from a large inflectional dictionary (Koeva, 1998). The words that are not recognized by the dictionary are handled by the guesser analyzing the s</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>E. Brill 1994. Some Advances In Rule-Based Part of Speech Tagging AAAI, Seattle, Washington B. Daille 1995. Combined approach for terminology extraction: lexical statistics and linguistic filtering. Technical paper. UCREL, Lancaster University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
</authors>
<title>Conceptual structuring through term variations,</title>
<date>2003</date>
<booktitle>Proceedings of the ACL Workshop on Multiword Expressions: Analysis, Acquisition and Treatment.</booktitle>
<contexts>
<context position="12400" citStr="Daille, 2003" startWordPosition="1921" endWordPosition="1922"> found out that most of the terms corresponding to these patterns are built up with the Bulgarian 61 preposition na (of). This may be explained by the fact that these PPs usually correspond to the English NPs with a noun modifier denoting more specific concepts. The possible strings of categories that might constitute the Bulgarian terms are exploited due to the fact that Bulgarian terms usually do not allow other constituents among their parts. 2.4 Term variations Some authors have pointed out the discrepancy between term representation in dictionaries, and the term forms used in real texts (Daille, 2003). It is well known that the same concept can be formulated in different ways and the automatic term extraction should be able to recognize and link those different linguistic forms or expressions. Different kinds of term variants are distinguished in the literature: orthographic variants (capitalization), inflectional variants (word forms), morpho-syntactic variants (derivation), syntactic variants (word order differences) and semantic variants (synonyms). In this study only the orthographic and inflectional variants are taken into consideration. It should be pointed out that compared to lemma</context>
</contexts>
<marker>Daille, 2003</marker>
<rawString>B. Daille 2003. Conceptual structuring through term variations, Proceedings of the ACL Workshop on Multiword Expressions: Analysis, Acquisition and Treatment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
<author>E Gaussier</author>
<author>J-M Lange</author>
</authors>
<title>An Evaluation of Statistical Scores for Word Association,</title>
<date>1998</date>
<pages>177--188</pages>
<publisher>CSLI Publications,</publisher>
<location>in</location>
<contexts>
<context position="21408" citStr="Daille et al., 1998" startWordPosition="3332" endWordPosition="3335">k term candidates and exclude those term candidates below a certain threshold. The statement that the more frequently a lexical unit appears in a given document the more likely it is that this unit has a terminological function can be applied to certain genres of texts. Alone, frequency is not a robust metric for assessing the terminological property of a candidate. In our case, we want to measure the cohesion of a multi-word candidate term by verifying if its words occur together as a coincidence or not. Association measures are often used to rate the correlation of word pairs (Daille, 1995; Daille et al., 1998). B !B A Nii Nij N1p !A Nji Njj N2p Np1 Np2 Npp Table 3. The contingency table These measures can be derived from the contingency table (Table 3.) of the word pair (A,B) containing the observed frequencies of (A,B), as follows: Nii = the joint frequency of word A and word B; Nij = the frequency word A occurs and word B does not; Nji = the frequency word B occurs and word A does not; Njj = the frequency word A and word B do not occur; Npp = the total number of ngrams; Np1, Np2, N1p, N2p are the marginal counts. The lexical association measures are formulas that relate the observed frequencies t</context>
</contexts>
<marker>Daille, Gaussier, Lange, 1998</marker>
<rawString>B. Daille, E. Gaussier, and J.-M. Lange 1998. An Evaluation of Statistical Scores for Word Association, in J. Ginzburg, Z. Khasidashvili, C. Vogel, J.-J. Levy, and E. Vallduvi (eds), The Tbilisi Symposium on Logic, Language and Computation: Selected Papers, CSLI Publications, p. 177-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for thestatistics of surprise and coincidence,.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="22196" citStr="Dunning, 1993" startWordPosition="3485" endWordPosition="3486">aining the observed frequencies of (A,B), as follows: Nii = the joint frequency of word A and word B; Nij = the frequency word A occurs and word B does not; Nji = the frequency word B occurs and word A does not; Njj = the frequency word A and word B do not occur; Npp = the total number of ngrams; Np1, Np2, N1p, N2p are the marginal counts. The lexical association measures are formulas that relate the observed frequencies to the expected frequency (Mij = (Np1 * N1p) / Npp) under the assumption that A and B are independent. For the current work, the Log-likelihood coefficient has been employed (Dunning, 1993), as it is reported to perform well among other scoring methods (Daille, 1995). Log-likelihood = 2 * ∑ ( Nij * log( Nij / Mij) ) This calculation over the text serves as an important technique in identifying term candidates. The larger the value of Log-likelihood is, the stronger is the association between the two pairs of the string; consequently the string is the most probable candidate. Statistic filtering is applied only to those term candidates extracted by the linguistic component. For the calculation, the Ngram Statistics Package (NSP), programs that aids in analyzing ngrams, is execute</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>T. Dunning 1993. Accurate methods for thestatistics of surprise and coincidence,. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
</authors>
<title>Spotting and Discovering Terms through Natural Language Processing.</title>
<date>2001</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="9495" citStr="Jacquemin, 2001" startWordPosition="1492" endWordPosition="1493">is used as a source for the determination of the most frequent syntactic structures of Bulgarian terms. It is claimed that NPs constitute about 80-99 % of whole terms in an English text, with the varying percentage depending on the text types (Arppe, 1995). The same statement is roughly true for Bulgarian; although there are some adjectives and verbs that can be regarded as terms in a certain domain (only three verbs and one adjective are detected in the annotated corpus). In this study we have concentrated on the NPs’ term extraction, which comprises the focus of interest in several studies (Jacquemin, 2001; Justeson &amp; Katz, 1995; Voutanen, 1993). In order to obtain the statistics, the annotated part of Bulgarian AC is pre-processing. This allows the consequences of the categories constituting Bulgarian terms to be extracted and their frequency to be calculated. As a result, 16 different sequences of categories are obtained, among them 5 with a rate higher than 11 %. In the next examples the most frequent syntactic patterns of the Bulgarian multiword terms are listed following their frequency rate: • AN —&gt; riboloven sezon (fishing season), iglolistno darvo (conifer), zemedelski ceni (firm prices</context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>C. Jacquemin 2001. Spotting and Discovering Terms through Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
<author>D Bouricault</author>
</authors>
<date>2000</date>
<booktitle>Chapter 19 Term Extraction and Automatic Indexing, Handbook of Computational Linguistics</booktitle>
<editor>R. Mitkov (ed.)),</editor>
<publisher>University Press,</publisher>
<location>Oxford</location>
<marker>Jacquemin, Bouricault, 2000</marker>
<rawString>C. Jacquemin and D. Bouricault 2000. Chapter 19 Term Extraction and Automatic Indexing, Handbook of Computational Linguistics (R. Mitkov (ed.)), Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Justeson</author>
<author>S M Katz</author>
</authors>
<title>Technical Terminology: Some Linguistic Properties and an Algorithm for Identification in Text,</title>
<date>1995</date>
<journal>Natural Language Engineering.</journal>
<pages>1--1</pages>
<contexts>
<context position="9518" citStr="Justeson &amp; Katz, 1995" startWordPosition="1494" endWordPosition="1497">ce for the determination of the most frequent syntactic structures of Bulgarian terms. It is claimed that NPs constitute about 80-99 % of whole terms in an English text, with the varying percentage depending on the text types (Arppe, 1995). The same statement is roughly true for Bulgarian; although there are some adjectives and verbs that can be regarded as terms in a certain domain (only three verbs and one adjective are detected in the annotated corpus). In this study we have concentrated on the NPs’ term extraction, which comprises the focus of interest in several studies (Jacquemin, 2001; Justeson &amp; Katz, 1995; Voutanen, 1993). In order to obtain the statistics, the annotated part of Bulgarian AC is pre-processing. This allows the consequences of the categories constituting Bulgarian terms to be extracted and their frequency to be calculated. As a result, 16 different sequences of categories are obtained, among them 5 with a rate higher than 11 %. In the next examples the most frequent syntactic patterns of the Bulgarian multiword terms are listed following their frequency rate: • AN —&gt; riboloven sezon (fishing season), iglolistno darvo (conifer), zemedelski ceni (firm prices), termalna energiya (t</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>J. S. Justeson and S. M. Katz 1995. Technical Terminology: Some Linguistic Properties and an Algorithm for Identification in Text, Natural Language Engineering. 1(1):9-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Koeva</author>
</authors>
<title>Bulgarian Grammatical dictionary. Organization of the language data,</title>
<date>1998</date>
<journal>Bulgarian language,</journal>
<volume>6</volume>
<pages>49--58</pages>
<contexts>
<context position="15710" citStr="Koeva, 1998" startWordPosition="2429" endWordPosition="2430"> (Koeva et al., 2006). The tagger has been developed as a modified version of the Brill tagger (Brill, 1994). The Brill tagger was trained for Bulgarian using a part of the tagged corpus. We applied a rule-based approach leading to 98.3% precision. A sophisticated tokenizer that recognizes sentence boundaries and categorizes tokens as words, abbreviations, punctuation, numerical expressions, hours, dates and URLs has been built as a part of the tagger. For each word in the text the initial (most probable) part of speech among the ambiguity set is assigned from a large inflectional dictionary (Koeva, 1998). The words that are not recognized by the dictionary are handled by the guesser analyzing the suffixes of the unrecognized words and assigning the initial part of speech among the ambiguity set. The part-of-speech ambiguity ratio calculated over the annotated corpus is 1.51 tags per word, which means that on average every second word is ambiguous. For solving the ambiguity, 144 contextual rules are implemented, utilizing the part of speech and dictionary information on the context, Some additional techniques for the optimizations are implemented – the application of dictionaries of abbreviati</context>
</contexts>
<marker>Koeva, 1998</marker>
<rawString>S. Koeva 1998. Bulgarian Grammatical dictionary. Organization of the language data, Bulgarian language, vol. 6: 49-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Koeva</author>
</authors>
<title>Inflection Morphology of Bulgarian Multiword Expressions,</title>
<date>2005</date>
<booktitle>Computer Applications in Slavic Studies – Proceedings of Azbuki@net, International Conference and Workshop,</booktitle>
<pages>201--216</pages>
<location>Sofia,</location>
<contexts>
<context position="13900" citStr="Koeva, 2005" startWordPosition="2154" endWordPosition="2155">ma of the head word (such as gender for nouns), the number and POS of the remaining constituents and the options for inserting some words (such as particles) in the multi-word term structure all show the grouping of multi-word terms’ grammatical subclasses and define which slots of the paradigm are realized in the language. And finally, the formation of word forms of each component of a multi-word term and the type of agreement dependencies between components show the classification of multi-word terms into grammatical types that describe the real word paradigm belonging to a particular term (Koeva, 2005). For instance, the Bulgarian term klimatichna instalaciya (air-conditioning) is a noun phrase; the members of the paradigm are determined by the head feminine noun. The inflection type is determined by the inflectional alternations of each member (the adjective and the noun): klimatichna instalaciya – singular, indefinite klimatichnata instalaciya – singular, definite klimatichni instalaciii – plural, indefinite klimatichnite instalaciii – plural, definite There are agreement dependencies between adjective and head noun and no other words’ intervention or word order changes are allowed. 3 Aut</context>
</contexts>
<marker>Koeva, 2005</marker>
<rawString>S. Koeva 2005. Inflection Morphology of Bulgarian Multiword Expressions, Computer Applications in Slavic Studies – Proceedings of Azbuki@net, International Conference and Workshop, Sofia, 201-216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Koeva</author>
<author>S Leseva</author>
<author>I Stoyanova</author>
<author>E Tarpomanova</author>
<author>M Todorova</author>
</authors>
<title>Bulgarian Tagged Corpora,</title>
<date>2006</date>
<booktitle>Proceedings of the Fifth International Conference Formal Approaches to South Slavic and Balkan Languages,</booktitle>
<pages>78--86</pages>
<location>Sofia,</location>
<contexts>
<context position="15119" citStr="Koeva et al., 2006" startWordPosition="2333" endWordPosition="2336">omatic term extraction 3.1 Pre-processing of the Bulgarian AC It is common practice to extract candidate terms using a part-of-speech (POS) tagger and an automaton (a program extracting word sequences corresponding to predefined POS patterns). The part-of-speech tagging is the process of automatically identifying the words in a text as corresponding to a particular part of speech. The part-ofspeech tagger used in this study is developed utilizing a large manually annotated corpus consisting of 197,000 tokens (150,000 words) randomly extracted from the Bulgarian Brawn corpus (1,000,000 words) (Koeva et al., 2006). The tagger has been developed as a modified version of the Brill tagger (Brill, 1994). The Brill tagger was trained for Bulgarian using a part of the tagged corpus. We applied a rule-based approach leading to 98.3% precision. A sophisticated tokenizer that recognizes sentence boundaries and categorizes tokens as words, abbreviations, punctuation, numerical expressions, hours, dates and URLs has been built as a part of the tagger. For each word in the text the initial (most probable) part of speech among the ambiguity set is assigned from a large inflectional dictionary (Koeva, 1998). The wor</context>
</contexts>
<marker>Koeva, Leseva, Stoyanova, Tarpomanova, Todorova, 2006</marker>
<rawString>S. Koeva, S. Leseva, I. Stoyanova, E. Tarpomanova, and M. Todorova 2006. Bulgarian Tagged Corpora, Proceedings of the Fifth International Conference Formal Approaches to South Slavic and Balkan Languages, Sofia, 78-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Steinberger</author>
<author>B Pouliquen</author>
<author>A Widiger</author>
<author>C Ignat</author>
<author>T Erjavec</author>
<author>D Tufiş</author>
<author>D Varga</author>
</authors>
<title>The JRCAcquis: A multilingual aligned parallel corpus with 20+ languages,</title>
<date>2006</date>
<booktitle>Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC&apos;2006),</booktitle>
<location>Genoa.</location>
<marker>Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufiş, Varga, 2006</marker>
<rawString>R. Steinberger, B. Pouliquen, A. Widiger, C. Ignat, T. Erjavec, D. Tufiş, and D. Varga 2006. The JRCAcquis: A multilingual aligned parallel corpus with 20+ languages, Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC&apos;2006), Genoa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Voutilainen</author>
</authors>
<title>NPtool. A detector of English noun phrases,</title>
<date>1993</date>
<booktitle>Proceedings of the Workshop on Very Large Corpora,</booktitle>
<location>Columbus, Ohio.</location>
<marker>Voutilainen, 1993</marker>
<rawString>A. Voutilainen. 1993. NPtool. A detector of English noun phrases, Proceedings of the Workshop on Very Large Corpora, Columbus, Ohio.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>