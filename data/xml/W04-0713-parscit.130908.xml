<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000635">
<title confidence="0.996108">
An Algorithm for Resolving Individual and Abstract Anaphora in
Danish Texts and Dialogues
</title>
<author confidence="0.980243">
Costanza Navarretta
</author>
<affiliation confidence="0.911989">
Center for Sprogteknologi
</affiliation>
<address confidence="0.8624">
Njalsgade 80,
2300 Copenhagen S
</address>
<email confidence="0.997339">
costanza@cst.dk
</email>
<sectionHeader confidence="0.979941" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999978">
This paper describes the DAR-algorithm for re-
solving intersentential pronominal anaphors re-
ferring to individual and abstract entities in
Danish texts and dialogues. Individual enti-
ties are resolved combining models which iden-
tify high degree of salience with high degree of
givenness (topicality) of entities in the hearer’s
cognitive model, e.g. (Grosz et al., 1995), with
Hajiˇcov´a et al.’s (1990) salience account which
assigns the highest degree of salience to entities
in the focal part of an utterance in Information
Structure terms. These focal entities often in-
troduce new information in discourse. Anaph-
ors referring to abstract entities are resolved
with an extension of the algorithm presented
by Eckert and Strube (2000). Manual tests of
the DAR-algorithm and other well-known reso-
lution algorithms on the same data show that
DAR performs significantly better on most types
of anaphor.
</bodyText>
<sectionHeader confidence="0.997332" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999812896551724">
Most intersentential anaphor resolution al-
gorithms exclusively account for pronominal
anaphors with individual nominal antecedents
(henceforth IPAs) in texts. Less attention
has been given to pronominal anaphors which
refer to abstract entities evoked by verbal
phrases, clauses or discourse segments (hence-
forth APAs). However APAs are quite com-
mon in English dialogues, see i.a. (Byron and
Allen, 1998). Recently two algorithms for re-
solving APAs and IPAs in specific English dia-
logues have been proposed: Eckert and Strube’s
(2000) Es00, Byron’s (2002) PHORA. APAs
are also frequent in Danish. We found that
15% of all pronominal anaphors in our texts
were APAs, while they constituted 48% of the
anaphors in the analysed dialogues. Further-
more third-person singular pronouns in neuter
gender which can be IPAs or APAs were APAs
in two-third of the cases in both texts and dia-
logues.
In this paper we describe an algorithm, called
DAR, for resolving intersentential IPAs and
APAs in Danish.&apos; Unlike Es00 and PHORA,
DAR applies to both texts and dialogues.
Differing from most resolution algorithms,
DAR correctly accounts for the resolution of pro-
nouns referring to newly introduced informa-
tion, as it is the case in examples (1) and (2).
</bodyText>
<listItem confidence="0.902182375">
(1) [Chefen]i fik kun [en søn]k og [han]k gad
i hvert fald ikke videreføre familieforetagendet.
[PID]
([The boss]i had only [one son]k and [he]k surely
did not want to carry on the family business.)
(2) A: hvem...hvem arbejdede [din mor]i med?
(with whom... whom did [your mother]i work)
B: [Hun]i arbejdede med [vores nabo]k
</listItem>
<bodyText confidence="0.999244045454546">
([She]i worked with [our neighbour]k)
[Hun]k var enke ... havde tre sønner [BYsOC]
([She]k was a widow... had three sons)
In (1) the antecedent of the pronoun han
(he) is the indefinite object and not the more
“given” definite subject. In (2) the antecedent
of the second occurrence of the pronoun hun
(she) is the object vores nabo (our neighbour)
which provides the information requested in the
preceding question. This nominal is assigned
lower prominence than the subject pronoun hun
(she) in most salience models. To account for
this type of data the DAR-algorithm proposes a
novel strategy combining two apparently con-
trasting accounts of salience of entities (Navar-
retta, 2002a). The first account, e.g. (Grosz et
al., 1995), assigns the highest degree of salience
to the most known (topical) entities in the dis-
course model, the second assigns the highest de-
gree of salience to entities in the focal part of ut-
terances in Information Structure terms which,
often, represent new information (Hajiˇcov´a et
</bodyText>
<footnote confidence="0.939735666666667">
1DAR presupposes that intrasentential anaphors are
correctly resolved. At present no resolution algorithm
accounts for all uses of Danish intrasentential pronouns.
</footnote>
<bodyText confidence="0.98156325">
al., 1990).
DAR was developed on the basis of the uses
of pronouns in three text collections and three
corpora of naturally-occurring dialogues. The
texts comprise computer manuals, henceforth
EDB, novels and newspaper articles. The dia-
logue collections are SL (Duncker and Hermann,
1996), consisting of recorded conversations be-
tween GPs and their patients, the BYSOC cor-
pus (Gregersen and Pedersen, 1991) and the PID
corpus (Jensen, 1989) both containing recorded
conversations about everyday subjects.
In the paper we first present related work
(section 2) then we discuss the background for
our proposal (section 3). In section 4 the DAR-
algorithm is described. In section 5 we present
some tests of the algorithm, evaluate it and
compare its performance with the performance
of other known algorithms. Finally, in section 6,
we make some concluding remarks.
</bodyText>
<sectionHeader confidence="0.998448" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999887184210526">
The two algorithms for resolving IPAs and
APAs in English dialogues, ES00 and PHORA,
recognise IPAs and APAs on the basis of se-
mantic constraints on the argument position oc-
cupied by the anaphors. Both algorithms ac-
count for differences in reference between per-
sonal and demonstrative pronouns. In ES00
demonstrative pronouns preferentially refer to
abstract entities, while personal pronouns pref-
erentially refer to individual ones. ES00 re-
solves IPAs applying Strube’s (1998) algorithm.
In PHORA the antecedents of personal pro-
nouns are searched for looking at their degree
of salience which is implemented by word order
as in (Grosz et al., 1995). Demonstratives, in-
stead, are searched for in the list of activated
entities (Gundel et al., 1993) containing non
NP antecedents, which are assumed to be less
salient. In PHORA demonstratives can also refer
to Kinds.
ES00 requires that the structure of dialogues
has been marked. Byron’s PHORA-algorithm
does not rely on predefined dialogue structure,
but only searches for abstract antecedents of
APAs in the sentence preceding the anaphor.
Thus it does not account for APAs referring to
larger discourse segments. PHORA relies on both
semantic knowledge and a model of speech acts
and accounts for more phenomena than ES00.
Differing from ES00, PHORA has been imple-
mented. A very different strategy for resolv-
ing IPAs and APAs in spoken dialogues is pro-
posed in (Strube and Miller, 2003). We will not
further discuss this proposal, but Strube and
Miller’s machine learning approach is an inter-
esting attempt to automatically resolve anaph-
ors without relying on any domain specific re-
source or preannotated data.
</bodyText>
<sectionHeader confidence="0.993582" genericHeader="method">
3 Background for DAR
</sectionHeader>
<bodyText confidence="0.999957878787879">
In most applied approaches pronominal anaph-
ora resolution is equivalent to determining
the antecedent domain and choosing the most
prominent or salient antecedent among possi-
ble candidates. Although there is not always an
identity relation between linguistic antecedents
and referents, we also follow this strategy, well
aware that it is particularly problematic for
APAs. In fact, the same linguistic expression
can evoke different abstract objects depending
on the context in which the APA occurs, see
(Webber, 1991).
Determining the degree of salience of dis-
course elements, henceforth DEs, is essential to
anaphor resolution because personal pronouns
refer to the most salient candidate antecedent
that matches the given predication (Sidner,
1983). Nearly all salience-based models iden-
tify high degree of salience with high degree of
givenness of DEs. In fact, although the vari-
ous algorithms use different criteria for ranking
DEs such as linear order, hierarchy of grammat-
ical roles, information structure, Prince’s Famil-
iarity Scale (Prince, 1981), they all assign the
highest prominence to the DEs which are most
topical, known, bound, familiar and thus given,
i.a. (Grosz et al., 1995; Brennan et al., 1987;
Strube and Hahn, 1996; Strube, 1998). Grosz et
al. (1995) also suggest that continuing speaking
about the same elements in a discourse segment
is perceived as more coherent than shifting the
focus of attention. They implement this by the
following ranking of transition states:
</bodyText>
<equation confidence="0.384898">
continue &gt; retain &gt; shift.
</equation>
<bodyText confidence="0.9966485">
One salience model departs from the given-
ness2 assumption. It has been proposed by
Hajiˇcov´a et al. (1990) and assigns the highest
degree of salience to DEs in the focal part of an
utterance in information structure terms (Sgall
et al., 1986). These entities often represent new
information. Hajiˇcov´a et al.’s approach is orig-
inal and can account for the data in (1) and
(2). However, it is problematic from an applied
point of view. In the first place it is difficult to
</bodyText>
<footnote confidence="0.972293">
2Here givenness subsumes concepts such as topicality
and familiarity.
</footnote>
<bodyText confidence="0.999649693877551">
determine the information structure of all ut-
terances. Secondly, focal candidate antecedents
are ranked highest in Hajiˇcov´a et al.’s model,
but they still compete with given candidate an-
tecedents in their system. Finally the data does
not confirm that all entities in the focal part of
an utterance have the highest degree of accessi-
bility.
We agree with Hajiˇcov´a’s insight, but in order
to operationalise the role of focality in resolu-
tion in a reliable way we propose the following.
Accessibility by default is connected with given-
ness as assumed in most resolution algorithms.
However, speakers can explicitly change the de-
gree of accessibility of entities in discourse by
marking them as salient with information struc-
ture related devices. These entities represent
the main focus of an utterance, have the high-
est degree of salience and are, in the majority
of cases, the preferred antecedents of anaphors.
In these cases the shift of focus of attention is,
in our opinion, as coherent as continuing speak-
ing about the same entities, because it is prean-
nounced to the addressee. On the basis of the
data we propose a list of identifiable construc-
tions in which explicit focus marking occurs and
the focal DEs have the highest degree of salience
in our data.3 Examples from the list are the fol-
lowing:
a: Entities referred to by NPs which are focally
marked structurally. In Danish this marking
occurs in clefts, existential and topicalised con-
structions.4
b: Entities referred to by NPs that follow fo-
cusing adverbs, as in (1).
c: Entities focally marked by the prosody (if
this information is available) and/or entities
providing the information requested in ques-
tions, as in (2).
The hierarchy of verbal complements can
model givenness preference in Danish. As in
English pronouns have high givenness degree
(pronominal chain preference). In addition to
salience preferences we found that parallelism
can account for numerous uses of Danish anaph-
ors. According to parallelism in adjacent utter-
ances with parallel grammatical complements,
the preferred antecedent of an anaphor in the
second utterance is the linguistic expression in
</bodyText>
<footnote confidence="0.9767364">
3Many of these constructions are also studied in the
Information Structure literature and in some studies on
anaphora.
4Nominals in clefts are also assigned high salience in
e.g. (Sidner, 1983).
</footnote>
<bodyText confidence="0.999801125">
the first utterance with the same grammatical
function. Inspired by the work of (Kameyama,
1996) we have defined a preference interaction
model to be used in resolution. Our model is
given in figure 1.5 The interaction model states
that givenness preferences are overridden by fo-
cality preference, when in conflict, and that they
all are overridden by parallelism. Also in Dan-
</bodyText>
<figure confidence="0.9160135">
Parallelism ⊇ Focality ⊇ Pronominal chain ⊇
Givenness
</figure>
<figureCaption confidence="0.99998">
Figure 1: Interaction of preferences
</figureCaption>
<bodyText confidence="0.926144978723404">
ish demonstrative and personal pronouns refer
to entities with different status in the discourse
model. Weak (cliticised and unstressed) pro-
nouns usually refer to the most salient entity in
the utterance. Strong (stressed and demonstra-
tive) pronouns emphasise or put in contrast the
entities they refer to and/or indicate that their
antecedents are not the most expected ones.6
Demonstratives preferentially refer to abstract
entities, while personal pronouns preferentially
refer to individual entities in ambiguous con-
texts. All these differences are implemented in
DAR.
Approx. half of the APA occurrences in our
dialogues refer to entities evoked by larger dis-
course segments (more turn takings). Thus we
follow Eckert and Strube’s approach of mark-
ing the structure of dialogues and searching for
APA antecedents in the right frontier of the dis-
course tree (Webber, 1991). DAR presupposes
different discourse structures for texts and dia-
logues.
DAR follows the ES00 and PHORA strategy
of discriminating between IPAs and APAs by
rules looking at the semantic constraints on
the predication contexts in which the anaphors
occur. DAR relies on many more discriminat-
ing rules than ES00. These rules were defined
analysing large amounts of data and using the
encodings of the Danish PAROLE computational
lexicon (Braasch et al., 1998; Navarretta, 1997).
DAR uses language-specific rules to account
5The interaction model was defined on the basis of
the data and the results of a survey of pronominal uses.
Commonsense preferences which override all the other
preferences (see inter alia (Hobbs, 1983) are not imple-
mented.
6The most frequent Danish third person singular gen-
der pronoun det can both be a personal pronoun (cor-
responding to it) and a demonstrative pronoun (corre-
sponding to this/that). In the latter case it is always
stressed.
for Danish APAs. These occur in much more
contexts than in English where elliptical con-
structions or other anaphors such as too and so
are used. Examples of Danish-specific uses of
abstract anaphors are given in (3) and (4).
</bodyText>
<listItem confidence="0.994914">
(3) Han var sulten. Det var jeg ikke. [PID]
(lit. He was hungry. That was I not.)
(My friends were hungry. I wasn’t.)
(4) Han kunne svømme, men det kunne hun
ikke.
</listItem>
<bodyText confidence="0.975449166666667">
(lit. He could swim, but it could she not.)
(He could swim, but she couldn’t.)
A language-specific rule recognising APAs is
the following: constructions with modal verbs
and an object, such as x skal man (lit. x shall
one) (one shall), x vil man (lit. x will one) (one
will).
An example of a rule identifying IPAs is the
following: adjectival constructions in which the
prepositional complement only subcategorises
for concrete entities such as let for x (easy for
x), fuld af x (full of x).
</bodyText>
<sectionHeader confidence="0.998626" genericHeader="method">
4 The DAR-algorithm
</sectionHeader>
<subsectionHeader confidence="0.999859">
4.1 Search Space and DE lists
</subsectionHeader>
<bodyText confidence="0.999929444444445">
DAR presupposes the discourse structure de-
scribed by Grosz and Sidner (1986). The min-
imal discourse unit is the utterance U. Para-
graphs correspond to discourse segments in
texts. Discourse segments in dialogues were
manually marked. The dialogues were struc-
tured with Synchronising Units (SU) according
to the definitions in ES00.
The immediate antecedent search space of a
pronoun x in utterance Un is the previous utter-
ance, Un−1. If Un is the first component in SUm
in dialogues the immediate search space for x is
SUm−1. DAR assumes two antecedent domains
depending on whether the pronoun has or has
not been recognised as an IPA. The antecedent
domain for IPAs is first Un−1 and then the pre-
ceding utterances in the right frontier of the dis-
course tree searched for in recency order.7 The
antecedent domain for APAs or anaphors which
can both be IPAs and APAs is Un−1.
DAR operates on two lists of DEs, the Ilist
and the Alist. The Ilist contains the NPs re-
ferred to in Un−1 ranked according to their de-
gree of salience and enriched with information
on gender, number, animacy and other sim-
ple semantic types necessary to implement se-
lectional restrictions. In the Ilist information
</bodyText>
<footnote confidence="0.832485666666667">
7The search space in ES00 is the preceding utterance
for all pronouns.
1 A-list
</footnote>
<bodyText confidence="0.8174315">
2 within same U, I in dialogues,: clause to the
left of the clause containing the anaphor
3 within previous U (I): rightmost main clause
and subordinate clauses to its right
4 within previous Us (Is): rightmost complete
sentence
</bodyText>
<figureCaption confidence="0.999725">
Figure 3: The ES00 context ranking
</figureCaption>
<bodyText confidence="0.999977631578947">
about the grammatical role of nominals is pro-
vided and strongly focally marked elements are
indicated. The leftmost element in the Ilist is
the most salient one. Givenness and focality
preferences are accounted for in the Ilist, as il-
lustrated in figure 2. Focally marked entities
are put in front of the list while the remaining
DEs are ordered according to verbal comple-
ment order. Inside verbal complements nom-
inals are ordered according to their occurrence
order as illustrated in the second row of figure 2.
The abstract entities which are referred to by
an APA in Un−1 or SUm−1 are encoded in the
Alist. They are removed from the list after a
new utterance (SU in dialogues) has been pro-
cessed if they have not been mentioned in it.
The context ranking for abstract entities is that
proposed by Eckert and Strube (2000) and is
given in figure 3.
</bodyText>
<subsectionHeader confidence="0.948367">
4.2 The Algorithm
</subsectionHeader>
<bodyText confidence="0.9996576">
DAR consists of two different functions RE-
SOLVEDET and RESOLVEIPA. The former is ap-
plied if the actual pronoun x is third person
singular neuter, while the latter is applied in all
the remaining cases:
</bodyText>
<construct confidence="0.568574666666667">
if x is singular &amp; neuter
then go to RESOLVEDET(x)
else go to RESOLVEIPA(x)
</construct>
<bodyText confidence="0.999845285714286">
RESOLVEIPA takes the IPA x as argument and
looks for possible antecedents in the Ilist for
the preceding Un−1 or Sm−1, after having ap-
plied syntactic constraints and selectional re-
strictions on the elements of the list. Three dif-
ferent cases are considered: (A) no antecedent
has been found in the immediate search space;
(B) one antecedent has been found; (C) more
antecedents have been found.
If no antecedent has been found (case A),
RESOLVEIPA looks for the highest ranked an-
tecedent in recency order in the Ilists of the
preceding discourse. If an antecedent is found
the algorithm returns it. If no antecedent is
</bodyText>
<figure confidence="0.798791333333333">
FOCAL MARKED &gt; SUBJECT &gt; OBJECT/PrepOBJECT &gt; OBJECT 2 &gt; OTHER
COMPLS &gt; ADJUNCTS
NCOMPL1 &gt;prec NCOMPL2 &gt;prec . . . &gt;prec NCOMPLn
</figure>
<figureCaption confidence="0.999045">
Figure 2: Order of DEs in the Ilist
</figureCaption>
<bodyText confidence="0.999374">
found, x is classified as inferable.8 If one an-
tecedent is found (case B), it is returned. If
more candidate antecedents are found (case C),
RESOLVEIPA performs tests, implementing the
preference interaction model described in sec-
tion 3, as follows. If Un and Un−1 are paral-
lels and one of the candidate antecedents has
the same grammatical role in Un−1 as x in Un,
this “parallel” antecedent is marked. In the re-
maining cases the algorithm marks the highest
ranked candidate in the Ilist. Pronouns are pre-
ferred, unless there are focally marked candi-
date antecedents. At this point the algorithm
individuates the preferred antecedent on the ba-
sis of x’s type. If x is weak the marked candi-
date proposed in the preceding steps is returned
together with the list of the remaining candi-
date antecedents (possible ambiguity). If x is
strong the highest ranked candidate antecedent
which was not marked in the preceding steps
is returned together with the list of candidate
antecedents.10 The approach of marking ambi-
guities resembles that proposed by Kameyama
(1996).
The main structure of the function RE-
SOLVEDET is inspired by ES00. RESOLVEDET
tests the pronoun x using the IPA and APA
discriminating rules discussed in section 3. If
x is IPA, the function RESOLVEIPA-NEU is ap-
plied. If x is APA the function RESOLVEAPA is
applied. Finally, if the pronoun is neither IPA
nor APA, RESOLVEDET looks at its type. If x
is strong the algorithm attempts to find an ab-
stract antecedent (RESOLVEAPA), while if it is
weak DAR tries to find an individual antecedent
(RESOLVEIPA-NEU). RESOLVEIPA-NEU is like
RESOLVEIPA except that it returns if no NP an-
tecedents are found in Un−1 (case A) so that
RESOLVEAPA can be applied.
</bodyText>
<footnote confidence="0.977004666666667">
8In DAR inferables comprise pronouns whose an-
tecedents must be inferred by the context, plural pro-
nouns with complex antecedents and generic uses of det
(it).
9Parallelism is investigated in coordinated, adjacent
or explicitly contrasted utterances.
10A special rule in DAR is applied to the demonstra-
tives dette/denne/disse (this/these) which never corefer
with subject candidates.
</footnote>
<bodyText confidence="0.999868833333333">
RESOLVEAPA distinguishes between types of
pronoun. If x is weak, the preferred antecedent
is searched for among the elements indicated in
the context ranking, unless it is the object of the
verb gøre (do), modals, have (have) or the ab-
stract subject in copula constructions. In these
cases the pronoun is resolved to the VP of the
element in the A-list or in the context ranking.
If x is strong RESOLVEAPA attempts to resolve
or classify it as vague depending on the type
of pronoun. This part of the algorithm is spe-
cific to Danish and accounts for the fact that
different strong pronouns preferentially refer to
different abstract entities in the data.
Resolved APAs are inserted into the Alist.
In case of failure RESOLVEAPA returns so that
RESOLVEIPA-NEU can be applied. If both func-
tions fail, the pronoun is classified as vague.
</bodyText>
<subsectionHeader confidence="0.998055">
4.3 Some Examples
</subsectionHeader>
<bodyText confidence="0.995861785714286">
In the following we look at the resolution of ex-
ample (2) from section 3 and the example in
(5).
(5): Du har svært ved at se musemarkøren p˚a
skærmen. Hvordan klarer du det? [EDB]
(You have difficulties seing the mouse-cursor
(common-gend) on the screen (common-gend).
How do you manage it/this (neuter gender))?
The simplified Ilists and Alists after each ut-
terance has been processed in example (2) are
given in figure 4. (2) contains three 5Us. U2
is an I/A thus it belongs to two synchronising
units (5U1 and 5U2). The Ilist after U1 has
been processed, contains one element, din mor
(your mother). In U2 the personal pronoun hun
(she) occurs, thus RESOLVEIPA is applied. It
resolves hun to the compatible NP in the Ilist,
din mor. After U2 has been processed the Ilist
contains two elements in this order: the focal
marked entity vores nabo (our neighbour) and
the pronoun hun (= din mor). RESOLVEIPA re-
solves the occurrence of the pronoun hun (she)
in U3 to the most salient candidate NP in the
Ilist, vores nabo. Here focal preference over-
rides pronominal chain preference. The simpli-
fied Ilists and Alists after the two utterances in
(5) have been processed are given in figure 5.
After U1 has been processed there are two com-
</bodyText>
<note confidence="0.5106185">
SU1: U1 (I) U2 (I/A):
U1: hvem...hvem arbejdede din mor med?
(with whom... whom did your mother work)
Ilist: [din mor]
</note>
<figure confidence="0.757367818181818">
Alist:[]
SU2: U2 (I/A)
U2: Hun arbejdede med vores nabo
(She worked with our neighbour)
Ilist: [vores nabo,hun=din mor]
Alist: []
SU3: U3 (I)
U3: Hun var enke ... havde tre sønner
(She was a widow... had three sons)
Ilist: [hun=vores nabo,tre sønner]
Alist: []
</figure>
<figureCaption confidence="0.99888">
Figure 4: Ilists and Alists for example (2)
</figureCaption>
<figure confidence="0.942347">
U1: Du har svært ved at se musemarkøren p˚a
skærmen.
Ilist: [musemarkøren, skærmen]
Alist:[]
U2: Hvordan klarer du det?
Ilist:[]
Alist:[det=U1]
</figure>
<figureCaption confidence="0.999988">
Figure 5: Ilists and Alists for example (5)
</figureCaption>
<bodyText confidence="0.999869933333333">
mon gender singular NPs in the Ilist, muse-
markøren (the mouse cursor) and skærmen (the
screen). In U2 the singular neuter gender pro-
noun det (it) occurs, thus RESOLVEDET is ap-
plied. The pronoun is neither IPA nor APA
according to the discriminating rules. Then
RESOLVEDET attempts to find an individual
antecedent of the weak pronoun, applying the
function RESOLVEIPA-NEU. RESOLVEIPA-NEU
fails because the two DEs in the Ilist do not
agree with the pronoun. Then the function
RESOLVEAPA resolves x looking at the context
ranking. Being the Alist empty, U1, is proposed
as antecedent. The resolved APA is added to
the Alist.
</bodyText>
<sectionHeader confidence="0.92445" genericHeader="evaluation">
5 Tests and Evaluation
</sectionHeader>
<bodyText confidence="0.999986875">
We have manually tested DAR on randomly cho-
sen texts and dialogues from our collections.
The performance of DAR on dialogues has been
compared with that of ES00. The function
for resolving IPAs (RESOLVEIPA) has similarly
been tested on texts, where APAs were ex-
cluded. We have compared the obtained re-
sults with those obtained by testing BFP (Bren-
nan et al., 1987) and STR98 (Strube, 1998). In
all tests the intrasentential anaphors have been
manually resolved. Expletive and cataphoric
uses of pronouns have been marked and ex-
cluded from the tests. Dialogue act units were
marked and classified by three persons following
the strategy proposed in (Eckert and Strube,
2000). The reliability for the two annotation
tasks (K-statistics (Carletta, 1996)) was of 0.94
and 0.90 respectively. Pronominal anaphors
were marked, classified and resolved by two
annotators. The K-statistics for the pronoun
classification was 0.86. When the annotators
did not agree upon resolution, the pronoun was
marked as ambiguous and excluded from evalu-
ation. The results obtained for BFP and STR98
are given in table 1, while the results of DAR’s
RESOLVEIPA are given in table 2. Because DAR
both classifies and resolves anaphors, both pre-
cision and recall are given in table 2. Precision
indicates the proportion of the resolved pro-
nouns which are correctly resolved, while recall
indicates the proportion of all pronouns resolved
by humans which are correctly resolved by the
algorithm.
The results indicate that RESOLVEIPA per-
forms significantly better than BFP and STR98
on the Danish texts. The better performance of
DAR was due to the account of focal and par-
allelism preferences and of the different refer-
ence mechanisms of personal and demonstrative
pronouns. Furthermore DAR recognises some
generic pronouns and inferable pronouns and
excludes them from resolution, but often fails
to recognise antecedentless and inferable plural
pronouns, because it often finds a plural nom-
inal in the preceding discourse and proposes it
as antecedent. The lack of commonsense knowl-
edge explains many incorrectly resolved anaph-
ors. The results of the test of the DAR algo-
</bodyText>
<table confidence="0.911260333333333">
algorithm corr.resolved res.human precision
BFP 513 645 79.53
STR98 524 645 81.24
</table>
<tableCaption confidence="0.999121">
Table 1: Results of BFP and STR98 on texts
</tableCaption>
<table confidence="0.9904475">
corr.res. res.overall res.hum. precis recall
575 651 645 88.33 89.14
</table>
<tableCaption confidence="0.999723">
Table 2: Results of RESOLVEIPA on texts
</tableCaption>
<bodyText confidence="0.97908975">
rithm on written texts are in table 3. These
results are good compared with the results of
the function RESOLVEIPA (table 2). The dis-
criminating rules identify correctly IPAs and
</bodyText>
<table confidence="0.999473">
resolution IPA
Algorithm correctly resolved resolved overall human resolution precision recall f-meaure
Es00 258 411 414 62.77 62.31 62.48
DAR 289 386 414 74.87 68.81 71.71
resolution APA
Algorithm correctly resolved resolved overall human resolution precision recall f-measure
Es00 179 286 269 62.59 66.54 64.5
DAR 194 277 269 70.04 72.19 69.13
</table>
<tableCaption confidence="0.999873">
Table 4: Results of Es00 and DAR on dialogues
</tableCaption>
<bodyText confidence="0.999774444444444">
APAs in the large majority of the cases. Recog-
nition failure often involves pronouns in con-
texts which are not covered by the discriminat-
ing rules. In particular DAR fails to resolve sin-
gular neuter gender pronouns with distant an-
tecedents and to identify vague anaphors, be-
cause it always “finds” an antecedent in the con-
text ranking. Correct resolution in these cases
requires a deep analysis of the context. The
</bodyText>
<table confidence="0.998554833333333">
resolution IPA
corr.res. res.overall res.hum. precis recall
560 651 645 86.02 86.82
resolution APA
corr.res. res.overall res.hum. precis recall
63 87 77 72.41 81.82
</table>
<tableCaption confidence="0.999921">
Table 3: Results of DAR on texts
</tableCaption>
<bodyText confidence="0.999624216216216">
results of applying DAR and Es00 on Danish di-
alogues are reported in table 4.11 In the last
colum the overall performance of the two algo-
rithms is given as f-measure (F) which is defined
as α1P+(i−α)R where P is precision, R is recall
and α is the weight of P and R. We have as-
signed the same weight to P and R (α = 0.5)
and thus F = 2� �
� +�. The results of the tests in-
dicate that DAR resolves IPAs significantly bet-
ter than Es00 (which uses sTR98). The better
performance of DAR is also due to the enlarged
resolution scope respect to the one used in Es00.
DAR correctly resolves more Danish demonstra-
tive pronouns than Es00, because it accounts
for language-specific particularities. In general,
however, the resolution results for APAs are
similar to those obtained for Es00. This is not
surprising, because DAR uses the same resolu-
tion strategy on these pronouns. DAR performs
better on texts than on dialogues. This reflects
the more complex nature of dialogues. The re-
sults indicate that the IPA/APA discriminat-
&amp;quot;We extended Es00 with the Danish-specific identifi-
cation rules before applying it.
ing rules also work well on dialogues. The cases
of resolution failure were the same as for the
texts. As an experiment we applied DAR on the
dialogues without relying on the predefined di-
alogue structure. In this test the recognition
of IPAs and APAs was still good, however the
success rate for IPAs was 60.1 % and for APAs
was only 39.3%. Many errors were due to the
fact that antecedents were searched for in the
preceding discourse in linear order and that un-
grounded utterances were included in the dis-
course model.
</bodyText>
<sectionHeader confidence="0.993839" genericHeader="conclusions">
6 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.998212833333333">
In this paper we presented DAR, an algorithm
for resolving IPAs and APAs in Danish texts
and dialogues. In DAR differences between the
referential characteristics of Danish weak and
strong pronouns are accounted for and a novel
strategy for resolving individual anaphors is
proposed. This strategy combines givenness
with focality preferences to model salience and
also accounts for parallelism preferences. DAR
performs significantly better on IPAs than al-
gorithms which only rely on givenness-based
salience models. The strategy and the general
assumptions behind DAR should be tested on
other languages.
Differing from Es00 and PHORA, DAR has
been developed for and tested on both texts and
dialogues. DAR extends the Es00 strategy of
classifying and resolving (some types of) APAs.
The tests of DAR indicate that the Es00’s ap-
proach of recognising APAs is also promising
for texts and other languages than English.
DAR has not been compared with PHORA
which is the only abstract anaphora algorithm
implemented. We find the algorithm very inter-
esting because it addresses many of the same
phenomena, but with different strategies. It
would be useful to combine some of these strate-
gies with the approaches proposed in DAR and
Es00 to improve the still problematic resolution
of abstract anaphors.
</bodyText>
<sectionHeader confidence="0.97732" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999752485714285">
A. Braasch, C. Navarretta, and N.H. Sørensen.
1998. Danish lexicon documentation. Techni-
cal Report LE-PAROLE. WP3.3-CST, CST.
S. F. Brennan, M. W. Friedman, and C. J. Pol-
lard. 1987. A Centering Approach to Pro-
nouns. In Proceedings of the 25th Annual
Meeting of the Association for Computational
Linguistics (ACL’87), pages 155–162, Cali-
fornia, USA. Stanford University.
D. Byron and J. Allen. 1998. Resolving Demon-
strative Pronouns in the TRAINS93 corpus.
In Proceedings of the Second Colloquium on
Discourse Anaphora and Anaphor Resolution
(DAARC 2), pages 68–81.
D. K. Byron. 2002. Resolving Pronominal Ref-
erence to Abstract Entities. In Proceedings of
the 40th Annual Meeting of the Association
for Computational Linguistics (ACL 2002).
J. Carletta. 1996. Assessing agreement on clas-
sification tasks. the kappa statistic. Compu-
tational Linguistics, 22(2):249–254.
D. Duncker and J. Hermann. 1996. Pa-
tientord og lægeord - særord eller fælle-
sord? M˚anedsskrift for Praktisk Leegegern-
ing - Tidsskrift for Praktiserende Leegers
Efteruddannelse, pages 1019–1030.
M. Eckert and M. Strube. 2000. Dialogue acts,
synchronising units and anaphora resolution.
Journal of Semantics, 17:51–89.
F. Gregersen and I. L. Pedersen, editors. 1991.
The Copenhagen study in urban sociolinguis-
tics. Reitzel.
B. J. Grosz and C. L. Sidner. 1986. Attention,
Intentions, and the Structure of Discourse.
Computational Linguistics, 12(3):175–284.
B. Grosz, A. K. Joshi, and S. Weinstein. 1995.
Centering:A Framework for Modeling the Lo-
cal Coherence of Discourse. Computational
Linguistics, 21(2):203–225.
J. K. Gundel, N. Hedberg, and R. Zacharski.
1993. Cognitive status and the form of re-
ferring expressions in discourse. Language,
69(2):274–307.
E. Hajiˇcov´a, P. Kuboˇn, and V. Kuboˇn. 1990.
Hierarchy of Salience and Discourse Analysis
and Production. In H. Karlgren, editor, Pro-
ceedings of the 13th International Conference
on Computational Linguistics (COLING’90),
volume III, pages 144–148, Helsinki.
J. R. Hobbs. 1983. Why Is Discourse Coher-
ent? In Fritz Neubauer, editor, Coherence In
Natural-Language Texts, volume 38 of Papers
in Textlinguistics, pages 29–70. Helmut Buske
Verlag Hamburg.
K. A. Jensen. 1989. Projekt invandrerdansk.
Technical report, Copenhagen University.
M. Kameyama. 1996. Indefeasible Semantics
and Defeasible Pragmatics. In M. Kanazawa,
C. Pi˜non, and H. de Stwart, editors, Quanti-
fiers, Deduction and Context, pages 111–138.
CSLI, Stanford, CA.
C. Navarretta. 1997. Encoding Danish Verbs in
the PAROLE Model. In R. Mitkov, N. Ni-
colov, and N. Nikolov, editors, Proceedings
of RANLP’97.Recent Advances in Natural
Language Processing, pages 359–363, Tzigov
Chark, Bulgaria.
C. Navarretta. 2002a. Combining Informa-
tion Structure and Centering-based Mod-
els of Salience for Resolving Intersenten-
tial Pronominal Anaphora. In A. Branco,
T. McEnery, and R.Mitkov, editors, Pro-
ceedings of the 4th Discourse Anaphora and
Anaphora Resolution Colloqium, pages 135–
140. Edi¸coes Colibri.
E. F. Prince. 1981. Toward a taxonomy of
given-new information. In P. Cole, editor,
Radical Pragmatics, pages 223–255. Aca-
demic Press.
P. Sgall, E. Haji˘cov´a, and J. Panevov´a. 1986.
The Meaning of the Sentence in its Semantic
and Pragmatic Aspects. Reidel, Dordrecht.
C. Sidner. 1983. Focusing in the Comprehen-
sion of Definite Anaphora. In M. Brady and
R. Berwick, editors, Computational Models of
Discourse, pages 267–330. MIT Press.
M. Strube and U. Hahn. 1996. Functional Cen-
tering. In Proceedings of the 34th Interna-
tional Conference on Computational Linguis-
tics (ACL’96), pages 270–277, Ca.
M. Strube and C. M¨uller. 2003. A ma-
chine learning approach to pronoun resolu-
tion in spoken dialogue. In Proceedings of the
ACL’03, pages 168–175.
M. Strube. 1998. Never Look Back: An Al-
ternative to Centering. In Proceedings of
the 36th Annual Meeting of the Association
for Computational Linguistics and the 17th
International Conference on Computational
Linguistics (COLING-ACL’98), volume II,
pages 1251–1257.
B. L. Webber. 1991. Structure and Osten-
sion in the Interpretation of Discourse Deixis.
Natural Language and Cognitive Processes,
6(2):107–135, January.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.548043">
<title confidence="0.9938145">An Algorithm for Resolving Individual and Abstract Anaphora in Danish Texts and Dialogues</title>
<author confidence="0.956502">Costanza</author>
<affiliation confidence="0.994198">Center for</affiliation>
<address confidence="0.7952665">Njalsgade 2300 Copenhagen</address>
<email confidence="0.990735">costanza@cst.dk</email>
<abstract confidence="0.99908080952381">This paper describes the DAR-algorithm for resolving intersentential pronominal anaphors referring to individual and abstract entities in Danish texts and dialogues. Individual entities are resolved combining models which identify high degree of salience with high degree of givenness (topicality) of entities in the hearer’s cognitive model, e.g. (Grosz et al., 1995), with Hajiˇcov´a et al.’s (1990) salience account which assigns the highest degree of salience to entities in the focal part of an utterance in Information Structure terms. These focal entities often introduce new information in discourse. Anaphors referring to abstract entities are resolved with an extension of the algorithm presented by Eckert and Strube (2000). Manual tests of the DAR-algorithm and other well-known resolution algorithms on the same data show that DAR performs significantly better on most types of anaphor.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Braasch</author>
<author>C Navarretta</author>
<author>N H Sørensen</author>
</authors>
<title>Danish lexicon documentation.</title>
<date>1998</date>
<tech>Technical Report LE-PAROLE. WP3.3-CST, CST.</tech>
<contexts>
<context position="12620" citStr="Braasch et al., 1998" startWordPosition="1989" endWordPosition="1992">low Eckert and Strube’s approach of marking the structure of dialogues and searching for APA antecedents in the right frontier of the discourse tree (Webber, 1991). DAR presupposes different discourse structures for texts and dialogues. DAR follows the ES00 and PHORA strategy of discriminating between IPAs and APAs by rules looking at the semantic constraints on the predication contexts in which the anaphors occur. DAR relies on many more discriminating rules than ES00. These rules were defined analysing large amounts of data and using the encodings of the Danish PAROLE computational lexicon (Braasch et al., 1998; Navarretta, 1997). DAR uses language-specific rules to account 5The interaction model was defined on the basis of the data and the results of a survey of pronominal uses. Commonsense preferences which override all the other preferences (see inter alia (Hobbs, 1983) are not implemented. 6The most frequent Danish third person singular gender pronoun det can both be a personal pronoun (corresponding to it) and a demonstrative pronoun (corresponding to this/that). In the latter case it is always stressed. for Danish APAs. These occur in much more contexts than in English where elliptical constru</context>
</contexts>
<marker>Braasch, Navarretta, Sørensen, 1998</marker>
<rawString>A. Braasch, C. Navarretta, and N.H. Sørensen. 1998. Danish lexicon documentation. Technical Report LE-PAROLE. WP3.3-CST, CST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Brennan</author>
<author>M W Friedman</author>
<author>C J Pollard</author>
</authors>
<title>A Centering Approach to Pronouns.</title>
<date>1987</date>
<booktitle>In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics (ACL’87),</booktitle>
<pages>155--162</pages>
<institution>Stanford University.</institution>
<location>California, USA.</location>
<contexts>
<context position="7631" citStr="Brennan et al., 1987" startWordPosition="1192" endWordPosition="1195"> essential to anaphor resolution because personal pronouns refer to the most salient candidate antecedent that matches the given predication (Sidner, 1983). Nearly all salience-based models identify high degree of salience with high degree of givenness of DEs. In fact, although the various algorithms use different criteria for ranking DEs such as linear order, hierarchy of grammatical roles, information structure, Prince’s Familiarity Scale (Prince, 1981), they all assign the highest prominence to the DEs which are most topical, known, bound, familiar and thus given, i.a. (Grosz et al., 1995; Brennan et al., 1987; Strube and Hahn, 1996; Strube, 1998). Grosz et al. (1995) also suggest that continuing speaking about the same elements in a discourse segment is perceived as more coherent than shifting the focus of attention. They implement this by the following ranking of transition states: continue &gt; retain &gt; shift. One salience model departs from the givenness2 assumption. It has been proposed by Hajiˇcov´a et al. (1990) and assigns the highest degree of salience to DEs in the focal part of an utterance in information structure terms (Sgall et al., 1986). These entities often represent new information. </context>
<context position="23329" citStr="Brennan et al., 1987" startWordPosition="3818" endWordPosition="3822">ils because the two DEs in the Ilist do not agree with the pronoun. Then the function RESOLVEAPA resolves x looking at the context ranking. Being the Alist empty, U1, is proposed as antecedent. The resolved APA is added to the Alist. 5 Tests and Evaluation We have manually tested DAR on randomly chosen texts and dialogues from our collections. The performance of DAR on dialogues has been compared with that of ES00. The function for resolving IPAs (RESOLVEIPA) has similarly been tested on texts, where APAs were excluded. We have compared the obtained results with those obtained by testing BFP (Brennan et al., 1987) and STR98 (Strube, 1998). In all tests the intrasentential anaphors have been manually resolved. Expletive and cataphoric uses of pronouns have been marked and excluded from the tests. Dialogue act units were marked and classified by three persons following the strategy proposed in (Eckert and Strube, 2000). The reliability for the two annotation tasks (K-statistics (Carletta, 1996)) was of 0.94 and 0.90 respectively. Pronominal anaphors were marked, classified and resolved by two annotators. The K-statistics for the pronoun classification was 0.86. When the annotators did not agree upon reso</context>
</contexts>
<marker>Brennan, Friedman, Pollard, 1987</marker>
<rawString>S. F. Brennan, M. W. Friedman, and C. J. Pollard. 1987. A Centering Approach to Pronouns. In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics (ACL’87), pages 155–162, California, USA. Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Byron</author>
<author>J Allen</author>
</authors>
<title>Resolving Demonstrative Pronouns in the TRAINS93 corpus.</title>
<date>1998</date>
<booktitle>In Proceedings of the Second Colloquium on Discourse Anaphora and Anaphor Resolution (DAARC 2),</booktitle>
<pages>68--81</pages>
<contexts>
<context position="1512" citStr="Byron and Allen, 1998" startWordPosition="219" endWordPosition="222">presented by Eckert and Strube (2000). Manual tests of the DAR-algorithm and other well-known resolution algorithms on the same data show that DAR performs significantly better on most types of anaphor. 1 Introduction Most intersentential anaphor resolution algorithms exclusively account for pronominal anaphors with individual nominal antecedents (henceforth IPAs) in texts. Less attention has been given to pronominal anaphors which refer to abstract entities evoked by verbal phrases, clauses or discourse segments (henceforth APAs). However APAs are quite common in English dialogues, see i.a. (Byron and Allen, 1998). Recently two algorithms for resolving APAs and IPAs in specific English dialogues have been proposed: Eckert and Strube’s (2000) Es00, Byron’s (2002) PHORA. APAs are also frequent in Danish. We found that 15% of all pronominal anaphors in our texts were APAs, while they constituted 48% of the anaphors in the analysed dialogues. Furthermore third-person singular pronouns in neuter gender which can be IPAs or APAs were APAs in two-third of the cases in both texts and dialogues. In this paper we describe an algorithm, called DAR, for resolving intersentential IPAs and APAs in Danish.&apos; Unlike Es</context>
</contexts>
<marker>Byron, Allen, 1998</marker>
<rawString>D. Byron and J. Allen. 1998. Resolving Demonstrative Pronouns in the TRAINS93 corpus. In Proceedings of the Second Colloquium on Discourse Anaphora and Anaphor Resolution (DAARC 2), pages 68–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D K Byron</author>
</authors>
<title>Resolving Pronominal Reference to Abstract Entities.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<marker>Byron, 2002</marker>
<rawString>D. K. Byron. 2002. Resolving Pronominal Reference to Abstract Entities. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
</authors>
<title>Assessing agreement on classification tasks. the kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="23715" citStr="Carletta, 1996" startWordPosition="3879" endWordPosition="3880">ompared with that of ES00. The function for resolving IPAs (RESOLVEIPA) has similarly been tested on texts, where APAs were excluded. We have compared the obtained results with those obtained by testing BFP (Brennan et al., 1987) and STR98 (Strube, 1998). In all tests the intrasentential anaphors have been manually resolved. Expletive and cataphoric uses of pronouns have been marked and excluded from the tests. Dialogue act units were marked and classified by three persons following the strategy proposed in (Eckert and Strube, 2000). The reliability for the two annotation tasks (K-statistics (Carletta, 1996)) was of 0.94 and 0.90 respectively. Pronominal anaphors were marked, classified and resolved by two annotators. The K-statistics for the pronoun classification was 0.86. When the annotators did not agree upon resolution, the pronoun was marked as ambiguous and excluded from evaluation. The results obtained for BFP and STR98 are given in table 1, while the results of DAR’s RESOLVEIPA are given in table 2. Because DAR both classifies and resolves anaphors, both precision and recall are given in table 2. Precision indicates the proportion of the resolved pronouns which are correctly resolved, wh</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>J. Carletta. 1996. Assessing agreement on classification tasks. the kappa statistic. Computational Linguistics, 22(2):249–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Duncker</author>
<author>J Hermann</author>
</authors>
<title>Patientord og lægeord - særord eller fællesord? M˚anedsskrift for Praktisk Leegegerning - Tidsskrift for Praktiserende Leegers Efteruddannelse,</title>
<date>1996</date>
<pages>1019--1030</pages>
<contexts>
<context position="4141" citStr="Duncker and Hermann, 1996" startWordPosition="643" endWordPosition="646">cond assigns the highest degree of salience to entities in the focal part of utterances in Information Structure terms which, often, represent new information (Hajiˇcov´a et 1DAR presupposes that intrasentential anaphors are correctly resolved. At present no resolution algorithm accounts for all uses of Danish intrasentential pronouns. al., 1990). DAR was developed on the basis of the uses of pronouns in three text collections and three corpora of naturally-occurring dialogues. The texts comprise computer manuals, henceforth EDB, novels and newspaper articles. The dialogue collections are SL (Duncker and Hermann, 1996), consisting of recorded conversations between GPs and their patients, the BYSOC corpus (Gregersen and Pedersen, 1991) and the PID corpus (Jensen, 1989) both containing recorded conversations about everyday subjects. In the paper we first present related work (section 2) then we discuss the background for our proposal (section 3). In section 4 the DARalgorithm is described. In section 5 we present some tests of the algorithm, evaluate it and compare its performance with the performance of other known algorithms. Finally, in section 6, we make some concluding remarks. 2 Related Work The two alg</context>
</contexts>
<marker>Duncker, Hermann, 1996</marker>
<rawString>D. Duncker and J. Hermann. 1996. Patientord og lægeord - særord eller fællesord? M˚anedsskrift for Praktisk Leegegerning - Tidsskrift for Praktiserende Leegers Efteruddannelse, pages 1019–1030.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Eckert</author>
<author>M Strube</author>
</authors>
<title>Dialogue acts, synchronising units and anaphora resolution.</title>
<date>2000</date>
<journal>Journal of Semantics,</journal>
<pages>17--51</pages>
<contexts>
<context position="927" citStr="Eckert and Strube (2000)" startWordPosition="133" endWordPosition="136">al and abstract entities in Danish texts and dialogues. Individual entities are resolved combining models which identify high degree of salience with high degree of givenness (topicality) of entities in the hearer’s cognitive model, e.g. (Grosz et al., 1995), with Hajiˇcov´a et al.’s (1990) salience account which assigns the highest degree of salience to entities in the focal part of an utterance in Information Structure terms. These focal entities often introduce new information in discourse. Anaphors referring to abstract entities are resolved with an extension of the algorithm presented by Eckert and Strube (2000). Manual tests of the DAR-algorithm and other well-known resolution algorithms on the same data show that DAR performs significantly better on most types of anaphor. 1 Introduction Most intersentential anaphor resolution algorithms exclusively account for pronominal anaphors with individual nominal antecedents (henceforth IPAs) in texts. Less attention has been given to pronominal anaphors which refer to abstract entities evoked by verbal phrases, clauses or discourse segments (henceforth APAs). However APAs are quite common in English dialogues, see i.a. (Byron and Allen, 1998). Recently two </context>
<context position="16417" citStr="Eckert and Strube (2000)" startWordPosition="2644" endWordPosition="2647">accounted for in the Ilist, as illustrated in figure 2. Focally marked entities are put in front of the list while the remaining DEs are ordered according to verbal complement order. Inside verbal complements nominals are ordered according to their occurrence order as illustrated in the second row of figure 2. The abstract entities which are referred to by an APA in Un−1 or SUm−1 are encoded in the Alist. They are removed from the list after a new utterance (SU in dialogues) has been processed if they have not been mentioned in it. The context ranking for abstract entities is that proposed by Eckert and Strube (2000) and is given in figure 3. 4.2 The Algorithm DAR consists of two different functions RESOLVEDET and RESOLVEIPA. The former is applied if the actual pronoun x is third person singular neuter, while the latter is applied in all the remaining cases: if x is singular &amp; neuter then go to RESOLVEDET(x) else go to RESOLVEIPA(x) RESOLVEIPA takes the IPA x as argument and looks for possible antecedents in the Ilist for the preceding Un−1 or Sm−1, after having applied syntactic constraints and selectional restrictions on the elements of the list. Three different cases are considered: (A) no antecedent h</context>
<context position="23638" citStr="Eckert and Strube, 2000" startWordPosition="3867" endWordPosition="3870">xts and dialogues from our collections. The performance of DAR on dialogues has been compared with that of ES00. The function for resolving IPAs (RESOLVEIPA) has similarly been tested on texts, where APAs were excluded. We have compared the obtained results with those obtained by testing BFP (Brennan et al., 1987) and STR98 (Strube, 1998). In all tests the intrasentential anaphors have been manually resolved. Expletive and cataphoric uses of pronouns have been marked and excluded from the tests. Dialogue act units were marked and classified by three persons following the strategy proposed in (Eckert and Strube, 2000). The reliability for the two annotation tasks (K-statistics (Carletta, 1996)) was of 0.94 and 0.90 respectively. Pronominal anaphors were marked, classified and resolved by two annotators. The K-statistics for the pronoun classification was 0.86. When the annotators did not agree upon resolution, the pronoun was marked as ambiguous and excluded from evaluation. The results obtained for BFP and STR98 are given in table 1, while the results of DAR’s RESOLVEIPA are given in table 2. Because DAR both classifies and resolves anaphors, both precision and recall are given in table 2. Precision indic</context>
</contexts>
<marker>Eckert, Strube, 2000</marker>
<rawString>M. Eckert and M. Strube. 2000. Dialogue acts, synchronising units and anaphora resolution. Journal of Semantics, 17:51–89.</rawString>
</citation>
<citation valid="true">
<title>The Copenhagen study in urban sociolinguistics.</title>
<date>1991</date>
<editor>F. Gregersen and I. L. Pedersen, editors.</editor>
<publisher>Reitzel.</publisher>
<marker>1991</marker>
<rawString>F. Gregersen and I. L. Pedersen, editors. 1991. The Copenhagen study in urban sociolinguistics. Reitzel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<date>1986</date>
<booktitle>Attention, Intentions, and the Structure of Discourse. Computational Linguistics,</booktitle>
<pages>12--3</pages>
<contexts>
<context position="14136" citStr="Grosz and Sidner (1986)" startWordPosition="2249" endWordPosition="2252">kke. (lit. He could swim, but it could she not.) (He could swim, but she couldn’t.) A language-specific rule recognising APAs is the following: constructions with modal verbs and an object, such as x skal man (lit. x shall one) (one shall), x vil man (lit. x will one) (one will). An example of a rule identifying IPAs is the following: adjectival constructions in which the prepositional complement only subcategorises for concrete entities such as let for x (easy for x), fuld af x (full of x). 4 The DAR-algorithm 4.1 Search Space and DE lists DAR presupposes the discourse structure described by Grosz and Sidner (1986). The minimal discourse unit is the utterance U. Paragraphs correspond to discourse segments in texts. Discourse segments in dialogues were manually marked. The dialogues were structured with Synchronising Units (SU) according to the definitions in ES00. The immediate antecedent search space of a pronoun x in utterance Un is the previous utterance, Un−1. If Un is the first component in SUm in dialogues the immediate search space for x is SUm−1. DAR assumes two antecedent domains depending on whether the pronoun has or has not been recognised as an IPA. The antecedent domain for IPAs is first U</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. J. Grosz and C. L. Sidner. 1986. Attention, Intentions, and the Structure of Discourse. Computational Linguistics, 12(3):175–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Centering:A Framework for Modeling the Local Coherence of Discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="3407" citStr="Grosz et al., 1995" startWordPosition="532" endWordPosition="535">ree sons) In (1) the antecedent of the pronoun han (he) is the indefinite object and not the more “given” definite subject. In (2) the antecedent of the second occurrence of the pronoun hun (she) is the object vores nabo (our neighbour) which provides the information requested in the preceding question. This nominal is assigned lower prominence than the subject pronoun hun (she) in most salience models. To account for this type of data the DAR-algorithm proposes a novel strategy combining two apparently contrasting accounts of salience of entities (Navarretta, 2002a). The first account, e.g. (Grosz et al., 1995), assigns the highest degree of salience to the most known (topical) entities in the discourse model, the second assigns the highest degree of salience to entities in the focal part of utterances in Information Structure terms which, often, represent new information (Hajiˇcov´a et 1DAR presupposes that intrasentential anaphors are correctly resolved. At present no resolution algorithm accounts for all uses of Danish intrasentential pronouns. al., 1990). DAR was developed on the basis of the uses of pronouns in three text collections and three corpora of naturally-occurring dialogues. The texts</context>
<context position="5379" citStr="Grosz et al., 1995" startWordPosition="840" endWordPosition="843">ng IPAs and APAs in English dialogues, ES00 and PHORA, recognise IPAs and APAs on the basis of semantic constraints on the argument position occupied by the anaphors. Both algorithms account for differences in reference between personal and demonstrative pronouns. In ES00 demonstrative pronouns preferentially refer to abstract entities, while personal pronouns preferentially refer to individual ones. ES00 resolves IPAs applying Strube’s (1998) algorithm. In PHORA the antecedents of personal pronouns are searched for looking at their degree of salience which is implemented by word order as in (Grosz et al., 1995). Demonstratives, instead, are searched for in the list of activated entities (Gundel et al., 1993) containing non NP antecedents, which are assumed to be less salient. In PHORA demonstratives can also refer to Kinds. ES00 requires that the structure of dialogues has been marked. Byron’s PHORA-algorithm does not rely on predefined dialogue structure, but only searches for abstract antecedents of APAs in the sentence preceding the anaphor. Thus it does not account for APAs referring to larger discourse segments. PHORA relies on both semantic knowledge and a model of speech acts and accounts for</context>
<context position="7609" citStr="Grosz et al., 1995" startWordPosition="1188" endWordPosition="1191">, henceforth DEs, is essential to anaphor resolution because personal pronouns refer to the most salient candidate antecedent that matches the given predication (Sidner, 1983). Nearly all salience-based models identify high degree of salience with high degree of givenness of DEs. In fact, although the various algorithms use different criteria for ranking DEs such as linear order, hierarchy of grammatical roles, information structure, Prince’s Familiarity Scale (Prince, 1981), they all assign the highest prominence to the DEs which are most topical, known, bound, familiar and thus given, i.a. (Grosz et al., 1995; Brennan et al., 1987; Strube and Hahn, 1996; Strube, 1998). Grosz et al. (1995) also suggest that continuing speaking about the same elements in a discourse segment is perceived as more coherent than shifting the focus of attention. They implement this by the following ranking of transition states: continue &gt; retain &gt; shift. One salience model departs from the givenness2 assumption. It has been proposed by Hajiˇcov´a et al. (1990) and assigns the highest degree of salience to DEs in the focal part of an utterance in information structure terms (Sgall et al., 1986). These entities often repre</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>B. Grosz, A. K. Joshi, and S. Weinstein. 1995. Centering:A Framework for Modeling the Local Coherence of Discourse. Computational Linguistics, 21(2):203–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J K Gundel</author>
<author>N Hedberg</author>
<author>R Zacharski</author>
</authors>
<title>Cognitive status and the form of referring expressions in discourse.</title>
<date>1993</date>
<journal>Language,</journal>
<volume>69</volume>
<issue>2</issue>
<contexts>
<context position="5478" citStr="Gundel et al., 1993" startWordPosition="856" endWordPosition="859">antic constraints on the argument position occupied by the anaphors. Both algorithms account for differences in reference between personal and demonstrative pronouns. In ES00 demonstrative pronouns preferentially refer to abstract entities, while personal pronouns preferentially refer to individual ones. ES00 resolves IPAs applying Strube’s (1998) algorithm. In PHORA the antecedents of personal pronouns are searched for looking at their degree of salience which is implemented by word order as in (Grosz et al., 1995). Demonstratives, instead, are searched for in the list of activated entities (Gundel et al., 1993) containing non NP antecedents, which are assumed to be less salient. In PHORA demonstratives can also refer to Kinds. ES00 requires that the structure of dialogues has been marked. Byron’s PHORA-algorithm does not rely on predefined dialogue structure, but only searches for abstract antecedents of APAs in the sentence preceding the anaphor. Thus it does not account for APAs referring to larger discourse segments. PHORA relies on both semantic knowledge and a model of speech acts and accounts for more phenomena than ES00. Differing from ES00, PHORA has been implemented. A very different strate</context>
</contexts>
<marker>Gundel, Hedberg, Zacharski, 1993</marker>
<rawString>J. K. Gundel, N. Hedberg, and R. Zacharski. 1993. Cognitive status and the form of referring expressions in discourse. Language, 69(2):274–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hajiˇcov´a</author>
<author>P Kuboˇn</author>
<author>V Kuboˇn</author>
</authors>
<title>Hierarchy of Salience and Discourse Analysis and Production. In</title>
<date>1990</date>
<booktitle>Proceedings of the 13th International Conference on Computational Linguistics (COLING’90), volume III,</booktitle>
<pages>144--148</pages>
<editor>H. Karlgren, editor,</editor>
<location>Helsinki.</location>
<marker>Hajiˇcov´a, Kuboˇn, Kuboˇn, 1990</marker>
<rawString>E. Hajiˇcov´a, P. Kuboˇn, and V. Kuboˇn. 1990. Hierarchy of Salience and Discourse Analysis and Production. In H. Karlgren, editor, Proceedings of the 13th International Conference on Computational Linguistics (COLING’90), volume III, pages 144–148, Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
</authors>
<title>Why Is Discourse Coherent?</title>
<date>1983</date>
<booktitle>Coherence In Natural-Language Texts,</booktitle>
<volume>38</volume>
<pages>29--70</pages>
<editor>In Fritz Neubauer, editor,</editor>
<publisher>Helmut Buske Verlag Hamburg.</publisher>
<contexts>
<context position="12887" citStr="Hobbs, 1983" startWordPosition="2032" endWordPosition="2033">y of discriminating between IPAs and APAs by rules looking at the semantic constraints on the predication contexts in which the anaphors occur. DAR relies on many more discriminating rules than ES00. These rules were defined analysing large amounts of data and using the encodings of the Danish PAROLE computational lexicon (Braasch et al., 1998; Navarretta, 1997). DAR uses language-specific rules to account 5The interaction model was defined on the basis of the data and the results of a survey of pronominal uses. Commonsense preferences which override all the other preferences (see inter alia (Hobbs, 1983) are not implemented. 6The most frequent Danish third person singular gender pronoun det can both be a personal pronoun (corresponding to it) and a demonstrative pronoun (corresponding to this/that). In the latter case it is always stressed. for Danish APAs. These occur in much more contexts than in English where elliptical constructions or other anaphors such as too and so are used. Examples of Danish-specific uses of abstract anaphors are given in (3) and (4). (3) Han var sulten. Det var jeg ikke. [PID] (lit. He was hungry. That was I not.) (My friends were hungry. I wasn’t.) (4) Han kunne s</context>
</contexts>
<marker>Hobbs, 1983</marker>
<rawString>J. R. Hobbs. 1983. Why Is Discourse Coherent? In Fritz Neubauer, editor, Coherence In Natural-Language Texts, volume 38 of Papers in Textlinguistics, pages 29–70. Helmut Buske Verlag Hamburg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K A Jensen</author>
</authors>
<title>Projekt invandrerdansk. Technical report,</title>
<date>1989</date>
<booktitle>Deduction and Context,</booktitle>
<pages>111--138</pages>
<editor>In M. Kanazawa, C. Pi˜non, and H. de Stwart, editors, Quantifiers,</editor>
<publisher>CSLI,</publisher>
<location>Copenhagen</location>
<contexts>
<context position="4293" citStr="Jensen, 1989" startWordPosition="669" endWordPosition="670">cov´a et 1DAR presupposes that intrasentential anaphors are correctly resolved. At present no resolution algorithm accounts for all uses of Danish intrasentential pronouns. al., 1990). DAR was developed on the basis of the uses of pronouns in three text collections and three corpora of naturally-occurring dialogues. The texts comprise computer manuals, henceforth EDB, novels and newspaper articles. The dialogue collections are SL (Duncker and Hermann, 1996), consisting of recorded conversations between GPs and their patients, the BYSOC corpus (Gregersen and Pedersen, 1991) and the PID corpus (Jensen, 1989) both containing recorded conversations about everyday subjects. In the paper we first present related work (section 2) then we discuss the background for our proposal (section 3). In section 4 the DARalgorithm is described. In section 5 we present some tests of the algorithm, evaluate it and compare its performance with the performance of other known algorithms. Finally, in section 6, we make some concluding remarks. 2 Related Work The two algorithms for resolving IPAs and APAs in English dialogues, ES00 and PHORA, recognise IPAs and APAs on the basis of semantic constraints on the argument p</context>
</contexts>
<marker>Jensen, 1989</marker>
<rawString>K. A. Jensen. 1989. Projekt invandrerdansk. Technical report, Copenhagen University. M. Kameyama. 1996. Indefeasible Semantics and Defeasible Pragmatics. In M. Kanazawa, C. Pi˜non, and H. de Stwart, editors, Quantifiers, Deduction and Context, pages 111–138. CSLI, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Navarretta</author>
</authors>
<title>Encoding Danish Verbs in the PAROLE Model. In</title>
<date>1997</date>
<booktitle>Proceedings of RANLP’97.Recent Advances in Natural Language Processing,</booktitle>
<pages>359--363</pages>
<editor>R. Mitkov, N. Nicolov, and N. Nikolov, editors,</editor>
<location>Tzigov Chark, Bulgaria.</location>
<contexts>
<context position="12639" citStr="Navarretta, 1997" startWordPosition="1993" endWordPosition="1994">s approach of marking the structure of dialogues and searching for APA antecedents in the right frontier of the discourse tree (Webber, 1991). DAR presupposes different discourse structures for texts and dialogues. DAR follows the ES00 and PHORA strategy of discriminating between IPAs and APAs by rules looking at the semantic constraints on the predication contexts in which the anaphors occur. DAR relies on many more discriminating rules than ES00. These rules were defined analysing large amounts of data and using the encodings of the Danish PAROLE computational lexicon (Braasch et al., 1998; Navarretta, 1997). DAR uses language-specific rules to account 5The interaction model was defined on the basis of the data and the results of a survey of pronominal uses. Commonsense preferences which override all the other preferences (see inter alia (Hobbs, 1983) are not implemented. 6The most frequent Danish third person singular gender pronoun det can both be a personal pronoun (corresponding to it) and a demonstrative pronoun (corresponding to this/that). In the latter case it is always stressed. for Danish APAs. These occur in much more contexts than in English where elliptical constructions or other ana</context>
</contexts>
<marker>Navarretta, 1997</marker>
<rawString>C. Navarretta. 1997. Encoding Danish Verbs in the PAROLE Model. In R. Mitkov, N. Nicolov, and N. Nikolov, editors, Proceedings of RANLP’97.Recent Advances in Natural Language Processing, pages 359–363, Tzigov Chark, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Navarretta</author>
</authors>
<title>Combining Information Structure and Centering-based Models of Salience for Resolving Intersentential Pronominal Anaphora. In</title>
<date>2002</date>
<booktitle>Proceedings of the 4th Discourse Anaphora and Anaphora Resolution Colloqium,</booktitle>
<pages>135--140</pages>
<editor>A. Branco, T. McEnery, and R.Mitkov, editors,</editor>
<publisher>Edi¸coes Colibri.</publisher>
<contexts>
<context position="3359" citStr="Navarretta, 2002" startWordPosition="525" endWordPosition="527"> sønner [BYsOC] ([She]k was a widow... had three sons) In (1) the antecedent of the pronoun han (he) is the indefinite object and not the more “given” definite subject. In (2) the antecedent of the second occurrence of the pronoun hun (she) is the object vores nabo (our neighbour) which provides the information requested in the preceding question. This nominal is assigned lower prominence than the subject pronoun hun (she) in most salience models. To account for this type of data the DAR-algorithm proposes a novel strategy combining two apparently contrasting accounts of salience of entities (Navarretta, 2002a). The first account, e.g. (Grosz et al., 1995), assigns the highest degree of salience to the most known (topical) entities in the discourse model, the second assigns the highest degree of salience to entities in the focal part of utterances in Information Structure terms which, often, represent new information (Hajiˇcov´a et 1DAR presupposes that intrasentential anaphors are correctly resolved. At present no resolution algorithm accounts for all uses of Danish intrasentential pronouns. al., 1990). DAR was developed on the basis of the uses of pronouns in three text collections and three cor</context>
</contexts>
<marker>Navarretta, 2002</marker>
<rawString>C. Navarretta. 2002a. Combining Information Structure and Centering-based Models of Salience for Resolving Intersentential Pronominal Anaphora. In A. Branco, T. McEnery, and R.Mitkov, editors, Proceedings of the 4th Discourse Anaphora and Anaphora Resolution Colloqium, pages 135– 140. Edi¸coes Colibri.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F Prince</author>
</authors>
<title>Toward a taxonomy of given-new information.</title>
<date>1981</date>
<booktitle>Radical Pragmatics,</booktitle>
<pages>223--255</pages>
<editor>In P. Cole, editor,</editor>
<publisher>Academic Press.</publisher>
<contexts>
<context position="7470" citStr="Prince, 1981" startWordPosition="1166" endWordPosition="1167">objects depending on the context in which the APA occurs, see (Webber, 1991). Determining the degree of salience of discourse elements, henceforth DEs, is essential to anaphor resolution because personal pronouns refer to the most salient candidate antecedent that matches the given predication (Sidner, 1983). Nearly all salience-based models identify high degree of salience with high degree of givenness of DEs. In fact, although the various algorithms use different criteria for ranking DEs such as linear order, hierarchy of grammatical roles, information structure, Prince’s Familiarity Scale (Prince, 1981), they all assign the highest prominence to the DEs which are most topical, known, bound, familiar and thus given, i.a. (Grosz et al., 1995; Brennan et al., 1987; Strube and Hahn, 1996; Strube, 1998). Grosz et al. (1995) also suggest that continuing speaking about the same elements in a discourse segment is perceived as more coherent than shifting the focus of attention. They implement this by the following ranking of transition states: continue &gt; retain &gt; shift. One salience model departs from the givenness2 assumption. It has been proposed by Hajiˇcov´a et al. (1990) and assigns the highest </context>
</contexts>
<marker>Prince, 1981</marker>
<rawString>E. F. Prince. 1981. Toward a taxonomy of given-new information. In P. Cole, editor, Radical Pragmatics, pages 223–255. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sgall</author>
<author>E Haji˘cov´a</author>
<author>J Panevov´a</author>
</authors>
<title>The Meaning of the Sentence in its Semantic and Pragmatic Aspects.</title>
<date>1986</date>
<location>Reidel, Dordrecht.</location>
<marker>Sgall, Haji˘cov´a, Panevov´a, 1986</marker>
<rawString>P. Sgall, E. Haji˘cov´a, and J. Panevov´a. 1986. The Meaning of the Sentence in its Semantic and Pragmatic Aspects. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sidner</author>
</authors>
<title>Focusing in the Comprehension of Definite Anaphora.</title>
<date>1983</date>
<booktitle>Computational Models of Discourse,</booktitle>
<pages>267--330</pages>
<editor>In M. Brady and R. Berwick, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7166" citStr="Sidner, 1983" startWordPosition="1119" endWordPosition="1120">nt or salient antecedent among possible candidates. Although there is not always an identity relation between linguistic antecedents and referents, we also follow this strategy, well aware that it is particularly problematic for APAs. In fact, the same linguistic expression can evoke different abstract objects depending on the context in which the APA occurs, see (Webber, 1991). Determining the degree of salience of discourse elements, henceforth DEs, is essential to anaphor resolution because personal pronouns refer to the most salient candidate antecedent that matches the given predication (Sidner, 1983). Nearly all salience-based models identify high degree of salience with high degree of givenness of DEs. In fact, although the various algorithms use different criteria for ranking DEs such as linear order, hierarchy of grammatical roles, information structure, Prince’s Familiarity Scale (Prince, 1981), they all assign the highest prominence to the DEs which are most topical, known, bound, familiar and thus given, i.a. (Grosz et al., 1995; Brennan et al., 1987; Strube and Hahn, 1996; Strube, 1998). Grosz et al. (1995) also suggest that continuing speaking about the same elements in a discours</context>
<context position="10819" citStr="Sidner, 1983" startWordPosition="1711" endWordPosition="1712">ts can model givenness preference in Danish. As in English pronouns have high givenness degree (pronominal chain preference). In addition to salience preferences we found that parallelism can account for numerous uses of Danish anaphors. According to parallelism in adjacent utterances with parallel grammatical complements, the preferred antecedent of an anaphor in the second utterance is the linguistic expression in 3Many of these constructions are also studied in the Information Structure literature and in some studies on anaphora. 4Nominals in clefts are also assigned high salience in e.g. (Sidner, 1983). the first utterance with the same grammatical function. Inspired by the work of (Kameyama, 1996) we have defined a preference interaction model to be used in resolution. Our model is given in figure 1.5 The interaction model states that givenness preferences are overridden by focality preference, when in conflict, and that they all are overridden by parallelism. Also in DanParallelism ⊇ Focality ⊇ Pronominal chain ⊇ Givenness Figure 1: Interaction of preferences ish demonstrative and personal pronouns refer to entities with different status in the discourse model. Weak (cliticised and unstre</context>
</contexts>
<marker>Sidner, 1983</marker>
<rawString>C. Sidner. 1983. Focusing in the Comprehension of Definite Anaphora. In M. Brady and R. Berwick, editors, Computational Models of Discourse, pages 267–330. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>U Hahn</author>
</authors>
<title>Functional Centering.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th International Conference on Computational Linguistics (ACL’96),</booktitle>
<pages>270--277</pages>
<location>Ca.</location>
<contexts>
<context position="7654" citStr="Strube and Hahn, 1996" startWordPosition="1196" endWordPosition="1199">resolution because personal pronouns refer to the most salient candidate antecedent that matches the given predication (Sidner, 1983). Nearly all salience-based models identify high degree of salience with high degree of givenness of DEs. In fact, although the various algorithms use different criteria for ranking DEs such as linear order, hierarchy of grammatical roles, information structure, Prince’s Familiarity Scale (Prince, 1981), they all assign the highest prominence to the DEs which are most topical, known, bound, familiar and thus given, i.a. (Grosz et al., 1995; Brennan et al., 1987; Strube and Hahn, 1996; Strube, 1998). Grosz et al. (1995) also suggest that continuing speaking about the same elements in a discourse segment is perceived as more coherent than shifting the focus of attention. They implement this by the following ranking of transition states: continue &gt; retain &gt; shift. One salience model departs from the givenness2 assumption. It has been proposed by Hajiˇcov´a et al. (1990) and assigns the highest degree of salience to DEs in the focal part of an utterance in information structure terms (Sgall et al., 1986). These entities often represent new information. Hajiˇcov´a et al.’s app</context>
</contexts>
<marker>Strube, Hahn, 1996</marker>
<rawString>M. Strube and U. Hahn. 1996. Functional Centering. In Proceedings of the 34th International Conference on Computational Linguistics (ACL’96), pages 270–277, Ca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>C M¨uller</author>
</authors>
<title>A machine learning approach to pronoun resolution in spoken dialogue.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL’03,</booktitle>
<pages>168--175</pages>
<marker>Strube, M¨uller, 2003</marker>
<rawString>M. Strube and C. M¨uller. 2003. A machine learning approach to pronoun resolution in spoken dialogue. In Proceedings of the ACL’03, pages 168–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
</authors>
<title>Never Look Back: An Alternative to Centering.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLING-ACL’98), volume II,</booktitle>
<pages>1251--1257</pages>
<contexts>
<context position="7669" citStr="Strube, 1998" startWordPosition="1200" endWordPosition="1201">onal pronouns refer to the most salient candidate antecedent that matches the given predication (Sidner, 1983). Nearly all salience-based models identify high degree of salience with high degree of givenness of DEs. In fact, although the various algorithms use different criteria for ranking DEs such as linear order, hierarchy of grammatical roles, information structure, Prince’s Familiarity Scale (Prince, 1981), they all assign the highest prominence to the DEs which are most topical, known, bound, familiar and thus given, i.a. (Grosz et al., 1995; Brennan et al., 1987; Strube and Hahn, 1996; Strube, 1998). Grosz et al. (1995) also suggest that continuing speaking about the same elements in a discourse segment is perceived as more coherent than shifting the focus of attention. They implement this by the following ranking of transition states: continue &gt; retain &gt; shift. One salience model departs from the givenness2 assumption. It has been proposed by Hajiˇcov´a et al. (1990) and assigns the highest degree of salience to DEs in the focal part of an utterance in information structure terms (Sgall et al., 1986). These entities often represent new information. Hajiˇcov´a et al.’s approach is origin</context>
<context position="23354" citStr="Strube, 1998" startWordPosition="3825" endWordPosition="3826">ist do not agree with the pronoun. Then the function RESOLVEAPA resolves x looking at the context ranking. Being the Alist empty, U1, is proposed as antecedent. The resolved APA is added to the Alist. 5 Tests and Evaluation We have manually tested DAR on randomly chosen texts and dialogues from our collections. The performance of DAR on dialogues has been compared with that of ES00. The function for resolving IPAs (RESOLVEIPA) has similarly been tested on texts, where APAs were excluded. We have compared the obtained results with those obtained by testing BFP (Brennan et al., 1987) and STR98 (Strube, 1998). In all tests the intrasentential anaphors have been manually resolved. Expletive and cataphoric uses of pronouns have been marked and excluded from the tests. Dialogue act units were marked and classified by three persons following the strategy proposed in (Eckert and Strube, 2000). The reliability for the two annotation tasks (K-statistics (Carletta, 1996)) was of 0.94 and 0.90 respectively. Pronominal anaphors were marked, classified and resolved by two annotators. The K-statistics for the pronoun classification was 0.86. When the annotators did not agree upon resolution, the pronoun was m</context>
</contexts>
<marker>Strube, 1998</marker>
<rawString>M. Strube. 1998. Never Look Back: An Alternative to Centering. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLING-ACL’98), volume II, pages 1251–1257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L Webber</author>
</authors>
<date>1991</date>
<booktitle>Structure and Ostension in the Interpretation of Discourse Deixis. Natural Language and Cognitive Processes,</booktitle>
<volume>6</volume>
<issue>2</issue>
<contexts>
<context position="6933" citStr="Webber, 1991" startWordPosition="1086" endWordPosition="1087">ors without relying on any domain specific resource or preannotated data. 3 Background for DAR In most applied approaches pronominal anaphora resolution is equivalent to determining the antecedent domain and choosing the most prominent or salient antecedent among possible candidates. Although there is not always an identity relation between linguistic antecedents and referents, we also follow this strategy, well aware that it is particularly problematic for APAs. In fact, the same linguistic expression can evoke different abstract objects depending on the context in which the APA occurs, see (Webber, 1991). Determining the degree of salience of discourse elements, henceforth DEs, is essential to anaphor resolution because personal pronouns refer to the most salient candidate antecedent that matches the given predication (Sidner, 1983). Nearly all salience-based models identify high degree of salience with high degree of givenness of DEs. In fact, although the various algorithms use different criteria for ranking DEs such as linear order, hierarchy of grammatical roles, information structure, Prince’s Familiarity Scale (Prince, 1981), they all assign the highest prominence to the DEs which are m</context>
<context position="12163" citStr="Webber, 1991" startWordPosition="1919" endWordPosition="1920"> put in contrast the entities they refer to and/or indicate that their antecedents are not the most expected ones.6 Demonstratives preferentially refer to abstract entities, while personal pronouns preferentially refer to individual entities in ambiguous contexts. All these differences are implemented in DAR. Approx. half of the APA occurrences in our dialogues refer to entities evoked by larger discourse segments (more turn takings). Thus we follow Eckert and Strube’s approach of marking the structure of dialogues and searching for APA antecedents in the right frontier of the discourse tree (Webber, 1991). DAR presupposes different discourse structures for texts and dialogues. DAR follows the ES00 and PHORA strategy of discriminating between IPAs and APAs by rules looking at the semantic constraints on the predication contexts in which the anaphors occur. DAR relies on many more discriminating rules than ES00. These rules were defined analysing large amounts of data and using the encodings of the Danish PAROLE computational lexicon (Braasch et al., 1998; Navarretta, 1997). DAR uses language-specific rules to account 5The interaction model was defined on the basis of the data and the results of</context>
</contexts>
<marker>Webber, 1991</marker>
<rawString>B. L. Webber. 1991. Structure and Ostension in the Interpretation of Discourse Deixis. Natural Language and Cognitive Processes, 6(2):107–135, January.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>