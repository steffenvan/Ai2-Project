<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003430">
<title confidence="0.869766">
MuLLinG: multilevel linguistic graphs for knowledge extraction
</title>
<author confidence="0.532253">
Vincent Archer
</author>
<note confidence="0.278567">
Laboratoire I3S (équipe RL), Université de Nice Sophia Antipolis
Sophia Antipolis, France
</note>
<email confidence="0.993648">
vincent.archer@unice.fr
</email>
<sectionHeader confidence="0.993741" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999822277777778">
MuLLinG is a model for knowledge extrac-
tion (especially lexical extraction from cor-
pora), based on multilevel graphs. Its aim is
to allow large-scale data acquisition, by mak-
ing it easy to realize automatically, and
simple to configure by linguists with limited
knowledge in computer programming. In
MuLLinG, each new level represents the in-
formation in a different manner (more and
more abstract). We also introduce several as-
sociated operators, written to be as generic as
possible. They are independent of what nodes
and edges represent, and of the task to
achieve. Consequently, they allow the de-
scription of a complex extraction process as a
succession of simple graph manipulations. Fi-
nally, we present an experiment of colloca-
tion extraction using MuLLinG model.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999796791666667">
Natural language processing systems often pro-
duce low-quality results, because of ambiguities
and particular linguistic phenomena. One major
reason is the lack of linguistic data needed to de-
tect these phenomena or to solve ambiguities. To
fill this lack, new linguistic resources should be
produced. It could be done quickly with automat-
ic processes, but quality would be unsatisfactory;
on the contrary, manual work by linguists allows
precise results, but takes lot of time. To get both
rapidity and precision, we must combine ma-
chine and human abilities, by giving automatic
processing tools to linguists, and allowing them
to guide the process. Existing tools are often too
centered on a task, and require too much know-
ledge in computer programming: they are not ap-
propriate for linguists with few knowledge in
coding. We should thus develop generic tools.
In this article, we first focus on how to make
the resource gathering easier. Then, we introduce
MuLLinG, our multilevel graph model for lin-
guistic extraction, with several associated opera-
tions. Finally, we present an application of that
model on collocation extraction.
</bodyText>
<sectionHeader confidence="0.967644" genericHeader="method">
2 Knowledge extraction
</sectionHeader>
<bodyText confidence="0.999910166666667">
There are several manners to collect resources
with automatic processes (machine learning, col-
laborative interfaces, etc.). We focus here on (lin-
guistic and statistic) extraction of candidates.
More precisely, our goal is to facilitate the large-
scale production of candidates by extraction.
</bodyText>
<subsectionHeader confidence="0.998136">
2.1 Simplify programming
</subsectionHeader>
<bodyText confidence="0.999535851851852">
Making a particular extraction task is not easy, as
there is often no dedicated tool. It forces to write
ad hoc tools (most of the time not unveiled).
Moreover, ad hoc tools are not written to be uni-
versal. They generally depend on the data model,
it is therefore difficult or impossible to use a new
resource with a different format (such as an ana-
lysis from an other parser). To be really useful,
an extraction tool should be generic (able to
handle different data models) and easy to under-
stand and to use. The data model on which the
tool rely must be simple, expressive (complex
structure should be represented easily), and uni-
versal (for monolingual or multilingual corpora,
dictionaries, etc.). It should also provide simple
generic, task-independent, high-level operations
that can be combined to describe a complex task.
We choose to introduce a graph-based model.
Graphs are understandable quickly by humans,
easy to use in automatic processes, and flexible
enough to represent various data types. Using
graphs for knowledge extraction is quite classic.
They can represent relations between words (pro-
duced by dependency analysers from corpora),
and be used to produce semantically close terms
(Widdows &amp; Dorrow, 2002) or to group similar
n-tuples (Hassan et al., 2006). Graphs also can be
</bodyText>
<page confidence="0.992418">
69
</page>
<note confidence="0.6331475">
Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 69–73,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.997318333333333">
generated from dictionaries, and used to produce
knowledge bases (Richardson et al., 1998) or
proximity information (Gaume et al., 2006).
</bodyText>
<subsectionHeader confidence="0.999318">
2.2 Existing graph models
</subsectionHeader>
<bodyText confidence="0.999934034482758">
Influenced by “existential graphs” (Peirce, 1931-
1935) where relations between elements are rep-
resented by nodes, “conceptual graphs” (Sowa,
1976) are bipartite graphs with two node types:
concepts and conceptual relations (edges only as-
sociate relations and concepts). That relation ma-
terialization is useful, as it allows to handle eas-
ily n-ary relations, without hypergraphs.
Another interesting network is the “lexical
system” one (Polguère, 2006), defined as ori-
ented, weighted, unhierarchical and, above all,
heterogeneous: there is no constraint on what is
modelized (it could be terms, meanings, colloca-
tions, etc.). It avoids the separation between dic-
tionary-like and network-like lexical databases,
and shows the same representation can be used
for each kind of data and relation.
Finally, graphs can be multilevel, to represent
different kinds of information. Links are gener-
ally allowed only in a same level or between two
adjacent levels, like in “hypertexts” (Agosti and
Crestani, 1993) made of three specified levels
(documents, terms, concepts), or in Multi-Level
Association Graphs (Witschel, 2007) in which
there is no constraint on the number of levels.
We believe that the use of several levels to rep-
resent various content types is pertinent in an ex-
traction process, as it allows to handle both the
occurrences of terms, and the terms themselves.
</bodyText>
<sectionHeader confidence="0.997412" genericHeader="method">
3 MuLLinG model
</sectionHeader>
<bodyText confidence="0.99841965">
We introduce MuLLinG (Multi-Level Linguistic
Graph), our own graph model. Divided in several
ordered and distinct levels, it contains two kinds
of edges: intra-level ones (between nodes from
same level) and inter-level ones (from a node on
level i to a node on level i+1). Intra-level edges
are not unique (several edges are allowed
between two nodes): every level is a multigraph.
On the contrary, a node can be the source of only
one inter-level edge; this association means that
the target node (on the superior level) is a more
global representation of the source node (it
defines a hierarchy of precision).
Finally, in order to allow the heterogeneity of
represented data, nodes and intra-level edges can
carry any attribute (with no limit on kind or num-
ber). Figure 1 shows an example of a MuLLinG
graph, in which 1st level contains occurrences of
words, 2nd level contains lemmas, and 3rd level
contains synonymy classes.
</bodyText>
<figureCaption confidence="0.980632">
Figure 1. Example of 3-level MuLLinG graph
</figureCaption>
<subsectionHeader confidence="0.982546">
3.1 Definition
</subsectionHeader>
<bodyText confidence="0.977439">
More precisely, a MuLLinG graph is an oriented
multigraph (
</bodyText>
<equation confidence="0.893383">
Gn = V,E, F, A, Φ, a , a
V E) (for n
levels) where:
</equation>
<listItem confidence="0.844302266666667">
• V: set of nodes, made of n disjoint sub-
sets V1,... ,Vn (for the n levels);
• E: set of intra-level edges, made of n dis-
joint subsets E1,... ,En ; A: set of functions
α i : Ei → Vi × Vi i ∈ { 1,..., n} associating
an edge and its two extremities;
• F: set of inter-level edges, in n-1 disjoint
sets F1 ,... , Fn− 1 defined as
Fi={ x,y ∈ Vi× Vi+1 |y =ϕ(x)}; Φ : set
of functions ϕ i : Vi → Vi+1 i ∈ { 1,...,n} , as-
sociating a node (on a given level) and a
node on the superior level);
• aV={ f :V → ΣV} , aE={ f :E → ΣE}
( ΣV, ΣE are alphabets for attributes of
objects from E and V) model attributes.
</listItem>
<subsectionHeader confidence="0.998697">
3.2 Associated operators
</subsectionHeader>
<bodyText confidence="0.9999435">
To manipulate MuLLinG graphs, we introduce
several operations, designed for their particular
structure. Some of them allow elementary ma-
nipulations: add or delete a node or an edge,
clean a node (delete all edges of which it is a
source or a target), delete a node and its “des-
cendants” (the nodes linked to it by inter-level
edges, and their own descendants). There are
</bodyText>
<page confidence="0.993162">
70
</page>
<figureCaption confidence="0.999739">
Figure 2. Two-steps emergence (nodes, then edges)
</figureCaption>
<bodyText confidence="0.982781590909091">
also operations to compute measures, to realize a
conditional manipulation on nodes or edges (it
can be use to filter the graph, by deleting nodes
depending on the value of a given attribute). All
these basic operations should not be directly
used, but rather be called by more elaborate ones.
These operations (modifying the graph struc-
ture) take parameters fixed by the user: the level,
the filtering function (which graph elements are
concerned by the operation?), and computation
functions (to produce attribute values for newly
created elements). Graph coherence is guaran-
teed if the user provides correct parameters.
Emergence is the essential operation associ-
ated with MuLLinG. Its aim is to generate a su-
perior level, by grouping elements (from the ini-
tial level) in equivalence classes. In the newly
created level, each node (resp. edge) represent a
equivalence class of nodes (resp. edges) from the
initial level. The identification of equivalence
classes is a parameter of the emergence (the user
provides it). The operation goes in two steps:
</bodyText>
<listItem confidence="0.9276531875">
• node emergence: for each equivalence
class of nodes, it creates a node on the su-
perior level to represent this class (and
each node in the class is linked to the
newly created node); figure 2 shows the
emergence of nodes representing equival-
ence classes containing all occurrences of
a same word;
• edge emergence: each edge added on the
superior level between nodes A and B de-
pict a set of equivalent edges between an
element of A class and an element of B
class; in figure 2, equivalent u and u&apos; are
grouped in a sole edge U, whereas s and t
(not equivalent) are represented by two
distinct edges S and T.
</listItem>
<bodyText confidence="0.999249103448276">
Finally, some other operations have been
defined to mix information from two graphs in a
third one. The intersection contain elements
(nodes, edges) present in both graphs, with uni-
fication of identical elements. The union contain
all elements from the two graphs, with unifica-
tion of identical elements. The difference contain
all elements from the first graph that are not
identical to an element from the second one.
It is essential to recognize the identity between
two nodes or two edges: identity functions are
parameters for these “mix” operations, and
should be provided by the user. Among paramet-
ers, there are also, depending on the case, func-
tions for fusion (production of attributes for uni-
fied nodes or edges) or copy (production of at-
tributes for elements present in only one graph).
To handle n-ary relations, we also provide a
complex version of MuLLinG, where relations
can be materialized. In that case, a relation is
represented by a standard node and numbered
argument edges linking that node to the argu-
ments of the relation. It also allows the represent-
ation of relations between relations themselves.
We made an implementation of MuLLinG as a
C++ library1, based on Boost (open-source C++
libraries), especially for graph access and itera-
tions. It can read and write MuLLinG graphs in
GraphML format (Brandes et al., 2001).
</bodyText>
<sectionHeader confidence="0.895793" genericHeader="method">
4 Application to collocation extraction
</sectionHeader>
<subsectionHeader confidence="0.98299">
4.1 Extraction process
</subsectionHeader>
<bodyText confidence="0.999780125">
We realized several experiments using our lib-
rary. We remind the reader that our goal was not
to obtain the more efficient method for extrac-
tion, but rather to introduce tools for simplifying
the programming of extraction tasks. We present
here experiments about collocation extraction.
Collocations are particular expressions where a
term is chosen arbitrarily, depending on the other
</bodyText>
<footnote confidence="0.987351">
1 Available at http://mulling.ligforge.imag.fr/ (under
CeCILL free software license)
</footnote>
<page confidence="0.998848">
71
</page>
<bodyText confidence="0.973325634146342">
term, to express a particular meaning (like in
“driving rain”, where “driving” is used to express
intensity). As the choice differs between lan-
guages2, it causes big issues to machine transla-
tion systems (which lack resources to handle
them correctly). In our experiment, the initial
graph is made of relations produced by a depend-
ency analyzer, on 1st level.
Firstly, we use the filtering operator to keep
only pertinent relations (nouns modified by ad-
jectives, like in figure 3, or verbs modified by
adverbs), according to the analyzer. There are re-
lations between term occurrences on 1st level, but
we want relations between terms themselves: we
generate them on 2nd level using emergence. So
we proceed node emergence by considering that
nodes with same attribute “lemma” are equival-
ent, then edge emergence by considering that
edges expressing a modification are equivalent.
Figure 3. Collocations extraction with emergence
(on 2nd level) and computation operations
The “collocation” candidates are all 2nd-level
edges created during the emergence. To rank
them, we use the computation operation (with
occurrence and co-occurrence frequencies) to fix
an association measure on those nodes. Figure 3
shows an example of a MuLLinG graph after
emergence and computation operations.
To facilitate the description, our library con-
tains lots of pre-defined generic functions. By
example, a filter (used as a parameter of emer-
gence) can be based on an excepted value, a
threshold, etc. We also described numerous asso-
ciation measures; for now, new ones should be
written in the C++ program.
We used our library to carry out the extraction
as described previously, with LeMonde95 corpus
(news articles) analyzed by Xerox&apos;s XIP parser.
Thanks to MuLLinG structure, it is very easy to
get all potential collocations (heavy/driving rain):
these are the relations of which it is the source.
</bodyText>
<footnote confidence="0.956898">
2By example, a “heavy smoker” is big in French (“gros
fumeur”) and strong in German (“starker Raucher”).
</footnote>
<table confidence="0.9906582">
Experiments verb-adverb noun-adjective
Level 1 nodes 1 155 824 1 319 474
edges 1 780 759 2 009 051
Level 2 nodes 6 813 33 132
edges 144 586 273 655
</table>
<tableCaption confidence="0.976714">
Table 1. Nodes and edges produced during ex-
periments on collocation extraction
</tableCaption>
<subsectionHeader confidence="0.982944">
4.2 Advantages and drawbacks
</subsectionHeader>
<bodyText confidence="0.99997416">
With MuLLinG library, we reproduced exactly
some experiments on collocation extraction we
made before (with ad hoc programs): results are
obviously coherent. The production is currently
slightly slower (around 20% more time) but
speed is not crucial, and could be optimized.
MuLLinG has a great advantage while writing
the program: it only calls functions (and declare
parameters). Consequently, task description with
our library is much faster (source lines of code
are divided by 5), it also avoids errors. It requires
less knowledge in programming, so it is far more
accessible. Nevertheless, usability should still be
improved: we must describe a high-level lan-
guage (we believe it should be a request one).
Furthermore, there is no constraint on input re-
sources, so programs could easily be re-used
with other relations (from other parsers). Finally,
as graphs with millions of elements can reach
RAM limits, we plan to allow database storage.
We also made bilingual experiments on col-
locations, taking advantage of MuLLinG com-
plex version to materialize monolingual “colloc-
ation” nodes, and to describe bilingual relations
between collocations as edges between them.
</bodyText>
<sectionHeader confidence="0.998904" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999977166666667">
Facing the lack of tools for extraction of lexical
knowledge, we looked for a new one, simple and
generic. We specified MuLLinG, multilevel
graph model (with no constraint on the data), as-
sociated with several simple manipulation opera-
tions (which could be combined to realize com-
plex tasks). The ensuing tool allows to program
linguistic tasks in a resource-independent man-
ner, simpler and more efficient. One major pro-
spect of this work concerns its implementation.
As explained before, we must provide a high-
level language. It is also necessary to facilitate
the import and to optimize memory management.
In order to provide a less NLP-centered tool, we
should extend it with new operations, and with
algorithms related to classic problems of graph
theory. It would also be interesting to interact
with semantic web tools (RDF/SPARQL).
</bodyText>
<page confidence="0.997608">
72
</page>
<sectionHeader confidence="0.995876" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999841954545455">
Maristella Agosti and Fabio Crestani. 1993. A Meth-
odology for the Automatic Construction of a Hy-
pertext for Information Retrieval. In Proceedings
of 1993 ACM Symposium on Applied Computing,
745-753.
Ulrik Brandes, Markus Eiglsperger, Ivan Herman, Mi-
chael Himsolt and M. Scott Marshall. 2001.
GraphML Progress Report - Structural Layer Pro-
posal. In Proceedings of 9th International Sym-
posium Graph Drawing (GD&apos;01), 501-512.
Hany Hassan, Ahmed Hassan and Sara Noeman.
2006. Graph based semi-supervised approach for
information extraction. In Proceedings of HLT-
NAACL-07 Workshop on Textgraphs-06, 9-16.
Bruno Gaume, Karine Duvignau and Martine Van-
hove. 2008. Semantic associations and confluences
in paradigmatic networks. In Martine Vanhove
(Ed.), From Polysemy to Semantic Change To-
wards a typology of lexical semantic associations,
John Benjamins, 233-264.
Charles Sanders Peirce. 1931-1935. Collected Papers
of C. S. Peirce (C. Hartshorne &amp; P. Weiss, eds.),
Cambridge: Harvard University Press.
Alain Polguère. 2006. Structural Properties of Lexical
Systems: Monolingual and Multilingual Perspect-
ives. In Proceedings of Workshop on Multilingual
Language Resources and Interoperability (COL-
ING/ACL 2006), 50-59.
Stephen D. Richardson, William B. Dolan, and Lucy
Vanderwende. 1998. MindNet: acquiring and
structuring semantic information from text. In Pro-
ceedings of COLING 1998. 1098-1102.
John F. Sowa. 1976. Conceptual graphs for a database
interface. IBM Journal of Research and Develop-
ment 20:4, 336-357.
Dominic Widdows and Beate Dorow. 2002. A Graph
Model for Unsupervised Lexical Acquisition. In
Proceedings of 19th International Conference on
Computational Linguistics(COLING 2002). 1093-
1099.
Hans Friedrich Witschel. 2007. Multi-level Associ-
ation Graphs - A New Graph-Based Model for In-
formation Retrieval. In Proceedings of HLT-
NAACL-07 Workshop on Textgraphs-07, 9-16.
</reference>
<page confidence="0.999291">
73
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.416942">
<title confidence="0.998907">MuLLinG: multilevel linguistic graphs for knowledge extraction</title>
<author confidence="0.997386">Vincent Archer</author>
<affiliation confidence="0.592323">Laboratoire I3S (équipe RL), Université de Nice Sophia</affiliation>
<address confidence="0.559162">Sophia Antipolis, France</address>
<email confidence="0.989863">vincent.archer@unice.fr</email>
<abstract confidence="0.993850684210526">MuLLinG is a model for knowledge extraction (especially lexical extraction from corpora), based on multilevel graphs. Its aim is to allow large-scale data acquisition, by making it easy to realize automatically, and simple to configure by linguists with limited knowledge in computer programming. In MuLLinG, each new level represents the information in a different manner (more and more abstract). We also introduce several associated operators, written to be as generic as possible. They are independent of what nodes and edges represent, and of the task to achieve. Consequently, they allow the description of a complex extraction process as a succession of simple graph manipulations. Finally, we present an experiment of collocation extraction using MuLLinG model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Maristella Agosti</author>
<author>Fabio Crestani</author>
</authors>
<title>A Methodology for the Automatic Construction of a Hypertext for Information Retrieval.</title>
<date>1993</date>
<booktitle>In Proceedings of 1993 ACM Symposium on Applied Computing,</booktitle>
<pages>745--753</pages>
<contexts>
<context position="5120" citStr="Agosti and Crestani, 1993" startWordPosition="786" endWordPosition="789">hs. Another interesting network is the “lexical system” one (Polguère, 2006), defined as oriented, weighted, unhierarchical and, above all, heterogeneous: there is no constraint on what is modelized (it could be terms, meanings, collocations, etc.). It avoids the separation between dictionary-like and network-like lexical databases, and shows the same representation can be used for each kind of data and relation. Finally, graphs can be multilevel, to represent different kinds of information. Links are generally allowed only in a same level or between two adjacent levels, like in “hypertexts” (Agosti and Crestani, 1993) made of three specified levels (documents, terms, concepts), or in Multi-Level Association Graphs (Witschel, 2007) in which there is no constraint on the number of levels. We believe that the use of several levels to represent various content types is pertinent in an extraction process, as it allows to handle both the occurrences of terms, and the terms themselves. 3 MuLLinG model We introduce MuLLinG (Multi-Level Linguistic Graph), our own graph model. Divided in several ordered and distinct levels, it contains two kinds of edges: intra-level ones (between nodes from same level) and inter-le</context>
</contexts>
<marker>Agosti, Crestani, 1993</marker>
<rawString>Maristella Agosti and Fabio Crestani. 1993. A Methodology for the Automatic Construction of a Hypertext for Information Retrieval. In Proceedings of 1993 ACM Symposium on Applied Computing, 745-753.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrik Brandes</author>
<author>Markus Eiglsperger</author>
<author>Ivan Herman</author>
<author>Michael Himsolt</author>
<author>M Scott Marshall</author>
</authors>
<title>GraphML Progress Report - Structural Layer Proposal.</title>
<date>2001</date>
<booktitle>In Proceedings of 9th International Symposium Graph Drawing (GD&apos;01),</booktitle>
<pages>501--512</pages>
<contexts>
<context position="10666" citStr="Brandes et al., 2001" startWordPosition="1759" endWordPosition="1762">r copy (production of attributes for elements present in only one graph). To handle n-ary relations, we also provide a complex version of MuLLinG, where relations can be materialized. In that case, a relation is represented by a standard node and numbered argument edges linking that node to the arguments of the relation. It also allows the representation of relations between relations themselves. We made an implementation of MuLLinG as a C++ library1, based on Boost (open-source C++ libraries), especially for graph access and iterations. It can read and write MuLLinG graphs in GraphML format (Brandes et al., 2001). 4 Application to collocation extraction 4.1 Extraction process We realized several experiments using our library. We remind the reader that our goal was not to obtain the more efficient method for extraction, but rather to introduce tools for simplifying the programming of extraction tasks. We present here experiments about collocation extraction. Collocations are particular expressions where a term is chosen arbitrarily, depending on the other 1 Available at http://mulling.ligforge.imag.fr/ (under CeCILL free software license) 71 term, to express a particular meaning (like in “driving rain”</context>
</contexts>
<marker>Brandes, Eiglsperger, Herman, Himsolt, Marshall, 2001</marker>
<rawString>Ulrik Brandes, Markus Eiglsperger, Ivan Herman, Michael Himsolt and M. Scott Marshall. 2001. GraphML Progress Report - Structural Layer Proposal. In Proceedings of 9th International Symposium Graph Drawing (GD&apos;01), 501-512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hany Hassan</author>
<author>Ahmed Hassan</author>
<author>Sara Noeman</author>
</authors>
<title>Graph based semi-supervised approach for information extraction.</title>
<date>2006</date>
<booktitle>In Proceedings of HLTNAACL-07 Workshop on Textgraphs-06,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="3738" citStr="Hassan et al., 2006" startWordPosition="581" endWordPosition="584">multilingual corpora, dictionaries, etc.). It should also provide simple generic, task-independent, high-level operations that can be combined to describe a complex task. We choose to introduce a graph-based model. Graphs are understandable quickly by humans, easy to use in automatic processes, and flexible enough to represent various data types. Using graphs for knowledge extraction is quite classic. They can represent relations between words (produced by dependency analysers from corpora), and be used to produce semantically close terms (Widdows &amp; Dorrow, 2002) or to group similar n-tuples (Hassan et al., 2006). Graphs also can be 69 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 69–73, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics generated from dictionaries, and used to produce knowledge bases (Richardson et al., 1998) or proximity information (Gaume et al., 2006). 2.2 Existing graph models Influenced by “existential graphs” (Peirce, 1931- 1935) where relations between elements are represented by nodes, “conceptual graphs” (Sowa, 1976) are bipartite graphs with two node types: concepts and conceptual relati</context>
</contexts>
<marker>Hassan, Hassan, Noeman, 2006</marker>
<rawString>Hany Hassan, Ahmed Hassan and Sara Noeman. 2006. Graph based semi-supervised approach for information extraction. In Proceedings of HLTNAACL-07 Workshop on Textgraphs-06, 9-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Gaume</author>
<author>Karine Duvignau</author>
<author>Martine Vanhove</author>
</authors>
<title>Semantic associations and confluences in paradigmatic networks. In Martine Vanhove (Ed.), From Polysemy to Semantic Change Towards a typology of lexical semantic associations,</title>
<date>2008</date>
<journal>John Benjamins,</journal>
<pages>233--264</pages>
<marker>Gaume, Duvignau, Vanhove, 2008</marker>
<rawString>Bruno Gaume, Karine Duvignau and Martine Vanhove. 2008. Semantic associations and confluences in paradigmatic networks. In Martine Vanhove (Ed.), From Polysemy to Semantic Change Towards a typology of lexical semantic associations, John Benjamins, 233-264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sanders Peirce</author>
</authors>
<title>Collected Papers</title>
<date>1931</date>
<editor>of C. S. Peirce (C. Hartshorne &amp; P. Weiss, eds.),</editor>
<publisher>Harvard University Press.</publisher>
<location>Cambridge:</location>
<contexts>
<context position="4166" citStr="Peirce, 1931" startWordPosition="644" endWordPosition="645">tween words (produced by dependency analysers from corpora), and be used to produce semantically close terms (Widdows &amp; Dorrow, 2002) or to group similar n-tuples (Hassan et al., 2006). Graphs also can be 69 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 69–73, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics generated from dictionaries, and used to produce knowledge bases (Richardson et al., 1998) or proximity information (Gaume et al., 2006). 2.2 Existing graph models Influenced by “existential graphs” (Peirce, 1931- 1935) where relations between elements are represented by nodes, “conceptual graphs” (Sowa, 1976) are bipartite graphs with two node types: concepts and conceptual relations (edges only associate relations and concepts). That relation materialization is useful, as it allows to handle easily n-ary relations, without hypergraphs. Another interesting network is the “lexical system” one (Polguère, 2006), defined as oriented, weighted, unhierarchical and, above all, heterogeneous: there is no constraint on what is modelized (it could be terms, meanings, collocations, etc.). It avoids the separati</context>
</contexts>
<marker>Peirce, 1931</marker>
<rawString>Charles Sanders Peirce. 1931-1935. Collected Papers of C. S. Peirce (C. Hartshorne &amp; P. Weiss, eds.), Cambridge: Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alain Polguère</author>
</authors>
<title>Structural Properties of Lexical Systems: Monolingual and Multilingual Perspectives.</title>
<date>2006</date>
<booktitle>In Proceedings of Workshop on Multilingual Language Resources and Interoperability (COLING/ACL</booktitle>
<pages>50--59</pages>
<contexts>
<context position="4570" citStr="Polguère, 2006" startWordPosition="703" endWordPosition="704">enerated from dictionaries, and used to produce knowledge bases (Richardson et al., 1998) or proximity information (Gaume et al., 2006). 2.2 Existing graph models Influenced by “existential graphs” (Peirce, 1931- 1935) where relations between elements are represented by nodes, “conceptual graphs” (Sowa, 1976) are bipartite graphs with two node types: concepts and conceptual relations (edges only associate relations and concepts). That relation materialization is useful, as it allows to handle easily n-ary relations, without hypergraphs. Another interesting network is the “lexical system” one (Polguère, 2006), defined as oriented, weighted, unhierarchical and, above all, heterogeneous: there is no constraint on what is modelized (it could be terms, meanings, collocations, etc.). It avoids the separation between dictionary-like and network-like lexical databases, and shows the same representation can be used for each kind of data and relation. Finally, graphs can be multilevel, to represent different kinds of information. Links are generally allowed only in a same level or between two adjacent levels, like in “hypertexts” (Agosti and Crestani, 1993) made of three specified levels (documents, terms,</context>
</contexts>
<marker>Polguère, 2006</marker>
<rawString>Alain Polguère. 2006. Structural Properties of Lexical Systems: Monolingual and Multilingual Perspectives. In Proceedings of Workshop on Multilingual Language Resources and Interoperability (COLING/ACL 2006), 50-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen D Richardson</author>
<author>William B Dolan</author>
<author>Lucy Vanderwende</author>
</authors>
<title>MindNet: acquiring and structuring semantic information from text.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>1098--1102</pages>
<contexts>
<context position="4044" citStr="Richardson et al., 1998" startWordPosition="625" endWordPosition="628">exible enough to represent various data types. Using graphs for knowledge extraction is quite classic. They can represent relations between words (produced by dependency analysers from corpora), and be used to produce semantically close terms (Widdows &amp; Dorrow, 2002) or to group similar n-tuples (Hassan et al., 2006). Graphs also can be 69 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 69–73, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics generated from dictionaries, and used to produce knowledge bases (Richardson et al., 1998) or proximity information (Gaume et al., 2006). 2.2 Existing graph models Influenced by “existential graphs” (Peirce, 1931- 1935) where relations between elements are represented by nodes, “conceptual graphs” (Sowa, 1976) are bipartite graphs with two node types: concepts and conceptual relations (edges only associate relations and concepts). That relation materialization is useful, as it allows to handle easily n-ary relations, without hypergraphs. Another interesting network is the “lexical system” one (Polguère, 2006), defined as oriented, weighted, unhierarchical and, above all, heterogene</context>
</contexts>
<marker>Richardson, Dolan, Vanderwende, 1998</marker>
<rawString>Stephen D. Richardson, William B. Dolan, and Lucy Vanderwende. 1998. MindNet: acquiring and structuring semantic information from text. In Proceedings of COLING 1998. 1098-1102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John F Sowa</author>
</authors>
<title>Conceptual graphs for a database interface.</title>
<date>1976</date>
<journal>IBM Journal of Research and Development</journal>
<volume>20</volume>
<pages>336--357</pages>
<contexts>
<context position="4265" citStr="Sowa, 1976" startWordPosition="658" endWordPosition="659">se terms (Widdows &amp; Dorrow, 2002) or to group similar n-tuples (Hassan et al., 2006). Graphs also can be 69 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 69–73, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics generated from dictionaries, and used to produce knowledge bases (Richardson et al., 1998) or proximity information (Gaume et al., 2006). 2.2 Existing graph models Influenced by “existential graphs” (Peirce, 1931- 1935) where relations between elements are represented by nodes, “conceptual graphs” (Sowa, 1976) are bipartite graphs with two node types: concepts and conceptual relations (edges only associate relations and concepts). That relation materialization is useful, as it allows to handle easily n-ary relations, without hypergraphs. Another interesting network is the “lexical system” one (Polguère, 2006), defined as oriented, weighted, unhierarchical and, above all, heterogeneous: there is no constraint on what is modelized (it could be terms, meanings, collocations, etc.). It avoids the separation between dictionary-like and network-like lexical databases, and shows the same representation ca</context>
</contexts>
<marker>Sowa, 1976</marker>
<rawString>John F. Sowa. 1976. Conceptual graphs for a database interface. IBM Journal of Research and Development 20:4, 336-357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Beate Dorow</author>
</authors>
<title>A Graph Model for Unsupervised Lexical Acquisition.</title>
<date>2002</date>
<booktitle>In Proceedings of 19th International Conference on Computational Linguistics(COLING</booktitle>
<pages>1093--1099</pages>
<marker>Widdows, Dorow, 2002</marker>
<rawString>Dominic Widdows and Beate Dorow. 2002. A Graph Model for Unsupervised Lexical Acquisition. In Proceedings of 19th International Conference on Computational Linguistics(COLING 2002). 1093-1099.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Friedrich Witschel</author>
</authors>
<title>Multi-level Association Graphs - A New Graph-Based Model for Information Retrieval.</title>
<date>2007</date>
<booktitle>In Proceedings of HLTNAACL-07 Workshop on Textgraphs-07,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="5235" citStr="Witschel, 2007" startWordPosition="803" endWordPosition="804">d, above all, heterogeneous: there is no constraint on what is modelized (it could be terms, meanings, collocations, etc.). It avoids the separation between dictionary-like and network-like lexical databases, and shows the same representation can be used for each kind of data and relation. Finally, graphs can be multilevel, to represent different kinds of information. Links are generally allowed only in a same level or between two adjacent levels, like in “hypertexts” (Agosti and Crestani, 1993) made of three specified levels (documents, terms, concepts), or in Multi-Level Association Graphs (Witschel, 2007) in which there is no constraint on the number of levels. We believe that the use of several levels to represent various content types is pertinent in an extraction process, as it allows to handle both the occurrences of terms, and the terms themselves. 3 MuLLinG model We introduce MuLLinG (Multi-Level Linguistic Graph), our own graph model. Divided in several ordered and distinct levels, it contains two kinds of edges: intra-level ones (between nodes from same level) and inter-level ones (from a node on level i to a node on level i+1). Intra-level edges are not unique (several edges are allow</context>
</contexts>
<marker>Witschel, 2007</marker>
<rawString>Hans Friedrich Witschel. 2007. Multi-level Association Graphs - A New Graph-Based Model for Information Retrieval. In Proceedings of HLTNAACL-07 Workshop on Textgraphs-07, 9-16.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>