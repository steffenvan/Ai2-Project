<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000065">
<title confidence="0.974437">
Scaling Understanding up to Mental Spaces
</title>
<author confidence="0.956907">
Eva Mok, John Bryant, Jerome Feldman
</author>
<affiliation confidence="0.930576">
International Computer Science Institute
</affiliation>
<address confidence="0.8282535">
1947 Center Street Suite 600,
Berkeley, CA 94704
</address>
<email confidence="0.992454">
{emok, jbryant, jfeldman}@icsi.berkeley.edu
</email>
<sectionHeader confidence="0.998572" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999243041666667">
Mental Space Theory (Fauconnier, 1985) en-
compasses a wide variety of complex linguis-
tics phenomena that are largely ignored in to-
day’s natural language processing systems.
These phenomena include conditionals (e.g. If
sentences), embedded discourse, and other
natural language utterances whose interpreta-
tion depends on cognitive partitioning of con-
textual knowledge. A unification-based
formalism, Embodied Construction Grammar
(ECG) (Chang et al., 2002a) took initial steps
to include space as a primitive type, but most
of the details are yet to be worked out. The
goal of this paper is to present a scalable com-
putational account of mental spaces based on
the Neural Theory of Language (NTL) simu-
lation-based understanding framework (Nara-
yanan, 1999; Chang et al., 2002b). We
introduce a formalization of mental spaces
based on ECG, and describe how this formal-
ization fits into the NTL framework. We will
also use English Conditionals as a case study
to show how mental spaces can be parameter-
ized from language.
</bodyText>
<sectionHeader confidence="0.999631" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999991630434782">
There are two dimensions to scalability: improving sys-
tem performance (e.g. speed and size) for a fixed task,
and expanding the range of tasks that the system can
handle. Today’s natural language processing (NLP)
systems are not very scalable in the latter dimension.
They tend to ignore a wide range of cognitive linguistic
phenomena, notably those associated with mental
spaces, which are key to understanding any non-trivial
piece of natural language. Mental spaces (Fauconnier,
1985) are partial cognitive structures built up during
discourse that keep track of entities and relations in dif-
ferent contexts. Hypothetical reasoning, depictions (e.g.
stories, paintings or movies) and reasoning about other
minds are but a few examples where new mental spaces
are required. Mental spaces provide an important parti-
tioning of contextual knowledge that allows scalable
reasoning in a partitioned large knowledge base.
However, the literature on Mental Space Theory
does not address how these cognitive structures are
specified compositionally, let alone offering formaliza-
tions of mental space representations or computational
realizations. We thus seek to scale up the complexity of
natural language understanding (NLU) systems by pro-
posing a computational method of handling mental
spaces. In this paper we give a brief introduction to
Mental Space Theory (Section 2), and then explain how
Mental Space Theory can be incorporated into the exist-
ing Neural Theory of Language (NTL) simulation-based
understanding framework (Section 3). In this frame-
work, each mental space is a separate thread of simula-
tion. Each thread of simulation comprises a dynamic
structure combining knowledge, event models and be-
liefs that evolve over time.
The use of a simulation-based framework imposes
constraints on how mental spaces are represented, and
we introduce a formalization of mental spaces based on
Embodied Construction Grammar (ECG). As a case
study (Section 4), we will walk through the formaliza-
tion of English Conditionals (Dancygier and Sweetser,
2004) using mental space analysis. Through this case
study we illustrate how mental spaces are parameterized
compositionally by language, and capture this composi-
tionality succinctly using construction grammar. Then
with these formal tools, we address the issue of infer-
ence in mental spaces (Section 5), which is at the core
of the scaling up understanding.
</bodyText>
<sectionHeader confidence="0.989563" genericHeader="method">
2 Mental Space Theory
</sectionHeader>
<bodyText confidence="0.9940817">
Mental spaces refer to the partial cognitive structures
built up, usually through discourse, that provide a parti-
tioning of contextual as well as world knowledge. This
partitioning in turn affects what inferences can be
drawn. In traditional mental space analysis, certain
linguistic constructions called space builders may open
a new mental space or shift focus to an existing space.
Examples are in this picture..., Nancy thinks..., if it
rains..., back in the ’50s...(Fauconnier, 1997). Consider
the following sentence:
</bodyText>
<listItem confidence="0.9409415">
(1) In Harry’s painting of Paris, the Eiffel Tower is
only half-finished.
</listItem>
<bodyText confidence="0.99985825">
Harry’s painting creates a new Depiction-Space. The
Eiffel Tower is the only entity local to this Depiction-
Space, and it maps to the physical Eiffel Tower. How-
ever, only the Eiffel Tower in the Depiction-Space has
an additional attribute half-finished, and one should not
be led to think that the real Eiffel Tower is also half-
done. This kind of space-building is traditionally illus-
trated in diagrams similar to Figure 1.
</bodyText>
<figureCaption confidence="0.9745175">
Figure 1. The painting opens a Depiction-
Space where the Eiffel Tower is half-finished.
</figureCaption>
<bodyText confidence="0.999985230769231">
In the mental space literature, the transfer of as-
sumptions between spaces is guided by the presupposi-
tion float principle. The presupposition float principle
states that any presupposed structure in the parent space
can float to a child space unless it conflicts with struc-
ture already in that space. In the above example, any
attributes about the real Eiffel Tower can be assumed in
the Depiction-Space, as long as they do not depend on it
being finished. However, this account of assumption
and inference transfer is incomplete. Specifically, it is
incorrect to assume that different types of mental spaces
obey the same presupposition float principle. For exam-
ple, if we are having a conversation right now about
Harry’s painting, very little of what is currently happen-
ing should transfer into the Depiction-Space. On the
other hand, if we are having a conversation about our
plans for tomorrow, our current situation is very rele-
vant to our actions tomorrow, and this information
should carry over to the future space. The other key
piece that is missing from the presupposition float ac-
count is how inference is drawn across spaces in gen-
eral. Any computational account of mental spaces must
address this inference process precisely and supply a
formalized representation that inference can operate
with. We will outline such a computational solution in
the next two sections of this paper.
</bodyText>
<sectionHeader confidence="0.995209" genericHeader="method">
3 Simulation-Based Understanding
</sectionHeader>
<bodyText confidence="0.999280137254902">
A central piece of a scalable computational treatment of
mental spaces is a robust language understanding
framework. Our work relies on the NTL simulation-
based understanding paradigm (Narayanan, 1999;
Chang et al., 2002b), and extends the model in a con-
ceptually straightforward way. The simulation-based
understanding paradigm stipulates that, in addition to
constructional analysis of the surface form, language
understanding requires active simulation.
The constructional analysis is based on Embodied
Construction Grammar (Chang et al., 2002a) which con-
tains four primitive types: schemas, constructions, maps
and mental spaces. Schemas are the basic ECG unit of
meaning, capturing embodied concepts such as image
schemas, actions, and events. Constructions are the ba-
sic linguistic unit, pairing meaning schemas with repre-
sentations of linguistic form (words, clauses, etc.).
Maps and mental spaces are the subject of this paper,
and will be discussed in detail in the next section. It is
worth noting that in the ECG formalism, in addition to
support of an inheritance hierarchy (with the keyword
subcase of), there is also an evokes relation that makes
an outside structure accessible to a schema through a
local name. The evokes relation is neither a subcase-of
or part-of relation, but is analogous to spreading activa-
tion in the neural sense.
During analysis, a Semantic Specification (Sem-
Spec) is created from the meaning poles of the construc-
tions, and is essentially a network of schemas with the
appropriate roles bounded and filled in. Crucially,
within this network of schemas are executing schemas
(or X-schemas), which are models of events. They are
active structures for event-based asynchronous control
that can capture both sequential flow and concurrency.
Simulation is a dynamic process which includes
executing the X-schemas specified in the SemSpec and
propagating belief updates in a belief network. This
mechanism is used for metaphor understanding in (Na-
rayanan, 1999), and is being generalized to Coordinated
Probabilistic Relational Models (CPRM) in current ef-
forts (Narayanan, submitted). The CPRM mechanism is
discussed in more detail in Section 5.
Within a simulation-based understanding paradigm,
each mental space involves a new thread of simulation,
with its own separate belief network and simulation
trace. This is necessary for keeping track of possibly
contradictory beliefs, such as the alternative scenarios
where it is sunny or rainy tomorrow. Each alternative
scenario exists within its own mental space, and in
many situations, there can be a large number of alterna-
tives. However, not only is it computationally expensive
</bodyText>
<figure confidence="0.991921">
Parent-Space
painting Eiffel Tower
Depiction-Space
Eiffel Tower
(half-finished)
</figure>
<bodyText confidence="0.996149041666667">
to create a new thread of simulation, but cognitive ca-
pacity also constrains the number of concurrently open
spaces. We need both a cognitively plausible and com-
putationally feasible theory of how mental spaces are
manipulated.
The insight in addressing this problem is that at any
given level of granularity, not all spaces need to be
opened at the same time. Harry’s painting, in example
(1), may be represented at different granularity depend-
ing on the context. If it is discussed simply as a wall-
hanging, the Depiction-Space need not be expanded and
the painting should be treated schematically as an ob-
ject. However, once the contents of the painting are un-
der discussion (e.g., the trip to Paris during which the
painting was done), inference in a separate mental space
is required, and the Depiction-Space needs to be built.
As illustrated by this example, the simulation proc-
ess dictates the actual building of mental spaces. The
analysis process is responsible for supplying all the nec-
essary parameterization of the spaces and their corre-
sponding maps in case they need to be built. As a result,
each potential space-builder is represented at two levels
of granularity – as an object in its schematic form and as
a full mental space.
</bodyText>
<figure confidence="0.992394933333333">
SCHEMA Compressed-Mental-Space
ROLES
ums: Mental-Space
parent-space: Mental-Space
status
CONSTRAINTS
self ↔ ums.cms
SPACE Mental-Space
ROLES
cms: Compressed-Mental-Space
parent: Mental-Space
alternatives: Mental-Space
local-content
CONSTRAINTS
parent ↔ cms.parent-space
</figure>
<figureCaption confidence="0.9957725">
Figure 2. ECG notation for Compressed
and Uncompressed Mental Spaces
</figureCaption>
<bodyText confidence="0.99964645">
Formalizing this idea in ECG, mental spaces are
represented in two ways: as a compressed mental space
and an uncompressed version. In the ECG notation in
Figure 2, the Compressed-Mental-Space is just a
schema, and Mental-Space is of the space primitive
type. In each version there is pointer to its counterpart,
ums and cms respectively. The role parent-space points
to the parent of this space. The uncompressed mental
space contains the list of alternatives and the local-
content. Alternatives are scenarios that are different and
cannot co-exist, such as the different activities one
might be doing tomorrow at noon. Local-content
at noon. Local-content provides the local semantics of
mental spaces, maintaining a list of predications that are
true in this space, ceteris paribus. Each predication con-
tains a role local-to that denotes the space to which it
belongs. The predication is then automatically added to
the local-content of the space when this role is assigned.
Figure 3 shows an example of the Cause-Effect schema
with the cause, effect, and local-to role.
</bodyText>
<figure confidence="0.986124">
SCHEMA Cause-Effect
ROLES
Cause: Predication
Effect: Predication
local-to: Mental-Space
</figure>
<figureCaption confidence="0.993975">
Figure 3. Cause-Effect is a predication
that contains a pointer to a Mental-Space
</figureCaption>
<bodyText confidence="0.9997955">
In the next section, we will demonstrate the use of
the above formalization with a case study on conditional
sentences in English. In Section 5, we will discuss how
this representation supports the needed inference.
</bodyText>
<sectionHeader confidence="0.957796" genericHeader="method">
4 Case Study: English Conditionals
</sectionHeader>
<bodyText confidence="0.987974769230769">
One of the most common classes of space-building
expressions is the predictive conditional. Predictive
conditionals are sentences like
(2) If it rains tomorrow, the game will be cancelled.
They are space-builders, setting up a primary condi-
tional space and an alternative space1 (Dancygier and
Sweetser, 2004). As shown in Figure 4, in the primary
conditional space for tomorrow, it rains, and therefore
the game is cancelled. In the alternative space, it does
not rain, and the game is not cancelled.
This case study will focus on predictive conditionals
in English. An English predictive conditional is charac-
terized by tense backshifting in the if clause, i.e., the use
of the present tense for a future event. On the meaning
side, the condition and the conclusion are related by
some causal or enablement relationship.
In this section we will gradually build up to the Con-
ditional-Prediction construction by introducing the rele-
vant schemas and smaller constructions. It is important
to stress how construction grammar succinctly captures
how mental spaces can be parameterized in a composi-
tional way. The larger constructions supply information
about the spaces that is not contained in any of its
smaller constituents. Through compositionality, the
grammar becomes much more scalable in handling a
wide range of linguistic variations.
</bodyText>
<footnote confidence="0.628514">
1 Readers interested in the mental space analysis of other types
of English conditionals should refer to (Dancygier and Sweetser,
2004), as well a technical report for the formalization (Bryant and
Mok, 2003).
</footnote>
<figure confidence="0.7548315">
If it rains tomorrow, the game will be cancelled.
backshifting
</figure>
<figureCaption confidence="0.9845565">
Figure 4. A predictive conditional sets up
two spaces
</figureCaption>
<subsectionHeader confidence="0.967407">
4.1 Conditions
</subsectionHeader>
<bodyText confidence="0.997927230769231">
The condition, often preceding the conclusion in a con-
ditional statement, sets up or locates the space in which
the conclusion is to be placed. Therefore the Condi-
tional-Schema, given below, is a subcase of the Com-
pressed-Mental-Space. In addition to the inherited roles,
the Conditional-Schema has roles for a condition, a
premise, and a conclusion. The condition role stands for
the condition P as expressed, and premise can be P or
~P, depending on the conjunction. Finally, epistemic-
stance is the degree of commitment that the speaker is
making towards the condition happening, as indicated
by the choice of verb tense. For example, a sentence
such as If you got me a cup of coffee, I’d be grateful
</bodyText>
<figure confidence="0.460060727272727">
SCHEMA Conditional-Schema
SUBCASE OF Compressed-Mental-Space
ROLES
epistemic-stance
condition: Predication
premise: Predication
conclusion: Predication
ums: Conditional-Space
CONSTRAINTS
epistemic-stance H ums.epistemic-stance
premise H ums.premise
conclusion H ums.conclusion
SPACE Conditional-Space
SUBCASE OF Mental-Space
ROLES
cms: Conditional-Schema
epistemic-stance
premise: Predication
conclusion: Predication
CONSTRAINTS
premise.local-to F self
conclusion.local-to Å self
</figure>
<figureCaption confidence="0.9803525">
Figure 5. Conditional-Space has roles for
premise, conclusion and epistemic-stance
</figureCaption>
<bodyText confidence="0.999940333333333">
forever (Dancygier and Sweetser, 2004) has a negative
epistemic stance. The speaker makes a low commitment
(by using the past tense got) so as to not sound pre-
sumptuous, even though she may think that the ad-
dressee will very likely bring her coffee. On the other
hand, a counterfactual such as If I’d’ve known you were
coming, I’d’ve stayed home has a very negative epis-
temic stance. The speaker, in this case, implies that he
did not know the addressee was coming.
</bodyText>
<subsectionHeader confidence="0.997253">
4.2 The If construction
</subsectionHeader>
<bodyText confidence="0.999687076923077">
The abstract construction Conditional-Conjunction is a
supertype of lexical constructions If and other condi-
tionals conjunctions. Each conjunction leads to a differ-
ent way of parameterizing the spaces, therefore a
Conditional-Conjunction does not have meaning on its
own. Instead, it EVOKES two copies of the Conditional-
Schema, one as primary and one as alternative.
Given the Conditional-Conjunction and the Condi-
tional-Schemas it evokes, the If construction only needs
to hook up the correct premise and set the epistemic-
stance to neutral. The condition itself is not filled in
until a larger construction uses the Conditional-
Conjunction as a constituent.
</bodyText>
<sectionHeader confidence="0.5118365" genericHeader="method">
CONSTRUCTION Conditional-Conjunction
MEANING
</sectionHeader>
<table confidence="0.631287222222222">
EVOKES Conditional-Schema AS cs
EVOKES Conditional-Schema AS alt
lexical CONSTRUCTION If
SUBCASE OF Conditional-Conjunction
FORM: Word
self.f.orth Å &amp;quot;if&amp;quot;
MEANING
cs.premise H cs.condition
cs.epistemic-stance Å neutral
</table>
<figureCaption confidence="0.940858">
Figure 6. Conditional-Conjunctions evokes
two Conditional-Schemas. The If construction
identifies the premise with the condition in the
primary space
</figureCaption>
<subsectionHeader confidence="0.992004">
4.3 The Condition Construction
</subsectionHeader>
<bodyText confidence="0.999249777777778">
The Condition construction forms a Subordinate-Clause
from a Conditional-Conjunction and a Clause, such as If
it rains tomorrow from our game cancellation example
in (2). The most important aspect of this construction is
that it identifies its meaning pole (a Conditional-
Schema) with the Conditional-Schema that is evoked by
the Conditional-Conjunction, thereby preserving all the
constraints on the premise, epistemic-stance and status
that the conjunction sets up.
</bodyText>
<figure confidence="0.944670888888889">
Base-Space
neutral neutral
Alternative Space
It rains tomorrow
1
The game is cancelled
It does not rain tomorrow
1
The game is not cancelled
</figure>
<bodyText confidence="0.989362666666667">
In addition, it also fills in the content of the condition
role with the meaning of the Clause. It sets the parent-
space to the current focus-space.
</bodyText>
<figure confidence="0.994342454545454">
CONSTRUCTION Condition
SUBCASE OF Subordinate-Clause
CONSTRUCTIONAL
conj: Conditional-Conjunction
cl: Clause
FORM
conj meets cl
MEANING: Conditional-Schema
self.m H conj.m.cs
self.m.condition H cl.m
self.m.parent-space H focus-space
</figure>
<figureCaption confidence="0.99383">
Figure 7. The Condition construction fills
in the content of the condition role
</figureCaption>
<subsectionHeader confidence="0.986992">
4.4 Predictions
</subsectionHeader>
<bodyText confidence="0.98282575">
Predictions are not space builders in and of themselves.
Instead, they are simply events that are marked as fu-
ture. The Prediction-Schema is therefore not a subcase
of Compressed-Mental-Space. It includes a predicted-
event, which is a predication of category Event (denoted
through the evokes statement and the binding), and a
basis-of-prediction. A predicted event also has an asso-
ciated probability of happening, which may be supplied
linguistically (through hedges like perhaps or proba-
bly). This probability directly affects what inferences we
draw based on the prediction, and is captured by the
likelihood-of-predicted-event role.
</bodyText>
<figure confidence="0.924762666666667">
SCHEMA Prediction-Schema
EVOKES Event AS e
ROLES
predicted-event: Predication
likelihood-of-predicted-event
basis-of-prediction: Predication
CONSTRAINTS
predicted-event.category H e
predicted-event.time-location Å future
</figure>
<figureCaption confidence="0.996473">
Figure 8. Predictions are not space-
builders by themselves.
</figureCaption>
<subsectionHeader confidence="0.970702">
4.5 The Prediction Construction
</subsectionHeader>
<bodyText confidence="0.998113142857143">
The Prediction construction is a Clause that evokes a
Prediction-Schema in its meaning, such as the game will
be cancelled. The meaning pole of a Clause is a Predica-
tion. The nature of prediction requires that the time ref-
erence be future with respect to the viewpoint-space, in
this case, today. The meaning of the Prediction construc-
tion is itself the predicted-event.
</bodyText>
<figure confidence="0.9363865">
CONSTRUCTION Prediction
SUBCASE OF Clause
CONSTRUCTIONAL
time-reference Å relative-future (viewpoint-
space)
MEANING:
EVOKES Prediction-Schema AS ps
ps.predicted-event H self.m
</figure>
<figureCaption confidence="0.988504">
Figure 9. The Prediction construction
makes itself the predicted-event in the
Prediction-Schema
</figureCaption>
<subsectionHeader confidence="0.992601">
4.6 Conditional Statements
</subsectionHeader>
<bodyText confidence="0.9717462">
Conditional-Statement is a very general construction
that puts a Condition and a Clause together, in unre-
stricted order. The most important thing to notice is that
this larger construction finally fills in the conclusion of
the Condition with the meaning pole of the statement.
</bodyText>
<figure confidence="0.9574475">
CONSTRUCTION Conditional-Statement
CONSTRUCTIONAL
cond: Condition
statement: Clause
MEANING
cond.conclusion H statement.m
</figure>
<figureCaption confidence="0.785191">
Figure 10. The Conditional-Statement
construction puts together a Condition and a
Clause
</figureCaption>
<subsectionHeader confidence="0.990426">
4.7 Predictive Conditionals
</subsectionHeader>
<bodyText confidence="0.999968181818182">
To a first approximation, a Conditional-Prediction is just
a special case of the Conditional-Statement where the
statement has to be a Prediction. However, extra care
has to be taken to ensure that the alternative spaces and
cause-effect relations between the premises and conclu-
sions are set up correctly.
Recall that the Conditional-Conjunction EVOKES two
Conditional-Schemas, which are either partially filled in
or not filled in at all. Intuitively, the goal of this con-
struction is to completely fill out these two schemas
(and their respective spaces), and put a Cause-Effect
relation between the premise and conclusion in the local-
content of each space.
A role alt is created with type Conditional-Schema to
capture the fact that there is an alternative space param-
eterized by this construction. alt is then identified with
the alternative Conditional-Schema evoked in the Condi-
tional-Conjunction. This allows the unused alternative
Conditional-Schema in the If construction to be filled in.
The complete filling out of both Conditional-
Schemas are done by identifying the premise in the al-
ternative schema with the negation of the premise in the
</bodyText>
<figure confidence="0.97391628">
CONSTRUCTION Conditional-Prediction
SUBCASE OF Conditional-Statement
CONSTRUCTIONAL
statement: Prediction
statement.time-reference F relative-future
(condition.time-reference)
MEANING:
EVOKES Cause-Effect AS ce-primary
EVOKES Cause-Effect AS ce-alternative
alt: Conditional-Schema
alt H cond.conj.alt
alt.premise H not(cond.premise)
alt.conclusion H not(cond.conclusion)
alt.epistemic-stance F opposite
(cond.epistemic-stance)
ce-primary.cause H cond.premise
ce-primary.effect H cond.conclusion
ce-primary.local-to F cond.msp
alt.msp.local-to F cond.msp.alternatives
ce-alternative.cause H not(cond.premise)
ce-alternative.effect H not(cond.conclusion)
ce-alternative F alt.msp
alt.msp.alternatives F cond.msp
ce-primary H assertion.ps.predicted-
event.ce1
</figure>
<figureCaption confidence="0.988722666666667">
Figure 11. The Conditional-Prediction
construction fills out the parameterization of
both the primary and alternative spaces
</figureCaption>
<bodyText confidence="0.9999545">
primary schema, and like-wise for the conclusion. The
epistemic-stance of the alternative schema is set to the
opposite of that in the primary. For example, the oppo-
site of a neutral stance is neutral, and the opposite of a
negative stance is a positive stance.
So far, the only things in the local-content of both
spaces are the premise and conclusion, which are just
predications without any relations between them. The
next two sections assert a Cause-Effect relation between
the respective premise and conclusion, and place that in
the local-content. It also adds the other space to its list
of alternatives.
Finally, the last statement identifies the primary
cause-effect with ce1 of the predicted-event (in the
Event schema), thereby filling in the cause of the pre-
dicted-event.
</bodyText>
<subsectionHeader confidence="0.970749">
4.8 Example
</subsectionHeader>
<bodyText confidence="0.999267454545455">
With the Conditional-Prediction construction and the
smaller constructions in hand, along with the related
schemas and spaces, we now return to example (2) in
the beginning of this section: If it rains tomorrow, the
game will be cancelled.
Figure 12 shows the schemas and mental spaces that
result from the analysis of this sentence. The first half of
the sentence, If it rains tomorrow, is an instance of the
Condition construction. The Conditional-Conjunction If
evokes a primary and an alternative Conditional-
Schema, and partially fills out the primary one. Specifi-
cally, the If construction sets the epistemic-stance to
neutral, and identifies the premise with the condition.
The Condition construction then fills in the condition
role with the meaning of the Clause it rains tomorrow.
For simplicity, the actual schemas for representing a
rain event are omitted from the diagram.
The second half of the sentence, the game will be
cancelled, is an instance of the Prediction construction.
The basic job that the Prediction construction performs
is to fill in the predicted-event with the actual predic-
tion, i.e., game cancellation tomorrow.
At this point, given a Condition with if and a Predic-
tion, an instance of the Conditional-Prediction construc-
tion is formed, and the diagram in Figure 12 is
completed. The predicted-event is filled into the conclu-
sion in the primary Conditional-Schema. The alternative
Conditional-Schema, previously untouched by If, now
gets the negated premise and conclusion. A primary
Cause-Effect (ce-Primary) is evoked and placed into the
local-content of the primary Conditional-Space, and
likewise for the alternative space. The two spaces are
then linked as alternatives.
</bodyText>
<sectionHeader confidence="0.99878" genericHeader="evaluation">
5 Inference and Scalability
</sectionHeader>
<bodyText confidence="0.999348962962963">
As we discussed in Section 3, the ECG simulation se-
mantics approach to NLU involves both dynamic simu-
lations and extensive belief propagation. This approach
leads to systems that are scalable in semantic depth. For
such systems to be practical, we also need them to be
scalable in size. In recent work, (Narayanan, submitted)
has shown how the dynamic simulations and belief
propagation techniques can be tightly coupled in a
highly scalable formalism called CPRM, Coordinated
Probabilistic Relation Models.
This same formalism also provides the tools for a
systematic treatment of inference across mental spaces,
which correspond to separate threads of simulation.
Returning to example (2) in the last section, If it rains
tomorrow, the game will be cancelled, we can now
make additional inference about the hypothetical sce-
nario and the actions of the participants involved. One
can ask, what if the game is cancelled and the partici-
pants need to plan for other activities? How will these
activities affect their actions today?
The CPRM mechanism elegantly handles the trans-
fer of assumptions and inferences needed to answer
such questions. While the varying types of mental
spaces have different rules of inference, all of the cou-
plings are of only two different types, both of which are
handled nicely by CPRM. Any two mental spaces will
be related either by some shared assumptions, some
</bodyText>
<page confidence="0.519154">
2
</page>
<figure confidence="0.999272653846154">
cond: Conditional-Schema
parent-space: Focus-Space (Base)
ums
alt: Conditional-Schema
parent-space:
ums
Prediction-Schema
predicted-event: Game will be cancelled
likelihood-of-prediction
basis-of-prediction
1
1
premise: It rains tomorrow
N1
2
N2
conclusion: Game will be cancelled
conclusion: Game will not be cancelled
status
status
Parent-Space
Local-content
cond.ums
alt.ums
Local-content:
Local-content:
1
N1
premise: It rains tomorrow
2
N2
conclusion: Game will be cancelled
1
N1
2
N2
alternatives
epistemic-stance: neutral
condition: It rains tomorrow
ce-Primary
cause
effect
neutral neutral
epistemic-stance: neutral
condition
premise: It doesn&apos;t rain tomorrow
conclusion: Game will not be
cancelled
premise: It doesn’t rain tomorrow
ce-Alternative
cause
effect
</figure>
<figureCaption confidence="0.99729">
Figure 12. If it rains tomorrow, the game will be cancelled.
</figureCaption>
<bodyText confidence="0.999962275862069">
influence links, or both. Since the CPRM formalism is
inherently nested, it is straightforward to have shared
spaces. For example, if several people are watching a
game and are talking about it, the progress of the game
is a (dynamic) shared space that is common ground for
all the speakers.
Influence links are the central primitive in all belief
networks, including CPRM. These encode the effect of
one attribute on the conditional probabilities of another
attribute. In the mental space context, we employ ex-
plicit influence links to encode the dependencies of one
space on attributes of another space. In the game cancel-
lation example, the participants can choose to further
plan for the scenario where it does rain. They might
pick a backup plan, for example going to the theater. If
this backup plan requires some resource (e.g. a discount
card), there should be an influence link back to the pre-
sent plan suggesting that the discount card be brought
along.
More generally, each particular kind of mental space
relation will have its own types of shared knowledge
and influence links. Some of these can be evoked by
particular constructions. For example: Harry never
agrees with Bob would set up dependency links between
our models of the minds of these two individuals. It
should be feasible to use these mechanisms to formalize
the informal insights in the Cognitive Linguistics litera-
ture and therefore significantly extend the range of
NLU.
</bodyText>
<sectionHeader confidence="0.999734" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99989554054054">
In this paper we have provided a computational realiza-
tion of mental spaces. Within a simulation-based under-
standing framework, a mental space corresponds to a
new thread of simulation, implementable using the Co-
ordinated Probabilistic Relational Model formalism.
Cognitive and computational constraints demand that
each mental space be represented at two levels of granu-
larity: as a schema (compressed-mental-space) and as a
full space. The analyzer, using constructions like the
ones shown in the case study, creates a Semantic Speci-
fication parameterizing the compressed and uncom-
pressed versions of each mental space. Simulation
determines the correct level of granularity to operate on,
and builds new mental spaces only when it is necessary
to perform inference in the new space. Once a new men-
tal space is built, shared spaces and influence links be-
tween any two mental spaces can be defined to allow
the transfer of inference between the spaces.
Our proposed formalization of mental spaces allows
systems to be scalable in both size and semantic depth:
(i) Our formalization makes explicit how mental spaces
partition contextual knowledge into manageable chunks,
thereby providing significant computational advantage.
(ii) By using Embodied Construction Grammar, our
formalization provides a compositional approach to
parameterizing mental spaces. Compositionality has the
advantage of allowing a small grammar to handle a
large degree of linguistic variation. (iii) During simula-
tion, new threads of simulation are built only as needed,
obeying cognitive capacity constraints as well as mak-
ing mental spaces computationally tractable. (iv) CPRM
provides a tightly coupled, scalable inference mecha-
nism that handles the couplings between mental spaces.
Our proposed mental space formalism thus provides a
precise and scalable means for handling a rich body of
complex linguistics phenomena beyond the reach of
current NLU systems.
</bodyText>
<sectionHeader confidence="0.999429" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99611896">
John Bryant and Eva Mok. 2003. Constructing English
Conditionals: Building Mental Spaces in ECG. Tech-
nical Report.
Nancy Chang, Jerome Feldman, Robert Porzel and
Keith Sanders. 2002. Scaling Cognitive Linguistics:
Formalisms for Language Understanding. First In-
ternational Workshop on Scalable Natural Language
Understanding (SCANALU 2002).
Nancy Chang, Srini Narayanan and Miriam R.L.
Petruck. 2002. From Frames to Inference. First In-
ternational Workshop on Scalable Natural Language
Understanding (SCANALU 2002).
Barbara Dancygier and Eve Sweetser. 2004. Mental
Spaces In Grammar: Conditional Constructions.
Cambridge University Press. In Press.
Gilles Fauconnier. 1985. Mental spaces: Aspects of
meaning construction in natural language. Cam-
bridge: MIT Press.
Gilles Fauconnier. 1997. Mappings in Thought and
Language. New York: Cambridge University Press.
Srini Narayanan. 1999. Moving Right Along: A Compu-
tational Model of Metaphoric Reasoning about
Events. Proceedings of the National Conference on
Artificial Intelligence (AAAI &apos;99), Orlando, Florida,
July 18-22, 1999, pp 121-128, AAAI Press, 1999.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.872846">
<title confidence="0.999955">Scaling Understanding up to Mental Spaces</title>
<author confidence="0.999651">Eva Mok</author>
<author confidence="0.999651">John Bryant</author>
<author confidence="0.999651">Jerome</author>
<affiliation confidence="0.999556">International Computer Science</affiliation>
<address confidence="0.989885">1947 Center Street Suite Berkeley, CA</address>
<email confidence="0.998803">emok@icsi.berkeley.edu</email>
<email confidence="0.998803">jbryant@icsi.berkeley.edu</email>
<email confidence="0.998803">jfeldman@icsi.berkeley.edu</email>
<abstract confidence="0.99536116">Mental Space Theory (Fauconnier, 1985) encompasses a wide variety of complex linguistics phenomena that are largely ignored in today’s natural language processing systems. phenomena include conditionals (e.g. sentences), embedded discourse, and other natural language utterances whose interpretation depends on cognitive partitioning of contextual knowledge. A unification-based formalism, Embodied Construction Grammar (ECG) (Chang et al., 2002a) took initial steps include a primitive type, but most of the details are yet to be worked out. The goal of this paper is to present a scalable computational account of mental spaces based on the Neural Theory of Language (NTL) simulation-based understanding framework (Narayanan, 1999; Chang et al., 2002b). We introduce a formalization of mental spaces based on ECG, and describe how this formalization fits into the NTL framework. We will also use English Conditionals as a case study to show how mental spaces can be parameterized from language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Bryant</author>
<author>Eva Mok</author>
</authors>
<title>Constructing English Conditionals: Building Mental Spaces in ECG.</title>
<date>2003</date>
<tech>Technical Report.</tech>
<contexts>
<context position="13592" citStr="Bryant and Mok, 2003" startWordPosition="2094" endWordPosition="2097">relevant schemas and smaller constructions. It is important to stress how construction grammar succinctly captures how mental spaces can be parameterized in a compositional way. The larger constructions supply information about the spaces that is not contained in any of its smaller constituents. Through compositionality, the grammar becomes much more scalable in handling a wide range of linguistic variations. 1 Readers interested in the mental space analysis of other types of English conditionals should refer to (Dancygier and Sweetser, 2004), as well a technical report for the formalization (Bryant and Mok, 2003). If it rains tomorrow, the game will be cancelled. backshifting Figure 4. A predictive conditional sets up two spaces 4.1 Conditions The condition, often preceding the conclusion in a conditional statement, sets up or locates the space in which the conclusion is to be placed. Therefore the Conditional-Schema, given below, is a subcase of the Compressed-Mental-Space. In addition to the inherited roles, the Conditional-Schema has roles for a condition, a premise, and a conclusion. The condition role stands for the condition P as expressed, and premise can be P or ~P, depending on the conjunctio</context>
</contexts>
<marker>Bryant, Mok, 2003</marker>
<rawString>John Bryant and Eva Mok. 2003. Constructing English Conditionals: Building Mental Spaces in ECG. Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Chang</author>
<author>Jerome Feldman</author>
<author>Robert Porzel</author>
<author>Keith Sanders</author>
</authors>
<title>Scaling Cognitive Linguistics: Formalisms for Language Understanding.</title>
<date>2002</date>
<booktitle>First International Workshop on Scalable Natural Language Understanding (SCANALU</booktitle>
<contexts>
<context position="676" citStr="Chang et al., 2002" startWordPosition="86" endWordPosition="89">yant, Jerome Feldman International Computer Science Institute 1947 Center Street Suite 600, Berkeley, CA 94704 {emok, jbryant, jfeldman}@icsi.berkeley.edu Abstract Mental Space Theory (Fauconnier, 1985) encompasses a wide variety of complex linguistics phenomena that are largely ignored in today’s natural language processing systems. These phenomena include conditionals (e.g. If sentences), embedded discourse, and other natural language utterances whose interpretation depends on cognitive partitioning of contextual knowledge. A unification-based formalism, Embodied Construction Grammar (ECG) (Chang et al., 2002a) took initial steps to include space as a primitive type, but most of the details are yet to be worked out. The goal of this paper is to present a scalable computational account of mental spaces based on the Neural Theory of Language (NTL) simulation-based understanding framework (Narayanan, 1999; Chang et al., 2002b). We introduce a formalization of mental spaces based on ECG, and describe how this formalization fits into the NTL framework. We will also use English Conditionals as a case study to show how mental spaces can be parameterized from language. 1 Introduction There are two dimensi</context>
<context position="6438" citStr="Chang et al., 2002" startWordPosition="993" endWordPosition="996">er key piece that is missing from the presupposition float account is how inference is drawn across spaces in general. Any computational account of mental spaces must address this inference process precisely and supply a formalized representation that inference can operate with. We will outline such a computational solution in the next two sections of this paper. 3 Simulation-Based Understanding A central piece of a scalable computational treatment of mental spaces is a robust language understanding framework. Our work relies on the NTL simulationbased understanding paradigm (Narayanan, 1999; Chang et al., 2002b), and extends the model in a conceptually straightforward way. The simulation-based understanding paradigm stipulates that, in addition to constructional analysis of the surface form, language understanding requires active simulation. The constructional analysis is based on Embodied Construction Grammar (Chang et al., 2002a) which contains four primitive types: schemas, constructions, maps and mental spaces. Schemas are the basic ECG unit of meaning, capturing embodied concepts such as image schemas, actions, and events. Constructions are the basic linguistic unit, pairing meaning schemas wi</context>
</contexts>
<marker>Chang, Feldman, Porzel, Sanders, 2002</marker>
<rawString>Nancy Chang, Jerome Feldman, Robert Porzel and Keith Sanders. 2002. Scaling Cognitive Linguistics: Formalisms for Language Understanding. First International Workshop on Scalable Natural Language Understanding (SCANALU 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Chang</author>
<author>Srini Narayanan</author>
<author>Miriam R L Petruck</author>
</authors>
<title>From Frames to Inference.</title>
<date>2002</date>
<booktitle>First International Workshop on Scalable Natural Language Understanding (SCANALU</booktitle>
<contexts>
<context position="676" citStr="Chang et al., 2002" startWordPosition="86" endWordPosition="89">yant, Jerome Feldman International Computer Science Institute 1947 Center Street Suite 600, Berkeley, CA 94704 {emok, jbryant, jfeldman}@icsi.berkeley.edu Abstract Mental Space Theory (Fauconnier, 1985) encompasses a wide variety of complex linguistics phenomena that are largely ignored in today’s natural language processing systems. These phenomena include conditionals (e.g. If sentences), embedded discourse, and other natural language utterances whose interpretation depends on cognitive partitioning of contextual knowledge. A unification-based formalism, Embodied Construction Grammar (ECG) (Chang et al., 2002a) took initial steps to include space as a primitive type, but most of the details are yet to be worked out. The goal of this paper is to present a scalable computational account of mental spaces based on the Neural Theory of Language (NTL) simulation-based understanding framework (Narayanan, 1999; Chang et al., 2002b). We introduce a formalization of mental spaces based on ECG, and describe how this formalization fits into the NTL framework. We will also use English Conditionals as a case study to show how mental spaces can be parameterized from language. 1 Introduction There are two dimensi</context>
<context position="6438" citStr="Chang et al., 2002" startWordPosition="993" endWordPosition="996">er key piece that is missing from the presupposition float account is how inference is drawn across spaces in general. Any computational account of mental spaces must address this inference process precisely and supply a formalized representation that inference can operate with. We will outline such a computational solution in the next two sections of this paper. 3 Simulation-Based Understanding A central piece of a scalable computational treatment of mental spaces is a robust language understanding framework. Our work relies on the NTL simulationbased understanding paradigm (Narayanan, 1999; Chang et al., 2002b), and extends the model in a conceptually straightforward way. The simulation-based understanding paradigm stipulates that, in addition to constructional analysis of the surface form, language understanding requires active simulation. The constructional analysis is based on Embodied Construction Grammar (Chang et al., 2002a) which contains four primitive types: schemas, constructions, maps and mental spaces. Schemas are the basic ECG unit of meaning, capturing embodied concepts such as image schemas, actions, and events. Constructions are the basic linguistic unit, pairing meaning schemas wi</context>
</contexts>
<marker>Chang, Narayanan, Petruck, 2002</marker>
<rawString>Nancy Chang, Srini Narayanan and Miriam R.L. Petruck. 2002. From Frames to Inference. First International Workshop on Scalable Natural Language Understanding (SCANALU 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Dancygier</author>
<author>Eve Sweetser</author>
</authors>
<title>Mental Spaces In Grammar: Conditional Constructions.</title>
<date>2004</date>
<publisher>Cambridge University Press. In Press.</publisher>
<contexts>
<context position="3305" citStr="Dancygier and Sweetser, 2004" startWordPosition="496" endWordPosition="499">corporated into the existing Neural Theory of Language (NTL) simulation-based understanding framework (Section 3). In this framework, each mental space is a separate thread of simulation. Each thread of simulation comprises a dynamic structure combining knowledge, event models and beliefs that evolve over time. The use of a simulation-based framework imposes constraints on how mental spaces are represented, and we introduce a formalization of mental spaces based on Embodied Construction Grammar (ECG). As a case study (Section 4), we will walk through the formalization of English Conditionals (Dancygier and Sweetser, 2004) using mental space analysis. Through this case study we illustrate how mental spaces are parameterized compositionally by language, and capture this compositionality succinctly using construction grammar. Then with these formal tools, we address the issue of inference in mental spaces (Section 5), which is at the core of the scaling up understanding. 2 Mental Space Theory Mental spaces refer to the partial cognitive structures built up, usually through discourse, that provide a partitioning of contextual as well as world knowledge. This partitioning in turn affects what inferences can be draw</context>
<context position="12352" citStr="Dancygier and Sweetser, 2004" startWordPosition="1898" endWordPosition="1901">se-Effect is a predication that contains a pointer to a Mental-Space In the next section, we will demonstrate the use of the above formalization with a case study on conditional sentences in English. In Section 5, we will discuss how this representation supports the needed inference. 4 Case Study: English Conditionals One of the most common classes of space-building expressions is the predictive conditional. Predictive conditionals are sentences like (2) If it rains tomorrow, the game will be cancelled. They are space-builders, setting up a primary conditional space and an alternative space1 (Dancygier and Sweetser, 2004). As shown in Figure 4, in the primary conditional space for tomorrow, it rains, and therefore the game is cancelled. In the alternative space, it does not rain, and the game is not cancelled. This case study will focus on predictive conditionals in English. An English predictive conditional is characterized by tense backshifting in the if clause, i.e., the use of the present tense for a future event. On the meaning side, the condition and the conclusion are related by some causal or enablement relationship. In this section we will gradually build up to the Conditional-Prediction construction </context>
<context position="15030" citStr="Dancygier and Sweetser, 2004" startWordPosition="2294" endWordPosition="2297"> of coffee, I’d be grateful SCHEMA Conditional-Schema SUBCASE OF Compressed-Mental-Space ROLES epistemic-stance condition: Predication premise: Predication conclusion: Predication ums: Conditional-Space CONSTRAINTS epistemic-stance H ums.epistemic-stance premise H ums.premise conclusion H ums.conclusion SPACE Conditional-Space SUBCASE OF Mental-Space ROLES cms: Conditional-Schema epistemic-stance premise: Predication conclusion: Predication CONSTRAINTS premise.local-to F self conclusion.local-to Å self Figure 5. Conditional-Space has roles for premise, conclusion and epistemic-stance forever (Dancygier and Sweetser, 2004) has a negative epistemic stance. The speaker makes a low commitment (by using the past tense got) so as to not sound presumptuous, even though she may think that the addressee will very likely bring her coffee. On the other hand, a counterfactual such as If I’d’ve known you were coming, I’d’ve stayed home has a very negative epistemic stance. The speaker, in this case, implies that he did not know the addressee was coming. 4.2 The If construction The abstract construction Conditional-Conjunction is a supertype of lexical constructions If and other conditionals conjunctions. Each conjunction l</context>
</contexts>
<marker>Dancygier, Sweetser, 2004</marker>
<rawString>Barbara Dancygier and Eve Sweetser. 2004. Mental Spaces In Grammar: Conditional Constructions. Cambridge University Press. In Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilles Fauconnier</author>
</authors>
<title>Mental spaces: Aspects of meaning construction in natural language.</title>
<date>1985</date>
<publisher>MIT Press.</publisher>
<location>Cambridge:</location>
<contexts>
<context position="1742" citStr="Fauconnier, 1985" startWordPosition="263" endWordPosition="264">e will also use English Conditionals as a case study to show how mental spaces can be parameterized from language. 1 Introduction There are two dimensions to scalability: improving system performance (e.g. speed and size) for a fixed task, and expanding the range of tasks that the system can handle. Today’s natural language processing (NLP) systems are not very scalable in the latter dimension. They tend to ignore a wide range of cognitive linguistic phenomena, notably those associated with mental spaces, which are key to understanding any non-trivial piece of natural language. Mental spaces (Fauconnier, 1985) are partial cognitive structures built up during discourse that keep track of entities and relations in different contexts. Hypothetical reasoning, depictions (e.g. stories, paintings or movies) and reasoning about other minds are but a few examples where new mental spaces are required. Mental spaces provide an important partitioning of contextual knowledge that allows scalable reasoning in a partitioned large knowledge base. However, the literature on Mental Space Theory does not address how these cognitive structures are specified compositionally, let alone offering formalizations of mental</context>
</contexts>
<marker>Fauconnier, 1985</marker>
<rawString>Gilles Fauconnier. 1985. Mental spaces: Aspects of meaning construction in natural language. Cambridge: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilles Fauconnier</author>
</authors>
<date>1997</date>
<booktitle>Mappings in Thought and Language.</booktitle>
<publisher>Cambridge University Press.</publisher>
<location>New York:</location>
<contexts>
<context position="4169" citStr="Fauconnier, 1997" startWordPosition="630" endWordPosition="631">the issue of inference in mental spaces (Section 5), which is at the core of the scaling up understanding. 2 Mental Space Theory Mental spaces refer to the partial cognitive structures built up, usually through discourse, that provide a partitioning of contextual as well as world knowledge. This partitioning in turn affects what inferences can be drawn. In traditional mental space analysis, certain linguistic constructions called space builders may open a new mental space or shift focus to an existing space. Examples are in this picture..., Nancy thinks..., if it rains..., back in the ’50s...(Fauconnier, 1997). Consider the following sentence: (1) In Harry’s painting of Paris, the Eiffel Tower is only half-finished. Harry’s painting creates a new Depiction-Space. The Eiffel Tower is the only entity local to this DepictionSpace, and it maps to the physical Eiffel Tower. However, only the Eiffel Tower in the Depiction-Space has an additional attribute half-finished, and one should not be led to think that the real Eiffel Tower is also halfdone. This kind of space-building is traditionally illustrated in diagrams similar to Figure 1. Figure 1. The painting opens a DepictionSpace where the Eiffel Tower</context>
</contexts>
<marker>Fauconnier, 1997</marker>
<rawString>Gilles Fauconnier. 1997. Mappings in Thought and Language. New York: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
</authors>
<title>Moving Right Along: A Computational Model of Metaphoric Reasoning about Events.</title>
<date>1999</date>
<booktitle>Proceedings of the National Conference on Artificial Intelligence (AAAI &apos;99),</booktitle>
<pages>121--128</pages>
<publisher>AAAI Press,</publisher>
<location>Orlando, Florida,</location>
<contexts>
<context position="975" citStr="Narayanan, 1999" startWordPosition="139" endWordPosition="141">ural language processing systems. These phenomena include conditionals (e.g. If sentences), embedded discourse, and other natural language utterances whose interpretation depends on cognitive partitioning of contextual knowledge. A unification-based formalism, Embodied Construction Grammar (ECG) (Chang et al., 2002a) took initial steps to include space as a primitive type, but most of the details are yet to be worked out. The goal of this paper is to present a scalable computational account of mental spaces based on the Neural Theory of Language (NTL) simulation-based understanding framework (Narayanan, 1999; Chang et al., 2002b). We introduce a formalization of mental spaces based on ECG, and describe how this formalization fits into the NTL framework. We will also use English Conditionals as a case study to show how mental spaces can be parameterized from language. 1 Introduction There are two dimensions to scalability: improving system performance (e.g. speed and size) for a fixed task, and expanding the range of tasks that the system can handle. Today’s natural language processing (NLP) systems are not very scalable in the latter dimension. They tend to ignore a wide range of cognitive lingui</context>
<context position="6418" citStr="Narayanan, 1999" startWordPosition="991" endWordPosition="992">re space. The other key piece that is missing from the presupposition float account is how inference is drawn across spaces in general. Any computational account of mental spaces must address this inference process precisely and supply a formalized representation that inference can operate with. We will outline such a computational solution in the next two sections of this paper. 3 Simulation-Based Understanding A central piece of a scalable computational treatment of mental spaces is a robust language understanding framework. Our work relies on the NTL simulationbased understanding paradigm (Narayanan, 1999; Chang et al., 2002b), and extends the model in a conceptually straightforward way. The simulation-based understanding paradigm stipulates that, in addition to constructional analysis of the surface form, language understanding requires active simulation. The constructional analysis is based on Embodied Construction Grammar (Chang et al., 2002a) which contains four primitive types: schemas, constructions, maps and mental spaces. Schemas are the basic ECG unit of meaning, capturing embodied concepts such as image schemas, actions, and events. Constructions are the basic linguistic unit, pairin</context>
<context position="8215" citStr="Narayanan, 1999" startWordPosition="1265" endWordPosition="1267"> Specification (SemSpec) is created from the meaning poles of the constructions, and is essentially a network of schemas with the appropriate roles bounded and filled in. Crucially, within this network of schemas are executing schemas (or X-schemas), which are models of events. They are active structures for event-based asynchronous control that can capture both sequential flow and concurrency. Simulation is a dynamic process which includes executing the X-schemas specified in the SemSpec and propagating belief updates in a belief network. This mechanism is used for metaphor understanding in (Narayanan, 1999), and is being generalized to Coordinated Probabilistic Relational Models (CPRM) in current efforts (Narayanan, submitted). The CPRM mechanism is discussed in more detail in Section 5. Within a simulation-based understanding paradigm, each mental space involves a new thread of simulation, with its own separate belief network and simulation trace. This is necessary for keeping track of possibly contradictory beliefs, such as the alternative scenarios where it is sunny or rainy tomorrow. Each alternative scenario exists within its own mental space, and in many situations, there can be a large nu</context>
</contexts>
<marker>Narayanan, 1999</marker>
<rawString>Srini Narayanan. 1999. Moving Right Along: A Computational Model of Metaphoric Reasoning about Events. Proceedings of the National Conference on Artificial Intelligence (AAAI &apos;99), Orlando, Florida, July 18-22, 1999, pp 121-128, AAAI Press, 1999.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>