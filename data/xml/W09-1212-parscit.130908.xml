<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001189">
<title confidence="0.997952">
A Second-Order Joint Eisner Model for Syntactic and Semantic Dependency
Parsing
</title>
<author confidence="0.98684">
Xavier Lluis Stefan Bott Lluis M`arquez
</author>
<affiliation confidence="0.9846535">
TALP Research Center – Software Department (LSI)
Technical University of Catalonia (UPC)
</affiliation>
<email confidence="0.998508">
{xlluis,sbott,lluism}@lsi.upc.edu
</email>
<sectionHeader confidence="0.99561" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998435357142857">
We present a system developed for the
CoNLL-2009 Shared Task (Hajiˇc et al., 2009).
We extend the Carreras (2007) parser to
jointly annotate syntactic and semantic depen-
dencies. This state-of-the-art parser factor-
izes the built tree in second-order factors. We
include semantic dependencies in the factors
and extend their score function to combine
syntactic and semantic scores. The parser is
coupled with an on-line averaged perceptron
(Collins, 2002) as the learning method. Our
averaged results for all seven languages are
71.49 macro Fl, 79.11 LAS and 63.06 seman-
tic Fl.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.990918352941176">
Systems that jointly annotate syntactic and semantic
dependencies were introduced in the past CoNLL-
2008 Shared Task (Surdeanu et al., 2008). These
systems showed promising results and proved the
feasibility of a joint syntactic and semantic pars-
ing (Henderson et al., 2008; Lluis and M`arquez,
2008).
The Eisner (1996) algorithm and its variants are
commonly used in data-driven dependency pars-
ing. Improvements of this algorithm presented
by McDonald et al. (2006) and Carreras (2007)
achieved state-of-the-art performance for English in
the CoNLL-2007 Shared Task (Nivre et al., 2007).
Johansson and Nugues (2008) presented a sys-
tem based on the Carreras’ extension of the Eis-
ner algorithm that ranked first in the past CoNLL-
2008 Shared Task. We decided to extend the Car-
</bodyText>
<page confidence="0.979683">
79
</page>
<bodyText confidence="0.998879642857143">
reras (2007) parser to jointly annotate syntactic and
semantic dependencies.
The present year Shared Task has the incentive
of being multilingual with each language presenting
their own particularities. An interesting particularity
is the direct correspondence between syntactic and
semantic dependencies provided in Catalan, Spanish
and Chinese. We believe that these correspondences
can be captured by a joint system. We specially look
at the syntactic-semantic alignment of the Catalan
and Spanish datasets.
Our system is an extension of the Lluis and
M`arquez (2008) CoNLL-2008 Shared Task system.
We introduce these two following novelties:
</bodyText>
<listItem confidence="0.976915166666667">
• An extension of the second-order Car-
reras (2007) algorithm to annotate semantic
dependencies.
• A combined syntactic-semantic scoring for
Catalan and Spanish to exploit the syntactic-
semantic mappings.
</listItem>
<bodyText confidence="0.999268">
The following section outlines the system archi-
tecture. The next sections present in more detail the
system novelties.
</bodyText>
<sectionHeader confidence="0.991959" genericHeader="introduction">
2 Architecture
</sectionHeader>
<bodyText confidence="0.999536428571429">
The architecture consists on four main components:
1) Preprocessing and feature extraction. 2) Syntactic
preparsing. 3) Joint syntactic-semantic parsing. 4)
Predicate classification.
The preprocessing and feature extraction is in-
tended to ease and improve the performance of
the parser precomputing a binary representation of
</bodyText>
<note confidence="0.5805375">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 79–84,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999594772727273">
each sentence features. These features are borrowed
from existing and widely-known systems (Xue and
Palmer, 2004; McDonald et al., 2005; Carreras et al.,
2006; Surdeanu et al., 2007).
The following step is a syntactic pre-parse. It
is only required to pre-compute additional features
(e.g., syntactic path, syntactic frame) from the syn-
tax. These new features will be used for the semantic
role component of the following joint parser.
The joint parser is the core of the system. This
single algorithm computes the complete parse that
optimizes a score according to a function that de-
pends on both syntax and semantics. Some of the
required features that could be unavailable or expen-
sive to compute at that time are provided by the pre-
vious syntactic pre-parse.
The predicate sense classification is performed as
the last step. Therefore no features representing the
predicate sense are employed during the training.
The predicates are labeled with the most frequent
sense extracted from the training corpus.
No further postprocessing is applied.
</bodyText>
<sectionHeader confidence="0.983398" genericHeader="method">
3 Second-order Eisner model
</sectionHeader>
<bodyText confidence="0.9999644">
The Carreras’ extension of the Eisner inference al-
gorithm is an expensive O(n4) parser. The number
of assignable labels for each dependency is a hidden
multiplying constant in this asymptotic cost.
We begin describing a first-order dependency
parser. It receives a sentence x and outputs a de-
pendency tree y. A dependency, or first-order factor,
is defined as f1 = (h, m, l). Where h is the head
token, m the modifier and l the syntactic label. The
score for this factor f1 is computed as:
</bodyText>
<equation confidence="0.671439">
score1(f1, x, w) = 0(h, m, x) &apos; w(l)
</equation>
<bodyText confidence="0.77408425">
Where w(l) is the weight vector for the syntactic la-
bel l and 0 a feature extraction function.
The parser outputs the best tree y* from the set
T (x) of all projective dependency trees.
</bodyText>
<equation confidence="0.994641">
1: y*(x) = argmax score(f1, x, w)
yET (x) f1Ey
</equation>
<bodyText confidence="0.999508666666667">
The second-order extension decomposes the de-
pendency tree in factors that include some children
of the head and modifier. A second-order factor is:
</bodyText>
<equation confidence="0.617776">
f2 = (h, m, l, ch, cmo, cmi)
</equation>
<bodyText confidence="0.9887992">
where ch is the daughter of h closest to m within
the tokens [h, ... , m]; cmo is the outermost daugh-
ter of m outside [h, ... , m]; and cmi is the furthest
daughter of m inside [h, ... , m].
The score for these new factors is computed by
</bodyText>
<equation confidence="0.973458">
score2(f2, x, w) = 0(h, m, x) &apos; w(l) +
0(h, m, ch, x) &apos; w(l)
ch +
0(h, m, cmi, x) &apos; w(l)
cmi +
0(h, m, cmo, x) &apos; w(l)
cmo
</equation>
<bodyText confidence="0.9994145">
The parser builds the best-scoring projective tree
factorized in second-order factors. The score of the
tree is also defined as the sum of the score of its
factors.
</bodyText>
<subsectionHeader confidence="0.9997">
3.1 Joint second-order model
</subsectionHeader>
<bodyText confidence="0.9993025">
We proceeded in an analogous way in which the
Lluis and M`arquez (2008) extended the first-order
parser. That previous work extended a first-order
model by including semantic labels in first-order de-
pendencies.
Now we define a second-order joint factor as:
</bodyText>
<equation confidence="0.670531">
f2syn-sem =
(h, m, l, ch, cmo, cmi, lsemp1, ... , lsempq )
</equation>
<bodyText confidence="0.9995579">
Note that we only added a set of semantic labels
lsemp1, . . . , lsempq to the second-order factor. Each
one of these semantic labels represent, if any, one
semantic relation between the argument m and the
predicate pi. There are q predicates in the sentence,
labeled p1, ... , pq.
The corresponding joint score to a given joint fac-
tor is computed by adding a semantic score to the
previously defined score2 second-order score func-
tion:
</bodyText>
<equation confidence="0.693866333333333">
score2syn-sem(f2syn-sem, x, w) =
score2(f2, x, w) +
scoresem(h, m, pi, lsempi, x, w)
q
where,
scoresem(h, m, pi, lsem, x, w) =
0sem(h, m,pi, x) &apos; w(lsem)
1:
pi
</equation>
<page confidence="0.936477">
80
</page>
<bodyText confidence="0.996246285714286">
We normalize the semantic score by the number
of predicates q. The semantic score is computed as a
score between m and each sentence predicate pi. No
second-order relations are considered in these score
functions. The search of the best ch, cmo and cmi is
independent of the semantic components of the fac-
tor. The computational cost of the algorithm is in-
creased by one semantic score function call for every
m, h, and pi combination. The asymptotic cost of
this operation is O(q · n2) and it is sequentially per-
formed among other O(n2) operations in the main
loop of the algorithm.
Algorithm 1 Extension of the Carreras (2007) algo-
rithm
</bodyText>
<equation confidence="0.949571380952381">
C[s][t][d][m] ← 0, ∀s, t, d, m
O[s][t][d][l] ← 0, ∀s, t, d, l
fork= 1,...,n do
for s = 0,...,n − k do
t ← s + k
∀l O[s][t][←][l] = maxr,cmi,ch
C[s][r][→][cmi] + C[r + 1][t][←][ch]
+score(t, s, l)+scorecmi(t, s, cmi, l)+
scorech(t, s, l, ch)+
Epi maxl3e„tscoresem(t, s, pi, lsem)/q
∀l O[s][t][→][l] = maxr,cmi,ch
C[s][r][→][ch] + C[r + 1][t][←][cmi]+
score(s, t, l)+scorecmi(s, t, cmi, l)+
scorech(s, t,l, ch)+
Epi maxl3e„tscoresem(t, s, pi, lsem)/q
∀m C[s][t][←][m] = maxl,cmo
C[s][m][←][cmo] + O[m][t][←][l]+
scorecmo(s, m,l, cmo)
∀m C[s][t][→][m] = maxl,cmo
O[s][m][→][l] + C[m][t][→][cmo]+
scorecmo(m, t,l, cmo)
</equation>
<listItem confidence="0.4227475">
end for
end for
</listItem>
<bodyText confidence="0.999864060606061">
Our implementation slightly differs from the orig-
inal Carreras algorithm description. The main dif-
ference is that no specific features are extracted for
the second-order factors. This allows us to reuse the
feature extraction mechanism of a first-order parser.
Algorithm 1 shows the Carreras’ extension of the
Eisner algorithm including our proposed joint se-
mantic scoring.
The tokens s and t represent the start and end
tokens of the current substring, also called span.
The direction d ∈ {←, →} defines whether t or
s is the head of the last dependency built inside
the span. The score functions scorech,scorecmi and
scorecmo are the linear functions that build up the
previously defined second-order global score, e.g.,
scorech= φ(h, m, ch, x)·w(l)
ch . The two tables C and
O maintain the dynamic programming structures.
Note that the first steps of the inner loop are ap-
plied for all l, the syntactic label, but the semantic
score function does not depend on l. Therefore the
best semantic label can be chosen independently.
For simplicity, we omitted the weight vectors re-
quired in each score function and the backpointers
tables to save the local decisions. We also omit-
ted the definition of the domain of some variables.
Moreover, the filter of the set of assignable labels
is not shown. A basic filter regards the POS of the
head and modifier to filter out the set of possible ar-
guments for each predicate. Another filter extract
the set of allowed arguments for each predicate from
the frames files. These last filters were applied to the
English, German and Chinese.
</bodyText>
<subsectionHeader confidence="0.997752">
3.2 Catalan and Spanish joint model
</subsectionHeader>
<bodyText confidence="0.9999467">
The Catalan and Spanish datasets (Taul´e et al., 2008)
present two interesting properties. The first prop-
erty, as previously said, is a direct correspondence
between syntactic and semantic labels. The second
interesting property is that all semantic dependen-
cies exactly overlap with the syntactic tree. Thus
the semantic dependency between a predicate and
an argument always has a matching syntactic depen-
dency between a head and a modifier. The Chinese
data also contains direct syntactic-semantic map-
pings. But due to the Shared Task time constraints
we did not implemented a specific parsing method
for this language.
The complete overlap between syntax and seman-
tics can simplify the definition of a second-order
joint factor. In this case, a second-order factor will
only have, if any, one semantic dependency. We only
allow at most one semantic relation lsem between
the head token h and the modifier m. Note that h
must be a sentence predicate and m its argument if
</bodyText>
<page confidence="0.993479">
81
</page>
<bodyText confidence="0.998618">
lsem is not null. We extend the second-order fac-
tors with a single and possibly null semantic label,
i.e., f2syn-sem = (h, m,l, ch, cmo, cmi, lsem). This
slightly simplifies the scoring function:
</bodyText>
<equation confidence="0.962440666666667">
score2syn-sem(f2syn-sem, x, w) =
score2(f2, x, w) +
α · scoresem(h, m, x, w)
</equation>
<bodyText confidence="0.999118096774194">
where α is an adjustable parameter of the model and,
scoresem(h, m, x, w) = φsem(h, m, x) · w(lsem)
The next property that we are intended to exploit
is the syntactic-semantic mappings. These map-
pings define the allowed combinations of syntactic
and semantic labels. The label combinations can
only be exploited when there is semantic depen-
dency between the head h and the modifier m of a
factor. An argument identification classifier deter-
mines the presence of a semantic relation, given h
is a predicate. In these cases we only generate fac-
tors that are compliant with the mappings. If a syn-
tactic label has many corresponding semantic labels
we will score all of them and select the combination
with the highest score.
The computational cost is not significantly in-
creased as there is a bounded number of syntactic
and semantic combinations to score. In addition, the
only one-argument-per-factor constraint reduces the
complexity of the algorithm with respect to the pre-
vious joint extension.
We found some inconsistencies in the frames files
provided by the organizers containing the correspon-
dences between syntax and semantics. For this rea-
son we extracted them directly from the corpus. The
extracted mappings discard the 7.9% of the cor-
rect combinations in the Catalan development cor-
pus that represent a 1.7% of its correct syntactic de-
pendencies. The discarded semantic labels are the
5.14% for Spanish representing the 1.3% of the syn-
tactic dependencies.
</bodyText>
<sectionHeader confidence="0.9996" genericHeader="evaluation">
4 Results and discussion
</sectionHeader>
<bodyText confidence="0.998106326530612">
Table 1 shows the official results for all seven lan-
guages, including out-of-domain data labeled as
ood. The high computational cost of the second-
order models prevented us from carefully tuning the
system parameters. After the shared task evaluation
deadline, some bug were corrected, improving the
system performance. The last results are shown in
parenthesis.
The combined filters for Catalan and Spanish hurt
the parsing due to the discarded correct labels but
we believe that this effect is compensated by an im-
proved precision in the cases where the correct la-
bels are not discarded. For example, in Spanish
these filters improved the syntactic LAS from 85.34
to 86.77 on the development corpus using the gold
syntactic tree as the pre-parse tree.
Figure 1 shows the learning curve for the English
and Czech language. The results are computed in
the development corpus. The semantic score is com-
puted using gold syntax and gold predicate sense
classification. We restricted the learning curve to
the first epoch. Although the this first epoch is very
close to the best score, some languages showed im-
provements until the fourth epoch. In the figure we
can see better syntactic results for the joint system
with respect to the syntactic-only parser. We should
not consider this improvement completely realistic
as the semantic component of the joint system uses
gold features (i.e., a gold pre-parse). Nonetheless,
it points that a highly accurate semantic component
could improve the syntax.
Table 2 shows the training time for a second-order
syntactic and joint configurations of the parser. Note
that the time per instance is an average and some
sentences could require a significantly higher time.
Recall that our parser is O(n4) dependant on the
sentence length. We discarded large sentences dur-
ing training for efficiency reasons. We discarded
sentences with more than 70 words for all languages
except for Catalan and Spanish where the thresh-
old was set to 100 words in the syntactic parser.
This larger number of sentences is aimed to im-
prove the syntactic performance of these languages.
The shorter sentences used in the joint parsing and
the pruning of the previously described filters re-
duced the training time for Catalan and Spanish. The
amount of main memory consumed by the system is
0.5–1GB. The machine used to perform the compu-
tations is an AMD64 Athlon 5000+.
</bodyText>
<page confidence="0.995285">
82
</page>
<table confidence="0.998949307692308">
avg cat chi cze eng ger jap spa
71.49 (74.90) 56.64 (73.21) 66.18 (70.91) 75.95 81.69 72.31 81.76 65.91 (68.46)
79.11 (82.22) 64.21(84.20) 70.53 (70.90) 75.00 87.48 81.94 91.55 83.09 (84.48)
63.06 (67.41) 46.79 (61.68) 59.72 (70.88) 76.90 75.86 62.66 71.60 47.88 (52.30)
71.92 - - 74.56 73.91 67.30 --
75.09 - - 72.11 80.92 72.25 - -
68.74 - - 77.01 66.88 62.34 - -
macro Fl
syn LAS
semantic Fl
ood macro Fl
ood syn LAS
ood sem Fl
</table>
<tableCaption confidence="0.994997">
Table 1: Overall results. In parenthesis post-evaluation results.
</tableCaption>
<table confidence="0.784304333333333">
cat chi cze eng ger jap spa
syntax only (s/sentence) 18.39 8.07 3.18 2.56 1.30 1.07 15.31
joint system (s/sentence) 10.91 9.49 3.99 3.13 2.36 1.25 12.29
</table>
<tableCaption confidence="0.996755">
Table 2: Parsing time per sentence.
</tableCaption>
<figure confidence="0.973799">
10 20 30 40 50 60 70 80 90 100
% of corpus
</figure>
<figureCaption confidence="0.9929485">
Figure 1: Learning curves for the syntactic-only and joint
parsers in Czech and English.
</figureCaption>
<sectionHeader confidence="0.989356" genericHeader="evaluation">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.988653629629629">
We have shown that a joint syntactic-semantic
parsing can be based on the state-of-the-art Car-
reras (2007) parser at an expense of a reasonable
cost. Our second-order parser still does not repro-
duce the state-of-the art results presented by similar
systems (Nivre et al., 2007). Although we achieved
mild results we believe that a competitive system
based in our model can be built. Further tuning is
required and a complete set of new second-order fea-
tures should be implemented to improve our parser.
The multilingual condition of the task allows us to
evaluate our approach in seven different languages.
A detailed language-dependent evaluation can give
us some insights about the strengths and weaknesses
of our approach across different languages. Unfor-
tunately we believe that this objective was possibly
not accomplished due to the time constraints.
The Catalan and Spanish datasets presented in-
teresting properties that could be exploited. The
mapping between syntax and semantics should be
specially useful for a joint system. In addition
the semantic dependencies for these languages are
aligned with the projective syntactic dependencies,
i.e., the predicate-argument pairs exactly match syn-
tactic dependencies. This is a useful property to si-
man
multaneously build joint dependencies.
</bodyText>
<sectionHeader confidence="0.906288" genericHeader="conclusions">
6 Future and ongoing work
</sectionHeader>
<bodyText confidence="0.9999181">
Our syntactic and semantic parsers, as many others,
is not exempt of bugs. Furthermore, very few tuning
and experimentation was done during the develop-
ment of our parser due to the Shared Task time con-
straints. We believe that we still did not have enough
data to fully evaluate our approach. Further exper-
imentation is required to asses the improvement of
a joint architecture vs. a pipeline architecture. Also
a careful analysis of the system across the different
languages is to be performed.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999356">
We thank the corpus providers (Taul´e et al., 2008;
Palmer and Xue, 2009; Hajiˇc et al., 2006; Surdeanu
et al., 2008; Burchardt et al., 2006; Kawahara et al.,
2002) for their effort in the annotation and conver-
sion of the seven languages datasets.
</bodyText>
<figure confidence="0.992951315789474">
92
90
88
86
84
82
80
78
76
74
72
70
syn cz
syn cz joint
sem cz joint
syn eng
syn eng joint
sem
eng joint
</figure>
<page confidence="0.995707">
83
</page>
<sectionHeader confidence="0.989403" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999453074468085">
Aljoscha Burchardt, Katrin Erk, Anette Frank, Andrea
Kowalski, Sebastian Pad´o, and Manfred Pinkal. 2006.
The SALSA corpus: a German corpus resource for
lexical semantics. In Proceedings of the 5th Interna-
tional Conference on Language Resources and Evalu-
ation (LREC-2006), Genoa, Italy.
Xavier Carreras, Mihai Surdeanu, and Llu´ıs M`arquez.
2006. Projective dependency parsing with perceptron.
In Proceedings of the 10th Conference on Computa-
tional Natural Language Learning (CoNLL-2006).
Xavier Carreras. 2007. Experiments with a higher-order
projective dependency parser. In Proceedings of the
11th Conference on Computational Natural Language
Learning (CoNLL-2007).
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
the ACL-02 conference on Empirical methods in natu-
ral language processing.
Jason M. Eisner. 1996. Three new probabilistic models
for dependency parsing: An exploration. In Proceed-
ings of the 16th International Conference on Compu-
tational Linguistics (COLING-96).
Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr
Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı Havelka, Marie
Mikulov´a, and Zdenˇek ˇZabokrtsk´y. 2006. Prague De-
pendency Treebank 2.0.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 shared task: Syntactic and semantic depen-
dencies in multiple languages. In Proceedings of
the 13th Conference on Computational Natural Lan-
guage Learning (CoNLL-2009), June 4-5, Boulder,
Colorado, USA.
James Henderson, Paola Merlo, Gabriele Musillo, and
Ivan Titov. 2008. A latent variable model of syn-
chronous parsing for syntactic and semantic depen-
dencies. In Proceedings of the 12th Conference on
Computational Natural Language Learning (CoNLL-
2008), Manchester, UK.
Richard Johansson and Pierre Nugues. 2008.
Dependency-based syntactic–semantic analysis
with propbank and nombank. In Proceedings of the
12th Conference on Computational Natural Language
Learning (CoNLL-2008), Manchester, UK.
Daisuke Kawahara, Sadao Kurohashi, and Kˆoiti Hasida.
2002. Construction of a Japanese relevance-tagged
corpus. In Proceedings of the 3rd International
Conference on Language Resources and Evaluation
(LREC-2002), pages 2008–2013, Las Palmas, Canary
Islands.
Xavier Llu´ıs and Llu´ıs M`arquez. 2008. A joint model
for parsing syntactic and semantic dependencies. In
Proceedings of the 12th Conference on Computational
Natural Language Learning (CoNLL-2008), Manch-
ester, UK.
Ryan McDonald and Fernando Pereira. 2006. On-
line learning of approximate dependency parsing algo-
rithms. In 11th Conference of the European Chapter of
the Association for Computational Linguistics (EACL-
2006).
Ryan McDonald, Koby Crammer, and Fernando Pereira.
2005. Online large-margin training of dependency
parsers. In Proceedings of the 43rd Annual Meeting of
the Association for Computational Linguistics (ACL-
2005).
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The CoNLL 2007
shared task on dependency parsing.
Martha Palmer and Nianwen Xue. 2009. Adding seman-
tic roles to the Chinese Treebank. Natural Language
Engineering, 15(1):143–172.
Mihai Surdeanu, Llu´ıs M`arquez, Xavier Carreras, and
Pere R. Comas. 2007. Combination strategies for se-
mantic role labeling. Journal of Artificial Intelligence
Research.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llu´ıs M`arquez, and Joakim Nivre. 2008. The CoNLL-
2008 shared task on joint parsing of syntactic and se-
mantic dependencies. In Proceedings of the 12th Con-
ference on Computational Natural Language Learning
(CoNLL-2008).
Mariona Taul´e, Maria Ant`onia Mart´ı, and Marta Re-
casens. 2008. AnCora: Multilevel Annotated Corpora
for Catalan and Spanish. In Proceedings of the 6th
International Conference on Language Resources and
Evaluation (LREC-2008), Marrakesh, Morroco.
Nianwen Xue and Martha Palmer. 2004. Calibrating fea-
tures for semantic role labeling. In Proceedings of the
Empirical Methods in Natural Language Processing
(EMNLP-2004).
</reference>
<page confidence="0.999205">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.831702">
<title confidence="0.9992935">A Second-Order Joint Eisner Model for Syntactic and Semantic Dependency Parsing</title>
<author confidence="0.996902">Xavier Lluis Stefan Bott Lluis M`arquez</author>
<affiliation confidence="0.996776">TALP Research Center – Software Department Technical University of Catalonia</affiliation>
<abstract confidence="0.988052214285714">We present a system developed for the CoNLL-2009 Shared Task (Hajiˇc et al., 2009). We extend the Carreras (2007) parser to jointly annotate syntactic and semantic dependencies. This state-of-the-art parser factorizes the built tree in second-order factors. We include semantic dependencies in the factors and extend their score function to combine syntactic and semantic scores. The parser is coupled with an on-line averaged perceptron (Collins, 2002) as the learning method. Our averaged results for all seven languages are macro 79.11 LAS and 63.06 seman-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Katrin Erk</author>
<author>Anette Frank</author>
<author>Andrea Kowalski</author>
<author>Sebastian Pad´o</author>
<author>Manfred Pinkal</author>
</authors>
<title>The SALSA corpus: a German corpus resource for lexical semantics.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC-2006),</booktitle>
<location>Genoa, Italy.</location>
<marker>Burchardt, Erk, Frank, Kowalski, Pad´o, Pinkal, 2006</marker>
<rawString>Aljoscha Burchardt, Katrin Erk, Anette Frank, Andrea Kowalski, Sebastian Pad´o, and Manfred Pinkal. 2006. The SALSA corpus: a German corpus resource for lexical semantics. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC-2006), Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Mihai Surdeanu</author>
<author>Llu´ıs M`arquez</author>
</authors>
<title>Projective dependency parsing with perceptron.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-2006).</booktitle>
<marker>Carreras, Surdeanu, M`arquez, 2006</marker>
<rawString>Xavier Carreras, Mihai Surdeanu, and Llu´ıs M`arquez. 2006. Projective dependency parsing with perceptron. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
</authors>
<title>Experiments with a higher-order projective dependency parser.</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th Conference on Computational Natural Language Learning (CoNLL-2007).</booktitle>
<contexts>
<context position="1328" citStr="Carreras (2007)" startWordPosition="195" endWordPosition="196">learning method. Our averaged results for all seven languages are 71.49 macro Fl, 79.11 LAS and 63.06 semantic Fl. 1 Introduction Systems that jointly annotate syntactic and semantic dependencies were introduced in the past CoNLL2008 Shared Task (Surdeanu et al., 2008). These systems showed promising results and proved the feasibility of a joint syntactic and semantic parsing (Henderson et al., 2008; Lluis and M`arquez, 2008). The Eisner (1996) algorithm and its variants are commonly used in data-driven dependency parsing. Improvements of this algorithm presented by McDonald et al. (2006) and Carreras (2007) achieved state-of-the-art performance for English in the CoNLL-2007 Shared Task (Nivre et al., 2007). Johansson and Nugues (2008) presented a system based on the Carreras’ extension of the Eisner algorithm that ranked first in the past CoNLL2008 Shared Task. We decided to extend the Car79 reras (2007) parser to jointly annotate syntactic and semantic dependencies. The present year Shared Task has the incentive of being multilingual with each language presenting their own particularities. An interesting particularity is the direct correspondence between syntactic and semantic dependencies prov</context>
<context position="7236" citStr="Carreras (2007)" startWordPosition="1183" endWordPosition="1184"> the semantic score by the number of predicates q. The semantic score is computed as a score between m and each sentence predicate pi. No second-order relations are considered in these score functions. The search of the best ch, cmo and cmi is independent of the semantic components of the factor. The computational cost of the algorithm is increased by one semantic score function call for every m, h, and pi combination. The asymptotic cost of this operation is O(q · n2) and it is sequentially performed among other O(n2) operations in the main loop of the algorithm. Algorithm 1 Extension of the Carreras (2007) algorithm C[s][t][d][m] ← 0, ∀s, t, d, m O[s][t][d][l] ← 0, ∀s, t, d, l fork= 1,...,n do for s = 0,...,n − k do t ← s + k ∀l O[s][t][←][l] = maxr,cmi,ch C[s][r][→][cmi] + C[r + 1][t][←][ch] +score(t, s, l)+scorecmi(t, s, cmi, l)+ scorech(t, s, l, ch)+ Epi maxl3e„tscoresem(t, s, pi, lsem)/q ∀l O[s][t][→][l] = maxr,cmi,ch C[s][r][→][ch] + C[r + 1][t][←][cmi]+ score(s, t, l)+scorecmi(s, t, cmi, l)+ scorech(s, t,l, ch)+ Epi maxl3e„tscoresem(t, s, pi, lsem)/q ∀m C[s][t][←][m] = maxl,cmo C[s][m][←][cmo] + O[m][t][←][l]+ scorecmo(s, m,l, cmo) ∀m C[s][t][→][m] = maxl,cmo O[s][m][→][l] + C[m][t][→][cm</context>
<context position="15558" citStr="Carreras (2007)" startWordPosition="2565" endWordPosition="2567">2 72.25 - - 68.74 - - 77.01 66.88 62.34 - - macro Fl syn LAS semantic Fl ood macro Fl ood syn LAS ood sem Fl Table 1: Overall results. In parenthesis post-evaluation results. cat chi cze eng ger jap spa syntax only (s/sentence) 18.39 8.07 3.18 2.56 1.30 1.07 15.31 joint system (s/sentence) 10.91 9.49 3.99 3.13 2.36 1.25 12.29 Table 2: Parsing time per sentence. 10 20 30 40 50 60 70 80 90 100 % of corpus Figure 1: Learning curves for the syntactic-only and joint parsers in Czech and English. 5 Conclusion We have shown that a joint syntactic-semantic parsing can be based on the state-of-the-art Carreras (2007) parser at an expense of a reasonable cost. Our second-order parser still does not reproduce the state-of-the art results presented by similar systems (Nivre et al., 2007). Although we achieved mild results we believe that a competitive system based in our model can be built. Further tuning is required and a complete set of new second-order features should be implemented to improve our parser. The multilingual condition of the task allows us to evaluate our approach in seven different languages. A detailed language-dependent evaluation can give us some insights about the strengths and weakness</context>
</contexts>
<marker>Carreras, 2007</marker>
<rawString>Xavier Carreras. 2007. Experiments with a higher-order projective dependency parser. In Proceedings of the 11th Conference on Computational Natural Language Learning (CoNLL-2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing.</booktitle>
<contexts>
<context position="705" citStr="Collins, 2002" startWordPosition="97" endWordPosition="98">s Stefan Bott Lluis M`arquez TALP Research Center – Software Department (LSI) Technical University of Catalonia (UPC) {xlluis,sbott,lluism}@lsi.upc.edu Abstract We present a system developed for the CoNLL-2009 Shared Task (Hajiˇc et al., 2009). We extend the Carreras (2007) parser to jointly annotate syntactic and semantic dependencies. This state-of-the-art parser factorizes the built tree in second-order factors. We include semantic dependencies in the factors and extend their score function to combine syntactic and semantic scores. The parser is coupled with an on-line averaged perceptron (Collins, 2002) as the learning method. Our averaged results for all seven languages are 71.49 macro Fl, 79.11 LAS and 63.06 semantic Fl. 1 Introduction Systems that jointly annotate syntactic and semantic dependencies were introduced in the past CoNLL2008 Shared Task (Surdeanu et al., 2008). These systems showed promising results and proved the feasibility of a joint syntactic and semantic parsing (Henderson et al., 2008; Lluis and M`arquez, 2008). The Eisner (1996) algorithm and its variants are commonly used in data-driven dependency parsing. Improvements of this algorithm presented by McDonald et al. (20</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason M Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96).</booktitle>
<contexts>
<context position="1161" citStr="Eisner (1996)" startWordPosition="170" endWordPosition="171">e factors and extend their score function to combine syntactic and semantic scores. The parser is coupled with an on-line averaged perceptron (Collins, 2002) as the learning method. Our averaged results for all seven languages are 71.49 macro Fl, 79.11 LAS and 63.06 semantic Fl. 1 Introduction Systems that jointly annotate syntactic and semantic dependencies were introduced in the past CoNLL2008 Shared Task (Surdeanu et al., 2008). These systems showed promising results and proved the feasibility of a joint syntactic and semantic parsing (Henderson et al., 2008; Lluis and M`arquez, 2008). The Eisner (1996) algorithm and its variants are commonly used in data-driven dependency parsing. Improvements of this algorithm presented by McDonald et al. (2006) and Carreras (2007) achieved state-of-the-art performance for English in the CoNLL-2007 Shared Task (Nivre et al., 2007). Johansson and Nugues (2008) presented a system based on the Carreras’ extension of the Eisner algorithm that ranked first in the past CoNLL2008 Shared Task. We decided to extend the Car79 reras (2007) parser to jointly annotate syntactic and semantic dependencies. The present year Shared Task has the incentive of being multiling</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason M. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jarmila Panevov´a</author>
<author>Eva Hajiˇcov´a</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
<author>Jan ˇStˇep´anek</author>
<author>Jiˇr´ı Havelka</author>
<author>Marie Mikulov´a</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
</authors>
<date>2006</date>
<journal>Prague Dependency Treebank</journal>
<volume>2</volume>
<marker>Hajiˇc, Panevov´a, Hajiˇcov´a, Sgall, Pajas, ˇStˇep´anek, Havelka, Mikulov´a, ˇZabokrtsk´y, 2006</marker>
<rawString>Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı Havelka, Marie Mikulov´a, and Zdenˇek ˇZabokrtsk´y. 2006. Prague Dependency Treebank 2.0.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Mart´ı</author>
<author>Llu´ıs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
<author>Pavel Straˇn´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL-2009),</booktitle>
<location>Boulder, Colorado, USA.</location>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Mart´ı, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL-2009), June 4-5, Boulder, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Henderson</author>
<author>Paola Merlo</author>
<author>Gabriele Musillo</author>
<author>Ivan Titov</author>
</authors>
<title>A latent variable model of synchronous parsing for syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL2008),</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="1115" citStr="Henderson et al., 2008" startWordPosition="161" endWordPosition="164">d-order factors. We include semantic dependencies in the factors and extend their score function to combine syntactic and semantic scores. The parser is coupled with an on-line averaged perceptron (Collins, 2002) as the learning method. Our averaged results for all seven languages are 71.49 macro Fl, 79.11 LAS and 63.06 semantic Fl. 1 Introduction Systems that jointly annotate syntactic and semantic dependencies were introduced in the past CoNLL2008 Shared Task (Surdeanu et al., 2008). These systems showed promising results and proved the feasibility of a joint syntactic and semantic parsing (Henderson et al., 2008; Lluis and M`arquez, 2008). The Eisner (1996) algorithm and its variants are commonly used in data-driven dependency parsing. Improvements of this algorithm presented by McDonald et al. (2006) and Carreras (2007) achieved state-of-the-art performance for English in the CoNLL-2007 Shared Task (Nivre et al., 2007). Johansson and Nugues (2008) presented a system based on the Carreras’ extension of the Eisner algorithm that ranked first in the past CoNLL2008 Shared Task. We decided to extend the Car79 reras (2007) parser to jointly annotate syntactic and semantic dependencies. The present year Sh</context>
</contexts>
<marker>Henderson, Merlo, Musillo, Titov, 2008</marker>
<rawString>James Henderson, Paola Merlo, Gabriele Musillo, and Ivan Titov. 2008. A latent variable model of synchronous parsing for syntactic and semantic dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL2008), Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Dependency-based syntactic–semantic analysis with propbank and nombank.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008),</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="1458" citStr="Johansson and Nugues (2008)" startWordPosition="211" endWordPosition="214">ntroduction Systems that jointly annotate syntactic and semantic dependencies were introduced in the past CoNLL2008 Shared Task (Surdeanu et al., 2008). These systems showed promising results and proved the feasibility of a joint syntactic and semantic parsing (Henderson et al., 2008; Lluis and M`arquez, 2008). The Eisner (1996) algorithm and its variants are commonly used in data-driven dependency parsing. Improvements of this algorithm presented by McDonald et al. (2006) and Carreras (2007) achieved state-of-the-art performance for English in the CoNLL-2007 Shared Task (Nivre et al., 2007). Johansson and Nugues (2008) presented a system based on the Carreras’ extension of the Eisner algorithm that ranked first in the past CoNLL2008 Shared Task. We decided to extend the Car79 reras (2007) parser to jointly annotate syntactic and semantic dependencies. The present year Shared Task has the incentive of being multilingual with each language presenting their own particularities. An interesting particularity is the direct correspondence between syntactic and semantic dependencies provided in Catalan, Spanish and Chinese. We believe that these correspondences can be captured by a joint system. We specially look a</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Richard Johansson and Pierre Nugues. 2008. Dependency-based syntactic–semantic analysis with propbank and nombank. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008), Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
<author>Kˆoiti Hasida</author>
</authors>
<title>Construction of a Japanese relevance-tagged corpus.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002),</booktitle>
<pages>2008--2013</pages>
<location>Las Palmas, Canary Islands.</location>
<marker>Kawahara, Kurohashi, Hasida, 2002</marker>
<rawString>Daisuke Kawahara, Sadao Kurohashi, and Kˆoiti Hasida. 2002. Construction of a Japanese relevance-tagged corpus. In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002), pages 2008–2013, Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Llu´ıs</author>
<author>Llu´ıs M`arquez</author>
</authors>
<title>A joint model for parsing syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008),</booktitle>
<location>Manchester, UK.</location>
<marker>Llu´ıs, M`arquez, 2008</marker>
<rawString>Xavier Llu´ıs and Llu´ıs M`arquez. 2008. A joint model for parsing syntactic and semantic dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008), Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL2006).</booktitle>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL2005).</booktitle>
<contexts>
<context position="3261" citStr="McDonald et al., 2005" startWordPosition="471" endWordPosition="474"> components: 1) Preprocessing and feature extraction. 2) Syntactic preparsing. 3) Joint syntactic-semantic parsing. 4) Predicate classification. The preprocessing and feature extraction is intended to ease and improve the performance of the parser precomputing a binary representation of Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 79–84, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics each sentence features. These features are borrowed from existing and widely-known systems (Xue and Palmer, 2004; McDonald et al., 2005; Carreras et al., 2006; Surdeanu et al., 2007). The following step is a syntactic pre-parse. It is only required to pre-compute additional features (e.g., syntactic path, syntactic frame) from the syntax. These new features will be used for the semantic role component of the following joint parser. The joint parser is the core of the system. This single algorithm computes the complete parse that optimizes a score according to a function that depends on both syntax and semantics. Some of the required features that could be unavailable or expensive to compute at that time are provided by the pr</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<booktitle>The CoNLL</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Nianwen Xue</author>
</authors>
<title>Adding semantic roles to the Chinese Treebank.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>1</issue>
<marker>Palmer, Xue, 2009</marker>
<rawString>Martha Palmer and Nianwen Xue. 2009. Adding semantic roles to the Chinese Treebank. Natural Language Engineering, 15(1):143–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Llu´ıs M`arquez</author>
<author>Xavier Carreras</author>
<author>Pere R Comas</author>
</authors>
<title>Combination strategies for semantic role labeling.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research.</journal>
<marker>Surdeanu, M`arquez, Carreras, Comas, 2007</marker>
<rawString>Mihai Surdeanu, Llu´ıs M`arquez, Xavier Carreras, and Pere R. Comas. 2007. Combination strategies for semantic role labeling. Journal of Artificial Intelligence Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llu´ıs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Llu´ıs M`arquez, and Joakim Nivre. 2008. The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariona Taul´e</author>
<author>Maria Ant`onia Mart´ı</author>
<author>Marta Recasens</author>
</authors>
<title>AnCora: Multilevel Annotated Corpora for Catalan and Spanish.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC-2008),</booktitle>
<location>Marrakesh, Morroco.</location>
<marker>Taul´e, Mart´ı, Recasens, 2008</marker>
<rawString>Mariona Taul´e, Maria Ant`onia Mart´ı, and Marta Recasens. 2008. AnCora: Multilevel Annotated Corpora for Catalan and Spanish. In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC-2008), Marrakesh, Morroco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Calibrating features for semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of the Empirical Methods in Natural Language Processing (EMNLP-2004).</booktitle>
<contexts>
<context position="3238" citStr="Xue and Palmer, 2004" startWordPosition="467" endWordPosition="470"> consists on four main components: 1) Preprocessing and feature extraction. 2) Syntactic preparsing. 3) Joint syntactic-semantic parsing. 4) Predicate classification. The preprocessing and feature extraction is intended to ease and improve the performance of the parser precomputing a binary representation of Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 79–84, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics each sentence features. These features are borrowed from existing and widely-known systems (Xue and Palmer, 2004; McDonald et al., 2005; Carreras et al., 2006; Surdeanu et al., 2007). The following step is a syntactic pre-parse. It is only required to pre-compute additional features (e.g., syntactic path, syntactic frame) from the syntax. These new features will be used for the semantic role component of the following joint parser. The joint parser is the core of the system. This single algorithm computes the complete parse that optimizes a score according to a function that depends on both syntax and semantics. Some of the required features that could be unavailable or expensive to compute at that time</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Nianwen Xue and Martha Palmer. 2004. Calibrating features for semantic role labeling. In Proceedings of the Empirical Methods in Natural Language Processing (EMNLP-2004).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>