<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.041924">
<note confidence="0.86687">
SENSEVAL-3: Third International Workshop on the Evaluation of Systems
for the Semantic Analysis of Text, Barcelona, Spain, July 2004
</note>
<title confidence="0.8446195">
Association for Computational Linguistics
Dependency Based Logical Form Transformations
</title>
<author confidence="0.996189">
Stephen Anthony and Jon Patrick
</author>
<affiliation confidence="0.865838666666667">
School of Information Technologies
The University of Sydney
Sydney, Australia 2006
</affiliation>
<email confidence="0.991162">
{stephen,jonpat}@it.usyd.edu.au
</email>
<sectionHeader confidence="0.992328" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999864083333333">
This paper describes a system developed for the
transformation of English sentences into a first
order logical form representation. The method-
ology is centered on the use of a dependency
grammar based parser. We demonstrate the suit-
ability of applying a dependency parser based
solution to the given task and in turn explain
some of the limitations and challenges involved
when using such an approach. The efficiencies
and deficiencies of our approach are discussed
as well as considerations for further enhanc e-
ments.
</bodyText>
<sectionHeader confidence="0.99849" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997625">
In addition to the well-known all words and lexi-
cal sample tasks deployed in previous Senseval
workshops a number of new tasks have been in-
cluded in this sense evaluation. These new tasks in-
clude identification of semantic roles as in FrameNet
(Gildea and Jurafsky 2002), disambiguation of
WordNet glosses (Miller 1990; Fellbaum 1998;
Harabagiu, Miller et al. 1999), automatic acquisition
of subcategorisation frames (Korhonen 2002; Preiss
and Korhonen 2002), and Logical Form Identifica-
tion (LFI) (Rus 2002; Rus and Moldovan 2002).
This paper discusses a solution developed for the
LFI task. The approach used here employs a func-
tional dependency parser (Järvinen and Tapanainen
1997; Tapanainen and Järvinen 1997) and uses a
limited number of additional resources. This contri-
bution is intended to demonstrate the suitability of a
dependency parser to the given task and also explain
some of the limitations and challenges involved
when using such an approach.
</bodyText>
<subsectionHeader confidence="0.987084">
1.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999968642857143">
Part of the initial step towards the interpretation of
a sentence as postulated by Hobbs et al. (1993) in-
volves the proof of the logical form of a sentence.
This statement entails the transformation of a sen-
tence into a logical form as a fundamental building
block towards sentence interpretation.
Advantages specifically related to the utilisation
of logical forms in language processing include a
simplified interface between syntax and semantics, a
natural and easily exploitable representation of syn-
tactic arguments, and the potential for formation of
conceptual predicates (Rus 2002) if predicates are
disambiguated with respect to a general ontology
such as WordNet.
</bodyText>
<subsectionHeader confidence="0.9733">
1.2 Task Description
</subsectionHeader>
<bodyText confidence="0.9973175">
The Logical Form (LF) employed in this task is a
flat, scope-free first order logic representation that
embeds lexical and syntactic information. A predi-
cate is generated for every nominal, verbal, adjecti-
val, and adverbial content word. The name of the
predicate is a concatenation of the lemmatised word
form and part-of-speech category. The sentence be-
low is followed by its corresponding target logical
form representation.
Some students like to study in the mornings.
</bodyText>
<equation confidence="0.6705345">
student:n_ (x3) like:v_ (e4, x3, e6) to (e5, e6)
study:v_ (e6, x3, x9) in (e7, x9) morning:n_ (x9).
</equation>
<bodyText confidence="0.998509666666667">
Relationships between predicates are shared
through their arguments. The two types of argu-
ments used are events (e) and entities (x). Using the
transformation shown above as an example, the
event predicate ‘like’ is labeled as e4 and has subject
argument x3 which corresponds to ‘student’ and
grammatical object argument e6 which corresponds
to the ‘study’ event predicate.
The remainder of the argument slots are reserved
for indirect and prepositional objects. Determiners,
plurals, negation, auxiliaries, verb tenses, and punc-
tuation are excluded from the final representation.
</bodyText>
<sectionHeader confidence="0.995105" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.9992342">
The system is built using a highly modular design
and is intended to be as generic and reusable as pos-
sible. The basic data structure is a flat list-like repre-
sentation with generic property slots attached to each
element. This structure maximises compatibility
with the final representation and allows for greater
flexibility in the types of information that may be
associated with each predicate. Figure 1 illustrates
the major processing modules available and the
work flow.
</bodyText>
<figureCaption confidence="0.9961">
Figure 1: Logical form identification work flow
</figureCaption>
<bodyText confidence="0.997049">
A syntactic parse including functional dependen-
cies is produced on a per sentence basis. Definitions
of the properties associated with each token are pre-
sented in Table 1.
</bodyText>
<table confidence="0.999599">
Attribute Value
Word ID Integer sentence position
Head ID Integer position of head dependency
Text The original word form
Lemma Lemmatised word form
Morpho Morphological function tags. Parts
of speech and sub-features
Syntax Surface syntactic tags
Depend Dependency functions
MAIN Main element
SUBJ Position of syntactic subject
OBJ Syntactic object position
I-OBJ Indirect object position
COMP Position of syntactic complement
PCOMP Prepositional complement position
DET Determiner dependent
ATTR Attributive nominal
CC Coordinating conjunction
GOAL Position of goal
OC Object complement
</table>
<tableCaption confidence="0.999911">
Table 1: Linguistic information stored for each
</tableCaption>
<bodyText confidence="0.927359571428571">
token
The resultant parse is transformed into a linear
data structure indexed by word position. This is il-
lustrated in Table 2 using the example sentence
‘Some students like to study in the mornings’. The
original token text is stored, as is the lemmatised
form.
</bodyText>
<table confidence="0.69508675">
WordID Lemma HeadID Depend Text Morpho Syntax
2 some 3 det Some DET &gt;N
3 stu- 4 subj stu- N NOM NH
dent dents PL
4 like 1 main like V PRES VA
5 to 6 pm to INF AUX
6 study 4 obj study MARK VA
V INF
7 in 6 tmp in PREP EH
8 the 9 det the DET &gt;N
9 morn 7 pcomp morn- N NOM NH
ing ings PL
</table>
<tableCaption confidence="0.98816">
Table 2: Example syntactic parse
</tableCaption>
<bodyText confidence="0.999986675675676">
Head and dependency type are the most important
class of information used by the system. The de-
pendency type and head of the token is often di-
rectly, if not indirectly, translatable into a predicate
argument. Examples of the types of dependency
functions employed include subject, object, preposi-
tional complement, agent, subject and object com-
plements, indirect object, goal, and coordinating
conjunctions. Determiner and negator functions are
also of interest because they are excluded from the
final representation.
The filter module moderates the presence or ab-
sence of tokens using stop lists or pass lists or a
combination of both. Stop lists are used to specify
content to be excluded from the token stream and
pass lists specify elements that should remain. To-
kens may be filtered from the stream based on any
attribute type and value listed in Table 1. This in-
formation is provided in the filter set. The principal
types of information filtered in this system are de-
terminers based on morphological tags and auxilia-
ries based on syntactic tag information. For example
‘some’ and ‘the’ are filtered as a consequence of a
morpho property equals ‘DET’ stop list rule.
When the token stream has been annotated with
the necessary information and has passed through
the filter, the tokens that remain are passed through
the logical form processor (LFP). The main function
of the LFP is to build an inverted index identifying
all dependent tokens. Once grammatical dependen-
cies are assigned and the inverted index is built the
logical form representation may be constructed.
Each predicate is constructed from the token stream
in turn based on the part-of--speech category of the
token. The base form of the token is concatenated
with the part-of-speech tag. A mapping table is used
to transform the part-of-speech information pro-
</bodyText>
<figure confidence="0.990753307692308">
Natural lan-
guage sen-
tences
Filter
set
Functional
dependency
parser
Filters
Logical Form
processor
Target logical
form
</figure>
<bodyText confidence="0.999304205882353">
duced by the parse into the coarser grained WordNet
tags.
Entities are the simplest type of predicate to con-
struct as they contain only a single argument, for
which the word identifier attribute value is used.
Noun tokens ‘student’ and ‘morning’ from the ex-
ample are transformed into the predicates
student:n_(x3) and morning:n_(x9). Pronouns,
prepositional complements, and coordinating con-
junctions are dealt with individually using their re-
spective dependency function values.
Adjectives are constructed using the head depend-
ency value as the argument unless the dependent is
marked with a subject. In this case the argument be-
comes the head of the subject. Adverbs are created
primarily using the dependency function alone.
Verbal predicates are constructed using SUBJ,
OBJ, GOAL, OC, I-OBJ, COMP, and PCOMP de-
pendencies in the specified order. A special case
exists for verbs that have object complement de-
pendencies. In these cases attributive nominals are
identified and assigned as arguments independently.
The main verb ‘like’ in our example is trans-
formed into the predicate like:v_(e4, x3, e6) as a
result of subject (SUBJ) and object (OBJ) dependen-
cies found in ‘student’ and ‘study’ respectively.
Given the fact that we are dealing with the main
verb, the LFP inverts the subject and object depend-
encies, inserts them into the head verb token prop-
erty slot and assigns their respective word identifier
values. The inverted properties augment the token
slot for ‘like’ which has word identifier four in Table
2. The additional elements of the inverted index used
to build the predicate are listed in Table 3.
</bodyText>
<table confidence="0.906835888888889">
Attribute Value
OBJ 6
SUBJ 3
depend main
head 1
lemma like
morpho V PRES
syntax VA
text like
</table>
<tableCaption confidence="0.999431">
Table 3: Augmented token slot for ‘like’
</tableCaption>
<bodyText confidence="0.9995374">
Verbal predicates which also serve as grammatical
objects also warrant special treatment. The token
‘study’ is an example of this as it serves as the object
of the head verb ‘like’. A cache is used to store the
sentential head, prepositional complements, subjects,
and coordinating conjunctions. The cache is used in
this instance to assign the subject and prepositional
complement arguments in order to form the predi-
cate study:v_(e6, x3, x9). Notice from Table 2 word
identifier three matches the grammatical subject to-
ken ‘students’ and word identifier nine matches the
head of the prepositional phrase ‘in the mornings’.
Once all tokens are processed the logical form
transformation is complete and the final representa-
tion is presented in the aforementioned notation.
</bodyText>
<sectionHeader confidence="0.996854" genericHeader="method">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.998956833333333">
Argument, predicate, and sentence level precision
and recall measures are used to evaluate perform-
ance of the system as compared to a gold-standard.
The system was trained on a set of 50 sentences with
corresponding logical forms. Final testing was per-
formed on a set of 300 LF-sentence pairs.
</bodyText>
<subsectionHeader confidence="0.999448">
3.1 Argument Level
</subsectionHeader>
<bodyText confidence="0.9999535">
Precision at the argument level is defined to be the
number of correctly identified arguments divided by
the number of all identified arguments. Recall is de-
fined to be the number of correctly identified argu-
ments divided by the real number of arguments that
should be present in the target transformation.
</bodyText>
<subsectionHeader confidence="0.999727">
3.2 Predicate Level
</subsectionHeader>
<bodyText confidence="0.99994275">
Predicates must identify all arguments correctly to
be counted as a correct predicate. Precision is de-
fined to be the number of correctly identified predi-
cates divided by the number of all attempted
predicates. Recall is defined as the number of cor-
rectly identified predicates divided by the real num-
ber of predicates that were supposed to be identified
in the target transformation.
</bodyText>
<subsectionHeader confidence="0.999798">
3.3 Sentence Level
</subsectionHeader>
<bodyText confidence="0.999985461538461">
Various other sentence level measures are also
used. Sentence-argument is defined as the number of
sentences that have all arguments correctly identi-
fied divided by the number of sentences attempted.
Sentence-predicate is similar except conditioned on
predicates. Sentence-argument-predicate is defined
to be the number of sentences that have all argu-
ments correctly identified divided by the number of
sentences which have all predicates correctly identi-
fied. Sentence-argument-predicate-sentences refers
to the number of sentences that have all arguments
and all predicates correctly identified divided by the
number of sentences attempted.
</bodyText>
<sectionHeader confidence="0.999955" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.9415996">
As stated earlier the final evaluation was con-
ducted on a set of 300 sentence-LF pairs. Table 4
lists the evaluation precision and recall results using
the measures discussed in section 3 which have been
converted into percentages.
</bodyText>
<table confidence="0.999214888888889">
Evaluation Measure Score
Argument Precision 76.4
Argument Recall 65.6
Predicate Precision 84.0
Predicate Recall 85.0
Sentence-Argument 16.0
Sentence-Predicate 35.3
Sentence-Argument-Predicate 38.7
Sentence-Argument-Predicate-Sentences 13.7
</table>
<tableCaption confidence="0.999858">
Table 4: Evaluation results as percentages
</tableCaption>
<bodyText confidence="0.999814571428571">
The major source of error in terms of arguments
originated from the parser’s inappropriate handling
of coordinating conjunctions. Another common
source of error arose from poor handling of nominal
group complexes. With regard to predicate perform-
ance, the decision to forfeit the use of the available
multi-word item list proved costly.
</bodyText>
<sectionHeader confidence="0.999636" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.999967333333333">
Harabagiu et al. (1999) proposed a scheme for at-
taching sense tags to predicates within the frame-
work of transforming WordNet glosses into a logical
form. In this way conceptual predicates may be
formed to manipulate a meaning representation in
more significant ways. Naturally the sense inventory
must be sensitive enough to allow for a meaningful
and representative mutation to be applied to the
meaning representation.
</bodyText>
<sectionHeader confidence="0.999617" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999940375">
Dependency grammars provide a natural and in-
tuitive solution to the task of logical form identific a-
tion. We have managed to demonstrate relatively
good overall performance on the given task with
minimal additional processing and a very small
amount of training data.
It is argued that a dependency grammar based
parse provides a rich source of knowledge that is
suitable for the transformation of English sentences
into a logical form. It would appear that there is to a
large extent enough information embedded within
the parser’s output to achieve the desired outcome. It
is however apparent that other types of information
could further improve the solution. These types of
information include named entity recognition and
multi-word phrase detection.
</bodyText>
<sectionHeader confidence="0.996465" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999871731707317">
Fellbaum, C. (1998). WordNet : An Electronic Lexi-
cal Database. Cambridge, Massachusetts;
London, MIT Press.
Gildea, D. and D. Jurafsky (2002). &amp;quot;Automatic La-
beling of Semantic Roles.&amp;quot; Computational
Linguistics 28(3): 245-288.
Harabagiu, S. M., G. A. Miller, et al. (1999). Word-
Net 2 - A Morphologically and Semantically
Enhanced Resource. SIGLEX.
Hobbs, J. R., M. E. Stickel, et al. (1993). &amp;quot;Interpreta-
tion as Abduction.&amp;quot; Artificial Intelligence
63: 69-142.
Järvinen, T. and P. Tapanainen (1997). Dependency
Parser for English. Helsinki, University of
Helsinki, Department of General Linguis-
tics.
Korhonen, A. (2002). Subcategorization Acquisition.
Ph.D. Dissertation. Computer Laboratory,
University of Cambridge.
Miller, G. (1990). &amp;quot;WordNet: An Online Lexical
Database.&amp;quot; International Journal of Lexi-
cography 3(4).
Preiss, J. and A. Korhonen (2002). Improving Sub-
categorization Acquisition with WSD. In
Proceedings of the ACL Workshop on Word
Sense Disambiguation: Recent Successes
and Future Directions.
Rus, V. (2002). Logic Form For WordNet Glosses.
Ph.D. Dissertation. Computer Science De-
partment, School of Engineering, Southern
Methodist University.
Rus, V. and D. I. Moldovan (2002). &amp;quot;High Precision
Logic Form Transformation.&amp;quot; International
Journal on Artificial Intelligence Tools
11(3).
Tapanainen, P. and T. Järvinen (1997). A Non-
Projective Dependency Parser. In Proceed-
ings of the 5th Conference on Applied Natu-
ral Language Processing, Association for
Computational Linguistics, Washington
D.C.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.304256">
<note confidence="0.7521125">SENSEVAL-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain, July 2004</note>
<title confidence="0.807109">Association for Computational Linguistics Dependency Based Logical Form Transformations</title>
<author confidence="0.99998">Stephen Anthony</author>
<author confidence="0.99998">Jon Patrick</author>
<affiliation confidence="0.999565">School of Information Technologies The University of Sydney</affiliation>
<address confidence="0.969455">Sydney, Australia 2006</address>
<email confidence="0.992437">stephen@it.usyd.edu.au</email>
<email confidence="0.992437">jonpat@it.usyd.edu.au</email>
<abstract confidence="0.989057076923077">This paper describes a system developed for the transformation of English sentences into a first order logical form representation. The methodology is centered on the use of a dependency grammar based parser. We demonstrate the suitability of applying a dependency parser based solution to the given task and in turn explain some of the limitations and challenges involved when using such an approach. The efficiencies and deficiencies of our approach are discussed as well as considerations for further enhanc ements.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet : An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, Massachusetts; London,</location>
<contexts>
<context position="1244" citStr="Fellbaum 1998" startWordPosition="183" endWordPosition="184">dependency parser based solution to the given task and in turn explain some of the limitations and challenges involved when using such an approach. The efficiencies and deficiencies of our approach are discussed as well as considerations for further enhanc ements. 1 Introduction In addition to the well-known all words and lexical sample tasks deployed in previous Senseval workshops a number of new tasks have been included in this sense evaluation. These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al. 1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002). This paper discusses a solution developed for the LFI task. The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources. This contribution is intended to demonstrate the suitability of a dependency parser to the given task and also explain some of the limitations and challenges involved</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, C. (1998). WordNet : An Electronic Lexical Database. Cambridge, Massachusetts; London, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.&amp;quot;</title>
<date>2002</date>
<journal>Computational Linguistics</journal>
<volume>28</volume>
<issue>3</issue>
<pages>245--288</pages>
<contexts>
<context position="1181" citStr="Gildea and Jurafsky 2002" startWordPosition="173" endWordPosition="176">endency grammar based parser. We demonstrate the suitability of applying a dependency parser based solution to the given task and in turn explain some of the limitations and challenges involved when using such an approach. The efficiencies and deficiencies of our approach are discussed as well as considerations for further enhanc ements. 1 Introduction In addition to the well-known all words and lexical sample tasks deployed in previous Senseval workshops a number of new tasks have been included in this sense evaluation. These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al. 1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002). This paper discusses a solution developed for the LFI task. The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources. This contribution is intended to demonstrate the suitability of a dependency parser to the given task a</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Gildea, D. and D. Jurafsky (2002). &amp;quot;Automatic Labeling of Semantic Roles.&amp;quot; Computational Linguistics 28(3): 245-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Harabagiu</author>
<author>G A Miller</author>
</authors>
<title>WordNet 2 - A Morphologically and Semantically Enhanced Resource.</title>
<date>1999</date>
<publisher>SIGLEX.</publisher>
<marker>Harabagiu, Miller, 1999</marker>
<rawString>Harabagiu, S. M., G. A. Miller, et al. (1999). WordNet 2 - A Morphologically and Semantically Enhanced Resource. SIGLEX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
<author>M E Stickel</author>
</authors>
<title>Interpretation as Abduction.&amp;quot;</title>
<date>1993</date>
<journal>Artificial Intelligence</journal>
<volume>63</volume>
<pages>69--142</pages>
<marker>Hobbs, Stickel, 1993</marker>
<rawString>Hobbs, J. R., M. E. Stickel, et al. (1993). &amp;quot;Interpretation as Abduction.&amp;quot; Artificial Intelligence 63: 69-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Järvinen</author>
<author>P Tapanainen</author>
</authors>
<date>1997</date>
<institution>Dependency Parser for English. Helsinki, University of Helsinki, Department of General Linguistics.</institution>
<contexts>
<context position="1595" citStr="Järvinen and Tapanainen 1997" startWordPosition="233" endWordPosition="236">le tasks deployed in previous Senseval workshops a number of new tasks have been included in this sense evaluation. These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al. 1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002). This paper discusses a solution developed for the LFI task. The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources. This contribution is intended to demonstrate the suitability of a dependency parser to the given task and also explain some of the limitations and challenges involved when using such an approach. 1.1 Motivation Part of the initial step towards the interpretation of a sentence as postulated by Hobbs et al. (1993) involves the proof of the logical form of a sentence. This statement entails the transformation of a sentence into a logical form as a fundamental building block towards sentence interpretation. Advantag</context>
</contexts>
<marker>Järvinen, Tapanainen, 1997</marker>
<rawString>Järvinen, T. and P. Tapanainen (1997). Dependency Parser for English. Helsinki, University of Helsinki, Department of General Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Korhonen</author>
</authors>
<title>Subcategorization Acquisition.</title>
<date>2002</date>
<tech>Ph.D.</tech>
<institution>Dissertation. Computer Laboratory, University of Cambridge.</institution>
<contexts>
<context position="1342" citStr="Korhonen 2002" startWordPosition="195" endWordPosition="196"> challenges involved when using such an approach. The efficiencies and deficiencies of our approach are discussed as well as considerations for further enhanc ements. 1 Introduction In addition to the well-known all words and lexical sample tasks deployed in previous Senseval workshops a number of new tasks have been included in this sense evaluation. These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al. 1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002). This paper discusses a solution developed for the LFI task. The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources. This contribution is intended to demonstrate the suitability of a dependency parser to the given task and also explain some of the limitations and challenges involved when using such an approach. 1.1 Motivation Part of the initial step towards the interpretation o</context>
</contexts>
<marker>Korhonen, 2002</marker>
<rawString>Korhonen, A. (2002). Subcategorization Acquisition. Ph.D. Dissertation. Computer Laboratory, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<title>WordNet: An Online Lexical Database.&amp;quot;</title>
<date>1990</date>
<journal>International Journal of Lexicography</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="1229" citStr="Miller 1990" startWordPosition="181" endWordPosition="182">f applying a dependency parser based solution to the given task and in turn explain some of the limitations and challenges involved when using such an approach. The efficiencies and deficiencies of our approach are discussed as well as considerations for further enhanc ements. 1 Introduction In addition to the well-known all words and lexical sample tasks deployed in previous Senseval workshops a number of new tasks have been included in this sense evaluation. These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al. 1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002). This paper discusses a solution developed for the LFI task. The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources. This contribution is intended to demonstrate the suitability of a dependency parser to the given task and also explain some of the limitations and chal</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>Miller, G. (1990). &amp;quot;WordNet: An Online Lexical Database.&amp;quot; International Journal of Lexicography 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Preiss</author>
<author>A Korhonen</author>
</authors>
<title>Improving Subcategorization Acquisition with WSD.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Workshop on Word Sense Disambiguation: Recent Successes and Future Directions.</booktitle>
<contexts>
<context position="1369" citStr="Preiss and Korhonen 2002" startWordPosition="197" endWordPosition="200">olved when using such an approach. The efficiencies and deficiencies of our approach are discussed as well as considerations for further enhanc ements. 1 Introduction In addition to the well-known all words and lexical sample tasks deployed in previous Senseval workshops a number of new tasks have been included in this sense evaluation. These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al. 1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002). This paper discusses a solution developed for the LFI task. The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources. This contribution is intended to demonstrate the suitability of a dependency parser to the given task and also explain some of the limitations and challenges involved when using such an approach. 1.1 Motivation Part of the initial step towards the interpretation of a sentence as postulated </context>
</contexts>
<marker>Preiss, Korhonen, 2002</marker>
<rawString>Preiss, J. and A. Korhonen (2002). Improving Subcategorization Acquisition with WSD. In Proceedings of the ACL Workshop on Word Sense Disambiguation: Recent Successes and Future Directions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rus</author>
</authors>
<title>Logic Form For WordNet Glosses.</title>
<date>2002</date>
<tech>Ph.D. Dissertation.</tech>
<institution>Computer Science Department, School of Engineering, Southern Methodist University.</institution>
<contexts>
<context position="1418" citStr="Rus 2002" startWordPosition="207" endWordPosition="208">es of our approach are discussed as well as considerations for further enhanc ements. 1 Introduction In addition to the well-known all words and lexical sample tasks deployed in previous Senseval workshops a number of new tasks have been included in this sense evaluation. These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al. 1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002). This paper discusses a solution developed for the LFI task. The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources. This contribution is intended to demonstrate the suitability of a dependency parser to the given task and also explain some of the limitations and challenges involved when using such an approach. 1.1 Motivation Part of the initial step towards the interpretation of a sentence as postulated by Hobbs et al. (1993) involves the proof of the </context>
</contexts>
<marker>Rus, 2002</marker>
<rawString>Rus, V. (2002). Logic Form For WordNet Glosses. Ph.D. Dissertation. Computer Science Department, School of Engineering, Southern Methodist University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rus</author>
<author>D I Moldovan</author>
</authors>
<title>High Precision Logic Form Transformation.&amp;quot;</title>
<date>2002</date>
<journal>International Journal on Artificial Intelligence Tools</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="1442" citStr="Rus and Moldovan 2002" startWordPosition="209" endWordPosition="212">approach are discussed as well as considerations for further enhanc ements. 1 Introduction In addition to the well-known all words and lexical sample tasks deployed in previous Senseval workshops a number of new tasks have been included in this sense evaluation. These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al. 1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002). This paper discusses a solution developed for the LFI task. The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources. This contribution is intended to demonstrate the suitability of a dependency parser to the given task and also explain some of the limitations and challenges involved when using such an approach. 1.1 Motivation Part of the initial step towards the interpretation of a sentence as postulated by Hobbs et al. (1993) involves the proof of the logical form of a senten</context>
</contexts>
<marker>Rus, Moldovan, 2002</marker>
<rawString>Rus, V. and D. I. Moldovan (2002). &amp;quot;High Precision Logic Form Transformation.&amp;quot; International Journal on Artificial Intelligence Tools 11(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
<author>T Järvinen</author>
</authors>
<title>A NonProjective Dependency Parser.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th Conference on Applied Natural Language Processing, Association for Computational Linguistics,</booktitle>
<location>Washington D.C.</location>
<contexts>
<context position="1626" citStr="Tapanainen and Järvinen 1997" startWordPosition="237" endWordPosition="240">Senseval workshops a number of new tasks have been included in this sense evaluation. These new tasks include identification of semantic roles as in FrameNet (Gildea and Jurafsky 2002), disambiguation of WordNet glosses (Miller 1990; Fellbaum 1998; Harabagiu, Miller et al. 1999), automatic acquisition of subcategorisation frames (Korhonen 2002; Preiss and Korhonen 2002), and Logical Form Identification (LFI) (Rus 2002; Rus and Moldovan 2002). This paper discusses a solution developed for the LFI task. The approach used here employs a functional dependency parser (Järvinen and Tapanainen 1997; Tapanainen and Järvinen 1997) and uses a limited number of additional resources. This contribution is intended to demonstrate the suitability of a dependency parser to the given task and also explain some of the limitations and challenges involved when using such an approach. 1.1 Motivation Part of the initial step towards the interpretation of a sentence as postulated by Hobbs et al. (1993) involves the proof of the logical form of a sentence. This statement entails the transformation of a sentence into a logical form as a fundamental building block towards sentence interpretation. Advantages specifically related to the </context>
</contexts>
<marker>Tapanainen, Järvinen, 1997</marker>
<rawString>Tapanainen, P. and T. Järvinen (1997). A NonProjective Dependency Parser. In Proceedings of the 5th Conference on Applied Natural Language Processing, Association for Computational Linguistics, Washington D.C.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>