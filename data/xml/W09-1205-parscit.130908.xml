<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000626">
<title confidence="0.9983935">
A Latent Variable Model of Synchronous Syntactic-Semantic Parsing for
Multiple Languages
</title>
<author confidence="0.894468">
Andrea Gesmundo James Henderson Paola Merlo Ivan Titov∗
</author>
<affiliation confidence="0.761651">
Univ Geneva Univ Geneva Univ Geneva Univ Illinois at U-C
</affiliation>
<table confidence="0.382548333333333">
Dept Computer Sci Dept Computer Sci Dept Linguistics Dept Computer Sci
Andrea.Gesmundo@ James.Henderson@ Paola.Merlo@ titov@uiuc.edu
unige.ch unige.ch unige.ch
</table>
<sectionHeader confidence="0.992427" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999879333333333">
Motivated by the large number of languages
(seven) and the short development time (two
months) of the 2009 CoNLL shared task, we
exploited latent variables to avoid the costly
process of hand-crafted feature engineering,
allowing the latent variables to induce features
from the data. We took a pre-existing gener-
ative latent variable model of joint syntactic-
semantic dependency parsing, developed for
English, and applied it to six new languages
with minimal adjustments. The parser’s ro-
bustness across languages indicates that this
parser has a very general feature set. The
parser’s high performance indicates that its la-
tent variables succeeded in inducing effective
features. This system was ranked third overall
with a macro averaged F1 score of 82.14%,
only 0.5% worse than the best system.
</bodyText>
<sectionHeader confidence="0.999467" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99734975">
Recent research in syntax-based statistical machine
translation and the recent availability of syntac-
tically annotated corpora for multiple languages
(Nivre et al., 2007) has provided a new opportunity
for evaluating the cross-linguistic validity of statis-
tical models of syntactic structure. This opportu-
nity has been significantly expanded with the 2009
CoNLL shared task on syntactic and semantic pars-
ing of seven languages (Hajiˇc et al., 2009) belonging
to several different language families.
We participate in this task with a generative,
history-based model proposed in the CoNLL 2008
</bodyText>
<footnote confidence="0.479197">
0Authors in alphabetical order.
</footnote>
<page confidence="0.995529">
37
</page>
<bodyText confidence="0.999809764705882">
shared task for English (Henderson et al., 2008) and
further improved to tackle non-planar dependencies
(Titov et al., 2009). This model maximises the joint
probability of the syntactic and semantic dependen-
cies and thereby enforces that the output structure be
globally coherent, but the use of synchronous pars-
ing allows it to maintain separate structures for the
syntax and semantics. The probabilistic model is
based on Incremental Sigmoid Belief Networks (IS-
BNs), a recently proposed latent variable model for
syntactic structure prediction, which has shown very
good performance for both constituency (Titov and
Henderson, 2007a) and dependency parsing (Titov
and Henderson, 2007b). The use of latent variables
enables this architecture to be extended to learning
a synchronous parse of syntax and semantics with-
out overly restrictive assumptions about the linking
between syntactic and semantic structures.
In this work, we evaluate the ability of this
method to generalise across several languages. We
take the model as it was developed for English, and
apply it directly to all seven languages. The only
fine-tuning was to evaluate whether to include one
feature type which we had previously found did not
help for English, but helped overall. No other fea-
ture engineering was done. The use of latent vari-
ables to induce features automatically from the data
gives our method the adaptability necessary to per-
form well across all seven languages, and demon-
strates the lack of language specificity in the models
of Henderson et al. (2008) and Titov et al. (2009).
The main properties of this model, that differen-
tiate it from other approaches, is the use of syn-
chronous syntactic and semantic derivations and the
</bodyText>
<note confidence="0.580848">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 37–42,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.9993235">
use of online planarisation of crossing semantic de-
pendencies. This system was ranked third overall
with a macro averaged F1 score of 82.14%, only
0.5% worse than the best system.
</bodyText>
<sectionHeader confidence="0.98883" genericHeader="method">
2 The Synchronous Model
</sectionHeader>
<bodyText confidence="0.9964554">
The use of synchronous parsing allows separate
structures for syntax and semantics, while still mod-
eling their joint probability. We use the approach
to synchronous parsing proposed in Henderson et al.
(2008), where we start with two separate derivations
specifying each of the two structures, then synchro-
nise these derivations at each word. The individual
derivations are based on Nivre’s shift-reduce-style
parsing algorithm (Nivre et al., 2006), as discussed
further below. First we illustrate the high-level struc-
ture of the model, discussed in more detail in Hen-
derson et al. (2008).
Let Td be a syntactic dependency tree with
derivation D1d, ..., Dmd
d , and Ts be a semantic
dependency graph with derivation D1s, ..., Dms
s.
To define derivations for the joint structure
Td, Ts, we divide the two derivations into the
chunks between shifting each word onto the
</bodyText>
<equation confidence="0.56963">
bt et bt et
stack, ctd = Ddd, ..., Ddd and ct = Dss, ..., Dss,
d−1
</equation>
<bodyText confidence="0.9984504">
the synchronous derivations consist of quadruples
Ct = (ctd, Switch, cts, Shiftt), where Switch means
switching from syntactic to semantic mode. This
gives us the following joint probability model,
where n is the number of words in the input.
</bodyText>
<equation confidence="0.998925">
P(Td,Ts) = fint=1 P(Ct|C1,...,Ct−1) (1)
</equation>
<bodyText confidence="0.999944">
These synchronous derivations C1, ... , Cn only re-
quire a single input queue, since the Shift actions are
synchronised, but they require two separate stacks,
one for the syntactic derivation and one for the se-
mantic derivation.
The probability of each synchronous derivation
chunk Ct is the product of four factors, related to
the syntactic level, the semantic level and the two
synchronising steps. The probability of ctd is de-
composed into one probability for each derivation
action Di, conditioned on its history using the chain
rule, and likewise for cts. These probabilities are es-
timated using the method described in section 3.
</bodyText>
<table confidence="0.993153875">
Syn cross Sem cross Sem tree No parse
Cat 0% 0% 61.4% 0%
Chi 0% 28.0% 28.6% 9.5%
Cze 22.4% 16.3% 6.1% 1.8%
Eng 7.6% 43.9% 21.4% 3.9%
Ger 28.1% 1.3% 97.4% 0.0%
Jap 0.9% 38.3% 11.2% 14.4%
Spa 0% 0% 57.1% 0%
</table>
<tableCaption confidence="0.99544775">
Table 1: For each language, percentage of training sen-
tences with crossing arcs in syntax and semantics, with
semantic arcs forming a tree, and which were not parsable
using the Swap action.
</tableCaption>
<bodyText confidence="0.996998351351352">
One of the main characteristics of our syn-
chronous representation, unlike other synchronous
representations of syntax and semantics (Nesson et
al., 2008), is that the synchronisation is done on
words, rather than on structural components. We
take advantage of this freedom and adopt different
methods for handling crossing arcs for syntax and
for semantics.
While both syntax and semantics are represented
as dependency graphs, these graphs differ substan-
tially in their properties. Some statistics which in-
dicate these differences are shown in table 1. For
example, English syntactic dependencies form trees,
while semantic dependency structures are only trees
21.4% of the time, since in general each struc-
ture does not form a connected graph and some
nodes may have more than one parent. The syn-
tactic dependency structures for only 7.6% of En-
glish sentences contain crossing arcs, while 43.9%
of the semantic dependency structures contain cross-
ing arcs. Due to variations both in language char-
acteristics and annotation decisions across corpora,
these differences between syntax and semantics vary
across the seven languages, but they are consis-
tent enough to motivate the development of new
techniques specifically for handling semantic depen-
dency structures. In particular, we use a different
method for parsing crossing arcs.
For parsing crossing semantic arcs (i.e. non-
planar graphs), we use the approach proposed in
Titov et al. (2009), which introduces an action Swap
that swaps the top two elements on the parser’s
stack. The Swap action allows the parser to reorder
words online during the parse. This allows words
to be processed in different orders during different
Dbt d = Dbts−1
where s = Shiftt−1 an
</bodyText>
<figure confidence="0.48050575">
d
Det
d = Dets+1
d+1 s = Shiftt. Then the actions of
</figure>
<page confidence="0.989648">
38
</page>
<bodyText confidence="0.999872181818182">
portions of the parse, so some arcs can be specified
using one ordering, then other arcs can be specified
using another ordering. Titov et al. (2009) found that
only using the Swap action as a last resort is the best
strategy for English (compared to using it preemp-
tively to address future crossing arcs) and we use
the same strategy here for all languages.
Syntactic graphs do not use a Swap action.
We adopt the HEAD method of Nivre and Nils-
son (2005) to de-projectivise syntactic dependencies
outside of parsing.1
</bodyText>
<sectionHeader confidence="0.994123" genericHeader="method">
3 Features and New Developments
</sectionHeader>
<bodyText confidence="0.99982378125">
The synchronous derivations described above are
modelled with a type of Bayesian Network called an
Incremental Sigmoid Belief Network (ISBN) (Titov
and Henderson, 2007a). As in Henderson et al.
(2008), the ISBN model distinguishes two types of
latent states: syntactic states, when syntactic deci-
sions are considered, and semantic states, when se-
mantic decision are considered. Latent states are
vectors of binary latent variables, which are condi-
tioned on variables from previous states via a pattern
of connecting edges determined by the previous de-
cisions. These latent-to-latent connections are used
to engineer soft biases which reflect the relevant do-
mains of locality in the structure being built. For
these we used the set of connections proposed in
Titov et al. (2009), which includes latent-to-latent
connections both from syntax states to semantics
states and vice versa. The latent variable vectors are
also conditioned on a set of observable features of
the derivation history. For these features, we start
with the feature set from Titov et al. (2009), which
extends the semantic features proposed in Hender-
son et al. (2008) to allow better handling of the non-
planar structures in semantics. Most importantly, all
the features previously included for the top of the
stack were also included for the word just under the
top of the stack. To this set we added one more type
of feature, discussed below.
We made some modifications to reflect differ-
ences in the task definition between the 2008 and
2009 shared tasks, and experimented with one
type of features which had been previously imple-
</bodyText>
<footnote confidence="0.6844795">
1The statistics in Table 1 suggest that, for some languages,
swapping might be beneficial for syntax as well.
</footnote>
<bodyText confidence="0.999983105263158">
mented. For the former modifications, the system
was adapted to allow the use of the PFEAT and
FILLPRED fields in the data, which both resulted
in improved accuracy for all the languages. The
PFEAT data field (automatically predicted morpho-
logical features) was introduced in the system in
two ways, as an atomic feature bundle that is pre-
dicted when predicting the word, and split into its
elementary components when conditioning on a pre-
vious word, as was done in Titov and Henderson
(2007b). Because the testing data included a spec-
ification of which words were annotated as predi-
cates (the FILLPRED data field), we constrained the
parser’s output so as to be consistent with this speci-
fication. For rare predicates, if the predicate was not
in the parser’s lexicon (extracted from the training
set), then a sense was taken from the list of senses
reported in the Lexicon and Frame Set resources
available for the closed challenge. If this informa-
tion was not available, then a default sense was con-
structed based on the automatically predicted lemma
(PLEMMA) of the predicate.
We also made use of a previously implemented
type of feature that allows the prediction of a seman-
tic link between two words to be conditioned on the
syntactic dependency already predicted between the
same two words. While this feature had previously
not helped for English, it did result in an overall im-
provement across the languages.
Also, in comparison with previous experiments,
the search beam used in the decoding phase was in-
creased from 50 to 80, producing a small improve-
ment in the overall development score.
All development effort took about two person-
months, mostly by someone who had no previous
experience with the system. Most of this time was
spent on the above differences in the task definition
between the 2008 and 2009 shared tasks.
</bodyText>
<sectionHeader confidence="0.999888" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999859571428572">
We participated in the joint task of the closed chal-
lenge, as described in Hajiˇc et al. (2009). The
datasets used in this challenge are described in Taul´e
et al. (2008) (Catalan and Spanish), Palmer and Xue
(2009) (Chinese), Hajiˇc et al. (2006) (Czech), Sur-
deanu et al. (2008) (English), Burchardt et al. (2006)
(German), and Kawahara et al. (2002) (Japanese).
</bodyText>
<page confidence="0.992523">
39
</page>
<table confidence="0.9997205">
Rank Average Catalan Chinese Czech English German Japanese Spanish
macro F1 3 82.14 82.66 76.15 83.21 86.03 79.59 84.91 82.43
syntactic acc 1 @85.77 @87.86 76.11 @80.38 88.79 87.29 92.34 @87.64
semantic F1 3 78.42 77.44 76.05 86.02 83.24 71.78 77.23 77.19
</table>
<tableCaption confidence="0.99522">
Table 2: The three main scores for our system. Rank is within task.
</tableCaption>
<table confidence="0.9998155">
Rank Ave Cze-ood Eng-ood Ger-ood
macro F1 3 75.93 @80.70 75.76 71.32
syn Acc 2 78.01 @76.41 80.84 76.77
sem F1 3 73.63 84.99 70.65 65.25
</table>
<tableCaption confidence="0.968903">
Table 3: Results on out-of-domain for our system. Rank
is within task.
</tableCaption>
<bodyText confidence="0.999970911764706">
The official results on the testing set are shown in
tables 2, 3, and 4. The symbol “@” indicates the
best result across systems. In table 5, we show our
rankings across the different datasets, amongst sys-
tems submitted for the same task.
The overall score used to rank systems is the un-
weighted average of the syntactic labeled accuracy
and the semantic labeled F1 measure, across all lan-
guages (“macro F1” in table 2). We were ranked
third, out of 14 systems. There was only a 0.5% dif-
ference between our score and that of the best sys-
tem, while there was a 1.29% difference between our
score and the fourth ranked system. Only consid-
ering syntactic accuracy, we had the highest aver-
age score of all systems, with the highest individual
score for Catalan, Czech, and Spanish. Only con-
sidering semantic F1, we were again ranked third.
Our results for out-of-domain data (table 3) achieved
a similar level of success, although here we were
ranked second for average syntactic accuracy. Our
precision on semantic arcs was generally much bet-
ter than our recall (shown in table 4). However,
other systems had a similar imbalance, resulting in
no change in our third place ranking for semantic
precision and for semantic recall. Only when the se-
mantic precision is averaged with syntactic accuracy
do we squeeze into second place (“macro Prec”).
To get a more detailed picture of the strengths
and weaknesses of our system, we computed its rank
within each dataset, shown in table 5. Overall, our
system is robust across languages, with little fluc-
tuation in ranking for the overall score, including
for out-of-domain data. The one noticeable excep-
tion to this consistency is the syntactic score for En-
</bodyText>
<figure confidence="0.971890444444445">
data time (min) macro F1
Czech 25% 5007 73.84
50% 3699 77.57
75% 4201 79.10
100% 6870 80.55
English 25% 1300 79.02
50% 1899 81.61
75% 3196 82.41
100% 3191 83.27
</figure>
<tableCaption confidence="0.709388">
Table 6: Training times and development set accuracies
using different percentages of the training data, for Czech
and English.
</tableCaption>
<bodyText confidence="0.994170862068966">
glish out-of-domain data. The other ranks for En-
glish out-of-domain and English in-domain scores
are also on the poor side. These results support our
claim that our parser has not undergone much hand-
tuning, since it was originally developed for English.
It is not currently clear whether this relative differ-
ence reflects a English-specific weakness in our sys-
tem, or that many of the other systems have been
fine-tuned for English.
On the higher end of our dataset rankings, we
do relatively well on Catalan, Czech, and Span-
ish. Catalan and Spanish are unique amongst these
datasets in that they have no crossing arcs in their
semantic structure. Czech seems to have semantic
structures which are relatively well handled by our
derivations with Swap. As indicated above in ta-
ble 1, only 2% of sentences are unparsable, despite
16% requiring the Swap action. However, this argu-
ment does not explain why our parser did relatively
poorly on German semantic dependencies. Regard-
less, these observations would suggest that our sys-
tem is still having trouble with crossing dependen-
cies, despite the introduction of the Swap operation,
and that our learning method could achieve better
performance with an improved treatment of cross-
ing semantic dependencies.
Table 6 shows how accuracies and training times
vary with the size of the training dataset, for Czech
and English. Training times vary in part because
</bodyText>
<page confidence="0.991866">
40
</page>
<table confidence="0.995957">
Rank Ave Cat Chi Cze Eng Ger Jap Spa Cze-ood Eng-ood Ger-ood
semantic Prec 3 81.60 79.08 80.93 87.45 84.92 75.60 83.75 79.44 85.90 72.89 75.19
semantic Rec 3 75.56 75.87 71.73 @84.64 81.63 68.33 71.65 75.05 @84.09 68.55 57.63
macro Prec 2 83.68 83.47 78.52 83.91 86.86 81.44 88.05 83.54 81.16 76.86 @75.98
macro Rec 3 80.66 @81.86 73.92 @82.51 85.21 77.81 81.99 81.35 @80.25 74.70 67.20
</table>
<tableCaption confidence="0.970177">
Table 4: Semantic precision and recall and macro precision and recall for our system. Rank is within task.
</tableCaption>
<table confidence="0.99868625">
Rank by Ave Cat Chi Cze Eng Ger Jap Spa Ave-ood Cze-ood Eng-ood Ger-ood
macro F1 3 2 3 2 4 4 3 2 3 1 4 3
syntactic Acc 1 1 4 1 3 2 2 1 2 1 7 2
semantic F1 3 2 4 2 4 5 4 2 3 2 4 3
</table>
<tableCaption confidence="0.99945">
Table 5: Our system’s rank within task according to the three main measures, for each dataset.
</tableCaption>
<figure confidence="0.921012">
0 10 20 30 40 50
Words per Second
</figure>
<figureCaption confidence="0.995160333333333">
Figure 1: Difference in development set macro F1 as the
search beam is decreased from the submitted beam (80)
to 40, 20, 10, and 5, plotted against parser speed.
</figureCaption>
<bodyText confidence="0.998456909090909">
random variations can result in different numbers of
training cycles before convergence. Accuracies ap-
pear to be roughly log-linear with data size.
Figure 1 shows how the accuracy of the parser de-
grades as we speed it up by decreasing the search
beam used in decoding, for each language. For some
languages, a slightly smaller search beam is actually
more accurate,2 but for smaller beams the trade-off
of accuracy versus words-per-second is roughly lin-
ear. Parsing time per word is also linear in beam
width, with a zero intercept.
</bodyText>
<sectionHeader confidence="0.996907" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999268">
In the joint task of the closed challenge of the
CoNLL 2009 shared task (Hajiˇc et al., 2009), we in-
vestigated how well a model of syntactic-semantic
dependency parsing developed for English would
</bodyText>
<footnote confidence="0.905842">
2This fact suggests that we could have gotten improved re-
sults by tailoring the search beam to individual languages.
</footnote>
<bodyText confidence="0.999590285714286">
generalise to the other six languages. This model
provides a single generative probability of the joint
syntactic and semantic dependency structures, but
allows separate representations for these two struc-
tures by parsing the two structures synchronously.
Finding the statistical correlations both between and
within these structures is facilitated through the use
of latent variables, which induce features automat-
ically from the data, thereby greatly reducing the
need for hand-coded feature engineering.
This latent variable model proved very robust
across languages, achieving a ranking of between
second and fourth on each language, including for
out-of-domain data. The extent to which the parser
does not rely on hand-crafting is underlined by the
fact that its worst ranking is for English, the lan-
guage for which it was developed (particularly for
out-of-domain data). The parser was ranked third
overall out of 14 systems, with a macro averaged F1
score of 82.14%, only 0.5% worse than the best sys-
tem.
Both joint learning and conditioning decisions
about semantic dependencies on latent representa-
tions of syntactic parsing states were crucial to the
success of our model, as was previously demon-
strated in Henderson et al. (2008). There, remov-
ing this conditioning led to a 3.5% drop in the SRL
score. This result seems to contradict the gen-
eral trend in the CoNLL-2008 shared task, where
joint learning had only limited success. The lat-
ter fact may be explained by recent theoretical re-
sults demonstrating that pipelines can be preferable
to joint learning (Roth et al., 2009) when no shared
hidden representation is learnt. Our system (Hender-
son et al., 2008) was the only one which attempted to
</bodyText>
<figure confidence="0.9979738">
Macro F1 Difference
−0.2
−0.4
−0.6
−0.8
−1.2
−1.4
−1
0
Saa
Rat
Ger
Eng
Cze
Chi
</figure>
<page confidence="0.998048">
41
</page>
<bodyText confidence="0.999915333333333">
learn a common hidden representation for this mul-
titask learning problem and also was the only one
which achieved significant gain from joint parameter
estimation. We believe that learning shared hidden
representations for related NLP problems is a very
promising direction for further research.
</bodyText>
<sectionHeader confidence="0.998359" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<copyright confidence="0.593678166666667">
We thank Gabriele Musillo and Dan Roth for help and
advice. This work was partly funded by Swiss NSF
grants 100015-122643 and PBGE22-119276, European
Community FP7 grant 216594 (CLASSiC, www.classic-
project.org), US NSF grant SoD-HCER-0613885 and
DARPA (Bootstrap Learning Program).
</copyright>
<sectionHeader confidence="0.998943" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999859360465116">
Aljoscha Burchardt, Katrin Erk, Anette Frank, Andrea
Kowalski, Sebastian Pad´o, and Manfred Pinkal. 2006.
The SALSA corpus: a German corpus resource for
lexical semantics. In Proceedings of the 5th Interna-
tional Conference on Language Resources and Evalu-
ation (LREC-2006), Genoa, Italy.
Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr
Sgall, Petr Pajas, Jan ˇStˇep´anek, JiˇrfHavelka, Marie
Mikulov´a, and Zdenˇek ˇZabokrtsk´y. 2006. Prague De-
pendency Treebank 2.0.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Martf, Llufs
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 shared task: Syntactic and semantic depen-
dencies in multiple languages. In Proceedings of
the 13th Conference on Computational Natural Lan-
guage Learning (CoNLL-2009), June 4-5, Boulder,
Colorado, USA.
James Henderson, Paola Merlo, Gabriele Musillo, and
Ivan Titov. 2008. A latent variable model of syn-
chronous parsing for syntactic and semantic dependen-
cies. In Proceedings of CONLL 2008, pages 178–182,
Manchester, UK.
Daisuke Kawahara, Sadao Kurohashi, and Kˆoiti Hasida.
2002. Construction of a Japanese relevance-tagged
corpus. In Proceedings of the 3rd International
Conference on Language Resources and Evaluation
(LREC-2002), pages 2008–2013, Las Palmas, Canary
Islands.
Rebecca Nesson, Giorgio Satta, and Stuart M. Shieber.
2008. Optimal k-arization of synchronous tree-
adjoining grammar. In Proceedings of ACL-08: HLT,
pages 604–612, Columbus, Ohio, June.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-projective
dependency parsing. In Proc. 43rd Meeting of Asso-
ciation for Computational Linguistics, pages 99–106,
Ann Arbor, MI.
Joakim Nivre, Johan Hall, Jens Nilsson, Gulsen Eryigit,
and Svetoslav Marinov. 2006. Pseudo-projective de-
pendency parsing with support vector machines. In
Proc. of the Tenth Conference on Computational Nat-
ural Language Learning, pages 221–225, New York,
USA.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 shared task on depen-
dency parsing. In Proceedings of the CoNLL Shared
Task Session of EMNLP-CoNLL 2007, pages 915–932,
Prague, Czech Republic, June.
Martha Palmer and Nianwen Xue. 2009. Adding seman-
tic roles to the Chinese Treebank. Natural Language
Engineering, 15(1):143–172.
Dan Roth, Kevin Small, and Ivan Titov. 2009. Sequential
learning of classifiers for structured prediction prob-
lems. In AISTATS, Clearwater, Florida, USA.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llufs M`arquez, and Joakim Nivre. 2008. The CoNLL-
2008 shared task on joint parsing of syntactic and se-
mantic dependencies. In Proceedings of the 12th Con-
ference on Computational Natural Language Learning
(CoNLL-2008).
Mariona Taul´e, Maria Ant`onia Martf, and Marta Re-
casens. 2008. AnCora: Multilevel Annotated Corpora
for Catalan and Spanish. In Proceedings of the 6th
International Conference on Language Resources and
Evaluation (LREC-2008), Marrakesh, Morroco.
Ivan Titov and James Henderson. 2007a. Constituent
parsing with Incremental Sigmoid Belief Networks. In
Proceedings of the 45th Annual Meeting of the Asso-
ciation of Computational Linguistics, pages 632–639,
Prague, Czech Republic.
Ivan Titov and James Henderson. 2007b. Fast and ro-
bust multilingual dependency parsing with a genera-
tive latent variable model. In Proc. Joint Conf. on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL 2007), Prague, Czech Republic. (CoNLL
Shared Task).
Ivan Titov, James Henderson, Paola Merlo, and Gabriele
Musillo. 2009. Online graph planarisation for syn-
chronous parsing of semantic and syntactic dependen-
cies. In Proc. Twenty-First International Joint Confer-
ence on Artificial Intelligence (IJCAI-09), Pasadena,
California.
</reference>
<page confidence="0.999295">
42
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.275437">
<title confidence="0.99993">A Latent Variable Model of Synchronous Syntactic-Semantic Parsing Multiple Languages</title>
<author confidence="0.999886">Andrea Gesmundo James Henderson Paola Merlo</author>
<affiliation confidence="0.9974185">Univ Geneva Univ Geneva Univ Geneva Univ Illinois at U-C Dept Computer Sci Dept Computer Sci Dept Linguistics Dept Computer Sci</affiliation>
<abstract confidence="0.945203571428571">Andrea.Gesmundo@ James.Henderson@ Paola.Merlo@ titov@uiuc.edu unige.ch unige.ch unige.ch Abstract Motivated by the large number of languages (seven) and the short development time (two months) of the 2009 CoNLL shared task, we exploited latent variables to avoid the costly process of hand-crafted feature engineering, allowing the latent variables to induce features from the data. We took a pre-existing generative latent variable model of joint syntacticsemantic dependency parsing, developed for English, and applied it to six new languages with minimal adjustments. The parser’s robustness across languages indicates that this parser has a very general feature set. The parser’s high performance indicates that its latent variables succeeded in inducing effective features. This system was ranked third overall with a macro averaged F1 score of 82.14%, only 0.5% worse than the best system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Katrin Erk</author>
<author>Anette Frank</author>
<author>Andrea Kowalski</author>
<author>Sebastian Pad´o</author>
<author>Manfred Pinkal</author>
</authors>
<title>The SALSA corpus: a German corpus resource for lexical semantics.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC-2006),</booktitle>
<location>Genoa, Italy.</location>
<marker>Burchardt, Erk, Frank, Kowalski, Pad´o, Pinkal, 2006</marker>
<rawString>Aljoscha Burchardt, Katrin Erk, Anette Frank, Andrea Kowalski, Sebastian Pad´o, and Manfred Pinkal. 2006. The SALSA corpus: a German corpus resource for lexical semantics. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC-2006), Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jarmila Panevov´a</author>
<author>Eva Hajiˇcov´a</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
<author>Jan ˇStˇep´anek</author>
<author>Marie Mikulov´a JiˇrfHavelka</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
</authors>
<date>2006</date>
<journal>Prague Dependency Treebank</journal>
<volume>2</volume>
<marker>Hajiˇc, Panevov´a, Hajiˇcov´a, Sgall, Pajas, ˇStˇep´anek, JiˇrfHavelka, ˇZabokrtsk´y, 2006</marker>
<rawString>Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek, JiˇrfHavelka, Marie Mikulov´a, and Zdenˇek ˇZabokrtsk´y. 2006. Prague Dependency Treebank 2.0.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Martf</author>
<author>Llufs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
<author>Pavel Straˇn´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL-2009),</booktitle>
<location>Boulder, Colorado, USA.</location>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Martf, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Martf, Llufs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL-2009), June 4-5, Boulder, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Henderson</author>
<author>Paola Merlo</author>
<author>Gabriele Musillo</author>
<author>Ivan Titov</author>
</authors>
<title>A latent variable model of synchronous parsing for syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of CONLL</booktitle>
<pages>178--182</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="1860" citStr="Henderson et al., 2008" startWordPosition="270" endWordPosition="273">ranslation and the recent availability of syntactically annotated corpora for multiple languages (Nivre et al., 2007) has provided a new opportunity for evaluating the cross-linguistic validity of statistical models of syntactic structure. This opportunity has been significantly expanded with the 2009 CoNLL shared task on syntactic and semantic parsing of seven languages (Hajiˇc et al., 2009) belonging to several different language families. We participate in this task with a generative, history-based model proposed in the CoNLL 2008 0Authors in alphabetical order. 37 shared task for English (Henderson et al., 2008) and further improved to tackle non-planar dependencies (Titov et al., 2009). This model maximises the joint probability of the syntactic and semantic dependencies and thereby enforces that the output structure be globally coherent, but the use of synchronous parsing allows it to maintain separate structures for the syntax and semantics. The probabilistic model is based on Incremental Sigmoid Belief Networks (ISBNs), a recently proposed latent variable model for syntactic structure prediction, which has shown very good performance for both constituency (Titov and Henderson, 2007a) and dependen</context>
<context position="3357" citStr="Henderson et al. (2008)" startWordPosition="505" endWordPosition="508">work, we evaluate the ability of this method to generalise across several languages. We take the model as it was developed for English, and apply it directly to all seven languages. The only fine-tuning was to evaluate whether to include one feature type which we had previously found did not help for English, but helped overall. No other feature engineering was done. The use of latent variables to induce features automatically from the data gives our method the adaptability necessary to perform well across all seven languages, and demonstrates the lack of language specificity in the models of Henderson et al. (2008) and Titov et al. (2009). The main properties of this model, that differentiate it from other approaches, is the use of synchronous syntactic and semantic derivations and the Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 37–42, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics use of online planarisation of crossing semantic dependencies. This system was ranked third overall with a macro averaged F1 score of 82.14%, only 0.5% worse than the best system. 2 The Synchronous Model The use of synchronous </context>
<context position="8707" citStr="Henderson et al. (2008)" startWordPosition="1384" endWordPosition="1387">g. Titov et al. (2009) found that only using the Swap action as a last resort is the best strategy for English (compared to using it preemptively to address future crossing arcs) and we use the same strategy here for all languages. Syntactic graphs do not use a Swap action. We adopt the HEAD method of Nivre and Nilsson (2005) to de-projectivise syntactic dependencies outside of parsing.1 3 Features and New Developments The synchronous derivations described above are modelled with a type of Bayesian Network called an Incremental Sigmoid Belief Network (ISBN) (Titov and Henderson, 2007a). As in Henderson et al. (2008), the ISBN model distinguishes two types of latent states: syntactic states, when syntactic decisions are considered, and semantic states, when semantic decision are considered. Latent states are vectors of binary latent variables, which are conditioned on variables from previous states via a pattern of connecting edges determined by the previous decisions. These latent-to-latent connections are used to engineer soft biases which reflect the relevant domains of locality in the structure being built. For these we used the set of connections proposed in Titov et al. (2009), which includes latent</context>
<context position="19438" citStr="Henderson et al. (2008)" startWordPosition="3199" endWordPosition="3202">h on each language, including for out-of-domain data. The extent to which the parser does not rely on hand-crafting is underlined by the fact that its worst ranking is for English, the language for which it was developed (particularly for out-of-domain data). The parser was ranked third overall out of 14 systems, with a macro averaged F1 score of 82.14%, only 0.5% worse than the best system. Both joint learning and conditioning decisions about semantic dependencies on latent representations of syntactic parsing states were crucial to the success of our model, as was previously demonstrated in Henderson et al. (2008). There, removing this conditioning led to a 3.5% drop in the SRL score. This result seems to contradict the general trend in the CoNLL-2008 shared task, where joint learning had only limited success. The latter fact may be explained by recent theoretical results demonstrating that pipelines can be preferable to joint learning (Roth et al., 2009) when no shared hidden representation is learnt. Our system (Henderson et al., 2008) was the only one which attempted to Macro F1 Difference −0.2 −0.4 −0.6 −0.8 −1.2 −1.4 −1 0 Saa Rat Ger Eng Cze Chi 41 learn a common hidden representation for this mul</context>
</contexts>
<marker>Henderson, Merlo, Musillo, Titov, 2008</marker>
<rawString>James Henderson, Paola Merlo, Gabriele Musillo, and Ivan Titov. 2008. A latent variable model of synchronous parsing for syntactic and semantic dependencies. In Proceedings of CONLL 2008, pages 178–182, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
<author>Kˆoiti Hasida</author>
</authors>
<title>Construction of a Japanese relevance-tagged corpus.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002),</booktitle>
<pages>2008--2013</pages>
<location>Las Palmas, Canary Islands.</location>
<contexts>
<context position="12430" citStr="Kawahara et al. (2002)" startWordPosition="2003" endWordPosition="2006">ment score. All development effort took about two personmonths, mostly by someone who had no previous experience with the system. Most of this time was spent on the above differences in the task definition between the 2008 and 2009 shared tasks. 4 Results and Discussion We participated in the joint task of the closed challenge, as described in Hajiˇc et al. (2009). The datasets used in this challenge are described in Taul´e et al. (2008) (Catalan and Spanish), Palmer and Xue (2009) (Chinese), Hajiˇc et al. (2006) (Czech), Surdeanu et al. (2008) (English), Burchardt et al. (2006) (German), and Kawahara et al. (2002) (Japanese). 39 Rank Average Catalan Chinese Czech English German Japanese Spanish macro F1 3 82.14 82.66 76.15 83.21 86.03 79.59 84.91 82.43 syntactic acc 1 @85.77 @87.86 76.11 @80.38 88.79 87.29 92.34 @87.64 semantic F1 3 78.42 77.44 76.05 86.02 83.24 71.78 77.23 77.19 Table 2: The three main scores for our system. Rank is within task. Rank Ave Cze-ood Eng-ood Ger-ood macro F1 3 75.93 @80.70 75.76 71.32 syn Acc 2 78.01 @76.41 80.84 76.77 sem F1 3 73.63 84.99 70.65 65.25 Table 3: Results on out-of-domain for our system. Rank is within task. The official results on the testing set are shown in</context>
</contexts>
<marker>Kawahara, Kurohashi, Hasida, 2002</marker>
<rawString>Daisuke Kawahara, Sadao Kurohashi, and Kˆoiti Hasida. 2002. Construction of a Japanese relevance-tagged corpus. In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002), pages 2008–2013, Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Nesson</author>
<author>Giorgio Satta</author>
<author>Stuart M Shieber</author>
</authors>
<title>Optimal k-arization of synchronous treeadjoining grammar.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>604--612</pages>
<location>Columbus, Ohio,</location>
<contexts>
<context position="6337" citStr="Nesson et al., 2008" startWordPosition="996" endWordPosition="999">e probabilities are estimated using the method described in section 3. Syn cross Sem cross Sem tree No parse Cat 0% 0% 61.4% 0% Chi 0% 28.0% 28.6% 9.5% Cze 22.4% 16.3% 6.1% 1.8% Eng 7.6% 43.9% 21.4% 3.9% Ger 28.1% 1.3% 97.4% 0.0% Jap 0.9% 38.3% 11.2% 14.4% Spa 0% 0% 57.1% 0% Table 1: For each language, percentage of training sentences with crossing arcs in syntax and semantics, with semantic arcs forming a tree, and which were not parsable using the Swap action. One of the main characteristics of our synchronous representation, unlike other synchronous representations of syntax and semantics (Nesson et al., 2008), is that the synchronisation is done on words, rather than on structural components. We take advantage of this freedom and adopt different methods for handling crossing arcs for syntax and for semantics. While both syntax and semantics are represented as dependency graphs, these graphs differ substantially in their properties. Some statistics which indicate these differences are shown in table 1. For example, English syntactic dependencies form trees, while semantic dependency structures are only trees 21.4% of the time, since in general each structure does not form a connected graph and some</context>
</contexts>
<marker>Nesson, Satta, Shieber, 2008</marker>
<rawString>Rebecca Nesson, Giorgio Satta, and Stuart M. Shieber. 2008. Optimal k-arization of synchronous treeadjoining grammar. In Proceedings of ACL-08: HLT, pages 604–612, Columbus, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Pseudo-projective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proc. 43rd Meeting of Association for Computational Linguistics,</booktitle>
<pages>99--106</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="8411" citStr="Nivre and Nilsson (2005)" startWordPosition="1341" endWordPosition="1345">arse. This allows words to be processed in different orders during different Dbt d = Dbts−1 where s = Shiftt−1 an d Det d = Dets+1 d+1 s = Shiftt. Then the actions of 38 portions of the parse, so some arcs can be specified using one ordering, then other arcs can be specified using another ordering. Titov et al. (2009) found that only using the Swap action as a last resort is the best strategy for English (compared to using it preemptively to address future crossing arcs) and we use the same strategy here for all languages. Syntactic graphs do not use a Swap action. We adopt the HEAD method of Nivre and Nilsson (2005) to de-projectivise syntactic dependencies outside of parsing.1 3 Features and New Developments The synchronous derivations described above are modelled with a type of Bayesian Network called an Incremental Sigmoid Belief Network (ISBN) (Titov and Henderson, 2007a). As in Henderson et al. (2008), the ISBN model distinguishes two types of latent states: syntactic states, when syntactic decisions are considered, and semantic states, when semantic decision are considered. Latent states are vectors of binary latent variables, which are conditioned on variables from previous states via a pattern of</context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>Joakim Nivre and Jens Nilsson. 2005. Pseudo-projective dependency parsing. In Proc. 43rd Meeting of Association for Computational Linguistics, pages 99–106, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>Gulsen Eryigit</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Pseudo-projective dependency parsing with support vector machines.</title>
<date>2006</date>
<booktitle>In Proc. of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>221--225</pages>
<location>New York, USA.</location>
<contexts>
<context position="4382" citStr="Nivre et al., 2006" startWordPosition="660" endWordPosition="663">ossing semantic dependencies. This system was ranked third overall with a macro averaged F1 score of 82.14%, only 0.5% worse than the best system. 2 The Synchronous Model The use of synchronous parsing allows separate structures for syntax and semantics, while still modeling their joint probability. We use the approach to synchronous parsing proposed in Henderson et al. (2008), where we start with two separate derivations specifying each of the two structures, then synchronise these derivations at each word. The individual derivations are based on Nivre’s shift-reduce-style parsing algorithm (Nivre et al., 2006), as discussed further below. First we illustrate the high-level structure of the model, discussed in more detail in Henderson et al. (2008). Let Td be a syntactic dependency tree with derivation D1d, ..., Dmd d , and Ts be a semantic dependency graph with derivation D1s, ..., Dms s. To define derivations for the joint structure Td, Ts, we divide the two derivations into the chunks between shifting each word onto the bt et bt et stack, ctd = Ddd, ..., Ddd and ct = Dss, ..., Dss, d−1 the synchronous derivations consist of quadruples Ct = (ctd, Switch, cts, Shiftt), where Switch means switching </context>
</contexts>
<marker>Nivre, Hall, Nilsson, Eryigit, Marinov, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Gulsen Eryigit, and Svetoslav Marinov. 2006. Pseudo-projective dependency parsing with support vector machines. In Proc. of the Tenth Conference on Computational Natural Language Learning, pages 221–225, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007,</booktitle>
<pages>915--932</pages>
<location>Prague, Czech Republic,</location>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915–932, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Nianwen Xue</author>
</authors>
<title>Adding semantic roles to the Chinese Treebank.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="12294" citStr="Palmer and Xue (2009)" startWordPosition="1981" endWordPosition="1984">periments, the search beam used in the decoding phase was increased from 50 to 80, producing a small improvement in the overall development score. All development effort took about two personmonths, mostly by someone who had no previous experience with the system. Most of this time was spent on the above differences in the task definition between the 2008 and 2009 shared tasks. 4 Results and Discussion We participated in the joint task of the closed challenge, as described in Hajiˇc et al. (2009). The datasets used in this challenge are described in Taul´e et al. (2008) (Catalan and Spanish), Palmer and Xue (2009) (Chinese), Hajiˇc et al. (2006) (Czech), Surdeanu et al. (2008) (English), Burchardt et al. (2006) (German), and Kawahara et al. (2002) (Japanese). 39 Rank Average Catalan Chinese Czech English German Japanese Spanish macro F1 3 82.14 82.66 76.15 83.21 86.03 79.59 84.91 82.43 syntactic acc 1 @85.77 @87.86 76.11 @80.38 88.79 87.29 92.34 @87.64 semantic F1 3 78.42 77.44 76.05 86.02 83.24 71.78 77.23 77.19 Table 2: The three main scores for our system. Rank is within task. Rank Ave Cze-ood Eng-ood Ger-ood macro F1 3 75.93 @80.70 75.76 71.32 syn Acc 2 78.01 @76.41 80.84 76.77 sem F1 3 73.63 84.99</context>
</contexts>
<marker>Palmer, Xue, 2009</marker>
<rawString>Martha Palmer and Nianwen Xue. 2009. Adding semantic roles to the Chinese Treebank. Natural Language Engineering, 15(1):143–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Kevin Small</author>
<author>Ivan Titov</author>
</authors>
<title>Sequential learning of classifiers for structured prediction problems.</title>
<date>2009</date>
<booktitle>In AISTATS,</booktitle>
<location>Clearwater, Florida, USA.</location>
<contexts>
<context position="19786" citStr="Roth et al., 2009" startWordPosition="3259" endWordPosition="3262">4%, only 0.5% worse than the best system. Both joint learning and conditioning decisions about semantic dependencies on latent representations of syntactic parsing states were crucial to the success of our model, as was previously demonstrated in Henderson et al. (2008). There, removing this conditioning led to a 3.5% drop in the SRL score. This result seems to contradict the general trend in the CoNLL-2008 shared task, where joint learning had only limited success. The latter fact may be explained by recent theoretical results demonstrating that pipelines can be preferable to joint learning (Roth et al., 2009) when no shared hidden representation is learnt. Our system (Henderson et al., 2008) was the only one which attempted to Macro F1 Difference −0.2 −0.4 −0.6 −0.8 −1.2 −1.4 −1 0 Saa Rat Ger Eng Cze Chi 41 learn a common hidden representation for this multitask learning problem and also was the only one which achieved significant gain from joint parameter estimation. We believe that learning shared hidden representations for related NLP problems is a very promising direction for further research. Acknowledgements We thank Gabriele Musillo and Dan Roth for help and advice. This work was partly fun</context>
</contexts>
<marker>Roth, Small, Titov, 2009</marker>
<rawString>Dan Roth, Kevin Small, and Ivan Titov. 2009. Sequential learning of classifiers for structured prediction problems. In AISTATS, Clearwater, Florida, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llufs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Llufs M`arquez, and Joakim Nivre. 2008. The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariona Taul´e</author>
<author>Maria Ant`onia Martf</author>
<author>Marta Recasens</author>
</authors>
<title>AnCora: Multilevel Annotated Corpora for Catalan and Spanish.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC-2008),</booktitle>
<location>Marrakesh, Morroco.</location>
<marker>Taul´e, Martf, Recasens, 2008</marker>
<rawString>Mariona Taul´e, Maria Ant`onia Martf, and Marta Recasens. 2008. AnCora: Multilevel Annotated Corpora for Catalan and Spanish. In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC-2008), Marrakesh, Morroco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
</authors>
<title>Constituent parsing with Incremental Sigmoid Belief Networks.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>632--639</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2445" citStr="Titov and Henderson, 2007" startWordPosition="357" endWordPosition="360">ask for English (Henderson et al., 2008) and further improved to tackle non-planar dependencies (Titov et al., 2009). This model maximises the joint probability of the syntactic and semantic dependencies and thereby enforces that the output structure be globally coherent, but the use of synchronous parsing allows it to maintain separate structures for the syntax and semantics. The probabilistic model is based on Incremental Sigmoid Belief Networks (ISBNs), a recently proposed latent variable model for syntactic structure prediction, which has shown very good performance for both constituency (Titov and Henderson, 2007a) and dependency parsing (Titov and Henderson, 2007b). The use of latent variables enables this architecture to be extended to learning a synchronous parse of syntax and semantics without overly restrictive assumptions about the linking between syntactic and semantic structures. In this work, we evaluate the ability of this method to generalise across several languages. We take the model as it was developed for English, and apply it directly to all seven languages. The only fine-tuning was to evaluate whether to include one feature type which we had previously found did not help for English, </context>
<context position="8674" citStr="Titov and Henderson, 2007" startWordPosition="1378" endWordPosition="1381"> be specified using another ordering. Titov et al. (2009) found that only using the Swap action as a last resort is the best strategy for English (compared to using it preemptively to address future crossing arcs) and we use the same strategy here for all languages. Syntactic graphs do not use a Swap action. We adopt the HEAD method of Nivre and Nilsson (2005) to de-projectivise syntactic dependencies outside of parsing.1 3 Features and New Developments The synchronous derivations described above are modelled with a type of Bayesian Network called an Incremental Sigmoid Belief Network (ISBN) (Titov and Henderson, 2007a). As in Henderson et al. (2008), the ISBN model distinguishes two types of latent states: syntactic states, when syntactic decisions are considered, and semantic states, when semantic decision are considered. Latent states are vectors of binary latent variables, which are conditioned on variables from previous states via a pattern of connecting edges determined by the previous decisions. These latent-to-latent connections are used to engineer soft biases which reflect the relevant domains of locality in the structure being built. For these we used the set of connections proposed in Titov et </context>
<context position="10710" citStr="Titov and Henderson (2007" startWordPosition="1713" endWordPosition="1716">ad been previously imple1The statistics in Table 1 suggest that, for some languages, swapping might be beneficial for syntax as well. mented. For the former modifications, the system was adapted to allow the use of the PFEAT and FILLPRED fields in the data, which both resulted in improved accuracy for all the languages. The PFEAT data field (automatically predicted morphological features) was introduced in the system in two ways, as an atomic feature bundle that is predicted when predicting the word, and split into its elementary components when conditioning on a previous word, as was done in Titov and Henderson (2007b). Because the testing data included a specification of which words were annotated as predicates (the FILLPRED data field), we constrained the parser’s output so as to be consistent with this specification. For rare predicates, if the predicate was not in the parser’s lexicon (extracted from the training set), then a sense was taken from the list of senses reported in the Lexicon and Frame Set resources available for the closed challenge. If this information was not available, then a default sense was constructed based on the automatically predicted lemma (PLEMMA) of the predicate. We also ma</context>
</contexts>
<marker>Titov, Henderson, 2007</marker>
<rawString>Ivan Titov and James Henderson. 2007a. Constituent parsing with Incremental Sigmoid Belief Networks. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 632–639, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
</authors>
<title>Fast and robust multilingual dependency parsing with a generative latent variable model.</title>
<date>2007</date>
<booktitle>In Proc. Joint Conf. on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL 2007),</booktitle>
<tech>(CoNLL Shared Task).</tech>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2445" citStr="Titov and Henderson, 2007" startWordPosition="357" endWordPosition="360">ask for English (Henderson et al., 2008) and further improved to tackle non-planar dependencies (Titov et al., 2009). This model maximises the joint probability of the syntactic and semantic dependencies and thereby enforces that the output structure be globally coherent, but the use of synchronous parsing allows it to maintain separate structures for the syntax and semantics. The probabilistic model is based on Incremental Sigmoid Belief Networks (ISBNs), a recently proposed latent variable model for syntactic structure prediction, which has shown very good performance for both constituency (Titov and Henderson, 2007a) and dependency parsing (Titov and Henderson, 2007b). The use of latent variables enables this architecture to be extended to learning a synchronous parse of syntax and semantics without overly restrictive assumptions about the linking between syntactic and semantic structures. In this work, we evaluate the ability of this method to generalise across several languages. We take the model as it was developed for English, and apply it directly to all seven languages. The only fine-tuning was to evaluate whether to include one feature type which we had previously found did not help for English, </context>
<context position="8674" citStr="Titov and Henderson, 2007" startWordPosition="1378" endWordPosition="1381"> be specified using another ordering. Titov et al. (2009) found that only using the Swap action as a last resort is the best strategy for English (compared to using it preemptively to address future crossing arcs) and we use the same strategy here for all languages. Syntactic graphs do not use a Swap action. We adopt the HEAD method of Nivre and Nilsson (2005) to de-projectivise syntactic dependencies outside of parsing.1 3 Features and New Developments The synchronous derivations described above are modelled with a type of Bayesian Network called an Incremental Sigmoid Belief Network (ISBN) (Titov and Henderson, 2007a). As in Henderson et al. (2008), the ISBN model distinguishes two types of latent states: syntactic states, when syntactic decisions are considered, and semantic states, when semantic decision are considered. Latent states are vectors of binary latent variables, which are conditioned on variables from previous states via a pattern of connecting edges determined by the previous decisions. These latent-to-latent connections are used to engineer soft biases which reflect the relevant domains of locality in the structure being built. For these we used the set of connections proposed in Titov et </context>
<context position="10710" citStr="Titov and Henderson (2007" startWordPosition="1713" endWordPosition="1716">ad been previously imple1The statistics in Table 1 suggest that, for some languages, swapping might be beneficial for syntax as well. mented. For the former modifications, the system was adapted to allow the use of the PFEAT and FILLPRED fields in the data, which both resulted in improved accuracy for all the languages. The PFEAT data field (automatically predicted morphological features) was introduced in the system in two ways, as an atomic feature bundle that is predicted when predicting the word, and split into its elementary components when conditioning on a previous word, as was done in Titov and Henderson (2007b). Because the testing data included a specification of which words were annotated as predicates (the FILLPRED data field), we constrained the parser’s output so as to be consistent with this specification. For rare predicates, if the predicate was not in the parser’s lexicon (extracted from the training set), then a sense was taken from the list of senses reported in the Lexicon and Frame Set resources available for the closed challenge. If this information was not available, then a default sense was constructed based on the automatically predicted lemma (PLEMMA) of the predicate. We also ma</context>
</contexts>
<marker>Titov, Henderson, 2007</marker>
<rawString>Ivan Titov and James Henderson. 2007b. Fast and robust multilingual dependency parsing with a generative latent variable model. In Proc. Joint Conf. on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL 2007), Prague, Czech Republic. (CoNLL Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
<author>Paola Merlo</author>
<author>Gabriele Musillo</author>
</authors>
<title>Online graph planarisation for synchronous parsing of semantic and syntactic dependencies.</title>
<date>2009</date>
<booktitle>In Proc. Twenty-First International Joint Conference on Artificial Intelligence (IJCAI-09),</booktitle>
<location>Pasadena, California.</location>
<contexts>
<context position="1936" citStr="Titov et al., 2009" startWordPosition="281" endWordPosition="284">ltiple languages (Nivre et al., 2007) has provided a new opportunity for evaluating the cross-linguistic validity of statistical models of syntactic structure. This opportunity has been significantly expanded with the 2009 CoNLL shared task on syntactic and semantic parsing of seven languages (Hajiˇc et al., 2009) belonging to several different language families. We participate in this task with a generative, history-based model proposed in the CoNLL 2008 0Authors in alphabetical order. 37 shared task for English (Henderson et al., 2008) and further improved to tackle non-planar dependencies (Titov et al., 2009). This model maximises the joint probability of the syntactic and semantic dependencies and thereby enforces that the output structure be globally coherent, but the use of synchronous parsing allows it to maintain separate structures for the syntax and semantics. The probabilistic model is based on Incremental Sigmoid Belief Networks (ISBNs), a recently proposed latent variable model for syntactic structure prediction, which has shown very good performance for both constituency (Titov and Henderson, 2007a) and dependency parsing (Titov and Henderson, 2007b). The use of latent variables enables</context>
<context position="3381" citStr="Titov et al. (2009)" startWordPosition="510" endWordPosition="513">y of this method to generalise across several languages. We take the model as it was developed for English, and apply it directly to all seven languages. The only fine-tuning was to evaluate whether to include one feature type which we had previously found did not help for English, but helped overall. No other feature engineering was done. The use of latent variables to induce features automatically from the data gives our method the adaptability necessary to perform well across all seven languages, and demonstrates the lack of language specificity in the models of Henderson et al. (2008) and Titov et al. (2009). The main properties of this model, that differentiate it from other approaches, is the use of synchronous syntactic and semantic derivations and the Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 37–42, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics use of online planarisation of crossing semantic dependencies. This system was ranked third overall with a macro averaged F1 score of 82.14%, only 0.5% worse than the best system. 2 The Synchronous Model The use of synchronous parsing allows separate </context>
<context position="7628" citStr="Titov et al. (2009)" startWordPosition="1197" endWordPosition="1200">s for only 7.6% of English sentences contain crossing arcs, while 43.9% of the semantic dependency structures contain crossing arcs. Due to variations both in language characteristics and annotation decisions across corpora, these differences between syntax and semantics vary across the seven languages, but they are consistent enough to motivate the development of new techniques specifically for handling semantic dependency structures. In particular, we use a different method for parsing crossing arcs. For parsing crossing semantic arcs (i.e. nonplanar graphs), we use the approach proposed in Titov et al. (2009), which introduces an action Swap that swaps the top two elements on the parser’s stack. The Swap action allows the parser to reorder words online during the parse. This allows words to be processed in different orders during different Dbt d = Dbts−1 where s = Shiftt−1 an d Det d = Dets+1 d+1 s = Shiftt. Then the actions of 38 portions of the parse, so some arcs can be specified using one ordering, then other arcs can be specified using another ordering. Titov et al. (2009) found that only using the Swap action as a last resort is the best strategy for English (compared to using it preemptivel</context>
<context position="9284" citStr="Titov et al. (2009)" startWordPosition="1475" endWordPosition="1478">son, 2007a). As in Henderson et al. (2008), the ISBN model distinguishes two types of latent states: syntactic states, when syntactic decisions are considered, and semantic states, when semantic decision are considered. Latent states are vectors of binary latent variables, which are conditioned on variables from previous states via a pattern of connecting edges determined by the previous decisions. These latent-to-latent connections are used to engineer soft biases which reflect the relevant domains of locality in the structure being built. For these we used the set of connections proposed in Titov et al. (2009), which includes latent-to-latent connections both from syntax states to semantics states and vice versa. The latent variable vectors are also conditioned on a set of observable features of the derivation history. For these features, we start with the feature set from Titov et al. (2009), which extends the semantic features proposed in Henderson et al. (2008) to allow better handling of the nonplanar structures in semantics. Most importantly, all the features previously included for the top of the stack were also included for the word just under the top of the stack. To this set we added one m</context>
</contexts>
<marker>Titov, Henderson, Merlo, Musillo, 2009</marker>
<rawString>Ivan Titov, James Henderson, Paola Merlo, and Gabriele Musillo. 2009. Online graph planarisation for synchronous parsing of semantic and syntactic dependencies. In Proc. Twenty-First International Joint Conference on Artificial Intelligence (IJCAI-09), Pasadena, California.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>