<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001753">
<title confidence="0.9899755">
UCM-2: a Rule-Based Approach to Infer the Scope of Negation via
Dependency Parsing
</title>
<author confidence="0.9945495">
Miguel Ballesteros, Alberto Diaz, Virginia Francisco,
Pablo Gerv´as, Jorge Carrillo de Albornoz and Laura Plaza
</author>
<affiliation confidence="0.846542">
Natural Interaction Based on Language Group
Complutense University of Madrid
Spain
</affiliation>
<email confidence="0.966182">
{miballes, albertodiaz, virginia}@fdi.ucm.es,
pgervas@sip.ucm.es, {jcalbornoz, lplazam}@fdi.ucm.es
</email>
<sectionHeader confidence="0.995596" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999539722222222">
UCM-2 infers the words that are affected by
negations by browsing dependency syntactic
structures. It first makes use of an algo-
rithm that detects negation cues, like no, not
or nothing, and the words affected by them
by traversing Minipar dependency structures.
Second, the scope of these negation cues is
computed by using a post-processing rule-
based approach that takes into account the in-
formation provided by the first algorithm and
simple linguistic clause boundaries. An initial
version of the system was developed to handle
the annotations of the Bioscope corpus. For
the present version, we have changed, omitted
or extended the rules and the lexicon of cues
(allowing prefix and suffix negation cues, such
as impossible or meaningless), to make it suit-
able for the present task.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953659574468">
One of the challenges of the *SEM Shared Task
(Morante and Blanco, 2012) is to infer and classify
the scope and event associated to negations, given
a training and a development corpus based on Co-
nan Doyle stories (Morante and Daelemans, 2012).
Negation, simple in concept, is a complex but essen-
tial phenomenon in any language. It turns an affir-
mative statement into a negative one, changing the
meaning completely. We believe therefore that be-
ing able to handle and classify negations we would
be able to improve several text mining applications.
Previous to this Shared Task, we can find several
systems that handle the scope of negation in the state
of the art. This is a complex problem, because it re-
quires, first, to find and capture the negation cues,
and second, based on either syntactic or semantic
representations, to identify the words that are di-
rectly (or indirectly) affected by these negation cues.
One of the main works that started this trend in natu-
ral language processing was published by Morante’s
team (2008; 2009), in which they presented a ma-
chine learning approach for the biomedical domain
evaluating it on the Bioscope corpus.
In 2010, a Workshop on Negation and Spec-
ulation in Natural Language Processing (Morante
and Sporleder, 2010) was held in Uppsala, Swe-
den. Most of the approaches presented worked in
the biomedical domain, which is the most studied in
negation detection.
The system presented in this paper is a modifica-
tion of the one published in Ballesteros et al. (2012).
This system was developed in order to replicate (as
far as possible) the annotations given in the Bio-
scope corpus (Vincze et al., 2008). Therefore, for
the one presented in the task we needed to modify
most of the rules to make it able to handle the more
complex negation structures in the Conan Doyle cor-
pus and the new challenges that it represents. The
present paper has the intention of exemplifying the
problems of such a system when the task is changed.
Our system presented to the Shared Task is based
on the following properties: it makes use of an algo-
rithm that traverses dependency structures, it classi-
fies the scope of the negations by using a rule-based
approach that studies linguistic clause boundaries
and the outcomes of the algorithm for traversing
dependency structures, it applies naive and simple
</bodyText>
<page confidence="0.956433">
288
</page>
<note confidence="0.527409">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 288–293,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999843416666667">
solutions to the problem of classifying the negated
event and it does not use the syntactic annotation
provided in the Conan Doyle corpus (just in an ex-
ception for the negated event annotation).
In Section 2 we describe the algorithms that we
propose for inferring the scope of negation and the
modifications that we needed to make to the previ-
ous version. In Section 3 we discuss the evaluation
performed with the blind test set and development
set and the error analysis over the development set.
Finally, in Section 4 we give our conclusions and
suggestions for future work.
</bodyText>
<sectionHeader confidence="0.993313" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.999972229166667">
Our system consists of two algorithms: the first one
is capable of inferring words affected by the negative
operators (cues) by traversing dependency trees and
the second one is capable of annotating sentences
within the scope of negations. This second algo-
rithm is the one in which we change the behaviour in
a deeper way. The first one just serves as a consult-
ing point in some of the rules of the second one. By
using the training set and development set provided
to the authors we modified, omitted or changed the
old rules when necessary.
The first algorithm which traverses a dependency
tree searching for negation cues to determine the
words affected by negations, was firstly applied (at
an earlier stage) to a very different domain (Balles-
teros et al., 2010) obtaining interesting results. At
that time, the Minipar parser (Lin, 1998) was se-
lected to solve the problem in a simple way with-
out needing to carry out several machine learning
optimizations which are well known to be daunting
tasks. We also selected Minipar because at that mo-
ment we only needed unlabelled parsing.
Therefore, our system consists of three different
modules: a static negation cue lexicon, an algorithm
that from a parse given by Minipar and the nega-
tion cue lexicon produces a set of words affected
by the negations, and a rule-based system that pro-
duces the annotation of the scope of the studied sen-
tence. These components are described in the fol-
lowing sections.
In order to annotate the sentence as it is done in
the Conan Doyle corpus, we also developed a post-
processing system that makes use of the outcomes
of the initial system and produces the expected out-
put. Besides this, we also generate a very naive rule-
based approach to handle the problem of annotating
the negated event.
It is worth to mention that we did not make
use of the syntactic annotation provided in the Co-
nan Doyle corpus, our input is the plain text sen-
tence. Therefore, the system could work without the
columns that are included in the annotation, just with
the word forms. We only make use of the annota-
tion when we annotate the negated event, checking
the part-of-speech tag to ascertain whether the cor-
responding word is a verb or not. The system could
work without these columns but only the results of
the negated event would be affected.
</bodyText>
<subsectionHeader confidence="0.97967">
2.1 Negation Cue Lexicon
</subsectionHeader>
<bodyText confidence="0.996591888888889">
The lexicon containing the negation cues is static. It
can be extended indefinitely but it has the restriction
that it does not learn and it does not grow automat-
ically when applying it to a different domain. The
lexicon used in the previous system (Ballesteros et
al., 2012) was also static but it was very small com-
pared to the one employed by the present system,
just containing less than 20 different negation cues.
Therefore, in addition to the previous lexicon, we
analysed the training set and development sets and
extracted 153 different negation cues (plus the ones
already present in the previous system). We stored
these cues in a file that feeds the system when it
starts. Table 1 shows a small excerpt of the lexicon.
not no neither..nor
unnecessary unoccupied unpleasant
unpractical unsafe unseen
unshaven windless without
</bodyText>
<tableCaption confidence="0.998275">
Table 1: Excerpt of the lexicon
</tableCaption>
<subsectionHeader confidence="0.997824">
2.2 Affected Wordforms Detection Algorithm
</subsectionHeader>
<bodyText confidence="0.999983714285714">
The algorithm that uses the outcomes of Minipar is
the same employed in (Ballesteros et al., 2012) with-
out modifications. It basically traverses the depen-
dency structures and returns for each negation cue a
set of words affected by the cue.
The algorithm takes into account the way of han-
dling main verbs by Minipar, in which these verbs
</bodyText>
<page confidence="0.988256">
289
</page>
<bodyText confidence="0.994583">
appear as heads and the auxiliary verbs are depen-
dants of them. Therefore, the system first detects the
nodes that contain a word which is a negation cue,
and afterwards it does the following:
</bodyText>
<listItem confidence="0.953199">
• If the negation cue is a verb, such as lack, it is
marked as a negation cue.
• If the negation cue is not a verb, the algorithm
</listItem>
<bodyText confidence="0.933707818181818">
marks the main verb (if it exists) that governs
the structure as a negation cue.
For the rest of nodes, if a node depends directly
on any of the ones previously marked as negation
cue, the system marks it as affected. The negation is
also propagated until finding leaves, so wordforms
that are not directly related to the cues are detected
too.
Finally, by using all of the above, the algorithm
generates a list of words affected by each negation
cue.
</bodyText>
<subsectionHeader confidence="0.998371">
2.3 Scope Classification Algorithm
</subsectionHeader>
<bodyText confidence="0.8059186">
This second algorithm is the one that has suffered
the deepest modifications from the first version. The
previous version handled the annotation as it is done
in the Bioscope corpus. The algorithm works as fol-
lows:
• The system opens a scope when it finds a new
negation cue detected by the affected word-
forms detection algorithm. In Bioscope, only
the sentences in passive voice include the sub-
ject inside the scope. However, the Conan
Doyle corpus does not contain this exception
always including the subject in the scope when
it exists. Therefore, we modified the decision
that fires this rule, and we apply the way of an-
notating sentences in passive voice for all the
negation cues, either passive or active voice
sentences.
Therefore, for most of the negation cues the
system goes backward and opens the scope
when it finds the subject involved or a marker
that indicates another statement, like a comma.
There are some exceptions to this, such as
scopes in which the cue is without or nei-
ther...nor. For them the system just opens the
scope at the cue.
</bodyText>
<listItem confidence="0.768629">
• The system closes a scope when there are no
more wordforms to be added, i.e.:
– It finds words that indicate another state-
ment, such as but or because.
– No more words in the output of the first
algorithm.
– End of the sentence.
• We also added a new rule that can handle the
negation cues that are prefix or suffix of another
word, such as meaning-less: if the system finds
a cue word like this, it then annotates the suffix
or prefix as the cue (such as less) and the rest of
the word as part of the scope. Note that the Af-
fected Wordforms Detection algorithm detects
the whole word as a cue word.
</listItem>
<subsectionHeader confidence="0.911107">
2.4 Negated Event Handling
</subsectionHeader>
<bodyText confidence="0.999769333333333">
In order to come up with a solution that could pro-
vide at least some results in the negated event han-
dling, we decided to do the following:
</bodyText>
<listItem confidence="0.911997857142857">
• When the cue word contains a negative prefix
or a negative suffix, we annotate the word as
the negated event.
• When the cue word is either not or n’t and the
next word is a verb, according to the part-of-
speech annotation of the Conan Doyle corpus,
we annotate the verb as the negated event.
</listItem>
<subsectionHeader confidence="0.990834">
2.5 Post-Processing Step
</subsectionHeader>
<bodyText confidence="0.946057833333333">
The post-processing step basically processes the an-
notated sentence with Bioscope style, (we show
an example for clarification: &lt;scope&gt;There is
&lt;cue&gt;no&lt;/cue&gt; problem&lt;/scope&gt;). It tokenizes
the sentences, in which each token is a word or a
wordform, after that, it does the following:
</bodyText>
<listItem confidence="0.998452555555555">
• If the token contains the string &lt;scope&gt;, the
system just starts a new scope column reserv-
ing three new columns and it puts the word in
the first free “scope” column. Because it means
that there is a new scope for the present sen-
tence.
• If the token is between a &lt;cue&gt; annotation, the
system puts it in the corresponding free “cue”
column of the scope already opened.
</listItem>
<page confidence="0.893359">
290
</page>
<listItem confidence="0.943961">
• If the token is annotated as “negated event”, the
system just puts the word in the last column of
the scope already opened.
</listItem>
<bodyText confidence="0.999426666666667">
Note that these three rules are not exclusive and
can be fired for the same token, but in this case they
are fired in the same order as they are presented.
</bodyText>
<sectionHeader confidence="0.999645" genericHeader="related work">
3 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999928666666667">
In this section we first show the evaluation results
and second the error analysis after studying the re-
sults on the development set.
</bodyText>
<subsectionHeader confidence="0.778118">
3.1 Results
</subsectionHeader>
<bodyText confidence="0.999993378378378">
In this section we show the results obtained in two
different tables: Table 2 shows the results of the sys-
tem with the test set, Table 3 shows the results of the
system with the development set.
As we can observe, the results for the develop-
ment set are higher than the ones obtained for the
test set. The reason is simple, we used the develop-
ment set (apart from the training set) to modify the
rules and to make the system able to annotate the
sentences of the test set.
Note that our system only detects some of the
negation cues (around 72% F1 and 76% F1, respec-
tively, for the test and development sets). We there-
fore believe that one of the main drawbacks of the
present system is the static lexicon of cues. In the
previous version, due to the simplicity of the task,
this was not an issue. However, it is worth noting
that once the negation is detected the results are not
that bad, we show a high precision in most of the
tasks. But the recall suffers due to the coverage of
the lexicon.
It is also worth noting that for the measure Scope
tokens, which takes into account the tokens included
in the scope but not a full scope match, our system
provides interesting outcomes (around 63% F1 and
73% F1, respectively), showing that it is able to an-
notate the tokens in a similar way. We believe that
this fact evidences that the present system comes
from a different kind of annotation and a different
domain, and the extension or modification of such a
system is a complex task.
We can also observe that the negated events re-
sults are very low (around 17.46% F1 and 22.53%
F1, respectively), but this was expected because by
using our two rules we are only covering two cases
and moreover, these two cases are not always behav-
ing in the same way in the corpora.
</bodyText>
<subsectionHeader confidence="0.997055">
3.2 Error Analysis
</subsectionHeader>
<bodyText confidence="0.997314130434783">
In this section we analyse the different errors of our
system with respect to the development set. This set
contains 787 sentences, of which 144 are negation
sentences containing 168 scopes, 173 cues and 122
negation events.
With respect to the negation cue detection we
have obtained 58 false negatives (fn) and 16 false
positives (fp). These results are not directly derived
from the static lexicon of cues. The main problem is
related with the management of sentences with more
than one scope. The majority of the errors have been
produced because in some cases all the cues are as-
signed to all the scopes detected in the same sen-
tence, generating fp, and in other cases the cues of
the second and subsequent scopes are ignored, gen-
erating fn. The first case occurs in sentences like
(1), no and without are labelled as cues in the two
scopes. The second case occurs in sentences like
(2), where neither the second scope nor the second
cue are labelled. In sentence (3) un is labelled as
cue two times (unbrushed, unshaven) but within the
same scope, generating a fp in the first scope and a
fn in the second one.
</bodyText>
<listItem confidence="0.938903285714286">
• (1) But no [one can glance at your toilet and at-
tire without [seeing that your disturbance dates
from the moment of your waking.. ’]]
• (2) [You do ]n’t [mean] - . [you do] n’t [mean
that I am suspected] ? ”
• (3) Our client smoothed down [his] un[brushed
hair] and felt [his] un[shaven chin].
</listItem>
<bodyText confidence="0.999278142857143">
We also found false negatives that occur in multi
word negation cues as by no means, no more and
rather than.
A different kind of false positives is related to
modality cues, dialogue elements and special cases
(Morante and Blanco, 2012). For example, no in (4),
not in (5) and save in (6).
</bodyText>
<listItem confidence="0.941347">
• (4) “ You traced him through the telegram, no
[doubt]., ” said Holmes.
</listItem>
<page confidence="0.986302">
291
</page>
<table confidence="0.999767">
Test set gold system tp fp fn precision (%) recall (%) F1 (%)
Cues: 264 235 170 39 94 81.34 64.39 71.88
Scopes(cue match): 249 233 96 47 153 67.13 38.55 48.98
Scopes(no cue match): 249 233 96 48 152 66.90 38.96 49.24
Scope tokens(no cue match): 1805 2096 1222 874 583 58.30 67.70 62.65
Negated(no cue match): 173 81 36 42 134 46.15 21.18 29.03
Full negation: 264 235 29 39 235 42.65 10.98 17.46
</table>
<tableCaption confidence="0.929384">
Table 2: Test set results.
</tableCaption>
<table confidence="0.999569142857143">
Development gold system tp fp fn precision (%) recall (%) F1 (%)
Cues: 173 161 115 16 58 87.79 66.47 75.66
Scopes(cue match): 168 160 70 17 98 80.46 41.67 54.90
Scopes(no cue match): 168 160 70 17 98 80.46 41.67 54.90
Scope tokens(no cue match): 1348 1423 1012 411 336 71.12 75.07 73.04
Negated(no cue match): 122 71 35 31 82 53.03 29.91 38.25
Full negation: 173 161 24 16 149 60.00 13.87 22.53
</table>
<tableCaption confidence="0.997805">
Table 3: Development set results.
</tableCaption>
<listItem confidence="0.9928092">
• (5) “ All you desire is a plain statement , [is it]
not ? ’.
• (6) Telegraphic inquiries ... that [Marx knew]
nothing [of his customer save that he was a
good payer] .
</listItem>
<bodyText confidence="0.960955333333333">
We can also find problems with affixal negations,
that is, bad separation of the affix and root of the
word. For example, in (7) dissatisfied was erro-
neously divided in di- and ssatisfied. Again, it is
derived from the use of a static lexicon.
• (7) He said little about the case, but from
that little we gathered that [he also was not
dis[satisfied] at the course of events].
Finally, we could also find cases that may be due
to annotation errors. For example, incredible is not
annotated as negation cue in (8). The annotation of
this cue we think is inconsistent, it appears 5 times
in the training corpus, 2 times is labelled as cue, but
3 times is not. According to the context in this sen-
tence, incredible means not credible.
</bodyText>
<listItem confidence="0.7506995">
• (8) “Have just had most incredible and
grotesque experience.
</listItem>
<bodyText confidence="0.999904857142857">
With respect to the full scope detection, most of
the problems are due again to the management of
sentences with more than one scope. We have ob-
tained 98 fn and 17 fp. Most of the problems are
related with affixal negations, as in (9), in which all
the words are included in the scope, which accord-
ing to the gold standard is not correct.
</bodyText>
<listItem confidence="0.6956345">
• (9) [Our client looked down with a rueful face
at his own] un[conventional appearance].
</listItem>
<bodyText confidence="0.999895428571428">
With respect to the scope tokens detection, the
results are higher, around 73% F1 in scope tokens
compared to 55% in full match scopes. The reason
is because our system included tokens for the ma-
jority of scopes, increasing the recall until 75% but
lowering the precision due to the inclusion of more
fp.
</bodyText>
<sectionHeader confidence="0.998805" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.998433888888889">
In this paper we presented our participation in the
SEM-Shared Task, with a modification of a rule-
based system that was designed to be used in a dif-
ferent domain. As the main conclusion we could say
that modifying such a system to perform in a differ-
ent type of texts is complicated. However, taking
into account this fact, and the results obtained, we
are tempted to say that our system presents compet-
itive results.
</bodyText>
<page confidence="0.988212">
292
</page>
<bodyText confidence="0.999770923076923">
We believe that the present system has a lot of
room for improvement: (i) improve the manage-
ment of sentences with more than one scope modify-
ing the scope classification algorithm and the post-
processing step, (ii) replacing the dependency parser
with a state-of-the-art parser in order to get higher
performance, or (iii) proposing a different way of
getting a reliable lexicon of cues, by using a seman-
tic approach that informs if the word has a negative
meaning in the context of the sentence. Again, this
could be achieved by using one of the parsers pre-
sented in the ConLL 2008 Shared Task (Surdeanu et
al., 2008).
</bodyText>
<sectionHeader confidence="0.998939" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.990311666666667">
This research is funded by the Spanish Ministry
of Education and Science (TIN2009-14659-C03-01
Project).
</bodyText>
<sectionHeader confidence="0.998335" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99974752">
Miguel Ballesteros, Ra´ul Martfn, and Bel´en Dfaz-Agudo.
2010. Jadaweb: A cbr system for cooking recipes. In
Proceedings of the Computing Cooking Contest of the
International Conference of Case-Based Reasoning.
Miguel Ballesteros, Virginia Francisco, Alberto Dfaz,
Jes´us Herrera, and Pablo Gerv´as. 2012. Inferring the
scope of negation in biomedical documents. In Pro-
ceedings of the 13th International Conference on Intel-
ligent Text Processing and Computational Linguistics
(CICLING 2012), New Delhi. Springer.
Dekang Lin. 1998. Dependency-based evaluation of
MINIPAR. In Proceedings of the Workshop on the
Evaluation of Parsing Systems, Granada.
Roser Morante and Eduardo Blanco. 2012. Sem 2012
shared task: Resolving the scope and focus of nega-
tion. In Proceedings of the First Joint Conference on
Lexical and Computational Semantics (*SEM 2012),
Montreal, Canada.
Roser Morante and Walter Daelemans. 2009. A met-
alearning approach to processing the scope of nega-
tion. In Proceedings of the Thirteenth Conference on
Computational Natural Language Learning, CoNLL
’09, pages 21–29, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Roser Morante and Walter Daelemans. 2012.
Conandoyle-neg: Annotation of negation in conan
doyle stories. In Proceedings of the Eighth Interna-
tional Conference on Language Resources and Evalu-
ation (LREC). Istanbul, Turkey.
Roser Morante and Caroline Sporleder, editors. 2010.
Proceedings of the Workshop on Negation and Specu-
lation in Natural Language Processing, Uppsala, Swe-
den.
Roser Morante, Anthony Liekens, and Walter Daele-
mans. 2008. Learning the scope of negation in
biomedical texts. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
EMNLP ’08, pages 715–724, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llufs M`arquez, and Joakim Nivre. 2008. The CoNLL-
2008 shared task on joint parsing of syntactic and se-
mantic dependencies. In CoNLL 2008: Proceedings of
the Twelfth Conference on Natural Language Learn-
ing, pages 159–177, Manchester, United Kingdom.
Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gy-
orgy Mora, and Janos Csirik. 2008. The Bio-
Scope corpus: biomedical texts annotated for uncer-
tainty, negation and their scopes. BMC Bioinformat-
ics, 9(Suppl 11):S9+.
</reference>
<page confidence="0.998966">
293
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.702374">
<title confidence="0.9934895">UCM-2: a Rule-Based Approach to Infer the Scope of Negation Dependency Parsing</title>
<author confidence="0.971587">Miguel Ballesteros</author>
<author confidence="0.971587">Alberto Diaz</author>
<author confidence="0.971587">Virginia Pablo Gerv´as</author>
<author confidence="0.971587">Jorge Carrillo de_Albornoz</author>
<author confidence="0.971587">Laura</author>
<affiliation confidence="0.9505405">Natural Interaction Based on Language Complutense University of</affiliation>
<email confidence="0.843903">albertodiaz,</email>
<abstract confidence="0.999058631578947">UCM-2 infers the words that are affected by negations by browsing dependency syntactic structures. It first makes use of an algothat detects negation cues, like not and the words affected by them by traversing Minipar dependency structures. Second, the scope of these negation cues is computed by using a post-processing rulebased approach that takes into account the information provided by the first algorithm and simple linguistic clause boundaries. An initial version of the system was developed to handle the annotations of the Bioscope corpus. For the present version, we have changed, omitted or extended the rules and the lexicon of cues (allowing prefix and suffix negation cues, such to make it suitable for the present task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Miguel Ballesteros</author>
<author>Ra´ul Martfn</author>
<author>Bel´en Dfaz-Agudo</author>
</authors>
<title>Jadaweb: A cbr system for cooking recipes.</title>
<date>2010</date>
<booktitle>In Proceedings of the Computing Cooking Contest of the International Conference of Case-Based Reasoning.</booktitle>
<contexts>
<context position="5053" citStr="Ballesteros et al., 2010" startWordPosition="821" endWordPosition="825">endency trees and the second one is capable of annotating sentences within the scope of negations. This second algorithm is the one in which we change the behaviour in a deeper way. The first one just serves as a consulting point in some of the rules of the second one. By using the training set and development set provided to the authors we modified, omitted or changed the old rules when necessary. The first algorithm which traverses a dependency tree searching for negation cues to determine the words affected by negations, was firstly applied (at an earlier stage) to a very different domain (Ballesteros et al., 2010) obtaining interesting results. At that time, the Minipar parser (Lin, 1998) was selected to solve the problem in a simple way without needing to carry out several machine learning optimizations which are well known to be daunting tasks. We also selected Minipar because at that moment we only needed unlabelled parsing. Therefore, our system consists of three different modules: a static negation cue lexicon, an algorithm that from a parse given by Minipar and the negation cue lexicon produces a set of words affected by the negations, and a rule-based system that produces the annotation of the s</context>
</contexts>
<marker>Ballesteros, Martfn, Dfaz-Agudo, 2010</marker>
<rawString>Miguel Ballesteros, Ra´ul Martfn, and Bel´en Dfaz-Agudo. 2010. Jadaweb: A cbr system for cooking recipes. In Proceedings of the Computing Cooking Contest of the International Conference of Case-Based Reasoning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miguel Ballesteros</author>
<author>Virginia Francisco</author>
<author>Alberto Dfaz</author>
<author>Jes´us Herrera</author>
<author>Pablo Gerv´as</author>
</authors>
<title>Inferring the scope of negation in biomedical documents.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th International Conference on Intelligent Text Processing and Computational Linguistics (CICLING 2012),</booktitle>
<publisher>Springer.</publisher>
<location>New Delhi.</location>
<marker>Ballesteros, Francisco, Dfaz, Herrera, Gerv´as, 2012</marker>
<rawString>Miguel Ballesteros, Virginia Francisco, Alberto Dfaz, Jes´us Herrera, and Pablo Gerv´as. 2012. Inferring the scope of negation in biomedical documents. In Proceedings of the 13th International Conference on Intelligent Text Processing and Computational Linguistics (CICLING 2012), New Delhi. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of MINIPAR.</title>
<date>1998</date>
<booktitle>In Proceedings of the Workshop on the Evaluation of Parsing Systems,</booktitle>
<location>Granada.</location>
<contexts>
<context position="5129" citStr="Lin, 1998" startWordPosition="835" endWordPosition="836">ations. This second algorithm is the one in which we change the behaviour in a deeper way. The first one just serves as a consulting point in some of the rules of the second one. By using the training set and development set provided to the authors we modified, omitted or changed the old rules when necessary. The first algorithm which traverses a dependency tree searching for negation cues to determine the words affected by negations, was firstly applied (at an earlier stage) to a very different domain (Ballesteros et al., 2010) obtaining interesting results. At that time, the Minipar parser (Lin, 1998) was selected to solve the problem in a simple way without needing to carry out several machine learning optimizations which are well known to be daunting tasks. We also selected Minipar because at that moment we only needed unlabelled parsing. Therefore, our system consists of three different modules: a static negation cue lexicon, an algorithm that from a parse given by Minipar and the negation cue lexicon produces a set of words affected by the negations, and a rule-based system that produces the annotation of the scope of the studied sentence. These components are described in the followin</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Dependency-based evaluation of MINIPAR. In Proceedings of the Workshop on the Evaluation of Parsing Systems, Granada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Eduardo Blanco</author>
</authors>
<title>Sem</title>
<date>2012</date>
<booktitle>In Proceedings of the First Joint Conference on Lexical and Computational Semantics (*SEM 2012),</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="1262" citStr="Morante and Blanco, 2012" startWordPosition="185" endWordPosition="188">structures. Second, the scope of these negation cues is computed by using a post-processing rulebased approach that takes into account the information provided by the first algorithm and simple linguistic clause boundaries. An initial version of the system was developed to handle the annotations of the Bioscope corpus. For the present version, we have changed, omitted or extended the rules and the lexicon of cues (allowing prefix and suffix negation cues, such as impossible or meaningless), to make it suitable for the present task. 1 Introduction One of the challenges of the *SEM Shared Task (Morante and Blanco, 2012) is to infer and classify the scope and event associated to negations, given a training and a development corpus based on Conan Doyle stories (Morante and Daelemans, 2012). Negation, simple in concept, is a complex but essential phenomenon in any language. It turns an affirmative statement into a negative one, changing the meaning completely. We believe therefore that being able to handle and classify negations we would be able to improve several text mining applications. Previous to this Shared Task, we can find several systems that handle the scope of negation in the state of the art. This i</context>
<context position="15385" citStr="Morante and Blanco, 2012" startWordPosition="2679" endWordPosition="2682">) but within the same scope, generating a fp in the first scope and a fn in the second one. • (1) But no [one can glance at your toilet and attire without [seeing that your disturbance dates from the moment of your waking.. ’]] • (2) [You do ]n’t [mean] - . [you do] n’t [mean that I am suspected] ? ” • (3) Our client smoothed down [his] un[brushed hair] and felt [his] un[shaven chin]. We also found false negatives that occur in multi word negation cues as by no means, no more and rather than. A different kind of false positives is related to modality cues, dialogue elements and special cases (Morante and Blanco, 2012). For example, no in (4), not in (5) and save in (6). • (4) “ You traced him through the telegram, no [doubt]., ” said Holmes. 291 Test set gold system tp fp fn precision (%) recall (%) F1 (%) Cues: 264 235 170 39 94 81.34 64.39 71.88 Scopes(cue match): 249 233 96 47 153 67.13 38.55 48.98 Scopes(no cue match): 249 233 96 48 152 66.90 38.96 49.24 Scope tokens(no cue match): 1805 2096 1222 874 583 58.30 67.70 62.65 Negated(no cue match): 173 81 36 42 134 46.15 21.18 29.03 Full negation: 264 235 29 39 235 42.65 10.98 17.46 Table 2: Test set results. Development gold system tp fp fn precision (%) </context>
</contexts>
<marker>Morante, Blanco, 2012</marker>
<rawString>Roser Morante and Eduardo Blanco. 2012. Sem 2012 shared task: Resolving the scope and focus of negation. In Proceedings of the First Joint Conference on Lexical and Computational Semantics (*SEM 2012), Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>A metalearning approach to processing the scope of negation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning, CoNLL ’09,</booktitle>
<pages>21--29</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009. A metalearning approach to processing the scope of negation. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning, CoNLL ’09, pages 21–29, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Conandoyle-neg: Annotation of negation in conan doyle stories.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC).</booktitle>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="1433" citStr="Morante and Daelemans, 2012" startWordPosition="214" endWordPosition="217">irst algorithm and simple linguistic clause boundaries. An initial version of the system was developed to handle the annotations of the Bioscope corpus. For the present version, we have changed, omitted or extended the rules and the lexicon of cues (allowing prefix and suffix negation cues, such as impossible or meaningless), to make it suitable for the present task. 1 Introduction One of the challenges of the *SEM Shared Task (Morante and Blanco, 2012) is to infer and classify the scope and event associated to negations, given a training and a development corpus based on Conan Doyle stories (Morante and Daelemans, 2012). Negation, simple in concept, is a complex but essential phenomenon in any language. It turns an affirmative statement into a negative one, changing the meaning completely. We believe therefore that being able to handle and classify negations we would be able to improve several text mining applications. Previous to this Shared Task, we can find several systems that handle the scope of negation in the state of the art. This is a complex problem, because it requires, first, to find and capture the negation cues, and second, based on either syntactic or semantic representations, to identify the </context>
</contexts>
<marker>Morante, Daelemans, 2012</marker>
<rawString>Roser Morante and Walter Daelemans. 2012. Conandoyle-neg: Annotation of negation in conan doyle stories. In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC). Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<date>2010</date>
<booktitle>Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,</booktitle>
<editor>Roser Morante and Caroline Sporleder, editors.</editor>
<location>Uppsala, Sweden.</location>
<marker>2010</marker>
<rawString>Roser Morante and Caroline Sporleder, editors. 2010. Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Anthony Liekens</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the scope of negation in biomedical texts.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>715--724</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Morante, Liekens, Daelemans, 2008</marker>
<rawString>Roser Morante, Anthony Liekens, and Walter Daelemans. 2008. Learning the scope of negation in biomedical texts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 715–724, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llufs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In CoNLL 2008: Proceedings of the Twelfth Conference on Natural Language Learning,</booktitle>
<pages>159--177</pages>
<location>Manchester, United Kingdom.</location>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Llufs M`arquez, and Joakim Nivre. 2008. The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies. In CoNLL 2008: Proceedings of the Twelfth Conference on Natural Language Learning, pages 159–177, Manchester, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Gyorgy Szarvas</author>
<author>Richard Farkas</author>
<author>Gyorgy Mora</author>
<author>Janos Csirik</author>
</authors>
<title>The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--9</pages>
<contexts>
<context position="2837" citStr="Vincze et al., 2008" startWordPosition="451" endWordPosition="454">008; 2009), in which they presented a machine learning approach for the biomedical domain evaluating it on the Bioscope corpus. In 2010, a Workshop on Negation and Speculation in Natural Language Processing (Morante and Sporleder, 2010) was held in Uppsala, Sweden. Most of the approaches presented worked in the biomedical domain, which is the most studied in negation detection. The system presented in this paper is a modification of the one published in Ballesteros et al. (2012). This system was developed in order to replicate (as far as possible) the annotations given in the Bioscope corpus (Vincze et al., 2008). Therefore, for the one presented in the task we needed to modify most of the rules to make it able to handle the more complex negation structures in the Conan Doyle corpus and the new challenges that it represents. The present paper has the intention of exemplifying the problems of such a system when the task is changed. Our system presented to the Shared Task is based on the following properties: it makes use of an algorithm that traverses dependency structures, it classifies the scope of the negations by using a rule-based approach that studies linguistic clause boundaries and the outcomes</context>
</contexts>
<marker>Vincze, Szarvas, Farkas, Mora, Csirik, 2008</marker>
<rawString>Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gyorgy Mora, and Janos Csirik. 2008. The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11):S9+.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>