<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000225">
<title confidence="0.976959">
Latent Semantic Analysis for Text Segmentation
</title>
<author confidence="0.986088">
Freddy Y. Y. Choi
</author>
<affiliation confidence="0.975873">
Artificial Intelligence Group
Dept. of Computer Science
University of Manchester
</affiliation>
<address confidence="0.990284">
Manchester M13 OAY, UK
</address>
<email confidence="0.998717">
choif@cs.man.ac.uk
</email>
<author confidence="0.653396">
Peter Wiemer-Hastings
</author>
<affiliation confidence="0.732705">
HCRC
University of Edinburgh
</affiliation>
<address confidence="0.8795205">
2, Buccleuch Place
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.998251">
peterwh@cogsci.ed.ac.uk
</email>
<author confidence="0.633594">
Johanna Moore
</author>
<affiliation confidence="0.7273605">
HCRC
University of Edinburgh
</affiliation>
<address confidence="0.87981">
2, Buccleuch Place
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.999315">
jmoore@cogsci.ed.ac.uk
</email>
<sectionHeader confidence="0.987714" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999161333333333">
This paper describes a method for linear text
segmentation that is more accurate or at least as
accurate as state-of-the-art methods (Utiyama
and Isahara, 2001; Choi, 2000a). Inter-sentence
similarity is estimated by latent semantic anal-
ysis (LSA). Boundary locations are discovered
by divisive clustering. Test results show LSA
is a more accurate similarity measure than the
cosine metric (van Rijsbergen, 1979).
</bodyText>
<sectionHeader confidence="0.993738" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999875428571428">
The aim of linear text segmentation is to par-
tition a document into blocks, such that each
segment is coherent and consecutive segments
are about different topics. This procedure
is useful in information retrieval (Hearst and
Plaunt, 1993; Hearst, 1994; Yaari, 1997; Rey-
nar, 1999), summarisation (Reynar, 1998), text
understanding, anaphora resolution (Kozima,
1993), language modelling (Morris and Hirst,
1991; Beeferman et al., 1997) and text naviga-
tion (Choi, 2000b).
This paper presents a new algorithm for seg-
menting written text. The method builds on
previous work by Choi (2000a). The primary
distinction is the use of latent semantic analy-
sis (LSA) in formulating the similarity matrix.
We discovered that (1) LSA is a more accurate
measure of similarity than the cosine metric, (2)
stemming does not always improve segmenta-
tion accuracy and (3) ranking is crucial to co-
sine but not LSA.
</bodyText>
<sectionHeader confidence="0.940136" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.9994815">
A text segmentation algorithm has three main
parts. First, the input text is divided into el-
ementary blocks. Second, a similarity metric
identifies blocks that are about the same topic.
Finally, topic boundaries are discovered by a
clustering algorithm.
</bodyText>
<subsectionHeader confidence="0.625415">
2.1 Elementary block
</subsectionHeader>
<bodyText confidence="0.999938533333333">
An elementary block is the smallest text seg-
ment that can describe an entire topic, e.g.
sentences (Ponte and Croft, 1997), paragraphs
(Yaari, 1997) and arbitrary-sized segments
(Hearst, 1994). Linguistic theories (Chafe,
1979; Longacre, 1979; Kieras, 1982) and work
in information retrieval (Salton et al., 1993;
Kaszkiel and Zobel, 1997) suggest a coherent
text segment is represented by paragraphs. We
argue that a paragraph can address multiple
topics and is motivated by content, writing style
and presentation. Thus, a topic segment is a
collection of sentences. This view is supported
by previous work in text segmentation (Ponte
and Croft, 1997; Choi, 2000a).
</bodyText>
<subsectionHeader confidence="0.981348">
2.2 Similarity metric
</subsectionHeader>
<bodyText confidence="0.999977285714286">
A similarity metric estimates the likelihood of
two segments describing the same topic. Ex-
isting methods fall into one of two categories.
Lexical cohesion methods stem from the work
of Halliday and Hasan (1976), in which a coher-
ent topic segment is believed to contain parts
with similar vocabulary. Implementations of
this use word stem repetition (Youmans, 1991;
Reynar, 1994; Ponte and Croft, 1997), context
vectors (Hearst, 1994; Yaari, 1997; Kaufmann,
1999; Eichmann et al., 1999; Choi, 2000a), en-
tity repetition (Kan et al., 1998), thesaurus re-
lations (Morris and Hirst, 1991), spreading ac-
tivation over dictionary (Kozima, 1993), a word
distance model (Beeferman et al., 1997) or a
word frequency model (Reynar, 1999; Utiyama
and Isahara, 2001) to detect cohesion. These
methods are typically applied in information re-
trieval (Hearst, 1994; Reynar, 1998) to segment
written text.
Multi-source methods use cue phrases,
prosodic features, ellipsis, anaphora, syntac-
tic features, language models and lexical cohe-
sion metrics to detect topic boundaries. Fea-
tures are combined using decision trees (Miike
et al., 1994; Kurohashi and Nagao, 1994; Lit-
man and Passonneau, 1995), probabilistic mod-
els (Hajime et al., 1998) and maximum entropy
models (Beeferman et al., 1997; Reynar, 1998).
The aim is to improve segmentation accuracy
by combining multiple indicators of topic shift.
These methods are typically applied in topic de-
tection and tracking (Allan et al., 1998) to seg-
ment transcribed text and broadcast news sto-
ries.
</bodyText>
<subsectionHeader confidence="0.99404">
2.3 Clustering
</subsectionHeader>
<bodyText confidence="0.999818">
Topic boundaries are discovered by merging
consecutive elementary blocks that are about
the same topic. Existing algorithms used a
sliding window (Hearst, 1994), lexical chains
(Morris, 1988; Kan et al., 1998), dynamic pro-
gramming (Ponte and Croft, 1997; Heinonen,
1998; Utiyama and Isahara, 2001), agglomera-
tive clustering (Yaari, 1997) and divisive clus-
tering (Reynar, 1994; Choi, 2000a) to determine
the optimal segmentation. The main difficulty
in clustering is automatic termination, i.e. de-
termining the number of topic boundaries in a
document.
</bodyText>
<sectionHeader confidence="0.987944" genericHeader="method">
3 A new method
</sectionHeader>
<bodyText confidence="0.999962666666667">
The input to our algorithm is a list of tokenised
sentences S = {81,..,8}. Content words are
identified by removing punctuation marks and
stopwords from S. A term frequency vector f, is
then constructed for each sentence i. fij denotes
the number of times content word j occurs in s,.
</bodyText>
<subsectionHeader confidence="0.998741">
3.1 Inter-sentence similarity in C99
</subsectionHeader>
<bodyText confidence="0.999941727272727">
The C99 algorithm (Choi, 2000a) uses the co-
sine metric (van Rijsbergen, 1979) (eq. 1) to
compute a nxn similarity matrix M for S.
represents the similarity between s, and si. The
assumption is, two sentences with similar word
usage are likely to be about the same topic. This
idea has two main problems. First, the esti-
mate is inaccurate for short passages. Second,
synonyms are considered negative evidence, e.g.
car E s, and automobile E si implies s, and si
are dissimilar.
</bodyText>
<equation confidence="0.995588">
Ek fik X f jk
Mii = COS(A, fj) = (1)
VEk fi2k X Ek f;k
</equation>
<bodyText confidence="0.9935041875">
The first problem was addressed by replacing
with its rank Rii (eq. 2, r defines the local
context). The idea is, the difference in magni-
tude is inaccurate, thus one can only use the
order as evidence for segmentation. Consider
X = {xl,x2,x3} = {1,3,6} as the length of
three objects. If X was measured with an ordi-
nary ruler, one can conclude that x2 is three
times longer than x1. This is a quantitative
analysis of X, i.e. the quantity is significant.
However, if the ruler was warped, but the or-
der of the markings is preserved, one can only
conclude that x1 &lt; x2 &lt; x3. This is a qualita-
tive analysis of X, i.e. the order is significant
but the relative value has no meaning. This is
a more robust interpretation of X.
</bodyText>
<equation confidence="0.994124">
E {-r,•••,r} MPq I (2)
(2r + 1)2
</equation>
<bodyText confidence="0.999893666666667">
The second problem was addressed by ap-
plying a stemming algorithm (Porter, 1980) to
S, such that syntactically motivated inflections
are placed in an equivalent class. For exam-
ple, cooking, cooked, cooks, cooker are all in-
stances of the class cook. Unlike morphological
analysers (Koskenniemi, 1983, for example), a
stemming algorithm does not identify the mor-
phemes. Its simply removes common affixes
from a word, e.g. combines, combine —&gt; com-
bin, depart, department —&gt; depart. Thus, similar
surface forms are considered positive evidence in
the similarity estimate. We propose that latent
semantic analysis offers a better solution to the
term matching problem.
</bodyText>
<subsectionHeader confidence="0.999602">
3.2 Latent semantic analysis
</subsectionHeader>
<bodyText confidence="0.99991735">
LSA (Deerwester et al., 1990) stems from work
in information retrieval, where the main diffi-
culty is formulating a similarity metric that as-
sociates a user query with the relevant docu-
ments in a database. The basic keyword search
approach retrieves all documents which contain
some or all of the query terms. This is inaccu-
rate since the same concept may be described
using different terms. To circumvent this, Jing
and Croft (1994) developed an association the-
saurus for matching semantically related words.
Xu and Croft (1996) offered a trainable
method call local context analysis (LCA) which
replaces each query term with frequently co-
occurring words. Roughly speaking, LCA com-
putes a word co-occurrence matrix C for a train-
ing corpus. A threshold is then applied such
that large values in C are replaced by 1 and
other values become 0. Each row C, can be
considered as a feature vector for word i. The
meaning of a text is approximated by the sum
of the word feature vectors. Similarity between
two texts is estimated by the distance between
the corresponding feature vectors (Ponte and
Croft, 1997, for details).
LSA is a classification approach to query ex-
pansion. The method is similar to LCA in that
the &amp;quot;meaning&amp;quot; of a word w is represented by
its relation to other words. The primary dis-
tinction is, LSA applies principle components
analysis to a word similarity matrix to identify
the best features for distinguishing dissimilar
words. Like LCA, the meaning of a text is com-
puted as the sum of the word feature vectors.
Text similarity is measured by the cosine of the
corresponding feature vectors. LSA has been
shown to match human similarity judgements
on a wide range of tasks (Landauer and Dumais,
1997; Wolfe et al., 1998; Wiemer-Hastings et al.,
1999, for example).
</bodyText>
<subsectionHeader confidence="0.875224">
3.2.1 Training LSA
</subsectionHeader>
<bodyText confidence="0.999399">
LSA is trained on a set of texts A = Y1, ...,
with vocabulary twi, turd-. Anxm matrix
A is calculated, in which, A,i is the number of
times to, occurs in Si. The values are scaled
according to a general form of inverse document
frequency,
</bodyText>
<equation confidence="0.909006">
Bii = Aij X
Ibk E {1,...,m} : Ak &gt;01
</equation>
<bodyText confidence="0.997057071428571">
Singular value decomposition, or SVD (Golub
and van Loan, 1989) is then applied to yield
B = UEVT, where XT denotes the transposed
matrix of X. The columns of U and V are
the eigenvectors of BBT and BTB, respectively.
The diagonal values of E are the correspond-
ing singular values, i.e. the non-negative square
roots of the eigenvalues of BBT. These are
sorted in descending order.
BBT is a word similarity matrix, where
the &amp;quot;meaning&amp;quot; of a word to, is expressed in
terms of its dot-product with all other words
{w1, 1.07,}. As a classification problem, the
eigenvectors in U are the principle axes for dis-
tinguishing the word feature vectors, or rows,
in BBT. In other words, the first k columns of
U, or Ak, is the best approximation of BBT in
k—dimensional space. Ak is the k—dimensional
LSA space for A. The i—th row in Ak, or Ak(i),
is the LSA feature vector for word to,.
Applying SVD to W has three main bene-
fits. First, Ak is a concise representation of W.
Thus, storage and computational complexity of
the similarity metric is reduced. Second, words
which occur in similar contexts are represented
by similar feature vectors in Ak. Finally, noise
in W is removed by simply omitting the less
salient dimensions in U.
</bodyText>
<subsectionHeader confidence="0.977636">
3.2.2 Applying LSA
</subsectionHeader>
<bodyText confidence="0.9984485">
A sentence s, is represented by its term fre-
quency vector A, where Li is the frequency of
term j in s,. Given Ak, the &amp;quot;meaning&amp;quot; of s,
is computed by eq. 3. Informally, s, is repre-
sented by the sum of the LSA feature vectors.
Inter-sentence similarity is estimated by the co-
sine of the corresponding X (eq. 4, Azk is the
k—th element in Ai).
</bodyText>
<equation confidence="0.993712333333333">
Ai = x Ak(j) (3)
E
= COS(Ai, A k Aik X Ajki) = (4)
E A2 E A2
jk
vJ k ik x k
</equation>
<subsectionHeader confidence="0.85594">
3.2.3 LSA parameters
</subsectionHeader>
<bodyText confidence="0.999964285714286">
Since Ak is derived from the co-occurrence ma-
trix A, the size of each training text Si E A is
crucial to its performance. Work in information
retrieval uses Sz = document since the aim is to
distinguish entire texts. Sz = paragraph is pop-
ular in psychology experiments. However, we
suspect the segmentation task may benefit from
Sz = sentence. Thus, two training corpora were
derived from the Brown Corpus (Marcus et al.,
1993). Annotations were first removed to leave
a set of tokenised raw text (1.2 million tokens).
This was partitioned into 35,000 paragraphs or
104,000 sentences, as two training corpora.
The parameter k adjusts the accuracy of Ak.
A large k implies minor differences in the fea-
ture space are significant. Thus, they should
be taken into account in the formulation of
Ak. This is appropriate when the vocabulary
is small and there is sufficient training data. A
small k is used when A is sparse and the values
in A are inaccurate.
</bodyText>
<subsectionHeader confidence="0.997271">
3.3 Image ranking
</subsectionHeader>
<bodyText confidence="0.999981692307692">
Once the similarity matrix M is calculated for
the input text S, the image ranking procedure
in C99 is then applied to obtain a rank matrix R
(see eq. 2). Rzi is the proportion of neighbours
of Mzi with a lower value than Mzi.
The motivation for applying image ranking in
the new algorithm is to test whether a quanti-
tative or qualitative interpretation of the sim-
ilarity values has any impact on segmentation
accuracy. The hypothesis is that LSA similar-
ity values are more accurate than cosine similar-
ity values. Thus, image ranking should have a
smaller impact on LSA than the cosine metric.
</bodyText>
<subsectionHeader confidence="0.922988">
3.4 Clustering
</subsectionHeader>
<bodyText confidence="0.977533307692308">
The input matrix X can either be the similar-
ity matrix M or the rank matrix R, depend-
ing on whether ranking is applied to M. Topic
boundaries are identified by the divisive clus-
tering procedure in C99. A topic segment tk is
defined by its start and end sentences, sz and
si, or its range tk = [i, j]. The number of inter-
sentence similarity values in tk is O(tk) = Itk12,
i.e. (j — j ± 1)2. The sum of the values in tk
is /3(tk) = EzEt.1
k E.Ebk X Thus, the average
inter-sentence similarity value for a segmenta-
tion T = {t,, ...,t} is defined as,
</bodyText>
<equation confidence="0.996846">
Elc1=1 l3(4)
[IT — n
Ek=1 ct(tic)
</equation>
<bodyText confidence="0.9998694">
The divisive clustering algorithm begins by
considering the entire input document S as a
coherent topic segment. This is partitioned into
two segments T = ftl, t21 at a sentence bound-
ary that maximises [IT, i.e. the most prominent
topic boundary. The recursive procedure pro-
ceeds until S can no longer be subdivided. The
optimal segmentation is signalled by a sharp
change in [IT. For implementation details and
optimisations, see (Choi, 2000a).
</bodyText>
<sectionHeader confidence="0.993067" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9999867">
The following experiments aim to establish the
relationship between linguistic processes (stem-
ming, ranking, cosine metric, LSA) and segmen-
tation error rate. The test procedure is based
on that presented in (Choi, 2000a) which was
derived from work in TDT (Allan et al., 1998)
and previous experiments in text segmentation
(Reynar, 1998, 71-73). The task is to find the
most prominent topic boundaries in a concate-
nated text.
</bodyText>
<subsectionHeader confidence="0.991117">
4.1 Experiment procedure
</subsectionHeader>
<bodyText confidence="0.9996275">
The accuracy of a segmentation algorithm is as-
sessed by the experiment package&apos; described in
(Choi, 2000a). A test sample is a concatenation
of ten text segments. Each segment is the first
n sentences of a randomly selected document
from a subset2 of the Brown corpus (Marcus et
al., 1993). Table 1 presents the corpus statis-
tics. A sample is characterised by the range of
n. Ti,j is a set of samples with i &lt;n &lt;j. T is
the union of the other four test sets.
</bodyText>
<table confidence="0.9880085">
T3,11 T3,5 T6,8 T9,11 T
Samples 400 100 100 100 700
</table>
<tableCaption confidence="0.999873">
Table 1: Test corpus statistics.
</tableCaption>
<bodyText confidence="0.999862777777778">
Segmentation accuracy is measured by the
metric proposed in (Beeferman et al., 1999).
Let Tr and Tp be the reference segmenta-
tion and that proposed by an automatic pro-
cedure. k is the average segment length in
T. p(samelTr, k) and p(diffiTr, k) refer to the
likelihood of sentence sz and sz±k belonging
to the same and different topic segment(s) in
Tk p(samelTr, Tp, diff, k) is the probability of a
miss, i.e. sz and sz±k are about different topics
in Tk but they belong to the same topic seg-
ment in T. p(difflTr, Tp, same, k) is the proba-
bility of false alarm, i.e. two sentences are about
the same topic in Tr but they belong to differ-
ent segments in T. Equation 5 combines these
four measures to calculate p(errorlTr, Tp, k), the
probability of segmentation errors. The error
rate of an algorithm is computed as the average
</bodyText>
<footnote confidence="0.86949775">
lhttp: //www.cs.man.ac .ukk-achoif/software
Package name : C99-1.2-release.tgz
2 News articles ca**.pos and informative text
cj**.pos.
</footnote>
<bodyText confidence="0.798163">
of p(errorlTr, Tp, k) for a test set. A low error
rate implies high segmentation accuracy.
</bodyText>
<equation confidence="0.9827195">
p(errorIT,,Tp, k) =
p(samelTr, Tp, diff, k)p(difflTr, k)+ (5)
</equation>
<bodyText confidence="0.984341166666667">
p(diffl , Tp , same, k)p(samelTr, k)
This test procedure is not perfect. First, as-
sessing the accuracy of an algorithm in an ar-
tificial task is inferior to a test that uses hu-
man segmented text. However, this approach
does allow us to conduct a large-scale compara-
tive study on similarity metrics which focuses on
text similarity rather than topic boundary de-
tection. Second, the error metric favours texts
with short topic segments. Segmentation errors
within a segment which is smaller than k are not
always detected correctly. Thus, an algorithm is
assessed using texts with different ranges of seg-
ment length. Although the metric is not perfect,
it is significantly more accurate than the pop-
ular precision/recall metric which ignores near
misses. Furthermore, the method is sufficiently
accurate for this comparative study.
</bodyText>
<subsectionHeader confidence="0.988864">
4.2 Experiment 1 - Baseline
</subsectionHeader>
<bodyText confidence="0.997905888888889">
Five degenerate algorithms define the baseline
for the experiments. Be partitions a document
into e = 10 segments of equal length. Br, does
not propose any boundaries. B,„ assumes all po-
tential boundaries are topic boundaries. Bb ran-
domly selects b = 10 boundaries. B? randomly
selects any number of boundaries as real bound-
aries. Details about Bb and B? are described in
(Choi, 2000a).
</bodyText>
<table confidence="0.998507666666667">
T3,11 T3,5 T6,8 T9,11 T
Be 45% 38% 39% 36% 42%
B 46% 47% 47% 47% 47%
B,„ 54% 53% 53% 53% 53%
Bb 46% 47% 47% 47% 47%
B? 54% 53% 53% 53% 53%
</table>
<tableCaption confidence="0.999733">
Table 2: Error rate: baseline algorithms
</tableCaption>
<bodyText confidence="0.982334333333333">
Table 2 shows Be performed best with an av-
erage error rate of 42%. This is the baseline for
algorithms that find the e most prominent topic
boundaries. B? serves as the baseline for meth-
ods that determines the optimal segmentation,
i.e. the number of topic segments in a text.
</bodyText>
<subsectionHeader confidence="0.972547">
4.3 Experiment 2 - An analysis of C99
</subsectionHeader>
<bodyText confidence="0.999964684210526">
The aim is to relate stemming, ranking and the
termination procedure in C99 with segmenta-
tion accuracy. The algorithm used in this ex-
periment is identical to that presented in (Choi,
2000a) except tokens such as -- and - are recog-
nised as punctuation marks and removed during
pre-processing. Test results show this modifica-
tion reduces error rate by 1%. An analysis of the
original algorithm reveals that non-word tokens
introduce errors since they are converted into a
null string by the stemming algorithm (Porter,
1980).
This implementation of C99 has three param-
eters. +r implies ranking is applied to the sim-
ilarity matrix prior to divisive clustering. +s
shows the stemming algorithm is used in pre-
processing. +b means the algorithm finds the
10 most prominent topic boundaries, i.e. the
automatic termination procedure is inactive.
</bodyText>
<table confidence="0.998730571428571">
r s b T3,11 T3,5 T6,8 T9,11 T
+ + + 12% 11% 9% 9% 11%
+ + - 13% 17% 10% 10% 12%
+ - + 13% 10% 10% 10% 12%
+ - - 13% 18% 10% 12% 13%
- + + 21% 18% 19% 18% 20%
- - + 23% 19% 21% 20% 22%
</table>
<tableCaption confidence="0.99992">
Table 3: Error rate: variants of C99.
</tableCaption>
<bodyText confidence="0.999708947368421">
Test results (table 3) show ranking is crucial
to C99. There is a 10% difference between row
3 and 6 for T. This confirms the cosine met-
ric is inaccurate for short text segments but the
order between values, or rank, is significant. Fu-
ture experiments will establish the relationship
between segment size and accuracy.
Stemming is generally believed to improve
segmentation accuracy. This is confirmed by
the experiment results. However, we discovered
that the process can introduce errors when seg-
menting short segments. There is a 0.7% differ-
ence between row 1 and 3 for T3,5.
Finally, the termination strategy in C99 is not
effective for short topic segments. There is a
6.3% improvement between row 1 and 2 for T3,5.
However, its performance for larger segments is
exceptional (0.6% difference between row 1 and
2 for T).
</bodyText>
<subsectionHeader confidence="0.5139505">
4.4 Experiment 3 — Latent semantic
analysis
</subsectionHeader>
<bodyText confidence="0.999701555555556">
The aim is to establish the relationship between
LSA dimensionality, training data and accuracy.
Our new algorithm, CWM, was used in this
experiment. The method is identical to C99
except the stemming algorithm has been dis-
abled and LSA is used in the formulation of
the similarity matrix. Ten LSA spaces were
examined. Each space is characterised by the
training data and its dimensionality. s and
p imply the LSA space was trained on sen-
tences and paragraphs, respectively. The val-
ues {100, 200, 300, 400, 500} represent the di-
mensionality of the trained space. For instance,
&amp;quot;p, 400&amp;quot; is a 400-dimensional space that was
trained on paragraphs. Like C99, +r implies
ranking is applied to the similarity matrix. +b
means CWM finds the ten most prominent
boundaries.
</bodyText>
<table confidence="0.920986461538462">
r - + - +
b - - + +
s, 100 16% 35% 15% 15%
s,200 17% 40% 15% 13%
s,300 17% 42% 16% 12%
s,400 18% 43% 16% 11%
s,500 18% 44% 16% 10%
p,100 12% 34% 11% 10%
p,200 13% 40% 11% 10%
p, 300 13% 41% 12% 9%
p, 400 14% 42% 12% 8%
p, 500 14% 43% 13% 8%
ii 15% 40% 14% 11%
</table>
<tableCaption confidence="0.9014025">
Table 4: Error rate: LSA parameters and
CWM.
</tableCaption>
<bodyText confidence="0.999914296296296">
Let ji be the column average. Test results
(table 4) show ranked LSA (column 4) has the
lowest error rate. The raw values (column 1
and 3) performed well. The 1% difference in
accuracy implies the termination strategy works
well with LSA. However, the same method is
not applicable to the ranked LSA values (see
column 2).
The results in column 3 highlights the re-
lationship between LSA space and error rate.
On average, a LSA space that was trained on
paragraphs ([2(p) = 11.8%) out-performed one
that was trained on sentences (p(s) = 15.6%).
This shows similarity is well modelled by word
co-occurrence in paragraphs. It also suggests
that although sentences are good for identify-
ing words about the same topic, paragraphs are
better for finding dissimilar words.
Intuitively speaking, large feature vectors are
expected to generate more accurate similarity
values. Thus, segmentation accuracy should im-
prove with dimensionality. The figures in col-
umn 3 show high dimensionality increases error
rate. However, the figures in column 4 suggest
the contrary. This implies high dimensionality
improves the ranking of LSA values but is detri-
mental to value accuracy.
</bodyText>
<table confidence="0.981490545454546">
4.5 Experiment 4 — A comparative
study
T3,11 T3,5 T6,8 T9,11 T
CWM1 9% 10% 7% 5% 8%
U00b 10% 9% 7% 5% 9%
CWM3 12% 10% 9% 8% 11%
C99b 12% 11% 9% 9% 11%
U00 12% 9% 10% 11% 11%
C99 13% 17% 10% 10% 12%
CWM2 14% 10% 11% 12% 13%
C99b,_, 23% 19% 21% 20% 22%
</table>
<tableCaption confidence="0.999746">
Table 5: Error rate: a comparative study.
</tableCaption>
<bodyText confidence="0.997824791666667">
Table 5 presents a summary of experiment
results. C99 and C99b are the algorithms de-
scribed in (Choi, 2000a). C99b,, is the same
as C99b except ranking has been disabled. The
11% difference between the two shows ranking
is crucial to the cosine metric. U00 and U00b
are the word frequency methods proposed in
(Utiyama and Isahara, 2001). CWM is the new
method described in this paper. All versions of
the algorithm use a LSA space that was trained
on paragraphs. CWM1 is identical to C99b ex-
cept the stemming algorithm has been disabled
and it uses A500 to measure similarity. The re-
sults show it is more accurate than previous
methods. CWM2 is the same algorithm but
ranking has been disabled. The 5% difference
between this and CWM1 implies ranking does
improve accuracy. Finally, CWM3 is a variant
of CWM2 which uses A100 to measure similarity.
The 11% difference between this and C99b,_,
shows LSA is more accurate than the cosine
metric. The significance of our results has been
confirmed by both t-test and KS-test (Press et
al., 1992).
</bodyText>
<sectionHeader confidence="0.991249" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999976431818182">
A series of experiments were conducted to es-
tablish the relationship between linguistic pro-
cesses and segmentation accuracy. C99 (Choi,
2000a) was used as the test bench. In the
first set of experiments, its stemming algorithm,
ranking procedure and automatic termination
method were systematically disabled to deter-
mine the contribution of each process to overall
performance. We discovered that, first, stem-
ming generally improves accuracy unless the
topic segments are short (3 to 5 sentences). Sec-
ond, ranking plays a vital role in C99. It reduces
error rate by half (22% to 10%). Finally, the
termination procedure in C99 is effective (0.6%
difference). The method works particularly well
on long topic segments (&gt; 6 sentences).
The second set of experiments focused on
LSA as a similarity metric. The cosine metric
in C99 was replaced by LSA. Ten different LSA
spaces were examined. We discovered that LSA
is twice as accurate as the cosine metric. The re-
sults also showed vocabulary difference between
paragraphs is a good feature for training a sim-
ilarity metric. Further investigation into the re-
lationship between ranking, LSA dimensionality
and error rate revealed that LSA values become
less accurate as more dimensions are incorpo-
rated into the feature vectors. This implies the
training data is noisy. However, with ranking,
error rate decreases. This shows the order of
LSA values becomes more accurate when more
features are used.
Future work will focus on document specific
LSA and the termination strategy of the new
algorithm. Test results have shown the termi-
nation procedure in C99 works well on LSA sim-
ilarity values but not on the ranked values. We
suspect the threshold selection method has to be
modified. In terms of clustering, dynamic pro-
gramming approaches (Ponte and Croft, 1997;
Utiyama and Isahara, 2001, for example) will be
examined. Finally, a LSA procedure for com-
puting document specific similarity values will
be evaluated.
</bodyText>
<sectionHeader confidence="0.970397" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999879571428571">
Thanks are due to the anonymous reviewers for
their invaluable comments; Masao Utiyama and
Hitoshi Isahara for providing the U00 algorithm
and detailed results; Marti Hearst for guidance
on the evaluation problem; Mary McGee Wood
for support and HCRC for making this work
possible.
</bodyText>
<sectionHeader confidence="0.997564" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.95444158974359">
James Allan, Jaime Carbonell, George Dod-
dington, Jonathan Yamron, and Yiming
Yang. 1998. Topic detection and tracking pi-
lot study final report. In Proceedings of the
DARPA Broadcast News Transcription and
Understanding Workshop.
Doug Beeferman, Adam Berger, and John Laf-
ferty. 1997. Text segmentation using expo-
nential models. In Proceedings of EMNLP-2.
Doug Beeferman, Adam Berger, and John Laf-
ferty. 1999. Statistical models for text seg-
mentation. Machine learning, special issue
on Natural Language Processing, 34 (1-3) : 177—
210. C. Cardie and R. Mooney (editors).
W. Chafe. 1979. The flow of thought and the
flow of language. In T. Givon, editor, Syntax
and Semantics: Discourse and Syntax, pages
159-182. Academic Press.
Freddy Y. Y. Choi. 2000a. Advances in do-
main independent linear text segmentation.
In Proceedings of the North American Chap-
ter of the Association for Computational Lin-
guistics, pages 26-33, Seattle, USA, May.
ACL.
Freddy Y. Y. Choi. 2000b. Improving the effi-
ciency of speech interfaces for text navigation.
In Proceedings of ICCHP &apos;00.
S. Deerwester, S. T. Dumais, G. W. Furnas,
T. K. Landauer, and R. Harshman. 1990. In-
dexing by latent semantic analysis. Journal
of the American Society for Information Sci-
ence, 41:391-407.
David Eichmann, Miguel Ruiz, and Padmini
Srinivasan. 1999. A cluster-based approach
to tracking, detection and segmentation of
broadcast news. In Proceedings of the 1999
DARPA Broadcast News Workshop (TDT-2).
G. H. Golub and C. F. van Loan. 1989. Ma-
trix Computations. John Hopkins University
Press.
Mochizuki Hajime, Honda Takeo, and Okumura
Manabu. 1998. Text segmentation with mul-
tiple surface linguistic cues. In Proceedings of
COLING-ACL &apos;98, pages 881-885.
Michael Halliday and Rugaiya Hasan. 1976.
Cohesion in English. Longman Group, New
York.
Marti Hearst and Christian Plaunt. 1993.
Subtopic structuring for full-length document
access. In Proceedings of the 16th Annual In-
ternational A CM/SIGIR Conference, Pitts-
burgh, PA.
Marti A. Hearst. 1994. Multi-paragraph seg-
mentation of expository text. In Proceedings
of the ACL&apos;94. Las Crces, NM.
Oskari Heinonen. 1998. Optimal multi-
paragraph text segmentation by dynamic
programming In Proceedings of COLING-
A CL &apos;98.
Y. Jing and W. B. Croft. 1994. An association
thesaurus for information retrieval. In Pro-
ceedings of RIA0&apos;94, Intelligent Multimedia
Information Retrieval Systems and Manage-
ment, pages 285-298.
Min-Yen Kan, Judith L. Klavans, and Kath-
leen R. McKeown. 1998. Linear segmenta-
tion and segment significance. In Proceed-
ings of the 6th International Workshop of
Very Large Corpora (WVLC-6), pages 197-
205, Montreal, Quebec, Canada, August.
M. Kaszkiel and J. Zobel. 1997. Passage re-
trieval revisited. In Proceedings of the ACM
SIGIR Conference on Research and Devel-
opment in Information Retrieval, pages 178-
185, Philadelphia. ACM.
Stefan Kaufmann. 1999. Cohesion and collo-
cation: Using context vectors in text seg-
mentation. In Proceedings of the 37th Annual
Meeting of the Association for Computational
Linguistics (Student Session), pages 591-595,
College Park, USA, June. ACL.
D. Kieras. 1982. A model of reader strategy for
abstracting main ideas from simple technical
prose. Text, 2(13).
K. Koskenniemi. 1983. Two-level Morphology:
a General Computational Model for Word-
Form Recognition and Production. Ph.D. the-
sis, Department of General Linguistics, Uni-
versity of Helsinki.
Hideki Kozima. 1993. Text segmentation based
on similarity between words. In Proceedings
of ACL&apos;93, pages 286-288, Ohio.
Sadao Kurohashi and Makoto Nagao. 1994.
Automatic detection of discourse structure by
checking surface information in sentences. In
Processings of COLING&apos;94, volume 2, pages
1123-1127.
T.K. Landauer and S.T. Dumais. 1997. A so-
lution to Plato&apos;s problem: The latent seman-
tic analysis theory of acquisition, induction,
and representation of knowledge. Psycholog-
ical Review, 104:211-240.
Diane J. Litman and Rebecca J. Passonneau.
1995. Combining multiple knowledge sources
for discourse segmentation. In Proceedings of
the 33rd Annual Meeting of the ACL.
R. Longacre. 1979. The paragraph as a gram-
matical unit. In T. Givon, editor, Syntax and
Semantics: Discourse and Syntax, pages 115-
134. Academic Press.
Mitch Marcus, M. A. Marcinkiewicz, and
B. Santorini. 1993. Building a large anno-
tated corpus of english: The penn treebank.
Computational Linguistics, 19(2).
S. Miike, E. Itoh, K. Ono, and K. Sumita. 1994.
A full text retrieval system. In Proceedings of
SI GIR &apos;94, Dublin, Ireland.
</reference>
<bodyText confidence="0.851847416666667">
J. Morris and G. Hirst. 1991. Lexical cohesion
computed by thesaural relations as an indi-
cator of the structure of text. Computational
Linguistics, (17):21-48.
Jane Morris. 1988. Lexical cohesion, the the-
saurus, and the structure of text. Techni-
cal Report CSRI 219, Computer Systems Re-
search Institute, University of Toronto.
Jay M. Ponte and Bruce W. Croft. 1997.
Text segmentation by topic. In Proceedings
of the first European Conference on research
and advanced technology for digital libraries.
</bodyText>
<reference confidence="0.995128916666667">
U.Mass. Computer Science Technical Report
TR97-18.
M. Porter. 1980. An algorithm for suffix strip-
ping. Program, 14(3):130-137, July.
William H. Press, Saul A. Teukolsky,
William T. Vettering, and Brian P. Flannery,
1992. Numerical recipes in C: The Art of
Scientific Computing, chapter 14, pages 623-
628. Cambridge University Press, second
edition.
Jeffrey C. Reynar. 1994. An automatic method
of finding topic boundaries. In Proceedings of
ACL &apos;94 (Student session).
Jeffrey C. Reynar. 1998. Topic segmentation:
Algorithms and applications. Ph.D. thesis,
Computer and Information Science, Univer-
sity of Pennsylvania.
Jeffrey C. Reynar. 1999. Statistical models
for topic segmentation. In Proceedings of the
37th Annual Meeting of the Association for
Computational Linguistics, pages 357-364,
College Park, USA, June. ACL.
Gerard Salton, James Allan, and Chris Buckley.
1993. Approaches to passage retrieval in full
text information systems. In Proceedings of
the 16th Annual International ACM/SIGIR
Conference, pages 49-58, Pittsburgh, PA.
Masao Utiyama and Hitoshi Isahara. 2001. A
statistical model for domain-independent text
segmentation. In Proceedings of ACL &apos;2001,
Toulouse, France, July. To appear.
C. J. van Rijsbergen. 1979. Information Re-
trieval. Buttersworth.
P. Wiemer-Hastings, K. Wiemer-Hastings, and
A. Graesser. 1999. Improving an intelligent
tutor&apos;s comprehension of students with La-
tent Semantic Analysis. In S. Lajoie and
M. Vivet, editors, Artificial Intelligence in
Education, pages 535-542, Amsterdam. IOS
Press.
M. Wolfe, M. E. Schreiner, B. Rehder, D. La-
ham, P. W. Foltz, W. Kintsch, and T. K. Lan-
dauer. 1998. Learning from text: Matching
readers and texts by Latent Semantic Analy-
sis. Discourse Processes, 25:309-336.
Jinxi Xu and Bruce W. Croft. 1996. Query
expansion using local and global document
analysis. In Proceedings of the 19th Annual
International ACM SIGIR Conference on Re-
search and Development in Information Re-
trieval, pages 4-11, Zurich, Switzerland, Au-
gust.
Yaakov Yaari. 1997. Segmentation of exposi-
tory texts by hierarchical agglomerative clus-
tering. In Proceedings of RANLP &apos;97. Bul-
garia.
Gilbert Youmans. 1991. A new tool for
discourse analysis: The vocabulary-
management profile. Language, pages
763-789.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.104519">
<title confidence="0.999834">Latent Semantic Analysis for Text Segmentation</title>
<author confidence="0.999767">Y Y Freddy</author>
<affiliation confidence="0.998411333333333">Artificial Intelligence Dept. of Computer University of</affiliation>
<address confidence="0.843208">Manchester M13 OAY,</address>
<email confidence="0.994913">choif@cs.man.ac.uk</email>
<author confidence="0.944053">Peter</author>
<affiliation confidence="0.997006">University of</affiliation>
<address confidence="0.7095015">2, Buccleuch Edinburgh EH8 9LW,</address>
<email confidence="0.988371">peterwh@cogsci.ed.ac.uk</email>
<author confidence="0.679287">Johanna</author>
<affiliation confidence="0.995226">University of</affiliation>
<address confidence="0.7496455">2, Buccleuch Edinburgh EH8 9LW,</address>
<email confidence="0.997498">jmoore@cogsci.ed.ac.uk</email>
<abstract confidence="0.996527666666667">This paper describes a method for linear text segmentation that is more accurate or at least as accurate as state-of-the-art methods (Utiyama and Isahara, 2001; Choi, 2000a). Inter-sentence similarity is estimated by latent semantic analysis (LSA). Boundary locations are discovered by divisive clustering. Test results show LSA is a more accurate similarity measure than the</abstract>
<note confidence="0.636242">cosine metric (van Rijsbergen, 1979).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allan</author>
<author>Jaime Carbonell</author>
<author>George Doddington</author>
<author>Jonathan Yamron</author>
<author>Yiming Yang</author>
</authors>
<title>Topic detection and tracking pilot study final report.</title>
<date>1998</date>
<booktitle>In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop.</booktitle>
<contexts>
<context position="4192" citStr="Allan et al., 1998" startWordPosition="632" endWordPosition="635">ynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama and Isahara, 2001), agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994; Choi, 2000a) to determine the optimal segmentation. The main difficulty in clustering is automatic termination, i.e. determining the number of topic bo</context>
<context position="13790" citStr="Allan et al., 1998" startWordPosition="2321" endWordPosition="2324">s is partitioned into two segments T = ftl, t21 at a sentence boundary that maximises [IT, i.e. the most prominent topic boundary. The recursive procedure proceeds until S can no longer be subdivided. The optimal segmentation is signalled by a sharp change in [IT. For implementation details and optimisations, see (Choi, 2000a). 4 Evaluation The following experiments aim to establish the relationship between linguistic processes (stemming, ranking, cosine metric, LSA) and segmentation error rate. The test procedure is based on that presented in (Choi, 2000a) which was derived from work in TDT (Allan et al., 1998) and previous experiments in text segmentation (Reynar, 1998, 71-73). The task is to find the most prominent topic boundaries in a concatenated text. 4.1 Experiment procedure The accuracy of a segmentation algorithm is assessed by the experiment package&apos; described in (Choi, 2000a). A test sample is a concatenation of ten text segments. Each segment is the first n sentences of a randomly selected document from a subset2 of the Brown corpus (Marcus et al., 1993). Table 1 presents the corpus statistics. A sample is characterised by the range of n. Ti,j is a set of samples with i &lt;n &lt;j. T is the u</context>
</contexts>
<marker>Allan, Carbonell, Doddington, Yamron, Yang, 1998</marker>
<rawString>James Allan, Jaime Carbonell, George Doddington, Jonathan Yamron, and Yiming Yang. 1998. Topic detection and tracking pilot study final report. In Proceedings of the DARPA Broadcast News Transcription and Understanding Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Beeferman</author>
<author>Adam Berger</author>
<author>John Lafferty</author>
</authors>
<title>Text segmentation using exponential models.</title>
<date>1997</date>
<booktitle>In Proceedings of EMNLP-2.</booktitle>
<contexts>
<context position="1284" citStr="Beeferman et al., 1997" startWordPosition="177" endWordPosition="180"> (LSA). Boundary locations are discovered by divisive clustering. Test results show LSA is a more accurate similarity measure than the cosine metric (van Rijsbergen, 1979). 1 Introduction The aim of linear text segmentation is to partition a document into blocks, such that each segment is coherent and consecutive segments are about different topics. This procedure is useful in information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999), summarisation (Reynar, 1998), text understanding, anaphora resolution (Kozima, 1993), language modelling (Morris and Hirst, 1991; Beeferman et al., 1997) and text navigation (Choi, 2000b). This paper presents a new algorithm for segmenting written text. The method builds on previous work by Choi (2000a). The primary distinction is the use of latent semantic analysis (LSA) in formulating the similarity matrix. We discovered that (1) LSA is a more accurate measure of similarity than the cosine metric, (2) stemming does not always improve segmentation accuracy and (3) ranking is crucial to cosine but not LSA. 2 Background A text segmentation algorithm has three main parts. First, the input text is divided into elementary blocks. Second, a similar</context>
<context position="3406" citStr="Beeferman et al., 1997" startWordPosition="512" endWordPosition="515"> describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 19</context>
</contexts>
<marker>Beeferman, Berger, Lafferty, 1997</marker>
<rawString>Doug Beeferman, Adam Berger, and John Lafferty. 1997. Text segmentation using exponential models. In Proceedings of EMNLP-2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Beeferman</author>
<author>Adam Berger</author>
<author>John Lafferty</author>
</authors>
<title>Statistical models for text segmentation.</title>
<date>1999</date>
<booktitle>Machine learning, special issue on Natural Language Processing,</booktitle>
<volume>34</volume>
<editor>(1-3) : 177— 210. C. Cardie and R. Mooney (editors).</editor>
<contexts>
<context position="14593" citStr="Beeferman et al., 1999" startWordPosition="2463" endWordPosition="2466">ccuracy of a segmentation algorithm is assessed by the experiment package&apos; described in (Choi, 2000a). A test sample is a concatenation of ten text segments. Each segment is the first n sentences of a randomly selected document from a subset2 of the Brown corpus (Marcus et al., 1993). Table 1 presents the corpus statistics. A sample is characterised by the range of n. Ti,j is a set of samples with i &lt;n &lt;j. T is the union of the other four test sets. T3,11 T3,5 T6,8 T9,11 T Samples 400 100 100 100 700 Table 1: Test corpus statistics. Segmentation accuracy is measured by the metric proposed in (Beeferman et al., 1999). Let Tr and Tp be the reference segmentation and that proposed by an automatic procedure. k is the average segment length in T. p(samelTr, k) and p(diffiTr, k) refer to the likelihood of sentence sz and sz±k belonging to the same and different topic segment(s) in Tk p(samelTr, Tp, diff, k) is the probability of a miss, i.e. sz and sz±k are about different topics in Tk but they belong to the same topic segment in T. p(difflTr, Tp, same, k) is the probability of false alarm, i.e. two sentences are about the same topic in Tr but they belong to different segments in T. Equation 5 combines these f</context>
</contexts>
<marker>Beeferman, Berger, Lafferty, 1999</marker>
<rawString>Doug Beeferman, Adam Berger, and John Lafferty. 1999. Statistical models for text segmentation. Machine learning, special issue on Natural Language Processing, 34 (1-3) : 177— 210. C. Cardie and R. Mooney (editors).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Chafe</author>
</authors>
<title>The flow of thought and the flow of language. In</title>
<date>1979</date>
<booktitle>Syntax and Semantics: Discourse and Syntax,</booktitle>
<pages>159--182</pages>
<editor>T. Givon, editor,</editor>
<publisher>Academic Press.</publisher>
<contexts>
<context position="2259" citStr="Chafe, 1979" startWordPosition="335" endWordPosition="336"> does not always improve segmentation accuracy and (3) ranking is crucial to cosine but not LSA. 2 Background A text segmentation algorithm has three main parts. First, the input text is divided into elementary blocks. Second, a similarity metric identifies blocks that are about the same topic. Finally, topic boundaries are discovered by a clustering algorithm. 2.1 Elementary block An elementary block is the smallest text segment that can describe an entire topic, e.g. sentences (Ponte and Croft, 1997), paragraphs (Yaari, 1997) and arbitrary-sized segments (Hearst, 1994). Linguistic theories (Chafe, 1979; Longacre, 1979; Kieras, 1982) and work in information retrieval (Salton et al., 1993; Kaszkiel and Zobel, 1997) suggest a coherent text segment is represented by paragraphs. We argue that a paragraph can address multiple topics and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories</context>
</contexts>
<marker>Chafe, 1979</marker>
<rawString>W. Chafe. 1979. The flow of thought and the flow of language. In T. Givon, editor, Syntax and Semantics: Discourse and Syntax, pages 159-182. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Freddy Y Y Choi</author>
</authors>
<title>Advances in domain independent linear text segmentation.</title>
<date>2000</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>26--33</pages>
<publisher>ACL.</publisher>
<location>Seattle, USA,</location>
<contexts>
<context position="1316" citStr="Choi, 2000" startWordPosition="185" endWordPosition="186">divisive clustering. Test results show LSA is a more accurate similarity measure than the cosine metric (van Rijsbergen, 1979). 1 Introduction The aim of linear text segmentation is to partition a document into blocks, such that each segment is coherent and consecutive segments are about different topics. This procedure is useful in information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999), summarisation (Reynar, 1998), text understanding, anaphora resolution (Kozima, 1993), language modelling (Morris and Hirst, 1991; Beeferman et al., 1997) and text navigation (Choi, 2000b). This paper presents a new algorithm for segmenting written text. The method builds on previous work by Choi (2000a). The primary distinction is the use of latent semantic analysis (LSA) in formulating the similarity matrix. We discovered that (1) LSA is a more accurate measure of similarity than the cosine metric, (2) stemming does not always improve segmentation accuracy and (3) ranking is crucial to cosine but not LSA. 2 Background A text segmentation algorithm has three main parts. First, the input text is divided into elementary blocks. Second, a similarity metric identifies blocks tha</context>
<context position="2697" citStr="Choi, 2000" startWordPosition="404" endWordPosition="405">can describe an entire topic, e.g. sentences (Ponte and Croft, 1997), paragraphs (Yaari, 1997) and arbitrary-sized segments (Hearst, 1994). Linguistic theories (Chafe, 1979; Longacre, 1979; Kieras, 1982) and work in information retrieval (Salton et al., 1993; Kaszkiel and Zobel, 1997) suggest a coherent text segment is represented by paragraphs. We argue that a paragraph can address multiple topics and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirs</context>
<context position="4651" citStr="Choi, 2000" startWordPosition="703" endWordPosition="704">tion accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama and Isahara, 2001), agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994; Choi, 2000a) to determine the optimal segmentation. The main difficulty in clustering is automatic termination, i.e. determining the number of topic boundaries in a document. 3 A new method The input to our algorithm is a list of tokenised sentences S = {81,..,8}. Content words are identified by removing punctuation marks and stopwords from S. A term frequency vector f, is then constructed for each sentence i. fij denotes the number of times content word j occurs in s,. 3.1 Inter-sentence similarity in C99 The C99 algorithm (Choi, 2000a) uses the cosine metric (van Rijsbergen, 1979) (eq. 1) to compute a</context>
<context position="13497" citStr="Choi, 2000" startWordPosition="2277" endWordPosition="2278">n tk is /3(tk) = EzEt.1 k E.Ebk X Thus, the average inter-sentence similarity value for a segmentation T = {t,, ...,t} is defined as, Elc1=1 l3(4) [IT — n Ek=1 ct(tic) The divisive clustering algorithm begins by considering the entire input document S as a coherent topic segment. This is partitioned into two segments T = ftl, t21 at a sentence boundary that maximises [IT, i.e. the most prominent topic boundary. The recursive procedure proceeds until S can no longer be subdivided. The optimal segmentation is signalled by a sharp change in [IT. For implementation details and optimisations, see (Choi, 2000a). 4 Evaluation The following experiments aim to establish the relationship between linguistic processes (stemming, ranking, cosine metric, LSA) and segmentation error rate. The test procedure is based on that presented in (Choi, 2000a) which was derived from work in TDT (Allan et al., 1998) and previous experiments in text segmentation (Reynar, 1998, 71-73). The task is to find the most prominent topic boundaries in a concatenated text. 4.1 Experiment procedure The accuracy of a segmentation algorithm is assessed by the experiment package&apos; described in (Choi, 2000a). A test sample is a conca</context>
<context position="16865" citStr="Choi, 2000" startWordPosition="2846" endWordPosition="2847">ric is not perfect, it is significantly more accurate than the popular precision/recall metric which ignores near misses. Furthermore, the method is sufficiently accurate for this comparative study. 4.2 Experiment 1 - Baseline Five degenerate algorithms define the baseline for the experiments. Be partitions a document into e = 10 segments of equal length. Br, does not propose any boundaries. B,„ assumes all potential boundaries are topic boundaries. Bb randomly selects b = 10 boundaries. B? randomly selects any number of boundaries as real boundaries. Details about Bb and B? are described in (Choi, 2000a). T3,11 T3,5 T6,8 T9,11 T Be 45% 38% 39% 36% 42% B 46% 47% 47% 47% 47% B,„ 54% 53% 53% 53% 53% Bb 46% 47% 47% 47% 47% B? 54% 53% 53% 53% 53% Table 2: Error rate: baseline algorithms Table 2 shows Be performed best with an average error rate of 42%. This is the baseline for algorithms that find the e most prominent topic boundaries. B? serves as the baseline for methods that determines the optimal segmentation, i.e. the number of topic segments in a text. 4.3 Experiment 2 - An analysis of C99 The aim is to relate stemming, ranking and the termination procedure in C99 with segmentation accurac</context>
<context position="21929" citStr="Choi, 2000" startWordPosition="3769" endWordPosition="3770"> 3 show high dimensionality increases error rate. However, the figures in column 4 suggest the contrary. This implies high dimensionality improves the ranking of LSA values but is detrimental to value accuracy. 4.5 Experiment 4 — A comparative study T3,11 T3,5 T6,8 T9,11 T CWM1 9% 10% 7% 5% 8% U00b 10% 9% 7% 5% 9% CWM3 12% 10% 9% 8% 11% C99b 12% 11% 9% 9% 11% U00 12% 9% 10% 11% 11% C99 13% 17% 10% 10% 12% CWM2 14% 10% 11% 12% 13% C99b,_, 23% 19% 21% 20% 22% Table 5: Error rate: a comparative study. Table 5 presents a summary of experiment results. C99 and C99b are the algorithms described in (Choi, 2000a). C99b,, is the same as C99b except ranking has been disabled. The 11% difference between the two shows ranking is crucial to the cosine metric. U00 and U00b are the word frequency methods proposed in (Utiyama and Isahara, 2001). CWM is the new method described in this paper. All versions of the algorithm use a LSA space that was trained on paragraphs. CWM1 is identical to C99b except the stemming algorithm has been disabled and it uses A500 to measure similarity. The results show it is more accurate than previous methods. CWM2 is the same algorithm but ranking has been disabled. The 5% diff</context>
</contexts>
<marker>Choi, 2000</marker>
<rawString>Freddy Y. Y. Choi. 2000a. Advances in domain independent linear text segmentation. In Proceedings of the North American Chapter of the Association for Computational Linguistics, pages 26-33, Seattle, USA, May. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Freddy Y Y Choi</author>
</authors>
<title>Improving the efficiency of speech interfaces for text navigation.</title>
<date>2000</date>
<booktitle>In Proceedings of ICCHP &apos;00.</booktitle>
<contexts>
<context position="1316" citStr="Choi, 2000" startWordPosition="185" endWordPosition="186">divisive clustering. Test results show LSA is a more accurate similarity measure than the cosine metric (van Rijsbergen, 1979). 1 Introduction The aim of linear text segmentation is to partition a document into blocks, such that each segment is coherent and consecutive segments are about different topics. This procedure is useful in information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999), summarisation (Reynar, 1998), text understanding, anaphora resolution (Kozima, 1993), language modelling (Morris and Hirst, 1991; Beeferman et al., 1997) and text navigation (Choi, 2000b). This paper presents a new algorithm for segmenting written text. The method builds on previous work by Choi (2000a). The primary distinction is the use of latent semantic analysis (LSA) in formulating the similarity matrix. We discovered that (1) LSA is a more accurate measure of similarity than the cosine metric, (2) stemming does not always improve segmentation accuracy and (3) ranking is crucial to cosine but not LSA. 2 Background A text segmentation algorithm has three main parts. First, the input text is divided into elementary blocks. Second, a similarity metric identifies blocks tha</context>
<context position="2697" citStr="Choi, 2000" startWordPosition="404" endWordPosition="405">can describe an entire topic, e.g. sentences (Ponte and Croft, 1997), paragraphs (Yaari, 1997) and arbitrary-sized segments (Hearst, 1994). Linguistic theories (Chafe, 1979; Longacre, 1979; Kieras, 1982) and work in information retrieval (Salton et al., 1993; Kaszkiel and Zobel, 1997) suggest a coherent text segment is represented by paragraphs. We argue that a paragraph can address multiple topics and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirs</context>
<context position="4651" citStr="Choi, 2000" startWordPosition="703" endWordPosition="704">tion accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama and Isahara, 2001), agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994; Choi, 2000a) to determine the optimal segmentation. The main difficulty in clustering is automatic termination, i.e. determining the number of topic boundaries in a document. 3 A new method The input to our algorithm is a list of tokenised sentences S = {81,..,8}. Content words are identified by removing punctuation marks and stopwords from S. A term frequency vector f, is then constructed for each sentence i. fij denotes the number of times content word j occurs in s,. 3.1 Inter-sentence similarity in C99 The C99 algorithm (Choi, 2000a) uses the cosine metric (van Rijsbergen, 1979) (eq. 1) to compute a</context>
<context position="13497" citStr="Choi, 2000" startWordPosition="2277" endWordPosition="2278">n tk is /3(tk) = EzEt.1 k E.Ebk X Thus, the average inter-sentence similarity value for a segmentation T = {t,, ...,t} is defined as, Elc1=1 l3(4) [IT — n Ek=1 ct(tic) The divisive clustering algorithm begins by considering the entire input document S as a coherent topic segment. This is partitioned into two segments T = ftl, t21 at a sentence boundary that maximises [IT, i.e. the most prominent topic boundary. The recursive procedure proceeds until S can no longer be subdivided. The optimal segmentation is signalled by a sharp change in [IT. For implementation details and optimisations, see (Choi, 2000a). 4 Evaluation The following experiments aim to establish the relationship between linguistic processes (stemming, ranking, cosine metric, LSA) and segmentation error rate. The test procedure is based on that presented in (Choi, 2000a) which was derived from work in TDT (Allan et al., 1998) and previous experiments in text segmentation (Reynar, 1998, 71-73). The task is to find the most prominent topic boundaries in a concatenated text. 4.1 Experiment procedure The accuracy of a segmentation algorithm is assessed by the experiment package&apos; described in (Choi, 2000a). A test sample is a conca</context>
<context position="16865" citStr="Choi, 2000" startWordPosition="2846" endWordPosition="2847">ric is not perfect, it is significantly more accurate than the popular precision/recall metric which ignores near misses. Furthermore, the method is sufficiently accurate for this comparative study. 4.2 Experiment 1 - Baseline Five degenerate algorithms define the baseline for the experiments. Be partitions a document into e = 10 segments of equal length. Br, does not propose any boundaries. B,„ assumes all potential boundaries are topic boundaries. Bb randomly selects b = 10 boundaries. B? randomly selects any number of boundaries as real boundaries. Details about Bb and B? are described in (Choi, 2000a). T3,11 T3,5 T6,8 T9,11 T Be 45% 38% 39% 36% 42% B 46% 47% 47% 47% 47% B,„ 54% 53% 53% 53% 53% Bb 46% 47% 47% 47% 47% B? 54% 53% 53% 53% 53% Table 2: Error rate: baseline algorithms Table 2 shows Be performed best with an average error rate of 42%. This is the baseline for algorithms that find the e most prominent topic boundaries. B? serves as the baseline for methods that determines the optimal segmentation, i.e. the number of topic segments in a text. 4.3 Experiment 2 - An analysis of C99 The aim is to relate stemming, ranking and the termination procedure in C99 with segmentation accurac</context>
<context position="21929" citStr="Choi, 2000" startWordPosition="3769" endWordPosition="3770"> 3 show high dimensionality increases error rate. However, the figures in column 4 suggest the contrary. This implies high dimensionality improves the ranking of LSA values but is detrimental to value accuracy. 4.5 Experiment 4 — A comparative study T3,11 T3,5 T6,8 T9,11 T CWM1 9% 10% 7% 5% 8% U00b 10% 9% 7% 5% 9% CWM3 12% 10% 9% 8% 11% C99b 12% 11% 9% 9% 11% U00 12% 9% 10% 11% 11% C99 13% 17% 10% 10% 12% CWM2 14% 10% 11% 12% 13% C99b,_, 23% 19% 21% 20% 22% Table 5: Error rate: a comparative study. Table 5 presents a summary of experiment results. C99 and C99b are the algorithms described in (Choi, 2000a). C99b,, is the same as C99b except ranking has been disabled. The 11% difference between the two shows ranking is crucial to the cosine metric. U00 and U00b are the word frequency methods proposed in (Utiyama and Isahara, 2001). CWM is the new method described in this paper. All versions of the algorithm use a LSA space that was trained on paragraphs. CWM1 is identical to C99b except the stemming algorithm has been disabled and it uses A500 to measure similarity. The results show it is more accurate than previous methods. CWM2 is the same algorithm but ranking has been disabled. The 5% diff</context>
</contexts>
<marker>Choi, 2000</marker>
<rawString>Freddy Y. Y. Choi. 2000b. Improving the efficiency of speech interfaces for text navigation. In Proceedings of ICCHP &apos;00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S T Dumais</author>
<author>G W Furnas</author>
<author>T K Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<pages>41--391</pages>
<contexts>
<context position="7163" citStr="Deerwester et al., 1990" startWordPosition="1138" endWordPosition="1141">yntactically motivated inflections are placed in an equivalent class. For example, cooking, cooked, cooks, cooker are all instances of the class cook. Unlike morphological analysers (Koskenniemi, 1983, for example), a stemming algorithm does not identify the morphemes. Its simply removes common affixes from a word, e.g. combines, combine —&gt; combin, depart, department —&gt; depart. Thus, similar surface forms are considered positive evidence in the similarity estimate. We propose that latent semantic analysis offers a better solution to the term matching problem. 3.2 Latent semantic analysis LSA (Deerwester et al., 1990) stems from work in information retrieval, where the main difficulty is formulating a similarity metric that associates a user query with the relevant documents in a database. The basic keyword search approach retrieves all documents which contain some or all of the query terms. This is inaccurate since the same concept may be described using different terms. To circumvent this, Jing and Croft (1994) developed an association thesaurus for matching semantically related words. Xu and Croft (1996) offered a trainable method call local context analysis (LCA) which replaces each query term with fre</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and R. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41:391-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Eichmann</author>
<author>Miguel Ruiz</author>
<author>Padmini Srinivasan</author>
</authors>
<title>A cluster-based approach to tracking, detection and segmentation of broadcast news.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 DARPA Broadcast News Workshop (TDT-2).</booktitle>
<contexts>
<context position="3207" citStr="Eichmann et al., 1999" startWordPosition="481" endWordPosition="484">n of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using</context>
</contexts>
<marker>Eichmann, Ruiz, Srinivasan, 1999</marker>
<rawString>David Eichmann, Miguel Ruiz, and Padmini Srinivasan. 1999. A cluster-based approach to tracking, detection and segmentation of broadcast news. In Proceedings of the 1999 DARPA Broadcast News Workshop (TDT-2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G H Golub</author>
<author>C F van Loan</author>
</authors>
<title>Matrix Computations.</title>
<date>1989</date>
<publisher>John Hopkins University Press.</publisher>
<marker>Golub, van Loan, 1989</marker>
<rawString>G. H. Golub and C. F. van Loan. 1989. Matrix Computations. John Hopkins University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mochizuki Hajime</author>
<author>Honda Takeo</author>
<author>Okumura Manabu</author>
</authors>
<title>Text segmentation with multiple surface linguistic cues.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL &apos;98,</booktitle>
<pages>881--885</pages>
<contexts>
<context position="3943" citStr="Hajime et al., 1998" startWordPosition="593" endWordPosition="596">tion over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama </context>
</contexts>
<marker>Hajime, Takeo, Manabu, 1998</marker>
<rawString>Mochizuki Hajime, Honda Takeo, and Okumura Manabu. 1998. Text segmentation with multiple surface linguistic cues. In Proceedings of COLING-ACL &apos;98, pages 881-885.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Halliday</author>
<author>Rugaiya Hasan</author>
</authors>
<title>Cohesion in English.</title>
<date>1976</date>
<publisher>Longman Group,</publisher>
<location>New York.</location>
<contexts>
<context position="2933" citStr="Halliday and Hasan (1976)" startWordPosition="439" endWordPosition="442">mation retrieval (Salton et al., 1993; Kaszkiel and Zobel, 1997) suggest a coherent text segment is represented by paragraphs. We argue that a paragraph can address multiple topics and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in</context>
</contexts>
<marker>Halliday, Hasan, 1976</marker>
<rawString>Michael Halliday and Rugaiya Hasan. 1976. Cohesion in English. Longman Group, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
<author>Christian Plaunt</author>
</authors>
<title>Subtopic structuring for full-length document access.</title>
<date>1993</date>
<booktitle>In Proceedings of the 16th Annual International A CM/SIGIR Conference,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="1087" citStr="Hearst and Plaunt, 1993" startWordPosition="151" endWordPosition="154">t segmentation that is more accurate or at least as accurate as state-of-the-art methods (Utiyama and Isahara, 2001; Choi, 2000a). Inter-sentence similarity is estimated by latent semantic analysis (LSA). Boundary locations are discovered by divisive clustering. Test results show LSA is a more accurate similarity measure than the cosine metric (van Rijsbergen, 1979). 1 Introduction The aim of linear text segmentation is to partition a document into blocks, such that each segment is coherent and consecutive segments are about different topics. This procedure is useful in information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999), summarisation (Reynar, 1998), text understanding, anaphora resolution (Kozima, 1993), language modelling (Morris and Hirst, 1991; Beeferman et al., 1997) and text navigation (Choi, 2000b). This paper presents a new algorithm for segmenting written text. The method builds on previous work by Choi (2000a). The primary distinction is the use of latent semantic analysis (LSA) in formulating the similarity matrix. We discovered that (1) LSA is a more accurate measure of similarity than the cosine metric, (2) stemming does not always improve segmentation a</context>
</contexts>
<marker>Hearst, Plaunt, 1993</marker>
<rawString>Marti Hearst and Christian Plaunt. 1993. Subtopic structuring for full-length document access. In Proceedings of the 16th Annual International A CM/SIGIR Conference, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Multi-paragraph segmentation of expository text.</title>
<date>1994</date>
<booktitle>In Proceedings of the ACL&apos;94. Las Crces, NM.</booktitle>
<contexts>
<context position="1101" citStr="Hearst, 1994" startWordPosition="155" endWordPosition="156">re accurate or at least as accurate as state-of-the-art methods (Utiyama and Isahara, 2001; Choi, 2000a). Inter-sentence similarity is estimated by latent semantic analysis (LSA). Boundary locations are discovered by divisive clustering. Test results show LSA is a more accurate similarity measure than the cosine metric (van Rijsbergen, 1979). 1 Introduction The aim of linear text segmentation is to partition a document into blocks, such that each segment is coherent and consecutive segments are about different topics. This procedure is useful in information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999), summarisation (Reynar, 1998), text understanding, anaphora resolution (Kozima, 1993), language modelling (Morris and Hirst, 1991; Beeferman et al., 1997) and text navigation (Choi, 2000b). This paper presents a new algorithm for segmenting written text. The method builds on previous work by Choi (2000a). The primary distinction is the use of latent semantic analysis (LSA) in formulating the similarity matrix. We discovered that (1) LSA is a more accurate measure of similarity than the cosine metric, (2) stemming does not always improve segmentation accuracy and (3</context>
<context position="3155" citStr="Hearst, 1994" startWordPosition="475" endWordPosition="476">ation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to </context>
<context position="4424" citStr="Hearst, 1994" startWordPosition="669" endWordPosition="670">ision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama and Isahara, 2001), agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994; Choi, 2000a) to determine the optimal segmentation. The main difficulty in clustering is automatic termination, i.e. determining the number of topic boundaries in a document. 3 A new method The input to our algorithm is a list of tokenised sentences S = {81,..,8}. Content words are identified by removing punctuation marks and stopwords from S. A term frequency vector f, is then co</context>
</contexts>
<marker>Hearst, 1994</marker>
<rawString>Marti A. Hearst. 1994. Multi-paragraph segmentation of expository text. In Proceedings of the ACL&apos;94. Las Crces, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oskari Heinonen</author>
</authors>
<title>Optimal multiparagraph text segmentation by dynamic programming</title>
<date>1998</date>
<booktitle>In Proceedings of COLINGA CL &apos;98.</booktitle>
<contexts>
<context position="4533" citStr="Heinonen, 1998" startWordPosition="686" endWordPosition="687">ls (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama and Isahara, 2001), agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994; Choi, 2000a) to determine the optimal segmentation. The main difficulty in clustering is automatic termination, i.e. determining the number of topic boundaries in a document. 3 A new method The input to our algorithm is a list of tokenised sentences S = {81,..,8}. Content words are identified by removing punctuation marks and stopwords from S. A term frequency vector f, is then constructed for each sentence i. fij denotes the number of times content word j occurs in s,. 3.1 Inter-sentenc</context>
</contexts>
<marker>Heinonen, 1998</marker>
<rawString>Oskari Heinonen. 1998. Optimal multiparagraph text segmentation by dynamic programming In Proceedings of COLINGA CL &apos;98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Jing</author>
<author>W B Croft</author>
</authors>
<title>An association thesaurus for information retrieval.</title>
<date>1994</date>
<booktitle>In Proceedings of RIA0&apos;94, Intelligent Multimedia Information Retrieval Systems and Management,</booktitle>
<pages>285--298</pages>
<contexts>
<context position="7566" citStr="Jing and Croft (1994)" startWordPosition="1206" endWordPosition="1209">ms are considered positive evidence in the similarity estimate. We propose that latent semantic analysis offers a better solution to the term matching problem. 3.2 Latent semantic analysis LSA (Deerwester et al., 1990) stems from work in information retrieval, where the main difficulty is formulating a similarity metric that associates a user query with the relevant documents in a database. The basic keyword search approach retrieves all documents which contain some or all of the query terms. This is inaccurate since the same concept may be described using different terms. To circumvent this, Jing and Croft (1994) developed an association thesaurus for matching semantically related words. Xu and Croft (1996) offered a trainable method call local context analysis (LCA) which replaces each query term with frequently cooccurring words. Roughly speaking, LCA computes a word co-occurrence matrix C for a training corpus. A threshold is then applied such that large values in C are replaced by 1 and other values become 0. Each row C, can be considered as a feature vector for word i. The meaning of a text is approximated by the sum of the word feature vectors. Similarity between two texts is estimated by the di</context>
</contexts>
<marker>Jing, Croft, 1994</marker>
<rawString>Y. Jing and W. B. Croft. 1994. An association thesaurus for information retrieval. In Proceedings of RIA0&apos;94, Intelligent Multimedia Information Retrieval Systems and Management, pages 285-298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min-Yen Kan</author>
<author>Judith L Klavans</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Linear segmentation and segment significance.</title>
<date>1998</date>
<booktitle>In Proceedings of the 6th International Workshop of Very Large Corpora (WVLC-6),</booktitle>
<pages>197--205</pages>
<location>Montreal, Quebec, Canada,</location>
<contexts>
<context position="3259" citStr="Kan et al., 1998" startWordPosition="490" endWordPosition="493">in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and N</context>
</contexts>
<marker>Kan, Klavans, McKeown, 1998</marker>
<rawString>Min-Yen Kan, Judith L. Klavans, and Kathleen R. McKeown. 1998. Linear segmentation and segment significance. In Proceedings of the 6th International Workshop of Very Large Corpora (WVLC-6), pages 197-205, Montreal, Quebec, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kaszkiel</author>
<author>J Zobel</author>
</authors>
<title>Passage retrieval revisited.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>178--185</pages>
<publisher>ACM.</publisher>
<location>Philadelphia.</location>
<contexts>
<context position="2372" citStr="Kaszkiel and Zobel, 1997" startWordPosition="350" endWordPosition="353">Background A text segmentation algorithm has three main parts. First, the input text is divided into elementary blocks. Second, a similarity metric identifies blocks that are about the same topic. Finally, topic boundaries are discovered by a clustering algorithm. 2.1 Elementary block An elementary block is the smallest text segment that can describe an entire topic, e.g. sentences (Ponte and Croft, 1997), paragraphs (Yaari, 1997) and arbitrary-sized segments (Hearst, 1994). Linguistic theories (Chafe, 1979; Longacre, 1979; Kieras, 1982) and work in information retrieval (Salton et al., 1993; Kaszkiel and Zobel, 1997) suggest a coherent text segment is represented by paragraphs. We argue that a paragraph can address multiple topics and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is </context>
</contexts>
<marker>Kaszkiel, Zobel, 1997</marker>
<rawString>M. Kaszkiel and J. Zobel. 1997. Passage retrieval revisited. In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval, pages 178-185, Philadelphia. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Kaufmann</author>
</authors>
<title>Cohesion and collocation: Using context vectors in text segmentation.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (Student Session),</booktitle>
<pages>591--595</pages>
<publisher>ACL.</publisher>
<location>College Park, USA,</location>
<contexts>
<context position="3184" citStr="Kaufmann, 1999" startWordPosition="479" endWordPosition="480">t is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Feat</context>
</contexts>
<marker>Kaufmann, 1999</marker>
<rawString>Stefan Kaufmann. 1999. Cohesion and collocation: Using context vectors in text segmentation. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (Student Session), pages 591-595, College Park, USA, June. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kieras</author>
</authors>
<title>A model of reader strategy for abstracting main ideas from simple technical prose.</title>
<date>1982</date>
<tech>Text, 2(13).</tech>
<contexts>
<context position="2290" citStr="Kieras, 1982" startWordPosition="339" endWordPosition="340">entation accuracy and (3) ranking is crucial to cosine but not LSA. 2 Background A text segmentation algorithm has three main parts. First, the input text is divided into elementary blocks. Second, a similarity metric identifies blocks that are about the same topic. Finally, topic boundaries are discovered by a clustering algorithm. 2.1 Elementary block An elementary block is the smallest text segment that can describe an entire topic, e.g. sentences (Ponte and Croft, 1997), paragraphs (Yaari, 1997) and arbitrary-sized segments (Hearst, 1994). Linguistic theories (Chafe, 1979; Longacre, 1979; Kieras, 1982) and work in information retrieval (Salton et al., 1993; Kaszkiel and Zobel, 1997) suggest a coherent text segment is represented by paragraphs. We argue that a paragraph can address multiple topics and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem</context>
</contexts>
<marker>Kieras, 1982</marker>
<rawString>D. Kieras. 1982. A model of reader strategy for abstracting main ideas from simple technical prose. Text, 2(13).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Two-level Morphology: a General Computational Model for WordForm Recognition and Production.</title>
<date>1983</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of General Linguistics, University of Helsinki.</institution>
<contexts>
<context position="6739" citStr="Koskenniemi, 1983" startWordPosition="1075" endWordPosition="1076">y is significant. However, if the ruler was warped, but the order of the markings is preserved, one can only conclude that x1 &lt; x2 &lt; x3. This is a qualitative analysis of X, i.e. the order is significant but the relative value has no meaning. This is a more robust interpretation of X. E {-r,•••,r} MPq I (2) (2r + 1)2 The second problem was addressed by applying a stemming algorithm (Porter, 1980) to S, such that syntactically motivated inflections are placed in an equivalent class. For example, cooking, cooked, cooks, cooker are all instances of the class cook. Unlike morphological analysers (Koskenniemi, 1983, for example), a stemming algorithm does not identify the morphemes. Its simply removes common affixes from a word, e.g. combines, combine —&gt; combin, depart, department —&gt; depart. Thus, similar surface forms are considered positive evidence in the similarity estimate. We propose that latent semantic analysis offers a better solution to the term matching problem. 3.2 Latent semantic analysis LSA (Deerwester et al., 1990) stems from work in information retrieval, where the main difficulty is formulating a similarity metric that associates a user query with the relevant documents in a database. </context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>K. Koskenniemi. 1983. Two-level Morphology: a General Computational Model for WordForm Recognition and Production. Ph.D. thesis, Department of General Linguistics, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Kozima</author>
</authors>
<title>Text segmentation based on similarity between words.</title>
<date>1993</date>
<booktitle>In Proceedings of ACL&apos;93,</booktitle>
<pages>286--288</pages>
<location>Ohio.</location>
<contexts>
<context position="1215" citStr="Kozima, 1993" startWordPosition="169" endWordPosition="170">entence similarity is estimated by latent semantic analysis (LSA). Boundary locations are discovered by divisive clustering. Test results show LSA is a more accurate similarity measure than the cosine metric (van Rijsbergen, 1979). 1 Introduction The aim of linear text segmentation is to partition a document into blocks, such that each segment is coherent and consecutive segments are about different topics. This procedure is useful in information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999), summarisation (Reynar, 1998), text understanding, anaphora resolution (Kozima, 1993), language modelling (Morris and Hirst, 1991; Beeferman et al., 1997) and text navigation (Choi, 2000b). This paper presents a new algorithm for segmenting written text. The method builds on previous work by Choi (2000a). The primary distinction is the use of latent semantic analysis (LSA) in formulating the similarity matrix. We discovered that (1) LSA is a more accurate measure of similarity than the cosine metric, (2) stemming does not always improve segmentation accuracy and (3) ranking is crucial to cosine but not LSA. 2 Background A text segmentation algorithm has three main parts. First</context>
<context position="3358" citStr="Kozima, 1993" startWordPosition="506" endWordPosition="507">timates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum en</context>
</contexts>
<marker>Kozima, 1993</marker>
<rawString>Hideki Kozima. 1993. Text segmentation based on similarity between words. In Proceedings of ACL&apos;93, pages 286-288, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>Automatic detection of discourse structure by checking surface information in sentences.</title>
<date>1994</date>
<booktitle>In Processings of COLING&apos;94,</booktitle>
<volume>2</volume>
<pages>1123--1127</pages>
<contexts>
<context position="3869" citStr="Kurohashi and Nagao, 1994" startWordPosition="581" endWordPosition="584">n et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1</context>
</contexts>
<marker>Kurohashi, Nagao, 1994</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 1994. Automatic detection of discourse structure by checking surface information in sentences. In Processings of COLING&apos;94, volume 2, pages 1123-1127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Landauer</author>
<author>S T Dumais</author>
</authors>
<title>A solution to Plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<pages>104--211</pages>
<contexts>
<context position="8852" citStr="Landauer and Dumais, 1997" startWordPosition="1426" endWordPosition="1429">roft, 1997, for details). LSA is a classification approach to query expansion. The method is similar to LCA in that the &amp;quot;meaning&amp;quot; of a word w is represented by its relation to other words. The primary distinction is, LSA applies principle components analysis to a word similarity matrix to identify the best features for distinguishing dissimilar words. Like LCA, the meaning of a text is computed as the sum of the word feature vectors. Text similarity is measured by the cosine of the corresponding feature vectors. LSA has been shown to match human similarity judgements on a wide range of tasks (Landauer and Dumais, 1997; Wolfe et al., 1998; Wiemer-Hastings et al., 1999, for example). 3.2.1 Training LSA LSA is trained on a set of texts A = Y1, ..., with vocabulary twi, turd-. Anxm matrix A is calculated, in which, A,i is the number of times to, occurs in Si. The values are scaled according to a general form of inverse document frequency, Bii = Aij X Ibk E {1,...,m} : Ak &gt;01 Singular value decomposition, or SVD (Golub and van Loan, 1989) is then applied to yield B = UEVT, where XT denotes the transposed matrix of X. The columns of U and V are the eigenvectors of BBT and BTB, respectively. The diagonal values o</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>T.K. Landauer and S.T. Dumais. 1997. A solution to Plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104:211-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane J Litman</author>
<author>Rebecca J Passonneau</author>
</authors>
<title>Combining multiple knowledge sources for discourse segmentation.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="3899" citStr="Litman and Passonneau, 1995" startWordPosition="585" endWordPosition="589">relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Pon</context>
</contexts>
<marker>Litman, Passonneau, 1995</marker>
<rawString>Diane J. Litman and Rebecca J. Passonneau. 1995. Combining multiple knowledge sources for discourse segmentation. In Proceedings of the 33rd Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Longacre</author>
</authors>
<title>The paragraph as a grammatical unit. In</title>
<date>1979</date>
<booktitle>Syntax and Semantics: Discourse and Syntax,</booktitle>
<pages>115--134</pages>
<editor>T. Givon, editor,</editor>
<publisher>Academic Press.</publisher>
<contexts>
<context position="2275" citStr="Longacre, 1979" startWordPosition="337" endWordPosition="338">ays improve segmentation accuracy and (3) ranking is crucial to cosine but not LSA. 2 Background A text segmentation algorithm has three main parts. First, the input text is divided into elementary blocks. Second, a similarity metric identifies blocks that are about the same topic. Finally, topic boundaries are discovered by a clustering algorithm. 2.1 Elementary block An elementary block is the smallest text segment that can describe an entire topic, e.g. sentences (Ponte and Croft, 1997), paragraphs (Yaari, 1997) and arbitrary-sized segments (Hearst, 1994). Linguistic theories (Chafe, 1979; Longacre, 1979; Kieras, 1982) and work in information retrieval (Salton et al., 1993; Kaszkiel and Zobel, 1997) suggest a coherent text segment is represented by paragraphs. We argue that a paragraph can address multiple topics and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesi</context>
</contexts>
<marker>Longacre, 1979</marker>
<rawString>R. Longacre. 1979. The paragraph as a grammatical unit. In T. Givon, editor, Syntax and Semantics: Discourse and Syntax, pages 115-134. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitch Marcus</author>
<author>M A Marcinkiewicz</author>
<author>B Santorini</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="11321" citStr="Marcus et al., 1993" startWordPosition="1885" endWordPosition="1888">arity is estimated by the cosine of the corresponding X (eq. 4, Azk is the k—th element in Ai). Ai = x Ak(j) (3) E = COS(Ai, A k Aik X Ajki) = (4) E A2 E A2 jk vJ k ik x k 3.2.3 LSA parameters Since Ak is derived from the co-occurrence matrix A, the size of each training text Si E A is crucial to its performance. Work in information retrieval uses Sz = document since the aim is to distinguish entire texts. Sz = paragraph is popular in psychology experiments. However, we suspect the segmentation task may benefit from Sz = sentence. Thus, two training corpora were derived from the Brown Corpus (Marcus et al., 1993). Annotations were first removed to leave a set of tokenised raw text (1.2 million tokens). This was partitioned into 35,000 paragraphs or 104,000 sentences, as two training corpora. The parameter k adjusts the accuracy of Ak. A large k implies minor differences in the feature space are significant. Thus, they should be taken into account in the formulation of Ak. This is appropriate when the vocabulary is small and there is sufficient training data. A small k is used when A is sparse and the values in A are inaccurate. 3.3 Image ranking Once the similarity matrix M is calculated for the input</context>
<context position="14254" citStr="Marcus et al., 1993" startWordPosition="2398" endWordPosition="2401">ic, LSA) and segmentation error rate. The test procedure is based on that presented in (Choi, 2000a) which was derived from work in TDT (Allan et al., 1998) and previous experiments in text segmentation (Reynar, 1998, 71-73). The task is to find the most prominent topic boundaries in a concatenated text. 4.1 Experiment procedure The accuracy of a segmentation algorithm is assessed by the experiment package&apos; described in (Choi, 2000a). A test sample is a concatenation of ten text segments. Each segment is the first n sentences of a randomly selected document from a subset2 of the Brown corpus (Marcus et al., 1993). Table 1 presents the corpus statistics. A sample is characterised by the range of n. Ti,j is a set of samples with i &lt;n &lt;j. T is the union of the other four test sets. T3,11 T3,5 T6,8 T9,11 T Samples 400 100 100 100 700 Table 1: Test corpus statistics. Segmentation accuracy is measured by the metric proposed in (Beeferman et al., 1999). Let Tr and Tp be the reference segmentation and that proposed by an automatic procedure. k is the average segment length in T. p(samelTr, k) and p(diffiTr, k) refer to the likelihood of sentence sz and sz±k belonging to the same and different topic segment(s)</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitch Marcus, M. A. Marcinkiewicz, and B. Santorini. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miike</author>
<author>E Itoh</author>
<author>K Ono</author>
<author>K Sumita</author>
</authors>
<title>A full text retrieval system.</title>
<date>1994</date>
<booktitle>In Proceedings of SI GIR &apos;94,</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="3842" citStr="Miike et al., 1994" startWordPosition="577" endWordPosition="580">ntity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (</context>
</contexts>
<marker>Miike, Itoh, Ono, Sumita, 1994</marker>
<rawString>S. Miike, E. Itoh, K. Ono, and K. Sumita. 1994. A full text retrieval system. In Proceedings of SI GIR &apos;94, Dublin, Ireland.</rawString>
</citation>
<citation valid="false">
<tech>Technical Report TR97-18.</tech>
<institution>U.Mass. Computer Science</institution>
<marker></marker>
<rawString>U.Mass. Computer Science Technical Report TR97-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<pages>14--3</pages>
<contexts>
<context position="6521" citStr="Porter, 1980" startWordPosition="1042" endWordPosition="1043">ider X = {xl,x2,x3} = {1,3,6} as the length of three objects. If X was measured with an ordinary ruler, one can conclude that x2 is three times longer than x1. This is a quantitative analysis of X, i.e. the quantity is significant. However, if the ruler was warped, but the order of the markings is preserved, one can only conclude that x1 &lt; x2 &lt; x3. This is a qualitative analysis of X, i.e. the order is significant but the relative value has no meaning. This is a more robust interpretation of X. E {-r,•••,r} MPq I (2) (2r + 1)2 The second problem was addressed by applying a stemming algorithm (Porter, 1980) to S, such that syntactically motivated inflections are placed in an equivalent class. For example, cooking, cooked, cooks, cooker are all instances of the class cook. Unlike morphological analysers (Koskenniemi, 1983, for example), a stemming algorithm does not identify the morphemes. Its simply removes common affixes from a word, e.g. combines, combine —&gt; combin, depart, department —&gt; depart. Thus, similar surface forms are considered positive evidence in the similarity estimate. We propose that latent semantic analysis offers a better solution to the term matching problem. 3.2 Latent seman</context>
<context position="17886" citStr="Porter, 1980" startWordPosition="3031" endWordPosition="3032">tation, i.e. the number of topic segments in a text. 4.3 Experiment 2 - An analysis of C99 The aim is to relate stemming, ranking and the termination procedure in C99 with segmentation accuracy. The algorithm used in this experiment is identical to that presented in (Choi, 2000a) except tokens such as -- and - are recognised as punctuation marks and removed during pre-processing. Test results show this modification reduces error rate by 1%. An analysis of the original algorithm reveals that non-word tokens introduce errors since they are converted into a null string by the stemming algorithm (Porter, 1980). This implementation of C99 has three parameters. +r implies ranking is applied to the similarity matrix prior to divisive clustering. +s shows the stemming algorithm is used in preprocessing. +b means the algorithm finds the 10 most prominent topic boundaries, i.e. the automatic termination procedure is inactive. r s b T3,11 T3,5 T6,8 T9,11 T + + + 12% 11% 9% 9% 11% + + - 13% 17% 10% 10% 12% + - + 13% 10% 10% 10% 12% + - - 13% 18% 10% 12% 13% - + + 21% 18% 19% 18% 20% - - + 23% 19% 21% 20% 22% Table 3: Error rate: variants of C99. Test results (table 3) show ranking is crucial to C99. There </context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>M. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130-137, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William H Press</author>
<author>Saul A Teukolsky</author>
<author>William T Vettering</author>
<author>Brian P Flannery</author>
</authors>
<date>1992</date>
<booktitle>Numerical recipes in C: The Art of Scientific Computing, chapter 14,</booktitle>
<pages>623--628</pages>
<publisher>Cambridge University Press,</publisher>
<note>second edition.</note>
<contexts>
<context position="22864" citStr="Press et al., 1992" startWordPosition="3928" endWordPosition="3931">SA space that was trained on paragraphs. CWM1 is identical to C99b except the stemming algorithm has been disabled and it uses A500 to measure similarity. The results show it is more accurate than previous methods. CWM2 is the same algorithm but ranking has been disabled. The 5% difference between this and CWM1 implies ranking does improve accuracy. Finally, CWM3 is a variant of CWM2 which uses A100 to measure similarity. The 11% difference between this and C99b,_, shows LSA is more accurate than the cosine metric. The significance of our results has been confirmed by both t-test and KS-test (Press et al., 1992). 5 Conclusions A series of experiments were conducted to establish the relationship between linguistic processes and segmentation accuracy. C99 (Choi, 2000a) was used as the test bench. In the first set of experiments, its stemming algorithm, ranking procedure and automatic termination method were systematically disabled to determine the contribution of each process to overall performance. We discovered that, first, stemming generally improves accuracy unless the topic segments are short (3 to 5 sentences). Second, ranking plays a vital role in C99. It reduces error rate by half (22% to 10%).</context>
</contexts>
<marker>Press, Teukolsky, Vettering, Flannery, 1992</marker>
<rawString>William H. Press, Saul A. Teukolsky, William T. Vettering, and Brian P. Flannery, 1992. Numerical recipes in C: The Art of Scientific Computing, chapter 14, pages 623-628. Cambridge University Press, second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey C Reynar</author>
</authors>
<title>An automatic method of finding topic boundaries.</title>
<date>1994</date>
<booktitle>In Proceedings of ACL &apos;94</booktitle>
<location>(Student session).</location>
<contexts>
<context position="3100" citStr="Reynar, 1994" startWordPosition="467" endWordPosition="468"> and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic fea</context>
<context position="4639" citStr="Reynar, 1994" startWordPosition="701" endWordPosition="702">prove segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama and Isahara, 2001), agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994; Choi, 2000a) to determine the optimal segmentation. The main difficulty in clustering is automatic termination, i.e. determining the number of topic boundaries in a document. 3 A new method The input to our algorithm is a list of tokenised sentences S = {81,..,8}. Content words are identified by removing punctuation marks and stopwords from S. A term frequency vector f, is then constructed for each sentence i. fij denotes the number of times content word j occurs in s,. 3.1 Inter-sentence similarity in C99 The C99 algorithm (Choi, 2000a) uses the cosine metric (van Rijsbergen, 1979) (eq. 1) </context>
</contexts>
<marker>Reynar, 1994</marker>
<rawString>Jeffrey C. Reynar. 1994. An automatic method of finding topic boundaries. In Proceedings of ACL &apos;94 (Student session).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey C Reynar</author>
</authors>
<title>Topic segmentation: Algorithms and applications.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="1159" citStr="Reynar, 1998" startWordPosition="163" endWordPosition="164">ethods (Utiyama and Isahara, 2001; Choi, 2000a). Inter-sentence similarity is estimated by latent semantic analysis (LSA). Boundary locations are discovered by divisive clustering. Test results show LSA is a more accurate similarity measure than the cosine metric (van Rijsbergen, 1979). 1 Introduction The aim of linear text segmentation is to partition a document into blocks, such that each segment is coherent and consecutive segments are about different topics. This procedure is useful in information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999), summarisation (Reynar, 1998), text understanding, anaphora resolution (Kozima, 1993), language modelling (Morris and Hirst, 1991; Beeferman et al., 1997) and text navigation (Choi, 2000b). This paper presents a new algorithm for segmenting written text. The method builds on previous work by Choi (2000a). The primary distinction is the use of latent semantic analysis (LSA) in formulating the similarity matrix. We discovered that (1) LSA is a more accurate measure of similarity than the cosine metric, (2) stemming does not always improve segmentation accuracy and (3) ranking is crucial to cosine but not LSA. 2 Background A</context>
<context position="3584" citStr="Reynar, 1998" startWordPosition="541" endWordPosition="542"> believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al</context>
<context position="13850" citStr="Reynar, 1998" startWordPosition="2331" endWordPosition="2332">ary that maximises [IT, i.e. the most prominent topic boundary. The recursive procedure proceeds until S can no longer be subdivided. The optimal segmentation is signalled by a sharp change in [IT. For implementation details and optimisations, see (Choi, 2000a). 4 Evaluation The following experiments aim to establish the relationship between linguistic processes (stemming, ranking, cosine metric, LSA) and segmentation error rate. The test procedure is based on that presented in (Choi, 2000a) which was derived from work in TDT (Allan et al., 1998) and previous experiments in text segmentation (Reynar, 1998, 71-73). The task is to find the most prominent topic boundaries in a concatenated text. 4.1 Experiment procedure The accuracy of a segmentation algorithm is assessed by the experiment package&apos; described in (Choi, 2000a). A test sample is a concatenation of ten text segments. Each segment is the first n sentences of a randomly selected document from a subset2 of the Brown corpus (Marcus et al., 1993). Table 1 presents the corpus statistics. A sample is characterised by the range of n. Ti,j is a set of samples with i &lt;n &lt;j. T is the union of the other four test sets. T3,11 T3,5 T6,8 T9,11 T Sa</context>
</contexts>
<marker>Reynar, 1998</marker>
<rawString>Jeffrey C. Reynar. 1998. Topic segmentation: Algorithms and applications. Ph.D. thesis, Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey C Reynar</author>
</authors>
<title>Statistical models for topic segmentation.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>357--364</pages>
<publisher>ACL.</publisher>
<location>College Park, USA,</location>
<contexts>
<context position="1129" citStr="Reynar, 1999" startWordPosition="159" endWordPosition="161">accurate as state-of-the-art methods (Utiyama and Isahara, 2001; Choi, 2000a). Inter-sentence similarity is estimated by latent semantic analysis (LSA). Boundary locations are discovered by divisive clustering. Test results show LSA is a more accurate similarity measure than the cosine metric (van Rijsbergen, 1979). 1 Introduction The aim of linear text segmentation is to partition a document into blocks, such that each segment is coherent and consecutive segments are about different topics. This procedure is useful in information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999), summarisation (Reynar, 1998), text understanding, anaphora resolution (Kozima, 1993), language modelling (Morris and Hirst, 1991; Beeferman et al., 1997) and text navigation (Choi, 2000b). This paper presents a new algorithm for segmenting written text. The method builds on previous work by Choi (2000a). The primary distinction is the use of latent semantic analysis (LSA) in formulating the similarity matrix. We discovered that (1) LSA is a more accurate measure of similarity than the cosine metric, (2) stemming does not always improve segmentation accuracy and (3) ranking is crucial to cosi</context>
<context position="3446" citStr="Reynar, 1999" startWordPosition="521" endWordPosition="522">nto one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation </context>
</contexts>
<marker>Reynar, 1999</marker>
<rawString>Jeffrey C. Reynar. 1999. Statistical models for topic segmentation. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 357-364, College Park, USA, June. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>James Allan</author>
<author>Chris Buckley</author>
</authors>
<title>Approaches to passage retrieval in full text information systems.</title>
<date>1993</date>
<booktitle>In Proceedings of the 16th Annual International ACM/SIGIR Conference,</booktitle>
<pages>49--58</pages>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="2345" citStr="Salton et al., 1993" startWordPosition="346" endWordPosition="349">osine but not LSA. 2 Background A text segmentation algorithm has three main parts. First, the input text is divided into elementary blocks. Second, a similarity metric identifies blocks that are about the same topic. Finally, topic boundaries are discovered by a clustering algorithm. 2.1 Elementary block An elementary block is the smallest text segment that can describe an entire topic, e.g. sentences (Ponte and Croft, 1997), paragraphs (Yaari, 1997) and arbitrary-sized segments (Hearst, 1994). Linguistic theories (Chafe, 1979; Longacre, 1979; Kieras, 1982) and work in information retrieval (Salton et al., 1993; Kaszkiel and Zobel, 1997) suggest a coherent text segment is represented by paragraphs. We argue that a paragraph can address multiple topics and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a</context>
</contexts>
<marker>Salton, Allan, Buckley, 1993</marker>
<rawString>Gerard Salton, James Allan, and Chris Buckley. 1993. Approaches to passage retrieval in full text information systems. In Proceedings of the 16th Annual International ACM/SIGIR Conference, pages 49-58, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A statistical model for domain-independent text segmentation.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL &apos;2001,</booktitle>
<location>Toulouse, France,</location>
<note>To appear.</note>
<contexts>
<context position="3474" citStr="Utiyama and Isahara, 2001" startWordPosition="523" endWordPosition="526"> categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic boundaries. Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multip</context>
<context position="22159" citStr="Utiyama and Isahara, 2001" startWordPosition="3806" endWordPosition="3809"> Experiment 4 — A comparative study T3,11 T3,5 T6,8 T9,11 T CWM1 9% 10% 7% 5% 8% U00b 10% 9% 7% 5% 9% CWM3 12% 10% 9% 8% 11% C99b 12% 11% 9% 9% 11% U00 12% 9% 10% 11% 11% C99 13% 17% 10% 10% 12% CWM2 14% 10% 11% 12% 13% C99b,_, 23% 19% 21% 20% 22% Table 5: Error rate: a comparative study. Table 5 presents a summary of experiment results. C99 and C99b are the algorithms described in (Choi, 2000a). C99b,, is the same as C99b except ranking has been disabled. The 11% difference between the two shows ranking is crucial to the cosine metric. U00 and U00b are the word frequency methods proposed in (Utiyama and Isahara, 2001). CWM is the new method described in this paper. All versions of the algorithm use a LSA space that was trained on paragraphs. CWM1 is identical to C99b except the stemming algorithm has been disabled and it uses A500 to measure similarity. The results show it is more accurate than previous methods. CWM2 is the same algorithm but ranking has been disabled. The 5% difference between this and CWM1 implies ranking does improve accuracy. Finally, CWM3 is a variant of CWM2 which uses A100 to measure similarity. The 11% difference between this and C99b,_, shows LSA is more accurate than the cosine m</context>
</contexts>
<marker>Utiyama, Isahara, 2001</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2001. A statistical model for domain-independent text segmentation. In Proceedings of ACL &apos;2001, Toulouse, France, July. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
</authors>
<date>1979</date>
<journal>Information Retrieval. Buttersworth.</journal>
<marker>van Rijsbergen, 1979</marker>
<rawString>C. J. van Rijsbergen. 1979. Information Retrieval. Buttersworth.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wiemer-Hastings</author>
<author>K Wiemer-Hastings</author>
<author>A Graesser</author>
</authors>
<title>Improving an intelligent tutor&apos;s comprehension of students with Latent Semantic Analysis.</title>
<date>1999</date>
<booktitle>Artificial Intelligence in Education,</booktitle>
<pages>535--542</pages>
<editor>In S. Lajoie and M. Vivet, editors,</editor>
<publisher>IOS Press.</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="8902" citStr="Wiemer-Hastings et al., 1999" startWordPosition="1434" endWordPosition="1437">on approach to query expansion. The method is similar to LCA in that the &amp;quot;meaning&amp;quot; of a word w is represented by its relation to other words. The primary distinction is, LSA applies principle components analysis to a word similarity matrix to identify the best features for distinguishing dissimilar words. Like LCA, the meaning of a text is computed as the sum of the word feature vectors. Text similarity is measured by the cosine of the corresponding feature vectors. LSA has been shown to match human similarity judgements on a wide range of tasks (Landauer and Dumais, 1997; Wolfe et al., 1998; Wiemer-Hastings et al., 1999, for example). 3.2.1 Training LSA LSA is trained on a set of texts A = Y1, ..., with vocabulary twi, turd-. Anxm matrix A is calculated, in which, A,i is the number of times to, occurs in Si. The values are scaled according to a general form of inverse document frequency, Bii = Aij X Ibk E {1,...,m} : Ak &gt;01 Singular value decomposition, or SVD (Golub and van Loan, 1989) is then applied to yield B = UEVT, where XT denotes the transposed matrix of X. The columns of U and V are the eigenvectors of BBT and BTB, respectively. The diagonal values of E are the corresponding singular values, i.e. th</context>
</contexts>
<marker>Wiemer-Hastings, Wiemer-Hastings, Graesser, 1999</marker>
<rawString>P. Wiemer-Hastings, K. Wiemer-Hastings, and A. Graesser. 1999. Improving an intelligent tutor&apos;s comprehension of students with Latent Semantic Analysis. In S. Lajoie and M. Vivet, editors, Artificial Intelligence in Education, pages 535-542, Amsterdam. IOS Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wolfe</author>
<author>M E Schreiner</author>
<author>B Rehder</author>
<author>D Laham</author>
<author>P W Foltz</author>
<author>W Kintsch</author>
<author>T K Landauer</author>
</authors>
<title>Learning from text: Matching readers and texts by Latent Semantic Analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<pages>25--309</pages>
<contexts>
<context position="8872" citStr="Wolfe et al., 1998" startWordPosition="1430" endWordPosition="1433">SA is a classification approach to query expansion. The method is similar to LCA in that the &amp;quot;meaning&amp;quot; of a word w is represented by its relation to other words. The primary distinction is, LSA applies principle components analysis to a word similarity matrix to identify the best features for distinguishing dissimilar words. Like LCA, the meaning of a text is computed as the sum of the word feature vectors. Text similarity is measured by the cosine of the corresponding feature vectors. LSA has been shown to match human similarity judgements on a wide range of tasks (Landauer and Dumais, 1997; Wolfe et al., 1998; Wiemer-Hastings et al., 1999, for example). 3.2.1 Training LSA LSA is trained on a set of texts A = Y1, ..., with vocabulary twi, turd-. Anxm matrix A is calculated, in which, A,i is the number of times to, occurs in Si. The values are scaled according to a general form of inverse document frequency, Bii = Aij X Ibk E {1,...,m} : Ak &gt;01 Singular value decomposition, or SVD (Golub and van Loan, 1989) is then applied to yield B = UEVT, where XT denotes the transposed matrix of X. The columns of U and V are the eigenvectors of BBT and BTB, respectively. The diagonal values of E are the correspo</context>
</contexts>
<marker>Wolfe, Schreiner, Rehder, Laham, Foltz, Kintsch, Landauer, 1998</marker>
<rawString>M. Wolfe, M. E. Schreiner, B. Rehder, D. Laham, P. W. Foltz, W. Kintsch, and T. K. Landauer. 1998. Learning from text: Matching readers and texts by Latent Semantic Analysis. Discourse Processes, 25:309-336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxi Xu</author>
<author>Bruce W Croft</author>
</authors>
<title>Query expansion using local and global document analysis.</title>
<date>1996</date>
<booktitle>In Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>4--11</pages>
<location>Zurich, Switzerland,</location>
<contexts>
<context position="7662" citStr="Xu and Croft (1996)" startWordPosition="1220" endWordPosition="1223">alysis offers a better solution to the term matching problem. 3.2 Latent semantic analysis LSA (Deerwester et al., 1990) stems from work in information retrieval, where the main difficulty is formulating a similarity metric that associates a user query with the relevant documents in a database. The basic keyword search approach retrieves all documents which contain some or all of the query terms. This is inaccurate since the same concept may be described using different terms. To circumvent this, Jing and Croft (1994) developed an association thesaurus for matching semantically related words. Xu and Croft (1996) offered a trainable method call local context analysis (LCA) which replaces each query term with frequently cooccurring words. Roughly speaking, LCA computes a word co-occurrence matrix C for a training corpus. A threshold is then applied such that large values in C are replaced by 1 and other values become 0. Each row C, can be considered as a feature vector for word i. The meaning of a text is approximated by the sum of the word feature vectors. Similarity between two texts is estimated by the distance between the corresponding feature vectors (Ponte and Croft, 1997, for details). LSA is a </context>
</contexts>
<marker>Xu, Croft, 1996</marker>
<rawString>Jinxi Xu and Bruce W. Croft. 1996. Query expansion using local and global document analysis. In Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 4-11, Zurich, Switzerland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaakov Yaari</author>
</authors>
<title>Segmentation of expository texts by hierarchical agglomerative clustering.</title>
<date>1997</date>
<booktitle>In Proceedings of RANLP &apos;97.</booktitle>
<contexts>
<context position="1114" citStr="Yaari, 1997" startWordPosition="157" endWordPosition="158"> at least as accurate as state-of-the-art methods (Utiyama and Isahara, 2001; Choi, 2000a). Inter-sentence similarity is estimated by latent semantic analysis (LSA). Boundary locations are discovered by divisive clustering. Test results show LSA is a more accurate similarity measure than the cosine metric (van Rijsbergen, 1979). 1 Introduction The aim of linear text segmentation is to partition a document into blocks, such that each segment is coherent and consecutive segments are about different topics. This procedure is useful in information retrieval (Hearst and Plaunt, 1993; Hearst, 1994; Yaari, 1997; Reynar, 1999), summarisation (Reynar, 1998), text understanding, anaphora resolution (Kozima, 1993), language modelling (Morris and Hirst, 1991; Beeferman et al., 1997) and text navigation (Choi, 2000b). This paper presents a new algorithm for segmenting written text. The method builds on previous work by Choi (2000a). The primary distinction is the use of latent semantic analysis (LSA) in formulating the similarity matrix. We discovered that (1) LSA is a more accurate measure of similarity than the cosine metric, (2) stemming does not always improve segmentation accuracy and (3) ranking is </context>
<context position="3168" citStr="Yaari, 1997" startWordPosition="477" endWordPosition="478"> topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora, syntactic features, language models and lexical cohesion metrics to detect topic </context>
<context position="4601" citStr="Yaari, 1997" startWordPosition="695" endWordPosition="696"> 1997; Reynar, 1998). The aim is to improve segmentation accuracy by combining multiple indicators of topic shift. These methods are typically applied in topic detection and tracking (Allan et al., 1998) to segment transcribed text and broadcast news stories. 2.3 Clustering Topic boundaries are discovered by merging consecutive elementary blocks that are about the same topic. Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama and Isahara, 2001), agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994; Choi, 2000a) to determine the optimal segmentation. The main difficulty in clustering is automatic termination, i.e. determining the number of topic boundaries in a document. 3 A new method The input to our algorithm is a list of tokenised sentences S = {81,..,8}. Content words are identified by removing punctuation marks and stopwords from S. A term frequency vector f, is then constructed for each sentence i. fij denotes the number of times content word j occurs in s,. 3.1 Inter-sentence similarity in C99 The C99 algorithm (Choi, 2000a) uses the cosine </context>
</contexts>
<marker>Yaari, 1997</marker>
<rawString>Yaakov Yaari. 1997. Segmentation of expository texts by hierarchical agglomerative clustering. In Proceedings of RANLP &apos;97. Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilbert Youmans</author>
</authors>
<title>A new tool for discourse analysis: The vocabularymanagement profile. Language,</title>
<date>1991</date>
<pages>763--789</pages>
<contexts>
<context position="3086" citStr="Youmans, 1991" startWordPosition="465" endWordPosition="466">multiple topics and is motivated by content, writing style and presentation. Thus, a topic segment is a collection of sentences. This view is supported by previous work in text segmentation (Ponte and Croft, 1997; Choi, 2000a). 2.2 Similarity metric A similarity metric estimates the likelihood of two segments describing the same topic. Existing methods fall into one of two categories. Lexical cohesion methods stem from the work of Halliday and Hasan (1976), in which a coherent topic segment is believed to contain parts with similar vocabulary. Implementations of this use word stem repetition (Youmans, 1991; Reynar, 1994; Ponte and Croft, 1997), context vectors (Hearst, 1994; Yaari, 1997; Kaufmann, 1999; Eichmann et al., 1999; Choi, 2000a), entity repetition (Kan et al., 1998), thesaurus relations (Morris and Hirst, 1991), spreading activation over dictionary (Kozima, 1993), a word distance model (Beeferman et al., 1997) or a word frequency model (Reynar, 1999; Utiyama and Isahara, 2001) to detect cohesion. These methods are typically applied in information retrieval (Hearst, 1994; Reynar, 1998) to segment written text. Multi-source methods use cue phrases, prosodic features, ellipsis, anaphora,</context>
</contexts>
<marker>Youmans, 1991</marker>
<rawString>Gilbert Youmans. 1991. A new tool for discourse analysis: The vocabularymanagement profile. Language, pages 763-789.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>