<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.054911">
<bodyText confidence="0.999731705882353">
mains: literary, computer science, medicine and
finance. Considering plenty of abbreviations,
numeric and other non-Chinese strings, our
segmentation system adopted a method combin-
ing character-based and subsequence-based tag-
ging, and took CRFs as sequence tagging model.
CRFs is a kind of conditional probability model
for sequence tagging presented by Lafferty et al.
in 2001(Lafferty J, et al., 2001). In our experi-
ment, the CRF++0.53 toolkit1 is used. CRF++
is a simple, customizable, and open source im-
plementation of CRFs for segmenting sequential
data. This paper described our system partici-
pating CIPS-SIGHAN 2010 and presented our
word-position tag set and feature template set
and their change in open tracks. Finally, we re-
port the results of our evaluation.
</bodyText>
<sectionHeader confidence="0.902309666666667" genericHeader="abstract">
2 Combining character-based and subse-
quence-based tagging for Chinese word
segmentation
</sectionHeader>
<bodyText confidence="0.999739611111111">
In character-based tagging approach to Chinese
word segmentation, it tags the word-position of
non-Chinese characters, such as punctuation,
letter words and numeric, just like what to do
with Chinese characters. This method works
well when there is a small quantity of these
characters. But plenty of these characters will
cut down the segmentation performance,
especially some abbreviation and programming
statement in computer science domain.
Considering this, we used a method combining
character-based and subsequence-based tagging
that is to take an English word or programming
statement as a subsequence to tag its word-
position. The correct tag for one-character word
is S.
M(Middle of word), E(End of word) and S(one-
character word).
</bodyText>
<subsectionHeader confidence="0.998825">
2.2 Feature templates
</subsectionHeader>
<bodyText confidence="0.999601515151515">
To define the relationship of some specific
language components or information in context
and some being forecasted things is the main
function of feature template. It is generally
considered that feature template is abstracted
from a group of context features on same
attributes.
In CRF++0.53 toolkit, there are two kind of
templates: Unigram template and Bigram tem-
plate. In word-position tagging Chinese seg-
mentation, available features are rather limited.
The main feature needed to take into account is
character feature, which includes current char-
acter, previous and next character. Jiang, Wang
and Guan (2007) abstracted the character fea-
tures into six templates according different dis-
tances from current character. They are Uni-
gram templates. The type and meaning of these
templates are presented in table 1. When train-
ing with CRFs model, these templates will be
extended to thousands of features and every fea-
ture has a group of corresponding feature func-
tions. All these functions are very important to
CRFs model learning. Seen from table 1, Bi-
gram feature has only one template: T-1T0 which
describes the word-position transfer feature of
two adjacent characters or subsequences. This
feature extends limited features in training.
Take four-WORD-POSITION-tag for instance,
it can be extended into sixteen features. In our
tracks, open or closed one, the seven templates
in table 1: C-1, C0, C1, C-1C0, C0C1, C-1C1, T-1T0
are used.
</bodyText>
<tableCaption confidence="0.809593">
Table 1 List of feature templates
</tableCaption>
<bodyText confidence="0.618284666666667">
Type of
template
Unigram
</bodyText>
<subsectionHeader confidence="0.993457">
2.1 Word-position tag set
</subsectionHeader>
<bodyText confidence="0.999578444444445">
In the closed track of traditional Chinese and
simplified Chinese, four word-position tag set is
used: B (Beginning of word), M(Middle of
word), E(End of word) and S(one-character
word). The tag set is also used in open tracks of
traditional Chinese. And we used six word-
position tag set for open tracks of simplified
Chinese: B(Beginning of word), B2(2nd
character of word), B3(3rd character of word)
</bodyText>
<table confidence="0.681099055555556">
template Meaning of template
C-1 previous character
C0 current character
C1 next character
String of current character and
previous one
String of current character and
next one
String of previous and next
character
C-1C0
C0C1
C-1C1
Word-position transfer feature
Bigram T-1T0
of two adjacent character
1 Download from this website:
http://crfpp.sourceforge.net/
</table>
<sectionHeader confidence="0.922808" genericHeader="related work">
3 Experiments and results
</sectionHeader>
<subsectionHeader confidence="0.996677">
3.1 Data set
</subsectionHeader>
<bodyText confidence="0.999423666666667">
Our training and test corpuses are gained from
evaluation conference. The training and test
corpuses of simplified Chinese are offered by
ICT and PKU, while traditional Chinese by
CityU. These corpuses involved in four domains:
literary(A), computer science(B), medicine(C),
finance(D). In addition, we also use the
CityU2005 training corpuses which gained from
the Bakeoff2005 for open track.
</bodyText>
<subsectionHeader confidence="0.993336">
3.2 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.999327">
Five evaluation metrics: precision(P), recall(R),
f-measue(F1), out-of-vocabulary words recall
rate (OOV RR) and In-vocabulary words recall
rate (IV RR) are used in our evaluation experi-
ments.
</bodyText>
<subsectionHeader confidence="0.991882">
3.3 Experiments and results
</subsectionHeader>
<bodyText confidence="0.977179578947368">
We adopted combining character-based and
subsequence-based tagging for Chinese word
segmentation, and conducted closed track ex-
periments on these corpuses. Four word-
position tag set(B, M, E, S) and seven tem-
plates(C-1, C0, C1, C-1C0, C0C1, C-1C1, T-1T0) are
adopted in closed tracks of simplified and tradi-
tional Chinese. Our results of the closed tracks
are described in Table 2.
In our open tracks of simplified Chinese, we
used six word-position tag set: B, B2, B3, M, E,
S and seven templates same with closed tracks.
Tag set and templates used in open tracks of
traditional Chinese are same with closed tracks,
too. In open tracks of traditional Chinese, we
trained the combination of CityU2005 and cor-
pus from this conference with CRFs model. The
results of open tracks are shown in Table 3.
Talbe 2 Our results of closed tracks
</bodyText>
<table confidence="0.99940747826087">
corpuses domains R P F1 OOV RR IV RR
Literature(A) 0.908 0.918 0.913 0.556 0.935
Computer science(B) 0.89 0.908 0.899 0.592 0.943
simplified
Medicine(C) 0.902 0.907 0.904 0.633 0.935
Finance(D) 0.925 0.938 0.931 0.664 0.95
Literature(A) 0.888 0.905 0.896 0.728 0.904
Computer(B) 0.908 0.931 0.919 0.684 0.931
traditional
Medicine(C) 0.905 0.924 0.914 0.725 0.919
Finance(D) 0.891 0.912 0.901 0.676 0.907
Table 3 Our results of open tracks
corpuses domains R P F1 OOV RR IV RR
Literature(A) 0.908 0.916 0.912 0.535 0.936
Computer science(B) 0.893 0.908 0.9 0.607 0.944
simplified
Medicine(C) 0.904 0.906 0.905 0.635 0.937
Finance(D) 0.925 0.937 0.931 0.669 0.95
Literature(A) 0.905 0.9 0.902 0.775 0.918
Computer(B) 0.911 0.924 0.918 0.698 0.933
traditional
Medicine(C) 0.903 0.903 0.903 0.729 0.917
Finance(D) 0.903 0.916 0.91 0.721 0.916
</table>
<sectionHeader confidence="0.997958" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999185">
As a fundamental task in Chinese information
processing, Chinese segmentation gained more
eyes in recent years and character-based tag-
ging becomes the main segmentation technol-
ogy. This paper describes our Chinese word
segmentation system for CIPS-SIGHAN 2010.
Then we present our word-position tag set and
feature templates used in closed tracks and
change of these parameters in open tracks. Fi-
nally, we report the results of the evaluation.
</bodyText>
<sectionHeader confidence="0.995636" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99987">
We would like to thank the anonymous review-
ers for their helpful comments and suggestions.
</bodyText>
<sectionHeader confidence="0.996355" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999336771428571">
Huang Changning, Zhao Hai. 2007. Chinese word
segmentation: A decade review. Journal of Chi-
nese Information Processing, 2007, 21(3):8-19.
Huang Changning, Zhao Hai. 2006. Character-
based tagging: A new method for Chinese word
segmentation. In Proceedings of Chinese Infor-
mation Processing Society 25 Annual Conference.
Beijing, China: Tsinghua University Press,
2006:53-63.
Jiang Wei, Wang Xiaolong, Guan Yi. 2007. Re-
search on Chinese Lexical Analysis System by
Fusing Multiple Knowledge Sources. Chinese
Journal of Computers, 2007, 30(1):137-145.
Liu Qun, Zhang Huaping, Yu Hongkui. 2004. Chi-
nese lexical analysis using cascaded hidden
Markov model. Journal of Computer Research
and Development, 2004, 41(8):1421-1429.
Lafferty J, Pereira F, McCallum A. 2001. Condi-
tional random fields: probabilistic models for
segmenting and labeling sequence data. In Pro-
ceedings of 18th International Conference on
Machine Learning, 2001:282-289.
Song Yan, Cai Dongfeng, Zhang Guiping. 2009.
Approach to Chinese word segmentation based
on character-word joint decoding. Journal of
Software, 2009,20(9):2366-2375.
Xue N W, Converse S P. 2002. Combining classifi-
ers for Chinese word segmentation. In Proceed-
ings of the First SIGHAN Workshop on Chinese
Language Processing. Taipei , Taiwan, China:
AS Press, 2002: 20-27.
Zhao Hai, Jie Chunyu. 2007. Effective subsequence-
based tagging for Chinese word segmentation.
Journal of Chinese Information Processing,
2007,21(5):8-13.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000011">
<abstract confidence="0.992143828358209">Considering plenty of abbreviations, numeric and other non-Chinese strings, our segmentation system adopted a method combining character-based and subsequence-based tagging, and took CRFs as sequence tagging model. CRFs is a kind of conditional probability model for sequence tagging presented by Lafferty et al. in 2001(Lafferty J, et al., 2001). In our experithe CRF++0.53 is used. CRF++ is a simple, customizable, and open source implementation of CRFs for segmenting sequential data. This paper described our system participating CIPS-SIGHAN 2010 and presented our word-position tag set and feature template set and their change in open tracks. Finally, we report the results of our evaluation. 2 Combining character-based and subsequence-based tagging for Chinese word segmentation In character-based tagging approach to Chinese word segmentation, it tags the word-position of as punctuation, letter words and numeric, just like what to do with Chinese characters. This method works well when there is a small quantity of these characters. But plenty of these characters will cut down the segmentation performance, especially some abbreviation and programming statement in computer science domain. Considering this, we used a method combining character-based and subsequence-based tagging that is to take an English word or programming statement as a subsequence to tag its wordposition. The correct tag for one-character word is S. M(Middle of word), E(End of word) and S(onecharacter word). 2.2 Feature templates To define the relationship of some specific language components or information in context and some being forecasted things is the main function of feature template. It is generally considered that feature template is abstracted from a group of context features on same attributes. In CRF++0.53 toolkit, there are two kind of templates: Unigram template and Bigram template. In word-position tagging Chinese segmentation, available features are rather limited. The main feature needed to take into account is character feature, which includes current character, previous and next character. Jiang, Wang and Guan (2007) abstracted the character features into six templates according different distances from current character. They are Unigram templates. The type and meaning of these templates are presented in table 1. When training with CRFs model, these templates will be extended to thousands of features and every feature has a group of corresponding feature functions. All these functions are very important to CRFs model learning. Seen from table 1, Bifeature has only one template: which describes the word-position transfer feature of two adjacent characters or subsequences. This feature extends limited features in training. Take four-WORD-POSITION-tag for instance, it can be extended into sixteen features. In our tracks, open or closed one, the seven templates table 1: are used. Table 1 List of feature templates Type of template Unigram 2.1 Word-position tag set In the closed track of traditional Chinese and simplified Chinese, four word-position tag set is used: B (Beginning of word), M(Middle of word), E(End of word) and S(one-character word). The tag set is also used in open tracks of traditional Chinese. And we used six wordposition tag set for open tracks of simplified Chinese: B(Beginning of word), B2(2nd character of word), B3(3rd character of word) template Meaning of template character character character String of current character and previous one String of current character and next one String of previous and next character Word-position transfer feature 1Download from this website: http://crfpp.sourceforge.net/ 3 Experiments and results 3.1 Data set Our training and test corpuses are gained from evaluation conference. The training and test corpuses of simplified Chinese are offered by ICT and PKU, while traditional Chinese by CityU. These corpuses involved in four domains: In addition, we also use the CityU2005 training corpuses which gained from the Bakeoff2005 for open track. 3.2 Evaluation metrics evaluation metrics: out-of-vocabulary words recall and In-vocabulary words recall are used in our evaluation experiments. 3.3 Experiments and results We adopted combining character-based and subsequence-based tagging for Chinese word segmentation, and conducted closed track experiments on these corpuses. Four wordposition tag set(B, M, E, S) and seven temare adopted in closed tracks of simplified and traditional Chinese. Our results of the closed tracks are described in Table 2. In our open tracks of simplified Chinese, we used six word-position tag set: B, B2, B3, M, E, S and seven templates same with closed tracks. Tag set and templates used in open tracks of traditional Chinese are same with closed tracks, too. In open tracks of traditional Chinese, we trained the combination of CityU2005 and corpus from this conference with CRFs model. The results of open tracks are shown in Table 3. Talbe 2 Our results of closed tracks corpuses domains R P F1 OOV RR IV RR</abstract>
<note confidence="0.476920791666667">Literature(A) 0.908 0.918 0.913 0.556 0.935 Computer science(B) 0.89 0.908 0.899 0.592 0.943 simplified Medicine(C) 0.902 0.907 0.904 0.633 0.935 Finance(D) 0.925 0.938 0.931 0.664 0.95 Literature(A) 0.888 0.905 0.896 0.728 0.904 Computer(B) 0.908 0.931 0.919 0.684 0.931 traditional Medicine(C) 0.905 0.924 0.914 0.725 0.919 Finance(D) 0.891 0.912 0.901 0.676 0.907 Table 3 Our results of open tracks corpuses domains R P F1 OOV RR IV RR Literature(A) 0.908 0.916 0.912 0.535 0.936 Computer science(B) 0.893 0.908 0.9 0.607 0.944 simplified Medicine(C) 0.904 0.906 0.905 0.635 0.937 Finance(D) 0.925 0.937 0.931 0.669 0.95 Literature(A) 0.905 0.9 0.902 0.775 0.918 Computer(B) 0.911 0.924 0.918 0.698 0.933 traditional Medicine(C) 0.903 0.903 0.903 0.729 0.917 Finance(D) 0.903 0.916 0.91 0.721 0.916 4 Conclusion As a fundamental task in Chinese information</note>
<abstract confidence="0.995297583333333">processing, Chinese segmentation gained more eyes in recent years and character-based tagging becomes the main segmentation technology. This paper describes our Chinese word segmentation system for CIPS-SIGHAN 2010. Then we present our word-position tag set and feature templates used in closed tracks and change of these parameters in open tracks. Finally, we report the results of the evaluation. Acknowledgments We would like to thank the anonymous reviewers for their helpful comments and suggestions.</abstract>
<note confidence="0.971702333333333">References Changning, Zhao Hai. 2007. word segmentation: A decade review. Journal of Chi- Information Processing, 21(3):8-19. Changning, Zhao Hai. 2006. Characterbased tagging: A new method for Chinese word</note>
<affiliation confidence="0.683429">of Chinese Infor- Processing Society 25 Annual Beijing, China: Tsinghua University</affiliation>
<address confidence="0.615815">2006:53-63. Wei, Wang Xiaolong, Guan Yi. 2007. Re-</address>
<note confidence="0.6790138">search on Chinese Lexical Analysis System by Fusing Multiple Knowledge Sources. Chinese of Qun, Zhang Huaping, Yu Hongkui. 2004. Chinese lexical analysis using cascaded hidden Markov model. Journal of Computer Research 2004, 41(8):1421-1429. J, Pereira F, McCallum A. 2001. Conditional random fields: probabilistic models for segmenting and labeling sequence data. In Proceedings of 18th International Conference on 2001:282-289. Song Yan, Cai Dongfeng, Zhang Guiping. 2009. Approach to Chinese word segmentation based on character-word joint decoding. Journal of 2009,20(9):2366-2375. N W, Converse S P. 2002. classifiers for Chinese word segmentation. In Proceedings of the First SIGHAN Workshop on Chinese Taipei , Taiwan, China: Press, Hai, Jie Chunyu. 2007. subsequencebased tagging for Chinese word segmentation. of Chinese Information 2007,21(5):8-13.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Huang Changning</author>
<author>Zhao Hai</author>
</authors>
<title>Chinese word segmentation: A decade review.</title>
<date>2007</date>
<journal>Journal of Chinese Information Processing,</journal>
<pages>21--3</pages>
<marker>Changning, Hai, 2007</marker>
<rawString>Huang Changning, Zhao Hai. 2007. Chinese word segmentation: A decade review. Journal of Chinese Information Processing, 2007, 21(3):8-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huang Changning</author>
<author>Zhao Hai</author>
</authors>
<title>Characterbased tagging: A new method for Chinese word segmentation.</title>
<date>2006</date>
<booktitle>In Proceedings of Chinese Information Processing Society 25 Annual Conference.</booktitle>
<marker>Changning, Hai, 2006</marker>
<rawString>Huang Changning, Zhao Hai. 2006. Characterbased tagging: A new method for Chinese word segmentation. In Proceedings of Chinese Information Processing Society 25 Annual Conference.</rawString>
</citation>
<citation valid="false">
<authors>
<author>China Beijing</author>
</authors>
<pages>2006--53</pages>
<publisher>Tsinghua University Press,</publisher>
<marker>Beijing, </marker>
<rawString>Beijing, China: Tsinghua University Press, 2006:53-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Wei</author>
<author>Wang Xiaolong</author>
<author>Guan Yi</author>
</authors>
<title>Research on Chinese Lexical Analysis System by Fusing Multiple Knowledge Sources.</title>
<date>2007</date>
<journal>Chinese Journal of Computers,</journal>
<pages>30--1</pages>
<marker>Wei, Xiaolong, Yi, 2007</marker>
<rawString>Jiang Wei, Wang Xiaolong, Guan Yi. 2007. Research on Chinese Lexical Analysis System by Fusing Multiple Knowledge Sources. Chinese Journal of Computers, 2007, 30(1):137-145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liu Qun</author>
</authors>
<title>Zhang Huaping, Yu Hongkui.</title>
<date>2004</date>
<journal>Journal of Computer Research</journal>
<pages>41--8</pages>
<marker>Qun, 2004</marker>
<rawString>Liu Qun, Zhang Huaping, Yu Hongkui. 2004. Chinese lexical analysis using cascaded hidden Markov model. Journal of Computer Research and Development, 2004, 41(8):1421-1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>F Pereira</author>
<author>A McCallum</author>
</authors>
<title>Conditional random fields: probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of 18th International Conference on Machine Learning,</booktitle>
<pages>2001--282</pages>
<marker>Lafferty, Pereira, McCallum, 2001</marker>
<rawString>Lafferty J, Pereira F, McCallum A. 2001. Conditional random fields: probabilistic models for segmenting and labeling sequence data. In Proceedings of 18th International Conference on Machine Learning, 2001:282-289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Yan</author>
</authors>
<title>Cai Dongfeng, Zhang Guiping.</title>
<date>2009</date>
<journal>Journal of Software,</journal>
<pages>2009--20</pages>
<marker>Yan, 2009</marker>
<rawString>Song Yan, Cai Dongfeng, Zhang Guiping. 2009. Approach to Chinese word segmentation based on character-word joint decoding. Journal of Software, 2009,20(9):2366-2375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N W Xue</author>
<author>S P Converse</author>
</authors>
<title>Combining classifiers for Chinese word segmentation.</title>
<date>2002</date>
<booktitle>In Proceedings of the First SIGHAN Workshop on Chinese Language Processing. Taipei ,</booktitle>
<publisher>AS Press,</publisher>
<location>Taiwan, China:</location>
<marker>Xue, Converse, 2002</marker>
<rawString>Xue N W, Converse S P. 2002. Combining classifiers for Chinese word segmentation. In Proceedings of the First SIGHAN Workshop on Chinese Language Processing. Taipei , Taiwan, China: AS Press, 2002: 20-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhao Hai</author>
<author>Jie Chunyu</author>
</authors>
<title>Effective subsequencebased tagging for Chinese word segmentation.</title>
<date>2007</date>
<journal>Journal of Chinese Information Processing,</journal>
<pages>2007--21</pages>
<marker>Hai, Chunyu, 2007</marker>
<rawString>Zhao Hai, Jie Chunyu. 2007. Effective subsequencebased tagging for Chinese word segmentation. Journal of Chinese Information Processing, 2007,21(5):8-13.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>