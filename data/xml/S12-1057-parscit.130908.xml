<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000706">
<title confidence="0.9106255">
MIXCD: System Description for Evaluating Chinese Word Similarity at
SemEval-2012
</title>
<author confidence="0.950465">
Yingjie Zhang Bin Li Xinyu Dai Jiajun Chen
</author>
<affiliation confidence="0.972122">
Nanjing University Nanjing University Nanjing University Nanjing University
</affiliation>
<address confidence="0.833539">
22 Hankou Road Nanjing Normal University 22 Hankou Road 22 Hankou Road
</address>
<note confidence="0.59484">
Jiangsu P. R. China 122 Ninghai Road Jiangsu P. R. China Jiangsu P. R. China
jillzhyj@139.c Jiangsu P. R. China dxy@nju.edu.cn cjj@nju.eud.cn
om gothere@126.com
</note>
<sectionHeader confidence="0.996072" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.985963857142857">
This document describes three systems calcu-
lating semantic similarity between two Chi-
nese words. One is based on Machine
Readable Dictionaries and the others utilize
both MRDs and Corpus. These systems are
performed on SemEval-2012 Task 4: Evaluat-
ing Chinese Word Similarity.
</bodyText>
<sectionHeader confidence="0.999355" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999890769230769">
The characteristics of polysemy and synonymy that
exist in words of natural language have always
been a challenge in the fields of Natural Language
Processing (NLP) and Information Retrieval (IR).
In many cases, humans have little difficulty in de-
termining the intended meaning of an ambiguous
word, while it is extremely difficult to replicate
this process computationally. For many tasks in
psycholinguistics and NLP, a job is often decom-
posed to the requirement of resolving the semantic
similarity between words or concepts.
There are two ways to get the similarity between
two words. One is to utilize the machine readable
dictionary (MRD). The other is to use the corpus.
For the 4th task in SemEval-2012 we are re-
quired to evaluate the semantic similarity of Chi-
nese word pairs. We consider 3 methods in this
study. One uses MRDs only and the other two use
both MRD and corpus. A post processing will be
done on the results of these methods to treat syno-
nyms.
In chapter 2 we introduce the previous works on
the evaluation of Semantic Similarity. Chapter 3
shows three methods used in this task. Chapter 4
reveals the results of these methods. And conclu-
sion is stated in chapter 5.
</bodyText>
<sectionHeader confidence="0.999943" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999868272727273">
For words may have more than one sense, similari-
ty between two words can be determined by the
best score among all the concept pairs which their
various senses belong to.
Before constructed dictionary is built, Lesk
similarity (Lesk, 1986) which is proposed as a so-
lution for word sense disambiguation is often used
to evaluating the similarity between two concepts.
This method calculates the overlap between the
corresponding definitions as provided by a diction-
ary.
</bodyText>
<equation confidence="0.534893">
( )  |( ) ( )|
</equation>
<bodyText confidence="0.964824214285714">
Since the availability of computational lexicons
such as WordNet, the taxonomy can be represented
as a hierarchical structure. Then we use the struc-
ture information to evaluate the semantic similarity.
In these methods, the hierarchical structure is often
seen as a tree and concepts as the nodes of the tree
while relations between two concepts as the edges.
(Resnik, 1995) determines the conceptual simi-
larity of two concepts by calculating the infor-
mation content (IC) of the least common subsumer
(LCS) of them.
( ) ( ( ))
where the IC of a concept can be quantified as
follow:
</bodyText>
<equation confidence="0.647503">
( ) ( )
</equation>
<page confidence="0.976427">
425
</page>
<note confidence="0.5235295">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 425–429,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.9984826">
This method do not consider the distance of two
concepts. Any two concepts have the same LCS
will have the same similarity even if the distances
between them are different. It is called node-based
method.
(Leacock and Chodorow, 1998) develops a simi-
larity measure based on the distance of two senses
and . They focus on hypernymy links and
scaled the path length by the overall depth of the
tree.
</bodyText>
<equation confidence="0.79922">
( ) ( )
</equation>
<bodyText confidence="0.789186">
(Wu and Palmer, 1994) combines the depth of
the LCS of two concepts into a similarity score.
</bodyText>
<equation confidence="0.999166">
( ) ( ) ( )
( ( ))
</equation>
<bodyText confidence="0.9698531875">
These approaches are regarded as edge-based
methods. They are more natural and direct to eval-
uating semantic similarity in taxonomy. But they
treat all nodes as the same and do not consider the
different information of different nodes.
(Jiang and Conrath, 1998) uses the information
content of concept instead of its depth. So both
node and edge information can be considered to
evaluate the similarity. It performs well in evaluat-
ing semantic similarity between two texts (Zhang
et al., 2008; Corley and Mihalcea, 2005; Pedersen,
2010).
( ) ( ) ( ) ( ( ))
SemCor is used in Jiang&apos;s work to get the fre-
quency of a word with a specific sense treated by
the Lagrange Smoothing.
</bodyText>
<sectionHeader confidence="0.996828" genericHeader="method">
3 Approaches
</sectionHeader>
<bodyText confidence="0.9999718">
For SemEval-2012 task 4, we use two MRDs and
one corpus as our knowledge resources. One MRD
is HIT IR-Lab Tongyici Cilin (Extended) (Cilin)
and the other is Chinese Concept Dictionary
(CCD). The corpus we used in our system is Peo-
ple&apos;s Daily. Three systems are proposed to evaluate
the semantic similarity between two Chinese words.
The first one utilizes both the MRDs called
MIXCC (Mixture of Cilin and CCD) and other two
named MIXCD1 (Mixture of Corpus and Diction-
ary) and MIXCD2 respectively combine the infor-
mation derived from both corpus and dictionary
into the similarity score. A post processing is done
to trim the similarity of words with the same mean-
ing.
</bodyText>
<subsectionHeader confidence="0.99923">
3.1 Knowledge Resources
</subsectionHeader>
<bodyText confidence="0.999575071428571">
HIT IR-Lab Tongyici Cilin (Extended) is built by
Harbin Institute of Technology which contained
77343 word items. Cilin is constructed as a tree
with five levels. With the increasing of the level,
word senses are more fine-grained. All word items
in Cilin are located at the fifth level. The larger
level the LCS of an item pair has, the closer their
concepts are.
Chinese Concept Dictionary (CCD) is a Chinese
WordNet produced by Peking University. Word
concepts in it are represented as Synsets and one-
one corresponding to WordNet 1.6. There are 4
types of hierarchical semantic relations in CCD as
follows:
</bodyText>
<listItem confidence="0.999677375">
• Synonym: the meanings of two words are
equivalence
• Antonym: two synsets contain the words
with opposite meaning
• Hypernym and Hyponym: two synsets
with the IS-A relation
• Holonym and Meronym: two synsets with
the IS-PART-OF relation
</listItem>
<bodyText confidence="0.999154230769231">
Additionally there is another type of semantic
relation such as Attribute in CCD This relation
type often happens between two words with differ-
ent part-of-speech. Even though it is not the hierar-
chical relation, this relation type can make two
words with different POS have a path between
them. In WordNet it is often shown as a Morpho-
logical transform between two words, while it may
happen on two different words with closed mean-
ing in CCD.
The corpus we use in our system is People&apos;s
Daily 2000 from January to June which has been
manually segmented.
</bodyText>
<subsectionHeader confidence="0.96358">
3.2 MIXCC
</subsectionHeader>
<bodyText confidence="0.999798714285714">
MIXCC utilizes both Cilin and CCD to evaluate
the semantic similarity of word pair. In this method
we get the rank in three steps.
First, we use Cilin to separate the list of word
pairs into five parts and sort them in descending
order of LCS&apos;s level. The word pairs having the
same level of LCS will be put in the same part.
</bodyText>
<page confidence="0.996264">
426
</page>
<bodyText confidence="0.99988275">
Second, for each part we compute the similarity
almost by Jiang and Conrath&apos;s method mentioned
in Section 2 above. Only Synonym and Hypernym-
Hyponym relations of CCD concepts are consid-
ered in this method. So CCD could be constructed
as a forest. We add a root node which combined
the forest into a tree to make sure that there is a
path between any two concepts.
</bodyText>
<equation confidence="0.8370585">
( ) ( ) ( )
( )
</equation>
<bodyText confidence="0.998527166666667">
and compose a word pair needed to cal-
culate semantic similarity between them. ( ) is
the Synset in CCD which contains ( ).
Because there is no sense-tagged corpus for
CCD, the frequency of every word in each concept
is always 1.
After ( ) of all word pairs in the
same part are calculated, we sort the scores in a
decreasing order again. Then we get five groups of
ranked word pairs.
At last the five groups are combined together as
the result shown in table 1.
</bodyText>
<subsectionHeader confidence="0.965142">
3.3 MIXCD
</subsectionHeader>
<bodyText confidence="0.999881581395349">
MIXCD combines the information of corpus and
MRDs to evaluate semantic similarity.
In this system we use trial data to learn a multiple
linear regression function. There are two classes of
features for this study which are derived from CCD
and People&apos;s Daily respectively. One class of fea-
ture is the mutual information of a word pair and
the other is the shortest path between two concepts
containing the words of which the similarity need-
ed to be evaluated.
We consider CCD as a large directed graph. The
nodes of the graph are Synsets and edges are the
semantic relations between two Synsets. All five
types of semantic relation showed in Section 3.1
will be used to build the graph.
For each word pair, the shortest path between
two Synsets which contain the words respectively
is found. Then the path is represented in two forms.
In one form we record the vector consisting of
the counts of every relation type in the path. The
system using this path&apos;s form is called MIXCD0.
For example the path between &amp;quot;心理学 (psy-
chology)&amp;quot; and &amp;quot;精神病学 (psychiatry)&amp;quot; is repre-
sented as (0, 0, 3, 2, 0). It means that &amp;quot;心理学&amp;quot; and
&amp;quot;精神病学&amp;quot; are not synonym and the shortest path
between them contained 3 IS-A relations and 2 IS-
PART-OF relations.
We suppose that the path&apos;s length is a significant
feature to measure the semantic similarity of a
word pair. So in the other form the length is added
into the vector as the first component. And the
counts of each relation are recorded in proportion
to the length. This form of path representation is
used in the submitted system called MIXCD. Then
the path between &amp;quot;心理学&amp;quot; and &amp;quot;精神病学&amp;quot; is rep-
resented as (5, 0, 0, 0.6, 0.4, 0).
In both forms, the Synonym feature will be 1 if
the length of the path is 0.
The mutual information of all word pairs is cal-
culated via the segmented People&apos;s Daily.
Last we use the result of multiple linear regres-
sion to forecast the similarity of other word pairs
and get the rank.
</bodyText>
<subsectionHeader confidence="0.97501">
3.4 Post Processing
</subsectionHeader>
<bodyText confidence="0.999981375">
The word pair with the same meaning may be con-
sisted of two same words or two different words
belong to the same concept. It is difficult for both
systems to separate one from the other. Therefore
we display a post processing on our systems to
make sure that the similarity between the same
words has a larger rank than two different words of
the same meaning.
</bodyText>
<sectionHeader confidence="0.998877" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999926714285714">
We perform our systems on trial data and then use
Kendall tau Rank Correlation (Kendall, 1995;
Wessa, 2012) to evaluate the results shown in Ta-
ble 1. The trial data contains 50 word pairs. The
similarity of each pair is scored by several experts
and the mean value is regarded as the standard an-
swer to get the manual ranking.
</bodyText>
<table confidence="0.994353">
Method Kendall tau 2-sided p value
MIXCC 0.273469 0.005208
MIXCD0 0.152653 0.119741
MIXCD 0.260408 0.007813
Manual(upper) 0.441633 6.27E-06
</table>
<tableCaption confidence="0.999884">
Table 1: Kendall tau Rank Correlation of systems on trial
</tableCaption>
<bodyText confidence="0.518828666666667">
From Table 1, we can see the tau value of MIX-
CD0 is 0.1526 and MIXCD is 0.2604. MIXCD
performed notably better than MIXCD0. It shows
</bodyText>
<page confidence="0.996807">
427
</page>
<bodyText confidence="0.998713027027027">
that path&apos;s length between two words is on an im-
portant position of measuring semantic similarity.
This feature does improve the similarity result. The
2-sided p value of MIXCD0 is 0.1197. It is much
larger than the value of MIXCD which is 0.0078.
So the ranking result of MIXCD0 is much more
occasional than result of MIXCD.
The tau value of MIXCC is 0.2735 and it is
much smaller than the manual ranking result which
is 0.4416 seen as the upper bound. It shows that the
similarity between two words in human&apos;s minds
dose not only depend on their hierarchical relation
represented in Dictionary. But the value is larger
than that of MIXCD. It seems that the mutual in-
formation derived from corpus which is expected
to improve the result reduces the correction of rank
result contrarily. There may be two reasons on it.
First, because of the use of trial data in MIXCD,
the result of similarity ranking strongly depended
on this data. The reliability of trial data&apos;s ranking
may influent the performance of our system. We
calculate the tau value between every manual and
the correct ranking. The least tau value is 0.4416
and the largest one is 0.8220 with a large disparity.
We use the Fleiss&apos; kappa value (Fleiss, 1971) to
evaluate the agreement of manual ranking and the
result is 0.1526 which showed the significant disa-
greement. This disagreement may make the regres-
sion result cannot show the relation between
features and score correctly. To reduce the disa-
greement&apos;s influence we calculate the mean of
manual similarity score omitting the maximum and
minimum ones and get a new standard rank (trial2).
Then we perform MIXCD on trail2 and show the
new result as MIXCD-2 in Form 2. MIXCC&apos;s re-
sult is also compared with trail2 shown as MIXCC-
2.
</bodyText>
<table confidence="0.9959285">
MIXCC-2 MIXCD-2 MIXCC MIXCD
Kendall tau 0.297959 0.265306 0.273469 0.260408
</table>
<tableCaption confidence="0.8544305">
Table 2: tau value on new standard (omit max/min manual
scores)
</tableCaption>
<bodyText confidence="0.999904111111111">
From Table 2 we can see the tau values of
MIXCC rose to 0.2980 and MIXCD to 0.2653. It
shows that omitting the maximum and minimum
manual scores can reduce some influence of the
disagreement of artificial scoring.
Second, the combination method of mutual in-
formation and semantic path in MRD may also
influent the performance of our system. The ranks
between MIXCD and MIXCC are also compared
and the tau value is 0.2065. It shows a low agree-
ment of semantic similarity measurements between
MRD and Corpus. The mutual information exerts a
large influence on the measure of similarity and
sometimes may bring the noise to the result mak-
ing it worse.
We also perform our systems on test data con-
taining 297 words pairs in the same form of trial
data and got the follow result:
</bodyText>
<table confidence="0.8927995">
Method Kendall tau
MIXCC 0.050
MIXCD0 -0.064
MIXCD 0.040
</table>
<tableCaption confidence="0.993316">
Table 3 tau values of the result of test data
</tableCaption>
<bodyText confidence="0.9997688">
The ranking on test data of our systems shows
an even worse result. Because of the low confi-
dence of trial data ranking, multiple linear regres-
sion function learning from the trial data performs
bad on other word pairs.
</bodyText>
<sectionHeader confidence="0.999352" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999537647058824">
In this paper we propose three methods to evaluate
the semantic similarity of Chinese word pairs. The
first one uses MRDs and the second one adds the
information derived from corpus. The third one
uses the same knowledge resources as the second
one but highlights the path length of the word pair.
The results of the systems show a large difference
and all have a low score. From the results we can
see the similarity showed in corpus is much differ-
ent from the one expressed in MRD. One reason of
the low score is that the manual rank given by the
task has a low agreement among them. We get a
new manual rank which reduces some influence of
disagreement by calculating the mean value of
scores omitting the maximum and minimum ones.
Comparing the result of our systems with the new
ranking, all of them get a higher tau value.
</bodyText>
<sectionHeader confidence="0.990944" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<reference confidence="0.742147166666667">
This paper is supported in part by National Natural
Science Fund of China under contract 61170181,
National Social Science Fund of China under con-
tract 10CYY021, State Key Lab. for Novel Soft-
ware Technology under contract KFKT2011B03,
Jiangsu PostDoc Fund under contract 1101065C.
</reference>
<page confidence="0.999185">
428
</page>
<sectionHeader confidence="0.995856" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999378333333334">
Mike E. Lesk, 1986. Automatic sense disambiguation
using machine readable dictionaries: How to tell a
pine cone from an ice cream cone. In Proceedings of
the SIGDOC Conference 1986, Toronto, June.
Philip Resnik, 1995. Using information content to eval-
uate semantic similarity. In Proceedings of the 14th
International Joint Conference on Artificial Intelli-
gence, Montreal, Canada.
Claudia Leacock and Martin Chodorow, 1998. Combin-
ing local context and WordNet sense similiarity for
word sense disambiguation. In WordNet, An Elec-
tronic Lexical Database. The MIT Press.
Zhibiao Wu and Martha Palmer, 1994. Verb semantics
and lexical selection. In Proceedings of the 32nd An-
nual Meeting of the Association for Computational
Linguistics, Las Cruces, New Mexico.
Jay J. Jiang and David W. Conrath, 1998. Semantic sim-
ilarity based on corpus statistics and lexical taxono-
my. In Proceedings of the International Conference
on Research in Computational Linguistics.
Ce Zhang , Yu-Jing Wang , Bin Cui , Gao Cong, 2008.
Semantic similarity based on compact concept ontol-
ogy. In Proceeding of the 17th international confer-
ence on World Wide Web, April 21-25, 2008, Beijing,
China
Courtney Corley , Rada Mihalcea, 2005. Measuring the
semantic similarity of texts. In Proceedings of the
ACL Workshop on Empirical Modeling of Semantic
Equivalence and Entailment, p.13-18, June 30-30,
2005, Ann Arbor, Michigan.
Ted Pedersen, 2010. Information content measures of
semantic similarity perform better without sense-
tagged text. In Human Language Technologies: The
2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, p.329-332, June 02-04, 2010, Los Angeles,
California.
M. G. Kendall, 1955. Rank Correlation Methods. New
York: Hafner Publishing Co.
P. Wessa, 2012. Free Statistics Software, Office for Re-
search Development and Education, version 1.1.23-
r7, URL http://www.wessa.net/
Jordan L. Fleiss, 1971. Measuring nominal scale agree-
ment among many raters. Psychological Bulletin, Vol.
76, No. 5 pp. 378–382.
</reference>
<page confidence="0.999241">
429
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.030920">
<title confidence="0.871786">MIXCD: System Description for Evaluating Chinese Word Similarity at</title>
<pubnum confidence="0.434346">SemEval-2012</pubnum>
<author confidence="0.930869">Yingjie Zhang Bin Li Xinyu Dai Jiajun Chen</author>
<affiliation confidence="0.999996">Nanjing University Nanjing University Nanjing University Nanjing University</affiliation>
<address confidence="0.797649">22 Hankou Road Nanjing Normal University 22 Hankou Road 22 Hankou Road Jiangsu P. R. China 122 Ninghai Road Jiangsu P. R. China Jiangsu P. R. China</address>
<abstract confidence="0.8094187">jillzhyj@139.c Jiangsu P. R. dxy@nju.edu.cn cjj@nju.eud.cn om gothere@126.com Abstract This document describes three systems calculating semantic similarity between two Chinese words. One is based on Machine Readable Dictionaries and the others utilize both MRDs and Corpus. These systems are performed on SemEval-2012 Task 4: Evaluating Chinese Word Similarity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>This paper is supported in part by National Natural Science Fund of China under contract 61170181,</title>
<booktitle>National Social Science Fund of China under contract 10CYY021, State Key Lab. for Novel Software Technology under contract KFKT2011B03, Jiangsu PostDoc Fund under contract 1101065C.</booktitle>
<marker></marker>
<rawString>This paper is supported in part by National Natural Science Fund of China under contract 61170181, National Social Science Fund of China under contract 10CYY021, State Key Lab. for Novel Software Technology under contract KFKT2011B03, Jiangsu PostDoc Fund under contract 1101065C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike E Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proceedings of the SIGDOC Conference</booktitle>
<location>Toronto,</location>
<contexts>
<context position="2176" citStr="Lesk, 1986" startWordPosition="352" endWordPosition="353">RDs only and the other two use both MRD and corpus. A post processing will be done on the results of these methods to treat synonyms. In chapter 2 we introduce the previous works on the evaluation of Semantic Similarity. Chapter 3 shows three methods used in this task. Chapter 4 reveals the results of these methods. And conclusion is stated in chapter 5. 2 Related Work For words may have more than one sense, similarity between two words can be determined by the best score among all the concept pairs which their various senses belong to. Before constructed dictionary is built, Lesk similarity (Lesk, 1986) which is proposed as a solution for word sense disambiguation is often used to evaluating the similarity between two concepts. This method calculates the overlap between the corresponding definitions as provided by a dictionary. ( ) |( ) ( )| Since the availability of computational lexicons such as WordNet, the taxonomy can be represented as a hierarchical structure. Then we use the structure information to evaluate the semantic similarity. In these methods, the hierarchical structure is often seen as a tree and concepts as the nodes of the tree while relations between two concepts as the edg</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Mike E. Lesk, 1986. Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In Proceedings of the SIGDOC Conference 1986, Toronto, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity.</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="2794" citStr="Resnik, 1995" startWordPosition="454" endWordPosition="455">h is proposed as a solution for word sense disambiguation is often used to evaluating the similarity between two concepts. This method calculates the overlap between the corresponding definitions as provided by a dictionary. ( ) |( ) ( )| Since the availability of computational lexicons such as WordNet, the taxonomy can be represented as a hierarchical structure. Then we use the structure information to evaluate the semantic similarity. In these methods, the hierarchical structure is often seen as a tree and concepts as the nodes of the tree while relations between two concepts as the edges. (Resnik, 1995) determines the conceptual similarity of two concepts by calculating the information content (IC) of the least common subsumer (LCS) of them. ( ) ( ( )) where the IC of a concept can be quantified as follow: ( ) ( ) 425 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 425–429, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics This method do not consider the distance of two concepts. Any two concepts have the same LCS will have the same similarity even if the distances between them are different. It is called node-based method. (Leaco</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Philip Resnik, 1995. Using information content to evaluate semantic similarity. In Proceedings of the 14th International Joint Conference on Artificial Intelligence, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Martin Chodorow</author>
</authors>
<title>Combining local context and WordNet sense similiarity for word sense disambiguation. In WordNet, An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="3416" citStr="Leacock and Chodorow, 1998" startWordPosition="556" endWordPosition="559">1995) determines the conceptual similarity of two concepts by calculating the information content (IC) of the least common subsumer (LCS) of them. ( ) ( ( )) where the IC of a concept can be quantified as follow: ( ) ( ) 425 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 425–429, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics This method do not consider the distance of two concepts. Any two concepts have the same LCS will have the same similarity even if the distances between them are different. It is called node-based method. (Leacock and Chodorow, 1998) develops a similarity measure based on the distance of two senses and . They focus on hypernymy links and scaled the path length by the overall depth of the tree. ( ) ( ) (Wu and Palmer, 1994) combines the depth of the LCS of two concepts into a similarity score. ( ) ( ) ( ) ( ( )) These approaches are regarded as edge-based methods. They are more natural and direct to evaluating semantic similarity in taxonomy. But they treat all nodes as the same and do not consider the different information of different nodes. (Jiang and Conrath, 1998) uses the information content of concept instead of its</context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Claudia Leacock and Martin Chodorow, 1998. Combining local context and WordNet sense similiarity for word sense disambiguation. In WordNet, An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Las Cruces, New Mexico.</location>
<contexts>
<context position="3609" citStr="Wu and Palmer, 1994" startWordPosition="595" endWordPosition="598">d as follow: ( ) ( ) 425 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 425–429, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics This method do not consider the distance of two concepts. Any two concepts have the same LCS will have the same similarity even if the distances between them are different. It is called node-based method. (Leacock and Chodorow, 1998) develops a similarity measure based on the distance of two senses and . They focus on hypernymy links and scaled the path length by the overall depth of the tree. ( ) ( ) (Wu and Palmer, 1994) combines the depth of the LCS of two concepts into a similarity score. ( ) ( ) ( ) ( ( )) These approaches are regarded as edge-based methods. They are more natural and direct to evaluating semantic similarity in taxonomy. But they treat all nodes as the same and do not consider the different information of different nodes. (Jiang and Conrath, 1998) uses the information content of concept instead of its depth. So both node and edge information can be considered to evaluate the similarity. It performs well in evaluating semantic similarity between two texts (Zhang et al., 2008; Corley and Miha</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Palmer, 1994. Verb semantics and lexical selection. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, Las Cruces, New Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Conference on Research in Computational Linguistics.</booktitle>
<contexts>
<context position="3961" citStr="Jiang and Conrath, 1998" startWordPosition="659" endWordPosition="662">hem are different. It is called node-based method. (Leacock and Chodorow, 1998) develops a similarity measure based on the distance of two senses and . They focus on hypernymy links and scaled the path length by the overall depth of the tree. ( ) ( ) (Wu and Palmer, 1994) combines the depth of the LCS of two concepts into a similarity score. ( ) ( ) ( ) ( ( )) These approaches are regarded as edge-based methods. They are more natural and direct to evaluating semantic similarity in taxonomy. But they treat all nodes as the same and do not consider the different information of different nodes. (Jiang and Conrath, 1998) uses the information content of concept instead of its depth. So both node and edge information can be considered to evaluate the similarity. It performs well in evaluating semantic similarity between two texts (Zhang et al., 2008; Corley and Mihalcea, 2005; Pedersen, 2010). ( ) ( ) ( ) ( ( )) SemCor is used in Jiang&apos;s work to get the frequency of a word with a specific sense treated by the Lagrange Smoothing. 3 Approaches For SemEval-2012 task 4, we use two MRDs and one corpus as our knowledge resources. One MRD is HIT IR-Lab Tongyici Cilin (Extended) (Cilin) and the other is Chinese Concept</context>
</contexts>
<marker>Jiang, Conrath, 1998</marker>
<rawString>Jay J. Jiang and David W. Conrath, 1998. Semantic similarity based on corpus statistics and lexical taxonomy. In Proceedings of the International Conference on Research in Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu-Jing Wang</author>
</authors>
<title>Semantic similarity based on compact concept ontology.</title>
<date>2008</date>
<booktitle>In Proceeding of the 17th international conference on World Wide Web,</booktitle>
<location>Beijing, China</location>
<marker>Wang, 2008</marker>
<rawString>Ce Zhang , Yu-Jing Wang , Bin Cui , Gao Cong, 2008. Semantic similarity based on compact concept ontology. In Proceeding of the 17th international conference on World Wide Web, April 21-25, 2008, Beijing, China</rawString>
</citation>
<citation valid="true">
<authors>
<author>Courtney Corley</author>
</authors>
<title>Measuring the semantic similarity of texts.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment,</booktitle>
<pages>13--18</pages>
<location>Ann Arbor, Michigan.</location>
<marker>Corley, 2005</marker>
<rawString>Courtney Corley , Rada Mihalcea, 2005. Measuring the semantic similarity of texts. In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, p.13-18, June 30-30, 2005, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>Information content measures of semantic similarity perform better without sensetagged text.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>329--332</pages>
<location>Los Angeles, California.</location>
<contexts>
<context position="4236" citStr="Pedersen, 2010" startWordPosition="705" endWordPosition="706">e depth of the LCS of two concepts into a similarity score. ( ) ( ) ( ) ( ( )) These approaches are regarded as edge-based methods. They are more natural and direct to evaluating semantic similarity in taxonomy. But they treat all nodes as the same and do not consider the different information of different nodes. (Jiang and Conrath, 1998) uses the information content of concept instead of its depth. So both node and edge information can be considered to evaluate the similarity. It performs well in evaluating semantic similarity between two texts (Zhang et al., 2008; Corley and Mihalcea, 2005; Pedersen, 2010). ( ) ( ) ( ) ( ( )) SemCor is used in Jiang&apos;s work to get the frequency of a word with a specific sense treated by the Lagrange Smoothing. 3 Approaches For SemEval-2012 task 4, we use two MRDs and one corpus as our knowledge resources. One MRD is HIT IR-Lab Tongyici Cilin (Extended) (Cilin) and the other is Chinese Concept Dictionary (CCD). The corpus we used in our system is People&apos;s Daily. Three systems are proposed to evaluate the semantic similarity between two Chinese words. The first one utilizes both the MRDs called MIXCC (Mixture of Cilin and CCD) and other two named MIXCD1 (Mixture o</context>
</contexts>
<marker>Pedersen, 2010</marker>
<rawString>Ted Pedersen, 2010. Information content measures of semantic similarity perform better without sensetagged text. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, p.329-332, June 02-04, 2010, Los Angeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Kendall</author>
</authors>
<title>Rank Correlation Methods.</title>
<date>1955</date>
<publisher>Hafner Publishing Co.</publisher>
<location>New York:</location>
<marker>Kendall, 1955</marker>
<rawString>M. G. Kendall, 1955. Rank Correlation Methods. New York: Hafner Publishing Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wessa</author>
</authors>
<title>Free Statistics Software, Office for Research Development and Education, version 1.1.23-r7,</title>
<date>2012</date>
<note>URL http://www.wessa.net/</note>
<contexts>
<context position="10122" citStr="Wessa, 2012" startWordPosition="1765" endWordPosition="1766">lt of multiple linear regression to forecast the similarity of other word pairs and get the rank. 3.4 Post Processing The word pair with the same meaning may be consisted of two same words or two different words belong to the same concept. It is difficult for both systems to separate one from the other. Therefore we display a post processing on our systems to make sure that the similarity between the same words has a larger rank than two different words of the same meaning. 4 Experiments and Results We perform our systems on trial data and then use Kendall tau Rank Correlation (Kendall, 1995; Wessa, 2012) to evaluate the results shown in Table 1. The trial data contains 50 word pairs. The similarity of each pair is scored by several experts and the mean value is regarded as the standard answer to get the manual ranking. Method Kendall tau 2-sided p value MIXCC 0.273469 0.005208 MIXCD0 0.152653 0.119741 MIXCD 0.260408 0.007813 Manual(upper) 0.441633 6.27E-06 Table 1: Kendall tau Rank Correlation of systems on trial From Table 1, we can see the tau value of MIXCD0 is 0.1526 and MIXCD is 0.2604. MIXCD performed notably better than MIXCD0. It shows 427 that path&apos;s length between two words is on an</context>
</contexts>
<marker>Wessa, 2012</marker>
<rawString>P. Wessa, 2012. Free Statistics Software, Office for Research Development and Education, version 1.1.23-r7, URL http://www.wessa.net/</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordan L Fleiss</author>
</authors>
<title>Measuring nominal scale agreement among many raters.</title>
<date>1971</date>
<journal>Psychological Bulletin,</journal>
<volume>76</volume>
<pages>378--382</pages>
<contexts>
<context position="11898" citStr="Fleiss, 1971" startWordPosition="2075" endWordPosition="2076">ue is larger than that of MIXCD. It seems that the mutual information derived from corpus which is expected to improve the result reduces the correction of rank result contrarily. There may be two reasons on it. First, because of the use of trial data in MIXCD, the result of similarity ranking strongly depended on this data. The reliability of trial data&apos;s ranking may influent the performance of our system. We calculate the tau value between every manual and the correct ranking. The least tau value is 0.4416 and the largest one is 0.8220 with a large disparity. We use the Fleiss&apos; kappa value (Fleiss, 1971) to evaluate the agreement of manual ranking and the result is 0.1526 which showed the significant disagreement. This disagreement may make the regression result cannot show the relation between features and score correctly. To reduce the disagreement&apos;s influence we calculate the mean of manual similarity score omitting the maximum and minimum ones and get a new standard rank (trial2). Then we perform MIXCD on trail2 and show the new result as MIXCD-2 in Form 2. MIXCC&apos;s result is also compared with trail2 shown as MIXCC2. MIXCC-2 MIXCD-2 MIXCC MIXCD Kendall tau 0.297959 0.265306 0.273469 0.260</context>
</contexts>
<marker>Fleiss, 1971</marker>
<rawString>Jordan L. Fleiss, 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, Vol. 76, No. 5 pp. 378–382.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>