<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006587">
<title confidence="0.616541">
Information and Deliberation in Discourse
</title>
<author confidence="0.393795">
Marilyn A. Walker*
</author>
<email confidence="0.996184">
lyn@linc.cis.upenn.edu
</email>
<sectionHeader confidence="0.999556" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998639238095238">
The most common assumption about intention in discourse is that the primary intention of discourse is to
communicate and receive information. This is a founding assumption of every formal model of discourse
meaning that I am aware of. The standard account of meaning is that utterances are functions from contexts
to contexts whose primary purpose is to describe the world, and whose meaning derives from the fact that they
delimit the set of worlds that the conversants believe possible. One of the ramifications of this assumption is
that utterances with no new information are infelicitous or have no meaning[1, 2, 14, 5]. However, consider
example 1, asserted by a passenger in a vehicle in response to the driver&apos;s comment that the heavy traffic
was unexpected:
(I) There&apos;s something on fire up there. I can&apos;t see what&apos;s on fire, but SOMETHING IS. (LW 6/12/92)
In the first clause of 1, the speaker asserts a proposition P, namely that something is on fire. In the
second clause, the speaker presupposes P, and finally in the third clause the speaker affirms P. I will argue
that examples like this show that a theory of discourse meaning must account for DELIBERATION-based
intentions. The DELIBERATION-based view emphasizes that agents produce utterances to support other
agents&apos; deliberations about what they want to believe or what they want to do. Agents don&apos;t take it for
granted that. their assertions will be accepted by other agents. I will call clauses like the third one above
INFORMATIONALLY REDUNDANT UTTERANCES, henceforth (IRUs). In the examples given here, IRUs are
shown in CAPS. The IRU&apos;s ANTECEDENT, the utterance which originally added the IRU&apos;s propositional
content to the discourse, is shown in italics.
Section 2 discusses deliberation in discourse. I will show how a set of assumptions about deliberation account
for many examples of IRUs in discourse. Then in section 3, I will briefly discuss how some RST relations
can be viewed a.s heuristic strategies for achieving DELIBERATION-based intentions[9].
</bodyText>
<sectionHeader confidence="0.987327" genericHeader="keywords">
2 Deliberation
</sectionHeader>
<bodyText confidence="0.930358833333333">
DELIBERATION as a component of a theory of intention in discourse is functionally related to the theory of
economic rationality, which in recent years has augmented the INFORMATION-based (logical) view of action
[3]. DELIBERATION is the process by which an agent explicitly or implicitly evaluates a set of alternates
in order to decide what s/he wants to believe and what course of action s/he wants to pursue.1 Thus
agents deliberate about whether as well as how to revise their beliefs and intentions as they receive new
information[4]. This is partially reflected in the following ATTITUDE assumption[16]:
</bodyText>
<listItem confidence="0.9985495">
• ATTITUDE: Agents deliberate whether to ACCEPT or REJECT an assertion or proposal made by another
agent in discourse.
</listItem>
<page confidence="0.6773805">
•This research was partially funded by ARO grant DAAL03-89-00031PRI and DARPA grant N00014-90-J-1863 at the
University of Pennsylvania, and by Hewlett Packard, U.K.
lEvaluation functions (utilities) for beliefs may have a different basis than those for intentions.
144
</page>
<bodyText confidence="0.999217944444445">
Empirical analyses of dialogue can inform an account of deliberation because dialogue provides an explicit
protocol of which facts agents believe will affect the ACCEPTANCE or REJECTION of an assertion or proposal.
An analysis of IRUs in problem-solving dialogues shows that the process of deliberating about beliefs depends
on the type of evidence supporting a belief, and that one of the primary functions of IRUs is to upgrade
the strength of the evidence supporting beliefs[18, 17, 20]. Beliefs that are strongly supported cohere with
other beliefs and are more difficult to defeat[4]. The process of deliberating about intentions also depends
on evidence supporting beliefs that the intention is based on, which can contribute to a perception of &apos;risk&apos;.
However, there is an additional independent factor that contributes to deliberating about intentions: the
utility of the resulting &apos;plan&apos;[11].2 IRUs function communicatively to support both deliberative processes.
Because of the ATTITUDE assumption, there are two fundamental relations in discourse between beliefs and
intentions and their supporting beliefs. The SUPPORT relation links beliefs at various endorsement levels,
e.g. a premise supports a conclusion and endorses it as an ENTAILMENT[6, 17]. The WARRANTS relation
links beliefs with intentions that they are a warrant for, e.g. the belief that you will make a 15% profit may
provide a WARRANT for an intention to purchase Hewlett Packard stock. Of course, measurable benefits of
intentions are the simplest case.
In addition to the factors noted above, other processing factors such as the frequency and salience of beliefs
contribute to deliberation. Furthermore, preferences may be relevant, so that other things being equal, human
agents believe what they prefer to believe[8, 4]. These factors are reflected in the following assumptions:
</bodyText>
<listItem confidence="0.9632856">
• PREFERENCE: Agents&apos; beliefs are partially determined by their preferences about what to believe,
which may have a nonlogical basis.
• AFFIRMATION: Repeating a proposition is a weak type of SUPPORT that provides evidence of the
speaker&apos;s commitment to the truth of the proposition. In addition, affirmation makes a proposition
salient and may increase the frequency of that proposition in memory.
</listItem>
<bodyText confidence="0.999829142857143">
The AFFIRMATION assumption means that the occurrence of an affirmation is a cue that the speaker believes
that s/he must provide additional SUPPORT for his/her assertions.3 This speaker belief is most often moti-
vated by the perception that some propositions in the discourse are in opposition with one another[19, 7].
In other words, if a proposition P is affirmed in a context C, something in C must either support or warrant
an opposite conclusion Q, or fail to support or warrant P. For example, consider 2, which demonstrates an
opposition in support., apparently based on the common-sense inference that torment leads to unproductivity
(Ward&apos;s 96)[19, 71:
</bodyText>
<listItem confidence="0.7494615">
(2) Tchaikovsky was one of the most tormented men in musical history. In fact, one wonders how he
managed to produce any music at all. BUT PRODUCE MUSIC HE DID.,[WFLN Radio]
Example 1 is also motivated by the speaker&apos;s goal to provide support, and shows that. the speaker believes
that visual evidence would support. her claim that, something is on fire. It also shows that. it is necessary to
represent the relation NOT-SUPPORT, since the fact that the speaker can&apos;t see what&apos;s on fire fails to support,
the belief that something is on. fire, without supporting its negation. Example 3 is also motivated by a
combination of the AFFIRMATION and ATTITUDE assumptions, where, as in example 1, the speaker states
that she cannot provide support for her claim:
(3) I like you Lizzy. I don&apos;t know why I like you. But I LIKE YOU. (CS, 3/4/92)
Similarly, in example 4, the relevant relation seems to be NOT-WARRANT:
</listItem>
<footnote confidence="0.995342571428571">
2The independence of these factors is easy to see in a simplified domain such as DesignWorld [16, 15], in which two agents
must attempt to maximize utility while negotiating a COLLABORATIVE PLAN for the design of a two room house, and where the
utility of the design plan is a function of the values of the individual pieces of furniture that make up the plan. Imagine that
there is a default rule that if an agent can&apos;t remember the value associated with a piece of furniture, then s/he can assume
that it. is worth 100 points. Then a proposal to include that piece of furniture in the final plan would have high utility for that
agent, but the belief is not well supported.
3 Not all IRUs in discourse function as affirmations [W].
</footnote>
<page confidence="0.995555">
145
</page>
<bodyText confidence="0.971123875">
(4) Ile didn&apos;t make a profit from doing it, but HE DID IT.
These examples all demonstrate that often the best support for deliberation that a speaker can provide is
his/her own AFFIRMATION of the relevant fact. In general, IRUs motivated by SUPPORT are characterized
by verbs referring to typical sources of evidence for propositions being deliberated, e.g. see, hear, say, as
well as mental state verbs reflecting deliberation, know, remember. IRUs motivated by WARRANT refer to
intentionality, costs, or benefits of a course of action as in 4..
The ATTITUDE and PREFERENCE assumptions motivate example 5, where what. is relevant is that the speaker
believes that. the hearer ina.y not want to accept the assertion of P, preferring to believe P (Horn&apos;s 32a)[7].
</bodyText>
<listItem confidence="0.516806">
(5) It&apos;s unfortunate that you failed, but FAIL YOU DID.
</listItem>
<bodyText confidence="0.99905925">
It is possible that P in 5 conflicts with the hearer&apos;s view of herself as extremely intelligent, or that the
acceptance of P would lead the hearer to infer a number of conclusions which she would prefer not to derive.
Factive predicates for other relations that express the difficulty of accepting a proposition are odd, strange,
surprising, amazing, I&apos;m sorry that, It&apos;s a wonder that, and all of these also license affirmation.
Finally, when two opposing facts are supported by the same quality of evidence, e.g. linguistic, other factors
may be important. In example 6, Jennifer, (j), has received verbal advice from two different sources. Both
of the statements shown in CAPS are IRUs, and reflect her deliberation process, showing that what seems
to be relevant is the source of these two opposed beliefs: 4
</bodyText>
<listItem confidence="0.7555824">
(6) II. Jennifer I understand what you&apos;re saying and I&apos;m sorry I have to tell you that, I really am.
J. Well, I&apos;m, I have more faith in you than what he told me,
HE SAID I DIDN&apos;T HAVE TO FILE,
BUT THEN YOU JUST TOLD ME I DO
II. Yes. and I wouldn&apos;t want to see you get in trouble.
</listItem>
<sectionHeader confidence="0.928197" genericHeader="introduction">
3 Information, Deliberation or Contrast
</sectionHeader>
<bodyText confidence="0.9867439">
I&apos;ve argued that supporting deliberation is a fundamental intention in discourse. In section 2, I showed how
examples of IRUs that would be analyzed with RST relations of CONTRAST, MOTIVATION and EXPLANATION
are motivated by the intention to support deliberation. One potential integration of rhetorical relation and
intention-based theories of discourse is to view schemas for contrast, motivation and explanation as heuristic
strategies for achieving discourse intentions of deliberation[13]. However, there are a residue of contrast
examples for which it is difficult to give a deliberation account. Example 7 demonstrates that a set-based
definition of contrast easily supports affirmation[12]. Here the speaker is talking about a recent vacation to
Mexico.
(7) We always had water (in that. room).
I think we were the only ones,
WE NEVER RAN OUT OF WATER.
Hot water, we ran out of.
but WE ALWAYS HAD WATER.
(Viv 3/20/92)
It is unclear whether the affirmations in this example are motivated by the fact that Viv believed that her
audience were unwilling to accept her assertions without further support. Here, Viv seems to be caught in
a rhetorical schema. as she enumerates two sets in set-based contrast. First, We, the others is enumerated
with the affirmation and negation of having water. Then a second set, hot water, cold .water is enumerated
with the affirmation/negation of running out of it. A challenge for the account presented here is to explain
what kind of intention motivates Viv&apos;s affirmations.
</bodyText>
<footnote confidence="0.696005">
@Phis excerpt is from a radio talk show for financial advice. I an, grateful to Julia Hirschberg and Martha Pollack for
originally transcribing this corpus and providing me with tapes of the original broadcast[10].
</footnote>
<page confidence="0.997653">
146
</page>
<sectionHeader confidence="0.990309" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999924108108108">
[1] James F. Allen. Recognizing intentions from natural language utterances. In M. Brady and R.C.
Berwick, editors, Computational Models of Discourse. MIT Press, 1983.
[2] Phillip R. Cohen. On knowing what to say: Planning speech acts. Technical Report 118, University of
Toronto; Department of Computer Science, 1978.
[3] Jon Doyle. Rationality and its roles in reasoning. Computational Intelligence, November 1992.
[4] Julia R. Gathers. Autonomous belief revision and communication. In P. Gardenfoors, editor, Belief
Revision, page 1. Cambridge University Press, 1991.
[5] Gerald Gazdar. Pragmatics : implicature, presupposition and logical form. Academic Press, 1979.
[6] Barbara J. Grosz and Candace L. Sidner. Attentions, intentions and the structure of discourse. Com-
putational Linguistics, 12:175-204, 1986.
[7] Laurence R. Horn. Given as new: When redundant affirmation isn&apos;t. Journal of Pragmatics, 15:305-328,
1991.
[8] Daniel Kalmeman, Paul Slovic, and Amos Tversky. Judgment under uncertainty : heuristics and biases.
Cambridge University Press, 1982.
[9] W.C. Mann and S.A. Thompson. Rhetorical structure theory: A framework for the analysis of texts.
Technical Report RS-87-190, USC/Information Sciences Institute, 1987.
[10] Martha Pollack, Julia Hirschberg, and Bonnie Webber. User participation in the reasoning process of
expert systems. In AAAI82, 1982.
[11] Martha E. Pollack. Plans as complex mental attitudes. In Cohen, Morgan and Pollack, eds. Intentions
in Communication, MIT Press, 1990.
[12] Ellen F. Prince. On the syntactic marking of the presupposed open proposition. 0;886, 1986.
[13] R. Sproull. Strategy construction using a synthesis of heuristic and decision-theoretic methods. PhD
thesis, Stanford University, 1977.
[14] Robert C. Stalnaker. Assertion. In Peter Cole, editor, Syntar and Semantics, Volume 9: Pragmatics,
pages 315-332. Academic Press, 1978.
[15] Marilyn Walker. Informational redundancy and resource bounds in dialogue. In AAAI Spring Sympo-
sium on Reasoning about Mental Slates, 1993.
[16] Marilyn A. Walker. A model of redundant information in dialogue: the role of resource bounds. Tech-
nical Report IRCS-92-95, University of Pennsylvania. Institute for Research in Cognitive Science, 1992.
Dissertation Proposal.
[17] Marilyn A. Walker. Redundancy in collaborative dialogue. In Fourteenth International Conference on
Computational Linguistics, 1992.
[18] Marilyn A. Walker and Steve Whittaker. Mixed initiative in dialogue: An investigation into discourse
segmentation. In Proc. 281.11 Annual Meeting of the .4 CL, pages 70-79, 1990.
[19] Gregory L. Ward. The discourse functions of vp preposing. Language, 66(4):742-763, 1990.
[20] Steve Whittaker, Erik •Geelhoed, and Elizabeth Robinson. Shared workspaces: How do they work and
when are they useful? Technical report, HP Labs, Bristol, England, 1993.
</reference>
<page confidence="0.998099">
147
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.968679">
<title confidence="0.999824">Information and Deliberation in Discourse</title>
<author confidence="0.998293">A Marilyn</author>
<email confidence="0.970409">lyn@linc.cis.upenn.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Recognizing intentions from natural language utterances.</title>
<date>1983</date>
<booktitle>Computational Models of Discourse.</booktitle>
<editor>In M. Brady and R.C. Berwick, editors,</editor>
<publisher>MIT Press,</publisher>
<contexts>
<context position="723" citStr="[1, 2, 14, 5]" startWordPosition="109" endWordPosition="112">mmon assumption about intention in discourse is that the primary intention of discourse is to communicate and receive information. This is a founding assumption of every formal model of discourse meaning that I am aware of. The standard account of meaning is that utterances are functions from contexts to contexts whose primary purpose is to describe the world, and whose meaning derives from the fact that they delimit the set of worlds that the conversants believe possible. One of the ramifications of this assumption is that utterances with no new information are infelicitous or have no meaning[1, 2, 14, 5]. However, consider example 1, asserted by a passenger in a vehicle in response to the driver&apos;s comment that the heavy traffic was unexpected: (I) There&apos;s something on fire up there. I can&apos;t see what&apos;s on fire, but SOMETHING IS. (LW 6/12/92) In the first clause of 1, the speaker asserts a proposition P, namely that something is on fire. In the second clause, the speaker presupposes P, and finally in the third clause the speaker affirms P. I will argue that examples like this show that a theory of discourse meaning must account for DELIBERATION-based intentions. The DELIBERATION-based view emph</context>
</contexts>
<marker>[1]</marker>
<rawString>James F. Allen. Recognizing intentions from natural language utterances. In M. Brady and R.C. Berwick, editors, Computational Models of Discourse. MIT Press, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phillip R Cohen</author>
</authors>
<title>On knowing what to say: Planning speech acts.</title>
<date>1978</date>
<tech>Technical Report 118,</tech>
<institution>University of Toronto; Department of Computer Science,</institution>
<contexts>
<context position="723" citStr="[1, 2, 14, 5]" startWordPosition="109" endWordPosition="112">mmon assumption about intention in discourse is that the primary intention of discourse is to communicate and receive information. This is a founding assumption of every formal model of discourse meaning that I am aware of. The standard account of meaning is that utterances are functions from contexts to contexts whose primary purpose is to describe the world, and whose meaning derives from the fact that they delimit the set of worlds that the conversants believe possible. One of the ramifications of this assumption is that utterances with no new information are infelicitous or have no meaning[1, 2, 14, 5]. However, consider example 1, asserted by a passenger in a vehicle in response to the driver&apos;s comment that the heavy traffic was unexpected: (I) There&apos;s something on fire up there. I can&apos;t see what&apos;s on fire, but SOMETHING IS. (LW 6/12/92) In the first clause of 1, the speaker asserts a proposition P, namely that something is on fire. In the second clause, the speaker presupposes P, and finally in the third clause the speaker affirms P. I will argue that examples like this show that a theory of discourse meaning must account for DELIBERATION-based intentions. The DELIBERATION-based view emph</context>
</contexts>
<marker>[2]</marker>
<rawString>Phillip R. Cohen. On knowing what to say: Planning speech acts. Technical Report 118, University of Toronto; Department of Computer Science, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Doyle</author>
</authors>
<title>Rationality and its roles in reasoning.</title>
<date>1992</date>
<journal>Computational Intelligence,</journal>
<contexts>
<context position="2364" citStr="[3]" startWordPosition="372" endWordPosition="372">he IRU&apos;s propositional content to the discourse, is shown in italics. Section 2 discusses deliberation in discourse. I will show how a set of assumptions about deliberation account for many examples of IRUs in discourse. Then in section 3, I will briefly discuss how some RST relations can be viewed a.s heuristic strategies for achieving DELIBERATION-based intentions[9]. 2 Deliberation DELIBERATION as a component of a theory of intention in discourse is functionally related to the theory of economic rationality, which in recent years has augmented the INFORMATION-based (logical) view of action [3]. DELIBERATION is the process by which an agent explicitly or implicitly evaluates a set of alternates in order to decide what s/he wants to believe and what course of action s/he wants to pursue.1 Thus agents deliberate about whether as well as how to revise their beliefs and intentions as they receive new information[4]. This is partially reflected in the following ATTITUDE assumption[16]: • ATTITUDE: Agents deliberate whether to ACCEPT or REJECT an assertion or proposal made by another agent in discourse. •This research was partially funded by ARO grant DAAL03-89-00031PRI and DARPA grant N0</context>
</contexts>
<marker>[3]</marker>
<rawString>Jon Doyle. Rationality and its roles in reasoning. Computational Intelligence, November 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia R Gathers</author>
</authors>
<title>Autonomous belief revision and communication.</title>
<date>1991</date>
<booktitle>Belief Revision,</booktitle>
<pages>1</pages>
<editor>In P. Gardenfoors, editor,</editor>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="2687" citStr="[4]" startWordPosition="426" endWordPosition="426">s for achieving DELIBERATION-based intentions[9]. 2 Deliberation DELIBERATION as a component of a theory of intention in discourse is functionally related to the theory of economic rationality, which in recent years has augmented the INFORMATION-based (logical) view of action [3]. DELIBERATION is the process by which an agent explicitly or implicitly evaluates a set of alternates in order to decide what s/he wants to believe and what course of action s/he wants to pursue.1 Thus agents deliberate about whether as well as how to revise their beliefs and intentions as they receive new information[4]. This is partially reflected in the following ATTITUDE assumption[16]: • ATTITUDE: Agents deliberate whether to ACCEPT or REJECT an assertion or proposal made by another agent in discourse. •This research was partially funded by ARO grant DAAL03-89-00031PRI and DARPA grant N00014-90-J-1863 at the University of Pennsylvania, and by Hewlett Packard, U.K. lEvaluation functions (utilities) for beliefs may have a different basis than those for intentions. 144 Empirical analyses of dialogue can inform an account of deliberation because dialogue provides an explicit protocol of which facts agents be</context>
<context position="4950" citStr="[8, 4]" startWordPosition="764" endWordPosition="765">se supports a conclusion and endorses it as an ENTAILMENT[6, 17]. The WARRANTS relation links beliefs with intentions that they are a warrant for, e.g. the belief that you will make a 15% profit may provide a WARRANT for an intention to purchase Hewlett Packard stock. Of course, measurable benefits of intentions are the simplest case. In addition to the factors noted above, other processing factors such as the frequency and salience of beliefs contribute to deliberation. Furthermore, preferences may be relevant, so that other things being equal, human agents believe what they prefer to believe[8, 4]. These factors are reflected in the following assumptions: • PREFERENCE: Agents&apos; beliefs are partially determined by their preferences about what to believe, which may have a nonlogical basis. • AFFIRMATION: Repeating a proposition is a weak type of SUPPORT that provides evidence of the speaker&apos;s commitment to the truth of the proposition. In addition, affirmation makes a proposition salient and may increase the frequency of that proposition in memory. The AFFIRMATION assumption means that the occurrence of an affirmation is a cue that the speaker believes that s/he must provide additional SU</context>
</contexts>
<marker>[4]</marker>
<rawString>Julia R. Gathers. Autonomous belief revision and communication. In P. Gardenfoors, editor, Belief Revision, page 1. Cambridge University Press, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
</authors>
<title>Pragmatics : implicature, presupposition and logical form.</title>
<date>1979</date>
<publisher>Academic Press,</publisher>
<contexts>
<context position="723" citStr="[1, 2, 14, 5]" startWordPosition="109" endWordPosition="112">mmon assumption about intention in discourse is that the primary intention of discourse is to communicate and receive information. This is a founding assumption of every formal model of discourse meaning that I am aware of. The standard account of meaning is that utterances are functions from contexts to contexts whose primary purpose is to describe the world, and whose meaning derives from the fact that they delimit the set of worlds that the conversants believe possible. One of the ramifications of this assumption is that utterances with no new information are infelicitous or have no meaning[1, 2, 14, 5]. However, consider example 1, asserted by a passenger in a vehicle in response to the driver&apos;s comment that the heavy traffic was unexpected: (I) There&apos;s something on fire up there. I can&apos;t see what&apos;s on fire, but SOMETHING IS. (LW 6/12/92) In the first clause of 1, the speaker asserts a proposition P, namely that something is on fire. In the second clause, the speaker presupposes P, and finally in the third clause the speaker affirms P. I will argue that examples like this show that a theory of discourse meaning must account for DELIBERATION-based intentions. The DELIBERATION-based view emph</context>
</contexts>
<marker>[5]</marker>
<rawString>Gerald Gazdar. Pragmatics : implicature, presupposition and logical form. Academic Press, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attentions, intentions and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--175</pages>
<contexts>
<context position="4408" citStr="[6, 17]" startWordPosition="678" endWordPosition="679">dence supporting beliefs that the intention is based on, which can contribute to a perception of &apos;risk&apos;. However, there is an additional independent factor that contributes to deliberating about intentions: the utility of the resulting &apos;plan&apos;[11].2 IRUs function communicatively to support both deliberative processes. Because of the ATTITUDE assumption, there are two fundamental relations in discourse between beliefs and intentions and their supporting beliefs. The SUPPORT relation links beliefs at various endorsement levels, e.g. a premise supports a conclusion and endorses it as an ENTAILMENT[6, 17]. The WARRANTS relation links beliefs with intentions that they are a warrant for, e.g. the belief that you will make a 15% profit may provide a WARRANT for an intention to purchase Hewlett Packard stock. Of course, measurable benefits of intentions are the simplest case. In addition to the factors noted above, other processing factors such as the frequency and salience of beliefs contribute to deliberation. Furthermore, preferences may be relevant, so that other things being equal, human agents believe what they prefer to believe[8, 4]. These factors are reflected in the following assumptions</context>
</contexts>
<marker>[6]</marker>
<rawString>Barbara J. Grosz and Candace L. Sidner. Attentions, intentions and the structure of discourse. Computational Linguistics, 12:175-204, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence R Horn</author>
</authors>
<title>Given as new: When redundant affirmation isn&apos;t.</title>
<date>1991</date>
<journal>Journal of Pragmatics,</journal>
<pages>15--305</pages>
<contexts>
<context position="5724" citStr="[19, 7]" startWordPosition="883" endWordPosition="884">y have a nonlogical basis. • AFFIRMATION: Repeating a proposition is a weak type of SUPPORT that provides evidence of the speaker&apos;s commitment to the truth of the proposition. In addition, affirmation makes a proposition salient and may increase the frequency of that proposition in memory. The AFFIRMATION assumption means that the occurrence of an affirmation is a cue that the speaker believes that s/he must provide additional SUPPORT for his/her assertions.3 This speaker belief is most often motivated by the perception that some propositions in the discourse are in opposition with one another[19, 7]. In other words, if a proposition P is affirmed in a context C, something in C must either support or warrant an opposite conclusion Q, or fail to support or warrant P. For example, consider 2, which demonstrates an opposition in support., apparently based on the common-sense inference that torment leads to unproductivity (Ward&apos;s 96)[19, 71: (2) Tchaikovsky was one of the most tormented men in musical history. In fact, one wonders how he managed to produce any music at all. BUT PRODUCE MUSIC HE DID.,[WFLN Radio] Example 1 is also motivated by the speaker&apos;s goal to provide support, and shows t</context>
<context position="8477" citStr="[7]" startWordPosition="1355" endWordPosition="1355">ide is his/her own AFFIRMATION of the relevant fact. In general, IRUs motivated by SUPPORT are characterized by verbs referring to typical sources of evidence for propositions being deliberated, e.g. see, hear, say, as well as mental state verbs reflecting deliberation, know, remember. IRUs motivated by WARRANT refer to intentionality, costs, or benefits of a course of action as in 4.. The ATTITUDE and PREFERENCE assumptions motivate example 5, where what. is relevant is that the speaker believes that. the hearer ina.y not want to accept the assertion of P, preferring to believe P (Horn&apos;s 32a)[7]. (5) It&apos;s unfortunate that you failed, but FAIL YOU DID. It is possible that P in 5 conflicts with the hearer&apos;s view of herself as extremely intelligent, or that the acceptance of P would lead the hearer to infer a number of conclusions which she would prefer not to derive. Factive predicates for other relations that express the difficulty of accepting a proposition are odd, strange, surprising, amazing, I&apos;m sorry that, It&apos;s a wonder that, and all of these also license affirmation. Finally, when two opposing facts are supported by the same quality of evidence, e.g. linguistic, other factors m</context>
</contexts>
<marker>[7]</marker>
<rawString>Laurence R. Horn. Given as new: When redundant affirmation isn&apos;t. Journal of Pragmatics, 15:305-328, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Kalmeman</author>
<author>Paul Slovic</author>
<author>Amos Tversky</author>
</authors>
<title>Judgment under uncertainty : heuristics and biases.</title>
<date>1982</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="4950" citStr="[8, 4]" startWordPosition="764" endWordPosition="765">se supports a conclusion and endorses it as an ENTAILMENT[6, 17]. The WARRANTS relation links beliefs with intentions that they are a warrant for, e.g. the belief that you will make a 15% profit may provide a WARRANT for an intention to purchase Hewlett Packard stock. Of course, measurable benefits of intentions are the simplest case. In addition to the factors noted above, other processing factors such as the frequency and salience of beliefs contribute to deliberation. Furthermore, preferences may be relevant, so that other things being equal, human agents believe what they prefer to believe[8, 4]. These factors are reflected in the following assumptions: • PREFERENCE: Agents&apos; beliefs are partially determined by their preferences about what to believe, which may have a nonlogical basis. • AFFIRMATION: Repeating a proposition is a weak type of SUPPORT that provides evidence of the speaker&apos;s commitment to the truth of the proposition. In addition, affirmation makes a proposition salient and may increase the frequency of that proposition in memory. The AFFIRMATION assumption means that the occurrence of an affirmation is a cue that the speaker believes that s/he must provide additional SU</context>
</contexts>
<marker>[8]</marker>
<rawString>Daniel Kalmeman, Paul Slovic, and Amos Tversky. Judgment under uncertainty : heuristics and biases. Cambridge University Press, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical structure theory: A framework for the analysis of texts.</title>
<date>1987</date>
<tech>Technical Report RS-87-190,</tech>
<institution>USC/Information Sciences Institute,</institution>
<contexts>
<context position="2132" citStr="[9]" startWordPosition="337" endWordPosition="337"> by other agents. I will call clauses like the third one above INFORMATIONALLY REDUNDANT UTTERANCES, henceforth (IRUs). In the examples given here, IRUs are shown in CAPS. The IRU&apos;s ANTECEDENT, the utterance which originally added the IRU&apos;s propositional content to the discourse, is shown in italics. Section 2 discusses deliberation in discourse. I will show how a set of assumptions about deliberation account for many examples of IRUs in discourse. Then in section 3, I will briefly discuss how some RST relations can be viewed a.s heuristic strategies for achieving DELIBERATION-based intentions[9]. 2 Deliberation DELIBERATION as a component of a theory of intention in discourse is functionally related to the theory of economic rationality, which in recent years has augmented the INFORMATION-based (logical) view of action [3]. DELIBERATION is the process by which an agent explicitly or implicitly evaluates a set of alternates in order to decide what s/he wants to believe and what course of action s/he wants to pursue.1 Thus agents deliberate about whether as well as how to revise their beliefs and intentions as they receive new information[4]. This is partially reflected in the followin</context>
</contexts>
<marker>[9]</marker>
<rawString>W.C. Mann and S.A. Thompson. Rhetorical structure theory: A framework for the analysis of texts. Technical Report RS-87-190, USC/Information Sciences Institute, 1987.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Martha Pollack</author>
<author>Julia Hirschberg</author>
<author>Bonnie Webber</author>
</authors>
<title>User participation in the reasoning process of expert systems.</title>
<booktitle>In AAAI82,</booktitle>
<pages>1982</pages>
<marker>[10]</marker>
<rawString>Martha Pollack, Julia Hirschberg, and Bonnie Webber. User participation in the reasoning process of expert systems. In AAAI82, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha E Pollack</author>
</authors>
<title>Plans as complex mental attitudes.</title>
<date>1990</date>
<booktitle>Intentions in Communication,</booktitle>
<editor>In Cohen, Morgan and Pollack, eds.</editor>
<publisher>MIT Press,</publisher>
<contexts>
<context position="4047" citStr="[11]" startWordPosition="629" endWordPosition="629">rating about beliefs depends on the type of evidence supporting a belief, and that one of the primary functions of IRUs is to upgrade the strength of the evidence supporting beliefs[18, 17, 20]. Beliefs that are strongly supported cohere with other beliefs and are more difficult to defeat[4]. The process of deliberating about intentions also depends on evidence supporting beliefs that the intention is based on, which can contribute to a perception of &apos;risk&apos;. However, there is an additional independent factor that contributes to deliberating about intentions: the utility of the resulting &apos;plan&apos;[11].2 IRUs function communicatively to support both deliberative processes. Because of the ATTITUDE assumption, there are two fundamental relations in discourse between beliefs and intentions and their supporting beliefs. The SUPPORT relation links beliefs at various endorsement levels, e.g. a premise supports a conclusion and endorses it as an ENTAILMENT[6, 17]. The WARRANTS relation links beliefs with intentions that they are a warrant for, e.g. the belief that you will make a 15% profit may provide a WARRANT for an intention to purchase Hewlett Packard stock. Of course, measurable benefits of </context>
</contexts>
<marker>[11]</marker>
<rawString>Martha E. Pollack. Plans as complex mental attitudes. In Cohen, Morgan and Pollack, eds. Intentions in Communication, MIT Press, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen F Prince</author>
</authors>
<title>On the syntactic marking of the presupposed open proposition. 0;886,</title>
<date>1986</date>
<contexts>
<context position="10365" citStr="[12]" startWordPosition="1665" endWordPosition="1665">2, I showed how examples of IRUs that would be analyzed with RST relations of CONTRAST, MOTIVATION and EXPLANATION are motivated by the intention to support deliberation. One potential integration of rhetorical relation and intention-based theories of discourse is to view schemas for contrast, motivation and explanation as heuristic strategies for achieving discourse intentions of deliberation[13]. However, there are a residue of contrast examples for which it is difficult to give a deliberation account. Example 7 demonstrates that a set-based definition of contrast easily supports affirmation[12]. Here the speaker is talking about a recent vacation to Mexico. (7) We always had water (in that. room). I think we were the only ones, WE NEVER RAN OUT OF WATER. Hot water, we ran out of. but WE ALWAYS HAD WATER. (Viv 3/20/92) It is unclear whether the affirmations in this example are motivated by the fact that Viv believed that her audience were unwilling to accept her assertions without further support. Here, Viv seems to be caught in a rhetorical schema. as she enumerates two sets in set-based contrast. First, We, the others is enumerated with the affirmation and negation of having water.</context>
</contexts>
<marker>[12]</marker>
<rawString>Ellen F. Prince. On the syntactic marking of the presupposed open proposition. 0;886, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproull</author>
</authors>
<title>Strategy construction using a synthesis of heuristic and decision-theoretic methods.</title>
<date>1977</date>
<tech>PhD thesis,</tech>
<institution>Stanford University,</institution>
<contexts>
<context position="10161" citStr="[13]" startWordPosition="1635" endWordPosition="1635">T TOLD ME I DO II. Yes. and I wouldn&apos;t want to see you get in trouble. 3 Information, Deliberation or Contrast I&apos;ve argued that supporting deliberation is a fundamental intention in discourse. In section 2, I showed how examples of IRUs that would be analyzed with RST relations of CONTRAST, MOTIVATION and EXPLANATION are motivated by the intention to support deliberation. One potential integration of rhetorical relation and intention-based theories of discourse is to view schemas for contrast, motivation and explanation as heuristic strategies for achieving discourse intentions of deliberation[13]. However, there are a residue of contrast examples for which it is difficult to give a deliberation account. Example 7 demonstrates that a set-based definition of contrast easily supports affirmation[12]. Here the speaker is talking about a recent vacation to Mexico. (7) We always had water (in that. room). I think we were the only ones, WE NEVER RAN OUT OF WATER. Hot water, we ran out of. but WE ALWAYS HAD WATER. (Viv 3/20/92) It is unclear whether the affirmations in this example are motivated by the fact that Viv believed that her audience were unwilling to accept her assertions without fu</context>
</contexts>
<marker>[13]</marker>
<rawString>R. Sproull. Strategy construction using a synthesis of heuristic and decision-theoretic methods. PhD thesis, Stanford University, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Assertion</author>
</authors>
<date>1978</date>
<booktitle>Syntar and Semantics, Volume 9: Pragmatics,</booktitle>
<pages>315--332</pages>
<editor>In Peter Cole, editor,</editor>
<publisher>Academic Press,</publisher>
<contexts>
<context position="723" citStr="[1, 2, 14, 5]" startWordPosition="109" endWordPosition="112">mmon assumption about intention in discourse is that the primary intention of discourse is to communicate and receive information. This is a founding assumption of every formal model of discourse meaning that I am aware of. The standard account of meaning is that utterances are functions from contexts to contexts whose primary purpose is to describe the world, and whose meaning derives from the fact that they delimit the set of worlds that the conversants believe possible. One of the ramifications of this assumption is that utterances with no new information are infelicitous or have no meaning[1, 2, 14, 5]. However, consider example 1, asserted by a passenger in a vehicle in response to the driver&apos;s comment that the heavy traffic was unexpected: (I) There&apos;s something on fire up there. I can&apos;t see what&apos;s on fire, but SOMETHING IS. (LW 6/12/92) In the first clause of 1, the speaker asserts a proposition P, namely that something is on fire. In the second clause, the speaker presupposes P, and finally in the third clause the speaker affirms P. I will argue that examples like this show that a theory of discourse meaning must account for DELIBERATION-based intentions. The DELIBERATION-based view emph</context>
</contexts>
<marker>[14]</marker>
<rawString>Robert C. Stalnaker. Assertion. In Peter Cole, editor, Syntar and Semantics, Volume 9: Pragmatics, pages 315-332. Academic Press, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
</authors>
<title>Informational redundancy and resource bounds in dialogue.</title>
<date>1993</date>
<booktitle>In AAAI Spring Symposium on Reasoning about Mental Slates,</booktitle>
<contexts>
<context position="7079" citStr="[16, 15]" startWordPosition="1114" endWordPosition="1115">t the relation NOT-SUPPORT, since the fact that the speaker can&apos;t see what&apos;s on fire fails to support, the belief that something is on. fire, without supporting its negation. Example 3 is also motivated by a combination of the AFFIRMATION and ATTITUDE assumptions, where, as in example 1, the speaker states that she cannot provide support for her claim: (3) I like you Lizzy. I don&apos;t know why I like you. But I LIKE YOU. (CS, 3/4/92) Similarly, in example 4, the relevant relation seems to be NOT-WARRANT: 2The independence of these factors is easy to see in a simplified domain such as DesignWorld [16, 15], in which two agents must attempt to maximize utility while negotiating a COLLABORATIVE PLAN for the design of a two room house, and where the utility of the design plan is a function of the values of the individual pieces of furniture that make up the plan. Imagine that there is a default rule that if an agent can&apos;t remember the value associated with a piece of furniture, then s/he can assume that it. is worth 100 points. Then a proposal to include that piece of furniture in the final plan would have high utility for that agent, but the belief is not well supported. 3 Not all IRUs in discour</context>
</contexts>
<marker>[15]</marker>
<rawString>Marilyn Walker. Informational redundancy and resource bounds in dialogue. In AAAI Spring Symposium on Reasoning about Mental Slates, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<title>A model of redundant information in dialogue: the role of resource bounds.</title>
<date>1992</date>
<tech>Technical Report IRCS-92-95,</tech>
<institution>University of Pennsylvania. Institute for Research in Cognitive Science,</institution>
<note>Dissertation Proposal.</note>
<contexts>
<context position="2757" citStr="[16]" startWordPosition="435" endWordPosition="435">BERATION as a component of a theory of intention in discourse is functionally related to the theory of economic rationality, which in recent years has augmented the INFORMATION-based (logical) view of action [3]. DELIBERATION is the process by which an agent explicitly or implicitly evaluates a set of alternates in order to decide what s/he wants to believe and what course of action s/he wants to pursue.1 Thus agents deliberate about whether as well as how to revise their beliefs and intentions as they receive new information[4]. This is partially reflected in the following ATTITUDE assumption[16]: • ATTITUDE: Agents deliberate whether to ACCEPT or REJECT an assertion or proposal made by another agent in discourse. •This research was partially funded by ARO grant DAAL03-89-00031PRI and DARPA grant N00014-90-J-1863 at the University of Pennsylvania, and by Hewlett Packard, U.K. lEvaluation functions (utilities) for beliefs may have a different basis than those for intentions. 144 Empirical analyses of dialogue can inform an account of deliberation because dialogue provides an explicit protocol of which facts agents believe will affect the ACCEPTANCE or REJECTION of an assertion or propo</context>
<context position="7079" citStr="[16, 15]" startWordPosition="1114" endWordPosition="1115">t the relation NOT-SUPPORT, since the fact that the speaker can&apos;t see what&apos;s on fire fails to support, the belief that something is on. fire, without supporting its negation. Example 3 is also motivated by a combination of the AFFIRMATION and ATTITUDE assumptions, where, as in example 1, the speaker states that she cannot provide support for her claim: (3) I like you Lizzy. I don&apos;t know why I like you. But I LIKE YOU. (CS, 3/4/92) Similarly, in example 4, the relevant relation seems to be NOT-WARRANT: 2The independence of these factors is easy to see in a simplified domain such as DesignWorld [16, 15], in which two agents must attempt to maximize utility while negotiating a COLLABORATIVE PLAN for the design of a two room house, and where the utility of the design plan is a function of the values of the individual pieces of furniture that make up the plan. Imagine that there is a default rule that if an agent can&apos;t remember the value associated with a piece of furniture, then s/he can assume that it. is worth 100 points. Then a proposal to include that piece of furniture in the final plan would have high utility for that agent, but the belief is not well supported. 3 Not all IRUs in discour</context>
</contexts>
<marker>[16]</marker>
<rawString>Marilyn A. Walker. A model of redundant information in dialogue: the role of resource bounds. Technical Report IRCS-92-95, University of Pennsylvania. Institute for Research in Cognitive Science, 1992. Dissertation Proposal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<title>Redundancy in collaborative dialogue.</title>
<date>1992</date>
<booktitle>In Fourteenth International Conference on Computational Linguistics,</booktitle>
<contexts>
<context position="3636" citStr="[18, 17, 20]" startWordPosition="567" endWordPosition="569">lett Packard, U.K. lEvaluation functions (utilities) for beliefs may have a different basis than those for intentions. 144 Empirical analyses of dialogue can inform an account of deliberation because dialogue provides an explicit protocol of which facts agents believe will affect the ACCEPTANCE or REJECTION of an assertion or proposal. An analysis of IRUs in problem-solving dialogues shows that the process of deliberating about beliefs depends on the type of evidence supporting a belief, and that one of the primary functions of IRUs is to upgrade the strength of the evidence supporting beliefs[18, 17, 20]. Beliefs that are strongly supported cohere with other beliefs and are more difficult to defeat[4]. The process of deliberating about intentions also depends on evidence supporting beliefs that the intention is based on, which can contribute to a perception of &apos;risk&apos;. However, there is an additional independent factor that contributes to deliberating about intentions: the utility of the resulting &apos;plan&apos;[11].2 IRUs function communicatively to support both deliberative processes. Because of the ATTITUDE assumption, there are two fundamental relations in discourse between beliefs and intentions </context>
</contexts>
<marker>[17]</marker>
<rawString>Marilyn A. Walker. Redundancy in collaborative dialogue. In Fourteenth International Conference on Computational Linguistics, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Steve Whittaker</author>
</authors>
<title>Mixed initiative in dialogue: An investigation into discourse segmentation.</title>
<date>1990</date>
<booktitle>In Proc. 281.11 Annual Meeting of the .4 CL,</booktitle>
<pages>70--79</pages>
<contexts>
<context position="3636" citStr="[18, 17, 20]" startWordPosition="567" endWordPosition="569">lett Packard, U.K. lEvaluation functions (utilities) for beliefs may have a different basis than those for intentions. 144 Empirical analyses of dialogue can inform an account of deliberation because dialogue provides an explicit protocol of which facts agents believe will affect the ACCEPTANCE or REJECTION of an assertion or proposal. An analysis of IRUs in problem-solving dialogues shows that the process of deliberating about beliefs depends on the type of evidence supporting a belief, and that one of the primary functions of IRUs is to upgrade the strength of the evidence supporting beliefs[18, 17, 20]. Beliefs that are strongly supported cohere with other beliefs and are more difficult to defeat[4]. The process of deliberating about intentions also depends on evidence supporting beliefs that the intention is based on, which can contribute to a perception of &apos;risk&apos;. However, there is an additional independent factor that contributes to deliberating about intentions: the utility of the resulting &apos;plan&apos;[11].2 IRUs function communicatively to support both deliberative processes. Because of the ATTITUDE assumption, there are two fundamental relations in discourse between beliefs and intentions </context>
</contexts>
<marker>[18]</marker>
<rawString>Marilyn A. Walker and Steve Whittaker. Mixed initiative in dialogue: An investigation into discourse segmentation. In Proc. 281.11 Annual Meeting of the .4 CL, pages 70-79, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory L Ward</author>
</authors>
<title>The discourse functions of vp preposing.</title>
<date>1990</date>
<journal>Language,</journal>
<pages>66--4</pages>
<contexts>
<context position="5724" citStr="[19, 7]" startWordPosition="883" endWordPosition="884">y have a nonlogical basis. • AFFIRMATION: Repeating a proposition is a weak type of SUPPORT that provides evidence of the speaker&apos;s commitment to the truth of the proposition. In addition, affirmation makes a proposition salient and may increase the frequency of that proposition in memory. The AFFIRMATION assumption means that the occurrence of an affirmation is a cue that the speaker believes that s/he must provide additional SUPPORT for his/her assertions.3 This speaker belief is most often motivated by the perception that some propositions in the discourse are in opposition with one another[19, 7]. In other words, if a proposition P is affirmed in a context C, something in C must either support or warrant an opposite conclusion Q, or fail to support or warrant P. For example, consider 2, which demonstrates an opposition in support., apparently based on the common-sense inference that torment leads to unproductivity (Ward&apos;s 96)[19, 71: (2) Tchaikovsky was one of the most tormented men in musical history. In fact, one wonders how he managed to produce any music at all. BUT PRODUCE MUSIC HE DID.,[WFLN Radio] Example 1 is also motivated by the speaker&apos;s goal to provide support, and shows t</context>
</contexts>
<marker>[19]</marker>
<rawString>Gregory L. Ward. The discourse functions of vp preposing. Language, 66(4):742-763, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Whittaker</author>
<author>Erik •Geelhoed</author>
<author>Elizabeth Robinson</author>
</authors>
<title>Shared workspaces: How do they work and when are they useful?</title>
<date>1993</date>
<tech>Technical report,</tech>
<institution>HP Labs,</institution>
<location>Bristol, England,</location>
<contexts>
<context position="3636" citStr="[18, 17, 20]" startWordPosition="567" endWordPosition="569">lett Packard, U.K. lEvaluation functions (utilities) for beliefs may have a different basis than those for intentions. 144 Empirical analyses of dialogue can inform an account of deliberation because dialogue provides an explicit protocol of which facts agents believe will affect the ACCEPTANCE or REJECTION of an assertion or proposal. An analysis of IRUs in problem-solving dialogues shows that the process of deliberating about beliefs depends on the type of evidence supporting a belief, and that one of the primary functions of IRUs is to upgrade the strength of the evidence supporting beliefs[18, 17, 20]. Beliefs that are strongly supported cohere with other beliefs and are more difficult to defeat[4]. The process of deliberating about intentions also depends on evidence supporting beliefs that the intention is based on, which can contribute to a perception of &apos;risk&apos;. However, there is an additional independent factor that contributes to deliberating about intentions: the utility of the resulting &apos;plan&apos;[11].2 IRUs function communicatively to support both deliberative processes. Because of the ATTITUDE assumption, there are two fundamental relations in discourse between beliefs and intentions </context>
</contexts>
<marker>[20]</marker>
<rawString>Steve Whittaker, Erik •Geelhoed, and Elizabeth Robinson. Shared workspaces: How do they work and when are they useful? Technical report, HP Labs, Bristol, England, 1993.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>