<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.293015">
<title confidence="0.988298">
The Annotation Conundrum
</title>
<author confidence="0.998957">
Mark Liberman
</author>
<affiliation confidence="0.998872">
University of Pennsylvania
</affiliation>
<email confidence="0.997366">
myl@cis.upenn.edu
</email>
<sectionHeader confidence="0.993859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999947916666667">
Without lengthy, iterative refinement of
guidelines, and equally lengthy and itera-
tive training of annotators, the level of in-
ter-subjective agreement on simple tasks
of phonetic, phonological, syntactic, se-
mantic, and pragmatic annotation is
shockingly low.
This is a significant practical problem in
speech and language technology, but it
poses questions of interest to psycholo-
gists, philosophers of language, and theo-
retical linguists as well.
</bodyText>
<sectionHeader confidence="0.997656" genericHeader="references">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997551">
Biologists believe that they know what
genes, organisms, chemical compounds,
and diseases are. Linguists believe that
they know what nouns, verbs, and claus-
es are. Ordinary literate speakers of En-
glish believe that they know what people,
places, and organizations are. And all of
them believe that they can recognize and
understand instances of these categories
in coherent text.
When two biologists, two linguists, or
two English speakers discuss such texts,
it seems plausible that they have under-
stood such instances in the same way.
Nevertheless, if they are asked to high-
light these instances, the level of inter-
subjective agreement will be shockingly
low.
Similarly depressing results are obtained
in tasks such as phonetic or surface-
phonemic transcription, co-reference an-
notation, identification of animacy, etc.
Things are usually not much better if we
compare annotations produced by the
same individuals on different occasions.
A solution exists, in the practical sense of
producing annotations with high inter-an-
notator agreement scores. The initially-
divergent results of multiple annotations
are discussed and adjudicated, and princi-
ples of interpretation are defined for fu-
ture use. This process is repeated over
and over again, typically for several
months, until the desired level of agree-
ment is obtained, or funding runs out.
At least for simple linguistic annotation
tasks, this process, reminiscent of the de-
velopment of common law, generally
converges (though the residual level of
disagreement may be depressingly high,
especially when multiple judgments must
be cascaded). The resulting annotation
manuals may be hundreds of pages long,
even for fairly limited tasks; and new an-
notators face weeks or months of training
to become competent in learning to apply
them.
There are several obvious ideas about
why this might be true, but most of these
ideas seem to be false. It will be argued
that part of the answer lies in understand-
ing that most linguistic annotation tasks
are not really classification problems, but
rather translation problems. We don’t
normally assume that there is only one
correct translation of a Chinese sentence
into English; nor do we try to make this
true by constructing elaborate translation
guidelines to cover every relevant contin-
gency, though in principle we could.
</bodyText>
<reference confidence="0.45252">
Implications in engineering and science
will be discussed.
Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics, page 2,
Athens, Greece, 30 March, 2009. c�2009 Association for Computational Linguistics
</reference>
<page confidence="0.995547">
2
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.974510">
<title confidence="0.99977">The Annotation Conundrum</title>
<author confidence="0.999427">Mark</author>
<affiliation confidence="0.99995">University of Pennsylvania</affiliation>
<email confidence="0.999825">myl@cis.upenn.edu</email>
<abstract confidence="0.997929615384615">Without lengthy, iterative refinement of guidelines, and equally lengthy and iterative training of annotators, the level of inter-subjective agreement on simple tasks of phonetic, phonological, syntactic, semantic, and pragmatic annotation is shockingly low. This is a significant practical problem in speech and language technology, but it poses questions of interest to psychologists, philosophers of language, and theoretical linguists as well.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Implications in engineering and science will be discussed.</title>
<marker></marker>
<rawString>Implications in engineering and science will be discussed.</rawString>
</citation>
<citation valid="true">
<date>2009</date>
<booktitle>Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics,</booktitle>
<pages>2</pages>
<location>Athens,</location>
<marker>2009</marker>
<rawString>Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics, page 2, Athens, Greece, 30 March, 2009. c�2009 Association for Computational Linguistics</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>