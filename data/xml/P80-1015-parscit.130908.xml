<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000559">
<title confidence="0.97788">
A Linear-time Model of Language Production: some psychological implications
(extended abstract)
</title>
<author confidence="0.820611">
David D. McDonald
</author>
<sectionHeader confidence="0.2528235" genericHeader="abstract">
MIT Artificial Intelligence Laboratory
Cambridge, Massachusetts
</sectionHeader>
<bodyText confidence="0.999721272727273">
Traditional psycholinguistic studies of language
production, using evidence from naturally occurring
errors in speech [1][2] and from real-time studies of
hesitations and reaction time [3][4] have resulted in
models of the levels at which different linguistic units
are represented and the constraints on their scope.
This kind of evidence by itself, however, can tell us
nothing about the character of the process that
manipulates these units, as there are many a priori
alternative computational devices that are equally
capable of implementing the observed behavior. It will
be the thesis of this paper that if principled, non-
trivial models of the language production process are
to be constructed, they must be informed by
computationally motivated constraints. In particular,
the design underlying the linguistic component I have
developed (&amp;quot;MUMBLE&amp;quot;--previously reported in [5][8])
is being investigated as a candidate set of such
constraints.
Any computational theory of production that is to
be interesting as a psycholinguistic model must meet
certain minimal criteria:
</bodyText>
<listItem confidence="0.999400777777778">
(1) Producing utterances incrementally, in their
normal left-to-right order, and with a well-
defined &amp;quot;point-of-no-return&amp;quot; since words
once said can not be invisibly taken back:
(2) Making the transition from the non-
linguistic &amp;quot;message&amp;quot;-level representation to
the utterance via a linguistically structured
buffer of only limited size: people are not
capable of linguistic precognition and can
</listItem>
<footnote confidence="0.992369714285714">
1. This report describes research done at the Artificial
Intelligence Laboratory of the Massachusetts Institute of
Technology. Support for the laboratory&apos;s artificial
intelligence research is provided in part by the Advanced
Research Projects Agency of the Department of Defence
under Office of Naval Research contract
NO0014-75-C-0643.
</footnote>
<listItem confidence="0.8345884">
readily &amp;quot;talk themselves into a corner&amp;quot;Z
(3) Grammatical robustness: people make very
few grammatical errors as compared with
lexical selection or planning errors (&amp;quot;false
starts&amp;quot;) [7].
</listItem>
<bodyText confidence="0.999970727272727">
Theories which incorporate these properties as an
inevitable consequence of independently motivated
structural properties will be more highly valued than
those which only stipulate them.
The design incorporated in MUMBLE has all of
these properties; they follow from two key
intertwined stipulations—hypotheses—motivated by
intrinsic differences in the kinds of decisions made
during language production and by the need for an
efficient representation of the information on which
the decisions depend (see [8] for elaboration).
</bodyText>
<listItem confidence="0.9693168">
(1) The execution time of the process is linear in
the number of elements in the input
message, i.e. the realization decision for each
element is made only once and may not be
revised.
</listItem>
<bodyText confidence="0.938415166666667">
(2) The representation for pending realization
decisions and planned linguistic actions (the
results of earlier decisions) is a surface-level
syntactic phrase structure augmented by
explicit labelings for its constituent
positions (hereafter referred to as the tree).3
This working-structure is used
simultaniously for control (determining
what action to take next), for specifying
constraints (what choices of actions are
Z. In addition, one inescapable conclusion of the research
on speech-errors is that the linguistic representation(s)
used during the production process must be capable of
representing positions independently of the units (lexical or
phonetic) that occupy them. This is a serious problem for
ATN-based theories of production since they have no
representation for linguistic structures that is independent
front their representation of the state of the process.
3. The leaves of this tree initially contain to-be-realized
message elements. These are replaced by syntactic/lexical
structures as the tree is refined in a top-down,
left-to-right traversal. Words are produced as they are
reached at (new) leaves, and grammatical actions are taken
as directed by the annotation on the traversed regions.
</bodyText>
<page confidence="0.996435">
55
</page>
<figureCaption confidence="0.4977265">
ruled out because of earlier decisions), for
the representation of linguistic context, and
for the implementation of actions motivated
only by grammatical convention (e.g.
agreement, word-order within the clause,
morphological specializations; see [6]).
</figureCaption>
<bodyText confidence="0.95613652">
The requirement of linear time rules out any
decision-making techniques that would require
arbitrary scanning of either message or tree. Its
corollary. &amp;quot;indelibility&amp;quot;.4 requires that message be
realized incrementally according to the relative
importance of the speaker&apos;s intentions. The paper will
discuss how as a consequence of these properties
decision-making is forced to take place within a kind
of blinders: restrictions on the information available
for decision-making and on the possibilities for
monitoring and for invisible self-repair, all describable
In terms of the usual linguistic vocabulary. A further
consequence is the adoption of a &amp;quot;lexicalist&amp;quot; position on
transformations (see [9]), i.e. once a syntactic
construction has been instantiated in the tree, the
relative position of its constituents cannot be modified;
therefore any &amp;quot;transformations&amp;quot; that apply must do so
at the moment the construction is instantiated and on
the basis of only the information available at that time.
This is because the tree is not buffer of objects. but a
program of scheduled events.
Noticed regularities in speech-errors have
counter-parts in MUMBLE&apos;s design5 which, to the
extent that it is independently motivated. may provide
an explanation for them. One example is the
</bodyText>
<tableCaption confidence="0.533207333333333">
4. I.e. decisions are not subject to backup--&amp;quot;they are
written in indelible ink&amp;quot;. This is also a property of
Marcus&apos;s &amp;quot;deterministic&amp;quot; parser. It is intriguing to
speculate that indelibility may be a key characteristic of
Psychologically plausible performance theories of natural
language.
5. MUMBLE produces texts, not speech. Consequently it
has no knowledge of syllable structure or intonation and
can make no specific contributions to the explanation of
errors at that level.
phenomena of combined-form errors: word-exchange
errors where functional morphemes such as plural or
tense are &amp;quot;stranded&amp;quot; at their original positions, e.g.
&amp;quot;My locals are more variable than that.&amp;quot;
Intended: &amp;quot;...variables are more local&amp;quot;
&amp;quot;Why don&apos;t we go to the 24hr. Star Marked and
you can see my friend checking cashes.&amp;quot;
Intended: &amp;quot;...cashing checks.&amp;quot;
</tableCaption>
<bodyText confidence="0.99742732">
One of the things to be explained about these errors is
why the two classes of morphemes are distinguished--
why does the &amp;quot;exchanging mechanism&amp;quot; effect the one
and not the other? The form of the answer to this
question is generally agreed upon: two independent
representations are being manipulated and the
mechanism applies to only one of them. MUMBLE
already employs two representations of roughly the
correct distribution, namely the phrase structure tree
(defining positions and grammatical properties) and
the message (whose elements occupy the positions and
prompt the selection of words). By incorporating
specific evidence from speech-errors into MUMBLE&apos;s
framework (such as whether the quantifier all
participates in exchanges), it is possible to perform
synthetic experiments to explore the impact of such a
hypothesis on other aspects of the design. The
interaction with psycholinguistics thus becomes a
two-way street.
The full paper6 will develop the notion of a
linear-time production process: how it is actomplished
and the specific limitations that it imposes, and will
explore its implications as a potential explanation for
certain classes of speech-errors, certain hesitation and
self-correction data, and certain linguistic constra_nts.
</bodyText>
<footnote confidence="0.453057666666667">
6. Regretably, the completion of this paper has been
delayed in order for the author to give priority to his
dissertation.
</footnote>
<page confidence="0.998116">
56
</page>
<sectionHeader confidence="0.978103" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999949">
[1] Garrett. M.F. (1979) &amp;quot;Levels of Processing in
Sentence Production&amp;quot;, in Butterworth ed.
Language Production Volume 1, Academic Press.
[2] Shattuck Hufnagel, S. (1976) Speech Errors and
Sentence Production Ph.D. Dissertation.
Department of Psychology, MIT.
[3] Ford, M. &amp; Holmes V.M. (1978) &amp;quot;Planning units and
syntax in sentence production&amp;quot;, Cognition 6, 35-
53.
[4] Ford M. (1979) &amp;quot;Sentence Planning Units:
Implications for the speaker&apos;s representation of
meaningful relations underlying sentences&amp;quot;,
Occasional Paper 2, Center for Cognitive Science,
MIT.
[5] McDonald, D.D. (1978) &amp;quot;Making subsequent
references: syntactic and rhetorical constraints&amp;quot;,
TINLAP-2. University of Illinois.
[6] (1978) &amp;quot;Language generation:
Automatic Control of Grammatical Detail&amp;quot;, COLING-
78, Bergen, Norway.
[7] Fay, D. (1977) &amp;quot;Transformational Errors&amp;quot;,
International Congress of Linguistics. Vienna.
Austria.
[8] McDonald D.D. (in preparation) Natural Language
Production as a Process of Decision-making
Under Constraint Ph.D. Dissertation, Department
of Electrical Engineering and Computer Science.
MIT.
[9] Bresnan, J. (1978) &amp;quot;Toward a realistic theory of
grammar&amp;quot;, in Bresnan. Miller. &amp; Halle eds.
Linguistic Theory and Psychological Reality MIT
Press.
</reference>
<page confidence="0.999142">
57
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.017176">
<title confidence="0.744704">A Linear-time Model of Language Production: some psychological implications</title>
<note confidence="0.771603">(extended abstract)</note>
<author confidence="0.999838">David D McDonald</author>
<affiliation confidence="0.999982">MIT Artificial Intelligence Laboratory</affiliation>
<address confidence="0.950613">Cambridge, Massachusetts</address>
<abstract confidence="0.995423093167702">Traditional psycholinguistic studies of language production, using evidence from naturally occurring errors in speech [1][2] and from real-time studies of hesitations and reaction time [3][4] have resulted in models of the levels at which different linguistic units are represented and the constraints on their scope. This kind of evidence by itself, however, can tell us nothing about the character of the process that these units, as there are many a alternative computational devices that are equally capable of implementing the observed behavior. It will be the thesis of this paper that if principled, nontrivial models of the language production process are to be constructed, they must be informed by computationally motivated constraints. In particular, the design underlying the linguistic component I have developed (&amp;quot;MUMBLE&amp;quot;--previously reported in [5][8]) is being investigated as a candidate set of such constraints. Any computational theory of production that is to be interesting as a psycholinguistic model must meet certain minimal criteria: (1) Producing utterances incrementally, in their normal left-to-right order, and with a welldefined &amp;quot;point-of-no-return&amp;quot; since words once said can not be invisibly taken back: (2) Making the transition from the nonlinguistic &amp;quot;message&amp;quot;-level representation to the utterance via a linguistically structured buffer of only limited size: people are not capable of linguistic precognition and can 1. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for the laboratory&apos;s artificial intelligence research is provided in part by the Advanced Research Projects Agency of the Department of Defence under Office of Naval Research contract NO0014-75-C-0643. &amp;quot;talk themselves into a (3) Grammatical robustness: people make very few grammatical errors as compared with lexical selection or planning errors (&amp;quot;false starts&amp;quot;) [7]. Theories which incorporate these properties as an inevitable consequence of independently motivated structural properties will be more highly valued than those which only stipulate them. The design incorporated in MUMBLE has all of these properties; they follow from two key intertwined stipulations—hypotheses—motivated by intrinsic differences in the kinds of decisions made during language production and by the need for an efficient representation of the information on which the decisions depend (see [8] for elaboration). The execution time of the process is in the number of elements in the input the realization decision for each element is made only once and may not be revised. (2) The representation for pending realization decisions and planned linguistic actions (the results of earlier decisions) is a surface-level syntactic phrase structure augmented by explicit labelings for its constituent (hereafter referred to as This working-structure is used simultaniously for control (determining what action to take next), for specifying constraints (what choices of actions are Z. In addition, one inescapable conclusion of the research on speech-errors is that the linguistic representation(s) used during the production process must be capable of representing positions independently of the units (lexical or phonetic) that occupy them. This is a serious problem for ATN-based theories of production since they have no representation for linguistic structures that is independent front their representation of the state of the process. 3. The leaves of this tree initially contain to-be-realized message elements. These are replaced by syntactic/lexical structures as the tree is refined in a top-down, left-to-right traversal. Words are produced as they are reached at (new) leaves, and grammatical actions are taken as directed by the annotation on the traversed regions. 55 ruled out because of earlier decisions), for the representation of linguistic context, and for the implementation of actions motivated only by grammatical convention (e.g. agreement, word-order within the clause, morphological specializations; see [6]). The requirement of linear time rules out any decision-making techniques that would require arbitrary scanning of either message or tree. Its requires that message be realized incrementally according to the relative importance of the speaker&apos;s intentions. The paper will as a consequence of these properties decision-making is forced to take place within a kind on the information available for decision-making and on the possibilities for monitoring and for invisible self-repair, all describable In terms of the usual linguistic vocabulary. A further consequence is the adoption of a &amp;quot;lexicalist&amp;quot; position on transformations (see [9]), i.e. once a syntactic construction has been instantiated in the tree, the position of its constituents cannot therefore any &amp;quot;transformations&amp;quot; that apply must do so at the moment the construction is instantiated and on the basis of only the information available at that time. This is because the tree is not buffer of objects. but a program of scheduled events. Noticed regularities in speech-errors have in MUMBLE&apos;s which, to the extent that it is independently motivated. may provide explanation for example is the 4. I.e. decisions are not subject to backup--&amp;quot;they are written in indelible ink&amp;quot;. This is also a property of Marcus&apos;s &amp;quot;deterministic&amp;quot; parser. It is intriguing to speculate that indelibility may be a key characteristic of Psychologically plausible performance theories of natural language. 5. MUMBLE produces texts, not speech. Consequently it has no knowledge of syllable structure or intonation and can make no specific contributions to the explanation of errors at that level. of errors: errors where functional morphemes such as plural or tense are &amp;quot;stranded&amp;quot; at their original positions, e.g. locals are more variablethan that.&amp;quot; are more local&amp;quot; &amp;quot;Why don&apos;t we go to the 24hr. Star Marked and you can see my friend checking cashes.&amp;quot; checks.&amp;quot; One of the things to be explained about these errors is the two morphemes are distinguished-why does the &amp;quot;exchanging mechanism&amp;quot; effect the one and not the other? The form of the answer to this question is generally agreed upon: two independent representations are being manipulated and the mechanism applies to only one of them. MUMBLE already employs two representations of roughly the correct distribution, namely the phrase structure tree (defining positions and grammatical properties) and the message (whose elements occupy the positions and prompt the selection of words). By incorporating specific evidence from speech-errors into MUMBLE&apos;s (such as whether the quantifier in exchanges), it is perform synthetic experiments to explore the impact of such a on other aspects of The interaction with psycholinguistics thus becomes a two-way street. full will develop the notion of a linear-time production process: how it is actomplished and the specific limitations that it imposes, and will explore its implications as a potential explanation for speech-errors, certain hesitation and self-correction data, and certain linguistic constra_nts. 6. Regretably, the completion of this paper has been delayed in order for the author to give priority to his dissertation.</abstract>
<note confidence="0.951578076923077">56 References [1] Garrett. M.F. (1979) &amp;quot;Levels of Processing in Sentence Production&amp;quot;, in Butterworth ed. Language Production Volume 1, Academic Press. [2] Shattuck Hufnagel, S. (1976) Speech Errors and Sentence Production Ph.D. Dissertation. Department of Psychology, MIT. [3] Ford, M. &amp; Holmes V.M. (1978) &amp;quot;Planning units and in sentence production&amp;quot;, 35- 53. [4] Ford M. (1979) &amp;quot;Sentence Planning Units: Implications for the speaker&apos;s representation of</note>
<abstract confidence="0.687167166666667">meaningful relations underlying sentences&amp;quot;, Occasional Paper 2, Center for Cognitive Science, MIT. [5] McDonald, D.D. (1978) &amp;quot;Making subsequent references: syntactic and rhetorical constraints&amp;quot;, TINLAP-2. University of Illinois.</abstract>
<note confidence="0.7809205">[6] (1978) &amp;quot;Language generation: Automatic Control of Grammatical Detail&amp;quot;, COLING- 78, Bergen, Norway. [7] Fay, D. (1977) &amp;quot;Transformational Errors&amp;quot;, International Congress of Linguistics. Vienna. Austria. [8] McDonald D.D. (in preparation) Natural Language Production as a Process of Decision-making Under Constraint Ph.D. Dissertation, Department of Electrical Engineering and Computer Science. MIT. [9] Bresnan, J. (1978) &amp;quot;Toward a realistic theory of in Bresnan. Miller. &amp; Halle Linguistic Theory and Psychological Reality MIT Press. 57</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M F</author>
</authors>
<title>Levels of Processing in Sentence Production&amp;quot;,</title>
<date>1979</date>
<booktitle>in Butterworth ed. Language Production</booktitle>
<volume>1</volume>
<publisher>Academic Press.</publisher>
<marker>[1]</marker>
<rawString>Garrett. M.F. (1979) &amp;quot;Levels of Processing in Sentence Production&amp;quot;, in Butterworth ed. Language Production Volume 1, Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shattuck Hufnagel</author>
<author>S</author>
</authors>
<title>Speech Errors and Sentence Production</title>
<date>1976</date>
<institution>Ph.D. Dissertation. Department of Psychology, MIT.</institution>
<marker>[2]</marker>
<rawString>Shattuck Hufnagel, S. (1976) Speech Errors and Sentence Production Ph.D. Dissertation. Department of Psychology, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ford</author>
<author>V M Holmes</author>
</authors>
<title>Planning units and syntax in sentence production&amp;quot;,</title>
<date>1978</date>
<journal>Cognition</journal>
<volume>6</volume>
<pages>35--53</pages>
<marker>[3]</marker>
<rawString>Ford, M. &amp; Holmes V.M. (1978) &amp;quot;Planning units and syntax in sentence production&amp;quot;, Cognition 6, 35-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ford</author>
</authors>
<title>Sentence Planning Units: Implications for the speaker&apos;s representation of meaningful relations underlying sentences&amp;quot;,</title>
<date>1979</date>
<journal>Occasional Paper</journal>
<volume>2</volume>
<institution>Center for Cognitive Science, MIT.</institution>
<marker>[4]</marker>
<rawString>Ford M. (1979) &amp;quot;Sentence Planning Units: Implications for the speaker&apos;s representation of meaningful relations underlying sentences&amp;quot;, Occasional Paper 2, Center for Cognitive Science, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D McDonald</author>
</authors>
<title>Making subsequent references: syntactic and rhetorical constraints&amp;quot;, TINLAP-2.</title>
<date>1978</date>
<institution>University of Illinois.</institution>
<contexts>
<context position="1060" citStr="[5]" startWordPosition="149" endWordPosition="149">ed and the constraints on their scope. This kind of evidence by itself, however, can tell us nothing about the character of the process that manipulates these units, as there are many a priori alternative computational devices that are equally capable of implementing the observed behavior. It will be the thesis of this paper that if principled, nontrivial models of the language production process are to be constructed, they must be informed by computationally motivated constraints. In particular, the design underlying the linguistic component I have developed (&amp;quot;MUMBLE&amp;quot;--previously reported in [5][8]) is being investigated as a candidate set of such constraints. Any computational theory of production that is to be interesting as a psycholinguistic model must meet certain minimal criteria: (1) Producing utterances incrementally, in their normal left-to-right order, and with a welldefined &amp;quot;point-of-no-return&amp;quot; since words once said can not be invisibly taken back: (2) Making the transition from the nonlinguistic &amp;quot;message&amp;quot;-level representation to the utterance via a linguistically structured buffer of only limited size: people are not capable of linguistic precognition and can 1. This repo</context>
</contexts>
<marker>[5]</marker>
<rawString>McDonald, D.D. (1978) &amp;quot;Making subsequent references: syntactic and rhetorical constraints&amp;quot;, TINLAP-2. University of Illinois.</rawString>
</citation>
<citation valid="true">
<title>Language generation: Automatic Control of Grammatical Detail&amp;quot;,</title>
<date>1978</date>
<location>COLING78, Bergen, Norway.</location>
<contexts>
<context position="4358" citStr="[6]" startWordPosition="623" endWordPosition="623">e process. 3. The leaves of this tree initially contain to-be-realized message elements. These are replaced by syntactic/lexical structures as the tree is refined in a top-down, left-to-right traversal. Words are produced as they are reached at (new) leaves, and grammatical actions are taken as directed by the annotation on the traversed regions. 55 ruled out because of earlier decisions), for the representation of linguistic context, and for the implementation of actions motivated only by grammatical convention (e.g. agreement, word-order within the clause, morphological specializations; see [6]). The requirement of linear time rules out any decision-making techniques that would require arbitrary scanning of either message or tree. Its corollary. &amp;quot;indelibility&amp;quot;.4 requires that message be realized incrementally according to the relative importance of the speaker&apos;s intentions. The paper will discuss how as a consequence of these properties decision-making is forced to take place within a kind of blinders: restrictions on the information available for decision-making and on the possibilities for monitoring and for invisible self-repair, all describable In terms of the usual linguistic v</context>
</contexts>
<marker>[6]</marker>
<rawString>(1978) &amp;quot;Language generation: Automatic Control of Grammatical Detail&amp;quot;, COLING78, Bergen, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Fay</author>
</authors>
<title>Transformational Errors&amp;quot;, International Congress of Linguistics.</title>
<date>1977</date>
<location>Vienna.</location>
<contexts>
<context position="2168" citStr="[7]" startWordPosition="306" endWordPosition="306">er of only limited size: people are not capable of linguistic precognition and can 1. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for the laboratory&apos;s artificial intelligence research is provided in part by the Advanced Research Projects Agency of the Department of Defence under Office of Naval Research contract NO0014-75-C-0643. readily &amp;quot;talk themselves into a corner&amp;quot;Z (3) Grammatical robustness: people make very few grammatical errors as compared with lexical selection or planning errors (&amp;quot;false starts&amp;quot;) [7]. Theories which incorporate these properties as an inevitable consequence of independently motivated structural properties will be more highly valued than those which only stipulate them. The design incorporated in MUMBLE has all of these properties; they follow from two key intertwined stipulations—hypotheses—motivated by intrinsic differences in the kinds of decisions made during language production and by the need for an efficient representation of the information on which the decisions depend (see [8] for elaboration). (1) The execution time of the process is linear in the number of eleme</context>
</contexts>
<marker>[7]</marker>
<rawString>Fay, D. (1977) &amp;quot;Transformational Errors&amp;quot;, International Congress of Linguistics. Vienna. Austria.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D D McDonald</author>
</authors>
<title>(in preparation) Natural Language Production as a Process of Decision-making</title>
<institution>Under Constraint Ph.D. Dissertation, Department of Electrical Engineering and Computer Science. MIT.</institution>
<contexts>
<context position="1063" citStr="[8]" startWordPosition="149" endWordPosition="149">and the constraints on their scope. This kind of evidence by itself, however, can tell us nothing about the character of the process that manipulates these units, as there are many a priori alternative computational devices that are equally capable of implementing the observed behavior. It will be the thesis of this paper that if principled, nontrivial models of the language production process are to be constructed, they must be informed by computationally motivated constraints. In particular, the design underlying the linguistic component I have developed (&amp;quot;MUMBLE&amp;quot;--previously reported in [5][8]) is being investigated as a candidate set of such constraints. Any computational theory of production that is to be interesting as a psycholinguistic model must meet certain minimal criteria: (1) Producing utterances incrementally, in their normal left-to-right order, and with a welldefined &amp;quot;point-of-no-return&amp;quot; since words once said can not be invisibly taken back: (2) Making the transition from the nonlinguistic &amp;quot;message&amp;quot;-level representation to the utterance via a linguistically structured buffer of only limited size: people are not capable of linguistic precognition and can 1. This report </context>
<context position="2679" citStr="[8]" startWordPosition="378" endWordPosition="378">rammatical errors as compared with lexical selection or planning errors (&amp;quot;false starts&amp;quot;) [7]. Theories which incorporate these properties as an inevitable consequence of independently motivated structural properties will be more highly valued than those which only stipulate them. The design incorporated in MUMBLE has all of these properties; they follow from two key intertwined stipulations—hypotheses—motivated by intrinsic differences in the kinds of decisions made during language production and by the need for an efficient representation of the information on which the decisions depend (see [8] for elaboration). (1) The execution time of the process is linear in the number of elements in the input message, i.e. the realization decision for each element is made only once and may not be revised. (2) The representation for pending realization decisions and planned linguistic actions (the results of earlier decisions) is a surface-level syntactic phrase structure augmented by explicit labelings for its constituent positions (hereafter referred to as the tree).3 This working-structure is used simultaniously for control (determining what action to take next), for specifying constraints (w</context>
</contexts>
<marker>[8]</marker>
<rawString>McDonald D.D. (in preparation) Natural Language Production as a Process of Decision-making Under Constraint Ph.D. Dissertation, Department of Electrical Engineering and Computer Science. MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bresnan</author>
</authors>
<title>Toward a realistic theory of grammar&amp;quot;,</title>
<date>1978</date>
<booktitle>Linguistic Theory and Psychological Reality</booktitle>
<editor>in Bresnan. Miller. &amp; Halle eds.</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="5061" citStr="[9]" startWordPosition="723" endWordPosition="723">ary scanning of either message or tree. Its corollary. &amp;quot;indelibility&amp;quot;.4 requires that message be realized incrementally according to the relative importance of the speaker&apos;s intentions. The paper will discuss how as a consequence of these properties decision-making is forced to take place within a kind of blinders: restrictions on the information available for decision-making and on the possibilities for monitoring and for invisible self-repair, all describable In terms of the usual linguistic vocabulary. A further consequence is the adoption of a &amp;quot;lexicalist&amp;quot; position on transformations (see [9]), i.e. once a syntactic construction has been instantiated in the tree, the relative position of its constituents cannot be modified; therefore any &amp;quot;transformations&amp;quot; that apply must do so at the moment the construction is instantiated and on the basis of only the information available at that time. This is because the tree is not buffer of objects. but a program of scheduled events. Noticed regularities in speech-errors have counter-parts in MUMBLE&apos;s design5 which, to the extent that it is independently motivated. may provide an explanation for them. One example is the 4. I.e. decisions are n</context>
</contexts>
<marker>[9]</marker>
<rawString>Bresnan, J. (1978) &amp;quot;Toward a realistic theory of grammar&amp;quot;, in Bresnan. Miller. &amp; Halle eds. Linguistic Theory and Psychological Reality MIT Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>