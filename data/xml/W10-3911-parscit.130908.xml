<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.80071875">
Adverse—Effect Relations Extraction from
Massive Clinical Records
Yasuhide Miura a, Eiji Aramaki b, Tomoko Ohkuma a, Masatsugu Tonoike a,
Daigo Sugihara &amp;quot;, Hiroshi Masuichi&amp;quot; and Kazuhiko Ohe `
</title>
<author confidence="0.746018">
&amp;quot; Fuji Xerox Co., Ltd.
</author>
<affiliation confidence="0.848416">
b Center for Knowledge Structuring, University of Tokyo
`University of Tokyo Hospital
</affiliation>
<email confidence="0.92775675">
yasuhide.miura@fujixerox.co.jp, eiji.aramaki@gmail.com,
{ohkuma.tomoko,masatsugu.tonoike,daigo.sugihara,
hiroshi.masuichi}@fujixerox.co.jp,
kohe@hcc.h.u—tokyo.ac.jp
</email>
<sectionHeader confidence="0.995408" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999979321428571">
The rapid spread of electronic health
records raised an interest to large-scale
information extraction from clinical
texts. Considering such a background,
we are developing a method that can
extract adverse drug event and effect
(adverse—effect) relations from massive
clinical records. Adverse—effect rela-
tions share some features with relations
proposed in previous relation extrac-
tion studies, but they also have unique
characteristics. Adverse—effect rela-
tions are usually uncertain. Not even
medical experts can usually determine
whether a symptom that arises after a
medication represents an adverse—
effect relation or not. We propose a
method to extract adverse—effect rela-
tions using a machine-learning tech-
nique with dependency features. We
performed experiments to extract ad-
verse—effect relations from 2,577 clini-
cal texts, and obtained F,-score of
37.54 with an optimal parameters and
F,-score of 34.90 with automatically
tuned parameters. The results also
show that dependency features increase
the extraction F,-score by 3.59.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992579095238095">
The widespread use of electronic health rec-
ords (EHR) made clinical texts to be stored as
computer processable data. EHRs contain im-
portant information about patients&apos; health.
However, extracting clinical information from
EHRs is not easy because they are likely to be
written in a natural language.
We are working on a task to extract adverse
drug event and effect relations from clinical
records. Usually, the association between a
drug and its adverse—effect relation is investi-
gated using numerous human resources, cost-
ing much time and money. The motivation of
our task comes from this situation. An example
of the task is presented in Figure 1. We defined
an adverse—effect relation as a relation that
holds between a drug entity and a symptom
entity. The sentence illustrates the occurrence
of the adverse—effect hepatic disorder by the
Singulair medication.
A hepatic disorder found was suspected drug-induced and the Singulair was stopped.
</bodyText>
<figure confidence="0.5006525">
symptom drug
adverse—effect relation
</figure>
<figureCaption confidence="0.989007">
Figure 1. Example of an adverse—effect relation.
</figureCaption>
<page confidence="0.992502">
75
</page>
<note confidence="0.740132333333333">
Proceedings of the Second Workshop on NLP Challenges in the Information Explosion Era (NLPIX 2010), pages 75–83,
Beijing, August 2010
ACTOS 30 recovered HbAlc to 6.5% but an edema appeared after the medication.
</note>
<figure confidence="0.7483875">
drug symptom
adverse-effect relation
</figure>
<figureCaption confidence="0.998916">
Figure 2. The example of an adverse-effect relation where the suspicion is not stated.
</figureCaption>
<figure confidence="0.989145666666667">
nominal subject nominal subject
A suspected drug-induced hepatic disorder was found and the Singulair was stopped.
conjunct
nominal subject nominal subject
ACTOS 30 recovered HbAlc to 6.5% but an edema appeared after the medication.
conjunct
</figure>
<figureCaption confidence="0.999964">
Figure 3. The example of a similarity within dependency structures.
</figureCaption>
<bodyText confidence="0.999964527272728">
A salient characteristic of adverse–effect re-
lations is that they are usually uncertain. The
sentence in the example states that the hepatic
disorder is suspected drug-induced, which
means the hepatic disorder is likely to present
an adverse–effect relation. Figure 2 presents an
example in which an adverse–effect relation is
suspected, but words to indicate the suspicion
are not stated. The two effects of the drug––the
recovery of HbAlc and the appearance of the
edema––are expressed merely as observation
results in this sentence. The recovery of
HbAlc is an expected effect of the drug and
the appearance of the edema probably repre-
sents an adverse–effect case. The uncertain
nature of adverse–effect relations often engen-
ders the statement of an adverse–effect rela-
tion as an observed fact. A sentence includ-
ing an adverse–effect relation occasionally be-
comes long to list all observations that ap-
peared after administration of a medication.
Whether an interpretation that expresses an
adverse–effect relation, such as drug-induced
or suspected to be an adverse–effect, exists in a
clinical record or not depends on a person who
writes it. However, an adverse–effect relation
is associated with an undesired effect of a
medication. Its appearance would engender an
extra action (e.g. stopped in the first example)
or lead to an extra indication (e.g. but ... ap-
peared in the second example). Proper han-
dling of this extra information is likely to boost
the extraction accuracy.
The challenge of this study is to capture re-
lations with various certainties. To establish
this goal, we used a dependency structure for
the adverse–effect relation extraction method.
Adverse–effect statements are assumed to
share a dependency structure to a certain
degree. For example, if we obtain the depend-
ency structures as shown in Figure 3, then we
can easily determine that the structures are
similar. Of course, obtaining such perfect pars-
ing results is not always possible. A statistical
syntactic parser is known to perform badly if a
text to be parsed belongs to a domain which
differs from a domain on which the parser is
trained (Gildea, 2001). A statistical parser will
likely output incomplete results in these texts
and will likely have a negative effect on rela-
tion extraction methods which depend on it.
The specified research topic of this study is to
investigate whether incomplete dependency
structures are effective and how they behave in
the extraction of uncertain relations.
</bodyText>
<page confidence="0.990094">
76
</page>
<sectionHeader confidence="0.999118" genericHeader="introduction">
2 Related Works
</sectionHeader>
<bodyText confidence="0.999858977777778">
Various studies have been done to extract se-
mantic information from texts. SemEval-2007
Task:04 (Girju et al., 2007) is a task to extract
semantic relations between nominals. The task
includes &amp;quot;Cause—Effect&amp;quot; relation extraction,
which shares some similarity with a task that
will be presented herein. Saeger et al. (2008)
presented a method to extract potential trou-
bles or obstacles related to the use of a given
object. This relation can be interpreted as a
more general relation of the adverse—effect
relation. The protein—protein interaction (PPI)
annotation extraction task of BioCreative II
(Krallinger et al., 2008) is a task to extract PPI
from PubMed abstracts. BioNLP&apos;09 Shared
Task on Event Extraction (Kim et al., 2009) is
a task to extract bio-molecular events (bio-
events) from the GENIA event corpus.
Similar characteristics to those of the ad-
verse—effect relation are described in previous
reports in the bio-medical domain. Friedman et
al. (1994) describes the certainty in findings of
clinical radiology. Certainty is also known in
scientific papers of biomedical domains as
speculation (Light et al., 2004). Vincze et al.
(2008) are producing a freely available corpus
including annotations of uncertainty along with
its scope.
Dependency structure feature which we uti-
lized to extract adverse—effect relations are
widely used in relation extraction tasks. We
present previous works which used syntac-
tic/dependency information as a feature of a
statistical method. Beamer et al. (2007), Giuli-
ano et al. (2007), and Hendrickx et al. (2007)
all used syntactic information with machine
learning techniques in SemEval-2007 Task:04
and achieved good performance. Riedel et al.
(2009) used dependency path features with a
statistical relational learning method in Bi-
oNLP&apos;09 Shared Task on Event Extraction and
achieved the best performance in the event en-
richment subtask. Miyao et al. (2008) com-
pared syntactic information of various statisti-
cal parsers on PPI.
</bodyText>
<sectionHeader confidence="0.995883" genericHeader="method">
3 Corpus
</sectionHeader>
<bodyText confidence="0.999416">
We produced an annotated corpus of adverse—
effect relations to develop and test an adverse—
effect relation extraction method. This section
presents a description of details of the corpus.
</bodyText>
<subsectionHeader confidence="0.998466">
3.1 Texts Comprising the Corpus
</subsectionHeader>
<bodyText confidence="0.999972368421053">
We used a discharge summary among various
documents in a hospital as the source data of
the task. The discharge summary is a docu-
ment created by a doctor or another medical
expert at the conclusion of a hospital stay.
Medications performed during a stay are writ-
ten in discharge summaries. If adverse—effect
relations were observed during the stay, they
are likely to be expressed in free text. Texts
written in discharge summaries tend to be writ-
ten more roughly than texts in newspaper arti-
cles or scientific papers. For example, the
amounts of medications are often written in a
name-value list as shown below:
&amp;quot;When admitted to the hospital, Artist 6 mglx,
Diovan 70 mglx, Norvasac 5 mglx and BP
was 145/83, but after dialysis, BP showed a
decreasing tendency and in 5/14 Norvasac was
reduced to 2.5 mglx.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.94696">
3.2 Why Adverse—Effect Relation Extrac-
</subsectionHeader>
<bodyText confidence="0.985868538461539">
tion from Discharge Summaries is
Important
In many countries, adverse—effects are investi-
gated through multiple phases of clinical trials,
but unexpected adverse—effects occur in actual
medications. One reason why this occurs is
that drugs are often used in combination with
others in actual medications. Clinical trials
usually target single drug use. For that reason,
the combinatory uses of drugs occasionally
engender unknown effects. This situation natu-
rally motivates automatic adverse—effect rela-
tion extraction from actual patient records.
</bodyText>
<page confidence="0.984503">
77
</page>
<figure confidence="0.968110166666667">
3,012
discharge
summaries
Contain keywords?
YES NO
SET-A (annotated corpus) SET-B
</figure>
<figureCaption confidence="0.9849355">
Figure 4. The overview of the summary
selection.
</figureCaption>
<subsectionHeader confidence="0.99961">
3.3 Corpus Size
</subsectionHeader>
<bodyText confidence="0.999974863636363">
We collected 3,012 discharge summaries1 writ-
ten in Japanese from all departments of a hos-
pital. To reduce a cost to survey the occurrence
of adverse—effects in the summaries, we first
split the summaries into two sets: SET-A,
which contains keywords related to adverse—
effects and SET-B, which do not contain the
keywords. The keywords we used were &amp;quot;stop,
change, adverse effect&amp;quot;, and they were chosen
based on a heuristic. The keyword filtering
resulted to SET-A with 435 summaries and
SET-B with 2,577 summaries. Regarding SET-
A, we randomly sampled 275 summaries and
four annotators annotated adverse—effect in-
formation to these summaries to create the ad-
verse—effect relation corpus. For SET-B, the
four annotators checked the small portion of
the summaries. Cases of ambiguity were re-
solved through discussion, and even suspicious
adverse—effect relations were annotated in the
corpus as positive data. The overview of the
summary selection is presented in Figure 4.
</bodyText>
<tableCaption confidence="0.68043425">
1 All private information was removed from them.
The definition of private information was referred
from the HIPAA guidelines.
Table 1. Markup scheme.
</tableCaption>
<bodyText confidence="0.977706888888889">
tag Definition and Examples
drug The expression of an administrated
drug: e.g. Levofloxacin, Flexeril.
symptom The expression of a disease or
symptom: e.g. endometrial cancer,
headache. This tag covers not only a
noun phrase but also a verb phrase
such as &amp;quot;&lt;symptom&gt;feels a pain in
front of the head&lt;/symptom&gt;&amp;quot;.
</bodyText>
<tableCaption confidence="0.491551111111111">
Table 2. Annotation examples.
&lt;drug relation=&amp;quot;1&amp;quot;&gt;Ridora&lt;/drug&gt; resumed
because it is associated with an &lt;symptom
relation=&amp;quot;1&amp;quot;&gt;eczematous rash&lt;/symptom&gt;.
&lt;drug relation=&amp;quot;1&amp;quot;&gt;ACTOS(30)&lt;/drug&gt; brought
both &lt;symptom relation=&amp;quot;1&amp;quot;&gt;headache&lt;symptom&gt;
and &lt;symptom relation=&amp;quot;1&amp;quot;&gt;insomnia&lt;/symptom&gt;.
* If a drug has two or more adverse-effects,
symptoms take a same relation ID.
</tableCaption>
<subsectionHeader confidence="0.9497035">
3.4 Quantities of Adverse—Effects in Clin-
ical Texts
</subsectionHeader>
<bodyText confidence="0.999937818181818">
55.6% (=158/275) of the summaries in SET-A
contained adverse—effects. 11.3% (=6/53) of
the summaries in SET-B contained adverse—
effects. Since the ratio of SET-A:SET-B is
14.4:85.6, we estimated that about 17.7%
(=0.556X0.144+0.113X0.856) of the summar-
ies contain adverse—effects. Even considering
that a summary may only include suspected
adverse—effects, we think that discharge sum-
maries are a valuable resource to explore ad-
verse—effects.
</bodyText>
<subsectionHeader confidence="0.900002">
3.5 Annotated Information
</subsectionHeader>
<bodyText confidence="0.999488666666667">
We annotated information of two kinds to the
corpus: term information and relation infor-
mation.
</bodyText>
<listItem confidence="0.50971">
(1) Term Annotation
</listItem>
<bodyText confidence="0.999543">
Term annotation includes two tags: a tag to
express a drug and a tag to express a drug ef-
fect. Table 1 presents the definition. In the
corpus, 2,739 drugs and 12,391 effects were
annotated.
</bodyText>
<listItem confidence="0.508719">
(2) Relation Annotation
</listItem>
<bodyText confidence="0.9964405">
Adverse—effect relations are annotated as the
&amp;quot;relation&amp;quot; attribute of the term tags. We repre-
sent the effect of a drug as a relation between a
drug tag and a symptom tag. Table 2 presents
</bodyText>
<figure confidence="0.999460944444444">
Random sampling
Contain adverse—
effects?
153
summaries
w/ adverse—
effects
YES
435
summaries
w/ keywords
275
summaries
122
summaries
w/o adverse—
effects
NO
6
summaries
w/ adverse—
effects
2,577
summaries
w/o keywords
53
summaries
YES
Random sampling
Contain adverse—
effects?
47
summaries
w/o adverse—
effects
NO
</figure>
<page confidence="0.985164">
78
</page>
<tableCaption confidence="0.99342">
Table 3. Features used in adverse-effect extraction.
</tableCaption>
<table confidence="0.998635533333333">
ID Feature Definition and Examples
1 Character Distance The number of characters between members of a pair.
2 Morpheme Distance The number of morpheme between members of a pair.
3 Pair Order Order in which a drug and a symptom appear in a text;
&amp;quot;drug—symptom&amp;quot; or &amp;quot;symptom—drug&amp;quot;.
4 Symptom Type The type of symptom: &amp;quot;disease name&amp;quot;, &amp;quot;medical test name&amp;quot;,
or &amp;quot;medical test value&amp;quot;.
5 Morpheme Chain Base—forms of morphemes that appear between a pair.
6 Dependency Chain Base—forms of morphemes included in the minimal
dependency path of a pair.
7 Case Frame Chain Verb, case frame, and object triples that appear between a
pair: e.g. &amp;quot;examine&amp;quot; —&amp;quot;de&amp;quot;(case particle) — &amp;quot;inhalation&amp;quot;,
&amp;quot;begin&amp;quot; —&amp;quot;wo&amp;quot;(case particle) —&amp;quot;medication&amp;quot;.
8 Case Frame Verb, case frame, and object triples included in the minimal
Dependency Chain dependency path of a pair.
</table>
<figure confidence="0.5385908">
&lt;drug relation=&amp;quot;I&amp;quot;&gt;Lasix&lt;ldrug&gt; for
&lt;symptom&gt;hyperpiesia&lt;/symptom &gt; has
been suspended due to the appearance of
a &lt;symptom relation=&amp;quot;I&amp;quot;&gt;headache
&lt;/symptom&gt;.
</figure>
<figureCaption confidence="0.70223075">
label drug symptom
negative Lasix hyperpiesia
positive Lasix headache
Figure 5. Pair extraction example.
</figureCaption>
<bodyText confidence="0.709602666666667">
several examples, wherein &amp;quot;relation--I&amp;quot; de-
notes the ID of a adverse—effect relation. In the
corpus, 236 relations were annotated.
</bodyText>
<sectionHeader confidence="0.994914" genericHeader="method">
4 Extraction Method
</sectionHeader>
<bodyText confidence="0.904944727272727">
We present a simple adverse—effect relation
extraction method. We extract drug—symptom
pairs from the corpus and discriminate them
using a machine-learning technique. Features
based on morphological analysis and depend-
ency analysis are used in discrimination. This
approach is similar to the PPI extraction ap-
proach of Miyao et al. (2008), in which we
binary classify pairs whether they are in ad-
Lasix, wo-PP, headache, no-PP,
appear, niyori-PP, suspend, ta-AUX
</bodyText>
<figureCaption confidence="0.955756">
Figure 6. Dependency chain example.
</figureCaption>
<bodyText confidence="0.961388866666667">
verse—effect relations or not. A pattern-based
semi-supervised approach like Saeger et al.
(2008), or more generally Espresso (Pantel and
Pennacchiotti, 2006), can also be taken, but we
chose a pair classification approach to avoid
the effect of seed patterns. To capture a view
of an adverseness of a drug, a statistic of ad-
verse—effect relations is important. We do not
want to favor certain patterns and chose a pair
classification approach to equally treat every
relation. Extraction steps of our method are as
presented below.
STEP 1: Pair Extraction
All combinations of drug—symptom pairs that
appear in a same sentence are extracted. Pairs
</bodyText>
<figure confidence="0.993535142857143">
hyperpiesia no-PP
for no-PP
Lasix wo-PP
headache no-PP
appear niyori-PP
minimal path
suspend ta-AUX
</figure>
<page confidence="0.993521">
79
</page>
<tableCaption confidence="0.997996">
Table 4. Best F1-scores and their parameters.
</tableCaption>
<table confidence="0.983379142857143">
ID Feature Parameters Precision Recall F1-score
Combination
A 1,2,3,4,5 log(c)=3.0, log(g)=-5.0, p=0.10 26.72 46.21 33.05
B 1,2,3,4,5,6 log(c)=1.0, log(g)=-5.0, p=0.10 33.30 42.43 36.64
C 1,2,3,4,5,6,7 log(c)=1.0, log(g)=-5.0, p=0.10 34.39 43.06 37.54
D 1,2,3,4,5,6,8 log(c)=1.0, log(g)=-5.0, p=0.10 35.01 40.67 36.78
E 1,2,3,4,5,6,7,8 log(c)=1.0, log(g)=-5.0, p=0.10 35.45 41.05 37.18
</table>
<figureCaption confidence="0.999229">
Figure 7. Precision—recall distribution.
</figureCaption>
<bodyText confidence="0.98632348">
with the same relation ID become positive
samples; pairs with different relation IDs be-
come negative samples. Figure 5 shows exam-
ples of positive and negative samples.
STEP 2: Feature Extraction
Features presented in Table 3 are extracted.
The text in the corpus is in Japanese. Some
features assume widely known characteristics
of Japanese. For example, the dependency fea-
ture allows a phrase to depend on only one
phrase that appears after a dependent phrase.
Figure 6 portrays an example of a dependency
chain feature. In the example, most terms were
translated into English, excluding postpositions
(PP) and auxiliaries (AUX), which are ex-
pressed in italic. To reduce the negative effect
of feature sparsity, features which appeared in
more than three summaries are used for fea-
tures with respective IDs 5—8.
STEP 3: Machine Learning
The support vector machine (SVM) (Vapnik,
1995) is trained using positive/negative labels
and features extracted in prior steps. In testing,
an unlabeled pair is given a positive or nega-
tive label with the trained SVM.
</bodyText>
<sectionHeader confidence="0.998351" genericHeader="method">
5 Experiment
</sectionHeader>
<bodyText confidence="0.9992225">
We performed two experiments to evaluate the
extraction method.
</bodyText>
<subsectionHeader confidence="0.919495">
5.1 Experiment 1
</subsectionHeader>
<bodyText confidence="0.999922">
Experiment 1 aimed to observe the effects of
the presented features. Five combinations of
the features were evaluated with a five-fold
cross validation assuming that an optimal pa-
rameter combination was obtained. The exper-
iment conditions are described below:
</bodyText>
<subsectionHeader confidence="0.615988">
A. Data
</subsectionHeader>
<bodyText confidence="0.999783666666667">
7,690 drug—symptom pairs were extracted
from the corpus. Manually annotated infor-
mation was used to identify drugs and symp-
toms. Within 7,690 pairs, 149 pairs failed to
extract the dependency chain feature. We re-
moved these 149 pairs and used the remaining
7,541 pairs in the experiment. The 7,541 pairs
consisted of 367 positive samples and 7,174
negative samples.
</bodyText>
<subsectionHeader confidence="0.635484">
B. Feature Combinations
</subsectionHeader>
<bodyText confidence="0.9998499">
We tested the five combinations of features in
the experiment. Manually annotated infor-
mation was used for the symptom type feature.
Features related to morphemes are obtained by
processing sentences with a Japanese mor-
phology analyzer (JUMAN2 ver. 6.0). Features
related to dependency and case are obtained by
processing sentences using a Japanese depend-
ency parser (KNP ver. 3.0; Kurohashi and Na-
gao, 1994).
</bodyText>
<sectionHeader confidence="0.61778" genericHeader="method">
C. Evaluations
</sectionHeader>
<bodyText confidence="0.999321">
We evaluated the extraction method with all
combinations of SVM parameters in certain
</bodyText>
<footnote confidence="0.8169425">
2 http://www-lab25.kuee.kyoto-u.acjp/nl-
resource/juman-e.html
</footnote>
<page confidence="0.996419">
80
</page>
<figureCaption confidence="0.945162">
Figure 8. Relation between the number of
pairs and the morpheme distance.
</figureCaption>
<bodyText confidence="0.992379238095238">
ranges. We used LIBSVM3 ver. 2.89 as an im-
plementation of SVM. The radial basis func-
tion (RBF) was used as the kernel function of
SVM. The probability estimates option of
LIBSVM was used to obtain the confidence
value of discrimination.
The gamma parameter of the RBF kernel
was chosen from the range of [2-20, 20]. The C
parameter of SVM was chosen from the range
of [2-10, 210]. The SVM was trained and tested
on 441 combinations of gamma and C. In test-
ing, the probability threshold parameter p be-
tween [0.05, 0.95] was also chosen, and the F1-
scores of all combination of gamma, C, and p
were calculated with five-fold cross validation.
The best F1-scores and their parameter values
for each combination of features (optimal F1-
scores in this setting) are portrayed in Table 4.
The precision—recall distribution of F1-scores
with feature combination C is presented in
Figure 7.
</bodyText>
<subsectionHeader confidence="0.986486">
5.2 Experiment 2
</subsectionHeader>
<bodyText confidence="0.9383589">
Experiment 2 aimed to observe the perfor-
mance of our extraction method when SVM
parameters were automatically tuned. In this
experiment, we performed two cross valida-
tions: a cross validation to tune SVM parame-
ters and another cross validation to evaluate
the extraction method. The experiment condi-
tions are described below:
A. Data
The same data as Experiment 1 were used.
</bodyText>
<subsectionHeader confidence="0.759531">
B. Feature Combination
</subsectionHeader>
<bodyText confidence="0.9950515">
Feature combination C, which performed best
in Experiment 1, was used.
</bodyText>
<sectionHeader confidence="0.308109" genericHeader="method">
C. Evaluation
</sectionHeader>
<footnote confidence="0.709291">
3 http://www.csie.ntu.edu.tw/—cjlin/libsvm
</footnote>
<figureCaption confidence="0.967305">
Figure 9. Number of dependency errors
in the improved pairs sentences.
</figureCaption>
<bodyText confidence="0.999987555555556">
Two five-fold cross validations were per-
formed. The first cross validation divided the
data to 5 sets (A, B, C, D, and E) each consist-
ing of development set and test set with the
ratio of 4:1. The second cross validation train
and test all combination of SVM parameters (C,
gamma, and p) in certain ranges and decide the
optimal parameter combination(s) for the de-
velopment sets of A, B, C, D, and E. The se-
cond cross validation denotes the execution of
Experiment 1 for each development set. For
each optimal parameter combination of A, B,
C, D, and E, the corresponding development
set was trained and the trained model was test-
ed on the corresponding test set. The average
F1-score on five test sets marked 34.90, which
is 2.64 lower than the F1-score of Experiment 1
with the same feature combination.
</bodyText>
<sectionHeader confidence="0.991626" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.959459571428571">
The result of the experiment reveals the effec-
tiveness of the dependency chain feature and
the case-frame chain feature. This section pre-
sents a description of the effects of several fea-
tures in detail. The section also mentions re-
maining problems in our extraction method.
6.1 Effects of the Dependency Chain Fea-
ture and Case-frame Features
A. Dependency Chain Feature
The dependency chain features improved the
F1-score by 3.59 (the F1-score difference be-
tween feature combination A and B). This in-
crease was obtained using 260 improved pairs
and 127 deproved pairs. Improved pairs con-
</bodyText>
<figure confidence="0.995901541666667">
frequency
40
20
50
30
10
0
distance less
than 40
distance larger than
or equal to 40
improved
deproved
23
93
25
sentence
with no error
sentence
with 1-3
errors
sentence
with 4 or
more errors
</figure>
<page confidence="0.995959">
81
</page>
<bodyText confidence="0.999928136363636">
tribute to the increase of a F1-score. Deproved
pairs have the opposite effect.
We observed that improved pairs tend to
have longer morpheme distance compared to
deproved pairs. Figure 8 shows the relation
between the number of pairs and the mor-
pheme distance of improved pairs and de-
proved pairs. The ratio between the improved
pairs and the deproved pairs is 11:1 when the
distance is greater than 40. In contrast, the
ratio is 2:1 when the distance is smaller than
40. This observation suggests that adverse—
effect relations share dependency structures to
a certain degree.
We also observed that in improved pairs,
dependency errors tended to be low. Figure 9
presents the manually counted number of de-
pendency errors in the 141 sentences in which
the 260 improved pairs exist: 65.96 % of the
sentences included 1—3 errors. The result sug-
gests that the dependency structure is effective
even if it includes small errors.
</bodyText>
<subsectionHeader confidence="0.541071">
B. Case-frame Features
</subsectionHeader>
<bodyText confidence="0.999939166666667">
The effect of the case-frame dependency chain
feature differed with the effect of the depend-
ency chain feature. The case-frame chain fea-
ture improved the F,-score by 0.90 (the F1-
score difference between feature combination
B and C), but the case-frame dependency chain
feature decreased the F,-score by 0.36 (the Fl-
score difference between feature combination
C and E). One reason for the negative effect of
the case-frame dependency feature might be
feature sparsity, but no clear evidence of it has
been found.
</bodyText>
<subsectionHeader confidence="0.812203">
6.2 Remaining Problems
A. Imbalanced Data
</subsectionHeader>
<bodyText confidence="0.99997225">
The adverse—effect relation pairs we used in
the experiment were not balanced. Low values
of optimal probability threshold parameter p
suggest the degree of imbalance. We are con-
sidering introduction of some kind of method-
ology to reduce negative samples or to use a
machine learning method that can accommo-
date imbalanced data well.
</bodyText>
<subsectionHeader confidence="0.94839">
B. Use of Medical Resources
</subsectionHeader>
<bodyText confidence="0.9999709">
The extraction method we propose uses no
medical resources. Gir u et al. (2007) indicate
the effect of WordNet senses in the classifica-
tion of a semantic relation between nominals.
Krallinger et al. (2008) report that top scoring
teams in the interaction pair subtask used so-
phisticated interactor protein normalization
strategies. If medical terms in texts can be
mapped to a medical terminology or ontology,
it would likely improve the extraction accuracy.
</bodyText>
<sectionHeader confidence="0.493918" genericHeader="method">
C. Fully Automated Extraction
</sectionHeader>
<bodyText confidence="0.9999721">
In the experiments, we used the manually
annotated information to extract pairs and fea-
tures. This setting is, of course, not real if we
consider a situation to extract adverse—effect
relations from massive clinical records, but we
chose it to focus on the relation extraction
problem. We performed an event recognition
experiment (Aramaki et al., 2009) and
achieved F,-score of about 80. We assume that
drug expressions and symptom expressions to
be automatically recognized in a similar accu-
racy.
We are planning to perform a fully automat-
ed adverse—effect relations extraction from a
larger set of clinical texts to see the perfor-
mance of our method on a raw corpus. The
extraction F,-score will likely to decrease, but
we intend to observe the other aspect of the
extraction, like the overall tendency of extract-
ed relations.
</bodyText>
<sectionHeader confidence="0.998376" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999624">
We presented a method to extract adverse—
effect relations from texts. One important
characteristic of adverse—effect relations is that
they are uncertain in most cases. We per-
formed experiments to extract adverse—effect
relations from 2,577 clinical texts, and ob-
tained F,-score of 37.54 with optimal SVM
parameters and F,-score of 34.90 with auto-
matically tuned SVM parameters. Results also
show that dependency features increase the
extraction F,-score by 3.59. We observed that
an increased F,-score was obtained using the
improvement of adverse—effects with long
morpheme distance, which suggests that ad-
verse—effect relations share dependency struc-
tures to a certain degree. We also observed that
the increase of the F,-score was obtained with
dependency structures that include small errors,
which suggests that the dependency structure
is effective even if it includes small errors.
</bodyText>
<page confidence="0.998272">
82
</page>
<sectionHeader confidence="0.989906" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999621855670103">
Aramaki, Eiji, Yasuhide Miura, Masatsugu Tonoike,
Tomoko Ohkuma, Hiroshi Masuichi, and
Kazuhiko Ohe. 2009. TEXT2TABLE: Medical
Text Summarization System Based on Named
Entity Recognition and Modality Identification.
In Proceedings of the BioNLP 2009 Workshop,
pages 185-192.
Beamer, Brandon, Suma Bhat, Brant Chee, Andrew
Fister, Alla Rozovskaya, and Roxana Girju.
2007. UIUC: A Knowledge-rich Approach to
Identifying Semantic Relations between Nomi-
nals. In Proceedings of Fourth International
Workshop on Semantic Evaluations, pages 386-
389.
Friedman, Carol, Philip O. Alderson, John H. M.
Austin, James J. Cimino, and Stephen B. John-
son. 1994. A General Natural-language Text
Processor for Clinical Radiology. Journal of the
American Medical Informatics Association, 1(2),
pages 161-174.
Gildea, Daniel. 2001. Corpus Variation and Parser
Performance. In Proceedings of the 2001 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 1-9.
Girju, Roxana, Preslav Nakov, Vivi Nastase, Stan
Szpakowicz, Peter Turney, and Deniz Yuret.
2007. SemEval-2007 task 04: Classification of
Semantic Relations between Nominals. In Pro-
ceedings of Fourth International Workshop on
Semantic Evaluations, pages 13-18.
Giuliano, Claudio, Alberto Lavelli, Daniele Pighin,
and Lorenza Romano. 2007. FBK-IRST: Kernel
Methods for Semantic Relation Extraction. In
Proceedings of the 4th International Workshop
on Semantic Evaluations, pages 141-144.
Hendrickx , Iris, Roser Morante, Caroline Sporleder,
and Antal van den Bosch. 2007. ILK: Machine
learning of semantic relations with shallow fea-
tures and almost no data. In Proceedings of the
4th International Workshop on Semantic Evalua-
tions, 187-190.
Kim, Jin-Dong, Tomoko Ohta, Sampo Pyysalo,
Yoshinobu Kano, and Jun&apos;ichi Tsujii. 2009.
Overview of BioNLP&apos;09 Shared Task on Event
Extraction. In Proceedings of the BioNLP 2009
Workshop Companion Volume for Shared Task,
pages 1-9.
Krallinger, Martin, Florian Leitner, Carlos
Rodriguez-Penagos, and Alfonso Valencia. 2008.
Overview of the protein-protein interaction an-
notation extraction task of BioCreative II. Ge-
nome Biology 2008, 9(Suppl 2):S4.
Kurohashi, Sadao and Makoto Nagao. 1994. KN
Parser : Japanese Dependency/Case Structure
Analyzer. In Proceedings of The International
Workshop on Sharable Natural Language Re-
sources, pages 22-28. Software available at
http://www-lab25.kuee.kyoto-u.ac.jp/nl-
resource/knp-e.html.
Light, Marc, Xin Ying Qiu, and Padmini Srinivasan.
2004. The Language of Bioscience: Facts, Spec-
ulations, and Statements in Between. In Pro-
ceedings of HLT/NAACL 2004 Workshop: Bi-
oLINK 2004, Linking Biological Literature, On-
tologies and Databases, pages 17-24.
Miyao, Yusuke, Rune Satre, Kenji Sagae, Takuya
Matsuzaki, and Jun&apos;ichi Tsujii. 2008. Task-
oriented Evaluation of Syntactic Parsers and
Their Representations. In Proceedings of the
46th Annual Meeting of the Association for
Computational Linguistics: Human Language
Technologies, pages 46-54.
Pantel, Patrick and Marco Pennacchiotti. 2006. Es-
presso: Leveraging Generic Patterns for Auto-
matically Harvesting Semantic Relations. In
Proceedings of the 21st International Confer-
ence on Computational Linguistics and 44th An-
nual Meeting of the Association for Computa-
tional Linguistics, pages 113-120.
Riedel, Sebastian, Hong-Woo Chun, Toshihisa
Takagi, and Jun&apos;ichi Tsujii. 2009. A Markov
Logic Approach to Bio-Molecular Event Extrac-
tion. In Proceedings of the BioNLP 2009 Work-
shop Companion Volume for Shared Task, pages
41-49.
Saeger, Stijn De, Kentaro Torisawa, and Jun&apos;ichi
Kazama. 2008. Looking for Trouble. In Proceed-
ings of the 22nd International Conference on
Computational Linguistics, pages 185-192.
Vapnik, Vladimir N.. 1995. The Nature of Statisti-
cal Learning Theory. Springer-Verlag New York,
Inc..
Vincze, Veronika, Gyorgy Szarvas, Richard Farkas,
Gyorgy M6ra, and Janos Csirik. 2008. The Bio-
Scope corpus: biomedical texts annotated for un-
certainty, negation and their scopes. BMC Bioin-
formatics 2008, 9(Suppl 11):S9.
</reference>
<page confidence="0.999307">
83
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.277582">
<title confidence="0.9904705">Adverse—Effect Relations Extraction Massive Clinical Records</title>
<author confidence="0.903092">Miura Eiji Aramaki Tomoko Ohkuma Masatsugu Tonoike Sugihara Hiroshi</author>
<author confidence="0.903092">Kazuhiko Ohe</author>
<affiliation confidence="0.861458">Xerox Co., Ltd. bCenter for Knowledge Structuring, University of Tokyo</affiliation>
<address confidence="0.754373">of Tokyo Hospital</address>
<email confidence="0.808163333333333">yasuhide.miura@fujixerox.co.jp,eiji.aramaki@gmail.com,{ohkuma.tomoko,masatsugu.tonoike,daigo.sugihara,kohe@hcc.h.u—tokyo.ac.jp</email>
<abstract confidence="0.990956931034483">The rapid spread of electronic health records raised an interest to large-scale information extraction from clinical texts. Considering such a background, we are developing a method that can extract adverse drug event and effect (adverse—effect) relations from massive clinical records. Adverse—effect relations share some features with relations proposed in previous relation extraction studies, but they also have unique characteristics. Adverse—effect relations are usually uncertain. Not even medical experts can usually determine whether a symptom that arises after a medication represents an adverse— effect relation or not. We propose a method to extract adverse—effect relations using a machine-learning technique with dependency features. We performed experiments to extract adverse—effect relations from 2,577 clinitexts, and obtained of 37.54 with an optimal parameters and of 34.90 with automatically tuned parameters. The results also show that dependency features increase extraction by 3.59.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eiji Aramaki</author>
<author>Yasuhide Miura</author>
</authors>
<title>Masatsugu Tonoike, Tomoko Ohkuma, Hiroshi Masuichi, and Kazuhiko Ohe.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop,</booktitle>
<pages>185--192</pages>
<marker>Aramaki, Miura, 2009</marker>
<rawString>Aramaki, Eiji, Yasuhide Miura, Masatsugu Tonoike, Tomoko Ohkuma, Hiroshi Masuichi, and Kazuhiko Ohe. 2009. TEXT2TABLE: Medical Text Summarization System Based on Named Entity Recognition and Modality Identification. In Proceedings of the BioNLP 2009 Workshop, pages 185-192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brandon Beamer</author>
<author>Suma Bhat</author>
<author>Brant Chee</author>
<author>Andrew Fister</author>
<author>Alla Rozovskaya</author>
<author>Roxana Girju</author>
</authors>
<title>UIUC: A Knowledge-rich Approach to Identifying Semantic Relations between Nominals.</title>
<date>2007</date>
<booktitle>In Proceedings of Fourth International Workshop on Semantic Evaluations,</booktitle>
<pages>386--389</pages>
<contexts>
<context position="7225" citStr="Beamer et al. (2007)" startWordPosition="1086" endWordPosition="1089">described in previous reports in the bio-medical domain. Friedman et al. (1994) describes the certainty in findings of clinical radiology. Certainty is also known in scientific papers of biomedical domains as speculation (Light et al., 2004). Vincze et al. (2008) are producing a freely available corpus including annotations of uncertainty along with its scope. Dependency structure feature which we utilized to extract adverse—effect relations are widely used in relation extraction tasks. We present previous works which used syntactic/dependency information as a feature of a statistical method. Beamer et al. (2007), Giuliano et al. (2007), and Hendrickx et al. (2007) all used syntactic information with machine learning techniques in SemEval-2007 Task:04 and achieved good performance. Riedel et al. (2009) used dependency path features with a statistical relational learning method in BioNLP&apos;09 Shared Task on Event Extraction and achieved the best performance in the event enrichment subtask. Miyao et al. (2008) compared syntactic information of various statistical parsers on PPI. 3 Corpus We produced an annotated corpus of adverse— effect relations to develop and test an adverse— effect relation extraction</context>
</contexts>
<marker>Beamer, Bhat, Chee, Fister, Rozovskaya, Girju, 2007</marker>
<rawString>Beamer, Brandon, Suma Bhat, Brant Chee, Andrew Fister, Alla Rozovskaya, and Roxana Girju. 2007. UIUC: A Knowledge-rich Approach to Identifying Semantic Relations between Nominals. In Proceedings of Fourth International Workshop on Semantic Evaluations, pages 386-389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol Friedman</author>
<author>Philip O Alderson</author>
<author>John H M Austin</author>
<author>James J Cimino</author>
<author>Stephen B Johnson</author>
</authors>
<title>A General Natural-language Text Processor for Clinical Radiology.</title>
<date>1994</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>1</volume>
<issue>2</issue>
<pages>161--174</pages>
<contexts>
<context position="6684" citStr="Friedman et al. (1994)" startWordPosition="1006" endWordPosition="1009"> to extract potential troubles or obstacles related to the use of a given object. This relation can be interpreted as a more general relation of the adverse—effect relation. The protein—protein interaction (PPI) annotation extraction task of BioCreative II (Krallinger et al., 2008) is a task to extract PPI from PubMed abstracts. BioNLP&apos;09 Shared Task on Event Extraction (Kim et al., 2009) is a task to extract bio-molecular events (bioevents) from the GENIA event corpus. Similar characteristics to those of the adverse—effect relation are described in previous reports in the bio-medical domain. Friedman et al. (1994) describes the certainty in findings of clinical radiology. Certainty is also known in scientific papers of biomedical domains as speculation (Light et al., 2004). Vincze et al. (2008) are producing a freely available corpus including annotations of uncertainty along with its scope. Dependency structure feature which we utilized to extract adverse—effect relations are widely used in relation extraction tasks. We present previous works which used syntactic/dependency information as a feature of a statistical method. Beamer et al. (2007), Giuliano et al. (2007), and Hendrickx et al. (2007) all u</context>
</contexts>
<marker>Friedman, Alderson, Austin, Cimino, Johnson, 1994</marker>
<rawString>Friedman, Carol, Philip O. Alderson, John H. M. Austin, James J. Cimino, and Stephen B. Johnson. 1994. A General Natural-language Text Processor for Clinical Radiology. Journal of the American Medical Informatics Association, 1(2), pages 161-174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
</authors>
<title>Corpus Variation and Parser Performance.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="5359" citStr="Gildea, 2001" startWordPosition="801" endWordPosition="802">ations with various certainties. To establish this goal, we used a dependency structure for the adverse–effect relation extraction method. Adverse–effect statements are assumed to share a dependency structure to a certain degree. For example, if we obtain the dependency structures as shown in Figure 3, then we can easily determine that the structures are similar. Of course, obtaining such perfect parsing results is not always possible. A statistical syntactic parser is known to perform badly if a text to be parsed belongs to a domain which differs from a domain on which the parser is trained (Gildea, 2001). A statistical parser will likely output incomplete results in these texts and will likely have a negative effect on relation extraction methods which depend on it. The specified research topic of this study is to investigate whether incomplete dependency structures are effective and how they behave in the extraction of uncertain relations. 76 2 Related Works Various studies have been done to extract semantic information from texts. SemEval-2007 Task:04 (Girju et al., 2007) is a task to extract semantic relations between nominals. The task includes &amp;quot;Cause—Effect&amp;quot; relation extraction, which sh</context>
</contexts>
<marker>Gildea, 2001</marker>
<rawString>Gildea, Daniel. 2001. Corpus Variation and Parser Performance. In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing, pages 1-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Preslav Nakov</author>
<author>Vivi Nastase</author>
<author>Stan Szpakowicz</author>
<author>Peter Turney</author>
<author>Deniz Yuret</author>
</authors>
<title>SemEval-2007 task 04: Classification of Semantic Relations between Nominals.</title>
<date>2007</date>
<booktitle>In Proceedings of Fourth International Workshop on Semantic Evaluations,</booktitle>
<pages>13--18</pages>
<contexts>
<context position="5838" citStr="Girju et al., 2007" startWordPosition="874" endWordPosition="877"> known to perform badly if a text to be parsed belongs to a domain which differs from a domain on which the parser is trained (Gildea, 2001). A statistical parser will likely output incomplete results in these texts and will likely have a negative effect on relation extraction methods which depend on it. The specified research topic of this study is to investigate whether incomplete dependency structures are effective and how they behave in the extraction of uncertain relations. 76 2 Related Works Various studies have been done to extract semantic information from texts. SemEval-2007 Task:04 (Girju et al., 2007) is a task to extract semantic relations between nominals. The task includes &amp;quot;Cause—Effect&amp;quot; relation extraction, which shares some similarity with a task that will be presented herein. Saeger et al. (2008) presented a method to extract potential troubles or obstacles related to the use of a given object. This relation can be interpreted as a more general relation of the adverse—effect relation. The protein—protein interaction (PPI) annotation extraction task of BioCreative II (Krallinger et al., 2008) is a task to extract PPI from PubMed abstracts. BioNLP&apos;09 Shared Task on Event Extraction (Ki</context>
</contexts>
<marker>Girju, Nakov, Nastase, Szpakowicz, Turney, Yuret, 2007</marker>
<rawString>Girju, Roxana, Preslav Nakov, Vivi Nastase, Stan Szpakowicz, Peter Turney, and Deniz Yuret. 2007. SemEval-2007 task 04: Classification of Semantic Relations between Nominals. In Proceedings of Fourth International Workshop on Semantic Evaluations, pages 13-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Giuliano</author>
<author>Alberto Lavelli</author>
<author>Daniele Pighin</author>
<author>Lorenza Romano</author>
</authors>
<title>FBK-IRST: Kernel Methods for Semantic Relation Extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>141--144</pages>
<contexts>
<context position="7249" citStr="Giuliano et al. (2007)" startWordPosition="1090" endWordPosition="1094">reports in the bio-medical domain. Friedman et al. (1994) describes the certainty in findings of clinical radiology. Certainty is also known in scientific papers of biomedical domains as speculation (Light et al., 2004). Vincze et al. (2008) are producing a freely available corpus including annotations of uncertainty along with its scope. Dependency structure feature which we utilized to extract adverse—effect relations are widely used in relation extraction tasks. We present previous works which used syntactic/dependency information as a feature of a statistical method. Beamer et al. (2007), Giuliano et al. (2007), and Hendrickx et al. (2007) all used syntactic information with machine learning techniques in SemEval-2007 Task:04 and achieved good performance. Riedel et al. (2009) used dependency path features with a statistical relational learning method in BioNLP&apos;09 Shared Task on Event Extraction and achieved the best performance in the event enrichment subtask. Miyao et al. (2008) compared syntactic information of various statistical parsers on PPI. 3 Corpus We produced an annotated corpus of adverse— effect relations to develop and test an adverse— effect relation extraction method. This section pr</context>
</contexts>
<marker>Giuliano, Lavelli, Pighin, Romano, 2007</marker>
<rawString>Giuliano, Claudio, Alberto Lavelli, Daniele Pighin, and Lorenza Romano. 2007. FBK-IRST: Kernel Methods for Semantic Relation Extraction. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 141-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante Iris</author>
<author>Caroline Sporleder</author>
<author>Antal van den Bosch</author>
</authors>
<title>ILK: Machine learning of semantic relations with shallow features and almost no data.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>187--190</pages>
<marker>Iris, Sporleder, van den Bosch, 2007</marker>
<rawString>Hendrickx , Iris, Roser Morante, Caroline Sporleder, and Antal van den Bosch. 2007. ILK: Machine learning of semantic relations with shallow features and almost no data. In Proceedings of the 4th International Workshop on Semantic Evaluations, 187-190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Sampo Pyysalo</author>
<author>Yoshinobu Kano</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Overview of BioNLP&apos;09 Shared Task on Event Extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="6453" citStr="Kim et al., 2009" startWordPosition="970" endWordPosition="973">7) is a task to extract semantic relations between nominals. The task includes &amp;quot;Cause—Effect&amp;quot; relation extraction, which shares some similarity with a task that will be presented herein. Saeger et al. (2008) presented a method to extract potential troubles or obstacles related to the use of a given object. This relation can be interpreted as a more general relation of the adverse—effect relation. The protein—protein interaction (PPI) annotation extraction task of BioCreative II (Krallinger et al., 2008) is a task to extract PPI from PubMed abstracts. BioNLP&apos;09 Shared Task on Event Extraction (Kim et al., 2009) is a task to extract bio-molecular events (bioevents) from the GENIA event corpus. Similar characteristics to those of the adverse—effect relation are described in previous reports in the bio-medical domain. Friedman et al. (1994) describes the certainty in findings of clinical radiology. Certainty is also known in scientific papers of biomedical domains as speculation (Light et al., 2004). Vincze et al. (2008) are producing a freely available corpus including annotations of uncertainty along with its scope. Dependency structure feature which we utilized to extract adverse—effect relations ar</context>
</contexts>
<marker>Kim, Ohta, Pyysalo, Kano, Tsujii, 2009</marker>
<rawString>Kim, Jin-Dong, Tomoko Ohta, Sampo Pyysalo, Yoshinobu Kano, and Jun&apos;ichi Tsujii. 2009. Overview of BioNLP&apos;09 Shared Task on Event Extraction. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pages 1-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Krallinger</author>
<author>Florian Leitner</author>
<author>Carlos Rodriguez-Penagos</author>
<author>Alfonso Valencia</author>
</authors>
<title>Overview of the protein-protein interaction annotation extraction task of BioCreative II. Genome Biology 2008, 9(Suppl 2):S4.</title>
<date>2008</date>
<contexts>
<context position="6344" citStr="Krallinger et al., 2008" startWordPosition="951" endWordPosition="954">s Various studies have been done to extract semantic information from texts. SemEval-2007 Task:04 (Girju et al., 2007) is a task to extract semantic relations between nominals. The task includes &amp;quot;Cause—Effect&amp;quot; relation extraction, which shares some similarity with a task that will be presented herein. Saeger et al. (2008) presented a method to extract potential troubles or obstacles related to the use of a given object. This relation can be interpreted as a more general relation of the adverse—effect relation. The protein—protein interaction (PPI) annotation extraction task of BioCreative II (Krallinger et al., 2008) is a task to extract PPI from PubMed abstracts. BioNLP&apos;09 Shared Task on Event Extraction (Kim et al., 2009) is a task to extract bio-molecular events (bioevents) from the GENIA event corpus. Similar characteristics to those of the adverse—effect relation are described in previous reports in the bio-medical domain. Friedman et al. (1994) describes the certainty in findings of clinical radiology. Certainty is also known in scientific papers of biomedical domains as speculation (Light et al., 2004). Vincze et al. (2008) are producing a freely available corpus including annotations of uncertaint</context>
<context position="23371" citStr="Krallinger et al. (2008)" startWordPosition="3604" endWordPosition="3607">as been found. 6.2 Remaining Problems A. Imbalanced Data The adverse—effect relation pairs we used in the experiment were not balanced. Low values of optimal probability threshold parameter p suggest the degree of imbalance. We are considering introduction of some kind of methodology to reduce negative samples or to use a machine learning method that can accommodate imbalanced data well. B. Use of Medical Resources The extraction method we propose uses no medical resources. Gir u et al. (2007) indicate the effect of WordNet senses in the classification of a semantic relation between nominals. Krallinger et al. (2008) report that top scoring teams in the interaction pair subtask used sophisticated interactor protein normalization strategies. If medical terms in texts can be mapped to a medical terminology or ontology, it would likely improve the extraction accuracy. C. Fully Automated Extraction In the experiments, we used the manually annotated information to extract pairs and features. This setting is, of course, not real if we consider a situation to extract adverse—effect relations from massive clinical records, but we chose it to focus on the relation extraction problem. We performed an event recognit</context>
</contexts>
<marker>Krallinger, Leitner, Rodriguez-Penagos, Valencia, 2008</marker>
<rawString>Krallinger, Martin, Florian Leitner, Carlos Rodriguez-Penagos, and Alfonso Valencia. 2008. Overview of the protein-protein interaction annotation extraction task of BioCreative II. Genome Biology 2008, 9(Suppl 2):S4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>KN Parser : Japanese Dependency/Case Structure Analyzer.</title>
<date>1994</date>
<booktitle>In Proceedings of The International Workshop on Sharable Natural Language Resources,</booktitle>
<pages>22--28</pages>
<note>Software available at http://www-lab25.kuee.kyoto-u.ac.jp/nlresource/knp-e.html.</note>
<contexts>
<context position="17876" citStr="Kurohashi and Nagao, 1994" startWordPosition="2709" endWordPosition="2713">ract the dependency chain feature. We removed these 149 pairs and used the remaining 7,541 pairs in the experiment. The 7,541 pairs consisted of 367 positive samples and 7,174 negative samples. B. Feature Combinations We tested the five combinations of features in the experiment. Manually annotated information was used for the symptom type feature. Features related to morphemes are obtained by processing sentences with a Japanese morphology analyzer (JUMAN2 ver. 6.0). Features related to dependency and case are obtained by processing sentences using a Japanese dependency parser (KNP ver. 3.0; Kurohashi and Nagao, 1994). C. Evaluations We evaluated the extraction method with all combinations of SVM parameters in certain 2 http://www-lab25.kuee.kyoto-u.acjp/nlresource/juman-e.html 80 Figure 8. Relation between the number of pairs and the morpheme distance. ranges. We used LIBSVM3 ver. 2.89 as an implementation of SVM. The radial basis function (RBF) was used as the kernel function of SVM. The probability estimates option of LIBSVM was used to obtain the confidence value of discrimination. The gamma parameter of the RBF kernel was chosen from the range of [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17</context>
</contexts>
<marker>Kurohashi, Nagao, 1994</marker>
<rawString>Kurohashi, Sadao and Makoto Nagao. 1994. KN Parser : Japanese Dependency/Case Structure Analyzer. In Proceedings of The International Workshop on Sharable Natural Language Resources, pages 22-28. Software available at http://www-lab25.kuee.kyoto-u.ac.jp/nlresource/knp-e.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Light</author>
<author>Xin Ying Qiu</author>
<author>Padmini Srinivasan</author>
</authors>
<title>The Language of Bioscience: Facts, Speculations, and Statements in Between.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT/NAACL 2004 Workshop: BioLINK</booktitle>
<pages>17--24</pages>
<contexts>
<context position="6846" citStr="Light et al., 2004" startWordPosition="1030" endWordPosition="1033">elation. The protein—protein interaction (PPI) annotation extraction task of BioCreative II (Krallinger et al., 2008) is a task to extract PPI from PubMed abstracts. BioNLP&apos;09 Shared Task on Event Extraction (Kim et al., 2009) is a task to extract bio-molecular events (bioevents) from the GENIA event corpus. Similar characteristics to those of the adverse—effect relation are described in previous reports in the bio-medical domain. Friedman et al. (1994) describes the certainty in findings of clinical radiology. Certainty is also known in scientific papers of biomedical domains as speculation (Light et al., 2004). Vincze et al. (2008) are producing a freely available corpus including annotations of uncertainty along with its scope. Dependency structure feature which we utilized to extract adverse—effect relations are widely used in relation extraction tasks. We present previous works which used syntactic/dependency information as a feature of a statistical method. Beamer et al. (2007), Giuliano et al. (2007), and Hendrickx et al. (2007) all used syntactic information with machine learning techniques in SemEval-2007 Task:04 and achieved good performance. Riedel et al. (2009) used dependency path featur</context>
</contexts>
<marker>Light, Qiu, Srinivasan, 2004</marker>
<rawString>Light, Marc, Xin Ying Qiu, and Padmini Srinivasan. 2004. The Language of Bioscience: Facts, Speculations, and Statements in Between. In Proceedings of HLT/NAACL 2004 Workshop: BioLINK 2004, Linking Biological Literature, Ontologies and Databases, pages 17-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Rune Satre</author>
<author>Kenji Sagae</author>
<author>Takuya Matsuzaki</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Taskoriented Evaluation of Syntactic Parsers and Their Representations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>46--54</pages>
<contexts>
<context position="7626" citStr="Miyao et al. (2008)" startWordPosition="1148" endWordPosition="1151">tilized to extract adverse—effect relations are widely used in relation extraction tasks. We present previous works which used syntactic/dependency information as a feature of a statistical method. Beamer et al. (2007), Giuliano et al. (2007), and Hendrickx et al. (2007) all used syntactic information with machine learning techniques in SemEval-2007 Task:04 and achieved good performance. Riedel et al. (2009) used dependency path features with a statistical relational learning method in BioNLP&apos;09 Shared Task on Event Extraction and achieved the best performance in the event enrichment subtask. Miyao et al. (2008) compared syntactic information of various statistical parsers on PPI. 3 Corpus We produced an annotated corpus of adverse— effect relations to develop and test an adverse— effect relation extraction method. This section presents a description of details of the corpus. 3.1 Texts Comprising the Corpus We used a discharge summary among various documents in a hospital as the source data of the task. The discharge summary is a document created by a doctor or another medical expert at the conclusion of a hospital stay. Medications performed during a stay are written in discharge summaries. If adver</context>
<context position="14276" citStr="Miyao et al. (2008)" startWordPosition="2159" endWordPosition="2162">=&amp;quot;I&amp;quot;&gt;headache &lt;/symptom&gt;. label drug symptom negative Lasix hyperpiesia positive Lasix headache Figure 5. Pair extraction example. several examples, wherein &amp;quot;relation--I&amp;quot; denotes the ID of a adverse—effect relation. In the corpus, 236 relations were annotated. 4 Extraction Method We present a simple adverse—effect relation extraction method. We extract drug—symptom pairs from the corpus and discriminate them using a machine-learning technique. Features based on morphological analysis and dependency analysis are used in discrimination. This approach is similar to the PPI extraction approach of Miyao et al. (2008), in which we binary classify pairs whether they are in adLasix, wo-PP, headache, no-PP, appear, niyori-PP, suspend, ta-AUX Figure 6. Dependency chain example. verse—effect relations or not. A pattern-based semi-supervised approach like Saeger et al. (2008), or more generally Espresso (Pantel and Pennacchiotti, 2006), can also be taken, but we chose a pair classification approach to avoid the effect of seed patterns. To capture a view of an adverseness of a drug, a statistic of adverse—effect relations is important. We do not want to favor certain patterns and chose a pair classification appro</context>
</contexts>
<marker>Miyao, Satre, Sagae, Matsuzaki, Tsujii, 2008</marker>
<rawString>Miyao, Yusuke, Rune Satre, Kenji Sagae, Takuya Matsuzaki, and Jun&apos;ichi Tsujii. 2008. Taskoriented Evaluation of Syntactic Parsers and Their Representations. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 46-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="14594" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="2204" endWordPosition="2207">se—effect relation extraction method. We extract drug—symptom pairs from the corpus and discriminate them using a machine-learning technique. Features based on morphological analysis and dependency analysis are used in discrimination. This approach is similar to the PPI extraction approach of Miyao et al. (2008), in which we binary classify pairs whether they are in adLasix, wo-PP, headache, no-PP, appear, niyori-PP, suspend, ta-AUX Figure 6. Dependency chain example. verse—effect relations or not. A pattern-based semi-supervised approach like Saeger et al. (2008), or more generally Espresso (Pantel and Pennacchiotti, 2006), can also be taken, but we chose a pair classification approach to avoid the effect of seed patterns. To capture a view of an adverseness of a drug, a statistic of adverse—effect relations is important. We do not want to favor certain patterns and chose a pair classification approach to equally treat every relation. Extraction steps of our method are as presented below. STEP 1: Pair Extraction All combinations of drug—symptom pairs that appear in a same sentence are extracted. Pairs hyperpiesia no-PP for no-PP Lasix wo-PP headache no-PP appear niyori-PP minimal path suspend ta-AUX 79 Table 4.</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Pantel, Patrick and Marco Pennacchiotti. 2006. Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 113-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Hong-Woo Chun</author>
<author>Toshihisa Takagi</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>A Markov Logic Approach to Bio-Molecular Event Extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task,</booktitle>
<pages>41--49</pages>
<contexts>
<context position="7418" citStr="Riedel et al. (2009)" startWordPosition="1115" endWordPosition="1118">ical domains as speculation (Light et al., 2004). Vincze et al. (2008) are producing a freely available corpus including annotations of uncertainty along with its scope. Dependency structure feature which we utilized to extract adverse—effect relations are widely used in relation extraction tasks. We present previous works which used syntactic/dependency information as a feature of a statistical method. Beamer et al. (2007), Giuliano et al. (2007), and Hendrickx et al. (2007) all used syntactic information with machine learning techniques in SemEval-2007 Task:04 and achieved good performance. Riedel et al. (2009) used dependency path features with a statistical relational learning method in BioNLP&apos;09 Shared Task on Event Extraction and achieved the best performance in the event enrichment subtask. Miyao et al. (2008) compared syntactic information of various statistical parsers on PPI. 3 Corpus We produced an annotated corpus of adverse— effect relations to develop and test an adverse— effect relation extraction method. This section presents a description of details of the corpus. 3.1 Texts Comprising the Corpus We used a discharge summary among various documents in a hospital as the source data of th</context>
</contexts>
<marker>Riedel, Chun, Takagi, Tsujii, 2009</marker>
<rawString>Riedel, Sebastian, Hong-Woo Chun, Toshihisa Takagi, and Jun&apos;ichi Tsujii. 2009. A Markov Logic Approach to Bio-Molecular Event Extraction. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pages 41-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stijn De Saeger</author>
<author>Kentaro Torisawa</author>
<author>Jun&apos;ichi Kazama</author>
</authors>
<title>Looking for Trouble.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>185--192</pages>
<contexts>
<context position="6043" citStr="Saeger et al. (2008)" startWordPosition="905" endWordPosition="908">these texts and will likely have a negative effect on relation extraction methods which depend on it. The specified research topic of this study is to investigate whether incomplete dependency structures are effective and how they behave in the extraction of uncertain relations. 76 2 Related Works Various studies have been done to extract semantic information from texts. SemEval-2007 Task:04 (Girju et al., 2007) is a task to extract semantic relations between nominals. The task includes &amp;quot;Cause—Effect&amp;quot; relation extraction, which shares some similarity with a task that will be presented herein. Saeger et al. (2008) presented a method to extract potential troubles or obstacles related to the use of a given object. This relation can be interpreted as a more general relation of the adverse—effect relation. The protein—protein interaction (PPI) annotation extraction task of BioCreative II (Krallinger et al., 2008) is a task to extract PPI from PubMed abstracts. BioNLP&apos;09 Shared Task on Event Extraction (Kim et al., 2009) is a task to extract bio-molecular events (bioevents) from the GENIA event corpus. Similar characteristics to those of the adverse—effect relation are described in previous reports in the b</context>
<context position="14533" citStr="Saeger et al. (2008)" startWordPosition="2196" endWordPosition="2199">ted. 4 Extraction Method We present a simple adverse—effect relation extraction method. We extract drug—symptom pairs from the corpus and discriminate them using a machine-learning technique. Features based on morphological analysis and dependency analysis are used in discrimination. This approach is similar to the PPI extraction approach of Miyao et al. (2008), in which we binary classify pairs whether they are in adLasix, wo-PP, headache, no-PP, appear, niyori-PP, suspend, ta-AUX Figure 6. Dependency chain example. verse—effect relations or not. A pattern-based semi-supervised approach like Saeger et al. (2008), or more generally Espresso (Pantel and Pennacchiotti, 2006), can also be taken, but we chose a pair classification approach to avoid the effect of seed patterns. To capture a view of an adverseness of a drug, a statistic of adverse—effect relations is important. We do not want to favor certain patterns and chose a pair classification approach to equally treat every relation. Extraction steps of our method are as presented below. STEP 1: Pair Extraction All combinations of drug—symptom pairs that appear in a same sentence are extracted. Pairs hyperpiesia no-PP for no-PP Lasix wo-PP headache n</context>
</contexts>
<marker>Saeger, Torisawa, Kazama, 2008</marker>
<rawString>Saeger, Stijn De, Kentaro Torisawa, and Jun&apos;ichi Kazama. 2008. Looking for Trouble. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 185-192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer-Verlag</publisher>
<location>New York, Inc..</location>
<contexts>
<context position="16544" citStr="Vapnik, 1995" startWordPosition="2503" endWordPosition="2504">anese. Some features assume widely known characteristics of Japanese. For example, the dependency feature allows a phrase to depend on only one phrase that appears after a dependent phrase. Figure 6 portrays an example of a dependency chain feature. In the example, most terms were translated into English, excluding postpositions (PP) and auxiliaries (AUX), which are expressed in italic. To reduce the negative effect of feature sparsity, features which appeared in more than three summaries are used for features with respective IDs 5—8. STEP 3: Machine Learning The support vector machine (SVM) (Vapnik, 1995) is trained using positive/negative labels and features extracted in prior steps. In testing, an unlabeled pair is given a positive or negative label with the trained SVM. 5 Experiment We performed two experiments to evaluate the extraction method. 5.1 Experiment 1 Experiment 1 aimed to observe the effects of the presented features. Five combinations of the features were evaluated with a five-fold cross validation assuming that an optimal parameter combination was obtained. The experiment conditions are described below: A. Data 7,690 drug—symptom pairs were extracted from the corpus. Manually </context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vapnik, Vladimir N.. 1995. The Nature of Statistical Learning Theory. Springer-Verlag New York, Inc..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Gyorgy Szarvas</author>
<author>Richard Farkas</author>
<author>Gyorgy M6ra</author>
<author>Janos Csirik</author>
</authors>
<title>The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes.</title>
<date>2008</date>
<journal>BMC Bioinformatics</journal>
<pages>9--11</pages>
<marker>Vincze, Szarvas, Farkas, M6ra, Csirik, 2008</marker>
<rawString>Vincze, Veronika, Gyorgy Szarvas, Richard Farkas, Gyorgy M6ra, and Janos Csirik. 2008. The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics 2008, 9(Suppl 11):S9.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>