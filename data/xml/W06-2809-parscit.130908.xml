<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010476">
<title confidence="0.9988375">
A proposal to automatically build and maintain gazetteers for Named
Entity Recognition by using Wikipedia
</title>
<author confidence="0.995926">
Antonio Toral
</author>
<affiliation confidence="0.995552">
University of Alicante
</affiliation>
<address confidence="0.6282455">
Carretera San Vicente S/N
Alicante 03690, Spain
</address>
<email confidence="0.995671">
atoral@dlsi.ua.es
</email>
<author confidence="0.992471">
Rafael Mu˜noz
</author>
<affiliation confidence="0.993966">
University of Alicante
</affiliation>
<address confidence="0.628412">
Carretera San Vicente S/N
Alicante 03690, Spain
</address>
<email confidence="0.997697">
rafael@dlsi.ua.es
</email>
<sectionHeader confidence="0.995619" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997380625">
This paper describes a method to automat-
ically create and maintain gazetteers for
Named Entity Recognition (NER). This
method extracts the necessary information
from linguistic resources. Our approach is
based on the analysis of an on-line ency-
clopedia entries by using a noun hierarchy
and optionally a PoS tagger. An impor-
tant motivation is to reach a high level of
language independence. This restricts the
techniques that can be used but makes the
method useful for languages with few re-
sources. The evaluation carried out proves
that this approach can be successfully used
to build NER gazetteers for location (F
78%) and person (F 68%) categories.
</bodyText>
<sectionHeader confidence="0.998967" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.977790530612245">
Named Entity Recognition (NER) was defined at
the MUC conferences (Chinchor, 1998) as the task
consisting of detecting and classifying strings of
text which are considered to belong to different
classes (e.g. person, location, organization, date,
time). Named Entities are theoretically identified
and classified by using evidence. Two kinds of
evidence have been defined (McDonald, 1996).
These are internal and external evidence. Internal
evidence is the one provided from within the se-
quence of words that constitute the entity. In con-
trast, external evidence is the criteria that can be
obtained by the context in which entities appear.
Since the time NER was introduced, mainly two
approaches have been adopted to deal with this
task. One is referred as knowledge-based and uses
explicit resources like rules and gazetteers, which
commonly are hand-crafted. The other follows the
learning paradigm and usually uses as a resource a
tagged corpus which is used to train a supervised
learning algorithm.
In the knowledge-based approach two kind of
gazetteers can be distinguished. On one hand there
are trigger gazetteers, which contain key words
that indicate the possible presence of an entity of
a given type. These words usually are common
nouns. E.g. ms. indicates that the entity after it
is a person entity. On the other hand there are en-
tity gazetteers which contain entities themselves,
which usually are proper nouns. E.g. Portugal
could be an instance in a location gazetteer.
Initially, and specially for the MUC confer-
ences, most of the NER systems developed did
belong to the knowledge-based approach. This ap-
proach proved to be able to obtain high scores. In
fact, the highest score obtained by a knowledge-
based system in MUC-7 reached F 93.39 %
(Mikheev et al., 1998). However, this approach
has an important problem: gazetteers and rules are
difficult and tedious to develop and to maintain. If
the system is to be used for an open domain, lin-
guistic experts are needed to build the rules, and
besides, it takes too much time to tune these re-
sources in order to obtain satisfactory results. Be-
cause of this, lately most of the research falls into
the learning-based paradigm.
Regarding the creation and maintenance of
gazetteers, several problems have been identified,
these are mainly:
</bodyText>
<listItem confidence="0.999874">
• Creation and maintenance effort
• Overlaps between gazetteers
</listItem>
<bodyText confidence="0.996392666666667">
The first problem identified assumes that the
gazetteers are manually created and maintained.
However, this is not always the case. Gazetteers
</bodyText>
<page confidence="0.99439">
56
</page>
<bodyText confidence="0.999973571428572">
could be automatically created and maintained by
extracting the necessary information from avail-
able linguistic resources, which we think is a
promising line of future research.
Several research works have been carried out in
this direction. An example of this is a NER sys-
tem which uses trigger gazetteers automatically
extracted from WordNet (Magnini et al., 2002)
by using wordnet predicates. The advantage in
this case is that the resource used is multilingual
and thus, porting it to another language is almost
straightforward (Negri and Magnini, 2004).
There is also a work that deals with automat-
ically building location gazetteers from internet
texts by applying text mining procedures (Ouri-
oupina, 2002), (Uryupina, 2003). However, this
work uses linguistic patterns, and thus is language
dependent. The author claims that the approach
may successfully be used to create gazetteers for
NER.
We agree with (Magnini et al., 2002) that in or-
der to automatically create and maintain trigger
gazetteers, using a hierarchy of common nouns is
a good approach. Therefore, we want to focus on
the automatically creation and maintenance of en-
tity gazetteers. Another reason for this is that the
class of common nouns (the ones being triggers) is
much more stable than the class of proper names
(the ones in entity gazetteers). Because of this,
the maintenance of the latter is important as new
entities to be taken into account appear. For exam-
ple, if we refer to presidents, the trigger word used
might be ’president’ and it is uncommon that the
trigger used to refer to them changes over time.
On the other hand, the entities being presidents
change as new presidents appear and current pres-
idents will disappear.
Our aim is to find a method which allow us to
automatically create and maintain entity gazetteers
by extracting the necessary information from lin-
guistic resources. An important restriction though,
is that we want our method to be as independent of
language as possible.
The rest of this paper is structured as follows.
In the next section we discuss about our proposal.
Section three presents the results we have obtained
and some comments about them. Finally, in sec-
tion four we outline our conclusions and future
work.
</bodyText>
<sectionHeader confidence="0.943253" genericHeader="introduction">
2 Approach
</sectionHeader>
<bodyText confidence="0.999588466666667">
In this section we present our approach to auto-
matically build and maintain dictionaries of proper
nouns. In a nutshell, we analyse the entries of an
encyclopedia with the aid of a noun hierarchy. Our
motivation is that proper nouns that form entities
can be obtained from the entries in an encyclo-
pedia and that some features of their definitions
in the encyclopedia can help to classify them into
their correct entity category.
The encyclopedia used has been Wikipedia1.
According to the English version of Wikipedia
2, Wikipedia is a multi-lingual web-based, free-
content encyclopedia which is updated continu-
ously in a collaborative way. The reasons why we
have chosen this encyclopedia are the following:
</bodyText>
<listItem confidence="0.992610238095238">
• It is a big source of information. By De-
cember 2005, it has over 2,500,000 defini-
tions. The English version alone has more
than 850,000 entries.
• Its content has a free license, meaning that it
will always be available for research without
restrictions and without needing to acquire
any license.
• It is a general knowledge resource. Thus, it
can be used to extract information for open
domain systems.
• Its data has some degree of formality and
structure (e.g. categories) which helps to pro-
cess it.
• It is a multilingual resource. Thus, if we are
able to develop a language independent sys-
tem, it can be used to create gazetteers for any
language for which Wikipedia is available.
• It is continuously updated. This is a very
important fact for the maintenance of the
gazetteers.
</listItem>
<bodyText confidence="0.999560166666667">
The noun hierarchy used has been the noun hi-
erarchy from WordNet (Miller, 1995). This is a
widely used resource for NLP tasks. Although
initially being a monolingual resource for the En-
glish language, a later project called EuroWordNet
(Vossen, 1998), provided wordnet-like hierarchies
</bodyText>
<footnote confidence="0.999908">
1http://www.wikipedia.org
2http://en.wikipedia.org/wiki/Main Page
</footnote>
<page confidence="0.998305">
57
</page>
<bodyText confidence="0.99929588">
for a set of languages of the European Union. Be-
sides, EuroWordNet defines a language indepen-
dent index called Inter-Lingual-Index (ILI) which
allows to establish relations between words in
wordnets of different languages. The ILI facili-
tates also the development of wordnets for other
languages.
From this noun hierarchy we consider the nodes
(called synsets in WordNet) which in our opinion
represent more accurately the different kind of en-
tities we are working with (location, organization
and person). For example, we consider the synset
6026 as the corresponding to the entity class Per-
son. This is the information contained in synset
number 6026:
person, individual, someone,
somebody, mortal,
human, soul -- (a human being;
&amp;quot;there was too much for one person
to do&amp;quot;)
Given an entry from Wikipedia, a PoS-tagger
(Carreras et al., 2004) is applied to the first sen-
tence of its definition. As an example, the first
sentence of the entry Portugal in the Simple En-
glish Wikipedia 3 is presented here:
</bodyText>
<table confidence="0.8552768">
Portugal portugal NN
is be VBZ
a a DT
country country NN
in in IN
the the DT
south-west south-west NN
of of IN
Europe Europe NP
. . Fp
</table>
<bodyText confidence="0.997827111111111">
For every noun in a definition we obtain the
synset of WordNet that contains its first sense4.
We follow the hyperonymy branch of this synset
until we arrive to a synset we have considered be-
longing to an entity class or we arrive to the root of
the hierarchy. If we arrive to a considered synset,
then we consider that noun as belonging to the en-
tity class of the considered synset. The following
example may clarify this explanation:
</bodyText>
<footnote confidence="0.944359666666667">
portugal --&gt; LOCATION
3http://simple.wikipedia.org/wiki/Portugal
4We have also carried out experiments taking into account
all the senses provided by WordNet. However, the perfor-
mance obtained is not substantially better while the process-
ing time increases notably.
</footnote>
<construct confidence="0.296676">
country --&gt; LOCATION
south-west --&gt; NONE
europe --&gt; LOCATION
</construct>
<bodyText confidence="0.999796933333334">
As it has been said in the abstract, the appli-
cation of a PoS tagger is optional. The algorithm
will perform considerably faster with it as with the
PoS data we only need to process the nouns. If a
PoS tagger is not available for a language, the al-
gorithm can still be applied. The only drawback
is that it will perform slower as it needs to pro-
cess all the words. However, through our experi-
mentation we can conclude that the results do not
significantly change.
Finally, we apply a weighting algorithm which
takes into account the amount of nouns in the defi-
nition identified as belonging to the different entity
types considered and decides to which entity type
the entry belongs. This algorithm has a constant
Kappa which allows to increase or decrease the
distance required within categories in order to as-
sign an entry to a given class. The value of Kappa
is the minimum difference of number of occur-
rences between the first and second most frequent
categories in an entry in order to assign the entry
to the first category. In our example, for any value
of Kappa lower than 4, the algorithm would say
that the entry Portugal belongs to the location en-
tity type.
Once we have this basic approach we apply dif-
ferent heuristics which we think may improve the
results obtained and which effect will be analysed
in the section about results.
The first heuristic, called is instance, tries to de-
termine whether the entries from Wikipedia are in-
stances (e.g. Portugal) or word classes (e.g. coun-
try). This is done because of the fact that named
entities only consider instances. Therefore, we are
not interested in word classes. We consider that an
entry from Wikipedia is an instance when it has an
associated entry in WordNet and it is an instance.
The procedure to determine if an entry from Word-
Net is an instance or a word class is similar to the
one used in (Magnini et al., 2002).
The second heuristic is called is in wordnet. It
simply determines if the entries from Wikipedia
have an associated entry in WordNet. If so, we
may use the information from WordNet to deter-
mine its category.
</bodyText>
<page confidence="0.998568">
58
</page>
<sectionHeader confidence="0.989105" genericHeader="related work">
3 Experiments and results
</sectionHeader>
<bodyText confidence="0.9999821875">
We have tested our approach by applying it to
3517 entries of the Simple English Wikipedia
which were randomly selected. Thus, these en-
tries have been manually tagged with the expected
entity category5. The distribution by entity classes
can be seen in table 1:
As it can be seen in table 1, the amount of enti-
ties of the categories Person and Location are bal-
anced but this is not the case for the type Organi-
zation. There are very few instances of this type.
This is understandable as in an encyclopedia lo-
cations and people are defined but this is not the
usual case for organizations.
According to what was said in section 2, we
considered the heuristics explained there by car-
rying out two experiments. In the first one we
applied the is instance heuristic. The second ex-
periment considers the two heuristics explained in
section 2 (is instance and is in wordnet). We do
not present results without the first heuristic as
through our experimentation it proved to increase
both recall and precision for every entity category.
For each experiment we considered two values
of a constant Kappa which is used in our algo-
rithm. The values are 0 and 2 as through exper-
imentation we found these are the values which
provide the highest recall and the highest preci-
sion, respectively. Results for the first experiment
can be seen in table 2 and results for the second
experiment in table 3.
As it can be seen in these tables, the best re-
call for all classes is obtained in experiment 2 with
Kappa 0 (table 3) while the best precision is ob-
tained in experiment 1 with Kappa 2 (table 2).
The results both for location and person cat-
egories are in our opinion good enough to the
purpose of building and maintaining good quality
gazetteers after a manual supervision. However,
the results obtained for the organization class are
very low. This is mainly due to the fact of the
high interaction between this category and loca-
tion combined with the practically absence of tra-
ditional entities of the organization type such as
companies. This interaction can be seen in the in-
depth results which presentation follows.
In order to clarify these results, we present more
in-depth data in tables 4 and 5. These tables
present an error analysis, showing the false posi-
</bodyText>
<footnote confidence="0.9527035">
5This data is available for research at http://www.
dlsi.ua.es/˜atoral/index.html\#resources
</footnote>
<bodyText confidence="0.99994652631579">
tives, false negatives, true positives and true nega-
tives among all the categories for the configuration
that provides the highest recall (experiment 2 with
Kappa 0) and for the one that provides the highest
precision (experiment 1 with Kappa 2).
In tables 4 and 5 we can see that the interactions
within classes (occurrences tagged as belonging to
one class but NONE and guessed as belonging to
other different class but NONE) is low. The only
case in which it is significant is between location
and organization. In table 5 we can see that 12 en-
tities tagged as organization are classified as LOC
while 20 tagged as organization are guessed with
the correct type. Following with these, 5 entities
tagged as location where classified as organiza-
tion. This is due to the fact that countries and
related entities such as ”European Union” can be
considered both as organizations or locations de-
pending on their role in a text.
</bodyText>
<sectionHeader confidence="0.997438" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999971766666667">
We have presented a method to automatically cre-
ate and maintain entity gazetteers using as re-
sources an encyclopedia, a noun hierarchy and,
optionally, a PoS tagger. The method proves to be
helpful for these tasks as it facilitates the creation
and maintenance of this kind of resources.
In our opinion, the principal drawback of our
system is that it has a low precision for the con-
figuration for which it obtains an acceptable value
of recall. Therefore, the automatically created
gazetteers need to pass a step of manual supervi-
sion in order to have a good quality.
On the positive side, we can conclude that our
method is helpful as it takes less time to automat-
ically create gazetteers with our method and after
that to supervise them than to create that dictio-
naries from scratch. Moreover, the updating of the
gazetteers is straightforward; just by executing the
procedure, the new entries in Wikipedia (the en-
tries that did not exist at the time the procedure
was performed the last time) would be analysed
and from these set, the ones detected as entities
would be added to the corresponding gazetteers.
Another important fact is that the method has
a high degree of language independence; in or-
der to apply this approach to a new language, we
need a version of Wikipedia and WordNet for that
language, but the algorithm and the process does
not change. Therefore, we think that our method
can be useful for the creation of gazetteers for lan-
</bodyText>
<page confidence="0.995614">
59
</page>
<table confidence="0.974703">
Entity type Number of instances Percentage
NONE 2822
LOC 404 58
ORG 55 8
PER 236 34
</table>
<tableCaption confidence="0.982839">
Table 1: Distribution by entity classes
</tableCaption>
<table confidence="0.9988935">
k LOC ORG PER
prec rec Fβ_1 prec rec Fβ_1 prec rec Fβ_1
0 66.90 94.55 78.35 28.57 18.18 22.22 61.07 77.11 68.16
2 86.74 56.68 68.56 66.66 3.63 6.89 86.74 30.50 45.14
</table>
<tableCaption confidence="0.991948">
Table 2: Experiment 1. Results applying is instance heuristic
</tableCaption>
<table confidence="0.99904125">
k LOC ORG PER
prec rec Fβ_1 prec rec Fβ_1 prec rec Fβ_1
0 62.88 96.03 76.00 16.17 20.00 17.88 43.19 84.74 57.22
2 77.68 89.60 83.21 13.95 10.90 12.24 46.10 62.71 53.14
</table>
<tableCaption confidence="0.998267">
Table 3: Experiment 2. Results applying is instance and is in wordnet heuristics
</tableCaption>
<table confidence="0.998472666666667">
Tagged Guessed
NONE LOC ORG PER
NONE 2777 33 1 11
LOC 175 229 0 0
ORG 52 1 2 0
PER 163 1 0 72
</table>
<tableCaption confidence="0.986978">
Table 4: Results fn-fp (results 1 k=2)
</tableCaption>
<table confidence="0.997584666666667">
Tagged Guessed
NONE LOC ORG PER
NONE 2220 196 163 243
LOC 8 387 5 4
ORG 20 12 20 3
PER 30 9 2 195
</table>
<tableCaption confidence="0.999418">
Table 5: Results fn-fp (results 2 k=0)
</tableCaption>
<page confidence="0.997367">
60
</page>
<bodyText confidence="0.999577210526316">
guages in which NER gazetteers are not available
but have Wikipedia and WordNet resources.
During the development of this research, several
future works possibilities have appeared. Regard-
ing the task we have developed, we consider to
carry out new experiments incorporating features
that Wikipedia provides such as links between
pairs of entries. Following with this, we consider
to test more complex weighting techniques for our
algorithm.
Besides, we think that the resulting gazetteers
for the configurations that provide high precision
and low recall, although not being appropriate for
building gazetteers for NER systems, can be in-
teresting for other tasks. As an example, we con-
sider to use them to extract verb frequencies for
the entity categories considered which can be later
used as features for a learning based Named Entity
Recogniser.
</bodyText>
<sectionHeader confidence="0.995997" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999909">
This research has been partially funded by the
Spanish Government under project CICyT num-
ber TIC2003-07158-C04-01 and by the Valencia
Government under project number GV04B-268.
We also would like to specially thank Borja
Navarro for his valuable help on WordNet.
</bodyText>
<sectionHeader confidence="0.999264" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999729147058824">
X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004.
Freeling: An Open-Source Suite of Language Ana-
lyzers. In Proceedings of the 4th LREC Conference.
N. Chinchor. 1998. Overview of MUC-7. In Proceed-
ings of the Seventh Message Understanding Confer-
ence (MUC-7).
B. Magnini, M. Negri, R. Preete, and H. Tanev. 2002.
A wordnet-based approach to named entities recog-
nition. In Proceedings of SemaNet ’02: Building
and Using Semantic Networks, pages 38–44.
D. McDonald. 1996. Internal and external evidence
in the identification and semantic categorization of
proper names. Corpus Processing for Lexical Aqui-
sition, pages 21–39, chapter 2.
A. Mikheev, C. Grover, and M. Moens. 1998. Descrip-
tion of the LTG system used for MUC-7. In Seventh
Message Understanding Conference (MUC-7): Pro-
ceedings of a Conference held in Fairfax, Virginia,
29 April-1 May.
G. A. Miller. 1995. Wordnet: A lexical database for
english. Communications ofACM, (11):39–41.
M. Negri and B. Magnini. 2004. Using wordnet pred-
icates for multilingual named entity recognition. In
Proceedings of The Second Global Wordnet Confer-
ence, pages 169–174.
O. Ourioupina. 2002. Extracting geographical knowl-
edge from the internet. In Proceedings of the ICDM-
AM International Workshop on Active Mining.
O. Uryupina. 2003. Semi-supervised learning of geo-
graphical gazetteers from the internet. In Proceed-
ings of the HLT-NAACL 2003 Workshop on Analysis
of Geographic References, pages 18–25.
P. Vossen. 1998. Introduction to eurowordnet. Com-
puters and the Humanities, 32:73–89.
</reference>
<page confidence="0.999271">
61
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.252527">
<title confidence="0.996744">A proposal to automatically build and maintain gazetteers for Entity Recognition by using Wikipedia</title>
<author confidence="0.999514">Antonio Toral</author>
<affiliation confidence="0.794493">University of Alicante Carretera San Vicente S/N</affiliation>
<address confidence="0.930469">Alicante 03690, Spain</address>
<email confidence="0.855205">atoral@dlsi.ua.es</email>
<affiliation confidence="0.7954455">University of Alicante Carretera San Vicente S/N</affiliation>
<address confidence="0.955836">Alicante 03690, Spain</address>
<email confidence="0.984752">rafael@dlsi.ua.es</email>
<abstract confidence="0.993641058823529">This paper describes a method to automatically create and maintain gazetteers for Named Entity Recognition (NER). This method extracts the necessary information from linguistic resources. Our approach is based on the analysis of an on-line encyclopedia entries by using a noun hierarchy and optionally a PoS tagger. An important motivation is to reach a high level of language independence. This restricts the techniques that can be used but makes the method useful for languages with few resources. The evaluation carried out proves that this approach can be successfully used to build NER gazetteers for location (F 78%) and person (F 68%) categories.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>I Chao</author>
<author>L Padr´o</author>
<author>M Padr´o</author>
</authors>
<title>Freeling: An Open-Source Suite of Language Analyzers.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th LREC Conference.</booktitle>
<marker>Carreras, Chao, Padr´o, Padr´o, 2004</marker>
<rawString>X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004. Freeling: An Open-Source Suite of Language Analyzers. In Proceedings of the 4th LREC Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chinchor</author>
</authors>
<title>Overview of MUC-7.</title>
<date>1998</date>
<booktitle>In Proceedings of the Seventh Message Understanding Conference (MUC-7).</booktitle>
<contexts>
<context position="1072" citStr="Chinchor, 1998" startWordPosition="160" endWordPosition="161">he necessary information from linguistic resources. Our approach is based on the analysis of an on-line encyclopedia entries by using a noun hierarchy and optionally a PoS tagger. An important motivation is to reach a high level of language independence. This restricts the techniques that can be used but makes the method useful for languages with few resources. The evaluation carried out proves that this approach can be successfully used to build NER gazetteers for location (F 78%) and person (F 68%) categories. 1 Introduction Named Entity Recognition (NER) was defined at the MUC conferences (Chinchor, 1998) as the task consisting of detecting and classifying strings of text which are considered to belong to different classes (e.g. person, location, organization, date, time). Named Entities are theoretically identified and classified by using evidence. Two kinds of evidence have been defined (McDonald, 1996). These are internal and external evidence. Internal evidence is the one provided from within the sequence of words that constitute the entity. In contrast, external evidence is the criteria that can be obtained by the context in which entities appear. Since the time NER was introduced, mainly</context>
</contexts>
<marker>Chinchor, 1998</marker>
<rawString>N. Chinchor. 1998. Overview of MUC-7. In Proceedings of the Seventh Message Understanding Conference (MUC-7).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>M Negri</author>
<author>R Preete</author>
<author>H Tanev</author>
</authors>
<title>A wordnet-based approach to named entities recognition.</title>
<date>2002</date>
<booktitle>In Proceedings of SemaNet ’02: Building and Using Semantic Networks,</booktitle>
<pages>38--44</pages>
<contexts>
<context position="3872" citStr="Magnini et al., 2002" startWordPosition="608" endWordPosition="611">lems have been identified, these are mainly: • Creation and maintenance effort • Overlaps between gazetteers The first problem identified assumes that the gazetteers are manually created and maintained. However, this is not always the case. Gazetteers 56 could be automatically created and maintained by extracting the necessary information from available linguistic resources, which we think is a promising line of future research. Several research works have been carried out in this direction. An example of this is a NER system which uses trigger gazetteers automatically extracted from WordNet (Magnini et al., 2002) by using wordnet predicates. The advantage in this case is that the resource used is multilingual and thus, porting it to another language is almost straightforward (Negri and Magnini, 2004). There is also a work that deals with automatically building location gazetteers from internet texts by applying text mining procedures (Ourioupina, 2002), (Uryupina, 2003). However, this work uses linguistic patterns, and thus is language dependent. The author claims that the approach may successfully be used to create gazetteers for NER. We agree with (Magnini et al., 2002) that in order to automaticall</context>
<context position="11394" citStr="Magnini et al., 2002" startWordPosition="1878" endWordPosition="1881">sults obtained and which effect will be analysed in the section about results. The first heuristic, called is instance, tries to determine whether the entries from Wikipedia are instances (e.g. Portugal) or word classes (e.g. country). This is done because of the fact that named entities only consider instances. Therefore, we are not interested in word classes. We consider that an entry from Wikipedia is an instance when it has an associated entry in WordNet and it is an instance. The procedure to determine if an entry from WordNet is an instance or a word class is similar to the one used in (Magnini et al., 2002). The second heuristic is called is in wordnet. It simply determines if the entries from Wikipedia have an associated entry in WordNet. If so, we may use the information from WordNet to determine its category. 58 3 Experiments and results We have tested our approach by applying it to 3517 entries of the Simple English Wikipedia which were randomly selected. Thus, these entries have been manually tagged with the expected entity category5. The distribution by entity classes can be seen in table 1: As it can be seen in table 1, the amount of entities of the categories Person and Location are bala</context>
</contexts>
<marker>Magnini, Negri, Preete, Tanev, 2002</marker>
<rawString>B. Magnini, M. Negri, R. Preete, and H. Tanev. 2002. A wordnet-based approach to named entities recognition. In Proceedings of SemaNet ’02: Building and Using Semantic Networks, pages 38–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McDonald</author>
</authors>
<title>Internal and external evidence in the identification and semantic categorization of proper names. Corpus Processing for Lexical Aquisition,</title>
<date>1996</date>
<pages>21--39</pages>
<contexts>
<context position="1378" citStr="McDonald, 1996" startWordPosition="204" endWordPosition="205">makes the method useful for languages with few resources. The evaluation carried out proves that this approach can be successfully used to build NER gazetteers for location (F 78%) and person (F 68%) categories. 1 Introduction Named Entity Recognition (NER) was defined at the MUC conferences (Chinchor, 1998) as the task consisting of detecting and classifying strings of text which are considered to belong to different classes (e.g. person, location, organization, date, time). Named Entities are theoretically identified and classified by using evidence. Two kinds of evidence have been defined (McDonald, 1996). These are internal and external evidence. Internal evidence is the one provided from within the sequence of words that constitute the entity. In contrast, external evidence is the criteria that can be obtained by the context in which entities appear. Since the time NER was introduced, mainly two approaches have been adopted to deal with this task. One is referred as knowledge-based and uses explicit resources like rules and gazetteers, which commonly are hand-crafted. The other follows the learning paradigm and usually uses as a resource a tagged corpus which is used to train a supervised le</context>
</contexts>
<marker>McDonald, 1996</marker>
<rawString>D. McDonald. 1996. Internal and external evidence in the identification and semantic categorization of proper names. Corpus Processing for Lexical Aquisition, pages 21–39, chapter 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mikheev</author>
<author>C Grover</author>
<author>M Moens</author>
</authors>
<title>Description of the LTG system used for MUC-7.</title>
<date>1998</date>
<booktitle>In Seventh Message Understanding Conference (MUC-7): Proceedings of a Conference held in</booktitle>
<location>Fairfax, Virginia, 29 April-1</location>
<contexts>
<context position="2775" citStr="Mikheev et al., 1998" startWordPosition="434" endWordPosition="437">he possible presence of an entity of a given type. These words usually are common nouns. E.g. ms. indicates that the entity after it is a person entity. On the other hand there are entity gazetteers which contain entities themselves, which usually are proper nouns. E.g. Portugal could be an instance in a location gazetteer. Initially, and specially for the MUC conferences, most of the NER systems developed did belong to the knowledge-based approach. This approach proved to be able to obtain high scores. In fact, the highest score obtained by a knowledgebased system in MUC-7 reached F 93.39 % (Mikheev et al., 1998). However, this approach has an important problem: gazetteers and rules are difficult and tedious to develop and to maintain. If the system is to be used for an open domain, linguistic experts are needed to build the rules, and besides, it takes too much time to tune these resources in order to obtain satisfactory results. Because of this, lately most of the research falls into the learning-based paradigm. Regarding the creation and maintenance of gazetteers, several problems have been identified, these are mainly: • Creation and maintenance effort • Overlaps between gazetteers The first probl</context>
</contexts>
<marker>Mikheev, Grover, Moens, 1998</marker>
<rawString>A. Mikheev, C. Grover, and M. Moens. 1998. Description of the LTG system used for MUC-7. In Seventh Message Understanding Conference (MUC-7): Proceedings of a Conference held in Fairfax, Virginia, 29 April-1 May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>Wordnet: A lexical database for english.</title>
<date>1995</date>
<journal>Communications ofACM,</journal>
<pages>11--39</pages>
<contexts>
<context position="7330" citStr="Miller, 1995" startWordPosition="1190" endWordPosition="1191">s and without needing to acquire any license. • It is a general knowledge resource. Thus, it can be used to extract information for open domain systems. • Its data has some degree of formality and structure (e.g. categories) which helps to process it. • It is a multilingual resource. Thus, if we are able to develop a language independent system, it can be used to create gazetteers for any language for which Wikipedia is available. • It is continuously updated. This is a very important fact for the maintenance of the gazetteers. The noun hierarchy used has been the noun hierarchy from WordNet (Miller, 1995). This is a widely used resource for NLP tasks. Although initially being a monolingual resource for the English language, a later project called EuroWordNet (Vossen, 1998), provided wordnet-like hierarchies 1http://www.wikipedia.org 2http://en.wikipedia.org/wiki/Main Page 57 for a set of languages of the European Union. Besides, EuroWordNet defines a language independent index called Inter-Lingual-Index (ILI) which allows to establish relations between words in wordnets of different languages. The ILI facilitates also the development of wordnets for other languages. From this noun hierarchy we</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>G. A. Miller. 1995. Wordnet: A lexical database for english. Communications ofACM, (11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>B Magnini</author>
</authors>
<title>Using wordnet predicates for multilingual named entity recognition.</title>
<date>2004</date>
<booktitle>In Proceedings of The Second Global Wordnet Conference,</booktitle>
<pages>169--174</pages>
<contexts>
<context position="4063" citStr="Negri and Magnini, 2004" startWordPosition="638" endWordPosition="641">nd maintained. However, this is not always the case. Gazetteers 56 could be automatically created and maintained by extracting the necessary information from available linguistic resources, which we think is a promising line of future research. Several research works have been carried out in this direction. An example of this is a NER system which uses trigger gazetteers automatically extracted from WordNet (Magnini et al., 2002) by using wordnet predicates. The advantage in this case is that the resource used is multilingual and thus, porting it to another language is almost straightforward (Negri and Magnini, 2004). There is also a work that deals with automatically building location gazetteers from internet texts by applying text mining procedures (Ourioupina, 2002), (Uryupina, 2003). However, this work uses linguistic patterns, and thus is language dependent. The author claims that the approach may successfully be used to create gazetteers for NER. We agree with (Magnini et al., 2002) that in order to automatically create and maintain trigger gazetteers, using a hierarchy of common nouns is a good approach. Therefore, we want to focus on the automatically creation and maintenance of entity gazetteers.</context>
</contexts>
<marker>Negri, Magnini, 2004</marker>
<rawString>M. Negri and B. Magnini. 2004. Using wordnet predicates for multilingual named entity recognition. In Proceedings of The Second Global Wordnet Conference, pages 169–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Ourioupina</author>
</authors>
<title>Extracting geographical knowledge from the internet.</title>
<date>2002</date>
<booktitle>In Proceedings of the ICDMAM International Workshop on Active Mining.</booktitle>
<contexts>
<context position="4218" citStr="Ourioupina, 2002" startWordPosition="663" endWordPosition="665">lable linguistic resources, which we think is a promising line of future research. Several research works have been carried out in this direction. An example of this is a NER system which uses trigger gazetteers automatically extracted from WordNet (Magnini et al., 2002) by using wordnet predicates. The advantage in this case is that the resource used is multilingual and thus, porting it to another language is almost straightforward (Negri and Magnini, 2004). There is also a work that deals with automatically building location gazetteers from internet texts by applying text mining procedures (Ourioupina, 2002), (Uryupina, 2003). However, this work uses linguistic patterns, and thus is language dependent. The author claims that the approach may successfully be used to create gazetteers for NER. We agree with (Magnini et al., 2002) that in order to automatically create and maintain trigger gazetteers, using a hierarchy of common nouns is a good approach. Therefore, we want to focus on the automatically creation and maintenance of entity gazetteers. Another reason for this is that the class of common nouns (the ones being triggers) is much more stable than the class of proper names (the ones in entity</context>
</contexts>
<marker>Ourioupina, 2002</marker>
<rawString>O. Ourioupina. 2002. Extracting geographical knowledge from the internet. In Proceedings of the ICDMAM International Workshop on Active Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Uryupina</author>
</authors>
<title>Semi-supervised learning of geographical gazetteers from the internet.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLT-NAACL 2003 Workshop on Analysis of Geographic References,</booktitle>
<pages>18--25</pages>
<contexts>
<context position="4236" citStr="Uryupina, 2003" startWordPosition="666" endWordPosition="667">ources, which we think is a promising line of future research. Several research works have been carried out in this direction. An example of this is a NER system which uses trigger gazetteers automatically extracted from WordNet (Magnini et al., 2002) by using wordnet predicates. The advantage in this case is that the resource used is multilingual and thus, porting it to another language is almost straightforward (Negri and Magnini, 2004). There is also a work that deals with automatically building location gazetteers from internet texts by applying text mining procedures (Ourioupina, 2002), (Uryupina, 2003). However, this work uses linguistic patterns, and thus is language dependent. The author claims that the approach may successfully be used to create gazetteers for NER. We agree with (Magnini et al., 2002) that in order to automatically create and maintain trigger gazetteers, using a hierarchy of common nouns is a good approach. Therefore, we want to focus on the automatically creation and maintenance of entity gazetteers. Another reason for this is that the class of common nouns (the ones being triggers) is much more stable than the class of proper names (the ones in entity gazetteers). Beca</context>
</contexts>
<marker>Uryupina, 2003</marker>
<rawString>O. Uryupina. 2003. Semi-supervised learning of geographical gazetteers from the internet. In Proceedings of the HLT-NAACL 2003 Workshop on Analysis of Geographic References, pages 18–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<date>1998</date>
<booktitle>Introduction to eurowordnet. Computers and the Humanities,</booktitle>
<pages>32--73</pages>
<contexts>
<context position="7501" citStr="Vossen, 1998" startWordPosition="1217" endWordPosition="1218">e degree of formality and structure (e.g. categories) which helps to process it. • It is a multilingual resource. Thus, if we are able to develop a language independent system, it can be used to create gazetteers for any language for which Wikipedia is available. • It is continuously updated. This is a very important fact for the maintenance of the gazetteers. The noun hierarchy used has been the noun hierarchy from WordNet (Miller, 1995). This is a widely used resource for NLP tasks. Although initially being a monolingual resource for the English language, a later project called EuroWordNet (Vossen, 1998), provided wordnet-like hierarchies 1http://www.wikipedia.org 2http://en.wikipedia.org/wiki/Main Page 57 for a set of languages of the European Union. Besides, EuroWordNet defines a language independent index called Inter-Lingual-Index (ILI) which allows to establish relations between words in wordnets of different languages. The ILI facilitates also the development of wordnets for other languages. From this noun hierarchy we consider the nodes (called synsets in WordNet) which in our opinion represent more accurately the different kind of entities we are working with (location, organization a</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>P. Vossen. 1998. Introduction to eurowordnet. Computers and the Humanities, 32:73–89.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>