<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.092356">
<title confidence="0.979593">
Using a maximum entropy-based tagger to improve a very fast vine parser
</title>
<author confidence="0.998951">
Anders Søgaard Jonas Kuhn
</author>
<affiliation confidence="0.999283">
Center for Language Technology Dpt. of Linguistics
University of Copenhagen University of Potsdam
</affiliation>
<email confidence="0.988722">
soegaard@hum.ku.dk kuhn@ling.uni-potsdam.de
</email>
<sectionHeader confidence="0.993681" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999657">
In this short paper, an off-the-shelf maxi-
mum entropy-based POS-tagger is used as
a partial parser to improve the accuracy of
an extremely fast linear time dependency
parser that provides state-of-the-art results
in multilingual unlabeled POS sequence
parsing.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.955641902777778">
The dependency parsing literature has grown in all
directions the past 10 years or so. Dependency
parsing is used in a wide variety of applications,
and many different parsing techniques have been
proposed.
Two dependency parsers have become more
popular than the rest, namely MSTParser (Mc-
Donald et al., 2005) and MaltParser (Nivre et
al., 2007). MSTParser is slightly more accu-
rate than MaltParser on most languages, especially
when dependencies are long and non-projective,
but MaltParser is theoretically more efficient as it
runs in linear time. Both are relatively slow in
terms of training (hours, sometimes days), and rel-
atively big models are queried in parsing.
MSTParser and MaltParser can be optimized for
speed in various ways,1 but the many applications
of dependency parsers today may turn model size
into a serious problem. MSTParser typically takes
about a minute to parse a small standard test suite,
say 2–300 sentences; the stand-alone version of
MaltParser may take 5–8 minutes. Such parsing
times are problematic in, say, a machine transla-
tion system where for each sentence pair multiple
1Recent work has optimized MaltParser considerably for
speed. Goldberg and Elhadad (2008) speed up the MaltParser
by a factor of 30 by simplifying the decision function for the
classifiers. Parsing is still considerably slower than with our
vine parser, i.e. a test suite is parsed in about 15–20 seconds,
whereas our vine parser parses a test suite in less than two
seconds.
target sentences are parsed (Charniak et al., 2003;
Galley and Manning, 2009). Since training takes
hours or days, researchers are also more reluctant
to experiment with new features, and it is very
likely that the features typically used in parsing
are suboptimal in, say, machine translation.
Conceptually simpler dependency parsers are
also easier to understand, which makes debugging,
cross-domain adaption or cross-language adapta-
tion a lot easier. Finally, state-of-the-art depen-
dency parsers may in fact be outperformed by sim-
pler systems on non-standard test languages with,
say, richer morphology or more flexible word or-
der.
Vine parsing is a parsing strategy that guaran-
tees fast parsing and smaller models, but the ac-
curacy of dependency-based vine parsers has been
non-competitive (Eisner and Smith, 2005; Dreyer
et al., 2006).
This paper shows how the accuracy of
dependency-based vine parsers can be improved
by 1–5% across six very different languages with
a very small cost in training time and practically
no cost in parsing time.
The main idea in our experiments is to use
a maximum entropy-based part-of-speech (POS)
tagger to identify roots and tokens whose heads
are immediately left or right of them. These are
tasks that a tagger can solve. You simply read
off a tagged text from the training, resp. test, sec-
tion of a treebank and replace all tags of roots,
i.e. tokens whose syntactic head is an artificial root
node, with a new tag ROOT. You then train on
the training section and apply your tagger on the
test section. The decisions made by the tagger
are then, subsequently, used as hard constraints by
your parser. When the parser then tries to find root
nodes, for instance, it is forced to use the roots as-
signed by the tagger. This strategy is meaningful
if the tagger has better precision for roots than the
parser. If it has better recall than the parser, the
</bodyText>
<page confidence="0.934607">
206
</page>
<bodyText confidence="0.99159825">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 206–209,
Paris, October 2009. c�2009 Association for Computational Linguistics
parser may be forced to select roots only from the
set of potential roots assigned by the tagger. In our
experiments, only the first strategy was used (since
the tagger’s precision was typically better than its
recall).
The dependency parser used in our experiments
is very simple. It is based on the Chu-Liu-
Edmonds algorithm (Edmonds, 1967), which is
also used in the MSTParser (McDonald et al.,
2005), but it is informed only by a simple MLE
training procedure and omits cycle contraction in
parsing. This means that it produces cyclic graphs.
In the context of poor training, insisting on acyclic
output graphs often compromises accuracy by &gt;
10%. On top of this parser, which is super fast but
often does not even outperform a simple structural
baseline, hard and soft constraints on dependency
length are learned discriminatively. The speed of
the parser allows us to repeatedly parse a tuning
section to optimize these constraints. In particular,
the tuning section (about 7500 tokens) is parsed
a fixed number of times for each POS/CPOS tag
to find the optimal dependency length constraint
when that tag is the tag of the head or dependent
word. In general, this discriminative training pro-
cedure takes about 10 minutes for an average-sized
treebank. The parser only produces unlabeled de-
pendency graphs and is still under development.
While accuracy is below state-of-the-art results,
our improved parser significantly outperforms a
default version of the MaltParser that is restricted
to POS tags only, on 5/6 languages (p ≤ 0.05),
and it significantly outperforms the baseline vine
parser on all languages.
</bodyText>
<sectionHeader confidence="0.993581" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.9999065">
Our languages are chosen from different language
families. Arabic is a Semitic language, Czech is
Slavic, Dutch is Germanic, Italian is Romance,
Japanese is Japonic-Ryukyuan, and Turkish is
Uralic. All treebanks, except Italian, were also
used in the CONLL-X Shared Task (Buchholz and
Marsi, 2006). The Italian treebank is the law
section of the TUT Treebank used in the Evalita
2007 Dependency Parsing Challenge (Bosco et al.,
2000).
</bodyText>
<sectionHeader confidence="0.999807" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.996344416666667">
The Python/C++ implementation of the maximum
entropy-based part-of-speech (POS) tagger first
described in Ratnaparkhi (1998) that comes with
the maximum entropy library in Zhang (2004) was
used to identify arcs to the root node and to tokens
immediately left or right of the dependent. This
was done by first extracting a tagged text from
each treebank with dependents of the root node as-
signed a special tag ROOT. Similarly, tagged texts
were extracted in which dependents of their im-
mediate left, resp. right neighbors, were assigned a
special tag. Our tagger was trained on the texts ex-
tracted from the training sections of the treebanks
and evaluated on the texts extracted from the test
sections. The number of gold standard, resp. pre-
dicted, ROOT/LEFT/RIGHT tags are presented in
Figure 1. Precision and f-score are also computed.
Note that since our parser uses information from
our tagger as hard constraints, i.e. it disregards
arcs to the root node or immediate neighbors not
predicted by our tagger, precision is really what
is important, not f-score. Or more precisely, preci-
sion indicates if our tagger is of any help to us, and
f-score tells us to what extent it may be of help.
</bodyText>
<sectionHeader confidence="0.999958" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999124392857143">
The results in Figure 2 show that using a maxi-
mum entropy-based POS tagger to identify roots
(ROOT), tokens with immediate left heads (LEFT)
and tokens with immediate (RIGHT) heads im-
proves the accuracy of a baseline vine parser
across the board for all languages measured in
terms of unlabeled attachment score (ULA), or de-
creases are insignificant (Czech and Turkish). For
all six languages, there is a combination of ROOT,
LEFT and RIGHT that significantly outperforms
the vine parser baseline. In 4/6 cases, absolute im-
provements are ≥ 2%. The score for Dutch is im-
proved by &gt; 4%. The extended vine parser is also
significantly better than the MaltParser restricted
to POS tags on 5/6 languages. MaltParser is prob-
ably better than the vine parser wrt. Japanese be-
cause average sentence length in this treebank is
very short (8.9); constraints on dependency length
do not really limit the search space.
In spite of the fact that our parser only uses POS
tags (except for the maximum entropy-based tag-
ger which considers both words and tags), scores
are now comparable to more mature dependency
parsers: ULA excl. punctuation for Arabic is
70.74 for Vine+ROOT+LEFT+RIGHT which is
better than six of the systems who participated in
the CONLL-X Shared Task and who had access to
all data in the treebank, i.e. tokens, lemmas, POS
</bodyText>
<page confidence="0.995154">
207
</page>
<table confidence="0.988993090909091">
Arabic Gold Predicted Precision F-score
ROOT 443 394 89.09 83.87
LEFT 3035 3180 84.28 86.24
RIGHT 313 196 82.14 63.26
Czech Gold Predicted Precision F-score
ROOT 737 649 85.36 79.94
LEFT 1485 1384 85.12 82.12
RIGHT 1288 1177 87.51 83.57
Dutch Gold Predicted Precision F-score
ROOT 522 360 74.44 60.77
LEFT 1734 1595 87.02 83.39
RIGHT 1300 1200 87.00 83.52
Italian Gold Predicted Precision F-score
ROOT 100 58 74.36 65.17
LEFT 1601 1640 90.30 91.39
RIGHT 192 129 84.87 74.14
Japanese Gold Predicted Precision F-score
ROOT 939 984 85.06 87.05
LEFT 1398 1382 97.76 97.19
RIGHT 2838 3016 92.27 95.08
Turkish Gold Predicted Precision F-score
ROOT 694 685 85.55 84.99
LEFT 750 699 91.70 88.47
RIGHT 3433 3416 84.19 83.98
Figure 1: Tag-specific evaluation of our tagger on the extracted texts.
Arabic Czech Dutch Italian Japanese Turkish
MaltParser 66.22 67.78 65.03 75.48 89.13 68.94
Vine 67.99 66.70 65.98 75.50 83.15 68.53
Vine+ROOT 68.68 66.65 66.21 78.06 83.82 68.45
Vine+ROOT+LEFT 69.68 68.14 68.05 77.14 84.64 68.37
Vine+RIGHT 68.50 67.38 68.18 78.55 84.17 69.87
Vine+ROOT+RIGHT 69.20 67.32 68.40 78.29 84.78 69.79
Vine+ROOT+LEFT+RIGHT 70.28 68.70 70.06 77.26 85.45 69.74
</table>
<figureCaption confidence="0.730569">
Figure 2: Labeled attachment scores (LASs) for MaltParser limited to POS tags, our baseline vine parser
(Vine) and our extensions of Vine. Best scores bold-faced.
</figureCaption>
<page confidence="0.995257">
208
</page>
<bodyText confidence="0.999992045454546">
tags, features and dependency relations; not just
the POS tags as in our case. In particular, our re-
sult is 2.28 better than Dreyer et al. (2006) who
also use soft and hard constraints on dependency
lengths. They extend the parsing algorithm in Eis-
ner and Smith (2005) to labeled k-best parsing and
use a reranker to find the best parse according to
predefined global features. ULA excl. punctuation
for Turkish is 67.06 which is better than six of the
shared task participants, incl. Dreyer et al. (2006)
(60.45).
The improvements come at an extremely low
cost. The POS tagger simply stores its decisions
in a very small table, typically 5–10 cells per sen-
tence, that is queried in no time in parsing. Pars-
ing a standard small test suite takes less than two
seconds, and the cost of the additional look-up is
too small to be measured. The training time of the
maximum entropy-based tagger is typically a mat-
ter of seconds or half a minute. Even running it on
the 1249k Prague Dependency Treebank (Czech)
is only a matter of minutes.
</bodyText>
<sectionHeader confidence="0.963954" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.99998284375">
Vine parsers are motivated by efficiency and ro-
bustness (Dreyer et al., 2006), which has become
more and more important over the last few years,
but none of the systems introduced in the liter-
ature provide competitive results in terms of ac-
curacy. Our experiments show how dependency-
based vine parsers can be significantly improved
by using a maximum entropy-based POS tagger
for initial partial parsing with almost no cost in
terms of training and parsing time.
Our choice of parser restricted us in a few re-
spects. Most importantly, our results are below
state-of-the-art results, and it is not clear if the
strategy scales to more accurate parsers. The strat-
egy of using a POS tagger to do partial parsing and
subsequently forward high precision decisions to
a parser only works on graph-based or constraint-
based dependency parsers where previous deci-
sions can be hardwired into candidate weight ma-
trices by setting weights to 0. It would be difficult
if at all possible to implement in history-based de-
pendency parsers such as MaltParser. Experiments
will be performed with the MSTParser soon.
Our parser also restricted us to considering un-
labeled dependency graphs. A POS tagger, how-
ever, can also be used to identify grammatical
functions (subjects, objects, ... ), for example,
which may be used to hardwire dependency rela-
tions into candidate weight matrices. POS taggers
may also be used to identify other dependency re-
lations or more fine-grained features that can im-
prove the accuracy of dependency parsers.
</bodyText>
<sectionHeader confidence="0.990142" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999698911111112">
Cristina Bosco, Vincenzo Lombardo, Daniela Vassallo,
and Leonardo Lesmo. 2000. Building a treebank for
Italian. In LREC, pages 99–105, Athens, Greece.
Sabine Buchholz and Erwin Marsi. 2006. CONLL-X
shared task on multilingual dependency parsing. In
CONLL-X, pages 149–164, New York City, NY.
Eugene Charniak, Kevin Knight, and Kenji Yamada.
2003. Syntax-based language models for statistical
machine translation. In MT Summit IX, New Or-
leans, Louisiana.
Markus Dreyer, David A. Smith, and Noah A. Smith.
2006. Vine parsing and minimum risk reranking for
speed and precision. In CONLL-X, pages 201–205,
New York City, NY.
J. Edmonds. 1967. Optimum branchings. Journal
of Research of the National Bureau of Standards,
71:233–240.
Jason Eisner and Noah A. Smith. 2005. Parsing with
soft and hard constraints on dependency length. In
IWPT’05, pages 30–41, Vancouver, Canada.
Michel Galley and Cristopher Manning. 2009.
Quadratic time dependency parsing for machine
translation. In ACL’09, Singapore, Singapore. To
appear.
Yoav Goldberg and Michael Elhadad. 2008.
splitSVM: fast, space-efficient, non-heuristic, poly-
nomial kernel computation for NLP applications. In
ACL’08, Short Papers, pages 237–240, Columbus,
Ohio.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In HLT-EMNLP
2005, pages 523–530, Vancouver, British Columbia.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CONLL 2007 shared task on
dependency parsing. In EMNLP-CONLL’07, pages
915–932, Prague, Czech Republic.
Adwait Ratnaparkhi. 1998. Maximum entropy mod-
elsfor natural language ambiguity resolution. Ph.D.
thesis, University of Pennsylvania.
Le Zhang. 2004. Maximum entropy mod-
eling toolkit for Python and C++. Uni-
versity of Edinburgh. Available at home-
pages.inf.ed.ac.uk/lzhang10/maxent toolkit.html.
</reference>
<page confidence="0.998951">
209
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.788344">
<title confidence="0.999939">Using a maximum entropy-based tagger to improve a very fast vine parser</title>
<author confidence="0.999863">Anders Søgaard Jonas Kuhn</author>
<affiliation confidence="0.9992755">Center for Language Technology Dpt. of Linguistics University of Copenhagen University of Potsdam</affiliation>
<email confidence="0.877189">soegaard@hum.ku.dkkuhn@ling.uni-potsdam.de</email>
<abstract confidence="0.987241875">In this short paper, an off-the-shelf maximum entropy-based POS-tagger is used as a partial parser to improve the accuracy of an extremely fast linear time dependency parser that provides state-of-the-art results in multilingual unlabeled POS sequence parsing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cristina Bosco</author>
<author>Vincenzo Lombardo</author>
<author>Daniela Vassallo</author>
<author>Leonardo Lesmo</author>
</authors>
<title>Building a treebank for Italian. In</title>
<date>2000</date>
<booktitle>LREC,</booktitle>
<pages>99--105</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="6134" citStr="Bosco et al., 2000" startWordPosition="975" endWordPosition="978"> a default version of the MaltParser that is restricted to POS tags only, on 5/6 languages (p ≤ 0.05), and it significantly outperforms the baseline vine parser on all languages. 2 Data Our languages are chosen from different language families. Arabic is a Semitic language, Czech is Slavic, Dutch is Germanic, Italian is Romance, Japanese is Japonic-Ryukyuan, and Turkish is Uralic. All treebanks, except Italian, were also used in the CONLL-X Shared Task (Buchholz and Marsi, 2006). The Italian treebank is the law section of the TUT Treebank used in the Evalita 2007 Dependency Parsing Challenge (Bosco et al., 2000). 3 Experiments The Python/C++ implementation of the maximum entropy-based part-of-speech (POS) tagger first described in Ratnaparkhi (1998) that comes with the maximum entropy library in Zhang (2004) was used to identify arcs to the root node and to tokens immediately left or right of the dependent. This was done by first extracting a tagged text from each treebank with dependents of the root node assigned a special tag ROOT. Similarly, tagged texts were extracted in which dependents of their immediate left, resp. right neighbors, were assigned a special tag. Our tagger was trained on the tex</context>
</contexts>
<marker>Bosco, Lombardo, Vassallo, Lesmo, 2000</marker>
<rawString>Cristina Bosco, Vincenzo Lombardo, Daniela Vassallo, and Leonardo Lesmo. 2000. Building a treebank for Italian. In LREC, pages 99–105, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CONLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In CONLL-X,</booktitle>
<pages>149--164</pages>
<location>New York City, NY.</location>
<contexts>
<context position="5998" citStr="Buchholz and Marsi, 2006" startWordPosition="952" endWordPosition="955">endency graphs and is still under development. While accuracy is below state-of-the-art results, our improved parser significantly outperforms a default version of the MaltParser that is restricted to POS tags only, on 5/6 languages (p ≤ 0.05), and it significantly outperforms the baseline vine parser on all languages. 2 Data Our languages are chosen from different language families. Arabic is a Semitic language, Czech is Slavic, Dutch is Germanic, Italian is Romance, Japanese is Japonic-Ryukyuan, and Turkish is Uralic. All treebanks, except Italian, were also used in the CONLL-X Shared Task (Buchholz and Marsi, 2006). The Italian treebank is the law section of the TUT Treebank used in the Evalita 2007 Dependency Parsing Challenge (Bosco et al., 2000). 3 Experiments The Python/C++ implementation of the maximum entropy-based part-of-speech (POS) tagger first described in Ratnaparkhi (1998) that comes with the maximum entropy library in Zhang (2004) was used to identify arcs to the root node and to tokens immediately left or right of the dependent. This was done by first extracting a tagged text from each treebank with dependents of the root node assigned a special tag ROOT. Similarly, tagged texts were extr</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CONLL-X shared task on multilingual dependency parsing. In CONLL-X, pages 149–164, New York City, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Kevin Knight</author>
<author>Kenji Yamada</author>
</authors>
<title>Syntax-based language models for statistical machine translation.</title>
<date>2003</date>
<booktitle>In MT Summit IX,</booktitle>
<location>New Orleans, Louisiana.</location>
<contexts>
<context position="2062" citStr="Charniak et al., 2003" startWordPosition="314" endWordPosition="317">e, say 2–300 sentences; the stand-alone version of MaltParser may take 5–8 minutes. Such parsing times are problematic in, say, a machine translation system where for each sentence pair multiple 1Recent work has optimized MaltParser considerably for speed. Goldberg and Elhadad (2008) speed up the MaltParser by a factor of 30 by simplifying the decision function for the classifiers. Parsing is still considerably slower than with our vine parser, i.e. a test suite is parsed in about 15–20 seconds, whereas our vine parser parses a test suite in less than two seconds. target sentences are parsed (Charniak et al., 2003; Galley and Manning, 2009). Since training takes hours or days, researchers are also more reluctant to experiment with new features, and it is very likely that the features typically used in parsing are suboptimal in, say, machine translation. Conceptually simpler dependency parsers are also easier to understand, which makes debugging, cross-domain adaption or cross-language adaptation a lot easier. Finally, state-of-the-art dependency parsers may in fact be outperformed by simpler systems on non-standard test languages with, say, richer morphology or more flexible word order. Vine parsing is</context>
</contexts>
<marker>Charniak, Knight, Yamada, 2003</marker>
<rawString>Eugene Charniak, Kevin Knight, and Kenji Yamada. 2003. Syntax-based language models for statistical machine translation. In MT Summit IX, New Orleans, Louisiana.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dreyer</author>
<author>David A Smith</author>
<author>Noah A Smith</author>
</authors>
<title>Vine parsing and minimum risk reranking for speed and precision.</title>
<date>2006</date>
<booktitle>In CONLL-X,</booktitle>
<pages>201--205</pages>
<location>New York City, NY.</location>
<contexts>
<context position="2851" citStr="Dreyer et al., 2006" startWordPosition="434" endWordPosition="437">ures typically used in parsing are suboptimal in, say, machine translation. Conceptually simpler dependency parsers are also easier to understand, which makes debugging, cross-domain adaption or cross-language adaptation a lot easier. Finally, state-of-the-art dependency parsers may in fact be outperformed by simpler systems on non-standard test languages with, say, richer morphology or more flexible word order. Vine parsing is a parsing strategy that guarantees fast parsing and smaller models, but the accuracy of dependency-based vine parsers has been non-competitive (Eisner and Smith, 2005; Dreyer et al., 2006). This paper shows how the accuracy of dependency-based vine parsers can be improved by 1–5% across six very different languages with a very small cost in training time and practically no cost in parsing time. The main idea in our experiments is to use a maximum entropy-based part-of-speech (POS) tagger to identify roots and tokens whose heads are immediately left or right of them. These are tasks that a tagger can solve. You simply read off a tagged text from the training, resp. test, section of a treebank and replace all tags of roots, i.e. tokens whose syntactic head is an artificial root n</context>
<context position="10171" citStr="Dreyer et al. (2006)" startWordPosition="1643" endWordPosition="1646">8 89.13 68.94 Vine 67.99 66.70 65.98 75.50 83.15 68.53 Vine+ROOT 68.68 66.65 66.21 78.06 83.82 68.45 Vine+ROOT+LEFT 69.68 68.14 68.05 77.14 84.64 68.37 Vine+RIGHT 68.50 67.38 68.18 78.55 84.17 69.87 Vine+ROOT+RIGHT 69.20 67.32 68.40 78.29 84.78 69.79 Vine+ROOT+LEFT+RIGHT 70.28 68.70 70.06 77.26 85.45 69.74 Figure 2: Labeled attachment scores (LASs) for MaltParser limited to POS tags, our baseline vine parser (Vine) and our extensions of Vine. Best scores bold-faced. 208 tags, features and dependency relations; not just the POS tags as in our case. In particular, our result is 2.28 better than Dreyer et al. (2006) who also use soft and hard constraints on dependency lengths. They extend the parsing algorithm in Eisner and Smith (2005) to labeled k-best parsing and use a reranker to find the best parse according to predefined global features. ULA excl. punctuation for Turkish is 67.06 which is better than six of the shared task participants, incl. Dreyer et al. (2006) (60.45). The improvements come at an extremely low cost. The POS tagger simply stores its decisions in a very small table, typically 5–10 cells per sentence, that is queried in no time in parsing. Parsing a standard small test suite takes </context>
</contexts>
<marker>Dreyer, Smith, Smith, 2006</marker>
<rawString>Markus Dreyer, David A. Smith, and Noah A. Smith. 2006. Vine parsing and minimum risk reranking for speed and precision. In CONLL-X, pages 201–205, New York City, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Edmonds</author>
</authors>
<title>Optimum branchings.</title>
<date>1967</date>
<journal>Journal of Research of the National Bureau of Standards,</journal>
<pages>71--233</pages>
<contexts>
<context position="4418" citStr="Edmonds, 1967" startWordPosition="702" endWordPosition="703">he tagger has better precision for roots than the parser. If it has better recall than the parser, the 206 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 206–209, Paris, October 2009. c�2009 Association for Computational Linguistics parser may be forced to select roots only from the set of potential roots assigned by the tagger. In our experiments, only the first strategy was used (since the tagger’s precision was typically better than its recall). The dependency parser used in our experiments is very simple. It is based on the Chu-LiuEdmonds algorithm (Edmonds, 1967), which is also used in the MSTParser (McDonald et al., 2005), but it is informed only by a simple MLE training procedure and omits cycle contraction in parsing. This means that it produces cyclic graphs. In the context of poor training, insisting on acyclic output graphs often compromises accuracy by &gt; 10%. On top of this parser, which is super fast but often does not even outperform a simple structural baseline, hard and soft constraints on dependency length are learned discriminatively. The speed of the parser allows us to repeatedly parse a tuning section to optimize these constraints. In </context>
</contexts>
<marker>Edmonds, 1967</marker>
<rawString>J. Edmonds. 1967. Optimum branchings. Journal of Research of the National Bureau of Standards, 71:233–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
<author>Noah A Smith</author>
</authors>
<title>Parsing with soft and hard constraints on dependency length.</title>
<date>2005</date>
<booktitle>In IWPT’05,</booktitle>
<pages>30--41</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2829" citStr="Eisner and Smith, 2005" startWordPosition="430" endWordPosition="433">ery likely that the features typically used in parsing are suboptimal in, say, machine translation. Conceptually simpler dependency parsers are also easier to understand, which makes debugging, cross-domain adaption or cross-language adaptation a lot easier. Finally, state-of-the-art dependency parsers may in fact be outperformed by simpler systems on non-standard test languages with, say, richer morphology or more flexible word order. Vine parsing is a parsing strategy that guarantees fast parsing and smaller models, but the accuracy of dependency-based vine parsers has been non-competitive (Eisner and Smith, 2005; Dreyer et al., 2006). This paper shows how the accuracy of dependency-based vine parsers can be improved by 1–5% across six very different languages with a very small cost in training time and practically no cost in parsing time. The main idea in our experiments is to use a maximum entropy-based part-of-speech (POS) tagger to identify roots and tokens whose heads are immediately left or right of them. These are tasks that a tagger can solve. You simply read off a tagged text from the training, resp. test, section of a treebank and replace all tags of roots, i.e. tokens whose syntactic head i</context>
<context position="10294" citStr="Eisner and Smith (2005)" startWordPosition="1663" endWordPosition="1667">8 68.14 68.05 77.14 84.64 68.37 Vine+RIGHT 68.50 67.38 68.18 78.55 84.17 69.87 Vine+ROOT+RIGHT 69.20 67.32 68.40 78.29 84.78 69.79 Vine+ROOT+LEFT+RIGHT 70.28 68.70 70.06 77.26 85.45 69.74 Figure 2: Labeled attachment scores (LASs) for MaltParser limited to POS tags, our baseline vine parser (Vine) and our extensions of Vine. Best scores bold-faced. 208 tags, features and dependency relations; not just the POS tags as in our case. In particular, our result is 2.28 better than Dreyer et al. (2006) who also use soft and hard constraints on dependency lengths. They extend the parsing algorithm in Eisner and Smith (2005) to labeled k-best parsing and use a reranker to find the best parse according to predefined global features. ULA excl. punctuation for Turkish is 67.06 which is better than six of the shared task participants, incl. Dreyer et al. (2006) (60.45). The improvements come at an extremely low cost. The POS tagger simply stores its decisions in a very small table, typically 5–10 cells per sentence, that is queried in no time in parsing. Parsing a standard small test suite takes less than two seconds, and the cost of the additional look-up is too small to be measured. The training time of the maximum</context>
</contexts>
<marker>Eisner, Smith, 2005</marker>
<rawString>Jason Eisner and Noah A. Smith. 2005. Parsing with soft and hard constraints on dependency length. In IWPT’05, pages 30–41, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Cristopher Manning</author>
</authors>
<title>Quadratic time dependency parsing for machine translation.</title>
<date>2009</date>
<booktitle>In ACL’09, Singapore,</booktitle>
<note>To appear.</note>
<contexts>
<context position="2089" citStr="Galley and Manning, 2009" startWordPosition="318" endWordPosition="321"> the stand-alone version of MaltParser may take 5–8 minutes. Such parsing times are problematic in, say, a machine translation system where for each sentence pair multiple 1Recent work has optimized MaltParser considerably for speed. Goldberg and Elhadad (2008) speed up the MaltParser by a factor of 30 by simplifying the decision function for the classifiers. Parsing is still considerably slower than with our vine parser, i.e. a test suite is parsed in about 15–20 seconds, whereas our vine parser parses a test suite in less than two seconds. target sentences are parsed (Charniak et al., 2003; Galley and Manning, 2009). Since training takes hours or days, researchers are also more reluctant to experiment with new features, and it is very likely that the features typically used in parsing are suboptimal in, say, machine translation. Conceptually simpler dependency parsers are also easier to understand, which makes debugging, cross-domain adaption or cross-language adaptation a lot easier. Finally, state-of-the-art dependency parsers may in fact be outperformed by simpler systems on non-standard test languages with, say, richer morphology or more flexible word order. Vine parsing is a parsing strategy that gu</context>
</contexts>
<marker>Galley, Manning, 2009</marker>
<rawString>Michel Galley and Cristopher Manning. 2009. Quadratic time dependency parsing for machine translation. In ACL’09, Singapore, Singapore. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>splitSVM: fast, space-efficient, non-heuristic, polynomial kernel computation for NLP applications.</title>
<date>2008</date>
<booktitle>In ACL’08, Short Papers,</booktitle>
<pages>237--240</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="1725" citStr="Goldberg and Elhadad (2008)" startWordPosition="256" endWordPosition="259">ow in terms of training (hours, sometimes days), and relatively big models are queried in parsing. MSTParser and MaltParser can be optimized for speed in various ways,1 but the many applications of dependency parsers today may turn model size into a serious problem. MSTParser typically takes about a minute to parse a small standard test suite, say 2–300 sentences; the stand-alone version of MaltParser may take 5–8 minutes. Such parsing times are problematic in, say, a machine translation system where for each sentence pair multiple 1Recent work has optimized MaltParser considerably for speed. Goldberg and Elhadad (2008) speed up the MaltParser by a factor of 30 by simplifying the decision function for the classifiers. Parsing is still considerably slower than with our vine parser, i.e. a test suite is parsed in about 15–20 seconds, whereas our vine parser parses a test suite in less than two seconds. target sentences are parsed (Charniak et al., 2003; Galley and Manning, 2009). Since training takes hours or days, researchers are also more reluctant to experiment with new features, and it is very likely that the features typically used in parsing are suboptimal in, say, machine translation. Conceptually simpl</context>
</contexts>
<marker>Goldberg, Elhadad, 2008</marker>
<rawString>Yoav Goldberg and Michael Elhadad. 2008. splitSVM: fast, space-efficient, non-heuristic, polynomial kernel computation for NLP applications. In ACL’08, Short Papers, pages 237–240, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP 2005,</booktitle>
<pages>523--530</pages>
<location>Vancouver, British Columbia.</location>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In HLT-EMNLP 2005, pages 523–530, Vancouver, British Columbia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<booktitle>The CONLL</booktitle>
<pages>915--932</pages>
<location>Prague, Czech Republic.</location>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CONLL 2007 shared task on dependency parsing. In EMNLP-CONLL’07, pages 915–932, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>Maximum entropy modelsfor natural language ambiguity resolution.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="6274" citStr="Ratnaparkhi (1998)" startWordPosition="994" endWordPosition="995">aseline vine parser on all languages. 2 Data Our languages are chosen from different language families. Arabic is a Semitic language, Czech is Slavic, Dutch is Germanic, Italian is Romance, Japanese is Japonic-Ryukyuan, and Turkish is Uralic. All treebanks, except Italian, were also used in the CONLL-X Shared Task (Buchholz and Marsi, 2006). The Italian treebank is the law section of the TUT Treebank used in the Evalita 2007 Dependency Parsing Challenge (Bosco et al., 2000). 3 Experiments The Python/C++ implementation of the maximum entropy-based part-of-speech (POS) tagger first described in Ratnaparkhi (1998) that comes with the maximum entropy library in Zhang (2004) was used to identify arcs to the root node and to tokens immediately left or right of the dependent. This was done by first extracting a tagged text from each treebank with dependents of the root node assigned a special tag ROOT. Similarly, tagged texts were extracted in which dependents of their immediate left, resp. right neighbors, were assigned a special tag. Our tagger was trained on the texts extracted from the training sections of the treebanks and evaluated on the texts extracted from the test sections. The number of gold sta</context>
</contexts>
<marker>Ratnaparkhi, 1998</marker>
<rawString>Adwait Ratnaparkhi. 1998. Maximum entropy modelsfor natural language ambiguity resolution. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Le Zhang</author>
</authors>
<title>Maximum entropy modeling toolkit for Python and C++. University of Edinburgh. Available at homepages.inf.ed.ac.uk/lzhang10/maxent toolkit.html.</title>
<date>2004</date>
<marker>Le Zhang, 2004</marker>
<rawString>Le Zhang. 2004. Maximum entropy modeling toolkit for Python and C++. University of Edinburgh. Available at homepages.inf.ed.ac.uk/lzhang10/maxent toolkit.html.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>