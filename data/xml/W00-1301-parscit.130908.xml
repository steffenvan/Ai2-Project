<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.993844">
Pattern-Based Disambiguation for Natural Language Processing
</title>
<author confidence="0.919713">
Eric Brill
</author>
<affiliation confidence="0.8186">
Microsoft Research
</affiliation>
<address confidence="0.8927085">
One Microsoft Way
Redmond, Wa. 98052
</address>
<email confidence="0.992436">
brill@microsoft.com
</email>
<sectionHeader confidence="0.976156" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999709666666667">
A wide range of natural language problems
can be viewed as disambiguating between a
small set of alternatives based upon the
string context surrounding the ambiguity
site. In this paper we demonstrate that
classification accuracy can be improved by
invoking a more descriptive feature set than
what is typically used. We present a
technique that disambiguates by learning
regular expressions describing the string
contexts in which the ambiguity sites
appear.
</bodyText>
<sectionHeader confidence="0.812798" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.99996065625">
Many natural language tasks are essentially n-
way classification problems, where classification
decisions are made from a small set of choices,
based upon the linguistic context in which the
ambiguity site occurs. Examples of such tasks
include: confusable word set disambiguation;
word sense disambiguation; determining such
lexical features as pronoun case and determiner
number for machine translation; part of speech
tagging; named entity labeling; spelling
correction; and some formulations of skeletal
parsing. Very similar feature sets have been
used across machine learning algorithms and
across classification problems. For example, in
confusable word set disambiguation, systems
typically use as features the occurrence of a
particular word within a window of +/- n words
of the target, and collocations based on the
words and part of speech tags of up to two
words to the left and two words to the right of
the target.
Below we present a machine learning
algorithm that learns from a much richer feature
set than that typically used for classification in
natural language. Our algorithm learns rule
sequences for n-way classification, where the
condition of a rule can be a restricted regular
expression on the string context in which the
ambiguity site appears. We demonstrate that
using this more powerful feature space leads to
an improvement in disambiguation performance
on confusable words.
</bodyText>
<sectionHeader confidence="0.912678" genericHeader="method">
1 Previous Work: Richer Features
</sectionHeader>
<bodyText confidence="0.998822233333333">
Most previous work applying machine learning
to linguistic disambiguation has used as features
very local collocational information as well as
the presence of a word within a fixed window of
an ambiguity site. Indeed, one of the great
insights in both speech recognition and natural
language processing is the realization that fixed
local cues provide a great deal of useful
information.
While the n-gram reins supreme in
language modeling, there has been some
interesting work done building language models
based on linguistically richer features. Bahl,
Brown et al. (1989) describe a language model
that builds a decision tree that is allowed to ask
questions about the history up to twenty words
back. Saul and Pereira (1997) describe a
language model that can in essence skip over
uninformative words in the history. Della Pietra
et al. (1994) discuss an approach to language
modeling based on link grammars, where the
model can look beyond the two previous words
to condition on linguistically relevant words in
the history. The language model described by
Chelba and Jelinek (1998) similarly conditions
on linguistically relevant words by assigning
partial phrase structure to the history and
percolating headwords.
Samuellson, Tapanainen et al. (1996)
describe a method for learning a particular
</bodyText>
<page confidence="0.977854">
1
</page>
<bodyText confidence="0.514571090909091">
useful type of pattern, which they call a barrier.
Given two symbols X and Y, and a set of
symbols S, they learn conditions of the form:
take an action if there is an X preceded by a Y,
with no intervening symbols from S. In their
paper they demonstrate how such patterns can be
useful for part of speech tagging. Even-Zohar
and Roth (2000) show that by including
linguistic features based on relations such as
subject and object, they can better disambiguate
between verb pairs.
</bodyText>
<sectionHeader confidence="0.931024" genericHeader="method">
2 Definitions
</sectionHeader>
<bodyText confidence="0.972776428571429">
Below we provide the standard definition for
regular expressions, and then define a less
expressive language formalism, which we will
refer to as reduced regular expressions. The
learning method we describe herein can learn
rules conditioned on any reduced regular
expression.
</bodyText>
<listItem confidence="0.831453214285714">
Regular Expression (RE): 1 Given a finite
alphabet E , the set of regular expressions over
that alphabet is defined as (Hoperoft and Ullman
1979):
(1) Va€ I, a is a regular expression and
denotes the set (a)
(2) if rand s are regular expressions denoting the
languages R and S, respectively, then (r+s), (rs),
and (r*) are regular expressions that denote the
sets R L.) S. RS and R* respectively.
Reduced (RRE): Given a
finite alphabet Z, the set of reduced regular
expressions over that alphabet is defined as:
(1) Va e Z :
</listItem>
<bodyText confidence="0.776912083333333">
a is an RRE and denotes the set {a}
a+ is an RRE and denotes the positive
closure of the set {a}
a* is an RRE and denotes the Kleene
closure of the set (a)
—a is an RRE and denotes the set I - a
—a+ is an RRE and denotes the positive
closure of the set Z - a
—a* is an RRE and denotes the Kleene
closure of the set Z - a
In all of our formulations, we ignore expressions
denoting the empty set 0 and the set {c}.
</bodyText>
<listItem confidence="0.995802625">
(2) . is an RRE denoting the set E
(3) .+ is an RRE denoting the positive closure
of the set Z
(4) .* is an RRE denoting the Kleene closure of
the set
(5) if r and s are RREs denoting the languages R
and S, respectively, then rs is an RRE denoting
the set RS.
</listItem>
<tableCaption confidence="0.495624166666667">
Some examples of strings that are
regular expressions but not reduced regular
expressions include: (ab)*, a(bIc)d, (a (bc)+)*
Next, we need some definitions to allow
us to make reference to particular positions in a
collection of strings.
</tableCaption>
<footnote confidence="0.259188">
Corpus: A corpus is an ordered set of strings.
We will notate the jth string of a corpus C as
C[j]. ICI is the number of strings in the corpus.
ICW1 is the number of symbols in the jth string of
the corpus.
</footnote>
<construct confidence="0.93561075">
Corpus Position: A corpus position for a
corpus C is a tuple (j,k), meaning the kth symbol
in the jth string in the corpus, with the
restrictions: 1 j I and 0 k5-IC[j]I.
</construct>
<bodyText confidence="0.9534655">
A Corpus Position Set is a set of corpus
positions.
Next, we define an RRE-Tree, the data
structure we will use in learning RREs.
</bodyText>
<construct confidence="0.634866875">
RRE-Tree: An RRE-Tree over Z is a tree
(V,E), where V is a set of tuples &lt;v,S&gt;, v being
a unique vertex identifier and S being a Corpus
Position Set, and E is a set of labeled directed
edges &lt;vi,v;,label&gt;, where vi and If; are vertex
identifiers, label E LABEL_SET and
LABELSET = (dot, dot+, dot*) U
fa,a+,a*,—a,—a+,—a* J Va e ).2
</construct>
<sectionHeader confidence="0.668831" genericHeader="method">
3 Rule Sequence Learning
</sectionHeader>
<bodyText confidence="0.7457545">
Our implemented learner is based upon the
transformation-based learning paradigm (Brill
</bodyText>
<footnote confidence="0.799695666666667">
1995). In this section we briefly review
transformation-based learning.
2 We use &amp;quot;dot&amp;quot; for &amp;quot;.&amp;quot;
</footnote>
<page confidence="0.991142">
2
</page>
<bodyText confidence="0.999283">
In string classification, the goal is to
assign the proper label to a string, from a
prespecified set of labels L. A transformation-
based system consists of:
</bodyText>
<listItem confidence="0.997027">
(1) A start-state annotator, which assigns an
initial label to a string.
(2) A sequence of rules of the form: Change the
label of a string from m to n if C(string), where
</listItem>
<bodyText confidence="0.959070666666667">
C is a predicate over strings and m,n E L.
A string is labelled by first applying the
start-state annotator to it, and then applying each
rule, in order.
To learn a transformation sequence, the
system begins with a properly labelled training
set. It then removes the labels and applies the
start-state annotator to each string. Then the
learner iteratively does the following:
</bodyText>
<listItem confidence="0.99922925">
(1) Find the best rule to apply to the training set.
(2) Append that rule to the end of the learned
transformation sequence.
(3) Apply that rule to the training set.
</listItem>
<bodyText confidence="0.650225">
until the stopping criterion is met.
</bodyText>
<sectionHeader confidence="0.755159" genericHeader="method">
4 Learning RRE Rules
</sectionHeader>
<bodyText confidence="0.956849972222222">
Below we will demonstrate how to learn
transformation sequences where the predicate
C(string) is of the form &apos;Does RRE R apply to
the string?&amp;quot; We will show this for the binary
classification case (where ILI = 2).
In each learning iteration, we will
construct an RRE-Tree in a particular way, find
the best node in that RRE-Tree, and then return
the edge labels on the path from root to best
node as the learned RRE. The learner will learn
a sequence of rules of the form:
Change the label of a string from li to 1, f the
string matches reduced regular expression R.
Before proceeding, we need to specify
two things: the start-state annotator and the
goodness measure for determining what rule is
best. The system will use a start-state annotator
that initially labels all strings with the most
frequent label in the training set, and the
goodness measure will simply be the number of
good label changes minus the number of bad
label changes when a rule is applied to the
training set.
Take the following training set:
String # String True Label Init. Guess
1 a b c 0 1
2 a b b 1 1
3 baa 1 1
Since 1 is the most frequent label in the
training set, the start-state annotator would
initially assign all three training set strings the
label 1, meaning string 1 would be incorrectly
labelled and strings 2 and 3 would be correct.
Now we want to learn a rule whose application
will best improve our labelling of the training
set.
</bodyText>
<subsectionHeader confidence="0.981251">
4.1 RRE-Tree Construction
</subsectionHeader>
<bodyText confidence="0.999952333333333">
We will first present an algorithm for
constructing an RRE-Tree for a training corpus,
and then trace through the application of this
algorithm to our example training corpus above.
To simplify the presentation, we will limit
ourselves to learning rules for a weaker language
type, which we call Very Reduced Regular
Expressions (VRREs). The extension to RRE
learning is straightforward.
</bodyText>
<subsectionHeader confidence="0.594214">
Very Reduced Regular Expression (VRRE):
</subsectionHeader>
<bodyText confidence="0.997148">
Given a finite alphabet , the set of very
reduced regular expressions over that alphabet is
defined as:
</bodyText>
<listItem confidence="0.992096625">
(1) Va E : a is a VRRE and denotes the set
(a)
(2) . is a VRRE denoting the set
(3) .* is a VRRE denoting the Kleene closure of
the set
(4) if r and s are VRREs denoting the languages
R and S, respectively, then rs is a VRRE
denoting the set RS.
</listItem>
<bodyText confidence="0.9998742">
Say we have a training corpus C. For
every string C[j]e C, Truth[C[j]] € (0,1) is the
true label of CU] and Guess[C[j]] is the current
guess of the label of CU]. The algorithm for one
iteration of rule learning follows.
</bodyText>
<sectionHeader confidence="0.624066" genericHeader="method">
Main() {
</sectionHeader>
<page confidence="0.984279">
3
</page>
<listItem confidence="0.99974225">
(1) Create root node with corpus position set S =
WM I j = 1 .. ICb. Push this node onto
processing stack (STACK).
(2) While (STACK not empty)(
</listItem>
<equation confidence="0.995981">
STATE = pop(STACK);
Push(dotexpand(STATE),STACK);
Push(dotstarexpand(STATE),STACK);
Va E Z
Push(atomexpand(a,STATE),STACK)
</equation>
<listItem confidence="0.991627333333333">
(3) Find best state S in the RRE-tree. Let R be
the RRE obtained by following the edges from
the root to S, outputting each edge label as the
edge is traversed. Return either the rule &amp;quot;041 if
R&amp;quot; or &amp;quot;140 if R&amp;quot; depending on which is
appropriate for state S.
</listItem>
<figure confidence="0.9357918125">
dotexpand(STATE)1
create new state STATE&apos;
let P be the corpus position set of STATE
P&apos; = {(j,k) I (j,k-1) e P and k-1 ICorpusWI}
If (P&apos; not empty) {
Make P&apos; the corpus position set of
STATE&apos;
Add (STATE,STATE&apos;,DOT) to tree
edges
return STATE&apos;
Else return NULL
dotstarexpand(STATE)
create new state STATE&apos;
let P be the corpus position set of STATE
P&apos; =1(j,k)I(j,m) E m5_ lc, and k
ICorpusW11
If (P&apos; P)1
Make P&apos; the corpus position set of STATE&apos;
Add (STATE,STATE&apos;,D01&apos;*) to tree edges
return STATE&apos;
Else return NULL
atomexpand(a,STATE)
create new state STATE&apos;
let P be the corpus position set of STATE
P&apos; = {(j,k) I (j,k-1) E P, k-1# rorpus[A, and
the k-1&amp;quot; symbol in Corpus[j] is a)
If (P&apos; not empty){
Make P&apos; the corpus position set of
STATE
Add (STATE,STATE&apos;,a) to tree edges
return STATE&apos;
Else return NULL
</figure>
<figureCaption confidence="0.8327358">
Each state S in the RRE-tree represents the RRE
corresponding to the edge labels on the path
from root to S. For a state S with corpus
position set P and corresponding RRE R, the
goodness of the rule: 041 if R, is computed as:3
</figureCaption>
<figure confidence="0.998081">
Goodness_0_to_l (S) =
E Score 0 to 1((j,k))
(j,k)EP -
where
Score_0_to_1((j,k)) = 1 if k =
A Guess[j] = 0
A Truth[j] = 1
-1 if k =
Guess[j] =0
A Truth[j] = 0
0 otherwise
</figure>
<bodyText confidence="0.905326466666667">
Similarly, we can compute the score for the
rule: 140 if R. We then define Goodness(S) =
max(Goodness_0_to_1(S),Goodness_l_to_0(S))
Returning to our example, for the 3
strings in this training corpus, the root node of
the RRE-Tree would have the corpus position
set: 1(1,0),(2,0),(3,0)). The root node
corresponds to the null RRE, and so the position
set consists of the beginning of each string in the
training set. In figure 1 (at the end of the paper)
we show a partial RRE-Tree. If we follow the
edge labelled &amp;quot;dot&amp;quot; from the root node, we see it
leads to a state with position set
1(1,1),(2,1),(3,1)), as a dot advances all
positions by one.
</bodyText>
<footnote confidence="0.64557">
3 This assumes an RRE must match the entire string
in order to accept it.
</footnote>
<page confidence="0.984973">
4
</page>
<bodyText confidence="0.99995684">
The square state in figure 1 represents
the RRE: &amp;quot;dot* c&amp;quot; and the triangular state
represents &amp;quot;a dot c&amp;quot;. Both the square and
triangular states have a corpus position set
consisting of only one corpus position, namely
the end of string 1, and both would have a
goodness score of 1 for the corresponding 140
rule. If we prefer shorter rules, we will learn as
our first rule in the rule list: 140 if dot* c.
After applying this rule to the training corpus, all
strings will be correctly labelled and training
will terminate. If the stopping criterion were not
met, we would apply the learned rule to change
the values of our Guess array, then create a new
RRE-tree, find the best state in that tree, and so
on.
It is easy to extend the above algorithm
to learn RREs instead of VRREs. Note, for
instance, that the corpus position set for a state S
with incoming edge labelled —a can be found by
taking the position set for the sibling of S with
incoming edge labelled dot and deleting those
corpus positions that are found in the position
set for the sibling of S with incoming edge
labelled a.
</bodyText>
<sectionHeader confidence="0.987666" genericHeader="method">
5 Optimizations
</sectionHeader>
<bodyText confidence="0.949323">
The algorithm above is exponential. There are
some optimizations we can perform that make it
feasible to apply the learning algorithm.
Optimization 1: Pruning states we know
cannot be on the path from root to the best state.
Define GoodPotential_0_to_1(S) as the number
of sentences s in the training corpus for which
Guess [s]=0, Truth [s]=1 and
3k : (s, k) E corpus_position_set(S) . We can
similarly define GoodPotential_l_to_0(S), and
then define
GoodPotential(S)=
max(GoodPotential_0_to_1(S),
GoodPotential_1_to_0(S))
As we construct the RRE-tree, we keep
track of the largest Goodness(S) we have
encountered. If that value is X, then for a state
S&apos;, if GoodPotential(S&apos;) 5_ X, it is impossible for
any path through S&apos; to reach a state with a better
goodness score than the best found thus far. We
can check this condition when pushing states
onto the stack, and when popping off the stack
to be processed, and if the pruning condition is
met, the state is discarded.
Optimization 2: Merging states with identical
corpus position sets. If we are going to push a
state onto the stack when a state already exists
with an identical corpus position set, we do not
need to retain both states. We may use
heuristics to decide which of the states with
identical corpus position sets we should keep
(such as choosing the one with the shortest path
to the root).
</bodyText>
<sectionHeader confidence="0.995156" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.9998461">
To test whether learning RREs can improve
disambiguation accuracy, we explored the task
of confusion set disambiguation (Golding and
Roth 1999). We trained and applied two
different rule sequence learners, one which used
the standard feature set for this problem (e.g. the
identical feature set to that used in (Golding and
Roth 1999) and (Mangu and Brill 1997) and
described in the introduction, and one which
learned RREs.4 Because we wanted to
determine what could be gained by using RREs,
we ran an ablation study where we kept
everything else constant across the two runs, and
did not use performance enhancing techniques
such as parameter tuning on held out data or
classifier combination.
Both learners were given a window of
+/- 5 words surrounding the ambiguity site.
Context was not allowed to cross sentence
boundaries. The training and test set were
derived by finding all instances of the
confusable words in the Brown Corpus, using
the Penn Treebank parts of speech and
tokenization (Marcus, Santorini et al. 1993), and
then dividing this set into 80% for training and
20% for testing.
For the RRE-based system, we mapped
the +/- 5 word window of context into a string as
follows (where wi is a word and ti is a part of
speech tag):
</bodyText>
<footnote confidence="0.9042855">
4 The set of RREs is a superset of what can be
learned using the standard feature set.
</footnote>
<page confidence="0.993985">
5
</page>
<bodyText confidence="0.975507666666667">
the accuracy attained on the test set by always
picking the word that appears more frequently in
the training set.
</bodyText>
<equation confidence="0.9600485">
W1-5 t1-5 Wi-4 ti4 W1-3 ti-3 W1-1t.1 MIDDLE
wi+i 4+1 Wi+2 ti+2 Wi+3 t1+3 Wi+4 ti+4 W1+5 ti+5
</equation>
<bodyText confidence="0.998923916666667">
where MIDDLE is the ambiguity site.
Both for execution time and space
considerations for the learner and for fear of
overtraining, we put a bound on the length of the
RRE that could be learned.5 We define an
atomic RRE as any RRE derived without any
concatenation operations. Then the length of an
RRE is defined as the number of atomic RREs
which that RRE is made up of. The atom
&amp;quot;MIDDLE&amp;quot; is not counted in length.
Below we give two examples of rules
that were learned for one confusion set:6
</bodyText>
<listItem confidence="0.6172355">
(1) past 4 passed if .* -DT MIDDLE DOT IN
(2) past 4 passed if (-to)* NN MIDDLE
</listItem>
<bodyText confidence="0.996952">
The first rule says to change the
disambiguation guess to « passed » if the word
before is not a determiner and the word after is a
preposition. This matches contexts such as: «
... they passed by ...&gt;&gt; while not matching
contexts such as: « ... made in the past by ... »
The second rule captures contexts such as: ...
the hike passed the campground ... » while not
matching contexts such as: « ... want to take a
hike past the campground... &gt;&gt;
In Table 1, we show test set results from
running the rule sequence learner with both the
standard set of features and with RILE-based
features.7 The results are sorted by training
corpus size, with the raise/rise training corpus
being the smallest and the then/than training
corpus being the largest. Baseline accuracy is
5 Note that this does not imply a bound on the length
of a string to which an RRE can apply.
</bodyText>
<sectionHeader confidence="0.857289" genericHeader="conclusions">
6 DT= determiner, IN = preposition, NN = singular
</sectionHeader>
<bodyText confidence="0.994272">
noun.
7 While these results look worse than those achieved
by other systems, as reported in (Golding and Roth,
1999), we used different data splits and tokenization.
Our baseline accuracies are significantly lower than
the baselines for their test sets. If we account for this
by instead measuring percent error reduction
compared to baseline accuracy, then our average
reduction is better than that reported for the BaySpell
system, but worse than that of WinSpell. If we add
voting to our system (WinSpell employs voting), then
we attain results on par with WinSpell.
</bodyText>
<table confidence="0.9995502">
Conf. Pair Baseline Standard RRE
Raise/Rise 53.6 75.0 78.6
Principal/Principle 64.5 80.6 83.9
Accept/Except 60.0 94.5 90.9
Affect/Effect 86.8 94.3 94.3
Lead/Led 53.6 89.3 89.3
Piece/Peace 51.1 83.0 83.0
Weather/Whether 79.7 84.6 89.2
Quiet/Quite 83.1 100 98.5
County/Country 75.6 78.2 83.3
Past/Passed 63.7 88.1 893
Amount/Number 74.1 83.3 87.0
Begin/Being 90.8 96.1 96.7
Among/Between 69.2 76.8 80.8
Then/Than 62.8 93.1 93.4
</table>
<tableCaption confidence="0.97196">
Table 1 Test Set Results: Standard vs RRE-
Based Features
</tableCaption>
<bodyText confidence="0.9920491">
In Table 2 we see that the RRE-based
system outperforms the standard system on 9 of
the confusion sets, the standard system
outperforms the RRE-based system on 2 and the
two systems attain identical results on 3. We see
that the relative performance of the RRE-based
learner is better overall on the larger training
sets than on the smaller sets. This is to be
expected, as more data is needed to support
learning the more expressive RRE-based rules.
</bodyText>
<table confidence="0.998676125">
RRE Standard Identical
Better Better
All 9 2 3
Confusables
7 Smallest 3 1 3
Sets •
7 Largest 6 1 0
Sets
</table>
<tableCaption confidence="0.664573571428571">
Table 2 Performance Analysis Across Different
Sets
Pooling all of the test sets into one big
set, the RRE-based system achieves an overall
accuracy of 89.9%, compared to 88.5% for the
standard learner. Weighting each confusion pair
equally, the RRE-based system achieves an
</tableCaption>
<page confidence="0.994853">
6
</page>
<bodyText confidence="0.964119368421053">
overall accuracy of 88.4%, compared to 86.9%
for the standard learner.
Conclusions
Marcus, M., B. Santorini, et al. (1993).
&amp;quot;Building a large annotated corpus of English:
the Penn Treebank.&amp;quot; Computational Linguistics.
The RRE-based rule sequence learner presented
above is able to learn rules using more
expressive conditions than what is typically used
for disambiguation tasks in natural language
processing. These regular-expression based
conditions lead to higher accuracy than what is
achieved when using the same learning
paradigm with the traditionally used feature set.
We hope that other learning algorithms can
benefit from the ideas presented here and that
the idea of learning RREs can be generalized to
allow other learners to incorporate more
powerful features as well.
</bodyText>
<sectionHeader confidence="0.879353" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999724243243243">
Bahl, L., P. Brown, et al. (1989). &amp;quot;A Tree-Based
Language Model for Natural Language Speech
Recognition.&amp;quot; IEEE Transactions on Acoustics,.
Speech and Signal Processing 37: 1001-1008.
Brill, E. (1995). &amp;quot;Transformation-Based error-
driven learning and natural language processing:
a case study in part of speech tagging.&amp;quot;
Computational Linguistics.
Chelba, C. and F. Jelinek (1998). Exploiting
Syntactic Structure for Language Modeling.
Proceedings of Coling/ACL, Montreal, Canada.
Even-Zohar, Y. and D. Roth (2000). A
Classification Approach to Word Prediction.
Proceedings of NAACL, Seattle, Wa.
Golding, A. and D. Roth (1999). &amp;quot;A Winnow-
Based Approach to Context-Sensitive Spelling
Correction.&amp;quot; Machine Learning.
Hoperoft, J. and J. Ullman (1979). Introduction
to Automata Theory, Languages and
Computation, Addison-Wesley.
Mangu, L. and E. Brill (1997). Automatic Rule
Acquisition for Spelling Correction. Proceedings
of the International Conference on Machine
Learning, Nashville, Tn.
Pietra, S. D., V. D. Pietra, et al. (1994).
Inference and Estimation of a Long-Range
Trigram Model. Proceedings of the Second
International Colloquium on Grammatical
Inference, Alicante, Spain.
Samuellson, C., P. Tapanainen, et al. (1996).
Inducing Constraint Grammars. Grammatical
Inference: Learning Syntax from Sentences. L.
Miclet and C. D. 1. Huguera, Springer. 1147.
Saul, L. and F. Pereira (1997). Aggregate and
mixed-order Markov models for statistical
language processing. Proceedings of the Second
Conference on EMNLP.
</reference>
<page confidence="0.996198">
7
</page>
<figure confidence="0.9995815">
•
(1,0)
(2,0)
(3,0)
(1,2),
•
(1,1),(1,2),
(1,3),(2,1),
(2,2),(2,3)
(1,2),
</figure>
<figureCaption confidence="0.985912">
Figure 1 : A Partial RRE-Tree
</figureCaption>
<page confidence="0.993551">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.856440">
<title confidence="0.999952">Pattern-Based Disambiguation for Natural Language Processing</title>
<author confidence="0.998733">Eric Brill</author>
<affiliation confidence="0.999866">Microsoft Research</affiliation>
<address confidence="0.9944325">One Microsoft Way Redmond, Wa. 98052</address>
<email confidence="0.999733">brill@microsoft.com</email>
<abstract confidence="0.989705923076923">range of natural language problems can be viewed as disambiguating between a small set of alternatives based upon the string context surrounding the ambiguity site. In this paper we demonstrate that classification accuracy can be improved by invoking a more descriptive feature set than what is typically used. We present a technique that disambiguates by learning regular expressions describing the string contexts in which the ambiguity sites appear.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Bahl</author>
<author>P Brown</author>
</authors>
<title>A Tree-Based Language Model for Natural Language Speech Recognition.&amp;quot;</title>
<date>1989</date>
<journal>IEEE Transactions on Acoustics,. Speech and Signal Processing</journal>
<volume>37</volume>
<pages>1001--1008</pages>
<marker>Bahl, Brown, 1989</marker>
<rawString>Bahl, L., P. Brown, et al. (1989). &amp;quot;A Tree-Based Language Model for Natural Language Speech Recognition.&amp;quot; IEEE Transactions on Acoustics,. Speech and Signal Processing 37: 1001-1008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Transformation-Based errordriven learning and natural language processing: a case study in part of speech tagging.&amp;quot;</title>
<date>1995</date>
<journal>Computational Linguistics.</journal>
<contexts>
<context position="6539" citStr="Brill 1995" startWordPosition="1101" endWordPosition="1102">ictions: 1 j I and 0 k5-IC[j]I. A Corpus Position Set is a set of corpus positions. Next, we define an RRE-Tree, the data structure we will use in learning RREs. RRE-Tree: An RRE-Tree over Z is a tree (V,E), where V is a set of tuples &lt;v,S&gt;, v being a unique vertex identifier and S being a Corpus Position Set, and E is a set of labeled directed edges &lt;vi,v;,label&gt;, where vi and If; are vertex identifiers, label E LABEL_SET and LABELSET = (dot, dot+, dot*) U fa,a+,a*,—a,—a+,—a* J Va e ).2 3 Rule Sequence Learning Our implemented learner is based upon the transformation-based learning paradigm (Brill 1995). In this section we briefly review transformation-based learning. 2 We use &amp;quot;dot&amp;quot; for &amp;quot;.&amp;quot; 2 In string classification, the goal is to assign the proper label to a string, from a prespecified set of labels L. A transformationbased system consists of: (1) A start-state annotator, which assigns an initial label to a string. (2) A sequence of rules of the form: Change the label of a string from m to n if C(string), where C is a predicate over strings and m,n E L. A string is labelled by first applying the start-state annotator to it, and then applying each rule, in order. To learn a transformation </context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Brill, E. (1995). &amp;quot;Transformation-Based errordriven learning and natural language processing: a case study in part of speech tagging.&amp;quot; Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chelba</author>
<author>F Jelinek</author>
</authors>
<title>Exploiting Syntactic Structure for Language Modeling.</title>
<date>1998</date>
<booktitle>Proceedings of Coling/ACL,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="3157" citStr="Chelba and Jelinek (1998)" startWordPosition="480" endWordPosition="483">nteresting work done building language models based on linguistically richer features. Bahl, Brown et al. (1989) describe a language model that builds a decision tree that is allowed to ask questions about the history up to twenty words back. Saul and Pereira (1997) describe a language model that can in essence skip over uninformative words in the history. Della Pietra et al. (1994) discuss an approach to language modeling based on link grammars, where the model can look beyond the two previous words to condition on linguistically relevant words in the history. The language model described by Chelba and Jelinek (1998) similarly conditions on linguistically relevant words by assigning partial phrase structure to the history and percolating headwords. Samuellson, Tapanainen et al. (1996) describe a method for learning a particular 1 useful type of pattern, which they call a barrier. Given two symbols X and Y, and a set of symbols S, they learn conditions of the form: take an action if there is an X preceded by a Y, with no intervening symbols from S. In their paper they demonstrate how such patterns can be useful for part of speech tagging. Even-Zohar and Roth (2000) show that by including linguistic feature</context>
</contexts>
<marker>Chelba, Jelinek, 1998</marker>
<rawString>Chelba, C. and F. Jelinek (1998). Exploiting Syntactic Structure for Language Modeling. Proceedings of Coling/ACL, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Even-Zohar</author>
<author>D Roth</author>
</authors>
<title>A Classification Approach to Word Prediction.</title>
<date>2000</date>
<booktitle>Proceedings of NAACL,</booktitle>
<location>Seattle, Wa.</location>
<contexts>
<context position="3715" citStr="Even-Zohar and Roth (2000)" startWordPosition="575" endWordPosition="578">e history. The language model described by Chelba and Jelinek (1998) similarly conditions on linguistically relevant words by assigning partial phrase structure to the history and percolating headwords. Samuellson, Tapanainen et al. (1996) describe a method for learning a particular 1 useful type of pattern, which they call a barrier. Given two symbols X and Y, and a set of symbols S, they learn conditions of the form: take an action if there is an X preceded by a Y, with no intervening symbols from S. In their paper they demonstrate how such patterns can be useful for part of speech tagging. Even-Zohar and Roth (2000) show that by including linguistic features based on relations such as subject and object, they can better disambiguate between verb pairs. 2 Definitions Below we provide the standard definition for regular expressions, and then define a less expressive language formalism, which we will refer to as reduced regular expressions. The learning method we describe herein can learn rules conditioned on any reduced regular expression. Regular Expression (RE): 1 Given a finite alphabet E , the set of regular expressions over that alphabet is defined as (Hoperoft and Ullman 1979): (1) Va€ I, a is a regu</context>
</contexts>
<marker>Even-Zohar, Roth, 2000</marker>
<rawString>Even-Zohar, Y. and D. Roth (2000). A Classification Approach to Word Prediction. Proceedings of NAACL, Seattle, Wa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Golding</author>
<author>D Roth</author>
</authors>
<title>A WinnowBased Approach to Context-Sensitive Spelling Correction.&amp;quot;</title>
<date>1999</date>
<journal>Machine Learning.</journal>
<contexts>
<context position="15091" citStr="Golding and Roth 1999" startWordPosition="2619" endWordPosition="2622"> to be processed, and if the pruning condition is met, the state is discarded. Optimization 2: Merging states with identical corpus position sets. If we are going to push a state onto the stack when a state already exists with an identical corpus position set, we do not need to retain both states. We may use heuristics to decide which of the states with identical corpus position sets we should keep (such as choosing the one with the shortest path to the root). 6 Experiments To test whether learning RREs can improve disambiguation accuracy, we explored the task of confusion set disambiguation (Golding and Roth 1999). We trained and applied two different rule sequence learners, one which used the standard feature set for this problem (e.g. the identical feature set to that used in (Golding and Roth 1999) and (Mangu and Brill 1997) and described in the introduction, and one which learned RREs.4 Because we wanted to determine what could be gained by using RREs, we ran an ablation study where we kept everything else constant across the two runs, and did not use performance enhancing techniques such as parameter tuning on held out data or classifier combination. Both learners were given a window of +/- 5 word</context>
<context position="18093" citStr="Golding and Roth, 1999" startWordPosition="3164" endWordPosition="3167">to take a hike past the campground... &gt;&gt; In Table 1, we show test set results from running the rule sequence learner with both the standard set of features and with RILE-based features.7 The results are sorted by training corpus size, with the raise/rise training corpus being the smallest and the then/than training corpus being the largest. Baseline accuracy is 5 Note that this does not imply a bound on the length of a string to which an RRE can apply. 6 DT= determiner, IN = preposition, NN = singular noun. 7 While these results look worse than those achieved by other systems, as reported in (Golding and Roth, 1999), we used different data splits and tokenization. Our baseline accuracies are significantly lower than the baselines for their test sets. If we account for this by instead measuring percent error reduction compared to baseline accuracy, then our average reduction is better than that reported for the BaySpell system, but worse than that of WinSpell. If we add voting to our system (WinSpell employs voting), then we attain results on par with WinSpell. Conf. Pair Baseline Standard RRE Raise/Rise 53.6 75.0 78.6 Principal/Principle 64.5 80.6 83.9 Accept/Except 60.0 94.5 90.9 Affect/Effect 86.8 94.3</context>
</contexts>
<marker>Golding, Roth, 1999</marker>
<rawString>Golding, A. and D. Roth (1999). &amp;quot;A WinnowBased Approach to Context-Sensitive Spelling Correction.&amp;quot; Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hoperoft</author>
<author>J Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages and Computation,</title>
<date>1979</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="4291" citStr="Hoperoft and Ullman 1979" startWordPosition="664" endWordPosition="667">art of speech tagging. Even-Zohar and Roth (2000) show that by including linguistic features based on relations such as subject and object, they can better disambiguate between verb pairs. 2 Definitions Below we provide the standard definition for regular expressions, and then define a less expressive language formalism, which we will refer to as reduced regular expressions. The learning method we describe herein can learn rules conditioned on any reduced regular expression. Regular Expression (RE): 1 Given a finite alphabet E , the set of regular expressions over that alphabet is defined as (Hoperoft and Ullman 1979): (1) Va€ I, a is a regular expression and denotes the set (a) (2) if rand s are regular expressions denoting the languages R and S, respectively, then (r+s), (rs), and (r*) are regular expressions that denote the sets R L.) S. RS and R* respectively. Reduced (RRE): Given a finite alphabet Z, the set of reduced regular expressions over that alphabet is defined as: (1) Va e Z : a is an RRE and denotes the set {a} a+ is an RRE and denotes the positive closure of the set {a} a* is an RRE and denotes the Kleene closure of the set (a) —a is an RRE and denotes the set I - a —a+ is an RRE and denotes</context>
</contexts>
<marker>Hoperoft, Ullman, 1979</marker>
<rawString>Hoperoft, J. and J. Ullman (1979). Introduction to Automata Theory, Languages and Computation, Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Mangu</author>
<author>E Brill</author>
</authors>
<title>Automatic Rule Acquisition for Spelling Correction.</title>
<date>1997</date>
<booktitle>Proceedings of the International Conference on Machine Learning,</booktitle>
<location>Nashville, Tn.</location>
<contexts>
<context position="15309" citStr="Mangu and Brill 1997" startWordPosition="2656" endWordPosition="2659">ts with an identical corpus position set, we do not need to retain both states. We may use heuristics to decide which of the states with identical corpus position sets we should keep (such as choosing the one with the shortest path to the root). 6 Experiments To test whether learning RREs can improve disambiguation accuracy, we explored the task of confusion set disambiguation (Golding and Roth 1999). We trained and applied two different rule sequence learners, one which used the standard feature set for this problem (e.g. the identical feature set to that used in (Golding and Roth 1999) and (Mangu and Brill 1997) and described in the introduction, and one which learned RREs.4 Because we wanted to determine what could be gained by using RREs, we ran an ablation study where we kept everything else constant across the two runs, and did not use performance enhancing techniques such as parameter tuning on held out data or classifier combination. Both learners were given a window of +/- 5 words surrounding the ambiguity site. Context was not allowed to cross sentence boundaries. The training and test set were derived by finding all instances of the confusable words in the Brown Corpus, using the Penn Treeba</context>
</contexts>
<marker>Mangu, Brill, 1997</marker>
<rawString>Mangu, L. and E. Brill (1997). Automatic Rule Acquisition for Spelling Correction. Proceedings of the International Conference on Machine Learning, Nashville, Tn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S D Pietra</author>
<author>V D Pietra</author>
</authors>
<title>Inference and Estimation of a Long-Range Trigram Model.</title>
<date>1994</date>
<booktitle>Proceedings of the Second International Colloquium on Grammatical Inference,</booktitle>
<location>Alicante,</location>
<marker>Pietra, Pietra, 1994</marker>
<rawString>Pietra, S. D., V. D. Pietra, et al. (1994). Inference and Estimation of a Long-Range Trigram Model. Proceedings of the Second International Colloquium on Grammatical Inference, Alicante, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Samuellson</author>
<author>P Tapanainen</author>
</authors>
<title>Inducing Constraint Grammars. Grammatical Inference: Learning Syntax from</title>
<date>1996</date>
<pages>1147</pages>
<publisher>Huguera, Springer.</publisher>
<marker>Samuellson, Tapanainen, 1996</marker>
<rawString>Samuellson, C., P. Tapanainen, et al. (1996). Inducing Constraint Grammars. Grammatical Inference: Learning Syntax from Sentences. L. Miclet and C. D. 1. Huguera, Springer. 1147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Saul</author>
<author>F Pereira</author>
</authors>
<title>Aggregate and mixed-order Markov models for statistical language processing.</title>
<date>1997</date>
<booktitle>Proceedings of the Second Conference on EMNLP.</booktitle>
<contexts>
<context position="2798" citStr="Saul and Pereira (1997)" startWordPosition="422" endWordPosition="425"> collocational information as well as the presence of a word within a fixed window of an ambiguity site. Indeed, one of the great insights in both speech recognition and natural language processing is the realization that fixed local cues provide a great deal of useful information. While the n-gram reins supreme in language modeling, there has been some interesting work done building language models based on linguistically richer features. Bahl, Brown et al. (1989) describe a language model that builds a decision tree that is allowed to ask questions about the history up to twenty words back. Saul and Pereira (1997) describe a language model that can in essence skip over uninformative words in the history. Della Pietra et al. (1994) discuss an approach to language modeling based on link grammars, where the model can look beyond the two previous words to condition on linguistically relevant words in the history. The language model described by Chelba and Jelinek (1998) similarly conditions on linguistically relevant words by assigning partial phrase structure to the history and percolating headwords. Samuellson, Tapanainen et al. (1996) describe a method for learning a particular 1 useful type of pattern,</context>
</contexts>
<marker>Saul, Pereira, 1997</marker>
<rawString>Saul, L. and F. Pereira (1997). Aggregate and mixed-order Markov models for statistical language processing. Proceedings of the Second Conference on EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>