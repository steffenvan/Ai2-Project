<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.189203">
<title confidence="0.983673">
Teaching Dialogue to Interdisciplinary Teams through Toolkits
</title>
<author confidence="0.934415">
Justine Cassell Matthew Stone
</author>
<affiliation confidence="0.933996">
Technology and Social Behavior Computer Science and Cognitive Science
Northwestern University Rutgers University
</affiliation>
<email confidence="0.999467">
justine@northwestern.edu matthew.stone@rutgers.edu
</email>
<sectionHeader confidence="0.99565" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999997666666667">
We present some lessons we have learned
from using software infrastructure to
support coursework in natural language
dialogue and embodied conversational
agents. We have a new appreciation
for the differences between coursework
and research infrastructure—supporting
teaching may be harder, because students
require a broader spectrum of implemen-
tation, a faster learning curve and the abil-
ity to explore mistaken ideas as well as
promising ones. We outline the collabo-
rative discussion and effort we think is re-
quired to create better teaching infrastruc-
ture in the future.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="acknowledgments">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989312387755102">
Hands-on interaction with dialogue systems is a nec-
essary component of a course on computational lin-
guistics and natural language technology. And yet, it
is clearly impracticable to have students in a quarter-
long or semester-long course build a dialogue sys-
tem from scratch. For this reason, instructors of
these courses have experimented with various op-
tions to allow students to view the code of a work-
ing dialogue system, tweak code, or build their own
application using a dialogue system toolkit. Some
popular options include the NLTK (Loper and Bird,
2002), CSLU (Cole, 1999), Trindi (Larsson and
Traum, 2000) and Regulus (Rayner et al., 2003)
toolkits. However, each of these options has turned
9
out to have disadvantages. Some of the toolkits re-
quire too much knowledge of linguistics for the av-
erage computer science student, and vice-versa, oth-
ers require too much programming for the average
linguist. What is needed is an extensible dialogue
toolkit that allows easy application building for be-
ginning students, and more sophisticated access to,
and tweakability of, the models of discourse for ad-
vanced students.
In addition, as computational linguists become in-
creasingly interested in the role of non-verbal be-
havior in discourse and dialogue, more of us would
like to give our students exposure to models of the
interaction between language and nonverbal behav-
iors such as eye gaze, head nods and hand gestures.
However, the available dialogue system toolkits ei-
ther have no graphical body or if they do have (part
of) a body—as in the case of the CSLU toolkit—the
toolkit does not allow the implementation of alterna-
tive models of body–language interaction.
We feel, therefore, that there is a need for a
toolkit that allows the beginning graduate student—
who may have some computer science or some lin-
guistics background, but not both—to implement a
working embodied dialogue system, as a way to ex-
periment with models of discourse, dialogue, collab-
orative conversation and the interaction between ver-
bal and nonverbal behavior in conversation. We be-
lieve the community as a whole must be engaged in
the design, implementation and fielding of this kind
of educational software. In this paper, we survey
the experience that has led us to these conclusions
and frame the broader discussion we hope the TNLP
workshop will help to further.
</bodyText>
<note confidence="0.7487515">
Proceedings of the Second ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL, pages 9–14,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.998480247311828">
2 Our Courses the course—only fair, since they are at the advan-
Our perspective in this paper draws on more than tage when it comes to implementation. But com-
fifteen course offerings at the graduate level in dis- puter scientists see the value in the exercise: even
course and dialogue over the years. Justine Cassell’s if they do not believe that interfaces should be de-
course Theories and Technologies of Human Com- signed to act like people, they still recognize that
munication is documented on the web here: well-designed interactive systems must be ready to
http://www.soc.northwestern.edu/justine/discourse handle the kinds of behaviors people actually carry
Matthew Stone’s courses Natural Language Pro- out. And hands-on experience convinces them that
cessing and Meaning Machines1 are documented behavior in human conversation is both rich and sur-
here: prising. The computer scientists agree—after turn-
http://www.cs.rutgers.edu/˜mdstone/class/533-spring-03/ ing in impoverished and uninformed “analyses” of
http://www.cs.rutgers.edu/˜mdstone/class/672 their discourse for a brutal critique—that they will
These courses are similar in perspective. All ad- never look at conversation the same way again.
dress an extremely diverse and interdisciplinary au- Our experience suggests that we should be try-
dience of students from computer science, linguis- ing to give students outside computer science the
tics, cognitive science, information science, commu- same kind of eye-opening hands-on experience with
nication, and education. The typical student is a first technology. For example, we have found that lin-
or second-year PhD student with a serious interest in guists are just as challenged and excited by the dis-
doing a dissertation on human-computer communi- cipline of technology as computer scientists are by
cation or in enriching their dissertation research with the discipline of empirical observations. Linguists
results from the theory or practice of discourse and in our classes typically report that successful en-
dialogue. All are project courses, but no program- gagement with technology “exposes a lot of de-
ming is required; projects may involve evaluation of tails that were missing from my theoretical under-
existing implementations or the prospective design standing that I never would have considered with-
of new implementations based on ongoing empir- out working through the code”. Nothing is better at
ical research. Nevertheless, the courses retain the bringing out the assumptions you bring to an anal-
dual goals that students should not only understand ysis of human-human conversation than the thought
discourse and the theory of pragmatics, but should experiment of replacing one of the participants by
also understand how the theory is implemented, ei- something that has to struggle consciously to un-
ther well enough to talk intelligently about the im- derstand it—a space alien, perhaps, or, more real-
plementation or, if they are computer scientists, to istically, an AI system. We are frustrated that no
actually carry it out. succinct assignment, comparable to our transcrip-
As befits our dual goals, our courses all involve tion homework, yet exists that can reliably deliver
a mix of instruction in human-human dialogue and this insight to students outside computer science.
human-computer dialogue. For example, Cassell be- 3 Framing the Problem
gins her course with a homework where students Our courses are not typical NLP classes. Our treat-
collect, transcribe and analyze their own recordings ment of parsing is marginal, and for the most part
of face-to-face conversation. Students are asked to we ignore the mainstays of statistical language pro-
discuss what constitutes a sufficient record of dis- cessing courses: the low-level technology such as
course, and to speculate on what the most challeng- finite-state methods; the specific language process-
ing processing issues would be to allow a computer ing challenges for machine learning methods; and
to replace one of the participants. Computer sci- “applied” subproblems like named entity extraction,
entists definitely have difficulty with this aspect of or phrase chunking. Our focus is almost exclu-
sively on high-level and interactional issues, such
as the structure of discourse and dialogue, informa-
tion structure, intentions, turn-taking, collaboration,
1The catchy title is the inspiration of Deb Roy at MIT.
10
reference and clarification. Context is central, and
under that umbrella we explicitly discuss both the
perceptual environment in which conversation takes
place and the non-verbal actions that contribute to
the management of conversation and participants’
real-world collaborations.
Our unusual focus means that we can not readily
take advantage of software toolkits such as NLTK
(Loper and Bird, 2002) or Regulus (Rayner et al.,
2003). These toolkits are great at helping students
implement and visualize the fundamentals of natu-
ral language processing—lexicon, morphology, syn-
tax. They make it easy to experiment with machine
learning or with specific models for a small scale,
short course assignment in a specific NLP module.
You can think of this as a “horizontal” approach, al-
lowing students to systematically develop a compre-
hensive approach to a single processing task. But
what we need is a “vertical” approach, which allows
students to follow a specific choice about the rep-
resentation of communicative behaviors or commu-
nicative functions all the way through an end-to-end
dialogue system. We have not succeeded in concep-
tualizing how a carefully modularized toolkit would
support this kind of student experience.
Still, we have not met with success with alterna-
tive approaches, either. As we describe in Section
3.1, our own research systems may allow the kinds
of experiments we want students to carry out. But
they demand too much expertise of students for a
one-semester course. In fact, as we describe in Sec-
tion 3.2, even broad research systems that come with
specific support for students to carry out a range of
tasks may not enable the specific directions that re-
ally turn students on to the challenge of discourse
and dialogue. However, our experience with im-
plementing dedicated modules for teaching, as de-
scribed in Section 3.3, is that the lack of synergy
with ongoing research can result in impoverished
tools that fail to engage students. We don’t have the
tools we want—but our experience argues that we
think the tools we really want will be developed only
through a collaborative effort shared across multiple
sites and broadly engaged with a range of research
issues as well as with pedagogical challenges.
</bodyText>
<subsectionHeader confidence="0.998882">
3.1 Difficulties with REA and BEAT
</subsectionHeader>
<bodyText confidence="0.999985565217391">
Cassell has experimented with the use of her re-
search platforms REA (Cassell et al., 1999) and
BEAT (Cassell et al., 2001) for course projects in
discourse and dialogue. REA is an embodied con-
versational agent that interacts with a user in a real
estate agent domain. It includes an end-to-end dia-
logue architecture; it supports speech input, stereo
vision input, conversational process including pres-
ence and turn-taking, content planning, the context-
sensitive generation of communicative action and
the animated realization of multimodal communica-
tive actions. BEAT (the behavior expression anima-
tion toolkit), on the other hand, is a module that fits
into animation systems. It marks up text to describe
appropriate synchronized nonverbal behaviors and
speech to realize on a humanoid talking character.
In teaching dialogue at MIT, Cassell invited stu-
dents to adapt her existing REA and BEAT system
to explore aspects of the theory and practice of dis-
course and dialogue. This led to a range of interest-
ing projects. For example, students were able to ex-
plore hypothetical differences among characters—
from virtual “Italians” with profuse gesture, to vir-
tual children whose marked use of a large gesture
space contrasted with typical adults, to characters
who showed new and interesting behavior such as
the repeated foot-tap of frustrated condescension.
However, we think we can serve students much bet-
ter. Many of these projects were accomplished only
with substantial help from the instructor and TAs,
who were already extremely familiar with the over-
all system. Students did not have time to learn how
to make these changes entirely on their own.
The foot-tapping agent is a good example of this.
To add foot-tapping is a paradigmatic “vertical”
modification. It requires adding suitable context to
the discourse state to represent uncooperative user
behavior; it requires extending the process for gener-
ating communicative actions to detect this new state
and schedule an appropriate behavioral response;
and then it requires extending the animation plat-
form to be able to show this behavior. BEAT makes
the second step easy—as it should be—even for lin-
guistics students. To handle the first and third steps,
you would hope that an interdisciplinary team con-
taining a communication student and a computer sci-
</bodyText>
<page confidence="0.984047">
11
</page>
<bodyText confidence="0.998327694736843">
ence student would be able to bring the expertise to face dialogue (Cassell et al., 2000), the information-
design the new dialogue state and the new animated state approach to domain-independent practical di-
behavior. But that wasn’t exactly true. In order to alogue (Larsson and Traum, 2000), or approaches
add the behavior to REA, students needed not only that emphasize the grounding of conversation in the
background in the relevant technology—like what a specifics of a particular ongoing collaboration (Rich
computer scientist would learn in a general human et al., 2001). The integration of a talking head into
animation class. To add the behavior, students also the CSLU toolkit epitomizes these limitations with
needed to know how this technology was realized the platform. The toolkit allows for the automatic
in our particular research platform. This proved too realization of text with an animated spoken deliv-
much for one semester. ery, but does not expose the model to programmers,
We think this is a general problem with new re- making it impossible for programmers adapt or con-
search systems. For example, we think many of the trol the behavior of the face and head.
same issues would arise in asking students to build a We think this is a general problem with platforms
dialogue system on top of the Trindi toolkit in a one that are primarily designed to streamline a particular
semester course. research methodology. For example, we think many
3.2 Difficulties with the CSLU toolkit of the same issues would arise in asking students to
In Fall 2004, Cassell experimented with using the build a multimodal behavior realization system on
CSLU dialogue toolkit (Cole, 1999) as a resource top of a general-purpose speech synthesis platform
for class projects. This is a broad toolkit to support like Festival (Black and Taylor, 1997).
research and teaching in spoken language technol- 3.3 Difficulties with TAGLET
ogy. A particular strength of the toolkit is its sup- At this point, the right solution might seem to be
port for the design of finite-state dialogue models. to devise resources explicitly for teaching. In fact,
Even students outside computer science appreciated Stone advocated more or less this at the 2002 TNLP
the toolkit’s drag-and-drop interface for scripting di- workshop (2002). There, Stone motivated the poten-
alogue flow. For example, with this interface, you tial role for a simple lexicalized formalism for nat-
can add a repair sequence to a dialogue flow in one ural language syntax, semantics and pragmatics in
easy step. However, the indirection the toolkit places a broad NLP class whose emphasis is to introduce
between students and the actual constructs of dia- topics of current research.
logue theory can by quite challenging. For example, The system, TAGLET, is a context-free tree-
the finite-state architecture of the CSLU toolkit al- rewriting formalism, defined by the usual comple-
lows students to look at floor management and at di- mentation operation and the simplest imaginable
alogue initiative only indirectly: specific transition modification operation. This formalism may in fact
networks encode specific strategies for taking turns be a good way to present computational linguistics
or managing problem solving by scheduling specific to technically-minded cognitive science students—
communicative functions and behaviors. those rare students who come with interest and ex-
The way we see it, the CSLU toolkit is more heav- perience in the science of language as well as a solid
ily geared towards the rapid construction of particu- ability to program. By implementing a strong com-
lar kinds of research prototypes than we would like petence TAGLET parser and generator students si-
in a teaching toolkit. Its dialogue models provide an multaneously get experience with central computer
instructive perspective on actions in discourse, one science ideas—data structures, unification, recur-
that nicely complements the perspective of DAMSL sion and abstraction—and develop an effective start-
(Core and Allen, 1997) in seeing utterances as the ing point for their own subsequent projects.
combined realization of a specific, constrained range However, in retrospect, TAGLET does not serve
of communicative functions. But we would like to to introduce students outside computer science to the
be able to explore a range of other metaphors for distinctive insights that come from a computational
organizing the information in dialogue. We would approach to language use. For one thing, to reach
like students to be able to realize models of face-to- a broad audience, it is a mistake to focus on repre-
12
sentations that programmers can easily build at the resources for teaching.
expense of representations that other students can We have reframed our ongoing activities so that
easily understand. These other students need visu- we can find new synergies between research and
alization; they need to be able to see what the sys- teaching. For example, we are currently working
tem computes and how it computes it. Moreover, to expand the repertoire of animated action in our
these other students can tolerate substantial com- freely-available talking head RUTH (DeCarlo et al.,
plexity in the underlying algorithms if the system 2004). In our next release, we expect to make dif-
can be understood clearly and mechanistically in ab- ferent kinds of resources available than in the initial
stract terms. You wouldn’t ask a computer scientist release. Originally, we distributed only the model
to implement a parser for full tree-adjoining gram- we created. The next version will again provide that
mar but that doesn’t change the fact that it’s still a model, along with a broader and more useful inven-
perfectly natural, and comprehensible, algorithmic tory of facial expressions for it, but we also want
abstraction for characterizing linguistic structure. the new RUTH to be more easily extensible than the
Another set of representations and algorithms last one. To do that, we have ported our model to a
might avoid some of these problems. But a new general-purpose animation environment (Alias Re-
approach could not avoid another problem that we search’s Maya) and created software tools that can
think applies generally to platforms that are de- output edited models into the collection of files that
signed exclusively for teaching: there is no synergy RUTH needs to run. This helps achieve our ob-
with ongoing research efforts. Rich resources are so jective of quickly-learned extensibility. We expect
crucial to any computational treatment of dialogue: that students with a background in human anima-
annotated corpora, wide-coverage grammars, plan- tion will bring experience with Maya to a dialogue
recognizers, context models, and the rest. We can’t course. (Anyway, learning Maya is much more gen-
afford to start from scratch. We have found this con- eral than learning RUTH!) Computer science stu-
cretely in our work. What got linguists involved in dents will thus find it easier to assist a team of com-
the computational exploration of dialogue semantics munication and linguistics students in adding new
at Rutgers was not the special teaching resources expressions to an animated character.
Stone created. It was hooking students up with the Creating such resources to span a general system
systems that were being actively developed in ongo- for face-to-face dialogue would be an enormous un-
ing research (DeVault et al., 2005). These research dertaking. It could happen only with broad input
efforts made it practical to provide students with the from those who teach discourse and dialogue, as we
visualizations, task and context models, and interac- do, through a mix of theory and practice. We hope
tive architecture they needed to explore substantive the TNLP workshop will spark this kind of process.
issues in dialogue semantics. Whatever we do will We close with the questions we’d like to consider
have to closely connect teaching and our ongoing re- further. What kinds of classes on dialogue and dis-
search. course pragmatics are currently being offered? What
4 Looking ahead kinds of audiences do others reach, what goals do
Our experience teaching dialogue to interdisci- they bring, and what do they teach them? What are
plinary teams through toolkits has been humbling. the scientific and technological principles that oth-
We have a new appreciation for the differences ers would use toolkits to teach and illustrate? In
between coursework and research infrastructure— short, what would your dialogue toolkit make possi-
supporting teaching may be harder, because stu- ble? And how can we work together to realize both
dents require a broader spectrum of implementa- our visions?
tion, a faster learning curve and the ability to ex- 5 Acknowledgments
plore mistaken ideas as well as promising ones. Thanks to Doug DeCarlo, NSF HLC 0308121.
But we increasingly think the community can and
should come together to foster more broadly useful
13
</bodyText>
<sectionHeader confidence="0.987507" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994581065573771">
Alan Black and Paul Taylor. 1997. Festi-
val speech synthesis system. Technical Report
HCRC/TR-83, Human Communication Research Cen-
ter. http://www.cstr.ed.ac.uk/projects/festival/.
J. Cassell, T. Bickmore, M. Billinghurst, L. Campbell,
K. Chang, H. Vilhj´almsson, and H. Yan. 1999. Em-
bodiment in conversational characters: Rea. In CHI
99, pages 520–527.
Justine Cassell, Tim Bickmore, Lee Campbell, Hannes
Vilhjalmsson, and Hao Yan. 2000. Human conver-
sation as a system framework. In J. Cassell, J. Sul-
livan, S. Prevost, and E. Churchill, editors, Embod-
ied Conversational Agents, pages 29–63. MIT Press,
Cambridge, MA.
Manny Rayner, Beth Ann Hockey, and John Dowd-
ing. 2003. An open source environment for com-
piling typed unification grammars into speech recog-
nisers. In Proceedings of the 10th Conference of the
European Chapter of the Association for Computa-
tion Linguistics (interactive poster and demo track).
http://sourceforge.net/projects/regulus.
C. Rich, C. L. Sidner, and N. Lesh. 2001. COL-
LAGEN: applying collaborative discourse theory to
human-computer interaction. AI Magazine, 22:15–25.
Matthew Stone. 2002. Lexicalized grammar 101.
In ACL Workshop on Effective Tools and Method-
ologies for Teaching NLP and CL, pages 76–83.
http://www.cs.rutgers.edu/˜mdstone/class/taglet/.
Justine Cassell, Hannes Vilhj´almsson, and Tim Bick-
more. 2001. BEAT: the behavioral expression ani-
mation toolkit. In SIGGRAPH, pages 477–486.
Ron Cole. 1999. Tools for research and ed-
ucation in speech science. In Proceedings of
the International Conference of Phonetic Sciences.
http://cslu.cse.ogi.edu/toolkit/.
Mark G. Core and James F. Allen. 1997. Cod-
ing dialogs with the DAMSL annotation scheme.
In Working Notes of AAAI Fall Symposium on
Communicative Action in Humans and Machines.
http://www.cs.rochester.edu/research/cisd/resources/damsl/.
Douglas DeCarlo, Corey Revilla, Matthew Stone, and
Jennifer Venditti. 2004. Specifying and animating fa-
cial signals for discourse in embodied conversational
agents. Journal of Visualization and Computer Ani-
mation. http://www.cs.rutgers.edu/˜village/ruth/.
David DeVault, Anubha Kothari, Natalia Kariaeva,
Iris Oved, and Matthew Stone. 2005. An
information-state approach to collaborative ref-
erence. In ACL Proceedings Companion Vol-
ume (interactive poster and demonstration track).
http://www.cs.rutgers.edu/˜mdstone/pointers/collabref.html.
Staffan Larsson and David Traum. 2000. In-
formation state and dialogue management in
the TRINDI dialogue move engine toolkit.
Natural Language Engineering, 6:323–340.
http://www.ling.gu.se/projekt/trindi/.
Edward Loper and Steven Bird. 2002. NLTK: the natu-
ral language toolkit. In Proceedings of the ACL Work-
shop on Effective Tools and Methodologies for Teach-
ing Natural Language Processing and Computational
Linguistics. http://nltk.sourceforge.net.
</reference>
<page confidence="0.999167">
14
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.806223">
<title confidence="0.999642">Teaching Dialogue to Interdisciplinary Teams through Toolkits</title>
<author confidence="0.997717">Justine Cassell Matthew Stone</author>
<affiliation confidence="0.9741615">Technology and Social Behavior Computer Science and Cognitive Science Northwestern University Rutgers University</affiliation>
<email confidence="0.9995">justine@northwestern.edumatthew.stone@rutgers.edu</email>
<abstract confidence="0.989810125">We present some lessons we have learned from using software infrastructure to support coursework in natural language dialogue and embodied conversational agents. We have a new appreciation for the differences between coursework and research infrastructure—supporting teaching may be harder, because students require a broader spectrum of implementation, a faster learning curve and the ability to explore mistaken ideas as well as promising ones. We outline the collaborative discussion and effort we think is required to create better teaching infrastructure in the future.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alan Black</author>
<author>Paul Taylor</author>
</authors>
<title>Festival speech synthesis system.</title>
<date>1997</date>
<booktitle>Technical Report HCRC/TR-83, Human Communication Research Center. http://www.cstr.ed.ac.uk/projects/festival/.</booktitle>
<contexts>
<context position="14246" citStr="Black and Taylor, 1997" startWordPosition="2225" endWordPosition="2228">s to build a We think this is a general problem with platforms dialogue system on top of the Trindi toolkit in a one that are primarily designed to streamline a particular semester course. research methodology. For example, we think many 3.2 Difficulties with the CSLU toolkit of the same issues would arise in asking students to In Fall 2004, Cassell experimented with using the build a multimodal behavior realization system on CSLU dialogue toolkit (Cole, 1999) as a resource top of a general-purpose speech synthesis platform for class projects. This is a broad toolkit to support like Festival (Black and Taylor, 1997). research and teaching in spoken language technol- 3.3 Difficulties with TAGLET ogy. A particular strength of the toolkit is its sup- At this point, the right solution might seem to be port for the design of finite-state dialogue models. to devise resources explicitly for teaching. In fact, Even students outside computer science appreciated Stone advocated more or less this at the 2002 TNLP the toolkit’s drag-and-drop interface for scripting di- workshop (2002). There, Stone motivated the potenalogue flow. For example, with this interface, you tial role for a simple lexicalized formalism for </context>
</contexts>
<marker>Black, Taylor, 1997</marker>
<rawString>Alan Black and Paul Taylor. 1997. Festival speech synthesis system. Technical Report HCRC/TR-83, Human Communication Research Center. http://www.cstr.ed.ac.uk/projects/festival/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cassell</author>
<author>T Bickmore</author>
<author>M Billinghurst</author>
<author>L Campbell</author>
<author>K Chang</author>
<author>H Vilhj´almsson</author>
<author>H Yan</author>
</authors>
<date>1999</date>
<booktitle>Embodiment in conversational characters: Rea. In CHI 99,</booktitle>
<pages>520--527</pages>
<marker>Cassell, Bickmore, Billinghurst, Campbell, Chang, Vilhj´almsson, Yan, 1999</marker>
<rawString>J. Cassell, T. Bickmore, M. Billinghurst, L. Campbell, K. Chang, H. Vilhj´almsson, and H. Yan. 1999. Embodiment in conversational characters: Rea. In CHI 99, pages 520–527.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justine Cassell</author>
<author>Tim Bickmore</author>
<author>Lee Campbell</author>
<author>Hannes Vilhjalmsson</author>
<author>Hao Yan</author>
</authors>
<title>Human conversation as a system framework. In</title>
<date>2000</date>
<booktitle>Embodied Conversational Agents,</booktitle>
<pages>29--63</pages>
<editor>J. Cassell, J. Sullivan, S. Prevost, and E. Churchill, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="12490" citStr="Cassell et al., 2000" startWordPosition="1939" endWordPosition="1942">uitable context to the discourse state to represent uncooperative user behavior; it requires extending the process for generating communicative actions to detect this new state and schedule an appropriate behavioral response; and then it requires extending the animation platform to be able to show this behavior. BEAT makes the second step easy—as it should be—even for linguistics students. To handle the first and third steps, you would hope that an interdisciplinary team containing a communication student and a computer sci11 ence student would be able to bring the expertise to face dialogue (Cassell et al., 2000), the informationdesign the new dialogue state and the new animated state approach to domain-independent practical dibehavior. But that wasn’t exactly true. In order to alogue (Larsson and Traum, 2000), or approaches add the behavior to REA, students needed not only that emphasize the grounding of conversation in the background in the relevant technology—like what a specifics of a particular ongoing collaboration (Rich computer scientist would learn in a general human et al., 2001). The integration of a talking head into animation class. To add the behavior, students also the CSLU toolkit epit</context>
</contexts>
<marker>Cassell, Bickmore, Campbell, Vilhjalmsson, Yan, 2000</marker>
<rawString>Justine Cassell, Tim Bickmore, Lee Campbell, Hannes Vilhjalmsson, and Hao Yan. 2000. Human conversation as a system framework. In J. Cassell, J. Sullivan, S. Prevost, and E. Churchill, editors, Embodied Conversational Agents, pages 29–63. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manny Rayner</author>
<author>Beth Ann Hockey</author>
<author>John Dowding</author>
</authors>
<title>An open source environment for compiling typed unification grammars into speech recognisers.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th Conference of the European Chapter of the Association</booktitle>
<note>http://sourceforge.net/projects/regulus.</note>
<contexts>
<context position="1503" citStr="Rayner et al., 2003" startWordPosition="218" endWordPosition="221">alogue systems is a necessary component of a course on computational linguistics and natural language technology. And yet, it is clearly impracticable to have students in a quarterlong or semester-long course build a dialogue system from scratch. For this reason, instructors of these courses have experimented with various options to allow students to view the code of a working dialogue system, tweak code, or build their own application using a dialogue system toolkit. Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al., 2003) toolkits. However, each of these options has turned 9 out to have disadvantages. Some of the toolkits require too much knowledge of linguistics for the average computer science student, and vice-versa, others require too much programming for the average linguist. What is needed is an extensible dialogue toolkit that allows easy application building for beginning students, and more sophisticated access to, and tweakability of, the models of discourse for advanced students. In addition, as computational linguists become increasingly interested in the role of non-verbal behavior in discourse and</context>
<context position="8243" citStr="Rayner et al., 2003" startWordPosition="1253" endWordPosition="1256">ional issues, such as the structure of discourse and dialogue, information structure, intentions, turn-taking, collaboration, 1The catchy title is the inspiration of Deb Roy at MIT. 10 reference and clarification. Context is central, and under that umbrella we explicitly discuss both the perceptual environment in which conversation takes place and the non-verbal actions that contribute to the management of conversation and participants’ real-world collaborations. Our unusual focus means that we can not readily take advantage of software toolkits such as NLTK (Loper and Bird, 2002) or Regulus (Rayner et al., 2003). These toolkits are great at helping students implement and visualize the fundamentals of natural language processing—lexicon, morphology, syntax. They make it easy to experiment with machine learning or with specific models for a small scale, short course assignment in a specific NLP module. You can think of this as a “horizontal” approach, allowing students to systematically develop a comprehensive approach to a single processing task. But what we need is a “vertical” approach, which allows students to follow a specific choice about the representation of communicative behaviors or communica</context>
</contexts>
<marker>Rayner, Hockey, Dowding, 2003</marker>
<rawString>Manny Rayner, Beth Ann Hockey, and John Dowding. 2003. An open source environment for compiling typed unification grammars into speech recognisers. In Proceedings of the 10th Conference of the European Chapter of the Association for Computation Linguistics (interactive poster and demo track). http://sourceforge.net/projects/regulus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rich</author>
<author>C L Sidner</author>
<author>N Lesh</author>
</authors>
<title>COLLAGEN: applying collaborative discourse theory to human-computer interaction.</title>
<date>2001</date>
<journal>AI Magazine,</journal>
<pages>22--15</pages>
<marker>Rich, Sidner, Lesh, 2001</marker>
<rawString>C. Rich, C. L. Sidner, and N. Lesh. 2001. COLLAGEN: applying collaborative discourse theory to human-computer interaction. AI Magazine, 22:15–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Stone</author>
</authors>
<title>Lexicalized grammar 101.</title>
<date>2002</date>
<booktitle>In ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL,</booktitle>
<pages>76--83</pages>
<marker>Stone, 2002</marker>
<rawString>Matthew Stone. 2002. Lexicalized grammar 101. In ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL, pages 76–83. http://www.cs.rutgers.edu/˜mdstone/class/taglet/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justine Cassell</author>
<author>Hannes Vilhj´almsson</author>
<author>Tim Bickmore</author>
</authors>
<title>BEAT: the behavioral expression animation toolkit.</title>
<date>2001</date>
<booktitle>In SIGGRAPH,</booktitle>
<pages>477--486</pages>
<marker>Cassell, Vilhj´almsson, Bickmore, 2001</marker>
<rawString>Justine Cassell, Hannes Vilhj´almsson, and Tim Bickmore. 2001. BEAT: the behavioral expression animation toolkit. In SIGGRAPH, pages 477–486.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Cole</author>
</authors>
<title>Tools for research and education in speech science.</title>
<date>1999</date>
<booktitle>In Proceedings of the International Conference of Phonetic Sciences. http://cslu.cse.ogi.edu/toolkit/.</booktitle>
<contexts>
<context position="1435" citStr="Cole, 1999" startWordPosition="209" endWordPosition="210"> in the future. 1 Introduction Hands-on interaction with dialogue systems is a necessary component of a course on computational linguistics and natural language technology. And yet, it is clearly impracticable to have students in a quarterlong or semester-long course build a dialogue system from scratch. For this reason, instructors of these courses have experimented with various options to allow students to view the code of a working dialogue system, tweak code, or build their own application using a dialogue system toolkit. Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al., 2003) toolkits. However, each of these options has turned 9 out to have disadvantages. Some of the toolkits require too much knowledge of linguistics for the average computer science student, and vice-versa, others require too much programming for the average linguist. What is needed is an extensible dialogue toolkit that allows easy application building for beginning students, and more sophisticated access to, and tweakability of, the models of discourse for advanced students. In addition, as computational linguists become increas</context>
<context position="14087" citStr="Cole, 1999" startWordPosition="2201" endWordPosition="2202">ers adapt or consearch systems. For example, we think many of the trol the behavior of the face and head. same issues would arise in asking students to build a We think this is a general problem with platforms dialogue system on top of the Trindi toolkit in a one that are primarily designed to streamline a particular semester course. research methodology. For example, we think many 3.2 Difficulties with the CSLU toolkit of the same issues would arise in asking students to In Fall 2004, Cassell experimented with using the build a multimodal behavior realization system on CSLU dialogue toolkit (Cole, 1999) as a resource top of a general-purpose speech synthesis platform for class projects. This is a broad toolkit to support like Festival (Black and Taylor, 1997). research and teaching in spoken language technol- 3.3 Difficulties with TAGLET ogy. A particular strength of the toolkit is its sup- At this point, the right solution might seem to be port for the design of finite-state dialogue models. to devise resources explicitly for teaching. In fact, Even students outside computer science appreciated Stone advocated more or less this at the 2002 TNLP the toolkit’s drag-and-drop interface for scri</context>
</contexts>
<marker>Cole, 1999</marker>
<rawString>Ron Cole. 1999. Tools for research and education in speech science. In Proceedings of the International Conference of Phonetic Sciences. http://cslu.cse.ogi.edu/toolkit/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark G Core</author>
<author>James F Allen</author>
</authors>
<title>Coding dialogs with the DAMSL annotation scheme.</title>
<date>1997</date>
<booktitle>In Working Notes of AAAI Fall Symposium on Communicative Action in Humans and Machines. http://www.cs.rochester.edu/research/cisd/resources/damsl/.</booktitle>
<contexts>
<context position="16464" citStr="Core and Allen, 1997" startWordPosition="2563" endWordPosition="2567">e it, the CSLU toolkit is more heav- perience in the science of language as well as a solid ily geared towards the rapid construction of particu- ability to program. By implementing a strong comlar kinds of research prototypes than we would like petence TAGLET parser and generator students siin a teaching toolkit. Its dialogue models provide an multaneously get experience with central computer instructive perspective on actions in discourse, one science ideas—data structures, unification, recurthat nicely complements the perspective of DAMSL sion and abstraction—and develop an effective start(Core and Allen, 1997) in seeing utterances as the ing point for their own subsequent projects. combined realization of a specific, constrained range However, in retrospect, TAGLET does not serve of communicative functions. But we would like to to introduce students outside computer science to the be able to explore a range of other metaphors for distinctive insights that come from a computational organizing the information in dialogue. We would approach to language use. For one thing, to reach like students to be able to realize models of face-to- a broad audience, it is a mistake to focus on repre12 sentations th</context>
</contexts>
<marker>Core, Allen, 1997</marker>
<rawString>Mark G. Core and James F. Allen. 1997. Coding dialogs with the DAMSL annotation scheme. In Working Notes of AAAI Fall Symposium on Communicative Action in Humans and Machines. http://www.cs.rochester.edu/research/cisd/resources/damsl/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas DeCarlo</author>
<author>Corey Revilla</author>
<author>Matthew Stone</author>
<author>Jennifer Venditti</author>
</authors>
<title>Specifying and animating facial signals for discourse in embodied conversational agents.</title>
<date>2004</date>
<journal>Journal of Visualization and Computer Animation. http://www.cs.rutgers.edu/˜village/ruth/.</journal>
<marker>DeCarlo, Revilla, Stone, Venditti, 2004</marker>
<rawString>Douglas DeCarlo, Corey Revilla, Matthew Stone, and Jennifer Venditti. 2004. Specifying and animating facial signals for discourse in embodied conversational agents. Journal of Visualization and Computer Animation. http://www.cs.rutgers.edu/˜village/ruth/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David DeVault</author>
<author>Anubha Kothari</author>
<author>Natalia Kariaeva</author>
<author>Iris Oved</author>
<author>Matthew Stone</author>
</authors>
<title>An information-state approach to collaborative reference.</title>
<date>2005</date>
<booktitle>In ACL Proceedings Companion Volume (interactive poster and demonstration track). http://www.cs.rutgers.edu/˜mdstone/pointers/collabref.html.</booktitle>
<contexts>
<context position="19881" citStr="DeVault et al., 2005" startWordPosition="3112" endWordPosition="3115">tart from scratch. We have found this con- eral than learning RUTH!) Computer science stucretely in our work. What got linguists involved in dents will thus find it easier to assist a team of comthe computational exploration of dialogue semantics munication and linguistics students in adding new at Rutgers was not the special teaching resources expressions to an animated character. Stone created. It was hooking students up with the Creating such resources to span a general system systems that were being actively developed in ongo- for face-to-face dialogue would be an enormous uning research (DeVault et al., 2005). These research dertaking. It could happen only with broad input efforts made it practical to provide students with the from those who teach discourse and dialogue, as we visualizations, task and context models, and interac- do, through a mix of theory and practice. We hope tive architecture they needed to explore substantive the TNLP workshop will spark this kind of process. issues in dialogue semantics. Whatever we do will We close with the questions we’d like to consider have to closely connect teaching and our ongoing re- further. What kinds of classes on dialogue and dissearch. course pr</context>
</contexts>
<marker>DeVault, Kothari, Kariaeva, Oved, Stone, 2005</marker>
<rawString>David DeVault, Anubha Kothari, Natalia Kariaeva, Iris Oved, and Matthew Stone. 2005. An information-state approach to collaborative reference. In ACL Proceedings Companion Volume (interactive poster and demonstration track). http://www.cs.rutgers.edu/˜mdstone/pointers/collabref.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Staffan Larsson</author>
<author>David Traum</author>
</authors>
<title>Information state and dialogue management in the TRINDI dialogue move engine toolkit. Natural Language Engineering,</title>
<date>2000</date>
<pages>6--323</pages>
<contexts>
<context position="1469" citStr="Larsson and Traum, 2000" startWordPosition="212" endWordPosition="215">roduction Hands-on interaction with dialogue systems is a necessary component of a course on computational linguistics and natural language technology. And yet, it is clearly impracticable to have students in a quarterlong or semester-long course build a dialogue system from scratch. For this reason, instructors of these courses have experimented with various options to allow students to view the code of a working dialogue system, tweak code, or build their own application using a dialogue system toolkit. Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al., 2003) toolkits. However, each of these options has turned 9 out to have disadvantages. Some of the toolkits require too much knowledge of linguistics for the average computer science student, and vice-versa, others require too much programming for the average linguist. What is needed is an extensible dialogue toolkit that allows easy application building for beginning students, and more sophisticated access to, and tweakability of, the models of discourse for advanced students. In addition, as computational linguists become increasingly interested in the role of no</context>
<context position="12691" citStr="Larsson and Traum, 2000" startWordPosition="1970" endWordPosition="1973">priate behavioral response; and then it requires extending the animation platform to be able to show this behavior. BEAT makes the second step easy—as it should be—even for linguistics students. To handle the first and third steps, you would hope that an interdisciplinary team containing a communication student and a computer sci11 ence student would be able to bring the expertise to face dialogue (Cassell et al., 2000), the informationdesign the new dialogue state and the new animated state approach to domain-independent practical dibehavior. But that wasn’t exactly true. In order to alogue (Larsson and Traum, 2000), or approaches add the behavior to REA, students needed not only that emphasize the grounding of conversation in the background in the relevant technology—like what a specifics of a particular ongoing collaboration (Rich computer scientist would learn in a general human et al., 2001). The integration of a talking head into animation class. To add the behavior, students also the CSLU toolkit epitomizes these limitations with needed to know how this technology was realized the platform. The toolkit allows for the automatic in our particular research platform. This proved too realization of text</context>
</contexts>
<marker>Larsson, Traum, 2000</marker>
<rawString>Staffan Larsson and David Traum. 2000. Information state and dialogue management in the TRINDI dialogue move engine toolkit. Natural Language Engineering, 6:323–340. http://www.ling.gu.se/projekt/trindi/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
<author>Steven Bird</author>
</authors>
<title>NLTK: the natural language toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics. http://nltk.sourceforge.net.</booktitle>
<contexts>
<context position="1416" citStr="Loper and Bird, 2002" startWordPosition="204" endWordPosition="207">etter teaching infrastructure in the future. 1 Introduction Hands-on interaction with dialogue systems is a necessary component of a course on computational linguistics and natural language technology. And yet, it is clearly impracticable to have students in a quarterlong or semester-long course build a dialogue system from scratch. For this reason, instructors of these courses have experimented with various options to allow students to view the code of a working dialogue system, tweak code, or build their own application using a dialogue system toolkit. Some popular options include the NLTK (Loper and Bird, 2002), CSLU (Cole, 1999), Trindi (Larsson and Traum, 2000) and Regulus (Rayner et al., 2003) toolkits. However, each of these options has turned 9 out to have disadvantages. Some of the toolkits require too much knowledge of linguistics for the average computer science student, and vice-versa, others require too much programming for the average linguist. What is needed is an extensible dialogue toolkit that allows easy application building for beginning students, and more sophisticated access to, and tweakability of, the models of discourse for advanced students. In addition, as computational lingu</context>
<context position="8210" citStr="Loper and Bird, 2002" startWordPosition="1247" endWordPosition="1250">usively on high-level and interactional issues, such as the structure of discourse and dialogue, information structure, intentions, turn-taking, collaboration, 1The catchy title is the inspiration of Deb Roy at MIT. 10 reference and clarification. Context is central, and under that umbrella we explicitly discuss both the perceptual environment in which conversation takes place and the non-verbal actions that contribute to the management of conversation and participants’ real-world collaborations. Our unusual focus means that we can not readily take advantage of software toolkits such as NLTK (Loper and Bird, 2002) or Regulus (Rayner et al., 2003). These toolkits are great at helping students implement and visualize the fundamentals of natural language processing—lexicon, morphology, syntax. They make it easy to experiment with machine learning or with specific models for a small scale, short course assignment in a specific NLP module. You can think of this as a “horizontal” approach, allowing students to systematically develop a comprehensive approach to a single processing task. But what we need is a “vertical” approach, which allows students to follow a specific choice about the representation of com</context>
</contexts>
<marker>Loper, Bird, 2002</marker>
<rawString>Edward Loper and Steven Bird. 2002. NLTK: the natural language toolkit. In Proceedings of the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics. http://nltk.sourceforge.net.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>