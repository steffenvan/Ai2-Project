<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007036">
<title confidence="0.982069">
Steps Toward Deep Lexical Acquisition
</title>
<author confidence="0.993703">
Sourabh Niyogi
</author>
<affiliation confidence="0.997274">
Massachusetts Institute of Technology
</affiliation>
<email confidence="0.998331">
niyogi@mit.edu
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999958333333333">
I describe steps toward “deep lexical ac-
quisition” based on naive theories, moti-
vated by modern results of developmental
psychology. I argue that today’s machine
learning paradigm is inappropriate to take
these steps. Instead we must develop com-
putational accounts of naive theory repre-
sentations, mechanisms of theory acquisi-
tion, and the mapping of naive theories to
lexicalizable concepts. This will enable
our theories to describe the flexibility of
the human conceptual apparatus.
</bodyText>
<sectionHeader confidence="0.901609" genericHeader="method">
1 Where We Are Now
</sectionHeader>
<bodyText confidence="0.987711784313726">
The present Machine Learning Paradigm
Much of computational linguistics has converged
onto a machine learning paradigm that provides us
soothing clarity. The machine learning approach de-
fines a problem as a mapping problem – map some
acoustic stream onto a list of word tokens, map a list
of word tokens onto a parse tree, map a parse tree
onto a set of semantic roles or “logical form”, map
each word in a tree onto its best sense, and so on.
We then develop a learning algorithm to accomplish
the desired mapping. Multiple groups describe how
well their algorithm maps various test sets given var-
ious training sets, and describe a “result” to improve
upon. The clarity provided by this paradigm is so
soothing, one gets the sense we can turn a crank,
and indeed, in many cases, progress has been made
proceeding precisely along these lines.
Turning the crank on deep lexical acquisition,
however, we might feel something is missing. What
is it? Underlying any model of deep lexical acquisi-
tion is a theory of the human conceptual apparatus.
Unlike our handle on acoustic streams, word lists,
and parse trees, our handle on a suitable “output”
for the space of word meanings is remarkably poor.
Somehow, via experience (of some kind or another),
children acquire a mapping from a space of vocabu-
lary items to a space of lexicalizable concepts – the
lexicon; our task as modelers is to figure out how
this mapping can occur. Many models for the space
of lexicalizable concepts exist: concepts are points
in Rn, concepts are Jackendoff’s lexical concep-
tual structures, concepts are FrameNet’s frame ele-
ments, concepts are Schankian script activators, con-
cepts are distributions over syntactic frames, con-
cepts are grounded in sensorimotor statistics, or all
of the above. Almost everyone nowadays reports
how their algorithm accomplished some mapping to
one or more of these models of concepts. They have
to, because today’s de facto idea of what constitutes
a “result” according the machine learning paradigm
today is to do exactly this.
The Golden Oldies formed our concept models
Our models of conceptual spaces did not origi-
nate from computational linguists following the ma-
chine learning paradigm. They were proposed from
linguists, psychologists and philosophers back in
earlier eras - what we will call Golden Oldies –
when the idea of a “result” was somewhat differ-
ent. There are too many to recall: Quine (1960)
argued that the linguist watching the natives utter-
ing Gavagai! in the context of a rabbit would nec-
</bodyText>
<page confidence="0.984987">
91
</page>
<note confidence="0.9944665">
Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 91–99,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.995431894736842">
essarily require far more constraints than met the
eye. Brown (1957) showed that children used syn-
tactic cues to disambiguate between possible mean-
ings; Landau and Gleitman (1985) followed on these
insights, showing just how deep it could be, that
even blind children could learn look and see, basing
their mapping on syntactic constraints. Chomsky’s
(1965) notion of “deep structure” – proposed to ac-
count for commonplace syntactic phenomena – mo-
tivated many insights explored in Gruber (1965)’s
thesis, Fillmore (1968)’s classical thematic roles,
and Jackendoff (1983)’s Lexical conceptual struc-
tures. Hale and Keyser and many linguists labored
under the MIT Lexicon project in the 1980s to deter-
mine the fundamental features of the lexicon; many
of these hard-earned observations appear in Levin
(1993). Schank (1972)’s Conceptual dependency
theory, Minsky (1975)’s Frames were proposed for
the broader goals of capturing commonsense knowl-
edge. Quillian’s (1968) and Miller et al (1990)’s
WordNet were not intended for models of lexical ac-
quisition or databases to be used in computational
linguistics but as models of human semantic mem-
ory. Many other Golden Oldies exist, and our debt
to them is quite large. Ask what motivates our col-
lection of subcategorization statistics or what drives
the quest for semantic roles, and the roots are found
in the science questions of the Golden Oldies.
The present Myopic Learning Paradigm
It would have been extremely myopic to take any
one of these classical results and accuse their authors
of not demonstrating a learning algorithm, not evalu-
ating them on large corpora, and not getting together
in workshops to share the results on test sets. The
standard for what constituted a result back then con-
sisted of none of these things, because today’s ma-
chine learning paradigm was just not present then.
The questions were:
</bodyText>
<listItem confidence="0.992012">
• Question (1): What is a lexicalizable concept?
• Question (2): How can a word-concept map-
ping be learned from evidence?
</listItem>
<bodyText confidence="0.988113642857143">
But for reasons that no one really talks about,
somehow, the standard of what constitutes a result
changed from some balance of Question (1) and (2)
to a machine learning paradigm essentially focused
on Question (2). The dependency between Ques-
tion (1) and (2) is quite well-understood, but do we
have an adequate answer to (1)? We tell ourselves:
We’ve gotta build betterparsers, speech recognizers,
search engines, machine translation systems, so...
let’s take shortcuts on Question (1) so as to make
progress on Question (2). For many, that shortcut
consists of semantic role labels and learning from
frame distributions. These shortcuts don’t answer
Question (1), unfortunately.
</bodyText>
<sectionHeader confidence="0.805864" genericHeader="method">
2 Where We Need to Go
</sectionHeader>
<bodyText confidence="0.987912628571428">
While the Golden Oldies were used as the founda-
tions of today’s lexical acquisition, psychology be-
gan to sing a new tune, still balancing Questions (1)
and (2).
Children have naive theories
Developmental psychology after the Golden
Oldies has shown just how deep our “deep lexical
acquisition” theories have to be. On this view, word
meanings are couched in changing naive theories of
how the world works. The model of the child is that
the child possesses a naive theory T* changing state
from T1 to T2, and that there is a space of concepts
accessible from T1 that substantively different from
the space of concepts accessible from T2. A learner
undergoes radical conceptual change. Developmen-
tal psychology has not been explicit about the pre-
cise form of T*, nor have they characterized how T*
relates to lexicalizable concepts. But their contribu-
tions inform us about the fundamental ingredients
of concepts (Question (1)) and inform us what deep
lexical acquisition must consist of (Question (2)).
A few examples must suffice in place of a review
(c.f. Gopnik and Meltzoff (1997)). Keil (1989)’s
transformation studies illustrate theory change in the
domain of biology. First, children are shown a pic-
ture of a skunk; then, are told a story – that the an-
imal received either (A) surgery or (B) a shot in in-
fancy – and then are shown a picture of a raccoon.
Young preschool children judge that the animal is
a raccoon, as if they base their judgements on su-
perficial features. Children between 7 and 9 (T2)
on the other hand, judge that the raccoon-looking
figure in (A) is still a skunk. Adults (T3) judge
that the raccoon-looking figure in both conditions is
still a skunk. Apparently, preschoolers’ theory T1
</bodyText>
<page confidence="0.992225">
92
</page>
<bodyText confidence="0.997412824324324">
lacks the belief that an animal’s kind is determined
at birth, but this becomes part of the adult’s T3.
Similarly, preschool children at T1 have concept
of death involving a belief in a continued existence
in an alternate location (like sleep); When asked
whether dead people dream, eat, defecate, and move,
4 to 6 year olds will say that dead people do all of
these, except move (Slaughter et al, 2001). Missing
in T1 are the causes of death (a total breakdown of
bodily functions) and that death is an irreversible, in-
evitable end. Between 4 and 6, children become su-
perficially aware of the general function of various
body parts (e.g “You need a heart to live”). Other
phenomena serve the same point: the child at T1
thinks uncle means friendly middle-aged man, and
at T2 thinks it means parent’s brother. The child at
T1 thinks island means a beachy territory and at T2
thinks it means body of land surrounded by water
(Keil 1989). And, “theory of mind” concepts/words
such as belief, desire, wonder, pretend (Wellman
and Bartsch 1995, Leslie 2000) are similarly situ-
ated.
How “theory-like” T1 and T2 are is subject to
considerable debate (diSessa 1993, Leslie 2000).
disessa (1993) describes a large number of causal
“p-prims” that are highly context specific and con-
siderably larger in number than what Carey (1985)
describes; these are shown to apply to everyday
physical phenomena – “force as mover”, “vaccu-
ums impel”, “overcoming”, “springiness”, “bigger
means lower pitch (or slower)”, to name a few. Each
of these have a FrameNet-like causal syntax, of
some unknown mapping to vocabulary items. Sim-
ilarly, Rozenblit and Keil (2003) show that non-
expert adults have a remarkably superficial notion
of how common mechanisms work – such as how a
helicopter changes from hovering to forward flight.
Theories may be suspiciously weak.
Students have alternative frameworks
Educational psychologists have characterized T*
by asking a different, more practical question: why
is it difficult for science students to learn certain sci-
entific concepts (weight, density, force, heat, ...)
when they come to class? The broad insight is this:
students come to class not as blank slates but with
alternative pre-conceptions that must be understood.
Data on their pre-conceptions yields clues as to con-
tents of T*, well before they walk into science class.
Again, a few examples illustrate the point.
Many studies on physics misconceptions have ob-
served deeply held views on the motion of pro-
jectiles (McCloskey 1983, Halloun and Hestenes
1985). Ask students to predict what happens when
a projectile is thrown upward at an angle, and their
answers will typically be consistent with one of (a-c)
These answers are consistent with an “impetus” the-
ory of motion, where an object’s motion is exclu-
sively dominated by whatever “impetus” the thrower
provides it. Medieval scientists such as Buridan
also held similar beliefs; Newtonian mechanics, of
course, shows that the answer is a parabola. disessa
(1993) report a wider array of these types of physics
misconceptions in a theoretical framework.
Likewise, ask students for their knowledge of how
their eyes work, and they reveal an “extramission”
belief: something somehow shoots out from the eye
and reaches the objects (Winer et al 2002); they also
say that eye is the sole organ in the body responsi-
ble for vision. Plato and da Vinci shared these same
beliefs. Systematic catalogues of these sorts of ob-
servations have been compiled for just about every
domain – e.g. megaphones create sounds, heat is a
substance, eggs are not alive, the moon and sun are
the same size, and so forth (AAAS 1993).
</bodyText>
<sectionHeader confidence="0.938619" genericHeader="method">
3 What Steps We Must Take
</sectionHeader>
<bodyText confidence="0.999951454545455">
Consider this fascinating phenomena from the Best
of Today and the comfort of the grammar-generates-
sentence relation will be replaced by queasiness: the
terms theory, concept, and change are most unclear,
as many developmental psychologists freely admit.
But computational linguists may contribute signifi-
cantly to rendering new clarity: If the Golden Oldies
drove the efforts on today’s shallow lexical acquisi-
tion, the Best of Today’s Psychology may drive the
results of tomorrow’s progress in deep lexical acqui-
sition.
</bodyText>
<page confidence="0.989068">
93
</page>
<figure confidence="0.999515242424243">
primitives // Concept
Generator G
(a)
//space of lexicalizable
concepts
Vocabulary
// Acquisition
Device
OO
// lexicon
experience
OO OO
space of possible
theories
(b)
//
Theory
Acquisition
Device
// Theory T* //
Concept
Generator
G
space of lexicalizable
// concepts G(T*)
Vocabulary
Acquisition
Device
theory-based
lexicon L
//
//
experience experience
</figure>
<figureCaption confidence="0.993507">
Figure 1: (a) The Model of Concepts from the Golden Oldies: used in the present Machine Learning Paradigm; (b) The Universal
Theory Model of Concepts: necessary for deep lexical acquisition
</figureCaption>
<bodyText confidence="0.998412291666667">
The new framework: Universal Theory
We have much progress to make: We can de-
scribe naive theories precisely; we can describe how
theory acquisition occurs; we can describe the map
from naive theories to a set of lexicalizable concepts.
We can describe how vocabulary acquisition occurs.
Figure 1(a) shows the Golden Oldies model of con-
cepts that we must abandon: a Vocabulary Acquisi-
tion Device receives a fixed hypothesis space of pos-
sible concepts completely determined by a fixed set
of primitives; Figure 1(b) shows the Universal The-
ory Model of Concepts that we must take steps to-
wards: A Theory Acquisition Device (TAD) outputs
a state T* that describes a learners’s naive theory; A
Concept Generator G maps T* to a set of lexical-
izable concepts G(T*). A Vocabulary Acquisition
Device (VAD) uses G(T*) to learn a lexicon. The
theory of the TAD states is Universal Theory (UT);
a UT metalanguage enables an abstract characteriza-
tion of possible theories – each possible theory de-
scribes a system of kinds, attributes, relations, part-
whole relations, and causal mechanisms. Within this
Universal Theory Model of Concepts, we can begin
to answer the following core questions:
</bodyText>
<listItem confidence="0.999349285714286">
1. what is the initial state of the TAD?
2. what are possible final states of the TAD?
3. how can the TAD change state?
4. how can the TAD use T* to parse experience?
5. how does the concept generator G map T* onto
a set of lexicalizable concepts G(T*)?
6. how can the VAD use G(T*)?
</listItem>
<bodyText confidence="0.999276131578948">
We have made progress on these core questions
Many of these questions have been addressed al-
ready in computational models where a candidate
UT metalanguage and theory T* is latent. diSessa
(1993) catalogs sets of p-prims in naive physics.
Atran (1995) describes a theory of family struc-
ture. Gopnik et al (2004) uses Bayesian networks to
model preschooler’s causal reasoning about blickets.
McClelland and Rogers (2004) describe connection-
ist models of some of Carey (1985)’s classic results.
In my own work, I have been situating the ele-
ments of the Universal Theory Model of Concepts in
a microgenesis study, where adult subjects undergo
a T1 to T2 transition (Niyogi 2005). The transition
can be understood with a minimal UT metalanguage
needed to characterize a set of possible theories: T*
is characterized by a interrelated sets of kinds, at-
tributes, relations, and causal laws. T1 and T2 are
described in that UT metalanguage, and the simplest
concept generator G is described that mechanically
maps T1 and T2 onto G(T1) and G(T2). Sub-
jects undergo theory change in a Blocksworld uni-
verse (see Figure 2(a)) while learning 3 verbs (gorp,
pilk, seb) that refer to the causal mechanisms gov-
erning the universe. Subjects interact with a set of
29 blocks, some of which activate other blocks on
contact. On activation, subjects are shown a transi-
tive verb frame (“Z is gorping L, “U is sebbing F”,
“D is pilking Y”) in a Word Cue Area. Unbeknownst
to subjects, each block belongs to 1 of 4 kinds (A, B,
C or D) and 3 activation mechanisms exist between
them: lawab: As activate Bs, lawc’: Cs activate Cs,
and lawd: Ds activate Ds; each of the 3 verbs refers
to one the 3 mechanisms. Subjects are probed for
the naming conditions on each of the 3 verbs.
Subjects’ responses indicate that their TAD state
changes from T* = T1 (there is 1 kind of block
governed by 1 causal mechanism lawq) to T* = T2
</bodyText>
<page confidence="0.985087">
94
</page>
<figure confidence="0.9999765">
(a)
(b)
</figure>
<figureCaption confidence="0.9969">
Figure 2: (a) Subjects try to learn the laws and word meanings in a “Causal Blocksworld” computer application by dragging and
dropping blocks onto each other. Cues to the meaning of 3 verbs (gorp, pilk and seb) are given in a Word Cue Area. Shown is how
two kinds of subjects – T2 Subjects and T1 Subjects – clustered the blocks; the clusters for the kinds A, B, C and D (boxed) are
clear for T2 Subjects but no such differentiation is apparent for T1 subjects; (b) When T* = T1, all 3 verbs can only be mapped
to a single concept in G(T1) = {Q} (dashed arrows); When T* = T2, gorp, pilk and seb can be mapped to 3 new concepts AB, C&apos;
and D in G(T2) (solid arrows).
</figureCaption>
<bodyText confidence="0.999437370967742">
(there are 4 kinds of blocks governed by 3 distinct
causal mechanisms, lawab, lawc’ and lawd). But
this is not true for all subjects: some remain “T1
subjects” while others move onto become “T2 sub-
jects”. Critically, when T* = T1, the verbs can only
be mapped to a single concept in G(T1) = {Q};
When T* = T2, the verbs can be mapped to 3 dis-
tinct concepts in G(T2) = {AB, C&apos;, D} (See Figure
2(b)). Once T* = T2, subjects can “parse” the ac-
tivation and infer the hidden kind and causal mech-
anism involved. Critically, subjects cannot learn to
distinguish the 3 verbs until T* = T2, when the
3 new concepts emerge in G(T*). Then gorp, pilk
and jeb may be mapped onto those 3 new concepts.
These verbs are thus theory-laden in the same way
as death, uncle and island.
This UT architecture concretely dissolves the
Puzzle of Concept Acquisition (Laurence and Mar-
golis 2002): how can a person ever acquire a “new”
concept, when a fixed set of primitives exhaustively
span the space of possible concepts? Taking the
viewpoint of the learner’s VAD at a specific moment
in time with a specific T*, it has access to just those
concepts in G(T*) – acquisition of a new concept
is possible if T* changes. Taking the viewpoint of
the learner’s species across all possible times, the
species has access to the union of G(T*) over all
possible TAD states – thus a “new” concept for the
species is impossible. Which viewpoint one takes is
a matter of perspective. Critically, the Golden Oldies
model of concepts does not expose the TAD state re-
vealed in the UT model of concepts (Fig. 1a,b).
Universal Theory and the Linguistic Analogy
Computational linguists can progress on these
questions, because naive theories are like gram-
mars. Just as a grammar generates a set of possible
sentences, a theory T* generates a set of possible
worlds. Just as the space of possible grammars is re-
stricted, so is the space of possible theories. Just as
learning a grammar consists of picking a point from
a space of possible grammars, learning a theory con-
sists of picking a point from the space of possible
theories. The task of writing a naive theory is like
writing a grammar. The task of characterizing the
space of possible theories requires a theory meta-
language just as characterizing the space of possible
grammars requires a grammar metalanguage.
Moreover, research into naive theories does not
proceed separately from the program of research in
grammar. The two programs are bridged by the con-
cept generator G: T* generates G(T*), a set of lexi-
calizable concepts. An adequate account of G would
generate concepts present in a particular language,
for every language, and for every possible T*.
Miller et al (1990) distinguish between a con-
structive and a differential lexicon. In a differential
theory of the lexicon, meanings can be represented
by any symbols that enable a theorist to distinguish
among them; In a constructive theory of the lexi-
con, the representation should “contain sufficient in-
formation to support an accurate construction of the
concept (by either a person or a machine)”.
</bodyText>
<page confidence="0.997566">
95
</page>
<bodyText confidence="0.999079333333333">
The conceptual analyst who desires to produce a
constructive theory of the lexicon has four kinds of
accounts to provide: (see Niyogi 2005)
</bodyText>
<listItem confidence="0.964401076923077">
• an explanatory account of the space of possible
theories, for all persons P
• an explanatory account of the space of possi-
ble concepts, for all persons P, for all possible
theories
• a descriptive account of a specific theory T*
held by a representative person P (e.g. of a 3-
year old or of a 10-year old)
• a descriptive account of a specific lexicon L
held by a representative person P (e.g. a 3-
year old Chinese speaker, 3-year old English
speaker, 10-year old Chinese speaker, 10-year
old Chinese speaker)
</listItem>
<bodyText confidence="0.993199441558442">
We may envision a “theory-based lexicon” that
would capture the two key state variables in Figure
1(b), the two descriptive accounts above: (1) T* for
an idealized human; (2) a set of vocabulary items
mapped to points in G(T*). Very limited instances
of a theory-based lexicon can be constructed already
for subjects at the end of the experiment – such a
theory-based lexicon has (1) T2 in the UT metalan-
guage; (2) the mapping in L to G(T2): gorp = AB,
pilk = C&apos;, seb = D. This constructive theory-based
lexicon would be in stark contrast to differential lex-
icons such as WordNet and FrameNet.
Grounding language in perception is insufficient
Many have proposed deep lexical acquisition by
“grounding language in perception” (Siskind 1996,
Regier 1996, Roy and Pentland 2002, Yu and Bal-
lard 2004), constructing systems that can learn to ut-
ter, e.g. red, banana, hit and triangle in contexts
where there are, e.g., three triangles hitting red ba-
nanas. Such systems also propose a space of possi-
ble concepts exhausted by a fixed set of primitives,
as in the Golden Oldies model. The initial state of
the TAD (T*(t = 0)) can explicitly incorporate all
these attributes and relations (contact, luminance,
...); but then, the TAD can further change state
to yield new kinds, attributes, relations, and causal
mechanisms not present in the initial state, but mo-
tivated by the data (see Gopnik and Meltzoff 1997).
As such, vague appeal to grounding is insufficient;
associative processes that may work on red, hit, ba-
nana, eye, three are extremely challenging to gen-
eralize to color, kind, wonder, pilk, seb, telescope,
maybe and uninvented groobles that cannot be per-
ceived. Again, developmental psychology provides
some insight on what theoretical innovations would
be required for a suitable interface to sensorimotor
apparatus (c.f. Mandler 2004).
Commonsense AI gives UT foundations
Primitives well beyond the sensory apparatus
have been developed to describe physical systems
qualitatively (Regier 1975, Forbus 1984). They
show us some of the possibilities of what T* and
candidate UT metalanguages may look like (quan-
tity spaces, kinds, attributes, relations, part-whole
relations, and causal mechanisms that interrelate
these sets). Regier (1975)’s description of a toi-
let appears particularly close to Rozenblit and Keil
(2003)’s helicopter. Later qualitative AI frameworks
of Forbus (1984) and Kuipers (1994) may be ap-
plied to McCloskey (1982)’s intuitive physics and
disessa’s (1993) p-prims. Except for the work of
Hobbs, Pustejovsky and their colleagues, few have
mapped commonsense theories onto the lexicon.
Similar domain-general elements of naive math and
causality are present in the workds of Hobbs et al
(1987), Kennedy and McNally (2002)’s degree rep-
resentations for gradable predicates, Talmy (1988)’s
force dynamics, and the quantity spaces of Kuipers
(1994) and Forbus (1984). These disparate frame-
works provide foundational elements for a UT met-
alanguage.
Shortcuts on UT foundations will not work
We must resist the urge to take shortcuts on
these foundations. Simply creating slots for foun-
dational phenomena will impede progress. Puste-
jovsky (1995)’s observations for co-composition
have clearly illustrated how much flexibility our in-
terpretation systems must have, e.g. in He enjoyed
the beer/movie. But specifying the telic role of beer
and movie to be drink and watch does not consti-
tute an adequate theory – we require constraints that
relate to the state space of the human conceptual ap-
paratus. Pustejovsky (1995)’s telic, formal, constitu-
tive, agentive roles may be mapped onto T*’s char-
acterization of artifacts, materials, and so on. We
require nothing less than absolute conceptual trans-
parency.
</bodyText>
<page confidence="0.979524">
96
</page>
<bodyText confidence="0.99903312">
We must bridge UT to analogy
Lakoff and Johnson (1980) and subsequent cog-
nitive linguistics work have catalogued a stunning
level of metaphoric usage of language. Lexical ex-
tension of items such as illuminate in, e.g. Analo-
gies illuminate us on theory acquisition are couched
in terms of conceptual metaphors such as “ideas are
light”. Significant steps have been taken to model
analogical mapping (c.f. Falkenhainer et al 1989,
Bailey et al 1997) and conceptual blending (Faucon-
nier and Turner 1998). These processes may moti-
vate TAD state changes. In most cases, the the un-
derlying predicates in the source and target domains
are ad hocly constructed; a natural source of these
predicates may be the sets internal to T* (kinds, at-
tributes, relations, causal mechanisms); similarity
between domains may be determined by the struc-
tural properties of the UT metalanguage and G. If
T* incorporates the common causal mechanisms be-
hind ideas and light transmission, for example, then
one may strive for a shorter lexicon where the vo-
cabulary item illuminate happens to be used in both
domains with “one” core entry. An adequate theory
of this process would obviously reduce the number
of so called “senses” in word sense disambiguation.
</bodyText>
<sectionHeader confidence="0.95218" genericHeader="method">
4 What We Assumed Wrong
</sectionHeader>
<bodyText confidence="0.999579681818182">
Modern computational linguistics appears to have
made a set of assumptions that deserve reanalysis,
given the availability of other options.
Assumption: A fixed alphabet of meaning com-
ponents exists, and we know what it is
A key assumption dating to the Golden Oldies is
that the meaning of a sentence is adequately cap-
tured by a “logical form” (LF) characterized by a
fixed alphabet of meaning components (e.g. the-
matic roles, lexical semantic primitives, conceptual
dependency primitives). Today’s computational lin-
guistics program uses this assumption to demon-
strate systems that answer “who did what to whom,
where, why, . . .” questions, given sentences like:
John saw the man with the telescope.
John hit the man with the umbrella.
Is the computational linguist is expected to be sat-
isfied when systems can answer Who saw the man
with the telescope? or Who did John hit with the um-
brella? This year’s CoNLL Shared Task, mapping
sentences onto semantic roles, assumes the above.
But try these: Does John have eyes? Were they ever
open when he was looking through the telescope?
Could John know whether the man was wearing un-
derwear? Did the umbrella move? Did John move?
Did the man feel anything when he was hit? Was
John alive? Was the man alive? Why would John
need a telescope to see the man, when he has eyes?
Why would John use an umbrella when his hands
would do? Something is missing in these systems.
We should be more accountable. Developmen-
tal psychology showed that theory change and con-
ceptual change is possible, proving this assumption
is wrong: the alphabet behind sentence meaning
is a varying set of lexicalizable concepts G(T*).
Missing in today’s systems attaching AGENT (or
FrameNet’s Perceiver passive, or Impactor) to John
and INSTRUMENT to umbrella and telescope is T*,
and a mapping of the lexical items to G(T*). What
T* must contain, in some as yet unknown form, is
a T of physics described by McCloskey and disessa
(1993), a T of vision studied by Landau and Gleit-
man (1985) and Winer et al (2002), a T of body
studied by Carey (1985), a T of materials and arti-
facts studied by Hobbs et al (1987) and Pustejovsky
(1995). This T*, when mapped via G, forms the al-
phabet of the above 2 sentences.
Assumption: The machine learning paradigm
can treat deep lexical acquisition.
If we reject the assumption that there is some
“meaning” of a sentence spanned by a set of mean-
ing primitives, the soothing clarity of the machine
learning paradigm is no longer available. We cannot
map parse trees onto sentence meanings. The pos-
sibility of “Putting Meaning in Your Trees” (Palmer
2004) completely disappears. We may still use the
machine learning paradigm to parse, disambiguate
and recognize speech. But these results are of lit-
tle use to model theory, concept and lexical acquisi-
tion, because there is no output representation where
a suitable training set could be collected. The human
conceptual apparatus is not that simple: the VAD re-
quires G(T*) (which changes, as T* changes), and
for that we need explanatory accounts of UT and G,
and must recognize the diverse ways the TAD may
change state.
</bodyText>
<page confidence="0.998819">
97
</page>
<bodyText confidence="0.978537063291139">
Assumption: Paths from shallow to deep lexical
acquisition exist
The Golden Oldies Models of concepts (Figure
1a) and the Universal Theory models of concepts
(Figure 1b) are incommensurable. The path from
the shallow to the deep cannot be declared to exist
by fiat. Wishful thinking is inappropriate, because
one architecture is more powerful than the other: the
Golden Oldies model did not expose the TAD state
space. Instead, lexical semantics results obtained
under the Golden Oldies model require translation
into the UT model: the privileged position syntactic
positions that motivated thematic roles and lexical
semantics primitives, the bi-partite event structure
revealed through adverbial modification, and so on.
This translation is mediated in G, and will not yield
a notational variant of what we started with.
Assumption: Verb classes determine meanings
We must distinguish between a representation of
verb meanings determined by the distribution of
subcategorization frames and cued by these frames.
Landau and Gleitman (1990) showed that verb’s par-
ticipation in some frames but not others are cues
that a child uses to constrain verb meaning. Levin
and Rappaport-Hovav (1998) explicitly distinguish
structural and idiosyncratic components of mean-
ing. But neither claim that verb classes or statistical
distributions of subcategorization frames determine
verb meaning. Yet VerbNet maps verbs to predicates
in precisely this way: (Kingsbury et al 2002).
cure, rob, ...: Verbs of Inalienable Possession
cause(Agent,E) location(start(E),Theme,Source)
marry, divorce, ...: Verbs of Social Interaction
social interaction(...)
The distinction between cure and rob, or between
marry and divorce is not astonishing to the English
speaker. Causal mechanisms behind disease, pos-
session, and the marital practices that were labeled
idiosyncratic by the lexical semanticist must be cap-
tured in T*.
Assumption: Language is separate from general
systems of knowledge and belief
This “defining” assumption helped for the Golden
Oldies, but innovations in developmental psychol-
ogy motivate dropping this assumption. The bridge
is provided by the concept generator G: it maps a
naive theory T* (general systems of knowledge and
belief) to G(T*), used by the VAD (language).
Assumption: Real-world knowledge is Bad
The absence of the soothing clarity of the machine
learning paradigm and presence of real world knowl-
edge in T* brings forth 2 associations:
Early Schank/Cyc = Much Knowledge = UT research = Bad
Statistics = Little Knowledge = shallow semantics = Good
The associations lead to the inference that Universal
Theory research will suffer a similar fate as the 70s
Schankian program and the Cyc program (Schank
1972, Lenat and Guha 1990). However, this infer-
ence is incorrect. The 70s Schankian program and
Cyc efforts did not carefully consider the constraints
of syntactic phenomena or developmental psychol-
ogy. Schank and his colleagues stimulated research
in qualitative physics and explanation-based learn-
ing that addressed many of these deficiencies, but
there is much work to be done to bridge today’s ef-
forts in deep lexical acquisition to this.
Assumption: Others will provide us the answers
Lexical semanticists now rely on cognitive expla-
nations far more heavily than ever before. Jack-
endoff (2002) concludes: “someone has to study
all these subtle frameworks of meaning - so why
not linguists?” Levin and Rappaport-Hovav (2003),
addressing denominal verbs such as mop and but-
ter, now freely point to “general cognitive prin-
ciples” rather than situate knowledge in the lexi-
con. Rather than consume lexical semantics of the
Golden Oldies, we can draw upon our toolbox to
again answer Question (1): “what is a lexicalizable
concept?”
</bodyText>
<sectionHeader confidence="0.984313" genericHeader="conclusions">
5 We Must Change Our Concepts
</sectionHeader>
<bodyText confidence="0.999289727272727">
Stop working with models of concepts from the
Golden Oldies. Start questioning whether results
under the machine learning paradigm are really re-
sults. Change your concept of a result. Learn how
children do theory, concept and vocabulary acqui-
sition. Expose the fundamental ingredients of con-
cepts. Change your concept of deep. Change your
concept of computational linguistics. Radical con-
ceptual change is possible. Write some new songs,
and sing some new tunes. We can have some Great
Golden Oldies of Tomorrow.
</bodyText>
<page confidence="0.99483">
98
</page>
<sectionHeader confidence="0.99582" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999865729166667">
S. Atran. Classifying nature across cultures. In E. Smith and D. Osherson, edi-
tors, Thinking: An invitation to cognitive science, Cambridge, MA, 1995. MIT
Press.
D. Bailey, J. Feldman, S. Narayanan, and G. Lakoff. Modeling embodied lexical
development. In Proceedings of the Annual Cognitive Science Society, 1997.
K. Bartsch and H. Wellman. Children Talk about the Mind. Oxford University
Press, New York, 1995.
R. Brown. Linguistic determinism and the part of speech. Journal of Abnormal
and Social Psychology, 1957.
S. Carey. Conceptual Change in Childhood. MIT Press, Cambridge, MA, 1985.
N. Chomsky. Aspects of the Theory of Syntax. MIT Press, Cambridge, MA, 1965.
A. M. Collins and M. R. Quillian. Retrieval time from semantic memory. Journal
of Verbal Learning and Verbal Behavior, 8:240–247, 1969.
B. Falkenhainer, K. Forbus, and D. Gentner. The structure-mapping engine: Al-
gorithm and examples. Artificial Intelligence, 41:1–63, 1989.
G. Fauconnier and M. Turner. Conceptual integration networks. Cognitive Sci-
ence, 22(2):133–187, 1998.
C. Fillmore. The case for case. In E. Bach and R. Harms, editors, Universals in
Linguistic Theory, pages 1–90, New York, 1968. Holt, Rinehart and Winston.
C. Fillmore, C. Wooters, and C. Baker. Building a large lexical databank which
provides deep semantics. In Proceedings of the Pacific Asian Conference on
Language, Information and Computation, Hong Kong, 2001.
K. Forbus. Qualitative process theory. Artificial Intelligence, 24:85–168, 1984.
D. Gentner. Why we’re so smart. In D. Gentner and S. Goldin-Meadow, editors,
Language in mind: Advances in the study of language and thought, pages
195–235, Cambridge, MA, 2003. MIT Press.
A. Gopnik, C. Glymour, D. Sobel, L. Schultz, and T. Kushnir. Theory formation
and causal learning in children: Causal maps and bayes nets. Psychological
Review, in press.
A. Gopnik and A. Meltzoff. Words, thoughts and theories. MIT Press, Cam-
bridge, MA, 1997.
J. Hobbs, W. Croft, T. Davies, D. Edwards, and K. Law. Commonsense meta-
physics and lexical semantics. Computational Linguistics, 13:241–250, 1987.
R. S. Jackendoff. Semantics and Cognition. MIT Press, Cambridge, MA, 1983.
R. S. Jackendoff. Foundations of Language. Oxford University Press, Oxford,
2002.
F. Keil. Semantic and Conceptual Development: An Ontological Perspective.
Harvard University Press, Cambridge, MA, 1979.
C. Kennedy and L. McNally. Scale structure and the semantic typology of grad-
able predicates. Language, 2002.
P. Kingsbury, M. Palmer, and M. Marcus. Adding semantic annotation to the penn
treebank. In Proceedings of Human Language Technology Conference, 2002.
B. Kuipers. Qualitative Reasoning. MIT Press., Cambridge, MA, 1994.
B. Landau and L. R. Gleitman. Language and experience: Evidence from the
blind child. Harvard University Press, Cambridge, MA, 1985.
S. Laurence and E. Margolis. Radical concept nativism. Cognition, 86:22–55,
2002.
D. Lenat and D. Guha. Building large knowledge-based systems: Representation
and Inference in the Cyc Project. Addison-Wesley, Reading, MA, 1990.
A. Leslie. How to acquire a representational theory of mind. In D. Sperber,
editor, Metarepresentations: An Multidisciplinary perspective., pages 197–
223, Oxford, 2000. Oxford Press.
B. Levin. English Verb Classes and Alternations: A Preliminary Investigation.
University of Chicago Press, Chicago, IL, 1993.
B. Levin and M. Rappaport-Hovav. Objecthood and object alternations. ms, 2003.
J. Mandler. Foundations of Mind: Origins of Conceptual Thought. Oxford Uni-
versity Press, New York, 2004.
M. McCloskey. Intuitive physics. Scientific American, 248:122–130, 1983.
G. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. Miller. Five papers on
wordnet. International Journal of Lexicology, 3(4), 1990.
M. Minsky. A framework for representing knowledge. In P. Winston, editor, The
psychology of Computer Vision., pages 211–277, New York, 1975. McGraw-
Hill.
N. Nersessian. Comparing historical and intuitive explanations of motion: Does
naive physics have a structure? In Proceedings of the Eleventh Annual Con-
ference of the Cognitive Science Society, pages 412–420, 1989.
S. Niyogi. Aspects of the logical structure of conceptual analysis. Proceedings of
the 27th Annual Meeting of the Cognitive Science Society, 2005.
S. Niyogi. The universal theory model of concepts and the dissolution of the
puzzle of concept acquisition. Proceedings of the 27th Annual Meeting of the
Cognitive Science Society, 2005.
M. Palmer. Putting meaning in your trees. In CoNLL-2004, 2004.
J. Pustejovsky. The Generative Lexicon. MIT Press, Cambridge, MA, 1995.
W. Quine. Word and Object. MIT Press, Cambridge, MA, 1960.
T. Regier. The Human Semantic Potential. MIT Press, Cambridge, MA, 1996.
T. Rogers and J. McClelland. Semantic Cognition: A parallel distributed Pro-
cessing approach. MIT Press, Cambridge, MA, 2004.
D. Roy and Pentland. Learning words from sights and sounds: A computational
model. Cognitive Science, 26:113–146, 2002.
L. Rozenblit and F. Keil. The misunderstood limits of folk science: an illusion of
explanatory depth. Cognitive Science, 26:521–562, 2002.
R. Schank. Conceptual dependency theory. Cognitive Psychology, 3:552–631,
1972.
J. Siskind. A computational study of cross-situational techniques for learning
word-to-meaning mappings. Cognition, 61:39–91, 1996.
V. Slaughter, R. Jaakola, and S. Carey. Constructing a coherent theory: children’s
biological understanding of life and death. In M. Siegel and C. Peterson,
editors, Children’s understanding of biology and health, Cambridge, 1999.
Cambridge University.
V. Slaughter, R. Jaakola, and S. Carey. Constructing a coherent theory: children’s
biological understanding of life and death. In M. Siegel and C. Peterson,
editors, Children’s understanding of biology and health, Cambridge, 1999.
Cambridge University.
C. Yu and Dana H. Ballard (2004) A Unified Model of Early Word Learning:
Integrating Statistical and Social Cues. Proceedings of the 3rd International
Conference on Development and Learning, 2004.
</reference>
<page confidence="0.998965">
99
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001834">
<title confidence="0.999224">Steps Toward Deep Lexical Acquisition</title>
<author confidence="0.957896">Sourabh Niyogi</author>
<affiliation confidence="0.98596">Massachusetts Institute of</affiliation>
<email confidence="0.996099">niyogi@mit.edu</email>
<abstract confidence="0.993142265217392">I describe steps toward “deep lexical acquisition” based on naive theories, motivated by modern results of developmental psychology. I argue that today’s machine learning paradigm is inappropriate to take these steps. Instead we must develop computational accounts of naive theory representations, mechanisms of theory acquisition, and the mapping of naive theories to lexicalizable concepts. This will enable our theories to describe the flexibility of the human conceptual apparatus. 1 Where We Are Now The present Machine Learning Paradigm Much of computational linguistics has converged onto a machine learning paradigm that provides us soothing clarity. The machine learning approach defines a problem as a mapping problem – map some acoustic stream onto a list of word tokens, map a list of word tokens onto a parse tree, map a parse tree onto a set of semantic roles or “logical form”, map each word in a tree onto its best sense, and so on. We then develop a learning algorithm to accomplish the desired mapping. Multiple groups describe how well their algorithm maps various test sets given various training sets, and describe a “result” to improve upon. The clarity provided by this paradigm is so soothing, one gets the sense we can turn a crank, and indeed, in many cases, progress has been made proceeding precisely along these lines. Turning the crank on deep lexical acquisition, however, we might feel something is missing. What is it? Underlying any model of deep lexical acquisiis a theory of the conceptual Unlike our handle on acoustic streams, word lists, and parse trees, our handle on a suitable “output” for the space of word meanings is remarkably poor. Somehow, via experience (of some kind or another), children acquire a mapping from a space of vocabulary items to a space of lexicalizable concepts – the lexicon; our task as modelers is to figure out how this mapping can occur. Many models for the space of lexicalizable concepts exist: concepts are points concepts are Jackendoff’s lexical conceptual structures, concepts are FrameNet’s frame elements, concepts are Schankian script activators, concepts are distributions over syntactic frames, concepts are grounded in sensorimotor statistics, or all of the above. Almost everyone nowadays reports how their algorithm accomplished some mapping to one or more of these models of concepts. They have to, because today’s de facto idea of what constitutes a “result” according the machine learning paradigm today is to do exactly this. The Golden Oldies formed our concept models models of conceptual spaces did originate from computational linguists following the machine learning paradigm. They were proposed from linguists, psychologists and philosophers back in earlier eras what we will call Golden Oldies – when the idea of a “result” was somewhat different. There are too many to recall: Quine (1960) argued that the linguist watching the natives utterthe context of a rabbit would nec- 91 of the Second Workshop on Psychocomputational Models of Human Language pages 91–99, Arbor, June 2005. Association for Computational Linguistics essarily require far more constraints than met the eye. Brown (1957) showed that children used syntactic cues to disambiguate between possible meanings; Landau and Gleitman (1985) followed on these insights, showing just how deep it could be, that blind children could learn basing their mapping on syntactic constraints. Chomsky’s (1965) notion of “deep structure” – proposed to account for commonplace syntactic phenomena – motivated many insights explored in Gruber (1965)’s thesis, Fillmore (1968)’s classical thematic roles, and Jackendoff (1983)’s Lexical conceptual structures. Hale and Keyser and many linguists labored under the MIT Lexicon project in the 1980s to determine the fundamental features of the lexicon; many of these hard-earned observations appear in Levin (1993). Schank (1972)’s Conceptual dependency theory, Minsky (1975)’s Frames were proposed for the broader goals of capturing commonsense knowledge. Quillian’s (1968) and Miller et al (1990)’s WordNet were not intended for models of lexical acquisition or databases to be used in computational linguistics but as models of human semantic memory. Many other Golden Oldies exist, and our debt to them is quite large. Ask what motivates our collection of subcategorization statistics or what drives the quest for semantic roles, and the roots are found in the science questions of the Golden Oldies. The present Myopic Learning Paradigm It would have been extremely myopic to take any one of these classical results and accuse their authors of not demonstrating a learning algorithm, not evaluating them on large corpora, and not getting together in workshops to share the results on test sets. The standard for what constituted a result back then consisted of none of these things, because today’s machine learning paradigm was just not present then. The questions were: • Question (1): What is a lexicalizable concept? • Question (2): How can a word-concept mapping be learned from evidence? But for reasons that no one really talks about, somehow, the standard of what constitutes a result changed from some balance of Question (1) and (2) to a machine learning paradigm essentially focused on Question (2). The dependency between Question (1) and (2) is quite well-understood, but do we have an adequate answer to (1)? We tell ourselves: We’ve gotta build betterparsers, speech recognizers, search engines, machine translation systems, so... let’s take shortcuts on Question (1) so as to make progress on Question (2). For many, that shortcut consists of semantic role labels and learning from frame distributions. These shortcuts don’t answer Question (1), unfortunately. 2 Where We Need to Go While the Golden Oldies were used as the foundations of today’s lexical acquisition, psychology began to sing a new tune, still balancing Questions (1) and (2). Children have naive theories Developmental psychology after the Golden Oldies has shown just how deep our “deep lexical acquisition” theories have to be. On this view, word are couched in changing theories how the world works. The model of the child is that child possesses a naive theory changing state and that there is a space of concepts from substantively different from space of concepts accessible from A learner conceptual Developmental psychology has not been explicit about the preform of nor have they characterized how relates to lexicalizable concepts. But their contributions inform us about the fundamental ingredients of concepts (Question (1)) and inform us what deep lexical acquisition must consist of (Question (2)). A few examples must suffice in place of a review (c.f. Gopnik and Meltzoff (1997)). Keil (1989)’s transformation studies illustrate theory change in the domain of biology. First, children are shown a picture of a skunk; then, are told a story – that the animal received either (A) surgery or (B) a shot in infancy – and then are shown a picture of a raccoon. Young preschool children judge that the animal is a raccoon, as if they base their judgements on superficial features. Children between 7 and 9 (T2) on the other hand, judge that the raccoon-looking in (A) is still a skunk. Adults judge that the raccoon-looking figure in both conditions is a skunk. Apparently, preschoolers’ theory 92 lacks the belief that an animal’s kind is determined birth, but this becomes part of the adult’s preschool children at concept a belief in a continued existence in an alternate location (like sleep); When asked whether dead people dream, eat, defecate, and move, 4 to 6 year olds will say that dead people do all of these, except move (Slaughter et al, 2001). Missing the causes of death (a total breakdown of bodily functions) and that death is an irreversible, inevitable end. Between 4 and 6, children become superficially aware of the general function of various body parts (e.g “You need a heart to live”). Other serve the same point: the child at friendly middle-aged man, and it means parent’s brother. The child at a beachy territory and at thinks it means body of land surrounded by water (Keil 1989). And, “theory of mind” concepts/words as and Bartsch 1995, Leslie 2000) are similarly situated. “theory-like” is subject to considerable debate (diSessa 1993, Leslie 2000). disessa (1993) describes a large number of causal “p-prims” that are highly context specific and considerably larger in number than what Carey (1985) describes; these are shown to apply to everyday physical phenomena – “force as mover”, “vaccuums impel”, “overcoming”, “springiness”, “bigger means lower pitch (or slower)”, to name a few. Each of these have a FrameNet-like causal syntax, of some unknown mapping to vocabulary items. Similarly, Rozenblit and Keil (2003) show that nonexpert adults have a remarkably superficial notion of how common mechanisms work – such as how a helicopter changes from hovering to forward flight. Theories may be suspiciously weak. Students have alternative frameworks psychologists have characterized by asking a different, more practical question: why is it difficult for science students to learn certain sciconcepts when they come to class? The broad insight is this: students come to class not as blank slates but with that must be understood. Data on their pre-conceptions yields clues as to conof well before they walk into science class. Again, a few examples illustrate the point. Many studies on physics misconceptions have observed deeply held views on the motion of projectiles (McCloskey 1983, Halloun and Hestenes 1985). Ask students to predict what happens when a projectile is thrown upward at an angle, and their answers will typically be consistent with one of (a-c) These answers are consistent with an “impetus” theory of motion, where an object’s motion is exclusively dominated by whatever “impetus” the thrower provides it. Medieval scientists such as Buridan also held similar beliefs; Newtonian mechanics, of course, shows that the answer is a parabola. disessa (1993) report a wider array of these types of physics misconceptions in a theoretical framework. Likewise, ask students for their knowledge of how and they reveal an “extramission” belief: something somehow shoots out from the eye and reaches the objects (Winer et al 2002); they also say that eye is the sole organ in the body responsible for vision. Plato and da Vinci shared these same beliefs. Systematic catalogues of these sorts of observations have been compiled for just about every domain – e.g. megaphones create sounds, heat is a substance, eggs are not alive, the moon and sun are the same size, and so forth (AAAS 1993). 3 What Steps We Must Take Consider this fascinating phenomena from the Best of Today and the comfort of the grammar-generatessentence relation will be replaced by queasiness: the and most unclear, as many developmental psychologists freely admit. But computational linguists may contribute significantly to rendering new clarity: If the Golden Oldies drove the efforts on today’s shallow lexical acquisition, the Best of Today’s Psychology may drive the results of tomorrow’s progress in deep lexical acquisition. 93 Generator G (a) of lexicalizable concepts Vocabulary Device OO experience OOOO space of theories (b) // Device //Theory Concept Generator G space of lexicalizable Device theory-based // // experience experience 1: The Model of Concepts from the Golden Oldies: used in the present Machine Learning Paradigm; (b) The Universal Theory Model of Concepts: necessary for deep lexical acquisition The new framework: Universal Theory have much progress to make: We can detheories precisely; we can acquisition occurs; we can map from naive theories to a set of lexicalizable concepts. can vocabulary acquisition occurs. Figure 1(a) shows the Golden Oldies model of concepts that we must abandon: a Vocabulary Acquisition Device receives a fixed hypothesis space of possible concepts completely determined by a fixed set primitives; Figure 1(b) shows the The- Model of Concepts we must take steps to- A Acquisition Device outputs state that describes a learners’s naive theory; A Generator to a set of lexicalconcepts A Acquisition uses learn a lexicon. The of the TAD states is Theory a UT metalanguage enables an abstract characterizaof theories each possible theory describes a system of kinds, attributes, relations, partwhole relations, and causal mechanisms. Within this Theory Model of we can begin to answer the following core questions: 1. what is the initial state of the TAD? 2. what are possible final states of the TAD? 3. how can the TAD change state? how can the TAD use to parse experience? how does the concept generator onto set of lexicalizable concepts how can the VAD use We have made progress on these core questions Many of these questions have been addressed already in computational models where a candidate metalanguage and theory is latent. diSessa (1993) catalogs sets of p-prims in naive physics. Atran (1995) describes a theory of family structure. Gopnik et al (2004) uses Bayesian networks to preschooler’s causal reasoning about McClelland and Rogers (2004) describe connectionist models of some of Carey (1985)’s classic results. In my own work, I have been situating the elements of the Universal Theory Model of Concepts in a microgenesis study, where adult subjects undergo (Niyogi 2005). The transition can be understood with a minimal UT metalanguage to characterize a set of possible theories: is characterized by a interrelated sets of kinds, atrelations, and causal laws. described in that UT metalanguage, and the simplest generator described that mechanically Subjects undergo theory change in a Blocksworld uni- (see Figure 2(a)) while learning 3 verbs that refer to the causal mechanisms governing the universe. Subjects interact with a set of 29 blocks, some of which activate other blocks on contact. On activation, subjects are shown a transiverb frame (“Z is “U is is in a Word Cue Area. Unbeknownst subjects, each block belongs to 1 of 4 kinds and 3 activation mechanisms exist between activate activate activate each of the 3 verbs refers to one the 3 mechanisms. Subjects are probed for the naming conditions on each of the 3 verbs. Subjects’ responses indicate that their TAD state from = is 1 kind of block by 1 causal mechanism to = 94 (a) (b) 2: Subjects try to learn the laws and word meanings in a “Causal Blocksworld” computer application by dragging and blocks onto each other. Cues to the meaning of 3 verbs are given in a Word Cue Area. Shown is how kinds of subjects – and – clustered the blocks; the clusters for the kinds are for but no such differentiation is apparent for (b) When = all 3 verbs can only be mapped a single concept in = arrows); When = be mapped to 3 arrows). (there are 4 kinds of blocks governed by 3 distinct mechanisms, But this is not true for all subjects: some remain “T1 subjects” while others move onto become “T2 sub- Critically, when = the verbs can only mapped to a single concept in = = the verbs can be mapped to 3 disconcepts in = Figure Once = subjects can “parse” the activation and infer the hidden kind and causal mechanism involved. Critically, subjects cannot learn to the 3 verbs until = when the new concepts emerge in Then be mapped onto those 3 new concepts. These verbs are thus theory-laden in the same way UT architecture concretely Puzzle of Concept Acquisition (Laurence and Margolis 2002): how can a person ever acquire a “new” concept, when a fixed set of primitives exhaustively span the space of possible concepts? Taking the viewpoint of the learner’s VAD at a specific moment time with a it has access to in acquisition of a new concept possible if changes. Taking the viewpoint of learner’s all possible times, the has access to the all possible TAD states – thus a “new” concept for the species is impossible. Which viewpoint one takes is a matter of perspective. Critically, the Golden Oldies model of concepts does not expose the TAD state revealed in the UT model of concepts (Fig. 1a,b). Universal Theory and the Linguistic Analogy Computational linguists can progress on these questions, because naive theories are like grammars. Just as a grammar generates a set of possible a theory generates a set of possible worlds. Just as the space of possible grammars is restricted, so is the space of possible theories. Just as learning a grammar consists of picking a point from a space of possible grammars, learning a theory consists of picking a point from the space of possible theories. The task of writing a naive theory is like writing a grammar. The task of characterizing the space of possible theories requires a theory metalanguage just as characterizing the space of possible grammars requires a grammar metalanguage. Moreover, research into naive theories does not the program of research in grammar. The two programs are bridged by the congenerator generates a set of lexiconcepts. An adequate account of generate concepts present in a particular language, every language, and for every possible Miller et al (1990) distinguish between a conand a differential lexicon. In a theory of the lexicon, meanings can be represented by any symbols that enable a theorist to distinguish them; In a theory the lexicon, the representation should “contain sufficient information to support an accurate construction of the concept (by either a person or a machine)”. 95 The conceptual analyst who desires to produce a of the lexicon has four kinds of accounts to provide: (see Niyogi 2005) • an explanatory account of the space of possible theories, for all persons P • an explanatory account of the space of possible concepts, for all persons P, for all possible theories a descriptive account of a specific theory held by a representative person P (e.g. of a 3year old or of a 10-year old) a descriptive account of a specific lexicon held by a representative person P (e.g. a 3year old Chinese speaker, 3-year old English speaker, 10-year old Chinese speaker, 10-year old Chinese speaker) We may envision a “theory-based lexicon” that capture the state variables in Figure the two descriptive accounts above: (1) for an idealized human; (2) a set of vocabulary items to points in Very limited instances of a theory-based lexicon can be constructed already for subjects at the end of the experiment – such a lexicon has (1) the UT metalan- (2) the mapping in This would be in stark contrast to lexicons such as WordNet and FrameNet. Grounding language in perception is insufficient Many have proposed deep lexical acquisition by “grounding language in perception” (Siskind 1996, Regier 1996, Roy and Pentland 2002, Yu and Ballard 2004), constructing systems that can learn to ute.g. contexts where there are, e.g., three triangles hitting red bananas. Such systems also propose a space of possiconcepts exhausted by a of primitives, as in the Golden Oldies model. The initial state of TAD can explicitly incorporate all attributes and relations but then, the TAD can state to yield new kinds, attributes, relations, and causal mechanisms not present in the initial state, but motivated by the data (see Gopnik and Meltzoff 1997). As such, vague appeal to grounding is insufficient; processes that may work on baextremely challenging to gento kind, wonder, pilk, seb, telescope, uninvented cannot be perceived. Again, developmental psychology provides some insight on what theoretical innovations would be required for a suitable interface to sensorimotor apparatus (c.f. Mandler 2004). Commonsense AI gives UT foundations Primitives well beyond the sensory apparatus have been developed to describe physical systems qualitatively (Regier 1975, Forbus 1984). They us some of the possibilities of what and candidate UT metalanguages may look like (quantity spaces, kinds, attributes, relations, part-whole relations, and causal mechanisms that interrelate sets). Regier (1975)’s description of a toiparticularly close to Rozenblit and Keil Later qualitative AI frameworks of Forbus (1984) and Kuipers (1994) may be applied to McCloskey (1982)’s intuitive physics and disessa’s (1993) p-prims. Except for the work of Hobbs, Pustejovsky and their colleagues, few have mapped commonsense theories onto the lexicon. Similar domain-general elements of naive math and causality are present in the workds of Hobbs et al (1987), Kennedy and McNally (2002)’s degree representations for gradable predicates, Talmy (1988)’s force dynamics, and the quantity spaces of Kuipers (1994) and Forbus (1984). These disparate frameworks provide foundational elements for a UT metalanguage. Shortcuts on UT foundations will not work We must resist the urge to take shortcuts on these foundations. Simply creating slots for foundational phenomena will impede progress. Pustejovsky (1995)’s observations for co-composition have clearly illustrated how much flexibility our insystems must have, e.g. in enjoyed But specifying the telic role of be not constitute an adequate theory – we require constraints that relate to the state space of the human conceptual apparatus. Pustejovsky (1995)’s telic, formal, constituagentive roles may be mapped onto characterization of artifacts, materials, and so on. We require nothing less than absolute conceptual transparency. 96 We must bridge UT to analogy Lakoff and Johnson (1980) and subsequent cognitive linguistics work have catalogued a stunning level of metaphoric usage of language. Lexical exof items such as e.g. Analoilluminate us on theory acquisition couched in terms of conceptual metaphors such as “ideas are light”. Significant steps have been taken to model analogical mapping (c.f. Falkenhainer et al 1989, Bailey et al 1997) and conceptual blending (Fauconnier and Turner 1998). These processes may motivate TAD state changes. In most cases, the the underlying predicates in the source and target domains are ad hocly constructed; a natural source of these may be the sets internal to (kinds, attributes, relations, causal mechanisms); similarity between domains may be determined by the strucproperties of the UT metalanguage and If the common causal mechanisms behind ideas and light transmission, for example, then one may strive for a shorter lexicon where the voitem to be used in both domains with “one” core entry. An adequate theory of this process would obviously reduce the number of so called “senses” in word sense disambiguation. 4 What We Assumed Wrong Modern computational linguistics appears to have made a set of assumptions that deserve reanalysis, given the availability of other options. Assumption: A fixed alphabet of meaning components exists, and we know what it is A key assumption dating to the Golden Oldies is that the meaning of a sentence is adequately captured by a “logical form” (LF) characterized by a alphabet meaning components (e.g. thematic roles, lexical semantic primitives, conceptual dependency primitives). Today’s computational linguistics program uses this assumption to demonstrate systems that answer “who did what to whom, why, . questions, given sentences like: John saw the man with the telescope. John hit the man with the umbrella. Is the computational linguist is expected to be satwhen systems can answer saw the man the telescope? did John hit with the umyear’s CoNLL Shared Task, mapping sentences onto semantic roles, assumes the above. But try these: Does John have eyes? Were they ever open when he was looking through the telescope? Could John know whether the man was wearing underwear? Did the umbrella move? Did John move? Did the man feel anything when he was hit? Was John alive? Was the man alive? Why would John need a telescope to see the man, when he has eyes? Why would John use an umbrella when his hands would do? Something is missing in these systems. We should be more accountable. Developmental psychology showed that theory change and conceptual change is possible, proving this assumption the alphabet behind sentence meaning a of lexicalizable concepts Missing in today’s systems attaching AGENT (or Perceiver passive, or Impactor) to INSTRUMENT to a mapping of the lexical items to What contain, in some as yet unknown form, is a T of physics described by McCloskey and disessa (1993), a T of vision studied by Landau and Gleitman (1985) and Winer et al (2002), a T of body studied by Carey (1985), a T of materials and artifacts studied by Hobbs et al (1987) and Pustejovsky This when mapped via forms the alphabet of the above 2 sentences. Assumption: The machine learning paradigm can treat deep lexical acquisition. If we reject the assumption that there is some “meaning” of a sentence spanned by a set of meaning primitives, the soothing clarity of the machine learning paradigm is no longer available. We cannot map parse trees onto sentence meanings. The possibility of “Putting Meaning in Your Trees” (Palmer 2004) completely disappears. We may still use the machine learning paradigm to parse, disambiguate and recognize speech. But these results are of little use to model theory, concept and lexical acquisition, because there is no output representation where a suitable training set could be collected. The human conceptual apparatus is not that simple: the VAD rechanges, as changes), and need explanatory accounts of UT and G, and must recognize the diverse ways the TAD may change state. 97 Assumption: Paths from shallow to deep lexical acquisition exist The Golden Oldies Models of concepts (Figure 1a) and the Universal Theory models of concepts 1b) are The path from the shallow to the deep cannot be declared to exist by fiat. Wishful thinking is inappropriate, because one architecture is more powerful than the other: the Golden Oldies model did not expose the TAD state space. Instead, lexical semantics results obtained under the Golden Oldies model require translation into the UT model: the privileged position syntactic positions that motivated thematic roles and lexical semantics primitives, the bi-partite event structure revealed through adverbial modification, and so on. translation is mediated in and will not yield a notational variant of what we started with. Assumption: Verb classes determine meanings We must distinguish between a representation of meanings by distribution of frames and by frames. Landau and Gleitman (1990) showed that verb’s parin some frames but not others are that a child uses to constrain verb meaning. Levin and Rappaport-Hovav (1998) explicitly distinguish of meaning. But neither claim that verb classes or statistical of subcategorization frames verb meaning. Yet VerbNet maps verbs to predicates in precisely this way: (Kingsbury et al 2002). Verbs of Inalienable Possession cause(Agent,E) location(start(E),Theme,Source) Verbs of Social Interaction distinction between or between not astonishing to the English speaker. Causal mechanisms behind disease, possession, and the marital practices that were labeled the lexical semanticist must be capin Assumption: Language is separate from general systems of knowledge and belief This “defining” assumption helped for the Golden Oldies, but innovations in developmental psychology motivate dropping this assumption. The bridge provided by the concept generator it maps a theory (general systems of knowledge and to used by the VAD (language). Assumption: Real-world knowledge is Bad The absence of the soothing clarity of the machine learning paradigm and presence of real world knowlin brings forth 2 associations: Early Schank/Cyc = Much Knowledge = UT research = Bad Statistics = Little Knowledge = shallow semantics = Good The associations lead to the inference that Universal Theory research will suffer a similar fate as the 70s Schankian program and the Cyc program (Schank 1972, Lenat and Guha 1990). However, this inference is incorrect. The 70s Schankian program and Cyc efforts did not carefully consider the constraints of syntactic phenomena or developmental psychology. Schank and his colleagues stimulated research in qualitative physics and explanation-based learning that addressed many of these deficiencies, but there is much work to be done to bridge today’s efforts in deep lexical acquisition to this. Assumption: Others will provide us the answers Lexical semanticists now rely on cognitive explanations far more heavily than ever before. Jackendoff (2002) concludes: “someone has to study all these subtle frameworks of meaning so why not linguists?” Levin and Rappaport-Hovav (2003), denominal verbs such as butnow freely point to “general cognitive principles” rather than situate knowledge in the lexicon. Rather than consume lexical semantics of the Golden Oldies, we can draw upon our toolbox to again answer Question (1): “what is a lexicalizable concept?” 5 We Must Change Our Concepts Stop working with models of concepts from the Golden Oldies. Start questioning whether results the machine learning paradigm are really re- Change your concept of a Learn how children do theory, concept and vocabulary acquisition. Expose the fundamental ingredients of con- Change your concept of Change your of Radical conceptual change is possible. Write some new songs, and sing some new tunes. We can have some Great Golden Oldies of Tomorrow.</abstract>
<note confidence="0.926838755102041">98 References S. Atran. Classifying nature across cultures. In E. Smith and D. Osherson, edi- An invitation to cognitive Cambridge, MA, 1995. MIT Press. D. Bailey, J. Feldman, S. Narayanan, and G. Lakoff. Modeling embodied lexical In of the Annual Cognitive Science 1997. Bartsch and H. Wellman. Talk about the Oxford University Press, New York, 1995. Brown. Linguistic determinism and the part of speech. of Abnormal Social 1957. Carey. Change in MIT Press, Cambridge, MA, 1985. Chomsky. of the Theory of MIT Press, Cambridge, MA, 1965. M. Collins and M. R. Quillian. Retrieval time from semantic memory. Verbal Learning and Verbal 8:240–247, 1969. B. Falkenhainer, K. Forbus, and D. Gentner. The structure-mapping engine: Aland examples. 41:1–63, 1989. Fauconnier and M. Turner. Conceptual integration networks. Sci- 22(2):133–187, 1998. Fillmore. The case for case. In E. Bach and R. Harms, editors, in pages 1–90, New York, 1968. Holt, Rinehart and Winston. C. Fillmore, C. Wooters, and C. Baker. Building a large lexical databank which deep semantics. In of the Pacific Asian Conference on Information and Hong Kong, 2001. Forbus. Qualitative process theory. 24:85–168, 1984. D. Gentner. Why we’re so smart. In D. Gentner and S. Goldin-Meadow, editors, in mind: Advances in the study of language and pages 195–235, Cambridge, MA, 2003. MIT Press. A. Gopnik, C. Glymour, D. Sobel, L. Schultz, and T. Kushnir. Theory formation causal learning in children: Causal maps and bayes nets. in press. Gopnik and A. Meltzoff. thoughts and MIT Press, Cambridge, MA, 1997. J. Hobbs, W. Croft, T. Davies, D. Edwards, and K. Law. Commonsense metaand lexical semantics. 13:241–250, 1987. S. Jackendoff. and MIT Press, Cambridge, MA, 1983. S. Jackendoff. of Oxford University Press, Oxford, 2002. Keil. and Conceptual Development: An Ontological Harvard University Press, Cambridge, MA, 1979. C. Kennedy and L. McNally. Scale structure and the semantic typology of gradpredicates. 2002. P. Kingsbury, M. Palmer, and M. Marcus. Adding semantic annotation to the penn In of Human Language Technology 2002. Kuipers. MIT Press., Cambridge, MA, 1994. Landau and L. R. Gleitman. and experience: Evidence from the Harvard University Press, Cambridge, MA, 1985. Laurence and E. Margolis. Radical concept nativism. 86:22–55, 2002. Lenat and D. Guha. large knowledge-based systems: Representation Inference in the Cyc Addison-Wesley, Reading, MA, 1990. A. Leslie. How to acquire a representational theory of mind. In D. Sperber, An Multidisciplinary pages 197– 223, Oxford, 2000. Oxford Press. Levin. Verb Classes and Alternations: A Preliminary University of Chicago Press, Chicago, IL, 1993. Levin and M. Rappaport-Hovav. Objecthood and object alternations. 2003. Mandler. of Mind: Origins of Conceptual Oxford University Press, New York, 2004. McCloskey. Intuitive physics. 248:122–130, 1983. G. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. Miller. Five papers on Journal of 3(4), 1990. Minsky. A framework for representing knowledge. In P. Winston, editor, of Computer pages 211–277, New York, 1975. McGraw- Hill. N. Nersessian. Comparing historical and intuitive explanations of motion: Does physics have a structure? In of the Eleventh Annual Conof the Cognitive Science pages 412–420, 1989. Niyogi. Aspects of the logical structure of conceptual analysis. of 27th Annual Meeting of the Cognitive Science 2005. S. Niyogi. The universal theory model of concepts and the dissolution of the of concept acquisition. of the 27th Annual Meeting of the Science 2005. Palmer. Putting meaning in your trees. In 2004. Pustejovsky. Generative MIT Press, Cambridge, MA, 1995. Quine. and MIT Press, Cambridge, MA, 1960. Regier. Human Semantic MIT Press, Cambridge, MA, 1996. Rogers and J. McClelland. Cognition: A parallel distributed Pro- MIT Press, Cambridge, MA, 2004. D. Roy and Pentland. Learning words from sights and sounds: A computational 26:113–146, 2002. L. Rozenblit and F. Keil. The misunderstood limits of folk science: an illusion of depth. 26:521–562, 2002. Schank. Conceptual dependency theory. 3:552–631, 1972. J. Siskind. A computational study of cross-situational techniques for learning mappings. 61:39–91, 1996. V. Slaughter, R. Jaakola, and S. Carey. Constructing a coherent theory: children’s biological understanding of life and death. In M. Siegel and C. Peterson, understanding of biology and Cambridge, 1999. Cambridge University. V. Slaughter, R. Jaakola, and S. Carey. Constructing a coherent theory: children’s biological understanding of life and death. In M. Siegel and C. Peterson, understanding of biology and Cambridge, 1999. Cambridge University. C. Yu and Dana H. Ballard (2004) A Unified Model of Early Word Learning: Statistical and Social Cues. of the 3rd International on Development and 2004.</note>
<intro confidence="0.610139">99</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Atran</author>
</authors>
<title>Classifying nature across cultures.</title>
<date>1995</date>
<editor>In E. Smith and D. Osherson, editors,</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="14190" citStr="Atran (1995)" startWordPosition="2321" endWordPosition="2322">eory Model of Concepts, we can begin to answer the following core questions: 1. what is the initial state of the TAD? 2. what are possible final states of the TAD? 3. how can the TAD change state? 4. how can the TAD use T* to parse experience? 5. how does the concept generator G map T* onto a set of lexicalizable concepts G(T*)? 6. how can the VAD use G(T*)? We have made progress on these core questions Many of these questions have been addressed already in computational models where a candidate UT metalanguage and theory T* is latent. diSessa (1993) catalogs sets of p-prims in naive physics. Atran (1995) describes a theory of family structure. Gopnik et al (2004) uses Bayesian networks to model preschooler’s causal reasoning about blickets. McClelland and Rogers (2004) describe connectionist models of some of Carey (1985)’s classic results. In my own work, I have been situating the elements of the Universal Theory Model of Concepts in a microgenesis study, where adult subjects undergo a T1 to T2 transition (Niyogi 2005). The transition can be understood with a minimal UT metalanguage needed to characterize a set of possible theories: T* is characterized by a interrelated sets of kinds, attrib</context>
</contexts>
<marker>Atran, 1995</marker>
<rawString>S. Atran. Classifying nature across cultures. In E. Smith and D. Osherson, editors, Thinking: An invitation to cognitive science, Cambridge, MA, 1995. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bailey</author>
<author>J Feldman</author>
<author>S Narayanan</author>
<author>G Lakoff</author>
</authors>
<title>Modeling embodied lexical development.</title>
<date>1997</date>
<booktitle>In Proceedings of the Annual Cognitive Science Society,</booktitle>
<contexts>
<context position="24431" citStr="Bailey et al 1997" startWordPosition="4056" endWordPosition="4059">onstitutive, agentive roles may be mapped onto T*’s characterization of artifacts, materials, and so on. We require nothing less than absolute conceptual transparency. 96 We must bridge UT to analogy Lakoff and Johnson (1980) and subsequent cognitive linguistics work have catalogued a stunning level of metaphoric usage of language. Lexical extension of items such as illuminate in, e.g. Analogies illuminate us on theory acquisition are couched in terms of conceptual metaphors such as “ideas are light”. Significant steps have been taken to model analogical mapping (c.f. Falkenhainer et al 1989, Bailey et al 1997) and conceptual blending (Fauconnier and Turner 1998). These processes may motivate TAD state changes. In most cases, the the underlying predicates in the source and target domains are ad hocly constructed; a natural source of these predicates may be the sets internal to T* (kinds, attributes, relations, causal mechanisms); similarity between domains may be determined by the structural properties of the UT metalanguage and G. If T* incorporates the common causal mechanisms behind ideas and light transmission, for example, then one may strive for a shorter lexicon where the vocabulary item illu</context>
</contexts>
<marker>Bailey, Feldman, Narayanan, Lakoff, 1997</marker>
<rawString>D. Bailey, J. Feldman, S. Narayanan, and G. Lakoff. Modeling embodied lexical development. In Proceedings of the Annual Cognitive Science Society, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bartsch</author>
<author>H Wellman</author>
</authors>
<title>Children Talk about the Mind.</title>
<date>1995</date>
<publisher>Oxford University Press,</publisher>
<location>New York,</location>
<marker>Bartsch, Wellman, 1995</marker>
<rawString>K. Bartsch and H. Wellman. Children Talk about the Mind. Oxford University Press, New York, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Brown</author>
</authors>
<title>Linguistic determinism and the part of speech.</title>
<date>1957</date>
<journal>Journal of Abnormal and Social Psychology,</journal>
<contexts>
<context position="3391" citStr="Brown (1957)" startWordPosition="545" endWordPosition="546">s following the machine learning paradigm. They were proposed from linguists, psychologists and philosophers back in earlier eras - what we will call Golden Oldies – when the idea of a “result” was somewhat different. There are too many to recall: Quine (1960) argued that the linguist watching the natives uttering Gavagai! in the context of a rabbit would nec91 Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 91–99, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics essarily require far more constraints than met the eye. Brown (1957) showed that children used syntactic cues to disambiguate between possible meanings; Landau and Gleitman (1985) followed on these insights, showing just how deep it could be, that even blind children could learn look and see, basing their mapping on syntactic constraints. Chomsky’s (1965) notion of “deep structure” – proposed to account for commonplace syntactic phenomena – motivated many insights explored in Gruber (1965)’s thesis, Fillmore (1968)’s classical thematic roles, and Jackendoff (1983)’s Lexical conceptual structures. Hale and Keyser and many linguists labored under the MIT Lexicon</context>
</contexts>
<marker>Brown, 1957</marker>
<rawString>R. Brown. Linguistic determinism and the part of speech. Journal of Abnormal and Social Psychology, 1957.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Carey</author>
</authors>
<title>Conceptual Change in Childhood.</title>
<date>1985</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="9059" citStr="Carey (1985)" startWordPosition="1484" endWordPosition="1485">hild at T1 thinks uncle means friendly middle-aged man, and at T2 thinks it means parent’s brother. The child at T1 thinks island means a beachy territory and at T2 thinks it means body of land surrounded by water (Keil 1989). And, “theory of mind” concepts/words such as belief, desire, wonder, pretend (Wellman and Bartsch 1995, Leslie 2000) are similarly situated. How “theory-like” T1 and T2 are is subject to considerable debate (diSessa 1993, Leslie 2000). disessa (1993) describes a large number of causal “p-prims” that are highly context specific and considerably larger in number than what Carey (1985) describes; these are shown to apply to everyday physical phenomena – “force as mover”, “vaccuums impel”, “overcoming”, “springiness”, “bigger means lower pitch (or slower)”, to name a few. Each of these have a FrameNet-like causal syntax, of some unknown mapping to vocabulary items. Similarly, Rozenblit and Keil (2003) show that nonexpert adults have a remarkably superficial notion of how common mechanisms work – such as how a helicopter changes from hovering to forward flight. Theories may be suspiciously weak. Students have alternative frameworks Educational psychologists have characterized</context>
<context position="14412" citStr="Carey (1985)" startWordPosition="2355" endWordPosition="2356"> to parse experience? 5. how does the concept generator G map T* onto a set of lexicalizable concepts G(T*)? 6. how can the VAD use G(T*)? We have made progress on these core questions Many of these questions have been addressed already in computational models where a candidate UT metalanguage and theory T* is latent. diSessa (1993) catalogs sets of p-prims in naive physics. Atran (1995) describes a theory of family structure. Gopnik et al (2004) uses Bayesian networks to model preschooler’s causal reasoning about blickets. McClelland and Rogers (2004) describe connectionist models of some of Carey (1985)’s classic results. In my own work, I have been situating the elements of the Universal Theory Model of Concepts in a microgenesis study, where adult subjects undergo a T1 to T2 transition (Niyogi 2005). The transition can be understood with a minimal UT metalanguage needed to characterize a set of possible theories: T* is characterized by a interrelated sets of kinds, attributes, relations, and causal laws. T1 and T2 are described in that UT metalanguage, and the simplest concept generator G is described that mechanically maps T1 and T2 onto G(T1) and G(T2). Subjects undergo theory change in </context>
<context position="27308" citStr="Carey (1985)" startWordPosition="4548" endWordPosition="4549">ntal psychology showed that theory change and conceptual change is possible, proving this assumption is wrong: the alphabet behind sentence meaning is a varying set of lexicalizable concepts G(T*). Missing in today’s systems attaching AGENT (or FrameNet’s Perceiver passive, or Impactor) to John and INSTRUMENT to umbrella and telescope is T*, and a mapping of the lexical items to G(T*). What T* must contain, in some as yet unknown form, is a T of physics described by McCloskey and disessa (1993), a T of vision studied by Landau and Gleitman (1985) and Winer et al (2002), a T of body studied by Carey (1985), a T of materials and artifacts studied by Hobbs et al (1987) and Pustejovsky (1995). This T*, when mapped via G, forms the alphabet of the above 2 sentences. Assumption: The machine learning paradigm can treat deep lexical acquisition. If we reject the assumption that there is some “meaning” of a sentence spanned by a set of meaning primitives, the soothing clarity of the machine learning paradigm is no longer available. We cannot map parse trees onto sentence meanings. The possibility of “Putting Meaning in Your Trees” (Palmer 2004) completely disappears. We may still use the machine learni</context>
</contexts>
<marker>Carey, 1985</marker>
<rawString>S. Carey. Conceptual Change in Childhood. MIT Press, Cambridge, MA, 1985. N. Chomsky. Aspects of the Theory of Syntax. MIT Press, Cambridge, MA, 1965.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Collins</author>
<author>M R Quillian</author>
</authors>
<title>Retrieval time from semantic memory.</title>
<date>1969</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<volume>8</volume>
<marker>Collins, Quillian, 1969</marker>
<rawString>A. M. Collins and M. R. Quillian. Retrieval time from semantic memory. Journal of Verbal Learning and Verbal Behavior, 8:240–247, 1969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Falkenhainer</author>
<author>K Forbus</author>
<author>D Gentner</author>
</authors>
<title>The structure-mapping engine: Algorithm and examples.</title>
<date>1989</date>
<journal>Artificial Intelligence,</journal>
<volume>41</volume>
<contexts>
<context position="24411" citStr="Falkenhainer et al 1989" startWordPosition="4052" endWordPosition="4055">(1995)’s telic, formal, constitutive, agentive roles may be mapped onto T*’s characterization of artifacts, materials, and so on. We require nothing less than absolute conceptual transparency. 96 We must bridge UT to analogy Lakoff and Johnson (1980) and subsequent cognitive linguistics work have catalogued a stunning level of metaphoric usage of language. Lexical extension of items such as illuminate in, e.g. Analogies illuminate us on theory acquisition are couched in terms of conceptual metaphors such as “ideas are light”. Significant steps have been taken to model analogical mapping (c.f. Falkenhainer et al 1989, Bailey et al 1997) and conceptual blending (Fauconnier and Turner 1998). These processes may motivate TAD state changes. In most cases, the the underlying predicates in the source and target domains are ad hocly constructed; a natural source of these predicates may be the sets internal to T* (kinds, attributes, relations, causal mechanisms); similarity between domains may be determined by the structural properties of the UT metalanguage and G. If T* incorporates the common causal mechanisms behind ideas and light transmission, for example, then one may strive for a shorter lexicon where the </context>
</contexts>
<marker>Falkenhainer, Forbus, Gentner, 1989</marker>
<rawString>B. Falkenhainer, K. Forbus, and D. Gentner. The structure-mapping engine: Algorithm and examples. Artificial Intelligence, 41:1–63, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Fauconnier</author>
<author>M Turner</author>
</authors>
<title>Conceptual integration networks.</title>
<date>1998</date>
<journal>Cognitive Science,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="24484" citStr="Fauconnier and Turner 1998" startWordPosition="4063" endWordPosition="4067">to T*’s characterization of artifacts, materials, and so on. We require nothing less than absolute conceptual transparency. 96 We must bridge UT to analogy Lakoff and Johnson (1980) and subsequent cognitive linguistics work have catalogued a stunning level of metaphoric usage of language. Lexical extension of items such as illuminate in, e.g. Analogies illuminate us on theory acquisition are couched in terms of conceptual metaphors such as “ideas are light”. Significant steps have been taken to model analogical mapping (c.f. Falkenhainer et al 1989, Bailey et al 1997) and conceptual blending (Fauconnier and Turner 1998). These processes may motivate TAD state changes. In most cases, the the underlying predicates in the source and target domains are ad hocly constructed; a natural source of these predicates may be the sets internal to T* (kinds, attributes, relations, causal mechanisms); similarity between domains may be determined by the structural properties of the UT metalanguage and G. If T* incorporates the common causal mechanisms behind ideas and light transmission, for example, then one may strive for a shorter lexicon where the vocabulary item illuminate happens to be used in both domains with “one” </context>
</contexts>
<marker>Fauconnier, Turner, 1998</marker>
<rawString>G. Fauconnier and M. Turner. Conceptual integration networks. Cognitive Science, 22(2):133–187, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
</authors>
<title>The case for case.</title>
<date>1968</date>
<booktitle>Universals in Linguistic Theory,</booktitle>
<pages>1--90</pages>
<editor>In E. Bach and R. Harms, editors,</editor>
<location>New York,</location>
<contexts>
<context position="3843" citStr="Fillmore (1968)" startWordPosition="615" endWordPosition="616">quisition, pages 91–99, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics essarily require far more constraints than met the eye. Brown (1957) showed that children used syntactic cues to disambiguate between possible meanings; Landau and Gleitman (1985) followed on these insights, showing just how deep it could be, that even blind children could learn look and see, basing their mapping on syntactic constraints. Chomsky’s (1965) notion of “deep structure” – proposed to account for commonplace syntactic phenomena – motivated many insights explored in Gruber (1965)’s thesis, Fillmore (1968)’s classical thematic roles, and Jackendoff (1983)’s Lexical conceptual structures. Hale and Keyser and many linguists labored under the MIT Lexicon project in the 1980s to determine the fundamental features of the lexicon; many of these hard-earned observations appear in Levin (1993). Schank (1972)’s Conceptual dependency theory, Minsky (1975)’s Frames were proposed for the broader goals of capturing commonsense knowledge. Quillian’s (1968) and Miller et al (1990)’s WordNet were not intended for models of lexical acquisition or databases to be used in computational linguistics but as models o</context>
</contexts>
<marker>Fillmore, 1968</marker>
<rawString>C. Fillmore. The case for case. In E. Bach and R. Harms, editors, Universals in Linguistic Theory, pages 1–90, New York, 1968. Holt, Rinehart and Winston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
<author>C Wooters</author>
<author>C Baker</author>
</authors>
<title>Building a large lexical databank which provides deep semantics.</title>
<date>2001</date>
<journal>Artificial Intelligence,</journal>
<booktitle>In Proceedings of the Pacific Asian Conference on Language, Information and Computation, Hong Kong,</booktitle>
<volume>24</volume>
<marker>Fillmore, Wooters, Baker, 2001</marker>
<rawString>C. Fillmore, C. Wooters, and C. Baker. Building a large lexical databank which provides deep semantics. In Proceedings of the Pacific Asian Conference on Language, Information and Computation, Hong Kong, 2001. K. Forbus. Qualitative process theory. Artificial Intelligence, 24:85–168, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gentner</author>
</authors>
<title>Why we’re so smart. In</title>
<date>2003</date>
<booktitle>Language in mind: Advances in the study of language and thought,</booktitle>
<pages>195--235</pages>
<editor>D. Gentner and S. Goldin-Meadow, editors,</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA,</location>
<marker>Gentner, 2003</marker>
<rawString>D. Gentner. Why we’re so smart. In D. Gentner and S. Goldin-Meadow, editors, Language in mind: Advances in the study of language and thought, pages 195–235, Cambridge, MA, 2003. MIT Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Gopnik</author>
<author>C Glymour</author>
<author>D Sobel</author>
<author>L Schultz</author>
<author>T Kushnir</author>
</authors>
<title>Theory formation and causal learning in children: Causal maps and bayes nets. Psychological Review,</title>
<note>in press.</note>
<marker>Gopnik, Glymour, Sobel, Schultz, Kushnir, </marker>
<rawString>A. Gopnik, C. Glymour, D. Sobel, L. Schultz, and T. Kushnir. Theory formation and causal learning in children: Causal maps and bayes nets. Psychological Review, in press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gopnik</author>
<author>A Meltzoff</author>
</authors>
<title>Words, thoughts and theories.</title>
<date>1997</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="7102" citStr="Gopnik and Meltzoff (1997)" startWordPosition="1143" endWordPosition="1146"> naive theory T* changing state from T1 to T2, and that there is a space of concepts accessible from T1 that substantively different from the space of concepts accessible from T2. A learner undergoes radical conceptual change. Developmental psychology has not been explicit about the precise form of T*, nor have they characterized how T* relates to lexicalizable concepts. But their contributions inform us about the fundamental ingredients of concepts (Question (1)) and inform us what deep lexical acquisition must consist of (Question (2)). A few examples must suffice in place of a review (c.f. Gopnik and Meltzoff (1997)). Keil (1989)’s transformation studies illustrate theory change in the domain of biology. First, children are shown a picture of a skunk; then, are told a story – that the animal received either (A) surgery or (B) a shot in infancy – and then are shown a picture of a raccoon. Young preschool children judge that the animal is a raccoon, as if they base their judgements on superficial features. Children between 7 and 9 (T2) on the other hand, judge that the raccoon-looking figure in (A) is still a skunk. Adults (T3) judge that the raccoon-looking figure in both conditions is still a skunk. Appa</context>
<context position="21658" citStr="Gopnik and Meltzoff 1997" startWordPosition="3632" endWordPosition="3635">nd Ballard 2004), constructing systems that can learn to utter, e.g. red, banana, hit and triangle in contexts where there are, e.g., three triangles hitting red bananas. Such systems also propose a space of possible concepts exhausted by a fixed set of primitives, as in the Golden Oldies model. The initial state of the TAD (T*(t = 0)) can explicitly incorporate all these attributes and relations (contact, luminance, ...); but then, the TAD can further change state to yield new kinds, attributes, relations, and causal mechanisms not present in the initial state, but motivated by the data (see Gopnik and Meltzoff 1997). As such, vague appeal to grounding is insufficient; associative processes that may work on red, hit, banana, eye, three are extremely challenging to generalize to color, kind, wonder, pilk, seb, telescope, maybe and uninvented groobles that cannot be perceived. Again, developmental psychology provides some insight on what theoretical innovations would be required for a suitable interface to sensorimotor apparatus (c.f. Mandler 2004). Commonsense AI gives UT foundations Primitives well beyond the sensory apparatus have been developed to describe physical systems qualitatively (Regier 1975, Fo</context>
</contexts>
<marker>Gopnik, Meltzoff, 1997</marker>
<rawString>A. Gopnik and A. Meltzoff. Words, thoughts and theories. MIT Press, Cambridge, MA, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
<author>W Croft</author>
<author>T Davies</author>
<author>D Edwards</author>
<author>K Law</author>
</authors>
<title>Commonsense metaphysics and lexical semantics.</title>
<date>1987</date>
<journal>Computational Linguistics,</journal>
<volume>13</volume>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="22976" citStr="Hobbs et al (1987)" startWordPosition="3827" endWordPosition="3830">k like (quantity spaces, kinds, attributes, relations, part-whole relations, and causal mechanisms that interrelate these sets). Regier (1975)’s description of a toilet appears particularly close to Rozenblit and Keil (2003)’s helicopter. Later qualitative AI frameworks of Forbus (1984) and Kuipers (1994) may be applied to McCloskey (1982)’s intuitive physics and disessa’s (1993) p-prims. Except for the work of Hobbs, Pustejovsky and their colleagues, few have mapped commonsense theories onto the lexicon. Similar domain-general elements of naive math and causality are present in the workds of Hobbs et al (1987), Kennedy and McNally (2002)’s degree representations for gradable predicates, Talmy (1988)’s force dynamics, and the quantity spaces of Kuipers (1994) and Forbus (1984). These disparate frameworks provide foundational elements for a UT metalanguage. Shortcuts on UT foundations will not work We must resist the urge to take shortcuts on these foundations. Simply creating slots for foundational phenomena will impede progress. Pustejovsky (1995)’s observations for co-composition have clearly illustrated how much flexibility our interpretation systems must have, e.g. in He enjoyed the beer/movie. </context>
<context position="27370" citStr="Hobbs et al (1987)" startWordPosition="4559" endWordPosition="4562"> change is possible, proving this assumption is wrong: the alphabet behind sentence meaning is a varying set of lexicalizable concepts G(T*). Missing in today’s systems attaching AGENT (or FrameNet’s Perceiver passive, or Impactor) to John and INSTRUMENT to umbrella and telescope is T*, and a mapping of the lexical items to G(T*). What T* must contain, in some as yet unknown form, is a T of physics described by McCloskey and disessa (1993), a T of vision studied by Landau and Gleitman (1985) and Winer et al (2002), a T of body studied by Carey (1985), a T of materials and artifacts studied by Hobbs et al (1987) and Pustejovsky (1995). This T*, when mapped via G, forms the alphabet of the above 2 sentences. Assumption: The machine learning paradigm can treat deep lexical acquisition. If we reject the assumption that there is some “meaning” of a sentence spanned by a set of meaning primitives, the soothing clarity of the machine learning paradigm is no longer available. We cannot map parse trees onto sentence meanings. The possibility of “Putting Meaning in Your Trees” (Palmer 2004) completely disappears. We may still use the machine learning paradigm to parse, disambiguate and recognize speech. But t</context>
</contexts>
<marker>Hobbs, Croft, Davies, Edwards, Law, 1987</marker>
<rawString>J. Hobbs, W. Croft, T. Davies, D. Edwards, and K. Law. Commonsense metaphysics and lexical semantics. Computational Linguistics, 13:241–250, 1987. R. S. Jackendoff. Semantics and Cognition. MIT Press, Cambridge, MA, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S Jackendoff</author>
</authors>
<title>Foundations of Language.</title>
<date>2002</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford,</location>
<contexts>
<context position="31684" citStr="Jackendoff (2002)" startWordPosition="5228" endWordPosition="5230">yc program (Schank 1972, Lenat and Guha 1990). However, this inference is incorrect. The 70s Schankian program and Cyc efforts did not carefully consider the constraints of syntactic phenomena or developmental psychology. Schank and his colleagues stimulated research in qualitative physics and explanation-based learning that addressed many of these deficiencies, but there is much work to be done to bridge today’s efforts in deep lexical acquisition to this. Assumption: Others will provide us the answers Lexical semanticists now rely on cognitive explanations far more heavily than ever before. Jackendoff (2002) concludes: “someone has to study all these subtle frameworks of meaning - so why not linguists?” Levin and Rappaport-Hovav (2003), addressing denominal verbs such as mop and butter, now freely point to “general cognitive principles” rather than situate knowledge in the lexicon. Rather than consume lexical semantics of the Golden Oldies, we can draw upon our toolbox to again answer Question (1): “what is a lexicalizable concept?” 5 We Must Change Our Concepts Stop working with models of concepts from the Golden Oldies. Start questioning whether results under the machine learning paradigm are r</context>
</contexts>
<marker>Jackendoff, 2002</marker>
<rawString>R. S. Jackendoff. Foundations of Language. Oxford University Press, Oxford, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keil</author>
</authors>
<title>Semantic and Conceptual Development: An Ontological Perspective.</title>
<date>1979</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA,</location>
<marker>Keil, 1979</marker>
<rawString>F. Keil. Semantic and Conceptual Development: An Ontological Perspective. Harvard University Press, Cambridge, MA, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kennedy</author>
<author>L McNally</author>
</authors>
<title>Scale structure and the semantic typology of gradable predicates.</title>
<date>2002</date>
<location>Language,</location>
<contexts>
<context position="23004" citStr="Kennedy and McNally (2002)" startWordPosition="3831" endWordPosition="3834">ces, kinds, attributes, relations, part-whole relations, and causal mechanisms that interrelate these sets). Regier (1975)’s description of a toilet appears particularly close to Rozenblit and Keil (2003)’s helicopter. Later qualitative AI frameworks of Forbus (1984) and Kuipers (1994) may be applied to McCloskey (1982)’s intuitive physics and disessa’s (1993) p-prims. Except for the work of Hobbs, Pustejovsky and their colleagues, few have mapped commonsense theories onto the lexicon. Similar domain-general elements of naive math and causality are present in the workds of Hobbs et al (1987), Kennedy and McNally (2002)’s degree representations for gradable predicates, Talmy (1988)’s force dynamics, and the quantity spaces of Kuipers (1994) and Forbus (1984). These disparate frameworks provide foundational elements for a UT metalanguage. Shortcuts on UT foundations will not work We must resist the urge to take shortcuts on these foundations. Simply creating slots for foundational phenomena will impede progress. Pustejovsky (1995)’s observations for co-composition have clearly illustrated how much flexibility our interpretation systems must have, e.g. in He enjoyed the beer/movie. But specifying the telic rol</context>
</contexts>
<marker>Kennedy, McNally, 2002</marker>
<rawString>C. Kennedy and L. McNally. Scale structure and the semantic typology of gradable predicates. Language, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kingsbury</author>
<author>M Palmer</author>
<author>M Marcus</author>
</authors>
<title>Adding semantic annotation to the penn treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of Human Language Technology Conference,</booktitle>
<publisher>MIT Press.,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="29834" citStr="Kingsbury et al 2002" startWordPosition="4944" endWordPosition="4947">ses determine meanings We must distinguish between a representation of verb meanings determined by the distribution of subcategorization frames and cued by these frames. Landau and Gleitman (1990) showed that verb’s participation in some frames but not others are cues that a child uses to constrain verb meaning. Levin and Rappaport-Hovav (1998) explicitly distinguish structural and idiosyncratic components of meaning. But neither claim that verb classes or statistical distributions of subcategorization frames determine verb meaning. Yet VerbNet maps verbs to predicates in precisely this way: (Kingsbury et al 2002). cure, rob, ...: Verbs of Inalienable Possession cause(Agent,E) location(start(E),Theme,Source) marry, divorce, ...: Verbs of Social Interaction social interaction(...) The distinction between cure and rob, or between marry and divorce is not astonishing to the English speaker. Causal mechanisms behind disease, possession, and the marital practices that were labeled idiosyncratic by the lexical semanticist must be captured in T*. Assumption: Language is separate from general systems of knowledge and belief This “defining” assumption helped for the Golden Oldies, but innovations in development</context>
</contexts>
<marker>Kingsbury, Palmer, Marcus, 2002</marker>
<rawString>P. Kingsbury, M. Palmer, and M. Marcus. Adding semantic annotation to the penn treebank. In Proceedings of Human Language Technology Conference, 2002. B. Kuipers. Qualitative Reasoning. MIT Press., Cambridge, MA, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Landau</author>
<author>L R Gleitman</author>
</authors>
<title>Language and experience: Evidence from the blind child.</title>
<date>1985</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="3502" citStr="Landau and Gleitman (1985)" startWordPosition="560" endWordPosition="563">hilosophers back in earlier eras - what we will call Golden Oldies – when the idea of a “result” was somewhat different. There are too many to recall: Quine (1960) argued that the linguist watching the natives uttering Gavagai! in the context of a rabbit would nec91 Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 91–99, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics essarily require far more constraints than met the eye. Brown (1957) showed that children used syntactic cues to disambiguate between possible meanings; Landau and Gleitman (1985) followed on these insights, showing just how deep it could be, that even blind children could learn look and see, basing their mapping on syntactic constraints. Chomsky’s (1965) notion of “deep structure” – proposed to account for commonplace syntactic phenomena – motivated many insights explored in Gruber (1965)’s thesis, Fillmore (1968)’s classical thematic roles, and Jackendoff (1983)’s Lexical conceptual structures. Hale and Keyser and many linguists labored under the MIT Lexicon project in the 1980s to determine the fundamental features of the lexicon; many of these hard-earned observati</context>
<context position="27248" citStr="Landau and Gleitman (1985)" startWordPosition="4532" endWordPosition="4536">hing is missing in these systems. We should be more accountable. Developmental psychology showed that theory change and conceptual change is possible, proving this assumption is wrong: the alphabet behind sentence meaning is a varying set of lexicalizable concepts G(T*). Missing in today’s systems attaching AGENT (or FrameNet’s Perceiver passive, or Impactor) to John and INSTRUMENT to umbrella and telescope is T*, and a mapping of the lexical items to G(T*). What T* must contain, in some as yet unknown form, is a T of physics described by McCloskey and disessa (1993), a T of vision studied by Landau and Gleitman (1985) and Winer et al (2002), a T of body studied by Carey (1985), a T of materials and artifacts studied by Hobbs et al (1987) and Pustejovsky (1995). This T*, when mapped via G, forms the alphabet of the above 2 sentences. Assumption: The machine learning paradigm can treat deep lexical acquisition. If we reject the assumption that there is some “meaning” of a sentence spanned by a set of meaning primitives, the soothing clarity of the machine learning paradigm is no longer available. We cannot map parse trees onto sentence meanings. The possibility of “Putting Meaning in Your Trees” (Palmer 2004</context>
</contexts>
<marker>Landau, Gleitman, 1985</marker>
<rawString>B. Landau and L. R. Gleitman. Language and experience: Evidence from the blind child. Harvard University Press, Cambridge, MA, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Laurence</author>
<author>E Margolis</author>
</authors>
<title>Radical concept nativism.</title>
<date>2002</date>
<journal>Cognition,</journal>
<volume>86</volume>
<contexts>
<context position="17386" citStr="Laurence and Margolis 2002" startWordPosition="2903" endWordPosition="2907">n only be mapped to a single concept in G(T1) = {Q}; When T* = T2, the verbs can be mapped to 3 distinct concepts in G(T2) = {AB, C&apos;, D} (See Figure 2(b)). Once T* = T2, subjects can “parse” the activation and infer the hidden kind and causal mechanism involved. Critically, subjects cannot learn to distinguish the 3 verbs until T* = T2, when the 3 new concepts emerge in G(T*). Then gorp, pilk and jeb may be mapped onto those 3 new concepts. These verbs are thus theory-laden in the same way as death, uncle and island. This UT architecture concretely dissolves the Puzzle of Concept Acquisition (Laurence and Margolis 2002): how can a person ever acquire a “new” concept, when a fixed set of primitives exhaustively span the space of possible concepts? Taking the viewpoint of the learner’s VAD at a specific moment in time with a specific T*, it has access to just those concepts in G(T*) – acquisition of a new concept is possible if T* changes. Taking the viewpoint of the learner’s species across all possible times, the species has access to the union of G(T*) over all possible TAD states – thus a “new” concept for the species is impossible. Which viewpoint one takes is a matter of perspective. Critically, the Gold</context>
</contexts>
<marker>Laurence, Margolis, 2002</marker>
<rawString>S. Laurence and E. Margolis. Radical concept nativism. Cognition, 86:22–55, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lenat</author>
<author>D Guha</author>
</authors>
<title>Building large knowledge-based systems:</title>
<date>1990</date>
<booktitle>Representation and Inference in the Cyc Project.</booktitle>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA,</location>
<contexts>
<context position="31112" citStr="Lenat and Guha 1990" startWordPosition="5139" endWordPosition="5142">e is provided by the concept generator G: it maps a naive theory T* (general systems of knowledge and belief) to G(T*), used by the VAD (language). Assumption: Real-world knowledge is Bad The absence of the soothing clarity of the machine learning paradigm and presence of real world knowledge in T* brings forth 2 associations: Early Schank/Cyc = Much Knowledge = UT research = Bad Statistics = Little Knowledge = shallow semantics = Good The associations lead to the inference that Universal Theory research will suffer a similar fate as the 70s Schankian program and the Cyc program (Schank 1972, Lenat and Guha 1990). However, this inference is incorrect. The 70s Schankian program and Cyc efforts did not carefully consider the constraints of syntactic phenomena or developmental psychology. Schank and his colleagues stimulated research in qualitative physics and explanation-based learning that addressed many of these deficiencies, but there is much work to be done to bridge today’s efforts in deep lexical acquisition to this. Assumption: Others will provide us the answers Lexical semanticists now rely on cognitive explanations far more heavily than ever before. Jackendoff (2002) concludes: “someone has to </context>
</contexts>
<marker>Lenat, Guha, 1990</marker>
<rawString>D. Lenat and D. Guha. Building large knowledge-based systems: Representation and Inference in the Cyc Project. Addison-Wesley, Reading, MA, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Leslie</author>
</authors>
<title>How to acquire a representational theory of mind. In</title>
<date>2000</date>
<booktitle>Metarepresentations: An Multidisciplinary perspective.,</booktitle>
<pages>197--223</pages>
<editor>D. Sperber, editor,</editor>
<publisher>Oxford Press.</publisher>
<location>Oxford,</location>
<contexts>
<context position="8790" citStr="Leslie 2000" startWordPosition="1441" endWordPosition="1442">h (a total breakdown of bodily functions) and that death is an irreversible, inevitable end. Between 4 and 6, children become superficially aware of the general function of various body parts (e.g “You need a heart to live”). Other phenomena serve the same point: the child at T1 thinks uncle means friendly middle-aged man, and at T2 thinks it means parent’s brother. The child at T1 thinks island means a beachy territory and at T2 thinks it means body of land surrounded by water (Keil 1989). And, “theory of mind” concepts/words such as belief, desire, wonder, pretend (Wellman and Bartsch 1995, Leslie 2000) are similarly situated. How “theory-like” T1 and T2 are is subject to considerable debate (diSessa 1993, Leslie 2000). disessa (1993) describes a large number of causal “p-prims” that are highly context specific and considerably larger in number than what Carey (1985) describes; these are shown to apply to everyday physical phenomena – “force as mover”, “vaccuums impel”, “overcoming”, “springiness”, “bigger means lower pitch (or slower)”, to name a few. Each of these have a FrameNet-like causal syntax, of some unknown mapping to vocabulary items. Similarly, Rozenblit and Keil (2003) show that</context>
</contexts>
<marker>Leslie, 2000</marker>
<rawString>A. Leslie. How to acquire a representational theory of mind. In D. Sperber, editor, Metarepresentations: An Multidisciplinary perspective., pages 197– 223, Oxford, 2000. Oxford Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>English Verb Classes and Alternations: A Preliminary Investigation.</title>
<date>1993</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, IL,</location>
<contexts>
<context position="4128" citStr="Levin (1993)" startWordPosition="658" endWordPosition="659">hese insights, showing just how deep it could be, that even blind children could learn look and see, basing their mapping on syntactic constraints. Chomsky’s (1965) notion of “deep structure” – proposed to account for commonplace syntactic phenomena – motivated many insights explored in Gruber (1965)’s thesis, Fillmore (1968)’s classical thematic roles, and Jackendoff (1983)’s Lexical conceptual structures. Hale and Keyser and many linguists labored under the MIT Lexicon project in the 1980s to determine the fundamental features of the lexicon; many of these hard-earned observations appear in Levin (1993). Schank (1972)’s Conceptual dependency theory, Minsky (1975)’s Frames were proposed for the broader goals of capturing commonsense knowledge. Quillian’s (1968) and Miller et al (1990)’s WordNet were not intended for models of lexical acquisition or databases to be used in computational linguistics but as models of human semantic memory. Many other Golden Oldies exist, and our debt to them is quite large. Ask what motivates our collection of subcategorization statistics or what drives the quest for semantic roles, and the roots are found in the science questions of the Golden Oldies. The prese</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>B. Levin. English Verb Classes and Alternations: A Preliminary Investigation. University of Chicago Press, Chicago, IL, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
<author>M Rappaport-Hovav</author>
</authors>
<title>Objecthood and object alternations. ms,</title>
<date>2003</date>
<journal>Scientific American,</journal>
<volume>248</volume>
<publisher>Oxford University Press,</publisher>
<location>New York,</location>
<contexts>
<context position="31814" citStr="Levin and Rappaport-Hovav (2003)" startWordPosition="5247" endWordPosition="5250">Cyc efforts did not carefully consider the constraints of syntactic phenomena or developmental psychology. Schank and his colleagues stimulated research in qualitative physics and explanation-based learning that addressed many of these deficiencies, but there is much work to be done to bridge today’s efforts in deep lexical acquisition to this. Assumption: Others will provide us the answers Lexical semanticists now rely on cognitive explanations far more heavily than ever before. Jackendoff (2002) concludes: “someone has to study all these subtle frameworks of meaning - so why not linguists?” Levin and Rappaport-Hovav (2003), addressing denominal verbs such as mop and butter, now freely point to “general cognitive principles” rather than situate knowledge in the lexicon. Rather than consume lexical semantics of the Golden Oldies, we can draw upon our toolbox to again answer Question (1): “what is a lexicalizable concept?” 5 We Must Change Our Concepts Stop working with models of concepts from the Golden Oldies. Start questioning whether results under the machine learning paradigm are really results. Change your concept of a result. Learn how children do theory, concept and vocabulary acquisition. Expose the funda</context>
</contexts>
<marker>Levin, Rappaport-Hovav, 2003</marker>
<rawString>B. Levin and M. Rappaport-Hovav. Objecthood and object alternations. ms, 2003. J. Mandler. Foundations of Mind: Origins of Conceptual Thought. Oxford University Press, New York, 2004. M. McCloskey. Intuitive physics. Scientific American, 248:122–130, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>K Miller</author>
</authors>
<title>Five papers on wordnet.</title>
<date>1990</date>
<journal>International Journal of Lexicology,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="4312" citStr="Miller et al (1990)" startWordPosition="682" endWordPosition="685">eep structure” – proposed to account for commonplace syntactic phenomena – motivated many insights explored in Gruber (1965)’s thesis, Fillmore (1968)’s classical thematic roles, and Jackendoff (1983)’s Lexical conceptual structures. Hale and Keyser and many linguists labored under the MIT Lexicon project in the 1980s to determine the fundamental features of the lexicon; many of these hard-earned observations appear in Levin (1993). Schank (1972)’s Conceptual dependency theory, Minsky (1975)’s Frames were proposed for the broader goals of capturing commonsense knowledge. Quillian’s (1968) and Miller et al (1990)’s WordNet were not intended for models of lexical acquisition or databases to be used in computational linguistics but as models of human semantic memory. Many other Golden Oldies exist, and our debt to them is quite large. Ask what motivates our collection of subcategorization statistics or what drives the quest for semantic roles, and the roots are found in the science questions of the Golden Oldies. The present Myopic Learning Paradigm It would have been extremely myopic to take any one of these classical results and accuse their authors of not demonstrating a learning algorithm, not evalu</context>
<context position="19212" citStr="Miller et al (1990)" startWordPosition="3216" endWordPosition="3219">ble theories. The task of writing a naive theory is like writing a grammar. The task of characterizing the space of possible theories requires a theory metalanguage just as characterizing the space of possible grammars requires a grammar metalanguage. Moreover, research into naive theories does not proceed separately from the program of research in grammar. The two programs are bridged by the concept generator G: T* generates G(T*), a set of lexicalizable concepts. An adequate account of G would generate concepts present in a particular language, for every language, and for every possible T*. Miller et al (1990) distinguish between a constructive and a differential lexicon. In a differential theory of the lexicon, meanings can be represented by any symbols that enable a theorist to distinguish among them; In a constructive theory of the lexicon, the representation should “contain sufficient information to support an accurate construction of the concept (by either a person or a machine)”. 95 The conceptual analyst who desires to produce a constructive theory of the lexicon has four kinds of accounts to provide: (see Niyogi 2005) • an explanatory account of the space of possible theories, for all perso</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>G. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. Miller. Five papers on wordnet. International Journal of Lexicology, 3(4), 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Minsky</author>
</authors>
<title>A framework for representing knowledge.</title>
<date>1975</date>
<booktitle>The psychology of Computer Vision.,</booktitle>
<pages>211--277</pages>
<editor>In P. Winston, editor,</editor>
<publisher>McGrawHill.</publisher>
<location>New York,</location>
<contexts>
<context position="4189" citStr="Minsky (1975)" startWordPosition="665" endWordPosition="666">blind children could learn look and see, basing their mapping on syntactic constraints. Chomsky’s (1965) notion of “deep structure” – proposed to account for commonplace syntactic phenomena – motivated many insights explored in Gruber (1965)’s thesis, Fillmore (1968)’s classical thematic roles, and Jackendoff (1983)’s Lexical conceptual structures. Hale and Keyser and many linguists labored under the MIT Lexicon project in the 1980s to determine the fundamental features of the lexicon; many of these hard-earned observations appear in Levin (1993). Schank (1972)’s Conceptual dependency theory, Minsky (1975)’s Frames were proposed for the broader goals of capturing commonsense knowledge. Quillian’s (1968) and Miller et al (1990)’s WordNet were not intended for models of lexical acquisition or databases to be used in computational linguistics but as models of human semantic memory. Many other Golden Oldies exist, and our debt to them is quite large. Ask what motivates our collection of subcategorization statistics or what drives the quest for semantic roles, and the roots are found in the science questions of the Golden Oldies. The present Myopic Learning Paradigm It would have been extremely myop</context>
</contexts>
<marker>Minsky, 1975</marker>
<rawString>M. Minsky. A framework for representing knowledge. In P. Winston, editor, The psychology of Computer Vision., pages 211–277, New York, 1975. McGrawHill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Nersessian</author>
</authors>
<title>Comparing historical and intuitive explanations of motion: Does naive physics have a structure?</title>
<date>1989</date>
<booktitle>In Proceedings of the Eleventh Annual Conference of the Cognitive Science Society,</booktitle>
<pages>412--420</pages>
<marker>Nersessian, 1989</marker>
<rawString>N. Nersessian. Comparing historical and intuitive explanations of motion: Does naive physics have a structure? In Proceedings of the Eleventh Annual Conference of the Cognitive Science Society, pages 412–420, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Niyogi</author>
</authors>
<title>Aspects of the logical structure of conceptual analysis.</title>
<date>2005</date>
<booktitle>Proceedings of the 27th Annual Meeting of the Cognitive Science Society,</booktitle>
<contexts>
<context position="14614" citStr="Niyogi 2005" startWordPosition="2390" endWordPosition="2391">stions have been addressed already in computational models where a candidate UT metalanguage and theory T* is latent. diSessa (1993) catalogs sets of p-prims in naive physics. Atran (1995) describes a theory of family structure. Gopnik et al (2004) uses Bayesian networks to model preschooler’s causal reasoning about blickets. McClelland and Rogers (2004) describe connectionist models of some of Carey (1985)’s classic results. In my own work, I have been situating the elements of the Universal Theory Model of Concepts in a microgenesis study, where adult subjects undergo a T1 to T2 transition (Niyogi 2005). The transition can be understood with a minimal UT metalanguage needed to characterize a set of possible theories: T* is characterized by a interrelated sets of kinds, attributes, relations, and causal laws. T1 and T2 are described in that UT metalanguage, and the simplest concept generator G is described that mechanically maps T1 and T2 onto G(T1) and G(T2). Subjects undergo theory change in a Blocksworld universe (see Figure 2(a)) while learning 3 verbs (gorp, pilk, seb) that refer to the causal mechanisms governing the universe. Subjects interact with a set of 29 blocks, some of which act</context>
<context position="19738" citStr="Niyogi 2005" startWordPosition="3303" endWordPosition="3304">articular language, for every language, and for every possible T*. Miller et al (1990) distinguish between a constructive and a differential lexicon. In a differential theory of the lexicon, meanings can be represented by any symbols that enable a theorist to distinguish among them; In a constructive theory of the lexicon, the representation should “contain sufficient information to support an accurate construction of the concept (by either a person or a machine)”. 95 The conceptual analyst who desires to produce a constructive theory of the lexicon has four kinds of accounts to provide: (see Niyogi 2005) • an explanatory account of the space of possible theories, for all persons P • an explanatory account of the space of possible concepts, for all persons P, for all possible theories • a descriptive account of a specific theory T* held by a representative person P (e.g. of a 3- year old or of a 10-year old) • a descriptive account of a specific lexicon L held by a representative person P (e.g. a 3- year old Chinese speaker, 3-year old English speaker, 10-year old Chinese speaker, 10-year old Chinese speaker) We may envision a “theory-based lexicon” that would capture the two key state variabl</context>
</contexts>
<marker>Niyogi, 2005</marker>
<rawString>S. Niyogi. Aspects of the logical structure of conceptual analysis. Proceedings of the 27th Annual Meeting of the Cognitive Science Society, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Niyogi</author>
</authors>
<title>The universal theory model of concepts and the dissolution of the puzzle of concept acquisition.</title>
<date>2005</date>
<booktitle>Proceedings of the 27th Annual Meeting of the Cognitive Science Society,</booktitle>
<contexts>
<context position="14614" citStr="Niyogi 2005" startWordPosition="2390" endWordPosition="2391">stions have been addressed already in computational models where a candidate UT metalanguage and theory T* is latent. diSessa (1993) catalogs sets of p-prims in naive physics. Atran (1995) describes a theory of family structure. Gopnik et al (2004) uses Bayesian networks to model preschooler’s causal reasoning about blickets. McClelland and Rogers (2004) describe connectionist models of some of Carey (1985)’s classic results. In my own work, I have been situating the elements of the Universal Theory Model of Concepts in a microgenesis study, where adult subjects undergo a T1 to T2 transition (Niyogi 2005). The transition can be understood with a minimal UT metalanguage needed to characterize a set of possible theories: T* is characterized by a interrelated sets of kinds, attributes, relations, and causal laws. T1 and T2 are described in that UT metalanguage, and the simplest concept generator G is described that mechanically maps T1 and T2 onto G(T1) and G(T2). Subjects undergo theory change in a Blocksworld universe (see Figure 2(a)) while learning 3 verbs (gorp, pilk, seb) that refer to the causal mechanisms governing the universe. Subjects interact with a set of 29 blocks, some of which act</context>
<context position="19738" citStr="Niyogi 2005" startWordPosition="3303" endWordPosition="3304">articular language, for every language, and for every possible T*. Miller et al (1990) distinguish between a constructive and a differential lexicon. In a differential theory of the lexicon, meanings can be represented by any symbols that enable a theorist to distinguish among them; In a constructive theory of the lexicon, the representation should “contain sufficient information to support an accurate construction of the concept (by either a person or a machine)”. 95 The conceptual analyst who desires to produce a constructive theory of the lexicon has four kinds of accounts to provide: (see Niyogi 2005) • an explanatory account of the space of possible theories, for all persons P • an explanatory account of the space of possible concepts, for all persons P, for all possible theories • a descriptive account of a specific theory T* held by a representative person P (e.g. of a 3- year old or of a 10-year old) • a descriptive account of a specific lexicon L held by a representative person P (e.g. a 3- year old Chinese speaker, 3-year old English speaker, 10-year old Chinese speaker, 10-year old Chinese speaker) We may envision a “theory-based lexicon” that would capture the two key state variabl</context>
</contexts>
<marker>Niyogi, 2005</marker>
<rawString>S. Niyogi. The universal theory model of concepts and the dissolution of the puzzle of concept acquisition. Proceedings of the 27th Annual Meeting of the Cognitive Science Society, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
</authors>
<title>Putting meaning in your trees.</title>
<date>2004</date>
<booktitle>In CoNLL-2004,</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="27849" citStr="Palmer 2004" startWordPosition="4641" endWordPosition="4642">tman (1985) and Winer et al (2002), a T of body studied by Carey (1985), a T of materials and artifacts studied by Hobbs et al (1987) and Pustejovsky (1995). This T*, when mapped via G, forms the alphabet of the above 2 sentences. Assumption: The machine learning paradigm can treat deep lexical acquisition. If we reject the assumption that there is some “meaning” of a sentence spanned by a set of meaning primitives, the soothing clarity of the machine learning paradigm is no longer available. We cannot map parse trees onto sentence meanings. The possibility of “Putting Meaning in Your Trees” (Palmer 2004) completely disappears. We may still use the machine learning paradigm to parse, disambiguate and recognize speech. But these results are of little use to model theory, concept and lexical acquisition, because there is no output representation where a suitable training set could be collected. The human conceptual apparatus is not that simple: the VAD requires G(T*) (which changes, as T* changes), and for that we need explanatory accounts of UT and G, and must recognize the diverse ways the TAD may change state. 97 Assumption: Paths from shallow to deep lexical acquisition exist The Golden Oldi</context>
</contexts>
<marker>Palmer, 2004</marker>
<rawString>M. Palmer. Putting meaning in your trees. In CoNLL-2004, 2004. J. Pustejovsky. The Generative Lexicon. MIT Press, Cambridge, MA, 1995. W. Quine. Word and Object. MIT Press, Cambridge, MA, 1960.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Regier</author>
</authors>
<title>The Human Semantic Potential.</title>
<date>1996</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="21004" citStr="Regier 1996" startWordPosition="3522" endWordPosition="3523">(1) T* for an idealized human; (2) a set of vocabulary items mapped to points in G(T*). Very limited instances of a theory-based lexicon can be constructed already for subjects at the end of the experiment – such a theory-based lexicon has (1) T2 in the UT metalanguage; (2) the mapping in L to G(T2): gorp = AB, pilk = C&apos;, seb = D. This constructive theory-based lexicon would be in stark contrast to differential lexicons such as WordNet and FrameNet. Grounding language in perception is insufficient Many have proposed deep lexical acquisition by “grounding language in perception” (Siskind 1996, Regier 1996, Roy and Pentland 2002, Yu and Ballard 2004), constructing systems that can learn to utter, e.g. red, banana, hit and triangle in contexts where there are, e.g., three triangles hitting red bananas. Such systems also propose a space of possible concepts exhausted by a fixed set of primitives, as in the Golden Oldies model. The initial state of the TAD (T*(t = 0)) can explicitly incorporate all these attributes and relations (contact, luminance, ...); but then, the TAD can further change state to yield new kinds, attributes, relations, and causal mechanisms not present in the initial state, bu</context>
</contexts>
<marker>Regier, 1996</marker>
<rawString>T. Regier. The Human Semantic Potential. MIT Press, Cambridge, MA, 1996. T. Rogers and J. McClelland. Semantic Cognition: A parallel distributed Processing approach. MIT Press, Cambridge, MA, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roy</author>
<author>Pentland</author>
</authors>
<title>Learning words from sights and sounds: A computational model.</title>
<date>2002</date>
<journal>Cognitive Science,</journal>
<volume>26</volume>
<contexts>
<context position="21027" citStr="Roy and Pentland 2002" startWordPosition="3524" endWordPosition="3527"> idealized human; (2) a set of vocabulary items mapped to points in G(T*). Very limited instances of a theory-based lexicon can be constructed already for subjects at the end of the experiment – such a theory-based lexicon has (1) T2 in the UT metalanguage; (2) the mapping in L to G(T2): gorp = AB, pilk = C&apos;, seb = D. This constructive theory-based lexicon would be in stark contrast to differential lexicons such as WordNet and FrameNet. Grounding language in perception is insufficient Many have proposed deep lexical acquisition by “grounding language in perception” (Siskind 1996, Regier 1996, Roy and Pentland 2002, Yu and Ballard 2004), constructing systems that can learn to utter, e.g. red, banana, hit and triangle in contexts where there are, e.g., three triangles hitting red bananas. Such systems also propose a space of possible concepts exhausted by a fixed set of primitives, as in the Golden Oldies model. The initial state of the TAD (T*(t = 0)) can explicitly incorporate all these attributes and relations (contact, luminance, ...); but then, the TAD can further change state to yield new kinds, attributes, relations, and causal mechanisms not present in the initial state, but motivated by the data</context>
</contexts>
<marker>Roy, Pentland, 2002</marker>
<rawString>D. Roy and Pentland. Learning words from sights and sounds: A computational model. Cognitive Science, 26:113–146, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rozenblit</author>
<author>F Keil</author>
</authors>
<title>The misunderstood limits of folk science: an illusion of explanatory depth.</title>
<date>2002</date>
<journal>Cognitive Science,</journal>
<volume>26</volume>
<marker>Rozenblit, Keil, 2002</marker>
<rawString>L. Rozenblit and F. Keil. The misunderstood limits of folk science: an illusion of explanatory depth. Cognitive Science, 26:521–562, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schank</author>
</authors>
<title>Conceptual dependency theory.</title>
<date>1972</date>
<journal>Cognitive Psychology,</journal>
<volume>3</volume>
<contexts>
<context position="4143" citStr="Schank (1972)" startWordPosition="660" endWordPosition="661"> showing just how deep it could be, that even blind children could learn look and see, basing their mapping on syntactic constraints. Chomsky’s (1965) notion of “deep structure” – proposed to account for commonplace syntactic phenomena – motivated many insights explored in Gruber (1965)’s thesis, Fillmore (1968)’s classical thematic roles, and Jackendoff (1983)’s Lexical conceptual structures. Hale and Keyser and many linguists labored under the MIT Lexicon project in the 1980s to determine the fundamental features of the lexicon; many of these hard-earned observations appear in Levin (1993). Schank (1972)’s Conceptual dependency theory, Minsky (1975)’s Frames were proposed for the broader goals of capturing commonsense knowledge. Quillian’s (1968) and Miller et al (1990)’s WordNet were not intended for models of lexical acquisition or databases to be used in computational linguistics but as models of human semantic memory. Many other Golden Oldies exist, and our debt to them is quite large. Ask what motivates our collection of subcategorization statistics or what drives the quest for semantic roles, and the roots are found in the science questions of the Golden Oldies. The present Myopic Learn</context>
<context position="31090" citStr="Schank 1972" startWordPosition="5137" endWordPosition="5138">on. The bridge is provided by the concept generator G: it maps a naive theory T* (general systems of knowledge and belief) to G(T*), used by the VAD (language). Assumption: Real-world knowledge is Bad The absence of the soothing clarity of the machine learning paradigm and presence of real world knowledge in T* brings forth 2 associations: Early Schank/Cyc = Much Knowledge = UT research = Bad Statistics = Little Knowledge = shallow semantics = Good The associations lead to the inference that Universal Theory research will suffer a similar fate as the 70s Schankian program and the Cyc program (Schank 1972, Lenat and Guha 1990). However, this inference is incorrect. The 70s Schankian program and Cyc efforts did not carefully consider the constraints of syntactic phenomena or developmental psychology. Schank and his colleagues stimulated research in qualitative physics and explanation-based learning that addressed many of these deficiencies, but there is much work to be done to bridge today’s efforts in deep lexical acquisition to this. Assumption: Others will provide us the answers Lexical semanticists now rely on cognitive explanations far more heavily than ever before. Jackendoff (2002) concl</context>
</contexts>
<marker>Schank, 1972</marker>
<rawString>R. Schank. Conceptual dependency theory. Cognitive Psychology, 3:552–631, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Siskind</author>
</authors>
<title>A computational study of cross-situational techniques for learning word-to-meaning mappings.</title>
<date>1996</date>
<journal>Cognition,</journal>
<volume>61</volume>
<contexts>
<context position="20991" citStr="Siskind 1996" startWordPosition="3520" endWordPosition="3521">counts above: (1) T* for an idealized human; (2) a set of vocabulary items mapped to points in G(T*). Very limited instances of a theory-based lexicon can be constructed already for subjects at the end of the experiment – such a theory-based lexicon has (1) T2 in the UT metalanguage; (2) the mapping in L to G(T2): gorp = AB, pilk = C&apos;, seb = D. This constructive theory-based lexicon would be in stark contrast to differential lexicons such as WordNet and FrameNet. Grounding language in perception is insufficient Many have proposed deep lexical acquisition by “grounding language in perception” (Siskind 1996, Regier 1996, Roy and Pentland 2002, Yu and Ballard 2004), constructing systems that can learn to utter, e.g. red, banana, hit and triangle in contexts where there are, e.g., three triangles hitting red bananas. Such systems also propose a space of possible concepts exhausted by a fixed set of primitives, as in the Golden Oldies model. The initial state of the TAD (T*(t = 0)) can explicitly incorporate all these attributes and relations (contact, luminance, ...); but then, the TAD can further change state to yield new kinds, attributes, relations, and causal mechanisms not present in the init</context>
</contexts>
<marker>Siskind, 1996</marker>
<rawString>J. Siskind. A computational study of cross-situational techniques for learning word-to-meaning mappings. Cognition, 61:39–91, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Slaughter</author>
<author>R Jaakola</author>
<author>S Carey</author>
</authors>
<title>Constructing a coherent theory: children’s biological understanding of life and death.</title>
<date>1999</date>
<booktitle>Children’s understanding of biology and health,</booktitle>
<editor>In M. Siegel and C. Peterson, editors,</editor>
<institution>Cambridge University.</institution>
<location>Cambridge,</location>
<marker>Slaughter, Jaakola, Carey, 1999</marker>
<rawString>V. Slaughter, R. Jaakola, and S. Carey. Constructing a coherent theory: children’s biological understanding of life and death. In M. Siegel and C. Peterson, editors, Children’s understanding of biology and health, Cambridge, 1999. Cambridge University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Slaughter</author>
<author>R Jaakola</author>
<author>S Carey</author>
</authors>
<title>Constructing a coherent theory: children’s biological understanding of life and death.</title>
<date>1999</date>
<booktitle>Children’s understanding of biology and health,</booktitle>
<editor>In M. Siegel and C. Peterson, editors,</editor>
<institution>Cambridge University.</institution>
<location>Cambridge,</location>
<marker>Slaughter, Jaakola, Carey, 1999</marker>
<rawString>V. Slaughter, R. Jaakola, and S. Carey. Constructing a coherent theory: children’s biological understanding of life and death. In M. Siegel and C. Peterson, editors, Children’s understanding of biology and health, Cambridge, 1999. Cambridge University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Yu</author>
<author>Dana H Ballard</author>
</authors>
<title>A Unified Model of Early Word Learning: Integrating Statistical and Social Cues.</title>
<date>2004</date>
<booktitle>Proceedings of the 3rd International Conference on Development and Learning,</booktitle>
<contexts>
<context position="21049" citStr="Yu and Ballard 2004" startWordPosition="3528" endWordPosition="3532"> set of vocabulary items mapped to points in G(T*). Very limited instances of a theory-based lexicon can be constructed already for subjects at the end of the experiment – such a theory-based lexicon has (1) T2 in the UT metalanguage; (2) the mapping in L to G(T2): gorp = AB, pilk = C&apos;, seb = D. This constructive theory-based lexicon would be in stark contrast to differential lexicons such as WordNet and FrameNet. Grounding language in perception is insufficient Many have proposed deep lexical acquisition by “grounding language in perception” (Siskind 1996, Regier 1996, Roy and Pentland 2002, Yu and Ballard 2004), constructing systems that can learn to utter, e.g. red, banana, hit and triangle in contexts where there are, e.g., three triangles hitting red bananas. Such systems also propose a space of possible concepts exhausted by a fixed set of primitives, as in the Golden Oldies model. The initial state of the TAD (T*(t = 0)) can explicitly incorporate all these attributes and relations (contact, luminance, ...); but then, the TAD can further change state to yield new kinds, attributes, relations, and causal mechanisms not present in the initial state, but motivated by the data (see Gopnik and Meltz</context>
</contexts>
<marker>Yu, Ballard, 2004</marker>
<rawString>C. Yu and Dana H. Ballard (2004) A Unified Model of Early Word Learning: Integrating Statistical and Social Cues. Proceedings of the 3rd International Conference on Development and Learning, 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>