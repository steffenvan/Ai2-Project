<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000043">
<title confidence="0.996819">
Generated Narratives for Computer-aided Language Teaching
</title>
<author confidence="0.997316">
Michael LEVISON Greg LESSARD
</author>
<affiliation confidence="0.975434">
School of Computing French Studies
Queen’s University Queen’s University
Kingston, Ontario Kingston, Ontario
</affiliation>
<address confidence="0.883984">
Canada K7L 3N6 Canada K7L 3N6
</address>
<email confidence="0.994787">
levison@cs.queensu.ca lessardg@post.queensu.ca
</email>
<sectionHeader confidence="0.997297" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999673307692307">
VINCI is a Natural Language Generation envi-
ronment designed for use in computer-aided sec-
ond language instruction. It dynamically gener-
ates multiple parallel trees representing an ini-
tial text, questions on this text, and expected
answers, and either orthographic or phonetic
output. Analyses of a learner’s answers to ques-
tions are used to diagnose comprehension and
language skills and to adaptively control sub-
sequent generation. The paper traces stages
in the generation of short texts in English and
French, and discusses issues of architecture, tex-
tual enrichment, and planning.
</bodyText>
<sectionHeader confidence="0.9977605" genericHeader="method">
1 VINCI: Architecture,
Implementation and Output
</sectionHeader>
<bodyText confidence="0.999916018181819">
Ideally, a language teaching system should both
“encourage the creative use of language in com-
municatively relevant settings” (Menzel and
Schroeder, 1998) and also provide detailed and
adaptive feedback (cf. (Michaud, 2002)). Many
systems resolve the issue by means of complex
parsing. In what follows, we describe VINCI, a
multilingual generation environment which rep-
resents a complementary approach in that it as-
sumes conversational control, dynamically pro-
ducing more or less complex texts and asking
information of users. VINCI is based on a col-
lection of metalanguages which define the se-
mantics, syntax, lexicon and morphology of a
language. Text files defining the language are
read by an interpreter (written in C) and out-
put is presented either orthographically or pho-
netically.
When used in a teaching context, VINCI cre-
ates an utterance and presents it to a learner.
It also creates a series of questions based on
each utterance, together with some hidden an-
swers. The learner is prompted to respond to
each question, and his or her response is com-
pared with the hidden one (or ones) and a de-
tailed report is produced on the relation be-
tween the two. This report provides informa-
tion on a learner’s comprehension and language
skills, as well as guidance for subsequent gener-
ation.
VINCI is capable of generation in many lan-
guages, and has been tested on such diverse lan-
guages as Spanish, Italian, Russian and Chi-
nese. Our work to date has been carried out
in both English and French, predominantly the
latter.
For the generation of simple utterances,
VINCI constructs a syntax tree using context-
free rules and syntactic transformations. The
nodes of the tree may be decorated with at-
tributes, whose role is to maintain grammatical
and perhaps semantic agreement by restricting
the choice of lexical items and controlling mor-
phology. Once a tree is formed, its leaves are
assigned suitable lexical choices which are in-
flected by morphology rules. In the most basic
situation, choices among syntactic alternatives
and among possible lexical entries are made at
random. In such a model, the semantic con-
trol exercised by attributes is minimal. They
can, for example, ensure that the subject of a
verb such as eat is animate and its object edible,
but they cannot influence the overall meaning of
the utterance produced. To achieve this, VINCI
makes use of preselections.
</bodyText>
<subsectionHeader confidence="0.998257">
1.1 Preselections
</subsectionHeader>
<bodyText confidence="0.997737736842105">
Preselections may be thought of as forming a
metaphoric blackboard on which the person re-
quiring an utterance writes some choices about
its features. Lexical entries corresponding to
these features are selected before the syntax tree
is formed, and syntax rules have access both to
the words themselves and to information about
them obtained from the lexicon. We will illus-
trate this by showing the steps in the generation
of a short fairy tale, although other sorts of texts
are also possible.
In a typical fairy tale we have a collection
of characters, including a pompous twit (a
king or a rich merchant), a victim or heroine
(the twit’s daughter), a villain (a sorcerer or
witch), a hero (a prince or a brave woodcutter),
a goodfairy (the victim’s fairy godmother), a
magicobj (a sword or a silver goblet). These
form the basis for a set of preselections such as:
</bodyText>
<equation confidence="0.9937745">
twit :
PN/&amp;quot;Midas&amp;quot;;
victim:
PN/ pre twit/@14: daughter;
hero :
PN[male, brave, handsome];
magicobj :
N[physobj, magic]
</equation>
<bodyText confidence="0.998447666666667">
These preselections presuppose a database of
characters/objects which are simply entries in a
lexicon:
</bodyText>
<listItem confidence="0.81376725">
&amp;quot;Midas&amp;quot;|PN|
male, rich, weak, vain|...
daughter: &amp;quot;Marie&amp;quot;;...
type: &amp;quot;king&amp;quot;; ...
home: &amp;quot;castle&amp;quot;; ...
&amp;quot;Marie&amp;quot;|PN|
female, beautiful, kind|...
type: &amp;quot;princess&amp;quot;; ...
</listItem>
<bodyText confidence="0.984994913043478">
Preselections can be specified with more or
less precision. In this example, only Midas can
be chosen for the role of twit, but any mem-
ber of the class PN (proper names) having the
attributes male, brave and handsome can be
selected as hero. We might well have writ-
ten twit: PN[rich]/@14: daughter mak-
ing the twit any PN who is rich and has a
pointer to a daughter in lexical field 14.
These preselections are global, in that they
persist across several utterances. If the hero is a
prince in one sentence, he cannot be a woodcut-
ter in the next. In contrast, the local preselec-
tions described below associate these characters
with a semantic role in a particular sentence,
for example, the agent or the patient. We can
envisage a user typing/editing a global preselec-
tions file to select favorite characters for a story.
Alternatively, there may be an interface which
allows a user to choose characters from a set of
menus. In the following tale, we assume that
Wanda has been preselected as the goodfairy
and magic sword as magicobj.
</bodyText>
<subsectionHeader confidence="0.997379">
1.2 Semantic Expressions
</subsectionHeader>
<bodyText confidence="0.943619191176471">
A semantic expression is a representation of the
content of an utterance in a form in which the
grammatical constraints of any particular natu-
ral language have been abstracted away, leav-
ing only some expression of meaning behind.
A simple functional notation is used, described
more fully in (Levison et al., 2001b). These
expressions are transformed into VINCI pres-
elections, triggering syntax rules which, in their
turn, yield sentences in some language. The
same sequence of expressions can transformed
into paragraphs in different languages or differ-
ent paragraphs in the same language.
The plot for the fairy tale can be specified as
a sequence of these expressions:
exists(twit)
Once upon a time there was a twit.
describe(twit)
He was rich and vain.
exists(victim)
The twit had a daughter, the victim.
describe(victim)
She was beautiful and kind.
admonish(twit, victim, action)
The twit warned the victim about
walking in the forest.
disobey(victim)
However, the victim disobeyed.
action(victim)
She went for a walk in the forest.
exists(villain)
In the forest there lived a villain.
describe(villain)
He was strong and evil.
kidnap(villain, victim)
The villain kidnapped the victim.
exists(hero)
In the same area, there lived a hero.
seekhelp(twit, hero)
The twit sought his help.
seek(hero, goodfairy)
The hero went to find the goodfairy...
give(goodfairy, hero, magicobj)
who gave him a magicobj.
seek(hero, villain)
The hero sought the villain...
kill(hero, villain, magicobj)
and killed him with the magicobj.
rescue(hero, victim)
The hero rescued the victim, ...
marry(hero, victim)
married her, ...
livehappily(hero, victim)
and lived happily ever after.
Obviously, the plot can be modified simply
by varying the expressions. Indeed there might
be alternative plots or sections, perhaps cho-
sen by a user or produced by a text plan-
ner. Let us repeat that these expressions are
language-independent. The names of the func-
tions and parameters are, in fact, VINCI at-
tributes, and although English words have been
used here, any string of letters or digits could
have been substituted. If a French grammar and
lexicon is built using the same attributes, as
in: &amp;quot;donner&amp;quot;|V|vtdi, give, ...|... then
VINCI can construct French sentences from the
same semantic expressions.
</bodyText>
<subsectionHeader confidence="0.993493">
1.3 Local Preselections
</subsectionHeader>
<bodyText confidence="0.856926777777778">
Each of the expressions in the previous section is
equivalent to and is transformed by VINCI into
a set of local preselections which apply to the
generation of a single sentence. For example,
give(goodfairy, hero, magicobj) becomes:
vtdi; {this attribute selects a
segment of syntax based
on a verb with direct and
indirect objects}
</bodyText>
<equation confidence="0.3619082">
act : V[give];
{e.g.: &amp;quot;give&amp;quot;,&amp;quot;offer&amp;quot;}
agent : PN/ pre goodfairy;
beneficiary : PN/ pre hero;
theme : N/ pre magicobj
</equation>
<bodyText confidence="0.999498571428571">
Some of these local preselections refer back
to the global ones, associating the characters
selected in the earlier preselections with the
semantic roles they will play in the current
sentence: agent, beneficiary and theme. So
goodfairy (and hence Wanda) becomes the
agent of the act of giving, magicobj (the magic
sword) becomes its theme, and hero its benefi-
ciary.
In effect, semantic expressions provide a more
user-friendly form for the set of preselections.
Conversion from the former to the latter is ef-
fected by semantic transformations; for exam-
ple:
</bodyText>
<equation confidence="0.8844914">
give : vtdi;
act : V[give];
agent : PN/ pre #1;
beneficiary : PN/ pre #2;
theme : N/ pre #3
</equation>
<bodyText confidence="0.9998705">
whose left-hand side matches give(goodfairy,
hero, magicobj), #1 being associated with
goodfairy, #2 with hero and #3 with
magicobj. In practice it shorter, if less ele-
gant, to replace this semantic expression by
vtdi(give, goodfairy, hero, magicobj),
since this single expression can be used for any
verb taking both direct and indirect objects.
</bodyText>
<subsectionHeader confidence="0.996662">
1.4 Syntax Rules
</subsectionHeader>
<bodyText confidence="0.999910428571429">
Syntax rules in Vinci take the abstract semantic
representations produced by semantic expres-
sions and preselections and clothe them in the
syntax of the language chosen. Among other
things, this allows the system to capture con-
straints on word order, argument structure, and
agreement. This is accomplished by means of
inheritance of attributes down the nodes of a
syntax tree, and guarded syntax rules, in which
attributes present on a parent node are used to
determine the nature of child nodes. For ex-
ample, given a parent node such as NP (noun
phrase) containing the attribute ’p1’ (first per-
son), a guarded syntax rule (these are headed
by the symbol &lt;) will determine that the only
possible child node is a pronoun. However, in
the default case (these are headed by the sym-
bol &gt;), the child may take either the form of a
pronoun or a full noun phrase.
Let us now return to the example of prese-
lections developed above and resume with the
action of syntax rules on the output of prese-
lections and semantic expressions. The section
of the context-free rules corresponding to vtdi
describe the structure of a sentence with a vtdi
verb in terms of the its agent, theme and ben-
eficiary. Thus, assuming the local preselections
given above:
</bodyText>
<equation confidence="0.6597795">
ROOT =
&lt; _pre_ vtdi:
NPP[sing, agent, def]
V[p3, sing, past]/_pre_ act
NPP[sing, beneficiary, def]
NP[sing, theme, indef] %
NPP = inherit Fn: Function, Nu: Number,
De: Detkind;
DET[De] N[Nu]/_pre_ Fn/@13:type %
NP = inherit Fn: Function, Nu: Number,
De: Detkind;
DET[De] N[Nu]/_pre_ Fn %
</equation>
<bodyText confidence="0.99923512">
The root of the utterance (the top of its syn-
tax tree) has four child nodes, two of them
proper noun phrases (NPP), a third a com-
mon noun phrase (NP). To the first it passes
a Number-value, sing, a Function-value, agent,
and a Detkind-value. When this NPP is devel-
oped into its two children, it assigns these at-
tribute values to Nu, Fn and De, passing De to
DET (hence a or the) and Nu to the child noun,
which will therefore be singular. This noun is
also directed to obtain its lexical entry from the
preselection labelled Fn (i.e. agent, which in
turn refers to goodfairy, and hence to Wanda).
Furthermore, rather than using Wanda itself,
the chosen noun must be replaced the lexical
entry indicated by tag type in field 13 (fairy
godmother).
The other noun phrases obtain their nouns
similarly from beneficiary and theme, though
the last (NP) uses the preselected magicobj di-
rectly. The root’s verb-child, which will be third
person singular past tense, will obtain its lexi-
cal entry from the preselection labelled act. So,
we get: the fairy godmother gave the prince a
magic sword.
</bodyText>
<subsectionHeader confidence="0.998462">
1.5 Two Generated Stories
</subsectionHeader>
<bodyText confidence="0.990949649122807">
Using a simple English lexicon and the grammar
described above, VINCI generates fairy tales, of
which the following is an intentionally short and
simple example.
Once upon a time there was a king
called Midas who lived in a castle.
He was rich and vain. The king had
a daughter, a princess named Marie,
who was beautiful. The king warned
Marie not to go out of the castle. The
princess disobeyed the king. She left
the castle.
A sorcerer called Merlin lived in the
woods. He was evil. The sorcerer kid-
napped the princess.
Nearby there lived a woodcutter
who was named Axel. The king sought
the help of the woodcutter. The wood-
cutter went to look for the fairy god-
mother. The fairy godmother passed
Axel a magic sword. Axel searched for
the sorcerer. The woodcutter killed the
sorcerer with the magic sword. The
woodcutter rescued the princess. The
woodcutter and the princess got mar-
ried and lived happily ever after.
When linked to a French lexicon, morphology
and syntax, VINCI generates comparable texts
in French, as the following example shows:
Il ´etait une fois un roi qui s’appelait
Midas et qui vivait dans un beau
chˆateau. Il ´etait riche et vain. Le
roi avait une fille: une princesse qui
s’appelait Marie et qui ´etait belle.
Le roi interdit a` Marie de quitter le
chˆateau. La princesse d´esob´eit au roi.
Elle quitta le chˆateau.
Dans la fˆoret il y avait un sorcier
qui s’appelait Merloc. Il ´etait m´echant.
Le sorcier enleva la princesse.
Aux alentours vivait un prince qui
s’appelait Coeur de Lion et qui ´etait
beau. Le roi demanda l’aide du prince.
Le prince chercha la bonne f´ee. La
bonne f´ee donna une ´ep´ee magique
au prince. Le prince chercha le sor-
cier. Coeur de Lion utilisa l’´ep´ee mag-
ique pour tuer le sorcier. Le prince
lib´era la princesse. Le prince ´epousa
la princesse et ils eurent beaucoup
d’enfants.
Along with orthographic output, (Thomas,
2002) describes the generation of good quality
prosodically controlled French oral output by
linking VINCI with the MBROLA speech syn-
thesizer (Dutoit, 2004). At this time, learner
responses must still be entered orthographically.
</bodyText>
<subsectionHeader confidence="0.999871">
1.6 Analysis of User Input
</subsectionHeader>
<bodyText confidence="0.910394888888889">
As well as constructing the story, VINCI may
produce a series of questions to put before a
learner; for example:
Question: What was the name of
the good fairy?
Expected (hidden) answer: The
good fairy was called Wanda.
Question: Describe Maria.
Expected (hidden) answer:
Maria was beautiful and
kind.
In French, whose complex morphology gives
scope for more varied errors, a typical question
such as:
Question: O`u vivait le roi?
and a reponse from a particularly incompetent
learner (one of the authors), gives rise to the
following error report:
</bodyText>
<equation confidence="0.715184857142857">
EXPECTED : le roi vivait dans
un beau ch^ateau
RESPONSE : la roi vivrait en
une chapeau belle
C4 DELETE dans
S4 INSERT en
C6 ORDER C7 C6
C1 S1 la/le MORPH f´em/masc
C2 S2 EXACT
C3 S3 vivrait/vivait MORPH
cond/imparf
C5 S5 une/un MORPH f´em/masc
C6 S7 belle/beau MORPH f´em/masc
C7 S6 APPROX chapeau/ch^ateau
</equation>
<bodyText confidence="0.998635291666667">
If the learner had typed habitait, VINCI
would have reported the change as LEX syn,
habiter being tagged in the lexicon as a syn-
onym for vivre. If he had omitted the circumflex
accent on chˆateau, the error would have been
marked as PHON, since the two forms would
have been similar in sound. This is made pos-
sible by the fact that in VINCI, lexical entries
may carry both orthographic and phonological
information.
Output of the error analysis routines as shown
above is not designed to be presented directly
to a learner. However, since it is machine-
generated, it is relatively easy to parse by a
routine which uses it to present error analyses
in a more user-friendly format. At the same
time, results of each analysis may be stored
and then used by a driver program to build
a user model, and to adaptively control sub-
sequent generation (Levison et al., 2001a). In
this way, VINCI’s architecture ’closes the loop’
in the traditional pipeline approach to genera-
tion, in that the output of analysis and diagnosis
drives the input of textual planning.
</bodyText>
<sectionHeader confidence="0.99318" genericHeader="conclusions">
2 Enhancements and Future Work
</sectionHeader>
<bodyText confidence="0.989458857142857">
VINCI’s use of semantic input by means of
functional expressions is designed to allow it
to function either as an autonomous narrative
generation system (cf. (Callaway and Lester,
2001a), (Bringsjord and Ferrucci, 2000) for ex-
amples) or as a story authoring environment
(cf. (Umaschi and Cassell, 1997)) in which a
language teacher may select or construct high-
level utterance specifications, or alternatively,
a learner may play with the order of a set of
semantic specifications, or even add new char-
acters with their own traits, examining in each
case the texts produced. Two kinds of enhance-
ments can be used to improve output.
</bodyText>
<subsectionHeader confidence="0.945796">
2.1 Encyclopedic Enrichment
</subsectionHeader>
<bodyText confidence="0.999946517241379">
In examples shown above, descriptions are
based on simple static attributes (beauty,
morality, etc.). In fact, VINCI’s compound at-
tribute mechanism also allows for the expres-
sion of actions by characters. Thus, the at-
tribute kill.monsters in the lexical entry for
Prince Braveheart might cause exists(hero)
to lead to: Nearby there lived a prince called
Braveheart, who was renowned for killing mon-
sters. This mechanism is also applicable to the
expression of a character’s thoughts and atti-
tudes, and past background information, both
narrative desiderata (Bringsjord and Ferrucci,
2000), (Robin, 1993) as well as the generation
more or less complex versions of the same text
(cf. (Chali, 1998)). Work is underway on mech-
anisms for the dynamic temporal tagging of at-
tributes, as a story develops. For example, a
learner given $50 and instructed to purchase
groceries in a textual supermarket would have
his or her remaining money reduced by each
purchase he or she describes.
It should also be noted that the micro-world
defined by means of Vinci may be fictional, as
in the cases above, or based on real people and
events. For example, we have performed exper-
iments based on a database of French authors,
their works, and their biographical details such
as date of birth, death, etc.
</bodyText>
<subsectionHeader confidence="0.991155">
2.2 Narrative Enrichment
</subsectionHeader>
<bodyText confidence="0.999835483870968">
Appropriate use of anaphoric pronous and ag-
gregation of sentences both have a significant
effect on perceptions of text quality (Callaway
and Lester, 2001b). In a number of systems,
both processes occur after sentences have been
realized, at the level of revision, which often
requires that utterances be reformulated. We
propose to perform comparable operations at
the level of semantic expressions. Suppose two
functions: exists(X), which generates There
was an X, and describe(X) which generates X
was brave and handsome. The fact that both ex-
pressions share a common argument allows for
their replacement by another, say exdesc(X),
which aggregates the two functions to produce
There was a brave and handsome X. Similarly,
in the case of anaphoric relations, shared argu-
ments allow for replacement of full names by
pronouns. We are currently researching this.
Finally, taking account of work by (Karamanis
and Manurung, 2002) which shows that sharing
of at least one argument characterizes a high
percentage of successive sentences in a text, it
is possible to use the sequence of arguments to
order a sequence of semantic expressions. Per-
haps more interestingly, it may be that one of
the criteria of a new paragraph is a break in the
chain of shared arguments from one semantic
expression to the next. The paragraph breaks
in the English and French texts above, while
human-constructed, respect this constraint.
</bodyText>
<sectionHeader confidence="0.999427" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999738084745763">
S. Bringsjord and D.A. Ferrucci. 2000. Artifi-
cial Intelligence and Literary Creativity: In-
side the Mind of BRUTUS, a Storytelling Ma-
chine. London, Lawrence Erlbaum.
C.B. Callaway and J.C. Lester. 2001a. Eval-
uating the effects of natural language gen-
eration techniques on reader satisfaction. In
Proceedings of the 23rd Annual Conference of
the Cognitive Science Society, pages 164–169.
Edinburgh, UK.
C.B. Callaway and J.C. Lester. 2001b. Narra-
tive prose generation. In Proceedings of the
Seventeenth International Joint Conference
on Artificial Intelligence (IJCAI 2001), pages
1241–1248. Seattle, WA.
Y. Chali. 1998. Text expansion using causal
and temporal relations. In Proceedings of the
Third International Conference on Natural
Language Processing and Industrial Applica-
tions. Moncton, New Brunswick.
T. Dutoit. 2004. The MBROLA Project.
http://tcts.fpms.ac.be/synthesis/mbrola.html.
N. Karamanis and H.M. Manurung. 2002.
Stochastic text structuring using the princi-
ple of continuity. In Proceedings of INLG-02,
pages 81–88. Columbia University.
M. Levison, G. Lessard, A-M. Danielson, and
D. Merven. 2001a. From symptoms to diag-
nosis. In (K. Cameron, editor, CALL – The
Challenge of Change, pages 53–59. Elm Bank,
Exeter.
M. Levison, G. Lessard, B. Gottesman, and
M. Stringer. 2001b. Semantic expressions:
An experiment. Working paper, found
at: http://www.cs.queensu.ca/CompLing/
semanticexpressions.html.
W. Menzel and I. Schroeder. 1998. Constraint-
based diagnosis for intelligent language tu-
toring systems. In Proc. ITHKNOWS, XV.
IFIP World Computer Congress, pages 484–
497. Vienna/Budapest.
L.N. Michaud. 2002. Modeling User Interlan-
guage in a Second Language Tutoring Sys-
tem for Deaf Users of American Sign Lan-
guage. PhD Dissertation, Department of
Computer and Information Sciences, Univer-
sity of Delaware.
J. Robin. 1993. A revision-based generation ar-
chitecture for reporting facts in their histor-
ical context. In M. Zock H. Horecek, editor,
New Concepts in Natural Language Genera-
tion, pages 238–268. Pinter, London.
C. Thomas. 2002. A Prosodic Transcription
Method for Natural Language Generation.
MSc Thesis, Queen’s University, Kingston.
M. Umaschi and J. Cassell. 1997. Storytelling
systems: Constructing the innerface of the
interface. In Cognitive Technologies Proceed-
ings ’97, pages 98–108. IEEE.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.999917">Generated Narratives for Computer-aided Language Teaching</title>
<author confidence="0.999967">Michael LEVISON Greg LESSARD</author>
<affiliation confidence="0.9995775">School of Computing French Studies Queen’s University Queen’s University</affiliation>
<address confidence="0.981948">Kingston, Ontario Kingston, Ontario Canada K7L 3N6 Canada K7L 3N6</address>
<email confidence="0.962208">levison@cs.queensu.calessardg@post.queensu.ca</email>
<abstract confidence="0.981985201612904">VINCI is a Natural Language Generation environment designed for use in computer-aided second language instruction. It dynamically generates multiple parallel trees representing an initial text, questions on this text, and expected answers, and either orthographic or phonetic output. Analyses of a learner’s answers to questions are used to diagnose comprehension and language skills and to adaptively control subsequent generation. The paper traces stages in the generation of short texts in English and French, and discusses issues of architecture, textual enrichment, and planning. 1 VINCI: Architecture, Implementation and Output Ideally, a language teaching system should both “encourage the creative use of language in communicatively relevant settings” (Menzel and Schroeder, 1998) and also provide detailed and adaptive feedback (cf. (Michaud, 2002)). Many systems resolve the issue by means of complex parsing. In what follows, we describe VINCI, a multilingual generation environment which represents a complementary approach in that it assumes conversational control, dynamically producing more or less complex texts and asking information of users. VINCI is based on a collection of metalanguages which define the semantics, syntax, lexicon and morphology of a language. Text files defining the language are read by an interpreter (written in C) and output is presented either orthographically or phonetically. When used in a teaching context, VINCI creates an utterance and presents it to a learner. It also creates a series of questions based on each utterance, together with some hidden answers. The learner is prompted to respond to each question, and his or her response is compared with the hidden one (or ones) and a detailed report is produced on the relation between the two. This report provides information on a learner’s comprehension and language skills, as well as guidance for subsequent generation. VINCI is capable of generation in many languages, and has been tested on such diverse languages as Spanish, Italian, Russian and Chinese. Our work to date has been carried out in both English and French, predominantly the latter. For the generation of simple utterances, VINCI constructs a syntax tree using contextfree rules and syntactic transformations. The nodes of the tree may be decorated with attributes, whose role is to maintain grammatical and perhaps semantic agreement by restricting the choice of lexical items and controlling morphology. Once a tree is formed, its leaves are assigned suitable lexical choices which are inflected by morphology rules. In the most basic situation, choices among syntactic alternatives and among possible lexical entries are made at random. In such a model, the semantic control exercised by attributes is minimal. They can, for example, ensure that the subject of a such as animate and its object edible, but they cannot influence the overall meaning of the utterance produced. To achieve this, VINCI makes use of preselections. 1.1 Preselections Preselections may be thought of as forming a metaphoric blackboard on which the person requiring an utterance writes some choices about its features. Lexical entries corresponding to these features are selected before the syntax tree is formed, and syntax rules have access both to the words themselves and to information about them obtained from the lexicon. We will illustrate this by showing the steps in the generation of a short fairy tale, although other sorts of texts are also possible. In a typical fairy tale we have a collection characters, including a pompous or a rich merchant), a heroine twit’s daughter), a sorcerer or a prince or a brave woodcutter), victim’s fairy godmother), a sword or a silver goblet). These form the basis for a set of preselections such as: twit : PN/&amp;quot;Midas&amp;quot;; victim: PN/ pre twit/@14: daughter; hero : PN[male, brave, handsome]; magicobj : N[physobj, magic] These preselections presuppose a database of characters/objects which are simply entries in a lexicon: &amp;quot;Midas&amp;quot;|PN| male, rich, weak, vain|... daughter: &amp;quot;Marie&amp;quot;;... type: &amp;quot;king&amp;quot;; ... home: &amp;quot;castle&amp;quot;; ... &amp;quot;Marie&amp;quot;|PN| female, beautiful, type: &amp;quot;princess&amp;quot;; ... Preselections can be specified with more or precision. In this example, only be chosen for the role of twit, but any member of the class PN (proper names) having the attributes male, brave and handsome can be selected as hero. We might well have writ- PN[rich]/@14: daughter making the twit any PN who is rich and has a pointer to a daughter in lexical field 14. These preselections are global, in that they persist across several utterances. If the hero is a prince in one sentence, he cannot be a woodcutter in the next. In contrast, the local preselections described below associate these characters with a semantic role in a particular sentence, for example, the agent or the patient. We can envisage a user typing/editing a global preselections file to select favorite characters for a story. Alternatively, there may be an interface which allows a user to choose characters from a set of menus. In the following tale, we assume that been preselected as the goodfairy sword magicobj. 1.2 Semantic Expressions A semantic expression is a representation of the content of an utterance in a form in which the grammatical constraints of any particular natural language have been abstracted away, leaving only some expression of meaning behind. A simple functional notation is used, described more fully in (Levison et al., 2001b). These expressions are transformed into VINCI preselections, triggering syntax rules which, in their turn, yield sentences in some language. The same sequence of expressions can transformed into paragraphs in different languages or different paragraphs in the same language. The plot for the fairy tale can be specified as a sequence of these expressions: exists(twit) Once upon a time there was a twit. describe(twit) He was rich and vain. exists(victim) The twit had a daughter, the victim. describe(victim) She was beautiful and kind. admonish(twit, victim, action) The twit warned the victim about walking in the forest. disobey(victim) However, the victim disobeyed. action(victim) She went for a walk in the forest. exists(villain) In the forest there lived a villain. describe(villain) He was strong and evil. kidnap(villain, victim) The villain kidnapped the victim. exists(hero) In the same area, there lived a hero. seekhelp(twit, hero) The twit sought his help. seek(hero, goodfairy) The hero went to find the goodfairy... give(goodfairy, hero, magicobj) who gave him a magicobj. seek(hero, villain) The hero sought the villain... kill(hero, villain, magicobj) and killed him with the magicobj. rescue(hero, victim) The hero rescued the victim, ... marry(hero, victim) married her, ... livehappily(hero, victim) and lived happily ever after. Obviously, the plot can be modified simply by varying the expressions. Indeed there might be alternative plots or sections, perhaps chosen by a user or produced by a text planner. Let us repeat that these expressions are language-independent. The names of the functions and parameters are, in fact, VINCI attributes, and although English words have been used here, any string of letters or digits could have been substituted. If a French grammar and lexicon is built using the same attributes, as give, ...|... VINCI can construct French sentences from the same semantic expressions. 1.3 Local Preselections Each of the expressions in the previous section is equivalent to and is transformed by VINCI into a set of local preselections which apply to the generation of a single sentence. For example, hero, magicobj) attribute selects a segment of syntax based on a verb with direct and act : V[give]; agent : PN/ pre goodfairy; beneficiary : PN/ pre hero; theme : N/ pre magicobj Some of these local preselections refer back to the global ones, associating the characters selected in the earlier preselections with the semantic roles they will play in the current sentence: agent, beneficiary and theme. So hence becomes the of the act of giving, becomes its theme, and beneficiary. In effect, semantic expressions provide a more user-friendly form for the set of preselections. Conversion from the former to the latter is effected by semantic transformations; for example: give : vtdi; act : V[give]; agent : PN/ pre #1; beneficiary : PN/ pre #2; theme : N/ pre #3 left-hand side matches In practice it shorter, if less elegant, to replace this semantic expression by goodfairy, hero, since this single expression can be used for any verb taking both direct and indirect objects. 1.4 Syntax Rules Syntax rules in Vinci take the abstract semantic representations produced by semantic expressions and preselections and clothe them in the syntax of the language chosen. Among other things, this allows the system to capture constraints on word order, argument structure, and agreement. This is accomplished by means of inheritance of attributes down the nodes of a syntax tree, and guarded syntax rules, in which attributes present on a parent node are used to determine the nature of child nodes. For example, given a parent node such as NP (noun phrase) containing the attribute ’p1’ (first person), a guarded syntax rule (these are headed the symbol will determine that the only possible child node is a pronoun. However, in the default case (these are headed by the symthe child may take either the form of a pronoun or a full noun phrase. Let us now return to the example of preselections developed above and resume with the action of syntax rules on the output of preselections and semantic expressions. The section of the context-free rules corresponding to vtdi describe the structure of a sentence with a vtdi verb in terms of the its agent, theme and beneficiary. Thus, assuming the local preselections given above: ROOT = &lt; _pre_ vtdi: NPP[sing, agent, def] V[p3, sing, past]/_pre_ act NPP[sing, beneficiary, def] NP[sing, theme, indef] % NPP = inherit Fn: Function, Nu: Number, De: Detkind; DET[De] N[Nu]/_pre_ Fn/@13:type % NP = inherit Fn: Function, Nu: Number, De: Detkind; DET[De] N[Nu]/_pre_ Fn % The root of the utterance (the top of its syntax tree) has four child nodes, two of them proper noun phrases (NPP), a third a common noun phrase (NP). To the first it passes a Number-value, sing, a Function-value, agent, and a Detkind-value. When this NPP is developed into its two children, it assigns these attribute values to Nu, Fn and De, passing De to (hence and Nu to the child noun, which will therefore be singular. This noun is also directed to obtain its lexical entry from the labelled which in refers to and hence to rather than using the chosen noun must be replaced the lexical indicated by tag type in field 13 The other noun phrases obtain their nouns similarly from beneficiary and theme, though the last (NP) uses the preselected magicobj directly. The root’s verb-child, which will be third person singular past tense, will obtain its lexical entry from the preselection labelled act. So, get: fairy godmother gave the prince a 1.5 Two Generated Stories Using a simple English lexicon and the grammar described above, VINCI generates fairy tales, of which the following is an intentionally short and simple example. Once upon a time there was a king called Midas who lived in a castle. He was rich and vain. The king had a daughter, a princess named Marie, who was beautiful. The king warned Marie not to go out of the castle. The princess disobeyed the king. She left the castle. A sorcerer called Merlin lived in the woods. He was evil. The sorcerer kidnapped the princess. Nearby there lived a woodcutter who was named Axel. The king sought the help of the woodcutter. The woodcutter went to look for the fairy godmother. The fairy godmother passed Axel a magic sword. Axel searched for the sorcerer. The woodcutter killed the sorcerer with the magic sword. The woodcutter rescued the princess. The woodcutter and the princess got married and lived happily ever after. When linked to a French lexicon, morphology and syntax, VINCI generates comparable texts in French, as the following example shows: Il ´etait une fois un roi qui s’appelait Midas et qui vivait dans un beau chˆateau. Il ´etait riche et vain. Le roi avait une fille: une princesse qui s’appelait Marie et qui ´etait belle. Le roi interdit a` Marie de quitter le chˆateau. La princesse d´esob´eit au roi. Elle quitta le chˆateau. Dans la fˆoret il y avait un sorcier qui s’appelait Merloc. Il ´etait m´echant. Le sorcier enleva la princesse. Aux alentours vivait un prince qui s’appelait Coeur de Lion et qui ´etait beau. Le roi demanda l’aide du prince. Le prince chercha la bonne f´ee. La bonne f´ee donna une ´ep´ee magique au prince. Le prince chercha le sorcier. Coeur de Lion utilisa l’´ep´ee magique pour tuer le sorcier. Le prince lib´era la princesse. Le prince ´epousa la princesse et ils eurent beaucoup d’enfants. Along with orthographic output, (Thomas, 2002) describes the generation of good quality prosodically controlled French oral output by linking VINCI with the MBROLA speech synthesizer (Dutoit, 2004). At this time, learner responses must still be entered orthographically. 1.6 Analysis of User Input As well as constructing the story, VINCI may produce a series of questions to put before a learner; for example: Question: What was the name of the good fairy? Expected (hidden) answer: The good fairy was called Wanda. Question: Describe Maria. Expected (hidden) answer: Maria was beautiful and kind. In French, whose complex morphology gives scope for more varied errors, a typical question such as: Question: O`u vivait le roi? and a reponse from a particularly incompetent learner (one of the authors), gives rise to the following error report: EXPECTED : le roi vivait dans un beau ch^ateau RESPONSE : la roi vivrait en une chapeau belle C4 DELETE dans S4 INSERT en C6 ORDER C7 C6 C1 S1 la/le MORPH f´em/masc C2 S2 EXACT C3 S3 vivrait/vivait MORPH cond/imparf C5 S5 une/un MORPH f´em/masc C6 S7 belle/beau MORPH f´em/masc C7 S6 APPROX chapeau/ch^ateau the learner had typed VINCI would have reported the change as LEX syn, tagged in the lexicon as a synfor If he had omitted the circumflex on the error would have been marked as PHON, since the two forms would have been similar in sound. This is made possible by the fact that in VINCI, lexical entries may carry both orthographic and phonological information. Output of the error analysis routines as shown above is not designed to be presented directly to a learner. However, since it is machinegenerated, it is relatively easy to parse by a routine which uses it to present error analyses in a more user-friendly format. At the same time, results of each analysis may be stored then used by a program build a user model, and to adaptively control subsequent generation (Levison et al., 2001a). In this way, VINCI’s architecture ’closes the loop’ in the traditional pipeline approach to generation, in that the output of analysis and diagnosis drives the input of textual planning. 2 Enhancements and Future Work VINCI’s use of semantic input by means of functional expressions is designed to allow it to function either as an autonomous narrative generation system (cf. (Callaway and Lester, 2001a), (Bringsjord and Ferrucci, 2000) for examples) or as a story authoring environment (cf. (Umaschi and Cassell, 1997)) in which a language teacher may select or construct highlevel utterance specifications, or alternatively, a learner may play with the order of a set of semantic specifications, or even add new characters with their own traits, examining in each case the texts produced. Two kinds of enhancements can be used to improve output. 2.1 Encyclopedic Enrichment In examples shown above, descriptions are based on simple static attributes (beauty, morality, etc.). In fact, VINCI’s compound attribute mechanism also allows for the expression of actions by characters. Thus, the attribute kill.monsters in the lexical entry for Braveheart might cause lead to: there lived a prince called Braveheart, who was renowned for killing monmechanism is also applicable to the expression of a character’s thoughts and attitudes, and past background information, both narrative desiderata (Bringsjord and Ferrucci, 2000), (Robin, 1993) as well as the generation more or less complex versions of the same text (cf. (Chali, 1998)). Work is underway on mechanisms for the dynamic temporal tagging of attributes, as a story develops. For example, a learner given $50 and instructed to purchase groceries in a textual supermarket would have his or her remaining money reduced by each purchase he or she describes. It should also be noted that the micro-world defined by means of Vinci may be fictional, as in the cases above, or based on real people and events. For example, we have performed experiments based on a database of French authors, their works, and their biographical details such as date of birth, death, etc. 2.2 Narrative Enrichment Appropriate use of anaphoric pronous and aggregation of sentences both have a significant effect on perceptions of text quality (Callaway and Lester, 2001b). In a number of systems, both processes occur after sentences have been realized, at the level of revision, which often requires that utterances be reformulated. We propose to perform comparable operations at the level of semantic expressions. Suppose two which generates an and generates brave and The fact that both expressions share a common argument allows for replacement by another, say which aggregates the two functions to produce was a brave and handsome Similarly, in the case of anaphoric relations, shared arguments allow for replacement of full names by pronouns. We are currently researching this. Finally, taking account of work by (Karamanis and Manurung, 2002) which shows that sharing of at least one argument characterizes a high percentage of successive sentences in a text, it is possible to use the sequence of arguments to order a sequence of semantic expressions. Perhaps more interestingly, it may be that one of the criteria of a new paragraph is a break in the chain of shared arguments from one semantic expression to the next. The paragraph breaks in the English and French texts above, while human-constructed, respect this constraint.</abstract>
<note confidence="0.7768042">References Bringsjord and D.A. Ferrucci. 2000. Artificial Intelligence and Literary Creativity: Inside the Mind of BRUTUS, a Storytelling Ma- London, Lawrence Erlbaum. C.B. Callaway and J.C. Lester. 2001a. Evaluating the effects of natural language generation techniques on reader satisfaction. In Proceedings of the 23rd Annual Conference of Cognitive Science pages 164–169. Edinburgh, UK. C.B. Callaway and J.C. Lester. 2001b. Narraprose generation. In of the Seventeenth International Joint Conference Artificial Intelligence (IJCAI pages 1241–1248. Seattle, WA. Y. Chali. 1998. Text expansion using causal temporal relations. In of the Third International Conference on Natural Language Processing and Industrial Applica-</note>
<address confidence="0.8175435">Moncton, New Brunswick. Dutoit. 2004. MBROLA</address>
<web confidence="0.947091">http://tcts.fpms.ac.be/synthesis/mbrola.html.</web>
<note confidence="0.831935181818182">N. Karamanis and H.M. Manurung. 2002. Stochastic text structuring using the princiof continuity. In of pages 81–88. Columbia University. M. Levison, G. Lessard, A-M. Danielson, and D. Merven. 2001a. From symptoms to diag- In (K. Cameron, editor, – The of pages 53–59. Elm Bank, Exeter. M. Levison, G. Lessard, B. Gottesman, and M. Stringer. 2001b. Semantic expressions:</note>
<abstract confidence="0.40774532">experiment. paper, found at: W. Menzel and I. Schroeder. 1998. Constraintbased diagnosis for intelligent language tusystems. In ITHKNOWS, XV. World Computer pages 484– 497. Vienna/Budapest. Michaud. 2002. User Interlanin a Second Language Tutoring System for Deaf Users of American Sign Lan- PhD Dissertation, Department of Computer and Information Sciences, University of Delaware. J. Robin. 1993. A revision-based generation architecture for reporting facts in their historical context. In M. Zock H. Horecek, editor, New Concepts in Natural Language Generapages 238–268. Pinter, London. Thomas. 2002. Prosodic Transcription for Natural Language MSc Thesis, Queen’s University, Kingston. M. Umaschi and J. Cassell. 1997. Storytelling systems: Constructing the innerface of the In Technologies Proceedpages 98–108. IEEE.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bringsjord</author>
<author>D A Ferrucci</author>
</authors>
<date>2000</date>
<booktitle>Artificial Intelligence and Literary Creativity: Inside the Mind of BRUTUS, a Storytelling Machine.</booktitle>
<location>London, Lawrence Erlbaum.</location>
<contexts>
<context position="16331" citStr="Bringsjord and Ferrucci, 2000" startWordPosition="2686" endWordPosition="2689">rmat. At the same time, results of each analysis may be stored and then used by a driver program to build a user model, and to adaptively control subsequent generation (Levison et al., 2001a). In this way, VINCI’s architecture ’closes the loop’ in the traditional pipeline approach to generation, in that the output of analysis and diagnosis drives the input of textual planning. 2 Enhancements and Future Work VINCI’s use of semantic input by means of functional expressions is designed to allow it to function either as an autonomous narrative generation system (cf. (Callaway and Lester, 2001a), (Bringsjord and Ferrucci, 2000) for examples) or as a story authoring environment (cf. (Umaschi and Cassell, 1997)) in which a language teacher may select or construct highlevel utterance specifications, or alternatively, a learner may play with the order of a set of semantic specifications, or even add new characters with their own traits, examining in each case the texts produced. Two kinds of enhancements can be used to improve output. 2.1 Encyclopedic Enrichment In examples shown above, descriptions are based on simple static attributes (beauty, morality, etc.). In fact, VINCI’s compound attribute mechanism also allows </context>
</contexts>
<marker>Bringsjord, Ferrucci, 2000</marker>
<rawString>S. Bringsjord and D.A. Ferrucci. 2000. Artificial Intelligence and Literary Creativity: Inside the Mind of BRUTUS, a Storytelling Machine. London, Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C B Callaway</author>
<author>J C Lester</author>
</authors>
<title>Evaluating the effects of natural language generation techniques on reader satisfaction.</title>
<date>2001</date>
<booktitle>In Proceedings of the 23rd Annual Conference of the Cognitive Science Society,</booktitle>
<pages>164--169</pages>
<location>Edinburgh, UK.</location>
<contexts>
<context position="16296" citStr="Callaway and Lester, 2001" startWordPosition="2682" endWordPosition="2685">ses in a more user-friendly format. At the same time, results of each analysis may be stored and then used by a driver program to build a user model, and to adaptively control subsequent generation (Levison et al., 2001a). In this way, VINCI’s architecture ’closes the loop’ in the traditional pipeline approach to generation, in that the output of analysis and diagnosis drives the input of textual planning. 2 Enhancements and Future Work VINCI’s use of semantic input by means of functional expressions is designed to allow it to function either as an autonomous narrative generation system (cf. (Callaway and Lester, 2001a), (Bringsjord and Ferrucci, 2000) for examples) or as a story authoring environment (cf. (Umaschi and Cassell, 1997)) in which a language teacher may select or construct highlevel utterance specifications, or alternatively, a learner may play with the order of a set of semantic specifications, or even add new characters with their own traits, examining in each case the texts produced. Two kinds of enhancements can be used to improve output. 2.1 Encyclopedic Enrichment In examples shown above, descriptions are based on simple static attributes (beauty, morality, etc.). In fact, VINCI’s compou</context>
<context position="18236" citStr="Callaway and Lester, 2001" startWordPosition="2997" endWordPosition="3000">ucted to purchase groceries in a textual supermarket would have his or her remaining money reduced by each purchase he or she describes. It should also be noted that the micro-world defined by means of Vinci may be fictional, as in the cases above, or based on real people and events. For example, we have performed experiments based on a database of French authors, their works, and their biographical details such as date of birth, death, etc. 2.2 Narrative Enrichment Appropriate use of anaphoric pronous and aggregation of sentences both have a significant effect on perceptions of text quality (Callaway and Lester, 2001b). In a number of systems, both processes occur after sentences have been realized, at the level of revision, which often requires that utterances be reformulated. We propose to perform comparable operations at the level of semantic expressions. Suppose two functions: exists(X), which generates There was an X, and describe(X) which generates X was brave and handsome. The fact that both expressions share a common argument allows for their replacement by another, say exdesc(X), which aggregates the two functions to produce There was a brave and handsome X. Similarly, in the case of anaphoric re</context>
</contexts>
<marker>Callaway, Lester, 2001</marker>
<rawString>C.B. Callaway and J.C. Lester. 2001a. Evaluating the effects of natural language generation techniques on reader satisfaction. In Proceedings of the 23rd Annual Conference of the Cognitive Science Society, pages 164–169. Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C B Callaway</author>
<author>J C Lester</author>
</authors>
<title>Narrative prose generation.</title>
<date>2001</date>
<booktitle>In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence (IJCAI</booktitle>
<pages>1241--1248</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="16296" citStr="Callaway and Lester, 2001" startWordPosition="2682" endWordPosition="2685">ses in a more user-friendly format. At the same time, results of each analysis may be stored and then used by a driver program to build a user model, and to adaptively control subsequent generation (Levison et al., 2001a). In this way, VINCI’s architecture ’closes the loop’ in the traditional pipeline approach to generation, in that the output of analysis and diagnosis drives the input of textual planning. 2 Enhancements and Future Work VINCI’s use of semantic input by means of functional expressions is designed to allow it to function either as an autonomous narrative generation system (cf. (Callaway and Lester, 2001a), (Bringsjord and Ferrucci, 2000) for examples) or as a story authoring environment (cf. (Umaschi and Cassell, 1997)) in which a language teacher may select or construct highlevel utterance specifications, or alternatively, a learner may play with the order of a set of semantic specifications, or even add new characters with their own traits, examining in each case the texts produced. Two kinds of enhancements can be used to improve output. 2.1 Encyclopedic Enrichment In examples shown above, descriptions are based on simple static attributes (beauty, morality, etc.). In fact, VINCI’s compou</context>
<context position="18236" citStr="Callaway and Lester, 2001" startWordPosition="2997" endWordPosition="3000">ucted to purchase groceries in a textual supermarket would have his or her remaining money reduced by each purchase he or she describes. It should also be noted that the micro-world defined by means of Vinci may be fictional, as in the cases above, or based on real people and events. For example, we have performed experiments based on a database of French authors, their works, and their biographical details such as date of birth, death, etc. 2.2 Narrative Enrichment Appropriate use of anaphoric pronous and aggregation of sentences both have a significant effect on perceptions of text quality (Callaway and Lester, 2001b). In a number of systems, both processes occur after sentences have been realized, at the level of revision, which often requires that utterances be reformulated. We propose to perform comparable operations at the level of semantic expressions. Suppose two functions: exists(X), which generates There was an X, and describe(X) which generates X was brave and handsome. The fact that both expressions share a common argument allows for their replacement by another, say exdesc(X), which aggregates the two functions to produce There was a brave and handsome X. Similarly, in the case of anaphoric re</context>
</contexts>
<marker>Callaway, Lester, 2001</marker>
<rawString>C.B. Callaway and J.C. Lester. 2001b. Narrative prose generation. In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence (IJCAI 2001), pages 1241–1248. Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Chali</author>
</authors>
<title>Text expansion using causal and temporal relations.</title>
<date>1998</date>
<booktitle>In Proceedings of the Third International Conference on Natural Language Processing and Industrial Applications.</booktitle>
<location>Moncton, New Brunswick.</location>
<contexts>
<context position="17466" citStr="Chali, 1998" startWordPosition="2869" endWordPosition="2870">, morality, etc.). In fact, VINCI’s compound attribute mechanism also allows for the expression of actions by characters. Thus, the attribute kill.monsters in the lexical entry for Prince Braveheart might cause exists(hero) to lead to: Nearby there lived a prince called Braveheart, who was renowned for killing monsters. This mechanism is also applicable to the expression of a character’s thoughts and attitudes, and past background information, both narrative desiderata (Bringsjord and Ferrucci, 2000), (Robin, 1993) as well as the generation more or less complex versions of the same text (cf. (Chali, 1998)). Work is underway on mechanisms for the dynamic temporal tagging of attributes, as a story develops. For example, a learner given $50 and instructed to purchase groceries in a textual supermarket would have his or her remaining money reduced by each purchase he or she describes. It should also be noted that the micro-world defined by means of Vinci may be fictional, as in the cases above, or based on real people and events. For example, we have performed experiments based on a database of French authors, their works, and their biographical details such as date of birth, death, etc. 2.2 Narra</context>
</contexts>
<marker>Chali, 1998</marker>
<rawString>Y. Chali. 1998. Text expansion using causal and temporal relations. In Proceedings of the Third International Conference on Natural Language Processing and Industrial Applications. Moncton, New Brunswick.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dutoit</author>
</authors>
<date>2004</date>
<note>The MBROLA Project. http://tcts.fpms.ac.be/synthesis/mbrola.html.</note>
<contexts>
<context position="14071" citStr="Dutoit, 2004" startWordPosition="2307" endWordPosition="2308">Le sorcier enleva la princesse. Aux alentours vivait un prince qui s’appelait Coeur de Lion et qui ´etait beau. Le roi demanda l’aide du prince. Le prince chercha la bonne f´ee. La bonne f´ee donna une ´ep´ee magique au prince. Le prince chercha le sorcier. Coeur de Lion utilisa l’´ep´ee magique pour tuer le sorcier. Le prince lib´era la princesse. Le prince ´epousa la princesse et ils eurent beaucoup d’enfants. Along with orthographic output, (Thomas, 2002) describes the generation of good quality prosodically controlled French oral output by linking VINCI with the MBROLA speech synthesizer (Dutoit, 2004). At this time, learner responses must still be entered orthographically. 1.6 Analysis of User Input As well as constructing the story, VINCI may produce a series of questions to put before a learner; for example: Question: What was the name of the good fairy? Expected (hidden) answer: The good fairy was called Wanda. Question: Describe Maria. Expected (hidden) answer: Maria was beautiful and kind. In French, whose complex morphology gives scope for more varied errors, a typical question such as: Question: O`u vivait le roi? and a reponse from a particularly incompetent learner (one of the aut</context>
</contexts>
<marker>Dutoit, 2004</marker>
<rawString>T. Dutoit. 2004. The MBROLA Project. http://tcts.fpms.ac.be/synthesis/mbrola.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Karamanis</author>
<author>H M Manurung</author>
</authors>
<title>Stochastic text structuring using the principle of continuity.</title>
<date>2002</date>
<booktitle>In Proceedings of INLG-02,</booktitle>
<pages>81--88</pages>
<institution>Columbia University.</institution>
<marker>Karamanis, Manurung, 2002</marker>
<rawString>N. Karamanis and H.M. Manurung. 2002. Stochastic text structuring using the principle of continuity. In Proceedings of INLG-02, pages 81–88. Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Levison</author>
<author>G Lessard</author>
<author>A-M Danielson</author>
<author>D Merven</author>
</authors>
<title>From symptoms to diagnosis. In</title>
<date>2001</date>
<booktitle>The Challenge of Change,</booktitle>
<pages>53--59</pages>
<editor>K. Cameron, editor, CALL –</editor>
<location>Exeter.</location>
<contexts>
<context position="5938" citStr="Levison et al., 2001" startWordPosition="956" endWordPosition="959">lobal preselections file to select favorite characters for a story. Alternatively, there may be an interface which allows a user to choose characters from a set of menus. In the following tale, we assume that Wanda has been preselected as the goodfairy and magic sword as magicobj. 1.2 Semantic Expressions A semantic expression is a representation of the content of an utterance in a form in which the grammatical constraints of any particular natural language have been abstracted away, leaving only some expression of meaning behind. A simple functional notation is used, described more fully in (Levison et al., 2001b). These expressions are transformed into VINCI preselections, triggering syntax rules which, in their turn, yield sentences in some language. The same sequence of expressions can transformed into paragraphs in different languages or different paragraphs in the same language. The plot for the fairy tale can be specified as a sequence of these expressions: exists(twit) Once upon a time there was a twit. describe(twit) He was rich and vain. exists(victim) The twit had a daughter, the victim. describe(victim) She was beautiful and kind. admonish(twit, victim, action) The twit warned the victim a</context>
<context position="15890" citStr="Levison et al., 2001" startWordPosition="2618" endWordPosition="2621">ce the two forms would have been similar in sound. This is made possible by the fact that in VINCI, lexical entries may carry both orthographic and phonological information. Output of the error analysis routines as shown above is not designed to be presented directly to a learner. However, since it is machinegenerated, it is relatively easy to parse by a routine which uses it to present error analyses in a more user-friendly format. At the same time, results of each analysis may be stored and then used by a driver program to build a user model, and to adaptively control subsequent generation (Levison et al., 2001a). In this way, VINCI’s architecture ’closes the loop’ in the traditional pipeline approach to generation, in that the output of analysis and diagnosis drives the input of textual planning. 2 Enhancements and Future Work VINCI’s use of semantic input by means of functional expressions is designed to allow it to function either as an autonomous narrative generation system (cf. (Callaway and Lester, 2001a), (Bringsjord and Ferrucci, 2000) for examples) or as a story authoring environment (cf. (Umaschi and Cassell, 1997)) in which a language teacher may select or construct highlevel utterance sp</context>
</contexts>
<marker>Levison, Lessard, Danielson, Merven, 2001</marker>
<rawString>M. Levison, G. Lessard, A-M. Danielson, and D. Merven. 2001a. From symptoms to diagnosis. In (K. Cameron, editor, CALL – The Challenge of Change, pages 53–59. Elm Bank, Exeter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Levison</author>
<author>G Lessard</author>
<author>B Gottesman</author>
<author>M Stringer</author>
</authors>
<title>Semantic expressions: An experiment. Working paper, found at: http://www.cs.queensu.ca/CompLing/ semanticexpressions.html.</title>
<date>2001</date>
<contexts>
<context position="5938" citStr="Levison et al., 2001" startWordPosition="956" endWordPosition="959">lobal preselections file to select favorite characters for a story. Alternatively, there may be an interface which allows a user to choose characters from a set of menus. In the following tale, we assume that Wanda has been preselected as the goodfairy and magic sword as magicobj. 1.2 Semantic Expressions A semantic expression is a representation of the content of an utterance in a form in which the grammatical constraints of any particular natural language have been abstracted away, leaving only some expression of meaning behind. A simple functional notation is used, described more fully in (Levison et al., 2001b). These expressions are transformed into VINCI preselections, triggering syntax rules which, in their turn, yield sentences in some language. The same sequence of expressions can transformed into paragraphs in different languages or different paragraphs in the same language. The plot for the fairy tale can be specified as a sequence of these expressions: exists(twit) Once upon a time there was a twit. describe(twit) He was rich and vain. exists(victim) The twit had a daughter, the victim. describe(victim) She was beautiful and kind. admonish(twit, victim, action) The twit warned the victim a</context>
<context position="15890" citStr="Levison et al., 2001" startWordPosition="2618" endWordPosition="2621">ce the two forms would have been similar in sound. This is made possible by the fact that in VINCI, lexical entries may carry both orthographic and phonological information. Output of the error analysis routines as shown above is not designed to be presented directly to a learner. However, since it is machinegenerated, it is relatively easy to parse by a routine which uses it to present error analyses in a more user-friendly format. At the same time, results of each analysis may be stored and then used by a driver program to build a user model, and to adaptively control subsequent generation (Levison et al., 2001a). In this way, VINCI’s architecture ’closes the loop’ in the traditional pipeline approach to generation, in that the output of analysis and diagnosis drives the input of textual planning. 2 Enhancements and Future Work VINCI’s use of semantic input by means of functional expressions is designed to allow it to function either as an autonomous narrative generation system (cf. (Callaway and Lester, 2001a), (Bringsjord and Ferrucci, 2000) for examples) or as a story authoring environment (cf. (Umaschi and Cassell, 1997)) in which a language teacher may select or construct highlevel utterance sp</context>
</contexts>
<marker>Levison, Lessard, Gottesman, Stringer, 2001</marker>
<rawString>M. Levison, G. Lessard, B. Gottesman, and M. Stringer. 2001b. Semantic expressions: An experiment. Working paper, found at: http://www.cs.queensu.ca/CompLing/ semanticexpressions.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Menzel</author>
<author>I Schroeder</author>
</authors>
<title>Constraintbased diagnosis for intelligent language tutoring systems.</title>
<date>1998</date>
<booktitle>In Proc. ITHKNOWS, XV. IFIP World Computer Congress,</booktitle>
<pages>484--497</pages>
<publisher>Vienna/Budapest.</publisher>
<contexts>
<context position="1070" citStr="Menzel and Schroeder, 1998" startWordPosition="145" endWordPosition="148">es representing an initial text, questions on this text, and expected answers, and either orthographic or phonetic output. Analyses of a learner’s answers to questions are used to diagnose comprehension and language skills and to adaptively control subsequent generation. The paper traces stages in the generation of short texts in English and French, and discusses issues of architecture, textual enrichment, and planning. 1 VINCI: Architecture, Implementation and Output Ideally, a language teaching system should both “encourage the creative use of language in communicatively relevant settings” (Menzel and Schroeder, 1998) and also provide detailed and adaptive feedback (cf. (Michaud, 2002)). Many systems resolve the issue by means of complex parsing. In what follows, we describe VINCI, a multilingual generation environment which represents a complementary approach in that it assumes conversational control, dynamically producing more or less complex texts and asking information of users. VINCI is based on a collection of metalanguages which define the semantics, syntax, lexicon and morphology of a language. Text files defining the language are read by an interpreter (written in C) and output is presented either</context>
</contexts>
<marker>Menzel, Schroeder, 1998</marker>
<rawString>W. Menzel and I. Schroeder. 1998. Constraintbased diagnosis for intelligent language tutoring systems. In Proc. ITHKNOWS, XV. IFIP World Computer Congress, pages 484– 497. Vienna/Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L N Michaud</author>
</authors>
<title>Modeling User Interlanguage in a Second Language Tutoring System for Deaf Users of American Sign Language.</title>
<date>2002</date>
<tech>PhD Dissertation,</tech>
<institution>Department of Computer and Information Sciences, University of Delaware.</institution>
<contexts>
<context position="1139" citStr="Michaud, 2002" startWordPosition="157" endWordPosition="158"> either orthographic or phonetic output. Analyses of a learner’s answers to questions are used to diagnose comprehension and language skills and to adaptively control subsequent generation. The paper traces stages in the generation of short texts in English and French, and discusses issues of architecture, textual enrichment, and planning. 1 VINCI: Architecture, Implementation and Output Ideally, a language teaching system should both “encourage the creative use of language in communicatively relevant settings” (Menzel and Schroeder, 1998) and also provide detailed and adaptive feedback (cf. (Michaud, 2002)). Many systems resolve the issue by means of complex parsing. In what follows, we describe VINCI, a multilingual generation environment which represents a complementary approach in that it assumes conversational control, dynamically producing more or less complex texts and asking information of users. VINCI is based on a collection of metalanguages which define the semantics, syntax, lexicon and morphology of a language. Text files defining the language are read by an interpreter (written in C) and output is presented either orthographically or phonetically. When used in a teaching context, V</context>
</contexts>
<marker>Michaud, 2002</marker>
<rawString>L.N. Michaud. 2002. Modeling User Interlanguage in a Second Language Tutoring System for Deaf Users of American Sign Language. PhD Dissertation, Department of Computer and Information Sciences, University of Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Robin</author>
</authors>
<title>A revision-based generation architecture for reporting facts in their historical context.</title>
<date>1993</date>
<booktitle>New Concepts in Natural Language Generation,</booktitle>
<pages>238--268</pages>
<editor>In M. Zock H. Horecek, editor,</editor>
<publisher>Pinter,</publisher>
<location>London.</location>
<contexts>
<context position="17374" citStr="Robin, 1993" startWordPosition="2852" endWordPosition="2853">richment In examples shown above, descriptions are based on simple static attributes (beauty, morality, etc.). In fact, VINCI’s compound attribute mechanism also allows for the expression of actions by characters. Thus, the attribute kill.monsters in the lexical entry for Prince Braveheart might cause exists(hero) to lead to: Nearby there lived a prince called Braveheart, who was renowned for killing monsters. This mechanism is also applicable to the expression of a character’s thoughts and attitudes, and past background information, both narrative desiderata (Bringsjord and Ferrucci, 2000), (Robin, 1993) as well as the generation more or less complex versions of the same text (cf. (Chali, 1998)). Work is underway on mechanisms for the dynamic temporal tagging of attributes, as a story develops. For example, a learner given $50 and instructed to purchase groceries in a textual supermarket would have his or her remaining money reduced by each purchase he or she describes. It should also be noted that the micro-world defined by means of Vinci may be fictional, as in the cases above, or based on real people and events. For example, we have performed experiments based on a database of French autho</context>
</contexts>
<marker>Robin, 1993</marker>
<rawString>J. Robin. 1993. A revision-based generation architecture for reporting facts in their historical context. In M. Zock H. Horecek, editor, New Concepts in Natural Language Generation, pages 238–268. Pinter, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Thomas</author>
</authors>
<title>A Prosodic Transcription Method for Natural Language Generation. MSc Thesis,</title>
<date>2002</date>
<institution>Queen’s University,</institution>
<location>Kingston.</location>
<contexts>
<context position="13920" citStr="Thomas, 2002" startWordPosition="2285" endWordPosition="2286"> le chˆateau. La princesse d´esob´eit au roi. Elle quitta le chˆateau. Dans la fˆoret il y avait un sorcier qui s’appelait Merloc. Il ´etait m´echant. Le sorcier enleva la princesse. Aux alentours vivait un prince qui s’appelait Coeur de Lion et qui ´etait beau. Le roi demanda l’aide du prince. Le prince chercha la bonne f´ee. La bonne f´ee donna une ´ep´ee magique au prince. Le prince chercha le sorcier. Coeur de Lion utilisa l’´ep´ee magique pour tuer le sorcier. Le prince lib´era la princesse. Le prince ´epousa la princesse et ils eurent beaucoup d’enfants. Along with orthographic output, (Thomas, 2002) describes the generation of good quality prosodically controlled French oral output by linking VINCI with the MBROLA speech synthesizer (Dutoit, 2004). At this time, learner responses must still be entered orthographically. 1.6 Analysis of User Input As well as constructing the story, VINCI may produce a series of questions to put before a learner; for example: Question: What was the name of the good fairy? Expected (hidden) answer: The good fairy was called Wanda. Question: Describe Maria. Expected (hidden) answer: Maria was beautiful and kind. In French, whose complex morphology gives scope</context>
</contexts>
<marker>Thomas, 2002</marker>
<rawString>C. Thomas. 2002. A Prosodic Transcription Method for Natural Language Generation. MSc Thesis, Queen’s University, Kingston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Umaschi</author>
<author>J Cassell</author>
</authors>
<title>Storytelling systems: Constructing the innerface of the interface.</title>
<date>1997</date>
<booktitle>In Cognitive Technologies Proceedings ’97,</booktitle>
<pages>98--108</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="16414" citStr="Umaschi and Cassell, 1997" startWordPosition="2700" endWordPosition="2703">r program to build a user model, and to adaptively control subsequent generation (Levison et al., 2001a). In this way, VINCI’s architecture ’closes the loop’ in the traditional pipeline approach to generation, in that the output of analysis and diagnosis drives the input of textual planning. 2 Enhancements and Future Work VINCI’s use of semantic input by means of functional expressions is designed to allow it to function either as an autonomous narrative generation system (cf. (Callaway and Lester, 2001a), (Bringsjord and Ferrucci, 2000) for examples) or as a story authoring environment (cf. (Umaschi and Cassell, 1997)) in which a language teacher may select or construct highlevel utterance specifications, or alternatively, a learner may play with the order of a set of semantic specifications, or even add new characters with their own traits, examining in each case the texts produced. Two kinds of enhancements can be used to improve output. 2.1 Encyclopedic Enrichment In examples shown above, descriptions are based on simple static attributes (beauty, morality, etc.). In fact, VINCI’s compound attribute mechanism also allows for the expression of actions by characters. Thus, the attribute kill.monsters in t</context>
</contexts>
<marker>Umaschi, Cassell, 1997</marker>
<rawString>M. Umaschi and J. Cassell. 1997. Storytelling systems: Constructing the innerface of the interface. In Cognitive Technologies Proceedings ’97, pages 98–108. IEEE.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>