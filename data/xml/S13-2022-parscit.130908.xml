<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026489">
<title confidence="0.994595">
BUAP: N-gram based Feature Evaluation for the Cross-Lingual Textual
Entailment Task
</title>
<author confidence="0.993171">
Darnes Vilari˜no, David Pinto, Sa´ul Le´on, Yuridiana Alem´an, Helena G´omez-Adorno
</author>
<affiliation confidence="0.9938065">
Benem´erita Universidad Aut´onoma de Puebla
Faculty of Computer Science
</affiliation>
<address confidence="0.9828335">
14 Sur y Av. San Claudio, CU
Puebla, Puebla, M´exico
</address>
<email confidence="0.966547">
{darnes, dpinto, saul.leon, candy.aleman, helena.gomez}@cs.buap.mx
</email>
<sectionHeader confidence="0.998497" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999875157894737">
This paper describes the evaluation of differ-
ent kinds of textual features for the Cross-
Lingual Textual Entailment Task of SemEval
2013. We have counted the number of N-
grams for three types of textual entities (char-
acter, word and PoS tags) that exist in the
pair of sentences from which we are inter-
ested in determining the judgment of textual
entailment. Difference, intersection and dis-
tance (Euclidian, Manhattan and Jaccard) of
N-grams were considered for constructing a
feature vector which is further introduced in
a support vector machine classifier which al-
lows to construct a classification model. Five
different runs were submitted, one of them
considering voting system of the previous four
approaches. The results obtained show a per-
formance below the median of six teams that
have participated in the competition.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999922444444444">
The cross-lingual textual entailment (CLTE), re-
cently proposed by (Mehdad et al., 2012) and
(Mehdad et al., 2011), is an extension of the tex-
tual entailment task (Dagan and Glickman, 2004).
Formally speaking, given a pair of topically related
text fragments (T1 and T2 which are assumed to
be TRUE statements) written in different languages,
the CLTE task consists of automatically annotating
it with one of the following entailment judgments:
</bodyText>
<listItem confidence="0.9961135">
• bidirectional (T1 -4 T2 &amp; T1 &lt;-- T2): the two
fragments entail each other (semantic equiva-
lence);
• forward (T1 -4 T2 &amp; T1 �w- T2): unidirec-
tional entailment from T1 to T2;
• backward (T1 -/-&gt; T2 &amp; T1 &lt;-- T2): unidirec-
tional entailment from T2 to T1;
• no entailment (T1 -/-&gt; T2 &amp; T1 �w- T2): there
is no entailment between T1 and T2 in both
directions;
</listItem>
<bodyText confidence="0.928956">
The Cross-lingual datasets evaluated were avail-
able for the following language combinations (T1-
T2):
</bodyText>
<listItem confidence="0.99987425">
• Spanish-English (SPA-ENG)
• German-English (DEU-ENG)
• Italian-English (ITA-ENG)
• French-English (FRA-ENG)
</listItem>
<bodyText confidence="0.9991035">
In this paper we describe the evaluation of differ-
ent features extracted from each pair of topically re-
lated sentences. N-grams of characters, words and
PoS tags were counted with the aim of constructing
a representative vector for each judgment entailment
(FORWARD, BACKWARD, BI-DIRECTIONAL or
NO-ENTAILMENT). The resulting vectors were
fed into a supervised classifier based on Support
Vector Machines (SVM)1 which attempted to con-
struct a classification model. The description of the
features and the vectorial representation is given in
Section 2. The obtained results are shown and di-
cussed in Section 3. Finally, the findings of this
work are given in Section 4.
</bodyText>
<footnote confidence="0.996669">
1We have employed the implementation of the Weka tool
(Hall et al., 2009).
</footnote>
<page confidence="0.925711">
124
</page>
<bodyText confidence="0.7605155">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 124–127, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.992539" genericHeader="method">
2 Experimental Setup
</sectionHeader>
<bodyText confidence="0.994189705882353">
We have considered the task as a classification prob-
lem using the pivot approach. Thus, we have trans-
lated2 each pair to their corresponding language in
order to have two pairs of sentences written in the
same language. Let Pair(T1, T2) be the origi-
nal pair of topically related sentences. Then, we
have obtained the English translation of T1, de-
noted by T3, which will be aligned with T2. On
the other hand, we have translated T2 to the other
language (Spanish, German, Italian or French), de-
noted by T4, which will be aligned with T1. The
two pairs of sentences, Pair(T2, T3) (English) and
Pair(T1,T4) (other language), are now written in
the same language, and we can proceed to calculate
the textual features we are interested in.
The features used to represent both sentences are
described below:
</bodyText>
<listItem confidence="0.945169090909091">
• N-grams of characters, with N = 2, · · · , 5.
• N-grams of words, with N = 2, · · · , 4.
• N-grams of PoS tags, with N = 2, · · · , 4.
• Euclidean measure between each pair of sen-
tences (Pair(T1, T4) and Pair(T2, T3)).
• Manhattan measure between each pair of sen-
tences (Pair(T1, T4) and Pair(T2, T3)).
• Jaccard coefficient, expanding English terms in
both sentences, T2 and T3, with their corre-
sponding synonyms (none disambiguation pro-
cess was considered).
</listItem>
<bodyText confidence="0.997467666666667">
The manner we have used the above mentioned
features is described in detail in the following sub-
sections.
</bodyText>
<subsectionHeader confidence="0.996204">
2.1 Approach 1: Difference operator
</subsectionHeader>
<bodyText confidence="0.902135125">
For each pair of sentences written in the same lan-
guage, this approach counts the number of N-grams
that occur in the first sentence (for instance T1), and
do not occur in the second sentence (for instance
T4) and viceversa. Formally speaking, the values
−−−→
obtained are P air(T1, T2) = {D1, D2, · · · , DO,
with D1 = |T1 − T4|, D2 = |T4 − T1|, D3 =
</bodyText>
<footnote confidence="0.966987">
2For this purpose we have used Google Translate
</footnote>
<tableCaption confidence="0.9266335">
Table 1: Classes considered in the composition of binary
classifiers
</tableCaption>
<figure confidence="0.824575909090909">
Class 1 Class 2
BACKWARD OTHER
BI-DIRECTIONAL OTHER
FORWARD OTHER
NO-ENTAILMENT OTHER
BACKWARD &amp; BI-DIRECTIONAL OTHER
BACKWARD &amp; FORWARD OTHER
BACKWARD &amp; NO-ENTAILMENT OTHER
BI-DIRECTIONAL &amp; NO-ENTAILMENT OTHER
FORWARD &amp; BI-DIRECTIONAL OTHER
FORWARD &amp; NO-ENTAILMENT OTHER
</figure>
<bodyText confidence="0.995279933333334">
|T2 − T3|, D4 = |T3 − T2|, · · ·. This vector is
calculated for all the possible values of N for each
type of N-gram, i.e., character, word and PoS tag.
The cardinality of −−−→
P air(T1, T2) will be 34, that is,
16 values when the N-grams of characters are con-
sidered, 12 values with word N-grams, and 6 values
when the PoS tag N-grams are used.
The vectors obtained are labeled with the corre-
sponding tag in order to construct a training dataset
which will be further used to feed a multiclass clas-
sifier which constructs the final classification model.
In this case, the system will directly return one of the
four valid entailment judgments (i.e. forward, back-
ward, bidirectional, no entailment).
</bodyText>
<subsectionHeader confidence="0.839116">
2.2 Approach 2: Difference and Intersection
operators
</subsectionHeader>
<bodyText confidence="0.932591714285714">
This approach enriches the previous one, by adding
the intersection between the two sentences of each
pair. In a sense, we have considered all the features
appearing in the pair of sentences. In this case, the
total number of features extracted, i.e., the cardinal-
−−−→
ity of the P air(T1, T2) vector is 51.
</bodyText>
<subsectionHeader confidence="0.999114">
2.3 Approach 3: Metaclassifier
</subsectionHeader>
<bodyText confidence="0.999941727272727">
In this approach, we have constructed a system
which is a composition of different binary classifica-
tion models. The binary judgments were constructed
considering the classes shown in Table 1.
The approach 2 was also considered in this com-
position generating a total of 11 models. 10 of them
are based on the features used by Approach 1, and
the last one is based on the features used by Ap-
proach 2. The result obtained is a vector which tells
whether or not a pair is judged to have some kind of
textual entailment or not (the OTHER class). This
</bodyText>
<page confidence="0.994225">
125
</page>
<bodyText confidence="0.999957857142857">
vector is then labeled with the correct class obtained
from the gold standard (training corpus) for auto-
matically obtaining a decision tree which allows us
to determine the correct class. Thus, the different
outputs of multiple classifiers are then introduced to
another supervised classifier which constructs the fi-
nal classification model.
</bodyText>
<subsectionHeader confidence="0.997573">
2.4 Approach 4: Distances measures
</subsectionHeader>
<bodyText confidence="0.999542333333333">
This approach is constructed by adding five distance
values to the Approach 2. These values are calcu-
lated as follows:
</bodyText>
<listItem confidence="0.997710111111111">
• The Euclidean distance between T2 and T3,
and between T1 and T4. We have used the fre-
quency of each word for constructing a repre-
sentative vector of each sentence.
• The Manhattan distance between T2 and T3,
and between T1 and T4. We have used the fre-
quency of each word for constructing a repre-
sentative vector of each sentence.
• A variant of the Jaccard’s Coefficient that con-
</listItem>
<bodyText confidence="0.967226714285714">
sider synonyms (Carrillo et al., 2012). Since we
have only obtained synonyms for the English
language, this measure was only calculated be-
tween T2 and T3.
Therefore, the total number of features of the
����
� ���(T1,T2) vector is 56.
</bodyText>
<subsectionHeader confidence="0.987493">
2.5 Approach 5: Voting system
</subsectionHeader>
<bodyText confidence="0.999451333333333">
With the results of the previous four models, we pre-
pared a voting system which uses the majority crite-
rion (3 of 4).
</bodyText>
<sectionHeader confidence="0.99717" genericHeader="method">
3 Experimental results
</sectionHeader>
<bodyText confidence="0.999945">
The results obtained in the competition are presented
and discussed in this section. First, we describe the
training and test corpus, and thereafter, the results
obtained with the different approaches submitted.
</bodyText>
<subsectionHeader confidence="0.976449">
3.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999846833333333">
In order to train the different approaches already dis-
cussed, we have constructed a training corpus made
up of two datasets: the training data provided by the
task organizers the task 8 of SemEval 2013 (Negri
et al., 2013), and the test dataset together with the
gold standard of CLTE task of SemEval 2012 (Ne-
gri et al., 2011). Thus, the training corpus contains
4000 sentence pairs. The test set provided in the
competition contains 2000 sentence pairs. The cor-
pus is balanced, with 1000 pairs for each language
in the training dataset, whereas, 500 pairs are given
in the test set for each language (see Table 2).
</bodyText>
<tableCaption confidence="0.996551">
Table 2: Description of the dataset
</tableCaption>
<table confidence="0.995981333333333">
Languages Training Test
SPA-ENG 1000 500
DEU-ENG 1000 500
ITA-ENG 1000 500
FRA-ENG 1000 500
Total 4000 2000
</table>
<subsectionHeader confidence="0.86672">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999982166666667">
In Table 3 we can see the results obtained by each
one of the five approaches we submitted to the com-
petition. Each approach has been labeled with the
prefix “BUAP-R” for indicating the approach used
by each submitted run. For instance, the BUAP-R1
run corresponds to the approach 1 described in the
previous section. As can be seen, the behavior of the
five approaches is quite similar, which we consider
it is expected because the underlying methodology
employed is almost the same for all the approaches.
With exception of the pair of sentences written in
SPA-ENG in which the best approach was obtained
by the BUAP-R5 run, the approach 4 outperformed
the other appproaches. We believe that this has been
a result of introducing measures of similarity be-
tween the two sentences and their translations. In
this table it is also reported the Highest, Average,
Median and Lowest values of the competition. The
results we obtained are under the Median but outper-
formed the results of two teams in the competition.
With the purpose of analyzing the behavior of the
approach 4 in each one of the entailment judgments,
we have provided the results obtained in Table 4.
There we can see that the BACKWARD class is the
easiest one for being predicted, independently of the
language. The second easiest class is FORWARD,
followed by NO-ENTAILMENT. Also we can see
that the BI-DIRECTIONAL class is the one that pro-
duce more confusion, thus leading to obtain a lower
performance than the other ones.
</bodyText>
<page confidence="0.999098">
126
</page>
<tableCaption confidence="0.9795965">
Table 3: Overall statistics obtained in the Task-8 of Se-
mEval 2013
</tableCaption>
<table confidence="0.998683454545455">
RUN SPA- ITA- FRA- DEU-
ENG ENG ENG ENG
Highest 0.434 0.454 0.458 0.452
Average 0.393 0.393 0.401 0.375
Median 0.392 0.402 0.416 0.369
Lowest 0.340 0.324 0.334 0.316
BUAP-R1 0.364 0.358 0.368 0.322
BUAP-R2 0.374 0.358 0.364 0.318
BUAP-R3 0.380 0.358 0.362 0.316
BUAP-R4 0.364 0.388 0.392 0.350
BUAP-R5 0.386 0.360 0.372 0.318
</table>
<tableCaption confidence="0.982498">
Table 4: Statistics of the approach 4, detailed by entail-
ment judgment
</tableCaption>
<table confidence="0.999297333333333">
ENTAILMENT SPA- ITA- FRA- DEU-
JUDGEMENT ENG ENG ENG ENG
BACKWARD 0.495 0.462 0.431 0.389
FORWARD 0.374 0.418 0.407 0.364
NO-ENTAILMENT 0.359 0.379 0.379 0.352
BI-DIRECTIONAL 0.277 0.327 0.352 0.317
</table>
<sectionHeader confidence="0.999606" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.99992125">
Five different approaches for the Cross-lingual Tex-
tual Entailment for the Content Synchronization task
of Semeval 2013 are reported in this paper. We used
several features for determining the textual entail-
ment judgment between two texts T1 and T2 (writ-
ten in two different languages). The approach 4
proposed, which employed lexical similarity and se-
mantic similarity in English language only was the
one that performed better. As future work, we would
like to include more distance metrics which allow to
extract additional features of the pair of sentences
topically related.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999571285714286">
Maya Carrillo, Darnes Vilari˜no, David Pinto,
Mireya Tovar, Saul Le´on, and Esteban Castillo.
Fcc: Three approaches for semantic textual sim-
ilarity. In *SEM 2012: The First Joint Confer-
ence on Lexical and Computational Semantics –
Volume 1 and 2 (SemEval 2012), pages 631–634,
Montr´eal, Canada, 7-8 June 2012. Association for
Computational Linguistics.
Ido Dagan and Oren Glickman. Probabilistic tex-
tual entailment: Generic applied modeling of
language variability. In PASCAL Workshop on
Learning Methods for Text Understanding and
Mining, 2004.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Wit-
ten. The weka data mining software: an update.
SIGKDD Explor. Newsl., 11(1):10–18, November
2009. ISSN 1931-0145.
Yashar Mehdad, Matteo Negri, and Marcello Fed-
erico. Using bilingual parallel corpora for cross-
lingual textual entailment. In Proc. of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technolo-
gies - Volume 1, HLT ’11, pages 1336–1345,
Stroudsburg, PA, USA, 2011. Association for
Computational Linguistics.
Yashar Mehdad, Matteo Negri, and Marcello Fed-
erico. Detecting semantic equivalence and infor-
mation disparity in cross-lingual documents. In
Proc. of the 50th Annual Meeting of the Associa-
tion for Computational Linguistics: Short Papers
- Volume 2, ACL ’12, pages 120–124, Strouds-
burg, PA, USA, 2012. Association for Computa-
tional Linguistics.
M. Negri, A. Marchetti, Y. Mehdad, L. Ben-
tivogli, and D. Giampiccolo. Semeval-2013 Task
8: Cross-lingual Textual Entailment for Content
Synchronization. In Proceedings of the 7th Inter-
national Workshop on Semantic Evaluation (Se-
mEval 2013), 2013.
Matteo Negri, Luisa Bentivogli, Yashar Mehdad,
Danilo Giampiccolo, and Alessandro Marchetti.
Divide and conquer: crowdsourcing the creation
of cross-lingual textual entailment corpora. In
Proc. of the Conference on Empirical Methods
in Natural Language Processing, EMNLP ’11,
pages 670–679, Stroudsburg, PA, USA, 2011. As-
sociation for Computational Linguistics. ISBN
978-1-937284-11-4.
</reference>
<page confidence="0.997312">
127
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.347531">
<title confidence="0.9967145">based Feature Evaluation for the Cross-Lingual Entailment Task</title>
<author confidence="0.790573">David Pinto</author>
<author confidence="0.790573">Sa´ul Le´on</author>
<author confidence="0.790573">Yuridiana Alem´an</author>
<author confidence="0.790573">Helena Benem´erita Universidad Aut´onoma de</author>
<affiliation confidence="0.8115185">Faculty of Computer 14 Sur y Av. San Claudio,</affiliation>
<address confidence="0.989922">Puebla, Puebla,</address>
<email confidence="0.980441">dpinto,saul.leon,candy.aleman,</email>
<abstract confidence="0.9995284">This paper describes the evaluation of different kinds of textual features for the Cross- Lingual Textual Entailment Task of SemEval We have counted the number of grams for three types of textual entities (character, word and PoS tags) that exist in the pair of sentences from which we are interested in determining the judgment of textual entailment. Difference, intersection and distance (Euclidian, Manhattan and Jaccard) of were considered for constructing a feature vector which is further introduced in a support vector machine classifier which allows to construct a classification model. Five different runs were submitted, one of them considering voting system of the previous four approaches. The results obtained show a performance below the median of six teams that have participated in the competition.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Maya Carrillo</author>
<author>Darnes Vilari˜no</author>
<author>David Pinto</author>
<author>Mireya Tovar</author>
<author>Saul Le´on</author>
<author>Esteban Castillo</author>
</authors>
<title>Fcc: Three approaches for semantic textual similarity.</title>
<date>2012</date>
<booktitle>In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics –</booktitle>
<volume>1</volume>
<pages>631--634</pages>
<location>Montr´eal,</location>
<marker>Carrillo, Vilari˜no, Pinto, Tovar, Le´on, Castillo, 2012</marker>
<rawString>Maya Carrillo, Darnes Vilari˜no, David Pinto, Mireya Tovar, Saul Le´on, and Esteban Castillo. Fcc: Three approaches for semantic textual similarity. In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1 and 2 (SemEval 2012), pages 631–634, Montr´eal, Canada, 7-8 June 2012. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
</authors>
<title>Probabilistic textual entailment: Generic applied modeling of language variability.</title>
<date>2004</date>
<booktitle>In PASCAL Workshop on Learning Methods for Text Understanding and Mining,</booktitle>
<contexts>
<context position="1400" citStr="Dagan and Glickman, 2004" startWordPosition="208" endWordPosition="211"> Manhattan and Jaccard) of N-grams were considered for constructing a feature vector which is further introduced in a support vector machine classifier which allows to construct a classification model. Five different runs were submitted, one of them considering voting system of the previous four approaches. The results obtained show a performance below the median of six teams that have participated in the competition. 1 Introduction The cross-lingual textual entailment (CLTE), recently proposed by (Mehdad et al., 2012) and (Mehdad et al., 2011), is an extension of the textual entailment task (Dagan and Glickman, 2004). Formally speaking, given a pair of topically related text fragments (T1 and T2 which are assumed to be TRUE statements) written in different languages, the CLTE task consists of automatically annotating it with one of the following entailment judgments: • bidirectional (T1 -4 T2 &amp; T1 &lt;-- T2): the two fragments entail each other (semantic equivalence); • forward (T1 -4 T2 &amp; T1 �w- T2): unidirectional entailment from T1 to T2; • backward (T1 -/-&gt; T2 &amp; T1 &lt;-- T2): unidirectional entailment from T2 to T1; • no entailment (T1 -/-&gt; T2 &amp; T1 �w- T2): there is no entailment between T1 and T2 in both </context>
</contexts>
<marker>Dagan, Glickman, 2004</marker>
<rawString>Ido Dagan and Oren Glickman. Probabilistic textual entailment: Generic applied modeling of language variability. In PASCAL Workshop on Learning Methods for Text Understanding and Mining, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: an update.</title>
<date>2009</date>
<journal>SIGKDD Explor. Newsl.,</journal>
<volume>11</volume>
<issue>1</issue>
<pages>1931--0145</pages>
<contexts>
<context position="2966" citStr="Hall et al., 2009" startWordPosition="462" endWordPosition="465">ams of characters, words and PoS tags were counted with the aim of constructing a representative vector for each judgment entailment (FORWARD, BACKWARD, BI-DIRECTIONAL or NO-ENTAILMENT). The resulting vectors were fed into a supervised classifier based on Support Vector Machines (SVM)1 which attempted to construct a classification model. The description of the features and the vectorial representation is given in Section 2. The obtained results are shown and dicussed in Section 3. Finally, the findings of this work are given in Section 4. 1We have employed the implementation of the Weka tool (Hall et al., 2009). 124 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 124–127, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics 2 Experimental Setup We have considered the task as a classification problem using the pivot approach. Thus, we have translated2 each pair to their corresponding language in order to have two pairs of sentences written in the same language. Let Pair(T1, T2) be the original pair of topically related sentences. Then, we have obtained the Engli</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. The weka data mining software: an update. SIGKDD Explor. Newsl., 11(1):10–18, November 2009. ISSN 1931-0145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Using bilingual parallel corpora for crosslingual textual entailment.</title>
<date>2011</date>
<booktitle>In Proc. of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>1336--1345</pages>
<location>Stroudsburg, PA, USA,</location>
<contexts>
<context position="1325" citStr="Mehdad et al., 2011" startWordPosition="195" endWordPosition="198"> textual entailment. Difference, intersection and distance (Euclidian, Manhattan and Jaccard) of N-grams were considered for constructing a feature vector which is further introduced in a support vector machine classifier which allows to construct a classification model. Five different runs were submitted, one of them considering voting system of the previous four approaches. The results obtained show a performance below the median of six teams that have participated in the competition. 1 Introduction The cross-lingual textual entailment (CLTE), recently proposed by (Mehdad et al., 2012) and (Mehdad et al., 2011), is an extension of the textual entailment task (Dagan and Glickman, 2004). Formally speaking, given a pair of topically related text fragments (T1 and T2 which are assumed to be TRUE statements) written in different languages, the CLTE task consists of automatically annotating it with one of the following entailment judgments: • bidirectional (T1 -4 T2 &amp; T1 &lt;-- T2): the two fragments entail each other (semantic equivalence); • forward (T1 -4 T2 &amp; T1 �w- T2): unidirectional entailment from T1 to T2; • backward (T1 -/-&gt; T2 &amp; T1 &lt;-- T2): unidirectional entailment from T2 to T1; • no entailment </context>
</contexts>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. Using bilingual parallel corpora for crosslingual textual entailment. In Proc. of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 1336–1345, Stroudsburg, PA, USA, 2011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Detecting semantic equivalence and information disparity in cross-lingual documents.</title>
<date>2012</date>
<booktitle>In Proc. of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2, ACL ’12,</booktitle>
<pages>120--124</pages>
<location>Stroudsburg, PA, USA,</location>
<contexts>
<context position="1299" citStr="Mehdad et al., 2012" startWordPosition="190" endWordPosition="193">etermining the judgment of textual entailment. Difference, intersection and distance (Euclidian, Manhattan and Jaccard) of N-grams were considered for constructing a feature vector which is further introduced in a support vector machine classifier which allows to construct a classification model. Five different runs were submitted, one of them considering voting system of the previous four approaches. The results obtained show a performance below the median of six teams that have participated in the competition. 1 Introduction The cross-lingual textual entailment (CLTE), recently proposed by (Mehdad et al., 2012) and (Mehdad et al., 2011), is an extension of the textual entailment task (Dagan and Glickman, 2004). Formally speaking, given a pair of topically related text fragments (T1 and T2 which are assumed to be TRUE statements) written in different languages, the CLTE task consists of automatically annotating it with one of the following entailment judgments: • bidirectional (T1 -4 T2 &amp; T1 &lt;-- T2): the two fragments entail each other (semantic equivalence); • forward (T1 -4 T2 &amp; T1 �w- T2): unidirectional entailment from T1 to T2; • backward (T1 -/-&gt; T2 &amp; T1 &lt;-- T2): unidirectional entailment from </context>
</contexts>
<marker>Mehdad, Negri, Federico, 2012</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. Detecting semantic equivalence and information disparity in cross-lingual documents. In Proc. of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2, ACL ’12, pages 120–124, Stroudsburg, PA, USA, 2012. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>A Marchetti</author>
<author>Y Mehdad</author>
<author>L Bentivogli</author>
<author>D Giampiccolo</author>
</authors>
<title>Semeval-2013 Task 8: Cross-lingual Textual Entailment for Content Synchronization.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="8763" citStr="Negri et al., 2013" startWordPosition="1456" endWordPosition="1459">. 2.5 Approach 5: Voting system With the results of the previous four models, we prepared a voting system which uses the majority criterion (3 of 4). 3 Experimental results The results obtained in the competition are presented and discussed in this section. First, we describe the training and test corpus, and thereafter, the results obtained with the different approaches submitted. 3.1 Dataset In order to train the different approaches already discussed, we have constructed a training corpus made up of two datasets: the training data provided by the task organizers the task 8 of SemEval 2013 (Negri et al., 2013), and the test dataset together with the gold standard of CLTE task of SemEval 2012 (Negri et al., 2011). Thus, the training corpus contains 4000 sentence pairs. The test set provided in the competition contains 2000 sentence pairs. The corpus is balanced, with 1000 pairs for each language in the training dataset, whereas, 500 pairs are given in the test set for each language (see Table 2). Table 2: Description of the dataset Languages Training Test SPA-ENG 1000 500 DEU-ENG 1000 500 ITA-ENG 1000 500 FRA-ENG 1000 500 Total 4000 2000 3.2 Results In Table 3 we can see the results obtained by each</context>
</contexts>
<marker>Negri, Marchetti, Mehdad, Bentivogli, Giampiccolo, 2013</marker>
<rawString>M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and D. Giampiccolo. Semeval-2013 Task 8: Cross-lingual Textual Entailment for Content Synchronization. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Negri</author>
<author>Luisa Bentivogli</author>
<author>Yashar Mehdad</author>
<author>Danilo Giampiccolo</author>
<author>Alessandro Marchetti</author>
</authors>
<title>Divide and conquer: crowdsourcing the creation of cross-lingual textual entailment corpora.</title>
<date>2011</date>
<journal>ISBN</journal>
<booktitle>In Proc. of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>670--679</pages>
<location>Stroudsburg, PA, USA,</location>
<contexts>
<context position="8867" citStr="Negri et al., 2011" startWordPosition="1475" endWordPosition="1479">m which uses the majority criterion (3 of 4). 3 Experimental results The results obtained in the competition are presented and discussed in this section. First, we describe the training and test corpus, and thereafter, the results obtained with the different approaches submitted. 3.1 Dataset In order to train the different approaches already discussed, we have constructed a training corpus made up of two datasets: the training data provided by the task organizers the task 8 of SemEval 2013 (Negri et al., 2013), and the test dataset together with the gold standard of CLTE task of SemEval 2012 (Negri et al., 2011). Thus, the training corpus contains 4000 sentence pairs. The test set provided in the competition contains 2000 sentence pairs. The corpus is balanced, with 1000 pairs for each language in the training dataset, whereas, 500 pairs are given in the test set for each language (see Table 2). Table 2: Description of the dataset Languages Training Test SPA-ENG 1000 500 DEU-ENG 1000 500 ITA-ENG 1000 500 FRA-ENG 1000 500 Total 4000 2000 3.2 Results In Table 3 we can see the results obtained by each one of the five approaches we submitted to the competition. Each approach has been labeled with the pre</context>
</contexts>
<marker>Negri, Bentivogli, Mehdad, Giampiccolo, Marchetti, 2011</marker>
<rawString>Matteo Negri, Luisa Bentivogli, Yashar Mehdad, Danilo Giampiccolo, and Alessandro Marchetti. Divide and conquer: crowdsourcing the creation of cross-lingual textual entailment corpora. In Proc. of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 670–679, Stroudsburg, PA, USA, 2011. Association for Computational Linguistics. ISBN 978-1-937284-11-4.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>