<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<note confidence="0.8360679">
Assigning Intonational Features in Synthesized Spoken Directions
James Raymond Davis
The Media Laboratory
MIT E15-325
Cambridge MA 02139
Julia Hirschberg
AT&amp;T Bell Laboratories
2D-450
600 Mountain Avenue
Murray Hill NJ 07974
</note>
<sectionHeader confidence="0.84398" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998031722222222">
Speakers convey much of the information hearers use to
interpret discourse by varying prosodic features such as
PHRASING, PITCH ACCENT placement, TUNE, and PITCH
RANGE. The ability to emulate such variation is crucial
to effective (synthetic) speech generation. While text-to-
speech synthesis must rely primarily upon structural in-
formation to determine appropriate intonational features,
speech synthesized from an abstract representation of the
message to be conveyed may employ much richer sources.
The implementation of an intonation assignment compo-
nent for Direction Assistance, a program which generates
spoken directions, provides a first approximation of how
recent models of discourse structure can be used to control
intonational variation in ways that build upon recent re-
search in intonational meaning. The implementation fur-
ther suggests ways in which these discourse models might
be augmented to permit the assignment of appropriate
intonational features.
</bodyText>
<sectionHeader confidence="0.961417" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.996380636363636">
DIRECTION ASSISTANCE1 was written to provide spo-
ken directions for driving between any two points in the
Boston area[7] over the telephone. Callers specify their
origin and destination via touch-tone input. The program
finds a route and synthesizes a spoken description of that
route. Earlier versions of Direction Assistance exhibited
notable deficiencies in prosody when a simple text-to-
speech system was used to produce such descriptions[6],
because prosody depends in part on discourse-level phe-
nomena such as topic structure and information status
which are not generally inferrable from text, and thus
</bodyText>
<note confidence="0.7819415">
The intonational component described here was completed at
AT&amp;T Bell Laboratories in the summer of 1987. We thank Janet
Pierrehumbert and Gregory Ward for valuable discussions.
Direction Assistance was originally developed by Jim Davis and
Tom Trobaugh in 1985 at the Thinking Machines Corporation of
Cambridge.
</note>
<bodyText confidence="0.99680896">
cannot be correctly produced by the text to speech sys-
tem.
To alleviate some of these problems, we modified Direc-
tion Assistance to make both attentional and intentional
information about the route description available for the
assignment of intonational features. With this informa-
tion, we generate spoken directions using the Bell Labo-
ratories Text-to-Speech System[21] in which pitch range,
accent placement, phrasing, and tune can be varied to
communicate attentional and intentional structure. The
implementation of this intonation assignment component
provides a first approximation of how recent models of
discourse structure can be used to control intonational
variation in ways that build upon recent research in into-
national meaning. Additionally, it suggests ways in which
these discourse models must be enhanced in order to per-
mit the assignment of appropriate intonational features.
In this paper, we first discuss some previous attempts
to synthesize speech from representations other than sim-
ple text. We next discuss the work on discourse structure,
on English phonology, and on intonational meaning which
we assume for this study. We then give a brief overview
of Direction Assistance. Next we describe how Direction
Assistance represents discourse structures and uses them
to generate appropriate prosody.
</bodyText>
<subsectionHeader confidence="0.952058">
Previous Studies
</subsectionHeader>
<bodyText confidence="0.9976104">
Only a few voice interactive systems have attempted to
exploit intonation in the interaction. The Telephone En-
quiry Service (TES) [19] was designed as a framework
for applications such as database inquiries, games, and
calculator functions. Application programmers specified
text by phonetic symbols and intonation by a code which
extended Halliday&apos;s[11] intonation scheme. While TES
gave programmers a high-level means of varying prosody,
it made no attempt to derive prosody automatically from
an abstract representation.
</bodyText>
<page confidence="0.996866">
187
</page>
<bodyText confidence="0.999882888888889">
Young and Fallside&apos;s[20] Speech Synthesis from Con-
cept (SSC) system first demonstrated the gains to be had
by providing more than simple text as input to a speech
synthesizer. SSC passed a network representation of syn-
tactic structure to the synthesizer. Syntactic information
could thus inform accenting and phrasing decisions. How-
ever, structural information alone is insufficient to deter-
mine intonational features[10], and SSC does not use se-
mantic or pragmatic/discourse information.
</bodyText>
<sectionHeader confidence="0.767796" genericHeader="method">
Discourse and Intonation
</sectionHeader>
<bodyText confidence="0.999919">
The theoretical foundations of the current work are three:
Grosz and Sidner&apos;s theory of discourse structure, Pierre-
humbert&apos;s theory of English intonation, and Hirschberg
and Pierrehumbert&apos;s studies of intonation and discourse.
</bodyText>
<subsectionHeader confidence="0.981167">
Modeling Discourse Structure
</subsectionHeader>
<bodyText confidence="0.98559073015873">
Grosz and Sidner[9] propose that discourse be understood
in terms of the purposes that underly it (INTENTIONAL
STRUCTURE) and the entities and attributes which are
salient during it (ATTENTIONAL STRUCTURE). In this ac-
count, discourses are analyzed as hierarchies of segments,
each of which has an underlying Discourse Segment
Purpose (DSP) intended by the speaker. All DSPs con-
tribute to the overall Discourse Purpose (DP) of the
discourse. For example, a discourse might have as its
DP something like &apos;intend that Hearer put together an
air compressor&apos;, while individual segments might have as
contributing DSP&apos;s &apos;intend that Hearer remove the fly-
wheel&apos; or &apos;intend that Hearer attach the conduit to the
motor&apos;. Such DSP&apos;s may in turn be represented as hier-
archies of intentions, such as &apos;intend that a hearer loosen
the allen-head screws&apos;, and &apos;intend that Hearer locate the
wheel-puller&apos;. DSPs a and b may be related to one an-
other in two ways: a may DOMINATE b if the DSP of
a is partially fulfilled by the DSP of b (equivalently, b
CONTRIBUTES TO a). So, &apos;intend that Hearer remove
the flywheel&apos; dominates &apos;intend that Hearer loosen the
allen-head screws&apos;, and the latter contributes to the for-
mer. Segment a SATISFACTION-PRECEDES b if the DSP
of a must be achieved in order for the DSP of b to be
successful. &apos;Intend that Hearer locate the wheel-puller&apos;
satisfaction-precedes &apos;intend that Hearer use the wheel-
puller&apos;, and so on. Such intentional structure has been
studied most extensively in task-oriented domains, such
as instruction in assembling machinery, where speaker in-
tentions appear to follow the structure of the task to some
extent. In Grosz and Sidner&apos;s model, part of understand-
ing a discourse is reconstructing the DP, DSPs and rela-
tions among them.
Attentional structure in this model is an abstraction
of &apos;focus of attention&apos;, in which the set of salient entities
changes as the discourse unfolds.2 A given discourse&apos;s
attentional structure is represented as a stack of FOCUS
SPACES, which contain representations of entities refer-
enced in a given DS, such as &apos;flywheel&apos; or &apos;allen-head
screws&apos;, as well as the DS&apos;s DSP. The accessibility of an
entity — as, for pronominal reference — depends upon
the depth of its containing focus space. Deeper spaces are
less accessible. Entities may be made inaccessible if their
focus space is popped from the stack.
Intonational Features and their Interpre-
tation
This model of discourse is employed for expository
purposes by Hirschberg and Pierrehumbert[12] in their
work on the relationship between intonational and dis-
course features. In Pierrehumbert&apos;s theory of English
phonology[16], intonational contours are represented as
sequences of high (H) and low (L) tones (local max-
ima and minima) in the FUNDAMENTAL FREQUENCY (ft)).
Pitch accents fall on the stressed syllables of some lexical
items, and may be simple H or L tones or complex tones.
The four bitonal accents in English (Hi-L,
L-I-H5) differ in the order of tones and in which
tone is aligned with the stressed syllable of the accented
item — the asterisk indicates alignment with stress. Pitch
accents mark items as intonationally prominent and con-
vey the relative &apos;newness&apos; or &apos;salience&apos; of items in the dis-
course. For example, in (la), right is accented (as &apos;new&apos;),
while in (lb) it is deaccented (as &apos;old&apos;).
</bodyText>
<listItem confidence="0.6436665">
(1) a. Take a right, onto Concord Avenue.
b. Take another right, onto Magazine Street.
</listItem>
<bodyText confidence="0.999411888888889">
Different pitch accents convey different meanings: For ex-
ample, a L4-H* on right in (la) may convey &apos;contrastive-
ness&apos;, as after the query So, you take a left onto Concord?.
A simple H* is more likely when the direction of the turn
has not been questioned. A L*-I-H, however, can convey
incredulity or uncertainty about the direction.
INTERMEDIATE PHRASES are composed of one or more
pitch accents, plus an additional PHRASE ACCENT (H or
L), which controls the pitch from the last pitch accent to
</bodyText>
<footnote confidence="0.495872">
2See [1] and [3] for earlier Al work on global and local focus.
</footnote>
<page confidence="0.994696">
188
</page>
<bodyText confidence="0.999765244444444">
the end of the phrase. INTONATIONAL PHRASES consist
of one or more intermediate phrases, plus a BOUNDARY
TONE, also H or L, which falls at the edge of the phrase;
we indicate boundary tones with an &apos;%&apos;, as H%. Phrase
boundaries are marked by lengthened final syllables and
(perhaps) a pause — as well as by tones. Variations in
phrasing may convey structural relationships among el-
ements of a phrase. For example, (2) uttered as two
phrases favors a non-restrictive reading in which the first
right happens to be onto Central Park.
(2) Take the first right [,] onto Central Park.
Uttered as a single phrase, (2) favors the restrictive read-
ing, instructing the driver to find the first right which
goes onto Central Park.
TUNES, or intonational contours, have as their domain
the intonational phrase. While the meaning of tunes ap-
pears to be compositional — from the meanings of their
pitch accents, phrase accents, and boundary tones[15],
certain broad generalizations may be made about par-
ticular tunes in English. Phrases ending in L H% ap-
pear to convey some sense that the phrase is to be com-
pleted by another phrase. Phrases ending in L L% ap-
pear more &apos;declarative&apos; than &apos;interrogative&apos; phrases end-
ing in H H%. Phrases composed of sequences of H*-1-L
accents are often used didactically.
The PITCH RANGE of a phrase is (roughly) the distance
between the maximum f0 value in the phrase (modulo
segmental effects and FINAL LOWERING effects) and the
speaker&apos;s BASELINE, defined for each speaker as the low-
est point reached in normal speech over all utterances.
Variation in pitch range can communicate the topic struc-
ture of a discourse[12, 18]; increasing the pitch range of a
phrase over prior phrases can convey the introduction of
a new topic, and decreasing the pitch range over a prior
phrase can convey the continuation of a subtopic. After
any bitonal pitch accent pitch range is compressed. This
compression, called catathesis, or downstep, extends to
the nearest phrase boundary. Another process, called FI-
NAL LOWERING, involves a compression of the pitch range
during the last half second or so of a &apos;declarative&apos; utter-
ances. The amount of final lowering present for utterance
appears to correlate with the amount of &apos;finality&apos; to be
conveyed by the utterance. That is, utterances that end
topics appear to exhibit more final lowering, while utter-
ances within a topic segment may have little or none.
</bodyText>
<subsectionHeader confidence="0.916784">
Intonation in Direction-Giving
</subsectionHeader>
<bodyText confidence="0.999987482758621">
To identify potential genre-specific intonational charac-
teristics of direction-giving, we performed informal pro-
duction studies, with speakers reading sample texts of
directions similar to those generated by Direction As-
sistance. From acoustic analysis of this data, we noted
first that speakers tended to use H*-I-L accents quite
frequently, in utterances like that whose pitch track ap-
pears in Figure 1. The use of such contours has been
associated in the literature with &apos;didactic&apos; or &apos;pedantic&apos;
contexts. Hence, the propensity for using this contour in
giving directions seems not inappropriate to emulate.
We also noted tendencies for subjects to vary pitch
range in ways similar to proposals mentioned above —
that is, to indicate large topic shifts by increasing pitch
range and to use smaller pitch ranges where utterances
appeared to &apos;continue&apos; a previous topic. And we noted
variation in pausal duration which was consistent with
the notion that speakers produce longer pauses at major
topic boundaries than before an utterance that contin-
ues a topic. However, these informal studies were simply
intended to produce guidelines.
In the intonation assignment component we added to
Direction Assistance, pitch accent placement, phrasing,
tune, and pitch range and final lowering are varied as
noted above to convey information status, structural
information, relationships among utterances, and topic
structure. We will now describe how Direction Assistance
works in general, and, in particular, how it uses this com-
ponent in generating spoken directions.
</bodyText>
<subsectionHeader confidence="0.791568">
Direction Assistance
</subsectionHeader>
<bodyText confidence="0.999721">
Direction Assistance has four major components. The
Location Finder queries the user to obtain the origin
and destination of the route. The Route Finder then
finds a &apos;best&apos; route, in terms of drivability and describabil-
ity. Once a route is determined, the Describer generates
a text describing the route, which the Narrator reads to
the user. In the work reported here, we modified the
Describer to generate an abstract representation of the
route description and replaced the Narrator with a new
component, the Talker, which computes prosodic values
from these structures and passes text augmented with
commands controlling prosodic variation to the speech
synthesizer.
</bodyText>
<page confidence="0.98264">
189
</page>
<figure confidence="0.954968166666667">
200
175
150
125
100
75
</figure>
<table confidence="0.833213965517241">
_ i ,, i I i I I I I : : : : : : : : : : • : : : : : : : : : : : : : ! &apos; I I : : : : • i i : : : : I i i I I I I i •
-..i....4.—i—i— —4.. &apos;.-4-4... ..4...4...i....i.... ....4....i....4.-4.—F.4...4...4..4........1-4--- • --— ....1....i....i...4........t.. 1,...4...4... ...4....?...4....4.... .....{....11....i...1... ...e....i...1....4........4.....?...i....j.... ....i....f....i....s........1....i....1&amp;quot;..?... ...4....4....1...4..., ...i, 44•44.-41 .— ..•4••••&amp;quot;&amp;quot;•••4••• •••1••••&amp;quot;1•••+•••• ••••+.
....i....4....i.&amp;quot;.s.... ..e... ....{....i...• ....4••••:....i....{.... •••.i....i...÷....6.... ...4....,....,....,... ...t.......t........ ....4.-4....s...4.... ...4...4...4...4... ...;........4...i.... ...;
...4....4...4....I... ..4... _4..4... _4_1...i...4... ....i...4....f...4.... _4_4...4-4_ .......z...f....4... _4..4.4...4._ —4...4_4_4.. .......,...4...4.... ...
....i...4...4...4... ...4... . ...;... ...4...4....4....i.... .... ;...4....4....8„... ...4...4...4...4... _4_4_4_4... ....i....1...4_4... _4..4...4...4— ,...4,....i....i...4.... — I. • •
....i...4....1...4... ...4...4 4.. +.. ; .i. i. ; • —4-4...4—.4._ ...4...3...4...4... ....!.....,....4....3.... ....3...4....i...4.......4&amp;quot;.4....i...4... ...4....,....4...4... ...I.
..,../.....1...4i...4.... ....1...4. .1.... • 4. + i.. to ..i. .i .4...1.... ••••4”.4...4...4...•.......4 _4...4._ ....i....i.&amp;quot;.■....i.... ...4...4...4...4... ...4........,....i.... ....i.
....4-1—!—.4.. —4.-4. 4 .4— 4 .-4:. 4- ..i. •L•••i••••!•••• • — 4- —1-4—i. • ... 4.— 4-4-4— ..-.4-4-4-4— .-4.-4....4....t..• ...4-4..4...4-... ...4-
. ._ . . : , : . . . . . . . .
....i.„„i....i....i.... ..../.4...4_4_4...4,..4....4... ....i....i....i...4.... .... 1...4...4....i... .. ..„;..,..i....i...4.... ....i...4...4...4&amp;quot;......,.....4........,..... ...L. - &amp;quot;
iI 8 .-44-4-4- 4 4..4 ; . ....i..&amp;quot;i....i.....i.... ...4...4.........i”. .. .......i....,—,.... _4...4..4.4.. .....i..-1....i....i.... ..-4..
....i...4—.4—. , ....1....t...4-4... ...4...a...4....i........i....i....4....i.......4....i...4....i... •••i••••i••••!••••i•••• •••4••••1-4-1—. —4-4-4-4— -...4.•
••••f••••!••••i-••• &apos; •-4-4-4-4—i—t—i— 4- ..4...-4....4.-4..-- .... ,-.4.-4...4— ...i....t....!....i.... ...;...4...4...1... ...+...4.....,....,.........i..
.... .. ....... .... ...4...4...4...4— ...;... .. ....i. ,........i............., ...4...4....f..4.. ...t...?....i....• ....t... —. ....1.......4...4...4...4... ...t...÷...?&amp;quot;.:.... . ... . . : . ...,...4...; . .... — —: —...: ...4...4...4...4... .. .... • .. . . ....1........ —I.... ....i...4...4....i... ...4... : ..4...: .. . ••• • .: .. ..4...4...4.-4..... : .. ; .4.... _4. — • —4-4-4-4.4 .—÷4.4.--.i..-1—. .-.4. : s, ...v••••4••• • • • . •• -mi—
— —1 — •-•-t--t• i t••• ...T.&amp;quot;+*&amp;quot;+&amp;quot;*. —7— •*** .... : —i* &apos;t&amp;quot;i&amp;quot;.•tV. ***7***t**•t**T&amp;quot;. ***1••°7••• • • + • e •• ••,4••
....it«. .... I.e.. ....3....«.+6.1... ...1....1....i....1....1‘i... • • • &amp;quot; • • • • : . ,
...4._.... ....I..., ...4...4...4...4_ ...;....z....;...1.... ....i... .... .&amp;quot; ...1.....1...4...4... .....i....4.4,...1..... ,.....L... ........ ....:_:&amp;quot;.i...4... ,...1....4....÷...i....
44 i...4.... ....4.-- — — ; --i-4.--ir-i— ,•••÷--4--÷-4—••-4--. — 1.4-4.-4&amp;quot;•4••• ••••;••••:.•••+•••i•••• -
.....1.......................4..4...4...4.... ...z.........:....x........z. ....,....:—.4....z.......4...i--:....«...1....t...............4.....k.......4....f........÷...+...÷...i.... ....
? ** • . .:.i.j.... ....»....i.....! &apos; ÷. 4. : : : . : . : . )........1... -...:.... ....4...4.....:. ; l..... . 4. ..... : . . • : : 41. •••. &amp;A &amp;quot; c : ÷ • —÷- &amp;quot;••••a• ...&amp;quot; I 14,44,1 10•Li 1 . . : . 4. 4....4.44........ ....1....l...+•.4... ....}... ; ; 4 i • 4. ± i ; . : • : • :
- . it• : . . . . • • • 4---., • ...... ,___-4. --- —: - : : : : — , .. — &amp;quot;.r. 1&amp;quot;.....? ! : •■•••■■ 4 . . . . — .. 44.1. I&apos; . • •
Aft* Iwgzeosiri•Orask. &apos; Street, driveasto thSJoitz.ra14 5iqhva . . ..
. : Rill.&apos; i
t..I.... . ......: —4 : .. ; , . ,
....
—4-4-4-4 • • :
• !MI* Iiii•ro
• i _ i ; lag . .
: i
</table>
<figureCaption confidence="0.993311">
Figure 1: Pitch Track of Subject Reading Directions
</figureCaption>
<bodyText confidence="0.997891739130435">
Generating text and discourse structures
The Describer&apos;s representation of a route is called a tour.
A tour is a sequence of acts to be taken in following the
route. Acts represent something the driver must do in
following the route. Act types include start and stop, for
the beginning and ending of the tour, and various kinds
of turns. A rich classification of turns is required in order
to generate natural text. A &apos;fork&apos; should be described
differently from a &apos;T&apos; and from a highway exit. Turning
acts include enter and exit from a limited access road,
merge, fork, u-turn, and rotary.
For each act type, there is a corresponding descriptive
schema to produce text describing that act. Text gen-
eration also involves selecting an appropriate cue for the
act. There are four types of cues: Action cues signal
when to perform an act, such as &amp;quot;When you reach the
end of the road, do x&amp;quot;. Confirmatory cues are indica-
tors that one is successfully following the route, such as
&amp;quot;You&apos;ll cross x&amp;quot; or &amp;quot;You&apos;ll see y&amp;quot;. Warning cues caution
the driver about possible mistakes. Failure cues to de-
scribe the consequences of mistakes (e.g. &amp;quot;If you see x,
you have gone too far&amp;quot;) have not yet been implemented.
In general, there will be several different items potentially
useful as action or confirmatory cues. The Describer se-
lects the one which is most easily recognized (e.g. a bridge
crossing) and which is close to the act for which it is a
cue.
Descriptive schemas are internally organized into syn-
tactic constituents. Some constituents are constant, and
others, e.g. street names and direction of turns, are slots
to be filled by the Describer from the tour. Constituents
are further grouped into one or more (potential) intona-
tional phrases. Each phrase will have a pitch range, a pre-
ceding pause duration, a phrase accent, and a boundary
tone assigned by the Talker. Phrases that end utterances
will also have a final lowering percentage. Where schemas
include more than one intonational phrase, relationships
among these phrases are documented in the schema tem-
plate so that they may be preserved when intonational
features are assigned.
Intentional structure is also represented at the level of
the intonational phrase. Unlike in Grosz and Sidner&apos;s
model, a single phrase may represent a discourse seg-
ment. This departure stems from our belief that, follow-
ing [12, 15], certain intonational contours can communi-
cate relationships among DSP&apos;s.3 Certain relationships
</bodyText>
<footnote confidence="0.7321565">
31t is possible that the intermediate phrase may prove an even
better unit for discourse segmentation.
</footnote>
<page confidence="0.997225">
190
</page>
<bodyText confidence="0.888411125">
among DSP&apos;s are specified within schemes; others are de-
termined from the general task structure indicated by the
domain and the particular task structure indicated by the
current path.
Constituents may be annotated with semantic infor-
mation to be used in determining information status. Se-
mantic annotations include the type of the object and
a pointer (to the internal representation for the object
designated). For each type of object, there is a predicate
which can test two objects of that type for co-designation.
For example, for purposes of reference or accenting we
may want to treat &apos;street&apos; and &apos;avenue&apos; as similar.
Each DS has associated with it a focus space. Following
[2], a focus space consists of a set of FORWARD-LOOKING
CENTERS, potentially salient discourse entities and mod-
ifiers. Focus spaces are pushed and popped from the FO-
CUS STACK as the description is generated, according to
the relationships among their associated DS&apos;s.
As an example, the generator for the rotary act ap-
pears in figure 2. This schema generates two sentences,
second of which is a conjunction. One slot in this
schema is taken by an NP constituent for the rotary.
The make-np-constituent routine handles agreement
between the article and the noun. A second slot is filled
with an expression giving the approximate angular dis-
tance traveled around the rotary. The actual value de-
pends upon the specifics of the act. A third slot in this
schema is filled by the name of the street reached after
taking the rotary. The choice of referring expression for
the street name depends upon the type of street. No
cues are generated here, on the grounds that a rotary is
unmistakable.
</bodyText>
<sectionHeader confidence="0.61121" genericHeader="method">
Assigning Intonational Features
</sectionHeader>
<bodyText confidence="0.998979">
The Talker employes variation in pitch range, pausal du-
ration, and final lowering ratio to reflect the topic struc-
ture of the description, or, the relationship among DS&apos;s as
reflected in the relationship among DSP&apos;s. Following the
proposals of [12], we implement this variation by assigned
each DS an embeddedness level, which is just the depth
of the DS within the discourse tree. Pitch range decreases
with embeddedness. In Grosz and Sidner&apos;s terms, for ex-
ample, for DS1 and DS2, with DSPi dominating DSP2,
we assign DS1 a larger pitch range than DS2. Similarly, if
DSP2 dominates DSP3, DS3 will have a still smaller pitch
range than DS2. Sibling DS&apos;s will thus share a common
pitch range. Pitch variation is perceived logarithmically,
so pitch range decreases as a constant fraction (.9) at each
</bodyText>
<figure confidence="0.994546933333333">
(defun disc-seg-rotary (act)
(list
(make-sentence
&amp;quot;You&apos;ll&amp;quot; &amp;quot;come&amp;quot; &amp;quot;to&amp;quot;
(make-np-constituent &apos;(&amp;quot;rotary&amp;quot;)
:article :indefinite))
(make-conjunction-sentence
(make-sentence
&amp;quot;Go&amp;quot; (rotary-angle-amount
(get-info act &apos;rotary-angle))
&amp;quot;way&amp;quot; &amp;quot;around&amp;quot; (make-anaphora nil &amp;quot;it&amp;quot;))
(make-sentence
&amp;quot;turn&amp;quot; &amp;quot;onto&amp;quot;
(make-street-constituent
(move-to-segment act) act)))))
</figure>
<figureCaption confidence="0.999714">
Figure 2: Generator for Rotary Act Type
</figureCaption>
<bodyText confidence="0.998577606060606">
level, but never falls below a minimum value above the
baseline. Also following [12], we vary final lowering to
indicate the level of embeddedness of the segment com-
pleted by the current utterance. We largely suspend final
lowering for the current utterance when it is followed by
an utterance with greater embedding, to produce a sense
of topic continuity. Where the subsequent utterance has a
lesser degree of embedding than the current utterance, we
increase final lowering proportionally. So, for example, if
the current utterance were followed by an utterance with
embedding level 0 (i.e., no embedding, indicating a major
topic shift), we would give the current utterance maxi-
mal final lowering (here, .87). Pausal duration is greatest
(here, 800 msec) between segments at the least embedded
level, and decreases by 200 msec for each level of embed-
ding, to a minimum of 100 msec between phrases. Of
course, the actual values assigned in the current applies,
tion are somewhat arbitrary. In assigning final lowering,
as pitch range and intervening pausal duration, it is the
relative differences that are important.
Accent placement is determined according to relative
salience and &apos;newness&apos; of the mentioned item.[12, 14, 5]
(We employ Prince&apos;s[17] Given,, or given-salient notion
here to distinguish &apos;given&apos; from &apos;new&apos; information. How-
ever, it would be possible to extend this to include hi-
erarchically related items evoked in a discourse as also
given, or `Chafe-given117], were such possibilities present
in our domain.) Certain object types and modifier types
in the domain have been declared to be potentially salient.
When such an item is to be mentioned in the path descrip-
tion, it is first sought in the current focus space and its
ancestors. In general, if it is found, it is deaccented; oth-
erwise it receives a pitch accent. If the object is not a
</bodyText>
<page confidence="0.996927">
191
</page>
<bodyText confidence="0.99987314">
potentially salient type, then, if it is a function word, it
is deaccented, otherwise it is taken to be a miscellaneous
content word and receives an accent by default. In some
cases, we found that — contra current theories of focus
— items should remain deaccentable even when the focus
spaces containing them have been popped from the focus
stack. In particular, items in the current focus space&apos;s
preceding sibling appear to retain their `givenness&apos;. Re-
analysis to place both occurrences in the same segment
or to ensure that the first is in a parent segment seemed
to lack independent justification. So, we decided to allow
items to remain &apos;given&apos; across sibling segment boundaries,
and extended our deaccenting possibilities accordingly.
We vary phrasing primarily to convey structural infor-
mation. Structural distinctions such as those presented
by example (2) are accomplished in this way.
Intentional structure is conveyed by varying intona-
tional contour as well as pitch range, final lowering, and
pausal duration. A phrase which required &apos;completion&apos; by
another phrase is assigned a low phrase accent and a high
boundary tone (this combination is commonly known as
CONTINUATION RISE).[15] For example, since we gener-
ate VP conjunctions primarily to indicate temporal or
causal relationship (e.g Stay on Main Street for about
ninety yards, and cross the Longfellow Bridge.), we use
continuation rise in such cases on the first phrase.
The sample text in Figure 3 is. generated by the sys-
tem. Note that commands to the speech synthesizer have
been simplified for readability as follows: &apos;T&apos; indicates
the topline of the current intonational phrase; &apos;F&apos; indi-
cates the amount of final lowering; &apos;D&apos; corresponds to the
duration of pause between phrases; &apos;Na&apos; indicates a pitch
accent of type N; other words are not accented. Phrase
accents are represented by simple H or L, and boundary
tones are indicated by %. The topic structure of the text
is indicated by indentation.
Note that pitch range, final lowering, and pauses be-
tween phrases are manipulated to enforce the desired
topic structure of the text. Pitch range is decreased to re-
flect the beginning of a subtopic; phrases that continue a
topic retain the pitch range of the preceding phrase. Final
lowering is increased to mark the end of topics; for exam-
ple, the large amount of final lowering produced on the
last phrase conveys the end of the discourse, while lesser
amounts of lowering within the text enhance the sense of
connection between its parts. Pauses between clauses are
also manipulated so that lesser pauses separate clauses
which are to be interpreted as more closely related to one
another. For example, the segment beginning with You&apos;ll
come to a rotary... is separated from the previous dis-
</bodyText>
<note confidence="0.7494565">
T[170] H*+L If your Hs+L car is on the H*+L
same H*+L side of the H*+L street as
H*+L 7 H*+L Broadway Street L H\Y, D[6003
T[153] H*+L turn H*+L around L H\%
T[1633 FE.90] and H*+L start H*+L driving
L L\Y. D[600]
</note>
<reference confidence="0.516589142857143">
T[153] FC.903 H*+L Merge with H*+L Main
Street I. IA% D[6003
T[163] H*+L Stay on Main Street for about
11*+L one H*+L quarter of a H*+L mile
L H\Y. DC600]
T[153] FE.903 and H*+L cross the Longfellow
H*+L Bridge L L\Y. D[600]
</reference>
<figure confidence="0.889891666666667">
T[163] F[.96] You&apos;ll H*+L come to a
H*+L rotary L D[400]
T[137] H*+L Go about a H*+L quarter
H*+L way H*+L around it
L H\% D[400]
Tt1373 Ft.90] and H*+L turn onto
H*+L Charles Street L L\% D[600]
[163] H*+L Number H*+L 130 is about H*+L
one H*+L eighth of a H*+L mile
H*+L down L H\% D[400]
T[137] FE.873 on your L+H* right
Ha side L L\%
</figure>
<figureCaption confidence="0.8762565">
Figure 3: A Sample Route Description from Direction
Assistance
</figureCaption>
<bodyText confidence="0.997847333333333">
course by a pause of 600 msec, but phrases within this
segment describing the procedure to follow once in the
rotary are separated by pauses of only 400 msec.
</bodyText>
<sectionHeader confidence="0.941715" genericHeader="conclusions">
Summary
</sectionHeader>
<bodyText confidence="0.999992266666667">
We have described how structural, semantic, and dis-
course information can be represented to permit the prin-
cipled assignment of pitch range, accent placement and
type, phrasing, and pause in order to generate spoken
directions with appropriate intonational features. We
have tested these ideas by modifying the text genera-
tion component of Direction Assistance to produce an ab-
stract representation of the information to be conveyed.
This &apos;message-to-speech&apos; approach to speech synthesis
has clear advantages over simple text-to-speech synthe-
sis, since the generator &apos;knows&apos; the meanings to be con-
veyed. This application, while over-simplifying the rela-
tionship between discourse information and intonational
features to some extent, nonetheless demonstrates that it
should be possible to assign more appropriate prosodic
</bodyText>
<page confidence="0.993998">
192
</page>
<bodyText confidence="0.9998954">
features automatically from an abstract representation of
the meaning of a text. Further research in intonational
meaning and in the relationship of that meaning to as-
pects of discourse structure should facilitate progress to-
ward this goal.
</bodyText>
<sectionHeader confidence="0.999241" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999981405797101">
[1] Barbara Grosz. The Representation and Use of Focus
in Dialogue Understanding. Phd thesis, University
of California at Berkeley, 1976.
[2] B. Grosz, A. K. Joshi, and S. Weinstein. Provid-
ing a Unified Account of Definite Noun Phrases in
Discourse. Proceedings of the Association for Com-
putational Linguistics, pages 44-50, June 1983.
[3] Candace Sidner. Towards a computational theory
of definite anaphora comprehension in English dis-
course. PhD thesis, MIT, 1979.
[4] M. Anderson, J. Pierrehumbert, and M. Liberman.
Synthesis by rule of English intonation patterns. Pro-
ceedings of the conference on Acoustics, Speech, and
Signal Processing, page 2.8.1 to 2.8.4, 1984.
[5] Gillian Brown. Prosodic structure and the given/new
distinction. In Cutler and Ladd, editors, Prosody:
Models and Measurements, chapter 6, Springer Ver-
lag, 1983.
[6] James R. Davis. Giving directions: a voice interface
to an urban navigation program. In American Voice
I/O Society, pages 77-84, Sept 1986.
[7] James-R. Davis and Thomas F. Trobaugh. Direction
Assistance. Technical Report, MIT Media Technol-
ogy Lab, Dec 1987.
[8] Marcia A. Derr and Kathleen R. McKeown. Using
focus to generate complex and simple sentences. Pro-
ceedings of the Tenth International Conference on
Computational Linguistics, pages 319-325, 1984.
[9] Barbara J. Grosz and Candace L. Sidner. Attention,
intentions, and the structure of discourse. Computa-
tional Linguistics, 12(3):175-204, 1986.
[10] Dwight Bolinger. Accent is predictable (if you&apos;re a
mind-reader). Language, 48:633-644, 1972.
[11] M. A. K. Halliday. Intonation and Grammar in
British English. Mouton, 1967.
[12] J. Hirschberg and J. Pierrehumbert. The intona-
tional structure of discourse. Proceedings of the As-
sociation for Computational Linguistics, pages 136-
144, July 1986.
[13] Kathleen R. McKeown. Discourse strategies for gen-
erating natural-language text. Artificial Intelligence,
27(1):1-41, 85.
[14] S. G. Nooteboom and J. M. B. Terken. What makes
speakers omit pitch accents? an experiment. Pho-
netica, 39:317-336, 1982.
[15] J. Pierrehumbert and J. Hirschberg. The meaning
of intonation contours in the interpretation of dis-
course. In Plans and Intentions in Communication,
SDF Benchmark Series in Computational Linguis-
tics, MIT Press, forthcoming.
[16] Janet B. Pierrehumbert. The Phonology and Pho-
netics of English Intonation. PhD thesis, MIT, Dept
of Linguistics, 1980.
[17] Ellen F. Prince. Toward a taxonomy of given - new
information. In Peter Cole, editor, Radical Pragmat-
ics, pages 223-256, Academic Press, 1981.
[18] Kim E. A. Silverman. Natural prosody for synthetic
speech. PhD thesis, Cambridge Universtity, 1987.
[19] L. Witten and P. Madams. The telephone in-
quiry service: a man-machine system using synthetic
speech. International Journal of Man-Machine Stud-
ies, 9:449-464, 1977.
[20] S. J. Young and F. Fallside. Speech synthesis from
concept: a method for speech output from infor-
mation systems. Journal of the Acoustic Society of
America, 66(3):685-695, Sept 1979.
[21] J. P. Olive and M. Y. Liberman. Text to speech
— An overview. Journal of the Acoustic Society of
America, SuppL 1, 78(3):s6, Fall 1985.
</reference>
<page confidence="0.999251">
193
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.628771">
<title confidence="0.99993">Assigning Intonational Features in Synthesized Spoken Directions</title>
<author confidence="0.99967">James Raymond Davis</author>
<affiliation confidence="0.999478">The Media Laboratory</affiliation>
<address confidence="0.8495735">MIT E15-325 Cambridge MA 02139</address>
<author confidence="0.997763">Julia Hirschberg</author>
<affiliation confidence="0.999879">AT&amp;T Bell Laboratories</affiliation>
<address confidence="0.992507333333333">2D-450 600 Mountain Avenue Murray Hill NJ 07974</address>
<abstract confidence="0.994811444444444">Speakers convey much of the information hearers use to interpret discourse by varying prosodic features such as PHRASING, PITCH ACCENT placement, TUNE, and PITCH RANGE. The ability to emulate such variation is crucial to effective (synthetic) speech generation. While text-tospeech synthesis must rely primarily upon structural information to determine appropriate intonational features, speech synthesized from an abstract representation of the message to be conveyed may employ much richer sources. The implementation of an intonation assignment component for Direction Assistance, a program which generates spoken directions, provides a first approximation of how recent models of discourse structure can be used to control intonational variation in ways that build upon recent research in intonational meaning. The implementation further suggests ways in which these discourse models might be augmented to permit the assignment of appropriate intonational features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>T[153] FC.903 H*+L Merge with H*+L Main Street I. IA% D[6003 T[163] H*+L Stay on Main Street for about 11*+L one H*+L quarter of a H*+L mile L H\Y. DC600] T[153] FE.903 and H*+L cross the Longfellow H*+L Bridge L L\Y. D[600]</booktitle>
<marker></marker>
<rawString> T[153] FC.903 H*+L Merge with H*+L Main Street I. IA% D[6003 T[163] H*+L Stay on Main Street for about 11*+L one H*+L quarter of a H*+L mile L H\Y. DC600] T[153] FE.903 and H*+L cross the Longfellow H*+L Bridge L L\Y. D[600]</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
</authors>
<title>The Representation and Use of Focus in Dialogue Understanding. Phd thesis,</title>
<date>1976</date>
<institution>University of California at Berkeley,</institution>
<contexts>
<context position="8705" citStr="[1]" startWordPosition="1340" endWordPosition="1340">(as &apos;old&apos;). (1) a. Take a right, onto Concord Avenue. b. Take another right, onto Magazine Street. Different pitch accents convey different meanings: For example, a L4-H* on right in (la) may convey &apos;contrastiveness&apos;, as after the query So, you take a left onto Concord?. A simple H* is more likely when the direction of the turn has not been questioned. A L*-I-H, however, can convey incredulity or uncertainty about the direction. INTERMEDIATE PHRASES are composed of one or more pitch accents, plus an additional PHRASE ACCENT (H or L), which controls the pitch from the last pitch accent to 2See [1] and [3] for earlier Al work on global and local focus. 188 the end of the phrase. INTONATIONAL PHRASES consist of one or more intermediate phrases, plus a BOUNDARY TONE, also H or L, which falls at the edge of the phrase; we indicate boundary tones with an &apos;%&apos;, as H%. Phrase boundaries are marked by lengthened final syllables and (perhaps) a pause — as well as by tones. Variations in phrasing may convey structural relationships among elements of a phrase. For example, (2) uttered as two phrases favors a non-restrictive reading in which the first right happens to be onto Central Park. (2) Take</context>
</contexts>
<marker>[1]</marker>
<rawString>Barbara Grosz. The Representation and Use of Focus in Dialogue Understanding. Phd thesis, University of California at Berkeley, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Providing a Unified Account of Definite Noun Phrases in Discourse.</title>
<date>1983</date>
<booktitle>Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>44--50</pages>
<contexts>
<context position="20783" citStr="[2]" startWordPosition="3171" endWordPosition="3171">ask structure indicated by the domain and the particular task structure indicated by the current path. Constituents may be annotated with semantic information to be used in determining information status. Semantic annotations include the type of the object and a pointer (to the internal representation for the object designated). For each type of object, there is a predicate which can test two objects of that type for co-designation. For example, for purposes of reference or accenting we may want to treat &apos;street&apos; and &apos;avenue&apos; as similar. Each DS has associated with it a focus space. Following [2], a focus space consists of a set of FORWARD-LOOKING CENTERS, potentially salient discourse entities and modifiers. Focus spaces are pushed and popped from the FOCUS STACK as the description is generated, according to the relationships among their associated DS&apos;s. As an example, the generator for the rotary act appears in figure 2. This schema generates two sentences, second of which is a conjunction. One slot in this schema is taken by an NP constituent for the rotary. The make-np-constituent routine handles agreement between the article and the noun. A second slot is filled with an expressio</context>
</contexts>
<marker>[2]</marker>
<rawString>B. Grosz, A. K. Joshi, and S. Weinstein. Providing a Unified Account of Definite Noun Phrases in Discourse. Proceedings of the Association for Computational Linguistics, pages 44-50, June 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace Sidner</author>
</authors>
<title>Towards a computational theory of definite anaphora comprehension in English discourse.</title>
<date>1979</date>
<tech>PhD thesis, MIT,</tech>
<contexts>
<context position="8713" citStr="[3]" startWordPosition="1342" endWordPosition="1342">&apos;). (1) a. Take a right, onto Concord Avenue. b. Take another right, onto Magazine Street. Different pitch accents convey different meanings: For example, a L4-H* on right in (la) may convey &apos;contrastiveness&apos;, as after the query So, you take a left onto Concord?. A simple H* is more likely when the direction of the turn has not been questioned. A L*-I-H, however, can convey incredulity or uncertainty about the direction. INTERMEDIATE PHRASES are composed of one or more pitch accents, plus an additional PHRASE ACCENT (H or L), which controls the pitch from the last pitch accent to 2See [1] and [3] for earlier Al work on global and local focus. 188 the end of the phrase. INTONATIONAL PHRASES consist of one or more intermediate phrases, plus a BOUNDARY TONE, also H or L, which falls at the edge of the phrase; we indicate boundary tones with an &apos;%&apos;, as H%. Phrase boundaries are marked by lengthened final syllables and (perhaps) a pause — as well as by tones. Variations in phrasing may convey structural relationships among elements of a phrase. For example, (2) uttered as two phrases favors a non-restrictive reading in which the first right happens to be onto Central Park. (2) Take the fir</context>
</contexts>
<marker>[3]</marker>
<rawString>Candace Sidner. Towards a computational theory of definite anaphora comprehension in English discourse. PhD thesis, MIT, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Anderson</author>
<author>J Pierrehumbert</author>
<author>M Liberman</author>
</authors>
<title>Synthesis by rule of English intonation patterns.</title>
<date>1984</date>
<booktitle>Proceedings of the conference on Acoustics, Speech, and Signal Processing,</booktitle>
<pages>2--8</pages>
<marker>[4]</marker>
<rawString>M. Anderson, J. Pierrehumbert, and M. Liberman. Synthesis by rule of English intonation patterns. Proceedings of the conference on Acoustics, Speech, and Signal Processing, page 2.8.1 to 2.8.4, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gillian Brown</author>
</authors>
<title>Prosodic structure and the given/new distinction.</title>
<date>1983</date>
<booktitle>In Cutler and Ladd, editors, Prosody: Models and Measurements, chapter 6,</booktitle>
<publisher>Springer Verlag,</publisher>
<contexts>
<context position="24220" citStr="[12, 14, 5]" startWordPosition="3706" endWordPosition="3708"> a major topic shift), we would give the current utterance maximal final lowering (here, .87). Pausal duration is greatest (here, 800 msec) between segments at the least embedded level, and decreases by 200 msec for each level of embedding, to a minimum of 100 msec between phrases. Of course, the actual values assigned in the current applies, tion are somewhat arbitrary. In assigning final lowering, as pitch range and intervening pausal duration, it is the relative differences that are important. Accent placement is determined according to relative salience and &apos;newness&apos; of the mentioned item.[12, 14, 5] (We employ Prince&apos;s[17] Given,, or given-salient notion here to distinguish &apos;given&apos; from &apos;new&apos; information. However, it would be possible to extend this to include hierarchically related items evoked in a discourse as also given, or `Chafe-given117], were such possibilities present in our domain.) Certain object types and modifier types in the domain have been declared to be potentially salient. When such an item is to be mentioned in the path description, it is first sought in the current focus space and its ancestors. In general, if it is found, it is deaccented; otherwise it receives a pit</context>
</contexts>
<marker>[5]</marker>
<rawString>Gillian Brown. Prosodic structure and the given/new distinction. In Cutler and Ladd, editors, Prosody: Models and Measurements, chapter 6, Springer Verlag, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Davis</author>
</authors>
<title>Giving directions: a voice interface to an urban navigation program.</title>
<date>1986</date>
<booktitle>In American Voice I/O Society,</booktitle>
<pages>77--84</pages>
<contexts>
<context position="1660" citStr="[6]" startWordPosition="237" endWordPosition="237">ementation further suggests ways in which these discourse models might be augmented to permit the assignment of appropriate intonational features. Introduction DIRECTION ASSISTANCE1 was written to provide spoken directions for driving between any two points in the Boston area[7] over the telephone. Callers specify their origin and destination via touch-tone input. The program finds a route and synthesizes a spoken description of that route. Earlier versions of Direction Assistance exhibited notable deficiencies in prosody when a simple text-tospeech system was used to produce such descriptions[6], because prosody depends in part on discourse-level phenomena such as topic structure and information status which are not generally inferrable from text, and thus The intonational component described here was completed at AT&amp;T Bell Laboratories in the summer of 1987. We thank Janet Pierrehumbert and Gregory Ward for valuable discussions. Direction Assistance was originally developed by Jim Davis and Tom Trobaugh in 1985 at the Thinking Machines Corporation of Cambridge. cannot be correctly produced by the text to speech system. To alleviate some of these problems, we modified Direction Assis</context>
</contexts>
<marker>[6]</marker>
<rawString>James R. Davis. Giving directions: a voice interface to an urban navigation program. In American Voice I/O Society, pages 77-84, Sept 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James-R Davis</author>
<author>Thomas F Trobaugh</author>
</authors>
<title>Direction Assistance.</title>
<date>1987</date>
<tech>Technical Report,</tech>
<institution>MIT Media Technology Lab,</institution>
<contexts>
<context position="1336" citStr="[7]" startWordPosition="190" endWordPosition="190">. The implementation of an intonation assignment component for Direction Assistance, a program which generates spoken directions, provides a first approximation of how recent models of discourse structure can be used to control intonational variation in ways that build upon recent research in intonational meaning. The implementation further suggests ways in which these discourse models might be augmented to permit the assignment of appropriate intonational features. Introduction DIRECTION ASSISTANCE1 was written to provide spoken directions for driving between any two points in the Boston area[7] over the telephone. Callers specify their origin and destination via touch-tone input. The program finds a route and synthesizes a spoken description of that route. Earlier versions of Direction Assistance exhibited notable deficiencies in prosody when a simple text-tospeech system was used to produce such descriptions[6], because prosody depends in part on discourse-level phenomena such as topic structure and information status which are not generally inferrable from text, and thus The intonational component described here was completed at AT&amp;T Bell Laboratories in the summer of 1987. We tha</context>
</contexts>
<marker>[7]</marker>
<rawString>James-R. Davis and Thomas F. Trobaugh. Direction Assistance. Technical Report, MIT Media Technology Lab, Dec 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcia A Derr</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Using focus to generate complex and simple sentences.</title>
<date>1984</date>
<booktitle>Proceedings of the Tenth International Conference on Computational Linguistics,</booktitle>
<pages>319--325</pages>
<marker>[8]</marker>
<rawString>Marcia A. Derr and Kathleen R. McKeown. Using focus to generate complex and simple sentences. Proceedings of the Tenth International Conference on Computational Linguistics, pages 319-325, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<contexts>
<context position="4795" citStr="[9]" startWordPosition="695" endWordPosition="695"> a network representation of syntactic structure to the synthesizer. Syntactic information could thus inform accenting and phrasing decisions. However, structural information alone is insufficient to determine intonational features[10], and SSC does not use semantic or pragmatic/discourse information. Discourse and Intonation The theoretical foundations of the current work are three: Grosz and Sidner&apos;s theory of discourse structure, Pierrehumbert&apos;s theory of English intonation, and Hirschberg and Pierrehumbert&apos;s studies of intonation and discourse. Modeling Discourse Structure Grosz and Sidner[9] propose that discourse be understood in terms of the purposes that underly it (INTENTIONAL STRUCTURE) and the entities and attributes which are salient during it (ATTENTIONAL STRUCTURE). In this account, discourses are analyzed as hierarchies of segments, each of which has an underlying Discourse Segment Purpose (DSP) intended by the speaker. All DSPs contribute to the overall Discourse Purpose (DP) of the discourse. For example, a discourse might have as its DP something like &apos;intend that Hearer put together an air compressor&apos;, while individual segments might have as contributing DSP&apos;s &apos;inte</context>
</contexts>
<marker>[9]</marker>
<rawString>Barbara J. Grosz and Candace L. Sidner. Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175-204, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dwight Bolinger</author>
</authors>
<title>Accent is predictable (if you&apos;re a mind-reader).</title>
<date>1972</date>
<journal>Language,</journal>
<pages>48--633</pages>
<contexts>
<context position="4427" citStr="[10]" startWordPosition="645" endWordPosition="645">day&apos;s[11] intonation scheme. While TES gave programmers a high-level means of varying prosody, it made no attempt to derive prosody automatically from an abstract representation. 187 Young and Fallside&apos;s[20] Speech Synthesis from Concept (SSC) system first demonstrated the gains to be had by providing more than simple text as input to a speech synthesizer. SSC passed a network representation of syntactic structure to the synthesizer. Syntactic information could thus inform accenting and phrasing decisions. However, structural information alone is insufficient to determine intonational features[10], and SSC does not use semantic or pragmatic/discourse information. Discourse and Intonation The theoretical foundations of the current work are three: Grosz and Sidner&apos;s theory of discourse structure, Pierrehumbert&apos;s theory of English intonation, and Hirschberg and Pierrehumbert&apos;s studies of intonation and discourse. Modeling Discourse Structure Grosz and Sidner[9] propose that discourse be understood in terms of the purposes that underly it (INTENTIONAL STRUCTURE) and the entities and attributes which are salient during it (ATTENTIONAL STRUCTURE). In this account, discourses are analyzed as </context>
</contexts>
<marker>[10]</marker>
<rawString>Dwight Bolinger. Accent is predictable (if you&apos;re a mind-reader). Language, 48:633-644, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>Intonation and Grammar in British English.</title>
<date>1967</date>
<location>Mouton,</location>
<contexts>
<context position="3832" citStr="[11]" startWordPosition="558" endWordPosition="558"> on intonational meaning which we assume for this study. We then give a brief overview of Direction Assistance. Next we describe how Direction Assistance represents discourse structures and uses them to generate appropriate prosody. Previous Studies Only a few voice interactive systems have attempted to exploit intonation in the interaction. The Telephone Enquiry Service (TES) [19] was designed as a framework for applications such as database inquiries, games, and calculator functions. Application programmers specified text by phonetic symbols and intonation by a code which extended Halliday&apos;s[11] intonation scheme. While TES gave programmers a high-level means of varying prosody, it made no attempt to derive prosody automatically from an abstract representation. 187 Young and Fallside&apos;s[20] Speech Synthesis from Concept (SSC) system first demonstrated the gains to be had by providing more than simple text as input to a speech synthesizer. SSC passed a network representation of syntactic structure to the synthesizer. Syntactic information could thus inform accenting and phrasing decisions. However, structural information alone is insufficient to determine intonational features[10], and</context>
</contexts>
<marker>[11]</marker>
<rawString>M. A. K. Halliday. Intonation and Grammar in British English. Mouton, 1967.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
<author>J Pierrehumbert</author>
</authors>
<title>The intonational structure of discourse.</title>
<date>1986</date>
<booktitle>Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>136--144</pages>
<contexts>
<context position="7294" citStr="[12]" startWordPosition="1102" endWordPosition="1102">olds.2 A given discourse&apos;s attentional structure is represented as a stack of FOCUS SPACES, which contain representations of entities referenced in a given DS, such as &apos;flywheel&apos; or &apos;allen-head screws&apos;, as well as the DS&apos;s DSP. The accessibility of an entity — as, for pronominal reference — depends upon the depth of its containing focus space. Deeper spaces are less accessible. Entities may be made inaccessible if their focus space is popped from the stack. Intonational Features and their Interpretation This model of discourse is employed for expository purposes by Hirschberg and Pierrehumbert[12] in their work on the relationship between intonational and discourse features. In Pierrehumbert&apos;s theory of English phonology[16], intonational contours are represented as sequences of high (H) and low (L) tones (local maxima and minima) in the FUNDAMENTAL FREQUENCY (ft)). Pitch accents fall on the stressed syllables of some lexical items, and may be simple H or L tones or complex tones. The four bitonal accents in English (Hi-L, L-I-H5) differ in the order of tones and in which tone is aligned with the stressed syllable of the accented item — the asterisk indicates alignment with stress. Pit</context>
<context position="10410" citStr="[12, 18]" startWordPosition="1631" endWordPosition="1632">% appear to convey some sense that the phrase is to be completed by another phrase. Phrases ending in L L% appear more &apos;declarative&apos; than &apos;interrogative&apos; phrases ending in H H%. Phrases composed of sequences of H*-1-L accents are often used didactically. The PITCH RANGE of a phrase is (roughly) the distance between the maximum f0 value in the phrase (modulo segmental effects and FINAL LOWERING effects) and the speaker&apos;s BASELINE, defined for each speaker as the lowest point reached in normal speech over all utterances. Variation in pitch range can communicate the topic structure of a discourse[12, 18]; increasing the pitch range of a phrase over prior phrases can convey the introduction of a new topic, and decreasing the pitch range over a prior phrase can convey the continuation of a subtopic. After any bitonal pitch accent pitch range is compressed. This compression, called catathesis, or downstep, extends to the nearest phrase boundary. Another process, called FINAL LOWERING, involves a compression of the pitch range during the last half second or so of a &apos;declarative&apos; utterances. The amount of final lowering present for utterance appears to correlate with the amount of &apos;finality&apos; to be</context>
<context position="19893" citStr="[12, 15]" startWordPosition="3030" endWordPosition="3031"> a pitch range, a preceding pause duration, a phrase accent, and a boundary tone assigned by the Talker. Phrases that end utterances will also have a final lowering percentage. Where schemas include more than one intonational phrase, relationships among these phrases are documented in the schema template so that they may be preserved when intonational features are assigned. Intentional structure is also represented at the level of the intonational phrase. Unlike in Grosz and Sidner&apos;s model, a single phrase may represent a discourse segment. This departure stems from our belief that, following [12, 15], certain intonational contours can communicate relationships among DSP&apos;s.3 Certain relationships 31t is possible that the intermediate phrase may prove an even better unit for discourse segmentation. 190 among DSP&apos;s are specified within schemes; others are determined from the general task structure indicated by the domain and the particular task structure indicated by the current path. Constituents may be annotated with semantic information to be used in determining information status. Semantic annotations include the type of the object and a pointer (to the internal representation for the ob</context>
<context position="22048" citStr="[12]" startWordPosition="3381" endWordPosition="3381"> rotary. The actual value depends upon the specifics of the act. A third slot in this schema is filled by the name of the street reached after taking the rotary. The choice of referring expression for the street name depends upon the type of street. No cues are generated here, on the grounds that a rotary is unmistakable. Assigning Intonational Features The Talker employes variation in pitch range, pausal duration, and final lowering ratio to reflect the topic structure of the description, or, the relationship among DS&apos;s as reflected in the relationship among DSP&apos;s. Following the proposals of [12], we implement this variation by assigned each DS an embeddedness level, which is just the depth of the DS within the discourse tree. Pitch range decreases with embeddedness. In Grosz and Sidner&apos;s terms, for example, for DS1 and DS2, with DSPi dominating DSP2, we assign DS1 a larger pitch range than DS2. Similarly, if DSP2 dominates DSP3, DS3 will have a still smaller pitch range than DS2. Sibling DS&apos;s will thus share a common pitch range. Pitch variation is perceived logarithmically, so pitch range decreases as a constant fraction (.9) at each (defun disc-seg-rotary (act) (list (make-sentence</context>
<context position="24220" citStr="[12, 14, 5]" startWordPosition="3706" endWordPosition="3708"> a major topic shift), we would give the current utterance maximal final lowering (here, .87). Pausal duration is greatest (here, 800 msec) between segments at the least embedded level, and decreases by 200 msec for each level of embedding, to a minimum of 100 msec between phrases. Of course, the actual values assigned in the current applies, tion are somewhat arbitrary. In assigning final lowering, as pitch range and intervening pausal duration, it is the relative differences that are important. Accent placement is determined according to relative salience and &apos;newness&apos; of the mentioned item.[12, 14, 5] (We employ Prince&apos;s[17] Given,, or given-salient notion here to distinguish &apos;given&apos; from &apos;new&apos; information. However, it would be possible to extend this to include hierarchically related items evoked in a discourse as also given, or `Chafe-given117], were such possibilities present in our domain.) Certain object types and modifier types in the domain have been declared to be potentially salient. When such an item is to be mentioned in the path description, it is first sought in the current focus space and its ancestors. In general, if it is found, it is deaccented; otherwise it receives a pit</context>
</contexts>
<marker>[12]</marker>
<rawString>J. Hirschberg and J. Pierrehumbert. The intonational structure of discourse. Proceedings of the Association for Computational Linguistics, pages 136-144, July 1986.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kathleen R McKeown</author>
</authors>
<title>Discourse strategies for generating natural-language text.</title>
<journal>Artificial Intelligence,</journal>
<pages>27--1</pages>
<marker>[13]</marker>
<rawString>Kathleen R. McKeown. Discourse strategies for generating natural-language text. Artificial Intelligence, 27(1):1-41, 85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Nooteboom</author>
<author>J M B Terken</author>
</authors>
<title>What makes speakers omit pitch accents? an experiment.</title>
<date>1982</date>
<journal>Phonetica,</journal>
<pages>39--317</pages>
<contexts>
<context position="24220" citStr="[12, 14, 5]" startWordPosition="3706" endWordPosition="3708"> a major topic shift), we would give the current utterance maximal final lowering (here, .87). Pausal duration is greatest (here, 800 msec) between segments at the least embedded level, and decreases by 200 msec for each level of embedding, to a minimum of 100 msec between phrases. Of course, the actual values assigned in the current applies, tion are somewhat arbitrary. In assigning final lowering, as pitch range and intervening pausal duration, it is the relative differences that are important. Accent placement is determined according to relative salience and &apos;newness&apos; of the mentioned item.[12, 14, 5] (We employ Prince&apos;s[17] Given,, or given-salient notion here to distinguish &apos;given&apos; from &apos;new&apos; information. However, it would be possible to extend this to include hierarchically related items evoked in a discourse as also given, or `Chafe-given117], were such possibilities present in our domain.) Certain object types and modifier types in the domain have been declared to be potentially salient. When such an item is to be mentioned in the path description, it is first sought in the current focus space and its ancestors. In general, if it is found, it is deaccented; otherwise it receives a pit</context>
</contexts>
<marker>[14]</marker>
<rawString>S. G. Nooteboom and J. M. B. Terken. What makes speakers omit pitch accents? an experiment. Phonetica, 39:317-336, 1982.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Pierrehumbert</author>
<author>J Hirschberg</author>
</authors>
<title>The meaning of intonation contours in the interpretation of discourse.</title>
<booktitle>In Plans and Intentions in Communication, SDF Benchmark Series in Computational Linguistics,</booktitle>
<pages>forthcoming.</pages>
<publisher>MIT Press,</publisher>
<contexts>
<context position="9702" citStr="[15]" startWordPosition="1511" endWordPosition="1511">ing may convey structural relationships among elements of a phrase. For example, (2) uttered as two phrases favors a non-restrictive reading in which the first right happens to be onto Central Park. (2) Take the first right [,] onto Central Park. Uttered as a single phrase, (2) favors the restrictive reading, instructing the driver to find the first right which goes onto Central Park. TUNES, or intonational contours, have as their domain the intonational phrase. While the meaning of tunes appears to be compositional — from the meanings of their pitch accents, phrase accents, and boundary tones[15], certain broad generalizations may be made about particular tunes in English. Phrases ending in L H% appear to convey some sense that the phrase is to be completed by another phrase. Phrases ending in L L% appear more &apos;declarative&apos; than &apos;interrogative&apos; phrases ending in H H%. Phrases composed of sequences of H*-1-L accents are often used didactically. The PITCH RANGE of a phrase is (roughly) the distance between the maximum f0 value in the phrase (modulo segmental effects and FINAL LOWERING effects) and the speaker&apos;s BASELINE, defined for each speaker as the lowest point reached in normal spe</context>
<context position="19893" citStr="[12, 15]" startWordPosition="3030" endWordPosition="3031"> a pitch range, a preceding pause duration, a phrase accent, and a boundary tone assigned by the Talker. Phrases that end utterances will also have a final lowering percentage. Where schemas include more than one intonational phrase, relationships among these phrases are documented in the schema template so that they may be preserved when intonational features are assigned. Intentional structure is also represented at the level of the intonational phrase. Unlike in Grosz and Sidner&apos;s model, a single phrase may represent a discourse segment. This departure stems from our belief that, following [12, 15], certain intonational contours can communicate relationships among DSP&apos;s.3 Certain relationships 31t is possible that the intermediate phrase may prove an even better unit for discourse segmentation. 190 among DSP&apos;s are specified within schemes; others are determined from the general task structure indicated by the domain and the particular task structure indicated by the current path. Constituents may be annotated with semantic information to be used in determining information status. Semantic annotations include the type of the object and a pointer (to the internal representation for the ob</context>
<context position="26055" citStr="[15]" startWordPosition="4006" endWordPosition="4006">fication. So, we decided to allow items to remain &apos;given&apos; across sibling segment boundaries, and extended our deaccenting possibilities accordingly. We vary phrasing primarily to convey structural information. Structural distinctions such as those presented by example (2) are accomplished in this way. Intentional structure is conveyed by varying intonational contour as well as pitch range, final lowering, and pausal duration. A phrase which required &apos;completion&apos; by another phrase is assigned a low phrase accent and a high boundary tone (this combination is commonly known as CONTINUATION RISE).[15] For example, since we generate VP conjunctions primarily to indicate temporal or causal relationship (e.g Stay on Main Street for about ninety yards, and cross the Longfellow Bridge.), we use continuation rise in such cases on the first phrase. The sample text in Figure 3 is. generated by the system. Note that commands to the speech synthesizer have been simplified for readability as follows: &apos;T&apos; indicates the topline of the current intonational phrase; &apos;F&apos; indicates the amount of final lowering; &apos;D&apos; corresponds to the duration of pause between phrases; &apos;Na&apos; indicates a pitch accent of type N</context>
</contexts>
<marker>[15]</marker>
<rawString>J. Pierrehumbert and J. Hirschberg. The meaning of intonation contours in the interpretation of discourse. In Plans and Intentions in Communication, SDF Benchmark Series in Computational Linguistics, MIT Press, forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet B Pierrehumbert</author>
</authors>
<title>The Phonology and Phonetics of English Intonation.</title>
<date>1980</date>
<tech>PhD thesis,</tech>
<institution>MIT, Dept of Linguistics,</institution>
<contexts>
<context position="7424" citStr="[16]" startWordPosition="1120" endWordPosition="1120">ies referenced in a given DS, such as &apos;flywheel&apos; or &apos;allen-head screws&apos;, as well as the DS&apos;s DSP. The accessibility of an entity — as, for pronominal reference — depends upon the depth of its containing focus space. Deeper spaces are less accessible. Entities may be made inaccessible if their focus space is popped from the stack. Intonational Features and their Interpretation This model of discourse is employed for expository purposes by Hirschberg and Pierrehumbert[12] in their work on the relationship between intonational and discourse features. In Pierrehumbert&apos;s theory of English phonology[16], intonational contours are represented as sequences of high (H) and low (L) tones (local maxima and minima) in the FUNDAMENTAL FREQUENCY (ft)). Pitch accents fall on the stressed syllables of some lexical items, and may be simple H or L tones or complex tones. The four bitonal accents in English (Hi-L, L-I-H5) differ in the order of tones and in which tone is aligned with the stressed syllable of the accented item — the asterisk indicates alignment with stress. Pitch accents mark items as intonationally prominent and convey the relative &apos;newness&apos; or &apos;salience&apos; of items in the discourse. For e</context>
</contexts>
<marker>[16]</marker>
<rawString>Janet B. Pierrehumbert. The Phonology and Phonetics of English Intonation. PhD thesis, MIT, Dept of Linguistics, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen F Prince</author>
</authors>
<title>Toward a taxonomy of given - new information.</title>
<date>1981</date>
<booktitle>Radical Pragmatics,</booktitle>
<pages>223--256</pages>
<editor>In Peter Cole, editor,</editor>
<publisher>Academic Press,</publisher>
<contexts>
<context position="24244" citStr="[17]" startWordPosition="3711" endWordPosition="3711"> give the current utterance maximal final lowering (here, .87). Pausal duration is greatest (here, 800 msec) between segments at the least embedded level, and decreases by 200 msec for each level of embedding, to a minimum of 100 msec between phrases. Of course, the actual values assigned in the current applies, tion are somewhat arbitrary. In assigning final lowering, as pitch range and intervening pausal duration, it is the relative differences that are important. Accent placement is determined according to relative salience and &apos;newness&apos; of the mentioned item.[12, 14, 5] (We employ Prince&apos;s[17] Given,, or given-salient notion here to distinguish &apos;given&apos; from &apos;new&apos; information. However, it would be possible to extend this to include hierarchically related items evoked in a discourse as also given, or `Chafe-given117], were such possibilities present in our domain.) Certain object types and modifier types in the domain have been declared to be potentially salient. When such an item is to be mentioned in the path description, it is first sought in the current focus space and its ancestors. In general, if it is found, it is deaccented; otherwise it receives a pitch accent. If the object</context>
</contexts>
<marker>[17]</marker>
<rawString>Ellen F. Prince. Toward a taxonomy of given - new information. In Peter Cole, editor, Radical Pragmatics, pages 223-256, Academic Press, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kim E A Silverman</author>
</authors>
<title>Natural prosody for synthetic speech. PhD thesis,</title>
<date>1987</date>
<institution>Cambridge Universtity,</institution>
<contexts>
<context position="10410" citStr="[12, 18]" startWordPosition="1631" endWordPosition="1632">% appear to convey some sense that the phrase is to be completed by another phrase. Phrases ending in L L% appear more &apos;declarative&apos; than &apos;interrogative&apos; phrases ending in H H%. Phrases composed of sequences of H*-1-L accents are often used didactically. The PITCH RANGE of a phrase is (roughly) the distance between the maximum f0 value in the phrase (modulo segmental effects and FINAL LOWERING effects) and the speaker&apos;s BASELINE, defined for each speaker as the lowest point reached in normal speech over all utterances. Variation in pitch range can communicate the topic structure of a discourse[12, 18]; increasing the pitch range of a phrase over prior phrases can convey the introduction of a new topic, and decreasing the pitch range over a prior phrase can convey the continuation of a subtopic. After any bitonal pitch accent pitch range is compressed. This compression, called catathesis, or downstep, extends to the nearest phrase boundary. Another process, called FINAL LOWERING, involves a compression of the pitch range during the last half second or so of a &apos;declarative&apos; utterances. The amount of final lowering present for utterance appears to correlate with the amount of &apos;finality&apos; to be</context>
</contexts>
<marker>[18]</marker>
<rawString>Kim E. A. Silverman. Natural prosody for synthetic speech. PhD thesis, Cambridge Universtity, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Witten</author>
<author>P Madams</author>
</authors>
<title>The telephone inquiry service: a man-machine system using synthetic speech.</title>
<date>1977</date>
<journal>International Journal of Man-Machine Studies,</journal>
<pages>9--449</pages>
<contexts>
<context position="3612" citStr="[19]" startWordPosition="528" endWordPosition="528">e intonational features. In this paper, we first discuss some previous attempts to synthesize speech from representations other than simple text. We next discuss the work on discourse structure, on English phonology, and on intonational meaning which we assume for this study. We then give a brief overview of Direction Assistance. Next we describe how Direction Assistance represents discourse structures and uses them to generate appropriate prosody. Previous Studies Only a few voice interactive systems have attempted to exploit intonation in the interaction. The Telephone Enquiry Service (TES) [19] was designed as a framework for applications such as database inquiries, games, and calculator functions. Application programmers specified text by phonetic symbols and intonation by a code which extended Halliday&apos;s[11] intonation scheme. While TES gave programmers a high-level means of varying prosody, it made no attempt to derive prosody automatically from an abstract representation. 187 Young and Fallside&apos;s[20] Speech Synthesis from Concept (SSC) system first demonstrated the gains to be had by providing more than simple text as input to a speech synthesizer. SSC passed a network represent</context>
</contexts>
<marker>[19]</marker>
<rawString>L. Witten and P. Madams. The telephone inquiry service: a man-machine system using synthetic speech. International Journal of Man-Machine Studies, 9:449-464, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Young</author>
<author>F Fallside</author>
</authors>
<title>Speech synthesis from concept: a method for speech output from information systems.</title>
<date>1979</date>
<journal>Journal of the Acoustic Society of America,</journal>
<pages>66--3</pages>
<contexts>
<context position="4030" citStr="[20]" startWordPosition="586" endWordPosition="586">m to generate appropriate prosody. Previous Studies Only a few voice interactive systems have attempted to exploit intonation in the interaction. The Telephone Enquiry Service (TES) [19] was designed as a framework for applications such as database inquiries, games, and calculator functions. Application programmers specified text by phonetic symbols and intonation by a code which extended Halliday&apos;s[11] intonation scheme. While TES gave programmers a high-level means of varying prosody, it made no attempt to derive prosody automatically from an abstract representation. 187 Young and Fallside&apos;s[20] Speech Synthesis from Concept (SSC) system first demonstrated the gains to be had by providing more than simple text as input to a speech synthesizer. SSC passed a network representation of syntactic structure to the synthesizer. Syntactic information could thus inform accenting and phrasing decisions. However, structural information alone is insufficient to determine intonational features[10], and SSC does not use semantic or pragmatic/discourse information. Discourse and Intonation The theoretical foundations of the current work are three: Grosz and Sidner&apos;s theory of discourse structure, P</context>
</contexts>
<marker>[20]</marker>
<rawString>S. J. Young and F. Fallside. Speech synthesis from concept: a method for speech output from information systems. Journal of the Acoustic Society of America, 66(3):685-695, Sept 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Olive</author>
<author>M Y Liberman</author>
</authors>
<title>Text to speech — An overview.</title>
<date>1985</date>
<journal>Journal of the Acoustic Society of America, SuppL</journal>
<volume>78</volume>
<issue>3</issue>
<location>Fall</location>
<contexts>
<context position="2508" citStr="[21]" startWordPosition="363" endWordPosition="363">es in the summer of 1987. We thank Janet Pierrehumbert and Gregory Ward for valuable discussions. Direction Assistance was originally developed by Jim Davis and Tom Trobaugh in 1985 at the Thinking Machines Corporation of Cambridge. cannot be correctly produced by the text to speech system. To alleviate some of these problems, we modified Direction Assistance to make both attentional and intentional information about the route description available for the assignment of intonational features. With this information, we generate spoken directions using the Bell Laboratories Text-to-Speech System[21] in which pitch range, accent placement, phrasing, and tune can be varied to communicate attentional and intentional structure. The implementation of this intonation assignment component provides a first approximation of how recent models of discourse structure can be used to control intonational variation in ways that build upon recent research in intonational meaning. Additionally, it suggests ways in which these discourse models must be enhanced in order to permit the assignment of appropriate intonational features. In this paper, we first discuss some previous attempts to synthesize speech</context>
</contexts>
<marker>[21]</marker>
<rawString>J. P. Olive and M. Y. Liberman. Text to speech — An overview. Journal of the Acoustic Society of America, SuppL 1, 78(3):s6, Fall 1985.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>