<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000687">
<title confidence="0.989098">
BUAP: Three Approaches for Semantic Textual Similarity
</title>
<author confidence="0.971385">
Maya Carrillo, Darnes Vilari˜no, David Pinto, Mireya Tovar, Saul Le´on, Esteban Castillo
</author>
<affiliation confidence="0.981096">
Benem´erita Universidad Aut´onoma de Puebla,
Faculty of Computer Science
</affiliation>
<address confidence="0.980804">
14 Sur &amp; Av. San Claudio, CU
Puebla, Puebla, M´exico
</address>
<email confidence="0.8894175">
{cmaya, darnes, dpinto, mtovar}@cs.buap.mx
saul.ls@live.com,ecjbuap@gmail.com
</email>
<sectionHeader confidence="0.9958" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9956278125">
In this paper we describe the three approaches
we submitted to the Semantic Textual Similar-
ity task of SemEval 2012. The first approach
considers to calculate the semantic similar-
ity by using the Jaccard coefficient with term
expansion using synonyms. The second ap-
proach uses the semantic similarity reported
by Mihalcea in (Mihalcea et al., 2006). The
third approach employs Random Indexing and
Bag of Concepts based on context vectors. We
consider that the first and third approaches ob-
tained a comparable performance, meanwhile
the second approach got a very poor behav-
ior. The best ALL result was obtained with
the third approach, with a Pearson correlation
equal to 0.663.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.883388755555555">
Finding the semantic similarity between two sen-
tences is very important in applications of natural
language processing such as information retrieval
and related areas. The problem is complex due to the
small number of terms involved in sentences which
are tipically less than 10 or 15. Additionally, it is re-
quired to “understand” the meaning of the sentences
in order to determine the “semantic” similarity of
texts, which is quite different of finding the lexical
similarity.
There exist different works at literature dealing
with semantic similarity, but the problem is far to
be solved because of the aforementioned issues.
In (Mihalcea et al., 2006), for instance, it is pre-
sented a method for measuring the semantic simi-
larity of texts, using corpus-based and knowledge-
based measures of similarity. The approaches pre-
sented in (Shrestha, 2011) are based on the Vector
Space Model, with the aim to capture the contex-
tual behavior, senses and correlation, of terms. The
performance of the method is better than the base-
line method that uses vector based cosine similarity
measure.
In this paper, we present three different ap-
proaches for the Textual Semantic Similarity task of
Semeval 2012 (Agirre et al., 2012). The task is de-
scribed as follows: Given two sentences s1 and s2,
the aim is to compute how similar s1 and s2 are,
returning a similarity score, and an optional confi-
dence score. The approaches should provide values
between 0 and 5 for each pair of sentences. These
values roughly correspond to the following consid-
erations, even when the system should output real
values:
5: The two sentences are completely equivalent,
as they mean the same thing.
4: The two sentences are mostly equivalent, but
some unimportant details differ.
3: The two sentences are roughly equivalent, but
some important information differs/missing.
2: The two sentences are not equivalent, but share
some details.
1: The two sentences are not equivalent, but are
on the same topic.
0: The two sentences are on different topics.
</bodyText>
<page confidence="0.945076">
631
</page>
<note confidence="0.5679795">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 631–634,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.897148">
)
The description of the runs submitted to the com-
petition follows.
</bodyText>
<sectionHeader confidence="0.951734" genericHeader="method">
2 Experimentation setup
</sectionHeader>
<bodyText confidence="0.999849">
The three runs submitted to the competition use
completely different mechanisms to find the degree
of semantic similarity between two sentences. The
approaches are described as follows:
</bodyText>
<subsectionHeader confidence="0.6504935">
2.1 Approach BUAP-RUN-1: Term expansion
with synonyms
</subsectionHeader>
<bodyText confidence="0.999636727272727">
Let s1 = w1,1w1,2...w1,|31 |and s2 =
w2,1w2,2...w2,|32 |be two sentences. The synonyms
of a given word wi,k, expressed as synonyms(wi,k),
are obtained from online dictionaries by extracting
the synonyms of wi,k. A better matching between
the terms contained in the text fragments and the
terms at the dictionary are obtained by stemming all
the terms (using the Porter stemmer).
In order to determine the semantic similarity be-
tween any pair of terms of the two sentences (w1,i
and w2,j) we use Eq. (1).
</bodyText>
<equation confidence="0.48080925">
sim(w1,i, w2,j) =  1 if (w1,i == w2,j) ||
 w1,i E synonyms(w2,j) ||
 w2,j E synonyms(w1,i)
0 otherwise
</equation>
<bodyText confidence="0.9974315">
The similarity between sentences s1 and s2 is cal-
culated as shown in Eq. (2).
</bodyText>
<equation confidence="0.986693">
() = 5 * PZ 1 j=1 sim(w1i, w2j)
similarity s1, s2
</equation>
<subsectionHeader confidence="0.99276">
2.2 Approach BUAP-RUN-2
</subsectionHeader>
<bodyText confidence="0.999925">
In this approach, the similarity of s1 and s2 is calcu-
lated as shown in Eq. (3) (Mihalcea et al., 2006).
</bodyText>
<equation confidence="0.9386085">
1 Pw∈{s1}(maxSim(w,s2)*idf(w))
similarity(s1, s2) = 2( P idf (w)
wE{sl}
+ Pw∈ {s2 } (max Sim(w,s1)*idf (w))
idf (w)
Pw∈{s2}
</equation>
<bodyText confidence="0.9998635">
where idf(w) is the inverse document frequency of
the word w, and maxSim(w, s2) is the maximum
lexical similarity between the word w in sentence s2
and all the words in sentence s2 calculated by means
of the Eq. (4) reported by (Wu and Palmer, 1994).
The sentence terms are assumed to be concepts, LCS
is the depth of the least common subsumer, and the
equation is calculated using the NLTK libraries1.
</bodyText>
<equation confidence="0.9939025">
2 * depth(LCS)
Sim�up = depth(concept1) + depth(concept2)
</equation>
<subsectionHeader confidence="0.9549475">
2.3 Approach BUAP-RUN-3: Random
Indexing and Bag of Concepts
</subsectionHeader>
<bodyText confidence="0.999990705882353">
The vector space model (VSM) for document rep-
resentation supporting search is probably the most
well-known IR model. The VSM assumes that term
vectors are pair-wise orthogonal. This assumption
is very restrictive because words are not indepen-
dent. There have been various attempts to build
representations for documents that are semantically
richer than only vectors based on the frequency of
terms occurrence. One example is Latent Seman-
tic Indexing (LSI), a method of word co-occurrence
analysis to compute semantic vectors (context vec-
tors) for words. LSI applies singular-value decom-
position (SVD) to the term-document matrix in or-
der to construct context vectors. As a result the di-
mension of the produced vector space will be signif-
icantly smaller; consequently the vectors that repre-
sent terms cannot be orthogonal. However, dimen-
sion reduction techniques such as SVD are expen-
sive in terms of memory and processing time. Per-
forming the SVD takes time O (nmz), where n is
the vocabulary size, m is the number of documents,
and z is the number of nonzero elements per column
in the words-by-documents matrix. As an alterna-
tive, there is a vector space methodology called Ran-
dom Indexing (RI) (Sahlgren, 2005), which presents
an efficient, scalable, and incremental method for
building context vectors. Its computational com-
plexity is O (nr) where n is as previously described
and r is the vector dimension. Particularly, we apply
RI to capture the inherent semantic structure using
Bag of Concepts representation (BoC) as proposed
by Sahlgren and C¨oster (Sahlgren and C¨oster, 2004),
where the meaning of a term is considered as the
sum of contexts in which it occurs.
</bodyText>
<footnote confidence="0.6335495">
1http://www.nltk.org/
|s1 U s2|
</footnote>
<page confidence="0.981805">
632
</page>
<subsubsectionHeader confidence="0.689717">
2.3.1 Random Indexing
</subsubsectionHeader>
<bodyText confidence="0.99379675">
Random Indexing (RI) is a vector space method-
ology that accumulates context vectors for words
based on co-occurrence data. The technique can be
described as:
</bodyText>
<listItem confidence="0.99552585">
• First a unique random representation known as
index vector is assigned to each context (docu-
ment). Index vectors are binary vectors with a
small number of non-zero elements, which are
either +1 or -1, with equal amounts of both.
For example, if the index vectors have twenty
non-zero elements in a 1024-dimensional vec-
tor space, they have ten +1s and ten -1s. Index
vectors serve as indices or labels for documents
• Index vectors are used to produce context vec-
tors by scanning through the text and every
time a target word occurs in a context, the in-
dex vector of the context is added to the con-
text vector of the target word. Thus, at each
encounters of the target word t with a context c
the context vector of t is updated as follows: ct
+ = ic where ct is the context vector of t and ic
is the index vector of c. In this way, the context
vector of a word keeps track of the contexts in
which it occurred.
</listItem>
<bodyText confidence="0.996154">
RI methodology is similar to latent semantic in-
dexing (LSI) (Deerwester et al., 1990). However,
to reduce the co-occurrence matrix no dimension re-
duction technique such as SVD is needed, since the
dimensionality d of the random index vectors is pre-
established as a parameter (implicit dimension re-
duction). Consequently d does not change once it
has been set; as a result, the dimensionality of con-
text vectors will never change with the addition of
new data.
</bodyText>
<subsectionHeader confidence="0.995097">
2.3.2 Bag of Concepts
</subsectionHeader>
<bodyText confidence="0.999967625">
Bag of Concepts (BoC) is a recent representa-
tion scheme proposed by Sahlgren and C¨oster in
(Sahlgren and C¨oster, 2004), which is based on the
perception that the meaning of a document can be
considered as the union of the meanings of its terms.
This is accomplished by generating term context
vectors from each term within the document, and
generating a document vector as the weighted sum
of the term context vectors contained within that
document. Therefore, we use RI to represent the
meaning of a word as the sum of contexts (entire
documents) in which it occurs. Illustrating this tech-
nique, suppose you have two documents: D1: A man
with a hard hat is dancing, and D2: A man wearing
a hard hat is dancing. Let us suppose that they have
index vectors ID1 and ID2, respectively: the context
vector for hat will be the ID1 + ID2, because this
word appears in both documents. Once the context
vectors have been built by RI, they are used to repre-
sent the document as BoC. For instance, supposing
CV1, CV2, CV3, ... and CV8, are the context vec-
tors of each word in D1, then document D1 will be
represented as the weighted sum of these eight con-
text vectors.
</bodyText>
<subsectionHeader confidence="0.766206">
2.3.3 Implementation
</subsectionHeader>
<bodyText confidence="0.999991125">
The sentences of each file were processed to gen-
erate the BoC representations of them. BoC rep-
resentations were generated by first stemming all
words in the sentences. We then used random index-
ing to produce context vectors for each word in the
files (i.e. STS.input.MSRpar, STS.input.MSRvid,
etc.), each file was considered a different corpus and
documents were the sentences in them. The dimen-
sion of the context vectors was fixed at 2048, de-
termined by experimentation using the training set.
These context vectors were then tf x idf-weighted,
according to the corpus, and added up for each sen-
tence, to produce BoC representations. Therefore
the similarity values were calculated by the cosine
function. Finally cosine values were multiplied by 5
to produce values between 0 and 5.
</bodyText>
<sectionHeader confidence="0.989456" genericHeader="method">
3 Experimental results
</sectionHeader>
<bodyText confidence="0.999222333333333">
In Table 1 we show the results obtained by the
three approaches submitted to the competition. The
columns of Table 1 stand for:
</bodyText>
<listItem confidence="0.904687428571428">
• ALL: Pearson correlation with the gold stan-
dard for the five datasets, and corresponding
rank.
• ALLnrm: Pearson correlation after the system
outputs for each dataset are fitted to the gold
standard using least squares, and corresponding
rank.
</listItem>
<page confidence="0.996103">
633
</page>
<table confidence="0.9908325">
Run ALL Rank ALL Rank Mean Rank MSR MSR SMT On - SMT-
nrm Nrm Mean par vid eur WN news
BUAP- 0.4997 63 0.7568 62 0.4892 57 0.4037 0.6532 0.4521 0.605 0.4537
RUN-1
BUAP- -0.026 89 0.5933 89 0.0669 89 0.1109 0.0057 0.0348 0.1788 0.1964
RUN-2
BUAP- 0.663 25 0.7474 64 0.488 59 0.4018 0.6378 0.4758 0.5691 0.4057
RUN-3
</table>
<tableCaption confidence="0.999881">
Table 1: Results of approaches of BUAP in Task 6.
</tableCaption>
<listItem confidence="0.916579">
• Mean: Weighted mean across the 5 datasets,
</listItem>
<bodyText confidence="0.999545923076923">
where the weight depends on the number of
pairs in the dataset.
Followed by Pearson for individual datasets.
At this moment, we are not aware of the reasons
because the second approach obtained a very poor
performance. The way in which the idf(w) is calcu-
lated could be one of the reasons, because the corpus
used is relatively small and also from a different do-
main. With respect to the other two approaches, we
consider that they (first and third) obtained a com-
parable performance, even when the third approach
obtained the best ALL result with a Pearson correla-
tion equal to 0.663.
</bodyText>
<sectionHeader confidence="0.995238" genericHeader="discussions">
4 Discussion and conclusion
</sectionHeader>
<bodyText confidence="0.999997833333333">
We have presented three different approaches for
tackling the problem of Semantic Textual Similarity.
The use of term expansion by synonyms performed
well in general and obtained a comparable behavior
than the third approach which used random index-
ing and bag of concepts. It is interesting to observe
that these two approaches performed similar when
the two term expansion mechanism are totally dif-
ferent. As further, it is important to analyze the poor
behavior of the second approach. We would like also
to introduce semantic relationships other than syn-
onyms in the process of term expansion.
</bodyText>
<sectionHeader confidence="0.998844" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99902675">
This project has been partially supported by
projects CONACYT #106625, #VIAD-ING11-II,
PROMEP/103.5/11/4481 and VIEP #PIAD-ING11-
II.
</bodyText>
<sectionHeader confidence="0.999163" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999746466666667">
E. Agirre, D. Cer, M. Diab, and B. Dolan. 2012.
SemEval-2012 Task 6: Semantic Textual Similarity.
In Proceedings of the 6th International Workshop on
Semantic Evaluation (SemEval 2012).
Scott C. Deerwester, Susan T. Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by Latent Semantic Analysis. Jour-
nal of the American Society of Information Science,
41(6):391–407.
Rada Mihalcea, Courtney Corley, and Carlo Strapparava.
2006. Corpus-based and knowledge-based measures
of text semantic similarity. Inproceedings ofAAAI’06,
pages 775–780.
Magnus Sahlgren and Rickard C¨oster. 2004. Using bag-
of-concepts to improve the performance of support
vector machines in text categorization. In Proceedings
of the 20th international conference on Computational
Linguistics, COLING ’04, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
M. Sahlgren. 2005. An Introduction to Random Index-
ing. Methods and Applications of Semantic Indexing
Workshop at the 7th International Conference on Ter-
minology and Knowledge Engineering, TKE 2005.
Prajol Shrestha. 2011. Corpus-based methods for short
text similarity. In TALN 2011, Montpellier, France.
Zhibiao Wu and Martha Palmer. 1994. Verb semantics
and lexical selection. In 32nd. Annual Meeting of the
Association for Computational Linguistics, pages 133
–138, New Mexico State University, Las Cruces, New
Mexico.
</reference>
<page confidence="0.998619">
634
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.198515">
<title confidence="0.992582">BUAP: Three Approaches for Semantic Textual Similarity</title>
<author confidence="0.979907">Darnes David Pinto Carrillo</author>
<author confidence="0.979907">Mireya Tovar</author>
<author confidence="0.979907">Saul Le´on</author>
<author confidence="0.979907">Esteban</author>
<affiliation confidence="0.737128">Benem´erita Universidad Aut´onoma de Faculty of Computer 14 Sur &amp; Av. San Claudio,</affiliation>
<address confidence="0.995367">Puebla, Puebla,</address>
<email confidence="0.991091">darnes,dpinto,</email>
<abstract confidence="0.9964266875">In this paper we describe the three approaches we submitted to the Semantic Textual Similarity task of SemEval 2012. The first approach considers to calculate the semantic similarity by using the Jaccard coefficient with term expansion using synonyms. The second approach uses the semantic similarity reported by Mihalcea in (Mihalcea et al., 2006). The third approach employs Random Indexing and Bag of Concepts based on context vectors. We consider that the first and third approaches obtained a comparable performance, meanwhile the second approach got a very poor behavior. The best ALL result was obtained with the third approach, with a Pearson correlation</abstract>
<note confidence="0.613989">equal to 0.663.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Cer</author>
<author>M Diab</author>
<author>B Dolan</author>
</authors>
<date>2012</date>
<booktitle>SemEval-2012 Task 6: Semantic Textual Similarity. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="2267" citStr="Agirre et al., 2012" startWordPosition="349" endWordPosition="352">e of the aforementioned issues. In (Mihalcea et al., 2006), for instance, it is presented a method for measuring the semantic similarity of texts, using corpus-based and knowledgebased measures of similarity. The approaches presented in (Shrestha, 2011) are based on the Vector Space Model, with the aim to capture the contextual behavior, senses and correlation, of terms. The performance of the method is better than the baseline method that uses vector based cosine similarity measure. In this paper, we present three different approaches for the Textual Semantic Similarity task of Semeval 2012 (Agirre et al., 2012). The task is described as follows: Given two sentences s1 and s2, the aim is to compute how similar s1 and s2 are, returning a similarity score, and an optional confidence score. The approaches should provide values between 0 and 5 for each pair of sentences. These values roughly correspond to the following considerations, even when the system should output real values: 5: The two sentences are completely equivalent, as they mean the same thing. 4: The two sentences are mostly equivalent, but some unimportant details differ. 3: The two sentences are roughly equivalent, but some important info</context>
</contexts>
<marker>Agirre, Cer, Diab, Dolan, 2012</marker>
<rawString>E. Agirre, D. Cer, M. Diab, and B. Dolan. 2012. SemEval-2012 Task 6: Semantic Textual Similarity. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott C Deerwester</author>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
<author>George W Furnas</author>
<author>Richard A Harshman</author>
</authors>
<title>Indexing by Latent Semantic Analysis.</title>
<date>1990</date>
<journal>Journal of the American Society of Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="7984" citStr="Deerwester et al., 1990" startWordPosition="1312" endWordPosition="1315">rs serve as indices or labels for documents • Index vectors are used to produce context vectors by scanning through the text and every time a target word occurs in a context, the index vector of the context is added to the context vector of the target word. Thus, at each encounters of the target word t with a context c the context vector of t is updated as follows: ct + = ic where ct is the context vector of t and ic is the index vector of c. In this way, the context vector of a word keeps track of the contexts in which it occurred. RI methodology is similar to latent semantic indexing (LSI) (Deerwester et al., 1990). However, to reduce the co-occurrence matrix no dimension reduction technique such as SVD is needed, since the dimensionality d of the random index vectors is preestablished as a parameter (implicit dimension reduction). Consequently d does not change once it has been set; as a result, the dimensionality of context vectors will never change with the addition of new data. 2.3.2 Bag of Concepts Bag of Concepts (BoC) is a recent representation scheme proposed by Sahlgren and C¨oster in (Sahlgren and C¨oster, 2004), which is based on the perception that the meaning of a document can be considered</context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>Scott C. Deerwester, Susan T. Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. 1990. Indexing by Latent Semantic Analysis. Journal of the American Society of Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Courtney Corley</author>
<author>Carlo Strapparava</author>
</authors>
<title>Corpus-based and knowledge-based measures of text semantic similarity.</title>
<date>2006</date>
<booktitle>Inproceedings ofAAAI’06,</booktitle>
<pages>775--780</pages>
<contexts>
<context position="705" citStr="Mihalcea et al., 2006" startWordPosition="96" endWordPosition="99">˜no, David Pinto, Mireya Tovar, Saul Le´on, Esteban Castillo Benem´erita Universidad Aut´onoma de Puebla, Faculty of Computer Science 14 Sur &amp; Av. San Claudio, CU Puebla, Puebla, M´exico {cmaya, darnes, dpinto, mtovar}@cs.buap.mx saul.ls@live.com,ecjbuap@gmail.com Abstract In this paper we describe the three approaches we submitted to the Semantic Textual Similarity task of SemEval 2012. The first approach considers to calculate the semantic similarity by using the Jaccard coefficient with term expansion using synonyms. The second approach uses the semantic similarity reported by Mihalcea in (Mihalcea et al., 2006). The third approach employs Random Indexing and Bag of Concepts based on context vectors. We consider that the first and third approaches obtained a comparable performance, meanwhile the second approach got a very poor behavior. The best ALL result was obtained with the third approach, with a Pearson correlation equal to 0.663. 1 Introduction Finding the semantic similarity between two sentences is very important in applications of natural language processing such as information retrieval and related areas. The problem is complex due to the small number of terms involved in sentences which ar</context>
<context position="4447" citStr="Mihalcea et al., 2006" startWordPosition="710" endWordPosition="713">ontained in the text fragments and the terms at the dictionary are obtained by stemming all the terms (using the Porter stemmer). In order to determine the semantic similarity between any pair of terms of the two sentences (w1,i and w2,j) we use Eq. (1). sim(w1,i, w2,j) =  1 if (w1,i == w2,j) ||  w1,i E synonyms(w2,j) ||  w2,j E synonyms(w1,i) 0 otherwise The similarity between sentences s1 and s2 is calculated as shown in Eq. (2). () = 5 * PZ 1 j=1 sim(w1i, w2j) similarity s1, s2 2.2 Approach BUAP-RUN-2 In this approach, the similarity of s1 and s2 is calculated as shown in Eq. (3) (Mihalcea et al., 2006). 1 Pw∈{s1}(maxSim(w,s2)*idf(w)) similarity(s1, s2) = 2( P idf (w) wE{sl} + Pw∈ {s2 } (max Sim(w,s1)*idf (w)) idf (w) Pw∈{s2} where idf(w) is the inverse document frequency of the word w, and maxSim(w, s2) is the maximum lexical similarity between the word w in sentence s2 and all the words in sentence s2 calculated by means of the Eq. (4) reported by (Wu and Palmer, 1994). The sentence terms are assumed to be concepts, LCS is the depth of the least common subsumer, and the equation is calculated using the NLTK libraries1. 2 * depth(LCS) Sim�up = depth(concept1) + depth(concept2) 2.3 Approach </context>
</contexts>
<marker>Mihalcea, Corley, Strapparava, 2006</marker>
<rawString>Rada Mihalcea, Courtney Corley, and Carlo Strapparava. 2006. Corpus-based and knowledge-based measures of text semantic similarity. Inproceedings ofAAAI’06, pages 775–780.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
<author>Rickard C¨oster</author>
</authors>
<title>Using bagof-concepts to improve the performance of support vector machines in text categorization.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Sahlgren, C¨oster, 2004</marker>
<rawString>Magnus Sahlgren and Rickard C¨oster. 2004. Using bagof-concepts to improve the performance of support vector machines in text categorization. In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sahlgren</author>
</authors>
<title>An Introduction to Random Indexing.</title>
<date>2005</date>
<booktitle>Methods and Applications of Semantic Indexing Workshop at the 7th International Conference on Terminology and Knowledge Engineering, TKE</booktitle>
<contexts>
<context position="6309" citStr="Sahlgren, 2005" startWordPosition="1018" endWordPosition="1019">D) to the term-document matrix in order to construct context vectors. As a result the dimension of the produced vector space will be significantly smaller; consequently the vectors that represent terms cannot be orthogonal. However, dimension reduction techniques such as SVD are expensive in terms of memory and processing time. Performing the SVD takes time O (nmz), where n is the vocabulary size, m is the number of documents, and z is the number of nonzero elements per column in the words-by-documents matrix. As an alternative, there is a vector space methodology called Random Indexing (RI) (Sahlgren, 2005), which presents an efficient, scalable, and incremental method for building context vectors. Its computational complexity is O (nr) where n is as previously described and r is the vector dimension. Particularly, we apply RI to capture the inherent semantic structure using Bag of Concepts representation (BoC) as proposed by Sahlgren and C¨oster (Sahlgren and C¨oster, 2004), where the meaning of a term is considered as the sum of contexts in which it occurs. 1http://www.nltk.org/ |s1 U s2| 632 2.3.1 Random Indexing Random Indexing (RI) is a vector space methodology that accumulates context vect</context>
</contexts>
<marker>Sahlgren, 2005</marker>
<rawString>M. Sahlgren. 2005. An Introduction to Random Indexing. Methods and Applications of Semantic Indexing Workshop at the 7th International Conference on Terminology and Knowledge Engineering, TKE 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prajol Shrestha</author>
</authors>
<title>Corpus-based methods for short text similarity.</title>
<date>2011</date>
<booktitle>In TALN 2011,</booktitle>
<location>Montpellier, France.</location>
<contexts>
<context position="1900" citStr="Shrestha, 2011" startWordPosition="289" endWordPosition="290">n sentences which are tipically less than 10 or 15. Additionally, it is required to “understand” the meaning of the sentences in order to determine the “semantic” similarity of texts, which is quite different of finding the lexical similarity. There exist different works at literature dealing with semantic similarity, but the problem is far to be solved because of the aforementioned issues. In (Mihalcea et al., 2006), for instance, it is presented a method for measuring the semantic similarity of texts, using corpus-based and knowledgebased measures of similarity. The approaches presented in (Shrestha, 2011) are based on the Vector Space Model, with the aim to capture the contextual behavior, senses and correlation, of terms. The performance of the method is better than the baseline method that uses vector based cosine similarity measure. In this paper, we present three different approaches for the Textual Semantic Similarity task of Semeval 2012 (Agirre et al., 2012). The task is described as follows: Given two sentences s1 and s2, the aim is to compute how similar s1 and s2 are, returning a similarity score, and an optional confidence score. The approaches should provide values between 0 and 5 </context>
</contexts>
<marker>Shrestha, 2011</marker>
<rawString>Prajol Shrestha. 2011. Corpus-based methods for short text similarity. In TALN 2011, Montpellier, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In 32nd. Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<institution>New Mexico State University, Las Cruces,</institution>
<location>New Mexico.</location>
<contexts>
<context position="4822" citStr="Wu and Palmer, 1994" startWordPosition="776" endWordPosition="779">rity between sentences s1 and s2 is calculated as shown in Eq. (2). () = 5 * PZ 1 j=1 sim(w1i, w2j) similarity s1, s2 2.2 Approach BUAP-RUN-2 In this approach, the similarity of s1 and s2 is calculated as shown in Eq. (3) (Mihalcea et al., 2006). 1 Pw∈{s1}(maxSim(w,s2)*idf(w)) similarity(s1, s2) = 2( P idf (w) wE{sl} + Pw∈ {s2 } (max Sim(w,s1)*idf (w)) idf (w) Pw∈{s2} where idf(w) is the inverse document frequency of the word w, and maxSim(w, s2) is the maximum lexical similarity between the word w in sentence s2 and all the words in sentence s2 calculated by means of the Eq. (4) reported by (Wu and Palmer, 1994). The sentence terms are assumed to be concepts, LCS is the depth of the least common subsumer, and the equation is calculated using the NLTK libraries1. 2 * depth(LCS) Sim�up = depth(concept1) + depth(concept2) 2.3 Approach BUAP-RUN-3: Random Indexing and Bag of Concepts The vector space model (VSM) for document representation supporting search is probably the most well-known IR model. The VSM assumes that term vectors are pair-wise orthogonal. This assumption is very restrictive because words are not independent. There have been various attempts to build representations for documents that ar</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Palmer. 1994. Verb semantics and lexical selection. In 32nd. Annual Meeting of the Association for Computational Linguistics, pages 133 –138, New Mexico State University, Las Cruces, New Mexico.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>