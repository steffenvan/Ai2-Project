<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000211">
<title confidence="0.9942565">
Statistical Post Editing and Dictionary Extraction:
Systran/Edinburgh submissions for ACL-WMT2009
</title>
<note confidence="0.740531666666667">
Loic Dugast*,** and Jean Senellart*
* SYSTRAN S.A.
La Grande Arche
</note>
<address confidence="0.718131333333333">
1, Parvis de la D´efense
92044 Paris
La D´efense Cedex
</address>
<email confidence="0.475276">
France
</email>
<sectionHeader confidence="0.96311" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999962142857143">
We describe here the two Sys-
tran/University of Edinburgh submissions
for WMT2009. They involve a statistical
post-editing model with a particular han-
dling of named entities (English to French
and German to English) and the extraction
of phrasal rules (English to French).
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99983062962963">
Previous results had shown a rather satisfying per-
formance for hybrid systems such as the Statis-
tical Phrase-based Post-Editing (SPE) (Simard et
al., 2007) combination in comparison with purely
phrase-based statistical models, reaching simi-
lar BLEU scores and often receiving better hu-
man judgement (German to English at WMT2007)
against the BLEU metric. This last result was
in accordance with the previous acknowledgment
(Callison-Burch et al., 2006) that systems of too
differing structure could not be compared reliably
with BLEU. We participated in the recent Work-
shop on Machine Translation (WMT’09) in the
language pairs English to French and German to
English. On the one hand we trained a Post-
Editing system with an additional special treat-
ment to avoid the loss of entities such as dates and
numbers. On the other hand we trained an addi-
tional English-to-French system (as a secondary
submission) that made use of automatically ex-
tracted linguistic entries. In this paper, we will
present both approaches. The latter is part of on-
going work motivated by the desire to both make
use of corpus statistics and keep the advantage of
the often (relative to automatic metrics’s scores)
higher rank in human judgement given to rule-
based systems on out-of-domain data, as seen on
</bodyText>
<author confidence="0.85618">
Philipp Koehn**
</author>
<affiliation confidence="0.973461">
**School of Informatics
University of Edinburgh
</affiliation>
<figure confidence="0.611568333333333">
10 Crichton Street,
Edinburgh
United Kingdom
</figure>
<figureCaption confidence="0.999805">
Figure 1: Translation with PBMT post-editing
</figureCaption>
<bodyText confidence="0.999555333333333">
the WMT 2008 results for both English to French
and German to English (Callison-Burch et al.,
2008).
</bodyText>
<sectionHeader confidence="0.977962" genericHeader="method">
2 Statistical Post Editing systems
</sectionHeader>
<subsectionHeader confidence="0.887539">
2.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999315583333333">
The basic setup is identical to the one described
in (Dugast et al., 2007). A statistical translation
model is trained between the rule-based transla-
tion of the source-side and the target-side of the
parallel corpus. This is done separately for each
parallel corpus. Language models are trained on
each target half of the parallel corpora and also on
additional in-domain corpora. Figure 1 shows the
translation process.
Here are a few additional details which tend to
improve training and limit unwanted statistical ef-
fects in translation:
</bodyText>
<listItem confidence="0.965134428571428">
• Named entities are replaced by special tokens
on both sides. By reducing vocabulary and
combined with the next item mentioned, this
should help word alignment. Moreover, en-
tity translation is handled more reliably by
the rule-based engine.
• The intersection of both vocabularies (i.e. vo-
</listItem>
<note confidence="0.225636">
Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 110–114,
Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.998079">
110
</page>
<bodyText confidence="0.9998208">
cabularies of the rule-based output and the
reference translation) is used to produce an
additional parallel corpus (whose target is
identical to source). This was added to the
parallel text to improve the word alignment.
</bodyText>
<listItem confidence="0.87943425">
• Rule-based output and reference translations
are lowercased before performing alignment,
leaving the recasing job up to the rule-based
engine.
• Singleton phrase pairs are deleted from the
phrase table to avoid overfitting.
• Phrase pairs non cohesive regarding entities
are also discarded. We make the hypothe-
sis that entities are always passed to the tar-
get language and all entities in the target lan-
guage originate from the source language.
This point is discussed in section 2.2.
</listItem>
<bodyText confidence="0.996898">
We will discuss some of these details further in
the upcoming sections.
Due to time constraints, we did not use the Giga
French-English Parallel corpus provided for the
workshop. We only made use of the News Com-
mentary and the Europarl corpora. We used ad-
ditional in-domain news corpora to train 5 grams
language models, according to the baseline rec-
ommendations. Weights for these separate models
were tuned through the Mert algorithm provided
in the Moses toolkit (Koehn et al., 2007), using
the provided news tuning set.
</bodyText>
<subsectionHeader confidence="0.998518">
2.2 Trimming
</subsectionHeader>
<bodyText confidence="0.99998">
In a statistical translation model, trimming of
the phrase table had been shown to be beneficial
(Johnson et al., 2007). For our post-editing model,
we can afford to perform an even more aggressive
trimming of the phrase table, since the rule-based
system already provides us with a translation and
we only aim at correcting the most frequent er-
rors. Therefore, we suppress all unique phrase
pairs before calculating the probabilities for the fi-
nal phrase table.
</bodyText>
<subsectionHeader confidence="0.999923">
2.3 Avoiding the loss of entities
</subsectionHeader>
<bodyText confidence="0.895307">
Deleted and spurious content is a well known
problem for statistical models (Chiang et al.,
2008). Though we do not know of any study prov-
ing it, it seems obvious that Named Entities that
would be either deleted or added to the output out
of nowhere is an especially problematic kind of
Rule-Based French Reference French
ent date et
ent date ent numeric et
ent numeric de golfe . du golfe ent date.
d´ecennie ent numeric ans
et ent numeric. .
</bodyText>
<tableCaption confidence="0.992726">
Table 1: Examples of problematic phrase pairs
</tableCaption>
<bodyText confidence="0.999955571428571">
error for the translation quality. The rule-based
translation engine benefits from an entity recogni-
tion layer for numbers, dates and hours, addresses,
company names and URIs. We therefore ”trim”
(delete) from the extracted phrase pairs any item
that would not translate all entities from the source
(i.e. the RBMT output) to the target or add spuri-
ous entities which were not present in the source
side of the phrase pair. Table 1 illustrates the kind
of phrase pairs that are excluded from the model.
For example, the first phrase pair, when applied,
would simply erase the date entity which was ex-
pressed in the source sentence, which we of course
do not want.
</bodyText>
<sectionHeader confidence="0.99174" genericHeader="method">
3 Rule Extraction
</sectionHeader>
<bodyText confidence="0.999951692307692">
The baseline Systran rule-based system is more
or less a linguistic-oriented system that makes
use of a dependency analysis, general transfer
rules and dictionary entries, and finally a synthe-
sis/reordering stage. The dictionary entries have
long been the main entry point for customization
of the system. Such lexical translation rules are
fully linguistically coded dictionary entries, with
the following features attached: part-of-speech,
inflection category, headword and possibly some
semantic tags. Table 2 displays a sample of
manually-entered entries. These entries may both
match any inflected form of the source and gen-
erate the appropriate (according to general agree-
ment rules and depending on the source analysis)
target inflection.
Motivations for adding phrasal dictionary en-
tries (compound words) are twofold: first, just as
for statistical translation models which went from
word-based to phrase-based models, it helps solve
disambiguation and non-literal translations. Sec-
ond, as the rule-based engine makes use of a syn-
tactic analysis of a source sentence, adding un-
ambiguous phrasal chunks as entries will reduce
the overall syntactic ambiguity and lead to a better
source analysis.
</bodyText>
<page confidence="0.993475">
111
</page>
<table confidence="0.99965275">
POS English French headword English headword French
Noun college level niveau d’´etudes universitaires level niveau
Adverb on bail sous caution on sous
Verb badmouth m´edire de badmouth m´edire
</table>
<tableCaption confidence="0.991427">
Table 2: Example dictionary entries
</tableCaption>
<figureCaption confidence="0.995543">
Figure 2: Extraction pipeline: from parallel texts
to bilingual dictionary
</figureCaption>
<subsectionHeader confidence="0.6105585">
3.1 Manual customization through
dictionary entries
</subsectionHeader>
<bodyText confidence="0.999890642857143">
The Systran system provides a dictionary coding
tool (Senellart et al., 2003). This tool allows the
manual task of coding entries to be partially au-
tomated with the use of monolingual dictionaries
and probabilistic context-free grammars, while al-
lowing the user to fine-tune it by correcting the au-
tomatic coding and/or add more features. How-
ever, this remains first of all a time-consuming
task. Moreover, it is not easy for humans to select
the best translation among a set of alternatives, let
alone assign them probabilities. Last but not least,
the beneficial effect on translation is not guaran-
teed (especially, the effect on the rule-based de-
pendency analysis).
</bodyText>
<subsectionHeader confidence="0.936854">
3.2 Automatic extraction of dictionary
entries
</subsectionHeader>
<bodyText confidence="0.99998">
The problem consists of selecting relevant phrase
pairs from a set, coding them linguistically and as-
sign them probabilities. The extraction setup as
depicted in figure 2) starts from a parallel cor-
pus dataset. The baseline procedure is followed
(word alignment using GIZA++ and use of com-
mon heuristics to extract phrase pairs (Koehn et
al., 2007)) to extract phrase pairs. At this stage
the ”phrases” are plain word sequences, not nec-
essarily linguistically motivated. Some statistical
information is attached to each phrase pair: fre-
quency of the pair and lexical weights in both di-
rections. Each unique phrase pair is then pro-
cessed by our dictionary coding tool which tries
to map both word sequences to a given category.
If both sides are mapped to the same category, the
phrase pair, now lemmatized, is retained as a bilin-
gual entry. Otherwise, the candidate is excluded.
Given that a bilingual entry with a same lemma
may have various inflectional forms in corpus, we
then sum the lemma counts. Finally, in the current
setup, we only keep the most frequent translation
for each source.
For our secondary submission for English-
French, we extracted such entries from both the
News Commentary and the Europarl corpus.
</bodyText>
<subsectionHeader confidence="0.999778">
3.3 Validation of dictionary entries
</subsectionHeader>
<bodyText confidence="0.999978142857143">
The coding procedure, when applied to phrase
pairs extracted from the corpus instead of man-
ually entered entries, may generate rules that do
not lead to an improved translation. Recall that
we start from an existing system and only want to
learn additional rules to adapt to the domain of the
bilingual corpus we have at our disposal.
Now the problem consists of building the opti-
mal subset from the set of candidate entries, ac-
cording to a translation evaluation metric (here,
BLEU). Unlike the Mert procedure, we would
like to do more than assign global weights for the
whole set of translation rules, but instead make a
decision for each individual phrasal rule.
As an approximate response to this problem,
we test each extracted entry individually, start-
ing from the lower n-grams to the longer (source)
chunks, following algorithm 1. This results in
dictionaries of 5k and 170k entries for the News
Commentary and the Europarl parallel corpora, re-
spectively.
</bodyText>
<page confidence="0.995439">
112
</page>
<table confidence="0.999610166666666">
System BLEU
RBMT English-French 20.48
RBMT+SPE English-French 21.90
RBMT+Extracted dictionary English-French 20.82
RBMT German-English 15.13
RBMT+SPE German-English 17.50
</table>
<tableCaption confidence="0.9171905">
Table 3: Compared results of original RBMT system,post-editing and dictionary extraction: real-cased,
untokenized NIST Bleu scores on the full newstest2009 set(%)
</tableCaption>
<table confidence="0.999853888888889">
System nc- test2007 newstest2009
test2007 (eu- (news)
(news roparl)
commen-
tary)
RBMT 24.88 22.75 20.48
RBMT +Dictionary extracted from News Commentary 26.54 - 20.57
RBMT +Dictionary extracted from Europarl - 25.55 -
RBMT +Dictionary extracted from NC and Europarl, priority on NC 26.65 - 20.82
</table>
<tableCaption confidence="0.990121">
Table 4: Results of dictionary extraction for English-French: real-cased, untokenized NIST Bleu scores
</tableCaption>
<listItem confidence="0.910727058823529">
(%)
Algorithm 1 Dictionary Validation Algorithm
1: n=1
2: for n=1 to Nmax do
3: map all n-gram entries to parallel sentences
4: translate training corpus with current dic-
tionary
5: for each entry do
6: translate all relevant sentences with cur-
rent dictionary, plus this entry
7: compute BLEU scores without and with
the entry
8: end for
9: Select entries with better/worse sentences
ratio above threshold
10: add these entries to current dictionary
11: end for
</listItem>
<sectionHeader confidence="0.999369" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999925">
BLEU scores of the dictionary extraction exper-
iments for the English-French language pair and
three types of corpora are displayed in table 4.
Table 3 shows results on the news test set. Post-
editing setups were tuned on the news tuning set.
</bodyText>
<sectionHeader confidence="0.960358" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999987736842105">
We presented a few improvements to the Statisti-
cal Post Editing setup. They are part of an effort
to better integrate a linguistic, rule-based system
and the statistical correcting layer also illustrated
in (Ueffing et al., 2008). Moreover, we presented
a dictionary extraction setup which resulted in an
improvement of 2 to 3 BLEU points over the base-
line rule-based system when in-domain,as can be
seen in table 4. This however improved transla-
tion very little on the ”news” domain which was
used for evaluation. We think that is a different
issue, namely of domain adaptation. In order to
push further this rule-extraction approach and ac-
cording to our previous work (Dugast et al., 2007)
(Dugast et al., 2008), the most promising would
probably be the use of alternative meanings and
a language model to decode the best translation
in such a lattice. Another path for improvement
would be to try and extract rules with more fea-
</bodyText>
<page confidence="0.997406">
113
</page>
<bodyText confidence="0.999924">
tures, such as constraints of lexical subcategoriza-
tion as they already exist in the manually entered
entries. Finally, we would like to try combining
the dictionary extraction setup with a Statistical
Post-Editing layer to see if the latter supersedes
the former.
</bodyText>
<sectionHeader confidence="0.94575" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9993505">
We would like to thank the anonymous reviewers
for their comments and corrections.
</bodyText>
<sectionHeader confidence="0.99853" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999893456140351">
C. Callison-Burch, M. Osborne, and P. Koehn. 2006.
Re-evaluating the role of bleu in machine translation
research. In In proceedings of EACL 2006.
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2008.
Further meta-evaluation of machine translation. In
Proceedings of the Third Workshop on Statisti-
cal Machine Translation, pages 70–106, Columbus,
Ohio, June. Association for Computational Linguis-
tics.
David Chiang, Steve Deneefe, Yee S. Chan, and
Hwee T. Ng. 2008. Decomposability of translation
metrics for improved evaluation and efficient algo-
rithms. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 610–619, Honolulu, Hawaii, October. As-
sociation for Computational Linguistics.
Loic Dugast, Jean Senellart, and Philipp Koehn. 2007.
Statistical post-editing on SYSTRAN’s rule-based
translation system. In Proceedings of the Second
Workshop on Statistical Machine Translation, pages
220–223, Prague, Czech Republic, June. Associa-
tion for Computational Linguistics.
Loic Dugast, Jean Senellart, and Philipp Koehn. 2008.
Can we relearn an rbmt system? In Proceedings of
the Third Workshop on Statistical Machine Transla-
tion, Columbus, Ohio, U.S.A., June. Association for
Computational Linguistics.
Howard Johnson, Joel Martin, George Foster, and
Roland Kuhn. 2007. Improving translation qual-
ity by discarding most of the phrasetable. In Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 967–975, Prague, Czech Republic,
June. Association for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
ACL 2007, demonstration session.
Jean Senellart, Jin Yang, and Anabel Rebollo. 2003.
Technologie systran intuitive coding. In in Proceed-
ings of MT Summit IX.
M. Simard, C. Goutte, and P. Isabelle. 2007. Statisti-
cal phrase-based post-editing. In proceedings of the
NAACL-HLT. 2007. NRC 49288.
Nicola Ueffing, Jens Stephan, Evgeny Matusov, Loic
Dugast, George Foster, Roland Kuhn, Jean Senel-
lart, and Jin Yang. 2008. Tighter integration of
rule-based and statistical MT in serial system com-
bination. In Proceedings of the 22nd International
Conference on Computational Linguistics (Coling
2008), pages 913–920, Manchester, UK, August.
Coling 2008 Organizing Committee.
</reference>
<page confidence="0.998657">
114
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.127486">
<title confidence="0.9024035">Statistical Post Editing and Dictionary Systran/Edinburgh submissions for ACL-WMT2009</title>
<author confidence="0.958467">La Grande</author>
<address confidence="0.811864">1, Parvis de la 92044</address>
<author confidence="0.742736">La D´efense</author>
<affiliation confidence="0.292987">France</affiliation>
<abstract confidence="0.97335125">We describe here the two Systran/University of Edinburgh submissions for WMT2009. They involve a statistical post-editing model with a particular handling of named entities (English to French and German to English) and the extraction of phrasal rules (English to French).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>M Osborne</author>
<author>P Koehn</author>
</authors>
<title>Re-evaluating the role of bleu in machine translation research. In</title>
<date>2006</date>
<booktitle>In proceedings of EACL</booktitle>
<contexts>
<context position="975" citStr="Callison-Burch et al., 2006" startWordPosition="140" endWordPosition="143">st-editing model with a particular handling of named entities (English to French and German to English) and the extraction of phrasal rules (English to French). 1 Introduction Previous results had shown a rather satisfying performance for hybrid systems such as the Statistical Phrase-based Post-Editing (SPE) (Simard et al., 2007) combination in comparison with purely phrase-based statistical models, reaching similar BLEU scores and often receiving better human judgement (German to English at WMT2007) against the BLEU metric. This last result was in accordance with the previous acknowledgment (Callison-Burch et al., 2006) that systems of too differing structure could not be compared reliably with BLEU. We participated in the recent Workshop on Machine Translation (WMT’09) in the language pairs English to French and German to English. On the one hand we trained a PostEditing system with an additional special treatment to avoid the loss of entities such as dates and numbers. On the other hand we trained an additional English-to-French system (as a secondary submission) that made use of automatically extracted linguistic entries. In this paper, we will present both approaches. The latter is part of ongoing work m</context>
</contexts>
<marker>Callison-Burch, Osborne, Koehn, 2006</marker>
<rawString>C. Callison-Burch, M. Osborne, and P. Koehn. 2006. Re-evaluating the role of bleu in machine translation research. In In proceedings of EACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Cameron Fordyce</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>Further meta-evaluation of machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>70--106</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="2058" citStr="Callison-Burch et al., 2008" startWordPosition="318" endWordPosition="321">that made use of automatically extracted linguistic entries. In this paper, we will present both approaches. The latter is part of ongoing work motivated by the desire to both make use of corpus statistics and keep the advantage of the often (relative to automatic metrics’s scores) higher rank in human judgement given to rulebased systems on out-of-domain data, as seen on Philipp Koehn** **School of Informatics University of Edinburgh 10 Crichton Street, Edinburgh United Kingdom Figure 1: Translation with PBMT post-editing the WMT 2008 results for both English to French and German to English (Callison-Burch et al., 2008). 2 Statistical Post Editing systems 2.1 Baseline The basic setup is identical to the one described in (Dugast et al., 2007). A statistical translation model is trained between the rule-based translation of the source-side and the target-side of the parallel corpus. This is done separately for each parallel corpus. Language models are trained on each target half of the parallel corpora and also on additional in-domain corpora. Figure 1 shows the translation process. Here are a few additional details which tend to improve training and limit unwanted statistical effects in translation: • Named e</context>
</contexts>
<marker>Callison-Burch, Fordyce, Koehn, Monz, Schroeder, 2008</marker>
<rawString>Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2008. Further meta-evaluation of machine translation. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 70–106, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Steve Deneefe</author>
<author>Yee S Chan</author>
<author>Hwee T Ng</author>
</authors>
<title>Decomposability of translation metrics for improved evaluation and efficient algorithms.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>610--619</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="4960" citStr="Chiang et al., 2008" startWordPosition="782" endWordPosition="785"> tuning set. 2.2 Trimming In a statistical translation model, trimming of the phrase table had been shown to be beneficial (Johnson et al., 2007). For our post-editing model, we can afford to perform an even more aggressive trimming of the phrase table, since the rule-based system already provides us with a translation and we only aim at correcting the most frequent errors. Therefore, we suppress all unique phrase pairs before calculating the probabilities for the final phrase table. 2.3 Avoiding the loss of entities Deleted and spurious content is a well known problem for statistical models (Chiang et al., 2008). Though we do not know of any study proving it, it seems obvious that Named Entities that would be either deleted or added to the output out of nowhere is an especially problematic kind of Rule-Based French Reference French ent date et ent date ent numeric et ent numeric de golfe . du golfe ent date. d´ecennie ent numeric ans et ent numeric. . Table 1: Examples of problematic phrase pairs error for the translation quality. The rule-based translation engine benefits from an entity recognition layer for numbers, dates and hours, addresses, company names and URIs. We therefore ”trim” (delete) fr</context>
</contexts>
<marker>Chiang, Deneefe, Chan, Ng, 2008</marker>
<rawString>David Chiang, Steve Deneefe, Yee S. Chan, and Hwee T. Ng. 2008. Decomposability of translation metrics for improved evaluation and efficient algorithms. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 610–619, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loic Dugast</author>
<author>Jean Senellart</author>
<author>Philipp Koehn</author>
</authors>
<title>Statistical post-editing on SYSTRAN’s rule-based translation system.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>220--223</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2182" citStr="Dugast et al., 2007" startWordPosition="339" endWordPosition="342">ngoing work motivated by the desire to both make use of corpus statistics and keep the advantage of the often (relative to automatic metrics’s scores) higher rank in human judgement given to rulebased systems on out-of-domain data, as seen on Philipp Koehn** **School of Informatics University of Edinburgh 10 Crichton Street, Edinburgh United Kingdom Figure 1: Translation with PBMT post-editing the WMT 2008 results for both English to French and German to English (Callison-Burch et al., 2008). 2 Statistical Post Editing systems 2.1 Baseline The basic setup is identical to the one described in (Dugast et al., 2007). A statistical translation model is trained between the rule-based translation of the source-side and the target-side of the parallel corpus. This is done separately for each parallel corpus. Language models are trained on each target half of the parallel corpora and also on additional in-domain corpora. Figure 1 shows the translation process. Here are a few additional details which tend to improve training and limit unwanted statistical effects in translation: • Named entities are replaced by special tokens on both sides. By reducing vocabulary and combined with the next item mentioned, this</context>
<context position="12706" citStr="Dugast et al., 2007" startWordPosition="2020" endWordPosition="2023">They are part of an effort to better integrate a linguistic, rule-based system and the statistical correcting layer also illustrated in (Ueffing et al., 2008). Moreover, we presented a dictionary extraction setup which resulted in an improvement of 2 to 3 BLEU points over the baseline rule-based system when in-domain,as can be seen in table 4. This however improved translation very little on the ”news” domain which was used for evaluation. We think that is a different issue, namely of domain adaptation. In order to push further this rule-extraction approach and according to our previous work (Dugast et al., 2007) (Dugast et al., 2008), the most promising would probably be the use of alternative meanings and a language model to decode the best translation in such a lattice. Another path for improvement would be to try and extract rules with more fea113 tures, such as constraints of lexical subcategorization as they already exist in the manually entered entries. Finally, we would like to try combining the dictionary extraction setup with a Statistical Post-Editing layer to see if the latter supersedes the former. Acknowledgement We would like to thank the anonymous reviewers for their comments and corre</context>
</contexts>
<marker>Dugast, Senellart, Koehn, 2007</marker>
<rawString>Loic Dugast, Jean Senellart, and Philipp Koehn. 2007. Statistical post-editing on SYSTRAN’s rule-based translation system. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 220–223, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loic Dugast</author>
<author>Jean Senellart</author>
<author>Philipp Koehn</author>
</authors>
<title>Can we relearn an rbmt system?</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio, U.S.A.,</location>
<marker>Dugast, Senellart, Koehn, 2008</marker>
<rawString>Loic Dugast, Jean Senellart, and Philipp Koehn. 2008. Can we relearn an rbmt system? In Proceedings of the Third Workshop on Statistical Machine Translation, Columbus, Ohio, U.S.A., June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Howard Johnson</author>
<author>Joel Martin</author>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Improving translation quality by discarding most of the phrasetable.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>967--975</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="4485" citStr="Johnson et al., 2007" startWordPosition="704" endWordPosition="707">ls further in the upcoming sections. Due to time constraints, we did not use the Giga French-English Parallel corpus provided for the workshop. We only made use of the News Commentary and the Europarl corpora. We used additional in-domain news corpora to train 5 grams language models, according to the baseline recommendations. Weights for these separate models were tuned through the Mert algorithm provided in the Moses toolkit (Koehn et al., 2007), using the provided news tuning set. 2.2 Trimming In a statistical translation model, trimming of the phrase table had been shown to be beneficial (Johnson et al., 2007). For our post-editing model, we can afford to perform an even more aggressive trimming of the phrase table, since the rule-based system already provides us with a translation and we only aim at correcting the most frequent errors. Therefore, we suppress all unique phrase pairs before calculating the probabilities for the final phrase table. 2.3 Avoiding the loss of entities Deleted and spurious content is a well known problem for statistical models (Chiang et al., 2008). Though we do not know of any study proving it, it seems obvious that Named Entities that would be either deleted or added t</context>
</contexts>
<marker>Johnson, Martin, Foster, Kuhn, 2007</marker>
<rawString>Howard Johnson, Joel Martin, George Foster, and Roland Kuhn. 2007. Improving translation quality by discarding most of the phrasetable. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 967–975, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="4315" citStr="Koehn et al., 2007" startWordPosition="676" endWordPosition="679"> target language and all entities in the target language originate from the source language. This point is discussed in section 2.2. We will discuss some of these details further in the upcoming sections. Due to time constraints, we did not use the Giga French-English Parallel corpus provided for the workshop. We only made use of the News Commentary and the Europarl corpora. We used additional in-domain news corpora to train 5 grams language models, according to the baseline recommendations. Weights for these separate models were tuned through the Mert algorithm provided in the Moses toolkit (Koehn et al., 2007), using the provided news tuning set. 2.2 Trimming In a statistical translation model, trimming of the phrase table had been shown to be beneficial (Johnson et al., 2007). For our post-editing model, we can afford to perform an even more aggressive trimming of the phrase table, since the rule-based system already provides us with a translation and we only aim at correcting the most frequent errors. Therefore, we suppress all unique phrase pairs before calculating the probabilities for the final phrase table. 2.3 Avoiding the loss of entities Deleted and spurious content is a well known problem</context>
<context position="8663" citStr="Koehn et al., 2007" startWordPosition="1368" endWordPosition="1371">e best translation among a set of alternatives, let alone assign them probabilities. Last but not least, the beneficial effect on translation is not guaranteed (especially, the effect on the rule-based dependency analysis). 3.2 Automatic extraction of dictionary entries The problem consists of selecting relevant phrase pairs from a set, coding them linguistically and assign them probabilities. The extraction setup as depicted in figure 2) starts from a parallel corpus dataset. The baseline procedure is followed (word alignment using GIZA++ and use of common heuristics to extract phrase pairs (Koehn et al., 2007)) to extract phrase pairs. At this stage the ”phrases” are plain word sequences, not necessarily linguistically motivated. Some statistical information is attached to each phrase pair: frequency of the pair and lexical weights in both directions. Each unique phrase pair is then processed by our dictionary coding tool which tries to map both word sequences to a given category. If both sides are mapped to the same category, the phrase pair, now lemmatized, is retained as a bilingual entry. Otherwise, the candidate is excluded. Given that a bilingual entry with a same lemma may have various infle</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL 2007, demonstration session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Senellart</author>
<author>Jin Yang</author>
<author>Anabel Rebollo</author>
</authors>
<title>Technologie systran intuitive coding.</title>
<date>2003</date>
<booktitle>In in Proceedings of MT Summit IX.</booktitle>
<contexts>
<context position="7676" citStr="Senellart et al., 2003" startWordPosition="1209" endWordPosition="1212">e makes use of a syntactic analysis of a source sentence, adding unambiguous phrasal chunks as entries will reduce the overall syntactic ambiguity and lead to a better source analysis. 111 POS English French headword English headword French Noun college level niveau d’´etudes universitaires level niveau Adverb on bail sous caution on sous Verb badmouth m´edire de badmouth m´edire Table 2: Example dictionary entries Figure 2: Extraction pipeline: from parallel texts to bilingual dictionary 3.1 Manual customization through dictionary entries The Systran system provides a dictionary coding tool (Senellart et al., 2003). This tool allows the manual task of coding entries to be partially automated with the use of monolingual dictionaries and probabilistic context-free grammars, while allowing the user to fine-tune it by correcting the automatic coding and/or add more features. However, this remains first of all a time-consuming task. Moreover, it is not easy for humans to select the best translation among a set of alternatives, let alone assign them probabilities. Last but not least, the beneficial effect on translation is not guaranteed (especially, the effect on the rule-based dependency analysis). 3.2 Auto</context>
</contexts>
<marker>Senellart, Yang, Rebollo, 2003</marker>
<rawString>Jean Senellart, Jin Yang, and Anabel Rebollo. 2003. Technologie systran intuitive coding. In in Proceedings of MT Summit IX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>C Goutte</author>
<author>P Isabelle</author>
</authors>
<title>Statistical phrase-based post-editing.</title>
<date>2007</date>
<booktitle>In proceedings of the NAACL-HLT.</booktitle>
<pages>49288</pages>
<contexts>
<context position="678" citStr="Simard et al., 2007" startWordPosition="97" endWordPosition="100">n/Edinburgh submissions for ACL-WMT2009 Loic Dugast*,** and Jean Senellart* * SYSTRAN S.A. La Grande Arche 1, Parvis de la D´efense 92044 Paris La D´efense Cedex France Abstract We describe here the two Systran/University of Edinburgh submissions for WMT2009. They involve a statistical post-editing model with a particular handling of named entities (English to French and German to English) and the extraction of phrasal rules (English to French). 1 Introduction Previous results had shown a rather satisfying performance for hybrid systems such as the Statistical Phrase-based Post-Editing (SPE) (Simard et al., 2007) combination in comparison with purely phrase-based statistical models, reaching similar BLEU scores and often receiving better human judgement (German to English at WMT2007) against the BLEU metric. This last result was in accordance with the previous acknowledgment (Callison-Burch et al., 2006) that systems of too differing structure could not be compared reliably with BLEU. We participated in the recent Workshop on Machine Translation (WMT’09) in the language pairs English to French and German to English. On the one hand we trained a PostEditing system with an additional special treatment t</context>
</contexts>
<marker>Simard, Goutte, Isabelle, 2007</marker>
<rawString>M. Simard, C. Goutte, and P. Isabelle. 2007. Statistical phrase-based post-editing. In proceedings of the NAACL-HLT. 2007. NRC 49288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Jens Stephan</author>
<author>Evgeny Matusov</author>
<author>Loic Dugast</author>
<author>George Foster</author>
<author>Roland Kuhn</author>
<author>Jean Senellart</author>
<author>Jin Yang</author>
</authors>
<title>Tighter integration of rule-based and statistical MT in serial system combination.</title>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>913--920</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="12244" citStr="Ueffing et al., 2008" startWordPosition="1942" endWordPosition="1945">tries with better/worse sentences ratio above threshold 10: add these entries to current dictionary 11: end for 4 Results BLEU scores of the dictionary extraction experiments for the English-French language pair and three types of corpora are displayed in table 4. Table 3 shows results on the news test set. Postediting setups were tuned on the news tuning set. 5 Conclusion and future work We presented a few improvements to the Statistical Post Editing setup. They are part of an effort to better integrate a linguistic, rule-based system and the statistical correcting layer also illustrated in (Ueffing et al., 2008). Moreover, we presented a dictionary extraction setup which resulted in an improvement of 2 to 3 BLEU points over the baseline rule-based system when in-domain,as can be seen in table 4. This however improved translation very little on the ”news” domain which was used for evaluation. We think that is a different issue, namely of domain adaptation. In order to push further this rule-extraction approach and according to our previous work (Dugast et al., 2007) (Dugast et al., 2008), the most promising would probably be the use of alternative meanings and a language model to decode the best trans</context>
</contexts>
<marker>Ueffing, Stephan, Matusov, Dugast, Foster, Kuhn, Senellart, Yang, 2008</marker>
<rawString>Nicola Ueffing, Jens Stephan, Evgeny Matusov, Loic Dugast, George Foster, Roland Kuhn, Jean Senellart, and Jin Yang. 2008. Tighter integration of rule-based and statistical MT in serial system combination. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 913–920, Manchester, UK, August. Coling 2008 Organizing Committee.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>