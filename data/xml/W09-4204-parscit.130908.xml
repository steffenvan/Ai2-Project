<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.377495">
HMMs, GRs, and n-grams as lexical substitution techniques – are
they portable to other languages?
</title>
<author confidence="0.690678">
Judita Preiss Andrew Coonce
</author>
<affiliation confidence="0.912034">
Department of Linguistics The Ohio State University
The Ohio State University coonce.3@osu.edu
</affiliation>
<email confidence="0.997429">
judita@ling.ohio-state.edu
</email>
<author confidence="0.980282">
Brittany Baker
</author>
<affiliation confidence="0.990998">
The Ohio State University
</affiliation>
<email confidence="0.997777">
baker.1189@osu.edu
</email>
<sectionHeader confidence="0.98947" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999881090909091">
We introduce a number of novel techniques to
lexical substitution, including an application of
the Forward-Backward algorithm, a grammatical
relation based similarity measure, and a modified
form of n-gram matching. We test these tech-
niques on the SEMEVAL-2007 lexical substitution
data [McCarthy and Navigli, 2007], to demon-
strate their competitive performance. We create
a similar (small scale) dataset for Czech, and our
evaluation demonstrates language independence
of the techniques.
</bodyText>
<sectionHeader confidence="0.986872" genericHeader="keywords">
Keywords
</sectionHeader>
<keyword confidence="0.991497333333333">
Lexical substitution, synonyms, Google n-gram corpus,
grammatical relations, HMMs, Forward-Backward algorithm,
Lucene, Czech, word sense disambiguation
</keyword>
<sectionHeader confidence="0.998795" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99907525">
We present a number of novel approaches to lexical
substitution, a task which for a given target word, re-
quires the selection of a suitable alternative word. Our
highly modular system not only allows a trivial addi-
tion of new modules, but also explores the applicability
of the techniques to English and Czech.
Lexical substitution was suggested as a way of eval-
uating word sense disambiguation [McCarthy, 2002],
accounting for the difficulties with selecting a sense
inventory in the traditional direct sense evaluations
(e.g., [Preiss and Yarowsky, 2002]). In the lexical sub-
stitution task, instead of being presented with a set
of possible senses to choose from, a system is given
a word and is required to find a suitable alternative
given the context. For example, the word bright in the
sentence
His parents felt that he was a bright boy.
can be replaced with the word intelligent. How-
ever, the same substitution for the same word in
the context of the word star (e.g., in the sentence
Our Sun is a bright star.) is unlikely to reflect
the intended meaning. The applications of a sys-
tem capable of making such substitutions lie in ques-
tion answering, summarisation, paraphrase acquisition
</bodyText>
<page confidence="0.992031">
21
</page>
<bodyText confidence="0.972992">
[Dagan et al., 2006], text simplification and lexical ac-
quisition [McCarthy, 2002].
An evaluation task was set up as part
of SEMEVAL-2007 evaluation exercises
[McCarthy and Navigli, 2007], in which partici-
pants were given a target word and its context and
were expected to find a suitable substitutable word or
phrase. A second task is proposed for SEMEVAL-2010
[Sinha et al., 2009], which expects participants to
select a possible substitute from another language,
given an input word and context in English.
As with many natural language processing tasks,
most work on lexical substitution has been carried
out in English. As the lexical substitution task re-
quires an annotated corpus, it is non-trivial to carry
out large-scale experiments in other languages. We
create a small corpus for Czech, and evaluate our
lexical substitution modulesl not only on the SE-
MEVAL-2007 lexical substitution data in English, but
also on our Czech dataset. Unlike the proposed
[Sinha et al., 2009] cross-lingual lexical substitution
task in SEMEVAL-2010, in our experiment the target
words and contexts as well as substitute are all in
Czech.
For English, we demonstrate
</bodyText>
<listItem confidence="0.898673">
1. the importance of refining the set of input can-
didate substitutes prior to a candidate ranking
module being run, and
2. show our modules’ suitability to be used in lexical
substitution tasks
</listItem>
<bodyText confidence="0.999335">
We create a communal set of candidates, which
are used by three independent modules: a gram-
matical relation [Briscoe et al., 2002] based module
investigating the syntactic (and to a certain ex-
tent semantic) similarity of contexts, an n-gram
module exploiting the Google Web 1T 5-gram cor-
pus [Brants and Franz, 2006], and a module discov-
ering the optimal path through the sentence based
on the Forward-Backward HMM algorithm (e.g.,
[Roark and Sproat, 2007]).
</bodyText>
<footnote confidence="0.865723">
1 Note that such an evaluation is not possible for all of our
modules, due to the lack of available tools for the Czech lan-
guage.
NLP Methods and Corpora in Translation, Lexicography, and Language Learning 2009 – Borovets, Bulgaria, pages 21–27
</footnote>
<bodyText confidence="0.999500285714286">
Our paper is organized as follows: Section 2 de-
scribes the technique used to create a weighted candi-
date set, Sections 3, 4, and 5 contain the GR, n-gram
and HMM modules respectively. An initial evaluation
on English is presented in Section 6. Our experiment
on Czech, and the data used to enable this, appears in
Section 7, with conclusions drawn in Section 8.
</bodyText>
<sectionHeader confidence="0.392699" genericHeader="method">
2 Building a candidate set
</sectionHeader>
<bodyText confidence="0.999221043478261">
We create a very modular system, where each of our
lexical substitution selection methods is entirely inde-
pendent of the others. The modules share a common
input: the possible set of candidates for each word.
In his work, [Yuret, 2007] presents the most successful
system in SEMEVAL-2007 and comments that “I spent
a considerable amount of effort trying to optimize the
substitute sets”. We therefore explore performance
with two different candidate sets to investigate the hy-
pothesis that the approach used is as important as the
candidates selected.
The first approach, which finds the maximum pos-
sible performance of the modules (an upper bound),
is given all candidates which appeared for the target
word in the gold standard data. I.e., all the possi-
ble substitutes from the gold standard are gathered
together, and given to the modules as possible can-
didates. (However, as no module is designed to cope
with multiword candidates, all the multiword candi-
dates are removed.)
Our second set of candidates is constructed from
WordNet [Miller et al., 1990] and the online encyclo-
pedia Encarta (http://encarta.msn.com) as follows:
</bodyText>
<listItem confidence="0.993804428571429">
• All WordNet (WN) synonyms of the target word
are included (i.e., synonyms of all the possible
senses of the correct part of speech)2.
• The hypernym synset and the hyponym synset
are also included for all possible senses.
• All possible Encarta synonyms of the correct part
of speech are extracted.
</listItem>
<bodyText confidence="0.9866585">
A probability distribution is placed on these candi-
dates based on these (manually selected) weights:
</bodyText>
<table confidence="0.967196">
Source Weight
WN synonym 3
WN hypernym 1
WN hyponym 2
Encarta 3
</table>
<bodyText confidence="0.9933545">
I.e., if a candidate appears both as a WN synonym
and in Encarta, it will get a weight of 6, while if it
is only appearing as a hyponym, it’s weight will be 2.
For example, for the test word account (noun):
</bodyText>
<listItem confidence="0.97560525">
1. WN synonyms: history, chronicle, story, bill, in-
voice, report, story, explanation, ...
2. WN hypernyms: record, importance, profit, gain,
statement, ...
</listItem>
<footnote confidence="0.455523">
2 The part of speech of the target word is given in the data.
</footnote>
<table confidence="0.9986974">
PoS Average
Noun 56
Verb 127
Adjective 37
Adverb 9
</table>
<tableCaption confidence="0.998611">
Table 1: Average number of candidates
</tableCaption>
<listItem confidence="0.99209275">
3. WN hyponyms: etymology, annals, biography,
life, recital, reckoning, tally, ...
4. Encarta: report, description, story, narrative, ex-
planation, version, interpretation, tally, ...
</listItem>
<bodyText confidence="0.901716352941176">
the Encarta synonyms add new candidates, while also
boosting the weights of, e.g., the synonym story, or
the hyponym tally. Once all the candidates for a tar-
get word are generated, the weights are converted into
a probability distribution.3 The average numbers of
candidates for each part of speech are presented in
Table 1.
While the GR and the n-gram modules only re-
quire a set of candidates for the target words, the
HMM module requires potential candidates for all
words in the sentence in order to find an optimal path
through the data. These candidates were generated
in the same manner, with PoS tags drawn from the
[Elworthy, 1994] tagger (executed as part of RASP
[Briscoe et al., 2006]), with the exception that for the
non-target words, the original word was also included
in the candidate set.
</bodyText>
<sectionHeader confidence="0.9914" genericHeader="method">
3 Grammatical relations
</sectionHeader>
<bodyText confidence="0.996716454545455">
Given the candidates generated in Section 2, we create
several different (hopefully complementary) modules.
A combination of these can then utilize the different
strengths and weakness of each approach to create a
more accurate ranking of proposed candidates overall.
The modules can therefore run independently to select
the most likely of any given candidates.
For each target word, its context was parsed with
RASP [Briscoe et al., 2006] producing grammatical
relations (GRs). GRs, mainly binary relations ex-
pressing information about predicates and arguments,
provide a good means for capturing both syntactic
structural information, but also some sense of seman-
tic meaning as well [Briscoe et al., 2002]. GR such as
(dobj give dog)
where the GR is dobj (direct object), it not only tells
us that give directly dominates dog (syntax), but there
is also a description about a patient relationship.
The main advantage of GRs, as opposed to, for ex-
ample, n-grams, is the possibility of GRs encoding long
distance dependencies. Even with simple sentences,
such as:
</bodyText>
<listItem confidence="0.70955225">
• Bob Smith gave the bone to the dog.
• Bob Smith gave the big juicy bone to the dog.
3 The low hypernym score is due to relatively rare occurrence
of the correct candidate being in the hypernym set.
</listItem>
<page confidence="0.988243">
22
</page>
<bodyText confidence="0.9999819">
the GRs will contain the dobj give bone relation for
both sentences, while a five word n-gram centered on
the target word give will not even mention the word
bone in the second case.
The motivation behind this approach is in the as-
sumption that a word which is a valid lexical substitute
will appear in the same GRs as the target word. This
requires a large corpus annotated with GRs: to this
end we employ Gigaword [Graff, 2003], a large collec-
tion of English text, which we parsed with the RASP
parser and collected information about frequencies of
GR occurrences. The GR occurrences are indexed us-
ing Lucene, to allow incremental building and search-
ing of the dataset. Each word can be queried, pro-
ducing a listing of every applicable GR in which said
word appeared in the Gigaword corpus, along with a
frequency count of occurrence(s) for each GR. A pre-
liminary search was performed on this index to obtain
initial probabilities for each GR.
For each target word, all the GRs from its context
are extracted and the target word is substituted with
a possible candidate. The frequency of this GR is ex-
tracted from the parsed corpus, and divided by the
probability of that GR, in order to account for un-
equal GR occurrences throughout the index (the GR
ncmod, for example, appeared many times more than
the GR iobj). For each candidate, all its GR fre-
quency weights are summed, and the weights are nor-
malized to produce a probability distribution on can-
didates.
</bodyText>
<sectionHeader confidence="0.894581" genericHeader="method">
4 n-grams
</sectionHeader>
<bodyText confidence="0.999799333333333">
Approaches based on n-grams drawn from the
Google Web1T corpus [Brants and Franz, 2006] have
been shown to constitute a particularly good ap-
proach to lexical substitution with the best perform-
ing system in SEMEVAL-2007 being n-gram based
[Hassan et al., 2007]. The basic algorithm for such an
approach is very clear: an n-gram containing the cho-
sen word is extracted from the context, the chosen
word is then replaced with a candidate and the fre-
quency of the newly formed n-gram is found. The
candidate with the highest frequency wins.
For this work, we use the Google Web1T corpus,
a publicly available resource, containing frequency in-
formation about 1, 2, 3, 4 and 5-grams drawn from
one trillion (1012) words of English Web text, sub-
ject to a minimum occurrence threshold. While such
a corpus is obviously a very valuable resource, it has
been found previously that it is difficult to use due
to its sheer size (it is 25Gb in compressed form). In
order to provide a reasonable access time (and mul-
tiple wildcard searches), we treated each 5-gram as
a separate document and indexed the 5-gram corpus
with the publicly available tool Lucene (available from
http://lucene.apache.org).4
For a word w with possible candidate substitutions
s1, s2, ... , sn, we exploit a 5 word window W centered
around w in the following way for each si:
</bodyText>
<footnote confidence="0.666353">
4 Note that subject to a predictably regular repetition, the in-
formation contained in the 2, 3, and 4-grams can be extracted
from the 5-gram corpus.
</footnote>
<listItem confidence="0.880046769230769">
• We search for the frequency (f5_9,,,,(si)) of the
5-gram W with w replaced with si.
• The replaced 5-gram is also searched in a sto-
plisted form (fgt,,(si)). Note that this can result
in a much smaller n-gram.
• The frequencies of all consecutive subset 4-grams
(with the target word w replaced with si) are ex-
tracted (f4_9,,,,j(si) for j = 1, ... , 4).
• The absolute frequency of the unigram si is also
retrieved (f1_9,,,,(si)). A more frequent unigram
is more likely to be found as part of a 5-gram or 4-
gram, purely due to the frequency of occurrence.
This factor allows us to remove this bias.
</listItem>
<bodyText confidence="0.999876">
The resulting weight of each si is then expressed as
shown in Figure 1.5
</bodyText>
<sectionHeader confidence="0.8782265" genericHeader="method">
5 Hidden Markov Models
5.1 Introduction
</sectionHeader>
<bodyText confidence="0.985879647058824">
Hidden Markov Models (e.g.,
[Roark and Sproat, 2007]) and, in particular,
Forward-Backward Hidden Markov Models (HMMs),
have a strong history of applications in linguistics.
The justification for the applicability of a Hidden
Markov Model to the problem of lexical substitu-
tion lies in both the limited number of possible
substitutions and the large training corpus.
When compared to the issue of speech processing,
for which a HMM is known to work as a reasonable
model, the issue of lexical substitution is highly simi-
lar and can be expected to produce results of similar
quality.
Meanwhile, the presence of the large training cor-
pus6 means that the transition probabilities can be
calculated with a high degree of certainty for transi-
tions between possible lexical substitutions.
</bodyText>
<subsectionHeader confidence="0.992647">
5.2 Motivation
</subsectionHeader>
<bodyText confidence="0.999834882352941">
Compared to n-gram and grammatical relation (GR)
models, the HMM introduce a few key distinctions
which should have significant contributions to the
quality of the substitution results. While the n-gram
and GR algorithms are capable of comparing the like-
lihood of a lexical substitution in their respective con-
texts, they do not allow the non-target words to take
on other senses in order to generate a better fit.
That said, the HMM lacks the ability of the GR
model to consider the impact of grammar on the sen-
tence. Furthermore, it does not benefit from the rel-
ative speed of implementation and execution enjoyed
by n-grams.
The forward-backward algorithm allows the model
to take into account both the words that preceded
and followed the target word that was being disam-
biguated. In comparison, a Viterbi Algorithm would
</bodyText>
<footnote confidence="0.996335">
5 As this module is not expected to be acting alone, we are not
making any adjustments for data sparsness.
6 In this case, Google Web1T data is used to generate the tran-
sition probabilities.
</footnote>
<page confidence="0.989955">
23
</page>
<figure confidence="0.62348">
p(si) = f5−gm(si) + fstop(si) + E4 j=1 f4−gmj(si)
En 4
k=1(f5−gm(sk) + fstop(sk) + �j=1 f4−gmj(sk)) + f1−gm(si)
</figure>
<figureCaption confidence="0.99374">
Fig. 1: The weight of each candidate si
</figureCaption>
<bodyText confidence="0.99814">
have limited the effectiveness of the solution to take
into consideration words that follow the target word.
For example, returning to the previous example
Brian is a bright boy.
the key word in determining the proper lexical substi-
tution of bright is boy. In this case, the Viterbi Al-
gorithm would not be able to determine the proper
substitution as the determining word boy follows the
target word bright.
</bodyText>
<subsectionHeader confidence="0.952386">
5.3 Algorithm
</subsectionHeader>
<bodyText confidence="0.996893">
The key inputs to the HMM implementation are:
</bodyText>
<listItem confidence="0.9983925">
• Si is one specific possible lexical substitution
within the set of all possible substitutions S
• Bwti, or P(Wt→Si), is the substitution probabil-
ity of a word Wt by a substitution Si7
• Aij, or P(Si→Sj), is the transition probability
between two possible substitutions Si and Sjs
• πi, or P(∅→Si), is the probability that the model
begins simulation in a given state Sig
</listItem>
<bodyText confidence="0.958268285714286">
In implementation, the Forward-Backward Algo-
rithm maximizes the product of the forward-looking
matrix, αit, the backward-looking matrix, βit, and the
lexical substitution probability, bwti. The forward-
looking matrix αit measures the likelihood that the
sentence is at state Si, at time t, when the word wt
is registered. Likewise, the backward-looking matrix
βit measures the likelihood, given that the sentence is
at state Si at time t with probability αit, that there
is a valid transition path that reaches the end of the
sentence. The lexical substitution likelihood probabil-
ity bwti represents the relative, context-free probability
that a given word wt uses the substitution Si.
Thus, the product αit×βit×bwti represents the rel-
ative probability that the lexical substitution Si is the
intended sense of the word Wt seen in location t of the
sentence. By comparing this product for each SiES
and dividing the resulting values by the summation of
the probabilities for all SiES, the relative probabili-
ties represent the likelihood that a specific word is the
expected lexical substitution. The candidate with the
highest likelihood estimation wins, though any substi-
tution with a probability within two orders of magni-
tude of the winner is included as a possible solution
for evaluation purposes.
7 The candidate sets, S, and their substitution probabilities,
Bwti, are shared with the other applications discussed in this
paper.
</bodyText>
<footnote confidence="0.98836175">
8 The transition probability, Aij, is generated from the Google
2-gram data set using Lucene.
9 The initial state probability, Tri, is generated from the Google
1-gram data set using Lucene.
</footnote>
<subsectionHeader confidence="0.903572">
5.4 Solution-Space Generalizations
</subsectionHeader>
<bodyText confidence="0.999993789473684">
In an ideal model, each sentence would be broken down
into its constituent words and every possible substitu-
tion of each word would be a possibility interpreta-
tion. This idealized model would allow for all possible
interpretations of the sentence, providing all possible
frames with which to consider a given lexical substitu-
tion. Such a model would feature upwards of twenty
possible substitutions per word with each requiring
processing for all possible preceding and following sub-
stitutions.
The complexity of the HMM was found to be pro-
portional to the square of the average number of possi-
ble lexical substitutions per word in its input sentences
(see Table 2). This idealized model, though loss-less,
proved computationally inefficient when scaled to the
demands of the application, given the large percentage
of time spent looking up transition probabilities in the
training corpus. In order to minimize the total number
of senses being processed without subjecting the model
to unnecessary generalizations, two methods were used
to reduce the solution complexity: sliding-window and
sense-reduction generalizations.
The sliding-window generalization assumed that
terms further from the target word would be less likely
to contain useful information to disambiguate the tar-
get word sense. As such, a sliding-window representing
likely relevant words was formed around each of the
target words; any word not within the sliding-window
had its possible word senses (expressed by lexical sub-
stitutes) reduced to unity while those within the win-
dow retained multiple senses.
The sense-reduction generalization assumed that
word-senses with low probabilities would not con-
tribute significant information to disambiguating the
word-sense of the target word. As such, the senses
were reduced by limiting possible sense for words
within the sliding-window to only those senses that
were common to both Encarta and WordNet.
</bodyText>
<sectionHeader confidence="0.999898" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.9993592">
We evaluated various combinations of the above
systems on the English lexical substitution data
[McCarthy and Navigli, 2007], which contains substi-
tution information about 171 nouns, verbs, adjectives
and adverbs manually constructed by 5 native English
speaker annotators. Each of our modules is capable of
producing a probability distribution which allows us
to investigate a number of possible combination tech-
niques. All systems are given identical candidate sets
as input, yielding two experiments:
</bodyText>
<listItem confidence="0.871795">
1. Candidate set created from the gold standard
(GS)
</listItem>
<page confidence="0.995776">
24
</page>
<table confidence="0.9999132">
Without Sense-Reduction 545 lexical substitution candidates/sentence
Non-Target Sense-Reduction 88 lexical substitution candidates/sentence
Full Sense-Reduction 45 lexical substitution candidates/sentence
Without Rolling-Window 83 Lucene queries/sentence
With Rolling-Window 24 Lucene queries/sentence
</table>
<tableCaption confidence="0.943981">
Table 2: Hidden Markov Model Computational Complexity
</tableCaption>
<table confidence="0.999982117647059">
Eval System Candidates Precision Recall Mode precision Mode recall
OOT GRs GS 63.49 7.23 71.05 8.78
Best GRs GS 5.58 0.64 6.58 0.81
OOT HMMs GS 52.74 43.41 63.41 52.28
Best HMMs GS 13.64 11.23 18.34 15.12
OOT n-grams GS 65.06 65.02 73.80 73.74
Best n-grams GS 12.31 12.30 17.33 17.32
OOT Voting GS 68.67 68.67 77.80 77.80
Best Voting GS 13.90 13.90 19.59 19.59
OOT GRs WNE 13.68 0.09 12.50 0.08
Best GRs WNE 1.82 0.01 0.00 0.00
OOT HMMs WNE 16.52 0.25 20.00 0.33
Best HMMs WNE 2.24 0.03 0.00 0.00
OOT n-grams WNE 35.79 8.90 48.11 12.44
Best n-grams WNE 6.92 1.72 11.01 2.85
OOT Voting WNE 36.07 8.98 48.43 12.52
Best Voting WNE 7.02 1.75 11.01 2.85
</table>
<tableCaption confidence="0.999838">
Table 3: Results of each module on the English lexical substitution task
</tableCaption>
<bodyText confidence="0.948558">
2. Candidate set created from WordNet and Encarta
as described in Section 2 (WNE).
The results of these evaluation can be found in Ta-
ble 3. Two evaluations are presented:
</bodyText>
<listItem confidence="0.9626372">
1. best: Only the top candidate is evaluated against
the gold standard (this corresponds to the highest
probability candidate).
2. oot: The top ten candidates are collected and
evaluated against the gold standard.
</listItem>
<bodyText confidence="0.999917875">
The results can be compared to the highest per-
forming system in SEMEVAL-2007 which achieved an
oot precision / recall of 69.03 / 68.90, and mode pre-
cision / recall of 58.54, while the highest performing
best system had a precision / recall of 12.90, and mode
precision / recall of 20.65. (Note that the results for
the WNE experiment are partial, as discussed in Sec-
tion 6.1 representing only 10% of the data.)
</bodyText>
<subsectionHeader confidence="0.976827">
6.1 Discussion
</subsectionHeader>
<bodyText confidence="0.999994604651163">
The single largest factor in the effectiveness of an ap-
proach to the problem space appears to be the proper
determination of the scope of its candidate list. If
an under-generated candidate set was used, the lexi-
cal substitutions suggested would be technically sound
but incorrect insofar as they were only the best from
the subset, not from the set of all possible substitu-
tions. Omission of candidates could also reduce the
number of valid substitutions to zero, creating a model
where no candidate that remained would fit within the
constraints imposed by the system evaluating its can-
didacy.
While under-generation was a concern, the candi-
date sets more directly suffered from over-generation.
In over-generated candidate sets, the inclusion of
rarely used substitutions, including hypernyms and
hyponyms, served only to dramatically increase solu-
tion time without a corresponding increase in solu-
tion accuracy. As the complexity of the systems fre-
quently increased proportional to the square of the av-
erage number of lexical substitution possibilities, these
candidate sets quickly became disproportionately large
when compared to the gold standard candidate sets.
For such candidate sets that were fully evaluated, no
noticable improvement was found in the ability to cor-
rectly identify the proper lexical substitution over the
gold standard candidates.
These issues served as the motivations for proced-
ing using the gold standard candidates (GS results) in-
stead of the locally generated sets (WNE results). The
gold standard candidates avoided the potential short-
fall of under-generation as they were guaranteed to
contain the anticipated substitution of the target word
within their candidate sets; thus, protecting them from
failing to produce a candidate selection. At the same
time, the candidate list was also small enough to avoid
the growth issues experienced in the over-generated
candidate lists. Since the gold standard candidates
do not overlap within their set, they are significantly
more likely to feature a broad selection of possible can-
didates within the OOT, boosting the accuracy of the
results. As we are merely interested in the perfor-
mance of our modules (to demonstrate their suitability
</bodyText>
<page confidence="0.993784">
25
</page>
<table confidence="0.8951913">
Czech PoS Senses English
cesta n 5 way, path
ˇc´ıslo n 6 number, performance
funkce n 8 function, event
z˚ustat v 6 stay, remain
tˇeˇzk´y a 6 hard, difficult
nechat v 16 leave
d˚ukaz n 9 proof
povrch n 7 surface
partie n 12 part, partner
vˇec n 6 thing
akce n 7 action, event
PoS Average
Noun 7
Verb 8
Adjective 7
Table 5: Average numbers of candidates for Czech
Evaluation Precision Recall
Best 18.86 18.86
OOT 92.11 92.11
</table>
<tableCaption confidence="0.9838245">
Table 4: Words selected for Czech lexical substitution
including (some) English translations
</tableCaption>
<bodyText confidence="0.9998834">
for the task and to enable their evaluation on the Czech
lexical sample task), the use of the gold standard can-
didate sets is justifiable. Also, a properly generated
candidate list would exhibit similar characteristics to
this set.
</bodyText>
<sectionHeader confidence="0.990165" genericHeader="evaluation">
7 Evaluation on Czech data
</sectionHeader>
<subsectionHeader confidence="0.993815">
7.1 Creating the evaluation corpus
</subsectionHeader>
<bodyText confidence="0.996206705882353">
Unfortunately a lexical substitution corpus is not
available for other languages. In an effort to inves-
tigate the applicability of our methods to other lan-
guages, we selected an extreme example: Czech, a
highly morphologically rich, free order language, which
should therefore produce a valuable comparison.
Ten words were selected at random from the on-
line, publicly available, Czech Wiktionary10 subject
to the constraint that they had at least 5 senses listed
(note that this step is completely automated, and
could be executed with any language). The words
chosen, along with the number of senses and their
parts of speech in Wiktionary can be found in Ta-
ble 4. The most frequent English translations are
also provided. Ten sample sentences for each of these
words (where the target word is to be substituted)
were extracted from the Prague Dependency Treebank
2.0 [Hajiˇcov´a, 1998], which contains markup of lemma-
tized form and thus allows various instances of use to
be extracted. The annotation was done by a single
native Czech speaker.
Due to the absence of a freely available parser pro-
viding GRs for Czech, it was only possible to run the n-
gram and HMM modules in this experiment. Also, af-
ter initial experiments with using the Czech Wikipedia
as training data, a further inflection problem came to
light: should the candidate substitute be of a differ-
ent gender to the original target word, the sentence
stopped being grammatically correct when the candi-
date was substituted due to agreement. Thus a same
animacy / type candidate would always be preferred.
Consider the example:
... vstoupit do chr´amu za ´uˇcelem policejn´ı
&lt;head&gt;akce&lt;/head&gt;
</bodyText>
<footnote confidence="0.360999">
io Available from http://cs.wiktionary.org/
</footnote>
<tableCaption confidence="0.982163">
Table 6: Czech lexical substitution
</tableCaption>
<bodyText confidence="0.997777157894737">
if the correct substitute for the word akce, ˇcin is
used, the sentence needs to change to:
... vstoupit do chr´amu za ´uˇcelem policejn´ıho
ˇcinu
The test data, and the training data, therefore re-
quired lemmatization: in the absence of a freely avail-
able lemmatizer for Czech, the PDT was used for
both training and testing (with the test sentences
being withheld from training). Thus n-grams (for
n = 1, 2,5) were acquired from this data, and indexed
as carried out for English.
The candidates for each word were acquired
from the Czech online synonyms resource
(http://www.synonyma-online.cz), but the
candidates for target words were also augmented
by semi-automatically extracted synonyms from
Wikipedia. The average numbers of candidates are
presented in Table 5, and the combined results for the
Czech lexical sample are presented in Table 6.
</bodyText>
<sectionHeader confidence="0.914243" genericHeader="conclusions">
8 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.9999814">
We have presented a modular lexical substitution sys-
tem which incorporates a number of novel approaches
to the task. The approaches were shown to have good
performance on the English lexical substitution data,
while also being highly portable to other, potentially
very different, languages (with a very good perfor-
mance on the Czech data). We highlight the impor-
tance of a comprehensive, yet not over-generated can-
didate set, an issue which we fell has not been ad-
dressed enough in the past.
</bodyText>
<sectionHeader confidence="0.532182" genericHeader="acknowledgments">
8.1 Future work
</sectionHeader>
<bodyText confidence="0.9913728">
The GR module did not deal with issues of sparsness
– the motivation being that the other modules will fill
in. However, an alternative method for future work
could be in grouping GRs together in meaningful ways
[Pereira et al., 1993].
The HMM implemented a 1&amp;quot;-Order Forward-
Backward Algorithm. This introduces certain limi-
tations to the transition probability matrices. If our
running example had been
Brian is a bright and lively boy.
</bodyText>
<page confidence="0.981415">
26
</page>
<bodyText confidence="0.999857">
instead, the separation of bright and boy by the inter-
vening words and lively would have the effect of neu-
tralizing the impact of the determining word on the
target word. In this case, the words that would have
the greatest impact on bright would be a and and, nei-
ther of which would contribute a significant amount of
information that could lead to a proper lexical substi-
tution.
</bodyText>
<sectionHeader confidence="0.999175" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999736181818182">
[Brants and Franz, 2006] Brants, T. and Franz, A.
(2006). Web 1T 5-gram Version 1.
[Briscoe et al., 2002] Briscoe, E. J., Carroll, J., Gra-
ham, J., and Copestake, A. (2002). Relational eval-
uation schemes. In Proceedings of the beyond PAR-
SEVAL Workshop at the 3rd International Confer-
ence on Language Resources and Evaluation, pages
4–8.
[Briscoe et al., 2006] Briscoe, E. J., Carroll, J., and
Watson, R. (2006). The second release of the RASP
system. In Proceedings of the COLING/ACL 2006,
Interactive Poster Session.
[Dagan et al., 2006] Dagan, I., Glickman, O., Gliozzo,
A., Marmorshtein, E., and Strapparava, C. (2006).
Direct word sense matching for lexical substitution.
In Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics, pages 449–456.
[Elworthy, 1994] Elworthy, D. (1994). Does Baum-
Welch re-estimation help taggers? In Proceedings
of the 4th Conference on Applied NLP, pages 53–
58.
[Graff, 2003] Graff, D. (2003). English gigaword.
Technical report, Linguistic Data Consortium.
[Hajiˇcov´a, 1998] Hajiˇcov´a, E. (1998). Prague depen-
dency treebank: From analytic to tectogrammatical
annotations. In Proceedings of 2nd TST, pages 45–
50.
[Hassan et al., 2007] Hassan, S., Csomai, A., Banea,
C., and Mihalcea, R. (2007). UNT: SubFinder: com-
bining knowledge sources for automatic lexical sub-
stitution. In Proceedings of the 4th International
Workshop on the Semantic Evaluations.
[McCarthy, 2002] McCarthy, D. (2002). Lexical sub-
stitution as a task for WSD evaluation. In Proceed-
ings of the Workshop on Word Sense Disambigua-
tion: Recent Successes and Future Directions, pages
109–115.
[McCarthy and Navigli, 2007] McCarthy, D. and
Navigli, R. (2007). Task 10: English lexical substi-
tution task. In Proceedings of the 4th International
Workshop on Semantic Evaluations, pages 48–53.
[Miller et al., 1990] Miller, G., Beckwith, R., Fel-
baum, C., Gross, D., and Miller, K. (1990). Intro-
duction to WordNet: An on-line lexical database.
Journal of Lexicography, 3(4):235–244.
[Pereira et al., 1993] Pereira, F., Tishby, F., and Lee,
L. (1993). Distributional clustering of English
words. In Proceedings of the Association for Com-
putational Linguistics, pages 183–190.
[Preiss and Yarowsky, 2002] Preiss, J. and Yarowsky,
D., editors (2002). Proceedings of SENSEVAL-2:
Second International Workshop on Evaluating Word
Sense Disambiguating Systems.
[Roark and Sproat, 2007] Roark, B. and Sproat,
R. W. (2007). Computational Approaches to Mor-
phology and Syntax. Oxford University Press.
[Sinha et al., 2009] Sinha, R., McCarthy, D., and Mi-
halcea, R. (2009). Semeval-2010 task 2: Cross-
lingual lexical substitution. In Proceedings of the
NAACL-HLT 2009 Workshop: SEW-2009 - Seman-
tic Evaluations.
[Yuret, 2007] Yuret, D. (2007). KU: Word sense dis-
ambiguation by substitution. In Workshop of Se-
mEval.
</reference>
<page confidence="0.9988">
27
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.260290">
<title confidence="0.896309">HMMs, GRs, and n-grams as lexical substitution techniques – they portable to other languages?</title>
<author confidence="0.997723">Judita Preiss Andrew Coonce</author>
<affiliation confidence="0.9997515">Department of Linguistics The Ohio State University Ohio State University</affiliation>
<email confidence="0.995076">judita@ling.ohio-state.edu</email>
<author confidence="0.995339">Brittany Baker</author>
<affiliation confidence="0.527268">The Ohio State</affiliation>
<email confidence="0.996871">baker.1189@osu.edu</email>
<abstract confidence="0.99997425">We introduce a number of novel techniques to lexical substitution, including an application of the Forward-Backward algorithm, a grammatical relation based similarity measure, and a modified of matching. We test these techon the lexical substitution data [McCarthy and Navigli, 2007], to demonstrate their competitive performance. We create a similar (small scale) dataset for Czech, and our evaluation demonstrates language independence of the techniques.</abstract>
<keyword confidence="0.990317666666667">Keywords Lexical substitution, synonyms, Google n-gram corpus, grammatical relations, HMMs, Forward-Backward algorithm,</keyword>
<intro confidence="0.597862">Lucene, Czech, word sense disambiguation</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Brants</author>
<author>A Franz</author>
</authors>
<title>Web 1T 5-gram Version 1.</title>
<date>2006</date>
<marker>[Brants and Franz, 2006]</marker>
<rawString>Brants, T. and Franz, A. (2006). Web 1T 5-gram Version 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E J Briscoe</author>
<author>J Carroll</author>
<author>J Graham</author>
<author>A Copestake</author>
</authors>
<title>Relational evaluation schemes.</title>
<date>2002</date>
<booktitle>In Proceedings of the beyond PARSEVAL Workshop at the 3rd International Conference on Language Resources and Evaluation,</booktitle>
<pages>4--8</pages>
<marker>[Briscoe et al., 2002]</marker>
<rawString>Briscoe, E. J., Carroll, J., Graham, J., and Copestake, A. (2002). Relational evaluation schemes. In Proceedings of the beyond PARSEVAL Workshop at the 3rd International Conference on Language Resources and Evaluation, pages 4–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E J Briscoe</author>
<author>J Carroll</author>
<author>R Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006, Interactive Poster Session.</booktitle>
<marker>[Briscoe et al., 2006]</marker>
<rawString>Briscoe, E. J., Carroll, J., and Watson, R. (2006). The second release of the RASP system. In Proceedings of the COLING/ACL 2006, Interactive Poster Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
<author>A Gliozzo</author>
<author>E Marmorshtein</author>
<author>C Strapparava</author>
</authors>
<title>Direct word sense matching for lexical substitution.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>449--456</pages>
<marker>[Dagan et al., 2006]</marker>
<rawString>Dagan, I., Glickman, O., Gliozzo, A., Marmorshtein, E., and Strapparava, C. (2006). Direct word sense matching for lexical substitution. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 449–456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Elworthy</author>
</authors>
<title>Does BaumWelch re-estimation help taggers?</title>
<date>1994</date>
<booktitle>In Proceedings of the 4th Conference on Applied NLP,</booktitle>
<pages>53--58</pages>
<marker>[Elworthy, 1994]</marker>
<rawString>Elworthy, D. (1994). Does BaumWelch re-estimation help taggers? In Proceedings of the 4th Conference on Applied NLP, pages 53– 58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Graff</author>
</authors>
<title>English gigaword.</title>
<date>2003</date>
<tech>Technical report,</tech>
<institution>Linguistic Data Consortium.</institution>
<marker>[Graff, 2003]</marker>
<rawString>Graff, D. (2003). English gigaword. Technical report, Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hajiˇcov´a</author>
</authors>
<title>Prague dependency treebank: From analytic to tectogrammatical annotations.</title>
<date>1998</date>
<booktitle>In Proceedings of 2nd TST,</booktitle>
<pages>45--50</pages>
<marker>[Hajiˇcov´a, 1998]</marker>
<rawString>Hajiˇcov´a, E. (1998). Prague dependency treebank: From analytic to tectogrammatical annotations. In Proceedings of 2nd TST, pages 45– 50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hassan</author>
<author>A Csomai</author>
<author>C Banea</author>
<author>R Mihalcea</author>
</authors>
<title>UNT: SubFinder: combining knowledge sources for automatic lexical substitution.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on the Semantic Evaluations.</booktitle>
<marker>[Hassan et al., 2007]</marker>
<rawString>Hassan, S., Csomai, A., Banea, C., and Mihalcea, R. (2007). UNT: SubFinder: combining knowledge sources for automatic lexical substitution. In Proceedings of the 4th International Workshop on the Semantic Evaluations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
</authors>
<title>Lexical substitution as a task for WSD evaluation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,</booktitle>
<pages>109--115</pages>
<marker>[McCarthy, 2002]</marker>
<rawString>McCarthy, D. (2002). Lexical substitution as a task for WSD evaluation. In Proceedings of the Workshop on Word Sense Disambiguation: Recent Successes and Future Directions, pages 109–115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>R Navigli</author>
</authors>
<title>Task 10: English lexical substitution task.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>48--53</pages>
<marker>[McCarthy and Navigli, 2007]</marker>
<rawString>McCarthy, D. and Navigli, R. (2007). Task 10: English lexical substitution task. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 48–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>R Beckwith</author>
<author>C Felbaum</author>
<author>D Gross</author>
<author>K Miller</author>
</authors>
<title>Introduction to WordNet: An on-line lexical database.</title>
<date>1990</date>
<journal>Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<marker>[Miller et al., 1990]</marker>
<rawString>Miller, G., Beckwith, R., Felbaum, C., Gross, D., and Miller, K. (1990). Introduction to WordNet: An on-line lexical database. Journal of Lexicography, 3(4):235–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>F Tishby</author>
<author>L Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>183--190</pages>
<marker>[Pereira et al., 1993]</marker>
<rawString>Pereira, F., Tishby, F., and Lee, L. (1993). Distributional clustering of English words. In Proceedings of the Association for Computational Linguistics, pages 183–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Preiss</author>
<author>D Yarowsky</author>
</authors>
<date>2002</date>
<booktitle>Proceedings of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguating Systems.</booktitle>
<marker>[Preiss and Yarowsky, 2002]</marker>
<rawString>Preiss, J. and Yarowsky, D., editors (2002). Proceedings of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguating Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
<author>R W Sproat</author>
</authors>
<title>Computational Approaches to Morphology and Syntax.</title>
<date>2007</date>
<publisher>Oxford University Press.</publisher>
<marker>[Roark and Sproat, 2007]</marker>
<rawString>Roark, B. and Sproat, R. W. (2007). Computational Approaches to Morphology and Syntax. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sinha</author>
<author>D McCarthy</author>
<author>R Mihalcea</author>
</authors>
<title>Semeval-2010 task 2: Crosslingual lexical substitution.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL-HLT 2009 Workshop: SEW-2009 - Semantic Evaluations.</booktitle>
<marker>[Sinha et al., 2009]</marker>
<rawString>Sinha, R., McCarthy, D., and Mihalcea, R. (2009). Semeval-2010 task 2: Crosslingual lexical substitution. In Proceedings of the NAACL-HLT 2009 Workshop: SEW-2009 - Semantic Evaluations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yuret</author>
</authors>
<title>KU: Word sense disambiguation by substitution.</title>
<date>2007</date>
<booktitle>In Workshop of SemEval.</booktitle>
<marker>[Yuret, 2007]</marker>
<rawString>Yuret, D. (2007). KU: Word sense disambiguation by substitution. In Workshop of SemEval.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>