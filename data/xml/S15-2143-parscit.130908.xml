<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.036884">
<title confidence="0.733829">
USAAR-CHRONOS: Crawling the Web for Temporal Annotations
</title>
<author confidence="0.672347">
Liling Tan and Noam Ordan
</author>
<affiliation confidence="0.649591">
Universit¨at des Saarlandes
</affiliation>
<address confidence="0.61844">
Campus A2.2, Saarbr¨ucken, Germany
</address>
<email confidence="0.994039">
alvations@gmail.com, noam.ordan@uni-saarland.de
</email>
<sectionHeader confidence="0.995605" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999643214285714">
This paper describes the USAAR-CHRONOS
participation in the Diachronic Text Evalua-
tion task of SemEval-2015 to identify the time
period of historical text snippets. We adapt
a web crawler to retrieve the original source
of the text snippets and determine the publi-
cation year of the retrieved texts from their
URLs. We report a precision score of &gt;90%
in identifying the text epoch. Additionally, by
crawling and cleaning the website that hosts
the source of the text snippets, we present
Daikon, a corpus that can be used for fu-
ture work on epoch identification from a di-
achronic perspective.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999783478260869">
”Time changes all things: there is no reason
why language should escape this universal law”
(De Saussure, 1959). Traditionally, there are two
ways to collect linguistic data to explore how words
change over time, viz. (i) the ‘armchair’ method and
(ii) the ‘tape-recorder’ method (Aitchison, 2001). In
the first, the linguist cross-examines numerous doc-
uments from bygone years and in the latter, the lin-
guist goes around recording language and studies the
changes as they happen.
With the ingress of historical data provided by
Google (Michel et al. 2011), the ‘armchair’ method
goes into warp speed as computational linguists ex-
plore the different facets of lexical changes in En-
glish (Mihalcea and Nastase, 2012; Popescu and
Strapparava, 2013; Niculae et al., 2014).
This paper presents the Saarland University
(USAAR-CHRONOS) participation in the Di-
achronic Text Evaluation task in SemEval-2015. We
participated in Subtask 1 that requires participants to
identify the year of publication for texts with clear
reference to time anchors (i.e. explicit references to
famous persons or events).
</bodyText>
<subsectionHeader confidence="0.995076">
1.1 Task Definition
</subsectionHeader>
<bodyText confidence="0.89540116">
In Subtask 1 of the Diachronic Text Evaluation par-
ticipants are required to identify the epoch (i.e. time
period) of a text snippet with clear reference to cer-
tain famous persons or events. The text snippets may
not necessarily contain temporal information such as
year or date but it has clear reference to a historical
event that can be identified from external knowledge
bases. For instance, given the following text, partic-
ipants are required to identify its epoch:
“Dictator Saddam Hussein ordered his troops to
march into Kuwait. After the invasion is condemned
by the UN Security Council, the US has forged a
coalition with allies. Today American troops are
sent to Saudi Arabia in Operation Desert Shield,
protecting Saudi Arabia from possible attack.”
The text has clear temporal evidence with refer-
ence to a historical figure (“Saddam Hussein”), a
notable organization (“UN Security Council”) and a
factual event (“Operation Desert Shield”). Histori-
cally, we know that Saddam Hussein lived between
1937 to 2006, that the UN Security Council has ex-
isted since 1946 and that Operation Desert Shield
(i.e. the Gulf War) occurred between 1990-1991.
Given the specific chronic deicticity (“today”) that
indicates that the text is published during the Gulf
</bodyText>
<page confidence="0.98721">
846
</page>
<bodyText confidence="0.892873636363636">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 846–850,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
War, we can conceive that the text snippet should be
dated 1990-1991.
For each text snippet, different epoch choices are
provided at three granularity levels; fine, medium
and coarse graded epochs, and they are assigned
the time periods of 3, 6 and 12 years, respectively.
For the given example above, the correct epochs are
1990-1992, 1988-1993 and 1985-1995 for the three
granularity levels respectively.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99988065">
Michel et al. (2011) launch the field of culturo-
nomics to study changes in human culture through
language change; for this, they release ngrams taken
from millions of digitized books; they show, for ex-
ample, that censorship and suppression can be de-
termined by comparing the frequencies of proper
names in multilingual ngrams in this dataset.
Mihalcea and Nastase (2012) explore word sense
disambiguation over time using snippets from
Google Books; they add a semantic dimension on
top of lexical frequency to conduct word epoch dis-
ambiguation based on the fact that words change
their neighbors throughout time.
The Google Ngram corpus has spawned several
related studies. To create a sense pool, Yu et al.
(2007) extract pairs of ngrams and filter them with
an appropriate statistical test using their frequen-
cies, where the resulting sense pool is manually ver-
ified. Interestingly, their experiments conflate the
ngrams across time, yet it is unclear whether the
resulting sense pool contains ngrams across differ-
ent epochs. Juola (2013) uses the bigrams from the
Google Books Ngram dataset to measure changes in
the Kolmogorov complexity of American culture at
ten-year intervals between 1900 and 2000. Related
to this, ˇStajner and Zampieri (2013) show, for Por-
tuguese, that lexical richness, average word length
and lexical density increase over a span of 400 years.
Topic models are also applied to study topical
changes across epochs (e.g. (Blei and Lafferty,
2007; Wijaya and Yeniterzi, 2011)). Related to
epoch identification, Wang and McCallum (2006)
develop time-specific topic models to a time stamp
prediction task.
With the renaissance of neural nets, recent stud-
ies are using deep neural language models to detect
diachronic lexical changes from several text types
ranging from published books (Kim et al., 2014)
to Twitter microblogs and Amazon movie reviews
(Kulkarni et al., 2014).
</bodyText>
<sectionHeader confidence="0.993951" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.974914409090909">
We take a different approach compared to previous
studies that treat epoch identification as a classifica-
tion task. We see it as an information retrieval task
where we want to know whether we can get the tem-
poral information of the text snippets from the Inter-
net.
In the age where there is a contest (known
as “Googlewhack”) for finding one-hit results on
Google since they are so rare , it is clear that a great
deal of the information we are looking for is just “out
there” for us to search. It is recommended to use ma-
chine learning classifiers for cases where test data is
supposedly unknown, but more often than not it can
be known by those who know how to retrieve, clean
and harvest systematically.
Prior to the days of Google and search engines,
historians and librarians1 had to cross-reference his-
tory books and newspaper archives to identify the
text epoch. The Internet is vast and infinite. Given
the advent of Wikipedia and Google, epoch identifi-
cation can be as simple as searching “When was Op-
eration Desert Shield?” on Google2 (see Figure 1).
</bodyText>
<figureCaption confidence="0.9913835">
Figure 1: Google Result for “When was Operation Desert
Shield?”.
</figureCaption>
<bodyText confidence="0.999839857142857">
Tan et al. (2014a) develop a Web Translation
Memory (WebTM) crawler capable of harvesting
parallel texts from the web given an initial seed
corpus, similar to the BootCaT system (Baroni and
Bernardini, 2004). They adapt WebTM such that
it attempts to find occurrences of the text snippets
from the web. This is akin to developing a dedicated
</bodyText>
<footnote confidence="0.999928">
1With the exception of the polymath librarian, Flynn Carsen
2See http://goo.gl/VD2Xtx
</footnote>
<page confidence="0.994945">
847
</page>
<bodyText confidence="0.999675153846154">
search- and crawl-system for the purpose of knowl-
edge extraction.
Surprisingly, the source of the all the
text snippets of Subtask 1 is found on
http://freepages.genealogy.rootsweb
.ancestry.com/∼dutillieul and
http://archive.spectator.co.uk/.
Moreover, these webpages contain dates in their
URL, so we extract the publication year with regex
pattern matching. Since the task requires an epoch
(time period) instead of a discrete publication year,
we perform some minor integer manipulation to fit
the publication year to the expected epoch3.
</bodyText>
<sectionHeader confidence="0.999969" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.997769333333333">
Out of the 267 text snippets, our system correctly
identifies 243, 248, 252 epochs for the fine, medium
and coarse epoch granularities.
</bodyText>
<figureCaption confidence="0.970863333333333">
Figure 2: Fine Graded Epoch Differential between Sys-
tems outputs and Gold Standards (warmer colors indi-
cates higher values).
</figureCaption>
<table confidence="0.99933325">
Fine Medium Coarse
AMBRA 0.0374 0.0711 0.0749
IXA-EHUDIAC 0.0225 0.0413 0.0902
USAAR-CHRONOS 0.9288 0.9101 0.9438
</table>
<tableCaption confidence="0.999915">
Table 1: Precision scores on Subtask 1.
</tableCaption>
<bodyText confidence="0.99469">
Table 1 presents the precision scores of the partic-
ipating teams in subtask 1. Our system scores best
on all three granularity levels.
Figure 2 shows a heatmap of the fine graded
epochal (6 years interval) differences between the
outputs and the gold standard4. The warm colors in-
dicate higher values within the interval. Looking at
the orange region of the heatmap, the other systems
were way off in the epoch identification where re-
spectively, AMBRA and IXA-EHUDIAC have 195
and 186 predictions that are 54 years off from the
gold standards. We have a total of 24 predictions
different from the gold standard and 9 out 24 were 6
years off from the gold standards.
</bodyText>
<sectionHeader confidence="0.999493" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999916">
We have manually checked our epoch predictions
and the years encoded in the URL to check whether
they correspond to the date of the source articles.
</bodyText>
<footnote confidence="0.995290666666667">
3Details on http://goo.gl/TcZ9z0
4An interactive version of the heatmap can be viewed on
https://plot.ly/ alvations/21/epochs-differential/
</footnote>
<bodyText confidence="0.999808592592592">
Some of our predictions are dated older than the gold
standards and vice versa.
For instance, the following text refers to the Battle
of Salamanca on 22 July 1812 and the text snippet
is from a battle report written on 16 August 1812
and published on 24 August 1812 in the Salisbury
and Winchester Journal; the gold annotation records
the epoch as 1813-1815 whereas our system reports
1810-1812.
“On Thursday last, the 69th Annual Conference
of the people called Methodists, was concluded. It
had been held by adjournment in Leeds from the
27th ult. About 309 Itinerant Preachers were present
from various parts of the United Kingdom, who gave
very gratifying accounts of the success with which
their ministry have been crowned.”
In this case, the gold standard source is clearly
a different source and the assumption that there are
hard boundaries in epoch identification should be re-
laxed. One should consider different granularity lev-
els of the epochs involved when evaluating the sys-
tem’s accuracy.
Relating to the historian and librarian anecdote,
the discrepancy in dates from different sources
shows that cross-referencing temporal annotations
from various sources should be considered in future
diachronic studies and temporal analyses.
</bodyText>
<page confidence="0.997889">
848
</page>
<sectionHeader confidence="0.998541" genericHeader="method">
6 Daikon Corpus
</sectionHeader>
<bodyText confidence="0.998159846153846">
After the SemEval task, we
crawled the full articles from
http://archive.spectator.co.uk/,
cleaned the corpus and annotated it with the exact
publication date of the article, its title and the URL
from which it was retrieved. The Daikon Corpus is
made up of articles from the British Spectator news
magazine from year 828 to 2008.
The Daikon corpus can be used for future di-
achronic studies and epoch identification tasks; it
provides a complementary dataset to the gold stan-
dard provided by task. The corpus is saved in JSON
format. An excerpt from the corpus looks like this:
</bodyText>
<figureCaption confidence="0.994542">
Figure 3: An Excerpt from the Daikon Corpus.
</figureCaption>
<bodyText confidence="0.999923923076923">
Each item in the body list is a paragraph embed-
ded within the &lt;p&gt;...&lt;/p&gt; tags of the webpage.
The corpus contains 24,280 articles with 19 million
tokens; the token count is calculated by summing the
number of whitespaces plus 1 for each paragraph.
To clean the corpus, the encodings are converted
to Unicode (UTF8) and XML escape tokens are con-
verted to its Unicode counterparts automatically5.
However, the current version still contains minor to-
kenization errors such as the hyphenation error seen
in Figure 3. Probably, a character language model
could be developed to identify lexical items bounded
by the r‘\w+- \w+’ regex.
</bodyText>
<sectionHeader confidence="0.994799" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.923064">
In this paper, we have described our submission to
the Diachronic Text Evaluation for SemEval-2015.
</bodyText>
<footnote confidence="0.811534">
5The cleaning tool used is a compilation of web cleaning
scripts (Emerson et al., 2014; Tan et al., 2014b; Tan and Bond,
2011)
</footnote>
<bodyText confidence="0.999938857142857">
We have adapted a web crawler to search for the
source of the text snippets used for the evaluation
and achieved the highest precision score. Addi-
tionally, we have crawled and cleaned the source
articles of the snippets and produced the Daikon
corpus that can be used for future research in di-
achronic/temporal analysis and epoch identification.
</bodyText>
<sectionHeader confidence="0.975303" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999687">
The research leading to these results has received
funding from the People Programme (Marie Curie
Actions) of the European Union’s Seventh Frame-
work Programme FP7/2007-2013/ under REA grant
agreement n ◦ 317471. In addition, we received sup-
port from Deutsche Forschungsgemeinschaft (DFG)
through grants from the Cluster of Excellence
– Multimodal Computing and Interaction (EXC-
MMCI) and SFB 1102. We thank Elke Teich for
her encouraging input.
</bodyText>
<sectionHeader confidence="0.998844" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998969428571429">
Jean Aitchison. 2001. Language Change: Progress or
Decay? Cambridge University Press.
Marco Baroni and Silvia Bernardini. 2004. BootCaT:
Bootstrapping Corpora and Terms from the Web. In
Proceedings of the Fourth International Conference on
Language Resources and Evaluation (LREC’04).
David M Blei and John D Lafferty. 2007. A Correlated
Topic Model of Science. The Annals ofApplied Statis-
tics, pages 17–35.
Ferdinand De Saussure. 1959. Course in General Lin-
guistics. New York:McGrawHill.
Guy Emerson, Liling Tan, Susanne Fertmann, Alexis
Palmer, and Michaela Regneri. 2014. SeedLing:
Building and Using a Seed corpus for the Human Lan-
guage Project. In Proceedings of the 2014 Workshop
on the Use of Computational Methods in the Study
of Endangered Languages, pages 77–85, Baltimore,
Maryland, USA, June.
Patrick Juola. 2013. Using the Google N-Gram corpus to
Measure Cultural Complexity. Literary and linguistic
computing, 28(4):668–675.
Yoon Kim, Yi-I Chiu, Kentaro Hanaki, Darshan Hegde,
and Slav Petrov. 2014. Temporal Analysis of
Language through Neural Language Models. arXiv
preprint arXiv:1405.3515.
Vivek Kulkarni, Rami Al-Rfou, Bryan Perozzi, and
Steven Skiena. 2014. Statistically Significant Detec-
tion of Linguistic Change. CoRR, abs/1411.3315.
</reference>
<page confidence="0.995564">
849
</page>
<reference confidence="0.9973095">
Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser
Aiden, Adrian Veres, Matthew K Gray, Joseph P Pick-
ett, Dale Hoiberg, Dan Clancy, Peter Norvig, Jon Or-
want, et al. 2011. Quantitative Analysis of Cul-
ture using Millions of Digitized Books. science,
331(6014):176–182.
Rada Mihalcea and Vivi Nastase. 2012. Word Epoch
Disambiguation: Finding how Words Change over
Time. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics: Short
Papers-Volume 2, pages 259–263.
Vlad Niculae, Marcos Zampieri, Liviu P. Dinu, and
Alina Maria Ciobanu. 2014. Temporal Text Ranking
and Automatic Dating of Texts. In Proceedings of the
14th Conference of the European Chapter of the Asso-
ciation for Computational Linguistics (EACL 2014).
Octavian Popescu and Carlo Strapparava. 2013. Behind
the Times: Detecting Epoch Changes using Large Cor-
pora. In Proceedings of 6th International Joint Con-
ference on Natural Language Processing (IJCNLP).
Sanja ˇStajner and Marcos Zampieri. 2013. Stylistic
Changes for Temporal Text Classification. In Pro-
ceedings of the 16th International Conference on Text
Speech and Dialogue (TSD2013), Lecture Notes in
Artificial Intelligence (LNAI), pages 519–526, Pilsen,
Czech Republic. Springer.
Liling Tan and Francis Bond. 2011. Building and An-
notating the Linguistically Diverse NTU-MC (NTU-
Multilingual Corpus). In Proceedings of the 25th Pa-
cific Asia Conference on Language, Information and
Computation, pages 362–371, Singapore.
Liling Tan, Anne Schumann, Jose Martinez, and Fran-
cis Bond. 2014a. Sensible: L2 Translation Assis-
tance by Emulating the Manual Post-Editing Process.
In Proceedings of the 8th International Workshop on
Semantic Evaluation (SemEval 2014), pages 541–545,
Dublin, Ireland.
Liling Tan, Marcos Zampieri, Nikola Ljubeˇsic, and J¨org
Tiedemann. 2014b. Merging Comparable Data
Sources for the Discrimination of Similar Languages:
The DSL Corpus Collection. In Proceedings of The
7th Workshop on Building and Using Comparable
Corpora (BUCC).
Xuerui Wang and Andrew McCallum. 2006. Topics
over Time: A Non-Markov Continuous-Time Model
of Topical Trends. In Proceedings of the 12th ACM
SIGKDD international conference on Knowledge dis-
covery and data mining, pages 424–433.
Derry Tanti Wijaya and Reyyan Yeniterzi. 2011. Under-
standing Semantic Change of Words over Centuries.
In Proceedings of the 2011 international workshop on
DETecting and Exploiting Cultural diversiTy on the
social web, pages 35–40.
Liang-Chih Yu, Chung-Hsien Wu, Andrew Philpot, and
EH Hovy. 2007. OntoNotes: Sense Pool Verification
using Google N-gram and Statistical Tests. In Pro-
ceedings of the OntoLex Workshop at the 6th Interna-
tional Semantic Web Conference (ISWC 2007).
</reference>
<page confidence="0.998157">
850
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.779730">
<title confidence="0.986601">USAAR-CHRONOS: Crawling the Web for Temporal Annotations</title>
<author confidence="0.908937">Liling Tan</author>
<author confidence="0.908937">Noam</author>
<affiliation confidence="0.980991">Universit¨at des</affiliation>
<address confidence="0.979188">Campus A2.2, Saarbr¨ucken,</address>
<email confidence="0.949879">alvations@gmail.com,noam.ordan@uni-saarland.de</email>
<abstract confidence="0.994307933333333">This paper describes the USAAR-CHRONOS participation in the Diachronic Text Evaluation task of SemEval-2015 to identify the time period of historical text snippets. We adapt a web crawler to retrieve the original source of the text snippets and determine the publication year of the retrieved texts from their We report a precision score of in identifying the text epoch. Additionally, by crawling and cleaning the website that hosts the source of the text snippets, we present a corpus that can be used for future work on epoch identification from a diachronic perspective.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jean Aitchison</author>
</authors>
<title>Language Change: Progress or Decay?</title>
<date>2001</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1109" citStr="Aitchison, 2001" startWordPosition="167" endWordPosition="168">ed texts from their URLs. We report a precision score of &gt;90% in identifying the text epoch. Additionally, by crawling and cleaning the website that hosts the source of the text snippets, we present Daikon, a corpus that can be used for future work on epoch identification from a diachronic perspective. 1 Introduction ”Time changes all things: there is no reason why language should escape this universal law” (De Saussure, 1959). Traditionally, there are two ways to collect linguistic data to explore how words change over time, viz. (i) the ‘armchair’ method and (ii) the ‘tape-recorder’ method (Aitchison, 2001). In the first, the linguist cross-examines numerous documents from bygone years and in the latter, the linguist goes around recording language and studies the changes as they happen. With the ingress of historical data provided by Google (Michel et al. 2011), the ‘armchair’ method goes into warp speed as computational linguists explore the different facets of lexical changes in English (Mihalcea and Nastase, 2012; Popescu and Strapparava, 2013; Niculae et al., 2014). This paper presents the Saarland University (USAAR-CHRONOS) participation in the Diachronic Text Evaluation task in SemEval-201</context>
</contexts>
<marker>Aitchison, 2001</marker>
<rawString>Jean Aitchison. 2001. Language Change: Progress or Decay? Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
</authors>
<title>BootCaT: Bootstrapping Corpora and Terms from the Web.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04).</booktitle>
<contexts>
<context position="7042" citStr="Baroni and Bernardini, 2004" startWordPosition="1117" endWordPosition="1120">. Prior to the days of Google and search engines, historians and librarians1 had to cross-reference history books and newspaper archives to identify the text epoch. The Internet is vast and infinite. Given the advent of Wikipedia and Google, epoch identification can be as simple as searching “When was Operation Desert Shield?” on Google2 (see Figure 1). Figure 1: Google Result for “When was Operation Desert Shield?”. Tan et al. (2014a) develop a Web Translation Memory (WebTM) crawler capable of harvesting parallel texts from the web given an initial seed corpus, similar to the BootCaT system (Baroni and Bernardini, 2004). They adapt WebTM such that it attempts to find occurrences of the text snippets from the web. This is akin to developing a dedicated 1With the exception of the polymath librarian, Flynn Carsen 2See http://goo.gl/VD2Xtx 847 search- and crawl-system for the purpose of knowledge extraction. Surprisingly, the source of the all the text snippets of Subtask 1 is found on http://freepages.genealogy.rootsweb .ancestry.com/∼dutillieul and http://archive.spectator.co.uk/. Moreover, these webpages contain dates in their URL, so we extract the publication year with regex pattern matching. Since the task</context>
</contexts>
<marker>Baroni, Bernardini, 2004</marker>
<rawString>Marco Baroni and Silvia Bernardini. 2004. BootCaT: Bootstrapping Corpora and Terms from the Web. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>John D Lafferty</author>
</authors>
<title>A Correlated Topic Model of Science. The Annals ofApplied Statistics,</title>
<date>2007</date>
<pages>17--35</pages>
<contexts>
<context position="5269" citStr="Blei and Lafferty, 2007" startWordPosition="819" endWordPosition="822">s manually verified. Interestingly, their experiments conflate the ngrams across time, yet it is unclear whether the resulting sense pool contains ngrams across different epochs. Juola (2013) uses the bigrams from the Google Books Ngram dataset to measure changes in the Kolmogorov complexity of American culture at ten-year intervals between 1900 and 2000. Related to this, ˇStajner and Zampieri (2013) show, for Portuguese, that lexical richness, average word length and lexical density increase over a span of 400 years. Topic models are also applied to study topical changes across epochs (e.g. (Blei and Lafferty, 2007; Wijaya and Yeniterzi, 2011)). Related to epoch identification, Wang and McCallum (2006) develop time-specific topic models to a time stamp prediction task. With the renaissance of neural nets, recent studies are using deep neural language models to detect diachronic lexical changes from several text types ranging from published books (Kim et al., 2014) to Twitter microblogs and Amazon movie reviews (Kulkarni et al., 2014). 3 Approach We take a different approach compared to previous studies that treat epoch identification as a classification task. We see it as an information retrieval task w</context>
</contexts>
<marker>Blei, Lafferty, 2007</marker>
<rawString>David M Blei and John D Lafferty. 2007. A Correlated Topic Model of Science. The Annals ofApplied Statistics, pages 17–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferdinand De Saussure</author>
</authors>
<title>Course in General Linguistics.</title>
<date>1959</date>
<location>New York:McGrawHill.</location>
<marker>De Saussure, 1959</marker>
<rawString>Ferdinand De Saussure. 1959. Course in General Linguistics. New York:McGrawHill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guy Emerson</author>
<author>Liling Tan</author>
<author>Susanne Fertmann</author>
<author>Alexis Palmer</author>
<author>Michaela Regneri</author>
</authors>
<title>SeedLing: Building and Using a Seed corpus for the Human Language Project.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages,</booktitle>
<pages>77--85</pages>
<location>Baltimore, Maryland, USA,</location>
<contexts>
<context position="11919" citStr="Emerson et al., 2014" startWordPosition="1895" endWordPosition="1898"> whitespaces plus 1 for each paragraph. To clean the corpus, the encodings are converted to Unicode (UTF8) and XML escape tokens are converted to its Unicode counterparts automatically5. However, the current version still contains minor tokenization errors such as the hyphenation error seen in Figure 3. Probably, a character language model could be developed to identify lexical items bounded by the r‘\w+- \w+’ regex. 7 Conclusion In this paper, we have described our submission to the Diachronic Text Evaluation for SemEval-2015. 5The cleaning tool used is a compilation of web cleaning scripts (Emerson et al., 2014; Tan et al., 2014b; Tan and Bond, 2011) We have adapted a web crawler to search for the source of the text snippets used for the evaluation and achieved the highest precision score. Additionally, we have crawled and cleaned the source articles of the snippets and produced the Daikon corpus that can be used for future research in diachronic/temporal analysis and epoch identification. Acknowledgements The research leading to these results has received funding from the People Programme (Marie Curie Actions) of the European Union’s Seventh Framework Programme FP7/2007-2013/ under REA grant agreem</context>
</contexts>
<marker>Emerson, Tan, Fertmann, Palmer, Regneri, 2014</marker>
<rawString>Guy Emerson, Liling Tan, Susanne Fertmann, Alexis Palmer, and Michaela Regneri. 2014. SeedLing: Building and Using a Seed corpus for the Human Language Project. In Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 77–85, Baltimore, Maryland, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Juola</author>
</authors>
<title>Using the Google N-Gram corpus to Measure Cultural Complexity. Literary and linguistic computing,</title>
<date>2013</date>
<pages>28--4</pages>
<contexts>
<context position="4837" citStr="Juola (2013)" startWordPosition="752" endWordPosition="753">s from Google Books; they add a semantic dimension on top of lexical frequency to conduct word epoch disambiguation based on the fact that words change their neighbors throughout time. The Google Ngram corpus has spawned several related studies. To create a sense pool, Yu et al. (2007) extract pairs of ngrams and filter them with an appropriate statistical test using their frequencies, where the resulting sense pool is manually verified. Interestingly, their experiments conflate the ngrams across time, yet it is unclear whether the resulting sense pool contains ngrams across different epochs. Juola (2013) uses the bigrams from the Google Books Ngram dataset to measure changes in the Kolmogorov complexity of American culture at ten-year intervals between 1900 and 2000. Related to this, ˇStajner and Zampieri (2013) show, for Portuguese, that lexical richness, average word length and lexical density increase over a span of 400 years. Topic models are also applied to study topical changes across epochs (e.g. (Blei and Lafferty, 2007; Wijaya and Yeniterzi, 2011)). Related to epoch identification, Wang and McCallum (2006) develop time-specific topic models to a time stamp prediction task. With the r</context>
</contexts>
<marker>Juola, 2013</marker>
<rawString>Patrick Juola. 2013. Using the Google N-Gram corpus to Measure Cultural Complexity. Literary and linguistic computing, 28(4):668–675.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoon Kim</author>
</authors>
<title>Yi-I Chiu, Kentaro Hanaki, Darshan Hegde, and Slav Petrov.</title>
<date>2014</date>
<marker>Kim, 2014</marker>
<rawString>Yoon Kim, Yi-I Chiu, Kentaro Hanaki, Darshan Hegde, and Slav Petrov. 2014. Temporal Analysis of Language through Neural Language Models. arXiv preprint arXiv:1405.3515.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivek Kulkarni</author>
<author>Rami Al-Rfou</author>
<author>Bryan Perozzi</author>
<author>Steven Skiena</author>
</authors>
<title>Statistically Significant Detection of Linguistic Change.</title>
<date>2014</date>
<location>CoRR, abs/1411.3315.</location>
<contexts>
<context position="5696" citStr="Kulkarni et al., 2014" startWordPosition="884" endWordPosition="887">at lexical richness, average word length and lexical density increase over a span of 400 years. Topic models are also applied to study topical changes across epochs (e.g. (Blei and Lafferty, 2007; Wijaya and Yeniterzi, 2011)). Related to epoch identification, Wang and McCallum (2006) develop time-specific topic models to a time stamp prediction task. With the renaissance of neural nets, recent studies are using deep neural language models to detect diachronic lexical changes from several text types ranging from published books (Kim et al., 2014) to Twitter microblogs and Amazon movie reviews (Kulkarni et al., 2014). 3 Approach We take a different approach compared to previous studies that treat epoch identification as a classification task. We see it as an information retrieval task where we want to know whether we can get the temporal information of the text snippets from the Internet. In the age where there is a contest (known as “Googlewhack”) for finding one-hit results on Google since they are so rare , it is clear that a great deal of the information we are looking for is just “out there” for us to search. It is recommended to use machine learning classifiers for cases where test data is supposedl</context>
</contexts>
<marker>Kulkarni, Al-Rfou, Perozzi, Skiena, 2014</marker>
<rawString>Vivek Kulkarni, Rami Al-Rfou, Bryan Perozzi, and Steven Skiena. 2014. Statistically Significant Detection of Linguistic Change. CoRR, abs/1411.3315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Baptiste Michel</author>
<author>Yuan Kui Shen</author>
<author>Aviva Presser Aiden</author>
<author>Adrian Veres</author>
<author>Matthew K Gray</author>
<author>Joseph P Pickett</author>
<author>Dale Hoiberg</author>
<author>Dan Clancy</author>
<author>Peter Norvig</author>
<author>Jon Orwant</author>
</authors>
<title>Quantitative Analysis of Culture using Millions of Digitized Books.</title>
<date>2011</date>
<journal>science,</journal>
<volume>331</volume>
<issue>6014</issue>
<contexts>
<context position="1368" citStr="Michel et al. 2011" startWordPosition="208" endWordPosition="211">h identification from a diachronic perspective. 1 Introduction ”Time changes all things: there is no reason why language should escape this universal law” (De Saussure, 1959). Traditionally, there are two ways to collect linguistic data to explore how words change over time, viz. (i) the ‘armchair’ method and (ii) the ‘tape-recorder’ method (Aitchison, 2001). In the first, the linguist cross-examines numerous documents from bygone years and in the latter, the linguist goes around recording language and studies the changes as they happen. With the ingress of historical data provided by Google (Michel et al. 2011), the ‘armchair’ method goes into warp speed as computational linguists explore the different facets of lexical changes in English (Mihalcea and Nastase, 2012; Popescu and Strapparava, 2013; Niculae et al., 2014). This paper presents the Saarland University (USAAR-CHRONOS) participation in the Diachronic Text Evaluation task in SemEval-2015. We participated in Subtask 1 that requires participants to identify the year of publication for texts with clear reference to time anchors (i.e. explicit references to famous persons or events). 1.1 Task Definition In Subtask 1 of the Diachronic Text Evalu</context>
<context position="3817" citStr="Michel et al. (2011)" startWordPosition="588" endWordPosition="591">edings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 846–850, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics War, we can conceive that the text snippet should be dated 1990-1991. For each text snippet, different epoch choices are provided at three granularity levels; fine, medium and coarse graded epochs, and they are assigned the time periods of 3, 6 and 12 years, respectively. For the given example above, the correct epochs are 1990-1992, 1988-1993 and 1985-1995 for the three granularity levels respectively. 2 Related Work Michel et al. (2011) launch the field of culturonomics to study changes in human culture through language change; for this, they release ngrams taken from millions of digitized books; they show, for example, that censorship and suppression can be determined by comparing the frequencies of proper names in multilingual ngrams in this dataset. Mihalcea and Nastase (2012) explore word sense disambiguation over time using snippets from Google Books; they add a semantic dimension on top of lexical frequency to conduct word epoch disambiguation based on the fact that words change their neighbors throughout time. The Goo</context>
</contexts>
<marker>Michel, Shen, Aiden, Veres, Gray, Pickett, Hoiberg, Clancy, Norvig, Orwant, 2011</marker>
<rawString>Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, Matthew K Gray, Joseph P Pickett, Dale Hoiberg, Dan Clancy, Peter Norvig, Jon Orwant, et al. 2011. Quantitative Analysis of Culture using Millions of Digitized Books. science, 331(6014):176–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Vivi Nastase</author>
</authors>
<title>Word Epoch Disambiguation: Finding how Words Change over Time.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2,</booktitle>
<pages>259--263</pages>
<contexts>
<context position="1526" citStr="Mihalcea and Nastase, 2012" startWordPosition="233" endWordPosition="236">aw” (De Saussure, 1959). Traditionally, there are two ways to collect linguistic data to explore how words change over time, viz. (i) the ‘armchair’ method and (ii) the ‘tape-recorder’ method (Aitchison, 2001). In the first, the linguist cross-examines numerous documents from bygone years and in the latter, the linguist goes around recording language and studies the changes as they happen. With the ingress of historical data provided by Google (Michel et al. 2011), the ‘armchair’ method goes into warp speed as computational linguists explore the different facets of lexical changes in English (Mihalcea and Nastase, 2012; Popescu and Strapparava, 2013; Niculae et al., 2014). This paper presents the Saarland University (USAAR-CHRONOS) participation in the Diachronic Text Evaluation task in SemEval-2015. We participated in Subtask 1 that requires participants to identify the year of publication for texts with clear reference to time anchors (i.e. explicit references to famous persons or events). 1.1 Task Definition In Subtask 1 of the Diachronic Text Evaluation participants are required to identify the epoch (i.e. time period) of a text snippet with clear reference to certain famous persons or events. The text </context>
<context position="4167" citStr="Mihalcea and Nastase (2012)" startWordPosition="644" endWordPosition="647">medium and coarse graded epochs, and they are assigned the time periods of 3, 6 and 12 years, respectively. For the given example above, the correct epochs are 1990-1992, 1988-1993 and 1985-1995 for the three granularity levels respectively. 2 Related Work Michel et al. (2011) launch the field of culturonomics to study changes in human culture through language change; for this, they release ngrams taken from millions of digitized books; they show, for example, that censorship and suppression can be determined by comparing the frequencies of proper names in multilingual ngrams in this dataset. Mihalcea and Nastase (2012) explore word sense disambiguation over time using snippets from Google Books; they add a semantic dimension on top of lexical frequency to conduct word epoch disambiguation based on the fact that words change their neighbors throughout time. The Google Ngram corpus has spawned several related studies. To create a sense pool, Yu et al. (2007) extract pairs of ngrams and filter them with an appropriate statistical test using their frequencies, where the resulting sense pool is manually verified. Interestingly, their experiments conflate the ngrams across time, yet it is unclear whether the resu</context>
</contexts>
<marker>Mihalcea, Nastase, 2012</marker>
<rawString>Rada Mihalcea and Vivi Nastase. 2012. Word Epoch Disambiguation: Finding how Words Change over Time. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2, pages 259–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vlad Niculae</author>
<author>Marcos Zampieri</author>
<author>Liviu P Dinu</author>
<author>Alina Maria Ciobanu</author>
</authors>
<title>Temporal Text Ranking and Automatic Dating of Texts.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL</booktitle>
<contexts>
<context position="1580" citStr="Niculae et al., 2014" startWordPosition="241" endWordPosition="244">to collect linguistic data to explore how words change over time, viz. (i) the ‘armchair’ method and (ii) the ‘tape-recorder’ method (Aitchison, 2001). In the first, the linguist cross-examines numerous documents from bygone years and in the latter, the linguist goes around recording language and studies the changes as they happen. With the ingress of historical data provided by Google (Michel et al. 2011), the ‘armchair’ method goes into warp speed as computational linguists explore the different facets of lexical changes in English (Mihalcea and Nastase, 2012; Popescu and Strapparava, 2013; Niculae et al., 2014). This paper presents the Saarland University (USAAR-CHRONOS) participation in the Diachronic Text Evaluation task in SemEval-2015. We participated in Subtask 1 that requires participants to identify the year of publication for texts with clear reference to time anchors (i.e. explicit references to famous persons or events). 1.1 Task Definition In Subtask 1 of the Diachronic Text Evaluation participants are required to identify the epoch (i.e. time period) of a text snippet with clear reference to certain famous persons or events. The text snippets may not necessarily contain temporal informat</context>
</contexts>
<marker>Niculae, Zampieri, Dinu, Ciobanu, 2014</marker>
<rawString>Vlad Niculae, Marcos Zampieri, Liviu P. Dinu, and Alina Maria Ciobanu. 2014. Temporal Text Ranking and Automatic Dating of Texts. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Octavian Popescu</author>
<author>Carlo Strapparava</author>
</authors>
<title>Behind the Times: Detecting Epoch Changes using Large Corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of 6th International Joint Conference on Natural Language Processing (IJCNLP).</booktitle>
<contexts>
<context position="1557" citStr="Popescu and Strapparava, 2013" startWordPosition="237" endWordPosition="240">ditionally, there are two ways to collect linguistic data to explore how words change over time, viz. (i) the ‘armchair’ method and (ii) the ‘tape-recorder’ method (Aitchison, 2001). In the first, the linguist cross-examines numerous documents from bygone years and in the latter, the linguist goes around recording language and studies the changes as they happen. With the ingress of historical data provided by Google (Michel et al. 2011), the ‘armchair’ method goes into warp speed as computational linguists explore the different facets of lexical changes in English (Mihalcea and Nastase, 2012; Popescu and Strapparava, 2013; Niculae et al., 2014). This paper presents the Saarland University (USAAR-CHRONOS) participation in the Diachronic Text Evaluation task in SemEval-2015. We participated in Subtask 1 that requires participants to identify the year of publication for texts with clear reference to time anchors (i.e. explicit references to famous persons or events). 1.1 Task Definition In Subtask 1 of the Diachronic Text Evaluation participants are required to identify the epoch (i.e. time period) of a text snippet with clear reference to certain famous persons or events. The text snippets may not necessarily co</context>
</contexts>
<marker>Popescu, Strapparava, 2013</marker>
<rawString>Octavian Popescu and Carlo Strapparava. 2013. Behind the Times: Detecting Epoch Changes using Large Corpora. In Proceedings of 6th International Joint Conference on Natural Language Processing (IJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanja ˇStajner</author>
<author>Marcos Zampieri</author>
</authors>
<title>Stylistic Changes for Temporal Text Classification.</title>
<date>2013</date>
<booktitle>In Proceedings of the 16th International Conference on Text Speech and Dialogue (TSD2013), Lecture Notes in Artificial Intelligence (LNAI),</booktitle>
<pages>519--526</pages>
<publisher>Springer.</publisher>
<location>Pilsen, Czech Republic.</location>
<marker>ˇStajner, Zampieri, 2013</marker>
<rawString>Sanja ˇStajner and Marcos Zampieri. 2013. Stylistic Changes for Temporal Text Classification. In Proceedings of the 16th International Conference on Text Speech and Dialogue (TSD2013), Lecture Notes in Artificial Intelligence (LNAI), pages 519–526, Pilsen, Czech Republic. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liling Tan</author>
<author>Francis Bond</author>
</authors>
<title>Building and Annotating the Linguistically Diverse NTU-MC (NTUMultilingual Corpus).</title>
<date>2011</date>
<booktitle>In Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation,</booktitle>
<pages>362--371</pages>
<contexts>
<context position="11959" citStr="Tan and Bond, 2011" startWordPosition="1903" endWordPosition="1906">o clean the corpus, the encodings are converted to Unicode (UTF8) and XML escape tokens are converted to its Unicode counterparts automatically5. However, the current version still contains minor tokenization errors such as the hyphenation error seen in Figure 3. Probably, a character language model could be developed to identify lexical items bounded by the r‘\w+- \w+’ regex. 7 Conclusion In this paper, we have described our submission to the Diachronic Text Evaluation for SemEval-2015. 5The cleaning tool used is a compilation of web cleaning scripts (Emerson et al., 2014; Tan et al., 2014b; Tan and Bond, 2011) We have adapted a web crawler to search for the source of the text snippets used for the evaluation and achieved the highest precision score. Additionally, we have crawled and cleaned the source articles of the snippets and produced the Daikon corpus that can be used for future research in diachronic/temporal analysis and epoch identification. Acknowledgements The research leading to these results has received funding from the People Programme (Marie Curie Actions) of the European Union’s Seventh Framework Programme FP7/2007-2013/ under REA grant agreement n ◦ 317471. In addition, we received</context>
</contexts>
<marker>Tan, Bond, 2011</marker>
<rawString>Liling Tan and Francis Bond. 2011. Building and Annotating the Linguistically Diverse NTU-MC (NTUMultilingual Corpus). In Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation, pages 362–371, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liling Tan</author>
<author>Anne Schumann</author>
<author>Jose Martinez</author>
<author>Francis Bond</author>
</authors>
<title>Sensible: L2 Translation Assistance by Emulating the Manual Post-Editing Process.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>541--545</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="6851" citStr="Tan et al. (2014" startWordPosition="1088" endWordPosition="1091">e learning classifiers for cases where test data is supposedly unknown, but more often than not it can be known by those who know how to retrieve, clean and harvest systematically. Prior to the days of Google and search engines, historians and librarians1 had to cross-reference history books and newspaper archives to identify the text epoch. The Internet is vast and infinite. Given the advent of Wikipedia and Google, epoch identification can be as simple as searching “When was Operation Desert Shield?” on Google2 (see Figure 1). Figure 1: Google Result for “When was Operation Desert Shield?”. Tan et al. (2014a) develop a Web Translation Memory (WebTM) crawler capable of harvesting parallel texts from the web given an initial seed corpus, similar to the BootCaT system (Baroni and Bernardini, 2004). They adapt WebTM such that it attempts to find occurrences of the text snippets from the web. This is akin to developing a dedicated 1With the exception of the polymath librarian, Flynn Carsen 2See http://goo.gl/VD2Xtx 847 search- and crawl-system for the purpose of knowledge extraction. Surprisingly, the source of the all the text snippets of Subtask 1 is found on http://freepages.genealogy.rootsweb .an</context>
<context position="11937" citStr="Tan et al., 2014" startWordPosition="1899" endWordPosition="1902">r each paragraph. To clean the corpus, the encodings are converted to Unicode (UTF8) and XML escape tokens are converted to its Unicode counterparts automatically5. However, the current version still contains minor tokenization errors such as the hyphenation error seen in Figure 3. Probably, a character language model could be developed to identify lexical items bounded by the r‘\w+- \w+’ regex. 7 Conclusion In this paper, we have described our submission to the Diachronic Text Evaluation for SemEval-2015. 5The cleaning tool used is a compilation of web cleaning scripts (Emerson et al., 2014; Tan et al., 2014b; Tan and Bond, 2011) We have adapted a web crawler to search for the source of the text snippets used for the evaluation and achieved the highest precision score. Additionally, we have crawled and cleaned the source articles of the snippets and produced the Daikon corpus that can be used for future research in diachronic/temporal analysis and epoch identification. Acknowledgements The research leading to these results has received funding from the People Programme (Marie Curie Actions) of the European Union’s Seventh Framework Programme FP7/2007-2013/ under REA grant agreement n ◦ 317471. In</context>
</contexts>
<marker>Tan, Schumann, Martinez, Bond, 2014</marker>
<rawString>Liling Tan, Anne Schumann, Jose Martinez, and Francis Bond. 2014a. Sensible: L2 Translation Assistance by Emulating the Manual Post-Editing Process. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 541–545, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liling Tan</author>
<author>Marcos Zampieri</author>
<author>Nikola Ljubeˇsic</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Merging Comparable Data Sources for the Discrimination of Similar Languages: The DSL Corpus Collection.</title>
<date>2014</date>
<booktitle>In Proceedings of The 7th Workshop on Building and Using Comparable Corpora (BUCC).</booktitle>
<marker>Tan, Zampieri, Ljubeˇsic, Tiedemann, 2014</marker>
<rawString>Liling Tan, Marcos Zampieri, Nikola Ljubeˇsic, and J¨org Tiedemann. 2014b. Merging Comparable Data Sources for the Discrimination of Similar Languages: The DSL Corpus Collection. In Proceedings of The 7th Workshop on Building and Using Comparable Corpora (BUCC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuerui Wang</author>
<author>Andrew McCallum</author>
</authors>
<title>Topics over Time: A Non-Markov Continuous-Time Model of Topical Trends.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>424--433</pages>
<contexts>
<context position="5358" citStr="Wang and McCallum (2006)" startWordPosition="831" endWordPosition="834">et it is unclear whether the resulting sense pool contains ngrams across different epochs. Juola (2013) uses the bigrams from the Google Books Ngram dataset to measure changes in the Kolmogorov complexity of American culture at ten-year intervals between 1900 and 2000. Related to this, ˇStajner and Zampieri (2013) show, for Portuguese, that lexical richness, average word length and lexical density increase over a span of 400 years. Topic models are also applied to study topical changes across epochs (e.g. (Blei and Lafferty, 2007; Wijaya and Yeniterzi, 2011)). Related to epoch identification, Wang and McCallum (2006) develop time-specific topic models to a time stamp prediction task. With the renaissance of neural nets, recent studies are using deep neural language models to detect diachronic lexical changes from several text types ranging from published books (Kim et al., 2014) to Twitter microblogs and Amazon movie reviews (Kulkarni et al., 2014). 3 Approach We take a different approach compared to previous studies that treat epoch identification as a classification task. We see it as an information retrieval task where we want to know whether we can get the temporal information of the text snippets fro</context>
</contexts>
<marker>Wang, McCallum, 2006</marker>
<rawString>Xuerui Wang and Andrew McCallum. 2006. Topics over Time: A Non-Markov Continuous-Time Model of Topical Trends. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 424–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Derry Tanti Wijaya</author>
<author>Reyyan Yeniterzi</author>
</authors>
<title>Understanding Semantic Change of Words over Centuries.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 international workshop on DETecting and Exploiting Cultural diversiTy on the social web,</booktitle>
<pages>35--40</pages>
<contexts>
<context position="5298" citStr="Wijaya and Yeniterzi, 2011" startWordPosition="823" endWordPosition="826">restingly, their experiments conflate the ngrams across time, yet it is unclear whether the resulting sense pool contains ngrams across different epochs. Juola (2013) uses the bigrams from the Google Books Ngram dataset to measure changes in the Kolmogorov complexity of American culture at ten-year intervals between 1900 and 2000. Related to this, ˇStajner and Zampieri (2013) show, for Portuguese, that lexical richness, average word length and lexical density increase over a span of 400 years. Topic models are also applied to study topical changes across epochs (e.g. (Blei and Lafferty, 2007; Wijaya and Yeniterzi, 2011)). Related to epoch identification, Wang and McCallum (2006) develop time-specific topic models to a time stamp prediction task. With the renaissance of neural nets, recent studies are using deep neural language models to detect diachronic lexical changes from several text types ranging from published books (Kim et al., 2014) to Twitter microblogs and Amazon movie reviews (Kulkarni et al., 2014). 3 Approach We take a different approach compared to previous studies that treat epoch identification as a classification task. We see it as an information retrieval task where we want to know whether </context>
</contexts>
<marker>Wijaya, Yeniterzi, 2011</marker>
<rawString>Derry Tanti Wijaya and Reyyan Yeniterzi. 2011. Understanding Semantic Change of Words over Centuries. In Proceedings of the 2011 international workshop on DETecting and Exploiting Cultural diversiTy on the social web, pages 35–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang-Chih Yu</author>
<author>Chung-Hsien Wu</author>
<author>Andrew Philpot</author>
<author>EH Hovy</author>
</authors>
<title>OntoNotes: Sense Pool Verification using Google N-gram and Statistical Tests.</title>
<date>2007</date>
<booktitle>In Proceedings of the OntoLex Workshop at the 6th International Semantic Web Conference (ISWC</booktitle>
<contexts>
<context position="4511" citStr="Yu et al. (2007)" startWordPosition="700" endWordPosition="703">anguage change; for this, they release ngrams taken from millions of digitized books; they show, for example, that censorship and suppression can be determined by comparing the frequencies of proper names in multilingual ngrams in this dataset. Mihalcea and Nastase (2012) explore word sense disambiguation over time using snippets from Google Books; they add a semantic dimension on top of lexical frequency to conduct word epoch disambiguation based on the fact that words change their neighbors throughout time. The Google Ngram corpus has spawned several related studies. To create a sense pool, Yu et al. (2007) extract pairs of ngrams and filter them with an appropriate statistical test using their frequencies, where the resulting sense pool is manually verified. Interestingly, their experiments conflate the ngrams across time, yet it is unclear whether the resulting sense pool contains ngrams across different epochs. Juola (2013) uses the bigrams from the Google Books Ngram dataset to measure changes in the Kolmogorov complexity of American culture at ten-year intervals between 1900 and 2000. Related to this, ˇStajner and Zampieri (2013) show, for Portuguese, that lexical richness, average word len</context>
</contexts>
<marker>Yu, Wu, Philpot, Hovy, 2007</marker>
<rawString>Liang-Chih Yu, Chung-Hsien Wu, Andrew Philpot, and EH Hovy. 2007. OntoNotes: Sense Pool Verification using Google N-gram and Statistical Tests. In Proceedings of the OntoLex Workshop at the 6th International Semantic Web Conference (ISWC 2007).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>