<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.053964">
<title confidence="0.994969">
Adaptation of POS Tagging for Multiple BioMedical Domains
</title>
<author confidence="0.992779">
John E. Miller1 Manabu Torii2 K. Vijay-Shanker1
</author>
<affiliation confidence="0.995156">
1Computer &amp; Information Sciences 2Biostatistics, Bioinformatics and Biomathematics
University of Delaware Georgetown University Medical Center
</affiliation>
<address confidence="0.891083">
Newark, DE 19716 Washington, DC 20057
</address>
<email confidence="0.999767">
{jmiller,vijay}@cis.udel.edu mt352@georgetown.edu
</email>
<sectionHeader confidence="0.999552" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999860421052632">
Part of Speech (POS) tagging is often a prerequi-
site for tasks such as partial parsing and informa-
tion extraction. However, when a POS tagger is
simply ported to another domain the tagger’s accu-
racy drops. This problem can be addressed through
hand annotation of a corpus in the new domain and
supervised training of a new tagger. In our meth-
odology, we use existing raw text and a generic
POS annotated corpus to develop taggers for new
domains without hand annotation or supervised
training. We focus in particular on out-of-
vocabulary words since they reduce accuracy
(Lease and Charniak. 2005; Smith et al. 2005).
There is substantial information in the deriva-
tional suffixes and few inflectional suffixes of
English. We look at individual words and their
suffixes along with the morphologically related
words to build a domain specific lexicon contain-
ing POS tags and probabilities for each word.
</bodyText>
<sectionHeader confidence="0.949671" genericHeader="method">
2 Adaptation Methodology
</sectionHeader>
<bodyText confidence="0.9999296875">
Our methodology is described in detail in Miller
et al (2007) and summarized here: 1) Process ge-
neric POS annotated text to obtain state and lexical
POS tag probabilities. 2) Obtain a frequency table
of words from a large corpus of raw sub-domain
text. 3) Construct a partial sub-domain lexicon
matching relative frequencies of morphologically
related words with words from the generic anno-
tated text averaging POS probabilities of the k
nearest neighbors. 4) Combine common generic
words and orthographic word categories with the
partial lexicon making the sub-domain lexicon. 5)
Train a first order Hidden Markov Model (HMM)
by Expectation Maximization (EM). 6) Apply the
Viterbi algorithm with the HMM to tag sub-
domain text.
</bodyText>
<sectionHeader confidence="0.922203" genericHeader="method">
3 Adaptation to Multiple Domains
</sectionHeader>
<bodyText confidence="0.99478684">
Molecular Biology Domain: We used the Wall
Street Journal corpus (WSJ) (Marcus et al, 1993)
as our generic POS annotated corpus. For our raw
un-annotated text we used 133,666 abstracts from
the MEDLINE distribution covering molecular
biology and biomedicine sub-domains. We split
the GENIA database (Tateisi et al, 2003) into
training and test portions and ignored the POS tags
for training. We ran a 5-fold cross validation study
and obtained an average accuracy of 95.77%.
Medical Domain: Again we used the WSJ as
our generic POS annotated corpus. For our raw un-
annotated text we used 164,670 abstracts from the
MEDLINE distribution with selection based on 83
journals from the medical domain. For our HMM
EM training we selected 1966 abstracts (same
journals). For evaluation purposes, we selected
1932 POS annotated sentences from the MedPost
(Smith et al, 2004) distribution (same journals).
The MedPost tag set coding was converted to the
Penn Treebank tag set using the utilities provided
with the MedPost tagger distribution. We obtained
an accuracy of 93.17% on the single medical test
corpus, a substantial drop from the 95.77% average
accuracy obtained in the GENIA corpus.
</bodyText>
<sectionHeader confidence="0.988664" genericHeader="method">
4 Coding Differences
</sectionHeader>
<bodyText confidence="0.999974666666667">
We looked at high frequency tagging errors in the
medical test set and found that many errors
resulted directly from the differences in the coding
styles between GENIA and MedPost. Our model
reflects the coding style of the WSJ, used for our
generic POS annotated text. GENIA largely fol-
lowed the WSJ coding conventions. Annotation in
the 1932 sentences taken from MedPost had some
systematic differences in coding style from this.
</bodyText>
<page confidence="0.960124">
179
</page>
<bodyText confidence="0.945060653846154">
BioNLP 2007: Biological, translational, and clinical language processing, pages 179–180,
Prague, June 2007. c�2007 Association for Computational Linguistics
Identified Differences: Lexical differences: 1)
Words such as ‘more’ and ‘less’ are JJR or RBR in
WSJ/GENIA but JJ or RB in MedPost. 2) Tokens
such as %, =, /, &lt;, &gt; are typically NN or JJ in
WSJ/GENIA but SYM in MedPost. 3)’be’ is VB in
WSJ/GENIA but VB or VBP in MedPost. 4) Some
orthographic categories are JJ in WSJ/GENIA but
NN in MedPost. Transition discrepancies: 1) Verbs
are tagged VB following a TO or MD in
WSJ/GENIA but only following a TO in MedPost.
2) MedPost prefers NN and NN-NN sequences.
Ad Hoc Adjustments: We constructed a new
lexicon accounting for some of the lexical differ-
ences and attained an accuracy of 94.15% versus
the previous 93.17%. Next we biased a few initial
state transition probabilities, changing P(VB|MD)
from very high to a very low and increasing
P(NN|NN), and attained an accuracy of 94.63%.
As the coding differences had nothing to do with
suffixes and suffix distributions, the central part of
our methodology, we tried some ad hoc fixes to
determine what our performance might have been.
We suffered at least a 1.46% drop in accuracy due
to differences in coding, not language use.
</bodyText>
<sectionHeader confidence="0.997801" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999814">
The table shows the accuracy of our tagger and a
few well-known taggers in our target biomedical
sub-domains.
</bodyText>
<table confidence="0.9978474">
Molecular Biology %Accuracy
- Our tagger (5-fold) 95.8%
- MedPost 94.1%
- Penn BioIE1 95.1%
- GENIA supervised 98.3%
Medical Domain
- Our tagger 93.17%
- Our tagger (+ lex bias) 94.15%
- Our tagger (+ lex &amp; trans bias) 94.63%
- MedPost supervised2 96.9%
</table>
<bodyText confidence="0.9928228">
The MedPost and Penn BioIE taggers used an-
notated text and supervised training in other bio-
medical domains, but they were not trained spe-
cifically for the GENIA Molecular Biology sub-
domain. Our tagger seems competitive with these
</bodyText>
<footnote confidence="0.51840775">
1 PennBioIE. 2005. Mining The Bibliome Project.
http://bioie.ldc.upenn.edu/.
2 Based on Medpost test set of 1000 sentences, not on our test
set of 1932 sentences.
</footnote>
<bodyText confidence="0.999905363636364">
taggers. We cannot claim superior accuracy as
these taggers may suffer the same coding bias ef-
fects we have noted. The superior performance of
the GENIA tagger (Tsuruoka et al. 2005) in the
Molecular Biology/GENIA domain and the Med-
Post tagger (Smith et al. 2004) in its biomedical
domain owes to their use of supervised training on
an annotated training set with evaluation on a test
set from the same domain. The approximate 1.5%
bias effect due to coding differences is attributable
to organizational differences in POS.
</bodyText>
<sectionHeader confidence="0.999461" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999914666666667">
To cope with domain specific vocabulary and uses
of vocabulary, we exploited the suffix information
of words and related words to build domain spe-
cific lexicons. We trained our HMM using EM and
un-annotated text from the specialized domains.
We assessed accuracy versus annotated test sets in
the specialized domains, noting discrepancies in
our results across specialized domains, and con-
cluding that our methodology performs competi-
tively versus well-known taggers that used anno-
tated text and supervised training in other biomedi-
cal domains.
</bodyText>
<sectionHeader confidence="0.998163" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999640863636364">
M. Lease and E. Charniak. 2005. Parsing Biomedical
Literature. IJCNLP-05: 58-69.
M. Marcus, B. Santorini, M.A. Marcinkiewicz. 1993.
Building a large annotated corpus of English: The
Penn Treebank. Comp. Ling., 19:313-330.
J.E. Miller, M. Torii, K. Vijay-Shanker. 2007. Building
Domain-Specific Taggers Without Annotated (Do-
main) Data. EMNLP-07.
L. Smith, T. Rindflesch, W.J. Wilbur. 2004. MedPost: a
part-of-speech tagger for bioMedical text. Bioinfor-
matics 20 (14):2320-2321.
L. Smith, T. Rindflesch, W.J. Wilbur. 2005. The impor-
tance of the lexicon in tagging biomedical text. Natu-
ral Language Engineering 12(2) 1-17.
Y. Tateisi, T. Ohta, J. Dong Kim, H. Hong, S. Jian, J.
Tsujii. 2003. The GENIA corpus: Medline abstracts
annotated with linguistic information. Third meeting
of SIG on Text Mining, ISMB.
Y. Tsuruoka, Y. Tateishi, J.D. Kim, T. Ohta, J.
McNaught, S. Ananiadou, J. Tsujii. 2005. Developing a
Robust Part-of-Speech Tagger for Biomedical Text,
Advances in Informatics, LNCS 3746: 382-392.
</reference>
<page confidence="0.997755">
180
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.818700">
<title confidence="0.99862">Adaptation of POS Tagging for Multiple BioMedical Domains</title>
<author confidence="0.929737">E Manabu K</author>
<affiliation confidence="0.9910315">amp; Information Sciences Bioinformatics and Biomathematics University of Delaware Georgetown University Medical Center</affiliation>
<address confidence="0.937019">Newark, DE 19716 Washington, DC 20057</address>
<email confidence="0.946706">mt352@georgetown.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Lease</author>
<author>E Charniak</author>
</authors>
<date>2005</date>
<booktitle>Parsing Biomedical Literature. IJCNLP-05:</booktitle>
<pages>58--69</pages>
<marker>Lease, Charniak, 2005</marker>
<rawString>M. Lease and E. Charniak. 2005. Parsing Biomedical Literature. IJCNLP-05: 58-69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank.</title>
<date>1993</date>
<pages>19--313</pages>
<publisher>Comp. Ling.,</publisher>
<contexts>
<context position="2130" citStr="Marcus et al, 1993" startWordPosition="324" endWordPosition="327">aw sub-domain text. 3) Construct a partial sub-domain lexicon matching relative frequencies of morphologically related words with words from the generic annotated text averaging POS probabilities of the k nearest neighbors. 4) Combine common generic words and orthographic word categories with the partial lexicon making the sub-domain lexicon. 5) Train a first order Hidden Markov Model (HMM) by Expectation Maximization (EM). 6) Apply the Viterbi algorithm with the HMM to tag subdomain text. 3 Adaptation to Multiple Domains Molecular Biology Domain: We used the Wall Street Journal corpus (WSJ) (Marcus et al, 1993) as our generic POS annotated corpus. For our raw un-annotated text we used 133,666 abstracts from the MEDLINE distribution covering molecular biology and biomedicine sub-domains. We split the GENIA database (Tateisi et al, 2003) into training and test portions and ignored the POS tags for training. We ran a 5-fold cross validation study and obtained an average accuracy of 95.77%. Medical Domain: Again we used the WSJ as our generic POS annotated corpus. For our raw unannotated text we used 164,670 abstracts from the MEDLINE distribution with selection based on 83 journals from the medical dom</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, M.A. Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Comp. Ling., 19:313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Miller</author>
<author>M Torii</author>
<author>K Vijay-Shanker</author>
</authors>
<title>Building Domain-Specific Taggers Without Annotated (Domain) Data.</title>
<date>2007</date>
<contexts>
<context position="1339" citStr="Miller et al (2007)" startWordPosition="199" endWordPosition="202">aw text and a generic POS annotated corpus to develop taggers for new domains without hand annotation or supervised training. We focus in particular on out-ofvocabulary words since they reduce accuracy (Lease and Charniak. 2005; Smith et al. 2005). There is substantial information in the derivational suffixes and few inflectional suffixes of English. We look at individual words and their suffixes along with the morphologically related words to build a domain specific lexicon containing POS tags and probabilities for each word. 2 Adaptation Methodology Our methodology is described in detail in Miller et al (2007) and summarized here: 1) Process generic POS annotated text to obtain state and lexical POS tag probabilities. 2) Obtain a frequency table of words from a large corpus of raw sub-domain text. 3) Construct a partial sub-domain lexicon matching relative frequencies of morphologically related words with words from the generic annotated text averaging POS probabilities of the k nearest neighbors. 4) Combine common generic words and orthographic word categories with the partial lexicon making the sub-domain lexicon. 5) Train a first order Hidden Markov Model (HMM) by Expectation Maximization (EM). </context>
</contexts>
<marker>Miller, Torii, Vijay-Shanker, 2007</marker>
<rawString>J.E. Miller, M. Torii, K. Vijay-Shanker. 2007. Building Domain-Specific Taggers Without Annotated (Domain) Data. EMNLP-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Smith</author>
<author>T Rindflesch</author>
<author>W J Wilbur</author>
</authors>
<title>MedPost: a part-of-speech tagger for bioMedical text.</title>
<date>2004</date>
<journal>Bioinformatics</journal>
<volume>20</volume>
<pages>14--2320</pages>
<contexts>
<context position="2905" citStr="Smith et al, 2004" startWordPosition="448" endWordPosition="451">omedicine sub-domains. We split the GENIA database (Tateisi et al, 2003) into training and test portions and ignored the POS tags for training. We ran a 5-fold cross validation study and obtained an average accuracy of 95.77%. Medical Domain: Again we used the WSJ as our generic POS annotated corpus. For our raw unannotated text we used 164,670 abstracts from the MEDLINE distribution with selection based on 83 journals from the medical domain. For our HMM EM training we selected 1966 abstracts (same journals). For evaluation purposes, we selected 1932 POS annotated sentences from the MedPost (Smith et al, 2004) distribution (same journals). The MedPost tag set coding was converted to the Penn Treebank tag set using the utilities provided with the MedPost tagger distribution. We obtained an accuracy of 93.17% on the single medical test corpus, a substantial drop from the 95.77% average accuracy obtained in the GENIA corpus. 4 Coding Differences We looked at high frequency tagging errors in the medical test set and found that many errors resulted directly from the differences in the coding styles between GENIA and MedPost. Our model reflects the coding style of the WSJ, used for our generic POS annota</context>
<context position="5998" citStr="Smith et al. 2004" startWordPosition="961" endWordPosition="964">d annotated text and supervised training in other biomedical domains, but they were not trained specifically for the GENIA Molecular Biology subdomain. Our tagger seems competitive with these 1 PennBioIE. 2005. Mining The Bibliome Project. http://bioie.ldc.upenn.edu/. 2 Based on Medpost test set of 1000 sentences, not on our test set of 1932 sentences. taggers. We cannot claim superior accuracy as these taggers may suffer the same coding bias effects we have noted. The superior performance of the GENIA tagger (Tsuruoka et al. 2005) in the Molecular Biology/GENIA domain and the MedPost tagger (Smith et al. 2004) in its biomedical domain owes to their use of supervised training on an annotated training set with evaluation on a test set from the same domain. The approximate 1.5% bias effect due to coding differences is attributable to organizational differences in POS. 6 Conclusions To cope with domain specific vocabulary and uses of vocabulary, we exploited the suffix information of words and related words to build domain specific lexicons. We trained our HMM using EM and un-annotated text from the specialized domains. We assessed accuracy versus annotated test sets in the specialized domains, noting </context>
</contexts>
<marker>Smith, Rindflesch, Wilbur, 2004</marker>
<rawString>L. Smith, T. Rindflesch, W.J. Wilbur. 2004. MedPost: a part-of-speech tagger for bioMedical text. Bioinformatics 20 (14):2320-2321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Smith</author>
<author>T Rindflesch</author>
<author>W J Wilbur</author>
</authors>
<title>The importance of the lexicon in tagging biomedical text.</title>
<date>2005</date>
<journal>Natural Language Engineering</journal>
<volume>12</volume>
<issue>2</issue>
<pages>1--17</pages>
<contexts>
<context position="967" citStr="Smith et al. 2005" startWordPosition="141" endWordPosition="144">on Part of Speech (POS) tagging is often a prerequisite for tasks such as partial parsing and information extraction. However, when a POS tagger is simply ported to another domain the tagger’s accuracy drops. This problem can be addressed through hand annotation of a corpus in the new domain and supervised training of a new tagger. In our methodology, we use existing raw text and a generic POS annotated corpus to develop taggers for new domains without hand annotation or supervised training. We focus in particular on out-ofvocabulary words since they reduce accuracy (Lease and Charniak. 2005; Smith et al. 2005). There is substantial information in the derivational suffixes and few inflectional suffixes of English. We look at individual words and their suffixes along with the morphologically related words to build a domain specific lexicon containing POS tags and probabilities for each word. 2 Adaptation Methodology Our methodology is described in detail in Miller et al (2007) and summarized here: 1) Process generic POS annotated text to obtain state and lexical POS tag probabilities. 2) Obtain a frequency table of words from a large corpus of raw sub-domain text. 3) Construct a partial sub-domain le</context>
</contexts>
<marker>Smith, Rindflesch, Wilbur, 2005</marker>
<rawString>L. Smith, T. Rindflesch, W.J. Wilbur. 2005. The importance of the lexicon in tagging biomedical text. Natural Language Engineering 12(2) 1-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tateisi</author>
<author>T Ohta</author>
<author>J Dong Kim</author>
<author>H Hong</author>
<author>S Jian</author>
<author>J Tsujii</author>
</authors>
<title>The GENIA corpus: Medline abstracts annotated with linguistic information.</title>
<date>2003</date>
<booktitle>Third meeting of SIG on Text Mining, ISMB.</booktitle>
<contexts>
<context position="2359" citStr="Tateisi et al, 2003" startWordPosition="358" endWordPosition="361">ombine common generic words and orthographic word categories with the partial lexicon making the sub-domain lexicon. 5) Train a first order Hidden Markov Model (HMM) by Expectation Maximization (EM). 6) Apply the Viterbi algorithm with the HMM to tag subdomain text. 3 Adaptation to Multiple Domains Molecular Biology Domain: We used the Wall Street Journal corpus (WSJ) (Marcus et al, 1993) as our generic POS annotated corpus. For our raw un-annotated text we used 133,666 abstracts from the MEDLINE distribution covering molecular biology and biomedicine sub-domains. We split the GENIA database (Tateisi et al, 2003) into training and test portions and ignored the POS tags for training. We ran a 5-fold cross validation study and obtained an average accuracy of 95.77%. Medical Domain: Again we used the WSJ as our generic POS annotated corpus. For our raw unannotated text we used 164,670 abstracts from the MEDLINE distribution with selection based on 83 journals from the medical domain. For our HMM EM training we selected 1966 abstracts (same journals). For evaluation purposes, we selected 1932 POS annotated sentences from the MedPost (Smith et al, 2004) distribution (same journals). The MedPost tag set cod</context>
</contexts>
<marker>Tateisi, Ohta, Kim, Hong, Jian, Tsujii, 2003</marker>
<rawString>Y. Tateisi, T. Ohta, J. Dong Kim, H. Hong, S. Jian, J. Tsujii. 2003. The GENIA corpus: Medline abstracts annotated with linguistic information. Third meeting of SIG on Text Mining, ISMB.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>Y Tateishi</author>
<author>J D Kim</author>
<author>T Ohta</author>
<author>J McNaught</author>
<author>S Ananiadou</author>
<author>J Tsujii</author>
</authors>
<title>Developing a Robust Part-of-Speech Tagger for Biomedical Text,</title>
<date>2005</date>
<booktitle>Advances in Informatics, LNCS</booktitle>
<volume>3746</volume>
<pages>382--392</pages>
<contexts>
<context position="5917" citStr="Tsuruoka et al. 2005" startWordPosition="947" endWordPosition="950">rans bias) 94.63% - MedPost supervised2 96.9% The MedPost and Penn BioIE taggers used annotated text and supervised training in other biomedical domains, but they were not trained specifically for the GENIA Molecular Biology subdomain. Our tagger seems competitive with these 1 PennBioIE. 2005. Mining The Bibliome Project. http://bioie.ldc.upenn.edu/. 2 Based on Medpost test set of 1000 sentences, not on our test set of 1932 sentences. taggers. We cannot claim superior accuracy as these taggers may suffer the same coding bias effects we have noted. The superior performance of the GENIA tagger (Tsuruoka et al. 2005) in the Molecular Biology/GENIA domain and the MedPost tagger (Smith et al. 2004) in its biomedical domain owes to their use of supervised training on an annotated training set with evaluation on a test set from the same domain. The approximate 1.5% bias effect due to coding differences is attributable to organizational differences in POS. 6 Conclusions To cope with domain specific vocabulary and uses of vocabulary, we exploited the suffix information of words and related words to build domain specific lexicons. We trained our HMM using EM and un-annotated text from the specialized domains. We</context>
</contexts>
<marker>Tsuruoka, Tateishi, Kim, Ohta, McNaught, Ananiadou, Tsujii, 2005</marker>
<rawString>Y. Tsuruoka, Y. Tateishi, J.D. Kim, T. Ohta, J. McNaught, S. Ananiadou, J. Tsujii. 2005. Developing a Robust Part-of-Speech Tagger for Biomedical Text, Advances in Informatics, LNCS 3746: 382-392.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>