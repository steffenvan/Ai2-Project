<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000191">
<title confidence="0.9984925">
Spoken Dialogue Control Based on a Turn-minimization
Criterion Depending on the Speech Recognition Accuracy
</title>
<author confidence="0.632798">
YASUDA Norihito and DOHSAKA Kohji and AIKAWA Kiyoaki
</author>
<affiliation confidence="0.559344">
NTT Communication Science Laboratories
</affiliation>
<address confidence="0.803033">
3-1 Morinosato-Wakamiya, Atsugi, Kanagawa, 243-0198 Japan
</address>
<email confidence="0.990346">
{yasuda, dohsaka}@atom.brl.ntt.co.jp, aik@idea.brl.ntt.co.jp
</email>
<sectionHeader confidence="0.993638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999922692307692">
This paper proposes a new dialogue
control method for spoken dialogue
systems. The method configures a
dialogue plan so as to minimize the
estimated number of turns to com-
plete the dialogue. The number of
turns is estimated depending on the
current speech recognition accuracy
and probability distribution of the
true user’s request. The proposed
method reduces the number of turns
to complete the task at almost any
recognition accuracy.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998668566666667">
A spoken dialogue system determines user
requests from user utterances. Spoken di-
alogue systems, however, can’t determine a
user’s request only from an initial utterance,
because there is a limitation to automatic
speech recognition and recognition errors are
unavoidable. Thus, most spoken dialogue sys-
tems confirm a user’s utterance or demand the
information that is lacking in order to deter-
mine user’s request. Such dialogues for con-
firmation or demand between the system and
the user are called “confirmation dialogues”.
Long confirmation dialogues are annoying, so
more efficient confirmation is desirable. To
measure the efficiency of the dialogue, we use
the number of turns (exchanges), where of
course, the fewer number of turns is better.
In practical applications, the system can
accepts multiple types of user requests like
“making a new appointment”, “changing a
schedule”, and “inquiring about a schedule”.
If the user request type is different, the re-
quired information for determining the user
request is also different. Sometimes the user
request type is ambiguous due to recognition
errors, and various types of user requests are
possible. In such a case, it is important for
the system to choose the type of user request
it will confirm at first, since it will be useless
to confirm items that are required for unlikely
type of request.
The recognition accuracy affects the effi-
ciency in other cases. For example, if there
are multiple items to be confirmed, intu-
itively, it seems efficient to confirm all of them
at once. However, the system must include
candidates for all attributes in recognition vo-
cabulary, which cause more recognition er-
rors. Moreover, even though there is only one
misrecognized item in confirmed items, the
user might just say coldly “No”, and the sys-
tem cannot know that what are correct items.
Several efficient dialogue control methods
have been proposed (Niimi and Kobayashi,
1996; Litman et al., 2000). But there is no
previous works that take into account mul-
tiple types of user requests and recognition
accuracy during confirmation, which changes
what to be confirmed without domain-specific
rules or training.
To prevent needlessly long confirmation di-
alogues even if the system can accepts mul-
tiple types of user request, our method esti-
mates the expected number of turns to a cer-
tain use request type and the approximated
probability distribution of user request types.
The expected number of turns can be derived
from the required vocabulary for confirmation
and base recognition accuracy under certain
vocabulary size.
</bodyText>
<sectionHeader confidence="0.753985" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.994683772727273">
Overview First, we describe about a sys-
tem to which we assume this method will be
applied. The system has belief state which
is represented by the set of attributes, their
values, and the certainty of the values. The
certainty is in [0 .. 1], and the certainty for
the determined value is 1. That is, if the
user replies “Yes” to the confirmation, the
system changes the certainty for that value to
1. In practice, we can use the score from the
recognition engine as this certainty. The sys-
tem changes the recognition vocabulary ac-
cording to the attributes to be confirmed at
each confirmation. At any given time, the
system either confirms or demands some at-
tribute(s); it doesn’t confirm and demand at
the same time. Any values required in order
to determine the user request are explicitly-
confirmed without exception. Words that are
irrelevant to the present confirmation are ex-
cluded from the recognition vocabulary. The
system knows the base recognition accuracy
under a certain vocabulary size, which is used
to estimate the recognition accuracy.
Our method can be divided roughly into
five parts; the first three parts are used to
obtain the expected number of turns, granting
that the user request type are already known,
the fourth part is used to approximate the
probability distribution of the user request,
and the last part is used to decide the next
action to be taken by the system.
The system needs to know only three sorts
of information: 1) the vocabulary for each
attribute; 2) the meaning constraints among
words like “If the family name of the person
is Yasuda, then his department must be ac-
counting”; and 3) the required information
for each type of user request like “To can-
cel an appointment; the day and the time are
required”. No other domain-specific rules or
training are necessary.
Guessing the Recognition Accuracy
Here we consider how to estimate the recogni-
tion accuracy during confirmation from con-
firmation target. Once attributes for confir-
mation are decided, the recognition vocabu-
lary will consist of the words accepted by the
attributes and general words for moving the
dialogue along that are at least necessary to
progress the dialogue such as “Yes”, “No”,
etc. We call the recognition accuracy at this
time the “attribute recognition accuracy”.
We adopt the rule of thumb that the recog-
nition error rate is in proportion to the square
root of vocabulary size (Rosenfeld, 1996; Nak-
agawa and Ida, 1998). Thus, the approxi-
mated attribute recognition accuracy can be
derived from the number of words accepted
by the attributes.
Note that the attribute recognition accu-
racy can’t be estimated beforehand, because
the candidates for some attributes are dynam-
ically change, as a result of the meaning con-
straints among words; if the value of one at-
tribute is fixed, then candidates for other at-
tributes will be limited to values that satisfy
the constraints. Besides, the degree of lim-
itation varies with the values. The relation
between the user’s family name and depart-
ment is such an example.
Turn Estimation to Determine Some
Attributes Next we consider how to esti-
mate the expected number of turns for de-
termining some attributes using the approxi-
mated attribute recognition accuracy.
We assume that the user’s reply to the con-
firmation must contain the intention that cor-
responds to “Yes” or “No”, and the inten-
tion must be transmitted to the system with-
out fail. Then, the expected number of turns
to complete confirming for some attributes is
equal to the expected number of turns in the
case that the confirmation is incorrect (i.e.
misrecognized). Therefore, we can derive the
number of expected turns to complete con-
firming Tc and demanding Td for some at-
tributes by the following expression:
</bodyText>
<equation confidence="0.898473111111111">
1
tr(1
r
Td = Tc + 1 = 1 +
∞
Tc = E
t=1
1
r
</equation>
<bodyText confidence="0.9965295625">
where r denotes the attribute recognition ac-
curacy for attributes that are to be confirmed.
Turn Estimation to a Certain User Re-
quest Type Here we estimate the expected
number of turns, granting that the type of
user request is already known.
If the user request type is fixed, the re-
quired attributes for that type are also fixed.
By comparing the belief state with these at-
tributes, we can represent the required actions
to determine the user request by a set of pairs
made up of attributes and actions for the at-
tribute (confirmation or demand). Once this
set of pairs is given, we can choose the optimal
plan, because we can estimate the expected
turns of any permutations of any partitions
of this set. The expected number of turns
for this optiomal plan is used as the expected
number of turns for a given user request type.
Probability Distribution of User Re-
quest Types Here, we consider how to es-
timate the relevance between the belief state
and each user request types.
As it is hard to obtain the actual probabil-
ity distribution, we define the degree of rele-
vance between the belief state and each user
request type as an approximation.
Let ai, vi, ci be the i-th attribute, the value
of ai, and the certainty of vi respectively. We
define the relevance Rel(S, Rj) between the
belief state S and the user request type Rj as
for any vi which can be accepted
</bodyText>
<equation confidence="0.8195714">
by Rj:
1
� ci
Rel(S, Rj) =
NGS M„i
</equation>
<bodyText confidence="0.983268391304348">
where NRS denotes the number of required at-
tributes in user request type Rj, and M„i de-
notes the number of user requests that accept
the value vi.
Choosing the Next Action Even if there
is a highly possible user request type, choos-
ing confirmation plan for it is not always best,
if the expected number of turns for that re-
quest is very large. In such case, confirm-
ing another type of request that is easily con-
firmed and medium possibility may better.
We assume that when the user request type
guessed by the system is not the real user re-
quest type, the number of turns required to
know that the guess is incorrect is equal to
the number of turns when the guess is correct
and finish confirming the contents.
Let pRi be the probability of user request
type Ri, and tRi be the expected number of
turns to user request type Ri.
From permutations of request types,
our method chooses the optimal order
a(1), a(2), ..., a(n) such that the expression
</bodyText>
<equation confidence="0.9474525">
pRa(1)tRa(1) + pRa(2)(tRa(1) + tRa(2)) + ... +
pRa(n)(tRa(1) + . . . + tRa(n)) is minimal. Then
</equation>
<bodyText confidence="0.998096">
our method chooses the action that appears
first in the optimal plan for request type Ra(1)
as the next action.
</bodyText>
<sectionHeader confidence="0.99939" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9465142">
We evaluated the proposed method by simula-
tion. In the simulation, the system conversed
with a simulated user program. Simulation
with a simulated user enables rapid prototyp-
ing and evaluation (Eckert et al., 1998). The
conversation was not done by exchanging spo-
ken language, but by exchanging attribute-
value pairs.
Simulated User Program The simulated
user program works in the following steps:
</bodyText>
<listItem confidence="0.999806444444445">
1. Select a request. The request never
changes throughout the dialogue
2. Tell the system the request or a subset of
the request
3. Respond Yes or No if the system confirms
4. Give corrections at random if confirma-
tion contains errors
5. Respond to the demand from the system
6. Tell the system that there is no infor-
</listItem>
<bodyText confidence="0.776716692307692">
mation if the system refers to attributes
with which the user is not concerned
Specification of Test Task We prepared
a fictitious task for simulation. This task ac-
cepts six types of user demand. There are
six attributes, and two of them have meaning
dependence like the family name and depart-
ment. The numbers of persons, family names,
and departments are 3000, 1000, 300 respec-
tively.
mean number of turns
0.65 0.7 0.75 0.8 0.85 0.9 0.95 1
recognition rate under 500 words vocaburaly
</bodyText>
<figureCaption confidence="0.9895615">
Figure 1: Average number of turns to com-
plete a dialogue
</figureCaption>
<bodyText confidence="0.5710695">
0.65 0.7 0.75 0.8 0.85 0.9 0.95 1
recognition rate under 500 words vocaburaly
</bodyText>
<figureCaption confidence="0.9913735">
Figure 2: Variance of the number of turns to
complete a dialogue
</figureCaption>
<bodyText confidence="0.771596130434782">
Comparison with a Naive Method For
comparison, we prepared a naive confirmation
dialogue control method, with the following
specifications:
1. If the user request can be fixed uniquely
and there are unbound attributes re-
quired for that request, demand those at-
tributes one by one.
2. If there are values that are not confirmed,
confirm them one by one.
3. If the user request type can’t be fixed yet,
demand a value for an attribute in the
order of the number of user request types
that require that attribute.
Experimental Results Figures 1 and 2
show the average number of turns and its vari-
ance out of 1000 diaglogue. We can see from
these figures that our method can complete
dialogues in shorter turns than other methods
under various levels of recognition accuracy.
In addition, the variance is small in almost
every range, which illustrates the stability of
our method.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999947416666667">
A new dialogue control method is proposed.
The method takes into consideration the ex-
pected number of turns based on the guessed
recognition accuracy and the approximated
probability distribution of user requests.
We don’t have to write domain-specific
rules manually by using this method. We can
thus easily transfer domain of the system.
We evaluated our method by simulation.
The result shows that it can complete di-
alogues in shorter turns than conventional
methods under various recognition accuracy.
</bodyText>
<sectionHeader confidence="0.996038" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99992375">
We thank Ken’ichiro Ishii, Norihiro Hagita,
and all our colleagues in the Dialogue Un-
derstanding Research Group for useful discus-
sions.
</bodyText>
<sectionHeader confidence="0.999207" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9978681">
Wieland Eckert, Esther Levin, and Roberto Pier-
accini. 1998. Automatic evaluation of spoken
dialogue systems. In TWLT13: Formal seman-
tics and pragmatics of dialogue.
Diane J. Litman, Michael S. Kearns, and Mari-
lyn A. Walker. 2000. Automatic optimization
of dialogue management. In COLING.
Seiichi Nakagawa and Masaki Ida. 1998. A
new measure of task complexity for continuous
speech recognition. IEICE, J81-D-II(7):1491–
1500(in Japanese).
Yasuhisa Niimi and Yutaka Kobayashi. 1996. Di-
alog control stragey based on the reliability of
speech recognition. In International Confer-
ence on Spoken Language Processing, pages 25–
30.
R. Rosenfeld. 1996. A maximum entropy ap-
proach to adaptive statistical language model-
ing. Computer, Speech and Language, 10:187–
228.
</reference>
<figure confidence="0.990405052631579">
16
14
12
10
8
6
4
2
Our method
Naive method
variance of the number of turns
100
40
20
80
60
0
Our method
Naive method
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.930524">
<title confidence="0.990893">Spoken Dialogue Control Based on a Criterion Depending on the Speech Recognition Accuracy</title>
<author confidence="0.996799">Norihito Kohji</author>
<affiliation confidence="0.999682">NTT Communication Science</affiliation>
<address confidence="0.991505">3-1 Morinosato-Wakamiya, Atsugi, Kanagawa, 243-0198</address>
<email confidence="0.978262">aik@idea.brl.ntt.co.jp</email>
<abstract confidence="0.998561642857143">This paper proposes a new dialogue control method for spoken dialogue systems. The method configures a dialogue plan so as to minimize the estimated number of turns to complete the dialogue. The number of turns is estimated depending on the current speech recognition accuracy and probability distribution of the true user’s request. The proposed method reduces the number of turns to complete the task at almost any recognition accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Wieland Eckert</author>
<author>Esther Levin</author>
<author>Roberto Pieraccini</author>
</authors>
<title>Automatic evaluation of spoken dialogue systems. In TWLT13: Formal semantics and pragmatics of dialogue.</title>
<date>1998</date>
<contexts>
<context position="9938" citStr="Eckert et al., 1998" startWordPosition="1672" endWordPosition="1675">nd tRi be the expected number of turns to user request type Ri. From permutations of request types, our method chooses the optimal order a(1), a(2), ..., a(n) such that the expression pRa(1)tRa(1) + pRa(2)(tRa(1) + tRa(2)) + ... + pRa(n)(tRa(1) + . . . + tRa(n)) is minimal. Then our method chooses the action that appears first in the optimal plan for request type Ra(1) as the next action. 3 Experiments We evaluated the proposed method by simulation. In the simulation, the system conversed with a simulated user program. Simulation with a simulated user enables rapid prototyping and evaluation (Eckert et al., 1998). The conversation was not done by exchanging spoken language, but by exchanging attributevalue pairs. Simulated User Program The simulated user program works in the following steps: 1. Select a request. The request never changes throughout the dialogue 2. Tell the system the request or a subset of the request 3. Respond Yes or No if the system confirms 4. Give corrections at random if confirmation contains errors 5. Respond to the demand from the system 6. Tell the system that there is no information if the system refers to attributes with which the user is not concerned Specification of Test</context>
</contexts>
<marker>Eckert, Levin, Pieraccini, 1998</marker>
<rawString>Wieland Eckert, Esther Levin, and Roberto Pieraccini. 1998. Automatic evaluation of spoken dialogue systems. In TWLT13: Formal semantics and pragmatics of dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane J Litman</author>
<author>Michael S Kearns</author>
<author>Marilyn A Walker</author>
</authors>
<title>Automatic optimization of dialogue management.</title>
<date>2000</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="2734" citStr="Litman et al., 2000" startWordPosition="417" endWordPosition="420">nlikely type of request. The recognition accuracy affects the efficiency in other cases. For example, if there are multiple items to be confirmed, intuitively, it seems efficient to confirm all of them at once. However, the system must include candidates for all attributes in recognition vocabulary, which cause more recognition errors. Moreover, even though there is only one misrecognized item in confirmed items, the user might just say coldly “No”, and the system cannot know that what are correct items. Several efficient dialogue control methods have been proposed (Niimi and Kobayashi, 1996; Litman et al., 2000). But there is no previous works that take into account multiple types of user requests and recognition accuracy during confirmation, which changes what to be confirmed without domain-specific rules or training. To prevent needlessly long confirmation dialogues even if the system can accepts multiple types of user request, our method estimates the expected number of turns to a certain use request type and the approximated probability distribution of user request types. The expected number of turns can be derived from the required vocabulary for confirmation and base recognition accuracy under </context>
</contexts>
<marker>Litman, Kearns, Walker, 2000</marker>
<rawString>Diane J. Litman, Michael S. Kearns, and Marilyn A. Walker. 2000. Automatic optimization of dialogue management. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seiichi Nakagawa</author>
<author>Masaki Ida</author>
</authors>
<title>A new measure of task complexity for continuous speech recognition.</title>
<date>1998</date>
<booktitle>IEICE, J81-D-II(7):1491– 1500(in Japanese).</booktitle>
<contexts>
<context position="5810" citStr="Nakagawa and Ida, 1998" startWordPosition="930" endWordPosition="934">g the Recognition Accuracy Here we consider how to estimate the recognition accuracy during confirmation from confirmation target. Once attributes for confirmation are decided, the recognition vocabulary will consist of the words accepted by the attributes and general words for moving the dialogue along that are at least necessary to progress the dialogue such as “Yes”, “No”, etc. We call the recognition accuracy at this time the “attribute recognition accuracy”. We adopt the rule of thumb that the recognition error rate is in proportion to the square root of vocabulary size (Rosenfeld, 1996; Nakagawa and Ida, 1998). Thus, the approximated attribute recognition accuracy can be derived from the number of words accepted by the attributes. Note that the attribute recognition accuracy can’t be estimated beforehand, because the candidates for some attributes are dynamically change, as a result of the meaning constraints among words; if the value of one attribute is fixed, then candidates for other attributes will be limited to values that satisfy the constraints. Besides, the degree of limitation varies with the values. The relation between the user’s family name and department is such an example. Turn Estima</context>
</contexts>
<marker>Nakagawa, Ida, 1998</marker>
<rawString>Seiichi Nakagawa and Masaki Ida. 1998. A new measure of task complexity for continuous speech recognition. IEICE, J81-D-II(7):1491– 1500(in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhisa Niimi</author>
<author>Yutaka Kobayashi</author>
</authors>
<title>Dialog control stragey based on the reliability of speech recognition.</title>
<date>1996</date>
<booktitle>In International Conference on Spoken Language Processing,</booktitle>
<pages>25--30</pages>
<contexts>
<context position="2712" citStr="Niimi and Kobayashi, 1996" startWordPosition="413" endWordPosition="416">ems that are required for unlikely type of request. The recognition accuracy affects the efficiency in other cases. For example, if there are multiple items to be confirmed, intuitively, it seems efficient to confirm all of them at once. However, the system must include candidates for all attributes in recognition vocabulary, which cause more recognition errors. Moreover, even though there is only one misrecognized item in confirmed items, the user might just say coldly “No”, and the system cannot know that what are correct items. Several efficient dialogue control methods have been proposed (Niimi and Kobayashi, 1996; Litman et al., 2000). But there is no previous works that take into account multiple types of user requests and recognition accuracy during confirmation, which changes what to be confirmed without domain-specific rules or training. To prevent needlessly long confirmation dialogues even if the system can accepts multiple types of user request, our method estimates the expected number of turns to a certain use request type and the approximated probability distribution of user request types. The expected number of turns can be derived from the required vocabulary for confirmation and base recog</context>
</contexts>
<marker>Niimi, Kobayashi, 1996</marker>
<rawString>Yasuhisa Niimi and Yutaka Kobayashi. 1996. Dialog control stragey based on the reliability of speech recognition. In International Conference on Spoken Language Processing, pages 25– 30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rosenfeld</author>
</authors>
<title>A maximum entropy approach to adaptive statistical language modeling.</title>
<date>1996</date>
<journal>Computer, Speech and Language,</journal>
<volume>10</volume>
<pages>228</pages>
<contexts>
<context position="5785" citStr="Rosenfeld, 1996" startWordPosition="928" endWordPosition="929">ecessary. Guessing the Recognition Accuracy Here we consider how to estimate the recognition accuracy during confirmation from confirmation target. Once attributes for confirmation are decided, the recognition vocabulary will consist of the words accepted by the attributes and general words for moving the dialogue along that are at least necessary to progress the dialogue such as “Yes”, “No”, etc. We call the recognition accuracy at this time the “attribute recognition accuracy”. We adopt the rule of thumb that the recognition error rate is in proportion to the square root of vocabulary size (Rosenfeld, 1996; Nakagawa and Ida, 1998). Thus, the approximated attribute recognition accuracy can be derived from the number of words accepted by the attributes. Note that the attribute recognition accuracy can’t be estimated beforehand, because the candidates for some attributes are dynamically change, as a result of the meaning constraints among words; if the value of one attribute is fixed, then candidates for other attributes will be limited to values that satisfy the constraints. Besides, the degree of limitation varies with the values. The relation between the user’s family name and department is suc</context>
</contexts>
<marker>Rosenfeld, 1996</marker>
<rawString>R. Rosenfeld. 1996. A maximum entropy approach to adaptive statistical language modeling. Computer, Speech and Language, 10:187– 228.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>